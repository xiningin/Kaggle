{"cell_type":{"aedd2aac":"code","cf0ccb73":"code","775114f9":"code","8b3f29eb":"code","81a48b64":"code","dc264a60":"code","c61c88d9":"code","d634e5e0":"code","7173b1f3":"code","3bb6670a":"code","a8d1063f":"code","b5f2f979":"code","429a2734":"code","ae20a7f3":"code","80b427b7":"code","20bde882":"code","4e37b194":"code","6718e1e5":"code","1060642c":"code","ad557438":"code","956b02e9":"markdown","3e92fdea":"markdown","0a1de9b2":"markdown","3efaac45":"markdown","f3d5bd26":"markdown","94395996":"markdown","8fe69c7f":"markdown","47beefa7":"markdown"},"source":{"aedd2aac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf0ccb73":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","775114f9":"dataset = pd.read_csv('..\/input\/car-price-prediction\/CarPrice_Assignment.csv')","8b3f29eb":"\nX = np.delete(dataset.values,[0,2,8,25],1)\ny = dataset.iloc[:,24:25].values\ny_bwd = dataset.iloc[:,25].values","81a48b64":"# Introduce dummy variables\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder","dc264a60":"columnTransformer = ColumnTransformer([('fuelType_encoder', OneHotEncoder(), [1])], remainder='passthrough')\nX = columnTransformer.fit_transform(X)\nX = X[:,1:] #Keep only 1 fuel type column\n","c61c88d9":"columnTransformer = ColumnTransformer([('aspiration_encoder', OneHotEncoder(), [2])], remainder='passthrough')\nX = columnTransformer.fit_transform(X)\nX = X[:,1:] #Keep only 1 aspiraion column","d634e5e0":"columnTransformer = ColumnTransformer([('doorNumber_encoder', OneHotEncoder(), [3])], remainder='passthrough')\nX = columnTransformer.fit_transform(X)\nX = X[:,1:] #Keep only 1 door column","7173b1f3":"columnTransformer = ColumnTransformer([('carBody_encoder', OneHotEncoder(), [4])], remainder='passthrough')\nX = columnTransformer.fit_transform(X)\nX = X[:,1:] #Keep only 3 car body columns","3bb6670a":"columnTransformer = ColumnTransformer([('driveWheel_encoder', OneHotEncoder(), [8])], remainder='passthrough')\nX = columnTransformer.fit_transform(X)\nX = X[:,1:] #Keep only 2 drive wheel columns","a8d1063f":"columnTransformer = ColumnTransformer([('engineType_encoder', OneHotEncoder(), [15])], remainder='passthrough')\nX = columnTransformer.fit_transform(X)\nX = X[:,1:] #Keep only 6 engine type columns","b5f2f979":"columnTransformer = ColumnTransformer([('cylinderNumber_encoder', OneHotEncoder(), [21])], remainder='passthrough')\nX = columnTransformer.fit_transform(X)\nX = X[:,1:] #Keep one less cylinder number column","429a2734":"columnTransformer = ColumnTransformer([('fuelSystem_encoder', OneHotEncoder(), [28])], remainder='passthrough')\nX = columnTransformer.fit_transform(X)\nX = X[:,1:] #Keep one less fuel system type columns","ae20a7f3":"# Backward Elimination\nimport statsmodels.api as sm\nX = np.append(arr = np.ones((205,1)).astype(int),values=X,axis=1)","80b427b7":"def backwardElimination(x, sl):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        regressor_OLS = sm.OLS(y_bwd, x).fit()\n        maxVar = max(regressor_OLS.pvalues).astype(float)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n    regressor_OLS.summary()\n    return x","20bde882":"SL = 0.05\nX = np.array(X,dtype=float)\nX_bwd_elm = backwardElimination(X, SL)\n","4e37b194":"#Test Train split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X_bwd_elm,y,test_size=0.2,random_state=0)\n","6718e1e5":"#Scaling of data\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)\nsc_Y = StandardScaler()\ny_train = sc_Y.fit_transform(y_train)\ny_test = sc_Y.transform(y_test)\n","1060642c":"#SVR\nfrom sklearn.svm import SVR\nsvr_regressor = SVR(kernel='linear')\nsvr_regressor.fit(X_train,y_train)\n\ny_pred = svr_regressor.predict(X_test)\n","ad557438":"from sklearn.metrics import mean_absolute_error\nprint (\"Mean Absolute Error: \", (mean_absolute_error(y_test, y_pred)))","956b02e9":"# **Separate Dependent and Independent Variables** \n- We extract the matrix of independent features (X) and dependent values (y) from the datatset\n- We also delete the redundant features from the X matrix, this includes - \n\n    1. Car id : has no impact on predicted value\n    2. Car Name: can be inferrred from symboling\n    3. Engine Location: column has constant value of front in every row\n","3e92fdea":"# **SVR Model created**","0a1de9b2":"# **Error Calculated**","3efaac45":"# **Data Scaling**\nThe given test train data is now scaled.\nThis ensures that the significance of each independent variable properly impacts the predicted value (y)\nWe scale both X & y","f3d5bd26":"# **Test-Train Split**\nWe split the given X & y matrices into test and train data","94395996":"#  **Avoid dummy variable trap**\n\nFor the independent variable's categorical values, we perform One hot encoding in order to get them in binary form. Also, for given *n categories* we only need *n-1* binary columns","8fe69c7f":"# **Backward Elimination**\nWe perform backward elimination on the matrix of independent variables (X).\nWe do this using OLS data and using the p-values of individual columns.\nThe significance level or SL = 0.05","47beefa7":"# **IMPORT ESSENTIAL LIBRARIES**"}}