{"cell_type":{"ea39ac7b":"code","71b1d84f":"code","01f895b5":"code","fce870ae":"code","216bdc92":"code","1ca3db71":"code","a889e9b4":"code","17f84217":"code","64766c5a":"code","b8e21c8e":"code","8245408b":"code","6c5166ff":"code","7bb4d0f3":"code","bcf990e6":"code","d2b1e1a3":"code","7aa1d1a6":"code","59fc3f75":"code","8679effa":"code","03aa29fb":"code","c6790571":"code","20518906":"code","066b7511":"code","f2978219":"code","d4ccb0f2":"code","7b04aabd":"code","001413ad":"markdown","09cb785c":"markdown","03748030":"markdown","3569248d":"markdown","7af8dd9c":"markdown","e84b3fa7":"markdown"},"source":{"ea39ac7b":"import pandas as pd\nimport numpy as np\nimport nltk \nfrom nltk.corpus import PlaintextCorpusReader\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","71b1d84f":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","01f895b5":"def removeurls(text):\n    regex= r'(https*:\\\/\\\/)(\\s)*(www\\.)*(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*'\n    return re.sub(regex,\" \",text)","fce870ae":"def removespecialchar(text):\n    regex= r\"[^A-Za-z0-9]\"\n    return re.sub(regex,\" \",text)","216bdc92":"def removeblanks(text):\n    return re.sub(r'\\s\\s+',\" \",text)","1ca3db71":"import random","a889e9b4":"sample_trial=[]\ndef samples(arg):\n    for i in range(0,200):\n        x = random.sample(arg,100)\n        sample_trial.append(x)\n    return sample_trial","17f84217":"def datacleaning(arg):\n    clean_data1 = removeurls(arg)\n    clean_data2 = removespecialchar(clean_data1)\n    clean_data3 = removeblanks(clean_data2)\n    tokenized_data = word_tokenize(clean_data3)\n    return tokenized_data","64766c5a":"book_data= open(\"\/kaggle\/input\/nlp-on-gutenberg-textual-data\/Aspects_of_nature.txt\",encoding='cp1252')\ndata1= book_data.read().replace(\"\\n\",\" \")\nbook_data.close()","b8e21c8e":"data1[0:1000]","8245408b":"clean_text_1= datacleaning(data1)","6c5166ff":"clean_text_1[0:8]","7bb4d0f3":"book_data2= open(\"\/kaggle\/input\/nlp-on-gutenberg-textual-data\/The_Bird_Boys.txt\",encoding='cp1252')\ndata2= book_data2.read().replace(\"\\n\",\" \")\nbook_data2.close()","bcf990e6":"data2[1000:1800]","d2b1e1a3":"clean_text_2= datacleaning(data2)","7aa1d1a6":"clean_text_2[0:8]","59fc3f75":"book_data3= open(\"\/kaggle\/input\/nlp-on-gutenberg-textual-data\/The_Truth_About_Lynching.txt\",encoding='cp1252')\ndata3= book_data3.read().replace(\"\\n\",\" \")\nbook_data2.close()","8679effa":"data3[1000:1800]","03aa29fb":"clean_text_3= datacleaning(data3)","c6790571":"clean_text_3[0:8]","20518906":"Aspects_of_nature = samples(clean_text_1)\nThe_Bird_Boys = samples(clean_text_2)\nThe_Truth_About_Lynching = samples(clean_text_3)","066b7511":"print(\"A single sample has\",len(Aspects_of_nature[1]),\"words\")\nprint(\"200th sample containing 100 words: \",\"\\n\",Aspects_of_nature[200])","f2978219":"import itertools\nnest= list(itertools.zip_longest(Aspects_of_nature,The_Bird_Boys,The_Truth_About_Lynching))","d4ccb0f2":"df = pd.DataFrame(nest, columns = ['Aspects_of_nature','The_Bird_Boys','The_Truth_About_Lynching'])","7b04aabd":"df.head(10)","001413ad":"### The Truth About Lynching","09cb785c":"### Ebook- Aspects of nature","03748030":"### Ebook- The Bird Boys","3569248d":"### Functions for data cleaning ","7af8dd9c":"### Random Sampling of 3 books\n200 samples of 100 random words for each book","e84b3fa7":"### A dataframe for all the books"}}