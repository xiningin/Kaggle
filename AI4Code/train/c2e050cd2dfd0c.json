{"cell_type":{"cdd06ead":"code","c69ccab2":"code","1a069572":"code","f153b021":"code","8bca3d37":"code","dba24689":"markdown","c41e5e2c":"markdown","d865d818":"markdown","cce22843":"markdown"},"source":{"cdd06ead":"from sklearn.datasets import make_classification\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nfrom matplotlib import pyplot","c69ccab2":"# define dataset\nX, y = make_classification(n_samples=1000, n_features=100, n_informative=10, n_redundant=90, random_state=1)\n# number of input columns\nn_inputs = X.shape[1]\n# split into train test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n# scale data\nt = MinMaxScaler()\nt.fit(X_train)\nX_train = t.transform(X_train)\nX_test = t.transform(X_test)","1a069572":"# define encoder\nvisible = Input(shape=(n_inputs,))\n# encoder level 1\ne = Dense(n_inputs*2)(visible)\ne = BatchNormalization()(e)\ne = LeakyReLU()(e)\n# encoder level 2\ne = Dense(n_inputs)(e)\ne = BatchNormalization()(e)\ne = LeakyReLU()(e)\n# bottleneck\nn_bottleneck = n_inputs\nbottleneck = Dense(n_bottleneck)(e)\n# define decoder, level 1\nd = Dense(n_inputs)(bottleneck)\nd = BatchNormalization()(d)\nd = LeakyReLU()(d)\n# decoder level 2\nd = Dense(n_inputs*2)(d)\nd = BatchNormalization()(d)\nd = LeakyReLU()(d)\n# output layer\noutput = Dense(n_inputs, activation='linear')(d)\n# define autoencoder model\nmodel = Model(inputs=visible, outputs=output)\n# compile autoencoder model\nmodel.compile(optimizer='adam', loss='mse')\n\n# fit the autoencoder model to reconstruct input\nhistory = model.fit(X_train, X_train, epochs=200, batch_size=16, verbose=0, validation_data=(X_test,X_test))","f153b021":"plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)","8bca3d37":"# plot loss\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()\n# define an encoder model (without the decoder)\nencoder = Model(inputs=visible, outputs=bottleneck)","dba24689":"# Dataset","c41e5e2c":"# Analyze","d865d818":"# Model","cce22843":"# Autoencoder for classification"}}