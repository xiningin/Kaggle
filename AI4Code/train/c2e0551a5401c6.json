{"cell_type":{"af93629a":"code","8a58bb4d":"code","c216b7ce":"code","643b346e":"code","f078ee0c":"code","6206420c":"code","542efce6":"code","4289d01d":"code","da7e3b07":"code","1af45884":"code","df1fb2f5":"code","6f204464":"code","bc90f8ea":"code","3ca7cf11":"code","dccad73d":"code","55099217":"markdown","939d4c0f":"markdown"},"source":{"af93629a":"import numpy as np\nimport pandas as pd \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.classify import SklearnClassifier\nfrom wordcloud import WordCloud,STOPWORDS\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom subprocess import check_output\nfrom IPython.display import Image\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","8a58bb4d":"PATH = \"\/kaggle\/input\/sentiment-analysis-report\/\"\nImage(filename = PATH + \"PA Sentiment Analysis Report.jpg\", width=1000, height=600)\n##Created Using excel & below anlysis data set. ","c216b7ce":"data = pd.read_excel(\"\/kaggle\/input\/sampledatafbpav1\/Sample Data.xlsx\")","643b346e":"data.head()","f078ee0c":"data_corr = data[['Comments','Like','Shares','Heart','Care','Sad\/Angry','Surprised']]","6206420c":"plt.figure(figsize=(16,6))\nsns.heatmap(data_corr.corr(), annot=True, cmap='Blues') \nplt.title(\"Last 10 Post Sentiment Correlation\")","542efce6":"data['Date']=data['Date'].apply(lambda x:x.strftime('%m-%d'))","4289d01d":"plt.figure(figsize=(16,6))\ndata.plot()","da7e3b07":"comments=data['Comments.1']\nwords = ' '.join(comments)\nwords_withoutStopwords = [i for i in words.lower().split() if i not in stopwords.words('english')]","1af45884":"clean_word= ' '.join(words_withoutStopwords)","df1fb2f5":" cleaned_word = \" \".join([word for word in clean_word.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and not word.startswith('#')\n                                and word != 'rc'\n                            ])","6f204464":"wordcloud = WordCloud(stopwords=STOPWORDS,background_color='white',width=850,height=450).generate(cleaned_word)\nplt.figure(1,figsize=(10, 5))\nplt.title(\"Word Cloud - Most Comman Words In Comments\")\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","bc90f8ea":"word1=cleaned_word.split()\ndf=pd.DataFrame(word1,columns=['word'])\nw1=df['word'].value_counts()\nw1.head()","3ca7cf11":"df2=pd.DataFrame(w1)\ndf3=df2.sort_values('word',ascending=False).head(20)\ndf3.plot(kind='bar')","dccad73d":"df4=df2.sort_values('word',ascending=True).head(20)\ndf4.plot(kind='bar')","55099217":"### Objective : Quick Basic Sentiment Analysis \n**Data Set**: From Facebook Post\/Feed.\n**Tech Use**: NLTK, Word Cloud & basic libraries of Python. \n\n***Steps*: **\n1. Exploratory Data Analysis to undestand different vairables, its impact on KPI's & corelation \n2. Data Cleansing to remove junk characters\/words \n3. Data Preparation likes of removing stop words, combining comments in order to feed to word cloud \n4. Word Cloud Formataion \n5. Identify Top\/Most common words used in comments by users \n6. Identify Bottom\/Lest common words used in comments by users \n7. Collate all information and create summary report\/dashboard using Excel\n\n***Last but not the least if you like this don't forget to upvote :) as a token of appreciation! ***","939d4c0f":"## This is how we can do a quick basic sentiment analysis. \n## If you like it don't forget to upvote :) "}}