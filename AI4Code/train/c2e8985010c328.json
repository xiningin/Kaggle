{"cell_type":{"2c41db3e":"code","40db66e9":"code","d6e5149e":"code","f45a6bfb":"code","2ce0de4c":"code","6cd8f734":"code","243587b4":"code","c595c609":"code","aff6fd2f":"markdown","46ca7d17":"markdown","f4c4ec03":"markdown","9a2731ca":"markdown","443ffa97":"markdown"},"source":{"2c41db3e":"#Load main libraries\nimport pandas as pd #Work with dataframes\nimport numpy as np #Work with arrays\nimport chardet #Useful to auto-detect encodings","40db66e9":"#Load the file_guide document, where the information of documents available in the dataset is presented. \nfile_guide = pd.read_csv(\"..\/input\/character-encoding-examples\/file_guide.csv\")\nfile_guide\n\n#Here, we can see encodings of the different .txt documents. We can \"ASCII\", \"Windows 1251\", \"UTF-8\" and more. ","d6e5149e":"#Load the first document. We can see the first 200 characters. The method used in this case is \"rb\", which means only-read a binary format. \nwith open(\"..\/input\/character-encoding-examples\/die_ISO-8859-1.txt\", 'rb') as simple_doc:\n    result = simple_doc.read(200)\n    \n#Print our result\nprint(result)    \n\n#Here, we can observe that there are many symbols that are not clear, thereby we can deduce that the encoding of this document is not UTF-8.","f45a6bfb":"with open(\"..\/input\/character-encoding-examples\/die_ISO-8859-1.txt\", 'rb') as simple_doc:\n    result = chardet.detect(simple_doc.read(200))\n\n#Print our result\nprint(result)\n\n#Using the first 1000 characters, it is suggested with a confidence of a 0.73 that the encoding utilised in this file is \"ISO-8859-1\".","2ce0de4c":"#Now, we can open the file using the more appropiate encoding.\nwith open(\"..\/input\/character-encoding-examples\/die_ISO-8859-1.txt\", encoding='ISO-8859-1') as simple_doc:\n    result = simple_doc.read(500)\n\n#Print our result\nprint(result)","6cd8f734":"#Now, we can open the file using the more appropiate encoding.Read the entire document\nwith open(\"..\/input\/character-encoding-examples\/die_ISO-8859-1.txt\", encoding='ISO-8859-1') as simple_doc:\n    result = simple_doc.read()","243587b4":"#To save the file we can use the method \"w\" of write.\nwith open(\".\/first_document_utf8.txt\",\"w+\") as output_doc:\n    output_doc.write(result)","c595c609":"#Now, we can test if the file is correctly read without add any encoding. As we mentioned before, Python uses UTF-8 as default encoding.\nwith open(\".\/first_document_utf8.txt\") as simple_doc_utf8:\n    result = simple_doc_utf8.read(500)\n#Print the result    \nprint(result)\n\n#As you can see, the document is read in the correct way.","aff6fd2f":"We can do this same process to each document located in this dataset.","46ca7d17":"Documents are in .txt format, thereby we can read them using \"open\" function. A short form to apply \"open\" is using \"with\" statement. If you don't know how this statement works, you can see [this link](https:\/\/www.pythonforbeginners.com\/files\/reading-and-writing-files-in-python).","f4c4ec03":"Now, we have identified the right encoding, we can read the entire document with its encoding and save as UTF-8.","9a2731ca":"# Tutorial \n\nIn this notebook we will see the treat of documents with different encodings. This can be a complex problem specially when users work with several documents and text analysis. Python works with UTF-8 encoding due to this one of the most universal encoding nowadays. The basis of this notebook is based on the Course [Character Encodings](https:\/\/www.kaggle.com\/alexisbcook\/character-encodings) of Kaggle.","443ffa97":"To know the correct encoding of this document, we can try different encodings to read it. However, in Python exists the function \"chardet.detect\" to guess the encoding of a file"}}