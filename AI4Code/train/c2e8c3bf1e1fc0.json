{"cell_type":{"fac943f1":"code","f7d24969":"code","b21be8b4":"code","1cb8f2a5":"code","79d97853":"code","79162a4d":"code","341b169e":"code","122fcd7e":"code","e8403adb":"code","4f9d8846":"code","bd7fc45b":"code","13233304":"code","fd56ea79":"code","7624d056":"code","90a30a29":"code","9e2d0a7b":"code","d6ab56df":"code","43ad772b":"code","f21ac3fc":"code","699b9a46":"code","4d8d92ec":"code","0086c65a":"markdown","9af88e1a":"markdown","db23b755":"markdown","c47710b1":"markdown","41a3c0fc":"markdown","59fd3d18":"markdown","48b9b9c2":"markdown","813399ae":"markdown","c3e4b745":"markdown"},"source":{"fac943f1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport numpy as np \nimport pandas as pd\n\n# to get the accuracy score, provided actual class labels and predicted labels\nfrom sklearn.metrics import accuracy_score\n\n# to split the dataset into training and validation set\nfrom sklearn.model_selection import train_test_split\n\n# for reproducibility purposes\nseed = 42\nnp.random.RandomState(seed)\n\nprint(os.listdir(\"..\/input\"))","f7d24969":"# importing the various Kers modules\n\n# We will be using the SGD optimization technique.\n# This method calculate the cost function for each datapoint individually.\n# Unlike th normal GD, in which error is calculated on the entire dataset altogether.\nfrom keras.optimizers import SGD \n\n# This is used to create a linear stack of layers, starting from input layer, \n# followed by hidden layers  and ending with the output layer.\nfrom keras.models import Sequential\n\n# to convert the categorical data into One-hot encoding vector\nfrom keras.utils import to_categorical\n\n# Dense is to create a single layer in a network, consist of input shape, number of nodes in the layer\n# and the activation function to use for the nodes in the layer\n\n# Dropout is to specify the dropout rate after each layer\nfrom keras.layers import Dense, Dropout\n\n# History is used to get the various information about the training of the model, \n# like the training and test accuracies at the each epoch\n\n# EarlyStopping help us to stop the training is the model is not showing significant improvement,\n# in certain number of epochs\nfrom keras.callbacks import EarlyStopping, History","b21be8b4":"# to read the training data i.e. the MNIST image data\ntrain_df = pd.read_csv(\"..\/input\/train.csv\")\ntrain_df.head(5)","1cb8f2a5":"print(\"Shape of the training dataset: \", train_df.shape)","79d97853":"# seperating the labels from the image pixels information\ny = train_df.values[:, 0] # get the values in the first column\nX = train_df.values[:, 1:]\/255.0 # get all the columns but the first. Also, we divided by 255 to normalize the values","79162a4d":"# create dummy variables from the labels using One-hot encoding method, which we imported above\ny_encoded = to_categorical(y)\nprint(\"Shape of the target variable: \", y_encoded.shape)\n\nprint(\"First few records:\")\nprint(y_encoded[:2])","341b169e":"# split the data into train and validation datasets with test size to be 30% of the total\nvalidation_split = .3\n\n# stratify here ensures that the proportion of the labels is maintained in the train & test dataset\n# random_state is specified so that the results can be replicated later on\nX_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=validation_split, stratify=y, random_state=seed)","122fcd7e":"print(\"Size of the training dataset: \", X_train.shape[0])\nprint(\"Size of the testing dataset: \", X_val.shape[0])","e8403adb":"def build_model(input_shape, num_classes, num_layers, num_nodes, activation=\"relu\", optimizer=\"adam\", dropout_rate=0.00):\n    \n    # this will contain all the layers in the network\n    model = Sequential()\n    \n    # add a layer with \"num_nodes\" and input size of \"input_size\"\n    model.add(Dense(num_nodes, activation=activation, input_shape=input_shape))\n    \n    # add the dropout layer\n    model.add(Dropout(rate=dropout_rate))\n    \n    # to add the hidden-layers\n    for i in range(num_layers-1):    \n        model.add(Dense(num_nodes, activation=activation))\n        model.add(Dropout(rate=dropout_rate))\n    \n    # add an output layer of size \"num_classes\" which is equal to the number of labels we've in the data\n    # in case of MNIST it is 10\n    # softmax function here converts the output into the probabilities i.e. in range [0,1]\n    model.add(Dense(num_classes, activation=\"softmax\"))\n    \n    # in our case we will be using SGD optimizer, loss\/cost function will be categorical_crossentropy\n    # the metrics we want our model to calculate at each epoch can also be passed\n    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    \n    return model","4f9d8846":"# if we found that at each consecutive epoch model is not getting any better that is loss is not decreasing then there is no\n# point in letting the model to keep training for the remainder of the epochs.\n# in such cases EarlyStopping, helps us to stop the training if there is no incremental benefit\n# Here, if the difference between the validation losses in two consecutive epochs is less than 1\/1000\n# the model will stop training\nearly_stopping_monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3)","bd7fc45b":"# maximum number epochs\/times to run the model\nmax_num_epochs = 50\n\n# a list of learning rates \nlearning_rate = [0.0001, 0.001]\n\n# a list of % drop rates\ndropouts = [0.05, 0.10]\n\n# number of hidden layers to keep in the NN models\nnum_layers = [10, 12]\n\n# number of nodes to keep in the hidden layer\nnum_nodes = [1000, 1200]","13233304":"# to keep the accuracies of each of the model\nmodel_accuracies = []\n\n# iterate over the configurations and create a model with those configurations\nfor dropout in dropouts:\n    for lr in learning_rate:\n        for num_layer in num_layers:\n            for num_node in num_nodes:\n                \n                # this keeps the history of the loss\/val_loss for each of the epoch\n                history = History()\n\n                print(\"\\n---- Model Configuration ----\")\n                print(\"Dropout rate: \", dropout)\n                print(\"Learning rate: \", lr)\n                print(\"Number of Layers: \", num_layer)\n                print(\"Number of Nodes in hidden layers: \", num_node)\n                \n                # create and train the model for each of the configuration\n                # here, SGD is being used\n                model = build_model(input_shape=(784,), num_classes=10, num_layers=num_layer, num_nodes=num_node,  \n                                    activation='relu', optimizer=SGD(lr=lr), dropout_rate=dropout)\n\n                # both training and validation datasets are provided\n                # we passing the history, early_stopping_monitor in the callbacks parameter\n                # setting verbose as False, will stop the model from printing the training information for each epoch\n                model.fit(X_train, y_train, epochs=max_num_epochs, callbacks=[history, early_stopping_monitor], \n                          validation_data=(X_val, y_val), verbose=False)\n                \n                print(\"Number of epochs: \", len(history.history['loss']))\n                print(\"Train accuracy: \", model.evaluate(X_train, y_train, verbose=0)[1])\n                print(\"Validation accuracy: \", model.evaluate(X_val, y_val, verbose=0)[1])\n\n                # maintain the configurations and the accuracies to pick the best model at a later stage\n                model_accuracies.append([\n                    dropout,\n                    lr,\n                    num_layer,\n                    num_node,\n                    model.evaluate(X_train, y_train, verbose=0)[1],\n                    model.evaluate(X_val, y_val, verbose=0)[1]\n                ])","fd56ea79":"# picking up the best configuration, i.e. the model giving the best performance on the validation dataset\nbest_config = sorted(model_accuracies, key=lambda row: row[5], reverse=True)[0]","7624d056":"print(\"The model giving the best performance has the following configuration: \", best_config)\nprint(\"Number of layers in the network: \", best_config[2])\nprint(\"Number of nodes in the hidden layers: \", best_config[3])\nprint(\"Dropout rate: \", best_config[0])\nprint(\"Learning rate: \", best_config[1])","90a30a29":"# Let's create 15 different models with same configuration\nmodels = [ build_model(input_shape=(784,), num_classes=10, num_layers=best_config[2], num_nodes=best_config[3],  \n           activation='relu', optimizer=SGD(lr=best_config[1]), dropout_rate=best_config[0]) for i in range(15)]","9e2d0a7b":"# train each of these models\n# setting verbose as false - to prevent any information from getting printed\nfor i in range(15):\n    models[i].fit(X_train, y_train, epochs=max_num_epochs, callbacks=[history, early_stopping_monitor], \n                  validation_data=(X_val, y_val), verbose=False)","d6ab56df":"# now, we will get the probabilities from each of the model\n# sum them up and will get the class with the highest total probability \n\nval_probabs = np.zeros((y_val.shape[0], 10), dtype='float32') # create an array containing zeroes\n\nfor i in range(15):\n    # predict and add the probabilities\n    val_probabs += models[i].predict(X_val)\n    \n# get the actual labels of the validation set\nacual_labels = y_val.argmax(axis=-1)\n\n# get the predict labels\npredicted_labels = val_probabs.argmax(axis=-1)\n\n# print the validation accuracy\nprint(\"Validation accuracy from the Ensemble model: \", accuracy_score(acual_labels, predicted_labels))","43ad772b":"# read the test dataset\ntest_df = pd.read_csv(\"..\/input\/test.csv\")\nprint(\"Shape of the test data: \", test_df.shape[0])\ntest_df.head(2)","f21ac3fc":"# get the values as numpy array\nX_test = test_df.values","699b9a46":"# create an array containing zeroes\ntest_probabs = np.zeros((X_test.shape[0], 10), dtype='float32') \n\nfor i in range(15):\n    # predict and add the probabilities\n    test_probabs += models[i].predict(X_test)\n    \n# get the actual labels of the validation set\npredicted_classes = test_probabs.argmax(axis=-1)\n\nprint(\"Size of the predicted classes: \", predicted_classes.shape)","4d8d92ec":"# create output dataframe and file\noutput = pd.DataFrame()\n\noutput[\"ImageId\"] = [i for i in range(1, predicted_classes.shape[0]+1)]\noutput[\"Label\"] = predicted_classes\n\noutput.to_csv(\"predicted_classes.csv\", index=False)","0086c65a":"### Classify the images in the test dataset","9af88e1a":"### A generic model builder function\nThis returns a model with the configurations provided","db23b755":"# Create an Ensemble of networks","c47710b1":"# Load & Prepare data","41a3c0fc":"**Define architecture**\nHere a generic method has been defined which takes following inputs and construct the neural network based on the provided input configurations.\n+ **input_shape:**  the shape of the input data, which in case of MNIST dataset is (784,)\n+ **num_classes:** number of labels\/classes we have in our dataset, which is 10 (0 to 9) for MNIST dataset\n+ **num_layers:** number of the hidden layers we want to create in out architecture\n+ **num_nodes:** number of nodes in each of the hidden layers\n+ **activation:** which activation function to use like 'relu', 'softmax', 'tanh', etc.\n+ **optimizer:** which optimizer methodology to use like SGD - Stochastic Gradient Descent, ADAM, etc.\n+ **dropout_rate:** it is a regularization technique, which randomly drops x% of nodes while training the model","59fd3d18":"### Setting the different configurations to train our model on","48b9b9c2":"# Build the network","813399ae":"### Training the model with different configurations","c3e4b745":"**In this notebook I will be using the MNIST dataset to explore ways to improve the performance of a Deep Neural Network model. The performance of any Neural network, just like the Random forest depends upon the configuration of the hyperparameters. Here, we will tune these hyperparmeters (like the number of hidden layers, number of nodes in the hidden layers, dropout rate, number of epochs, etc.) and will optimze our network. \n\nAlso, in the end we will create an ensemble of the best model and will make the predictions of test data on it.\n\nP.S. please do 'upvote' if you find this notebook helpful.**"}}