{"cell_type":{"36b2a256":"code","ff2cc966":"code","36fb150d":"code","81bbedd4":"code","38bed4b4":"code","8e89873e":"code","36ad938b":"code","8672d9a2":"code","bd03c663":"code","cebcfa57":"code","92f7908e":"code","4ecaec5d":"code","30955c02":"code","33006188":"code","dffa8cad":"code","9a69ef05":"code","911b29d0":"code","5ddef4b4":"code","615a5449":"code","633bd96e":"code","26c6f06a":"code","12d884d3":"code","0686c2a6":"code","745b60d7":"code","76e4608a":"code","b799b10b":"code","111d808d":"code","10ee081a":"code","54922034":"code","cc5cce65":"code","2f210173":"code","52d6e745":"code","2e056e4e":"code","479e6bf9":"code","93f0a096":"code","a4aafb93":"code","d4706bf1":"code","a2069064":"code","c7bc28af":"code","97fa5abb":"code","ce1fc87d":"code","de42c157":"code","3f05e360":"code","0687ccb0":"code","573aad8a":"code","a8447827":"code","32e02619":"code","49d75755":"code","0df13498":"code","928c8b78":"code","2336df76":"code","f0c9d2d9":"code","9c1527cc":"code","71f8b89c":"code","ff58bf9c":"code","42e5292a":"code","4aa7316b":"code","3628ba9b":"code","a9b31dad":"code","2af54cd3":"code","02c3f24a":"code","0636ab74":"code","dfcb9114":"code","3aa1022b":"markdown","c151ff0f":"markdown","4ff598dc":"markdown","87b632e0":"markdown","6b0cb96d":"markdown","6559155a":"markdown","86c7aa47":"markdown","baecde88":"markdown","167699d8":"markdown","30773483":"markdown","9d4fb1bb":"markdown","621beb96":"markdown","667e5e23":"markdown","25112ece":"markdown","da80906c":"markdown","51796ccb":"markdown"},"source":{"36b2a256":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n","ff2cc966":"train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","36fb150d":"#show the top five columns in train data\ntrain.head()","81bbedd4":"#illustrate the information of train and test data\ntrain.info()","38bed4b4":"test.info()","8e89873e":"train.describe()","36ad938b":"train.describe(include='O')","8672d9a2":"test.info()","bd03c663":"train['SalePrice'].describe()","cebcfa57":"sns.distplot(train['SalePrice'])","92f7908e":"corr_tr=train.corr()\ncorr_tr","4ecaec5d":"f, ax = plt.subplots(figsize=(15, 12))\nsns.heatmap(corr_tr)","30955c02":"max_corr=corr_tr[corr_tr['SalePrice']>.5]['SalePrice']\nprint(max_corr)","33006188":"cols = ['SalePrice', 'OverallQual', 'GrLivArea','GarageArea','GarageCars','1stFlrSF', 'TotalBsmtSF', 'FullBath', 'YearBuilt','YearRemodAdd']\nsns.pairplot(train[cols], size = 2.5)\nplt.show();","dffa8cad":"f, ax = plt.subplots(figsize=(8, 6))\n\nplt.scatter(train['GrLivArea'],train['SalePrice'])","9a69ef05":"price=train[train['SalePrice']<300000]\nprice.head()\nGriv=price[price['GrLivArea']>4000]\nGriv.head()\n#we can make it by getting the two biggest values in GrlivArea \n#train.sort_values(by = 'GrLivArea', ascending = False)[:2]","911b29d0":"train_1=train.drop(train[train['Id']==524].index)\ntrain_2=train_1.drop(train_1[train_1['Id']==1299].index)","5ddef4b4":"f, ax = plt.subplots(figsize=(8, 6))\n\nplt.scatter(train_2['1stFlrSF'],train_2['SalePrice'])\n","615a5449":"f, ax = plt.subplots(figsize=(10, 6))\n\nplt.scatter(train_2['TotalBsmtSF'],train_2['SalePrice'])","633bd96e":"train_2.shape","26c6f06a":"test.shape","12d884d3":"#missing function\ndef missing_percentage(df):\n    \"\"\"This function takes a DataFrame(df) as input and returns two columns, total missing values and total missing values percentage\"\"\"\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = round(df.isnull().sum().sort_values(ascending = False)\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','Percent'])\n","0686c2a6":"missing_percentage(train_2)[missing_percentage(train_2)['Total']>=1]","745b60d7":"train_3 = train_2.drop(train_2[missing_percentage(train_2)[missing_percentage(train_2)['Percent']>20].index],1)\n","76e4608a":"missing_percentage(train_3)[missing_percentage(train_3)['Total']>=1]","b799b10b":"null_train=missing_percentage(train_3)[missing_percentage(train_3)['Total']>=1].index\nnull_train","111d808d":"obj=[]\nflo=[]\nfor col in null_train:\n  if(train_3[col].dtypes)==object:\n    obj.append(col)\n  else:\n    flo.append(col)  \nprint(obj)\nprint('=======================================================')\nprint(flo)","10ee081a":"for c in obj:\n  train_3[c]=train_3[c].fillna(str(train_3[c].mode()))\n","54922034":"for x in flo:\n  train_3[x]=train_3[x].fillna(float(train_3[x].mean()))\n\n","cc5cce65":"train_3.isnull().sum().sum()","2f210173":"train_3.shape","52d6e745":"test_1 = test.drop(train_1[missing_percentage(train)[missing_percentage(train_1)['Percent']>20].index],1)\n","2e056e4e":"missing_percentage(test_1)[missing_percentage(test_1)['Total']>=1]","479e6bf9":"null_test=missing_percentage(test_1)[missing_percentage(test_1)['Total']>=1].index\nnull_test","93f0a096":"obj=[]\nflo=[]\nfor col in null_test:\n  if(test_1[col].dtypes)==object:\n    obj.append(col)\n  else:\n    flo.append(col)  \nprint(obj)\nprint('=======================================================')\nprint(flo)","a4aafb93":"for c in obj:\n  test_1[c]=test_1[c].fillna(str(test_1[c].mode()))\n","d4706bf1":"for x in flo:\n  test_1[x]=test_1[x].fillna(float(test_1[x].mean()))\n\n","a2069064":"test_1.isnull().sum().sum()","c7bc28af":"test_1.shape","97fa5abb":"train_4=train_3.drop('Id',axis=1)","ce1fc87d":"train_5=pd.get_dummies(train_4)","de42c157":"train_5.shape","3f05e360":"train_6=train_5.drop('SalePrice',axis=1)","0687ccb0":"test_Id=test_1['Id']\ntest_2=test_1.drop('Id',axis=1)\ntest_3=pd.get_dummies(test_2)","573aad8a":"test_3.shape","a8447827":"train_cols = list(train_6.columns)\ntest_cols = list(test_3.columns)\ncols_not_in_test = {c:0 for c in train_cols if c not in test_cols}\ntest_4 = test_3.assign(**cols_not_in_test)","32e02619":"train_cols = list(train_6.columns)\ntest_cols = list(test_3.columns)\ncols_not_in_train = {c:0 for c in test_cols if c not in train_cols}\ntrain_7 = train_6.assign(**cols_not_in_train)","49d75755":"train_7.shape","0df13498":"test_4.shape","928c8b78":"X=train_7\ny=train_5['SalePrice']","2336df76":"X.shape","f0c9d2d9":"y.shape","9c1527cc":"'''\n# Import Libraries\nfrom sklearn.preprocessing import StandardScaler\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Standard Scaler for Data\n\nscaler = StandardScaler(copy=True, with_mean=True, with_std=True)\nX = scaler.fit_transform(X)\ntest_5=scaler.fit_transform(test_4)\n\n#showing data\nprint('X \\n' , X[:10])\n#print('y \\n' , y[:10])\n'''\nfrom sklearn.preprocessing import MinMaxScaler\n#----------------------------------------------------\n\n#----------------------------------------------------\n#MinMaxScaler for Data\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(copy=True, feature_range=(0, 1))\nX = scaler.fit_transform(X)\ntest_5=scaler.fit_transform(test_4)\n","71f8b89c":"#Import Libraries\nfrom sklearn.model_selection import train_test_split\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Splitting data\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=44, shuffle =True)\n\n#Splitted Data\n#print('X_train shape is ' , X_train.shape)\n#print('X_test shape is ' , X_test.shape)\n#print('y_train shape is ' , y_train.shape)\n#print('y_test shape is ' , y_test.shape)","ff58bf9c":"#Import Libraries\nfrom sklearn.linear_model import Lasso\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Applying Lasso Regression Model \n\n'''\nsklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=\n                           False, copy_X=True, max_iter=1000, tol=0.0001,\n                           warm_start=False, positive=False, random_state=None,selection='cyclic')\n'''\n\nLassoRegressionModel = Lasso(alpha=.1,random_state=33,normalize=True)\nLassoRegressionModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('Lasso Regression Train Score is : ' , LassoRegressionModel.score(X_train, y_train))\nprint('Lasso Regression Test Score is : ' , LassoRegressionModel.score(X_test, y_test))\n#print('Lasso Regression Coef is : ' , LassoRegressionModel.coef_)\n#print('Lasso Regression intercept is : ' , LassoRegressionModel.intercept_)\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = LassoRegressionModel.predict(X_test)\n#print('Predicted Value for Lasso Regression is : ' , y_pred[:10])\n#Import Libraries\nfrom sklearn.metrics import mean_squared_error \n#----------------------------------------------------\n\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)","42e5292a":"#Import Libraries\nfrom sklearn.linear_model import Ridge\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Applying Ridge Regression Model \n\n'''\nsklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, normalize=False,\n                           copy_X=True, max_iter=None, tol=0.001, solver='auto',\n                           random_state=None)\n'''\n\nRidgeRegressionModel = Ridge(alpha=1,random_state=44,normalize=False)\nRidgeRegressionModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('Ridge Regression Train Score is : ' , RidgeRegressionModel.score(X_train, y_train))\nprint('Ridge Regression Test Score is : ' , RidgeRegressionModel.score(X_test, y_test))\n#print('Ridge Regression Coef is : ' , RidgeRegressionModel.coef_)\n#print('Ridge Regression intercept is : ' , RidgeRegressionModel.intercept_)\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = RidgeRegressionModel.predict(X_test)\n#print('Predicted Value for Ridge Regression is : ' , y_pred[:10])\n#Import Libraries\nfrom sklearn.metrics import mean_squared_error \n#----------------------------------------------------\n\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)","4aa7316b":"import xgboost as xg\nxgb_r = xg.XGBRegressor(learning_rate=0.01,n_estimators=3460,\n                                     max_depth=2, min_child_weight=0,\n                                     gamma=0, subsample=0.7,\n                                     colsample_bytree=0.7,\n                                     objective='reg:linear', nthread=-1,\n                                     scale_pos_weight=1, seed=27,\n                                     reg_alpha=0.000001\n                  )\n\nxgb_r.fit(X_train,y_train)\nprint('score',xgb_r.score(X_train,y_train))\nprint('score',xgb_r.score(X_test,y_test))\n\nfrom sklearn.metrics import mean_squared_error \n#----------------------------------------------------\n\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)","3628ba9b":"#Import Libraries\nfrom sklearn.ensemble import GradientBoostingRegressor\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Applying Gradient Boosting Regressor Model \n\n'''\nsklearn.ensemble.GradientBoostingRegressor(loss='ls\u2019, learning_rate=0.1,n_estimators=100, subsample=\n                                           1.0, criterion='friedman_mse\u2019,min_samples_split=2,min_samples_leaf=1,\n                                           min_weight_fraction_leaf=0.0,max_depth=3,min_impurity_decrease=0.0,\n                                           min_impurity_split=None,init=None, random_state=None,max_features=None, alpha=0.9,\n                                           verbose=0, max_leaf_nodes=None,warm_start=False, presort='auto'\n                                           , validation_fraction=0.1,n_iter_no_change=None, tol=0.0001)\n'''\n\nGBRModel = GradientBoostingRegressor(n_estimators=100,max_depth=2,learning_rate = 1.5 ,random_state=33)\nGBRModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('GBRModel Train Score is : ' , GBRModel.score(X_train, y_train))\nprint('GBRModel Test Score is : ' , GBRModel.score(X_test, y_test))\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = GBRModel.predict(X_test)\n#print('Predicted Value for GBRModel is : ' , y_pred[:10])\n#Import Libraries\nfrom sklearn.metrics import mean_squared_error \n#----------------------------------------------------\n\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)","a9b31dad":"#Import Libraries\nfrom sklearn.tree import DecisionTreeRegressor\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Applying DecisionTreeRegressor Model \n\n'''\nsklearn.tree.DecisionTreeRegressor(criterion='mse\u2019, splitter=\u2019best\u2019, max_depth=None,min_samples_split=2,\n                                   min_samples_leaf=1,min_weight_fraction_leaf=0.0, max_features=None,\n                                   random_state=None, max_leaf_nodes=None,min_impurity_decrease=0.0,\n                                   min_impurity_split=None, presort=False)\n'''\n\nDecisionTreeRegressorModel = DecisionTreeRegressor( max_depth=3,random_state=33)\nDecisionTreeRegressorModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('DecisionTreeRegressor Train Score is : ' , DecisionTreeRegressorModel.score(X_train, y_train))\nprint('DecisionTreeRegressor Test Score is : ' , DecisionTreeRegressorModel.score(X_test, y_test))\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = DecisionTreeRegressorModel.predict(X_test)\n#print('Predicted Value for DecisionTreeRegressorModel is : ' , y_pred[:10])\n#Import Libraries\nfrom sklearn.metrics import mean_squared_error \n#----------------------------------------------------\n\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)","2af54cd3":"#Import Libraries\nfrom sklearn.neighbors import KNeighborsRegressor\n#----------------------------------------------------\n\n#----------------------------------------------------\n#Applying KNeighborsRegressor Model \n\n'''\nsklearn.neighbors.KNeighborsRegressor(n_neighbors=5, weights=, algorithm=\u2019auto\u2019, leaf_size=30,\n                                      p=2, metric=\u2019minkowski\u2019, metric_params=None,n_jobs=None)\n'''\n\nKNeighborsRegressorModel = KNeighborsRegressor(n_neighbors = 5, weights='uniform', #also can be : distance, or defined function \n                                               algorithm = 'auto')    #also can be : ball_tree ,  kd_tree  , brute\nKNeighborsRegressorModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('KNeighborsRegressorModel Train Score is : ' , KNeighborsRegressorModel.score(X_train, y_train))\nprint('KNeighborsRegressorModel Test Score is : ' , KNeighborsRegressorModel.score(X_test, y_test))\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = KNeighborsRegressorModel.predict(X_test)\n#print('Predicted Value for KNeighborsRegressorModel is : ' , y_pred[:10])\n#Import Libraries\nfrom sklearn.metrics import mean_squared_error \n#----------------------------------------------------\n\n#----------------------------------------------------\n#Calculating Mean Squared Error\nMSEValue = mean_squared_error(y_test, y_pred, multioutput='uniform_average') # it can be raw_values\nprint('Mean Squared Error Value is : ', MSEValue)","02c3f24a":"my_submission = pd.DataFrame({'Id': test_Id, 'SalePrice':xgb_r.predict(test_5) })","0636ab74":"my_submission.head(30)","dfcb9114":"my_submission.to_csv('submission.csv', index=False)","3aa1022b":"# premodeling","c151ff0f":"We will determine the 'Id' of these values to remove it. I did two methods choose what you want","4ff598dc":"\n#loading data\n\nThe Python Pandas packages helps us work with our datasets.\n\n","87b632e0":"welcome brothers! we will make a simple code to predict the dream house for anyone that contain some features.\n\n First we will import library that help us to analyse and visualize your data","6b0cb96d":"From the above photo I note that there are some values out of range these case misleading in the algorithms so we should remove it from our data","6559155a":"we will show some statistical feature of our numerical train data\n\n","86c7aa47":"if we want to show statistical feature of categorical train data\n\n","baecde88":"We will use seaborn that help us to illustrate the correlation of the important features with each other","167699d8":"# splitting data","30773483":"There are many features have null values and i note these features have not affect in 'SalePrice' feature. so,it is the best will dropped them","9d4fb1bb":"We found two index in 'Id' feature are '524' and '1299'.\n\nI note this '1299' make misleading problem in '1stFlrSF' and 'TotalBsmtSF' features too.so when we remove it the problem solved in the three features","621beb96":"We will show features that have posetive correlation with 'Saleprice' feature more than .5 to make more intersting about them.\n\nNote,we should do like this in negative correlation too, but in this case it is not has affect in 'SalePrice' feature(the biggest negative correlation with 'SalePrice' is less than .2)","667e5e23":"We will consert on the 'SalePrice' feature ","25112ece":"# model","da80906c":"We will show the correlation of train data in a heatmap by using seaborn to see what features has more affect  'SalePrice' feature","51796ccb":"# missing valuse"}}