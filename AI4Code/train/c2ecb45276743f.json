{"cell_type":{"057329d0":"code","dc3859d5":"code","59ce3605":"code","c38c4ba2":"code","a1fc45fd":"code","aa3f8633":"code","35d7ea17":"code","88253aaf":"code","49efb9a5":"markdown","bfac6907":"markdown","6846b4d6":"markdown"},"source":{"057329d0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn import metrics","dc3859d5":"tweet_df = pd.read_csv('..\/input\/disaster-tweets\/tweets.csv')\ntweet_df.head()\n","59ce3605":"import re\nimport string\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\ntweet_df['text']=tweet_df['text'].apply(lambda x : clean_text(x))\n","c38c4ba2":"from sklearn.feature_extraction import text \n\nmy_additional_stop_words = ['just', 'like', 'amp', 'im']\nstop_words = text.ENGLISH_STOP_WORDS.union(my_additional_stop_words)","a1fc45fd":"y = tweet_df['target']\nX_train, X_test, y_train, y_test = train_test_split(tweet_df['text'], y, random_state=53, test_size=.33)\n\ntfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n\n# Create tfidf train and test variables\ntfidf_train = tfidf_vectorizer.fit_transform(X_train)\ntfidf_test =  tfidf_vectorizer.transform(X_test)","aa3f8633":"# Create MulitnomialNB model\ntfidf_nb = MultinomialNB()\ntfidf_nb.fit(tfidf_train, y_train)\n\n# Get predictions\ntfidf_nb_pred = tfidf_nb.predict(tfidf_test)\n\n# Calculate the accuracy \ntfidf_nb_score = metrics.accuracy_score(y_test, tfidf_nb_pred)\n\nprint('NaiveBayes Tfidf Score: ', tfidf_nb_score)","35d7ea17":"# Create a LinearSVM model\ntfidf_svc = LinearSVC()\ntfidf_svc.fit(tfidf_train, y_train)\n\n\n# Get predictions\ntfidf_svc_pred = tfidf_svc.predict(tfidf_test)\n\n# Calculate accuracy\ntfidf_svc_score = metrics.accuracy_score(y_test, tfidf_svc_pred)\n\nprint(\"LinearSVC Score:   %0.3f\" % tfidf_svc_score)","88253aaf":"terms = tfidf_vectorizer.get_feature_names()\n\n# sum tfidf frequency of each term through documents\nsums = tfidf_train.sum(axis=0)\n\n# connecting term to its sums frequency\ndata = []\nfor col, term in enumerate(terms):\n    data.append( (term, sums[0,col] ))\n\nranking = pd.DataFrame(data, columns=['term','rank'])\nprint(ranking.sort_values('rank', ascending=False))","49efb9a5":"This notebook attempts to build a machine learning model that predicts which Tweets are about real disasters and which one\u2019s aren\u2019t. We have access to a dataset of 10,000 tweets that were hand classified.\n\nThe issue here is that sometimes words like \u201cABLAZE\u201d \n1. can be used metaphorically - e.g. 'Lord Jesus, your love brings freedom and pardon. Fill me with your Holy Spirit and set my heart ablaze'\n2. or used literally - e.g. 'Arsonist sets cars ablaze at dealership'\n\nAnd we attempt to differentiate them with NLP principles\n\nIn the dataset, it has a `text` column with the tweet content, and a `target` column that has two values, 1 to indicate it is a real disaster tweet, and 0 to indicate otherwise.","bfac6907":"In this project we will focus just on the 'text' and 'target' column. Because a disaster can happen anywhere, so the 'location' should not matter. Also as we have described in the introduction, a word can be used metaphorically or literally, so the 'keyword' should not matter either.\n\nAdding extra stop words\nFrom checking tweets that included the initally top ranked term, such as 'just', 'like' and 'amp', I realised that usage of 'just' and 'like'were pretty similar to other stop words, and 'amp' is just how this dataset substitue the `&` sign.\n```word = 'amp'\nfor index, row in tweet_df.iterrows():\n    if word in row['text']:\n        print(row['text'])\n```\n\naddition of these few stop words increased accuracy score by 0.001","6846b4d6":"We shall cleanup the text. Without textcleaning, accuracy score was just 80%."}}