{"cell_type":{"777e3b7c":"code","1f200dfb":"code","36be494d":"code","9d68a3ee":"code","f00b3fdc":"code","dd6e253c":"code","3125b91f":"code","dd3d210e":"code","c3438707":"code","dd832127":"code","4fb7e3dd":"code","8a9fecdd":"code","862e2c3c":"code","bd282432":"code","4f05bbbc":"code","776a8bcd":"code","22213fa5":"code","8bea047a":"code","a1087608":"code","d21e7eaf":"code","0a572e0d":"code","0f3bcbe3":"code","e32c64fd":"code","baf3c1f4":"code","363e271f":"code","0460fc38":"code","52b85f1b":"code","7b50521b":"code","737f6f64":"code","c0765cbd":"code","6b370563":"code","999dd260":"code","ab2c7631":"code","2c20d51e":"code","0f8f4403":"code","0b5949d9":"code","51cf0849":"code","60305861":"code","da6a1ef4":"markdown","32f071f2":"markdown","623fee20":"markdown","6c3a4947":"markdown","f1b5224e":"markdown","e973c466":"markdown","152e7e66":"markdown","3c35918a":"markdown","48150e96":"markdown"},"source":{"777e3b7c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1f200dfb":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","36be494d":"df=pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-3\/train.csv\")","9d68a3ee":"df.head()","f00b3fdc":"df.info()","dd6e253c":"print(df[df[\"Province_State\"]==\"New York\"])","3125b91f":"df[\"days\"]=[x for x in range(1,307) for x in range(1,75)]","dd3d210e":"df.info()","c3438707":"df=df[df[\"Province_State\"]==\"New York\"]","dd832127":"df.info()","4fb7e3dd":"df.head()\nx=df.iloc[:,1]\ntime=df.iloc[:,6]\ny=df.iloc[:,4]\ntime=time.to_numpy(dtype=\"float32\")\nseries=y.to_numpy(dtype=\"float32\")\ntime.shape","8a9fecdd":"plt.figure(figsize=(10, 6))\n\nplt.plot(time, series)\nplt.title(\"Confirmed Cases in New York\")\nplt.ylabel(\"Confirmed Cases\")\nplt.xlabel(\"Days\")","862e2c3c":"time=np.array(time)\nseries=np.array(series)\nsplit_time = 71\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]","bd282432":"window_size = 2\nbatch_size = 3\nshuffle_buffer_size = 71","4f05bbbc":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n  dataset = tf.data.Dataset.from_tensor_slices(series)\n  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n  dataset = dataset.batch(batch_size).prefetch(1)\n  \n  return dataset","776a8bcd":"dataset = windowed_dataset(x_train, window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)","22213fa5":"print(x_train)","8bea047a":"l0 = tf.keras.layers.Dense(1, input_shape=[window_size])\nmodel = tf.keras.models.Sequential([l0])\n\nmodel.compile(loss=tf.keras.losses.Huber(), optimizer=\"adam\")\nmodel.fit(dataset,epochs=100)","a1087608":"forecast=[]\nfor time in range(len(series) - window_size):\n  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n  \n\nforecast = forecast[split_time-window_size:]\nprint(forecast)\nresults = np.array(forecast)[:, 0, 0]\nprint(forecast)\n\nplt.figure(figsize=(10, 6))\n\nline1=plt.plot( time_valid, x_valid,label=\"Real\")\nline2=plt.plot(time_valid, results,label=\"Forecasted\")\nplt.title(\"New York Single Neuron Forecasting\")\nplt.ylabel(\"Confirmed Cases\")\nplt.xlabel(\"Days\")\nplt.legend()","d21e7eaf":"tf.keras.backend.clear_session()\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(150, input_shape=[window_size], activation=\"relu\"), \n    tf.keras.layers.Dense(10, activation=\"relu\"), \n    tf.keras.layers.Dense(1)\n])\n\nmodel.compile(loss=tf.keras.losses.Huber(), optimizer=\"adam\")\nmodel.fit(dataset,epochs=100)","0a572e0d":"forecast=[]\nfor time in range(len(series) - window_size):\n  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n  \n\nforecast = forecast[split_time-window_size:]\nresults = np.array(forecast)[:, 0, 0]\nprint(forecast)\n\nplt.figure(figsize=(10, 6))\nplt.title(\"New York SNN Forecasting\")\nplt.ylabel(\"Confirmed Cases\")\nplt.xlabel(\"Days\")\n\nplt.plot( time_valid, x_valid,label=\"Real\")\nplt.plot(time_valid, results,label=\"Forecasted\")\nplt.legend()","0f3bcbe3":"tf.keras.backend.clear_session()\ndataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n                      input_shape=[None]),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True,activation=\"relu\")),\n  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50,activation=\"relu\")),\n  tf.keras.layers.Dense(1),\n  tf.keras.layers.Lambda(lambda x: x * 100.0)\n])\n\n\nmodel.compile(loss=tf.keras.losses.Huber(), optimizer=\"adam\",metrics=[\"mae\"])\nhistory = model.fit(dataset,epochs=1000)","e32c64fd":"forecast=[]\nfor time in range(len(series) - window_size):\n  forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n\nforecast = forecast[split_time-window_size:]\nresults = np.array(forecast)[:, 0, 0]\nprint(forecast)\n\nplt.figure(figsize=(10, 6))\n\nplt.plot( time_valid, x_valid,label=\"Real\")\nplt.plot(time_valid, results,label=\"Forecasted\")\nplt.title(\"Bidirectionl LSTM Forecasting\")\nplt.ylabel(\"Confirmed Cases\")\nplt.xlabel(\"Days\")","baf3c1f4":"df1=pd.read_csv(\"\/kaggle\/input\/covid19-global-forecasting-week-3\/test.csv\")","363e271f":"df1.info()","0460fc38":"df1=df1[df1[\"Province_State\"]==\"New York\"]","52b85f1b":"df1.info()","7b50521b":"df2=pd.DataFrame()","737f6f64":"df2[\"days_test\"]=[x for x in range(1,85)]","c0765cbd":"#df3=df.reset_index()\n#df2=df2.reset_index()\ndf4 = [df3, df2]\ndf_test = pd.concat(df4, axis=1)","6b370563":"df_test.info()","999dd260":"df_test.tail(20)","ab2c7631":"x=df_test.iloc[:,2]\ntime=df_test.iloc[:,8]\ny=df_test.iloc[:,5]\ntime=time.to_numpy(dtype=\"float32\")\nseries=y.to_numpy(dtype=\"float32\")","2c20d51e":"time=np.array(time)\nseries=np.array(series)\nsplit_time = 72\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]","0f8f4403":"window_size = 2\nbatch_size = 3\nshuffle_buffer_size = 74","0b5949d9":"print(series)","51cf0849":"forecast=[]\nfor time in range(len(series) - window_size):\n    print(time)\n    z=model.predict(series[time:time + window_size][np.newaxis])\n    print(z)\n    if time >= 72:\n        series[time+window_size]=z\n        print(series)\n    forecast.append(model.predict(series[time:time + window_size][np.newaxis]))\n \n  \n\n\nforecast = forecast[split_time-window_size:]\nresults = np.array(forecast)[:, 0, 0]\n\n\nplt.figure(figsize=(20, 10))\n\nplt.plot( time_valid, x_valid,label=\"Real\")\nplt.plot(time_valid, results,label=\"Forecasted\")\nplt.title(\"Bidirectionl LSTM Forecasting\")\nplt.ylabel(\"Confirmed Cases\")\nplt.xlabel(\"Days\")","60305861":"print(forecast)","da6a1ef4":"**Bidirectional LSTM seems to give most accurate results on validation set. This neural network will be trained with full train set and then will be used to forecast on test set.**","32f071f2":"**First Method is single neuron regression**","623fee20":"**Open training file**","6c3a4947":"**Bidirectional LSTM forecasting**","f1b5224e":"**Filter New York, for forecasting New York**","e973c466":"**Split the training Set into training and Validation. Training set is until 70 days last 4 days will be predicted. The last 4 days will serve to select which method is the best for forecasting.**","152e7e66":"**Add new column for time named as days**","3c35918a":"**Simple Neural Network forecasting**","48150e96":"**Import Libraries**"}}