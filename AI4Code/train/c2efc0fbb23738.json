{"cell_type":{"ef54de8e":"code","0d76db4a":"code","9a385ad6":"code","4c61f88d":"code","a68f449a":"code","87288dc4":"code","236d601a":"code","d023ddb2":"code","c1560507":"code","6cb2392d":"code","33632288":"code","466f14cb":"code","c2260aca":"code","05696e02":"code","970b40b3":"code","89191fb8":"code","f4222ac6":"code","bd0de139":"markdown","53c48f3f":"markdown"},"source":{"ef54de8e":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nimport codecs\nfrom pandas.io.json import json_normalize","0d76db4a":"files=[]\nfor dirname, _, filenames in os.walk('..\/input\/rsna-miccai-brain-annotation\/rsna_biccai_brain_0916'):\n    for filename in filenames:\n        files+=[os.path.join(dirname, filename)]","9a385ad6":"imgpath=[]\nfor item in files:\n    if item[-4:]=='.png':\n          imgpath+=[item]\nprint(imgpath[0:5])\nprint(len(imgpath))","4c61f88d":"jsonpath=[]\nfor item in files:\n    if item[-4:]=='json':\n          jsonpath+=[item]\nprint(jsonpath[0:5])\nprint(len(jsonpath))","a68f449a":"box=[]\nwith open('\/kaggle\/input\/rsna-miccai-brain-annotation\/rsna_biccai_brain_0916\/0000\/Image-88.json') as f:\n    d = json.load(f)\n    print(d)","87288dc4":"jsonpath[0]","236d601a":"BOX=[]\nfor path in jsonpath:\n    with open(path) as f:\n        idn=path.split('\/')[-2]\n        d = json.load(f)\n        labels=d['shapes']\n        height=d['imageHeight']\n        width=d['imageWidth']\n        file=path[0:-5].split('\/')[-1]\n        for item in labels:\n            BOX+=[[idn,file,item['label'],item['points'][0][0],item['points'][0][1],item['points'][1][0],item['points'][1][1],height,width]]\nprint(BOX[0:5])    ","d023ddb2":"data0=pd.DataFrame(BOX)\ndata0.columns=['idn','file','name','ymin','xmin','ymax','xmax','height','width']\ndata0[0:5]","c1560507":"data0['label']=data0['name'].map({'non_tumor':0,'tumor':1})\ndata0['Ycent']=(data0['ymin']+data0['ymax'])\/(2*data0['height'])\ndata0['Xcent']=(data0['xmin']+data0['xmax'])\/(2*data0['width'])\ndata0['boxH']=(data0['ymax']-data0['ymin'])\/data0['height']\ndata0['boxW']=(data0['xmax']-data0['xmin'])\/data0['width']\ndata0[0:5]","6cb2392d":"data0.to_csv('brain_tumor_annotation.csv',index=False)","33632288":"data0[data0['file']=='Image-88'][data0['idn']=='0000']","466f14cb":"items=data0[data0['file']=='Image-88'][data0['idn']=='0000'].iloc[:,0:6].reset_index(drop=True)\nprint(len(items))\nprint(items.loc[0])","c2260aca":"imgpath[322]","05696e02":"for i,item in enumerate(imgpath):\n    if item[0:-4].split('\/')[-1]=='Image-88' and item[0:-4].split('\/')[-2]=='0000':\n          print(i)","970b40b3":"def draw_bbox2(path):\n\n    items=data0[data0['file']==path[0:-4].split('\/')[-1]][data0['idn']==path[0:-4].split('\/')[-2]].iloc[:,0:13].reset_index(drop=True)\n    image=cv2.imread(path)\n    idn=path[0:-4].split('\/')[-2]\n    file=path[0:-4].split('\/')[-1]    \n    print(idn,file)\n    if len(items)>0:\n        for i in range(len(items)):\n            label=items.loc[i,'label'].astype(int)\n            xmin=items.loc[i,'xmin'].astype(int)\n            ymin=items.loc[i,'ymin'].astype(int)\n            xmax=items.loc[i,'xmax'].astype(int)\n            ymax=items.loc[i,'ymax'].astype(int)\n            H=items.loc[i,'height'].astype(int)\n            W=items.loc[i,'width'].astype(int)            \n            print(label,ymin,xmin,ymax,xmax)\n            if label==0:\n                cv2.rectangle(image,(ymin,xmin),(ymax,xmax),(0,255,0),2)\n            elif label==1:\n                cv2.rectangle(image,(ymin,xmin),(ymax,xmax),(0,0,255),2)         \n            \n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    plt.show()       ","89191fb8":"draw_bbox2(imgpath[322])","f4222ac6":"for item in imgpath[0:6]:\n    draw_bbox2(item)","bd0de139":"## YOLO approach for RSNA Brain Tumor\n* The YOLO system includes a function to train a classifier to identify the object.\n * https:\/\/github.com\/ultralytics\/yolov5\n* To do it, need to manually create annotation data to train the classifier. \n* Annotation work is conducted manually using png-converted dataset and an annotation tool, LabelMe.\n * https:\/\/www.kaggle.com\/jonathanbesomi\/rsna-miccai-png\n * https:\/\/github.com\/wkentaro\/labelme\n* This notebook shows the process of converting json annotation data to DataFrame.\n* If YOLO is used in this competition, it is required that the trained classifier never produce false positive judgement, because there are dozens of images per patient.","53c48f3f":"## cv2.rectangle(image,(ymin,xmin),(ymax,xmax),(0,255,0),2)\n* https:\/\/www.geeksforgeeks.org\/python-opencv-cv2-rectangle-method\/"}}