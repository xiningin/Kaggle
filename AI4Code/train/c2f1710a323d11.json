{"cell_type":{"2ae78542":"code","9a55f6f0":"code","82bc772e":"code","ec7aee5d":"code","f227a5f6":"code","0a4098c2":"code","fef6e45b":"code","7d6335fa":"code","0aeab58e":"code","3c3a7024":"code","eda99f97":"code","a8900e67":"code","3180cf10":"code","d982c547":"code","ac634f2f":"code","c5db5c9d":"code","43d2ac2a":"code","0eea58d8":"code","875a30f1":"code","5c870bb3":"code","bb56b8b2":"code","96c67f69":"code","2563d233":"code","856ed79e":"code","bdf0fca4":"code","52169a5b":"code","21c12a86":"code","0ed5b448":"code","9ebdf05a":"code","477e4583":"code","97b735d6":"code","3b4d8bf9":"code","840ddebc":"markdown","e72daf03":"markdown","4dd8fbe7":"markdown","af35996e":"markdown","4146df9c":"markdown","22c3221d":"markdown","032162cc":"markdown","68513502":"markdown","ec549778":"markdown","06b3914a":"markdown","81934bc0":"markdown"},"source":{"2ae78542":"!pip install -q quick-ml","9a55f6f0":"import tensorflow as tf\nimport quick_ml","82bc772e":"from quick_ml.begin_tpu import define_tpu_strategy\n","ec7aee5d":"strategy, tpu = define_tpu_strategy()\n","f227a5f6":"strategy.num_replicas_in_sync","0a4098c2":"from quick_ml.load_models_quick import create_model\n","fef6e45b":"from quick_ml.begin_tpu import get_training_dataset\nfrom quick_ml.begin_tpu import get_validation_dataset\n\nEPOCHS = 5 # Small number of epochs to quickly finish off training. You can set number of epochs as per your requirement.\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nSTEPS_PER_EPOCH = 7155 \/\/ BATCH_SIZE\nprint(f\"Steps per epoch -> {STEPS_PER_EPOCH}\")\n\nfrom kaggle_datasets import KaggleDatasets\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('dog-breed-classification')\n\nprint(f'GCS_DS_PATH -> {GCS_DS_PATH}')","7d6335fa":"dictionary_labeled = \"{ 'image' : tf.io.FixedLenFeature([], tf.string), 'label' : tf.io.FixedLenFeature([], tf.int64) }\"\nIMAGE_SIZE = \"192,192\"\n\nfrom quick_ml.begin_tpu import get_labeled_tfrecord_format\n\nget_labeled_tfrecord_format(dictionary_labeled, IMAGE_SIZE)","0aeab58e":"train_tfrec_path = '\/train.tfrecords'   # Be careful with this\nval_tfrec_path = '\/val.tfrecords'       # as well as this, full file path doesn't work.\n\ntraindata = get_training_dataset(GCS_DS_PATH, train_tfrec_path , 128)\nval_data = get_validation_dataset(GCS_DS_PATH, val_tfrec_path , 128)","3c3a7024":"VAL_STEPS = 3067\/\/BATCH_SIZE\nVAL_STEPS","eda99f97":"class_model = tf.keras.Sequential([tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation = 'relu'),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(120, activation = 'softmax')])","a8900e67":"from quick_ml.load_models_quick import create_model\n\nwith strategy.scope():\n    model = create_model(120, model_name = 'InceptionV3', classification_model = class_model, freeze = True, input_shape = [192, 192,3], activation  = 'softmax', weights= \"imagenet\", optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'sparse_categorical_accuracy')\n","3180cf10":"model.summary()","d982c547":"history = model.fit( traindata, \n    steps_per_epoch = STEPS_PER_EPOCH, \n    epochs = EPOCHS,\n          batch_size = BATCH_SIZE,\n    validation_data = val_data,\n        validation_steps = VAL_STEPS\n)","ac634f2f":"history = model.fit( traindata, \n    steps_per_epoch = STEPS_PER_EPOCH, \n    epochs = EPOCHS,\n          batch_size = BATCH_SIZE,\n    validation_data = val_data,\n        validation_steps = VAL_STEPS\n)","c5db5c9d":"history = model.fit( traindata, \n    steps_per_epoch = STEPS_PER_EPOCH, \n    epochs = 6,\n          batch_size = BATCH_SIZE,\n    validation_data = val_data\n)","43d2ac2a":"from quick_ml.augments import augment_and_train\n\nfrom quick_ml.augments import define_augmentations\n","0eea58d8":"define_augmentations(flip_left_right = True, hue = None , contrast = None, brightness = 0.3, random_crop = None, random_saturation = None,random_zoom = None, flip_up_down = False, random_rotation = None, random_shear = None, random_shift = None)","875a30f1":"from quick_ml.augments import define_callbacks\n\ndefine_callbacks(lr_scheduler = None)","5c870bb3":"augment_and_train(model, GCS_DS_PATH, train_tfrec_path, val_tfrec_path, BATCH_SIZE, 10, STEPS_PER_EPOCH, plot = False)","bb56b8b2":"from quick_ml.augments import define_callbacks\n\ndefine_callbacks(lr_scheduler = None)","96c67f69":"augment_and_train(model, GCS_DS_PATH, train_tfrec_path, val_tfrec_path, BATCH_SIZE, 4, STEPS_PER_EPOCH, plot = False)","2563d233":"augment_and_train(model, GCS_DS_PATH, train_tfrec_path, val_tfrec_path, BATCH_SIZE, 4, STEPS_PER_EPOCH, plot = False)","856ed79e":"augment_and_train(model, GCS_DS_PATH, train_tfrec_path, val_tfrec_path, BATCH_SIZE, 4, STEPS_PER_EPOCH, plot = False)","bdf0fca4":"from quick_ml.augments import define_callbacks\n\ndefine_callbacks(lr_scheduler = 'rampup')","52169a5b":"augment_and_train(model, GCS_DS_PATH, train_tfrec_path, val_tfrec_path, BATCH_SIZE, EPOCHS, STEPS_PER_EPOCH, plot = False)","21c12a86":"from quick_ml.training_predictions import get_models_training_report","0ed5b448":"models =['MobileNet', 'MobileNetV2',\n    'InceptionV3', 'InceptionResNetV2', \n    'EfficientNetB0', 'EfficientNetB1', 'EfficientNetB2']","9ebdf05a":"print(f'Total number of models -> {len(models)}')\n","477e4583":"n_class = 120","97b735d6":"df = get_models_training_report(models,tpu, n_class, traindata, STEPS_PER_EPOCH, EPOCHS, BATCH_SIZE, \n                                val_data,  classification_model = 'default', freeze = False, \n                                input_shape = [192,192,3], activation = 'softmax', weights = \"imagenet\", \n                                optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", \n                                metrics = \"sparse_categorical_accuracy\", plot = False)\n","3b4d8bf9":"df","840ddebc":"experiment by changing the default classification model & setting optimizer as Adam(0.004)","e72daf03":"We will use data augmentation to perform training","4dd8fbe7":"More detailed notebook will be made in the near future. :)","af35996e":"Let's train the model for few more epochs","4146df9c":"experiment with freeze as True","22c3221d":"# Summary","032162cc":"### Training with Callbacks","68513502":"w\/o augments","ec549778":"### For Dog Breed Identification Dataset -> \n\n        without Data Augmentation of quick_ml => \n                quick_ml vs Keras -> quick_ml (10% val score) == Keras (10% val score) for the same NN architecture & parameters\n        \n        with Data Augmentation (minimal) of quick_ml => \n                quick_ml vs Keras -> quick_ml (67% val score) >> Keras (10% val score) for the same NN architecture & parameters","06b3914a":"with minimal augmentations, we have achieved this. Experiment with more augmentations.","81934bc0":"This is without data augmentation"}}