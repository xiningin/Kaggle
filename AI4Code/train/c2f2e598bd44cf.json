{"cell_type":{"66380e3d":"code","8d077d28":"code","6e144aa7":"code","31d5c023":"code","2c850600":"code","f65ae580":"code","420a50dc":"code","77256358":"code","3753958d":"code","3d8cc2f3":"code","5780067e":"code","d72d4098":"code","484d2f29":"code","1cc7bac3":"code","25615619":"code","6c98bd2f":"code","63b431f5":"code","aca6fb1f":"markdown","5b20dabe":"markdown","b2c51a3a":"markdown"},"source":{"66380e3d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8d077d28":"from keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPool2D\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport math\nimport random","6e144aa7":"from tensorflow.keras.datasets.cifar10 import load_data","31d5c023":"dataset_size = 10000\n(inps, labs), (tinps, tlabs) = load_data()\ninps = inps[:dataset_size]\nlabs = labs[:dataset_size]","2c850600":"labs = to_categorical(labs, num_classes=10)\ntlabs = to_categorical(tlabs, num_classes=10)","f65ae580":"# Save originals\norg_inps = inps\norg_tinps = tinps\n\ninps = inps.astype('float32')\nlabs = labs.astype('float32')\n\ntinps = tinps.astype('float32')\ntlabs = tlabs.astype('float32')","420a50dc":"print( np.shape(inps), np.shape(labs) )","77256358":"model = Sequential()\nmodel.add( BatchNormalization() )\nmodel.add( Conv2D(filters=64, kernel_size=(4,4), activation='relu', padding='same') )\nmodel.add( MaxPool2D() )\nmodel.add( Dropout(0.2) )\n\nmodel.add( BatchNormalization() )\nmodel.add( Conv2D(filters=128, kernel_size=(4,4), activation='relu', padding='same') )\nmodel.add( MaxPool2D() )\nmodel.add( Dropout(0.2) )\n\nmodel.add( BatchNormalization() )\nmodel.add( Conv2D(filters=256, kernel_size=(4,4), activation='relu', padding='same') )\nmodel.add( MaxPool2D() )\nmodel.add( Dropout(0.2) )\n\nmodel.add( Flatten() )\nmodel.add( Dense(units=10, activation='softmax') )","3753958d":"from keras.optimizers import Adam\n\nopt = Adam( lr=0.001 )\nmodel.compile( optimizer = opt,\n             loss = 'categorical_crossentropy',\n             metrics = ['accuracy'])","3d8cc2f3":"history = model.fit( inps, labs, batch_size=100, epochs=20, validation_split=0.1 )","5780067e":"results = model.evaluate( tinps, tlabs )\nprint( 'Test Loss is : {} and Test Accuracy is: {}'.format(results[0],results[1]))","d72d4098":"# SELECT A RANDOM PICTURE AND PREDICT\n\nrandom_index =  int(random.random()*1000)\nplt.imshow( org_tinps[random_index])\nprint( \"Prediction\",np.argmax(model.predict( org_tinps[[random_index]]) )) \nprint( \"Real Value\",np.argmax(tlabs[random_index]) ) ","484d2f29":"Y_pred = model.predict(org_tinps)\ny_preds = np.argmax(Y_pred, axis=1)\ntest_labels = np.argmax(tlabs, axis=1)","1cc7bac3":"from sklearn.metrics import confusion_matrix\nimport itertools \n\ncm = confusion_matrix(y_true=test_labels, y_pred=y_preds)","25615619":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        pass\n        #print('Confusion matrix, without normalization')\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","6c98bd2f":"cm_plot_labels = ['0','1','2','3','4','5','6','7','8','9']","63b431f5":"plot_confusion_matrix(cm, cm_plot_labels)","aca6fb1f":"## One-Hot Encoding of Labels","5b20dabe":"## Model Part","b2c51a3a":"## CONFUSION MATRIX"}}