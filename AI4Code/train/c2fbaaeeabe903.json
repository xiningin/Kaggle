{"cell_type":{"d7a21906":"code","f31c1135":"code","30798664":"code","82e06730":"code","1f27e193":"code","2bd4de8c":"code","793c1598":"code","57a44c5f":"code","76691101":"code","c9de3e1b":"code","b8551d6e":"code","2c16103f":"code","99a9d880":"markdown","998f5917":"markdown","3b30c6c4":"markdown","b3d4a56b":"markdown","b577b4eb":"markdown","720cb7ef":"markdown","c10ff494":"markdown","7c47c4e8":"markdown"},"source":{"d7a21906":"from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https:\/\/cdn-images-1.medium.com\/max\/1600\/0*rBQI7uBhBKE8KT-X.png\")","f31c1135":"import numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(42)\nX = np.random.rand(100,1)\ny = 2 + X+np.random.randn(100,1)\/7.5\ny_no_noise = 2 + X","30798664":"plt.plot(X, y, 'ro')\nplt.plot(X, y_no_noise, 'go')\nplt.show()","82e06730":"def calculateGradientVector(X, y, theta):\n    X_b = np.c_[np.ones((len(X),1)), X] # concatenate a 1 to each instance (because we dont have x_0 in X)\n    return (2\/len(X))*X_b.T.dot(X_b.dot(theta)-y)\n\ndef batchGradientDescent(X, y, eta, iterations):\n    np.random.seed(42)\n    theta = np.random.randn(2,1)\n    for i in range(iterations):\n        gradientVector = calculateGradientVector(X, y, theta)\n        theta = theta - eta * gradientVector\n    return theta\n\nbatchGradientDescent(X,y,0.1,1000)","1f27e193":"def predictY(x, theta): # predicts a single y value\n    return theta[0]+theta[1]*x\n\ndef getLearningRatePlot(X, y, eta, iterations):\n    plt.plot(X, y, 'ro')\n    for i in range(iterations):\n        theta = batchGradientDescent(X, y, eta, i)\n        if i is 0:\n            plt.plot([0, 1],[predictY(0, theta), predictY(1, theta)], 'r--')\n        elif i is iterations-1:\n            plt.plot([0, 1],[predictY(0, theta), predictY(1, theta)], 'g-' , linewidth=3)\n        else:\n            plt.plot([0, 1],[predictY(0, theta), predictY(1, theta)], 'b-')\n    plt.xlabel('$X_1$', fontsize=20)\n    plt.title(\"$\\eta = {}$ for ${}$ iterations\".format(eta, iterations), fontsize=20)\n    plt.axis([0, 1, 0, 4])","2bd4de8c":"plt.figure(figsize=(20,4))\nplt.subplot(131); getLearningRatePlot(X, y, 0.02, 10)\nplt.ylabel(\"$y$\", rotation=0, fontsize=18)\nplt.subplot(132); getLearningRatePlot(X, y, 0.1, 10)\nplt.subplot(133); getLearningRatePlot(X, y, 0.8, 10)","793c1598":"plt.figure(figsize=(20,4))\nplt.subplot(131); getLearningRatePlot(X, y, 0.02, 100)\nplt.ylabel(\"$y$\", rotation=0, fontsize=18)\nplt.subplot(132); getLearningRatePlot(X, y, 0.1, 100)\nplt.subplot(133); getLearningRatePlot(X, y, 0.8, 100)","57a44c5f":"def learningSchedule(t, t0=5, t1=50):\n    #t0 and t1 define your starting eta (5\/50 = 0.1) and the growth rate (1\/11 = 0.090 but 5\/51 = 0.098)\n    return t0 \/ (t+t1)\n\ndef stochasticGradientDescent(X, y, epochs, t0=5, t1=50):\n    np.random.seed(42)\n    theta = np.random.randn(2,1)\n    for epoch in range(epochs):\n        for i in range(len(X)):\n            random_iteration = np.random.randint(len(X))\n            x_i = X[random_iteration:random_iteration+1]\n            y_i = y[random_iteration:random_iteration+1]\n            gradientVector = calculateGradientVector(x_i, y_i, theta)\n            eta = learningSchedule(epoch*len(X)+i, t0, t1)\n            theta = theta - eta*gradientVector\n    return theta\n\nstochasticGradientDescent(X, y, 1000)","76691101":"def plotStochastic(X,y,iterations, t0=5, t1=50): \n    plt.plot(X, y, 'ro')\n    for i in range(iterations):\n        theta = stochasticGradientDescent(X, y, i, t0, t1)\n        if i is 0:\n            plt.plot([0, 1],[predictY(0, theta), predictY(1, theta)], 'r--')\n        elif i is iterations-1:\n            plt.plot([0, 1],[predictY(0, theta), predictY(1, theta)], 'g-' , linewidth=3)\n        else:\n            plt.plot([0, 1],[predictY(0, theta), predictY(1, theta)], 'b-')\n    plt.xlabel('$X_1$', fontsize=20)\n    plt.title(\"SGD for ${}$ iterations with schedule {}\/{}\".format(iterations,t0,t1), fontsize=15)\n    plt.axis([0, 1, 0, 4])","c9de3e1b":"plt.figure(figsize=(20,4))\nplt.subplot(131); plotStochastic(X, y, 10)\nplt.ylabel(\"$y$\", rotation=0, fontsize=18)\nplt.subplot(132); plotStochastic(X, y, 10, 1, 100)\nplt.subplot(133); plotStochastic(X, y, 10, 1, 200)","b8551d6e":"def miniBatchGradientDescent(X, y, epochs, batchSize, t0=5, t1=50):\n    np.random.seed(42)\n    theta = np.random.randn(2,1)\n    for epoch in range(epochs):\n        for i in range(len(X)):\n            x_i = np.zeros((batchSize,1))\n            y_i = np.zeros((batchSize,1))\n            for b in range(batchSize):\n                random_iteration = np.random.randint(len(X))\n                x_i[b] = X[random_iteration]\n                y_i[b] = y[random_iteration]\n            gradientVector = calculateGradientVector(x_i, y_i, theta)\n            eta = learningSchedule(epoch*len(X)+i, t0, t1)\n            theta = theta - eta*gradientVector\n    return theta\n\nminiBatchGradientDescent(X, y, 1000, 20)","2c16103f":"def plotMBGD(X,y,iterations, batchSize): \n    plt.plot(X, y, 'ro')\n    for i in range(iterations):\n        theta = miniBatchGradientDescent(X, y, i, batchSize, t0=1, t1=100)\n        if i is 0:\n            plt.plot([0, 1],[predictY(0, theta), predictY(1, theta)], 'r--')\n        elif i is iterations-1:\n            plt.plot([0, 1],[predictY(0, theta), predictY(1, theta)], 'g-' , linewidth=3)\n        else:\n            plt.plot([0, 1],[predictY(0, theta), predictY(1, theta)], 'b-')\n    plt.xlabel('$X_1$', fontsize=20)\n    plt.title(\"MBGD for ${}$ iterations with batchsize {}\".format(iterations,batchSize), fontsize=15)\n    plt.axis([0, 1, 0, 4])\n    \nplt.figure(figsize=(20,4))\nplt.subplot(121); plotStochastic(X, y, 10, 1, 100)\nplt.ylabel(\"$y$\", rotation=0, fontsize=18)\nplt.subplot(122); plotMBGD(X, y, 10, 10)","99a9d880":"The low _learning rate_ takes a while to get at the optimal $\\theta$ but it did get there. The good _learning rate_ shows us that it gets near to the optimum fast and then starts slowly optimizing it for the optimal $\\theta$. When the high _learning rate_ goes on for a little longer it'll slowly converge on the optimal $\\theta$ but right now it hasn't even come close.\n\n## Stochastic Gradient Descent\nThe problem with Batch Gradient Descent is the use of the full training set every step. This takes a long time to compute and thus makes it very slow with large training sets. Stochastic Gradient Descent is the complete opposite of this. It picks a random instance in the training set every step and computes the gradients based on this instance. This increases the speed of the algorithm immensely. This also makes it possible to train on huge datasets because it doesn't use all the data at once.\n\nThe random nature of the Stochastic Gradient Descent algorithm does cause some problems. It doesn't gently decrease until it reaches a minimum, instead it goes up and down while decreasing on average. This means that once it reaches its optimal $\\theta$ it will still move around. Because of this SGD will only get a very good $\\theta$ but (almost) never the optimal $\\theta$.\n\nWhen cost function is irregular (containing multiple local minima and one global minimum) this can help it \"jump out\" of the local minima towards the global minimum so SGD does have a better chance at finding these then the BGD does. \n\nSo randomness is a good thing when you want to find the global minimum but a bad thing when you want to get the actual global minimum. How do we fix this? We use a _learning schedule_, a function that decreases our step size when we get to a higher iteration.\n\nA function that can compute Stochastic Gradient Descent will have to exist out of these parts:\n* Random instance selection\n* A learning schedule to calculate eta\n* Gradient Vector calculation (of the instance)","998f5917":"## Batch Gradient Descent\nBatch Gradient Descent works by calculating the gradient vector ($\\nabla_\\theta$) of a cost function. This vector contains all _partial derivatives_ of the cost function. A _partial derivative_ is the value you get by calculating how much the cost function will change if you change parameter $\\theta_j$ a tiny bit. For this Kernel we'll use the Mean Squared Error as our cost function.\n\nCalculating the partial derivatives of the cost function for instance $i$:\n\n$\\frac{\\partial}{\\partial\\theta_j}MSE(\\theta) = \\frac{2}{m}\\displaystyle\\sum_{i=1}^{m}(\\theta^Tx^{(i)}-y^{(i)})x^{(i)}_j$\n\nWhere:\n* $\\frac{\\partial}{\\partial\\theta_j}MSE(\\theta)$ is the partial derivative of the MSE cost function for parameter $j$ \n* $\\theta$ is the vector of parameters\n* $m$ is the number of instances in the dataset\n* $x$ is the vector of feature values for the  $i^{th}$ instance\n* $y$ is the label value for the  $i^{th}$ instance\n\n\nCalculating the Gradient Vector of a cost function:\n\n$\\nabla_\\theta MSE(\\theta)= \\begin{bmatrix} \\frac{\\partial}{\\partial\\theta_0}MSE(\\theta) \\\\ \\frac{\\partial}{\\partial\\theta_1}MSE(\\theta) \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial\\theta_n}MSE(\\theta) \\end{bmatrix} = \\frac{2}{m}X^T(X\\theta-y)$\n\nWhere:\n* $\\nabla_\\theta MSE(\\theta)$ is the gradient vector for the MSE cost function for all partial derivatives of $\\theta$\n* $X$ is the matrix combining all feature values (excluding labels) of all instances in the dataset\n\nEach Batch Gradient Descent step uses the full training data (the whole _batch_). This means that the Gradient Vector has to be calculated every step when using this algorithm.\n\nOnce you have calculated the Gradient Vector, which points uphill, you need to go downhill. You can do this by subracting the Gradient Vector from $\\theta$. To make sure the size of the steps isn't to big we use the _learning rate_ $\\eta$ (eta). The smaller our learning rate, the smaller our steps.\n\nCalculating the Gradient Descent Step:\n\n$\\theta^{(next step)} = \\theta - \\eta \\nabla_\\theta MSE(\\theta)$\n\nWhere:\n* $\\theta^{(next step)}$ is the value of theta for the next step\/iteration\n* $\\eta$ is the learning rate","3b30c6c4":"That's pretty close to the BGD $\\theta$! BDG will be superior on this dataset because there is only one minimum but this just shows how close SGD can get. Now that we have seen both Batch and Stochastic Gradient Descent there is only one more Gradient Descent type left.\n\n## Mini-Batch Gradient Descent\nWhat if we combined Batch Gradient Descent and Stochastic Gradient Descent? We would get Mini-Batch Gradient Descent. Using a small random subset of the training set (a _mini-batch_) to compute the Gradient Vector creates less randomness than SGD has and still has the possibility to \"jump out\" of local minima, though not as much as SGD.","b3d4a56b":"## Conclusion\nNow that we have tried all 3 types of Gradient Descent you hopefully have a better grasp of when you can best use which type of Gradient Descent. If you want to use Gradient Descent without creating your own function then Scikit-Learn has its _linearmodel.SGDRegressor_ model. Sadly it doesn't have Batch Gradient Descent or Mini-Batch Gradient Descent.\n\n### Previous Kernel\n[How Does Linear Regression Work?](https:\/\/www.kaggle.com\/veleon\/how-does-linear-regression-work)\n### Next Kernel\n[Polynomial Regression](https:\/\/www.kaggle.com\/veleon\/what-is-polynomial-regression)","b577b4eb":"# What is Gradient Descent?\n[Index](https:\/\/www.kaggle.com\/veleon\/in-depth-look-at-machine-learning-models)\n\nGradient Descent is a generic optimization algorithm for minimizing cost functions by tweaking parameters iteratively. Gradient Descent is not useful for every Machine Learning model or metric. When computing the Mean Squared Error of a Linear Regression model you only have a global minimum. Not every model or metric has only one global minimum. A lot have multiple local minimums and one global minimum. Gradient Descent is used to find these local minimums and hopefully the global minimum as well.\n\n## What does it do?\nThe Gradient Descent algorithm works by calculating the slope of a value in the desired cost function that you want to minimize. It then goes down this slope towards the lowest point. When it reaches this point it stops. Picture a ball rolling down a valley, it'll keep rolling toward the bottom but eventually it will be at the lowest point possible and it'll no longer move from its place.","720cb7ef":"As we can see, the Batch Gradient Descent gives us the same values for $\\theta_0$ and $\\theta_1$ as the Normal Equation that we used in the Linear Regression Kernel. This would be the optimal outcome for this dataset. But what would happen if we changed the _learning rate_?\n\n\n## Learning Rate\nTo show the effect of _learning rate_ on Gradient Descent we'll plot the first \"guesses\" of the algorithm. This will show us how big the steps are that the algorithm makes. We'll also give the first and last guess a different color so we can distinguish them from all the other lines.","c10ff494":"## How does it calculate this?\nWhen implementing Gradient Descent there are 3 types of Gradient Descent you can choose from:\n* Batch Gradient Descent\n* Stochastic Gradient Descent\n* Mini-batch Gradient Descent\n\nEach type of Gradient Descent calculates its minimum in its own way. So we'll go over all three of them in this kernel.\n\n## Creating a Dataset\nBefore we start creating our Gradient Descent functions we'll have to create a dataset that we can use. To do this we'll use numpy's random library.\n\nWe'll use the formula:\n$y = 2+X","7c47c4e8":"As you can see in the 3 different plots, the _learning rate_ has a big effect on the $\\theta$ output of Gradient Descent. When the _learning rate_ is too small (the first plot) then it'll take only small steps. This aproach gets at the optimal $\\theta$ eventually but it'll take a really long time. When you have a good _learning rate_ (the second plot) you take some big steps toward the optimal $\\theta$ at first but then take smaller steps as you get closer. Last, when your _learning rate_ is too high (the third plot) it'll overshoot the target. It will slowly close in but will most likely never reach the optimal $\\theta$ or at least take a really long time. We'll plot all plots once more but this time we'll add some more iterations. "}}