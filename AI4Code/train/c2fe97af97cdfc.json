{"cell_type":{"97f04e44":"code","3646b520":"code","5519a11c":"code","a0082e8a":"code","e5c2877d":"code","4ecba9e0":"code","3f6da89f":"code","e8904c08":"code","64e72db4":"code","dbfe95eb":"code","0ae51c8f":"code","2b644167":"code","747d7fab":"code","4437d634":"code","8ab36fd2":"code","4de7db60":"code","7de834fb":"code","ae834d65":"code","380c8604":"code","3e99de7d":"code","7981f2c6":"code","12bf82f0":"code","16936c56":"code","74494aa1":"code","4e58f26b":"markdown"},"source":{"97f04e44":"import lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport random\nimport optuna\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error","3646b520":"train = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2021\/test.csv\")","5519a11c":"train.head()","a0082e8a":"train.info()","e5c2877d":"from sklearn.preprocessing import LabelEncoder\ndf=train\nfor c in df.columns:\n    if df[c].dtype=='object': \n        lbl = LabelEncoder()\n        df[c]=df[c].fillna('N')\n        lbl.fit(list(df[c].values))\n        df[c] = lbl.transform(df[c].values)\ntrain=df","4ecba9e0":"df=test\nfor c in df.columns:\n    if df[c].dtype=='object': \n        lbl = LabelEncoder()\n        df[c]=df[c].fillna('N')\n        lbl.fit(list(df[c].values))\n        df[c] = lbl.transform(df[c].values)\ntest=df","3f6da89f":"train[0:5]","e8904c08":"test[0:5]","64e72db4":"target = train['target']\ndata = train.drop(['target','id'],axis=1)","dbfe95eb":"columns=data.columns.to_list()\nprint(columns)","0ae51c8f":"def objective(trial,data=data,target=target):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n    param =   {\n        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n        'objective': trial.suggest_categorical('objective',['regression','rmse','binary']),  \n        'max_depth': -1,\n        'learning_rate': 0.1,\n        \"boosting\": \"gbdt\",\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n        \"bagging_freq\": 5,\n        \"bagging_fraction\": trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n        \"feature_fraction\": trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n        \"verbosity\": -1,\n    }\n    model = lgb.LGBMRegressor(**param)      \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    preds = model.predict(test_x)\n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse","2b644167":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=32)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","747d7fab":"study.trials_dataframe()","4437d634":"# shows the scores from all trials\noptuna.visualization.plot_optimization_history(study)","8ab36fd2":"# interactively visualizes the hyperparameters and scores\noptuna.visualization.plot_parallel_coordinate(study)","4de7db60":"# shows the evolution of the search\noptuna.visualization.plot_slice(study)","7de834fb":"# parameter interactions on an interactive chart.\noptuna.visualization.plot_contour(study, params=['num_leaves','objective'])","ae834d65":"# Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","380c8604":"# Visualize empirical distribution function\noptuna.visualization.plot_edf(study)","3e99de7d":"Best_trial=study.best_trial.params\nprint(Best_trial)","7981f2c6":"sample = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2021\/sample_submission.csv\")\nprint(sample.shape)","12bf82f0":"preds = np.zeros((sample.shape[0]))\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nfor trn_idx, test_idx in kf.split(train[columns],target):\n    X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n    y_tr,y_val=target.iloc[trn_idx],target.iloc[test_idx]\n    model = lgb.LGBMRegressor(**Best_trial)\n    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n    preds+=model.predict(test[columns])\/kf.n_splits   ###### predict_proba\n    rmse=mean_squared_error(y_val, model.predict(X_val),squared=False)\n    print(rmse)","16936c56":"print(preds.shape)\nprint(preds[0])","74494aa1":"subm = sample\nsubm['target'] = preds\nsubm.to_csv('submission.csv',index=False)\nsubm","4e58f26b":"# LightGBM with Optuna tuning\n* doc: \nhttps:\/\/github.com\/optuna\/optuna"}}