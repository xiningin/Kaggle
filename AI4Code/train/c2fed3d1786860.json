{"cell_type":{"dff0b927":"code","196ead2c":"code","0faf0629":"code","32e0795a":"code","8d810fe9":"code","11b60b35":"code","dd34d89e":"code","b757ac2f":"code","8aa43d21":"code","0586aca7":"code","378c550a":"code","12e5dc2e":"code","7208dd75":"code","179d7dd9":"code","6fc29525":"code","343431af":"code","b601e79c":"code","35d58996":"markdown","7106fa30":"markdown","4665fcd5":"markdown","beb3f0e0":"markdown","86131573":"markdown","0283af82":"markdown","9ef062bb":"markdown"},"source":{"dff0b927":"# Libraries \nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nfrom PIL import Image\n\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.optimizers import Adam\nfrom keras.layers import Dropout","196ead2c":"#importing training dataset\ntrain=pd.read_csv('..\/input\/gtsrb-german-traffic-sign\/Train.csv')\nX_train=train['Path']\ny_train=train.ClassId\ntrain","0faf0629":"data_dir = \"..\/input\/gtsrb-german-traffic-sign\"\ntrain_imgpath= list((data_dir + '\/' + str(train.Path[i])) for i in range(len(train.Path)))","32e0795a":"for i in range(0,9):\n    plt.subplot(331+i)\n    seed=np.random.randint(0,39210)\n    im = Image.open(train_imgpath[seed])  \n    plt.imshow(im)\n    \nplt.show()","8d810fe9":"train_data=[]\ntrain_labels=[]\n\n\npath = \"..\/input\/gtsrb-german-traffic-sign\/\"\nfor i in range(len(train.Path)):\n    image=cv2.imread(train_imgpath[i])\n    image_from_array = Image.fromarray(image, 'RGB')\n    size_image = image_from_array.resize((28,28))\n    train_data.append(np.array(size_image))\n    train_labels.append(train.ClassId[i])\n\n\nX=np.array(train_data)\ny=np.array(train_labels)","11b60b35":"#Spliting the images into train and validation sets\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split( X, y, test_size=0.20, random_state=7777)  ","dd34d89e":"X_train = X_train.astype('float32')\/255 \nX_val = X_val.astype('float32')\/255\n\n#Using one hote encoding for the train and validation labels\nfrom keras.utils import to_categorical\ny_train = to_categorical(y_train, 43)\ny_val = to_categorical(y_val, 43)","b757ac2f":"def create_model(layers):\n    cnn = tf.keras.models.Sequential()\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 3]))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Flatten())\n    \n    for i, nodes in enumerate(layers):\n        cnn.add(tf.keras.layers.Dense(units=nodes, activation='relu'))\n            \n    cnn.add(tf.keras.layers.Dense(units=43, activation='softmax'))\n    \n    cnn.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return cnn\n\nmodel = KerasClassifier(build_fn=create_model, verbose=1)\nlayers = [[128],(256, 128),(200, 150, 120)]\nparam_grid = dict(layers=layers)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=1)\ngrid_results = grid.fit(X_train,y_train, validation_data=(X_val, y_val))\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nstds = grid_results.cv_results_['std_test_score']\nparams = grid_results.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print('{0} ({1}) with: {2}'.format(mean, stdev, param))","8aa43d21":"def create_model1():\n    cnn = tf.keras.models.Sequential()\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 3]))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Flatten())\n    cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))\n    cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n    cnn.add(tf.keras.layers.Dense(units=43, activation='softmax'))\n    \n    cnn.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return cnn\n\nmodel = KerasClassifier(build_fn = create_model1, verbose = 1)\n\nbatch_size = [20,40]\nparam_grid = dict(batch_size=batch_size)\n\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 1)\ngrid_results = grid.fit(X_train,y_train, validation_data=(X_val, y_val))\n\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nparams = grid_results.cv_results_['params']\nfor mean,param in zip(means,params):\n    print('{0} with: {1}'.format(mean,param))","0586aca7":"def create_model2(dropout):\n    # create model\n    cnn = tf.keras.models.Sequential()\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 3]))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n    cnn.add(tf.keras.layers.Flatten())\n    cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))\n    cnn.add(Dropout(dropout))\n    cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n    cnn.add(Dropout(dropout))\n    cnn.add(tf.keras.layers.Dense(units=43, activation='softmax'))\n    \n    cnn.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return cnn\n\nmodel = KerasClassifier(build_fn = create_model2, verbose = 1, batch_size=20)\n\ndropout = [0.0, 0.1, 0.2]\nparam_grid = dict(dropout=dropout)\n\ngrid = GridSearchCV(estimator = model, param_grid = param_grid, verbose = 1)\ngrid_results = grid.fit(X_train,y_train, validation_data=(X_val, y_val))\n\nprint(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\nmeans = grid_results.cv_results_['mean_test_score']\nparams = grid_results.cv_results_['params']\nfor mean,param in zip(means,params):\n    print('{0} with: {1}'.format(mean,param))","378c550a":"#Definition of the DNN model\n\ncnn = tf.keras.models.Sequential()\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[28, 28, 3]))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\ncnn.add(tf.keras.layers.Flatten())\ncnn.add(tf.keras.layers.Dense(units=256, activation='relu'))\ncnn.add(Dropout(0.1))\ncnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\ncnn.add(Dropout(0.1))\ncnn.add(tf.keras.layers.Dense(units=43, activation='softmax'))\n\n# compile the model\ncnn.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nhistory = cnn.fit(X_train, y_train, batch_size=20, epochs=20,validation_data=(X_val, y_val))","12e5dc2e":"import matplotlib.pyplot as plt\n\nplt.figure(0)\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\nplt.figure(1)\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.title('Loss')\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.legend()","7208dd75":"test=pd.read_csv('..\/input\/gtsrb-german-traffic-sign\/Test.csv')\nX_test=train['Path']\ny_test=train.ClassId","179d7dd9":"data_dir = \"..\/input\/gtsrb-german-traffic-sign\"\ntest_imgpath= list((data_dir + '\/' + str(test.Path[i])) for i in range(len(test.Path)))","6fc29525":"test_data=[]\ntest_labels=[]\n\n\npath = \"..\/input\/gtsrb-german-traffic-sign\/\"\nfor i in range(len(test.Path)):\n    image=cv2.imread(test_imgpath[i])\n    image_from_array = Image.fromarray(image, 'RGB')\n    size_image = image_from_array.resize((28,28))\n    test_data.append(np.array(size_image))\n    test_labels.append(test.ClassId[i])\n\n\nX_test=np.array(test_data)\ny_test=np.array(test_labels)\n\nX_test = X_test.astype('float32')\/255 ","343431af":"#predictions-\npred = cnn.predict_classes(X_test)","b601e79c":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, pred)","35d58996":"Inputing the parameters in the final model (for better accuracy, you can run grid search multiple times zooming into each range used before)","7106fa30":"Grid Search to determine the batch size","4665fcd5":"# CNN Model-\n\nGrid Search to determine the layers and neurons in each layer in the sequential model.","beb3f0e0":"Plotting the values of accuracy and loss vs epoch to visually determine the suitable number of epochs required","86131573":"Grid Search to determine the dropout rate","0283af82":"# Preprocessing image-\nconverting images into arrays of the form (28,28,3)","9ef062bb":"# preparing test data"}}