{"cell_type":{"a5be3bd9":"code","d208b2a3":"code","6c6f7043":"code","bd9c42a1":"code","d52bd47f":"code","7201b6c1":"code","f26722a7":"code","6e78585a":"code","25c2b8a1":"code","1093f846":"code","061c471c":"code","15ea97e2":"code","2acbf662":"code","ad23423a":"code","0d42dab8":"code","2047986d":"code","de9d2945":"code","eb094b83":"code","e5da4758":"markdown","cfa5f301":"markdown","e1787fa6":"markdown","1e89030e":"markdown","28043e1a":"markdown","ce3e326d":"markdown","9971b19c":"markdown","a7b89184":"markdown","2e28be27":"markdown","d30682e0":"markdown","ce4b39d3":"markdown","007400f7":"markdown"},"source":{"a5be3bd9":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np \nimport pandas as pd \nimport os\nimport pickle\nprint(os.listdir(\"..\/input\"))\n\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom tqdm import tqdm\nfrom tqdm import tqdm_notebook\nimport random\nimport PIL\nfrom PIL import Image, ImageOps\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\nfrom keras.applications.xception import preprocess_input\nimport keras.backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score, accuracy_score\nfrom keras.utils import Sequence\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split","d208b2a3":"!pip install -U efficientnet","6c6f7043":"from efficientnet import EfficientNetB4","bd9c42a1":"#Hyper parameters\nWORKERS = 2\nCHANNEL = 3\nSIZE = 380\nNUM_CLASSES = 196\nepoch = 20\nbatch_size = 16","d52bd47f":"#seed \uace0\uc815\n#Fix seed number.\nseed = 200\n\nnp.random.seed(seed)\ntf.set_random_seed(seed)\nos.environ['PYTHONHASHSEED']=str(seed)\nrandom.seed(seed)\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\nK.set_session(sess)","7201b6c1":"from PIL import Image, ImageEnhance, ImageOps\nimport numpy as np\nimport random\n\nclass ImageNetPolicy(object):\n    \"\"\" Randomly choose one of the best 24 Sub-policies on ImageNet.\n        Example:\n        >>> policy = ImageNetPolicy()\n        >>> transformed = policy(image)\n        Example as a PyTorch Transform:\n        >>> transform=transforms.Compose([\n        >>>     transforms.Resize(256),\n        >>>     ImageNetPolicy(),\n        >>>     transforms.ToTensor()])\n    \"\"\"\n    def __init__(self, fillcolor=(128, 128, 128)):\n        self.policies = [\n            SubPolicy(0.4, \"posterize\", 8, 0.6, \"rotate\", 9, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor),\n            SubPolicy(0.6, \"posterize\", 7, 0.6, \"posterize\", 6, fillcolor),\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 4, 0.8, \"rotate\", 8, fillcolor),\n            SubPolicy(0.6, \"solarize\", 3, 0.6, \"equalize\", 7, fillcolor),\n            SubPolicy(0.8, \"posterize\", 5, 1.0, \"equalize\", 2, fillcolor),\n            SubPolicy(0.2, \"rotate\", 3, 0.6, \"solarize\", 8, fillcolor),\n            SubPolicy(0.6, \"equalize\", 8, 0.4, \"posterize\", 6, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 0.4, \"color\", 0, fillcolor),\n            SubPolicy(0.4, \"rotate\", 9, 0.6, \"equalize\", 2, fillcolor),\n            SubPolicy(0.0, \"equalize\", 7, 0.8, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n\n            SubPolicy(0.8, \"rotate\", 8, 1.0, \"color\", 2, fillcolor),\n            SubPolicy(0.8, \"color\", 8, 0.8, \"solarize\", 7, fillcolor),\n            SubPolicy(0.4, \"sharpness\", 7, 0.6, \"invert\", 8, fillcolor),\n            SubPolicy(0.6, \"shearX\", 5, 1.0, \"equalize\", 9, fillcolor),\n            SubPolicy(0.4, \"color\", 0, 0.6, \"equalize\", 3, fillcolor),\n\n            SubPolicy(0.4, \"equalize\", 7, 0.2, \"solarize\", 4, fillcolor),\n            SubPolicy(0.6, \"solarize\", 5, 0.6, \"autocontrast\", 5, fillcolor),\n            SubPolicy(0.6, \"invert\", 4, 1.0, \"equalize\", 8, fillcolor),\n            SubPolicy(0.6, \"color\", 4, 1.0, \"contrast\", 8, fillcolor),\n            SubPolicy(0.8, \"equalize\", 8, 0.6, \"equalize\", 3, fillcolor)\n        ]\n\n\n    def __call__(self, img):\n        policy_idx = random.randint(0, len(self.policies) - 1)\n        return self.policies[policy_idx](img)\n\n    def __repr__(self):\n        return \"AutoAugment ImageNet Policy\"\nclass SubPolicy(object):\n    def __init__(self, p1, operation1, magnitude_idx1, p2, operation2, magnitude_idx2, fillcolor=(128, 128, 128)):\n        ranges = {\n            \"shearX\": np.linspace(0, 0.3, 10),\n            \"shearY\": np.linspace(0, 0.3, 10),\n            \"translateX\": np.linspace(0, 150 \/ 331, 10),\n            \"translateY\": np.linspace(0, 150 \/ 331, 10),\n            \"rotate\": np.linspace(0, 30, 10),\n            \"color\": np.linspace(0.0, 0.9, 10),\n            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n            \"solarize\": np.linspace(256, 0, 10),\n            \"contrast\": np.linspace(0.0, 0.9, 10),\n            \"sharpness\": np.linspace(0.0, 0.9, 10),\n            \"brightness\": np.linspace(0.0, 0.9, 10),\n            \"autocontrast\": [0] * 10,\n            \"equalize\": [0] * 10,\n            \"invert\": [0] * 10\n        }\n\n        # from https:\/\/stackoverflow.com\/questions\/5252170\/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand\n        def rotate_with_fill(img, magnitude):\n            rot = img.convert(\"RGBA\").rotate(magnitude)\n            return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)\n\n        func = {\n            \"shearX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, magnitude * random.choice([-1, 1]), 0, 0, 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"shearY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, magnitude * random.choice([-1, 1]), 1, 0),\n                Image.BICUBIC, fillcolor=fillcolor),\n            \"translateX\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, magnitude * img.size[0] * random.choice([-1, 1]), 0, 1, 0),\n                fillcolor=fillcolor),\n            \"translateY\": lambda img, magnitude: img.transform(\n                img.size, Image.AFFINE, (1, 0, 0, 0, 1, magnitude * img.size[1] * random.choice([-1, 1])),\n                fillcolor=fillcolor),\n            \"rotate\": lambda img, magnitude: rotate_with_fill(img, magnitude),\n            # \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),\n            \"color\": lambda img, magnitude: ImageEnhance.Color(img).enhance(1 + magnitude * random.choice([-1, 1])),\n            \"posterize\": lambda img, magnitude: ImageOps.posterize(img, magnitude),\n            \"solarize\": lambda img, magnitude: ImageOps.solarize(img, magnitude),\n            \"contrast\": lambda img, magnitude: ImageEnhance.Contrast(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"sharpness\": lambda img, magnitude: ImageEnhance.Sharpness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"brightness\": lambda img, magnitude: ImageEnhance.Brightness(img).enhance(\n                1 + magnitude * random.choice([-1, 1])),\n            \"autocontrast\": lambda img, magnitude: ImageOps.autocontrast(img),\n            \"equalize\": lambda img, magnitude: ImageOps.equalize(img),\n            \"invert\": lambda img, magnitude: ImageOps.invert(img)\n        }\n\n        # self.name = \"{}_{:.2f}_and_{}_{:.2f}\".format(\n        #     operation1, ranges[operation1][magnitude_idx1],\n        #     operation2, ranges[operation2][magnitude_idx2])\n        self.p1 = p1\n        self.operation1 = func[operation1]\n        self.magnitude1 = ranges[operation1][magnitude_idx1]\n        self.p2 = p2\n        self.operation2 = func[operation2]\n        self.magnitude2 = ranges[operation2][magnitude_idx2]\n\n\n    def __call__(self, img):\n        if random.random() < self.p1: img = self.operation1(img, self.magnitude1)\n        if random.random() < self.p2: img = self.operation2(img, self.magnitude2)\n        return img","f26722a7":"trans = ImageNetPolicy()","6e78585a":"#\ub370\uc774\ud130 path\npath = '..\/input\/2019-3rd-ml-month-with-kakr\/'\n#train_img_path = os.path.join(path, 'train')\n#test_img_path = os.path.join(path, 'test')\ncrop_train_path = '..\/input\/2019-3rd-ml-month-with-kakr\/train\/'\ncrop_test_path = '..\/input\/2019-3rd-ml-month-with-kakr\/test\/'\nweight_path = '..\/input\/model-weight\/'\n\n#Load csv files\ndf_train = pd.read_csv(os.path.join(path, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(path, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(path, 'class.csv'))","25c2b8a1":"#To use to_categorical function, add -1\ndf_train['class'] = df_train['class'].values.astype(int) -1\ndf_train['class'] = df_train['class'].astype('str')\n\nx = df_train['img_file']\ny = df_train['class']\ny = to_categorical(y, num_classes=NUM_CLASSES)\n\ntrain_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n                                                      stratify=y, random_state=8)\nprint(train_x.shape)\nprint(train_y.shape)\nprint(valid_x.shape)\nprint(valid_y.shape)","1093f846":"from keras.utils import Sequence\n\nclass My_Generator(Sequence):\n\n    def __init__(self, image_filenames, labels,\n                 batch_size, is_train=False, is_test=False,\n                 mix=False, augment=False):\n        self.image_filenames, self.labels = image_filenames, labels\n        self.batch_size = batch_size\n        self.is_train = is_train\n        self.is_test = is_test\n        self.is_augment = augment\n        if(self.is_train):\n            self.on_epoch_end()\n        self.is_mix = mix\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_filenames) \/ float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        if(self.is_train):\n            return self.train_generate(batch_x, batch_y)\n        if(self.is_test):\n            return self.test_generate(batch_x)\n        return self.valid_generate(batch_x, batch_y)\n\n    def on_epoch_end(self):\n        if(self.is_train):\n            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n    \n    def mix_up(self, x, y):\n        lam = np.random.beta(0.2, 0.4)\n        ori_index = np.arange(int(len(x)))\n        index_array = np.arange(int(len(x)))\n        np.random.shuffle(index_array)        \n        \n        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n        \n        return mixed_x, mixed_y\n\n    def train_generate(self, batch_x, batch_y):\n        batch_images = []\n        for (sample, label) in zip(batch_x, batch_y):\n            #img = cv2.imread(os.path.join(crop_train_path, sample))\n            #img = cv2.resize(img, (SIZE, SIZE))\n            img = PIL.Image.open(os.path.join(crop_train_path, sample)).convert('RGB')\n            img = img.resize((SIZE, SIZE))\n            \n            if(self.is_augment):\n                #img = seq.augment_image(img)\n                img = trans(img)\n            img_np  = np.asarray(img)\n            if img_np.shape != (240, 240, 3):\n                img = img.convert('RGB')\n                img_np  = np.asarray(img)   \n            batch_images.append(img_np)\n        batch_images = np.array(batch_images, np.float32) \/ 255\n        batch_y = np.array(batch_y, np.float32)\n        if(self.is_mix):\n            batch_images, batch_y = self.mix_up(batch_images, batch_y)\n        return batch_images, batch_y\n\n    def valid_generate(self, batch_x, batch_y):\n        batch_images = []\n        for (sample, label) in zip(batch_x, batch_y):\n            #img = cv2.imread(os.path.join(crop_train_path, sample))\n            #img = cv2.resize(img, (SIZE, SIZE))\n            img = PIL.Image.open(os.path.join(crop_train_path, sample)).convert('RGB')\n            img = img.resize((SIZE, SIZE))\n            img  = np.asarray(img)\n            batch_images.append(img)\n        batch_images = np.array(batch_images, np.float32) \/ 255\n        batch_y = np.array(batch_y, np.float32)\n        return batch_images, batch_y\n    \n    def test_generate(self, batch_x):\n        batch_images = []\n        for sample in batch_x:\n            #img = cv2.imread(os.path.join(crop_train_path, sample))\n            #img = cv2.resize(img, (SIZE, SIZE))\n            img = PIL.Image.open(os.path.join(crop_test_path, sample)).convert('RGB')\n            img = img.resize((SIZE, SIZE))\n            \n            if (self.is_augment):\n                img = trans(img)\n            img_np  = np.asarray(img)\n            if img_np.shape != (380, 380, 3): #\uc704\uc758 Auto Augmentation\uc744 \uc801\uc6a9\ud558\uba74 \ub4dc\ubb3c\uac8c grayscale\ud55c \uacb0\uacfc\ub97c \uc8fc\uac8c \ub418\ub294\ub370, \uc774\ub54c \uc5d0\ub7ec\ub97c \ubc29\uc9c0\ud558\uae30 \uc704\ud568.\n                img = img.convert('RGB')\n                img_np  = np.asarray(img)\n            batch_images.append(img_np)\n        batch_images = np.array(batch_images, np.float32) \/ 255\n        return batch_images","061c471c":"submit = pd.read_csv(os.path.join(path, 'sample_submission.csv'))\ntest_x = submit['img_file']\ntest_y = submit['class']","15ea97e2":"train_step = np.ceil(len(test_x) \/ batch_size)\ntest_generator = My_Generator(test_x, test_y, batch_size=batch_size, is_train=False, is_test=True)\ntest_aug_generator = My_Generator(test_x, test_y, batch_size=batch_size, is_train=False, is_test=True, augment=True)","2acbf662":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D, Concatenate)\n#from keras.applications.xception import Xception\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nimport keras\nfrom keras.models import Model","ad23423a":"function = \"softmax\"\ndef create_model(input_shape, n_out):\n    input_tensor = Input(shape=input_shape)\n    base_model = EfficientNetB4(include_top=False,\n                   #weights='imagenet',\n                    weights=None,\n                   input_tensor=input_tensor)\n    #base_model.load_weights('..\/input\/model-weight\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    final_output = Dense(n_out, activation=function, name='final_output')(x)\n    model = Model(input_tensor, final_output)\n    \n    return model","0d42dab8":"def generator_predict(model, filename=None, test_generator=test_generator, test_aug_generator=test_aug_generator,batch_size=batch_size):\n    '''\n        input param\n            model : \uc0ac\uc6a9\ud560 \ubaa8\ub378\n            filename : output\uc744 \uc800\uc7a5\ud560 pickle \ud30c\uc77c\uba85, \ub9cc\uc57d \uc785\ub825\ud558\uc9c0 \uc54a\uc73c\uba74 \uc800\uc815\ud558\uc9c0 \uc54a\uc74c. \n            test_generator : \uc6d0\ubcf8 image generator\n            test_aug_generator : Augmentation\uc744 \uc801\uc6a9\ud55c image generator\n        return \n            TTA\ud55c \uac12\uc744 \ud3c9\uade0\ud55c output\n    '''\n    pred_list = []\n    #org predict\n    pred_list.append(model.predict_generator(test_generator, \n                                             steps=train_step, \n                                             #steps=5,\n                                             verbose=1\n                                            ))\n    #Add TTA predict\n    for i in range(9):\n        pred_list.append(model.predict_generator(test_aug_generator, \n                                                 steps=train_step, \n                                                 #steps=5,\n                                                 #verbose=1\n                                                ))\n\n    #Store org predict score\n    if filename:\n        filename = filename + '.pickle'\n        with open(filename, 'wb') as f:\n                pickle.dump(pred_list, f, pickle.HIGHEST_PROTOCOL)\n\n    #Predict by score avg\n    predicted = np.mean(pred_list, axis=0)\n    return predicted #(Num of image, NUM of classes)","2047986d":"model_list = ['effi_basic.h5', \n              'effi_basic_add_4f.h5', \n              'effi_basic_add.h5', \n              'effi_f1_bestqwk.h5', \n              'effi_f2_bestqwk.h5', \n              'effi_f3_bestqwk.h5', \n              'effi_f4_bestqwk.h5',\n              'effi_f5_bestqwk.h5']","de9d2945":"model_pred = []\nfor i, name in enumerate(tqdm_notebook(model_list)):\n    test_generator = My_Generator(test_x,test_y, batch_size=batch_size, is_train=False, is_test=True)\n    test_aug_generator = My_Generator(test_x, test_y, batch_size=batch_size, is_train=False, is_test=True, augment=True)\n    \n    print('{} model predict'.format(name))\n    model = create_model(\n        input_shape=(SIZE,SIZE,3), \n        n_out=NUM_CLASSES)\n    model.load_weights(os.path.join(weight_path, name))\n    model_pred.append(generator_predict(model=model, filename=name))","eb094b83":"predict = np.mean(model_pred, axis=0)\npredict = np.argmax(predict, axis=1) + 1\nsubmit['class'] = predict\nprint(submit.head())","e5da4758":"## Predict by Test Time augmentation ","cfa5f301":"## data augmentation\n\n* Autoaugmentation by ImageNetPolicy, https:\/\/github.com\/DeepVoltaire\/AutoAugment","e1787fa6":"\ubaa8\ub4e0 \uacb0\uacfc\uac12\uc744 \ud3c9\uade0\ub0b4\uc11c \ucd5c\uc885 \uacb0\uacfc\uac12\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.","1e89030e":"# <a id='0'>[3rd ML] Keras EfficientNet + TTA solution<\/a>","28043e1a":"### Install efficientNet\n\nefficientNet input size by https:\/\/github.com\/lukemelas\/EfficientNet-PyTorch\/issues\/42\n\n        # Coefficients:   width,depth,res,dropout\n        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n        'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n        'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n        'efficientnet-b7': (2.0, 3.1, 600, 0.5),","ce3e326d":"## Create model","9971b19c":"## Set up ","a7b89184":"\uc544\ub798\ubd80\ud130\ub294 \ubaa8\ub378 weight\ub97c load\ud574\uc11c TTA\ud558\ub294 \uacfc\uc815\uc785\ub2c8\ub2e4.","2e28be27":"## Load csv data","d30682e0":"## Create Generator\n\nCustom Generator\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. `augmen` \ub85c augmentation\uc744 \uc801\uc6a9\ud560\uc9c0 \uc120\ud0dd\ud569\ub2c8\ub2e4.","ce4b39d3":"\uc5ec\uae30\uc11c class\uc5d0 1\uc744 \ube7c\uc8fc\ub294 \uc774\uc720\ub294 `df_train['class']`0\uc774 \uc544\ub2cc 1\ubd80\ud130 \ud074\ub798\uc2a4 \ubd80\uc5ec\uac00 \ub418\uc5b4\uc788\uc5b4 \ub530\ub85c `to_categorical`\uc744 \uc801\uc6a9\ud558\uba74 \uc5d0\ub7ec\uac00 \ubc1c\uc0dd\ud569\ub2c8\ub2e4. \uc774\ubd80\ubd84\uc744 \ud574\uacb0\ud558\uae30 \uc704\ud574 1\uc744 \ube90\uc2b5\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9 \ubd80\ubd84\uc5d0\uc11c \ub2e4\uc2dc 1\uc744 \ub354\ud574\uc918\uc57c\ud569\ub2c8\ub2e4.","007400f7":"## Record\n\nBaseline \ucf54\ub4dc\ub294 [@\ud0dc\uc9c4\ub2d8\uc758 \ucee4\ub110](https:\/\/www.kaggle.com\/fulrose\/3rd-ml-month-car-model-classification-baseline)\uacfc \ud568\uaed8 APTOS competition\uc758 \ucee4\ub110\uc778 [resnet50 baseline](https:\/\/www.kaggle.com\/mathormad\/aptos-resnet50-baseline) \ucf54\ub4dc\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n\ud574\ub2f9 \ucee4\ub110\ub97c \ud544\uc0ac\ud558\uba74\uc11c Generator\uc640 Callback\uc744 custom\ud558\ub294 \ubd80\ubd84\uc774 \ub9ce\uc774 \ub3c4\uc6c0\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc774\ubc88 \ucee4\ub110\uc5d0\uc11c\ub294 \uacb0\uacfc\ub97c \uc815\ub9ac\ud558\uace0, \ubaa8\ub378\uc758 weight\ub97c \ubd88\ub7ec\uc640 TTA\ub85c \uacb0\uacfc\uac12\uc744 \uacc4\uc0b0\ud558\ub294 \uacfc\uc815\uacfc \uc5ec\uae30\uc11c \ud544\uc694\ud55c Test Generator\ub97c \uc9c1\uc811 \uc124\uacc4\ud588\ub358 \uacfc\uc815\uc744 \uc62c\ub838\uc2b5\ub2c8\ub2e4. \uc88b\uc740 \ub300\ud68c \uc5f4\uc5b4\uc8fc\uc2e0 \uce90\uae00 \ucf54\ub9ac\uc544 \uc6b4\uc601\uc9c4\uaed8 \uac10\uc0ac\ud569\ub2c8\ub2e4.\n\n\n### 1. Model\n* Xception\uacfc Resnet, Moblienet, EfficientNet(B0, B3, B4)\ub97c \uc2e4\ud5d8\ud558\uc600\uc73c\uba70, \ucd5c\uc885\uc801\uc73c\ub85c EfficientNetB4\ub85c \ucd1d 8\uac1c \ubaa8\ub378 weight\ub97c \uc0dd\uc131\ud588\uc2b5\ub2c8\ub2e4. \n\n```\ntrain(0.85), val(0.15) \ub370\uc774\ud130\ub85c \ud559\uc2b5(50 epoch) : 0.93400\ntrain(0.85), val(0.15) \ub370\uc774\ud130\ub85c \ud559\uc2b5 + \ucd94\uac00 20 epoch \ud559\uc2b5: 0.92826\ntrain(0.85), val(0.15) \ub370\uc774\ud130\ub85c \ud559\uc2b5 + \uc804\uccb4 \ub370\uc774\ud130 \ucd94\uac00\ud559\uc2b5 : 0.93591\n\n@saewonYang \ub2d8\uc758 How to split folds and train\uc758 fold.csv\ub97c \uc774\uc6a9\ud574\uc11c \ud559\uc2b5\n1 fold : 0.93208\n2 fold : 0.93161\n3 fold : 0.93591\n4 fold : 0.93298\n5 fold : 0.94021\n```\n### 2. Image & Augmentation\n* Data\ub294 \ud5c8\ud0dc\uba85\ub2d8\uc774 \uc81c\uacf5\ud574\uc8fc\uc2e0 [Crop image](https:\/\/www.kaggle.com\/tmheo74\/3rd-ml-month-car-image-cropping-updated-7-10)\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n* Size \ub294 300\uc5d0\uc11c 380\uc73c\ub85c \uc62c\ub838\uc744 \ub54c, EfficientNet \uae30\uc900 3%\uac00 \uc62c\ub77c\uc11c 380\uc73c\ub85c \uacb0\uc815\ud558\uc600\uc2b5\ub2c8\ub2e4.\n* Augmentation\uc740 \ucd08\uae30\uc5d0\ub294 ImageGenerator\uc5d0\uc11c \uc124\uc815\ud558\ub294 \uac12\ub9cc \uc801\uc6a9\ud558\ub2e4\uac00, [Autoaugmentation](https:\/\/github.com\/DeepVoltaire\/AutoAugment)\uc744 \uc801\uc6a9\ud588\uc2b5\ub2c8\ub2e4(\uc57d 0.8%\uc758 \uc0c1\ud5a5).\n\n\n### 3. Optimizer\n* Adam\uacfc AdamAccumulate_v1, AdamBound \uc138\uac00\uc9c0\ub97c \uc2e4\ud5d8\ud588\uc2b5\ub2c8\ub2e4. Warm up \ud559\uc2b5\uc5d0\ub294 Adam\ub97c \uc4f0\uace0 \uc774\ud6c4  AdamBound\uc640 AdamAccumulate_v1 \uc911, AdamAccumulate_v1\uac00 0.2% \ub192\uac8c \ub098\uc654\uc2b5\ub2c8\ub2e4.\n\n\n### 4. TTA\n* TTA\ub97c \uc801\uc6a9\ud558\ub294 \uac83\ub9cc\uc73c\ub85c\ub3c4 \uc57d 0.5% \uc815\ud655\ub3c4\uac00 \uc0c1\uc2b9\ud588\uc2b5\ub2c8\ub2e4. \uc6d0\ubcf8 \uc774\ubbf8\uc9c0 output + 9\ubc88\uc758 TTA output, \ucd1d 10\uac1c\uc758 \uac12\uc744 \ud3c9\uade0\ub0b4\uc11c \ucd5c\uc885 output\uc744 \uad6c\ud588\uc2b5\ub2c8\ub2e4. NN\ub3c4 \uc801\uc6a9\ud574\ubd24\ub294\ub370 \uc624\ud788\ub824 \ud3c9\uade0\ud55c \uac83\ubcf4\ub2e4 score\uac00 \ub5a8\uc5b4\uc9c0\ub354\uad70\uc694. Augmentation \ubc29\ubc95\uc740 \ud559\uc2b5\ud588\ub358 \uac83\uacfc \ub3d9\uc77c\ud558\uac8c Autoaugmentation\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n\n### 5. Ensemble\n\n* \ucd5c\uc885 8\uac1c \uac12\uc73c\ub85c Ensemble \ubc29\ubc95 \uc911 \uba87 \uac00\uc9c0\ub97c \uc2e4\ud5d8\ud574\ubcf4\uc558\uc2b5\ub2c8\ub2e4. \n\n    1. \ub2e8\uc21c \ud3c9\uade0\n    2. \ubaa8\ub378\uc758 public score\ub85c \uac00\uc911\uce58\ub97c \ubd80\uc5ec\ud558\ub294 Weight \ud3c9\uade0\n    3. 8\uac1c\uc758 \ubaa8\ub378 output(8, 6150, 196)\uc744 NN\uc744 \ud1b5\uacfc\uc2dc\ucf1c \uacc4\uc0b0\ud55c \uacb0\uacfc\uac12.\n\n* 1\ubc88\uacfc 2\ubc88\ub294 public score \uae30\uc900 0.95265, 3\ubc88\uc740 0.95361\uc744 \ubcf4\uc5ec\uc8fc\uc5c8\uc2b5\ub2c8\ub2e4.\n\n### 6. Etc....\n* `categorical_crossentropy` \ub300\uc2e0 Focal loss\uc744 \uc801\uc6a9\ud574\ubcf4\uc558\uc2b5\ub2c8\ub2e4. \uc624\ud788\ub824 \uc815\ud655\ub3c4\uac00 \ub5a8\uc5b4\uc838\uc11c \uc801\uc6a9\ud558\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4. focal loss\ub294 \uc544\ub798 \ucf54\ub4dc\ub97c \uc0ac\uc6a9\ud588\ub294\ub370 \ud639\uc2dc \ub2e4\ub978 \ucf54\ub4dc\uac00 \uc788\uc73c\uba74 comment\uc5d0 \ub0a8\uaca8\uc8fc\uc2dc\uba74 \uac10\uc0ac\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n\n```\ngamma = 2.0\nepsilon = K.epsilon() #1e-7\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.mean(FL, axis=1)\n    return loss\n```\n* \uc790\ub3d9\ucc28\uc758 \uc885\ub958\uc640 \ube0c\ub79c\ub4dc\ub97c \uacb0\ud569\ud574\uc11c \ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5b4\ubcf4\uc558\uc2b5\ub2c8\ub2e4. class.csv \ud30c\uc77c\uc744 \uc0b4\ud3b4\ubcf4\uba74, \uc790\ub3d9\ucc28\uc758 \ube0c\ub79c\ub4dc\uc640 \uc885\ub958\uac00 \uc798 \ub098\ub220\uc838 \uc788\uc5b4, 49\uac1c\uc758 \ube0c\ub79c\ub4dc, 9\uac1c\uc758 \ucc28\uc885\uc73c\ub85c \ubd84\ub958\ud558\ub294 CNN \ubaa8\ub378\uc744 \ud559\uc2b5\uc2dc\ud0a4\uace0 (196,), (49, ), (9, )\ub97c concat\ud558\uc5ec Dense\ub85c \uc5f0\uacb0\uc2dc\ud0a8 \ubaa8\ub378\uc744 \uad6c\uc131\ud588\uc2b5\ub2c8\ub2e4. Moblienet \uae30\uc900, 2% \uc0c1\uc2b9\ud588\uc73c\uba70 EfficientNetB4\uc5d0\ub3c4 \uc801\uc6a9\ud558\ub824\uace0 \ud588\uc73c\ub098 \ucee4\ub110 \uba54\ubaa8\ub9ac\uac00 \ud130\uc838\ubc84\ub9ac\ub294 \ubc14\ub78c\uc5d0 \ud559\uc2b5\uc5d0 \uc2e4\ud328\ud588\ub124\uc694\u3160 "}}