{"cell_type":{"fd6b80a9":"code","31f6b542":"code","314db3aa":"code","d0bfbb05":"code","5987c0ca":"code","66a7779d":"code","39b4b502":"code","3e2a52b1":"code","69f087ec":"code","f718fb83":"code","0ef57965":"code","8b91c5a8":"code","db7b1cfd":"code","2f126a2e":"code","210035f0":"code","d36ee46a":"code","fa42563c":"code","40678721":"code","65f1c8bd":"code","afc3a5fd":"code","8f8481e0":"code","54ecf0de":"code","87301fcb":"code","08abdf3d":"code","baf99118":"code","25a2eac1":"code","f4a5b5f9":"code","a579e4cc":"code","20501573":"code","0195c917":"code","3ab3720d":"code","14f9b495":"code","5a8975e6":"code","8a262e12":"code","65066c0d":"code","c3dee499":"code","7a672841":"markdown","11a08327":"markdown","066c9ca8":"markdown","e8460cac":"markdown"},"source":{"fd6b80a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","31f6b542":"# ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport cv2       # open CV\nimport os\nimport tensorflow as tf\nimport keras\n# Data manipulation & visulation\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# data augmentation\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#model creation and evaluation \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score, recall_score, classification_report\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom keras.layers import Dense\nfrom keras.layers import Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.applications.vgg16 import VGG16\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nimport random as rn\nfrom tqdm import tqdm","314db3aa":"print(os.listdir('\/kaggle\/input\/flower-photos\/flower_photos'))\n# count = 0\n# for root, folders, filenames in os.walk('\/kaggle\/input'):\n#    print(root, folders)","d0bfbb05":"Daisy_flower_dir = '\/kaggle\/input\/flower-photos\/flower_photos\/daisy'\nSunflower_flower_dir = '..\/input\/flower-photos\/flower_photos\/sunflowers'\nTulip_flower_dir = '..\/input\/flower-photos\/flower_photos\/tulips'\nDandelion_flower_dir = '..\/input\/flower-photos\/flower_photos\/dandelion'\nRose_flower_dir = '..\/input\/flower-photos\/flower_photos\/roses'","5987c0ca":"images = []\nlabels = []\nimg_size = 150\n\ndef image_data(flower_name, DIR):\n    for i in tqdm(os.listdir(DIR)):\n        try:\n            \n            path = os.path.join(DIR,i)\n            img = cv2.imread(path)\n            img = cv2.resize(img, (img_size, img_size))\n            img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        \n            images.append(np.array(img))\n            labels.append(str(flower_name))\n            \n        except:\n            print(path)\n            ","66a7779d":"image_data('Daisy', Daisy_flower_dir)\nlen(images)","39b4b502":"image_data('Sunflowers', Sunflower_flower_dir)\nlen(images)","3e2a52b1":"image_data('Tulip', Tulip_flower_dir)\nlen(images)","69f087ec":"image_data('Dandelion', Dandelion_flower_dir)\nlen(images)","f718fb83":"image_data('Rose', Rose_flower_dir)\nlen(images)","0ef57965":"633+699+799+898+641","8b91c5a8":"data = np.array(images)\nlabels = np.array(labels)\nprint('Input(Feature) Data shape :', data.shape)\nprint('Output(Labels) Data shape :', labels.shape)","db7b1cfd":"fig, ax = plt.subplots(4, 2, figsize = (15, 20))\nfor i in range(4):\n    for j in range(2):\n        l = rn.randint(0, data.shape[0])\n        ax[i,j].imshow(data[l])\n        ax[i,j].set_title(labels[l])\n        ax[i,j].axis('off')","2f126a2e":"sns.countplot(labels)\nplt.title(\"Class Distribution\")\nplt.xlabel(\"Class Name\")","210035f0":"le = LabelEncoder()\ny = le.fit_transform(labels)\ny = to_categorical(y, 5)\ny[0]","d36ee46a":"# Normalize the input data in range [0 1]\nX = data\/255","fa42563c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 5)\n\nprint(\"X_train shape :\",X_train.shape)\nprint(\"y_train shape :\",y_train.shape)\nprint(\"X_test shape :\" ,X_test.shape)\nprint(\"y_test shape :\",y_test.shape)","40678721":"from keras.layers import Dense\nfrom keras.layers import Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import Adam, RMSprop, SGD\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom keras.callbacks import ReduceLROnPlateau","65f1c8bd":"Base_model = VGG16(include_top= False, \n                   weights='imagenet',\n                   input_shape=(150,150,3), \n                   pooling='avg')\nBase_model.summary()","afc3a5fd":"model = Sequential()\n\nmodel.add(Base_model)\nmodel.add(Dense(256,activation='relu'))\n# adding prediction(softmax) layer\nmodel.add(Dense(5,activation=\"softmax\"))","8f8481e0":"# freeze layers that are already pre-trained(Base Model)\nBase_model.trainable = False","54ecf0de":"reduc_lr=ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=0.0001, patience=2, verbose=1)","87301fcb":"# Data augmentation\ndatagen = ImageDataGenerator(featurewise_center= False,\n                              samplewise_center= False,\n                              featurewise_std_normalization= False,\n                              samplewise_std_normalization=False,\n                              rotation_range= 10,        # 0- 180\n                              zca_whitening=False,\n                              zoom_range=0.1,            # Randomly zoom image\n                              width_shift_range=0.2,     # randomly shift images horizontally (fraction of total width)\n                              height_shift_range=0.2,    # randomly shift images vertically (fraction of total height)\n                              horizontal_flip=True,      # randomly flip images\n                              vertical_flip=False)       # randomly flip images\n                             \ndatagen.fit(X_train)","08abdf3d":"model.summary()","baf99118":"# Compiling and Training the Model\nmodel.compile(optimizer=Adam(lr = 1e-4), loss= 'categorical_crossentropy', metrics=['accuracy'])","25a2eac1":"batch_size=64\nmodel_history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = 50, validation_data = (X_test,y_test),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] \/\/ batch_size)","f4a5b5f9":"model.save('kaggle\/working\/model.h5')","a579e4cc":"from tensorflow.keras.models import load_model","20501573":"model1 = load_model('kaggle\/working\/model.h5')","0195c917":"model1.summary()","3ab3720d":"model.evaluate(X_test,y_test)","14f9b495":"y_pred = model1.predict(X_train)","5a8975e6":"def readImg(path):\n    img_size = 150\n    img = cv2.imread(path)\n    img = cv2.resize(img, (img_size, img_size))\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    x = np.array(img)\n    X = x\/255\n    print(X.shape)\n    return X\n\nimage11 = r\"..\/input\/flower-photos\/flower_photos\/dandelion\/10043234166_e6dd915111_n.jpg\"\nxtest_scaled = readImg(image11)\n\npred = model1.predict([xtest_scaled])\npred = np.argmax(pred, axis=1)[0]","8a262e12":"X_train.shape","65066c0d":"model1.predict(X_train[0])","c3dee499":"y_pred","7a672841":"## model test accuracy is 81%","11a08327":"## Add Fully Connected Layers","066c9ca8":"- We are not using fully connected layers of VGG16 model(include_top= False). \n- We will add it from our side because in VGG16 softmax layer has 1000 classes and We have only 5 classes.\n- We are using pretrained weights of Imagenet\n- This is a sumary of my base model not a actual model","e8460cac":"Setting a learning rate annealer\nTo make the optimizer converge faster and closest to the global minimum of the loss function, an annealing method of the learning rate (LR) needs to be used."}}