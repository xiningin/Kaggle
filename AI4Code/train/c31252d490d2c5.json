{"cell_type":{"14c13aa6":"code","51059fec":"code","f8e7d749":"code","24271714":"code","c1b2035d":"code","893481ee":"code","344389d9":"code","33472ff6":"code","8cb47a94":"code","3be5bf70":"code","58cc224d":"code","65c58dc4":"code","b68f085d":"code","1ee186fe":"code","7ff46ba9":"code","86c4ab98":"code","b64e2ca9":"code","b8335a91":"code","b66f4d10":"code","219d077d":"code","12a5cf2b":"code","ea1dd93b":"code","284549ed":"code","ba666c5c":"code","60ddc219":"code","b5450f72":"markdown","5e505d3a":"markdown","0a048145":"markdown","990aaeb8":"markdown","489fafd2":"markdown","d8ec4126":"markdown","6c6a9070":"markdown","0c7d48b6":"markdown","bfb81a98":"markdown","59e7cad9":"markdown","abdf2675":"markdown","62f678f7":"markdown","8c3f0a54":"markdown","577f3209":"markdown","e0f03c2e":"markdown","bfcb9f0b":"markdown","41f503ae":"markdown","3720aba1":"markdown","627e05aa":"markdown","a5fb474c":"markdown","70e26d89":"markdown","2edf9cee":"markdown","d0a64a3a":"markdown","8fc15001":"markdown","40342e3d":"markdown","b330d181":"markdown","6fef83c4":"markdown","6c2e8d66":"markdown","4e4c8f87":"markdown","8a972a84":"markdown","7608d371":"markdown"},"source":{"14c13aa6":"import numpy as np\nimport pandas as pd","51059fec":"# Remove 'Data.(csv\/json\/xslx)' with your own csv\/xslx\/json filename. I have added templates for reading other formats as well.\n\ndataset = pd.read_csv('..\/input\/dummydata\/Data.csv') #For reading csv files and storing them as pandas data frame\n\n#dataset = pd.read_excel('Data.xslx') #For reading excel files and storing them as pandas data frame\n#datasets = pd.read_json('Data.json') #For reading json files and storing them as pandas data frame","f8e7d749":"# Seperating data frame into X and y. X and y are both now numpy arrays.\n\nX = dataset.iloc[:, :-1].values #Leaves out the last column and stores the rest in variable 'X' \ny = dataset.iloc[:, -1].values #Stores the last column and stores them in variable 'y'","24271714":"X","c1b2035d":"y","893481ee":"from sklearn.impute import SimpleImputer","344389d9":"# a) Imputing Mean values\nimputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n\n# b) Imputing Median values\n#imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n\n# c) Imputing Most frequent values\n#imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n\n# d) Imputing Constant values\n#imputer = SimpleImputer(missing_values=np.nan, strategy='constant')","33472ff6":"imputer.fit(X[:, 1:3])\nX[:, 1:3] = imputer.transform(X[:, 1:3])","8cb47a94":"print(X)","3be5bf70":"# a) Drop entire row where atleast one element is missing.\n#dataset.dropna()\n\n# b) Drop the columns where at least one element is missing.\n#dataset.dropna(axis='columns')\n\n# c) Drop the rows where all elements are missing.\n#dataset.dropna(how='all')\n\n# d) Keep only the rows with at least 2 non-NA values.\n#dataset.dropna(thresh=2)","58cc224d":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))","65c58dc4":"print(X)","b68f085d":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)","1ee186fe":"print(y)","7ff46ba9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","86c4ab98":"print(X_train)","b64e2ca9":"print(X_test)","b8335a91":"print(y_train)","b66f4d10":"print(y_test)","219d077d":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\nX_test[:, 3:] = sc.transform(X_test[:, 3:])","12a5cf2b":"print(X_train)","ea1dd93b":"print(X_test)","284549ed":"# Done to ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","ba666c5c":"pip install lazypredict","60ddc219":"from lazypredict.Supervised import LazyClassifier\nfrom sklearn.model_selection import train_test_split\n\nclf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\nmodels,predictions = clf.fit(X_train, X_test, y_train, y_test)\nmodels","b5450f72":"I am going to use **'lazypredict'** for this part as it helps build a lot of basic models without much code and helps understand which models works better without any parameter tuning. It supports supervised learning (Classification and Regression).","5e505d3a":"A dummy dataset made for the purpose of this exapmle notebook. It has four columns in total. The three independent data columns are 'Country', 'Age' and 'Salary'. The independent column is titled as 'Purchased'. This dummy dataset is about house purchases. ","0a048145":"### Lazy Classifier","990aaeb8":"## Splitting the dataset into the Training set and Test set","489fafd2":"What really happens is, if you look at row 1 in 'Country' column it states 'Spain' and in row 2 it states 'Germany'. In hot encoding it creates as many columns as the number of categories. In this case two columns and according to their exsistance they are marked on each row.\n\n**NOTE:** 0 indicates non existent while 1 indicates existent. ","d8ec4126":"## Importing the dataset","6c6a9070":"## Feature Scaling","0c7d48b6":"Now, seeing the results for different models I can choose the ones that show the most promise and build a fine tuned version of them.","bfb81a98":"## Taking care of missing data","59e7cad9":"**SimpleImputer** is a scikit-learn class which is helpful in handling the missing data in the predictive model dataset. It replaces the NaN values with a specified placeholder.\n\nIt is implemented by the use of the SimpleImputer() method which takes the following arguments :\n\n+ **missing_values:** The missing_values placeholder which has to be imputed. By default is NaN\n+ **stategy:** The data which will replace the NaN values from the dataset. The strategy argument can take the values:\n    - 'mean'(default) -- Can only be used with numeric data\n    - 'median' -- Can only be used with numeric data\n    - 'most_frequent' -- Can be used with numeric or string data \n    - 'constant' -- Can be used with numeric or string data\n+ **fill_value:** The constant value to be given to the NaN data using the constant strategy.\n\nI have provided examples with all the possible strategies.\n\nFor more information and reading up on it, click [here](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.impute.SimpleImputer.html).","abdf2675":"**What is Label Encoder ?**\n\nEncode target labels with value between 0 and n_classes-1.\n\nThis transformer should be used to encode target values, i.e. y, and not the input X.","62f678f7":"For this example, I have chosen to go with 'mean' strategy.","8c3f0a54":"Hope you enjoyed reading this and learned something new ! Feel free to provide any feedback and connect with me.\n\nThanks !\n\nPerpared by Asad Mahmood.","577f3209":"## Importing the libraries","e0f03c2e":"# Data Preprocessing and ML Modelling Template Notebook","bfcb9f0b":"For more in depth information about different pandas read functions click [here](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/io.html).","41f503ae":"## Let's see what ML Algo suits best - LazyPredict","3720aba1":"### 1) Imputing Missing Data - Simple Imputer","627e05aa":"For more examples and to read up on iloc functions, click [here](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.iloc.html).","a5fb474c":"## Dataset Intro","70e26d89":"**What is StandardScaler?**\nStandardize features by removing the mean and scaling to unit variance\n\nThe standard score of a sample x is calculated as:\n\n$$z = \\frac{(x - u)}{s}$$\n\n+ **x** is the sample\n+ **u** is the mean of the training samples or zero if with_mean=False\n+ **s** is the standard deviation of the training samples or one if with_std=False.","2edf9cee":"### 2) Deleting missing data","d0a64a3a":"**What is One Hot Encoding?**<br\/>\n\nOne hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction. For example you have a dataframe like this:\n\n| | Country   |  Salary Level  |\n|-|:---------:|:-----------:|\n| | Spain   | 2 |\n| | Germany | 1 |\n| | Germany | 1 |\n| | Spain   | 2 |\n\nAfter one hot encoding it will look like this\n\n| | Spain   | Germany  |  Salary Level    |\n|-|:---------:|:-----------:|:-----------:|\n| | 1 | 0 | 2 |\n| | 0 | 1 | 1 |\n| | 0 | 1 | 1 |\n| | 1 | 0 | 2 |","8fc15001":"**NOTE:** <br\/>\n + It only works for python version \u2265 3.6\n + It's built on top of various other libraries so if you don't have those libraries in the system,\n + If you encounter 'ModuleError' so interpret the error properly and install the required libraries.\n \nFor more information about LazyPredict, please visit [here](https:\/\/pypi.org\/project\/lazypredict\/)","40342e3d":"The dataset I am using has one column 'Country' as categorical column.","b330d181":"Deleting missing values, is not a good practice in most cases and should be avoided because it caan lead the data to become biased in some instances.","6fef83c4":"### Encoding the Dependent Variable","6c2e8d66":"----","4e4c8f87":"## Encoding categorical data","8a972a84":"### Encoding the Independent Variable","7608d371":"As seen by the printout of code cell 14, there are few missing values. There are several ways to handle this."}}