{"cell_type":{"e1193a71":"code","fc7c8b76":"code","4ca44d11":"code","93dd95dc":"code","79ec6d0b":"code","5e2f71a8":"code","dde73b31":"code","deb0c2b1":"code","39ebc055":"code","569f12f4":"code","e084da62":"code","76ff708a":"markdown","9466550d":"markdown","16fac019":"markdown","56602cda":"markdown","91926b6f":"markdown","eb66efc5":"markdown","b390af75":"markdown","aa458af6":"markdown","95ca899e":"markdown","5e3991e4":"markdown"},"source":{"e1193a71":"from __future__ import print_function, division\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport torch\nimport glob\nimport re\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport os\nimport copy\nimport cv2 \nimport torch.nn.functional as F\n\nfrom PIL import Image\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom torchvision import datasets, models, transforms\nfrom torch.autograd import Variable\nfrom torch.utils import data\nfrom IPython.display import clear_output\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.ion()   \n\nimport os\nprint(os.listdir(\"..\/input\"))","fc7c8b76":"train = glob.glob(\"..\/input\/dataset\/train\/*.jpeg\")\ntest = glob.glob(\"..\/input\/dataset\/test\/*.jpeg\")\n\nfrom random import shuffle\nshuffle(train)\n\ntrainset_size = 75000\ncross_val = train[trainset_size:]\ntrain = train[:trainset_size]\n\n# CUDA for PyTorch\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\ntorch.backends.cudnn.benchmark = True\n# Device configuration","4ca44d11":"def blockshaped(arr, nrows, ncols):\n    h, w = arr.shape\n    return (arr.reshape(h\/\/nrows, nrows, -1, ncols)\n               .swapaxes(1,2)\n               .reshape(-1, nrows, ncols))\n\ndef fen_from_filename(filename):\n  return os.path.splitext(os.path.basename(filename))[0]\n\ndef get_all_labels(list_filename):\n    labels = []\n    for i in range(len(list_filename)):\n        labels.append(fen_from_filename(list_filename[i]))\n    return labels","93dd95dc":"def img_processing(img):\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img_shrink = cv2.resize(img_gray, (200, 200))\n    box_list = blockshaped(img_shrink, 25, 25)\n    flatten_list = box_list.reshape(box_list.shape[0], -1)\n    return flatten_list\n\ndef fen_to_piece_label(fen):\n    y = []\n    for i in fen:\n        if(str.isdigit(i)):\n            d = int(i, 10)\n            y.extend(np.zeros(d, np.int16).tolist())\n        elif(str.isalpha(i)):\n            case = 0\n            if(str.isupper(i)):\n                case = 6\n                i = str.lower(i)\n                \n            if(i == 'k'):\n                case = case + 1\n            elif(i == 'q'):\n                case = case + 2               \n            elif(i == 'r'):\n                case = case + 3\n            elif(i == 'n'):\n                case = case + 4\n            elif(i == 'b'):\n                case = case + 5\n            elif(i == 'p'):\n                case = case + 6\n            y.append(case)\n    return y\n\n\ndef lb_to_fen(label):\n    s = ''\n    count = 0\n    for i in range(len(label)):\n        if(i%8 == 0):\n            if(count !=0):\n                s = s + str(count)\n                count =0\n            s = s + '-'\n        if(label[i]==0):\n            count = count+1\n        else:\n            if(count !=0):\n                s = s + str(count)\n                count =0\n            if(label[i] == 1):\n                s = s + 'k'\n            elif(label[i] == 2):\n                s = s + 'q'\n            elif(label[i] == 3):\n                s = s + 'r'\n            elif(label[i] == 4):\n                s = s + 'n'\n            elif(label[i] == 5):\n                s = s + 'b'\n            elif(label[i] == 6):\n                s = s + 'p'\n            elif(label[i] == 7):\n                s = s + 'K'\n            elif(label[i] == 8):\n                s = s + 'Q'\n            elif(label[i] == 9):\n                s = s + 'R'\n            elif(label[i] == 10):\n                s = s + 'N'\n            elif(label[i] == 11):\n                s = s + 'B'\n            elif(label[i] == 12):\n                s = s + 'P'\n            else:\n                print('Invalid Error#######################################')\n    if(count != 0):\n        s = s+ str(count)\n    return s[1:]\n\ndef lbs_to_fen(label):\n    fen = []\n    for grp_no in range(0, int(len(label)\/ 64)):\n        start_index = grp_no*64\n        fen.append(lb_to_fen(label[start_index : start_index +64]))\n    return fen   \n","79ec6d0b":"\ndef decoded_board_with_label(board):\n    X = []\n    Y = []\n    X.extend(img_processing(cv2.imread(board)))\n    Y.extend(fen_to_piece_label(fen_from_filename(board)))\n    return X, Y\n\n\ndef  get_batch(dataset, batch_size, start_index):\n    x = []\n    y = []\n    for j in range(0, batch_size):\n        temp_x, temp_y = decoded_board_with_label(dataset[start_index+ j])\n        x.extend(temp_x)\n        y.extend(temp_y)\n    x = torch.FloatTensor(x)\n    y = torch.FloatTensor(y)\n    return x, y","5e2f71a8":"\n###### giving metrics to neural net #####\nn_in, n_out = 625, 13\nh1 = 60\nh2 = 50\nh3 = 40\nh4 = 30\nh5 = 20\nbatch_size = 5\nlearning_rate = 1e-4\nmomentum = 0.9\nweight_decay = 0.0000001\nepochs  = 5\n###############################################","dde73b31":"\n\n\nclass NeuralNet(nn.Module):\n    def __init__(self, n_in, h1, h2, h3, h4, h5, n_out):\n        super(NeuralNet, self).__init__()\n        self.f1 = nn.Linear(n_in, h1) \n        self.f2 = nn.Linear(h1, h2) \n        self.f3 = nn.Linear(h2, h3)\n        self.f4 = nn.Linear(h3, h4)\n        self.f5 = nn.Linear(h4, h5)\n        self.f6 = nn.Linear(h5, n_out)\n    \n    def forward(self, x):\n        x = F.relu(self.f1(x))\n        x = F.relu(self.f2(x))\n        x = F.relu(self.f3(x))\n        x = F.relu(self.f4(x))\n        x = F.relu(self.f5(x))\n        x = self.f6(x)        \n        return F.log_softmax(x)\n\n","deb0c2b1":"# CREATING THE NEURAL NETWORK\nmodel = NeuralNet(n_in, h1, h2, h3, h4, h5, n_out).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum,weight_decay= weight_decay)\n\nfor epoch in range(epochs):\n    batch_count = int(len(train)\/ batch_size)\n    for i in range(0, batch_count):  \n        \n        x_batch, y_batch = get_batch(train, batch_size, batch_size*i)\n        \n        # Loading batch to the GPU\n        x_batch = x_batch.to(device)\n        y_batch = y_batch.type(torch.LongTensor).to(device)\n        \n        # Forward pass\n        outputs = model(x_batch)\n        loss = criterion(outputs, y_batch)\n        if(i%100 ==0):\n            print('epoch: ', epoch, 'group no : ', i,'\/',batch_count,' loss: ', loss.data.mean())\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        ","39ebc055":"def dataset_accuracy_finder(dataset, batch_size):\n\n    # Getting all the actual Test label \n    actual_FEN = get_all_labels(dataset)\n\n    # To store the precdicted labels\n    \n    Correct_lbs = 0\n    y_actual = []\n    y_pred = []\n    batch_count = int(len(dataset)\/ batch_size)\n    \n    for i in range(0, batch_count):\n            x_batch, y_batch = get_batch(dataset, batch_size, batch_size*i)\n            y_actual.extend(y_batch.numpy().tolist())\n            \n            # Loading Features to the GPU\n            x_batch = x_batch.to(device)\n        \n            # Predicting on the model\n            y_batch_pred = model(x_batch)\n            y_batch_pred = y_batch_pred.view(len(y_batch_pred), -1).argmax(1).cpu().numpy().astype(np.int32).tolist()\n            y_pred.extend(y_batch_pred)\n\n    y_actual = np.array(y_actual)\n    y_pred = np.array(y_pred)\n    Correct_lbs = np.count_nonzero(y_actual == y_pred)\n    \n    \n    pred_FEN = lbs_to_fen(y_pred)\n    \n    # Calculating the real Test Set Accuracy\n    Correct_fen = 0\n    for i in range(0, len(actual_FEN)):\n        if(pred_FEN[i] == actual_FEN[i]):\n            Correct_fen = Correct_fen + 1\n    return Correct_lbs\/(len(y_pred)), Correct_fen\/len(actual_FEN),  \n","569f12f4":"train_err, train_actual_err = dataset_accuracy_finder(train, 500)\ncross_val_err, cross_val_actual_err = dataset_accuracy_finder(cross_val, 500)\ntest_err, test_actual_err = dataset_accuracy_finder(test, 500)","e084da62":"print('============================================================================================')\nprint('    Dataset                   (  Label   )                  (  FEN code  )    ')\nprint('    Train                      ',train_err, '                ' , train_actual_err)\nprint('    DEV                        ',cross_val_err, '              ' , cross_val_actual_err)\nprint('    Test                       ',test_err, '                   ' , test_actual_err)\n","76ff708a":"**GETTING THE TRAIN AND TEST SET, SHUFFLING THE TRAIN SET, CREATING TRAINING SET AND DEVLOPMENT SET, INITIALIZING CUDA, **","9466550d":"**DETAILS ON THE FUNCTIONS**\n\n    **img_processing(img)**\n            Given a RGB image file location with 3 channels this will convert into single channel(grayscale) then shrinks image to (200, 200), cuts the image , and then      flattens the 2d subimage to single image\n            \n    **fen_to_piece_label(fen)**\n            given a FEN code of a board it return enumerates labels i.e 64 labels\n            \n    **lb_to_fen(label)**\n        given 64 labels lb_to_fen returns label into a string of FEN code\n    \n    **lbs_to_fen(label)**\n        given 64 X N labels lbs_to_fen changes return list of FEN codes of length N.","16fac019":"**FUNCTION TO RETURN DATASET ACCURACY **","56602cda":"**DEFINING THE NEURAL NETWORK **","91926b6f":"**DETAILS ON THE FUNCTIONS**\n\n\n    **blockshaped(arr, nrows, ncols)**\n        given a 2d numpy array as arr this fuction will cut the array into sub array with shape (nrows, ncols)\n        \n        \n    **fen_from_filename(filename)**\n        the filename of each image contains it's solution i.e. the real fen code it extracts it.**\n        \n        \n    **get_all_labels(list_filename)**\n        al 1d list of file names get_all_labels return a list of the actual FEN code list","eb66efc5":"**DETAILS ON THE FUNCTIONS**\n    \n    **decoded_board_with_label(board)\n        given a board address , it reads the file and return image matrix (after processing) and its labels\n        \n    ** get_batch(dataset, batch_size, start_index) **\n        get_batch returns the image matrix(after processing) and its label in group of size batch_size starting form start_index in dataset","b390af75":"**Calculating label accuracy , FEN code generation accuracy of each train, test, cross_val sets**","aa458af6":"**MAKING THE MODEL AND TRAINING IT**","95ca899e":"**IMPORTING THE LIBRARIES**","5e3991e4":"**MODEL TRAINING PARAMETERS**"}}