{"cell_type":{"91061b76":"code","d2580fee":"code","d0aec341":"code","94e9381b":"code","4f6d39c6":"code","b9923f59":"code","a74d19ca":"code","d4241008":"code","75ed0622":"code","c443015f":"code","ed2f9001":"code","095ccbbf":"code","6eda4aa7":"code","23cee331":"markdown","3de03788":"markdown","4cb63cd5":"markdown","e1ba1ff3":"markdown","6d49075c":"markdown","ab82ceb2":"markdown","57426260":"markdown","485280f2":"markdown","285600bf":"markdown","0ab5b9e5":"markdown","c6673f56":"markdown","3a25d04a":"markdown","b8c05787":"markdown","5a6edc65":"markdown","65f06bf7":"markdown"},"source":{"91061b76":"!pip install imutils","d2580fee":"import cv2\nimport os, glob\n\nimport numpy as np\nimport seaborn as sns\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport sklearn.metrics as metrics\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16, ResNet101, Xception\nfrom tensorflow.keras.layers import Input, Dense, Flatten, AveragePooling2D, Dropout, BatchNormalization, Conv2D","d0aec341":"LR = 0.001\nEPOCHS = 20\nBATCH_SIZE = 32\nCOVID_LEN = 218\nINP_SIZE = (224,224,3)","94e9381b":"def create_data(dir_name):\n    temp_data = []\n    img_list = glob.glob('..\/' + dir_name + '\/*')\n    for img in img_list[:COVID_LEN]:\n        image = cv2.imread(img)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (224, 224))\n        temp_data.append(image)\n    return temp_data\n\ndata = []\nlabels = []\n\ncovid_dir = 'input\/covid19-radiography-database\/COVID-19 Radiography Database\/COVID-19'\nnormal_dir = 'input\/covid19-radiography-database\/COVID-19 Radiography Database\/NORMAL'\npneumonia_dir = 'input\/covid19-radiography-database\/COVID-19 Radiography Database\/Viral Pneumonia'\n\ndata.extend(create_data(covid_dir))\ndata.extend(create_data(normal_dir))\ndata.extend(create_data(pneumonia_dir))\n\nlabels.extend([1] * COVID_LEN)\nlabels.extend([0]*2*COVID_LEN)\n\ndata = np.array(data)\/255.0\nlabels = np.array(labels)\n\nprint(data.shape)\nprint(labels.shape)","4f6d39c6":"lb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)\n\n(x_train, x_test, y_train, y_test) = train_test_split(\n    data,\n    labels,\n    test_size=0.20,\n    stratify=labels,\n    random_state=42\n)\ntrainAug = ImageDataGenerator(\n    rotation_range=15,\n    fill_mode=\"nearest\"\n)\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","b9923f59":"def generate_custom_model():\n    \n    model = Sequential()\n    model.add(BatchNormalization(input_shape=INP_SIZE))\n    model.add(Conv2D(16, kernel_size=(3,3), padding='same', activation='relu'))\n    model.add(Conv2D(16, kernel_size=(3,3), padding='same', activation='relu'))\n    model.add(AveragePooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.35))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.35))\n    model.add(Dense(2, activation='softmax'))\n    \n    return model\n\ndef generate_pretrained_model(model_name):\n    if model_name == 'VGG16':\n        model = VGG16(\n            include_top = False,\n            weights = 'imagenet',\n            input_tensor = Input(shape=INP_SIZE)\n        )\n    elif model_name == 'ResNet101':\n        model = ResNet101(\n            include_top = False,\n            weights = 'imagenet',\n            input_tensor = Input(shape=INP_SIZE)\n        )\n    elif model_name == 'Xception':\n        model = Xception(\n            include_top = False,\n            weights = 'imagenet',\n            input_tensor = Input(shape=INP_SIZE)\n        )\n    else:\n        model = None\n        print('Invalid Choice!')\n    \n    return model","a74d19ca":"def fit_model(model, model_name):\n    optim = Adam(lr = LR, decay = LR\/EPOCHS)\n    \n    if model_name == 'Custom':\n        model.compile(loss=\"categorical_crossentropy\", optimizer=optim, metrics=[\"accuracy\"])\n        history = model.fit_generator(\n            trainAug.flow(x_train, y_train, batch_size = BATCH_SIZE),\n            steps_per_epoch = len(x_train) \/\/ BATCH_SIZE,\n            validation_data = (x_test, y_test),\n            validation_steps = len(x_test) \/\/ BATCH_SIZE,\n            epochs = EPOCHS\n        )\n    else :\n        for layer in model.layers:\n            layer.trainable = False\n        # top layer for shaping output    \n        headModel = model.output\n        headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n        headModel = Flatten(name=\"flatten\")(headModel)\n        headModel = Dense(64, activation=\"relu\")(headModel)\n        headModel = Dropout(0.5)(headModel)\n        headModel = Dense(2, activation=\"softmax\")(headModel)\n        model = Model(inputs=model.input, outputs=headModel)\n        model.compile(loss=\"categorical_crossentropy\", optimizer=optim, metrics=[\"accuracy\"])\n        \n        history = model.fit_generator(\n            trainAug.flow(x_train, y_train, batch_size = BATCH_SIZE),\n            steps_per_epoch = len(x_train) \/\/ BATCH_SIZE,\n            validation_data = (x_test, y_test),\n            validation_steps = len(x_test) \/\/ BATCH_SIZE,\n            epochs = EPOCHS\n        )\n    \n    return history, model","d4241008":"def display_history(history_):\n    fig, ax = plt.subplots(1,2, figsize=(12, 3))\n    ax[0].plot(history_.history['loss'], color='b', label=\"training_loss\")\n    ax[0].plot(history_.history['val_loss'], color='r', label=\"validation_loss\",axes =ax[0])\n    legend = ax[0].legend(loc='best', shadow=True)\n\n    ax[1].plot(history_.history['accuracy'], color='b', label=\"training_accuracy\")\n    ax[1].plot(history_.history['val_accuracy'], color='r',label=\"validation_accuracy\")\n    legend = ax[1].legend(loc='best', shadow=True)\n\ndef plot_metrices(model_):\n    \n    plt.figure()\n    ax = plt.subplot()\n    ax.set_title('Confusion Matrix')\n    \n    pred = model_.predict(x_test, batch_size = BATCH_SIZE)\n    pred = np.argmax(pred, axis = 1)\n    cm = confusion_matrix(y_test.argmax(axis = 1), pred)\n    classes=['normal', 'covid19']\n    sns.heatmap(cm, annot = True, xticklabels = classes, yticklabels = classes, cmap = 'Reds')\n\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.show\n    \n    print(classification_report(y_test.argmax(axis = 1), pred))\n    total = sum(sum(cm))\n    acc = (cm[0, 0] + cm[1, 1]) \/ total\n    sensitivity = cm[0, 0] \/ (cm[0, 0] + cm[0, 1])\n    specificity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\n    \n    print(\"ACC: {:.4f}\".format(acc))\n    print(\"Sensitivity: {:.4f}\".format(sensitivity))\n    print(\"Specificity: {:.4f}\".format(specificity))","75ed0622":"custom_mod = generate_custom_model()\nvgg_mod = generate_pretrained_model('VGG16')\nresnet_mod = generate_pretrained_model('ResNet101')\nxception_mod = generate_pretrained_model('Xception')","c443015f":"(cus_his, custom_mod) = fit_model(custom_mod, 'Custom')\ndisplay_history(cus_his)\nplot_metrices(custom_mod)\ncustom_mod.save('custom.h5')","ed2f9001":"(vgg_his, vgg_mod)= fit_model(vgg_mod, 'VGG16')\ndisplay_history(vgg_his)\nplot_metrices(vgg_mod)\nvgg_mod.save('vgg.h5')","095ccbbf":"res_his, resnet_mod = fit_model(resnet_mod, 'ResNet101')\ndisplay_history(res_his)\nplot_metrices(resnet_mod)\nresnet_mod.save('resnet.h5')","6eda4aa7":"xcep_his, xception_mod = fit_model(xception_mod, 'Xception')\ndisplay_history(xcep_his)\nplot_metrices(xception_mod)\nxception_mod.save('xception.h5')","23cee331":"**ResNet101 Model**","3de03788":"**Fitting model according to input. Various parameters here can be changed for better model tuning.**","4cb63cd5":"# Function Calls","e1ba1ff3":"**Custom Model**","6d49075c":"# Introduction\nCOVID-19 is one of the biggest issues on the planet right now. With thousands of deaths worldwide, the pandemic has affected the world's economy and lifestyle very deeply. One of the major causes of death by Corona Virus is the lack of testing in time. In many developing countries, testing is a far cry for the mass, and therefore new measurements for detection of COVID-19 are becoming essential. In this notebook, the detection of COVID-19 has been attempted using Chest X-Ray radiography images. Among the 4 CNN models used here, 3 are popular imagenet trained models; VGG16, ResNet101 and Xception, and a simple CNN model. The work here is heavily inspired by the amazing tutorial of [Adrian Rosebrock](https:\/\/www.linkedin.com\/in\/adrian-rosebrock-59b8732a) at [Pyimagesearch](https:\/\/www.pyimagesearch.com\/2020\/03\/16\/detecting-covid-19-in-x-ray-images-with-keras-tensorflow-and-deep-learning\/). The dataset primarily used is the [COVID-19 Radiography Database](https:\/\/www.kaggle.com\/tawsifurrahman\/covid19-radiography-database) which can be found in Kaggle. The plan is to make a continuously upgradable framework to integrate new data published on this topic every week. **I am an absolute beginner in the world of data science and machine learning. So expect this work to be vastly immature and incomplete in many regards !**\n\nLastly, to quote the pyimagesearch tutorial,\n> It\u2019s possible that this model is learning patterns that are not relevant to COVID-19, and instead are just variations between the two data splits (i.e., positive versus negative COVID-19 diagnosis). It would take a trained medical professional and rigorous testing to validate the results coming out of our COVID-19 detector. Future (and better) COVID-19 detectors will be multi-modal. Right now we are using only image data (i.e., X-rays) \u2014 better automatic COVID-19 detectors should leverage multiple data sources not limited to just images, including patient vitals, population density, geographical location, etc. Image data by itself is typically not sufficient for these types of applications. For these reasons, it must once again be stressed that this notebook is meant for educational purposes only \u2014 it is not meant to be a robust COVID-19 detector. If you believe that yourself or a loved one has COVID-19, you should follow the protocols outlined by the Center for Disease Control (CDC), World Health Organization (WHO), or local country, state, or jurisdiction.","ab82ceb2":"# Model Generation and Fitting","57426260":"**VGG16 Model**","485280f2":"# Plotting Methods","285600bf":"**Xception Model**","0ab5b9e5":"# Data Processing","c6673f56":"# Imports","3a25d04a":"**Functions for generating Custom and Pretrained models.**","b8c05787":"**Image to data list transformation. Directories needs to changed for different input setup.**","5a6edc65":"**Genereate models**","65f06bf7":"**Setting Hyperparameter values to be used in CNN. These can be changed to tune the networks performance.**"}}