{"cell_type":{"0240e753":"code","80d49a78":"code","47383785":"code","5bbad8e1":"code","0b6ce772":"code","0b8b8ef4":"code","7af9a73e":"markdown","9d8b8360":"markdown","ad0a6f3c":"markdown","0d08b4dd":"markdown","347469ee":"markdown","da33ec0a":"markdown"},"source":{"0240e753":"\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\nfrom tensorflow.keras.optimizers import SGD\nimport math\nfrom sklearn.metrics import mean_squared_error\n\n# Some functions to help out with\ndef plot_predictions(test,predicted,cur):\n    plt.plot(test, color='red',label='Actual Stock Price')\n    plt.plot(predicted, color='blue',label='Predicted Stock Price')\n    plt.plot(cur, color='orange',label='Current Stock Price')\n    plt.title('Stock Price Prediction')\n    plt.xlabel('Time')\n    plt.ylabel('Stock Price')\n    plt.legend()\n    plt.show()\n\ndef return_rmse(test,predicted):\n    rmse = math.sqrt(mean_squared_error(test, predicted))\n    print(\"The root mean squared error is {}.\".format(rmse))\n    ","80d49a78":"import pandas as pd\ndataset = pd.read_csv(\"..\/input\/msft.csv\",index_col='Dates', parse_dates=['Dates'], dayfirst =True)\n\ndataset['PREDICT'] = dataset['PX_LAST'].shift(-10) #trying to predict 10 days ahead, can change this to any days.\ndf=dataset.dropna()\ndf=df.iloc[:][:]\nprint(df.head())\nprint(df.describe())\nsize_data = len(df)\n#split data_set\ntrain_ratio=10\nsize_train = int(size_data*(1-train_ratio\/100))\nsize_test = int(size_data*(train_ratio\/100))\n\nprint('size of dataset:' , size_data)\nprint('size_train:', size_train)\nprint('size_train:', size_test)\n\n","47383785":"\n# Checking for missing values\n# select column\n#Dates\tPX_LAST\tPX_VOLUME\tVOLATILITY_90D\tBEST_ANALYST_RATING\n\nselected_column_list = ['PX_LAST'\n                        #,'VOLATILITY_90D'\n                        ,'BEST_ANALYST_RATING'\n                        ,'PREDICT']\n\nnum_fields = len(selected_column_list)\nnum_training_fields = num_fields -1\n\ndf = df[selected_column_list]\n\ndf_training_set = df[selected_column_list][:size_train]\ndf_test_set = df[selected_column_list][size_train:]\n\ntraining_set = df_training_set.values\ntest_set     = df_test_set.values\n\nsize_train = len(df_training_set)\nsize_test  = len(df_test_set)","5bbad8e1":"from pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\nplt.clf()\nplt.plot(df_training_set['PX_LAST'],color='red') \nplt.plot(df_test_set[\"PX_LAST\"],color='blue')\n\nplt.legend(['Training set','Test set'])\nplt.title('MSFT stock price')\nplt.show()\n\n# Scaling the training set\nsc = MinMaxScaler(feature_range=(0,1))\n#fit the entire dataset\nsc.fit(df) \n\ntraining_set_scaled = sc.transform(training_set)\ntest_set_scaled = sc.transform(test_set)\n","0b6ce772":"X_train = []\ny_train = []\nfor i in range(60,len(training_set)):\n    X_train.append(training_set_scaled[i-60:i,:-1])\n    y_train.append(training_set_scaled[i,-1]) # last column is actual price to predict\nX_train, y_train = np.array(X_train), np.array(y_train)\n\n# Reshaping X_train for efficient modelling\nX_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],num_training_fields))\n\n\n# The LSTM architecture\nregressor = Sequential()\n# First LSTM layer with Dropout regularisation\nregressor.add(LSTM(units=20, return_sequences=True, input_shape=(X_train.shape[1],num_training_fields)))\nregressor.add(Dropout(0.2))\n# Second LSTM layer\nregressor.add(LSTM(units=40, return_sequences=True))\nregressor.add(Dropout(0.2))\n# Third LSTM layer\nregressor.add(LSTM(units=40, return_sequences=True))\nregressor.add(Dropout(0.2))\n# Fourth LSTM layer\nregressor.add(LSTM(units=20))\nregressor.add(Dropout(0.2))\n# The output layer\nregressor.add(Dense(units=1))\n\n# Compiling the RNN\nregressor.compile(optimizer='rmsprop',loss='mean_squared_error')\n# Fitting to the training set\nregressor.fit(X_train,y_train,epochs=10,batch_size=64)\n\n# Now to get the test set ready in a similar way as the training set.\n# The following has been done so forst 60 entires of test set have 60 previous values which is impossible to get unless we take the whole \n# 'High' attribute data for processing\n#df = pd.concat((df_training_set, df_test_set),axis=0)\n\n\ninputs = df.iloc[:][len(training_set)-60:].values\n\ninputs = inputs.reshape(-1,num_fields)\ninputs  = sc.transform(inputs)\n","0b8b8ef4":"# Preparing X_test and predicting the prices\nX_test = []\ny_test = []\nfor i in range(60,len(inputs)):\n    X_test.append(inputs[i-60:i,:-1])\n    y_test.append(inputs[i,-1])\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\nX_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],num_training_fields))\n\npredicted_stock_price_sc = regressor.predict(X_test)\n\n#compute inverse scale\n# delete last column\npredict_test_set_scaled = test_set_scaled[:,:-1]\n#add last column with predicted value\npredict_test_set_scaled = np.concatenate((predict_test_set_scaled,predicted_stock_price_sc), axis=1 )\npredict_test_set = sc.inverse_transform(predict_test_set_scaled)\n\n\n\n# Visualizing the results for LSTM\n#test\n#actual\n#curent\n\nplot_predictions(test_set[:,-1],predict_test_set[:,-1],test_set[:,0])\n\n# Evaluating our model\nreturn_rmse(test_set[:,-1],predict_test_set[:,-1])","7af9a73e":"Next, we create a new field which we try to predict by using the dataframe.shift() function. In this case, we are trying to predict the price in 10 days time. Few free to change the parameters later on.\n\nWe create a new last column 'PREDICT' which is the parameter we want to predict. In this case, it is the price in 10 days time, using the .shift method.","9d8b8360":"We need the stock data for the AI engeine. I have downloaded some data from the Bloomberg terminal. There are manh other sources of stock data which you can download like Yahoo Finance. In this .csv (comma separate, can open with Excel) file, we pick a few parameters like Prices, and Analyst Target Price.\nIf you sucessfully loaded the data file, the following codes will display a summary of the data file.","ad0a6f3c":"Next we have to split to data into 2 sets. One set for training and the rests for testing. The percentage is defined by . \n10 means that 10% of data set will be used for testing. After excuting the code below, you will see the graph of the data that are used for training and testing in different colors.","0d08b4dd":"We then plot out the test data, and predicted data. \nAt any time, you have the current price, predicted price, and the actual price in 10 days. As you can see, the system is not accurate. Try using more parameters which you think has a influence of the predict share price.\n\nAny item which has not been added is to monitor the errors, and simulate a particular tradiing strategy and see if we can make money from it. E.g. to buy a particular amount of shares if the predicted price is more than 10% of current price.\n\nSome models try to precict the 1 day price, but that is not very meaningful to be used in an investment strategy.\n","347469ee":"Next, we need to pre-process the data by normaling the parameters. \n","da33ec0a":"*by Alex Koo (2019)*\n*Alex Koo is a director at Phillip Private Equity*\n\nThis is a simple example to demonstrate the concept of using LSMT (a type of AI model) to predict share prices. The example is relatively simple. LSTM is suitable for time series data like in stock trading. For example, when we look at today's share prices, we not only look at the current PE, but also how the PE of the stock has changed over time. In another word, we need to remember the behavious of its PE over a period of time (memory), not just a static view of today's PE.\n\nFor a start, we load in all the libraries that are required. As you can see, these are Open-Source libraries, which means you do not have to be an expert scientist to use AI. The complex mathematics are solved by smart and very intelligence people working round the clock. Today, AI application programmers do not have to do the heavy lifting. The libraries, whether they are paid, free or trained, can be used like tools to solve real life problems. As long as your know how to use the tools. Much of the current advancement in AI is Deep Learning. The mathematics involved are complexed, but you only need to know how to use the tools in order to solve real life problems. Analogy is like electricity. Thomas Edison invented electricity. The major developments happen when engineers start to harness the power of electricity and build businesses around it to solve real life solutions.\n"}}