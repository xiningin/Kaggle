{"cell_type":{"2290d8c2":"code","a44b1f7b":"code","56f9f3df":"code","7eba42c6":"code","95748db1":"code","5cf13f5d":"code","01eb935b":"code","6fbc4093":"code","638d4256":"code","674f34f8":"code","80b1a67b":"code","d5773a1a":"code","cf0af6ca":"markdown","95983aab":"markdown","5caec70d":"markdown","4ed14b34":"markdown","7d975c2a":"markdown","8ee6bdab":"markdown"},"source":{"2290d8c2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# Any results you write to the current directory are saved as output.","a44b1f7b":"dataBottle = pd.read_csv('..\/input\/calcofi\/bottle.csv',encoding='latin1')","56f9f3df":"salinity = dataBottle[['Salnty']]\ntemperature = dataBottle[['T_degC']]","7eba42c6":"from sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()\nsalinityLast = my_imputer.fit_transform(salinity)\ntemperatureLast = my_imputer.fit_transform(temperature)\n# Convert structured or record ndarray to DataFrame\ntempFrame = pd.DataFrame.from_records(temperatureLast, index=None, exclude=None, columns=None, coerce_float=False, nrows=None)\nsalinityFrame = pd.DataFrame.from_records(salinityLast, index=None, exclude=None, columns=None, coerce_float=False, nrows=None)","95748db1":"plt.scatter(salinityLast, temperatureLast, edgecolors='r')\nplt.xlabel('salinity')\nplt.ylabel('temperature')\nplt.show()","5cf13f5d":"# salinityFrame.corr(tempFrame)","01eb935b":"from sklearn.model_selection  import train_test_split","6fbc4093":"x_train, x_test, y_train, y_test = train_test_split(salinityLast,temperatureLast,test_size=0.33,random_state=0)","638d4256":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()","674f34f8":"lr.fit(x_train,y_train)","80b1a67b":"# By giving the test values of Salinity Data, predictions will be made for temperature.\nprediction = lr.predict(x_test)","d5773a1a":"# We're sorting the data by their indexes to see the graphs more clear.\n# x_train = x_train.sort_index()\n# y_train = y_train.sort_index()\nplt.plot(x_train,y_train)\nplt.plot(x_test,prediction)\nplt.rcParams['agg.path.chunksize'] = 10000\nplt.show()","cf0af6ca":"Imputation fills in the missing value with some number. The imputed value won't be exactly right in most cases, but it usually gives more accurate models than dropping the column entirely.","95983aab":"* Now we're adding the module that let us divide the data into test and training processes\n* **Cross validation** allows us to compare different machine learning methods and get a sense of how well they will work in practice.","5caec70d":"**CalCOFI**: Over 60 years of oceanographic data: *Is there a relationship between water salinity & water temperature? Can you predict the water temperature based on salinity?*","4ed14b34":"The default behavior fills in the mean value for imputation. Statisticians have researched more complex strategies, but those complex strategies typically give no benefit once you plug the results into sophisticated machine learning models.\n\nOne (of many) nice things about Imputation is that it can be included in a scikit-learn Pipeline. Pipelines simplify model building, model validation and model deployment.","7d975c2a":"We're giving the training values to make the machine learn","8ee6bdab":"* **T_degCWater** : temperature in degree Celsius\n* **Salnty** : Salinity in g of salt per kg of water (g\/kg)"}}