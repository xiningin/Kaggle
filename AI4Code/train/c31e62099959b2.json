{"cell_type":{"d96eb192":"code","c67b23ed":"code","c261bac5":"code","2c3dc271":"code","d012a169":"code","30235f59":"code","02f378ac":"code","506713c1":"code","85321533":"code","28874ce3":"code","bff468ec":"code","62369f10":"code","10de7b8d":"code","14378a79":"code","dbf2f0ee":"code","964b46bb":"code","73a381ed":"code","e2c4f7d3":"code","1864a787":"code","7a5a36dd":"code","cf7d4646":"code","c76dd100":"code","5c64dc1f":"code","1055e646":"code","272b0f34":"code","e321c621":"code","b5d6d046":"code","eeb52783":"code","bb4c18de":"code","4ce70639":"code","405af438":"code","b1dd86b3":"code","e75c4bf5":"code","ce53e3a8":"code","ae524548":"code","e43a3059":"code","e9be6f84":"code","24aced90":"code","eb48e46b":"code","977ec5b2":"code","58103b04":"code","5090fbd3":"code","768bdebf":"code","40af676c":"code","67d2da99":"code","6201d542":"code","a9bff144":"code","80054d32":"code","f1dd80b7":"code","76782bd7":"code","eba18e98":"code","0f3c84e9":"code","95be7f36":"code","c693926b":"code","437e8699":"code","0eda2093":"code","c8fd471e":"code","e3e1968c":"code","5dd7742f":"markdown","eebbc9fd":"markdown","8c5824d3":"markdown","b6bd2482":"markdown","c6b0fc10":"markdown","5d9b4715":"markdown","2817a8ac":"markdown","a8c88ade":"markdown","b0217b3c":"markdown","ae02f558":"markdown","1e847cb6":"markdown","be6e556d":"markdown","75ca3ae1":"markdown","e9866173":"markdown","26c83b64":"markdown","c85a5d8a":"markdown","8483112c":"markdown","d07ac532":"markdown","6b8af866":"markdown","27ec0611":"markdown","bfc1482d":"markdown","a13630f4":"markdown","1a42eee3":"markdown","bcd1276e":"markdown","cae896ec":"markdown","f8a8774f":"markdown","3997a3ed":"markdown","fa4ef85e":"markdown","59963e93":"markdown","1381ec53":"markdown","5dffdb86":"markdown","e216aeaf":"markdown"},"source":{"d96eb192":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","c67b23ed":"df=pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv')\ndf.head()","c261bac5":"df.isna().any()","2c3dc271":"\ng=sns.lmplot('GRE Score','Chance of Admit ',data=df,order=1,line_kws={'color':'red','linewidth':2.5},\n           height=5,aspect=2,scatter_kws={'s':50,'alpha':0.4})\nplt.title('GRE score Vs Admission chances',size=25)\n\nplt.axhline(0.8,color='black',alpha=0.2)\nplt.axvline(324,color='black',alpha=0.2)\nplt.xticks(np.arange(280,365,5))","d012a169":"plt.figure(figsize=(10,8))\ng=sns.distplot(df['GRE Score'],label='GRE scores')\nplt.title('GRE Score distribution \\n Median:{0:.1f} \\n Mean:{1:.1f}'.format(df['GRE Score'].median(),\n                                                                            df['GRE Score'].mean()),size=25)\nl1=plt.axvline(df['GRE Score'].median(),color='black',label='Median score')\nplt.legend()","30235f59":"plt.figure(figsize=(10,8))\ng=sns.distplot(df['TOEFL Score'],label='TOEFL scores',color='green')\nplt.title('TOEFL Score distribution \\n Median:{0:.1f} \\n Mean:{1:.1f}'.format(df['TOEFL Score'].median(),\n                                                                            df['TOEFL Score'].mean()),size=25)\nl1=plt.axvline(df['TOEFL Score'].median(),color='black',label='Median score')\nplt.legend()","02f378ac":"sns.lmplot('TOEFL Score','Chance of Admit ',data=df,order=1,line_kws={'color':'red','linewidth':2.5},\n           height=5,aspect=2,scatter_kws={'s':50,'alpha':0.4})\nplt.title('TOEFL score Vs Admission chances',size=25)\n\nplt.axhline(0.8,color='black',alpha=0.2)\nplt.axvline(111,color='black',alpha=0.2)","506713c1":"\nsns.catplot('University Rating',data=df,kind='count',height=5,aspect=2)\nplt.title('Number of universities of each rating',size=23)","85321533":"df_r1=df[df['University Rating']==1]\ndf_r2=df[df['University Rating']==2]\ndf_r3=df[df['University Rating']==3]\ndf_r4=df[df['University Rating']==4]\ndf_r5=df[df['University Rating']==5]","28874ce3":"fig2=plt.figure(figsize=(10,8))\nax2=fig2.add_subplot(1,1,1)\n\nr1=ax2.scatter(df_r1['GRE Score'],df_r1['TOEFL Score'],color='green',label='Rating 1')\nr2=ax2.scatter(df_r2['GRE Score'],df_r2['TOEFL Score'],color='orange',label='Rating 2',)\nr3=ax2.scatter(df_r3['GRE Score'],df_r3['TOEFL Score'],color='cyan',label='Rating 3',)\nr4=ax2.scatter(df_r4['GRE Score'],df_r4['TOEFL Score'],color='blue',label='Rating 4',)\nr5=ax2.scatter(df_r5['GRE Score'],df_r5['TOEFL Score'],color='red',label='Rating 5',)\nplt.legend()\nplt.title('University rating wise score requirements',size=25)\nplt.xlabel('GRE Score')\nplt.ylabel('TOEFL Score')","bff468ec":"fig3=plt.figure(figsize=(20,8))\nax3=fig3.add_subplot(121)\nax4=fig3.add_subplot(122)\n\nsns.boxplot(df['CGPA'],orient='v',ax=ax3)\nsns.distplot(df['CGPA'],ax=ax4,label='CGPA',color='green')\nax4.axvline(df['CGPA'].median(),color='black',label='Median CGPA')\nax4.set_title('CGPA Distribution \\n Median: {}'.format(df['CGPA'].median()),size=25)\nplt.legend()","62369f10":"sns.lmplot('CGPA','Chance of Admit ',data=df,line_kws={'color':'red','linewidth':2.5},scatter_kws={'alpha':0.3},height=6,aspect=2)\nplt.title('CGPA Vs Chance of admit',size=25)","10de7b8d":"sns.catplot('Research','Chance of Admit ',data=df,kind='point' ,height=7,aspect=2)\nplt.title('Research Vs Chances of Admit',size=25)\nplt.xlabel('Research',size=15)\nplt.ylabel('Chances of Admit',size=15)","14378a79":"fig4=plt.figure(figsize=(14,5))\nax5=fig4.add_subplot(121)\nax6=fig4.add_subplot(122)\ng=sns.regplot('SOP','Chance of Admit ',data=df,ax=ax5)\nax5.set_title('SOP  Vs Chance of admit',size=20)\nh=sns.regplot('LOR ','Chance of Admit ',data=df,ax=ax6)\nax6.set_title('LOR Vs Chance of Admit',size=20)","dbf2f0ee":"df['Scaled CGPA']=(df['CGPA']-df['CGPA'].min())\/(df['CGPA'].max()-df['CGPA'].min())","964b46bb":"sns.set()\ndf_high=df[df['Chance of Admit ']>0.7]\ndf_low=df[df['Chance of Admit ']<0.71]\nfig5=plt.figure(figsize=(10,8))\nax7=fig5.add_subplot(1,1,1)\nax7.scatter(df_high['GRE Score'],df_high['TOEFL Score'],alpha=0.5,s=df_high['Scaled CGPA']*200,color='seagreen',label='Chance>70%')\nax7.scatter(df_low['GRE Score'],df_low['TOEFL Score'],alpha=0.5,s=df_low['Scaled CGPA']*200,color='red',label='Chance<70%')\nplt.legend(fontsize=15)\nplt.title('GRE, TOEFL, CGPA relation \\n \\n Marker size= CGPA',size=25)\nplt.xlabel('GRE Score',size=15)\nplt.ylabel('TOEFL Score',size=15)","73a381ed":"unn_cols=['Serial No.','Scaled CGPA']\nfor cols in  unn_cols:\n    df.drop(cols,axis=1,inplace=True)\ncorrelations=df.corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(correlations,annot=True,cmap='viridis')","e2c4f7d3":"df.head()","1864a787":"Y=df['Chance of Admit '] #Target\nX=df.drop('Chance of Admit ',axis=1) #Input","7a5a36dd":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nX_scaled=scaler.fit_transform(X)","cf7d4646":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_scaled,Y,test_size=0.2,shuffle=True,random_state=0)","c76dd100":"from sklearn.linear_model import LinearRegression\n","5c64dc1f":"lin_reg=LinearRegression()\nlin_reg.fit(X_train,y_train)","1055e646":"lin_reg.score(X_train,y_train)","272b0f34":"y_pred_lin=lin_reg.predict(X_test)\nlin_reg.score(X_test,y_test)","e321c621":"from sklearn.metrics import mean_squared_error\nmse_lin_reg=np.sqrt(mean_squared_error(y_pred_lin,y_test))\nprint('Root mean squared error of linear regression : {0:.2f}'.format(mse_lin_reg))","b5d6d046":"lin_reg_df=pd.DataFrame()\nlin_reg_df['Target']=y_test\nlin_reg_df['Predictions']=y_pred_lin","eeb52783":"from sklearn.linear_model import RidgeCV","bb4c18de":"Rid_reg=RidgeCV(cv=10)\nRid_reg.fit(X_train,y_train.values)","4ce70639":"Rid_reg.score(X_train,y_train)","405af438":"y_pred_rid=Rid_reg.predict(X_test)\nRid_reg.score(X_test,y_test)","b1dd86b3":"mse_rid_reg=np.sqrt(mean_squared_error(y_pred_rid,y_test))\nprint('Root mean squared error of Ridge regression : {0:.2f}'.format(mse_lin_reg))","e75c4bf5":"Rid_reg_df=pd.DataFrame()\nRid_reg_df['Target']=y_test\nRid_reg_df['Predictions']=y_pred_rid","ce53e3a8":"fig6=plt.figure(figsize=(15,5))\nax8=fig6.add_subplot(121)\nsns.regplot('Target','Predictions',data=lin_reg_df,line_kws={'color':'red'},ax=ax8)\nax9=fig6.add_subplot(122)\nsns.regplot('Target','Predictions',data=Rid_reg_df,line_kws={'color':'red'},ax=ax9,scatter_kws={'color':'green'})\n\nax8.set_title('Linear Regression results \\n  RMSE={0:.3f}'.format(mse_lin_reg),size=15)\nax9.set_title('Ridge Regression results \\n  RMSE={0:.3f}'.format(mse_rid_reg),size=15)","ae524548":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV","e43a3059":"rfr=RandomForestRegressor(random_state=0)\nparam_grid={'n_estimators':[5,7,9,10], 'max_depth':[5,7,9,10]}\ngrid_search=GridSearchCV(rfr,param_grid)","e9be6f84":"grid_result=grid_search.fit(X_train,y_train)","24aced90":"grid_result.best_params_","eb48e46b":"grid_result.score(X_train,y_train)","977ec5b2":"grid_result.score(X_test,y_test)","58103b04":"y_pred_rfr=grid_result.predict(X_test)\nrfr_df=pd.DataFrame()\nrfr_df['Target']=y_test\nrfr_df['Predictions']=y_pred_rfr\nmse_rfr=np.sqrt(mean_squared_error(y_pred_rfr,y_test))\nprint('Root mean squared error of Random Forest regression : {0:.3f}'.format(mse_rfr))","5090fbd3":"\nsns.lmplot('Target','Predictions',data=rfr_df,line_kws={'color':'orange'},height=6,aspect=2)\nplt.title('Random Forest regression \\n RMSE:{0:.4f}'.format(mse_rfr),size=15)","768bdebf":"from xgboost import XGBRegressor","40af676c":"xgb=XGBRegressor()\nxgb.fit(X_train,y_train)","67d2da99":"xgb.score(X_train,y_train)","6201d542":"xgb.score(X_test,y_test)","a9bff144":"y_pred_xgb=xgb.predict(X_test)\nxgb_df=pd.DataFrame()\nxgb_df['Target']=y_test\nxgb_df['Predictions']=y_pred_xgb\nmse_xgb=np.sqrt(mean_squared_error(y_pred_xgb,y_test))\nprint('Root mean squared error of XGB regression : {0:.4f}'.format(mse_xgb))","80054d32":"sns.lmplot('Target','Predictions',data=xgb_df,line_kws={'color':'green'},height=6,aspect=2,scatter_kws={'alpha':0.5})\nplt.title('XGBoosted regression \\n RMSE:{0:.4f}'.format(mse_xgb),size=15)","f1dd80b7":"from lightgbm import LGBMRegressor","76782bd7":"lgb=LGBMRegressor()","eba18e98":"lgb.fit(X_train,y_train)\nlgb.score(X_train,y_train)","0f3c84e9":"y_pred_lgb=lgb.predict(X_test)\nlgb.score(X_test,y_test)","95be7f36":"lgb_df=pd.DataFrame()\nlgb_df['Target']=y_test\nlgb_df['Predictions']=y_pred_lgb\nmse_lgb=np.sqrt(mean_squared_error(y_pred_lgb,y_test))\nprint('Root mean squared error of LGBM regression : {0:.4f}'.format(mse_lgb))","c693926b":"sns.lmplot('Target','Predictions',data=lgb_df,line_kws={'color':'black'},height=6,aspect=2,scatter_kws={'alpha':0.5})\nplt.title('LGBM regression \\n RMSE:{0:.4f}'.format(mse_lgb),size=15)","437e8699":"cols=df.columns[:-1]\nimp_df=pd.DataFrame(cols)\nimp_df.rename(columns={0:'Feature name'},inplace=True)","0eda2093":"rfr.fit(X_train,y_train)\nimp_df['Importance']=(rfr.feature_importances_ * 100)","c8fd471e":"imp_df.sort_values(by='Importance',inplace=True,ascending=False)\nimp_df","e3e1968c":"sns.catplot('Feature name','Importance',data=imp_df,kind='bar',height=5,aspect=2)\nplt.xticks(rotation=45,size=15)\nplt.title('Feature importances',size=25)","5dd7742f":"Great ! So, the TOEFL scores are normally distributed too considering that the mean and median are nearly identical.\n\nLet us now check how the TOEFL scores influence the chances of admissions.","eebbc9fd":"From the above barplots, we can see that most universities have a rating of 3 followed by 2 and 4. Usually, the extremities are always least. Hence, number of universities with ratings 1 and 5 are low.\n\nOur intuition says that higher rated universities would have higher GRE and TOEFL score cutoffs. Let us test this theory of ours.","8c5824d3":"Now that we are done with the data visualisation section, we can move ahead with the prediction section using Machine Learning algorithms.\n\n# 5. Machine Learning\n\nAt the very start, we need to check the correlations of the various features we have in our dataset.\n\nIn order to align our data better, let us remove all the unnecessary columns","b6bd2482":"## TOEFL Score\n\nThis score is an evaluation of the command over the English language which is necessary for English speaking nations such as United States, Canada, UK, Australia, New Zealand and a few more.\n\nLet's see how the scores are first distributed. ","c6b0fc10":"As we can clearly see, CGPA is by far the most important feature when considering university applications followed by GRE score.\n\nLet us plot these results for more readability.","5d9b4715":"As we can see see, the predictions and targets are somewhat following a linear line which is ideal. We need to try to reduce the scattering of these points about the red line. The closer these points are to the straight line, the higher accuracy we have in our results.\n\nAlso, both simple and ridge regressions have given us nearly identical results. Hence, it seems that the linear model cannot get past a RMSE of 0.06 .\n\nLet us look at some of the regressions that could yield better results.\n\nMaybe tree based ensembles such as Random Forest regressor ? Let's check it out !\n\n### Random Forest ","2817a8ac":"Unexpectedly, Random Forest regressor actually performed worse than simple linear and ridge regression.\n\nLet's check a gradient boosted algorithm such as XGBoost.\n\n### XGBoost","a8c88ade":"We see that for CGPAs lower than 8.5, the variance in the scattters are high and hence, are not following a linear correlation. However, for CGPAs higher than 8.5, there is a strong linear correlation. Hence, higher CGPAs (above 8.5) are likely (greater than 70% chance) to get an admission in their preferred university.\n\n## Research\n\nLet us now check if a research profile of a student helps him\/her to get into their preferred universities. Research would generally include things like research publications or research project involvements in their previous studies.","b0217b3c":"The MSE is decent with 0.06 . However, we shall aim to do better than this using other regression models.\n\nLet us check how the predictions look on a plot.","ae02f558":"Now, we need to separate the target label and inputs from our dataframe into X and Y variables. Let us do that.","1e847cb6":"As we can see, the red dots in the plot are the 5 star rated universities. As expected, students with high GRE Scores and TOEFL scores have mostly applied for the high rated unversities. Most of the applications are dominated by rating 3 universities in the cyan colors. These are those applicants who have scored between 300-320 in GRE and 100-110 in TOEFL. Scores higher than those have bee found in the higher rated university applications.\n\n## CGPA\n\nNow, we shall evaluate how the CGPA scores influence chances of admit. CGPA is the cumulative grade point score of a student in his undergraduate\/post graduate course.\n\nLet us draw a boxplot and a distplot to understand the distribution of the CGPA scores of all the entries.","be6e556d":"It seems even the complex tree based algorithms couldn't bring down the error.\n\nLet us check if LightGBM can give us better results.\n\n### LightGBM","75ca3ae1":"From the above plot, we have made an attempt to check the relation between TOEFL score, GRE score and CGPA value. The **CGPA value is given by the size of the markers on the scatterplot** . The bigger the marker, the higher the CGPA of the applicant.\n\nAs it can be seen, students with high GRE scores and TOEFL scores tend to have a high CGPA as well. The green markers also show that the student has a greater than 70% chance of making it to the preferred university.\n\n\nSince we are done checking all the different features, we will try to check how the various features are correlated to each other using a heatmap.","e9866173":"As we can see, the mean and median are almost the same. This means we have a normal distribution of GRE scores which is always preferred while dealing with ML regression later on.","26c83b64":"Great ! So we don't have to deal with any missing values. I guess we must really be thankful to the data contributor who took all the time in the world to give us such a clean dataset. Thanks again !\n\nAs the data is fairly clean, we can head towards the data visualisation aspect.\n\n# 4. Data Visualisation\n\nIn this section, we will be trying to plot various values of our features that could give us an idea of the important features for admission predictions.\n\n## GRE \n\nLet us check how the GRE scores influence the Admission chances.","c85a5d8a":"### Linear Regression\n\nLet's start off with a simple linear regression and check how close are we to the actual results\n","8483112c":"As we can see, there is a roughly linear relation between GRE scores and Admission chances. This is expected since students with high GRE scores tend to get their applications accepted into multiple universities of their choices which increases their chances of an admit.\n\nAs we can see from the horizontal and vertical lines here, the regression fitted red line suggests that a score of 324 gives you a 80% chance of getting your preferred admission.\n\n\nLet us check how the GRE scores are distributed in total and try to find the median and mean of the scores.","d07ac532":"Again, we see that LGBM has fared worse than the linear regression results.\n\nWe can safely say that given the data is normally distributed with no multicollinearity, Linear Regression maybe the best algorithm as was the case in our exercise here.\n\nLet us check the important features that played the most important role in our decision making.\n\n\n### Importance of features","6b8af866":"The linear regression scores are extremely average. We should be able to do better than a simple linear regression. Let's check the mean squared error of our predictions.","27ec0611":"As we can see, the TOEFL scores also have a linear correlation with admission chances. It is seen that a score of about 111 gives us a roughly 80% chance of admissions.\n\n## University Rating\n\nNext, let us see the different ratings of the universities. A higher rating would definitely be a preferred destination for many. \n\nLet us see how the different universities based on ratings stack up.","bfc1482d":"Great ! So we have scaled our data. All we gotta do now is to split our input data into train and test data. ","a13630f4":"As we can see, with higher value of SOPs and LORs, the chances of admittance also increase. Hence, high LORs and SOPs are definitely beneficial.\n\n\n## GRE scores Vs TOEFL scores Vs CGPA\n\nLet us now try to check if there are any common relations amongst GRE, TOEFL scores and CGPA. For this, we shall use scatter plots.","1a42eee3":"# 1. Acknowledgment\n\nFirst and foremost, I would like to thank Mohan S Acharya for taking the effort to obtain such meaningful data that could be very well used by budding kagglers like us. I hope to find some really insightful data visualisations that could help me and everyone here to find the important features which play an important role during college admissions.\n\n# 2. Importing the relevant data and libraries\n","bcd1276e":"\n### Ridge Regression\n\nLet us use a Ridge regression technique which is similar to simple linear regression albeit, it uses a penalty technique that penalises wrong predictions based on the residual. Lasso regression utilises a L2 regularisation which is squared in nature.\n\nIn our case, we have utilised a Ridge regression built in with cross validation. The cross validation technique prevents the overfitting issue.","cae896ec":"Let us see which CGPAs are more likely to get an admit. ","f8a8774f":"There is only a marginal improvement from Random Forest regression and still has underperformed when compared to Linear regression.","3997a3ed":"As we can see, the data provided to us is fairly clean and hence, easy to work with. We have various relevant features such as GRE , TOEFL scores, SOP, etc. The final column which is the chance of Admit is the target label that we are gonna try to predict as correctly as possible with the given features.","fa4ef85e":" As we can see from our dataframe, the various inputs have extremely different ranges of values. For example, GRE scores are triple digit values while research feature is a binary value. Hence, in order to give equal weights to each feature, it is important to apply standard scale transformation. Let us do that.\n ","59963e93":"# Conclusion\n\n* In the end, we can conclude that if the data has a good normal distribution, even simple algorithms like Linear Regressions can give us the best results.\n\n* In our study, we found that in order to increase the chances of a student to get into their preferred university, one must really concetrate on their CGPA since it has an extremely high importance that can determine the chances of getting an admit.\n\n\n# If you found this kernel useful, an upvote would be great ! Thanks :)","1381ec53":"# 3. Data Wrangling\n\nLet us see how if there are any entries which are missing or require any special attention from us.","5dffdb86":"As we can see, the scores are quite similar to simple linear regression. Hence, even with regularisation and cross validation, we could not improve upon the score much. It seems we need to think past the linear models for getting higher accuracies.","e216aeaf":"As we can see from the plot above, the chances of a student with a research profile increases his\/her chances of of getting an admission in their preferred universities.\n\n## LOR and SOP\n\nThese are letter of recommendations and statement of purpose which are mandatory for a student application. Statement of purpose generally checks the student's research and why should the university admit a particular student along with the various research outputs that the student can provide with the  limited time they get in the university.\n\nLORs on the other hand serve as an accredition by the student's faculties or peer researchers whose words could help influence the student to get an admit.\n\nLet us now check how these factors play a role in admissions."}}