{"cell_type":{"0e63e7ee":"code","fd4590f0":"code","7b93ad4b":"code","170b3314":"code","90f405ab":"code","e9331c1f":"code","69b4c8f1":"code","254f65b9":"code","a6b75359":"code","56846e01":"code","ba54e26c":"code","b399db4f":"code","a25228d8":"code","22232da5":"code","6ad2fff1":"code","75b80989":"markdown","cf371d78":"markdown","14939e4b":"markdown","7ec2d633":"markdown","23570b3e":"markdown","c0b6da21":"markdown","9cf04b37":"markdown","3fac74cb":"markdown","44a3e244":"markdown","d5b6663a":"markdown","172f2933":"markdown","e1202085":"markdown","7b194585":"markdown","2985d23f":"markdown"},"source":{"0e63e7ee":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf","fd4590f0":"dataset = pd.read_excel('\/kaggle\/input\/combined-cycle-power-plant\/Folds5x2_pp.xlsx')\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","7b93ad4b":"dataset.head()","170b3314":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)\nX_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size = 0.2, shuffle=True)","90f405ab":"ann = tf.keras.models.Sequential()","e9331c1f":"ann.add(tf.keras.layers.Dense(units=4, activation='relu'))","69b4c8f1":"ann.add(tf.keras.layers.Dense(units=6, activation='relu'))","254f65b9":"ann.add(tf.keras.layers.Dense(units=1))","a6b75359":"ann.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['MeanSquaredLogarithmicError'])","56846e01":"model = ann.fit(X_train, y_train, batch_size = 32, epochs = 25,validation_data=(X_val, y_val),\n              shuffle=True)","ba54e26c":"y_pred = ann.predict(X_test)\nnp.set_printoptions(precision=2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","b399db4f":"import matplotlib.pyplot as plt\n%matplotlib inline\n","a25228d8":"import sklearn.metrics\nevs_no=sklearn.metrics.explained_variance_score(y_test,ann.predict(X_test))\nme_no=sklearn.metrics.max_error(y_test,ann.predict(X_test))\nmae_no=sklearn.metrics.mean_absolute_error(y_test,ann.predict(X_test))\nmse_no=sklearn.metrics.mean_squared_error(y_test,ann.predict(X_test))\nmsle_no=sklearn.metrics.mean_squared_log_error(y_test,ann.predict(X_test))\nMae_no=sklearn.metrics.median_absolute_error(y_test,ann.predict(X_test))\nr2_no=sklearn.metrics.r2_score(y_test,ann.predict(X_test))\nmpd_no=sklearn.metrics.mean_poisson_deviance(y_test,ann.predict(X_test))\nmgd_no=sklearn.metrics.mean_gamma_deviance(y_test,ann.predict(X_test))\nmtd_no=sklearn.metrics.mean_tweedie_deviance(y_test,ann.predict(X_test))","22232da5":"print('Explained Variance Score:',evs_no)\nprint('Max Error               :',me_no)\nprint('Mean Absolute Error     :',mae_no)\nprint('Mean Square Error       :',mse_no)\nprint('Mean Squared Log Error  :',msle_no)\nprint('Median Absolute Error   :',Mae_no)\nprint('R2 Score                :',r2_no)\nprint('Mean Poisson Deviance   :',mpd_no)\nprint('Mean Gamma Deviance     :',mgd_no)\nprint('Mean Tweedie Deviance   :',mtd_no)","6ad2fff1":"# list all data in history\nprint(model.history.keys())\nplt.plot(model.history['loss'])\nplt.plot(model.history['val_loss'])\nplt.grid()\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()\n# summarize history for loss\nplt.plot(model.history['mean_squared_logarithmic_error'])\nplt.plot(model.history['val_mean_squared_logarithmic_error'])\nplt.grid()\nplt.title('model Mean Squared Logarithmic Error')\nplt.ylabel('mean_squared_logarithmic_error')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()\n","75b80989":"### Importing the libraries","cf371d78":"### Adding the input layer and the first hidden layer","14939e4b":"## Part 1 - Data Preprocessing","7ec2d633":"### Predicting the results of the Test set","23570b3e":"### Adding the output layer","c0b6da21":"### Splitting the dataset into the Training set and Test set","9cf04b37":"## Part 2 - Building the ANN","3fac74cb":"## Part 3 - Training the ANN","44a3e244":"### Training the ANN model on the Training set","d5b6663a":"# Artificial Neural Network","172f2933":"### Compiling the ANN","e1202085":"### Importing the dataset","7b194585":"### Initializing the ANN","2985d23f":"### Adding the second hidden layer"}}