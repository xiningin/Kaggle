{"cell_type":{"c3dc4425":"code","5c15273a":"code","9e713e00":"code","65cc972a":"code","993566cc":"code","97b271e2":"code","fe302ce3":"code","6b1dbfc1":"code","4e981227":"code","58fc405d":"code","59f2af13":"code","a0ef74c6":"code","e941b685":"code","b41bae7f":"code","4f2db96c":"code","bdf2291a":"code","dddd13f8":"code","a7dbc51b":"code","61cba3d4":"markdown","28951153":"markdown","32d56a75":"markdown","dffaf008":"markdown","2418d3ab":"markdown","09cf8cd8":"markdown","a273af78":"markdown","74c106ef":"markdown","d1b0fd8f":"markdown","6962cb3f":"markdown","8af97c27":"markdown","222598c0":"markdown","29142fa7":"markdown","b35993e8":"markdown"},"source":{"c3dc4425":"import numpy as np # linear algebra\nfrom numpy import mean\nfrom numpy import std\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.metrics import accuracy_score # accuracy score\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.linear_model import SGDClassifier\nimport category_encoders as ce\nfrom sklearn import preprocessing\nfrom sklearn import datasets\nfrom sklearn import svm\nfrom sklearn import metrics \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5c15273a":"eval_data = pd.read_csv(\"..\/input\/homework2\/eval.csv\") # Loading test.csv\ntrain_data = pd.read_csv(\"..\/input\/homework2\/train.csv\") # Loading train.csv","9e713e00":"eval_data.info()\ntrain_data.info()","65cc972a":"eval_data.isnull().sum()","993566cc":"train_data.isnull().sum()","97b271e2":"train_data.sum()","fe302ce3":"eval_data.sum()","6b1dbfc1":"#le = preprocessing.LabelEncoder()\n#le.fit([\"E\", \"ET\", \"T\", \"M\", \"A\"])\n#train_data['esrb_rating'] = le.fit_transform(train_data['esrb_rating'])\n\n#train_data.head()","4e981227":"#train_data.describe()","58fc405d":"Id_list = eval_data['id']\n\neval_data.drop(columns= ['id','console'], axis=1, inplace= True)\ntrain_data.drop(columns=['id','title','console'], axis=1, inplace=True)","59f2af13":"X = train_data.drop(['esrb_rating'], axis=1)\ny = train_data['esrb_rating']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.10, random_state = 42)\n\ncv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=42)\n\nprint(X.shape)\n\nprint(y.shape)","a0ef74c6":"# Logistic Regression model\nfrom sklearn.linear_model import LogisticRegression\n\nparam_grid = {'C': np.logspace(-3, 3, 10), 'penalty': ['l2']}\n\nlogreg = LogisticRegression(solver='liblinear')\n\nlogreg_cv = RandomizedSearchCV(logreg,param_grid,cv=cv)\nlogreg_cv.fit(X_train,y_train)\n\nlogregR_prediction=logreg_cv.predict(eval_data)\n\n\nprint(\"Randomized Search Tuned hyperparameters : {}\".format(logreg_cv.best_params_))\nprint(\"Randomized Search Best Accuracy: {}\".format(logreg_cv.best_score_))\n\nparam_grid = {'C': [1000], 'penalty': ['l2']}\n\nlogreg_cv = GridSearchCV(logreg,param_grid,cv=cv)\nlogreg_cv.fit(X_train,y_train)\n\nlogregG_prediction=logreg_cv.predict(eval_data)\n\n\nprint(\"Grid Search Best Accuracy: {}\".format(logreg_cv.best_score_))","e941b685":"#Support Vector Machine\nfrom sklearn import svm\n\nparam_grid = {'C': [0.1, 1, 10, 100, 1000],\n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n              'kernel': ['rbf'],\n              'random_state' : [42]}\n\nSVM = svm.SVC()\n\nSVM_cv = RandomizedSearchCV(SVM,param_grid,cv=cv)\nSVM_cv.fit(X_train,y_train)\n\nsvmR_prediction = SVM_cv.predict(eval_data)\n\n\nprint(\"Randomized Search Tuned hyperparameters : {}\".format(SVM_cv.best_params_))\nprint(\"Randomized Search Best Accuracy: {}\".format(SVM_cv.best_score_))\n\nparam_grid = {'C': [1],\n              'gamma': [1],\n              'kernel': ['rbf'],\n              'random_state' : [42]}\n\nSVM_cv = GridSearchCV(SVM,param_grid,cv=cv)\nSVM_cv.fit(X_train,y_train)\n\nsvmG_prediction = SVM_cv.predict(eval_data)\n\nprint(\"Grid Search Best Accuracy: {}\".format(SVM_cv.best_score_))\n","b41bae7f":"# Decision Tree model\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n\nparam_grid = {'max_leaf_nodes': list(range(2, 50)), 'min_samples_split': [2, 3, 4]}\n\nclf = DecisionTreeClassifier()\nclf_cv = RandomizedSearchCV(clf, param_grid, cv=cv)\nclf_cv.fit(X_train,y_train)\n\nclfR_prediction = clf_cv.predict(eval_data)\n\n# Print hyperparameter\nprint(\"Randomized Search Tuned hyperparameter k: {}\".format(clf_cv.best_params_)) \nprint(\"Randomized Search Best score: {}\".format(clf_cv.best_score_))\n\nparam_grid = {'max_leaf_nodes': [47], 'min_samples_split': [3]}\n\nclf_cv = GridSearchCV(clf, param_grid, cv=cv)\nclf_cv.fit(X_train,y_train)\n\nclfG_prediction = clf_cv.predict(eval_data)\n\nprint(\"Grid Search Best score: {}\".format(clf_cv.best_score_))","4f2db96c":"#Random Forest model\nfrom sklearn.ensemble import RandomForestClassifier\n\nparam_grid = { \n    'n_estimators': [10, 20, 30],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [4,5,6,7,8],\n    'criterion' :['gini', 'entropy']\n}\n\nrf = RandomForestClassifier()\nrf_cv = RandomizedSearchCV(rf, param_grid, cv=cv)\nrf_cv.fit(X_train,y_train)\n\nrfR_prediction = rf_cv.predict(eval_data)\n\n# Print hyperparameter\nprint(\"Randomized Search Tuned hyperparameter k: {}\".format(rf_cv.best_params_)) \nprint(\"Randomized Search Best score: {}\".format(rf_cv.best_score_))\n\nparam_grid = { \n    'n_estimators': [30],\n    'max_features': ['log2'],\n    'max_depth' : [8],\n    'criterion' :['gini']\n}\n\nrf_cv = GridSearchCV(rf, param_grid, cv=cv)\nrf_cv.fit(X_train,y_train)\n\nrfG_prediction = rf_cv.predict(eval_data)\n\nprint(\"Grid Search Best score: {}\".format(rf_cv.best_score_))","bdf2291a":"# K Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\n\nparam_grid = {'n_neighbors': np.arange(1,50)}\n\nKNNmodel = KNeighborsClassifier(n_neighbors = 5)\nKNNmodel_cv = RandomizedSearchCV(KNNmodel, param_grid, cv=cv)\nKNNmodel_cv.fit(X_train,y_train)\n\nKNNmodelR_prediction = KNNmodel_cv.predict(eval_data)\n\n# Print hyperparameter\nprint(\"Randomized Search Tuned hyperparameter k: {}\".format(KNNmodel_cv.best_params_)) \nprint(\"Randomized Search Best score: {}\".format(KNNmodel_cv.best_score_))\n\nparam_grid = {'n_neighbors': [7]}\n\nKNNmodel_cv = GridSearchCV(KNNmodel, param_grid, cv=cv)\nKNNmodel_cv.fit(X_train,y_train)\n\nKNNmodelG_prediction = KNNmodel_cv.predict(eval_data)\n\nprint(\"Grid Search Best score: {}\".format(KNNmodel_cv.best_score_))","dddd13f8":"cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=42)\n\n#logreg\nprint(\"logreg\")\nscores = cross_val_score(logreg_cv, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n#scores.describe()\n\n#SVM\nscores = cross_val_score(SVM_cv, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nprint(\"SVM\")\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n#scores.describe()\n\n#clf\nprint(\"clf\")\nscores = cross_val_score(clf_cv, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n#scores.describe()\n\n#rf\nprint(\"rf\")\nscores = cross_val_score(rf_cv, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n#scores.describe()\n\n#KNNmodel\nprint(\"KNNmodel\")\nscores = cross_val_score(KNNmodel_cv, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nprint('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n#scores.describe()\n\n#---------------------------------------------------------------------#\n# describe as requested                                               #\n#---------------------------------------------------------------------#\n\nlogisticregression = pd.DataFrame(logregG_prediction) \nprint(logisticregression.describe())\n\nSVM = pd.DataFrame(svmG_prediction) \nprint(SVM.describe())\n\ndecisiontree = pd.DataFrame(clfG_prediction) \nprint(decisiontree.describe())\n\nrandomforest = pd.DataFrame(rfG_prediction) \nprint(randomforest.describe())\n\nKNN = pd.DataFrame(KNNmodelG_prediction) \nprint(KNN.describe())","a7dbc51b":"#result = []\n#for i in rf_prediction:\n#    if i < 1:\n#        result.append('E')\n#    if i < 2 and i >= 1:\n#        result.append('ET')\n#    if i < 3 and i >= 2:\n#        result.append('T')\n#    if i < 4 and i >= 3:\n#        result.append('M')\n#    if i >= 4:\n#        result.append('A')\n\n#print(result)\nsubmission = pd.DataFrame({'id' : Id_list.values, 'esrb_rating': svmG_prediction})\nsubmission.to_csv(\"submission.csv\", index = False)","61cba3d4":"# Loading Data","28951153":"**Column Removal**\n\nGoing to remove the id column from both sets and save the eval data ids. I will also be dropping console as there are no A rated games which console could help determine but since there isnt all it will do is provide a random corrolation throwing off the data. ","32d56a75":"===============================================================================================================================\n\n","dffaf008":"# Exploratory Data Analysis","2418d3ab":"ESRB ratings are done through a catagorial system and is determined by the type of content in a game .\n\nE may contain cartoon, fantasy, or mild violence with infrequent use of mild language.\n\nET may contain more cartoon, fantasy, or mild violence with some use of mild language with some suggestive themes.\n\nT may contain violence, suggestive themes, crude humor, minimal blood, simulated gambling, and\/or infrequent use of strong language.\n\nM may contain intense violence, blood and gore, sexual content, and\/or strong language. \n\nA may include prolonged scenes of intense violence, graphic and sexual content, and\/or gambling with real currency. ","09cf8cd8":"# Evaluating Models","a273af78":"**Label Encoding**\n\nI am going to change the ESRB ratings on the train dataset with an integer representation of the ESRB Rating\n* 0 will be E\n* 1 will be ET\n* 2 will be T\n* 3 will be M\n* 4 will be A\n\n**EDIT**\n\nEncoding the ESRB rankings has compromised my score and my body. I have decided against it as of this moment but I am keeping this system and code for encoding incase I realize where I made my mistakes and can create a better score with it. Thank you\n","74c106ef":"# Building Models","d1b0fd8f":"===============================================================================================================================","6962cb3f":"===============================================================================================================================\n\n","8af97c27":"SVM has the highest accuracy so I opted to go with it. \n\nI had attempted to use .describe() method as told in the assignment however im unsure if i implemented it correctly. ","222598c0":"# Submission Data","29142fa7":"===============================================================================================================================\n\n","b35993e8":"===============================================================================================================================\n"}}