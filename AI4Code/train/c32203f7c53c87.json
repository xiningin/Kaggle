{"cell_type":{"e309ad38":"code","6eef15c1":"code","ca110830":"code","ee5a7e0d":"code","a98f6a2c":"code","3e61bae5":"code","5a36da74":"code","befd0bc2":"code","8c6b8d84":"code","f57cda7c":"code","0f7e0532":"code","f5f43b98":"markdown","6b8b6925":"markdown","a07fa906":"markdown","1b501707":"markdown","79376e81":"markdown","448c8b32":"markdown","d041fb76":"markdown","8cb66a65":"markdown"},"source":{"e309ad38":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6eef15c1":"train_data_exo = pd.read_csv(\"..\/input\/kepler-labelled-time-series-data\/exoTrain.csv\")\ntest_data_exo = pd.read_csv(\"..\/input\/kepler-labelled-time-series-data\/exoTest.csv\")\ndata = pd.read_csv(\"..\/input\/predicting-a-pulsar-star\/pulsar_stars.csv\")\ndata.head()","ca110830":"data.corr()","ee5a7e0d":"train_data_exo.info()","a98f6a2c":"test_data_exo.info()","3e61bae5":"X = data.drop([\"target_class\"],axis=1)\ny = data[\"target_class\"]","5a36da74":"x_train_exo = train_data_exo.drop([\"LABEL\"],axis=1)\ny_train_exo = train_data_exo[\"LABEL\"]\nx_test_exo = test_data_exo.drop([\"LABEL\"],axis=1)\ny_test_exo = test_data_exo[\"LABEL\"]","befd0bc2":"X_train,X_test, y_train , y_test = train_test_split(X,y,test_size=0.2)","8c6b8d84":"lr = LogisticRegression()\nlr.fit(X_train,y_train)\naccuracy_lr=lr.score(X_test,y_test)\nprint(\"logistic regression accuracy:%{}\".format(accuracy_lr*100))","f57cda7c":"from tensorflow import set_random_seed\nset_random_seed(101)\nimport tensorflow\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential # initialize neural network library\nfrom keras.layers import Dense # build our layers library\ndef build_classifier():\n    classifier = Sequential() # initialize neural network\n    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train_exo.shape[1]))\n    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return classifier\nclassifier = KerasClassifier(build_fn = build_classifier, epochs = 10)\naccuracies = cross_val_score(estimator = classifier, X = x_train_exo, y = y_train_exo, cv = 3)\nmean = accuracies.mean()\nvariance = accuracies.std()\nprint(\"Accuracy mean: \"+ str(mean))\nprint(\"Accuracy variance: \"+ str(variance))","0f7e0532":"print(\"Predicting Pulsar mean: \"+ str(mean))\nprint(\"Predicting Pulsar variance: \"+ str(variance))\n\nprint(\"Exoplanets accuracy:%{}\".format(accuracy_lr*100))","f5f43b98":"## Exoplanet Hunting in Deep Space\n**The Search for New Earths**\n\nThe data describe the change in flux (light intensity) of several thousand stars. Each star has a binary label of 2 or 1. 2 indicated that that the star is confirmed to have at least one exoplanet in orbit; some observations are in fact multi-planet systems.\n\nAs you can imagine, planets themselves do not emit light, but the stars that they orbit do. If said star is watched over several months or years, there may be a regular 'dimming' of the flux (the light intensity). This is evidence that there may be an orbiting body around the star; such a star could be considered to be a 'candidate' system. Further study of our candidate system, for example by a satellite that captures light at a different wavelength, could solidify the belief that the candidate can in fact be 'confirmed'.\n\nFlux Diagram\n\nIn the above diagram, a star is orbited by a blue planet. At t = 1, the starlight intensity drops because it is partially obscured by the planet, given our position. The starlight rises back to its original value at t = 2. The graph in each box shows the measured flux (light intensity) at each time interval.\n\n**Description**\nTrainset:\n\n* 5087 rows or observations.\n* 3198 columns or features.\n* Column 1 is the label vector. Columns 2 - 3198 are the flux values over time.\n* 37 confirmed exoplanet-stars and 5050 non-exoplanet-stars.\n\nTestset:\n\n* 570 rows or observations.\n* 3198 columns or features.\n* Column 1 is the label vector. Columns 2 - 3198 are the flux values over time.\n* 5 confirmed exoplanet-stars and 565 non-exoplanet-stars.\n\n**Acknowledgements**\nThe data presented here are cleaned and are derived from observations made by the NASA Kepler space telescope. The Mission is ongoing - for instance data from Campaign 12 was released on 8th March 2017. Over 99% of this dataset originates from Campaign 3. To boost the number of exoplanet-stars in the dataset, confirmed exoplanets from other campaigns were also included.\n\nTo be clear, all observations from Campaign 3 are included. And in addition to this, confirmed exoplanet-stars from other campaigns are also included.\n\nThe datasets were prepared late-summer 2016.\n\nCampaign 3 was used because 'it was felt' that this Campaign is unlikely to contain any undiscovered (i.e. wrongly labelled) exoplanets.\n\nNASA open-sources the original Kepler Mission data and it is hosted at the Mikulski Archive. After being beamed down to Earth, NASA applies de-noising algorithms to remove artefacts generated by the telescope. The data - in the .fits format - is stored online. And with the help of a seasoned astrophysicist, anyone with an internet connection can embark on a search to find and retrieve the datafiles from the Archive.\n\nThe cover image is copyright \u00a9 2011 by Dan Lessmann\n\n## PREDICTING A PULSAR STAR\n\n*Dr Robert Lyon*\n\nHTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey .\n\nPulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter .\n\nAs pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsars rotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes.\n\nEach pulsar produces a slightly different emission pattern, which varies slightly with each rotation . Thus a potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find.\n\nMachine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted, which treat the candidate data sets as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class.\n\nThe data set shared here contains 16,259 spurious examples caused by RFI\/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators.\n\nEach row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).\n\n**Attribute Information:**\nEach candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency . The remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below:\n\n* Mean of the integrated profile.\n* Standard deviation of the integrated profile.\n* Excess kurtosis of the integrated profile.\n* Skewness of the integrated profile.\n* Mean of the DM-SNR curve.\n* Standard deviation of the DM-SNR curve.\n* Excess kurtosis of the DM-SNR curve.\n* Skewness of the DM-SNR curve.\n* Class\n* HTRU 2 Summary \n* 17,898 total examples. \n* 1,639 positive examples. \n* 16,259 negative examples.\n\nSource: https:\/\/archive.ics.uci.edu\/ml\/datasets\/HTRU2\n\n    Dr Robert Lyon \n    University of Manchester \n    School of Physics and Astronomy \n    Alan Turing Building \n    Manchester M13 9PL \n    United Kingdom \n    robert.lyon '@' manchester.ac.uk","6b8b6925":"### DATA ANALYSIS","a07fa906":"### ACCURACIES","1b501707":"### Creating Model and Predicting","79376e81":"## Thanks for your reading. If you support me just vote up and leave a comment. Have a nice day.","448c8b32":"# PRELIMINARY INFORMATION\n\n","d041fb76":"### READING DATA","8cb66a65":"### SPLITING DATA"}}