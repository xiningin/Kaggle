{"cell_type":{"d8447970":"code","9b8562e0":"code","1a734518":"code","875272e4":"code","285b69f2":"code","076faa14":"code","2da20664":"code","62db088a":"code","0dc384bb":"code","16b72ac9":"code","6451883d":"code","95e4c484":"code","ba6080d3":"code","73827cc3":"code","f5cade83":"code","5beba85f":"code","87bb119f":"code","a4289b2f":"code","563b4f24":"code","f552dc7a":"code","0f31e836":"code","f51ef1ff":"code","8ec62a4b":"code","36fb38ee":"code","9e55a978":"code","09518c95":"code","a1e2f140":"code","82f07a37":"code","78159139":"markdown","8862e2ce":"markdown","e04052c4":"markdown","9dde99a3":"markdown","642ee75e":"markdown","52549a52":"markdown","099068f2":"markdown","ea7c4f64":"markdown","cd8a81d6":"markdown","e5bd8ee3":"markdown","8ce8fc6a":"markdown","aa43ece0":"markdown","8b323e89":"markdown","3bda42c5":"markdown","e51b5821":"markdown","83dbf58e":"markdown","fe319ffd":"markdown","12d300d6":"markdown","02cde960":"markdown","d3e42564":"markdown","253efcdf":"markdown","49fabfcd":"markdown","11003923":"markdown","5a820253":"markdown","8355ec6c":"markdown","5e2b29cb":"markdown","c3d71fa4":"markdown","bf803721":"markdown","4fe6c63c":"markdown","403a7843":"markdown","56cae32e":"markdown","7a6b0b58":"markdown","7387458d":"markdown","86d9cd30":"markdown","d1ebe18f":"markdown","0bbb70b5":"markdown"},"source":{"d8447970":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# Ploting and visualisations \nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.express as px \nfrom plotly.offline import download_plotlyjs,init_notebook_mode, iplot\nimport plotly.tools as tls \nimport plotly.figure_factory as ff \npy.init_notebook_mode(connected=True)\n# ----------------------- #\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9b8562e0":"confirmed_case = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_confirmed.csv')\nconfirmed_case_us = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_confirmed_US.csv')\ndeath_case = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_deaths_US.csv')\ncovid_19_recovered = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_recovered.csv')\ncovid_19_data = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/covid_19_data.csv')\ncovid_19_deaths = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_deaths.csv')\nCOVID19_line_list_data = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/COVID19_line_list_data.csv')\nCOVID19_open_line_list = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/COVID19_open_line_list.csv')","1a734518":"display(covid_19_data.info(),covid_19_data.head())","875272e4":"## checking if any null values in the dataset\ncovid_19_data.isnull().sum()","285b69f2":"def missing_value(covid_19_data):\n    null_data = pd.DataFrame(((covid_19_data.isnull().sum())\/len(covid_19_data['Confirmed']))*100,columns = ['percentage'])\n    null_data = null_data.round(2)\n    trace = go.Bar(x=null_data.index,y=null_data['percentage'],opacity=0.5,text = null_data['percentage'],textposition = 'auto', marker=dict(color = 'turquoise',line=dict(color= 'green',width=1.5)))\n    \n    layout = dict(title='Percentage of null data in dataset')\n    \n    fig = dict(data=[trace], layout=layout)\n    py.iplot(fig)","076faa14":"missing_value(covid_19_data)","2da20664":"covid_19_data['Province\/State'] = covid_19_data['Province\/State'].fillna('Unknown')","62db088a":"display(covid_19_data.isnull().sum(),covid_19_data.head())","0dc384bb":"covid_19_data[[\"Confirmed\",\"Deaths\",\"Recovered\"]] = covid_19_data[[\"Confirmed\",\"Deaths\",\"Recovered\"]].astype(int)","16b72ac9":"covid_19_data['Country\/Region'] = covid_19_data['Country\/Region'].replace('Mainland China','China')","6451883d":"covid_19_data['Active'] = covid_19_data['Confirmed'] - (covid_19_data['Deaths']+covid_19_data['Recovered']) ","95e4c484":"# Used just to see all the rows for critical analysis. \n# pd.set_option(\"display.max.rows\", None)","ba6080d3":"## covid_19_data[covid_19_data['ObservationDate'] == covid_19_data['ObservationDate'].max()] to find the latest data on dases of the day \n## We then sum the latest day data and group them by 'Countries'\n\ndf1 = covid_19_data[covid_19_data['ObservationDate'] == covid_19_data['ObservationDate'].max()].groupby([\"Country\/Region\"])[[\"Confirmed\",\"Active\",\"Recovered\",\"Deaths\"]].sum().reset_index()","73827cc3":"## We are adding the latitude and longitude with df1 table.\ndf2 = confirmed_case[['Country\/Region','Lat','Long']].reset_index()\n\n## We had multiple loction for the same country so we removed the duplicate values. \ndf2 = df2.drop_duplicates(subset = [\"Country\/Region\"])","f5cade83":"# We merged the two dataframes to have location of the countries also .. \nmerge_1_2 = pd.merge(df1,df2, on=['Country\/Region'], how='inner')\n\n## Droping Column index as not required\nmerge_1_2 = merge_1_2.drop(columns=['index'])\n\ndisplay(merge_1_2,merge_1_2.info())","5beba85f":"## Our tool for ploting these beautiful maps..\nimport folium","87bb119f":"## We need coordinates to figure out where we can place our pointers \nlocations = merge_1_2[['Lat', 'Long']]\nlocationlist = locations.values.tolist()","a4289b2f":"from folium.plugins import MarkerCluster\nmap2 = folium.Map(location=[20.5937, 0], tiles='CartoDB dark_matter', zoom_start=2)\n\nmarker_cluster = MarkerCluster().add_to(map2)\n\nfor point in range(0, len(locationlist)):\n    folium.Marker(locationlist[point], popup=merge_1_2['Country\/Region'][point]).add_to(marker_cluster)\nmap2","563b4f24":"map = folium.Map(location= [20.5937, 0],tiles='CartoDB dark_matter', zoom_start=2)\nfor point in range(0, len(locationlist)):\n    folium.Marker(locationlist[point], popup=merge_1_2['Country\/Region'][point]).add_to(map)\nmap","f552dc7a":"# Make an empty map\nm = folium.Map(location=[20,0], tiles=\"CartoDB dark_matter\", zoom_start=2)\n \n# I can add marker one by one on the map\nfor i in range(0,len(merge_1_2)):\n    folium.Circle(\n      location=locationlist[i],\n      popup = (\n        \"<strong>Country\/Region:<\/strong> {Country}<\/br>\"\n        \"<strong>Confirmed case:<\/strong> {Confirmed}<br>\"\n    ).format(Country=str(merge_1_2.iloc[i]['Country\/Region']), Confirmed=str(merge_1_2.iloc[i]['Confirmed'])),\n      radius=merge_1_2.iloc[i]['Confirmed']\/2.5,\n      color='darkorange',\n      fill=True,\n      fill_color='darkorange'\n   ).add_to(m)\n \n# Save it as html\n#m.save('mymap.html')\nm","0f31e836":"def bar_plot(merge_1_2,var):\n    Countries_data = merge_1_2.nlargest(10,[var])\n    #Countries_data['per'] = (Countries_data[var]\/sum(Countries_data[var]))*100\n    trace = go.Bar(y=Countries_data[var],x=Countries_data['Country\/Region'],opacity=0.5,\n                   text = Countries_data[var],textposition = 'auto',\n                   marker_color =  px.colors.qualitative.Bold\n                   )\n    \n    layout = dict(title='Top 10 countries with highest {} cases'.format(var))\n    \n    fig = dict(data=[trace], layout=layout)\n    py.iplot(fig)","f51ef1ff":"bar_plot(merge_1_2,'Confirmed')","8ec62a4b":"# Make an empty map\nm = folium.Map(location=[20,0], tiles=\"CartoDB dark_matter\", zoom_start=2)\n \n# I can add marker one by one on the map\nfor i in range(0,len(merge_1_2)):\n    folium.Circle(\n      location=locationlist[i],\n      popup = (\n        \"<strong>Country\/Region:<\/strong> {Country}<\/br>\"\n        \"<strong>Active case:<\/strong> {Active}<br>\"\n    ).format(Country=str(merge_1_2.iloc[i]['Country\/Region']), Active=str(merge_1_2.iloc[i]['Active'])),\n      radius=merge_1_2.iloc[i]['Active']\/2.5,\n      color='#9ACD32',\n      fill=True,\n      fill_color='#9ACD32'\n   ).add_to(m)\n \n# Save it as html\n#m.save('mymap.html')\nm","36fb38ee":"bar_plot(merge_1_2,'Active')","9e55a978":"# Make an empty map\nm = folium.Map(location=[20,0], tiles=\"CartoDB dark_matter\", zoom_start=2)\n \n# I can add marker one by one on the map\nfor i in range(0,len(merge_1_2)):\n    folium.Circle(\n      location=locationlist[i],\n      popup = (\n        \"<strong>Country\/Region:<\/strong> {Country}<\/br>\"\n        \"<strong>Death case:<\/strong> {Deaths}<br>\"\n    ).format(Country=str(merge_1_2.iloc[i]['Country\/Region']), Deaths=str(merge_1_2.iloc[i]['Deaths'])),\n      radius=merge_1_2.iloc[i]['Deaths']\/.125,\n      color='crimson',\n      fill=True,\n      fill_color='crimson'\n   ).add_to(m)\n \n# Save it as html\n#m.save('mymap.html')\nm","09518c95":"bar_plot(merge_1_2,'Deaths')","a1e2f140":"# Make an empty map\nm = folium.Map(location=[20,0], tiles=\"CartoDB dark_matter\", zoom_start=2)\n \n# I can add marker one by one on the map\nfor i in range(0,len(merge_1_2)):\n    folium.Circle(\n      location=locationlist[i],\n      popup = (\n        \"<strong>Country\/Region:<\/strong> {Country}<\/br>\"\n        \"<strong>Recovered patient:<\/strong> {Recovered}<br>\"\n    ).format(Country=str(merge_1_2.iloc[i]['Country\/Region']), Recovered=str(merge_1_2.iloc[i]['Recovered'])),\n      radius=merge_1_2.iloc[i]['Recovered']\/1,\n      color='#028ACA',\n      fill=True,\n      fill_color='#028ACA'\n   ).add_to(m)\n \n# Save it as html\n#m.save('mymap.html')\nm","82f07a37":"bar_plot(merge_1_2,'Recovered')","78159139":"## Hey, now that we have filled missing values we can tune some of featuers like the names of countries and few columns to our requirement..","8862e2ce":"# Feature Engineering ","e04052c4":"## 3. Active case column \n\n### Some countries may have a lot of confirmed cases but have also have many cured people.. ","9dde99a3":"## + Distribution on the bases of -- 'Recovered patient'","642ee75e":"# Finally , If you like it do comment and upvote . Thank you!!!\ud83d\ude4f","52549a52":"## Again country with higher number of 'Recovery rate' has bigger 'Circler' size.\n## Brazil has the highest number of 'Recovery rate' followed by America,Russia & India.","099068f2":"![Folium-2.jpg](attachment:Folium-2.jpg)","ea7c4f64":"# So with this we come to the end. I have discused on only out of so many ways one can use these tools to perform the analysis. Well keep on updating the notebook with new maps also. \n\n# Hope You will find it useful and interesting. \n\n# Please do comment and upvote the same. Thank You!!\ud83d\ude4f\ud83d\ude4f","cd8a81d6":"# Geo-Spatial analysis\n\n\n\n### Geospatial analysis is the gathering, display, and manipulation of imagery, GPS, satellite photography and historical data, described explicitly in terms of geographic coordinates or implicitly, in terms of a street address, postal code, or forest stand identifier as they are applied to geographic models.","e5bd8ee3":"## All countries are doing good as the recovery is not stoping and is more than Active case in some countries. ","8ce8fc6a":"## America has the highest number of 'Active' cases followed by Brazil,India and Russia. However except US other countries have comparatively less number of 'Active' case in comparison with 'Confirmed' cases.  ","aa43ece0":"## Again country with higher number of 'Active cases' has bigger 'Circler' size.\n## America has the highest number of 'Active' cases followed by Brazil, India and Russia.","8b323e89":"## We can clearly see that many African and Europian regions are affected most.","3bda42c5":"## + Distribution on the bases of -- 'Death Cases'","e51b5821":"# Affected countries.. ","83dbf58e":"### 1. Let's see which all countries are affected and then evaluate which continents where affected on bases of '*Areas affected*'. ","fe319ffd":"## Again we have confirmed that America has the highest number of 'Confirmed' cases followed by Brazil,India and Russia.","12d300d6":"## 2. Change name of few countries.. \n\n### we are going to change name of 'Mainland China' to 'China'.  ","02cde960":"## + Distribution on the bases of -- 'Active Cases'","d3e42564":"## Importing Libraries ","253efcdf":"# Ques. What are we going to do here?? \n\n### We are going to use the data given to find -- <br> 1. Regions affected - on the bases of area affected.\n### 2. Highlight regions on the bases of --- <br>a) No. of Confirmed cases <br>b) No. of Deaths occured <br> c) No. of Cured cases and <br>d) No. of Active cases. \n","49fabfcd":"## 1. 'Areas affected' -- using Folium Marker Clusters \u2013\n### Marker clusters can be a good way to simply a map containing many markers. When the map is zoomed out nearby markers are combined together into a cluster, which is separated out when the map zoom level is closer.","11003923":"## Here we can see which country has more number of 'Confirmed cases' by seeing the size of the 'Circle'. \n## America has the highest number of 'Confirmed' cases followed by Brazil,India and Russia.","5a820253":"## + Distribution on the bases of -- 'Confirmed Cases'","8355ec6c":"# We will be using Folium for the analysis. \n\n### Folium makes it easy to visualize data that\u2019s been manipulated in Python on an interactive Leaflet map. It enables both the binding of data to a map for choropleth visualizations as well as passing Vincent\/Vega visualizations as markers on the map.\n\n### The library has a number of built-in tilesets from OpenStreetMap, MapQuest Open, MapQuest Open Aerial, Mapbox, and Stamen, and supports custom tilesets with Mapbox or Cloudmade API keys. Folium supports both GeoJSON and TopoJSON overlays, as well as the binding of data to those overlays to create choropleth maps with color-brewer color schemes.","5e2b29cb":"## Top 10  countries affected by Covid-19 ","c3d71fa4":"### We are going to fill missing names with 'unknown' region.","bf803721":"# Fill missing values ","4fe6c63c":"## Note: Interestingly though India and Russia was among the top 4 countries in other catogeries yet they has managed to keep the number of casualities very low.","403a7843":"# We will only use the covid_19.csv as it is a compliation of the other dataset. ","56cae32e":"## 1.Changing Data Type -- \n\n### The data looks better however we can also convert Data Type for \"Confirmed\",\"Deaths\" and \"Recovered\" columns to int as they don't happen in fractions..","7a6b0b58":"## 2. If we want to check individual regions we can simply use Marker..","7387458d":"####  It's clearly evident that Africa is the most affected region in terms of '**Area**' affected, followed by Europian Nation and South America and so on..","86d9cd30":"### We have a column(Province\/State) with 35.64% null values thus we cannot drop it and have to fill the missing values","d1ebe18f":"### Its evident that column -- 'Province\/State' has some null values that has to be filled. \n### But before it lets check what percentage of null data are we talking about..","0bbb70b5":"## Again country with higher number of 'Death cases' has bigger 'Circler' size.\n## Sadly again, America has the highest number of 'Death' cases followed by Brazil,Italy and Spain."}}