{"cell_type":{"c98ba0ca":"code","254b6600":"code","058b2530":"code","a26b1c55":"code","e2ca5416":"code","2ae61c75":"code","9591bcfa":"code","a5eff80a":"code","619a113d":"code","fff7557a":"code","fa480e95":"code","dc4c03f7":"code","63c31d06":"code","4f8336ec":"code","1a751d11":"code","c7ef6858":"code","b3c934ab":"code","bd03d47e":"code","e8bc790b":"code","8d986ebc":"code","dd10b077":"code","862bdbb7":"code","ba8dae0c":"code","453813b1":"markdown","e2490f4a":"markdown","605edef3":"markdown","8fd4578e":"markdown","169bd7f3":"markdown","c3538811":"markdown","05507443":"markdown"},"source":{"c98ba0ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","254b6600":"from pathlib import Path\nmain_directory = os.listdir(\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\")\ndirectory = Path(\"..\/input\/a-large-scale-fish-dataset\/Fish_Dataset\/Fish_Dataset\")\nimg_path = [str(x) for x in list(directory.glob('**\/*.png'))]\nimg_path[:5]","058b2530":"img_path = list(filter(lambda x: x.find('GT') == -1, img_path))","a26b1c55":"os.path.split\n\nlabels = [os.path.split(os.path.split(x)[0])[1] for x in img_path]\nlabels[:5]","e2ca5416":"data = pd.concat([pd.Series(img_path), pd.Series(labels)], axis=1)\ndata.columns = ['path', 'label']\ndata[:5]","2ae61c75":"data.label.value_counts()","9591bcfa":"from sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(data, test_size=0.2, random_state=7)\n\nprint('train_df:', train_df.shape)\nprint('test_df:', test_df.shape)\ntrain_df[:5]","a5eff80a":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2,\n)\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='path',\n    y_col='label',\n    target_size=(590, 445),\n    subset='training'\n)\nval_generator = train_datagen.flow_from_dataframe(\n    train_df,\n    x_col='path',\n    y_col='label',\n    target_size=(590, 445),\n    subset='validation',\n)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    x_col='path',\n    y_col='label',\n    target_size=(590, 445),\n)","619a113d":"import matplotlib.pyplot as plt\n\nfor _ in range(5):\n    img, label = train_generator.next()\n    plt.imshow(img[0])\n    print(label)\n    plt.show()","fff7557a":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# TODO - sizing\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(590, 445, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\n\nmodel.summary()","fa480e95":"# TODO - sizing\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(9, activation='softmax'))","dc4c03f7":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","63c31d06":"# model.load_weights('..\/input\/weights\/model.h5')","4f8336ec":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=15,\n)","1a751d11":"# import pickle\n\n# with open('hist.pickle', 'wb') as file:\n#     pickle.dump(hist, file)","c7ef6858":"model.save_weights('model.h5')","b3c934ab":"import matplotlib.pyplot as plt\n\nhist = history.history\nfib, ax = plt.subplots(1, 2, figsize=(20, 10))\n\nax[0].set_title('Loss')\nax[0].plot(hist['loss'], label='loss')\nax[0].plot(hist['val_loss'], label='validation')\nax[0].legend()\n\nax[1].set_title('Accuracy')\nax[1].plot(hist['accuracy'], label='training')\nax[1].plot(hist['val_accuracy'], label='validation')\nax[1].legend()","bd03d47e":"results = model.evaluate(train_generator)","e8bc790b":"# predictions = model.predict(test_generator)","8d986ebc":"# from tensorflow.keras.preprocessing import image\n\n# def predict(idx):\n#     img = image.load_img(test_df.iloc[idx].path, target_size=(590, 445))\n#     img_array = image.img_to_array(img)\n#     img_array = img_array \/ 255\n#     img_array = np.expand_dims(img_array, axis=0)\n#     return model.predict(img_array).argmax()","dd10b077":"# from PIL import Image\n# i = 12\n# pred = predict(i)\n# # plt.imshow(Image.open(test_df.iloc[i].path))\n# print(list(test_generator.class_indices.keys())[pred])\n# print(test_df.iloc[i].label)","862bdbb7":"# print(test_generator.class_indices)\n# test_generator.class_indices.keys()","ba8dae0c":"# match = 0\n# for i in range(1800):\n#     pred = predict(i)\n#     pred_str = list(test_generator.class_indices.keys())[pred]\n#     true_str = test_df.iloc[i].label\n#     if pred_str == true_str:\n#         match = match + 1\n# print(match\/1800)\n    ","453813b1":"# Train","e2490f4a":"# Model","605edef3":"# Test","8fd4578e":"## CNN","169bd7f3":"## Remove Ground Truth Images","c3538811":"## Fully Connected","05507443":"# Data"}}