{"cell_type":{"832fa4da":"code","7e0e4278":"code","240c5dd1":"code","032efae6":"code","93bed49b":"code","6ad6ed32":"code","76d7d0d0":"code","76819d51":"code","7cfbddb9":"code","28846447":"code","e61198d4":"code","7092005c":"code","6c8ae007":"code","7950feab":"code","34dbed21":"code","1795a7ad":"code","e30da32f":"code","c6306f2f":"code","a232be1f":"code","84397cfc":"code","6b2b0c2c":"code","d7f4ce11":"code","cfd6b593":"code","3ccaa621":"code","c94af1d5":"code","3878253f":"code","43c61158":"code","fad75ffd":"code","2a6afbdd":"code","da7f3882":"code","4ba64fae":"code","37b73e8b":"code","599fa2c5":"code","5f73465d":"code","bd168ae9":"code","8a36a23b":"code","5ef69923":"code","b9a3fdbc":"code","2a395c68":"code","7cd6f494":"code","f50ce958":"code","ff75ada5":"code","d76872d8":"code","d6c004f6":"code","2b765ebd":"code","4082119e":"markdown","0e3f5b05":"markdown","7202e774":"markdown","d84df594":"markdown"},"source":{"832fa4da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7e0e4278":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","240c5dd1":"df_train.head()","032efae6":"drop_cols = ['PassengerId','Ticket', 'Name']\n# Drop columns not required - PassengerId, Ticket\ndf_train.drop(drop_cols, axis=1, inplace=True)\n\n# Save PassengerId from test df as it'd be needed for submission\ntest_pass_ids = df_test.PassengerId.values\n\ndf_test.drop(drop_cols, axis=1, inplace=True)","93bed49b":"df_train.head()","6ad6ed32":"df_test.head()","76d7d0d0":"test_pass_ids.shape","76819d51":"# Find NaN values\ndf_train.isna().sum()","7cfbddb9":"# We can drop Cabin as it has missing values more than actual values present.\ndf_train.drop(['Cabin'], axis=1, inplace=True)\ndf_test.drop(['Cabin'], axis=1, inplace=True)","28846447":"df_train.isna().sum()","e61198d4":"# Let's check the data where Embarked is NaN\ndf_train[df_train['Embarked'].isna()]","7092005c":"# Check data where Pclass = 1\ndf_train[df_train['Pclass']==1]","6c8ae007":"# Check data where Pclass = 1 and Fare >= 80.0 and Sex=female and SibSp=0 and Parch=0\ndf_train[(df_train['Pclass']==1) \n         & (df_train['Fare'] >= 80) \n         & (df_train['Sex'] == 'female')\n         & (df_train['SibSp'] == 0)\n         & (df_train['Parch'] == 0)]","7950feab":"df_train.loc[:, 'Embarked'] = df_train.Embarked.fillna('NONE')","34dbed21":"df_train.isna().sum()","1795a7ad":"# To move to Imputation, first we need to convert str data to numeric data\nfrom sklearn.preprocessing import LabelEncoder","e30da32f":"lbl = LabelEncoder()\ndf_train.loc[:, 'Sex'] = lbl.fit_transform(df_train['Sex'])\ndf_test.loc[:, 'Sex'] = lbl.fit_transform(df_test['Sex'])","c6306f2f":"lbl = LabelEncoder()\ndf_train.loc[:, 'Embarked'] = lbl.fit_transform(df_train['Embarked'])\ndf_test.loc[:, 'Embarked'] = lbl.fit_transform(df_test['Embarked'])","a232be1f":"df_train.head()","84397cfc":"df_test.head()","6b2b0c2c":"train_Survived = df_train.Survived.values","d7f4ce11":"df_train.drop('Survived', axis=1, inplace=True)","cfd6b593":"features = df_train.columns.tolist()\nprint(features)","3ccaa621":"from sklearn.impute import KNNImputer","c94af1d5":"imputer = KNNImputer(n_neighbors=2, weights='uniform')\ndf_train = pd.DataFrame(imputer.fit_transform(df_train), columns = features)\ndf_test = pd.DataFrame(imputer.transform(df_test), columns = features)","3878253f":"df_train.isna().sum()","43c61158":"df_test.isna().sum()","fad75ffd":"df_train.head()","2a6afbdd":"# Create bins for Age, Fare columns\n# 0. infants              [0, 12)\n# 1. teenager             [12, 18)\n# 2. student              [18, 25)\n# 3. adult                [25, 40)\n# 4. mid_age              [40, 60)\n# 5. senior_citizen       [60, 100)\n# 6. super_senior_citizen [100, )\nage_bins = [0, 12, 18, 25, 40, 60, 100]\nlabels =[0, 1, 2, 3, 4, 5]\ndf_train['Age_binned'] = pd.cut(df_train['Age'], age_bins,labels=labels)\ndf_test['Age_binned']  = pd.cut(df_test['Age'], age_bins, labels=labels)","da7f3882":"df_train.Age_binned.value_counts()","4ba64fae":"df_train.isna().sum()","37b73e8b":"df_test.isna().sum()","599fa2c5":"df_train.Fare.describe()","5f73465d":"# Create bins for Fare columns\n# 0. lowest              [0,           7.9104 )\n# 1. low                 [7.9104,     14.4542 )\n# 2. medium              [14.4542,    31      )\n# 3. high                [31,         56.4958 )\n# 4. higher              [56.4958,   112.07915)\n# 5. highest             [112.07915, 512.3292 )\nfare_bins = np.quantile(df_train.Fare, [0, .25, .5, .75, .85, .95, 1])\nprint(fare_bins)\nlabels =[0, 1, 2, 3, 4, 5]\ndf_train['Fare_binned'] = pd.cut(df_train['Fare'], fare_bins,labels=labels)\ndf_train.loc[df_train['Fare']==0.0, ['Fare_binned']] = 0\ndf_test['Fare_binned']  = pd.cut(df_test['Fare'], fare_bins, labels=labels)\ndf_test.loc[df_test['Fare']==0.0, ['Fare_binned']] = 0","bd168ae9":"df_train.Fare_binned.value_counts()","8a36a23b":"df_train.isna().sum()","5ef69923":"df_test.isna().sum()","b9a3fdbc":"df_train.drop(['Age', 'Fare'], axis=1, inplace=True)\ndf_test.drop(['Age', 'Fare'], axis=1, inplace=True)","2a395c68":"df_train.head()","7cd6f494":"df_test.head()","f50ce958":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split","ff75ada5":"x_train, x_val, y_train, y_val=train_test_split(df_train, train_Survived, test_size=0.33, random_state=42)","d76872d8":"lr = LogisticRegression()\n\nlr.fit(x_train, y_train)\n\nval_preds = lr.predict(x_val)\npreds = lr.predict_proba(x_val)[:, 1]\n\nacc = accuracy_score(y_val, val_preds)\nauc = roc_auc_score(y_val, preds)\n\nprint('Accuracy: {}, AUC score:{}'.format(acc, auc))\n","d6c004f6":"# Submission\ndef submission(X, passengerId, model, submission_index):\n    preds = model.predict(X)\n    \n    sub_df = pd.DataFrame({'PassengerId': passengerId, 'Survived': preds})\n    sub_df.to_csv(f'Submission_{submission_index}.csv', index=False)","2b765ebd":"submission(df_test, test_pass_ids, lr, submission_index=3)","4082119e":"# 1. Logistic regression","0e3f5b05":"Now, we need to impute missing values for Age using other columns","7202e774":"We don't see a particular pattern for Imputin missing values for Embarked column. We just assign 'None' for now as new category","d84df594":"We still have 'Age' and 'Embarked' columns with missing values"}}