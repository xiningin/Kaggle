{"cell_type":{"c4f38c70":"code","5b4900bf":"code","d3dab504":"code","ecfa2e32":"code","6be5b40a":"code","ab0a0f31":"code","77e263a1":"code","52a4aee0":"code","3f83806d":"code","4171e4d9":"code","a5649bcf":"code","33a244ca":"code","c0500e54":"code","d1d22f88":"code","782485b8":"code","2518b1a8":"code","4eea6538":"code","5b0c6ced":"code","03d275d8":"code","c2d82bb3":"code","9c72e7f0":"code","09c89a66":"code","69bb0f84":"code","364b4d3b":"code","6b911324":"code","eb37fac9":"code","38119a24":"code","bdbef0aa":"code","6d0fb069":"code","f55096b4":"code","d7d0e215":"code","6f139523":"code","54c869b6":"code","3abaa283":"code","b8efa4a9":"code","816c65b8":"code","7680855f":"code","2c28a014":"code","4a7092e8":"markdown","2875e688":"markdown","d22206f0":"markdown","181fbc4e":"markdown","cad85a1c":"markdown","8ca488c3":"markdown","fc3350e3":"markdown","e743550e":"markdown","05d3a784":"markdown","8c28b8b6":"markdown"},"source":{"c4f38c70":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5b4900bf":"# read csv.\ndf = pd.read_csv(\"\/kaggle\/input\/kickstarter-projects\/ks-projects-201801.csv\")\n\n# add count.\ndf['count'] = 1\n\n# add state_type.\ndf.loc[df['state'] == 'failed', 'state_type'] = 'failed'\ndf.loc[df['state'] == 'successful', 'state_type'] = 'successful'\n\n# to datetime.\ndf['launched'] = pd.to_datetime(df['launched'])\ndf['deadline'] = pd.to_datetime(df['deadline'])\n\n# add days.\ndf['days'] = (df['deadline'] - df['launched']).dt.days","d3dab504":"df.head()","ecfa2e32":"# show heatmap.\nsns.heatmap(df.isnull())","6be5b40a":"df.groupby('main_category').sum().index","ab0a0f31":"#sns.set_style('darkgrid')\nmains = df.main_category.value_counts().head(15)\n\nx = mains.values\ny = mains.index\n\nfig = plt.figure(dpi=80)\nax = fig.add_subplot(111)\nax = sns.barplot(y=y, x=x, orient='h', palette=\"Accent\", alpha=0.8)\n\nplt.title('Kickstarter Top 15 Category Count')\nplt.show()","77e263a1":"mains","52a4aee0":"df.groupby('category').sum().index","3f83806d":"cats = df.category.value_counts().head(15)\n\nx = cats.values\ny = cats.index\n\nfig = plt.figure(dpi=80)\nax = fig.add_subplot(111)\nax = sns.barplot(y=y, x=x, orient='h', palette=\"CMRmap\", alpha=0.8)\n\nplt.title('Kickstarter Top 15 Sub-Category Count')\nplt.show()","4171e4d9":"cats","a5649bcf":"plt.style.use('seaborn-pastel')\n\nfig, ax = plt.subplots(1, 1, dpi=100)\nexplode = [0,0,.1,.2, .4]\ndf.state.value_counts().head(5).plot.pie(autopct='%0.2f%%',\n                                        explode=explode)\n\nplt.title('Breakdown of Kickstarter Project Status')\nplt.ylabel('')\nplt.show()","33a244ca":"fig, ax = plt.subplots(1, 1)\n(df.backers >=1).value_counts().plot.pie(autopct='%0.0f%%', \n                                         explode=[0,.1], \n                                         labels=None, \n                                         shadow=False)\n\nplt.ylabel('')\nplt.title('Kickstarter Backer Share')\nplt.legend(['backers', 'no backers'], loc=2)\n\nplt.show()","c0500e54":"df_failed = df[df['state'] == 'failed']\ndf_successful = df[df['state'] == 'successful']","d1d22f88":"df_failed.describe()","782485b8":"df_successful.describe()","2518b1a8":"#Plot Success Trend.\n\n#success\ndf2 = df_successful[['launched', 'count']]\ndf2.set_index('launched', inplace=True)\ndf2 = df2.resample('Y').sum() \ndf2\n\n# failed\ndf3 = df_failed[['launched', 'count']]\ndf3.set_index('launched', inplace=True)\ndf3 = df3.resample('Y').sum() \ndf3\n\ndf4 = df[['launched', 'count']]\ndf4 = df4[(df4['launched'] >= '2009-01-01') & (df4['launched'] < '2018-01-01')]\ndf4.set_index('launched', inplace=True)\ndf4 = df4.resample('Y').sum() \ndf4\n\ndf5 = df2 \/ df4 * 100\ndf5","4eea6538":"df5['count'].plot(label=\"Success rate\", figsize = (8, 6))\nplt.title('Success rate Trend')\nplt.legend(ncol=1)\nplt.show()","5b0c6ced":"# Group by main_category\ngrouped = df[['main_category', 'state_type', 'count']].groupby(['main_category', 'state_type']).sum()\n\nfailed = grouped.xs('failed',level=\"state_type\")[\"count\"]\nsuccess = grouped.xs('successful',level=\"state_type\")[\"count\"]\n\nindex = failed.index\ndf1 = pd.DataFrame({'failed': failed, 'success': success}, index=index)\n\ndf1","03d275d8":"plt.style.use('seaborn-darkgrid')\nax = df1.plot.bar(figsize = (16, 9), rot=0)\nplt.title('Success and failure comparison by category')\nfig = ax.get_figure()","c2d82bb3":"# show Success and failure comparison by category\n\ncategory = df1.index\nsuccess = df1['success'] \/ (df1['success'] + df1['failed'])\nfailed = df1['failed'] \/ (df1['success'] + df1['failed'])\n\nindex = failed.index\ndf2 = pd.DataFrame({'failed': failed, 'success': success}, index=index)\n\nax = df2.plot.barh(stacked = True, figsize = (8,6))\n\n# we also need to switch the labels\nplt.xlabel('Success and failure comparison by category')  \nplt.ylabel('Category')\n    \nind = np.arange(15)\nlst = df2.values\n\nfor x, y in zip(ind, lst):\n    plt.text(y[0]\/2, x, '{:.2%}'.format(y[0]), ha='center', va='center')\n    plt.text((y[0] + (y[1]\/2)), x, '{:.2%}'.format(y[1]), ha='center', va='center')\n    \nplt.vlines([0.5], -1, 100, \"black\")\n    \nax.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) \n    \nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0, fontsize=12)\nplt.show()","9c72e7f0":"# add goal decile rank.\ndf['goal_decile_rank'] = pd.qcut(df['goal'], 10, labels=False)\ndf","09c89a66":"# Group by goal_decile_rank\ngrouped = df[['goal_decile_rank', 'state_type', 'count']].groupby(['goal_decile_rank', 'state_type']).sum()\n\nfailed = grouped.xs('failed',level=\"state_type\")[\"count\"]\nsuccess = grouped.xs('successful',level=\"state_type\")[\"count\"]\n\nindex = failed.index\ndf6 = pd.DataFrame({'failed': failed, 'success': success}, index=index)\n\ndf6","69bb0f84":"plt.style.use('seaborn-darkgrid')\nax = df6.plot.bar(figsize = (16, 9), rot=0)\nplt.title('Success and failure comparison by goal_decile_rank')\nfig = ax.get_figure()","364b4d3b":"# show Success and failure comparison by goal_decile_rank\n\ncategory = df6.index\nsuccess = df6['success'] \/ (df6['success'] + df6['failed'])\nfailed = df6['failed'] \/ (df6['success'] + df6['failed'])\n\nindex = failed.index\ndf7 = pd.DataFrame({'failed': failed, 'success': success}, index=index)\n\nax = df7.plot.barh(stacked = True, figsize = (8,6))\n\n# we also need to switch the labels\nplt.xlabel('Success and failure comparison by goal_decile_rank')  \nplt.ylabel('decile rank')\n    \nind = np.arange(15)\nlst = df7.values\n\nfor x, y in zip(ind, lst):\n    plt.text(y[0]\/2, x, '{:.2%}'.format(y[0]), ha='center', va='center')\n    plt.text((y[0] + (y[1]\/2)), x, '{:.2%}'.format(y[1]), ha='center', va='center')\n    \nplt.vlines([0.5], -1, 100, \"black\")\n    \nax.xaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0%}'.format(y))) \n    \nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0, fontsize=12)\nplt.show()","6b911324":"features = df.copy()\nfeatures['success'] = np.where(features.state == 'successful', 1, 0)","eb37fac9":"df_dummy = pd.get_dummies(features['main_category'])\nfeatures = pd.concat([features.drop(['main_category'],axis=1),df_dummy],axis=1)","38119a24":"features['US'] = np.where(features.country=='US', 1,0)","bdbef0aa":"features.drop(['ID', 'name', 'category', 'currency', 'backers', 'pledged', 'usd pledged', 'usd_pledged_real', 'usd_goal_real', 'deadline', 'launched', 'country', 'state', 'state_type', 'count'], axis=1, inplace=True)","6d0fb069":"#features = features.dropna()\nfeatures.drop(features.columns[np.isnan(features).any()], axis=1, inplace=True)","f55096b4":"med = features['goal'].median()\nMAD = 1.4826 * np.median(abs(features['goal']-med))\nfeatures = features[(med - 3 * MAD < features['goal']) & (features['goal'] < med + 3 * MAD)]","d7d0e215":"med = features['days'].median()\nMAD = 1.4826 * np.median(abs(features['days']-med))\nfeatures = features[(med - 3 * MAD < features['days']) & (features['days'] < med + 3 * MAD)]","6f139523":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import ensemble","54c869b6":"X = features.drop(['success'], 1)\ny = features.success\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","3abaa283":"# Declare a logistic regression classifier.\n# Parameter regularization coefficient C described above.\nlr = LogisticRegression(penalty='l2', solver='liblinear')\n\n# Fit the model.\nfit = lr.fit(X_train, y_train)\n\n# Display.\n# print('Coefficients')\n# print(fit.coef_)\n# print(fit.intercept_)\n\npred_y_sklearn = fit.predict(X_test)\n\nprint('\\n Accuracy by success')\nprint(pd.crosstab(pred_y_sklearn, y_test))\n\nprint('\\n Percentage accuracy')\nprint(lr.score(X_test, y_test))\n\n# CV\n#scores = cross_val_score(lr, X, y, cv=10)\n\n#print(scores)","b8efa4a9":"def gradient_boost(estimators, depth, loss_function, sampling):\n    clf = ensemble.GradientBoostingClassifier(n_estimators=estimators, \n                                              max_depth=depth, \n                                              loss=loss_function, \n                                              subsample=sampling\n                                              )\n    clf.fit(X_train, y_train)\n    print('\\n Percentage accuracy for Gradient Boosting Classifier')\n    predict_train = clf.predict(X_train)\n    predict_test = clf.predict(X_test)\n\n# Accuracy tables.\n    table_train = pd.crosstab(y_train, predict_train, margins=True)\n    table_test = pd.crosstab(y_test, predict_test, margins=True)\n\n    train_tI_errors = table_train.loc[0.0,1.0] \/ table_train.loc['All','All']\n    train_tII_errors = table_train.loc[1.0,0.0] \/ table_train.loc['All','All']\n\n    test_tI_errors = table_test.loc[0.0,1.0]\/table_test.loc['All','All']\n    test_tII_errors = table_test.loc[1.0,0.0]\/table_test.loc['All','All']\n    \n    train_accuracy = 1 - (train_tI_errors + train_tII_errors)\n    test_accuracy = 1 - (test_tI_errors + test_tII_errors)\n    \n    print((\n    'Training set accuracy:\\n'\n    'Overall Accuracy: {}\\n'\n    'Percent Type I errors: {}\\n'\n    'Percent Type II errors: {}\\n\\n'\n    'Test set accuracy:\\n'\n    'Overall Accuracy: {}\\n'\n    'Percent Type I errors: {}\\n'\n    'Percent Type II errors: {}'\n    ).format(train_accuracy, train_tI_errors, train_tII_errors, test_accuracy, test_tI_errors, test_tII_errors))","816c65b8":"#500 estimators, max depth of 2, loss function = 'deviance', subsampling default to 1.0\ngradient_boost(500, 2, 'deviance', 1.0)","7680855f":"clf = ensemble.GradientBoostingClassifier(n_estimators=500, max_depth=2, loss='deviance', subsample=1.0)\nclf.fit(X_train, y_train)\n\nfeature_importance = clf.feature_importances_[:30]\n\n# Make importances relative to max importance.\nplt.figure(figsize=(10,10))\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\nplt.subplot(1, 2, 2)\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()","2c28a014":"import lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nclf_lgbm = LGBMClassifier(\n        n_estimators=300,\n        num_leaves=15,\n        colsample_bytree=.8,\n        subsample=.8,\n        max_depth=7,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01\n    )\n\nclf_lgbm.fit(X_train, \n        y_train,\n        eval_set= [(X_train, y_train), (X_test, y_test)], \n        eval_metric='auc', \n        verbose=0, \n        early_stopping_rounds=30\n       )\n\nacc_clf_lgbm = round(clf_lgbm.score(X_test, y_test) * 100, 2)\nacc_clf_lgbm\n\n# # Run Cross validation\n# scores = cross_val_score(clf_lgbm, X, y, cv=5)\n# np.mean(scores)","4a7092e8":"# Feature Engineering","2875e688":"# Gradient Boosting gets 65.3% test set accuracy","d22206f0":"# Show a graph comparing failures and successes by main category","181fbc4e":"# Introduction\n\nThis kernel is inspired by the following kernels: [kickstarter Success Classifier [0.685]](https:\/\/www.kaggle.com\/majickdave\/kickstarter-success-classifier-0-685)","cad85a1c":"# Show sub category.","8ca488c3":"# Try LightGBM","fc3350e3":"# Try Gradient Boosting","e743550e":"# Show main category.","05d3a784":"# Success rate Trend.","8c28b8b6":"# Classification"}}