{"cell_type":{"fa017d47":"code","236a16b8":"code","ba54c448":"code","5d09fad5":"code","67855798":"code","c8077efd":"code","cdf583d2":"code","108cb2ce":"code","2bf942af":"code","405bcb39":"code","3ce34726":"code","fb719d8a":"code","56a7d578":"code","0cb7bec6":"code","4cad608d":"code","6b0b6b36":"code","4fef29f6":"code","6f95f8e4":"code","5e331f5e":"code","bdbb8687":"code","2fdd87f2":"code","a3ac5e71":"code","a3cd3334":"code","4f677ae5":"code","1e7fa5d0":"code","47f4f991":"code","2ed7edc0":"code","7b2b672d":"markdown"},"source":{"fa017d47":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","236a16b8":"X_train = pd.read_csv('\/kaggle\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv')\nX_test = pd.read_csv('\/kaggle\/input\/loan-prediction-problem-dataset\/test_Y3wMUE5_7gLdaTN.csv')","ba54c448":"X_train.head()","5d09fad5":"X_test.head()","67855798":"X_train.shape","c8077efd":"X_train.isnull().sum().sort_values(ascending=False)","cdf583d2":"X_train = X_train.drop([\"Loan_ID\"], axis = 1)\nX_test = X_test.drop([\"Loan_ID\"], axis = 1)","108cb2ce":"r = X_train[X_train['Married'].isnull()].index.tolist()","2bf942af":"X_train.drop(X_train.index[r])","405bcb39":"X_train.isnull().sum().sort_values(ascending=False)","3ce34726":"X_test.isnull().sum().sort_values(ascending=False)","fb719d8a":"X_train.describe()","56a7d578":"import matplotlib.pyplot as plt\nimport seaborn as sns\nX_train.hist(figsize = (10,10))\nplt.show()","0cb7bec6":"# Get list of categorical variables\ny = X_train.Loan_Status\nX_train = X_train.drop(['Loan_Status'], axis=1)\ns = (X_train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)\n\n","4cad608d":"from sklearn.preprocessing import OneHotEncoder\n\n# Remove categorical columns (will replace with one-hot encoding)\nnum_X_train = X_train.drop(object_cols, axis=1)\nnum_X_test = X_test.drop(object_cols, axis=1)\ncat_X_train = X_train[object_cols]\ncat_X_test = X_test[object_cols]","6b0b6b36":"cat_X_train = cat_X_train.fillna(method = 'ffill')\ncat_X_test = cat_X_test.fillna(method = 'ffill')","4fef29f6":"from sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer()\n\nimputed_num_X_train = pd.DataFrame(my_imputer.fit_transform(num_X_train))\nimputed_num_X_test = pd.DataFrame(my_imputer.transform(num_X_test))\n\n# Imputation removed column names; put them back\nimputed_num_X_train.columns = num_X_train.columns\nimputed_num_X_test.columns = num_X_test.columns\n\n","6f95f8e4":"from sklearn.preprocessing import LabelEncoder\n\n# Make copy to avoid changing original data \nlabel_X_train = X_train.copy()\nlabel_X_test = X_test.copy()\n\n# Apply label encoder to each column with categorical data\nlabel_encoder = LabelEncoder()\nfor col in object_cols:\n    cat_X_train[col] = label_encoder.fit_transform(cat_X_train[col])\n    cat_X_test[col] = label_encoder.transform(cat_X_test[col])","5e331f5e":"cat_X_train.head(3)","bdbb8687":"cat_X_test.head(3)","2fdd87f2":"concat_X_train = pd.concat([imputed_num_X_train, cat_X_train], axis = 1, sort = False)\nconcat_X_test = pd.concat([imputed_num_X_test, cat_X_test], axis =1, sort = False)\n\nconcat_X_train.head()","a3ac5e71":"y.isnull().any()","a3cd3334":"target = {'Y': 1, 'N':0}\ny_train = y.map(target)\ny_train.head()","4f677ae5":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC","1e7fa5d0":"models = []\nmodels.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n    cv_results = cross_val_score(model, concat_X_train, y_train, cv=kfold, scoring='accuracy')\n    results.append(cv_results)\n    names.append(name)\n    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))","47f4f991":"# Compare Algorithms\nplt.boxplot(results, labels=names)\nplt.title('Algorithm Comparison')\nplt.show()","2ed7edc0":"# Make predictions on validation dataset\nmodel = LinearDiscriminantAnalysis()\nmodel.fit(concat_X_train, y_train)\npredictions = model.predict(concat_X_test)","7b2b672d":"Model Evaluation****"}}