{"cell_type":{"73f1063d":"code","f9936203":"code","937ee755":"code","8b9052cf":"code","92195daf":"code","079c854e":"code","144a6869":"code","4ebab443":"code","d1729afc":"code","1383d76c":"code","a9558f89":"code","04b21db0":"code","3599060d":"code","682e361e":"code","8c7417d7":"code","a4dc3662":"markdown","18d46b98":"markdown"},"source":{"73f1063d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\/facial-expression\/fer2013\/\"))\n\n# Any results you write to the current directory are saved as output.","f9936203":"import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","937ee755":"# get the data\nfilname = '..\/input\/facial-expression\/fer2013\/fer2013.csv'\nlabel_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\nnames=['emotion','pixels','usage']\ndf=pd.read_csv('..\/input\/facial-expression\/fer2013\/fer2013.csv',names=names, na_filter=False)\nim=df['pixels']\ndf.head(10)","8b9052cf":"def getData(filname):\n    # images are 48x48\n    # N = 35887\n    Y = []\n    X = []\n    first = True\n    for line in open(filname):\n        if first:\n            first = False\n        else:\n            row = line.split(',')\n            Y.append(int(row[0]))\n            X.append([int(p) for p in row[1].split()])\n\n    X, Y = np.array(X) \/ 255.0, np.array(Y)\n    return X, Y\n","92195daf":"X, Y = getData(filname)\nnum_class = len(set(Y))\nprint(num_class)","079c854e":"# keras with tensorflow backend\nN, D = X.shape\nX = X.reshape(N, 48, 48, 1)","144a6869":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\ny_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\ny_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)","4ebab443":"from keras.models import Sequential\nfrom keras.layers import Dense , Activation , Dropout ,Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.metrics import categorical_accuracy\nfrom keras.models import model_from_json\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import *\nfrom keras.layers.normalization import BatchNormalization","d1729afc":"def my_model():\n    model = Sequential()\n    input_shape = (48,48,1)\n    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation='relu', padding='same'))\n    model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(Conv2D(128, (5, 5),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(Conv2D(256, (3, 3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(7))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n    # UNCOMMENT THIS TO VIEW THE ARCHITECTURE\n    #model.summary()\n    \n    return model\nmodel=my_model()\nmodel.summary()","1383d76c":"path_model='model_filter.h5' # save model at this location after each epoch\nK.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\nmodel=my_model() # create the model\nK.set_value(model.optimizer.lr,1e-3) # set the learning rate\n# fit the model\nh=model.fit(x=X_train,     \n            y=y_train, \n            batch_size=64, \n            epochs=20, \n            verbose=1, \n            validation_data=(X_test,y_test),\n            shuffle=True,\n            callbacks=[\n                ModelCheckpoint(filepath=path_model),\n            ]\n            )","a9558f89":"objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\ny_pos = np.arange(len(objects))\nprint(y_pos)","04b21db0":"def emotion_analysis(emotions):\n    objects = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n    y_pos = np.arange(len(objects))\n    plt.bar(y_pos, emotions, align='center', alpha=0.9)\n    plt.tick_params(axis='x', which='both', pad=10,width=4,length=10)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n    \nplt.show()","3599060d":"y_pred=model.predict(X_test)\n#print(y_pred)\ny_test.shape","682e361e":"from skimage import io\nimg = image.load_img('..\/input\/myimage\/img2.jpeg', grayscale=True, target_size=(48, 48))\nshow_img=image.load_img('..\/input\/myimage\/img2.jpeg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx \/= 255\n\ncustom = model.predict(x)\n#print(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])\n        ","8c7417d7":"from skimage import io\nimg = image.load_img('..\/input\/testimage\/img1.jpg', grayscale=True, target_size=(48, 48))\nshow_img=image.load_img('..\/input\/testimage\/img1.jpg', grayscale=False, target_size=(200, 200))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n\nx \/= 255\n\ncustom = model.predict(x)\n#print(custom[0])\nemotion_analysis(custom[0])\n\nx = np.array(x, 'float32')\nx = x.reshape([48, 48]);\n\nplt.gray()\nplt.imshow(show_img)\nplt.show()\n\nm=0.000000000000000000001\na=custom[0]\nfor i in range(0,len(a)):\n    if a[i]>m:\n        m=a[i]\n        ind=i\n        \nprint('Expression Prediction:',objects[ind])","a4dc3662":"**Real Time Expression Prediction**","18d46b98":"**Live Demo of Production Level Project**\n\n[Facial Expression Detection Web App](https:\/\/faceai.herokuapp.com\/)"}}