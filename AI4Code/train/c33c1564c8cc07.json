{"cell_type":{"2136f9da":"code","76fb3403":"code","880b4e46":"code","33bf65de":"code","2bbe1703":"code","448a1f18":"code","f7a3e930":"code","274a797e":"code","97d96fa5":"markdown","73d82ac2":"markdown","dfa950a8":"markdown","5f6c2d9f":"markdown","d1329aa2":"markdown","893c1fff":"markdown","fef6607f":"markdown"},"source":{"2136f9da":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\n","76fb3403":"train_file = \"\/kaggle\/input\/30-days-of-ml\/train.csv\"\ntest_file = \"\/kaggle\/input\/30-days-of-ml\/test.csv\"\nX = pd.read_csv(train_file,index_col = 'id')\nX_test_full = pd.read_csv(test_file, index_col = 'id')\n\n#training data inspection\nX.head()","880b4e46":"#Remove the rows with missing target\nX.dropna(axis = 0, subset = [\"target\"], inplace = True)\ny = X[\"target\"]\n# Remove the target column from the training dataset\nX.drop([\"target\"],axis=1,inplace = True)\nX.head()","33bf65de":"# Split the data into train test set\nX_train_full, X_valid_full,y_train, y_valid = train_test_split(X,y, \n                                                               train_size = 0.8, test_size = 0.2, \n                                                               random_state = 0)\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncat_cols = [cname for cname in X_train_full.columns if\n                    X_train_full[cname].dtype == \"object\"]\n\n# Select numeric columns\nnum_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n# Keep selected columns only\nmy_cols = cat_cols + num_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()\nX_train.head()\n\n","2bbe1703":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='mean')\n\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')) \n    ,('scaler', OrdinalEncoder())\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, num_cols),\n        ('cat', categorical_transformer, cat_cols)\n    ],\n    remainder=\"passthrough\"\n  )\n","448a1f18":"model = XGBRegressor(n_estimators = 1400, learning_rate = 0.1)\n#I have tried:\n#n_est = 5000, l_rate = 0.1, rmse = 0.73\n# n_est = 1000, l_rate = 0.3, rmse = 0.722\n#n_est = 2000, l_rate = 0.2, rmse = 0.727\n#n_est = 1500. l_rate = 0.1, rmse = 0.715","f7a3e930":"# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)\n                             ])\n\n# Preprocessing of training data, fit model \nmy_pipeline.fit(X_train, y_train)\n\n# Preprocessing of validation data, get predictions\npreds = my_pipeline.predict(X_valid)\n\n# Evaluate the model\nscore = mean_squared_error(y_valid, preds)\nrmse = math.sqrt(score)\nprint('RMSE:', rmse)\n\n","274a797e":"test_preds = my_pipeline.predict(X_test)\n# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': test_preds})\noutput.to_csv(\"30_Days_ML_Challenge.csv\", index=False)","97d96fa5":"# 3. Preparing the Data for Model Building and pipeline\n","73d82ac2":"# 1. Importing Libraries","dfa950a8":"**Step 2. Define the model**","5f6c2d9f":"# 5. Predicting the test dataset","d1329aa2":"# 2. Loading and inspecting the data","893c1fff":"**Step 3. Create and Evaluate the pipeline**","fef6607f":"# 4. Preparing the Pipeline\n**Step 1. Define the preprocessing steps**"}}