{"cell_type":{"03faa622":"code","9e1e4231":"code","88384bce":"code","486c2117":"code","b3a16694":"code","62175b5c":"code","9db7b511":"code","e5c370fc":"code","8e81039c":"code","5dc749a8":"code","ca173a99":"code","733ac333":"code","fb0c5896":"code","1e79f10e":"code","e87720b5":"code","af2cb08a":"code","756d00ae":"markdown","52dec9cc":"markdown","bf9dbcd8":"markdown","401d6af9":"markdown","fc6fae58":"markdown","929c4087":"markdown"},"source":{"03faa622":"import numpy as np \nimport pandas as pd \nimport cv2\nimport time\nimport random\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom skimage.feature import hog\nimport os\nimport re\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split , GridSearchCV\nfrom sklearn.metrics import confusion_matrix, classification_report , accuracy_score","9e1e4231":"t1=time.time()\nfolderpath=\"..\/input\/pins-face-recognition\/pins\/PINS\/\"\ncascade = \"..\/input\/haarcascadefrontalfaces\/haarcascade_frontalface_default.xml\"\nheight=128\nwidth=64\ndata=[]\nlabels=[]\nCelebs=[]","88384bce":"for dirname,_, filenames in tqdm(os.walk(folderpath)):\n    for filename in filenames:\n        image = cv2.imread(os.path.join(dirname, filename))\n        image= cv2.resize(image , (width,height))\n        labels.append(dirname.split(\"\/\")[-1])\n        data.append(image)","486c2117":"fig = plt.figure(figsize=(20,15))\n\nfor i in range(1,10):\n    index = random.randint(0,10769) #https:\/\/www.pythoncentral.io\/how-to-generate-a-random-number-in-python\/\n    plt.subplot(3,3,i)\n    plt.imshow(data[index])\n    plt.xlabel(labels[index].split(\"_\")[1])\nplt.show()","b3a16694":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nLabels= le.fit_transform(labels)","62175b5c":"data_gray = [cv2.cvtColor(data[i] , cv2.COLOR_BGR2GRAY) for i in range(len(data))]","9db7b511":"fig = plt.figure(figsize=(20,15))\n\nfor i in range(1,10):\n    index = random.randint(1,10770) #https:\/\/www.pythoncentral.io\/how-to-generate-a-random-number-in-python\/\n    plt.subplot(3,3,i)\n    plt.imshow(data_gray[index])\n    plt.xlabel(Labels[index])\nplt.show()","e5c370fc":"Labels = np.array(Labels).reshape(len(Labels),1)","8e81039c":"ppc =8\ncb=4\nhog_features=[]\nhog_image=[]\nfor image in tqdm(data_gray):\n    fd , hogim = hog(image , orientations=9 , pixels_per_cell=(ppc , ppc) , block_norm='L2' , cells_per_block=(cb,cb) , visualize=True)\n    hog_image.append(hogim)\n    hog_features.append(fd)","5dc749a8":"fig = plt.figure(figsize=(20,15))\n\nfor i in range(1,10):\n    index = random.randint(1,10770)\n    plt.subplot(3,3,i)\n    plt.imshow(hog_image[index])\n    plt.xlabel(Labels[index])\nplt.show()","ca173a99":"hog_features = np.array(hog_features)\ndf = np.hstack((hog_features,Labels))","733ac333":"X_train , X_test , Y_train , Y_test = train_test_split(df[:,:-1] ,\n                                                       df[:,-1], \n                                                       test_size=0.3 , \n                                                       random_state=0 , \n                                                       stratify=df[:,-1])","fb0c5896":"from sklearn.decomposition import PCA\nt= time.time()\npca = PCA(n_components=150 , svd_solver='randomized' , whiten=True).fit(X_train)\nprint(\"Time evolved\", time.time()-t)","1e79f10e":"print(\"Projecting the input data on the orthonormal basis\")\nt0 = time.time()\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)\nprint(\"done in %0.3fs\" % (time.time() - t0))","e87720b5":"t3=time.time()\nsvm = SVC(kernel='rbf' , class_weight='balanced' , C=1000 , gamma=0.0082)\nsvm.fit(X_train_pca , Y_train)\nprint(svm.score(X_test_pca , Y_test))\nprint(\"done in %0.3fs\" % (time.time() - t3))","af2cb08a":"\nprint(\"total time evolved\", (time.time()-t1))","756d00ae":">  ## HOG Descriptor\n\nLet\u2019s look at some important aspects of HOG that makes it different from other feature descriptors:\n\n* The HOG descriptor focuses on the structure or the shape of an object. Now you might ask, how is this different from the edge features we extract for images? In the case of edge features, we only identify if the pixel is an edge or not. **HOG is able to provide the edge direction as well.** This is done by extracting the gradient and orientation (or you can say magnitude and direction) of the edges\n* Additionally, these orientations are calculated in **\u2018localized\u2019** portions. This means that the complete image is broken down into smaller regions and for each region, the gradients and orientation are calculated. We will discuss this in much more detail in the upcoming sections\n* Finally the HOG would generate a **Histogram** for each of these regions separately. The histograms are created using the gradients and orientations of the pixel values, hence the name \u2018Histogram of Oriented Gradients\u2019 \n\nSOURCE: <https:\/\/www.analyticsvidhya.com\/blog\/2019\/09\/feature-engineering-images-introduction-hog-feature-descriptor\/>\n\nUsing HOG function from skimage.\n* if you set the parameter \u2018visualize = True\u2019, it will return an image of the HOG.\n\n+++++++ ======================================================= ++++++++\n\nBefore going ahead, let me give you a basic idea of what each of these hyperparameters represents.\n* The orientations are the number of buckets we want to create. Since I want to have a 9 x 1 matrix, I will set the orientations to 9\n\n* pixels_per_cell defines the size of the cell for which we create the histograms.We used 8 x 8 cells and you can choose to change this value.\n\n* We have another hyperparameter cells_per_block which is the size of the block over which we normalize the histogram. Here, we mention the cells per blocks and not the number of pixels. So, instead of writing 32 x 32, we will use 2 x 2 here.","52dec9cc":">  ENCODING THE LABELS","bf9dbcd8":"> VISUALISING HOG IMAGES","401d6af9":">  Using PCA for dimension reduction","fc6fae58":">  Converting to grayscale images","929c4087":">  ## Create SVM model to fit"}}