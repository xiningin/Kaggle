{"cell_type":{"484affd7":"code","4523d8e6":"code","89718451":"code","9194e151":"code","e9a96ef6":"code","37e18e61":"code","f3df9768":"code","e57bd05c":"code","078197b2":"code","9beac01c":"code","37385016":"code","128d001b":"code","931589fa":"code","8e79b4bd":"code","e17cb30f":"code","5a7d7f45":"code","7dd9117f":"code","21beeb37":"code","199ef05d":"code","293e65d1":"code","013a5806":"code","dc4ad4fe":"code","cea8549f":"code","6cd6fb63":"code","272a8029":"code","d64c8fd5":"code","4e304a55":"code","4ed49c1f":"code","d91b0124":"code","4ba99568":"code","283fdc96":"code","0a143259":"code","878040e9":"code","a277d10b":"code","1dd0c173":"code","6068f87e":"code","2fe98c2a":"code","fa4791a3":"code","56e8c92f":"code","e90584a1":"code","80d601b8":"code","d5bda557":"code","58a62928":"code","c3233e6e":"code","0ce72475":"code","6b4d3ff4":"code","df480d4f":"code","d97dfa00":"code","ac70f19d":"code","e0db5743":"markdown","cf9125ef":"markdown","e319c67d":"markdown","f38a26cf":"markdown"},"source":{"484affd7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\nimport string\nimport os\n\n\nfrom bs4 import BeautifulSoup\nfrom textblob import TextBlob","4523d8e6":"# Import true and fake data","89718451":"true = pd.read_csv('..\/input\/fake-and-real-news-dataset\/True.csv', index_col=False)\nfake = pd.read_csv('..\/input\/fake-and-real-news-dataset\/Fake.csv', index_col=False)","9194e151":"# Some info about dataframes:","e9a96ef6":"true.head()","37e18e61":"fake.head()","f3df9768":"true.info()","e57bd05c":"fake.info()","078197b2":"# As we can see, totally we have something about 50k news divided by \n# fake and not fake news\n# Let's check some null values in dataframes:","9beac01c":"true.isna().sum()","37385016":"fake.isna().sum()","128d001b":"# Okay, now we can concatenate our data's , but before we'll do it, we need \n# to mark them by 1 and 0 (true \/ fake)","931589fa":"true['target'] = 0","8e79b4bd":"true.head()","e17cb30f":"fake['target'] = 1","5a7d7f45":"fake.head()","7dd9117f":"# let's concatenate our data","21beeb37":"df = [true, fake]\n\n# Ignore index\ndata = pd.concat(df, ignore_index=True)","199ef05d":"# words count\ndef words_count(df):\n    length = len(str(df).split())\n    return length\n\n# characters count\n\ndef char_count(df):\n    string = df.split()\n    x = ''.join(string)\n    return len(x)\n\n# hashtags count\n\ndef hashtag_count(df):\n    hashtag = len([t for t in df.split() if t.startswith('#')])\n    return hashtag\n\n# email count\n\ndef email_count(df):\n    email = len([t for t in df.split() if t.startswith('@')])\n    return email\n\n# digits count\n\ndef digits_count(df):\n    digits = re.findall(r'[0-9]+', df)\n    return digits\n","293e65d1":"def get_features(df):\n    df['words_count'] = df['text'].apply(lambda x: words_count(x))\n    df['char_count'] = df['text'].apply(lambda x: char_count(x))\n    df['hashtags_count'] = df['text'].apply(lambda x: hashtag_count(x))\n    df['email_counts'] = df['text'].apply(lambda x: email_count(x))\n    df['digits_count'] = df['text'].apply(lambda x: digits_count(x))\n    \n    return df","013a5806":"data = get_features(data)","dc4ad4fe":"data.head()","cea8549f":"plt.style.use('ggplot')\n\nplt.rcParams['figure.figsize'] = [8,4]\nplt.rcParams['figure.dpi'] = 120","6cd6fb63":"# Value count on sns.countplot\n\nsns.countplot('target', data=data)\nplt.title('Counts')","272a8029":"sns.catplot(x='target', y='words_count', kind='bar', data=data)\nplt.xlabel('0 - True news  ||  Fake news - 1')\nplt.title('Correlation between number of words and target')","d64c8fd5":"# As we can see, fake news have more words count","4e304a55":"sns.catplot(x='target', y='hashtags_count', kind='bar', data=data)\nplt.xlabel('0 - True news  ||  Fake news - 1')\nplt.title('Correlation between hashtags and target')","4ed49c1f":"sns.catplot(x='target', y='email_counts', kind='bar', data=data)\nplt.xlabel('0 - True news  ||  Fake news - 1')\nplt.title('Correlation between email and target')","d91b0124":"plt.rcParams['figure.figsize'] = [12,8]\n\nsns.catplot(x='target', y='words_count', kind='bar', data=data, hue='subject')\nplt.xlabel('0 - True news  ||  Fake news - 1')","4ba99568":"data['text'][1]","283fdc96":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem.porter import *\n\np_stemming = PorterStemmer()","0a143259":"def nltk_process(data):\n    # Tokenization\n    tokenList = word_tokenize(data)\n    \n    # Stemming\n    stemedList = []\n    for word in tokenList:\n        stemedList.append(p_stemming.stem(word))\n\n    # Lemmatization\n    wordnet_lemmatizer = WordNetLemmatizer()\n    lemmaList = []\n    for word in stemedList:\n        lemmaList.append(wordnet_lemmatizer.lemmatize(word))\n        \n    # Stopwords\n    filtered_words = []\n    nltk_stop_words = set(stopwords.words(\"english\"))\n    for word in lemmaList:\n        if word not in nltk_stop_words:\n            filtered_words.append(word)\n    \n    # Remove punct.\n    \n    for word in filtered_words:\n        if word in string.punctuation:\n            filtered_words.remove(word)\n    \n    return filtered_words","878040e9":"data['text'][1]","a277d10b":"%%time\ndata['text'] = data['text'].apply(lambda x: nltk_process(x))","1dd0c173":"data['text'][1]","6068f87e":"type(data['text'][1])","2fe98c2a":"data['text'] = [\" \".join(text) for text in data['text'].values]","fa4791a3":"data['text'][1]","56e8c92f":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","e90584a1":"tfidf = TfidfVectorizer(lowercase=False, stop_words='english')","80d601b8":"text = data['text']\nX = tfidf.fit_transform(text)\ny = data['target']","d5bda557":"data.head()","58a62928":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 777)","c3233e6e":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","0ce72475":"from sklearn.svm import LinearSVC","6b4d3ff4":"clf_svc = LinearSVC()\nclf_svc.fit(X_train, y_train)\ny_pred = clf_svc.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","df480d4f":"print(confusion_matrix(y_test, y_pred))","d97dfa00":"clf_svc.score(X_test, y_test)","ac70f19d":"# Accuracy on the test set is near to 100%","e0db5743":"# Data Cleaning","cf9125ef":"# TF_IDF","e319c67d":"# Support Vector Machine","f38a26cf":"# EDA"}}