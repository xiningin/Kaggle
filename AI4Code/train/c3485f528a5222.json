{"cell_type":{"a12ec9a5":"code","e366312a":"code","6ad11b8c":"code","bd98f373":"code","0b1d06a9":"code","15fb47bb":"code","73c99139":"code","478974b3":"code","35e70e5e":"code","330b6d88":"code","6906448c":"code","af13e1aa":"code","8aab929a":"code","c17b138d":"code","f3685d02":"code","054b851b":"code","b220338c":"code","0ae65780":"code","437d50b8":"code","2f6ba3d3":"code","dcdbe9a3":"code","f5b78748":"code","af3a91d9":"code","294bc840":"code","8b84d9f0":"code","790fc7e7":"code","a06c261f":"code","36c182a4":"code","79a195f2":"code","12c898d4":"markdown","2baa1e59":"markdown","2a996548":"markdown","fe3d02c4":"markdown","dc4bb5b8":"markdown","26a29c4f":"markdown","b114f40f":"markdown","af1b93a9":"markdown","8df322b8":"markdown","ad248f92":"markdown"},"source":{"a12ec9a5":"import os\nimport numpy as np\nimport pandas as pd\nimport math\nimport shutil\nimport csv\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score, average_precision_score, classification_report, confusion_matrix, plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Dropout, GlobalAveragePooling2D, Conv2D, MaxPooling2D, BatchNormalization, Activation\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, preprocess_input, decode_predictions\n# from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n# from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input, decode_predictions\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, LearningRateScheduler","e366312a":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nelse:\n    print('Found GPU at: {}'.format(device_name))\n    physical_devices = tf.config.list_physical_devices('GPU')\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)","6ad11b8c":"path = '..\/input\/chest-xray-pneumonia\/chest_xray\/'\ndestination = '.\/'\n\nwith open('.\/train.csv', 'w+', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(['image_path', 'label'])\n    for s in ['train\/','val\/']:\n        for root, dirs, files in os.walk(path + s):\n            for f in files:\n                fullpath = os.path.join(root, f)\n                \n                if fullpath.split('\/')[-2] == 'NORMAL':\n                    label = '0'\n                else:\n                    label = '1'\n                    \n                writer.writerow([fullpath, label])\n                \nwith open('.\/test.csv', 'w+', newline='') as csvfile:\n    writer = csv.writer(csvfile)\n    writer.writerow(['image_path', 'label'])\n    for s in ['test\/']:\n        for root, dirs, files in os.walk(path + s):\n            for f in files:\n                fullpath = os.path.join(root, f)\n                \n                if fullpath.split('\/')[-2] == 'NORMAL':\n                    label = '0'\n                else:\n                    label = '1'\n                    \n                writer.writerow([fullpath, label])\n\nprint(\"done\")","bd98f373":"data_dir = \".\/\"\nlabels = ['NORMAL','PNEUMONIA']\nBATCH_SIZE = 16\nIMG_SIZE = (224, 224)","0b1d06a9":"pd.set_option('max_colwidth', 800)\ndf = pd.read_csv('.\/train.csv')\ntest_df = pd.read_csv('.\/test.csv')\n\ndf.head(3)","15fb47bb":"df['label'] = df['label'].astype('str')\ntest_df['label'] = test_df['label'].astype('str')","73c99139":"neg, pos = np.bincount(df['label'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos \/ total))","478974b3":"train_df, valid_df = train_test_split(df, test_size=0.20, random_state=13, stratify=df['label'])\nlen(train_df), len(valid_df)","35e70e5e":"neg, pos = np.bincount(train_df['label'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos \/ total))","330b6d88":"weight_for_0 = (1 \/ neg) * (total \/ 2.0)\nweight_for_1 = (1 \/ pos) * (total \/ 2.0)\n\nclass_weights = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","6906448c":"bool_train_labels = train_df['label']!='0'\n\npos_features = train_df['image_path'][bool_train_labels]\nneg_features = train_df['image_path'][~bool_train_labels]\n\npos_labels = train_df['label'][bool_train_labels]\nneg_labels = train_df['label'][~bool_train_labels]\n\nlen(pos_features), len(neg_features)","af13e1aa":"ids = np.arange(len(pos_features))\nchoices = np.random.choice(ids, len(neg_features))\n\nres_pos_features = pos_features[pos_features.index[choices]]\nres_pos_labels = pos_labels[pos_labels.index[choices]]\n\nres_pos_features.head(3)","8aab929a":"resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\nresampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n\norder = np.arange(len(resampled_labels))\nnp.random.shuffle(order)\nresampled_features = resampled_features[order]\nresampled_labels = resampled_labels[order]\n\nresampled_data = {'image_path': resampled_features,\n        'label': resampled_labels\n        }\n\nresampled_df = pd.DataFrame(resampled_data, columns = ['image_path', 'label'])\nresampled_df.head(3)","c17b138d":"train_datagen = ImageDataGenerator(\n#     rescale=1.\/255,\n    preprocessing_function=preprocess_input,\n    rotation_range=20,\n#     width_shift_range=0.2,\n#     height_shift_range=0.2,\n    brightness_range=[0.6, 1.3],\n    shear_range=0.3,\n    zoom_range=[0.8, 1.0],\n#     horizontal_flip=True,\n#     vertical_flip=True,\n    fill_mode='constant'\n)\n\ntest_datagen = ImageDataGenerator(\n#     rescale=1.\/255,\n    preprocessing_function=preprocess_input,\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n                                        dataframe=train_df,\n                                        x_col='image_path',\n                                        y_col='label',\n                                        class_mode='binary',\n                                        target_size=IMG_SIZE,\n                                        batch_size=BATCH_SIZE)\n\nvalidation_generator = test_datagen.flow_from_dataframe(\n                                        dataframe=valid_df,\n                                        x_col='image_path',\n                                        y_col='label',\n                                        class_mode='binary',\n                                        shuffle=False,\n                                        target_size=IMG_SIZE,\n                                        batch_size=BATCH_SIZE)\n\ntest_generator = test_datagen.flow_from_dataframe(\n                                        dataframe=test_df,\n                                        x_col='image_path',\n                                        y_col='label',\n                                        class_mode='binary',\n                                        shuffle=False,\n                                        target_size=IMG_SIZE,\n                                        batch_size=BATCH_SIZE)","f3685d02":"fig, axes = plt.subplots(1, 3)\nfig.tight_layout()\n\nfor i in range(3):\n    img, label = train_generator.next()\n    axes[i].set_title(label[0])  \n    axes[i].imshow(img[0].astype(int))","054b851b":"IMG_SHAPE = IMG_SIZE + (3,)\ndr = 0.4\n\nbase_model = EfficientNetB0(\n    weights='imagenet',\n    input_shape=IMG_SHAPE,\n    include_top=False,\n    drop_connect_rate=dr\n)\n\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    BatchNormalization(),\n    Dropout(dr),\n    \n#     Dense(64),\n#     BatchNormalization(),\n#     Activation(\"relu\"),\n#     Dropout(dr),\n    \n    Dense(1),\n    BatchNormalization(),\n    Activation(\"sigmoid\"),\n])\n\nmodel.summary()","b220338c":"metrics = [\n    tf.keras.metrics.BinaryAccuracy(name=\"binary_acc\"),\n    tf.keras.metrics.AUC(name=\"AUC\"),\n    tf.keras.metrics.Precision(name=\"precision\"),\n    tf.keras.metrics.Recall(name=\"recall\"),\n]\n\nmodel.compile(optimizer=Adam(learning_rate=1e-3),\n              loss=BinaryCrossentropy(),\n              metrics=metrics)","0ae65780":"callbacks = [\n#              ModelCheckpoint(\"model_at_epoch_{epoch}.h5\"),\n#              ReduceLROnPlateau(monitor='val_loss',\n#                             patience=2,\n#                             verbose=1,\n#                             factor=0.07,\n#                             min_lr=1e-9),\n             EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n]\n\nhistory = model.fit(train_generator, \n                    epochs=10,\n                    batch_size=BATCH_SIZE,\n                    callbacks=callbacks,\n                    validation_data=validation_generator,\n                    class_weight=class_weights\n)","437d50b8":"def plot_metrics(history, name, bot=0.0, top=0.0):\n    plt.plot(history.history[name])\n    plt.plot(history.history['val_'+name])\n    plt.title('Model '+name)\n    plt.ylabel(name)\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Test'], loc='upper left')\n    if top != 0.0:\n        plt.ylim([bot, top])\n    plt.show()\n\nplot_metrics(history, 'loss')\nfor i in range(len(metrics)):\n    plot_metrics(history, metrics[i].name, 0.5, 1.0)","2f6ba3d3":"print(\"Number of layers in the base model: \", len(base_model.layers))","dcdbe9a3":"for layer in base_model.layers:\n    if not isinstance(layer, BatchNormalization):\n        layer.trainable = True","f5b78748":"metrics = [\n#     tf.keras.metrics.BinaryAccuracy(name=\"bin_acc\"),\n    tf.keras.metrics.AUC(name=\"AUC\"),\n    tf.keras.metrics.Precision(name=\"precision\"),\n    tf.keras.metrics.Recall(name=\"recall\"),\n]\n\nmodel.compile(optimizer=Adam(learning_rate=1e-4),\n              loss=BinaryCrossentropy(),\n              metrics=metrics)","af3a91d9":"callbacks = [\n#              ModelCheckpoint(\"model_at_epoch_{epoch}.h5\"),\n#              ReduceLROnPlateau(monitor='val_loss',\n#                             patience=2,\n#                             verbose=1,\n#                             factor=0.07,\n#                             min_lr=1e-9),\n             EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n            ]\n\nhistory = model.fit(train_generator, \n                    epochs=15,\n#                     steps_per_epoch=resampled_steps_per_epoch,\n                    batch_size=BATCH_SIZE,\n                    callbacks=callbacks,\n                    validation_data=validation_generator,\n#                     class_weight=class_weights\n                   )","294bc840":"plot_metrics(history, 'loss')\nfor i in range(len(metrics)):\n    plot_metrics(history, metrics[i].name, 0.5, 1.0)","8b84d9f0":"model.evaluate(test_generator, batch_size=BATCH_SIZE)","790fc7e7":"Y_pred = model.predict(test_generator, batch_size=BATCH_SIZE)\n\ny_pred = np.rint(Y_pred)","a06c261f":"conf_matrix = confusion_matrix(test_generator.classes, y_pred)\n\nplt.matshow(conf_matrix, cmap=plt.cm.Blues)\nfor (i, j), z in np.ndenumerate(conf_matrix):\n    plt.text(j, i, z, ha='center', va='center')","36c182a4":"print('Classification Report')\ntarget_names = ['0','1']\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","79a195f2":"def plot_top_losses(actual, pred, k=9, figsize=(10,10)):\n    loss = BinaryCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n    loss_values = loss(actual, pred).numpy()\n    top_k = loss_values.argsort()[-k:][::-1]\n    cols = math.ceil(math.sqrt(k))\n    rows = math.ceil(k\/cols)\n    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n    fig.suptitle('Prediction\/Actual\/Loss\/Prediction_Probability', weight='bold', size=14)\n    fig.tight_layout()\n    for i, index in enumerate(top_k):\n        image = validation_generator[int(index\/16)][0][index%16]\n        actual = validation_generator.classes[index]\n        loss_value = loss_values[index]\n        predicted = np.argmax(pred[index])\n        prob = pred[index][predicted]\n        title = f'{predicted}\/{actual}\/{loss_value:.2f}\/{prob:.2f}'\n        ax = axes.flat[i]\n        ax.imshow(image.astype(int))\n        ax.set_title(title)\n        \nplot_top_losses(test_generator.classes, Y_pred, 9)","12c898d4":"## Plot Top Losses","2baa1e59":"# Calculate Class Weight (Optional)","2a996548":"## Fine-tuning Model","fe3d02c4":"# Make CSV","dc4bb5b8":"# Data Preprocessing","26a29c4f":"# Build and Train Model","b114f40f":"# Evaluate Model","af1b93a9":"# Oversampling (Optional)","8df322b8":"## Plot Confusion Matrix","ad248f92":"# Image Data Generator"}}