{"cell_type":{"51f63318":"code","b3302c82":"code","5020944d":"code","4dce7f91":"code","48353149":"code","f9f9286d":"code","ef55cff8":"code","a6ef51e5":"code","d08f4ab0":"markdown","33f4a737":"markdown","4e73a923":"markdown","55ef8296":"markdown","0345f095":"markdown","49218000":"markdown","f0fec351":"markdown","6285a75e":"markdown","43575bab":"markdown","c9c04fc3":"markdown"},"source":{"51f63318":"import pandas as pd\n\ndf = pd.read_csv('..\/input\/iris-data\/Iris.csv')\ndf.head()","b3302c82":"#eleminiting the Id column\ndf = df.drop(['Id'],axis=1)\n#df.head()\ntarget = df['Species']\n#target.head()\ns = set()\nfor val in target:\n    s.add(val)\ns = list(s)\nprint(s)","5020944d":"rows = list(range(100,150))\ndf = df.drop(df.index[rows])\ndf.head()","4dce7f91":"import matplotlib.pyplot as plt\n\nx = df['SepalLengthCm'] #feature 1\ny = df['PetalLengthCm'] #feature 2\n\nsetosa_x = x[:50]\nsetosa_y = y[:50]\n\nversicolor_x = x[50:]\nversicolor_y = y[50:]\n\nplt.figure(figsize=(8,6))\nplt.scatter(setosa_x,setosa_y,marker='+',color='green')\nplt.scatter(versicolor_x,versicolor_y,marker='_',color='red')\nplt.show()","48353149":"from sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n## Drop rest of the features and extract the target values\ndf = df.drop(['SepalWidthCm','PetalWidthCm'],axis=1)\nY = []\ntarget = df['Species']\n\n#assigning value in y according to class\nfor val in target:\n    if(val == 'Iris-setosa'):\n        Y.append(-1)\n    else:\n        Y.append(1)\n        \ndf = df.drop(['Species'],axis=1)\nX = df.values.tolist()\n## Shuffle and split the data into training and test set\nX, Y = shuffle(X,Y)\nx_train = []\ny_train = []\nx_test = []\ny_test = []\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.9)\n\nx_train = np.array(x_train)\ny_train = np.array(y_train)\nx_test = np.array(x_test)\ny_test = np.array(y_test)\n\ny_train = y_train.reshape(90,1)\ny_test = y_test.reshape(10,1)","f9f9286d":"## Support Vector Machine \nimport numpy as np\n\ntrain_f1 = x_train[:,0]\ntrain_f2 = x_train[:,1]\n\ntrain_f1 = train_f1.reshape(90,1)\ntrain_f2 = train_f2.reshape(90,1)\n\nw1 = np.zeros((90,1))\nw2 = np.zeros((90,1))\n\nepochs = 1\nalpha = 0.0001\n\nwhile(epochs < 10000):\n    y = w1 * train_f1 + w2 * train_f2\n    prod = y * y_train\n    print(epochs)\n    count = 0\n    for val in prod:\n        if(val >= 1):\n            cost = 0\n            w1 = w1 - alpha * (2 * 1\/epochs * w1)\n            w2 = w2 - alpha * (2 * 1\/epochs * w2)\n            \n        else:\n            cost = 1 - val \n            w1 = w1 + alpha * (train_f1[count] * y_train[count] - 2 * 1\/epochs * w1)\n            w2 = w2 + alpha * (train_f2[count] * y_train[count] - 2 * 1\/epochs * w2)\n        count += 1\n    epochs += 1","ef55cff8":"from sklearn.metrics import accuracy_score\n\n## Clip the weights \nindex = list(range(10,90))\nw1 = np.delete(w1,index)\nw2 = np.delete(w2,index)\n\nw1 = w1.reshape(10,1)\nw2 = w2.reshape(10,1)\n## Extract the test data features \ntest_f1 = x_test[:,0]\ntest_f2 = x_test[:,1]\n\ntest_f1 = test_f1.reshape(10,1)\ntest_f2 = test_f2.reshape(10,1)\n## Predict\ny_pred = w1 * test_f1 + w2 * test_f2\npredictions = []\nfor val in y_pred:\n    if(val > 1):\n        predictions.append(1)\n    else:\n        predictions.append(-1)\n\nprint(accuracy_score(y_test,predictions))\nprint(accuracy_score(y_test,predictions,normalize=False))\n","a6ef51e5":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\nclf = SVC(kernel='linear')\nclf.fit(x_train,y_train)\ny_pred = clf.predict(x_test)\nprint(accuracy_score(y_test,y_pred))\n#print(clf.score(x_train,y_train))","d08f4ab0":"**accuracy_score :** take test set output and porediction set then calculate accuracy\n\nreturn -> If normalize == True, return the fraction of correctly classified samples                              (float), else returns the number of correctly classified samples (int).\n\nThe best performance is 1 with normalize == True and the number of samples with normalize == False.","33f4a737":"find the class of species from the dataset . ","4e73a923":"as there is 3 class so elemenating one to make it binary class classification problem .","55ef8296":"afer training , use the test set to calculate the accuracy .","0345f095":"# SVM Implementation in Python","49218000":"The dataset we will be using to implement our SVM algorithm is the Iris dataset.\nfirst load the dataset and show 1st 5 row.","f0fec351":"1st initialize weight of feature 1 and 2 with zero .then compute the forward propagation . if the classification can classify accurate then use back propagation as \n![1_-nKEXrWos8Iuf-DWSv_srQ.png](attachment:1_-nKEXrWos8Iuf-DWSv_srQ.png)\nand if there is misclassification then \n![1_tnvMhAKaTUCO43diEvtTAQ.png](attachment:1_tnvMhAKaTUCO43diEvtTAQ.png)\nhere lemda = 1\/epochs","6285a75e":"Take two feature such as **SepalLengthCm** and **PetalLengthCm** from four feature and draw it in graph . A linear line can be use to separate the data point in 2 class .","43575bab":"# using scikit learn library\n","c9c04fc3":"preaparing the test set and training set of data . extracting the required features and split it into training and testing data. 90% of the data is used for training and the rest 10% is used for testing."}}