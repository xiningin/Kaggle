{"cell_type":{"a3f73710":"code","ca5efbe4":"code","5682c2af":"code","c7513a91":"code","f0df6a02":"code","8acbc84a":"code","446c007c":"code","fa5be046":"code","6391d924":"code","baa146b6":"code","25a363f3":"code","f831e80c":"code","48e62499":"code","3df34c17":"code","956f53e1":"code","00567669":"code","f63c54a7":"code","4af95f69":"code","79d1f7e6":"code","207a1a77":"code","73a600d4":"markdown","b59d81f6":"markdown","8532262c":"markdown","345b3e5a":"markdown","e198bd79":"markdown"},"source":{"a3f73710":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ca5efbe4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_confusion_matrix","5682c2af":"Data = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")\nData.head(5)","c7513a91":"Data.info()","f0df6a02":"Data.shape","8acbc84a":"Data.describe()","446c007c":"print(\"Class 0 Count : \",Data[Data['Class']==0].shape[0])\nprint(\"Class 1 Count : \",Data[Data['Class']==1].shape[0])","fa5be046":"from sklearn.model_selection import train_test_split\nX_train , X_test , Y_train , Y_test = train_test_split(Data.iloc[:,:-1],Data.iloc[:,-1])\ntrain = pd.concat([X_train, Y_train], axis=1)\ntest = pd.concat([X_test, Y_test], axis=1)\nprint(train,\"\\n\")\nprint(test,\"\\n\")","6391d924":"class0 = train[train['Class']==0]\nclass1 = train[train['Class']==1]\n\ncl0 = test[test['Class']==0]\ncl1 = test[test['Class']==1]","baa146b6":"from sklearn.utils import resample\nundersample = resample(class0, \n                       replace=True, \n                       n_samples=len(class1), #set the number of samples to equal the number of the minority class\n                       random_state=42)\n\nundersample_train = pd.concat([class1, undersample])\nundersample_train.Class.value_counts(normalize=True)\n\nundersample_test = resample(cl0,\n                            replace=True, \n                            n_samples=len(cl1), #set the number of samples to equal the number of the minority class\n                            random_state=42)\nundersample_test = pd.concat([class1, undersample])\nundersample_test.Class.value_counts(normalize=True)","25a363f3":"Xtr = undersample_train.iloc[:,:-1]\nYtr = undersample_train.iloc[:,-1]\nprint(Xtr,\"\\n\")\nprint(Ytr,\"\\n\")","f831e80c":"models={'Logistic':LogisticRegression(),\n        'Ridge':RidgeClassifier(),\n        'KNN':KNeighborsClassifier(),\n        'SVM':SVC(),\n        'Bagging':BaggingClassifier(),\n        'RandomForest':RandomForestClassifier()}","48e62499":"HyperGrid = {\n    'Logistic':dict(solver=['newton-cg', 'lbfgs', 'liblinear']\n                    ,penalty=['l2'],C=[100, 10, 1.0, 0.1, 0.01]),\n    'Ridge':dict(alpha=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n    'KNN':dict(n_neighbors=range(1, 21, 2),\n               weights=['uniform', 'distance'],\n               metric=['euclidean', 'manhattan', 'minkowski']),\n    'SVM':dict(kernel=['poly', 'rbf', 'sigmoid'],\n               C=[50, 10, 1.0, 0.1, 0.01],\n               gamma=['scale']),\n    'Bagging':dict(n_estimators=[10, 100, 1000]),\n    'RandomForest':dict(n_estimators=[10, 100, 1000],\n                        max_features=['sqrt', 'log2']),\n}","3df34c17":"cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\nfitted_model={}","956f53e1":"for model in models.keys():\n    GS=GridSearchCV(estimator=models[model], param_grid=HyperGrid[model], \n                    n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n    try:\n        print('Starting training for {}.'.format(model))\n        GS.fit(Xtr, Ytr)\n        fitted_model[model] = GS\n        print('{} has been successfully fit.'.format(model))\n    except NotFittedError as e:\n        print(repr(e))","00567669":"for model in fitted_model.keys():\n    print(\"Best: %f using %s\" % (fitted_model[model].best_score_, fitted_model[model].best_params_))","f63c54a7":"for model in fitted_model.keys():\n    print(\"Best model : \"+str(fitted_model[model].best_estimator_))","4af95f69":"bestModels_predictions = {}\nXte = undersample_test.iloc[:,:-1]\nYte = undersample_test.iloc[:,-1]","79d1f7e6":"for model in fitted_model.keys():\n    bestModels_predictions[model]=fitted_model[model].best_estimator_.predict(Xte)\nfor model in bestModels_predictions.keys():\n    print(model)\n    print(classification_report(bestModels_predictions[model],Yte))\n    print(\"\\n\\n\")","207a1a77":"fig, axs = plt.subplots(2, 3,figsize=(15,15));k=0;m=list(bestModels_predictions.keys())\nbest_model =[fitted_model[i].best_estimator_ for i in fitted_model.keys()]\nfor i in range(2):\n    for j in range(3):\n        axs[i,j].set_title(m[k])\n        plot_confusion_matrix(best_model[k],\n                              Xtr,Ytr,ax=axs[i,j])\n        k+=1","73a600d4":"* Class 0 Count : Not Fraud = 284315\n* Class 1 Count : Fraud = 492","b59d81f6":"**CONCLUSION**\n\nFrom the Above Confusion Matrix for models we can see that the given Models like KNN,Bagging and Random Forest have the best fit and can be used.","8532262c":"The Data.info() shows us that, all the labels present in the dataset have float values and there are no missing values present in the dataset.","345b3e5a":"* Features(V1-V28) are a just result of PCA transformation & simple numerical representations.\n* \"Amount\" is the value in dollars of the transaction.\n* \"Time\" variable is the amount of time that passed from the time when the transaction took place.\n* There are 492 Frauds out of 284,807 transactions.","e198bd79":"Applying the Models."}}