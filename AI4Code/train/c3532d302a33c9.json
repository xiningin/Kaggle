{"cell_type":{"72aa6a9f":"code","e3ce9225":"code","88bd7962":"code","5f7c880c":"code","c77ece67":"code","5cc973f1":"code","25c0536f":"code","0f275151":"code","09daef7d":"code","32161eb9":"code","e2d2c38c":"code","c7cf96e5":"code","153dd582":"code","b6ca6656":"code","fee21c66":"code","7ccea774":"code","a89bf2f2":"code","e766f1af":"code","f7a22c0b":"code","6950e1ab":"code","5b163056":"code","080c36ef":"code","fa4cb673":"code","ef2d298b":"code","ed27bf96":"code","b496dfad":"code","59d5c12e":"code","47e22b6d":"code","41bba877":"code","a8a5be1e":"code","02007891":"code","a1289d01":"code","fbb41ff3":"code","2dc2d8ca":"code","03cf5233":"code","b843f468":"code","de5cd6e8":"code","dd42ebae":"code","f4704a42":"code","09185851":"code","4d5d755b":"code","0486dfd3":"code","1efb1866":"code","2fdefca6":"markdown","c4749040":"markdown"},"source":{"72aa6a9f":"import matplotlib.image as mpimg\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# advanced ploting\nimport seaborn as sns","e3ce9225":"import warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\n# Image manipulations\nfrom PIL import Image\n\n# Timing utility\nfrom timeit import default_timer as timer\n\nfrom IPython.core.interactiveshell import InteractiveShell\n\n# Printing out all outputs\nInteractiveShell.ast_node_interactivity = 'all'","88bd7962":"import torchvision\nfrom torchvision import transforms, datasets, models\n\nimport torch\nimport matplotlib.pyplot as plt\nimport os\nfrom torch import optim, cuda\nfrom torch.utils.data import DataLoader, sampler\nfrom torch.autograd import Variable\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d\nfrom torch.nn import Module, Softmax, BatchNorm2d, Dropout\n\nimport gc","5f7c880c":"os.listdir('..\/input\/ptbdb-ecg\/PTB\/train')","c77ece67":"ECG_list = os.listdir('..\/input\/ptbdb-ecg\/PTB\/train')\n\nn_classes = len(ECG_list)\n\nprint(f'There are {n_classes} different classes.')","5cc973f1":"ECG_list","25c0536f":"N_imgs = os.listdir('..\/input\/ptbdb-ecg\/PTB\/train\/N')\nprint('# of Normal beats: ',len(N_imgs))","0f275151":"M_imgs = os.listdir('..\/input\/ptbdb-ecg\/PTB\/train\/M')\nprint('number of mycardial infarction beats: ',len(M_imgs))","09daef7d":"def imshow(image):\n    \"\"\"Display image\"\"\"\n    plt.figure(figsize=(6, 6))\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()","32161eb9":"import matplotlib.image as mpimg\nimage = mpimg.imread(os.path.join('..\/input\/ptbdb-ecg\/PTB\/train\/M', M_imgs[0]))\n\nimshow(image)","e2d2c38c":"\n\nprint(image.shape)\nprint(type(image))\n\n","c7cf96e5":"# Define a function which will plot several images\n\ndef image_shows(folder, number_of_images):\n    \n    n=number_of_images;\n    \n    folder_list = os.listdir(folder)\n    \n    fig, axes = plt.subplots(nrows = 1, ncols=n, figsize=(20, 10))\n    \n    for i in range(n):\n        \n        print(os.path.join(folder, folder_list[i]))\n        \n        image = mpimg.imread(os.path.join(folder, folder_list[i]));\n        \n        axes[i].imshow(image);","153dd582":"# Examples of N\nimage_shows(folder = '..\/input\/ptbdb-ecg\/PTB\/train\/N', number_of_images = 6)","b6ca6656":"import shutil\nfrom os import walk","fee21c66":"len(os.listdir('..\/input\/ptbdb-ecg\/PTB\/train\/M')), len(os.listdir('..\/input\/ptbdb-ecg\/PTB\/test\/M'))\n","7ccea774":"len(os.listdir('..\/input\/ptbdb-ecg\/PTB\/train\/N')), len(os.listdir('..\/input\/ptbdb-ecg\/PTB\/test\/N'))","a89bf2f2":"# no. of files\n\ndef list_files(startpath):\n    \n    for root, dirs, files in os.walk(startpath):\n        \n        level = root.replace(startpath, '').count(os.sep)\n        \n        indent = ' ' * 4 * (level)\n        \n        print('{}{}'.format(indent, os.path.basename(root)), '-', len(os.listdir(root)))\n        \nfolder = '..\/input\/ptbdb-ecg\/PTB\/'\nlist_files(folder)","e766f1af":"def imshow(image):\n    \"\"\"Display image\"\"\"\n    plt.figure(figsize=(6, 6))\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()","f7a22c0b":"image = mpimg.imread(os.path.join('..\/input\/ptbdb-ecg\/PTB\/train\/M', M_imgs[0]))\n\nimshow(image)","6950e1ab":"print(image.shape)\nprint(type(image))","5b163056":"# Define default PATH\n\nTRAIN_PATH        = '..\/input\/ptbdb-ecg\/PTB\/train'\n\ntransform         = transforms.Compose(\n                                       [transforms.Resize([64,64]),\n                                        transforms.Grayscale(num_output_channels=3), \n                                        transforms.ToTensor(),\n                                        transforms.Normalize((0.5), (0.5))\n                                       ])\n  \ntrain_data_set    = datasets.ImageFolder(root=TRAIN_PATH, transform=transform)\n\nbatch_size=32\n\ntrain_data_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=True)","080c36ef":"TEST_PATH        = '..\/input\/ptbdb-ecg\/PTB\/test'\n  \ntest_data_set    = datasets.ImageFolder(root=TEST_PATH, transform=transform)\n\ntest_data_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=True)","fa4cb673":"# Run this to test your data loader\n\nimages, labels = next(iter(train_data_loader))","ef2d298b":"print(type(images))\n\nprint(images.size())\n\nprint(\"\")\nprint(\"Batch Size:   \",images.size()[0])\nprint(\"Channel Size: \",images.size()[1])\nprint(\"Image Height: \",images.size()[2])\nprint(\"Image Width:  \",images.size()[3])","ed27bf96":"device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )\ndevice","b496dfad":"import torchvision\nmodel = models.wide_resnet50_2()\nn_fltrs=model.fc.in_features\nmodel.fc=nn.Linear(n_fltrs,2)\nmodel.to(device)","59d5c12e":"# Define Criterion\n\ncriterion = nn.CrossEntropyLoss()\n\n# Define Optimizer\n\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","47e22b6d":"# Whether to train on a gpu and Number of gpus\n\nif cuda.is_available(): \n    \n    print(f'{cuda.device_count()} number of gpus are detected and available.')\n    \nelse:\n        \n    print(f'Train on gpu is not available')","41bba877":"%%time\n\n\n# This part is working\n\nif torch.cuda.is_available():\n    \n    MODEL = model.cuda()\n    CRITERION = criterion.cuda()\n    print(\"cuda\")\n    \nelse:\n    \n    MODEL = model\n    CRITERION = criterion\n    print(\"cpu\")\n\n# Train the model\n\ntotal_step = len(train_data_loader)\nloss_list = []\nacc_list = []\n\nnum_epochs = 5\n\nclass_list = ['N', 'M']\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nall_con_mat = torch.zeros([num_epochs, 2, 2], dtype=torch.int32, device=device)\n\nfor epoch in range(num_epochs):\n    \n    f1_score_list=[0,0]\n\n    precision_list=[0,0]\n\n    recall_list=[0,0]\n    \n    delta = 0.0000000000001 \n    \n    # define empty tensor 5*5 beginning of every epoch\n    # tensor [row,column]\n    con_mat = torch.zeros([2, 2], dtype=torch.int32, device=device)\n    \n    for i, data in enumerate(train_data_loader):\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # optimization\n        optimizer.zero_grad()\n        \n        # Forward to get output\n        outputs = MODEL(inputs)\n        # Calculate Loss\n        loss = CRITERION(outputs, labels)\n        # Backward propagation\n        loss.backward()\n        # Updating parameters\n        optimizer.step()\n        \n        # Store loss\n        loss_list.append(loss.item())\n    \n        # Calculate labels size\n        total = labels.size(0)\n        \n        # Outputs.data has dimension batch size * 5\n        # torch.max returns the max value of elements(_) and their indices(predicted) in the tensor array\n        _, predicted = torch.max(outputs.data, 1)\n        \n        # Calculate total number of correct labels \n        correct = (predicted == labels).sum().item()\n        \n        # Store accuracy\n        acc_list.append(correct \/ total)\n        \n        for element in range(total):\n            \n            # con_mat[row,column]\n            # con_mat[predictions, actual]\n            con_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n\n        if (i + 1) % 70 == 0:                             # every 300 mini-batches...\n            \n            print('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}, Accuracy: {:.4f}%'\n                  \n                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n                          (correct \/ total) * 100))\n    print(con_mat)\n            \n    all_con_mat[epoch] = con_mat\n    \n    # Print Confusion Matrix\n    \n    for i in range(torch.sum(con_mat, dim=0).size(0)): \n    \n        recall_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=0)[i].item()+delta)\n    \n        precision_list[i] = con_mat[i][i].item()\/(torch.sum(con_mat, dim=1)[i].item()+delta)\n    \n        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]\/(precision_list[i]+recall_list[i]+delta)\n        \n    \n        print('class name: {}, total number of class: {:>5}, Correctly predicted: {:>5}, Recall: {:.2f}%, Precision: {:.4f}%, F1-Score: {:.4f}%'\n          \n                  .format(class_list[i],\n                          torch.sum(con_mat, dim=0)[i].item(),\n                          con_mat[i][i].item(), \n                          recall_list[i],\n                          precision_list[i],\n                          f1_score_list[i]\n                         ))\n    \n            \nprint('Finished Training')\n\nplt.plot(loss_list);\nplt.show();\n\nplt.plot(acc_list);\nplt.show();","a8a5be1e":"import pandas as pd\ndf4 = pd.DataFrame(loss_list)\ndf4.to_csv(\"train_4.csv\", index=False)","02007891":"import pandas as pd\ndf2 = pd.DataFrame(acc_list)\ndf2.to_csv(\"train_acc.csv\", index=False)","a1289d01":"with plt.style.context(\"seaborn-poster\"):\n    fig, ax = plt.subplots(figsize=(12, 5));\n    plt.plot(df2,color='red',  marker='o',markerfacecolor='r', label=\"Training Acc\");\n    #plt.plot(df4,  marker='*', label=\"Validation Acc\")\n    #plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    plt.yticks(fontweight='bold');\n    plt.ylabel('Accuracy', fontsize=18, fontweight='bold');\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Accuracy history using CNN+LSTM\", fontweight='bold');\n    plt.legend();\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()\n\n","fbb41ff3":"\"\"\"with plt.style.context(\"seaborn-poster\"):\n    plt.plot(df4, color='red', linewidth=5, marker='o',\n    markerfacecolor='k', markersize=12)\n    plt.show()\"\"\";","2dc2d8ca":"with plt.style.context(\"seaborn-poster\"):\n    fig, ax = plt.subplots(figsize=(12, 5))\n    plt.plot(df4,  color='red', marker='o',  label=\"Training Loss\")\n    #plt.plot(df4[\"val_loss\"],  marker='o', label=\"Validation Loss\")\n    #plt.xticks(np.arange(0, 201, 20),fontweight='bold')\n    #plt.yticks(fontweight='bold')\n    plt.ylabel('loss', fontsize=18, fontweight='bold')\n    plt.xlabel('epochs', fontsize=18, fontweight='bold')\n    plt.title(\"Loss history using SMOTE+Tomek+CNN+LSTM\", fontweight='bold')\n    plt.legend()\n    #plt.savefig(f\"loss_history.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n    #plt.savefig(f\"loss_history.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2) \n    plt.show()","03cf5233":"%%time\n\n\nconfusion_mat = torch.zeros([2, 2], dtype=torch.int32, device=device)\n\nwith torch.no_grad():\n    \n    for data in test_data_loader:\n        \n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        outputs = MODEL(inputs)\n        \n        _, predicted = torch.max(outputs.data, 1)\n        \n        total = labels.size(0)\n        \n        # Calculate total number of correct labels \n        correct = (predicted == labels).sum().item()\n        \n        for element in range(total):\n            \n            # confusion_mat[row,column]\n            # confusion_mat[predictions, actual]\n            confusion_mat[predicted[element].item()-1][labels[element].item()-1] += 1\n\n    print(confusion_mat)","b843f468":"class_list = ['N', 'M']\n\nf1_score_list=[0,0]\n\nprecision_list=[0,0]\n\nrecall_list=[0,0]\n    \ndelta = 0.0000000000001 \n\n\nfor i in range(torch.sum(confusion_mat, dim=0).size(0)): \n    \n        recall_list[i] = confusion_mat[i][i].item()\/(torch.sum(confusion_mat, dim=0)[i].item()+delta)\n    \n        precision_list[i] = confusion_mat[i][i].item()\/(torch.sum(confusion_mat, dim=1)[i].item()+delta)\n    \n        f1_score_list[i] = 2 * precision_list[i]*recall_list[i]\/(precision_list[i]+recall_list[i]+delta)\n        \n    \n        print('class name: {}, total number of class: {:>5}, Correctly predicted: {:>5}, Recall: {:.4f}%, Precision: {:.4f}%, F1-Score: {:.4f}%'\n          \n                  .format(class_list[i],\n                          torch.sum(confusion_mat, dim=0)[i].item(),\n                          confusion_mat[i][i].item(), \n                          recall_list[i],\n                          precision_list[i],\n                          f1_score_list[i]\n                         ))","de5cd6e8":"!pip install git+https:\/\/github.com\/qubvel\/segmentation_models.pytorch\n","dd42ebae":"import segmentation_models_pytorch as smp","f4704a42":"from segmentation_models_pytorch.encoders import get_preprocessing_fn","09185851":"preprocess_input = get_preprocessing_fn('resnet18', pretrained='imagenet')","4d5d755b":"from segmentation_models_pytorch.unet import Unet","0486dfd3":"model = Unet(encoder_name=\"efficientnet-b0\", classes=2, aux_params={\"classes\": 2})","1efb1866":"optimizer = optim.Adam(model.parameters())\ncriterion = nn.BCELoss()","2fdefca6":"# Load data","c4749040":"# Train CNN with LSTM"}}