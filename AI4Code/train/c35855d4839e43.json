{"cell_type":{"b508da27":"code","e98642f8":"code","7661ec8a":"code","35db15eb":"code","41c7a947":"code","99b8d88a":"code","a3b410a5":"code","489db168":"code","27880602":"code","0374c939":"code","8a421756":"code","9ccfdba6":"code","b11fc045":"code","42f73f7d":"code","880871f0":"code","c5b1b1ea":"code","b4fb027d":"code","70552331":"code","c812e4dc":"code","5be49d3a":"code","ea1e7bbe":"code","9e8a1479":"code","1b277bec":"code","ca79f112":"code","31fb11bd":"code","421a1e39":"code","8d8f9749":"code","5c623e8e":"code","9912b0e9":"code","c239cbe2":"code","795a86d5":"markdown","b2998868":"markdown","27e573c0":"markdown","ab67e879":"markdown","89f51574":"markdown","c4fa072d":"markdown","4e58af2c":"markdown","38481807":"markdown","616e2e30":"markdown","efdaa849":"markdown"},"source":{"b508da27":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e98642f8":"df=pd.read_csv('\/kaggle\/input\/clothessizeprediction\/final_test.csv')","7661ec8a":"df.head","35db15eb":"df['size'].unique()","41c7a947":"df=df.replace({'XXS':1, 'S':2,'M':3,'L':4,'XL':5,'XXL':6,'XXXL':7})","99b8d88a":"df.isnull().sum()","a3b410a5":"df=df.dropna(how='any')","489db168":"import matplotlib.pyplot as plt\nimport seaborn as sns","27880602":"sns.pairplot(df)","0374c939":"df.describe()","8a421756":"q1=df['age'].quantile(0.99)\nq2=df['age'].quantile(0.01)\ndf=df[df['age']<q1]\ndf=df[df['age']>q2]","9ccfdba6":"q3=df['weight'].quantile(0.99)\nq4=df['weight'].quantile(0.01)\ndf=df[df['weight']<q3]\ndf=df[df['weight']>q4]","b11fc045":"sns.pairplot(df)","42f73f7d":"df['bmi']=df['weight']\/(df['height']**2\/100)","880871f0":"sns.heatmap(df.corr(),annot=True)","c5b1b1ea":"from sklearn.model_selection import train_test_split\nX=df.drop('size', axis=1)\ny=df['size']\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n\nfrom sklearn.linear_model import LinearRegression\nclf = LinearRegression()\nclf.fit(X_train,y_train)\nclf.predict(X_test)\nLinearRegressionScore = clf.score(X_test,y_test)\nprint(\"Accuracy of LR:\",LinearRegressionScore*100)\n\nfrom sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nmodel.fit(X_train,y_train)\nmodel.predict(X_test)\nnp.array(y_test)\nRandomForestClassifierScore = model.score(X_test,y_test)\nprint(\"Accuracy of RFC:\",RandomForestClassifierScore*100)","b4fb027d":"!pip install pycaret","70552331":"from pycaret.regression import *","c812e4dc":"ex1=setup(df,target='size',silent=True)","5be49d3a":"compare_models()","ea1e7bbe":"xg = create_model('xgboost')","9e8a1479":"xg.fit(X_train,y_train)","1b277bec":"y_pred = xg.predict(X_test)","ca79f112":"y_test=pd.DataFrame(y_test)\ny_pred=pd.DataFrame(y_pred)","31fb11bd":"y_test = y_test.reset_index()","421a1e39":"y_test=y_test.drop('index', axis=1)","8d8f9749":"df_pred=pd.concat([y_test,y_pred],axis=1)","5c623e8e":"df_pred=df_pred.rename(columns={'size': 'actual', 0: 'pred'})","9912b0e9":"df_pred.describe()","c239cbe2":"df_pred.groupby('actual')['pred'].describe()","795a86d5":"# Bacically, 25% to 75% of each model output will be high possibility to fit the size. For example,if I get 2.0 as output of prediction model, I should try XXS and S. But it depends on individuals. Considering the max prediction of each size, if you like larger one, you should choose lager size than indication.","b2998868":"# catboost or xgboost seem to be better model. I chose xgboost.","27e573c0":"# This is the rough indication table of 'size' and 'model output'.","ab67e879":"# 2) I added new feature 'BMI' BodyMassIndex in which we can find eacn physique.","89f51574":"# 'Regression' seems to be better.","c4fa072d":"# 1) I tried to drop outliers.","4e58af2c":"# Which I should use ,'Classification' or 'Regression' ?","38481807":"# I tried to find better regression model by PyCaret.","616e2e30":"![image.png](attachment:df418410-c1be-4448-9736-f72ac45d169b.png)","efdaa849":"# 1. Features Engineering"}}