{"cell_type":{"3fc73015":"code","96c244e6":"code","51e121a7":"code","e066aaab":"code","2bb51f7a":"code","018f3184":"code","4f0120a4":"code","32eb3007":"code","f34b9fec":"code","446c0953":"code","c5d2248e":"code","2d217c87":"code","78779de8":"code","255e54a2":"code","c06f522f":"code","87c3e8be":"code","b8c717a4":"code","27132073":"code","8d24293e":"code","234c3b6d":"code","c8c3f5f0":"code","ff34e1e5":"code","a896951e":"code","644b914c":"code","53958ef4":"code","aabb2372":"code","d3fa6129":"code","1e780eaf":"code","6623981d":"code","cc6700bf":"code","31a393d7":"markdown","bfe445bf":"markdown","d8a58f1b":"markdown","db59cfe2":"markdown","f4250c59":"markdown","63ac175f":"markdown","7b0d014a":"markdown","56598678":"markdown","feceeb4f":"markdown","9dc85bb2":"markdown","b0135b66":"markdown","8ce3c55c":"markdown","8798324c":"markdown","2e0b0c9a":"markdown","885aa38e":"markdown","5a620d63":"markdown","87c2b383":"markdown","753ddb0a":"markdown","83403fe0":"markdown","36180e60":"markdown"},"source":{"3fc73015":"import numpy as np\nimport pandas as pd\nimport os\n","96c244e6":"print(\"Hi This Project is sales DATA analysis of whole year using PANDA Library  \")","51e121a7":"\nap = pd.read_csv(\"..\/input\/year-data-sale\/Sales_April_2019.csv\")\nap.head()\n","e066aaab":"# Check shape of data in ap file\nprint('shape of ap', ap.shape)","2bb51f7a":"\n\nfiles = [file for file in os.listdir('..\/input\/year-data-sale')]\nfor file in files: \n    print(file)\n","018f3184":"\n\n# providing empty dataframe to read the data\nyear_data = pd.DataFrame()\n\n# now giving for loop to read and mearge all files\nfor file in files: \n    dd = pd.read_csv(\"..\/input\/year-data-sale\/\"+file)\n    year_data = pd.concat([year_data, dd])\n\nyear_data.head()\n","4f0120a4":"print('shape of year data', year_data.shape)","32eb3007":"nan_rows = year_data[year_data.isna().any(axis =1)]\nnan_rows.head()","f34b9fec":"year_data = year_data.dropna(how = 'all')\nyear_data.head()","446c0953":"nan_rows = year_data[year_data.isna().any(axis =1)]\nnan_rows.head()","c5d2248e":"year_data['Month'] = year_data['Order Date'].str [0:2]\nyear_data.head()","2d217c87":"# year_data['Month'] = year_data['Month'].astype('int32')\n# year_data.head()","78779de8":"year_data = year_data[year_data['Order Date'].str [0:2] != 'Or']\nyear_data.head()","255e54a2":"# this is extra work to change the data type of the cloumn values to numeric (int , float) to avoide some bad entry errors\n# try to run without doing this and you will see the error\nyear_data['Quantity Ordered'] = pd.to_numeric(year_data['Quantity Ordered']) # make int\nyear_data['Price Each'] = pd.to_numeric(year_data['Price Each']) # make float","c06f522f":"year_data['Month'] = year_data['Month'].astype('int32')\nyear_data.head()","87c3e8be":"year_data['Quantity Ordered'] = pd.to_numeric(year_data['Quantity Ordered']) # make int\nyear_data['Price Each'] = pd.to_numeric(year_data['Price Each']) # make float\n# this is extra work to change the data type of the cloumn values to numeric (int , float) to avoide some bad entry errors\n# try to run without doing this and you will see the error\n# Now code to make the sales column\n\nyear_data['sales'] = year_data['Quantity Ordered'] * year_data['Price Each'] \nyear_data.head()","b8c717a4":"# Now We can answer the Q1\n \nResults = year_data.groupby('Month').sum()\n\nResults","27132073":"# plot the data in bar chart form\nimport matplotlib.pyplot as plt # importing graph making library\nmonths = range(1,13)\n\nplt.bar (months, Results['sales'])\nplt.xticks(months) # to show number of each month for each bar in x axis\nplt.ylabel(\"Sales in USD ($)\")\nplt.xlabel (\"Month Number\")\nplt.show()","8d24293e":"year_data['City'] = year_data['Purchase Address'].apply(lambda x: x.split(',')[1])\nyear_data.head()","234c3b6d":"# another method to get the same results but with more generic approach\n\ndef get_city(address):\n    return address.split(',')[1]\ndef get_state(address):   # because only city name is not sufficent so we also need state name to avoide any error if there is any same city name in differet state\/country\n    return address.split(',')[2].split(' ')[1]    # first split will get the 2nd index (state name + post code), 2nd split will get only state name and will drop the post code\n\nyear_data['City'] = year_data['Purchase Address'].apply(lambda x: get_city(x) + ' ' + get_state(x))\nyear_data.head()","c8c3f5f0":"City_Sale_Results = year_data.groupby('City').sum()\nCity_Sale_Results","ff34e1e5":"# plot the city sale data in bar chart form\n\nimport matplotlib.pyplot as plt # importing graph making library\n\ncities = [city for city, df in year_data.groupby('City')]  # this step is for arrangment of city names according to city column in data set other wise it can mix the citywise sales \n\nplt.bar (cities, City_Sale_Results['sales'])\nplt.xticks(cities, rotation='vertical', size=8) # to show number of each month for each bar in x axis\nplt.ylabel(\"Sales in USD ($)\")\nplt.xlabel (\"City Name\")\nplt.show()","a896951e":"# first need to split time column from \"Order Date\" column in data set\n\nyear_data['Order Date'] = pd.to_datetime(year_data['Order Date']) # to change the style of  \"Order Date\" column so it make easy to split time\n\nyear_data['Hour'] = year_data['Order Date'].dt.hour  # to get the \"hour\" from \"Order Date\" column\nyear_data['Minute'] = year_data['Order Date'].dt.minute # to get the \"minute\" from \"Order Date\" column\nyear_data['count'] = 1 # for all rows of data set\nyear_data.head()\n","644b914c":"# now plot it in line chart form\n\nHours = [Hour for Hour, df in year_data.groupby('Hour')]\nplt.plot(Hours, year_data.groupby(['Hour']).count())\nplt.xticks(Hours)\nplt.ylabel(\"Number of Orders\")\nplt.xlabel (\"Hour\")\nplt.grid()\nplt.show()","53958ef4":"# this can be done by finding duplicate order IDs in data frame and then arrange them\n\ndf = year_data[year_data['Order ID'].duplicated(keep = False)] \n\n# df = new data frame, it will find\/store duplicated Oreder IDs from year_data, False = print all elemnts of \"Product\" while duplicate\n\n\n\ndf.head(10)","aabb2372":"# now we will Group the products with same Orders IDs and make new column\n\n\ndf['Grouped'] = df.groupby('Order ID')['Product'].transform(lambda x: (',').join(x) )\n\n# Grouped = New Column, it will group the Order IDs, and in paralle collect values from \"Product\" column and join then with comma sperator\n# dont worry about error \"Try using .loc[row_indexer,col_indexer] = value instead\" \ndf = df[['Order ID', 'Grouped']].drop_duplicates() # it will drop the rows with similar entries\n\ndf.head()","d3fa6129":"# now we need to import further libraries\n\nfrom itertools import combinations\nfrom collections import Counter\n\n\ncount = Counter()\nfor row in df['Grouped']:    # row = list\n    row_list = row.split(',') # row_list = sublist\n    count.update(Counter(combinations(row_list, 2))) # 2 = two number of items \n    \n\nfor key, value in count.most_common(10):\n    print(key, value)","1e780eaf":"# as per strategy we need to sum the \"Quantity Ordered\" while lookup \"Product\"\n\nproduct_group = year_data.groupby('Product')\nQuantity_ordered = product_group.sum()['Quantity Ordered']\n\nproducts = [product for product , df in product_group ]\n\nplt.bar(products, Quantity_ordered)\nplt.xticks(products, rotation='vertical', size=8)\nplt.ylabel(\"Quantity of Orders\")\nplt.xlabel (\"Product Name\")\nplt.show()\n","6623981d":"prices = year_data.groupby(\"Product\").mean()['Price Each']\nprint(prices)","cc6700bf":"#import matplotlib as mpl\n#import matplotlib.pyplot as plt\n#import matplotlib.ticker as mticker\n\nfig, ax1 = plt.subplots()\n\nax2 = ax1.twinx()\nax1.bar (products, Quantity_ordered, color='green')\nax2.plot (products, prices, 'b')\nax1.set_xlabel (\"Product Name\")\nax1.set_ylabel (\"Quantity_Ordered\", color = 'g')\nax2.set_ylabel (\"Prices\", color = 'b')\nax1.set_xticklabels(products, rotation='vertical', size=8)\n\nplt.show()","31a393d7":" **Add another data column for city**\n \n see the Purchase Address column and you will se the city name within commas\n\n we will use **\".apply \"** method to split this city name from Purchase Address column and make City column\n\n **Standard Syantex **= **df[\"New Column Name\"] = df['Target Column'].apply (lambda x: x.split(',')[index])**\n \n df => given data frame name in our case => year_data\n    \nlamda x =>  the command for value detection and temporarily store, technically saying it will detect the cell content\n\nx.split => is the given operation name for value  temporarily store means split\n\n(',') => is the condition for split \n\nindex => position or index or word of value you wnat to split and write in new column","bfe445bf":"while running the above code in previous line it gave following error (you coan check run by removing # from start)\n\n\n**ValueError: invalid literal for int() with base 10: 'Or'**\n\nmeans that it has some cells with alphabets 'Or' so these cannot change into integers\n\nnow we have to clean all those rows from data set\n\n**standard Sytex =** New data frame name = old data frame name [old data frame name['Target column'].str [0:2] != 'Or'\n\n.str => data type of target column\n\n'Or' => target value that need to be clean\n\n\"!=\" => this will not allow all the rows having 'Or' in new data frame\n\n**Note: **\n\nwe can use the same data frame name as new data frame name so it will automatically update the old data set\n\n","d8a58f1b":"Now run the code again to change the data value type in Month coulmn","db59cfe2":"change the type of data in New Month column, it will helpful for data visulizations\n\nat the moment it is with string values because we extract it from string values clolumn \"Order Date\"\n\n\nstandard Syntex => year_data['Column Name'] = year_data['Target Column Name'].astype('int32')\n\n.astype => command for change type\n\nint32 => new type of values\n","f4250c59":"Import multiple files from input data set","63ac175f":"Drop the rows that all fully filled with NAN\n\nfor rows partially filled with NAN we use other statistical methods like mean, median, mode etc\n\n\nstandard syntex=> df = df.dropna(condition)","7b0d014a":"**Q4: What product are most often Sold Together?**","56598678":"Now find out \n\n**Q1 = A month with highest sales and  money earned**\n\nif you see data head (in  \"order date\" column) first two digits are for month\n\nwe need a sepreate coulmn for month accordingly\n\nmay be while doing this we need some data seperation, data cleaning, error removing etc\n\nstandard syntex => year_data['new coulmn name'] = year_data['target column name for data collection'].str [0:2]\n\n\nyear_data => data frame name\n\n.str => data type\n\n[0:2] => collection elemnt's index number\n\n","feceeb4f":"# DATA cleaning section!","9dc85bb2":"\nremove all NAN rows from panadas data frame (that is sales data set we uploaded)\n\nstandared sytex => df1 = df[df.isna().any(axis =1)]\n\ndf1 = new name for data set\n\ndf =>  give here your data frame name that you used in previos lines\n\naxis = 1 means => rows\n\nremaining are builtin commands in this syntax","b0135b66":"import file of one month sale january, Just copy\/paste file address line from input data","8ce3c55c":"to mearge all data file and make a one big data file, \nkeep in mind to put last \"\/\" in line \"(df = pd.read_csv(\"..\/input\/year-data-sale\/\"+file)\"","8798324c":"to answer Q1 we also need sales value for each order and for this \n\n\nwe have to multiply \"Quantity Ordered\" to \" Price Each \" and add it in a new column \"sales\" in data set","2e0b0c9a":"# Q2: Which city had highest number of sales?","885aa38e":"**Q3 = What is best time for advertisement to increase the sales?**","5a620d63":"**Q6 = What is relationship between Most saled products and their prices?**","87c2b383":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","753ddb0a":"Just for check we will run again the previous code (line 11) to check the fully filled NAN rows and the result will be none means no fully filled NAN rows\n\n\nin line 12 if we use \"any\" instead of \"all\" that will cause another error in data frame\n\nwith using \"any\" it will remove any NAN value (also from partially filled rows with NAN) so it will make data having uneven columns length\n\nto avoid this we used \"all\" means only drop that rows that are having all values NAN\n\n","83403fe0":"to remove the index numbring from file\n\n#year_data.to_csv(\"year_data.csv\", index = False)\n\nknow the shape of data","36180e60":"**Q5 = What Product sold the Most and Why?**"}}