{"cell_type":{"b1266303":"code","967cbec7":"code","606a6e8d":"code","15cbe0b6":"code","886ef653":"code","72e7624f":"code","a3b98da2":"code","c245c5d1":"code","bbbe4eff":"code","67e6e553":"code","5d8b1cba":"code","11ffb1bd":"code","186d70ad":"code","cbf28e18":"code","4b175f84":"code","b07aa636":"code","e94bc2bc":"code","d1d1ccce":"code","452b2e0d":"code","b37f7a88":"code","7e6e1dd9":"code","8951328c":"code","97e1c917":"code","b2a6e975":"code","378e5ee3":"code","53522eed":"code","c354295b":"code","ca5dcb7e":"code","ebed09b9":"code","cb8f977e":"code","a187ccbf":"code","f0e49096":"code","5997559a":"code","f255541f":"code","acef56f1":"code","730e674b":"code","6674615f":"markdown","e3b01d47":"markdown","be66f5df":"markdown","103721cb":"markdown","7a5d1191":"markdown","602a0bef":"markdown","1125998e":"markdown","54870b9c":"markdown","f227d525":"markdown","59cb506a":"markdown","39f646ff":"markdown","daa4a85f":"markdown","48292553":"markdown","b4a10b09":"markdown"},"source":{"b1266303":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","967cbec7":"train=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntrain.head(10)","606a6e8d":"test=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest.head(10)","15cbe0b6":"train.info()","886ef653":"test.info()","72e7624f":"plt.figure(figsize=(15,10))\nplt.title('heatgraph of null-values')\nsns.heatmap(train.isnull(),yticklabels=False,cbar=False) # there mamy of NaN in 'Cabin' and 'age' in the train dataset","a3b98da2":"plt.figure(figsize=(15,10))\nplt.title('heatgraph of null-values')\nsns.heatmap(test.isnull(),yticklabels=False,cbar=False) # as same as train dataset it also have many NaN in the 'Cabin' and 'age' column ","c245c5d1":"train1=train.drop(\"Cabin\",axis=1)\n\ntrain1.head(10)","bbbe4eff":"test1=test.drop(\"Cabin\",axis=1)\ntest1.head(10)","67e6e553":"train.describe()","5d8b1cba":"test.describe()","11ffb1bd":"train1.Age.replace([None],[29.699118],inplace=True)","186d70ad":"plt.figure(figsize=(15,10))\nplt.title('heatgraph of null-values')\nsns.heatmap(train1.isnull(),yticklabels=False,cbar=False) # now we can see that there is no null-value","cbf28e18":"test1.Age.replace([None],[30.272590\t],inplace=True)","4b175f84":"plt.figure(figsize=(15,10))\nplt.title('heatgraph of null-values')\nsns.heatmap(test1.isnull(),yticklabels=False,cbar=False) #similarly here also","b07aa636":"test1.Fare.replace([None],[35.627188],inplace=True)","e94bc2bc":"corr=train1.corr()\nplt.figure(figsize=(15,10))\nsns.heatmap(corr,annot=True,annot_kws={\"size\":15}) # for train dataset\nplt.title('heatgraph of correlation')","d1d1ccce":"corr=test1.corr()\nplt.figure(figsize=(15,10))\nsns.heatmap(corr,annot=True,annot_kws={\"size\":15}) # for test dataset\nplt.title('heatgraph of correlation')","452b2e0d":"from sklearn.linear_model import LogisticRegression","b37f7a88":"train1.head(5)","7e6e1dd9":"train1.Sex.replace([\"male\", \"female\"], [0, 1], inplace=True)","8951328c":"train1.head(5)","97e1c917":"print(\"number of rows in train data -> \",len(train1))\nprint(\"number of rows in test data -> \",len(test1))","b2a6e975":"train2=train1","378e5ee3":"#now we choose the independent part\nTrain_IndepentVars=train1.drop(\"PassengerId\",axis=1)\nTrain_IndepentVars=Train_IndepentVars.drop(\"Survived\",axis=1)\nTrain_IndepentVars=Train_IndepentVars.drop(\"Name\",axis=1)\nTrain_IndepentVars=Train_IndepentVars.drop(\"Ticket\",axis=1)\nTrain_IndepentVars=Train_IndepentVars.drop(\"Embarked\",axis=1)\nTrain_IndepentVars.head(5)\nTrain_IndepentVars=np.array(Train_IndepentVars)\nprint(Train_IndepentVars)","53522eed":"#now we choose the dependent\/target part\nTrain_TargetVar = train2.values[:,1]\nprint(Train_TargetVar)","c354295b":"Train_TargetVar.dtype","ca5dcb7e":"logmodel=LogisticRegression()\nTrain_TargetVar=Train_TargetVar.astype('int')\nlogmodel.fit(Train_IndepentVars,Train_TargetVar)","ebed09b9":"predictions=logmodel.predict(Train_IndepentVars)\npredictions,len(predictions)","cb8f977e":"from sklearn.metrics import classification_report","a187ccbf":"print(classification_report(Train_TargetVar,predictions))","f0e49096":"from sklearn.metrics import confusion_matrix","5997559a":"print (pd.Series(Train_TargetVar).value_counts())\nprint(confusion_matrix(Train_TargetVar,predictions))\n# confusion_matrix(Train_TargetVar,predictions)\nconfusion_df = pd.DataFrame(confusion_matrix(Train_TargetVar,predictions),\n             columns=[\"Predicted Class \" + str(class_name) for class_name in [0,1]],\n             index = [\"Class \" + str(class_name) for class_name in [0,1]])\n\nprint(confusion_df)\n\n#                 predicted     \n# actual     No           YES\n# NO         TN           FP   \n# YES        FN           TP","f255541f":"print(logmodel.coef_)","acef56f1":"print(logmodel.intercept_)","730e674b":"c=logmodel.score(Train_IndepentVars,Train_TargetVar)\nc","6674615f":"for the least number of null value we will replace that null vaue by this own mean value","e3b01d47":"#### step 2\nimplement the data in this module by using read_csv(). and giving some name of it.","be66f5df":"#### step 3 \nNow we analyse some the important and meanful information and data pre-processing, data clearing etc. of the dataset","103721cb":"now we replace all the NaN age by the mean value of the age column. for finding the mean value we use .describe()","7a5d1191":"#### Logistic Regression","602a0bef":"<b>therefore the mean age of train dataset is 29.699118<\/b>\n<b>and the mean age of the test dataset is 30.272590<\/b>","1125998e":"now first we delete the cabin column from the data","54870b9c":"#now the split of train ana test is already done so now we will see that how many of number of row are divided with each other","f227d525":"### step 4\n\nnow we enter the part of machine learning...\n\n## <b><u>Our Goal<\/u><\/b>\nfirst we train the \"train.csv\" dataset and then predic the \"test.csv\" dataset","59cb506a":"now we find the correlation between different column attributes...","39f646ff":"##### now we can solve this problem in such a way that we delete the cabin column from the dataset and all the NaN of age are replace by the mean value of the column age...","daa4a85f":"# Hello Everyone....\n\n### Overview\n\nThe data has been split into two groups:\n-> training set(tain.csv)\n-> test set(test.csv)\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You can also use feature engineering to create new features.\n\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n\nWe also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.","48292553":"#### step 1:\nimport all the primary important module. like pandas, numpy, matplotlib, seaborn etc.","b4a10b09":"now we replace it..."}}