{"cell_type":{"032ec594":"code","054df96b":"code","541c5177":"code","9f4557b9":"code","1c310577":"code","e50f5aab":"code","eb795511":"code","22e27369":"code","8da2088c":"code","5b420087":"code","fbe2298d":"code","23ca6fc8":"code","9e0d3f4b":"code","49c21da9":"code","df965a76":"markdown","3ce27433":"markdown","922d08bd":"markdown","dd996fd1":"markdown","f077b526":"markdown","08a1c76d":"markdown","9810802a":"markdown","d5d4cc2a":"markdown","f6b48c8b":"markdown","d6a575ae":"markdown","63def2d1":"markdown","f20bcdf8":"markdown","90052bf8":"markdown","766aadb7":"markdown","efb42e39":"markdown","593a6e6f":"markdown","afe0dcad":"markdown"},"source":{"032ec594":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex6 import *\nprint(\"Setup Complete\")","054df96b":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"stackoverflow\" dataset\ndataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","541c5177":"# Get a list of available tables \ntables = list(client.list_tables(dataset))\nlist_of_tables = [table.table_id for table in tables] \n\n# Print your answer\nprint(list_of_tables)\n\n# Check your answer\nq_1.check()","9f4557b9":"#q_1.solution()","1c310577":"# Construct a reference to the \"posts_answers\" table\nanswers_table_ref = dataset_ref.table(\"posts_answers\")\n\n# API request - fetch the table\nanswers_table = client.get_table(answers_table_ref)\n\n# Preview the first five lines of the \"posts_answers\" table\nclient.list_rows(answers_table, max_results=5).to_dataframe()","e50f5aab":"# Construct a reference to the \"posts_questions\" table\nquestions_table_ref = dataset_ref.table(\"posts_questions\")\n\n# API request - fetch the table\nquestions_table = client.get_table(questions_table_ref)\n\n# Preview the first five lines of the \"posts_questions\" table\nclient.list_rows(questions_table, max_results=5).to_dataframe()","eb795511":"#q_2.solution()","22e27369":"# Your code here\nquestions_query = \"\"\"\n                  SELECT id, title, owner_user_id\n                  FROM `bigquery-public-data.stackoverflow.posts_questions`\n                  WHERE tags LIKE '%bigquery%'\n                  \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nquestions_query_job = client.query(questions_query,job_config=safe_config) # Your code goes here\n\n# API request - run the query, and return a pandas DataFrame\nquestions_results = questions_query_job.to_dataframe()# Your code goes here\n\n# Preview results\nprint(questions_results.head())\n\n# Check your answer\nq_3.check()","8da2088c":"#q_3.hint()\n#q_3.solution()","5b420087":"# Your code here\nanswers_query = \"\"\"  SELECT a.id, a.body, a.owner_user_id\n                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q \n                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                    ON q.id = a.parent_id\n                WHERE q.tags LIKE '%bigquery%'\"\"\"\n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nanswers_query_job = client.query(answers_query) # Your code goes here\n\n# API request - run the query, and return a pandas DataFrame\nanswers_results = answers_query_job.to_dataframe()# Your code goes here\n\n# Preview results\nprint(answers_results.head())\n\n# Check your answer\nq_4.check()","fbe2298d":"#q_4.hint()\n#q_4.solution()","23ca6fc8":"# Your code here\nbigquery_experts_query = \"\"\"SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n                         FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n                         INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                             ON q.id = a.parent_Id\n                         WHERE q.tags LIKE '%bigquery%'\n                         GROUP BY a.owner_user_id\"\"\"\n\n# Set up the query\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\nbigquery_experts_query_job = client.query(bigquery_experts_query,job_config=safe_config) # Your code goes here\n\n# API request - run the query, and return a pandas DataFrame\nbigquery_experts_results = bigquery_experts_query_job.to_dataframe()   # Your code goes here\n\n# Preview results\nprint(bigquery_experts_results.head())\n\n# Check your answer\nq_5.check()","9e0d3f4b":"#q_5.hint()\n#q_5.solution()","49c21da9":"def expert_finder(topic, client):\n    '''\n    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n\n    Inputs:\n        topic: A string with the topic of interest\n        client: A Client object that specifies the connection to the Stack Overflow dataset\n\n    Outputs:\n        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n    '''\n    my_query = \"\"\"\n               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                   ON q.id = a.parent_Id\n               WHERE q.tags like '%{topic}%'\n               GROUP BY a.owner_user_id\n               \"\"\"\n\n    # Set up the query (a real service would have good error handling for \n    # queries that scan too much data)\n    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)      \n    my_query_job = client.query(my_query, job_config=safe_config)\n\n    # API request - run the query, and return a pandas DataFrame\n    results = my_query_job.to_dataframe()\n\n    return results\n\n#q_6.solution()","df965a76":"For the solution, uncomment the line below.","3ce27433":"### 5) Answer the question\nYou have the merge you need. But you want a list of users who have answered many questions... which requires more work beyond your previous result.\n\nWrite a new query that has a single row for each user who answered at least one question with a tag that includes the string \"bigquery\". Your results should have two columns:\n- `user_id` - contains the `owner_user_id` column from the `posts_answers` table\n- `number_of_answers` - contains the number of answers the user has written to \"bigquery\"-related questions","922d08bd":"It isn't clear yet how to find users who answered questions on any given topic. But `posts_answers` has a `parent_id` column. If you are familiar with the Stack Overflow site, you might figure out that the `parent_id` is the question each post is answering.\n\nLook at `posts_questions` using the cell below.","dd996fd1":"For a hint or the solution, uncomment the appropriate line below.","f077b526":"**[SQL Home Page](https:\/\/www.kaggle.com\/learn\/intro-to-sql)**\n\n---\n","08a1c76d":"For a hint or the solution, uncomment the appropriate line below.","9810802a":"### 3) Selecting the right questions\n\nA lot of this data is text. \n\nWe'll explore one last technique in this course which you can apply to this text.\n\nA **WHERE** clause can limit your results to rows with certain text using the **LIKE** feature. For example, to select just the third row of the `pets` table from the tutorial, we could use the query in the picture below.\n\n![](https:\/\/i.imgur.com\/RccsXBr.png) \n\nYou can also use `%` as a \"wildcard\" for any number of characters. So you can also get the third row with:\n\n```\nquery = \"\"\"\n        SELECT * \n        FROM `bigquery-public-data.pet_records.pets` \n        WHERE Name LIKE '%ipl%'\n        \"\"\"\n```\n\nTry this yourself. Write a query that selects the `id`, `title` and `owner_user_id` columns from the `posts_questions` table. \n- Restrict the results to rows that contain the word \"bigquery\" in the `tags` column. \n- Include rows where there is other text in addition to the word \"bigquery\" (e.g., if a row has a tag \"bigquery-sql\", your results should include that too).","d5d4cc2a":"---\n**[SQL Home Page](https:\/\/www.kaggle.com\/learn\/intro-to-sql)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https:\/\/www.kaggle.com\/learn-forum) to chat with other Learners.*","f6b48c8b":"# Congratulations!\n\nYou know all the key components to use BigQuery and SQL effectively. Your SQL skills are sufficient to unlock many of the world's largest datasets.\n\nWant to go play with your new powers?  Kaggle has BigQuery datasets available [here](https:\/\/www.kaggle.com\/datasets?sortBy=hottest&group=public&page=1&pageSize=20&size=sizeAll&filetype=fileTypeBigQuery).\n\n# Feedback\n\nBring any questions or feedback to the [Learn Discussion Forum](https:\/\/www.kaggle.com\/learn-forum).","d6a575ae":"Are there any fields that identify what topic or technology each question is about? If so, how could you find the IDs of users who answered questions about a specific topic?\n\nThink about it, and then check the solution by running the code in the next cell.","63def2d1":"# Introduction\n\n[Stack Overflow](https:\/\/stackoverflow.com\/) is a widely beloved question and answer site for technical questions. You'll probably use it yourself as you keep using SQL (or any programming language). \n\nTheir data is publicly available. What cool things do you think it would be useful for?\n\nHere's one idea:\nYou could set up a service that identifies the Stack Overflow users who have demonstrated expertise with a specific technology by answering related questions about it, so someone could hire those experts for in-depth help.\n\nIn this exercise, you'll write the SQL queries that might serve as the foundation for this type of service.\n\nAs usual, run the following cell to set up our feedback system before moving on.","f20bcdf8":"For a hint or the solution, uncomment the appropriate line below.","90052bf8":"Run the next cell to fetch the `stackoverflow` dataset.","766aadb7":"# Exercises\n\n### 1) Explore the data\n\nBefore writing queries or **JOIN** clauses, you'll want to see what tables are available. \n\n*Hint*: Tab completion is helpful whenever you can't remember a command. Type `client.` and then hit the tab key. Don't forget the period before hitting tab.","efb42e39":"### 6) Building a more generally useful service\n\nHow could you convert what you've done to a general function a website could call on the backend to get experts on any topic?  \n\nThink about it and then check the solution below.","593a6e6f":"### 2) Review relevant tables\n\nIf you are interested in people who answer questions on a given topic, the `posts_answers` table is a natural place to look. Run the following cell, and look at the output.","afe0dcad":"### 4) Your first join\nNow that you have a query to select questions on any given topic (in this case, you chose \"bigquery\"), you can find the answers to those questions with a **JOIN**.  \n\nWrite a query that returns the `id`, `body` and `owner_user_id` columns from the `posts_answers` table for answers to \"bigquery\"-related questions. \n- You should have one row in your results for each answer to a question that has \"bigquery\" in the tags.  \n- Remember you can get the tags for a question from the `tags` column in the `posts_questions` table.\n\nHere's a reminder of what a **JOIN** looked like in the tutorial:\n```\nquery = \"\"\"\n        SELECT p.Name AS Pet_Name, o.Name AS Owner_Name\n        FROM `bigquery-public-data.pet_records.pets` as p\n        INNER JOIN `bigquery-public-data.pet_records.owners` as o \n            ON p.ID = o.Pet_ID\n        \"\"\"\n```\n\nIt may be useful to scroll up and review the first several rows of the `posts_answers` and `posts_questions` tables.  "}}