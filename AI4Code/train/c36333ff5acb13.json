{"cell_type":{"d81013ce":"code","781d2b2f":"code","ebf4401e":"code","5f41ea84":"code","e4b07048":"code","c8fc3048":"code","3ec84776":"code","c2206079":"code","ab7874ad":"code","90435d36":"code","7605529f":"code","70f41a6d":"code","141e2bdc":"code","0a401e55":"code","f5bdaf13":"code","3a173f20":"code","8e0b216e":"code","7d62f52c":"code","e3931e26":"code","8c773a85":"code","dea841f7":"code","9a590267":"code","3954b360":"code","1590241e":"code","307a2d59":"code","4ea978be":"code","81bd5831":"code","19cc89a4":"code","de437f79":"code","61d735fc":"code","d81f06f6":"code","611485d4":"code","27a52137":"code","c010c3dd":"code","d3a4624f":"markdown","1fc258b5":"markdown","2b330117":"markdown","1153ad5d":"markdown","e92cbb54":"markdown","0f5130b6":"markdown","df1f7a1c":"markdown","81b0caf6":"markdown","c0e41a78":"markdown","7d1e3d34":"markdown"},"source":{"d81013ce":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline,make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\nwarnings.filterwarnings('ignore')","781d2b2f":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ndataset = pd.concat([train, test], ignore_index = True)\n#Retrieve Passenger ID from test set, used for submission\nPassengerId = test['PassengerId']","ebf4401e":"#Check null values and missing values\ndataset = dataset.fillna(np.nan)\ndataset.isnull().sum()","5f41ea84":"#Check missing values in train set\ntrain.info()\ntrain.isnull().sum()","e4b07048":"# check the first five information of the train set\ntrain.head()","c8fc3048":"# Check the data types of every column\ntrain.dtypes","3ec84776":"# Generate descriptive statistics that summarize the central tendency, dispersion and shape of a dataset's distribution\ntrain.describe()","c2206079":"sns.barplot(x=\"Sex\", y=\"Survived\", data=train, palette='Set3')\nprint(\"Percentage of females that could survive: %.2f\" %(train['Survived'][train['Sex'] == 'female'].value_counts(normalize = True)[1]*100))\nprint(\"Percentage of females that could survive: %.2f\" %(train['Survived'][train['Sex'] == 'male'].value_counts(normalize = True)[1]*100))","ab7874ad":"# Pclass feature\n# The higher the class is, the high probability survive\nsns.barplot(x='Pclass', y='Survived', data=train, palette='Set3')\nprint(\"Percentage of Pclass = 1, survived probability: %.2f\" %(train['Survived'][train['Pclass']==1].value_counts(normalize = True)[1]*100))\nprint(\"Percentage of Pclass = 2, survived probability: %.2f\" %(train['Survived'][train['Pclass']==2].value_counts(normalize = True)[1]*100))\nprint(\"Percentage of Pclass = 3, survived probability: %.2f\" %(train['Survived'][train['Pclass']==3].value_counts(normalize = True)[1]*100))\n","90435d36":"# SibSp Feature\n# With a suitable number of siblings and spouse, he\/she will have a high survival rate.\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train, palette='Set3')","7605529f":"# Parch Feature \n# With a suitable number of parents and children, he\/she will have a high survival rate.\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train, palette='Set3')","70f41a6d":"# Age Feature\n# Child and adolecent will have a higher survival rate\nage = sns.FacetGrid(train, hue=\"Survived\",aspect=2)\nage.map(sns.kdeplot,'Age',shade= True)\nage.set(xlim=(0, train['Age'].max()))\nage.add_legend()","141e2bdc":"# Fare Feature\n# Passengers who paid higher fare had higher survival rate.\nfare = sns.FacetGrid(train, hue=\"Survived\",aspect=2)\nfare.map(sns.kdeplot,'Fare',shade= True)\nfare.set(xlim=(0, 200))\nfare.add_legend()","0a401e55":"# Title Feature\n# Retrieve the title from passengers name, classify them into six kinds, which are officer, royalty, Mrs, Miss, Mr, and Master.\ndataset['Title'] = dataset['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip())\nTitle_Dict = {}\nTitle_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))\nTitle_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))\nTitle_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))\nTitle_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))\nTitle_Dict.update(dict.fromkeys(['Mr'], 'Mr'))\nTitle_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))\ndataset['Title'] = dataset['Title'].map(Title_Dict)\nsns.barplot(x=\"Title\", y=\"Survived\", data=dataset, palette='Set3')","f5bdaf13":"# FamilyLabel\n# Add new feature FamilyLabel\n# Calculate the family size = Sibsp+Parch+1\ndataset['FamilySize']=dataset['SibSp']+dataset['Parch']+1\nsns.barplot(x=\"FamilySize\", y=\"Survived\", data=dataset, palette='Set3')","3a173f20":"# Based on the family size, classify them into three groups\ndef Family_label(s):\n    if (s >= 2) & (s <= 4):\n        return 2\n    elif ((s > 4) & (s <= 7)) | (s == 1):\n        return 1\n    elif (s > 7):\n        return 0\ndataset['FamilyLabel']=dataset['FamilySize'].apply(Family_label)\nsns.barplot(x=\"FamilyLabel\", y=\"Survived\", data=dataset, palette='Set3')","8e0b216e":"# Deck Feature\n# Fill the missing cabin as Unknown\n# Retrieve the capital words as Deck number\ndataset['Cabin'] = dataset['Cabin'].fillna('Unknown')\ndataset['Deck']= dataset['Cabin'].str.get(0)\nsns.barplot(x=\"Deck\", y=\"Survived\", data=dataset, palette='Set3')","7d62f52c":"# TicketGroup Feature\n# Calculate the number of passengers who has the same ticket number\nTicket_Count = dict(dataset['Ticket'].value_counts())\ndataset['TicketGroup'] = dataset['Ticket'].apply(lambda x:Ticket_Count[x])\nsns.barplot(x='TicketGroup', y='Survived', data=dataset, palette='Set3')","e3931e26":"# Classify the TicketGroup into three kinds\ndef Ticket_Label(s):\n    if (s >= 2) & (s <= 4):\n        return 2\n    elif ((s > 4) & (s <= 8)) | (s == 1):\n        return 1\n    elif (s > 8):\n        return 0\n\ndataset['TicketGroup'] = dataset['TicketGroup'].apply(Ticket_Label)\nsns.barplot(x='TicketGroup', y='Survived', data=dataset, palette='Set3')","8c773a85":"# Fill the missing age value, use feature Pclass, Sex and Title and random forest regressor model to predict \nage = dataset[['Age','Pclass','Sex','Title']]\nage = pd.get_dummies(age)\n# print(age)\nknown_age = age[age.Age.notnull()].values\nnull_age = age[age.Age.isnull()].values\nx = known_age[:, 1:]\ny = known_age[:, 0]\nrf = RandomForestRegressor(n_jobs=-1)\nrf.fit(x, y)\npredictedAge = rf.predict(null_age[:, 1:])\ndataset.loc[(dataset.Age.isnull()),'Age'] = predictedAge","dea841f7":"dataset[dataset['Embarked'].isnull()]","9a590267":"C = dataset[(dataset['Embarked']=='C') & (dataset['Pclass'] == 1)]['Fare'].median()\nprint(C)\nS = dataset[(dataset['Embarked']=='S') & (dataset['Pclass'] == 1)]['Fare'].median()\nprint(S)\nQ = dataset[(dataset['Embarked']=='S') & (dataset['Pclass'] == 1)]['Fare'].median()\nprint(Q)\ndataset['Embarked'] = dataset['Embarked'].fillna('C')","3954b360":"dataset[dataset['Fare'].isnull()]","1590241e":"fare=dataset[(dataset['Embarked'] == \"S\") & (dataset['Pclass'] == 3)].Fare.median()\ndataset['Fare']=dataset['Fare'].fillna(fare)","307a2d59":"dataset['Surname']=dataset['Name'].apply(lambda x:x.split(',')[0].strip())\nSurname_Count = dict(dataset['Surname'].value_counts())\ndataset['FamilyGroup'] = dataset['Surname'].apply(lambda x:Surname_Count[x])\nFemale_Child_Group=dataset.loc[(dataset['FamilyGroup']>=2) & ((dataset['Age']<=12) | (dataset['Sex']=='female'))]\nMale_Adult_Group=dataset.loc[(dataset['FamilyGroup']>=2) & (dataset['Age']>12) & (dataset['Sex']=='male')]","4ea978be":"Female_Child=pd.DataFrame(Female_Child_Group.groupby('Surname')['Survived'].mean().value_counts())\nFemale_Child.columns=['GroupCount']\nFemale_Child","81bd5831":"Male_Adult=pd.DataFrame(Male_Adult_Group.groupby('Surname')['Survived'].mean().value_counts())\nMale_Adult.columns=['GroupCount']\nMale_Adult","19cc89a4":"Female_Child_Group=Female_Child_Group.groupby('Surname')['Survived'].mean()\nDead_List=set(Female_Child_Group[Female_Child_Group.apply(lambda x:x==0)].index)\nprint(Dead_List)\nMale_Adult_List=Male_Adult_Group.groupby('Surname')['Survived'].mean()\nSurvived_List=set(Male_Adult_List[Male_Adult_List.apply(lambda x:x==1)].index)\nprint(Survived_List)","de437f79":"train=dataset.loc[dataset['Survived'].notnull()]\ntest=dataset.loc[dataset['Survived'].isnull()]\ntest.loc[(test['Surname'].apply(lambda x:x in Dead_List)),'Sex'] = 'male'\ntest.loc[(test['Surname'].apply(lambda x:x in Dead_List)),'Age'] = 60\ntest.loc[(test['Surname'].apply(lambda x:x in Dead_List)),'Title'] = 'Mr'\ntest.loc[(test['Surname'].apply(lambda x:x in Survived_List)),'Sex'] = 'female'\ntest.loc[(test['Surname'].apply(lambda x:x in Survived_List)),'Age'] = 5\ntest.loc[(test['Surname'].apply(lambda x:x in Survived_List)),'Title'] = 'Miss'","61d735fc":"# Get trainset and testset based on whether the value of Survived is null or not.\ndataset = pd.concat([train, test])\ndataset=dataset[['Survived','Pclass','Sex','Age','Fare','Embarked','Title','FamilyLabel','Deck','TicketGroup']]\ndataset=pd.get_dummies(dataset)\ntrainset=dataset[dataset['Survived'].notnull()]\ntestset=dataset[dataset['Survived'].isnull()].drop('Survived',axis=1)\nX = trainset.values[:,1:]\nY = trainset.values[:,0]","d81f06f6":"pipe=Pipeline([('select',SelectKBest(k=20)), \n               ('classify', RandomForestClassifier(random_state = 10, max_features = 'sqrt'))])\n\nparam_test = {'classify__n_estimators':list(range(20,50,2)), \n              'classify__max_depth':list(range(3,60,3))}\ngsearch = GridSearchCV(estimator = pipe, param_grid = param_test, scoring='accuracy', cv=10)\ngsearch.fit(X,Y)\nprint(gsearch.best_params_, gsearch.best_score_)","611485d4":"select = SelectKBest(k = 20)\nclf = RandomForestClassifier(random_state = 10, warm_start = True, \n                                  n_estimators = 30,\n                                  max_depth = 6, \n                                  max_features = 'sqrt')\npipeline = make_pipeline(select, clf)\npipeline.fit(X, Y)","27a52137":"cv_score = model_selection.cross_val_score(pipeline, X, Y, cv= 10)\nprint(\"CV Score : Mean - %.7g | Std - %.7g \" % (np.mean(cv_score), np.std(cv_score)))","c010c3dd":"predictions = pipeline.predict(testset)\nsubmission = pd.DataFrame({\"PassengerId\": PassengerId, \"Survived\": predictions.astype(np.int32)})\nsubmission.to_csv(\"submission.csv\", index=False)","d3a4624f":"# Transfer the features into numerial values.","1fc258b5":"# *Please upvote the kernel if you find it insightful*","2b330117":"# Fill the missing values","1153ad5d":"# Random Forest\n> Random Forest is an ensemble learning method that is flexible and easy to use.It is a non linear ensemble learning binary classifier which neglects the correlation of the data. Random forest is an advance version of decision tree. Random forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance. This comes at the expense of a small increase in the bias and some loss of interpret ability, but generally greatly boosts the performance in the final model. Instead of searching for the most important feature while splitting a node, it searches for the best feature among a random subset of features. This results in a wide diversity that generally results in a better model.\n\n# Grid Search\n> Grid searching is a module that performs parameter tuning which is the process of selecting the values for a model\u2019s parameters that maximize the accuracy of the model. Grid Search does this by fitting every combination of parameters and selecting the best parameters by which model had the best score.","e92cbb54":"# Submission","0f5130b6":"# Import train and test data","df1f7a1c":"# Data visualization","81b0caf6":"# Import Libraries","c0e41a78":"# Model training and prediction\nUse grid search to find the best parameter of random forest classifier.","7d1e3d34":"# Cross Validation"}}