{"cell_type":{"544a6830":"code","35c041f4":"code","3aefad3c":"code","06fe7b72":"code","5cc22e16":"code","e78904e4":"code","aff78c76":"code","26084697":"code","6a8673af":"code","c4a7f6a7":"code","1cc74b36":"code","1d9a33de":"code","6105bcd8":"code","299f5b97":"code","ee91e404":"code","e908a271":"code","66c552bc":"code","1494bb17":"markdown","9067e5b9":"markdown","48cd51a4":"markdown","ed682589":"markdown","7a92f797":"markdown","2b2fef70":"markdown","355ab38c":"markdown","2e114671":"markdown","292a9bbf":"markdown","3755fc88":"markdown","23833986":"markdown","62937502":"markdown"},"source":{"544a6830":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom PIL import Image\nimport os\nimport torch\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport torchvision.transforms as tt\nfrom torchvision.utils import make_grid","35c041f4":"! ls \/kaggle\/input\/human-protein-atlas-image-classification","3aefad3c":"DATA_DIR = '\/kaggle\/input\/human-protein-atlas-image-classification'\n\nTRAIN_CSV = DATA_DIR + '\/train.csv'\nTRAIN_DIR = DATA_DIR + '\/train'","06fe7b72":"df = pd.read_csv(TRAIN_CSV)\ndisplay(df.head())\nprint(f\"df.shape: {df.shape}\")","5cc22e16":"len(df['Id'].value_counts())","e78904e4":"text_labels = {\n0:  \"Nucleoplasm\", \n1:  \"Nuclear membrane\",   \n2:  \"Nucleoli\",   \n3:  \"Nucleoli fibrillar center\" ,  \n4:  \"Nuclear speckles\",\n5:  \"Nuclear bodies\",\n6:  \"Endoplasmic reticulum\",   \n7:  \"Golgi apparatus\",\n8:  \"Peroxisomes\",\n9:  \"Endosomes\",\n10:  \"Lysosomes\",\n11:  \"Intermediate filaments\",   \n12:  \"Actin filaments\",\n13:  \"Focal adhesion sites\",   \n14:  \"Microtubules\",\n15:  \"Microtubule ends\",   \n16:  \"Cytokinetic bridge\",   \n17:  \"Mitotic spindle\",\n18:  \"Microtubule organizing center\",  \n19:  \"Centrosome\",\n20:  \"Lipid droplets\",   \n21:  \"Plasma membrane\",   \n22:  \"Cell junctions\", \n23:  \"Mitochondria\",\n24:  \"Aggresome\",\n25:  \"Cytosol\",\n26:  \"Cytoplasmic bodies\",   \n27:  \"Rods & rings\" \n}\n\nNUM_LABELS = len(text_labels)\nprint(f\"There are {NUM_LABELS} labels\")","aff78c76":"FILTERS = ['red', 'green', 'blue','yellow']","26084697":"def get_image(ddir, filename):\n    r = Image.open(f'{ddir}\/{filename}_red.png')\n    g = Image.open(f'{ddir}\/{filename}_green.png')\n    b = Image.open(f'{ddir}\/{filename}_blue.png')\n    y = Image.open(f'{ddir}\/{filename}_yellow.png')\n    return r, g, b, y\n\n\ndef display_image(image, ax):\n    [a.axis('off') for a in ax]\n    r, g, b, y = image\n    ax[0].imshow(r,cmap='Reds')\n    ax[0].set_title('Microtubules')\n    ax[1].imshow(g,cmap='Greens')\n    ax[1].set_title('Protein of Interest')\n    ax[2].imshow(b,cmap='Blues')\n    ax[2].set_title('Nucleus')\n    ax[3].imshow(y,cmap='Oranges') \n    ax[3].set_title('Endoplasmic Reticulum')\n    return ax","6a8673af":"filename = df.Id.sample(1, random_state=9473).values[0]\nimgs = get_image(TRAIN_DIR, filename)\n\nfig, ax = plt.subplots(figsize=(15,5),nrows=1, ncols=4)\ndisplay_image(imgs, ax);","c4a7f6a7":"for key in text_labels.keys():\n    df[key] = df['Target'].apply(lambda x: int(str(key) in x.split()))\n\ntargets_df = df.drop(labels=['Id', 'Target'], axis=1)\n\n# targets_df.head()\n\ntarget_counts = pd.DataFrame({'Localization': [v + ' ' + str(k) for k, v in text_labels.items()],\n                              'Count': targets_df[text_labels.keys()].sum().values})\ntarget_counts.sort_values('Count', inplace=True)\nax = target_counts.plot.barh(x='Localization', y='Count',figsize=(15,10), legend=False)\n\nfor i, v in enumerate(target_counts['Count']):\n    ax.text(v + 3, i - 0.25, str(v) + ', ' + str(round(v \/ len(df) * 100, 2)) + '%')\nax.set_xlabel('Count');\nax.set_ylabel('');\n# plt.axis('off')","1cc74b36":"targets_df['num_labels'] = targets_df.sum(axis=1)\ntargets_df.head()","1d9a33de":"label_counts = pd.DataFrame({'image_count': targets_df['num_labels'].value_counts(),\n                             'pct_of_dataset': targets_df['num_labels'].value_counts() \/ len(df) * 100})\nlabel_counts.columns = ['image_count','pct_of_dataset']\nlabel_counts","6105bcd8":"plt.figure(figsize=(10, 10))\nsns.heatmap(targets_df[targets_df['num_labels']>1].drop(['num_labels'], axis=1).rename(\n    columns={k: f\"{v} ({str(k)})\" for k, v in text_labels.items()}\n).corr(), cmap='YlGnBu');","299f5b97":"class LocalizationDataLoader():\n    def __init__(self, labels, batch_size, ddir):\n        self.labels = labels\n        self.batch_size = batch_size\n        self.ddir = ddir\n        self.get_image_ids()\n    \n    \n    def are_labels_subset_of_targets(self, s):\n        targets = [int(i) for i in s.split()]\n        return np.where(set(self.labels).issubset(targets), 1, 0)\n    \n    \n    def get_image_ids(self):\n        df['check_condition'] = df.Target.apply(lambda s: self.are_labels_subset_of_targets(s))\n        self.identified_image_ids = df[df['check_condition'] == 1].Id.values\n        df.drop('check_condition', axis=1, inplace=True)\n        \n    \n    def get_loader(self):\n        idx = 0\n        batch_images = []\n        batch_image_ids = []\n        for image_id in self.identified_image_ids:\n            idx += 1\n            batch_images.append(get_image(self.ddir, image_id))\n            batch_image_ids.append(image_id)\n            if idx == self.batch_size:\n                yield batch_images, batch_image_ids\n                idx = 0\n                batch_images = []\n                batch_image_ids = []\n        if batch_images != []:\n            yield batch_images, batch_image_ids","ee91e404":"def get_image_targets(image_id):\n    targets = df[df.Id==image_id].Target.values[0]\n    targets = ', '.join([f\"{text_labels[int(t)]} {t}\" for t in targets.split()])\n    return f\"{targets}\"","e908a271":"batch_size = 5\nendo_lyso = LocalizationDataLoader([9, 10], batch_size, TRAIN_DIR)\nloader = endo_lyso.get_loader()","66c552bc":"imgs, img_ids = next(loader)\n\nfig, ax = plt.subplots(nrows=len(imgs), ncols=4, figsize=(15, 5 * len(imgs)))\nfor i, img in enumerate(imgs):\n    display_image(img, ax[i])\n#     ax[i][1].set_title(get_image_targets(img_ids[i]), y=-0.1)","1494bb17":"For the image id, we are provided with staining of the protein of interest, microtubules, nucleus, and endoplasmic reticulum.","9067e5b9":"# Input Data Structure\n\nLet's take a look at the structure of the input folder","48cd51a4":"# Q3.\n\n**Are there any correlations between labels?**","ed682589":"Now let's take a look at a batch of images where the protein of interest is present in both the Endosomes and the Lysosomes","7a92f797":"This notebook covers the following topic\n\n- [Input Data Structure](#Input-Data-Structure)  \n- [Exploration](#Exploration)  \n    - [Q1. What is the occurrence of each label?](#Q1.)\n    - [Q2. How many labels do most images have?](#Q2.)\n    - [Q3. Are there any correlations between the pairs of labels?](#Q3.)\n\n**Credits** \n- https:\/\/www.kaggle.com\/allunia\/protein-atlas-exploration-and-baseline","2b2fef70":"# Exploration\n\n## Q1.\n\n**What is the occurrence of each label?**","355ab38c":"## A2 \n\nIt is most common for protein to localize in exactly 1 organelle (at 48.7%). The other 51.3% of the dataset are [multilocalizing proteins](https:\/\/www.proteinatlas.org\/humanproteome\/cell\/multilocalizing) with 2 to up to 5 labels.","2e114671":"## A3:\n\nFrom the heatmap we can see that,\n\n- Endosomes (9) and Lysosomes (10) are higly correlated, and the two of them occassionaly show up together with Endoplasmatic Reticulum (6)\n\n- Mitotik spindle (17), Cytokinetic bridges (16) and Microtubules (14) are correlated.","292a9bbf":"## A1. \n\nIt makes sense that nucleoplasm, cytosol, plasma membrane are the top occuring organelle with localized proteins, given that they are much larger in size comparing to other organelles. The plot above also agrees with Fig.2 (Protein distribution in the human cell) on [this page](https:\/\/www.proteinatlas.org\/humanproteome\/cell\/organelle)\n\nFor details about each organelle, structure and substrucutre, check out this [awesome interactive graph](https:\/\/www.proteinatlas.org\/humanproteome\/cell)\n\nThe class imbalance means that we need to,\n- do train-validation split wisely\n- maybe resample the dataset\n- look into precision-recall curve\n- use loss function that giving FN more weight than TN, for example Focal Loss","3755fc88":"We are ready to plot out the four channels of a random image id","23833986":"## Q2. \n\n**We know this is a multi-label classification problem. How many labels does the majority of images have?**","62937502":"In the train.csv, we have 31072 unique image ids and their labels.\n\nIn the training image folder,\n```\n\/kaggle\/input\/human-protein-atlas-image-classification\/train\n```\neach Image Id is associated with the following four PNGs:  \n\n- the protein of interest (green) \n- nucleus (blue)  \n- microtubules (red)  \n- endoplasmic reticulum (yellow)\n\nThe labels indicate the localization of the protein of interest, which can be within multiple organelles, meaning this is a multi-label classification problem.\n\nNow let's add the integer to text mapping of the target."}}