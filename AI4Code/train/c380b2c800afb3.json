{"cell_type":{"61935b14":"code","e7e01a9d":"code","bdb2b44b":"code","8827caaa":"code","e487af3e":"code","35cfb2f0":"code","9011eaea":"code","28594127":"code","5905d90d":"code","a51e90cf":"code","cf7c9605":"code","2ebe4e0c":"code","f5833b9c":"code","fb58007e":"code","8f40dc98":"code","62c8f7b5":"code","cf6ecf3c":"markdown","76cbc481":"markdown","57f42098":"markdown","68541444":"markdown","9466b833":"markdown","3c01e263":"markdown","670d7041":"markdown","cbcfa989":"markdown","e0b16fb5":"markdown","4f573cb4":"markdown","b513bbe5":"markdown","2ca27965":"markdown","28dbf1d0":"markdown","887ba097":"markdown","b57dac3d":"markdown","6ad4270a":"markdown","65b906d2":"markdown","6a7ad81e":"markdown","9e8e518b":"markdown","1537624d":"markdown","ea104057":"markdown","fb2bf007":"markdown","ff04e14b":"markdown","6cbfacf0":"markdown","ab16f00f":"markdown","d9de66d3":"markdown","b9d74ed4":"markdown","f5f390a5":"markdown"},"source":{"61935b14":"import pandas as pd  # To handle dataset\n\nfrom pandas import factorize  # To handle categories columns\n\nimport numpy as np   # To handle numeric values\n\n# To handle Visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Machine learning libraries\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Get dataset\ndata = pd.read_csv('..\/input\/insurance\/insurance.csv')","e7e01a9d":"data.head()","bdb2b44b":"numerical_cols = [\"age\", \"bmi\", \"charges\"]\ncategories_cols = [\"children\", \"region\", \"sex\", \"smoker\"]\n\ndef unistats(df):\n    df_stats = pd.DataFrame(columns=[\"Count\", \"Missing\", \"Dtype\", \"Unique\",\n                                     \"Mode\", \"Mean\", \"Min\", \"25%\", \"50%\", \"75%\", \"Max\", \n                                     \"Std\", \"Skew\", \"Kurt\"])\n    for col in df:\n        if pd.api.types.is_numeric_dtype(df[col]):\n            df_stats.loc[col] = [data[col].count(), data[col].isnull().sum(), data[col].dtype, data[col].nunique(),\n                                data[col].mode()[0], data[col].mean(), data[col].min(), data[col].quantile(0.25), data[col].quantile(0.5), data[col].quantile(0.75), data[col].max(),\n                                data[col].std(), data[col].skew(), data[col].kurt()]\n            \n        else:\n            df_stats.loc[col] = [data[col].count(), data[col].isnull().sum(), data[col].dtype, data[col].nunique(),\n                                data[col].mode()[0], \"-\", \"-\", \"-\", \"-\", \"-\", \"-\",\n                                \"-\", \"-\", \"-\"]\n            \n    df_stats =  df_stats.sort_index(ascending=True)  \n    return df_stats\n\nunistats(data)","8827caaa":"df = data.copy()\nfor col in categories_cols:\n    labels, categories = factorize(data[col])\n    df[col] = labels\ndf.head()","e487af3e":"df_names = df.columns.tolist()\n\ndf_corr = pd.DataFrame(columns=df_names, index=df_names[-1:])\nfor col in df:\n    df_corr[col] = round(df[col].corr(df[\"charges\"]), 3)\ndf_corr","35cfb2f0":"def proportion(data, df):\n    m = data[df].mean()\n    std = data[df].std()\n    \n    right_prop = m + std\n    left_prop = m - std\n    \n    mid_prop = len(data.loc[(data[df] < right_prop) & (data[df] > left_prop)])\/len(data[df])*100\n    left_prop = len(data.loc[data[df] < left_prop])\/len(data[df])*100\n    right_prop = len(data.loc[data[df] > right_prop])\/len(data[df])*100\n    \n    summ = mid_prop+ left_prop + right_prop\n    \n    return [left_prop, mid_prop, right_prop, summ]","9011eaea":"for col in numerical_cols:\n    plt.figure(figsize=(10,8))\n    sns.distplot(data[col])\n    plt.axvline(data[col].mean(), color='red', linestyle='--', label=\"mean\")\n    plt.axvline(data[col].median(), color='b', linestyle='--', label=\"median\")\n    plt.axvline(data[col].mode()[0], color='black', linestyle='--', label=\"mode\")\n    plt.axvline(data[col].mean() - data[col].std(), color='purple', linestyle='--', label=\"+std\")\n    plt.axvline(data[col].mean() + data[col].std(), color='green', linestyle='--', label=\"-std\")\n    plt.legend()\n    plt.show()\n    print(proportion(data, col))\n    \nfor col in categories_cols:\n    plt.figure(figsize=(10,8))\n    plt.title('Counts | Precantage', fontsize=20)\n    ax = sns.countplot(data=data, x=col, palette=\"hls\")\n    for bar in ax.patches:\n        bar_value = bar.get_height()\n        bar_perc = round(bar_value\/len(data[col])*100,2)\n        text = str(bar_value)+\" | \"+str(bar_perc)+\"%\"\n        text_x = bar.get_x() + bar.get_width() \/ 2\n        text_y = bar.get_y() + bar_value\n        bar_color = bar.get_facecolor()\n        ax.text(text_x, text_y, text, ha='center', va='bottom', color=bar_color,size=14)","28594127":"plt.figure(figsize=(12,10))\nsns.jointplot(data=data, x=\"age\", y=\"charges\", hue=\"sex\")\nsns.jointplot(data=data, x=\"age\", y=\"charges\", hue=\"sex\", kind=\"kde\")\nsns.lmplot(data=data, x=\"age\", y=\"charges\", hue=\"sex\", size=6)\n\nplt.show()","5905d90d":"plt.figure(figsize=(12,10))\nsns.jointplot(data=data, x=\"age\", y=\"charges\", hue=\"smoker\")\nsns.jointplot(data=data, x=\"age\", y=\"charges\", hue=\"smoker\", kind=\"kde\")\nsns.lmplot(data=data, x=\"age\", y=\"charges\", hue=\"smoker\", size=6)\n\nplt.show()","a51e90cf":"plt.figure(figsize=(12,10))\nsns.jointplot(data=data, x=\"bmi\", y=\"charges\", hue=\"smoker\")\nsns.jointplot(data=data, x=\"bmi\", y=\"charges\", hue=\"smoker\", kind=\"kde\")\nsns.lmplot(data=data, x=\"bmi\", y=\"charges\", hue=\"smoker\", size=6)\n\nplt.show()","cf7c9605":"corr = df.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(8, 6))\n    ax = sns.heatmap(round(corr, 3), mask=mask, vmax=.8, square=True, annot=True, cmap= \"Pastel1_r\")","2ebe4e0c":"# Plotting 3d {age, charges, bmi}\nimport plotly_express as px\n\nfig = px.scatter_3d(data, x=\"age\", y=\"charges\", z=\"bmi\", color=\"smoker\")\nfig.show()","f5833b9c":"features = df.drop(['charges'], axis = 1)\ntargets = df.charges.values.reshape(-1,1)","fb58007e":"features = StandardScaler().fit_transform(features)\ntargets = StandardScaler().fit_transform(targets)","8f40dc98":"X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state= 0)","62c8f7b5":"GS = {\n    \"n_estimators\": [10, 100],\n    'criterion': ['mse', 'poisson'],\n    'random_state': np.arange(1,5),\n    \"n_jobs\": [-1]\n}\n\nrf = RandomForestRegressor()\nrf_GS = GridSearchCV(rf, GS)\nrf_GS.fit(X_train, y_train)\n\ny_train_pred = rf_GS.predict(X_train)\ny_test_pred = rf_GS.predict(X_test)\n\nprint(f'HP: {rf_GS.best_params_}')\nprint(f'Train Score:  {round(r2_score(y_train, y_train_pred)*100, 2)}%')\nprint(f'Test Score:  {round(r2_score(y_test, y_test_pred)*100, 2)}%')","cf6ecf3c":"Now i will explore a data set to know what is cost of insurance charges for sample of people have some of features we should keep them in our mind.\n\n**So let's get start**","76cbc481":"**What is StandardScaler?**\n\nstandardizes a feature by subtracting the mean and then scaling to unit variance.\n> https:\/\/towardsdatascience.com\/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02","57f42098":"Data preprocessing in Machine Learning is a crucial step that helps enhance the quality of data to promote the extraction of meaningful insights from the data.","68541444":"# What is health insurance?!\n\nHealth insurance is a type of insurance coverage that pays for medical and surgical expenses incurred by the insured.","9466b833":"**We had passed all we want, so i hope that I was able to explain this problem clearly.**\n\n![](https:\/\/media4.giphy.com\/media\/3o6Zt6KHxJTbXCnSvu\/200.gif)","3c01e263":"# **Data_preprocessing**","670d7041":"I tried to explain everything on visualization so, i think all information on bars.","cbcfa989":"Here we will use grid search to get the hyperparameters give us best test and train score.","e0b16fb5":"Ooooh!, here is a big effect on charges, between smokers and non-smokers, the smokers pay a charges higher than non-smokers, please look at the 2 lines, you will see that charges for non-smokers increses a little bit based on age, but charges for smokers are high, **so we had know that smoking have a high effect on charges**.","4f573cb4":"![](https:\/\/phantom-marca.unidadeditorial.es\/cc5f8b927647f13bae017d9c19bd0bc0\/resize\/1320\/f\/jpg\/assets\/multimedia\/imagenes\/2021\/11\/29\/16382212439623.jpg)","b513bbe5":"**The best algorithm is: RandomForestRegressor with train score is: 97.41%, and test score is: 87.43%**","2ca27965":"Here **no difference between males and females to effect on charges**, if you look at 2 lines you will see that charges increases a little bit based on age, *so i think it's the fact.*","28dbf1d0":"**Correlation between columns**","887ba097":"![](https:\/\/media1.giphy.com\/media\/RK5SpxZukBFLVS2MjR\/giphy.gif)","b57dac3d":"Now we know 100% about dataset and understanding EDA, so this machine learning algorithm time.\n\n**let's get start.**","6ad4270a":"Here i could show the **Univariate Analysis** for all columes in dataset, then, i found out that index can sorted ascending to give us **numerical indexes up** and **categories indexes down**.\n\n   ![Great Job](https:\/\/thumbs.gfycat.com\/UniformGreedyBullmastiff-max-1mb.gif)","65b906d2":"Come on, let's explain our univariate analysis!\n\n**For numerical or categorical columns**\n\n1. The count of dataset is 1338 record.\n2. There is no any missing value in dataset.\n3. We have 4 numerical columns {age, bmi, charges, children} and 3 categorical columns {region, sex, smoker}.\n4. We have some unique values for each col but if you look at the last 2 col we'd find that each column has 2 unique value this means that 2 columns should be binary.\n\n**For just numerical columns**\n\n5. **The mode** of a set of data values is the value that appears most often.\n6. **Mean**: The \"average\" number; found by adding all data points and dividing by the number of data points.\n7. **The minimum** is the smallest value in the data set.\n8. **The first quartile** = 25% of dataset below this value in each column.\n9. **The secound quartile** = 50% = median of dataset.\n10. **The third quartile** = 75% of dataset below this value in each column.\n11. **The maximum** is the largest value in the data set.\n12. **The standard deviation** is a statistic that measures the dispersion of a dataset relative to its mean \n13. **Skewness** refers to a distortion or asymmetry that deviates from the symmetrical bell curve, or normal distribution, in a set of data. If the curve is shifted to the left or to the right, it is said to be skewed, so if the value higher than +1 it is highly right skewed or -1 it is highly left skewed\n14. **Kurtosis** is a statistical measure used to describe the degree to which scores cluster in the tails or the peak of a frequency distribution, so if the value +pos it is heavier tails or -neg it is lighter tails\n\n![](https:\/\/excelrcom.b-cdn.net\/assets\/admin\/ckfinder\/userfiles\/images\/tableau1\/tableau2\/tableau3\/tableau4\/tableau5\/tableau6\/skewness-kurtosis_1JPG-.jpg)","6a7ad81e":"Splitting dataset to 4 categories {**X_train**, **y_train**} to train algorithm, {**X_test**, **y_test**} to test algorithm.","9e8e518b":"See another big effect in bmi, okay take a look at 2 lines we will see a big correlation between bmi and charges, **the smokers have high bmi most pay the highest charges.**","1537624d":"# **Visualization**","ea104057":"We printed some of records now we will see the most important part in EDA for me, it is **Univariate Analysis** so, \n\n# What is Univariate Analysis?\n*Univariate analysis is the simplest form of analyzing data. \u201cUni\u201d means \u201cone\u201d, so in other words your data has only one variable. It doesn\u2019t deal with causes or relationships (unlike regression ) and it\u2019s major purpose is to describe; It takes data, summarizes that data and finds patterns in the data.*\n\n> https:\/\/www.statisticshowto.com\/univariate\/","fb2bf007":"Let's see correlation for each column with charges, to know what is the rate effect for columns on charges.","ff04e14b":"Ooh! the highest columns effect on charges are {**smoker**, **age**, **bmi**} **descending**, as well as the other columns not have a big effect on charges.","6cbfacf0":"Now i think that we're understanding the 50% of dataset, so the other 50% based on **visualization** let's take a look.\n\n![](https:\/\/i.gifer.com\/8mx.gif)","ab16f00f":"Here we will encode categories columns to numeric values to handle them. ","d9de66d3":"# **Import libraries**","b9d74ed4":"**Data Visualization**: helps to tell stories by curating data into a form easier to understand.","f5f390a5":"After we import libraries and put dataset in var called data, **let's print 5 records of dataset**."}}