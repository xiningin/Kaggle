{"cell_type":{"a75b9325":"code","a2b2042d":"code","8cfa87fe":"code","75351005":"code","85fa17a6":"code","7cc80603":"code","e942944e":"code","6db1a9c9":"code","7a6650a7":"code","3ae88b65":"code","5643b9b1":"code","22c2096e":"code","3c1b1a4d":"markdown","9d8f5e11":"markdown","342563f7":"markdown","1131ce11":"markdown","e11efba0":"markdown","c4f78cb9":"markdown","92ab5d28":"markdown","bd340b59":"markdown","5d26e4f7":"markdown","2e640f66":"markdown","de11d2fc":"markdown"},"source":{"a75b9325":"# Import relevant libraries for the project\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, classification_report\nplt.style.use('ggplot')","a2b2042d":"# Specify directory of train data\ndir_train = '\/kaggle\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/train\/'\ndir_train_def = dir_train+'def_front\/'  # Class label: Defective\ndir_train_ok = dir_train+'ok_front\/'    # Class label: OK\n\n# Specify directory of test data\ndir_test = '\/kaggle\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/test\/'\ndir_test_def = dir_test+'def_front\/'\ndir_test_ok = dir_test+'ok_front\/'\n\n# Plot samples of defective and non-defective casting\nfig, axes = plt.subplots(1, 2, figsize=(8,4))\nsample_def = plt.imread(dir_train_def+os.listdir(dir_train_def)[0])\nsample_ok = plt.imread(dir_train_ok+os.listdir(dir_train_ok)[0])\naxes[0].imshow(sample_def)\naxes[1].imshow(sample_ok)\naxes[0].set_title('Casting Sample: Defective', loc='left')\naxes[1].set_title('Casting Sample: OK', loc='left')\naxes[0].grid(False)\naxes[1].grid(False)\nplt.show()","8cfa87fe":"# Create dataframe of class distribution\nn_train = [len(os.listdir(dir_train_def)), len(os.listdir(dir_train_ok))]\nn_test = [len(os.listdir(dir_test_def)), len(os.listdir(dir_test_ok))]\ndist_df = pd.DataFrame(\n    data=[n_train, n_test],\n    columns=['Defective', 'OK'],\n    index=['Train', 'Test'])\n\n# Visualize class distribution\nax = dist_df.T.plot(kind='bar', stacked=True, rot=0, figsize=(8,5), colormap='Accent')\nax.set_title('Class Distribution', loc='left', weight='bold')\nfor bar in ax.patches:\n    ax.text(bar.get_x()+bar.get_width()-0.25, \n            bar.get_y()+bar.get_height()\/2,\n            int(bar.get_height()),\n            ha='center', va='center', color='white')\npct_def = 100*dist_df['Defective'].values.sum()\/dist_df.values.sum()\npct_ok = 100-pct_def\nax.set_xticklabels([f'Class: Defective ({pct_def:.0f}%)',\n                    f'Class: OK ({pct_ok:.0f}%)'], weight='bold')\nplt.show()","75351005":"# Define instances of ImageDataGenerator\ntrain_gen = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)\ntest_gen = ImageDataGenerator(rescale=1.\/255)\n\n# Specify parameters\/arguments for data generation\nimg_size, batch_size, rand_seed = (300, 300), 64, 0\narg_train = {'target_size': img_size,\n             'color_mode': 'grayscale',\n             'classes': {'ok_front': 0,\n                         'def_front': 1},\n             'class_mode': 'binary',\n             'batch_size': batch_size,\n             'seed': rand_seed}\narg_test = {'target_size': img_size,\n            'color_mode': 'grayscale',\n            'classes': {'ok_front': 0,\n                        'def_front': 1},\n            'class_mode': 'binary',\n            'batch_size': batch_size,\n            'seed': rand_seed,\n            'shuffle': False}\n\n# Generate data by iterating through directories\ntrain_set = train_gen.flow_from_directory(\n    directory=dir_train, subset='training', **arg_train)\nvalid_set = train_gen.flow_from_directory(\n    directory=dir_train, subset='validation', **arg_train)\ntest_set = test_gen.flow_from_directory(\n    directory=dir_test, **arg_test)","85fa17a6":"# Define CNN model architecture\ncnn_model = Sequential([ \n    # First block\n    Conv2D(32, 3, activation='relu', padding='same', strides=2,\n           input_shape=img_size+(1,)),\n    MaxPooling2D(pool_size=2, strides=2),\n    # Second block\n    Conv2D(64, 3, activation='relu', padding='same', strides=2),\n    MaxPooling2D(pool_size=2, strides=2),\n    # Flatenning\n    Flatten(),\n    # Fully connected layers\n    Dense(128, activation='relu'),\n    Dense(1, activation='sigmoid')        # Only 1 output\n])\n\n# Compile model\ncnn_model.compile(\n    optimizer=Adam(learning_rate=0.001),  # Default lr\n    loss='binary_crossentropy',\n    metrics=['accuracy'])\n\n# Display summary of model architecture\ncnn_model.summary()","7cc80603":"%%time\n\n# Fit model using train set and validation set\nn_epochs = 20\ncnn_model.fit(\n    train_set,\n    validation_data=valid_set,\n    epochs=n_epochs,\n    callbacks=ModelCheckpoint(\n        'CNN_Casting_Inspection.hdf5',\n        save_best_only=True,\n        monitor='val_loss'),\n    verbose=1)","e942944e":"# Plot learning curve from model history\nhisto_dict = cnn_model.history.history\nhisto_df = pd.DataFrame(histo_dict, index=range(1,n_epochs+1))\nfig, ax = plt.subplots(figsize=(8,5))\nfor m in histo_df.columns:\n    ax.plot(histo_df.index, m, data=histo_df)\nax.set_xlabel('Epoch')\nax.set_title('Learning Curve', loc='left', weight='bold')\nax.legend()\nplt.show()","6db1a9c9":"# Load saved model\nbest_model = load_model('.\/CNN_Casting_Inspection.hdf5')\n\n# Make predictions on images in the test set\ny_pred_prob = best_model.predict(test_set, verbose=1)\ny_pred = (y_pred_prob >= 0.5).reshape(-1,)\ny_true = test_set.classes[test_set.index_array]","7a6650a7":"# Visualize the confusion matrix\nfig, ax = plt.subplots(figsize=(4,3))\nax = sns.heatmap(confusion_matrix(y_true,y_pred), annot=True,\n                 annot_kws={'size':14, 'weight':'bold'},\n                 fmt='d', cbar=False, cmap='Blues')\nax.set_xticklabels(['OK', 'Defective'])\nax.set_yticklabels(['OK', 'Defective'], va='center')\nplt.tick_params(axis='both', labelsize=14, length=0)\nplt.ylabel('Actual', size=14, weight='bold')\nplt.xlabel('Predicted', size=14, weight='bold')\nplt.show()","3ae88b65":"print(classification_report(y_true, y_pred, digits=4))","5643b9b1":"class_map = {0: 'OK', 1: 'Defective'}\nimages, labels = next(iter(test_set))\nimages = images.reshape(batch_size,*img_size)\n\nfig, axes = plt.subplots(1, 3, figsize=(9, 4))\nfig.suptitle('Prediction on Test Images', y=0.98, weight='bold', size=14)\nfor ax, img, label in zip(axes.flat, images, labels):\n    ax.imshow(img, cmap='gray')\n    [[pred_prob]] = best_model.predict(img.reshape(1, *img_size, -1))\n    pred_label = class_map[int(pred_prob>=0.5)]\n    true_label = class_map[label]\n    prob_class = 100*pred_prob if pred_label=='Defective' else 100*(1-pred_prob)\n    ax.set_title(f'Actual: {true_label}', size=12)\n    ax.set_xlabel(f'Predicted: {pred_label} ({prob_class:.2f}%)',\n                  color='g' if pred_label==true_label else 'r')\n    ax.set_xticks([])\n    ax.set_yticks([])\nplt.tight_layout()\nplt.show()","22c2096e":"misclassified = np.nonzero(y_pred != y_true)[0]\nbatch_num = misclassified\/\/batch_size\nimage_num = misclassified%batch_size\n\nfig, axes = plt.subplots(1, 4, figsize=(12, 4))\nfig.suptitle('Misclassified Test Images', y=0.98, weight='bold', size=14)\nfor ax, bnum, inum in zip(axes.flat, batch_num, image_num):\n    images, labels = test_set[bnum]\n    img = images[inum]\n    ax.imshow(img.reshape(*img_size), cmap='gray')\n    [[pred_prob]] = best_model.predict(img.reshape(1, *img_size, -1))\n    pred_label = class_map[int(pred_prob>=0.5)]\n    true_label = class_map[labels[inum]]\n    prob_class = 100*pred_prob if pred_label=='Defective' else 100*(1-pred_prob)\n    ax.set_title(f'Actual: {true_label}', size=12)\n    ax.set_xlabel(f'Predicted: {pred_label} ({prob_class:.2f}%)',\n                  color='g' if pred_label==true_label else 'r')\n    ax.set_xticks([])\n    ax.set_yticks([])\nplt.tight_layout()\nplt.show()","3c1b1a4d":"# Model Building\n\nWe will use convolutional neural networks to approach the problem of classifying whether a casting is Defective or OK based on the given image. Almost universally used in computer vision applications, convolutional neural networks (CNN, convnets) is a type of deep-learning model that can look at groups of adjacent pixels in an area of an image and learn to find spatial patterns.\n\n<p style=\"text-align:center;\">\n    <img src=\"https:\/\/cezannec.github.io\/assets\/cnn_intro\/CNN_ex.png\" alt=\"CNN architecture\" width=\"500\">\n<\/p>\n<p style=\"text-align:center;font-style:italic\">Image classification with a typical CNN architecture<\/p>\n\nAs pictured above, CNN is made up of a number of layers: a series of convolutional layers (with activation), pooling layers, and at least one final fully-connected layer that produces a set of class scores for a given image. The convolutional layers of a CNN act as feature extractors; they extract shape and color patterns from the pixel values of training images.\n\nMore in-depth explanations of how each CNN layer works can be found on [this awesome blog by Cezanne Camacho](https:\/\/cezannec.github.io\/Convolutional_Neural_Networks\/).\n\nFor our model, we will adapt the general architectural principles of the [VGG models](https:\/\/arxiv.org\/abs\/1409.1556). The architecture involves stacking convolutional layers with small 3\u00d73 filters followed by a max pooling layer, together forming a block. These blocks can be repeated with increasing number of filters such as 32, 64, 128, 256.\n\nPadding is used on the convolutional layers to ensure same height and width between input and output. ReLU activation function is applied on every layer except the last one. Since a binary classification task requires a prediction of either a value of 0 or 1, the output layer is defined with 1 node and a sigmoid activation function.\n\nThe model is fit with Adam optimizer (learning rate of 0.001) and with binary cross-entropy loss function. The metric with which to monitor model training is accuracy.","9d8f5e11":"An overall classification accuracy of 99.44% is achieved by the trained model which means that, out of 715 test images, there are 4 cases of misclassification. On predicting whether or not an image is of `Defective` casting, the model scores 99.78% on recall, 99.34% on precision, and 99.56% on F1-score.\n\nFalse negatives (mis-detections), i.e., cases when `Defective` castings are predicted as `OK`, must be minimized as it may cause revenue loss for the casting company due to rejection of the whole production order by customer. On the other hand, false positives (over-detection) may increase waste and production cost, not to mention unnecessary downtime.\n\nThe metric recall helps us evaluate model performance when the cost of false negatives is high. Alternatively, when the cost of false positives is high, the metric precision is prioritized. However, since both cases of misclassification negatively impact the business, F1-score can be selected as a performance metric. F1-score is an overall measure of a model's accuracy that combines precision and recall.\n\nThe following plots show prediction results and the probability score of some images from the test set. The visualization codes are adapted from [this notebook by Tomy Tjandra](https:\/\/www.kaggle.com\/tomythoven\/casting-inspection-with-data-augmentation-cnn).","342563f7":"# Introduction\n\nOne of the ways to manufacture metal products is through a process called casting, in which liquid metal is poured into a mold to harden. Casting products may contain irregularities or defects and thus must be inspected prior shipping to ensure that customer specifications are met. Accurate inspection is important because defective products can cause rejection of the whole production order by the customers, resulting in financial loss for the casting company.\n\nVisual inspection is a non-destructive technique to detect flaws on casting products. It involves an inspector looking at each test piece with the naked eye and then classifying the product as either defective or OK based on his assessment. Due to its reliance on human factors, however, visual inspection is prone to misclassification and can be time-consuming.\n\nThis project explores automation of visual inspection with computer vision. A deep learning model called convolutional neural networks (CNN) is created to distinguish images of defective and non-defective castings.","1131ce11":"# Dataset\n\nOur casting product data comprises top-view JPEG images of cast submersible pump impellers, provided by [Pilot Technocast](https:\/\/pilottechnocast.com\/). Images were captured with Canon EOS 1300D DSLR camera. Every images are 300\u00d7300 pixels in size and already labeled as either `def_front` (defective castings) or `ok_front` (non-defective).\n\nThe folder `train` in the input directory contains images that are used for model training\/validation. Images located in the `test` folder are used to test the trained model's performance.","e11efba0":"# Conclusion","c4f78cb9":"# Data Preprocessing\n\nThe first step of preparing the data is to normalize pixel values (originally between 0 and 255) to a range of 0 to 1. This is done by passing the `rescale` arguments on instances of Keras ImageDataGenerator for train and test sets.\n\nWith the train set generator we specify `validation_split=0.2` to reserve 20% of data for validation. The function `flow_from_directory()` is then used on the data generators for each of `train\/` and `test\/` directories. Arguments for data generation are also specified:\n- Target image size is 300\u00d7300 pixels\n- `color_mode='grayscale'` to convert images as having 1 channel\n- Define class mapping: `0` for `OK`, `1` for `Defective`\n- `class_mode='binary'`  since there are two classes\n- Batch size fixed at 64","92ab5d28":"# Using Model to Classify New Images\n\nThe trained model is used to predict the class of images that weren't previously included in the training and validation process. The classification will output a probability score between 0-1 and a threshold value of 0.5 is specified to separate the classes. A probability score that is equal to or greater than this threshold is classified as `Defective`, otherwise `OK`.","bd340b59":"# Model Training and Evaluation\n\nThe model is trained for 20 epochs, each requiring 83 steps for all image batches to pass through the network. The `ModelCheckpoint` callback is specified to save the model at an epoch that yields the best value of `val_loss` (when it is most minimized). We will later load the saved model to make predictions on the test set.","5d26e4f7":"Accuracies of the model generally increase while loss decrease with increasing epoch. It can also be observed that training and validation curves are closely aligned, indicating that the model does not result in overfitting and may perform well on classifying images from the test set. Epoch 20 achieved best performance with the following results:\n- 99.81% training accuracy,\n- 98.94% validation accuracy,\n- 0.76% training loss, and\n- 2.78% validation loss.","2e640f66":"A convolutional neural networks model was created to classify images of a casting product as either Defective or OK and achieved a good performance based on F1-score (99.56%). Results of this project suggest viability of deep learning method in automating visual inspection. Incorporation of this method in the production line can provide support for trained inspectors in making better assessments of product quality.","de11d2fc":"We are performing a classification predictive modeling which involves assigning a class label (`Defective` or `OK`) for a given image of casting product. To prevent the model from making a biased prediction, the dataset must be checked for class imbalance. As shown in the following plot, there is uneven distribution between `Defective` and `OK`. However, considering the class imbalance is only by a small amount (6:4), the problem can be treated like a normal classification predictive modeling."}}