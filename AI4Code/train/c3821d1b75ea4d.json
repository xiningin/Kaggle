{"cell_type":{"92b54f6a":"code","e54e11d7":"code","56b7c9bb":"code","40c27f05":"code","fc1b1896":"code","de599703":"code","50dbd900":"code","c94d985d":"code","39ae6b9a":"code","6c5e2088":"code","cacc8e3b":"code","dda93d9b":"code","68727474":"code","5d3a33f5":"code","ced3fbe3":"code","082f48e9":"markdown","d9a3ff09":"markdown","14f0dc57":"markdown","924aa239":"markdown","cacfae9a":"markdown","5c8e85b6":"markdown","0e424a22":"markdown","1c12dd63":"markdown","21044c15":"markdown","e4382a7d":"markdown","0363ae81":"markdown"},"source":{"92b54f6a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\n# Importing required data\n\nnfl_data = pd.read_csv(\"..\/input\/nflplaybyplay2009to2016\/NFL Play by Play 2009-2017 (v4).csv\")","e54e11d7":"# look at a few rows of the nfl_data file.\nnfl_data.sample(5)\n# Missing values are represented by NaN\n","56b7c9bb":"# get the number of missing data points per column\nmissing_values_count = nfl_data.isnull().sum()\n\n# look at the # of missing points in the first ten columns\nmissing_values_count[0:10]","40c27f05":"# how many total missing values do we have?\ntotal_cells = np.product(nfl_data.shape)\ntotal_missing = missing_values_count.sum()\n\n# percent of data that is missing\n(total_missing\/total_cells) * 100","fc1b1896":"# remove all the rows that contain a missing value\nnfl_data.dropna()","de599703":"# remove all columns with at least one missing value\ncolumns_with_na_dropped = nfl_data.dropna(axis=1)\ncolumns_with_na_dropped.head()","50dbd900":"# just how much data did we lose?\nprint(\"Columns in original dataset: %d \\n\" % nfl_data.shape[1])\nprint(\"Columns with na's dropped: %d\" % columns_with_na_dropped.shape[1])","c94d985d":"# get a small subset of the NFL dataset\nsubset_nfl_data = nfl_data.loc[:, 'EPA':'Season'].head()\nsubset_nfl_data","39ae6b9a":"# replace all NA's with 0\nsubset_nfl_data.fillna(0)","6c5e2088":"# replace all NA's the value that comes directly after it in the same column, \n# then replace all the reamining na's with 0\nsubset_nfl_data.fillna(method = 'bfill', axis=0).fillna(0)","cacc8e3b":"# Your turn! Try replacing all the NaN's in the nfl_data data with the one that\n# comes directly after it and then replacing any remaining NaN's with 0","dda93d9b":"nfl_predictors = nfl_data.select_dtypes(exclude=['object'])\nfrom sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()\ndata_with_imputed_values = my_imputer.fit_transform(nfl_predictors)\n# Default behavior is filling with mean values\ndata_with_imputed_values","68727474":"# modules we'll use\nimport pandas as pd\nimport numpy as np\n\n# for Box-Cox Transformation\nfrom scipy import stats\n\n# for min_max scaling\nfrom mlxtend.preprocessing import minmax_scaling\n\n# plotting modules\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# read in all our data\nkickstarters_2017 = pd.read_csv(\"..\/input\/kickstarter-projects\/ks-projects-201801.csv\")\n","5d3a33f5":"# generate 1000 data points randomly drawn from an exponential distribution\noriginal_data = np.random.exponential(size = 1000)\n\n# mix-max scale the data between 0 and 1\nscaled_data = minmax_scaling(original_data, columns = [0])\n\n# plot both together to compare\nfig, ax=plt.subplots(1,2)\nsns.distplot(original_data, ax=ax[0])\nax[0].set_title(\"Original Data\")\nsns.distplot(scaled_data, ax=ax[1])\nax[1].set_title(\"Scaled data\")","ced3fbe3":"df = pd.DataFrame(np.random.randint(100, 200, size=(5, 3)), columns=['A', 'B', 'C'])\nprint(df)\nfrom scipy.stats import zscore\ndf.apply(zscore)","082f48e9":"## d) Imputation \/ Filling in the missing values with some meaningful number","d9a3ff09":"## b) Filling in the missing values automatically with some global constant","14f0dc57":"## b) Z score normalization","924aa239":"We can use the Panda's fillna() function to fill in missing values in a dataframe for us. One option we have is to specify what we want the `NaN` values to be replaced with. Here, we're going  to replace all the `NaN` values with 0.","cacfae9a":"## c) Filling in missing values with adjacent values","5c8e85b6":"## a) MinMax Scaling","0e424a22":"# Why do we need data preprocessing?\n* Incomplete data\n* Noisy data\n* Inconsistent data\n\n# Major tasks in data preprocessing\n1. Data cleaning\n2. Data integration\n3. Data reduction\n4. Data discretization\n5. Data transformation\n___","1c12dd63":"# 2. Data Transformation\n","21044c15":"## Take a first look at the data","e4382a7d":"# 1. Data Cleaning\n## a) Dropping missing values","0363ae81":"### Sources:\n* https:\/\/www.kaggle.com\/rtatman\/data-cleaning-challenge-handling-missing-values\n* https:\/\/www.kaggle.com\/dansbecker\/handling-missing-values\n* https:\/\/stackoverflow.com\/questions\/24761998\/pandas-compute-z-score-for-all-columns\n* https:\/\/scikit-learn.org\/stable\/modules\/preprocessing.html\n* ** https:\/\/data-flair.training\/blogs\/python-ml-data-preprocessing\/**"}}