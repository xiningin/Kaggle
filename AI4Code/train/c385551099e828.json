{"cell_type":{"128cc2c3":"code","4301bf99":"code","8f1419c1":"code","cbe3354c":"code","00758cf3":"code","3dd31491":"code","1f1c4884":"code","071fbd8c":"code","46b40340":"code","8d2d6d97":"code","532b3dfc":"code","eecf07c5":"code","4ccfdcdb":"code","f3760422":"code","305a2171":"code","7673553f":"code","00eb5a06":"code","7e2bb54e":"code","6bed22dc":"code","cd102a2a":"code","25c708db":"code","dcfe2e15":"code","8d129638":"code","613e98b6":"code","8b478de7":"code","38004fc6":"code","4caf417a":"code","ee6ec8bd":"code","1bc011f2":"code","fc9e7ae6":"code","b96ce8ba":"code","93be7f6a":"code","fcd09dc0":"code","ae83750c":"code","cfe996c5":"code","76292177":"code","1d729c1d":"code","c0827aac":"code","90d77cc0":"code","600bf610":"code","8ff090be":"code","de99683c":"code","1f19d10a":"code","77ead5d2":"code","eccab8be":"code","a874fbd7":"code","43fdfb2d":"code","71e9efa4":"code","7f6d7e3f":"code","8fab634b":"code","b0f13acb":"code","2c6321ca":"code","009bcd94":"code","3948f4f1":"code","0bf2fc13":"code","bded93b0":"code","3f9c8763":"code","9db77c29":"code","e8687d3c":"code","8160026c":"code","3a012950":"code","afa3f96d":"code","37e9ff72":"code","67307f55":"code","97babf2e":"code","da1ed891":"code","43d6c58d":"code","921a60bf":"code","586f19cb":"code","3d629973":"code","544d75f8":"code","8e48a85b":"markdown","878d3627":"markdown"},"source":{"128cc2c3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt #likley won't be used much as i'm experimenting with plotly \nimport plotly.graph_objects as go #you will be learning how go and px work with me! \nimport plotly.express as px \n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4301bf99":"#load data \ndf = pd.read_csv('\/kaggle\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\ndf.shape\n#remove the top row\ndf_fin = df.iloc[1:,:]","8f1419c1":"#inspect the data and questions \ndf.head()","cbe3354c":"#create a dictionary for questions \nQuestions = {}\n\n#create list of questions \n#not very efficient, but keeps things ordered\nqnums = list(dict.fromkeys([i.split('_')[0] for i in df_fin.columns]))\n\n#add data for each question to key value pairs in dictionary\nfor i in qnums:\n    if i in ['Q1','Q2','Q3']: #since we are using .startswith() below this prevents all questions that start with \n        Questions[i] = df_fin[i] #[1,2,3] from going in the key value pair (Example in vid)\n    else:\n        Questions[i] = df_fin[[q for q in df_fin.columns if q.startswith(i)]]","00758cf3":"# create disctionary for different gender selections \nGenders = {}\nfor i in df_fin.Q2.unique():\n    Genders[i] = df_fin[df_fin.Q2 == i]","3dd31491":"# Notes I created as I was going\n\n#Brief EDA \/ Pivot Tables \n## Heatmap \n## Percentage distribution\n## Income by Gender By Country \n## Income by Gender \n## Income by Skills\n## Income by Role\n## Income by Education \n\n# Convert Salary to Continuous?\n# Which variables to consider? \n# Regression for Income --> Paying particular attention to Gender\n# Regression for Income --> Men and Women (2 different Regressions)\n\n#Normalize for female population of sample ","1f1c4884":"#look at gender distribution\ndf_fin.Q2.value_counts()\/ df_fin.Q2.value_counts().sum()","071fbd8c":"#filter dataframe for male & female for simplicity (not that prefer not & nonbinary aren't important!)\ndf_mf = df_fin[df_fin.Q2.isin(['Man','Woman'])] ","46b40340":"#DS is clearly already a male dominated field (or at least this sample of kaggle users is)\ndf_mf.Q2.value_counts()\/ df_mf.Q2.value_counts().sum() ","8d2d6d97":"#Female Distribution by Role \nfig= px.histogram(df_mf,x='Q4',color ='Q2')\nfig.show()","532b3dfc":"#Female Distribution by Role Normalized by sample of respective population \nfig= px.histogram(df_mf,x='Q4',color ='Q2', histnorm='probability density')\nfig.show()","eecf07c5":"#Percent more or less than distribution of the average population of women (Absolute)\nmale_degrees = df_mf[df_mf.Q2 == 'Man'].Q4.value_counts()\nfemale_degrees = df_mf[df_mf.Q2 == 'Woman'].Q4.value_counts()\ntotal_degrees = df_mf.Q4.value_counts()\nmore_women = (female_degrees\/total_degrees)-.197 #greater proportion of women than sample\nmore_women['Color'] = np.where(more_women.values <0, 'blue','red')\nfig = go.Figure(go.Bar(x=(female_degrees\/total_degrees).index, y= (female_degrees\/total_degrees).values-.197, marker_color=more_women.Color))\nfig.update_layout(title= \"Level of Female Education Relative to AVG of Sample (19.7%)\")\nfig.show()\n","4ccfdcdb":"#Female Distribution by Country\nfig= px.histogram(df_mf,x='Q3',color ='Q2')\nfig.update_xaxes(categoryorder= \"total descending\")\nfig.show()\n","f3760422":"#Percent more or less than distribution of the average population of women \nmale_country = df_mf[df_mf.Q2 == 'Man'].Q3.value_counts()\nfemale_country = df_mf[df_mf.Q2 == 'Woman'].Q3.value_counts()\ntotal_country = df_mf.Q3.value_counts()\nmore_women = (female_country\/total_country)-.197 #greater proportion of women than sample\nmore_women['Color'] = np.where(more_women.values <0, 'blue','red')\nfig = go.Figure(go.Bar(x=(female_country\/total_country).index, y= (female_country\/total_country).values-.197, marker_color=more_women.Color))\nfig.update_layout(title= \"Amount of Women By Country Relative to AVG of Sample (19.7%)\")\nfig.update_layout(xaxis={'categoryorder':'total descending'})\nfig.show()\n#flip colors \ntotal_country\nfemale_country","305a2171":"#function for creating new graphs \ndef create_norm_graph(qnum, data, title, baseline):\n    male = data[data.Q2 == 'Man'][qnum].value_counts()\n    female = data[data.Q2 == 'Woman'][qnum].value_counts()\n    total = data[qnum].value_counts()\n    more_women = (female\/total)-baseline #greater proportion of women than sample\n    more_women['Color'] = np.where(more_women.values <0, 'blue','red')\n    fig = go.Figure(go.Bar(x=(female\/total).index, y= (female\/total).values-baseline, marker_color=more_women.Color))\n    fig.update_layout(title= title)\n    fig.update_layout(xaxis={'categoryorder':'total descending'})\n    fig.show()\n    return ","7673553f":"# which countries have the most relative female representitives in the survey?\ncreate_norm_graph('Q3',df_mf,\"Amount of Women By Country Relative to AVG of Sample (19.7%)\",.197)","00eb5a06":"#Which roles have the most women relative to the baseline?\ncreate_norm_graph('Q5',df_mf,\"Amount of Women By Role Relative to AVG of Sample (19.7%)\",.197)","7e2bb54e":"#create new baseline for only employed people\ndf_workers_mf = df_mf[~df_mf['Q5'].isin(['Student','Currently not employed'])]\ndf_workers_mf.Q2.value_counts()\/df_workers_mf.Q2.value_counts().sum()","6bed22dc":"# Women's experience \ncreate_norm_graph('Q6',df_workers_mf,\"Amount of Women By Experience Relative to AVG of Sample (17.4%)\",.174)\n\n#absolute number is a lot lower \ndf_workers_mf.Q6.value_counts()","cd102a2a":"#by income level \ncreate_norm_graph('Q24',df_workers_mf,\"Amount of Women By Income Level Relative to AVG of Sample (17.4%)\",.174)\ndf_workers_mf.Q24.value_counts()","25c708db":"#graph for just data scientists \ndf_mf_ds= df_mf[df_mf['Q5'] =='Data Scientist']\ncreate_norm_graph('Q24',df_mf_ds,\"Amount of Women By Country Relative to AVG of Sample (17.4%)\", .174)","dcfe2e15":"#count for perspective, some sample size issues here\ndf_mf_ds.Q24.value_counts()","8d129638":"#graph for US \ndf_mf_US= df_mf[df_mf['Q3'] =='United States of America']\ncreate_norm_graph('Q24',df_mf_US,\"Amount of Women By Country Relative to AVG of Sample (17.4%)\",.174)","613e98b6":"df_mf_US.Q24.value_counts()","8b478de7":"#Income by role (awful graph I know)\nfig= px.histogram(df_fin.dropna(subset=['Q24','Q5']),x='Q24',color ='Q5')\nfig.update_xaxes(categoryorder= \"total descending\")\nfig.show()","38004fc6":"#Income by experience \nfig= px.histogram(df_fin.dropna(subset=['Q24','Q6']),x='Q24',color ='Q6')\nfig.update_xaxes(categoryorder= \"total descending\")\nfig.show()","4caf417a":"#Income by education\nfig= px.histogram(df_fin.dropna(subset=['Q24','Q4']),x='Q24',color ='Q4')\nfig.update_xaxes(categoryorder= \"total descending\")\nfig.show()","ee6ec8bd":"#convert dollar ranges to numeric \n#explore converting other continuious variables \n#build model with just gender ","1bc011f2":"#replace '$',',','>' in data \ndf_model = df_fin.dropna(subset=['Q24'])\ndf_model['salary_cleaned'] = df_model.Q24.apply(lambda x: str(x).replace('$','').replace(',','').replace('>','').strip())\ndf_model.salary_cleaned.value_counts()","fc9e7ae6":"#create min range and max range for salary \ndf_model['salary_min'] = df_model.salary_cleaned.apply(lambda x: 500000 if '-' not in x else int(x.split('-')[0]))\ndf_model['salary_max'] = df_model.salary_cleaned.apply(lambda x: 500000 if '-' not in x else int(x.split('-')[1]))\n\ndf_model.salary_max.value_counts()","b96ce8ba":"#Convert to rough continuous variable \ndf_model['aprox_salary'] = (df_model.salary_min+df_model.salary_max)\/2\ndf_model.aprox_salary.value_counts()","93be7f6a":"#simple linear regression just gender \nimport statsmodels.api as sm ","fcd09dc0":"#filter for men & women \ndf_model_fin = df_model[df_model.Q2.isin(['Man','Woman'])] \n#filter for workers \ndf_model_fin = df_model_fin[~df_model_fin['Q5'].isin(['Student','Currently not employed'])]\ndf_model_fin.drop('Time from Start to Finish (seconds)', axis =1, inplace = True)","ae83750c":"df_model_fin.isnull().any()","cfe996c5":"# create dummy variables, this is needed because essentially all our data is categorical\nmodel_dummies = pd.get_dummies(df_model_fin)\nmodel_dummies","76292177":"# We only need one gender in this case because we trimmed it to only have Men & Women\nY = model_dummies.aprox_salary\nX = model_dummies.Q2_Man","1d729c1d":"#for statsmodels, we need to add a constant to create intercept \nX = sm.add_constant(X)","c0827aac":"#fit model with data \nmodel = sm.OLS(Y,X)\nresults= model.fit()","90d77cc0":"#create summary report (watch video to see interpretation)\nresults.summary()","600bf610":"# create function to add additional questions to dataframe for easier processing\ndef qnums(question_list, dataframe):\n    q_out = [] \n    for i in question_list:\n        for j in dataframe.columns:\n            if i == j.split('_')[0]:\n                q_out.append(j)\n    return dataframe.loc[:,q_out]\n        \n#create data for questions 2,4,5\nq245 =  qnums(['Q2','Q4','Q5'], model_dummies)\nq245","8ff090be":"#drop one of the gender columns, it is redundant \nX = q245.drop('Q2_Man', axis=1)\nX = sm.add_constant(X)","de99683c":"#build model with additional features education, gender, and role \nmodel = sm.OLS(Y,X)\nresults= model.fit()\nresults.summary()","1f19d10a":"#questions 2,4,5,7 add in programming languages \n        \nq2457 =  qnums(['Q2','Q4','Q5','Q7'], model_dummies).drop('Q2_Man', axis=1)\nq2457\n","77ead5d2":"X = q2457\nX = sm.add_constant(X)","eccab8be":"model = sm.OLS(Y,X)\nresults= model.fit()\nresults.summary()","a874fbd7":"#questions 2,3,4,5,7 add in country (huge boost in model performance)\n        \nq24573 =  qnums(['Q2','Q4','Q5','Q7','Q3'], model_dummies).drop('Q2_Man', axis=1)\nq24573\n","43fdfb2d":"X = q24573\nX = sm.add_constant(X)","71e9efa4":"model = sm.OLS(Y,X)\nresults= model.fit()\nresults.summary()","7f6d7e3f":"# lasso regression \n# random forest \n#remove some features ","8fab634b":"#questions 2,3,4,5,6,7\n        \nq245736 =  qnums(['Q2','Q4','Q5','Q7','Q3','Q6','Q20'], model_dummies).drop('Q2_Man', axis=1)\nX = q245736\nX = sm.add_constant(X)","b0f13acb":"model2 = sm.OLS(Y,X)\nresults= model2.fit()\nresults.summary()","2c6321ca":"#fit model with lasso parameters Set alpha high enough to eliminate some variables \nresults_reg = model2.fit_regularized(L1_wt=1, alpha= 5)\nfinal = sm.regression.linear_model.OLSResults(model2,results_reg.params,model2.normalized_cov_params)\nprint(final.summary())","009bcd94":"from sklearn.ensemble import RandomForestRegressor","3948f4f1":"#compare random forest feature importance (allows us to rank)\nclf_rf = RandomForestRegressor()\nclf_rf.fit(X,Y)","0bf2fc13":"feat_importances = pd.Series(clf_rf.feature_importances_, index=X.columns)\nax  = feat_importances.nlargest(25).sort_values().plot(kind='barh', figsize=(6,12))\nax.barh([2],feat_importances.loc['Q2_Woman'],color='red')","bded93b0":"#build models for men and women independently. See how they estimate salary on the same data \n#I think this is a decent way to isolate individual effects of education, country, etc.\nWomen_Model = model_dummies[model_dummies.Q2_Man == 0]\nMen_Model = model_dummies[model_dummies.Q2_Man == 1]","3f9c8763":"# create and train women's model \nwomen_fin =  qnums(['Q4','Q5','Q7','Q3','Q6','Q20'], Women_Model)\nY_W = Women_Model.aprox_salary\nX_W = women_fin\nX_W = sm.add_constant(X_W)\n\nWomen_Model","9db77c29":"model_W = sm.OLS(Y_W,X_W)\nresults_W= model_W.fit()\nresults_W.summary()","e8687d3c":"results_reg_W = model_W.fit_regularized(L1_wt=1, alpha= 5)\nfinal_W = sm.regression.linear_model.OLSResults(model_W,results_reg_W.params,model_W.normalized_cov_params)\nprint(final_W.summary())","8160026c":"#create and train men's model \nmen_fin =  qnums(['Q4','Q5','Q7','Q3','Q6','Q20'], Men_Model)\nY_M = Men_Model.aprox_salary\nX_M = men_fin\nX_M = sm.add_constant(X_M)\n\nmodel_M = sm.OLS(Y_M,X_M)\nresults_M= model_M.fit()\nresults_M.summary()","3a012950":"results_reg_M = model_M.fit_regularized(L1_wt=1, alpha= 5)\nfinal_M = sm.regression.linear_model.OLSResults(model_M,results_reg_M.params,model_M.normalized_cov_params)\nprint(final_M.summary())","afa3f96d":"#run model on all data & compare \ncombined_data = qnums(['Q4','Q5','Q7','Q3','Q6','Q20'], model_dummies)\nmale_preds = final_M.predict(np.array(sm.add_constant(combined_data)))\nfemale_preds = final_W.predict(np.array(sm.add_constant(combined_data)))","37e9ff72":"combined_data['male_preds'] = male_preds\ncombined_data['female_preds'] = female_preds","67307f55":"combined_data['aprox_salary'] = model_dummies.aprox_salary\ncombined_data","97babf2e":"px.scatter(combined_data.sort_values('aprox_salary'), x = 'aprox_salary', y = ['male_preds','female_preds'])","da1ed891":"combined_data['projected_diff'] = combined_data.male_preds - combined_data.female_preds","43d6c58d":"combined_data.projected_diff.mean()","921a60bf":"combined_data.projected_diff.std()","586f19cb":"combined_data['women_prj_higher'] = combined_data.projected_diff.apply(lambda x: 1 if x < 0 else 0)","3d629973":"combined_data.women_prj_higher.value_counts()","544d75f8":"## Next Steps\n#roles\n#countries\n#sample size\n#t test men & women\n#would love people to expand on this","8e48a85b":"# Attempting to Quantify Gender Differences in Kaggle Dev Survey\n\nThis notebook is meant to accompany this video: https:\/\/youtu.be\/GO420aMtHfk\n\nTo see part 1 & 2 of this series refer to these resources:\n- Part 1 video: https:\/\/www.youtube.com\/watch?v=r-DR9HBaipU&ab_channel=KenJee\n- Part 2 video: https:\/\/www.youtube.com\/watch?v=KQ80oD_boBM&ab_channel=KenJee\n- Kaggle Kernel (Part 2): https:\/\/www.kaggle.com\/kenjee\/kaggle-project-from-scratch\n\nOne of the initial questions that came up in part 1 of my analysis was how much gender inequality is there currently in data science. Assuming there is some (80 % of the samples being male makes me think there probably is...), how does this impact earning potential. \n\nIn this notebook I:\n1. First visualize and normalize gender differences in the sample \n2. Run a multiple linear regression to understand which factors contribute most to earning potential\n3. Run a lasso regression to narrow variable set and try to quantify the extent gender impacts earning potential\n4. Run a random forest on same data to evaluate feature importance (A nonlinear model like this is a good check)\n5. Compare models for just subsets of women and men to hopefully normalize for more variables ","878d3627":"# Building a Model \nI thought it made more sense to use a regression here to try to predict salary. Although it will be very rough around the edges, I think converting the salaries from categorical to numeric will allow us to more easily interperet the data. "}}