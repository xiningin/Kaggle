{"cell_type":{"1908044e":"code","bd5f6d14":"code","e796eeda":"code","08d78c99":"code","cd09dfd2":"code","7715f462":"code","671264a7":"code","5996ceb0":"code","9aa5e40f":"code","a487881e":"code","12b412a9":"code","c4efb589":"code","dba24a74":"code","bb5e61db":"code","cc7ff5c2":"code","74617211":"code","123dc2c6":"code","156f12a8":"code","bdd5f76b":"code","32f3a8c4":"code","8ec4c36a":"code","9acce532":"code","3f294505":"code","216d0dee":"code","774dfa19":"code","cf86f506":"code","3aa6559b":"code","380caefc":"code","20a8df2a":"code","3306f8f4":"code","0a9d9253":"markdown","62c5cdb0":"markdown","1ed31bae":"markdown","75b61acd":"markdown","7b13c032":"markdown","69906d35":"markdown","73c558da":"markdown","5492d961":"markdown","47e4e70e":"markdown","7dd28bd4":"markdown","f595637c":"markdown","4141d339":"markdown","55987c02":"markdown","0d80233e":"markdown","bcd6df78":"markdown","a306520f":"markdown","ae3f96cf":"markdown","22016946":"markdown","56a9047c":"markdown","8348f6dc":"markdown","db1ae13e":"markdown","1230f890":"markdown"},"source":{"1908044e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","bd5f6d14":"from zipfile import ZipFile\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport seaborn as sb","e796eeda":"zip = ZipFile('\/kaggle\/input\/whats-cooking\/train.json.zip','r')\nzip.extractall()\nzip = ZipFile('\/kaggle\/input\/whats-cooking\/test.json.zip','r')\nzip.extractall()","08d78c99":"for dirname, _, filenames in os.walk('\/kaggle\/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cd09dfd2":"feed = pd.read_json('\/kaggle\/working\/train.json')\nfeed","7715f462":"ingre=set()\n\nfor i in feed['ingredients']:\n    for j in i:\n        if j in ingre:\n            pass\n        else:\n            ingre.add(j)\nprint (\"Number of Ingredients :\" + str(len(ingre)))\n\ncus= set()\nfor i in feed['cuisine']:\n    if i in cus:\n        pass\n    else:\n        cus.add(i)\nprint (\"Number of Cuisines :\"+str(len(cus)))","671264a7":"feed.drop('id',axis = 1).groupby('cuisine').count().plot(kind='bar')","5996ceb0":"ingre = sorted(ingre)\ningre","9aa5e40f":"columns = list(ingre)\n\nfor i in columns:\n    tem =[ ]\n    for j in feed['ingredients']:\n        if i in j:\n            tem.append(1)\n        else:\n            tem.append(0)\n    feed[i] = tem\nfeed.head()","a487881e":"feed.head()","12b412a9":"feed.columns","c4efb589":"feed = feed.drop(['id','ingredients'],axis = 1)\nfeed.head()","dba24a74":"df_train_x = feed.drop('cuisine',axis = 1)\ndf_train_y = feed[['cuisine']]","bb5e61db":"a=[]\ncuisine = list(cus)\nfor i in df_train_y.cuisine:\n    a.append(cuisine.index(i))\ndf_train_y['cuisine'] = a\ndf_train_y.describe()","cc7ff5c2":"df_train_y.describe","74617211":"x_train, x_test, y_train, y_test = train_test_split(df_train_x, df_train_y, test_size=0.15, random_state=42)","123dc2c6":"acc=[]\ngauss = GaussianNB().fit(x_train,y_train)\nprediction = gauss.predict(x_test)\ny_test['output'] = prediction\n\naccuracy = 0\ny_test['equal'] = np.where(y_test['cuisine']==y_test['output'],1,0)\nfor i in y_test.equal:\n    accuracy +=i\naccuracy = (accuracy\/5967)*100\nacc.append((accuracy))","156f12a8":"dt = DecisionTreeRegressor().fit(x_train,y_train)\nprediction = dt.predict(x_test)\ny_test['output'] = prediction\n\naccuracy = 0\ny_test['equal'] = np.where(y_test['cuisine']==y_test['output'],1,0)\nfor i in y_test.equal:\n    accuracy +=i\naccuracy = (accuracy\/5967)*100\nacc.append((accuracy))","bdd5f76b":"rf = RandomForestRegressor(n_estimators = 10).fit(x_train,y_train)\nprediction = rf.predict(x_test)\ny_test['output'] = prediction\n\naccuracy = 0\ny_test['equal'] = np.where(y_test['cuisine']==y_test['output'],1,0)\nfor i in y_test.equal:\n    accuracy +=i\naccuracy = (accuracy\/5967)*100\nacc.append((accuracy))","32f3a8c4":"acc","8ec4c36a":"y_test.describe","9acce532":"dt = DecisionTreeRegressor().fit(df_train_x,df_train_y)","3f294505":"test = pd.read_json('\/kaggle\/working\/test.json')\ncolumns = list(ingre)\n\nfor i in columns:\n    tem =[]\n    for j in test['ingredients']:\n        if i in j:\n            tem.append(1)\n        else:\n            tem.append(0)\n    test[i] = tem\ntest.head()","216d0dee":"test_output = test[['id']]","774dfa19":"test.columns","cf86f506":"test = test.drop(['id','ingredients'],axis=1)\ntest.columns","3aa6559b":"predictions = dt.predict(test)\n\ntest_output['cuisine'] = predictions\n\ntest_output.describe()","380caefc":"cuisines = []\ntest_output.describe\nfor i in test_output.cuisine:\n    cuisines.append(cuisine[int(i)])\ntest_output['cuisine'] = cuisines ","20a8df2a":"test_output.describe","3306f8f4":"test_output.to_csv('submission.csv',index=False)","0a9d9253":"## Implementing one hot endcoding for the all the ingredients","62c5cdb0":"We can see that the decison tree model works kmuch better compared to the Gaussian classifier so we use the decision tree.","1ed31bae":"# Preparing the training data set.","75b61acd":"### Performing train test split. ","7b13c032":"## Exporting output to csv","69906d35":"#### Gaussian classifier","73c558da":"# Preparing Training and Testing datasets.","5492d961":"### Predicting values over test set.","47e4e70e":"## Plotting the counts of various cuisines.","7dd28bd4":"## Loading dataset into memory.","f595637c":"## Extracting the different types of ingredients and cuisines.","4141d339":"### Retraining over the whole data set.","55987c02":"## Converting cuisines to numbers as some models require numbers like decision trees.","0d80233e":"### One Hot encoding of test data.","bcd6df78":"## Machine learning Model","a306520f":"#### Decision Tree","ae3f96cf":"Our data set consists of 20 different cuisines made from 6714 different ingredients","22016946":"# Importing important libraries","56a9047c":"### Comparing accuracies of different models.","8348f6dc":"## Preparing test data. ","db1ae13e":"## Extracting the zip files","1230f890":"#### Random Forest "}}