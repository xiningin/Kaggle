{"cell_type":{"a889bfa7":"code","86a122cd":"code","c25b2d86":"code","1ca7dcfd":"code","b60066b9":"code","921a842f":"code","426ecc21":"code","3e414c0d":"code","54c5ada9":"code","c185be36":"code","5708cb7c":"code","9c3a13f0":"markdown","9991bbaf":"markdown","dca1be2f":"markdown","424bfc56":"markdown","39b0e36e":"markdown"},"source":{"a889bfa7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport datatable as dt  # pip install datatable - for faster data download\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport random\n\nfrom matplotlib.lines import Line2D\n\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBClassifier\n\n\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.metrics import roc_auc_score, plot_roc_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import precision_recall_curve\n\nimport optuna\n\n# Pandas setting to display more dataset rows and columns\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%.5f' % x)\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=UserWarning)","86a122cd":"# Read the data\ntrain = dt.fread(\"..\/input\/tabular-playground-series-sep-2021\/train.csv\").to_pandas().set_index(\"id\")\ntest = dt.fread(\"..\/input\/tabular-playground-series-sep-2021\/test.csv\").to_pandas().set_index(\"id\")","c25b2d86":"print(\"(train, test) na --> \",(train.isna().sum().sum(), test.isna().sum().sum()))","1ca7dcfd":"is_na_train_df = train.drop(columns=\"claim\").isna().sum(axis = 1)\nprint(is_na_train_df.shape)\n\nis_na_test_df = test.isna().sum(axis = 1)\nprint(is_na_test_df.shape)","b60066b9":"train[\"isNA\"] =is_na_train_df\nprint(train.shape)\n\ntest[\"isNA\"] = is_na_test_df\nprint(test.shape)\n","921a842f":"### Sampling data to reduce time during NB writing process\n\n# Uncomment to some try and error session\n# train = train.head(10000)\n# test = test.head(10000)","426ecc21":"x_Mm_scaler = MinMaxScaler()\nX = pd.DataFrame(x_Mm_scaler.fit_transform(train.drop(\"claim\", axis=1)),\n                 columns=train.drop(\"claim\", axis=1).columns)\ny = train.claim\nX_test = pd.DataFrame(x_Mm_scaler.transform(test), columns=test.columns)","3e414c0d":"imputer_zeros = SimpleImputer(strategy=\"median\")\nX = pd.DataFrame(imputer_zeros.fit_transform(train.drop(\"claim\", axis=1)),\n                 columns=train.drop(\"claim\", axis=1).columns)\nX_test = pd.DataFrame(imputer_zeros.transform(test), columns=test.columns)\nX = pd.DataFrame(x_Mm_scaler.fit_transform(X),\n                 columns=train.drop(\"claim\", axis=1).columns)\nX_test = pd.DataFrame(x_Mm_scaler.transform(X_test), columns=test.columns)\nprint(\"(train, test) na --> \",(X.isna().sum().sum(), X_test.isna().sum().sum()))","54c5ada9":"# Parameters from a 2 hours Optuna Optimization here: https:\/\/www.kaggle.com\/sgiuri\/sep21tp-optuna-feature-eng-xgbc\nxgb_params = {'n_estimators': 10000, \n              'learning_rate': 0.08625196792060146, \n              'subsample': 0.5959773829663169, \n              'colsample_bytree': 0.7603045913120982, \n              'max_depth': 7, 'booster': 'gbtree', \n              'tree_method': 'gpu_hist', # comment this line if you don't have a GPU\n              'reg_lambda': 74.60593770387143, \n              'reg_alpha': 33.38858560681472, \n              'random_state': 42, \n              'n_jobs': 4}\n","c185be36":"splits = 8\nskf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=42)\noof_preds = np.zeros((X.shape[0],))\npreds = 0\nmodel_fi = 0\ntotal_mean_rmse = 0\ntotal_mean_roc_auc_score = 0\n\ntprs = []\naucs = []\nmean_fpr = np.linspace(0, 1, 100)\n\nfig, ax = plt.subplots(figsize=(16,16))\n\n\nfor fold, (train_indicies, valid_indicies) in enumerate(skf.split(X,y)):\n    \n    X_train, X_valid = X.loc[train_indicies], X.loc[valid_indicies]\n    y_train, y_valid = y.loc[train_indicies], y.loc[valid_indicies]\n\n    model = XGBClassifier(**xgb_params)\n    print(f\"Fitting fold {fold+1} of {splits} \")\n    model.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              eval_metric=\"auc\",\n              early_stopping_rounds=100,\n              verbose=False)\n    \n    viz = plot_roc_curve(model, X_valid, y_valid,\n                         name='ROC fold {}'.format(fold),\n                         alpha=0.3, lw=1, ax=ax)\n    \n    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n    interp_tpr[0] = 0.0\n    tprs.append(interp_tpr)\n    aucs.append(viz.roc_auc)\n    \n  \n    preds += (model.predict_proba(X_test))[:,1] \/ splits\n    model_fi += model.feature_importances_\n    \n    oof_preds[valid_indicies] = model.predict_proba(X_valid)[:,1]\n    oof_preds[oof_preds < 0] = 0\n#     fold_rmse = np.sqrt(mean_squared_error(y_scaler.inverse_transform(np.array(y_valid).reshape(-1,1)), y_scaler.inverse_transform(np.array(oof_preds[valid_idx]).reshape(-1,1))))\n    fold_roc_auc_score = roc_auc_score(y_valid, oof_preds[valid_indicies])\n    # fold_rmse = np.sqrt(mean_squared_error(y_valid, oof_preds[valid_indicies]))\n    print(f\"Fold {fold} ROC AUC Score: {fold_roc_auc_score}\")\n#         print(f\"Trees: {model.tree_count_}\")\n    # total_mean_rmse += fold_rmse \/ splits\n    total_mean_roc_auc_score += fold_roc_auc_score \/ splits\nprint(f\"\\nOverall ROC AUC Score: {total_mean_roc_auc_score}\\n\\n\")\nax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n        label='Chance', alpha=.8)\n\nmean_tpr = np.mean(tprs, axis=0)\nmean_tpr[-1] = 1.0\nmean_auc = auc(mean_fpr, mean_tpr)\nstd_auc = np.std(aucs)\nax.plot(mean_fpr, mean_tpr, color='b',\n        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.4f)' % (mean_auc, std_auc),\n        lw=2, alpha=.8)\n\nstd_tpr = np.std(tprs, axis=0)\ntprs_upper = np.minimum(mean_tpr + std_tpr, 1)\ntprs_lower = np.maximum(mean_tpr - std_tpr, 0)\nax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n                label=r'$\\pm$ 1 std. dev.')\n\nax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n       title=\"Receiver operating characteristic\")\nax.legend(loc=\"lower right\")\nplt.show()","5708cb7c":"# xgb public Score untuned and fast parameters: 0.76817\npredictions = pd.DataFrame()\npredictions[\"id\"] = test.index\npredictions[\"claim\"] = preds\n\npredictions.to_csv('submission.csv', index=False, header=predictions.columns)\npredictions.head()","9c3a13f0":"# Creating Folds and representing the Roc Curve","9991bbaf":"In this ntebook i'm going to apply the ROC woth cross validation, following the guide in the Scikit-learn.org procedure: \nhttps:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py\n\n> ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the \u201cideal\u201d point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.\n> \n> The \u201csteepness\u201d of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate.\n> \n> This example shows the ROC response of different datasets, created from K-fold cross-validation. Taking all of these curves, it is possible to calculate the mean area under curve, and see the variance of the curve when the training set is split into different subsets. This roughly shows how the classifier output is affected by changes in the training data, and how different the splits generated by K-fold cross-validation are from one another.","dca1be2f":"# Libraries and Data import","424bfc56":"## Data preparation: Feature enG + Siple Imputer + NA to median","39b0e36e":"# NA values in train and test"}}