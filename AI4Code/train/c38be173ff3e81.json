{"cell_type":{"edd64e6b":"code","f478ad31":"code","cdd6f987":"code","b1924f29":"code","124c2566":"code","d1dca4f2":"code","30e3e41a":"code","24079d79":"code","0d52e9ec":"code","b9b1a2ff":"code","e996d02f":"code","e3a03c08":"code","d264b05c":"code","28a0c69a":"code","37a37b63":"code","ac91f11f":"code","7fd39abc":"code","2fdffb06":"code","63e3a8c6":"code","788ab166":"code","d186356d":"code","7ceba245":"code","e78a958f":"code","397b7c53":"code","ef1fd73f":"code","e4a029e4":"code","9b6a67be":"code","8c683880":"code","5e59cceb":"code","108c5324":"code","572fb605":"code","2087092f":"code","5cb6cfae":"code","fc919887":"code","45761369":"code","9fb80020":"code","12b8c9b2":"code","b090a6af":"code","15f79931":"code","bef350ae":"code","cdee8f5d":"code","7160daee":"code","1b19ebfa":"code","3ab91b45":"code","5df5d979":"code","1d92d9e9":"code","eef34c2e":"code","bc47ca54":"code","2d546d78":"code","a763ada2":"code","fff1e678":"code","f6d46fb2":"code","b64dc924":"code","b0476f5f":"code","4bf8740c":"code","51c1ef9e":"code","c125ecc9":"code","e57d9a6e":"code","23ff6ed7":"code","50dc2c63":"code","36dc6b6a":"code","2bd8eaf6":"code","bc63cb1a":"code","d0d027cc":"code","4b314b68":"markdown","5fbdd4f8":"markdown","f1f5910a":"markdown","9e07dfcf":"markdown","d19492e8":"markdown","cef5265e":"markdown","81319401":"markdown","b7d38f4c":"markdown","94274cd0":"markdown","8a4d76dd":"markdown","be7b6fcd":"markdown","9c067e37":"markdown","bad91d03":"markdown","fa9866cd":"markdown","3a8dc3c6":"markdown","151f5619":"markdown","996f1a18":"markdown","83180b32":"markdown","0fcd3b1a":"markdown","1912fc07":"markdown","f975caf6":"markdown","99d78572":"markdown","c6134925":"markdown","94d90290":"markdown","bcf93d16":"markdown","d1f1fbe2":"markdown","1bf08cb6":"markdown","948d22f2":"markdown","c7fe971c":"markdown","d3d26f5f":"markdown","5b3fa1a9":"markdown","76195671":"markdown","9b911db6":"markdown","46900bec":"markdown","a93237e7":"markdown","a1389350":"markdown","3c16192f":"markdown","30605417":"markdown","df49b335":"markdown","e6f99cb2":"markdown","52fe985c":"markdown","c571546b":"markdown","47029b53":"markdown","e9cff773":"markdown","2dc5bd9e":"markdown","5164b1f6":"markdown","b76b0d61":"markdown","44fd94fc":"markdown","07fb0d5b":"markdown","5daa5ebb":"markdown","e2744dbc":"markdown","e8b53b0f":"markdown","a4628785":"markdown","a5707fef":"markdown","aab2007c":"markdown","1366929e":"markdown","6990d561":"markdown","e3d931ce":"markdown","43bde6f1":"markdown","2296ef24":"markdown","0ff5bd20":"markdown","725d555d":"markdown","e52a5b88":"markdown","34a4ff67":"markdown","81dd62e9":"markdown","44262663":"markdown","9f798d6c":"markdown","313b6f8b":"markdown","9af02419":"markdown","33d9c7a4":"markdown","1b51943a":"markdown","99b9ac01":"markdown","daa6170c":"markdown","850a62ed":"markdown","b0013cb3":"markdown","a3526491":"markdown","ba014aa3":"markdown","5424ba12":"markdown","9e5de85e":"markdown","37620280":"markdown","f4134d99":"markdown","a73692ca":"markdown","09c5ce51":"markdown","556af088":"markdown","58813c59":"markdown"},"source":{"edd64e6b":"import pandas as pd \nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nimport gc\nfrom datetime import datetime \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom catboost import CatBoostClassifier\nimport lightgbm as lgb\nimport xgboost as xgb\n\npd.set_option('display.max_columns', 100)","f478ad31":"RFC_METRIC = 'gini'  #metric used for RandomForrestClassifier\nNUM_ESTIMATORS = 100 #number of estimators used for RandomForrestClassifier\nNO_JOBS = 4 #number of parallel jobs used for RandomForrestClassifier\n\n#VALIDATION\nVALID_SIZE = 0.20 # simple validation using train_test_split\n\n#CROSS-VALIDATION\nNUMBER_KFOLDS = 5 #number of KFolds for cross-validation\n\nRANDOM_STATE = 2018\n\nMAX_ROUNDS = 1000 #lgb iterations\nEARLY_STOP = 50 #lgb early stop \nOPT_ROUNDS = 1000  #To be adjusted based on best validation rounds\nVERBOSE_EVAL = 50 #Print out metric result\n\nIS_LOCAL = False\n\nimport os\n\nif(IS_LOCAL):\n    PATH=\"..\/input\/default-of-credit-card-clients-dataset\"\nelse:\n    PATH=\"..\/input\"\nprint(os.listdir(PATH))","cdd6f987":"data_df = pd.read_csv(PATH+\"\/UCI_Credit_Card.csv\")","b1924f29":"print(\"Default Credit Card Clients data -  rows:\",data_df.shape[0],\" columns:\", data_df.shape[1])","124c2566":"data_df.head()","d1dca4f2":"data_df.describe()","30e3e41a":"total = data_df.isnull().sum().sort_values(ascending = False)\npercent = (data_df.isnull().sum()\/data_df.isnull().count()*100).sort_values(ascending = False)\npd.concat([total, percent], axis=1, keys=['Total', 'Percent']).transpose()","24079d79":"temp = data_df[\"default.payment.next.month\"].value_counts()\ndf = pd.DataFrame({'default.payment.next.month': temp.index,'values': temp.values})\nplt.figure(figsize = (6,6))\nplt.title('Default Credit Card Clients - target value - data unbalance\\n (Default = 0, Not Default = 1)')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x = 'default.payment.next.month', y=\"values\", data=df)\nlocs, labels = plt.xticks()\nplt.show()","0d52e9ec":"plt.figure(figsize = (14,6))\nplt.title('Amount of credit limit - Density Plot')\nsns.set_color_codes(\"pastel\")\nsns.distplot(data_df['LIMIT_BAL'],kde=True,bins=200, color=\"blue\")\nplt.show()","b9b1a2ff":"data_df['LIMIT_BAL'].value_counts().shape","e996d02f":"data_df['LIMIT_BAL'].value_counts().head(5)","e3a03c08":"class_0 = data_df.loc[data_df['default.payment.next.month'] == 0][\"LIMIT_BAL\"]\nclass_1 = data_df.loc[data_df['default.payment.next.month'] == 1][\"LIMIT_BAL\"]\nplt.figure(figsize = (14,6))\nplt.title('Default amount of credit limit  - grouped by Payment Next Month (Density Plot)')\nsns.set_color_codes(\"pastel\")\nsns.distplot(class_1,kde=True,bins=200, color=\"red\")\nsns.distplot(class_0,kde=True,bins=200, color=\"green\")\nplt.show()","d264b05c":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\ns = sns.boxplot(ax = ax1, x=\"SEX\", y=\"LIMIT_BAL\", hue=\"SEX\",data=data_df, palette=\"PRGn\",showfliers=True)\ns = sns.boxplot(ax = ax2, x=\"SEX\", y=\"LIMIT_BAL\", hue=\"SEX\",data=data_df, palette=\"PRGn\",showfliers=False)\nplt.show();","28a0c69a":"var = ['BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6']\n\nplt.figure(figsize = (8,8))\nplt.title('Amount of bill statement (Apr-Sept) \\ncorrelation plot (Pearson)')\ncorr = data_df[var].corr()\nsns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,vmin=-1, vmax=1)\nplt.show()","37a37b63":"var = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5']\n\nplt.figure(figsize = (8,8))\nplt.title('Amount of previous payment (Apr-Sept) \\ncorrelation plot (Pearson)')\ncorr = data_df[var].corr()\nsns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,vmin=-1, vmax=1)\nplt.show()","ac91f11f":"var = ['PAY_0','PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n\nplt.figure(figsize = (8,8))\nplt.title('Repayment status (Apr-Sept) \\ncorrelation plot (Pearson)')\ncorr = data_df[var].corr()\nsns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,vmin=-1, vmax=1)\nplt.show()","7fd39abc":"def boxplot_variation(feature1, feature2, feature3, width=16):\n    fig, ax1 = plt.subplots(ncols=1, figsize=(width,6))\n    s = sns.boxplot(ax = ax1, x=feature1, y=feature2, hue=feature3,\n                data=data_df, palette=\"PRGn\",showfliers=False)\n    s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    plt.show();","2fdffb06":"boxplot_variation('MARRIAGE','AGE', 'SEX',8)","63e3a8c6":"boxplot_variation('EDUCATION','AGE', 'MARRIAGE',12)","788ab166":"boxplot_variation('AGE','LIMIT_BAL', 'SEX',16)","d186356d":"boxplot_variation('MARRIAGE','LIMIT_BAL', 'EDUCATION',12)","7ceba245":"target = 'default.payment.next.month'\npredictors = [  'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', \n                'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', \n                'BILL_AMT1','BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n                'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']","e78a958f":"train_df, val_df = train_test_split(data_df, test_size=VALID_SIZE, random_state=RANDOM_STATE, shuffle=True )","397b7c53":"train_df_bkp = train_df.copy()\nval_df_bkp = val_df.copy()","ef1fd73f":"clf = RandomForestClassifier(n_jobs=NO_JOBS, \n                             random_state=RANDOM_STATE,\n                             criterion=RFC_METRIC,\n                             n_estimators=NUM_ESTIMATORS,\n                             verbose=False)","e4a029e4":"clf.fit(train_df[predictors], train_df[target].values)","9b6a67be":"preds = clf.predict(val_df[predictors])","8c683880":"tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance',ascending=False)\nplt.figure(figsize = (7,4))\nplt.title('Features importance',fontsize=14)\ns = sns.barplot(x='Feature',y='Feature importance',data=tmp)\ns.set_xticklabels(s.get_xticklabels(),rotation=90)\nplt.show()   \n","5e59cceb":"cm = pd.crosstab(val_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\nfig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\nsns.heatmap(cm, \n            xticklabels=['Not Default', 'Default'],\n            yticklabels=['Not Default', 'Default'],\n            annot=True,ax=ax1,\n            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\nplt.title('Confusion Matrix', fontsize=14)\nplt.show()","108c5324":"roc_auc_score(val_df[target].values, preds)","572fb605":"cat_features = ['EDUCATION', 'SEX', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']","2087092f":"train_f_df = pd.get_dummies(train_df_bkp, columns = cat_features)\nval_f_df = pd.get_dummies(val_df_bkp, columns = cat_features)","5cb6cfae":"print(\"Default of Credit Card Clients train data -  rows:\",train_f_df.shape[0],\" columns:\", train_f_df.shape[1])\nprint(\"Default of Credit Card Clients val  data -  rows:\",val_f_df.shape[0],\" columns:\", val_f_df.shape[1])","fc919887":"train_fa_df, val_fa_df = train_f_df.align(val_f_df, join='outer', axis=1, fill_value=0)","45761369":"print(\"Default of Credit Card Clients train data -  rows:\",train_fa_df.shape[0],\" columns:\", train_fa_df.shape[1])\nprint(\"Default of Credit Card Clients val  data -  rows:\",val_fa_df.shape[0],\" columns:\", val_fa_df.shape[1])","9fb80020":"train_fa_df.head(5)","12b8c9b2":"val_fa_df.head(5)","b090a6af":"target_f = 'default.payment.next.month'\npredictors_f = ['AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4',\n       'BILL_AMT5', 'BILL_AMT6', 'EDUCATION_0', 'EDUCATION_1',\n       'EDUCATION_2', 'EDUCATION_3', 'EDUCATION_4', 'EDUCATION_5',\n       'EDUCATION_6', 'LIMIT_BAL', 'MARRIAGE_0', 'MARRIAGE_1',\n       'MARRIAGE_2', 'MARRIAGE_3', 'PAY_0_-1', 'PAY_0_-2', 'PAY_0_0',\n       'PAY_0_1', 'PAY_0_2', 'PAY_0_3', 'PAY_0_4', 'PAY_0_5', 'PAY_0_6',\n       'PAY_0_7', 'PAY_0_8', 'PAY_2_-1', 'PAY_2_-2', 'PAY_2_0', 'PAY_2_1',\n       'PAY_2_2', 'PAY_2_3', 'PAY_2_4', 'PAY_2_5', 'PAY_2_6', 'PAY_2_7',\n       'PAY_2_8', 'PAY_3_-1', 'PAY_3_-2', 'PAY_3_0', 'PAY_3_1', 'PAY_3_2',\n       'PAY_3_3', 'PAY_3_4', 'PAY_3_5', 'PAY_3_6', 'PAY_3_7', 'PAY_3_8',\n       'PAY_4_-1', 'PAY_4_-2', 'PAY_4_0', 'PAY_4_1', 'PAY_4_2', 'PAY_4_3',\n       'PAY_4_4', 'PAY_4_5', 'PAY_4_6', 'PAY_4_7', 'PAY_4_8', 'PAY_5_-1',\n       'PAY_5_-2', 'PAY_5_0', 'PAY_5_2', 'PAY_5_3', 'PAY_5_4', 'PAY_5_5',\n       'PAY_5_6', 'PAY_5_7', 'PAY_5_8', 'PAY_6_-1', 'PAY_6_-2', 'PAY_6_0',\n       'PAY_6_2', 'PAY_6_3', 'PAY_6_4', 'PAY_6_5', 'PAY_6_6', 'PAY_6_7',\n       'PAY_6_8', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4',\n       'PAY_AMT5', 'PAY_AMT6', 'SEX_1', 'SEX_2']","15f79931":"clf.fit(train_fa_df[predictors_f], train_df[target_f].values)","bef350ae":"preds = clf.predict(val_fa_df[predictors_f])","cdee8f5d":"tmp = pd.DataFrame({'Feature': predictors_f, 'Feature importance': clf.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance',ascending=False)\nplt.figure(figsize = (16,4))\nplt.title('Features importance',fontsize=14)\ns = sns.barplot(x='Feature',y='Feature importance',data=tmp)\ns.set_xticklabels(s.get_xticklabels(),rotation=90)\nplt.show()","7160daee":"cm = pd.crosstab(val_fa_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\nfig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\nsns.heatmap(cm, \n            xticklabels=['Not Default', 'Default'],\n            yticklabels=['Not Default', 'Default'],\n            annot=True,ax=ax1,\n            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\nplt.title('Confusion Matrix', fontsize=14)\nplt.show()","1b19ebfa":"roc_auc_score(val_fa_df[target].values, preds)","3ab91b45":"clf = AdaBoostClassifier(random_state=RANDOM_STATE,\n                         algorithm='SAMME.R',\n                         learning_rate=0.8,\n                             n_estimators=NUM_ESTIMATORS)","5df5d979":"clf.fit(train_df[predictors], train_df[target].values)","1d92d9e9":"preds = clf.predict(val_df[predictors])","eef34c2e":"tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance',ascending=False)\nplt.figure(figsize = (7,4))\nplt.title('Features importance',fontsize=14)\ns = sns.barplot(x='Feature',y='Feature importance',data=tmp)\ns.set_xticklabels(s.get_xticklabels(),rotation=90)\nplt.show()   ","bc47ca54":"cm = pd.crosstab(val_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\nfig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\nsns.heatmap(cm, \n            xticklabels=['Not Default', 'Default'],\n            yticklabels=['Not Default', 'Default'],\n            annot=True,ax=ax1,\n            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\nplt.title('Confusion Matrix', fontsize=14)\nplt.show()","2d546d78":"roc_auc_score(val_df[target].values, preds)","a763ada2":"clf = CatBoostClassifier(iterations=500,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='AUC',\n                             random_seed = RANDOM_STATE,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = VERBOSE_EVAL,\n                             od_wait=100)","fff1e678":"clf.fit(train_df[predictors], train_df[target].values,verbose=True)","f6d46fb2":"preds = clf.predict(val_df[predictors])","b64dc924":"tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance',ascending=False)\nplt.figure(figsize = (7,4))\nplt.title('Features importance',fontsize=14)\ns = sns.barplot(x='Feature',y='Feature importance',data=tmp)\ns.set_xticklabels(s.get_xticklabels(),rotation=90)\nplt.show()   ","b0476f5f":"cm = pd.crosstab(val_df[target].values, preds, rownames=['Actual'], colnames=['Predicted'])\nfig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\nsns.heatmap(cm, \n            xticklabels=['Not Fraud', 'Fraud'],\n            yticklabels=['Not Fraud', 'Fraud'],\n            annot=True,ax=ax1,\n            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\nplt.title('Confusion Matrix', fontsize=14)\nplt.show()","4bf8740c":"roc_auc_score(val_df[target].values, preds)","51c1ef9e":"# Prepare the train and valid datasets\ndtrain = xgb.DMatrix(train_df[predictors], train_df[target].values)\ndvalid = xgb.DMatrix(val_df[predictors], val_df[target].values)\n\n#What to monitor (in this case, **train** and **valid**)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n\n# Set xgboost parameters\nparams = {}\nparams['objective'] = 'binary:logistic'\nparams['eta'] = 0.039\nparams['silent'] = True\nparams['max_depth'] = 2\nparams['subsample'] = 0.8\nparams['colsample_bytree'] = 0.9\nparams['eval_metric'] = 'auc'\nparams['random_state'] = RANDOM_STATE","c125ecc9":"model = xgb.train(params, \n                dtrain, \n                MAX_ROUNDS, \n                watchlist, \n                early_stopping_rounds=EARLY_STOP, \n                maximize=True, \n                verbose_eval=VERBOSE_EVAL)","e57d9a6e":"fig, (ax) = plt.subplots(ncols=1, figsize=(8,5))\nxgb.plot_importance(model, height=0.8, title=\"Features importance (XGBoost)\", ax=ax, color=\"green\") \nplt.show()","23ff6ed7":"params = {\n          'boosting_type': 'gbdt',\n          'objective': 'binary',\n          'metric':'auc',\n          'learning_rate': 0.05,\n          'num_leaves': 7,  # we should let it be smaller than 2^(max_depth)\n          'max_depth': 4,  # -1 means no limit\n          'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n          'max_bin': 100,  # Number of bucketed bin for feature values\n          'subsample': 0.9,  # Subsample ratio of the training instance.\n          'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n          'colsample_bytree': 0.7,  # Subsample ratio of columns when constructing each tree.\n          'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n          'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n          'nthread': 8,\n          'verbose': 0,\n          'scale_pos_weight':50, # because training data is sightly unbalanced \n         }","50dc2c63":"categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE','PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']","36dc6b6a":"dtrain = lgb.Dataset(train_df[predictors].values, \n                     label=train_df[target].values,\n                     feature_name=predictors,\n                     categorical_feature=categorical_features)\n\ndvalid = lgb.Dataset(val_df[predictors].values,\n                     label=val_df[target].values,\n                     feature_name=predictors,\n                     categorical_feature=categorical_features)","2bd8eaf6":"evals_results = {}\n\nmodel = lgb.train(params, \n                  dtrain, \n                  valid_sets=[dtrain, dvalid], \n                  valid_names=['train','valid'], \n                  evals_result=evals_results, \n                  num_boost_round=MAX_ROUNDS,\n                  early_stopping_rounds=EARLY_STOP,\n                  verbose_eval=VERBOSE_EVAL, \n                  feval=None)\n\ndel dvalid\ngc.collect()","bc63cb1a":"fig, (ax) = plt.subplots(ncols=1, figsize=(8,5))\nlgb.plot_importance(model, height=0.8, title=\"Features importance (LightGBM)\", ax=ax,color=\"red\") \nplt.show()","d0d027cc":"kf = KFold(n_splits = NUMBER_KFOLDS, random_state = RANDOM_STATE, shuffle = True)\nfor train_index, test_index in kf.split(data_df):\n    train_X, valid_X = data_df.iloc[train_index], data_df.iloc[test_index]\n\n    dtrain = lgb.Dataset(train_X[predictors].values, label=train_X[target].values,\n                     feature_name=predictors)\n\n    dvalid = lgb.Dataset(valid_X[predictors].values, label=valid_X[target].values,\n                     feature_name=predictors)\n\n    evals_results = {}\n    model =  lgb.train(params, \n                  dtrain, \n                  valid_sets=[dtrain, dvalid], \n                  valid_names=['train','valid'], \n                  evals_result=evals_results, \n                  num_boost_round=MAX_ROUNDS,\n                  early_stopping_rounds=EARLY_STOP,\n                  verbose_eval=VERBOSE_EVAL, \n                  feval=None)","4b314b68":"There is no missing data in the entire dataset.","5fbdd4f8":"# <a id=\"6\">Predictive models<\/a>  \n\n","f1f5910a":"### Define predictors and target values\n\nLet's define the predictor features and the target features. Categorical features, if any, are also defined. In our case, there are no categorical feature.","9e07dfcf":"## Credit limit vs. sex\n\nLet's check the credit limit distribution vs. sex. For the sex, 1 stands for male and 2 for female.","d19492e8":"Indeed, the largest number of credit cards are with limit of 50,000 (3365), followed by 20,000 (1976) and 30,000 (1610).","cef5265e":"<h1><center><font size=\"6\">Default of Credit Card Clients - Predictive Models<\/font><\/center><\/h1>\n\n\n<img src=\"https:\/\/kaggle2.blob.core.windows.net\/datasets-images\/306\/666\/d68d599bfe6995fa5772df1e82c4e83c\/dataset-card.jpg\" width=\"400\"><\/img>\n\n\n# <a id='0'>Content<\/a>\n\n- <a href='#1'>Introduction<\/a>  \n- <a href='#2'>Load packages<\/a>  \n- <a href='#3'>Read the data<\/a>  \n- <a href='#4'>Check the data<\/a>  \n    - <a href='#41'>Glimpse the data<\/a>  \n    - <a href='#42'>Check missing data<\/a>\n    - <a href='#43'>Check data unbalance<\/a>\n- <a href='#5'>Data exploration<\/a>\n- <a href='#6'>Predictive models<\/a>  \n    - <a href='#61'>RandomForrestClassifier<\/a> \n    - <a href='#62'>AdaBoostClassifier<\/a>\n    - <a href='#63'>CatBoostClassifier<\/a> \n    - <a href='#64'>XGBoost<\/a> \n    - <a href='#65'>LightGBM<\/a> \n- <a href='#7'>Conclusions<\/a>\n- <a href='#8'>References<\/a>\n","81319401":"Let's now predict the **target** values for the **val_df** data, using **predict** function.","b7d38f4c":"### Train the model\n\nLet's train the model. ","94274cd0":"## <a id=\"62\">AdaBoostClassifier<\/a>\n\n\nAdaBoostClassifier stands for Adaptive Boosting Classifier <a href='#8'>[5]<\/a>.\n\n### Prepare the model\n\nLet's set the parameters for the model and initialize the model.","8a4d76dd":"Mean, Q3 and Q4 values are increasing for both male and female with age until aroung 35 years and then they are oscilating and get to a maximum of Q4 for males at age 64.\n\nMean values are generally smaller for males than for females, with few exceptions, for example at age 39, 48, until approximately 60, where mean values for males are generally larger than for females.\n\n","be7b6fcd":"### Predict the target values\n\nLet's now predict the **target** values for the **val_df** data, using predict function.","9c067e37":"It looks like Married status 3 (others), with mean values over 40 and Q4 values over 60 means mostly vidowed or divorced whilst Married status 0 could be not specified or divorced, as Q1 values are above values for married of both sexes.\n\nMarried males have mean age above married women. Unmarried males have mean value for age above unmarried women as well but closer. Q3 abd Q4 values for married man are above corresponding values for married women.\n\n\nLet's show the boxplots with age distribution grouped by education and marriage.\n\nEducation status meaning is:\n\n* 1 : graduate school\n* 2 : university\n* 3 : high school\n* 4 : others\n* 5 : unknown\n* 6 : unknow\n","bad91d03":"### Confusion matrix\n\nLet's visualize the confusion matrix.","fa9866cd":"We investigated the data, checking for data unbalancing, visualizing the features and understanding the relationship between different features.   \n\nWe then investigated five predictive models:  \n* We started with **RandomForrestClassifier**, for which we obtained an AUC scode of **0.66**. \n   For the **RandomForrestClassifier** we also experimented with **OneHotEncoder**, replacing the categorical features with dummified values (introducing one dummy variable for each category). The AUC score did not improved significantly in this case.\n* Next we used  an **AdaBoostClassifier** model, with lower AUC score (**0.65**).   \n* We followed with an **CatBoostClassifier** model, with lower AUC score (**0.66**).   \n* Then we experimented with a **XGBoost** model, for which the AUC score obtained was **0.77**.   \n* We then presented the data to a **LightGBM** model. We used both train-validation split and cross-validation to evaluate the model effectiveness to predict the target value, i.e. detecting if a credit card client  will default next month. With both methods for LightGBM the obtained values of AUC for the validation set were around **0.78**.","3a8dc3c6":"We also make copies of the train_df and val_df for later usage.","151f5619":"### Split data in train and validation set\n\nLet's define train and validation sets.","996f1a18":"We also calculate area under curve (receiver operator characteristic)","83180b32":"Let's now predict the **target** values for the **val_df** data, using **predict** function.","0fcd3b1a":"Let's calculate also the ROC-AUC.\n\n\n### Area under curve","1912fc07":"### Confusion matrix\n\nLet's visualize the confusion matrix.","f975caf6":"## Marriage status, education level and credit amount limit\n\n\nLet's show the  boxplots with credit amount limit distribution grouped by marriage status and education level.","99d78572":"The ROC-AUC score obtained with AdaBoostClassifier is 0.65.","c6134925":"Correlation is decreasing with distance between months. Lowest correlations are between Sept-April.\n","94d90290":"Most of defaults are for credit limits 0-100,000 (and density for this interval is larger for defaults than for non-defaults). Larger defaults number are for the amounts of **50,000**, **20,000** and **30,000**.","bcf93d16":"Let's look into more details to the data.","d1f1fbe2":"Let's run a model using the training set for training. Then, we will use the validation set for validation. \n\n### Metric\n\nWe will use as validation criterion **GINI**, which formula is **GINI = 2 * (AUC) - 1**, where **AUC** is the **Receiver Operating Characteristic - Area Under Curve (ROC-AUC)** <a href='#8'>[4]<\/a>.  Number of estimators is set to **100** and number of parallel jobs is set to **4**.\n\nWe start by initializing the RandomForestClassifier.","1bf08cb6":"# <a id=\"3\">Read the data<\/a>","948d22f2":"Let's check again the data.","c7fe971c":"The most important features are **PAY_0**, **AGE**, **BILL_AMT1**, **LIMIT_BAL**, **BILL_AMT2**, **BILL_AMT3**.\n\n\n### Confusion matrix\n\nLet's show a confusion matrix for the results we obtained. ","d3d26f5f":"# <a id=\"2\">Load packages<\/a>\n\n## Load packages","5b3fa1a9":"# <a id=\"5\">Data exploration<\/a>","76195671":"There are no correlations between amounts of previous payments for April-Sept 2005.\n\nLet's check the correlation between Repayment status in April - September 2005.","9b911db6":"Let's also visualize the features importance. \n\n#### Features importance","46900bec":"The **ROC-AUC** score obtained with **RandomForrestClassifier** is **0.66**.\n\n\nLet's use for RandomForrestClassifier **dummified variables** for the **categorical features**.\n\n\nWe start by defining the categorical features.\n\n\n### RandomForrest with OneHotEncoder","a93237e7":"## <a id=\"64\">XGBoost<\/a>","a1389350":"## <a id=\"42\">Check missing data<\/a>  \n\nLet's check if there is any missing data.","3c16192f":"## Amount of credit limit ","30605417":"### Predict the target values\n\nLet's now predict the **target** values for the **val_df** data, using predict function.","df49b335":"The limit credit amount is quite balanced between sexes. The males have a slightly smaller Q2 and larger Q3 and Q4 and a lower mean. The female have a larger outlier max value (1M NT dollars).","e6f99cb2":"### Prepare the model\n\nWe initialize the DMatrix objects for training and validation, starting from the datasets. We also set some of the parameters used for the model tuning.","52fe985c":"### Prepare the model\n","c571546b":"Let's start with a RandomForrestClassifier <a href='#8'>[3]<\/a>   model.","47029b53":"## Amount of credit limit grouped by default payment next month\n\nLet's visualize the density plot for amount of credit limit (LIMIT_BAL), grouped by default payment next month.","e9cff773":"## <a id=\"65\">LightGBM<\/a>\n\n\nLet's continue with another gradient boosting algorithm, LightGBM <a href='#8'>[7]<\/a> <a href='#8'>[8]<\/a>.\n\n\n### Define model parameters\n\nLet's set the parameters for the model.","2dc5bd9e":"## <a id=\"63\">CatBoostClassifier<\/a>\n\n\nCatBoostClassifier is a gradient boosting for decision trees algorithm with support for handling categorical data <a href='#8'>[6]<\/a>.\n\n### Prepare the model\n\nLet's set the parameters for the model and initialize the model.","5164b1f6":"Let's also visualize the features importance.\n\n### Features importance","b76b0d61":"### Plot variable importance","44fd94fc":"Let's calculate also the ROC-AUC.\n\n\n### Area under curve","07fb0d5b":"## <a id=\"43\">Data unbalance<\/a>","5daa5ebb":"# <a id=\"7\">Conclusions<\/a>","e2744dbc":"XGBoost is a gradient boosting algorithm <a href='#8'>[7]<\/a>.\n\nLet's prepare the model.","e8b53b0f":"## <a id=\"61\">RandomForestClassifier<\/a>\n\n\n","a4628785":"Let's check data unbalance with respect with *target* value, i.e. **default.payment.next.month**.","a5707fef":"### Features importance\n\nLet's see also the features importance.","aab2007c":"## Sex, Education, Age and Marriage\n\n\nLet's show sex, education, age and marriage distributions.\n\nWe start by showing the boxplots with age distribution grouped by marriage status and sex.\n\nMarriage status meaning is:\n\n* 0 : unknown (let's consider as others as well)\n* 1 : married\n* 2 : single\n* 3 : others\n\nSex meaning is:\n\n* 1 : male\n* 2 : female\n","1366929e":"Correlation is decreasing with distance between months. Lowest correlations are between Sept-April.\n\n\nLet's check the correlation of Amount of previous payment in April - September 2005.","6990d561":"# <a id=\"4\">Check the data<\/a>","e3d931ce":"#### Confusion matrix\n\nLet's show a confusion matrix for the results we obtained. ","43bde6f1":"We also calculate area under curve (receiver operator characteristic).","2296ef24":"Largest group of amount of credit limit is apparently for amount of 50K. Let's verify this.","0ff5bd20":"The best validation score (ROC-AUC) was **0.78**, for round **453**.","725d555d":"### Training and validation using cross-validation\n\nLet's use now cross-validation. We will use cross-validation (KFolds) with 5 folds. Data is divided in 5 folds and, by rotation, we are training using 4 folds (n-1) and validate using the 5th (nth) fold.","e52a5b88":"Best validation score  was obtained for round **265**, for which **AUC ~= 0.78**.\n\nLet's plot variable importance.","34a4ff67":"### Fit the model\n\nLet's fit the model.","81dd62e9":"## <a id=\"41\">Glimpse the data<\/a>\n\nWe start by looking to the data features (first 5 rows).","44262663":"Let's define the categorical features.","9f798d6c":"### Features importance\n\nLet's see also the features importance.","313b6f8b":"## Features correlation\n\n\nFor the numeric values, let's represent the features correlation.\n\n\nLet's check the correlation of Amount of bill statement in April - September 2005.","9af02419":"# <a id=\"8\">References<\/a>\n\n[1] Default Credit Card Clients Dataset,  https:\/\/www.kaggle.com\/uciml\/default-of-credit-card-clients-dataset\/  \n[2] Principal Component Analysis, Wikipedia Page, https:\/\/en.wikipedia.org\/wiki\/Principal_component_analysis  \n[3] RandomForrestClassifier, http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html  \n[4] ROC-AUC characteristic, https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic#Area_under_the_curve   \n[5] AdaBoostClassifier, http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.AdaBoostClassifier.html   \n[6] CatBoostClassifier, https:\/\/tech.yandex.com\/catboost\/doc\/dg\/concepts\/python-reference_catboostclassifier-docpage\/  \n[7] XGBoost Python API Reference, http:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html  \n[8] LightGBM Python implementation, https:\/\/github.com\/Microsoft\/LightGBM\/tree\/master\/python-package  \n[9] LightGBM algorithm, https:\/\/www.microsoft.com\/en-us\/research\/wp-content\/uploads\/2017\/11\/lightgbm.pdf   \n\n","33d9c7a4":"A number of **6,636** out of **30,000** (or **22%**) of clients will default next month. The data has not a large unbalance with respect of the target value (default.payment.next.month).","1b51943a":"Let's prepare the model, creating the **Dataset**s data structures from the train and validation sets.\n\nWe will also initialize the Datasets with the list of the categorical features (**lgb** has a special treatment for categorical values).","99b9ac01":"The ROC-AUC score obtained with CatBoostClassifier is 0.66.","daa6170c":"The most important features are **AGE**, **LIMIT_BAL**, **BILL_AMT1**, **PAY_0_2**, **BILL_AMT2**, **BILL_AMT3**.","850a62ed":"## Age, sex and credit amount limit\n\n\nLet's show the  boxplots with credit amount limit distribution grouped by age and sex.\n\n","b0013cb3":"There are 30,000 distinct credit card clients.  \n\nThe average value for the amount of credit card limit is 167,484. The standard deviation is unusually large, max value being 1M.\n\nEducation level is mostly graduate school and university.\n\nMost of the clients are either marrined or single (less frequent the other status).\n\nAverage age is 35.5 years, with a standard deviation of 9.2.\n\nAs the value 0 for default payment means 'not default' and value 1 means 'default', the mean of 0.221 means that there are 22.1% of credit card contracts that will default next month (will verify this in the next sections of this analysis).\n","a3526491":"# <a id=\"1\">Introduction<\/a>  \n\n\n## Dataset\n\nThis dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from **April 2005** to **September 2005**. \n\n## Content\n\nThere are 25 variables:\n\n* **ID**: ID of each client\n* **LIMIT_BAL**: Amount of given credit in NT dollars (includes individual and family\/supplementary credit\n* **SEX**: Gender (1=male, 2=female)\n* **EDUCATION**: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n* **MARRIAGE**: Marital status (1=married, 2=single, 3=others)\n* **AGE**: Age in years\n* **PAY_0**: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n* **PAY_2**: Repayment status in August, 2005 (scale same as above)\n* **PAY_3**: Repayment status in July, 2005 (scale same as above)\n* **PAY_4**: Repayment status in June, 2005 (scale same as above)\n* **PAY_5**: Repayment status in May, 2005 (scale same as above)\n* **PAY_6**: Repayment status in April, 2005 (scale same as above)\n* **BILL_AMT1**: Amount of bill statement in September, 2005 (NT dollar)\n* **BILL_AMT2**: Amount of bill statement in August, 2005 (NT dollar)\n* **BILL_AMT3**: Amount of bill statement in July, 2005 (NT dollar)\n* **BILL_AMT4**: Amount of bill statement in June, 2005 (NT dollar)\n* **BILL_AMT5**: Amount of bill statement in May, 2005 (NT dollar)\n* **BILL_AMT6**: Amount of bill statement in April, 2005 (NT dollar)\n* **PAY_AMT1**: Amount of previous payment in September, 2005 (NT dollar)\n* **PAY_AMT2**: Amount of previous payment in August, 2005 (NT dollar)\n* **PAY_AMT3**: Amount of previous payment in July, 2005 (NT dollar)\n* **PAY_AMT4**: Amount of previous payment in June, 2005 (NT dollar)\n* **PAY_AMT5**: Amount of previous payment in May, 2005 (NT dollar)\n* **PAY_AMT6**: Amount of previous payment in April, 2005 (NT dollar)\n* **default.payment.next.month**: Default payment (1=yes, 0=no)\n\n","ba014aa3":"With the dummified features, the improvement of the AUC score is quite small.","5424ba12":"## Set parameters\n\nHere we set few parameters for the analysis and models.","9e5de85e":"Because train and validation data does not have the same number of columns, we will align them.","37620280":"Let's train the **RandonForestClassifier** using the **train_df** data and **fit** function.","f4134d99":"There are 81 distinct values for amount of credit limit.","a73692ca":"### Run the model\n\nLet's run the model, using the **train** function.","09c5ce51":"Let's define the target and predictors lists.","556af088":"The average validation **AUC** for the 5 folds obtained was **0.78**, with values between **0.778** and **0.79**.","58813c59":"Let's train the **RandonForestClassifier** using the **train_fa_df** data and **fit** function."}}