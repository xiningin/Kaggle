{"cell_type":{"82beb065":"code","6fd78345":"code","9b8cba12":"code","c139f45f":"code","a319e345":"code","a499065f":"code","0c0ab0b4":"code","67b40cc2":"code","418287ae":"code","860e5dcb":"code","eb255c91":"code","5ef07019":"code","6cbf44dc":"code","0127eb9a":"code","b67b418b":"code","8e78718d":"code","9525fc6e":"code","f047c1c1":"code","4e028964":"code","784aceb6":"code","325cb737":"code","d359d3ce":"code","8153f58e":"code","0da20a27":"code","244993ad":"code","18132003":"code","e893830b":"markdown","d55dcddf":"markdown","a548d9a2":"markdown","b8f39e72":"markdown","fde1f399":"markdown","e3507150":"markdown","b156d498":"markdown","8aae9071":"markdown","1ca846d2":"markdown","a9743cff":"markdown","e2025002":"markdown","076997ac":"markdown","40f0501c":"markdown","a71b8d36":"markdown","516fb6e4":"markdown","d821e2dc":"markdown","6a48806d":"markdown","e0e526aa":"markdown","6ab298c2":"markdown","1bb75797":"markdown","98fb4dff":"markdown","278ec09e":"markdown","c48505f8":"markdown","58d4372e":"markdown","2417e5cd":"markdown","21dd499b":"markdown","a7a32ba3":"markdown","6723725d":"markdown","bd796c3e":"markdown"},"source":{"82beb065":"import pandas as pd\nimport numpy as np\n\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import month_plot, seasonal_plot, plot_acf, plot_pacf, quarter_plot\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ncolors = ['#126E82', '#0A043C', '#F25287', '#F0A500', '#7D1935']\nplt.style.use('tableau-colorblind10')\nsns.set_style('whitegrid')\nsns.set_palette(colors)","6fd78345":"train_data = pd.read_csv(\"..\/input\/store-sales-time-series-forecasting\/train.csv\", parse_dates =['date'])\ntest_data = pd.read_csv(\"..\/input\/store-sales-time-series-forecasting\/test.csv\", parse_dates =['date'])\nholidays = pd.read_csv(\"..\/input\/store-sales-time-series-forecasting\/holidays_events.csv\", parse_dates =['date'])\noil = pd.read_csv(\"..\/input\/store-sales-time-series-forecasting\/oil.csv\", parse_dates =['date'])\ntransaction = pd.read_csv(\"..\/input\/store-sales-time-series-forecasting\/transactions.csv\", parse_dates =['date'])\nstores = pd.read_csv(\"..\/input\/store-sales-time-series-forecasting\/stores.csv\")","9b8cba12":"# rename the column name of oil dataframe.\noil.rename(columns={'dcoilwtico':'oilPrice'}, inplace=True)\n\n# Let's merge oil data into the train and test data\ntrain = train_data.merge(oil, on='date')\ntest = test_data.merge(oil, on='date') ","c139f45f":"train.head()","a319e345":"test.head()","a499065f":"print(\"train shape :\", train.shape)\nprint(\"test shape :\", test.shape)","0c0ab0b4":"# Let's examine holidays dataframe.\nholidays.head()","67b40cc2":"train = train.merge(holidays[['date', 'type', 'transferred']], on='date')\ntrain = train.merge(stores, on='store_nbr')\ntrain.rename(columns={'type_x':'holiday_type', 'type_y':'store_type'}, inplace=True)","418287ae":"train['Year'] = train.date.dt.year\ntrain['Year-Month'] = train['date'].apply(lambda x : x.strftime('%Y-%m'))\ntrain['Month'] = train.date.dt.month\ntrain['Day'] = train.date.dt.day","860e5dcb":"train.describe()","eb255c91":"# Missing data in train dataset\ntrain.isna().sum()","5ef07019":"# box plots to see distribution of sales in each year.\nplt.figure(figsize=(14, 8))\nsns.boxplot(data=train, x='Year', y='sales')\n\nplt.tight_layout()\nplt.show()","6cbf44dc":"# Let's examine sales in Year 2016\ndata2016 = train.loc[train.Year == 2016, 'sales']\ndata2016.reset_index(drop=True, inplace=True)\n\n# plot\nplt.figure(figsize=(14, 8))\nplt.scatter(data2016.index, data2016.values)\nplt.show()","0127eb9a":"# sales greater than 40000\ntrain.loc[train.sales > 40000].shape # there are 10 entries for sales greater than 40,000.\n\n# Let's remove values greater than 40,000.\ntrain = train.loc[train.sales < 40000]\ntrain.sales.max()","b67b418b":"# Sales observation over time.\nplt.figure(figsize=(14, 8),dpi=100)\nsns.lineplot(data = train, x='date', y='sales', label='Sales')\n\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.title(\"Sales observation over time\")\n\nplt.legend()\nplt.show()","8e78718d":"# Year-to-Year observation of sales.\nyear_data = pd.DataFrame(train.groupby('Year-Month').sum()['sales'])\n\n# plot\nyear_data.plot(kind='line', figsize=(14, 8), marker=\"o\")\n\nplt.xlabel(\"Year-Month\")\nplt.ylabel(\"Sales\")\nplt.title(\"Year-Month observation of Total Sales\")\nplt.plot()","9525fc6e":"# Monthly observation of Sales for each year.\nmonthly_sales = pd.DataFrame(train.groupby(by = ['Year', 'Month']).sum()['sales'])\n\n# let's add 0 for remaining months(9, 10, 11, 12) in 2017.\nre_months = [9, 10, 11, 12]\nfor month in re_months:\n    monthly_sales.loc[(2017, month), :] = 0\n    \nyrs = [2013, 2014, 2015, 2016, 2017]\n\n# Plots\nfig, axs = plt.subplots(nrows = 5, ncols=1, figsize=(14, 12))\nfor i in range(len(yrs)):\n    yr = yrs[i]\n    axs[i] = monthly_sales.loc[yr].plot(ax=axs[i], marker=\"o\", label=yr)\n    axs[i].set_ylabel(str(yr)+'Sales')\n\nfig.suptitle(\"Monthly Trend Pattern Observations\")\nplt.legend()\nplt.tight_layout()\nplt.show()","f047c1c1":"# prepare data\nfilter1 = (train.Day == 15) \nfilter2 = (train.Day.apply(lambda x: x in [31, 30, 29, 28]))\n\nSales = train.loc[(filter1 | filter2), ['date','Year-Month','sales']]\nsales_data = pd.DataFrame(Sales.groupby(by=['Year-Month']).sum())\n\n#plot\nsales_data.plot(kind='bar', figsize=(14, 8), edgecolor=colors[1], color=colors[-2], fill=True, alpha=0.75, linewidth=1.5)\nsns.lineplot(data = sales_data, x = sales_data.index, y = 'sales', color=colors[1])\n\nplt.title('Monthly Wages Observation')\n\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()","4e028964":"# prepare data\nd = train[['date', 'sales']]\nd.set_index('date', inplace=True)\nptable = pd.pivot_table(data=d, index=d.index.year, columns=d.index.quarter)\n\n# plot\nplt.figure(figsize=(14, 8))\nsns.heatmap(ptable, square=True, cmap='Blues', xticklabels=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\nplt.show()","784aceb6":"# Groupby Sales by Quarter\n# Only use upto 2016 because we have partial data for 2017\ndata_2016 = d.loc[:'2016']\navg_2016 = np.int(data_2016.mean())\n\n# Avg sales per quarter\nqrt_avg = data_2016.groupby(data_2016.index.quarter)[\"sales\"].mean()\n\n# Groupby quarter\nqrt_table = pd.pivot_table(data_2016, index=data_2016.index.quarter, columns=data_2016.index.year)\n\n# add qrt_avg to qrt_table\nqrt_table[\"avg\"] = qrt_avg\n\n# Additive Seasonality Factor: Subtract mean from avg column\nqrt_table[\"additive\"] = (qrt_table[\"avg\"] - avg_2016).round(2)\n\n# Multiplicative Seasonality Factor: Divide mean from avg column\nqrt_table[\"multiplicative\"] = (qrt_table[\"avg\"]\/avg_2016).round(2)\n\nqrt_table.index.name=\"Quarters\"\nprint(\"Seasonal Factor Analysis Table\")\nqrt_table","325cb737":"# prepare_data \ndata = pd.DataFrame(train_data.groupby(by=['date']).sum()['sales'])\n\ndef test_stationarity(timeseries, title):\n    \n    # calculating rolling statistics.\n    roll_mean = timeseries['sales'].rolling(window = 91,  center=True).mean()\n    roll_std = timeseries['sales'].rolling(window = 91,  center=True).std()\n\n    # plotting rolling statistics with orignal data.\n    plt.figure(figsize=(12, 4), dpi=100)\n    plt.plot(timeseries.sales, label= title, marker=\".\", alpha=0.6)\n    plt.plot(roll_mean, label=\"Rolling Mean\", color=\"red\", linestyle=\"--\")\n    plt.plot(roll_std, label=\"Rolling Standard Deviation\")\n\n    plt.title(\"Rolling Statistics\")\n    plt.legend()\n    plt.show()\n\ntest_stationarity(data, 'raw data')","d359d3ce":"# coefficient of variance. \ncv = data.sales.std()\/data.sales.mean()\ncv","8153f58e":"# Let's find if covariance is constant or not using acf plot and pacf plot of statsmodels.\nplt.rcParams['figure.figsize'] = (14, 4);\nplot_acf(data.sales);\nplt.tight_layout()\nplot_pacf(data.sales);\nplt.tight_layout()","0da20a27":"# Let's take a adfuller test on sales data.\n\ndef adfuller_test(data, description):\n    \n    print(f\"Augmented Dickey-fuller test result for {description}\")\n    result = adfuller(data.dropna(), autolag=\"AIC\")\n    \n    print(\"ADF test statistic: {:.3f}\".format(result[0]))\n    print(\"p-value:{:.3f}\".format(result[1]))\n    \n    print(\"Critical Values:\")\n    for k, v in result[4].items():\n        print('\\t{}: {} - The data is {} stationary with {}% confidence'.format(k, v, 'not' if v<result[0] else '', 100-int(k[:-1])))\n        \nadfuller_test(data, 'raw data')","244993ad":"# de-trending\ndata_detrend = ((data - data.rolling(91).mean()) \/ data.rolling(91).std()).dropna()\n\n# To check if detrended data is stationary or not?\nadfuller_test(data_detrend, \"de-trended data\")\ntest_stationarity(data_detrend, \"de-trended data\")","18132003":"diff_data = (data - data.shift(15))\ntest_stationarity(diff_data, 'difference data')\nadfuller_test(diff_data, 'difference data')","e893830b":"The ACF Plot shows that, it has momentum process since all AC's are positive. Let's check stationarity of data using Augmented Dickey-fuller test (adfuller test).","d55dcddf":"### Missing Values","a548d9a2":"We can see that, there is increase in sales in April 2016 as expected.","b8f39e72":"Heatmap shows peak at Quarter Q4 for every year. For each of the years the upward trend observed in all quarters.","fde1f399":"We can see that, Every year there is Rise in Sales in Month of December and drop in January. This may be because of Christmas. Let's examine the sales over month and see if the same pattern observe in each year.","e3507150":"Seasonality Analysis table shows that in quarter 4 we can see that there is increament in sales by ~69k as compare to others and there is sudden drop in quarter 1. We can see from the above table is that the sales is not stable, The multiplicative seasonallity would capture the pattern better than additive seasonality.","b156d498":"### Line plot","8aae9071":"### Summary Statistics","1ca846d2":"# Store Sales Time Series Analysis","a9743cff":"This has low variability process.","e2025002":"# Data Analysis","076997ac":"## Seasonality Factor","40f0501c":"## Stationarity\nTime series is Stationary if it has,\n* Constant Mean\n* Constant Variance\n* Constant Covariance\n\nLet's verify it by observing change in mean, variance and statistical test (**adfuller**)","a71b8d36":"### Coefficient of Variance\nC.V = std\/mean\n\n* If C.V<0.75 **-** Low Variability\n* If 0.75<C.V<1.3 **-** Medium Variability\n* If C.V>1.3 **-** High Variability","516fb6e4":"### ADFuller Test.","d821e2dc":"## Importing Libraries","6a48806d":"Above plot show that, Both Mean and Standard deviation is increasing over time. Therefore, this time series is not stationary.","e0e526aa":"There is **increasing** **trend** or **growth** in sales over the time.","6ab298c2":"This method removes the underlying seasonal or cyclical patterns in the time series. I used a 15-lag difference since wages in public sector is paid every 2 weeks.","1bb75797":"# To make Time Series Stationary\n## Detrend","98fb4dff":"Augmented Dickey-fuller test is a statistical test for stationarity. If the p-value is less than 0.05 then the series is not stationary. Here the p-value is ~0.08989 so, the time series is not stationary.","278ec09e":"We can see that, There is peak in December month for each year however, at different levels. <br>\nWages in the public sector are paid every two weeks on the 15th and on the last day of the month. Let's observed the sales at 15th day and last day of month.","c48505f8":"### Sales Distribution","58d4372e":"## Differencing","2417e5cd":"### HeatMap","21dd499b":"We can see that, Outliers present in each year, but specifically in year 2016 there are some extreme outliers present which is becasue of earthquake on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake. So, let's remove this extreme outliers in 2016.","a7a32ba3":"## Loading DataSets","6723725d":"Both the adfuller statistical test and rolling statistics graph shows that the series is now stationary. The relative smoothness of rolling mean and rolling standard deviation graph shows the sationarity in time series.","bd796c3e":"Both stationarity tests shows that, the this time series is stationary. Differencing performs much better as compare to de-trending."}}