{"cell_type":{"a35b4c05":"code","4795954a":"code","67960625":"code","c991dce9":"code","3fa4e9b1":"code","439b7f40":"code","a6186a5e":"code","be7c3fb6":"code","6bdc99f7":"code","aed8cec7":"code","5bd5d565":"code","4ed4cf09":"code","d0556ffd":"code","515d555c":"code","a7620cd8":"code","75f32dfd":"code","ae2f301c":"code","cb8c5237":"code","a6d2cc46":"code","0260481a":"code","9b62179f":"code","31907214":"code","239c23a6":"code","e49da731":"code","81c2c026":"code","c2914a4b":"code","7926179c":"code","732072cd":"code","6481c501":"code","44d9ca34":"code","e1e6ccaa":"code","304a914a":"code","90d33f1c":"code","e181a99f":"code","9a105e0d":"code","2e2f3028":"code","b1889792":"code","0f2e7d8a":"code","af9b27c3":"code","94b32522":"code","97a25c0d":"code","8e0506da":"markdown","caa964c3":"markdown","646c7ce0":"markdown","ad12c86c":"markdown","14dd2930":"markdown","727ad86b":"markdown","283b01da":"markdown","6dc74690":"markdown","70aece40":"markdown","f357917f":"markdown","4ae6f98f":"markdown","6a0484f9":"markdown","dd3fb406":"markdown","e74ea2f4":"markdown","f70efcba":"markdown","99919561":"markdown","cc2cf3b6":"markdown","863a2a37":"markdown","0285b31c":"markdown"},"source":{"a35b4c05":"# import libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n%matplotlib inline\nimport seaborn as sns\nimport itertools\nimport warnings\nwarnings.filterwarnings('ignore')\nimport io\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff","4795954a":"# load data set\ndf = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\ndf.head()","67960625":"# rename the columns\ndf.columns = ['age','sex','chest_pain_type','resting_blood_pressure',\n              'cholestrol','fasting_blood_sugar','rest_ecg','max_heart_rate',\n              'exercise_induced_angina','st_slope','slope','major_vassel','thalassemia','target']","c991dce9":"print('No of Rows      :', df.shape[0])\nprint('No of Attributes:', df.shape[1])\nprint('\\nAttributes Name:\\n', df.columns)","3fa4e9b1":"df['sex'] = df['sex'].replace({1:'male',0:'female'})\n\ndf['chest_pain_type'] = df['chest_pain_type'].replace({0:'typical angina',1:'atypical angina',\n                                                      2:'non-angianl',3:'asymptomatic'})\n\ndf['fasting_blood_sugar'] = df['fasting_blood_sugar'].replace({1:'greater than 120 mg\/dl',\n                                                             0:'less than 120 mg\/dl'})\n\ndf['rest_ecg'] = df['rest_ecg'].replace({0:'normal',1:'ST T wave',2:'show probable'})\n\ndf['exercise_induced_angina'] = df['exercise_induced_angina'].replace({0:'exercise not induced angina',\n                                                                      1: 'exercise induced angina'})\n\ndf['slope'] = df['slope'].replace({0:'upslopping',1:'flat',2:'down slopping'})\n\ndf['thalassemia'] = df['thalassemia'].replace({0:'unknow',1:'normal',\n                                              2:'fixed defect', 3 : 'reversable defect'})\n\ndf['target'] = df['target'].replace({0:'no',1:'yes'})","439b7f40":"# target column\ntarget_col = ['target']\n\n# categorical columns\ncat_cols = ['sex','chest_pain_type','fasting_blood_sugar','rest_ecg','exercise_induced_angina','slope',\n          'major_vassel','thalassemia']\n\n# numerical columns\nnum_cols = [x for x in df.columns if x not in target_col + cat_cols]\n\n# sepration of data\ndis = df[df['target'] == 'yes']\nnot_dis = df[df['target'] == 'no']","a6186a5e":"# label\nlab = df['target'].value_counts().keys().tolist()\n\n# val\nval = df['target'].value_counts().values.tolist()\n\ntrace = go.Pie(labels = lab,\n              values = val,\n              marker = dict(colors = ['royalblue', 'lime'],\n                           line = dict(color = 'white',\n                                      width = 1.3)\n                           ),\n              rotation = 90,\n              hoverinfo = 'label+value+text',\n              hole = .5\n              )\n\nlayout = go.Layout(dict(title = 'Patients Disease in Data',\n                          plot_bgcolor = 'rgb(243,243,243)',\n                          paper_bgcolor = 'rgb(243,243,243)'\n                          )\n                  )\n\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","be7c3fb6":"# function for pie plot for customer attrition type\ndef plot_pie(column):\n    trace1 = go.Pie(values = dis[column].value_counts().values.tolist(),\n                   labels = dis[column].value_counts().keys().tolist(),\n                   marker = dict(line = dict(width = 2,\n                                            color = 'rgb(243,243,243)',\n                                            )\n                                ),\n                   hoverinfo = 'label+percent+name',\n                   domain = dict(x = [0, .48]),\n                   name = 'Disease',\n                   hole = .5\n                   )\n    \n    trace2 = go.Pie(values = not_dis[column].value_counts().values.tolist(),\n                   labels = not_dis[column].value_counts().keys().tolist(),\n                   marker = dict(line = dict(width = 2,\n                                            color = 'rgb(243,243,243)',\n                                            )\n                                ),\n                   hoverinfo = 'label+percent+name',\n                   domain = dict(x = [.52, 1]),\n                   name = 'Not Disease',\n                   hole = .5\n                   )\n    \n    layout = go.Layout(dict(title = column + 'Distribution in Disease',\n                           plot_bgcolor = 'rgb(243,243,243)',\n                           paper_bgcolor = 'rgb(243,243,243)',\n                           annotations = [dict(text = 'Disease',\n                                              font = dict(size = 13),\n                                              showarrow = False,\n                                              x = .20, y = .5),\n                                         dict(text = 'Not Disease',\n                                             font = dict(size = 13),\n                                             showarrow = False,\n                                             x = .82, y = .5\n                                             )\n                                         ]\n                           )\n                      )\n    \n    data = [trace1, trace2]\n    fig = go.Figure(data = data, layout = layout)\n    py.iplot(fig)","6bdc99f7":"# for all categorical columns plot pie\nfor i in cat_cols:\n    plot_pie(i)","aed8cec7":"# function for histogram for customer subscription\ndef histogram(column):\n    trace1 = go.Histogram(x = dis[column],\n                         histnorm = 'percent',\n                         name = 'Customer Subscribe',\n                         marker = dict(line = dict(width = .5,\n                                                  color = 'black'\n                                                  )\n                                      ),\n                         opacity = .9\n                         )\n    trace2 = go.Histogram(x = not_dis[column],\n                         histnorm = 'percent',\n                         name = 'Customer Not Subscribe',\n                         marker = dict(line = dict(width = .5,\n                                                  color = 'black'\n                                                  )\n                                      ),\n                         opacity = .9\n                         )\n    layout = go.Layout(dict(title = column + 'Distribution in Customer Subscription',\n                           plot_bgcolor = 'rgb(243,243,243)',\n                           paper_bgcolor = 'rgb(243,243,243)',\n                           xaxis = dict(gridcolor = 'rgb(255,255,255)',\n                                       title = column,\n                                       zerolinewidth = 1,\n                                       ticklen = 5,\n                                       gridwidth = 2\n                                       ),\n                           yaxis = dict(gridcolor = 'rgb(255,255,255)',\n                                       title = 'percent',\n                                       zerolinewidth = 1,\n                                       ticklen = 5,\n                                       gridwidth = 2\n                                       )\n                           )\n                      )\n    data = [trace1, trace2]\n    fig = go.Figure(data = data, layout = layout)\n    py.iplot(fig)","5bd5d565":"# for all numerical columns plot histogram\nfor i in num_cols:\n    histogram(i)","4ed4cf09":"num_cols","d0556ffd":"# function for scatter plot matrix for numerical columns in data\ndef scatter_matrix(data):\n    data = data.sort_values(by = 'target', ascending = True)\n    classes = data['target'].unique().tolist()\n    classes\n    \n    classes_code = {classes[k]: k for k in range(2)}\n    classes_code\n    \n    color_vals = [classes_code[cl] for cl in data['target']]\n    color_vals\n    \n    pl_colorscale = 'Portland'\n    \n    pl_colorscale\n    \n    text = [data.loc[k, 'target'] for k in range(len(data))]\n    text\n    \n    trace = go.Splom(dimensions = [dict(label='age',\n                                       values = data['age']),\n                                  dict(label='resting_blood_pressure',\n                                      values = data['resting_blood_pressure']),\n                                  dict(label='cholestrol',\n                                      values= data['cholestrol']),\n                                  dict(label='max_heart_rate',\n                                      values = data['max_heart_rate']),\n                                  dict(label='st_slope',\n                                      values = data['st_slope'])],\n                    text = text,\n                    marker = dict(color = color_vals,\n                                 colorscale = pl_colorscale,\n                                 showscale = False\n                                 )\n                    )\n    layout = go.Layout(dict(title =\n                           'Scatter plot for Numerical Variables',\n                           autosize=False,\n                           height = 900,\n                           width = 900,\n                           )\n                      )\n    data = [trace]\n    fig = go.Figure(data=data,layout=layout)\n    py.iplot(fig)","515d555c":"scatter_matrix(df)","a7620cd8":"# target columns\ntarget_col = ['target']\n\n# categorical variables\ncat_cols = ['sex','chest_pain_type','fasting_blood_sugar','rest_ecg','exercise_induced_angina','slope',\n          'major_vassel','thalassemia']\n\n# numerical vaiables\nnum_cols = [x for x in df.columns if x not in target_col + cat_cols]\n\n# binary column with 2 values\nbin_cols = df.nunique()[df.nunique() == 2].keys().tolist()\n\n# column more than 2 values\nmulti_cols = [x for x in cat_cols if x not in bin_cols]","75f32dfd":"# label encoding binary column\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor i in bin_cols:\n    df[i] = le.fit_transform(df[i])","ae2f301c":"# duplicating columns for multi value column\ndf = pd.get_dummies(data = df, columns = multi_cols)","cb8c5237":"# scalling numerical columns\nfrom sklearn.preprocessing import StandardScaler\nstd = StandardScaler()\nscaled = std.fit_transform(df[num_cols])\nscaled = pd.DataFrame(scaled, columns = num_cols)","a6d2cc46":"# dropping original values, merging scaled values for numerical columns\ndf_og = df.copy()\ndf = df.drop(columns = num_cols, axis = 1)\ndf = df.merge(scaled, left_index=True, right_index=True, how = 'left')","0260481a":"summary = (df.describe().transpose().reset_index())\n\nsummary = summary.rename(columns = {'index':'feature'})\nsummary = np.round(summary, 3)\n\nval_list = [summary['feature'], summary['count'],\n           summary['mean'], summary['std'],\n           summary['min'], summary['25%'],\n           summary['50%'], summary['75%'], summary['max']]\n\ntrace = go.Table(header = dict(values = summary.columns.tolist(),\n                              line = dict(color = ['#506784']),\n                              fill = dict(color = ['#119DFF']),\n                              ),\n                cells = dict(values = val_list,\n                            line = dict(color = ['#506784']),\n                            fill = dict(color = ['lightgrey', '#F5F8FF'])\n                            ),\n                columnwidth = [300, 60,100,100,60,60,80,80,80])\n\nlayout = go.Layout(dict(title = 'Variable Summary'))\n\nfig = go.Figure(data = [trace], layout = layout)\npy.iplot(fig)","9b62179f":"# correlation\ncorrelation = df.corr()\n\n# tick labels\nmatrix_cols = correlation.columns.tolist()\n\n# convert to array\ncorr_array = np.array(correlation)\n\n# plotting\ntrace = go.Heatmap(z = corr_array,\n                  x = matrix_cols,\n                  y = matrix_cols,\n                  colorscale = 'Viridis',\n                  colorbar = dict(title = 'Person Correlation Cofficient',\n                                 titleside = 'right'\n                                 )\n                  )\n\nlayout = go.Layout(dict(title = 'Correlation Matrix for Attributes',\n                       autosize = False,\n                       height = 900,\n                       width = 950,\n                       margin = dict(r = 0, l = 210,\n                                    t = 25, b = 210,\n                                    ),\n                       yaxis = dict(tickfont = dict(size = 9)),\n                       xaxis = dict(tickfont = dict(size = 9))\n                       )\n                  )\ndata = [trace]\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)","31907214":"# import required libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score, roc_curve, scorer\nfrom sklearn.metrics import f1_score\nimport statsmodels.api as sm\nfrom sklearn.metrics import precision_score, recall_score\nfrom yellowbrick.classifier import DiscriminationThreshold","239c23a6":"# splitting train & test data\ntrain, test = train_test_split(df, test_size = .25, random_state = 111)\n\n# seprating dependent & independent variable\ncols = [i for i in df.columns if i not in target_col]\ntrain_X = train[cols]\ntrain_Y = train[target_col]\ntest_X = test[cols]\ntest_Y = test[target_col]\n\ndef patient_disease_prediction(algorithm, training_x, testing_x,\n                               training_y, testing_y, cols, cf, threshold_plot):\n    # model\n    algorithm.fit(training_x, training_y)\n    predictions = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    \n    # coeff\n    if cf == 'coefficients':\n        coefficients = pd.DataFrame(algorithm.coef_.ravel())\n    elif cf == 'features':\n        coefficients = pd.DataFrame(algorithm.feature_importances_)\n        \n    column_df = pd.DataFrame(cols)\n    coef_sumry = (pd.merge(coefficients, column_df, left_index = True,\n                          right_index = True, how = 'left'))\n    coef_sumry.columns = ['coefficients','features']\n    coef_sumry = coef_sumry.sort_values(by = 'coefficients', ascending = False)\n    \n    print(algorithm)\n    print('\\nClassification Report:\\n', classification_report(testing_y, predictions))\n    print('\\nAccuracy Score:', accuracy_score(testing_y, predictions))\n    \n    # confusion matrix\n    conf_matrix = confusion_matrix(testing_y, predictions)\n    \n    # roc auc score\n    model_roc_auc = roc_auc_score(testing_y, predictions)\n    \n    print('Area Under Curve:', model_roc_auc,'\\n')\n    fpr, tpr, threshold = roc_curve(testing_y, predictions)\n    \n    # plot confusion matrix\n    trace1 = go.Heatmap(z = conf_matrix,\n                       x = ['Not Disease', 'Disease'],\n                       y = ['Not Disease', 'Disease'],\n                       showscale = False, colorscale = 'Picnic',\n                       name = 'Matrix')\n    \n    # plot roc curve\n    trace2 = go.Scatter(x = fpr, y = tpr,\n                       name = 'ROC :' + str(model_roc_auc),\n                       line = dict(color = ('rgb(22,96,167)'), width = 2))\n    trace3 = go.Scatter(x = [0,1], y = [0,1],\n                       line = dict(color = 'rgb(205,12,24)', width = 2, dash = 'dot'))\n    # plot coeff\n    trace4 = go.Bar(x = coef_sumry['features'], y = coef_sumry['coefficients'],\n                   name = 'coefficients',\n                   marker = dict(color = coef_sumry['coefficients'],\n                                colorscale = 'Picnic',\n                                line = dict(width = .6, color = 'black')))\n    \n    # subplots\n    fig = tls.make_subplots(rows = 2, cols = 2, specs = [[{},{}], [{'colspan':2},None]],\n                           subplot_titles = ('Confusion Matrix',\n                                            'Receiver Operating Characterstic',\n                                            'Feature Importance'))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,1,2)\n    fig.append_trace(trace4,2,1)\n    \n    fig['layout'].update(showlegend=False, title = 'Model Performance',\n                        autosize = False, height = 900, width = 800,\n                        plot_bgcolor = 'rgba(240,240,240,0.95)',\n                        paper_bgcolor = 'rgba(240,240,240,0.95)',\n                        margin = dict(b = 195))\n    fig['layout']['xaxis2'].update(dict(title = 'False Positive Rate'))\n    fig['layout']['yaxis2'].update(dict(title = 'True Positive Rate'))\n    fig['layout']['xaxis3'].update(dict(showgrid=True, tickfont = dict(size = 10),\n                                       tickangle=90))\n    py.iplot(fig)\n    \n    if threshold_plot == True:\n        visulizer = DiscriminationThreshold(algorithm)\n        visulizer.fit(training_x, training_y)\n        visulizer.poof()","e49da731":"logit = LogisticRegression()","81c2c026":"patient_disease_prediction(logit, train_X, test_X, train_Y, test_Y,\n                                cols, 'coefficients', threshold_plot=True)","c2914a4b":"from imblearn.over_sampling import SMOTE\n\ncols = [i for i in df.columns if i not in target_col]\n\nsmote_X = df[cols]\nsmote_Y = df[target_col]\n\n# split train & test data\nsmote_train_X, smote_test_X, smote_train_Y, smote_test_Y = train_test_split(smote_X, smote_Y,\n                                                                           test_size = .25, random_state = 111)\n\n# oversampling minority class using smote\nos = SMOTE(random_state = 0)\nos_smote_X, os_smote_Y = os.fit_sample(smote_train_X, smote_train_Y)\nos_smote_X = pd.DataFrame(data = os_smote_X, columns = cols)\nos_smote_Y = pd.DataFrame(data = os_smote_Y, columns = target_col)","7926179c":"logit_smote = LogisticRegression()","732072cd":"patient_disease_prediction(logit_smote, os_smote_X, test_X, os_smote_Y, test_Y,\n                           cols, 'coefficients', threshold_plot=True)","6481c501":"from sklearn.feature_selection import RFE\n\nlogit = LogisticRegression()\n\nrfe = RFE(logit, 10)\nrfe = rfe.fit(os_smote_X, os_smote_Y.values.ravel())\n\nrfe.support_\nrfe.ranking_\n\n# identified columns recrusive feature elimation\nidc_rfe = pd.DataFrame({'rfe_support':rfe.support_,\n                       'columns':[i for i in df.columns if i not in target_col],\n                       'ranking':rfe.ranking_,\n                       })\n\ncols = idc_rfe[idc_rfe['rfe_support'] == True]['columns'].tolist()\n\n# seprating train & test data\ntrain_rf_X = os_smote_X[cols]\ntrain_rf_Y = os_smote_Y\ntest_rf_X = test[cols]\ntest_rf_Y = test[target_col]\n\nlogit_rfe = LogisticRegression()","44d9ca34":"patient_disease_prediction(logit_rfe, train_rf_X, test_rf_X, train_rf_Y, test_rf_Y,\n                           cols, 'coefficients', threshold_plot=True)\ntab_rk = ff.create_table(idc_rfe)\npy.iplot(tab_rk)","e1e6ccaa":"from sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\n\n#select columns\ncols = [i for i in df.columns if i not in target_col]\n\n#dataframe with non negative values\ndf_x = df_og[cols]\ndf_y = df_og[target_col]\n\n#fit model with k= 3\nselect = SelectKBest(score_func = chi2,k = 3)\nfit = select.fit(df_x,df_y)\n\n#Summerize scores\nprint (\"scores\")\nprint (fit.scores_)\nprint (\"P - Values\")\nprint (fit.pvalues_)\n\n#create dataframe\nscore = pd.DataFrame({\"features\":cols,\"scores\":fit.scores_,\"p_values\":fit.pvalues_ })\nscore = score.sort_values(by = \"scores\" ,ascending =False)\n\n\n#createing new label for categorical and numerical columns\nscore[\"feature_type\"] = np.where(score[\"features\"].isin(num_cols),\"Numerical\",\"Categorical\")\n\n#plot\ntrace  = go.Scatter(x = score[score[\"feature_type\"] == \"Categorical\"][\"features\"],\n                    y = score[score[\"feature_type\"] == \"Categorical\"][\"scores\"],\n                    name = \"Categorial\",mode = \"lines+markers\",\n                    marker = dict(color = \"red\",\n                                  line = dict(width =1))\n                   )\n\ntrace1 = go.Bar(x = score[score[\"feature_type\"] == \"Numerical\"][\"features\"],\n                y = score[score[\"feature_type\"] == \"Numerical\"][\"scores\"],name = \"Numerical\",\n                marker = dict(color = \"royalblue\",\n                              line = dict(width =1)),\n                xaxis = \"x2\",yaxis = \"y2\"\n               )\nlayout = go.Layout(dict(title = \"Scores for Categorical & Numerical features\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     tickfont = dict(size =10),\n                                     domain=[0, 0.7],\n                                     tickangle = 90,zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"scores\",\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(b=200),\n                        xaxis2=dict(domain=[0.8, 1],tickangle = 90,\n                                    gridcolor = 'rgb(255, 255, 255)'),\n                        yaxis2=dict(anchor='x2',gridcolor = 'rgb(255, 255, 255)')\n                        )\n                  )\n\ndata=[trace,trace1]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","304a914a":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn import tree\nfrom graphviz import Source\nfrom IPython.display import SVG, display\n\n# top 3 categorical features\nfeatures_cat = score[score['feature_type'] == 'Categorical']['features'][:3].tolist()\n\n# top 3 numerical features\nfeatures_num = score[score['feature_type'] == 'Numerical']['features'][:3].tolist()\n\n# function attributes\n# columns = selected columns\n# maximum_depth = depth of tree\n# criterion_type = ['gini' or 'entropy']\n# split_type = ['best' or 'random']\n# model performance = True (gives model output)\n\ndef plot_decision_tree(columns, maximum_depth, criterion_type, split_type, model_performance = None):\n    \n    # sepreting dependent & independent variable\n    dtc_x = df_x[columns]\n    dtc_y = df_y[target_col]\n    \n    # model \n    dt_classifier = DecisionTreeClassifier(max_depth = maximum_depth,\n                                          splitter = split_type,\n                                          criterion = criterion_type,\n                                          )\n    dt_classifier.fit(dtc_x, dtc_y)\n    \n    # plot decision tree\n    graph = Source(tree.export_graphviz(dt_classifier, out_file=None,\n                                       rounded=True, proportion=False,\n                                       feature_names = columns,\n                                       precision=2,\n                                       class_names = ['Not churn', 'Churn'],\n                                       filled = True\n                                       )\n                  )\n    \n    # model performance\n    if model_performance == True:\n        patient_disease_prediction(dt_classifier,\n                                   dtc_x, test_X[columns],\n                                   dtc_y, test_Y,\n                                   columns, 'features', threshold_plot=True)\n        \n    display(graph)\n    \nplot_decision_tree(features_num,3,'gini','best')","90d33f1c":"plot_decision_tree(features_cat, 3, 'entropy', 'best', model_performance = True)","e181a99f":"def patient_disease_prediction_alg(algorithm, training_x, testing_x,\n                                   training_y, testing_y, threshold_plot = True):\n    \n    # model\n    algorithm.fit(training_x, training_y)\n    predictions = algorithm.predict(testing_x)\n    probabilities = algorithm.predict_proba(testing_x)\n    \n    print(algorithm)\n    print('\\n Classification Report:\\n', classification_report(testing_y, predictions))\n    print('Accuracy Scor:', accuracy_score(testing_y, predictions))\n    # confusion matrix\n    conf_matrix = confusion_matrix(testing_y, predictions)\n    # roc_auc_score\n    model_roc_auc = roc_auc_score(testing_y, predictions)\n    print('Area under curve:', model_roc_auc)\n    fpr, tpr, thresholds = roc_curve(testing_y, probabilities[:,1])\n    \n    # plot roc curve\n    trace1 = go.Scatter(x = fpr, y = tpr,\n                       name = 'Roc :' + str(model_roc_auc),\n                       line = dict(color = ('rgb(22,96,167)'), width = 2),\n                       )\n    trace2 = go.Scatter(x = [0,1], y = [0,1],\n                       line = dict(color = ('rgb(205, 12, 24)'), width = 2,\n                                  dash = 'dot'))\n    \n    # plot confusion matrix\n    trace3 = go.Heatmap(z = conf_matrix, x = ['Not Disease', 'Disease'],\n                       y = ['Not Disease', 'Disease'],\n                       showscale = False, colorscale ='Blues', name= 'matrix',\n                       xaxis = 'x2', yaxis = 'y2'\n                       )\n    \n    layout = go.Layout(dict(title = 'Model Performance',\n                           autosize = False, height = 500, width = 800,\n                           showlegend = False,\n                           plot_bgcolor = 'rgb(243,243,243)',\n                           paper_bgcolor = 'rgb(243,243,243)',\n                           xaxis = dict(title = 'False Positive Rate',\n                                       gridcolor = 'rgb(255,255,255)',\n                                       domain = [0, 0.6],\n                                       ticklen = 5, gridwidth = 2),\n                           yaxis = dict(title = 'True Positive Rate',\n                                       gridcolor = 'rgb(255,255,255)',\n                                       zerolinewidth = 1,\n                                       ticklen = 5, gridwidth = 2),\n                           margin = dict(b = 200),\n                           xaxis2 = dict(domain = [0.7, 1], tickangle = 90,\n                                        gridcolor = 'rgb(255,255,255)'),\n                           yaxis2 = dict(anchor = 'x2', gridcolor = 'rgb(255,255,255)')\n                           )\n                      )\n    \n    data = [trace1, trace2, trace3]\n    fig = go.Figure(data = data, layout = layout)\n    py.iplot(fig)\n    \n    if threshold_plot == True:\n        visualizer = DiscriminationThreshold(algorithm)\n        visualizer.fit(training_x, training_y)\n        visualizer.poof()\n        \n        \nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(algorithm = 'auto', leaf_size = 30, metric = 'minkowski',\n                          metric_params=None, n_jobs = 1, n_neighbors = 5, p = 2,\n                          weights = 'uniform')\npatient_disease_prediction_alg(knn, os_smote_X, test_X,\n                               os_smote_Y, test_Y, threshold_plot = True)","9a105e0d":"from sklearn.ensemble import RandomForestClassifier\n\n# function attributes\n# columns - column used\n# nf_estimators = The number of trees in the forest\n# estimated_tree = The number to be displayed\n# maximum_depth = depth of tree\n# criterion_type = split criterion type ['gini' or 'entropy']\n# model performance = prints performance of model\n\ndef plot_tree_randomforest(columns, nf_estimators,\n                          estimated_tree, maximum_depth,\n                          criterion_type, model_performance = None):\n    dataframe = df_og[columns + target_col].copy()\n    \n    # train and test dataset\n    rf_x = dataframe[[i for i in columns if i not in target_col]]\n    rf_y = dataframe[target_col]\n    \n    # random forest classifier\n    rfc = RandomForestClassifier(n_estimators = nf_estimators,\n                                max_depth = maximum_depth,\n                                criterion = criterion_type,\n                                )\n    rfc.fit(rf_x, rf_y)\n    \n    estimated_tree = rfc.estimators_[estimated_tree]\n    \n    graph = Source(tree.export_graphviz(estimated_tree, out_file = None,\n                                       rounded = True, proportion = False,\n                                       feature_names = columns,\n                                       precision =2,\n                                       class_names = ['Not churn', 'Churn'],\n                                       filled = True))\n    \n    display(graph)\n    \n    # model performance\n    if model_performance == True:\n        patient_disease_prediction(rfc, rf_x, test_X[columns],\n                                   rf_y, test_Y,\n                                   columns, 'features', threshold_plot = True)\n        \ncols1 = [i for i in train_X.columns if i not in target_col]\nplot_tree_randomforest(cols1, 100, 99, 3, 'entropy', True)","2e2f3028":"# making 10 trees with random forest \nn = np.arange(0,10).tolist()\ncols1 = [i for i in train_X.columns if i not in target_col]\nfor i in n:\n    plot_tree_randomforest(cols1, 10, i, 3, 'entropy',False)","b1889792":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB(priors = None)\n\npatient_disease_prediction_alg(gnb, os_smote_X, test_X, os_smote_Y, test_Y)","0f2e7d8a":"from lightgbm import LGBMClassifier\n\nlgbm_c = LGBMClassifier(boosting_type = 'gbdt', class_weight=None, colsample_bytree =1.0,\n                       learning_rate=0.5, max_depth=7, min_child_samples=20,\n                       min_child_weight=0.001, min_split_gain = 0.0, n_estimators =100,\n                       n_jobs = -1, num_leaves=500, objective='binary', random_state=None,\n                       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n                       subsample_for_bin=200000, subsample_freq= 0)\n\ncols = [i for i in df.columns if i not in target_col]\npatient_disease_prediction(lgbm_c, os_smote_X, test_X, os_smote_Y, test_Y,\n                           cols, 'features', threshold_plot=True)","af9b27c3":"from xgboost import XGBClassifier\n\nxgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n                    max_depth = 7, min_child_weight=1, missing=None, n_estimators=100,\n                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n                    silent=True, subsample=1)\n\n\npatient_disease_prediction(xgc,os_smote_X,test_X,os_smote_Y,test_Y,\n                           cols,\"features\",threshold_plot = True)","94b32522":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import cohen_kappa_score\n\n#gives model report in dataframe\ndef model_report(model,training_x,testing_x,training_y,testing_y,name) :\n    model.fit(training_x,training_y)\n    predictions  = model.predict(testing_x)\n    accuracy     = accuracy_score(testing_y,predictions)\n    recallscore  = recall_score(testing_y,predictions)\n    precision    = precision_score(testing_y,predictions)\n    roc_auc      = roc_auc_score(testing_y,predictions)\n    f1score      = f1_score(testing_y,predictions) \n    kappa_metric = cohen_kappa_score(testing_y,predictions)\n    \n    df = pd.DataFrame({\"Model\"           : [name],\n                       \"Accuracy_score\"  : [accuracy],\n                       \"Recall_score\"    : [recallscore],\n                       \"Precision\"       : [precision],\n                       \"f1_score\"        : [f1score],\n                       \"Area_under_curve\": [roc_auc],\n                       \"Kappa_metric\"    : [kappa_metric],\n                      })\n    return df\n\n#outputs for every model\nmodel1 = model_report(logit,train_X,test_X,train_Y,test_Y,\n                      \"Logistic Reg(Baseline_model)\")\nmodel2 = model_report(logit_smote,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"Logistic Reg(SMOTE)\")\nmodel3 = model_report(logit_rfe,train_rf_X,test_rf_X,train_rf_Y,test_rf_Y,\n                      \"Logistic Reg(RFE)\")\ndecision_tree = DecisionTreeClassifier(max_depth = 9,\n                                       random_state = 123,\n                                       splitter  = \"best\",\n                                       criterion = \"gini\",\n                                      )\nmodel4 = model_report(decision_tree,train_X,test_X,train_Y,test_Y,\n                      \"Decision Tree\")\nmodel5 = model_report(knn,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"KNN Classifier\")\nrfc = RandomForestClassifier(n_estimators = 1000,\n                             random_state = 123,\n                             max_depth = 9,\n                             criterion = \"gini\")\nmodel6 = model_report(rfc,train_X,test_X,train_Y,test_Y,\n                      \"Random Forest Classifier\")\nmodel7 = model_report(gnb,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"Naive Bayes\")\nmodel8 = model_report(lgbm_c,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"LGBM Classifier\")\nmodel9 = model_report(xgc,os_smote_X,test_X,os_smote_Y,test_Y,\n                      \"XGBoost Classifier\")\n\n#concat all models\nmodel_performances = pd.concat([model1,model2,model3,\n                                model4,model5,model6,\n                                model7,model8,model9],axis = 0).reset_index()\n\nmodel_performances = model_performances.drop(columns = \"index\",axis =1)\n\ntable  = ff.create_table(np.round(model_performances,4))\n\npy.iplot(table)","97a25c0d":"model_performances\ndef output_tracer(metric,color) :\n    tracer = go.Bar(y = model_performances[\"Model\"] ,\n                    x = model_performances[metric],\n                    orientation = \"h\",name = metric ,\n                    marker = dict(line = dict(width =.7),\n                                  color = color)\n                   )\n    return tracer\n\nlayout = go.Layout(dict(title = \"Model performances\",\n                        plot_bgcolor  = \"rgb(243,243,243)\",\n                        paper_bgcolor = \"rgb(243,243,243)\",\n                        xaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     title = \"metric\",\n                                     zerolinewidth=1,\n                                     ticklen=5,gridwidth=2),\n                        yaxis = dict(gridcolor = 'rgb(255, 255, 255)',\n                                     zerolinewidth=1,ticklen=5,gridwidth=2),\n                        margin = dict(l = 250),\n                        height = 780\n                       )\n                  )\ntrace1  = output_tracer(\"Accuracy_score\",\"#6699FF\")\ntrace2  = output_tracer('Recall_score',\"red\")\ntrace3  = output_tracer('Precision',\"#33CC99\")\ntrace4  = output_tracer('f1_score',\"lightgrey\")\ntrace5  = output_tracer('Kappa_metric',\"#FFCC99\")\n\ndata = [trace1,trace2,trace3,trace4,trace5]\nfig = go.Figure(data=data,layout=layout)\npy.iplot(fig)","8e0506da":"Gaussian Naive Bayes","caa964c3":"Variable Distribution in Data","646c7ce0":"Model Performance Matrix","ad12c86c":"Visualize Decision Tree with Random Forest Classifer","14dd2930":"Data Preprocessing","727ad86b":"Decision Tree Visualization","283b01da":"KNN Classifer","6dc74690":"LightGBM Classifier","70aece40":"XGBoost Classifer","f357917f":"Data Overview**","4ae6f98f":"Random Forest Classifer","6a0484f9":"Correlation Matrix","dd3fb406":"Receiver Feature Elimination","e74ea2f4":"Compare Model Performance","f70efcba":"Variable Summary","99919561":"Logistic Regression ","cc2cf3b6":"Patient's Disease in Data","863a2a37":"Univariate Selection","0285b31c":"Model Building"}}