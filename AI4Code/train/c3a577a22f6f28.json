{"cell_type":{"ef698499":"code","28411e52":"code","d428d945":"code","3fd033ad":"code","e3e8ffaf":"code","3d850a24":"code","f97ae0f5":"code","c9f2bd2c":"code","bff2e866":"code","d0a36ec3":"code","3d4252ef":"code","0c34c95c":"code","1e39c0c9":"code","39be10a9":"code","d9aafe46":"code","9c302df6":"code","2fdba859":"code","c6b13aec":"code","b6f60d0d":"code","e12003da":"code","dc54bbda":"code","6686bf44":"code","51ff87ca":"code","585eacf1":"code","87297da4":"code","f62ef645":"code","52e64562":"code","c92c8ba0":"code","f5567851":"code","cc0e2bfe":"code","55d9ddbb":"code","7330a142":"code","77021ee7":"code","88c420bf":"code","6608e635":"code","ac3fa8df":"code","06573758":"code","526f0220":"markdown"},"source":{"ef698499":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport scipy.stats as stats\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nimport joblib\nimport cufflinks\nfrom plotly.offline import iplot\nimport plotly.figure_factory as ff","28411e52":"df = pd.read_csv('bodyfat.csv')\ndf","d428d945":"df.describe().loc[['min', 'max']]","3fd033ad":"df.shape","e3e8ffaf":"df.describe()","3d850a24":"numerical_feature = [feature for feature in df.columns if df[feature].dtypes != 'O']\ndiscrete_feature= [feature for feature in numerical_feature if len(df[feature].unique())<25]\ncontinuous_feature = [feature for feature in numerical_feature if feature not in discrete_feature]\ncategorical_feature = [feature for feature in df.columns if feature not in numerical_feature]\nprint(\"Numerical Features Count {}\".format(len(numerical_feature)))\nprint(\"Discrete feature Count {}\".format(len(discrete_feature)))\nprint(\"Continuous feature Count {}\".format(len(continuous_feature)))\nprint(\"Categorical feature Count {}\".format(len(categorical_feature)))","f97ae0f5":"df.isnull().sum()*100\/len(df)","c9f2bd2c":"print(numerical_feature)\n","bff2e866":"plt.hist(df['BodyFat'], bins=100)\nplt.ylabel('Count')\nplt.xlabel('BodyFat')\nplt.title('Distribution of BodyFat variable');","d0a36ec3":"df.loc[df['BodyFat'] < 4, 'BodyFat']","3d4252ef":"df = df.drop(df[df['BodyFat'] < 1].index)\ndf.describe()","0c34c95c":"plt.hist(df['Height'], bins=100)\nplt.ylabel('Count')\nplt.xlabel('Height')\nplt.title('Distribution of Height variable');","1e39c0c9":"df = df.drop(df[df['Height'] < 30].index)","39be10a9":"df = df.drop(df[df['Weight'] > 350].index)","d9aafe46":"df.sort_values(by=['Height']).tail(30)","9c302df6":"axes = pd.plotting.scatter_matrix(df, figsize=(41, 40), s=75, diagonal='kde')\nfor ax in axes.flatten():\n    ax.set_ylabel(ax.get_ylabel(), fontsize=25, rotation=45)\n    ax.set_xlabel(ax.get_xlabel(), fontsize=25)","2fdba859":"corr = df.corr(method = \"spearman\")\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(corr,annot=True)","c6b13aec":"for feature in numerical_feature:\n    data=df.copy()\n    sns.distplot(df[feature])\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.figure(figsize=(15,15))\n    plt.show()","b6f60d0d":"for feature in continuous_feature:\n    data=df.copy()\n    sns.boxplot(data[feature])\n    plt.title(feature)\n    plt.figure(figsize=(10,10))","e12003da":"sns.set_theme(style=\"whitegrid\")\n\n# Load the example planets dataset\n#planets = sns.load_dataset(df)\n\ncmap = sns.cubehelix_palette(rot=-.2, as_cmap=True)\ng = sns.relplot(\n    data=df,\n    x=\"BodyFat\", y=\"Age\",\n    hue=\"Age\", size=\"BodyFat\",\n    palette=cmap, sizes=(10, 200),\n)\ng.set(xscale=\"log\", yscale=\"log\")\ng.ax.xaxis.grid(True, \"minor\", linewidth=.25)\ng.ax.yaxis.grid(True, \"minor\", linewidth=.25)\ng.despine(left=True, bottom=True)","dc54bbda":"for feature in continuous_feature:\n    print(feature)","6686bf44":"def qq_plots(df, variable):\n    plt.figure(figsize=(15,6))\n    plt.subplot(1, 2, 1)\n    df[variable].hist()\n    plt.subplot(1, 2, 2)\n    stats.probplot(df[variable], dist=\"norm\", plot=plt)\n    plt.show()","51ff87ca":"for feature in continuous_feature:\n    print(feature)\n    plt.figure(figsize=(15,6))\n    plt.subplot(1, 2, 1)\n    df[feature].hist()\n    plt.subplot(1, 2, 2)\n    stats.probplot(df[feature], dist=\"norm\", plot=plt)\n    plt.show()","585eacf1":"mwr = df[(df.Weight >= 145) & (df.Weight <= 165)]","87297da4":"import plotly.express as px\nfig = px.scatter_3d(mwr, x='BodyFat', y='Height', z='Age',\n                    color='Weight')\nfig.show()","f62ef645":"figure = ff.create_scatterplotmatrix(\n    mwr[['Height', 'Weight', 'BodyFat', 'Age']],\n    height=1000,\n    width=1000,\n    title='Relationship between Height, BodyFat, Age and Weight in the 145-165lb weight range',\n    colormap='Blues',\n    text=mwr['Height'],\n    diag='histogram',\n    index='Weight')\niplot(figure)","52e64562":"df = df.drop(columns='Density')","c92c8ba0":"df_features = df.drop(columns=\"BodyFat\")","f5567851":"df_features_new = pd.concat(\n    [\n        df_features.drop(columns=['Abdomen', 'Age']).div(df_features['Abdomen'], axis=0),\n        df_features[['Age', 'Abdomen']]\n        ], axis=1)\n\n        # Feature engineering to get a better linear relationship between y_pred and y_test \n        # for more accurate predictions by dividing measurements by the abdominal area which is where most men store body fat","cc0e2bfe":"X = df_features_new\nY = df[\"BodyFat\"]","55d9ddbb":"import catboost\nimport time\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\nbegin = time.time()\n\nX_train, X_val, y_train, y_val = train_test_split(X, Y)\n\nparameters = {\n    \"depth\": [6, 7, 8, 9, 10],\n    \"learning_rate\": [0.07, 0.08, 0.09, 0.10, 0.11, 0.12, 0.18, 0.19, 0.2, 0.21, 0.22],\n    \"iterations\": [500, 1000], \n}\n\ndef train_catboost(hyperparameters, X_train, X_val, y_train, y_val):\n    keys = hyperparameters.keys() #keys of each hyperparam\n    best_index = {key:0 for key in keys} \n    best_cat = None\n    best_score = 10e8\n    \n    \n    for (index, key) in enumerate(keys):\n        print(\"Find best %s\" %(key))\n        items = hyperparameters[key]\n        best_parameter = None\n        temp_best = 10e8\n        \n        \n        for (key_index, item) in enumerate(items):\n            iterations = hyperparameters[\"iterations\"][best_index[\"iterations\"]] if key != \"iterations\" else item\n            learning_rate = hyperparameters[\"learning_rate\"][best_index[\"learning_rate\"]] if key != \"learning_rate\" else item\n            depth = hyperparameters[\"depth\"][best_index[\"depth\"]] if key != \"depth\" else item\n            print(\"Train with iterations: %d learning_rate: %.2f depth:%d\"%(iterations, learning_rate, depth))\n            \n            cat = catboost.CatBoostRegressor(\n                iterations = iterations, \n                learning_rate = learning_rate,\n                depth = depth\n            )\n           \n           \n            if best_cat == None:\n                best_cat = cat\n            cat.fit(X_train, y_train, verbose=False)\n            y_pred = cat.predict(X_val)\n            score = mean_absolute_error(np.square(y_val), np.square(y_pred))\n            print(\"MAE: %.2f\"%(score))\n            \n            \n            if score < temp_best:\n                temp_best = score\n                best_index[key] = key_index\n                best_parameter = item\n            \n            \n            if score < best_score:\n                best_score = score\n                best_cat = cat\n        print(\"Best %s: \"%(key), best_parameter)\n    \n    \n    best_parameters = {\n        \"iterations\": hyperparameters[\"iterations\"][best_index[\"iterations\"]],\n        \"learning_rate\": hyperparameters[\"learning_rate\"][best_index[\"learning_rate\"]],\n        \"depth\": hyperparameters[\"depth\"][best_index[\"depth\"]]\n    }\n\n    return best_cat, best_score, best_parameters\n\n\n\nbest_cat, best_score, best_parameters = train_catboost(parameters, X_train, X_val, y_train, y_val)\n\n\n\nprint(\"Best CatBoost Model: \", best_cat)\nprint(\"Best MAE: \", best_score)\nelapsed = time.time() - begin \nprint(\"Elapsed time: \", elapsed)","7330a142":"cat = catboost.CatBoostRegressor(\n                iterations = 600, \n                learning_rate = .18001,\n                depth = 7\n            )\n\ncat.fit(X_train, y_train, verbose=False)\ny_pred = cat.predict(X_val)\nscore = mean_absolute_error(np.square(y_val), np.square(y_pred))\nprint(\"MAE: %.2f\"%(score))","77021ee7":"sns.distplot(y_val-y_pred)","88c420bf":"plt.scatter(y_val,y_pred)","6608e635":"plt.scatter(y_pred, y_val)\nplt.plot([0, 50], [0, 50], ls='--')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Comparison of the real vs predicted values of body fat level');","ac3fa8df":"final_model = catboost.CatBoostRegressor(\n                iterations = 600, \n                learning_rate = .18001,\n                depth = 7\n            )\n\nfinal_model.fit(X,Y, verbose=False)","06573758":"\njoblib.dump(final_model, \"cat.pkl\")","526f0220":"## Data Collection and Analysis"}}