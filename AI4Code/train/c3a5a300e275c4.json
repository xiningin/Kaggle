{"cell_type":{"089a185c":"code","557bac6e":"code","24bce7c6":"code","691b19b4":"code","34fee95b":"code","61390470":"code","2e5433c8":"code","15e2c76a":"code","928db268":"code","fbd76868":"code","8d147514":"code","8efa4204":"code","c32d6034":"code","b6ef0fd9":"code","6a3f244a":"code","52e63d9a":"code","5a3792dd":"code","612a1bb4":"code","75046946":"code","bee3a5b3":"code","e99b6e1d":"code","4f863cd9":"code","660bda37":"code","77a697f9":"code","2fe9e295":"code","4f1647ba":"code","c9520fbe":"code","bb439a2f":"code","af55a90a":"code","7fc61f90":"code","3fce0417":"code","e1e61ec4":"code","d2c25d49":"code","f356d53f":"code","6ced93e8":"code","177f52f3":"code","6c213ed4":"code","7e22d0e4":"code","aa230e07":"code","dda17657":"code","6e045288":"code","4a90a357":"code","f163ec3e":"code","d82bd8aa":"code","34df231c":"code","29f17c12":"code","dd26e215":"code","2e3f9783":"code","26c63126":"markdown","556907f1":"markdown","1e7f7e4d":"markdown","ba4f4b12":"markdown","480aadec":"markdown","bea2d289":"markdown","51b535c0":"markdown","7970b93f":"markdown","c4b1cd1d":"markdown"},"source":{"089a185c":"# Import our libraries\nimport pandas as pd\nimport numpy as np\n\n# Import sklearn libraries\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve, auc, make_scorer, confusion_matrix, f1_score, fbeta_score\n\n# Import the Naive Bayes, logistic regression, Bagging, RandomForest, AdaBoost, GradientBoost, Decision Trees and SVM Classifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom xgboost import XGBClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#from matplotlib import style\n#plt.style.use('bmh')\n#plt.style.use('ggplot')\nplt.style.use('seaborn-notebook')\nfrom matplotlib.ticker import StrMethodFormatter\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer\n\nfrom sklearn.metrics import classification_report, confusion_matrix","557bac6e":"# load the datasets\ntrain = pd.read_csv(\"train.csv\")\ntest = pd.read_csv(\"test.csv\")\n\nprint(\"Train size: {0}\\nTest size: {1}\".format(train.shape,test.shape))","24bce7c6":"train.head()","691b19b4":"test.isna().sum()\ntest.fillna(value=np.mean(test['Fare']), inplace=True)","34fee95b":"child_age = 18\ndef get_person(passenger):\n    age, sex = passenger\n    if (age < child_age):\n        return 'child'\n    elif (sex == 'female'):\n        return 'female_adult'\n    else:\n        return 'male_adult'\ntrain = pd.concat([train, pd.DataFrame(train[['Age', 'Sex']].apply(get_person, axis=1), columns=['person'])],axis=1)\ntrain = pd.concat([train, pd.get_dummies(train['person'])], axis=1)","61390470":"test = pd.concat([test, pd.DataFrame(test[['Age', 'Sex']].apply(get_person, axis=1), columns=['person'])],axis=1)\ntest = pd.concat([test, pd.get_dummies(test['person'])], axis=1)","2e5433c8":"train['surname'] = train[\"Name\"].apply(lambda x: x.split(',')[0].lower())\ntest['surname'] = test[\"Name\"].apply(lambda x: x.split(',')[0].lower())","15e2c76a":"train.head()","928db268":"test.head()","fbd76868":"### FEATURES BASED ON SURNAME    --------------------------------------------------------\ntable_surname = pd.DataFrame(train[\"surname\"].value_counts())\ntable_surname.rename(columns={'surname':'Surname_Members'}, inplace=True)\n\ntable_surname['Surname_perishing_women'] = train.surname[(train.female_adult == 1.0) \n                                    & (train.Survived == 0.0) \n                                    & ((train.Parch > 0) | (train.SibSp > 0))].value_counts()\ntable_surname['Surname_perishing_women'] = table_surname['Surname_perishing_women'].fillna(0)\ntable_surname['Surname_perishing_women'][table_surname['Surname_perishing_women'] > 0] = 1.0 \n\ntable_surname['Surname_surviving_men'] = train.surname[(train.male_adult == 1.0) \n                                    & (train.Survived == 1.0) \n                                    & ((train.Parch > 0) | (train.SibSp > 0))].value_counts()\ntable_surname['Surname_surviving_men'] = table_surname['Surname_surviving_men'].fillna(0)\ntable_surname['Surname_surviving_men'][table_surname['Surname_surviving_men'] > 0] = 1.0 \n\n####O PULO DO GATO FOI AQUI\ntable_surname['Surname_Id'] = pd.CategoricalIndex(table_surname.index).codes\ntable_surname[\"Surname_Id\"][table_surname[\"Surname_Members\"] < 3 ] = -1\ntable_surname[\"Surname_Members\"] = pd.cut(table_surname[\"Surname_Members\"], bins=[0,1,4,20], labels=[0,1,2])\ntrain = pd.merge(train, table_surname, left_on=\"surname\",right_index=True,how='left', sort=False)","8d147514":"### FEATURES BASED ON SURNAME    --------------------------------------------------------\ntable_surname = pd.DataFrame(test[\"surname\"].value_counts())\ntable_surname.rename(columns={'surname':'Surname_Members'}, inplace=True)\n\ntable_surname['Surname_perishing_women'] = test.surname[(test.female_adult == 1.0) \n                                    & ((test.Parch > 0) | (test.SibSp > 0))].value_counts()\ntable_surname['Surname_perishing_women'] = table_surname['Surname_perishing_women'].fillna(0)\ntable_surname['Surname_perishing_women'][table_surname['Surname_perishing_women'] > 0] = 1.0 \n\ntable_surname['Surname_surviving_men'] = test.surname[(test.male_adult == 1.0) \n                                    & ((test.Parch > 0) | (test.SibSp > 0))].value_counts()\ntable_surname['Surname_surviving_men'] = table_surname['Surname_surviving_men'].fillna(0)\ntable_surname['Surname_surviving_men'][table_surname['Surname_surviving_men'] > 0] = 1.0 \n\n####O PULO DO GATO FOI AQUI\ntable_surname['Surname_Id'] = pd.CategoricalIndex(table_surname.index).codes\ntable_surname[\"Surname_Id\"][table_surname[\"Surname_Members\"] < 3 ] = -1\ntable_surname[\"Surname_Members\"] = pd.cut(table_surname[\"Surname_Members\"], bins=[0,1,4,20], labels=[0,1,2])\ntest = pd.merge(test, table_surname, left_on=\"surname\",right_index=True,how='left', sort=False)","8efa4204":"labels = train['Survived']\nlabels","c32d6034":"train.head()","b6ef0fd9":"train.columns","6a3f244a":"train.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'surname'], axis=1, inplace=True)\ntest.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'surname'], axis=1, inplace=True)","52e63d9a":"data = [train, test]\nfor dataset in data:\n    mean = train[\"Age\"].mean()\n    std = test[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    # compute random numbers between the mean, std and is_null\n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    # fill NaN values in Age column with random values generated\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = train[\"Age\"].astype(int)","5a3792dd":"data","612a1bb4":"embarked_mode = train['Embarked'].mode()\ndata = [train, test]\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].fillna(embarked_mode)","75046946":"data = [train, test]\nfor dataset in data:\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'travelled_alone'] = 'No'\n    dataset.loc[dataset['relatives'] == 0, 'travelled_alone'] = 'Yes'","bee3a5b3":"train_numerical_features = list(train.select_dtypes(include=['int64', 'float64', 'int32']).columns)\nss_scaler = StandardScaler()\ntrain_df_ss = pd.DataFrame(data = train)\ntrain_df_ss[train_numerical_features] = ss_scaler.fit_transform(train_df_ss[train_numerical_features])","e99b6e1d":"test_numerical_features = list(test.select_dtypes(include=['int64', 'float64', 'int32']).columns)\ntest_df_ss = pd.DataFrame(data = test)\ntest_df_ss[test_numerical_features] = ss_scaler.fit_transform(test_df_ss[test_numerical_features])\ntest_df_ss.head()","4f863cd9":"encode_col_list = list(train.select_dtypes(include=['object']).columns)\nfor i in encode_col_list:\n    train_df_ss = pd.concat([train_df_ss,pd.get_dummies(train_df_ss[i], prefix=i, drop_first=True)],axis=1)\n    train_df_ss.drop(i, axis = 1, inplace=True)","660bda37":"train_df_ss.head()","77a697f9":"encode_col_list = list(test.select_dtypes(include=['object']).columns)\n\nfor i in encode_col_list:\n    test_df_ss = pd.concat([test_df_ss,pd.get_dummies(test_df_ss[i], prefix=i, drop_first=True)],axis=1)\n    test_df_ss.drop(i, axis = 1, inplace=True)","2fe9e295":"test_df_ss.head()","4f1647ba":"train_df_ss.columns","c9520fbe":"train_df_ss.drop(['female_adult', 'male_adult', 'Sex_male','Surname_perishing_women',\n       'Surname_surviving_men'], axis=1, inplace=True)\ntest_df_ss.drop(['female_adult', 'male_adult', 'Sex_male', 'Surname_perishing_women',\n       'Surname_surviving_men'], axis=1, inplace=True)","bb439a2f":"X_train, X_test, y_train, y_test = train_test_split(train_df_ss,\n                                                    labels,\n                                                    test_size=0.25,\n                                                    stratify=labels,\n                                                    random_state=12)","af55a90a":"X_train.head()","7fc61f90":"test_df_ss","3fce0417":"# Using Logistic Regression with [child, female, male_adult]\n\n# Instantiate our model\nlogreg = LogisticRegression() #===>0,78468\n# Fit our model to the training data\nlogreg.fit(X_train, y_train)\n# Predict on the test data\nlogreg_predictions = logreg.predict(X_test)\nprint(classification_report(y_test, logreg_predictions))\n#logreg_data = pd.read_csv('test.csv')\n#logreg_data.insert((logreg_data.shape[1]),'Survived',logreg_predictions)\n#logreg_data.to_csv('LogisticRegression_SS_OH_FE2.csv')","e1e61ec4":"lr_pred = logreg.predict(test_df_ss)\nlr_data = pd.read_csv('test.csv')\nlr_data.insert((lr_data.shape[1]),'Survived',lr_pred)","d2c25d49":"lr_data.head()","f356d53f":"lr_data.columns","6ced93e8":"lr_data.set_index('PassengerId')\nlr_submit = lr_data[lr_data.columns.drop(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n       'Ticket', 'Fare', 'Cabin', 'Embarked'])]\nlr_submit.set_index('PassengerId', inplace=True)","177f52f3":"lr_submit","6c213ed4":"lr_submit.to_csv('test_lr.csv', sep=',')","7e22d0e4":"X_train.head()","aa230e07":"test_df_ss.head()","dda17657":"X_train['Surname_Members'] = pd.to_numeric(X_train['Surname_Members'])\nX_test['Surname_Members'] = pd.to_numeric(X_test['Surname_Members'])\ntest_df_ss['Surname_Members'] = pd.to_numeric(test_df_ss['Surname_Members'])","6e045288":"X_train.dtypes","4a90a357":"# Instantiate our model => 0,73684\nxg = XGBClassifier(learning_rate=0.02, n_estimators=750,\n                   max_depth= 3, min_child_weight= 1, \n                   colsample_bytree= 0.6, gamma= 0.0, \n                   reg_alpha= 0.001, subsample= 0.8\n                  )\nxg.fit(X_train, y_train)\n\nxg_predictions = xg.predict(X_test)\nprint(classification_report(y_test, xg_predictions))","f163ec3e":"xg_pred = xg.predict(test_df_ss)\nxg_data = pd.read_csv('test.csv')\nxg_data.insert((xg_data.shape[1]),'Survived',xg_pred)\nxg_data","d82bd8aa":"xg_submit = xg_data[xg_data.columns.drop(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n       'Ticket', 'Fare', 'Cabin', 'Embarked'])]\nxg_submit.set_index('PassengerId',inplace=True)\nxg_submit.to_csv('test_xgb.csv', sep=',')","34df231c":"rfc = RandomForestClassifier(n_estimators=3000, min_samples_split=4, class_weight={0:0.745,1:0.255})\nrfc.fit(X_train, y_train)\nrfc_predictions = rfc.predict(X_test)\n\nprint(classification_report(y_test, rfc_predictions))","29f17c12":"rfc_predictions = rfc.predict(test_df_ss)","dd26e215":"rfc_data = pd.read_csv('test.csv')\nrfc_data.insert((rfc_data.shape[1]),'Survived',rfc_predictions)\nrfc_data.set_index('PassengerId')\nrfc_submit = rfc_data[rfc_data.columns.drop(['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n       'Ticket', 'Fare', 'Cabin', 'Embarked'])]\nrfc_submit.set_index('PassengerId')\nrfc_submit.to_csv('test_rfc.csv', index=False, sep=',')","2e3f9783":"train_df_ss.head()","26c63126":"### 2. XGBoost (Score = 0.77033)","556907f1":"### 3. First look at the dataset","1e7f7e4d":"### 2. Get data, including EDA","ba4f4b12":"## So, now we are going to do the pre-processinf test:","480aadec":"# 1. Getting Started with Kaggle","bea2d289":"![alt text](https:\/\/gestoindigesto.files.wordpress.com\/2011\/09\/fred-mercury-queen-meme-so-close.png)","51b535c0":"### 1. Logistic Regression (Score = 0,79425)","7970b93f":"### 1.1 Load Libraries","c4b1cd1d":"### 3. Random Forest Classifier (Score = 0.76555)"}}