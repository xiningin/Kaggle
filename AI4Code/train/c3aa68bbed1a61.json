{"cell_type":{"a2201504":"code","e89461b7":"code","708de336":"code","aeb9e2b7":"code","1f5d7c66":"code","216328d2":"code","15366f30":"code","9e72f188":"code","3f76ee61":"code","fd5803a9":"code","183d9625":"code","e87a7011":"code","7d91adcb":"code","df2d525f":"code","ae1fdeac":"code","2ce3eca9":"code","9b43d688":"code","789fb233":"code","98a45fcc":"code","26a40618":"code","a3040941":"markdown","11d82b03":"markdown","5ed13ac5":"markdown","b99a6969":"markdown","256b785f":"markdown","29173e04":"markdown","b1cdb760":"markdown"},"source":{"a2201504":"# Linear algebra\nimport numpy as np \n# Data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas as pd\n\n# Keras \nfrom keras.utils.np_utils import to_categorical # For convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense,MaxPooling2D,Flatten,Dropout,MaxPool2D\nfrom keras.layers.convolutional import Conv2D\nfrom keras import backend\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD\nfrom keras.optimizers import RMSprop\nfrom keras.losses import categorical_crossentropy\nfrom keras.callbacks import ReduceLROnPlateau\n\n# Seaborn\nfrom seaborn import countplot","e89461b7":"# Globals constants\ninput_neurons=784  # 28 * 28 = 784\noutput_neurons=10","708de336":"# Fix random seed for reproducibility\nnp.random.seed(2)","aeb9e2b7":"# Load the dataset\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","1f5d7c66":"# Apply a reshape and load to the x and y\nxtrain_df=train_df.drop(['label'], axis=1)\nytrain_df=train_df.label\n# Load data for test, just the variables without the prediction\nxtest_df = test_df","216328d2":"# Free some space\ndel train_df\ndel test_df","15366f30":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nxtrain_df = xtrain_df.values.reshape(-1, 28, 28, 1)\nxtest_df=xtest_df.values.reshape(-1, 28, 28, 1)","9e72f188":"ytrain_df.value_counts()","3f76ee61":"# Chart with the quantity of fields\n_=countplot(ytrain_df)","fd5803a9":"# Generate categorical labels\nytrain_df = to_categorical(ytrain_df, output_neurons)","183d9625":"# Function for normalize the data\ndef normalize(df):\n    df.astype(np.float32)\n    df=df\/255.0\n    return df\n    \nxtrain_df=normalize(xtrain_df)\nxtest_df=normalize(xtest_df)","e87a7011":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(output_neurons, activation = \"softmax\"))","7d91adcb":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='acc',patience=3,verbose=1,factor=0.5, min_lr=0.00001)","df2d525f":"# Define the optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n# optimizer = SGD(lr=0.01) # 0.9822, model 1\n# optimizer='adam' # 0.994, model 2","ae1fdeac":"model.compile(\n    loss=categorical_crossentropy,\n    optimizer=optimizer,\n    metrics=['accuracy']\n)","2ce3eca9":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # Set input mean to 0 over the dataset\n        samplewise_center=False,  # Set each sample mean to 0\n        featurewise_std_normalization=False,  # Divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # Divide each input by its std\n        zca_whitening=False,  # Apply ZCA whitening\n        rotation_range=13,  # Randomly rotate images in the range (degrees, 0 to 180) # 10\n        zoom_range = 0.13, # Randomly zoom image # 0.1\n        width_shift_range=0.1,  # Randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # Randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # Randomly flip images\n        vertical_flip=False)  # Randomly flip images\n\ndatagen.fit(xtrain_df)","9b43d688":"model.fit_generator(\n    datagen.flow(xtrain_df, ytrain_df, batch_size=86),\n    steps_per_epoch=len(xtrain_df) \/\/ 86,\n    epochs=50,\n    callbacks=[learning_rate_reduction]\n)","789fb233":"# model.fit(xtrain_df, ytrain_df, epochs=30, batch_size=86,verbose=1)","98a45fcc":"scores = model.evaluate(xtrain_df, ytrain_df)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","26a40618":"predictions = model.predict(xtest_df,verbose=0)\nresults=np.argmax(predictions,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"digit_recognizer_datagen.csv\",index=False)\n# For clear the tensorflow session\nbackend.clear_session()","a3040941":"## Compile the model","11d82b03":"## Fit the model","5ed13ac5":"## Evaluate the model","b99a6969":"## Data Augmentation","256b785f":"# Digit Recognizer with Keras","29173e04":"## Normalization","b1cdb760":"## Create the model"}}