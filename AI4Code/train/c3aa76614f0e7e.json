{"cell_type":{"2ad1683a":"code","ee366027":"code","d589dc00":"code","b21fe85f":"code","2a0cbf7c":"code","314e240c":"code","8c336092":"code","0f1814b1":"code","0b48e92c":"code","fad5f4cb":"code","db8c7b6b":"code","61c8fc14":"code","222ddf9c":"code","455059da":"code","513fa46f":"code","b71b91bf":"code","8929ed95":"code","b4967696":"code","89d745b9":"code","c78fbdd5":"code","7c9729dc":"code","b2bcc82d":"code","c17bacb3":"code","9243208b":"code","e2385bb4":"code","bf65fdd1":"code","68e6e5c9":"code","01747c00":"code","c4edd880":"code","528968ad":"code","1115a52a":"code","55c205e5":"code","812848a3":"code","c06ad672":"code","d26625a6":"code","033f1c85":"code","aedb1403":"code","84909f7c":"code","09fc150d":"code","6fccbeb1":"code","68ff5c82":"code","f272d633":"code","1cf677e0":"code","b32e4296":"code","cab44ed8":"markdown","50288418":"markdown","9331eeb9":"markdown","652b7e06":"markdown","2d5d32be":"markdown","d37e7267":"markdown","cb67b333":"markdown","5455abf1":"markdown","637c8af2":"markdown","2300266f":"markdown","ffc8d6b7":"markdown","8a8af460":"markdown","a3bbbf5f":"markdown","0016ce9a":"markdown","0fac461f":"markdown","201dc4c4":"markdown","9a28a5ee":"markdown","d13cc46b":"markdown","5b110c5b":"markdown","c515cef3":"markdown","b1273c86":"markdown","b2f043d6":"markdown","a6838d57":"markdown","c38d7217":"markdown","c2b8cdda":"markdown","ba1acd66":"markdown","3fdb7612":"markdown","fbf2fb2c":"markdown","a06cb895":"markdown","23d36960":"markdown","c29b0d6f":"markdown","6d42b419":"markdown","ccdbbc4e":"markdown","0bc61b63":"markdown","dc6425ca":"markdown","58db2ea7":"markdown"},"source":{"2ad1683a":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport sys, os\nfrom matplotlib import pyplot as plt\nfrom sklearn.utils import resample\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.preprocessing import LabelEncoder\nfrom itertools import product\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix","ee366027":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d589dc00":"gender_data_dir = \"\/kaggle\/input\/voicegender\/\"\nvoice_df = pd.read_csv(os.path.join(gender_data_dir, \"voice.csv\"))","b21fe85f":"voice_df.head()","2a0cbf7c":"print(\"Size of Gender Recognition dataset       : {}\".format(voice_df.shape))","314e240c":"voice_df.info()","8c336092":"voice_df.describe().T","0f1814b1":"voice_df.isna().sum()                        # Printing a count of missing value w.r.t each feature in full_df","0b48e92c":"plt.figure(figsize=(9,6))\nsns.countplot(x='label', data=voice_df, order=[\"male\", \"female\"] )","fad5f4cb":"voice_df['label'].value_counts()           # Prints the count of different classes in 'label'","db8c7b6b":"# creating instance of labelencoder\nlabel_encode = LabelEncoder()","61c8fc14":"# Perform Encoding by coverting 'label' feature into numerical form\nvoice_df['label'] = label_encode.fit_transform(voice_df['label'])","222ddf9c":"voice_df.head()","455059da":"plt.subplots(4,5,figsize=(30,30))\nfor i in range(1,21):\n    plt.subplot(4,5,i)\n    plt.title(voice_df.columns[i-1])\n    sns.kdeplot(voice_df.loc[voice_df['label'] == 0, voice_df.columns[i-1]], color= 'red', label='female')\n    sns.kdeplot(voice_df.loc[voice_df['label'] == 1, voice_df.columns[i-1]], color= 'brown', label='male')","513fa46f":"fig = plt.figure(figsize = (20, 15))\nj = 0\nfor i in voice_df.columns:\n    plt.subplot(5, 5, j+1)\n    j += 1\n    sns.distplot(voice_df[i][voice_df['label']==0], color='r', label = 'Female')\n    sns.distplot(voice_df[i][voice_df['label']==1], color='b', label = 'Male')\n    plt.legend(loc='best')\nfig.suptitle('Voice Data Analysis')\nfig.tight_layout()\nfig.subplots_adjust(top=0.90)\nplt.show()","b71b91bf":"corr_data = voice_df.corr()                              # calculating correlation data between features\nplt.figure(figsize=(32, 20))                            # setting figure size\nsns.set_style('ticks')                                  # setting plot style\nsns.heatmap(corr_data, cmap='viridis',annot=True)       # plotting heatmap using sns library\nplt.show()","8929ed95":"selected_pixel_features = corr_data['label'].apply(lambda x: abs(x)).sort_values(ascending=False).iloc[1:21][::-1]\nplt.figure(figsize=(25,12))\nselected_pixel_features.plot(kind='barh',color='red')\n# calculating highest correlated faetures\n# with respect to target variable i.e. \"convert\"\nplt.title(\"Top highly correlated features\", size=20, pad=26)\nplt.xlabel(\"Correlation coefficient\")\nplt.ylabel(\"Features\")","b4967696":"selected_features = ['IQR','Q25','meanfun']","89d745b9":"voice_df_X = voice_df[selected_features]\nvoice_df_y = voice_df.label","c78fbdd5":"voice_df_X.head()","7c9729dc":"voice_df_y.head()","b2bcc82d":"# Splitting voice_df into 70% and 30% to construct Training and Testing Data respectively.\ntrainX, testX, trainy, testy = train_test_split(voice_df_X, voice_df_y,test_size=0.3,random_state=14)","c17bacb3":"trainX.shape","9243208b":"trainX.head()","e2385bb4":"trainy.shape","bf65fdd1":"trainy.head()","68e6e5c9":"testX.shape","01747c00":"testX.head()","c4edd880":"testy.shape","528968ad":"testy.head()","1115a52a":"def svm_kernel(trainX, trainy, testX, testy):\n    rate=[]\n    kernel=['rbf','poly','linear']\n    for i in kernel:\n        SVM_Model = SVC(kernel=i).fit(trainX,trainy)\n        y_pred = SVM_Model.predict(trainX)\n        print(i, 'Accuracy of Train Data : ', accuracy_score(trainy,y_pred))\n        y_pred = SVM_Model.predict(testX)\n        print(i, 'Accuracy of Test Data : ', accuracy_score(testy,y_pred))\n        rate.append(accuracy_score(testy,y_pred))\n    nloc = rate.index(max(rate))\n    print(\"Highest accuracy is %s occurs at %s kernel.\" % (rate[nloc], kernel[nloc]))\n    return kernel[nloc]","55c205e5":"def svm_error(k,C,x_train,y_train,x_test,y_test):\n    error_rate = []\n    C = range(1,C)\n    for i in C:\n        model = SVC(kernel=k,C=i).fit(x_train,y_train)\n        model.fit(x_train, y_train)\n        y_pred = model.predict(x_test)\n        error_rate.append(np.mean(y_pred != y_test))\n    cloc = error_rate.index(min(error_rate))\n    print(\"Lowest error is %s occurs at C=%s.\" % (error_rate[cloc], C[cloc]))\n\n    plt.plot(C, error_rate, color='red', linestyle='dashed', marker='o', markerfacecolor='green', markersize=10)\n    plt.title('Error Rate Vs C Value')\n    plt.xlabel('C')\n    plt.ylabel('Error Rate')\n    plt.show()\n    return C[cloc]","812848a3":"k = svm_kernel(trainX, trainy, testX, testy)","c06ad672":"c = svm_error(k, 10, trainX, trainy, testX, testy)","d26625a6":"# Initializing Principal Component Analysis(PCA)\nPCA_method = PCA(n_components=2)","033f1c85":"# Fit And Transorm Data\ntraindf= PCA_method.fit_transform(trainX)\ntestdf = PCA_method.transform(testX)","aedb1403":"# Plotting decision regions\nx_min, x_max = traindf[:, 0].min() - 1, traindf[:, 0].max() + 1\ny_min, y_max = traindf[:, 1].min() - 1, traindf[:, 1].max() + 1\n\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n\nf, ax = plt.subplots(figsize=(20, 12))\n\nSVM_Model = SVC(kernel=k, C=c).fit(traindf,trainy)\n\nfor clf, tt in zip([SVM_Model],['RBF Kernel SVM']):\n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    ax.contourf(xx, yy, Z, alpha=0.5)\n    ax.scatter(traindf[:, 0], traindf[:, 1], c=trainy, s=30, edgecolor='k')\n    ax.set_title(tt)\nplt.show()","84909f7c":"# Initailizing the Final SVM Classifier\nFinal_SVM_Model = SVC(kernel=k, C=c)\n# Train the model using the training sets\nFinal_SVM_Model.fit(trainX, trainy)","09fc150d":"Final_SVM_Model_train_predictions = Final_SVM_Model.predict(trainX)","6fccbeb1":"Final_SVM_Model_test_predictions = Final_SVM_Model.predict(testX)","68ff5c82":"print(\"SVM Model Confusion Matrix:\")\nprint(confusion_matrix(trainy, Final_SVM_Model_train_predictions))\n\nprint(\"SVM Model Classification Report\")\nprint(classification_report(trainy, Final_SVM_Model_train_predictions))","f272d633":"print(\"SVM Model Confusion Matrix:\")\nprint(confusion_matrix(testy, Final_SVM_Model_test_predictions))\n\nprint(\"SVM Model Classification Report\")\nprint(classification_report(testy, Final_SVM_Model_test_predictions))","1cf677e0":"OutputDF = pd.DataFrame({'Actual_label':testy,'Predicted_label':Final_SVM_Model_test_predictions})","b32e4296":"#Save to csv\nOutputDF.to_csv('gender_pred.csv',index=False)\nOutputDF.head()","cab44ed8":"# **Visualization :**","50288418":"**Using Above Analysis(KDE Plot, Distance Plot & correlation coefficient) on Voice DataFrame, we got to know that there are three important features which are IQR, Q25, meanfun.**","9331eeb9":"## **Correlation Matrix and Heat Map**","652b7e06":"### **On Training :**","2d5d32be":"# **Selected Features :**","d37e7267":"## **Data Description**","cb67b333":"**Hence, it is clearly visible that Q25, IQR and meanfun features will play an important role while classification. Since, they can classify Male and Female more effectively.**","5455abf1":"## **Kernel Density Estimate Plot :**","637c8af2":"**It is analagous to a histogram. It represents the data using a continuous probability density curve.**","2300266f":"**To analyze gender by voice and speech, a training database was required. A database was built using thousands of samples of male and female voices, each labeled by their gender of male or female. Voice samples were collected from the following resources:**\n\n**The Harvard-Haskins Database of Regularly-Timed Speech Telecommunications & Signal Processing Laboratory (TSP) Speech Database at McGill University VoxForge Speech Corpus Festvox CMU_ARCTIC Speech Database at Carnegie Mellon University Each voice sample is stored as a.WAV file, which is then pre-processed for acoustic analysis using the specan function from the WarbleR R package. Specan measures 22 acoustic parameters on acoustic signals for which the start and end times are provided.**\n\n**The output from the pre-processed WAV files were saved into a CSV file, containing 3168 rows and 21 columns (20 columns for each feature and one label column for the classification of male or female). You can download the pre-processed dataset in CSV format, using the link above.In order to analyze gender by voice and speech, a training database was required. A database was built using thousands of samples of male and female voices, each labeled by their gender of male or female.**\n\n","ffc8d6b7":"# **Descriptive Analysis of the dataset**","8a8af460":"## **Distance Plot :**","a3bbbf5f":"# **About Data:**","0016ce9a":"<a href=\"https:\/\/colab.research.google.com\/github\/Nikunjbansal99\/GenderPrediction\/blob\/main\/GenderRecognition.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","0fac461f":"# **Train-Test Splitting :**","201dc4c4":"**Hence, Value of C is Selected as 9 for our final SVM Model.**","9a28a5ee":"**Hence, We found that our data is Balanced.**","d13cc46b":"**Hence, RBF kernel is Selected for our final SVM Model.**","5b110c5b":"**If we will set the threshold i.e. correlation coefficient >= 0.5. We got three feature's which are meanfun, IQR, Q25**","c515cef3":"# **Applying Dimensionality Reduction :**","b1273c86":"# **Optimizing Best Parameters for SVM Classifier :**","b2f043d6":"# **Analysis of Target Variable**","a6838d57":"# **Creating Final SVM Classifier :**","c38d7217":"### **Perform Prediction on Testing Data :**","c2b8cdda":"### **On Testing :**","ba1acd66":"**Hence, it is clearly visible that Q25, IQR and meanfun features will play an important role while classification. Since, they can classify Male and Female more effectively.**","3fdb7612":"# **Evaluation**","fbf2fb2c":"### **Perform Prediction on Training Data :**","a06cb895":"# **Predictions on Test Data :**","23d36960":"**Thank you**,<br>\nNikunj Bansal,<br>\nR177218063,<br>\nB2 Batch<br>","c29b0d6f":"\n*   Importing Some Basic Libraries\n*   Importing Data\n*   Performing Descriptive Analysis on the dataset\n    *   Data Description\n    *   Checking null values\n*   Processing Categorical Values using encoding\n*   Analysis of Target Variable\n    *   Plotting Kernel Density Estimate Plot\n    *   Plotting Distance Plot\n    *   Plotting Correlation Matrix and Heat Map\n*   Select Features based on above analysis\n*   Splitting voice_df into 70% and 30% to construct Training data and Testing data respectively\n*   Optimizing Best Parameters for SVM Classifier\n*   Applying Dimensionality reduction\n*   Visualization\n*   Creating Final SVM Classifier\n    *   Perform Prediction on Training Data\n    *   Perform Prediction on Testing Data\n*   For Training data, Evaluating Model based on Confusion Matrix and Classification Report\n*   For Testing data, Evaluating Model based on Confusion Matrix and Classification Report\n*   Save predictions of Testing data in gender_pred.csv","6d42b419":"# **Importing Some Basic Libraries**","ccdbbc4e":"# **Importing Data**","0bc61b63":"## **Processing Categorical Values:**","dc6425ca":"# **Methodology**","58db2ea7":"## **Checking NULL\/NaN Values :**"}}