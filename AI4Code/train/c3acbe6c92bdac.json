{"cell_type":{"b8db5c66":"code","998e92d1":"code","8badc514":"code","1ae877b9":"code","402cffd0":"code","edc397dd":"code","47deb8e4":"code","a4ba9a76":"code","788fbd38":"code","2ecc410d":"code","6df761ce":"code","e606e714":"code","48865508":"code","6cd377eb":"code","19237dae":"code","eb2898e0":"code","d97c08ce":"code","5ecc77e0":"code","3cbad17f":"code","9ee87da7":"code","2be7774b":"code","a08104ac":"code","e4dd2e5d":"code","f22dccf3":"code","aeed04ac":"code","28a8206a":"code","244164e5":"code","f73bd921":"code","d13bb616":"code","6c9f5a02":"markdown","93e4a7de":"markdown","5b5f5686":"markdown","47572b69":"markdown","996e0a63":"markdown","ff937d71":"markdown","f1cb2cfe":"markdown","4e77172c":"markdown","52255a26":"markdown","22e4f5c4":"markdown","8e47fece":"markdown","be481291":"markdown","dd43e089":"markdown","55347111":"markdown"},"source":{"b8db5c66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","998e92d1":"df = pd.read_csv('\/kaggle\/input\/yeh-concret-data\/Concrete_Data_Yeh.csv')","8badc514":"df.head()","1ae877b9":"df.shape","402cffd0":"df.info()","edc397dd":"df.describe()","47deb8e4":"df.nunique()","a4ba9a76":"df.isnull().sum()","788fbd38":"import seaborn as sns \nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2ecc410d":"plt.figure(figsize=(10,10))\nsns.countplot(df[\"age\"])","6df761ce":"sns.color_palette(\"pastel\")\nfor col in df.columns:\n    if col !='age':\n        sns.histplot(df[col],kde=True, color='yellow')\n        plt.show()","e606e714":"df.head()","48865508":"sns.set_style(\"whitegrid\")\nsns.color_palette(\"pastel\")\nfor col in df.columns:\n    if col !='age':\n        sns.boxplot(df[col])\n        plt.show()","6cd377eb":"plt.figure(figsize=(15,15))\nsns.pairplot(df)\n\n\n\n","19237dae":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True,cmap='Spectral')","eb2898e0":"X = df.drop(['csMPa'],axis=1)\ny = df[\"csMPa\"]","d97c08ce":"from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, StackingRegressor, BaggingRegressor\nmodel = ExtraTreesRegressor()\nmodel.fit(X,y)","5ecc77e0":"feature_imps = pd.Series(model.feature_importances_, index = X.columns)\nfeature_imps.nlargest(8).plot(kind='barh')","3cbad17f":"from sklearn.decomposition import PCA\nplt.figure(figsize=(7,5))\npca_dummy = PCA(n_components=None)\nX_dummy = X\nX_dummy = pca_dummy.fit_transform(X_dummy)\nplt.plot(np.cumsum(pca_dummy.explained_variance_ratio_))","9ee87da7":"from sklearn.model_selection import train_test_split, cross_val_score\nX_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state=15)","2be7774b":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","a08104ac":"from xgboost import XGBRegressor\nxgb = XGBRegressor()\nxgb.fit(X_train,y_train)\ny_pred = xgb.predict(X_test)\nscore = r2_score(y_test,y_pred)\nscore\nprint('Accuracy of the Stacking regressor model is {}'.format(score*100))","e4dd2e5d":"print(cross_val_score(xgb, X_train, y_train, cv=5, scoring = 'r2').mean())","f22dccf3":"cross_val_score(xgb, X_test, y_test, cv=5, scoring = 'r2').mean()","aeed04ac":"from sklearn.linear_model import LinearRegression, SGDRegressor, ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, StackingRegressor, BaggingRegressor\nfrom sklearn.metrics import r2_score","28a8206a":"et = ElasticNet()\ngb = GradientBoostingRegressor()\nsr = StackingRegressor(estimators=[\n    ('et', et),\n    ('gb', gb),\n    ('xgb',xgb)])\n\nsr.fit(X_train,y_train)\n\n","244164e5":"y_pred = sr.predict(X_test)\nscore = r2_score(y_test,y_pred)\nprint('Accuracy of the Stacking regressor model is {}'.format(score*100))","f73bd921":"cross_val_score(sr, X_train, y_train, cv=5, scoring = 'r2').mean()","d13bb616":"cross_val_score(sr, X_test, y_test, cv=5, scoring = 'r2').mean()","6c9f5a02":"## Number of features to select","93e4a7de":"## Here, we can find the correlation between the variables ","5b5f5686":"# 3. EDA (bivariate) ","47572b69":"# 1. Initial Analysis","996e0a63":"### We have to select more than 4 features for best results ","ff937d71":"# 2. EDA (univariate)","f1cb2cfe":"# 5. Feature scaling","4e77172c":"## Some outliers in columns. If there are a lot, we can fix them. ","52255a26":"## Not in Guassian form : cement, slag, flyash, superplasticizer (Skewed Data)","22e4f5c4":"# 4. Feature Selection ","8e47fece":"## Features ranked based on importance ","be481291":"## Heatmap","dd43e089":"##  Extra Trees Regressor ","55347111":"# 6. Model Building"}}