{"cell_type":{"213e0cf6":"code","56f28717":"code","2389d377":"code","e831df75":"code","871a895a":"code","073a382c":"code","86c8a5ba":"code","c86a9045":"code","fd5f9c62":"code","2a330996":"code","290380c2":"code","fdf5c0c7":"code","f2075c3a":"code","fb8ec36f":"code","9178837e":"code","b8b4068a":"code","4fe7088c":"code","539368bb":"code","cd92ede6":"code","2e682620":"code","d98e6e19":"code","f711d7ce":"code","c592e9d9":"code","52110f2c":"code","e3a94801":"code","160249ac":"markdown","833082fd":"markdown","61966dde":"markdown","ac3f8157":"markdown","4c79c28b":"markdown","fdd10658":"markdown","c75305c2":"markdown","337d8492":"markdown","e33fad30":"markdown","bb968909":"markdown","dde4a322":"markdown","000e2d2d":"markdown","b073d334":"markdown","43762a01":"markdown","b03c40a0":"markdown","88ab44d7":"markdown","e0a31f1e":"markdown"},"source":{"213e0cf6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport cv2\nfrom keras import applications\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model","56f28717":"dataframe = pd.read_csv('\/kaggle\/input\/human-protein-atlas-image-classification\/train.csv')\ndataframe.head(5)","2389d377":"INPUT_SHAPE = (512, 512, 3)\nBATCH_SIZE = 16\npath_to_train = '\/kaggle\/input\/human-protein-atlas-image-classification\/train\/'","e831df75":"dataframe[\"complete_path\"] = path_to_train + dataframe[\"Id\"]\ndataframe.head(5)","871a895a":"import random\nfig, axes = plt.subplots(3, 4, figsize=(10, 10))\nfor i in range(3):\n    for j in range(4):\n        idx = random.randint(0, dataframe.shape[0])\n        row = dataframe.iloc[idx,:]\n        path = row.complete_path\n        red = np.array(Image.open(path + '_red.png'))\n        green = np.array(Image.open(path + '_green.png'))\n        blue = np.array(Image.open(path + '_blue.png'))\n        im = np.stack((\n                red,\n                green,\n                blue),-1)\n        axes[i][j].imshow(im)\n        axes[i][j].set_title(row.Target)\n        axes[i][j].set_xticks([])\n        axes[i][j].set_yticks([])\nfig.tight_layout()\nfig.show(5);","073a382c":"train, val = train_test_split(dataframe, test_size=0.2, random_state=42)\n","86c8a5ba":"print(f'Shape of train: {train.shape}')\nprint(f'Shape of val: {val.shape}')","c86a9045":"def get_clean_data(df):\n    targets = []\n    paths = []\n    for _, row in df.iterrows():\n        target_np = np.zeros((28))\n        t = [int(t) for t in row.Target.split()]\n        target_np[t] = 1\n        targets.append(target_np)\n        paths.append(row.complete_path)\n    return np.array(paths), np.array(targets)","fd5f9c62":"train_path, train_target = get_clean_data(train)\nval_path, val_target = get_clean_data(val)","2a330996":"print(f'Train path shape: {train_path.shape}')\nprint(f'Train target shape: {train_target.shape}')\nprint(f'Val path shape: {val_path.shape}')\nprint(f'Val target shape: {val_target.shape}')\n","290380c2":"train_data = tf.data.Dataset.from_tensor_slices((train_path, train_target))\nval_data = tf.data.Dataset.from_tensor_slices((val_path, val_target))","fdf5c0c7":"def load_data(path, target):\n    red = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_red.png'), channels=1), [2])\n    blue = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_blue.png'), channels=1), [2])\n    green = tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_green.png'), channels=1), [2])\n    #yellow=tf.squeeze(tf.image.decode_png(tf.io.read_file(path+'_yellow.png'), channels=1), [2])\n    img = tf.stack((\n                red,\n                green,\n                blue), axis=2)\n    return img, target\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_data = train_data.map(load_data, num_parallel_calls=AUTOTUNE)\nval_data = val_data.map(load_data, num_parallel_calls=AUTOTUNE)","f2075c3a":"def image_augment(img, target):\n    img = tf.image.random_contrast(img, lower=0.3, upper=2.0)\n    img = tf.image.random_flip_up_down(img)\n    img = tf.image.random_brightness(img, max_delta=0.1)\n    return img, target\n    \ntrain_data = train_data.map(image_augment, num_parallel_calls=AUTOTUNE)","fb8ec36f":"train_data_batches = train_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\nval_data_batches = val_data.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)","9178837e":"inception_model = applications.InceptionResNetV2(include_top=False, weights='imagenet')\n\ninception_model.trainable = False\n\ninput_layer = Input(shape=INPUT_SHAPE)\nx = inception_model(input_layer)\nx = Flatten()(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput = Dense(28, activation='softmax')(x)\nmodel = Model(input_layer, output)\n\nmodel.summary()","b8b4068a":"model.compile(optimizer=Adam(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])","4fe7088c":"history = model.fit(train_data_batches, validation_data = val_data_batches,steps_per_epoch = 50, epochs=10)","539368bb":"model.save('InceptionV2.h5')","cd92ede6":"binary_accuracy=history.history['accuracy']\nval_binary_accuracy=history.history['val_accuracy']\nepochs=range(1,len(binary_accuracy)+1)\nplt.plot(epochs,binary_accuracy,'b',label='Training accuracy')  \nplt.plot(epochs,val_binary_accuracy,'r',label='Validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\nplt.figure()\nplt.show()","2e682620":"loss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(1,len(binary_accuracy)+1)\nplt.plot(epochs,loss,'b',label='Training loss')\nplt.plot(epochs,val_loss,'r',label='Validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.figure()\nplt.show()","d98e6e19":"dataframe = pd.read_csv('\/kaggle\/input\/human-protein-atlas-image-classification\/sample_submission.csv')\ndataframe.head(5)","f711d7ce":"INPUT_SHAPE = (512, 512, 3)\nBATCH_SIZE = 16\npath_to_test = '\/kaggle\/input\/human-protein-atlas-image-classification\/test\/'","c592e9d9":"dataframe[\"complete_path\"] = path_to_test + dataframe[\"Id\"]\ndataframe.head(5)","52110f2c":"targets = dataframe['Predicted']\ntest_path ,targets = np.array(path_to_test), np.array(targets)","e3a94801":"savedModel = load_model('.\/kaggle\/output\/hpa-new\/InceptionV2.h5')","160249ac":"Spliting the data into parts train and val(valiation)","833082fd":"#  Visualizing the pictures\n\n","61966dde":" Adding the column with the name of complete_path and load the full path of each image on csv ","ac3f8157":"Better performance with the tf.data API\n","4c79c28b":"Using transfer learning and fine tuning on InceptionResNetV2","fdd10658":"model compilation ","c75305c2":"Cleaning the data for better results ","337d8492":"Adjust the contrast of an image or images by a random factor.\nApply Data Augmentation\n\n","e33fad30":"# Load the Lables of the images from train.csv file ","bb968909":"printing train and val path and target\n\n","dde4a322":" * Defining the input shape of 1st input layer \n * decalare the batch size\n * save the path of train images in the variable 'path_to_train'","000e2d2d":"# Here Importing the Eseantial libraries","b073d334":"Visualizing the Results ","43762a01":"# Building the Model Architecture ","b03c40a0":"Now finally fit the model for trianing ...","88ab44d7":"creating datasets from cleaned data\n","e0a31f1e":"Experimental API for building input pipelines.\n\n"}}