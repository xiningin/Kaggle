{"cell_type":{"056819a6":"code","75ffca42":"code","70d80200":"code","f1bdd99f":"code","7784b5e9":"code","81a5f344":"code","c70c900b":"code","8a901ea5":"code","fba59107":"code","2c927bfe":"code","a69bb6b4":"code","cf5ab0c1":"code","e86d38db":"code","0c1c68e0":"code","e9f1a8d3":"code","43ff26c7":"code","1562c059":"code","81bfdf33":"markdown","6dcda8f3":"markdown","145ee139":"markdown","8fe45bed":"markdown","7f700cdc":"markdown","b98537fd":"markdown","b35d8fd9":"markdown","60f371ec":"markdown","d643edd8":"markdown","1c3d6bb1":"markdown","74be226c":"markdown","8d60fa40":"markdown","c211385c":"markdown","e8c730fa":"markdown","9b2c4531":"markdown","6c515341":"markdown","b0920234":"markdown","04c2b3f7":"markdown"},"source":{"056819a6":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","75ffca42":"path_train = '..\/input\/30-days-of-ml\/train.csv'\npath_test = '..\/input\/30-days-of-ml\/test.csv'\n\n\ndf_train = pd.read_csv(path_train)\ndf_test = pd.read_csv(path_test)","70d80200":"df_train.head()","f1bdd99f":"df_test.head()","7784b5e9":"# Overview of df_train metadata\ndf_train.shape, df_test.shape","81a5f344":"# Checking the missing value\ndf_train.isnull().sum().sum(), df_test.isnull().sum().sum()","c70c900b":"cat_features_list = [feature for feature in df_train.columns if df_train[feature].dtype == 'object']\nprint(cat_features_list)","8a901ea5":"# Check the cardnality for each one of the categorical features\ndf_train[cat_features_list].nunique()","fba59107":"# checking if there is any categories present in df_test and not in df_train\nfor cat in cat_features_list:\n    print(f'df_test.{cat} is subset of df_train.{cat}: {set(df_test[cat]).issubset(set(df_train[cat]))}')","2c927bfe":"# Checking the distribution of the target column\nnbins = 100\nfig = px.histogram(df_train, x = \"target\", nbins = nbins, title = f'Distribution of the target with {nbins} bins.')\nfig.show()","a69bb6b4":"# Checking the distribution of the target column\ntemp_df = df_train[df_train.target > 6]\n\nnbins = 100\nfig = px.histogram(temp_df, x=\"target\", nbins=100, title = f'Distribution of the target with {nbins} bins.')\nfig.show()","cf5ab0c1":"# boxplot of the target\nfig = px.box(df_train, x = \"target\", title = 'Boxplot for the Target column.')\nfig.show()","e86d38db":"# Number of outliers below the Min value for the Target column.\nlen(df_train[df_train.target < 6.26])","0c1c68e0":"fig = make_subplots(rows = 10, cols = 1, subplot_titles = cat_features_list)\n\nfor i, feature in enumerate(cat_features_list, 1):\n    fig.add_trace(\n        go.Bar(x = df_train[feature].value_counts().index, y = df_train[feature].value_counts().values, name = feature),\n        row = i, col = 1\n    )\n\nfig.update_layout(height = 1400, title_text = 'Distribution of the values for the categorical features', showlegend = False)\nfig.show()","e9f1a8d3":"# Plotting the distribution for the count features\ncont_features_list = [feature for feature in df_train.columns if feature.startswith('cont')]\n\nfig = make_subplots(rows = int(len(cont_features_list) \/ 2), cols = 2, subplot_titles = cont_features_list)\n\nfor i in range(1, int((len(cont_features_list)) \/ 2) + 1):\n    for j in range (1, 3):\n        fig.add_trace(\n            go.Histogram(x = df_train[cont_features_list[i - 1]], nbinsx = 50),\n            row = i, col = j\n        )\n\nfig.update_layout(height = 2500, title_text = 'Distribution of the values for the cont features', showlegend = False)\nfig.show()","43ff26c7":"# Plotting the correlation for the count features and the target\ncont_features_list = [feature for feature in df_train.columns if feature.startswith('cont')]\nsubplot_titles = [f\"{col}(x) vs target(y)\" for col in cont_features_list]\n\ndf_temp = df_train.sample(frac = 0.005)\n\nfig = make_subplots(rows = int(len(cont_features_list) \/ 2), cols = 2, subplot_titles = subplot_titles)\n\nfor i in range(1, int((len(cont_features_list)) \/ 2) + 1):\n    for j in range (1, 3):\n        fig.add_trace(\n            go.Scatter(x = df_temp[cont_features_list[i - 1]], y = df_temp.target, mode='markers', opacity = 0.7),\n            row = i, col = j\n        )\n    \n\nfig.update_layout(height = 1500, title_text = 'Distribution of cont features vs target', showlegend = False)\nfig.show()","1562c059":"# Plotting the feature correlation\ncont_features_list.append(\"target\")\n\nfig = go.Figure(data=go.Heatmap(\n                   z = df_train[cont_features_list].corr(),\n                   x= cont_features_list,\n                   y= cont_features_list,\n                   hoverongaps = False,\n                   colorscale = 'blues'))\n\nfig.update_layout(height = 600, title_text = 'Correlations Heatmap', showlegend = False)\nfig.show() ","81bfdf33":"As there is a lot of entries, the plots for the distribution aren`t clear enough to see any relationship. In order to try to get something, let\u00b4s plot a correlation matrix","6dcda8f3":"# 3. Exploring the distribuion of the categorical featres.","145ee139":"The graph doesn't show much indeed but we can see that is outliers laying before 6. Lets remove them and see hor the behaviur looks like. ","8fe45bed":"Some interesting points from these graphs are:   \n- Almost every features are in the range between 0 and 1 (it looks like they were already normalized\/standardized);\n- cont0, cont1, cont2, cont3, cont6 and cont8 has negative values, which discharge the hipotheses off all cont to be normalized already;\n- Didn't find any useful patter in a first glance.","7f700cdc":"Only the feature cat9 has more than 10 categories. Anyway it shouldn't be a problem hence the df_train has 300k rows and a few more columns with this proportion won't cause any trouble.","b98537fd":"It turns out that 458 out of 300k isn't a relevant amount but stratified CV should be used to workout a safe solution that wont lost efficiency that much when facing these values.\n\nNow let's check the distributon for the categorical features.","b35d8fd9":"Some observations about the categorical features:    \n\n- only the cat1 seams to have an even distribution;   \n- cat0 seams to habe 66\/33% for distribution;    \n- cat2, cat3, cat4, cat6 and cat7 have only one column with the majority of the sample and the other categories with just so few elements;   \n- cat5, cat8, cat9 have and decrescent distbrution with some categoreis with much more entries, then some in an intermediate level and some with just few entries;\n- some features like cat0, cat1 and cat2 looks like to be a good fit for OneHotEncoding and the rest looks like to be a good fit for LabelEncoder    \n\nMust pay attention in this distribution when generating new features!\n\n","60f371ec":"# Explorating for the 30 Days of ML Competition\n\n## About the data\nThe dataset is used for this competition is synthetic, but based on a real dataset. The original dataset deals with predicting the amount of an insurance claim. Although the features are anonymized, they have properties relating to real-world features.","d643edd8":"# 1. First looking at train and test data","1c3d6bb1":"It seams that there  is no different entries that wont be seen in the training set. ","74be226c":"# 5. Exploring the correlations between the target and the cont features.","8d60fa40":"# 4. Exploring the distribution of the cont features","c211385c":"As suspected, the correlation between the features and the target is pretty weak never higher than 0.3 or lower than -0.3.\n\nBesides that, the highest correlation between the features we see is around 0.45. Also too small to be much relevant.   \n\nThat means the features are also not so strong correlated and a good feature engineering must be done in order to get better results!","e8c730fa":"No missing values either in the training data or in the test data.","9b2c4531":"# 2. Exploring the target feature.","6c515341":"Still a use case for Kfold-CV with bins ","b0920234":"Very strange distribution with some outliers and far away from normal behaviour. A good plot now may be box plot to get more insights about the distribution itself as well as about the outliers.","04c2b3f7":"Now, with these graphs we can say:   \n- There are some concerning outliers under the Min values (I would like to know how much they are);   \n- There are also some above the max value but they don't go far beyenond the max value.\n- It isn't a normal distribution;\n- Take realy much care while using the Cross Validation because the distributon in the bins must represent also these outliers."}}