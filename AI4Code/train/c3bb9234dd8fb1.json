{"cell_type":{"96456547":"code","81df4ca7":"code","785a27c9":"code","225c27f9":"code","45f58894":"code","685e2223":"code","1826e3bb":"code","9a9742eb":"code","8e108c40":"code","e5510d2c":"code","1e569150":"code","a2263f0b":"code","09af7241":"code","44e03375":"code","45c73146":"code","e219fe21":"code","bb7514e5":"code","6f466da7":"code","eb2d6144":"markdown","fc2b589b":"markdown","f74367ad":"markdown","b5ef24ab":"markdown","0db0abd2":"markdown","ac05396e":"markdown","db6f56de":"markdown","d0872712":"markdown","1f6c800e":"markdown","30c3e140":"markdown","4cfe44af":"markdown","61135efe":"markdown","972fa104":"markdown","250d1ddf":"markdown","7e89e87a":"markdown"},"source":{"96456547":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt  # data visualization","81df4ca7":"data_2C = pd.read_csv(\"..\/input\/column_2C_weka.csv\")  # for clearence I will name both of my DataFrames corresponding to original csv files","785a27c9":"data_2C.info()    # except our classes, whole dataset is float and there is no null value at all.","225c27f9":"data_2C.head(10)   # as we also know from the overview provided by owner of data, there is only 2 classes, Normal and Abnormal","45f58894":"data_2C.describe()","685e2223":"data_2C.corr()  # there are some highly correlated columns. such as pelvic_incidence and sacral_slope","1826e3bb":"import seaborn as sns   # for making better plots easily\nsns.pairplot(data_2C,hue=\"class\",palette=\"Set2\")\nplt.show()","9a9742eb":"data_2C.boxplot(figsize=(20,16),by=\"class\",grid=True)\nplt.show()","8e108c40":"plt.figure(figsize=(8,6))\nsns.heatmap(data_2C.corr(),vmax=1,vmin=-1,linewidths=0.4,annot=True)\nplt.show()","e5510d2c":"# first I will work on our x and y values for model\n\nx_train = data_2C.pelvic_incidence.values.reshape(-1,1)   # shape is crucial for sklearn models since they don't work well with \"(n,)\" style shapes.\ny_train = data_2C.sacral_slope.values.reshape(-1,1)\n\nx_test = np.arange(min(x_train),max(x_train)).reshape(-1,1)   # to predict each possible value between lowest and highest x values","1e569150":"plt.clf()\nplt.figure(figsize=(10,6))\nplt.scatter(x_train,y_train,c=\"orange\")\nplt.xlabel(\"pelvic incidence\")\nplt.ylabel(\"sacral slope\")\nplt.show()   # it's very sutiable especially for regression.","a2263f0b":"# importing the model\nfrom sklearn.linear_model import LinearRegression\n# declaring the model\nlr_model = LinearRegression()\n# training the model\nlr_model.fit(x_train,y_train)\n\n# predicting for all x_test (for graph) values (sequential) and storing in lr_y_head\nlr_y_head = lr_model.predict(x_test)\n\n# predicting real x values for score evaluation\nlr_y_head_real = lr_model.predict(x_train)","09af7241":"# importing the model\nfrom sklearn.tree import DecisionTreeRegressor\n# declaring the model\ndtr_model = DecisionTreeRegressor()\n# training the model\ndtr_model.fit(x_train,y_train)\n\n# predicting for all x_test values and storing in dtr_y_head\ndtr_y_head = dtr_model.predict(x_test)\n\n# predicting for all x_test (for graph) values (sequential) and storing in dtr_y_head\ndtr_y_head_real = dtr_model.predict(x_train)","44e03375":"# importing the model\nfrom sklearn.ensemble import RandomForestRegressor\n# declaring the model and setting amount of trees to the 128\nrf_model = RandomForestRegressor(n_estimators=128,random_state=42)\n# training the model\nrf_model.fit(x_train,y_train)\n\n# predicting for all x_test values and storing in rf_y_head\nrf_y_head = rf_model.predict(x_test)\n\n# predicting for all x_test (for graph) values (sequential) and storing in rf_y_head\nrf_y_head_real = rf_model.predict(x_train)","45c73146":"plt.figure(figsize=(20,10))\nplt.scatter(x_train,y_train,c=\"gray\")\nplt.xlabel(\"pelvic incidence\")\nplt.ylabel(\"sacral slope\")\nplt.plot(x_test,lr_y_head,c=\"red\",label=\"Linear Regression\",linewidth=4)\nplt.plot(x_test,rf_y_head,c=\"green\",label=\"RandomForest Regression\",linewidth=4)\nplt.plot(x_test,dtr_y_head,c=\"blue\",label=\"DecisionTree Regression\",linewidth=4)\nplt.legend()\nplt.suptitle(\"COMPARISON OF THE REGRESSION MODELS\",fontsize=20)\nplt.show()   ","e219fe21":"from sklearn.metrics import r2_score\n\nprint(\"score of linear regressor:\",          r2_score(y_train,lr_y_head_real))\nprint(\"score of decisiontree regressor:\",    r2_score(y_train,dtr_y_head_real))\nprint(\"score of randomforest regressor:\",    r2_score(y_train,rf_y_head_real))","bb7514e5":"algorithms = (\"Linear Regression\",\"Random Forest Regression\",\"Decision Tree Regression\")\nscores = (r2_score(y_train,lr_y_head_real), r2_score(y_train,dtr_y_head_real), r2_score(y_train,rf_y_head_real))\ny_pos = np.arange(1,4)\ncolors = (\"red\",\"green\",\"blue\")\n\nplt.figure(figsize=(24,12))\nplt.xticks(y_pos,algorithms,fontsize=18)\nplt.yticks(np.arange(0.00, 1.01, step=0.1))\nplt.bar(y_pos,scores,color=colors)\nplt.grid()\nplt.suptitle(\"Bar Chart Comparison of Models\",fontsize=24)\nplt.show()","6f466da7":"# Your Votes and Comments does matter to me. Please share your ideas or advices.       Regards,efe.","eb2d6144":"We can see that \"Normal\" people's values are very near. On the other hand \"Abnormal\" values are literally messy and quite separated. \n\nA simple Boxplot would show it even clearly.","fc2b589b":"# Conclusion:\nBoth graphs and scores shows that, with simple regressions we can easily make good predictions on this data.","f74367ad":"Let's see how it looks for regression.","b5ef24ab":"### Model #2: Decision Tree Regression","0db0abd2":"# Hello, this notebook will have:\n### EDA\n### Visual EDA            \n### Application of Some Good Regression Models with Sklearn\n### Visually and Statisticly Comparisons of the Results\n\n# ---------------------------------------------------------------------------------------------------------------","ac05396e":"### Model #3: RandomForest Regression","db6f56de":"## Regression Models","d0872712":"Plots above again showed us that \"Abnormal\"  data values (left side on plots from our view) has wider range and noisy.\n\nAn another goal of this Notebook is using regression models on the data, so I need to find some correlated values to use these models. \nWe already saw some correlated columns on EDA phase but let's create visual representation too.","1f6c800e":"## Visual EDA","30c3e140":"## EDA","4cfe44af":"I will use 3 different Regression models for my data then evaluate them\n\n### Model #1: Linear Regression","61135efe":"As seen above, they all worked well on their style. But what about the score?","972fa104":"Let's start with the \"column_2C_weka.csv\"","250d1ddf":" I decided to do my regrressions on pelvic_incidence and sacral_slope becasue they are most correlated columns by far","7e89e87a":"Since I predicted with all 3 different models, I can visualize them and see how they worked"}}