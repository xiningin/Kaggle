{"cell_type":{"723e09ae":"code","7a1c0157":"code","82b4d617":"code","91f2832d":"code","e5341c48":"code","3665cad1":"code","4185e9fb":"code","d2fb76ed":"code","d7a84e2e":"markdown","7c2c2edc":"markdown","d16adc78":"markdown","899ae5e3":"markdown"},"source":{"723e09ae":"import pandas as pd\nimport numpy as np\nimport os\nimport random\nimport torch\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nSEED = 1129\n\ndef seed_everything(seed=1129):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(SEED)","7a1c0157":"# load competition data\n\nclass_map = pd.read_csv(\"..\/input\/bengaliai-cv19\/class_map.csv\")\ntrain = pd.read_csv(\"..\/input\/bengaliai-cv19\/train.csv\")\n\ny = train[[\"vowel_diacritic\", \"grapheme_root\", \"consonant_diacritic\"]]","82b4d617":"# get validation data which you used\n\ntrain_idx, val_idx = train_test_split(train.index.tolist(), test_size=0.2, random_state=SEED, stratify=train[\"grapheme_root\"])\n\ny_val = y.values[val_idx].T\ny_val.shape, y_val","91f2832d":"# load your validation preds data\n\ny_pred = np.load('\/kaggle\/input\/bengali-valid-preds\/bengali_valid_preds.npy')\ny_pred.shape, y_pred","e5341c48":"def get_mislabel_and_probs(y_pred_df, y_test_df, class_map, component_type, threshold):\n    # Compute confusion matrix\n    cnf_matrix = confusion_matrix(y_test_df, y_pred_df)\n    \n    # normalization\n    cm = cnf_matrix.astype('float') \/ cnf_matrix.sum(axis=1)[:, np.newaxis]\n    \n    class_names = list(y_pred_df[0].unique())\n    \n    matrix_map = dict([(n, c) for n, c in enumerate(class_names)])\n    res = [[dict([c for c in class_map[class_map['component_type']==component_type] \\\n           [['label', 'component']].values])[matrix_map[np.argmax(c)]], \n            matrix_map[np.argmax(c)],\n            max(c)] for c in cm if max(c) < threshold]\n    return res","3665cad1":"# vowel_diacritic\ny_test_df = pd.DataFrame(y_val[0]) # V\ny_pred_df = pd.DataFrame(y_pred[0]) # V\n\nget_mislabel_and_probs(y_pred_df, y_test_df, class_map, 'vowel_diacritic', 0.99)","4185e9fb":"# grapheme_root\ny_test_df = pd.DataFrame(y_val[1]) # G\ny_pred_df = pd.DataFrame(y_pred[1]) # G\n\nget_mislabel_and_probs(y_pred_df, y_test_df, class_map, 'grapheme_root', 0.9)","d2fb76ed":"# consonant_diacritic\ny_test_df = pd.DataFrame(y_val[2]) # C\ny_pred_df = pd.DataFrame(y_pred[2]) # C\n\nget_mislabel_and_probs(y_pred_df, y_test_df, class_map, 'consonant_diacritic', 0.99)","d7a84e2e":"### EOF\n\n### Thank you!","7c2c2edc":"### \ud83d\udd3c My model is poor at predicting '\u09a6\u09cd\u09a6'\n\n### I have to tuning more.","d16adc78":"### \ud83d\udd3c above means your model predict '\u09c8' with probability 0.9858053650908216","899ae5e3":"# TL;DR\n\n### I made utility function to get classes and accuracy rate\n### I wish this will be useful for your modeling"}}