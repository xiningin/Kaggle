{"cell_type":{"3d6f06a6":"code","e23ef6c2":"code","5988408e":"code","134f95f7":"code","1e7029b9":"code","9bfc713e":"code","c661d757":"code","d28b9f79":"code","178b5b6b":"code","f3f77ed1":"code","34e91246":"code","fdfce0da":"code","442157da":"code","624aeeb5":"code","09d88efd":"code","f0a0faa1":"code","d3af3e29":"code","c0fba32d":"code","97e7c3ee":"markdown"},"source":{"3d6f06a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e23ef6c2":"import pandas as pd\ndf = pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict.csv')","5988408e":"import sklearn\nfrom sklearn.model_selection import train_test_split\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","134f95f7":"df.head(2)\ndf.columns\ndf.shape","1e7029b9":"labels = df['Chance of Admit ']\nfeatures = df.iloc[:,:-1]","9bfc713e":"X = features\ny = labels\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n\nX_train_Res = X_train['Research']\nX_test_Res = X_test['Research']\nX_train.drop(columns=['Research'],axis=1,inplace=True)\nX_test.drop(columns=['Research'],axis=1,inplace=True)\n","c661d757":"mean = X_train.mean(axis=0)\nX_train -= mean\nstd = X_train.std(axis=0)\nX_train \/= std\n\n\nX_test -= mean\nX_test \/= std","d28b9f79":"X_train['Research']=X_train_Res\nX_train.head(2)\n\nX_test['Research']=X_test_Res\nX_test.head(2)\n\nX_train.shape\nX_test.shape","178b5b6b":"import keras\nfrom keras import models\nfrom keras import layers\n","f3f77ed1":"def build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(8, activation='relu',\n                           input_shape=(X_train.shape[1],)))\n    model.add(layers.Dense(8, activation='relu'))\n    model.add(layers.Dense(1))\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n    return model","34e91246":"k = 4\nnum_val_samples = len(X_train) \/\/ k\n\nnum_epochs = 200\nall_mae_histories = []\nfor i in range(k):\n    print('processing fold #', i)\n    # Prepare the validation data: data from partition # k\n    val_data = X_train[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = y_train[i * num_val_samples: (i + 1) * num_val_samples]\n\n    # Prepare the training data: data from all other partitions\n    partial_train_data = np.concatenate(\n        [X_train[:i * num_val_samples],\n         X_train[(i + 1) * num_val_samples:]],\n        axis=0)\n    partial_train_targets = np.concatenate(\n        [y_train[:i * num_val_samples],\n         y_train[(i + 1) * num_val_samples:]],\n        axis=0)\n\n    # Build the Keras model (already compiled)\n    model = build_model()\n    # Train the model (in silent mode, verbose=0)\n    history = model.fit(partial_train_data, partial_train_targets,\n                        validation_data=(val_data, val_targets),\n                        epochs=num_epochs, batch_size=4, verbose=0)\n    mae_history = history.history['val_mae']\n    all_mae_histories.append(mae_history)\n","fdfce0da":"average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]","442157da":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nplt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()","624aeeb5":"def smooth_curve(points, factor=0.9):\n  smoothed_points = []\n  for point in points:\n    if smoothed_points:\n      previous = smoothed_points[-1]\n      smoothed_points.append(previous * factor + point * (1 - factor))\n    else:\n      smoothed_points.append(point)\n  return smoothed_points\n\nsmooth_mae_history = smooth_curve(average_mae_history[10:])\n\nplt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\nplt.xlabel('Epochs')\nplt.ylabel('Validation MAE')\nplt.show()","09d88efd":"model = build_model()\n# Train it on the entirety of the data.\nmodel.fit(X_train, y_train,\n          epochs=60, batch_size=8)\ntest_mse_score, test_mae_score = model.evaluate(X_test, y_test)","f0a0faa1":"test_mse_score, test_mae_score\n\nmodel.metrics_names","d3af3e29":"predictions = model.predict(X_test)\npred = predictions.flatten()\ndiff = abs(y_test-pred)\ndiff.describe()","c0fba32d":"import matplotlib.pyplot as plt\n_, ax = plt.subplots()\n\nax.scatter(x = range(0, y_test.size), y=y_test, c = 'blue', label = 'Actual', alpha = 0.3)\nax.scatter(x = range(0, pred.size), y=pred, c = 'red', label = 'Predicted', alpha = 0.3)\n\nplt.title('Actual and predicted values')\nplt.xlabel('Student')\nplt.ylabel('Chance of Admission')\nplt.legend()\nplt.show()","97e7c3ee":"Normalizing all umerical columns, omitting Research\n"}}