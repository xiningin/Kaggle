{"cell_type":{"1593f34e":"code","12a1a20c":"code","7dfac6a7":"code","7e373b20":"code","2c9d0165":"code","606cea2a":"code","989248e9":"code","043d19c6":"code","401b3512":"code","adaca1e7":"code","2e9b6f51":"code","c30b7887":"code","1167e7b6":"code","2e53d661":"code","52ddc7d7":"code","0aecfb14":"code","22a39dac":"code","85814c37":"code","c95580c9":"code","d3d3b366":"code","6d0082a7":"code","84c46741":"code","3e20e5a3":"code","7cbdc1f0":"code","2173e537":"code","b9571f3e":"code","699db66e":"code","e9de1ad6":"code","78cecc4e":"code","8bc2ee8a":"code","f9ad2a19":"code","17a19481":"code","4d9645ce":"code","a4adecdb":"code","37d6daa3":"code","8d6cfd04":"code","487e5faa":"code","ed0602e8":"code","d3039abe":"code","55a67d95":"code","f76f0a1d":"code","ba632e59":"code","36819580":"code","6db6fc12":"code","b2bd72e6":"code","a0e9b733":"code","4b28296b":"code","efc283b8":"code","bd4b744c":"code","fb670e07":"code","e98ecc93":"code","ab8b7ea7":"code","69370035":"code","eb8ea4ad":"markdown","5ea5c58f":"markdown","b682371f":"markdown","31d49cd1":"markdown","da4e67c8":"markdown","8612cc6c":"markdown","9abdbca3":"markdown","21a3d40f":"markdown","2ae9b386":"markdown","85e9161b":"markdown","9b2647ee":"markdown","797f9819":"markdown","e818714c":"markdown","aeaa0c8a":"markdown","7d177451":"markdown","780d3657":"markdown","3ddaaff3":"markdown","f36b90fe":"markdown","61c88ab7":"markdown","f11bc2df":"markdown","fa8c280b":"markdown","6efc662d":"markdown","fcbf3ba7":"markdown","27f9fddb":"markdown","f104040a":"markdown","7daf805c":"markdown","153ca47c":"markdown","b894fd5e":"markdown","d8af4ff6":"markdown","c09d6548":"markdown","407382d0":"markdown","42e2d52c":"markdown","2f95935a":"markdown","9f88f889":"markdown","7abe4c54":"markdown","7567ae5e":"markdown","f552644a":"markdown","317fe499":"markdown","289c7ec8":"markdown","945392c5":"markdown","07fa7e47":"markdown","343c8a3c":"markdown","9b18646c":"markdown","97d02c9b":"markdown","140e6f28":"markdown"},"source":{"1593f34e":"#Basic libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#Preprocessing\nfrom sklearn.preprocessing import RobustScaler\n\n#Machine Learning\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_selection import SelectKBest, f_classif\n\n#Metrics\nfrom sklearn.metrics import f1_score, recall_score, confusion_matrix, classification_report, precision_recall_curve\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')","12a1a20c":"#data importation\ndata = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","7dfac6a7":"#quick data visualization\ndata.head()","7e373b20":"data.shape","2c9d0165":"data.dtypes","606cea2a":"#Convert SeniorCitizen to object\ndata['SeniorCitizen'] = data['SeniorCitizen'].apply(str)\n\n#convert TotalCharges to float\ndata['TotalCharges'] = data['TotalCharges'].replace({\" \":'0'})\ndata['TotalCharges'] = data['TotalCharges'].astype(float)","989248e9":"#Let's delete unusefull features\ndata = data.drop('customerID', axis=1)","043d19c6":"# Colonnes quantitative\nnumeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n# Colonnes qualitative\nnominal_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']","401b3512":"#Description of numericall variables\ndata.describe()","adaca1e7":"for col in data[numeric_features]:\n    plt.figure()\n    sns.distplot(data[col])","2e9b6f51":"for col in data.select_dtypes('object'):\n    plt.figure()\n    data[col].value_counts().plot.pie()","c30b7887":"columns = ['tenure', 'MonthlyCharges', 'TotalCharges','gender', 'SeniorCitizen', 'Partner', 'Dependents',\n       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']","1167e7b6":"for col in nominal_features :\n    plt.figure()\n    sns.heatmap(pd.crosstab(data['Churn'], data[col]), annot=True, fmt='d')\n","2e53d661":"for col in nominal_features:\n    plt.figure()\n    sns.countplot(x=col, hue='Churn', data=data)","52ddc7d7":"churn_df = data[data['Churn'] == 'Yes']\nnoChurn_df = data[data['Churn'] == 'No']\n\nfor col in numeric_features:\n    plt.figure()\n    sns.distplot(churn_df[col], label='Yes')\n    sns.distplot(noChurn_df[col], label='No')\n    plt.legend()","0aecfb14":"df = data.copy()","22a39dac":"from sklearn.model_selection import train_test_split","85814c37":"trainset, testset = train_test_split(df, test_size=0.2, random_state=0)","c95580c9":"trainset['Churn'].value_counts(normalize=True)","d3d3b366":"testset['Churn'].value_counts(normalize=True)","6d0082a7":"#encoding for our services columns\n\n#columns for label endoding \nlabelEndoding_cols =  ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n       'PhoneService', 'MultipleLines', 'OnlineSecurity',\n       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n       'StreamingMovies', 'PaperlessBilling','Churn']\n\n#columns for oneHot encoding\noneHot_cols = ['InternetService','Contract', 'PaymentMethod']","84c46741":"#create encoding function\ndef encoding(df):\n    \n    code = {'Male':1,\n        'Female':0,\n        '1':1,\n        '0':0,\n        'Yes':1,\n       'No':0,\n       'No internet service':0,\n       'No phone service':0}\n        \n    for col in df[labelEndoding_cols].columns:\n        df.loc[:,col] = df[col].map(code)\n\n    df = pd.get_dummies(df,columns=['InternetService'],prefix='InternetService')\n    df = pd.get_dummies(df,columns=['Contract'],prefix='Contract')\n    df = pd.get_dummies(df,columns=['PaymentMethod'],prefix='PaymentMethod')\n    \n    return df","3e20e5a3":"def preprocessing(df):\n    \n    df = encoding(df)\n    \n    X = df.drop('Churn',axis=1)\n    y = df['Churn']\n    \n    print(y.value_counts())\n    \n    return X,y","7cbdc1f0":"X_train, y_train = preprocessing(trainset)","2173e537":"X_test, y_test = preprocessing(testset)","b9571f3e":"def evaluation(name,model):\n    \n    model.fit(X=X_train, y=y_train)\n    ypred = model.predict(X_test)\n    \n    print(name)\n    print(confusion_matrix(y_test,ypred))\n    print(classification_report(y_test,ypred))\n    \n    N, train_score, val_score = learning_curve(model, X_train, y_train, \n                                               cv=4, scoring='f1',\n                                               train_sizes=np.linspace(0.1,1,10))\n    \n    \n    plt.figure(figsize=(12,8))\n    plt.title(name)\n    plt.plot(N,train_score.mean(axis=1), label='train score')\n    plt.plot(N,val_score.mean(axis=1), label='val score')","699db66e":"preprocessor = make_pipeline(SelectKBest(f_classif,k=8))","e9de1ad6":"DecisionTree = make_pipeline(preprocessor,DecisionTreeClassifier(random_state=0))\nRandomForest = make_pipeline(preprocessor, RandomForestClassifier(random_state=0))\nLR = make_pipeline(preprocessor,LogisticRegression(random_state=0))\nAdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state=0))\nSVM = make_pipeline(preprocessor,StandardScaler(), SVC(random_state=0))\nKNN = make_pipeline(preprocessor,StandardScaler(), KNeighborsClassifier())","78cecc4e":"list_of_models = [DecisionTree,RandomForest,LogisticRegression, AdaBoost, SVM, KNN]","8bc2ee8a":"dict_of_models = {'DecisionTree': DecisionTree,\n                 'RandomForest': RandomForest,\n                 'LR': LR,\n                 'AdaBoost': AdaBoost,\n                 'SVM': SVM,\n                 'KNN': KNN\n                 }","f9ad2a19":"for name, model in dict_of_models.items():\n    evaluation(name,model)","17a19481":"LR.get_params().keys()","4d9645ce":"hyper_params_lr = {\n    'logisticregression__penalty':['l1', 'l2', 'elasticnet'],        # l1 is Lasso, l2 is Ridge\n    'logisticregression__C': np.arange(1e-05, 3, 0.1),\n}","a4adecdb":"grid_lr = GridSearchCV(LR,hyper_params_lr,scoring='recall', cv=4)\n\ngrid_lr.fit(X_train,y_train)\n\nprint(grid_lr.best_params_)\n\ny_pred = grid_lr.predict(X_test)","37d6daa3":"evaluation('Logistic Regression',grid_lr.best_estimator_)","8d6cfd04":"SVM.get_params().keys()","487e5faa":"hyper_params_svm = {'svc__gamma':[1e-3, 1e-4, 0.0005],\n                'svc__C':[1, 10, 100, 1000, 3000],\n               }","ed0602e8":"grid_svm = GridSearchCV(SVM,hyper_params_svm,scoring='recall', cv=4)\n\ngrid_svm.fit(X_train,y_train)\n\nprint(grid_svm.best_params_)\n\ny_pred = grid_svm.predict(X_test)","d3039abe":"evaluation('SVM',grid_svm.best_estimator_)","55a67d95":"AdaBoost.get_params().keys()","f76f0a1d":"hyper_params_abc = {\n     'adaboostclassifier__n_estimators': np.arange(10,300,10),\n     'adaboostclassifier__learning_rate': [0.01, 0.05, 0.1, 1],\n }","ba632e59":"grid_abc = GridSearchCV(AdaBoost,hyper_params_abc,scoring='recall', cv=4)\n\ngrid_abc.fit(X_train,y_train)\n\nprint(grid_abc.best_params_)\n\ny_pred = grid_abc.predict(X_test)","36819580":"evaluation('AdaBoost',grid_abc.best_estimator_)","6db6fc12":"KNN.get_params().keys()","b2bd72e6":"hyper_params_knn = {'kneighborsclassifier__n_neighbors':[4,5,6,7],\n              'kneighborsclassifier__leaf_size':[1,3,5],\n              }","a0e9b733":"grid_knn = GridSearchCV(KNN,hyper_params_knn,scoring='recall', cv=4)\n\ngrid_knn.fit(X_train,y_train)\n\nprint(grid_knn.best_params_)\n\ny_pred = grid_knn.predict(X_test)","4b28296b":"evaluation('KNN',grid_abc.best_estimator_)","efc283b8":"precision, recall, threshold = precision_recall_curve(y_test,grid_abc.best_estimator_.decision_function(X_test))","bd4b744c":"plt.plot(threshold, precision[:-1], label='precision')\nplt.plot(threshold, recall[:-1], label='recall')\nplt.legend()","fb670e07":"def model_final(model, X, threshold=0) :\n    return model.decision_function(X) > threshold","e98ecc93":"y_pred = model_final(grid_abc.best_estimator_, X_test, threshold=-0.1)","ab8b7ea7":"recall_score(y_test,y_pred)","69370035":"f1_score(y_test, y_pred)","eb8ea4ad":"Each row represents a customer, each column contains customer\u2019s attributes described on the column Metadata.","5ea5c58f":"### Quick exploration on numeric features","b682371f":"### Conclusion","31d49cd1":"### Encoding","da4e67c8":"The churn proportions are similar between the train and the test set.","8612cc6c":"We will continue our project with the Adaboost model.","9abdbca3":"### Model selection","21a3d40f":"Models to test : \n* Decision Tree\n* Random Forest\n* Logistic Regression\n* AdaBoost\n* SVM\n* KNN","2ae9b386":"**Demographic info**\n* Gender : balanced distribution\n* SeniorCitizen : unbalanced variable with only 20% of SeniorCitizen\n* Partner : balanced distribution\n\n**Services** \n* MultipleLines : balanced distribution between Yes and No. A minority of customers don't have a phone service\n* InternetService : balanced distribution between DSL, Fiber optic and no\n* OnlineSecurity : balanced distribution between Yes, No and no internet service (but we can notice a majority of No)\n* OnlineBackup : balanced distribution between Yes, No and no internet service\n* DeviceProtection : balanced distribution between Yes, No and no internet service (but we can notice a majority of No)\n* TechSupport : balanced distribution between Yes, No and no internet service (but we can notice a majority of No)\n* StreamingTV : balanced distribution between Yes, No and no internet service\n* StreamingMovies : balanced distribution between Yes, No and no internet service\n\nEven if these variables are equally distributed, we can note that the answer \"No\" and the answer \"no internet\/phone service\" mean the same thing => The customer did not subscribe to the service. So there is a minority of customers subscribed for each service.\n\n**Customer account information**\n* Contract : the majority of clients have a month-to-month contract\n* PaperlessBilling : majority of paperless billing\n* PaymentMethod : balanced distribution between Credit card (automatic), Electronic check, Bank transfert (automatic) and Mailed check\n\n**Target**\n* Churn : a quarter of the clients are in churn","85e9161b":"### Preprocessing function","9b2647ee":"Decision Tree and Random Forest are overfeating.\nAfter analyzing the results, we will focus on the Logistic Regression, KNN, SVM and AdaBoost models.","797f9819":"**Objective** : Predict churn characteristics to retain customers. ","e818714c":"We can notice characteristics of churn customers :\n* Fiber optic \n* month to month contract \n* Paperless billing\n* Electronic check","aeaa0c8a":"We can notice some problems: \n* the SeniorCitizen attribute is considered as a numerical variable whereas it is a cathegory variable. \n* The TotalCharges attribute is considered as an object whereas it is a numerical variable.","7d177451":"With Adaboost and some optimization elements, we managed to obtain a model able to **detect 91% of TELCO's customers who went to churn**. Thanks to this type of model, the company could contact these customers in order to propose them to modify their contract.","780d3657":"### KNN Optimization","3ddaaff3":"Let's choose a threshold at -0.1 in order to get a best recall.","f36b90fe":"# 4. Modeling","61c88ab7":"### Explore relations between variables and target","f11bc2df":"# 3. Preprocessing","fa8c280b":"### Models","6efc662d":"* The SVM model could have been an interesting model if we had less data. \n* Logistic Regression has good results, but the Adaboost and KNN models have the best performance with a recall of 0.52 and an f1-score of 0.57. ","fcbf3ba7":"### AdaBoost Optimization","27f9fddb":"### Precision Recall Curve for the Adaboost model","f104040a":"### Let's split the dataset as train and test set","7daf805c":"#### Timechart : chrun distribution for each numeric features","153ca47c":"### Let's have a look on the 21 attributes","b894fd5e":" # Telco Churn Prediction","d8af4ff6":"### Quick exploration on the nominal features + target","c09d6548":"### Separate quantitative and qualitative features","407382d0":"### SVM Optimization","42e2d52c":"We can notice that none of the quantitative variables are normally distributed.","2f95935a":"### Countplot nominal features \/ target","9f88f889":"**Demographic info about customers**\n* gender : the customer is a male or a female\n* SeniorCitizen : the customer is a old person no longer employed (1 or 0 if not)\n* Partner : the customer has a partner (Yes or No)\n* Dependents : the client has dependents (Yes or No)\n* tenure :  number of months a customer has had an account\n    \n    \n**Services that each customer has signed up for**\n* PhoneService (Yes or No)\n* MultipleLines  (Yes, No or No phone service)\n* InternetService (DSL, Fiberoptic or NO)\n* OnlineSecurity (Yes, No or No internet Service)\n* OnlineBackup (Yes, No or No internet Service)\n* DeviceProtection (Yes, No or No internet Service)\n* TechSupport (Yes, No or No internet Service)\n* StreamingTV (Yes, No or No internet Service)\n* StreamingMovies (Yes, No or No internet Service)\n\n\n**Customer account information**\n* customerID : unique identification number given to each customer\n* Contract : : contract renewal (One year, Two year or Month-to-month)\n* PaperlessBilling : online billing (Yes or No)\n* PaymentMethod :  (Credit card (automatic), Electronic check, Bank transfert (automatic) or Mailed check)\n* MonthlyCharges : from 18.25 to 118.75\n* TotalCharges : from 0 to 8884.80\n\n\n**Target**\n* Churn : customers who left within the last month (Yes or No)","7abe4c54":"In this project, we prefer to focus on recall and f1 score metrics. Indeed, the company will prefer to identify a maximum number of customers potentially wishing to churn in order to offer them a different offer. It would be a shame to let customers leave without offering them another offer. We therefore seek to minimize the number of false negatives.","7567ae5e":"### Logistic Regression Optimization","f552644a":"The dataset gathers data from 7043 customers described by 21 attributes.","317fe499":"This notebook is my first contribution on Kaggle. I'm open to any kind of feedback to help me improve my work and skills !","289c7ec8":"# 2. Quick data exploration and cleaning","945392c5":"clients who have a contract for less than 20 months are more likely to churn.","07fa7e47":"After a quick exploration of Telco's customer data, we will implement Machine Learning models to help the company to identify customers at risk of churn. This customer classification will allow the company to implement actions to try to keep these customers.","343c8a3c":"# 1. Libraries and data importation","9b18646c":"### Models Evaluation","97d02c9b":"#### Heatmap crosstab : target distribution for each nominal features","140e6f28":"### Evaluation funtion"}}