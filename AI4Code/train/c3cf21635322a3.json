{"cell_type":{"dd06d329":"code","757413c0":"code","720eade5":"code","27b98ed8":"code","f5421d25":"code","19874c7d":"code","f353067d":"code","57818785":"code","d09fcdae":"code","6b930136":"code","e236c631":"markdown","76708e6d":"markdown","2aab68f6":"markdown","6fb30917":"markdown","41bee0d5":"markdown","c12f28b7":"markdown","1e95b901":"markdown","c3d5edaf":"markdown","519d639e":"markdown","88360df1":"markdown","1122a63a":"markdown"},"source":{"dd06d329":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nfrom fastai.vision import *\n# Function that returns an image from its url\n\ndef get_img(img_path): return open_image(img_path)\n# Function that displays many transformations of an image\ndef plots_of_one_image(img_path, tfms, rows=1, cols=3, width=15, height=5, **kwargs):\n    img = get_img(img_path)\n    [img.apply_tfms(tfms, **kwargs).show(ax=ax) \n     for i,ax in enumerate(plt.subplots(rows,cols,figsize=(width,height))[1].flatten())]           \n    \nimport os\nos.listdir() \nos.getcwd()","757413c0":"from glob import glob\nlist_img_train = sorted(glob('..\/input\/siimdatasetx128\/siim-datasetx128\/siim-datasetx128\/train\/128\/dicom\/*.png'))\nlist_img_mask_train =  sorted(glob('..\/input\/siimdatasetx128\/siim-datasetx128\/siim-datasetx128\/train\/128\/mask\/*.png'))\nlist_img_test =  sorted(glob('..\/input\/siimdatasetx128\/siim-datasetx128\/siim-datasetx128\/test\/128\/dicom\/*.png'))\n\nprint(len(list_img_train),len(list_img_mask_train),len(list_img_test))","720eade5":"_,axs = plt.subplots(1,4,figsize=(20,10))\nfor (i,ax),(img_,j) in zip(enumerate(axs),[(get_img(list_img_train[j]),j) \n                                           for j in [2974,9638,9357,8702]]):\n    img_.show(ax=ax, title=f'Xray {j}')\n    \n_,axs = plt.subplots(1,4,figsize=(20,10))\nfor (i,ax),(img_,j) in zip(enumerate(axs),[(get_img(list_img_mask_train[j]),j) \n                                           for j in [2974,9638,9357,8702]]):\n    img_.show(ax=ax, title=f'Mask {j}')","27b98ed8":"list_img_train[2974]\ntfms = [rotate(degrees=(-30,30), p=1.0)]\nplots_of_one_image(list_img_train[2974],tfms,padding_mode='border')\nplots_of_one_image(list_img_mask_train[2974],tfms,padding_mode='border')","f5421d25":"list_img_train[2974]\ntfms = [rotate(degrees=(-30,30), p=1.0)]\nplots_of_one_image(list_img_train[2974],tfms,padding_mode='reflection')\nplots_of_one_image(list_img_mask_train[2974],tfms,padding_mode='reflection')","19874c7d":"tfms = [brightness(change=(0.1, 0.9))]\nplots_of_one_image(list_img_train[2974],tfms)","f353067d":"tfms = [contrast(scale=(0.5, 2.), p=1.)]\nplots_of_one_image(list_img_train[2974],tfms)","57818785":"fig, axs = plt.subplots(1,3,figsize=(20,5))\nfor magnitude, ax in zip(np.linspace(-0.05,0.05,5), axs):\n    tfms = [jitter(magnitude=magnitude, p=1.)]\n    get_img(list_img_train[2974]).apply_tfms(tfms).show(ax=ax,title=\"magnitude={}\".format(magnitude))","d09fcdae":"tfms = [symmetric_warp(magnitude=(-0.2,0.2), p=1.)]\nplots_of_one_image(list_img_train[2974],tfms,padding_mode='zeros')\nplots_of_one_image(list_img_mask_train[2974],tfms,padding_mode='zeros')","6b930136":"fig, axs = plt.subplots(1,3,figsize=(20,5))\nfor scale, ax in zip(np.linspace(1.,2.5,3), axs):\n    tfms = [zoom(scale=scale, p=1.)]\n    get_img(list_img_train[2974]).apply_tfms(tfms).show(ax=ax,title='scale={}'.format(scale))\n    \nfig, axs = plt.subplots(1,3,figsize=(20,5))\nfor scale, ax in zip(np.linspace(1.,2.5,3), axs):\n    tfms = [zoom(scale=scale, p=1.)]\n    get_img(list_img_mask_train[2974]).apply_tfms(tfms).show(ax=ax,title='scale={}'.format(scale))","e236c631":"## Brightness","76708e6d":"### \"padding_mode' = border : Apply reflection effect to fill pixels","2aab68f6":"### \"padding_mode' = border : Apply full color at the border of the image in missing pixels","6fb30917":"## Simple Data Augmentation for SIIM Pneumotorax Challenge with fastai\n\nOn this challenge we have a really small amount of data while the problem is highly complicated. Here we will go through some strategies of Data Augmentation in order to be able to increase the amount of data available for our neural network training ;).\n\n**The kernel will be updated often, do not hesitate to leave your comments.**\n> Please upvote if you find this kernel useful. \n\n**Important Note: Only apply transformation on mask when the position move (do not apply to brightness and contrast for example it is useless :))**","41bee0d5":"## Jitter","c12f28b7":"## More details and specific scripts to construct the new dataset will follow","1e95b901":"### Constrast << Really useful !","c3d5edaf":"### Perspective","519d639e":"## Rotation + fill missing pixels","88360df1":" ## List all images saved in format 128x128**","1122a63a":"## Zoom"}}