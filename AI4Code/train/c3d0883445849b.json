{"cell_type":{"bcb3f17e":"code","383c4e01":"code","2dfac09f":"code","dd233885":"code","dede431c":"code","5f7b5fbe":"code","e5c29885":"code","6fc6dff7":"code","c5607b1a":"code","51e5b57f":"code","16b16914":"code","0f398cb2":"code","79ac22e3":"code","71a6c88d":"code","c0095b3b":"code","78100b30":"code","9ce2eb54":"code","9fa32936":"code","7554d097":"code","20d862ee":"code","08551caf":"code","6a3b63c9":"markdown","a38cb84d":"markdown","ba3a169b":"markdown","dfda7e58":"markdown","c468bfc4":"markdown","0b2ae38f":"markdown","d500e5df":"markdown","32168815":"markdown","da5712a9":"markdown","8a72a208":"markdown"},"source":{"bcb3f17e":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import activations,callbacks\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\n\nfrom keras.layers import Dense, Flatten, Conv1D,MaxPooling1D, Dropout,BatchNormalization,Embedding,Concatenate, Input\nfrom keras.models import Model","383c4e01":"train = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv')","2dfac09f":"!pip install git+https:\/\/github.com\/Lpourchot\/dfencoding.git","dd233885":"from dfencoding import utilities","dede431c":"train_dum = train.copy() # need to change type in string \ntest_dum = test.copy()","5f7b5fbe":"train_dum = train_dum.iloc[:,1:].astype('str')\ntest_dum = test_dum.iloc[:,1:].astype('str')","e5c29885":"dfe = utilities.dfencoding(train_dum,'target',test_dum, missing_value = 'Y', cat_limit = 150, dummies_limit = 150)","6fc6dff7":"X = dfe.data.iloc[:len(train),:-1].astype('float')\ntest = dfe.data.iloc[len(train):,:-1].astype('float')\nX.shape, test.shape","c5607b1a":"dfe.get_dummies()","51e5b57f":"X_Onehot = dfe.data.iloc[:len(train_dum),1:]\ntest_Onehot = dfe.data.iloc[len(train_dum):,1:]\nprint(X_Onehot.shape)\nprint(test_Onehot.shape)","16b16914":"target = pd.get_dummies(train['target']).astype('float')\ny = train['target']","0f398cb2":"# To avoid negative values (for embedding), we just add 8 to all categories :\nX = X + 8\ntest = test + 8\nX.shape, test.shape, y.shape, target.shape","79ac22e3":"es = callbacks.EarlyStopping(\n                monitor = 'val_categorical_crossentropy', \n                min_delta = 0.0000001, \n                patience = 3,\n                mode = 'min',\n                baseline = None, \n                restore_best_weights = True,\n                verbose = 1)\n\nplateau  = callbacks.ReduceLROnPlateau(\n                monitor = 'val_categorical_crossentropy',\n                factor = 0.5, \n                patience = 2, \n                mode = 'min', \n                min_delt = 0.0000001,\n                cooldown = 0, \n                min_lr = 1e-7,\n                verbose = 1) \n\nmetrics = [tf.keras.metrics.CategoricalCrossentropy()]\nloss = tf.keras.losses.CategoricalCrossentropy(\n                from_logits=False,\n                label_smoothing=0,\n                reduction=\"auto\",\n                name=\"categorical_crossentropy\")\n","71a6c88d":"def api_onehot():\n    inputs_Onehot = layers.Input(shape = (1285,))\n    w = layers.Dense(40, activation=\"relu\")(inputs_Onehot)\n    w = layers.Dropout(0.3)(w)\n    \n    outputs_Onehot = layers.Dense(20, activation = \"relu\")(w)\n    \n    return  outputs_Onehot,inputs_Onehot","c0095b3b":"def api_embedding_row():\n    inputs_Embedding_row = layers.Input(shape = (50,))\n    x = layers.Embedding(80, 10, input_length = 50)(inputs_Embedding_row)\n    x = layers.Flatten()(x)\n    x = layers.Dense(40, activation = 'relu')(x)\n    x = layers.Dropout(0.3)(x)\n\n    \n    outputs_Embedding_row = layers.Dense(20, activation='relu')(x)\n    \n    return outputs_Embedding_row,inputs_Embedding_row","78100b30":"def api_conv1D():\n    inputs_Conv1D = layers.Input(shape=(50,1)) \n    v = layers.Conv1D(\n                filters = 256, \n                kernel_size = 4,\n                padding = 'same', \n                activation = 'relu',\n                )(inputs_Conv1D)\n\n    v = layers.MaxPooling1D(pool_size = 3)(v)\n    v = layers.Flatten()(v)\n    v = layers.Dropout(0.3)(v)\n\n\n    outputs_Conv1D = layers.Dense(20, activation = 'relu')(v)\n    \n    return outputs_Conv1D,inputs_Conv1D","9ce2eb54":"def api_embedding_col():    \n    inputs_Embedding_col = layers.Input(shape = (50,))\n    a = layers.Reshape((-1,1))(inputs_Embedding_col)\n    a = layers.Embedding(80, 10,input_length = 128)(a)\n    a = layers.Flatten()(a)\n    a = layers.Dense(40, activation='relu')(a)\n    a = layers.Dropout(0.3)(a)\n\n\n    outputs_Embedding_col = layers.Dense(20, activation = 'relu')(a)\n\n    return outputs_Embedding_col,inputs_Embedding_col","9fa32936":"def api_seq():    \n    inputs_seq = layers.Input(shape = (50,))\n    b = layers.Dense(40, activation=\"relu\")(inputs_seq)\n    b = layers.Dropout(0.3)(b)\n        \n    outputs_seq  = layers.Dense(20, activation = 'relu')(b)\n\n    return outputs_seq ,inputs_seq ","7554d097":"N_FOLDS = 10\nSEED = 2021\noof = np.zeros((X.shape[0],4))\npred = np.zeros((test.shape[0],4))\n\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n\nfor fold, (tr_idx, ts_idx) in enumerate(skf.split(X, y)):\n    print(f\"===== FOLD {fold} =====\")\n       \n    x_tr = X.iloc[tr_idx] \n    x_Onehot_tr = X_Onehot.iloc[tr_idx]\n    y_tr = target.iloc[tr_idx] \n    x_ts = X.iloc[ts_idx] \n    x_Onehot_ts = X_Onehot.iloc[ts_idx] \n    y_ts = target.iloc[ts_idx] \n    \n    #---------- Base models collection ---------------------\n    \n    outputs_Onehot,inputs_Onehot = api_onehot()\n    outputs_Embedding_row,inputs_Embedding_row = api_embedding_row()\n    outputs_Conv1D,inputs_Conv1D = api_conv1D()\n    outputs_Embedding_col, inputs_Embedding_col = api_embedding_col()\n    outputs_seq ,inputs_seq = api_seq()\n    \n   #---------- Final Model Layers --------------------------  \n        \n    z = layers.Concatenate(axis=1)(\n                    [\n                    outputs_Onehot,\n                    outputs_Embedding_row,\n                    outputs_Conv1D,                \n                    outputs_Embedding_col,\n                    outputs_seq])\n    \n    z = layers.Dense(20, activation = 'sigmoid')(z)\n    out = layers.Dense(4, activation = 'softmax', name = 'out')(z)\n    \n    #----------Model creation---------------------------\n    \n    model_merged = Model(inputs=[\n                    inputs_Onehot,\n                    inputs_Embedding_row,\n                    inputs_Conv1D,                \n                    inputs_Embedding_col,\n                    inputs_seq,\n                    ],outputs=out,\n                    name=\"model_merged\")\n    \n    #----------Model compile--------------------------- \n    \n    model_merged.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),\n                    loss = loss ,\n                    metrics = metrics)\n\n    #----------Model fit--------------------------- \n    \n    model_merged.fit([\n                    x_Onehot_tr,\n                     x_tr,\n                     x_tr,\n                     x_tr,\n                     x_tr,\n                     ],\n                    y_tr,\n                    validation_data = ([\n                    x_Onehot_ts,\n                    x_ts,\n                    x_ts,\n                    x_ts,\n                    x_ts,\n                    ],y_ts),\n                    batch_size = 256,\n                    epochs = 40,\n                    verbose = 1,\n                    callbacks = [es,plateau]\n                    )\n    \n    #----------Model prediction--------------------------- \n    \n    oof[ts_idx] = model_merged.predict([\n                    x_Onehot_ts,\n                    x_ts,\n                    x_ts,\n                    x_ts,\n                    x_ts,\n                    ])\n\n    score = log_loss(y_ts, oof[ts_idx])\n    print(f\"FOLD {fold} Score {score}\\n\")\n    \n    pred += model_merged.predict([\n                    test_Onehot,\n                    test,\n                    test,\n                    test,\n                    test,\n                    ]) \/ N_FOLDS\n\nscore = log_loss(target, oof)\nprint(f\"Score total {score}\\n\")   ","20d862ee":"submission = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/sample_submission.csv')","08551caf":"submission_df = pd.DataFrame(pred)\nsubmission_df.columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4']\nsubmission_df['id'] = submission['id']\nsubmission_df = submission_df[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4']]\nsubmission_df.to_csv(\"submission_Keras_18.csv\", index=False)\ndisplay(submission_df.head())","6a3b63c9":"<h3> Column Embedding Model","a38cb84d":"<h2> Base models : Row Embedding + Column Emedding + Conv1D + Onehot","ba3a169b":"<h3> Data for OneHot Models","dfda7e58":"<h3> Data for others Models","c468bfc4":"<h3> Row Embedding Model","0b2ae38f":"<h3> OneHot Model","d500e5df":"<h2> Basic data cooking","32168815":"<h3> Parameters for the training","da5712a9":"<h3> Conv1D Model","8a72a208":"<h3> Sequential Model"}}