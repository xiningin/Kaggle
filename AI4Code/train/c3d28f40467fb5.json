{"cell_type":{"853d92b2":"code","5458cdf9":"code","ad294e51":"code","783aeefe":"code","752ebb95":"code","a43c6a21":"code","5d47d85b":"code","4e019425":"code","9c18579f":"code","6b49512a":"code","eb56c5eb":"code","b29b9364":"code","7c9e7366":"code","0d85d159":"code","8a29bd23":"code","77d7a361":"code","ea95c5ad":"code","138d7ff4":"code","29da3b2b":"code","ff2e7682":"code","5eb79ba1":"code","e05b1060":"code","8c8c44a4":"code","55455beb":"markdown","dcc718d0":"markdown","2af40cd9":"markdown","96d8cf28":"markdown","a58a0e3a":"markdown","22b497d2":"markdown","1931687b":"markdown","45b23125":"markdown","d4e13b5a":"markdown"},"source":{"853d92b2":"from __future__ import print_function, division\nfrom builtins import range, input\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import confusion_matrix, roc_curve\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom glob import glob\nimport pandas as pd","5458cdf9":"dataset = '..\/input\/covid19-chest-xray-dataset'","ad294e51":"#define size to which images are to be resized\nIMAGE_SIZE = [224, 224] # feel free to change depending on dataset\n\n# training config:\nepochs = 500\nbatch_size = 32\n\n#define paths\ncovid_path = '..\/input\/covid19-chest-xray-dataset\/Chest_COVID'\nnoncovid_path = '..\/input\/covid19-chest-xray-dataset\/Chest_NonCOVID'\n\n# Use glob to grab images from path .jpg or jpeg\ncovid_files = glob(covid_path + '\/*')\nnoncovid_files = glob(noncovid_path + '\/*')","783aeefe":"# Preparing Labels\ncovid_labels = []\nnoncovid_labels = []\n\ncovid_images=[]\nnoncovid_images=[]\n\nimport cv2 \n\nfor i in range(len(covid_files)):\n  image = cv2.imread(covid_files[i])\n  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  image = cv2.resize(image,(224,224))\n  covid_images.append(image)\n  covid_labels.append('Chest_COVID')\nfor i in range(len(noncovid_files)):\n  image = cv2.imread(noncovid_files[i])\n  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n  image = cv2.resize(image,(224,224))\n  noncovid_images.append(image)\n  noncovid_labels.append('Chest_NonCOVID')","752ebb95":"# look at a random image for fun\ndef plot_images(images, title):\n    nrows, ncols = 5, 8\n    figsize = [10, 6]\n\n    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, facecolor=(1, 1, 1))\n\n    for i, axi in enumerate(ax.flat):\n        axi.imshow(images[i])\n        axi.set_axis_off()\n\n    plt.suptitle(title, fontsize=24)\n    plt.tight_layout(pad=0.2, rect=[0, 0, 1, 0.9])\n    plt.show()\nplot_images(covid_images, ' COVID-19 positive Chest X-ray')\nplot_images(noncovid_images, 'COVID-19 negative Chest X-ray')","a43c6a21":"# Convert to array and Normalize to interval of [0,1]\ncovid_images = np.array(covid_images) \/ 255\nnoncovid_images = np.array(noncovid_images) \/ 255","5d47d85b":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom tensorflow.keras.utils import to_categorical\n\n# split into training and testing\ncovid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(\n    covid_images, covid_labels, test_size=0.2)\nnoncovid_x_train, noncovid_x_test, noncovid_y_train, noncovid_y_test = train_test_split(\n    noncovid_images, noncovid_labels, test_size=0.2)\n\n\nX_train = np.concatenate((noncovid_x_train, covid_x_train), axis=0)\nX_test = np.concatenate((noncovid_x_test, covid_x_test), axis=0)\ny_train = np.concatenate((noncovid_y_train, covid_y_train), axis=0)\ny_test = np.concatenate((noncovid_y_test, covid_y_test), axis=0)\n\n# make labels into categories - either 0 or 1\ny_train = LabelBinarizer().fit_transform(y_train)\ny_train = to_categorical(y_train)\n\ny_test = LabelBinarizer().fit_transform(y_test)\ny_test = to_categorical(y_test)","4e019425":"plot_images(covid_x_train, 'X_train')\nplot_images(covid_x_test, 'X_test')\n# y_train and y_test contain class lables 0 and 1 representing COVID and NonCOVID for X_train and X_test","9c18579f":"vggModel = VGG19(weights=\"imagenet\", include_top=False,\n    input_tensor=Input(shape=(224, 224, 3)))\n\noutputs = vggModel.output\noutputs = Flatten(name=\"flatten\")(outputs)\noutputs = Dropout(0.5)(outputs)\noutputs = Dense(2, activation=\"softmax\")(outputs)\n\nmodel = Model(inputs=vggModel.input, outputs=outputs)\n\nfor layer in vggModel.layers:\n    layer.trainable = False\n\nmodel.compile(\n        loss='categorical_crossentropy', \n        optimizer='adam', \n        metrics=['accuracy']\n)","6b49512a":"model.summary()","eb56c5eb":"train_aug = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True\n)","b29b9364":"history = model.fit(train_aug.flow(X_train, y_train, batch_size=32),\n                    validation_data=(X_test, y_test),\n                    validation_steps=len(X_test) \/ 32,\n                    steps_per_epoch=len(X_train) \/ 32,\n                    epochs=500)","7c9e7366":"model.save('vgg_chest.h5')","0d85d159":"model.save_weights('vggweights_chest.hdf5')","8a29bd23":"model = load_model('vgg_chest.h5')","77d7a361":"y_pred = model.predict(X_test, batch_size=batch_size)","ea95c5ad":"prediction=y_pred[0:10]\nfor index, probability in enumerate(prediction):\n  if probability[1] > 0.5:\n        plt.title('%.2f' % (probability[1]*100) + '% COVID')\n  else:\n        plt.title('%.2f' % ((1-probability[1])*100) + '% NonCOVID')\n  plt.imshow(X_test[index])\n  plt.show()\n","138d7ff4":"# Convert to Binary classes\ny_pred_bin = np.argmax(y_pred, axis=1)\ny_test_bin = np.argmax(y_test, axis=1)","29da3b2b":"fpr, tpr, thresholds = roc_curve(y_test_bin, y_pred_bin)\nplt.plot(fpr, tpr,linewidth=2)\nplt.plot([0,1],[0,1],'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for our model')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","ff2e7682":"\ndef plot_confusion_matrix(normalize):\n  classes = ['COVID','NonCOVID']\n  tick_marks = [0.5,1.5]\n  cn = confusion_matrix(y_test_bin, y_pred_bin,normalize=normalize)\n  sns.heatmap(cn,cmap=plt.cm.Blues,annot=True)\n  plt.xticks(tick_marks, classes)\n  plt.yticks(tick_marks, classes)\n  plt.title('Confusion Matrix')\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n  plt.show()\n\nprint('Confusion Matrix without Normalization')\nplot_confusion_matrix(normalize=None)\n\nprint('Confusion Matrix with Normalized Values')\nplot_confusion_matrix(normalize='true')","5eb79ba1":"from sklearn.metrics import classification_report\nprint(classification_report(y_test_bin, y_pred_bin))","e05b1060":"plt.figure(figsize=(12,12))\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\n\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\n\nplt.legend(['Training', 'Testing'],loc='upper left')\nplt.savefig('inception_chest_accuracy.png')\nplt.show()","8c8c44a4":"plt.figure(figsize=(12,12))\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\n\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\n\nplt.legend(['Training', 'Testing'],loc='upper left')\nplt.savefig('inception_chest_loss.png')\nplt.show()","55455beb":"**Visualize First 40 Images from Data set**","dcc718d0":"**Classification Report**","2af40cd9":"**Making Predictions**","96d8cf28":"**Define few parameters**","a58a0e3a":"**Accuracy and Loss plot**","22b497d2":"**Visualising 10 Predictions**","1931687b":"**Fetch Images and Class Labels from Files**","45b23125":"**Plot ROC Curve**","d4e13b5a":"**Plot confusion matrix**"}}