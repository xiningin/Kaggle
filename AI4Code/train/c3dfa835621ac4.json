{"cell_type":{"810b3942":"code","a8a765fc":"code","1863faea":"code","7b6ba782":"code","04cc86ed":"code","25438989":"code","6d0dcb3f":"code","133c8ba0":"code","4e1a2135":"code","020a931c":"markdown","d23117a2":"markdown","02bfef6f":"markdown","2853f5e3":"markdown","9e79e54d":"markdown","3a86bcaa":"markdown","9b7e9763":"markdown","1556abb0":"markdown"},"source":{"810b3942":"#               0        1       2      3        4         5       6         7         8        9\ncolor_codes = ['k',     'b',    'r',   'g',     'y',      'e',    'p',      'o',      'z',     'n']\ncolor_names = ['black', 'blue', 'red', 'green', 'yellow', 'grey', 'purple', 'orange', 'azure', 'brown']","a8a765fc":"import ipywidgets as widgets\nfrom ipywidgets import interact, interact_manual, Layout\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib import colors, animation\n\nfrom IPython.display import HTML\n\nimport numpy as np\n\nfrom itertools import product\n\nimport os\nimport json\n\n!jupyter nbextension enable --py widgetsnbextension\n\nroot_dir = '\/kaggle\/input\/abstraction-and-reasoning-challenge'\ntraining_files = sorted(os.listdir(f\"{root_dir}\/training\/\"))\nevaluation_files = sorted(os.listdir(f\"{root_dir}\/evaluation\/\"))\ntest_files = sorted(os.listdir(f\"{root_dir}\/test\/\"))","1863faea":"arc_colors =  ['#000000', \"#0074D9\", \"#FF4136\", \"#2ECC40\", '#FFDC00', \"#AAAAAA\", '#F012BE', '#FF851B', '#7FDBFF', \"#870C25\"]\n# dark_colors are just a \"darker\" version of arc_colors (30% percent) to display as \"background\"\ndark_colors = ['#000000', '#002241', '#4c1310', '#0d3d13', '#4c4200', '#333333', '#480539', '#4c2708', '#26414c', '#28030b']\ncmap = colors.ListedColormap(arc_colors)\ndark_cmap = colors.ListedColormap(dark_colors)\nnorm = colors.Normalize(vmin=0, vmax=9)\n\ndef load_data(path):\n    with open(path) as file:\n        data = json.load(file)\n    return data\n\n# method called by the interact cell\ndef plot_data(path):\n    data = load_data(path)\n        \n    n_train = len(data['train'])\n    fig, axs = plt.subplots(2, n_train+1, figsize=(8,4))\n    \n    for x in axs:\n        for y in x:    \n            y.grid(b=True)\n            y.tick_params(direction='out', length=0, width=0, colors='r',\n                          labelsize=0, grid_color='w', grid_alpha=0.5)\n\n    for i in range(0, n_train): \n        # Train Input\n        axs[0,i].imshow(data['train'][i]['input'], cmap=cmap, norm=norm)\n        # To fix misalignment of grid and image caused by the pixel snapping issue in matplotlib\n        axs[0,i].set_xticks(np.array(range(len(data['train'][i]['input'][0])))-0.5)\n        axs[0,i].set_yticks(np.array(range(len(data['train'][i]['input'])))-0.5)\n        # Train Output\n        axs[1,i].imshow(data['train'][i]['output'], cmap=cmap, norm=norm)\n        axs[1,i].set_xticks(np.array(range(len(data['train'][i]['output'][0])))-0.5)\n        axs[1,i].set_yticks(np.array(range(len(data['train'][i]['output'])))-0.5)\n    # Test Input\n    axs[0,n_train].imshow(data['test'][0]['input'], cmap=cmap, norm=norm)\n    axs[0,n_train].set_xticks(np.array(range(len(data['test'][0]['input'][0])))-0.5)\n    axs[0,n_train].set_yticks(np.array(range(len(data['test'][0]['input'])))-0.5)\n    # Test output\n    axs[1,n_train].imshow(data['test'][0]['output'], cmap=cmap, norm=norm)\n    axs[1,n_train].set_xticks(np.array(range(len(data['test'][0]['output'][0])))-0.5)\n    axs[1,n_train].set_yticks(np.array(range(len(data['test'][0]['output'])))-0.5)\n\n    # separator\n    axs[0,n_train].plot([-0.1, -0.1], [0,1], color='grey', lw=3, transform=axs[0,n_train].transAxes, clip_on=False)\n    axs[1,n_train].plot([-0.1, -0.1], [0,1], color='grey', lw=3, transform=axs[1,n_train].transAxes, clip_on=False)\n\n    axs[0,0].set_ylabel('input')\n    axs[1,0].set_ylabel('output')\n    \n    plt.show()","7b6ba782":"OUT_OF_BORDER = '#'\nWILD_CARD = '.'\nca_dtype = np.dtype('<U1')\n\nclass FilterBase(object):\n\n    def match(self, feature):    \n        raise NotImplementedError('')\n\n    def shape(self):\n        raise NotImplementedError('')\n    \nclass FixedFilter(FilterBase):\n    \n    def __init__(self, filt):\n        self._filter = np.array(filt, dtype=ca_dtype)\n        self._valid_pos = self._filter != WILD_CARD\n        self._valid_filt = self._filter[self._valid_pos]\n    \n    def __repr__(self):\n        return 'I(' + repr(self._filter) + ')'\n    \n    def shape(self):\n        return self._filter.shape\n    \n    def match(self, feature):\n        if feature.shape != self._filter.shape:\n            raise ValueError('filter and feature size dont match: {}, {}'.format(self._filter.shape, feature.shape))\n        return np.all(feature[self._valid_pos] == self._valid_filt)\n\ndef cal_hist(arr):\n    val, cnt = np.unique(arr, return_counts=True)\n    hist = dict(zip(val, cnt))\n    #print('hist', filt, hist)\n    return hist\n\nclass HistFilter(FilterBase):\n    \n    def __init__(self, filt):\n        self._filter = np.array(filt, dtype=ca_dtype)\n        w, h = self._filter.shape\n        self._hist = self._cal_hist(self._filter)\n        if WILD_CARD in self._hist:\n            del self._hist[WILD_CARD]\n        \n    def _cal_hist(self, filt):\n        return cal_hist(filt)\n    \n    def __repr__(self):\n        return 'H(' + repr(self._hist) + ')'\n    \n    def shape(self):\n        return self._filter.shape\n    \n    def match(self, feature):\n        fhist = self._cal_hist(feature)\n        #print('hist filter', self._hist, fhist)\n        for k, v in self._hist.items():\n            if k not in fhist or fhist[k] < v:\n                return False\n        return True\n\nclass NeighHistFilter(HistFilter):\n    \n    def __init__(self, filt):\n        w = len(filt[0])\n        h = len(filt)\n        #print(w, h)\n        self._center_x = w \/\/ 2\n        self._center_y = h \/\/ 2\n        super().__init__(filt)\n        self._c = self._filter[self._center_x, self._center_y]\n        if self._c != WILD_CARD and self._hist[self._c] == 0:\n            del self._hist[self._c]\n        \n    def _cal_hist(self, filt):\n        hist = cal_hist(filt)\n        #print(hist)\n        c = filt[self._center_x, self._center_y]\n        hist[c] -= 1\n        #print(hist)\n        return hist\n\n    def __repr__(self):\n        return 'HN(hist=' + repr(self._hist) + ', center=' + repr(self._c) + ')'\n    \n    def match(self, feature):\n        c = feature[self._center_x, self._center_y]\n        if self._c == WILD_CARD or self._c == c:\n            return super().match(feature)\n        return False\n\nclass DirectNeighHistFilter(HistFilter):\n    \n    def __init__(self, filt):\n        w = len(filt[0])\n        h = len(filt)\n        #print(w, h)\n        self._center_x = xc = w \/\/ 2\n        self._center_y = yc = h \/\/ 2\n        self._pos = [(xc + dx, yc + dy) for dx, dy in \\\n                     [(-1, 0), (1, 0), (0, -1), (0, 1)]]\n        self._bool_idx = np.zeros((3, 3), dtype=bool)\n        for i, j in self._pos:\n            self._bool_idx[i, j] = True\n        #print(self._bool_idx)\n        super().__init__(filt)\n        self._c = self._filter[self._center_x, self._center_y]\n        \n    def _cal_hist(self, filt):\n        vals = cal_hist(filt[self._bool_idx])\n        return vals\n\n    def __repr__(self):\n        return 'HD(hist=' + repr(self._hist) + ', center=' + repr(self._c) + ')'\n    \n    def match(self, feature):\n        c = feature[self._center_x, self._center_y]\n        if self._c == WILD_CARD or self._c == c:\n            return super().match(feature)\n        return False\n\ndef iter_array_indices(arr):\n    h, w = arr.shape\n    return product(range(h), range(w))\n    \ndef get_array_indices(arr):\n    return list(iter_array_indices(arr))\n\ndef reshape_like(arr1d, ref):\n    return arr1d.reshape(ref.shape)\n\ndef get_array_indices_2d(arr):\n    h, w = arr.shape\n    idx = []\n    for i in range(h):\n        idx.append([(i, j) for j in range(w)])\n    idx = np.array(idx, dtype=np.int)\n    #print('index of array: ', arr, idx)\n    return idx\n\ndef coord_rotate_right_90(x, y):\n    return -y, x\ndef coord_rotate_left_90(x, y):\n    return y, -x\ndef coord_rotate_180(x, y):\n    return -x, -y\ndef coord_rotate_right_45(x, y):\n    if x == y:\n        return 0, y\n    elif x == -y:\n        return x, 0\n    elif x == 0:\n        return -y, y\n    elif y == 0:\n        return x, x\ndef coord_rotate_left_45(x, y):\n    if x == y:\n        return x, 0\n    elif x == -y:\n        return 0, y\n    elif x == 0:\n        return y, y\n    elif y == 0:\n        return x, -x\ndef coord_flip_horiz(x, y):\n    return -x, y\ndef coord_flip_verti(x, y):\n    return x, -y\ndef coord_flip_diag(x, y):\n    return y, x\ndef coord_flip_anti_diag(x, y):\n    return -y, -x\n\ndef trans_array(arr, coord_target):\n    h, w = arr.shape\n    if h != 3 or w != 3:\n        raise ValueError('only support 3x3 array at this point')\n    ret = np.zeros_like(arr)\n    ci, cj = h \/\/ 2, w \/\/ 2  # center point\n    rh, rw = ci, cj\n    for y, x in product(range(-rh, rh+1), range(-rw, rw+1)):\n        i, j = ci + y, cj + x\n        dst_x, dst_y = coord_target(x, y)\n        dst_i, dst_j = ci + dst_y, cj + dst_x\n        #i, j, dst_i, dst_j = i\/\/2, j\/\/2, dst_i\/\/2, dst_j\/\/2\n        #print(x, y, ' --> ', dst_x, dst_y, ' | ', i, j, ' --> ', dst_i, dst_j)\n        ret[dst_i, dst_j] = arr[i, j]\n    return ret\n\nrotate_right_45 = lambda a: trans_array(a, coord_rotate_right_45)\nrotate_left_45 = lambda a: trans_array(a, coord_rotate_left_45)\nrotate_right_90 = lambda a: trans_array(a, coord_rotate_right_90)\nrotate_left_90 = lambda a: trans_array(a, coord_rotate_left_90)\nrotate_180 = lambda a: trans_array(a, coord_rotate_180)\nflip_horiz = lambda a: trans_array(a, coord_flip_horiz)\nflip_verti = lambda a: trans_array(a, coord_flip_verti)\nflip_diag = lambda a: trans_array(a, coord_flip_diag)\nflip_anti_diag = lambda a: trans_array(a, coord_flip_anti_diag)\n\ndef trans_iter(trans, flip=False):\n    def _iter(arr):\n        seeds = [arr]\n\n        if flip:\n            ff = flip_diag(arr)\n            # if array is symmetric, the flipped array and all its rotations \n            # will be included in the rotations of the array itself.\n            if np.any(ff != arr) and np.any(arr != flip_horiz(arr)) \\\n                    and np.any(arr != flip_verti(arr)) \\\n                    and np.any(arr != flip_anti_diag(arr)):\n                seeds.append(ff)\n\n        #print('seeds', seeds)\n        for seed in seeds:\n            t = seed\n            while True:\n                yield t\n                t = trans(t)\n                if any(np.all(t == s) for s in seeds):\n                    break\n    return _iter\n\na = np.arange(9).reshape((3,3))\na = np.array([[0, 1, 2], [3, 5, 3], [2, 1, 0]])\na = np.array([[2, 1, 2], [3, 5, 3], [1, 4, 1]])\n#a = np.array([[0, 1, 0], [1, 5, 1], [0, 1, 0]])\nprint(a)\n# print(rotate_right_45(a))\n# print(rotate_left_45(a))\n# print(rotate_right_90(a))\n# print(rotate_left_90(a))\n# print(rotate_180(a))\n# print(flip_horiz(a))\n# print(flip_verti(a))\n# print(flip_diag(a))\n# print(flip_anti_diag(a))\n\n# print(list(trans_iter(rotate_right_45)(a)))\n# print(list(trans_iter(rotate_left_45)(a)))\n# print(list(trans_iter(rotate_right_45, flip=True)(a)))\n# print(list(trans_iter(rotate_left_45, flip=True)(a)))\n# print(list(trans_iter(flip_horiz, True)(a)))\n\nclass TransFilter(FilterBase):\n    def __init__(self, filt, trans_iter):\n        self._filter = self._filter = np.array(filt, dtype=ca_dtype)\n        self._trans_iter = trans_iter\n        self._equivs = self._cal_equivs(self._filter)\n        self._equivs_pos = [e != WILD_CARD for e in self._equivs]\n        self._equivs_to_compare = [e[p] for e, p in zip(self._equivs, self._equivs_pos)]\n    \n    def _cal_equivs(self, filt):\n        idx_list = list(self._trans_iter(filt))\n        return idx_list\n    \n    def shape(self):\n        return self._filter.shape\n    \n    def match(self, feature):\n        for eq, pos in zip(self._equivs_to_compare, self._equivs_pos):\n            feat_to_compare = feature[pos]\n            #print('compare', eq, feat_to_compare, 'pos')\n            #print(pos)\n            if np.all(eq == feat_to_compare):\n                return True\n            #print('not equal')\n        return False\n        \n    def __repr__(self):\n        return 'TF(' + repr(self._equivs) + ')'\n\ndef create_filter(filt_type, filt):\n    try:\n        filt = np.array(filt, dtype=ca_dtype)\n    except:\n        print('invalid filter: ' + repr(filt))\n        raise\n        \n    if filt_type == 'I':\n        return FixedFilter(filt)\n    elif filt_type == 'H':\n        return HistFilter(filt)\n    elif filt_type == 'HN':\n        return NeighHistFilter(filt)\n    elif filt_type == 'HD':\n        return DirectNeighHistFilter(filt)\n    elif filt_type == 'R8':\n        return TransFilter(filt, trans_iter(rotate_right_45, flip=False))\n    elif filt_type == 'R4':\n        return TransFilter(filt, trans_iter(rotate_right_90, flip=False))\n    elif filt_type == 'R2':\n        return TransFilter(filt, trans_iter(rotate_180, flip=False))\n    elif filt_type == 'L8':\n        return TransFilter(filt, trans_iter(rotate_left_45, flip=False))\n    elif filt_type == 'L4':\n        return TransFilter(filt, trans_iter(rotate_left_90, flip=False))\n    elif filt_type == 'L2':\n        return TransFilter(filt, trans_iter(rotate_180, flip=False))\n    elif filt_type == 'R8F':\n        return TransFilter(filt, trans_iter(rotate_right_45, flip=True))\n    elif filt_type == 'R4F':\n        return TransFilter(filt, trans_iter(rotate_right_90, flip=True))\n    elif filt_type == 'R2F':\n        return TransFilter(filt, trans_iter(rotate_180, flip=True))\n    elif filt_type == 'L8F':\n        return TransFilter(filt, trans_iter(rotate_left_45, flip=True))\n    elif filt_type == 'L4F':\n        return TransFilter(filt, trans_iter(rotate_left_90, flip=True))\n    elif filt_type == 'L2F':\n        return TransFilter(filt, trans_iter(rotate_180, flip=True))\n    elif filt_type == 'FH':\n        return TransFilter(filt, trans_iter(flip_horiz))\n    elif filt_type == 'FV':\n        return TransFilter(filt, trans_iter(flip_verti))\n    elif filt_type == 'FD':\n        return TransFilter(filt, trans_iter(flip_diag))\n    elif filt_type == 'FA':\n        return TransFilter(filt, trans_iter(flip_anti_diag))\n    else:\n        raise ArgumentError('unknown filter type ' + filt_type)\n\n# filt = np.array([[0, '1', 0], ['1', '#', '1'], ['.', '.', '.']], dtype=ca_dtype)\n# filt = np.array([[0, '.', 0], ['.', '0', '.'], ['.', '.', '#']], dtype=ca_dtype)\nfilt = np.array([['.', '.', 0], ['.', '0', '.'], ['#', '.', '0']], dtype=ca_dtype)\n# filt = np.array([[0, '#', 1], ['2', '0', '#'], [2, 1, 0]], dtype=ca_dtype)\nprint(filt)\nff = create_filter('I', filt)\nhf = create_filter('HN', filt)\ndf = create_filter('HD', filt)\nr4 = create_filter('R4', filt)\nprint(r4)\nfeat1 = np.array([[0, 1, 0], ['a', '#', 0], [1, 1, 1]], dtype=ca_dtype)\nfeat2 = np.array([[0, '#', 0], ['#', '0', 1], [0, 2, '#']], dtype=ca_dtype)\nprint(feat1)\nprint(ff.match(feat1))\nprint(hf.match(feat1))\nprint(df.match(feat1))\nprint(feat2)\nprint(ff.match(feat2))\nprint(hf.match(feat2))\nprint(df.match(feat2))\nprint(r4.match(feat2))","04cc86ed":"mem_dtype = np.int\n\ndef chunk_list(lst, sep, remove_empty=True):\n    ck = []\n    for e in lst:\n        if sep(e):\n            if not remove_empty or len(ck) > 0:\n                yield ck\n            ck = []\n        else:\n            ck.append(e)\n    if not remove_empty or len(ck) > 0:\n        yield ck\n    \ndef remove_invalid(lines):\n    return (x for x in \\\n                (line.strip() for line in lines) \\\n                if len(x) > 0)\n\ncolor_code_mapping = { c:str(i) for i, c in enumerate(color_codes) }\n\ndef parse_elem(x):\n    x = x.strip()\n    return color_code_mapping.get(x, x)\n\ndef parse_mem_elem(x):\n    return int(x)\n\nclass CABase(object):\n    \n    def __init__(self):\n        self.reset_memory()\n    \n    def reset_memory(self):\n        self._memory = None\n    \n    def extract(self, state, i, j):\n        pass\n    def apply(self, feature, memory):\n        pass\n    \n    def run(self, state, n_iter=10):\n        s = state\n        for i in n_iter:\n            s = self.step(s)\n        return s\n\n    def step(self, state):\n        if self._memory is None:\n            self._memory = np.zeros_like(state, dtype=mem_dtype)\n        new_state, self._memory = self._step(state, self._memory)\n        return new_state\n\n    def updates(self, state, memory):\n        w, h = state.shape\n        for i in range(w):\n            for j in range(h):\n                ns = self.extract(state, i, j)\n                ret = self.apply(ns, memory[i, j])\n                if ret is not None:\n                    yield i, j, ret[0], ret[1]\n        \n    def _step(self, state, memory):\n        #print(state, memory)\n        w, h = state.shape\n        new_state = np.array(state, dtype=ca_dtype)\n        new_memory = np.array(memory, dtype=mem_dtype)\n        for i, j, s, m in self.updates(state, memory):\n            new_state[i, j] = s\n            new_memory[i, j] = m\n        return new_state, new_memory\n\nclass CALambda(CABase):\n    def __init__(self, extract, apply):\n        super().__init__()\n        self._extract = extract\n        self._apply = apply\n        \n    def extract(self, state, i, j):\n        return self._extract(state, i, j)\n    \n    def apply(self, feature, memory):\n        return self._apply(feature, memory)\n    \nclass CAFilter(CABase):\n    def __init__(self, filt, out, mem_in=None, mem_out=None):\n        super().__init__()\n        self._filter = filt\n        self._out = out\n        self._mem_in = mem_in\n        self._mem_out = mem_out\n        self._w, self._h = self._filter.shape()\n        self._feat_center_x = self._w \/\/ 2\n        self._feat_center_y = self._h \/\/ 2\n        \n    def __repr__(self):\n        return repr([self._filter, ', mem_in=' + repr(self._mem_in), \\\n                ' -> out=' + repr(self._out), ', mem_out=' + repr(self._mem_out)])\n    \n    def shape(self):\n        return self._filter.shape()\n    \n    def extract(self, state, i, j):\n        feat = np.zeros(self._filter.shape(), dtype=ca_dtype)\n        w, h = state.shape\n        for xf in range(self._w):\n            for yf in range(self._h):\n                xs = i - (self._feat_center_x - xf)\n                ys = j - (self._feat_center_y - yf)\n                #print(xf, yf, '-->', xs, ys)\n                if xs >= 0 and xs < w and ys >= 0 and ys < h:\n                    feat[xf, yf] = state[xs, ys]\n                else:\n                    feat[xf, yf] = OUT_OF_BORDER\n        #print('feature at ', i, j, ':', feat)\n        return feat\n    \n    def apply(self, feature, memory):\n        #print(feature, memory)\n        #print(self._valid_pos)\n        #print(self._valid_filt)\n        if self._filter.match(feature) \\\n                and (self._mem_in is None or self._mem_in == memory):\n            out = feature[self._feat_center_x, self._feat_center_y] if self._out == WILD_CARD else self._out\n            mem_out = memory if self._mem_out is None else self._mem_out\n            return out, mem_out\n        return None\n    \n    @staticmethod\n    def parse_lines(lines):\n        #print(lines)\n        if len(lines) == 3:\n            filt = []\n            filt.append([parse_elem(i) for i in lines[0].strip().split()])\n            \n            # middle line contains condition on memory and the output\n            filt_type = 'I'\n            tmp = lines[1].split(']')\n            if len(tmp) == 2 and tmp[0].strip().startswith('['):\n                filt_type = tmp[0].strip()[1:]\n                ln = tmp[1]\n            elif len(tmp) == 1:\n                ln = tmp[0]\n            else:\n                raise ValueError('invalid line: ' + lines[1])\n                \n            mem_in = mem_out = None\n            in_txt, out_txt = ln.split('->')\n            tmp = in_txt.split(',')\n            filt.append([parse_elem(i) for i in tmp[0].strip().split()])\n            if len(tmp) == 2:\n                mem_in = parse_mem_elem(tmp[1])\n            \n            tmp = out_txt.split(',')\n            out = parse_elem(tmp[0])\n            if len(tmp) == 2:\n                mem_out = parse_mem_elem(tmp[1])\n            \n            filt.append([parse_elem(i) for i in lines[2].strip().split()])\n            #print(filt)\n            filt_obj = create_filter(filt_type, filt)\n            #print(filt_obj)\n            return CAFilter(filt_obj, out, mem_in=mem_in, mem_out=mem_out)\n        else:\n            raise ValueError('invalid lines: ' + str(lines))\n\nclass CAMFilter(CABase):\n    def __init__(self):\n        super().__init__()\n        self._filters = []\n        self._applied_rules = None\n    \n    def add_filter(self, filt):\n        if len(self._filters) > 0 and self._filters[0].shape() != filt.shape():\n            raise ArgumentError('filters must be in the same size')\n        self._filters.append(filt)\n\n    def extract(self, state, i, j):\n        if len(self._filters) == 0:\n            return 0\n        if i == 0 and j == 0:\n            #print(repr(state))\n            self._applied_rules = np.ones_like(state, dtype=np.int) * -1\n        self._curr_pos = (i, j)\n        return self._filters[0].extract(state, i, j)\n    \n    def apply(self, feature, memory):\n        for i, f in enumerate(self._filters):\n            ret = f.apply(feature, memory)\n            if ret is not None:\n                #print('rule {} applied: {}'.format(i, f))\n                xx, yy = self._curr_pos\n                self._applied_rules[xx, yy] = i\n                return ret\n        #print('no rules applied at this point')\n        return None\n        \n    @staticmethod\n    def parse(txt):\n        mf = CAMFilter()\n        for ck in chunk_list(remove_invalid(txt.split('\\n')), lambda x: x.startswith('---')):\n            mf.add_filter(CAFilter.parse_lines(ck))\n        return mf\n\n    def __repr__(self):\n        return repr(self._filters)\n\n    def rule(self, i):\n        return self._filters[i]\n    \n        \nrule_txt = '''\n--- this is a comment\n--- rule 1\n     1 0 .\n[HN] 0 0 . -> 1\n     . . .\n------ rule 2\n--- . . .\n--- . 1 . -> 0\n--- . . .\n------ rule 3\n. . .\n. 1 ., 0 -> 1, 1\n. . .\n------ rule 4\n. . .\n. 1 ., 1 -> 0, 1\n. . .\n'''\n\nstate0 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nstate0 = np.array([[1, 0, 0], [0, 0, 0], [0, 0, 0]])\n\nr = CAMFilter.parse(rule_txt)\nprint(r)\njoin_rows = lambda a, n=10: ('\\n' + ' ' * n).join(str(x) for x in a)\nprint('state 0  ', join_rows(state0))\ns = state0\nfor i in range(1, 4):\n    print('-' * 10)\n    s = r.step(s)\n    print(f'state {i}  ', join_rows(s))\n    print(f'memory {i} ', join_rows(r._memory))\n    print('rules applied: ', join_rows(r._applied_rules, 16))\n","25438989":"%%capture\n%matplotlib inline\n\n# This is a separate part in which the plots are captured(not shown) \n# to avoid extra plotting in animation at next section\n\nfig_for_anim = plt.figure(figsize=(15,5))\naxs_for_anim = fig_for_anim.subplots(1, 3)\n","6d0dcb3f":"def plot_pair(img_pair):\n    fig, axs = plt.subplots(1, 2, figsize=(4,2))\n    \n    for ax in axs:\n        ax.grid(b=True)\n        ax.tick_params(direction='out', length=0, width=0, colors='r',\n                      labelsize=0, grid_color='w', grid_alpha=0.5)\n\n    # Train Input\n    iimg = img_pair['input']\n    #print(iimg)\n    #print(axs)\n    #print(axs[0, 0])\n    axs[0].imshow(iimg, cmap=cmap, norm=norm)\n    # To fix misalignment of grid and image caused by the pixel snapping issue in matplotlib\n    axs[0].set_title('input')\n    axs[0].set_xticks(np.array(range(len(iimg[0])))-0.5)\n    axs[0].set_yticks(np.array(range(len(iimg)))-0.5)\n    # Train Output\n    oimg = img_pair['output']\n    axs[1].imshow(oimg, cmap=cmap, norm=norm)\n    axs[1].set_title('output')\n    axs[1].set_xticks(np.array(range(len(oimg)))-0.5)\n    axs[1].set_yticks(np.array(range(len(oimg)))-0.5)\n\n    \ndef animate_data(data, ca, num_frames=10):\n    #n_train = len(data['train'])\n    img = np.array(data['input'])\n    \n    #fig, axs = plt.subplots(1, 2)\n    axs = axs_for_anim\n    mat_state = [0]\n    mat_memory = [0]\n    applied_rules = [0]\n    texts_memory = np.zeros_like(img, dtype=np.object)\n    texts_rules = np.zeros_like(img, dtype=np.object)\n    \n    def init():\n        print('generating animation: ', end='')\n        for ax in axs:\n            ax.clear()\n        \n        axs[0].set_title('state')\n        axs[1].set_title('memory')\n        axs[2].set_title('applied rules')\n\n        #mat = ax.imshow(data['train'][0]['input'], cmap=cmap, norm=norm)\n        mat_state[0] = axs[0].imshow(img, cmap=cmap, norm=norm)\n        mat_memory[0] = axs[1].imshow(img, cmap=dark_cmap, norm=norm)\n        for (i, j), z in np.ndenumerate(img):\n            texts_memory[i, j] = axs[1].text(j, i, '0', ha='center', va='center', color='gray', size='large')\n        applied_rules[0] = axs[2].imshow(np.zeros_like(img), cmap=dark_cmap, norm=norm)\n        for (i, j), z in np.ndenumerate(img):\n            texts_rules[i, j] = axs[2].text(j, i, '', ha='center', va='center', color='white', size='large')\n        \n        for ax in axs:\n            ax.set_xticks(np.array(range(len(img[0])))-0.5)\n            ax.set_yticks(np.array(range(len(img)))-0.5)\n            ax.grid(b=True)\n            ax.tick_params(direction='out', length=0, width=0, colors='r',\n                          labelsize=0, grid_color='w', grid_alpha=0.5)    \n\n    state = [np.array(img, dtype=ca_dtype)]\n    ca.reset_memory()\n    \n    def animate(i):\n        print(str(i) + (' ' if i < num_frames - 1 else ' Done.') , end='')\n        if i > 0:\n            state[0] = ca.step(state[0])    \n        \n        state_data = np.array(state[0], dtype=np.int)\n        mat_state[0].set_data(state_data)\n        \n        mem_data = ca._memory if ca._memory is not None else np.zeros_like(state[0], dtype=np.int)\n        mat_memory[0].set_data(state_data)\n        for (i, j), z in np.ndenumerate(mem_data):\n            color = 'gray' if z == 0 else 'white'\n            texts_memory[i, j].set_text(str(z))\n            texts_memory[i, j].set_color(color)\n            \n        rules_data = ca._applied_rules if ca._applied_rules is not None else (np.zeros_like(state[0], dtype=np.int)-1)\n        applied_rules[0].set_data(state_data)\n        for (i, j), z in np.ndenumerate(rules_data):\n            texts_rules[i, j].set_text(str(z) if z >= 0 else '')\n            \n    anim = animation.FuncAnimation(fig_for_anim, animate, init_func=init, frames=num_frames, interval=600)\n    return HTML(anim.to_jshtml())\n    \nlist_type = 'training'\n# change `task_name`, `task_sample_type`, and `task_sample_idx` here to view the process for a few other tasks.\n# task_name = 'db3e9e38'\n# task_name = 'b27ca6d3'\ntask_name = '00d62c1b'\n\ntask_sample_type = 'train'\n# task_sample_type = 'test'\ntask_sample_idx = 2\ndata_name = task_name + '.json'\ndata = load_data(f'{root_dir}\/{list_type}\/{data_name}')\ntask_data = data[task_sample_type][task_sample_idx]\n\nplot_pair(task_data)\nplt.show()\n    \npreset_task_rules = {\n    'db3e9e38':\n        '''--- pre-set rules for task db3e9e38\n             .  .  .\n        [FH] 8  0  .  -> 7\n             8  .  . \n        -----\n             .  .  .\n        [FH] 7  0  .  -> 8\n             7  .  .\n        ''',\n    '00d62c1b': \n        '''--- pre-set rules for task 00d62c1b\n        ----- turn black to yellow if >4 green blocks around\n             g g g\n        [HN] g k ., 0 -> y\n             . . .\n        ----- if yellow block reaches the border, turn to red for burning\n             . y .\n        [HD] # k . -> r, 1\n             . . .\n        ----- spread the red fire\n             . r .\n        [HD] . y . -> r, 1\n             . . .\n        ----- spread yellow region\n             . y .\n        [HD] . k ., 0 -> y\n             . . .\n        ----- let red burns down\n             . . .\n             . r . -> k\n             . . . \n        ''',\n    'b27ca6d3':\n        '''--- pre-set rules for task b27ca6d3\n        ------ turn black to green if two consective red blocks in neighbor area\n              . . .\n        [R4F] 0 0 . -> g\n              r r .\n        ------ turn black to green if \"green red green\" pattern found\n              . . .\n        [R4]  . 0 . -> g\n              g r g\n        ------ corner case\n              . . #\n        [R4F] . 0 # -> g\n              g r #\n        ------ change corner points out of two consective red blocks into green\n              . . .\n        [R4]  g 0 . -> g\n              r g .\n        ''',\n    '9c56f360':\n        '''\n        . . .\n        . 0 3 -> 3\n        . . .\n        ------\n        . . .\n        0 3 . -> 0\n        . . .\n        '''\n}\n\nca = CALambda(lambda s, i, j: s[i, j], lambda n, m: (7-n, m+1))\nca = CAMFilter.parse(preset_task_rules[task_name])\n# print(ca._filters)\nanim = animate_data(task_data, ca, num_frames=16)\nanim","133c8ba0":"%%html\n<style>\ntextarea, input {\n    font-family: monospace;\n}\n<\/style>","4e1a2135":"data_type = widgets.ToggleButtons(\n    options=['training', 'evaluation'],\n    description='Data:',\n    value='training'\n)\n\ninput_type = widgets.ToggleButtons(\n    options=['index', 'json'],\n    value='json',\n    description='Input:',\n)\n\nnum_index = widgets.BoundedIntText(\n    value=1,\n    min=1,\n    max=400,\n    step=1,\n    description='Index:',\n    disabled=False\n)\n\nnum_iter_input = widgets.BoundedIntText(\n    value=10,\n    min=1,\n    max=100,\n    step=1,\n    description='Iterations:',\n    disabled=False\n)\n\ntext_json = widgets.Text(\n    value='db3e9e38',\n    description='.JSON:',\n)\n\nsample_seletor = widgets.RadioButtons(\n    options=[],\n    value=None, # Defaults to 'pineapple'\n#    layout={'width': 'max-content'}, # If the items' names are long\n    description='Sample:',\n    disabled=False\n)\n\nrules_input = widgets.Textarea(\n    layout=Layout(width='50%', height='200px'),\n    description='Rules:'\n)\n\n\ndef get_data_path(list_type, inp, index, json_id):\n    \n    json_id = json_id+\".json\"\n    \n    print(list_type, inp, index, json_id)\n    if list_type == 'training':\n        if inp == 'index':\n            data = training_files[index-1]\n        elif json_id in training_files:\n            data = json_id\n        else:\n            print(u\"\\u274C\", \" check file id\")\n            return None, None\n\n    elif list_type == \"evaluation\":\n        if inp  == 'index':\n            data = evaluation_files[index-1]\n        elif json_id in evaluation_files:\n            data = json_id\n        else:\n            print(u\"\\u274C\", \" check file id\")\n            return None, None\n    \n    return f'{root_dir}\/{list_type}\/{data}', data\n\n\nrule_txts = { (k+'.json'):v for k, v in preset_task_rules.items() }\n#print(rule_txts)\n\ndata_path = None\nprev_data_path = None\ndata_to_show = None\n\ndef update_data(*args):\n    global data_path, prev_data_path, data_to_show, rule_txts\n    data_path, data_base_name = get_data_path(data_type.value, input_type.value, num_index.value, text_json.value)\n    \n    if (input_type.value == 'index'):\n        num_index.disabled = False\n        text_json.disabled = True\n    else:\n        num_index.disabled = True\n        text_json.disabled = False\n        \n    if data_path is None:\n        print('unknown data path ' + str(data_path))\n        return\n    if prev_data_path != data_path:\n        #print('load data from ' + f)\n        try:\n            data_to_show = load_data(data_path)\n        except:\n            print('unable to load data from ' + str(data_path))\n            return\n        \n        sample_seletor.options = [ 'train ' + str(i) for i, _ in enumerate(data_to_show['train']) ] \\\n                                + [ 'test ' + str(i) for i, _ in enumerate(data_to_show['test']) ]\n        #print(data_path)\n        rules_input.value = rule_txts.get(data_base_name, '')\n        prev_data_path = data_path\n\n\ndata_type.observe(update_data, 'value')\nnum_index.observe(update_data, 'value')\ntext_json.observe(update_data, 'value')\ninput_type.observe(update_data, 'value')\n\nupdate_data()\n\nplt.figure(figsize=(8, 2))\nplt.imshow([list(range(10))], cmap=cmap, norm=norm)\nplt.xticks(list(range(10)), [f'{i} [{color_codes[i]}]' for i in range(10)])\nplt.yticks([])\n\n@interact_manual\ndef show_me_the_data(list_type = data_type, \n                     inp = input_type,\n                     #index=(1, 400, 1),\n                     index = num_index,\n                     json_id = text_json,\n                     sample_sel = sample_seletor,\n                     rules_txt = rules_input,\n                     num_iter = num_iter_input):\n    rule_txts[data_path] = rules_txt\n    \n    try:\n        tag, i = sample_sel.split(' ')\n    except AttributeError:\n        return\n    print(list_type, index, data_path, tag, i)\n    i = int(i)\n    #print(data_to_show[tag][i])\n    plot_pair(data_to_show[tag][i])\n    #plot_data(f'{root_dir}\/{list_type}\/{data}')\n    plt.show()\n    \n    #f = CALambda(lambda s, i, j: s[i, j], lambda n, m: (7-n, m+1))\n    if len(rules_txt.strip()) > 0:\n        ca = CAMFilter.parse(rules_txt)\n        return (animate_data(data_to_show[tag][i], ca, num_frames=num_iter))","020a931c":"# Interactive CA Tool\n\nAlmost there. The final step is to create an interactive UI integrating all the components above for exploring the tasks and rules ","d23117a2":"This work is greatly inspired by [Cellular Automata as a Language for Reasoning](https:\/\/www.kaggle.com\/arsenynerinovsky\/cellular-automata-as-a-language-for-reasoning), [Simple and Interactive visualization of tasks](https:\/\/www.kaggle.com\/bsridatta\/simple-and-interactive-visualization-of-tasks#Interactive-visualization), and [Training Cellular Automata Part I: Game of Life](https:\/\/www.kaggle.com\/teddykoker\/training-cellular-automata-part-i-game-of-life). Great thanks to all the great works!\n\n# Key Points \n\nThis notebook\n\n1. Proposed a DSL to describe Cellular Automata rules in a simple, plain-text format like\n    \n        x x x\n        r g b -> b\n        r r r\n    \n2. Created a interactive tool for fast CA experiment. Simply type in your rules and see how it works.\n\n<p><font color=\"red\" size=3>If you like my work please upvote this kernel. It encorages me to produce more quality content!<\/font><\/p>\n\n\n\n# Intro\n\nSince Cellular Automata(CA) could be a powerful tool to solve this task, this notebook is to provide a way leading to CA-based Domain Specific Languages (DSLs) which is likely easily simulated or synthesized by machine learning models. If you don't have the knowledge of CA, [Cellular Automata as a Language for Reasoning](https:\/\/www.kaggle.com\/arsenynerinovsky\/cellular-automata-as-a-language-for-reasoning) is a greate introduction. \n\n# Rule Format\n\n## Basic Format\n\nTo step further, this notebook is an exploration in developing a DSL with more regular and less number of syntax rules. Rather than write CA rules in pure Python code, a CA rule can be written in a form like\n\n    x x x\n    x x x, m -> o, n\n    x x x\n\nOn the left hand of the arrow, the 3x3 array is a filter to match a 3x3 neighbor area around the central point (maybe 5x5 would be more powerful?), and `m` after the comma is a memory used in [Cellular Automata as a Language for Reasoning](https:\/\/www.kaggle.com\/arsenynerinovsky\/cellular-automata-as-a-language-for-reasoning) to expand the capability of CA. On the right side of the arrow, `o` is the output and `n` is the updated memory. This rule simply means \"when the 3x3 neighbor area matches the template and the memory equals the given value, change the value of the central point to `o` and update the memory at this place to `n`\". Of course we can omit the memory part, which implies we are not comparing the memory value and not updating it. \n\nSimple wildcard is useful and will be supported, like a dot(`.`) means matching any value.\n\n## Transform of Filters\n\nTo let us write less number of rules, we introduce the transform of filters. To explain this, let's take a simple example: if the value at any of the four corners are 0, change it to 1. For the case of top-left corner, it's easy to be written as\n\n    # # #\n    # 0 . -> 1\n    # . .\n \nwhere `#` means out-of-border and `.` means \"any value\". However, we need to repeat 3 more times to write rules for another corners.\n\nHowever, the filters for other 3 corners are merely rotations of that for top-left corner. If we introduce a concept of \"rotation\" we can unify the four rules into one, like\n\n         # # #\n    [R4] # 0 . -> 1\n         # . .\n         \nwhere `R4` means a rotation with number 4 (rotation in 90 degrees results in 4 distint filters).\n\n## Syntax List\n\nAll the syntax of the DSL introduced in this work are listed as follows:\n\nA CA rule is in form of\n\n        x x x\n    [T] x x x, m -> o, n\n        x x x\n\nwhere `T` is the transform, 3x3 `x`s are the template, `m` is memory input, `o` is output, and `n` is memory update. `T`, `m` and `n` can be optional. When no `T` is presented, the default is no transform, i.e. exact match.\n\n### Memory\n\nOnly integer values are supported in memory at this point, and only the value in memory at the central point is considered (not its neighborhood). It could be useful if we take into account the same neighbor region in memory as in the state, as a future work.\n\n### Transforms\n\nSupported `T`s:\n\n- `I`: fixed filter, i.e. exact match, the default value\n\n- Histogram: only the count of certain values matters (the location is irrelevant). \n  + `H` histogram includes the central point. \n  + `HN` only compares the histogram of 8 values in the neighborhood and the central value should be exact match. \n  + `HD` is like `HN` but only takes into account the 4-direct neighbor values(i.e. the values at 4 corners are not compared).\n\n- rotations and flips(mirrors): `R8`, `R4`, `R2`, `L8`, `L4`, `L2`, `FH`, `FV`, `FD`, `FA`, `R8F`, `R4F`, `R2F`, `L8F`, `L4F`, `L2F`\n  + `R`, `L` means left or right rotation, respectively\n  + the number means the angle of rotations, 8 means 45 degrees (resulting in 8 distinct rotations), 4 means 90 degree, and 2 means 180 degree. So infact `R2 == L2`. However, if the filter itself has a certain symmetric property, the result will be less than the number indicated. E.g. the 90 degrees rotation of a filter equals itself, so `R8` only ends up with 2 filters.\n  + `F` means flip (mirror), while `H`, `V`, `D`, `A` means horizontal, vertical, diagonal (top left to bottom right), anti-diagonal (top right to bottom left)\n  + the suffix `F` in any `R` or `F` means also including the rotations of the mirror of the filter. \n\n### Filter\n\n For the values in a filter, some special values are defined:\n \n - `#`: out of border\n - `.`: any value include out-of-border\n \n Some other values might be also useful but not supported yet, like: `*` any value inside the border;\n `+` any value but black (0). Apparently we can introduce more complex syntax leading to a regex-like rules, and this is a trade-off between capability and simplicity.\n \n And the color values are defined as follows. Both index and code are supported, e.g. either `0` or `k` can be used for \"black\".\n","02bfef6f":"# Implementation of Filters\n\nNow lets create a variety of kinds of filters. Here we got\n\n- `I`: `FixedFilter`\n- `H`: `HistFilter`\n- `HN`: `NeighHistFilter`\n- `HD`: `DirectNeighHistFilter`\n- Rotations and flips: `TransFilter` working with a bunch of rotation and flip functions\n\nNote the values in the filter and state is represented as string even it's a number in the dataset, i.e., it's string `\"1\"` instead of integer `1`.","2853f5e3":"# Interactive Tool\n\nIn order to experiment rules more easily, an interactive UI is created in this notebook which eventually looks like this. It's base on the work of [Simple and Interactive visualization of tasks](https:\/\/www.kaggle.com\/bsridatta\/simple-and-interactive-visualization-of-tasks#Interactive-visualization), plus the rules editing and animation. To use this please go to section [Interactive CA Tool](#Interactive-CA-Tool)(maybe you need to run the notebook before able to see it), simply select the data sample, type your rules in the format defined above in the \"rules_txt\" input box, and click \"Run interact\" to see how the rule works.\n\n![image.png](attachment:image.png)\n\nIf you want a quick look about the animation, please refer to [this section](#Visualization-&-Animation) for an animation example.","9e79e54d":"# Visualization & Animation\n\nNow we have created all the functions and classes for logic. Next we are going to visualize and animate the process. \n\nFirst plot the input and ouput of a pair of sample.\n\nThen generate an animation to show how the state changes when a CA is applied onto the input. Here three matrix will be shown: the first is the state; the second is the memory; the third is the indices of CA rules applied in this step.\n\nHere some tasks solved in [Cellular Automata as a Language for Reasoning](https:\/\/www.kaggle.com\/arsenynerinovsky\/cellular-automata-as-a-language-for-reasoning) as examples are presented here for demostration. If you don't understand the rules please read this article first.","3a86bcaa":"P.S. Here is another rule set figured out for task train\/2281f1f4, which is somewhat lengthy (18 rules). Each rule has two conterparts for horizontal and vertical directions respectively, and some of them are dealing with corner cases.\n\n```\n------ mark grey blocks on top row as green to move down\n. # .\n. e ., 0 -> g\n. k .\n------ extend green blocks down\n. g .\n. k . -> g\n. . .\n----- mark grey blocks on right column as blue to move left\n. . .\n. e #, 0 -> b\n. . .\n----- extend blue block left\n. . .\n. k b -> b\n. . .\n----- mark cross block red\n. g .\n. . b -> r\n. . .\n----- deal with horizontal consecutive red block marking\n. g .\n. . r -> r\n. . .\n----- deal with vertical consecutive red block marking\n. r .\n. . b -> r\n. . .\n----- deal with rectangle consecutive red block marking\n. r .\n. . r -> r\n. . .\n----- generate green blocks down from red one if stops\n. r .\n. k ., 0 -> g\n. . .\n----- generate blue blocks left from red one if stops\n. . .\n. k r, 0 -> b\n. . .\n----- change blue blocks near a red block back to grey (corner case)\n. . .\nr b # -> e, 1\n. . .\n----- change blue blocks near a red block into yellow for removal\n     . . .\n[FH] . b r -> y\n     . . .\n----- change green blocks near a red block into yellow for removal\n     . r .\n[FV] . g . -> y\n     . . .\n----- extend yellow blocks and turn back to grey if reach the border\n. # .\n. g . -> e, 1\n. y .\n-----\n. . .\ny b # -> e, 1\n. . .\n----- extend yellow blocks\n     . y .\n[FV] . g . -> y\n     . . .\n-----\n     . . .\n[FH] y b . -> y\n     . . .\n----- remove yellow blocks and memorize it\n. . .\n. y . -> k, 5\n. . .\n```","9b7e9763":"# Implementation\n\nOK, now let's do this.\n\nImport & setup, and create functions for loading and ploting data. This part is mostly from [Simple and Interactive visualization of tasks](https:\/\/www.kaggle.com\/bsridatta\/simple-and-interactive-visualization-of-tasks#Interactive-visualization)","1556abb0":"# Implementation of CA\n\nOK, now let's create the transition(or step) function of CA based on the filters above. A CA is a list of rules (first rules first matched; once get one matched, skip the rest)"}}