{"cell_type":{"d28b466a":"code","06d898c1":"code","b94eaeb4":"code","8cd08e09":"code","eb1e88a8":"code","14667586":"code","f59bc74d":"code","566a57e6":"code","91518d9a":"code","d3dcb5a9":"code","750b4c2f":"markdown"},"source":{"d28b466a":"import numpy as np \nimport pandas as pd\nimport IPython.display as ipd\nimport math\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nimport soundfile as sf\nimport keras\nimport glob\nimport scipy\nfrom scipy.signal import decimate\nfrom scipy.io import wavfile\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ntrain_folder = \"..\/input\/train\/Train\"\ntrain_df = pd.read_csv('..\/input\/train\/train.csv')\ntrain_df['file'] = train_df['ID'].apply(lambda x: train_folder+'\/'+str(x)+'.wav')\ntest_folder = \"..\/input\/test\/Test\"\ntest_df = pd.read_csv('..\/input\/test\/test.csv')\ntest_df['file'] = test_df['ID'].apply(lambda x: test_folder+'\/'+str(x)+'.wav')","06d898c1":"labelEncoder=LabelEncoder()\ntrain_df['Class_id'] = labelEncoder.fit_transform(train_df['Class'])\ntrain_df['Class'].describe()","b94eaeb4":"samples_channels = [sf.read(f, dtype='float32')[0].shape for f in test_df['file']]\nframerates = [sf.read(f, dtype='float32')[1] for f in test_df['file']]\nchannels = [1 if len(x)==1 else x[1] for x in samples_channels]\nsamples = [x[0] for x in samples_channels]\nlengths = np.array(samples) \/ np.array(framerates)\n\npd.DataFrame({'framerate':framerates, 'channel':channels, 'sample':samples, 'length':lengths}).describe()","8cd08e09":"N_CLASSES=10\nRATE = 8000\nCHANNELS = 1\nLENGTH = 4\nSAMPLES = RATE*LENGTH\ndef proc_sound(data, rate):\n    data = decimate(data, rate \/\/ RATE, axis=0)\n    if 2==len(data.shape):\n        data = np.sum(data, axis=1)\n    pad = SAMPLES - len(data)\n    if pad > 0:\n        data = np.pad(data, ((0, pad)), mode = 'wrap')\n    else:\n        data = data[:SAMPLES]\n    return data.reshape((-1, 1))\ndef fit_generator(files, labels, augments, per_batch):\n    while True:\n        for i in range(0, len(files), per_batch):\n            signals = []\n            _labels = []\n            for j in range(i, min(len(files), i+per_batch)):\n                file = files[j]\n                label = labels[j]\n                data, rate = sf.read(file, dtype='float32')\n                data = proc_sound(data, rate)\n                for _ in range(augments+1):\n                    signals.append(np.roll(data, np.random.randint(0, SAMPLES)))\n                    _labels.append(label)\n            yield np.array(signals), np.array(_labels)\n            \ndef test_generator(files, labels, per_batch):\n    while True:\n        signals = []\n        _labels = []\n        for i in range(0, per_batch):\n            j = np.random.randint(0, len(files))\n            file = files[j]\n            label = labels[j]\n            data, rate = sf.read(file, dtype='float32')\n            data = proc_sound(data, rate)\n            signals.append(np.roll(data, np.random.randint(0, SAMPLES)))\n            _labels.append(label)\n        yield np.array(signals), np.array(_labels)\n        \ndef predict_generator(files, per_batch):\n    while True:\n        for i in range(0, len(files), per_batch):\n            signals = []\n            for j in range(i, min(len(files), i+per_batch)):\n                file = files[j]\n                data, rate = sf.read(file, dtype='float32')\n                data = proc_sound(data, rate)\n                signals.append(data)\n            yield np.array(signals)\n        \ndef steps_per_epoch(total, batch):\n    return int(math.ceil(total \/ batch))","eb1e88a8":"model = keras.models.Sequential()\nmodel.add(keras.layers.InputLayer((SAMPLES, CHANNELS,)))\nfor n, k, s in ((30, 25, 5),(50, 19, 5), (100, 19, 5), (100, 19, 4), (100, 19, 4), (100, 15, 4), (100, 7, 4)):\n    model.add(keras.layers.Conv1D(n, kernel_size=k, strides=s, padding='same'))\n    model.add(keras.layers.LeakyReLU())\n    model.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(N_CLASSES, activation='softmax'))\n\nmodel.summary()","14667586":"per_batch = 100\nepochs = 25\naugments = 1\n\nmodel.compile(loss='sparse_categorical_crossentropy',\n              optimizer=keras.optimizers.Adam(0.01),\n             metrics=['accuracy'])\nmodel.fit_generator(fit_generator(train_df['file'], train_df['Class_id'], augments, per_batch),\n                   epochs=epochs,\n                   steps_per_epoch=steps_per_epoch(len(train_df), per_batch),\n                   verbose=2)","f59bc74d":"predicted_probs = model.predict_generator(predict_generator(train_df['file'],per_batch),\n                   steps=steps_per_epoch(len(train_df), per_batch))\npredicted = np.argmax(predicted_probs, axis=1)\nprint(classification_report(train_df['Class_id'], predicted))\nsns.heatmap(confusion_matrix(train_df['Class_id'], predicted));","566a57e6":"predict_probs = model.predict_generator(predict_generator(test_df['file'], per_batch),\n                   steps=steps_per_epoch(len(test_df), per_batch))\npredicts = np.argmax(predict_probs, axis=1)\nout_df = test_df[['ID']]\nout_df['Class'] = labelEncoder.inverse_transform(predicts)\nout_df.to_csv('submission.csv')","91518d9a":"out_df.head(10)","d3dcb5a9":"for data in next(predict_generator(test_df['file'], 10)):\n    ipd.display(ipd.Audio(data.flatten(), rate=RATE))","750b4c2f":"## Simplified CNN For Sound classification\n\nThe model is simple, because reading 24-bit wav files requires a custom package `soundfile` that currently GPU kernels do not support. "}}