{"cell_type":{"b8a24d26":"code","fbe9005f":"code","a1a9247e":"code","6657f75e":"code","1423833b":"code","2c34883a":"code","116b59ba":"code","eca96550":"code","dab303a7":"code","ab8f41f4":"code","3e51f393":"code","752078fb":"code","a36c04d5":"code","efebd259":"code","d980e4d9":"code","483ee5df":"code","af7c9661":"code","5a349f16":"code","de8b71ac":"code","9bd1b820":"code","0714dd23":"code","144b8cc0":"code","8c5e7b58":"code","ec040560":"code","55e595f8":"code","84d6ecfb":"code","3663608e":"code","4c5bedf8":"code","87a2e11c":"code","05acb441":"markdown","0cd83edb":"markdown","41b016c6":"markdown","15495f55":"markdown","62e1638d":"markdown","d0edc62d":"markdown","932ef494":"markdown","d5abab6e":"markdown","635aa006":"markdown","463aa181":"markdown","3de1fedf":"markdown","f91ed03f":"markdown","207c4d9d":"markdown","92a0ac81":"markdown","24d1d0f6":"markdown","fb8e976c":"markdown","bc0ccd78":"markdown","86203e4f":"markdown","015ec090":"markdown","a6004576":"markdown","bbf9bedc":"markdown","9ce5b68c":"markdown","19e3d9b0":"markdown","1e65b8f9":"markdown","493109b4":"markdown","d209403d":"markdown","693b95d3":"markdown","98a5bd52":"markdown","24831b11":"markdown","a983ec1c":"markdown","88b1128e":"markdown","c29477ac":"markdown","f38bcf0a":"markdown","be067bf2":"markdown","fbfd31e8":"markdown"},"source":{"b8a24d26":"## Library imports\nimport numpy as np \nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nimport os, glob, re, sys, random, unicodedata, collections\nfrom tqdm import tqdm\nfrom functools import reduce\nimport nltk\nfrom collections import Counter\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import RSLPStemmer\nfrom nltk.tokenize import sent_tokenize , word_tokenize\n\nSTOP_WORDS = set(stopwords.words('portuguese'))","fbe9005f":"random.seed(42) ## turn it reproductible\n\nfiles = []\n# Read only the txt version of files and discard the pdf files of the colleciton\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/machado-de-assis\/raw\/txt\/'):\n    for filename in filenames:\n        files.append(os.path.join(dirname, filename))\n\nprint('There are a total of {} files'.format(len(files)), '\\n')\n        \n# select and read 10 random files \nsample_books = random.sample(files,10)\n\ndocs = []\nfor fname in sample_books:\n    with open(fname , \"r\") as file:\n        text = file.read()\n    docs.append(text)\n\n# count term frequency using CountVectorizer from scikit-learn\n## limiting number of words just for illustrating the concept\nvec = CountVectorizer(max_features=10, stop_words=STOP_WORDS) \nX = vec.fit_transform(docs)\ndf = pd.DataFrame(X.toarray(), columns=vec.get_feature_names())\nbooks_names = [book.split('\/')[-1] for book in sample_books]\ndf['book'] = books_names\ndf = df.set_index('book')\n\nprint(df)","a1a9247e":"WORD_MIN_LENGTH = 2 ## we'll drop all tokens with less than this size\n\ndef strip_accents(text):\n    \"\"\"Strip accents and punctuation from text. \n    For instance: strip_accents(\"Jo\u00e3o e Maria, n\u00e3o entrem!\") \n    will return \"Joao e Maria  nao entrem \"\n\n    Parameters:\n    text (str): Input text\n\n    Returns:\n    str: text without accents and punctuation\n\n   \"\"\"    \n    nfkd = unicodedata.normalize('NFKD', text)\n    newText = u\"\".join([c for c in nfkd if not unicodedata.combining(c)])\n    return re.sub('[^a-zA-Z0-9 \\\\\\']', ' ', newText)\n\ndef tokenize_text(text):\n    \"\"\"Make all necessary preprocessing of text: strip accents and punctuation, \n    remove \\n, tokenize our text, convert to lower case, remove stop words and \n    words with less than 2 chars.\n\n    Parameters:\n    text (str): Input text\n\n    Returns:\n    str: cleaned tokenized text\n\n   \"\"\"        \n    text = strip_accents(text)\n    text = re.sub(re.compile('\\n'),' ',text)\n    words = word_tokenize(text)\n    words = [word.lower() for word in words]\n    words = [word for word in words if word not in STOP_WORDS and len(word) >= WORD_MIN_LENGTH]\n    return words","6657f75e":"def inverted_index(words):\n    \"\"\"Create a inverted index of words (tokens or terms) from a list of terms\n\n    Parameters:\n    words (list of str): tokenized document text\n\n    Returns:\n    Inverted index of document (dict)\n\n   \"\"\"       \n    inverted = {}\n    for index, word in enumerate(words):\n        locations = inverted.setdefault(word, [])\n        locations.append(index)\n    return inverted\n\ndef inverted_index_add(inverted, doc_id, doc_index):\n    \"\"\"Insert document id into Inverted Index\n\n    Parameters:\n    inverted (dict): Inverted Index\n    doc_id (int): Id of document been added\n    doc_index (dict): Inverted Index of a specific document.\n\n    Returns:\n    Inverted index of document (dict)\n\n   \"\"\"        \n    for word in doc_index.keys():\n        locations = doc_index[word]\n        indices = inverted.setdefault(word, {})\n        indices[doc_id] = locations\n    return inverted","1423833b":"inverted_doc_indexes = {}\nfiles_with_index = []\nfiles_with_tokens = {}\ndoc_id=0\nfor fname in tqdm(files):\n    with open(fname , \"r\") as file:\n        text = file.read()\n    #Clean and Tokenize text of each document\n    words = tokenize_text(text)\n    #Store tokens\n    files_with_tokens[doc_id] = words\n\n    doc_index = inverted_index(words)\n    inverted_index_add(inverted_doc_indexes, doc_id, doc_index)\n    files_with_index.append(os.path.basename(fname))\n    doc_id = doc_id+1","2c34883a":"## Check presence of capitu token into Dom Casmurro book:\ncapitu_docs = inverted_doc_indexes['capitu']\nfor idx in capitu_docs.keys():\n    print(files_with_index[idx])","116b59ba":"## Using AND as logical operator\ndef boolean_search(inverted, file_names, query):\n    \"\"\"Run a boolean search with AND operator between terms over \n    the inverted index.\n\n    Parameters:\n    inverted (dict): Inverted Index\n    file_names (list): List with names of files (books)\n    query (txt): Query text\n\n    Returns:\n    Names of books that matchs the query.\n\n   \"\"\"      \n    # preprocess the user query using same function used to build Inverted Index\n    words = [word for _, word in enumerate(tokenize_text(query)) if word in inverted]\n    # list with a disctinct document match for each term from query\n    results = [set(inverted[word].keys()) for word in words]\n    # AND operator. Replace & for | to modify to OR behavior.\n    docs = reduce(lambda x, y: x & y, results) if results else []\n    return ([file_names[doc] for doc in docs])","eca96550":"# Passage from \"Quincas borba\"\nprint(boolean_search(inverted_doc_indexes, files_with_index, \n                     \"Ao vencido, \u00f3dio ou compaix\u00e3o; ao vencedor, as batatas\"))\nprint(boolean_search(inverted_doc_indexes, files_with_index, \n                     \"Quincas borba\"))","dab303a7":"# Passage from \"Dom Casmurro\"\nprint(boolean_search(inverted_doc_indexes, files_with_index, \n                     \"Capitu, apesar daqueles olhos que o diabo lhe deu\"))\nprint(boolean_search(inverted_doc_indexes, files_with_index, \n                     \"Capitu\"))","ab8f41f4":"## Passage from \"Mem\u00f3rias P\u00f3stumas de Br\u00e1s Cubas\"\nprint(boolean_search(inverted_doc_indexes, files_with_index, \n                     \"Sandice criar amor \u00e0s casas alheias, de modo que, \\\n                     apenas senhora de uma, dificilmente lha far\u00e3o despejar\"))\nprint(boolean_search(inverted_doc_indexes, files_with_index, \n                     \"Sandice\"))","3e51f393":"## Exaple of two term query present in several books, but there's \n## no relevance order to evaluate with result to look first. \nprint(boolean_search(inverted_doc_indexes, files_with_index, \"\u00e1rvore rua\"))","752078fb":"## Number of documents each term occurs\nDF = {}\nfor word in inverted_doc_indexes.keys():\n    DF[word] = len ([doc for doc in inverted_doc_indexes[word]])\n\ntotal_vocab_size = len(DF)\nprint(total_vocab_size)","a36c04d5":"tf_idf = {} # Our data structure to store Tf-Idf weights\n\nN = len(files_with_tokens)\n\nfor doc_id, tokens in tqdm(files_with_tokens.items()):\n    \n    counter = Counter(tokens)\n    words_count = len(tokens)\n    \n    for token in np.unique(tokens):\n        \n        # Calculate Tf\n        tf = counter[token] # Counter returns a tuple with each terms counts\n        tf = 1+np.log(tf)\n        \n        # Calculate Idf\n        if token in DF:\n            df = DF[token]\n        else:\n            df = 0\n        idf = np.log((N+1)\/(df+1))\n        \n        # Calculate Tf-idf        \n        tf_idf[doc_id, token] = tf*idf","efebd259":"def ranked_search(k, tf_idf_index, file_names, query):\n    \"\"\"Run ranked query search using tf-idf model.\n\n    Parameters:\n    k (int): number of results to return\n    tf_idf_index (dict): Data Structure storing Tf-Idf weights to each \n                        pair of (term,doc_id) \n    file_names (list): List with names of files (books)\n    query (txt): Query text\n\n    Returns:\n    Top-k names of books that matchs the query.\n\n   \"\"\"   \n    tokens = tokenize_text(query)\n    query_weights = {}\n    for doc_id, token in tf_idf:\n        if token in tokens:\n            query_weights[doc_id] = query_weights.get(doc_id, 0) + tf_idf_index[doc_id, token]\n    \n    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n    results = []\n    for i in query_weights[:k]:\n        results.append(file_names[i[0]])\n    \n    return results\n    ","d980e4d9":"# Passage from \"Quincas borba\"\nprint(ranked_search(10, tf_idf, files_with_index, \n                    \"Ao vencido, \u00f3dio ou compaix\u00e3o; ao vencedor, as batatas\"))\nprint(ranked_search(10, tf_idf, files_with_index, \"Quincas borba\"))","483ee5df":"# Passage from \"Dom Casmurro\"\nprint(ranked_search(10, tf_idf, files_with_index, \n                    \"Capitu, apesar daqueles olhos que o diabo lhe deu\"))\nprint(ranked_search(10, tf_idf, files_with_index, \"Capitu\"))","af7c9661":"## Passage from \"Mem\u00f3rias P\u00f3stumas de Br\u00e1s Cubas\"\nprint(ranked_search(10, tf_idf, files_with_index, \n                    \"Sandice criar amor \u00e0s casas alheias, de modo que, \\\n                    apenas senhora de uma, dificilmente lha far\u00e3o despejar\"))\nprint(ranked_search(10, tf_idf, files_with_index, \"Sandice\"))","5a349f16":"## Here we reproduce the previous query with common words, \n## but now we have a score to sort results.\nprint(ranked_search(10, tf_idf, files_with_index, \"\u00e1rvore rua\"))","de8b71ac":"##Source: https:\/\/gist.github.com\/bwhite\/3726239\ndef mean_reciprocal_rank(bool_results, k=10):\n    \"\"\"Score is reciprocal of the rank of the first relevant item\n    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n    Example from http:\/\/en.wikipedia.org\/wiki\/Mean_reciprocal_rank\n    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n    >>> mean_reciprocal_rank(rs)\n    0.61111111111111105\n\n    Args:\n        rs: Iterator of relevance scores (list or numpy) in rank order\n            (first element is the first item)\n    Returns:\n        Mean reciprocal rank\n    \"\"\"\n    bool_results = (np.atleast_1d(r[:k]).nonzero()[0] for r in bool_results)\n    return np.mean([1. \/ (r[0] + 1) if r.size else 0. for r in bool_results])\n\nmean_reciprocal_rank([[0, 0, 1], [0, 1, 0], [1, 0, 0]])","9bd1b820":"!pip install rank_bm25\nfrom rank_bm25 import BM25Okapi","0714dd23":"### Processing DOCUMENTS\ndoc_set = {}\ndoc_id = \"\"\ndoc_text = \"\"\nwith open('\/kaggle\/input\/cisi-a-dataset-for-information-retrieval\/CISI.ALL') as f:\n    lines = \"\"\n    for l in f.readlines():\n        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n    lines = lines.lstrip(\"\\n\").split(\"\\n\")\ndoc_count = 0\nfor l in lines:\n    if l.startswith(\".I\"):\n        doc_id = int(l.split(\" \")[1].strip())-1\n    elif l.startswith(\".X\"):\n        doc_set[doc_id] = doc_text.lstrip(\" \")\n        doc_id = \"\"\n        doc_text = \"\"\n    else:\n        doc_text += l.strip()[3:] + \" \" # The first 3 characters of a line can be ignored.    \n\n        \n### Processing QUERIES\nwith open('\/kaggle\/input\/cisi-a-dataset-for-information-retrieval\/CISI.QRY') as f:\n    lines = \"\"\n    for l in f.readlines():\n        lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n    lines = lines.lstrip(\"\\n\").split(\"\\n\")\n    \nqry_set = {}\nqry_id = \"\"\nfor l in lines:\n    if l.startswith(\".I\"):\n        qry_id = int(l.split(\" \")[1].strip()) -1\n    elif l.startswith(\".W\"):\n        qry_set[qry_id] = l.strip()[3:]\n        qry_id = \"\"\n\n### Processing QRELS\nrel_set = {}\nwith open('\/kaggle\/input\/cisi-a-dataset-for-information-retrieval\/CISI.REL') as f:\n    for l in f.readlines():\n        qry_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]) -1\n        doc_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1])-1\n        if qry_id in rel_set:\n            rel_set[qry_id].append(doc_id)\n        else:\n            rel_set[qry_id] = []\n            rel_set[qry_id].append(doc_id)","144b8cc0":"## Here we check some statistics and info of CISI dataset\n\nprint('Read %s documents, %s queries and %s mappings from CISI dataset' % \n      (len(doc_set), len(qry_set), len(rel_set)))\n\nnumber_of_rel_docs = [len(value) for key, value in rel_set.items()]\nprint('Average %.2f and %d min number of relevant documents by query ' % \n      (np.mean(number_of_rel_docs), np.min(number_of_rel_docs)))\n\nprint('Queries without relevant documents: ', \n      np.setdiff1d(list(qry_set.keys()),list(rel_set.keys())))","8c5e7b58":"random.seed(42)\nidx = random.sample(rel_set.keys(),1)[0]\n\nprint('Query ID %s ==>' % idx, qry_set[idx])\nrel_docs = rel_set[idx]\nprint('Documents relevants to Query ID %s' % idx, rel_docs)\nsample_document_idx = random.sample(rel_docs,1)[0]\nprint('Document ID %s ==>' % sample_document_idx, doc_set[sample_document_idx])","ec040560":"query = qry_set[idx] #get query text\nrel_docs = rel_set[idx] #get relevant documents\n\n# Index all documents using BM25\ncorpus = list(doc_set.values())\ntokenized_corpus = [doc.split(\" \") for doc in corpus]\nbm25 = BM25Okapi(tokenized_corpus)\n\n# Process query and get scores for each indexed document using BM25\ntokenized_query = query.split(\" \")\nprint('Query ==> ', query, '\\nRelevant documents IDs: ==> ', rel_docs)\nscores = bm25.get_scores(tokenized_query)\nprint(scores, len(scores), len(doc_set))","55e595f8":"## Argsort gives the indexes of values in increasing order, so we input with the negative values of scores\nmost_relevant_documents = np.argsort(-scores)\n\nprint(most_relevant_documents[:20]) # printing first 20 most relevant results\n\n## Mask relevant documents with 0's and 1's according to query <-> document annotation\nmasked_relevance_results = np.zeros(most_relevant_documents.shape)\nmasked_relevance_results[rel_docs] = 1\nsorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n\nprint(sorted_masked_relevance_results[:20]) #printing first 20 results: 1 is relevant 0 isn't\n\n# Calculate MRR@10\nprint(mean_reciprocal_rank([sorted_masked_relevance_results]))","84d6ecfb":"def results_from_query(qry_id, bm25):\n    \"\"\"Return an ordered array of relevant documents returned by query_id\n\n    Args:\n        qry_id (int): id of query on dataset\n        bm25 (object): indexed corpus\n\n    Returns:\n        boolean sorted relevance array of documents\n    \"\"\"    \n    query = qry_set[qry_id]\n    rel_docs = []\n    if qry_id in rel_set:\n        rel_docs = rel_set[qry_id]\n    tokenized_query = query.split(\" \")\n    scores = bm25.get_scores(tokenized_query)\n    most_relevant_documents = np.argsort(-scores)\n    masked_relevance_results = np.zeros(most_relevant_documents.shape)\n  \n    masked_relevance_results[rel_docs] = 1\n    sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n    \n    return sorted_masked_relevance_results\n\n\nresults = [results_from_query(qry_id, bm25) for qry_id in list(qry_set.keys())]\nprint('MRR@10 %.4f' % mean_reciprocal_rank(results))","3663608e":"# Instaciate objects from NLTK\nstemmer = nltk.stem.PorterStemmer()\nstop_words = nltk.corpus.stopwords.words('english')","4c5bedf8":"def preprocess_string(txt, remove_stop=True, do_stem=True, to_lower=True):\n    \"\"\"\n    Return a preprocessed tokenized text.\n    \n    Args:\n        txt (str): original text to process\n        remove_stop (boolean): to remove or not stop words (common words)\n        do_stem (boolean): to do or not stemming (suffixes and prefixes removal)\n        to_lower (boolean): remove or not capital letters.\n        \n    Returns:\n        Return a preprocessed tokenized text.\n    \"\"\"      \n    if to_lower:\n        txt = txt.lower()\n    tokens = nltk.tokenize.word_tokenize(txt)\n    \n    if remove_stop:\n        tokens = [tk for tk in tokens if tk not in stop_words]\n    if do_stem:\n        tokens = [stemmer.stem(tk) for tk in tokens]\n    return tokens","87a2e11c":"corpus = list(doc_set.values())\n# You may experiment with this trying to improve MRR@10\nremove_stop = True\ndo_stem = True\nto_lower = True\n\ntokenized_corpus = [preprocess_string(doc, remove_stop, do_stem, to_lower) for doc in corpus]\n\nbm25 = BM25Okapi(tokenized_corpus)\n\ndef results_from_query_new(qry_id, bm25):\n    query = qry_set[qry_id]\n    rel_docs = []\n    if qry_id in rel_set:\n        rel_docs = rel_set[qry_id]\n    tokenized_query = preprocess_string(query, remove_stop, do_stem, to_lower)\n    scores = bm25.get_scores(tokenized_query)\n    most_relevant_documents = np.argsort(-scores)\n    masked_relevance_results = np.zeros(most_relevant_documents.shape)\n    masked_relevance_results[rel_docs] = 1\n    sorted_masked_relevance_results = np.take(masked_relevance_results, most_relevant_documents)\n    return sorted_masked_relevance_results\n\n\nresults = [results_from_query_new(qry_id, bm25) for qry_id in list(qry_set.keys())]\nprint('MRR@10 %.4f' % mean_reciprocal_rank(results))","05acb441":"## 1.1 Basic Concepts","0cd83edb":"As we can see above, our boolean search works pretty well. But this model has few problems:\n\n* The user must have some knowledge of the collection to proper use the logical operators (OR, AND, NOT...). We over simplified here using only AND.\n* We don't have a notion of rank here. For example, if we search for a couple of common words not present into STOP_WORDS, it'll probably return all documents, but without any importance order. \n* Larger documents have bigger probability to be returned in any query, since it contains more terms. \n\nWe'll try to address these issues with another retrieval model called Ranked TF-IDF.\n\nPS: There are several issues related to deal with phrase queries, but we won't deal with them. Please refer to Chapter 2 of Chris Manning's [book](https:\/\/nlp.stanford.edu\/IR-book\/pdf\/irbookonlinereading.pdf).","41b016c6":"## 3.2 Index CISI dataset using BM25","15495f55":"### 1.3.2 Building Inverted index","62e1638d":"Now we're ready to reproduce scores through all queries in dataset. First we'll create a function to return the masked results.","d0edc62d":"## 1.3 Inverted Index","932ef494":"### 1.3.1 Cleanning up and tokenizing text\n\nIn this section we'll tokenize (split it into terms or tokens) a piece of text and clean it: eliminate accentuation, puctuation and put all letter into lower case. We also remove stop words, the most common words such as articles, prepositions, etc.\nThese steps are important to improve the results of our search engine, because since a user can search by \"Capit\u00fa\", \"capitu\", \"Capitu\" or \"capit\u00fa\", we want all these forms to match te character of Machado de Assis's book, \"Dom Casmurro\".  So we process both the text of the books and later the user queries with same methods.","d5abab6e":"In the code below we index each document from CISI without any preprocessing and get scores for one random query.","635aa006":"<h1>Introduction to Information Retrieval - <i>Machado de Assis Collection<\/i><\/h1> \n\n","463aa181":"[Information Retrieval](https:\/\/en.wikipedia.org\/wiki\/Information_retrieval) could be defined as a field of study interested in ways to finding relevant material of an unstructured nature (usually text) from a collection of data (i.e.: files stored in your file system) to satisfy user information need. \n\nUsers try to translate their needs into a *query*. This *query* is processed by a *search engine* over the *collection* and retrive matching *results*. Users then evaluates the relevance of these *results* and refine his *query* iteratively.\n","3de1fedf":"# 2. Ranked TF-IDF Retrieval Model","f91ed03f":"Below there's a sample of a pair query and a document relevant to it in the dataset.","207c4d9d":"Now we'll test some passages and character names from well known books from author.","92a0ac81":"As we can see, a huge improvement (~35%) in MRR@10 doing this 3 preprocessing steps !!","24d1d0f6":"Finally we sort documents by score, compare with hand annotated relevant documents from dataset and create a boolean mask of the results. With this boolean array we can calculate MRR@10.","fb8e976c":"TF-IDF stands for term frequency\u2013inverse document frequency. It's a retrieval model whereas each pair of term *i* in document *d* receiveis a weight given by formulas below:","bc0ccd78":"Disclaimer: this tutorial follows the ideas presented in [Stanford CS124 class Week 4](https:\/\/www.youtube.com\/channel\/UC_48v322owNVtORXuMeRmpA) and in Chis Manning's Book [An Introduction to Information Retrieval](https:\/\/nlp.stanford.edu\/IR-book\/pdf\/irbookonlinereading.pdf). Also, some code was borrowed from this [github repo](https:\/\/github.com\/williamscott701\/Information-Retrieval\/blob\/master\/2.%20TF-IDF%20Ranking%20-%20Cosine%20Similarity%2C%20Matching%20Score\/TF-IDF.ipynb).\n\nIn this tutorial we'll cover the basics of Information Retrieval (IR) concepts and focus on Boolean and TF-IDF Ranked Retrieval models. At the end we present ways to evaluate an IR system using a benchmark dataset and an algorithm shipped with modern search engines based on Lucene (i.e. Elasticsearch and Solr).\n\nFor our demo, we'll use a collection of [Machado de Assis](https:\/\/pt.wikipedia.org\/wiki\/Machado_de_Assis)'s books and articles. He is a famous brazilian writer. ","86203e4f":"## 3.1 Load and process CISI dataset","015ec090":"One problem with this approach is, since a big collection usually has hundreds of thousands of distinct words and possibly another hundreds of thousands of distinct documents, this table (or matrix) will have approxemately 10^10 elements, or 10 Billion. Even using a efficient data structure for sparse data, it's hard to build such matrix. \n\nOne possible solution is to store the information in a inverted manner: An <b>Inverted Index<\/b>.\n","a6004576":"## 3.3 Trying to improve results\n\nIn this section we'll try to improve results through preprocessing our corpus and query using stemming, lowercase and removing stop words.","bbf9bedc":"# 3. Evaluating IR Systems\n\nIn this section we'll discuss how to evaluate an Information Retrieval System. To assess our design decisions (kind of data structure, preprocessing steps, type of term weigthing, etc) we need to set up a benchmark.\n\nThere are several available benchmarks over the Internet. Probably the most important IR dataset nowadays is [MS Marco Document retrieval dataset](https:\/\/microsoft.github.io\/msmarco\/). It contains more than 3 million documents and 300k queries. Besides documents and queries a IR benchmark must be a relevance mapping between them. This way we can evaluate if a document returned by our system should be returned or not according to this mapping.\n\nThere are several metrics to evaluate IR systems. The evaluation process consists of \"firing\" a set of queries \"against\" the IR System and compare the returned documents with the answers annotated in relevance mapping. Some metrics use the orders of returned documents, but others don't. In some metrics we define a cut in the number of documents returned (i.e. top 10 documents only). A extensive list of metrics can be found [here](https:\/\/en.wikipedia.org\/wiki\/Evaluation_measures_(information_retrieval)).\n\nIn this tutorial we'll use [MRR@10 (Mean Reciprocal Rank)](https:\/\/en.wikipedia.org\/wiki\/Mean_reciprocal_rank), a metric which takes into account only the position of the first relevant document returned into the first 10 documents by each query. MS Marco benchmark also uses this metric, but it is calculated with 100 first returned results.\n","9ce5b68c":"The code above will receive a boolean relevance results vector and return the MRR@10.","19e3d9b0":"The table above shows 10 words occurrence into 10 books sampled  from the 116 available. Now, from this table, we're able to search documents which contains specific terms using set operations (AND, OR, NOT). \n\nFor example, for table above, if our *query* is the *term* \"helena\", documents number 2, 3 and 9 match our criteria. If our *query* is \"est\u00e1cio\", only document 9 matches. If our *query* is \"helena AND est\u00e1cio\", the engine will compute (2, 3, 9) AND (9) and return 9. Also, with a *query* \"helena OR est\u00e1cio\", it will compute (2, 3, 9) OR (9) and return (2, 3, 9) as results. (Remember: OR is Union and AND is Intersection).","1e65b8f9":"To acomplish this model here, we'll create a data structure using a dictionary whereas the key is the pair (term, doc_id) and value is Tf-Idf weight. First we calculate the term frequency (number of documents each term is present).","493109b4":"Instead of using a huge dataset, for didatic purposes we'll use a much smaller one, known as [CISI collection](http:\/\/ir.dcs.gla.ac.uk\/resources\/test_collections\/cisi\/), from Glasgow Univesity. The code below loads the original dataset into dictionaries to easy access.","d209403d":"Now we iterate over our collection of books and build our Inverted Index.","693b95d3":"### 1.4 Running boolean search\nNow we're ready to run boolean search on our inverted index. This index and query processing together consists of we call a *search engine*. To simplify, again, our boolean search function will use only AND operator, retrieving only documents that contain all terms in user query.","98a5bd52":"## 2.1 Running Ranked search\n\nSimilar to boolean search, here we define a function to process a query and return documents that matches it.","24831b11":"# 1. Boolean Retrieval Model\n\nWe'll start this tutorial with the boolean retrieval model.","a983ec1c":"Again, we'll test same passages and character names we used previously.","88b1128e":"To evaluate our benchmark, instead of using the Tf-Idf model we build previously, we'll use an API which implements a rank function called [Okapi BM25](https:\/\/en.wikipedia.org\/wiki\/Okapi_BM25). It's the standard function built in [Apache Lucene](https:\/\/lucene.apache.org\/), [Elastic](https:\/\/www.elastic.co\/) and [Apache Solr](https:\/\/solr.apache.org\/), leading solutions for indexing and searching documents.\n\nBM25 is very similar to Tf-Idf concept we discussed earlier in this tutorial.","c29477ac":"To build our Inverted Index, we'll use two auxiliary functions. The first one process the tokenized text from one document (book) to build a local inverted index. The second merge this information into our Inverted Index adding document id of each document. The final structure of our index will have the form of:\n\n<pre>\n{'term1': \n    {doc_id0: [pos0, pos1, pos2], #positions of term1 found in doc_id0\n    doc_id1: [pos0, pos1, pos2] #positions of term1 found in doc_id1\n}, 'term2': \n    {doc_id0: [pos0, pos1, pos2], #positions of term1 found in doc_id0\n    doc_id3: [pos0, pos1, pos2] #positions of term1 found in doc_id3\n    ...\n}\n<\/pre>","f38bcf0a":"An inverted index is something that we usually found at the end of books, to find in which pages a given keyword is writen. The picture below illustrates the process of extracting an inverted index from a collection of text documents.\n\n<img src=\"http:\/\/2.bp.blogspot.com\/_J9MP4B6pAZw\/TLRkm-m6itI\/AAAAAAAABQA\/CP9j7zENK3M\/s1600\/invertedIndex.jpg\"\/>\nImage source: http:\/\/th30z.blogspot.com\/2010\/10\/python-inverted-index-for-dummies.html","be067bf2":"## 1.2 Term-document frequency\n\nAn important processing step of a *search engine* is to build a term-document frequency table, counting the number of occurrences (or a boolean version) each term (or word) occurs in each document (or file). \n\nWe illustrate this in the piece of code below. For simplification, we use a scikit-learn builtin function [CountVectorizer](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.feature_extraction.text.CountVectorizer.html) to achieve this.\n","fbfd31e8":"* $ \\mbox{Tf-Idf}_{i,d} = \\mbox{Tf}_{i,d} \\cdot \\mbox{Idf}_{i} $\n\n* $ \\mbox{Tf}_{i,d} = 1 + log(f_{i,d}) $, where $f_{i,d}$ is how many times term $i$ occurs in document $d$\n\n* $ \\mbox{Idf}_{i,d} = log(N \/ n_{t}) $, where $N$ is the number of documents of Collection and $n_{t}$ is the number of documents the term occurs \n\n\nThen, we compute the relevance of a document to a specific query adding weights of each term of query present in each document:\n\n* $ Score_{q,d} = \\sum_{t \\in q \\cap d} \\mbox{Tf-Idf}_{t,d} $\n\n\nSee https:\/\/en.wikipedia.org\/wiki\/Tf%E2%80%93idf"}}