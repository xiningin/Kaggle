{"cell_type":{"14fe5ba3":"code","40aafe66":"code","b6253e0b":"code","02d3f1d0":"code","e03167e2":"code","d495b528":"code","f2e79f34":"code","a503cecc":"code","6455b3d1":"code","9e13f324":"code","5f29322f":"code","e3c24c48":"code","4de3f755":"code","655951c3":"code","aa821272":"code","bf9f45a9":"code","365bd5c3":"code","95e33601":"code","80158dd6":"code","4ddf9090":"code","f84a246a":"code","c3f22e76":"code","42623837":"code","86d06b8e":"code","31da935a":"code","21737ee5":"code","9f2a5977":"code","15602fed":"code","9f3a0967":"code","618e80b2":"code","4677079c":"code","c525ec3b":"markdown","32891faa":"markdown","4670a584":"markdown","12704718":"markdown","e4492dae":"markdown","9a8170c3":"markdown","8702f9a2":"markdown","d4990f60":"markdown","e50e160a":"markdown","e48abf2b":"markdown","8ac31b2e":"markdown","dccf77ce":"markdown","57852b0e":"markdown","7bdb90f6":"markdown","6b4bc2a7":"markdown","274bc673":"markdown","45cdbe6a":"markdown","b017a42e":"markdown","b014b75e":"markdown","c2139cb3":"markdown","01bda767":"markdown","b97ad09d":"markdown","65a15db9":"markdown","b4ab0662":"markdown","10957013":"markdown","8bb17ea9":"markdown","a2873489":"markdown","25400d0a":"markdown","82144c20":"markdown","1df54048":"markdown","4e619e83":"markdown","b71c82e2":"markdown","45df7495":"markdown","98d63377":"markdown","bc2e9e4b":"markdown","242e50b1":"markdown","0f889edd":"markdown","de995b26":"markdown","584a7358":"markdown"},"source":{"14fe5ba3":"import matplotlib.pyplot as plt\nimport matplotlib.image as img\n  \ntestImage = img.imread('..\/input\/plant-pathology-2021-fgvc8\/train_images\/8002cb321f8bfcdf.jpg')\n  \n# displaying the image\nplt.imshow(testImage)","40aafe66":"from matplotlib import pyplot as plt\n\ndef show_image(image, title='Image', cmap_type='gray'): \n  plt.imshow(image, cmap=cmap_type)\n  plt.title(title)\n  plt.axis('off')\n  plt.show()","b6253e0b":"leaf_image = img.imread('..\/input\/plant-pathology-2021-fgvc8\/train_images\/8002cb321f8bfcdf.jpg')\nshow_image(leaf_image, 'Original Image')","02d3f1d0":"from skimage import color\nleaf_image_gray = color.rgb2gray(leaf_image)\nshow_image(leaf_image_gray)","e03167e2":"red = leaf_image[:, :, 0] # using the red channel of the rocket image.\n\nplt.hist(red.ravel(), bins=256) # plot its histogram with 256 bins, the number of possible values of a pixel.\nplt.title('Red Histogram')\nplt.show","d495b528":"import cv2\nleaf_img= cv2.imread('..\/input\/plant-pathology-2021-fgvc8\/train_images\/8002cb321f8bfcdf.jpg')\ngrayimg = cv2.cvtColor(leaf_img,cv2.COLOR_BGR2GRAY)","f2e79f34":"plt.imshow(grayimg,cmap='gray') #cmap has been used as matplotlib uses some default colormap to plot grayscale images\nplt.xticks([]) #To get rid of the x-ticks and y-ticks on the image axis\nplt.yticks([])\nprint('New Image Shape',grayimg.shape)","a503cecc":"#Finding optimal threshold\nfrom skimage.filters import threshold_otsu\nthresh_val = threshold_otsu(grayimg)\nprint('The optimal seperation value is',thresh_val)","6455b3d1":"thresh = 120 # set a random thresh value\n\nbinary_high = grayimg > thresh_val\nbinary_low = grayimg <= thresh_val\n\nshow_image(binary_high, 'Tresholded high values')\nshow_image(binary_low, 'Tresholded low values')","9e13f324":"from skimage.filters import try_all_threshold\n\nfig, ax = try_all_threshold(grayimg, verbose=False)","5f29322f":"from skimage.filters import threshold_otsu\n\nthresh = threshold_otsu(grayimg)\n\ntext_binary_otsu = grayimg > thresh\n\nshow_image(text_binary_otsu, 'Otsu algorithm')","e3c24c48":"def plot_comparison(original, filtered, title_filtered):\n  fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(8, 6), sharex=True, sharey=True)\n  ax1.imshow(original, cmap=plt.cm.gray) \n  ax1.set_title('original') \n  ax1.axis('off')\n  ax2.imshow(filtered, cmap=plt.cm.gray) \n  ax2.set_title(title_filtered) \n  ax2.axis('off')","4de3f755":"from skimage.filters import sobel\n\nedge_image = sobel(grayimg) # apply the filter\n\nplot_comparison(grayimg, edge_image, 'Edge image')","655951c3":"from skimage.filters import gaussian\nsmooth_leaf_image = gaussian(leaf_img, multichannel=True) # you have to specify the multichannel\n\nplot_comparison(leaf_img, smooth_leaf_image, 'Smooth leaf')","aa821272":"from skimage import exposure\nequalized_leaf_image = exposure.equalize_hist(leaf_img)\n\nplot_comparison(leaf_img, equalized_leaf_image, 'Histogram equalization')","bf9f45a9":"from skimage import exposure\n\nadapthits_leag_image = exposure.equalize_adapthist(leaf_img)\n\nplot_comparison(leaf_img, adapthits_leag_image, 'Adaptive Histogram equalization')","365bd5c3":"def show_image_contour(image, contours):\n    plt.figure()\n    for n, contour in enumerate(contours):\n        plt.plot(contour[:, 1], contour[:, 0], linewidth=3)\n    plt.imshow(image, interpolation='nearest', cmap='gray_r')\n    plt.title('Contours')\n    plt.axis('off')\n    plt.show()","95e33601":"from skimage import measure\n\n\n\ncontours_gray_image = measure.find_contours(grayimg, 0.8)\n\nshow_image_contour(grayimg, contours_gray_image)","80158dd6":"from skimage.feature import canny\ncanny_leaf_image = canny(grayimg)\n\nshow_image(canny_leaf_image)","4ddf9090":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport PIL\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport random\nfrom tqdm import tqdm\nimport tensorflow_addons as tfa\nimport random\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, smart_resize\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.constraints import maxnorm\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport cv2\nfrom PIL import Image\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.models import load_model\nfrom keras.metrics import AUC\n\npd.set_option(\"display.max_columns\", None)","f84a246a":"train_dir= '..\/input\/plant-pathology-2021-fgvc8\/train_images'\ntest_dir =  '..\/input\/plant-pathology-2021-fgvc8\/test_images'\ntrain = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')\n#print(len(train))\n#print(train.columns)\n# print(train['labels'].value_counts())\n#print(train['labels'].value_counts().plot.bar())","c3f22e76":"train.head","42623837":"train['labels'].value_counts()","86d06b8e":"plt.figure(figsize=(20,12))\nlabels = sns.barplot(train.labels.value_counts().index,train.labels.value_counts())\nfor item in labels.get_xticklabels():\n    item.set_rotation(45)","31da935a":"train['labels'] = train['labels'].apply(lambda string: string.split(' '))\ntrain","21737ee5":"s = list(train['labels'])\nmlb = MultiLabelBinarizer()\ntrainx = pd.DataFrame(mlb.fit_transform(s), columns=mlb.classes_, index=train.index)\nprint(trainx.columns)\n","9f2a5977":"print(trainx.sum())","15602fed":"labels = list(trainx.sum().keys())\n#print(labels)\nlabel_counts = trainx.sum().values.tolist()\n\nfig, ax = plt.subplots(1,1, figsize=(20,6))\n\nsns.barplot(x= labels, y= label_counts, ax=ax)","9f3a0967":"labels = pd.concat([train['image'], trainx], axis=1)\nlabels.head()","618e80b2":"fig1 = plt.figure(figsize=(20,10))\n\nfor i in range(1, 10):\n    \n    rand =  random.randrange(1, 18000)\n    sample = os.path.join('..\/input\/plant-pathology-2021-fgvc8\/train_images\/', train['image'][rand])\n    \n    img = PIL.Image.open(sample)\n    \n    ax = fig1.add_subplot(4,3,i)\n    ax.imshow(img)\n    \n    title = f\"{train['labels'][rand]}{img.size}\"\n    plt.title(title)\n    \n    fig1.tight_layout()\n","4677079c":"%%time\ndatagen = keras.preprocessing.image.ImageDataGenerator(rescale=1\/255.0,\n                                                        preprocessing_function=None,\n                                                        data_format=None,\n                                                    )\n\ntrain_data = datagen.flow_from_dataframe(\n    train,\n    directory= '..\/input\/resized-plant2021\/img_sz_512',\n    x_col=\"image\",\n    y_col= 'labels',\n    color_mode=\"rgb\",\n    target_size = (256,256),\n    class_mode=\"categorical\",\n    batch_size=32,\n    shuffle=False,\n    seed=40,\n)","c525ec3b":"So there are not 12 labels, its actually just 6 labels.\n5 diseases: \n1. rust\n2. scab \n3. complex \n4. frog eye leaf spot\n5. powdery mildew \n\nand another label is \n\n6. healthy (healthy leaves) \n\nNow the most important thing is, as one image can have multiple diseases, that means this problem is **Multi label classification** problem. Many get confused betweeen multilabel and multiclass classification. if you are new to multilabel classification I would suggest going over this [An introduction to MultiLabel classification](https:\/\/www.geeksforgeeks.org\/an-introduction-to-multilabel-classification\/) . \n\nSo now we gotta process the labels. And then lets find out the actual frequencies of the labels. \n","32891faa":"# Applying Edge Detection Techniques on The Image","4670a584":"# Grayscale Image","12704718":"# Import the necessary libraries","e4492dae":"# **Specific Objectives**\n\nThe main objective of the competition is to develop machine learning-based models to accurately classify a given leaf image from the test dataset to a particular disease category, and to identify an individual disease from multiple disease symptoms on a single leaf image.","9a8170c3":"**We see that Iso data , Mean and Otsu , dives better results than the others so let us look at Otsu Thresholding**","8702f9a2":"**Note**\n\nNotice that there is a huge imbalance in dataset with \"scab\" having the highest number of frequency and \"powdery_mildew complex\" , the least","d4990f60":"# If you liked the Notebook Please Upvote It ! ","e50e160a":"**ADAPTIVE HISTOGRAM EQUALISATION**","e48abf2b":"**Grayscale Image**","8ac31b2e":"It seems to have a better representation of the image","dccf77ce":"# Let's See the Plant Pathology Images","57852b0e":"# Let Us See an Image","7bdb90f6":"**Interestingly it shows The Focused Leaf Properly**","6b4bc2a7":"# Imaze Size & Processing\nfrom the titles we can see some random image sizes - (4000, 2672). Larger images are harder to process hence takes much longer to train the CNN. Downsampling all these 18632 images is also a time consuming task. This is I am going to use the resized imaged for this dataset [resized-plant2021](https:\/\/www.kaggle.com\/ankursingh12\/resized-plant2021) by Ankur Singh. He has already downsampled the images into size of 256, 384, 512 & 640px.\nNow for Pre Processing I take help of the [Keras Image Data Generator](http:\/\/https:\/\/keras.io\/api\/preprocessing\/image\/). We transform it to size of (256,256,3) .","274bc673":"# Applying Thresholding Algorithms ","45cdbe6a":"Converting the labels representation into **one hot encoded format** using MultilabelBinarizer from Scikit learn. Now we can see and plot the frequencies of each label. ","b017a42e":"We divide it based on \" \" or space character , in order to get the labels for each of the image","b014b75e":"**NOW WE CAN SEE THE DATASET BECOMES MORE OR LESS BALANCED , AT LEAST BETTER THAN WHAT IT WAS PREVIOUSLY!**","c2139cb3":"**Trying All Thresholded Values**","01bda767":"# Let Us Look at the Smoothening Features ","b97ad09d":"**We get to know that we have \"many\" images with mostly 12 types of labels (but there is a twist) which we will comeback to later.**","65a15db9":"**Sobel Operator**","b4ab0662":"# Now Let Us Finally Look at the Contour Methods","10957013":"# **What is this about?**\n\nApples are one of the most important temperate fruit crops in the world. Foliar (leaf) diseases pose a major threat to the overall productivity and quality of apple orchards. The current process for disease diagnosis in apple orchards is based on manual scouting by humans, which is time-consuming and expensive.\n\nAlthough computer vision-based models have shown promise for plant disease identification, there are some limitations that need to be addressed. Large variations in visual symptoms of a single disease across different apple cultivars, or new varieties that originated under cultivation, are major challenges for computer vision-based disease identification. These variations arise from differences in natural and image capturing environments, for example, leaf color and leaf morphology, the age of infected tissues, non-uniform image background, and different light illumination during imaging etc.\n\nPlant Pathology 2020-FGVC7 challenge competition had a pilot dataset of 3,651 RGB images of foliar disease of apples. For Plant Pathology 2021-FGVC8, we have significantly increased the number of foliar disease images and added additional disease categories. This year\u2019s dataset contains approximately 23,000 high-quality RGB images of apple foliar diseases, including a large expert-annotated disease dataset. This dataset reflects real field scenarios by representing non-homogeneous backgrounds of leaf images taken at different maturity stages and at different times of day under different focal camera settings.\n\n\n\n","8bb17ea9":"# Important Observation\n\n**Look at the labels, doesn't it strike you ??** \n\n**Some of the labels are mixture of one or more types !!! And thus the problem becomes Multilabel Problem**\n","a2873489":"# Let Us See The Histogram Of An Image","25400d0a":"# Edge Detection","82144c20":"These are the 6 different labels ","1df54048":"# Let's Study the dataset in a better way and try to find some interesting stuff!!! ","4e619e83":"We notice that the frequency of the pixels varies between 25 to 250 , with most of it being in the region between 100 to 175 approximately","b71c82e2":"Let's look at the number of images for various of 12 categories present","45df7495":"**Note the leaves become more prominent by Histogram Equalization Techniques**","98d63377":"# **Resources**\nI thank Kaggle for providing the dataset and [Data](http:\/\/https:\/\/bsapubs.onlinelibrary.wiley.com\/doi\/10.1002\/aps3.11390)\nwithout whom this wouldn't have been Possible. \nAlso I would like to thank [Ankur Singh](http:\/\/https:\/\/www.kaggle.com\/ankursingh12\/resized-plant2021) for this amazing dataset as without it , it would have taken hours and hours to train the below mentioned model. ","bc2e9e4b":"# **Let's Now Have a look at the Dataset and Study it better**\n\nI would like to thank [Praveen](http:\/\/https:\/\/www.kaggle.com\/praveengovi\/plant-pathology-detail-eda-pytorch) for this amazing EDA and analysis and also [Arnab](http:\/\/https:\/\/www.kaggle.com\/arnabs007\/apple-leaf-diseases-with-inceptionresnetv2-keras) from whom I have taken reference from . I have implemented various EDA and studied from their models and approached it with Transfer Learning Model of ResNet 50v2 base.\n ","242e50b1":"**We Can Now safely say , Sobel Operator , doesn't work on the image**","0f889edd":"# **Let Us Perform Some Image Operations that We Can Perform on This Image**","de995b26":"# Thank You","584a7358":"# Contrast Enhancement Techniques"}}