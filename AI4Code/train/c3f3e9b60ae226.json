{"cell_type":{"361acc39":"code","7d1217d7":"code","c7962d32":"code","890f258e":"code","523854f3":"code","299eeb90":"code","d7054298":"code","160d61e5":"code","d7572376":"code","78e63b66":"code","b546408a":"code","2c05cd21":"code","301d94f2":"code","bfbaaf4d":"markdown","373d4f0c":"markdown","22a6aa38":"markdown","cd526baf":"markdown","691d9df2":"markdown","4b4c81f8":"markdown","6c75930d":"markdown","93c25a54":"markdown"},"source":{"361acc39":"%matplotlib inline \nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image\n\n\ndata_train_dir = r'..\/input\/train'\nanswer_file_path = r'..\/input\/train.csv'\n\nchannels = ['_yellow', '_red', '_green', '_blue']\n\nindex_class_dict = {\n    0: \"Nucleoplasm\",\n    1: \"Nuclear membrane\",\n    2: \"Nucleoli\",\n    3: \"Nucleoli fibrillar center\",\n    4: \"Nuclear speckles\",\n    5: \"Nuclear bodies\",\n    6: \"Endoplasmic reticulum\",\n    7: \"Golgi apparatus\",\n    8: \"Peroxisomes\",\n    9: \"Endosomes\",\n    10: \"Lysosomes\",\n    11: \"Intermediate filaments\",\n    12: \"Actin filaments\",\n    13: \"Focal adhesion sites\",\n    14: \"Microtubules\",\n    15: \"Microtubule ends\",\n    16: \"Cytokinetic bridge\",\n    17: \"Mitotic spindle\",\n    18: \"Microtubule organizing center\",\n    19: \"Centrosome\",\n    20: \"Lipid droplets\",\n    21: \"Plasma membrane\",\n    22: \"Cell junctions\",\n    23: \"Mitochondria\",\n    24: \"Aggresome\",\n    25: \"Cytosol\",\n    26: \"Cytoplasmic bodies\",\n    27: \"Rods & rings\"\n}\n","7d1217d7":"train_df = pd.read_csv(answer_file_path)\ntrain_df.head()","c7962d32":"train_df[f'target_vec'] = train_df['Target'].map(lambda x: list(map(int, x.strip().split())))\nfor i in range(28):\n    train_df[f'{index_class_dict[i]}'] = train_df['Target'].map(\n             lambda x: 1 if str(i) in x.strip().split() else 0)\ntrain_df.head()\n","890f258e":"class_index = 1  # Nuclear membrane\ncurrent_part = train_df[train_df[index_class_dict[class_index]] == 1]\nprint(f'shape before {train_df.shape}, shape after {current_part.shape}')\ncurrent_part.head()","523854f3":"def make_rgb_image_from_four_channels(channels: list, image_width=512, image_height=512) -> np.ndarray:\n    \"\"\"\n    It makes literally RGB image from source four channels, \n    where yellow image will be yellow color, red will be red and so on  \n    \"\"\"\n    rgb_image = np.zeros(shape=(image_height, image_width, 3), dtype=np.float)\n    yellow = np.array(Image.open(channels[0]))\n    # yellow is red + green\n    rgb_image[:, :, 0] += yellow\/2   \n    rgb_image[:, :, 1] += yellow\/2\n    # loop for R,G and B channels\n    for index, channel in enumerate(channels[1:]):\n        current_image = Image.open(channel)\n        rgb_image[:, :, index] += current_image\n    # Normalize image\n    rgb_image = rgb_image \/ rgb_image.max() * 255\n    return rgb_image.astype(np.uint8)","299eeb90":"def visualize_part(start_class_index=0, nrows=4, ncols=3):\n    \"\"\"\n    Visualize the part of classes, started from class with index start_class_index,\n    make nrows classes, ncols examples for each one\n    \"\"\"\n    fig, ax = plt.subplots(nrows = nrows, ncols=ncols, figsize=(15, 25))\n    for class_index in range(nrows):\n        current_index = class_index + start_class_index\n        for sample in range(ncols):\n            current_part = train_df[train_df[index_class_dict[current_index]] == 1] \n            # 0 index is id\n            random_index = np.random.choice(current_part.values.shape[0], 1, replace=False)\n            # random line from data with selected class\n            current_line = current_part.values[random_index][0]\n            image_names = [os.path.join(data_train_dir, current_line[0]) \n                           + x + '.png' for x in channels]\n            rgb_image = make_rgb_image_from_four_channels(image_names)\n            # text annotations, main title and subclasses (may be empty in case one label)\n            main_class = index_class_dict[current_index]+'\\n'\n            # 2 index is vector with classes, split version of Target col\n            other_classes = [index_class_dict[x] for x in current_line[2] \n                             if x != (current_index)]\n            subtitle = ', '.join(other_classes)\n            # show image\n            ax[class_index, sample].set_title(main_class, fontsize=18)\n            ax[class_index, sample].text(250, -10, subtitle, \n                                         fontsize=14, horizontalalignment='center')\n            ax[class_index, sample].imshow(rgb_image)\n            ax[class_index, sample].set_xticklabels([])\n            ax[class_index, sample].set_yticklabels([])\n            ax[class_index, sample].tick_params(left=False, bottom=False)\n","d7054298":"visualize_part(0)","160d61e5":"visualize_part(4)","d7572376":"visualize_part(8)","78e63b66":"visualize_part(12)","b546408a":"visualize_part(16)","2c05cd21":"visualize_part(20)","301d94f2":"visualize_part(24)","bfbaaf4d":"## Create cols for each class:","373d4f0c":"## Let's visualize 3 examples for each class:","22a6aa38":"## Load data:","cd526baf":"## Conclusion\nIn fact, I don't see any special features for each class and don't understand what differences really are. Provably, addition of yellow channel is a bad idea (yellow color is red + green) or we have to analyse only green one, but I did't get good results in my experiments yet. I guess I will allow to network choose the correct features.","691d9df2":"## Introduction\nThe hypothesis: if we visualize a few examples for each class, we will get the visual patterns for each class.\n\nAlso, we will get the method for merge channels into one image","4b4c81f8":"## Functions for visualization:","6c75930d":"## Imports and constants:","93c25a54":"## Get part of data with specific class:"}}