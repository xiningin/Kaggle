{"cell_type":{"130c1d4e":"code","83d02f4b":"code","6dcf6e71":"code","d5140e54":"code","a51df2db":"code","a0860402":"code","0d425b06":"code","fa9a7201":"code","89a6d6b5":"code","874e1628":"code","26fef224":"code","b59301a8":"code","505b3957":"code","00c03c2a":"code","f1661fdb":"markdown","0266baae":"markdown","4e545b5b":"markdown","d3c1fb97":"markdown"},"source":{"130c1d4e":"# Libraries\nimport numpy as np\nimport pandas as pd\n\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances\n\nfrom IPython.display import display","83d02f4b":"# Read data\ntrain = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/train.csv', index_col=0)\ntest = pd.read_csv('..\/input\/tabular-playground-series-mar-2021\/test.csv', index_col=0)","6dcf6e71":"# Predictors & target\npredictors = train.columns[:-1]\ntarget = train.columns[-1]","d5140e54":"# Data processing\ncat_cols = [col for col in predictors if 'cat' in col]\n\ntrain[cat_cols] = train[cat_cols].astype('category')\ntrain[target] = train[target].astype('category')\n\ntest[cat_cols] = test[cat_cols].astype('category')","a51df2db":"# Functions for KFold evaluation\ndef create(hyperparams):\n    \"\"\"Create LGBM Classifier for a given set of hyper-parameters.\"\"\"\n    model = LGBMClassifier(**hyperparams)\n    return model\n\ndef fit(model, X, y):\n    \"\"\"Simple training of a given model.\"\"\"\n    model.fit(X, y)\n    return model\n\ndef fit_with_stop(model, X, y, X_val, y_val, esr):\n    \"\"\"Advanced training with early stopping.\"\"\"\n    model.fit(X, y,\n              eval_set=(X_val, y_val),\n              early_stopping_rounds=esr, \n              verbose=200)\n    return model\n\ndef evaluate(model, X, y):\n    \"\"\"Compute AUC for a given model.\"\"\"\n    yp = model.predict_proba(X)[:, 1]\n    auc_score = roc_auc_score(y, yp)\n    return auc_score\n\ndef kfold_evaluation(X, y, k, hyperparams, esr=100):\n    \"\"\"Run a KFlod evaluation.\"\"\"\n    scores = []\n    \n    print(f\"\\n------ {k}-fold evaluation -----\")\n    print(hyperparams)\n    \n    kf = KFold(k)\n    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n        print(f\"\\n----- FOLD {i} -----\")\n        \n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[test_idx]\n        y_val = y.iloc[test_idx]\n        \n        model = create(hyperparams)\n        model = fit_with_stop(model, X_train, y_train, X_val, y_val, esr)\n        train_score = evaluate(model, X_train, y_train)\n        val_score = evaluate(model, X_val, y_val)\n        scores.append((train_score, val_score))\n        \n        print(f\"Fold {i} | Eval AUC: {val_score}\")\n        \n        \n    scores = pd.DataFrame(scores, columns=['train score', 'validation score'])\n    \n    return scores\n\ndef kfold_prediction(X, y, X_test, k, hyperparams, esr=100):\n    \"\"\"Make predictions with a bagged model based on KFold.\"\"\"\n    yp = np.zeros(len(X_test))\n    \n    print(f\"\\n------ {k}-fold evaluation -----\")\n    print(hyperparams)\n    \n    kf = KFold(k)\n    for i, (train_idx, test_idx) in enumerate(kf.split(X)):\n        print(f\"\\n----- FOLD {i} -----\")\n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[test_idx]\n        y_val = y.iloc[test_idx]\n        \n        model = create(hyperparams)\n        model = fit_with_stop(model, X_train, y_train, X_val, y_val, esr)\n        yp += model.predict_proba(X_test)[:, 1] \/ k\n    \n    return yp","a0860402":"# Constant\nK = 10\nX = train[predictors]\nY = train[target]\nX_TEST = test[predictors]\nBEST_PARAMS = {\n    'n_estimators': 10000, # Waiting for early-stopping\n    'learning_rate': 0.05, # Me\n    'metric': 'auc' # Me\n}","0d425b06":"# Objective function\ndef objective(trial):\n    # Search spaces\n    hyperparams = {\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 10.0),\n        'num_leaves': trial.suggest_int('num_leaves', 5, 1000),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n        'max_depth': trial.suggest_int('max_depth', 5, 64),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 0.5),\n        'cat_smooth' : trial.suggest_int('cat_smooth', 10, 100),\n        'cat_l2': trial.suggest_int('cat_l2', 1, 20),\n        'min_data_per_group': trial.suggest_int('min_data_per_group', 50, 200)\n    }\n    \n    # Add BEST_PARAMS\n    hyperparams.update(BEST_PARAMS)\n    \n    # Evaluation\n    scores = kfold_evaluation(X, Y, K, hyperparams, 100)\n    \n    return scores['validation score'].mean()","fa9a7201":"# Optimization\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, timeout=3600*7)","89a6d6b5":"# Best score\nstudy.best_value","874e1628":"# Historic\nplot_optimization_history(study)","26fef224":"# Importance\nplot_param_importances(study)","b59301a8":"# Best parameters\nBEST_PARAMS.update(study.best_params)\nBEST_PARAMS","505b3957":"# Update hyperparams for prediction\nBEST_PARAMS['learning_rate'] = 0.005","00c03c2a":"# Predictions on test set and submission\ntest[target] = kfold_prediction(X, Y, X_TEST, 10, BEST_PARAMS, 500)\ntest[target].to_csv('submission.csv')","f1661fdb":"## Setup","0266baae":"## Submision","4e545b5b":"## Functions for training, evaluation and prediction","d3c1fb97":"## Optuna Tuning"}}