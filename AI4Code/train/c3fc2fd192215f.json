{"cell_type":{"9a8aafa2":"code","b05c55b3":"code","65ebec68":"code","8c8b22ac":"code","9eed720c":"code","5079abf0":"code","2d5e2860":"code","b4d87434":"code","f44fc39c":"code","5b019a43":"code","c05151ac":"code","38d8abc7":"code","57b461b3":"code","4af9417d":"code","3d61fb29":"code","eaa23d8b":"code","72f1498f":"code","02081225":"code","827c711b":"code","e04240e8":"code","41a78cbc":"code","73fd999c":"code","7ce318de":"code","5a5f848d":"code","f9148c73":"markdown","16cadac1":"markdown","7b078aff":"markdown","ae742cc5":"markdown","527eb05b":"markdown","6b77330f":"markdown","18474d23":"markdown","78df9a93":"markdown","e449fccd":"markdown","be442aeb":"markdown","086476c1":"markdown","cfadbab1":"markdown"},"source":{"9a8aafa2":"import pandas as pd\nimport numpy as np\nimport random\nimport os\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n\nimport lightgbm as lgb\nimport catboost as ctb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\n\nimport graphviz\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter('ignore')","b05c55b3":"TARGET = 'Survived'\n\nN_ESTIMATORS = 1000\nN_SPLITS = 10\nSEED = 2021\nEARLY_STOPPING_ROUNDS = 100\nVERBOSE = 100","65ebec68":"def set_seed(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nset_seed(SEED)","8c8b22ac":"train_df = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest_df = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\nsubmission = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv')\ntest_df[TARGET] = pd.read_csv(\"..\/input\/tps-apr-2021-label\/pseudo_label.csv\")[TARGET]\n\nall_df = pd.concat([train_df, test_df]).reset_index(drop=True)","9eed720c":"# Age fillna with mean age for each class\nall_df['Age'] = all_df['Age'].fillna(all_df['Age'].mean())\n\n# Cabin, fillna with 'X' and take first letter\nall_df['Cabin'] = all_df['Cabin'].fillna('X').map(lambda x: x[0].strip())\n\n# Ticket, fillna with 'X', split string and take first split \nall_df['Ticket'] = all_df['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n\n# Fare, fillna with mean value\nfare_map = all_df[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\nall_df['Fare'] = all_df['Fare'].fillna(all_df['Pclass'].map(fare_map['Fare']))\nall_df['Fare'] = np.log1p(all_df['Fare'])\n\n# Embarked, fillna with 'X' value\nall_df['Embarked'] = all_df['Embarked'].fillna('X')\n\n# Name, take only surnames\nall_df['Name'] = all_df['Name'].map(lambda x: x.split(',')[0])","5079abf0":"label_cols = ['Name', 'Ticket', 'Sex']\nonehot_cols = ['Cabin', 'Embarked']\nnumerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']","2d5e2860":"def label_encoder(c):\n    le = LabelEncoder()\n    return le.fit_transform(c)\n\nscaler = StandardScaler()\n\nonehot_encoded_df = pd.get_dummies(all_df[onehot_cols])\nlabel_encoded_df = all_df[label_cols].apply(label_encoder)\nnumerical_df = pd.DataFrame(scaler.fit_transform(all_df[numerical_cols]), columns=numerical_cols)\ntarget_df = all_df[TARGET]\n\nall_df = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df], axis=1)","b4d87434":"params = {\n    'metric': 'binary_logloss',\n    'n_estimators': N_ESTIMATORS,\n    'objective': 'binary',\n    'random_state': SEED,\n    'learning_rate': 0.01,\n    'min_child_samples': 150,\n    'reg_alpha': 3e-5,\n    'reg_lambda': 9e-2,\n    'num_leaves': 20,\n    'max_depth': 16,\n    'colsample_bytree': 0.8,\n    'subsample': 0.8,\n    'subsample_freq': 2,\n    'max_bin': 240,\n}","f44fc39c":"lgb_oof = np.zeros(train_df.shape[0])\nlgb_preds = np.zeros(test_df.shape[0])\nfeature_importances = pd.DataFrame()\n\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(all_df, all_df[TARGET])):\n    print(f\"===== FOLD {fold} =====\")\n    oof_idx = np.array([idx for idx in valid_idx if idx < train_df.shape[0]])\n    preds_idx = np.array([idx for idx in valid_idx if idx >= train_df.shape[0]])\n\n    X_train, y_train = all_df.iloc[train_idx].drop(TARGET, axis=1), all_df.iloc[train_idx][TARGET]\n    X_valid, y_valid = all_df.iloc[oof_idx].drop(TARGET, axis=1), all_df.iloc[oof_idx][TARGET]\n    X_test = all_df.iloc[preds_idx].drop(TARGET, axis=1)\n    \n    pre_model = lgb.LGBMRegressor(**params)\n    pre_model.fit(\n        X_train, y_train,\n        eval_set=[(X_train, y_train),(X_valid, y_valid)],\n        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n        verbose=VERBOSE\n    )\n\n    params2 = params.copy()\n    params2['learning_rate'] = params['learning_rate'] * 0.1\n    model = lgb.LGBMRegressor(**params2)\n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_train, y_train),(X_valid, y_valid)],\n        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n        verbose=VERBOSE,\n        init_model=pre_model\n    )\n    \n    fi_tmp = pd.DataFrame()\n    fi_tmp[\"feature\"] = model.feature_name_\n    fi_tmp[\"importance\"] = model.feature_importances_\n    fi_tmp[\"fold\"] = fold\n    fi_tmp[\"seed\"] = SEED\n    feature_importances = feature_importances.append(fi_tmp)\n    \n    lgb_oof[oof_idx] = model.predict(X_valid)\n    lgb_preds[preds_idx-train_df.shape[0]] = model.predict(X_test)\n    \n    acc_score = accuracy_score(y_valid, np.where(lgb_oof[oof_idx]>0.5, 1, 0))\n    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n    \nacc_score = accuracy_score(all_df[:train_df.shape[0]][TARGET], np.where(lgb_oof>0.5, 1, 0))\nprint(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")","5b019a43":"# just to get ideas to improve\norder = list(feature_importances.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\nplt.figure(figsize=(10, 10))\nsns.barplot(x=\"importance\", y=\"feature\", data=feature_importances, order=order)\nplt.title(\"{} importance\".format(\"LGBMRegressor\"))\nplt.tight_layout()","c05151ac":"params = {\n    'bootstrap_type': 'Poisson',\n    'loss_function': 'Logloss',\n    'eval_metric': 'Logloss',\n    'random_seed': SEED,\n    'task_type': 'GPU',\n    'max_depth': 8,\n    'learning_rate': 0.01,\n    'n_estimators': N_ESTIMATORS,\n    'max_bin': 280,\n    'min_data_in_leaf': 64,\n    'l2_leaf_reg': 0.01,\n    'subsample': 0.8\n}","38d8abc7":"ctb_oof = np.zeros(train_df.shape[0])\nctb_preds = np.zeros(test_df.shape[0])\nfeature_importances = pd.DataFrame()\n\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(all_df, all_df[TARGET])):\n    print(f\"===== FOLD {fold} =====\")\n    oof_idx = np.array([idx for idx in valid_idx if idx < train_df.shape[0]])\n    preds_idx = np.array([idx for idx in valid_idx if idx >= train_df.shape[0]])\n\n    X_train, y_train = all_df.iloc[train_idx].drop(TARGET, axis=1), all_df.iloc[train_idx][TARGET]\n    X_valid, y_valid = all_df.iloc[oof_idx].drop(TARGET, axis=1), all_df.iloc[oof_idx][TARGET]\n    X_test = all_df.iloc[preds_idx].drop(TARGET, axis=1)\n    \n    model = ctb.CatBoostClassifier(**params)\n    model.fit(X_train, y_train,\n              eval_set=[(X_valid, y_valid)],\n              use_best_model=True,\n              early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n              verbose=VERBOSE\n              )\n    \n    fi_tmp = pd.DataFrame()\n    fi_tmp[\"feature\"] = X_test.columns.to_list()\n    fi_tmp[\"importance\"] = model.get_feature_importance()\n    fi_tmp[\"fold\"] = fold\n    fi_tmp[\"seed\"] = SEED\n    feature_importances = feature_importances.append(fi_tmp)\n    \n    ctb_oof[oof_idx] = model.predict(X_valid)\n    ctb_preds[preds_idx-train_df.shape[0]] = model.predict(X_test)\n    \n    acc_score = accuracy_score(y_valid, np.where(ctb_oof[oof_idx]>0.5, 1, 0))\n    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n    \nacc_score = accuracy_score(all_df[:train_df.shape[0]][TARGET], np.where(ctb_oof>0.5, 1, 0))\nprint(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")","57b461b3":"# just to get ideas to improve\norder = list(feature_importances.groupby(\"feature\").mean().sort_values(\"importance\", ascending=False).index)\nplt.figure(figsize=(10, 10))\nsns.barplot(x=\"importance\", y=\"feature\", data=feature_importances, order=order)\nplt.title(\"{} importance\".format(\"CatBoostClassifier\"))\nplt.tight_layout()","4af9417d":"# Tuning the DecisionTreeClassifier by the GridSearchCV\nparameters = {\n    'max_depth': np.arange(2, 5, dtype=int),\n    'min_samples_leaf':  np.arange(2, 5, dtype=int)\n}\n\nclassifier = DecisionTreeClassifier(random_state=2021)\n\nmodel = GridSearchCV(\n    estimator=classifier,\n    param_grid=parameters,\n    scoring='accuracy',\n    cv=10,\n    n_jobs=-1)\nmodel.fit(X_train, y_train)\n\nbest_parameters = model.best_params_\nprint(best_parameters)","3d61fb29":"dtm_oof = np.zeros(train_df.shape[0])\ndtm_preds = np.zeros(test_df.shape[0])\nfeature_importances = pd.DataFrame()\n\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nfor fold, (train_idx, valid_idx) in enumerate(skf.split(all_df, all_df[TARGET])):\n    print(f\"===== FOLD {fold} =====\")\n    oof_idx = np.array([idx for idx in valid_idx if idx < train_df.shape[0]])\n    preds_idx = np.array([idx for idx in valid_idx if idx >= train_df.shape[0]])\n\n    X_train, y_train = all_df.iloc[train_idx].drop(TARGET, axis=1), all_df.iloc[train_idx][TARGET]\n    X_valid, y_valid = all_df.iloc[oof_idx].drop(TARGET, axis=1), all_df.iloc[oof_idx][TARGET]\n    X_test = all_df.iloc[preds_idx].drop(TARGET, axis=1)\n    \n    model = DecisionTreeClassifier(\n        max_depth=best_parameters['max_depth'],\n        min_samples_leaf=best_parameters['min_samples_leaf'],\n        random_state=SEED\n    )\n    model.fit(X_train, y_train)\n    \n    dtm_oof[oof_idx] = model.predict(X_valid)\n    dtm_preds[preds_idx-train_df.shape[0]] = model.predict(X_test)\n    \n    acc_score = accuracy_score(y_valid, np.where(dtm_oof[oof_idx]>0.5, 1, 0))\n    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")\n    \nacc_score = accuracy_score(all_df[:train_df.shape[0]][TARGET], np.where(dtm_oof>0.5, 1, 0))\nprint(f\"===== ACCURACY SCORE {acc_score:.6f} =====\")","eaa23d8b":"# plot tree\ndot_data = export_graphviz(\n    model,\n    out_file=None,\n    feature_names=X_train.columns,\n    class_names=['0', '1'],\n    filled=True,\n    rounded=False,\n    special_characters=True,\n    precision=3\n)\ngraph = graphviz.Source(dot_data)\ngraph ","72f1498f":"submission['submit_lgb'] = np.where(lgb_preds>0.5, 1, 0)\nsubmission['submit_ctb'] = np.where(ctb_preds>0.5, 1, 0)\nsubmission['submit_dtm'] = np.where(dtm_preds>0.5, 1, 0)","02081225":"submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis = 1).value_counts()","827c711b":"submission[TARGET] = (submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis=1) >= 2).astype(int)\nsubmission.drop([col for col in submission.columns if col.startswith('submit_')], axis=1, inplace=True)","e04240e8":"submission['submit_1'] = submission[TARGET].copy()\nsubmission['submit_2'] = pd.read_csv(\"..\/input\/tps-apr-2021-label\/dae.csv\")[TARGET]\nsubmission['submit_3'] = pd.read_csv(\"..\/input\/tps-apr-2021-label\/pseudo_label.csv\")[TARGET]","41a78cbc":"submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis = 1).value_counts()","73fd999c":"submission[TARGET] = (submission[[col for col in submission.columns if col.startswith('submit_')]].sum(axis=1) >= 2).astype(int)","7ce318de":"submission[['PassengerId', TARGET]].to_csv(\"voting_submission.csv\", index = False)","5a5f848d":"submission[TARGET].hist()","f9148c73":"# Encoding","16cadac1":"# Filling missing values","7b078aff":"### Feature importance","ae742cc5":"### Plot tree","527eb05b":"# Ensemble","6b77330f":"# Load data","18474d23":"# CatBoost","78df9a93":"### Feature importance","e449fccd":"# DecisionTreeModel","be442aeb":"# Libraries","086476c1":"# LightGBM","cfadbab1":"# Ensemble\/Submission"}}