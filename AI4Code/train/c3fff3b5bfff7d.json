{"cell_type":{"aaa20fae":"code","c03b8e80":"code","1ff616a0":"code","e2c93f02":"code","a58bf12e":"code","2cbc86fd":"code","d1bf7244":"code","8b2f3649":"code","585cd043":"code","5b2abfc7":"code","6ef14916":"code","94076a50":"code","7ba02092":"code","3071af74":"code","0f5f75a6":"code","41086d1d":"code","731f6089":"code","e846b58c":"code","dfabeeb1":"code","3d9ee528":"code","b245db44":"code","0c5deae0":"code","127fbb01":"code","71c22e54":"code","28a11a02":"code","84a3844d":"code","4e237e0b":"code","50eab9db":"code","d7ab6c29":"markdown","680891a0":"markdown","00d87951":"markdown","9acfd076":"markdown","f054ec21":"markdown","755f3373":"markdown","0b374b06":"markdown"},"source":{"aaa20fae":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib as mlp\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import cross_val_score","c03b8e80":"print(os.listdir(\"..\/input\"))\ndf = pd.read_csv(\"..\/input\/BlackFriday.csv\")\ndf.info()","1ff616a0":"df.isna().sum()","e2c93f02":"# remove categories with NaNs\ndf = df.loc[:, ~df.isna().any()]","a58bf12e":"# Top 5 users by count\nuser_counts = df.groupby('User_ID').size().reset_index(name='counts') \nuser_counts.sort_values('counts', ascending=False)[0:5]","2cbc86fd":"# Top 5 users by purchase\nuser_purchase = df[['User_ID','Purchase']].groupby('User_ID').agg('sum')\nuser_purchase.sort_values('Purchase', ascending=False)[0:5]","d1bf7244":"# Top 5 products by count\nproduct_counts = df.groupby('Product_ID').size().reset_index(name='counts') \nproduct_counts.sort_values('counts', ascending=False)[0:5]","8b2f3649":"# Top 5 cities by purchase\ncity_purchase = df[['City_Category','Purchase']].groupby('City_Category').agg('sum')\ncity_purchase.sort_values('Purchase', ascending=False)[0:5]","585cd043":"# show purchase distribution\n# we can clearly see the long tail only few customers purchase a lot\nuser_purchase.hist(bins=100) ","5b2abfc7":"# compare number of female to male customers\ndf[['User_ID', 'Gender']].drop_duplicates()\\\n                         .groupby('Gender')['Gender']\\\n                         .agg('count').plot.pie()","6ef14916":"# count customers per age group\ndf[['User_ID', 'Age']].drop_duplicates()\\\n                      .groupby('Age')['Age']\\\n                      .agg('count').plot.bar()","94076a50":"# compare married customers to not married customers\ndf[['User_ID', 'Marital_Status']].drop_duplicates()\\\n                                 .groupby('Marital_Status')['Marital_Status']\\\n                                 .agg('count').plot.pie()","7ba02092":"# prepare matrices for sklearn learners\nX = np.zeros((len(user_counts), len(product_counts)))\ny = np.zeros(len(user_counts))\n\n# map user_ids, product_ids and gender to 0,1,2,...\nuser_map =  {v: k for k,v in enumerate(np.unique(df.User_ID))} \nproduct_map =  {v: k for k,v in enumerate(np.unique(df.Product_ID))} \ngender_map = {v: k for k,v in enumerate(np.unique(df.Gender))} \n\n# for each user create a vector with ones for product he bought\nprint(\"Total transactions: {}\".format(len(df)))\nfor i in range(len(df)):\n    if i % 100000 == 0:\n        print(\"{} processed\".format(i))\n    X[user_map[df.iloc[0]['User_ID']]][product_map[df.iloc[0]['Product_ID']]] = 1\n    y[user_map[df.iloc[0]['User_ID']]] = gender_map[df.iloc[0]['Gender']]","3071af74":"# calculate sparsity\ntotal = X.size\nzeros = total - np.count_nonzero(X)\nsparsity = zeros \/ total\nprint(\"Total: {}\".format(total))\nprint(\"Zeros: {}\".format(zeros))\nprint(\"Sparsity: {}\".format(sparsity))","0f5f75a6":"# even though data is sparse random forest may be a good classifier for this problem\nscores = cross_val_score(RandomForestClassifier(n_estimators=10), X, y, cv=3)\nprint(\"Accuracy: {}\".format(np.mean(scores)))","41086d1d":"# 100% accuracy ????? Wooooooooooooooooooooooot\n# Maybe I made a mistake but seems women buy very different articles compared to man","731f6089":"# lets investigate the random forest features\nforest = RandomForestClassifier(n_estimators=10)\nforest.fit(X, y)\nimportances = forest.feature_importances_\nidx = np.argsort(importances)[::-1]\nsorted_importances = importances[idx]\nproduct_ids = np.array(list(product_map.keys()))[idx]\n\nprint(\"Best 5 features indices: {}\".format(idx[0:5]))\nprint(\"Best 5 features importances: {}\".format(sorted_importances[0:5]))\nprint(\"Best 5 features (product_ids): {}\".format(product_ids[0:5]))","e846b58c":"# mmh only one feature has a score bigger than 0.\n# let's see the male vs female ratio on that product\ndf[df.Product_ID == 'P00069042'].groupby('Gender')['Gender'].agg('count').plot.pie()","dfabeeb1":"# that's weird, I would expect a product which was only bought by man or women. \n# let's see if we can find such products ourself\nproduct_ratios = pd.DataFrame(columns=['w_ratio', 'm_ratio'], index=list(product_map.keys()))\nprint('Number of products: {}'.format(len(product_map)))\nfor pid, i in product_map.items():\n    tmp = df[df.Product_ID == pid].groupby('Gender')['Gender'].agg('count')\n    total = len(df[df.Product_ID == pid])\n    w_ratio = tmp.get('F', 0) \/ total\n    m_ratio = tmp.get('M', 0) \/ total\n    product_ratios.loc[pid]= [w_ratio, m_ratio]\n    if i % 1000 == 0:\n        print(\"{} processed\".format(i))","3d9ee528":"# products only bought by women\nw_products = product_ratios[product_ratios.w_ratio == 1].index\nprint(\"Number of products bought only by women: {}\".format(len(w_products)))\nprint(\"Examples: {}\".format(w_products[:5]))","b245db44":"# products only bought by men\nm_products = product_ratios[product_ratios.w_ratio == 0].index\nprint(\"Number of products bought only by men: {}\".format(len(m_products)))\nprint(\"Examples: {}\".format(m_products[:5]))","0c5deae0":"# There are quite a lot of products which are only bought by women or men which makes it easy to build \n# a classifier and explains the good result","127fbb01":"# input this time is just one value per user = total amount purchased\n# create output vector = age group per user\ny = np.zeros(len(user_purchase))\n\n# map age groups to 0,1,2,...\nage_map = {v: k for k,v in enumerate(np.unique(df.Age))} \n\nfor i in range(len(user_purchase)):\n    user_id = user_purchase.index[i]\n    age = df[df['User_ID'] == user_id]['Age'].iloc[0]\n    y[i] = age_map[age]","71c22e54":"# let's try random forest again\nscores = cross_val_score(RandomForestClassifier(n_estimators=10), user_purchase, y, cv=3)\nprint(\"Random Forest Accuracy: {}\".format(np.mean(scores)))","28a11a02":"# does not seem to work that well for age group\n# Lets try SVC and LinearDiscriminantAnalysis \nscores = cross_val_score(SVC(gamma='auto'), user_purchase, y,  cv=3)\nprint(\"SVC Accuracy: {}\".format(np.mean(scores)))\nscores = cross_val_score(LinearDiscriminantAnalysis(), user_purchase, y, cv=3)\nprint(\"LDA Accuracy: {}\".format(np.mean(scores)))","84a3844d":"# we can use same X as for gender classifier\n# prepare y \ny = np.zeros(len(user_counts))\nfor uid, i in user_map.items():\n    y[user_map[uid]] = df[df.User_ID == uid].iloc[0].Marital_Status","4e237e0b":"# predict maritial status \nscores = cross_val_score(RandomForestClassifier(n_estimators=10), X, y, cv=3)\nprint(\"Accuracy: {}\".format(np.mean(scores)))","50eab9db":"# also for maritial status the bought products seem not to work very well","d7ab6c29":"**Predict Age Group by Purchases**","680891a0":"Questions to Answer\n---\n\nFrom the fields I compiled the following list of questions to answer:\n* Which person bought the most products on black friday?\n* What product selled the most on black friday?\n* In which city most money was spend?","00d87951":"**Clean the dataset**\n\nCheck for NaNs","9acfd076":"**Predict Gender by Bought Products**","f054ec21":"Classifiers examples\n---\n\nLet's see if we can train some models.\n\n* Predict male or female by products bought\n* Predict age group by total amount spent\n* Predict maritial status by several features","755f3373":"Black Friday Madness\n===\n\n\nInvestigate Fields in Dataset\n---\n\n\nLet's investigate the fields providede in the dataset and come up with questions we can ask.","0b374b06":"**Predict Maritial Status by bought Products**"}}