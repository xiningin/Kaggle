{"cell_type":{"00376dbb":"code","8df10ac8":"code","12377a2e":"code","e7a2191b":"code","c7b78d38":"code","726d0480":"code","04ba0205":"code","7d5ca0db":"code","3c2f5049":"code","597a0259":"code","aa8e922d":"code","20a86e16":"code","f70afbdd":"code","4dd92a2b":"code","be0f0f23":"code","ad4daced":"code","99d617b6":"code","1bd3bf0c":"code","b9bba4f4":"code","fe9ac19d":"code","b88b6bee":"code","3ba5f00a":"code","644ac66f":"code","0c8de8e9":"code","589503d1":"code","9b247a7f":"code","18a3eca0":"code","5f92c06d":"code","b7d9ad96":"code","e97415b5":"markdown","6e965711":"markdown","d372be91":"markdown","542b2dc5":"markdown","47d59910":"markdown","88e592bc":"markdown","0eb60dfa":"markdown","cae61372":"markdown","74f6a513":"markdown","7557ee88":"markdown","08be4cd5":"markdown","79d42be6":"markdown","bac4b9d0":"markdown","faedd3f2":"markdown"},"source":{"00376dbb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras import backend as K\nfrom tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout\nfrom tensorflow.python.keras.optimizers import Adadelta, Nadam ,Adam\nfrom tensorflow.python.keras.models import Model, load_model\nfrom tensorflow.python.keras.utils import multi_gpu_model, plot_model ,Sequence\nfrom tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.python.keras.preprocessing.image import load_img,img_to_array\nimport tensorflow as tf\nfrom tensorflow.python.keras.losses import binary_crossentropy\nfrom scipy.ndimage import morphology as mp\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nfrom glob import glob  # for getting list paths of image and labels\nfrom random import choice,sample\nfrom matplotlib import pyplot as plt\nimport cv2 # saving and loading images\n\n# Any results you write to the current directory are saved as output.","8df10ac8":"train_img_dir = '..\/input\/plant-pathology-2021-fgvc8\/train_images\/' \ntrain_mask_dir = '..\/input\/eron-masks\/masks\/'\ntrain_imgs = os.listdir(train_mask_dir)# if you have an error take a look here ...\ntrain_masks = os.listdir(train_mask_dir)\ntrain_imgs= [ i for i in train_imgs if \"jpg\" in i][:-1000]\ntrain_masks= [ i for i in train_masks if \"jpg\" in i][:-1000]\nprint(len(train_imgs))\nprint(len(train_masks))\n","12377a2e":"val_img_dir = '..\/input\/plant-pathology-2021-fgvc8\/train_images\/'\nval_mask_dir = '..\/input\/eron-masks\/masks\/'\nval_imgs = train_imgs[-1000:]#os.listdir(val_mask_dir)\nval_masks = train_masks[-1000:]#os.listdir(val_mask_dir)\nprint(len(val_imgs))\nprint(len(val_masks))","e7a2191b":"class DataGenerator(Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, images,image_dir,labels,label_dir ,batch_size=16, dim=(224,224,3) ,shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.images = images\n        self.image_dir = image_dir\n        self.labels = labels\n        self.label_dir = label_dir\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.images) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [k for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.images))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        batch_imgs = list()\n        batch_labels = list()\n\n        # Generate data\n        for i in list_IDs_temp:\n            # Store sample\n            img = load_img(self.image_dir + self.images[i] ,target_size=self.dim)\n            img = img_to_array(img)\/255.\n            batch_imgs.append(img)\n           # Store class\n            label = load_img(self.label_dir + self.labels[i] ,target_size=self.dim)\n            label = img_to_array(label)[:,:,0]\n            label = label != 0\n            label = mp.binary_erosion(mp.binary_erosion(label))\n            label = mp.binary_dilation(mp.binary_dilation(mp.binary_dilation(label)))\n            label = np.expand_dims((label)*1 , axis=2)\n            batch_labels.append(label)\n            \n        return np.array(batch_imgs) ,np.array(batch_labels)","c7b78d38":"train_generator = DataGenerator(train_imgs,train_img_dir,train_masks,train_mask_dir,batch_size=36, dim=(224,224,3) ,shuffle=True)\ntrain_steps = train_generator.__len__()\ntrain_steps","726d0480":"X,y = train_generator.__getitem__(5)\nt = 27\nplt.figure(figsize=(8,8))\nplt.subplot(121)\nplt.imshow(X[t])\nplt.subplot(122)\nplt.imshow(np.reshape(y[t],(224,224)))\n#print(np.unique(y[t],return_counts=True))","04ba0205":"val_generator = DataGenerator(val_imgs,val_img_dir,val_masks,val_mask_dir,batch_size=36, dim=(224,224,3) ,shuffle=True)\nval_steps = val_generator.__len__()\nval_steps","7d5ca0db":"def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n\n\ndef deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n    y = concatenate([y, residual], axis=3)\n    y = conv_block(y, nfilters)\n    return y\n\n\ndef Unet(h, w, filters):\n# down\n    input_layer = Input(shape=(h, w, 3), name='image_input')\n    conv1 = conv_block(input_layer, nfilters=filters)\n    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = conv_block(conv1_out, nfilters=filters*2)\n    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = conv_block(conv2_out, nfilters=filters*4)\n    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = conv_block(conv3_out, nfilters=filters*8)\n    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n    conv4_out = Dropout(0.5)(conv4_out)\n    conv5 = conv_block(conv4_out, nfilters=filters*16)\n    conv5 = Dropout(0.5)(conv5)\n# up\n    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n    deconv6 = Dropout(0.5)(deconv6)\n    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n    deconv7 = Dropout(0.5)(deconv7) \n    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n    output_layer = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(deconv9)\n    # using sigmoid activation for binary classification\n    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n    return model","3c2f5049":"model = Unet(224 , 224 , 34)\n#model.summary()","597a0259":"def jaccard_distance_loss(y_true, y_pred,smooth = 100):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return (1 - jac) * smooth\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","aa8e922d":"model.compile(optimizer='adam', loss=jaccard_distance_loss ,metrics = [dice_coef, 'accuracy'])\nmc = ModelCheckpoint(mode='max', filepath='top-weights.h5', monitor='val_dice_coef',save_best_only='True', save_weights_only='True', verbose=1)\nes = EarlyStopping(mode='max', monitor='val_dice_coef', patience=3, verbose=1)\ncallbacks = [mc, es]\nmodel.metrics_names","20a86e16":"# model.load_weights('..\/input\/background-removal\/top-weights.h5')","f70afbdd":"\nresults = model.fit_generator(train_generator, steps_per_epoch=train_steps,epochs=10,callbacks=callbacks,validation_data=val_generator,validation_steps=val_steps)","4dd92a2b":"results.history.keys()","be0f0f23":"loss = results.history[\"loss\"]\nval_loss = results.history[\"val_loss\"]\n\ndice_coef = results.history[\"dice_coef\"]\nval_dice_coef = results.history[\"val_dice_coef\"]\n\nacc = results.history[\"acc\"]\nval_acc = results.history[\"val_acc\"]\n","ad4daced":"plt.plot(loss,label = \"loss\")\nplt.plot(val_loss,label  = \"val loss\")\nplt.xlabel(\"iterations\")\n# plt.ylabel(\"X axis label\")\nplt.legend()","99d617b6":"plt.plot(dice_coef,label = \"dice_coef\")\nplt.plot(val_dice_coef,label  = \"val dice_coef\")\nplt.xlabel(\"iterations\")\n# plt.ylabel(\"X axis label\")\nplt.legend()","1bd3bf0c":"plt.plot(acc,label = \"acc\")\nplt.plot(val_acc,label  = \"val acc\")\nplt.xlabel(\"iterations\")\n# plt.ylabel(\"X axis label\")\nplt.legend()","b9bba4f4":"model.save_weights('top-weights.h5')","fe9ac19d":"# plt.figure(figsize=(8, 8))\n# plt.title(\"Learning curve\")\n# plt.plot(results.history[\"loss\"], label=\"loss\")\n# plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n# plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"log_loss\")\n# plt.legend();","b88b6bee":"#model.load_weights('\/kaggle\/input\/background-removal\/weights.08-0.97.h5')\n#k = model.evaluate_generator(generator=val_generator,steps=val_steps)","3ba5f00a":"test_image = glob('..\/input\/plant-pathology-2021-fgvc8\/test_images')\n#mask_set = glob('\/kaggle\/input\/back-remove\/binary_segment\/binary_segment\/train\/masks\/1004.jpg')\n#len(test_image)","644ac66f":"# def jaccard_distance(y_true, y_pred, smooth=100):\n#     intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n#     sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n#     jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n#     return (1 - jac) * smooth\n\n# def jaccard_acc(y_true, y_pred):\n#     intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n#     sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n#     jac = intersection \/ sum_ - intersection\n#     return jac\n\n# img = img_to_array(load_img(test_image[0]))\n# mask = img_to_array(load_img(mask_set[0]))\n# plt.imshow(mask\/255.)\n\n# jaccard_distance_loss(mask[:,:,0],mask[:,:,0])","0c8de8e9":"def make_prediction(model,image,shape):\n    img = img_to_array(load_img(image,target_size=shape))\n    img = np.expand_dims(img,axis=0)\/255.\n    mask = model.predict(img)\n    \n    mask = (mask[0] > 0.5)*1\n#     print(np.unique(mask,return_counts=True))\n    mask = np.reshape(mask,(224,224))\n    return mask                       ","589503d1":"image = \"..\/input\/plant-pathology-2021-fgvc8\/train_images\/802b59956a7aa5e7.jpg\"\nimg = img_to_array(load_img(image))\nplt.imshow(img\/255.)\nimg.shape","9b247a7f":"im = \"..\/input\/eron-masks\/masks\/802b59956a7aa5e7.jpg\"\ni = img_to_array(load_img(im))\n# i = cv2.resize(i,(img.shape[1],img.shape[0]))\nplt.imshow(i)\ni.shape","18a3eca0":"mask = make_prediction(model,image,(224,224,3))\nmask2 = cv2.merge([mask,mask,mask])\nprint(img.shape,mask.shape)\nmask2 = cv2.resize(mask2,(img.shape[1],img.shape[0]))\n# print(mask.shape)\nplt.imshow(mask2)","5f92c06d":"h,w = img.shape[:2]\nmask_resized = cv2.resize(np.uint8(mask*1),(w,h))\nmask_resized = mask_resized != 0\n#print(np.unique(mask_resized,return_counts=True))\nsegment = np.zeros((h,w,3))\nsegment[:,:,0] = img[:,:,0]*mask_resized\nsegment[:,:,1] = img[:,:,1]*mask_resized\nsegment[:,:,2] = img[:,:,2]*mask_resized\nsegment[np.where((segment == [0,0,0]).all(axis=2))] = [0,0,0]\n#img[np.where((img==[255,255,255]).all(axis=2))] = [0,0,0];","b7d9ad96":"plt.figure(figsize=(8,8))\nplt.imshow(segment\/255.)","e97415b5":"# Here we define keras custom metric for the loss and accuracy computation\n\nJaccard distance loss - this loss help to get rid of the side effects of unbalanced class label in a image (like - 80% background , 20 % human )  https:\/\/en.wikipedia.org\/wiki\/Jaccard_index\n\ndice_coef - To evaluate accuracy of the segmentation.   https:\/\/en.wikipedia.org\/wiki\/S%C3%B8rensen%E2%80%93Dice_coefficient","6e965711":"# listing image and their respective labels \nalso here we are asserting the presence of label file w.r.t each image.","d372be91":"**Repeat same steps for validation dataset**","542b2dc5":"# Now finally train our model with above configuration and train data generator.","47d59910":"# Now its time to make some predictions","88e592bc":"# After preparing input pipeline we are going to define our U-net model\n\nhere we first define down convolution (encoder ) and up convolution layer (decoder) and stack them up with a short circuting features from down sampling to corresponding up sampling\n\nfull detail of the  architecture is present here - https:\/\/arxiv.org\/abs\/1505.04597","0eb60dfa":"**After defining generator lets check the some of the dataset it generates for the training and visualize them**","cae61372":"# Background removal using Sementic Segmentation Network Unet\n\n","74f6a513":"**Function to make prediction \nNote:-  Dont forget to Normalise image dataset (here i divided every pixel by 255. )**","7557ee88":"# Defining callbacks and compile model with adam optimiser with default learning rate.","08be4cd5":" **Now we need to define our training and validation generator using above implimented class.**","79d42be6":"** Visualizing train and val loss w.r.t epoch**","bac4b9d0":"# Here we impliment keras custom data generator to get batch images and labels without loading whole dataset in the active memory\n","faedd3f2":"**Now use the mask to get the segmented image**"}}