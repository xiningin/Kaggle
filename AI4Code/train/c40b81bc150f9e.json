{"cell_type":{"a8919fbf":"code","9a0552bc":"code","5ebed30d":"code","fa46e9a4":"code","46862944":"code","9ac7cd40":"code","90aeb53f":"code","c789ded8":"code","2bd79ab2":"code","ca118e4f":"code","f9935309":"code","6f6c7c20":"code","6fc949d0":"code","977faae1":"code","d391ec86":"code","aa91dfe3":"code","d632389e":"code","6e336bb2":"code","c11156ae":"markdown","9c73df95":"markdown","56d2ce8b":"markdown","ec9cf128":"markdown","0ee32167":"markdown","45c16902":"markdown","23fee613":"markdown"},"source":{"a8919fbf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9a0552bc":"from tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os, cv2 \nfrom multiprocessing import Pool\nimport threading","5ebed30d":"! mkdir -p \/root\/.kaggle\/\n! cp ..\/input\/api-token\/kaggle.json \/root\/.kaggle\/kaggle.json","fa46e9a4":"! mkdir -p \/kaggle\/tmp\/hpa_stacked\n!kaggle datasets init -p \/kaggle\/tmp\/hpa_stacked","46862944":"%%bash\necho \"{\n  \\\"title\\\": \\\"HPA: Stacked channels 512x512\\\",\n  \\\"id\\\": \\\"tchaye59\/HPASTACKEDCHANNELS512x512\\\",\n  \\\"licenses\\\": [\n    {\n      \\\"name\\\": \\\"CC0-1.0\\\"\n    }\n  ]\n}\" > \/kaggle\/tmp\/hpa_stacked\/dataset-metadata.json","9ac7cd40":"DATA_DIR = \"..\/input\/hpa-single-cell-image-classification\/\"\nTRAIN_DIR = os.path.join('..\/input\/hpa512x512dataset',\"train\/\")\nTEST_DIR = os.path.join('..\/input\/hpa512x512dataset',\"test\/\")\nTRAIN_CSV = '..\/input\/hpa512x512dataset\/train.csv'\nTEST_CSV = os.path.join(DATA_DIR,\"sample_submission.csv\")\n\nDS_DIR = '\/kaggle\/tmp\/hpa_stacked\/'","90aeb53f":"train_df = pd.read_csv(TRAIN_CSV)\ntest_df = pd.read_csv(TEST_CSV)","c789ded8":"# Runs a process in a thread\nclass Worker(threading.Thread):\n    \n    def __init__(self, process,args,pbar=None):\n        super().__init__()\n        self.pbar = pbar\n        self.process = process\n        self.args = args\n\n    def run(self):\n        res = self.process(self.args)\n        if self.pbar:\n            self.pbar.update(1)","2bd79ab2":"def worker_fn(args):\n    id_,src_path,dest_path = args\n    red_image = cv2.imread(src_path+id_+\"_red.png\", cv2.IMREAD_UNCHANGED)\n    green_image = cv2.imread(src_path+id_+\"_green.png\", cv2.IMREAD_UNCHANGED)\n    blue_image = cv2.imread(src_path+id_+\"_blue.png\", cv2.IMREAD_UNCHANGED)\n    yellow_image = cv2.imread(src_path+id_+\"_yellow.png\", cv2.IMREAD_UNCHANGED)\n    stacked_images = np.transpose(np.array([red_image, green_image, blue_image, yellow_image]), (1,2,0))\n    #stacked_images=stacked_images.astype(np.uint8) \n    \n    np.savez_compressed(dest_path+id_+'.npz',image=stacked_images)\n    \n    #np.save(dest_path+id_+'.npy',stacked_images,allow_pickle=False)","ca118e4f":"src_dir = TRAIN_DIR\ndest_dir = DS_DIR+'train\/'\nos.makedirs(dest_dir,exist_ok=True)","f9935309":"size = len(train_df.ID)\npbar = tqdm(total=size)\nn = 5000\nfor i in range(0,size,n):\n    workers = []\n    for id_ in train_df.ID[i:min(size,i+n)]:\n        worker =  Worker(worker_fn,(id_,src_dir,dest_dir),pbar=pbar)\n        worker.start()\n        workers.append(worker)\n    for worker in workers:\n        worker.join()","6f6c7c20":"src_dir = TEST_DIR\ndest_dir = DS_DIR+'test\/'\nos.makedirs(dest_dir,exist_ok=True)","6fc949d0":"size = len(train_df.ID)\npbar = tqdm(total=size)\nn = 5000\nfor i in range(0,size,n):\n    workers = []\n    for id_ in test_df.ID[i:min(size,i+n)]:\n        worker =  Worker(worker_fn,(id_,src_dir,dest_dir),pbar=pbar)\n        worker.start()\n        workers.append(worker)\n    for worker in workers:\n        worker.join()","977faae1":"def readImage(id_):\n  imgPath = f'{DS_DIR}train\/{id_}.npz'\n  return np.load(imgPath)['image']","d391ec86":"img = readImage(train_df.ID[0])\nimg.shape","aa91dfe3":"# Only display the first 3 channels\nplt.imshow(img[:,:,:3])\nplt.show()","d632389e":"! kaggle datasets version -p \/kaggle\/tmp\/hpa_stacked -m \"Update\" --dir-mode tar\n#! kaggle datasets create -p \/kaggle\/tmp\/hpa_stacked -u --dir-mode tar","6e336bb2":"! rm -rf \/root\/.kaggle\/kaggle.json","c11156ae":"# This notebook creates a new dataset by combining the four channels in a single file\n\nThe directory \/kaggle\/working is only disk limited to 20GB because everything there is stored forever on when you hit Save > Run All.\n\n[We can have much more disk space outside this directory ](https:\/\/www.kaggle.com\/product-feedback\/155538#872885)(ex. create a directory \/kaggle\/tmp, you can write many GBs there and it won't count towards your disk usage, but also won't be saved on commit).","9c73df95":"Dataset link : https:\/\/www.kaggle.com\/tchaye59\/hpastackedchannels512x512","56d2ce8b":"# Let read one image","ec9cf128":"We first resize each single image to 512x512 :\n\nhttps:\/\/www.kaggle.com\/tchaye59\/hpa512x512dataset\n\nhttps:\/\/www.kaggle.com\/tchaye59\/hpa-512x512-dataset","0ee32167":"Training","45c16902":"# Build Stacked images","23fee613":"testing"}}