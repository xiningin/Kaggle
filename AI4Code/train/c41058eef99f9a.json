{"cell_type":{"112549a2":"code","56f2e3b6":"code","ef207496":"code","3fb0868d":"code","ffc2de50":"code","dee2f4f6":"code","47736058":"code","1216f5c2":"code","857c2df8":"code","7134872c":"code","58c8bbc9":"code","45fdbe4d":"code","603f9d19":"code","c4be6ab8":"code","506e49b4":"code","2bc9dc47":"code","1ce1e2f7":"code","179c2d59":"code","c76e3e12":"code","477ba5d4":"code","5868afe0":"code","b55c2100":"code","ca2fb653":"code","b2b6876c":"code","730b00d8":"code","2639b962":"code","bafc5bf7":"code","5c282b0c":"code","5afe3ef8":"code","3dbe9789":"code","aafbb90a":"code","e18c8b33":"code","5190beb2":"code","b1604775":"code","8c5aa478":"code","8cfc6574":"code","8f39cd34":"code","85c55e8b":"code","7c20c056":"code","abee3a46":"code","83a1fee0":"code","652dac54":"code","82b5d590":"code","82ae3ddf":"code","bc53594e":"code","6da1aaea":"code","6e29f96e":"code","70517706":"code","9cc4f4ca":"code","9f41e6d0":"code","62da17db":"markdown","e1970522":"markdown","22980b00":"markdown","38f16ae1":"markdown","4e8746ba":"markdown","bac08f02":"markdown"},"source":{"112549a2":"import numpy as np  \nimport pandas as pd  \nimport os\nfrom typing import Tuple\nimport pickle\nimport seaborn as sns\nimport time\nfrom collections import Counter  \n\nimport matplotlib.pyplot as plt\nimport plotly.io as plt_io\nimport plotly.graph_objects as go\nfrom matplotlib.pyplot import figure\n%matplotlib inline\nfrom mpl_toolkits.basemap import Basemap\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import precision_recall_curve, average_precision_score, auc\n\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV,KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC \nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, ShuffleSplit\nfrom sklearn.model_selection import cross_val_predict\n\nfrom pdpbox import pdp, get_dataset, info_plots\nimport shap \nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', None)\nlistFiles = os.listdir('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv')\nlistFiles","56f2e3b6":"patients = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/patients.csv')\nprint(patients.shape)\npatients.sample()","ef207496":"mySource = 'HEALTHCARE_EXPENSES'\n\nsource4chart = patients.copy()\nsource4chart = source4chart[['HEALTHCARE_EXPENSES','LON', 'LAT']]\nsource4chart.shape","3fb0868d":"fig = plt.gcf()\nfig = plt.figure(figsize=(10, 10))\n\nm = Basemap(projection='merc',llcrnrlat=25,urcrnrlat=51,\\\n            llcrnrlon=-128,urcrnrlon=-60,lat_ts=20,resolution='c')\nm.drawstates(linewidth=0.1)\nm.fillcontinents(color='lightgrey')\n\nx,y = m(source4chart['LON'].values, source4chart['LAT'].values)\nplt.scatter(x,y, marker='.', s=0.1, zorder=2)\n\nplt.title(mySource+' in USA based on a sample of '+str(source4chart.shape[0]), fontsize=12)\n\nplt.show()","ffc2de50":"# Mortality \n\npatients.DEATHDATE.value_counts().sum() \/ len(patients.Id.unique())","dee2f4f6":"RawData4ML = patients.copy()\nRawData4ML = RawData4ML[['Id', 'BIRTHDATE', 'DEATHDATE','MARITAL', 'RACE', 'ETHNICITY',\n       'GENDER','LAT', 'LON', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE']]\nRawData4ML.sample()","47736058":"conditions = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/conditions.csv')\nprint(conditions.shape)\nprint(conditions.sample())\nconditionsCount = conditions.groupby('PATIENT').size().reset_index(name='NumConditions')\nconditionsCount.columns = ['Id','NumConditions']\nRawData4ML = RawData4ML.merge(conditionsCount, how='left', on='Id')\nRawData4ML.sample()","1216f5c2":"procedures = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/procedures.csv')\nprint(procedures.shape)\nprint(procedures.sample())\n\nproceduresCount = procedures.groupby('PATIENT').size().reset_index(name='NumProcedures')\nproceduresCount.columns = ['Id','NumProcedures']\nRawData4ML = RawData4ML.merge(proceduresCount, how='left', on='Id')\nRawData4ML.sample()","857c2df8":"medications = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/medications.csv')\nprint(medications.shape)\nprint(medications.sample())\nmedicationsCount = medications.groupby('PATIENT').size().reset_index(name='NumMedications')\nmedicationsCount.columns = ['Id','NumMedications']\nRawData4ML = RawData4ML.merge(medicationsCount, how='left', on='Id')\nRawData4ML.sample()","7134872c":"observations = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/observations.csv')\nprint(observations.shape)\nprint(observations.sample())\nobservationsCount = observations.groupby('PATIENT').size().reset_index(name='NumObservations')\nobservationsCount.columns = ['Id','NumObservations']\nRawData4ML = RawData4ML.merge(observationsCount, how='left', on='Id')\nRawData4ML.sample()","58c8bbc9":"encounters = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/encounters.csv')\nprint(encounters.shape)\nprint(encounters.sample())\nencountersCount = encounters.groupby('PATIENT').size().reset_index(name='NumEncounters')\nencountersCount.columns = ['Id','NumEncounters']\nRawData4ML = RawData4ML.merge(encountersCount, how='left', on='Id')\nRawData4ML.sample()","45fdbe4d":"imaging_studies = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/imaging_studies.csv')\nprint(imaging_studies.shape)\nprint(imaging_studies.sample())\nimaging_studiesCount = imaging_studies.groupby('PATIENT').size().reset_index(name='NumImages')\nimaging_studiesCount.columns = ['Id','NumImages']\nRawData4ML = RawData4ML.merge(imaging_studiesCount, how='left', on='Id')\nRawData4ML.sample()","603f9d19":"careplans = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/careplans.csv')\nprint(careplans.shape)\nprint(careplans.sample())\ncareplansCount = careplans.groupby('PATIENT').size().reset_index(name='NumCareplans')\ncareplansCount.columns = ['Id','NumCareplans']\nRawData4ML = RawData4ML.merge(careplansCount, how='left', on='Id')\nRawData4ML.sample()","c4be6ab8":"allergies = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/allergies.csv')\nprint(allergies.shape)\nprint(allergies.sample())\nallergiesCount = allergies.groupby('PATIENT').size().reset_index(name='NumAllergies')\nallergiesCount.columns = ['Id','NumAllergies']\nRawData4ML = RawData4ML.merge(allergiesCount, how='left', on='Id')\nRawData4ML.sample()","506e49b4":"payers = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/payers.csv')\nprint(payers.shape)\nprint(payers.sample())\npayersCount = payers.groupby('Id').size().reset_index(name='NumPayers')\npayersCount.columns = ['Id','NumPayers']\nRawData4ML = RawData4ML.merge(payersCount, how='left', on='Id')\nRawData4ML.sample()","2bc9dc47":"organizations = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/organizations.csv')\nprint(organizations.shape)\nprint(organizations.sample())\norganizationsCount = organizations.groupby('Id').size().reset_index(name='NumOrganizations')\norganizationsCount.columns = ['Id','NumOrganizations']\nRawData4ML = RawData4ML.merge(organizationsCount, how='left', on='Id')\nRawData4ML.sample()","1ce1e2f7":"supplies = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/supplies.csv')\nprint(supplies.shape)\nprint(supplies.sample())\nsuppliesCount = supplies.groupby('PATIENT').size().reset_index(name='NumSupplies')\nsuppliesCount.columns = ['Id','NumSupplies']\nRawData4ML = RawData4ML.merge(suppliesCount, how='left', on='Id')\nRawData4ML.sample()","179c2d59":"devices = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/devices.csv')\nprint(devices.shape)\nprint(devices.sample())\ndevicesCount = devices.groupby('PATIENT').size().reset_index(name='NumDevices')\ndevicesCount.columns = ['Id','NumDevices']\nRawData4ML = RawData4ML.merge(devicesCount, how='left', on='Id')\nRawData4ML.sample()","c76e3e12":"payer_transitions = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/payer_transitions.csv')\nprint(payer_transitions.shape)\nprint(payer_transitions.sample())\npayer_transitionsCount = payer_transitions.groupby('PATIENT').size().reset_index(name='NumPayer_transitions')\npayer_transitionsCount.columns = ['Id','NumPayer_transitions']\nRawData4ML = RawData4ML.merge(payer_transitionsCount, how='left', on='Id')\nRawData4ML.sample()","477ba5d4":"providers = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/providers.csv')\nprint(providers.shape)\nprint(providers.sample())\nprovidersCount = providers.groupby('Id').size().reset_index(name='NumProviders')\nprovidersCount.columns = ['Id','NumProviders']\nRawData4ML = RawData4ML.merge(providersCount, how='left', on='Id')\nRawData4ML.sample()","5868afe0":"immunizations = pd.read_csv('\/kaggle\/input\/syntheacovid100k\/100k_synthea_covid19_csv\/immunizations.csv')\nprint(immunizations.shape)\nprint(immunizations.sample())\nimmunizationsCount = immunizations.groupby('PATIENT').size().reset_index(name='NumImmunizations')\nimmunizationsCount.columns = ['Id','NumImmunizations']\nRawData4ML = RawData4ML.merge(immunizationsCount, how='left', on='Id')\nRawData4ML.sample()","b55c2100":"print(RawData4ML.shape)\nRawData4ML.isnull().sum()\n","ca2fb653":"RawData4ML = RawData4ML[['BIRTHDATE', 'DEATHDATE', 'MARITAL', 'RACE', 'ETHNICITY',\n       'GENDER', 'LAT', 'LON', 'HEALTHCARE_EXPENSES', 'HEALTHCARE_COVERAGE',\n       'NumConditions', 'NumProcedures', 'NumMedications', 'NumObservations',\n       'NumEncounters', 'NumCareplans', \n       'NumPayer_transitions', 'NumImmunizations']]\n\nprint(RawData4ML.shape)\nRawData4ML.isnull().sum()","b2b6876c":"# Age\n\nRawData4ML['BIRTHDATE'] = pd.to_datetime(RawData4ML['BIRTHDATE'])\nRawData4ML['BIRTHDATE']\n\nnow = pd.to_datetime('now')\nnow\n# Timestamp('2019-04-14 00:00:43.105892')\n\nRawData4ML['Age'] = (now - RawData4ML['BIRTHDATE']).astype('<m8[Y]') \nRawData4ML.drop('BIRTHDATE', axis=1, inplace=True)\nRawData4ML.sample()","730b00d8":"RawData4ML['Dead'] = 0\nRawData4ML['Dead'] = ~RawData4ML.DEATHDATE.isnull()\nRawData4ML.Dead.value_counts()","2639b962":"RawData4ML.drop('DEATHDATE', axis=1, inplace=True)\nRawData4ML.Dead.value_counts(normalize=True)","bafc5bf7":"RawData4ML.shape","5c282b0c":"# Categorical data\n\nprint(RawData4ML.shape)\ncols4OHE = ['MARITAL', 'RACE', 'ETHNICITY']\n\nRawData4ML = pd.get_dummies(RawData4ML, columns = cols4OHE)\nprint(RawData4ML.shape)","5afe3ef8":"RawData4ML['GENDER']=RawData4ML['GENDER'].apply(lambda x: 1 if x =='M'  else 0)\nRawData4ML.isnull().sum()","3dbe9789":"# Fill NA\n\nRawData4ML['NumEncounters'].fillna((RawData4ML['NumEncounters'].mean()), inplace=True)\nRawData4ML['NumMedications'].fillna((RawData4ML['NumMedications'].mean()), inplace=True)\nRawData4ML['NumConditions'].fillna((RawData4ML['NumConditions'].mean()), inplace=True)\nRawData4ML['NumProcedures'].fillna((RawData4ML['NumProcedures'].mean()), inplace=True)\nRawData4ML['NumCareplans'].fillna((RawData4ML['NumCareplans'].mean()), inplace=True)\nRawData4ML['NumPayer_transitions'].fillna((RawData4ML['NumPayer_transitions'].mean()), inplace=True)\nRawData4ML['NumImmunizations'].fillna((RawData4ML['NumImmunizations'].mean()), inplace=True)\nRawData4ML.isnull().sum()","aafbb90a":"# Separate X,y for normalizing only X\n\nRawData4ML = RawData4ML.sample(frac=1) # shuffles df\n\n\ny = RawData4ML.Dead.values\nprint(y.shape)\nX = RawData4ML.drop('Dead', axis=1)\nprint(X.shape)","e18c8b33":"# Normalize X\n\nx = X.values #returns a numpy array\nscaler = preprocessing.StandardScaler()\nx_scaled = scaler.fit_transform(x)\nNormData = pd.DataFrame(x_scaled, columns=X.columns)\nprint(NormData.shape)\nNormData.tail()","5190beb2":"#SPLIT into Train & Test \n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint ('X_train: ', X_train.shape)\nprint ('X_test: ', X_test.shape)\nprint ('y_train: ', y_train.shape)\nprint ('y_test: ', y_test.shape)","b1604775":"%%time\n\n# Test Models and evaluation metric\nseed = 7\nscoring = 'accuracy' \n\n# Spot Check Algorithms\nMymodels = []\n#Mymodels.append(('LogReg', LogisticRegression()))\nMymodels.append(('RandomForest', RandomForestClassifier()))\n#Mymodels.append(('SGDclassifier', SGDClassifier()))\n#Mymodels.append(('KNearestNeighbors', KNeighborsClassifier()))\n#Mymodels.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n#Mymodels.append(('GaussianNB', GaussianNB()))\n#Mymodels.append(('SVM', SVC())) # works for 40 mins and nada\n\n# Evaluate each model in turn\nresults = []\nnames = []\nfor name, model in Mymodels:\n    kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg) ","8c5aa478":"# Predict on test\n\nmodel = RandomForestClassifier()\n\nmodel.fit(X_train, y_train)\nPreds = model.predict(X_test)\n\n# Classification report\nprint(classification_report(y_test, Preds))","8cfc6574":"# CM\n\nCM = confusion_matrix(y_test, Preds)\ntn, fp, fn, tp = confusion_matrix(y_test, Preds).ravel()\n\nprint(CM)\nprint(\"_\"*50)\nprint(\"TP \", tp)\nprint(\"FP \", fp)\nprint(\"TN \", tn)\nprint(\"FN \", fn)","8f39cd34":"# Function for a nice CM\n\ndef plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None,\n                          normalize=False):\n    import itertools\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    \n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        \n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()\n","85c55e8b":"plot_confusion_matrix(CM, \n                      normalize    = False,\n                      target_names = ['0', '1'],\n                      title        = \"Confusion Matrix\")","7c20c056":"print ('precision ',round(precision_score(y_test, Preds),3))\nprint ('recall ',round(recall_score(y_test, Preds),3 ))\nprint ('accuracy ',round(accuracy_score(y_test, Preds),3))\nprint ('F1 score ',round(f1_score(y_test, Preds),3))","abee3a46":"# AUC\/ROC curves should be used when there are roughly equal numbers of observations for each class\n# Precision-Recall curves should be used when there is a moderate to large class imbalance\n\n# calculate AUC\nauc = roc_auc_score(y_test, Preds)\nprint('AUC: %.3f' % auc)\n# calculate roc curve\nfpr, tpr, thresholds = roc_curve(y_test, Preds)\n# plot no skill\nplt.plot([0, 1], [0, 1], linestyle='--')\n# plot the roc curve for the model\nplt.plot(fpr, tpr, marker='.')\nplt.title('ROC ')\n# show the plot\nplt.show()","83a1fee0":"# calculate precision-recall curve\nprecision, recall, thresholds = precision_recall_curve(y_test, Preds)\n# calculate F1 score\nf1 = f1_score(y_test, Preds)\n# calculate precision-recall AUC\n#auc = auc(recall, precision)\n# calculate average precision score\nap = average_precision_score(y_test, Preds)\nprint('f1=%.3f ap=%.3f' % (f1, ap))\n# plot no skill\nplt.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the roc curve for the model\nplt.plot(recall, precision, marker='.')\n# show the plot\nplt.show()","652dac54":"# Feature importance\n\nimportance = model.feature_importances_\nFIdf = pd.DataFrame()\nFIdf['Feature'] = X.columns\nFIdf['Importance'] = importance\n\nFIdf.sort_values(by=['Importance'], ascending=False, inplace=True)\nFIdf.head(30)","82b5d590":"FIdf.sort_values(by=['Importance'], ascending=True, inplace=True)\nfigure(figsize=(12, 12), dpi=80)\n\nplt.barh(FIdf['Feature'], FIdf['Importance'])\nplt.show()","82ae3ddf":"# Create the data that we will plot\npdp_goals = pdp.pdp_isolate(model=model, dataset=X, model_features=X.columns, feature='Age')\n\n# plot it\npdp.pdp_plot(pdp_goals, 'Age')\nplt.show()","bc53594e":"# Create the data that we will plot\npdp_goals = pdp.pdp_isolate(model=model, dataset=X, model_features=X.columns, feature='HEALTHCARE_EXPENSES')\n\n# plot it\npdp.pdp_plot(pdp_goals, 'HEALTHCARE_EXPENSES')\nplt.show()","6da1aaea":"# Create the data that we will plot\npdp_goals = pdp.pdp_isolate(model=model, dataset=X, model_features=X.columns, feature='NumObservations')\n\n# plot it\npdp.pdp_plot(pdp_goals, 'NumObservations')\nplt.show()","6e29f96e":"row_to_show = np.where(y==True)[0][1234]\n\ndata_for_prediction = X.iloc[row_to_show]  \ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\nmodel.predict_proba(data_for_prediction_array)","70517706":" # SHAP\n\nexplainer = shap.TreeExplainer(model)\n\n# Calculate Shap values\nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)","9cc4f4ca":"row_to_show = np.where(y==False)[0][1234]\n\ndata_for_prediction = X.iloc[row_to_show]  \ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\nmodel.predict_proba(data_for_prediction_array)","9f41e6d0":" # SHAP\n\nexplainer = shap.TreeExplainer(model)\n\n# Calculate Shap values\nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)","62da17db":"# Hypothesis\n\n### AI can predict mortality with only basic demographics and the number of interactions a patient has with the system\n\n## Data\n100K rows - synthetic data from \nhttp:\/\/hdx.mitre.org\/downloads\/syntheticmass\/100k_synthea_covid19_csv.zip\n\n## Goals\n#### EDA and then pick the best model (accuracy \/ F1 score) from some shallows that have FI\n#### Feature importance - Which features impact most model predictions\n#### Partial dependence plots - How is ONE feature impacting predictions\n#### SHAP values - How are ALL features impacting ONE prediction","e1970522":"## Partial Dependence Plots - How ONE feature affects predictions\n\nWhile feature importance shows what variables most affect predictions, partial dependence plots show how a feature affects predictions.","22980b00":"## SHAP - Impact of each feature on ONE prediction\n\nSHAP Values (an acronym from SHapley Additive exPlanations) break down a prediction to show the impact of each feature. ","38f16ae1":"## Feature importance - What features have the biggest impact on predictions","4e8746ba":"# Data","bac08f02":"# Models"}}