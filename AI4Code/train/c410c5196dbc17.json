{"cell_type":{"1fc0f6b4":"code","bac5210d":"code","560c90eb":"code","bbe5b175":"code","dc547d4a":"code","2af08ae3":"code","a7d58484":"code","801baf2b":"code","0f00da70":"code","7863b6ab":"code","3772a70d":"code","c40d788f":"code","b8fc0984":"code","fe0aa850":"code","1e0adfb5":"code","3d587fc5":"code","80ec6f97":"code","97d111eb":"code","28a604b0":"code","2f3af988":"code","38337277":"code","babb91c3":"code","d4605438":"code","bd359626":"code","04761e41":"code","942da895":"code","57e1a8d8":"code","87399fd7":"code","5b9ee874":"code","b2f94278":"code","8859da0f":"code","720a2ac6":"code","0152c54e":"code","67c507c3":"code","4637daa2":"code","10a24a38":"markdown","dc7c98f7":"markdown","246bd00d":"markdown","d9f02e83":"markdown","844fb24a":"markdown","dcd6ce12":"markdown","29353d22":"markdown","84a3d708":"markdown","94eb41c0":"markdown","f958d52e":"markdown","9dd61ddb":"markdown","85b87986":"markdown","37702761":"markdown","38c0bb12":"markdown","3fdf8cce":"markdown","e439bdf2":"markdown","47b3dc32":"markdown","1ddba346":"markdown","db1349c6":"markdown","2b432347":"markdown","a574ca54":"markdown","637ff981":"markdown","466ca562":"markdown","53802bd1":"markdown","71184f99":"markdown","f365f41b":"markdown","78fcc8f5":"markdown","6281097f":"markdown","b0930173":"markdown","521b8c72":"markdown","2bd93b69":"markdown","a4983d8b":"markdown","483d503a":"markdown","5d73268d":"markdown","d1ab0167":"markdown","df4e8e33":"markdown","b7c9c1aa":"markdown","8216ed32":"markdown","e3fdfa79":"markdown","0bc9c7e9":"markdown","9fdcadfc":"markdown","b637bcd8":"markdown","6871788c":"markdown","a07107bd":"markdown","e2fb751f":"markdown","c6765ae8":"markdown","c0154b6d":"markdown","e9d59f6e":"markdown","13f5d6c0":"markdown","36c68cb9":"markdown","da9c8b3d":"markdown","e2a2ffbd":"markdown","ba3b12bd":"markdown","dbb592e1":"markdown","def91b56":"markdown","6a355a2d":"markdown","2a53470a":"markdown"},"source":{"1fc0f6b4":"%%javascript\n$.getScript('https:\/\/kmahelona.github.io\/ipython_notebook_goodies\/ipython_notebook_toc.js')","bac5210d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","560c90eb":"# Import the basic python libraries\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nget_ipython().run_line_magic('matplotlib', 'inline')\nsns.set(style='white', context='notebook', palette='deep')\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Read the datasets\ntrain = pd.read_csv(\"..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")\ntrain.info()\n","bbe5b175":"# Check missing values in train data set\ntrain_na = (train.isnull().sum() \/ len(train)) * 100\ntrain_na = train_na.drop(train_na[train_na == 0].index).sort_values(ascending=False)[:30]\nmiss_train = pd.DataFrame({'Train Missing Ratio' :train_na})\nmiss_train.head()\n","dc547d4a":"def plot(var):\n    fig = plt.figure(figsize = (10,6))\n    sns.barplot(x = 'quality', y = var , data = train)\n    print(train[[var, \"quality\"]].groupby(['quality']).mean().sort_values(by=var, ascending=False))","2af08ae3":"plot('fixed acidity')","a7d58484":"plot('volatile acidity')","801baf2b":"plot('citric acid')","0f00da70":"plot('residual sugar')","7863b6ab":"plot('chlorides')","3772a70d":"plot('free sulfur dioxide')","c40d788f":"plot('total sulfur dioxide')","b8fc0984":"plot('density')","fe0aa850":"plot('pH')","1e0adfb5":"plot('sulphates')","3d587fc5":"plot('alcohol')","80ec6f97":"bins = (2, 6.5, 8)\ntarget_groups = ['BadQ', 'GoodQ']\ntrain['quality'] = pd.cut(train['quality'], bins = bins, labels = target_groups)\nlabel_quality = LabelEncoder()\ntrain['quality'] = label_quality.fit_transform(train['quality'])","97d111eb":"train['quality'].value_counts()","28a604b0":"y = train.quality\nX = train.drop('quality', axis=1)","2f3af988":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, stratify=y)","38337277":"# standardization\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)","babb91c3":"# Import the required libraries\nfrom sklearn.svm import SVC\nfrom collections import Counter\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier","d4605438":"# Cross validate model with Kfold stratified cross val\nkfold = StratifiedKFold(n_splits=10)","bd359626":"# Modeling differents algorithms. \n\nrandom_state = 2\nclassifiers = []\n\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LinearDiscriminantAnalysis())\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train_scaled, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\n                       \"Algorithm\":[\"SVC\",\n                                    \"AdaBoost\",\n                                    \"ExtraTrees\",\n                                    \"KNeighboors\",\n                                    \"DecisionTree\",\n                                    \"RandomForest\",\n                                    \"GradientBoosting\",\n                                    \"LogisticRegression\",\n                                    \"MultipleLayerPerceptron\",\n                                    \"LinearDiscriminantAnalysis\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","04761e41":"# Adaboost\nDTC = DecisionTreeClassifier()\n\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\n\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n                  \"base_estimator__splitter\" :   [\"best\", \"random\"],\n                  \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n                  \"n_estimators\" :[1,2],\n                  \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsadaDTC.fit(X_train_scaled,y_train)\n\n# Predicting on test data\ny_pred_rf = gsadaDTC.predict(X_test_scaled)\nprint(\"Training Accuracy - AdaBoost Model: \", gsadaDTC.score(X_train_scaled,y_train))\nprint('Testing Accuarcy - AdaBoost Model: ', gsadaDTC.score(X_test_scaled, y_test))\n\n# making a classification report\ncr = classification_report(y_test,  y_pred_rf)\nprint(cr)","942da895":"#ExtraTrees \nExtC = ExtraTreesClassifier()\n\n## Search grid for optimal parameters\nex_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\n\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsExtC.fit(X_train_scaled,y_train)\n\n# Predicting on test data\ny_pred_rf = gsExtC.predict(X_test_scaled)\nprint(\"Training Accuracy - ExtraTreeClassifier: \", gsExtC.score(X_train_scaled,y_train))\nprint('Testing Accuarcy - ExtraTreeClassifier: ', gsExtC.score(X_test_scaled, y_test))\n\n# Making a classification report\ncr = classification_report(y_test,  y_pred_rf)\nprint(cr)","57e1a8d8":"# RFC Parameters tunning \nRFC = RandomForestClassifier()\n\n## Search grid for optimal parameters\nrf_param_grid = {\"max_depth\": [None],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [2, 3, 10],\n              \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[100,300],\n              \"criterion\": [\"gini\"]}\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsRFC.fit(X_train_scaled,y_train)\n\n# Predicting on test data\ny_pred_rf = gsRFC.predict(X_test_scaled)\nprint(\"Training Accuracy - RandomForestClassifier: \", gsRFC.score(X_train_scaled,y_train))\nprint('Testing Accuarcy - RandomForestClassifier: ', gsRFC.score(X_test_scaled, y_test))\n\n# Making a classification report\ncr = classification_report(y_test,  y_pred_rf)\nprint(cr)","87399fd7":"# Gradient boosting \nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsGBC.fit(X_train_scaled,y_train)\n\n# Predicting on test data\ny_pred_rf = gsGBC.predict(X_test_scaled)\nprint(\"Training Accuracy - Gradient Boosting: \", gsGBC.score(X_train_scaled,y_train))\nprint('Testing Accuarcy - Gradient Boosting: ', gsGBC.score(X_test_scaled, y_test))\n\n# Making a classification report\ncr = classification_report(y_test,  y_pred_rf)\nprint(cr)","5b9ee874":"### SVC classifier\nSVMC = SVC(probability=True)\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsSVMC.fit(X_train_scaled,y_train)\n\n# Predicting on test data\ny_pred_rf = gsSVMC.predict(X_test_scaled)\nprint(\"Training Accuracy - SVC Classifier: \", gsSVMC.score(X_train_scaled,y_train))\nprint('Testing Accuarcy - SVC Classifier: ', gsSVMC.score(X_test_scaled, y_test))\n\n# Making a classification report\ncr = classification_report(y_test,  y_pred_rf)\nprint(cr)","b2f94278":"train['quality'].value_counts()","8859da0f":"# Creating new samples using SMOTE technique\nfrom imblearn.over_sampling import SMOTE\nx_resample, y_resample  = SMOTE().fit_sample(X, y.values.ravel())\nprint(\"Shape of x_resample :\",x_resample.shape)\nprint(\"Shape of y_resample :\",y_resample.shape)","720a2ac6":"# Testing balanced values\nd=pd.DataFrame(y_resample, columns=['a']) \nd['a'].value_counts()","0152c54e":"x_train2, x_test2, y_train2, y_test2 = train_test_split(x_resample, y_resample, test_size = 0.2, random_state = 0)\nprint(\"Shape of x_train2 :\", x_train2.shape)\nprint(\"Shape of y_train2 :\", y_train2.shape)\nprint(\"Shape of x_test2 :\", x_test2.shape)\nprint(\"Shape of y_test2 :\", y_test2.shape)","67c507c3":"# standardization\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train2 = sc.fit_transform(x_train2)\nx_test2 = sc.transform(x_test2)","4637daa2":"SVMC = SVC(probability=True)\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\ngsSVMC.fit(x_train2,y_train2)\n\n# Predicting on test data\ny_pred_rf = gsSVMC.predict(x_test2)\nprint(\"Training Accuracy: \", gsSVMC.score(x_train2, y_train2))\nprint('Testing Accuarcy: ', gsSVMC.score(x_test2, y_test2))\n\n# Making a classification report\ncr = classification_report(y_test2,  y_pred_rf)\nprint(cr)","10a24a38":"**residual sugar**","dc7c98f7":"**ExtraTrees Classifier**\n\nET is a meta estimator that fits a number of randomized decision trees on various sub-samples of the dataset and then uses averaging method to improve the predictive accuracy and control over-fitting.","246bd00d":"From Feature Engineering perspective there is not much room to experimen except following two steps - \n* Convert the 'Quality' column values to 1 and 0 using bins and label encoders\n* Standardize the data for ease of calculations\n","d9f02e83":"***Using Grid Search, the ExtraTreeClassifier model gives training accuracy as 100% and testing accuracy as 91%***","844fb24a":"# What data do we have?","dcd6ce12":"<h1 id=\"tocheading\">Table of Contents<\/h1>\n<div id=\"toc\"><\/div>","29353d22":"Not very informative, however, it seems average quality wines have higher values of 'free sulphur dioxide'","84a3d708":"**AdaBoost classifier** \n\nAdaboost begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases.","94eb41c0":"Not very informative as all quality groups have almost same pH","f958d52e":"The chart suggests that low quality wines have low citric acid ","9dd61ddb":"The guided approach explained in this notebook will help you to understand how you should design and approach Data Science problems. Though there are many ways to do the same analysis, I have used the codes which I found more efficient and helpful.\n\nAs we can see that dataset is not balanced, we will leverage SMOTE technique to oversample the data and evaluate the impact on model performance.\n\n**The idea is just to show you the path, try your own ways and share the same with others.**","85b87986":"Let's pick up one of the algoritham SVC and see how SMOTE helps in improving the model accuracy","37702761":"Not very informative as all quality groups have almost same average density","38c0bb12":"The chart suggests that low quality wines have high volatile acidity ","3fdf8cce":"# Feature engineering\n![FE.png](attachment:FE.png)","e439bdf2":"**Alcohol**","47b3dc32":"Now the classes are balanced and model has enough data points to learn and create a decision boundary. Let's further split the new samples into train and test data","1ddba346":"Now we have the training and test datasets available and we can start training the model. We will build couple of base models and then will use Grid Search method to optimize the parameters. There are several classification you can select.\nWe are trying following to develop a baseline - \n\n        1. K Nearest Neighbour\n        2. Linear Discriminant Analysis\n        3. Support Vector Classifier\n        4. Multi-layer Perceptron classifier\n        5. Extra Trees Classifier\n        6. Logistic Regression\n        7. Decision Trees\n        8. Random Forest\n        9. Gradient Boosting Classifier\n        10. AdaBoost Classifier\n","db1349c6":"**Sulphates**","2b432347":"Let's start with finding the number of missing values. \n\nUse the groupby\/univariate\/bivariate analysis method to compare the distribution across Train data","a574ca54":"# Conclusion\n![Conclusion.png](attachment:Conclusion.png)","637ff981":"**Random Forest Classifier**\n\nSimilar to Extra Tree Classifier a Random Forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default).\n\nHow ET differes from RF - \n\n1) When choosing variables at a split, samples are drawn from the entire training set instead of a bootstrap sample of the training set.\n\n2) Splits are chosen completely at random from the range of values in the sample at each split.","466ca562":"**total sulfur dioxide**","53802bd1":"Let's define a function for quick plotting","71184f99":"\n![Data.jpg](attachment:Data.jpg)\n\nLet's import necessary libraries & bring in the datasets in Python environment first. Once we have the datasets in Python environment we can slice & dice the data to understand what we have and what is missing.","f365f41b":" \n![Prob%20Ident.png](attachment:Prob%20Ident.png)\n**Best Practice -** The most important part of any project is correct problem identification. Before you jump to \"How to do this\" part like typical Data Scientists, understand \"What\/Why\" part.  \nUnderstand the problem first and draft a rough strategy on a piece of paper to start with. Write down things like what are you expected to do & what data you might need or let's say what all algorithms you plan to use. \n\nThe goal of this kernel is to treat this dataset to explore classification algorithms. The target variable will be converted to a categories such as 'Good' and 'Bad' based on 10 point scale suggested by dataset uploader. \n\nSo it is a classification problem and you are expected to predict good as 1 and bad as 0.","78fcc8f5":"**density**","6281097f":"***Using Grid Search, the SVC model gives training accuracy as 98% and testing accuracy as 90%***","b0930173":"# What would be the workflow?\n\nI will keep it simple & crisp.\n\nThis will help you to stay on track. So here is the workflow.\n\n**Problem Identification**\n\n**What data do we have?**\n\n**Exploratory data analysis**\n\n**Data preparation including feature engineering**\n\n**Developing a model**\n\n**Model evaluation**\n\n**Conclusions**\n\nThat's all you need to solve a data science problem.","521b8c72":"Creating binary classification for target variable","2bd93b69":"Split data into training and test sets.\n\nFirst, let's separate our target (y) features from our input (X) features:","a4983d8b":"**fixed acidity**\n\nLet's look at the distribution.","483d503a":"**Volatile Acidity**\n\nLet's look at the distribution.","5d73268d":"This features also seems to be directly related to quality of wine as good quality wines have more alcohol","d1ab0167":"**Citric Acid**","df4e8e33":"***Using Grid Search, the Random Forest model gives training accuracy as 100% and testing accuracy as 90%***","b7c9c1aa":"***Using Grid Search, the AdaBoost model gives training accuracy as 100% and testing accuracy as 88%***","8216ed32":"# Creating a Model","e3fdfa79":"This features seems to be directly related to quality of wine as good quality wines have more sulphates","0bc9c7e9":"Post label encoding the train data has imbalanced target data which means there could be a significant difference between the majority and minority classes (1 and 0). In other words, there are too few examples of the minority class (1) for a model to effectively learn the decision boundary. One way to tackle such a situation is to oversample the minority class (GoodQ = 1 in this case). The approach involves simply duplicating the minority class examples. This is a type of data processing for the minority class is referred to as the Synthetic Minority Oversampling Technique or SMOTE for short.\n\nAlmost 10% difference between training and testing accuracy also proves that model is getting overtrained and not performing on test data as expected. In Data Science language we can say that we are experiencing 'High Bias and High Variance' cases. Let's see if SMOTE can help in address this issue as well.","9fdcadfc":"**chlorides**","b637bcd8":"Not very informative feature ","6871788c":"As we can clearly see, how balancing of data using SMOTE can help in improving the model accuracy. In this case **testing accuracy improved all the way to 96% from initial 90%.**\n\nWe can also notice that model is performing well on test data as well so we have the '**Low Bias and Low Variance**' case now.","a07107bd":"**Gradient Boosting**\n\nGradient boosting is one of the most powerful techniques for building predictive models. Boosting is a method of converting weak learners into strong learners by building an additive model in a forward stage-wise fashion. In boosting, each new tree is a fit on a modified version of the original data set.","e2fb751f":"# Applying Over Sampling Techniques Using SMOTE","c6765ae8":"There are no missing values","c0154b6d":"**pH**","e9d59f6e":"**Support Vector Machines**\n\nSVM builds a hyperplane in multidimensional space to separate different classes. SVM generates optimal hyperplane in an iterative manner, which is used to minimize the error. The idea behind SVM is to find a maximum marginal hyperplane(MMH) that best divides the dataset into classes.","13f5d6c0":"# Model Evaluation\n![model.png](attachment:model.png)","36c68cb9":"# EDA & Visualization\n","da9c8b3d":"# **If you liked this notebook, Please upvote and leave a comment**\n![Good%20Bye.png](attachment:Good%20Bye.png)","e2a2ffbd":"**free sulfur dioxide**","ba3b12bd":"\n\nEvaluating multiple models using GridSearch optimization method. \n\nHyper-parameters are key parameters that are not directly learnt within the estimators. We have to pass these as arguments. Different hyper parameters can result in different model with varying performance\/accuracy. To find out what paparmeters are resulting in best score, we can use Grid Search method and use the optimum set of hyper parameters to build and select a good model.\n\nA search consists of:\n\n1. an estimator (regressor or classifier)\n2. a parameter space;\n3. a method for searching or sampling candidates;\n4. a cross-validation scheme; and\n5. a score function.","dbb592e1":"Based on data above, better quality wines will have less chlorides","def91b56":"***Using Grid Search, the Gradient Boosting model gives training accuracy as 99% and testing accuracy as 90%***","6a355a2d":"**Cross Validation Strategy**\n![CV.png](attachment:CV.png)\n\nCross Validation is one of the most powerful tool in Data Scientist's tool box. It helps you to understand the performance of your model and fight with overfitting. As we all know that Learning the model parameters and testing it on the same data is a big mistake. Such a model would have learned everything about the training data and would give result in a near perfect test score as it has already seen the data. The same model would fail terribly when tested on unseen data. This situation is called overfitting. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a test set X_test, y_test. \n\nThe general approach is as follows:\n\n1. Split the dataset into k groups\n2. For each unique group:\n        a. Keep one group as a hold out or test data set\n        b. Use the remaining groups as training data set\n        c. Build the model on the training set and evaluate it on the test set\n        d. Save the evaluation score \n3. Summarize the performance of the model using the sample of model evaluation scores\n\nYou can access following link and read about Cross Validation in detail.\n\nhttps:\/\/medium.com\/datadriveninvestor\/k-fold-cross-validation-6b8518070833\nhttps:\/\/www.analyticsvidhya.com\/blog\/2018\/05\/improve-model-performance-cross-validation-in-python-r\/","2a53470a":"# Problem Identification"}}