{"cell_type":{"678feff6":"code","373ff0ff":"code","05e23d22":"code","72a18659":"code","2188a818":"code","63cbbe82":"code","c3aa7b74":"code","3724bff9":"code","57e7547c":"code","66c419b4":"code","e120561d":"code","a6b5f5e3":"code","acb91744":"code","d854dea0":"code","dd112999":"markdown","36a407f6":"markdown","0003e81c":"markdown","27601438":"markdown","58503e47":"markdown","1f443c6e":"markdown","ff6901b9":"markdown","124a8ba9":"markdown","02aa2390":"markdown","64cd6f4e":"markdown","30571d86":"markdown","4c2426ed":"markdown","4650417d":"markdown","166e1310":"markdown","f2b1799d":"markdown"},"source":{"678feff6":"# Importing required libraries\n\nimport os \nimport numpy as np\nimport pickle \nfrom tensorflow import keras \nimport cv2\nimport matplotlib.pyplot as plt\nimport random\nfrom keras.preprocessing.image import ImageDataGenerator\nos.getcwd()","373ff0ff":"data = []\nimg_size = 125\ncategories = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\ndef create_data():\n    for category in categories:\n        path = os.path.join('..\/input\/flowers-recognition\/flowers', category)\n        class_num = categories.index(category)\n        for img in os.listdir(path):\n            img_arr = cv2.imread(os.path.join(path, img))\n            try:\n                new_arr = cv2.resize(img_arr, (img_size, img_size))\n            except cv2.error as e:\n                print('Not valid')\n            cv2.waitKey()\n            \n            data.append([new_arr, class_num])","05e23d22":"create_data()\nrandom.shuffle(data)\nX=[]\ny=[]\n\nfor features, labels in data:\n    X.append(features)\n    y.append(labels)\n\nX = np.array(X).reshape(-1, img_size, img_size, 3)\ny = np.array(y)","72a18659":"# Checking if everything is working \nprint('Shape of X: ', X.shape)\nprint('Shape of y: ', y.shape)","2188a818":"pickle_out = open('X.pickle', 'wb')\n\npickle.dump(X, pickle_out)\n\npickle_out_2 = open('y.pickle', 'wb')\n\npickle.dump(y, pickle_out_2)","63cbbe82":"X = X \/ 255.0\n","c3aa7b74":"plt.imshow(X[4])\ny[4]\n","3724bff9":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nle = LabelEncoder()\ny= le.fit_transform(y)\ny = to_categorical(y,5)\ny.shape\n","57e7547c":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.8, random_state= 7)\n","66c419b4":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False) \ndatagen.fit(X_train)","e120561d":"\nmodel = keras.models.Sequential([keras.layers.Conv2D(32, 5, activation='relu', padding='SAME', input_shape=X.shape[1:]),\n                                keras.layers.MaxPooling2D(2),\n                                # keras.layers.Dropout(0.2),\n                                keras.layers.Conv2D(64, 3, activation='relu', padding='SAME'),\n                                keras.layers.MaxPooling2D(pool_size=2),\n                                # keras.layers.Dropout(0.2),\n                                \n                                keras.layers.Conv2D(96, 3, activation=\"relu\", padding=\"same\"),\n                                keras.layers.MaxPooling2D(pool_size=2),\n                                # keras.layers.Dropout(0.2),\n                                keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n                                # keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n                                keras.layers.MaxPooling2D(pool_size=2),\n                                # keras.layers.Dropout(0.2),\n                                keras.layers.Flatten(),\n                                \n                                keras.layers.Dense(500, activation='relu'),\n                                keras.layers.Dropout(0.7),\n                                keras.layers.Dense(5, activation='softmax')\n                                ])\nmodel.summary()","a6b5f5e3":"#Compiling the model\n\nmodel.compile(optimizer = keras.optimizers.Adam(learning_rate=0.001), loss = 'categorical_crossentropy', metrics=['accuracy'])\n","acb91744":"history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=128), epochs=70, validation_data=(X_valid, y_valid))","d854dea0":"import pandas as pd\n\npd.DataFrame(history.history).plot(figsize=(8, 5))\nplt.grid(True)\nplt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\nplt.show()","dd112999":"**Splitting the datasets into training and validation sets**","36a407f6":"# *If this notebook helped you please upvote and comment your suggestions. Thanks* ","0003e81c":"**Viewing an image from the dataset**","27601438":"I have tried various other models. This is by far the best.","58503e47":"**Now let us create our custom cnn model**","1f443c6e":"**Calling the function to create the dataset and seprating images and their labels**","ff6901b9":"During last epochs accuracy decreased a bit. So we can train for few less epochs.\n\n","124a8ba9":"**Preprocessing the labels to categorical variables**","02aa2390":"**Creating the dataset**","64cd6f4e":"**Normalising the pixel values betweel 0 and 1**","30571d86":"# Custom Flower Recognition CNN model","4c2426ed":"**Let us go through the learning curves**","4650417d":"This is an optional step \n\nIt hepls if we do not want to create dataset everytime","166e1310":"Since we have around 800 images per class so it might not be sufficient to learn easily\n\nSo in next step we will artificially create some more examples from the training data\n","f2b1799d":"Let us feed the dataset through our model"}}