{"cell_type":{"ee63ac3f":"code","4929a0de":"code","8c3b2e3d":"code","9562d01b":"code","a42412e0":"code","9ce8d187":"code","7a4aae11":"code","6da24622":"code","b64214df":"code","6d399dd3":"code","48926d3a":"code","19aee32d":"code","f0084987":"code","34f104c1":"code","5e5dbf06":"code","5c8eb76b":"code","cc7aa09d":"code","b101c64d":"code","3037fb9a":"code","9d5f678b":"code","9f2673b1":"code","c6b43522":"code","561a9c7c":"code","ae64813e":"code","5df6ade3":"code","2d02b0f9":"code","4554be48":"code","636cd811":"code","b51c1ae1":"code","9178c712":"code","211b49f0":"code","b7851b2a":"code","7be2f48b":"code","e362d217":"code","5ede7e49":"code","8ed41ec6":"code","9c867f3d":"code","1bbc2ae5":"markdown","e0269edd":"markdown","6b983a01":"markdown","0a2e8ad0":"markdown","80dc5515":"markdown","e4b88e5e":"markdown","85b5402d":"markdown","436ad622":"markdown","4da28cc8":"markdown","14a31fb8":"markdown","7f095c0a":"markdown","843fddd2":"markdown","868797f2":"markdown","aef0e2b1":"markdown","6462544b":"markdown","0c2bd192":"markdown","18df14b2":"markdown","757bfc48":"markdown","a17010af":"markdown","d9f443f6":"markdown","cf53a0e0":"markdown","78aedbeb":"markdown","73639155":"markdown","556a7bb8":"markdown","3f48ed7a":"markdown","5d5892a4":"markdown","02d070f5":"markdown","7732a557":"markdown","4bc42e67":"markdown","f6d6a9b9":"markdown","d9f7ddac":"markdown","8048c334":"markdown","d04f162d":"markdown","b1cbe6a5":"markdown","58c4c228":"markdown","606659cd":"markdown"},"source":{"ee63ac3f":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","4929a0de":"dataset = pd.read_csv(\"..\/input\/car-price-prediction\/CarPrice_Assignment.csv\", index_col=0)","8c3b2e3d":"print(dataset.shape)","9562d01b":"print(dataset.head())","a42412e0":"print(dataset.info())","9ce8d187":"dataset['CarName'] = dataset['CarName'].str.split(' ',expand =True)[0]","7a4aae11":"print(dataset['CarName'].unique())","6da24622":"dataset['CarName'] = dataset['CarName'].replace({'maxda': 'mazda', 'porcshce': 'porsche', 'toyouta': 'toyota', \n                                                 'vokswagen': 'volkswagen', 'vw': 'volkswagen', 'Nissan': 'nissan'})","b64214df":"print(dataset['CarName'].unique())","6d399dd3":"print(dataset.duplicated().sum())","48926d3a":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.kdeplot(dataset['price'],  color='blue', shade=True)\nplt.xlabel(\"price\")\n\nplt.subplot(1,2,2)\nsns.boxplot(dataset['price'], palette=\"Set3\")\n\nplt.show()","19aee32d":"plt.figure(figsize=(16,5))\nsorted = dataset.groupby(['CarName'])['price'].median().sort_values()\nsns.boxplot(x=dataset['CarName'], y=dataset['price'], order = list(sorted.index))\nplt.title(\"Car Name vs Price\")\nplt.xticks(rotation=90)\nplt.show()","f0084987":"sns.pairplot(dataset, diag_kind=\"kde\", vars=['symboling', 'wheelbase', 'carlength', 'carwidth', 'carheight', 'curbweight', 'enginesize', 'price'])\nplt.show()","34f104c1":"sns.pairplot(dataset, diag_kind=\"kde\", vars=['boreratio', 'stroke', 'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg', 'price'])\nplt.show()","5e5dbf06":"categorical_columns = ['fueltype', 'aspiration', 'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'enginetype', 'cylindernumber', 'fuelsystem']\ncategorical_data = dataset[categorical_columns]","5c8eb76b":"plt.figure(figsize=(20,15))\nfor index, item in enumerate(categorical_columns, 1):\n    plt.subplot(3,3,index)\n    sns.barplot(x = item, y = 'price', data = dataset)\nplt.show()  ","cc7aa09d":"from scipy import stats\nnumerical_columns = dataset.select_dtypes(exclude='object').columns\nfor i in (list(numerical_columns)):\n    pearson_coef, p_value = stats.pearsonr(dataset[i], dataset['price'])\n    print(i.capitalize(), \"Pearson Correlation:\", pearson_coef, \"P-value:\", p_value)\n    print(\"The correlation is not significant:\", p_value>0.05)\n    print()","b101c64d":"dataset.drop(['symboling', 'carheight', 'stroke', 'compressionratio', 'peakrpm', 'doornumber'], axis=1, inplace=True)","3037fb9a":"print(dataset.shape)","9d5f678b":"data_new = dataset.copy()\nt_price = data_new.groupby(['CarName'])['price'].mean()\ndata_new = data_new.merge(t_price.reset_index(), how='left', on='CarName')\nbins = [0,10000,20000,40000]\nlabel =['Budget_Friendly','Medium_Range','Expensive_Cars']\ndataset['Cars_Category'] = pd.cut(data_new['price_y'], bins, right=False, labels=label)\ndataset.drop(\"CarName\", axis=1, inplace=True)\ndataset.head()","9f2673b1":"column = ['fueltype','aspiration','carbody', 'drivewheel', 'enginelocation', 'enginetype','cylindernumber', 'fuelsystem', 'Cars_Category']\ndummies = pd.get_dummies(dataset[column], drop_first = True)\ndataset = pd.concat([dataset, dummies], axis = 1)\ndataset.drop(column, axis = 1, inplace = True)","c6b43522":"print(dataset.shape)","561a9c7c":"from sklearn.preprocessing import QuantileTransformer\ntransform =  QuantileTransformer(n_quantiles=205)\ncolumns = ['wheelbase', 'carlength', 'carwidth', 'curbweight','enginesize','boreratio','horsepower','citympg','highwaympg','price']\ndataset[columns] = transform.fit_transform(dataset[columns]) ","ae64813e":"print(dataset.columns.values)","5df6ade3":"plt.figure(figsize = (40, 40))\nsns.heatmap(dataset.corr(method ='pearson'), cmap='PuBu', annot=True, linewidths=.5, annot_kws={'size':8})\nplt.show()","2d02b0f9":"print(dataset.corr(method ='pearson').unstack().sort_values().drop_duplicates())","4554be48":"data = list(dataset.columns)\nfor i in data:\n    pearson_coef, p_value = stats.pearsonr(dataset[i], dataset['price'])\n    print(i.capitalize(), \"Pearson Correlation:\", pearson_coef, \"P-value:\", p_value)\n    print(\"The correlation is not significant:\", p_value>0.05)\n    if p_value>0.05:\n        dataset.drop(i, axis=1, inplace=True)\n    print()","636cd811":"print(dataset.shape)","b51c1ae1":"X = dataset.drop('price', axis=1)\ny = dataset['price']","9178c712":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"variables\"] = X.columns\nvif['vif'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nfor index,column in enumerate(X.columns):\n    print(index, column, vif['vif'][index])\n    if vif['vif'][index]>10:\n        vif = vif.drop([index], axis=0)","211b49f0":"print(vif)","b7851b2a":"print(list(vif['variables']))","7be2f48b":"columns = list(vif['variables'])\ndata = dataset [columns]\ndata = pd.concat([data, dataset['price']], axis=1)","e362d217":"from sklearn.model_selection import train_test_split\nX = data.drop('price', axis=1)\ny = data ['price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, test_size = 0.25, random_state=42)","5ede7e49":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nlr = LinearRegression()\nlr.fit(X_train,y_train)\npred_test = lr.predict(X_test)\npred_train = lr.predict(X_train)\nprint(\"R Squared Value of Train Data: {}\".format(r2_score(y_train, pred_train)))\nprint(\"R Squared Value of Test Data: {}\".format(r2_score(y_test, pred_test)))","8ed41ec6":"plt.figure(figsize=(16,5))\n\nplt.subplot(1,2,1)\nsns.distplot((y_train - pred_train))\nplt.title('Train Data Residual Analysis', fontsize = 20)                   \nplt.xlabel('Errors', fontsize = 18)\n\nplt.subplot(1,2,2)\nsns.distplot((y_test - pred_test))\nplt.title('Test Data Residual Analysis', fontsize = 20)              \nplt.xlabel('Errors', fontsize = 18)\n\nplt.show()","9c867f3d":"from yellowbrick.regressor import ResidualsPlot\nvisualizer = ResidualsPlot(lr)\nvisualizer.fit(X_train, y_train)\nvisualizer.score(X_test, y_test)\nvisualizer.poof()\nplt.show()","1bbc2ae5":"### Correlation Between Variables","e0269edd":"Stroke, Compressionratio, Peakrpm doesn't affect price. There is not a linear relationship. I will drop these variables as well.\n\nFirstly, I will analyze the relationship between categorical variables and the price.","6b983a01":"I will analyze this dataset based on some assumptions of linear regression.\n\nLinear Relationship between the features and target - Linear regression requires the relationship between the independent and dependent variables to be linear. Linearity can be checked with the scatter plot and Pearson Correlation.\n\nNo Multicollinearity - Linear regression assumes that the independent variables are not highly correlated with each other. This assumption is tested using Variance Inflation Factor (VIF) values.\n\nHomoscedasticity \u2013 This assumption states that the variance of errors are similar across the values of the independent variables. A plot of standardized residuals versus predicted values can show whether points are equally distributed across all values of the independent variables.\n\nNormal distribution of errors \u2013 Linear regression assumes that the residuals are normally distributed.","0a2e8ad0":"Linear regression assumes the independent variables are not related with each other. If the correlation degree is high, it will cause problems when we fit the model.\n\nTo check multicollinearity, I will use heatmap and VIF.","80dc5515":"I will add \"cars category\" column to the dataset according to car prices. I will group cars as budget friendly, medium range, expensive cars. I will drop \"cars name\" column as I will add \"cars category\" column.","e4b88e5e":"I will check the residual normality assumption visually. Errors should be normally distributed.","85b5402d":"* diesel-powered cars more expensive than the gas-powered cars. \n* convertible and hardop is more expensive than sedan, hatchback, and wagon.\n* rwd drivewheel is more expensive than fwd and 4wd.\n* rear engine location is more expensive.\n* If the cylinder number is high, price is high.\n* mpfi and idi fuel systems is relatively expensive than other types.","436ad622":"Symboling, Carheight, Stroke, Compressionratio, Peakrpm has a weak relationship with Price. The correlation between these variables and the price is not statistically significant. I will drop them from the dataset.\n\nWheelbase, Boreratio has a moderate relationship with Price. The correlation is statistically significant.\n\nCarlength, Carwidth, Curbweight, Enginesize, Horsepower has a strong positive relationship with Price. The correlation is statistically significant.\n\nCitympg, Highwaympg has a strong negative relationship with Price. The correlation is statistically significant.","4da28cc8":"# **1. Reading And Understanding The Data**","14a31fb8":"\nMulticollinearity exists among predictors. After even transforming the variables, there is a strong relationships between independent variables. For this reason, I will use Variation Inflation Factor (VIF) to detect multicollinearity and to eliminate these variables from the dataset.","7f095c0a":"There are no duplicated values in the dataset.","843fddd2":"I will check ***Homoscedasticity***. There should not be specific pattern in the distribution of residuals. ","868797f2":"# 2. Cleaning The Data","aef0e2b1":"I will convert categorical variables to numerical variables. Categorical variables in the dataset are nominal. I can apply OneHotEncoder.","6462544b":"On the other hand, door number has no relationship with the price at all. It is clear visually. I will drop door number from the dataset.","0c2bd192":"### Converting to numerical values","18df14b2":"### Checking Pearson Correlation","757bfc48":"Some car names are badly written in the dataset. We need to fix them to get more accurate results.\n * maxda = mazda \n * toyouta = toyota\n * vokswagen = volkswagen\n * vw = volkswagen\n * porcshce = porsche\n * Nissan = nissan","a17010af":"# 4. Data Preparation","d9f443f6":"Firstly, I will check the linear relationship between variables visually. After that, I will analyze Pearson Correlation and P-values to be able to understand the correlation. If the correlation is weak, I will drop related variables.","cf53a0e0":"Ordinary Least Squares method does not make normality assumptions about the data. It makes normality assumptions about the residuals. I will not transform the data to ensure Gaussian distribution. \n\nOn the other hand, linear regression is sensitive to outliers. Quantile Transformer is robust to outliers. It will transform the variables and handle the outliers in the dataset.","78aedbeb":"There are no null values in the dataset. On the other hand, there are some categorical variables.","73639155":"Chevrolet is the cheapest car. Honda, Dodge, Plymouth has cheap prices, but these cars have some outlier prices. Bmw, Porsche, Buick, Jaguar has the highest prices.\n","556a7bb8":"### Rescaling","3f48ed7a":"A variance inflation factor(VIF) detects multicollinearity in regression analysis. I will select the features with VIF that is below 10.","5d5892a4":"I will check Pearson Correlation to investigate the linear relationship between two continuous variables. If the features have a weak relationship with the price, I will drop from the dataset. \n\nI will also check P-value to analyze the correlation is statistically significant or not. It is generally accepted that if the value is above 0.05, the correlation is not significant. If it is below 0.05, the correlation is significant.","02d070f5":"Firstly, it is better to check car price distribution.","7732a557":"These are all the columns in the dataset now.","4bc42e67":"# 3. Exploratory Data Analysis","f6d6a9b9":"Before eliminating correlated variables, I will check Pearson Correlation and p values. I will eliminate the features based on the accordingly.","d9f7ddac":"Symboling and Carheight doesn't affect price. There is not a linear relationship.","8048c334":"# Assumptions Of Linear Regression Algorithm","d04f162d":"### Variation Inflation Factor (VIF)","b1cbe6a5":"# 6. Evaluating The Model","58c4c228":"# 5. Building the Model","606659cd":"Car price distribution is left skewed. On the other hand, there are some outliers in the dataset. Since linear regression is sensitive to outliers, I will analyze them later."}}