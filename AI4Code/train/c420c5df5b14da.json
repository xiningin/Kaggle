{"cell_type":{"5ad3dc5a":"code","9e8fcf30":"code","0db5f429":"code","9283661d":"code","b97ae13f":"code","01b3faca":"code","4d6e48d6":"code","02d5323d":"code","d7520cfa":"markdown","3d5fed7b":"markdown","705ea63c":"markdown","b8e58051":"markdown","0d65cb98":"markdown"},"source":{"5ad3dc5a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9e8fcf30":"full_train = pd.read_csv(\"\/kaggle\/input\/riiid-test-answer-prediction\/train.csv\",nrows=20000)\nquestions = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv')\nlectures = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/lectures.csv')","0db5f429":"fmean = full_train.mean()\nfull_train = full_train.fillna(fmean)","9283661d":"features = ['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n       'task_container_id', 'user_answer',\n       'prior_question_elapsed_time']\ntarget = ['answered_correctly']","b97ae13f":"X = full_train[features]\ny = full_train[target]","01b3faca":"#split the dataset\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)","4d6e48d6":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score","02d5323d":"'''code taken from https:\/\/www.kaggle.com\/nilanml\/telecom-customer-churn-voting-80-1-accuracy'''\n\nclassifiers = [['Neural Network :', MLPClassifier()],\n               ['LogisticRegression :', LogisticRegression()],\n               ['ExtraTreesClassifier :', ExtraTreesClassifier()],\n               ['DecisionTree :',DecisionTreeClassifier()],\n               ['RandomForest :',RandomForestClassifier()], \n               ['Naive Bayes :', GaussianNB()],\n               ['KNeighbours :', KNeighborsClassifier()],\n               ['SVM :', SVC()],\n               ['AdaBoostClassifier :', AdaBoostClassifier()],\n               ['GradientBoostingClassifier: ', GradientBoostingClassifier()],\n               ['XGB :', XGBClassifier()],\n               ['CatBoost :', CatBoostClassifier(logging_level='Silent')]]\n\npredictions_df = pd.DataFrame()\npredictions_df['answered_correctly'] = y_test['answered_correctly'].values\n\nfor name,classifier in classifiers:\n    classifier = classifier\n    classifier.fit(X_train, y_train.values.ravel())\n    predictions = classifier.predict(X_test)\n    predictions_df[name.strip(\" :\")] = predictions\n    print(name, accuracy_score(y_test, predictions))","d7520cfa":"### Just see which model gives the best score and then try to improve that model by hyperparameter optimization.","3d5fed7b":"### You can use the evaluation metric according to your need","705ea63c":"### If there are two three models which gives you nearly same score then consider those models as well ","b8e58051":"# Pour out everything\n### If you are new to machine learning and if you don't know which algorithm to use then this notebook is for you!","0d65cb98":"### Best way to do machine learning modelling if you don't know which one to use specifically is to pour out all the models into the loop and then analyze"}}