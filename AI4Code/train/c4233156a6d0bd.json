{"cell_type":{"8efc94cf":"code","7b3a26c8":"code","6174c73c":"code","98ffcb24":"code","59cb110d":"code","21413935":"code","28e1e5c0":"code","a338b965":"code","63335edb":"code","ef77ff2e":"code","bde0bfe4":"code","1c833196":"code","4f11c157":"code","908ca5f6":"code","f415996d":"code","3a995c9c":"code","2aeedb77":"code","07c35134":"code","3a7af16b":"code","27d60f8c":"code","964f5830":"code","ff7fed22":"code","f6476b52":"code","3e97a5f8":"code","615a050a":"code","15f1bbb6":"code","a12deee5":"code","d26ed78b":"markdown","d869d81d":"markdown","df95436e":"markdown","b8af7947":"markdown","444725aa":"markdown","4c5b3021":"markdown","41a47c67":"markdown","0e621498":"markdown","490b972b":"markdown","a63052a9":"markdown","f6b92305":"markdown","99a93a78":"markdown","d659b604":"markdown","f95b2ed1":"markdown","220694ce":"markdown","b1e08391":"markdown","02c0ccce":"markdown","0a0071b6":"markdown","c76eeba7":"markdown","00de45f5":"markdown","8bc6a509":"markdown"},"source":{"8efc94cf":"import warnings\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport torch\nimport torchvision\nfrom torchvision import transforms\n\nwarnings.filterwarnings(\"ignore\")","7b3a26c8":"!wget -c -O pic.png \"https:\/\/source.unsplash.com\/random\/750x750\"","6174c73c":"img = torchvision.io.read_image(\"pic.png\")\n\n# Using GPU if available\nif torch.cuda.is_available():\n    img = img.to(\"cuda\")","98ffcb24":"img.shape","59cb110d":"def display_img(img: torch.Tensor) -> None:\n    plt.imshow(img.permute(1, 2, 0).cpu())","21413935":"display_img(img)","28e1e5c0":"x = transforms.CenterCrop([200, 200])\ndisplay_img(x.forward(img))","a338b965":"fig, ax = plt.subplots(2, 2, figsize=(12, 8))\nNUM = 0.9\nx = transforms.ColorJitter(brightness=NUM)\nax[0, 0].imshow(x.forward(img).permute(1, 2, 0).cpu())\nax[0, 0].set_title(f\"brightness - {NUM}\")\nx = transforms.ColorJitter(contrast=NUM)\nax[0, 1].imshow(x.forward(img).permute(1, 2, 0).cpu())\nax[0, 1].set_title(f\"contrast - {NUM}\")\nx = transforms.ColorJitter(saturation=NUM)\nax[1, 0].imshow(x.forward(img).permute(1, 2, 0).cpu())\nax[1, 0].set_title(f\"saturation - {NUM}\")\nx = transforms.ColorJitter(hue=0.45)\nax[1, 1].imshow(x.forward(img).permute(1, 2, 0).cpu())\nax[1, 1].set_title(f\"hue - 0.45\")\nfig.show()","63335edb":"x = transforms.Grayscale(num_output_channels=3)\ndisplay_img(x.forward(img))","ef77ff2e":"fig, ax = plt.subplots(2, 2, figsize=(12, 8))\nNUM = 100\nx = transforms.Pad(NUM, padding_mode=\"constant\")\nax[0, 0].imshow(x.forward(img).permute(1, 2, 0).cpu())\nx = transforms.Pad(NUM, padding_mode=\"edge\")\nax[0, 1].imshow(x.forward(img).permute(1, 2, 0).cpu())\nx = transforms.Pad(NUM, padding_mode=\"reflect\")\nax[1, 0].imshow(x.forward(img).permute(1, 2, 0).cpu())\nx = transforms.Pad(NUM, padding_mode=\"symmetric\")\nax[1, 1].imshow(x.forward(img).permute(1, 2, 0).cpu())\nfig.show()","bde0bfe4":"x = transforms.RandomAffine(30)\ndisplay_img(x.forward(img))","1c833196":"x = transforms.RandomAffine(0, translate=(0.2, 0.2))\ndisplay_img(x.forward(img))","4f11c157":"x = transforms.RandomAffine(0, scale=(0.5, 5))\ndisplay_img(x.forward(img))","908ca5f6":"x = transforms.RandomAffine(0, shear=45)\ndisplay_img(x.forward(img))","f415996d":"x = transforms.RandomCrop([200, 200])\ndisplay_img(x.forward(img))","3a995c9c":"x = transforms.RandomGrayscale(p=0.9)\ndisplay_img(x.forward(img))","2aeedb77":"x = transforms.RandomPerspective(distortion_scale=0.5, p=0.9)\ndisplay_img(x.forward(img))","07c35134":"x = transforms.RandomHorizontalFlip(p=0.9)\ndisplay_img(x.forward(img))","3a7af16b":"x = transforms.RandomVerticalFlip(p=0.75)\ndisplay_img(x.forward(img))","27d60f8c":"x = transforms.RandomResizedCrop(500)\ndisplay_img(x.forward(img))","964f5830":"x = transforms.RandomRotation(45)\ndisplay_img(x.forward(img))","ff7fed22":"x = transforms.FiveCrop([375, 375])\nfig, ax = plt.subplots(2, 2, figsize=(12, 8))\nfigs = x.forward(img)\nax[0, 0].imshow(figs[0].permute(1, 2, 0).cpu())\nax[0, 1].imshow(figs[1].permute(1, 2, 0).cpu())\nax[1, 0].imshow(figs[2].permute(1, 2, 0).cpu())\nax[1, 1].imshow(figs[3].permute(1, 2, 0).cpu())\nfig.show()","f6476b52":"display_img(figs[4])","3e97a5f8":"x = transforms.Resize([100, 100])\ndisplay_img(x.forward(img))","615a050a":"x = transforms.GaussianBlur(kernel_size=29, sigma=11)\ndisplay_img(x.forward(img))","15f1bbb6":"img_f = img.float()\nx = transforms.Normalize(torch.mean(img_f), torch.std(img_f))\ndisplay_img(x.forward(img_f))","a12deee5":"x = transforms.RandomErasing(p=0.75)\ndisplay_img(x.forward(img))","d26ed78b":"First we will fetch a random picture","d869d81d":"`Resize` resizes the input image to the given size.","df95436e":"`ColorJitter` randomly change the brightness, contrast, saturation and hue of an image. We can control four parameters independently.\n\nFor brightness, saturation and contrast, we can either pass a single number which a random number will be chosen uniformly from $[\\max(0, 1 - x), 1 + x]$ or we can pass $[\\min, \\max]$ as non-negative numbers.\n\nFor hue, we can pass a single number or a tuple where a random number will be chosen uniformly between $[-\\text{hue}, \\text{hue}]$ or $[\\min, \\max]$ where $0 \\le \\text{hue} \\le 0.5$ or $-0.5 <= \\min <= \\max <= 0.5$.","b8af7947":"`Normalize` normalizes a tensor image with mean and standard deviation.\n\n$$\\text{out} = \\frac{\\text{in} - \\mu}{\\sigma}$$\n\nwhere $\\mu$ is mean and $\\sigma$ is standard deviation.\n\nWe need to convert our image to float for the operations to take place successfully.","444725aa":"# Image Tranformations using PyTorch\n\nOften in computer vision, we first need to apply certain types of transformations before we can actually train the models. In this notebook, we will explore some commonly used helpful tranformations.\n\nFor our purpose, we will be using the `torchvision` package. [PyTorch](https:\/\/pytorch.org\/) has a subpackage [torchvision](https:\/\/pytorch.org\/vision\/stable\/index.html) that consists of popular datasets, model architectures, and common image transformations for computer vision.","4c5b3021":"`RandomErasing` randomly selects a rectangle region and erases its pixels.","41a47c67":"PyTorch stores images in form of $[C, H, W]$ while plotting libraries like matplotlib, numpy and PIL use $[H, W, C]$ format. So we need to use the `permute` function that will produce a view of the tensor without actually copying and hence it is very efficient. Also we need to use the `cpu` function as matplotlib cannot directly read tensors from GPU.","0e621498":"`Pad` pads the given image on all sides with the given \"pad\" value. We can specify a `fill` argument to change the pixel value of the padding. We can also specify a `padding_mode`.\n\nDescription of various `padding_mode`:\n\n- \"constant\": pads with a constant value, this value is specified with fill\n- \"edge\": pads with the last value at the edge of the image\n- \"reflect\": pads with reflection of image without repeating the last value on the edge\n- \"symmetric\": pads with reflection of image repeating the last value on the edge","490b972b":"`CenterCrop` crops the given image at the center. We can pass a sequence of $[H, W]$ to crop the image with the required dimensions.","a63052a9":"`RandomPerspective` performs a random perspective transformation of the given image with a given probability. `distortion_scale` argument is used to control the degree of distortion and ranges from $[0, 1]$.","f6b92305":"\nThis was a basic use of some useful and handy image transformations.\n\nThis isn't a exhaustive list of tranforms. The entire set can be found by referring to its documentation here at https:\/\/pytorch.org\/vision\/stable\/transforms.html.\n\nAll transformations accept PIL Image, Tensor Image or batch of Tensor Images as input. Tensor Image is a tensor with $(C, H, W)$ shape, where $C$ is a number of channels, $H$ and $W$ are image height and width. Batch of Tensor Images is a tensor of $(B, C, H, W)$ shape, where $B$ is a number of images in the batch. Deterministic or random transformations applied on the batch of Tensor Images identically transform all the images of the batch.\n\nFurther we can also apply a pipeline of transforms.\n\n---","99a93a78":"`RandomVerticalFlip` vertically flip the given image randomly with a given probability.","d659b604":"`RandomResizedCrop` creates a crop of random size (default: of 0.08 to 1.0) of the original size and a random aspect ratio (default: of 3\/4 to 4\/3) of the original aspect ratio is made. This crop is finally resized to given size.\n\nThis is popularly used to train the Inception networks.","f95b2ed1":"`RandomRotation` rotates the image by angle.","220694ce":"`RandomCrop` crops the given image at a random location with the desired output size.","b1e08391":"`FiveCrop` crops the given image into four corners and the central crop of the input size. Similarly, `TenCrop` produces the images of `FiveCrop` and also produces a flipped version of them.","02c0ccce":"`RandomGrayscale` randomly convert image to grayscale with a probability of $p$.","0a0071b6":"`RandomHorizontalFlip` horizontally flip the given image randomly with a given probability.","c76eeba7":"`RandomAffine` performs random affine transformation of the image keeping center invariant. We can tune following parameters:\n\n- degrees\n- translate\n- scale\n- shear\n- interpolation\n- fill","00de45f5":"`GaussianBlur` blurs image with randomly chosen Gaussian blur. We must specify `kernel_size` and `sigma` (Standard deviation to be used for creating kernel to perform blurring)","8bc6a509":"`Grayscale` converts image to grayscale. We can choose the number of output channel as $1$ or $3$."}}