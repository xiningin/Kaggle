{"cell_type":{"fdc104c0":"code","46a3f3ed":"code","da213846":"code","988ee904":"code","6d055c7f":"code","d7314cd4":"code","0911ba6c":"code","95358081":"code","b427aa61":"code","887be1d6":"code","f2b7ed2c":"code","da72b957":"code","e7885826":"code","04729b82":"code","06884187":"code","ce85cbd9":"code","d49bcd22":"code","ecdf8ca6":"code","7f7fb4b8":"markdown","0f2b799d":"markdown","8360bf7d":"markdown","be08dcc5":"markdown","6832d48b":"markdown","879db7d9":"markdown","d18b99ee":"markdown","8604ae71":"markdown"},"source":{"fdc104c0":"import cv2 as cv\n# from google.colab.patches import cv2_imshow\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, TensorDataset, DataLoader\n\nimport scipy.ndimage as sci\nimport matplotlib.pyplot as plt\n\n# Delete if dataset isn't in the Google Drive\n# from google.colab import drive\n# drive.mount('\/content\/drive')","46a3f3ed":"# Reading files\nN_of_People = 103\nN_of_Photos = 12 \n\ndata_photo = []\nstr_data_labels = []\n\n# While compiling it, please, change path to the dataset to location in your machine.\n# Here I'm using my GoogleDrive\nphoto_path = '..\/input\/gi4e-gaze-interaction-for-everybody\/images'\nlabels_path = '..\/input\/gi4e-gaze-interaction-for-everybody\/labels'\n\nfor i in range(N_of_People):\n    photo_list = []\n    frac_label_list = []\n    # Reading .txt labels\n    if i < 9:\n      txt_path = labels_path + f'\/00{i+1}_image_labels.txt'\n      png_1 = f'\/00{i+1}'\n    elif 9 >= i < 99:\n      txt_path = labels_path + f'\/0{i+1}_image_labels.txt'\n      png_1 = f'\/0{i+1}'\n    elif i >= 99:\n      txt_path = labels_path + f'\/{i+1}_image_labels.txt'\n      png_1 = f'\/{i+1}'\n    with open(txt_path, 'r') as f:\n        label_list = f.readlines()\n    for j in range(N_of_Photos):\n        frac_label_list.append(label_list[j].split()[1:])\n        # Reading an .png image and converting it to GrayScale\n        if j < 9:\n          png_2 = f'_0{j+1}.png'\n        elif j>= 9:\n          png_2 = f'_{j+1}.png'\n        png_path = photo_path + png_1 + png_2\n        photo_list.append(cv.imread(png_path, cv.IMREAD_GRAYSCALE)) \n    str_data_labels.append(frac_label_list)\n    data_photo.append(photo_list)\n\nstr_data_labels = np.array(str_data_labels)\nfloat_data_labels = str_data_labels.astype(float)\n\ndata_labels = float_data_labels.astype(int)\ndata_photo = np.array(data_photo)\n","da213846":"# Test: Finding eyes and irises on an arbitrary photo\n\nu = 0     # User number\np = 0     # Photo number\n\nexample = data_photo[u][p].copy()\n\n# left eye\ncv.rectangle(example, (data_labels[u][p][0], data_labels[u][p][1]), (data_labels[u][p][4],  data_labels[u][p][5]), (255, 0, 0), thickness=1 ) \ncv.circle(example, (data_labels[u][p][2], data_labels[u][p][3]), 1, (255,0,0), thickness=-1)\n\n# right eye\ncv.rectangle(example, (data_labels[u][p][6], data_labels[u][p][7]), (data_labels[u][p][10], data_labels[u][p][11]), (255, 0, 0), thickness=1 )\ncv.circle(example, (data_labels[u][p][8], data_labels[u][p][9]), 1, (255,0,0), thickness=-1)\n\nplt.imshow(example, cmap = 'gray')","988ee904":"data_photo = data_photo.reshape(103*12,600,800)\ndata_labels = data_labels.reshape(103*12,12)\n\nblank = np.zeros((600,800), dtype='uint8')\nx = []\ny = []\n\n# Cropping data_sets:\nfor i in range(N_of_People * N_of_Photos):\n  # LEFT eye\n  l_center_x = data_labels[i][0] - abs(data_labels[i][0] - data_labels[i][4]) \/\/ 2\n  l_center_y = data_labels[i][1] - abs(data_labels[i][1] - data_labels[i][5]) \/\/ 2\n  left_eye = data_photo[i][l_center_y -24 : l_center_y + 24  , l_center_x - 24: l_center_x + 24 ] \n  x.append(left_eye)\n\n  # OPTIMIZATION: [list] - [list] can be used\n  l_iris_x = data_labels[i][2] - (l_center_x - 24)\n  l_iris_y = data_labels[i][3] - (l_center_y - 24)\n  left_eye_iris = blank.copy()[l_center_y - 24 : l_center_y + 24  , l_center_x - 24: l_center_x + 24 ]\n  left_eye_iris[l_iris_x, l_iris_y] = 255\n  left_eye_iris = sci.gaussian_filter(left_eye_iris, sigma = 1)\n  left_eye_iris = left_eye_iris * 4    # Increasing intencity\n  y.append(left_eye_iris)\n\n  # RIGHT eye\n  r_center_x = data_labels[i][6] - abs(data_labels[i][10] - data_labels[i][6]) \/\/ 2\n  r_center_y = data_labels[i][7] - abs(data_labels[i][11] - data_labels[i][7]) \/\/ 2\n  right_eye = data_photo[i][r_center_y - 24 : r_center_y + 24  , r_center_x - 24: r_center_x + 24 ]\n  x.append(right_eye)\n\n  r_iris_x = data_labels[i][8] - (r_center_x - 24)\n  r_iris_y = data_labels[i][9] - (r_center_y - 24)\n  right_eye_iris = blank.copy()[r_center_y - 24 : r_center_y + 24  , r_center_x - 24: r_center_x + 24 ]\n  right_eye_iris[r_iris_x, r_iris_y] = 255\n  right_eye_iris = sci.gaussian_filter(right_eye_iris, sigma = 1)\n  right_eye_iris = right_eye_iris * 4     # Increasing intencity\n  y.append(right_eye_iris)\n \nx = np.array(x)\ny = np.array(y)\n\nprint(x.shape, y.shape)","6d055c7f":"plt.imshow(x[0], cmap = 'gray')","d7314cd4":"plt.imshow(y[0], cmap = 'gray')","0911ba6c":"# Normalization\nx = x\/255\ny = y\/255","95358081":"# Shuffling and splitting\n\nnp.random.shuffle(x)\nx_train, x_test = x[:1980], x[1980:]\ny_train, y_test = y[:1980], y[1980:]\n\n# Turn into tensors\nx_train = torch.Tensor(x_train[:, np.newaxis] )\nx_test = torch.Tensor(x_test[:, np.newaxis] )\ny_train = torch.Tensor(y_train[:, np.newaxis] )\ny_test = torch.Tensor(y_test[:, np.newaxis] )","b427aa61":"x_train.shape","887be1d6":"train_ds = TensorDataset(x_train, y_train)\ntest_ds = TensorDataset(x_test, y_test)\ntrain_ds = DataLoader(train_ds, 10)\ntest_ds = DataLoader(test_ds, 10)","f2b7ed2c":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        # Use some MaxPool layers\n        self.conv1 = nn.Conv2d(1, 64, 3, padding = 1)               # 48*48\n        self.conv2 = nn.Conv2d(64, 128, 3, padding = 1) \n        self.pool1 = nn.MaxPool2d(2, stride = 2)                       # 24*24\n        self.conv3 = nn.Conv2d(128, 256, 3, padding = 1)\n        self.pool2 = nn.MaxPool2d(2, stride = 2)                        # 12*12\n        self.conv4 = nn.Conv2d(128, 64, 3, padding = 1)\n        self.conv5 = nn.Conv2d(64, 1, 3, padding = 1)\n\n        self.t_conv1 = nn.ConvTranspose2d(256, 64, 3, stride = 5, padding = 5)\n        self.t_conv2 = nn.ConvTranspose2d(256, 128, 3, stride = 3, padding = 6)\n        self.t_conv3 = nn.ConvTranspose2d(128, 64, 3, stride = 3, padding = 12)\n        self.t_conv4 = nn.ConvTranspose2d(64, 1, 3, stride=1, padding = 1)\n\n    def forward(self, x, a_func):\n        x = a_func(self.conv1(x))\n        x_skip = x\n        x = a_func(self.pool1(self.conv2(x)))\n        x = a_func(self.pool2(self.conv3(x)))\n        y = x\n        x = a_func(self.t_conv1(y))\n      \n        x = torch.cat((x, x_skip), 1)\n        x = a_func(self.conv4(x))\n        x = F.sigmoid(self.conv5(x))\n\n        y = a_func(self.t_conv2(y))\n        y = a_func(self.t_conv3(y))\n        y = F.sigmoid(self.t_conv4(y))\n        return x, y\n\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\nmodel_cnn = Net().to(device)\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(\"Number of params in the CNN model:\", count_parameters(model_cnn))","da72b957":"def train( model, device, train_loader, a_func, loss_func, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output_1, output_2 = model(data, a_func)\n        # loss - is our custom loss function\n        loss_1 = loss_func(output_1[:,:,12:36,12:36], target[:,:,12:36,12:36]) \n        loss_2 = loss_func(output_2, data) \n        loss = loss_1 + loss_2\n        loss.backward()\n        optimizer.step()\n    return loss.item()\n            \ndef test( model, device, a_func, loss_func, test_loader):\n    model.eval()\n    test_loss, loss1, loss2 = 0,0,0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output_1, output_2  = model(data, a_func)\n            loss1 += loss_func(output_1[:,:,12:36,12:36], target[:,:,12:36,12:36], reduction = 'sum').item() \n            loss2 += loss_func(output_2, data, reduction = 'sum').item() \n\n    test_loss = loss1 + loss2\n    test_loss \/= len(test_loader.dataset) * 10\n \n    return test_loss","e7885826":"optimizers = [optim.Adam, optim.Adamax, optim.RMSprop, optim.SGD]\nactivations = [F.relu, F.tanh, F.sigmoid]\nloss_functions = [F.mse_loss, F.l1_loss]\n\nepochs = 15\nlr = 0.01\nmomentum = 0.5\nlog_interval = 700\n\nfor i in optimizers:\n  for j in activations:\n    for k in loss_functions:\n      tr_error, test_error = [], []\n      final_model = Net().to(device)\n      if i == optim.SGD:\n        optimizer = i(final_model.parameters(), lr=lr, momentum = momentum)\n      else:\n        optimizer = i(final_model.parameters())\n      for epoch in range(1, epochs + 1):\n        tr_error.append(train(final_model, device, train_ds, j, k, optimizer, epoch))\n        test_error.append(test(final_model, device, j, k, test_ds))\n      min_tr_e = min(tr_error)\n      min_test_e = min(test_error)\n      print(f'Results for {i.__name__} + {j.__name__} + {k.__name__}: train_error = {round(min_tr_e, 5)}, test_error = {round(min_test_e, 5)} \\n')\n      final_model.eval()\n      with torch.no_grad():\n        for data, target in test_ds:\n          data, target = data.to(device), target.to(device)\n          iris, remake  = final_model(data, F.relu)\n          fig, axis = plt.subplots(1, 3)\n          axis[0].imshow(data.cpu().detach()[0][0], cmap=\"gray\")\n          axis[0].set_title(f'{i.__name__} + {j.__name__} + {k.__name__}')\n          axis[1].imshow(iris.cpu().detach()[0][0], cmap=\"gray\")\n          axis[2].imshow(remake.cpu().detach()[0][0], cmap=\"gray\")\n          break\n","04729b82":"epochs = 40\nlr = 0.01\nmomentum = 0.5\nlog_interval = 700 \n\n# training CNN model\nmodel_cnn = Net().to(device)\nmodel = model_cnn\noptimizer = optim.Adam(model.parameters())\n\ntr_error, test_error = [], []\n\nfor epoch in range(1, epochs + 1):\n    tr_error.append(train(model, device, train_ds, F.tanh, F.mse_loss, optimizer, epoch))\n    test_error.append(test(model, device, F.tanh, F.mse_loss, test_ds))","06884187":"epoch_list = np.arange(1,epochs + 1)\n\n# Printing error graph\n\nplt.figure()\nplt.plot(epoch_list,tr_error, linewidth=2, color = 'blue', label=\"tr_error\")\nplt.xlabel('epoch', fontsize=18)\nplt.xlim([0, max(epoch_list)])\nplt.ylim([0,max(tr_error)])\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.plot(epoch_list,test_error, linewidth=2, color = 'red', label=\"test_error\")\nplt.xlabel('epoch', fontsize=18)\nplt.xlim([0, max(epoch_list)])\nplt.ylim([0,max(test_error)])\nplt.legend()\nplt.show()","ce85cbd9":"model.eval()\nwith torch.no_grad():\n  for data, target in test_ds:\n    data, target = data.to(device), target.to(device)\n    iris, remake  = model(data, F.tanh)\n    for i in range(10):\n      fig, axis = plt.subplots(1, 4)\n      axis[0].imshow(data.cpu().detach()[i][0], cmap=\"gray\")\n      axis[0].set_title(f'{i+1}. Original')\n      axis[1].imshow(target.cpu().detach()[i][0], cmap=\"gray\")\n      axis[1].set_title(f'{i+1}. Target')\n      axis[2].imshow(iris.cpu().detach()[i][0], cmap=\"gray\")\n      axis[2].set_title(f'{i+1}. Iris')\n      axis[3].imshow(remake.cpu().detach()[i][0], cmap=\"gray\")\n      axis[3].set_title(f'{i+1}. Autoencoder_output')\n    break","d49bcd22":"max_list = []\nphoto_list = []\nfor i in range(10):\n    j = int(torch.argmax(iris[i,0,12:36,12:36]))\n    max_list.append(np.unravel_index(j, (24,24)))\n    ex = np.array(data.cpu().detach()[i][0])\n    photo_list.append(ex)\nprint(max_list)","ecdf8ca6":"for i in range(10):\n    cv.circle(photo_list[i][12:36,12:36], (max_list[i][0], max_list[i][1]), 1, (1,0,0), thickness=-1)\n    fig, axis = plt.subplots(1, 1)\n    axis.imshow(photo_list[i], cmap=\"gray\")\n    axis.set_title(f'{i+1}. Iris Detected')","7f7fb4b8":"# Building CNN","0f2b799d":"# Printing Iris Center","8360bf7d":"# Dataset preprocessing","be08dcc5":"# Best combination: Adam + MSE + tanh\n\n---\n\n","6832d48b":"# Importing necessary modules","879db7d9":"# Task 3. Human iris center calculation","d18b99ee":"# Choosing parameters\n","8604ae71":"# Akhmetzhanov Ravil, MS-RO-21.\n# r.akhmetzhanov@innopolis.university"}}