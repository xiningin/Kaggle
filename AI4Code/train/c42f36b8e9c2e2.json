{"cell_type":{"6919d99b":"code","00cf4de4":"code","6e69962c":"code","c490ae1b":"code","805070eb":"code","6b04a9a2":"code","75c3a104":"code","01195792":"code","b1403e51":"code","c5832fb4":"code","15fdc205":"code","d03f679c":"code","074336e8":"code","9ba07109":"code","a7d6286c":"code","4d148df8":"code","4823dcd1":"code","dd3bffbb":"code","b213f152":"code","e8358bd0":"code","cc414e97":"code","84c65577":"code","199b8830":"code","ab527971":"code","6bb57ac4":"code","aa56862a":"code","b9186a27":"code","026811ff":"code","eb01fc89":"code","483f2b1d":"code","3c1923cf":"code","0c4bd3f7":"code","471e4c50":"code","fbaf60ee":"code","c075a2c7":"code","78527c64":"code","2e9c9b0b":"code","0b94f536":"code","b36e1715":"code","54c46d24":"code","0a4e27b9":"code","a1761a7b":"code","76871a02":"code","b10ca40c":"code","2e2df8bf":"code","f4fd1fb5":"code","e5716573":"code","aa81baeb":"code","5ad38a4e":"code","998eecf2":"code","efc9329a":"code","3185cf9e":"code","06e545db":"code","1697ccc4":"code","a5a0afb7":"code","39963788":"markdown","f8a37f00":"markdown","958be91a":"markdown","b052aecc":"markdown","8737ca0b":"markdown","f6e5bd1d":"markdown","72802c6c":"markdown","af7d7563":"markdown","ec1e83a7":"markdown","68c3c265":"markdown","4895bb2a":"markdown","d75692f0":"markdown","ddb2c9e2":"markdown","2e0aadf1":"markdown","1b254f05":"markdown","f8285dc1":"markdown","af41f91c":"markdown","673e434e":"markdown","18587140":"markdown","86d1981c":"markdown","22f51cee":"markdown","9d43eef5":"markdown"},"source":{"6919d99b":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nimport skimage\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\nfrom keras.regularizers import l1,l2,L1L2\nfrom tensorflow.keras import regularizers\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","00cf4de4":"Indian_Sign_Main_Path = Path(\"..\/input\/indian-sign-language-isl\/Indian\")","6e69962c":"Sign_JPG = list(Indian_Sign_Main_Path.glob(r\"*\/*.jpg\"))","c490ae1b":"Sign_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Sign_JPG))","805070eb":"Sign_JPG_Series = pd.Series(Sign_JPG,name=\"JPG\").astype(str)\nSign_Labels_Series = pd.Series(Sign_Labels,name=\"CATEGORY\")","6b04a9a2":"Main_Sign_Data = pd.concat([Sign_JPG_Series,Sign_Labels_Series],axis=1)","75c3a104":"print(Main_Sign_Data.head(-1))","01195792":"Main_Sign_Data = Main_Sign_Data.sample(frac=1).reset_index(drop=True)","b1403e51":"print(Main_Sign_Data.head(-1))","c5832fb4":"def simple_vision(img_path):\n    Picking_Img = cv2.cvtColor(cv2.imread(img_path),cv2.COLOR_BGR2RGB)\n    \n    return Picking_Img","15fdc205":"def threshold_vision(img_path):\n    Picking_Img = simple_vision(img_path)\n    Gray_Img = cv2.cvtColor(Picking_Img,cv2.COLOR_RGB2GRAY)\n    _,threshold_Img = cv2.threshold(Gray_Img,90,255,cv2.THRESH_BINARY_INV)\n    \n    return threshold_Img\n    ","d03f679c":"def canny_vision(img_path):\n    Threshold_Img = threshold_vision(img_path)\n    Canny_Img = cv2.Canny(Threshold_Img,10,100)\n    \n    return Canny_Img","074336e8":"def skeleton_morph_vision(img_path):\n    Picking_Img = simple_vision(img_path)\n    Gray_Img = cv2.cvtColor(Picking_Img,cv2.COLOR_RGB2GRAY)\n    _,Threshold_Img = cv2.threshold(Gray_Img,90,255,cv2.THRESH_BINARY_INV)\n    \n    Array_Img = np.array(Gray_Img > Threshold_Img).astype(int)\n    Skeleton_Img = skimage.morphology.skeletonize(Array_Img)\n    \n    return Skeleton_Img","9ba07109":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = simple_vision(Main_Sign_Data[\"JPG\"][33])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][33])\nplt.imshow(Image_Sign)","a7d6286c":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = threshold_vision(Main_Sign_Data[\"JPG\"][33])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][33])\nplt.imshow(Image_Sign,cmap=\"gray\")","4d148df8":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = canny_vision(Main_Sign_Data[\"JPG\"][33])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][33])\nplt.imshow(Image_Sign,cmap=\"gray\")","4823dcd1":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(20,20))\n\nExample_Image = cv2.cvtColor(cv2.imread(Main_Sign_Data[\"JPG\"][33]),cv2.COLOR_BGR2GRAY)\n\nHessian_Mat = hessian_matrix(Example_Image,sigma=5,order=\"rc\")\nmax_S,min_S = hessian_matrix_eigvals(Hessian_Mat)\n\naxis[0].imshow(min_S)\naxis[0].set_xlabel(min_S.shape)\naxis[0].set_ylabel(min_S.size)\naxis[0].set_title(Main_Sign_Data[\"CATEGORY\"][33])\naxis[1].imshow(max_S)\naxis[1].set_xlabel(max_S.shape)\naxis[1].set_ylabel(max_S.size)\naxis[1].set_title(Main_Sign_Data[\"CATEGORY\"][33])","dd3bffbb":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(20,20))\n\nSkel_Img = skeleton_morph_vision(Main_Sign_Data[\"JPG\"][33])\nSimple_Img = simple_vision(Main_Sign_Data[\"JPG\"][33])\n\naxis[0].imshow(Skel_Img)\naxis[0].set_xlabel(Skel_Img.shape)\naxis[0].set_ylabel(Skel_Img.size)\naxis[0].set_title(Main_Sign_Data[\"CATEGORY\"][33])\naxis[1].imshow(Simple_Img)\naxis[1].set_xlabel(Simple_Img.shape)\naxis[1].set_ylabel(Simple_Img.size)\naxis[1].set_title(Main_Sign_Data[\"CATEGORY\"][33])","b213f152":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = simple_vision(Main_Sign_Data[\"JPG\"][41113])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][41113])\nplt.imshow(Image_Sign)","e8358bd0":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = threshold_vision(Main_Sign_Data[\"JPG\"][41113])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][41113])\nplt.imshow(Image_Sign,cmap=\"gray\")","cc414e97":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = canny_vision(Main_Sign_Data[\"JPG\"][41113])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][41113])\nplt.imshow(Image_Sign,cmap=\"gray\")","84c65577":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(20,20))\n\nExample_Image = cv2.cvtColor(cv2.imread(Main_Sign_Data[\"JPG\"][41113]),cv2.COLOR_BGR2GRAY)\n\nHessian_Mat = hessian_matrix(Example_Image,sigma=5,order=\"rc\")\nmax_S,min_S = hessian_matrix_eigvals(Hessian_Mat)\n\naxis[0].imshow(min_S)\naxis[0].set_xlabel(min_S.shape)\naxis[0].set_ylabel(min_S.size)\naxis[0].set_title(Main_Sign_Data[\"CATEGORY\"][41113])\naxis[1].imshow(max_S)\naxis[1].set_xlabel(max_S.shape)\naxis[1].set_ylabel(max_S.size)\naxis[1].set_title(Main_Sign_Data[\"CATEGORY\"][41113])","199b8830":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(20,20))\n\nSkel_Img = skeleton_morph_vision(Main_Sign_Data[\"JPG\"][41113])\nSimple_Img = simple_vision(Main_Sign_Data[\"JPG\"][41113])\n\naxis[0].imshow(Skel_Img)\naxis[0].set_xlabel(Skel_Img.shape)\naxis[0].set_ylabel(Skel_Img.size)\naxis[0].set_title(Main_Sign_Data[\"CATEGORY\"][41113])\naxis[1].imshow(Simple_Img)\naxis[1].set_xlabel(Simple_Img.shape)\naxis[1].set_ylabel(Simple_Img.size)\naxis[1].set_title(Main_Sign_Data[\"CATEGORY\"][41113])","ab527971":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = simple_vision(Main_Sign_Data[\"JPG\"][22213])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][22213])\nplt.imshow(Image_Sign)","6bb57ac4":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = threshold_vision(Main_Sign_Data[\"JPG\"][22213])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][22213])\nplt.imshow(Image_Sign,cmap=\"gray\")","aa56862a":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = canny_vision(Main_Sign_Data[\"JPG\"][22213])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][22213])\nplt.imshow(Image_Sign,cmap=\"gray\")","b9186a27":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(20,20))\n\nExample_Image = cv2.cvtColor(cv2.imread(Main_Sign_Data[\"JPG\"][22213]),cv2.COLOR_BGR2GRAY)\n\nHessian_Mat = hessian_matrix(Example_Image,sigma=5,order=\"rc\")\nmax_S,min_S = hessian_matrix_eigvals(Hessian_Mat)\n\naxis[0].imshow(min_S)\naxis[0].set_xlabel(min_S.shape)\naxis[0].set_ylabel(min_S.size)\naxis[0].set_title(Main_Sign_Data[\"CATEGORY\"][22213])\naxis[1].imshow(max_S)\naxis[1].set_xlabel(max_S.shape)\naxis[1].set_ylabel(max_S.size)\naxis[1].set_title(Main_Sign_Data[\"CATEGORY\"][22213])","026811ff":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(20,20))\n\nSkel_Img = skeleton_morph_vision(Main_Sign_Data[\"JPG\"][22213])\nSimple_Img = simple_vision(Main_Sign_Data[\"JPG\"][22213])\n\naxis[0].imshow(Skel_Img)\naxis[0].set_xlabel(Skel_Img.shape)\naxis[0].set_ylabel(Skel_Img.size)\naxis[0].set_title(Main_Sign_Data[\"CATEGORY\"][22213])\naxis[1].imshow(Simple_Img)\naxis[1].set_xlabel(Simple_Img.shape)\naxis[1].set_ylabel(Simple_Img.size)\naxis[1].set_title(Main_Sign_Data[\"CATEGORY\"][22213])","eb01fc89":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = simple_vision(Main_Sign_Data[\"JPG\"][10000])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][10000])\nplt.imshow(Image_Sign)","483f2b1d":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = threshold_vision(Main_Sign_Data[\"JPG\"][10000])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][10000])\nplt.imshow(Image_Sign,cmap=\"gray\")","3c1923cf":"figure = plt.figure(figsize=(10,10))\n\nImage_Sign = canny_vision(Main_Sign_Data[\"JPG\"][10000])\n\nplt.xlabel(Image_Sign.shape)\nplt.ylabel(Image_Sign.size)\nplt.title(Main_Sign_Data[\"CATEGORY\"][10000])\nplt.imshow(Image_Sign,cmap=\"gray\")","0c4bd3f7":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(20,20))\n\nExample_Image = cv2.cvtColor(cv2.imread(Main_Sign_Data[\"JPG\"][10000]),cv2.COLOR_BGR2GRAY)\n\nHessian_Mat = hessian_matrix(Example_Image,sigma=5,order=\"rc\")\nmax_S,min_S = hessian_matrix_eigvals(Hessian_Mat)\n\naxis[0].imshow(min_S)\naxis[0].set_xlabel(min_S.shape)\naxis[0].set_ylabel(min_S.size)\naxis[0].set_title(Main_Sign_Data[\"CATEGORY\"][10000])\naxis[1].imshow(max_S)\naxis[1].set_xlabel(max_S.shape)\naxis[1].set_ylabel(max_S.size)","471e4c50":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(20,20))\n\nSkel_Img = skeleton_morph_vision(Main_Sign_Data[\"JPG\"][10000])\nSimple_Img = simple_vision(Main_Sign_Data[\"JPG\"][10000])\n\naxis[0].imshow(Skel_Img)\naxis[0].set_xlabel(Skel_Img.shape)\naxis[0].set_ylabel(Skel_Img.size)\naxis[0].set_title(Main_Sign_Data[\"CATEGORY\"][10000])\naxis[1].imshow(Simple_Img)\naxis[1].set_xlabel(Simple_Img.shape)\naxis[1].set_ylabel(Simple_Img.size)\naxis[1].set_title(Main_Sign_Data[\"CATEGORY\"][10000])","fbaf60ee":"X_Train,X_Test = train_test_split(Main_Sign_Data,train_size=0.9,random_state=123,shuffle=True)","c075a2c7":"print(X_Train.shape)\nprint(X_Test.shape)","78527c64":"print(type(X_Train))\nprint(type(X_Test))","2e9c9b0b":"Train_IMG_Generator = ImageDataGenerator(rescale=1.\/255,\n                                        zoom_range=0.5,\n                                        shear_range=0.5,\n                                        brightness_range=[0.6,1.0],\n                                        rotation_range=35,\n                                        width_shift_range=0.1,\n                                        height_shift_range=0.1,\n                                        vertical_flip=True,\n                                         featurewise_std_normalization=False,\n                                         samplewise_center=False,\n                                         samplewise_std_normalization=False,\n                                        fill_mode=\"nearest\",\n                                        validation_split=0.1)","0b94f536":"Test_IMG_Generator = ImageDataGenerator(rescale=1.\/255)","b36e1715":"Example_Img = simple_vision(X_Train.JPG[3])\nExample_Img = Example_Img.reshape((1,) + Example_Img.shape)\n\ni = 0 \n\nfor batch in Train_IMG_Generator.flow(Example_Img,batch_size=32):\n    \n    figure = plt.figure(figsize=(8,8))\n    plt.imshow(image.img_to_array(batch[0]))\n    \n    i += 1\n    if i % 4 == 0:\n        break\n        \nplt.show()","54c46d24":"Train_Set = Train_IMG_Generator.flow_from_dataframe(dataframe=X_Train,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   batch_size=32,\n                                                   class_mode=\"categorical\",\n                                                   color_mode=\"grayscale\",\n                                                   subset=\"training\")","0a4e27b9":"Validation_Set = Train_IMG_Generator.flow_from_dataframe(dataframe=X_Train,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   batch_size=32,\n                                                   class_mode=\"categorical\",\n                                                   color_mode=\"grayscale\",\n                                                   subset=\"validation\")","a1761a7b":"Test_Set = Test_IMG_Generator.flow_from_dataframe(dataframe=X_Test,\n                                                   x_col=\"JPG\",\n                                                   y_col=\"CATEGORY\",\n                                                   batch_size=32,\n                                                   class_mode=\"categorical\",\n                                                   color_mode=\"grayscale\",\n                                                   shuffle=False)","76871a02":"print(\"TRAIN: \")\nprint(Train_Set.class_indices)\nprint(Train_Set.classes[0:5])\nprint(Train_Set.image_shape)\nprint(\"---\"*20)\nprint(\"VALIDATION: \")\nprint(Validation_Set.class_indices)\nprint(Validation_Set.classes[0:5])\nprint(Validation_Set.image_shape)\nprint(\"---\"*20)\nprint(\"TEST: \")\nprint(Test_Set.class_indices)\nprint(Test_Set.classes[0:5])\nprint(Test_Set.image_shape)","b10ca40c":"COMPILE_OPTIMIZER = \"adam\"\nCOMPILE_LOSS = \"categorical_crossentropy\"\nCOMPILE_METRICS = [\"accuracy\"]\nINPUT_DIM = (256,256,1)\nOUTPUT_DIM = 35","2e2df8bf":"Early_Stopper = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=3,mode=\"min\")\nCheckpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=True,\n                                                      filepath=\".\/modelcheck\")","f4fd1fb5":"Model = Sequential()\n\nModel.add(Conv2D(24,(3,3),activation=\"relu\",input_shape=INPUT_DIM))\nModel.add(BatchNormalization())\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Conv2D(256,(3,3),activation=\"relu\",padding=\"same\"))\nModel.add(Dropout(0.3))\nModel.add(MaxPooling2D((2,2),strides=2))\n\nModel.add(Flatten())\nModel.add(Dense(2352,activation=\"relu\"))\nModel.add(Dropout(0.5))\nModel.add(Dense(OUTPUT_DIM,activation=\"softmax\"))","e5716573":"Model.compile(optimizer=COMPILE_OPTIMIZER,loss=COMPILE_LOSS,metrics=COMPILE_METRICS)","aa81baeb":"CNN_Model = Model.fit(Train_Set,\n                      validation_data=Validation_Set,\n                      callbacks=[Early_Stopper,Checkpoint_Model],\n                      epochs=50)","5ad38a4e":"Model.save(\"Prediction_Model.h5\")","998eecf2":"Grap_Data = pd.DataFrame(CNN_Model.history)\nGrap_Data.plot()","efc9329a":"plt.plot(CNN_Model.history[\"accuracy\"])\nplt.plot(CNN_Model.history[\"val_accuracy\"])\nplt.ylabel(\"ACCURACY\")\nplt.legend()\nplt.show()","3185cf9e":"plt.plot(CNN_Model.history[\"loss\"])\nplt.plot(CNN_Model.history[\"val_loss\"])\nplt.ylabel(\"LOSS\")\nplt.legend()\nplt.show()","06e545db":"Model_Results = Model.evaluate(Test_Set)\nprint(\"LOSS:  \" + \"%.4f\" % Model_Results[0])\nprint(\"ACCURACY:  \" + \"%.2f\" % Model_Results[1])","1697ccc4":"Model_Test_Prediction = Model.predict(Test_Set)\nModel_Test_Prediction = Model_Test_Prediction.argmax(axis=-1)","a5a0afb7":"fig, axes = plt.subplots(nrows=5,\n                         ncols=5,\n                         figsize=(20, 20),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(X_Test[\"JPG\"].iloc[i]))\n    ax.set_title(f\"PREDICTION:{Model_Test_Prediction[i]}\")\n    ax.set_xlabel(X_Test[\"CATEGORY\"].iloc[i])\nplt.tight_layout()\nplt.show()","39963788":"#### TO SHUFFLE","f8a37f00":"#### JPG PATH","958be91a":"# SPLITTING DATA","b052aecc":"#### TO SERIES","8737ca0b":"#### APPLYING","f6e5bd1d":"# PATH, LABEL, TRANSFORMATION","72802c6c":"##### EXAMPLE I","af7d7563":"#### LABELS","ec1e83a7":"#### VISION FUNCTION","68c3c265":"# IMAGE DATA GENERATOR PROCESS","4895bb2a":"#### TO DATAFRAME","d75692f0":"#### GENERATOR STRUCTURE","ddb2c9e2":"# PACKAGES AND LIBRARIES","2e0aadf1":"# VISION","1b254f05":"##### EXAMPLE IV","f8285dc1":"##### EXAMPLE III","af41f91c":"#### HOW TO LOOK BY GENERATOR","673e434e":"#### CHECKING","18587140":"##### EXAMPLE II","86d1981c":"#### PARAMETERS","22f51cee":"#### MAIN PATH","9d43eef5":"# MODEL"}}