{"cell_type":{"14b7d357":"code","a68e829c":"code","015c40ff":"code","12c0241d":"code","ab3bd8dd":"code","c6e80be4":"code","b6539741":"code","9f971c41":"code","21fca5f6":"code","6ce5472b":"code","1df59376":"code","b3adda31":"code","a191d0ac":"code","638c44ab":"code","d8f9a0e6":"code","9803dfe4":"code","82422a56":"code","892fecc3":"code","356316c8":"code","f2531f05":"code","0eb98c28":"code","88879d77":"code","b3717ed3":"code","ce2d7cd6":"code","7b149188":"code","5c1d0a6b":"code","389ff859":"code","696111a9":"code","8465ad6f":"code","9c656fc4":"code","7457f8b8":"code","a4fb80d7":"markdown","d8dd1aff":"markdown","0bce7151":"markdown","6c179012":"markdown","6e6dc1dc":"markdown"},"source":{"14b7d357":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a68e829c":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint(f'The train set contain {train.shape[0]} examples')\ntrain.head(3)","015c40ff":"y_train = train['label']\nX_train = train.drop(labels = [\"label\"],axis = 1)","12c0241d":"import matplotlib.pyplot as plt\n%matplotlib inline","ab3bd8dd":"digits = y_train.unique()\ncount = y_train.value_counts()\n\nplt.bar(digits, count)\nplt.title('Train set')\nplt.xlabel('Digit')\nplt.ylabel('Count')","c6e80be4":"# Normalize the data\nX_train = X_train \/ 255.0\ntest = test \/ 255.0","b6539741":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","9f971c41":"!pip install tensorflow==2.0.0-alpha0","21fca5f6":"\nimport tensorflow as tf","6ce5472b":" print(tf.__version__)","1df59376":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding","b3adda31":"y_train = to_categorical(y_train, num_classes = 10)","a191d0ac":"plt.imshow(X_train[100][:,:,0])","638c44ab":"from sklearn.model_selection import train_test_split","d8f9a0e6":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state= 101)","9803dfe4":"from tensorflow import keras","82422a56":"from tensorflow.keras import layers, models","892fecc3":"model = models.Sequential()","356316c8":"model.add(layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\n\nmodel.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation = \"relu\"))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(10, activation = \"softmax\"))","f2531f05":"model.summary()","0eb98c28":"optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","88879d77":"## Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","b3717ed3":"# Fit the model\nhistory = model.fit(X_train, y_train, batch_size = 100, epochs = 10, validation_data = (X_test, y_test))","ce2d7cd6":"# Plot the loss and accuracy curves for training and validation \nplt.figure(figsize=(24,8))\nplt.subplot(1,2,1)\nplt.plot(history.history[\"val_accuracy\"], label=\"validation_accuracy\", c=\"red\", linewidth=4)\nplt.plot(history.history[\"accuracy\"], label=\"training_accuracy\", c=\"green\", linewidth=4)\nplt.legend()\nplt.grid(True)\n\nplt.subplot(1,2,2)\nplt.plot(history.history[\"val_loss\"], label=\"validation_loss\", c=\"red\", linewidth=4)\nplt.plot(history.history[\"loss\"], label=\"training_loss\", c=\"green\", linewidth=4)\nplt.legend()\nplt.grid(True)\n\nplt.suptitle(\"ACC \/ LOSS\",fontsize=18)\n\nplt.show()","7b149188":"print('Train accuracy of the model: ',history.history['accuracy'][-1])","5c1d0a6b":"print('Train loss of the model: ',history.history['loss'][-1])\n","389ff859":"print('Validation accuracy of the model: ',history.history['val_accuracy'][-1])","696111a9":"print('Validation loss of the model: ',history.history['val_loss'][-1])","8465ad6f":"from sklearn.metrics import confusion_matrix","9c656fc4":"# confusion matrix\nimport seaborn as sns\n# Predict the values from the validation dataset\nY_pred = model.predict(X_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"BuPu\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","7457f8b8":"results = model.predict(test)\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist.csv\",index=False)","a4fb80d7":"# Normalization","d8dd1aff":"# Validation","0bce7151":"# Data Preparation\nLoad the training data with pandas and explore it.","6c179012":"# Reshape","6e6dc1dc":"# CNN Model "}}