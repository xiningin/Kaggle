{"cell_type":{"aa192311":"code","76223f77":"code","6e607c74":"code","542e814d":"code","57d5689d":"code","65d8fe02":"code","2cb052e0":"code","825d65a5":"code","0653353b":"code","cdd7193b":"code","57a5f136":"code","d0252a47":"code","0abd5199":"code","a4b163e7":"code","2a4be3ec":"code","1733164a":"code","200924ca":"code","27f2bbc1":"code","112c33f7":"code","6f6317a6":"code","ae7c5fd0":"code","77e140d2":"code","838c197e":"code","72ece314":"code","5368b13a":"code","60d069d0":"code","b9239278":"code","b1e8065b":"code","e1be57fb":"code","4445d363":"code","becd1836":"code","27a51122":"code","7ecaa984":"code","d65b3d2a":"code","baa1fd12":"code","2a6ec8fe":"code","b4f4ce3a":"code","1f85765c":"code","99dcf76e":"code","74de04bf":"code","8d49d598":"code","b700e39b":"code","abb8fbaf":"code","2e2c2570":"code","da8cd651":"code","4a5fe7c1":"code","c171eb1c":"code","c6a8fdbd":"code","14e3d9f6":"code","6c9285eb":"code","98b64d17":"code","bfb91e7c":"markdown","084523fa":"markdown","975454fc":"markdown","9846a9a6":"markdown","8e1ebcf6":"markdown","1cc6481a":"markdown","35aa07e7":"markdown","ab2e766e":"markdown","3f467a17":"markdown","35b648e6":"markdown","b2338697":"markdown","00fd87c6":"markdown","d9fda758":"markdown","26a0c2aa":"markdown","9416dbaa":"markdown","2ab221d8":"markdown","e2ea6d09":"markdown","743f8ba0":"markdown","8c07670a":"markdown","d10141fb":"markdown","6ff0654b":"markdown"},"source":{"aa192311":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport sklearn\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt ","76223f77":"X = pd.read_csv('\/kaggle\/input\/titanic-processed-data\/train_data.csv').set_index('Unnamed: 0')\ny = pd.read_csv('\/kaggle\/input\/titanic-processed-data\/train_output.csv').set_index('Unnamed: 0')\nX_test = pd.read_csv('\/kaggle\/input\/titanic-processed-data\/test_data.csv').set_index('Unnamed: 0')\nkaggle_test_data = pd.read_csv('\/kaggle\/input\/titanic-processed-data\/kaggle_test.csv') # needed to get corresponding passenger id\ny = np.array(y).reshape(891)","6e607c74":"X.info()","542e814d":"# Linear model\nfrom sklearn.linear_model import LogisticRegression\nlogistic_linear_classifier = LogisticRegression()","57d5689d":"coarse_parameters_grid = [{'C':[0.01,0.1,1,10], 'max_iter':[300,400,500,600,700]}]\nLogistic_wth_Grid_clf = GridSearchCV(logistic_linear_classifier,param_grid=coarse_parameters_grid,cv=10,scoring='accuracy')\nLogistic_wth_Grid_clf.fit(X,y)","65d8fe02":"cvres = Logistic_wth_Grid_clf.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","2cb052e0":"optimized_logistic_classifier = Logistic_wth_Grid_clf.best_estimator_\noptimized_logistic_classifier","825d65a5":"Logistic_wth_Grid_clf.best_score_","0653353b":"y_test_logistic = optimized_logistic_classifier.predict(X_test)","cdd7193b":"'''\noutput = pd.DataFrame()\noutput['PassengerId'] = kaggle_test_data['PassengerId']\noutput['Survived'] = y_test_logistic\noutput.to_csv('\/outputs\/logistic_linear.csv',index=False)\n'''","57a5f136":"optimized_logistic_classifier.coef_","d0252a47":"\n#feature_importances['feature_importance_logistic'] = list(optimized_logistic_classifier.coef_[0])","0abd5199":"from sklearn.svm import LinearSVC\nsvm_linear = LinearSVC()\nparameters_grid = [{'C':[1,0.1,0.01,0.001],'max_iter':[4000,4500,3000]}]\nsvm_with_grid_search=GridSearchCV(svm_linear,param_grid=parameters_grid,scoring='accuracy',cv=10,return_train_score=True)\nsvm_with_grid_search.fit(X,y)","a4b163e7":"optimized_svm_linear = svm_with_grid_search.best_estimator_\noptimized_svm_linear","2a4be3ec":"svm_with_grid_search.best_score_","1733164a":"#cvres","200924ca":"y_test_svm_linear = optimized_svm_linear.predict(X_test)","27f2bbc1":"'''\noutput = pd.DataFrame()\noutput['PassengerId'] = kaggle_test_data['PassengerId']\noutput['Survived'] = y_test_svm_linear\noutput.to_csv('.\/outputs\/svm_linear.csv',index=False)\n'''","112c33f7":"from sklearn.svm import SVC\nsvm_gaussian_kernel = SVC(kernel='rbf')\nparameters_grid = [{'gamma':[0.01,0.1,0.05,0.2],'C':[0.01,0.1,1,5,10]}]\nsvm_gaussian_kernel_wth_grid_search = GridSearchCV(svm_gaussian_kernel,param_grid=parameters_grid,cv=10,scoring='accuracy')\nsvm_gaussian_kernel_wth_grid_search.fit(X,y)","6f6317a6":"optimized_svm_gaussian_kernel = svm_gaussian_kernel_wth_grid_search.best_estimator_\noptimized_svm_gaussian_kernel","ae7c5fd0":"svm_gaussian_kernel_wth_grid_search.best_score_","77e140d2":"cvres = svm_gaussian_kernel_wth_grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","838c197e":"#cvres","72ece314":"y_test_svm_gaussian_kernel = optimized_svm_gaussian_kernel.predict(X_test)","5368b13a":"'''\noutput = pd.DataFrame()\noutput['PassengerId'] = kaggle_test_data['PassengerId']\noutput['Survived'] = y_test_svm_gaussian_kernel\noutput.to_csv('.\/outputs\/svm_guassian_kernel.csv',index=False)\n'''","60d069d0":"#X_new = X.drop(['Tick_len_10','Tick_len_11','Q','cabin_A','cabin_T','Tick_len_3','Tick_len_4'],axis=1)\n","b9239278":"from sklearn.ensemble import RandomForestClassifier\nRandomforest = RandomForestClassifier()\nparameters_grid = [{'n_estimators':[250,500,1000],'max_features':[0.3,0.7,1],'max_leaf_nodes':[40,80,200,400],'max_depth':[3,5,8]}]\nRandomforest_grid_search = GridSearchCV(Randomforest,param_grid=parameters_grid,cv=10,scoring='accuracy')\nRandomforest_grid_search.fit(X,y)","b1e8065b":"optimized_Randomforest = Randomforest_grid_search.best_estimator_\nRandomforest_grid_search.best_score_","e1be57fb":"cvres = Randomforest_grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","4445d363":"#cvres","becd1836":"y_test_random_forest = optimized_Randomforest.predict(X_test)","27a51122":"#y_test_random_forest-y_test_logistic","7ecaa984":"'''\noutput = pd.DataFrame()\noutput['PassengerId'] = kaggle_test_data['PassengerId']\noutput['Survived'] = y_test_random_forest\noutput.to_csv('.\/outputs\/random_forest.csv',index=False)\n'''","d65b3d2a":"feature_importances = pd.DataFrame()\nfeature_importances['Features'] = list(X.columns)\nfeature_importances['RF_features_impodtance'] = optimized_Randomforest.feature_importances_","baa1fd12":"from sklearn.ensemble import AdaBoostClassifier\nadaboost_clf =  AdaBoostClassifier(algorithm=\"SAMME.R\",random_state=4)\nparameters_grid = [{'n_estimators':[10,20,30,40,50,60],'learning_rate':[0.01,0.1,0.2,0.5,0.8,1]}]\nadaboost_grid_search = GridSearchCV(adaboost_clf,param_grid=parameters_grid,cv=10,scoring='accuracy')\nadaboost_grid_search.fit(X,y)","2a6ec8fe":"adaboost = adaboost_grid_search.best_estimator_\nadaboost_grid_search.best_estimator_","b4f4ce3a":"cvres = adaboost_grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","1f85765c":"y_test_adaboost = adaboost.predict(X_test)","99dcf76e":"'''\noutput = pd.DataFrame()\noutput['PassengerId'] = kaggle_test_data['PassengerId']\noutput['Survived'] = y_test_adaboost\noutput.to_csv('.\/outputs\/adaboost.csv',index=False)\n'''","74de04bf":"from xgboost import XGBClassifier\nxgboost_clf = XGBClassifier(use_label_encoder=False)\nparameters_grid = [{'max_depth':[5,6,7,8,9], 'n_estimators':[2,3,4,5,6], 'colsample_bytree':[0.1,0.3,0.5,0.7,1],'learning_rate':[0.1,0.3,0.5,0.7,1]}]\nxboost_grid_search = GridSearchCV(xgboost_clf,parameters_grid,cv=3,scoring='accuracy')\nxboost_grid_search.fit(X,y)","8d49d598":"optimized_xgboost = xboost_grid_search.best_estimator_\noptimized_xgboost\nxboost_grid_search.best_score_","b700e39b":"cvres = xboost_grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(mean_score, params)","abb8fbaf":"# cvres","2e2c2570":"y_test_xgboost = optimized_xgboost.predict(X_test)","da8cd651":"'''\noutput = pd.DataFrame()\noutput['PassengerId'] = kaggle_test_data['PassengerId']\noutput['Survived'] = y_test_xgboost\noutput.to_csv('.\/outputs\/xgboost.csv',index=False)\n'''","4a5fe7c1":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import cross_val_score\nvoting_clf = VotingClassifier(estimators=[('lr',optimized_logistic_classifier),('xgb',optimized_xgboost), ('svm_linear',optimized_svm_linear), ('rf',optimized_Randomforest),  ('ada',adaboost), ('rbf',optimized_svm_gaussian_kernel)],weights=[1,0.5,2,1,2,2],voting='hard')\nvoting_score = cross_val_score(voting_clf,X,y,cv=10,scoring='accuracy').mean()\nvoting_clf.fit(X,y)","c171eb1c":"y_test_voting = voting_clf.predict(X_test)","c6a8fdbd":"'''\noutput = pd.DataFrame()\noutput['PassengerId'] = kaggle_test_data['PassengerId']\noutput['Survived'] = y_test_voting\noutput.to_csv('.\/outputs\/voting.csv',index=False)\n'''","14e3d9f6":"all_scores = pd.DataFrame()\nall_scores['Algorithm'] = ['Logistic', 'SVM Linear', 'SVM Gaussian K', 'Random Forest', 'Adaboost', 'Xgboost','Voting score']\n\nall_scores['CV scores'] = [Logistic_wth_Grid_clf.best_score_, svm_with_grid_search.best_score_,\nsvm_gaussian_kernel_wth_grid_search.best_score_, Randomforest_grid_search.best_score_,\nadaboost_grid_search.best_score_, xboost_grid_search.best_score_,voting_score]\n\nall_scores['Kaggle scores'] = [0.77272,0.78229,0.76794,0.77511,0.77272,0.76555,0.77511]\nall_scores","6c9285eb":"sns.scatterplot(data=all_scores,x='Algorithm',y='CV scores')\nsns.scatterplot(data=all_scores,x='Algorithm',y='Kaggle scores')","98b64d17":"feature_importances","bfb91e7c":"## Kaggle Test Score - 0.76555 (For xgboost)","084523fa":"## Kaggle Test Score - 0.77272 (For logistic classifier)","975454fc":"## Kaggle Test Score - 0.78229 (For svm linear classifier)","9846a9a6":"## SVM Classifier","8e1ebcf6":"- Logistic Regression - 0.77272 (Kaggle scores)\n- Linear SVM - 0.78229\n- SVM - Gaussian Kernel - 0.76794\n- Random Forest - 0.77511\n- Ensemble methods\n    - Voting Method - 0.77272\n- Boosting methods\n    - Adaboost - 0.76555\n    - Xgboost - 0.77511","1cc6481a":"**Here I directly used preprocessed features from earlier notebook. For Feature Generation look at my other notebook** -  [Titanic dataset Top-7%](https:\/\/www.kaggle.com\/mohitludhiyani\/titanic-dataset-top-7) ","35aa07e7":"## XGBoost","ab2e766e":"## Reading Data","3f467a17":"## Kaggle Test Score - 0.76794  (For svm non-linear gaussian kernel classifier) ","35b648e6":"## Adaboost","b2338697":"Some Noteworthy points:\n\n    - if max_iter<=500 lbfgs solver doesnt converge\n    - will adding polynomial features help here, I don't think so as all features are polynomial","00fd87c6":"0.8350187265917602 {'max_depth': 5, 'max_features': 0.3, 'max_leaf_nodes': 15, 'n_estimators': 150}\n0.8372659176029963 {'max_depth': 5, 'max_features': 0.3, 'max_leaf_nodes': 20, 'n_estimators': 250}\n0.8383895131086142 {'max_depth': 5, 'max_features': 0.3, 'max_leaf_nodes': 40, 'n_estimators': 500}\n0.8372659176029963 {'max_depth': 5, 'max_features': 0.3, 'n_estimators': 500}\n0.8361423220973782 {'max_depth': 5, 'max_features': 0.3, 'max_leaf_nodes': 80, 'n_estimators': 500}\n0.8383895131086142 {'max_depth': 5, 'max_features': 0.3, 'max_leaf_nodes': 80, 'n_estimators': 250}\n0.8350187265917602 {'max_depth': 5, 'max_features': 0.3, 'max_leaf_nodes': 80, 'n_estimators': 1000}","d9fda758":"## Ensemble Model","26a0c2aa":"## Non Linear SVM Classifier --  Gaussian Kernel","9416dbaa":"## Kaggle Test Score - 0.77511 (For voting)","2ab221d8":"## Kaggle Test Score - 0.77511  (For Random Forest) ","e2ea6d09":"## Random Forest Classifier","743f8ba0":"## Feature Importances","8c07670a":"## List of various Classifiers tested in this notebook with corresponding kaggle scores.","d10141fb":"## Kaggle Test Score -  0.77272 (For adaboost) ","6ff0654b":"## Logistic Regression"}}