{"cell_type":{"238db9a0":"code","b169e715":"code","9a12db42":"code","834d94de":"code","812fea56":"code","69f83133":"code","c87bca45":"code","6527efc7":"code","4732481c":"code","8aa6900e":"code","5fc28084":"code","6bea056e":"code","17a0a18b":"code","6fee6c9b":"code","1b4a2729":"code","db48598c":"code","49e294ba":"code","06c0e581":"code","0938471f":"code","24fd9ce3":"code","f8fa554f":"code","6ace6a88":"code","c9e91400":"code","de2c0a71":"code","2310ded8":"code","dfab3a28":"code","a87f7a54":"code","40dabfae":"code","9f48b2d9":"code","fd1fef81":"code","113d9570":"code","d7648c77":"code","f7005e61":"code","9081fd21":"code","36859972":"code","b167b116":"code","4fca651d":"code","92560ebb":"code","aaf3f91c":"code","462d279e":"code","21988a5b":"code","ce47d513":"code","789cbdd3":"code","f56e1659":"code","d9f72e68":"code","d0849db5":"code","111481e0":"code","34c2f836":"code","e99845a0":"code","be6b20e2":"code","be3424d4":"code","f7605925":"code","6257ce3a":"code","0d218814":"code","78a1a238":"code","e28ffa80":"code","e621e8ed":"code","c0014b34":"code","734be579":"code","a6119881":"code","2d17c5cd":"code","f462b426":"code","851721a2":"code","0b5df801":"code","f832086e":"code","d9b93b61":"code","1169296c":"code","b2f9764d":"code","3de58989":"code","73c98e2c":"code","1fcc28c7":"code","58bda74e":"code","5b41bd7c":"code","96819eb3":"code","88365626":"markdown","6d82ed4c":"markdown","aff24610":"markdown","29ea828e":"markdown","e02f618f":"markdown","561d61f2":"markdown","e75c6166":"markdown","4df05b61":"markdown","170f3516":"markdown","77c07c7c":"markdown","6613c8f3":"markdown","5bbcb89f":"markdown","5760907b":"markdown","365487c4":"markdown","f1c9074e":"markdown","c07fd484":"markdown","2c18627d":"markdown","dac8d22b":"markdown"},"source":{"238db9a0":"import pandas as pd\nfrom IPython.core.display import HTML\n\npath = \"..\/input\/\"\n\nversions = pd.read_csv(path+\"KernelVersions.csv\")\nkernels = pd.read_csv(path+\"Kernels.csv\")\nusers = pd.read_csv(path+\"Users.csv\")\n\nlanguage_map = {'1' : 'R','5' : 'R', '12' : 'R', '13' : 'R', '15' : 'R', '16' : 'R',\n                '2' : 'Python','8' : 'Python', '9' : 'Python', '14' : 'Python'}\n\ndef pressence_check(title, tokens, ignore = []):\n    present = False\n    for token in tokens:\n        words = token.split()\n        if all(wrd.lower().strip() in title.lower() for wrd in words):\n            present = True\n    for token in ignore:\n        if token in title.lower():\n            present = False\n    return present \n\n## check if the latest version of the kernel is about the same topic \ndef get_latest(idd):\n    latest = versions[versions['KernelId'] == idd].sort_values('VersionNumber', ascending = False).iloc(0)[0]\n    return latest['VersionNumber']\n\ndef get_kernels(tokens, n, ignore = []):\n    versions['isRel'] = versions['Title'].apply(lambda x : pressence_check(x, tokens, ignore))\n    relevant = versions[versions['isRel'] == 1]\n    results = relevant.groupby('KernelId').agg({'TotalVotes' : 'sum', \n                                                'KernelLanguageId' : 'max', \n                                                'Title' : lambda x : \"#\".join(x).split(\"#\")[-1],\n                                                'VersionNumber' : 'max'})\n    results = results.reset_index().sort_values('TotalVotes', ascending = False).head(n)\n    results = results.rename(columns={'KernelId' : 'Id', 'TotalVotes': 'Votes'})\n\n\n    results['latest_version']  = results['Id'].apply(lambda x : get_latest(x))\n    results['isLatest'] = results.apply(lambda r : 1 if r['VersionNumber'] == r['latest_version'] else 0, axis=1)\n    results = results[results['isLatest'] == 1]\n\n    results = results.merge(kernels, on=\"Id\").sort_values('TotalVotes', ascending = False)\n    results = results.merge(users.rename(columns={'Id':\"AuthorUserId\"}), on='AuthorUserId')\n    results['Language'] = results['KernelLanguageId'].apply(lambda x : language_map[str(x)] if str(x) in language_map else \"\")\n    results = results.sort_values(\"TotalVotes\", ascending = False)\n    return results[['Title', 'CurrentUrlSlug','Language' ,'TotalViews', 'TotalComments', 'TotalVotes', \"DisplayName\",\"UserName\"]]\n\n\ndef best_kernels(tokens, n = 10, ignore = []):\n    response = get_kernels(tokens, n, ignore)     \n    hs = \"\"\"<style>\n                .rendered_html tr {font-size: 12px; text-align: left}\n            <\/style>\n            <h3><font color=\"#1768ea\">\"\"\"+tokens[0].title()+\"\"\"<\/font><\/h3>\n            <table>\n            <th>\n                <td><b>Kernel<\/b><\/td>\n                <td><b>Author<\/b><\/td>\n                <td><b>Language<\/b><\/td>\n                <td><b>Views<\/b><\/td>\n                <td><b>Comments<\/b><\/td>\n                <td><b>Votes<\/b><\/td>\n            <\/th>\"\"\"\n    for i, row in response.iterrows():\n        url = \"https:\/\/www.kaggle.com\/\"+row['UserName']+\"\/\"+row['CurrentUrlSlug']\n        aurl= \"https:\/\/www.kaggle.com\/\"+row['UserName']\n        hs += \"\"\"<tr>\n                    <td>\"\"\"+str(i+1)+\"\"\"<\/td>\n                    <td><a href=\"\"\"+url+\"\"\" target=\"_blank\"><b>\"\"\"  + row['Title'] + \"\"\"<\/b><\/a><\/td>\n                    <td><a href=\"\"\"+aurl+\"\"\" target=\"_blank\">\"\"\"  + row['DisplayName'] + \"\"\"<\/a><\/td>\n                    <td>\"\"\"+str(row['Language'])+\"\"\"<\/td>\n                    <td>\"\"\"+str(row['TotalViews'])+\"\"\"<\/td>\n                    <td>\"\"\"+str(row['TotalComments'])+\"\"\"<\/td>\n                    <td>\"\"\"+str(row['TotalVotes'])+\"\"\"<\/td>\n                    <\/tr>\"\"\"\n    hs += \"<\/table>\"\n    display(HTML(hs))","b169e715":"tokens = [\"linear regression\"]\nbest_kernels(tokens, 10)","9a12db42":"tokens = ['logistic regression', \"logistic\"]\nbest_kernels(tokens, 10)","834d94de":"tokens = ['Ridge']\nbest_kernels(tokens, 10)","812fea56":"tokens = ['Lasso']\nbest_kernels(tokens, 10)","69f83133":"tokens = ['ElasticNet']\nbest_kernels(tokens, 4)","c87bca45":"tokens = ['Decision Tree']\nbest_kernels(tokens, 10)","6527efc7":"tokens = ['random forest']\nbest_kernels(tokens, 10)","4732481c":"tokens = ['lightgbm', 'light gbm', 'lgb']\nbest_kernels(tokens, 10)","8aa6900e":"tokens = ['xgboost', 'xgb']\nbest_kernels(tokens, 10)","5fc28084":"tokens = ['catboost']\nbest_kernels(tokens, 10)","6bea056e":"tokens = ['neural network']\nbest_kernels(tokens, 10)","17a0a18b":"tokens = ['autoencoder']\nbest_kernels(tokens, 10)","6fee6c9b":"tokens = ['deep learning']\nbest_kernels(tokens, 10)","1b4a2729":"tokens = ['convolutional neural networks', 'cnn']\nbest_kernels(tokens, 10)","db48598c":"tokens = ['lstm']\nbest_kernels(tokens, 10)","49e294ba":"tokens = ['gru']\nignore = ['grupo']\nbest_kernels(tokens, 10, ignore)","06c0e581":"tokens = ['mxnet']\nbest_kernels(tokens, 10)","0938471f":"tokens = ['resnet']\nbest_kernels(tokens, 10)","24fd9ce3":"tokens = ['Capsule network', 'capsulenet']\nbest_kernels(tokens, 5)","f8fa554f":"tokens = ['vgg']\nbest_kernels(tokens, 5)","6ace6a88":"tokens = ['inception']\nbest_kernels(tokens, 5)","c9e91400":"tokens = ['computer vision']\nbest_kernels(tokens, 5)","de2c0a71":"tokens = ['transfer learning']\nbest_kernels(tokens, 5)","2310ded8":"tokens = ['yolo']\nbest_kernels(tokens, 5)","dfab3a28":"tokens = ['kmeans', 'k means']\nbest_kernels(tokens, 10)","a87f7a54":"tokens = ['hierarchical clustering']\nbest_kernels(tokens, 3)","40dabfae":"tokens = ['dbscan']\nbest_kernels(tokens, 10)","9f48b2d9":"tokens = ['unsupervised']\nbest_kernels(tokens, 10)","fd1fef81":"tokens = ['naive bayes']\nbest_kernels(tokens, 10)","113d9570":"tokens = ['svm']\nbest_kernels(tokens, 10)","d7648c77":"tokens = ['knn']\nbest_kernels(tokens, 10)","f7005e61":"tokens = ['recommendation engine']\nbest_kernels(tokens, 5)","9081fd21":"tokens = ['EDA', 'exploration', 'exploratory']\nbest_kernels(tokens, 10)","36859972":"tokens = ['feature engineering']\nbest_kernels(tokens, 10)","b167b116":"tokens = ['feature selection']\nbest_kernels(tokens, 10)","4fca651d":"tokens = ['outlier treatment', 'outlier']\nbest_kernels(tokens, 10)","92560ebb":"tokens = ['anomaly detection', 'anomaly']\nbest_kernels(tokens, 8)","aaf3f91c":"tokens = ['smote']\nbest_kernels(tokens, 5)","462d279e":"tokens = ['pipeline']\nbest_kernels(tokens, 10)","21988a5b":"tokens = ['missing value']\nbest_kernels(tokens, 10)","ce47d513":"tokens = ['dataset decomposition', 'dimentionality reduction']\nbest_kernels(tokens, 2)","789cbdd3":"tokens = ['PCA']\nbest_kernels(tokens, 10)","f56e1659":"tokens = ['Tsne', 't-sne']\nbest_kernels(tokens, 10)","d9f72e68":"tokens = ['cross validation']\nbest_kernels(tokens, 10)","d0849db5":"tokens = ['model selection']\nbest_kernels(tokens, 10)","111481e0":"tokens = ['model tuning', 'tuning']\nbest_kernels(tokens, 10)","34c2f836":"tokens = ['gridsearch', 'grid search']\nbest_kernels(tokens, 10)","e99845a0":"tokens = ['ensemble']\nbest_kernels(tokens, 10)","be6b20e2":"tokens = ['stacking', 'stack']\nbest_kernels(tokens, 10)","be3424d4":"tokens = ['bagging']\nbest_kernels(tokens, 10)","f7605925":"tokens = ['NLP', 'Natural Language Processing', 'text mining']\nbest_kernels(tokens, 10)","6257ce3a":"tokens = ['topic modelling']\nbest_kernels(tokens, 8)","0d218814":"tokens = ['word embedding','fasttext', 'glove', 'word2vec']\nbest_kernels(tokens, 8)","78a1a238":"tokens = ['scikit']\nbest_kernels(tokens, 10)","e28ffa80":"tokens = ['tensorflow', 'tensor flow']\nbest_kernels(tokens, 10)","e621e8ed":"tokens = ['theano']\nbest_kernels(tokens, 10)","c0014b34":"tokens = ['keras']\nbest_kernels(tokens, 10)","734be579":"tokens = ['pytorch']\nbest_kernels(tokens, 10)","a6119881":"tokens = ['vowpal wabbit','vowpalwabbit']\nbest_kernels(tokens, 10)","2d17c5cd":"tokens = ['eli5']\nbest_kernels(tokens, 10)","f462b426":"tokens = ['hyperopt']\nbest_kernels(tokens, 5)","851721a2":"tokens = ['pandas']\nbest_kernels(tokens, 10)","0b5df801":"tokens = ['SQL']\nbest_kernels(tokens, 10)","f832086e":"tokens = ['bigquery', 'big query']\nbest_kernels(tokens, 10)","d9b93b61":"tokens = ['gpu']\nbest_kernels(tokens, 10)","1169296c":"tokens = ['visualization', 'visualisation']\nbest_kernels(tokens, 10)","b2f9764d":"tokens = ['plotly', 'plot.ly']\nbest_kernels(tokens, 10)","3de58989":"tokens = ['seaborn']\nbest_kernels(tokens, 10)","73c98e2c":"tokens = ['d3.js']\nbest_kernels(tokens, 4)","1fcc28c7":"tokens = ['bokeh']\nbest_kernels(tokens, 10)","58bda74e":"tokens = ['time series']\nbest_kernels(tokens, 10)","5b41bd7c":"tokens = ['arima']\nbest_kernels(tokens, 10)","96819eb3":"tokens = ['tutorial']\nbest_kernels(tokens, 10)","88365626":"## 3. Tree Based Models","6d82ed4c":"## 12. Some of the Best Tutorials on Kaggle","aff24610":"## 7. Important Data Science Techniques","29ea828e":"<br>\nThanks for viewing. Suggest the list of items which can be added to the list. If you liked this kernel, please upvote.  \n","e02f618f":"Thanks @shivamb and @sudalairajkumar.","561d61f2":"## 4. Neural Networks and Deep Learning Models","e75c6166":"# Data Science Glossary on Kaggle\n\nKaggle is the place to do data science projects. There are so many algorithms and concepts to learn. Kaggle Kernels are one of the best resources on internet to understand the practical implementation of algorithms. There are almost 200,000 kernels published on kaggle and sometimes it becomes diffcult to search for the right implementation. I have used the [Meta Kaggle](https:\/\/www.kaggle.com\/kaggle\/meta-kaggle) database to create a glossary of data science models, techniques and tools shared on kaggle kernels. One can use this kernel as the one place to find other great kernels shared by great authors. Hope you like this kernel.  \n\n\n## Contents \n\n<ul>\n  <li>1. Regression Algorithms\n    <ul>\n    <li>1.1 Linear Regression<\/li>\n    <li>1.2 Logistic Regression<\/li>\n    <\/ul>\n  <\/li>\n    <li>2. Regularization Algorithms\n    <ul>\n    <li>2.1 Ridge Regression Regression<\/li>\n    <li>2.2 Lasso Regression<\/li>\n    <li>2.3 Elastic Net<\/li>\n    <\/ul>\n  <\/li>\n  <\/li>\n    <li>3. Tree Based Models\n    <ul>\n    <li>3.1 Decision Tree<\/li>\n    <li>3.2 Random Forests<\/li>\n    <li>3.3 Lightgbm<\/li>\n    <li>3.4 XgBoost<\/li>\n    <li>3.5 Cat Boost<\/li>\n    <\/ul>\n  <\/li>\n<li>4. Neural Networks and Deep Learning\n    <ul>\n    <li>4.1 Neural Networks<\/li>\n    <li>4.2 AutoEncoders<\/li>\n    <li>4.3 DeepLearning<\/li>\n    <li>4.4 Convolutional Neural Networks<\/li>\n    <li>4.5 LSTMs<\/li>\n    <li>4.6 GRUs<\/li>\n    <li>4.7 MxNet<\/li>\n    <li>4.8 ResNet<\/li>\n    <li>4.9 CapsuleNets<\/li>\n    <li>4.10 VGGs<\/li>\n    <li>4.11 Inception Nets<\/li>\n     <li>4.12 Computer Vision<\/li>\n     <li>4.13 Transfer Learning<\/li>\n     <\/ul>\n  <\/li>\n<li>5. Clustering Algorithms\n    <ul>\n    <li>5.1 K Means Clustering <\/li>\n    <li>5.2 Hierarchial Clustering<\/li>\n    <li>5.3 DB Scan<\/li>\n    <li>5.4 Unsupervised Learning <\/li>\n    <\/ul>\n  <\/li>\n  <li>6. Misc - Models\n    <ul>\n    <li>6.1 K Naive Bayes <\/li>\n    <li>6.2 SVMs<\/li>\n    <li>6.3 KNN<\/li>\n    <li>6.4 Recommendation Engine <\/li>\n    <\/ul>\n  <\/li>\n  <li>7.1 Data Science Techniques - Preprocessing\n    <ul>\n    <li>a. EDA, Exploration <\/li>\n    <li>b. Feature Engineering <\/li>\n    <li>c. Feature Selection <\/li>\n    <li>d. Outlier Treatment<\/li>\n    <li>e. Anomaly Detection<\/li>\n    <li>f. SMOTE<\/li>\n    <li>g. Pipeline<\/li>\n    <li>g. Missing Values<\/li>\n    <\/ul>\n  <\/li>\n  <li>7.2 Data Science Techniques - Dimentionality Reduction\n    <ul>\n    <li>a. Dataset Decomposition <\/li>\n    <li>b. PCA <\/li>\n    <li>c. Tsne <\/li>\n    <\/ul>\n  <\/li>\n  <li>7.3 Data Science Techniques - Post Modelling\n    <ul>\n    <li>a. Cross Validation <\/li>\n    <li>b. Model Selection <\/li>\n    <li>c. Model Tuning <\/li>\n    <li>d. Grid Search <\/li>\n    <\/ul>\n  <\/li>\n  <li>7.4 Data Science Techniques - Ensemblling\n    <ul>\n    <li>a. Ensembling <\/li>\n    <li>b. Stacking <\/li>\n    <li>c. Bagging<\/li>\n    <\/ul>\n  <\/li>\n  <li>8. Text Data \n    <ul>\n    <li>8.1. NLP <\/li>\n    <li>8.2. Topic Modelling <\/li>\n    <li>8.3. Word Embeddings <\/li>\n    <\/ul>\n  <\/li>\n <li>9. Data Science Tools \n    <ul>\n    <li>9.1 Scikit Learn <\/li>\n    <li>9.2 TensorFlow <\/li>\n    <li>9.3 Theano <\/li>\n    <li>9.4 Kears <\/li>\n    <li>9.5 PyTorch <\/li>\n    <li>9.6 Vopal Wabbit <\/li>\n    <li>9.7 ELI5 <\/li>\n    <li>9.8 HyperOpt <\/li>\n    <li>9.9 Pandas <\/li>\n    <li>9.10 Sql <\/li>\n    <li>9.11 BigQuery <\/li>\n    <\/ul>\n  <\/li>\n<li>10. Data Visualizations \n    <ul>\n    <li>10.1. Visualizations <\/li>\n    <li>10.2. Plotly <\/li>\n    <li>10.3. Seaborn <\/li>\n    <li>10.4. D3.Js <\/li>\n    <li>10.5. Bokeh <\/li>\n    <\/ul>\n  <\/li>\n  <li>11. Time Series  \n    <ul>\n    <li>11.1. Time Series Analysis <\/li>\n    <li>10.2. ARIMA <\/li>\n    <\/ul>\n  <\/li>\n<\/ul>\n\n<br><br>\n\n## 1. Regression Algorithms\n","4df05b61":"### 7.4 Ensemblling","170f3516":"### 7.1 Preprocessing","77c07c7c":"## 5. Clustering Algorithms ","6613c8f3":"## 8. Text Data","5bbcb89f":"## 10. Data Visualization","5760907b":"### 7.2 Dimentionality Reduction","365487c4":"## 11. Time Series","f1c9074e":"## 6. Misc - Models ","c07fd484":"## 2. Regularization Algorithms","2c18627d":"### 7.3 Post Modelling Techniques","dac8d22b":"## 9. Data Science Tools"}}