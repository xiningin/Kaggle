{"cell_type":{"da0c6f78":"code","c5836bf3":"code","9f153fd1":"code","343ee575":"code","5e271b06":"code","e848dd5f":"code","5ac9ec19":"code","cc1ea5a0":"code","046c86da":"code","790fbe09":"code","f9b6f4e6":"code","8010b8e2":"code","99168013":"code","7668cf21":"code","6fc63780":"code","8a46bfef":"code","efbbeb5e":"code","29962c1a":"code","e084259f":"code","145c28b7":"code","32d2f29d":"code","2e8a6e8d":"code","c234d859":"code","16033b9c":"code","ceb094c2":"code","ffe152f3":"code","e8b976eb":"code","124c45f2":"code","75a226f2":"code","ac74deaf":"code","834b71dd":"code","4e66fe7e":"code","ff29cddb":"code","98c35939":"code","f7e5a11b":"code","80a35b77":"code","bca47f1a":"code","69135dce":"markdown","40734ccc":"markdown","a39451a1":"markdown","3b7abbb6":"markdown"},"source":{"da0c6f78":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c5836bf3":"from sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.datasets import make_blobs\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report","9f153fd1":"df_train=pd.read_csv('\/kaggle\/input\/anomaly-detection\/train.csv')","343ee575":"df_train.head()","5e271b06":"print(df_train.isnull().sum())","e848dd5f":"df_train['is_anomaly']=df_train['is_anomaly'].replace(False,0).replace(True,1)","5ac9ec19":"print(df_train.head())","cc1ea5a0":"print(df_train.describe())","046c86da":"corr=df_train.corr()","790fbe09":"sns.heatmap(corr, \n            xticklabels=df_train.corr().columns.values,\n            yticklabels=df_train.corr().columns.values,\n            cmap='Accent'\n           )","f9b6f4e6":"print(df_train['is_anomaly'])","8010b8e2":"sns.set_style(\"darkgrid\")\nsns.scatterplot(x=df_train['predicted'], y=df_train['value'])","99168013":"sns.histplot(x='predicted',data=df_train)","7668cf21":"sns.histplot(x='value',data=df_train)","6fc63780":"plt.scatter(range(15830),df_train['value'])","8a46bfef":"#Determine the number of anomalous transactions in the dataset\n\nprint(\"Total No of Transactions:\",len(df_train))\n\nFraud = df_train[df_train['is_anomaly']==True]\nprint(\"No of Anomalous Transactions:\",len(Fraud))\n\nValid = df_train[df_train['is_anomaly']==False]\nprint(\"No of Valid Transactions:\",len(Valid))\n\noutlier_fraction = len(Fraud)\/float(len(df_train))\nvalid_fraction = len(Valid)\/float(len(df_train))\nprint(\"Percentage of Anomalous Transactions:\",round((outlier_fraction*100),3))\nprint(\"Percentage of Valid Transactions:\",round((valid_fraction*100),3))","efbbeb5e":"sns.countplot(x='is_anomaly',data=df_train)","29962c1a":"df_train['is_anomaly'].value_counts()","e084259f":"X_train = df_train.drop(columns=['is_anomaly'],inplace=False,axis=1)\nprint(X_train)\n","145c28b7":"y_train=df_train['is_anomaly']\nprint(y_train)","32d2f29d":"print(X_train.shape)\nprint(y_train.shape)","2e8a6e8d":"# Define a random state \nstate = np.random.RandomState(42)\nX_outliers = state.uniform(low=0, high=1, size=(X_train.shape[0], X_train.shape[1]))","c234d859":"classifiers = {\n    \"Isolation Forest\":IsolationForest(n_estimators=100, max_samples=len(X_train), \n                                       contamination=outlier_fraction,random_state=state, verbose=0),\n    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n                                              leaf_size=30, metric='minkowski',novelty=False,\n                                              p=2, metric_params=None, contamination=outlier_fraction),\n    \"Novelty Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n                                              leaf_size=30, metric='minkowski',novelty=True,\n                                              p=2, metric_params=None, contamination=outlier_fraction),\n    \"Support Vector Machine\":OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05, \n                                         max_iter=-1),\n    \"XGBClassifier\":XGBClassifier(learning_rate=1, n_estimators=1300,eta = 0.7, max_depth= 3,  objective= 'multi:softprob',  num_class= 3)\n}","16033b9c":"\nfor i, (clf_name,clf) in enumerate(classifiers.items()):\n    #Fit the data and tag outliers\n    if clf_name == \"Local Outlier Factor\":\n        y_pred = clf.fit_predict(X_train)\n        scores_prediction = clf.negative_outlier_factor_\n    elif clf_name == \"Support Vector Machine\":\n        clf.fit(X_train)\n        y_pred = clf.predict(X_train)\n    elif clf_name == \"Novelty Local Outlier Factor\":\n        clf.fit(X_train)\n        y_pred = clf.predict(X_train)\n        scores_prediction = clf.negative_outlier_factor_  \n    elif clf_name == \"XGBClassifier\":\n        clf.fit(X_train,y_train)\n        y_pred = clf.predict(X_train)\n    else:    \n        clf.fit(X_train)\n        scores_prediction = clf.decision_function(X_train)\n        y_pred = clf.predict(X_train)\n    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n    y_pred[y_pred == 1] = 0\n    y_pred[y_pred == -1] = 1\n    n_errors = (y_pred != y_train).sum()\n    # Run Classification Metrics\n    print(\"{}: {}\".format(clf_name,n_errors))\n    print(\"Accuracy Score :\")\n    print(accuracy_score(y_train,y_pred))\n    print(\"Classification Report :\")\n    print(classification_report(y_train,y_pred))\n    print(\"Confusion Matrix:\")\n    print(confusion_matrix(y_train, y_pred))","ceb094c2":"df_test=pd.read_csv('\/kaggle\/input\/anomaly-detection\/test.csv')","ffe152f3":"df_test.head()","e8b976eb":"df_test.describe()","124c45f2":"X_test = df_test\nprint(X_test)\n","75a226f2":"# Define a random state \nstate = np.random.RandomState(42)\nX_outliers = state.uniform(low=0, high=1, size=(X_test.shape[0], X_test.shape[1]))","ac74deaf":"print(X_test.shape)","834b71dd":"print(type(X_test))","4e66fe7e":"X_test['value']","ff29cddb":"clf = XGBClassifier(learning_rate=1, n_estimators=1300,eta = 0.7, max_depth= 3,  objective= 'multi:softprob',  num_class= 3)\nclf.fit(X_train,y_train)","98c35939":"y_test_pred = clf.predict(X_test)","f7e5a11b":"data={\"timestamp\":[],\"is_anomaly\":[]}\nfor id,pred in zip(df_test[\"timestamp\"].unique(),y_test_pred):\n  data[\"timestamp\"].append(id)\n  data[\"is_anomaly\"].append(pred)","80a35b77":"output=pd.DataFrame(data,columns=[\"timestamp\",\"is_anomaly\"])\noutput","bca47f1a":"output.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\noutput['is_anomaly'].value_counts()","69135dce":"As seen in the heat map, whether the transactions is anomaly or not is highly dependant on Value.\nSo , here we are considering only Value to make the prediction whether the transaction is an anomaly or not","40734ccc":"Replacing all the false values ie if there are no anomaly as \"0\" and if there are anomaly ie true as replaced with \"1\"","a39451a1":"Test data Analysis","3b7abbb6":"From the above plot we can see that the number of anomaly is very less. This is an imbalanced data set. But , this imbalance in the dataset is expected can be handled by the following algorithm itself."}}