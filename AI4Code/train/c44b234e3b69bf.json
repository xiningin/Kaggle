{"cell_type":{"0def7aec":"code","3ba8f536":"code","dd9a4a19":"code","b25aa65c":"code","a9779ae9":"code","cf7e51a4":"code","a2964e16":"code","8f4299d5":"code","e2853e63":"code","36ef82fc":"code","2512d929":"code","01325d33":"markdown","b4022b86":"markdown"},"source":{"0def7aec":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport glob\nimport random\nfrom tqdm.notebook import tqdm\nfolders=os.listdir('..\/input\/example1')+os.listdir('..\/input\/example2')\nmetadatas=[]\nfor x in tqdm(folders):\n    metadatas.append(pd.read_json('..\/input\/metadatas\/metadata'+x.replace('example','')+'.json'))","3ba8f536":"paths=[]\nY=[]\nfor x in tqdm(folders):\n    for y in glob.glob('..\/input\/dfdc-images-p*\/'+x+'\/*.jpg'):\n        if '_' in y:\n            continue\n        if not os.path.exists(y):\n            continue\n        Y.append(['REAL','FAKE'].index(metadatas[folders.index(x)][y.replace('..\/input\/dfdc-images-p1\/','').replace('..\/input\/dfdc-images-p2\/','').replace(x+'\/','').replace('.jpg','.mp4')]['label']))\n        paths.append(y)","dd9a4a19":"real=[]\nfake=[]\nfor m,n in zip(paths,Y):\n    if n==0:\n        real.append(m)\n    else:\n        fake.append(m)\nfake=random.sample(fake,len(real))\npaths,Y=[],[]\nfor x in real:\n    paths.append(x)\n    Y.append(0)\nfor x in fake:\n    paths.append(x)\n    Y.append(1)","b25aa65c":"def shuffle(X,y):\n    new_train=[]\n    for m,n in zip(X,y):\n        new_train.append([m,n])\n    random.shuffle(new_train)\n    X,y=[],[]\n    for x in new_train:\n        X.append(x[0])\n        y.append(x[1])\n    return X,y","a9779ae9":"paths,y=shuffle(paths,Y)","cf7e51a4":"def get_birghtness(img):\n    return img\/img.max()","a2964e16":"def process_img(img):\n    imgs=[]\n    for x in range(10):\n        imgs.append(get_birghtness(img[:,x*240:(x+1)*240,:]))\n    return np.array(imgs)","8f4299d5":"def gets(paths):\n    al=[]\n    for x in paths:\n        al.append(process_img(cv2.cvtColor(cv2.imread(x),cv2.COLOR_BGR2RGB)))\n    return al\ndef generator(paths,y,batch_size=16):\n    while True:\n        for x in range(len(paths)\/\/batch_size):\n            if x*batch_size+batch_size>len(paths):\n                yield (np.array(gets(paths[x*batch_size:])),y[x*batch_size:])\n            yield (np.array(gets(paths[x*batch_size:x*batch_size+batch_size])),\n                   y[x*batch_size:x*batch_size+batch_size])","e2853e63":"!pip install efficientnet\nimport efficientnet.keras as efn\nbottleneck = efn.EfficientNetB1(weights='imagenet',include_top=False,pooling='avg')\nfrom keras.layers import *\ninp=Input((10,240,240,3))\nx=TimeDistributed(bottleneck)(inp)\nx = LSTM(128)(x)\nx = Dense(64, activation='elu')(x)\nx = Dense(1,activation='sigmoid')(x)","36ef82fc":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(paths,y,test_size=0.15)\nfrom keras import Model\nmodel=Model(inp,x)\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler\ndef schedule(epoch):\n    return [6e-4,1e-4][epoch]\ncallback=LearningRateScheduler(schedule)\nmodel.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-4))\n#model.fit(X,y,batch_size=16)\nmodel.fit_generator(generator(X_train,y_train,4),steps_per_epoch=len(X_train)\/\/4+1,validation_data=generator(X_test,y_test,4),validation_steps=len(X_test)\/\/4+1,epochs=2)","2512d929":"model.save('model.h5')","01325d33":"Here is the training notebook for [this](https:\/\/www.kaggle.com\/unkownhihi\/dfdc-lrcn-inference) inference notebook. The reason why I'm doing it, is because I saw myself in other competition, struggling to get to the medal zone, but don't have a clue how people got there. I removed the dataset because I want to avoid people just clone, run, submit. \n\nThis training notebook is nothing special, just load, train.","b4022b86":"Please upvote if you found this helpful."}}