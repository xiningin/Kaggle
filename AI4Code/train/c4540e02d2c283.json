{"cell_type":{"601be1a7":"code","4747da9f":"code","b758dbb3":"code","2bb12cf1":"code","c79713be":"code","dac3ab3a":"code","31d46378":"code","c4060c69":"code","12915165":"code","a3b8fd5f":"code","4547e4a9":"code","9c6bb8b0":"code","77801ffe":"code","0ad4c4a3":"code","8ef49e5a":"code","3351218c":"code","0df3891f":"code","9df8e512":"code","dfcd3fa1":"markdown"},"source":{"601be1a7":"!pip install pyspark","4747da9f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b758dbb3":"import pyspark\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"Spark\").getOrCreate()","2bb12cf1":"from pyspark.sql.functions import *\nfrom pyspark.sql import functions as f\n\n# Get data\ntrainin_data = spark.read.csv(\"\/kaggle\/input\/car-acceptability-prediction\/train.csv\",header=True,inferSchema = True)\ntest_data = spark.read.csv(\"\/kaggle\/input\/car-acceptability-prediction\/test.csv\",header=True,inferSchema = True)","c79713be":"from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import StringIndexer, IndexToString, VectorIndexer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier,DecisionTreeClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator","dac3ab3a":"#STAGE 1\nlabelindexer = StringIndexer(inputCol = \"acceptability\", outputCol = \"indexedlabel\").fit(trainin_data)\n#STAGE 2\nindexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(trainin_data) for column in trainin_data.columns[1:-1] ]\n#indexedFeature = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(dff).transform(dff) for column in dfx.columns ]\n#featureindexer = VectorIndexer(inputCol = dfx.columns, outputCol = \"indexedFeature\").fit(df)\nassembler = VectorAssembler(inputCols=['buying_price_index','maintenance_price_index','number_of_doors_index',\n                                       'carry_capacity_index','trunk_size_index','safety_index'], outputCol=\"features\")\n#STAGE 3\nrfc = RandomForestClassifier(labelCol = 'indexedlabel', featuresCol = 'features', numTrees=10)\nrfc_1 = RandomForestClassifier(labelCol = 'indexedlabel', featuresCol = 'features', numTrees=15)\nrfc_2 = RandomForestClassifier(labelCol = 'indexedlabel', featuresCol = 'features', maxDepth=10)\n\ndtc = DecisionTreeClassifier(labelCol = 'indexedlabel', featuresCol = 'features', maxDepth=10)\n\n\n\n# STAGE 4\nlabelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",labels = labelindexer.labels)","31d46378":"# pipeline = Pipeline().setStages([labelindexer, indexers, assembler, decisiontreemodel])\n\nstages = indexers\nstages.append(labelindexer)\nstages.append(assembler)\nstages.append(rfc_2)\nstages.append(labelConverter)\n\npipeline = Pipeline().setStages(stages)","c4060c69":"model = pipeline.fit(trainin_data)","12915165":"prediction = model.transform(trainin_data)","a3b8fd5f":"prediction.show(5)","4547e4a9":"evaluator = MulticlassClassificationEvaluator(labelCol = 'indexedlabel',predictionCol = 'prediction',metricName='accuracy')\nscore = evaluator.evaluate(prediction)\nprint(f\"accuracy: {score:.5f}\")","9c6bb8b0":"# Testing\n \ntest_prediction = model.transform(test_data)\nsubmit_pred = test_prediction.select('car_id','predictedLabel')","77801ffe":"submit_pred.write.csv('results.csv',mode = \"overwrite\",header=[\"car_id\",\"acceptability\"])","0ad4c4a3":"sample_sol = spark.read.csv(\"\/kaggle\/input\/car-acceptability-prediction\/sampleSolutions.csv\",header=True,inferSchema = True)\ntest_label_indexer = StringIndexer(inputCol = \"acceptability\",outputCol = \"indexedlabel\").fit(sample_sol)\nsample_sol = test_label_indexer.transform(sample_sol)","8ef49e5a":"test_prediction = test_prediction.join(sample_sol,test_prediction.car_id == sample_sol.car_id)","3351218c":"test_prediction.show(5,truncate=False)","0df3891f":"test_evaluator = MulticlassClassificationEvaluator(labelCol = 'indexedlabel',predictionCol = 'prediction',metricName='accuracy')\ntest_score = test_evaluator.evaluate(test_prediction)\nprint(f\"accuracy: {test_score:.5f}\")","9df8e512":"!jupyter nbconvert --to pdf \/kaggle\/input\/hello-world-turn-this-into-a-pdf\/__notebook__.ipynb --output \/kaggle\/working\/Assignment7_18520842_18520426_18520908.pdf","dfcd3fa1":"# **Danh s\u00e1ch th\u00e0nh vi\u00ean:**\n1. Nguy\u1ec5n Ho\u00e0ng Huy - 18520842\n2. L\u00ea Tr\u1ea7n Ho\u00e0i \u00c2n - 18520426\n3. Tr\u1ea7n Qu\u1ed1c Kh\u00e1nh - 18520908"}}