{"cell_type":{"c851671b":"code","54b824fa":"code","a084c59d":"code","497fe4bd":"code","caaf59ba":"code","6804e062":"code","63af3fc0":"code","785faf3b":"code","64b1e04c":"code","c9c64bc9":"code","065708ff":"code","ef69a4a9":"code","a1627879":"code","9281f717":"code","30582880":"code","15917ffb":"code","923a36be":"code","337c7c83":"code","78f3588e":"code","ffeb540c":"code","42422a13":"code","27b6b87b":"code","85f79634":"code","ff28f8fc":"code","6850f8d2":"code","effa6445":"code","487966fc":"code","7a8d5c9b":"code","cbd08b69":"code","06702271":"code","70e65aea":"code","73bc2810":"code","05e1abe2":"code","494acfcc":"code","be66e6ad":"code","a69824a1":"code","e6cae069":"code","4501c42d":"code","63b59954":"code","0aadfe5d":"code","00dc97b7":"code","ad9d6745":"code","6adb33bc":"code","180e45cf":"code","9a158fe5":"code","829d1a3f":"code","16d2829a":"code","d6713c1c":"code","8c5e2cc8":"code","df1f92f4":"code","e3091f3a":"code","9171a354":"code","beb412f2":"code","ae7e60fc":"code","ae235eb9":"code","19ca551f":"code","3612b9e1":"code","3dba9f04":"code","33b0c68e":"code","b12cf9d9":"code","82284235":"code","2f4ccf03":"code","601d0f36":"code","81e1c1ff":"code","cde2d13a":"code","099267d6":"code","f1f31039":"code","049a653c":"code","ac15e94d":"code","d250504c":"code","89471952":"code","e17e5c33":"code","70d6de32":"code","09e9d355":"code","218e2f99":"code","1a690549":"code","297dec9d":"code","acdb2298":"code","68679720":"code","eb34785a":"code","271d60c1":"code","9b67a9dc":"code","55e819b9":"code","f0827650":"code","39bebb84":"code","5dd6ee8d":"code","c3efcb33":"markdown","335d418e":"markdown","284d724e":"markdown","40fd3251":"markdown","1afa30c6":"markdown","fa8c3f43":"markdown","deec27d3":"markdown","d32f0184":"markdown","f5b99b15":"markdown","a5bf123f":"markdown","68eeee20":"markdown","07fa749a":"markdown","35f7a244":"markdown","f3c8ec78":"markdown","f833e4bf":"markdown","e58c3331":"markdown","abbc71f6":"markdown","acfc47df":"markdown"},"source":{"c851671b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot\nimport seaborn as sns\nfrom sklearn import preprocessing\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets, linear_model, metrics","54b824fa":"df = pd.read_csv('..\/input\/car-selling-price-prediction\/CarSalePrice.csv')\ndf","a084c59d":"\n# Exploratory Data Analysis\ndef libraries():\n    global pd,np\n    import pandas as pd\n    import numpy as np\ndef load():\n    global df\n    df=pd.read_csv('..\/input\/car-selling-price-prediction\/CarSalePrice.csv')\n    \ndef top_rows(value):\n    print('\\033[1m'+ 'displaying the', value, 'rows from top'+'\\033[0m')\n    a=df.head(value)\n    print(a,'\\n')\n    \ndef bottom_rows(value):\n    print('\\033[1m'+'displaying the', value, 'rows from bottom'+'\\033[0m')\n    b=df.tail(value)\n    print(b,'\\n')\n    \ndef rows_columns():\n    print('\\033[1m'+'Shape of the Data set'+'\\033[0m')\n    c=df.shape\n    print(c,'\\n')\n    \ndef col_names():\n    print('\\033[1m'+'Column Names in the Data set'+'\\033[0m')\n    d=df.columns\n    print(d,'\\n')\n    \ndef information():\n    print('\\033[1m'+'Quick Overview of DataSet(info)'+'\\033[0m')\n    e = df.info()\n    print(e,'\\n')\n\ndef sizee():\n    print('\\033[1m'+'No.of Elements in the DataSet'+'\\033[0m')\n    f = df.size\n    print(f,'\\n')\n\ndef ndimension():\n    print('\\033[1m'+'Dimensions in your dataframe'+'\\033[0m')\n    g = df.ndim\n    print(g,'\\n')\n    \ndef stats_summary():\n    print('\\033[1m'+'Staistical Summary of DataSet'+'\\033[0m')\n    h = df.describe()\n    print(h,'\\n')\n    \ndef null_values():\n    print('\\033[1m'+'Number of Missing values in each column'+'\\033[0m')\n    i = df.isnull().sum()\n    print(i,'\\n')\n    \ndef n_unique():\n    print('\\033[1m'+'Number of unique elements'+'\\033[0m')\n    j = df.nunique()\n    print(j,'\\n')\n    \ndef memory_use():\n    print('\\033[1m'+'Memory used by all colomns in bytes'+'\\033[0m')\n    k = df.memory_usage()\n    print(k,'\\n')\n    \ndef is_na(value):\n    print('\\033[1m'+'Dataframe filled with boolean values with true indicating missing values'+'\\033[0m')\n    l = df.isna().head(value)\n    print(l,'\\n')\n    \ndef duplicate():\n    print('\\033[1m'+'Boolean Series denoting duplicate rows'+'\\033[0m')\n    m = df.duplicated().sum()\n    print(m,'\\n')\n    \ndef valuecounts():\n    print('\\033[1m'+'Series containing count of unique values'+'\\033[0m')\n    n = df.value_counts()\n    print(n,'\\n')\n\ndef datatypes():\n    print('\\033[1m'+'Datatype of each column'+'\\033[0m')\n    o = df.dtypes\n    print(o,'\\n')\n    \ndef correlation():\n    print('\\033[1m'+'Correalation between all columns in DataFrame'+'\\033[0m')\n    p = df.corr()\n    print(p,'\\n')\n    \ndef nonnull_count():\n    print('\\033[1m'+'Count of non-null values'+'\\033[0m')\n    q = df.count()\n    print(q,'\\n')\n    \ndef eda():\n    load()\n    value= 5 \n    datatypes()\n    top_rows(value)\n    bottom_rows(value)\n    rows_columns()\n    col_names()\n    information()\n    sizee()\n    ndimension()\n    stats_summary()\n    null_values()\n    n_unique()\n    memory_use()\n    is_na(value)\n    nonnull_count()\n    duplicate()\n    valuecounts()\n    correlation()\n    \n    \n    \n        \ndef stats_u(data,col):\n    if data[col].dtype == \"float64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        max_value = data[col].max()\n        print('Maximum value of',col,'column',max_value)\n        min_value = data[col].min()\n        print('Minimum value of',col,'column',min_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n            \n    elif data[col].dtype == \"int64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(\"Outliers are:\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n    else:\n        print(col,'has Qualitative Data')\n        z = df[col].mode()\n        print('mode of',col,'column:\\n',z)\n        print('Count of mode is:\\n',df[col].value_counts())\n        print('Unique strings in',col,'are',data[col].nunique())\n        if(data[col].nunique() == 1):\n            print(col,'has same string')\n        elif(data[col].nunique() == 2):\n            print(col,'has binary strings')\n        else:\n            print(col,'has multi stings')\n\n\nlibraries()\neda()\n\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of DataSet'+'\\033[0m')\nprint('\\033[1m'+'DataTypes in the DataSet:\\n'+'\\033[0m',df.dtypes)\nprint('\\033[1m'+'Columns in DataSet:'+'\\033[0m',df.columns)\nprint('\\033[1m'+'Shape of DataSet:'+'\\033[0m',df.shape)\nprint('\\033[1m'+'Size of DataSet:'+'\\033[0m',df.size)\nprint('\\033[1m'+'Dimension of DataSet:'+'\\033[0m',df.ndim)\nprint('\\033[1m'+'Total Memory used in DataSet:'+'\\033[0m',df.memory_usage().sum())\nprint('\\033[1m'+'Total Number of missing values in DataSet:'+'\\033[0m',df.isnull().sum().sum())\nprint('\\033[1m'+'Total Number of Unique values in DataSet:'+'\\033[0m',df.nunique().sum())\nprint('\\033[1m'+'Total Number of non null values in DataSet:'+'\\033[0m',df.count().sum())\nprint('\\033[1m'+'Total Number of duplicate rows in DataSet:'+'\\033[0m',df.duplicated().sum())\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of Each Colomn'+'\\033[0m')\nprint(\"\\n\")\ncols=df.columns\ncols\nfor i in cols:\n    print('\\033[1m'+i+'\\033[0m')\n    stats_u(df,i)\n    print(\"\\n\")\n            ","497fe4bd":"df.head()","caaf59ba":"df.tail()","6804e062":"df.shape","63af3fc0":"df.size","785faf3b":"df.dtypes","64b1e04c":"df.columns","c9c64bc9":"df.info()","065708ff":"df.describe()","ef69a4a9":"df.duplicated().sum()","a1627879":"df.isnull().sum()","9281f717":"df.skew()","30582880":"df.corr()","15917ffb":"! pip install Autoviz","923a36be":"! pip install xlrd","337c7c83":"from autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()\ndf_av = AV.AutoViz('..\/input\/car-selling-price-prediction\/CarSalePrice.csv')","78f3588e":"''' Plot a Shifted Correlation Matrix '''\n# Diagonal correlation is always unity & less relevant, shifted variant shows only relevant cases\ndef corrMat(df,id=False):\n    \n    corr_mat = df.corr().round(2)\n    f, ax = plt.subplots(figsize=(12,7))\n    mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n    mask = mask[1:,:-1]\n    corr = corr_mat.iloc[1:,:-1].copy()\n    sns.heatmap(corr,mask=mask,vmin=-0.3,vmax=0.3,center=0, \n                cmap='RdPu_r',square=False,lw=2,annot=True,cbar=False)\n#     bottom, top = ax.get_ylim() \n#     ax.set_ylim(bottom + 0.5, top - 0.5) \n    ax.set_title('Shifted Linear Correlation Matrix')\n    \ncorrMat(df)","ffeb540c":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='Fuel',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['Dist_travelled', 'Safetyscore', 'InitialBuyingPrice', 'SellingPrice', 'YearOfRegistration','Fuel']\nsnsPairGrid(df[numvars_targ])","42422a13":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df.corr(),annot = True, cmap = 'viridis')\nplt.show()\n\n# heat map of original dataframe","27b6b87b":"sns.pairplot(df)","85f79634":"df['ImportedOrNot'].value_counts()","ff28f8fc":"sns.countplot(df['ImportedOrNot'])\nplt.show()","6850f8d2":"df['YearOfRegistration'].value_counts()","effa6445":"sns.countplot(df['YearOfRegistration'])\nplt.show()\n\n# 2004-2009 registrations are more","487966fc":"df['Transmission'].value_counts()","7a8d5c9b":"for i in range(len(df['Transmission'])):\n    if df['Transmission'][i] == 'Autto':\n        df['Transmission'][i] = 'Auto'","cbd08b69":"df['Transmission'].value_counts()","06702271":"sns.countplot(df['Transmission'])\nplt.show()","70e65aea":"df['Fuel'].value_counts()","73bc2810":"sns.countplot(df['Fuel'])\nplt.show()","05e1abe2":"df['Safetyscore'].value_counts()","494acfcc":"sns.countplot(df['Safetyscore'])\nplt.show()","be66e6ad":"fig = px.histogram(df, 'Dist_travelled',             \n                   color=\"ImportedOrNot\",\n                   title=\"<b>Average Dist_travelled per ImportedOrNot<\/b>\")\n\nfig.add_vline(x=df['Dist_travelled'].mean(), line_width=2, line_dash=\"dash\", line_color=\"black\")\nfig.update_layout(bargap=0.2)\nfig.show()\n\n# many cars travelled between 2ok to 3ok kms","a69824a1":"a = df.drop(['Dist_travelled','InitialBuyingPrice','SellingPrice'],axis = 1)\nfor i in a:\n    x = df[i]\n    y = df['Dist_travelled']\n    sns.barplot(x = x,y = y)\n    plt.show()","e6cae069":"for i in a:\n    x = df[i]\n    y = df['InitialBuyingPrice']\n    sns.barplot(x = x,y = y)\n    plt.show()","4501c42d":"for i in a:\n    x = df[i]\n    y = df['SellingPrice']\n    sns.barplot(x = x,y = y)\n    plt.show()","63b59954":"### Selling price for imported cars are more\n### Selling price for autotransmission cars are more\n### except for safteyscore 2 as safety score increases sellinf price increases","0aadfe5d":"obj = a.columns\nobj","00dc97b7":"num = []\nfor i in df.columns:\n    if i not in obj:\n        num.append(i)\nnum","ad9d6745":"for i in range(len(obj)):\n    x='ImportedOrNot'\n    for j in range(len(num)):\n        if obj[i] != x:\n            sns.barplot(x= x,y=num[j],hue=obj[i],data=df)\n            plt.legend(bbox_to_anchor=(1.1, 1.05))\n            plt.show()","6adb33bc":"for i in range(len(obj)):\n    x='YearOfRegistration'\n    for j in range(len(num)):\n        if obj[i] != x:\n            sns.barplot(x= x,y=num[j],hue=obj[i],data=df)\n            plt.legend(bbox_to_anchor=(1.1, 1.05))\n            plt.show()","180e45cf":"for i in range(len(obj)):\n    x='Transmission'\n    for j in range(len(num)):\n        if obj[i] != x:\n            sns.barplot(x= x,y=num[j],hue=obj[i],data=df)\n            plt.legend(bbox_to_anchor=(1.1, 1.05))\n            plt.show()\n            \n# no impoted cars are in manual","9a158fe5":"for i in range(len(obj)):\n    x='Fuel'\n    for j in range(len(num)):\n        if obj[i] != x:\n            sns.barplot(x= x,y=num[j],hue=obj[i],data=df)\n            plt.legend(bbox_to_anchor=(1.1, 1.05))\n            plt.show()","829d1a3f":"for i in range(len(obj)):\n    x='Safetyscore'\n    for j in range(len(num)):\n        if obj[i] != x:\n            sns.barplot(x= x,y=num[j],hue=obj[i],data=df)\n            plt.legend(bbox_to_anchor=(1.1, 1.05))\n            plt.show()","16d2829a":"for i in range(len(obj)):\n    x='Dist_travelled'\n    for j in range(len(num)):\n        if num[j] != x:\n            sns.scatterplot(x= x,y=num[j],hue=obj[i],data=df)\n            plt.legend(bbox_to_anchor=(1.5, 1))\n            plt.show()","d6713c1c":"for i in range(len(obj)):\n    x='InitialBuyingPrice'\n    for j in range(len(num)):\n        if num[j] != x:\n            sns.scatterplot(x= x,y=num[j],hue=obj[i],data=df)\n            plt.legend(bbox_to_anchor=(1.5, 1))\n            plt.show()","8c5e2cc8":"for i in range(len(obj)):\n    x='SellingPrice'\n    for j in range(len(num)):\n        if num[j] != x:\n            sns.scatterplot(x= x,y=num[j],hue=obj[i],data=df)\n            plt.legend(bbox_to_anchor=(1.5, 1))\n            plt.show()","df1f92f4":"df1 = df.groupby('YearOfRegistration').agg({'Dist_travelled' : 'mean','Safetyscore' : 'mean','InitialBuyingPrice' : 'mean','SellingPrice':'mean'})\ndf1","e3091f3a":"px.bar(data_frame=df1, barmode='group',\n       title = \"<b>Quality wise Analyzing<\/b>\",template=\"plotly_dark\")","9171a354":"df_ni = df[df['ImportedOrNot'] == 0]\ndf_ni\n# data frame of cars which are not imported","beb412f2":"df_ni1 = df_ni.groupby('YearOfRegistration').agg({'Dist_travelled' : 'mean','Safetyscore' : 'mean','InitialBuyingPrice' : 'mean','SellingPrice':'mean'})\ndf_ni1","ae7e60fc":"px.bar(data_frame=df_ni1, barmode='group',\n       title = \"<b>Quality wise Analyzing<\/b>\",template=\"plotly_dark\")","ae235eb9":"df_ni.corr()","19ca551f":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df_ni.drop('ImportedOrNot',axis = 1).corr(),annot = True, cmap = 'viridis')\nplt.show()","3612b9e1":"sns.pairplot(df_ni)","3dba9f04":"df_i = df[df['ImportedOrNot'] == 1]\ndf_i\n# data frame of cars which are imported","33b0c68e":"df_i1 = df_i.groupby('YearOfRegistration').agg({'Dist_travelled' : 'mean','Safetyscore' : 'mean','InitialBuyingPrice' : 'mean','SellingPrice':'mean'})\ndf_i1","b12cf9d9":"px.bar(data_frame=df_i1, barmode='group',\n       title = \"<b>Quality wise Analyzing<\/b>\",template=\"plotly_dark\")","82284235":"df_i.corr()","2f4ccf03":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df_i.drop('ImportedOrNot',axis = 1).corr(),annot = True, cmap = 'viridis')\nplt.show()","601d0f36":"plt.figure(figsize=(6,8))\nx = df.drop(obj,axis = 1)\nfor i in x.columns:\n    sns.histplot(x[i],kde = True)\n    plt.show()","81e1c1ff":"x = df.drop(obj,axis = 1)\nfor i in x.columns:\n    sns.boxplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","cde2d13a":"x = df.drop(obj,axis = 1)\nfor i in x.columns:\n    sns.violinplot(x = i, data = x,color = 'yellowgreen')   \n    plt.xlabel(i)\n    plt.show()","099267d6":"plt.figure(figsize=(6,8))\nfor i in df.columns:\n    if i not in 'SellingPrice':\n        sns.scatterplot(x = 'SellingPrice',y = i,data = df,color = 'Red')\n        plt.show()","f1f31039":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nfor i in x.columns:\n    count_outliers(df,i)","049a653c":"df.isnull().sum()#no null value treatment","ac15e94d":"for i in a:\n    Q1 = np.percentile(df[i], 25,interpolation = 'midpoint')\n    Q3 = np.percentile(df[i], 75,interpolation = 'midpoint')\n    IQR = Q3 - Q1\n    upper1 = np.where(df[i] >= (Q3+1.5*IQR))\n    lower1 = np.where(df[i] <= (Q1-1.5*IQR))\n    for j in range(len(upper1[0])):\n        df.replace(df[i][upper1[0][j]],np.nan, inplace = True)\n    for k in range(len(lower1[0])):\n        df.replace(df[i][lower1[0][k]],np.nan, inplace = True)","d250504c":"df.isnull().sum()","89471952":"for t in a:\n    q1=df[t].quantile(0.25)\n    q2=df[t].quantile(0.5)\n    q3=df[t].quantile(0.75)\n    IQR=q3-q1\n    LLP=q1-1.5*IQR\n    ULP=q3+1.5*IQR\n    l=[]\n    m=[]\n    df7 = df[df[t].values>ULP][t]\n    for i in df7:\n        l.append(i)\n    df8 = df[df[t].values<LLP][t]\n    for i in df8:\n        m.append(i)\n    k = 0\n    p = 0\n    if len(l)>0:\n        k=sum(l)\/len(l)\n    if len(m)>0:\n        p=sum(m)\/len(m)\n    u=(k+p)\/2\n    for i in df.columns:\n        if df[i].isnull().sum()>=1:\n            df[i].fillna(u,inplace = True)","e17e5c33":"a[0]","70d6de32":"df.isnull().sum()","09e9d355":"df2=pd.get_dummies(data=df,columns=obj,drop_first=True)\ndf2","218e2f99":"df2 = df2[['Dist_travelled', 'InitialBuyingPrice',\n       'ImportedOrNot_1', 'YearOfRegistration_2004', 'YearOfRegistration_2005',\n       'YearOfRegistration_2006', 'YearOfRegistration_2007',\n       'YearOfRegistration_2008', 'YearOfRegistration_2009',\n       'YearOfRegistration_2011', 'YearOfRegistration_2012',\n       'Transmission_Manual', 'Transmission_SemiAuto', 'Fuel_Diesel',\n       'Fuel_Petrol', 'Safetyscore_3', 'Safetyscore_4', 'Safetyscore_5',\n       'Safetyscore_6', 'Safetyscore_7', 'Safetyscore_8', 'SellingPrice']]","1a690549":"df2","297dec9d":"df2.corr()","acdb2298":"X = df2\ny = df2['SellingPrice']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","68679720":"reg = linear_model.LinearRegression()\nreg.fit(X_train, y_train)","eb34785a":"reg.coef_","271d60c1":"pred = reg.predict(X_test)\npred","9b67a9dc":"plt.scatter(y_test,pred)\nplt.xlabel('Y Test (True Values)')\nplt.ylabel('Predicted values')\nplt.show()","55e819b9":"print('MAE',metrics.mean_absolute_error(y_test,pred))\nprint('MSE',metrics.mean_squared_error(y_test,pred))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(y_test,pred)))","f0827650":"metrics.explained_variance_score(y_test,pred)","39bebb84":"sns.displot(y_test-pred,bins = 50,kde = True)","5dd6ee8d":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\nforest= RandomForestRegressor(n_estimators =50, random_state = 0)\nforest.fit(X_train,y_train)  \ny_pred = forest.predict(X_test)\nforest.score(X_test,y_test)","c3efcb33":"# Exploratory Data Analysis in one code","335d418e":"# Importing Libraries","284d724e":"# Data Preprocessing","40fd3251":"# Prediction using linear Regression","1afa30c6":"# Exploratory Data Analysis","fa8c3f43":"# count of outliers","deec27d3":"## histplot for numerical cloumns","d32f0184":"### You can easily write observations from above plots","f5b99b15":"### Initially buying price for imported cars is more\n### Intially buying price for auto transmission is more \n### as initial price increases safetyscore also increases","a5bf123f":"### here there is cleaning of column Transmission because auto is mistakenly given as Autto for some data","68eeee20":"## Rearranging columns","07fa749a":"# Data Visualisation Using Autoviz","35f7a244":"# Loading Dataset","f3c8ec78":"# Data Visualisation","f833e4bf":"## Encoding","e58c3331":"# Feature Selection","abbc71f6":"# Prediction using random forest regressor","acfc47df":"### the only observation is as year dist_travelled increases safety score increases"}}