{"cell_type":{"f4a1e2c2":"code","475b1493":"code","ae7c6f60":"code","ca1e1229":"code","e3865816":"code","d9b3a57c":"code","c468f9f0":"code","a2899a11":"code","3eaeff46":"code","9f4dcc9b":"code","4fd7aaeb":"code","c251472d":"code","2a690f8c":"code","453cd0a5":"code","52c489e6":"code","1a0023eb":"code","8b307dc7":"code","711ece40":"markdown"},"source":{"f4a1e2c2":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom fastai.vision import *\nfrom fastai.metrics import accuracy\nfrom fastai.basic_data import *\nfrom skimage.util import montage\nimport pandas as pd\nfrom torch import optim\nimport re\n\nfrom utils import *","475b1493":"!git clone https:\/\/github.com\/radekosmulski\/whale\n","ae7c6f60":"import sys\n # Add directory holding utility functions to path to allow importing utility funcitons\n#sys.path.insert(0, '\/kaggle\/working\/protein-atlas-fastai')\nsys.path.append('\/kaggle\/working\/whale')","ca1e1229":"from whale.utils import map5","e3865816":"import fastai\nfrom fastprogress import force_console_behavior\nimport fastprogress\nfastprogress.fastprogress.NO_BAR = True\nmaster_bar, progress_bar = force_console_behavior()\nfastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar","d9b3a57c":"from fastai import *\nfrom fastai.vision import *","c468f9f0":"ls ..\/input","a2899a11":"path = Path('..\/input\/humpback-whale-identification\/')\npath_test = Path('..\/input\/humpback-whale-identification\/test')\npath_train = Path('..\/input\/humpback-whale-identification\/train')","3eaeff46":"df = pd.read_csv(path\/'train.csv')#.sample(frac=0.05)\ndf.head()\nval_fns = {'69823499d.jpg'}","9f4dcc9b":"fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}\npath2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)","4fd7aaeb":"name = f'res50-full-train'","c251472d":"SZ = 224\nBS = 64\nNUM_WORKERS = 0\nSEED=0","2a690f8c":"data = (\n    ImageItemList\n        .from_df(df[df.Id != 'new_whale'], '..\/input\/humpback-whale-identification\/train', cols=['Image'])\n        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n        .label_from_func(lambda path: fn2label[path2fn(path)])\n        .add_test(ImageItemList.from_folder('..\/input\/humpback-whale-identification\/test'))\n        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n        .databunch(bs=BS, num_workers=NUM_WORKERS, path='..\/input\/humpback-whale-identification')\n        .normalize(imagenet_stats)\n)","453cd0a5":"MODEL_PATH = \"\/kaggle\/working\/\"","52c489e6":"%%time\n\nlearn = create_cnn(data, models.resnet50, lin_ftrs=[2048], model_dir=MODEL_PATH)\nlearn.clip_grad();","1a0023eb":"learn.fit_one_cycle(14, 1e-2)\nlearn.save(f'{name}-stage-1')","8b307dc7":"!rm -rf \/kaggle\/working\/whale","711ece40":"I take a curriculum approach to training here. I first expose the model to as many different images of whales as quickly as possible (no oversampling) and train on images resized to 224x224.\n\nI would like the conv layers to start picking up on features useful for identifying whales. For that, I want to show the model as rich of a dataset as possible.\n\nI then train on images resized to 448x448.\n\nFinally, I train on oversampled data. Here, the model will see some images more often than others but I am hoping that this will help alleviate the class imbalance in the training data."}}