{"cell_type":{"6d478aa4":"code","fef1cb81":"code","c62685f6":"code","aa801dcd":"code","8da42c12":"code","61297ed0":"code","142c3ada":"code","0ca3d805":"code","b1e97b43":"code","46d91bc7":"code","2d1eda8f":"code","9d55d0bd":"code","292a39a6":"code","bb084ffb":"code","bd2fffd3":"code","89c9a7c9":"code","9a4374c6":"code","663cf5c7":"code","52c5df8b":"code","764b9f3c":"code","d8ee1093":"code","a18f693c":"code","edbd90f3":"code","b092c4df":"markdown","15e7ca95":"markdown"},"source":{"6d478aa4":"from tensorflow.keras.layers import Input, Lambda, Conv2D, Dense, Flatten\nfrom tensorflow.keras.models import Sequential, Model\nfrom glob import glob\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image\n","fef1cb81":"model = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"relu\", input_shape=(150,150,3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=32, kernel_size=2, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(100,activation=\"relu\"))\nmodel.add(Dense(6,activation=\"softmax\"))\nmodel.summary()","c62685f6":"model.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","aa801dcd":"train_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","8da42c12":"training_set = train_datagen.flow_from_directory('..\/input\/intel-image-classification\/seg_train\/seg_train',\n                                                 target_size = (150, 150),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')","61297ed0":"test_set = train_datagen.flow_from_directory('..\/input\/intel-image-classification\/seg_test\/seg_test',\n                                                 target_size = (150, 150),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')","142c3ada":"model_fit = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=10,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)","0ca3d805":"model.save('model.h5')","b1e97b43":"y_pred = model.predict(test_set)","46d91bc7":"y_pred","2d1eda8f":"y_pred = np.argmax(y_pred,axis=1)\ny_pred","9d55d0bd":"model=load_model('model.h5')\nimg=image.load_img('..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10875.jpg',target_size=(150,150))\nx=image.img_to_array(img)\nx=np.expand_dims(x,axis=0)\n#img_data=preprocess_input(x)\n#img_data.shape\nmodel.predict(x)\na=np.argmax(model.predict(x), axis=1)\nif a == 0:\n    print(\"buildings\")\nelif a == 1:\n    print(\"forest\")\nelif a == 2:\n    print(\"glacier\")\nelif a == 3:\n    print(\"moutain\")\nelif a == 4:\n    print(\"sea\")\nelse:\n    print(\"street\")","292a39a6":"\nfrom tensorflow.keras.applications.vgg16 import VGG16\n","bb084ffb":"\n# re-size all the images to this\nIMAGE_SIZE = [224, 224]","bd2fffd3":"\nvgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\nfor layer in vgg16.layers:\n    layer.trainable = False","89c9a7c9":"# useful for getting number of output classes\nfolders = glob('..\/input\/intel-image-classification\/seg_train\/seg_train\/*')\nfolders","9a4374c6":"# our layers - you can add more if you want\nx = Flatten()(vgg16.output)\n\nprediction = Dense(len(folders), activation='softmax')(x)\n\n# create a model object\nmodel_vgg16 = Model(inputs=vgg16.input, outputs=prediction)\nmodel_vgg16.summary()","663cf5c7":"model_vgg16.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","52c5df8b":"train_datagen_vgg16 = ImageDataGenerator(rescale = 1.\/255)\n\ntest_datagen_vgg16 = ImageDataGenerator(rescale = 1.\/255)\n\ntraining_set_vgg16 = train_datagen_vgg16.flow_from_directory('..\/input\/intel-image-classification\/seg_train\/seg_train',\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')\n\ntest_set_vgg16 = train_datagen_vgg16.flow_from_directory('..\/input\/intel-image-classification\/seg_test\/seg_test',\n                                                 target_size = (244, 244),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')","764b9f3c":"model_vgg16_fit = model_vgg16.fit_generator(\n  training_set_vgg16,\n  validation_data=test_set_vgg16,\n  epochs=5,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)","d8ee1093":"from tensorflow.keras.models import load_model\n\nmodel_vgg16.save('model_vgg16.h5')","a18f693c":"y_pred = model_vgg16.predict(test_set_vgg16)\ny_pred = np.argmax(y_pred, axis=1)\ny_pred","edbd90f3":"model=load_model('model_vgg16.h5')\nimg=image.load_img('..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10875.jpg',target_size=(224,224))\nx=image.img_to_array(img)\nx=np.expand_dims(x,axis=0)\n#img_data=preprocess_input(x)\n#img_data.shape\nmodel.predict(x)\na=np.argmax(model.predict(x), axis=1)\nif a == 0:\n    print(\"buildings\")\nelif a == 1:\n    print(\"forest\")\nelif a == 2:\n    print(\"glacier\")\nelif a == 3:\n    print(\"moutain\")\nelif a == 4:\n    print(\"sea\")\nelse:\n    print(\"street\")","b092c4df":"#  #VGG19 \n","15e7ca95":"# CNN model "}}