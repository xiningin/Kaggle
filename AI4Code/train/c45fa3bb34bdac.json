{"cell_type":{"59087c59":"code","24d93077":"code","e0a8ac43":"code","85fa1d45":"code","a6954543":"code","5b8c3212":"code","c9c7b9af":"code","93535469":"code","23649967":"code","1270d750":"code","3298e8f9":"code","88fc34dc":"code","a0ce42f8":"code","3089e218":"code","50fbec93":"code","fb857aac":"code","42239471":"code","1cc8257d":"code","a76f4996":"code","20a8dc31":"markdown","31334a1a":"markdown","02482aea":"markdown","f7f0ff50":"markdown","77d12000":"markdown","a17a6065":"markdown","be055445":"markdown","38254d48":"markdown","32d08092":"markdown","b1acbe34":"markdown","21fffb73":"markdown","4f4b6a0c":"markdown","beec500b":"markdown","ab4c13ae":"markdown","7f42442a":"markdown","4be29779":"markdown","8872f5cd":"markdown"},"source":{"59087c59":"\nimport numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","24d93077":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split","e0a8ac43":"data = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\n\ntst = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\n\nprint(data.columns.values)","85fa1d45":"data['keyword'].value_counts()[0:15]","a6954543":"data['location'].value_counts()[0:15]","5b8c3212":"data['text'][0:5]","c9c7b9af":"vocab_size = 10000\nembedding_dim = 16\nmax_length = 100\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"\ntraining_size = 20000\n","93535469":"sentences = data['text']\ntarget = data['target']\n\nX_train, X_test, y_train, y_test = train_test_split(sentences, target, random_state=3, test_size=0.2)","23649967":"tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n\ntokenizer.fit_on_texts(X_train)\n\ntext_index = tokenizer.word_index\n\ndata_sequences = tokenizer.texts_to_sequences(X_train)\n\ndata_padded = pad_sequences(data_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\ntest_sequences = tokenizer.texts_to_sequences(X_test)\n\ntest_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\ntst_sequences = tokenizer.texts_to_sequences(tst[\"text\"])\n\ntst_padded = pad_sequences(tst_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\nprint(test_padded[0])","1270d750":"training_data = np.array(data_padded)\n\ntraining_labels = np.array(y_train)\n\neval_data = np.array(test_padded)\n\neval_labels = np.array(y_test)\n\ntst_data = tst_padded\n\ntst_labels = np.array(tst[\"id\"])\n                ","3298e8f9":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","88fc34dc":"model.summary()\n","a0ce42f8":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","3089e218":"lrr = ReduceLROnPlateau(monitor='val_loss',patience=3,verbose=1,factor=0.5, min_lr=0.00001)","50fbec93":"num_epochs = 30\nhist = model.fit(training_data, training_labels, epochs=num_epochs, validation_data=(eval_data, eval_labels), verbose=2,\ncallbacks=[early_stopping, lrr])","fb857aac":"test_loss, test_acc = model.evaluate(eval_data, eval_labels)","42239471":"def plot_loss_and_accuracy(history):\n    history_df = pd.DataFrame(history)\n    history_df.loc[0:, ['loss', 'val_loss']].plot()\n    history_df.loc[0:, ['accuracy', 'val_accuracy']].plot()\n\nplot_loss_and_accuracy(hist.history)","1cc8257d":"predictions = model.predict(tst_data)\n\npredictions = np.around(predictions)\n\npredictions = predictions.astype(int)\n\n","a76f4996":"output = pd.DataFrame()\n\noutput[\"id\"] = tst[\"id\"]\n\noutput[\"target\"] = predictions\n\noutput.to_csv(\"my_submission.csv\", index=False)","20a8dc31":"# Building model","31334a1a":"model fitting","02482aea":"* Data prepation and cleaning(encoding)","f7f0ff50":"* Feature selection and data split into training and testing splits","77d12000":"* Making predictions","a17a6065":"Evaluating model","be055445":"Early stopping","38254d48":"visualization","32d08092":"* Import required libraries","b1acbe34":"Final Data preparation","21fffb73":"* Keywords","4f4b6a0c":"Reduce learning rate","beec500b":"* Location","ab4c13ae":"* Defining layers","7f42442a":"Model summary","4be29779":"* parameters","8872f5cd":"* Text"}}