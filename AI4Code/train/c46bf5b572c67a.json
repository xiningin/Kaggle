{"cell_type":{"d1b06a26":"code","f8ea090a":"code","2fbe117b":"code","73a8922f":"code","6fc0d90a":"code","fa4a8a2d":"code","be54b6ab":"code","73f1b48c":"code","851be840":"code","3116b472":"code","dae54040":"code","84fbc0a3":"code","032bcd38":"code","18107b7d":"code","2345ec8f":"code","0d445af2":"code","b2c2c291":"code","5eb52fed":"code","2c0e63fe":"code","e0ba4e83":"code","f94820f8":"code","d72d1dc5":"code","d46c6131":"code","b272d33f":"code","a88b63a2":"code","91374075":"code","680575d4":"code","7f73a0bc":"code","151936d5":"code","dc589433":"code","670a9eea":"code","195a43f8":"code","fd122bf4":"code","ecf42521":"code","4437d272":"code","b67803c4":"code","da569833":"code","52bd3321":"code","45686d8f":"code","52ec8e98":"code","0c31b9ae":"code","8c5a52b9":"markdown","2d1b9f4d":"markdown","1e48829a":"markdown","28695e2b":"markdown","1a407b13":"markdown","4fe0b368":"markdown","5df3901a":"markdown","6890606c":"markdown","a3c3a4ac":"markdown"},"source":{"d1b06a26":"# Librarys\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","f8ea090a":"# Data Load\ndata = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndata.shape","2fbe117b":"data.head()","73a8922f":"data.describe()","6fc0d90a":"data.info()","fa4a8a2d":"# Null count per column\ndata.isnull().sum()","be54b6ab":"# Explore the target: Survived\nsurvived_group = data.groupby([\"Survived\"]).size()\nsurvived_group.plot.bar(color='gray')","73f1b48c":"# Explore Age\nsns.histplot(x=\"Age\", data=data)","851be840":"# The sex distribuition\nsex_group = data.groupby([\"Sex\"]).size()\nsex_group.plot.bar(color='gray')","3116b472":"# Number of siblings\nsib_group = data.groupby([\"SibSp\"]).size()\nsib_group.plot.bar(color=\"gray\")","dae54040":"# Number of family relations in this way\nparch_group = data.groupby([\"Parch\"]).size()\nparch_group.plot.bar(color=\"gray\")","84fbc0a3":"embarked_group = data.groupby([\"Embarked\"]).size()\nembarked_group.plot.bar(color=\"gray\")","032bcd38":"# Passenger fare\nsns.boxplot(x=\"Fare\", data=data)","18107b7d":"# Age\nage_median = np.nanmedian(data[\"Age\"])\ndata[\"Age\"].fillna(age_median, inplace=True)\ndata[\"Age\"].isnull().sum()","2345ec8f":"# Replace Age for Age Categorie\ndef modifie_age(dataset):\n    age = []\n    for i in dataset.index:\n        if dataset[\"Age\"].loc[i] > 0 and dataset[\"Age\"].loc[i] <= 10:\n            age.append(\"Kid\")\n        elif dataset[\"Age\"].loc[i] > 10 and dataset[\"Age\"].loc[i] < 21:\n            age.append(\"Teen\")\n        elif dataset[\"Age\"].loc[i] >= 21 and dataset[\"Age\"].loc[i] < 60:\n            age.append(\"Aduld\")\n        elif dataset[\"Age\"].loc[i] >= 60:\n            age.append(\"Senior\")\n    return age","0d445af2":"data.Age = modifie_age(data)","b2c2c291":"# Cabin\ndata = data.drop(columns=[\"Cabin\"])","5eb52fed":"# Embarked\ndata[\"Embarked\"].fillna(\"S\", inplace=True)\ndata[\"Embarked\"].isnull().sum()","2c0e63fe":"# Null count\ndata.isnull().sum()","e0ba4e83":"# Separate Survived from database and creates copy\ntarget = data[\"Survived\"]\ndata.drop(\"Survived\", axis=1, inplace=True)\ndata_main = data.copy()\ndata_w_family = data.copy()\ndata_w_embarked = data.copy()","f94820f8":"# Drop columns considered useless\ndata_main.drop([\"Name\", \"PassengerId\", \"Ticket\", \"Embarked\", \"SibSp\", \"Parch\"], axis=1, inplace=True)\ndata_w_family.drop([\"Name\", \"PassengerId\", \"Ticket\", \"Embarked\"], axis=1, inplace=True)\ndata_w_embarked.drop([\"Name\", \"PassengerId\", \"Ticket\", \"SibSp\", \"Parch\"], axis=1, inplace=True)","d72d1dc5":"# Get Dummies\ndata_main = pd.get_dummies(data_main)\ndata_w_family = pd.get_dummies(data_w_family)\ndata_w_embarked = pd.get_dummies(data_w_embarked)","d46c6131":"# Split train and test\nx_main_train, x_main_test, y_main_train, y_main_test = train_test_split(data_main, target, test_size=0.2)\nx_family_train, x_family_test, y_family_train, y_family_test = train_test_split(data_w_family, target, test_size=0.2)\nx_embarked_train, x_embarked_test, y_embarked_train, y_embarked_test = train_test_split(data_w_embarked, target, test_size=0.2)","b272d33f":"# Create the models - Logistic Regression\nmain_logistic = LogisticRegression(solver='liblinear')\nfamily_logistic = LogisticRegression(solver='liblinear')\nembarked_logistic = LogisticRegression(solver='liblinear')","a88b63a2":"# Create the models - Decision Tree\nmain_tree = DecisionTreeClassifier(max_depth=3)\nfamily_tree = DecisionTreeClassifier(max_depth=3)\nembarked_tree = DecisionTreeClassifier(max_depth=3)","91374075":"# Train decision tree models\nmain_tree.fit(x_main_train, y_main_train)\nfamily_tree.fit(x_family_train, y_family_train)\nembarked_tree.fit(x_embarked_train, y_embarked_train)","680575d4":"# Predict with decision tree models\nmain_predict = main_tree.predict(x_main_test)\nfamily_predict = family_tree.predict(x_family_test)\nembarked_predict = embarked_tree.predict(x_embarked_test)","7f73a0bc":"# Logistic model\nmain_acc = cross_val_score(main_logistic, x_main_train, y_main_train, cv=5)\nfamily_acc = cross_val_score(family_logistic, x_family_train, y_family_train, cv=5)\nembarked_acc = cross_val_score(embarked_logistic, x_embarked_train, y_embarked_train, cv=5)","151936d5":"print(\"Main: \", np.mean(main_acc)*100)\nprint(\"Family: \", np.mean(family_acc)*100)\nprint(\"Embarked: \", np.mean(embarked_acc)*100)","dc589433":"# Decision Tree model\nmain_decision = cross_val_score(main_tree, x_main_train, y_main_train, cv=5)\nfamily_decision = cross_val_score(family_tree, x_family_train, y_family_train, cv=5)\nembarked_decision = cross_val_score(embarked_tree, x_embarked_train, y_embarked_train, cv=5)","670a9eea":"print(\"Main: \", np.mean(main_decision)*100)\nprint(\"Family: \", np.mean(family_decision)*100)\nprint(\"Embarked: \", np.mean(embarked_decision)*100)","195a43f8":"# Accuracy Score\nmain_accuracy = accuracy_score(y_main_test, main_predict) * 100\nfamily_accuracy = accuracy_score(y_family_test, family_predict) * 100\nembarked_accuracy = accuracy_score(y_embarked_test, embarked_predict) * 100","fd122bf4":"print(\"Main: \", main_accuracy)\nprint(\"Family: \", family_accuracy)\nprint(\"Embarked: \", embarked_accuracy)","ecf42521":"# Test dataframe\ndata_test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ndata_test.shape","4437d272":"data_test.info()","b67803c4":"# Quick Data Processing \ndata_test.drop([\"Name\", \"PassengerId\", \"Ticket\", \"Embarked\", \"Cabin\"], axis=1, inplace=True)\n\ntest_median = np.nanmedian(data_test[\"Age\"])\ndata_test[\"Age\"].fillna(test_median, inplace=True)\ndata_test.Age = modifie_age(data_test)\n\nfare_median = np.nanmedian(data_test[\"Fare\"])\ndata_test[\"Fare\"].fillna(fare_median, inplace=True)","da569833":"data_test.info()","52bd3321":"# Get dummies to exchange categorical for numeric\ndata_test = pd.get_dummies(data_test)","45686d8f":"# Creates Prediction\nsubmission_predict = family_tree.predict(data_test)\nsubmission_predict[0:5]","52ec8e98":"# Read submission model\nsubmission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsubmission.shape","0c31b9ae":"# Creates submission model with prediction\nsubmission.Survived = submission_predict\nsubmission.to_csv(\".\/submission.csv\", index=False)\nsubmission.head()","8c5a52b9":"### Data Processing","2d1b9f4d":"### Evaluate the model\nEvaluate the models with their accuracy and cross validation score.","1e48829a":"<p>\n    Decision Tree achieved better accuracy and Cross Validation Score in relation to Logistic Regression algorithm.\n<\/p>    \n<p> \n   The three types of models are precisely similar on average.\n<\/p>","28695e2b":"### Machine Learning\nIn this session i will use two algorithms: Logistic Regression and Decision Tree, for classification.","1a407b13":"### Conclusion","4fe0b368":"### Prepare dataset for machine learning","5df3901a":"### Data Exploration","6890606c":"### Submission","a3c3a4ac":"## Titanic Competition - Kaggle\n\nThe propouse of this notebook is study the titanic dataset and create a Machine Learning model to predict survivors on titanic."}}