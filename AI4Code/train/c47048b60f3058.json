{"cell_type":{"dce4d89d":"code","e266598f":"code","f7cd1fdd":"code","87a10d07":"code","5c9dd353":"code","ccf114e0":"code","9b761a98":"code","62438bb0":"code","73f0c681":"markdown","21aba13f":"markdown","0a0ee70e":"markdown","2099b033":"markdown","8a61aba8":"markdown"},"source":{"dce4d89d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e266598f":"def read_data(path,label_name):\n    data=pd.read_csv(path)\n    label=data[label_name]\n    data=data.drop(label_name,axis=1)\n    test_data=data[:100]\n    test_label=label[:100]\n    data=data[100:]\n    label=label[100:]\n    return data,label,test_data,test_label","f7cd1fdd":"from sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\ndata,label,test_data,test_label=read_data('..\/input\/oranges-vs-grapefruit\/citrus.csv','name')\nmodel.fit(data,label)\npred=model.predict(data)\nprint(\"Accuracy : \"+str(accuracy_score(label,pred)))\nplt.plot(data[['red','green','blue']],pred)\nplt.scatter(data['red'],pred)\nplt.scatter(data['green'],pred)\nplt.scatter(data['blue'],pred)\nplt.xlabel('Color Codes')\nplt.ylabel('Fruit')\nplt.legend(['Red','Green','Blue'])","87a10d07":"from sklearn.linear_model import LinearRegression\nmodel=LinearRegression()\ndata,label,test_data,test_label=read_data('..\/input\/weight-and-heightcsv\/weight-height.csv','Weight')\ndata['Gender']=data['Gender'].replace({'Male':0,'Female':1})\ntest_data['Gender']=test_data['Gender'].replace({'Male':0,'Female':1})   #Changing string data to int type\nmodel.fit(data,label)\npred=model.predict(test_data)\nplt.plot(test_data['Height'],pred)\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.scatter(test_data['Height'],pred)","5c9dd353":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\ndata,label,test_data,test_label=read_data('..\/input\/oranges-vs-grapefruit\/citrus.csv','name')\nmodel.fit(data,label)\npred=model.predict(data)\nprint(\"Accuracy : \"+str(accuracy_score(label,pred)))\nplt.plot(data[['red','green','blue']],pred)\nplt.scatter(data['red'],pred)\nplt.scatter(data['green'],pred)\nplt.scatter(data['blue'],pred)\nplt.xlabel('Color Codes')\nplt.ylabel('Fruit')\nplt.legend(['Red','Green','Blue'])","ccf114e0":"from sklearn.tree import DecisionTreeRegressor\nmodel=DecisionTreeRegressor()\ndata,label,test_data,test_label=read_data('..\/input\/weight-and-heightcsv\/weight-height.csv','Weight')\ndata['Gender']=data['Gender'].replace({'Male':0,'Female':1})\ntest_data['Gender']=test_data['Gender'].replace({'Male':0,'Female':1})   #Changing string data to int type\nmodel.fit(data,label)\npred=model.predict(test_data)\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.plot(test_data['Height'][:10],pred[:10])\nplt.scatter(test_data['Height'][:10],pred[:10])","9b761a98":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(max_depth=2)\ndata,label,test_data,test_label=read_data('..\/input\/oranges-vs-grapefruit\/citrus.csv','name')\nmodel.fit(data,label)\npred=model.predict(data)\nprint(\"Accuracy : \"+str(accuracy_score(label,pred)))\nplt.plot(data[['red','green','blue']],pred)\nplt.scatter(data['red'],pred)\nplt.scatter(data['green'],pred)\nplt.scatter(data['blue'],pred)\nplt.xlabel('Color Codes')\nplt.ylabel('Fruit')\nplt.legend(['Red','Green','Blue'])","62438bb0":"from sklearn.ensemble import RandomForestRegressor\nmodel=RandomForestRegressor(max_depth=4,random_state=2)\ndata,label,test_data,test_label=read_data('..\/input\/weight-and-heightcsv\/weight-height.csv','Weight')\ndata['Gender']=data['Gender'].replace({'Male':0,'Female':1})\ntest_data['Gender']=test_data['Gender'].replace({'Male':0,'Female':1})   #Changing string data to int type\nmodel.fit(data,label)\npred=model.predict(test_data)\nplt.plot(test_data['Height'],pred)\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.scatter(test_data['Height'],pred)","73f0c681":"# LINEAR REGRESSION\nRegression analysis is a set of statistical processes for estimating the relationships between a dependent variable and one or more independent variables.\n![Linear Regression](https:\/\/miro.medium.com\/max\/640\/1*LEmBCYAttxS6uI6rEyPLMQ.png)","21aba13f":"# Reading data","0a0ee70e":"# DECISION TREE\n decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label\n![Decision Tree](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcSf6ZCldSJYqWkCm49qEKvSj1a90Pj8mFCG0NSI_lmIZU_GY7eD&usqp=CAU) ","2099b033":"# RANDOM FOREST\nA random forest is a meta estimator that contains a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n![Random Forest](https:\/\/miro.medium.com\/max\/1170\/1*58f1CZ8M4il0OZYg2oRN4w.png)","8a61aba8":"# LOGISTIC REGRESSION\nthe Logistic model is used to model the probability of a certain class or event existing such as pass\/fail, win\/lose, alive\/dead or healthy\/sick.  Logistic Regression is best suited for binary classification problem.  \n![Logistic Regression](https:\/\/miro.medium.com\/max\/2400\/1*RqXFpiNGwdiKBWyLJc_E7g.png)"}}