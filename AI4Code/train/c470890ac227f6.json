{"cell_type":{"605a6e7f":"code","4e8e4491":"code","1bd64dab":"code","e00586d8":"code","30d610b7":"code","f6ed958a":"code","d3537b01":"code","56c1ff3d":"code","a4ba59c8":"code","8a9e0c54":"code","4e5a5d6a":"code","78ab2e12":"code","6d5a656c":"code","522c5dd7":"code","145cd56d":"code","3a6c9d2d":"code","97b32f2e":"code","7a66f33f":"code","2344aac5":"code","42851859":"code","dd2f6c85":"code","cb124783":"code","68bbcb51":"code","cd0ec04d":"code","bd7763e6":"code","029204c0":"code","ef2ac5ad":"code","7a50c583":"code","a20c3743":"code","75323f27":"code","18b34782":"code","5498ad29":"code","254c9064":"markdown","d67c2d2c":"markdown","be611d0c":"markdown","f150d62a":"markdown","fad299d4":"markdown","ba34f3a9":"markdown","06ce3486":"markdown","cf32e577":"markdown","0507a80a":"markdown","aa9a8c54":"markdown","3c6f2761":"markdown","f2fbbabe":"markdown","d6ab0367":"markdown","3316a51a":"markdown","41904dd5":"markdown","d647b9d9":"markdown","b438722d":"markdown","97252f71":"markdown","7eab3f54":"markdown","b6f30d5d":"markdown"},"source":{"605a6e7f":"import pydot\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nsns.set()\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nimport datetime, os\n\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import export_graphviz, DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.exceptions import NotFittedError\nfrom sklearn.utils import shuffle\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import optimizers\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nfrom IPython.display import display\n%load_ext tensorboard.notebook","4e8e4491":"# Some useful functions we'll use in this notebook\ndef display_confusion_matrix(target, prediction, score=None):\n    cm = metrics.confusion_matrix(target, prediction)\n    plt.figure(figsize=(6,6))\n    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square=True, cmap='Blues_r')\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')\n    if score:\n        score_title = 'Accuracy Score: {0}'.format(round(score, 5))\n        plt.title(score_title, size = 14)\n    classification_report = pd.DataFrame.from_dict(metrics.classification_report(target, prediction, output_dict=True))\n    display(classification_report.round(2))\n\ndef draw_missing_data_table(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    return missing_data\n\ndef visualize_tree(tree, feature_names):\n    with open(\"dt.dot\", 'w') as f:\n        export_graphviz(tree, out_file=f, feature_names=feature_names)\n    try:\n        subprocess.check_call([\"dot\", \"-Tpng\", \"dt.dot\", \"-o\", \"dt.png\"])\n    except:\n        exit(\"Could not run dot, ie graphviz, to produce visualization\")","1bd64dab":"# Path of datasets\npath_train = '..\/input\/withnan\/equip_failures_training_set.csv'\npath_test = '..\/input\/withnan\/equip_failures_test_set.csv'","e00586d8":"# Create dataframe for training dataset and print five first rows as preview\ntrain_df_raw = pd.read_csv(path_train)\ntrain_df_raw.head()","30d610b7":"sns.countplot(train_df_raw['target'],label=\"Count\")","f6ed958a":"all_pos = train_df_raw.loc[train_df_raw['target'] == 1]\nnegative_sample = train_df_raw.loc[train_df_raw['target'] == 0]\nall_neg = train_df_raw.loc[train_df_raw['target'] == 0]\nchosen_idx = np.random.choice(59000, replace=False, size=8000)\nall_neg_trimmed = all_neg.iloc[chosen_idx]\nall_neg_trimmed.head()","d3537b01":"frames = [all_neg_trimmed, all_pos]\n\nresult = shuffle(pd.concat(frames))\nsns.countplot(result['target'],label=\"Count\")","56c1ff3d":"train_df_raw = result","a4ba59c8":"def preprocess_data(df):\n    \n    processed_df = df\n    processed_df.drop('id',axis=1)    \n    ########## Deal with missing values ##########\n    for col in processed_df.columns:\n        #print(col)    \n        processed_df[col] = processed_df[col].fillna(0)\n          \n    return processed_df","8a9e0c54":"# Let's divide the train dataset in two datasets to evaluate perfomance of the machine learning models we'll use\ntrain_df = train_df_raw.copy()\nX = train_df.drop(['target'], 1)\nY = train_df['target']\n\nX = preprocess_data(X)\n# We scale our data, it is essential for a smooth working of the models.\nsc = StandardScaler()\nX = pd.DataFrame(sc.fit_transform(X.values), index=X.index, columns=X.columns)\n    \n# Split dataset for model testing\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)","4e5a5d6a":"#Create and train model on train data sample\nlg = LogisticRegression(solver='lbfgs', random_state=42)\nlg.fit(X_train, Y_train)\n\n#Predict for test data sample\nlogistic_prediction = lg.predict(X_test)\n\n#Compute error between predicted data and true response and display it in confusion matrix\nscore = metrics.accuracy_score(Y_test, logistic_prediction)\ndisplay_confusion_matrix(Y_test, logistic_prediction, score=score)\nprint(score)\nscores = []\nscores.append(score)","78ab2e12":"dt = DecisionTreeClassifier(min_samples_split=15, min_samples_leaf=20, random_state=42)\ndt.fit(X_train, Y_train)\ndt_prediction = dt.predict(X_test)\n\nscore = metrics.accuracy_score(Y_test, dt_prediction)\ndisplay_confusion_matrix(Y_test, dt_prediction, score=score)\nprint(score)\nscores.append(score)\nprint(scores)","6d5a656c":"#visualize_tree(dt, X_test.columns)\n#! dot -Tpng dt.dot > dt.png","522c5dd7":"svm = SVC(gamma='auto', random_state=42)\nsvm.fit(X_train, Y_train)\nsvm_prediction = svm.predict(X_test)\n\nscore = metrics.accuracy_score(Y_test, svm_prediction)\ndisplay_confusion_matrix(Y_test, svm_prediction, score=score)\nprint(score)\nscores.append(score)\nprint(scores)","145cd56d":"rf = RandomForestClassifier(n_estimators=200, random_state=42)\nrf.fit(X_train, Y_train)\nrf_prediction = rf.predict(X_test)\n\nscore = metrics.accuracy_score(Y_test, rf_prediction)\ndisplay_confusion_matrix(Y_test, rf_prediction, score=score)\nprint(score)\nscores.append(score)\nprint(scores)","3a6c9d2d":"### **3.5 Artificial neural network**","97b32f2e":"def build_ann(optimizer='adam'):\n    \n    # Initializing our ANN\n    ann = Sequential()\n    \n    # Adding the input layer and the first hidden layer of our ANN with dropout\n    ann.add(Dense(units=32, kernel_initializer='glorot_uniform', activation='relu', input_shape=(171,)))\n    \n    # Add other layers, it is not necessary to pass the shape because there is a layer before\n    ann.add(Dense(units=128, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.3))\n    ann.add(Dense(units=128, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.3))\n    ann.add(Dense(units=128, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.3))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.3))\n    ann.add(Dense(units=64, kernel_initializer='glorot_uniform', activation='relu'))\n    ann.add(Dropout(rate=0.3))\n    # Adding the output layer\n    ann.add(Dense(units=1, kernel_initializer='glorot_uniform', activation='sigmoid'))\n    \n    # Compiling the ANN\n    ann.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return ann","7a66f33f":"opt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\n# Training the ANN\nhistory = ann.fit(X_train, Y_train, batch_size=16, epochs=30, validation_data=(X_test, Y_test))","2344aac5":"#Predicting the Test set results\nann_prediction = ann.predict(X_test)\nann_prediction = (ann_prediction > 0.5) # convert probabilities to binary output\nann_prediction = ann_prediction.astype(int)\n#Compute error between predicted data and true response and display it in confusion matrix\nscore = metrics.accuracy_score(Y_test, ann_prediction)\ndisplay_confusion_matrix(Y_test, ann_prediction, score=score)\nprint(score)\nscores.append(score)\nprint(scores)","42851859":"ann_prediction","dd2f6c85":"n_folds = 10\ncv_score_lg = cross_val_score(estimator=lg, X=X_train, y=Y_train, cv=n_folds, n_jobs=-1)\ncv_score_dt = cross_val_score(estimator=dt, X=X_train, y=Y_train, cv=n_folds, n_jobs=-1)\ncv_score_svm = cross_val_score(estimator=svm, X=X_train, y=Y_train, cv=n_folds, n_jobs=-1)\ncv_score_rf = cross_val_score(estimator=rf, X=X_train, y=Y_train, cv=n_folds, n_jobs=-1)\ncv_score_ann = cross_val_score(estimator=KerasClassifier(build_fn=build_ann, batch_size=16, epochs=20, verbose=0),\n                                 X=X_train, y=Y_train, cv=n_folds, n_jobs=-1)","cb124783":"cv_result = {'lg': cv_score_lg, 'dt': cv_score_dt, 'svm': cv_score_svm, 'rf': cv_score_rf, 'ann': cv_score_ann}\ncv_data = {model: [score.mean(), score.std()] for model, score in cv_result.items()}\ncv_df = pd.DataFrame(cv_data, index=['Mean_accuracy', 'Variance'])\ncv_df","68bbcb51":"plt.figure(figsize=(20,8))\nplt.plot(cv_result['lg'])\nplt.plot(cv_result['dt'])\nplt.plot(cv_result['svm'])\nplt.plot(cv_result['rf'])\nplt.plot(cv_result['ann'])\nplt.title('Models Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Trained fold')\nplt.xticks([k for k in range(n_folds)])\nplt.legend(['logreg', 'tree', 'randomforest', 'ann', 'svm'], loc='upper left')\nplt.show()","cd0ec04d":"class EsemblingClassifier:\n    \n    def __init__(self, verbose=True):\n        self.ann = build_ann(optimizer=optimizers.Adam(lr=0.001))\n        self.rf = RandomForestClassifier(n_estimators=300, max_depth=11, random_state=42)\n        self.svm = SVC(random_state=42)\n        self.trained = False\n        self.verbose = verbose\n        \n    def fit(self, X, y):\n        if self.verbose:\n            print('-------- Fitting models --------')\n        self.ann.fit(X, y, epochs=30, batch_size=16, verbose=0)\n        self.rf.fit(X, y)\n        self.svm.fit(X, y)\n        self.trained = True\n    \n    def predict(self, X):\n        if self.trained == False:\n            raise NotFittedError('Please train the classifier before making a prediction')\n        if self.verbose:\n            print('-------- Making and combining predictions --------')\n        predictions = list()\n        pred_ann = self.ann.predict(X)\n        pred_ann = (pred_ann > 0.5)*1\n        pred_rf = self.rf.predict(X)\n        pred_svm = self.svm.predict(X)\n        for n in range(len(pred_ann)):\n            combined = pred_ann[n] + pred_rf[n] + pred_svm[n]\n            p = 0 if combined == 1 or combined == 0 else 1\n            predictions.append(p)\n        return predictions","bd7763e6":"ens = EsemblingClassifier()\nens.fit(X_train, Y_train)\nens_prediction = ens.predict(X_test)\nscore = metrics.accuracy_score(Y_test, ens_prediction)\ndisplay_confusion_matrix(Y_test, ens_prediction, score=score)\n\nscore","029204c0":"test_df_raw = pd.read_csv(path_test)\ntest = test_df_raw.copy()\ntest = preprocess_data(test)\ntest = pd.DataFrame(sc.fit_transform(test.values), index=test.index, columns=test.columns)\ntest.head()","ef2ac5ad":"# Create and train model on train data sample\nmodel_test = EsemblingClassifier()\nmodel_test.fit(X, Y)\n\n# Predict for test data sample\nprediction = model_test.predict(test)\n\nresult_df = test_df_raw.copy()\nresult_df['target'] = prediction\nresult_df.to_csv('submissionEsemble.csv', columns=['id', 'target'], index=False)","7a50c583":"# Create and train model on train data sample\nlg = LogisticRegression(solver='lbfgs', random_state=42)\nlg.fit(X, Y)\n\n# Predict for test data sample\nlogistic_prediction = lg.predict(test)\n\nresult_df = test_df_raw.copy()\nresult_df['target'] = logistic_prediction\nresult_df.to_csv('submissionLogReg.csv', columns=['id', 'target'], index=False)\n# Compute error between predicted data and true response and display it in confusion matrix\n#score = metrics.accuracy_score(Y_test, logistic_prediction)\n#display_confusion_matrix(Y_test, logistic_prediction, score=score)","a20c3743":"dt = DecisionTreeClassifier(min_samples_split=15, min_samples_leaf=20, random_state=42)\ndt.fit(X, Y)\ndt_prediction = dt.predict(test)\n\nresult_df = test_df_raw.copy()\nresult_df['target'] = dt_prediction\nresult_df.to_csv('submissionDecisionTree.csv', columns=['id', 'target'], index=False)","75323f27":"rf = RandomForestClassifier(n_estimators=200, random_state=42)\nrf.fit(X, Y)\nrf_prediction = rf.predict(test)\n\nresult_df = test_df_raw.copy()\nresult_df['target'] = rf_prediction\nresult_df.to_csv('submissionRF.csv', columns=['id', 'target'], index=False)","18b34782":"svm = SVC(gamma='auto', random_state=42)\nsvm.fit(X, Y)\nsvm_prediction = svm.predict(test)\n\nresult_df = test_df_raw.copy()\nresult_df['target'] = rf_prediction\nresult_df.to_csv('submissionSVC.csv', columns=['id', 'target'], index=False)","5498ad29":"opt = optimizers.Adam(lr=0.001)\nann = build_ann(opt)\n# Training the ANN\nhistory = ann.fit(X_test, Y_test, batch_size=16, epochs=30, validation_data=(X_test, Y_test))\n# Predicting the Test set results\nann_prediction = ann.predict(test)\nann_prediction = (ann_prediction > 0.5) # convert probabilities to binary output\nresult_df = test_df_raw.copy()\nresult_df['target'] = ann_prediction.astype(int)\nresult_df.to_csv('submissionANN.csv', columns=['id', 'target'], index=False)","254c9064":"### **3.3 SVM**","d67c2d2c":"## **5. Ensembling: creating a homemade classifier** <a id=\"ensembling\"><\/a>","be611d0c":"### **3.1 Logistic regression**","f150d62a":"Lets load and process the test set","fad299d4":"Im going to create a submission file for ensemble and one of each method to submit. Since we get 20 submissions a day.   ","ba34f3a9":"### **3.4 Random forest**","06ce3486":"* ## **2. Data Cleanup** <a id=\"fe\"><\/a>","cf32e577":"Note: When I downloaded the files, I  did a find\/replace for 'na' and changed it to NaN.  This was so it would be interpreted as ints or floats and not all string columns in Pandas","0507a80a":"### **3.2 Decision tree**","aa9a8c54":"Split data and run it through preprocess, and normalize","3c6f2761":"I chose arbitrarily  8:1 negative samples to positive samples. I may explore different splits later and see if that imporoves my scores.\n\nI concatenated the data, and shuffled it up. Now lets see what the ratio looksl like","f2fbbabe":"Helper functions that are usefull: ","d6ab0367":"Reference notebook:   I followed a guide built on the Titanic dataset.  Some of the code is borrowed and reused.   https:\/\/www.kaggle.com\/nhlr21\/complete-titanic-tutorial-with-ml-nn-ensembling","3316a51a":"Cross Validation attempt to choose between models","41904dd5":"Im going to take a very simple approach to data cleanup.  Looking through there are lots and lots of colulmns with massive amounts of NaN and 0s.   I'm just going to start by setting all NaNs to 0 for now, and come back to this if I dont get anywhere. ","d647b9d9":"From first inspection, lots of columns.  Lots of zero values, and lots of NaN\n\nI want to determine how many positive and negative examples we have. ","b438722d":"Okay lets apply some basic ML techniques","97252f71":"**Predictive Maintenance Notebook, with several basic ML techniques, a NN implementation and an attempt at ensembeling**\n\nCorey Vessar Corporate Analytics Analyst\n\n*Loading the data*","7eab3f54":"## **1. Data exploration** <a id=\"data_exploration\"><\/a>","b6f30d5d":"Out of 60k rows only 1000 are positive examples.  We will have to cut down and make it closer\n\nLets seperate the 0 targets from the 1 targets, then Ill just randomly sample the 0s to build a smaller training. "}}