{"cell_type":{"0de49f34":"code","91f4e129":"code","614a14ff":"code","eb57eb99":"code","690378aa":"code","1dad4c35":"code","7565cb00":"code","8f715685":"code","3bbff9df":"code","a327cdc0":"code","ae94991c":"code","cfe18fec":"code","00c8497f":"code","58b59112":"code","64151969":"code","6c11ac32":"code","539ec542":"code","8cb41b74":"code","8b8453c0":"code","5cc67962":"code","31775f77":"code","a82f4016":"code","cbdc1951":"code","02523c46":"code","5b4d6b55":"code","fb0aa5d0":"code","0727931d":"code","106a2598":"code","733819be":"code","d4ea886b":"code","b9993ca4":"code","b0f277ba":"code","ddbc7589":"code","2da2470f":"code","c2ed99e8":"code","2d367dd8":"code","4b607708":"code","73f49887":"code","f23315d6":"code","6199fbed":"code","5c30dddc":"code","2019cc26":"code","73ac1f7f":"code","73584b2b":"code","c9b71bed":"code","0422eadf":"code","a3e055a8":"code","e87d1a9a":"markdown","eac32953":"markdown","ceb35c04":"markdown","6ce44502":"markdown","6bab6932":"markdown","cbc3cb59":"markdown","28051304":"markdown","b1981efb":"markdown","623d4f3a":"markdown","8740d16d":"markdown","90c66467":"markdown","9ffee96d":"markdown","07c2fd0b":"markdown"},"source":{"0de49f34":"# Install packages\n# !pip install boostaroota","91f4e129":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\npyo.init_notebook_mode() # Set notebook mode to work in offline\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nfrom sklearn import model_selection as sk_model_selection\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\nfrom sklearn import metrics\nimport optuna\n# from boostaroota import BoostARoota\nfrom sklearn.metrics import log_loss\nfrom optuna.samplers import TPESampler\nimport functools\nfrom functools import partial\nimport xgboost as xgb\nimport joblib\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport warnings \nwarnings.filterwarnings('ignore')\nimport torch.optim as optim\nimport time\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import RobustScaler, normalize\nimport gc\n\nSEED = 42","614a14ff":"train_data = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\nsample_submission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\ntest_data = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')","eb57eb99":"# u_in - 0 is completely closed and no air is let in and 100 is completely open\n# u_out - the exploratory valve is open (1) or closed (0) to let air out.\nprint(train_data.shape)\ntrain_data.head()","690378aa":"print('# Breath IDs in train data:', train_data['breath_id'].nunique())\ntrain_data[train_data['breath_id']==1]","1dad4c35":"print(train_data['breath_id'].nunique())\ntrain_data[train_data['breath_id']==2]","7565cb00":"print(train_data['breath_id'].nunique())\ntrain_data[train_data['breath_id']==3]","8f715685":"temp = train_data.groupby(['breath_id']).agg({'R':'nunique','C':'nunique'}).reset_index()\nprint('# Breath ids with >1 R or >1 C:', temp[(temp['R']>1) | (temp['C']>1)].shape[0])\ntemp.head()","3bbff9df":"train_data['R'].unique(), train_data['C'].unique()","a327cdc0":"temp = train_data.groupby(['breath_id']).size().reset_index().rename(columns = {0:'# Entries'})\nprint(temp['# Entries'].unique())\ntemp","ae94991c":"print(train_data['id'].nunique(), train_data.shape)\ntrain_data[train_data['id']==1]","cfe18fec":"train_data.describe()","00c8497f":"print(sample_submission.shape)\nsample_submission.head()","58b59112":"print(test_data.shape)\nprint('# Breath IDs in test data:', test_data['breath_id'].nunique())\ntest_data.head()","64151969":"temp = test_data.groupby(['breath_id']).agg({'R':'nunique','C':'nunique'}).reset_index()\nprint('# Breath ids with >1 R or >1 C:', temp[(temp['R']>1) | (temp['C']>1)].shape[0])\ntemp.head()","6c11ac32":"test_data['R'].unique(), test_data['C'].unique()","539ec542":"temp = test_data.groupby(['breath_id']).size().reset_index().rename(columns = {0:'# Entries'})\nprint(temp['# Entries'].unique())\ntemp","8cb41b74":"def interactive_line_chart(Breath_ID):\n    # Create traces\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(y=train_data[train_data['breath_id']==Breath_ID][\"pressure\"], \n                             x = train_data[train_data['breath_id']==Breath_ID]['time_step'],\n                        mode='lines',\n                        name='pressure'))\n    fig.add_trace(go.Scatter(y=train_data[train_data['breath_id']==Breath_ID][\"u_in\"], \n                             x = train_data[train_data['breath_id']==Breath_ID]['time_step'],\n                        mode='lines',\n                        name='u_in'))\n    fig.add_trace(go.Scatter(y=train_data[train_data['breath_id']==Breath_ID][\"u_out\"], \n                             x = train_data[train_data['breath_id']==Breath_ID]['time_step'],\n                        mode='lines',\n                        name='u_out'))\n\n    # Edit the layout\n    fig.update_layout(title='Variation by time step',\n                       xaxis_title='Time step',\n                       yaxis_title='Value')\n    fig.show()\n    \nw = widgets.interactive(interactive_line_chart, Breath_ID = train_data['breath_id'].unique().tolist())\ndisplay(w)","8b8453c0":"fig = px.histogram(train_data.groupby(['breath_id']).agg({'pressure':'mean'}).reset_index(), x=\"pressure\", nbins=20)\nfig.show()","5cc67962":"all_pressure = np.sort(train_data.pressure.unique())\nPRESSURE_MIN = all_pressure[0].item()\nPRESSURE_MAX = all_pressure[-1].item()\nPRESSURE_STEP = ( all_pressure[1] - all_pressure[0] ).item()","31775f77":"# Splitting into train and validation datasets\nbreath_id_list = train_data['breath_id'].unique().tolist()\ndf_train, df_valid = sk_model_selection.train_test_split(\n    breath_id_list, \n    test_size=0.2, \n    random_state=SEED)\n\ndf_train = train_data[train_data['breath_id'].isin(df_train)].reset_index(drop = True)\ndf_valid = train_data[train_data['breath_id'].isin(df_valid)].reset_index(drop = True)","a82f4016":"scaler = MinMaxScaler()\nscaler.fit(df_train[['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']])","cbdc1951":"# From https:\/\/www.kaggle.com\/dlaststark\/gb-vpp-pulp-fiction\ndef add_features(df):\n    df['cross']= df['u_in'] * df['u_out']\n    df['cross2']= df['time_step'] * df['u_out']\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    print(\"Step-1...Completed\")\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    print(\"Step-2...Completed\")\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    print(\"Step-3...Completed\")\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    print(\"Step-4...Completed\")\n    \n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    df['u_in_cummean'] =df['u_in_cumsum'] \/df['count']\n    \n    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n    print(\"Step-5...Completed\")\n    \n    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n    df['ewm_u_in_mean'] = (df\\\n                           .groupby('breath_id')['u_in']\\\n                           .ewm(halflife=9)\\\n                           .mean()\\\n                           .reset_index(level=0,drop=True))\n    df[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\"]] = (df\\\n                                                              .groupby('breath_id')['u_in']\\\n                                                              .rolling(window=15,min_periods=1)\\\n                                                              .agg({\"15_in_sum\":\"sum\",\n                                                                    \"15_in_min\":\"min\",\n                                                                    \"15_in_max\":\"max\",\n                                                                    \"15_in_mean\":\"mean\"})\\\n                                                               .reset_index(level=0,drop=True))\n    print(\"Step-6...Completed\")\n    \n    df['u_in_lagback_diff1'] = df['u_in'] - df['u_in_lag_back1']\n    df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n    df['u_in_lagback_diff2'] = df['u_in'] - df['u_in_lag_back2']\n    df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n    print(\"Step-7...Completed\")\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    print(\"Step-8...Completed\")\n    \n    return df\n\n\n# print(\"Train data...\\n\")\n# train = add_features(train_data)\n\n# print(\"\\nTest data...\\n\")\n# test = add_features(test_data)\n\n# del train_data\n# del test_data\n# gc.collect()","02523c46":"# targets = train[['pressure']].to_numpy()\n\n# train.drop(['id','one','count','pressure',\n#             'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n#             'breath_id_lag2same'], axis=1, inplace=True)\n\n# test = test.drop(['id','one','count','breath_id_lag',\n#                   'breath_id_lag2','breath_id_lagsame',\n#                   'breath_id_lag2same'], axis=1)\n\n# print(f\"train: {train.shape} \\ntest: {test.shape}\")\n\n# np.save('x_train.npy', train)\n# np.save('y_train.npy', targets)\n\n# np.save('x_test.npy', test)","5b4d6b55":"# train = np.load('..\/input\/ventilator_pressure_prediction_x_train\/x_train.npy')\n# targets = np.load('..\/input\/ventilator_pressure_prediction_y_train\/y_train.npy')\n# test = np.load('..\/input\/ventilator_pressure_prediction_x_test\/x_test.npy')\n\n# scaler = RobustScaler()\n\n# cols = [x for x in train.columns if x!='breath_id']\n# train = scaler.fit_transform(train)\n# test = scaler.transform(test)\n\n# print(f\"train: {train.shape} \\ntest: {test.shape} \\ntargets: {targets.shape}\")","fb0aa5d0":"# print(train.shape)\n# train[0][0].shape","0727931d":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, breath_id_list, train_flag):\n        self.breath_id_list = breath_id_list\n        self.train_flag = train_flag\n            \n    def __len__(self):\n        return len(self.breath_id_list)\n    \n    def __getitem__(self, index):\n        breath_id = self.breath_id_list[index]\n\n        formatted_train_data = pd.DataFrame(data = None)\n\n        if self.train_flag:\n            formatted_data = train_data[train_data['breath_id']==breath_id][['breath_id']].iloc[0:1,:].reset_index(drop = True)\n        else:\n            formatted_data = test_data[test_data['breath_id']==breath_id][['breath_id']].iloc[0:1,:].reset_index(drop = True)\n            formatted_data['pressure'] = 0\n            \n        for i in range(0, 80):\n            temp = formatted_data[formatted_data['breath_id']==breath_id][['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']].iloc[i:i+1,:].reset_index(drop = True)\n            temp = temp.sort_values(by = ['time_step'], ascending = True)\n            temp.columns = [temp.columns[j] + '_' + str(i+1) for j in range(0, len(temp.columns))]\n            formatted_data = pd.concat([formatted_data.reset_index(drop = True),temp.reset_index(drop = True)], axis = 1).reset_index(drop = True)\n            \n        formatted_train_data = pd.concat([formatted_train_data,formatted_data], axis = 0).reset_index(drop = True)\n#         cols = [x for x in formatted_train_data.columns if 'time_step_' in x] + [x for x in formatted_train_data.columns if 'R_' in x] + [x for x in formatted_train_data.columns if 'C_' in x] + [x for x in formatted_train_data.columns if 'u_in_' in x] + [x for x in formatted_train_data.columns if 'u_out_' in x]\n\n        X = torch.tensor(np.stack([formatted_train_data[[x for x in formatted_train_data.columns if 'time_step_' in x]].iloc[0], formatted_train_data[[x for x in formatted_train_data.columns if 'R_' in x]].iloc[0], formatted_train_data[[x for x in formatted_train_data.columns if 'C_' in x]].iloc[0], formatted_train_data[[x for x in formatted_train_data.columns if 'u_in_' in x]].iloc[0], formatted_train_data[[x for x in formatted_train_data.columns if 'u_out_' in x]].iloc[0]], axis = 1)).float()\n        \n        if (self.train_flag):\n            return {\"X\": X, \"y\": torch.tensor(formatted_train_data[[x for x in formatted_train_data.columns if 'pressure' in x]].iloc[0]).float()}\n        else:\n            return {\"X\": X, \"id\": breath_id}","106a2598":"class DataRetriever_LSTM(torch_data.Dataset):\n    def __init__(self, breath_id_list, train_flag):\n        self.breath_id_list = breath_id_list\n        self.train_flag = train_flag\n            \n    def __len__(self):\n        return len(self.breath_id_list)\n    \n    def __getitem__(self, index):\n        breath_id = self.breath_id_list[index]\n\n        if self.train_flag:\n            formatted_data = train_data[train_data['breath_id']==breath_id].sort_values(by = ['time_step'], ascending = True)[['breath_id','R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']].reset_index(drop = True)\n        else:\n            formatted_data = test_data[test_data['breath_id']==breath_id].sort_values(by = ['time_step'], ascending = True)[['breath_id','R', 'C', 'time_step', 'u_in', 'u_out']].reset_index(drop = True)\n            formatted_data['pressure'] = 0\n        \n        # Scaling\n        formatted_data = pd.DataFrame(scaler.transform(formatted_data[['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']])).reset_index(drop = True)\n        formatted_data.columns = ['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']\n        \n        X = torch.tensor(np.stack([formatted_data['time_step'], formatted_data['R'], formatted_data['C'], formatted_data['u_in'], formatted_data['u_out']], axis = 1)).float()\n        \n        if (self.train_flag):\n            return {\"X\": X, \"y\": torch.tensor(formatted_data['pressure']).float()}\n        else:\n            return {\"X\": X, \"id\": breath_id}","733819be":"formatted_train_data = pd.DataFrame(data = None)\nbreath_id_list = train_data['breath_id'].unique().tolist()[:10]\n\nfor breath_id in tqdm(breath_id_list):\n    formatted_data = train_data[train_data['breath_id']==breath_id][['breath_id']].iloc[0:1,:].reset_index(drop = True)\n    for i in range(0, 80):\n        temp = train_data[train_data['breath_id']==breath_id][['R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']].iloc[i:i+1,:].reset_index(drop = True)\n        temp.columns = [temp.columns[j] + '_' + str(i+1) for j in range(0, len(temp.columns))]\n        formatted_data = pd.concat([formatted_data.reset_index(drop = True),temp.reset_index(drop = True)], axis = 1).reset_index(drop = True)\n    formatted_train_data = pd.concat([formatted_train_data,formatted_data], axis = 0).reset_index(drop = True)","d4ea886b":"formatted_train_data = formatted_train_data[[x for x in formatted_train_data.columns if 'pressure' not in x] + [x for x in formatted_train_data.columns if 'pressure' in x]]\nformatted_train_data.head()","b9993ca4":"# TBU","b0f277ba":"# TBU","ddbc7589":"class LSTMModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob, device):\n        super(LSTMModel, self).__init__()\n\n        self.device = device\n        # Defining the number of layers and the nodes in each layer\n        self.hidden_dim = hidden_dim\n        self.layer_dim = layer_dim\n\n        # LSTM layers\n        self.lstm = nn.LSTM(\n            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n        )\n        \n        # Fully connected layer\n        self.fc = nn.Linear(hidden_dim, output_dim)\n#         self.relu = nn.ReLU()\n\n    def forward(self, x):\n        # Initializing hidden state for first input with zeros\n        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n        h0.to(self.device)\n\n        # Initializing cell state for first input with zeros\n        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n        c0.to(self.device)\n        \n        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n        # If we don't, we'll backprop all the way to the start even after going through another batch\n        # Forward propagation by passing in the input, hidden state, and cell state into the model\n        out, (hn, cn) = self.lstm(x, (h0.detach().to(self.device), c0.detach().to(self.device)))\n\n        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n        # so that it can fit into the fully connected layer\n        out = out[:, -1, :]\n\n        # Convert the final state to our desired output shape (batch_size, output_dim)\n        out = self.fc(out)\n        \n#         out = self.relu(out)\n\n        return out","2da2470f":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n\n        self.best_valid_score = np.inf\n        self.n_patience = 0\n        self.lastmodel = None\n        \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        train_loss_list = []\n        val_loss_list = []\n        train_mae_list = []\n        val_mae_list = []\n        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_mae, train_mse, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_mae, valid_mse, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                \"[Epoch Train: {}] loss: {:.4f}, mae: {:.4f}, time: {:.4f} s            \",\n                n_epoch, train_loss, train_mae, train_time\n            )\n            \n            self.info_message(\n                \"[Epoch Valid: {}] loss: {:.4f}, mae: {:.4f}, time: {:.4f} s\",\n                n_epoch, valid_loss, valid_mae, valid_time\n            )\n\n            if self.best_valid_score > valid_loss: \n                self.info_message(\n                     \"Validation loss improved from {:.4f} to {:.4f}. Saved model to '{}'\", \n                    self.best_valid_score, valid_loss, self.lastmodel\n                )\n                self.best_valid_score = valid_loss\n                self.save_model(n_epoch, save_path, valid_loss)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            train_loss_list.append(train_loss)\n            val_loss_list.append(valid_loss)\n            train_mae_list.append(train_mae)\n            val_mae_list.append(valid_mae)\n            \n            if self.n_patience >= patience:\n                self.info_message(\"\\nValidation loss didn't improve last {} epochs.\", patience)\n                break\n                \n        return {'train_loss':train_loss_list, 'val_loss':val_loss_list, 'train_mae':train_mae_list, 'val_mae':val_mae_list,'n_epoch':n_epoch}\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        sum_loss = 0\n        runnning_mae = 0\n        runnning_mse = 0\n        \n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            \n            outputs = self.model(X)\n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            sum_loss += loss.detach().item()\n\n            self.optimizer.step()\n            \n            error = ((torch.abs(outputs - targets).sum(axis = 1)\/outputs.shape[1]).sum()\/outputs.shape[0]).data\n            squared_error = (((((outputs - targets)*(outputs - targets)).sum(axis = 1))\/outputs.shape[1]).sum()\/(outputs.shape[0])).data\n            (torch.abs(outputs - targets).sum(axis = 1)\/outputs.shape[1]).sum()\/outputs.shape[0]\n            runnning_mae += error\n            runnning_mse += squared_error\n            \n            message = 'Train Step {}\/{}, train_loss: {:.4f}, train_mae: {:.4f}'\n            self.info_message(message, step, len(train_loader), sum_loss\/step, runnning_mae\/step, end=\"\\r\")\n        \n        return sum_loss\/len(train_loader), runnning_mae\/len(train_loader), runnning_mse\/len(train_loader), int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        sum_loss = 0\n        runnning_mae = 0\n        runnning_mse = 0\n \n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X)\n                loss = self.criterion(outputs, targets)\n\n                sum_loss += loss.detach().item()\n#                 y_all.extend(batch[\"y\"].tolist())\n\n                error = ((torch.abs(outputs - targets).sum(axis = 1)\/outputs.shape[1]).sum()\/outputs.shape[0]).data\n                squared_error = (((((outputs - targets)*(outputs - targets)).sum(axis = 1))\/outputs.shape[1]).sum()\/(outputs.shape[0])).data\n                runnning_mae += error\n                runnning_mse += squared_error\n\n            message = 'Valid Step {}\/{}, valid_loss: {:.4f}, valid_mae: {:.4f}'\n            self.info_message(message, step, len(valid_loader), sum_loss\/step, runnning_mae\/step, end=\"\\r\")\n            \n        return sum_loss\/len(valid_loader), runnning_mae\/len(train_loader), runnning_mse\/len(train_loader), int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path, loss):\n        self.lastmodel = f\"{save_path}\"\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            self.lastmodel,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","c2ed99e8":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ninput_dim = 5\noutput_dim = 80\nhidden_dim = 128\nlayer_dim = 3\nbatch_size = 128\ndropout = 0.02\nn_epochs = 30\npatient_epochs = 20\nlearning_rate = 1e-3\nweight_decay = 1e-6\n\nmodel_params = {'input_dim': input_dim,\n                'hidden_dim' : hidden_dim,\n                'layer_dim' : layer_dim,\n                'output_dim' : output_dim,\n                'dropout_prob' : dropout,\n                'device' : device}\n\nmodel = LSTMModel(**model_params)\n\nmodel.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\ncriterion = nn.L1Loss(reduction='mean')\n\n# train_data_retriever = DataRetriever_LSTM(\n#     df_train[\"breath_id\"].unique().tolist(),\n#     train_flag = True)\n\n# train_loader = torch_data.DataLoader(\n#     train_data_retriever,\n#     batch_size=batch_size,\n#     shuffle=True,\n#     num_workers=8,\n# )\n\n# valid_data_retriever = DataRetriever_LSTM(\n#     df_valid[\"breath_id\"].unique().tolist(),\n#     train_flag = True)\n\n# valid_loader = torch_data.DataLoader(\n#     valid_data_retriever,\n#     batch_size=batch_size,\n#     shuffle=False,\n#     num_workers=8,\n# )\n\n# trainer = Trainer(\n#     model, \n#     device, \n#     optimizer, \n#     criterion\n# )\n\n# history = trainer.fit(\n#     n_epochs, \n#     train_loader,\n#     valid_loader, \n#     f\"lstm_model.pth\",\n#     patient_epochs,\n# )","2d367dd8":"# temp = pd.DataFrame(data = {'Train loss':history['train_loss'],'Validation loss':history['val_loss']}, columns = ['Train loss', 'Validation loss'])\n# temp['epoch'] = temp.index + 1\n\n# # Create traces\n# fig = go.Figure()\n# fig.add_trace(go.Scatter(y=temp[\"Train loss\"], \n#                          x = temp['epoch'],\n#                     mode='lines',\n#                     name='Train loss'))\n# fig.add_trace(go.Scatter(y=temp[\"Validation loss\"], \n#                          x = temp['epoch'],\n#                     mode='lines',\n#                     name='Validation loss'))\n# # Edit the layout\n# fig.update_layout(title='Model loss',\n#                    xaxis_title='Epoch',\n#                    yaxis_title='Loss')\n# fig.show()","4b607708":"# temp = pd.DataFrame(data = {'Train MAE':[x.cpu().numpy().item() for x in history['train_mae']],'Validation MAE':[x.cpu().numpy().item() for x in history['val_mae']]}, columns = ['Train MAE', 'Validation MAE'])\n# temp['epoch'] = temp.index + 1\n\n# # Create traces\n# fig = go.Figure()\n# fig.add_trace(go.Scatter(y=temp[\"Train MAE\"], \n#                          x = temp['epoch'],\n#                     mode='lines',\n#                     name='Train MAE'))\n# fig.add_trace(go.Scatter(y=temp[\"Validation MAE\"], \n#                          x = temp['epoch'],\n#                     mode='lines',\n#                     name='Validation MAE'))\n# # Edit the layout\n# fig.update_layout(title='Model accuracy',\n#                    xaxis_title='Epoch',\n#                    yaxis_title='MAE')\n# fig.show()","73f49887":"# Load model\n\nmodel_params = {'input_dim': input_dim,\n                'hidden_dim' : hidden_dim,\n                'layer_dim' : layer_dim,\n                'output_dim' : output_dim,\n                'dropout_prob' : dropout,\n                'device' : device}\n\nmodel = LSTMModel(**model_params)\n\ncheckpoint = torch.load(f\"..\/input\/ventilatorpressurepredictionlstmmodel\/lstm_model.pth\")\nprint(checkpoint['best_valid_score'])\nmodel.load_state_dict(checkpoint[\"model_state_dict\"])\nmodel.eval()\nmodel.to(device)","f23315d6":"# Predictions on validation data\ny_pred = []\ny_true = []\n\nvalid_data_retriever = DataRetriever_LSTM(\n    df_valid[\"breath_id\"].unique().tolist(),\n    train_flag = True)\n\nvalid_loader = torch_data.DataLoader(\n    valid_data_retriever,\n    batch_size=batch_size*5,\n    shuffle=False,\n    num_workers=8,\n)\n\nfor e, batch in enumerate(valid_loader):\n    print(f\"{e}\/{len(valid_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        tmp_res = (model(batch[\"X\"].to(device))).cpu().numpy()\n        temp = pd.DataFrame(np.vstack(batch[\"X\"].cpu().numpy()))\n        temp['predicted pressure'] = np.concatenate(tmp_res)\n        temp['actual pressure'] = np.concatenate(batch[\"y\"].numpy().tolist())\n        temp.columns = ['time_step','R', 'C','u_in', 'u_out','predicted pressure','actual pressure']\n        y_pred.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'predicted pressure']])).iloc[:,5].tolist())\n        y_true.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'actual pressure']])).iloc[:,5].tolist())","6199fbed":"# y_pred = np.concatenate(y_pred)\ny_true = np.concatenate(y_true)\n\n# From https:\/\/www.kaggle.com\/cdeotte\/ensemble-folds-with-median-0-153\n# y_pred = np.round((y_pred - PRESSURE_MIN)\/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\n# y_pred = np.clip(y_pred, PRESSURE_MIN, PRESSURE_MAX)\n\nprint('MAE for validation data:', np.sum((np.abs((y_pred) - (y_true)).sum(axis = 0))\/len(y_pred)))","5c30dddc":"def interactive_line_chart_for_validation(Breath_ID):\n    data_retriever = DataRetriever_LSTM(\n    [Breath_ID],\n    train_flag = True)\n    y_pred = []\n    y_true = []\n    with torch.no_grad():\n        batch = np.expand_dims(data_retriever[0][\"X\"], axis = 0)\n        tmp_res = (model(torch.tensor(batch).float().to(device))).cpu().numpy()\n        temp = pd.DataFrame(np.vstack(batch))\n        temp['predicted pressure'] = np.concatenate(tmp_res)\n        temp['actual pressure'] = data_retriever[0][\"y\"].numpy().tolist()\n        temp.columns = ['time_step','R', 'C','u_in', 'u_out','predicted pressure','actual pressure']\n        y_pred.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'predicted pressure']])).iloc[:,5].tolist())\n        y_true.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'actual pressure']])).iloc[:,5].tolist())\n\n    # Create traces\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(y=temp[\"actual pressure\"], \n                             x = temp['time_step'],\n                        mode='lines',\n                        name='actual pressure'))\n    fig.add_trace(go.Scatter(y=temp[\"predicted pressure\"], \n                             x = temp['time_step'],\n                        mode='lines',\n                        name='predicted pressure'))\n\n    # Edit the layout\n    fig.update_layout(title='Variation by time step',\n                       xaxis_title='Time step',\n                       yaxis_title='Value')\n    fig.show()\n    \nw = widgets.interactive(interactive_line_chart_for_validation, Breath_ID = train_data['breath_id'].unique().tolist())\ndisplay(w)","2019cc26":"import gc\n# Predictions on test data\ny_pred = []\nids = []\n\ntest_data_retriever = DataRetriever_LSTM(\n    test_data[\"breath_id\"].unique().tolist(),\n    train_flag = False)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=batch_size*5,\n    shuffle=False,\n    num_workers=8,\n)\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}\/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        tmp_res = (model(batch[\"X\"].to(device))).cpu().numpy()\n        temp = pd.DataFrame(np.vstack(batch[\"X\"].cpu().numpy()))\n        temp['predicted pressure'] = np.concatenate(tmp_res)\n        temp.columns = ['time_step','R', 'C','u_in', 'u_out','predicted pressure']\n        y_pred.append(pd.DataFrame(scaler.inverse_transform(temp[['R', 'C', 'time_step', 'u_in', 'u_out', 'predicted pressure']])).iloc[:,5].tolist())\n        ids.append(batch['id'])\n        gc.collect()\n        torch.cuda.empty_cache()","73ac1f7f":"final_output = sample_submission[['id']].sort_values(by = ['id'], ascending = True)\nfinal_output['pressure'] = np.concatenate(y_pred)\n\nfinal_output.to_csv('orig_submission.csv', index = False)\n\n# From https:\/\/www.kaggle.com\/cdeotte\/ensemble-folds-with-median-0-153\nfinal_output['pressure'] = np.round((final_output.pressure - PRESSURE_MIN)\/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\nfinal_output.pressure = np.clip(final_output.pressure, PRESSURE_MIN, PRESSURE_MAX)\n\nfinal_output.to_csv('clip_submission.csv', index = False)","73584b2b":"final_output['breath_id'] = np.concatenate([np.concatenate([[i]*80 for i in x.numpy()]) for x in ids])","c9b71bed":"print(final_output.shape)\nfinal_output.head()","0422eadf":"print('Test data pressure values\\n')\ndisplay(final_output['pressure'].describe())\nprint('\\nTrain data pressure values\\n')\ndisplay(train_data['pressure'].describe())","a3e055a8":"fig = px.histogram(final_output.groupby(['breath_id']).agg({'pressure':'mean'}).reset_index(), x=\"pressure\", nbins=20)\nfig.show()","e87d1a9a":"# Pre-processing data for modelling","eac32953":"# Import packages","ceb35c04":"# EDA","6ce44502":"# Perceptron","6bab6932":"# LSTM","cbc3cb59":"# Data description\nid - globally-unique time step identifier across an entire file\n\nbreath_id - globally-unique time step for breaths\n\nR - lung attribute indicating how restricted the airway is (in cmH2O\/L\/S). Physically, this is the change in pressure per change in flow (air volume per time). Intuitively, one can imagine blowing up a balloon through a straw. We can change R by changing the diameter of the straw, with higher R being harder to blow.\n\nC - lung attribute indicating how compliant the lung is (in mL\/cmH2O). Physically, this is the change in volume per change in pressure. Intuitively, one can imagine the same balloon example. We can change C by changing the thickness of the balloon\u2019s latex, with higher C having thinner latex and easier to blow.\n\ntime_step - the actual time stamp.\n\nu_in - the control input for the inspiratory solenoid valve. Ranges from 0 to 100.\n\nu_out - the control input for the exploratory solenoid valve. Either 0 or 1.\n\npressure - the airway pressure measured in the respiratory circuit, measured in cmH2O.","28051304":"# Predictions","b1981efb":"# Google Brain - Ventilator Pressure Prediction\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/29594\/logos\/header.png?t=2021-07-29-12-44-09&quot)","623d4f3a":"Insights from EDA:\n\nThere are 80 entries for every breath_id. Hence we can consider a sequence of 80 steps to feed data into a LSTM model or we can build tree-based models\/perceptron\/other models by feeding 80 * features.\n\nR and C are constant for a breath id. Also, there are only 3 unique entries for R and C for all breath ids in train and test datasets.","8740d16d":"# ML models - Logistic regression","90c66467":"## Data summaries","9ffee96d":"![](https:\/\/raw.githubusercontent.com\/google\/deluca-lung\/main\/assets\/2020-10-02%20Ventilator%20diagram.svg)","07c2fd0b":"# Tree-based model"}}