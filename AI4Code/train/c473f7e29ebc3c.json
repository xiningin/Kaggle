{"cell_type":{"7b60a7c2":"code","3de8a5b2":"code","ad69dab8":"code","9813e0ce":"code","0eee2328":"code","94ef3947":"code","f282e082":"code","9dee7993":"code","5ce94e50":"code","e120644b":"code","3bd62fea":"code","38cdda7c":"code","0ae74d07":"code","197a2bd6":"code","4b645f13":"code","bb860b35":"code","73f7caf6":"code","207e01ba":"code","a3bedee0":"code","34254982":"code","ea2f89fd":"code","8befc36d":"code","2d884000":"code","f594f134":"code","5f55dc98":"code","acb566c5":"code","209740a0":"code","5a3a3940":"code","eb8c910e":"code","0661a4f7":"code","3d619d9d":"code","cac860a3":"code","ba77b2ef":"code","170c9069":"code","82d1de06":"code","d968f03e":"code","13a36d7b":"code","5f8bbd20":"markdown","61a6edcc":"markdown","9eb106f3":"markdown","8e446e20":"markdown"},"source":{"7b60a7c2":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib as mlp\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler # OneHE is used for convert 'str' data to numerical\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline  # multi preproseccing\nfrom sklearn.base import BaseEstimator, TransformerMixin  #use to construct eg. AttributesAdder \nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor","3de8a5b2":"df=pd.read_csv('\/kaggle\/input\/daily-sun-spot-data-1818-to-2019\/sunspot_data.csv')\ndf.head(10)","ad69dab8":"df.drop(['Unnamed: 0'], axis=1, inplace=True)","9813e0ce":"df.shape","0eee2328":"df.info()","94ef3947":"df.describe()","f282e082":"cor_mx=df.corr()\ncor_mx['Number of Sunspots'].sort_values(ascending=False)","9dee7993":"df_2018=df[df['Year']==2018]","5ce94e50":"plt.figure(figsize=(50,30))\nsns.set(font_scale = 2.5)\nsns.barplot(data=df_2018, y='Month', x='Number of Sunspots', hue='Day', orient='h')\nplt.title('Number of sunspot in each day of Jan 2018')","e120644b":"df_2018.head()","3bd62fea":"plt.figure(figsize=(8,6))\nsns.set(font_scale=0.8)\nsns.barplot(data=df_2018, y=df_2018['Day'][df_2018['Month']==1], x='Number of Sunspots', orient='h', color='blue')\nplt.title('Number of sunspot in each day of Jan 2018')","38cdda7c":"plt.figure(figsize=(8,6))\nsns.set(font_scale=0.8)\nsns.barplot(data=df_2018, y=df_2018['Day'][df_2018['Month']==2], x='Number of Sunspots', orient='h', color='red')\nplt.title('Number of sunspot in each day of Feb 2018')","0ae74d07":"plt.figure(figsize=(8,6))\nsns.set(font_scale=0.8)\nsns.barplot(data=df_2018, y=df_2018['Day'][df_2018['Month']==6], x='Number of Sunspots', orient='h', color='green')\nplt.title('Number of sunspot in each day of Jun 2018')","197a2bd6":"df.isnull().sum()","4b645f13":"df.drop(['Month','Day','Observations', 'Indicator'], axis=1, inplace=True)","bb860b35":"df","73f7caf6":"from sklearn.model_selection import train_test_split\n\ntrain, test=train_test_split(df, test_size=0.2, random_state=42)\ntrain","207e01ba":"X=train.drop('Number of Sunspots', axis=1, inplace=False)\ny=train['Number of Sunspots'].copy()","a3bedee0":"scale=StandardScaler()\nX_scaled=scale.fit_transform(X)","34254982":"lin_reg=LinearRegression()\n\nlin_reg.fit(X_scaled, y)","ea2f89fd":"lin_scores=cross_val_score(lin_reg, X_scaled, y, scoring='neg_mean_absolute_error', cv=10)\nlin_mae=-lin_scores\nlin_mae\n\ndef cost_fun(scores):\n    print('Scores:', scores,\n         'Mean:', scores.mean(),\n         'Standard Deviation:', scores.std())","8befc36d":"cost_fun(lin_mae)","2d884000":"from sklearn.linear_model import Ridge, Lasso\n\nridge=Ridge()\nridge.fit(X_scaled, y)\nridge_scores=cross_val_score(ridge, X_scaled, y, cv=10, scoring='neg_mean_absolute_error')\nridge_mae=-ridge_scores\n\ncost_fun(ridge_mae)","f594f134":"param_grid=({\n    'alpha': np.logspace(-5,5,10)\n})\n\nridge_search=GridSearchCV(ridge, param_grid, cv=10, \n                         scoring='neg_mean_absolute_error',\n                         return_train_score=True)\nridge_search.fit(X_scaled,y)\n","5f55dc98":"ridge_search.best_params_","acb566c5":"ridge_model=ridge_search.best_estimator_\nridge_model.fit(X_scaled,y)\nridge_model_scores=cross_val_score(ridge_model, X_scaled, y, cv=10, scoring='neg_mean_absolute_error')\nridge_model_mae=-ridge_model_scores\n\ncost_fun(ridge_model_mae)","209740a0":"tree_reg=DecisionTreeRegressor()\ntree_reg.fit(X_scaled, y)\ntree_scores=cross_val_score(tree_reg, X_scaled, y, cv=10, scoring='neg_mean_absolute_error')\ntree_mae=-tree_scores\n\ncost_fun(tree_mae)","5a3a3940":"random_forest=RandomForestRegressor()\nrandom_forest.fit(X_scaled, y)\n\nforest_score=cross_val_score(random_forest, X_scaled, y, cv=10, scoring='neg_mean_absolute_error')\nforest_mae=-forest_score\n\ncost_fun(forest_mae)","eb8c910e":"from sklearn.preprocessing import PolynomialFeatures\n\npoly=PolynomialFeatures(degree=3)\nX_poly=poly.fit_transform(X_scaled)\n\nlin_reg.fit(X_poly, y)","0661a4f7":"lin_scores=cross_val_score(lin_reg, X_poly, y, scoring='neg_mean_absolute_error', cv=10)\nlin_mae=-lin_scores\n\ncost_fun(lin_mae)","3d619d9d":"tree_reg=DecisionTreeRegressor()\ntree_reg.fit(X_poly, y)\n\ntree_scores=cross_val_score(tree_reg, X_poly, y, cv=10, scoring='neg_mean_absolute_error')\ntree_mae=-tree_scores\n\ncost_fun(tree_mae)","cac860a3":"random_forest=RandomForestRegressor()\nrandom_forest.fit(X_poly, y)\n\nforest_score=cross_val_score(random_forest, X_poly, y, cv=5, scoring='neg_mean_absolute_error')\nforest_mae=-forest_score\n\ncost_fun(forest_mae)","ba77b2ef":"\nparam_grid = [\n    # Try 20 (4*5) combination of hyperparameters\n    {'n_estimators': [10, 20, 40], 'max_features': [2, 3]},\n    # Try bootstrap as False with 12 combination\n    {'bootstrap': [False], 'n_estimators': [20, 40], 'max_features': [2, 3]},\n]\nforest_reg = RandomForestRegressor(random_state=42)\n# Train across 5 fold, that is a total of (16 + 12)*5 rounds of training\nforest_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring=\"neg_mean_absolute_error\",\n                           return_train_score=True)\nforest_search.fit(X_scaled, y)","170c9069":"forest_search.best_params_","82d1de06":"forest_model=forest_search.best_estimator_\n\nforest_model.fit(X_scaled, y)\n\nforest_model_score=cross_val_score(forest_model, X_scaled, y, cv=5, scoring='neg_mean_absolute_error')\nforest_model_rmse=np.sqrt(-forest_model_score)\n\ncost_fun(forest_model_rmse)","d968f03e":"test","13a36d7b":"X_test=test.drop('Number of Sunspots', axis=1, inplace=False)\ny_test=test['Number of Sunspots'].copy()\n\nX_test_scaled=scale.transform(X_test)\nfinal_prediction=forest_model.predict(X_test_scaled)\nfinal_mae=mean_absolute_error(final_prediction, y_test)\nfinal_mae=np.sqrt(final_mae)\nfinal_mae","5f8bbd20":"let's go through our `test_set` for final `MAE`","61a6edcc":"Prediction `Number of Sunspots` with several models,**LieanrRegression, DecisionTree, RandomForest, Ridge**. Finally I got the best `MAE` almost **1.6**.","9eb106f3":"It ( Polynomial) does not make sense","8e446e20":"### Training Model with polynomial features"}}