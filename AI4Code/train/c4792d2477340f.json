{"cell_type":{"608c7421":"code","f043b021":"code","f806cd7e":"code","83ee36cc":"code","15fac0e5":"code","11fc174c":"code","ed12087d":"code","5bfe02b8":"code","bc71ebc0":"code","2557132d":"code","74eae45b":"code","696a6b55":"code","69dbaa10":"code","44a2f915":"code","62a61425":"code","9bd5f464":"code","860ea462":"code","384c43f3":"code","23877860":"markdown","ff85609b":"markdown","9529ac3a":"markdown","cd0f99af":"markdown","1246eacd":"markdown","f0233f7c":"markdown","17654ebc":"markdown","ed4cdf2d":"markdown","86a208a9":"markdown","c699d3dc":"markdown","5a412b5a":"markdown","22835e8d":"markdown","283cbc86":"markdown"},"source":{"608c7421":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npal = sns.color_palette()\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f043b021":"import h2o\nprint(h2o.__version__)\nfrom h2o.automl import H2OAutoML\n\nh2o.init(max_mem_size='16G')","f806cd7e":"%%time\ntrain = h2o.import_file(\"..\/input\/mercedes-benz-greener-manufacturing\/train.csv\")\ntest = h2o.import_file(\"..\/input\/mercedes-benz-greener-manufacturing\/test.csv\")\n","83ee36cc":"train.head(5)","15fac0e5":"print(f'Size of training set: {train.shape[0]} rows and {train.shape[1]} columns')","11fc174c":"x = train.columns\ny = 'y'\nx.remove(y)\n","ed12087d":"aml = H2OAutoML(max_runtime_secs = 250000, seed = 1, project_name = \"lb_frame\")\naml.train(x = x, y = y, training_frame = train)","5bfe02b8":"\nlb = aml.leaderboard\nlb.head()  ","bc71ebc0":"# The leader model is stored here\naml.leader","2557132d":"\n# Get model ids for all models in the AutoML Leaderboard\nmodel_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n# Get the \"All Models\" Stacked Ensemble model\nse = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n# Get the Stacked Ensemble metalearner model\nmetalearner = h2o.get_model(se.metalearner()['name'])","74eae45b":"metalearner.coef_norm()","696a6b55":"metalearner.std_coef_plot()","69dbaa10":"pred = aml.predict(test)\npred.head()","44a2f915":"h2o.save_model(aml.leader, path = \".\/product_backorders_model_bin\")","62a61425":"sample_submission = pd.read_csv('..\/input\/mercedes-benz-greener-manufacturing\/sample_submission.csv')\nsample_submission.shape","9bd5f464":"sample_submission['y'] = pred.as_data_frame().values\nsample_submission.to_csv('submission.csv', index=False)","860ea462":"h2o.save_model(aml.leader, path = \"submission.csv\")","384c43f3":"sample_submission.head()","23877860":"# Leaderboard\nNext, we will view the AutoML Leaderboard. Since we specified a leaderboard_frame in the H2OAutoML.train() method for scoring and ranking the models, the AutoML leaderboard uses the performance on this data to rank the models.\n\nA default performance metric for each machine learning task (binary classification, multiclass classification, regression) is specified internally and the leaderboard will be sorted by that metric. In the case of regression, the default ranking metric is mean residual deviance. In the future, the user will be able to specify any of the H2O metrics so that different metrics can be used to generate rankings on the leaderboard.","ff85609b":"# Start H2O\nImport the h2o Python module and H2OAutoML class and initialize a local H2O cluster","9529ac3a":"# Predicting Using Leader Model","cd0f99af":"Plotting the base learner contributions to the ensemble.","1246eacd":"## Submissions","f0233f7c":"**Automated machine learning** (**AutoML**) is the process of automating the end-to-end process of applying machine learning to real-world problems. AutoML makes machine learning available in a true sense, even to people with no major expertise in this field.\n\n# Advantages\n\nThe advantages of AutoML can be summed up in three major points:\n\n-   **Increases productivity**  by automating repetitive tasks. This enables a  data scientist to focus more on the problem rather than the models.\n-   Automating the ML pipeline also helps to  **avoid errors** that might creep in manually.\n-   Ultimately,  AutoML is a step towards **democratizing machine learning** by making the power of ML accessible to everybody.\n\n# [H2O AutoML](http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/automl.html)\nH2O\u2019s AutoML can be used for automating the machine learning workflow, which includes automatic training and tuning of many models within a user-specified time-limit. [Stacked Ensembles](http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/data-science\/stacked-ensembles.html) \u2013 one based on all previously trained models, another one on the best model of each family \u2013 will be automatically trained on collections of individual models to produce highly predictive ensemble models which, in most cases, will be the top performing models in the AutoML Leaderboard.\n\nProperties of H2O AutoML\n\n* Basic data pre-processing (as in all H2O algos).\n\n* Trains a random grid of GBMs, DNNs, GLMs, etc. using a carefully chosen hyper-parameter space.\n\n* Individual models are tuned using cross-validation.\n\n* Two Stacked Ensembles are trained (\u201cAll Models\u201d ensemble & a lightweight \u201cBest of Family\u201d ensemble).\n\n* Returns a sorted \u201cLeaderboard\u201d of all models. All models can be easily exported to production.\n\n\n# Objective\n\nOur job is to predict how long a car on a production line will take to pass the testing phase. This is a classical regression problem, and we're evaluated with the R2 metric.\n","17654ebc":"# Run AutoML\n\nRun AutoML, stopping after around 1 hour. The max_runtime_secs argument provides a way to limit the AutoML run by time. When using a time-limited stopping criterion, the number of models train will vary between runs. If different hardware is used or even if the same machine is used but the available compute resources on that machine are not the same between runs, then AutoML may be able to train more models on one run vs another.\n","ed4cdf2d":"## Ensemble Exploration\nTo understand how the ensemble works, let's take a peek inside the Stacked Ensemble \"All Models\" model. The \"All Models\" ensemble is an ensemble of all of the individual models in the AutoML run. This is often the top performing model on the leaderboard.","86a208a9":"Next, let's identify the response column and save the column name as y. In this dataset, we will use all columns except the response as predictors.","c699d3dc":"# Load data into H2O","5a412b5a":"Let's take a look at the data.","22835e8d":"## Save Leader Model\n\nYou can also save and download your model and use it for deploying it to productiont.","283cbc86":"Examine the variable importance of the metalearner (combiner) algorithm in the ensemble. This shows us how much each base learner is contributing to the ensemble. "}}