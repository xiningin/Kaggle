{"cell_type":{"a01c74a7":"code","1d73289b":"code","faf838cf":"code","ffd86336":"code","51f8ae59":"code","43975fb9":"code","879cb2ed":"code","82c6f1c3":"code","4f8fd425":"code","1a2502a7":"code","f4ace379":"code","4d8d40d8":"code","1ea75558":"code","2ee01605":"code","11039344":"code","00b67dff":"code","015e591a":"markdown","752985e0":"markdown","70d5a6e9":"markdown","a96cd3b6":"markdown","5ba09679":"markdown"},"source":{"a01c74a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1d73289b":"import matplotlib.pyplot as plt\nimport cv2 \nfrom keras.utils import np_utils\nfrom sklearn.datasets import load_files       \nimport tensorflow as tf \nfrom tensorflow import keras \nfrom glob import glob \nimport os\nprint(os.listdir(\"..\/input\/fruits360v14\/\"))\n\n# Any results you write to the current directory are saved as output","faf838cf":"#Loading the train images into the root directory for training the model\nroot_dir = '..\/input\/fruits360v14\/fruits-360-v-14\/Training'\n#We will be selecting around 30 images for visualization purposes\nrows = 14\ncols = 6\nfig, ax = plt.subplots(rows, cols, frameon=False, figsize=(12, 20))\nfig.suptitle('Images selected at random from multiple classes', fontsize=20)\nsorted_food_dirs = sorted(os.listdir(root_dir))\nfor i in range(rows):\n    for j in range(cols):\n        try:\n            food_dir = sorted_food_dirs[i*cols + j]\n        except:\n            break\n        all_files = os.listdir(os.path.join(root_dir, food_dir))\n        rand_img = np.random.choice(all_files)\n        img = plt.imread(os.path.join(root_dir, food_dir, rand_img))\n        ax[i][j].imshow(img)\n        ec = (0, .6, .1)\n        fc = (0, .7, .2)\n        ax[i][j].text(0, -20, food_dir, size=10, rotation=0,\n                ha=\"left\", va=\"top\", \n                bbox=dict(boxstyle=\"round\", ec=ec, fc=fc))\n        \n#Visualizsing the results\nplt.setp(ax, xticks=[], yticks=[])\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","ffd86336":"#Now we will load the actual train and test datasets and define a function for the same\n#Defining the function\ndef load_dataset(path):\n    data = load_files(path)\n    fruit_files = np.array(data['filenames'])\n    fruit_targets = np_utils.to_categorical(np.array(data['target']), 60)\n    return fruit_files, fruit_targets\n\n# Setting uo train and test data into variables from input dataset\ntrain_files, train_targets = load_dataset('..\/input\/fruits360v14\/fruits-360-v-14\/Training\/')\ntest_files, test_targets = load_dataset('..\/input\/fruits360v14\/fruits-360-v-14\/Validation\/')\n\n\n# loading a directory with the names of the fruits\nfruit_names = [item[9:] for item in sorted(glob(\"Training\/*\"))]\n\n# Basic description of the dataset\nprint('Total images of fruits in the dataset are %s.\\n' % len(np.hstack([train_files, test_files])))\nprint('No. of training images are %d .' % len(train_files))\nprint('No of test images are %d .'% len(test_files))","51f8ae59":"#Inclusion of images using glob\nimport glob\n\n#initializing empty lists fot training image and training label\ntraining_fruit_img = []\ntraining_label = []\n\nfor dir_path in glob.glob(\"..\/input\/fruits360v14\/fruits-360-v-14\/Training\/*\"):\n    img_label = dir_path.split(\"\/\")[-1]\n    for img_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n        img = cv2.imread(img_path)\n        img = cv2.resize(img, (64,64))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        training_fruit_img.append(img)\n        training_label.append(img_label)\ntraining_fruit_img = np.array(training_fruit_img)\ntraining_label = np.array(training_label)\nlen(np.unique(training_label))","43975fb9":"#initializing empty lists fot test image and test label\ntest_fruit_img = []\ntest_label = []\nfor dir_path in glob.glob(\"..\/input\/fruits360v14\/fruits-360-v-14\/Validation\/*\"):\n    img_label = dir_path.split(\"\/\")[-1]\n    for img_path in glob.glob(os.path.join(dir_path, \"*.jpg\")):\n        img = cv2.imread(img_path)\n        img = cv2.resize(img, (64,64))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        test_fruit_img.append(img)\n        test_label.append(img_label)\ntest_fruit_img = np.array(test_fruit_img)\ntest_label = np.array(test_label)\nlen(np.unique(test_label))","879cb2ed":"#Labeling images uniquely with individual ids\nlabel_to_id = {v : k for k, v in enumerate(np.unique(training_label))}\nid_to_label = {v : k for k, v in label_to_id.items()}\ntraining_label_id = np.array([label_to_id[i] for i in training_label])\ntest_label_id = np.array([label_to_id[i] for i in test_label])\ntest_label_id","82c6f1c3":"#Normalizing the images\ntraining_fruit_img, test_fruit_img = training_fruit_img \/ 255.0, test_fruit_img \/ 255.0 \n#Visualising a sample random image after normalising\nplt.imshow(training_fruit_img[12])","4f8fd425":"#Importing cv2 library - This is a library of Python bindings designed to solve computer vision problems\n#All the OpenCV array structures are converted to and from Numpy arrays\n#This also makes it easier to integrate with other libraries that use Numpy such as SciPy and Matplotlib\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n#imread method loads an image from the specified file\nimg = cv2.imread(train_files[0])\ncolor = ('b','g','r')\nfor i,col in enumerate(color):\n#To deal with an image which  consist of intensity distribution of pixels where pixel value varies\n#We use cv2's inbuild function calcHist to to plot the histogram.\n    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n    plt.plot(histr,color = col)\n    plt.xlim([0,256])\nplt.show()","1a2502a7":"#Instanitating the model\nmodel = keras.Sequential()\n#Conv layer 1\nmodel.add(keras.layers.Conv2D(16, (3, 3), input_shape = (64,64, 3), padding = \"same\", activation = \"relu\"))\nmodel.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n\n#Conv layer 2\nmodel.add(keras.layers.Conv2D(32, (3, 3), padding = \"same\", activation = \"relu\"))\nmodel.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n\n#Conv layer 3\nmodel.add(keras.layers.Conv2D(32, (3, 3), padding = \"same\", activation = \"relu\"))\nmodel.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n\n#Conv layer 4\nmodel.add(keras.layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\"))\nmodel.add(keras.layers.MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(keras.layers.Flatten())\n\n#Hidden layer\nmodel.add(keras.layers.Dense(256, activation = \"relu\"))\n\n#Output layer\nmodel.add(keras.layers.Dense(75, activation = \"softmax\"))","f4ace379":"#Compiling the model\nmodel.compile(loss = \"sparse_categorical_crossentropy\", optimizer = keras.optimizers.Adamax(), metrics = ['accuracy'])\ntensorboard = keras.callbacks.TensorBoard(log_dir = \".\/Graph\", histogram_freq = 0, write_graph = True, write_images = True)\nmodel.summary()","4d8d40d8":"#Fitting the model\n#Hpyer parameters\nBATCH_SIZE = 128\nEPOCHS = 10\nHistory = model.fit(training_fruit_img, training_label_id, batch_size = BATCH_SIZE, epochs = EPOCHS, callbacks = [tensorboard])","1ea75558":"#Training accuracy\nloss, accuracy = model.evaluate(training_fruit_img,training_label_id)\nprint(\"\\n\\nLoss:\", loss)\nprint(\"Accuracy:\", accuracy)\n#model.save(\"model.h5\")","2ee01605":"#Test accuracy\nloss, accuracy = model.evaluate(test_fruit_img, test_label_id)\nprint(\"\\n\\nLoss:\", loss)\nprint(\"Accuracy:\", accuracy)\nmodel.save(\"model.fruit\")","11039344":"#Plotting the results\nN = 10\nplt.figure()\nplt.plot(np.arange(0, N), History.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), History.history[\"accuracy\"], label=\"train_acc\")\nplt.title(\"Training Loss and Accuracy on Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.savefig(\"plot.png\")","00b67dff":"predictions = model.predict(test_fruit_img)\nplt.figure(figsize = (20, 20))\nfor i in range(30):\n    plt.subplot(9,5, i + 1)\n    plt.xlabel(\"{}\".format(id_to_label[np.argmax(predictions[i])]))\n    plt.imshow(test_fruit_img[i])","015e591a":"# Checking Accuracy","752985e0":"# Making Predictions","70d5a6e9":"# **Visualizing the sample images**","a96cd3b6":"# Loading Data","5ba09679":"# Model"}}