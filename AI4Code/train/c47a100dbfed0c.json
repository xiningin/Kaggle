{"cell_type":{"b6f648e1":"code","1805c9fe":"code","9d7307a1":"code","a674e7e4":"code","537e40ea":"code","289e660f":"code","8f0bc1a9":"code","11f869e4":"code","c520cf3d":"code","37d6341f":"code","aed864fc":"code","9dd13806":"code","64aaa919":"code","a576eda1":"code","8d38187d":"code","6ad10f49":"code","55f901db":"code","82332a86":"code","96c17af1":"code","8546dfa7":"code","def876cf":"code","eaa5f546":"code","de6e9845":"code","d5c732b5":"code","10b76e2c":"code","c99d3ee4":"code","98fd2d4a":"code","790e3150":"markdown","98d1ed06":"markdown","acc49c49":"markdown","4b41826e":"markdown","bd298b39":"markdown","aee26d16":"markdown","794f1fec":"markdown","903e194c":"markdown","e7fbf4d0":"markdown","e02256f8":"markdown","ffa9a700":"markdown","14eede11":"markdown","651885da":"markdown","6cf01066":"markdown","bb9f94a8":"markdown","02f33b1f":"markdown","19b6c6d3":"markdown","46695eb7":"markdown","ef3cd727":"markdown"},"source":{"b6f648e1":"from numpy.random import seed\nseed(1)\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n# Warning\nimport warnings\nwarnings.filterwarnings('ignore')","1805c9fe":"# Random seeds\nimport random\nrandom.seed(319)\nnp.random.seed(319)\ntf.random.set_seed(319)","9d7307a1":"train_full = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","a674e7e4":"pixels = train_full.drop(labels=[\"label\"],axis=1, inplace=False)\nlabels =  train_full['label']","537e40ea":"# Free memory\ndel train_full","289e660f":"sns.countplot(labels)","8f0bc1a9":"pixels.isnull().any().describe()","11f869e4":"labels.isnull().any()","c520cf3d":"test.isnull().any().describe()","37d6341f":"# Normalization\npixels = pixels\/255\ntest = test\/255","aed864fc":"# Reshape\npixels = pixels.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","9dd13806":"# Label encoding\nlabels = to_categorical(labels, num_classes=10)","64aaa919":"X_train, X_val, y_train, y_val = train_test_split(pixels, labels,\n                                                 test_size=0.1,\n                                                 random_state=42)","a576eda1":"X_train.shape","8d38187d":"BATCH_SIZE = 64 # random number depend on your processor.","6ad10f49":"train_datagen = ImageDataGenerator(featurewise_center=False,\n                             samplewise_center=False,\n                             featurewise_std_normalization=False,\n                             samplewise_std_normalization=False,\n                             zca_whitening=False,\n                             rotation_range=10,\n                             zoom_range=0.1,\n                             width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             horizontal_flip=False,\n                             vertical_flip=False\n                            )\ntrain_generator = train_datagen.flow(X_train, y_train,\n                                     batch_size=BATCH_SIZE,\n                                     shuffle=True)","55f901db":"val_datagen = ImageDataGenerator()\nval_generator = val_datagen.flow(X_val, y_val,\n                                 batch_size=BATCH_SIZE,\n                                 shuffle=True)","82332a86":"EPOCH = 20\nLEARNING_RATE = 0.001\nkernel_initializer = tf.keras.initializers.GlorotNormal(seed=319)","96c17af1":"def create_model():\n    model = Sequential()\n\n    model.add(Input(shape=(28,28,1)))\n    model.add(Conv2D(32, kernel_size=(5,5), kernel_initializer=kernel_initializer, padding=\"Same\", activation=\"relu\",))\n    model.add(Conv2D(32, kernel_size=(5,5), kernel_initializer=kernel_initializer, padding=\"Same\", activation=\"relu\",))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25, seed=319))\n\n    model.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=kernel_initializer, padding=\"Same\", activation=\"relu\"))\n    model.add(Conv2D(64, kernel_size=(5,5), kernel_initializer=kernel_initializer, padding=\"Same\", activation=\"relu\"))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25, seed=319))\n\n    model.add(Flatten())\n    model.add(Dense(256, kernel_initializer=kernel_initializer, activation=\"relu\"))\n    model.add(Dropout(0.5, seed=319))\n    model.add(BatchNormalization())\n    model.add(Dense(10, kernel_initializer=kernel_initializer, activation=\"softmax\"))\n    \n    # Define the optimizer\n    decay= 5 * LEARNING_RATE \/ EPOCH\n    optimizer = RMSprop(learning_rate=LEARNING_RATE, rho=0.9, epsilon=1e-08, decay=decay)\n    \n    #Compile model\n    model.compile(optimizer=optimizer,\n                  loss=\"categorical_crossentropy\",\n                  metrics=['accuracy']\n                 )\n    return model","8546dfa7":"lr_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                patience=3,\n                                verbose=1, # update messages.\n                                factor=0.5,\n                                min_lr=0.00001)","def876cf":"model = create_model()\nmodel.summary()","eaa5f546":"history = model.fit(train_generator,\n                    epochs= EPOCH,\n                    validation_data=val_generator,\n                    verbose=2,\n                    callbacks=[lr_reduction]\n                   )","de6e9845":"def plot_loss_accuracy(history):\n    # Plot the loss and accuracy curves for training and validation \n    fig, ax = plt.subplots(2,1)\n    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n    ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n    legend = ax[0].legend(loc='best', shadow=True)\n\n    ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n    ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n    legend = ax[1].legend(loc='best', shadow=True)\n\nplot_loss_accuracy(history)","d5c732b5":"val_acc_per_epoch = history.history['val_accuracy']\nbest_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch))+1\nbest_epoch, max(val_acc_per_epoch)","10b76e2c":"model_best = create_model()\nhistory_best = model_best.fit(train_generator,\n                    epochs= best_epoch,\n                    validation_data=val_generator,\n                    verbose=2,\n                    callbacks=[lr_reduction]\n                   )\nplot_loss_accuracy(history_best)","c99d3ee4":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")","98fd2d4a":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","790e3150":"<a id=\"3.2\"><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>3.2  Reducing Learning Rate <\/b><\/font><br>\n[Content](#0)\n\nReducing the Learning Rate by half of the accuracy is not improved after 3 epoches","98d1ed06":"   - Randomly rotate some training images by 10 degrees\n   - Randomly  Zoom by 10% some training images\n   - Randomly shift images horizontally by 10% of the width\n   - Randomly shift images vertically by 10% of the height\n   \n**Vertical_flip** and **Horizontal_flip** are not applied because they could have lead to misclassify symetrical numbers such as 6 and 9.\n","acc49c49":"<a id=\"3.3\"><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>3.3  Re-instantiate the hypermodel and train it with the optimal number of epochs <\/b><\/font><br>\n[Content](#0)\n","4b41826e":"<a id=2.1 ><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>2.1. Load Data <\/b><\/font><br>\n[Content](#0)","bd298b39":"<a id=10 ><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 20px 50px;\">Reference<\/p>\n\n[Content](#0)\n","aee26d16":"<a id='1'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\">1. Introduction and updates<\/p>\n ","794f1fec":"<a id=1.2 ><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>1.2. Update via Versions <\/b><\/font><br>\n[Content](#0)\n\n### Current Version\n* Fit the error in [here](https:\/\/www.kaggle.com\/c\/digit-recognizer\/discussion\/290372)\n\n### Version 7\n* Add One BatchNormalization layer in front of the last layer in model.\n* Increase Epoch to 30 to prevent Underfitting. \n\n### Version 6\n* This version, the Decay hyperparameter in Optimizer is '5*learningrate\/epoch'\n* Using ImageDataGenerator for both Train\/Validation Data\n\n### Version 5\n* This version, the Decay hyperparameter in Optimizer is '7*learningrate\/epoch'\n\n### Version 4\n* Model is use RMSprop Optimizer. Decay parameter (in this optimizer) will decays the learning rate over time, so we can move even closer to the local minimum in the end of training. The previous version, this parameter is not used (set equal zero). And in this version, the value is '5*learningrate\/epoch'\n\n\n### Version 2,3\n* Using Data Augmentation and running with the best epoch\n* Update Markdowns\n\n### Version 1\n* No Data Augmentation --> 0.984\n\n","903e194c":"### Data is distributed similarity from number 0 to 9 ","e7fbf4d0":"<a id=1.1 ><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>1.1. Introduction <\/b><\/font><br>\n[Content](#0)\n\n* In this kernel, Data is augmented to increace validation.\n* Using a simple CNN model.\n* To prevent overfitting, [Reduce Learning Rate technic](https:\/\/keras.io\/api\/callbacks\/reduce_lr_on_plateau\/) to apply Learning Rate in model.","e02256f8":"<a id=3 ><\/a>\n## <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 20px 50px;\">3. CNN Model<\/p>\n[Content](#0)\n","ffa9a700":"<a id=2.5 ><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>2.5 Data Augmentation <\/b><\/font><br>\n[Content](#0)","14eede11":"<a id=2.4 ><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>2.4. Preprocessing <\/b><\/font><br>\n[Content](#0)\n","651885da":"<a id='2'><\/a>\n# <p style=\"background-color:skyblue; font-family:newtimeroman; font-size:150%; text-align:center; border-radius: 15px 50px;\"> 2. Data Preparation<\/p>\n","6cf01066":"<a id=2.3 ><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>2.3. Check null and missing <\/b><\/font><br>\n[Content](#0)\n","bb9f94a8":"* [ZCA Whitening](https:\/\/martin-thoma.com\/zca-whitening\/)\n\n* [Basic Data Augumentation](https:\/\/youtu.be\/yYqAvlkRwUQ)\n\n    * https:\/\/machinelearningmastery.com\/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks\/\n    \n* [RMSprop](https:\/\/keras.io\/api\/optimizers\/rmsprop\/)","02f33b1f":"<a id=0><\/a>\n## <p style=\"background-color:lightblue; font-family:newtimeroman; font-size:120%; text-align:left; border-radius: 15px 50px;\">Table of Content<\/p>\n* [1. Introduction and updates](#1)\n* [2. Data Preparation](#2)\n    * [2.1. Load Data](#2.1)\n    * [2.2. Count record number per each category](#2.2)\n    * [2.3. Check null and missing](#2.3)\n    * [2.4. Preprocessing](#2.4)\n    * [2.5 Data Augmentation](#2.5)\n* [3. Model](#3)\n    * [3.1 Define Model](#3.1)\n    * [3.2 Reducing Learning Rate](#3.2)\n    * [3.3 Re-instantiate the hypermodel and train it with the optimal number of epochs](#3.3)\n    \n\n* [References](#10)","19b6c6d3":"<a id=2.2 ><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>2.2. Count record number per each category <\/b><\/font><br>\n[Content](#0)\n","46695eb7":"### No corrupted images(missing\/null inside)","ef3cd727":"<a id=\"3.1\"><\/a>\n<font size=\"+3\" color=\"#5bc0de\"><b>3.1. Define Model <\/b><\/font><br>\n[Content](#0)"}}