{"cell_type":{"81703b24":"code","66521012":"code","63ad12ea":"code","02c35de2":"code","8039e359":"code","21affb13":"code","4f3bb762":"code","56a29252":"code","f0d0a500":"code","c8006f0b":"code","f1a02730":"code","5e81d553":"markdown","7f824936":"markdown","fbda35b9":"markdown","20f24552":"markdown","9e4bbd0d":"markdown","aaf00a64":"markdown","b69c7df8":"markdown","a78230b4":"markdown","ed0dad8e":"markdown"},"source":{"81703b24":"!pip install numpyro==0.6.0","66521012":"!pip install git+https:\/\/github.com\/blackjax-devs\/blackjax","63ad12ea":"import jax\nimport numpy as np\nimport pymc3 as pm\nimport pymc3.sampling_jax\n\nimport blackjax.nuts as nuts\nimport blackjax.stan_warmup as stan_warmup\n\nprint(f\"Running on PyMC3 v{pm.__version__}\")","02c35de2":"# Data of the Eight Schools Model\nJ = 8\ny = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\nsigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])","8039e359":"with pm.Model() as model:\n\n    mu = pm.Normal(\"mu\", mu=0.0, sigma=10.0)\n    tau = pm.HalfCauchy(\"tau\", 5.0)\n\n    theta = pm.Normal(\"theta\", mu=0, sigma=1, shape=J)\n    theta_1 = mu + tau * theta\n    obs = pm.Normal(\"obs\", mu=theta_1, sigma=sigma, shape=J, observed=y)","21affb13":"%%time\n\nimport numpyro\nimport numpyro.distributions as dist\n\n# Eight Schools example\ndef eight_schools(J, sigma, y=None):\n    mu = numpyro.sample('mu', dist.Normal(0, 10))\n    tau = numpyro.sample('tau', dist.HalfCauchy(5))\n    theta = numpyro.sample('theta', dist.Normal(0, 1))\n    with numpyro.plate('J', J):\n        theta_1  = mu + tau * theta\n        numpyro.sample('obs', dist.Normal(theta_1, sigma), obs=y)\n        \nfrom jax import random\nfrom numpyro.infer import MCMC, NUTS\n\nnuts_kernel = NUTS(eight_schools)\nmcmc = MCMC(nuts_kernel, num_warmup=1000, num_samples=50000)\nrng_key = random.PRNGKey(0)\nmcmc.run(rng_key, J, sigma, y=y, extra_fields=('potential_energy',))","4f3bb762":"%%time\n\nwith model:\n    posterior = pm.sample(50_000, chains=1)","56a29252":"\n# with model:\n#     hierarchical_trace_jax = pm.sampling_jax.sample_numpyro_nuts(\n#         50_000, target_accept=0.9, chains=1\n#     )","f0d0a500":"from theano.graph.fg import FunctionGraph\nfrom theano.link.jax.jax_dispatch import jax_funcify\n\nseed = jax.random.PRNGKey(1234)\nchains = 1\n\n# Get the FunctionGraph of the model.\nfgraph = FunctionGraph(model.free_RVs, [model.logpt])\n\n# Jax funcify builds Jax variant of the FunctionGraph.\nfns = jax_funcify(fgraph)\nlogp_fn_jax = fns[0]\n\n# Now we build a Jax variant of the initial state\/inputs to the model.\nrv_names = [rv.name for rv in model.free_RVs]\ninit_state = [model.test_point[rv_name] for rv_name in rv_names]\ninit_state_batched = jax.tree_map(\n    lambda x: np.repeat(x[None, ...], chains, axis=0), init_state\n)","c8006f0b":"# Then we transform the Jaxified input and FunctionGraph to a BlackJax NUTS sampler\npotential = lambda x: -logp_fn_jax(*x)\ninitial_position = init_state\ninitial_state = nuts.new_state(initial_position, potential)","f1a02730":"%%time\n\nkernel_factory = lambda step_size, inverse_mass_matrix: nuts.kernel(\n    potential, step_size, inverse_mass_matrix\n)\n\nlast_state, (step_size, inverse_mass_matrix), _ = stan_warmup.run(\n    seed, kernel_factory, initial_state, 1000\n)\n\n\ndef inference_loop(rng_key, kernel, initial_state, num_samples):\n    def one_step(state, rng_key):\n        state, info = kernel(rng_key, state)\n        return state, (state, info)\n\n    keys = jax.random.split(rng_key, num_samples)\n    _, (states, infos) = jax.lax.scan(one_step, initial_state, keys)\n\n    return states, infos\n\n\n# Build the kernel using the step size and inverse mass matrix returned from the window adaptation\nkernel = kernel_factory(step_size, inverse_mass_matrix)\n\n# Sample from the posterior distribution\nstates, infos = inference_loop(seed, kernel, last_state, 50_000)","5e81d553":"## Data\n\nPlease refer to the [original TFP example](https:\/\/www.tensorflow.org\/probability\/examples\/Eight_Schools) for a description of the problem and the model that is used.","7f824936":"# Sampling using native numpyro","fbda35b9":"# Sampling using BlackJax\n\n## Configuring the model for BlackJax\n","20f24552":"# Use BlackJAX with PyMC3\nAuthor: Kaustubh Chaudhari","9e4bbd0d":"# Sampling using PyMC NUTS Sampler","aaf00a64":"BlackJAX can take any log-probability function as long as it is compatible with JAX's JIT. In this notebook we show how we can use PyMC as a modeling language and BlackJAX as an inference library.\n\nFor this notebook to run you will need to install PyMC3:\n\n```bash\npip install pymc3\n```","b69c7df8":"# Sampling using PyMC JAX Numpyro NUTS sampler","a78230b4":"## Sampling","ed0dad8e":"# Model\n"}}