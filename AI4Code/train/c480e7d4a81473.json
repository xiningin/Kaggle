{"cell_type":{"73e80f81":"code","b6754011":"code","8040e119":"code","cc404840":"code","63986279":"code","8f9e457a":"code","dcc4f955":"code","bfb4587b":"code","b2f0034a":"code","b2db1c32":"code","c838e5dc":"code","523f3d18":"code","fd7d676c":"code","36a8f365":"markdown","810f6063":"markdown"},"source":{"73e80f81":"!pip install albumentations","b6754011":"!pip install pretrainedmodels","8040e119":"!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html","cc404840":"import torch\nprint(torch.__version__)\nprint(torch.cuda.get_device_name(0))","63986279":"%%writefile preprocess.py\n\nimport os\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelBinarizer\n\nroot_dir = '..\/input\/caltech256\/256_ObjectCategories'\n# get all the folder paths\nall_paths = os.listdir(root_dir)\n\n# create a DataFrame\ndata = pd.DataFrame()\n\nimages = []\nlabels = []\ncounter = 0\nfor folder_path in tqdm(all_paths, total=len(all_paths)):\n    # get all the image names in the particular folder\n    image_paths = os.listdir(f\"{root_dir}\/{folder_path}\")\n    # get the folder as label\n    label = folder_path.split('.')[-1]\n    \n    if label == 'clutter':\n        continue\n\n    # save image paths in the DataFrame\n    for image_path in image_paths:\n        if image_path.split('.')[-1] == 'jpg':\n            data.loc[counter, 'image_path'] = f\"{root_dir}\/{folder_path}\/{image_path}\"\n            labels.append(label)\n            counter += 1\n\nlabels = np.array(labels)\n# one-hot encode the labels\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\n\n# add the image labels to the dataframe\nfor i in range(len(labels)):\n    index = np.argmax(labels[i])\n    data.loc[i, 'target'] = int(index)\n    \n# shuffle the dataset\ndata = data.sample(frac=1).reset_index(drop=True)\n\nprint(f\"Number of labels or classes: {len(lb.classes_)}\")\nprint(f\"The first one hot encoded labels: {labels[0]}\")\nprint(f\"Mapping the first one hot encoded label to its category: {lb.classes_[0]}\")\nprint(f\"Total instances: {len(data)}\")\n \n# save as CSV file\ndata.to_csv('data.csv', index=False)\n \nprint(data.head(5))","8f9e457a":"!python preprocess.py","dcc4f955":"%%writefile dataset.py\n\nimport albumentations\nimport numpy as np\nimport torch\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\n# custom dataset\nclass ImageDataset(Dataset):\n    def __init__(self, images, labels=None, tfms=None):\n        self.X = images\n        self.y = labels\n\n        # apply augmentations\n        if tfms == 0: # if validating\n            self.aug = albumentations.Compose([\n                albumentations.Resize(224, 224, always_apply=True),\n            ])\n        else: # if training\n            self.aug = albumentations.Compose([\n                albumentations.Resize(224, 224, always_apply=True),\n                albumentations.HorizontalFlip(p=0.5),\n                albumentations.ShiftScaleRotate(\n                    shift_limit=0.3,\n                    scale_limit=0.3,\n                    rotate_limit=15,\n                    p=0.5\n                ),\n            ])\n         \n    def __len__(self):\n        return (len(self.X))\n    \n    def __getitem__(self, i):\n        image = Image.open(self.X[i])\n        image = image.convert('RGB')\n        image = self.aug(image=np.array(image))['image']\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        label = self.y[i]\n        return {\n            'image': torch.tensor(image, dtype=torch.float), \n            'target': torch.tensor(label, dtype=torch.long)\n        }","bfb4587b":"%%writefile model.py\n\nimport pretrainedmodels\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ResNet50(nn.Module):\n    def __init__(self, pretrained, requires_grad):\n        super(ResNet50, self).__init__()\n        if pretrained is True:\n            self.model = pretrainedmodels.__dict__['resnet50'](pretrained='imagenet')\n        else:\n            self.model = pretrainedmodels.__dict__['resnet50'](pretrained=None)\n            \n        if requires_grad == True:\n            for param in self.model.parameters():\n                param.requires_grad = True\n        elif requires_grad == False:\n            for param in self.model.parameters():\n                param.requires_grad = False\n        \n        self.l0 = nn.Linear(2048, 256)\n\n    def forward(self, x):\n        batch, _, _, _ = x.shape\n        x = self.model.features(x)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n        l0 = self.l0(x)\n        return l0\n\nmodel = ResNet50(pretrained=True, requires_grad=False)\n# print(model)","b2f0034a":"%%writefile engine.py\n\nfrom tqdm import tqdm\n\nimport torch\n\n# training function\ndef fit(model, dataloader, optimizer, criterion, train_data, device, use_amp):\n    print('Training')\n    if use_amp == 'yes':\n        scaler = torch.cuda.amp.GradScaler() \n\n    model.train()\n    train_running_loss = 0.0\n    train_running_correct = 0\n    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)\/dataloader.batch_size)):\n        data, target = data['image'].to(device), data['target'].to(device)\n        optimizer.zero_grad()\n        \n        if use_amp == 'yes':\n            with torch.cuda.amp.autocast():\n                outputs = model(data)\n                loss = criterion(outputs, target)\n        \n        elif use_amp == 'no':\n            outputs = model(data)\n            loss = criterion(outputs, target)\n            \n        train_running_loss += loss.item()\n        _, preds = torch.max(outputs.data, 1)\n        train_running_correct += (preds == target).sum().item()\n        \n        if use_amp == 'yes':\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        \n        elif use_amp == 'no':\n            loss.backward()\n            optimizer.step()\n        \n    train_loss = train_running_loss\/len(dataloader.dataset)\n    train_accuracy = 100. * train_running_correct\/len(dataloader.dataset)    \n    return train_loss, train_accuracy\n\n# validation function\ndef validate(model, dataloader, optimizer, criterion, val_data, device, use_amp):\n    print('Validating')\n    if use_amp == True:\n        scaler = torch.cuda.amp.GradScaler() \n        \n    model.eval()\n    val_running_loss = 0.0\n    val_running_correct = 0\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)\/dataloader.batch_size)):\n            data, target = data['image'].to(device), data['target'].to(device)\n            \n            if use_amp == 'yes':\n                with torch.cuda.amp.autocast():\n                    outputs = model(data)\n                    loss = criterion(outputs, target)\n        \n            elif use_amp == 'no':\n                outputs = model(data)\n                loss = criterion(outputs, target)\n            \n            val_running_loss += loss.item()\n            _, preds = torch.max(outputs.data, 1)\n            val_running_correct += (preds == target).sum().item()\n        \n        val_loss = val_running_loss\/len(dataloader.dataset)\n        val_accuracy = 100. * val_running_correct\/len(dataloader.dataset)        \n        return val_loss, val_accuracy","b2db1c32":"%%writefile train.py\n\nfrom sklearn.model_selection import train_test_split\nfrom model import model\nfrom dataset import ImageDataset\nfrom torch.utils.data import DataLoader\nfrom engine import fit, validate\n\nimport torch.optim as optim\nimport time\nimport torch.nn as nn\nimport argparse\nimport pandas as pd\nimport matplotlib\nimport torch \nimport matplotlib.pyplot as plt\n\n# build and parse the argument parser\nparser = argparse.ArgumentParser()\nparser.add_argument('-b', '--batch-size', dest='batch_size', type=int, \n                    help='batch size for the dataset', default=512)\nparser.add_argument('-a', '--use-amp', dest='use_amp', \n                    help='to use Automatic Mixed Precision or not',\n                    default='yes', choices=['yes', 'no'])\nargs = vars(parser.parse_args())\n\n# learning parameters\nbatch_size = args['batch_size']\nprint(f\"Batch size: {batch_size}\")\nepochs = 5\nlr = 0.0001\nuse_amp = args['use_amp']\nprint(f\"Use AMP: {use_amp}\")\n\n# computation device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# get the dataset ready\ndf = pd.read_csv('data.csv')\nX = df.image_path.values # image paths\ny = df.target.values # targets\n(xtrain, xtest, ytrain, ytest) = train_test_split(X, y,\n\ttest_size=0.10, random_state=42)\nprint(f\"Training instances: {len(xtrain)}\")\nprint(f\"Validation instances: {len(xtest)}\")\ntrain_data = ImageDataset(xtrain, ytrain, tfms=1)\ntest_data = ImageDataset(xtest, ytest, tfms=0)\n# dataloaders\ntrain_data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nvalid_data_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n\n# model\nmodel.to(device)\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=lr)\n# loss function\ncriterion = nn.CrossEntropyLoss()\n# total parameters and trainable parameters\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"{total_params:,} total parameters.\")\ntotal_trainable_params = sum(\n    p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"{total_trainable_params:,} trainable parameters.\")\n\ntrain_loss , train_accuracy = [], []\nval_loss , val_accuracy = [], []\nif use_amp == 'yes':\n    print('Tranining and validating with Automatic Mixed Precision')\nelif use_amp == 'no':\n    print('Tranining and validating without Automatic Mixed Precision')\n    \nstart = time.time()\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch+1} of {epochs}\")\n    train_epoch_loss, train_epoch_accuracy = fit(model, train_data_loader, \n                                                 optimizer, criterion, \n                                                 train_data, device, use_amp)\n    val_epoch_loss, val_epoch_accuracy = validate(model, valid_data_loader, \n                                                 optimizer, criterion, \n                                                 test_data, device, use_amp)\n    train_loss.append(train_epoch_loss)\n    train_accuracy.append(train_epoch_accuracy)\n    val_loss.append(val_epoch_loss)\n    val_accuracy.append(val_epoch_accuracy)\n    print(f\"Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_accuracy:.2f}\")\n    print(f'Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_accuracy:.2f}')\nend = time.time()\n\nprint(f\"Took {((end-start)\/60):.3f} minutes to train for {epochs} epochs\")\n    \n# save model checkpoint\ntorch.save({\n            'epoch': epochs,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': criterion,\n            }, f\"amp_{use_amp}_model.pth\")\n\n# accuracy plots\nplt.figure(figsize=(10, 7))\nplt.plot(train_accuracy, color='green', label='train accuracy')\nplt.plot(val_accuracy, color='blue', label='validataion accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig(f\"amp_{use_amp}_accuracy.png\")\nplt.show()\n \n# loss plots\nplt.figure(figsize=(10, 7))\nplt.plot(train_loss, color='orange', label='train loss')\nplt.plot(val_loss, color='red', label='validataion loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig(f\"amp_{use_amp}_loss.png\")\nplt.show()","c838e5dc":"!python train.py --batch-size 1024 --use-amp no","523f3d18":"# this will show OOM error without AMP\n!python train.py --batch-size 2048 --use-amp no ","fd7d676c":"# double the batch size run perfectly fine with AMP\n!python train.py --batch-size 2048 --use-amp yes","36a8f365":"The following cell block will give OOM error","810f6063":"## <u>Introduction<\/u>\n* Train twice:\n    * Once without mixed precision.\n    * Then once again with mixed precision.\n* Check by how much we can really increase the batch size.\n* Check by how fast is the mixed precision training when compared to normal training."}}