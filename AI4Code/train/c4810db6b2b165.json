{"cell_type":{"55d15f8e":"code","b5cd55b9":"code","a42026e1":"code","ddcbab4c":"code","679e304e":"code","e7752fbc":"code","2d82252d":"code","c704c26f":"code","c4608d73":"code","7e94d466":"code","9d081e41":"code","2d274ca8":"code","9e769dc6":"code","71a2f2e3":"code","03e4f2ee":"code","db84c805":"code","80d61c0f":"code","c8c3eb16":"code","8d07d01e":"code","7a21e82b":"code","6291f9b4":"code","c11a04f7":"code","97730f65":"code","0748e906":"code","f018ef6d":"code","9af5493c":"code","c120da84":"code","44bd8f68":"code","9d09209a":"code","acf1bdea":"code","12df5597":"code","fb5cc7f7":"code","54c2d89f":"code","dff71c76":"code","0e0a4aae":"code","1153383d":"code","0221b536":"code","c02befe3":"code","e99440d9":"code","dcc43e08":"code","5a4bbdc3":"code","f3eb7e80":"code","a3470438":"code","00ffeac6":"code","94769c39":"code","b60af309":"code","f4fa09a6":"code","abf3ca70":"code","15216a9c":"code","8eb0c0bb":"code","3d24b587":"code","aa7b2758":"code","60d66f75":"code","ee4d1440":"code","e1146d53":"code","cf8b5f83":"code","f4088d0d":"code","d66adbec":"code","0179b917":"code","99c13561":"code","74e9da2b":"code","db9a94d4":"code","56c0ff2b":"code","7fb8c15d":"code","0e17f7a4":"code","c4f7e3b4":"code","f0d80fae":"code","0575201d":"code","825a699c":"code","a159c8eb":"code","554603d4":"code","ef9388e3":"markdown","5f3cfad1":"markdown","3bd9046d":"markdown","9fdf2a88":"markdown","2e8d9c0b":"markdown","0a8c2c76":"markdown","91055885":"markdown","50ada1c2":"markdown","1c3f31e6":"markdown","cd76effb":"markdown","393a4ab3":"markdown","75486d83":"markdown","669e1386":"markdown"},"source":{"55d15f8e":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.svm import SVC\nfrom imblearn.combine import SMOTETomek\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom scipy.stats import probplot","b5cd55b9":"# download link:   https:\/\/www.kaggle.com\/andrewmvd\/heart-failure-clinical-data\/download\n# api command to download data:   kaggle datasets download -d andrewmvd\/heart-failure-clinical-data\n\ndf = pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\ndf.head()","a42026e1":"df.info()\n# all are numeric features\n# no null values...","ddcbab4c":"# lets check for suspicious values that can be null\ndf.describe()","679e304e":"# sns.pairplot(df)","e7752fbc":"for i in df.columns:\n    cat_num = df[i].value_counts()\n    print(\"graph for %s: total = %d\" % (i, len(cat_num)))\n    chart = sns.barplot(x=cat_num.index, y=cat_num)\n    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n    plt.show()","2d82252d":"plt.figure(figsize=(15,15))\nsns.heatmap(df.corr(), annot=True);","c704c26f":"df.boxplot(['age']);","c4608d73":"df.boxplot(['creatinine_phosphokinase']); # outliers... log transform","7e94d466":"df.boxplot(['ejection_fraction'])","9d081e41":"df.boxplot(['platelets'])   # outliers","2d274ca8":"df.boxplot(['serum_creatinine'])   # outliers","9e769dc6":"df.boxplot(['serum_sodium'])","71a2f2e3":"df.boxplot(['time'])","03e4f2ee":"df.describe()","db84c805":"probplot(df['age'],plot=plt);","80d61c0f":"probplot(df['platelets'],plot=plt);","c8c3eb16":"probplot(df['creatinine_phosphokinase'],plot=plt);","8d07d01e":"sns.distplot(df['creatinine_phosphokinase'])","7a21e82b":"probplot(np.log(df['creatinine_phosphokinase']),plot=plt);","6291f9b4":"sns.distplot(np.log(df['creatinine_phosphokinase']));","c11a04f7":"df['creatinine_phosphokinase'] = np.log(df['creatinine_phosphokinase'])","97730f65":"probplot(df['ejection_fraction'],plot=plt);","0748e906":"probplot(df['serum_creatinine'],plot=plt);","f018ef6d":"sns.distplot(df['serum_creatinine'])","9af5493c":"probplot(np.log(df['serum_creatinine']),plot=plt);","c120da84":"sns.distplot(np.log(df['serum_creatinine']));","44bd8f68":"df[df['creatinine_phosphokinase'] == 7861.000000]","9d09209a":"df[df['platelets'] == 850000.000000]","acf1bdea":"df.drop([1,109], inplace=True)","12df5597":"X = df.iloc[:,:-1]\ny = df.iloc[:,-1]\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nX_scaled = pd.DataFrame(X_scaled,columns=df.columns[:-1])\n","fb5cc7f7":"probplot(X_scaled['serum_creatinine'],plot=plt);","54c2d89f":"# from sklearn.preprocessing import MinMaxScaler\n\n# min_max = MinMaxScaler()\n# s_c_scaled = min_max.fit_transform(X_scaled[['serum_creatinine']])\n# s_c , _ = boxcox(s_c_scaled.T[0])\n# probplot(s_c,plot=plt);","dff71c76":"X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.3,random_state=3)","0e0a4aae":"log_clf = LogisticRegression()\nlog_clf.fit(X_train,y_train)\nlog_pred = log_clf.predict(X_test)\nlog_clf.score(X_test,y_test)","1153383d":"dt_clf = DecisionTreeClassifier()\ndt_clf.fit(X_train,y_train)\ndt_clf.score(X_test,y_test)","0221b536":"kn_clf = KNeighborsClassifier()\nkn_clf.fit(X_train,y_train)\nkn_clf.score(X_test,y_test)","c02befe3":"from sklearn.metrics import confusion_matrix\n\nconfusion_matrix(log_pred,y_test)","e99440d9":"log_clf = RidgeClassifier()\nlog_clf.fit(X_train,y_train)\nlog_pred = log_clf.predict(X_test)\nlog_clf.score(X_test,y_test)","dcc43e08":"\nrf_clf = RandomForestClassifier()\nrf_clf.fit(X_train,y_train)\nrf_clf.score(X_test,y_test)","5a4bbdc3":"# n_estimators = [10, 100, 1000]\n# max_features = ['sqrt', 'log2']\n# # define grid search\n# grid = dict(n_estimators=n_estimators,max_features=max_features)\n# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# grid_search = GridSearchCV(estimator=rf_clf, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n# grid_result = grid_search.fit(X, y)","f3eb7e80":"# grid_result.best_estimator_","a3470438":"rf_clf = RandomForestClassifier(max_features='log2', n_estimators=1000)\nrf_clf.fit(X_train,y_train)\nrf_clf.score(X_test,y_test)","00ffeac6":"kn_clf = KNeighborsClassifier()\nkn_clf.fit(X_scaled,y)","94769c39":"kn_clf.predict(X_scaled)","b60af309":"len(kn_clf.classes_)","f4fa09a6":"df['knn_clf'] = kn_clf.predict(X_scaled)","abf3ca70":"df1 = df[df['knn_clf'] == 1].iloc[:,:-1]\ndf2 = df[df['knn_clf'] == 0].iloc[:,:-1]","15216a9c":"X1 = df.iloc[:,:-1]\ny1 = df.iloc[:,-1]\n\nscaler = StandardScaler()\nX_scaled1 = scaler.fit_transform(X1)\n\nX_scaled1 = pd.DataFrame(X_scaled1,columns=df.columns[:-1])\n\nX2 = df.iloc[:,:-1]\ny2 = df.iloc[:,-1]\n\nscaler = StandardScaler()\nX_scaled2 = scaler.fit_transform(X2)\n\nX_scaled2 = pd.DataFrame(X_scaled2,columns=df.columns[:-1])\n\nX_train1,X_test1,y_train1,y_test1 = train_test_split(X_scaled1,y1,test_size=0.3,random_state=3)\nX_train2,X_test2,y_train2,y_test2 = train_test_split(X_scaled2,y2,test_size=0.3,random_state=3)","8eb0c0bb":"def try_models(Xtr,Xts,ytr,yts):\n    for model in [LogisticRegression(),DecisionTreeClassifier(),RandomForestClassifier(),KNeighborsClassifier(n_neighbors=2)]:\n        print(model)\n        model.fit(Xtr,ytr)\n        print(model.score(Xts,yts))\n        y_pred = model.predict(Xts)\n        print(confusion_matrix(y_pred,yts))\n        print()","3d24b587":"print(\"class 1: ***********************************\")\ntry_models(X_train1,X_test1,y_train1,y_test1)\nprint(\"class 2: ***********************************\")\ntry_models(X_train2,X_test2,y_train2,y_test2)","aa7b2758":"y_tests = []\ny_preds = []\n# for i in range(2):\nmodel = RandomForestClassifier(max_features='log2', n_estimators=1000)\nmodel.fit(X_train1,y_train1)\ny_preds.extend(model.predict(X_test1))\ny_tests.extend(y_test1)\nmodel = RandomForestClassifier(max_features='log2', n_estimators=1000)\nmodel.fit(X_train2,y_train2)\ny_preds.extend(model.predict(X_test2))\ny_tests.extend(y_test2)\n\nprint(accuracy_score(y_preds,y_tests))\nprint(confusion_matrix(y_preds,y_tests))","60d66f75":"df.DEATH_EVENT.value_counts()","ee4d1440":"!pip install imblearn","e1146d53":"smt = SMOTETomek(random_state=42)\nX_res,y_res = smt.fit_resample(X,y)","cf8b5f83":"pd.DataFrame(y_res)['DEATH_EVENT'].value_counts()","f4088d0d":"def clustering_approach(X,y, models,type = \"none\"):\n    \n    dfs = {}\n    X_cls = {}\n    y_cls = {}\n    X_scaled = {}\n    X_train, X_test, y_train, y_test = {},{},{},{}\n    y_pred = {}\n    models_out = {}\n    \n    # create knn model and predict\n    knn_clf = KNeighborsClassifier()\n    knn_clf.fit(X,y)\n    df = pd.concat([X,y],axis=1) # so we can later separate x and y for each cluster\n    df['knn_clf'] = knn_clf.predict(X)\n    no_cls = knn_clf.classes_\n    \n    # get the dataframes, apply std.scaler, form train, test sets, apply models\n    for cls in knn_clf.classes_:\n        print(\"--------------The {} cluster's results-------------------\".format(cls),end=\"\\n\\n\")\n        dfs[cls] = df[df['knn_clf'] == cls].iloc[:,:-1]\n        \n        X_cls[cls] = dfs[cls].iloc[:,:-1]\n        y_cls[cls] = dfs[cls].iloc[:,-1]\n        scaler = StandardScaler()\n        X_scaled[cls] = scaler.fit_transform(X_cls[cls])\n#         X_scaled[cls] = pd.DataFrame(X_scaled[cls],columns=df.columns[:-1])\n    \n        X_train[cls],X_test[cls],y_train[cls],y_test[cls] = train_test_split(X_scaled[cls],y_cls[cls],test_size=0.3,random_state=3)\n        print(\"here\")\n        # type can be used for analyzing... eg: confusion matrix\n        for model in models:\n            model.fit(X_train[cls], y_train[cls])\n            y_pred[cls] = model.predict(X_test[cls])\n            print(model)\n            print(model.score(X_test[cls],y_test[cls]))\n            print(confusion_matrix(y_pred[cls], y_test[cls]), end=\"\\n\\n\")\n            models_out[str(model) + str(cls)] = model\n            \n    \n    return [X_train, X_test, y_train, y_test,knn_clf, models_out]\n        \n","d66adbec":"!pip install lightgbm","0179b917":"mutual_info_vals = mutual_info_classif(X_res,y_res)\nmutual_val_df = pd.DataFrame({\"vals\":mutual_info_vals},index=X.columns) # we're keeping the passenger id\nplt.figure(figsize=(10,5))\nmutual_val_df.vals.sort_values(ascending=False).plot(kind='bar');\n","99c13561":"X_res[['time','serum_creatinine','ejection_fraction','platelets','age','serum_sodium','creatinine_phosphokinase']].head()","74e9da2b":"\nmodels = [LogisticRegression(), RandomForestClassifier(), KNeighborsClassifier(), XGBClassifier(verbosity = 0),LGBMClassifier(),SVC()] \nX_train, X_test, y_train, y_test,clusterer, models = clustering_approach(X_res[['time','serum_creatinine','ejection_fraction','platelets','age','serum_sodium','creatinine_phosphokinase']],y_res,models)\n","db9a94d4":"# n_estimators = [10, 100, 1000,1500]\n# max_features = np.arange(1,20)\n# # define grid search\n# grid = dict(n_estimators=n_estimators,max_features=max_features)\n# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n# grid_result = grid_search.fit(X_res, y_res)\n","56c0ff2b":"# grid_result.best_estimator_","7fb8c15d":"# grid_result = grid_search.fit(X_train[1], y_train[1])\n# grid_result.best_estimator__","0e17f7a4":"len(X_train)","c4f7e3b4":"\n\ny_tests = []\ny_preds = []\ni=0\nmodel = XGBClassifier(verbosity = 0)\nmodel.fit(X_train[i],y_train[i])\ny_preds.extend(model.predict(X_test[i]))\ny_tests.extend(y_test[i])\ni=1\nmodel = RandomForestClassifier(max_features='log2', n_estimators=1000)\nmodel.fit(X_train[i],y_train[i])\ny_preds.extend(model.predict(X_test[i]))\ny_tests.extend(y_test[i])\n    \nprint(accuracy_score(y_preds,y_tests))\nprint(confusion_matrix(y_preds,y_tests))","f0d80fae":"models['RandomForestClassifier()0']","0575201d":"models['RandomForestClassifier()1']","825a699c":"clusterer","a159c8eb":"# import joblib","554603d4":"# model = clusterer\n# filename = \"clusterer\" \n# joblib.dump(model, filename)\n\n# model = models['RandomForestClassifier()0']\n# filename = \"RF_model1\"\n# joblib.dump(model, filename)\n\n# model = models['RandomForestClassifier()1']\n# filename = \"RF_model2\"\n# joblib.dump(model, filename)","ef9388e3":"### Lets find the total accuarcy and performance now!","5f3cfad1":"### Lets find the best params for our models....","3bd9046d":"### lets work on hyper parameter tuning of Logistic regression","9fdf2a88":"### creatinine_phosphokinase: In summary, renal injury with high serum CPK values becomes a true concern when levels of CPK reach 5,000 IU\/L and the patient has serious co-morbid disease such as volume depletion, sepsis or acidosis. Otherwise, values of up to 20,000 IU\/L may be tolerated without untoward event.\n\n","2e8d9c0b":"### Using knn for clustering approach","0a8c2c76":"### Treat imbalanced dataset","91055885":"### Lets try to balance our dataset and see what comes...","50ada1c2":"### random forest grid search","1c3f31e6":"### knn seems to perform well with a accuracy of 86%","cd76effb":"### i want to try logistic regression so i wanted to drop these values... but we already have less values so we'll just scale these and create a model","393a4ab3":"### Looks like random forest has worked out for both the clusters","75486d83":"### although we've go 4 False negatives... we have gotten more of False positives...","669e1386":"### 1 means a person is dead and 0 means alive... we have less number of deaths but still our death classification is better then not_dead classification... "}}