{"cell_type":{"9f3e30ec":"code","5dcff669":"code","c16825a0":"code","2cb801a0":"code","20624502":"code","381e2fc0":"code","432d8f89":"code","725bf3f9":"code","a40b7490":"code","00e39895":"code","bcbff70e":"code","93d7e313":"code","45b06c88":"code","56da777a":"code","b06766d7":"code","179d26fe":"code","f4cb8bd7":"code","9cf3376d":"code","43e681f6":"code","2923db3a":"code","72ae9f8c":"code","1598bd2f":"code","bf519ed9":"code","7ef18c66":"code","c6d78518":"code","5af8a531":"code","0855b08d":"markdown","e5c6aa2b":"markdown","3d2bc780":"markdown"},"source":{"9f3e30ec":"import numpy as np\nimport pandas as pd\nfrom catboost import CatBoostClassifier, CatBoostRegressor, Pool, cv, sum_models\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport random\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5dcff669":"train = pd.read_csv('\/kaggle\/input\/realestatepriceprediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/realestatepriceprediction\/test.csv')\ntest['Price'] = ''\ncombine = [train, test]\ncombine = pd.concat(combine, ignore_index=True)\n\n# \u043f\u0435\u0440\u0435\u043d\u0435\u0441\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 \u0441 \u0442\u0430\u0440\u0433\u0435\u0442\u043e\u043c \u043d\u0430 \u043f\u0435\u0440\u0432\u043e\u0435 \u043c\u0435\u0441\u0442\u043e\ncols = combine.columns.tolist()\ncols = cols[-1:] + cols[:-1]\ncombine = combine[cols]\n\ncombine","c16825a0":"combine.info()","2cb801a0":"plt.figure(figsize = (16, 4))\n\nplt.subplot(121)\ncombine['Square'][:10000].hist(density=True)\nplt.ylabel('count')\nplt.xlabel('Square \/ train')\n\nplt.subplot(122)\nsns.kdeplot(combine['Square'][:10000], shade=True, legend=False)\nplt.xlabel('Square \/ train')\n\nplt.suptitle('Distribution of Square \/ train')\nplt.show()\n\n#\n\nplt.figure(figsize = (16, 4))\n\nplt.subplot(121)\ncombine['Square'][10000:].hist(density=True)\nplt.ylabel('count')\nplt.xlabel('Square \/ test')\n\nplt.subplot(122)\nsns.kdeplot(combine['Square'][10000:], shade=True, legend=False)\nplt.xlabel('Square \/ test')\n\nplt.suptitle('Distribution of Square \/ test')\nplt.show()","20624502":"# #scatter plot totalbsmtsf\/saleprice\nvar = 'Square'\ndata = pd.concat([combine[:10000].loc[combine['Rooms'] < 200]['Price'], combine[:10000].loc[combine['Rooms'] < 200][var]], axis=1)\ndata.plot.scatter(x=var, y='Price', ylim=(0,800000));","381e2fc0":"# \u0417\u0430\u043c\u0435\u043d\u044f\u0435\u043c \u043f\u0443\u0441\u0442\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0441\u0440\u0435\u0434\u043d\u0438\u043c\u0438\ncombine['LifeSquare'].fillna(value=combine['LifeSquare'].mean(), inplace=True)\ncombine['Healthcare_1'].fillna(value=combine['Healthcare_1'].mean(), inplace=True)\n\ncombine.isnull().sum().sum()","432d8f89":"combine.nunique()","725bf3f9":"# \u0417\u0430\u043c\u0435\u043d\u044f\u0435\u043c Rooms == 0 \u043d\u0430 1\ncombine.at[combine.query('Rooms == 0').index, 'Rooms'] = 1\n\n# \u0417\u0430\u043c\u0435\u043d\u044f\u0435\u043c Rooms > 6 \u043d\u0430 2\ncombine.at[combine.query('Rooms > 6').index, 'Rooms'] = 2","a40b7490":"plt.figure(figsize = (16, 4))\n\nplt.subplot(121)\ncombine.loc[combine['KitchenSquare'] < 25, 'KitchenSquare'][:10000].hist(density=True)\nplt.ylabel('count')\nplt.xlabel('KitchenSquare \/ train')\n\nplt.subplot(122)\nsns.kdeplot(combine.loc[combine['KitchenSquare'] < 25, 'KitchenSquare'][:10000], shade=True, legend=False)\nplt.xlabel('KitchenSquare \/ train')\n\nplt.suptitle('KitchenSquare of Square \/ train')\nplt.show()\n\n#\n\nplt.figure(figsize = (16, 4))\n\nplt.subplot(121)\ncombine.loc[combine['KitchenSquare'] < 25, 'KitchenSquare'][10000:].hist(density=True)\nplt.ylabel('count')\nplt.xlabel('KitchenSquare \/ test')\n\nplt.subplot(122)\nsns.kdeplot(combine.loc[combine['KitchenSquare'] < 25, 'KitchenSquare'][10000:], shade=True, legend=False)\nplt.xlabel('KitchenSquare \/ test')\n\nplt.suptitle('Distribution of KitchenSquare \/ test')\nplt.show()","00e39895":"# \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0444\u0438\u0447\u0438\ncombine['squ_room'] = (combine['Square'] \/ combine['Rooms']).astype('float')","bcbff70e":"target = 'Price'\nnumfeat, catfeat = list(combine.select_dtypes(include=np.number))[1:], list(combine.select_dtypes(exclude=np.number))\ncatfeat.remove(target)\nprint(numfeat)\nprint(catfeat)","93d7e313":"# \u0423\u0434\u0430\u043b\u044f\u0435\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u044b\n\nto_drop1 = combine[:10000].query('Square > 200').index\nto_drop2 = combine[:10000].query('LifeSquare > 200 & Rooms < 4').index\nto_drop3 = combine[:10000].query('KitchenSquare > 200').index\nto_drop4 = combine[:10000].query('HouseYear > 2020').index\nto_drop5 = combine[:10000].query('(Square < 13) | (Square < 20 & Rooms > 1)').index\n\ncombine.drop(list(to_drop1) + list(to_drop2) + list(to_drop3) + list(to_drop4) + list(to_drop5), axis=0, inplace=True)\n\nto_replace1 = combine[10000:].query('KitchenSquare > 200').index\ncombine.at[to_replace1, 'KitchenSquare'] = 24","45b06c88":"# \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0444\u0438\u0447\u0438\ncombine['squ_room'] = (combine['Square'] \/ combine['Rooms']).astype('float')\ncombine['squ_room']","56da777a":"len_combine = len(combine)\nlen_test = 5000\nlen_validate = 3000\nlen_train = len_combine - (len_test+ len_validate)\nprint(len_combine)\nprint(len_test)\nprint(len_validate)\nprint(len_train)","b06766d7":"# \u0421\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u043e \u0447\u0438\u0441\u043b\u043e\u0432\u044b\u0435 \u0441\u043b\u043e\u043b\u0431\u0446\u044b \u0434\u043b\u044f \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445\nfor n in numfeat:\n    combine[n + '_num'] = combine[n]","179d26fe":"combine['Rooms'] = combine['Rooms'].astype('int')\ncombine['KitchenSquare'] = combine['KitchenSquare'].astype('int')\ncombine['HouseFloor'] = combine['HouseFloor'].astype('int')\ncombine['Square'] = combine['Square'].astype('int')\ncombine['Ecology_1'] = (combine['Ecology_1'] * 1000000).astype('int')\ncombine['LifeSquare'] = combine['LifeSquare'].astype('int')\ncombine[numfeat] = combine[numfeat].astype('str')","f4cb8bd7":"numfeat, catfeat = list(combine.select_dtypes(include=np.number))[1:], list(combine.select_dtypes(exclude=np.number))\ncatfeat.remove(target)\nprint(numfeat)\nprint(catfeat)","9cf3376d":"corr = combine.corr()\nfig, ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(corr, cmap='RdBu', annot=True, fmt=\".2f\")\nplt.xticks(range(len(corr.columns)), corr.columns);\nplt.yticks(range(len(corr.columns)), corr.columns)\nplt.show()","43e681f6":"train_data = combine[:len_train]\nvalidate_data = combine[len_train:len_train + len_validate]\ncv_data = combine[:len_train + len_validate]\ntest_data = combine[len_train + len_validate:]","2923db3a":"features = train_data.iloc[:, 2:].values\nlabels = train_data.loc[:, 'Price'].values\nfeatures2 = validate_data.iloc[:, 2:].values\nlabels2 = validate_data.loc[:, 'Price'].values\nfeatures_test = test_data.iloc[:, 2:].values\nfeatures_cv = cv_data.iloc[:, 2:].values\nlabels_cv = cv_data.loc[:, 'Price'].values\nprint(features.shape, labels.shape, features2.shape, labels2.shape, features_test.shape, features_cv.shape)","72ae9f8c":"X_train = features\nX_validation = features2\ny_train = labels\ny_validation = labels2\nX_cv = features_cv\ny_cv = labels_cv\nprint(X_train.shape, X_validation.shape, y_train.shape, y_validation.shape, X_cv.shape)\n\n# from sklearn.model_selection import train_test_split\n# X_train, X_validation, y_train, y_validation = train_test_split(features_cv, labels_cv, train_size=0.7, random_state=100, shuffle=True)\n# print(X_train.shape, X_validation.shape, y_train.shape, y_validation.shape, X_cv.shape)","1598bd2f":"cat_features = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n\n\ntrain_dataset = Pool(data=X_train,\n                     label=y_train,\n                     cat_features=cat_features)\n\neval_dataset = Pool(data=X_validation,\n                    label=y_validation,\n                    cat_features=cat_features)\n\nmodel = CatBoostRegressor(iterations=20000,\n                           grow_policy=\"Depthwise\",\n                           loss_function = 'RMSE',\n                           eval_metric = 'R2',\n                           early_stopping_rounds = 1000,\n                           task_type=\"GPU\", # \u0437\u0430\u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c, \u0435\u0441\u043b\u0438 \u043d\u0435 \u043d\u0430 GPU\n                           devices='0', # \u0437\u0430\u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c, \u0435\u0441\u043b\u0438 \u043d\u0435 \u043d\u0430 GPU\n                           verbose = False,\n                           use_best_model=True\n                         )\n\n# Fit model\nmodel.fit(train_dataset, eval_set=eval_dataset, logging_level='Silent', plot=True)","bf519ed9":"model.best_iteration_","7ef18c66":"# model.get_feature_importance(eval_dataset, prettified=True)\n\nfeats = {}\nfor feature, importance in zip(combine.iloc[:, 2:].columns, model.feature_importances_):\n    feats[feature] = importance\nimportances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-Importance'})\nimportances = importances.sort_values(by='Gini-Importance', ascending=False)\nimportances = importances.reset_index()\nimportances = importances.rename(columns={'index': 'Features'})\nsns.set(font_scale = 5)\nsns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.7)\nfig, ax = plt.subplots()\nfig.set_size_inches(30,15)\nsns.barplot(x=importances['Gini-Importance'], y=importances['Features'], data=importances, color='skyblue')\nplt.xlabel('Importance', fontsize=25, weight = 'bold')\nplt.ylabel('Features', fontsize=25, weight = 'bold')\nplt.title('Feature Importance', fontsize=25, weight = 'bold')\ndisplay(plt.show())\ndisplay(importances)","c6d78518":"Y_hat_train = [yhat for yhat in model.predict(X_train)]\nY_hat = [yhat for yhat in model.predict(X_validation)]\n\nfrom sklearn.metrics import r2_score\nprint(r2_score(y_train, Y_hat_train))\nprint(r2_score(y_validation, Y_hat))","5af8a531":"# Get predicted classes\npreds_class = model.predict(features_test)\npred = [value for value in preds_class]\n\nsubmission = pd.DataFrame({\n        \"Id\": test_data[\"Id\"],\n        \"Price\": pred\n    })\nsubmission.to_csv('prediction.csv', index=False)\nsubmission.values","0855b08d":"### Predict","e5c6aa2b":"### Python for Data Science: \u043a\u0443\u0440\u0441\u043e\u0432\u043e\u0439 \u043f\u0440\u043e\u0435\u043a\u0442","3d2bc780":"### \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c"}}