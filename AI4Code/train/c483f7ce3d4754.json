{"cell_type":{"a54968b7":"code","9553fe59":"code","818614f2":"code","78ed87d0":"markdown"},"source":{"a54968b7":"import os\n\nfrom transformers import *\n\nMODEL_NAME = 'allenai\/longformer-base-4096'","9553fe59":"#os.mkdir('longformer')\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ntokenizer.save_pretrained('..\/working')\n\nconfig = AutoConfig.from_pretrained(MODEL_NAME)\nconfig.save_pretrained('..\/working')\n\nbackbone = TFAutoModel.from_pretrained(MODEL_NAME)\nbackbone.save_pretrained('..\/working')","818614f2":"# Upload to Kaggle Dataset\n","78ed87d0":"# HuggingFace Transformer\n\nDownload 3 files from HuggingFace for AllenAI's model **longformer-base**\n\n* tokenizer files\n    - special_token_map.json\n    - merges.txt\n    - vocab.json\n    - tokenizer_config.json\n    - tokenizer.json\n* config file\n    - config.json\n* model weights file\n    - tf_model.h5"}}