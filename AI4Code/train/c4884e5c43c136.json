{"cell_type":{"538ee8ed":"code","f3a8e07a":"code","aa0deea8":"code","c26326d8":"code","5974dad2":"code","37ff02ca":"code","d6f29374":"code","1a274855":"code","cc340887":"code","8b46e26e":"code","67d8088b":"code","3824c724":"code","14fe763c":"code","81ed74d9":"code","ad800e6e":"code","7f95c8dc":"code","7008bdee":"code","46c07960":"code","ef11ae02":"code","4c249c4e":"code","07861fd7":"code","189728e8":"code","22dbbbcb":"code","3704f221":"code","93700314":"code","f0e848cb":"code","43de085c":"code","ce2a576f":"code","5cf21496":"code","927a526a":"code","3b577686":"code","46c911a7":"code","fba82ce1":"code","901c2115":"code","8327b185":"code","fb6fd9b1":"code","0724a157":"code","f8dcedb5":"code","b01aebfc":"code","4d7e1c55":"code","fca6e221":"code","27487a9c":"code","da33b82c":"code","17067fe4":"code","779c422e":"code","7fd3a500":"code","b053804d":"code","2ead5dd9":"code","7206601a":"code","c5d6bc0e":"code","32cb31b8":"code","24943ce7":"code","56b0bd7b":"code","fe3831c9":"code","09e2885e":"code","712cc0d1":"code","527ddf1d":"code","c24b54d0":"code","a3d500a4":"code","e5917e73":"code","77deda00":"code","eebc1ed6":"code","0cdb244a":"code","e0230b5c":"code","7f0a9f9f":"code","83f27da8":"code","c6ea73bd":"code","200533c7":"code","db225b3b":"code","39167d53":"code","5e422859":"code","f0a73eba":"code","70201fd5":"code","49dc8aac":"code","530cd03f":"code","9b49c29d":"code","2716791a":"code","9449ce46":"code","858365df":"code","0132fd6c":"code","341f07ef":"code","685cf036":"code","ec489f34":"code","f6ba2fe5":"code","8ff062a8":"code","d597cfbe":"code","5abb46a4":"code","2a03dccf":"code","2b459267":"code","31e69af4":"code","9a4b6929":"code","51876f38":"code","8867013c":"code","962e49f1":"code","72dbb7b2":"code","4083d157":"code","52cd04a1":"code","23442fab":"code","29d9bdf0":"code","e737c5bb":"code","7b9eb035":"code","128cd9e4":"code","2982ca9d":"code","cc6b9603":"code","f002012a":"code","a318ad17":"code","abee8106":"code","ddb81696":"code","397ffde9":"code","424e802e":"code","0d3e9d7a":"code","2712986a":"code","7ec243bf":"code","ae8198c9":"code","7951e00d":"code","e5f916c2":"code","c6102bff":"code","7a91203d":"code","fbaedfa3":"code","61564353":"code","759d03cd":"code","3376a074":"code","78c00ddf":"code","c6fa40d4":"code","2405282a":"code","2bd9d0c2":"code","1b52b868":"code","16940910":"code","c800450f":"code","5bb20f96":"code","b417907f":"code","1969a28f":"code","dc3292cf":"code","c6b4433d":"code","50036dc4":"code","2d8bb2f4":"code","3d0fda44":"code","79f60404":"code","f9ef36aa":"code","733b2286":"code","eeee5e53":"code","5f29ef84":"code","2f86568b":"code","d806b16b":"code","b72829e1":"code","e67ce2da":"code","552a4294":"code","004ccd32":"code","3c7cffc7":"code","ee4a0930":"code","9411ba15":"code","a112bd7d":"code","b2a9fa39":"code","25d2ec80":"code","a51ae88b":"code","da98108a":"code","0a58ffc5":"code","0118f7a1":"code","eb7af156":"code","d7eabce8":"code","142f7516":"code","123ccda4":"code","4c370ec0":"code","6411df5d":"code","5a981474":"code","09261bb7":"code","15aa16c9":"code","522fd6ea":"code","42aa59e5":"code","ff116c08":"code","fe0d4f57":"code","1e328cbe":"code","7db1abd2":"code","287d3cc0":"code","ddb2a9f8":"code","cedbfbf3":"code","94cefe23":"code","b0bfdbcd":"code","13a069ab":"code","bb4b5cb3":"code","c6f7d679":"code","03737e92":"code","d01d2c13":"code","c049c035":"code","d7b3c517":"code","fd1b06ae":"code","2f044832":"code","e48dca02":"code","d7060725":"code","2212cb5f":"markdown","b6656e94":"markdown","b30f9e17":"markdown","d768c771":"markdown","86f3aebc":"markdown","45b74f76":"markdown","3ee35ec0":"markdown","845ffacf":"markdown","fba8f71b":"markdown","42a701ae":"markdown","8a3df3ec":"markdown","4ef115b8":"markdown","8dbf39ee":"markdown","95f32a9b":"markdown","7f15ee6e":"markdown","5fc7b6dd":"markdown","e5b54592":"markdown","c1521481":"markdown","d5801f9b":"markdown","4feef9df":"markdown","8bf90ea0":"markdown","9abcf4b0":"markdown","00f7ab9e":"markdown","5ee58bce":"markdown","11afde3f":"markdown","e3d8e3c7":"markdown","f33adb13":"markdown","72cdc936":"markdown","60125d4b":"markdown","b1b2e1a5":"markdown","2cc889c9":"markdown","6cce48ec":"markdown","45f0a408":"markdown","ad2672a1":"markdown","cfe5acb4":"markdown","56db8b99":"markdown","67395185":"markdown","8ebd2d11":"markdown","45134f59":"markdown","4a9878ef":"markdown","ecc1a2e5":"markdown","f766c32b":"markdown","59d50f63":"markdown","0d3b844b":"markdown","c946acdb":"markdown","dc8db5fd":"markdown","822beeb0":"markdown","c7b45f47":"markdown","3d28d8f1":"markdown","581bd955":"markdown","c2cc7d6b":"markdown","e6bfd734":"markdown"},"source":{"538ee8ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f3a8e07a":"#Importing python libraries\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import preprocessing\nimport matplotlib.pylab as pylab\nimport matplotlib.pyplot as plt\nfrom pandas import get_dummies\nimport matplotlib as mpl\nimport xgboost as xgb\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport warnings\nimport sklearn\nimport scipy\nimport numpy\nimport json\nimport sys\nimport csv\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import Perceptron\nimport os\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn import linear_model","aa0deea8":"pd.set_option('display.max_rows',10)#So that we can see the whole dataset at one go","c26326d8":"# import train and test to play with it\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')","5974dad2":"#get the type\ntype(train_df)","37ff02ca":"\ntest_df.info()","d6f29374":"train_df.info()","1a274855":"test_df['Survived'] = -888 #Adding Survived with a default value","cc340887":"test_df.info()","8b46e26e":"#test_df.head()\ntrain_df.head()","67d8088b":"train_df = train_df[['PassengerId','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Survived']]","3824c724":"\n#Concatinating two data frames(train and test)\ndf = pd.concat((train_df,test_df),axis = 0)\n\ndf = df.reset_index()\n","14fe763c":"df.info()","81ed74d9":"df = df.drop(['index'],axis=1)\n\ndf.head()\n","ad800e6e":"df = df.set_index('PassengerId')\ndf.tail()","7f95c8dc":"\n\n\ndf.Name.head()","7008bdee":"df.loc[5:10]","46c07960":"#indexing : use iloc based indexing","ef11ae02":"df.iloc[5:10,3:8]","4c249c4e":"#filter rows based on the condition\nmale_passengers = df.loc[df.Sex =='male',:]\nprint('Number of male passengers : {0}'.format(len(male_passengers)))\n","07861fd7":"#use & or | operators to build complex logic","189728e8":"male_passengers_first_class = df.loc[((df.Sex =='male') &(df.Pclass == 1)),:]","22dbbbcb":"print('Number of passengers in first class:{0}'.format(len(male_passengers_first_class)))","3704f221":"# use .describe() to get statistics for all numeric columns\ndf.describe()","93700314":"df.isnull().sum()","f0e848cb":"#Numerical feature\n#centrality measures","43de085c":"print('Mean Fare : {0}'.format(df.Fare.mean()))\nprint('Median Fare : {0}'.format(df.Fare.median()))\n","ce2a576f":"#dispersion measure\nprint('Max fare  : {0}'.format(df.Fare.max()))#max\nprint('Min fare  : {0}'.format(df.Fare.min()))#max\nprint('Fare range  : {0}'.format(df.Fare.max() - df.Fare.min()))#range\nprint('25 percentile  : {0}'.format(df.Fare.quantile(.25)))#25 percentile\nprint('50 percentile  : {0}'.format(df.Fare.quantile(.50)))#50 percentile\nprint('75 percentile  : {0}'.format(df.Fare.quantile(.75)))#75 percentile\nprint('Variance fare: {0}'.format(df.Fare.var()))#variance\nprint('Standard deviation  : {0}'.format(df.Fare.std()))#standard deviation\n\n\n","5cf21496":"# box-whiskers plot\ndf.Fare.plot(kind='box')","927a526a":"#use describe to get statistics for all columns including non-numeric ones\ndf.describe(include='all')","3b577686":"\ndf.Sex.value_counts()","46c911a7":"df.Sex.value_counts(normalize = True)","fba82ce1":"df[df.Survived != -888].Survived.value_counts()","901c2115":"df.Pclass.value_counts()","8327b185":"#Visualize Sex count,Survived and Class wise survival\ndf.Sex.value_counts().plot(kind='bar');","fb6fd9b1":"df[df.Survived != -888].Survived.value_counts().plot(kind='bar');","0724a157":"df.Pclass.value_counts().plot(kind='bar');","f8dcedb5":"\n\ndf.Pclass.value_counts().plot(kind='bar',rot = 0,title = \"Pclass count on Titanic\");","b01aebfc":"#for univariate distributions we use Histogram and KDE\n#KDE stands for Kerenl Density Estimation","4d7e1c55":"df.Age.plot(kind ='hist',title = 'histogram for Age' );","fca6e221":"df.Age.plot(kind ='kde',title = 'histogram for Age' );","27487a9c":"df.Fare.plot(kind ='hist',title = 'histogram for Age' );","da33b82c":"#We use bivariate distribution for Scatter plot","17067fe4":"df.plot.scatter(x='Age',y='Fare',title='Scatter Plot:Age vs Fare');","779c422e":"df.plot.scatter(x='Age',y='Fare',title='Scatter Plot:Age vs Fare',alpha = 0.5);","7fd3a500":"df.plot.scatter(x='Pclass',y='Fare',title='Scatter Plot:Pclass vs Fare');","b053804d":"df.groupby('Sex').Age.median()","2ead5dd9":"#group by\ndf.groupby('Pclass').Fare.median()","7206601a":"\n\n\ndf.groupby('Pclass').Age.median()","c5d6bc0e":"df.groupby(['Pclass'])['Fare','Age'].median()","32cb31b8":"\n\n\ndf.groupby(['Pclass']).agg({'Fare':'mean','Age':'median'})","24943ce7":"# more complicated aggregation\naggregations ={\n    'Fare': {#work on fare column\n        'mean_Fare':'mean',\n        'median_Fare':'median',\n        'Max_Fare':max,\n        'Min_Fare' :np.min\n    },\n    'Age': {\n        'mean_Age':'mean',\n        'median_Age':'median',\n        'Max_Age':max,\n        'Min_Age' :np.min\n    }\n}","56b0bd7b":"df.groupby(['Pclass']).agg(aggregations)","fe3831c9":"df.groupby(['Pclass','Embarked']).Fare.median()","09e2885e":"pd.crosstab(df.Sex,df.Pclass)","712cc0d1":"pd.crosstab(df.Sex,df.Pclass).plot(kind='bar');","527ddf1d":"#pivot table\ndf.pivot_table(index='Sex',columns = 'Pclass',values = 'Age',aggfunc='mean')","c24b54d0":"df.groupby(['Sex','Pclass']).Age.mean().unstack()","a3d500a4":"df.isnull().sum()","e5917e73":"train_df.isnull().sum()","77deda00":"df.info()","eebc1ed6":"df[df.Embarked.isnull()]","0cdb244a":"#how many people embarked at a particular points\ndf.Embarked.value_counts()","e0230b5c":"#which embarked point has highest survival count\npd.crosstab(df[df.Survived != -888].Survived,df[df.Survived != -888].Embarked)","7f0a9f9f":"# impute missing value with 'S'\n#df.loc[df.Embarked.isnull(),'Embarked'] = S\n#df.Embarked.fillna('S',inplace = True)","83f27da8":"df.groupby(['Pclass','Embarked']).Fare.median() ","c6ea73bd":"\ndf.Embarked.fillna('C',inplace = True)","200533c7":"df.Embarked.isnull().sum()","db225b3b":"df.info()","39167d53":"df[df.Fare.isnull()]","5e422859":"median_fare = df.loc[(df.Pclass == 3) & (df.Embarked=='S'),'Fare'].median()\nprint (median_fare)","f0a73eba":"df.Fare.fillna(median_fare,inplace=True)","70201fd5":"df.info()","49dc8aac":"df.Age.isnull().sum()","530cd03f":"df.Age.plot(kind='hist',bins=20);","9b49c29d":"df.Age.mean()","2716791a":"df.groupby('Sex').Age.median()","9449ce46":"df[df.Age.notnull()].boxplot('Age','Sex');","858365df":"df[df.Age.notnull()].boxplot('Age','Pclass');","0132fd6c":"df.Name.head()","341f07ef":"def GetTitle(name):\n    first_name_with_title = name.split(',')[1]\n    title = first_name_with_title.split('.')[0]\n    title = title.strip().lower()\n    return title","685cf036":"#use map function to apply the function on each Name value row i\ndf.Name.map(lambda x : GetTitle(x))","ec489f34":"df.Name.map(lambda x : GetTitle(x)).unique()","f6ba2fe5":"def GetTitle(name):\n    title_group = {'mr' : 'Mr', \n               'mrs' : 'Mrs', \n               'miss' : 'Miss', \n               'master' : 'Master',\n               'don' : 'Sir',\n               'rev' : 'Sir',\n               'dr' : 'Officer',\n               'mme' : 'Mrs',\n               'ms' : 'Mrs',\n               'major' : 'Officer',\n               'lady' : 'Lady',\n               'sir' : 'Sir',\n               'mlle' : 'Miss',\n               'col' : 'Officer',\n               'capt' : 'Officer',\n               'the countess' : 'Lady',\n               'jonkheer' : 'Sir',\n               'dona' : 'Lady'\n                 }\n    first_name_with_title = name.split(',')[1]\n    title = first_name_with_title.split('.')[0]\n    title = title.strip().lower()\n    return title_group[title]","8ff062a8":"df['Title'] = df.Name.map(lambda x : GetTitle(x))","d597cfbe":"df.head()","5abb46a4":"df[df.Age.notnull()].boxplot('Age','Title');","2a03dccf":"#replace missing values\ntitle_age_median = df.groupby('Title').Age.transform('median')","2b459267":"df.Age.fillna(title_age_median,inplace = True)","31e69af4":"df.info()","9a4b6929":"# use histograms to get to understand the distribution\ndf.Age.plot(kind = 'hist' , bins = 20);","51876f38":"df.loc[df.Age > 70]","8867013c":"# hsitograms for fare\ndf.Fare.plot(kind='hist',bins = 20, title = 'Histograms for Fare')","962e49f1":"df.Fare.plot(kind='box');","72dbb7b2":"# look for the outliers\ndf.loc[df.Fare == df.Fare.max()]","4083d157":"#try to use transformation to reduce the skewness","52cd04a1":"LogFare = np.log(df.Fare +1)#adding 1 to accomalate ","23442fab":"LogFare.plot(kind='hist',bins = 20);","29d9bdf0":"#binning","e737c5bb":"pd.qcut(df.Fare,4)","7b9eb035":"pd.qcut(df.Fare,4,labels=['very_low','low','high','very_high'])","128cd9e4":"pd.qcut(df.Fare,4,labels = ['very_low','low','high','very_high']).value_counts().plot(kind='bar',rot = 0);","2982ca9d":"# create fare bin feature\ndf['Fare_Bin']=pd.qcut(df.Fare,4,labels=['very_low','low','high','very_high'])","cc6b9603":"#Age State based on Age\ndf['AgeState'] = np.where(df['Age']>=18,'Adult','Child')","f002012a":"#AgeState Counts\ndf['AgeState'].value_counts()","a318ad17":"pd.crosstab(df[df.Survived != -888].Survived , df[df.Survived != -888].AgeState)","abee8106":"df['FamilySize'] = df.Parch + df.SibSp + 1 # i for Self","ddb81696":"#explore the family feature\ndf['FamilySize'].plot(kind = 'hist',color = 'c');","397ffde9":"#further exploring familoy size with mjax family size\ndf.loc[df.FamilySize == df.FamilySize.max(),['Name','Survived','FamilySize','Ticket']]","424e802e":"pd.crosstab(df[df.Survived != -888].Survived , df[df.Survived != -888].FamilySize)","0d3e9d7a":"# a lady aged 18 or more who has Parch >0 and is married \ndf['IsMother'] = np.where(((df.Sex == 'female') & (df.Parch > 0) & (df.Age>18) & (df.Title != 'Miss')),1,0)","2712986a":"\n\n#Crosstab with mother\npd.crosstab(df[df['Survived'] != -888].Survived,df[df['Survived'] != -888].IsMother )","7ec243bf":"#explore Cabin values\ndf.Cabin","ae8198c9":"#Getting unique cabin\ndf.Cabin.value_counts()","7951e00d":"#We see that T is odd one out in above observation so we can asume it is mistaken value","e5f916c2":"# get the value to Nan\ndf.loc[df.Cabin == 'T','Cabin']=np.NaN","c6102bff":"def get_deck(cabin):\n    return np.where(pd.notnull(cabin),str(cabin)[0].upper(),'Z')\n","7a91203d":"df['Deck'] = df['Cabin'].map(lambda x: get_deck(x))","fbaedfa3":"# check counts\ndf.Deck.value_counts()","61564353":"pd.crosstab(df[df.Survived != -888].Survived,df[df.Survived != -888].Deck)","759d03cd":"df.info()","3376a074":"#sex\ndf['IsMale'] = np.where(df.Sex == 'male',1,0)","78c00ddf":"#columns deck,pclass,title,Agestate\ndf = pd.get_dummies(df,columns=['Deck','Pclass','Title','Fare_Bin','Embarked','AgeState'])","c6fa40d4":"df.info()","2405282a":"\n\n\n#drop columns","2bd9d0c2":"df.drop(['Cabin','Name','Ticket','Parch','SibSp','Sex'],axis = 1,inplace = True)","1b52b868":"#reorder columns\ncolumns = [column for column in df.columns if column != 'Survived']\ncolumns = ['Survived']+columns\ndf = df[columns]","16940910":"df.info()","c800450f":"df.to_csv('out.csv')#Saving Dataset before making predicting model\n#This would be saved as output in Version folder.","5bb20f96":"train_df = df.loc[0:891,:]","b417907f":"train_df.info()","1969a28f":"train_df.tail()","dc3292cf":"test_df = df.loc[892:,:]","c6b4433d":"test_df.tail()","50036dc4":"train_df.shape","2d8bb2f4":"test_df.shape\ntest_df.info()\n","3d0fda44":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"Survived\", axis=1).copy()","79f60404":"X_train.shape","f9ef36aa":"Y_train.shape","733b2286":"X_test.shape","eeee5e53":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2","5f29ef84":"Xtr = X_train.copy()\nXtr.head()","2f86568b":"ytr = Y_train.copy()\n#target column i.e price range\nytr.head()\nY_train.head()","d806b16b":"#apply SelectKBest class to extract top 20 best features\nbestfeatures = SelectKBest(score_func=chi2, k=20)\nfit = bestfeatures.fit(Xtr,ytr)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(Xtr.columns)","b72829e1":"#concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nprint(featureScores.nlargest(32,'Score'))  #print 10 best features","e67ce2da":"from sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt","552a4294":"model = ExtraTreesClassifier()\nmodel.fit(Xtr,ytr)","004ccd32":"\n\n\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=Xtr.columns)\nfeat_importances.nlargest(20).plot(kind='barh')\nplt.show()\n\n\n","3c7cffc7":"train_df.head()","ee4a0930":"corrmat = train_df.corr()\nprint(corrmat.Survived)\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(train_df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","9411ba15":"list = ['Title_Master','Fare_Bin_low','Title_Lady','Fare_Bin_high','Deck_F','Title_Sir','AgeState_Adult','Deck_A','FamilySize','Deck_G',\n        'Title_Officer','Embarked_Q','Deck_B','IsMother','Embarked_C','Deck_Z','Deck_D','Deck_E','AgeState_Child']","a112bd7d":"X_train.drop(list,axis=1,inplace = True)\nX_test.drop(list,axis = 1,inplace = True)\n","b2a9fa39":"X_train.shape\n","25d2ec80":"Y_train.shape","a51ae88b":"# Random FOrest Classifier using Grid SearchSearch CV","da98108a":"X_test.shape","0a58ffc5":"rfc=RandomForestClassifier(random_state=42)","0118f7a1":"param_grid = { \n    'n_estimators': [200, 500],\n    'max_features': ['auto', 'sqrt', 'log2'],\n    'max_depth' : [4,5,6,7,8],\n    'criterion' :['gini', 'entropy']\n}","eb7af156":"\"\"\"CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\nCV_rfc.fit(X_train, Y_train)\"\"\"","d7eabce8":"\"\"\"CV_rfc.best_params_\"\"\"","142f7516":"rfc1=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 500, max_depth=7, criterion='gini')","123ccda4":"rfc1.fit(X_train, Y_train)","4c370ec0":"pred=rfc1.predict(X_test)","6411df5d":"X_test.index","5a981474":"df_result = pd.DataFrame(pred)","09261bb7":"df_result","15aa16c9":"df_result['Survived'] = pred","522fd6ea":"df_result.drop(0,axis =1,inplace = True)","42aa59e5":"df_result['PassengerId']=X_test.index","ff116c08":"df_result.head()\n","fe0d4f57":"df_result = df_result.set_index('PassengerId')","1e328cbe":"df_result.head()","7db1abd2":"df_result.to_csv('output.csv')\n","287d3cc0":"from sklearn.model_selection import RandomizedSearchCV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10,20]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4,10,15,20,30]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","ddb2a9f8":"\"\"\"\nrf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42,\n                               n_jobs = -1)\n\n# Fit the random search model\nrf_random.fit(X_train, Y_train)\"\"\"","cedbfbf3":"\"\"\"print(rf_random.best_params_)\"\"\"","94cefe23":"rf1=RandomForestClassifier(random_state=42, max_features='sqrt', n_estimators= 200, max_depth=7, criterion='gini',\n                           min_samples_split = 2, min_samples_leaf = 2, bootstrap =  False)","b0bfdbcd":"rf1.fit(X_train, Y_train)","13a069ab":"pred1 = rf1.predict(X_test)","bb4b5cb3":"df_result_1 = pd.DataFrame(pred1)","c6f7d679":"df_result_1","03737e92":"df_result_1['Survived'] = pred1","d01d2c13":"df_result_1.head()","c049c035":"df_result_1.drop(0,axis =1,inplace = True)","d7b3c517":"df_result_1['PassengerId']=X_test.index","fd1b06ae":"df_result_1.head()","2f044832":"df_result_1 = df_result_1.set_index('PassengerId')","e48dca02":"df_result_1.head()","d7060725":"df_result_1.to_csv('output_1.csv')\n","2212cb5f":"<h2>Spread\/Dispersion measure<h2>","b6656e94":"# Outliers","b30f9e17":"<h2>Grouping<h2>","d768c771":"Techniques to compensate for outliers\n1. 1.Removal\n1. 2.Transformation\n1. 3.Binning\n1. 4.Imputation","86f3aebc":"1. Univariate Selection","45b74f76":"**So we would start analysing by importing all important libraries .**","3ee35ec0":"# Feature Engineering","845ffacf":"We are making dataframe test and train to analyse the given dataset.","fba8f71b":"\n**Feature:Deck**","42a701ae":"Feature : Embarked","8a3df3ec":"# Building Machine Learning Models","4ef115b8":"\n<h2>Centrality Measure<h2>","8dbf39ee":"**Step 1:Missing value addressing**","95f32a9b":"<h2>option 2: Replace by median<h2>","7f15ee6e":"# Data Munging","5fc7b6dd":" <h1>Categorical feature<h1>\n \n ","e5b54592":"2 . Feature Importance","c1521481":"Various technique such as Mean and Median are used as Centrality measures\nMean may me good option often but it is quite affected by extreme value.In such cases we can use median for analysis.","d5801f9b":"\n# Summaty Statistics","4feef9df":"From the analysis we get that score of various columns vary differentely. For now using this method we can drop the feature with score less than 10 will make our dataset more cleaner and more accurate.\nLets try another method\n","8bf90ea0":"You can get the feature importance of each feature of your dataset by using the feature importance property of the model.\n\nFeature importance gives you a score for each feature of your data, the higher the score more important or relevant is the feature towards your output variable.\n\nFeature importance is an inbuilt class that comes with Tree Based Classifiers, we will be using Extra Tree Classifier for extracting the top 10 features for the dataset.","9abcf4b0":"Feature Selection Methods:\n\nI will share 3 Feature selection techniques that are easy to use and also gives good results.\n\n1. Univariate Selection\n\n2. Feature Importance\n\n3. Correlation Matrix with Heatmap","00f7ab9e":"<h2>Pivot Table<h2>","5ee58bce":"# Drop and Reorder Columns","11afde3f":"<h2>option 3 : replace with median age of Pclass<h2>","e3d8e3c7":"<h2>Bivariate Distribution<h2>","f33adb13":"\n\n**Feature :isMother**","72cdc936":"**Feature : Age State(Adult or Child) **","60125d4b":"Going through the complete dataset to get the jist of it.","b1b2e1a5":"Deck_B    25.875581\n3             IsMother    24.601467\n27          Embarked_C    22.009402\n12              Deck_Z    20.731648\n8               Deck_D    19.489646\n9               Deck_E    18.140638\n31      AgeState_Child    11.827471\n7               Deck_C    10.936730","2cc889c9":"# Feature Selection for higher accuracy","6cce48ec":"Feature : Fare","45f0a408":"**Feature : FamilySize**","ad2672a1":"Feature : Age","cfe5acb4":"We all know that the' Mr' is used for old veteran and 'master' is used for young man.Similar goes with females.So we will extract titles to predict the values of the age of the passenger of titanic. ","56db8b99":"<h2>Distributions of univariate feature at a time<h1>","67395185":"# Basic Structure","8ebd2d11":"I will be using RandomDomforest Classifier for predicting the outcomes as it yeild's most result.(more detail checkout discussion panel)After that to tune the model use GridSearchCV and RandomizedSearchCV. \n","45134f59":"<h2>option 4 : replace with median age of title<h2>","4a9878ef":"Now lets remove the worst 12 features to make the dataset clearner and more perfect.\n\nHere is the list of not important features <br>\n        Title_Master    <br>\n        Fare_Bin_low     <br>\n          Title_Lady     <br>\n       Fare_Bin_high     <br>\n              Deck_F     <br>\n           Title_Sir     <br>\n      AgeState_Adult     <br>\n              Deck_A    <br>\n           FamilySize    <br>\n              Deck_G     <br>\n       Title_Officer     <br>\n         Embarked_Q      <br>","ecc1a2e5":"\n# <h1>Various pandas functions on data set<h1>","f766c32b":"<h1>We have three options to fill missing age value<h1>\n<h2> option 1 : replace all missing value with the mean value<h2>","59d50f63":"3.Correlation Matrix with Heatmap\n\nCorrelation states how the features are related to each other or the target variable.\n\nCorrelation can be positive (increase in one value of feature increases the value of the target variable) or negative (increase in one value of feature decreases the value of the target variable)\n\nHeatmap makes it easy to identify which features are most related to the target variable, we will plot heatmap of correlated features using the seaborn library.","0d3b844b":"we use range we can see how things are packed.But it is affected by extreme values.\nSo percentiles are used.These are specially used as quartiles\n","c946acdb":"Now we will train several Machine Learning models and compare their results. Note that because the dataset does not provide labels for their testing-set, we need to use the predictions on the training set to compare the algorithms with each other. ","dc8db5fd":"From above we get to know that the passenger who are in class 1 and paid fare of 80 has  more chances to be Embarked from C.","822beeb0":"<h2>Crosstab<h2>","c7b45f47":"Due to several 70's and 80's the mean is quite affected","3d28d8f1":"So far we have use numpy and pandas to analyse the whole data and going through it.\nNow we will Start exploring the whole Dataset.","581bd955":"\n\n\nSimilar results can be found by group by table","c2cc7d6b":"# Categorical features\n<p>Also known as features with non integer values.(Boolean,Someone's Name or Gender)<p>","e6bfd734":"Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n\nThe scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features.\n\nThe example below uses the chi-squared (chi\u00b2) statistical test for non-negative features to select  the best features"}}