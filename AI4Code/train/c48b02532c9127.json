{"cell_type":{"4f192781":"code","efb1fa39":"code","3e3432f0":"code","8d81cfb9":"code","baf50a25":"code","512c5d3d":"code","c93e96d4":"code","4cdfabf4":"code","d6c66be5":"code","6342a336":"code","173fd55b":"code","818ff378":"code","275164fa":"code","3499130f":"code","4c516bcc":"code","083df55f":"code","9176cb0b":"code","9c12c5e9":"code","da00d938":"code","ede67063":"code","4fa30945":"code","ecf86410":"code","963c5172":"code","25045e0a":"code","d3ebafc2":"code","9968a2d3":"code","a8a44bdf":"code","12eb3e07":"code","95dc4aca":"code","e5c40b68":"code","0faf3541":"code","67fef821":"code","276c7013":"code","468f637b":"code","3fb347da":"code","2640e062":"code","71c85aff":"code","827dbad1":"code","259545d6":"code","1b7dbbfc":"code","8925c99b":"code","dd70f07e":"code","cc038362":"code","5168cba3":"code","25cb2587":"code","875538a0":"code","25c8a0bf":"code","eb6aac04":"code","574ceb0a":"code","8bbaee25":"code","43159064":"code","85bd1767":"code","30928b20":"code","5a09b3d4":"code","bb1b9731":"code","19e120d3":"code","29fa2603":"code","71fb8ac8":"code","7dd68b28":"code","857bc35d":"code","5cb0ef15":"code","569d9834":"code","f5a2b266":"code","0276f64e":"code","6e6e8b21":"code","84971df9":"code","6bea1517":"code","64c89cf8":"code","f5269505":"code","17dbd9ee":"code","e9cff8ae":"code","61100255":"code","8532f5c5":"code","ab0e1ea4":"code","e028ac49":"code","03cf5e79":"code","5d3c03a0":"code","3d3b63c6":"code","873fedba":"code","5a28b17d":"code","48b814e0":"code","8fcedf73":"code","211a8790":"code","914e96af":"markdown","ef817e27":"markdown","fa2390d6":"markdown","31902522":"markdown","76ffa8b0":"markdown","bbea3324":"markdown","bcb443b7":"markdown","e17eddc8":"markdown","2baf6579":"markdown"},"source":{"4f192781":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport seaborn as sb\n%matplotlib inline\n\nimport os\nimport glob","efb1fa39":"data = pd.read_csv('..\/input\/application_train.csv')\ntest = pd.read_csv('..\/input\/application_test.csv')\nprev = pd.read_csv('..\/input\/previous_application.csv')\nburo = pd.read_csv('..\/input\/bureau.csv')\nburo_balance = pd.read_csv('..\/input\/bureau_balance.csv')\ncredit_card = pd.read_csv('..\/input\/credit_card_balance.csv')\nPOS_CASH = pd.read_csv('..\/input\/POS_CASH_balance.csv')\npayments = pd.read_csv('..\/input\/installments_payments.csv')","3e3432f0":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold","8d81cfb9":"import xgboost as xgb\nfrom xgboost import XGBClassifier\n\nimport gc","baf50a25":"from sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\nfrom sklearn.feature_selection import VarianceThreshold","512c5d3d":"from sklearn.model_selection import GridSearchCV\nfrom skopt import BayesSearchCV\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold","c93e96d4":"def status_print(optim_result):\n    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n    \n    # Get all the models tested so far in DataFrame format\n    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n    \n    # Get current parameters and the best parameters    \n    best_params = pd.Series(bayes_cv_tuner.best_params_)\n    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n        len(all_models),\n        np.round(bayes_cv_tuner.best_score_, 4),\n        bayes_cv_tuner.best_params_\n    ))\n    \n    # Save all model results\n    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n    all_models.to_csv(clf_name+\"_cv_results.csv\")","4cdfabf4":"data.head()","d6c66be5":"#Separate target variable\ny = data['TARGET']\ndel data['TARGET']","6342a336":"#One-hot encoding of categorical features in data and test sets\ncategorical_feature = [col for col in data.columns if data[col].dtype == 'object']","173fd55b":"categorical_feature","818ff378":"# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","275164fa":"# Missing values statistics\nmissing_values = missing_values_table(data)\nmissing_values.head(20)","3499130f":"data.dtypes.value_counts()","4c516bcc":"# Number of unique classes in each object column\n#app_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0) or\ndata.select_dtypes('object').nunique()","083df55f":"data.shape, test.shape","9176cb0b":"one_hot_df = pd.concat([data, test])","9c12c5e9":"one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_feature)","da00d938":"one_hot_df.shape","ede67063":"one_hot_df.head()","4fa30945":"data = one_hot_df.iloc[:data.shape[0],:]\ntest = one_hot_df.iloc[data.shape[0]:,]","ecf86410":"data.shape, test.shape","963c5172":"test.head()","25045e0a":"data.head()","d3ebafc2":"buro.head()","9968a2d3":"buro_grouped_size = buro_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].size()\nburo_grouped_max = buro_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].max()\nburo_grouped_min = buro_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].min()","a8a44bdf":"buro_grouped_size.head(),  buro_grouped_max.head(),   buro_grouped_min.head()","12eb3e07":"buro_balance.head()","95dc4aca":"buro_counts = buro_balance.groupby('SK_ID_BUREAU')['STATUS'].value_counts(normalize = False)","e5c40b68":"buro_balance.shape","0faf3541":"buro_counts.head()","67fef821":"buro_counts_unstacked = buro_counts.unstack('STATUS')\nburo_counts_unstacked.head()","276c7013":"buro_counts_unstacked.columns = ['STATUS_0', 'STATUS_1','STATUS_2','STATUS_3','STATUS_4','STATUS_5','STATUS_C','STATUS_X']\nburo_counts_unstacked['MONTHS_COUNT'] = buro_grouped_size\nburo_counts_unstacked['MONTHS_MIN'] = buro_grouped_min\nburo_counts_unstacked['MONTHS_MAX'] = buro_grouped_max","468f637b":"buro_grouped_size.head(),  buro_grouped_max.head(),   buro_grouped_min.head()","3fb347da":"buro = buro.join(buro_counts_unstacked, how ='left', on ='SK_ID_BUREAU')","2640e062":"buro.head()","71c85aff":"prev_cat_features = [pcol for pcol in prev.columns if prev[pcol].dtype == 'object']","827dbad1":"prev_cat_features","259545d6":"prev.head()","1b7dbbfc":"prev.shape","8925c99b":"prev = pd.get_dummies(prev, columns=prev_cat_features)","dd70f07e":"prev.head()","cc038362":"avg_prev = prev.groupby('SK_ID_CURR').mean()","5168cba3":"avg_prev.head()","25cb2587":"avg_prev.shape","875538a0":"cnt_prev = prev[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()","25c8a0bf":"cnt_prev.head(),  cnt_prev.shape","eb6aac04":"avg_prev['nb_app'] = cnt_prev['SK_ID_PREV']","574ceb0a":"del avg_prev['SK_ID_PREV']","8bbaee25":"#One-hot encoding of categorical features in buro data set\n\nburo_cat_features = [bcol for bcol in buro.columns if buro[bcol].dtype == 'object']\nburo_cat_features ","43159064":"buro = pd.get_dummies(buro, columns=buro_cat_features)","85bd1767":"buro.head()","30928b20":"avg_buro = buro.groupby('SK_ID_CURR').mean()","5a09b3d4":"avg_buro.head()","bb1b9731":"avg_buro['buro_count'] = buro[['SK_ID_BUREAU', 'SK_ID_CURR']].groupby('SK_ID_CURR').count()['SK_ID_BUREAU']\ndel avg_buro['SK_ID_BUREAU']","19e120d3":"POS_CASH.head()","29fa2603":"POS_CASH.shape","71fb8ac8":"le = LabelEncoder()\nPOS_CASH['NAME_CONTRACT_STATUS'] = le.fit_transform(POS_CASH['NAME_CONTRACT_STATUS'].astype(str))\nnunique_status = POS_CASH[['SK_ID_CURR', 'NAME_CONTRACT_STATUS']].groupby('SK_ID_CURR').nunique()\nnunique_status2 = POS_CASH[['SK_ID_CURR', 'NAME_CONTRACT_STATUS']].groupby('SK_ID_CURR').max()\nPOS_CASH['NUNIQUE_STATUS'] = nunique_status['NAME_CONTRACT_STATUS']\nPOS_CASH['NUNIQUE_STATUS2'] = nunique_status2['NAME_CONTRACT_STATUS']\nPOS_CASH.drop(['SK_ID_PREV', 'NAME_CONTRACT_STATUS'], axis=1, inplace=True)","7dd68b28":"credit_card.head()","857bc35d":"credit_card_cat_features = [c_col for c_col in credit_card.columns if credit_card[c_col].dtype == 'object']\ncredit_card_cat_features ","5cb0ef15":"credit_card.shape","569d9834":"credit_card['NAME_CONTRACT_STATUS'] = le.fit_transform(credit_card['NAME_CONTRACT_STATUS'].astype(str))\nnunique_status = credit_card[['SK_ID_CURR', 'NAME_CONTRACT_STATUS']].groupby('SK_ID_CURR').nunique()\nnunique_status2 = credit_card[['SK_ID_CURR', 'NAME_CONTRACT_STATUS']].groupby('SK_ID_CURR').max()\ncredit_card['NUNIQUE_STATUS'] = nunique_status['NAME_CONTRACT_STATUS']\ncredit_card['NUNIQUE_STATUS2'] = nunique_status2['NAME_CONTRACT_STATUS']\ncredit_card.drop(['SK_ID_PREV', 'NAME_CONTRACT_STATUS'], axis=1, inplace=True)","f5a2b266":"payments.head()","0276f64e":"payments.shape","6e6e8b21":"avg_payments = payments.groupby('SK_ID_CURR').mean()\navg_payments2 = payments.groupby('SK_ID_CURR').max()\navg_payments3 = payments.groupby('SK_ID_CURR').min()\ndel avg_payments['SK_ID_PREV']","84971df9":"data = data.merge(right=avg_prev.reset_index(), how='left', on ='SK_ID_CURR')","6bea1517":"data.head()","64c89cf8":"test = test.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')","f5269505":"test.head()","17dbd9ee":"data = data.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')","e9cff8ae":"data = data.merge(POS_CASH.groupby('SK_ID_CURR').mean().reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(POS_CASH.groupby('SK_ID_CURR').mean().reset_index(), how='left', on='SK_ID_CURR')","61100255":"data = data.merge(credit_card.groupby('SK_ID_CURR').mean().reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(credit_card.groupby('SK_ID_CURR').mean().reset_index(), how='left', on='SK_ID_CURR')","8532f5c5":"data = data.merge(right=avg_payments.reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(right=avg_payments.reset_index(), how='left', on='SK_ID_CURR')","ab0e1ea4":"data = data.merge(right=avg_payments2.reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(right=avg_payments2.reset_index(), how='left', on='SK_ID_CURR')","e028ac49":"data = data.merge(right=avg_payments3.reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(right=avg_payments3.reset_index(), how='left', on='SK_ID_CURR')","03cf5e79":"data.shape, test.shape","5d3c03a0":"data.head()","3d3b63c6":"test.head()","873fedba":"test = test[test.columns[data.isnull().mean() < 0.80]]\ndata = data[data.columns[data.isnull().mean() < 0.80]]","5a28b17d":"data.head()","48b814e0":"from lightgbm import LGBMClassifier\nimport gc\n\ngc.enable()\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=546789)\noof_preds = np.zeros(data.shape[0])\nsub_preds = np.zeros(test.shape[0])\n\nfeature_importance_df = pd.DataFrame()\n\nfeats = [f for f in data.columns if f not in ['SK_ID_CURR']]\n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(data)):\n    trn_x, trn_y = data[feats].iloc[trn_idx], y.iloc[trn_idx]\n    val_x, val_y = data[feats].iloc[val_idx], y.iloc[val_idx]\n    \n    clf = LGBMClassifier(\n        n_estimators=10000,\n        learning_rate=0.01,\n        num_leaves=255,\n        colsample_bytree=0.81,\n        subsample=0.82,\n        max_depth = 9,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01,\n        #min_child_weight=250,\n        min_sum_hessian_in_leaf = 200,\n        silent=-1,\n        verbose=-1,\n        )\n    \n    clf.fit(trn_x, trn_y, \n            eval_set= [(trn_x, trn_y), (val_x, val_y)], \n            eval_metric='auc', verbose=100, early_stopping_rounds=200  #30\n           )\n    \n    oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n    sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] \/ folds.n_splits\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = feats\n    fold_importance_df[\"importance\"] = clf.feature_importances_\n    fold_importance_df[\"fold\"] = n_fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n    del clf, trn_x, trn_y, val_x, val_y\n    gc.collect()\n","8fcedf73":"print('Full AUC score %.6f' % roc_auc_score(y, oof_preds)) ","211a8790":"test['TARGET'] = sub_preds\n\ntest[['SK_ID_CURR', 'TARGET']].to_csv('home_risk_1submission.csv', index=False)","914e96af":"\n#Pre-processing credit_card","ef817e27":"#Pre-processing buro_balance","fa2390d6":"\n#Pre-processing payments","31902522":"# Examine missing value","76ffa8b0":"\n#Pre-processing buro","bbea3324":"\nPre-processing previous_application","bcb443b7":"\n#Pre-processing POS_CASH","e17eddc8":"\n#Join data bases","2baf6579":"\n#Remove features with many missing values"}}