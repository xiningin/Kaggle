{"cell_type":{"49d7e3f0":"code","cfc339c8":"markdown","0f2f68c9":"markdown","6c9bcb40":"markdown"},"source":{"49d7e3f0":"import math\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\nclass EfficientNET(nn.Module):\n    '''\n    Based on the paper by \uff08\u4ee5\u4e0b\u306e\u8ad6\u6587\u306e\u5b9f\u88c5\u3067\u3059\u3002\uff09\n    Mingxing Tan, Quoc V. Le\n    EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n    ICML'19, https:\/\/arxiv.org\/abs\/1905.11946\n    \n    Resolution for each of the scaled model is as follows.\n    B0\uff5eB7\u306e\u89e3\u50cf\u5ea6\u306f\u6b21\u3067\u3059\u3002\n    B0:224, B1:240, B2:260, B3:300, B4:380, B5:456, B6:528, B7:600\n    \n    Takes in arguments input channels, num_classes, optional (B0~B7 variant), optional batchnorm momentum, optional batchnorm epsilon\n    \u5165\u529b\u306f\u5165\u529b\u753b\u50cf\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u6570\u3001\u5206\u985e\u30af\u30e9\u30b9\u6570\u3001\uff08\u4efb\u610f\uff09B0~B7\u306e\u7a2e\u985e\u3001\uff08\u4efb\u610f\uff09\u30d0\u30c3\u30c1\u6b63\u898f\u5316\u306e\u30e2\u30e1\u30f3\u30bf\u30e0\u3001\uff08\u4efb\u610f\uff09\u30d0\u30c3\u30c1\u6b63\u898f\u5316\u306e0\u9664\u7b97\u9632\u304e\u5c0f\u6570\n    \n    '''\n    def __init__(self,in_channels,num_classes,architecture='B0',BN_momentum = 0.99,BN_eps =1e-3):\n        super(EfficientNET,self).__init__()\n        self.in_channels = in_channels\n        self.channelscale = {'B0':1,'B1':1,'B2':1.1,'B3':1.2,'B4':1.4,'B5':1.6,'B6':1.8,'B7':2}\n        self.depthscale = {'B0':1,'B1':1.1,'B2':1.2,'B3':1.4,'B4':1.8,'B5':2.2,'B6':2.6,'B7':3.1}\n        self.BN_momentum = BN_momentum\n        self.BN_eps = BN_eps\n        self.survival_prob = 0.8\n        self.dropoutparams = [0.2,0.2,0.3,0.3,0.4,0.4,0.5,0.5] \n        self.dropout = self.dropoutparams[int(architecture[1])]\n        \n        #architecture follows the format: conv type, num filters(out channels), num layers, kernel size, stride, padding\n        self.architecture = [['C',32,1,3,2,1],\n                            ['MB1',self.channelscaling(self.channelscale[architecture],16),self.depthscaling(self.depthscale[architecture],1),3,1,1],\n                            ['MB6',self.channelscaling(self.channelscale[architecture],24),self.depthscaling(self.depthscale[architecture],2),3,2,1],\n                            ['MB6',self.channelscaling(self.channelscale[architecture],40),self.depthscaling(self.depthscale[architecture],2),5,2,2],\n                            ['MB6',self.channelscaling(self.channelscale[architecture],80),self.depthscaling(self.depthscale[architecture],3),3,2,1],\n                            ['MB6',self.channelscaling(self.channelscale[architecture],112),self.depthscaling(self.depthscale[architecture],3),5,1,2],\n                            ['MB6',self.channelscaling(self.channelscale[architecture],192),self.depthscaling(self.depthscale[architecture],4),5,2,2],\n                            ['MB6',self.channelscaling(self.channelscale[architecture],320),self.depthscaling(self.depthscale[architecture],1),3,1,1],\n                            ['C',1280,1,1,1,0]]\n        \n        self.EffNet = nn.Sequential(self.create_layers(),nn.AdaptiveAvgPool2d(1),nn.Flatten(),nn.Dropout(self.dropout),nn.Linear(1280,num_classes)).apply(self.init_weights)\n    \n    def create_layers(self): #return list of layers (nn\u8981\u7d20\u306e\u30ea\u30b9\u30c8\u3092\u8fd4\u3059)\n        in_channels=self.in_channels\n        layers=[]\n        for stage in self.architecture:\n            if stage[0]=='C': #regular convolution (\u666e\u901a\u306e\u7573\u307f\u8fbc\u307f)\n                layers.append(nn.Conv2d(in_channels,stage[1],stage[3],stride=stage[4],padding=stage[5]))\n                in_channels = stage[1] #in channels = out channels\n                layers.append(nn.BatchNorm2d(in_channels,momentum = self.BN_momentum,eps = self.BN_eps)) #momentum value as stated in paper\n                layers.append(nn.SiLU())\n            \n            else:#execute MBConv (MobileNetV2\u306e\u7573\u307f\u8fbc\u307f)\n                for layer_num in range(stage[2]):\n                    layers.append(MBConv(in_channels,stage,layer_num,self.survival_prob,self.BN_momentum,self.BN_eps))\n                    in_channels = stage[1]\n        \n        return nn.Sequential(*layers)\n    \n    def forward(self,x):\n        return self.EffNet(x)\n    \n    #function to scale channels for B0~B7\n    def channelscaling(self,scale,channels):\n        channels = channels*scale\n        new_channels = max(8,int(channels+4)\/\/8*8) #8\u306e\u500d\u7387\u306b\u3059\u308b\u305f\u3081\n        if new_channels <0.9 * channels:\n            new_channels += 8\n        return int(new_channels)\n    \n    #function to scale layers for B0~B7\n    def depthscaling(self,scale,layers):\n        return int(math.ceil(scale*layers))\n    \n    #initialize weights\n    def init_weights(self,m):\n        if type(m) == nn.Linear:\n            nn.init.kaiming_uniform_(m.weight,a=np.sqrt(5),mode='fan_out',nonlinearity='leaky_relu')\n        elif type(m) == nn.Conv2d:\n            nn.init.kaiming_normal_(m.weight,mode = 'fan_out',nonlinearity = 'relu')\n    \nclass MBConv(nn.Module):#mobile inverted bottleneck\n    '''\n    \u4ee5\u4e0b\u306e\u8ad6\u6587\u3092\u53c2\u7167\u3057\u307e\u3057\u305f\u3002\n    Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, Quoc V. Le\n    MnasNet: Platform-Aware Neural Architecture Search for Mobile\n    arXiv:1807.11626v3\n    \n    Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen\n    MobileNetV2: Inverted Residuals and Linear Bottlenecks\n    arXiv:1801.04381v4\n    '''\n    def __init__(self,in_channels,stage_archi_list,layer_num,survival_probability,BN_momentum, BN_eps):\n        super(MBConv,self).__init__()\n        if stage_archi_list[0] == 'MB1':#\u62e1\u5927\u4fc2\u6570\u306f1\n            self.expansion = 1\n        else:#\u62e1\u5927\u4fc2\u6570\u306f6\n            self.expansion = 6\n        self.in_channels = in_channels\n        self.out_channels = stage_archi_list[1]\n        self.layers = layer_num\n        self.kernel_size = stage_archi_list[3]\n        self.layer1stride = stage_archi_list[4]\n        self.padding = stage_archi_list[5]\n        self.BN_momentum = BN_momentum\n        self.BNeps = BN_eps\n        self.survival_prob = survival_probability\n        self.mbconv = self.MBConvblock(self.in_channels,self.layers)\n    \n    def conv1x1block(self,in_channels,activation='SiLU',order = 'first'):\n        layers=[]\n        if order == 'first':\n            out_channels = in_channels * self.expansion\n        elif order == 'last':\n            out_channels = self.out_channels\n        layers.append(nn.Conv2d(in_channels,out_channels,kernel_size=1))\n        layers.append(nn.BatchNorm2d(out_channels,momentum = self.BN_momentum,eps = self.BNeps))\n        if activation == 'SiLU':\n            layers.append(nn.SiLU())\n        return nn.Sequential(*layers)\n    \n    def depthwiseblock(self,in_channels,layer_num):\n        layers=[]\n        if layer_num == 0:\n            stride = self.layer1stride\n        else:\n            stride = 1\n        layers.append(nn.Conv2d(in_channels,in_channels,kernel_size = self.kernel_size,stride = stride,padding = self.padding,groups = in_channels)) #group makes it depthwise\n        layers.append(nn.BatchNorm2d(in_channels,momentum = self.BN_momentum,eps = self.BNeps))\n        layers.append(nn.SiLU())\n        return nn.Sequential(*layers)\n    \n    def MBConvblock(self,in_channels,layer_num):\n        return nn.Sequential(self.conv1x1block(in_channels),self.depthwiseblock(in_channels*self.expansion,layer_num),SEBlock(in_channels*self.expansion),self.conv1x1block(in_channels*self.expansion,activation = None,order = 'last'))\n      \n    def StochasticDepth(self,x):\n        if not self.training:\n            return x\n        prob = torch.rand((x.shape[0],1,1,1)).to('cuda' if torch.cuda.is_available else 'cpu')\n        mask = prob < self.survival_prob\n        return torch.mul(torch.div(x,self.survival_prob),mask)\n      \n    def forward(self,x):\n        if self.layers == 0: #first layer in the layers\n            return self.mbconv(x)\n        else:\n            return torch.add(self.StochasticDepth(self.mbconv(x)),x)#\u753b\u50cf\u89e3\u50cf\u5ea6\u3092\u534a\u5206\u306b\u3059\u308b\u5c64\u4ee5\u5916Stochastic Depth\u3092\u5b9f\u65bd\u3059\u308b\n\nclass SEBlock(nn.Module):\n    '''\n    \u4ee5\u4e0b\u306e\u8ad6\u6587\u3092\u53c2\u7167\u3057\u307e\u3057\u305f\u3002\n    Jie Hu, Li Shen, Samuel Albanie, Gang Sun, Enhua Wu\n    Squeeze-and-Excitation Networks\n    arXiv:1709.01507v4\n    '''\n    def __init__(self,in_channels):\n        super(SEBlock,self).__init__()\n        self.SEratio = 0.25\n        self.in_channels = in_channels\n        self.squeezedchannels = max(1,int(0.25*in_channels)) #\u30c1\u30e3\u30f3\u30cd\u30eb\u6570\u306f4\u5206\u306e1\u307e\u3067\u5727\u7e2e\u3059\u308b\n        self.squeezeexcite = self.SE()\n    \n    def SE(self):#squeeze and excitation\n        return nn.Sequential(nn.AdaptiveAvgPool2d(1),\n                             nn.Conv2d(self.in_channels,self.squeezedchannels,kernel_size=1,bias=False),\n                            nn.SiLU(),\n                            nn.Conv2d(self.squeezedchannels,self.in_channels,kernel_size=1,bias=False),\n                            nn.Sigmoid())\n    \n    def forward(self,x):\n        return torch.mul(self.squeezeexcite(x),x)\n        ","cfc339c8":"![EfficientNET Table.JPG](attachment:f81eaf38-4b2c-4e33-9da8-de470fbec888.JPG)","0f2f68c9":"A pytorch implementation of EfficientNet from scratch for my own learning and practice. The specifications of B1 to B7 was not explicitly stated in the paper so I looked into the source code for the values. The model references quite a few other papers such as the MobilenetV2 and MnasNet and Squeeze and Excitation and on first reading through the paper certain details of the architecture was not obvious without referring to the other papers. To visualise the architecture I made a diagram detailing the specifics of the architecture. The diagram is included after the code. If there are any mistakes I would appreciate any comments pointing them out.\n\n\u7df4\u7fd2\u306e\u305f\u3081\u306b\u3001pytorch\u3067EfficientNet\u3092\u5b9f\u88c5\u3057\u307e\u3059\u3002B1\uff5eB7\u306e\u4ed5\u69d8\u306f\u8ad6\u6587\u306b\u66f8\u304b\u308c\u3066\u3044\u307e\u305b\u3093\u306e\u3067\u3001\u30d9\u30fc\u30b9B0\u306b\u5bfe\u3059\u308b\u30b9\u30b1\u30fc\u30ea\u30f3\u30b0\u500d\u7387\u306e\u5024\u306f\u30bd\u30fc\u30b9\u30b3\u30fc\u30c9\u304b\u3089\u5f97\u307e\u3057\u305f\u3002EfficientNet\u306e\u8ad6\u6587\u306f\u4ed6\u306e\u8ad6\u6587\u3092\u5f15\u7528\u3057\u3001\u30e2\u30c7\u30eb\u306e\u69cb\u9020\u8a73\u7d30\u307e\u3067\u66f8\u304b\u308c\u3066\u3044\u307e\u305b\u3093\u306e\u3067\u4ed6\u306e\u8ad6\u6587\u3092\u53c2\u7167\u3057\u306a\u3044\u3068\u3044\u3051\u307e\u305b\u3093\u3002\u307e\u3068\u307e\u3063\u305f\u30e2\u30c7\u30eb\u69cb\u9020\u306e\u8a73\u7d30\u56f3\u3092\u4f5c\u3063\u3066\u307f\u3066\u3001\u30b3\u30fc\u30c9\u306e\u5f8c\u306b\u63b2\u8f09\u3057\u307e\u3059\u3002\u4f55\u304b\u9593\u9055\u3044\u304c\u3042\u308c\u3070\u30b3\u30e1\u30f3\u30c8\u6b04\u3067\u6559\u3048\u3066\u3044\u305f\u3060\u3051\u308c\u3070\u5e78\u3044\u3067\u3059\u3002","6c9bcb40":"![EfficientNET.JPG](attachment:2e8f4d2e-094e-4e4a-bb78-53014d98efbe.JPG)"}}