{"cell_type":{"0710c8b6":"code","eedd39f3":"code","5f5325fb":"code","3e8f99e9":"code","d7c88c27":"code","692e1078":"code","7bda03d0":"code","e084b35e":"code","55c6a9b2":"code","151d69bb":"code","91ebedb3":"code","c0a589c4":"code","0cec8bb2":"code","66da20e5":"code","baff6612":"code","b842575b":"code","7ea936be":"markdown","96f41ebd":"markdown","6c1d8d68":"markdown","64ca3f0c":"markdown","6f9146f7":"markdown","42239757":"markdown","f06d190f":"markdown","27b07d18":"markdown"},"source":{"0710c8b6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, sys \n\n%matplotlib inline\n\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_columns', 200)","eedd39f3":"platform = 'kaggle'\ndefault_dir = None","5f5325fb":"if platform == 'google':\n    # google drive\n    from google.colab import drive \n    drive.mount('\/content\/gdrive')\n    default_dir = \"\/content\/gdrive\/My Drive\"\nelse:\n    default_dir = \"..\/input\/home-credit-default-risk\/\"","3e8f99e9":"def get_dataset():\n    \"\"\"\n    Minimize memory allocated usage\n    \"\"\"\n    prev_dtype = {\n        'SK_ID_PREV':np.uint32, 'SK_ID_CURR':np.uint32, 'HOUR_APPR_PROCESS_START':np.int32, 'NFLAG_LAST_APPL_IN_DAY':np.int32,\n        'DAYS_DECISION':np.int32, 'SELLERPLACE_AREA':np.int32, 'AMT_ANNUITY':np.float32, 'AMT_APPLICATION':np.float32,\n        'AMT_CREDIT':np.float32, 'AMT_DOWN_PAYMENT':np.float32, 'AMT_GOODS_PRICE':np.float32, 'RATE_DOWN_PAYMENT':np.float32,\n        'RATE_INTEREST_PRIMARY':np.float32, 'RATE_INTEREST_PRIVILEGED':np.float32, 'CNT_PAYMENT':np.float32,\n        'DAYS_FIRST_DRAWING':np.float32, 'DAYS_FIRST_DUE':np.float32, 'DAYS_LAST_DUE_1ST_VERSION':np.float32,\n        'DAYS_LAST_DUE':np.float32, 'DAYS_TERMINATION':np.float32, 'NFLAG_INSURED_ON_APPROVAL':np.float32\n    }\n    \n    bureau_dtype = {\n        'SK_ID_CURR':np.uint32, 'SK_ID_BUREAU':np.uint32, 'DAYS_CREDIT':np.int32,'CREDIT_DAY_OVERDUE':np.int32,\n        'CNT_CREDIT_PROLONG':np.int32, 'DAYS_CREDIT_UPDATE':np.int32, 'DAYS_CREDIT_ENDDATE':np.float32,\n        'DAYS_ENDDATE_FACT':np.float32, 'AMT_CREDIT_MAX_OVERDUE':np.float32, 'AMT_CREDIT_SUM':np.float32,\n        'AMT_CREDIT_SUM_DEBT':np.float32, 'AMT_CREDIT_SUM_LIMIT':np.float32, 'AMT_CREDIT_SUM_OVERDUE':np.float32,\n        'AMT_ANNUITY':np.float32\n    }\n    \n    bureau_bal_dtype = {\n        'SK_ID_BUREAU':np.int32, 'MONTHS_BALANCE':np.int32,\n    }\n    \n    pos_dtype = {\n        'SK_ID_PREV':np.uint32, 'SK_ID_CURR':np.uint32, 'MONTHS_BALANCE':np.int32, 'SK_DPD':np.int32,\n        'SK_DPD_DEF':np.int32, 'CNT_INSTALMENT':np.float32,'CNT_INSTALMENT_FUTURE':np.float32\n    }\n    \n    install_dtype = {\n        'SK_ID_PREV':np.uint32, 'SK_ID_CURR':np.uint32, 'NUM_INSTALMENT_NUMBER':np.int32, 'NUM_INSTALMENT_VERSION':np.float32,\n        'DAYS_INSTALMENT':np.float32, 'DAYS_ENTRY_PAYMENT':np.float32, 'AMT_INSTALMENT':np.float32, 'AMT_PAYMENT':np.float32\n    }\n    \n    card_dtype = {\n        'SK_ID_PREV':np.uint32, 'SK_ID_CURR':np.uint32, 'MONTHS_BALANCE':np.int16,\n        'AMT_CREDIT_LIMIT_ACTUAL':np.int32, 'CNT_DRAWINGS_CURRENT':np.int32, 'SK_DPD':np.int32,'SK_DPD_DEF':np.int32,\n        'AMT_BALANCE':np.float32, 'AMT_DRAWINGS_ATM_CURRENT':np.float32, 'AMT_DRAWINGS_CURRENT':np.float32,\n        'AMT_DRAWINGS_OTHER_CURRENT':np.float32, 'AMT_DRAWINGS_POS_CURRENT':np.float32, 'AMT_INST_MIN_REGULARITY':np.float32,\n        'AMT_PAYMENT_CURRENT':np.float32, 'AMT_PAYMENT_TOTAL_CURRENT':np.float32, 'AMT_RECEIVABLE_PRINCIPAL':np.float32,\n        'AMT_RECIVABLE':np.float32, 'AMT_TOTAL_RECEIVABLE':np.float32, 'CNT_DRAWINGS_ATM_CURRENT':np.float32,\n        'CNT_DRAWINGS_OTHER_CURRENT':np.float32, 'CNT_DRAWINGS_POS_CURRENT':np.float32, 'CNT_INSTALMENT_MATURE_CUM':np.float32\n    }\n    \n    app_train = pd.read_csv(os.path.join(default_dir, 'application_train.csv'))\n    app_test = pd.read_csv(os.path.join(default_dir, 'application_test.csv'))\n    apps = pd.concat([app_train, app_test])\n    prev = pd.read_csv(os.path.join(default_dir, 'previous_application.csv'), dtype=prev_dtype)\n    bureau = pd.read_csv(os.path.join(default_dir, 'bureau.csv'), dtype=bureau_dtype)\n    bureau_bal = pd.read_csv(os.path.join(default_dir, 'bureau_balance.csv'), dtype=bureau_bal_dtype)\n    pos_bal = pd.read_csv(os.path.join(default_dir, 'POS_CASH_balance.csv'), dtype=pos_dtype)\n    install = pd.read_csv(os.path.join(default_dir, 'installments_payments.csv'), dtype=install_dtype)\n    card_bal = pd.read_csv(os.path.join(default_dir, 'credit_card_balance.csv'), dtype=card_dtype)\n\n    return apps, prev, bureau, bureau_bal, pos_bal, install, card_bal","d7c88c27":"from sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMClassifier","692e1078":"def get_apps_processed(apps):\n    '''\n    feature engineering for apps - current loan\n    including customer information\n    '''\n    # EXT_SOURCE_X FEATURE\n    apps['APPS_EXT_SOURCE_MEAN'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n    apps['APPS_EXT_SOURCE_STD'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n    apps['APPS_EXT_SOURCE_STD'] = apps['APPS_EXT_SOURCE_STD'].fillna(apps['APPS_EXT_SOURCE_STD'].mean())\n    \n    # AMT_ANNUITY - amount should be paid per month.\n    # AMT_CREDIT  - total amount of loan.\n    # AMT_GOODS_PRICE : consumer loadn.eg) car purchase installment.\n    apps['APPS_ANNUITY_CREDIT_RATIO'] = apps['AMT_ANNUITY']\/apps['AMT_CREDIT']\n    apps['APPS_GOODS_CREDIT_RATIO'] = apps['AMT_GOODS_PRICE']\/apps['AMT_CREDIT']\n    \n    # AMT_INCOME_TOTAL : income \n    # CNT_FAM_MEMBERS  : the number of family members\n    apps['APPS_ANNUITY_INCOME_RATIO'] = apps['AMT_ANNUITY']\/apps['AMT_INCOME_TOTAL']\n    apps['APPS_CREDIT_INCOME_RATIO'] = apps['AMT_CREDIT']\/apps['AMT_INCOME_TOTAL']\n    apps['APPS_GOODS_INCOME_RATIO'] = apps['AMT_GOODS_PRICE']\/apps['AMT_INCOME_TOTAL']\n    apps['APPS_CNT_FAM_INCOME_RATIO'] = apps['AMT_INCOME_TOTAL']\/apps['CNT_FAM_MEMBERS']\n    \n    # DAYS_BIRTH : Client's age in days at the time of application\n    # DAYS_EMPLOYED : How many days before the application the person started current employment\n    apps['APPS_EMPLOYED_BIRTH_RATIO'] = apps['DAYS_EMPLOYED']\/apps['DAYS_BIRTH']\n    apps['APPS_INCOME_EMPLOYED_RATIO'] = apps['AMT_INCOME_TOTAL']\/apps['DAYS_EMPLOYED']\n    apps['APPS_INCOME_BIRTH_RATIO'] = apps['AMT_INCOME_TOTAL']\/apps['DAYS_BIRTH']\n    apps['APPS_CAR_BIRTH_RATIO'] = apps['OWN_CAR_AGE'] \/ apps['DAYS_BIRTH']\n    apps['APPS_CAR_EMPLOYED_RATIO'] = apps['OWN_CAR_AGE'] \/ apps['DAYS_EMPLOYED']\n    \n    return apps\n\ndef get_prev_processed(prev):\n    \"\"\"\n    feature engineering for previous credit amount.\n    \"\"\"\n    # AMT_APPLICATION : For how much credit did client ask on the previous application\n    # AMT_GOODS_PRICE : Goods price of good that client asked for (if applicable) on the previous application\n    prev['PREV_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n    prev['PREV_GOODS_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_GOODS_PRICE']\n    prev['PREV_CREDIT_APPL_RATIO'] = prev['AMT_CREDIT']\/ prev['AMT_APPLICATION']\n    # prev['PREV_ANNUITY_APPL_RATIO'] = prev['AMT_ANNUITY']\/prev['AMT_APPLICATION']\n    prev['PREV_GOODS_APPL_RATIO'] = prev['AMT_GOODS_PRICE'] \/ prev['AMT_APPLICATION']   \n    \n    # data cleansing\n    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n    \n    # important features for determine days overdue\n    # 1.PREV_INTERESTS_RATE : interest ratio\n    \n    prev['PREV_DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n    \n    # \ub9e4\uc6d4 \ub0a9\ubd80 \uae08\uc561\uacfc \ub0a9\ubd80 \ud69f\uc218 \uacf1\ud574\uc11c \uc804\uccb4 \ub0a9\ubd80 \uae08\uc561 \uad6c\ud568. \n    # AMT_ANNUITY : Annuity of previous application\n    all_pay = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n    # \uc804\uccb4 \ub0a9\ubd80 \uae08\uc561 \ub300\ube44 AMT_CREDIT \ube44\uc728\uc744 \uad6c\ud558\uace0 \uc5ec\uae30\uc5d0 \ub2e4\uc2dc \ub0a9\ubd80\ud69f\uc218\ub85c \ub098\ub204\uc5b4\uc11c \uc774\uc790\uc728 \uacc4\uc0b0. \n    prev['PREV_INTERESTS_RATE'] = (all_pay\/prev['AMT_CREDIT'] - 1)\/prev['CNT_PAYMENT']\n        \n    return prev\n    \n    \ndef get_prev_amt_agg(prev):\n    '''\n    A newly creatd feature aggregation \n    \uc0c8\ub86d\uac8c \uc0dd\uc131\ub41c \ub300\ucd9c \uc2e0\uccad\uc561 \ub300\ube44 \ub2e4\ub978 \uae08\uc561 \ucc28\uc774 \ubc0f \ube44\uc728\ub85c aggregation \uc218\ud589. \n    '''\n    agg_dict = {\n         # \uae30\uc874 \uceec\ub7fc aggregation. \n        'SK_ID_CURR':['count'],\n        'AMT_CREDIT':['mean', 'max', 'sum'],\n        'AMT_ANNUITY':['mean', 'max', 'sum'], \n        'AMT_APPLICATION':['mean', 'max', 'sum'],\n        'AMT_DOWN_PAYMENT':['mean', 'max', 'sum'],\n        'AMT_GOODS_PRICE':['mean', 'max', 'sum'],\n        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n        'DAYS_DECISION': ['min', 'max', 'mean'],\n        'CNT_PAYMENT': ['mean', 'sum'],\n        # \uac00\uacf5 \uceec\ub7fc aggregation\n        'PREV_CREDIT_DIFF': ['mean', 'max', 'sum'],\n        'PREV_CREDIT_APPL_RATIO':['mean', 'max'],\n        'PREV_GOODS_DIFF':['mean', 'max', 'sum'],\n        'PREV_GOODS_APPL_RATIO':['mean', 'max'],\n        'PREV_DAYS_LAST_DUE_DIFF':['mean', 'max', 'sum'],\n        'PREV_INTERESTS_RATE':['mean', 'max']\n    }\n    prev_group = prev.groupby('SK_ID_CURR')\n    prev_amt_agg = prev_group.agg(agg_dict)\n    \n    # multi index \uceec\ub7fc\uc744 '_'\ub85c \uc5f0\uacb0\ud558\uc5ec \uceec\ub7fc\uba85 \ubcc0\uacbd\n    prev_amt_agg.columns = [\"PREV_\"+ \"_\".join(x).upper() for x in prev_amt_agg.columns.ravel()]\n    return prev_amt_agg\n\ndef get_prev_refused_appr_agg(prev):\n    '''\n    Groupby SK_ID_CURR + MANE_CONTRACT_STATUS\n    \uc6d0\ub798 groupby \uceec\ub7fc + \uc138\ubd80 \uae30\uc900 \uceec\ub7fc\uc73c\ub85c groupby \uc218\ud589. \uc138\ubd84\ud654\ub41c \ub808\ubca8\ub85c aggregation \uc218\ud589 \ud55c \ub4a4\uc5d0 unstack()\uc73c\ub85c \uceec\ub7fc\ub808\ubca8\ub85c \ubcc0\ud615\n    '''\n    prev_refused_appr_group = prev[prev['NAME_CONTRACT_STATUS'].isin(['Approved', 'Refused'])].groupby(['SK_ID_CURR', 'NAME_CONTRACT_STATUS'])\n    prev_refused_appr_agg = prev_refused_appr_group['SK_ID_CURR'].count().unstack()\n    \n    # rename column\n    prev_refused_appr_agg.columns = ['PREV_APPROVED_COUNT', 'PREV_REFUSED_COUNT']\n    \n    # NaN\uac12\uc740 \ubaa8\ub450 0\uc73c\ub85c \ubcc0\uacbd. \n    prev_refused_appr_agg = prev_refused_appr_agg.fillna(0)    \n    return prev_refused_appr_agg\n\ndef get_prev_agg(prev):\n    '''\n    Aggregation for previous credit\n    '''\n    prev = get_prev_processed(prev)\n    prev = get_prev_processed(prev)\n    prev_amt_agg = get_prev_amt_agg(prev)\n    \n    # Refused or Approved previous credit\n    prev_refused_appr_agg = get_prev_refused_appr_agg(prev)\n    \n    # prev_amt_agg\uc640 \uc870\uc778. \n    prev_agg = prev_amt_agg.merge(prev_refused_appr_agg, on='SK_ID_CURR', how='left')\n    \n    # SK_ID_CURR\ubcc4 \uacfc\uac70 \ub300\ucd9c\uac74\uc218 \ub300\ube44 APPROVED_COUNT \ubc0f REFUSED_COUNT \ube44\uc728 \uc0dd\uc131. \n    prev_agg['PREV_REFUSED_RATIO'] = prev_agg['PREV_REFUSED_COUNT']\/prev_agg['PREV_SK_ID_CURR_COUNT']\n    prev_agg['PREV_APPROVED_RATIO'] = prev_agg['PREV_APPROVED_COUNT']\/prev_agg['PREV_SK_ID_CURR_COUNT']\n    \n    # 'PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT' \uceec\ub7fc drop \n    prev_agg = prev_agg.drop(['PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT'], axis = 1)\n    \n    return prev_agg\n\ndef get_bureau_processed(bureau):\n    '''\n    feature engineering for bureau\n    \uc608\uc815 \ucc44\ubb34 \uc2dc\uc791 \ubc0f \uc644\ub8cc\uc77c\uacfc \uc2e4\uc81c \ucc44\ubb34 \uc644\ub8cc\uc77c\uac04\uc758 \ucc28\uc774 \ubc0f \ub0a0\uc9dc \ube44\uc728 \uac00\uacf5.  \n    '''\n    \n    # DAYS_CREDIT_ENDDATE : CB \ud06c\ub808\ub527 \ucc44\ubb34 \uc644\ub8cc\uae4c\uc9c0 \ub0a8\uc544\uc788\ub294 \uc77c\uc218(\uc2e0\uccad\uc77c \uae30\uc900) Remaining duration of CB credit (in days) at the time of application in Home Credit\n    # DAYS_ENDDATE_FACT : CB \ud06c\ub808\ub527 \ucc44\ubb34 \uc644\ub8cc\uae4c\uc9c0 \uac78\ub9b0 \uc2e4\uc81c \uc77c\uc218(\uc2e0\uccad\uc77c \uae30\uc900, \uc0c1\ud0dc\uac00 Close\uc77c\ub54c\ub9cc) Days since CB credit ended at the time of application in Home Credit (only for closed credit)\n    # DAYS_CREDIT : \ud604\uc7ac \ub300\ucd9c \uc2e0\uccad \uc77c \uae30\uc900 \uacfc\uac70 \ub300\ucd9c \uc2e0\uccad \uc9c0\ub09c \uae30\uac04(How many days before current application did client apply for Credit Bureau credit)\n    bureau['BUREAU_ENDDATE_FACT_DIFF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n    bureau['BUREAU_CREDIT_FACT_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_ENDDATE_FACT']\n    bureau['BUREAU_CREDIT_ENDDATE_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_CREDIT_ENDDATE']\n  \n    # \ucc44\ubb34 \uae08\uc561 \ub300\ube44\/\ub300\ucd9c \uae08\uc561 \ube44\uc728 \ubc0f \ucc28\uc774 \uac00\uacf5\n    bureau['BUREAU_CREDIT_DEBT_RATIO'] = bureau['AMT_CREDIT_SUM_DEBT'] \/ bureau['AMT_CREDIT_SUM']\n    #bureau['BUREAU_CREDIT_DEPT_DIFF'] =  bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n    bureau['BUREAU_CREDIT_DEBT_DIFF'] = bureau['AMT_CREDIT_SUM_DEBT'] - bureau['AMT_CREDIT_SUM']\n    \n    # \uc5f0\uccb4 \uc5ec\ubd80 \ubc0f 120\uc77c \uc774\uc0c1 \uc5f0\uccb4 \uc5ec\ubd80 \uac00\uacf5\n    # CREDIT_DAY_OVERDUE : \ub300\ucd9c \uc2e0\uccad \uc2dc CB \ud06c\ub808\ub527 \uc5f0\uccb4 \uc77c\uc218\n    # Number of days past due on CB credit at the time of application for related loan in our sample\n    bureau['BUREAU_IS_DPD'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 0 else 0)\n    bureau['BUREAU_IS_DPD_OVER120'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 120 else 0)\n    \n    return bureau\n\ndef get_bureau_day_amt_agg(bureau):\n    '''\n    Aggregationn for bureau\n    bureau \uc8fc\uc694 \uceec\ub7fc \ubc0f \uc55e\uc5d0\uc11c \ucc44\ubb34 \ubc0f \ub300\ucd9c\uae08\uc561 \uad00\ub828 \uceec\ub7fc\ub4e4\ub85c SK_ID_CURR \ub808\ubca8\uc758 aggregation \uceec\ub7fc \uc0dd\uc131. \n    '''        \n    bureau_agg_dict = {\n    'SK_ID_BUREAU':['count'],\n    'DAYS_CREDIT':['min', 'max', 'mean'],\n    'CREDIT_DAY_OVERDUE':['min', 'max', 'mean'],\n    'DAYS_CREDIT_ENDDATE':['min', 'max', 'mean'],\n    'DAYS_ENDDATE_FACT':['min', 'max', 'mean'],\n    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n    'AMT_ANNUITY': ['max', 'mean', 'sum'],\n    # \ucd94\uac00 \uac00\uacf5 \uceec\ub7fc\n    'BUREAU_ENDDATE_FACT_DIFF':['min', 'max', 'mean'],\n    'BUREAU_CREDIT_FACT_DIFF':['min', 'max', 'mean'],\n    'BUREAU_CREDIT_ENDDATE_DIFF':['min', 'max', 'mean'],\n    'BUREAU_CREDIT_DEBT_RATIO':['min', 'max', 'mean'],\n    'BUREAU_CREDIT_DEBT_DIFF':['min', 'max', 'mean'],\n    'BUREAU_IS_DPD':['mean', 'sum'],\n    'BUREAU_IS_DPD_OVER120':['mean', 'sum']\n    }\n\n    bureau_grp = bureau.groupby('SK_ID_CURR')\n    bureau_day_amt_agg = bureau_grp.agg(bureau_agg_dict)\n    bureau_day_amt_agg.columns = ['BUREAU_'+('_').join(column).upper() for column in bureau_day_amt_agg.columns.ravel()]\n    # \uc870\uc778\uc744 \uc704\ud574 SK_ID_CURR\uc744 reset_index()\ub85c \uceec\ub7fc\ud654 \n    bureau_day_amt_agg = bureau_day_amt_agg.reset_index()\n    #print('bureau_day_amt_agg shape:', bureau_day_amt_agg.shape)\n    return bureau_day_amt_agg\n\n\ndef get_bureau_active_agg(bureau):\n    '''\n    CREDIT_ACTIVE='Active' \uc778 \ub370\uc774\ud130\ub9cc filtering\n    Bureau\uc758 CREDIT_ACTIVE='Active' \uc778 \ub370\uc774\ud130\ub9cc filtering \ud6c4 \uc8fc\uc694 \uceec\ub7fc \ubc0f \uc55e\uc5d0\uc11c \ucc44\ubb34 \ubc0f \ub300\ucd9c\uae08\uc561 \uad00\ub828 \uceec\ub7fc\ub4e4\ub85c SK_ID_CURR \ub808\ubca8\uc758 aggregation \uceec\ub7fc \uc0dd\uc131\n    '''\n    cond_active = bureau['CREDIT_ACTIVE'] == 'Active'\n    bureau_active_grp = bureau[cond_active].groupby(['SK_ID_CURR'])\n    bureau_agg_dict = {\n        'SK_ID_BUREAU':['count'],\n        'DAYS_CREDIT':['min', 'max', 'mean'],\n        'CREDIT_DAY_OVERDUE':['min', 'max', 'mean'],\n        'DAYS_CREDIT_ENDDATE':['min', 'max', 'mean'],\n        'DAYS_ENDDATE_FACT':['min', 'max', 'mean'],\n        'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n        'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n        'AMT_ANNUITY': ['max', 'mean', 'sum'],\n        # \ucd94\uac00 \uac00\uacf5 \uceec\ub7fc\n        'BUREAU_ENDDATE_FACT_DIFF':['min', 'max', 'mean'],\n        'BUREAU_CREDIT_FACT_DIFF':['min', 'max', 'mean'],\n        'BUREAU_CREDIT_ENDDATE_DIFF':['min', 'max', 'mean'],\n        'BUREAU_CREDIT_DEBT_RATIO':['min', 'max', 'mean'],\n        'BUREAU_CREDIT_DEBT_DIFF':['min', 'max', 'mean'],\n        'BUREAU_IS_DPD':['mean', 'sum'],\n        'BUREAU_IS_DPD_OVER120':['mean', 'sum']\n        }\n\n    bureau_active_agg = bureau_active_grp.agg(bureau_agg_dict)\n    bureau_active_agg.columns = ['BUREAU_ACT_'+('_').join(column).upper() for column in bureau_active_agg.columns.ravel()]\n    # \uc870\uc778\uc744 \uc704\ud574 SK_ID_CURR\uc744 reset_index()\ub85c \uceec\ub7fc\ud654 \n    bureau_active_agg = bureau_active_agg.reset_index()\n    #print('bureau_active_agg shape:', bureau_active_agg.shape)\n    return bureau_active_agg\n\ndef get_bureau_bal_agg(bureau, bureau_bal):\n    '''\n    1.BUREAU_BAL join with BUREAU\n    2.Aggregation for added features\n    bureau_bal\uc744 SK_ID_CURR \ub808\ubca8\ub85c \uac74\uc218\uc640 MONTHS_BALANCE\uc758 aggregation \uac00\uacf5 \n    '''\n    bureau_bal = bureau_bal.merge(bureau[['SK_ID_CURR', 'SK_ID_BUREAU']], on='SK_ID_BUREAU', how='left')\n    \n    # Status of Credit Bureau loan during the month (active, closed, DPD0-30,?[C means closed, X means status unknown, 0 means no DPD, \n    # 1 means maximal did during month between 1-30, 2 means DPD 31-60,?5 means DPD 120+ or sold or written off ] )\n    bureau_bal['BUREAU_BAL_IS_DPD'] = bureau_bal['STATUS'].apply(lambda x:1 if x in ['1', '2', '3', '4', '5'] else 0)\n    bureau_bal['BUREAU_BAL_IS_DPD_OVER120'] = bureau_bal['STATUS'].apply(lambda x: 1 if x =='5'  else 0)\n    \n    bureau_bal_grp = bureau_bal.groupby('SK_ID_CURR')\n    \n    # SK_ID_CURR \ub808\ubca8\ub85c \uac74\uc218\uc640 MONTHS_BALANCE\uc758 aggregation \uac00\uacf5 \n    bureau_bal_agg_dict = {\n        'SK_ID_CURR':['count'],\n        'MONTHS_BALANCE':['min', 'max', 'mean'],\n        'BUREAU_BAL_IS_DPD':['mean','sum'],\n        'BUREAU_BAL_IS_DPD_OVER120':['mean','sum']\n    }\n    bureau_bal_agg = bureau_bal_grp.agg(bureau_bal_agg_dict)\n    bureau_bal_agg.columns = ['BUREAU_BAL_'+ '_'.join(column).upper() for column in bureau_bal_agg.columns.ravel()]\n    \n    # \uc870\uc778\uc744 \uc704\ud574 SK_ID_CURR\uc744 reset_index()\ub85c \uceec\ub7fc\ud654 \n    bureau_bal_agg = bureau_bal_agg.reset_index()\n    #print('bureau_bal_agg shape:', bureau_bal_agg.shape)\n    return bureau_bal_agg\n    \n\ndef get_bureau_agg(bureau, bureau_bal):\n    '''\n    \uac00\uacf5\ub41c bureau\uad00\ub828 aggregation \uceec\ub7fc\ub4e4\uc744 \ubaa8\ub450 \uacb0\ud569   \n    '''\n    bureau = get_bureau_processed(bureau)\n    bureau_day_amt_agg = get_bureau_day_amt_agg(bureau)\n    bureau_active_agg = get_bureau_active_agg(bureau)\n    bureau_bal_agg = get_bureau_bal_agg(bureau, bureau_bal)\n    \n    # bureau_day_amt_agg\uc640 bureau_active_agg \uc870\uc778.  \n    bureau_agg = bureau_day_amt_agg.merge(bureau_active_agg, on='SK_ID_CURR', how='left')\n    \n    # STATUS\uac00 ACTIVE IS_DPD RATIO\uad00\ub828 \ube44\uc728 \uc7ac\uac00\uacf5. \n    #bureau_agg['BUREAU_IS_DPD_RATIO'] = bureau_agg['BUREAU_BUREAU_IS_DPD_SUM']\/bureau_agg['BUREAU_SK_ID_BUREAU_COUNT']\n    #bureau_agg['BUREAU_IS_DPD_OVER120_RATIO'] = bureau_agg['BUREAU_BUREAU_IS_DPD_OVER120_SUM']\/bureau_agg['BUREAU_SK_ID_BUREAU_COUNT']\n    bureau_agg['BUREAU_ACT_IS_DPD_RATIO'] = bureau_agg['BUREAU_ACT_BUREAU_IS_DPD_SUM']\/bureau_agg['BUREAU_SK_ID_BUREAU_COUNT']\n    bureau_agg['BUREAU_ACT_IS_DPD_OVER120_RATIO'] = bureau_agg['BUREAU_ACT_BUREAU_IS_DPD_OVER120_SUM']\/bureau_agg['BUREAU_SK_ID_BUREAU_COUNT']\n    \n    # bureau_agg\uc640 bureau_bal_agg \uc870\uc778. \n    bureau_agg = bureau_agg.merge(bureau_bal_agg, on='SK_ID_CURR', how='left')\n    \n    #print('bureau_agg shape:', bureau_agg.shape)\n    \n    return bureau_agg\n\ndef get_pos_bal_agg(pos_bal):  \n    '''\n    Aggregation for datasets from consumer load and balance information\n    '''\n    # \uc5f0\uccb4\uc5ec\ubd80,  \uc5f0\uccb4\uc77c\uc218 0~ 120 \uc0ac\uc774 \uc5ec\ubd80, \uc5f0\uccb4 \uc77c\uc218 120\ubcf4\ub2e4 \ud070 \uc5ec\ubd80 \n    pos_bal['POS_IS_DPD'] = pos_bal['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n    pos_bal['POS_IS_DPD_UNDER_120'] = pos_bal['SK_DPD'].apply(lambda x:1 if (x > 0) & (x <120) else 0 )\n    pos_bal['POS_IS_DPD_OVER_120'] = pos_bal['SK_DPD'].apply(lambda x:1 if x >= 120 else 0)\n\n    # \uae30\uc874 \uceec\ub7fc\uacfc \uc2e0\uaddc \uceec\ub7fc\uc73c\ub85c SK_ID_CURR \ub808\ubca8\ub85c \uc2e0\uaddc aggregation \uceec\ub7fc \uc0dd\uc131\n    pos_bal_grp = pos_bal.groupby('SK_ID_CURR')\n    pos_bal_agg_dict = {\n        'SK_ID_CURR':['count'], \n        'MONTHS_BALANCE':['min', 'mean', 'max'], \n        'SK_DPD':['min', 'max', 'mean', 'sum'],\n        'CNT_INSTALMENT':['min', 'max', 'mean', 'sum'],\n        'CNT_INSTALMENT_FUTURE':['min', 'max', 'mean', 'sum'],\n        # \ucd94\uac00 \uceec\ub7fc. \n        'POS_IS_DPD':['mean', 'sum'],\n        'POS_IS_DPD_UNDER_120':['mean', 'sum'],\n        'POS_IS_DPD_OVER_120':['mean', 'sum']\n    }    \n    pos_bal_agg = pos_bal_grp.agg(pos_bal_agg_dict)\n    \n    pos_bal_agg.columns = ['POS_'+'_'.join(column).upper() for column in pos_bal_agg.columns.ravel()]\n    \n    # MONTHS_BALANCE\uac00 \ucd5c\uadfc(20\uac1c\uc6d4 \uc774\ud558)\uc778 \ub370\uc774\ud130 \uc138\ud2b8 \ubcc4\ub3c4 \uac00\uacf5. \n    # MONTHS_BALANCE < 20 : having tendency to fall into DPD\n    cond_months = pos_bal['MONTHS_BALANCE'] > -20\n    pos_bal_m20_grp = pos_bal[cond_months].groupby('SK_ID_CURR')\n    \n    pos_bal_m20_agg_dict = {\n        'SK_ID_CURR':['count'], \n        'MONTHS_BALANCE':['min', 'mean', 'max'], \n        'SK_DPD':['min', 'max', 'mean', 'sum'],\n        'CNT_INSTALMENT':['min', 'max', 'mean', 'sum'],\n        'CNT_INSTALMENT_FUTURE':['min', 'max', 'mean', 'sum'],\n        # \ucd94\uac00 \uceec\ub7fc. \n        'POS_IS_DPD':['mean', 'sum'],\n        'POS_IS_DPD_UNDER_120':['mean', 'sum'],\n        'POS_IS_DPD_OVER_120':['mean', 'sum']\n    }\n\n    pos_bal_m20_agg = pos_bal_m20_grp.agg(pos_bal_m20_agg_dict)\n    # \uceec\ub7fc \ubcc0\uacbd \n    pos_bal_m20_agg.columns = [('POS_M20')+('_').join(column).upper() for column in pos_bal_m20_agg.columns.ravel()]\n    pos_bal_agg = pos_bal_agg.merge(pos_bal_m20_agg, on='SK_ID_CURR', how='left')\n    \n    # SK_ID_CURR\uc744 reset_index()\ub97c \uc774\uc6a9\ud558\uc5ec \uceec\ub7fc\uc73c\ub85c \ubcc0\ud658\n    pos_bal_agg = pos_bal_agg.reset_index()\n    \n    \n    return pos_bal_agg\n\ndef get_install_agg(install):\n    \"\"\"\n    \uc608\uc815 \ub0a9\ubd80 \uae08\uc561 \ub300\ube44 \uc2e4\uc81c \ub0a9\ubd80 \uae08\uc561 \uad00\ub828 \ub370\uc774\ud130 \uac00\uacf5. \uc608\uc815 \ub0a9\ubd80 \uc77c\uc790 \ub300\ube44 \uc2e4\uc81c \ub0a9\ubd80 \uc77c\uc790 \ube44\uad50\ub97c DPD \uc77c\uc790 \uc0dd\uc131  \n    \"\"\"\n    # AMT_INSTALMENT : \uc608\uc815\ub0a9\ubd80\uae08\uc561\n    # AMT_PAYMENT - \ub0a9\ubd80\uae08\uc561\n    \n    # DAYS_ENTRY_PAYMENT : When was the installments of previous credit paid actually (relative to application date of current loan - \ud604 \ub300\ucd9c\uc2e0\uccad\uc77c \ub300\ube44 \uacfc\uac70 \ub300\ucd9c\uac74 \ub300\ucd9c\ub0a9\uc785 \uc2e4\uc81c\uc77c\uc790)\n    # DAYS_INSTALMENT - When the installment of previous credit was supposed to be paid (relative to application date of current loan-\ud604 \ub300\ucd9c\uc2e0\uccad\uc77c \ub300\ube44 \uc774\uc804 \ub300\ucd9c\ub0a9\uc785 \uc608\uc815\uc77c\uc790)\n    \n    install['AMT_DIFF'] = install['AMT_INSTALMENT'] - install['AMT_PAYMENT']\n    install['AMT_RATIO'] =  (install['AMT_PAYMENT'] +1)\/ (install['AMT_INSTALMENT'] + 1)\n    install['SK_DPD'] = install['DAYS_ENTRY_PAYMENT'] - install['DAYS_INSTALMENT']\n\n    # \uc5f0\uccb4\uc5ec\ubd80,  \uc5f0\uccb4\uc77c\uc218 30~ 120 \uc0ac\uc774 \uc5ec\ubd80, \uc5f0\uccb4 \uc77c\uc218 100\ubcf4\ub2e4 \ud070 \uc5ec\ubd80 \ub370\uc774\ud130 \uac00\uacf5. \n    install['INS_IS_DPD'] = install['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n    install['INS_IS_DPD_UNDER_120'] = install['SK_DPD'].apply(lambda x: 1 if (x>0) & (x < 120) else 0)\n    install['INS_IS_DPD_OVER_120'] = install['SK_DPD'].apply(lambda x: 1 if (x >= 120) else 0)\n\n    # \uae30\uc874 \uceec\ub7fc\uacfc \uc2e0\uaddc \uceec\ub7fc\uc73c\ub85c SK_ID_CURR \ub808\ubca8\ub85c \uc2e0\uaddc aggregation \uceec\ub7fc \uc0dd\uc131. \n    install_grp = install.groupby('SK_ID_CURR')\n\n    install_agg_dict = {\n        'SK_ID_CURR':['count'],\n        'NUM_INSTALMENT_VERSION':['nunique'], \n        'DAYS_ENTRY_PAYMENT':['mean', 'max', 'sum'],\n        'DAYS_INSTALMENT':['mean', 'max', 'sum'],\n        'AMT_INSTALMENT':['mean', 'max', 'sum'],\n        'AMT_PAYMENT':['mean', 'max','sum'],\n        #  \ucd94\uac00 \uceec\ub7fc\n        'AMT_DIFF':['mean','min', 'max','sum'],\n        'AMT_RATIO':['mean', 'max'],\n        'SK_DPD':['mean', 'min', 'max'],\n        'INS_IS_DPD':['mean', 'sum'],\n        'INS_IS_DPD_UNDER_120':['mean', 'sum'],\n        'INS_IS_DPD_OVER_120':['mean', 'sum']    \n    }\n\n    install_agg = install_grp.agg(install_agg_dict)\n    install_agg.columns = ['INS_'+('_').join(column).upper() for column in install_agg.columns.ravel()]\n\n    \n    # \uc2e4\uc81c \ub0a9\ubd80 \uc77c\uc790(DAYS_ENTRY_PAYMENT)\uac00 \ube44\uad50\uc801 \ucd5c\uadfc(1\ub144 \uc774\ub0b4) \ub370\uc774\ud130\ub9cc \ubcc4\ub3c4\ub85c \uac00\uacf5\n    cond_day = install['DAYS_ENTRY_PAYMENT'] >= -365\n    install_d365_grp = install[cond_day].groupby('SK_ID_CURR')\n    install_d365_agg_dict = {\n        'SK_ID_CURR':['count'],\n        'NUM_INSTALMENT_VERSION':['nunique'], \n        'DAYS_ENTRY_PAYMENT':['mean', 'max', 'sum'],\n        'DAYS_INSTALMENT':['mean', 'max', 'sum'],\n        'AMT_INSTALMENT':['mean', 'max', 'sum'],\n        'AMT_PAYMENT':['mean', 'max','sum'],\n        #  \ucd94\uac00 \uceec\ub7fc\n        'AMT_DIFF':['mean','min', 'max','sum'],\n        'AMT_RATIO':['mean', 'max'],\n        'SK_DPD':['mean', 'min', 'max'],\n        'INS_IS_DPD':['mean', 'sum'],\n        'INS_IS_DPD_UNDER_120':['mean', 'sum'],\n        'INS_IS_DPD_OVER_120':['mean', 'sum']    \n    }\n    \n    install_d365_agg = install_d365_grp.agg(install_d365_agg_dict)\n    install_d365_agg.columns = ['INS_D365'+('_').join(column).upper() for column in install_d365_agg.columns.ravel()]\n    \n    install_agg = install_agg.merge(install_d365_agg, on='SK_ID_CURR', how='left')\n    install_agg = install_agg.reset_index()\n    \n    return install_agg\n\ndef get_card_bal_agg(card_bal):\n    '''\n    # \uc6d4\ubcc4 \uce74\ub4dc \ud5c8\uc6a9\ud55c\ub3c4\uc5d0 \ub530\ub978 \uc794\uace0\uc640 \uc778\ucd9c \uae08\uc561 \ube44\uc728 \n    '''\n    card_bal['BALANCE_LIMIT_RATIO'] = card_bal['AMT_BALANCE']\/card_bal['AMT_CREDIT_LIMIT_ACTUAL']\n    card_bal['DRAWING_LIMIT_RATIO'] = card_bal['AMT_DRAWINGS_CURRENT'] \/ card_bal['AMT_CREDIT_LIMIT_ACTUAL']\n\n    # DPD\uc5d0 \ub530\ub978 \uac00\uacf5 \uceec\ub7fc \uc0dd\uc131.\n    card_bal['CARD_IS_DPD'] = card_bal['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n    card_bal['CARD_IS_DPD_UNDER_120'] = card_bal['SK_DPD'].apply(lambda x:1 if (x > 0) & (x <120) else 0 )\n    card_bal['CARD_IS_DPD_OVER_120'] = card_bal['SK_DPD'].apply(lambda x:1 if x >= 120 else 0)\n\n    # \uae30\uc874 \uceec\ub7fc\uacfc \uac00\uacf5 \uceec\ub7fc\uc73c\ub85c SK_ID_CURR \ub808\ubca8\ub85c aggregation \uc2e0\uaddc \uceec\ub7fc \uc0dd\uc131. \n    card_bal_grp = card_bal.groupby('SK_ID_CURR')\n    card_bal_agg_dict = {\n        'SK_ID_CURR':['count'],\n         #'MONTHS_BALANCE':['min', 'max', 'mean'],\n        'AMT_BALANCE':['max'],\n        'AMT_CREDIT_LIMIT_ACTUAL':['max'],\n        'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n        'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n        'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n        'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n        'AMT_PAYMENT_TOTAL_CURRENT': ['max','sum'],\n        'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n        'CNT_DRAWINGS_ATM_CURRENT': ['max','sum'],\n        'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n        'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n        'SK_DPD': ['mean', 'max', 'sum'],\n        #  \ucd94\uac00 \uceec\ub7fc\n        'BALANCE_LIMIT_RATIO':['min','max'],\n        'DRAWING_LIMIT_RATIO':['min', 'max'],\n        'CARD_IS_DPD':['mean', 'sum'],\n        'CARD_IS_DPD_UNDER_120':['mean', 'sum'],\n        'CARD_IS_DPD_OVER_120':['mean', 'sum']    \n    }\n    card_bal_agg = card_bal_grp.agg(card_bal_agg_dict)\n    card_bal_agg.columns = ['CARD_'+('_').join(column).upper() for column in card_bal_agg.columns.ravel()]\n\n    card_bal_agg = card_bal_agg.reset_index()\n    \n    # MONTHS_BALANCE\uac00 \ube44\uad50\uc801 \ucd5c\uadfc \ub370\uc774\ud130( 3\uac1c\uc6d4 \uc774\ud558)\ub9cc \ubcc4\ub3c4\ub85c \uac00\uacf5.  \n    cond_month = card_bal.MONTHS_BALANCE >= -3\n    card_bal_m3_grp = card_bal[cond_month].groupby('SK_ID_CURR')\n    card_bal_m3_agg = card_bal_m3_grp.agg(card_bal_agg_dict)\n    card_bal_m3_agg.columns = ['CARD_M3'+('_').join(column).upper() for column in card_bal_m3_agg.columns.ravel()]\n    \n    card_bal_agg = card_bal_agg.merge(card_bal_m3_agg, on='SK_ID_CURR', how='left')\n    card_bal_agg = card_bal_agg.reset_index()\n    \n    return card_bal_agg\n\ndef get_apps_all_encoded(apps_all):\n    \"\"\"\n    factorize for object columns and return apps_all\n    \"\"\"\n    object_columns = apps_all.dtypes[apps_all.dtypes == 'object'].index.to_list()\n    for column in object_columns:\n        apps_all[column] = pd.factorize(apps_all[column])[0]\n    return apps_all\ndef get_apps_all_train_test(apps_all):\n    \"\"\"\n    split train, test and return train datasets, test datasets\n    \"\"\"\n    apps_all_train = apps_all[~apps_all['TARGET'].isnull()]\n    apps_all_test = apps_all[apps_all['TARGET'].isnull()]\n    apps_all_test = apps_all_test.drop('TARGET', axis = 1)\n    return apps_all_train, apps_all_test","7bda03d0":"def get_apps_all_with_all_agg(apps, prev, bureau, bureau_bal, pos_bal, install, card_bal):\n    '''\n    apps\uc640 prev_agg, bureau_agg, pos_bal_agg, install_agg, card_bal_agg\ub97c \uac1c\ubcc4 \ud568\uc218 \ud638\ucd9c\ud558\uc5ec \uc0dd\uc131\ud6c4 \uc870\uc778 \uacb0\ud569\n    '''\n    apps_all =  get_apps_processed(apps)\n    prev_agg = get_prev_agg(prev)\n    bureau_agg = get_bureau_agg(bureau, bureau_bal)\n    pos_bal_agg = get_pos_bal_agg(pos_bal)\n    install_agg = get_install_agg(install)\n    card_bal_agg = get_card_bal_agg(card_bal)\n    print('prev_agg shape:', prev_agg.shape, 'bureau_agg shape:', bureau_agg.shape )\n    print('pos_bal_agg shape:', pos_bal_agg.shape, 'install_agg shape:', install_agg.shape, 'card_bal_agg shape:', card_bal_agg.shape)\n    print('apps_all before merge shape:', apps_all.shape)\n    \n    # \uc0dd\uc131\ub41c prev_agg, bureau_agg, pos_bal_agg, install_agg, card_bal_agg\ub97c apps\uc640 \uc870\uc778\ud558\uc5ec \ucd5c\uc885 \ud559\uc2b5\/\ud14c\uc2a4\ud2b8 \uc9d1\ud569 \uc0dd\uc131. \n    apps_all = apps_all.merge(prev_agg, on='SK_ID_CURR', how='left')\n    apps_all = apps_all.merge(bureau_agg, on='SK_ID_CURR', how='left')\n    apps_all = apps_all.merge(pos_bal_agg, on='SK_ID_CURR', how='left')\n    apps_all = apps_all.merge(install_agg, on='SK_ID_CURR', how='left')\n    apps_all = apps_all.merge(card_bal_agg, on='SK_ID_CURR', how='left')\n    \n    print('apps_all after merge with all shape:', apps_all.shape)\n    \n    return apps_all","e084b35e":"apps, prev, bureau, bureau_bal, pos_bal, install, card_bal = get_dataset()\n\n# application, previous, bureau, bureau_bal \uad00\ub828 \ub370\uc774\ud130\uc14b \uac00\uacf5 \ubc0f \ucde8\ud569. \napps_all = get_apps_all_with_all_agg(apps, prev, bureau, bureau_bal, pos_bal, install, card_bal)\n\n# Category \uceec\ub7fc\uc744 \ubaa8\ub450 Label \uc778\ucf54\ub529 \uc218\ud589. \napps_all = get_apps_all_encoded(apps_all)\n\n# \ud559\uc2b5\uacfc \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\ub85c \ubd84\ub9ac. \napps_all_train, apps_all_test = get_apps_all_train_test(apps_all)","55c6a9b2":"apps_all_train.shape, apps_all_test.shape","151d69bb":"np.zeros(10)  # note that 1 dim","91ebedb3":"from sklearn.model_selection import KFold","c0a589c4":"def train_apps_all_with_oof(apps_all_train, apps_all_test, nfolds=5):\n    \"\"\"\n    Predict credit risk using OOF(Out of Fold) method \n    Parameter : apps_all_train, apps_all_test, nfolds count\n    \"\"\"\n    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)  # feature dateset\n    target_app = apps_all_train['TARGET']                           # target datasets\n\n    # nfolds \uac1c\uc758 cross validatin fold set\uc744 \uac00\uc9c0\ub294 KFold \uc0dd\uc131 \n    folds = KFold(n_splits = nfolds, shuffle=True, random_state = 2020)\n    \n    #  Out of Folds\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 validation set\uc744 \uc608\uce21\ud558\uc5ec \uacb0\uacfc \ud655\ub960\uc744 \ub2f4\uc744 array \uc0dd\uc131.\n    # validation set\uac00 n_split\uac2f\uc218\ub9cc\ud07c \uc788\uc73c\ubbc0\ub85c \ud06c\uae30\ub294 ftr_app\uc758 \ud06c\uae30\uac00 \ub418\uc5b4\uc57c \ud568. \n    oof_preds = np.zeros(ftr_app.shape[0])\n    \n    # Ouf of Folds\ub85c \ud559\uc2b5\ub41c \ubaa8\ub378\uc758 test dataset\uc744 \uc608\uce21\ud558\uc5ec \uacb0\uacfc \ud655\ub960\uc744 \ub2f4\uc744 array \uc0dd\uc131. \n    test_preds = np.zeros(apps_all_test.shape[0])\n    \n    # n_estimators\ub97c 4000\uae4c\uc9c0 \ud655\ub300. \n    # \ud604\uc7ac \ub370\uc774\ud130\uc14b\uc73c\ub85c \ud558\uc774\ud130 \ud30c\ub77c\ubbf8\ud130\ub97c \ud29c\ub2dd\ud558\ub294\uac83\uc774 \ubc14\ub78c\uc9c1.\n    clf = LGBMClassifier(\n                nthread=4,\n                n_estimators=4000,\n                learning_rate=0.01,\n                max_depth = 11,\n                num_leaves=58,\n                colsample_bytree=0.613,\n                subsample=0.708,\n                max_bin=407,\n                reg_alpha=3.564,\n                reg_lambda=4.930,\n                min_child_weight= 6,\n                min_child_samples=165,\n                silent=-1,\n                verbose=-1,\n                )\n\n    # nfolds \ubc88 cross validation Iteration \ubc18\ubcf5\ud558\uba74\uc11c OOF \ubc29\uc2dd\uc73c\ub85c \ud559\uc2b5 \ubc0f \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc608\uce21\n    for fold_idx, (train_idx , valid_idx) in enumerate(folds.split(ftr_app)):\n        print(\"##### iteration \", fold_idx, 'starts')\n        # \ud559\uc2b5\uc6a9 \ub370\uc774\ud130 \uc138\ud2b8\uc758 \uc778\ub371\uc2a4\uc640 \uac80\uc99d\uc6a9 \ub370\uc774\ud130 \uc138\ud2b8\uc758 \uc778\ub371\uc2a4 \ucd94\ucd9c\ud558\uc5ec \uc774\ub97c \uae30\ubc18\uc73c\ub85c \ud559\uc2b5\/\uac80\uc99d \ub370\uc774\ud130 \ucd94\ucd9c\n        train_x = ftr_app.iloc[train_idx, :]\n        train_y = target_app.iloc[train_idx]\n        valid_x = ftr_app.iloc[valid_idx, :]\n        valid_y = target_app.iloc[valid_idx]\n\n        # \ucd94\ucd9c\ub41c \ud559\uc2b5\/\uac80\uc99d \ub370\uc774\ud130 \uc138\ud2b8\ub85c \ubaa8\ub378 \ud559\uc2b5. early_stopping\uc740 200\uc73c\ub85c \uc99d\uac00. \n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 200, \n                early_stopping_rounds= 200)\n        \n        # \uac80\uc99d \ub370\uc774\ud130 \uc138\ud2b8\ub85c \uc608\uce21\ub41c \ud655\ub960 \uc800\uc7a5 \uc0ac\uc6a9\ub418\uc9c0\ub294 \uc54a\uc74c. \n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)[:, 1]\n        \n        # \ud559\uc2b5\ub41c \ubaa8\ub378\ub85c \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc138\ud2b8\uc5d0 \uc608\uce21 \ud655\ub960 \uacc4\uc0b0. \n        # nfolds \ubc88 \ubc18\ubcf5 \uc2e4\ud589\ud558\ubbc0\ub85c \ud3c9\uade0 \ud655\ub960\uc744 \uad6c\ud558\uae30 \uc704\ud574 \uac1c\ubcc4 \uc218\ud589\uc2dc \ub9c8\ub2e4 \uc218\ud589 \ud69f\uc218\ub85c \ub098\ub208 \ud655\ub960\uc744 \ucd94\ud6c4\uc5d0 \ub354\ud574\uc11c \ucd5c\uc885 \ud3c9\uade0 \ud655\ub960 \uacc4\uc0b0. \n        # num_iteration  - stops at the time of early stopping\n        # [0 - normal , 1 - overdue] : fetch the probability of overdue\n        # Predecited probabily should be mean value \n        test_preds += clf.predict_proba(apps_all_test.drop('SK_ID_CURR', axis = 1),num_iteration=clf.best_iteration_)[:, 1] \/ folds.n_splits\n        \n    return clf, test_preds","0cec8bb2":"import datetime\n \nprint(\"Starting Time \" , datetime.datetime.now())\n\nclf, test_preds = train_apps_all_with_oof(apps_all_train, apps_all_test, nfolds=5)\n\nprint(\"End Time : \", datetime.datetime.now())\n\n'''\nPrivate Score: 0.79440, Public Score: 0.80178\n'''\n","66da20e5":"display(test_preds.shape, test_preds)","baff6612":"apps_all_test['TARGET'] = test_preds\nif platform =='google':\n    default_dir = \"\/content\/gdrive\/My Drive\"\nelse:\n    default_dir = \"..\/working\/\"\napps_all_test[['SK_ID_CURR', 'TARGET']].to_csv(os.path.join(default_dir,'oof_all_01.csv'), index=False)","b842575b":"apps_all_test = apps_all_test.drop(['TARGET'], axis=1)","7ea936be":"##### \ucf54\ub7a9 \ubc84\uc804\uc740 Google Drive\uc5d0\uc11c \ub370\uc774\ud130 \uc138\ud2b8\ub97c \ub85c\ub529","96f41ebd":"### CVS for predicted result","6c1d8d68":"### Modulization for Feature Engineering","64ca3f0c":"### Creation of the final train and test datasets","6f9146f7":"## Calculated the running avg of predicted probability with OOF Prediction","42239757":"### Ouf Of Fold Prediction","f06d190f":"### load data as pandas DataFrame","27b07d18":"### Load Package"}}