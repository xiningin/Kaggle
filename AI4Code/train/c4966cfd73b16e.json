{"cell_type":{"40aea061":"code","7770449e":"code","8a44e145":"code","d5f50324":"code","cfb4be50":"code","4a965ff2":"code","334d9662":"code","24d1b928":"code","0f394deb":"code","f2a8b616":"code","902b5047":"code","48eb1663":"code","bead3625":"code","c9223ad1":"code","f12e7d3a":"code","7df19866":"code","0efcca78":"code","e7f00d9d":"code","42e84fcb":"code","e2c904ef":"code","dea208cd":"markdown","98106027":"markdown","a9ac6b5d":"markdown","13ede5a3":"markdown","2a18756c":"markdown","f5fd2e8c":"markdown","9af4b7a2":"markdown","8ce897e9":"markdown","c1a7f4be":"markdown","b2dd0aa5":"markdown","3a1562aa":"markdown","5f88740d":"markdown","eae1d3e0":"markdown","60467e19":"markdown","eed97d31":"markdown","9b1152c0":"markdown","b3202d83":"markdown","8c5972cf":"markdown","4a7970e1":"markdown","e725c558":"markdown","cdcf23aa":"markdown","15a28774":"markdown","39425e13":"markdown","cceeeef6":"markdown","1e29ab9b":"markdown","e26757c6":"markdown","786b8fe4":"markdown","72bebae5":"markdown","7489e660":"markdown","9f42fc6d":"markdown","24296ece":"markdown","b5638da1":"markdown","a60e5242":"markdown"},"source":{"40aea061":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n# Any results you write to the current directory are saved as output.","7770449e":"df= pd.read_csv(\"..\/input\/Tweets.csv\")\ndf.head()","8a44e145":"print(\"Shape of the dataframe is\",df.shape)\nprint(\"The number of nulls in each column are \\n\", df.isna().sum())","d5f50324":"print(\"Percentage null or na values in df\")\n((df.isnull() | df.isna()).sum() * 100 \/ df.index.size).round(2)","cfb4be50":"del df['tweet_coord']\ndel df['airline_sentiment_gold']\ndel df['negativereason_gold']\ndf.head()","4a965ff2":"print(\"Total number of tweets for each airline \\n \",df.groupby('airline')['airline_sentiment'].count().sort_values(ascending=False))\nairlines= ['US Airways','United','American','Southwest','Delta','Virgin America']\nplt.figure(1,figsize=(12, 12))\nfor i in airlines:\n    indices= airlines.index(i)\n    plt.subplot(2,3,indices+1)\n    new_df=df[df['airline']==i]\n    count=new_df['airline_sentiment'].value_counts()\n    Index = [1,2,3]\n    plt.bar(Index,count, color=['red', 'green', 'blue'])\n    plt.xticks(Index,['negative','neutral','positive'])\n    plt.ylabel('Mood Count')\n    plt.xlabel('Mood')\n    plt.title('Count of Moods of '+i)","334d9662":"from wordcloud import WordCloud,STOPWORDS\n","24d1b928":"new_df=df[df['airline_sentiment']=='negative']\nwords = ' '.join(new_df['text'])\ncleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(cleaned_word)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","0f394deb":"new_df=df[df['airline_sentiment']=='positive']\nwords = ' '.join(new_df['text'])\ncleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and word != 'RT'\n                            ])\nwordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(cleaned_word)\nplt.figure(1,figsize=(12, 12))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","f2a8b616":"\n\n# Calculate highest frequency words in positive tweets\ndef freq(str): \n  \n    # break the string into list of words  \n    str = str.split()          \n    str2 = [] \n  \n    # loop till string values present in list str \n    for i in str:              \n  \n        # checking for the duplicacy \n        if i not in str2: \n  \n            # insert value in str2 \n            str2.append(i)  \n              \n    for i in range(0, len(str2)): \n        if(str.count(str2[i])>50): \n            print('Frequency of', str2[i], 'is :', str.count(str2[i]))\n        \nprint(freq(cleaned_word))","902b5047":"#get the number of negative reasons\ndf['negativereason'].nunique()\n\nNR_Count=dict(df['negativereason'].value_counts(sort=False))\ndef NR_Count(Airline):\n    if Airline=='All':\n        a=df\n    else:\n        a=df[df['airline']==Airline]\n    count=dict(a['negativereason'].value_counts())\n    Unique_reason=list(df['negativereason'].unique())\n    Unique_reason=[x for x in Unique_reason if str(x) != 'nan']\n    Reason_frame=pd.DataFrame({'Reasons':Unique_reason})\n    Reason_frame['count']=Reason_frame['Reasons'].apply(lambda x: count[x])\n    return Reason_frame\ndef plot_reason(Airline):\n    \n    a=NR_Count(Airline)\n    count=a['count']\n    Index = range(1,(len(a)+1))\n    plt.bar(Index,count, color=['red','yellow','blue','green','black','brown','gray','cyan','purple','orange'])\n    plt.xticks(Index,a['Reasons'],rotation=90)\n    plt.ylabel('Count')\n    plt.xlabel('Reason')\n    plt.title('Count of Reasons for '+Airline)\n    \nplot_reason('All')\nplt.figure(2,figsize=(13, 13))\nfor i in airlines:\n    indices= airlines.index(i)\n    plt.subplot(2,3,indices+1)\n    plt.subplots_adjust(hspace=0.9)\n    plot_reason(i)","48eb1663":"date = df.reset_index()\n#convert the Date column to pandas datetime\ndate.tweet_created = pd.to_datetime(date.tweet_created)\n#Reduce the dates in the date column to only the date and no time stamp using the 'dt.date' method\ndate.tweet_created = date.tweet_created.dt.date\ndate.tweet_created.head()\ndf = date\nday_df = df.groupby(['tweet_created','airline','airline_sentiment']).size()\n# day_df = day_df.reset_index()\nday_df","bead3625":"day_df = day_df.loc(axis=0)[:,:,'negative']\n\n#groupby and plot data\nax2 = day_df.groupby(['tweet_created','airline']).sum().unstack().plot(kind = 'bar', color=['red', 'green', 'blue','yellow','purple','orange'], figsize = (15,6), rot = 70)\nlabels = ['American','Delta','Southwest','US Airways','United','Virgin America']\nax2.legend(labels = labels)\nax2.set_xlabel('Date')\nax2.set_ylabel('Negative Tweets')\nplt.show()","c9223ad1":"def tweet_to_words(tweet):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \",tweet) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return( \" \".join( meaningful_words )) ","f12e7d3a":"df['clean_tweet']=df['text'].apply(lambda x: tweet_to_words(x))\n","7df19866":"train,test = train_test_split(df,test_size=0.2,random_state=42)\n","0efcca78":"train_clean_tweet=[]\nfor tweet in train['clean_tweet']:\n    train_clean_tweet.append(tweet)\ntest_clean_tweet=[]\nfor tweet in test['clean_tweet']:\n    test_clean_tweet.append(tweet)","e7f00d9d":"from sklearn.feature_extraction.text import CountVectorizer\nv = CountVectorizer(analyzer = \"word\")\ntrain_features= v.fit_transform(train_clean_tweet)\ntest_features=v.transform(test_clean_tweet)","42e84fcb":"Classifiers = [\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=200)]","e2c904ef":"dense_features=train_features.toarray()\ndense_test= test_features.toarray()\nAccuracy=[]\nModel=[]\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(train_features,train['airline_sentiment'])\n        pred = fit.predict(test_features)\n    except Exception:\n        fit = classifier.fit(dense_features,train['airline_sentiment'])\n        pred = fit.predict(dense_test)\n    accuracy = accuracy_score(pred,test['airline_sentiment'])\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print('Accuracy of '+classifier.__class__.__name__+'is '+str(accuracy))\n    print(classification_report(pred,test['airline_sentiment']))\n    cm=confusion_matrix(pred , test['airline_sentiment'])\n    plt.figure()\n    plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Reds)\n    plt.xticks(range(2), ['Negative', 'Neutral', 'Positive'], fontsize=16,color='black')\n    plt.yticks(range(2), ['Negative', 'Neutral', 'Positive'], fontsize=16)\n    plt.show()","dea208cd":"- Decision Tree Classifier\n- Random Forest Classifier","98106027":"* Words like **Thanks**, **best**, **customer** , **love**, **flying** , **good** are understandably present in the **most frequent** words of positive tweets. \n* However, other than these, most of the words are stop words and need to be filtered. We will do so later.\n* Lets try and visualize the reasons for negative tweets first !!","a9ac6b5d":"### Wordcloud for Negative sentiments of tweets","13ede5a3":"We will explore the **negative reason** column of our dataframe to extract conclusions about negative sentiments in the tweets by the customers ","2a18756c":"The data is split in the standard 80,20 ratio.","f5fd2e8c":"Now, we will clean the tweet text data and apply classification algorithms on it","9af4b7a2":"- Firstly lets calculate the total number of tweets for each airline\n- Then, we are going to get the barplots for each airline with respect to sentiments of tweets (positive,negative or neutral).\n- This will give us a clearer idea about the airline sentiments , airlines relationship. ","8ce897e9":"### Wordcloud for positive reasons","c1a7f4be":"Wordcloud is a great tool for visualizing nlp data. The larger the words in the wordcloud image , the more is the frequency of that word in our text data.","b2dd0aa5":"### Prediciting sentiments from tweet text data ","3a1562aa":"- Interestingly, **American** has a sudden upsurge in negative sentimental tweets on **2015-02-23**, which reduced to half the very next day **2015-02-24**. (*I hope American is doing better these days and resolved their Customer Service Issue as we saw before*)\n- **Virgin America** has the least number of negative tweets throughout the weekly data that we have. It should be noted that the total number of tweets for **Virgin America** was also significantly less as compared to the rest airlines, and hence the least negative tweets.\n- The negative tweets for all the rest airlines is slightly skewed towards the end of the week !","5f88740d":"To get a better idea, lets calculate the percentage of nulls or NA values in each column","eae1d3e0":"The first step should be to check the shape of the dataframe and then check the number of null values in each column.\n\nIn this way we can get an idea of the redundant columns in the data frame depending on which columns have the highest number of null values.","60467e19":"This shows the sentiments of tweets for each date from **2015-02-17** to **2015-02-24** for every airline in our dataframe.\n\nOur next step will be to plot this and get better visualization for negative tweets.","eed97d31":"## Most used words in Positive and Negative tweets ","9b1152c0":"- Customer Service Issue is the main neagtive reason for US Airways,United,American,Southwest,Virgin America\n- Late Flight is the main negative reason for Delta  \n- Interestingly, Virgin America has the least count of negative reasons (all less than 60)\n- Contrastingly to Virgin America, airlines like US Airways,United,American have more than 500 negative reasons (Late flight, Customer Service Issue)","b3202d83":"### Airline sentiments for each airline\n","8c5972cf":" - United, US Airways, American substantially get negative reactions.\n - Tweets for Virgin America are the most balanced.","4a7970e1":"Breakdown of this notebook:\n1. Loading the dataset: Load the data and import the libraries.\n2. Data Preprocessing:\n     - Analysing missing data \n     - Removing redundant columns.\n3. Visualising and counting sentiments of tweets for each airline\n4. Wordcloud plots for positive and negative tweets to visualise most frequent words for each.\n5. Analysing the reasons for negative tweets for each airline.\n6. Visualising negative tweet-sentiment relationship with dates.\n7. Predicting the tweet sentiments with tweet text data with:\n      - Decision Tree Classifier\n      - Random Forest Classifier\n8. Calculating accuracies, plotting the confusion matrix and comparing the models.","e725c558":"\n#### ANY FEEDBACK IN THE COMMENTS WILL BE HIGHLY APPRECIATED.","cdcf23aa":"### Data Preprocessing","15a28774":"### What are the reasons for negative sentimental tweets for each airline ?","39425e13":"### Importing the libraries and loading the data","cceeeef6":"### Is there a relationship between negative sentiments and date ?","1e29ab9b":"#### Lets try and calculate the highest frequency words in postive sentimental tweets","e26757c6":"\n\n#### Please feel free to upvote and comment if you found this to be helpful !!","786b8fe4":"### References:- \nI learnt a lot from this blog which shows you how to handle nlp data and implement data preprocessing and explanatory visualization for better understanding.\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2018\/07\/hands-on-sentiment-analysis-dataset-python\/","72bebae5":"Our dataframe has data from **2015-02-17** to **2015-02-24**\n\nIt will be interesting to see if the date has any effect on the sentiments of the tweets(*especially negative !*). We can draw various coclusions by visualizing this.","7489e660":"- The goal is to firstly get an idea of the most frequent words in negative tweets.\n- Get idea about most frequent words in positive tweets.","9f42fc6d":"The code for getting positive sentiments is completely same with the one for negative sentiments. Just replace negative with positive in the first line. Easy, right!","24296ece":"### Preprocessing the tweet text data","b5638da1":"- As we you can see above we have plotted the **confusion matrix** for predicted sentiments and actual sentiments (negative,neutral and positive)\n- **Random Forest Classifier** gives us the best accuracy score, precision scores according to the classification report.\n- The confusion matrix shows the TP,TN,FP,FN for all the 3 sentiments(negative,neutral and positive),Here also **Random Forest Classifier** gives **better** results than the **Decision Tree Classifier**.","a60e5242":"**tweet_coord , airline_sentiment_gold, negativereason_gold**  have more than 90% missing data. It will be better to delete these columns as they will not provide any constructive information.\n\n"}}