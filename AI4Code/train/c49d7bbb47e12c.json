{"cell_type":{"d599d982":"code","0c35cf9e":"code","67f06994":"code","8c81fc9c":"code","16308ac4":"code","804b1446":"code","8f4c1664":"code","615c8601":"code","1c8151b0":"code","9309bc2d":"code","40a79559":"code","651bc194":"code","56e70948":"code","a24e3459":"code","91938cec":"code","1b5b0322":"code","4d776650":"code","c0654ebc":"code","cd378007":"code","769cf379":"code","6b2fa078":"code","561f4355":"code","cd8a9bc9":"code","64d9d4d1":"code","1054374d":"code","115647c0":"code","0e1a9730":"code","8469748b":"code","0909c423":"markdown","34501fa9":"markdown","55a029fd":"markdown","ac945e07":"markdown","34ca46c0":"markdown","ba1e333a":"markdown"},"source":{"d599d982":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","0c35cf9e":"train_data = pd.read_csv('\/kaggle\/input\/leaf-classification\/train.csv.zip',index_col='id')\ntest_data = pd.read_csv('\/kaggle\/input\/leaf-classification\/test.csv.zip')","67f06994":"train_data.head()","8c81fc9c":"test_data.head()","16308ac4":"test_id=test_data.id\ntest_data = test_data.drop(['id'], axis =1)","804b1446":"test_data.head()","8f4c1664":"train_data.shape","615c8601":"test_data.shape","1c8151b0":"train_data.isnull().any().sum()","9309bc2d":"test_data.isnull().any().sum()","40a79559":"train_data.info()","651bc194":"test_data.info()","56e70948":"train_data['species'].nunique()","a24e3459":"from sklearn.preprocessing import LabelEncoder\n\nle=LabelEncoder().fit(train_data.species)\nlabels=le.transform(train_data.species)\nclasses=list(le.classes_)","91938cec":"classes","1b5b0322":"labels","4d776650":"X=train_data.drop(['species'],axis=1).values\nY=labels","c0654ebc":"X","cd378007":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=1,shuffle=True,stratify=Y)","769cf379":"from sklearn.ensemble import RandomForestClassifier\nclassifier2=RandomForestClassifier(n_estimators = 40,n_jobs=4)\nclassifier2.fit(x_train,y_train)","6b2fa078":"classifier2.score(x_test,y_test)","561f4355":"y_pred2=classifier2.predict_proba(x_test)\n","cd8a9bc9":"y_pred2","64d9d4d1":"sample_data = pd.read_csv('\/kaggle\/input\/leaf-classification\/sample_submission.csv.zip',index_col='id')\nsample_data.head()","1054374d":"final_pred=classifier2.predict_proba(test_data) # final prediction on test_data","115647c0":"final_pred","0e1a9730":"submission = pd.DataFrame(final_pred, columns=classes)\nsubmission.insert(0, 'id', test_id)\nsubmission.reset_index()","8469748b":"submission.to_csv('submission.csv', index = False)","0909c423":"## Splitting Data","34501fa9":"# Label Encoding","55a029fd":"# Species is our categorical column which is our Target column","ac945e07":"## Data set details\nThe dataset consists approximately 1,584 images of leaf specimens (16 samples each of 99 species) which have been converted to binary black leaves against white backgrounds. Three sets of features are also provided per image: a shape contiguous descriptor, an interior texture histogram, and a \ufb01ne-scale margin histogram. For each feature, a 64-attribute vector is given per leaf sample.\n\nNote that of the original 100 species, we have eliminated one on account of incomplete associated data in the original dataset.","34ca46c0":"# Random Forest Classifier","ba1e333a":"# Data fields\n\nid - an anonymous id unique to an image\n\nmargin_1, margin_2, margin_3, ..., margin_64 - each of the 64 attribute vectors for the margin feature\n\nshape_1, shape_2, shape_3, ..., shape_64 - each of the 64 attribute vectors for the shape feature\n\ntexture_1, texture_2, texture_3, ..., texture_64 - each of the 64 attribute vectors for the texture feature"}}