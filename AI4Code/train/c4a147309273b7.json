{"cell_type":{"9a4b0066":"code","813cdad2":"code","d96ca3d3":"code","213f0f10":"code","d5962371":"code","1e0ae901":"code","36c2f99f":"code","e6d2dbf5":"code","e00258bd":"code","23fec3d8":"code","2b2938d5":"code","fe683587":"code","d8f78cc8":"code","35860003":"code","af839d19":"code","0a361cf5":"code","e2504243":"code","a539cc74":"code","2025b5b5":"code","ebcd73ff":"code","054c715f":"code","a11b29eb":"code","ecd5631e":"code","9f6ea4aa":"code","0611f294":"code","a489f7dc":"code","1d0e1459":"code","0f7135c9":"code","7d3d288e":"code","0ad27654":"code","105def4b":"code","a6df3870":"code","101ba023":"code","8a846d3c":"code","db3ab0ec":"code","d85a8e76":"code","fcca4517":"code","1c619df1":"code","9fc389b6":"code","edcb2f82":"code","09303044":"code","1054c6e5":"code","9ec7d866":"code","562e07c7":"code","d7203a70":"markdown","50f8e2ac":"markdown","3464a55a":"markdown","8624b809":"markdown"},"source":{"9a4b0066":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","813cdad2":"df = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\n\ndf","d96ca3d3":"from scipy.stats import chi2_contingency","213f0f10":"ct = pd.crosstab(df['gender'], df['stroke'])\nchi2_contingency(ct)","d5962371":"ct_marry = pd.crosstab(df['ever_married'], df['stroke'])\nct_marry","1e0ae901":"29 \/ (1728+29)","36c2f99f":"220 \/ (3133+220)","e6d2dbf5":"chi2_contingency(ct_marry)[1].round(5)","e00258bd":"df.groupby(['ever_married', 'gender'])['stroke'].agg(['sum', 'count', 'mean']).reset_index()","23fec3d8":"df.groupby(['ever_married', 'gender'])['stroke'].agg(['sum', 'mean']).reset_index().plot(kind='bar')","2b2938d5":"df['Residence_type'].value_counts()","fe683587":"ct_residence = pd.crosstab(df['Residence_type'], df['stroke'])\nct_residence","d8f78cc8":"ct_residence.plot.bar()","35860003":"sorted(df['age'].unique())","af839d19":"df['work_type'].value_counts()","0a361cf5":"ct_job = pd.crosstab(df['work_type'], df['stroke'])\nct_job","e2504243":"ct_job.plot.bar()","a539cc74":"import seaborn as sns","2025b5b5":"sns.scatterplot(data=df, x='age', y='stroke', hue='stroke')","ebcd73ff":"cats, values = pd.factorize(df.age)\nprint('catagory: {}'.format(cats))\nprint('value: {}'.format(values))","054c715f":"df_ = df.copy()\ndf_['is_over_40'] = df['age'].apply(lambda  x: x >= 40)\ndf_.head()","a11b29eb":"df_.drop(['age', 'id'], axis=1, inplace=True)","ecd5631e":"df_","9f6ea4aa":"df_[['hypertension', 'heart_disease', 'stroke']].corr()['stroke']","0611f294":"ct_dis_by_stroke = pd.crosstab([df.hypertension, df.heart_disease], df.stroke, margins = True).reset_index()","a489f7dc":"ct_dis_by_stroke.style.background_gradient(cmap = 'summer_r')","1d0e1459":"import matplotlib.pyplot as plt\nct_dis_by_stroke.plot.bar(figsize=(10,15))\nplt.show()","0f7135c9":"df_","7d3d288e":"df.bmi.isna().sum()","0ad27654":"# 'avg_glucose_level'\nsns.scatterplot(data= df, x='avg_glucose_level', y='stroke', hue='stroke')","105def4b":"df_[['avg_glucose_level', 'stroke']].corr()","a6df3870":" 'smoking_status'\npd.crosstab(df['smoking_status'], df['stroke'])","101ba023":"%config Completer.use_jedi = False","8a846d3c":"from sklearn.model_selection import train_test_split","db3ab0ec":"train, test = train_test_split(df_, test_size=0.2, stratify=df_['stroke'])\n\ntrain.shape, test.shape","d85a8e76":"target = 'stroke'\n\nX_train = train.drop(target, axis=1)\ny_train = train[target]\nX_test = test.drop(target, axis=1)\ny_test = test[target]","fcca4517":"y_train.value_counts(normalize=True)","1c619df1":"y_test.value_counts(normalize=True)","9fc389b6":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom category_encoders import OrdinalEncoder, OneHotEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, classification_report, accuracy_score","edcb2f82":"def run_model(model):\n    pipe = make_pipeline(\n        OrdinalEncoder(),\n        SimpleImputer(),\n        model\n    )\n    return pipe","09303044":"def evaluate(model, X, y):\n    y_pred = model.predict(X)\n    f1 = f1_score(y, y_pred)\n    roc_auc = roc_auc_score(y, y_pred)\n    acc = accuracy_score(y, y_pred)\n    print('Confusion_Matrix')\n    print(confusion_matrix(y, y_pred))\n    print('f1: ', f1)\n    print('roc_auc: ', roc_auc)\n    print('Acc : ', acc)","1054c6e5":"rf_clf = run_model(RandomForestClassifier(class_weight='balanced'))\nrf_clf.fit(X_train, y_train)\nevaluate(rf_clf, X_test, y_test)","9ec7d866":"xgb_clf = run_model(XGBClassifier(n_jobs=-1, random_state=33, n_estimators=200))\nxgb_clf.fit(X_train, y_train)\nevaluate(xgb_clf, X_test, y_test)","562e07c7":"lgbm_clf = run_model(LGBMClassifier(n_jobs=-1, random_state=33, n_estimators=200))\nlgbm_clf.fit(X_train, y_train)\nevaluate(lgbm_clf, X_test, y_test)","d7203a70":"# Split Data","50f8e2ac":"['work type']","3464a55a":"# 3>1>2>0","8624b809":"# Model Selection"}}