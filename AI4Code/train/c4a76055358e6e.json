{"cell_type":{"ebbdb788":"code","34a23a8d":"code","ba091573":"code","a5a42e1f":"code","b2a0c4d3":"code","b349c04e":"code","d47b59a6":"code","f4c569dc":"code","c0fd4a54":"code","dc2e3059":"code","59e98b81":"code","4b5f648b":"code","528f120e":"code","8d2b9c2d":"code","93118fe2":"code","c13e4640":"code","84dd5c3d":"code","1e78c9ca":"code","295af90f":"code","54a6e048":"code","cb05a269":"code","71844180":"code","d34f1faf":"code","7e3dda92":"code","d95f4667":"code","4ff35606":"code","ed6c3cf5":"code","b3916675":"code","fbd5e614":"code","f548a42e":"code","11ed0716":"code","c3d61c61":"code","48b91269":"code","6c911a74":"code","798d150b":"code","7febdd59":"code","2d17076c":"code","ba1a458a":"code","550a9fa9":"code","5b25dccd":"code","1dd6523f":"code","13692f43":"code","155cc60f":"code","1ee1133c":"code","083be29b":"code","87da17fb":"code","c8f8f410":"code","0c14e503":"code","4f6fdad0":"code","5131b2be":"code","82801ad8":"code","a7399bd5":"code","cad32381":"code","67a40415":"code","40571ee3":"code","ce7ead9a":"code","9f677ff0":"code","7ab0371e":"code","f22e6fa9":"code","6db0d867":"code","ceaba735":"code","4bfabc04":"code","0567a2cd":"code","35140cd8":"code","31aaf588":"code","5f1799fe":"code","824e0246":"code","acc16abc":"code","4ad6e3bf":"code","dfef4244":"code","9209d528":"code","7aeaa76a":"code","8817fb5f":"code","de8cd42c":"code","fc6673d2":"code","da75a9fc":"code","f72eaec2":"code","e3711cb4":"code","9fc31357":"code","008fc5e6":"code","0a6aa56a":"code","ecaff36f":"code","c38973e9":"code","093564e6":"code","a017f1a6":"code","e4a318cb":"code","4dfc680b":"code","616c41a2":"code","508f149f":"code","8309a9ae":"code","791f95e4":"code","047ea42b":"code","984f4449":"markdown","f2bd2a38":"markdown","83eb5794":"markdown","d00b2c5b":"markdown","1cade42b":"markdown","55db4195":"markdown","2c3b0112":"markdown","eba508c4":"markdown","c2374aed":"markdown","64e120e3":"markdown","f66f6ebe":"markdown","82bddb12":"markdown","52ffff9c":"markdown","94502fac":"markdown","7c16e817":"markdown","3f983a8c":"markdown","78ed7f4a":"markdown","9d5bf4ae":"markdown","5ac9f020":"markdown","f51e9c6b":"markdown","e6c077d7":"markdown","07e68b39":"markdown","6f469b3c":"markdown","eeadc2f5":"markdown","b57339f3":"markdown","eee5d17e":"markdown","143b9664":"markdown","dcac33a5":"markdown","76cdf4b1":"markdown","9c64fa26":"markdown","ae932df4":"markdown","120964ee":"markdown","df0ac4e4":"markdown","b66bf712":"markdown","64a181e3":"markdown","e48cb501":"markdown","da038dcc":"markdown","348cc466":"markdown","811333db":"markdown","fb5563e1":"markdown","8aefa80d":"markdown","8c9ca453":"markdown","444e5b47":"markdown","9a6d0b72":"markdown","9d514535":"markdown","8f5f623b":"markdown","732968a8":"markdown","89fabd75":"markdown","8b5239ad":"markdown"},"source":{"ebbdb788":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings('ignore')  #Ignore the warnings from python\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","34a23a8d":"plt.style.available  #Available Graphic Sections","ba091573":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","a5a42e1f":"test_df.info()","b2a0c4d3":"train_df.columns","b349c04e":"train_df.head()","d47b59a6":"train_df.describe()","f4c569dc":"train_df.info()","c0fd4a54":"def bar_plot(variable):\n    \"\"\"\n    input: variable ex: \"Sex\"\n    output: bar plot & value count\n    \"\"\"\n    #get feature\n    var = train_df[variable]\n    #count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    #visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable, varValue))\n    ","dc2e3059":"category1 = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\nfor c in category1:\n    bar_plot(c)","59e98b81":"category2 = [\"Cabin\", \"Name\", \"Ticket\"]\n\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","4b5f648b":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_df[variable], bins = 50) #bins parameter\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","528f120e":"numericVar = [\"Fare\", \"Age\", \"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","8d2b9c2d":"# Pclass vs Survived\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)\n#According to Pclass, group the survived and died numbers, take the means and sort values","93118fe2":"# Sex vs Survived\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","c13e4640":"# SibSp vs Survived\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","84dd5c3d":"# Parch vs Survived\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","1e78c9ca":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        #1st quartile\n        Q1 = np.percentile(df[c],25)\n        #2nd quartile\n        Q3 = np.percentile(df[c],75)\n        #IQR\n        IQR = Q3 - Q1\n        #Outlier step\n        outlier_step = IQR * 1.5\n        #Detect outlier and their indices\n        outlier_list_col = df[(df[c] < Q1 - outlier_step ) | (df[c] > Q3 + outlier_step )].index\n        #Store Ind\u0131ces\n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v>2)\n    return multiple_outliers","295af90f":"train_df.loc[detect_outliers(train_df, [\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","54a6e048":"#Drop outliers\n\ntrain_df = train_df.drop(detect_outliers(train_df, [\"Age\",\"SibSp\",\"Parch\",\"Fare\"]), axis = 0).reset_index(drop = True)","cb05a269":"train_df.info()","71844180":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df, test_df],axis = 0).reset_index(drop = True)","d34f1faf":"train_df.columns[train_df.isnull().any()] #Detect missing values' titles","7e3dda92":"train_df.isnull().sum()","d95f4667":"train_df[train_df[\"Embarked\"].isnull()]","4ff35606":"#We can predict approximate result of Embarked by using fare\ntrain_df.boxplot(column = \"Fare\", by = \"Embarked\")\nplt.show()","ed6c3cf5":"#As we can see, C class is more closer to the 80 which is fare for unknown passengers\n#We can fill these Embarked info as C\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","b3916675":"train_df[train_df[\"Fare\"].isnull()]","fbd5e614":"#His class was 3, we can predict his fare according to Pclass (Mean value of passengers have their Pclass is 3)\ntrain_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))","f548a42e":"train_df[train_df[\"Fare\"].isnull()]","11ed0716":"list1 = [\"SibSp\", \"Parch\", \"Age\" , \"Fare\"  ,\"Survived\"]\nsns.heatmap(train_df[list1].corr(),annot = True, fmt = \".2f\")","c3d61c61":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","48b91269":"g = sns.factorplot(x = \"Parch\", y =\"Survived\", kind =\"bar\", data = train_df, size = 6)\ng.set_ylabels=(\"Survived Probability\")\nplt.show()","6c911a74":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","798d150b":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","7febdd59":"g = sns.FacetGrid(train_df, col=\"Survived\", row = \"Pclass\", size = 2)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","2d17076c":"g = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\ng.map(sns.pointplot,\"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","ba1a458a":"g = sns.FacetGrid(train_df, row= \"Embarked\", col=\"Survived\", size = 2.3)\ng.map(sns.barplot, \"Sex\",\"Fare\")\ng.add_legend()\nplt.show()","550a9fa9":"train_df[train_df[\"Age\"].isnull()]","5b25dccd":"#To predict ages, we can see the genders\n\nsns.factorplot(x=\"Sex\",y=\"Age\",data=train_df, kind = \"box\")\nplt.show()","1dd6523f":"#Let's have a look at the Pclass\nsns.factorplot(x=\"Sex\",y=\"Age\",hue = \"Pclass\",data=train_df, kind = \"box\")\nplt.show()","13692f43":"    #Let's have a look at the Parch\nsns.factorplot(x=\"Parch\",y=\"Age\",data=train_df, kind = \"box\")\nsns.factorplot(x=\"SibSp\",y=\"Age\",data=train_df, kind = \"box\")\nplt.show()","155cc60f":"#1 for male, 0 for female\ntrain_df[\"Sex\"]= [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","1ee1133c":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),annot=True)\nplt.show()","083be29b":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred =train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) & (train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"]) & (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med\n","87da17fb":"train_df[train_df[\"Age\"].isnull()]","c8f8f410":"train_df","0c14e503":"train_df[\"Name\"].head(10)","4f6fdad0":"#EXAMPLE\ns = \"McCarthy, Mr. Timothy J\"\ns.split(\".\")[0].split(\",\")[1].strip() #strip method deletes the spaces where begin and end.","5131b2be":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[1].strip() for i in name]","82801ad8":"train_df[\"Title\"].head(10)","a7399bd5":"sns.countplot(x = \"Title\", data=train_df)\nplt.xticks(rotation = 60)\nplt.show()","cad32381":"#Convert to categorical\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady, the Countess\", \"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] = [0 if i ==\"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i ==\"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)","67a40415":"sns.countplot(x = \"Title\", data=train_df)\nplt.xticks(rotation = 60)\nplt.show()","40571ee3":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Surivival Probability\")\nplt.show()","ce7ead9a":"train_df","9f677ff0":"#Dividing title feature as 4 feature\ntrain_df = pd.get_dummies(train_df, columns = [\"Title\"])\ntrain_df.head()","7ab0371e":"train_df.head()","f22e6fa9":"train_df[\"Fsize\"] =train_df[\"SibSp\"] + train_df[\"Parch\"] +1  # +1 for the passenger","6db0d867":"train_df","ceaba735":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data =train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","4bfabc04":"train_df[\"family_size\"] = [1 if i <5 else 0 for i in train_df[\"Fsize\"]]","0567a2cd":"train_df.head(10)","35140cd8":"sns.countplot(x = \"family_size\",data=train_df)\nplt.show()","31aaf588":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data =train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","5f1799fe":"train_df = pd.get_dummies(train_df, columns= [\"family_size\"])\ntrain_df.head()","824e0246":"train_df[\"Embarked\"].head()","acc16abc":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","4ad6e3bf":"train_df = pd.get_dummies(train_df, columns = [\"Embarked\"])\ntrain_df.head()","dfef4244":"train_df[\"Ticket\"].head(20)","9209d528":"#EXAMPLE\na = \"A\/5. 2151\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]","7aeaa76a":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","8817fb5f":"train_df[\"Ticket\"].head(20)","de8cd42c":"train_df.head()","fc6673d2":"train_df = pd.get_dummies(train_df, columns = [\"Ticket\"], prefix = \"T\") #When the columns are created, use \"T\" as title instead of \"Ticket\"\ntrain_df.head(10)","da75a9fc":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","f72eaec2":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\") #Converting categorical\ntrain_df = pd.get_dummies(train_df, columns = [\"Pclass\"])\ntrain_df.head()","e3711cb4":"train_df[\"Sex\"] = [\"male\" if i == 1 else \"female\" for i in train_df[\"Sex\"]]\ntrain_df.head()","9fc31357":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns = [\"Sex\"])\ntrain_df.head()","008fc5e6":"train_df.drop(labels = [\"PassengerId\",\"Cabin\",\"Name\"], axis = 1, inplace = True)","0a6aa56a":"train_df.columns","ecaff36f":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","c38973e9":"train_df_len","093564e6":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)","a017f1a6":"test.head()","e4a318cb":"train = train_df[: train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","4dfc680b":"logreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\naccuracy_log_train = round(logreg.score(X_train,y_train)*100,2) #Rounding with 2 decimal after comma\naccuracy_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(accuracy_log_train))\nprint(\"Testing Accuracy: % {}\".format(accuracy_log_test))","616c41a2":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n              RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\nsvc_param_grid = { \"kernel\" : [\"rbf\"],\n                  \"gamma\" : [0.001,0.01,0.1,1],\n                  \"C\": [1,10,50,100,200,300,1000]}\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\": [1,3,10],\n                \"bootstrap\": [False],\n                \"n_estimators\": [100,300],\n                \"criterion\":[\"gini\"]}\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10,dtype = int).tolist(),\n                 \"weights\":[\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid, svc_param_grid, rf_param_grid, logreg_param_grid, knn_param_grid]","508f149f":"cv_result = []\nbest_estimator = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i],param_grid = classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1, verbose =1) #KFold Cross Validation will be used.\n    #njobs means that code runs parallel, verbose means when code is running results are shown to us.\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimator.append(clf.best_estimator_)\n    print(cv_result[i])","8309a9ae":"cv_results = pd.DataFrame({\"Cross Validation Means\": cv_result, \"ML Models\": [\"DecisionTreeClassifier\", \"SVC\", \n                          \"RandomForestClassifier\", \"LogisticRegression\", \"KNeighborsClassifier\"]})\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","791f95e4":"#We selected 3 best accurate ML models and we will merge them via Voting Classifier\nvotingC = VotingClassifier(estimators = [(\"dt\", best_estimator[0]),\n                                        (\"rfc\", best_estimator[2]),\n                                        (\"lr\", best_estimator[3])],\n                                        voting = \"soft\", n_jobs = -1)\n#voting = \"hard\" : If three votes is like that (0, 0 ,1), result is 0.\n#voting = \"soft\" : If three votes is like that (0, 0 ,1), results(probabilities) are added on probability table. The biggest probability is become as result.\n\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","047ea42b":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived], axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","984f4449":"<a id ='12' ><\/a> <br>\n\n## Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived","f2bd2a38":"<a id ='6' ><\/a> <br>\n\n# Basic Data Analysis\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","83eb5794":"<a id = \"33\" ><\/a> <br>\n\n## Ensemble Modeling","d00b2c5b":"* Age is not correlated with sex but it is correlated with pach, sibsp and pclass.","1cade42b":"* According to its title (Mr. or Mrs.), we can describe his or her gender that helps survived or not","55db4195":"<a id = \"34\" ><\/a> <br>\n\n## Prediction and Submission","2c3b0112":"<a id = \"22\" ><\/a> <br>\n\n# Name -- Title","eba508c4":"* float64(2): Fare and Age\n* int64(5): PassengerId, Survived, Pclass, SibSp and Parch\n* object(5): Name, Sex, Ticket, Cabin and Embarked","c2374aed":"<a id = \"32\" ><\/a> <br>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\n*We will compare 5 ML classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","64e120e3":"* Sex is not informative for age prediction. Age distribution seems to be same.","f66f6ebe":"<a id = \"24\" ><\/a> <br>\n\n# Embarked","82bddb12":"<a id ='15' ><\/a> <br>\n\n## Pclass -- Survived\n","52ffff9c":"<a id = \"28\" ><\/a> <br>\n\n# Drop Passenger ID and Cabin","94502fac":"<a id ='3' ><\/a> <br>\n\n# Univariate Variable Analysis\n* Categorical Variable: Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp and Parch\n* Numerical Variable: Fare, Age and PassengerId","7c16e817":"<a id ='8' ><\/a> <br>\n\n# Missing Value\n* Find Missing Value\n* Fill Missing Value","3f983a8c":"<a id = \"18\" ><\/a> <br>\n        \n## Embarked -- Sex -- Pclass -- Survived","78ed7f4a":"<a id ='2' ><\/a> <br>\n# **Variable Description**\n\n1. PassengerId: Unique identify number for each passenger at ship\n2. Survived: Passenger survived or not (0: died, 1: survived)\n3. Pclass: Passenger class\n4. Name: Name of the passenger\n5. Sex: Gender of the passenger\n6. Age: Age of the passenger\n7. SibSp: Number of siblings or spouse in Titanic\n8. Parch: Number of parents or children in Titanic\n9. Ticket: Ticket number\n10. Fare: Amount of money spent for ticket\n11. Cabin: Cabin category for accomodation in Titanic\n12. Embarked: Ports where passengers embarked (C = Cherbourg, Q = Queenstown, S=Southampton)","9d5bf4ae":"<a id = \"30\" ><\/a> <br>\n\n## Train - Test - Split","5ac9f020":"# **Introduction**\n\nSinking of the Titanic is one of the most damaged and popular crash in the history. In 1912, Titanic sank after colliding to an iceberg. As a result of this situation, lots of workers and clients injured and died. \n\n<font color = 'blue' >\n    Contents:\n\n1. [Load and Check Data](#1)   \n2. [Variable Description](#2)   \n    * [Univariate Variable Analysis](#3)\n        * [Categorical Variable Analysis](#4)\n        * [Numerical Variable Analysis](#5)\n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n6. [Visualization](#11)\n    * [Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    * [Sibsp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Survived -- Age](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill Missing: Age Feature](#20)\n7. [Feature Engineering](#21)\n    * [Name -- Title](#22)\n    * [Family Size](#23)\n    * [Embarked](#24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Drop Passenger ID and Cabin](#28)\n8. [Modeling](#29)\n    * [Train - Test - Split](#30)\n    * [Simple Logistic Regression](#31)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n    * [Ensemble Modeling](#33)\n    * [Prediction and Submission](#34)\n","f51e9c6b":"* Female passengers have much better survival rate than males.\n* Males have better survival rate in pclass 3 in C.\n* Embarked and sex will be used in training.","e6c077d7":"<a id = \"20\" ><\/a> <br>\n\n# Fill Missing: Age Feature","07e68b39":"* Pclass is important feature for model training.","6f469b3c":"<a id ='14' ><\/a> <br>\n\n## Parch -- Survived","eeadc2f5":"Fare feature seems to have correlation with survived feature (0.26).","b57339f3":"<a id = \"26\" ><\/a> <br>\n\n# Pclass","eee5d17e":"<a id ='1' ><\/a> <br>\n### **Load and Check Data**","143b9664":"* Large families' survival probability is lower than the small families.","dcac33a5":"<a id ='10' ><\/a> <br>\n\n# Fill Missing Value\n\n* Embarked has 2 missing value\n* Fare has only 1","76cdf4b1":"<a id ='13' ><\/a> <br>\n\n## SibSp -- Survived","9c64fa26":"<a id ='5' ><\/a> <br>\n\n## Numerical Variable:","ae932df4":"<a id = \"19\" ><\/a> <br>\n\n## Embarked -- Sex -- Fare -- Survived","120964ee":"<a id = \"23\" ><\/a> <br>\n\n# Family Size","df0ac4e4":"* Pclass is helpful to predict age values\n* First class is older than 2nd and 2nd is older than 3rd class.","b66bf712":"<a id ='11' ><\/a> <br>\n\n# Visualization","64a181e3":"<a id ='16' ><\/a> <br>\n\n## Age -- Survived","e48cb501":"* As we can see, we filled the age values","da038dcc":"<a id = \"29\" ><\/a> <br>\n\n# Modeling","348cc466":"* SibSp and parch can be used for new feature extraction with th = 3\n* Small families have more chance to survive.\n* There is a std in survival of passenger with parch = 3","811333db":"* Having a lot of SibSp have less chance to survive.\n* If sibsp == 0 or 1 or 2, passenger has more chance to survive.\n* We can consider a new feature describing these categories.","fb5563e1":"<a id = \"21\" ><\/a> <br>\n\n# Feature Engineering\n","8aefa80d":"<a id = \"27\" ><\/a> <br>\n\n# Sex","8c9ca453":"<a id ='7' ><\/a> <br>\n# Outlier Detection","444e5b47":"* Passengers who paid higher fare had better survival. Fare can be used as categorical for training.","9a6d0b72":"<a id = \"31\" ><\/a> <br>\n\n## Simple Logistic Regression","9d514535":"* Age <= 10 has a high survival rate,\n* Oldest passengers (80) survived,\n* Large number of 20 years old did not survive,\n* Most passengers are in 15-35 age range,\n* Use age feature in training\n* Use age distribution for missing value of age","8f5f623b":"<a id ='4' ><\/a> <br>\n\n## Categorical Variable:\n","732968a8":"<a id ='17' ><\/a> <br>\n\n## Pclass -- Survived -- Age","89fabd75":"<a id = \"25\" ><\/a> <br>\n\n# Ticket","8b5239ad":"<a id ='9' ><\/a> <br>\n\n# Find Missing Value"}}