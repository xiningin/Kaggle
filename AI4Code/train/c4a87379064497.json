{"cell_type":{"716b3763":"code","62679ad0":"code","44537eac":"code","10440bf6":"code","72d37ce2":"code","de0d665f":"code","0df49d6a":"code","9e0dd6e1":"code","f190921c":"code","c1fabed9":"code","23be8ab6":"code","9b9a3734":"code","94abf15a":"code","aa227eb4":"code","6ea81373":"code","66d360b6":"code","11450dd6":"code","bd06883c":"code","62fcd814":"code","6ffe4520":"code","a2906bfe":"code","b501f4cf":"code","2f6df6fd":"code","d7ce9ae5":"code","7dbc1981":"code","ae22faa4":"code","b147b714":"code","ec1d7cb2":"code","18f6a545":"code","b0220c66":"code","3f980cf7":"code","91d347ce":"code","2ece746c":"code","0d4bafff":"code","24f3caa1":"code","51993421":"code","8411756c":"code","1470292f":"code","35a3d68e":"code","ae3c88d2":"code","8a3b8830":"code","0a48820d":"code","d3a838ad":"code","a2383e3b":"code","75766def":"code","afcc464a":"code","cb2f0159":"code","1fec5658":"markdown","ac2c6a77":"markdown","b1f53ec6":"markdown","dc92b603":"markdown"},"source":{"716b3763":"import pandas as pd\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_transformer\nimport sklearn\nimport warnings\nimport lightgbm as lgb\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import log_loss","62679ad0":"def draw_plot(fig_size_x = 15,\n              fig_size_y = 10,\n              tick_params_labelsize = 14,\n             xlabel_name_fontsize = 20,\n             ylabel_name_fontsize = 20,\n             title_name_fontsize = 20,\n             xlabel_name = \"\", ylabel_name = \"\",title_name = \"\"):\n    \n    #get current figure \n    fig=plt.gcf()\n    \n    #set the size of the figure\n    fig.set_size_inches(fig_size_x,fig_size_y)\n\n    #get axes of the current figure \n    ax =  fig.gca()\n\n    # set the label size of the ticks of the axes\n    ax.tick_params(labelsize=tick_params_labelsize)\n\n    # set the label size of the x axis\n    ax.set_xlabel(xlabel_name,fontsize = xlabel_name_fontsize)\n\n    # set the label size of the y axis\n    ax.set_ylabel(ylabel_name,fontsize = ylabel_name_fontsize)\n\n     # set the title of the plot\n    ax.set_title(title_name,fontsize = title_name_fontsize)","44537eac":"train = pd.read_csv('..\/input\/sliced-s01e02-xunyc5\/train.csv')\ntest =  pd.read_csv('..\/input\/sliced-s01e02-xunyc5\/test.csv')\nsub = pd.read_csv('..\/input\/sliced-s01e02-xunyc5\/sample_submission.csv')","10440bf6":"train.head()","72d37ce2":"len(train)","de0d665f":"test.head()","0df49d6a":"len(test)","9e0dd6e1":"sub.head()","f190921c":"train.dtypes","c1fabed9":"# Get list of categorical variables\ns = (train.dtypes == 'object')\nobject_cols = list(s[s].index)\nprint(object_cols)","23be8ab6":"features_cat = ['operator', 'aircraft', 'aircraft_type', 'aircraft_make', \n                'engine_model', 'engine_type', 'engine3_position', 'airport', 'state', \n                'faa_region', 'flight_phase', 'visibility', 'precipitation', 'species_name', \n                'flight_impact','species_quantity']\nprint(features_cat)","9b9a3734":"def plot_categorical_var_distro(col,dataset = train,head_rows = 10,fig_size_x = 15,fig_size_y = 5 ):\n    data_group = dataset[col].value_counts().reset_index().head(head_rows)\n    sns.barplot( y = 'index', x = col, data = data_group, color=\"blue\")\n\n    title_name = str(col) + \" Count\"\n    xlabel_name = str(col)\n    ylabel_name = \"Count\"\n    draw_plot(fig_size_x = fig_size_x,fig_size_y = fig_size_y,\n             xlabel_name = xlabel_name, ylabel_name = ylabel_name,title_name = title_name)","94abf15a":"plot_categorical_var_distro(\"aircraft\")","aa227eb4":"plot_categorical_var_distro(\"aircraft_make\")","6ea81373":"palette ={0: \"green\", 1: \"red\"}","66d360b6":"col = \"aircraft_make\"","11450dd6":"def plot_categorical(col,train,description = \"\"):\n    data_group = train.groupby([col,\"damaged\"])[\"id\"].count().reset_index() \\\n.sort_values( by = 'id',ascending = False).head(10) \n    \n    \n    \n    sns.barplot( y = 'id', x = col, data = data_group, hue=\"damaged\",palette = palette)\n\n    title_name = col + \" distribution \" + description\n    xlabel_name = col\n    ylabel_name = \"Count\"\n    draw_plot(xlabel_name = xlabel_name,ylabel_name = ylabel_name,title_name = title_name)","bd06883c":"plot_categorical(\"aircraft_make\",train[train[\"damaged\"] == 1],description = \" Damaged only\")","62fcd814":"def plot_continous_var_distro(col,color):\n    sns.displot(train[col],kde = False, color = color)\n\n    title_name = col + \" distribution\"\n    xlabel_name = col\n    ylabel_name = \"Count\"\n\n    draw_plot(xlabel_name = xlabel_name,ylabel_name = ylabel_name,title_name = title_name)","6ffe4520":"def plot_continous_var_distro_with_damaged(col):\n    \n    palette ={0: \"green\", 1: \"red\"}\n    sns.displot(train, x= col,kde = False, hue = \"damaged\",palette = palette,multiple='dodge')\n\n    title_name = col + \" distribution\"\n    xlabel_name = col\n    ylabel_name = \"Count\"\n\n    draw_plot(xlabel_name = xlabel_name,ylabel_name = ylabel_name,title_name = title_name)","a2906bfe":"s = (train.dtypes != 'object')\nnumeric_cols = list(s[s].index)\nprint(numeric_cols)","b501f4cf":"plot_continous_var_distro(\"engines\",\"#a34d33\")","2f6df6fd":"plot_continous_var_distro_with_damaged(\"engines\")","d7ce9ae5":"plot_continous_var_distro(\"incident_month\",\"#a33362\")","7dbc1981":"plot_continous_var_distro_with_damaged(\"incident_month\")","ae22faa4":"train=train.fillna(0)","b147b714":"features_num = ['incident_year', 'incident_month', \n                 'incident_day', 'aircraft_model', 'aircraft_mass', \n                 'engine_make', 'engines', 'engine1_position', \n                 'engine2_position', 'engine4_position', \n                 'height', 'speed', 'distance']\nprint(features_num)","ec1d7cb2":"for col in features_cat:\n    train[col] = train[col].apply(lambda x:str(x))","18f6a545":"preprocessor = make_column_transformer(\n    (StandardScaler(), features_num),\n    (OneHotEncoder(handle_unknown = \"ignore\"), features_cat)\n)","b0220c66":"# Separate target from predictors\ny = train.damaged\nX = train.drop(['damaged','id','operator_id'], axis=1)","3f980cf7":"# Divide data into training and validation subsets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)","91d347ce":"len(X_train.columns),X_train.columns","2ece746c":"X_train = preprocessor.fit_transform(X_train)\nX_valid = preprocessor.transform(X_valid)","0d4bafff":"#https:\/\/johaupt.github.io\/scikit-learn\/tutorial\/python\/data%20processing\/ml%20pipeline\/model%20interpretation\/columnTransformer_feature_names.html\ndef get_feature_names(column_transformer):\n    \"\"\"Get feature names from all transformers.\n    Returns\n    -------\n    feature_names : list of strings\n        Names of the features produced by transform.\n    \"\"\"\n    # Remove the internal helper function\n    #check_is_fitted(column_transformer)\n    \n    # Turn loopkup into function for better handling with pipeline later\n    def get_names(trans):\n        # >> Original get_feature_names() method\n        if trans == 'drop' or (\n                hasattr(column, '__len__') and not len(column)):\n            return []\n        if trans == 'passthrough':\n            if hasattr(column_transformer, '_df_columns'):\n                if ((not isinstance(column, slice))\n                        and all(isinstance(col, str) for col in column)):\n                    return column\n                else:\n                    return column_transformer._df_columns[column]\n            else:\n                indices = np.arange(column_transformer._n_features)\n                return ['x%d' % i for i in indices[column]]\n        if not hasattr(trans, 'get_feature_names'):\n        # >>> Change: Return input column names if no method avaiable\n            # Turn error into a warning\n            warnings.warn(\"Transformer %s (type %s) does not \"\n                                 \"provide get_feature_names. \"\n                                 \"Will return input column names if available\"\n                                 % (str(name), type(trans).__name__))\n            # For transformers without a get_features_names method, use the input\n            # names to the column transformer\n            if column is None:\n                return []\n            else:\n                return [name + \"__\" + f for f in column]\n\n        return [name + \"__\" + f for f in trans.get_feature_names()]\n    \n    ### Start of processing\n    feature_names = []\n    \n    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n    if type(column_transformer) == sklearn.pipeline.Pipeline:\n        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]\n    else:\n        # For column transformers, follow the original method\n        l_transformers = list(column_transformer._iter(fitted=True))\n    \n    \n    for name, trans, column, _ in l_transformers: \n        if type(trans) == sklearn.pipeline.Pipeline:\n            # Recursive call on pipeline\n            _names = get_feature_names(trans)\n            # if pipeline has no transformer that returns names\n            if len(_names)==0:\n                _names = [name + \"__\" + f for f in column]\n            feature_names.extend(_names)\n        else:\n            feature_names.extend(get_names(trans))\n    \n    return feature_names\n","24f3caa1":"    params = {\n            'boosting_type': 'gbdt',\n            'objective': 'binary',\n            'metric': 'binary_logloss',\n            'max_depth': 8,\n            'num_leaves': 31,\n            'learning_rate': 0.015,\n            'feature_fraction': 0.85,\n            'bagging_fraction': 0.85,\n            'bagging_freq': 5,\n            'verbose': -1,\n            'num_threads': 1,\n            'lambda_l2': 1.0,\n            'min_gain_to_split': 0,\n        }  ","51993421":"lgb_train = lgb.Dataset(\nX_train, \ny_train\n)\nlgb_train.raw_data = None\n\nlgb_valid = lgb.Dataset(\n X_valid, y_valid\n)\nlgb_valid.raw_data = None","8411756c":"model = lgb.train(\n    params,\n    lgb_train,\n    num_boost_round=10000,\n    valid_sets=[lgb_train, lgb_valid],\n    early_stopping_rounds=100,\n    verbose_eval=0,\n)","1470292f":"#https:\/\/stackoverflow.com\/questions\/53413701\/feature-importance-using-lightgbm\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\ndef plotImp(model, num = 20, fig_size = (40, 20)):\n    feature_imp = pd.DataFrame({'Value':model.feature_importance(),'Feature':get_feature_names(preprocessor)})\n    plt.figure(figsize=fig_size)\n    sns.set(font_scale = 5)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n                                                        ascending=False)[0:num])\n    plt.title('LightGBM Features ')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances-01.png')\n    plt.show()","35a3d68e":"plotImp(model)","ae3c88d2":"test = test.fillna(0)","8a3b8830":"folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold_n, (trn_idx, val_idx) in enumerate(folds.split(train, train['damaged'])):\n    print('Fold: %s, Train size: %s, Validation size %s' % \n      (fold_n, len(trn_idx), len(val_idx)))\n    train[('fold_%s' % fold_n)] = 0\n    train[('fold_%s' % fold_n)].loc[trn_idx] = 'train'\n    train[('fold_%s' % fold_n)].loc[val_idx] = 'validation'","0a48820d":"preds_list=[]\nlogloss_list = []","d3a838ad":"for i in range(5):\n    \n    colname = \"fold_\" + str(i)\n    train_df = train[(train[colname] == 'train')]\n    valid_df = train[(train[colname] == 'validation')]\n    \n    # Separate target from predictors\n    y_train = train_df['damaged']\n    X_train = train_df.drop(['damaged','id','operator_id','fold_0', 'fold_1', 'fold_2', 'fold_3',\n       'fold_4'], axis=1)\n    y_valid = valid_df['damaged']\n    X_valid = valid_df.drop(['damaged','id','operator_id','fold_0', 'fold_1', 'fold_2', 'fold_3',\n       'fold_4'], axis=1)\n    X_test = test.drop(['id','operator_id'], axis=1)\n\n  \n\n    X_train = preprocessor.fit_transform(X_train)\n    X_valid = preprocessor.transform(X_valid)\n    X_test = preprocessor.transform(X_test)\n\n    lgb_train = lgb.Dataset(\n    X_train, \n    y_train\n    )\n    lgb_train.raw_data = None\n\n    lgb_valid = lgb.Dataset(\n     X_valid, y_valid\n    )\n    lgb_valid.raw_data = None\n\n    model = lgb.train(\n        params,\n        lgb_train,\n        num_boost_round=10000,\n        valid_sets=[lgb_train, lgb_valid],\n        early_stopping_rounds=100,\n        verbose_eval=100,\n    )\n    \n    valid_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n    valid_logloss = log_loss(y_valid,valid_pred)\n    logloss_list.append(valid_logloss)\n   \n    predictions = model.predict(X_test, num_iteration=model.best_iteration)\n    \n    preds_list.append(predictions)","a2383e3b":"predictions_df = pd.DataFrame(preds_list)\npredictions_df.head()","75766def":"predictions_df_mean = np.mean(predictions_df, axis = 0)\npredictions_df_mean","afcc464a":"sub = pd.DataFrame({'id':test[\"id\"],'damaged':predictions_df_mean})\nsub.head()","cb2f0159":"sub.to_csv(\"lgbm_01.csv\",index = False)","1fec5658":"<div class=\"alert alert-block alert-info\">  \n<h2><strong>Aircraft analysis<\/strong><\/h2>\n<\/div>","ac2c6a77":"<div class=\"alert alert-block alert-info\">  \n<h2><strong>Engines<\/strong><\/h2>\n<\/div>","b1f53ec6":"<div class=\"alert alert-block alert-info\">  \n<h2><strong>Incident Month<\/strong><\/h2>\n<\/div>","dc92b603":"<div class=\"alert alert-block alert-info\">  \n<h2><strong>Aircraft make analysis<\/strong><\/h2>\n<\/div>"}}