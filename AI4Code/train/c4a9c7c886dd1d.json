{"cell_type":{"31e440ad":"code","fc827c49":"code","5c662e8d":"code","663183ff":"code","9d4e696e":"code","3d86488a":"code","c08fdf51":"code","fec9d0ec":"code","2f2a50ed":"code","018651c0":"code","3816f79e":"code","949e946b":"code","dbff4336":"code","66ed8c6a":"code","5db84d2c":"code","e9880d18":"code","59303b1a":"code","8bfb7112":"code","56a26b3a":"code","16f02c11":"code","74339ef4":"markdown","c1f0e82c":"markdown","48d4cab7":"markdown","35e353b3":"markdown","db8ed21e":"markdown","4d20ddbb":"markdown","a78073e3":"markdown","28b708fa":"markdown","c1784a48":"markdown","4c6169ea":"markdown","32b1fa75":"markdown","ccc615ad":"markdown","462e530a":"markdown","c112a642":"markdown","cad321a7":"markdown"},"source":{"31e440ad":"!pip install -U imbalanced-learn","fc827c49":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom collections import Counter\nfrom scipy.special import softmax\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5c662e8d":"data = pd.read_csv(\"\/kaggle\/input\/website-phishing-data-set\/Website Phishing.csv\")\nfeats = data.columns.tolist()[:-1]\nnum_feats = len(feats)\ny = data[\"Result\"].tolist()\nX = data.drop(columns=[\"Result\"]).to_numpy()\nclasses = set(y)\nprint(\"Features: \", feats)\nprint(\"Classes: \", classes)","663183ff":"feats = data.columns.tolist()\nnum_exem = len(data[feats[0]])\nnum_missing_values = 0\nfor feat in feats:\n    num_missing_values += abs(len(data[feat]) - num_exem)\n    \nprint(\"Number of missing values: \",num_missing_values)  ","9d4e696e":"for label in classes:\n    print(\"Number of exemples of class {}: {}\".format(label, len(data[data[\"Result\"]==label])))","3d86488a":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=0)\nX_balanced, y_balanced = ros.fit_resample(X, y)\nprint(\"Nova quantidade de exemplos: \", Counter(y_balanced))\ny_balanced = np.array(y_balanced)","c08fdf51":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscl_X_balanced = scaler.fit_transform(X_balanced)\nscl_X = scaler.fit_transform(X_balanced)","fec9d0ec":"def get_percentil(X):\n    percent_array=np.zeros((num_feats, 100))\n\n    # Calculates the percentiles for each feature\n    for f in range(num_feats):\n        for i in range(1,101):\n            percent_array[f][i-1] = np.percentile(X[:,f], i)\n \n    return percent_array","2f2a50ed":"\ndef plot_info(feats_mean, feats_std, percent_array):\n    fig, axis = plt.subplots(1,2,figsize=(16,5))\n\n    plt.xlabel(\"Features\")\n\n    axis[0].hist(feats_mean) \n    axis[1].hist(feats_std)\n    \n    axis[0].legend([\"Mean\"])\n    axis[1].legend([\"Stantard Desviation\"])\n   \n    plt.xlabel(\"Percentiles\")\n    fold1 = percent_array[:3]\n    fold2 = percent_array[3:6]\n    fold3 = percent_array[6:9]\n    for fold in [fold1,fold2,fold2]:\n        fig1, axis1 = plt.subplots(1,3,figsize=(25,10))\n        for i, percent in enumerate(fold):\n            axis1[i].plot(range(100), percent)\n    fig1.subplots_adjust(wspace=0.5)","018651c0":"feats_mean, feats_std = feats_mean = np.mean(X, axis=0), np.std(X, axis=0)\npercent_array = get_percentil(X)\nplot_info(feats_mean, feats_std, percent_array)","3816f79e":"feats_mean, feats_std = feats_mean = np.mean(scl_X_balanced, axis=0), np.std(scl_X_balanced, axis=0)\npercent_array = get_percentil(scl_X_balanced)\nplot_info(feats_mean, feats_std, percent_array)","949e946b":"from sklearn.cluster import KMeans\nfig = plt.figure(1, figsize=(4, 3))\n\nkmeans = KMeans(n_clusters=3)\nkmeans.fit(scl_X_balanced[:100])\ny_pred = kmeans.predict(scl_X_balanced[100:200])\n\nplt.scatter(range(len(y_pred)), y_pred)","dbff4336":"classes = ['class '+str(c) for c in classes] # tornando as classes strings","66ed8c6a":"from sklearn import svm\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, shuffle=True)\nsvm_clf = svm.SVC()\n\nsvm_clf.fit(X_train,y_train)\npreds = svm_clf.predict(X_test)\n\nprint(\"Training Count: \", Counter(y_train))\nprint(\"Testing Count: \", Counter(y_test))\nprint(classification_report(y_test, preds, target_names=classes))","5db84d2c":"X_train, X_test, y_train, y_test = train_test_split(scl_X_balanced, y_balanced,test_size=0.2, shuffle=True)\nprint(\"Training Count: \", Counter(y_train))\nprint(\"Testing Count: \", Counter(y_test))","e9880d18":"#Classification using SVM -> Support Vector Machine \n# spliting training and validation\n\nsvm_clf = svm.SVC()\n\nsvm_clf.fit(X_train,y_train)\npreds = svm_clf.predict(X_test)\n\nsvm_result = classification_report(y_test, preds, target_names=classes, output_dict=True)\nprint(classification_report(y_test, preds, target_names=classes))","59303b1a":"from sklearn.ensemble import RandomForestClassifier\n\nclf_rf = RandomForestClassifier()\nclf_rf.fit(X_train, y_train)\npreds = clf_rf.predict(X_test)\nrf_result = classification_report(y_test, preds, target_names=classes, output_dict=True)\nprint(classification_report(y_test, preds, target_names=classes))","8bfb7112":"from sklearn.ensemble import AdaBoostClassifier\n\nclf_ada = AdaBoostClassifier(n_estimators=100)\ny_pred = clf_ada.fit(X_train, y_train).predict(X_test)\nada_result = classification_report(y_test, y_pred, target_names=classes, output_dict=True)\nprint(classification_report(y_test, y_pred, target_names=classes))","56a26b3a":"print(rf_result.keys())\nmetrics = ['accuracy']\n\nresults = []\n\n\nfor metric in metrics:\n    score = []\n    for i, r in enumerate([svm_result, rf_result, ada_result]):\n        print(r[metric])\n        score.append(r[metric]) \n    \n    results.append(score)\n    \nfor j,result in enumerate(results): \n    fig, axis = plt.subplots(1,1,figsize=(16,5))\n    fig.suptitle('Resultado de Classifica\u00e7\u00e3o Metric: {}'.format(metrics[j]), fontsize=16)\n    for i, res in enumerate(results):\n        print(res)\n        axis.bar([1,2,3],res,\n                    tick_label=['svm_result', 'rf_result', 'ada_result'], color=['green', 'blue', 'yellow'])","16f02c11":"# \u00c9 preciso rolar o output para visualizar todas as m\u00e9tricas\nmetrics = ['f1-score', 'recall', 'precision']\nmetric_avg = ['macro avg', 'weighted avg']\nfor metric in metrics:\n    for label in metric_avg:\n        score = []\n        for i, result in enumerate([svm_result, rf_result, ada_result]):\n            result_f1 = result[label][metric]\n            score.append(result_f1) \n        results.append(score)\n    for j,label in enumerate(metric_avg): \n        fig, axis = plt.subplots(1,1,figsize=(5,3))\n        fig.suptitle('Resultado de Classifica\u00e7\u00e3o {} Metric: {}'.format(metric_avg[j], metric), fontsize=16)\n        for i, result in enumerate(results):\n            axis.bar([1,2,3],result,\n                        tick_label=['svm_result', 'rf_result', 'ada_result'], color=['green', 'blue', 'yellow'])        ","74339ef4":"Como pode ser visto os dados podem ser agrupados e portanto separados por um classificador","c1f0e82c":"## An\u00e1lise Preliminar\n\nComo pode ser visto, os resultados que utilizam os dados originais, apesar de terem um resultado consider\u00e1vel, apresentam um score totalmente desbalanceado em rela\u00e7\u00e3o as classes. A classe 1, por exemplo, apresenta um recall de 0.16, enquanto a classe 0 tem um score de 0.92 representando uma diferen\u00e7a de 75%! Isso mostra que os dados do nosso classificador precisam ser balanceados e escalonados. Como vemos a seguir, quando isso acontece, obtemos resultados significativamente melhores. Isso ocorre tanto em rela\u00e7\u00e3o as m\u00e9tricas obtidas em cada classe, como tamb\u00e9m, em rela\u00e7\u00e3o a acur\u00e1cia e as m\u00e9dias de recall, f1-score e precision.","48d4cab7":"\n Os resultados para o data-set balanceado apresentam um equil\u00edbrio maior em rela\u00e7\u00e3o a m\u00e9dia de cada features o que consequentemente ajudar\u00e1 no processo de classifica\u00e7\u00e3o. Al\u00e9m disso, a diminuis\u00e3o do desvis\u00e3o padr\u00e3o criou um distribui\u00e7\u00e3o homogenea das features no data-set, isso fa\u00e7a com que as diferentes caracter\u00edsticas dos dados sejam igualmente relevantes evitando que um sopreponha a outra. Isso permite que classificadores lineares como SVM, por exemplo, obtenha resultados consideravelmente melhores.","35e353b3":"## Plot Information\n\n\nConsiderando que temos features que apresentam valores negativos, podemos utilizar a fun\u00e7\u00e3o softmax para garantir que todos os valores sejam positivos. Isso \u00e9 importante para c\u00e1lculo da m\u00e9dia que poderia apresentar um valor negativo, o que \u00e9 indesejado. Sendo assim, Isso garante a propor\u00e7\u00e3o dos dados e, portanto, o significado atribuido a eles.","db8ed21e":"# Classification\n\n","4d20ddbb":"# AdaBoostClassifier","a78073e3":"# An\u00e1lise\n\nO random forest assim como o Adabooster (pr\u00f3ximo classificador), apresentam um abordagem distinta. Ao inv\u00e9s de utilizarem apenas um algoritmo para gerar as previs\u00f5es, eles usam a combina\u00e7\u00e3o de v\u00e1rios classificadores para chegar a um predi\u00e7\u00e3o mais precisa. De fato, \u00e9 o que se apresenta nesse caso ontem a acur\u00e1cia supera a do algoritmo SVM. Assim como o primeiro classificador (SVM), h\u00e1 um \u00f3tima distribui\u00e7\u00e3o de scores entre as classes, evitando que uma classe seja mais bem classificado do que as demais. Contudo, existe uma clara tend\u00eancia de over-fitting, principalmente se analisarmos a class 1 onde os exemplos positivos tem um score de 1.0. Isso faz com que a \u00e1rvore de decis\u00e3o seja, tamb\u00e9m, um \u00f3timo candidato.","28b708fa":"Como pode ser visto, h\u00e1 uma distribui\u00e7\u00e3o heterog\u00eanea das features o que pode fazer com que uma se sopreponha as demais por apresentar um desvio padr\u00e3o acima da m\u00e9dia. Al\u00e9m disso, o percentile mostra que os dados dos \u00faltimos valores (pr\u00f3ximos a 100) tende a ter regi\u00f5es um pouco distintas de concentra\u00e7\u00e3o dos dados. Isso significa que o classificador ter\u00e1, de alguma forma, possiveis regi\u00f5es de classifica\u00e7\u00e3o mais comuns, sendo mais d\u00edficil classificar um dado fora dessa tend\u00eancia. ","c1784a48":"# Conclus\u00e3o\n\nEm resumo, os classificadores apresentam um bom desempenho no geral com destalhe para a SVM e o RandomForest. \nNo requisito acur\u00e1icia o random forest se apresenta melhor, por\u00e9m apresenta sinais de over-fitting em um das classes \nenquanto o SVM distribui um pouco melhor o scores entre as classes existentes. O adabooster n\u00e3o obteve um resultado satisfat\u00f3rio, e apresenta\num distribui\u00e7\u00e3o dos scores finais mais sparsas em rela\u00e7\u00e3o as classes. Portanto, entre os classificadores o que se \napresenta com melhor resultado \u00e9 a SVM, devido a n\u00e3o exist\u00eancia de overfitting em rela\u00e7\u00e3o as classes e ao mesmo tempo\napresentar uma acur\u00e1icia e scores m\u00e9dias melhores.","4c6169ea":"# SVM -> Support Vector Machine ","32b1fa75":"# Random Forest\n","ccc615ad":"## An\u00e1lise \n\nEsse se apresenta como um dos melhores classificadores testados. Apesar de n\u00e3o termos um quantidade grande de dimenss\u00f5es nos nossos dados (9 apenas), o classificador consegui gerar bem um hiperplano capaz de separar os dados. Al\u00e9m disso, o desempenho do classificador melhora consideravelmente quando regularizamos os dados, o que de fato \u00e9 o esperado para esse tipo de classificador.\nComo pode ser visto, ele apresenta uma acur\u00e1cia de 0.92, o que um bom resultado. Al\u00e9m disso, a classifica\u00e7\u00e3o de todas as classes obtem resultados consideravelmente bons igualmente. Considerando a precis\u00e3o e recall, podemos afirmar que o classificador tem bons n\u00edveis de verdadeiro positivo como de verdadeiro negativo.","462e530a":"Apesar de n\u00e3o existirem dados faltando, o dataset est\u00e1 claramente desbalanceado. Isso pode afetar consideramente os resultados, porqu\u00ea ainda que a avali\u00e7\u00f5es de acur\u00e1cia sejam boas, alguns classes podem apresentar um n\u00edvel de erro maior do que as demais principalmente aquelas que n\u00e3o possuem muitos exemplos , bem como, podemos enfretar casos de overfitting nas que tem muito. Considerando isso, uma boa tentativa de melhorar o desempenho \u00e9 balancear o data-set. Usando *RandomOverSampler*, podemos balancear todas as classes, assim, as classes com menos exemplos teram a quantidade aumentada.","c112a642":"# Exploratory Analysis","cad321a7":"## An\u00e1lise\n\nApesar de ser um classificador baseado em diversos estimadores (nesse caso 100) o Adabooster n\u00e3o apresentam um resultado t\u00e3o promissor quantos os demais. Ainda que mantenha uma boa distribui\u00e7\u00e3o dos acertos ao longo de todas as classes, o algoritimo, na m\u00e9dia, apresenta um resultado inferior. Um dos poss\u00edveis motivos \u00e9 o n\u00e3o melhor ajuste do meta-estimator aos dados, deixando muitos exemplos d\u00edfices para os demais estimators. "}}