{"cell_type":{"fe9579b8":"code","3dff25af":"code","41f802fa":"code","b576cbf6":"code","38aff47f":"code","18fd84af":"code","ad0b0bd7":"code","799bc682":"code","1f66e36f":"code","3a330ae1":"code","e708bab9":"code","25dbf3ac":"code","3bb8c36e":"code","6b3446f3":"code","5c3b1475":"code","aad54081":"code","f7eb463f":"code","2b2ecbb1":"code","8783d18d":"code","e80d6953":"code","855306ea":"code","7938f23f":"code","7694db33":"code","0e2f8f3a":"code","e38f4872":"code","5f179661":"code","dfb9f3e1":"code","5cf16b39":"code","365dfb2e":"code","22595014":"code","6968fc0c":"code","b0a65870":"code","085a93aa":"code","20ba047a":"code","d52c6168":"code","e9a68eb1":"code","8112c60a":"code","7a26931c":"markdown","614c7b0d":"markdown","32f4ecd2":"markdown","e7cd2569":"markdown","85cbe814":"markdown","7fd4d564":"markdown","c7643ec6":"markdown","ce8bb152":"markdown","8b713737":"markdown","d137d56b":"markdown","2c7be2a2":"markdown","6ce8f9f9":"markdown","a6011df4":"markdown","0538de3d":"markdown","cd5e9e06":"markdown","65e3100f":"markdown","00d4e5dd":"markdown","88b24537":"markdown"},"source":{"fe9579b8":"!apt install apt-utils psmisc -y\n!killall -9 ngrok\n!rm -rf *ngrok*\n!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n!mkdir -p ngrok-dir\n!mv ngrok ngrok-dir\/\n# \u03a3\u03c4\u03b7\u03bd \u03b5\u03c0\u03cc\u03bc\u03b5\u03bd\u03b7 \u03b3\u03c1\u03b1\u03bc\u03bc\u03ae \u03b2\u03ac\u03bb\u03c4\u03b5 \u03c4\u03bf \u03b4\u03b9\u03ba\u03cc \u03c3\u03b1\u03c2 authentication token \u03b1\u03c0\u03cc \u03c4\u03bf ngrok\n!ngrok-dir\/ngrok authtoken 1pQXAmawXFhcccxNaTqxBybnA8M_8ab6i8BfThM2qQcPHkUKv\n\nLOG_DIR = 'tb_log\/'\n!mkdir -p LOG_DIR\n\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('ngrok-dir\/ngrok http 6006 &')\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\nprint(\"Wait 10-15 seconds and then click the URL above to open TensorBoard\")","3dff25af":"!pip install --upgrade pip\n!pip install --upgrade stable_baselines3[extra]\n# we need a specific version of gym because of this issue: https:\/\/github.com\/DLR-RM\/stable-baselines3\/issues\/294\n!pip install gym==0.17.3","41f802fa":"atari_env_name='PitfallDeterministic-v4'\n#'Pitfall-v0'\n#'PitfallDeterministic-v4'\n#'PitfallDeterministic-v0'\n#'PitfallNoFrameskip-v4'\n#'PitfallNoFrameskip-v0'","b576cbf6":"\nfrom stable_baselines3.common.env_util import make_atari_env\nfrom stable_baselines3.common.vec_env import VecFrameStack","38aff47f":"\n# \u039c\u03b5 \u03c4\u03b9\u03c2 \u03c3\u03c5\u03bd\u03b1\u03c1\u03c4\u03ae\u03c3\u03b5\u03b9\u03c2 \u03c0\u03bf\u03c5 \u03b1\u03ba\u03bf\u03bb\u03bf\u03c5\u03b8\u03bf\u03cd\u03bd \u03ba\u03ac\u03bd\u03bf\u03c5\u03bc\u03b5 \u03c4\u03b7\u03bd \u03af\u03b4\u03b9\u03b1 \u03c0\u03c1\u03bf\u03b5\u03c0\u03b5\u03be\u03b5\u03c1\u03b3\u03b1\u03c3\u03af\u03b1 \u03bc\u03b5 \u03c4\u03b7\u03bd Deepmind\n\n# Here we are also multi-worker training (n_envs=4 => 4 environments), The model must support Multi Processing. To DQN \u03b4\u03b5\u03bd \u03b5\u03c0\u03b9\u03c4\u03c1\u03ad\u03c0\u03b5\u03b9 multi envs\nenv = make_atari_env(atari_env_name, n_envs=1, seed=0)\n# Frame-stacking with 4 frames\n# \u03bc\u03b5 \u03ad\u03bd\u03b1 frame \u03ad\u03c7\u03bf\u03c5\u03bc\u03b5 \u03c4\u03b7 \u03b8\u03ad\u03c3\u03b7, \u03bc\u03b5 \u03b4\u03cd\u03bf \u03c4\u03b7\u03bd \u03c4\u03b1\u03c7\u03cd\u03c4\u03b7\u03c4\u03b1, \u03bc\u03b5 \u03c4\u03c1\u03af\u03b1 \u03c4\u03b7\u03bd \u03b5\u03c0\u03b9\u03c4\u03ac\u03c7\u03c5\u03bd\u03c3\u03b7 \u03ba\u03b1\u03b9 \u03bc\u03b5 \u03c4\u03ad\u03c3\u03c3\u03b5\u03c1\u03b1 \u03c4\u03bf\u03bd \u03c1\u03c5\u03b8\u03bc\u03cc \u03bc\u03b5\u03c4\u03b1\u03b2\u03bf\u03bb\u03ae\u03c2 \u03c4\u03b7\u03c2 \u03b5\u03c0\u03b9\u03c4\u03ac\u03c7\u03c5\u03bd\u03c3\u03b7\u03c2 (jerk)\nenv = VecFrameStack(env, n_stack=4)\n# Test environment must be unique\ntest_env = make_atari_env(atari_env_name, n_envs=1, seed=0)\n# Frame-stacking with 4 frames\ntest_env = VecFrameStack(test_env, n_stack=4)","18fd84af":"import datetime # For filenames while logging\nfrom stable_baselines3 import DQN\nfrom stable_baselines3 import A2C\nfrom stable_baselines3 import PPO\n!pip install sb3-contrib\nfrom sb3_contrib import QRDQN\n\nfrom stable_baselines3.common.evaluation import evaluate_policy","ad0b0bd7":"class baseModelEval():\n    def __init__ (self,env,test_env,LOG_DIR):\n        self.env=env\n        self.test_env=test_env\n        self.RL_algo={\n            \"DQN\":DQN,\n            \"A2C\":A2C,\n            \"PPO\":PPO,\n            \"QRDQN\":QRDQN\n        }\n        self.RL_models={}\n        self.policy='CnnPolicy'\n        self.buffer_size=100000\n        self.LOG_DIR=LOG_DIR\n        self.max_steps=1000\n    \n    def createModels (self,policy='MlpPolicy',max_steps=1000):\n        self.policy=policy\n        for model_name, algo in self.RL_algo.items():\n            self.RL_models[model_name]= self.modelInit( model_name,algo)\n        \n    def modelInit( self, model_name,algo):\n        time_stamp=datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")\n        model_log= self.LOG_DIR + model_name +self.policy+ time_stamp\n        try:\n            return algo(self.policy, self.env, verbose=1, tensorboard_log=model_log, device=\"cuda\",buffer_size=self.buffer_size)\n        except:\n            return  algo(self.policy, self.env, verbose=1, tensorboard_log=model_log, device=\"cuda\")\n        \n    def learn(self,):\n        for model_name, model in self.RL_models.items():\n            model.learn(total_timesteps=self.max_steps)\n\n    def evaluate (self,  n_eval_episodes=5):\n        for model_name, model in self.RL_models.items():\n            mean_reward, std_reward = evaluate_policy(model, self.test_env, n_eval_episodes=n_eval_episodes)\n            print(f\"{model_name} -> Eval reward: {mean_reward} (+\/-{std_reward})\")","799bc682":"clsObj=baseModelEval(env,test_env,LOG_DIR)\nclsObj.createModels ()\nclsObj.learn()","1f66e36f":"#clsObj.evaluate ()\n","3a330ae1":"from stable_baselines3 import DQN\n\nmodel_name='DQN-CnnPolicy'\ntime_stamp=datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")\nmodel_log= LOG_DIR + model_name + time_stamp\n\nDQN_model = DQN('CnnPolicy', env, verbose=1, tensorboard_log=model_log,buffer_size=100000)","e708bab9":"max_steps=1000\nDQN_model.learn(total_timesteps=max_steps)","25dbf3ac":"from stable_baselines3 import A2C\n\nmodel_name='A2C-CnnPolicy'\ntime_stamp=datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")\nmodel_log= LOG_DIR + model_name + time_stamp\n\nA2C_model = A2C('CnnPolicy', env, verbose=1, tensorboard_log=model_log)","3bb8c36e":"max_steps=1000\nA2C_model.learn(total_timesteps=max_steps)","6b3446f3":"from stable_baselines3 import PPO\n\nmodel_name='PPO-CnnPolicy'\ntime_stamp=datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")\nmodel_log= LOG_DIR + model_name + time_stamp\n\nPPO_model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=model_log)","5c3b1475":"max_steps=1000\nPPO_model.learn(total_timesteps=max_steps)","aad54081":"!pip install sb3-contrib","f7eb463f":"!pip install sb3-contrib\nfrom sb3_contrib import QRDQN\n\nmodel_name='QRDQN-CnnPolicy'\ntime_stamp=datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")\nmodel_log= LOG_DIR + model_name + time_stamp\n\nQRDQN_model = QRDQN('CnnPolicy', env, verbose=1, tensorboard_log=model_log, buffer_size=100000)","2b2ecbb1":"max_steps=1000\nQRDQN_model.learn(total_timesteps=max_steps)","8783d18d":"atari_env_name='PitfallNoFrameskip-v4'\n# \u039c\u03b5 \u03c4\u03b9\u03c2 \u03c3\u03c5\u03bd\u03b1\u03c1\u03c4\u03ae\u03c3\u03b5\u03b9\u03c2 \u03c0\u03bf\u03c5 \u03b1\u03ba\u03bf\u03bb\u03bf\u03c5\u03b8\u03bf\u03cd\u03bd \u03ba\u03ac\u03bd\u03bf\u03c5\u03bc\u03b5 \u03c4\u03b7\u03bd \u03af\u03b4\u03b9\u03b1 \u03c0\u03c1\u03bf\u03b5\u03c0\u03b5\u03be\u03b5\u03c1\u03b3\u03b1\u03c3\u03af\u03b1 \u03bc\u03b5 \u03c4\u03b7\u03bd Deepmind\n\n# Here we are also multi-worker training (n_envs=4 => 4 environments), The model must support Multi Processing. To DQN \u03b4\u03b5\u03bd \u03b5\u03c0\u03b9\u03c4\u03c1\u03ad\u03c0\u03b5\u03b9 multi envs\nenv = make_atari_env(atari_env_name, n_envs=1, seed=0)\n# Frame-stacking with 4 frames\n# \u03bc\u03b5 \u03ad\u03bd\u03b1 frame \u03ad\u03c7\u03bf\u03c5\u03bc\u03b5 \u03c4\u03b7 \u03b8\u03ad\u03c3\u03b7, \u03bc\u03b5 \u03b4\u03cd\u03bf \u03c4\u03b7\u03bd \u03c4\u03b1\u03c7\u03cd\u03c4\u03b7\u03c4\u03b1, \u03bc\u03b5 \u03c4\u03c1\u03af\u03b1 \u03c4\u03b7\u03bd \u03b5\u03c0\u03b9\u03c4\u03ac\u03c7\u03c5\u03bd\u03c3\u03b7 \u03ba\u03b1\u03b9 \u03bc\u03b5 \u03c4\u03ad\u03c3\u03c3\u03b5\u03c1\u03b1 \u03c4\u03bf\u03bd \u03c1\u03c5\u03b8\u03bc\u03cc \u03bc\u03b5\u03c4\u03b1\u03b2\u03bf\u03bb\u03ae\u03c2 \u03c4\u03b7\u03c2 \u03b5\u03c0\u03b9\u03c4\u03ac\u03c7\u03c5\u03bd\u03c3\u03b7\u03c2 (jerk)\nenv = VecFrameStack(env, n_stack=4)\n# Test environment must be unique\ntest_env = make_atari_env(atari_env_name, n_envs=1, seed=0)\n# Frame-stacking with 4 frames\ntest_env = VecFrameStack(test_env, n_stack=4)","e80d6953":"from stable_baselines3.common.evaluation import evaluate_policy","855306ea":"from stable_baselines3.common.evaluation import evaluate_policy\nmean_reward, std_reward = evaluate_policy(QRDQN_model, test_env, n_eval_episodes=1)\nprint(f\"Eval reward: {mean_reward} (+\/-{std_reward})\")","7938f23f":"dqn_model.save(\"dqn_pitfall\")","7694db33":"!wget --no-check-certificate 'https:\/\/www.dropbox.com\/s\/opbqvg1bbqfrxet\/a2c_pong.zip?dl=1' -O a2c_pong.zip","0e2f8f3a":"from stable_baselines3 import A2C\na2c_model = A2C.load(\"a2c_pong\", verbose=1)","e38f4872":"# \u03a0\u03c1\u03bf\u03c3\u03bf\u03c7\u03ae, \u03c4\u03bf n_envs \u03c0\u03c1\u03ad\u03c0\u03b5\u03b9 \u03bd\u03b1 \u03b5\u03af\u03bd\u03b1\u03b9 \u03c0\u03ac\u03bd\u03c4\u03b1 \u03c4\u03bf \u03af\u03b4\u03b9\u03bf (\u03b1\u03c5\u03c4\u03cc \u03bc\u03b5 \u03c4\u03bf \u03bf\u03c0\u03bf\u03af\u03bf \u03ad\u03b3\u03b9\u03bd\u03b5 \u03b7 \u03b1\u03c1\u03c7\u03b9\u03ba\u03ae \u03b5\u03ba\u03c0\u03b1\u03af\u03b4\u03b5\u03c5\u03c3\u03b7 \u03c4\u03bf\u03c5 \u03bc\u03bf\u03bd\u03c4\u03ad\u03bb\u03bf\u03c5)\nnew_env = make_atari_env(atari_env_name, n_envs=4, seed=0)\n# Frame-stacking with 4 frames\nnew_env = VecFrameStack(new_env, n_stack=4)\n# \u03a4\u03bf \u03bc\u03bf\u03bd\u03c4\u03ad\u03bb\u03bf \u03b4\u03b5\u03bd \u03ad\u03c7\u03b5\u03b9 \u03bc\u03b1\u03b6\u03af \u03c4\u03bf\u03c5 \u03c4\u03bf \u03c0\u03b5\u03c1\u03b9\u03b2\u03ac\u03bb\u03bb\u03bf\u03bd, \u03c0\u03c1\u03ad\u03c0\u03b5\u03b9 \u03bd\u03b1 \u03c4\u03bf\u03c5 \u03c4\u03bf \u03b1\u03bd\u03b1\u03b8\u03ad\u03c3\u03bf\u03c5\u03bc\u03b5 \u03be\u03b1\u03bd\u03ac.\na2c_model.set_env(new_env)","5f179661":"max_steps=1000\na2c_model.learn(total_timesteps=max_steps)","dfb9f3e1":"mean_reward, std_reward = evaluate_policy(a2c_model, test_env, n_eval_episodes=10)\nprint(f\"Eval reward: {mean_reward} (+\/-{std_reward})\")","5cf16b39":"a2c_model.save(\"a2c_pong\")","365dfb2e":"!apt-get install ffmpeg freeglut3-dev xvfb  -y # For visualization","22595014":"# Set up fake display; otherwise rendering will fail\nimport os\nos.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\nos.environ['DISPLAY'] = ':1'","6968fc0c":"video_folder = '\/kaggle\/working\/videos'","b0a65870":"import base64\nfrom pathlib import Path\n\nfrom IPython import display as ipythondisplay\n\ndef show_videos(video_path='', prefix=''):\n  \"\"\"\n  Taken from https:\/\/github.com\/eleurent\/highway-env\n\n  :param video_path: (str) Path to the folder containing videos\n  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n  \"\"\"\n  html = []\n  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n      video_b64 = base64.b64encode(mp4.read_bytes())\n      html.append('''<video alt=\"{}\" autoplay \n                    loop controls style=\"height: 400px;\">\n                    <source src=\"data:video\/mp4;base64,{}\" type=\"video\/mp4\" \/>\n                <\/video>'''.format(mp4, video_b64.decode('ascii')))\n  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))","085a93aa":"import numpy as np\nfrom stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n\ndef record_video(eval_env, model, video_length=500, prefix='', video_folder=video_folder):\n  \"\"\"\n  :param env_id: (str)\n  :param model: (RL model)\n  :param video_length: (int)\n  :param prefix: (str)\n  :param video_folder: (str)\n  \"\"\"\n  # Start the video at step=0 and record video_length steps\n  env = VecVideoRecorder(eval_env, video_folder=video_folder,\n                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n                              name_prefix=prefix)\n\n  obs = env.reset()\n  for _ in range(video_length):\n    #action, _ = model.predict(obs)\n    #\u03b8\u03b1 \u03b5\u03c0\u03b9\u03bb\u03ad\u03be\u03bf\u03c5\u03bc\u03b5 \u03c4\u03b7\u03bd \u03b5\u03bd\u03ad\u03c1\u03b3\u03b5\u03b9\u03b1 \u03bc\u03b5 \u03c4\u03b9\u03c2 \u03bc\u03b5\u03b3\u03b1\u03bb\u03cd\u03c4\u03b5\u03c1\u03b5\u03c2 \u03c0\u03b9\u03b8\u03b1\u03bd\u03cc\u03c4\u03b7\u03c4\u03b5\u03c2\n    actions, _ = model.predict(obs, deterministic=True)\n    obs, _, _, _ = env.step(actions)\n\n  # Close the video recorder\n  env.close()","20ba047a":"record_video(test_env, dqn_model, video_length=5000, prefix='dqn_pong')","d52c6168":"record_video(test_env, a2c_model, video_length=5000, prefix='a2c_pong')","e9a68eb1":"show_videos(video_path = video_folder, prefix='dqn')","8112c60a":"show_videos(video_path = video_folder, prefix='a2c')","7a26931c":"\u039c\u03c0\u03bf\u03c1\u03b5\u03af\u03c4\u03b5 \u03bd\u03b1 \u03ba\u03b1\u03c4\u03b5\u03b2\u03ac\u03c3\u03b5\u03c4\u03b5 \u03c4\u03bf video \u03bc\u03b5 hover \u03c0\u03ac\u03bd\u03c9 \u03c4\u03bf\u03c5, \u03ba\u03ac\u03c4\u03c9 \u03b4\u03b5\u03be\u03b9\u03ac \u03c3\u03c4\u03bf ellipsis menu \u03ba\u03b1\u03b9 \"Download\".","614c7b0d":"# \u03a0\u03b1\u03af\u03b6\u03bf\u03bd\u03c4\u03b1\u03c2 Atari \u03bc\u03b5 \u03b2\u03b1\u03b8\u03b9\u03ac \u03b5\u03bd\u03b9\u03c3\u03c7\u03c5\u03c4\u03b9\u03ba\u03ae \u03bc\u03ac\u03b8\u03b7\u03c3\u03b7\n","32f4ecd2":"## \u0395\u03ba\u03c4\u03af\u03bc\u03b7\u03c3\u03b7 \u03b1\u03c0\u03cc\u03b4\u03bf\u03c3\u03b7\u03c2","e7cd2569":"## Tensorboard \u03ba\u03b1\u03b9 ngrok\n\n\u0391\u03bd\u03c4\u03b9\u03ba\u03b1\u03c4\u03b1\u03c3\u03c4\u03ae\u03c3\u03c4\u03b5 \u03c4\u03bf authentication token \u03c3\u03b1\u03c2 \u03c0\u03bf\u03c5 \u03c0\u03b1\u03af\u03c1\u03bd\u03b5\u03c4\u03b5 \u03b1\u03c0\u03cc \u03c4\u03bf [ngrok](https:\/\/ngrok.com\/) \u03c3\u03c4\u03b7 \u03b3\u03c1\u03b1\u03bc\u03bc\u03ae \u03c0\u03bf\u03c5 \u03c5\u03c0\u03bf\u03b4\u03b5\u03b9\u03ba\u03bd\u03cd\u03b5\u03c4\u03b1\u03b9. \u038c\u03c4\u03b1\u03bd \u03b5\u03ba\u03c4\u03b5\u03bb\u03b5\u03c3\u03c4\u03b5\u03af \u03c4\u03bf \u03ba\u03b5\u03bb\u03af \u03b8\u03b1 \u03c3\u03b1\u03c2 \u03b4\u03ce\u03c3\u03b5\u03b9 \u03c4\u03bf URL \u03cc\u03c0\u03bf\u03c5 \u03bc\u03c0\u03bf\u03c1\u03b5\u03af\u03c4\u03b5 \u03bd\u03b1 \u03b2\u03bb\u03ad\u03c0\u03b5\u03c4\u03b5 \u03c4\u03bf TensorBoard. \u03a3\u03b7\u03bc\u03b5\u03b9\u03ce\u03c3\u03c4\u03b5 \u03cc\u03c4\u03b9 \u03c3\u03b5 \u03c0\u03b5\u03c1\u03af\u03c0\u03c4\u03c9\u03c3\u03b7 \u03b5\u03c0\u03b1\u03bd\u03b5\u03ba\u03ba\u03af\u03bd\u03b7\u03c3\u03b7\u03c2 \u03c4\u03bf\u03c5 \u03c0\u03c5\u03c1\u03ae\u03bd\u03b1 \u03b8\u03b1 \u03c0\u03c1\u03ad\u03c0\u03b5\u03b9 \u03bd\u03b1 \u03be\u03b1\u03bd\u03b1\u03c4\u03c1\u03ad\u03be\u03b5\u03c4\u03b5 \u03c4\u03bf \u03ba\u03b5\u03bb\u03af. \u0397 \u03b4\u03b9\u03b5\u03cd\u03b8\u03c5\u03bd\u03c3\u03b7 \u03b8\u03b1 \u03b5\u03af\u03bd\u03b1\u03b9 \u03b4\u03b9\u03b1\u03c6\u03bf\u03c1\u03b5\u03c4\u03b9\u03ba\u03ae, \u03b1\u03bb\u03bb\u03ac \u03c4\u03b1 \u03c0\u03c1\u03bf\u03b7\u03b3\u03bf\u03cd\u03bc\u03b5\u03bd\u03b1 \u03c3\u03c4\u03b1\u03c4\u03b9\u03c3\u03c4\u03b9\u03ba\u03ac \u03c3\u03b1\u03c2 \u03b4\u03b5\u03bd \u03c7\u03ac\u03bd\u03bf\u03bd\u03c4\u03b1\u03b9 (\u03bc\u03ad\u03c7\u03c1\u03b9 \u03bd\u03b1 \u03b1\u03bd\u03b1\u03ba\u03c5\u03ba\u03bb\u03c9\u03b8\u03b5\u03af \u03bf \u03c0\u03c5\u03c1\u03ae\u03bd\u03b1\u03c2).","85cbe814":"## PPO","7fd4d564":"## \u039f\u03c1\u03b9\u03c3\u03bc\u03cc\u03c2 \u03c0\u03b1\u03b9\u03c7\u03bd\u03b9\u03b4\u03b9\u03bf\u03cd\n\n\u0392\u03ac\u03bb\u03c4\u03b5 \u03b5\u03b4\u03ce \u03c4\u03bf string \u03c0\u03bf\u03c5 \u03b1\u03bd\u03c4\u03b9\u03c3\u03c4\u03bf\u03b9\u03c7\u03b5\u03af \u03c3\u03c4\u03bf \u03c0\u03b1\u03b9\u03c7\u03bd\u03af\u03b4\u03b9 \u03c3\u03b1\u03c2. \u0393\u03b9\u03b1 \u03c4\u03b7\u03bd \u03bf\u03bd\u03bf\u03bc\u03b1\u03c4\u03bf\u03bb\u03bf\u03b3\u03af\u03b1 \u03c4\u03c9\u03bd \u03c0\u03b5\u03c1\u03b9\u03b2\u03b1\u03bb\u03bb\u03cc\u03bd\u03c4\u03c9\u03bd:\n- v0 vs v4: v0 has repeat_action_probability of 0.25 (meaning 25% of the time the previous action will be used instead of the new action), while v4 has 0 (always follow your issued action)\n- Deterministic: a fixed frameskip of 4, while for the env without Deterministic, frameskip is sampled from [2,4]\n- There is also NoFrameskip-v4 with no frame skip and no action repeat stochasticity.\n\n\u0391\u03bd\u03b1\u03bb\u03c5\u03c4\u03b9\u03ba\u03cc\u03c4\u03b5\u03c1\u03b1 \u03c3\u03c4\u03b7\u03bd \u03b5\u03ba\u03c6\u03ce\u03bd\u03b7\u03c3\u03b7 \u03c4\u03b7\u03c2 \u03ac\u03c3\u03ba\u03b7\u03c3\u03b7\u03c2.","c7643ec6":"## \u03a3\u03c5\u03bd\u03ad\u03c7\u03b9\u03c3\u03b7 \u03c4\u03b7\u03c2 \u03b5\u03ba\u03c0\u03b1\u03af\u03b4\u03b5\u03c5\u03c3\u03b7\u03c2","ce8bb152":"## \u0394\u03b7\u03bc\u03b9\u03bf\u03c5\u03c1\u03b3\u03af\u03b1 \u03c0\u03b5\u03c1\u03b9\u03b2\u03ac\u03bb\u03bb\u03bf\u03bd\u03c4\u03bf\u03c2","8b713737":"## QR-DQN","d137d56b":"## DQN","2c7be2a2":"## \u03a3\u03ce\u03c3\u03b9\u03bc\u03bf \u03b5\u03ba\u03c0\u03b1\u03b9\u03b4\u03b5\u03c5\u03bc\u03ad\u03bd\u03bf\u03c5 \u03bc\u03bf\u03bd\u03c4\u03ad\u03bb\u03bf\u03c5","6ce8f9f9":"## A2C","a6011df4":"## \u039a\u03b1\u03c4\u03b1\u03b3\u03c1\u03b1\u03c6\u03ae video \u03c4\u03bf\u03c5 actual gameplay \u03c4\u03bf\u03c5 \u03c0\u03c1\u03ac\u03ba\u03c4\u03bf\u03c1\u03b1\n\n\u03a9\u03c1\u03b1\u03af\u03b1 \u03c4\u03b1 \u03b4\u03b9\u03b1\u03b3\u03c1\u03ac\u03bc\u03bc\u03b1\u03c4\u03b1, \u03c9\u03c1\u03b1\u03af\u03b1\u03bf \u03c4\u03bf TensorBoard, \u03b1\u03bb\u03bb\u03ac \u03b8\u03ad\u03bb\u03bf\u03c5\u03bc\u03b5 \u03bf\u03c0\u03c9\u03c3\u03b4\u03ae\u03c0\u03bf\u03c4\u03b5 \u03bd\u03b1 \u03b4\u03bf\u03cd\u03bc\u03b5 \u03c4\u03bf\u03bd \u03c0\u03c1\u03ac\u03ba\u03c4\u03bf\u03c1\u03b1 \u03bd\u03b1 \u03c0\u03b1\u03af\u03b6\u03b5\u03b9 \u03c4\u03bf \u03c0\u03b1\u03b9\u03c7\u03bd\u03af\u03b4\u03b9!","0538de3d":"## \u039c\u03b1\u03ba\u03c1\u03bf\u03c7\u03c1\u03cc\u03bd\u03b9\u03b1 \u03b5\u03ba\u03c0\u03b1\u03af\u03b4\u03b5\u03c5\u03c3\u03b7\n\n\u03a4\u03bf \u03bc\u03bf\u03bd\u03c4\u03ad\u03bb\u03bf \u03b8\u03b1 \u03b1\u03c0\u03bf\u03b8\u03b7\u03ba\u03b5\u03c5\u03b8\u03b5\u03af \u03c9\u03c2 zip \u03ba\u03b1\u03b9 \u03bc\u03c0\u03bf\u03c1\u03b5\u03af\u03c4\u03b5 \u03bd\u03b1 \u03c4\u03bf \u03ba\u03b1\u03c4\u03b5\u03b2\u03ac\u03c3\u03b5\u03c4\u03b5 \u03c4\u03bf\u03c0\u03b9\u03ba\u03ac \u03b1\u03c0\u03cc \u03c4\u03bf \u03b4\u03b5\u03be\u03af sidebar \u03c4\u03bf\u03c5 Kaggle \u03c3\u03c4\u03bf \"Data\" \u03ba\u03b1\u03b9 \u03bc\u03b5\u03c4\u03ac \u03c3\u03c4\u03bf ellipsis menu \u03c0\u03ac\u03bd\u03c9 \u03c3\u03c4\u03bf filename.\n\n\u039b\u03cc\u03b3\u03c9 \u03c4\u03c9\u03bd \u03c0\u03b5\u03c1\u03b9\u03bf\u03c1\u03b9\u03c3\u03bc\u03ce\u03bd \u03c4\u03c9\u03bd cloud notebooks, \u03c0\u03c1\u03bf\u03ba\u03b5\u03b9\u03bc\u03ad\u03bd\u03bf\u03c5 \u03bd\u03b1 \u03bc\u03c0\u03bf\u03c1\u03ad\u03c3\u03b5\u03c4\u03b5 \u03bd\u03b1 \u03b5\u03ba\u03c0\u03b1\u03b9\u03b4\u03b5\u03cd\u03c3\u03b5\u03c4\u03b5 \u03bc\u03b1\u03ba\u03c1\u03bf\u03c7\u03c1\u03cc\u03bd\u03b9\u03b1 \u03c4\u03b1 \u03bc\u03bf\u03bd\u03c4\u03ad\u03bb\u03b1 \u03c3\u03b1\u03c2, \u03b8\u03b1 \u03c0\u03c1\u03ad\u03c0\u03b5\u03b9 \u03bd\u03b1 \u03c4\u03b1 \u03b5\u03ba\u03c0\u03b1\u03b9\u03b4\u03b5\u03cd\u03b5\u03c4\u03b5, \u03bd\u03b1 \u03c3\u03ce\u03b6\u03b5\u03c4\u03b5 \u03c4\u03b1 zip files \u03ba\u03b1\u03b9 \u03c3\u03c4\u03b7 \u03c3\u03c5\u03bd\u03ad\u03c7\u03b5\u03b9\u03b1 \u03bd\u03b1 \u03c4\u03b1 \u03c6\u03bf\u03c1\u03c4\u03ce\u03bd\u03b5\u03c4\u03b5 \u03ba\u03b1\u03b9 \u03bd\u03b1 \u03c3\u03c5\u03bd\u03b5\u03c7\u03af\u03b6\u03b5\u03c4\u03b5 \u03c4\u03b7\u03bd \u03b5\u03ba\u03c0\u03b1\u03af\u03b4\u03b5\u03c5\u03c3\u03b7 \u03cc\u03c0\u03c9\u03c2 \u03ba\u03ac\u03bd\u03bf\u03c5\u03bc\u03b5 \u03c3\u03c4\u03bf \u03b5\u03c0\u03cc\u03bc\u03b5\u03bd\u03bf section.","cd5e9e06":"## \u0395\u03ba\u03c0\u03b1\u03af\u03b4\u03b5\u03c5\u03c3\u03b7\n\n\u0398\u03b1 \u03b5\u03ba\u03c0\u03b1\u03b9\u03b4\u03b5\u03cd\u03c3\u03bf\u03c5\u03bc\u03b5 \u03ad\u03bd\u03b1 \u03b4\u03af\u03ba\u03c4\u03c5\u03bf deep q-learning (DQN) \u03cc\u03c0\u03c9\u03c2 \u03b1\u03c5\u03c4\u03cc \u03c4\u03b7\u03c2 Deepmind. \u03a3\u03b7\u03bc\u03b5\u03b9\u03ce\u03c3\u03c4\u03b5 \u03cc\u03c4\u03b9 \u03c4\u03b1 timesteps \u03b5\u03af\u03bd\u03b1\u03b9 \u03c0\u03bf\u03bb\u03cd \u03bb\u03af\u03b3\u03b1 \u03ba\u03b1\u03b9 \u03cc\u03c4\u03b9 \u03b4\u03b5\u03bd \u03ba\u03ac\u03bd\u03bf\u03c5\u03bc\u03b5 \u03b4\u03b9\u03b5\u03c1\u03b5\u03cd\u03bd\u03b7\u03c3\u03b7 \u03c3\u03c4\u03b9\u03c2 \u03c0\u03b1\u03c1\u03b1\u03bc\u03ad\u03c4\u03c1\u03bf\u03c5\u03c2 \u03c4\u03bf\u03c5 \u03bc\u03bf\u03bd\u03c4\u03ad\u03bb\u03bf\u03c5 \u03c0\u03bf\u03c5 \u03bc\u03c0\u03bf\u03c1\u03b5\u03af\u03c4\u03b5 \u03bd\u03b1 \u03b2\u03c1\u03b5\u03af\u03c4\u03b5 [\u03b5\u03b4\u03ce](https:\/\/stable-baselines3.readthedocs.io\/en\/master\/modules\/dqn.html#parameters).","65e3100f":"## \u03a6\u03cc\u03c1\u03c4\u03c9\u03c3\u03b7 \u03b5\u03ba\u03c0\u03b1\u03b9\u03b4\u03b5\u03c5\u03bc\u03ad\u03bd\u03bf\u03c5 \u03bc\u03bf\u03bd\u03c4\u03ad\u03bb\u03bf\u03c5\n\n\u03a4\u03bf Kaggle \u03b4\u03b5\u03bd \u03bc\u03b1\u03c2 \u03b1\u03c6\u03ae\u03bd\u03b5\u03b9 \u03bd\u03b1 \u03b1\u03bd\u03b5\u03b2\u03ac\u03c3\u03bf\u03c5\u03bc\u03b5 \u03ac\u03bb\u03bb\u03bf\u03c5 \u03b5\u03af\u03b4\u03bf\u03c5\u03c2 \u03b4\u03b5\u03b4\u03bf\u03bc\u03ad\u03bd\u03b1 \u03b5\u03ba\u03c4\u03cc\u03c2 \u03b1\u03c0\u03cc datasets. \u0398\u03b1 \u03c7\u03c1\u03b7\u03c3\u03b9\u03bc\u03bf\u03c0\u03bf\u03b9\u03ae\u03c3\u03bf\u03c5\u03bc\u03b5 \u03ad\u03bd\u03b1\u03bd \u03bf\u03c0\u03bf\u03b9\u03bf\u03bd\u03b4\u03ae\u03c0\u03bf\u03c4\u03b5 \u03bb\u03bf\u03b3\u03b1\u03c1\u03b9\u03b1\u03c3\u03bc\u03cc Dropbox \u03b3\u03b9\u03b1 \u03bd\u03b1 \u03b4\u03b7\u03bc\u03b9\u03bf\u03c5\u03c1\u03b3\u03ae\u03c3\u03bf\u03c5\u03bc\u03b5 \u03ad\u03bd\u03b1 \u03b1\u03c0\u03b5\u03c5\u03b8\u03b5\u03af\u03b1\u03c2 link \u03b3\u03b9\u03b1 \u03c4\u03bf \u03b1\u03c1\u03c7\u03b5\u03af\u03bf zip \u03c4\u03bf\u03c5 \u03b5\u03ba\u03c0\u03b1\u03b9\u03b4\u03b5\u03c5\u03bc\u03ad\u03bd\u03bf\u03c5 \u03bc\u03bf\u03bd\u03c4\u03ad\u03bb\u03bf\u03c5.\n1. \u03a4\u03bf\u03c0\u03bf\u03b8\u03b5\u03c4\u03ae\u03c3\u03c4\u03b5 \u03c4\u03bf zip \u03bc\u03ad\u03c3\u03b1 \u03c3\u03b5 \u03ad\u03bd\u03b1 \u03c6\u03ac\u03ba\u03b5\u03bb\u03bf Dropbox\n2. \u0391\u03bd \u03b5\u03af\u03c3\u03c4\u03b5 \u03c3\u03b5 Windows \u03ba\u03ac\u03bd\u03c4\u03b5 \u03b4\u03b5\u03be\u03af \u03ba\u03bb\u03b9\u03ba \u03c0\u03ac\u03bd\u03c9 \u03c3\u03c4\u03bf \u03b1\u03c1\u03c7\u03b5\u03af\u03bf \u03ba\u03b1\u03b9 \u03b5\u03c0\u03b9\u03bb\u03ad\u03be\u03c4\u03b5 \"Copy Dropbox Link'. \u0391\u03bd \u03b5\u03af\u03c3\u03c4\u03b5 \u03c3\u03b5 Linux \u03bc\u03c0\u03b5\u03af\u03c4\u03b5 \u03c3\u03c4\u03b7\u03bd web \u03b5\u03c6\u03b1\u03c1\u03bc\u03bf\u03b3\u03ae \u03ba\u03b1\u03b9 \u03ba\u03ac\u03bd\u03c4\u03b5 \u03c4\u03bf \u03af\u03b4\u03b9\u03bf (\u03bb\u03ad\u03b3\u03b5\u03c4\u03b1\u03b9 \"Copy link\"\n3. \u039a\u03ac\u03bd\u03c4\u03b5 \u03ba\u03ac\u03c0\u03bf\u03c5 paste \u03c4\u03bf URL https:\/\/www.dropbox.com\/s\/umw5k9wcuiy0l2u\/a2c_pong.zip?dl=0 \u03ba\u03b1\u03b9 \u03b1\u03bb\u03bb\u03ac\u03be\u03c4\u03b5 \u03c4\u03bf \u03c4\u03b5\u03bb\u03b5\u03c5\u03c4\u03b1\u03af\u03bf 0 \u03c3\u03b5 1 \u03cc\u03c0\u03c9\u03c2 \u03b5\u03b4\u03ce https:\/\/www.dropbox.com\/s\/umw5k9wcuiy0l2u\/a2c_pong.zip?dl=1\n4. \u0391\u03bd\u03c4\u03b9\u03b3\u03c1\u03ac\u03c8\u03c4\u03b5 \u03c4\u03bf \u03bd\u03ad\u03bf URL \u03c3\u03c4\u03bf clipboard.\n\n\u0395\u03b4\u03ce \u03c6\u03ad\u03c1\u03bd\u03bf\u03c5\u03bc\u03b5 \u03ad\u03bd\u03b1 \u03bc\u03bf\u03bd\u03c4\u03ad\u03bb\u03bf \u03912C \u03c0\u03bf\u03c5 \u03ad\u03c7\u03bf\u03c5\u03bc\u03b5 \u03b5\u03ba\u03c0\u03b1\u03b9\u03b4\u03b5\u03cd\u03c3\u03b5\u03b9 \u03bd\u03c9\u03c1\u03af\u03c4\u03b5\u03c1\u03b1. \u0395\u03c3\u03b5\u03af\u03c2 \u03b1\u03c0\u03bb\u03ac \u03b1\u03bb\u03bb\u03ac\u03b6\u03b5\u03c4\u03b5 \u03c4\u03bf URL \u03c4\u03b7\u03c2 \u03c0\u03b1\u03c1\u03b1\u03ba\u03ac\u03c4\u03c9 \u03b5\u03bd\u03c4\u03bf\u03bb\u03ae\u03c2 \u03b3\u03b9\u03b1 \u03c4\u03b1 \u03b4\u03b9\u03ba\u03ac \u03c3\u03b1\u03c2 \u03b1\u03c1\u03c7\u03b5\u03af\u03b1. \u03a0\u03c1\u03bf\u03c3\u03ad\u03be\u03c4\u03b5 \u03bc\u03b5\u03c4\u03ac \u03c4\u03b7\u03bd \u03c0\u03b1\u03c1\u03ac\u03bc\u03b5\u03c4\u03c1\u03bf -\u039f \u03bd\u03b1 \u03b2\u03ac\u03bb\u03b5\u03c4\u03b5 \u03c4\u03bf \u03c3\u03c9\u03c3\u03c4\u03cc \u03cc\u03bd\u03bf\u03bc\u03b1 \u03b1\u03c1\u03c7\u03b5\u03af\u03bf\u03c5, \u03bc\u03b5 \u03c0\u03bf\u03b9\u03bf  \u03cc\u03bd\u03bf\u03bc\u03b1 \u03b8\u03b1 \u03c3\u03c9\u03b8\u03b5\u03af \u03b4\u03b7\u03bb\u03b1\u03b4\u03ae.","00d4e5dd":"## \u03a4\u03b1 \u03ad\u03c7\u03bf\u03c5\u03bc\u03b5 \u03b3\u03b9\u03b1 \u03c0\u03b9\u03bf \u03b5\u03cd\u03ba\u03bf\u03bb\u03b1 \u03c3\u03b5 \u03ad\u03bd\u03b1 object \u03b1\u03bb\u03bb\u03ac \u03c0\u03b1\u03c1\u03b1\u03ba\u03ac\u03c4\u03c9 \u03c6\u03b1\u03af\u03bd\u03bf\u03bd\u03c4\u03b1\u03b9 \u03ba\u03b1\u03b9 \u03c0\u03b9\u03bf \u03b1\u03c0\u03bb\u03ac \u03cc\u03c0\u03c9\u03c2 \u03bc\u03b1\u03c2 \u03b4\u03cc\u03b8\u03b7\u03ba\u03b1\u03bd  ","88b24537":"## \u0395\u03b3\u03ba\u03b1\u03c4\u03ac\u03c3\u03c4\u03b1\u03c3\u03b7 \u03b2\u03b9\u03b2\u03bb\u03b9\u03bf\u03b8\u03ae\u03ba\u03b7\u03c2 \u03ba\u03b1\u03b9 gym"}}