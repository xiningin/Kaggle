{"cell_type":{"79e1965d":"code","0631a466":"code","70d9f065":"code","d75aac89":"code","dae53408":"code","7bd30c34":"code","5b9cf14d":"code","c8558de0":"code","f90559f1":"markdown","b9e8fbc9":"markdown","d9bd65e1":"markdown","fe6e7433":"markdown","300bab8d":"markdown"},"source":{"79e1965d":"!git clone https:\/\/github.com\/facebookresearch\/detectron2.git\n%cd detectron2\n!python -m pip install -e .\/","0631a466":"from tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom PIL import ImageDraw\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport json\nimport copy\nimport os\nimport cv2\nimport ast\n\n# functions\ndef get_templates():\n    coco_json_template = {\n        \"info\":{},\n        \"images\":[],\n        \"licenses\":[],\n        \"annotations\":[],\n        \"categories\":[]\n    }\n    image_template = {\n        'license': 0, \n        'file_name': '',\n        'coco_url': None,\n        'height': None,\n        'width': None,\n        'date_captured': None,\n        'flickr_url': None,\n        'id': None\n    }\n    annotation_template = {\n        'segmentation':[[]],\n        'area':None,\n        'iscrowd':0,\n        'image_id':None,\n        'bbox':[],\n        'category_id':None,\n        'id':None\n    }\n    category_template = {\n        'supercategory': 'Coral_creatures', \n        'id': None, \n        'name': ''\n    }\n    return coco_json_template,image_template, annotation_template, category_template","70d9f065":"def to_json(df, base_dir, draw=False):\n    coco_json, image_template, annotation_template, category_template = get_templates()\n\n    category_ = copy.deepcopy(category_template)\n    category_[\"id\"] = 1\n    category_[\"name\"] =\"starfish\"\n    coco_json['categories'].append(category_)\n\n    annot_id = 1\n    image_id = 1\n    with tqdm(total=len(df)) as pbar:\n        for i, row in df.iterrows():\n            # get instances of annotations\n            image_prop = copy.deepcopy(image_template)\n\n            # get image properties\n            image_name = os.path.join(f\"video_{row['video_id']}\", f\"{row['video_frame']}.jpg\")\n\n            img_ = Image.open(os.path.join(base_dir, image_name))\n            img_width, img_height = img_.size\n\n            image_prop['file_name'] = image_name\n            image_prop['height'] = img_height\n            image_prop['width'] = img_width\n            image_prop['id'] = image_id\n            image_id+=1\n\n            # append the image\n            coco_json['images'].append(image_prop)\n\n            annotations = eval(row[\"annotations\"])\n            for annotation in annotations:\n                image_annot = copy.deepcopy(annotation_template)\n                bbox = [\n                    annotation[\"x\"],\n                    annotation[\"y\"],\n                    annotation[\"width\"],\n                    annotation[\"height\"]\n                ]\n\n                if draw:\n                    draw_handle = ImageDraw.Draw(img_)\n                    draw_handle.rectangle([(int(bbox[0]),int(bbox[1])),(int(bbox[2])+int(bbox[0]),int(bbox[3])+int(bbox[1]))],\n                                         width = 5)\n                    if not os.path.exists(\"output\"):\n                        os.mkdir(\"output\")\n\n                # populate the template\n                image_annot['segmentation'] = []\n                image_annot[\"area\"] = bbox[2]*bbox[3]\n                image_annot['image_id'] = image_id\n                image_annot['bbox'] = bbox\n                image_annot['category_id'] = 1\n                image_annot['id'] = annot_id\n                annot_id+=1\n\n                # append the annotations\n                coco_json['annotations'].append(image_annot)\n\n            pbar.update(1)\n            \n    return coco_json","d75aac89":"from sklearn.model_selection import train_test_split\ndf = pd.read_csv(\"\/kaggle\/input\/tensorflow-great-barrier-reef\/train.csv\")\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=43)\n\nprint(f\"total images in test set :- {len(train_df)}\")\nprint(f\"total images in test set :- {len(test_df)}\")","dae53408":"IMG_BASE_DIR = \"\/kaggle\/input\/tensorflow-great-barrier-reef\/train_images\"\n\ntrain_json = to_json(train_df, IMG_BASE_DIR)\nwith open(\"train.json\", \"w\") as file:\n    json.dump(train_json, file)\n    \ntest_json = to_json(test_df, IMG_BASE_DIR)\nwith open(\"test.json\", \"w\") as file:\n    json.dump(test_json, file)","7bd30c34":"from detectron2.data.datasets import register_coco_instances\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.data import detection_utils as utils\nfrom detectron2.utils.visualizer import Visualizer\nimport matplotlib.pyplot as plt\nimport random\n\ntry:\n    register_coco_instances(\"Coral_starfish_train\", {}, \"train.json\", IMG_BASE_DIR)\n    register_coco_instances(\"Coral_starfish_test\", {}, \"test.json\", IMG_BASE_DIR)\nexcept AssertionError:\n    print(\"dataset already created\")","5b9cf14d":"n = 5\ndamage_metadata = MetadataCatalog.get(\"Coral_starfish_train\")\ndataset_dicts = DatasetCatalog.get(\"Coral_starfish_train\")\nimages_with_annot = [d for d in dataset_dicts if len(d[\"annotations\"])!=0]\nprint(f\"images with atleast one annotation in train Set :- {len(images_with_annot)}\")\nfor d in random.sample(images_with_annot, n):\n    print(d)\n    # Draw ground Truths\n    img = cv2.imread(d[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=damage_metadata, scale=1)\n    vis = visualizer.draw_dataset_dict(d)\n    gt_image = vis.get_image()\n\n    plt.figure(figsize=(16,9))\n    plt.imshow(gt_image)\n    plt.show()","c8558de0":"n = 5\ndamage_metadata = MetadataCatalog.get(\"Coral_starfish_test\")\ndataset_dicts = DatasetCatalog.get(\"Coral_starfish_test\")\nimages_with_annot = [d for d in dataset_dicts if len(d[\"annotations\"])!=0]\nprint(f\"images with atleast one annotation in test Set :- {len(images_with_annot)}\")\nfor d in random.sample(images_with_annot, n):\n    print(d)\n    # Draw ground Truths\n    img = cv2.imread(d[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=damage_metadata, scale=1)\n    vis = visualizer.draw_dataset_dict(d)\n    gt_image = vis.get_image()\n\n    plt.figure(figsize=(16,9))\n    plt.imshow(gt_image)\n    plt.show()","f90559f1":"# register datasets","b9e8fbc9":"# visualize test Set","d9bd65e1":"# visualize train Set","fe6e7433":"# Initialize Templates","300bab8d":"# Split the data and convert to json"}}