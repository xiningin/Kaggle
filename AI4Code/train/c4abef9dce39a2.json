{"cell_type":{"bf0e6d34":"code","89c62b78":"code","520655d8":"code","f74b3906":"code","3307f698":"code","11a9f556":"code","301b8ed3":"code","29e69a8d":"code","177145cb":"code","60240c5c":"code","b55a4e58":"code","b953b05b":"code","08e334e4":"code","e0101079":"code","b250fd13":"code","b759133a":"code","1276dabe":"code","515a71bd":"code","ec683c51":"code","219dd348":"code","42645a70":"code","7e5ed31f":"code","8358a475":"code","a92e252e":"code","53fd8d49":"code","69148214":"code","254fab9d":"code","9142fd0a":"code","99c37765":"code","ab511162":"code","aefac7e8":"code","9b149c04":"code","5291db15":"code","0a7d7d5e":"code","e257b19a":"code","a0f5cc55":"code","0f68d372":"markdown","8af2b1a4":"markdown","ca22eccc":"markdown","cd46378d":"markdown","96af0ae0":"markdown","eb374c39":"markdown","fef3ed86":"markdown","2f1da89b":"markdown","69ddacfa":"markdown","b51bc4b6":"markdown","ccb7c89b":"markdown","d7431392":"markdown","dc3beb2f":"markdown","f538b716":"markdown","e39822a2":"markdown","79c1c9ca":"markdown","f0414db1":"markdown","acd41dae":"markdown","eaba9cc2":"markdown","8370cc18":"markdown","3f339283":"markdown"},"source":{"bf0e6d34":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","89c62b78":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn import metrics\nimport warnings\nwarnings.simplefilter(\"ignore\")\nnp.random.seed(42)\nprint(\"Tensorflow Version is :\",tf.__version__)","520655d8":"plt.figure(figsize=(15,12))\nplt.imshow(plt.imread(\"..\/input\/allentelescope\/allen.jpg\"))","f74b3906":"train_images = pd.read_csv(\"..\/input\/seti-radio-signals-csv-dataset\/dataset\/train\/images.csv\",header=None)\ntrain_labels = pd.read_csv(\"..\/input\/seti-radio-signals-csv-dataset\/dataset\/train\/labels.csv\",header=None)\nval_images = pd.read_csv(\"..\/input\/seti-radio-signals-csv-dataset\/dataset\/validation\/images.csv\",header=None)\nval_labels = pd.read_csv(\"..\/input\/seti-radio-signals-csv-dataset\/dataset\/validation\/labels.csv\",header=None)","3307f698":"train_images.head()","11a9f556":"train_labels.head()","301b8ed3":"plt.figure(figsize=(12,10))\nplt.imshow(plt.imread(\"..\/input\/seti-data\/primary_small\/train\/squiggle\/1015_squiggle.png\"))\nplt.title(\"Squiggle Radio Signals\")","29e69a8d":"plt.figure(figsize=(12,10))\nplt.imshow(plt.imread(\"..\/input\/seti-data\/primary_small\/train\/narrowband\/1012_narrowband.png\"))\nplt.title(\"Narrowband Radio Signals\")","177145cb":"plt.figure(figsize=(12,10))\nplt.imshow(plt.imread(\"..\/input\/seti-data\/primary_small\/train\/noise\/1001_noise.png\"))\nplt.title(\"Noises\")","60240c5c":"plt.figure(figsize=(12,10))\nplt.imshow(plt.imread(\"..\/input\/seti-data\/primary_small\/train\/narrowbanddrd\/1006_narrowbanddrd.png\"))\nplt.title(\"Narrowbanddrd Radio Signals\")","b55a4e58":"print(\"Training set shape:\", train_images.shape, train_labels.shape)\nprint(\"Validation set shape:\", val_images.shape, val_labels.shape)","b953b05b":"X_train = train_images.values.reshape(3200,64,128,1) \nX_test = val_images.values.reshape(800,64,128,1)\ny_train = train_labels.values\ny_test = val_labels.values\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","08e334e4":"print(X_train.ndim)\nprint(X_test.ndim)\nprint(y_train.ndim)\nprint(y_test.ndim)","e0101079":"X_train[0]","b250fd13":"y_train[0]","b759133a":"plt.figure(figsize=(20,15))\nfor i in range(1,5):\n    plt.subplot(1,4,i)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_train[np.random.randint(0, X_train.shape[0])])","1276dabe":"plt.figure(figsize=(20,15))\nfor i in range(1,5):\n    plt.subplot(1,4,i)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_train[np.random.randint(0, X_train.shape[0])],cmap=\"gray\")","515a71bd":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n        horizontal_flip=True)\ntest_datagen = ImageDataGenerator(\n        horizontal_flip=True)\ntrain_datagen.fit(X_train)\ntest_datagen.fit(X_test)","ec683c51":"from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.utils import plot_model","219dd348":"cnn = Sequential()\n#Adding 1. Convolution Layer\ncnn.add(Conv2D(filters=32,kernel_size=5,activation=\"relu\",padding=\"same\", input_shape=(64,128,1))) \ncnn.add(BatchNormalization())\ncnn.add(MaxPooling2D(pool_size=2, strides=2))\ncnn.add(Dropout(0.2))\n\n#Adding 2. Convolution Layer\ncnn.add(Conv2D(filters=32,kernel_size=5,activation=\"relu\",padding=\"same\"))\ncnn.add(BatchNormalization())\ncnn.add(MaxPooling2D(pool_size=2, strides=2))\ncnn.add(Dropout(0.2))\n\n# Adding Flattening\ncnn.add(Flatten())\n\n# Adding fully connected layer\ncnn.add(Dense(units=1024, activation=\"relu\"))\ncnn.add(BatchNormalization())\ncnn.add(Dropout(0.4))   \n\ncnn.add(Dense(4, activation='softmax'))","42645a70":"initial_learning_rate = 0.005\nlearning_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n                    initial_learning_rate,\n                    decay_steps=5,\n                    decay_rate=0.96,\n                    staircase=True)\n# This will calculate 0.005 * (0.96 **5) in every 5 steps and recalculate learning steps and the result of this operation as the leanring step\noptimizer = Adam(learning_rate=learning_schedule)","7e5ed31f":"cnn.compile(optimizer=optimizer, loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\ncnn.summary()","8358a475":"checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',\n                             save_weights_only=True, mode='min', verbose=0)\ncallbacks = [checkpoint,EarlyStopping(monitor='val_loss',patience=4)]\nbatch_size = 32\nhistory = cnn.fit(\n    train_datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True),\n    steps_per_epoch=len(X_train)\/\/batch_size,\n    validation_data = test_datagen.flow(X_test, y_test, batch_size=batch_size, shuffle=True),\n    validation_steps = len(X_test)\/\/batch_size,\n    epochs=50,\n    callbacks=callbacks\n)","a92e252e":"pd.DataFrame(cnn.history.history)","53fd8d49":"plt.style.use(\"ggplot\")\npd.DataFrame(cnn.history.history).plot(figsize=(12,10))","69148214":"print(cnn.evaluate(X_train,y_train))","254fab9d":"print(cnn.evaluate(X_test,y_test))","9142fd0a":"predictions = cnn.predict(X_test)\ny_true = np.argmax(y_test, 1)\ny_pred = np.argmax(predictions, 1)\nprint(metrics.classification_report(y_true, y_pred))\nprint(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true, y_pred))","99c37765":"labels = [\"squiggle\", \"narrowband\", \"noise\", \"narrowbanddrd\"]\nplt.figure(figsize=(15,12))\nax= plt.subplot()\nsns.heatmap(metrics.confusion_matrix(y_true, y_pred, normalize='true'), annot=True, ax=ax,cmap=\"rainbow\"); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_title('Confusion Matrix'); \nax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);","ab511162":"np.argmax(predictions,1)","aefac7e8":"np.argmax(y_test,1)","9b149c04":"predictions_df = pd.DataFrame(np.argmax(predictions,1),columns=[\"Predictions\"])\ny_test_df = pd.DataFrame(np.argmax(y_test,1),columns=[\"Real Values\"])\ncomparison_df = pd.concat([y_test_df, predictions_df],axis=1)\ncomparison_df ","5291db15":"plt.figure(figsize=(20,15))\nfor i in range(1,5):\n    plt.subplot(1,4,i)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(X_test[np.random.randint(0, X_test.shape[0])])","0a7d7d5e":"labels = [\"squiggle\",  \"narrowband\",\"noise\" ,\"narrowbanddrd\",]\nlabels[comparison_df[\"Predictions\"][0]]","e257b19a":"labels = [\"squiggle\", \"narrowband\", \"noise\", \"narrowbanddrd\"]\nfig, axs = plt.subplots(2, 5, figsize=(20, 10))\naxs[0][0].title.set_text(labels[comparison_df[\"Predictions\"][0]])\naxs[0][0].imshow(X_test[0])\naxs[0][1].title.set_text(labels[comparison_df[\"Predictions\"][1]])\naxs[0][1].imshow(X_test[1]) \naxs[0][2].title.set_text(labels[comparison_df[\"Predictions\"][2]])\naxs[0][2].imshow(X_test[2])\naxs[0][3].title.set_text(labels[comparison_df[\"Predictions\"][3]])\naxs[0][3].imshow(X_test[3])  \naxs[0][4].title.set_text(labels[comparison_df[\"Predictions\"][4]])\naxs[0][4].imshow(X_test[4])    \naxs[1][0].title.set_text(labels[comparison_df[\"Predictions\"][5]])\naxs[1][0].imshow(X_test[5])   \naxs[1][1].title.set_text(labels[comparison_df[\"Predictions\"][6]])\naxs[1][1].imshow(X_test[6])  \naxs[1][2].title.set_text(labels[comparison_df[\"Predictions\"][7]])\naxs[1][2].imshow(X_test[7]) \naxs[1][3].title.set_text(labels[comparison_df[\"Predictions\"][8]])\naxs[1][3].imshow(X_test[8])  \naxs[1][4].title.set_text(labels[comparison_df[\"Predictions\"][9]])\naxs[1][4].imshow(X_test[9])\n\nfig.tight_layout()","a0f5cc55":"random = np.random.randint(0,800)\nlabels = [\"squiggle\", \"narrowband\",  \"narrowbanddrd\",\"noise\"]\nfig, axs = plt.subplots(2, 5, figsize=(20, 10))\naxs[0][0].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[0][0].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[0][0].imshow(X_test[random])\nrandom = np.random.randint(0,800)\naxs[0][1].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[0][1].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[0][1].imshow(X_test[random]) \nrandom = np.random.randint(0,800)\naxs[0][2].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[0][2].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[0][2].imshow(X_test[random])\nrandom = np.random.randint(0,800)\naxs[0][3].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[0][3].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[0][3].imshow(X_test[random])\nrandom = np.random.randint(0,800)\naxs[0][4].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[0][4].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[0][4].imshow(X_test[random])  \nrandom = np.random.randint(0,800)\naxs[1][0].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[1][0].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[1][0].imshow(X_test[random]) \nrandom = np.random.randint(0,800)\naxs[1][1].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[1][1].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[1][1].imshow(X_test[random])\nrandom = np.random.randint(0,800)\naxs[1][2].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[1][2].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[1][2].imshow(X_test[random]) \nrandom = np.random.randint(0,800)\naxs[1][3].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[1][3].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[1][3].imshow(X_test[random])\nrandom = np.random.randint(0,800)\naxs[1][4].title.set_text(labels[comparison_df[\"Predictions\"][random]])\naxs[1][4].set_xlabel(labels[comparison_df[\"Real Values\"][random]])\naxs[1][4].imshow(X_test[random])\n\nfig.tight_layout()","0f68d372":"## 3.1. Building the Model","8af2b1a4":"<font color=\"red\">\nModelCheckpoint enables us to save the highest accurate weights to use it for future predictions.","ca22eccc":"<font color=\"red\">\nConvolutional layer takes an input volume Applies a filter at every position of the input Outputs another volume (usually of different size).\nSimilar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial size of the Convolved Feature. It is used to decrease the computational power required to process the data through dimensionality reduction. Furthermore, it is useful for extracting dominant features","cd46378d":"<font color=\"red\">\nWe have 3200 samples in the training set and 800 in the test set. We need to transform the shape of the image in the both train and test set into smaller image before sending convolutional neural networks as follows.The first one represents the number of samples, the second is width of the images. the third is the height and the last one is number of rgb channels:","96af0ae0":"<font color=\"red\">\nWe see gray color representations of the images:","eb374c39":"## 2. Data Preprocessing and Visualization","fef3ed86":"ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    zca_epsilon=1e-06,\n    rotation_range=0,\n    width_shift_range=0.0,\n    height_shift_range=0.0,\n    brightness_range=None,\n    shear_range=0.0,\n    zoom_range=0.0,\n    channel_shift_range=0.0,\n    fill_mode='nearest',\n    cval=0.0,\n    horizontal_flip=False,\n    vertical_flip=False,\n    rescale=None,\n    preprocessing_function=None,\n    data_format=None,\n    validation_split=0.0,\n    dtype=None,\n)","2f1da89b":"<font color=\"red\">\nThe third column represents Noise as label which we can see the signal visualization in the image below:","69ddacfa":"## 3.3.Training the Model","b51bc4b6":"<font color=\"red\">\nNow lets visualize how the images look like:","ccb7c89b":"<font color=\"red\">\nThe second column represents narrowband signal as label which we can see the signal visualization in the image below:","d7431392":"<font color=\"red\">\nThere are 4 labels for the radio signasl according to their features. The first label is represented in the columns zero and the name of this radio signal is Squiggle. We can see the representation of this type of radio signal in the image below:","dc3beb2f":"## 1. Exploratory Data Analysis:","f538b716":"## 3.2. Learning Rate Scheduling and Compile the Model","e39822a2":"<font color=\"red\">\nX_train and X_test which represents the features of the radio signals are 4D numpy arrays as seen in the example below:","79c1c9ca":"<font color=\"red\">\nOur model performs good, but have a confusion between narrowband and narrowbanddrd radio signasl because they are so similar, this can be retrained by hyperparameter tuning for better accuracy.","f0414db1":"<font color=\"red\">\nThis will calculate 0.005 * (0.96 **5) in every 5 steps and recalculate learning steps and the result of this operation as the learning step.\n","acd41dae":"## 4. MAKING PREDICTIONS AND EVALUATING THE MODEL PERFORMANCE","eaba9cc2":"<font color=\"red\">\nThe fourth column represents narrowbanddrd signal as label which we can see the signal visualization in the image below:","8370cc18":"<font color=\"red\">\ny_train and y_test which represents the labels of the radio signals are 2D numpy arrays as seen in the example below:","3f339283":"## 3. Create Training and Validation Data Generators and CNN Model"}}