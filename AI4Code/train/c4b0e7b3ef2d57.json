{"cell_type":{"61a95f38":"code","a0e22d49":"code","272928a9":"code","e31b76fc":"code","5f7ad4df":"code","6e529e32":"code","5886d720":"code","18f06d07":"code","a7561e87":"code","0de1dfa7":"code","29aaed3b":"code","14dfa979":"code","42bed180":"code","7930c023":"code","82311e6f":"code","1c70120d":"code","d97baea3":"code","c9ae779f":"code","da606ec7":"code","484de23e":"code","17bb7fc2":"code","c12b9403":"code","5549de09":"code","a47409bb":"code","989ca0a0":"code","ddf6524d":"code","7b2feb97":"code","c4436713":"code","be97764c":"code","5c8f24d9":"code","d85a73b5":"code","d3b0623d":"code","e46e39b8":"code","0648b7b3":"code","85429fa1":"code","c68a76b7":"code","930d8658":"code","b4c67ae8":"code","c8573b32":"code","286c65fc":"code","fff0842b":"code","e75cba67":"code","a3167d8a":"code","a139fb5c":"code","e24f2140":"code","e3faa311":"code","a11b0b4b":"code","73c6a200":"code","f60747f3":"code","d57f7cc6":"code","ac271301":"code","14690307":"code","965eb870":"code","3a508d4d":"code","b6047fb5":"code","a4375d3c":"code","86a4043d":"code","85884c6d":"code","0d082df4":"code","8aea4367":"code","5f462097":"code","8a501aa1":"code","4fff51d4":"code","204b007f":"code","bdf7ec6d":"code","e4698ab0":"code","43358e28":"code","ed54eb64":"markdown","31d15c5a":"markdown","baa595e3":"markdown","1e2ef4e8":"markdown","bed3f131":"markdown","1a957043":"markdown","c2889920":"markdown","829b0927":"markdown","31af5438":"markdown","f0184dc4":"markdown","b151be52":"markdown","b849159a":"markdown","a1c77301":"markdown","f2420ef7":"markdown"},"source":{"61a95f38":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a0e22d49":"train = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-5\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-5\/test.csv')","272928a9":"train.head(3)","e31b76fc":"import seaborn as sns","5f7ad4df":"train.info()","6e529e32":"df1 = train.Population.groupby(train['Country_Region']).max().sort_values(ascending= False)\ndf10 = pd.DataFrame()\ndf20 = pd.DataFrame()\ndf10['population'] = df1.iloc[0:10]\ndf10['country']= df10.index\ndf20['population'] = df1.iloc[11:20]\ndf20['country'] = df20.index","5886d720":"plt.figure(figsize =(10,10))\nplt.subplot(2,1,1)\nsns.barplot(x='country', y='population', data=df10, orient ='v')\nplt.xlabel('Country')\nplt.title('Popoulation Top 10')\nplt.subplot(2,1,2)\nsns.barplot(x='country', y='population', data=df20, orient ='v')\nplt.xlabel('Country')\nplt.title('Population Next 10')","18f06d07":"train1= train[train['Target']=='ConfirmedCases']\ndata1 = pd.DataFrame()\ndata1['values'] =train1.TargetValue.groupby(train1['Country_Region']).sum().sort_values(ascending= False)\ndata1['country'] = data1.index\ndata1.index = np.arange(0,len(data1))\ndata10 = data1.iloc[0:10,:]\ndata20 = data1.iloc[11:20,:]","a7561e87":"plt.figure(figsize =(10,10))\nplt.subplot(2,1,1)\nsns.barplot(x='country', y='values', data=data10, orient ='v')\nplt.xlabel('Country')\nplt.ylabel('Cases')\nplt.title('Covid Cases Top 10')\nplt.subplot(2,1,2)\nsns.barplot(x='country', y='values', data=data20, orient ='v')\nplt.xlabel('Country')\nplt.ylabel('Cases')\nplt.title('Covid Cases Next 10')","0de1dfa7":"train1= train[train['Target']!='ConfirmedCases']\ndata1 = pd.DataFrame()\ndata1['values'] =train1.TargetValue.groupby(train1['Country_Region']).sum().sort_values(ascending= False)\ndata1['country'] = data1.index\ndata1.index = np.arange(0,len(data1))\ndata10 = data1.iloc[0:10,:]\ndata20 = data1.iloc[11:20,:]","29aaed3b":"plt.figure(figsize =(10,10))\nplt.subplot(2,1,1)\nsns.barplot(x='country', y='values', data=data10, orient ='v')\nplt.xlabel('Country')\nplt.ylabel('Deaths')\nplt.title('Covid Cases Top 10')\nplt.subplot(2,1,2)\nsns.barplot(x='country', y='values', data=data20, orient ='v')\nplt.xlabel('Country')\nplt.ylabel('Deaths')\nplt.title('Covid Cases Next 10')","14dfa979":"df = train['TargetValue'].groupby(train['Target']).sum()\nlabels =[df.index[0],df.index[1]]\nsizes = [df[0],df[1]]\nexplode = (0, 0.2)  \n\nplt.figure(figsize = (5,5))\nplt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\n\nplt.show()","42bed180":"india = train[train['Country_Region']=='India']","7930c023":"india.info()","82311e6f":"india.drop(['County','Province_State'],axis =1,inplace =True)","1c70120d":"india.head(2)","d97baea3":"india.index = np.arange(0,len(india)) #rechanging the index","c9ae779f":"india.head(2)","da606ec7":"ind = india[india['Target']=='ConfirmedCases']\nind.index = np.arange(0,len(ind))","484de23e":"ind.head(2)","17bb7fc2":"print(\"Date with more no.of cases in india {}\".format((ind[ind['TargetValue']==ind['TargetValue'].max()]['Date']).values))\nprint(\"The cases are {}\".format((ind[ind['TargetValue']==ind['TargetValue'].max()]['TargetValue']).values))","c12b9403":"list1 = []\nfor i in range(2,7):\n    date = '2020'+'-0'+str(i)+'-01'\n    list1.append(ind[ind['Date']<date]['TargetValue'].sum())\nprint(list1)","5549de09":"sns.barplot(['upto Jan','Upto Feb','Upto Mar', 'Upto Apr','Upto May'],list1)","a47409bb":"list2 =[]\nfor i in range(len(list1)):\n    if i ==0:\n        list2.append(list1[i])\n    else:\n        list2.append(list1[i]-list1[i-1])\nprint(list2)","989ca0a0":"labels =['Jan','Feb','Mar','Apr','May']\nsns.barplot(labels,list2)","ddf6524d":"df = india['TargetValue'].groupby(train['Target']).sum()\ndf","7b2feb97":"labels =[df.index[0],df.index[1]]\nsizes = [df[0],df[1]]\nexplode = (0, 0.2)  \nplt.figure(figsize = (5,5))\n\nplt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\n\nplt.show()","c4436713":"wor = train[train['Target']=='ConfirmedCases']","be97764c":"print(\"Date with more no.of cases  {}\".format((wor[wor['TargetValue']==wor['TargetValue'].max()]['Date']).values))\nprint(\"The cases are {}\".format((wor[wor['TargetValue']==wor['TargetValue'].max()]['TargetValue']).values))\nprint(\"The Country is {}\".format((wor[wor['TargetValue']==wor['TargetValue'].max()]['Country_Region']).values))","5c8f24d9":"wor.columns","d85a73b5":"independent_columns = ['Country_Region','Weight','Target','Date']\ndependent_column = ['TargetValue']","d3b0623d":"X= train[independent_columns]\ny = train[dependent_column]","e46e39b8":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nX['Target']=le.fit_transform(X['Target'])","0648b7b3":"X.info()","85429fa1":"train1= train[train['Target']=='ConfirmedCases']\ndata1 = pd.DataFrame()\ndata1['values'] =train1.TargetValue.groupby(train1['Country_Region']).sum().sort_values(ascending= False)\ndata1['country'] = data1.index","c68a76b7":"k = len(data1['country'])\ndict1 = {}\nfor i in data1['country']:\n    dict1[i] = k\n    k =k-1","930d8658":"list1=[]\nX['encoded_country']=0\nfor i in X['Country_Region']:\n    list1.append(dict1[i])\nX['encoded_country'] = list1","b4c67ae8":"X['encoded_country'].value_counts()","c8573b32":"X['date_dup'] = pd.to_datetime(X['Date'])","286c65fc":"X['month'] = 0\nlist1=[]\nfor i in X['date_dup']:\n    list1.append(i.month)\nX['month'] = list1","fff0842b":"X['date'] = 0\nlist1=[]\nfor i in X['date_dup']:\n    list1.append(i.day)\nX['date'] = list1","e75cba67":"X.head(2)","a3167d8a":"X.drop(['Country_Region','Date','date_dup'],axis =1,inplace =True)","a139fb5c":"X.head(2)","e24f2140":"plt.figure(figsize =(10,10))\nsns.heatmap(X.corr(),annot=True)","e3faa311":"from sklearn.model_selection import train_test_split as tts","a11b0b4b":"max_range =10","73c6a200":"from sklearn.ensemble import RandomForestRegressor as regr\nfrom sklearn.metrics import r2_score","f60747f3":"'''for i in range(max_range):\n    X_train,X_test,y_train,y_test = tts(X,y,test_size =0.3,random_state =i)\n    model = regr()\n    model.fit(X_train,y_train)\n    print(\"Random state {}\\n\".format(i))\n    print(r2_score(y_test,model.predict(X_test)))'''","d57f7cc6":"X_train,X_test,y_train,y_test = tts(X,y,test_size =0.3,random_state =7)\nmodel = regr()\nmodel.fit(X_train,y_train)","ac271301":"print(r2_score(y_test,model.predict(X_test)))","14690307":"test = test[independent_columns]","965eb870":"list1=[]\ntest['encoded_country']=0\nfor i in test['Country_Region']:\n    list1.append(dict1[i])\ntest['encoded_country'] = list1","3a508d4d":"test['date_dup'] = pd.to_datetime(test['Date'])","b6047fb5":"test['month'] = 0\nlist1=[]\nfor i in test['date_dup']:\n    list1.append(i.month)\ntest['month'] = list1","a4375d3c":"test['date'] = 0\nlist1=[]\nfor i in test['date_dup']:\n    list1.append(i.day)\ntest['date'] = list1","86a4043d":"test.head(2)","85884c6d":"test.drop(['Country_Region','Date','date_dup'],axis =1,inplace =True)","0d082df4":"test.head(2)","8aea4367":"le1 =LabelEncoder()\ntest['Target'] = le1.fit_transform(test['Target'])","5f462097":"pred = model.predict(test)","8a501aa1":"t =pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-5\/test.csv')\nss = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-5\/submission.csv')","4fff51d4":"output = pd.DataFrame({'Id': t.ForecastId  , 'TargetValue': pred})","204b007f":"a=output.groupby(['Id'])['TargetValue'].quantile(q=0.05).reset_index()\nb=output.groupby(['Id'])['TargetValue'].quantile(q=0.5).reset_index()\nc=output.groupby(['Id'])['TargetValue'].quantile(q=0.95).reset_index()","bdf7ec6d":"a.columns=['Id','q0.05']\nb.columns=['Id','q0.5']\nc.columns=['Id','q0.95']\na=pd.concat([a,b['q0.5'],c['q0.95']],1)\na['q0.05']=a['q0.05']\na['q0.5']=a['q0.5']\na['q0.95']=a['q0.95']","e4698ab0":"sub=pd.melt(a, id_vars=['Id'], value_vars=['q0.05','q0.5','q0.95'])\nsub['variable']=sub['variable'].str.replace(\"q\",\"\", regex=False)\nsub['ForecastId_Quantile']=sub['Id'].astype(str)+'_'+sub['variable']\nsub['TargetValue']=sub['value']\nsub=sub[['ForecastId_Quantile','TargetValue']]\nsub.reset_index(drop=True,inplace=True)\nsub.to_csv(\"submission.csv\",index=False)\nsub.head()","43358e28":"sub.info()","ed54eb64":"# <center>Monthly Progression of disease <\/center>","31d15c5a":"In this kernal i'm going to create a predictive model for covid19 global-forecasting week 5 data which contains around 7 lakhs data for  training and we have to predict the target values for 3 lakhs test data\n\nIn this model first i have did some analysis with the data with some graphs and also the the effect of corona in  India have been analysed seperately.\n\nFinally I created a ensemble learning model with almost 0.96 Rsquared score","baa595e3":"# <center>Analysing the cases in India<\/center>","1e2ef4e8":"# <center>Top 20 in Population<\/center>","bed3f131":"# <center>Fatalities vs Confirmed cases(WW)<\/center>","1a957043":"# <center>Encoding Country according to it's rank in no.of confirmed cases<\/center>","c2889920":"# Actually I did some processing to find the best random state and I commented because it takes so much time to run\nBEST RANDOM STATE:7","829b0927":"# <center>Fatalities vs Confirmed cases(India)<\/center>","31af5438":"# <center>Top 20 in Deaths<\/center>","f0184dc4":"# <center>Top 20 in Confirmed Cases<\/center>","b151be52":"# <center> Seeing the Correleation<\/center>","b849159a":"# <center> Picking out date and month seperately<\/center>","a1c77301":"# <center>Preprocessing the test data in the same way we did for training data<\/center>","f2420ef7":"# <center>Count per month<\/center>"}}