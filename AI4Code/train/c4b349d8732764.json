{"cell_type":{"59450707":"code","780e3188":"code","2316fb2a":"code","71eab403":"code","d061f2b3":"code","3248e8e6":"code","ebea28c6":"code","93218c6a":"code","4a2d1c74":"code","cb48f65f":"markdown","78c512f4":"markdown","331894e7":"markdown","f2fe5284":"markdown","7d95ac5b":"markdown","8d5561b5":"markdown","f756044e":"markdown"},"source":{"59450707":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, MaxPooling1D, Conv1D, GlobalMaxPooling1D, Dropout\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","780e3188":"KAGGLE_PATH = '\/kaggle\/input\/dl-urfu-yelp\/'\nx_train = pd.read_csv(KAGGLE_PATH + 'train.csv')\ny_train = pd.read_csv(KAGGLE_PATH + 'train_label.csv', index_col=0)\nx_test = pd.read_csv(KAGGLE_PATH + 'test.csv')\nx_train.shape, y_train.shape, x_test.shape, ","2316fb2a":"# \u0438\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 \u0441 \u0442\u0435\u043a\u0441\u0442\u043e\u043c\nx_train = x_train.Review\nx_test = x_test.Review","71eab403":"# \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0434\u043b\u0438\u043d\u0443 \u0441\u043b\u043e\u0432\u0430\u0440\u044f, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043c\u044b \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\nnum_words = 10000\n# \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u043c \u0434\u043b\u0438\u043d\u0443 \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0441\u0442\u0438, \u043a \u043a\u043e\u0442\u043e\u0440\u043e\u0439 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043c \u0432\u0441\u0435 \u0442\u0435\u043a\u0441\u0442\u044b\nmax_review_len = 50\n# \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0438 \u043e\u0431\u0443\u0447\u0430\u0435\u043c \u0442\u043e\u043a\u0435\u043d\u0438\u0437\u0430\u0442\u043e\u0440 \u043d\u0430 \u0442\u0435\u0440\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\ntokenizer = Tokenizer(num_words=num_words)\ntokenizer.fit_on_texts(x_train)\n# \u043f\u0440\u0438\u043c\u0435\u043d\u044f\u0435\u043c \u0442\u043e\u043a\u0435\u043d\u0438\u0437\u0430\u0442\u043e\u0440 \u043a \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u044b\u043c \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u043c \u0434\u0430\u043d\u043d\u044b\u043c\nx_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)\n# \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u043c \u0432\u0441\u0435 \u0432\u0435\u043a\u0442\u043e\u0440\u0430 \u0442\u0435\u043a\u0441\u0442\u043e\u0432 \u043a \u043e\u0431\u0449\u0435\u0439 \u0434\u043b\u0438\u043d\u0435\nx_train = pad_sequences(x_train, maxlen=max_review_len, padding='post')\nx_test = pad_sequences(x_test, maxlen=max_review_len, padding='post')","d061f2b3":"model = Sequential()\nmodel.add(Embedding(num_words, 30, input_length=max_review_len))\nmodel.add(Conv1D(64, 5, padding='valid', activation='relu'))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))","3248e8e6":"model.compile(optimizer='sgd', \n              loss='binary_crossentropy', \n              metrics=['accuracy'])","ebea28c6":"history = model.fit(x_train, \n                    y_train, \n                    epochs=6,\n                    batch_size=128,\n                    validation_split=0.1)","93218c6a":"plt.plot(history.history['accuracy'], \n         label='\u0414\u043e\u043b\u044f \u0432\u0435\u0440\u043d\u044b\u0445 \u043e\u0442\u0432\u0435\u0442\u043e\u0432 \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u043c \u043d\u0430\u0431\u043e\u0440\u0435')\nplt.plot(history.history['val_accuracy'], \n         label='\u0414\u043e\u043b\u044f \u0432\u0435\u0440\u043d\u044b\u0445 \u043e\u0442\u0432\u0435\u0442\u043e\u0432 \u043d\u0430 \u043f\u0440\u043e\u0432\u0435\u0440\u043e\u0447\u043d\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435')\nplt.xlabel('\u042d\u043f\u043e\u0445\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f')\nplt.ylabel('\u0414\u043e\u043b\u044f \u0432\u0435\u0440\u043d\u044b\u0445 \u043e\u0442\u0432\u0435\u0442\u043e\u0432')\nplt.legend()\nplt.show()","4a2d1c74":"sample_submission = pd.read_csv(KAGGLE_PATH + 'sample_submission.csv', index_col='id')\nsample_submission.label = model.predict_classes(x_test)\nsample_submission.to_csv(\"sample_submission.csv\")","cb48f65f":"## \u041e\u0431\u0443\u0447\u0430\u0435\u043c \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c","78c512f4":"## \u0413\u043e\u0442\u043e\u0432\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f LeaderBoard","331894e7":"## \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0442\u0438","f2fe5284":"## \u041e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0442\u043e\u043d\u0430\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u0442\u0435\u043a\u0441\u0442\u043e\u0432 \u043e\u0442\u0437\u044b\u0432\u043e\u0432 \u043d\u0430 \u0441\u0430\u0439\u0442\u0435 [YELP](https:\/\/www.yelp.com\/dataset) \u043e\u0434\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0439 \u0441\u0432\u0435\u0440\u0442\u043e\u0447\u043d\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c\u044e\n\n\u0423\u0447\u0435\u0431\u043d\u044b\u0439 \u043a\u0443\u0440\u0441 \"[\u041f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0433\u043b\u0443\u0431\u043e\u043a\u0438\u0445 \u043d\u0435\u0439\u0440\u043e\u043d\u043d\u044b\u0445 \u0441\u0435\u0442\u0435\u0439 \u043d\u0430 Python](https:\/\/openedu.ru\/course\/urfu\/PYDNN\/)\".\n","7d95ac5b":"\u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435","8d5561b5":"### \u0422\u043e\u043a\u0435\u043d\u0438\u0437\u0430\u0446\u0438\u044f \u0442\u0435\u043a\u0441\u0442\u0430","f756044e":"## \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f"}}