{"cell_type":{"55d73074":"code","1ed895c2":"code","f23988be":"code","b17b2bd4":"code","9d2378ca":"code","72e1737b":"code","e6f750f7":"code","581b6983":"code","795671b0":"code","f33867f8":"code","7cd09472":"code","867af00b":"code","6a8bd2e4":"code","99d8fe1c":"code","0f81a4c0":"code","618274ff":"code","237c812c":"code","ec193162":"code","cb3977b7":"code","7c33f90c":"code","36386485":"code","f5968a58":"code","4c2394b5":"code","25cfa43f":"code","a5c7414d":"code","f8e3f5ad":"code","dcc0b713":"code","52e49be3":"code","f9b84fd4":"code","e5e8e6c4":"code","7dc52f82":"code","df78d2ee":"code","c94055fd":"code","5c03fb83":"code","2202f141":"code","35bb6cf9":"code","5c6d179d":"code","c135af3a":"code","3139a0ac":"markdown"},"source":{"55d73074":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ed895c2":"# importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler","f23988be":"dataframe = pd.read_csv('\/kaggle\/input\/nyse\/prices-split-adjusted.csv')","b17b2bd4":"dataframe = dataframe.set_index('date')","9d2378ca":"dataframe.info()","72e1737b":"dataframe.head()","e6f750f7":"# we'll see how many number of stocks present.\nlen(set(dataframe['symbol']))","581b6983":"dataframe.describe()","795671b0":"plt.figure(figsize = (15, 5))\nplt.subplot(1, 1, 1)\nplt.plot(dataframe[dataframe['symbol'] == 'EQIX']['close'], label = 'close')\nplt.title('Stock Prices')\nplt.xlabel('time')\nplt.ylabel('price')\nplt.legend()\nplt.show()","f33867f8":"# fetching only the close column\ndataframe_close = dataframe[dataframe['symbol'] == 'EQIX']['close']","7cd09472":"dataframe_close.head()","867af00b":"# creating 80% of training data and 20% of testing data\ntraining_data_length = round((80\/100 * len(dataframe_close)))","6a8bd2e4":"len(dataframe_close)","99d8fe1c":"training_data_length","0f81a4c0":"training_dataframe = dataframe_close[:training_data_length]\ntraining_dataframe","618274ff":"testing_dataframe = dataframe_close[training_data_length:]\ntesting_dataframe","237c812c":"print(training_dataframe.shape)\ntraining_dataframe = training_dataframe.values.reshape(-1, 1)\nprint(training_dataframe.shape)","ec193162":"# scaling the data\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0, 1))\nscaled_training_dataset = scaler.fit_transform(training_dataframe)\nscaled_training_dataset","cb3977b7":"scaled_training_dataset[0:1, 0]","7c33f90c":"# creating a moving window\nX_train, y_train = [], []\nmoving_window_size = 60 # standard size for all time series analysis\n\nfor i in range(moving_window_size, len(scaled_training_dataset)):\n    X_train.append(scaled_training_dataset[i-moving_window_size:i, 0])\n    y_train.append(scaled_training_dataset[i, 0])","36386485":"# we need to convert list into array to fed it into recurrent neural networks","f5968a58":"X_train = np.array(X_train)","4c2394b5":"y_train = np.array(y_train)","25cfa43f":"print('X_train shape {0}'.format(X_train.shape))\nprint('y_train shape {0}'.format(y_train.shape))","a5c7414d":"# we can add dimensions in the future here.\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\ny_train = y_train.reshape(y_train.shape[0], 1)\nprint('X_train shape {0}'.format(X_train.shape))\nprint('y_train shape {0}'.format(y_train.shape))","f8e3f5ad":"# RNN\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\n\n# initializing the neural network\nrnn = Sequential()\nrnn.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\nrnn.add(Dropout(rate = 0.2))\nrnn.add(LSTM(units = 50, return_sequences = True))\nrnn.add(Dropout(rate = 0.2))\nrnn.add(LSTM(units = 50, return_sequences = False))\nrnn.add(Dropout(rate = 0.2))\nrnn.add(Dense(units = 1))\n\n# compiling the neural network\nrnn.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# fitting the model\nrnn.fit(X_train, y_train, epochs = 10, batch_size = 32)","dcc0b713":"rnn.summary()","52e49be3":"rnn.history.history.keys()\nplt.plot(rnn.history.history['loss'], 'o-')\nplt.xlabel('epochs')\nplt.ylabel('loss')","f9b84fd4":"# we are testing the model\nprint(testing_dataframe.shape)\ntesting_dataframe = testing_dataframe.values.reshape(-1, 1)\nprint(testing_dataframe.shape)","e5e8e6c4":"# scaling the testing dataframe\nscaled_testing_dataframe = scaler.fit_transform(testing_dataframe)","7dc52f82":"scaled_testing_dataframe[0]","df78d2ee":"# preparing the dataframe for testing\nX_test , y_test = [], []\nfor i in range(moving_window_size, len(testing_dataframe)):\n    X_test.append(scaled_testing_dataframe[i-moving_window_size : i, 0])\n    y_test.append(scaled_testing_dataframe[i])","c94055fd":"X_test = np.array(X_test)","5c03fb83":"X_test.shape","2202f141":"X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)","35bb6cf9":"X_test.shape","5c6d179d":"predictions = rnn.predict(X_test)","c135af3a":"# plotting the actual values and the predicted values\nplt.plot(y_test)\nplt.plot(predictions)","3139a0ac":"Thank you for viewing. Please comment if you find any suggestions or if you have any creative ideas."}}