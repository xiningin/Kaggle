{"cell_type":{"25c909dd":"code","7948fa08":"code","8e6525cf":"code","63b9fe83":"code","9a288c87":"code","0c342758":"code","8fc0d131":"code","5a6a5ad5":"code","ecad2701":"code","a482698e":"code","ff37de23":"code","d0a55bb1":"code","91d32589":"code","97bcfddc":"code","10c2e843":"code","a4e4d734":"code","09148344":"markdown","533f5a97":"markdown","a527eb42":"markdown","53cd4aad":"markdown","0bc06806":"markdown","9ee3c670":"markdown","e7b25680":"markdown","50fcfc1a":"markdown","ef0e9473":"markdown","0c3d45d0":"markdown","0f999417":"markdown","de3385de":"markdown","6d36cfc4":"markdown","190e512f":"markdown","befa4f61":"markdown","fb67ef2c":"markdown"},"source":{"25c909dd":"import numpy as np  # Data manipulation\nimport pandas as pd # Dataframe manipulation \nimport matplotlib.pyplot as plt # Plotting the data and the results\nimport matplotlib.image as mpimg # For displaying imagees\n%matplotlib inline\nfrom keras import models\nfrom keras import layers\nimport keras.preprocessing  as kp\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import regularizers\nfrom keras import optimizers","7948fa08":"train_datagen = ImageDataGenerator( # Data Augumentation for test data\nrescale=1.\/255,\nrotation_range=30,\nshear_range=0.3,\nzoom_range=0.3\n)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","8e6525cf":"train_gen=train_datagen.flow_from_directory('..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Train',\n                                            target_size=(250,250),\n                                            batch_size=48,\n                                            class_mode='binary')","63b9fe83":"valid_gen=test_datagen.flow_from_directory('..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Validation',\n                                           target_size=(250,250),\n                                           batch_size=48,\n                                           class_mode='binary')","9a288c87":"kernel_s=(3,3) # The size of kernel","0c342758":"model=models.Sequential()\nmodel.add(layers.Conv2D(32,kernel_s,activation='relu',input_shape=(250,250,3),\n                        kernel_regularizer=regularizers.l2(0.001),padding=\"VALID\"))\nmodel.add(layers.MaxPooling2D((2,2)))\n\nmodel.add(layers.Conv2D(64,kernel_s,activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64,kernel_s,activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\n\nmodel.add(layers.Conv2D(128,kernel_s,activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(128,kernel_s,activation='relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256,activation='relu'))\nmodel.add(layers.Dense(1,activation='sigmoid'))\nmodel.summary()","8fc0d131":"model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])","5a6a5ad5":"history=model.fit(train_gen,steps_per_epoch=70,epochs=30,\n                  validation_data=valid_gen,validation_steps=50)","ecad2701":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'ro', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'ro', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.figure()","a482698e":"test_datagen1 = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen1.flow_from_directory(\n'..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Test',\ntarget_size=(250,250),\nbatch_size=32,\nclass_mode='binary')","ff37de23":"test_loss, test_acc = model.evaluate_generator(test_generator, steps=32)\nprint('test acc:', test_acc)\nprint('test_loss:',test_loss)","d0a55bb1":"fig,ax=plt.subplots(ncols=2,nrows=4,figsize=(20,20))\nimg1 = mpimg.imread('..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Test\/Female\/160003.jpg')\nax[0][0].imshow(img1)\nax[0][0].set_title(\"Dataset we trained and tested on.\")\nimg2 = mpimg.imread('..\/input\/gender-classification-dataset\/Training\/female\/131422.jpg.jpg')\nax[0][1].imshow(img2)\nax[0][1].set_title(\"The completely new dataset.\")\nimg3 =  mpimg.imread('..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Validation\/Female\/180019.jpg')\nax[1][0].imshow(img3)\nimg4= mpimg.imread('..\/input\/gender-classification-dataset\/Validation\/female\/113010.jpg.jpg')\nax[1][1].imshow(img4)\nimg5 = mpimg.imread('..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Validation\/Male\/180028.jpg')\nax[2][0].imshow(img5)\nimg6 = mpimg.imread('..\/input\/gender-classification-dataset\/Validation\/male\/063517.jpg.jpg')\nax[2][1].imshow(img6)\nax[3][0].imshow(mpimg.imread('..\/input\/gender-recognition-200k-images-celeba\/Dataset\/Validation\/Male\/180073.jpg'))\nax[3][1].imshow(mpimg.imread('..\/input\/gender-classification-dataset\/Validation\/male\/063531.jpg.jpg'))\nplt.tight_layout()","91d32589":"test_datagen2 = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen2.flow_from_directory(\n'..\/input\/gender-classification-dataset\/Training',\ntarget_size=(250,250),\nbatch_size=64,\nclass_mode='binary')","97bcfddc":"test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('test acc:', test_acc)\nprint('test_loss:',test_loss)","10c2e843":"test_datagen3 = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen1.flow_from_directory(\n'..\/input\/gender-classification-dataset\/Validation',\ntarget_size=(250,250),\nbatch_size=64,\nclass_mode='binary')","a4e4d734":"test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('test acc:', test_acc)\nprint('test_loss:',test_loss)","09148344":"# Model testing on completely new dataset!","533f5a97":"For going through this notebook.","a527eb42":"# Model Training","53cd4aad":"Let's plot the training vs validation loss and accuracy graphs.","0bc06806":"160000 images should be enough for the model to pick up the local patterns.","9ee3c670":" # Gender classification using keras API","e7b25680":"Let's build the model now.","50fcfc1a":"Observe how different the new dataset is. It is low resoultion, and the images are zoomed in!","ef0e9473":"**Let's first prep the ImageDataGenerator with minor data augmentations to keep the training time optimal.**","0c3d45d0":"# Model Testing","0f999417":"# Exploratory Data Analysis","de3385de":"Uh, the accuracy falls drastically (over 20%) and the error rate (loss) increases by 1100%","6d36cfc4":"**Also, I am fairly new to data science and machine and I still hope that you found something useful in this notebook.** ","190e512f":"This tells us that the model is not yet prepared to deal with any set of male\/female classification dataset, but I guess that is what deep learning is about. All models are somewhat specific to the kind of the data they were trained on.\n\n\nWhat should be changed to better the generalization of the model?\n\nShould more features be augmented? (Horizontal\/Vertical flips, Rotation etc). \n\nShould I stop trying to fit my model on a totally new dataset? (Is it a waste of time?)\n\n**What do you think?**","befa4f61":"![pexels-vie-studio-4439457.jpg](attachment:pexels-vie-studio-4439457.jpg)","fb67ef2c":"A error rate under 0.10 and accuracy of above 90% is reasonably fair for a gender recognition task! (at least for a novice like me :D )"}}