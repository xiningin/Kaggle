{"cell_type":{"fc18ca04":"code","4bb2aab7":"code","646bf252":"code","718fbfa6":"code","d50662db":"code","80c6b175":"code","c5541196":"code","4e583cc2":"code","bf9129ac":"code","d4cc1c3d":"code","ce5f177f":"code","24696c58":"code","0bca2a11":"code","9584d512":"code","f41fbec3":"code","55402462":"code","bf77a433":"code","1bc1914f":"code","307876cd":"code","d781cfc5":"code","b85baedd":"code","855aa1cf":"code","6be69ac3":"code","2b579f88":"code","b830d1e2":"code","d6eb0ab8":"code","bd5f8410":"code","0babeb4c":"code","212dd326":"code","c2a58cb1":"code","280a191e":"code","df36e6d7":"code","ee4eaedf":"code","b6bc8a27":"code","88906ce4":"code","6228bf6d":"code","390d3217":"code","65ebb632":"code","bbc64d56":"code","28104874":"code","91a73505":"code","03498e90":"code","39f1513c":"code","2e97f6c9":"code","d2ae23fd":"code","81041c3e":"code","3d564628":"code","a3f9d654":"code","f10d879d":"code","95b86507":"code","2624d39c":"code","51a52487":"code","40909e60":"code","eff0e58d":"code","e43135e3":"code","0015898a":"code","9907caad":"code","2000d50d":"code","3416a606":"code","897e5712":"code","e9a25da2":"code","f31c4f88":"code","42475281":"code","a7ce0c92":"code","e7891c94":"code","c9f26dbb":"code","caa65f01":"code","a41eda56":"code","ae6eca9a":"code","94b6150b":"code","11c933c5":"code","f08dc0a8":"code","eedcc073":"code","a79dc7b5":"code","4e76e9f1":"code","7ee9e3f3":"code","73f3e8a2":"code","424f9806":"code","8fdb79a2":"code","39859147":"code","12c2d086":"code","2fd0a551":"code","9f2d3a1a":"code","e3d069ed":"code","f7d338ec":"code","1aee4a07":"code","2dab5d38":"code","5dbf9658":"code","4b150f6d":"code","9a863adc":"code","0af287b7":"code","3495d482":"code","97bd3f2b":"code","19e70ee2":"code","0ec6482e":"code","af1099c4":"code","3bcb7e77":"code","94602732":"code","e7faff4d":"code","f37b572e":"code","4a54b0ed":"code","ecd89a90":"code","84a54426":"code","7e5cebcf":"code","34d5c5d3":"code","60be4068":"code","6cf97385":"code","49039c8e":"code","e96d369e":"code","e2d256a6":"code","8ae9bbb9":"code","4a8700fd":"code","af450666":"code","69dbac25":"code","d04ca137":"code","d06d4d08":"code","efbea9ba":"code","8faeedae":"code","0bf21925":"markdown","a1231054":"markdown","f5d67794":"markdown","59aff179":"markdown","a16e14b1":"markdown","207e1307":"markdown","1b1caa40":"markdown","ab2abce1":"markdown"},"source":{"fc18ca04":"%matplotlib inline\n%reload_ext autoreload\n%autoreload 2","4bb2aab7":"from fastai.conv_learner import *\nfrom fastai.dataset import *\n\nimport json, pdb\nfrom PIL import ImageDraw, ImageFont\nfrom matplotlib import patches, patheffects","646bf252":"torch.backends.cudnn.benchmark = True","718fbfa6":"TMP_PATH = \"\/tmp\/tmp\"\nMODEL_PATH = \"\/tmp\/model\/\"","d50662db":"PATH = Path('..\/input\/')\ntrn_j = json.load((PATH\/'pascal_voc\/PASCAL_VOC\/pascal_train2007.json').open())\nIMAGES, ANNOTATIONS, CATEGORIES = ['images', 'annotations', 'categories']\n\nFILE_NAME, ID, IMG_ID, CAT_ID, BBOX = 'file_name', 'id', 'image_id', 'category_id', 'bbox'\n\ncats = {o[ID]:o['name'] for o in trn_j[CATEGORIES]}\ntrn_fns = {o[ID]:o[FILE_NAME] for o in trn_j[IMAGES]}\ntrn_ids = [o[ID] for o in trn_j[IMAGES]]\nJPEGS = 'voctrainval_06-nov-2007\/VOCdevkit\/VOC2007\/JPEGImages'\nIMG_PATH = PATH\/JPEGS","80c6b175":"def get_trn_anno():\n    trn_anno = collections.defaultdict(lambda:[])\n    for o in trn_j[ANNOTATIONS]:\n        if not o['ignore']:\n            bb = o[BBOX]\n            bb = np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n            trn_anno[o[IMG_ID]].append((bb, o[CAT_ID]))\n    return trn_anno\n\ntrn_anno = get_trn_anno()","c5541196":"def show_img(im, figsize=None, ax=None):\n    if not ax: fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im)\n    ax.set_xticks(np.linspace(0, 224, 8))\n    ax.set_yticks(np.linspace(0, 224, 8))\n    ax.grid()\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])\n    return ax\n\ndef draw_outline(o, lw):\n    o.set_path_effects([patheffects.Stroke(\n        linewidth=lw, foreground='black'), patheffects.Normal()])\n\ndef draw_rect(ax, b, color='white'):\n    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=color, lw=2))\n    draw_outline(patch, 4)\n\ndef draw_text(ax, xy, txt, sz=14, color='white'):\n    text = ax.text(*xy, txt, verticalalignment='top', color=color, fontsize=sz, weight='bold')\n    draw_outline(text, 1)","4e583cc2":"def bb_hw(a): return np.array([a[1], a[0], a[3]-a[1] + 1, a[2] - a[0] + 1])\n\ndef draw_im(im, ann):\n    ax = show_img(im, figsize=(16, 8))\n    for b, c in ann:\n        b = bb_hw(b)\n        draw_rect(ax, b)\n        draw_text(ax, b[:2], cats[c], sz=16)\n        draw_text(ax, b[:2], cats[c], sz=16)\n\ndef draw_idx(i):\n    im_a = trn_anno[i]\n    im = open_image(IMG_PATH + trn_fns[i])\n    draw_im(im, im_a)","bf9129ac":"!mkdir {TMP_PATH}","d4cc1c3d":"MC_CSV = Path(TMP_PATH + '\/lrg.csv')","ce5f177f":"trn_anno[12]","24696c58":"mc = [set([cats[p[1]] for p in trn_anno[o]]) for o in trn_ids]\nmcs = [' '.join(str(p) for p in o) for o in mc]","0bca2a11":"df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids], 'clas': mcs}, columns=['fn', 'clas'])\ndf.to_csv(MC_CSV, index=False)","9584d512":"f_model = resnet34\nsz=224\nbs=64","f41fbec3":"tfms=tfms_from_model(f_model, sz, crop_type=CropType.NO)\nmd = ImageClassifierData.from_csv(PATH, JPEGS, MC_CSV, tfms=tfms, bs=bs)","55402462":"learn = ConvLearner.pretrained(f_model, md, tmp_name=TMP_PATH, models_name=MODEL_PATH)\nlearn.opt_fn = optim.Adam","bf77a433":"lrf = learn.lr_find(1e-5, 100)","1bc1914f":"learn.sched.plot(0)","307876cd":"lr = 2e-2","d781cfc5":"learn.fit(lr, 1, cycle_len=3, use_clr=(32, 5))","b85baedd":"lrs= np.array([lr\/100, lr\/10, lr])","855aa1cf":"learn.freeze_to(-2)","6be69ac3":"learn.lr_find(lrs\/1000)\nlearn.sched.plot(0)","2b579f88":"learn.fit(lrs\/10, 1, cycle_len=5, use_clr=(32, 5))","b830d1e2":"learn.save('mclas')","d6eb0ab8":"learn.load('mclas')","bd5f8410":"y = learn.predict()\nx,_ = next(iter(md.val_dl))\nx = to_np(x)","0babeb4c":"fig, axes = plt.subplots(3, 4, figsize=(12, 8))\nfor i,ax in enumerate(axes.flat):\n    ima=md.val_ds.denorm(x)[i]\n    ya = np.nonzero(y[i]>0.4)[0]\n    b = '\\n'.join(md.classes[o] for o in ya)\n    ax = show_img(ima, ax=ax)\n    draw_text(ax, (0,0), b)\nplt.tight_layout()","212dd326":"CLAS_CSV = Path(TMP_PATH + '\/clas.csv')\nMBB_CSV = Path(TMP_PATH + '\/mbb.csv')\n\nf_model = resnet34\nsz=224\nbs=64","c2a58cb1":"mc = [[cats[p[1]] for p in trn_anno[o]] for o in trn_ids]\nid2cat = list(cats.values())\ncat2id = {v:k for k, v in enumerate(id2cat)}\nmcs = np.array([np.array([cat2id[p] for p in o]) for o in mc]);mcs","280a191e":"val_idxs = get_cv_idxs(len(trn_fns))\n((val_mcs, trn_mcs),) = split_by_idx(val_idxs, mcs)","df36e6d7":"mbb = [np.concatenate([p[0] for p in trn_anno[o]]) for o in trn_ids]\nmbbs = [' '.join(str(p) for p in o) for o in mbb]\n\ndf = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids], 'bbox': mbbs}, columns=['fn', 'bbox'])\ndf.to_csv(MBB_CSV, index=False)","ee4eaedf":"df.head()","b6bc8a27":"aug_tfms = [RandomRotate(3, p=0.5, tfm_y=TfmType.COORD),\n           RandomLighting(0.05, 0.05, tfm_y=TfmType.COORD),\n           RandomFlip(tfm_y=TfmType.COORD)]\ntfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=aug_tfms)\nmd = ImageClassifierData.from_csv(PATH, JPEGS, MBB_CSV, tfms=tfms, bs=bs, continuous=True, num_workers=4)","88906ce4":"import matplotlib.cm as cmx\nimport matplotlib.colors as mcolors\nfrom cycler import cycler\n\ndef get_cmap(N):\n    color_norm = mcolors.Normalize(vmin=0, vmax=N-1)\n    return cmx.ScalarMappable(norm=color_norm, cmap='Set3').to_rgba\n\nnum_colr = 12\ncmap = get_cmap(num_colr)\ncolr_list = [cmap(float(x)) for x in range(num_colr)]","6228bf6d":"def show_ground_truth(ax, im, bbox, clas=None, prs=None, thresh=0.3):\n    bb = [bb_hw(o) for o in bbox.reshape(-1, 4)]\n    if prs is None: prs = [None]*len(bb)\n    if clas is None: clas= [None]*len(bb)\n    ax = show_img(im, ax=ax)\n    for im , (b, c, pr) in enumerate(zip(bb, clas, prs)):\n        if ((b[2]>0) and (pr is None or pr>thresh)):\n            draw_rect(ax, b, color=colr_list[i%num_colr])\n            txt = f'{i}: '\n            if c is not None: txt += ('bg' if c==len(id2cat) else id2cat[c])\n            if pr is not None: txt += f' {pr:.2f}'\n            draw_text(ax, b[:2], txt, color=colr_list[i%num_colr])","390d3217":"class ConcatLblDataset(Dataset):\n    def __init__(self, ds, y2):\n        self.ds, self.y2 = ds, y2\n        self.sz = ds.sz\n    \n    def __len__(self):\n        return len(self.ds)\n    \n    def __getitem__(self, i):\n        x, y = self.ds[i]\n        return (x, (y, self.y2[i]))","65ebb632":"trn_ds2= ConcatLblDataset(md.trn_ds, trn_mcs)\nval_ds2 = ConcatLblDataset(md.val_ds, val_mcs)\nmd.trn_dl.dataset = trn_ds2\nmd.val_dl.dataset = val_ds2","bbc64d56":"x, y = to_np(next(iter(md.val_dl)))\nx = md.val_ds.ds.denorm(x)","28104874":"x,y=to_np(next(iter(md.trn_dl)))\nx=md.trn_ds.ds.denorm(x)","91a73505":"fig, axes = plt.subplots(3, 4, figsize=(16, 12))\nfor i,ax in enumerate(axes.flat):\n    show_ground_truth(ax, x[i], y[0][i], y[1][i])\nplt.tight_layout()","03498e90":"anc_grid = 4\nk = 1\n\nanc_offset = 1\/(anc_grid*2)\nanc_x = np.repeat(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\nanc_y = np.tile(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\n\nanc_ctrs = np.tile(np.stack([anc_x, anc_y], axis=1), (k, 1))\nanc_sizes = np.array([[1\/anc_grid, 1\/anc_grid] for i in range(anc_grid*anc_grid)])\nanchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()","39f1513c":"grid_sizes = V(np.array([1\/anc_grid]), requires_grad=False).unsqueeze(1)","2e97f6c9":"plt.scatter(anc_x, anc_y)\nplt.xlim(0, 1)\nplt.ylim(0,1 );","d2ae23fd":"anchors","81041c3e":"def hw2corners(ctr, hw): return torch.cat([ctr-hw\/2, ctr+hw\/2], dim=1)","3d564628":"anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])\nanchor_cnr","a3f9d654":"n_clas = len(id2cat) + 1\nn_cat = k*(4+n_clas)","f10d879d":"class StdConv(nn.Module):\n    def __init__(self, nin, nout, stride=2, drop=0.1):\n        super().__init__()\n        self.conv = nn.Conv2d(nin, nout, 3, stride=stride, padding=1)\n        self.bn = nn.BatchNorm2d(nout)\n        self.drop = nn.Dropout(drop)\n    \n    def forward(self, x):\n        return self.drop(self.bn(F.relu(self.conv(x))))\n\ndef flatten_conv(x, k):\n    bs, nf, gx, gy = x.size()\n    x = x.permute(0,2,3,1).contiguous()\n    return x.view(bs, -1, nf\/\/k)","95b86507":"class OutConv(nn.Module):\n    def __init__(self, k, nin, bias):\n        super().__init__()\n        self.k = k\n        self.oconv1 = nn.Conv2d(nin, (len(id2cat)+1)*k, 3, padding=1)\n        self.oconv2 = nn.Conv2d(nin, 4*k, 3, padding=1)\n        self.oconv1.bias.data.zero_().add_(bias)\n    \n    def forward(self, x):\n        return [flatten_conv(self.oconv1(x), self.k),\n                flatten_conv(self.oconv2(x), self.k)]","2624d39c":"class SSD_Head(nn.Module):\n    def __init__(self, k, bias):\n        super().__init__()\n        self.drop = nn.Dropout(0.25)\n        self.sconv0 = StdConv(512,256, stride=1)\n        self.sconv2 = StdConv(256,256)\n        self.out = OutConv(k, 256, bias)\n        \n    def forward(self, x):\n        x = self.drop(F.relu(x))\n        x = self.sconv0(x)\n        x = self.sconv2(x)\n        return self.out(x)\n\nhead_reg4 = SSD_Head(k, -3.)\nmodels = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\nlearn = ConvLearner(md, models, tmp_name=TMP_PATH, models_name=MODEL_PATH)\nlearn.opt_fn = optim.Adam","51a52487":"def one_hot_embedding(labels, num_classes):\n    return torch.eye(num_classes)[labels.data.cpu()]\n\nclass BCE_Loss(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n\n    def forward(self, pred, targ):\n        t = one_hot_embedding(targ, self.num_classes+1)\n        t = V(t[:,:-1].contiguous())#.cpu()\n        x = pred[:,:-1]\n        w = self.get_weight(x,t)\n        return F.binary_cross_entropy_with_logits(x, t, w, size_average=False)\/self.num_classes\n    \n    def get_weight(self,x,t): return None\n\nloss_f = BCE_Loss(len(id2cat))","40909e60":"def intersect(box_a, box_b):\n    max_xy = torch.min(box_a[:, None, 2:], box_b[None, :, 2:])\n    min_xy = torch.max(box_a[:, None, :2], box_b[None, :, :2])\n    inter = torch.clamp((max_xy - min_xy), min=0)\n    return inter[:, :, 0] * inter[:, :, 1]\n\ndef box_sz(b): return ((b[:, 2]-b[:, 0]) * (b[:, 3]-b[:, 1]))\n\ndef jaccard(box_a, box_b):\n    inter = intersect(box_a, box_b)\n    union = box_sz(box_a).unsqueeze(1) + box_sz(box_b).unsqueeze(0) - inter\n    return inter \/ union","eff0e58d":"def get_y(bbox,clas):\n    bbox = bbox.view(-1,4)\/sz\n    bb_keep = ((bbox[:,2]-bbox[:,0])>0).nonzero()[:,0]\n    return bbox[bb_keep],clas[bb_keep]\n\ndef actn_to_bb(actn, anchors):\n    actn_bbs = torch.tanh(actn)\n    actn_centers = (actn_bbs[:,:2]\/2 * grid_sizes) + anchors[:,:2]\n    actn_hw = (actn_bbs[:,2:]\/2+1) * anchors[:,2:]\n    return hw2corners(actn_centers, actn_hw)\n\ndef map_to_ground_truth(overlaps, print_it=False):\n    prior_overlap, prior_idx = overlaps.max(1)\n    if print_it: print(prior_overlap)\n#     pdb.set_trace()\n    gt_overlap, gt_idx = overlaps.max(0)\n    gt_overlap[prior_idx] = 1.99\n    for i,o in enumerate(prior_idx): gt_idx[o] = i\n    return gt_overlap,gt_idx\n\ndef ssd_1_loss(b_c,b_bb,bbox,clas,print_it=False):\n    bbox,clas = get_y(bbox,clas)\n    a_ic = actn_to_bb(b_bb, anchors)\n    overlaps = jaccard(bbox.data, anchor_cnr.data)\n    gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it)\n    gt_clas = clas[gt_idx]\n    pos = gt_overlap > 0.4\n    pos_idx = torch.nonzero(pos)[:,0]\n    gt_clas[1-pos] = len(id2cat)\n    gt_bbox = bbox[gt_idx]\n    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n    clas_loss  = loss_f(b_c, gt_clas)\n    return loc_loss, clas_loss","e43135e3":"def ssd_loss(pred,targ,print_it=False):\n    lcs,lls = 0.,0.\n    for b_c,b_bb,bbox,clas in zip(*pred,*targ):\n        loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,print_it)\n        lls += loc_loss\n        lcs += clas_loss\n    if print_it: print(f'loc: {lls.data[0]}, clas: {lcs.data[0]}')\n    return lls+lcs","0015898a":"x,y = next(iter(md.val_dl))\n# x,y = V(x).cpu(),V(y)\nx,y = V(x),V(y)","9907caad":"# for i,o in enumerate(y): y[i] = o.cpu()\n# learn.model.cuda()","2000d50d":"batch = learn.model(x)","3416a606":"# anchors = anchors.cpu(); grid_sizes = grid_sizes.cpu(); anchor_cnr = anchor_cnr.cpu()","897e5712":"ssd_loss(batch, y, True)","e9a25da2":"learn.crit = ssd_loss\nlr = 3e-3\nlrs = np.array([lr\/100,lr\/10,lr])","f31c4f88":"learn.lr_find(lrs\/1000,1.)\nlearn.sched.plot(1)","42475281":"learn.fit(lr, 1, cycle_len=5, use_clr=(20,10))","a7ce0c92":"learn.save('0')","e7891c94":"learn.load('0')","c9f26dbb":"x,y = next(iter(md.val_dl))\nx,y = V(x),V(y)\nlearn.model.eval()\nbatch = learn.model(x)\nb_clas,b_bb = batch","caa65f01":"b_clas.size(),b_bb.size()","a41eda56":"idx=7\nb_clasi = b_clas[idx]\nb_bboxi = b_bb[idx]\nima=md.val_ds.ds.denorm(to_np(x))[idx]\nbbox,clas = get_y(y[0][idx], y[1][idx])\nbbox,clas","ae6eca9a":"def torch_gt(ax, ima, bbox, clas, prs=None, thresh=0.4):\n    return show_ground_truth(ax, ima, to_np((bbox*224).long()),\n         to_np(clas), to_np(prs) if prs is not None else None, thresh)","94b6150b":"fig, ax = plt.subplots(figsize=(7,7))\ntorch_gt(ax, ima, bbox, clas)","11c933c5":"fig, ax = plt.subplots(figsize=(7,7))\ntorch_gt(ax, ima, anchor_cnr, b_clasi.max(1)[1])","f08dc0a8":"grid_sizes","eedcc073":"anchors","a79dc7b5":"a_ic = actn_to_bb(b_bboxi, anchors)","4e76e9f1":"fig, ax = plt.subplots(figsize=(7,7))\ntorch_gt(ax, ima, a_ic, b_clasi.max(1)[1], b_clasi.max(1)[0].sigmoid(), thresh=0.0)","7ee9e3f3":"overlaps = jaccard(bbox.data, anchor_cnr.data)\noverlaps","73f3e8a2":"overlaps.max(1)","424f9806":"overlaps.max(0)","8fdb79a2":"gt_overlap,gt_idx = map_to_ground_truth(overlaps)\ngt_overlap,gt_idx","39859147":"gt_clas = clas[gt_idx]; gt_clas\n","12c2d086":"thresh = 0.5\npos = gt_overlap > thresh\npos_idx = torch.nonzero(pos)[:,0]\nneg_idx = torch.nonzero(1-pos)[:,0]\npos_idx","2fd0a551":"gt_clas[1-pos] = len(id2cat)\n[id2cat[o] if o<len(id2cat) else 'bg' for o in gt_clas.data]","9f2d3a1a":"gt_bbox = bbox[gt_idx]\nloc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\nclas_loss  = F.cross_entropy(b_clasi, gt_clas)\nloc_loss,clas_loss","e3d069ed":"fig, axes = plt.subplots(3, 4, figsize=(16, 12))\nfor idx,ax in enumerate(axes.flat):\n    ima=md.val_ds.ds.denorm(to_np(x))[idx]\n    bbox,clas = get_y(y[0][idx], y[1][idx])\n    ima=md.val_ds.ds.denorm(to_np(x))[idx]\n    bbox,clas = get_y(bbox,clas); bbox,clas\n    a_ic = actn_to_bb(b_bb[idx], anchors)\n    torch_gt(ax, ima, a_ic, b_clas[idx].max(1)[1], b_clas[idx].max(1)[0].sigmoid(), 0.01)\nplt.tight_layout()","f7d338ec":"anc_grids = [4,2,1]\n# anc_grids = [2]\nanc_zooms = [0.7, 1., 1.3]\n# anc_zooms = [1.]\nanc_ratios = [(1.,1.), (1.,0.5), (0.5,1.)]\n# anc_ratios = [(1.,1.)]\nanchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\nk = len(anchor_scales)\nanc_offsets = [1\/(o*2) for o in anc_grids]\nk","1aee4a07":"anc_x = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n                        for ao,ag in zip(anc_offsets,anc_grids)])\nanc_y = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n                        for ao,ag in zip(anc_offsets,anc_grids)])\nanc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)","2dab5d38":"anc_sizes  =   np.concatenate([np.array([[o\/ag,p\/ag] for i in range(ag*ag) for o,p in anchor_scales])\n               for ag in anc_grids])\ngrid_sizes = V(np.concatenate([np.array([ 1\/ag       for i in range(ag*ag) for o,p in anchor_scales])\n               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\nanchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\nanchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])","5dbf9658":"anchors","4b150f6d":"x,y=to_np(next(iter(md.val_dl)))\nx=md.val_ds.ds.denorm(x)","9a863adc":"a=np.reshape((to_np(anchor_cnr) + to_np(torch.randn(*anchor_cnr.size()))*0.01)*224, -1)","0af287b7":"fig, ax = plt.subplots(figsize=(7,7))\nshow_ground_truth(ax, x[0], a)","3495d482":"fig, ax = plt.subplots(figsize=(7,7))\nshow_ground_truth(ax, x[0], a)","97bd3f2b":"drop=0.4\n\nclass SSD_MultiHead(nn.Module):\n    def __init__(self, k, bias):\n        super().__init__()\n        self.drop = nn.Dropout(drop)\n        self.sconv0 = StdConv(512,256, stride=1, drop=drop)\n        self.sconv1 = StdConv(256,256, drop=drop)\n        self.sconv2 = StdConv(256,256, drop=drop)\n        self.sconv3 = StdConv(256,256, drop=drop)\n        self.out0 = OutConv(k, 256, bias)\n        self.out1 = OutConv(k, 256, bias)\n        self.out2 = OutConv(k, 256, bias)\n        self.out3 = OutConv(k, 256, bias)\n\n    def forward(self, x):\n        x = self.drop(F.relu(x))\n        x = self.sconv0(x)\n        x = self.sconv1(x)\n        o1c,o1l = self.out1(x)\n        x = self.sconv2(x)\n        o2c,o2l = self.out2(x)\n        x = self.sconv3(x)\n        o3c,o3l = self.out3(x)\n        return [torch.cat([o1c,o2c,o3c], dim=1),\n                torch.cat([o1l,o2l,o3l], dim=1)]\n\nhead_reg4 = SSD_MultiHead(k, -4.)\nmodels = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\nlearn = ConvLearner(md, models, tmp_name=TMP_PATH, models_name=MODEL_PATH)\nlearn.opt_fn = optim.Adam","19e70ee2":"learn.crit = ssd_loss\nlr = 1e-2\nlrs = np.array([lr\/100,lr\/10,lr])","0ec6482e":"x,y = next(iter(md.val_dl))\nx,y = V(x),V(y)\nbatch = learn.model(V(x))","af1099c4":"batch[0].size(),batch[1].size()","3bcb7e77":"ssd_loss(batch, y, True)","94602732":"learn.lr_find(lrs\/1000,1.)\nlearn.sched.plot(n_skip_end=2)","e7faff4d":"learn.fit(lrs, 1, cycle_len=4, use_clr=(20,8))","f37b572e":"learn.save('tmp')","4a54b0ed":"learn.freeze_to(-2)\nlearn.fit(lrs\/2, 1, cycle_len=4, use_clr=(20,8))","ecd89a90":"learn.save('prefocal')","84a54426":"x,y = next(iter(md.val_dl))\ny = V(y)\nbatch = learn.model(V(x))\nb_clas,b_bb = batch\nx = to_np(x)\n\nfig, axes = plt.subplots(3, 4, figsize=(16, 12))\nfor idx,ax in enumerate(axes.flat):\n    ima=md.val_ds.ds.denorm(x)[idx]\n    bbox,clas = get_y(y[0][idx], y[1][idx])\n    a_ic = actn_to_bb(b_bb[idx], anchors)\n    torch_gt(ax, ima, a_ic, b_clas[idx].max(1)[1], b_clas[idx].max(1)[0].sigmoid(), 0.21)\nplt.tight_layout()","7e5cebcf":"def plot_results(thresh):\n    x,y = next(iter(md.val_dl))\n    y = V(y)\n    batch = learn.model(V(x))\n    b_clas,b_bb = batch\n\n    x = to_np(x)\n    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n    for idx,ax in enumerate(axes.flat):\n        ima=md.val_ds.ds.denorm(x)[idx]\n        bbox,clas = get_y(y[0][idx], y[1][idx])\n        a_ic = actn_to_bb(b_bb[idx], anchors)\n        clas_pr, clas_ids = b_clas[idx].max(1)\n        clas_pr = clas_pr.sigmoid()\n        torch_gt(ax, ima, a_ic, clas_ids, clas_pr, clas_pr.max().data[0]*thresh)\n    plt.tight_layout()","34d5c5d3":"class FocalLoss(BCE_Loss):\n    def get_weight(self,x,t):\n        alpha,gamma = 0.25,1\n        p = x.sigmoid()\n        pt = p*t + (1-p)*(1-t)\n        w = alpha*t + (1-alpha)*(1-t)\n        return w * (1-pt).pow(gamma)\n\nloss_f = FocalLoss(len(id2cat))","60be4068":"x,y = next(iter(md.val_dl))\nx,y = V(x),V(y)\nbatch = learn.model(x)\nssd_loss(batch, y, True)","6cf97385":"learn.lr_find(lrs\/1000,1.)\nlearn.sched.plot(n_skip_end=1)","49039c8e":"learn.fit(lrs, 1, cycle_len=10, use_clr=(20,10))","e96d369e":"learn.save('fl0')","e2d256a6":"learn.load('fl0')","8ae9bbb9":"learn.freeze_to(-2)\nlearn.fit(lrs\/4, 1, cycle_len=10, use_clr=(20,10))","4a8700fd":"learn.save('drop4')","af450666":"learn.load('drop4')","69dbac25":"plot_results(0.75)","d04ca137":"def nms(boxes, scores, overlap=0.5, top_k=100):\n    keep = scores.new(scores.size(0)).zero_().long()\n    if boxes.numel() == 0: return keep\n    x1 = boxes[:, 0]\n    y1 = boxes[:, 1]\n    x2 = boxes[:, 2]\n    y2 = boxes[:, 3]\n    area = torch.mul(x2 - x1, y2 - y1)\n    v, idx = scores.sort(0)  # sort in ascending order\n    idx = idx[-top_k:]  # indices of the top-k largest vals\n    xx1 = boxes.new()\n    yy1 = boxes.new()\n    xx2 = boxes.new()\n    yy2 = boxes.new()\n    w = boxes.new()\n    h = boxes.new()\n\n    count = 0\n    while idx.numel() > 0:\n        i = idx[-1]  # index of current largest val\n        keep[count] = i\n        count += 1\n        if idx.size(0) == 1: break\n        idx = idx[:-1]  # remove kept element from view\n        # load bboxes of next highest vals\n        torch.index_select(x1, 0, idx, out=xx1)\n        torch.index_select(y1, 0, idx, out=yy1)\n        torch.index_select(x2, 0, idx, out=xx2)\n        torch.index_select(y2, 0, idx, out=yy2)\n        # store element-wise max with next highest score\n        xx1 = torch.clamp(xx1, min=x1[i])\n        yy1 = torch.clamp(yy1, min=y1[i])\n        xx2 = torch.clamp(xx2, max=x2[i])\n        yy2 = torch.clamp(yy2, max=y2[i])\n        w.resize_as_(xx2)\n        h.resize_as_(yy2)\n        w = xx2 - xx1\n        h = yy2 - yy1\n        # check sizes of xx1 and xx2.. after each iteration\n        w = torch.clamp(w, min=0.0)\n        h = torch.clamp(h, min=0.0)\n        inter = w*h\n        # IoU = i \/ (area(a) + area(b) - i)\n        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n        union = (rem_areas - inter) + area[i]\n        IoU = inter\/union  # store result in iou\n        # keep only elements with an IoU <= overlap\n        idx = idx[IoU.le(overlap)]\n    return keep, count","d06d4d08":"x,y = next(iter(md.val_dl))\ny = V(y)\nbatch = learn.model(V(x))\nb_clas,b_bb = batch\nx = to_np(x)","efbea9ba":"def show_nmf(idx):\n    ima=md.val_ds.ds.denorm(x)[idx]\n    bbox,clas = get_y(y[0][idx], y[1][idx])\n    a_ic = actn_to_bb(b_bb[idx], anchors)\n    clas_pr, clas_ids = b_clas[idx].max(1)\n    clas_pr = clas_pr.sigmoid()\n\n    conf_scores = b_clas[idx].sigmoid().t().data\n\n    out1,out2,cc = [],[],[]\n    for cl in range(0, len(conf_scores)-1):\n        c_mask = conf_scores[cl] > 0.25\n        if c_mask.sum() == 0: continue\n        scores = conf_scores[cl][c_mask]\n        l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n        boxes = a_ic[l_mask].view(-1, 4)\n        ids, count = nms(boxes.data, scores, 0.4, 50)\n        ids = ids[:count]\n        out1.append(scores[ids])\n        out2.append(boxes.data[ids])\n        cc.append([cl]*count)\n    cc = T(np.concatenate(cc))\n    out1 = torch.cat(out1)\n    out2 = torch.cat(out2)\n\n    fig, ax = plt.subplots(figsize=(8,8))\n    torch_gt(ax, ima, out2, cc, out1, 0.1)","8faeedae":"for i in range(12): show_nmf(i)","0bf21925":"### Anchors\n\n## create Anchors","a1231054":"BBOX per cell","f5d67794":"**Model**","59aff179":"## Set Up model\n\n####","a16e14b1":"### Train","207e1307":"### Set up Data","1b1caa40":"### Testing","ab2abce1":"# NMS"}}