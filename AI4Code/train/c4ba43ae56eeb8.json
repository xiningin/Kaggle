{"cell_type":{"a479c8bd":"code","ae0e082f":"code","9d493350":"code","d33fe621":"code","03f83908":"code","8265079e":"code","5ed241b5":"code","79949285":"code","fb2dc180":"code","fa563d9c":"code","668c275f":"code","69aa6f3f":"code","3e0843ae":"code","77bb14ca":"code","46809b8a":"code","649ead09":"code","27dff2bd":"code","7ab96852":"code","d3865863":"code","a07137fd":"code","a4c9fb31":"code","fc91346b":"code","2c1186d5":"code","bfe897b1":"code","4b8234e8":"code","0fc3365e":"code","f46a28fb":"code","b6888148":"code","a5d618a6":"code","aa9df558":"code","6da871d4":"code","1d3c8a32":"code","dfba750c":"code","8b0b928d":"code","4f54365c":"code","06cfee2c":"code","770b8e47":"code","cc3cb1c1":"code","cbedc057":"code","e63b5cd9":"code","46cbf2e6":"markdown","38c11557":"markdown","fdf0b223":"markdown","11beabb4":"markdown","224810f9":"markdown","df6ac9c5":"markdown","0254711c":"markdown","ef3be9f1":"markdown","04e014cd":"markdown","ecd4931b":"markdown","6a6784b9":"markdown","c51ac7ff":"markdown","1e26998a":"markdown","3e0c1a5c":"markdown","ee782bac":"markdown","8b5e3441":"markdown","916bedd3":"markdown","90f1d05d":"markdown","308f7bc7":"markdown","5cc64928":"markdown","62c371dd":"markdown","fca92ea3":"markdown","338db5cd":"markdown","f4498ef4":"markdown","974d50c2":"markdown","1f823c9e":"markdown","2c8cde60":"markdown","e1b4ea72":"markdown","a6b9071d":"markdown","7a13a954":"markdown","eec2ff42":"markdown","6f8a8c29":"markdown","b8647c37":"markdown","0ccd42f8":"markdown","c791f395":"markdown","51355169":"markdown","cdda9925":"markdown","137a2c1b":"markdown","60ee716b":"markdown","cfc78e49":"markdown","d7be10d8":"markdown","8deff880":"markdown","0564d53f":"markdown","cf431ab8":"markdown","af2ef90a":"markdown","d5eeb193":"markdown","750dd3b5":"markdown","d0cc79ca":"markdown","ffc58a9e":"markdown","2e461778":"markdown","bb59215e":"markdown","b4db04db":"markdown","6ab0c45a":"markdown","da0c5fba":"markdown","f78d6caf":"markdown","d2a71c49":"markdown","8cefd024":"markdown","6c1c2c76":"markdown","94845aaa":"markdown","f99e4367":"markdown","19cbb000":"markdown","bb6d436d":"markdown","5993a20a":"markdown","4f478b41":"markdown","f7f329b7":"markdown","e54c3e69":"markdown","27fe6a3d":"markdown","fa35302e":"markdown","0576fa82":"markdown","f887e23e":"markdown","4030426e":"markdown","faff167b":"markdown","70eeffdb":"markdown","e9dec4ae":"markdown"},"source":{"a479c8bd":"import numpy as np\nimport pandas as pd\npd.set_option(\"display.precision\", 2)","ae0e082f":"df = pd.read_csv('..\/input\/telecom_churn.csv')\ndf.head()","9d493350":"print(df.shape)","d33fe621":"De la salida, podemos ver que la tabla contiene 3333 filas y 20 columnas.\n\nAhora vamos a intentar imprimir los nombres de las columnas utilizando columns.","03f83908":"print(df.columns)","8265079e":"print(df.info())","5ed241b5":"df['Churn'] = df['Churn'].astype('int64')","79949285":"df.describe()","fb2dc180":"df.describe(include=['object', 'bool'])","fa563d9c":"df['Churn'].value_counts()","668c275f":"df['Churn'].value_counts(normalize=True)","69aa6f3f":"df.sort_values(by='Total day charge', ascending=False).head()","3e0843ae":"df.sort_values(by=['Churn', 'Total day charge'],\n        ascending=[True, False]).head()","77bb14ca":"df['Churn'].mean()","46809b8a":"df[df['Churn'] == 1].mean()","649ead09":"df[df['Churn'] == 1]['Total day minutes'].mean()","27dff2bd":"df[(df['Churn'] == 0) & (df['International plan'] == 'No')]['Total intl minutes'].max()","7ab96852":"df.loc[0:5, 'State':'Area code']","d3865863":"df.iloc[0:5, 0:3]","a07137fd":"df[-1:]","a4c9fb31":"df.apply(np.max) ","fc91346b":"df[df['State'].apply(lambda state: state[0] == 'W')].head()","2c1186d5":"d = {'No' : False, 'Yes' : True}\ndf['International plan'] = df['International plan'].map(d)\ndf.head()","bfe897b1":"df = df.replace({'Voice mail plan': d})\ndf.head()","4b8234e8":"columns_to_show = ['Total day minutes', 'Total eve minutes', \n                   'Total night minutes']\n\ndf.groupby(['Churn'])[columns_to_show].describe(percentiles=[])","0fc3365e":"columns_to_show = ['Total day minutes', 'Total eve minutes', \n                   'Total night minutes']\n\ndf.groupby(['Churn'])[columns_to_show].agg([np.mean, np.std, np.min, \n                                            np.max])","f46a28fb":"pd.crosstab(df['Churn'], df['International plan'])","b6888148":"pd.crosstab(df['Churn'], df['Voice mail plan'], normalize=True)","a5d618a6":"df.pivot_table(['Total day calls', 'Total eve calls', 'Total night calls'],\n               ['Area code'], aggfunc='mean')","aa9df558":"total_calls = df['Total day calls'] + df['Total eve calls'] + \\\n              df['Total night calls'] + df['Total intl calls']\ndf.insert(loc=len(df.columns), column='Total calls', value=total_calls) \n# loc parameter is the number of columns after which to insert the Series object\n# we set it to len(df.columns) to paste it at the very end of the dataframe\ndf.head()","6da871d4":"df['Total charge'] = df['Total day charge'] + df['Total eve charge'] + \\\n                     df['Total night charge'] + df['Total intl charge']\ndf.head()","1d3c8a32":"# get rid of just created columns\ndf.drop(['Total charge', 'Total calls'], axis=1, inplace=True) \n# and here\u2019s how you can delete rows\ndf.drop([1, 2]).head() ","dfba750c":"pd.crosstab(df['Churn'], df['International plan'], margins=True)","8b0b928d":"# some imports to set up plotting \nimport matplotlib.pyplot as plt\n# pip install seaborn \nimport seaborn as sns\n# Graphics in retina format are more sharp and legible\n%config InlineBackend.figure_format = 'retina'","4f54365c":"sns.countplot(x='International plan', hue='Churn', data=df);","06cfee2c":"pd.crosstab(df['Churn'], df['Customer service calls'], margins=True)","770b8e47":"sns.countplot(x='Customer service calls', hue='Churn', data=df);","cc3cb1c1":"df['Many_service_calls'] = (df['Customer service calls'] > 3).astype('int')\n\npd.crosstab(df['Many_service_calls'], df['Churn'], margins=True)","cbedc057":"sns.countplot(x='Many_service_calls', hue='Churn', data=df);","e63b5cd9":"pd.crosstab(df['Many_service_calls'] & df['International plan'] , df['Churn'])","46cbf2e6":"We can also sort by multiple columns:","38c11557":"El m\u00e9todo de aplicaci\u00f3n tambi\u00e9n se puede utilizar para aplicar una funci\u00f3n a cada fila. Para hacer esto, especifique axis = 1. Las funciones Lambda son muy convenientes en tales escenarios. Por ejemplo, si necesitamos seleccionar todos los estados que comienzan con W, podemos hacerlo as\u00ed:","fdf0b223":"Un dataframe puede ser indexado de pocas diferentes maneras.\n\nPara conseguir una unica columna, puedes utilizar una construccion DataFrame[\"Name\"]. Vamos a usar esta respuesta a pregunta solo sobre esa columna. Que is la proporcion de usarios churned en nuestro dataframe?","11beabb4":"Echemos un vistazo en la dimensionalidad de los datos,  nombres de caracteristicas y tipos de caracteristicas.","224810f9":"Although it's not so obvious from the summary table, it's easy to see from the above plot that the churn rate increases sharply from 4 customer service calls and above.\n\nNow let's add a binary feature to our DataFrame \u2013 `Customer service calls > 3`. And once again, let's see how it relates to churn. ","df6ac9c5":"Vamos a hacer la misma cosa, pero ligeramente diferente mediante pasar una lista de funciones a agg()","0254711c":"2850 usarios de 3333 son leales, su valor \"Churn\" es 0. Para calcular la fraccion, pasa \"normalize=True\" para la funcion \"value_counts\"","ef3be9f1":"14.5% is actually quite bad for a company; such a churn rate can make the company go bankrupt.\n\n**Boolean indexing** with one column is also very convenient. The syntax is `df[P(df['Name'])]`, where `P` is some logical condition that is checked for each element of the `Name` column. The result of such indexing is the DataFrame consisting only of rows that satisfy the `P` condition on the `Name` column. \n\nLet's use it to answer the question:\n\n**What are average values of numerical features for churned users?**","04e014cd":"Para aplicar funciones en cada columna, utiliza apply():","ecd4931b":"For categorical (type `object`) and boolean (type `bool`) features we can use the `value_counts` method. Let's have a look at the distribution of `Churn`:","6a6784b9":"Por lo tanto, prediciendo que un cliente no es leal (Churn = 1) en el caso de que el n\u00famero de llamadas al centro de servicio sea mayor que 3 y se agregue el Plan Internacional (y prediciendo Churn = 0 en caso contrario), podr\u00edamos esperar una precisi\u00f3n del 85,8% (nos equivocamos solo 464 + 9 veces). Este n\u00famero, 85,8%, que obtuvimos a trav\u00e9s de este razonamiento muy simple, sirve como un buen punto de partida (l\u00ednea de base) para los modelos de aprendizaje autom\u00e1tico adicionales que construiremos.\n\nA medida que avanzamos en este curso, recuerde que, antes de la llegada del aprendizaje autom\u00e1tico, el proceso de an\u00e1lisis de datos se parec\u00eda a esto. Recapitulemos lo que hemos cubierto:\n\n* La proporci\u00f3n de clientes leales en la muestra es del 85,5%. El modelo m\u00e1s ingenuo que siempre predice un \"cliente leal\" en esos datos acertar\u00e1 en aproximadamente el 85,5% de todos los casos. Es decir, la proporci\u00f3n de respuestas correctas (precisi\u00f3n) de los modelos posteriores no deber\u00eda ser menor que este n\u00famero y, con suerte, ser\u00e1 significativamente mayor;\n* Con la ayuda de un pron\u00f3stico simple que se puede expresar con la siguiente f\u00f3rmula: \"Plan internacional = Verdadero y llamadas de servicio al cliente> 3 => Churn = 1, de lo contrario Churn = 0\", podemos esperar una tasa de adivinaci\u00f3n del 85,8%, que est\u00e1 apenas por encima del 85,5%. Posteriormente, hablaremos sobre los \u00e1rboles de decisi\u00f3n y descubriremos c\u00f3mo encontrar dichas reglas autom\u00e1ticamente bas\u00e1ndose solo en los datos de entrada;\n* Obtuvimos estas dos l\u00edneas de base sin aplicar el aprendizaje autom\u00e1tico y servir\u00e1n como punto de partida para nuestros modelos posteriores. Si resulta que con un esfuerzo enorme aumentamos la proporci\u00f3n de respuestas correctas en un 0.5% per se, entonces posiblemente estemos haciendo algo mal, y basta con limitarnos a un modelo simple con dos condiciones;\n* Antes de entrenar modelos complejos, se recomienda manipular un poco los datos, hacer algunos gr\u00e1ficos y verificar suposiciones simples. Adem\u00e1s, en las aplicaciones comerciales de aprendizaje autom\u00e1tico, generalmente comienzan con soluciones simples y luego experimentan con otras m\u00e1s complejas.","c51ac7ff":"Tambien podemos sortear por multiples columnas:","1e26998a":"\n1. First, the `groupby` method divides the `grouping_columns` by their values. They become a new index in the resulting dataframe.\n2. Then, columns of interest are selected (`columns_to_show`). If `columns_to_show` is not included, all non groupby clauses will be included.\n3. Finally, one or several functions are applied to the obtained groups per selected columns.\n\nHere is an example where we group the data according to the values of the `Churn` variable and display statistics of three columns in each group:","3e0c1a5c":"**How much time (on average) do churned users spend on the phone during daytime?**","ee782bac":"El metodo `describe` muestra caracteristicas estadisticas basicas para cada rasgo numerico(`int64` y `float64` tipos): numeros no perdidos valores, media, desv. estandard, rango, mediana, .025 y .75 quartiles.","8b5e3441":"## 2. First attempt at predicting telecom churn\n\n\nLet's see how churn rate is related to the *International plan* feature. We'll do this using a `crosstab` contingency table and also through visual analysis with `Seaborn` (however, visual analysis will be covered more thoroughly in the next article).\n","916bedd3":"1. Primero, el m\u00e9todo groupby divide las grouping_columns por sus valores. Se convierten en un nuevo \u00edndice en el marco de datos resultante.\n2. Luego, se seleccionan las columnas de inter\u00e9s (columnas_para_mostrar). Si no se incluye column_to_show, se incluir\u00e1n todas las cl\u00e1usulas que no sean groupby.\n3. Finalmente, se aplica una o varias funciones a los grupos obtenidos por columnas seleccionadas.\n\nAqu\u00ed hay un ejemplo en el que agrupamos los datos de acuerdo con los valores de la variable Churn y mostramos estad\u00edsticas de tres columnas en cada grupo:","90f1d05d":"En general, agrupamiento de datos en Pandas funciona de la siguiente manera:","308f7bc7":"## 1. Demonstration of main Pandas methods\nWell... There are dozens of cool tutorials on Pandas and visual data analysis. If you are already familiar with these topics, you can wait for the 3rd article in the series, where we get into machine learning.  \n\n**[Pandas](http:\/\/pandas.pydata.org)** is a Python library that provides extensive means for data analysis. Data scientists often work with data stored in table formats like `.csv`, `.tsv`, or `.xlsx`. Pandas makes it very convenient to load, process, and analyze such tabular data using SQL-like queries. In conjunction with `Matplotlib` and `Seaborn`, `Pandas` provides a wide range of opportunities for visual analysis of tabular data.\n\nThe main data structures in `Pandas` are implemented with **Series** and **DataFrame** classes. The former is a one-dimensional indexed array of some fixed data type. The latter is a two-dimensional data structure - a table - where each column contains data of the same type. You can see it as a dictionary of `Series` instances. `DataFrames` are great for representing real data: rows correspond to instances (examples, observations, etc.), and columns correspond to features of these instances.","5cc64928":"We'll demonstrate the main methods in action by analyzing a [dataset](https:\/\/bigml.com\/user\/francisco\/gallery\/dataset\/5163ad540c0b5e5b22000383) on the churn rate of telecom operator clients. Let's read the data (using `read_csv`), and take a look at the first 5 lines using the `head` method:","62c371dd":"\n**What is the maximum length of international calls among loyal users (`Churn == 0`) who do not have an international plan?**\n\n","fca92ea3":"Como muchas otras cosas en Pandas, agregar columnas a un DataFrame es factible de muchas maneras.\n\nPor ejemplo, si queremos calcular el n\u00famero total de llamadas para todos los usuarios, creemos la serie total_calls y p\u00e9guela en el DataFrame:","338db5cd":"We can see that most of the users are loyal and do not use additional services (International Plan\/Voice mail).\n\nThis will resemble **pivot tables** to those familiar with Excel. And, of course, pivot tables are implemented in Pandas: the `pivot_table` method takes the following parameters:\n\n* `values` \u2013 a list of variables to calculate statistics for,\n* `index` \u2013 a list of variables to group data by,\n* `aggfunc` \u2013 what statistics we need to calculate for groups, ex. sum, mean, maximum, minimum or something else.\n\nLet's take a look at the average number of day, evening, and night calls by area code:","f4498ef4":"El 14,5% es bastante malo para una empresa; tal tasa de abandono puede llevar a la empresa a la quiebra.\n\nLa indexaci\u00f3n booleana con una columna tambi\u00e9n es muy conveniente. La sintaxis es df [P (df ['Nombre'])], donde P es alguna condici\u00f3n l\u00f3gica que se comprueba para cada elemento de la columna Nombre. El resultado de dicha indexaci\u00f3n es el DataFrame que consta solo de filas que satisfacen la condici\u00f3n P en la columna Nombre.\n\nUs\u00e9moslo para responder la pregunta:\n\n\u00bfCu\u00e1les son los valores medios de las caracter\u00edsticas num\u00e9ricas para los usuarios que han cambiado?","974d50c2":"Podemos utilizar el metodo info() para generar informacion acerca del dataframe en la salida","1f823c9e":"Los DataFrames se pueden indexar por nombre de columna (etiqueta) o nombre de fila (\u00edndice) o por el n\u00famero de serie de una fila. El m\u00e9todo loc se usa para indexar por nombre, mientras que iloc () se usa para indexar por n\u00famero.\n\nEn el primer caso a continuaci\u00f3n, decimos * \"danos los valores de las filas con \u00edndice de 0 a 5 (inclusive) y las columnas etiquetadas de estado a c\u00f3digo de \u00e1rea (inclusive)\". En el segundo caso, decimos * \"danos los valores de las primeras cinco filas en las primeras tres columnas\" (como en un segmento t\u00edpico de Python: el valor m\u00e1ximo no est\u00e1 incluido).","2c8cde60":"<center>\n<img src=\"https:\/\/habrastorage.org\/webt\/ia\/m9\/zk\/iam9zkyzqebnf_okxipihkgjwnw.jpeg\">\n    \n## [mlcourse.ai](https:\/\/mlcourse.ai) \u2013 Open Machine Learning Course \n\nAuthor: [Yury Kashnitsky](https:\/\/yorko.github.io). Translated and edited by [Christina Butsko](https:\/\/www.linkedin.com\/in\/christinabutsko\/), [Yuanyuan Pao](https:\/\/www.linkedin.com\/in\/yuanyuanpao\/), [Anastasia Manokhina](https:\/\/www.linkedin.com\/in\/anastasiamanokhina), Sergey Isaev and [Artem Trunov](https:\/\/www.linkedin.com\/in\/datamove\/). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https:\/\/creativecommons.org\/licenses\/by-nc-sa\/4.0\/) license. Free use is permitted for any non-commercial purpose.\n\n*You can also check out the latest version of this notebook in the [course repository](https:\/\/github.com\/Yorko\/mlcourse.ai), and a [video lecture](https:\/\/youtu.be\/fwWCw_cE5aI).*","e1b4ea72":"Vamos a demostrar los metodos principales en accion para analizar un dataset en el chne rate de clientes operadores telecom. Vamos a leer los datos (usando read_csv), y tomar una mirada a las primeras 5 lineas usando el metodo head.","a6b9071d":"Acerca de imprimir DataFrames en las libretas de Jupyter.\nRecuerda que cada fila corresponde a un cliente, un instante, y las columnas son caracteristicas de este instante.\n","7a13a954":"In order to see statistics on non-numerical features, one has to explicitly indicate data types of interest in the `include` parameter.","eec2ff42":"The `map` method can be used to **replace values in a column** by passing a dictionary of the form `{old_value: new_value}` as its argument:","6f8a8c29":"\n### Applying Functions to Cells, Columns and Rows\n\n**To apply functions to each column, use `apply()`:**\n","b8647c37":"If we need the first or the last line of the data frame, we can use the `df[:1]` or `df[-1:]` construct:","0ccd42f8":"The same thing can be done with the `replace` method:","c791f395":"Bien... Hay docenas de tutoriales en Pandas y visualizacion de analisis de datos. si ya eres familiar con estos temas, puedes esperar por el tercer articulo en la serie, donde abarcamos aprendizaje automatico.\n\nPandas is una libreria de Python que provee significados extensivos de analisis de datos. Cientificos de datos seguidamente trabajan con datos guardados en un formato de tabla como .csv, .tsv, o .xlsx. Pandas hace muy conveniente cargar, procesos y analizar datos en tablas utilizando como SQL consultas. En conjunto con Matplotlib y Seabron, Pandas provee una aplia gama de oportunidades para visualizar datos en tablas.\n\nLas principales estructuras de datos en Pandas se implementan con clases Series y DataFrame. El primero es una matriz indexada unidimensional de alg\u00fan tipo de datos fijo. Este \u00faltimo es una estructura de datos bidimensional, una tabla, donde cada columna contiene datos del mismo tipo. Puede verlo como un diccionario de instancias de Series. Los DataFrames son excelentes para representar datos reales: las filas corresponden a instancias (ejemplos, observaciones, etc.) y las columnas corresponden a caracter\u00edsticas de estas instancias.\n","51355169":"Para eliminar columnas o filas, use el m\u00e9todo de colocaci\u00f3n, pasando los \u00edndices requeridos y el par\u00e1metro del eje (1 si elimina columnas y nada o 0 si elimina filas). El argumento en el lugar indica si se debe cambiar el DataFrame original. Con inplace = False, el m\u00e9todo drop no cambia el DataFrame existente y devuelve uno nuevo con filas o columnas eliminadas. Con inplace = True, altera el DataFrame.","cdda9925":"En orden para ver las estadisticas en rasgos no numericos, uno tiene que indicar explicitamente los tipos de datos de interes en el parametro \"include\".","137a2c1b":"`bool`, `int64`, `float64` y `object` son tipos de datos de nuestras caracteriticas. Vemos que una caracteristica es logica (`bool`), 3 son de tipo`object`, y 16 son numericas. Con este mismo metodo, podemo ver facilmente si hay valores faltantes. Aqui, no hay ninguno porque cada columna contiene 3333 observaciones. el mismo numero de filas vimos antes con`shape`.\n\nPodemos cambiar el tipo de columna con el metodo `astype`. Vamos aplicaro a la caracteristica `Churn` para covnertirla en `int64`:","60ee716b":"> \n```python\ndf.groupby(by=grouping_columns)[columns_to_show].function()\n```","cfc78e49":"It is possible to add a column more easily without creating an intermediate Series instance:","d7be10d8":"Aunque no es tan obvio en la tabla de resumen, es f\u00e1cil ver en el gr\u00e1fico anterior que la tasa de abandono aumenta considerablemente a partir de 4 llamadas de servicio al cliente o m\u00e1s.\n\nAhora agreguemos una funci\u00f3n binaria a nuestro DataFrame - Llamadas de servicio al cliente> 3. Y una vez m\u00e1s, veamos c\u00f3mo se relaciona con el abandono.","8deff880":"\u00bfCuanto tiempo en promedio los usuarios de churned gastan en el telefono durante el dia?","0564d53f":"La misma cosa pueder ser hecha con el metodo replace:","cf431ab8":"2850 users out of 3333 are *loyal*; their `Churn` value is `0`. To calculate fractions, pass `normalize=True` to the `value_counts` function.","af2ef90a":"\nLet's construct another contingency table that relates *Churn* with both *International plan* and freshly created *Many_service_calls*.\n\n","d5eeb193":"We can use the `info()` method to output some general information about the dataframe: ","750dd3b5":"\n### Sorting\n\nA DataFrame can be sorted by the value of one of the variables (i.e columns). For example, we can sort by *Total day charge* (use `ascending=False` to sort in descending order):\n","d0cc79ca":"Un Dataframe puede ser sorteado por el valor de una de las variables (i.e colums). Por ejemplo, podemos sortear por Total Day charge (use \"ascending=False\" para sortear en orden decendiente):","ffc58a9e":"To delete columns or rows, use the `drop` method, passing the required indexes and the `axis` parameter (`1` if you delete columns, and nothing or `0` if you delete rows). The `inplace` argument tells whether to change the original DataFrame. With `inplace=False`, the `drop` method doesn't change the existing DataFrame and returns a new one with dropped rows or columns. With `inplace=True`, it alters the DataFrame.","2e461778":"\n### Grouping\n\nIn general, grouping data in Pandas works as follows:\n","bb59215e":"Cual es la longitud maxima de llamadas internacionales entre usarios leales (churn ==0). Quien no tiene un plan internacional?","b4db04db":"The `apply` method can also be used to apply a function to each row. To do this, specify `axis=1`. Lambda functions are very convenient in such scenarios. For example, if we need to select all states starting with W, we can do it like this:","6ab0c45a":"Construyamos otra tabla de contingencia que relacione el Churn con el plan internacional y con Many_service_calls reci\u00e9n creadas.","da0c5fba":"\n### Summary tables\n\nSuppose we want to see how the observations in our sample are distributed in the context of two variables - `Churn` and `International plan`. To do so, we can build a **contingency table** using the `crosstab` method:\n\n","f78d6caf":"`bool`, `int64`, `float64` and `object` are the data types of our features. We see that one feature is logical (`bool`), 3 features are of type `object`, and 16 features are numeric. With this same method, we can easily see if there are any missing values. Here, there are none because each column contains 3333 observations, the same number of rows we saw before with `shape`.\n\nWe can **change the column type** with the `astype` method. Let's apply this method to the `Churn` feature to convert it into `int64`:","d2a71c49":"### Indexing and retrieving data\n\nA DataFrame can be indexed in a few different ways. \n\nTo get a single column, you can use a `DataFrame['Name']` construction. Let's use this to answer a question about that column alone: **what is the proportion of churned users in our dataframe?**","8cefd024":"Let\u2019s have a look at data dimensionality, feature names, and feature types.","6c1c2c76":"\nWe see that, with *International Plan*, the churn rate is much higher, which is an interesting observation! Perhaps large and poorly controlled expenses with international calls are very conflict-prone and lead to dissatisfaction among the telecom operator's customers.\n\nNext, let's look at another important feature \u2013 *Customer service calls*. Let's also make a summary table and a picture.","94845aaa":"<details>\n<summary>About printing DataFrames in Jupyter notebooks<\/summary>\n<p>\nIn Jupyter notebooks, Pandas DataFrames are printed as these pretty tables seen above while `print(df.head())` is less nicely formatted.\nBy default, Pandas displays 20 columns and 60 rows, so, if your DataFrame is bigger, use the `set_option` function as shown in the example below:\n\n```python\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\n```\n<\/p>\n<\/details>\n\nRecall that each row corresponds to one client, an **instance**, and columns are **features** of this instance.","f99e4367":"Para el tipo de categoria \"object\" y \"bool\", podemos usar el metodo \"vale_counts\". Vamos a echar un vistazo a la distribucion de Churn:","19cbb000":"Let\u2019s do the same thing, but slightly differently by passing a list of functions to `agg()`:","bb6d436d":"Vemos que, con International Plan, la tasa de abandono es mucho mayor, \u00a1lo cual es una observaci\u00f3n interesante! Quiz\u00e1s los gastos grandes y mal controlados con las llamadas internacionales son muy propensos a conflictos y generan insatisfacci\u00f3n entre los clientes del operador de telecomunicaciones.\n\nA continuaci\u00f3n, veamos otra caracter\u00edstica importante: las llamadas de servicio al cliente. Hagamos tambi\u00e9n una tabla resumen y una imagen.","5993a20a":"DataFrames can be indexed by column name (label) or row name (index) or by the serial number of a row. The `loc` method is used for **indexing by name**, while `iloc()` is used for **indexing by number**.\n\nIn the first case below, we say *\"give us the values of the rows with index from 0 to 5 (inclusive) and columns labeled from State to Area code (inclusive)\"*. In the second case, we say *\"give us the values of the first five rows in the first three columns\"* (as in a typical Python slice: the maximal value is not included).","4f478b41":"Therefore, predicting that a customer is not loyal (*Churn*=1) in the case when the number of calls to the service center is greater than 3 and the *International Plan* is added (and predicting *Churn*=0 otherwise), we might expect an accuracy of 85.8% (we are mistaken only 464 + 9 times). This number, 85.8%, that we got through this very simple reasoning serves as a good starting point (*baseline*) for the further machine learning models that we will build. \n\nAs we move on in this course, recall that, before the advent of machine learning, the data analysis process looked something like this. Let's recap what we've covered:\n    \n- The share of loyal clients in the sample is 85.5%. The most naive model that always predicts a \"loyal customer\" on such data will guess right in about 85.5% of all cases. That is, the proportion of correct answers (*accuracy*) of subsequent models should be no less than this number, and will hopefully be significantly higher;\n- With the help of a simple forecast that can be expressed by the following formula: \"International plan = True & Customer Service calls > 3 => Churn = 1, else Churn = 0\", we can expect a guessing rate of 85.8%, which is just above 85.5%. Subsequently, we'll talk about decision trees and figure out how to find such rules **automatically** based only on the input data;\n- We got these two baselines without applying machine learning, and they'll serve as the starting point for our subsequent models. If it turns out that with enormous effort, we increase the share of correct answers by 0.5% per se, then possibly we are doing something wrong, and it suffices to confine ourselves to a simple model with two conditions;\n- Before training complex models, it is recommended to manipulate the data a bit, make some plots, and check simple assumptions. Moreover, in business applications of machine learning, they usually start with simple solutions and then experiment with more complex ones.\n\n## 3. Demo assignment\nTo practice with Pandas and EDA, you can complete [this assignment](https:\/\/www.kaggle.com\/kashnitsky\/a1-demo-pandas-and-uci-adult-dataset) where you'll be analyzing socio-demographic data. The assignment is just for you to practice, and goes with [solution](https:\/\/www.kaggle.com\/kashnitsky\/a1-demo-pandas-and-uci-adult-dataset-solution).\n\n## 4. Useful resources\n\n* The same notebook as an interactive web-based [Kaggle Kernel](https:\/\/www.kaggle.com\/kashnitsky\/topic-1-exploratory-data-analysis-with-pandas)\n* [\"Merging DataFrames with pandas\"](https:\/\/nbviewer.jupyter.org\/github\/Yorko\/mlcourse.ai\/blob\/master\/jupyter_english\/tutorials\/merging_dataframes_tutorial_max_palko.ipynb) - a tutorial by Max Plako within mlcourse.ai (full list of tutorials is [here](https:\/\/mlcourse.ai\/tutorials))\n* [\"Handle different dataset with dask and trying a little dask ML\"](https:\/\/nbviewer.jupyter.org\/github\/Yorko\/mlcourse.ai\/blob\/master\/jupyter_english\/tutorials\/dask_objects_and_little_dask_ml_tutorial_iknyazeva.ipynb) - a tutorial by Irina Knyazeva within mlcourse.ai\n* Main course [site](https:\/\/mlcourse.ai), [course repo](https:\/\/github.com\/Yorko\/mlcourse.ai), and YouTube [channel](https:\/\/www.youtube.com\/watch?v=QKTuw4PNOsU&list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX)\n* Official Pandas [documentation](http:\/\/pandas.pydata.org\/pandas-docs\/stable\/index.html)\n* Course materials as a [Kaggle Dataset](https:\/\/www.kaggle.com\/kashnitsky\/mlcourse)\n* Medium [\"story\"](https:\/\/medium.com\/open-machine-learning-course\/open-machine-learning-course-topic-1-exploratory-data-analysis-with-pandas-de57880f1a68) based on this notebook\n* If you read Russian: an [article](https:\/\/habrahabr.ru\/company\/ods\/blog\/322626\/) on Habr.com with ~ the same material. And a [lecture](https:\/\/youtu.be\/dEFxoyJhm3Y) on YouTube\n* [10 minutes to pandas](http:\/\/pandas.pydata.org\/pandas-docs\/stable\/10min.html)\n* [Pandas cheatsheet PDF](https:\/\/github.com\/pandas-dev\/pandas\/blob\/master\/doc\/cheatsheet\/Pandas_Cheat_Sheet.pdf)\n* GitHub repos: [Pandas exercises](https:\/\/github.com\/guipsamora\/pandas_exercises\/) and [\"Effective Pandas\"](https:\/\/github.com\/TomAugspurger\/effective-pandas)\n* [scipy-lectures.org](http:\/\/www.scipy-lectures.org\/index.html) \u2014 tutorials on pandas, numpy, matplotlib and scikit-learn\n\n## Support course creators\n<br>\n<center>\nYou can make a monthly (Patreon) or one-time (Ko-Fi) donation \u2193\n\n<br>\n<br>\n\n<a href=\"https:\/\/www.patreon.com\/ods_mlcourse\">\n<img src=\"https:\/\/habrastorage.org\/webt\/zc\/11\/0y\/zc110yh0u3kgnlmay1gwbekk0ys.png\" width=20% \/>\n\n<br>\n\n<a href=\"https:\/\/ko-fi.com\/mlcourse_ai\">\n<img src=\"https:\/\/habrastorage.org\/webt\/8r\/ml\/xf\/8rmlxfpdzukegpxa62cxlfvgkqe.png\" width=20% \/>\n    \n<\/center>","f7f329b7":"Veamos c\u00f3mo se relaciona la tasa de abandono con la funci\u00f3n del plan internacional. Haremos esto usando una tabla de contingencia de tabla cruzada y tambi\u00e9n a trav\u00e9s del an\u00e1lisis visual con Seaborn (sin embargo, el an\u00e1lisis visual se cubrir\u00e1 m\u00e1s a fondo en el pr\u00f3ximo art\u00edculo).","e54c3e69":"From the output, we can see that the table contains 3333 rows and 20 columns.\n\nNow let's try printing out column names using `columns`:","27fe6a3d":"Podemos ver que la mayor\u00eda de los usuarios son leales y no utilizan servicios adicionales (Plan Internacional \/ Buz\u00f3n de voz).\n\nEsto se parecer\u00e1 a las tablas din\u00e1micas a las que est\u00e1n familiarizadas con Excel. Y, por supuesto, las tablas din\u00e1micas se implementan en Pandas: el m\u00e9todo pivot_table toma los siguientes par\u00e1metros:\n\n* Values - una lista de variables calculadas estadisticamente para,\n* index - una lista de variables para grupos de datos por,\n* aggfunc - que estadisticas necesitamos para calculgar para grupos, ex. sumas, medias, maximos, minimos o otra cosa.\n\nEchemos un vistazo al promedio de numeros de llamadas por dia, tarde y noche por codigo de areas:","fa35302e":"El metodo map puede ser usado para reemplazar valores en una columna mediante pasar un diccionario de la forma {old_value: new_value} como un argumento:","0576fa82":"The `describe` method shows basic statistical characteristics of each numerical feature (`int64` and `float64` types): number of non-missing values, mean, standard deviation, range, median, 0.25 and 0.75 quartiles.","f887e23e":"# <center> Topic 1. Exploratory data analysis with Pandas\n\n<img align=\"center\" src=\"https:\/\/habrastorage.org\/files\/10c\/15f\/f3d\/10c15ff3dcb14abdbabdac53fed6d825.jpg\"  width=50% \/>\n\n## Article outline\n1. [Demonstration of main Pandas methods](#1.-Demonstration-of-main-Pandas-methods)\n2. [First attempt at predicting telecom churn](#2.-First-attempt-at-predicting-telecom-churn)\n3. [Demo assignment](#3.-Demo-assignment)\n4. [Useful resources](#4-Useful-resources)","4030426e":"Es posible agregar una columna mas facilmente sin crear una serie intermediaria:","faff167b":"Si necesitamos la primera o ultima linea del marco de datos, podemos utilizar la construct df[:1] or df[-1:]","70eeffdb":"Suponga que queremos ver c\u00f3mo se distribuyen las observaciones de nuestra muestra en el contexto de dos variables: Churn y Plan internacional. Para hacerlo, podemos construir una tabla de contingencia usando el m\u00e9todo de tabla cruzada:","e9dec4ae":"\n### DataFrame transformations\n\nLike many other things in Pandas, adding columns to a DataFrame is doable in many ways.\n\nFor example, if we want to calculate the total number of calls for all users, let's create the `total_calls` Series and paste it into the DataFrame:\n\n"}}