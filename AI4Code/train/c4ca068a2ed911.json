{"cell_type":{"8437ebd3":"code","68cbe394":"code","06d00b21":"code","08ac25bf":"code","c2ff35b5":"code","ada29d07":"code","cbce9d38":"code","3a170593":"code","f1f0e965":"code","6dd7bba4":"code","1a075a67":"code","f465ec4f":"code","3274a366":"code","8fe289ec":"markdown","462cee57":"markdown","84772b09":"markdown","8505cf9c":"markdown","09272ebe":"markdown","4db67426":"markdown"},"source":{"8437ebd3":"import os\nimport numpy as np\nfrom glob import glob\nimport numpy as np\n#import keras\nfrom keras.utils import np_utils\nfrom sklearn.datasets import load_files\nfrom glob import glob\ndef load_dataset(path):\n    data = load_files(path)\n    fruit_files = np.array(data['filenames'])\n    fruit_targets = np_utils.to_categorical(np.array(data['target']),81)\n    return fruit_files,fruit_targets\n\nfiles,targets = load_dataset(\"..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Training\/\")\ntrain_files,train_targets = files[:30269],targets[:30269]\n#os.listdir(\"..\/input\/fruits-360_dataset\/fruits-360\/Training\")\nvalid_files,valid_targets = files[30269:],targets[30269:]\ntest_files, test_targets = load_dataset('..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Test\/')\nfruit_categories = [item[55:] for item in sorted(glob(\"..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Training\/*\"))]\nprint('There are %d total fruit categories.' % len(fruit_categories))\nprint('There are %s total fruit images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\nprint('There are %d training fruit images.' % len(train_files))\nprint('There are %d validation dog images.' % len(valid_files))\nprint('There are %d test fruit images.'% len(test_files))\n#print('There are %d multiple test fruit images.'% len(multiple_test_files))\n\n","68cbe394":"import cv2\nimport matplotlib.pyplot as plt                        \n%matplotlib inline    \ncount = 0\nfor i in train_files:\n    print(i[83:90])\n    img = cv2.imread(i)\n    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(cv_rgb)\n    plt.show()\n    count += 1\n    if count == 5:\n        break","06d00b21":"from keras.preprocessing import image\nfrom tqdm import tqdm\n\ndef path_to_tensor(img_path):\n    img = image.load_img(img_path, target_size=(100,100))\n    x = image.img_to_array(img)\n    return np.expand_dims(x,axis=0)\n\ndef paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)","08ac25bf":"import keras\nfrom keras.applications.xception import Xception, preprocess_input\ntrain_data = preprocess_input(paths_to_tensor(train_files))\nvalid_data = preprocess_input(paths_to_tensor(valid_files))\ntest_data = preprocess_input(paths_to_tensor(test_files))\n#multiple_test_data = preprocess_input(paths_to_tensor(multiple_test_files))\nweights = \"..\/input\/xception\/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nmodel_xception = keras.applications.xception.Xception(include_top=False, weights=weights)","c2ff35b5":"np.savez(\"FruitFeaturesXception.npz\",train=model_xception.predict(train_data),valid=model_xception.predict(valid_data),\\\n         test=model_xception.predict(test_data))","ada29d07":"import numpy as np\nbottleneck_features = np.load(\"FruitFeaturesXception.npz\")\ntrain_xception = bottleneck_features['train']\nvalid_xception = bottleneck_features['valid']\ntest_xception = bottleneck_features['test']\n","cbce9d38":"from keras.callbacks import ModelCheckpoint  \nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\nmy_model = Sequential()\nmy_model.add(GlobalAveragePooling2D(input_shape=train_xception.shape[1:]))\nmy_model.add(Dense(1032, activation='relu'))\nmy_model.add(Dropout(0.2))\nmy_model.add(Dense(512, activation='relu'))\nmy_model.add(Dropout(0.2))\nmy_model.add(Dense(256, activation='relu'))\nmy_model.add(Dropout(0.2))\nmy_model.add(Dense(81, activation='softmax'))\n\nmy_model.summary()","3a170593":"my_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","f1f0e965":"from keras.callbacks import ModelCheckpoint  \n\n### TODO: specify the number of epochs that you would like to use to train the model.\n\nepochs = 50\n\n### Do NOT modify the code below this line.\n\ncheckpointer = ModelCheckpoint(filepath='weights.best.xception.hdf5', \n                               verbose=1, save_best_only=True)\n\n","6dd7bba4":"my_model.fit(train_xception, train_targets, \n          validation_data=(valid_xception, valid_targets),\n          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)","1a075a67":"my_model.load_weights('weights.best.xception.hdf5')","f465ec4f":"predictions = [np.argmax(my_model.predict(np.expand_dims(feature, axis=0))) for feature in test_xception]\n\n# report test accuracy\ntest_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))\/len(predictions)\nprint('Test accuracy for xception: %.4f%%' % test_accuracy)","3274a366":"\nfruit_names = [fruit_categories[i] for i in predictions]\ncounter = 0\nfor i,j,k in zip(test_files,predictions,np.argmax(test_targets,axis=1)):\n    img = cv2.imread(i)\n    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(cv_rgb)\n    plt.show()\n    print(\"Actual category:\",fruit_categories[k])\n    print(\"Predicted:\",fruit_categories[j])\n    counter += 1\n    if counter == 25:\n        break\n    ","8fe289ec":"**Preprocessing the data **","462cee57":"**Loading the data sets**","84772b09":"**Preparing the data and building the model**","8505cf9c":"**Transfer Learning using Xception**","09272ebe":"**Saving the features**","4db67426":"**Visualizing the images**"}}