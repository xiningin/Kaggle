{"cell_type":{"3839ac3e":"code","b7088130":"code","a8b0c733":"code","2dfdfad1":"code","8db3d379":"code","b0b18967":"code","203605c4":"code","97741554":"code","a4136359":"code","1e62a890":"code","d9d3c21f":"code","bab8a01d":"code","c4764325":"code","337b92d0":"code","d33d89fa":"code","39667362":"code","bad05209":"code","2347e797":"code","52dea830":"markdown","29504dc9":"markdown"},"source":{"3839ac3e":"!pip install pytorch-tabnet","b7088130":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\n\nimport optuna\n\nimport torch\nfrom pytorch_tabnet.tab_model import TabNetClassifier\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\n\nimport os","a8b0c733":"BASE_DIR = '\/kaggle\/input\/tabular-playground-series-mar-2021'\n\nFILE_TRAIN = BASE_DIR + '\/train.csv'\nFILE_TEST = BASE_DIR + '\/test.csv'","2dfdfad1":"orig_data = pd.read_csv(FILE_TRAIN)","8db3d379":"orig_data.head()","b0b18967":"# GLOBALS\nFOLDS = 5\nPREDICTOR = 'target'\n\n# feature not used\nunused_feat = ['id']","203605c4":"# before any transformation, make a copy\ndata = orig_data.copy()","97741554":"# columns that will be used\nnum_col_list = [ 'cont0', 'cont1', 'cont2', 'cont3', 'cont4',\n                'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10']\n\ncat_col_list = ['cat0', 'cat1', 'cat2','cat3','cat4','cat5','cat6',\n                'cat7','cat8', 'cat9', 'cat10',\n                'cat11', 'cat12','cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18']\n\nall_col_list = num_col_list + cat_col_list","a4136359":"# encode cat features (with label encoder)\nnunique = data.nunique()\ntypes = data.dtypes\n\ncategorical_columns = cat_col_list\ncategorical_dims =  {}\n\n# I need to save the encoder list for the processing of the test set\nenc_list = []\n \nfor col in cat_col_list:\n    print(col, data[col].nunique())\n    l_enc = LabelEncoder()\n    data[col] = l_enc.fit_transform(data[col].values)\n    \n    # save the encoder for the test set\n    enc_list.append(l_enc)\n    categorical_dims[col] = len(l_enc.classes_)","1e62a890":"# split data in train, validation\nFRAC = 0.8\n\nN_TRAIN = int(data.shape[0] * FRAC)\nN_VALID = data.shape[0] - N_TRAIN\n\n# before splitting, shuffle\ndata = data.sample(frac = 1)\n\ndf_train = data[:N_TRAIN]\ndf_valid = data[N_TRAIN:]\n\nprint('Number of records in train dataset:', N_TRAIN)\nprint('Number of records in validation dataset:', N_VALID)","d9d3c21f":"label_train = df_train[PREDICTOR].values\nlabel_valid = df_valid[PREDICTOR].values\n\ndf_train = df_train[all_col_list]\ndf_valid = df_valid[all_col_list]","bab8a01d":"features = [ col for col in df_train.columns if col not in unused_feat+[PREDICTOR]] \n\ncat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n\ncat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]","c4764325":"df_train.head()","337b92d0":"# fit parameters\nEPOCHS = 30\nBATCH_SIZE = 4096","d33d89fa":"def objective(trial):\n    # parameter set by optuna\n    N_D = trial.suggest_int('N_D', 8, 32)\n    N_A = N_D\n    GAMMA = trial.suggest_float('GAMMA', 1.0, 2.0)\n    N_STEPS = trial.suggest_int('N_STEPS', 1, 3, 1)\n    LAMBDA_SPARSE = trial.suggest_loguniform(\"LAMBDA_SPARSE\", 1e-5, 1e-1)\n    \n    # changes\n    # introduced lambda-sparse\n    clf = TabNetClassifier(cat_idxs=cat_idxs,\n                       cat_dims=cat_dims,\n                       cat_emb_dim=1,\n                       optimizer_fn=torch.optim.Adam,\n                       optimizer_params=dict(lr=2e-2),\n                       scheduler_params={\"step_size\":4, # how to use learning rate scheduler\n                                         \"gamma\":0.9},\n                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n                       mask_type='sparsemax',\n                          n_d = N_D,\n                          n_a = N_A,\n                          gamma = GAMMA,\n                          n_steps = N_STEPS,\n                          lambda_sparse = LAMBDA_SPARSE)\n    \n    clf.fit(df_train.values, label_train,\n        eval_set=[(df_train.values, label_train),(df_valid.values, label_valid)],\n        max_epochs = EPOCHS,\n        batch_size = BATCH_SIZE,\n        patience = 5,\n        eval_name=['train', 'valid'],\n        eval_metric=['auc']\n           )\n    \n    # changed, now score is max val_uac\n    score = np.max(clf.history['valid_auc'])\n    \n    return score","39667362":"study = optuna.create_study(direction='maximize', study_name = 'tabnet-study1')\n\nstudy.optimize(objective, n_trials=100, timeout = 3600*8)\n \nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","bad05209":"from optuna.visualization import plot_optimization_history\n\nplot_optimization_history(study)","2347e797":"from optuna.visualization import plot_param_importances\n\nplot_param_importances(study)","52dea830":"### In this Notebook I'm going to use PyTorch TabNet","29504dc9":"### Predictions on test Set"}}