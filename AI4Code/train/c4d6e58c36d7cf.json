{"cell_type":{"c8a40647":"code","fe2a938e":"code","e02e5869":"code","74cdf7c8":"code","961f75a4":"code","4c74c7d0":"code","b00a8a8e":"code","25306095":"code","f1de3be3":"code","69602688":"code","70d6e715":"code","e5374cb6":"code","6c467255":"code","20029369":"code","3a4e5091":"code","02ee5f0b":"code","08f71330":"code","c1887a4f":"code","cd4c18e1":"code","a0b589c5":"code","4a918f12":"code","5e684663":"code","f19ccabc":"code","70e88e0a":"code","245f9697":"code","a6c96951":"code","10e4b026":"code","823cfd09":"code","8c0ceeb7":"code","75d194aa":"code","15e2b380":"code","4aa01117":"code","d32b6c79":"markdown","40e7a6fd":"markdown","bc361b7e":"markdown","187c5efc":"markdown","af75d941":"markdown","a1152e7e":"markdown"},"source":{"c8a40647":"import numpy as np\nimport pandas as pd\nimport os\nimport shutil\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom PIL import ImageFilter\nfrom sklearn.preprocessing import LabelEncoder\nimport timeit\nimport cv2 as cv\nimport argparse\n\n#Neural Network packages\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset\nfrom torchvision import models\nfrom torch.autograd import Variable","fe2a938e":"# checking working directory\nos.getcwd()","e02e5869":"# Device selection(GPU or CPU)\ndevice= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device, torch.cuda.get_device_name(0))","74cdf7c8":"#Check the size of input images\nim=Image.open('..\/input\/intel-image-classification\/seg_train\/seg_train\/buildings\/1001.jpg')\nwidth, height= im.size\nprint(width,height)","961f75a4":"# set tranformations for images\ntransform = transforms.Compose([transforms.Resize(256),\n                                transforms.RandomHorizontalFlip(),\n                                transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0,0,0], \n                                                    [1,1,1])])\n\n","4c74c7d0":"# Custom Dataset Class\nclass INTELDataset(Dataset):\n    def __init__(self, img_data,img_path,transform=None):\n        self.img_path = img_path\n        self.transform = transform\n        self.img_data = img_data\n        \n   \n    \n    def __getitem__(self, index):\n        img_name = os.path.join(self.img_path,self.img_data.loc[index, 'labels'],\n                                self.img_data.loc[index, 'Images'])\n        image = Image.open(img_name)\n        image = image.convert('RGB')\n        #image = image.resize((300,300))\n        label = torch.tensor(self.img_data.loc[index, 'encoded_labels'])\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label\n\n    \n    \n    def __len__(self):\n        return len(self.img_data)\n         ","b00a8a8e":"base_path_train='..\/input\/intel-image-classification\/seg_train'","25306095":"images_train=[]\nlabels_train=[]\n\n\nfor file in os.listdir(os.path.join(base_path_train,'seg_train')):\n  if file=='buildings':\n    for img in os.listdir(os.path.join(base_path_train,'seg_train', file)):\n      images_train.append(img)\n      labels_train.append('buildings')\n  if file=='forest':\n    for img in os.listdir(os.path.join(base_path_train,'seg_train', file)):\n      images_train.append(img)\n      labels_train.append('forest')      \n  if file=='glacier':\n    for img in os.listdir(os.path.join(base_path_train,'seg_train', file)):\n      images_train.append(img)\n      labels_train.append('glacier')\n  if file=='mountain':\n    for img in os.listdir(os.path.join(base_path_train,'seg_train', file)):\n      images_train.append(img)\n      labels_train.append('mountain')  \n  if file=='sea':\n    for img in os.listdir(os.path.join(base_path_train,'seg_train', file)):\n      images_train.append(img)\n      labels_train.append('sea')  \n  if file=='street':\n    for img in os.listdir(os.path.join(base_path_train,'seg_train', file)):\n      images_train.append(img)\n      labels_train.append('street')      \n\ndata_train= {'Images': images_train, 'labels':labels_train}     \ndata_train=pd.DataFrame(data_train)\nprint(data_train.head(10))\n        ","f1de3be3":"data_train.labels.value_counts()","69602688":"# Encoding the string labels to digits\nencoder= LabelEncoder()\ndata_train['encoded_labels']= encoder.fit_transform(data_train['labels'])\ndata_train.head(10)\ndata_train.encoded_labels.value_counts()","70d6e715":"train_batch_size=32\nrandom_seed=50","e5374cb6":"# Create train sampler\ntrain_indices = list(range(len(data_train)))\n\ntrain_sampler = SubsetRandomSampler(train_indices)\n","6c467255":"#training image path\npath_train=os.path.join(base_path_train,'seg_train')\nprint(path_train)","20029369":"dataset_train = INTELDataset(data_train,path_train,transform)\n\n\n\ntrain_loader = torch.utils.data.DataLoader(dataset_train, batch_size=train_batch_size, \n                                           sampler=train_sampler)\n","3a4e5091":"#Check the size of a test images\nim=Image.open('..\/input\/intel-image-classification\/seg_test\/seg_test\/street\/20719.jpg')\nwidth, height= im.size\nprint(width,height)","02ee5f0b":"base_path_test='..\/input\/intel-image-classification\/seg_test'\n","08f71330":"images_test=[]\nlabels_test=[]\n\n\nfor file in os.listdir(os.path.join(base_path_test,'seg_test')):\n  if file=='buildings':\n    for img in os.listdir(os.path.join(base_path_test,'seg_test', file)):\n      images_test.append(img)\n      labels_test.append('buildings')\n  if file=='forest':\n    for img in os.listdir(os.path.join(base_path_test,'seg_test', file)):\n      images_test.append(img)\n      labels_test.append('forest')      \n  if file=='glacier':\n    for img in os.listdir(os.path.join(base_path_test,'seg_test', file)):\n      images_test.append(img)\n      labels_test.append('glacier')\n  if file=='mountain':\n    for img in os.listdir(os.path.join(base_path_test,'seg_test', file)):\n      images_test.append(img)\n      labels_test.append('mountain')  \n  if file=='sea':\n    for img in os.listdir(os.path.join(base_path_test,'seg_test', file)):\n      images_test.append(img)\n      labels_test.append('sea')  \n  if file=='street':\n    for img in os.listdir(os.path.join(base_path_test,'seg_test', file)):\n      images_test.append(img)\n      labels_test.append('street')      \n\ndata_test= {'Images': images_test, 'labels':labels_test}     \ndata_test=pd.DataFrame(data_test)\nprint(data_test.head(10))\n        ","c1887a4f":"# Encoding the string labels to digits\nencoder= LabelEncoder()\ndata_test['encoded_labels']= encoder.fit_transform(data_test['labels'])\ndata_test.head(10)\ndata_test.encoded_labels.value_counts()","cd4c18e1":"path_test=os.path.join(base_path_test,'seg_test')\n","a0b589c5":"# Creating Test Sampler\ntest_indices = list(range(len(data_test)))\n\ntest_sampler = SubsetRandomSampler(test_indices)\n","4a918f12":"test_batch_size=20","5e684663":"dataset_test = INTELDataset(data_test,path_test,transform)\n\n\n\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=test_batch_size, \n                                           sampler=test_sampler)\n","f19ccabc":"def train(model, device, train_loader, criterion, optimizer, epoch):\n    model.cuda()\n    model.train()\n    train_losses=[]\n    for batch_idx, (data, target) in enumerate(train_loader):\n       \n        # send the image, target to the device\n        data, target = data.to(device), target.to(device)\n        # flush out the gradients stored in optimizer\n        optimizer.zero_grad()\n        # pass the image to the model and assign the output to variable named output\n        output = model(data)\n        # calculate the loss (use cross entropy in pytorch)\n        loss = criterion(output, target)\n        #appending train loss list\n        train_losses.append(loss.item())\n        # do a backward pass\n        loss.backward()\n        # update the weights\n        optimizer.step()\n     \n        if batch_idx % 32 == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.item()))\n            \n    return train_losses","70e88e0a":"def test(model, device, test_loader, criterion):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n          \n            # send the image, target to the device\n            data, target = data.to(device), target.to(device)\n            # pass the image to the model and assign the output to variable named output\n            output = model(data)\n            #print(output)\n         \n            test_loss += criterion(output, target).item()  # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n    #print(output)\n    test_loss \/= len(test_loader.dataset)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct \/ len(test_loader.dataset)))","245f9697":"model = models.resnet50(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\nnum_features= model.fc.in_features\nmodel.fc = nn.Linear(num_features, 6)\n\n\ncriterion = nn.CrossEntropyLoss().cuda()\n#Define Adam Optimiser with a learning rate of 0.01\noptimizer = optim.Adam(model.fc.parameters(), lr=0.01)\n\nstart = timeit.default_timer()\nfor epoch in range(1, 11):\n    train(model, device, train_loader, criterion, optimizer, epoch)\n    test(model, device, test_loader, criterion)\nstop = timeit.default_timer()\nprint('Total time taken: {} seconds'.format(int(stop - start)) )","a6c96951":"valid_transforms = transforms.Compose([transforms.Resize(224),\n                                      transforms.ToTensor(),\n                                     ])","10e4b026":"\ndef predict_image(image):\n    image_tensor = valid_transforms(image).float()\n    image_tensor = image_tensor.unsqueeze_(0)\n    input = Variable(image_tensor)\n    input = input.to(device)\n    output = model(input)\n    index = output.data.cpu().numpy().argmax()\n    vector={0:'buildings',1:'forest',2:'glacier',3:'mountain',4:'sea',5:'street'}\n    obj=vector[index]\n    \n        \n    return obj","823cfd09":"im=Image.open('..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10004.jpg')\nim","8c0ceeb7":"predict_image(im)","75d194aa":"im2=Image.open('..\/input\/intel-image-classification\/seg_pred\/seg_pred\/10769.jpg')\nim2","15e2b380":"predict_image(im2)","4aa01117":"pred_path='..\/input\/intel-image-classification\/seg_pred'\nvalid_path=os.path.join(pred_path,'seg_pred')","d32b6c79":"# ***Function for Training***","40e7a6fd":"# **Creating Test data labels**","bc361b7e":"# ***Creating training data labels***","187c5efc":"# ***Training and Testing using pretrained Resnet50***","af75d941":"# ***Function for Testing***","a1152e7e":"# ***Validate the Model***"}}