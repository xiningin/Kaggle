{"cell_type":{"962eb630":"code","797a42e5":"code","62470285":"code","c3440dcd":"code","afe71c89":"code","eea80185":"code","2d2868f0":"code","887a5727":"code","df647bfb":"code","4fe16bcc":"code","95eb8534":"code","bcf4fcd8":"code","3cfec7a1":"code","8cbd9378":"code","89dea770":"code","35e20be4":"code","3ea18621":"code","7e6e3d04":"code","cf268f97":"code","e4105270":"code","57967c76":"code","7bd26d5a":"markdown","c4a3a173":"markdown","7fd665c6":"markdown","a2800f2c":"markdown","3c56ef37":"markdown","939ce323":"markdown","e1941fd2":"markdown","5fab0661":"markdown","25561cc0":"markdown","65ed8cf4":"markdown","23fd6fb2":"markdown","4c5f8117":"markdown","f8c34f88":"markdown","5632a4ab":"markdown","df0223e9":"markdown","123f5b63":"markdown","039874cf":"markdown","aabbab63":"markdown"},"source":{"962eb630":"\"\"\"\n This Python 3 environment comes with many helpful analytics libraries installed\n It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n Input data files are available in the read-only \"..\/input\/\" directory\n For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\"\"\"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nfrom pandas_profiling import ProfileReport\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nwarnings.filterwarnings('ignore')\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","797a42e5":"# Importing the dataset\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df  = pd.read_csv('..\/input\/titanic\/test.csv')","62470285":"train_df.head(6)","c3440dcd":"test_df.head(3)","afe71c89":"# Unlikely to help\ntrain_df = train_df.drop(['Name', 'Ticket', 'PassengerId'], axis = 1 )\n\n# Unlikely to match with future data\ntrain_df = train_df.drop(['Cabin', 'Embarked'], axis = 1 )\n\ntrain_df.head(3)","eea80185":"print(train_df.isnull().sum())\ntrain_df.head(6)","2d2868f0":"train_df['Age_new'] = train_df['Age'].fillna(train_df['Age'].mean())\ntrain_df['missing_age']  = train_df['Age'].isnull().astype('int')\ntrain_df = train_df.drop(['Age'], axis = 1 )\ntrain_df.head(6)","887a5727":"Sex_encoding = pd.get_dummies(train_df['Sex'])\ntrain_df = pd.concat([train_df, Sex_encoding],axis =1)\ntrain_df = train_df.drop(['Sex'],axis=1)\ntrain_df.head(3)","df647bfb":"profile = ProfileReport(train_df, title=\"Pandas Profiling Report\")\nprofile","4fe16bcc":"sns.scatterplot(data=train_df, x=\"male\", y=\"Fare\", hue=\"Survived\")","95eb8534":"train_df['Family_Size']=train_df['SibSp']+train_df['Parch']","bcf4fcd8":"train_df.head(5)","3cfec7a1":"from sklearn import decomposition\n\nX = train_df.head(30).drop(['Survived'], axis = 1).to_numpy()\nY = train_df.head(30)['Survived'].to_numpy()\n\npca = decomposition.PCA(n_components=4)\npc = pca.fit_transform(X)\n\npc_df = pd.DataFrame(data = pc , columns = ['PC1', 'PC2','PC3','PC4'])\npc_df['Cluster'] = Y\ndf = pd.DataFrame({'Variance':pca.explained_variance_ratio_,\n             'Principle_components':['PC1','PC2','PC3','PC4']})\nsns.barplot(x='Principle_components',y=\"Variance\", \n           data=df, color=\"c\");\nsns.lmplot( x=\"PC1\", y=\"PC2\", data=pc_df, \n  fit_reg=False, \n  hue='Cluster', # color by cluster\n  legend=True,\n  scatter_kws={\"s\": 20})","8cbd9378":"target_name   = 'Survived'\nfeatures_name = train_df.columns.drop(target_name).tolist()\nprint('Learning to map from {} to {}'.format(features_name, target_name))\n\nfor f in features_name:\n    train_df[f] = train_df[f].astype('float64')\ntrain_df[target_name] = train_df[target_name].astype('int64')\ntrain_df.dtypes","89dea770":"from sklearn.model_selection import train_test_split\nX = train_df.drop('Survived', axis=1)\nY = train_df['Survived']\n\nx_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state =0)\nprint(x_train.shape)\nprint(y_train.shape)\n","35e20be4":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_val = sc.transform(x_val)","3ea18621":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nclassifier = LogisticRegression()\nclassifier.fit(x_train, y_train)\ny_pred = classifier.predict(x_val)\n\nmylist = []\n\ncm = confusion_matrix(y_val, y_pred)\nac = accuracy_score(y_val, y_pred)\nmylist.append(ac)\nprint(cm)\nprint(ac)","7e6e3d04":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 11, criterion='entropy', random_state=0)\nclassifier.fit(x_train,y_train)\ny_pred = classifier.predict(x_val)\n\ncm = confusion_matrix(y_val, y_pred)\nac = accuracy_score(y_val, y_pred)\nmylist.append(ac)\nprint(cm)\nprint(ac)\nprint(classifier.feature_importances_) ","cf268f97":"feat_importances = pd.Series(classifier.feature_importances_, index=features_name)\nfeat_importances.nlargest(12).plot(kind='barh')\nplt.show()","e4105270":"np.random.seed(0)\nimport tensorflow as tf\n\nann = tf.keras.models.Sequential()\nann.add(tf.keras.layers.Dense(units = 10, activation = 'relu'))\nann.add(tf.keras.layers.Dense(units = 10, activation = 'relu'))\nann.add(tf.keras.layers.Dense(units = 10, activation = 'relu'))\nann.add(tf.keras.layers.Dense(units = 10, activation = 'relu'))\nann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\nann.compile(optimizer = 'adam', loss = 'binary_crossentropy' , metrics = ['accuracy'] )\n\nann.fit(x_train, y_train, batch_size = 8, epochs = 50)\n\ny_pred = ann.predict(x_val)\ny_pred = (y_pred > 0.5)\nnp.set_printoptions()\n\ncm = confusion_matrix(y_val,y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\n\n# accuracy\nac = accuracy_score(y_val,y_pred)\nprint(\"Accuracy\")\nprint(ac)\nmylist.append(ac)","57967c76":"mylist2 = [\"Logistic Regression\", \"RandomForest\",\"ANN\"]\nplt.rcParams['figure.figsize']=15,6 \nsns.set_style(\"darkgrid\")\nax = sns.barplot(x=mylist2, y=mylist, palette = \"rocket\", saturation =1.5)\nplt.xlabel(\"Classifier Models\", fontsize = 20 )\nplt.ylabel(\"% of Accuracy\", fontsize = 20)\nplt.title(\"Accuracy of different Classifier Models\", fontsize = 20)\nplt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\nplt.yticks(fontsize = 13)\nfor p in ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height:.2%}', (x + width\/2, y + height*1.02), ha='center', fontsize = 'x-large')\nplt.show()","7bd26d5a":"### **Ignoring features**","c4a3a173":"# **Required libs & data files**","7fd665c6":"# **Data Preparation**","a2800f2c":"## Random forest","3c56ef37":"## Split into train and validation","939ce323":"## Logistic regression","e1941fd2":"## Data standarization","5fab0661":"# **Explanatory data analysis (EDA)**","25561cc0":"# **Data preprocessing**","65ed8cf4":"## Artificial neural network","23fd6fb2":"![image.png](attachment:3423528c-d306-4829-84bf-5fee9ff65923.png)\n\n## Variable Notes\npclass: A proxy for socio-economic status (SES) \n\n1st = Upper\n\n2nd = Middle\n\n3rd = Lower\n\nage: Age is fractional if less than 1.\n\nsibsp: Number of Siblings + Spouse\n\nparch: Number of parents + Number of children ","4c5f8117":"# **Data inspection** \n","f8c34f88":"# **Model training**","5632a4ab":"### Feature importance","df0223e9":"# Model selection and evaluation","123f5b63":"### **Handling missing values**","039874cf":"### **Handling categorical values: hot encoding**","aabbab63":"## PCA"}}