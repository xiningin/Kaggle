{"cell_type":{"1fbac9b9":"code","5be9dd8d":"code","08adae29":"code","cf423f33":"code","a87e5138":"code","23ae7ec5":"code","34046f92":"code","4dce5e65":"code","70722e82":"code","811695d1":"code","284457a1":"code","5580b494":"code","5e113edd":"code","114f9fcb":"code","4c7f7900":"code","20d5e8c6":"code","09f14290":"code","0c85fc3f":"code","05c630a7":"code","e71ff9e7":"code","a4044503":"code","fce311bd":"code","a1e17977":"code","262bac47":"code","9ea9cca6":"code","1cfba39c":"code","a3e3f93a":"code","dccd3722":"code","33b12032":"code","8d8cebfb":"code","d45c458b":"code","7d840750":"code","45811cd2":"code","9f45a50e":"code","d73c5fe0":"code","88aac99f":"code","a3855b02":"code","1506201d":"code","89f8c7cc":"code","6fd912c5":"code","c5734c16":"code","6770d5d0":"code","7963d646":"code","61eff138":"code","893b66bc":"code","773d74fe":"code","75d17893":"code","ea8c4a39":"code","61386a73":"code","73cd99ac":"code","3e37b49a":"code","7a9c498f":"code","40821064":"code","fac1acbe":"code","23689d11":"code","f4af8f54":"code","09b23ada":"markdown","1f654696":"markdown","dfe0ceb8":"markdown","72e32499":"markdown","69186a47":"markdown","f455a0c8":"markdown","74eab33b":"markdown","869429f8":"markdown","b5d594fa":"markdown","b50a2a25":"markdown","cdcac2ba":"markdown","451a6b2d":"markdown","98b25429":"markdown","aa4061ac":"markdown"},"source":{"1fbac9b9":"!pip install -q -U seaborn\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport plotly as pl\nimport lightgbm as lgb","5be9dd8d":"db=pd.read_csv('..\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 4.csv',\n               parse_dates=['Order Date'])\n\ndb.head()","08adae29":"print('Checking null values in each Columns')\ndb.isnull().sum()","cf423f33":"print(\"Bestseller :\",db['Book Name'].value_counts().nlargest(1,keep='all').to_frame().index.values[0]); # bestseller\nprint(\"Top City :\",db['City (Billing)'].value_counts().nlargest(1,keep='all').to_frame().index.values[0]); # top city for orders\n\ndb['Book Name'] = db['Book Name'].fillna('\u0627\u0646\u0679\u0631\u0646\u06cc\u0679 \u0633\u06d2 \u067e\u06cc\u0633\u06c1 \u06a9\u0645\u0627\u0626\u06cc\u06ba') # filling null values with most sold book\ndb['City (Billing)'] = db['City (Billing)'].fillna('Karachi') # filling null valuse with top city\n\ndisplay(\"Checking null values in each Columns\")\ndb.isnull().sum()","a87e5138":"db['Date'] = [d.date() for d in db['Order Date']]\ndb['Time'] = [d.time() for d in db['Order Date']]\ndb['Month'] = [d.month for d in db['Order Date']]\ndb['Month_Year'] = [d.to_period(\"M\") for d in db['Order Date']]\ndb['Year'] = [d.year for d in db['Order Date']]\ndb['Weekday'] = [d.week for d in db['Order Date']]\ndb.head()","23ae7ec5":"cities=pd.read_csv('..\/input\/pakistan-cities\/pk.csv')\ncities.head()","34046f92":"cities['city'] = cities['city'].replace(['Sialkot City'],'Sialkot') # Replacing names for merggin DB","4dce5e65":"geo=db['City (Billing)'].value_counts().rename_axis('City').reset_index(name='counts')\nclean_geo=geo.merge(cities,how='inner',left_on='City', right_on='city')\nclean_geo=clean_geo[[\"City\",\"lat\",\"lng\",\"admin_name\",\n         \"population_proper\",\"counts\"]]\nclean_geo=clean_geo.rename(columns={\"lat\":\"Latitude\",\"lng\":\"Longitude\",\n                                    \"population_proper\":\"Population\",\n                                    \"admin_name\":\"Province\",\"counts\":\"Total Orders\"})\nclean_geo.head()","70722e82":"import plotly.graph_objects as go\n\n\nclean_geo['text'] = clean_geo['City'] + '<br> Book Sold ' + (clean_geo['Total Orders']).astype(str)\n# limits = [(0,99),(100,299),(300,499),(500,999),(1000,3000)]\n \nlimits = [(0,3),(3,9),(9,19),(19,49),(49,3000)]\ncolors = [\"royalblue\",\"crimson\",\"lightseagreen\",\"orange\",\"lightgrey\"]\nscale = 5000\n\nfig = go.Figure()\n\nfor i in range(len(limits)):\n    lim = limits[i]\n    df_sub = clean_geo[lim[0]:lim[1]]\n    fig.add_trace(go.Scattergeo(\n        lon = df_sub['Longitude'],\n        lat = df_sub['Latitude'],\n        text = df_sub['text'],\n        marker = dict(\n            size = df_sub['Total Orders'],\n            color = colors[i],\n            line_color='rgb(40,40,40)',\n            line_width=0.5,\n            sizemode = 'area'\n        ),\n        name = 'Top {0} - {1}'.format(lim[0]+1,lim[1])))\n\nfig.update_layout(\n        title_text = 'Total Books Sold by Gufhtugu per City',\n        showlegend = True,\n        legend_title=\"Top Books\",\n        legend_title_font_size=14,\n        geo = dict(\n            scope = 'asia',\n            landcolor = 'rgb(217, 217, 217)',\n            lonaxis = dict(range = [60.578993, 82.65129]),\n            lataxis = dict(range = [24.407138, 36.885931]),\n            \n        ),\n        \n    )\n\nfig.show()","811695d1":"month=db[['City (Billing)','Month']].value_counts().rename_axis(['City','Month']).reset_index(name='counts')\nmonth_geo=month.merge(clean_geo,how='inner',left_on='City', right_on='City').sort_values(['Month'])\nmonth_geo.head()","284457a1":"import plotly.express as px\n# df = px.data.gapminder()\npx.scatter(month_geo, x=\"Total Orders\", y=\"counts\", animation_frame=\"Month\", animation_group=\"City\",\n           size=\"counts\", color=\"Province\", hover_name=\"City\",title='Number of Books bought by cities over month',\n           log_x=True, size_max=40, range_x=[1,3000], range_y=[0,500])\n# px.update_xaxes(autorange=True)","5580b494":"weekday=db[['City (Billing)','Weekday']].value_counts().rename_axis(['City','Week']).reset_index(name='counts')\nweekday_geo=weekday.merge(clean_geo,how='inner',left_on='City', right_on='City').sort_values(['Week'])","5e113edd":"px.scatter(weekday_geo, x=\"Total Orders\", y=\"counts\", animation_frame=\"Week\", animation_group=\"City\",\n           size=\"counts\", color=\"Province\", hover_name=\"City\",title='Number of Books bought by cities over Week',\n           log_x=True, size_max=40, range_x=[1,3000], range_y=[0,200])","114f9fcb":"# sns.set_theme(style=\"whitegrid\", palette=\"muted\")\ntotal_month=db['Month'].value_counts().rename_axis(['Month']).reset_index(name='counts')\nsns.set(rc={'figure.figsize':(12,8)},style=\"whitegrid\", palette=\"muted\")\n# Draw a categorical scatterplot to show each observation\nax = sns.barplot(data=total_month, x=\"Month\", y=\"counts\",palette='CMRmap')\nax.set(ylabel=\"\",title=\"Number of Books sold per month\",);\n# ax.legend(loc='upper right', bbox_to_anchor=(0.3, 1), ncol=1);","4c7f7900":"db=db.merge(cities,how='left',left_on='City (Billing)', right_on='city').set_index('Order Number')\n","20d5e8c6":"total=db[[\"Order Status\",\"Book Name\",\"Date\",\"Time\",\"City (Billing)\",\n         \"lat\",\"lng\",\"population_proper\",\"admin_name\",\"Month\"]]\ntotal=total.rename(columns={\"Order Status\":\"Status\",\"Book Name\":\"Book\",\"City (Billing)\":\"City\",\n         \"lat\":\"Latitude\",\"lng\":\"Longitude\",\"population_proper\":\"Population\",\"admin_name\":\"Province\"})\ntotal.head()","09f14290":"import matplotlib as mpl\nax = sns.histplot(data=total, x=\"Month\", hue=\"Province\",\n    multiple=\"stack\",\n    palette=\"rocket\",\n    edgecolor=\".3\",binwidth=1,kde=True,\n    linewidth=.5)\nax.set(ylabel=\"\",title=\"Number of Books sold to province per month\")\nax.set_xticklabels([ \"\",'Feb', 'Apr','Jun','Aug','Oct','Dec']);","0c85fc3f":"status=db[['Order Status','Month']].value_counts().rename_axis(['Status','Month']).reset_index(name='counts')\npal = dict(Completed=\"#6495ED\", Returned=\"#F08080\",Canceled=\"#90ee90\")\n\n# Show the survival probability as a function of age and sex\ng = sns.lmplot(x=\"Month\", y=\"counts\", col=\"Status\", hue=\"Status\", data=status,\n               palette=pal, y_jitter=.02, logistic=False, truncate=True,);","05c630a7":"status_pro=total[['Status','Month','Province']].value_counts().rename_axis(['Status','Month','Province']).reset_index(name='counts')\n\n\ng = sns.relplot(\n    data=status_pro,\n    x=\"Month\", y=\"counts\",\n    hue=\"Status\", size=\"Province\",\n    palette=pal, sizes=(10, 200),alpha=0.9,height=8,aspect=1.2\n)\ng.set( yscale=\"log\")\ng.set(ylabel=\"\",title=\"Status of Books sold to Province per month\")\ng.despine(left=True, bottom=True);","e71ff9e7":"from catboost import CatBoostRegressor,Pool\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder","a4044503":"train=db[['Order Status','Year','admin_name','City (Billing)','Weekday']].value_counts().rename_axis(['Status','Year','Province','City','Week']).reset_index(name='counts')","fce311bd":"train[['Year','Week']]=train[['Year','Week']].astype('int')\n","a1e17977":"DataX = train.drop(columns=['counts'])\nDatay = train['counts'].values\nx_train, x_val, y_train, y_val = train_test_split(DataX, Datay, test_size=0.3)","262bac47":"train_pool = Pool(x_train, \n                  y_train, \n                  cat_features=['Status','Province','City'])\ntest_pool = Pool(x_val, \n                  y_val, \n                  cat_features=['Status','Province','City'])","9ea9cca6":"model=CatBoostRegressor(iterations=10000,\n                             learning_rate=0.001,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             od_type='Iter',\n                             metric_period = 100,\n                             od_wait=100) # catboost is used for avoiding over fitting","1cfba39c":"model.fit(train_pool,\n             eval_set=test_pool,\n             use_best_model=True,\n             verbose=False,plot=True);","a3e3f93a":"predict=model.predict(test_pool)","dccd3722":"res = model.calc_feature_statistics(train_pool,\n                                    feature=1,\n                                    plot=True)","33b12032":"import shap\nshap.initjs()","8d8cebfb":"explainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(x_train)\n\n# visualize the first prediction's explanation\nshap.force_plot(explainer.expected_value, shap_values[0,:], x_train.iloc[0,:])","d45c458b":"shap.force_plot(explainer.expected_value, shap_values, x_train)","7d840750":"shap.dependence_plot(\"Week\", shap_values, x_train)","45811cd2":"shap.summary_plot(shap_values, x_train)","9f45a50e":"shap.force_plot(explainer.expected_value, shap_values[91,:],x_train.iloc[91,:])","d73c5fe0":"x=range(len(predict))\ny=y_val\nax=sns.lineplot(x=x,y=y,label='Train',color='#9FD1FF')\nax=sns.lineplot(x=x,y=predict,label='Predicted',color='#FF8B8B')\nax.set(title='Trainig and predicted by Weekday data over the time');","88aac99f":"Status ='Completed'\nYear = 2021\nProvince = 'Punjab'\nCity = 'Lahore'\nWeek= 20\ndata1 = [Status,Year,Province,City,Week]\ntest1 = model.predict(data1)","a3855b02":"print(int(test1),\"Books Order\",Status,\"in week\",Week,\"-\",Year,\" from \",City,\",\",Province,\".\" )","1506201d":"Status =['Completed','Completed','Completed','Returned']\nYear = [2021,2021,2022,2021]\nProvince = ['Punjab','Punjab','Sindh','Punjab']\nCity = ['Lahore','Bahawalpur','Karachi','Lahore']\nWeek= [20,10,13,14]\ndata2 = pd.DataFrame(np.transpose([Status,Year,Province,City,Week]),\n                     columns=['Status','Year','Province','City','Week'])\ntest2 = model.predict(data2).astype('int')","89f8c7cc":"for i in range(len(test2)):\n    print(i+1,')',test2[i],\"Books Order\",data2.Status[i],\"in\",\"in week\",data2.Week[i],\"-\",data2.Year[i],\n          \" from \",data2.City[i],\",\",data2.Province[i],\".\\n\" )","6fd912c5":"Week=DataX\nWeek['Year']=Week['Year'].replace([2019,2020],[2021,2022])\n\nypred=model.predict(Week)\nWeek['counts']=ypred.astype('int')\nTotaldf=pd.concat([train, Week], axis=0)\nTotaldf.shape","c5734c16":"\nax=sns.lineplot(x='Week',y='counts',hue='Year',data=Totaldf,palette='Set2')\nax.set( yscale=\"log\")\nax.set(title='Trainig and predicted by Weekday data over the time');","6770d5d0":"train1=db[['Order Status','Month','Year','admin_name','City (Billing)']].value_counts().rename_axis(['Status','Month','Year','Province','City']).reset_index(name='counts')\ntrain1[['Year','Month']]=train1[['Year','Month']].astype('int')\nDataX = train1.drop(columns=['counts'])\nDatay = train1['counts'].values\nx_train, x_val, y_train, y_val = train_test_split(DataX, Datay, test_size=0.3)\ntrain_pool = Pool(x_train, \n                  y_train, \n                  cat_features=['Status','Province','City'])\ntest_pool = Pool(x_val, \n                  y_val, \n                  cat_features=['Status','Province','City'])","7963d646":"model=CatBoostRegressor(iterations=10000,\n                             learning_rate=0.001,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             od_type='Iter',\n                             metric_period = 100,\n                             od_wait=100)\nmodel.fit(train_pool,\n             eval_set=test_pool,\n             use_best_model=True,\n             verbose=False,plot=True);","61eff138":"predict=model.predict(test_pool)\nres = model.calc_feature_statistics(train_pool,\n                                    feature=1,\n                                    plot=True)","893b66bc":"x=range(len(predict))\ny=y_val\nax=sns.lineplot(x=x,y=y,label='Train',color='#9FD1FF')\nax=sns.lineplot(x=x,y=predict,label='Predicted',color='#FF8B8B')\nax.set(title='Trainig and predicted by Month data over the time');","773d74fe":"Make = train1.drop(columns=['counts'])\nWeek=Make\nWeek['Year']=Week['Year'].replace([2019,2020],[2021,2022])\n\nypred=model.predict(Week)\nWeek['counts']=ypred.astype('int')\nTotal=pd.concat([train1, Week], axis=0)\nax=sns.lineplot(x='Month',y='counts',hue='Year',data=Total,palette='Set2')\nax.set( yscale=\"log\")\nax.set(title='Trainig and predicted by Month data over the time');","75d17893":"from sklearn.linear_model import LinearRegression\nReadDb=pd.read_csv('..\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 5.csv',\n                  parse_dates=['Order Date & Time'])\nReadDb['Month'] = [d.month for d in ReadDb['Order Date & Time']]\nReadDb['Month_Year'] = [d.to_period(\"M\") for d in ReadDb['Order Date & Time']]\nReadDb['Year'] = [d.year for d in ReadDb['Order Date & Time']]\nReadDb['Weekday'] = [d.week for d in ReadDb['Order Date & Time']]\nRevenue=ReadDb[['Month','Year']].value_counts().rename_axis(['Month','Year']).\\\n   reset_index(name='counts')\nRevenue[\"Sale\"]=Revenue['counts']*500\n\nXpred=[i for i in range(2,13)]\npred=pd.DataFrame()\npred['Month']=Xpred\npred['Year']=2021\n\nRevenue.sort_values(by=['Year','Month'],inplace=True)\nreg=LinearRegression()\nX = Revenue.drop(columns=['counts','Sale'])\ny = Revenue['Sale'].values\nreg.fit(X,y)\n\nprediction_rev=reg.predict(pred)\n\nax=sns.lineplot(x=list(range(16)),y=Revenue.Sale,label=\"Past Sale\",color='#9FD1FF');\nax=sns.lineplot(x=[i for i in range(15,len(prediction_rev)+15)],y=prediction_rev,\n                label=\"Future Sale\",color='#FF8B8B');\nax.set(title='Predicting future sales till December 2021 Using Linear Regression ');","ea8c4a39":"Year_books=db[['Book Name','Year']].value_counts().rename_axis(['Book','Year']).reset_index(name='counts')","61386a73":"Year2019=Year_books[Year_books['Year']==2019].nlargest(10, 'counts')\nYear2020=Year_books[Year_books['Year']==2020].nlargest(10, 'counts')\nYear2021=Year_books[Year_books['Year']==2021].nlargest(10, 'counts')","73cd99ac":"f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n\n# Generate some sequential data\nsns.barplot(x='Book', y='counts', palette='Set2', ax=ax1,data=Year2019)\nax1.axhline(0, color=\"k\", clip_on=False)\nax1.set_ylabel(\"2019\")\n\n\n# Center the data to make it diverging\n\nsns.barplot(x='Book', y='counts', palette='Set2', ax=ax2,data=Year2020)\nax2.axhline(0, color=\"k\", clip_on=False)\nax2.set_ylabel(\"2020\")\n\n# Randomly reorder the data to make it qualitative\n\nsns.barplot(x='Book', y='counts', palette='Set2', ax=ax3,data=Year2021)\nax3.axhline(0, color=\"k\", clip_on=False)\nax3.set_ylabel(\"2021\")\n\n# Finalize the plot\nsns.despine(bottom=True)\nplt.setp(f.axes, yticks=[])\nfor p in ax1.patches:\n    ax1.annotate(format(p.get_height(), '1.0f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\nfor p in ax2.patches:\n    ax2.annotate(format(p.get_height(), '1.0f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\nfor p in ax3.patches:\n    ax3.annotate(format(p.get_height(), '1.0f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\n    \nax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\nax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\nax3.set_xticklabels(ax3.get_xticklabels(),rotation=90)\n\nax1.set_xticklabels([ \"Data Science\",'Kaggle', 'R ka Taaruf','(C++)','Apna Elaaj','Shaoor','Molo Masali',\n                    'Kaggle for Begginers','CryptoCurrency','Blockchain']);\nax2.set_xticklabels([ \"Earn Money\",'Python Programming','Product Management', 'Blockchain','Justju ka safar',\n                     'Artificial Intelligence','Molo Masali','(C++)',\n                    'Python Programming 2020','Sukkur To Florida','Blockchain']);\nax3.set_xticklabels([ \"Lucky Draw\",'Earn Money','Column Nigari', 'Python Programming','Waqfa e Pareshani',\n                     'Data Science','Arif Kareem','Machine Learning',\n                    'Artificial Intelligence','Blockchain']);\nplt.tight_layout(h_pad=2);\nax1.set(title='Best Seller in 2019');\nax2.set(title='Best Seller in 2020');\nax3.set(title='Best Seller in 2021');","3e37b49a":"Month_books=db[['Book Name','Month','Year']].value_counts().rename_axis(['Book','Month','Year']).reset_index(name='counts')","7a9c498f":"Month_2019=Month_books.sort_values(by=['counts'],ascending=False)\nMonth_2019=Month_2019[Month_2019['Year']==2019]\nRange=  pd.Series(range(10,13))\nTop_Month=[]\nTop_Book=[]\nTop_counts=[]\nfor x in Range:\n    Book=Month_2019[Month_2019['Month']==x].nlargest(1,'counts')['Book'].values\n    Month=Month_2019[Month_2019['Month']==x].nlargest(1,'counts')['Month'].values\n    Counts=Month_2019[Month_2019['Month']==x].nlargest(1,'counts')['counts'].values\n    Top_Book.append(Book)\n    Top_Month.append(Month)\n    Top_counts.append(Counts)\nTop_Month=[['Oct','Nov','Dec']]\nTop_Book=np.transpose(Top_Book)\nTop_counts=np.transpose(Top_counts)\nTotal=pd.DataFrame(np.concatenate([Top_Month,Top_Book,Top_counts]).transpose(),\n                   columns=['Month','Book','Sale'])\nTotal","40821064":"ax4=sns.barplot(data=Total,y='Book',x='Sale',hue='Month',palette='Set2',orient='h'\n                ,dodge=False)\n# ax4.set_yticklabels(ax4.get_xticklabels(),rotation=90)\nax4.set_yticklabels([ \"Kaggle for Begginers\",'Apna Elaaj Khud Karay','Data Science'])\nsns.despine(bottom=True)\n\nplt.setp(f.axes, yticks=[]);\nax4.set(title='Bestseller by Month in 2019 ');","fac1acbe":"Month_2020=Month_books.sort_values(by=['counts'],ascending=False)\nMonth_2020=Month_2020[Month_2020['Year']==2020]\nRange=  pd.Series(range(1,13))\nTop_Month=[]\nTop_Book=[]\nTop_counts=[]\nfor x in Range:\n    Book=Month_2020[Month_2020['Month']==x].nlargest(1,'counts')['Book'].values\n    Month=Month_2020[Month_2020['Month']==x].nlargest(1,'counts')['Month'].values\n    Counts=Month_2020[Month_2020['Month']==x].nlargest(1,'counts')['counts'].values\n    Top_Book.append(Book)\n    Top_Month.append(Month)\n    Top_counts.append(Counts)\nTop_Month=[['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']]\nTop_Book=np.transpose(Top_Book)\nTop_counts=np.transpose(Top_counts)\nTotal=pd.DataFrame(np.concatenate([Top_Month,Top_Book,Top_counts]).transpose(),\n                   columns=['Month','Book','Sale'])\nTotal","23689d11":"ax4=sns.barplot(data=Total,y='Book',x='Sale',hue='Month',palette='Set2',orient='h'\n                ,dodge=False,alpha=0.9)\n# ax4.set_yticklabels(ax4.get_xticklabels(),rotation=90)\nax4.set_yticklabels([ \"C++\",'Data Science','Justju ka safar-1','Artificial Intelligence',\n                     'Product Management','Python Programming','Earn Money From Internet'])\nsns.despine(bottom=True)\n\nplt.setp(f.axes, yticks=[]);\nax4.set(title='Bestseller by Month in 2020 ');","f4af8f54":"Month_2021=Month_books.sort_values(by=['counts'],ascending=False)\nMonth_2021=Month_2021[Month_2021['Year']==2021]\nTotal=Month_2021[Month_2021['Month']==1].nlargest(1,'counts')\nTotal","09b23ada":"### Best Seller per year","1f654696":"# Geographical Analysis ","dfe0ceb8":"## Prediction By Weekday","72e32499":"## Simpler Linear Regression","69186a47":"## Using Shap for feature dependency ","f455a0c8":"# Work in progress \ud83d\udc68\u200d\ud83d\udd27 and if you like my work do \"up vote\" \u261d","74eab33b":"## Importing Datasets and Cleaning","869429f8":"## Catboost for Futher prediction","b5d594fa":"## Test model with real world orders","b50a2a25":"# Best Seller","cdcac2ba":"# Exploring","451a6b2d":"## Prediction by Month","98b25429":"* In 2019 Data Science was a bestseller with 303 copies and the rest of the top ten don't even compete.\n* In 2020 trend changed as the pandemic started and people were stuck in the home so more people order the books online and the bestseller was Earn Money online with 2206 copies, which have a direct relationship with people losing jobs and stuck in their homes.\n* In 2021 we have limited data so we can assume that the sales have increased since the pandemic and people reading trend have changed. the best seller is Lucy Draw book which is a gift and the second, best was Earn Money online with 373 copies sold in the first few days.","aa4061ac":"# Simple Regression on Status"}}