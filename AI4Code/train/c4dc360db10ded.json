{"cell_type":{"63c3f43e":"code","08ef4205":"code","50259453":"code","e695c86c":"code","7e2c094c":"code","af9ee3e9":"code","cec94b3c":"code","85c9ab01":"code","b91190f7":"code","64d32162":"code","119c62c2":"code","0a2dbf2b":"code","cfe8b45a":"code","1a123155":"code","e9a09e46":"code","b1c6a36b":"code","f60c5342":"code","48cef483":"code","65363b15":"code","c0c5eb9e":"code","b0511b56":"code","2944c3c9":"code","72df4d40":"code","c9c4cfb6":"code","3ca04105":"code","733d2898":"code","53748d54":"code","295b437d":"code","aab7aa3d":"code","b1255673":"code","8224d4fb":"code","351c131d":"code","7709eaf4":"code","6b75dbd2":"code","7bcd3cf6":"code","2f69f64e":"code","f25d1575":"code","9e58b1ba":"code","100c0bef":"code","1882c5c2":"code","f974b9dd":"code","48e4b1b2":"code","b52f78d4":"markdown","eafd1c4c":"markdown","fa79a66e":"markdown","6bd709c0":"markdown","8f931560":"markdown","46c99fb6":"markdown","94234082":"markdown","c2e4fa2a":"markdown","ac36862e":"markdown","94496576":"markdown","77b0a253":"markdown","3a7bf2f0":"markdown","ebb8400e":"markdown","51e8489f":"markdown","04fe3411":"markdown","044c2df4":"markdown","1dca5c53":"markdown","b2314c1d":"markdown","36aa4d08":"markdown","fde6d964":"markdown"},"source":{"63c3f43e":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler\n# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import SimpleRNN\nfrom keras.layers import Dropout\n#\nimport plotly.graph_objs as go\nimport plotly.offline as offline\n#\nimport warnings\nwarnings.filterwarnings('ignore')\n#\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","08ef4205":"data = pd.read_csv(\"\/kaggle\/input\/sandp500\/individual_stocks_5yr\/individual_stocks_5yr\/GOOG_data.csv\")\ndata.head()","50259453":"data.shape","e695c86c":"data.info()","7e2c094c":"trace_high = go.Scatter(x=data.date,\n                        y=data.high,\n                        \n                        name = \"Google High\",\n                        \n                        line = dict(color = '#6699FF')\n                       )\ntrace_low = go.Scatter( x=data.date,\n                        y=data.low,\n                        \n                        name = \"Google Low\",\n                        \n                        line = dict(color = '#FF6633')\n                       )\ntrace_open = go.Scatter( x=data.date,\n                        y=data.open,\n                        \n                        name = \"Google Open\",\n                        \n                        line = dict(color = 'red')\n                       )\ntrace_close = go.Scatter( x=data.date,\n                        y=data.close,\n                        \n                        name = \"Google Close\",\n                        \n                        line = dict(color = 'black')\n                       )\ndata_figure = [trace_open,trace_high, trace_low,trace_close]\nlayout = dict(\n    \n    title = 'Google Stock Price Data ',\n    \n    xaxis = dict(rangeselector = dict(buttons = list([dict(count = 1,\n                                                           label = '1m',\n                                                           step = 'month',\n                                                           stepmode = 'todate',\n                                                          visible = True),\n                                                      \n                                                  dict(count = 3,\n                                                           label = '3m',\n                                                           step = 'month',\n                                                           stepmode = 'backward',\n                                                          visible = True),\n                                                      \n                                                      dict(count = 6,\n                                                           label = '6m',\n                                                           step = 'month',\n                                                           stepmode = 'backward',\n                                                          visible = True),\n                                                  \n                                                      dict(step = 'all')])\n                                     ),\n                 \n                 rangeslider=dict(visible = True),\n                 type='date'\n    )\n)\nfig = dict(data=data_figure, \n           layout=layout)\n\noffline.iplot(fig)","af9ee3e9":"data_temp = data.iloc[965:975,:]\ntrace = go.Candlestick(x = data_temp.date,                       \n                       open = data_temp.open,                       \n                       high = data_temp.high,                       \n                       low = data_temp.low,                       \n                       close = data_temp.close,\n                      increasing = dict(fillcolor = 'greenyellow', \n                                         line = dict(color = 'green', \n                                                     width = 3\n                                                    )),\n                       decreasing = dict(fillcolor = 'lightcoral'),                       \n                       whiskerwidth = 0.2)\ndata_figure_2 = [trace]\nlayout = dict(title = 'Google Stock Price Data ')\nfig = dict(data=data_figure_2, \n           layout=layout)\noffline.iplot(fig)","cec94b3c":"data_temp = data.iloc[875:975,:]\ndata_open = list(data_temp['open'])\ndateList = list(data_temp['date'])\nxList = []\nyList = []\nframesList = []\nfor i in range(len(dateList)):\n    \n    xList.append(dateList[i])\n    yList.append(data_open[i])\n    \n    framesList.append(dict(data = [dict(x = xList.copy(), y = yList.copy())]))\n#\nplayButton = dict(label = 'Play',\n                  method= 'animate',\n                  args= [None, \n                         dict(fromcurrent = True, \n                              transition = dict(duration = 200), \n                              frame = dict(duration = 100)\n                             )\n                        ]\n                 )\n#\npauseButton = dict(label = 'Pause',\n                  method= 'animate',\n                  args= [[None], dict(mode = 'immediate')]\n                 )\n#\nlayout = go.Layout(xaxis = dict(range = [dateList[0], dateList[-1]]), \n                   yaxis = dict(range = [0, 1 + max(data_open)]),\n                   \n                   updatemenus = [dict(type = 'buttons',\n                                       buttons = [playButton, pauseButton]\n                                       )\n                                 ]\n                  )\n#\nfig = dict(data=[{}], \n           layout=layout, \n           frames = framesList)\n\noffline.iplot(fig)","85c9ab01":"# Split Data\ndataset_train = data.loc[0:750,:]\ndataset_test  = data.loc[750:,:]","b91190f7":"scaler = MinMaxScaler(feature_range = (0, 1))\ntrain_scaled = scaler.fit_transform(dataset_train.loc[:,[\"open\"]].values)\ntrain_scaled","64d32162":"f,ax = plt.subplots(figsize = (30,7))\nplt.plot(train_scaled)\nplt.show()","119c62c2":"X_train = []\ny_train = []\ntimesteps = 50\nfor i in range(timesteps, 751):\n    X_train.append(train_scaled[i-timesteps:i, 0])\n    y_train.append(train_scaled[i, 0])\nX_train, y_train = np.array(X_train), np.array(y_train)","0a2dbf2b":"# Reshaping\nX_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\nprint(\"X:\",X_train)\nprint(\"X size:\",X_train.size)","cfe8b45a":"print(\"Y:\",y_train)\nprint(\"Y size:\",y_train.size)","1a123155":"# Initialising the RNN\nregressor = Sequential()\n\n# Adding the first RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True, input_shape = (X_train.shape[1], 1)))\nregressor.add(Dropout(0.2))\n\n# Adding a second RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a third RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50,activation='tanh', return_sequences = True))\nregressor.add(Dropout(0.2))\n\n# Adding a fourth RNN layer and some Dropout regularisation\nregressor.add(SimpleRNN(units = 50))\nregressor.add(Dropout(0.2))\n\n# Adding the output layer\nregressor.add(Dense(units = 1))\n\n# Compiling the RNN\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n# Fitting the RNN to the Training set\nregressor.fit(X_train, y_train, epochs = 250, batch_size = 32)","e9a09e46":"dataset_test.head()","b1c6a36b":"real_stock_price = dataset_test.loc[:,[\"open\"]].values\nreal_stock_price","f60c5342":"# Getting the predicted stock price of 2017\ndataset_total = pd.concat((dataset_train['open'], dataset_test['open']), axis = 0)\ninputs = dataset_total[len(dataset_total) - len(dataset_test) - timesteps:].values.reshape(-1,1)\ninputs = scaler.transform(inputs)  # min max scaler\ninputs","48cef483":"X_test = []\nfor i in range(timesteps, 275):\n    X_test.append(inputs[i-timesteps:i, 0])\nX_test = np.array(X_test)\nX_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\npredicted_stock_price = regressor.predict(X_test)\npredicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n\n# Visualising the results\nf,ax = plt.subplots(figsize = (30,7))\nplt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\nplt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\nplt.title('Google Stock Price Prediction')\nplt.xlabel('Time')\nplt.ylabel('Google Stock Price')\nplt.legend()\nplt.show()","65363b15":"import numpy\nimport math\nfrom keras.layers import Bidirectional\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error","c0c5eb9e":"data = pd.read_csv(\"\/kaggle\/input\/sandp500\/individual_stocks_5yr\/individual_stocks_5yr\/GOOG_data.csv\")\ndata.head()","b0511b56":"# reshape\n# Choice \"open\" feature:\ndataset = data.iloc[:,1].values\ndataset = dataset.reshape(-1,1) # (975,) sometimes can be problem\ndataset = dataset.astype(\"float32\")\ndataset.shape","2944c3c9":"# scaling \nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)","72df4d40":"# train test split\ntrain_size = int(len(dataset) * 0.75) # Split dataset 75% for train set, 25% for test set\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\nprint(\"train size: {}, test size: {} \".format(len(train), len(test)))","c9c4cfb6":"time_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = numpy.array(dataX)\ntrainY = numpy.array(dataY)  ","3ca04105":"dataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = numpy.array(dataX)\ntestY = numpy.array(dataY)  ","733d2898":"trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","53748d54":"# model\nmodel = Sequential()\nmodel.add(LSTM(10, input_shape=(1, time_stemp))) # 10 lstm neuron(block)\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nmodel.fit(trainX, trainY, epochs=50, batch_size=1)","295b437d":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore_vanilla = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore_vanilla))","aab7aa3d":"# shifting train\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nf,ax = plt.subplots(figsize = (30,7))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","b1255673":"# Need to Preprocessing \ndata = pd.read_csv(\"\/kaggle\/input\/sandp500\/individual_stocks_5yr\/individual_stocks_5yr\/GOOG_data.csv\")\ndataset = data.iloc[:,1].values\ndataset = dataset.reshape(-1,1) # (975,) sometimes can be problem\ndataset = dataset.astype(\"float32\")\n# scaling \nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n# train test split\ntrain_size = int(len(dataset) * 0.75) # Split dataset 75% for train set, 25% for test set\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\ntime_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = numpy.array(dataX)\ntrainY = numpy.array(dataY)  \ndataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = numpy.array(dataX)\ntestY = numpy.array(dataY)  \ntrainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","8224d4fb":"# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1,time_stemp)))\nmodel.add(LSTM(50, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\nmodel.fit(trainX, trainY, epochs=50, batch_size=1)","351c131d":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore_Stacked = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore_Stacked))","7709eaf4":"# shifting train\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nf,ax = plt.subplots(figsize = (30,7))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","6b75dbd2":"# Need to Preprocessing \ndata = pd.read_csv(\"\/kaggle\/input\/sandp500\/individual_stocks_5yr\/individual_stocks_5yr\/GOOG_data.csv\")\ndataset = data.iloc[:,1].values\ndataset = dataset.reshape(-1,1) # (975,) sometimes can be problem\ndataset = dataset.astype(\"float32\")\n# scaling \nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n# train test split\ntrain_size = int(len(dataset) * 0.75) # Split dataset 75% for train set, 25% for test set\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\ntime_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = numpy.array(dataX)\ntrainY = numpy.array(dataY)  \ndataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = numpy.array(dataX)\ntestY = numpy.array(dataY)  \ntrainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))","7bcd3cf6":"# define model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(1,time_stemp)))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\nmodel.fit(trainX, trainY, epochs=50, batch_size=1)","2f69f64e":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore_bidirectional = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore_bidirectional))","f25d1575":"# shifting train\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nf,ax = plt.subplots(figsize = (30,7))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","9e58b1ba":"# Need to Preprocessing \ndata = pd.read_csv(\"\/kaggle\/input\/sandp500\/individual_stocks_5yr\/individual_stocks_5yr\/GOOG_data.csv\")\ndataset = data.iloc[:,1].values\ndataset = dataset.reshape(-1,1) # (975,) sometimes can be problem\ndataset = dataset.astype(\"float32\")\n# scaling \nscaler = MinMaxScaler(feature_range=(0, 1))\ndataset = scaler.fit_transform(dataset)\n# train test split\ntrain_size = int(len(dataset) * 0.75) # Split dataset 75% for train set, 25% for test set\ntest_size = len(dataset) - train_size\ntrain = dataset[0:train_size,:]\ntest = dataset[train_size:len(dataset),:]\ntime_stemp = 10\ndataX = []\ndataY = []\nfor i in range(len(train)-time_stemp-1):\n    a = train[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(train[i + time_stemp, 0])\ntrainX = numpy.array(dataX)\ntrainY = numpy.array(dataY)  \ndataX = []\ndataY = []\nfor i in range(len(test)-time_stemp-1):\n    a = test[i:(i+time_stemp), 0]\n    dataX.append(a)\n    dataY.append(test[i + time_stemp, 0])\ntestX = numpy.array(dataX)\ntestY = numpy.array(dataY)  \ntrainX = numpy.reshape(trainX, (trainX.shape[0], 1,1, trainX.shape[1]))\ntestX = numpy.reshape(testX, (testX.shape[0], 1,1, testX.shape[1]))","100c0bef":"from keras.layers import Flatten\nfrom keras.layers import TimeDistributed\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D","1882c5c2":"model = Sequential()\nmodel.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None,1, time_stemp)))\nmodel.add(TimeDistributed(MaxPooling1D(pool_size=2, padding='same')))\nmodel.add(TimeDistributed(Flatten()))\nmodel.add(LSTM(50, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\nmodel.fit(trainX, trainY, epochs=50,batch_size=1)","f974b9dd":"trainPredict = model.predict(trainX)\ntestPredict = model.predict(testX)\n# invert predictions\ntrainPredict = scaler.inverse_transform(trainPredict)\ntrainY = scaler.inverse_transform([trainY])\ntestPredict = scaler.inverse_transform(testPredict)\ntestY = scaler.inverse_transform([testY])\n# calculate root mean squared error\ntrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\nprint('Train Score: %.2f RMSE' % (trainScore))\ntestScore_cnn = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\nprint('Test Score: %.2f RMSE' % (testScore_cnn))","48e4b1b2":"# shifting train\ntrainPredictPlot = numpy.empty_like(dataset)\ntrainPredictPlot[:, :] = numpy.nan\ntrainPredictPlot[time_stemp:len(trainPredict)+time_stemp, :] = trainPredict\n# shifting test predictions for plotting\ntestPredictPlot = numpy.empty_like(dataset)\ntestPredictPlot[:, :] = numpy.nan\ntestPredictPlot[len(trainPredict)+(time_stemp*2)+1:len(dataset)-1, :] = testPredict\n# plot baseline and predictions\nf,ax = plt.subplots(figsize = (30,7))\nplt.plot(scaler.inverse_transform(dataset))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","b52f78d4":"#### Plot the candlesticks\nThe plot has the following components:\n* A bounding box whose y values represent the range between the stock's open and close prices \n* A green box represents a higher close value than open (i.e. stock price went up that day)\n* The box is red when the stock closed lower\n* The vertical lines (bars above and below the box) show the range of intra-day high and low prices\n* The vertical lines are capped at the top by horizontal lines called whiserks. By default, the width of the whisker is 0 which is why we don't see them\n\nNotice that a slider appears by default along the X axis","eafd1c4c":"<a id=\"10\"><\/a>\n## 1 - Vanilla LSTM\n* A Vanilla LSTM is an LSTM model that has a single hidden layer of LSTM units, and an output layer used to make a prediction.","fa79a66e":"<a id=\"11\"><\/a>\n## 2 - Stacked LSTM\n* Multiple hidden LSTM layers can be stacked one on top of another in what is referred to as a Stacked LSTM model.","6bd709c0":"<hr>\n\n### Context\n* Google Stock Price\n\n### Content of Dataset\n* Historical stock prices (last 5 years) for all companies currently found on the S&P 500 index.\n\n* All the files have the following columns:\n  * Date - in format: yy-mm-dd\n  * Open - price of the stock at market open (this is NYSE data so all in USD)\n  * High - Highest price reached in the day\n  * Low Close - Lowest price reached in the day\n  * Volume - Number of shares traded\n  * Name - the stock's ticker name\n  \n<hr>","8f931560":"<a id=\"7\"><\/a>\n## Predictions and Visualising RNN Model","46c99fb6":"## Open Price Animation","94234082":"<a id=\"4\"><\/a>\n## Data Ploting","c2e4fa2a":"<hr>","ac36862e":"<a id=\"14\"><\/a>\n## Reference","94496576":"<a id=\"9\"><\/a>\n## Preprocessing Data\n* reshape\n* change type\n* scaling\n* train test split\n* Create dataset","77b0a253":"<a id=\"5\"><\/a>\n## Creating a data structure with 50 timesteps and 1 output","3a7bf2f0":"<a id=\"1\"><\/a>\n## Load Libraries","ebb8400e":"<a id=\"13\"><\/a>\n## 4 - CNN LSTM\n* A CNN model can be used in a hybrid model with an LSTM backend where the CNN is used to interpret subsequences of input that together are provided as a sequence to an LSTM model to interpret.","51e8489f":"## Content of Kernel\n* [Load Libraries](#1)\n* [Loading and Preprocessing Data](#2)\n* [Feature Scaling](#3)\n* [Data Ploting](#4)\n* [Creating a Data Structure for Train and Test](#5)\n* [Create RNN Model](#6)\n    * [Predictions and Visualising RNN Model](#7)\n* [Univariate LSTM Models](#8) \n    * [Preprocessing Data](#9)\n    * [1 - Vanilla LSTM](#10)\n    * [2 - Stacked LSTM](#11)\n    * [3 - Bidirectional LSTM](#12)\n    * [4 - CNN LSTM](#13)\n* [Reference](#14) \n\n<hr>","04fe3411":"<a id=\"8\"><\/a>\n## Univariate LSTM Models","044c2df4":"<a id=\"3\"><\/a>\n## Feature Scaling","1dca5c53":"<a id=\"6\"><\/a>\n## Create RNN Model","b2314c1d":"<a id=\"2\"><\/a>\n## Loading and Preprocessing Data","36aa4d08":"<a id=\"12\"><\/a>\n## 3 - Bidirectional LSTM\n* On some sequence prediction problems, it can be beneficial to allow the LSTM model to learn the input sequence both forward and backwards and concatenate both interpretations.","fde6d964":"https:\/\/machinelearningmastery.com\/how-to-develop-lstm-models-for-time-series-forecasting\/"}}