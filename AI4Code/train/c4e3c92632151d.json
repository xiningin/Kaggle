{"cell_type":{"3d1ebc6e":"code","f353559c":"code","9b68e772":"code","a369f1d4":"code","0ef8a72d":"code","110ae28a":"code","0ab75795":"code","3e335dd1":"code","cc7d4a94":"code","4be42029":"code","669c5302":"code","dcb354ba":"code","3dac73ea":"code","755e7e53":"code","99fd04c3":"code","f17209ff":"code","6c7311fb":"code","4912150f":"code","2a80353b":"code","f792866c":"code","143e9ddf":"code","4082b230":"code","d444b02e":"code","69e2bfc0":"code","5f812e6d":"code","4190c927":"code","26b9eb8a":"code","c5117835":"code","703991ef":"code","0e03edd3":"code","da07c411":"code","68d1758f":"code","67c5d5bf":"code","47861ff9":"code","b4fe2bda":"code","b89071ff":"code","47bfa40f":"code","a317d395":"code","8b15cdb4":"code","5eaaf6bb":"code","372b7d76":"code","87c5a3ae":"code","2e92869f":"markdown","0e1a2ed8":"markdown","85f650fc":"markdown","626be17f":"markdown","9897c4ad":"markdown","dd318461":"markdown","832531df":"markdown","05741dec":"markdown","1f5be55e":"markdown","571ca60f":"markdown","430d0cfa":"markdown","f7642c01":"markdown","2626452e":"markdown","87a0e78a":"markdown","5b5e9266":"markdown"},"source":{"3d1ebc6e":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)\n\nfrom glob import glob\nimport gc\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nimport cv2\n\nfrom tqdm import tqdm, tqdm_notebook\ntqdm.pandas()\n\nfrom sklearn.model_selection import train_test_split\n\nplt.rcParams[\"figure.figsize\"] = (12, 8)\nplt.rcParams['axes.titlesize'] = 16\nplt.style.use('seaborn-whitegrid')\nsns.set_palette('Set2')\n\nimport tensorflow as tf\n\nimport os\nprint(os.listdir('..\/input\/'))\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))","f353559c":"base_dir = '..\/input\/meat-quality-assessment-based-on-deep-learning\/'\nos.listdir(base_dir)","9b68e772":"fresh = glob(base_dir + 'Fresh\/*.jpg')\nspoiled = glob(base_dir + 'Spoiled\/*.jpg')\n\nprint(f\"Number of images in Fresh Category: {len(fresh)}\")\nprint(f\"Number of images in Spoiled Category: {len(spoiled)}\")","a369f1d4":"fresh[:5], spoiled[:5]","0ef8a72d":"def display_images(paths, rows, cols, cat = None):\n    fig, ax = plt.subplots(rows, cols, figsize = (16, 12))\n    ax = ax.flatten()\n    if cat == 'Fresh':\n        c = 'green'\n    else:\n        c = 'red'\n    for i, path in enumerate(image_paths):\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n        ax[i].set_title(f\"{cat} - {img.shape}\", color = c)\n        ax[i].imshow(img)\n        ax[i].grid(False)\n    plt.tight_layout()\n    plt.show()","110ae28a":"image_paths = np.random.choice(fresh, 9)\ndisplay_images(image_paths, 3, 3, 'Fresh')","0ab75795":"image_paths = np.random.choice(spoiled, 9)\ndisplay_images(image_paths, 3, 3, 'Spoiled')","3e335dd1":"df = pd.DataFrame(columns = ['image', 'target'])\ndf['image'] = fresh + spoiled\ndf['target'] = df['image'].apply(lambda x: 0 if 'Fresh' in x else 1)\ndf = df.sample(frac = 1).reset_index(drop = True)\nlabels = ['Fresh', 'Spoiled']\ndf.head()","cc7d4a94":"plt.title('Target Distribution', color = 'grey')\nsns.countplot(data = df, x = 'target');","4be42029":"print(tf.__version__)\nimport tensorflow.keras.layers as L\nfrom tensorflow.keras.utils import Sequence, to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import backend as K\n\nimport math","669c5302":"dim = 256\nseed = 2021\nEPOCHS = 30","dcb354ba":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nprint(BATCH_SIZE)\nAUTO = tf.data.experimental.AUTOTUNE","3dac73ea":"def display_training_curves(training, validation, title, subplot):\n    \"\"\"\n    Source: https:\/\/www.kaggle.com\/mgornergoogle\/getting-started-with-100-flowers-on-tpu\n    \"\"\"\n    if subplot % 10 == 1: # set up the subplots on the first call\n        plt.subplots(figsize = (10, 10), facecolor = '#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    #ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","755e7e53":"from tensorflow.keras.applications.densenet import DenseNet121","99fd04c3":"with strategy.scope():\n    model = tf.keras.Sequential([\n        DenseNet121(\n            input_shape = (dim, dim, 3),\n            weights = 'imagenet',\n            include_top = False),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(512, activation = 'elu', kernel_regularizer = regularizers.l2(0.001)),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(256, activation = 'elu', kernel_regularizer = regularizers.l2(0.001)),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(len(labels), activation = 'sigmoid')\n    ])\n    model.compile(\n        optimizer = tf.keras.optimizers.Adam(0.001),\n        loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n        metrics = ['accuracy']\n                )\n    model.summary()","f17209ff":"train_df, valid_df = train_test_split(df, test_size = 0.2, random_state = 42)\nprint(train_df.shape, valid_df.shape)","6c7311fb":"def decode_image(filename, label = None, image_size = (dim, dim)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels = 3)\n    image = tf.cast(image, tf.float32)\n    image \/= 255.0\n    image = tf.image.resize(image, image_size)\n    \n    if label is None:\n        return image\n    else:\n        return image, tf.one_hot(label, depth = len(labels))\n\ndef data_augment(image, label = None):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, 0.2)\n    image = tf.image.random_contrast(image, lower = 0.3, upper = 0.9)\n    \n    if label is None:\n        return image\n    else:\n        return image, label","4912150f":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_df['image'], train_df['target']))\n    .map(decode_image, num_parallel_calls = AUTO)\n    #.map(data_augment, num_parallel_calls = AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_df['image'], valid_df['target']))\n    .map(decode_image, num_parallel_calls = AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","2a80353b":"for t, l in train_dataset.take(1):\n    print(t.numpy().shape, l.numpy().shape)\n    break","f792866c":"def plot_dataset(dataset, row, col):\n    for (img, lbls) in dataset.take(1):\n        for i in range(row * col):\n            ax = plt.subplot(row, col, i + 1)\n            plt.imshow(img[i].numpy())\n            if labels[np.argmax(lbls[i].numpy())] == 'Fresh':\n                c = 'green'\n            else:\n                c = 'red'\n            plt.title(labels[np.argmax(lbls[i].numpy())], color = c)\n            plt.axis('off')\n            plt.grid(False)\n        plt.show()","143e9ddf":"plot_dataset(train_dataset, 3, 3)","4082b230":"check = tf.keras.callbacks.ModelCheckpoint('.\/meat_model.h5', monitor = 'val_loss', mode = 'min', save_best_only = True)\nearly = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 4, verbose = 1)\nreduce = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", patience = 3, factor = 0.1, mode = 'min', verbose = 1)\n\ncallback_list = [check, early]\n\nsteps_per_epoch = len(train_df) \/\/ BATCH_SIZE","d444b02e":"history = model.fit(\n                    train_dataset, \n                    epochs = 5,\n                    verbose = 1,\n                    callbacks = callback_list,\n                    steps_per_epoch = steps_per_epoch,\n                    validation_data = valid_dataset\n            )","69e2bfc0":"print('Evaluate Model....')\nev = model.evaluate(valid_dataset, return_dict = True)\nprint(ev)","5f812e6d":"del model, train_dataset, valid_dataset\ngc.collect()","4190c927":"display_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'Loss', 211)\ndisplay_training_curves(\n    history.history['accuracy'], \n    history.history['val_accuracy'], \n    'Accuracy', 212)","26b9eb8a":"with strategy.scope():\n    model = tf.keras.Sequential([\n        DenseNet121(\n            input_shape = (dim, dim, 3),\n            weights = 'imagenet',\n            include_top = False),\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(512, activation = 'elu', kernel_regularizer = regularizers.l2(0.001)),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(256, activation = 'elu', kernel_regularizer = regularizers.l2(0.001)),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(len(labels), activation = 'sigmoid')\n    ])\n    model.compile(\n        optimizer = tf.keras.optimizers.Adam(0.001),\n        loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n        metrics = [tf.keras.losses.BinaryCrossentropy(from_logits = True, \n                                                      name = 'BCE'), 'accuracy']\n                )\n    model.summary()","c5117835":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((train_df['image'], train_df['target']))\n    .map(decode_image, num_parallel_calls = AUTO)\n    .map(data_augment, num_parallel_calls = AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((valid_df['image'], valid_df['target']))\n    .map(decode_image, num_parallel_calls = AUTO)\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)","703991ef":"plot_dataset(train_dataset, 3, 3)","0e03edd3":"# Code Credits : https:\/\/www.kaggle.com\/cdeotte\/how-to-compete-with-gpus-workshop\n\nLR_START = 1e-8\nLR_MAX = 3e-5 * 9\nLR_MIN = 1e-8\nLR_RAMPUP_EPOCHS = 3\nLR_SUSTAIN_EPOCHS = 0\nN_CYCLES = .5\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) \/ LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        progress = (epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) \/ (EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)\n        lr = LR_MAX * (0.5 * (1.0 + tf.math.cos(math.pi * N_CYCLES * 2.0 * progress)))\n        if LR_MIN is not None:\n            lr = tf.math.maximum(LR_MIN, lr)\n            \n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n\nplt.figure(figsize = (8, 6))\nrng = [i for i in range(25 if EPOCHS < EPOCHS else EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","da07c411":"check = tf.keras.callbacks.ModelCheckpoint('.\/meat_det_model_.h5', monitor = 'val_binary_crossentropy', mode = 'min', save_best_only = True)\nearly = tf.keras.callbacks.EarlyStopping(monitor = 'val_binary_crossentropy', mode = 'min', patience = 4, verbose = 1)\nreduce = tf.keras.callbacks.ReduceLROnPlateau(monitor = \"val_binary_crossentropy\", patience = 3, factor = 0.1, mode = 'min', verbose = 1)\n\ncallback_list = [check, early]\n\nsteps_per_epoch = len(train_df) \/\/ BATCH_SIZE","68d1758f":"history = model.fit(\n                    train_dataset, \n                    epochs = EPOCHS,\n                    verbose = 1,\n                    callbacks = callback_list,\n                    steps_per_epoch = steps_per_epoch,\n                    validation_data = valid_dataset\n            )","67c5d5bf":"display_training_curves(\n    history.history['loss'], \n    history.history['val_loss'], \n    'Loss', 211)\ndisplay_training_curves(\n    history.history['accuracy'], \n    history.history['val_accuracy'], \n    'Accuracy', 212)","47861ff9":"display_training_curves(\n    history.history['BCE'], \n    history.history['val_BCE'], \n    'BCE', 211)","b4fe2bda":"print('Evaluate Model....')\nev = model.evaluate(valid_dataset, return_dict = True)\nprint(ev)","b89071ff":"preds = model.predict(valid_dataset, verbose = 1)\npreds[:5]","47bfa40f":"ytrue = valid_df['target'].values\nypred = np.argmax(preds, axis = 1)\nytrue[:5], ypred[:5]","a317d395":"from sklearn.metrics import classification_report, confusion_matrix\n\nc_mat = confusion_matrix(ytrue, ypred)\nc_report = classification_report(ytrue, ypred, target_names = labels)\n\nplt.figure(figsize = (8, 8))\nsns.heatmap(c_mat, annot = True, vmin = 0, fmt = 'g', cmap = 'GnBu_r', cbar = False)       \nplt.xticks(np.arange(len(labels)) + .5, labels, rotation = 0)\nplt.yticks(np.arange(len(labels))+.5, labels, rotation = 0)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()    ","8b15cdb4":"print(c_report)","5eaaf6bb":"vdf = valid_df.reset_index(drop = True)\nvdf.head(5)","372b7d76":"f, ax = plt.subplots(10, 3, figsize = (18, 30))\n\nfor idx, p in enumerate(ax.flatten()):\n    bits = tf.io.read_file(vdf['image'][idx])\n    image = tf.image.decode_jpeg(bits, channels = 3)\n    p.imshow(image.numpy())\n    if vdf['target'][idx] == ypred[idx]:\n        c = 'blue'\n    else:\n        c = 'red'\n    p.set_title(f\"True: {vdf['target'][idx]} Pred: {ypred[idx]} \\n {preds[idx]}\", color = c, fontsize = 10)\n    p.grid(False)\n    p.axis('off')\nplt.show()","87c5a3ae":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","2e92869f":"__Split dataset into traina and valid sets__","0e1a2ed8":"- Classes are balanced","85f650fc":"# Meat Quality Classification\n- Fresh\n- Spoiled","626be17f":"__Define Callback lists__","9897c4ad":"__DenseNet121 Model__","dd318461":"__Methods to prevent Overfitting__","832531df":"__Train Dataset Images without Augmentation__","05741dec":"# Display few Images from Fresh Category","1f5be55e":"__We use Image augmentation__\n- To increase the train size \n- To prevent overfitting, which is likely given the limited number of samples","571ca60f":"- Our Model is clearly overfitting, the reason being few sample size.\n- We will try to prevent overfitting with image augmentation as well as Learning Rate Scheduler\n- We also change the metrics to BinaryCrossEntropy\n- Doing this should help our model","430d0cfa":"__Helper Function to display training plots__","f7642c01":"# Display few Images from Spoiled Category","2626452e":"__Train Dataset Images with Augmentation__","87a0e78a":"__Make a Dataframe of image path and class__","5b5e9266":"- Images are of same shape: (720, 1280, 3)\n- All these images are of same batch taken at different time intervals, I don't think a model will generalise well to other unseen images"}}