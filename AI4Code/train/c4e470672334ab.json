{"cell_type":{"0ded5ffd":"code","a6083ba7":"code","c568ff50":"code","449d9b5a":"code","a9ddc39d":"code","33d8e6a4":"code","3d5feb0a":"code","d4268031":"code","0cd5b8a4":"markdown","f967f6a1":"markdown","55e4f340":"markdown","1248cdc1":"markdown","3ab2c866":"markdown","5034f8e9":"markdown","6fc9dd88":"markdown"},"source":{"0ded5ffd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nimport gc\nimport time\nfrom contextlib import contextmanager","a6083ba7":"@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))","c568ff50":"def data_preprocessing():\n\n    print(\"Data Preprocessing Process Has Been Started\" \"\\n\")\n\n    train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n    test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\n    train = train.drop(['Ticket'], axis = 1)\n    test = test.drop(['Ticket'], axis = 1)\n\n    train['Fare'] = train['Fare'].replace(512.3292, 300)\n    test['Fare'] = test['Fare'].replace(512.3292, 300)\n\n    train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n    test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n\n    # Fill NA with the most frequent value:\n    train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n    test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")\n\n    test[\"Fare\"] = test[\"Fare\"].fillna(12)\n\n    train[\"CabinBool\"] = train[\"Cabin\"].notnull().astype('int')\n    test[\"CabinBool\"] = test[\"Cabin\"].notnull().astype('int')\n\n    train = train.drop(['Cabin'], axis = 1)\n    test = test.drop(['Cabin'], axis = 1)\n\n    # Map each Embarked value to a numerical value:\n\n    embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\n    train['Embarked'] = train['Embarked'].map(embarked_mapping)\n    test['Embarked'] = test['Embarked'].map(embarked_mapping)\n\n\n    lbe = preprocessing.LabelEncoder()\n\n\n    train[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\n    test[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])\n\n    train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    test[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n    train['Title'] = train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    train['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    train['Title'] = train['Title'].replace('Mlle', 'Miss')\n    train['Title'] = train['Title'].replace('Ms', 'Miss')\n    train['Title'] = train['Title'].replace('Mme', 'Mrs')\n\n\n    test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    test['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    test['Title'] = test['Title'].replace('Mlle', 'Miss')\n    test['Title'] = test['Title'].replace('Ms', 'Miss')\n    test['Title'] = test['Title'].replace('Mme', 'Mrs')\n\n    # Map each of the title groups to a numerical value\n\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n    train['Title'] = train['Title'].map(title_mapping)\n    test['Title'] = test['Title'].map(title_mapping)\n\n    train = train.drop(['Name'], axis = 1)\n    test = test.drop(['Name'], axis = 1)\n\n\n    bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\n\n    mylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n\n\n    train['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\n    test['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)\n\n\n    # Map each Age value to a numerical value:\n    age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\n    train['AgeGroup'] = train['AgeGroup'].map(age_mapping)\n    test['AgeGroup'] = test['AgeGroup'].map(age_mapping)\n\n    #dropping the Age feature for now, might change:\n    train = train.drop(['Age'], axis = 1)\n    test = test.drop(['Age'], axis = 1)\n\n    # Map Fare values into groups of numerical values:\n    train['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\n    test['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])\n\n    # Drop Fare values:\n    train = train.drop(['Fare'], axis = 1)\n    test = test.drop(['Fare'], axis = 1)\n\n    print(\"Data Preprocessing Process Has Been Finished\" \"\\n\")\n    \n    return train, test","449d9b5a":"def feature_engineering(train, test):\n\n    print(\"Feature Engineering Process Has Been Started\" \"\\n\")\n\n    train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n    test[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n\n    # Create new feature of family size:\n\n    train['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    train['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n    train['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n    train['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n    # Create new feature of family size:\n\n    test['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    test['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n    test['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n    test['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n\n    # Convert Title and Embarked into dummy variables:\n\n    train = pd.get_dummies(train, columns = [\"Title\"], drop_first = True)\n    train = pd.get_dummies(train, columns = [\"Embarked\"], drop_first = True, prefix=\"Em\")\n\n    test = pd.get_dummies(test, columns = [\"Title\"], drop_first = True)\n    test = pd.get_dummies(test, columns = [\"Embarked\"], drop_first = True, prefix=\"Em\")\n\n    # Create categorical values for Pclass:\n    train[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\n    train = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")\n\n    test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\n    test = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")\n\n    print(\"Feature Engineering Process Has Been Finished\" \"\\n\")\n    \n    \n    return train, test","a9ddc39d":"def modeling(train):\n\n    print(\"Modeling Process Has Been Started:\" \"\\n\")\n\n    X = train.drop(['Survived', 'PassengerId'], axis=1)\n    Y = train[\"Survived\"]\n\n    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state = 17)\n\n    from sklearn.ensemble import GradientBoostingClassifier\n\n    gbm = GradientBoostingClassifier()\n\n    gbm_params = {\n            'n_estimators': [200, 500],\n            'subsample': [1.0],\n            'max_depth': [8],\n            'learning_rate': [0.01,0.02],\n            \"min_samples_split\": [10]}\n\n    gbm_cv_model = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 5)\n\n    gbm_cv_model.fit(x_train, y_train)\n\n    print(gbm_cv_model.best_params_ , \"\\n\")\n\n    gbm_tuned = GradientBoostingClassifier(learning_rate = gbm_cv_model.best_params_[\"learning_rate\"], \n                        max_depth = gbm_cv_model.best_params_[\"max_depth\"],\n                        min_samples_split = gbm_cv_model.best_params_[\"min_samples_split\"],\n                        n_estimators = gbm_cv_model.best_params_[\"n_estimators\"],\n                        subsample = gbm_cv_model.best_params_[\"subsample\"])\n\n    gbm_tuned.fit(x_train, y_train)\n\n    y_pred = gbm_tuned.predict(x_test)\n    print(\"Accuracy Score of Your Model:\")\n    print(round(accuracy_score(y_pred, y_test) * 100, 2))\n    \n    return gbm_tuned\n","33d8e6a4":"def submission(gbm_tuned, test):\n\n    #set ids as PassengerId and predict survival \n    ids = test['PassengerId']\n\n    predictions = gbm_tuned.predict(test.drop('PassengerId', axis=1))\n\n    #set the output as a dataframe and convert to csv file named submission.csv\n    output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n    \n    output.to_csv('submission.csv', index=False)\n    print(\"Submission file has been created\")","3d5feb0a":"def main():\n    \n    with timer(\"Pre processing Time\"):\n        train, test = data_preprocessing()\n    \n    with timer(\"Feature Engineering\"):\n        train, test = feature_engineering(train, test)\n        \n    with timer(\"Modeling\"):\n        gbm_tuned = modeling(train)\n        \n    with timer(\"Submission\"):\n        submission(gbm_tuned, test)    ","d4268031":"if __name__ == \"__main__\":\n    with timer(\"Full model run\"):\n        main()","0cd5b8a4":"# Data Preprocessing","f967f6a1":"# Deployment","55e4f340":"# Modeling","1248cdc1":"# Libraries","3ab2c866":"# Helper Functions","5034f8e9":"# Feature Engineering","6fc9dd88":"# Main"}}