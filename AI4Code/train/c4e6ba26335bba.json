{"cell_type":{"f7762f87":"code","7819d0d7":"code","e1c9c0d9":"code","b261c26a":"code","905b496f":"code","19c1a23f":"code","9c2961b9":"code","073229d5":"code","c54494df":"code","290dead9":"code","c99c25c7":"code","b2a267ea":"code","edd1c158":"code","7b87dbd8":"code","06b65523":"code","ad4dd6c2":"code","bf6d9252":"code","b9185a9a":"code","57a3f2ef":"code","18f5f7e1":"code","3252d1d0":"code","c3cfcb38":"code","c9318e1f":"code","4fe359c0":"code","5698aca5":"code","8bc25c67":"code","f2da325e":"code","6645820f":"code","c900b47c":"code","f118f5a1":"code","5027ab84":"code","36a2531f":"code","39d71285":"code","9dba3272":"code","71e0ded2":"code","578eab83":"code","a5568ab2":"code","99b691e6":"code","73a9557d":"code","8af4f144":"code","16f62b86":"code","e4eaa95e":"code","2fdcb7d3":"code","16f90ca7":"code","7abc76fc":"code","a4334c79":"code","35849599":"code","115d29ac":"code","1821dc3a":"code","15de2d83":"markdown","15263633":"markdown","e7c5ec9d":"markdown","fd1ee004":"markdown","88bda7b5":"markdown","51a002d6":"markdown","d605f3cc":"markdown","70c272f9":"markdown","1179fb0d":"markdown","9c4c8c16":"markdown","e250f1af":"markdown","23b620ca":"markdown","f376268c":"markdown","25bda9f9":"markdown","7a5e6eb1":"markdown","41c1c254":"markdown","3b620185":"markdown","4571daf7":"markdown","cff3f96b":"markdown","2a6fa0ee":"markdown","ceda1122":"markdown","247882cf":"markdown","52798971":"markdown","40b35325":"markdown","a2bb21c0":"markdown","79c6cf2b":"markdown","43eecc3e":"markdown","8928cee3":"markdown","f5a542b6":"markdown","578f0a49":"markdown","a6e6dcd2":"markdown","d10908e9":"markdown","6d0c080c":"markdown","f44e005b":"markdown","27186635":"markdown","c0a1e201":"markdown","20e17775":"markdown","1c2b1fca":"markdown","95148b50":"markdown","9872cf7f":"markdown","d8936063":"markdown","0b8d9640":"markdown","1f8dd80f":"markdown","9754b791":"markdown","df4810ff":"markdown","ac701456":"markdown","cbe581b6":"markdown","3ff041ed":"markdown","88598db5":"markdown","a01f4307":"markdown","161b4b94":"markdown","45d75edf":"markdown","4288f5ef":"markdown","81b76cd1":"markdown","b974ba0b":"markdown"},"source":{"f7762f87":"# Importing the Libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport plotly.figure_factory as ff\nimport plotly.graph_objs as go\nimport plotly\nfrom wordcloud import WordCloud, STOPWORDS\n\n\nimport json\nfrom datetime import datetime","7819d0d7":"# Getting our data\n\nyoutube = pd.read_csv(\"..\/input\/youtube-new\/INvideos.csv\")","e1c9c0d9":"youtube.head()","b261c26a":"print(\"Number of rows in data :\",youtube.shape[0])\nprint(\"Number of columns in data :\", youtube.shape[1])","905b496f":"youtube.columns","19c1a23f":"print(youtube.nunique())","9c2961b9":"youtube.info()","073229d5":"temp = youtube.copy() # creating a copy just in case","c54494df":"youtube[youtube.description.isnull()].head()","290dead9":"desc = youtube['description'].isnull().sum()\/(len(youtube))*100\n\nprint(f\"Description column has {desc.round(2)}% null values.\")","c99c25c7":"# Replacing all the NaN values to a empty string\n\nyoutube[\"description\"] = youtube[\"description\"].fillna(value=\"\")","b2a267ea":"# Making format of date and time better\n\nyoutube.trending_date = pd.to_datetime(youtube.trending_date, format='%y.%d.%m')\nyoutube.publish_time = pd.to_datetime(youtube.publish_time, format='%Y-%m-%dT%H:%M:%S.%fZ')\nyoutube.category_id = youtube.category_id.astype(str)\n\nyoutube.head()","edd1c158":"# creating a new category column by loading json \n\nid_to_category = {}\n\nwith open('..\/input\/youtube-new\/IN_category_id.json' , 'r') as f:\n    data = json.load(f)\n    for category in data['items']:\n        id_to_category[category['id']] = category['snippet']['title']\n        \nyoutube['category'] = youtube['category_id'].map(id_to_category)","7b87dbd8":"youtube.head()","06b65523":"# Looking at each category and number of unique values\n\nyoutube['category'].value_counts()","ad4dd6c2":"zero_dislikes = len(youtube.dislikes)-youtube.dislikes.astype(bool).sum(axis=0)\nzero_likes = len(youtube.likes)-youtube.likes.astype(bool).sum(axis=0)\n\nprint(f\"There are {zero_likes} videos with 0 likes.\")\nprint(f\"There are {zero_dislikes} videos with 0 dislikes.\")","bf6d9252":"# this will hold all the ratios\nlikes_dislikes = {}\n\nfor i in range(len(youtube['likes'])):\n    \n    # if the value of dislikes is not zero\n    if youtube['dislikes'][i]!=0:\n        \n        # compute the ratio\n        likes_dislikes[i]=youtube['likes'][i]\/youtube['dislikes'][i]\n        \n    else:\n        \n        # simply use the likes value\n        likes_dislikes[i]=youtube['likes'][i]\n        \nyoutube['likes_dislikes_ratio'] = likes_dislikes.values()","b9185a9a":"youtube.head()","57a3f2ef":"print(f\"Does the data contain duplicate video_ids? - {youtube.video_id.duplicated().any()}\")","18f5f7e1":"print(f\"Before Deduplication : {youtube.shape}\")\nyoutube = youtube[~youtube.video_id.duplicated(keep='last')]\nprint(f\"After Deduplication : {youtube.shape}\")\n\nprint(f\"Does the data contain duplicate video_ids now? - {youtube.video_id.duplicated().any()}\")","3252d1d0":"# Creating a custom formatter for pandas describe function\n\nimport contextlib\nimport numpy as np\nimport pandas as pd\nimport pandas.io.formats.format as pf\nnp.random.seed(2015)\n\npd.set_option('display.max_colwidth', 100)\n\n@contextlib.contextmanager\ndef custom_formatting():\n    orig_float_format = pd.options.display.float_format\n    orig_int_format = pf.IntArrayFormatter\n\n    pd.options.display.float_format = '{:0,.2f}'.format\n    class IntArrayFormatter(pf.GenericArrayFormatter):\n        def _format_strings(self):\n            formatter = self.formatter or '{:,d}'.format\n            fmt_values = [formatter(x) for x in self.values]\n            return fmt_values\n    pf.IntArrayFormatter = IntArrayFormatter\n    yield\n    pd.options.display.float_format = orig_float_format\n    pf.IntArrayFormatter = orig_int_format\n\nwith custom_formatting():\n    print(youtube[['views','likes','dislikes','comment_count']].describe())","c3cfcb38":"# Plotting the Heatmap of the columns using correlation matrix\n\nf,ax = plt.subplots(figsize=(20, 10))\nsns.heatmap(youtube.corr(), annot=True, linewidths=0.5,linecolor=\"red\",ax=ax)\nplt.show()","c9318e1f":"# Extracting the year from the 'trending date' and converting to a list\nvideo_by_year = temp[\"trending_date\"].apply(lambda x: '20' + x[:2]).value_counts().tolist()","4fe359c0":"# Plotting a pie chart for number of videos by year\n\nlabels = ['2017','2018']\nvalues = [video_by_year[1],video_by_year[0]]\ncolors = ['turquoise', 'royalblue']\n\ntrace = go.Pie(labels=labels, values=values, textinfo='value', \n               textfont=dict(size=20),\n               marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nplotly.offline.iplot([trace], filename='styled_pie_chart')","5698aca5":"def plot_distributions(col, i, colors):\n\n    column_name = col+'_log'\n    youtube[column_name] = np.log(youtube[col] + 1)\n\n    group_labels = [column_name]\n    hist_data = [youtube[column_name]]\n    \n    colors = [colors]\n\n    # Create distplot with curve_type set to 'normal'\n    fig = ff.create_distplot(hist_data, group_labels = group_labels, colors=colors,\n                             bin_size=0.1, show_rug=False)\n\n    # Add title\n    title_dict = {1:'Views', 2:'Likes', 3:'Dislikes', 4:'Likes and Dislikes Ratio', 5:'Comment Count'}\n    fig.update_layout(width=700, title_text= title_dict[i]+' Log Distribution')\n    fig.show()","8bc25c67":"columns_list = ['views', 'likes', 'dislikes', 'likes_dislikes_ratio', 'comment_count']\ncolors = ['coral', 'darkmagenta', 'green', 'red', 'blue']\n\nfor i in range(0,5):\n    plot_distributions(columns_list[i], i+1, colors[i])","f2da325e":"one_mil = youtube[youtube['views'] > 1000000]['views'].count() \/ youtube['views'].count() * 100\n\nprint(f\"Only {round(one_mil, 2)}% videos have more than 1 Million views.\")","6645820f":"hundered_k = youtube[youtube['likes'] > 100000]['likes'].count() \/ youtube['likes'].count() * 100\n\nprint(f\"Only {round(hundered_k, 2)}% videos have more than 1OOK Likes.\")","c900b47c":"five_k = youtube[youtube['dislikes'] > 5000]['dislikes'].count() \/ youtube['dislikes'].count() * 100\n\nprint(f\"Only {round(five_k, 2)}% videos have more than 5K Dislikes.\")","f118f5a1":"five_k = youtube[youtube['comment_count'] > 5000]['comment_count'].count() \/ youtube['comment_count'].count() * 100\n\nprint(f\"Only {round(five_k, 2)}% videos have more than 5K Comments.\")","5027ab84":"most_likes = youtube.loc[youtube[['views']].idxmax()]['title']\nmost_views = youtube.loc[youtube[['likes']].idxmax()]['title']\nmost_dislikes = youtube.loc[youtube[['dislikes']].idxmax()]['title']\nmost_comments = youtube.loc[youtube[['comment_count']].idxmax() ]['title']\n\nprint(f\"Most Viewed Video : {most_likes.to_string(index=False)}\\n\")\nprint(f\"Most Liked Video : {most_views.to_string(index=False)}\\n\")\nprint(f\"Most Disliked Video : {most_dislikes.to_string(index=False)}\\n\")\nprint(f\"Video with most comments : {most_comments.to_string(index=False)}\")","36a2531f":"most_likes_ratio = youtube.loc[youtube[['likes_dislikes_ratio']].idxmax() ]['title']\n\nprint(f\"Video with highest likes ratio : {most_likes_ratio.to_string(index=False)}\\n\")","39d71285":"# category had the largest number of trending videos\n\nCategory = youtube.category.value_counts().index\nCount = youtube.category.value_counts().values\n\nfig = px.bar(youtube, x=Category, y=Count, labels={'x':'Category', 'y' : 'Number of Videos'})\n\nfig.update_traces(marker_color='mistyrose', marker_line_color='darkmagenta',\n                  marker_line_width=1.5)\n\nfig.update_layout(title_text='Video Per Category')\nfig.show()","9dba3272":"# Plotting a pie chart for top 10 channels with most trending videos\n\nx = youtube.channel_title.value_counts().head(10).index\ny = youtube.channel_title.value_counts().head(10).values\n\ntrace = go.Pie(labels=x, values=y, textinfo='value', \n               textfont=dict(size=20),\n               marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nplotly.offline.iplot([trace], filename='styled_pie_chart')","71e0ded2":"sort_by_views = youtube.sort_values(by=\"views\" , ascending = False)\n\nTitle = sort_by_views['title'].head(10)\nViews = sort_by_views['views'].head(10)\n\nfig = px.bar(youtube, x=Title, y=Views, labels={'x':'Title', 'y' : 'Number of views'})\n\nfig.update_traces(marker_color='gold', marker_line_color='darkmagenta',\n                  marker_line_width=1.5)\n\nfig.update_layout(title_text='Top 10 Most Watched Videos')\nfig.show()","578eab83":"sort_by_likes = youtube.sort_values(by =\"likes\" , ascending = False)\n\nTitle = sort_by_likes['title'].head(10)\nLikes = sort_by_likes['likes'].head(10)\n\nfig = px.bar(youtube, x=Title, y=Likes, labels={'x':'Title', 'y' : 'Number of Likes'})\n\nfig.update_traces(marker_color='dodgerblue', marker_line_color='olive',\n                  marker_line_width=2.5)\n\nfig.update_layout(title_text='Top 10 Most Liked Videos')\nfig.show()","a5568ab2":"sort_by_dislikes = youtube.sort_values(by = \"dislikes\" , ascending = False)\n\nTitle = sort_by_dislikes['title'].head(10)\nDislikes = sort_by_dislikes['dislikes'].head(10)\n\nfig = px.bar(youtube, x=Title, y=Dislikes, labels={'x':'Title', 'y' : 'Number of Dislikes'})\n\nfig.update_traces(marker_color='tomato', marker_line_color='#000000',\n                  marker_line_width=1.5)\n\nfig.update_layout(title_text='Top 10 Most Disliked Videos',width=1200,\n    height=800)\nfig.show()","99b691e6":"sort_by_comments = youtube.sort_values(by = \"comment_count\" , ascending = False)\n\nTitle = sort_by_comments['title'].head(10)\nComments = sort_by_comments['comment_count'].head(10)\n\nfig = px.bar(youtube, x=Title, y=Comments, labels={'x':'Title', 'y' : 'Number of Comments'})\n\nfig.update_traces(marker_color='papayawhip', marker_line_color='darkblue',\n                  marker_line_width=2.5)\n\nfig.update_layout(title_text='Top 10 Videos with Most Comments',width=950,\n    height=700)\nfig.show()","73a9557d":"sort_by_ldr = youtube.sort_values(by = \"likes_dislikes_ratio\" , ascending = False)\n\nTitle = sort_by_ldr['title'].head(10)\nComments = sort_by_ldr['likes_dislikes_ratio'].head(10)\n\nfig = px.bar(youtube, x=Title, y=Comments, labels={'x':'Title', 'y' : 'Like\/Dislike'})\n\nfig.update_traces(marker_color='cyan', marker_line_color='darkred',\n                  marker_line_width=2.5)\n\nfig.update_layout(title_text='Top 10 Videos with Most Like to Dislike Ratio',width=1100, height = 800)\nfig.show()","8af4f144":"# Utility Function for creating word cloud\n\ndef createwordcloud(data, bgcolor, title):\n    plt.figure(figsize=(15,10))\n    wc = WordCloud(width=1200, height=500, \n                         collocations=False, background_color=bgcolor, \n                         colormap=\"tab20b\").generate(\" \".join(data))\n    plt.imshow(wc, interpolation='bilinear')\n    plt.title(title)\n    plt.axis('off')","16f62b86":"# WordCloud for Title Column\n\ntitle = youtube['title']\ncreatewordcloud(title , 'black' , 'Commonly used words in Titles')","e4eaa95e":"# WordCloud for Description Column\n\ndescription = youtube['description'].astype('str')\ncreatewordcloud(description , 'black' , 'Commonly used words in Description')","2fdcb7d3":"# WordCloud for Tags Column\n\n\ntags = youtube['tags'].astype('str')\ncreatewordcloud(tags , 'black' , 'Commonly used words in Tags')","16f90ca7":"youtube['publish_date'] = pd.to_datetime(youtube['publish_time'])\nyoutube['difference'] = (youtube['trending_date'] - youtube['publish_date']).dt.days","7abc76fc":"fig = px.bar(youtube, x=youtube['trending_date'], y=youtube['views'], labels={'x':'Trending Date', 'y' : 'Number of Views'})\n\nfig.update_traces(marker_color='darkred', marker_line_color='#000000',\n                  marker_line_width=0.5)\n\nfig.update_layout(title_text='Trending Date VS Number of Views')\nfig.show()","a4334c79":"error_or_removed = youtube[\"video_error_or_removed\"].value_counts().tolist()\n\nlabels = ['No','Yes']\nvalues = [error_or_removed[0],error_or_removed[1]]\ncolors = ['orange', 'yellow']\n\ntrace = go.Pie(labels=labels, values=values, textinfo='value', \n               textfont=dict(size=20),\n               marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nplotly.offline.iplot([trace], filename='styled_pie_chart')","35849599":"error_or_removed = youtube[\"comments_disabled\"].value_counts().tolist()\n\nlabels = ['No','Yes']\nvalues = [error_or_removed[0],error_or_removed[1]]\ncolors = ['pink', 'purple']\n\ntrace = go.Pie(labels=labels, values=values, textinfo='value', \n               textfont=dict(size=20),\n               marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nplotly.offline.iplot([trace], filename='styled_pie_chart')","115d29ac":"error_or_removed = youtube[\"ratings_disabled\"].value_counts().tolist()\n\nlabels = ['No','Yes']\nvalues = [error_or_removed[0],error_or_removed[1]]\ncolors = ['khaki', 'olive']\n\ntrace = go.Pie(labels=labels, values=values, textinfo='value', \n               textfont=dict(size=20),\n               marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nplotly.offline.iplot([trace], filename='styled_pie_chart')","1821dc3a":"youtube[(youtube[\"comments_disabled\"] == True) & (youtube[\"ratings_disabled\"] == True)]['category'].value_counts()","15de2d83":"**Looks like youtube won in their own game! XD**","15263633":"### Video Title","e7c5ec9d":"# Data Cleaning","fd1ee004":"# Visualization of Text Features\n\n**Let's create a WordCloud for the text features of (video title, description and tags), which is a way to visualize most common words in the titles; the more common the word is, the bigger its font size is.**","88bda7b5":"### Distribution of Log of Continous variables\n\n**The reason for choosing log distribution is beacause it is very hard to get insights from normal number as they are very large so you will just a large peak. So, taking log will scale it to lower values to analyse it better!**","51a002d6":"**I am still not statisfied with the data because I personally like to look at likes and dislikes beacuse what If we have a lot of likes but also a lot of dislikes? So, Is there anything which can quantify both of them at the same time? Yes!!**\n\n**Let's create a new column 'likes_dislikes_ratio' and note that there can be vids with 0 dislikes and likes so we will have to handle that to avoid odd values**","d605f3cc":"### Category","70c272f9":"### Likes","1179fb0d":"**That is a very close math between all the channels! This wasn't very insignful so let's move on to doing a top 10 of all the continous features - Views, Likes, Dislikes etc. Believe me it will be a lot of fun!**","9c4c8c16":"### Dislikes","e250f1af":"**Awesome! Now, let's see what video categories do we have in our data.**","23b620ca":"**A number of videos can appear multiple times in our dataset, as they were trending across multiple days. Thus, we will remove these duplicated entries for now, and only keep the last entry of each video, as that entry will be the most recent statistic.**","f376268c":"**Let's look at some of the rows of our data.**","25bda9f9":"**Trending videos in category of Eduction, News & Politics, Entertainment and People & Blogs have the most number of such videos. I am not sure why they have disabled comments in Eductional videos because views might have some doubts!**","7a5e6eb1":"## Single Variate Statistics\n\n**Let's look at how many percentage of trending videos got more than certain number of views, likes, dislikes etc.**","41c1c254":"**Finally, let's get some of the information about our data.**","3b620185":"### Time and Date Column Analysis\n\n**To analyse this time series feature we will find the difference between the time a video was trending and the video was published and plot it against the number of views. It will tell us how the views vary day by day after a video is published.**","4571daf7":"## Trending Videos with Ratings Disabled","cff3f96b":"**So, if we have any zero in denominator(dislikes) then we will keep the its value same as number of likes and if we don't then we will calculate the ratio.** ","2a6fa0ee":"**Let's look at the number of rows and columns in our data.**","ceda1122":"**Entertainment category contains the largest number of trending videos among other categories with around ~7600 videos, followed by News & Politics with 2505 videos, followed by People&Blogs category with around 1232 videos, and so on.**","247882cf":"### Tags","52798971":"> TASKS FOR YOU\n\n(I) Provide suggestion, improvements and Criticism! (if any) :)\n\n(II) Please do Upvote if you want to see more content like this!","40b35325":"**Notice that we didn't get Youtube Rewind as the answer in case of maximum likes and dislike ratio. So, it was indeed a useful feature and we did a great job adding it!**","a2bb21c0":"**OBSERVATION**\n\n**The results were predictable. Most of the youtube videos have profile links in their description section to increase reachibility among viewers which explains the abundance of words like twitter, facebook etc. Also, https is in the link of these links itself so it is ultimately the most used word.**","79c6cf2b":"### Most Viewed, Liked, Disliked and Commented Videos","43eecc3e":"**Most of the work is done so now we are left with a time feature and three binary categorical features. So, let's start with the time feature which is very interesting!**","8928cee3":"**Let's look at the descriptive properties of the data**\n\n**I don't like to look at large scientific notations and float values when they are not. So, here I am using a custom formatter to make the values look a bit nicer. If you don't understand this code, it is fine.**","f5a542b6":"**OBSERVATIONS**\n\n(I) Half of the videos in our dataset have:\n<ul>\n    <li>Views greater than 205k.<\/li>\n    <li>Likes greater than ~1700.<\/li>\n    <li>Dislikes greater than 194.<\/li>\n    <li>Comments greater than 195.<\/li>\n<\/ul>\n\n(II)<ul>\n    <li>Maximum Views = 125,432,237<\/li>\n    <li>Maximum Likes = 2,912,710<\/li>\n    <li>Maximum Dislikes = 1,545,017<\/li>\n    <li>Maximum Comments = 807,558<\/li>\n<\/ul>","578f0a49":"**Much better! But if we want to watch a video we don't refer to with categoryID 5 but rather using a category. So, why not our data can do this? Let's create a new column 'category' using our json file which contains categories for each ID and map both of them.** ","a6e6dcd2":"## Top 10 for each Continous Feature","d10908e9":"**Now, let's see what columns are there in our data.**","6d0c080c":"**OBSERVATION**\n\n**Episodes is the most popular word along with full, song and new. These all are related to Entertainment which makes sense as it is the category with most number of trending videos.**","f44e005b":"**We can easily notice that all columns except the 'description' have non-null values so let's do a sanity check!**","27186635":"### Comments","c0a1e201":"# Visualizations of Continous Features","20e17775":"### What are the categories with largest number of trending videos?","1c2b1fca":"**OBSERVATIONS**\n\n**All of the continous distributions are close are log-normal which is very common when studying internet based data like views, dwell time of a user etc. For more read visit this [link](https:\/\/www.wikiwand.com\/en\/Log-normal_distribution#Occurrence_and_applications).**","95148b50":"### Number of videos by year","9872cf7f":"# THANKS FOR READING!","d8936063":"**Thanks to Plotly's Awesome Interactive Visualization, it is very easy to drive insights from above drawn plots.**","0b8d9640":"**OBSERVATION**\n\n**Most used tags are video, new, latest, song, show, movie and serial which are related to Entertainment category so this means that tags used by channels are pretty relatable to the title and aren't just anything.**","1f8dd80f":"**Let's look at the number of unique values in each column.**","9754b791":"### Description","df4810ff":"## Trending Videos with Comments Disabled","ac701456":"**OBSERVATION**\n\n**Looks like in between December 2017 and January 2018 there was a significant increase in the number of views which is might be because a lot of youtubers publish their summary of the year videos which views like to watch a lot as it summarises the whole past year.**\n\n**Also, there is 3 days gap in Jan and 7 Days gap in April.**","cbe581b6":"### Views","3ff041ed":"**Indeed, the some channels did not even bother to write a description of their video or maybe this is just a data collection fault.**","88598db5":"### Note: I chose to do EDA On Youtube Statistics of India. To perform EDA on any other country's dataset, just replace the file name and enjoy!","a01f4307":"## Trending Videos having Errors\n\n**Let's see how many trending videos got removed or had some error, we can use video_error_or_removed column in the dataset.**","161b4b94":"**I don't know if you can notice, but the time and date columns looks odd and verbose! Especially the time column. So, let's clean them and make them readable by parsing it using datetime module function to_datetime.**","45d75edf":"### Trending videos with both Comments and Ratings Disabled","4288f5ef":"**Thus, in our data, ~76% of the videos are from 2018 and only 24% are from 2017.**","81b76cd1":"### Like and Dislike Ratio","b974ba0b":"**Let's change the description to something which can describe that description is indeed empty. - We will replace the description with an empty string.**"}}