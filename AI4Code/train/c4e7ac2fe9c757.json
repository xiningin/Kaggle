{"cell_type":{"687967b9":"code","6cbede10":"code","a39e69c6":"code","6ce20ec3":"code","1bbffac1":"markdown","cb9c9c25":"markdown","d6eb38c7":"markdown","c65020b5":"markdown","f7ba3240":"markdown","ac6df90d":"markdown","f63e0035":"markdown","5b6777b7":"markdown","60bf3074":"markdown"},"source":{"687967b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint()\nprint(os.listdir('..\/input'))\n\n\n# Any results you write to the current directory are saved as output.\n","6cbede10":"# Reading image with OpenCV library\n# In this way image is opened already as numpy array\n# WARNING! OpenCV by default reads images in BGR format\nimage_BGR = cv2.imread('..\/input\/traffic-signs-dataset-in-yolo-format\/ts\/ts\/00001.jpg')\n\n# Showing image shape\nprint('Image shape:', image_BGR.shape)  # tuple of (800, 1360, 3)\n\n# Getting spatial dimension of input image\nh, w = image_BGR.shape[:2]  # Slicing from tuple only first two elements\n\n# Showing height an width of image\nprint('Image height={0} and width={1}'.format(h, w))  # 800 1360\n","a39e69c6":"# Reading annotation txt file that has bounding boxes coordinates in YOLO format\nwith open('..\/input\/traffic-signs-dataset-in-yolo-format\/ts\/ts\/00001.txt') as f:\n    # Preparing list for annotation of BB (bounding boxes)\n    lst = []\n    for line in f:\n        lst += [line.rstrip()]\n        print(line)\n\n# Going through all BB\nfor i in range(len(lst)):\n    # Getting current bounding box coordinates, its width and height\n    bb_current = lst[i].split()\n    x_center, y_center = int(float(bb_current[1]) * w), int(float(bb_current[2]) * h)\n    box_width, box_height = int(float(bb_current[3]) * w), int(float(bb_current[4]) * h)\n    \n    # Now, from YOLO data format, we can get top left corner coordinates\n    # that are x_min and y_min\n    x_min = int(x_center - (box_width \/ 2))\n    y_min = int(y_center - (box_height \/ 2))\n\n    # Drawing bounding box on the original image\n    cv2.rectangle(image_BGR, (x_min, y_min), (x_min + box_width, y_min + box_height), [172 , 10, 127], 2)\n\n    # Preparing text with label and confidence for current bounding box\n    class_current = 'Class: {}'.format(bb_current[0])\n\n    # Putting text with label and confidence on the original image\n    cv2.putText(image_BGR, class_current, (x_min, y_min - 5), cv2.FONT_HERSHEY_COMPLEX, 0.7, [172 , 10, 127], 2)\n    ","6ce20ec3":"%matplotlib inline\n\n# Plotting this example\n# Setting default size of the plot\nplt.rcParams['figure.figsize'] = (15, 15)\n\n# Initializing the plot\nfig = plt.figure()\n\nplt.imshow(cv2.cvtColor(image_BGR, cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.title('Image 00003.jpg with Traffic Signs', fontsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('example.png')\nplt.close()","1bbffac1":"# \ud83d\uddbc\ufe0f Showing Image ***00001.jpg*** with Detected Traffic Signs","cb9c9c25":"# \ud83c\udf93 Related course for classification tasks","d6eb38c7":"# \ud83d\udce5 Importing needed libraries","c65020b5":"**Design**, **Train** & **Test** deep CNN for Image Classification.\n\n**Join** the course & enjoy new opportunities to get deep learning skills:\n\n\n[https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/](https:\/\/www.udemy.com\/course\/convolutional-neural-networks-for-image-classification\/?referralCode=12EE0D74A405BF4DDE9B)\n\n\n![](https:\/\/github.com\/sichkar-valentyn\/1-million-images-for-Traffic-Signs-Classification-tasks\/blob\/main\/images\/slideshow_classification.gif?raw=true)","f7ba3240":"# \u26d4\ufe0f Example of Traffic Signs' Images with Bounding Boxes' Annotations in YOLO format","ac6df90d":"# \ud83c\udf93 Related course for detection tasks","f63e0035":"**Training YOLO v3 for Objects Detection with Custom Data.** *Build your own detector by labelling, training and testing on image, video and in real time with camera.* **Join** here: [https:\/\/www.udemy.com\/course\/training-yolo-v3-for-objects-detection-with-custom-data\/](https:\/\/www.udemy.com\/course\/training-yolo-v3-for-objects-detection-with-custom-data\/?referralCode=A283956A57327E37DDAD)\n\nDetections on video are shown below. **Trained weights** for detection tasks can be found in the course mentioned above.\n![Detections on Video](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-user-content\/o\/inbox%2F3400968%2F11bee8c0918c092b7d256b5254ba441c%2Fts_detections.gif?generation=1581794210627123&alt=media \"Detections of Traffic Signs on Video\")","5b6777b7":"# \ud83d\uddbd Drawing Bounding Boxes of Traffic Signs on Image","60bf3074":"# \ud83d\udcc2 Reading Image ***00001.jpg*** and getting its spatial dimension"}}