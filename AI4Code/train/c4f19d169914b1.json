{"cell_type":{"2f02244a":"code","cdb8d8b8":"code","1ccec1e6":"code","a5a4561a":"code","ef6549e4":"code","75ae7231":"code","977d131d":"code","dc8b2da5":"code","d2f5e91c":"code","529aa2d9":"code","2646f9b1":"code","fc3c940d":"code","56ad7c2e":"code","a5290178":"code","e4dac23f":"code","57b5997c":"code","dafaac85":"code","a706068d":"code","6406e4f5":"code","d1a65130":"code","5320628c":"code","9909e658":"code","16a20d83":"code","e97220ee":"code","f67389eb":"markdown","912709bc":"markdown","915e57dd":"markdown","fbb0b34c":"markdown"},"source":{"2f02244a":"# Import Libraries\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport tensorflow_datasets as tfds","cdb8d8b8":"# View available TensorFlow dataset\ntfds.list_builders()","1ccec1e6":"(training_set, validation_set), dataset_info = tfds.load(\n    'tf_flowers',\n    split=['train[:70%]', 'train[70%:]'],\n    with_info=True,\n    as_supervised=True,\n)","a5a4561a":"# Print the dataset info\ndataset_info","ef6549e4":"training_set","75ae7231":"validation_set","977d131d":"# Print Information about the Flowers Dataset\nnum_classes = dataset_info.features['label'].num_classes\nnum_classes","dc8b2da5":"num_training_examples = 0\nnum_validation_examples = 0\nfor example in training_set:\n    num_training_examples += 1\nfor example in validation_set:\n    num_validation_examples += 1\nprint('Total Number of Classes: {}'.format(num_classes))\nprint('Total Number of Training Images: {}'.format(num_training_examples))\nprint('Total Number of Validation Images: {} \\n'.format(num_validation_examples))","d2f5e91c":"# The images in the Flowers dataset are not all the same size.\nfor i, example in enumerate(training_set.take(5)):\n    print('Image {} shape: {} label: {}'.format(i+1, example[0].shape, example[1]))","529aa2d9":"# Visualize training dataset\nimport numpy as np\nimport matplotlib.pyplot as plt","2646f9b1":"# Plot 1 image from the training set.\nfor image, label in training_set.take(1):\n    break\nimage = image.numpy()\nplt.figure()\nplt.imshow(image, cmap=plt.cm.binary)\nplt.title('Label {}'.format(label))\nplt.colorbar()\nplt.grid(False)\nplt.show()","fc3c940d":"# Reformat Images and Create Batches\nIMAGE_RES = 224\ndef format_image(image, label):\n    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))\/255.0\n    return image, label\nBATCH_SIZE = 32\ntrain_batches = training_set.shuffle(num_training_examples\/\/4).map(format_image).batch(BATCH_SIZE).prefetch(1)\nvalidation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(1)\nprint(train_batches)\nprint(validation_batches)","56ad7c2e":"!pip install tensorflow_hub","a5290178":"import tensorflow_hub as hub","e4dac23f":"URL = \"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/feature_vector\/4\"\nfeature_extractor = hub.KerasLayer(URL,\n                                   input_shape=(IMAGE_RES, IMAGE_RES, 3))","57b5997c":"# Freeze the Pre-Trained Model\nfeature_extractor.trainable = False","dafaac85":"# Create a model\nmodel = tf.keras.Sequential([\n  feature_extractor,\n  tf.keras.layers.Dense(num_classes)\n])\nmodel.summary()","a706068d":"# Compile the model\nmodel.compile(\n  optimizer='adam',\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","6406e4f5":"# Train the model\nEPOCHS = 10\nhistory = model.fit(train_batches,\n                    epochs=EPOCHS,\n                    validation_data=validation_batches)","d1a65130":"# Plot Training and Validation Graphs\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(EPOCHS)\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","5320628c":"# Check Predictions\nclass_names = np.array(dataset_info.features['label'].names)\nprint(class_names)","9909e658":"# Create an Image Batch and Make Predictions\nimage_batch, label_batch = next(iter(train_batches))\nimage_batch = image_batch.numpy()\nlabel_batch = label_batch.numpy()\npredicted_batch = model.predict(image_batch)\npredicted_batch = tf.squeeze(predicted_batch).numpy()\npredicted_ids = np.argmax(predicted_batch, axis=-1)\npredicted_class_names = class_names[predicted_ids]\nprint(predicted_class_names)","16a20d83":"# Print True Labels and Predicted Indices\nprint(\"Labels:           \", label_batch)\nprint(\"Predicted labels: \", predicted_ids)","e97220ee":"# Plot Model Predictions\u200b\nplt.figure(figsize=(10,10))\nfor n in range(30):\n    plt.subplot(6,5,n+1)\n    plt.subplots_adjust(hspace = 0.3)\n    plt.imshow(image_batch[n])\n    color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\n    plt.title(predicted_class_names[n].title(), color=color)\n    plt.axis('off')\n_ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")","f67389eb":"## Create a image classification model for the folwers dataset. Download thedataset from the given link (Dataset). Perform the following.\n- 1. Preparing the data\n- 2. Build and compile the model\n- 3. Train and evaluate the model\n- 4. Save the model to disk for reuse","912709bc":"# Transfer learning and fine-tuning\n- A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task. You either use the pretrained model as is or use transfer learning to customize this model to a given task.\n- The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.","915e57dd":"# Transfer Learning with TensorFlow Hub\n# What is TensorFlow Hub?\n- TensorFlow Hub is an online repository of already trained TensorFlow models that we can use. These models can either be used as is, or they can be used for Transfer Learning.\n- Transfer learning is a process where we take an existing trained model, and extend it to do additional work. This involves leaving the bulk of the model unchanged, while adding and retraining the final layers, in order to get a different set of possible outputs.","fbb0b34c":"## Download the Flowers Dataset using TensorFlow Datasets\n- tfds.load() Loads the named dataset into a tf.data.Dataset.\n- We are downloading the tf_flowers dataset. This dataset is only split into a TRAINING set. We have to use tfds.splits to split this training set into to a training_set and a validation_set. In this example we are splitting 70 to the training_set and 30 to the validation_set."}}