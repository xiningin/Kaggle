{"cell_type":{"2bb1e98e":"code","cfcb247a":"code","453678a5":"code","752f1a0a":"code","01f64583":"code","d4a86f81":"code","f22569b3":"code","53ec37d8":"code","6a8ecf04":"code","5f6fcb39":"code","d5ef3cfe":"code","70408d8b":"code","f750849e":"code","c0d836b0":"code","52692727":"code","0711f031":"code","fd50e823":"code","431bed8c":"code","dca36f80":"code","ed6d4ced":"code","7c6def34":"code","1188d146":"code","99eaa716":"code","f659e6a8":"code","1be7875a":"code","bef72d59":"code","8253cdc0":"code","9c03030a":"code","b82eca3b":"code","02d3938b":"code","81b42ead":"code","3483cb62":"code","d5289aec":"code","75a9f3c2":"code","6eff70b7":"code","4301fef6":"code","dc12f470":"code","fbc03df6":"code","589d0edc":"code","20f9b4b6":"code","0b985751":"code","3ab2ff16":"code","d99d9c62":"code","6705c07d":"code","b5669a71":"code","d8c9e1ad":"code","0b4c2517":"code","e45f25b3":"code","7eae0ee6":"code","f21cc7ca":"code","826d0cc5":"code","46cec023":"markdown","efb383a6":"markdown","bdea7ba4":"markdown","92bb4b68":"markdown","11d2db31":"markdown","e3979abd":"markdown","960df1d5":"markdown","705eaa36":"markdown","52b16611":"markdown","5bbc1754":"markdown","68b93f2c":"markdown","047a216a":"markdown","ae11d042":"markdown","e6ceb99d":"markdown","09577384":"markdown","ab51912e":"markdown","403531ea":"markdown","5d7f181b":"markdown","92c6c15b":"markdown","952b5d5f":"markdown","8e4311c5":"markdown","d5f6890c":"markdown","6febea2b":"markdown","bc84cc8b":"markdown","a2acf7d5":"markdown","617264ce":"markdown","8970b41c":"markdown","4aadd937":"markdown","cf5f2db4":"markdown","131ecf8f":"markdown","56af578d":"markdown","08e0fdb8":"markdown","7fec925c":"markdown","3777578e":"markdown"},"source":{"2bb1e98e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cfcb247a":"import matplotlib.pyplot as plt","453678a5":"data = {\n'year': [2010, 2011, 2012,\n2010, 2011, 2012,\n2010, 2011, 2012],\n'team': ['FCBarcelona', 'FCBarcelona', 'FCBarcelona',\n'RMadrid', 'RMadrid', 'RMadrid',\n'ValenciaCF', 'ValenciaCF', 'ValenciaCF'],\n'wins': [30, 28, 32, 29, 32, 26, 21, 17, 19],\n'draws': [6, 7, 4, 5, 4, 7, 8, 10, 8],\n'losses': [2, 3, 2, 4, 2, 5, 9, 11, 11]\n}","752f1a0a":"football = pd.DataFrame(data, columns = ['year', 'team', 'wins', 'draws', 'losses'])","01f64583":"football","d4a86f81":"edu = pd.read_csv('\/kaggle\/input\/datasetjupyter\/files\/ch02\/educ_figdp_1_Data.csv',\n                  na_values=':', usecols=['TIME', 'GEO', 'Value'])","f22569b3":"edu","53ec37d8":"edu.head()","6a8ecf04":"edu.head(10)","5f6fcb39":"edu.tail()","d5ef3cfe":"edu.tail(10)","70408d8b":"edu.describe()","f750849e":"edu['Value']","c0d836b0":"edu[10:14]","52692727":"edu['GEO']","0711f031":"edu.iloc[90:94][['TIME','GEO']]","fd50e823":"edu[edu['Value'] > 6.5].tail()","431bed8c":"edu['Value'] > 6.5","dca36f80":"a = edu[edu['Value'] > 6.5]","ed6d4ced":"a","7c6def34":"type(edu[edu['Value'] > 6.5])","1188d146":"type(a)","99eaa716":"edu[\"Value\"].isnull()","f659e6a8":"~edu[\"Value\"].isnull()","1be7875a":"edu[edu[\"Value\"].isnull()].head()","bef72d59":"edu.max(axis = 0)","8253cdc0":"print ('Pandas max function:', edu['Value'].max())\nprint ('Python max function:', max(edu['Value']))","9c03030a":"s = edu[\"Value\"]\/100\ns.head()","b82eca3b":"s = edu[\"Value\"].apply(np.sqrt)\ns.head()","02d3938b":"s = edu[\"Value\"].apply(lambda d: d**2)\ns.head()","81b42ead":"edu['ValueNorm'] = edu['Value']\/edu['Value'].max()\nedu.tail()","3483cb62":"edu.drop('ValueNorm', axis = 1, inplace = True)\nedu.head()","d5289aec":"eduApp = edu.append({\"TIME\": 2000, \"Value\": 5.00, \"GEO\": 'a'},\n                  ignore_index = True)\neduApp.tail()","75a9f3c2":"eduApp.drop(max(edu.index), axis = 0, inplace = True)\nedu.tail()","6eff70b7":"eduDrop = edu[~edu[\"Value\"].isnull()].copy()\neduDrop.head()","4301fef6":"eduDrop = edu.dropna(how = 'any', subset = [\"Value\"])\neduDrop.head()","dc12f470":"eduFilled = edu.fillna(value = {\"Value\": 0})\neduFilled.head()","fbc03df6":"edu.sort_values(by = 'Value', ascending = False,\n                inplace = True)\nedu.head()","589d0edc":"edu.sort_index(axis = 0, ascending = True, inplace = True)\nedu.head()","20f9b4b6":"edu[[\"GEO\", \"Value\"]].groupby('GEO')","0b985751":"group = edu[[\"GEO\", \"Value\"]].groupby('GEO').mean()\ngroup.head()","3ab2ff16":"type(group)","d99d9c62":"filtered_data = edu[edu[\"TIME\"] > 2005]\npivedu = pd.pivot_table(filtered_data, values = 'Value',\n                        index = ['GEO'], columns = ['TIME'])\npivedu.head()","6705c07d":"pivedu.loc[['Spain','Portugal'], [2006,2011]]","b5669a71":"pivedu = pivedu.drop(['Euro area (13 countries)',\n                      'Euro area (15 countries)',\n                      'Euro area (17 countries)',\n                      'Euro area (18 countries)',\n                      'European Union (25 countries)',\n                      'European Union (27 countries)',\n                      'European Union (28 countries)'\n                      ], axis=0)\npivedu = pivedu.rename(\n    index={'Germany (until 1990 former territory of the FRG)': 'Germany'})\npivedu = pivedu.dropna()\npivedu.rank(ascending=False, method='first').head()","d8c9e1ad":"pivedu.rank(ascending=True, method='first').head()","0b4c2517":"pivedu.shape","e45f25b3":"pivedu","7eae0ee6":"totalSum = pivedu.sum(axis = 1)\n\ntotalSum.rank(ascending = False, method = 'dense').sort_values()","f21cc7ca":"totalSum = pivedu.sum(axis = 1).sort_values(ascending = False)\ntotalSum.plot(kind = 'bar', style = 'b', alpha = 0.7,\n              title = \"Total Values for Country\")","826d0cc5":"my_colors = ['b', 'r', 'g', 'y', 'm', 'c']\nax = pivedu.plot(kind='barh', stacked=True, color=my_colors, figsize=(12, 6))\nax.legend(loc='lower right', bbox_to_anchor=(1.15, 0.4))\nplt.savefig('Value_Time_Country.png', dpi=300, bbox_inches='tight')","46cec023":"**6.3 Filtering data**","efb383a6":"Aggregation functions: We can also find the max of each col in the data frame, this returns a transpose of the matrix with the names of the colums of the original matrix in the first column and the maxima found in the second column.","bdea7ba4":"- What is the size of the edu DataFrame (rows x columns)?\n\nThis is indicated at the bottom of the previous cell, so 384 rows and 3 columns.\n","92bb4b68":"**6.9 Ranking data**","11d2db31":"**6.4 Filtering missing values**","e3979abd":"Same is possible for a subset of rows","960df1d5":"The first exercise consists of creating a dictionary and then creating a data frame from the Panda library, named football.","705eaa36":"**6.8 Rearranging data**","52b16611":"- 7. What do you observe regarding the parameter ascending=False?\n\nThis parameter indicates whether the rank should be considered in an ascending or descending way. In other words, if ascending=True the countries will be ranked from a low to a high value. If ascending=False, they are ranked from a high to low value.\n\nThis means that if you were to make a sum of the rank that is assigned to each country in a specific year, it always equals the amount of countries considered plus one (22 countries in this case).","5bbc1754":"**7.1 Plotting data**","68b93f2c":"**6.1 Reading data**","047a216a":"If we want to return to the original order, we can sort by an index using the function sort_indexand specifying axis=0:","ae11d042":"Now, if we want to remove this column from the DataFrame, we can use the function drop.\n\nThis removes the indicated rows if axis=0, or the indicated columns if axis=1.\n\nIn Pandas, all the functions that change the contents of a DataFrame, such as the function drop, will normally return a copy of the modified data, instead of overwriting the DataFrame. Use inplace = True to make sure that the data is not copied, nut replaced.","e6ceb99d":"Now, if we want to see the data frame, just execute the name of the data frame","09577384":"Also possible to append new rows to the data frame, with using ignore_index=True we can avoid clashes of already existing index rows. This makes sure the new index is done automatically.","ab51912e":"Also possible to use lambda functions","403531ea":"**6.2 Selecting data**","5d7f181b":"Or use the not generic function","92c6c15b":"Since this returns a special type of Data Frame, it is necessary to use an aggregation function to make it a proper one.","952b5d5f":"Could do the same for 'GEO'.","8e4311c5":"- What happens if we give a number as argument to the method head()?\n\nThe amount of rows that are portrayed become equal to the number given as an argument. So for example edu.head(10) shows rows 0 to 9 of the CSV. Not giving an argument returns 5 rows in total by default.\n\n- What does the method tail()return?\n\nIt returns the last rows of the CSV data. It is again possible to give a number as an argument, which works the same way as the head method (default is 5 rows).","d5f6890c":"- What does the operation edu[\u2019Value\u2019] > 6.5 produce? And if we apply the index edu[edu[\u2019Value\u2019] > 6.5]?Is this a Series or a DataFrame?\n\n\n- 1. The first index produces a mask with True or False for each row.\n\n- 2. The second one returns the actual Series of the dataframe where all of the booleans from the equation returned True as found in the mask.\n\n- 3. This is a DataFrame structure, as can be seen a few cells down by using the method 'type()'. A series is a set of tupples, so you can't acces the columns, intervals in rows, perform projections... No panda operations can be performed on this structure. We obtain this type of structure after performing an aggregation function.","6febea2b":"Now we open and read a CSV from the data provided. We know that the non available values are represented by a colon by looking at the raw data, which we specify in the method. The index colums (usecols) do not count as a column\/row!!!","bc84cc8b":"**6.6 Sorting data**","a2acf7d5":"The combination of projection and selecting rows is also possible by using the method 'iloc' indexing. The dtype is now object, not dataframe!!!","617264ce":"**6.5 Manipulating data**","8970b41c":"Beside these aggregation functions, we can apply operations over all the values in rows, columns or a selection of both.","4aadd937":"Can replace the NaN values by some other value as well","cf5f2db4":"- Which measures does the result show? It seems that it shows some default values, can you guess which ones?\n\nIt shows statistical info about the data frame, such as the following:\n\n    Count = Number of non-null observations (extracted)\n    Mean = Mean of Values (computed)\n    std = Standard Deviation of the Values (computed)\n    min = Minimum Value (extracted)\n    procentiles 25, 50 and 75 % (computed)\n    max = Maximum Value (extracted)\n    ","131ecf8f":"- Which measures does the result show? It seems that it shows some default values, can you guess which ones?\n\n","56af578d":"There is a difference between the generic 'max' functions in Python and the specific 'max' function of Pandas","08e0fdb8":"We want to present a subset of columns, this is called projection. For now, we only want 1 column with the name 'Value'. Keep in mind that the names are capital sensitive: e.g. Value=\/value.","7fec925c":"**6.7 Grouping data**","3777578e":"- What does this index return? What does the first index represent? And the second one?\n\nThis returns the rows 90 through 93, with only the colums from TIME and GEO. This means that the first index represents the wanted rows and the second one represents the wanted subset of columns."}}