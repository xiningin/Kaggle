{"cell_type":{"fcd30ceb":"code","5a0eeaf4":"code","b84c2af0":"code","5ad80fc9":"code","0b7a5acf":"code","3c868cdb":"code","bfbc3099":"code","caa76288":"code","6cab94cd":"code","fa4f6b17":"code","21c99af3":"code","93830789":"code","c720f15a":"code","5966e3c5":"code","08d85ab4":"code","b13a5ce5":"code","c65071a9":"code","640688a9":"code","e614a7d8":"code","a489ee98":"code","5eade34d":"code","06fa21e9":"code","7b77082a":"code","fcfd97d7":"code","f5e5cb7b":"code","5f34185e":"code","18a6716d":"code","a7157eeb":"code","9c43b8db":"code","c397d976":"code","06495593":"code","e89bce60":"code","f9143177":"code","9de3e286":"code","481f1e43":"code","e5366984":"code","63bd0d42":"code","d67f3ac6":"code","02718c96":"code","48ccf1ca":"code","8b73fcc0":"code","21da5e3d":"code","bd09eee7":"markdown","07e164ff":"markdown","82dea7b7":"markdown","728cdeee":"markdown","65b40ed4":"markdown","573accae":"markdown","c2785a45":"markdown","9dcdb216":"markdown","7fa4ce92":"markdown","93a64412":"markdown","e6005682":"markdown","1a2ade79":"markdown","d5bd187e":"markdown","0df4f26d":"markdown","fbdf0f10":"markdown","36ac6aec":"markdown","8262aa4b":"markdown","098c97fc":"markdown","ef465d75":"markdown","b5892656":"markdown","29333cb0":"markdown","cd59b37b":"markdown","6fb187e0":"markdown","9326ee4d":"markdown","9fd338f8":"markdown","188fc373":"markdown","681e008b":"markdown","9c2d61f3":"markdown","1071a2dd":"markdown","fec2508a":"markdown","ff0605d5":"markdown","0a550c3f":"markdown","9becae85":"markdown","72ea082c":"markdown","2fdc9a8b":"markdown","2847693c":"markdown","7f193cdc":"markdown","423303fd":"markdown","6544af3a":"markdown","38927ca5":"markdown","4b450e5f":"markdown","89409061":"markdown","adfa9886":"markdown","1df4207d":"markdown","1e733793":"markdown","da91c7ee":"markdown","4aafa2aa":"markdown","0acbe69d":"markdown","6d2e2df3":"markdown","ee80726b":"markdown","a7acabe4":"markdown","8441d716":"markdown","165225f2":"markdown","2b557348":"markdown","20568c6c":"markdown","841e04e3":"markdown","bfcd9731":"markdown","7d3c4a53":"markdown","eaf17cde":"markdown","6b6ab297":"markdown","d877ecdd":"markdown","34338149":"markdown","ff661a90":"markdown","b0727858":"markdown","29cb45a4":"markdown","4a323296":"markdown","a5e1ef6c":"markdown","7d369edb":"markdown","024a9749":"markdown","82ba4acc":"markdown","f3593afe":"markdown","0a7509bc":"markdown","966a097d":"markdown","08ce7706":"markdown","0a931159":"markdown","e17bddb6":"markdown","3d72e77b":"markdown","20650471":"markdown","4d09bd20":"markdown","5f128cf7":"markdown","a21ce6e1":"markdown","d9006449":"markdown","547a5d48":"markdown","ed122538":"markdown","166cd158":"markdown","400ebfaa":"markdown","4d0e5115":"markdown","b248f272":"markdown","8ade2ee5":"markdown","dad21c16":"markdown","4793c36a":"markdown","9bab2bed":"markdown","c53683c9":"markdown","0e55a5c0":"markdown","25fa5ca8":"markdown","b0fd6875":"markdown","9e199830":"markdown","27c07326":"markdown"},"source":{"fcd30ceb":"import pandas as pd\nimport os\nimport numpy as np\nimport seaborn as sns\nimport warnings\nfrom scipy import stats\nfrom scipy.stats import shapiro\nfrom scipy.stats import mannwhitneyu\nfrom matplotlib import pylab as plt\nfrom statsmodels.graphics.gofplots import qqplot\nfrom IPython.core.interactiveshell import InteractiveShell\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\nwarnings.simplefilter(action=\"ignore\", category=Warning)\nInteractiveShell.ast_node_interactivity = 'all'\n\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\nset_seed()\n\nsns.set_style('whitegrid')\nsns.set_context('paper', font_scale=1.5)\nplt.style.use('fivethirtyeight')\npd.set_option(\"display.width\", 100)\npd.set_option(\"display.max_columns\", 50)\npd.set_option(\"display.max_rows\", 30)\n\nprint(\"setup-complete!\")","5a0eeaf4":"# Accomodate raw path to variables\nraw_customer, raw_orders = \"..\/input\/shopping-cart-database\/customers.csv\", \"..\/input\/shopping-cart-database\/orders.csv\"\nraw_products, raw_sales = \"..\/input\/shopping-cart-database\/products.csv\", \"..\/input\/shopping-cart-database\/sales.csv\"\n\n# Read-in data\ncustomer, order = pd.read_csv(raw_customer), pd.read_csv(raw_orders)\nproduct, sales = pd.read_csv(raw_products), pd.read_csv(raw_sales)","b84c2af0":"cust_order = pd.merge(left=customer, right=order, \n                      left_index=True, right_index=True) # merging\ncop_data = pd.merge(left=cust_order, right=product, \n                    left_index=True, right_index=True) # merging","5ad80fc9":"cop_data # check customer, order, and product data","0b7a5acf":"sales # let's check sales data","3c868cdb":"cop_data.info() # Getting the information","bfbc3099":"sales.info() # Getting the information","caa76288":"categorical = cop_data.select_dtypes([\"category\", \"object\"]).columns\nfor cat_col in categorical:\n    print(f\"{cat_col} : {cop_data[cat_col].nunique()} uniqueness variable(s)\")","6cab94cd":"numeric = sales.select_dtypes([\"int\", \"float\"]).columns\nfor num_col in numeric:\n    print(f\"{num_col} : {sales[num_col].nunique()} uniqueness variable(s)\")","fa4f6b17":"# Get the number of missing data points per column\nmissing_values_count = cop_data.isnull().sum()\n# Look at the missing points in the first ten columns\nmissing_values_count[:10]","21c99af3":"# Get the number of missing data points per column\nmissing_values_count = sales.isnull().sum()\n# Look at the missing points in the first ten columns\nmissing_values_count[:10]","93830789":"# Convert it using to_datetime() function\ncop_data[\"order_date\"], cop_data[\"delivery_date\"] = pd.to_datetime(cop_data[\"order_date\"]), pd.to_datetime(cop_data[\"delivery_date\"])\n# Let's see it\ncop_data.info()","c720f15a":"cop_data[\"sales\"] = cop_data[\"price\"] * cop_data[\"quantity\"] # let's make a sales data\ncop_data.head(2)","5966e3c5":"# let's get the year data in order date column\ncop_data['year_order'] = cop_data['order_date'].dt.year\n\n# let's get the month data in order date column\ncop_data['month_order'] = cop_data['order_date'].dt.month\n\n# Let's get the day data in order date column\ncop_data[\"day_order\"] = cop_data[\"order_date\"].dt.day","08d85ab4":"cop_data.head(2)","b13a5ce5":"# let's get the year data in delivery date column\ncop_data['year_delivery'] = cop_data['delivery_date'].dt.year\n\n# let's get the month data in delivery date column\ncop_data['month_delivery'] = cop_data['delivery_date'].dt.month\n\n# Let's get the day data in delivery date column\ncop_data[\"day_delivery\"] = cop_data[\"delivery_date\"].dt.day","c65071a9":"cop_data.head(2)","640688a9":"sns.set_style(\"whitegrid\") # set the seaborn style\n# let's make a correlation matrix for `cop_data`\nplt.figure(dpi=100, figsize=(24, 18)) # figure the size\nsns.heatmap(cop_data.corr(), annot=True) # create a heatmap\nplt.title(\"COP Data Correlation\", weight=\"bold\", fontsize=30, fontname=\"monospace\", pad=30) # title\nplt.xticks(weight=\"bold\", fontsize=15) # x-ticks\nplt.yticks(weight=\"bold\", fontsize=15); # y-ticks","e614a7d8":"# Let's see the correlation from `cop_data`\n(cop_data.corr()[\"sales\"] # transform it into data corr\n         .sort_values(ascending=False) # sort values\n         .to_frame() # change it into data frame\n         .T) # transpose","a489ee98":"# let's make a correlation matrix for `sales`\nplt.figure(dpi=100, figsize=(24, 16)) # figure the size\nsns.heatmap(sales.corr(), annot=True) # construct the heatmap\nplt.title(\"Sales Data Correlation\", weight=\"bold\", fontsize=30, fontname=\"monospace\", pad=30) # title\nplt.xticks(weight=\"bold\", fontsize=15) # x-ticks\nplt.yticks(weight=\"bold\", fontsize=15); # y-ticks","5eade34d":"# Let's see the correlation\n(sales.corr()[\"total_price\"] # transform it into data corr\n      .sort_values(ascending=False) # sort the values\n      .to_frame() # change it into data frame\n      .T) # transpose ","06fa21e9":"cop_data.describe(include=[np.number]) # Let's have a look to the discrete and continuous data first","7b77082a":"sales.describe(include=[np.number]) # Let's have a look to sales data","fcfd97d7":"cop_data.describe(exclude=[np.number]) # Let's have a look to categorical data","f5e5cb7b":"try:\n    sales.describe(exclude=[np.number]) # Let's see on sales data\nexcept ValueError as error:\n    print(error)","5f34185e":"# checking and visualizing the type of distribution of a feature column\ndef univariate_analysis(data, color, title1, title2):\n    \n    \"\"\"\n    Showing visualization of univariate\n    analysis with displot and qqplot\n    visualization from seaborn and statsmodel\n    library.\n    \n    Parameters\n    ----------\n    data : DataFrame, array, or list of arrays, optional\n        Dataset for plotting. If ``x`` and ``y`` are absent, this is\n        interpreted as wide-form. Otherwise it is expected to be long-form. \n    title1: The title of the visualization, title1 for displot visualization\n        And title2 for quantile plot from statsmodel.\n    title2: The title of the visualization, title1 for displot visualization\n        And title2 for quantile plot from statsmodel.\n        \n    Returns\n    -------\n    fig : matplotlib figure\n        Returns the Figure object with the plot drawn onto it.\n    \"\"\"\n    \n    fig, (ax1, ax2) = plt.subplots( # subplots\n        ncols=2, # num of cols\n        nrows=1, # num of rows\n        figsize=(20, 6) # set the width and high\n    )\n\n    sns.distplot( # create a distplot visualization\n        data, # data\n        ax=ax1, # axes 1\n        kde=True, # kde\n        color=color # color\n    )\n    \n    ax1.set_title( # set the title 1\n        title1, \n        weight=\"bold\", # weight\n        fontname=\"monospace\", # font-name\n        fontsize=25, # font-size\n        pad=30 # padding\n    )\n    \n    qqplot( # qqplot (quantile plot)\n        data, # data\n        ax=ax2, # axes 2\n        line='s' # line \n    )\n    \n    ax2.set_title( # set the title 2\n        title2, \n        weight=\"bold\", # weight\n        fontname=\"monospace\", # font-name\n        fontsize=25, # font-size\n        pad=30 # padding\n    )\n    \n    return fig # returning the figure","18a6716d":"# Sales Data\nunivariate_analysis( # call the function\n    data=cop_data['sales'], # put the data\n    color='red', # pick the color\n    title1='COP Data - Sales Data Distribution', # title1\n    title2='Quantile Plot'); # title2","a7157eeb":"# Age Data\nunivariate_analysis( # call the function\n    data=cop_data['age'], # put the data\n    color='blue', # pick the color\n    title1='COP Data - Age Data Distribution', # title1\n    title2='Quantile Plot'); # title2","9c43b8db":"# Price Data\nunivariate_analysis( # call the function\n    data=cop_data['price'], # put the data\n    color='purple', # pick the color\n    title1='COP Data - Price Data Distribution', # title1\n    title2='Quantile Plot'); # title2","c397d976":"# Quantity Data\nunivariate_analysis( # call the function\n    data=cop_data['quantity'], # put the data\n    color='black', # pick the color\n    title1='COP Data - Quantity Data Distribution', # title1\n    title2='Quantile Plot'); # title2","06495593":"# checking skewness value\n# if value lies between -0.5 to 0.5  then it is normal otherwise skewed\nskew_value = cop_data.skew().sort_values(ascending=False).to_frame().head()\nskew_value","e89bce60":"# Total Price Data\nunivariate_analysis( # call the function\n    data=sales['price_per_unit'], # put the data\n    color='orange', # pick the color\n    title1='SALES Data - Price Per-Unit Data Distribution', # title1\n    title2='Quantile Plot'); # title2","f9143177":"# Price Data\nunivariate_analysis( # call the function\n    data=sales['total_price'], # put the data\n    color='grey', # pick the color\n    title1='SALES Data - Total Price Data Distribution', # title1\n    title2='Quantile Plot'); # title2","9de3e286":"# Price per-unit Data\nunivariate_analysis( # call the function\n    data=sales['quantity'], # put the data\n    color='green', # pick the color\n    title1='SALES Data - Quantity Data Distribution', # title1\n    title2='Quantile Plot'); # title2","481f1e43":"# checking skewness value\n# if value lies between -0.5 to 0.5  then it is normal otherwise skewed\nskew_value = sales.skew().sort_values(ascending=False).to_frame().head()\nskew_value","e5366984":"(cop_data.groupby([\"month_order\", \"product_type\", \"product_name\"])[\"sales\"] # groupping\n        .sum() # sum\n        .astype(\"int\") # change the type \n        .sort_values(ascending=False) # sort the values\n        .to_frame() # change it into data frame\n        .head(17) # look the first 17 rows\n        .T) # Transpose","63bd0d42":"# group the Month cols\nsum_month_order = cop_data.groupby([\"month_order\"]).sum().astype(\"int\")\n# let's plot it\nplt.figure(dpi=100, figsize=(24, 10)) # figuring the size\n# makes bar plot \nsns.barplot(\n    x=sum_month_order.index, # x-axis\n    y=sum_month_order[\"sales\"], # y-axis\n    data=sum_month_order, # data\n    palette=\"deep\" # palette\n) \n# title \nplt.title(\n    \"How have sales and revenue changed over the past few quarters?\", \n    fontname=\"monospace\", # fontname\n    weight=\"bold\", # weight\n    fontsize=35, # font-size\n    pad=30 # padding\n)\n# x-label\nplt.xlabel( # x-label\n    \"Months\", \n    weight=\"bold\", # weight\n    color=\"purple\", # color\n    fontsize=25, # font-size\n    loc=\"center\" # location\n)\nplt.xticks( # x-ticks\n    weight=\"bold\", # weight\n    fontsize=15 # font-size\n)\nplt.ylabel( # y-label\n    \"Sales in Dollar Australia ($)\", \n    weight=\"bold\", # weight\n    color=\"green\", # color\n    fontsize=20 # font-size\n)\nplt.yticks( # y-ticks\n    weight=\"bold\", # weight \n    fontsize=15 # font-size\n);","d67f3ac6":"plt.figure(dpi=100, figsize=(26, 8)) # figure the size\nplt.subplot(1, 2, 1) # make a subplots for making 2 visualization \ncop_data.groupby(\"gender\").age.plot(kind='kde'); # groupping gender and plot it\nplt.subplot(1, 2, 2) # make a subplots for making 2 visualization\ncop_data.groupby(\"gender\").age.hist(); # grouping gender and plot it using hist plot","02718c96":"fig, (ax1, ax2) = plt.subplots( # subplots\n    ncols=2, # n-cols\n    nrows=1, # c-rows\n    figsize=(24, 12) # figuring the size\n)\nsns.barplot( # barplot\n    x=cop_data[\"gender\"].value_counts().values, # x-axis\n    y=cop_data[\"gender\"].value_counts().index, # y-axis\n    palette=\"viridis\", # palette\n    ax=ax1 # axes\n)\n# Prepare data for Pie Plots\ncop_pie = {\"gender\": [\"Male\", \"Non-binary\", \"Polygender\", \"Genderqueer\", \"Genderfluid\", \"Bigender\", \"Female\", \"Agender\"], # gender\n           \"count\": [143, 131, 128, 127, 122, 120, 115, 114]} # count\ncop_pie = pd.DataFrame(cop_pie)\ncop_pie.plot( # plot \n    kind=\"pie\", # kind pie of course\n    y=\"count\", # y-axis\n    labels=cop_pie[\"gender\"], # the labels\n    autopct='%1.1f%%', # pct\n    startangle=90, # angle\n    legend=True, # legend\n    colormap=plt.cm.PuBuGn, # cmap\n    fontsize=20, # fontsize\n    textprops=dict(color=\"red\"), # textprops\n    ax=ax2 # axes\n)\nax1.set_xlabel( # x-label\n    \"Counts\", \n    weight=\"bold\", # weight\n    fontsize=20 # font-size\n) \nax1.set_xticklabels( # x-ticklabels\n    labels=cop_pie[\"count\"], # labels \n    weight=\"bold\", # weight\n    fontsize=15 # font-size\n) \nax1.set_ylabel( # y-label\n    \"Genders\", \n    weight=\"bold\", # weight\n    fontsize=20 # font-size\n) \nax1.set_yticklabels( # y-ticklabels\n    labels=cop_pie[\"gender\"], # labels \n    weight=\"bold\", # weight \n    fontsize=15 # font-size\n); ","48ccf1ca":"high_state_sales = (cop_data.groupby(\"state\") # groupping\n                           .sum() # sum\n                           .astype(\"int\")[\"sales\"] # change type into int and get the sales features \n                           .sort_values(ascending=False) # sort the values \n                           .to_frame()) # change it into data frame\n# let's plot it\nplt.figure(dpi=100, figsize=(24, 10)) # figuring the size\n# makes bar plot \nsns.barplot( # barplot\n    x=high_state_sales.index, # x-axis\n    y=\"sales\", # y-axis\n    data=high_state_sales, # data\n    palette=\"viridis\" # palette (like cmap)\n)\n# title\nplt.title( # title\n    \"State with the highest number of Sales\", \n    fontname=\"monospace\", # font-name \n    weight=\"bold\", # weight\n    fontsize=35, # the size of font \n    pad=30 # padding\n)\n# x-label\nplt.xlabel( # x-label\n    \"States\", \n    weight=\"bold\", # weight\n    color=\"purple\", # color\n    fontsize=25, # fontsize\n    loc=\"center\" # location\n)\nplt.xticks( # x-ticks\n    weight=\"bold\", # weight\n    fontsize=15, # font-size\n    rotation=20 # rotate\n) \nplt.ylabel( # y-label\n    \"Sales in Dollar Australia ($)\", \n    weight=\"bold\", # weight\n    color=\"g\", # color\n    fontsize=20, # font-size\n    loc=\"center\" # location\n)\nplt.yticks(  # y-ticks\n    weight=\"bold\", # weight\n    fontsize=15 # font-size\n);","8b73fcc0":"# group of the highest number of sales in city\ntop_20_city = (cop_data.groupby(\"city\") # groupping\n                      .sum() # sum\n                      .astype(\"int\")[\"sales\"] # change type into int and get the sales features\n                      .sort_values(ascending=False) # sort values\n                      .head(20) # head\n                      .to_frame()) # change it into data frame\n# let's plot it\nplt.figure(dpi=100, figsize=(24, 24)) # figuring the size\nsns.barplot( # barplot\n    x=\"sales\", # x-axis\n    y=top_20_city.index, # y-axis \n    data=top_20_city, # data\n    palette=\"viridis\" # palette (colormap)\n)\nplt.title( # title\n    \"Top 20 City with high number of sales\", \n    fontname=\"monospace\",  # font-name\n    weight=\"bold\",  # weight\n    fontsize=35, # size\n    pad=30 # padding\n)\nplt.xlabel( # x-label\n    \"Sales in Dollar Australia ($)\", \n    weight=\"bold\", # weight\n    color=\"g\", # color\n    fontsize=25, # font-size\n    loc=\"center\" # location\n)\nplt.xticks( # x-ticks\n    weight=\"bold\", # weight\n    fontsize=15, # font-size\n    rotation=10 # rotation\n) \nplt.ylabel( # y-label\n    \"Name of Cities\", \n    weight=\"bold\", # weight\n    color=\"purple\", # color\n    fontsize=30, # font-size\n    loc=\"center\" # location\n)\nplt.yticks( # y-ticks\n    weight=\"bold\", # weight\n    fontsize=15 # font-size\n);","21da5e3d":"fig, ax = plt.subplots( # the figure and axes\n    figsize=(24, 12) # the figure size \n)\ncop_data.plot( # plotting\n    x=\"order_date\", # x-axis\n    y=\"sales\", # y-axis\n    color=\"grey\", # color\n    ax=ax # axes\n)\nax.set_title( # title\n    \"Order Date\", \n    fontsize=30, # font-size\n    weight=\"bold\", # weight\n    pad=30 # padding\n) \nax.set_ylabel( # y-label\n    \"Sales in Dollar Australia ($)\", \n    weight=\"bold\", # weight\n    fontsize=20, # font-size\n    color=\"green\", # color\n    loc=\"center\" # location\n)\nax.set_xlabel( # x-label\n    \"Order Date\", \n    weight=\"bold\", # weight\n    fontsize=25, # font-size\n    color=\"purple\", # color\n    loc=\"center\" # location\n); ","bd09eee7":"## **Quantity**\n\nFind the proportion that lies in between two standard deviation ($\\sigma$) from mean ($\\mu$), and let's try to interprete that. and In the Quantity Data, the $\\mu = 60.3$ and the $\\sigma = 11.6$, then without further ado let's calculate it.\n\n#### **Calculation:**\n\n* $60.3 - 2(11.6) = 37$\n* $60.3 + 2(11.6) = 83.5$\n\n#### ***Interpretation:***\n\nAt least $75\\%$ of the Shopping Cart Database Quantity ordered population in Australia has a quantity range from $37 - 83.5$ quantity ordered.","07e164ff":"> My plan is to go through feature (question) by feature and take closer look those features to inspect their relationships with previous features. So it's gonna take a while to finish this notebook with all features involved. I'm planning to update it regulary whenever I have free time.","82dea7b7":"## **Age**\n\nFind the proportion that lies in between two standard deviation ($\\sigma$) from mean ($\\mu$), and let's try to interprete that. and In the Age Data, the $\\mu = 49.8$ and the $\\sigma = 17.6$, then without further ado let's calculate it.\n\n#### **Calculation:**\n\n* $49.8 - 2(17.6) = 14.59$\n* $49.8 + 2(17.6) = 85.0$\n\n#### ***Interpretation:***    \n\nAt least $75\\%$ of the Shopping Cart Database customer population in Australia has an age range of $14 - 85$ years.","728cdeee":"---","65b40ed4":"## **Univariate Analysis**\n\nUnivariate analysis is perhaps the simplest form of statistical analysis. Like other forms of statistics, it can be inferential or descriptive. The key fact is that only one variable is involved. Univariate analysis can yield misleading results in cases in which multivariate analysis is more appropriate.","573accae":"> Great!, let's check the Discrete and the Continuous variables...","c2785a45":"---","9dcdb216":"#### ***Reference: [Sales Data Deep Analysis](https:\/\/www.kaggle.com\/knightbearr\/sales-data-deep-analysis-knightbearr)***","7fa4ce92":"<p style=\"font-name: monospace; line-height: 2; font-size: 25px; font-weight: bold; letter-spacing: 2px; text-align: center;\">Which products were sold the most in the last month?<\/p>","93a64412":"---","e6005682":"### **Discrete and Continuous Variables**\nLet's have a look at Discrete and Continuous variables.","1a2ade79":"### ***Answer:***\n\n> The question is said that **Which products were sold the most in the last month?** that mean we're now in **October**, which mean the **last month** is **September** *(cmiiw)*, and if we see the output above, we can see that the most *Product Type* that sold the most is a **Trousers**, and the *Name of the Product* is **Chinos**, with $50.500$ (Dollar Australia) of **sales**.","d5bd187e":"> Great! look like the data is not have any missing values! okay, let's go to the next steps!","0df4f26d":"### You: Forking Without Upvoting and Feedback\n### Me:","fbdf0f10":"---","36ac6aec":"---","8262aa4b":"> **East Aidan** occupies the first position in the city with the highest number of sales with total sales of $20.247$ (Dollar Australia), and the second position is occupied by **East Sophia** with total sales of $19.628$ (Dollar Australia).","098c97fc":"Let's try to find the proportion that lies in between two standard deviation ($\\sigma$) from mean ($\\mu$) using ***Chebychev's Theorem***, and let's try to interprete...","ef465d75":"> Look like there's no null value, let's move on...","b5892656":"---","29333cb0":"<p style=\"font-name: monospace; line-height: 2; font-size: 25px; font-weight: bold; letter-spacing: 2px; text-align: center;\">Chebychev's Theorem<\/p>\n$$\n\\begin{aligned}\n1 - \\frac{1}{k^2}: k &= 2 -> 1 - \\frac{1}{2^2} = \\frac{3}{4} -> 75 \\\\\n                   k &= 3 -> 1 - \\frac{1}{3^2} = \\frac{8}{9} -> 88.9\n\\end{aligned}\n$$\n<br>\n<p style=\"font-name: monospace; line-height: 2; font-size: 20px; font-weight: bold; letter-spacing: 2px; text-align: center;\">How to find Standard Deviation ($\\sigma$)?<\/p>\n<p style=\"font-name: monospace; line-height: 2; font-size: 13px; font-weight: bold; letter-spacing: 2px; text-align: center;\">Here's the Formula:<\/p>\n$$\n\\begin{aligned}\n\\sigma &= \\sqrt{\\sigma^2} = \\sqrt{\\frac{\\sum{(x - \\mu)^2}}{N}} \\\\\ns &= \\sqrt{s^2} = \\sqrt{\\frac{\\sum{(x - \\bar{x})^2}}{n - 1}}\n\\end{aligned}\n$$\n<br>\n<p style=\"font-name: monospace; line-height: 2; font-size: 20px; font-weight: bold; letter-spacing: 2px; text-align: center;\">How to find Mean ($\\mu$)?<\/p>\n<p style=\"font-name: monospace; line-height: 2; font-size: 13px; font-weight: bold; letter-spacing: 2px; text-align: center;\">Here's the Formula:<\/p>\n$$\n\\begin{aligned}\n\\mu = \\frac{\\sum{x}}{N} \\\\\n\\bar{x} = \\frac{\\sum{x}}{n}\n\\end{aligned}\n$$","cd59b37b":"---","6fb187e0":"> Okay, we know that on the sales data is not categorical type, but, just for sure, I'm check that twice..\n\n> Okay let's go to the univariate analysis...","9326ee4d":"## **Price**\n\nFind the proportion that lies in between two standard deviation ($\\sigma$) from mean ($\\mu$), and let's try to interprete that. and In the Price Data, the $\\mu = 108.095$ and the $\\sigma = 9.15$, then without further ado let's calculate it.\n\n#### **Calculation:**\n\n* $108.095 - 2(9.15) = 89.795$\n* $108.095 + 2(9.15) = 126.395$\n\n#### ***Interpretation:***    \n\nAt least $75\\%$ of Shopping Cart population The product price database in Australia has a price range from $89,795 - 126,395$ (Australian Dollars).","9fd338f8":"---","188fc373":"---","681e008b":"---","9c2d61f3":"---","1071a2dd":"> Okay, I think, now we have every column that we want to use for the analysis, let's move on to the next steps...","fec2508a":"---","ff0605d5":"> Hmm... interesting, there are so many increases and decreases in **sales** that occur every month, well... that is indeed of natural, because, I have said before, to predict market prices, people's interest in shopping, people's reasons for shopping, product prices, and materials to make these products are in short supply, or just production declines due to the policies of every company during a pandemic like this, we don't know, and it's also quite difficult to predict, because that's how the world is, full of surprises. not sure, but if we look at the **average** of the **sales** **order date** every month, the value is quite good, which is $6532,937$ (Dollar Australia).","0a550c3f":"Okay, let's get started....\n\nWait...\n\n**Note:** *before you read this analysis, it would be nice to prepare snacks and coffee to accompany you*\n\nDone? Okay, let's start!","9becae85":"## **Merging data**\n\nLet's merge customers, orders, and product data since it's have the same rows...","72ea082c":"---","2fdc9a8b":"---","2847693c":"---\n### ***Note:***\n\n> I will not explore further Customer data regarding their names and residential addresses, because it falls into the realm of **Privacy** users, because I am a Knight, I will not publish user **Privacy** data to the public, and the reasons are given it's also because I don't have permission to explore further about the name, or the address where the customer lives.\n\n---","7f193cdc":"---","423303fd":"### **How many missing data points do we have?**\n\nLet's see how many missing data we have in each column....","6544af3a":"> `cop_data` has $1.000$ rows and $22$ columns, hmm, interesting, because in this data there is **customer name**, also **customer's full address**, I don't know if this data is ok to be retrieved published publicly because evil actions can happen at any time, and luckily I'm not a bad person, because I am a **Knight Bear** who is analyzing data and also discovering, and of course you all know, a knight never does evil , and really loves peace and serenity, okay, let's move on...","38927ca5":"# **Import Libraries**","4b450e5f":"---","89409061":"---","adfa9886":"# **Data Analysis**\n\nData Analysis is the process of systematically applying statistical and\/or logical techniques to describe and illustrate, condense and recap, and evaluate data. Indeed, researchers generally analyze for patterns in observations through the entire data collection phase *(Savenye, Robinson, $2004$)*.\nanalyze and investigate data sets and summarize their main characteristics, often employing data visualization methods.\n\nOr, the easier, you can say in Data Analysis we (Data Scientist or Data Analyst) what ever you want to call that, in this section, we're looking for the correlation and also the relationships between every data (features and labels) or the variables using and applying the statistical and visualization methods for looking some patterns.","1df4207d":"### **Uniqueness Categorical Variables**\nLet's have a look at categorical variables. How many unique values of these variables.","1e733793":"# **Introduction**\n\n<p style=\"font-name: monospace; line-height: 2; font-size: 20px; font-weight: bold; letter-spacing: 2px; text-align: center;\">\u0628\u0633\u0645 \u0627\u0644\u0644\u0647 \u0627\u0644\u0631\u062d\u0645\u0646 \u0627\u0644\u0631\u062d\u064a\u0645<\/p>\n\n<p style=\"font-name: monospace; line-height: 2; font-size: 20px; font-weight: bold; letter-spacing: 2px; text-align: center;\">\u0627\u0644\u0633\u0644\u0627\u0645 \u0639\u0644\u064a\u0643\u0645 \u0648\u0631\u062d\u0645\u0629 \u0627\u0644\u0644\u0647 \u0648\u0628\u0631\u0643\u0627\u062a\u0647<\/p>\n\nHello fellow kagglers! My name is Azmi, this is my second public notebook Deep Analysis that I made, please give me an upvote before you fork the notebook! and please, leave me your feedback, Hope you like it! In this notebook we're going to Analyst Shopping Cart Database by doing so we're going to get some insights.\n\nI'm planning to go through feature (question) by feature and take closer look those features to inspect their relationships with previous features. So it's gonna take a while to finish this notebook with all features involved. I'm planning to update it regulary whenever I have free time.\n\n*Sorry if my English is bad :') I hope you like it!*\n\nmore about myself: https:\/\/linktr.ee\/mazmimuis","da91c7ee":"> Hmm, if we look the output above, look like the `sales` - `price` is skewed...","4aafa2aa":"> Hmm.. okay, next..","0acbe69d":"> If we look at the visualization and also the values \u200b\u200bthat we have printed above, we can see that `quantity`, `price`, and `sales`, have a good correlation with `sales`, this is because the two features are closely related, for example, `quantity` affects the number of `sales`, because if the `quantity` of products is good and large, and the `price` is also high, then the number of `sales` is also the same.","6d2e2df3":"---","ee80726b":"> Hmm, great! `price_per_unit` - `quantity` is not skewed, otherwise skewed...","a7acabe4":"> You know what? If we look at the $4$ visualizations above, we can see that the male gender occupies the first position in terms of numbers, and I am also a bit surprised, I think that it will be women who will occupy that position because if you think about it, women like shopping the most, lol, I can't say no, because this data says otherwise, and also I don't really understand gender **Non-binary, Polygender, Genderfluid, etc...**, because there are only $2$ genders that I know, Its male and female, if you know about what's non-binary, polygender, and etc... please leave a comment! \n\nLet's move on...","8441d716":"# **Context**\n\nThis dataset contains synthetic data generated by the Dataset Owner for one of the courses at Carnegie Mellon University.","165225f2":"---","2b557348":"---","20568c6c":"## **Statistical Measure**\n\nLet's have a look to the statistical measure in both of data...","841e04e3":"---","bfcd9731":"> Great!, let's have a look for the Statistical Measure...","7d3c4a53":"---","eaf17cde":"> Okay, look like there's no unique variable(s) in Discrete and Continuous data...","6b6ab297":"---","d877ecdd":"<p style=\"font-name: monospace; line-height: 2; font-size: 25px; font-weight: bold; letter-spacing: 2px; text-align: center;\">Understanding Customer demographics and their preferences\n<\/p>","34338149":"---","ff661a90":"---","b0727858":"> **South Australia** took first place with the highest total sales of $907.400$ (Dollar Australia), and **Queensland** took second place with sales of $862.965$ (Dollar Australia).","29cb45a4":"---","4a323296":"---","a5e1ef6c":"**regards,**<br>\n**Azmi**","7d369edb":"# **Inspiration**\n\nSeveral deductions and analyses can be drawn from this data, including:\n\n* Which products were sold the most in the last month?\n* How have sales and revenue changed over the past few quarters?\n* Understanding Customer demographics and their preferences","024a9749":"# **Content**\n\nExample file structure\n```\nshopping_car_data <- top level folder\n\u2514\u2500\u2500\u2500customer.csv\n\u2502   \u2514\u2500\u2500\u2500customers data     \n\u2514\u2500\u2500\u2500orders.csv\n\u2502   \u2514\u2500\u2500\u2500orders data  \n\u2514\u2500\u2500\u2500product.csv\n\u2502   \u2514\u2500\u2500\u2500product data  \n\u2514\u2500\u2500\u2500sales.csv\n    \u2514\u2500\u2500\u2500sales data  \n ```","82ba4acc":"## **Total Price**\n\nFind the proportion that lies in between two standard deviation ($\\sigma$) from mean ($\\mu$), and let's try to interprete that. and In the Total Price Data, the $\\mu = 206.3$ and the $\\sigma = 86.3$, then without further ado let's calculate it.\n\n#### **Calculation:**\n\n* $206.3 - 2(86.3) = 33.7$\n* $206.3 + 2(86.3) = 378.9$\n\n#### ***Interpretation:***\n\nAt least $75\\%$ of the population data sales total price in Australia has a total price range from $33.7 - 378.9$ (Australian Dollars).","f3593afe":"# **Read-in Data**","0a7509bc":"---","966a097d":"![FB_IMG_15637614668311836.jpg](attachment:a137852e-50ec-4828-9c0d-cf081e7979aa.jpg)","08ce7706":"---","0a931159":"![shopping image.jpg](attachment:4f0bbd8b-bc4e-451a-b0e8-7d3461a28350.jpg)","e17bddb6":"## **Price Per-Unit**\n\nFind the proportion that lies in between two standard deviation ($\\sigma$) from mean ($\\mu$), and let's try to interprete that. and In the Price Per Unit Data, the $\\mu = 103.5$ and the $\\sigma = 9.1$, then without further ado let's calculate it.\n\n#### **Calculation:**\n* $103.5 - 2(9.1) = 85.3$\n* $103.5 + 2(9.1) = 121.7$\n\n#### ***Interpretation:***\n\nAt least $75\\%$ of the population of the Shopping Cart Database, the price of each item in Australia ranges in price per unit from $85.3 - 121.7$ (Australian Dollars).","3d72e77b":"---","20650471":"---","4d09bd20":"## **Quantity**\n\nFind the proportion that lies in between two standard deviation ($\\sigma$) from mean ($\\mu$), and let's try to interprete that. and In the Quantity Data, the $\\mu = 2$ and the $\\sigma = 1$, if we round it, then without further ado let's calculate it.\n\n#### **Calculation**:\n\n* $2 - 2(1) = 0$\n* $2 + 2(1) = 4$\n\n#### ***Interpretation:***\n\nAt least $75\\%$ of the population of Shopping Cart Database Quantity ordered in Australia has a quantity range from $0 - 4$ quantity ordered.","5f128cf7":"---","a21ce6e1":"# **Data Preparation**\n\nLet's prepare the data before we visualize and do another stuff...","d9006449":"> Okay, let's go to the Question that have been asked in Inspiration...","547a5d48":"<p style=\"font-name: monospace; line-height: 2; font-size: 30px; font-weight: bold; letter-spacing: 2px; text-align: center;\">Shopping Cart Database Deep Analysis - Knightbearr<\/p>","ed122538":"### ***Answer:***\n\n> If we look at the data visualization above, I think sales and revenue have changed over the last few quarters, you could say there were a few months that saw quite a big increase as well as a pretty big drop, the reason maybe it could be due to the prolonged pandemic and the lockdown in several places in Australia, and also there are **other reasons such as market prices, people's interest in shopping, people's reasons for shopping, product prices, and ingredients to make these products are in short supply**, and yes, We don't know, and it's also quite difficult to predict, because that's how the world is, full of uncertain surprises.","166cd158":"> Strangerrr in the night... ","400ebfaa":"> `sales` data have $5.000$ rows dan $6$ columns, and look like the data is not have any null-values.","4d0e5115":"---","b248f272":"<p style=\"font-name: monospace; line-height: 2; font-size: 20px; font-weight: bold; letter-spacing: 2px; text-align: center;\">\u062a\u062d\u064a\u0629 \u0637\u064a\u0628\u0629\n<\/p>","8ade2ee5":"### **Recap Data**\n\nThis is some point that we have.\n\n#### **Costumer, Order, and Products Data:**\n\n* We have total $1000$ rows and $22$ columns\n* There's no missing value(s)\n* customer_name : $1000$ uniqueness variable(s)\n* gender : $8$ uniqueness variable(s)\n* home_address : $1000$ uniqueness variable(s)\n* city : $961$ uniqueness variable(s)\n* state : $8$ uniqueness variable(s)\n* country : $1$ uniqueness variable(s)\n* order_date : $291$ uniqueness variable(s)\n* delivery_date : $305$ uniqueness variable(s)\n* product_type : $3$ uniqueness variable(s)\n* product_name : $28$ uniqueness variable(s)\n* size : $5$ uniqueness variable(s)\n* colour : $7$ uniqueness variable(s)\n* description : $1000$ uniqueness variable(s)\n\n### **Sales Data:**\n\n* There's no missing value(s)\n* It's not have a uniqueness value(s)\n* All data type in these data is Int$64$\n\n> Next, we will try to do some exploration and visualization. But we need to do some Data Preparation first.","dad21c16":"---","4793c36a":"---","9bab2bed":"---","c53683c9":"### **Convert Order Date column**\nAnd let's convert Order Date column too, so we can take the Year, Month, and the other date easily.","0e55a5c0":"### Haha, I'm joking, hope my notebook is useful for you **Kagglers**! thank you for watching! ","25fa5ca8":"## **Sales**\n\nFind the proportion that lies in between two standard deviation ($\\sigma$) from mean ($\\mu$), and let's try to interprete that. and In the Sales Data, the $\\mu = 6533$ and the $\\sigma = 1409$ if we round it, then without further ado let's calculate it.\n\n#### **Calculation:**\n\n* $6533 - 2(1409) = 3715$\n* $6533 + 2(1409) = 9531$\n\n#### ***Interpretation:***\n\nAt least $75\\%$ of the Shopping Cart Database Sales customer population in Australia has sales ranging from $3.715 - 9.531$ (Australian Dollars).","b0fd6875":"# **On Going...**","9e199830":"# **Check Data**\n\nLet's see the data and how it looks.","27c07326":"> Great! let's have a look to the categorical type..."}}