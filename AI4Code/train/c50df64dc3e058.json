{"cell_type":{"019d2f14":"code","f6eb3108":"code","83141f4a":"code","683dbeaf":"code","27014dac":"code","a9d22e76":"code","8cfd480c":"code","9b7b9177":"code","7b0f58be":"code","3a3becd8":"code","2a42806b":"code","da0a2ebd":"code","c665be76":"code","95bd41c1":"code","5cc25e59":"code","6951552e":"code","c38c6e83":"code","32fab64d":"code","7f969e24":"code","7b347613":"code","2c51cd16":"code","ad6815dc":"code","4fd129d7":"code","ecee3c3b":"code","e966474e":"code","be15df63":"code","4e0e74d6":"code","08e37c4a":"code","b7a229aa":"code","058be259":"code","80ce5537":"code","08e8aa48":"code","65ad561b":"code","962a4acf":"code","25903d04":"code","0c731a71":"code","ae344d70":"code","a54b0e55":"code","5879f4f1":"code","4a6bf5d5":"code","628dfcbc":"code","bc3d07da":"code","ddb13cdd":"code","82e95b00":"code","1b35fc53":"code","34c9fdb8":"code","5ecab513":"code","caf73f60":"code","da69c2da":"code","57556c9b":"code","5f73635f":"code","68dfcf7b":"code","34c60c3f":"code","1863d392":"code","568a60e5":"code","2d97d481":"code","055019ef":"code","80e08b3c":"code","5ad6e997":"code","225660cc":"code","af4d472b":"code","612cd8f9":"code","f02bc596":"markdown","f4cadeb7":"markdown","43113b9d":"markdown","8daa585a":"markdown","95b28955":"markdown","e4f07ccf":"markdown","23aa854e":"markdown","c7eda1ef":"markdown","3b720a46":"markdown","3484e201":"markdown","b9974c46":"markdown","7cfd88e8":"markdown","aa0079b6":"markdown","d204b852":"markdown","eaf7b458":"markdown","4b549c84":"markdown","13853ca9":"markdown","4d0a536c":"markdown","0104f3f6":"markdown","6a3ce55e":"markdown"},"source":{"019d2f14":"#Importing required packages.\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold, cross_val_predict, StratifiedKFold\n\n%matplotlib inline\n","f6eb3108":"# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.machine_learning.ex2 import *\nprint(\"Setup Complete\")","83141f4a":"# print the folder name, so it can be added to the file path in next code kernel below (before adding the csv file name)\nprint(os.listdir(\"..\/input\"))","683dbeaf":"#Loading dataset\nwine = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","27014dac":"# checking a first few lines of the dataset\nwine.head()","a9d22e76":"# to check the variables we are working with\nwine.info()","8cfd480c":"# we can see non-null for each column but in case we want to check how many nulls in each column\nwine.isnull().sum()","9b7b9177":"# check the range of values in Quality column so that bins for Good and Bad wines can be created\nwine['quality'].hist()","7b0f58be":"bins = (2, 6.5, 8)\ngroup_names = ['bad', 'good']\nwine['quality'] = pd.cut(wine['quality'], bins = bins, labels = group_names)","3a3becd8":"# now the column has been changed form numerical to categorical\nwine['quality'].unique()","2a42806b":"# to encode bad as 0 and good as 1, use the sklearn preprocessing function\nlabel_quality = LabelEncoder()\nwine['quality'] = label_quality.fit_transform(wine['quality'])","da0a2ebd":"#check the dataset again to see the quality column having binary values\nwine.head(10)","c665be76":"# count number of good and bad quality wines\nwine['quality'].value_counts()","95bd41c1":"#bar plot using Seaborn package\nsns.countplot(wine['quality'])","5cc25e59":"# without using the seaborn package, generating the visualization\n# wine['quality'].hist() # this treats the 0 and 1's as integers instead of categories\nwine['quality'].value_counts().plot(kind='bar')","6951552e":"# Dividing dataset into predictor (X) and response features (y)\nX = wine.drop('quality', axis = 1) # axis = 0 means row; axis = 1 means columns; so here we select all columns except quality\ny = wine['quality']","c38c6e83":"# Split into train and test datasets (using sklearn package)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # using 20% of data for testing hence 0.2; random state is like setting a seed","32fab64d":"# We scale the data using standardized scaling so that columns with higher numerical values (eg. total sulphur dioxide) are not biased compared to columns with very small numerical values (e.g. chlorides)\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train) #fit_transform is gonna fit AND transform at the same time, much like label encoder\nX_test = sc.transform(X_test) # we want the same fit (i.e. values of mean and standard deviation for each column) that we used for (centering the) training data so instead of fit_transform() (which internally calls fit() followed by transform()), we just use transform()","7f969e24":"#checking to see how the scaled valued look like\nX_train[1:10] #since X_train is an array now, not a dataframe","7b347613":"rfc = RandomForestClassifier(n_estimators= 200) # n_estimators equals how many forests do you need. start with a higher number and bring it down slowly as smaller the model better the fit\nrfc.fit(X_train, y_train)\npred_rfc = rfc.predict(X_test)","2c51cd16":"#check some of the predicted values\npred_rfc[1:40]","ad6815dc":"#confusion matrix\nprint(confusion_matrix(y_test, pred_rfc))","4fd129d7":"#let's check model's accuracy at prediction using the testing set we have (i.e. y_test)\nprint(classification_report(y_test, pred_rfc))","ecee3c3b":"# another way to print out accuracy explicity (using scikit-learn)\naccuracy_score(y_test, pred_rfc)","e966474e":"f1_score(y_test, pred_rfc)","be15df63":"clf = SVC()\nclf.fit(X_train, y_train)\npred_clf = clf.predict(X_test)","4e0e74d6":"#let's check model's accuracy at prediction using the testing set we have (i.e. y_test)\nprint(classification_report(y_test, pred_clf))\nprint(confusion_matrix(y_test, pred_clf))","08e37c4a":"# another way to print out accuracy explicity (using scikit-learn)\naccuracy_score(y_test, pred_clf)","b7a229aa":"# another way to print out accuracy explicity (using scikit-learn)\nclf.score(X_test, y_test)","058be259":"# Grid search Cross Validation : automatically find good values for the SVM classifier parameters by using tools such as grid search and cross-validation\n\n# Set the parameter candidates\nparameter_candidates = {\n    'C': [0.1,0.8,0.9,1,1.1,1.2,1.3,1.4],\n    'kernel':['linear', 'rbf'],\n    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n}\n\n# Create a classifier with the parameter candidates\ngrid_svc = GridSearchCV(estimator=clf, param_grid=parameter_candidates, scoring='accuracy', cv=10)\n# estimator = model we are using for hyperparameter tuning\n# param_grid = list of parameters and the range of values for each parameter of the specified estimator\n# cv: to determine the hyper-parameter value set (i.e. [C = , kernel = , gamma = ]) which provides the best accuracy level\n\n# Train the classifier on training data\ngrid_svc.fit(X_train, y_train)","80ce5537":"#Best parameters for our svc model\nprint(grid_svc.best_params_)\n\n#OR\n\n# Print out the results individually\nprint('Best score for training data:', grid_svc.best_score_)\nprint('Best `C`:',grid_svc.best_estimator_.C)\nprint('Best kernel:',grid_svc.best_estimator_.kernel)\nprint('Best `gamma`:',grid_svc.best_estimator_.gamma)","08e8aa48":"#Let's run our SVC again with the best parameters.\nsvc2 = SVC(C = 1.2, gamma =  0.9, kernel= 'rbf') # kernel is a similarity function used to compute similarity between training data points\nsvc2.fit(X_train, y_train)\npred_svc2 = svc2.predict(X_test)\nprint(classification_report(y_test, pred_svc2))","65ad561b":"print(svc2.score(X_test, y_test)) #OR\nprint(accuracy_score(pred_svc2, y_test))","962a4acf":"mlpc = MLPClassifier(hidden_layer_sizes = (11,11,11), max_iter = 500) # hidden_layer_size is the number of nodes in each of the three layer. we chose 11 because we have 11 predictor features in our original data\nmlpc.fit(X_train, y_train)\npred_mlpc = mlpc.predict(X_test)","25903d04":"# checking the accuracy of model\nprint(classification_report(y_test, pred_mlpc))\nprint(confusion_matrix(y_test, pred_mlpc))","0c731a71":"# another way to print out accuracy explicity (using scikit-learn)\naccuracy_score(y_test, pred_mlpc)","ae344d70":"# Finally we want to see what happens when we feed in brand new data into the classifier and see what sort of predictions it churns out\n\n# to do that we first create a vector of values i.e. give as input one row of data  (here we are giving 2 inputs so we will get 2 prediction outputs)\nXnew = [[7.3, 0.58, 0.00, 2.0, 0.065, 15.0, 21.0, 0.9946, 3.36, 0.47, 10.0], \n        [9.3, 0.58, 0.20, 3.0, 0.065, 16.0, 22.0, 0.9946, 5.96, 0.47, 12.0]]\nXnew = sc.transform(Xnew) # very imp step because the classifier was designed using scaled data and any input to the classifier must also be scaled that too using the same 'sc' that was fitted using the original training data\nYnew = mlpc.predict(Xnew)\nYnew # Based on the predictions, both the wine inputs are supposedly poor quality wines (i.e. quality = 0)","a54b0e55":"sgdc = SGDClassifier(loss = \"hinge\", penalty = \"l2\", max_iter = 500) #the concrete loss function is set via the loss parameter\nsgdc.fit(X_train, y_train)\npred_sgdc = sgdc.predict(X_test)","5879f4f1":"#check accuracy\naccuracy_score(pred_sgdc, y_test)","4a6bf5d5":"# to see the model parameters to be reported in journal papers\nsgdc.coef_","628dfcbc":"# to see the intercepts\nsgdc.intercept_","bc3d07da":"knn = KNeighborsClassifier(n_neighbors = 2) # to see rule of thumb for selecting n_neighbour parameter, see Section 5.1 below\nknn.fit(X_train, y_train)\npred_knn = knn.predict(X_test)","ddb13cdd":"#checking the accuracy\naccuracy_score(pred_knn, y_test)","82e95b00":"# printing the confusion matrix\nprint(confusion_matrix(pred_knn, y_test))","1b35fc53":"# printing the classification report\nprint(classification_report(pred_knn, y_test))","34c9fdb8":"print(len(X_train))\nimport math\nprint(math.sqrt(len(X_train))) # this should be the value of k in knn algo","5ecab513":"#lets try running the knn model with new k values and see if there is any improvement in accuracy\nknn_opt = KNeighborsClassifier(n_neighbors = 35, p = 2, metric= \"euclidean\") # p=2 because outcome can only take two values: good (0) or bad (1)\nknn_opt.fit(X_train, y_train)\npred_knn_opt = knn_opt.predict(X_test)\n#checking the accuracy\naccuracy_score(pred_knn_opt, y_test)","caf73f60":"# printing the confusion matrix\nprint(confusion_matrix(pred_knn_opt, y_test))","da69c2da":"# also imp to look at f1 score because that one will tell you false positives\/negatives in addition to accuracy which tells us how many we got right and how many we got wrong (i.e. true positives and true negatives)\nprint(f1_score(pred_knn_opt, y_test)) # perfect precision and recall gives f1 score as 1 and at worst 0. ","57556c9b":"knn = KNeighborsClassifier()\nparameter_candidatess = {\n    'n_neighbors': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n}\ncross_validation = StratifiedKFold(n_splits=10, random_state = 45)\n\ngrid_knn = GridSearchCV(estimator = knn, param_grid = parameter_candidatess, scoring = 'accuracy', cv = cross_validation)\ngrid_knn.fit(X_train, y_train)\ngrid_knn.best_params_","5f73635f":"knn2 = KNeighborsClassifier(n_neighbors = 60, p = 2, metric= \"euclidean\")\nknn2.fit(X_train, y_train)\npred_knn2 = knn2.predict(X_test)","68dfcf7b":"#check accuracy after parameter tuning\naccuracy_score(pred_knn2, y_test)","34c60c3f":"dtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\npred_dtc = dtc.predict(X_test)","1863d392":"accuracy_score(pred_dtc, y_test)\n# print(accuracy_score(pred_dtc, y_test))","568a60e5":"# As of now decision tree classifier was created using default values, but now lets try to figure out the 'best' hyperparameters\n\nparameter_candidates = {\n    'criterion': ['gini', 'entropy'],\n    'min_samples_leaf' :[1,2,3,4,5],\n    'max_depth': [2,3,4,5,6,7,8,9,10]\n}\n\ngrid_dtc = GridSearchCV(estimator = dtc, param_grid= parameter_candidates, scoring= 'accuracy', cv = 5)","2d97d481":"grid_dtc.fit(X_train, y_train)\ngrid_dtc.best_params_","055019ef":"# Recreating the dtc model but with the new hyperparameters obtained\ndtc2 = DecisionTreeClassifier(criterion= 'gini', max_depth = 2, min_samples_leaf= 1)\ndtc2.fit(X_train, y_train)\npred_dtc2 = dtc2.predict(X_test)","80e08b3c":"#check accuracy of new model\naccuracy_score(pred_dtc2, y_test) ","5ad6e997":"scores = [] # to store the accuracy obtained from each 'fold'\nbest_clf = SVC(gamma= \"auto\") # we had to set the gamma parameter because we were getting a warning saying in the next version, the default value will change from gamma to auto so it is better to explicitly define one\ncv = KFold(n_splits=10, random_state=42, shuffle=False) #it is a 10-fold cv so n_splits = 10\nfor train_index, test_index in cv.split(X):\n    # printing out the indexes of the training and the testing sets in each iteration \n    # to clearly see the process of K-Fold CV where the training and testing set changes in each iteration\n    print(\"Train Index: \", train_index, \"\\n\")\n    print(\"Test Index: \", test_index)\n    \n    # setting the training and testing sets in each iteration,\n    # followed by generating the model using the X_train and y_train datasets and\n    # finally recording the accuracy for each model (after testing with the X_test and y_test datasets) in the 'scores' array\n    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n    best_clf.fit(X_train, y_train)\n    scores.append(best_clf.score(X_test, y_test))","225660cc":"# We appended each score to a list called 'scores' and now, \n# we get the mean value in order to determine the overall accuracy of the model.\nprint(np.mean(scores))","af4d472b":"# this will give you a list of r2 scores \nbest_clf_eval =  cross_val_score(best_clf, X, y, cv=10)\n\n# we will average all the scores to get a mean value from the 'new' and improved model\nbest_clf_eval.mean()","612cd8f9":"# this will give you a list of predictions using the 'new' and improved model\ncross_val_predict(best_clf, X, y, cv=10) # output will be 0 or 1 depending on whether wine was good (0) or bad (1)","f02bc596":"## 6. Decision trees","f4cadeb7":"## 4. Stochastic Gradient Descent Classifier \n#### supports different penalties for misclassification ","43113b9d":"#### 6.1 Parameter tuning for Decision trees","8daa585a":"### Alternative (and much simpler way to do K-fold Cross validation)","95b28955":"#### We see a very big increment from 0.83 to 0.86","e4f07ccf":"### We are going to look at few models and compare them","23aa854e":"## 2. SVM classifier \n#### works better with smaller numbers\n","c7eda1ef":"## Beginning our predictive models with some pre-processing using Scikit functions","3b720a46":"### Longer way to do the 10fold CV \n(in few minutes, we will introduce a one-line code for doing the same.","3484e201":"## Pre-processing data: addition of new categorical column to perform ML agorithms","b9974c46":"#### Thus, we observe a small increment in the accuract from 0.853 (n_neighbors = 35) to 0.859 (n_neighbors = 60)","7cfd88e8":"#### Overall, we saw a reduction in accuracy meaning there can be better values for n_neighbours. We will now see how to choose the best value using GridSearch CV","aa0079b6":"### Parameter Tuning: To increase the accuracy of the classifier we created.\n\nWe need to have a more systematic way of selecting the parameters which were used to create the classifier *(i.e. parameter tuning)*.","d204b852":"## 1. Random Forest Classifier\n#### works well for mid-sized data","eaf7b458":"## 3. Neural networks\n#### works well with large data \/ text analyses \/ time series","4b549c84":"### Generating visualization to analyze the data","13853ca9":"##### As we can see, we saw an increment from 0.875 (clf accuracy) to 0.896 ( svm2 accuracy) by adjusting the parameters","4d0a536c":"#### 5.1 Rule of thumb for selection of number of neigbors in knn\n\n#### how to choose value of k: too small value, too much noice, too big value require larger computational resources\n\nOptions: k = \n1. sqrt(n) where n = number of data points ; \n** if it comes out to be even, add or subtract 1 to make odd (P.S. Odd values of k is preferred to avoid confusion between binary groupings) \n\nhttps:\/\/www.youtube.com\/watch?v=4HKqjENq9OU : useful link to understand KNN algo at 06:49","0104f3f6":"## BONUS SECTION: 10-fold Cross validation\n\nWhat this means is that currently the models are created using a 80:20 data split (80 for training and 20 for testing). however what if all the extreme cases fall into the testing dataset or vice versa. Thus to avoid this, we create folds (or sections) in our data such that *each* fold is used at least once for testing the model. The overall aim behind doing so is increasing the accuracy of model. The new model will be less biased since it does not depend upon what portion of the data was initially selected for testing\/training since we involve ALL data in the model testing\/training process.","6a3ce55e":"## 5. KNN - nearest neighbour"}}