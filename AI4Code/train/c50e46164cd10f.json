{"cell_type":{"df67008a":"code","f68f28fc":"code","b6ec9332":"code","aa505c5c":"code","e6cde05d":"code","6ae6cda1":"code","b627b144":"code","eac691a7":"code","f2c6624e":"code","fd0e1324":"code","619fd825":"code","100ede2e":"code","d376dd98":"code","f30f3b2d":"code","2924b5db":"code","c778c935":"code","1a5d9ee0":"code","313b9cd6":"code","4e1a6e76":"code","df9710d0":"code","e6bf1a29":"code","0a4fdcaf":"code","b5466e6a":"code","46b63658":"code","f115a5f9":"code","bea8b359":"code","23c57e36":"code","60814cd8":"code","fc671e8e":"code","a6bb3670":"code","dabc9ce4":"code","22cdaaf3":"code","5f2ec149":"code","09684096":"markdown","82af9697":"markdown","56f2565a":"markdown","adc4a6f9":"markdown","3726b39a":"markdown","da7e8049":"markdown","2d3cc301":"markdown","7125d2c0":"markdown","555c3811":"markdown","00f3a00c":"markdown","6834f826":"markdown","1b49566b":"markdown","2b0287e6":"markdown","9a99eb78":"markdown","9bf1229e":"markdown","6b572a65":"markdown","93276820":"markdown","c288f2eb":"markdown","99ff3b87":"markdown","ac6d4400":"markdown","16064744":"markdown","590eb602":"markdown","1d1464b5":"markdown","61a7eebd":"markdown","4f0c2c74":"markdown","5c0b61ff":"markdown","97a40705":"markdown","53577cb2":"markdown","d0079e80":"markdown","5323dc6d":"markdown","40ac9141":"markdown","881fa139":"markdown","2816ae4d":"markdown","d9fcd19d":"markdown","8eb2c1ff":"markdown"},"source":{"df67008a":"#DO NOT DISTURB!\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# the King and the Queen of libraries\nimport pandas as pd\nimport numpy as np\n\n#friendly stats\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n#plots\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nplt.style.use('ggplot')\nimport seaborn as sns\n\n#Modeling\nfrom sklearn import ensemble, metrics\nfrom sklearn import linear_model, preprocessing\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.kernel_ridge import KernelRidge\nimport xgboost as xgb","f68f28fc":"df_train=pd.read_csv('..\/input\/train.csv', index_col='Id')\ndf_test=pd.read_csv('..\/input\/test.csv', index_col='Id')\n#Save the 'Id' column\ntrain_ID = df_train.index\ntest_ID = df_test.index\n","b6ec9332":"print('the Train dataframe shape is:',df_train.shape,' while the Test dataframe shape is:',df_test.shape)","aa505c5c":"df_train.head(5)","e6cde05d":"df_test.head(5)","6ae6cda1":"fig, ax = plt.subplots()\nax.scatter(x = df_train['GrLivArea'], y = df_train['SalePrice'], color='blue')\nplt.ylabel('Sale_Price', fontsize=13)\nplt.xlabel('Ground_Living_Area', fontsize=13)\nplt.show()","b627b144":"df_train = df_train.drop((df_train[df_train['GrLivArea']>4000]).index)","eac691a7":"#looking at the df_train without the two outliers\nfig, ax = plt.subplots()\nax.scatter(x = df_train['GrLivArea'], y = df_train['SalePrice'], color='blue')\nplt.ylabel('Sale_Price', fontsize=13)\nplt.xlabel('Ground_Living_Area', fontsize=13)\nplt.show()","f2c6624e":"sns.distplot(df_train['SalePrice'] , fit=norm, color='blue');\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(df_train['SalePrice'])\nprint('mu:',mu,'sigma:',sigma)\n\n#Let's plot the distribution of Sale Price\nplt.legend(['Normal dist'],loc='best')\nplt.ylabel('Frequency')\nplt.title('Sale_Price distribution')","fd0e1324":"#Numpy Abrakadabra!\nSALEPRICE_ABRAKADABRA=df_train[\"SalePrice\"]\nSALEPRICE_ABRAKADABRA= np.log1p(SALEPRICE_ABRAKADABRA)\n\n#And now\nsns.distplot(SALEPRICE_ABRAKADABRA , fit=norm,color='blue');\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(SALEPRICE_ABRAKADABRA)\nprint('mu:',mu,'sigma:',sigma)\n\n#Let's plot again the distribution of Sale Price\nplt.legend(['Normal dist'],loc='best')\nplt.ylabel('Frequency')\nplt.title('Sale_Price distribution')","619fd825":"quantitative = [i for i in df_train.columns if df_train.dtypes[i] != 'object']\nquantitative.remove('SalePrice')\nqualitative = [j for j in df_train.columns if df_train.dtypes[j] == 'object']\nprint('Quantitative:',quantitative)\nprint('')\nprint('Qualitative:',qualitative)","100ede2e":"merged_data = df_train.append(df_test, sort=False).reset_index(drop=True)\nprint(\"The size of the merged data is:\", merged_data.shape)\nntrain = df_train.shape[0]\nntest = df_test.shape[0]\ny_train = df_train.SalePrice.values","d376dd98":"missing = merged_data.isnull().sum()\nmissing = missing[missing > 0]\nmissing50=missing[missing>=2915\/2] #feature with_more than 50 percent of all data missing\nmissing.sort_values(inplace=True)\ndel missing['SalePrice']\ndel missing50['SalePrice']\nmissing.plot.bar()","f30f3b2d":"print('Features with missing values:\\n',missing)\nprint('')\nprint('Total of features with missing values:\\n',len(missing))\nprint('')\nprint('Total of the missing values of the features with more than 50 percent of all data missing:\\n',missing50)","2924b5db":"merged_data[\"Alley\"] = merged_data[\"Alley\"].fillna(\"None\")\n\nmerged_data[\"Fence\"] = merged_data[\"Fence\"].fillna(\"None\")\n\nmerged_data[\"MiscFeature\"] = merged_data[\"MiscFeature\"].fillna(\"None\")\n\nmerged_data[\"PoolQC\"] = merged_data[\"PoolQC\"].fillna(\"None\")\n\nmerged_data[\"FireplaceQu\"] = merged_data[\"FireplaceQu\"].fillna(\"None\")\n\nmerged_data[\"LotFrontage\"] = merged_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    merged_data[col] = merged_data[col].fillna('None')\n    \nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    merged_data[col] = merged_data[col].fillna(0)\n    \nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    merged_data[col] = merged_data[col].fillna(0)\n    \nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    merged_data[col] = merged_data[col].fillna('None')\n    \nmerged_data[\"MasVnrType\"] = merged_data[\"MasVnrType\"].fillna(\"None\")\n\nmerged_data[\"MasVnrArea\"] = merged_data[\"MasVnrArea\"].fillna(0)\n\nmerged_data['MSZoning'] = merged_data['MSZoning'].fillna(merged_data['MSZoning'].mode()[0])\n\nmerged_data = merged_data.drop(['Utilities'], axis=1)\n\nmerged_data[\"Functional\"] = merged_data[\"Functional\"].fillna(\"Typ\")\n\nmerged_data['Electrical'] = merged_data['Electrical'].fillna(merged_data['Electrical'].mode()[0])\n\nmerged_data['KitchenQual'] = merged_data['KitchenQual'].fillna(merged_data['KitchenQual'].mode()[0])\n\nmerged_data['Exterior1st'] = merged_data['Exterior1st'].fillna(merged_data['Exterior1st'].mode()[0])\n\nmerged_data['Exterior2nd'] = merged_data['Exterior2nd'].fillna(merged_data['Exterior2nd'].mode()[0])\n\nmerged_data['SaleType'] = merged_data['SaleType'].fillna(merged_data['SaleType'].mode()[0])\n\nmerged_data['MSSubClass'] = merged_data['MSSubClass'].fillna(\"None\")","c778c935":"merged_data.head(10)","1a5d9ee0":"#Check\nmerged_data_NA_VALUES =merged_data.isnull().sum()","313b9cd6":"merged_data['TotalSF'] = merged_data['TotalBsmtSF'] + merged_data['1stFlrSF'] + merged_data['2ndFlrSF']","4e1a6e76":"merged_data['MSSubClass'] = merged_data['MSSubClass'].apply(str)\nmerged_data['OverallCond'] = merged_data['OverallCond'].astype(str)\nmerged_data['YrSold'] = merged_data['YrSold'].astype(str)\nmerged_data['MoSold'] = merged_data['MoSold'].astype(str)","df9710d0":"from sklearn.preprocessing import LabelEncoder\ncolumns = ['LandContour',  'MSZoning',  'Alley',\n      'MasVnrType',  'ExterQual',  'ExterCond',\n      'BsmtQual',  'BsmtCond',  'BsmtExposure',\n      'BsmtFinType1',  'BsmtFinType2', 'HeatingQC',\n      'CentralAir',  'KitchenQual',  'FireplaceQu',\n      'GarageFinish',  'GarageQual',  'GarageCond',\n      'PavedDrive',  'PoolQC',  'MiscFeature']\nfor col in columns:\n    lbl = LabelEncoder() \n    lbl.fit(list(merged_data[col].values)) \n    merged_data[col] = lbl.transform(list(merged_data[col].values))\n    \ncolumns_Qual=['LotShape', 'LotConfig', 'LandSlope', 'Neighborhood',\n       'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n       'Foundation', 'Heating', 'Electrical', 'Functional',\n       'GarageType', 'GarageCond', 'Fence', 'SaleType',\n       'SaleCondition', 'Street']\ntemp = pd.get_dummies(merged_data[columns_Qual], drop_first=True)\nmerged_data = merged_data.drop(columns_Qual, axis=1)\nmerged_data = pd.concat([merged_data, temp], axis=1)","e6bf1a29":"df_train = merged_data[merged_data['SalePrice'].notnull()]\ndf_test = merged_data[merged_data['SalePrice'].isnull()].drop('SalePrice', axis=1)","0a4fdcaf":"x_train = df_train.drop(['SalePrice'], axis=1)\ny_train = df_train['SalePrice']\nx_test  = df_test","b5466e6a":"scaler = preprocessing.RobustScaler();\nx_train_scaled = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\nx_test_scaled = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)","46b63658":"df_test.shape","f115a5f9":"KRR = KernelRidge(alpha=0.05, kernel='polynomial', degree=1, coef0=2.5)","bea8b359":"lasso = linear_model.Lasso(alpha=0.001, max_iter=5000, random_state=42)","23c57e36":"GBoost = ensemble.GradientBoostingRegressor(n_estimators=1000, learning_rate=0.05, max_depth=3, max_features='sqrt', loss='huber', random_state=42)","60814cd8":"from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n#It is very useful to create a class in order to make predictions with the above defined models! \n\nclass Averaging_the_models(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, cool_models, peso):\n        self.cool_models = cool_models\n        self.peso = peso\n        \n    def fit(self, X, y):\n        self.cool_models_ = [clone(x) for x in self.cool_models]\n        for model in self.cool_models_:\n            model.fit(X, y)\n        return self\n    \n    def predict(self, X):\n        predictions = np.column_stack([(model.predict(X) * peso) for model, peso in zip(self.cool_models_, self.peso)])\n        return np.sum(predictions, axis=1)","fc671e8e":"regression = Averaging_the_models(cool_models=(KRR, lasso, GBoost), peso=[0.25, 0.25, 0.50])","a6bb3670":"regression.fit(x_train_scaled, np.log1p(y_train))\nresult = np.expm1(regression.predict(x_test_scaled))","dabc9ce4":"subFDS = pd.DataFrame({\n    \"Id\": test_ID,\n    \"SalePrice\": result\n})\nsubFDS.to_csv(\"subFDS.csv\", index=False)","22cdaaf3":"def rmse_cv(model, x, y):\n    rmse = np.sqrt(-cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=5))\n    return rmse\n\nscore = rmse_cv(regression, x_train_scaled, np.log1p(y_train))\nprint(round(score.mean(), 5))","5f2ec149":"subFDS","09684096":"<font color='Black'>**Reading the Description file and some more information about the data, provided by the author http:\/\/jse.amstat.org\/v19n3\/decock.pdf I found out that there are outliers present in the training data. We can explore these outliers using a scatter plot!**<\/font><br\/>","82af9697":"<font color='Black'>**We got it!**<\/font><br\/>","56f2565a":"<font color='Blue'>**House Prices: Advanced Regression Techniques**<\/font><br\/>","adc4a6f9":"<font color='Red'>**Model**<\/font><br\/>","3726b39a":"<font color='Black'>**\"When in doubt, go to the library.\"\n J.K. Rowling**<\/font><br\/>","da7e8049":"<font color='Black'>**Let's load the train and test dataframes using Pandas the king of the libraries, let's then have a look to their shape and to their the firsts rows**<\/font><br\/>","2d3cc301":"<font color='Black'>**Let's find out which features are quantitative and which instead are qualitative**<\/font><br\/>","7125d2c0":"<font color='Black'>**Sale Price variable is right skewed. But we can log-transform it thanks to Queen Numpy!**<\/font><br\/>","555c3811":"<font color='Blue'>**Prediction**<\/font><br\/>","00f3a00c":"<font color='Blue'>**Features engineering**<\/font><br\/>","6834f826":"<font color='Red'>**The target: Sale Price**<\/font><br\/>","1b49566b":"<font color='Black'>**It's easy to spot at the bottom right two values with extremely large Ground_Living_Area that are offered at a low price. These values are oultliers, therefore it is good to delete them.**<\/font><br\/>","2b0287e6":"<font color='Black'>**Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.**<\/font><br\/>","9a99eb78":"<font color='Black'>**LASSO REGRESSION**<\/font><br\/>","9bf1229e":"<font color='Red'>**Quantitative and qualitative**<\/font><br\/>","6b572a65":"<font color='red'>**Outliers**<\/font><br\/>","93276820":"<font color='Black'>**KERNEL RIDGE REGRESSION**<\/font><br\/>","c288f2eb":"<font color='Blue'>**The Datasets**<\/font><br\/>","99ff3b87":"<font color='Blue'>**Competition description**<\/font><br\/>","ac6d4400":"<font color='Black'>**Label Encoding thanks to sklearn preprocessing :)**<\/font><br\/>","16064744":"<font color='Blue'>**Libraries**<\/font><br\/>","590eb602":"<font color='Black'>**Prediction**<\/font><br\/>","1d1464b5":"<font color='Black'>**It is good to continue our Feature engineering using the train and test dataframes**<\/font><br\/>","61a7eebd":"<font color='Black'><br\/>\n- Alley : Data description says NA means \"no alley access\"\n- Fence : Data description says NA means \"no fence\"\n- MiscFeature : Data description says NA means \"no misc feature\"\n- PoolQC : Data description says NA means \"No Pool\".\n- FireplaceQu : Data description says NA means \"no fireplace\"\n- LotFrontage : The area of each street connected to the house property often has a similar area to other houses in its neighborhood, so let's fill in missing values by the median LotFrontage of the neighborhood.\n- GarageType, GarageFinish, GarageQual and GarageCond : Data description says NA means None\n- GarageYrBlt, GarageArea and GarageCars : we can replace missing data with 0\n- BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath and BsmtHalfBath : Missing values are likely zero for having no basement\n- BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1 and BsmtFinType2 : For all these categorical basement-related features, NaN means that there is no basement.\n- MasVnrArea and MasVnrType : NA means no masonry veneer for these houses.\n- MSZoning: We could fill in missing values with the mode\n- Utilities : Since the house with 'NoSewa' is in the training set, other values are set on 'AllPub' this feature won't help in predictive modelling. We can remove it!\n- Functional : data description says NA means typical.\n- Electrical : We could fill in missing values with the mode\n- KitchenQual: We could fill in missing values with the mode\n- Exterior1st and Exterior2nd: We could fill in missing values with the mode\n- SaleType : We could fill in missing values with the mode\nFinally\n- MSSubClass :Here NA means No building class, so we can replace missing values with None<\/font><br\/>","4f0c2c74":"<font color='Black'>**Gradient Boosting REGRESSION**<\/font><br\/>","5c0b61ff":"<font color='Black'>**GOODBYE MISSING VALUES!**<\/font><br\/>","97a40705":"<font color='Black'>**Let's create a new variable: the total squarefootage!**<\/font><br\/>","53577cb2":"<font color='Blue'>**Processing Data**<\/font><br\/>","d0079e80":"<font color='Black'>**Root Mean Square Error of cross validation**<\/font><br\/>","5323dc6d":"<font color='Black'>**Some of the quantitative variables such as \"MSSubClass\",\"OverallCond\",\"YrSold\",'MoSold\" are qualitative features!! We need to tranform them!!**<\/font><br\/>","40ac9141":"<font color='Black'>**Let's see if Sales Price follows a normal distribution, which would be great for linear models**<\/font><br\/>","881fa139":"<font color='Red'>**Missing data**<\/font><br\/>","2816ae4d":"<font color='Black'>**Let's get back our df_train and df_test with their new cool appearence**<\/font><br\/>","d9fcd19d":"<font color='Black'>**DON'T JUDGE A BOOK BY ITS COVER!!! Most of times NA means lack of subject described by attribute, like missing pool, no garage and basement etc...indeed if we have a look to the file description we find out that**<\/font><br\/>","8eb2c1ff":"<font color='Black'>**Scaling**<\/font><br\/>"}}