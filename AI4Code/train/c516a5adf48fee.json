{"cell_type":{"1602d75a":"code","e1726865":"code","c1aa225e":"code","c2b85c46":"code","2c349174":"code","1beab4bd":"code","dc9c8792":"code","1a8c0f10":"code","8ead1d04":"code","231cb5c1":"code","887d5f9e":"code","1dad2e47":"code","0bb0710c":"code","011e4bee":"code","0e178f60":"code","cb8b0c47":"code","faac178c":"code","0a126d68":"code","ad8e6212":"code","4f699453":"code","8ad3faba":"code","85845fdb":"code","cdf82310":"code","b5bab481":"code","eaccfc41":"code","b161a2b3":"code","029dfe0f":"code","46194716":"code","68fd09a8":"code","c63e23b7":"code","25bbe582":"code","50cc7891":"code","36607c9b":"code","8669d4d7":"code","288d2725":"code","ffcbdc0b":"code","ad0aa75a":"code","1aa78223":"code","0f237864":"code","da4e36e0":"code","e0280e24":"code","eda83b96":"code","203df4d7":"code","32325474":"code","e793a18e":"code","802d2da9":"code","680676e6":"code","91dc7b3c":"code","35f0637a":"code","b0e22959":"code","cae56669":"code","e5f22adc":"code","2442100a":"code","176e6e46":"code","34628b82":"code","70df4772":"code","5f595c2b":"code","7947462b":"code","209cc0c6":"markdown","0fabf9cd":"markdown","7aef6683":"markdown","d1a752ae":"markdown","b2c50f36":"markdown","35cf179f":"markdown","b298b043":"markdown","873d527d":"markdown","3cf9350c":"markdown","ad07bb9d":"markdown","b552577b":"markdown","6004d8b6":"markdown","496651df":"markdown","3446b7d7":"markdown","14b8c285":"markdown","353557a2":"markdown","9d1ff965":"markdown","5483c61b":"markdown"},"source":{"1602d75a":"#importing the required libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom matplotlib import rcParams\nimport warnings\nwarnings.filterwarnings('ignore')","e1726865":"df=pd.read_csv('..\/input\/pca-dataset\/pca.csv')\ndf.head()","c1aa225e":"df.tail(5)","c2b85c46":"df.dtypes","2c349174":"df.info()","1beab4bd":"df.describe()","dc9c8792":"df.shape","1a8c0f10":"df.isnull()","8ead1d04":"df.isnull().sum()","231cb5c1":"df.fillna(df.mean(), axis = 0, inplace = True)\ndf.isnull().sum()","887d5f9e":"df.groupby('class').count()","1dad2e47":"df['class'].value_counts()","0bb0710c":"df.corr()","011e4bee":"rcParams['figure.figsize']=(16,10)\nsns.heatmap(df.corr(),annot=True,cmap = 'Wistia')\nplt.title('Heatmap for the Dataset', fontsize = 20)\nplt.show()","0e178f60":"rcParams['figure.figsize']=(8,6)\nsns.distplot(df['compactness'])\nplt.title('Distribution plot')","cb8b0c47":"fig, (s1, s2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(13,4)\nsns.distplot(df['radius_ratio'], ax = s1)\ns1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df['radius_ratio'], ax = s2)\ns2.set_title(\"Box Plot\")","faac178c":"q1 = np.quantile(df['radius_ratio'], 0.25)\nq2 = np.quantile(df['radius_ratio'], 0.50)\nq3 = np.quantile(df['radius_ratio'], 0.75)\nIQR = q3 - q1\n\nprint(\"Quartile q1: \", q1)\nprint(\"Quartile q2: \", q2)\nprint(\"Quartile q3: \", q3)\nprint(\"Inter Quartile Range: \", IQR)\n\nprint(\"radius_ratio above \", df['radius_ratio'].quantile(0.75) + (1.5*IQR), \"are outliers\")\nprint(\"No. of outliers \", df[df['radius_ratio'] > 276]['radius_ratio'].shape[0])","0a126d68":"fig, (s1, s2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(13,4)\nsns.distplot(df['circularity'], ax = s1)\ns1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df['circularity'], ax = s2)\ns2.set_title(\" BoxPlot\")","ad8e6212":"fig, (g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(df['distance_circularity'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df['distance_circularity'], ax = g2)\ng2.set_title(\"Box Plot\")","4f699453":"rcParams['figure.figsize']=(6,4)\nsns.distplot(df['pr.axis_aspect_ratio'])\nplt.title('Distribution plot')","8ad3faba":"rcParams['figure.figsize']=(6,4)\nsns.boxplot(df['max.length_aspect_ratio'])\nplt.title('Box plot')","85845fdb":"fig,(g1,g2) = plt.subplots(nrows = 1, ncols = 2)\nfig.set_size_inches(15,2)\nsns.distplot(df['scatter_ratio'], ax = g1)\ng1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df['scatter_ratio'], ax = g2)\ng2.set_title(\"Box Plot\")","cdf82310":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df['elongatedness'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df['elongatedness'],ax=ax2)\nax2.set_title(\"Box Plot\")","b5bab481":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df['pr.axis_rectangularity'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df['pr.axis_rectangularity'],ax=ax2)\nax2.set_title(\"Box Plot\")","eaccfc41":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df['scaled_radius_of_gyration.1'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.swarmplot(df['scaled_radius_of_gyration.1'],ax=ax2)\nax2.set_title(\"Swarm Plot\")","b161a2b3":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df['skewness_about'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df['skewness_about'],ax=ax2)\nax2.set_title(\"Box plot\")","029dfe0f":"fig,(ax1,ax2) = plt.subplots(nrows=1,ncols=2)\nfig.set_size_inches(20,4)\nsns.distplot(df['hollows_ratio'],ax=ax1)\nax1.set_title(\"Distribution Plot\")\n\nsns.boxplot(df['hollows_ratio'],ax=ax2)\nax2.set_title(\"Box Plot\")","46194716":"sns.countplot(df['class'])","68fd09a8":"x_train=df.drop('class',axis=1)\nx_target=df['class']","c63e23b7":"x_train.shape","25bbe582":"x_target.shape","50cc7891":"sc=StandardScaler()","36607c9b":"sc.fit(x_train)","8669d4d7":"from scipy.stats import zscore\nx_train_std=x_train.apply(zscore)","288d2725":"cov_matrix = np.cov(x_train_std.T)","ffcbdc0b":"print(cov_matrix)","ad0aa75a":"eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\nprint('Eigen Vectors \\n%s', eig_vecs)\nprint('\\n Eigen Values \\n%s', eig_vals)","1aa78223":"from sklearn.decomposition import PCA\npca = PCA(n_components = 18)\npca.fit(x_train_std)","0f237864":"print(pca.components_)","da4e36e0":"from sklearn.decomposition import PCA\npca1 = PCA(n_components = 6)\npca1.fit(x_train_std)","e0280e24":"print(pca1.components_)","eda83b96":"X_train, X_test, y_train, y_test = train_test_split(x_train_std,x_target,test_size=0.33)","203df4d7":"from sklearn.svm import SVC\nsvc_model1 = SVC(C= .1, kernel='linear', gamma= 1)\nsvc_model1.fit(X_train, y_train)\nprediction = svc_model1.predict(X_test)","32325474":"print(accuracy_score(prediction,y_test))","e793a18e":"from sklearn.svm import SVC\nsvc_model2 = SVC(C= .1, kernel='rbf', gamma= 1)\nsvc_model2.fit(X_train, y_train)\nprediction = svc_model2.predict(X_test)","802d2da9":"print(accuracy_score(prediction,y_test))","680676e6":"from sklearn.svm import SVC\nsvc_model3 = SVC(C= .1, kernel='poly', gamma= 1)\nsvc_model3.fit(X_train, y_train)\nprediction = svc_model3.predict(X_test)","91dc7b3c":"print(accuracy_score(prediction,y_test))","35f0637a":"from sklearn.linear_model import LogisticRegression\nLR=LogisticRegression()","b0e22959":"LR.fit(X_train,y_train)","cae56669":"yhat=LR.predict(X_test)","e5f22adc":"accuracy_score(yhat,y_test)","2442100a":"print(classification_report(yhat,y_test))","176e6e46":"print(confusion_matrix(yhat,y_test))","34628b82":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\nnb_model = GaussianNB()\nnb_model.fit(X_train, y_train)\npredicted = nb_model.predict(X_test)","70df4772":"print(confusion_matrix(predicted,y_test))","5f595c2b":"print(classification_report(predicted,y_test))","7947462b":"print(accuracy_score(predicted,y_test))","209cc0c6":"Among the three kernels , SVM with polynomial kernel has the most accuracy.","0fabf9cd":"<h2>INTRODUCTION<\/h2>\n\nThe objective is to classify a given silhouette as one of three types of vehicle, using a set of features extracted from the silhouette. The vehicle may be viewed from one of many different angles.","7aef6683":"<h2>PCA<\/h2>","d1a752ae":"<h2>SVM<\/h2>","b2c50f36":"SVM with polynomial kernel has given us the highest accuracy  among other models after DIMENSIONALITY REDUCTION has been performed.","35cf179f":"<h2>Naive Bayes<\/h2>","b298b043":"<h3>Reading the DataSet<\/h3>","873d527d":"Let us understand the correlation between the columns of the dataset","3cf9350c":"<h2>Exploratory Data Analysis<\/h2>","ad07bb9d":"<h2>Data PreProcessing<\/h2>","b552577b":"<h2>CONCLUSION<\/h2>","6004d8b6":"We can observe that some features are highly correlated with one another.","496651df":"Inferences:\n\n1.Spread of compactness is least for van. mean compactness is highest for car. For Bus compactness is right skewed indicating that less number of buses have high compactness.\n\n2.Mean circularity is higher for cars.\n\n3.Mean distance_circularity is also higher for cars\n\n4.Mean radius_ratio is higher for cars, followed by Bus. It is least for vans\n\n5.pr.axis_aspect_ratio is has almost same distribution for car, van and buses\n\n6.max.length_aspect_ratio is almost same for cars and vans, lower for buses\n\n7.Mean scatter ratio is highest for cars, followed by bus and van\n\n8.Mean elomngatedness is highest for vans folowed by bus and car\n\n9.pr.axis_rectangularity is highest for cars, followed by bus and then vans\n\n10.distribution of max.length_rectangularity is almost same for cars, bus and vans\n\n11.Mean scaled variance is highest for cars followed by bus then vans\n\n12.Mean scaled variance1 is highest for cars followed by bus then vans\n\n13.'scaled_radius_of_gyration', 'scaled_radius_of_gyration.1', 'skewness_about', 'skewness_about.1', 'skewness_about.2', have almost similar distribution for cars, buses and vans.\n\n14.'hollows_ratio' is lower for buses as compared to cars and vans\nMany columns have lonmg tails indicating outliers\n\n15.pr.axis_aspect ratio and radius ratio varies strongly +ve for van. for cars and buses it varies in small range- mostly cpuld like\n\n16.Scatter ratio & Scaled_variance1 has almost perfect positive linear relationship\n\n17.Many features show high correlation indicating that we need to drop multiple features- we will use PCA for the same","3446b7d7":"Now we have to calculate the covariance so as to understand which features will be converted into principal components.","14b8c285":"We can either replace the null values with the mean of the column or delete the rows in which null values are present","353557a2":"To identify whether null values are present in the dataset","9d1ff965":"Lets reduce the number of components from 18 to 6","5483c61b":"<h2>LOGISTIC REGRESSION<\/h2>"}}