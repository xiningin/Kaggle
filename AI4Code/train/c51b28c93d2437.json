{"cell_type":{"f0599b73":"code","da684e48":"code","b51267ed":"code","26d24283":"code","79aba9ee":"code","be61b737":"code","b0ef96a3":"code","be338bce":"code","a95995de":"code","b6a2fb60":"code","31c9bc9a":"code","d37f324c":"code","7b27f885":"code","ffb38121":"code","15da4c46":"code","5da9fdf4":"code","7ce3f5bb":"code","7d46423c":"code","be1a25a3":"code","b53a4289":"code","c0767fa6":"markdown","768e06c1":"markdown","3907b6fd":"markdown","271504fa":"markdown","eced57fd":"markdown","0f7e1644":"markdown","1dd71bb4":"markdown","038713a5":"markdown","cb1b64bb":"markdown","6758811b":"markdown","22dfd884":"markdown","cf23b08d":"markdown","45883631":"markdown","17b2fbb8":"markdown","6c68f482":"markdown","cc789352":"markdown","982ff084":"markdown","44a4065d":"markdown","e727cf1a":"markdown"},"source":{"f0599b73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt #Simple plots\nimport seaborn as sns #Pretty plots\nimport altair as alt #Interactive plots\nimport IPython #for JS\n\n#Data science\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense,Input\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da684e48":"vgDB = pd.read_csv(\"\/kaggle\/input\/videogamesales\/vgsales.csv\")\nvgDB","b51267ed":"plt.figure(figsize=(25,5))\nplt.subplot(2, 2, 1)\nplt.title('Top 5 of the sum of sales per Publisher')\nplt.plot(vgDB.groupby([\"Publisher\"]).sum().filter([\"Global_Sales\"]).sort_values(by=[\"Global_Sales\"],ascending=False).head(5))\n\nplt.figure(figsize=(25,2))\nplt.subplot(2, 2, 2)\nplt.title('Top 10 sales per Platform')\nplt.plot(vgDB.groupby([\"Platform\"]).sum().filter([\"Global_Sales\"]).sort_values(by=[\"Global_Sales\"],ascending=False).head(10))\n\nplt.figure(figsize=(20,5))\nplt.subplot(2, 2, 3)\nplt.title('Sum of sales per Year')\nplt.plot(vgDB.query(\"Year < 2015\").groupby([\"Year\"]).sum().filter([\"Global_Sales\"]))","26d24283":"plt.title('Ventes par an')\nan = vgDB.query(\"Year < 2015 & Publisher in ['Electronic Arts','Ubisoft','Nintendo','Activision','Sony Computer Entertainment']\").filter([\"Year\",\"Global_Sales\",\"Publisher\"])\nsns.scatterplot(an.iloc[:,0],an.iloc[:,1]\/80,hue=an.iloc[:,2])","79aba9ee":"source = an\n\nan['Year'] = an['Year'].astype(float).astype(int).astype(str)\n\nselection = alt.selection_multi(fields=['Publisher'], bind='legend')\n\nalt.Chart(source).mark_point().encode(\n  alt.X('Year:T'),\n  alt.Y('Global_Sales'),\n  alt.Color('Publisher'),\n  opacity=alt.condition(selection, alt.value(1), alt.value(0.1))\n).add_selection(\n    selection\n).interactive()","be61b737":"List_dev = vgDB.groupby([\"Publisher\"]).sum().filter([\"Global_Sales\"]).sort_values(by=[\"Global_Sales\"],ascending=False).head(10)\nclass_to_dev = { List_dev.index.values[i]:i  for i in range(len(List_dev.index.values))}\nDB = vgDB.copy()\nDB[\"Publisher\"].replace(class_to_dev,inplace=True)\nL =[i for i in range(len(List_dev.index.values))]\nDB = DB.drop(DB.query(\"Publisher not in @L\").index)\nDB = DB.reset_index(drop=True)","b0ef96a3":"List_platf = vgDB[\"Platform\"].unique()\nclass_to_platf = { List_platf[i]:i  for i in range(len(List_platf))}\nDB[\"Platform\"].replace(class_to_platf,inplace=True)","be338bce":"List_genre = vgDB[\"Genre\"].unique()\nclass_to_genre = { List_genre[i]:i  for i in range(len(List_genre))}\nDB[\"Genre\"].replace(class_to_genre,inplace=True)\nDB.dropna(inplace=True)","a95995de":"def Normalization(column):\n  return (column-column.mean())\/column.std()","b6a2fb60":"DB[\"Year\"],DB[\"NA_Sales\"],DB[\"EU_Sales\"],DB[\"JP_Sales\"],DB[\"Other_Sales\"],DB[\"Global_Sales\"]= Normalization(DB[\"Year\"]),Normalization(DB[\"NA_Sales\"]),Normalization(DB[\"EU_Sales\"]),Normalization(DB[\"JP_Sales\"]),Normalization(DB[\"Other_Sales\"]),Normalization(DB[\"Global_Sales\"])","31c9bc9a":"X = DB.reset_index().filter([\"Year\",\"Genre\",\"Publisher\",\"NA_Sales\",\"EU_Sales\",\"JP_Sales\",\"Other_Sales\",\"Global_Sales\"]).to_numpy()\ny = DB.reset_index().filter([\"Platform\"]).to_numpy()\nX_train, X_test, y_train, y_test = train_test_split(X,y)\nprint(\"Separation from {} elements to : train = {} ; test = {}.\".format(X.shape[0],X_train.shape[0],X_test.shape[0]))","d37f324c":"knn = KNeighborsClassifier(len(List_platf))\nknn.fit(X_train, y_train.ravel())\nscore = knn.score(X_test, y_test)\nprint(\"Score :\", score)","7b27f885":"test = np.array([5,1,0,1,2,2,1,2]) #random test with Nintendo as a publisher and \ntest = test.reshape((1,8))\n\nprint(\"For \" + str(List_dev.index.values[test[0,2]]) + \" as a publisher and \" + str(List_genre[test[0,1]]) + \" as a genre, the platform predicted is : \\n\" + str(List_platf[np.argmax(knn.predict(test))]))","ffb38121":"model_sk = MLPClassifier(hidden_layer_sizes=(8,16,32,64))\nmodel_sk.fit(X_train,y_train.ravel())\nscore = model_sk.score(X_test,y_test)\nprint(\"Score :\", score)","15da4c46":"test = np.array([5,1,0,1,2,2,1,2]) #random test with Nintendo as a publisher and \ntest = test.reshape((1,8))\n\nprint(\"For \" + str(List_dev.index.values[test[0,2]]) + \" as a publisher and \" + str(List_genre[test[0,1]]) + \" as a genre, the platform predicted is : \\n\" + str(List_platf[np.argmax(model_sk.predict(test))]))","5da9fdf4":"X_train= np.array(X_train).astype('float32')\nX_test=np.array(X_test).astype('float32')\ny_train=np.array(y_train).astype('float32')\ny_test =np.array(y_test).astype('float32')","7ce3f5bb":"model = Sequential()\nmodel.add(Input(shape=(8,)))\nmodel.add(Dense(8,activation=\"relu\"))\nmodel.add(Dense(16,activation=\"relu\"))\nmodel.add(Dense(32,activation=\"relu\"))\nmodel.add(Dense(64,activation=\"relu\"))\nmodel.add(Dense(len(List_platf),activation=\"softmax\"))\nmodel.build(X[0].shape)\nmodel.summary()","7d46423c":"loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\nmodel.compile(loss=loss_fn, optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train,y_train,epochs=150,validation_data=(X_test,y_test))","be1a25a3":"loss_curve = history.history[\"loss\"]\nacc_curve = history.history[\"accuracy\"]\nloss_val_curve = history.history[\"val_loss\"]\nacc_val_curve = history.history[\"val_accuracy\"]\n\nplt.plot(loss_curve,label=\"Train\")\nplt.plot(loss_val_curve,label=\"Validation\")\nplt.legend(loc='upper right')\nplt.title(\"Loss\")\nplt.show()\nplt.plot(acc_curve,label=\"Train\")\nplt.plot(acc_val_curve,label=\"Validation\")\nplt.legend(loc='lower right')\nplt.title(\"Accuracy\")\nplt.show()","b53a4289":"test = np.array([5,1,0,1,2,2,1,2]) #random test with Nintendo as a publisher and \ntest = test.reshape((1,8))\n\nprint(\"For \" + str(List_dev.index.values[test[0,2]]) + \" as a publisher and \" + str(List_genre[test[0,1]]) + \" as a genre, the platform predicted is : \\n\" + str(List_platf[np.argmax(model.predict(test))]))","c0767fa6":"This notebook is a simple look at the dataset **videogamesales** from GregorySmith. We will do some simple Data Visualization and also try to create a simple model to guess a game's plateform according to the other attributs.","768e06c1":"# 1. Introduction","3907b6fd":"Our neural network has to handle numbers rather than strings, we have to categorize *Publisher*, *Genre* and *Platform*, meaning for instance we change \"Nintendo\" to 0, \"Sega\" to 1 ect... using dictionnaries.\nHowever, for this notebook, I will only keep the top 10 publishers.","271504fa":"This model has correct score but we will see later that classifiers are way more relevent for this problem, furthermore we need to already know the number of clusters (different platforms possible) we are searching for which will not be necessary for classifiers.","eced57fd":"## 3.2. Using a MLPClassifier Neighbour with sklearn","0f7e1644":"We can see the curves of accuracy and loss from both our training and test. Here we can see a sign of the beginning of overfitting as training accuracy increase without test accuracy which stay stuck around 0.55. However, this remains a better score than our two previous models.","1dd71bb4":"## 1.2. A look at the dataset with Pandas","038713a5":"## 2.2. Using Seaborn (for pretty graphs)","cb1b64bb":"## 2.1. Using Matplotlib","6758811b":"## 1.1. Imports ","22dfd884":"Then, we shall normalize the value of *Year* and all the sales in order to make it more understandable for the network.","cf23b08d":"## 3.2. Using a K-nearest Neighbour with sklearn","45883631":"It is common to use sklearn's *train_test_split* function in order to separate the dataset. This way, the network will be tested on never seen before data to have a better view of its accuracy\/score.","17b2fbb8":"# 2. Data Visualization","6c68f482":"## 3.3. Using TensorFlow","cc789352":"## 2.2. Using Altair (for interative graphs)","982ff084":"Here, we will try to find the platform according to all other attributes of a raw in the dataset. In order to see if our model is relevant, we can see if choosing a publisher returns a platform of its own, for instance, i will choose Nintendo and check if it returns a Nintendo's platform.","44a4065d":"# 3. Data Science","e727cf1a":"## 3.1. Data Preparation"}}