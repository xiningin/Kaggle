{"cell_type":{"af51aa80":"code","5c27f943":"code","bbb1c2f8":"code","a50b2094":"code","818e9b7d":"code","e2134c20":"code","b790bc16":"code","a2aa3744":"code","58b8a887":"code","db645be9":"code","a9b922cf":"code","1191fb77":"code","3bed8c25":"code","293fb99d":"code","ffad31a8":"code","060bc2ec":"code","5125ab75":"code","e0ef15ba":"code","6e8b8b7d":"code","d7b926f2":"code","785e8e4a":"code","a06bda93":"code","eaf7583d":"code","767cc3f4":"code","3c7a1603":"code","785503ff":"code","62ffbbee":"code","608c7b17":"code","0e73d56c":"code","ea789fdb":"code","8978b417":"code","47d1dfea":"code","db1e67b1":"code","ad430039":"code","e6bfcbeb":"code","ef1c10eb":"markdown","6c5c2618":"markdown","6fabf261":"markdown","e9ba518b":"markdown","39d16a85":"markdown","f35d9aff":"markdown","9a01347a":"markdown","147decec":"markdown","d3f69f8b":"markdown","28c1c3f4":"markdown","a449bff7":"markdown","9d0588b6":"markdown","ba8c9317":"markdown","5afe19a7":"markdown","9868f109":"markdown","2e8be92b":"markdown","dc0555e6":"markdown","a6db5253":"markdown","38c8aa1b":"markdown"},"source":{"af51aa80":"!pip install -U scikit-learn","5c27f943":"import sklearn\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, RobustScaler, MinMaxScaler\nfrom sklearn.linear_model import LinearRegression, BayesianRidge, LassoCV, RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.ensemble import StackingRegressor, VotingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_log_error, r2_score, mean_squared_error\nfrom sklearn import set_config\nfrom sklearn.metrics import r2_score\nfrom sklearn.tree import DecisionTreeRegressor\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom lightgbm import LGBMRegressor\n\nfrom scipy.stats import norm, skew","bbb1c2f8":"train_data_path = '\/kaggle\/input\/seoul-bike-rental-ai-pro-iti\/train.csv'\ntest_data_path = '\/kaggle\/input\/seoul-bike-rental-ai-pro-iti\/test.csv'\n\n\ntrain = pd.read_csv(train_data_path)\ntest = pd.read_csv(test_data_path)","a50b2094":"columns={'Temperature(\ufffdC)':'Temperature','Humidity(%)':'Humidity',\n                      'Wind speed (m\/s)':'Wind speed', 'Dew point temperature(\ufffdC)':'Dew point temperature',\n                      'Solar Radiation (MJ\/m2)':'Solar_Radiation', 'Visibility (10m)':'Visibility',\n                      'Functioning Day':'Functioning Day', 'Rainfall(mm)':'Rainfall',\n                      'Snowfall (cm)':'Snowfall'}\ntrain.rename(columns=columns,inplace=True)\n\ntest.rename(columns=columns,inplace=True)","818e9b7d":"train.head()","e2134c20":"test.head()","b790bc16":"train.hist(bins=50, figsize=(20,20))\nplt.show()","a2aa3744":"train.info()","58b8a887":"test.info()","db645be9":"def dayPeriods(row):\n    hour = row.loc['Hour']\n    if hour >= 23 or hour <= 5:\n        period = 'early_morning'\n    elif hour >= 6 and hour <= 10:\n        period = 'morning'\n    elif hour >= 11 and hour <= 17:\n        period = 'afternoon'\n    else:\n        period = 'night'\n        \n    row['period'] = period \n    return row\n\ntrain = train.apply(dayPeriods, axis=1)\ntest = test.apply(dayPeriods, axis=1)","a9b922cf":"train['sin_Hour'] = np.sin(2*np.pi*train['Hour']\/24.0)\ntest['sin_Hour'] = np.sin(2*np.pi*test['Hour']\/24.0)\n\ntrain['cos_Hour'] = np.cos(2*np.pi*train['Hour']\/24.0)\ntest['cos_Hour'] = np.cos(2*np.pi*test['Hour']\/24.0)","1191fb77":"train['label_day_night'] = train['Hour'].apply(lambda x : 'Night' if (x >20 or x<5) else('Day'))\ntest['label_day_night'] = test['Hour'].apply(lambda x : 'Night' if (x >20 or x<5) else('Day'))","3bed8c25":"train[\"day\"] = [t.day for t in pd.DatetimeIndex(train.Date)]\ntrain[\"day_week\"] = [t.dayofweek for t in pd.DatetimeIndex(train.Date)]\ntrain[\"month\"] = [t.month for t in pd.DatetimeIndex(train.Date)]\ntrain['year'] = [t.year for t in pd.DatetimeIndex(train.Date)]\n\ntest[\"day\"] = [t.day for t in pd.DatetimeIndex(test.Date)]\ntest[\"day_week\"] = [t.dayofweek for t in pd.DatetimeIndex(test.Date)]\ntest[\"month\"] = [t.month for t in pd.DatetimeIndex(test.Date)]\ntest['year'] = [t.year for t in pd.DatetimeIndex(test.Date)]","293fb99d":"train['sin_month'] = np.sin(2*np.pi*train['month']\/12.0)\ntest['sin_month'] = np.sin(2*np.pi*test['month']\/12.0)\n\ntrain['cos_month'] = np.cos(2*np.pi*train['month']\/12.0)\ntest['cos_month'] = np.cos(2*np.pi*test['month']\/12.0)","ffad31a8":"def dayHoliday(row):\n    isHoliday = False\n    holiday = row.loc['Holiday']\n    day_week = row.loc['day_week']\n    if holiday and (day_week==6 or day_week==5):\n        isHoliday = True\n        \n    row['isHoliday'] = isHoliday \n    return row\n\ntrain = train.apply(dayHoliday, axis=1)\ntest = test.apply(dayHoliday, axis=1)","060bc2ec":"train['relative_humidity'] = 100 - 5*(train['Temperature'] - train['Dew point temperature'])\ntest['relative_humidity'] = 100 - 5*(test['Temperature'] - test['Dew point temperature'])","5125ab75":"train['Wind speed_sqrt'] = np.sqrt(train['Wind speed'])\ntest['Wind speed_sqrt'] = np.sqrt(test['Wind speed'])\n\ntrain['Wind speed_0.1'] = train['Wind speed']**0.1\ntest['Wind speed_0.1'] = test['Wind speed']**0.1","e0ef15ba":"train['Temperature_0.5'] = train['Temperature']**0.5\ntest['Temperature_0.5'] = test['Temperature']**0.5\n\n# train['Temperature_sin'] = np.sin(train['Temperature'])\n# test['Temperature_sin'] = np.sin(test['Temperature'])\n\n# train['Temperature_cos'] = np.cos(train['Temperature'])\n# test['Temperature_cos'] = np.cos(test['Temperature'])","6e8b8b7d":"train['Visibility_5'] = train['Visibility']**5\ntest['Visibility_5'] = test['Visibility']**5","d7b926f2":"train['Snowfall_'] = train['Snowfall'] > 0\ntest['Snowfall_'] = test['Snowfall'] > 0\n\ntrain['Rainfall_'] = train['Rainfall'] > 0\ntest['Rainfall_'] = test['Rainfall'] > 0","785e8e4a":"# train['Humidity_sin'] = np.sin(train['Humidity'])\n# test['Humidity_sin'] = np.sin(test['Humidity'])\n\n# train['Humidity_cos'] = np.cos(train['Humidity'])\n# test['Humidity_cos'] = np.cos(test['Humidity'])","a06bda93":"numerical_features = [x for x in train.select_dtypes(include='number').columns if x not in ['y']]\ncategorical_features = train.select_dtypes(exclude='number').columns.tolist()\nnominal_features = [x for x in categorical_features if x not in ['Date']]\nordinal_features = [x for x in categorical_features if x not in nominal_features]\n\nlabel = ['y']","eaf7583d":"def ordinal_feature_encoding(feature, train, test):\n    new_train = train.copy()\n    new_test = test.copy()\n    ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n    ordinal.fit(pd.DataFrame(train[feature]))\n    new_train[feature] = ordinal.transform(pd.DataFrame(new_train[feature]))\n    new_test[feature] = ordinal.transform(pd.DataFrame(new_test[feature]))\n    return new_train, new_test","767cc3f4":"for feature in ordinal_features:\n    train, test = ordinal_feature_encoding(feature, train, test)","3c7a1603":"def nominal_feature_encoding(feature, train, test):\n    new_train = train.copy()\n    new_train = test.copy()\n    nominal = OneHotEncoder(handle_unknown = 'ignore')\n    nominal.fit(pd.DataFrame(train[feature]))\n    nominal_cols_train = nominal.transform(pd.DataFrame(train[feature]))\n    nominal_cols_test = nominal.transform(pd.DataFrame(test[feature]))\n    column_names = nominal.categories_[0].tolist()\n    column_names = [feature+'_'+str(x) for x in column_names]\n    new_train = train.join(pd.DataFrame(nominal_cols_train.toarray(), columns=column_names))\n    new_train = new_train.drop(columns=[feature])\n    new_test = test.join(pd.DataFrame(nominal_cols_test.toarray(), columns=column_names))\n    new_test = new_test.drop(columns=[feature])\n    return new_train, new_test","785503ff":"for feature in nominal_features:\n    train, test = nominal_feature_encoding(feature, train, test)","62ffbbee":"train.columns.to_list()","608c7b17":"dropped_columns_tr = ['y', 'ID', 'Date', 'isHoliday_False', 'isHoliday_True']\ndropped_columns_ts = ['ID', 'Date', 'isHoliday_False', 'isHoliday_True']\n\nX_train = train.drop(columns=dropped_columns_tr)\ny_train = np.sqrt(train[label])\n\nX_val = train.drop(columns=dropped_columns_tr)\ny_val = np.sqrt(train[label])\nX_test = test.drop(columns=dropped_columns_ts)\n\nfeatures = [X_train.columns]","0e73d56c":"scaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)","ea789fdb":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)","8978b417":"def pipeline_prediction_plot(pipeline, X_train, y_train, X_val, y_val):    \n    # Use the fitted pipeline to make predictions on the train dataset\n    train_predictions = (pipeline.predict(X_train))\n    # Use the fitted pipeline to make predictions on the test dataset\n    test_predictions = (pipeline.predict(X_val))\n    K=2\n    sns.regplot(x=y_train, y=train_predictions, scatter_kws={'alpha':1, 'color':'brown'})\n    plt.xlabel('Actual')\n    plt.ylabel('Predicted')\n    plt.title(\"Training Set\")\n    plt.show()\n\n    sns.regplot(x=y_val, y=test_predictions, scatter_kws={'alpha':1, 'color':'r'})\n    plt.xlabel('Actual')\n    plt.ylabel('Predicted')\n    plt.title(\"Test Set\")\n    plt.show()\n    \n    \n    r2 = r2_score(y_train**K, train_predictions**K)\n    rmse = np.sqrt(mean_squared_error(y_train**K, train_predictions**K))\n    rmsle = np.sqrt(mean_squared_log_error(y_train**K, train_predictions**K))\n    print(\"r2_score = \", r2)\n    print(\"RMSE = \", rmse)\n    print(\"RMSLE = \", rmsle)\n    print()\n    r2 = r2_score(y_val**K, test_predictions**K)\n    rmse = np.sqrt(mean_squared_error(y_val**K, test_predictions**K))\n    rmsle = np.sqrt(mean_squared_log_error(y_val**K, test_predictions**K))\n    print(\"r2_score = \", r2)\n    print(\"RMSE = \", rmse)\n    print(\"RMSLE = \", rmsle)","47d1dfea":"model2 = XGBRegressor(n_estimators=500, learning_rate = 0.02, max_depth=10, subsample=0.9,\n                      reg_lambda = 80, booster='gbtree')","db1e67b1":"model2.fit(X_train, y_train, eval_metric=\"rmse\", early_stopping_rounds = 1,\n           eval_set=[(X_train, y_train), (X_val, y_val)], verbose=False)","ad430039":"pipeline_prediction_plot(model2, X_train, y_train, X_val, y_val)","e6bfcbeb":"sub = pd.DataFrame()\nsub['ID'] = test['ID']\nsub['y'] = (model2.predict(X_test))**2\nsub.to_csv('\/kaggle\/working\/submission.csv', index=False)","ef1c10eb":"## (e) Temperature","6c5c2618":"# Import Libraries","6fabf261":"# 5. Modelling","e9ba518b":"## (b) Date Processing","39d16a85":"# 2. EDA","f35d9aff":"# 1. Read Data","9a01347a":"## (a) Hour Processing","147decec":"# 4. Splitting and Cross Validation","d3f69f8b":"## (f) Visibility","28c1c3f4":"# 3. Data Preprocessing","a449bff7":"## (b) XGBRegressor","9d0588b6":"# 6. Submisssion","ba8c9317":"## (g) Snowfall and Rainfall","5afe19a7":"## (h) Humidity","9868f109":"## Encoding ordinal features","2e8be92b":"## Encoding nominal features","dc0555e6":"## (d) Wind Speed","a6db5253":"## (c) Dew Point Temperature ----> Relative Humidity","38c8aa1b":"## Extract numerical and categorical features (nominal and ordinal)"}}