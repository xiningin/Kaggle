{"cell_type":{"8dfc8a1d":"code","aa7b6ddd":"code","acb4dfa6":"code","0f9efdcb":"code","b8853a08":"code","0f123996":"code","8658a6bf":"code","377d9024":"code","cfe7c304":"code","c0d155bb":"code","05949b2a":"code","8d5c1195":"code","e8f2f973":"code","d397146d":"code","81bc4cd1":"code","8b50ba64":"code","742acf3c":"code","34d07326":"code","144d2ebc":"code","d1b89404":"code","8f349008":"code","ab24315c":"code","dbe35940":"code","b2eaefa1":"code","258bd71c":"code","e801eaa2":"markdown","ffce6241":"markdown","c9ba8564":"markdown","c221f8a9":"markdown","130c5f1d":"markdown","7200db1f":"markdown","e007a37d":"markdown","8edc376c":"markdown","cb8ef791":"markdown","dc348595":"markdown","318c683e":"markdown","aae5d244":"markdown","87947d97":"markdown","2f0d646f":"markdown","6c35cf9f":"markdown","ad2b12d7":"markdown"},"source":{"8dfc8a1d":"!pip install --upgrade pytorch-tabnet\n!pip install --upgrade evalml\n","aa7b6ddd":"\n%matplotlib inline\n\n\n\nimport warnings\nimport evalml\n# from evalml.model_understanding.graphs import graph_prediction_vs_actual\n\nfrom pytorch_tabnet.tab_model import TabNetRegressor\n\nfrom pytorch_tabnet.callbacks import EarlyStopping\n\nfrom pytorch_tabnet.pretraining import TabNetPretrainer\n\nimport torch\nfrom torch import nn\n\nimport numpy as np\n\nnp.random.seed(0)\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import mean_squared_log_error\n\nimport os\nfrom matplotlib import pyplot as plt\n\n","acb4dfa6":"warnings.filterwarnings('ignore')\npath = \"..\/input\/tabular-playground-series-jul-2021\/\"\ntrain_csv = \"train.csv\"\ntest_csv = \"test.csv\"\nsample_csv = \"sample_submission.csv\"\ntorch.cuda.is_available()\n","0f9efdcb":"train_data = pd.read_csv(path+train_csv)  # reading the train data to a data frame\ntest_sub_data = pd.read_csv(path+test_csv)  # reading the test data into a data frame\nsample_submission = pd.read_csv(path+sample_csv)  # reading the test data into a data frame\n\n","b8853a08":"train_data.set_index('date_time')\ntest_sub_data.set_index('date_time')","0f123996":"all_df = pd.concat([train_data, test_sub_data]).reset_index(drop=True)\nprint(all_df.shape)\n\n\n","8658a6bf":"all_df['date_time'] = pd.to_datetime(all_df['date_time'])\nall_df[\"hour\"] = all_df[\"date_time\"].dt.hour\nall_df[\"working_hours\"] = all_df[\"hour\"].isin(np.arange(8, 21, 1)).astype(\"int\")\nall_df[\"is_weekend\"] = (all_df[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")\nall_df['hr'] = all_df.date_time.dt.hour * 60 + all_df.date_time.dt.minute\nall_df['deg_C_lag_2'] = all_df['deg_C'] - all_df['deg_C'].shift(periods=2, fill_value=0)\n# all_df['relative_humidity_lag_2'] = all_df['relative_humidity'] - all_df['relative_humidity'].shift(periods=-2, fill_value=0)\n# all_df['absolute_humidity_lag_2'] = all_df['absolute_humidity'] - all_df['absolute_humidity'].shift(periods=-2, fill_value=0)\n\nall_df['satday'] = (all_df.date_time.dt.weekday == 5).astype(\"int\")\n\nall_df[\"SMC\"] = (all_df[\"absolute_humidity\"] * 100) \/ all_df[\"relative_humidity\"]\n# periods = 2\n# for i in range(1, 5):\n#     all_df[f\"s1-{periods}\"] = all_df[f\"sensor_{i}\"] - all_df[f\"sensor_{i}\"].shift(periods=periods, fill_value=0)\n\ntrain, test_sub = all_df.iloc[:(len(all_df) - len(test_sub_data)), :], all_df.iloc[(len(all_df) - len(test_sub_data)):,\n                                                                       :]\nprint(train.shape, test_sub.shape)","377d9024":"\nlabels = ['target_carbon_monoxide', 'target_benzene', 'target_nitrogen_oxides']\nto_drop = [\n              \"date_time\",\n              # \"hour\"\n\n          ] + labels\ntest_sub = test_sub.drop(columns=to_drop)\nX_train = train.drop(columns=to_drop)\ncarbon_monoxide = train['target_carbon_monoxide']\nbenzene = train['target_benzene']\nnitrogen_oxides = train['target_nitrogen_oxides']\nlables = pd.DataFrame()\nlables['target_carbon_monoxide'] = train['target_carbon_monoxide']\nlables['target_benzene'] = train['target_benzene']\nlables['target_nitrogen_oxides'] = train['target_nitrogen_oxides']\n\ntest_sub.shape\n\n","cfe7c304":"test_size = 0.05\nX_train_e, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X_train, lables,\n                                                                           problem_type='regression',\n                                                                           test_size=test_size)\n\nX_pretrain = pd.concat([X_train, test_sub]).reset_index(drop=True)\nX_pretrain_e, X_pretrain_holdout, _, _ = evalml.preprocessing.split_data(X_pretrain, X_pretrain,\n                                                                         problem_type='regression',\n                                                                         test_size=test_size,\n                                                                         random_seed=19)","c0d155bb":"max_epochs = 1000\npatience = 30\nbatch_size = 1024\nnum_workers = 0","05949b2a":"class MSLELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n\n    def forward(self, pred, actual):\n        c_pred = torch.clip(pred, min=0)\n        c_actual = torch.clip(actual, min=0)\n        return self.mse(torch.log(c_pred + 1), torch.log(c_actual + 1))\n\n\nloss_fn = MSLELoss()\n\n\n","8d5c1195":"early_stopping = EarlyStopping('valid_rmsle', is_maximize=False, patience=patience * 2, tol=0.001)\n","e8f2f973":"DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","d397146d":"\nregressor = TabNetRegressor(device_name=DEVICE, )","81bc4cd1":"unsupervised_model = TabNetPretrainer(\n    optimizer_fn=torch.optim.Adam,\n    optimizer_params=dict(lr=2e-2),\n    mask_type=\"sparsemax\",\n    device_name=DEVICE,\n\n)","8b50ba64":"\nunsupervised_model.fit(\n    X_train=X_pretrain_e.values,\n    eval_set=[X_pretrain_holdout.values],\n    eval_name=['test'],\n    patience=patience * 4,\n    max_epochs=max_epochs,\n    batch_size=batch_size,\n    num_workers=num_workers,\n\n)","742acf3c":"targets_train = y_train.values.reshape(-1, 3)\ntargets_valid = y_holdout.values.reshape(-1, 3)\n\nregressor.fit(\n    X_train_e.values,\n    targets_train,\n    eval_metric=['rmsle', 'rmse', ],\n    eval_name=['train', 'valid'],\n    eval_set=[(X_train_e.values, targets_train),\n              (X_holdout.values, targets_valid)],\n    from_unsupervised=unsupervised_model,\n    patience=patience * 4,\n    max_epochs=max_epochs,\n    batch_size=batch_size,\n    callbacks=[early_stopping],\n\n    loss_fn=loss_fn,\n    num_workers=num_workers,\n)","34d07326":"def predict_df(model, data):\n    res = model.predict(data.values)\n    pred_cm = pd.Series(np.clip(res[:, 0].reshape(-1, ), a_min=0, a_max=None))\n\n    pred_b = pd.Series(np.clip(res[:, 1].reshape(-1, ), a_min=0, a_max=None))\n\n    pred_no = pd.Series(np.clip(res[:, 2].reshape(-1, ), a_min=0, a_max=None))\n    df = pd.DataFrame()\n    df['target_carbon_monoxide'] = pred_cm\n    df['target_benzene'] = pred_b\n    df['target_nitrogen_oxides'] = pred_no\n    return df","144d2ebc":"pred_test_sub = predict_df(regressor, test_sub)\n\npred_cm = pred_test_sub['target_carbon_monoxide']\n\npred_b = pred_test_sub['target_benzene']\n\npred_no = pred_test_sub['target_nitrogen_oxides']\n\nsample_submission['target_carbon_monoxide'] = pred_cm\nsample_submission['target_benzene'] = pred_b\nsample_submission['target_nitrogen_oxides'] = pred_no\nsample_submission.to_csv('submission.csv', index=False)\n\nsample_submission.shape","d1b89404":"pred_holdout = predict_df(regressor, X_holdout)\nvalid_cm = pred_holdout['target_carbon_monoxide']\n\nvalid_b = pred_holdout['target_benzene']\n\nvalid_no = pred_holdout['target_nitrogen_oxides']","8f349008":"graph_prediction_vs_actual(\n    valid_cm,\n    y_holdout['target_carbon_monoxide'],\n    outlier_threshold=0.5)","ab24315c":"graph_prediction_vs_actual(\n    valid_b,\n    y_holdout['target_benzene'],\n    outlier_threshold=1)","dbe35940":"graph_prediction_vs_actual(\n    valid_no,\n    y_holdout['target_nitrogen_oxides'],\n    outlier_threshold=30)\n","b2eaefa1":"\nregressor.feature_importances_","258bd71c":"rmsle = \"rmsle\"\nrmse = \"rmse\"\nfig, axs = plt.subplots(2, 1, constrained_layout=True)\nrmsle_plot = axs[0]\nrmse_plot = axs[1]\nlosses = [rmsle, rmse]\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nfor i, loss in enumerate(losses):\n    axs[i].plot(regressor.history[f'train_{loss}'])\n    axs[i].plot(regressor.history[f'valid_{loss}'])\n    axs[i].set_title(loss)\n\n","e801eaa2":"## Official TabNet github repository is [here](https:\/\/github.com\/dreamquark-ai\/tabnet)\n\n## TabNet: Attentive Interpretable Tabular Learning paper [here](https:\/\/arxiv.org\/pdf\/1908.07442.pdf)\n\nHere we will import the libraries we use in this kernel:\n# About this notebook\n\n- Data: Official competition data only.\n- Data Split: 0.95 train, 0.05 test\n- Features: 15 training, 3 labels\n- Number of Models: 2\n- Models: Unsupervised Pretraining Model, TabNet-Regressor\n- Hyperparameters: None\n- GPUs: Recommended\n- Modules: PyTorch, TabNet-PyTorch, EvalML","ffce6241":"## Step 3.0 predictions and submission","c9ba8564":"# Step 3 evaluation and submission","c221f8a9":"# Step 2 train\n\n\n\n\n\n\n## Step 2.1 train Self-Supervised pretraining model","130c5f1d":"## Step 1.0 data loading","7200db1f":"# Step 1 preprocessing and models preparations\n","e007a37d":"# Step 0 installation\n","8edc376c":"# **TabNet: TPS Semi-Supervised Deep Learning Solution** #","cb8ef791":"## Step 1.5 models\n","dc348595":"## Step 1.4  objective and parameters\n","318c683e":"## Step 1.3 train test data split\n","aae5d244":"## Step 3.1 evaluation","87947d97":"## Thoughts:\nTabNet proves to be effective and might be even better with\n hyperparameters tuning and\/or further features engineering.\n## Credits:\n- Sum parts of this notebook feature engineering are taken from published notebooks, Thanks to those Kagglers (upvoted).\n- Thanks to TabNet contributors in GitHub(link at the start of the notebook).\n- Thanks to EvalML for great tool kits. [link here](https:\/\/github.com\/alteryx\/evalml)\n- Thanks to all upvoters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","2f0d646f":"## Step 1.2 data preprocessing","6c35cf9f":"\n\n## Step 2.2 train TabNet regression model","ad2b12d7":"# Thoughts, Recommendation and Credits"}}