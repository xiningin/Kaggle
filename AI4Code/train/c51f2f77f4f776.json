{"cell_type":{"f4f06c29":"code","9c91136e":"code","90974ba3":"code","8aab5ac1":"code","c3405ee2":"code","3bf663cc":"code","b06f5336":"code","a33a9104":"code","54c67ebc":"code","c6982d5d":"code","d25c37be":"code","53f6d207":"code","8aad87fb":"code","40fd23c7":"code","3b33dcd0":"code","625b126d":"code","7e0e5155":"code","2939a658":"code","ea695865":"code","f5f0af62":"code","44268e9c":"code","9b619a5e":"code","d86cfb23":"code","6ad631c0":"code","9fa8e52b":"markdown","82208126":"markdown"},"source":{"f4f06c29":"import os\nimport re\nimport cv2\nimport keras\nimport skimage\n\nimport numpy as np\nfrom tqdm import tqdm\nfrom pathlib import Path\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Dense\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Flatten, BatchNormalization\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.utils.np_utils import to_categorical\nfrom keras import backend as K\nK.set_image_dim_ordering('th')\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline","9c91136e":"# Removes everything except alphabetical and selected characters from name string\ndef name_correct(name):\n    return re.sub(r\"[^a-zA-Z, :]\", \" \", name).title()","90974ba3":"# Configure input\/output directory\n# Configure training, validation, testing directory\n\ninput_directory = r\"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/\"\noutput_directory = r\"\/kaggle\/output\/chest-xray-pneumonia\/chest_xray\/chest_xray\/\"\n\ntraining_dir = input_directory + r\"train\"\nvalidation_dir = input_directory + r\"val\"\ntesting_dir = input_directory + r\"test\"","8aab5ac1":"def get_data(directory):\n    X = []\n    y = []\n    \n    for nextdir in os.listdir(directory):\n        if not nextdir.startswith(\".\"):\n            if nextdir in [\"NORMAL\"]:\n                label = 0\n            elif nextdir in [\"PNEUMONIA\"]:\n                label = 1\n            else:\n                label = 2\n            \n            temp = directory + \"\/\" + nextdir\n        \n            for image_filename in tqdm(os.listdir(temp)):\n                path = os.path.join(temp + \"\/\", image_filename)\n                img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n                if img is not None:\n                    img = skimage.transform.resize(img, (150, 150, 3))\n                    img = np.asarray(img)\n                    X.append(img)\n                    y.append(label)\n                \n    X = np.asarray(X)\n    y = np.asarray(y)\n    \n    return X, y","c3405ee2":"X_train, y_train = get_data(training_dir)\nX_test, y_test = get_data(testing_dir)","3bf663cc":"x = [\"Normal\", \"Pneumonia\"]\ny1 = [len(os.listdir(training_dir + \"\/NORMAL\")), len(os.listdir(training_dir + \"\/PNEUMONIA\"))]\ny2 = [len(os.listdir(validation_dir + \"\/NORMAL\")), len(os.listdir(validation_dir + \"\/PNEUMONIA\"))]\ny3 = [len(os.listdir(testing_dir + \"\/NORMAL\")), len(os.listdir(testing_dir + \"\/PNEUMONIA\"))]\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5), sharey=False)\nax1.bar(x=np.arange(len(x)), height=y1, width=0.8, color=[\"blue\", \"orange\"], edgecolor=[\"blue\", \"orange\"])\nax1.set_title(\"#Train Set\")\nax1.set_xticks(np.arange(len(x)))\nax1.set_xticklabels(x)\nax1.legend()\n\nax2.bar(x=np.arange(len(x)), height=y2, width=0.8, color=[\"blue\", \"orange\"], edgecolor=[\"blue\", \"orange\"])\nax2.set_title(\"#Validation Set\")\nax2.set_xticks(np.arange(len(x)))\nax2.set_xticklabels(x)\nax2.legend()\n\nax3.bar(x=np.arange(len(x)), height=y3, width=0.8, color=[\"blue\", \"orange\"], edgecolor=[\"blue\", \"orange\"])\nax3.set_title(\"#Test Set\")\nax3.set_xticks(np.arange(len(x)))\nax3.set_xticklabels(x)\nax3.legend()\n\nplt.show()","b06f5336":"print(\"X_train Shape: \" + str(X_train.shape))\nprint(\"X_test Shape: \" + str(X_test.shape))\nprint(\"y_train Shape: \" + str(y_train.shape))\nprint(\"y_test Shape: \" + str(y_test.shape))","a33a9104":"y_train = to_categorical(y_train, 2)\ny_test = to_categorical(y_test, 2)","54c67ebc":"Pneumonia_images = os.listdir(training_dir + \"\/PNEUMONIA\")\nNormal_images = os.listdir(training_dir + \"\/NORMAL\")","c6982d5d":"pneumonia_sample = []\nnormal_sample = []\nfor i in range(0, 5):\n    pneumo = cv2.imread(training_dir + \"\/PNEUMONIA\/\" + Pneumonia_images[i])\n    normal = cv2.imread(training_dir + \"\/NORMAL\/\" + Normal_images[i])\n    \n    pneumo = skimage.transform.resize(pneumo, (150, 150, 3), mode=\"reflect\")\n    normal = skimage.transform.resize(normal, (150, 150, 3))\n    \n    pneumonia_sample.append(pneumo)\n    normal_sample.append(normal)\n\nsample = pneumonia_sample + normal_sample\ndel pneumonia_sample, normal_sample\n\n# Plot the data \nf, ax = plt.subplots(2,5, figsize=(30,10))\nfor i in range(10):\n    ax[i \/\/ 5, i % 5].imshow(sample[i], cmap=\"gray\")\n    if i<5:\n        ax[i \/\/ 5, i % 5].set_title(\"Pneumonia\")\n    else:\n        ax[i \/\/ 5, i % 5].set_title(\"Normal\")\n    ax[i \/\/ 5, i % 5].axis(\"off\")\n    ax[i \/\/ 5, i % 5].set_aspect(\"auto\")\nplt.show()","d25c37be":"# initialize the base pretrained model\nbase_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))\nbase_model.trainable = False\n\nmodel1 = tf.keras.Sequential([\n    base_model,\n    Dropout(0.5),\n    GlobalAveragePooling2D(),\n    Dense(128, activation=\"relu\"),\n    BatchNormalization(),\n    Dense(2, activation=\"sigmoid\")\n])\n\nmodel1.summary()","53f6d207":"batch_size = 32\nepochs = 25\n\nfilepath = \"transferlearning_weights.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.01, patience=2, min_delta=1E-7, verbose=1)\nearly_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", min_delta=1E-7, patience=5, restore_best_weights=True, verbose=1)\n\nmodel1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory1 = model1.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), callbacks=[lr_reduce, early_stop, checkpoint])","8aad87fb":"def display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])\n\ndisplay_training_curves(history1.history[\"acc\"], history1.history[\"val_acc\"], \"accuracy\", 211)\ndisplay_training_curves(history1.history[\"loss\"], history1.history[\"val_loss\"], \"loss\", 212)","40fd23c7":"# for i, layer in enumerate(base_model.layers):\n#     print(i, layer.name)\n    \nfor layer in model.layers[:249]:\n     layer.trainable = False\nfor layer in model.layers[249:]:\n     layer.trainable = True","3b33dcd0":"checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.01, patience=2, min_delta=1E-7, verbose=1)\nearly_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", min_delta=1E-7, patience=5, restore_best_weights=True, verbose=1)\n\nmodel1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory1 = model1.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), callbacks=[lr_reduce, early_stop, checkpoint])","625b126d":"display_training_curves(history1.history[\"acc\"], history1.history[\"val_acc\"], \"accuracy\", 211)\ndisplay_training_curves(history1.history[\"loss\"], history1.history[\"val_loss\"], \"loss\", 212)","7e0e5155":"y_pred1 = model1.predict(X_test)\ny_pred1 = np.argmax(y_pred1, axis=1) \ny_true = np.argmax(y_test, axis=1)\n\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_true, y_pred1), figsize=(5, 5))\nplt.show()","2939a658":"# initialize the base pretrained model\nbase_model = InceptionV3(weights=None, include_top=False, input_shape=(150, 150, 3))\nbase_model.trainable = True\n\nmodel2 = tf.keras.Sequential([\n    base_model,\n    Dropout(0.5),\n    GlobalAveragePooling2D(),\n    Dense(128, activation=\"relu\"),\n    BatchNormalization(),\n    Dense(2, activation=\"sigmoid\")\n])\n\nmodel2.summary()","ea695865":"batch_size = 32\nepochs = 25\n\nfilepath = \"without_pretrained_inceptionv3_weights.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.01, patience=2, min_delta=1E-7, verbose=1)\nearly_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", min_delta=1E-7, patience=5, restore_best_weights=True, verbose=1)\n\nmodel2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory2 = model2.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), callbacks=[lr_reduce, early_stop, checkpoint])","f5f0af62":"display_training_curves(history2.history[\"acc\"], history2.history[\"val_acc\"], \"accuracy\", 211)\ndisplay_training_curves(history2.history[\"loss\"], history2.history[\"val_loss\"], \"loss\", 212)","44268e9c":"y_pred2 = model2.predict(X_test)\ny_pred2 = np.argmax(y_pred2, axis=1) \ny_true = np.argmax(y_test, axis=1)\n\nfig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_true, y_pred2), figsize=(5, 5))\nplt.show()","9b619a5e":"y_test_decoded = []\nfor i in y_test:\n    if i[0] == 1:\n        y_test_decoded.append(0)\n    else:\n        y_test_decoded.append(1)","d86cfb23":"accuracy_model1 = accuracy_score(y_test_decoded, y_pred1)\nf1_model1 = f1_score(y_test_decoded, y_pred1)\nprecision_model1 = precision_score(y_test_decoded, y_pred1)\nrecall_model1 = recall_score(y_test_decoded, y_pred1)\n\nprint(\"Accuracy Model 1: \" + str(accuracy_model1))\nprint(\"F1 Score Model 1: \" + str(f1_model1))\nprint(\"Precision Score Model 1: \" + str(precision_model1))\nprint(\"Recall Score Model 1: \" + str(recall_model1))\nprint()\naccuracy_model2 = accuracy_score(y_test_decoded, y_pred2)\nf1_model2 = f1_score(y_test_decoded, y_pred2)\nprecision_model2 = precision_score(y_test_decoded, y_pred2)\nrecall_model2 = recall_score(y_test_decoded, y_pred2)\n\nprint(\"Accuracy Model 2: \" + str(accuracy_model2))\nprint(\"F1 Score Model 2: \" + str(f1_model2))\nprint(\"Precision Score Model 2: \" + str(precision_model2))\nprint(\"Recall Score Model 2: \" + str(recall_model2))\nprint()\nprint(\"Left: Pretrained InceptionV3 vs Right: Untrained InceptionV3\")\n\nwidth = 0.4\nlabels = [\"Accuracy\", \"F1 Score\", \"Precision Score\", \"Recall Score\"]\nx = np.arange(len(labels))\n\nfig, ax = plt.subplots(figsize=(14, 6))\nax.bar(x - width\/2, height=[accuracy_model1, f1_model1, precision_model1, recall_model1], width=width)\nax.bar(x + width\/2, height=[accuracy_model2, f1_model2,precision_model2, recall_model2], width=width)#, color=[\"red\", \"blue\", \"orange\", \"green\"])\n\nax.set_title(\"Comparing Scores\")\nax.set_xticks(x)\nax.set_xticklabels(labels)\nax.legend()\n\nplt.show()","6ad631c0":"\"\"","9fa8e52b":"## Preprocessing","82208126":"### Testing if InceptionV3 works better without pretrained wheights"}}