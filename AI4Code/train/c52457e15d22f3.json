{"cell_type":{"c229f556":"code","76a79daf":"code","49add0b3":"code","88c9aa51":"code","89fdff79":"code","bc7f39fc":"code","70e42d6c":"code","16d3f5a1":"code","c5b9a5cd":"code","4066d357":"code","211a99da":"code","a042a30a":"code","aef7596f":"code","3f286b62":"code","2cf2343a":"code","9ae88875":"code","7b4a152c":"code","64c20660":"code","eae9ab5d":"code","8255efd5":"code","18d8e042":"code","4d09c77c":"code","11628934":"code","91f6b0f3":"code","75e77f74":"code","849152b9":"code","b8346451":"code","34fb9b72":"code","e6329de8":"code","0282aba4":"code","656ce143":"code","02fa0318":"code","20d2dae7":"code","f0f08222":"code","c1b393b0":"code","2bd78677":"code","e450f484":"code","d488c846":"code","24e7d664":"code","e6ec83bd":"code","681d6cbb":"code","80936a28":"code","5b81223d":"code","3bc083c2":"code","d342467e":"code","e2aa98af":"code","959e29a2":"code","a47e49ef":"code","558bedd9":"code","22482c08":"markdown","c7a9246d":"markdown","5dac6b5d":"markdown","2d218680":"markdown","79d0bbc2":"markdown","057fba5b":"markdown","f9c1c8cd":"markdown","49fb42ef":"markdown","02705187":"markdown","e8427e35":"markdown","289113a8":"markdown","11c94d4f":"markdown","8b2ebe13":"markdown","4f391c43":"markdown","0dc00547":"markdown","1f33af31":"markdown","ffb76e42":"markdown","f861de7d":"markdown","8f36993b":"markdown","94b93c8d":"markdown","9fafed41":"markdown","ae0c4bc3":"markdown","064dca13":"markdown","b0fcd22f":"markdown","af201e2d":"markdown","86512565":"markdown"},"source":{"c229f556":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","76a79daf":"train = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/test.csv')\nsample_submission = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/sample_submission.csv')","49add0b3":"train.head()","88c9aa51":"test.head()","89fdff79":"X_train=train.drop('label',axis=1)\nY_train=train.label","bc7f39fc":"X_train.head()","70e42d6c":"Y_train.head()","16d3f5a1":"test=test.drop('id',axis=1)","c5b9a5cd":"test.head()","4066d357":"X_train=X_train\/255\ntest=test\/255","211a99da":"X_train=X_train.values.reshape((-1,28,28,1))\ntest=test.values.reshape((-1,28,28,1))","a042a30a":"X_train.shape","aef7596f":"# Number of rows in X_train\nX_train.shape[0]","3f286b62":"test.shape","2cf2343a":"# print(X_train[0][:,:,0])","9ae88875":"plt.imshow(X_train[0][:,:,0])\nplt.title(Y_train[0])","7b4a152c":"plt.imshow(X_train[1][:,:,0])\nplt.title(Y_train[1])","64c20660":"! pwd","eae9ab5d":"! ls","8255efd5":"! mkdir trainIm testIm","18d8e042":"! ls","4d09c77c":"array = X_train[0][:,:,0].astype(np.uint8)\nprint(array)","11628934":"lengthX_train = X_train.shape[0]\nfor i in range(lengthX_train):\n    array = X_train[i][:,:,0].astype(np.uint8)\n    img = Image.fromarray(array)\n    img = img.convert(\"L\")\n    fn = \"\/kaggle\/working\/trainIm\/TrainImg{}.png\".format(i)\n    img.save(fn)","91f6b0f3":"lengthtest = test.shape[0]\nfor i in range(lengthtest):\n    array = test[i][:,:,0].astype(np.uint8)\n    img = Image.fromarray(array)\n    img = img.convert(\"L\")\n    fn = \"\/kaggle\/working\/testIm\/TestImg{}.png\".format(i)\n    img.save(fn)","75e77f74":"train_label = pd.DataFrame(columns = ['image_id_path', 'Label']) ","849152b9":"train_label.head()","b8346451":"Y_train.head()","34fb9b72":"for index,row in Y_train.iteritems():\n    #print(row)\n    #print(index)\n    pathname = \"TrainImg{}.png\".format(index)\n    train_label.loc[index,'image_id_path']=pathname\n    train_label.loc[index,'Label']=row","e6329de8":"train_label.head()","0282aba4":"train_label.to_csv(\"train.csv\", index=False)","656ce143":"! pwd","02fa0318":"!git clone https:\/\/github.com\/Tessellate-Imaging\/monk_v1.git","20d2dae7":"!cd monk_v1\/installation\/Misc && pip install -r requirements_kaggle.txt","f0f08222":"! pip install pillow==5.4.1","c1b393b0":"# Monk\nimport os\nimport sys\nsys.path.append(\"monk_v1\/monk\/\");","2bd78677":"#Using pytorch backend \nfrom pytorch_prototype import prototype","e450f484":"gtf = prototype(verbose=1);\ngtf.Prototype(\"Kannada-MNIST\", \"Using_Pytorch_Backend\");","d488c846":"gtf.List_Models()","24e7d664":"gtf.Default(dataset_path=\"\/kaggle\/working\/trainIm\/\",\n            path_to_csv=\"\/kaggle\/working\/train.csv\", # updated csv file \n            model_name=\"resnet50\", \n            freeze_base_network=False,\n            num_epochs=20); ","e6ec83bd":"#Start Training\ngtf.Train();\n#Read the training summary generated once you run the cell and training is completed","681d6cbb":"gtf = prototype(verbose=0);\ngtf.Prototype(\"Kannada-MNIST\", \"Using_Pytorch_Backend\", eval_infer=True);","80936a28":"img_name = \"\/kaggle\/working\/testIm\/TestImg0.png\";\npredictions = gtf.Infer(img_name=img_name);\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name,width=200,height=300)","5b81223d":"from tqdm import tqdm_notebook as tqdm\nfrom scipy.special import softmax","3bc083c2":"img_name = \"\/kaggle\/working\/testIm\/TestImg1.png\";\npredictions = gtf.Infer(img_name=img_name);\nprint(predictions)\nprint(predictions['predicted_class'])\n\n#Display \nfrom IPython.display import Image\nImage(filename=img_name,width=200,height=300)","d342467e":"for i in tqdm(range(len(sample_submission))):\n    img_name = \"\/kaggle\/working\/testIm\/TestImg{}.png\".format(i)\n    \n    #Invoking Monk's nferencing engine inside a loop\n    predictions = gtf.Infer(img_name=img_name, return_raw=True);\n    x = predictions['predicted_class']\n    sample_submission[\"id\"][i] = i;\n    sample_submission[\"label\"][i] = x;\n   ","e2aa98af":"sample_submission.head()","959e29a2":"sample_submission.to_csv(\"submission.csv\", index=False);","a47e49ef":"! rm -r monk_v1","558bedd9":"! rm -r workspace","22482c08":"# <div id=\"im\"> [Installing Monk](https:\/\/github.com\/Tessellate-Imaging\/monk_v1\/tree\/master\/installation) <\/div>","c7a9246d":"Load the experiment in inference mode\n\n* Set flag eval_infer as True","5dac6b5d":"# Converting the pixel values given into images and storing them","2d218680":"<div id=\"pb\"> Importing pytorch backend <\/div>","79d0bbc2":"# Running Inference on all test images","057fba5b":"# Select image and Run inference","f9c1c8cd":"![Kannada Numbers](https:\/\/2.bp.blogspot.com\/-e13ee8EcKxU\/Wl7dQ32q44I\/AAAAAAAAAB4\/um6EcQ9gq0YL9un_WWQNpw_d_uTvrDpBgCLcBGAs\/s1600\/numbers-kannada1.jpg)","49fb42ef":"# <div id=\"monk\"> [MONK](https:\/\/github.com\/Tessellate-Imaging\/monk_v1) <\/div>\n\nMonk is a low code Deep Learning tool and a unified wrapper for Computer Vision.\n\nMonk Features\n\n* low-code\n* unified wrapper over major deep learning framework - keras, pytorch, gluoncv\n* syntax invariant wrapper\n\nMonk Enables\n\n* To create, manage and version control deep learning experiments.\n* To compare experiments across training metrics.\n* To quickly find best hyper-parameters.\n\nGoals\n\n* To experiment with Models\n* Understand how easy is it to use Monk","02705187":"Kannada (\/\u02c8k\u0251\u02d0n\u0259d\u0259, \u02c8k\u00e6n-\/; \u0c95\u0ca8\u0ccd\u0ca8\u0ca1, [\u02c8k\u0250nn\u0250\u0256a\u02d0]; lesser known as Kanarese) is a Dravidian language spoken predominantly by people of Karnataka in Southwestern India and by linguistic minorities in the states of Maharashtra, Andhra Pradesh, Tamil Nadu, Telangana, Kerala and Goa and also by Carnatican expats abroad. The language has roughly 44 million native speakers, who are called Kannadigas. Kannada is also spoken as a second and third language by over 12.9 million non-Kannada speakers in Karnataka, which adds up to 56 million speakers. It is one of the scheduled languages of India and the official and administrative language of the state of Karnataka. Kannada was the court language of some of the most powerful empires of South and Central India, such as the Chalukya dynasty, the Rashtrakuta dynasty, the Vijayanagara Empire and the Hoysala Empire.\n\nSource: https:\/\/en.wikipedia.org\/wiki\/Kannada","e8427e35":"# <div id=\"lm\"> List of models <\/div>\n\nSee what other models Monk's backend supports","289113a8":"# Check out\n\n* [Monk_Object_Detection](https:\/\/github.com\/Tessellate-Imaging\/Monk_Object_Detection)\n\nA one-stop repository for low-code easily-installable object detection pipelines.\n\n\n* [Monk_Gui](https:\/\/github.com\/Tessellate-Imaging\/Monk_Gui)\n\nA Graphical user Interface for deep learning and computer vision over Monk Libraries\n\n\n* [Pytorch_Tutorial](https:\/\/github.com\/Tessellate-Imaging\/Pytorch_Tutorial)\n\nA set of jupyter notebooks on pytorch functions with examples","11c94d4f":"* [MONK](#monk)\n* [Converting the given dataset into the required format](#pp)\n* [Installing Monk](#im)\n* [Importing pytorch backend](#pb)\n* [Creating and managing experiments](#cm)\n* [List of models-See what other models Monk's backend supports](#lm)\n* [Quick Mode Training - Load the data and the model](#ldm)\n* [Train the classifier](#tc)\n* [Running inference on test images](#rit)","8b2ebe13":"# <div id=\"ldm\"> Load the data and the model <\/div>\n\nDocs on quick mode loading of data and model: https:\/\/github.com\/Tessellate-Imaging\/monk_v1#4\n\nTutorials on Monk: https:\/\/github.com\/Tessellate-Imaging\/monk_v1\/tree\/master\/study_roadmaps\/1_getting_started_roadmap\n\n# Quick mode training\n\n* Using Default Function\n* dataset_path\n* model_name\n* num_epochs","4f391c43":"# <div id=\"tc\"> Train the classifier <\/div>","0dc00547":"# <div id=\"rit\"> Running inference on test images <\/div>","1f33af31":"![](https:\/\/cdn3.vectorstock.com\/i\/1000x1000\/98\/02\/set-of-monochrome-icons-with-kannada-numbers-vector-15469802.jpg)","ffb76e42":"This creates files and directories as per the following structure\nworkspace\n\n|\n|--------Kannada-MNIST (Project name can be different)\n\n                |\n                |\n                |-----Using_Pytorch_Backend (Experiment name can be different)\n                            |\n                            |-----experiment-state.json\n                            |\n                            |-----output\n                                    |\n                                    |------logs (All training logs and graphs saved here)\n                                    |\n                                    |------models (all trained models saved here)","f861de7d":"# <div id=\"cm\"> Creating and managing experiments <\/div>\n\n* Provide project name\n* Provide experiment name\n* For a specific data create a single project\n* Inside each project multiple experiments can be created\n* Every experiment can be have diferent hyper-parameters attached to it","8f36993b":"Imports","94b93c8d":"* git clone https:\/\/github.com\/Tessellate-Imaging\/monk_v1.git\n\n* cd monk_v1\/installation\/Linux && pip install -r requirements_cu9.txt\n\n(Select the requirements file as per OS and CUDA version)","9fafed41":"**Creating a CSV file that contains the labels of the training images**","ae0c4bc3":"* If using Colab install using the commands below\n\n!cd monk_v1\/installation\/Misc && pip install -r requirements_colab.txt\n\n* If using Kaggle uncomment the following command\n\n!cd monk_v1\/installation\/Misc && pip install -r requirements_kaggle.txt\n\n\n* Select the requirements file as per OS and CUDA version when using a local system or cloud\n\n!cd monk_v1\/installation\/Linux && pip install -r requirements_cu9.txt","064dca13":"# Table of Contents","b0fcd22f":"**Visualizing**","af201e2d":"* To use mxnet backend\n\nfrom gluon_prototype import prototype\n\n* To use keras backend\n\nfrom keras_prototype import prototype","86512565":"# <div id=\"pp\"> Converting the given dataset into the required format <\/div>"}}