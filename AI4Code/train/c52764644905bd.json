{"cell_type":{"573a63c7":"code","2e243bb3":"code","e936e841":"code","602345bb":"code","aca9c66a":"code","e2c2375b":"code","c2258ed7":"code","f6d26fcc":"code","c1d03a90":"code","a78991b8":"code","642408e7":"code","9c61de2f":"code","5e8039fb":"code","ba6ea4f5":"code","b943bd4e":"code","bcdf423c":"code","7080fac6":"code","5c0978d5":"code","6a57a30f":"code","b3e4142c":"code","8712f55c":"code","1751c3a5":"code","759ca3cc":"code","ce6f910c":"code","3a324b2c":"code","df8967ab":"code","49b7169a":"code","8a3ee407":"code","438676a2":"code","3cf3f3f1":"code","48d86d18":"code","840cd3d1":"markdown","8147703b":"markdown","8a9807ff":"markdown","6cb6b7de":"markdown","4ef1dd45":"markdown","ef12b2f5":"markdown","c4cf6d4d":"markdown"},"source":{"573a63c7":"!nvidia-smi","2e243bb3":"#accelerate pandas\n# !pip install modin[ray]\n# !pip install pandas","e936e841":"from fastai import *\nfrom fastai.vision import *\nimport pandas as pd","602345bb":"path = '..\/input\/Kannada-MNIST\/\/'\npath\n! ls {path} -l","aca9c66a":"# df1 = pd.read_csv(path+'train.csv')\n# df2 = pd.read_csv(path+'Dig-MNIST.csv')\n# df = pd.concat([df1,df2],axis=0)\n# df.to_csv('train.csv',index = False)","e2c2375b":"# df.iloc[:,1:] = df.iloc[:,1:].replace(range(128,254),'255')\n# df.iloc[:,1:] = df.iloc[:,1:].replace(range(1,127),'0')","c2258ed7":"# df.to_csv('train.csv',index = False)","f6d26fcc":"class CustomImageItemList(ImageList):\n    def open(self, fn):\n        img = fn.reshape(28, 28)\n        img = np.stack((img,)*3, axis=-1) # convert to 3 channels\n        return Image(pil2tensor(img, dtype=np.float32))\n\n    @classmethod\n    def from_csv_custom(cls, path:PathOrStr, csv_name:str, imgIdx:int=1, header:str='infer', **kwargs) -> 'ItemList':\n        df = pd.read_csv(Path(path)\/csv_name, header=header)\n        res = super().from_df(df, path=path, cols=0, **kwargs)\n        # convert pixels to an ndarray\n        res.items = df.iloc[:,imgIdx:].apply(lambda x: x.values \/ 783.0, axis=1).values\n        return res","c1d03a90":"#best 0.986\n# test = CustomImageItemList.from_csv_custom(path=path, csv_name='test.csv', imgIdx=1)\n# data = (CustomImageItemList.from_csv_custom(path=path, csv_name='train.csv')\n#                        .split_by_rand_pct(0.2)\n#                        .label_from_df(cols='label')\n#                        .add_test(test, label=0)\n#                        .transform(get_transforms(do_flip = False, max_rotate = 0.), size=49)\n#                        .databunch(bs=256, num_workers=16)\n#                        .normalize(mnist_stats))\n# data","a78991b8":"test = CustomImageItemList.from_csv_custom(path=path, csv_name='test.csv', imgIdx=1)\n# DigMNIST = CustomImageItemList.from_csv_custom(path=path, csv_name='Dig-MNIST.csv')\ndata = (CustomImageItemList.from_csv_custom(path=path, csv_name='train.csv')\n                       .split_by_rand_pct(0.2)\n#                       .split_by_idx(list(range(60000,70240)))\n                       .label_from_df(cols='label')\n                       .add_test(test, label=0)\n#                        .transform(get_transforms(do_flip = False))\n                       .transform(get_transforms(do_flip = False, max_rotate = 0.,max_zoom = 1.), size=49)#, p_affine = 0.), size=49)\n                       .databunch(bs=256, num_workers=16)\n                       .normalize(mnist_stats))\ndata","642408e7":"data.show_batch(rows=3, figsize=(12,9))","9c61de2f":"arch = models.resnet50\n# arch = models.resnet152\n# arch = models.resnet18\narch","5e8039fb":"!mkdir -p \/tmp\/.cache\/torch\/checkpoints\n!cp ..\/input\/resnet50\/resnet50-19c8e357.pth \/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth\n# !cp ..\/input\/resnet152\/resnet152-b121ed2d.pth \/tmp\/.cache\/torch\/checkpoints\/resnet152-b121ed2d.pth","ba6ea4f5":"# !cd ..\/input\/radam-pytorch\/RAdam\/\n# !ls","b943bd4e":"# !cp ..\/input\/radam-pytorch\/RAdam .\n# import radam\n# optar = partial(radam)","bcdf423c":"#learn = cnn_learner(data, arch,pretrained = False, loss_func = nn.CrossEntropyLoss(), metrics=[error_rate,accuracy], model_dir='..\/kaggle\/working').to_fp16()\n\n# learn = cnn_learner(data, arch,pretrained = False, opt_func = optar, loss_func = nn.CrossEntropyLoss(), metrics=[error_rate,accuracy], model_dir='..\/kaggle\/working').to_fp16()\n#learn = cnn_learner(data, models.densenet161, metrics=[error_rate, accuracy], model_dir=\"\/tmp\/model\/\", pretrained=False)","7080fac6":"#FOR TESTING\nlearn = cnn_learner(data, arch,pretrained = False, loss_func = nn.MultiMarginLoss(), metrics=[error_rate,accuracy], model_dir='..\/kaggle\/working')","5c0978d5":"# lr = 1e-02","6a57a30f":"# learn.lr_find()\n# learn.recorder.plot(suggestion=True)","b3e4142c":"# 0.9986\nlearn.fit_one_cycle(20)\nlearn.save('stage-1-50')","8712f55c":"# #TEST\n# learn.fit_one_cycle(3,1e-02)","1751c3a5":"# learn.unfreeze()\n# learn.lr_find()\n# learn.recorder.plot()","759ca3cc":"# lr = slice(1e-04, 1e-03)","ce6f910c":"# learn.fit_one_cycle(6,lr)","3a324b2c":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","df8967ab":"interp.plot_top_losses(20, figsize=(15,11))","49b7169a":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","8a3ee407":"interp.most_confused(min_val=2)","438676a2":"tmp_df = pd.read_csv(path+'sample_submission.csv')\ntmp_df.head()","3cf3f3f1":"for i in range(0,5000):\n    img = learn.data.test_ds[i][0]\n    tmp_df.loc[i]=[i,int(learn.predict(img)[1])]\ntmp_df","48d86d18":"tmp_df.to_csv('submission.csv',index=False)","840cd3d1":"# Fast.ai \u5fc5\u8981\u7684\u5b89\u88dd\nFAST.AI\u53c3\u8003\u8a2d\u7f6e\u8cc7\u6599\nhttps:\/\/towardsdatascience.com\/fastai-image-classification-32d626da20","8147703b":"# Submission(with fast.ai predict())\nwith learn.data.test_ds in datablock fast.ai","8a9807ff":"# Input Image\nbecause there is no corresponding function in fastai, so we inheritance \"ImageList\" and alter it to read .csv.","6cb6b7de":"# Model\nresnet 50","4ef1dd45":"# Plot","ef12b2f5":"# Learning\nOne-Cycle-Policy \u5927\u6982\u6709\u4e09\u4e2a\u6b65\u9aa4\uff1a\n\n\u6211\u4eec\u9010\u6e10\u5c06\u5b66\u4e60\u7387\u4ece lr_max \/ div_factor \u63d0\u9ad8\u5230 lr_max\uff0c\u540c\u65f6\u6211\u4eec\u9010\u6e10\u51cf\u5c11\u4ece mom_max \u5230 mom_min \u7684\u52a8\u91cf(momentum)\u3002\n\n\u53cd\u5411\u518d\u505a\u4e00\u6b21\uff1a\u6211\u4eec\u9010\u6e10\u5c06\u5b66\u4e60\u7387\u4ece lr_max \u964d\u4f4e\u5230 lr_max \/ div_factor\uff0c\u540c\u65f6\u6211\u4eec\u9010\u6e10\u589e\u52a0\u4ece mom_min \u5230 mom_max \u7684\u52a8\u91cf\u3002\n\n\u6211\u4eec\u8fdb\u4e00\u6b65\u5c06\u5b66\u4e60\u7387\u4ece lr_max \/ div_factor \u964d\u4f4e\u5230 lr_max \/\uff08div_factor x 100\uff09\uff0c\u6211\u4eec\u4fdd\u6301\u52a8\u529b\u7a33\u5b9a\u5728 mom_max\u3002\n\n\u4f5c\u8005\uff1alai-bluejay\n\u94fe\u63a5\uff1ahttps:\/\/hacpai.com\/article\/1552929502787\n\u6765\u6e90\uff1a\u9ed1\u5ba2\u6d3e\n\u534f\u8bae\uff1aCC BY-SA 4.0 https:\/\/creativecommons.org\/licenses\/by-sa\/4.0\/","c4cf6d4d":"# Databunch(Fast.AI)\nget_transforms() \u5247\u662ffastai\u7684\u5167\u5efa\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u9069\u7528\u65bc\u5927\u591a\u6578\u8a08\u7b97\u6a5f\u8996\u89ba\u4efb\u52d9\u7684\u9810\u8a2d\u8cc7\u6599\u589e\u5f37\u65b9\u6848\uff1a\n\n\u4ee50.5\u7684\u6982\u7387\u96a8\u6a5f\u6c34\u5e73\u7ffb\u8f49\n\n\u4ee50.75\u7684\u6982\u7387\u5728-10\u820710\u5ea6\u4e4b\u9593\u65cb\u8f49\n\n\u4ee50.75\u7684\u6982\u7387\u57281\u82071.1\u500d\u4e4b\u9593\u96a8\u6a5f\u653e\u5927\n\n\u4ee50.75\u7684\u6982\u7387\u96a8\u6a5f\u6539\u8b8a\u4eae\u5ea6\u548c\u5c0d\u6bd4\u5ea6\n\n\u4ee50.75\u7684\u6982\u7387\u9032\u884c\u96a8\u6a5f\u5c0d\u7a31\u626d\u66f2\n\n\n\u5927\u591a\u6578\u5377\u7a4d\u795e\u7d93\u7db2\u8def\u7684\u8f38\u5165\u5c64\u5f62\u72c0\u90fd\u662f28\u300132\u300164\u300196\u3001224\u3001384\u3001512\u4e4b\u985e\u7684\u6578\u5b57"}}