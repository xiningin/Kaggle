{"cell_type":{"c519a35f":"code","be65baac":"code","36911910":"code","003b628c":"code","0547575b":"code","1cec92d7":"code","498f3066":"code","03aacce1":"code","b1cc24cf":"code","4079bc7a":"code","8fb8f3e2":"code","07f576dd":"code","c2e171ac":"code","acd754ae":"code","7211f80e":"code","d9cb4bb0":"code","71541887":"code","3dd19d46":"code","ccae2024":"code","b04a2616":"code","2963cbe2":"code","398ce18c":"code","213d3371":"code","2d229c27":"code","437b086f":"code","6b549392":"markdown","89636403":"markdown","dbd3825d":"markdown","ec2d55a7":"markdown","5924824b":"markdown","430ae3df":"markdown","d618e5af":"markdown","4a6aff1f":"markdown"},"source":{"c519a35f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be65baac":"from tensorflow import keras","36911910":"MNIST_file_path = '..\/input\/digit-recognizer\/train.csv'\nMNIST_data = pd.read_csv(MNIST_file_path) # dane przechowujemy jako DataFrame\nMNIST_data.shape","003b628c":"MNIST_data.head() # w tym przypadku dane z 5 pierwszych wierszy niewiele nam m\u00f3wi\u0105 :(","0547575b":"train_set, valid_set, test_set = MNIST_data[:30000], MNIST_data[30000:40000], MNIST_data[40000:]\n[train_set.shape, valid_set.shape, test_set.shape]","1cec92d7":"# dzielimy nasz zbi\u00f3r na X (dane) i y (rozwi\u0105zanie \/ etykiet\u0119)\nX_train = train_set.drop('label', axis=1) # axis=1 oznacza 'pozb\u0105d\u017a si\u0119 kolumny'\nX_valid = valid_set.drop('label', axis=1)\nX_test = test_set.drop('label', axis=1)\nX_train.columns","498f3066":"# Wszystkie algorytmy uczenia maszynowego dzia\u0142aj\u0105 dobrze tylko je\u015bli wystandaryzujemy \/ znormalizujemy\n# nasze dane (ich warto\u015b\u0107 mie\u015bci si\u0119 w przedziale 0-1), s\u0142u\u017c\u0105 do tego gotowe biblioteki\n# UWAGA! Nigdy nie zmieniaj warto\u015bci y (etykiet)\nX_train = X_train \/ 255.\nX_valid = X_valid \/ 255.\nX_test = X_test \/ 255.","03aacce1":"y_train = train_set.label\ny_valid = valid_set.label\ny_test = test_set.label\ny_train.dtype","b1cc24cf":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\n\ndef print_image(index):\n    sample_digit = X_train.to_numpy()[index]\n    sample_digit_image = sample_digit.reshape(28,28)\n\n    plt.imshow(sample_digit_image, cmap=\"binary\")\n    plt.axis('off')\n    plt.show()\n\nprint_image(7)","4079bc7a":"y_train[7]","8fb8f3e2":"from keras import layers # budujemy nasz model\n\nmodel = keras.models.Sequential([ # model sekwencyjny zawiera kolejno u\u0142o\u017cone warstwy neuron\u00f3w\n    layers.InputLayer(input_shape=[784]), # warstwa wej\u015bciowa nie ma funkcji aktywacji\n    layers.Dense(50, activation='relu'), # relu jest najpopularniejsz\u0105 funkcj\u0105 aktywacji\n    layers.Dense(50, activation='relu'), # w warstwach ukrytych\n    layers.Dense(50, activation='relu'), # 50 neuron\u00f3w u\u0142o\u017conych w jednym rz\u0119dzie\n    layers.Dense(10, activation='softmax')\n])\n\n# Prosz\u0119 zignorowa\u0107 ewentualne informacje User \/ Experience settings\n# Informacja zwr\u00f3cona przez platform\u0119 Kaggle, nie ma wp\u0142ywu na model","07f576dd":"model.summary()","c2e171ac":"keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True)","acd754ae":"# Kolejnym krokiem jest okre\u015blenie funkcji straty, optymalizatora i dodatkowych wska\u017anik\u00f3w\nmodel.compile(loss='sparse_categorical_crossentropy', # funkcja straty\n              optimizer=keras.optimizers.SGD(lr=0.01), # optymalizator (gradient prosty)\n              metrics=['accuracy'] # wska\u017anik (odsetek dobrych odpowiedzi)\n             )","7211f80e":"# trenujemy model za pomoc\u0105 zbioru treningowego i walidacyjnego\n# epochs=10 oznacza, \u017ce 10 razy rozlosujemy nasz zbi\u00f3r treningowy na minigrupy po 32 przyk\u0142ady\n# 30 000 \/ 32 = 938\nhistory = model.fit(X_train, y_train, epochs=10,\n                    validation_data=(X_valid, y_valid))","d9cb4bb0":"pd.DataFrame(history.history).plot(figsize=(8,5))\nplt.grid(True)\nplt.gca().set_ylim(0,1) # Wyznacza zakres osi pionowej od 0 do 1\nplt.show()","71541887":"model.evaluate(X_test, y_test) # oceniamy wytrenowany model na zbiorze testowym","3dd19d46":"X_new = X_test[:5]\ny_proba = model.predict(X_new)\ny_proba.round(2)","ccae2024":"#na koniec przygotowujemy ostateczn\u0105 odpowied\u017a na zadanie konkursowe\n\nTEST_data_filepath='..\/input\/digit-recognizer\/test.csv'\nTEST_data = pd.read_csv(TEST_data_filepath)","b04a2616":"TEST_proba = model.predict(TEST_data)","2963cbe2":"# Format odpowiedzi podany jest w pliku sample_submission.csv w zak\u0142adce po prawej\n\nImageId = [id for id in range(1,len(TEST_proba)+1)]\n\nLabel = []\nfor image_proba in TEST_proba:\n    highest_value_index = np.argmax(image_proba) # indeks najwi\u0119kszego prawdopodobie\u0144stwa w tablicy\n    Label.append(highest_value_index)","398ce18c":"ImageId[:5] # nr obrazka","213d3371":"Label[:5] # jaka liczba jest wg naszego modelu na obrazku","2d229c27":"TEST_proba[:5]","437b086f":"output = pd.DataFrame({'ImageId': ImageId,\n                      'Label': Label})\noutput.to_csv('submission.csv', index=False)","6b549392":"> Keras is an API designed for human beings, not machines. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear & actionable error messages. It also has extensive documentation and developer guides.\n\nhttps:\/\/keras.io\/","89636403":"Rozwi\u0105zywany przez nas problem jest przyk\u0142adem klasyfikacji wieloklasowej. Ka\u017cdy obrazek mo\u017cemy przyporz\u0105dkowa\u0107 do jednej z dziesi\u0119ciu klas (10 cyfr). Zadaniem naszego modelu b\u0119dzie obliczenie jakie jest prawdopodobie\u0144stwo, \u017ce dany obrazek nale\u017cy do ka\u017cdej z klas. Cyfra z najwi\u0119kszym prawdopodobie\u0144stwem \"wygrywa\" i jest naszym rozwi\u0105zaniem.\n\nPrzyk\u0142ad:\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] - tablica klas\n\n[0., 0., 0., 0.15, 0., 0.26, 0., 0., 0.59, 0.] - tablica prawdopodobie\u0144stw\n\nOdpowied\u017a - na obrazku jest cyfra 8\n\nFunkcj\u0105 aktywacji na wyj\u015bciu jest softmax, poniewa\u017c mamy wtedy pewno\u015b\u0107, \u017ce wyj\u015bcia neuron\u00f3w (prawdopodobie\u0144stwa) sumuj\u0105 si\u0119 do 1.","dbd3825d":"Praca domowa:\n\nUdoskonal powy\u017cszy kod, tak aby uzyska\u0107 lepsz\u0105 dok\u0142adno\u015b\u0107 \/ wy\u017csz\u0105 pozycj\u0119 w rankingu\n\nPodpowied\u017a:\n* Przede wszystkim spr\u00f3buj zmieni\u0107 warto\u015bci hiperparametr\u00f3w:\n* * liczba warstw ukrytych: zazwyczaj jest ich od 1 do 5, nasz problem jest stosunkowo prosty, bez problemu osi\u0105gn\u0119li\u015bmy dok\u0142adno\u015b\u0107 powy\u017cej 90%\n* * liczba neuron\u00f3w w warstwie ukrytych: zazwyczaj jest ich do 10 do 100\n* Kolejnym krokiem jest zmiana wsp\u00f3\u0142czynnika uczenia (lr), ma\u0142y lr da dok\u0142adniejsze wyniki, ale b\u0119dzie potrzebowa\u0142 wi\u0119cej czasu na dotarcie do minimum, mo\u017ce tak\u017ce utkn\u0105\u0107 w minimum lokalnym (obserwuj wykres dok\u0142adno\u015bci \/ straty)\n* * Mo\u017cesz tak\u017ce d\u0142u\u017cej trenowa\u0107 model (zwi\u0119ksz warto\u015b\u0107 epochs)\n* Dla ambitnych: sprawd\u017a czym jest data augmentation","ec2d55a7":"Parametrami w naszym modelu s\u0105 wagi po\u0142\u0105cze\u0144 pomi\u0119dzy neuronami. Neurony z dw\u00f3ch kolejnych warstw s\u0105 po\u0142\u0105czone ka\u017cdy z ka\u017cdym. Dodatkowo w ka\u017cdej warstwie jest obci\u0105\u017cenie (bias) r\u00f3wne 1\n\nPrzyk\u0142ad:\n\n1 warstwa - 784 neurony (liczba pikseli) + obci\u0105\u017cenie\n\n2 warstwa - 50 neuron\u00f3w (hiperparametr ustalany przez programist\u0119)\n\nRazem (784+1) * 50 = 39250 wag po\u0142\u0105cze\u0144\n\n2, 3 warstwa -> 51 * 50 = 2550\n\nOptymalizowaniem wag po\u0142\u0105cze\u0144 zajmuje si\u0119 komputer, dlatego nie musimy przejmowa\u0107 si\u0119 tymi ogromnymi liczbami.","5924824b":"Na pocz\u0105tku importujemy dane (tak jak to pokaza\u0142em na Teamsach)","430ae3df":"W\u0142a\u015bnie stworzyli\u015bmy nasz\u0105 pierwsz\u0105 sie\u0107 neuronow\u0105. Sk\u0142ada si\u0119 ona z jednej warstwy wej\u015bciowej,trzech warstw ukrytych i jednej warstwy wyj\u015bciowej. Warstwa wej\u015bciowa sk\u0142ada si\u0119 z 784 neuron\u00f3w, po jednym na ka\u017cdy piksel. Warstwy ukryte zawieraj\u0105 po 50 neuron\u00f3w. Warstwa wyj\u015bciowa sk\u0142ada si\u0119 z 10 neuron\u00f3w, po jednym na ka\u017cd\u0105 klas\u0119 [0,1,2,3,4,5,6,7,8,9]. Na wyj\u015bciu ka\u017cdego z tych neuron\u00f3w znajduje si\u0119 prawdopodobie\u0144stwo, \u017ce na danym obrazku jest pewna liczba. Prawdopodobie\u0144stwa sumuj\u0105 si\u0119 do jedynki, dlatego u\u017cyli\u015bmy funkcji aktywacji softmax.","d618e5af":"W zbiorze treningowym znajduje si\u0119 42.000 obrazk\u00f3w liczb, ka\u017cdy w postaci 784 (28X28) pikseli w r\u00f3\u017cnych odcieniach szaro\u015bci od 0 - bia\u0142y do 255 - czarny piksel","4a6aff1f":"Z naszego zbioru treningowego (MNIST_data) wyodr\u0119bniamy trzy mniejsze zbiory:\n* Treningowy - model uczy si\u0119 na tym zbiorze, jaka warto\u015b\u0107 **parametr\u00f3w** (w przypadku sieci neuronowych b\u0119d\u0105 to **wagi po\u0142\u0105cze\u0144 pomi\u0119dzy neuronami**) b\u0119dzie najbardziej optymalna \/ zmniejszy funkcj\u0119 kosztu \/ da najdok\u0142adniejsze wyniki predykcji\n* Walidacyjny - s\u0142u\u017cy do oceny modelu jeszcze w trakcie jego uczenia, pomo\u017ce nam stwierdzi\u0107, jaka warto\u015b\u0107 **hiperparametr\u00f3w** b\u0119dzie najlepsza dla rozwi\u0105zywanego zadania, co wa\u017cne model nie uczy si\u0119 z danych walidacyjnych, a jedynie ocenia na nich dok\u0142adno\u015b\u0107 predykcji\n* Testowy - s\u0142u\u017cy do oceny finalnego, ju\u017c wytrenowanego modelu, dobry programista nigdy nie zagl\u0105da do tego zbioru, co mog\u0142oby spowodowa\u0107 mylne skojarzenia, wnioski\n\nZazwyczaj zbi\u00f3r treningowy zawiera 70-80% danych, w przypadku wi\u0119kszych zbior\u00f3w danych (> 1 mln wierszy) na zbi\u00f3r walidacyjny \/ testowy sk\u0142ada si\u0119 po kilkadziesi\u0105t tysi\u0119cy obserwacji"}}