{"cell_type":{"839e356e":"code","7bea2914":"code","e397fd64":"code","a58c4ed3":"code","2a4b8629":"code","d87f06f4":"code","263023bf":"code","61fdfdc5":"code","6411bb0f":"code","18ec5b1b":"code","290c835b":"code","9985cd6d":"code","34171948":"code","1ffad7a2":"code","7cbe5f30":"code","5f8962ea":"code","be8ce7fa":"code","25dcd4d8":"code","995f8e47":"code","7fcf7a01":"code","67863b69":"code","88914495":"code","5269d163":"code","d8f7bf90":"code","2dacc587":"code","e32c7f0b":"code","a8d45d57":"code","2894f692":"code","3a327498":"code","f210ca3a":"code","80a7388a":"code","8847d139":"code","c9c4e9e0":"code","3f835701":"code","393365da":"code","c6035174":"code","88340fdb":"code","b7f86ca3":"code","68340181":"markdown","a0fedb74":"markdown","dd9dae09":"markdown","b32c0108":"markdown","644e63ad":"markdown","32638c01":"markdown","110f8a87":"markdown","740eebd3":"markdown","34d2a0ae":"markdown","46406f8b":"markdown","bbf9fe8b":"markdown","28d9d58f":"markdown","92372460":"markdown","2ca34772":"markdown","cc841e37":"markdown","59f54b70":"markdown","4eb9e73c":"markdown","4ed7b243":"markdown","43424c4d":"markdown","c3249122":"markdown","c3f3f5bf":"markdown","d08d55c0":"markdown","f8ab83cd":"markdown","df4419eb":"markdown","8d96c47d":"markdown","a7143e8c":"markdown","ffcb9e96":"markdown","0f6cfd3e":"markdown","e4fd71a6":"markdown","0e9f3aac":"markdown","1a98b78e":"markdown","bd8666a8":"markdown","d252eff3":"markdown","cd85601a":"markdown","2dd48c0f":"markdown","f02efc78":"markdown","9c82bf6e":"markdown","984b6777":"markdown","3d5f54ce":"markdown","7d21ab88":"markdown","45eeac05":"markdown","fe2f2800":"markdown","0193c3c1":"markdown","a586b872":"markdown","beb63470":"markdown","d5b29934":"markdown","6c72956a":"markdown","55084d1a":"markdown","6a4874e1":"markdown","2987909a":"markdown","84241257":"markdown","3d46f7c6":"markdown","fe55e0d8":"markdown","4cd9ab4f":"markdown","189a9225":"markdown","6551fca5":"markdown","5f745aa9":"markdown","bfbd0d6a":"markdown","bdee49e5":"markdown","3b2c3cdc":"markdown"},"source":{"839e356e":"!cp -r ..\/input\/100-bird-species .\/\n!pip install adamp\n!pip install timm\n!pip install -q imutils","7bea2914":"CFG = {\n    'fold_num': 5,\n    'seed': 125,\n    'img_size': 224, \n    'train_bs': 128,\n    'valid_bs': 128,\n    'weight_decay':1e-6,\n    'model_arch': 'gluon_seresnext50_32x4d', \n    'epochs': 12,\n    'lr': 0.0003,\n    'num_workers': 4,\n    'accum_iter': 1,\n    'accelerator': 'TPU', \n    'num_classes': 275,\n    'grad_clip': 0.001\n}","e397fd64":"if CFG['accelerator']=='TPU':\n    !curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py\n    !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n    import torch\n    import torch_xla\n    import torch_xla.core.xla_model as xm\n    import torch_xla.debug.metrics as met\n    import torch_xla.distributed.parallel_loader as pl\n    import torch_xla.distributed.xla_multiprocessing as xmp\n    import torch_xla.utils.utils as xu\n    import os\n    os.environ[\"XLA_USE_BF16\"] = \"1\"\n    os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\"\n    device = xm.xla_device()\n    \nif CFG['accelerator']=='GPU':\n    import torch\n    device = torch.device('cuda:0')\n    torch.backends.cudnn.benchmark = True\n    print(torch.cuda.is_available())","a58c4ed3":"package_paths = [\n    '..\/input\/image-fmix\/FMix-master'\n]\n\nimport sys; \n\nfor pth in package_paths:\n    sys.path.append(pth)\n    \nfrom fmix import sample_mask, make_low_freq_image, binarise_mask\n\nfrom glob import glob\nimport joblib\nimport sklearn\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom sklearn import metrics\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom skimage import io\nfrom torchvision.datasets import ImageFolder\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom torch import nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.nn.modules.loss import _WeightedLoss\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\nfrom torchvision import datasets\nfrom torchvision import transforms\n\nimport xgboost\nimport sklearn\n\nimport os\nfrom os.path import join\nfrom os import listdir, rmdir\nfrom shutil import move\nimport random\nfrom operator import itemgetter\nimport copy\nimport time\nimport timm\nfrom adamp import AdamP\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.image import imread\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport pydicom\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.cluster.vq import kmeans,whiten\nfrom scipy.stats import zscore\nfrom operator import itemgetter\nimport shutil\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nimport imutils\nimport gc\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2a4b8629":"le = LabelEncoder()\n\nall_data = pd.read_csv('.\/100-bird-species\/birds\/birds.csv')\nall_data = all_data.rename(columns={'filepaths':'image_id', 'labels':'species'})\n\ntrain = all_data[all_data['data set'] != 'test'].loc[:, ['image_id', 'species']]#, 'labels']]\ntrain['image_id'] = train.image_id.apply(lambda x: '\/'.join(x.split('\\\\')[-3:]))\ntrain = train.reset_index(drop=True)\n\ntest = all_data[all_data['data set'] == 'test'].loc[:, ['image_id', 'species']]#, 'labels']]\ntest['image_id'] = test.image_id.apply(lambda x: '\/'.join(x.split('\\\\')[-3:]))\ntest = test.reset_index(drop=True)\n\ndisplay(train)\ndisplay(test)","d87f06f4":"fig = go.Figure(\n    data=[ go.Bar(x=train['species'].value_counts().index, \n            y=train['species'].value_counts().values,\n            text=train['species'].value_counts().values,\n            textposition='auto',name='Count',\n           marker_color='indianred')],\n    layout_title_text=\"Class distribution\"\n)\nfig.show()","263023bf":"for idx in tqdm(train.index):\n    img_name = train.loc[idx,'image_id']\n    #reading the image and converting BGR color space to RGB\n    img = cv2.cvtColor(cv2.imread('.\/100-bird-species\/birds\/'+img_name), cv2.COLOR_BGR2RGB)\n    \n    #normalize the image in the range [0,1]\n    norm_image = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    \n    width,height,depth = img.shape\n    \n    #adding new column to the tabel with width height and aspect ratio for every image\n    train.loc[idx,'Width'] = width\n    train.loc[idx,'Height'] = height\n    train.loc[idx,'Aspect Ratio'] = width\/height\n    \n    #calculate mean and standart deviation for each image\n    train.loc[idx,'Mean'] = img.mean()\n    train.loc[idx,'SD'] = img.std()\n    \n    #calculate mean and standart deviation for each normalized image\n    train.loc[idx,'Normalized_Mean'] = norm_image.mean()\n    train.loc[idx,'Normalized_SD'] = norm_image.std()\ntrain","61fdfdc5":"fig =  make_subplots(rows=2,cols=1,subplot_titles=['Original Image', 'Normalized Image'])\ncolors = ['rgb({}, {}, {})'.format(random.randint(0,255), random.randint(0,255), random.randint(0,255)) for iter in range(len(train['species'].unique()))]\nfor idx,class_name in enumerate(train['species'].unique()):\n    #scatter plot between mean and variance of the images for every disease\n    fig.add_trace(go.Scatter(x=train[train['species'] == class_name]['Mean'],\n                             y=train[train['species'] == class_name]['SD'],\n                            mode = 'markers',name=class_name, marker_color=colors[idx]),1,1)\n    \n    #scatter plot between mean and variance of the normalized images for every disease\n    fig.add_trace(go.Scatter(x=train[train['species'] == class_name]['Normalized_Mean'],\n                             y=train[train['species'] == class_name]['Normalized_SD'],\n                            mode = 'markers',name=class_name, marker_color=colors[idx], showlegend=False),2,1)\n#x-axis and y axis title\nfig.update_xaxes(title_text=\"Mean\", row=1, col=1)\nfig.update_yaxes(title_text=\"Standard Deviation\", row=1, col=1)\n\nfig.update_xaxes(title_text=\"Mean\", row=2, col=1)\nfig.update_yaxes(title_text=\"Standard Deviation\", row=2, col=1)\nfig.show()","6411bb0f":"input_path = '.\/100-bird-species\/birds\/'\nfrom scipy.cluster.vq import kmeans,whiten\nfrom scipy.stats import zscore","18ec5b1b":"fig = make_subplots(rows=2,cols=1,\n                    subplot_titles=['Normalized Mean','Normalized Standard Deviation'],\n                    shared_xaxes=True)\ncolors = ['rgb({}, {}, {})'.format(random.randint(0,255), random.randint(0,255), random.randint(0,255)) for iter in range(len(train['species'].unique()))]\nfor idx,class_name in enumerate(train['species'].unique()):\n    fig.add_trace(go.Box(y=train[train['species'] == class_name]['Normalized_Mean'],\n                        name=class_name,showlegend=False,\n                        marker_color=colors[idx]),1,1)\n    fig.add_trace(go.Box(y=train[train['species'] == class_name]['Normalized_SD'],\n                        name=class_name,showlegend=False,\n                        marker_color=colors[idx]),2,1)\nfig.update_layout(title='Outlier Detection - Box Plot')\nfig.show()","290c835b":"def calculate_fences_new(array):\n    upper_fence = array.describe()['75%']+1.5*(array.describe()['75%']-array.describe()['25%'])\n    lower_fence = array.describe()['25%']-1.5*(array.describe()['75%']-array.describe()['25%'])\n    return lower_fence, upper_fence","9985cd6d":"outliers = set()\n\nfor species in train['species'].unique():\n    images  = train[train['species'] ==  species]\n    \n    data_for_fences_mean = train[train['species']==species].loc[:, 'Normalized_Mean']\n    data_for_fences_sd = train[train['species']==species].loc[:, 'Normalized_SD']\n    \n    outliers_mean = images[images['Normalized_Mean'].between(calculate_fences_new(data_for_fences_mean)[0],calculate_fences_new(data_for_fences_mean)[1],inclusive=True)]\n    outliers_mean = images[~images['image_id'].isin(outliers_mean['image_id'])]\n    \n    outliers_st = images[images['Normalized_SD'].between(calculate_fences_new(data_for_fences_sd)[0],calculate_fences_new(data_for_fences_sd)[1],inclusive=True)]\n    outliers_st = images[~images['image_id'].isin(outliers_st['image_id'])]\n    \n    delete_mean = set(input_path+outliers_mean['image_id'].astype(str).values)\n    delete_st= input_path+outliers_st['image_id'].astype(str).values\n    outliers = outliers.union(delete_mean)\n    outliers = outliers.union(delete_st)\n    \nprint(len(outliers))\n","34171948":"imgs = list(outliers)\n\ngridimg = []        \nfor idx,img_name in enumerate(np.random.choice(imgs,25,replace=False)):\n    np_image = mpimg.imread(img_name)\n    gridimg.append(np_image)\n\nfig = plt.figure(figsize=(25, 25))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(5, 5),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 label_mode=\"1\")\n\nfor ax, im in zip(grid, gridimg):\n    # Iterating over the grid returns the Axes.\n    ax.imshow(im)\n    ax.axis('off')\n\nplt.show()","1ffad7a2":"for images in outliers:\n    os.remove(images)\n    train = train.drop(train[train['image_id']=='\/'.join(images.split('\/')[-3:])].index)","7cbe5f30":"train","5f8962ea":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(CFG['seed'])","be8ce7fa":"def init_logger(log_file='.\/'+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()","25dcd4d8":"def get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb","995f8e47":"def rand_bbox(size, lam):\n    W = size[0]\n    H = size[1]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.int(W * cut_rat)\n    cut_h = np.int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w \/\/ 2, 0, W)\n    bby1 = np.clip(cy - cut_h \/\/ 2, 0, H)\n    bbx2 = np.clip(cx + cut_w \/\/ 2, 0, W)\n    bby2 = np.clip(cy + cut_h \/\/ 2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, df, data_root, \n                 transforms=None, \n                 output_label=True, \n                 one_hot_label=False,\n                 do_fmix=False, \n                 fmix_params={\n                     'alpha': 1., \n                     'decay_power': 3., \n                     'shape': (CFG['img_size'], CFG['img_size']),\n                     'max_soft': True, \n                     'reformulate': False\n                 },\n                 do_cutmix=False,\n                 cutmix_params={\n                     'alpha': 1,\n                 }\n                ):\n        \n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms = transforms\n        self.data_root = data_root\n        self.do_fmix = do_fmix\n        self.fmix_params = fmix_params\n        self.do_cutmix = do_cutmix\n        self.cutmix_params = cutmix_params\n        \n        self.output_label = output_label\n        self.one_hot_label = one_hot_label\n        \n        if output_label == True:\n            self.species = self.df['species'].values\n            \n            if one_hot_label is True:\n                self.species = np.eye(self.df['species'].max()+1)[self.species]\n            \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            target = self.species[index]\n          \n        img  = get_img(\"{}\/{}\".format(self.data_root, self.df.loc[index]['image_id']))\n\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        \n        if self.do_fmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n            with torch.no_grad():\n                \n                lam = np.clip(np.random.beta(self.fmix_params['alpha'], self.fmix_params['alpha']),0.6,0.7)\n                \n                # Make mask, get mean \/ std\n                mask = make_low_freq_image(self.fmix_params['decay_power'], self.fmix_params['shape'])\n                mask = binarise_mask(mask, lam, self.fmix_params['shape'], self.fmix_params['max_soft'])\n    \n                fmix_ix = np.random.choice(self.df.index, size=1)[0]\n                fmix_img  = get_img(\"{}\/{}\".format(self.data_root, self.df.iloc[fmix_ix]['image_id']))\n\n                if self.transforms:\n                    fmix_img = self.transforms(image=fmix_img)['image']\n\n                mask_torch = torch.from_numpy(mask)\n                \n                # mix image\n                img = mask_torch*img+(1.-mask_torch)*fmix_img\n\n                # mix target\n                rate = mask.sum()\/CFG['img_size']\/CFG['img_size']\n                target = rate*target + (1.-rate)*self.labels[fmix_ix]\n        \n        if self.do_cutmix and np.random.uniform(0., 1., size=1)[0] > 0.5:\n            with torch.no_grad():\n                cmix_ix = np.random.choice(self.df.index, size=1)[0]\n                cmix_img  = get_img(\"{}\/{}\".format(self.data_root, self.df.iloc[cmix_ix]['image_id']))\n                if self.transforms:\n                    cmix_img = self.transforms(image=cmix_img)['image']\n                    \n                lam = np.clip(np.random.beta(self.cutmix_params['alpha'], self.cutmix_params['alpha']),0.3,0.4)\n                bbx1, bby1, bbx2, bby2 = rand_bbox((CFG['img_size'], CFG['img_size']), lam)\n\n                img[:, bbx1:bbx2, bby1:bby2] = cmix_img[:, bbx1:bbx2, bby1:bby2]\n\n                rate = 1 - ((bbx2 - bbx1) * (bby2 - bby1) \/ (CFG['img_size'] * CFG['img_size']))\n                target = rate*target + (1.-rate)*self.labels[cmix_ix]\n        if self.output_label == True:\n            return img, target\n        else:\n            return img","7fcf7a01":"from albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,ImageCompression,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, \n    CenterCrop, Resize, RandomGamma, Posterize, GaussianBlur\n)\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations.pytorch import ToTensorV2\n\ndef get_transforms(data):\n    \n    if data == 'train':\n        return Compose([\n            #RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            CLAHE(p=0.5),\n#             Posterize(p=0.5),\n#             GaussianBlur(p=0.5),\n#             ImageCompression(p=0.5),\n            #HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0),\n        ], p=1.)\n\n    elif data == 'val':\n        return Compose([\n            #CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            #Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","67863b69":"#Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=5, ncols=5, figsize=(15,12))\n    i = 0\n    for row in range(5):\n         for col in range(5):\n                img = mpimg.imread(input_path+samples[i][0][0])\n                ax[row][col].imshow(img)\n                ax[row][col].axis('off')\n                ax[row][col].set_title(samples[i][1], fontsize=15)\n                i+=1\n  \nexample = train\n\nrand_samples = [] \nfor _ in range(25): \n    sample = random.sample(list(train['image_id']), 1)\n    rand_samples.append([sample, train[train['image_id']==sample[0]]['species'].values[0]])\nrand_samples[0]\nplot_samples(rand_samples)\nplt.suptitle('Samples', fontsize=30)\nplt.tight_layout()\nplt.show()","88914495":"le = LabelEncoder()\nsets = {'train':train, 'test':test}\nfor x in ['train', 'test']:\n    sets[x]['species'] = le.fit_transform(sets[x].species.values)","5269d163":"def prepare_dataloader(df, trn_idx, val_idx, data_root='.\/100-bird-species\/birds'):\n    \n    \n\n    train_ = df.reset_index().loc[trn_idx,:].reset_index(drop=True)\n    valid_ = df.reset_index().loc[val_idx,:].reset_index(drop=True)\n        \n    train_ds = CustomDataset(train_, data_root, transforms=get_transforms(data='train'), output_label=True, one_hot_label=False, do_fmix=False, do_cutmix=False)\n    valid_ds = CustomDataset(valid_, data_root, transforms=get_transforms(data='val'), output_label=True)\n    \n    if CFG['accelerator']=='TPU':\n        \n        train_sampler = torch.utils.data.distributed.DistributedSampler(\n            train_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n\n        valid_sampler = torch.utils.data.distributed.DistributedSampler(\n            valid_ds,\n            num_replicas=xm.xrt_world_size(),\n            rank=xm.get_ordinal(),\n            shuffle=True\n    )\n    \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            shuffle=False,\n            sampler=train_sampler,\n            num_workers=CFG['num_workers'],\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            sampler=valid_sampler,\n            pin_memory=True,\n    )\n        \n    if CFG['accelerator']=='GPU':\n        \n        train_loader = torch.utils.data.DataLoader(\n            train_ds,\n            batch_size=CFG['train_bs'],\n            pin_memory=True,\n            drop_last=False,\n            shuffle=True,        \n            num_workers=CFG['num_workers']\n    )\n        val_loader = torch.utils.data.DataLoader(\n            valid_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=True\n    )\n    \n    \n    return train_loader, val_loader, len(train_ds), len(valid_ds)","d8f7bf90":"from torch import autograd\n\ndef train_one_epoch(loader, epoch, model, optimizer, criterion, device, gradient_clipping=False):\n   \n   LOGGER.info('--------------------------------------------------------------')\n   LOGGER.info('Epoch: {}\/{}'.format(epoch+1, CFG['epochs']))\n   model.train()\n  \n   running_loss = 0.\n   running_corrects = 0.\n\n   pbar = tqdm(enumerate(loader), total=len(loader))\n   for step, (imgs, targets) in pbar:\n      imgs, targets = imgs.to(device).float(), targets.to(device).long()\n      if CFG['accelerator']=='GPU':\n        with autocast():\n            output = model(imgs)\n            loss = criterion(output, targets)\n            loss = loss \/ CFG['accum_iter']\n        scaler.scale(loss).backward()\n            \n            \n      if CFG['accelerator']=='TPU':   \n        \n        output = model(imgs)\n        gc.collect()\n        loss = criterion(output, targets)\n        loss = loss \/ CFG['accum_iter']\n        loss.backward()\n      \n      if gradient_clipping:\n        timm.utils.agc.adaptive_clip_grad(model.parameters(), clip_factor=CFG['grad_clip'], eps=1e-3, norm_type=2.0)\n        \n      _, pred = output.max(dim=1)\n      running_corrects += torch.sum(pred == targets.data)\n      running_loss += loss.item()*imgs.size(0)\n            \n      pbar.set_description(f'train | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}')\n      if ((step + 1) % CFG['accum_iter'] == 0) or ((step + 1) == len(loader)):\n            \n            if CFG['accelerator']=='GPU':\n                scaler.step(optimizer)\n                scaler.update()\n                \n            if CFG['accelerator']=='TPU':\n                xm.optimizer_step(optimizer)\n                \n            optimizer.zero_grad()\n   return running_corrects, running_loss","2dacc587":"def valid_one_epoch(loader,epoch, model, device, criterion):\n    model.eval()\n    \n    running_loss = 0.\n    running_corrects = 0.\n    \n    pbar = tqdm(enumerate(loader), total=len(loader))\n    for step, (imgs, targets) in pbar:\n       imgs, targets = imgs.to(device).float(), targets.to(device).long()\n       with torch.no_grad():\n             output = model(imgs)\n             gc.collect()\n             _, pred = output.max(dim=1)\n             loss = criterion(output, targets)\n       running_corrects += torch.sum(pred == targets.data)\n       running_loss += loss.item()*imgs.size(0)\n       gc.collect()\n    \n       pbar.set_description(f'val | epoch {epoch+1} | current loss: {loss.item()*imgs.size(0):.4f}')\n                \n    return running_corrects, running_loss","e32c7f0b":"def fit(seed, epochs, model, freeze, device, fold, train_loader, val_loader, criterion, gradient_clipping=False):\n  if CFG['accelerator']=='TPU':\n          LOGGER.info('Creating a model...')\n          WRAPPED_MODEL = xmp.MpModelWrapper(model)\n          model = WRAPPED_MODEL.to(device)\n          model.to(device)\n          if freeze==True:\n            if seed==1:\n              optimizer = torch.optim.Adam(model.head.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n            if seed==2 or seed==3:\n              optimizer = torch.optim.Adam(model.fc.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n            if seed==4 or seed==0:\n              optimizer = torch.optim.Adam(model.classifier.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n          if freeze==False:\n            optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr']* xm.xrt_world_size(), betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n        \n  if CFG['accelerator'] == 'GPU':\n    LOGGER.info('Creating a model...')\n    model.to(device)\n    if freeze==True:\n        if seed==1:\n            optimizer = torch.optim.Adam(model.head.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n        if seed==2 or seed==3:\n            optimizer = torch.optim.Adam(model.fc.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])\n        if seed==4 or seed==0:\n            optimizer = torch.optim.Adam(model.classifier.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])           \n    if freeze==False:\n       optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'], amsgrad=False)\n       #optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'], amsgrad=False)\n       #optimizer = AdamP(model.parameters(), lr=CFG['lr'], betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'], amsgrad=False)\n    \n  #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, threshold=.9, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)\n  #scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 10, T_mult=1, eta_min=0, last_epoch=-1)\n  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3, gamma=0.1)\n  since = time.time()\n  best_model = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n  \n  if CFG['accelerator']=='TPU':\n     if freeze==True:\n                                         \n        for fase in ['CLASSIFIER TRAINING', 'ALL NET TRAINING']:\n                                         \n            if fase=='ALL NET TRAINING':             \n               model.load_state_dict(best_model)\n               for param in model.parameters():\n                   param.requires_grad=True\n               optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr']* xm.xrt_world_size()\/10, betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])  \n               scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)     \n                                         \n            for epoch in range(epochs):\n                                         \n                #train\n                para_loader = pl.ParallelLoader(train_loader, [device])\n                running_corrects, running_loss = train_one_epoch(para_loader.per_device_loader(device), epoch, model, optimizer, criterion, device, gradient_clipping)\n                epoch_loss = running_loss \/ train_len\n                epoch_acc = running_corrects\/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n                \n                #val\n                para_loader = pl.ParallelLoader(val_loader, [device])\n                running_corrects, running_loss = valid_one_epoch(para_loader.per_device_loader(device), epoch, model, device, criterion)\n                epoch_loss = running_loss \/ val_len\n                epoch_acc = running_corrects\/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss)\n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n                   \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n            time_elapsed = time.time() - since\n            LOGGER.info('{} TIME {}m {}s'.format(fase, time_elapsed\/\/60, time_elapsed%60))\n            LOGGER.info('=='*31)\n                                         \n     if freeze==False:\n        for epoch in range(epochs):\n                                         \n                #train\n                para_loader = pl.ParallelLoader(train_loader, [device])\n                running_corrects, running_loss = train_one_epoch(para_loader.per_device_loader(device), epoch, model, optimizer, criterion, device, gradient_clipping)\n                epoch_loss = running_loss \/ train_len\n                epoch_acc = running_corrects\/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n                \n                \n                #val\n                para_loader = pl.ParallelLoader(val_loader, [device])\n                running_corrects, running_loss = valid_one_epoch(para_loader.per_device_loader(device), epoch, model, device, criterion)\n                epoch_loss = running_loss \/ val_len\n                epoch_acc = running_corrects\/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                del para_loader\n                gc.collect()\n    \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step(epoch_loss)\n      \n        time_elapsed = time.time() - since\n        LOGGER.info('FOLD_{} TRAINING TIME {}m {}s'.format(fold+1, time_elapsed\/\/60, time_elapsed%60))\n        LOGGER.info('=='*31) \n                                         \n                                         \n  if CFG['accelerator']=='GPU':\n     if freeze==True:\n                                         \n        for fase in ['CLASSIFIER TRAINING', 'ALL NET TRAINING']:\n                                         \n            if fase=='ALL NET TRAINING':             \n               model.load_state_dict(best_model)\n               for param in model.parameters():\n                   param.requires_grad=True\n               optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr']\/10, betas=(0.9, 0.999), eps=1e-08, weight_decay=CFG['weight_decay'])  \n               scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)     \n                                         \n            for epoch in range(CFG['epochs']):\n                                         \n                #train                           \n                running_corrects, running_loss = train_one_epoch(train_loader, epoch, model, optimizer, criterion, device, gradient_clipping)\n                epoch_loss = running_loss \/ train_len\n                epoch_acc = running_corrects\/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                \n                #val\n                running_corrects, running_loss = valid_one_epoch(val_loader, epoch, model, device, criterion)\n                epoch_loss = running_loss \/ val_len\n                epoch_acc = running_corrects\/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n            time_elapsed = time.time() - since\n            LOGGER.info('{} TIME {}m {}s'.format(fase, time_elapsed\/\/60, time_elapsed%60))\n            LOGGER.info('=='*31)\n                                         \n     if freeze == False :\n        for epoch in range(epochs):\n                \n                #train                           \n                running_corrects, running_loss = train_one_epoch(train_loader, epoch, model, optimizer, criterion, device, gradient_clipping)\n                epoch_loss = running_loss \/ train_len\n                epoch_acc = running_corrects\/ train_len\n                all_accuracies['fold_{}'.format(fold+1)][0].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][0].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('train', epoch_loss, epoch_acc))\n                \n                #val                             \n                running_corrects, running_loss = valid_one_epoch(val_loader, epoch, model, device, criterion)\n                epoch_loss = running_loss \/ val_len\n                epoch_acc = running_corrects\/ val_len\n                all_accuracies['fold_{}'.format(fold+1)][1].append(epoch_acc) \n                all_losses['fold_{}'.format(fold+1)][1].append(epoch_loss) \n                LOGGER.info('{} - loss:{}, accuracy:{}'.format('val', epoch_loss, epoch_acc))\n                \n                #epoch end\n                LOGGER.info('Time: {}m {}s'.format((time.time()- since)\/\/60, (time.time()- since)%60))\n                LOGGER.info('=='*31)\n                if epoch_acc >= best_acc:\n                  best_acc = epoch_acc\n                  best_model = copy.deepcopy(model.state_dict())\n                scheduler.step()\n      \n        time_elapsed = time.time() - since\n        LOGGER.info('FOLD_{} TRAINING TIME {}m {}s'.format(fold+1, time_elapsed\/\/60, time_elapsed%60))\n        LOGGER.info('=='*31) \n                                         \n  if CFG['accelerator']=='TPU':\n     xm.save(best_model,'{}_{}_fold_{}.pth'.format(CFG['accelerator'], CFG['model_arch'], fold+1))\n  if CFG['accelerator']=='GPU':\n     torch.save(best_model,'{}_{}_fold_{}.pth'.format(CFG['accelerator'], CFG['model_arch'], fold+1))\n  \n  LOGGER.info('Model Saved! \\n')","a8d45d57":"CFG","2894f692":"if __name__ == '__main__':\n    \n    seed_everything(CFG['seed'])\n    gc.enable() \n    \n    folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.species.values)\n    \n    fold_best_acc = []\n    \n    all_losses = {f'fold_{x+1}':[[],[]] for x in range(CFG['fold_num'])}\n    all_accuracies = {f'fold_{x+1}':[[],[]] for x in range(CFG['fold_num'])}\n    \n    criterion = nn.CrossEntropyLoss().to(device)\n    scaler = GradScaler()\n    \n    for fold, (trn_idx, val_idx) in enumerate(folds):\n            \n        LOGGER.info('\\n\\n')\n        LOGGER.info(f'========== fold: {fold+1} training ==========')\n        LOGGER.info('Accelerator: {}'.format(CFG['accelerator']))\n                                                     \n        train_loader, val_loader, train_len, val_len = prepare_dataloader(train, trn_idx, val_idx, data_root='.\/100-bird-species\/birds')\n        model = timm.create_model(CFG['model_arch'], pretrained=True, num_classes=CFG['num_classes'])\n        model = fit(seed=2, epochs = CFG['epochs'], model=model, freeze=False, device=device, fold=fold, train_loader=train_loader, val_loader=val_loader, criterion=criterion, gradient_clipping=False)\n        \n        LOGGER.info(f'========== fold: {fold+1} result ==========')\n        LOGGER.info('Score: {}'.format(max(all_accuracies['fold_{}'.format(fold+1)][1])))\n        fold_best_acc.append(max(all_accuracies['fold_{}'.format(fold+1)][1])) \n        del model, train_loader, val_loader\n        torch.cuda.empty_cache()\n        gc.collect(1)\n    # CV result\n    LOGGER.info(f\"========== CV ==========\")\n    LOGGER.info(f'Score: {max(fold_best_acc)}')","3a327498":"model_5 = timm.create_model(CFG['model_arch'], pretrained=False, num_classes=CFG['num_classes'])\nstate = torch.load('.\/TPU_gluon_seresnext50_32x4d_fold_5.pth')\nmodel_5.load_state_dict(state)\nmodel_5.to(device);","f210ca3a":"model_4 = timm.create_model(CFG['model_arch'], pretrained=False, num_classes=CFG['num_classes'])\nstate = torch.load('.\/TPU_gluon_seresnext50_32x4d_fold_4.pth')\nmodel_4.load_state_dict(state)\nmodel_4.to(device);","80a7388a":"model_3 = timm.create_model(CFG['model_arch'], pretrained=False, num_classes=CFG['num_classes'])\nstate = torch.load('.\/TPU_gluon_seresnext50_32x4d_fold_3.pth')\nmodel_3.load_state_dict(state)\nmodel_3.to(device);","8847d139":"model_2 = timm.create_model(CFG['model_arch'], pretrained=False, num_classes=CFG['num_classes'])\nstate = torch.load('.\/TPU_gluon_seresnext50_32x4d_fold_2.pth')\nmodel_2.load_state_dict(state)\nmodel_2.to(device);","c9c4e9e0":"model_1 = timm.create_model(CFG['model_arch'], pretrained=False, num_classes=CFG['num_classes'])\nstate = torch.load('.\/TPU_gluon_seresnext50_32x4d_fold_1.pth')\nmodel_1.load_state_dict(state)\nmodel_1.to(device);","3f835701":"models = [model_1, model_2, model_3, model_4, model_5]","393365da":"class Ensemble(nn.Module):\n    def __init__(self, device):\n        super(Ensemble,self).__init__()\n        # you should use nn.ModuleList. Optimizer doesn't detect python list as parameters\n        self.models = nn.ModuleList(models)\n        \n    def forward(self, x):\n        ## it is super simple. just forward num_ models and concat it.\n        output = torch.zeros([x.size(0), CFG['num_classes']]).to(device)\n        preds = []\n        softmax = nn.Softmax(dim=1)\n        for model in self.models:\n            output += model(x)\n        return output\n    \nens_model =  Ensemble(device)","c6035174":"test.reset_index()\ntest_ds= CustomDataset(test, '.\/100-bird-species\/birds', transforms=get_transforms(data='val'), output_label=True)\ntest_loader = torch.utils.data.DataLoader(\n            test_ds, \n            batch_size=CFG['valid_bs'],\n            num_workers=CFG['num_workers'],\n            shuffle=False,\n            pin_memory=True)\ntest_len = len(test_ds)","88340fdb":"def test_func(loader, model, test_len):\n        with torch.no_grad():\n            model.eval()\n            running_corrects = 0.\n            running_uncorrects = 0.\n            pbar = tqdm(enumerate(loader), total=len(loader))\n            for step, (imgs, targets) in pbar:\n                imgs, targets = imgs.to(device).float(), targets.to(device).long()\n                output = model(imgs)\n                _, pred = output.max(dim=1)\n                running_corrects += torch.sum(pred == targets.data)\n            acc = running_corrects \/ test_len\n            return acc","b7f86ca3":"print('Accuracy:', test_func(test_loader, ens_model, test_len).item())","68340181":"# **1. Data processing**","a0fedb74":"When Google developed the TPU, they were faced with the task of developing a processor not for general purpose, but for a specific task, so a matrix processor was made that specializes in working with neural networks. The TPU will not be able to work with a word processor, control rocket engines or perform bank transactions, but it can process a huge number of multiplications and additions for neural networks at an incredible speed, while consuming much less energy and fitting in a smaller physical volume","dd9dae09":"**Uploading five models**","b32c0108":"**We check that the number of rows in the table is reduced by the required number**","644e63ad":"# **0. Importing Libraries**","32638c01":"And now, using the example of the bird recognition task for 275 classes, I will show you how to implement the training of neural networks on a TPU","110f8a87":"**Making an Ensemble class**","740eebd3":"**Depending on which hardware accelerator you have selected, the corresponding libraries will be imported**","34d2a0ae":"**Let's look at the distribution of classes**","46406f8b":"![Boxplot-with-outliers-The-upper-and-lower-fences-represent-values-more-and-less-than.png](attachment:b84be10f-43b7-4fa0-9895-c6bd5324ca61.png)","bbf9fe8b":"# **4. Test**","28d9d58f":"![0_R9u16eEcsZHpjH4O_.png](attachment:ac728ac1-d71b-4d6d-bea0-36e1a2e5672c.png)","92372460":"![](https:\/\/habrastorage.org\/r\/w1560\/getpro\/habr\/post_images\/2d6\/bf4\/585\/2d6bf4585be28678f66652fd77ecb2f8.png)","2ca34772":"**This function gets the indexes for the pandas table and forms datasets from the corresponding objects. Then it wraps datasets in dataloaders depending on which accelerator you choose. It also gives out the length of datasets, that is, the number of objects in it in order to then calculate the accuracy and loss**","cc841e37":"# **2. Data preparation**","59f54b70":"**Here I use cross-validation for five folds on the combined validation and training parts**","4eb9e73c":"![](https:\/\/miro.medium.com\/max\/1070\/1*uR7-mfI6AE6cqGqG0rDE8w.png)","4ed7b243":"**This function will help us save the training process in a separate file, which we can download after training in the working folder**","43424c4d":"**A dictionary for storing some important hyperparameters**","c3249122":"![](https:\/\/habrastorage.org\/getpro\/habr\/post_images\/fbb\/bcb\/17b\/fbbbcb17b7732e20d2658d5e76023beb.gif)","c3f3f5bf":"![](https:\/\/habrastorage.org\/getpro\/habr\/post_images\/04a\/ef8\/b31\/04aef8b31b8eb550ba093df4eb811d58.gif)","d08d55c0":"![](https:\/\/habrastorage.org\/getpro\/habr\/post_images\/9ec\/de3\/fc6\/9ecde3fc6d69116db89aacd83bdf15e5.gif)","f8ab83cd":"**Tensor Processing Unit (TPU)** is an AI accelerator application-specific integrated circuit developed by Google specifically for neural network machine learning. It works in several major Google products, including Translate, Photos, Search Assistant and Gmail","df4419eb":"For example, we will consider a single-layer neural network for solving MNIST","8d96c47d":"**This is what birds with different classes look like**","a7143e8c":"Before comparing the GPU with the GPU, let's remember how the neural network works","ffcb9e96":"**For augmentation, I use my favorite library Albumentations. Also, the augmentations are divided into two parts, since we need to change the training part a lot, and the validation and test parts only slightly**","0f6cfd3e":"Therefore, the TPU demonstrates greater throughput when calculating for neural networks, consuming much less energy and taking up less space","e4fd71a6":"# **Why are TPUs so well suited for deep learning?**","0e9f3aac":"**If it will be useful, please upvote it**","1a98b78e":"Since I'm going to use cross-validation next, I decided to combine the validation part and the training part, for this we will change the paths in the csv file","bd8666a8":"But the GPU is still a general-purpose processor that must support a million different applications and software. And this brings us back to the fundamental problem of the bottleneck of the von Neumann architecture. For each calculation in thousands of APUs, the GPU needs to access registers or shared memory in order to read and save the intermediate results of calculations. Since the GPU performs more parallel calculations on thousands of its ALUs, it also spends proportionally more energy on accessing memory and occupies a larger area","d252eff3":"**Finding outliers**","cd85601a":"# **3. Training**","2dd48c0f":"Let's see how the pipeline array performs calculations for the neural network. First, the TPU loads the parameters from memory into the matrix of multipliers and adders:","f02efc78":"![](https:\/\/habrastorage.org\/getpro\/habr\/post_images\/020\/141\/559\/0201415596ab1132ba07a3b430a2fa34.gif)","9c82bf6e":"**Outlier Detection using Mean and Standard Deviation**","984b6777":"# **How the neural network calculates**","3d5f54ce":"**Next, we will process the outliers, for this we will normalize the data and determine the outliers by the standard deviation and the average**","7d21ab88":"Before comparing the GPU with the GPU, let's remember how the neural network works","45eeac05":"**We are testing our model on new data**","fe2f2800":"The task is to perform a large number of matrix multiplications as quickly as possible, spending as little energy as possible","0193c3c1":"**With this function, we will make predictions on the test data**","a586b872":"**Let's depict the outliers**","beb63470":"**Before starting the model, it is useful to remember the model configurations**","d5b29934":"# How the GPU works","6c72956a":"# How the TPU works","55084d1a":"**The function is very simple, although it looks scary. It does two things: it checks the configurator which accelerator we are using, and the second thing is that it checks the condition for whether the upper layers need to be frozen. I also added several optimizers that depend on the seed, because when the layers are frozen, the classifier is called differently for some networks (by default, freezing means the freezing of the classifier, if you need to freeze the network in your own way, you will have to rewrite the code a little). To be honest, this function made my life very much easier and now I don't have to constantly rewrite the code for TPU, which speeds up my experiments with the network**","6a4874e1":"**Here I have encoded the target values of the objects into numbers**","2987909a":"This neuron works as a filter and extracts the similarity of the input data with the number eight, the highest result indicates the best match of the entered data and the corresponding parameter, which is most likely to be the correct answer:","84241257":"**Own dataset for loading data, nothing out of the ordinary**","3d46f7c6":"**To carry out experiments and so that your results do not differ from mine, we will make our code more deterministic**","fe55e0d8":"# ***Thanks for reading to the end. I hope this was helpful. I posted this work because I want to show something new and get feedback if you changed something and it turned out better. I am always glad to hear recommendations for changing the code. Please support if this was helpful. Thanks again for your attention***","4cd9ab4f":"# **What is a TPU and what is the difference from a GPUs?**","189a9225":"If the MNIST image is a 28x28 matrix, then when converted to a vector, we will get 784 values (dimensions). The neuron responsible for the number 8 takes these values and multiplies them with its parameters (look at the red lines)","6551fca5":"The GPU has a large total bandwidth due to the use of a huge number of ALUs (a processor unit that, under the control of a control device, serves to perform arithmetic and logical transformations on data). A modern GPU contains about 2500-5000 ALUs on the processor, which makes it possible to perform thousands of multiplications and additions simultaneously","5f745aa9":"**Uploading test data**","bfbd0d6a":"**Removing outliers from the table and folders**","bdee49e5":"Let's look at the BoxPlot of each class","3b2c3cdc":"The TPU then loads the data from the memory. After performing each multiplication, the result is passed to the following multipliers, while performing additions at the same time. Therefore, the output will be the sum of all multiplications of data and parameters. During the entire process of bulk calculations and data transfer, access to memory is completely unnecessary:"}}