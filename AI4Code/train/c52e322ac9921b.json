{"cell_type":{"b69783b6":"code","47328891":"code","d2131968":"code","f77028cf":"code","a4873e48":"code","32734dc2":"code","46342f66":"code","00782a62":"code","b3349ae7":"code","88dcbb57":"code","3fd31a18":"code","c8cafca0":"code","f83cd51e":"code","9738b4da":"code","b351c337":"code","14caedd5":"code","cb15f870":"code","7c36b591":"code","460fd1a2":"code","7bf9b6b3":"code","74c406e3":"code","3d29bc18":"code","e1e51d12":"code","14566d07":"code","3e2333b2":"markdown","4f544c34":"markdown","cbe77845":"markdown","e2fa3cda":"markdown","156f93aa":"markdown","8d865616":"markdown","c32536c5":"markdown","0ee9845c":"markdown","fd839280":"markdown"},"source":{"b69783b6":"!pip install -q --upgrade pip\n!pip install -q tensorflow==2.2.0\n!git clone -q https:\/\/github.com\/thunderInfy\/imagenet-5-categories.git\n!pip install -q efficientnet","47328891":"!wget -q https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip -q ngrok-stable-linux-amd64.zip","d2131968":"import random\nimport math\nimport tqdm\nfrom datetime import datetime\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt","f77028cf":"import efficientnet.tfkeras as efn\nfrom sklearn.model_selection import train_test_split\nimport imgaug","a4873e48":"LOG_DIR = 'logs\/' \nget_ipython().system_raw('tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'.format(LOG_DIR))\nget_ipython().system_raw('.\/ngrok http 6006 &')\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","32734dc2":"image_size = 100\nbatch_size = 16","46342f66":"test_files = tf.io.gfile.glob('imagenet-5-categories\/test\/*.jpg')\ntrain_files = tf.io.gfile.glob('imagenet-5-categories\/train\/*.jpg')\ntrain_files, sub_train_files = train_test_split(train_files, test_size=150)","00782a62":"def random_brightness(image):\n    return tf.image.random_brightness(image, .4)\n\ndef random_contrast(image):\n    return tf.image.random_contrast(image, .3,1.7)\n\ndef random_saturation(image):\n    return tf.image.random_saturation(image, 0, 3)\n\ndef random_flip_left_right(image):\n    return tf.image.random_flip_left_right(image)\n\ndef random_crop(image):\n    a,b = tf.random.uniform((2,),image_size\/\/2,image_size,dtype=tf.int32)\n    image = tf.image.random_crop(image, [a,b,3])\n    return tf.image.resize(image,(image_size,image_size))\n\ndef random_hue(image):\n    return tf.image.random_hue(image, 0.05)\n\naugs_color = [random_brightness, random_contrast]\naugs_str = [random_flip_left_right, random_crop]\nonly_one_of = [random_saturation, random_hue]\n\ndef aug(image):\n    augs = augs_color + augs_str + [random.choice(only_one_of)]\n    random.shuffle(augs)\n    for i in augs:\n        image = i(image) \n    return image","b3349ae7":"class DataGeneratorSiam(tf.keras.utils.Sequence):\n    def __init__(self, data, batch_size):\n        self.data = data\n        self.batch_size = batch_size\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.data) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        pics = []\n        names = self.data[index*self.batch_size:(index+1)*self.batch_size]\n        for i in names:\n            pics.append(tf.image.resize(tf.io.decode_jpeg(tf.io.read_file(i)),(image_size,image_size)))\n        images = tf.stack(pics, 0)\/255.\n        return tf.map_fn(aug, images), tf.map_fn(aug, images)\n        \n    def on_epoch_end(self):\n        np.random.shuffle(self.data)\n\n\nclass DataGenerator(DataGeneratorSiam):\n    def __init__(self, data, batch_size, isaug=False):\n        self.data = data\n        self.batch_size = batch_size\n        self.isaug = isaug\n        self.on_epoch_end()\n        self.label_dict = {'airplane':0, 'car':1, 'cat':2, 'dog':3, 'elephant':4}\n\n    def __getitem__(self, index):\n        pics = []\n        names = self.data[index*self.batch_size:(index+1)*self.batch_size]\n        labels = [i.split('\/')[-1].split('_')[0] for i in names]\n        for i in names:\n            pics.append(tf.image.resize(tf.io.decode_jpeg(tf.io.read_file(i)),(image_size,image_size)))\n        images = tf.stack(pics, 0)\/255.\n        if self.isaug:\n            images = tf.map_fn(aug, images)\n        one_hot = tf.one_hot([self.label_dict[i]for i in labels], len(self.label_dict))\n        return images, one_hot","88dcbb57":"for x,y in DataGenerator(test_files, batch_size, False):\n    break\nN=math.ceil(math.sqrt(batch_size))\nplt.imshow(imgaug.draw_grid(np.array(x.numpy()*255, dtype='uint8'), cols=N, rows=N)); plt.show()","3fd31a18":"for i1, i2 in DataGeneratorSiam(train_files, batch_size):\n    break\nN=math.ceil(math.sqrt(batch_size))\nplt.imshow(imgaug.draw_grid(np.array(i1.numpy()*255, dtype='uint8'), cols=N, rows=N)); plt.show()\nplt.imshow(imgaug.draw_grid(np.array(i2.numpy()*255, dtype='uint8'), cols=N, rows=N)); plt.show()","c8cafca0":"inputs = tf.keras.Input(shape=(image_size,image_size,3))\nx = efn.EfficientNetB0(include_top=False, weights='imagenet')(inputs)\nvec = tf.keras.layers.GlobalMaxPool2D()(x)\n\ndi = tf.keras.layers.Dense(128,'sigmoid')(vec)\ncls_out = tf.keras.layers.Dense(5, activation='softmax')(di)\n\ncls_model = tf.keras.Model(inputs, cls_out)","f83cd51e":"logdir = \"logs\/baseline\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, write_graph=False)","9738b4da":"cls_model.compile(\n    optimizer=tf.keras.optimizers.Adam(0.00001),\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    metrics=tf.keras.metrics.CategoricalAccuracy())\n\nhistory = cls_model.fit(\n    DataGenerator(sub_train_files, batch_size, True),\n    epochs=200,\n    validation_data = DataGenerator(test_files, batch_size, False),\n    callbacks=[tensorboard_callback])","b351c337":"inputs = tf.keras.Input(shape=(image_size,image_size,3))\nx = efn.EfficientNetB0(include_top=False, weights='imagenet')(inputs)\nvec = tf.keras.layers.GlobalMaxPool2D()(x)\n\ndi = tf.keras.layers.Dense(128,'sigmoid')(vec)\nf_out = tf.keras.layers.Dense(64,'sigmoid')(di)\ncls_out = tf.keras.layers.Dense(5, activation='softmax')(di)\n\nf_model = tf.keras.Model(inputs, f_out)\ncls_model = tf.keras.Model(inputs, cls_out)","14caedd5":"tau = .5\n\ndef loss(a,b):\n    a_norm = tf.reshape(tf.norm(a,axis=1),(-1,1))\n    a_cap = tf.divide(a,a_norm)\n    b_norm = tf.reshape(tf.norm(b,axis=1),(-1,1))\n    b_cap = tf.divide(b,b_norm)\n\n    a_cap_b_cap = tf.concat([a_cap, b_cap], 0)\n    a_cap_b_cap_transpose = tf.transpose(a_cap_b_cap)\n    b_cap_a_cap = tf.concat([b_cap,a_cap], 0)\n\n    sim_by_tau = tf.matmul(a_cap_b_cap,a_cap_b_cap_transpose) \/ tau\n    exp_sim_by_tau = tf.exp(sim_by_tau)\n    sum_of_rows = tf.math.reduce_sum(exp_sim_by_tau, 1)\n    exp_sim_by_tau_diag = tf.linalg.diag_part(exp_sim_by_tau)\n\n    numerators = tf.exp(tf.divide(-tf.losses.cosine_similarity(a_cap_b_cap,b_cap_a_cap),tau))\n    denominators = sum_of_rows - exp_sim_by_tau_diag\n    \n    num_by_den = tf.divide(numerators,denominators)\n    neglog_num_by_den = -tf.math.log(num_by_den)\n    return tf.math.reduce_mean(neglog_num_by_den)","cb15f870":"logdir = 'logs\/contrastive_learning\/' +  datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nloss_steps_summary_writer = tf.summary.create_file_writer(logdir)","7c36b591":"datagen_siam = DataGeneratorSiam(train_files+sub_train_files, batch_size*8)\nglosses = []\noptimizer = tf.keras.optimizers.Adam(0.0001)\nfor epoch in tqdm.tqdm(range(200)):\n    losses = []\n    for x,y in datagen_siam:\n        with tf.GradientTape() as tape:\n            yhat1 = f_model(x, training=True)\n            yhat2 = f_model(y, training=True)\n            loss_value = loss(yhat1, yhat2)\n            losses.append(loss_value)\n        grads = tape.gradient(loss_value, f_model.trainable_weights)\n        optimizer.apply_gradients(zip(grads, f_model.trainable_weights))\n    with loss_steps_summary_writer.as_default():\n        tf.summary.scalar('loss', np.mean(losses), step=epoch)\n    glosses.append(np.mean(losses))","460fd1a2":"plt.plot(glosses); plt.show()","7bf9b6b3":"logdir = \"logs\/post_train\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, write_graph=False)","74c406e3":"cls_model.compile(\n    optimizer=tf.keras.optimizers.Adam(0.00001),\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    metrics=tf.keras.metrics.CategoricalAccuracy())\n\nhistory = cls_model.fit(\n    DataGenerator(sub_train_files, batch_size, True),\n    epochs=200,\n    initial_epoch=0,\n    validation_data = DataGenerator(test_files, batch_size, False),\n    callbacks=[tensorboard_callback])","3d29bc18":"inputs = tf.keras.Input(shape=(image_size,image_size,3))\nx = efn.EfficientNetB0(include_top=False, weights='imagenet')(inputs)\nvec = tf.keras.layers.GlobalMaxPool2D()(x)\n\ndi = tf.keras.layers.Dense(128,'sigmoid')(vec)\ncls_out = tf.keras.layers.Dense(5, activation='softmax')(di)\n\ncls_model = tf.keras.Model(inputs, cls_out)","e1e51d12":"logdir = \"logs\/supervised\/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, write_graph=False)","14566d07":"cls_model.compile(\n    optimizer=tf.keras.optimizers.Adam(0.00001),\n    loss=tf.keras.losses.CategoricalCrossentropy(),\n    metrics=tf.keras.metrics.CategoricalAccuracy())\n\nhistory = cls_model.fit(\n    DataGenerator(train_files+sub_train_files, batch_size, True),\n    epochs=200,\n    validation_data = DataGenerator(test_files, batch_size, False),\n    callbacks=[tensorboard_callback])","3e2333b2":"# Post Training","4f544c34":"# Inits; Download data, packages; Imports","cbe77845":"\u041f\u0440\u0438\u043c\u0435\u0440\u044b \u0434\u0430\u043d\u043d\u044b\u0445 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0438 \u0434\u043b\u044f \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f","e2fa3cda":"# Contrastive learning","156f93aa":"# Consts","8d865616":"# Fully supervised learning","c32536c5":"# Baseline","0ee9845c":"# Data pipeline","fd839280":"# Tensorboard"}}