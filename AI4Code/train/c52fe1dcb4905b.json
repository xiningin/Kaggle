{"cell_type":{"785c12e3":"code","0cd29064":"code","44cea031":"code","e8212e57":"code","301805a0":"code","3dbae7a8":"code","112c46dd":"code","1a3f5021":"code","5fdc52b8":"code","4b1db4dd":"code","71f62d81":"code","b4ea8a83":"code","08f27c00":"code","465fa14f":"code","e49bc2ed":"code","7ef74c1b":"code","66275d18":"code","fa0b06a7":"code","a4a9c1ef":"code","7bc9e01c":"code","ba28a67b":"code","b6eeefff":"code","11783840":"code","cdf42677":"code","a8c75eb1":"code","88b864b8":"code","7fd51bb1":"code","079a33c6":"code","70815ddc":"code","ce7b59ea":"code","d08aece6":"code","55dad2c9":"code","e809d3d1":"code","0afeadfc":"code","4f5eb324":"code","60f2826b":"code","b75e9f40":"code","2df1ffc7":"code","805a2f87":"code","05e830d8":"code","49506c83":"code","ca7287eb":"code","8d4a447d":"code","1838f5e3":"code","0ad82952":"code","d7e963e5":"code","160c7291":"code","140a6465":"code","acb8c193":"code","64bdd2d5":"code","b137d955":"code","7fd53076":"code","73312cb5":"code","bad62832":"code","f271c29a":"code","22ef5eac":"code","8b2c56dc":"code","5b19a961":"code","b7349c3a":"code","d909f3d3":"code","cbc317e1":"code","e0e733da":"code","a39622f0":"code","542d22b1":"code","9e87e747":"code","377d91c0":"code","87f381fc":"code","34292eff":"code","c9a41fdf":"code","13ac05b1":"code","b6f959a4":"code","fbdd9a64":"code","4c69b91b":"code","5808d6d9":"code","535d53d9":"code","88e796e4":"code","f1470720":"code","6dc5b83f":"code","d7bf8e6f":"code","38a85159":"code","32c29334":"code","e92e362d":"code","9af3bf32":"code","f0165411":"code","8baa7334":"code","9500aef2":"code","f42086f3":"code","2663b390":"code","829b54ea":"code","b407e667":"markdown","eeb8e81a":"markdown","f9acc523":"markdown","9ee6dfd3":"markdown","dc42410e":"markdown","b0aead44":"markdown","5655f3a9":"markdown","6ce5ea49":"markdown","33f2b37e":"markdown","c4411ea4":"markdown","445b3c9f":"markdown","96791d03":"markdown","5470c0f4":"markdown","de3b9dfd":"markdown","938088b0":"markdown","5127e328":"markdown","6d52c9cb":"markdown","4e802710":"markdown","cc90d3b9":"markdown","10807674":"markdown","64a73618":"markdown","0fcd4772":"markdown","223e3cbd":"markdown","8827913a":"markdown","155d4f93":"markdown","8c458daa":"markdown","23eac7bb":"markdown","ccea2e2e":"markdown","d1fc84a4":"markdown","3f2df5df":"markdown","a0f02a14":"markdown","ba53652b":"markdown","40b704a4":"markdown","fcbac27b":"markdown","2c648535":"markdown","098e40a6":"markdown","c5dfb928":"markdown","63f2ef19":"markdown","00e974b6":"markdown","5917ea25":"markdown","d5394737":"markdown","eee94331":"markdown","5e4ff8bb":"markdown","e063b456":"markdown","88384764":"markdown","af806439":"markdown","27fa1512":"markdown"},"source":{"785c12e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt #visualize\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns #visualize\n\nfrom collections import Counter\n\nimport warnings # don't show warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0cd29064":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","44cea031":"#The Columns\ntrain_df.columns","e8212e57":"train_df.head()","301805a0":"train_df.describe()","3dbae7a8":"train_df.info()","112c46dd":"def bar_plot(variable):\n    \"\"\"\n    input : variable ex : \"Sex\"\n    output : bar plot & value count  \n    \"\"\"\n    # get feature\n    var = train_df[variable]\n    #count number of categorical variable (value\/sample)\n    varValue = var.value_counts()\n\n    #visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue,color = \"green\", edgecolor = \"black\", linewidth = 2)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))\n    \n    \n    \n    ","1a3f5021":"category1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\",\"Parch\"]\nfor c in category1:\n    bar_plot(c)","5fdc52b8":"category2 = [\"Cabin\",\"Name\",\"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_df[c].value_counts()))","4b1db4dd":"def plot_hist(variable):\n    plt.figure(figsize=(9,3))\n    plt.hist(train_df[variable])\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist \".format(variable))\n    plt.show()\n    ","71f62d81":"numericVar = [\"Fare\",\"Age\",\"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","b4ea8a83":"# Pclass - Survived\ntrain_df[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index = False).mean().sort_values(by = \"Survived\",ascending = False)","08f27c00":"# Sex - Survived\ntrain_df[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by = \"Sex\",ascending = False)","465fa14f":"# SibSp - Survived\ntrain_df[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by = \"SibSp\",ascending = False)","e49bc2ed":"# Parch - Survived\ntrain_df[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by = \"Parch\",ascending = False)","7ef74c1b":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3st quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier Step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces \n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2) \n    \n    return multiple_outliers","66275d18":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","fa0b06a7":"train_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\"]),axis = 0).reset_index(drop=True)","a4a9c1ef":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df,test_df],axis = 0).reset_index(drop = True)","7bc9e01c":"train_df.head()","ba28a67b":"train_df.columns[train_df.isnull().any()]","b6eeefff":"train_df.isnull().sum()","11783840":"train_df[train_df[\"Embarked\"].isnull()]","cdf42677":"train_df.boxplot(column=\"Fare\", by = \"Embarked\")\nplt.show()","a8c75eb1":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")\ntrain_df[train_df[\"Embarked\"].isnull()]","88b864b8":"train_df[train_df[\"Fare\"].isnull()]","7fd51bb1":"np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"])","079a33c6":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"])) \ntrain_df[train_df[\"Fare\"].isnull()]","70815ddc":"# Fare 13.30 (fill mean)\ntrain_df[train_df[\"PassengerId\"] == 1044]","ce7b59ea":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")\nplt.show()","d08aece6":"g = sns.factorplot(x = \"SibSp\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","55dad2c9":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", kind = \"bar\", data = train_df, size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","e809d3d1":"g = sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()\n","0afeadfc":"g = sns.FacetGrid(train_df, col = \"Survived\")\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","4f5eb324":"g = sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 2)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()","60f2826b":"\ng = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","b75e9f40":"g = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 2.3)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()","2df1ffc7":"train_df[train_df[\"Age\"].isnull()]","805a2f87":"sns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","05e830d8":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\",data = train_df, kind = \"box\")\nplt.show()","49506c83":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","ca7287eb":"\n#train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","8d4a447d":"sns.heatmap(train_df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\nplt.show()","1838f5e3":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","0ad82952":"train_df[train_df[\"Age\"].isnull()]","d7e963e5":"train_df[\"Name\"].head(10)","160c7291":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","140a6465":"train_df[\"Title\"].head(10)","acb8c193":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","64bdd2d5":"# convert to categorical\ntrain_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)","b137d955":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","7fd53076":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","73312cb5":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","bad62832":"train_df.head()","f271c29a":"train_df = pd.get_dummies(train_df,columns=[\"Title\"])\ntrain_df.head()","22ef5eac":"train_df.head()","8b2c56dc":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1","5b19a961":"train_df.head()","b7349c3a":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","d909f3d3":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]]","cbc317e1":"train_df.head(10)","e0e733da":"sns.countplot(x = \"family_size\", data = train_df)\nplt.show()","a39622f0":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","542d22b1":"train_df = pd.get_dummies(train_df, columns= [\"family_size\"])\ntrain_df.head()","9e87e747":"train_df[\"Embarked\"].head()","377d91c0":"sns.countplot(x = \"Embarked\", data = train_df)\nplt.show()","87f381fc":"train_df = pd.get_dummies(train_df, columns=[\"Embarked\"])\ntrain_df.head()","34292eff":"train_df[\"Ticket\"].head(20)","c9a41fdf":"a = \"A\/5. 2151\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]","13ac05b1":"tickets = []\nfor i in list(train_df.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets","b6f959a4":"train_df[\"Ticket\"].head(20)","fbdd9a64":"train_df.head()","4c69b91b":"train_df = pd.get_dummies(train_df, columns= [\"Ticket\"], prefix = \"T\")\ntrain_df.head(10)","5808d6d9":"sns.countplot(x = \"Pclass\", data = train_df)\nplt.show()","535d53d9":"train_df[\"Pclass\"] = train_df[\"Pclass\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns= [\"Pclass\"])\ntrain_df.head()","88e796e4":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns=[\"Sex\"])\ntrain_df.head()","f1470720":"train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)","6dc5b83f":"train_df.columns","d7bf8e6f":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","38a85159":"train_df_len","32c29334":"test = train_df[train_df_len:]\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)","e92e362d":"test.head()","9af3bf32":"train = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","f0165411":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2) \nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","8baa7334":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","9500aef2":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","f42086f3":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","2663b390":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","829b54ea":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","b407e667":" <a id = \"4\"><\/a>\n### Categorical Variable","eeb8e81a":"\nAge is not correlated with sex but it is correlated with parch, sibsp and pclass.","f9acc523":"<a id = \"15\"><\/a>\n### Pclass -- Survived","9ee6dfd3":" <a id = \"7\"><\/a>\n## Outlier Detection","dc42410e":"* float64(2) : Fare and Age\n* int64(5) : Pclass, sibsp, parch, passengerId and survived\n* object(5) : Cabin, embarked, ticket, name and sex","b0aead44":"<a id = \"27\"><\/a><br>\n### Sex","5655f3a9":"pclass is important feature for model training.","6ce5ea49":"Fare feature seems to have correlation with survived feature (0.26).","33f2b37e":"<a id = \"26\"><\/a><br>\n### Pclass","c4411ea4":"<a id = \"22\"><\/a>\n### Name -- Title","445b3c9f":"Sex is not informative for age prediction, age distribution seems to be same.","96791d03":"* age <= 10 has a high survival rate,\n* oldest passengers (80) survived,\n* large number of 20 years old did not survive,\n* most passengers are in 15-35 age range,\n* use age feature in training\n* use age distribution for missing value of age","5470c0f4":"<a id = \"16\"><\/a>\n### Age -- Survived","de3b9dfd":"<a id = \"10\"><\/a>\n## Fill Missing Value\n* Embarked has 2 missing value\n* Fare has only 1","938088b0":"<a id = \"13\"><\/a>\n### SibSp -- Survived","5127e328":"<a id = \"2\"><\/a>\n## Variable Description\n\n1. PassengerId : unique id number to each passenger\n2. Survived : passenger survive(1) or died(0) \n3. Pclass : passenger class\n4. Name : name of passenger\n5. Sex : gender of passenger\n6. Age : age of passenger\n7. SibSp : number of siblings\/spouses\n8. Parch : number of parents\/children\n9. Ticket : ticket number\n10. Fare : amount of money spent on ticket \n11. Cabin : cabin category \n12. Embarked : port where passenger embarked (C = Cherbourg, Q = Queenstown, S = Southampton)\n      ","6d52c9cb":"* Small familes have more chance to survive than large families.","4e802710":"<a id = \"29\"><\/a><br>\n# Modeling","cc90d3b9":"<a id = \"24\"><\/a><br>\n### Embarked","10807674":"<a id = \"1\"><\/a>\n## Load and Check Data","64a73618":"* Female passengers have much better survival rate than males.\n* males have better surv\u015fval rate in pclass 3 in C.\n* embarked and sex will be used in training.","0fcd4772":"<a id = \"34\"><\/a><br>\n## Prediction and Submission","223e3cbd":"<a id = \"11\"><\/a>\n## Visualization","8827913a":"<a id = \"25\"><\/a><br>\n### Ticket","155d4f93":" <a id = \"3\"><\/a>\n ## Univariate Variable Analysis\n   * Categorical Variable : Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp and Parch\n   * Numerical Variable : Fare, age and passengerId","8c458daa":" <a id = \"6\"><\/a>\n## Basic Data Analysis\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","23eac7bb":"<a id = \"8\"><\/a>\n## Missing Value\n* Find Missing Value\n* Fill Missing Value","ccea2e2e":"<a id = \"19\"><\/a>\n### Embarked -- Sex -- Fare -- Survived","d1fc84a4":"# **Introduction**\n   ***The sinking of Titanic is one the most notorious shipwredcks in the history , \n   In 1912, during her voyage, the titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.***\n \n<font color = 'blue'\/>  \n  ## Content :\n    \n1. [Load and Check Data](#1)\n2. [Variable Description](#2)  \n   * [Univariate Variable Analysis](#3)    \n     * [Categorical Variable ](#4)\n     * [Numerical Variable ](#5)\n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n6. [Visualization](#11)\n    * [Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    * [SibSp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Survived -- Age](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill Missing: Age Feature](#20)\n7. [Feature Engineering](#21)\n    * [Name -- Title](#22)\n    * [Family Size](#23)\n    * [Embarked](24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Drop Passenger ID and Cabin](#28)\n8. [Modeling](#29)\n    * [Train - Test Split](#30)\n    * [Simple Logistic Regression](#31)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n    * [Ensemble Modeling](#33)\n    * [Prediction and Submission](#34)\n","3f2df5df":"<a id = \"14\"><\/a>\n### Parch -- Survived","a0f02a14":"* Having a lot of SibSp have less chance to survive.\n* if sibsp == 0 or 1 or 2, passenger has more chance to survive\n* we can consider a new feature describing these categories.","ba53652b":"<a id = \"5\"><\/a>\n### Numerical Variable","40b704a4":"<a id = \"9\"><\/a>\n## Find Missing Value","fcbac27b":"<a id = \"21\"><\/a>\n# Feature Engineering\n","2c648535":"* Sibsp and parch can be used for new feature extraction with th = 3\n* small familes have more chance to survive.\n* there is a std in survival of passenger with parch = 3","098e40a6":"\n1st class passengers are older than 2nd, and 2nd is older than 3rd class.","c5dfb928":"<a id = \"20\"><\/a>\n### Fill Missing: Age Feature","63f2ef19":"<a id = \"33\"><\/a><br>\n## Ensemble Modeling","00e974b6":"Passsengers who pay higher fare have better survival. Fare can be used as categorical for training.","5917ea25":"<a id = \"30\"><\/a><br>\n## Train - Test Split","d5394737":"<a id = \"17\"><\/a>\n### Pclass -- Survived -- Age","eee94331":"<a id = \"12\"><\/a>\n### Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived","5e4ff8bb":"<a id = \"31\"><\/a><br>\n## Simple Logistic Regression","e063b456":"<a id = \"23\"><\/a><br>\n### Family Size","88384764":"<a id = \"18\"><\/a>\n### Embarked -- Sex -- Pclass -- Survived","af806439":"<a id = \"32\"><\/a><br>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\nWe will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","27fa1512":"<a id = \"28\"><\/a><br>\n### Drop Passenger ID and Cabin "}}