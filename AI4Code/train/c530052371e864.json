{"cell_type":{"e9cea110":"code","db5dad96":"code","3720e590":"code","f9b7dc26":"code","ab31f9b0":"code","7007b7f7":"code","e77b1556":"code","2e769c46":"code","29768bbd":"code","a6be504a":"code","fa0f4b8d":"code","e79f9a84":"markdown","cacd541c":"markdown"},"source":{"e9cea110":"import sys #system\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib #graph plotting\nimport scipy as sp #scientific calculation\nimport sklearn #machine learning models\nimport xgboost as xgb # for xgBoost learning model\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\nimport matplotlib.pyplot as plt #visualization\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore') #ignore warnings\n\nimport os\nprint(os.listdir(\"..\/input\")) #show stuffs under input\n# Any results you write to the current directory are saved as output.","db5dad96":"#time to read the data first\nraw_data_train = pd.read_csv('..\/input\/train.csv')\nraw_data_test = pd.read_csv('..\/input\/test.csv')\nraw_data = [raw_data_train,raw_data_test]\ndef print_info():\n    print(raw_data_train.info()) #to show datas info\n    print('-'*30)\n    print(raw_data_test.info())\n    print('-'*30)\nprint_info()\nraw_data_train.describe(include = 'all')","3720e590":"#data cleaning - Correcting, completing, creating, and converting\n#correcting = correct wrong values and outlier\n\n#completing = complete NaN datas\n#fill all the nan datas\nfor data in raw_data:\n    data['Age'].fillna(data['Age'].mean(), inplace = True) #fill age with mean\n    data['Embarked'].fillna(data['Embarked'].mode()[0],inplace = True) #fill embarked with the mode as no number,[0] is impt\n    data['Fare'].fillna(data['Fare'].median(),inplace = True) #fill fare with median\n#drop cabin feature as too many unknown from training dataset (test dataset remains same as no effect result)\nraw_data_train.drop(['PassengerId','Cabin','Ticket','Name'],axis = 1,inplace=True) #if inplace=false means not replacing original data\nprint_info()","f9b7dc26":"#Creating - create new features for analysis\nfor data in raw_data:\n    data['FamilySize'] = data['Parch'] + data['SibSp'] + 1\n    data['Alone'] = 1 #alone = 1, not alone = 0\n    data['Alone'].loc[data['FamilySize'] > 1] = 0   \n    data['FareBin'] = pd.qcut(data['Fare'], 5) #seperate fare into 5 classes\n    data['AgeBin'] = pd.cut(data['Age'].astype(int),5) #seperate age into 5 classes\nprint_info()","ab31f9b0":"#converting - to require data\n#convert string data (categoricaEl) to int data through Label encoder\nle = LabelEncoder()\nfor data in raw_data:\n    data['SexCode'] = le.fit_transform(data['Sex'])\n    data['EmbarkedCode'] = le.fit_transform(data['Embarked'])\n    data['AgeBinCode'] = le.fit_transform(data['AgeBin'])\n    data['FareBinCode'] = le.fit_transform(data['FareBin'])\nprint_info()","7007b7f7":"#Split training datas to train and validation set\ndata_bin = ['Pclass','SexCode','AgeBinCode','FamilySize','FareBinCode','EmbarkedCode','Alone']\nprediction = ['Survived']\nx_train,x_val,y_train,y_val = train_test_split(raw_data_train[data_bin],raw_data_train[prediction],\n                                               test_size = 0.25,random_state = 42)\nx_train.head()","e77b1556":"#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heatmap(raw_data_train)","2e769c46":"#seaborn graphics for multi-variable comparison: https:\/\/seaborn.pydata.org\/api.html\n#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'EmbarkedCode', y = 'Survived', data=raw_data_train, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived', order=[1,2,3], data=raw_data_train, ax = saxis[0,1])\nsns.barplot(x = 'Alone', y = 'Survived', order=[1,0], data=raw_data_train, ax = saxis[0,2])\n\nsns.pointplot(x = 'FareBin', y = 'Survived',  data=raw_data_train, ax = saxis[1,0])\nsns.barplot(x = 'AgeBinCode', y = 'Survived',  data=raw_data_train, ax = saxis[1,1])\nsns.barplot(x = 'FamilySize', y = 'Survived', data=raw_data_train, ax = saxis[1,2])","29768bbd":"XGBmodel = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(x_train, y_train)\nXGBmodel.fit(x_train,y_train)\npred = XGBmodel.predict(x_val)","a6be504a":"accuracy = accuracy_score(y_val, pred)\nprint(accuracy) #validation accuracy","fa0f4b8d":"#predict the test score\nraw_data_test['Survived'] = XGBmodel.predict(raw_data_test[data_bin]) #create new column called survive on test.csv\nsubmit = raw_data_test[['PassengerId','Survived']] #submit only passengerId and survived column\nsubmit.to_csv(\"..\/working\/submit.csv\", index=False)","e79f9a84":"This is my first time practicing for a supervised learning problem completely, many codes is reference from other kernels ","cacd541c":"**Jack should be dying or Rose?!** "}}