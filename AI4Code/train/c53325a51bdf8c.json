{"cell_type":{"90ba1166":"code","c8b1b9de":"code","1b970678":"code","13e55e48":"code","44a6d571":"code","b9fc0ac0":"code","4c70ffa4":"code","881686bb":"code","b1438cda":"code","1809f1ec":"code","c97c7eb0":"code","5fd33718":"code","4b396ef5":"code","511bb906":"code","0018b3ab":"code","1057e336":"code","c0a57394":"code","f22723bc":"code","c4b6822a":"code","e2b3af0c":"code","87e8f1d1":"code","087fb75f":"code","d3b9f665":"code","b6c6e062":"code","17e94353":"code","b4abfe82":"code","3e7b3cca":"code","05930ea2":"code","eeb5fc62":"code","7a3a0c72":"code","a9e86d9b":"code","0931a0cb":"code","3cf28cd3":"code","98591a47":"code","51d1b8b0":"markdown","ccc3da07":"markdown","e3e15a31":"markdown","017b7b9c":"markdown","c897f469":"markdown","c378358a":"markdown","4870b61c":"markdown","fdd72823":"markdown","9e352a24":"markdown","b7a6f66f":"markdown","9ab59734":"markdown","c705267e":"markdown","e1383a0f":"markdown","edad8f42":"markdown","91f8d448":"markdown","a883016f":"markdown","26cf1639":"markdown","24a8b021":"markdown","9aa84fa2":"markdown","244d6ec4":"markdown","7322fe49":"markdown","7b701fe5":"markdown","75007b6a":"markdown","4e327984":"markdown","cf953519":"markdown","898cec14":"markdown","5f0a288a":"markdown","cdc9f792":"markdown","025e29c9":"markdown","b8984ab5":"markdown","23d49cb8":"markdown","87b78812":"markdown","09fe9f31":"markdown","18022274":"markdown","9e262f99":"markdown","9ac867b3":"markdown","c5bc3ce0":"markdown","aa76fd64":"markdown","cb961169":"markdown","04a37e4e":"markdown","c1c36b00":"markdown"},"source":{"90ba1166":"# Basic libraries\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Directry check\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c8b1b9de":"!pip install factor_analyzer","1b970678":"# Statistics library\nfrom scipy.stats import norm\nfrom scipy import stats\nimport scipy\n\n# Data preprocessing\nimport datetime\nimport re\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Visualization\nfrom matplotlib import pyplot as plt\nplt.style.use('fivethirtyeight')\nimport seaborn as sns\n\n# Dimension reduction\nfrom factor_analyzer import FactorAnalyzer\nfrom sklearn.manifold import Isomap\nfrom sklearn.manifold import TSNE\nfrom sklearn import cluster","13e55e48":"df_train = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")","44a6d571":"# data size\nprint(\"train data size:{}\".format(df_train.shape))\nprint(\"test data size:{}\".format(df_test.shape))","b9fc0ac0":"# data info\nprint(\"*\"*50)\nprint(\"train data information\")\nprint(df_train.info())","4c70ffa4":"# summery\ndf_train.describe()","881686bb":"# Distribution\nfig, ax = plt.subplots(1,2,figsize=(20,6))\nsns.distplot(df_train[\"SalePrice\"], ax=ax[0])\nax[0].set_xlabel(\"SalePrice\")\nax[0].set_ylabel(\"count(normalized)\")\nax[0].set_title(\"SalePrice distribution\")\n\n# Probability  plot\nstats.probplot(df_train['SalePrice'], plot=ax[1])","b1438cda":"# define function\n# quantile_list\ndef quantile(data):\n    quat_list = []\n    for i in range(0,9):\n        quat = data.quantile((i+1)*0.1)\n        quat_list.append(quat)\n    return quat_list\n\n# decyl flag\ndef decyl(x):\n    if x[\"SalePrice\"] < quat_list[0]:\n        res = 10\n    elif x[\"SalePrice\"] < quat_list[1] and x[\"SalePrice\"] >= quat_list[0]:\n        res = 9\n    elif x[\"SalePrice\"] < quat_list[2] and x[\"SalePrice\"] >= quat_list[1]:\n        res = 8\n    elif x[\"SalePrice\"] < quat_list[3] and x[\"SalePrice\"] >= quat_list[2]:\n        res = 7\n    elif x[\"SalePrice\"] < quat_list[4] and x[\"SalePrice\"] >= quat_list[3]:\n        res = 6\n    elif x[\"SalePrice\"] < quat_list[5] and x[\"SalePrice\"] >= quat_list[4]:\n        res = 5\n    elif x[\"SalePrice\"] < quat_list[6] and x[\"SalePrice\"] >= quat_list[5]:\n        res = 4\n    elif x[\"SalePrice\"] < quat_list[7] and x[\"SalePrice\"] >= quat_list[6]:\n        res = 3\n    elif x[\"SalePrice\"] < quat_list[8] and x[\"SalePrice\"] >= quat_list[7]:\n        res = 2\n    else:\n        res = 1\n    return res\n\n# quat_list\nquat_list = quantile(df_train[\"SalePrice\"])\n# decyl\ndf_train[\"decyl\"] = df_train.apply(decyl, axis=1)","1809f1ec":"# decyl data frame\ndecyl_df = pd.DataFrame(data=df_train.groupby(\"decyl\").SalePrice.sum()).reset_index().sort_values(by=\"SalePrice\", ascending=False)\n\n# Ratio\ndecyl_df[\"ratio\"] = decyl_df[\"SalePrice\"] \/ decyl_df[\"SalePrice\"].sum()\ndecyl_df[\"ratio_cumsum\"] = decyl_df[\"ratio\"].cumsum()*100\n\n# Price band\nprice_band = pd.DataFrame({})\nlist_min = [df_train[\"SalePrice\"].min()]\nlist_max = []\n\nfor i in range(0,9):\n    quat = df_train[\"SalePrice\"].quantile((i+1)*0.1)\n    list_min.append(quat)\n    list_max.append(quat)\nlist_max.append(df_train[\"SalePrice\"].max())\n\ndecyl_df[\"min\"] = sorted(list_min, reverse=True)\ndecyl_df[\"max\"] = sorted(list_max, reverse=True)\n\ndecyl_df.head(10)","c97c7eb0":"# Visualization decyl analysis\nplt.figure(figsize=(10,6))\nplt.bar(decyl_df[\"decyl\"], decyl_df[\"max\"]\/1000-decyl_df[\"min\"]\/1000, bottom=decyl_df[\"min\"]\/1000, color=\"green\")\nplt.xlabel(\"decyl\")\nplt.xticks(range(1,11))\nplt.ylabel(\"Price band(K)\")\nplt.yticks([0,200,400,600,800])","5fd33718":"# Visualization decyl analysis\ndef barcumsum(x1, x2, y1, y2):\n    fig, ax1 = plt.subplots(figsize=(10,6))\n    ax1.bar(x1,y1, color=\"blue\", label='Sale Price')\n    ax1.set_xticks(range(1,11))\n    ax1.set_ylim([0,60])\n    ax1.grid()\n    ax1.set_ylabel(\"Sale Price sum(M)\")\n    plt.legend(loc=\"upper left\")\n    ax2 = ax1.twinx()\n    ax2.set_ylim([0, 110])\n    ax2.set_ylabel(\"Ratio(%)\")\n    ax2.plot(x2,y2, color=\"red\", label=\"Ratio\", marker='o')\n    ax1.set_xlabel(\"decyl\")\n    plt.legend(loc=\"upper right\")\n    \n    \nx1 = decyl_df[\"decyl\"]\nx2 = decyl_df[\"decyl\"]\ny1 = decyl_df[\"SalePrice\"]\/1000000\ny2 = decyl_df[\"ratio_cumsum\"]\nbarcumsum(x1, x2, y1, y2)","4b396ef5":"# R:year, M:Sale Price\nRM_pivot = pd.pivot_table(df_train, index=\"decyl\", columns=\"YrSold\", values=\"SalePrice\", aggfunc=\"sum\").sort_index(by=\"decyl\")\n# color palette \ncm = sns.light_palette(\"red\", as_cmap=True)\nRM_pivot.style.background_gradient(cmap=cm)","511bb906":"# dtype object\ndtype = pd.DataFrame({\"columns\":df_train.dtypes.index,\n                     \"dtype\":df_train.dtypes})\ndtype[\"dtype\"] = [str(i) for i in dtype[\"dtype\"]]\ndtype","0018b3ab":"# columns\nnum_columns = dtype.query('dtype==\"int64\" | dtype==\"float64\"')[\"columns\"].values[1:-1]\nobj_columns = dtype.query('dtype==\"object\"')[\"columns\"].values\n\nprint(\"numerical_values_count:{}\".format(len(num_columns)))\nprint(\"object_values_count:{}\".format(len(obj_columns)))","1057e336":"# correlation\nmatrix = df_train[num_columns].fillna(0) # tempolary fill na =0\n\nplt.figure(figsize=(16,16))\nhm = sns.heatmap(matrix.corr(), vmax=1, vmin=-1, cmap=\"bwr\", square=True)","c0a57394":"fig, ax = plt.subplots(1,3,figsize=(20,6))\n\nax[0].scatter(df_train[\"TotalBsmtSF\"], df_train[\"1stFlrSF\"], color=\"pink\")\nax[0].set_xlabel(\"TotalBsmtSF\")\nax[0].set_ylabel(\"1stFlrSF\")\n\nax[1].scatter(df_train[\"GrLivArea\"], df_train[\"TotRmsAbvGrd\"], color=\"pink\")\nax[1].set_xlabel(\"GrLivArea\")\nax[1].set_ylabel(\"TotRmsAbvGrd\")\n\nax[2].scatter(df_train[\"GarageCars\"], df_train[\"GarageArea\"], color=\"pink\")\nax[2].set_xlabel(\"GarageCars\")\nax[2].set_ylabel(\"GarageArea\")","f22723bc":"# Correlation coefficient\ncoef = matrix.corr().iloc[36,:].round(3)\n\n# skewness\nskew = []\nfor i in range(df_train[num_columns].shape[1]):\n    median = df_train[num_columns].iloc[:,i].median()\n    s = scipy.stats.skew(df_train[num_columns].iloc[:,i].fillna(median))\n    skew.append(s)\n\n# kurtosis\nkurt = []\nfor i in range(df_train[num_columns].shape[1]):\n    median = df_train[num_columns].iloc[:,i].median()\n    s = scipy.stats.kurtosis(df_train[num_columns].iloc[:,i].fillna(median))\n    kurt.append(s)\n\n\nske_kur = pd.DataFrame(skew, index=df_train[num_columns].columns, columns=[\"skew\"])\nske_kur[\"kurt\"] = kurt\n\nskew = ske_kur[\"skew\"].values.round(2)\nkurt = ske_kur[\"kurt\"].values.round(2)","c4b6822a":"fig, ax = plt.subplots(18,4, figsize=(25,100))\nplt.subplots_adjust(hspace=0.3, wspace=0.3)\nfor i in range(0,36):\n    if i < 4:\n        ax[0,i].scatter(df_train[num_columns].iloc[:,i], df_train[\"SalePrice\"], color=\"red\")\n        ax[0,i].set_title(\"{}\".format(df_train[num_columns].columns[i] + \" :R\" + str(coef[i])))\n        ax[0,i].set_ylabel(\"SalePrice\")\n        ax[0,i].set_xlabel(\"{}\".format(df_train[num_columns].columns[i]))\n        sns.distplot(df_train[num_columns].iloc[:,i], ax=ax[1,i], kde=False, color=\"red\")\n        ax[1,i].set_title(\"{}\".format(\"skew:\"+ str(skew[i]) + \"\/\" + \"kurt:\" + str(kurt[i])))\n        ax[1,i].set_ylabel(\"Count\")\n        \n    elif i >= 4 and i < 8:\n        ax[2,i-4].scatter(df_train[num_columns].iloc[:,i], df_train[\"SalePrice\"], color=\"blue\")\n        ax[2,i-4].set_title(\"{}\".format(df_train[num_columns].columns[i] + \" :R\" + str(coef[i])))\n        ax[2,i-4].set_ylabel(\"SalePrice\")\n        ax[2,i-4].set_xlabel(\"{}\".format(df_train[num_columns].columns[i]))\n        sns.distplot(df_train[num_columns].iloc[:,i], ax=ax[3,i-4], kde=False, color=\"blue\")\n        ax[3,i-4].set_title(\"{}\".format(\"skew:\"+ str(skew[i]) + \"\/\" + \"kurt:\" + str(kurt[i])))\n        ax[3,i-4].set_ylabel(\"Count\")\n        \n    elif i >= 8 and i < 12:\n        ax[4,i-8].scatter(df_train[num_columns].iloc[:,i], df_train[\"SalePrice\"], color=\"green\")\n        ax[4,i-8].set_title(\"{}\".format(df_train[num_columns].columns[i] + \" :R\" + str(coef[i])))\n        ax[4,i-8].set_ylabel(\"SalePrice\")\n        ax[4,i-8].set_xlabel(\"{}\".format(df_train[num_columns].columns[i]))\n        sns.distplot(df_train[num_columns].iloc[:,i], ax=ax[5,i-8], kde=False, color=\"green\")\n        ax[5,i-8].set_title(\"{}\".format(\"skew:\"+ str(skew[i]) + \"\/\" + \"kurt:\" + str(kurt[i])))\n        ax[5,i-8].set_ylabel(\"Count\")\n        \n    elif i >= 12 and i < 16:\n        ax[6,i-12].scatter(df_train[num_columns].iloc[:,i], df_train[\"SalePrice\"], color=\"pink\")\n        ax[6,i-12].set_title(\"{}\".format(df_train[num_columns].columns[i] + \" :R\" + str(coef[i])))\n        ax[6,i-12].set_ylabel(\"SalePrice\")\n        ax[6,i-12].set_xlabel(\"{}\".format(df_train[num_columns].columns[i]))\n        sns.distplot(df_train[num_columns].iloc[:,i], ax=ax[7,i-12], kde=False, color=\"pink\")\n        ax[7,i-12].set_title(\"{}\".format(\"skew:\"+ str(skew[i]) + \"\/\" + \"kurt:\" + str(kurt[i])))\n        ax[7,i-12].set_ylabel(\"Count\")\n        \n    elif i >= 16 and i < 20:\n        ax[8,i-16].scatter(df_train[num_columns].iloc[:,i], df_train[\"SalePrice\"], color=\"orange\")\n        ax[8,i-16].set_title(\"{}\".format(df_train[num_columns].columns[i] + \" :R\" + str(coef[i])))\n        ax[8,i-16].set_ylabel(\"SalePrice\")\n        ax[8,i-16].set_xlabel(\"{}\".format(df_train[num_columns].columns[i]))\n        sns.distplot(df_train[num_columns].iloc[:,i], ax=ax[9,i-16], kde=False, color=\"orange\")\n        ax[9,i-16].set_title(\"{}\".format(\"skew:\"+ str(skew[i]) + \"\/\" + \"kurt:\" + str(kurt[i])))\n        ax[9,i-16].set_ylabel(\"Count\")\n        \n    elif i >= 20 and i < 24:\n        ax[10,i-20].scatter(df_train[num_columns].iloc[:,i], df_train[\"SalePrice\"], color=\"purple\")\n        ax[10,i-20].set_title(\"{}\".format(df_train[num_columns].columns[i] + \" :R\" + str(coef[i])))\n        ax[10,i-20].set_ylabel(\"SalePrice\")\n        ax[10,i-20].set_xlabel(\"{}\".format(df_train[num_columns].columns[i]))\n        sns.distplot(df_train[num_columns].iloc[:,i], ax=ax[11,i-20], kde=False, color=\"purple\")\n        ax[11,i-20].set_title(\"{}\".format(\"skew:\"+ str(skew[i]) + \"\/\" + \"kurt:\" + str(kurt[i])))\n        ax[11,i-20].set_ylabel(\"Count\")\n        \n    elif i >= 24 and i < 28:\n        ax[12,i-24].scatter(df_train[num_columns].iloc[:,i], df_train[\"SalePrice\"], color=\"sienna\")\n        ax[12,i-24].set_title(\"{}\".format(df_train[num_columns].columns[i] + \" :R\" + str(coef[i])))\n        ax[12,i-24].set_ylabel(\"SalePrice\")\n        ax[12,i-24].set_xlabel(\"{}\".format(df_train[num_columns].columns[i]))\n        sns.distplot(df_train[num_columns].iloc[:,i], ax=ax[13,i-24], kde=False, color=\"sienna\")\n        ax[13,i-24].set_title(\"{}\".format(\"skew:\"+ str(skew[i]) + \"\/\" + \"kurt:\" + str(kurt[i])))\n        ax[13,i-24].set_ylabel(\"Count\")\n        \n    elif i >= 28 and i < 32:\n        ax[14,i-28].scatter(df_train[num_columns].iloc[:,i], df_train[\"SalePrice\"], color=\"cyan\")\n        ax[14,i-28].set_title(\"{}\".format(df_train[num_columns].columns[i] + \" :R\" + str(coef[i])))\n        ax[14,i-28].set_ylabel(\"SalePrice\")\n        ax[14,i-28].set_xlabel(\"{}\".format(df_train[num_columns].columns[i]))\n        sns.distplot(df_train[num_columns].iloc[:,i], ax=ax[15,i-28], kde=False, color=\"cyan\")\n        ax[15,i-28].set_title(\"{}\".format(\"skew:\"+ str(skew[i]) + \"\/\" + \"kurt:\" + str(kurt[i])))\n        ax[15,i-28].set_ylabel(\"Count\")\n        \n    else:\n        ax[16,i-32].scatter(df_train[num_columns].iloc[:,i], df_train[\"SalePrice\"], color=\"gray\")\n        ax[16,i-32].set_title(\"{}\".format(df_train[num_columns].columns[i] + \" :R\" + str(coef[i])))\n        ax[16,i-32].set_ylabel(\"SalePrice\")\n        ax[16,i-32].set_xlabel(\"{}\".format(df_train[num_columns].columns[i]))\n        sns.distplot(df_train[num_columns].iloc[:,i], ax=ax[17,i-32], kde=False, color=\"gray\")\n        ax[17,i-32].set_title(\"{}\".format(\"skew:\"+ str(skew[i]) + \"\/\" + \"kurt:\" + str(kurt[i])))\n        ax[17,i-32].set_ylabel(\"Count\")","e2b3af0c":"columns = df_train[num_columns[:-1]].columns\n\n# fill by median\nfor i in range(len(columns)):\n    median = df_train[columns[i]].median()\n    df_train[columns[i]].fillna(median, inplace=True)","87e8f1d1":"# calculate eigen values\neigen_vals = sorted(np.linalg.eigvals(df_train[num_columns[:-1]].corr()), reverse=True)\n\n# plot\nplt.figure(figsize=(10,6))\nplt.plot(eigen_vals, \"s-\")\nplt.xlabel(\"factor\")\nplt.ylabel(\"eigenvalue\")","087fb75f":"# Create instance\nfa = FactorAnalyzer(n_factors=5, rotation=\"promax\", impute=\"drop\")\nfa.fit(df_train[num_columns[:-1]].fillna(0))\n\nresult = fa.loadings_\ncolnames = df_train[num_columns[:-1]].columns\n\n# Visualization by heatmap\nplt.figure(figsize=(15,15))\nhm = sns.heatmap(result,\n                cbar=True,\n                annot=True,\n                cmap=\"bwr\",\n                fmt=\".2f\",\n                annot_kws={\"size\":10},\n                yticklabels=colnames,\n                vmax=1,\n                vmin=-1,\n                center=0)\nplt.xlabel(\"factors\")\nplt.ylabel(\"numerical values\")","d3b9f665":"# factor point dataframe\nfactor_point = pd.DataFrame(fa.transform(df_train[num_columns[:-1]]), columns=[\"factor1\", \"factor2\", \"factor3\", \"factor4\", \"factor5\"])\nfactor_point.head()","b6c6e062":"# Visualization by plot\nx1 = factor_point[\"factor1\"]\ny1 = factor_point[\"factor2\"]\nc = df_train[\"SalePrice\"]\n\nplt.figure(figsize=(10,8))\nplt.scatter(x1, y1, c=c)\nplt.xlabel(\"factor1\\nSize of the first floor of the house factor\")\nplt.ylabel(\"factor2\\nNewness from outside factor\")\nplt.colorbar()","17e94353":"# Create instance\niso = Isomap(n_components=2)\n\n# Fitting\niso.fit(df_train[num_columns[:-1]])\niso_projected = iso.transform(df_train[num_columns[:-1]])","b4abfe82":"# Visualization by plot\nx1 = iso_projected[:,0]\ny1 = iso_projected[:,1]\nc = df_train[\"SalePrice\"]\n\nplt.figure(figsize=(10,8))\nplt.scatter(x1, y1, c=c)\nplt.xlabel(\"iso_axis1\")\nplt.ylabel(\"iso_axis2\")\nplt.colorbar()","3e7b3cca":"# Create instance\ntsne = TSNE(n_components=2, random_state=10)\n\n# Fitting\ntsne_projected = tsne.fit_transform(df_train[num_columns[:-1]])","05930ea2":"# Visualization by plot\nx1 = tsne_projected[:,0]\ny1 = tsne_projected[:,1]\nc = df_train[\"SalePrice\"]\n\nplt.figure(figsize=(10,8))\nplt.scatter(x1, y1, c=c)\nplt.xlabel(\"iso_axis1\")\nplt.ylabel(\"iso_axis2\")\nplt.colorbar()","eeb5fc62":"# Scaling parameters with standarlizing\n# Create instance\nsc = StandardScaler()\n# Fitting\nsc.fit(df_train[num_columns[:-1]])\n\n# Create prameters\nX = sc.fit_transform(df_train[num_columns[:-1]])","7a3a0c72":"# kmeans and visualization with violinplots cluster numbers.\nfig, ax = plt.subplots(2,3, figsize=(24,12))\nfor i in range(2,8):\n    # Create instance\n    kmeans = cluster.KMeans(n_clusters=i, max_iter=30, init=\"random\", random_state=10)\n    \n    # Fitting\n    kmeans.fit(X)\n    \n    # cluster label\n    labels = kmeans.predict(X)\n    \n    # Combine with df_train\n    df_train[\"cluster_label\"] = labels\n\n    # Confirming by violinplot, if they can separate habing relationship with SalePrice\n    if i >= 2 and i < 5:\n        sns.violinplot(\"cluster_label\",\"SalePrice\", data=df_train, ax=ax[0,i-2])\n        ax[0,i-2].set_xlabel(\"cluster\")\n        ax[0,i-2].set_ylabel(\"Price\")\n    else:\n        sns.violinplot(\"cluster_label\",\"SalePrice\", data=df_train, ax=ax[1,i-5])\n        ax[1,i-5].set_xlabel(\"cluster\")\n        ax[1,i-5].set_ylabel(\"Price\")","a9e86d9b":"# decided cluster values 6\nkmeans = cluster.KMeans(n_clusters=6, max_iter=30, init=\"random\", random_state=10)\n    \n# Fitting\nkmeans.fit(X)\n    \n# cluster label\nlabels = kmeans.predict(X)\n\n# Combine with df_train\ndf_train[\"cluster_label\"] = labels\n\n# Cisualization\nplt.figure(figsize=(10,6))\nsns.violinplot(\"cluster_label\",\"SalePrice\", data=df_train)","0931a0cb":"# Visualization by plot\nx1 = tsne_projected[:,0]\ny1 = tsne_projected[:,1]\nc_clust = labels\n\nfig, ax = plt.subplots(1,2,figsize=(20, 6))\ncs = ax[0].scatter(x1, y1, c=c_clust, cmap='Set1_r')\nax[0].set_xlabel(\"iso_axis1\")\nax[0].set_ylabel(\"iso_axis2\")\nfig.colorbar(cs, ax=ax[0])\nax[0].set_title(\"Cluster label\")\n\ncp = ax[1].scatter(x1, y1, c=c)\nax[1].set_xlabel(\"iso_axis1\")\nax[1].set_ylabel(\"iso_axis2\")\nfig.colorbar(cp, ax=ax[1])\nax[1].set_title(\"Price\")","3cf28cd3":"# Create dataframe with scaling values\ncompare = pd.DataFrame(X, columns=num_columns[:-1])\ncompare[\"cluster_label\"] = labels\ncompare = compare.groupby(\"cluster_label\").mean()[num_columns[:-1]].reset_index()\ncompare = compare.iloc[:,1:].T\ncompare.head()","98591a47":"# Visualization by plot\nplt.figure(figsize=(20,10))\nplt.plot(compare.index, compare[0])\nplt.plot(compare.index, compare[3])\nplt.plot(compare.index, compare[4])\nplt.xticks(rotation=90)\nplt.xlabel(\"Parameter\")\nplt.ylabel(\"Values(Standarlized)\")\nplt.legend([\"cluster_0\", \"cluster_3\", \"cluster_4\"])","51d1b8b0":"When we using k-means cluster analysis, it is important to decide how many do we select the cluster number.<br>\nThis time, I decide 6 clusters from checking each result, hoping they are separated like higher or lower price class and to capture the difference between feature groups.","ccc3da07":"- Although it is a characteristic division, we can see that the price increases as you go to the lower right, information is more densely compressed.","e3e15a31":"## 2. Numerical parameters","017b7b9c":"- Cluster number 5 result, the price is cluster (0 & 1) < 2 < 5 < 3 < 4.","c897f469":"## Conclusion","c378358a":"- Next try to visualization with ISO map.","4870b61c":"### About numerical parameters of dataset, we could understand a lot of information through basic aggregation and visualization.\n### And, It was possible to understand more relationship with the target price by factor analysis, and ISO map, combination of t-SNE and cluster analysis for data with many parameters, which is a dimension reduction method.","fdd72823":"### Consideration\n- Both methods have advantages and disadvantages.<br>\n- In the factor analysis, it is easy to interpret the features, but when the number of factors is large, the information cannot be compressed and the distribution cannot be clearly divided.\n- The ISO map and t-SNE compress the information and divide the price, but it is difficult to interpret the result only it. They are need to combine with cluster analysis is required.\n- In either method, it is necessary to judge the right person in the right place.","9e352a24":"Before dimension reduction, Null values were filled median values.","b7a6f66f":"## Agenda\n### 1. Target value, Sale price distribution\n### 2. Numerical parameters\n### 3. Try to dimension reduction about numerical parameters","9ab59734":"### Correlation matrix","c705267e":"- Last, I try to visualization with t-SNE","e1383a0f":"- The price can be decomposed relatively well on the axes of factors 1 and 2.\n- From result, large 1st floor size and newness from outside viewing is important for high price.","edad8f42":"## Libraries","91f8d448":"### Scree Plot","a883016f":"### RM analysis of Year and SalePrice by using decyl","26cf1639":"## 1. Target value, Sale price distribution","24a8b021":"- They contribute to understand parameter's features by plot and distribution confirming. Is the data biased? Do they have information that affects the desired selling price?, we can find from those visualization.\n- But, actually, howdo they have influence? Which is the more important in the complex information? we cannot know only those information. So, next I try to compress parameter information by using dimension reduction.","9aa84fa2":"- Lower Price cluster 0 have feature that, each params are lower, especially, Year is lower (= Old), Garage is lower (= Small). On the other hand, we can know porch are are not important.\n- Cluster 4 and 3 is higer than cluster 0 by each params, cluster 4 is strong higher than cluster 3 by \"MasVnrArea\",\"2ndFlrSF\",\"BedroomAbvGr\",\"PoolArea\".","244d6ec4":"### Create cluster labels","7322fe49":"## Data loading and Checking","7b701fe5":"## Factor analysis\n- Some variables are not normal, but some are continuous and highly normal.\n- Perform a factor analysis. Originally, it should be performed for variables whose normality has been confirmed, but try factor analysis for all variables.","75007b6a":"## 3. Try to dimension reduction about numerical prameters","4e327984":"# House Prices, EDA and Dimension reduction","cf953519":"- It can be aggregated into 5 variables.","898cec14":"Data distribution","5f0a288a":"## Combination with t-SNE and k-means cluster analysis. ","cdc9f792":"Re calculating","025e29c9":"- High-priced samples are skewed to the edge of the plot.From this distribution as well, it can be judged that the price level is divided by t-SNE, and that the underlying variable includes price information.","b8984ab5":"### Perform factor analysis","23d49cb8":"### Decyl analysis of sale price","87b78812":"## t-SNE","09fe9f31":"### plot and distribution, each values vs SalesPrice","18022274":"## Next, try to categorical values analysis.","9e262f99":"- \u3010\"TotalBsmtSF\" & \"1stFlrSF\"\u3011, \u3010\"GrLivArea\" & \"TotRmsAbvGrd\"\u3011\u3010\"GarageCars\" & \"GarageArea\"\u3011have strong correlation. \n- Even if, correlation value is high and similar values, distribution are various forms. It is important to visually confirm each distribution.","9ac867b3":"- It can be seen from the graph that the distribution is also located in the high price range around clusters 3 and 4, similar to the results of the violin plot.\nNext, try to compare higher cluster (3, 4) and cluster 0.","c5bc3ce0":"- In the market analysis, the decyl analysis and RFM (RM analysis this time), which are common in the market analysis, were able to capture the characteristics of the distribution of selling prices. In particular, the fact that the upper price range is the widest and the next is the lowest low price range is important information for understanding the overall characteristics.","aa76fd64":"## ISO map","cb961169":"### For predicting prices, basic analysis to understand the information in the data is important, even for complex data sets. This time, we tried to understand the data set using basic analysis by EDA and dimension reduction for numerical values.","04a37e4e":"### Plot by 1st factor and 2nd factor","c1c36b00":"- 5 factors besed on following parameters.I grouped each and named them.<br>\n\n\n### 1st factor : Size of the first floor of the house factor\nprameters<br>\nTotalBsmtSF : Total square feet of basement area<br>\n1stFlrSF : First Floor square feet<br>\n\n### 2nd factor : Newness from outside factor\nprameters<br>\nYearBuilt : Original construction date<br>\nYeerRemodeAdd : Remodel date (same as construction date if no remodeling or additions)<br>\nGarageYrBlt : Year garage was built<br>\n\n### 3rd factor : Individual elements factor\nprameters<br>\n2ndFlrSF : Second floor square feet<br>\nHalfBath : Half baths above grade<br>\n\n### 4th factor : Basement factor\nprameters<br>\nBsmtFinSF1 : Type 1 finished square feet<br>\nBsmtUnfSF : Unfinished square feet of basement area<br>\nBsmtFullBath : Basement full bathrooms<br>\n\n### 5th factor : Kitchen factor\nprameters<br>\nKitchinAbvGr : Kitchens above grade<br>"}}