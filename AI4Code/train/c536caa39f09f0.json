{"cell_type":{"c99a8955":"code","706205aa":"code","c7ac2ea1":"code","ca870a26":"code","dec91f49":"code","6c0cf94b":"code","b2d61e42":"code","beeb59da":"code","9d809e22":"code","9152af71":"code","878771ad":"code","8e17fdfc":"code","e88232ec":"code","e363c985":"code","aad18854":"code","71fcfbbb":"code","afe573a4":"code","dd3f9142":"code","deac5cce":"code","584de49c":"code","54aba979":"code","a622487f":"code","704b90d7":"code","86f7fe50":"code","ebe3f4c0":"code","0380ad68":"code","94ba1e22":"code","5f77672a":"code","eb2f1235":"code","50ef6841":"code","84cde744":"code","3b1fc815":"code","a79148e5":"code","8cc78344":"code","cc3a826d":"code","81b2c910":"code","ee2459af":"code","feee6089":"markdown","920f46c0":"markdown","e0c3cdf3":"markdown","73fafda1":"markdown","dc62ca9a":"markdown","7cd5f2b4":"markdown","8f3c993e":"markdown","f9295a59":"markdown","1e858a25":"markdown","d381d376":"markdown","226abebe":"markdown","06d1b295":"markdown","40d728ee":"markdown","9fa81ae2":"markdown","c64307bf":"markdown","830b4e6d":"markdown","1519ae78":"markdown","c30ffb22":"markdown"},"source":{"c99a8955":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","706205aa":"import math, re, os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom tensorflow import keras\nfrom functools import partial\nfrom sklearn.model_selection import train_test_split\nprint(\"Tensorflow version \" + tf.__version__)","c7ac2ea1":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","ca870a26":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nGCS_PATH = KaggleDatasets().get_gcs_path()\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [512, 512]\nCLASSES = ['0', '1', '2', '3', '4']\nEPOCHS = 25","dec91f49":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image","6c0cf94b":"def read_tfrecord(example, labeled):\n    tfrecord_format = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64)\n    } if labeled else {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    if labeled:\n        label = tf.cast(example['target'], tf.int32)\n        return image, label\n    idnum = example['image_name']\n    return image, idnum","b2d61e42":"def load_dataset(filenames, labeled=True, ordered=False):\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n    return dataset","beeb59da":"TRAINING_FILENAMES, VALID_FILENAMES = train_test_split(\n    tf.io.gfile.glob(GCS_PATH + '\/train_tfrecords\/ld_train*.tfrec'),\n    test_size=0.35, random_state=5\n)\n\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '\/test_tfrecords\/ld_test*.tfrec')","9d809e22":"print(len(TRAINING_FILENAMES))","9152af71":"def data_augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.central_crop(image, 0.2)\n    return image, label","878771ad":"def get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)  \n    #dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)  \n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","8e17fdfc":"def get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered) \n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","e88232ec":"def get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","e363c985":"def count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","aad18854":"NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n\nprint('Dataset: {} training images, {} validation images, {} (unlabeled) test images'.format(\n    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","71fcfbbb":"print(\"Training data shapes:\")\nfor image, label in get_training_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Training data label examples:\", label.numpy())\n\nprint(\"Validation data shapes:\")\nfor image, label in get_validation_dataset().take(3):\n    print(image.numpy().shape, label.numpy().shape)\nprint(\"Validation data label examples:\", label.numpy())\n\nprint(\"Test data shapes:\")\nfor image, idnum in get_test_dataset().take(3):\n    print(image.numpy().shape, idnum.numpy().shape)\n    \nprint(\"Test data IDs:\", idnum.numpy().astype('U')) # U=unicode string","afe573a4":"# numpy and matplotlib defaults\nnp.set_printoptions(threshold=15, linewidth=80)\n\ndef batch_to_numpy_images_and_labels(data):\n    images, labels = data\n    numpy_images = images.numpy()\n    numpy_labels = labels.numpy()\n    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n        numpy_labels = [None for _ in enumerate(numpy_images)]\n    # If no labels, only image IDs, return None for labels (this is the case for test data)\n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    if correct_label is None:\n        return CLASSES[label], True\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_plant(image, title, subplot, red=False, titlesize=16):\n    plt.subplot(*subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    if len(title) > 0:\n        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize\/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize\/1.5))\n    return (subplot[0], subplot[1], subplot[2]+1)\n\ndef display_batch_of_images(databatch, predictions=None):\n    \"\"\"This will work with:\n    display_batch_of_images(images)\n    display_batch_of_images(images, predictions)\n    display_batch_of_images((images, labels))\n    display_batch_of_images((images, labels), predictions)\n    \"\"\"\n    # data\n    images, labels = batch_to_numpy_images_and_labels(databatch)\n    if labels is None:\n        labels = [None for _ in enumerate(images)]\n        \n    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n    rows = int(math.sqrt(len(images)))\n    cols = len(images)\/\/rows\n        \n    # size and spacing\n    FIGSIZE = 13.0\n    SPACING = 0.1\n    subplot=(rows,cols,1)\n    if rows < cols:\n        plt.figure(figsize=(FIGSIZE,FIGSIZE\/cols*rows))\n    else:\n        plt.figure(figsize=(FIGSIZE\/rows*cols,FIGSIZE))\n    \n    # display\n    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n        title = '' if label is None else CLASSES[label]\n        correct = True\n        if predictions is not None:\n            title, correct = title_from_label_and_target(predictions[i], label)\n        dynamic_titlesize = FIGSIZE*SPACING\/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n        subplot = display_one_plant(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n    \n    #layout\n    plt.tight_layout()\n    if label is None and predictions is None:\n        plt.subplots_adjust(wspace=0, hspace=0)\n    else:\n        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n    plt.show()","dd3f9142":"# load our training dataset for EDA\ntraining_dataset = get_training_dataset()\ntraining_dataset = training_dataset.unbatch().batch(20)\ntrain_batch = iter(training_dataset)","deac5cce":"# run this cell again for another randomized set of training images\ndisplay_batch_of_images(next(train_batch))","584de49c":"# load our validation dataset for EDA\nvalidation_dataset = get_validation_dataset()\nvalidation_dataset = validation_dataset.unbatch().batch(20)\nvalid_batch = iter(validation_dataset)","54aba979":"# run this cell again for another randomized set of training images\ndisplay_batch_of_images(next(valid_batch))","a622487f":"# load our test dataset for EDA\ntesting_dataset = get_test_dataset()\ntesting_dataset = testing_dataset.unbatch().batch(20)\ntest_batch = iter(testing_dataset)","704b90d7":"# we only have one test image\ndisplay_batch_of_images(next(test_batch))","86f7fe50":"from tensorflow.keras.applications import InceptionV3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport random\nimport os\nimport cv2\nimport sys\nfrom pylab import rcParams\nfrom PIL import Image\nwarnings.filterwarnings('ignore')\n\n\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Input, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.applications import InceptionV3, Xception\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom tensorflow.keras.applications import EfficientNetB0","ebe3f4c0":"lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n                                                initial_learning_rate=1e-5, \n                                                decay_steps=10000, \n                                                decay_rate=0.9)","0380ad68":"with strategy.scope(): \n    \n    x = Input(shape=(*IMAGE_SIZE, 3))\n    \n    img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.efficientnet.preprocess_input, \n                                              input_shape=[*IMAGE_SIZE, 3])\n    \n    base_model = EfficientNetB0(include_top=False,\n                             weights=\"imagenet\")\n    \n    base_model.trainable = False\n    \n    \n    \n    input_s = img_adjust_layer(x)\n    model = base_model(input_s)\n    pooling = GlobalAveragePooling2D()(model)\n    #dropout = Dropout(0.2)(pooling)\n    flatten  = tf.keras.layers.Flatten()(pooling)\n    output = Dense(units=5, activation='softmax', name='dense', dtype='float32')(flatten)\n    effic = Model(inputs=[x], outputs=[output])\n    \n    # compile\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n    loss = tf.keras.losses.sparse_categorical_crossentropy\n    \n    effic.compile(optimizer=optimizer, loss=loss, metrics=['sparse_categorical_accuracy'])\n    \n    ","94ba1e22":"#     img_adjust_layer = tf.keras.layers.Lambda(tf.keras.applications.inception_v3.preprocess_input, input_shape=[*IMAGE_SIZE, 3])\n    \n#     base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False)\n#     base_model.trainable = False\n    \n#     model = tf.keras.Sequential([\n#         tf.keras.layers.BatchNormalization(renorm=True),\n#         img_adjust_layer,\n#         base_model,\n#         tf.keras.layers.GlobalAveragePooling2D(),\n#         tf.keras.layers.Dense(8, activation='relu'),\n#         #tf.keras.layers.BatchNormalization(renorm=True),\n#         tf.keras.layers.Dense(len(CLASSES), activation='softmax')  \n#     ])\n    \n#     model.compile(\n#         optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler, epsilon=0.001),\n#         loss='sparse_categorical_crossentropy',  \n#         metrics=['sparse_categorical_accuracy'])","5f77672a":"effic.summary()","eb2f1235":"# load data\ntrain_dataset = get_training_dataset()\nvalid_dataset = get_validation_dataset()","50ef6841":"STEPS_PER_EPOCH = NUM_TRAINING_IMAGES \/\/ BATCH_SIZE\nVALID_STEPS = NUM_VALIDATION_IMAGES \/\/ BATCH_SIZE\n\nhistory = effic.fit(train_dataset, \n                    steps_per_epoch=STEPS_PER_EPOCH, \n                    epochs=EPOCHS,\n                    validation_data=valid_dataset,\n                    validation_steps=VALID_STEPS)","84cde744":"# print out variables available to us\nprint(history.history.keys())","3b1fc815":"# create learning curves to evaluate model performance\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot();","a79148e5":"# this code will convert our test image data to a float32 \ndef to_float32(image, label):\n    return tf.cast(image, tf.float32), label","8cc78344":"test_ds = get_test_dataset(ordered=True) \ntest_ds = test_ds.map(to_float32)\n\nprint('Computing predictions...')\n\ntest_images_ds = testing_dataset\ntest_images_ds = test_ds.map(lambda image, idnum: image)","cc3a826d":"probabilities = effic.predict(test_images_ds)\npredictions = np.argmax(probabilities, axis=-1)\nprint(predictions)","81b2c910":"print('Generating submission.csv file...')\ntest_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\ntest_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n\nnp.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=['%s', '%d'], delimiter=',', header='id,label', comments='')\n!head submission.csv","ee2459af":" # Save your model to disk using the .save() functionality. Here we save in .h5 format\n    # This step will be replaced with an alternative call to save models in Tensorflow 2.3\neffic.save('efficientnetb0_1.h5')","feee6089":"You can also modify the above code to look at your `validation` and `test` data, like this:","920f46c0":"# Creating a submission file\nNow that we've trained a model and made predictions we're ready to submit to the competition! You can run the following code below to get your submission file.","e0c3cdf3":"# Set up variables\n","73fafda1":"## Decode the data\nIn the code chunk below we'll set up a series of functions that allow us to convert our images into tensors so that we can utilize them in our model. We'll also normalize our data. Our images are using a \"Red, Blue, Green (RBG)\" scale that has a range of [0, 255], and by normalizing it we'll set each pixel's value to a number in the range of [0, 1]. ","dc62ca9a":"# Making predictions\nNow that we've trained our model we can use it to make predictions! ","7cd5f2b4":"# Building the model\n## Learning rate schedule","8f3c993e":"Be aware that because this is a code competition with a hidden test set, internet and TPUs cannot be enabled on your submission notebook. Therefore TPUs will only be available for training models. For a walk-through on how to train on TPUs and run inference\/submit on GPUs, see our [TPU Docs](https:\/\/www.kaggle.com\/docs\/tpu#tpu6).","f9295a59":"# Set up environment","1e858a25":"## Detect TPU","d381d376":"## Adding in augmentations ","226abebe":"# Train the model\nAs our model is training you'll see a printout for each epoch, and can also monitor TPU usage by clicking on the TPU metrics in the toolbar at the top right of your notebook.","06d1b295":"## Building our model\nIn order to ensure that our model is trained on the TPU, we build it using `with strategy.scope()`.    \n\nNote that we're using `sparse_categorical_crossentropy` as our loss function, because we did _not_ one-hot encode our labels.","40d728ee":"# Evaluating our model\nThe first chunk of code is provided to show you where the variables in the second chunk of code came from. As you can see, there's a lot of room for improvement in this model, but because we're using TPUs and have a relatively short training time, we're able to iterate on our model fairly rapidly.","9fa81ae2":"# Load the data\n","c64307bf":"## Define data loading methods\nThe following functions will be used to load our `training`, `validation`, and `test` datasets, as well as print out the number of images in each dataset.","830b4e6d":"We'll use the following function to load our dataset. One of the advantages of a TPU is that we can run multiple files across the TPU at once, and this accounts for the speed advantages of using a TPU. To capitalize on that, we want to make sure that we're using data as soon as it streams in, rather than creating a data streaming bottleneck.","1519ae78":"The following code chunk sets up a series of functions that will print out a grid of images. The grid of images will contain images and their corresponding labels.","c30ffb22":"# Brief exploratory data analysis (EDA)\nFirst we'll print out the shapes and labels for a sample of each of our three datasets:"}}