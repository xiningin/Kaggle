{"cell_type":{"0dd4d017":"code","5fcb6ea7":"code","bd4e3d09":"code","616461b5":"code","1aa00f2e":"code","f5cef2aa":"code","ff99a759":"code","518f02ff":"code","c8c8c451":"code","9f320b50":"code","261bef5a":"code","c5d0bd3f":"markdown","3d56bf9c":"markdown","94a9a8f0":"markdown","d3959394":"markdown","77a59f95":"markdown","d4a35f67":"markdown","9ad52101":"markdown","4abd4e58":"markdown","f838b5c9":"markdown","558a7691":"markdown","ec250c12":"markdown","7359b2fd":"markdown","db57c95c":"markdown","59d04b1f":"markdown"},"source":{"0dd4d017":"import os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","5fcb6ea7":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/train.csv')\ntest = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/test.csv')\n\nY1=train['ConfirmedCases']\nY2=train['Fatalities']","bd4e3d09":"train['Complete_Date'] = train['Date'].astype('datetime64[ns]')\ntest['Complete_Date'] = test['Date'].astype('datetime64[ns]')\n\nmonth = [int(el[5:7]) for el in list(train['Date'].values)]\nday = [int(el[8:10]) for el in list(train['Date'].values)]\n\nmonth_test = [int(el[5:7]) for el in list(test['Date'].values)]\nday_test = [int(el[8:10]) for el in list(test['Date'].values)]\n\ndf_month= pd.DataFrame(month, columns= ['Month'])\ndf_day= pd.DataFrame(day, columns= ['Day'])\n\ndf_month_test= pd.DataFrame(month_test, columns= ['Month'])\ndf_day_test= pd.DataFrame(day_test, columns= ['Day'])\n\ntrain=pd.concat([train, df_month], axis=1)\ntest=pd.concat([test, df_month_test], axis=1)\n\ntrain=pd.concat([train, df_day], axis=1)\ntest=pd.concat([test, df_day_test], axis=1)\n\ntrain['Date']=train['Month']*100+train['Day']\ntest['Date']=test['Month']*100+test['Day']","616461b5":"train['Province_State'].fillna('',inplace=True)\ntest['Province_State'].fillna('',inplace=True)\n\ntrain['Province_State']=train['Province_State'].astype(str)\ntest['Province_State']=test['Province_State'].astype(str)\n\ny= train['Country_Region']+train['Province_State']\ny= pd.DataFrame(y, columns= ['Place'])\n\ny_test= test['Country_Region']+test['Province_State']\ny_test= pd.DataFrame(y_test, columns= ['Place'])\n\ntrain=pd.concat([train, y], axis=1)\ntest=pd.concat([test, y_test], axis=1)\n\nCountry_df=train[\"Place\"]\nConfirmedCases_df=train[\"ConfirmedCases\"]\nCountry_df.to_numpy()\nConfirmedCases_df.to_numpy()\nCountry=Country_df[0]\nNbDay = pd.DataFrame(columns=['NbDay'])\nday=0\ncount=0\nfor x in train[\"Month\"]:\n    if (ConfirmedCases_df[count]==0):      \n        NbDay = NbDay.append({'NbDay': int(0)}, ignore_index=True)\n        count=count+1 \n    else:\n        if (Country_df[count]==Country):\n            day=day+1\n            NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)\n            count=count+1\n        else:\n            Country=Country_df[count]\n            day=1\n            NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)\n            count=count+1\ntrain=pd.concat([train, NbDay], axis=1)","1aa00f2e":"# Adding NbDay feature to the test data\nNbDay_test_array=np.zeros(test.shape[0])\ni=0\ndf=test[\"Place\"]\nPlace_array=df.to_numpy()\nfor t in test.Date:\n    place=Place_array[i]\n    if t==402:\n        row=train.loc[(train['Place'] == place) & (train['Date'] ==t)]\n        row=row.to_numpy()\n        NbDay_test_array[i]= row[0][10]\n    else: \n        NbDay_test_array[i]=0\n    i=i+1\n\nNbDay=pd.DataFrame(NbDay_test_array, columns=['NbDay1'])\ntest=pd.concat([test,NbDay], axis=1)\n\nCountry_df=test[\"Place\"]\nNbDay_df=test['NbDay1']\nCountry_df.to_numpy()\nday_array=NbDay_df.to_numpy()\nCountry=Country_df[0]\nNbDay = pd.DataFrame(columns=['NbDay'])\nday=0\ncount=0\nfor t in test[\"Date\"]:\n    if (t==402):\n        day=day_array[count] \n        NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)  \n        count=count+1\n    else:\n        day=day+1\n        NbDay = NbDay.append({'NbDay': int(day)}, ignore_index=True)\n        count=count+1\ntest=pd.concat([test,NbDay], axis=1)","f5cef2aa":"train=train[['Place','NbDay','ConfirmedCases','Fatalities']]\ntest=test[['Place','NbDay']]\n\ntrain_data = train\ntest_data = test","ff99a759":"country_array=train_data['Place'].to_numpy()\n\ndef distinct_values(country_array):\n    liste=[]\n    liste.append(country_array[0])\n    for i in range(1,len(country_array)): \n        if country_array[i]!=country_array[i-1]:\n            liste.append(country_array[i])\n    return liste\n\n\nCountries_liste=distinct_values(country_array)\n\nlen(Countries_liste)","518f02ff":"def exponentiate_alpha(column,v):\n\n    \n    array=column.to_numpy()\n    \n    string='NbDay'+str(v)\n    \n    array=np.power(v,array)\n        \n    frame=pd.DataFrame(array, columns=[string])\n    \n        \n    return frame\n\nliste_mse_countries=[]\nliste_r2_countries=[]\nresults=[]\n\ni=1\nfor country in Countries_liste:\n    \n    \n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['ConfirmedCases']\n    \n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    alpha=[1+i*0.01 for i in range(1,101)]\n\n    liste_mse_countries=[]\n    liste_r2_countries=[]\n    liste_mse=[]\n    liste_r2=[]\n    liste_rmsle=[]\n    \n    \n    i=i+1\n    \n    for v in alpha: \n    \n        \n        X1=exponentiate_alpha(train_NbDay,v)\n    \n        \n        X_train,X_test,y_train,y_test = train_test_split(X1,y_NbDay,test_size = 0.3, shuffle= False)\n    \n        # Create linear regression object\n        regr = linear_model.LinearRegression()\n\n        # Train the model using the training sets\n        regr.fit(X_train, y_train)\n\n        # Make predictions using the testing set\n        y_pred = regr.predict(X_test)\n        y_pred = np.maximum(y_pred, 0)\n    \n        liste_rmsle.append(np.sqrt(mean_squared_log_error( y_test, y_pred )))\n        \n\n        liste_r2.append(r2_score(y_test, y_pred))\n\n    argmaximum = np.argmax(liste_r2)\n    \n    maximum = liste_r2[argmaximum]\n    minimum = liste_rmsle[argmaximum]\n\n    \n    results.append([country,maximum,minimum,alpha[argmaximum]])\n\ndic_alpha1={}\nfor liste in results: \n    dic_alpha1[liste[0]]=liste[3]","c8c8c451":"liste_mse_countries=[]\nliste_r2_countries=[]\nresults2=[]\n\ni=1\nfor country in Countries_liste:\n    \n    \n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['Fatalities']\n    \n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    alpha=[1+i*0.01 for i in range(1,101)]\n\n    liste_mse_countries=[]\n    liste_r2_countries=[]\n    liste_mse=[]\n    liste_r2=[]\n    liste_rmsle=[]\n    \n    \n    i=i+1\n    \n    for v in alpha: \n    \n        \n        X1=exponentiate_alpha(train_NbDay,v)\n    \n        \n        X_train,X_test,y_train,y_test = train_test_split(X1,y_NbDay,test_size = 0.3, shuffle= False)\n    \n        # Create linear regression object\n        regr = linear_model.LinearRegression()\n\n        # Train the model using the training sets\n        regr.fit(X_train, y_train)\n\n\n        y_pred = regr.predict(X_test)\n        y_pred = np.maximum(y_pred, 0)\n    \n\n        liste_rmsle.append(np.sqrt(mean_squared_log_error( y_test, y_pred )))\n\n        liste_r2.append(r2_score(y_test, y_pred))\n\n    argmaximum = np.argmax(liste_r2)\n    \n    maximum = liste_r2[argmaximum]\n    minimum = liste_rmsle[argmaximum]\n\n    \n    results2.append([country,maximum,minimum,alpha[argmaximum]])\n    \ndic_alpha2={}\nfor liste in results2: \n    dic_alpha2[liste[0]]=liste[3]","9f320b50":"ConfirmedCasesPredictions=[]\n\ni=1\nfor country in Countries_liste:\n        \n    # Train\n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['ConfirmedCases']\n    \n    \n    # Test\n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    \n    #Best alpha1\n    v= dic_alpha1[country]\n    \n    #Modifiying NbDay for test and train    \n    X1=exponentiate_alpha(train_NbDay,v)\n    X2=exponentiate_alpha(test_NbDay,v)\n\n    \n    # Create linear regression object\n    regr = linear_model.LinearRegression()\n\n    \n    # Train the model using the training sets\n    regr.fit(X1, y_NbDay)\n\n    \n    # Make predictions using the testing set\n    y_pred = regr.predict(X2)\n    y_pred = list(np.maximum(y_pred, 0))\n    ConfirmedCasesPredictions+=y_pred\n    \n    i=i+1\n    \n\n    \nFatalitiesPredictions=[]\n\ni=1\nfor country in Countries_liste:\n        \n    # Train\n    train_NbDay=train[train['Place']==country]['NbDay']\n    y_NbDay=train[train['Place']==country]['Fatalities']\n    \n    \n    # Test\n    test_NbDay=test[test['Place']==country]['NbDay']\n    \n    \n    #Best alpha1\n    v= dic_alpha2[country]\n    \n    #Modifiying NbDay for test and train    \n    X1=exponentiate_alpha(train_NbDay,v)\n    X2=exponentiate_alpha(test_NbDay,v)\n\n    \n    # Create linear regression object\n    regr = linear_model.LinearRegression()\n\n    \n    # Train the model using the training sets\n    regr.fit(X1, y_NbDay)\n\n    \n    # Make predictions using the testing set\n    y_pred = regr.predict(X2)\n    y_pred = list(np.maximum(y_pred, 0))\n    FatalitiesPredictions+=y_pred\n    \n    i=i+1","261bef5a":"ConfirmedCases=np.array(ConfirmedCasesPredictions)\nFatalities=np.array(FatalitiesPredictions)\n\nConfirmedCases=pd.DataFrame(ConfirmedCases, columns=['ConfirmedCases'])\nFatalities=pd.DataFrame(Fatalities, columns=['Fatalities'])\n\n# Submission\n\nt = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/test.csv')\n\nId=t['ForecastId']\n\n\nsub = pd.DataFrame()\nsub['ForecastId'] = Id\nsub['ConfirmedCases'] = ConfirmedCases\nsub['Fatalities'] = Fatalities\nsub.to_csv('submission.csv', index=False)","c5d0bd3f":"# II) Preparing the Data","3d56bf9c":"## 5) Taking the essential features for the next steps","94a9a8f0":"## 2) Modifiying date feature","d3959394":"## 3) Combining Province_State and Country_Region in one Feature","77a59f95":"# V) Submission","d4a35f67":"## 2) Finding best alpha1 for each region","9ad52101":"# IV) Forecasting","4abd4e58":"# III) Choosing best alphas to fit exponential forecasting ","f838b5c9":"# I) Quick Introduction","558a7691":"## 3) Finding best alpha2 for each region","ec250c12":"## 1) Reading the Data","7359b2fd":"Why would we complicate things if they are simple? \n\nIs it possible to get great results using one single feature? If yes, how? \n\nWe share this for the diversity and to show that sometimes the usage of advanced ML algorithms is not mandatory.\n\nEventhough the model is simple, it shows good results.\n\nTo understand what that feature is and what is the model that I am using you can check my previous notebook:\nhttps:\/\/www.kaggle.com\/ffares\/exponential-growth-forecasting-using-one-feature where I am explaining the mathematical model, explianing my assumptions and the limits of model.\n\nIf you have any feedback on that please let me know!","db57c95c":"## 1) Creating a list of all the countries ","59d04b1f":"## 4) Making a new features counting days since the starting of the pandemic for each region"}}