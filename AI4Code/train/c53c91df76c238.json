{"cell_type":{"13a77942":"code","6c078596":"code","469a5193":"code","2c1597c5":"code","1d79ec2b":"code","9f76364a":"code","7d9990ab":"code","d421a63b":"code","45e41d41":"code","4448cc80":"code","2f6fa0d3":"code","aeb224f5":"code","45f37b0d":"code","8cac9f3a":"code","9adadfd5":"code","ad27be51":"code","ee16fa41":"code","1926b872":"code","e2c7e587":"code","da806108":"code","354d585c":"code","22ee30f1":"markdown","0e790fd4":"markdown","39236180":"markdown","219814e2":"markdown","d62e4aa6":"markdown","a9ca0293":"markdown","412c183f":"markdown","2caac53c":"markdown","ea3b93de":"markdown","5d5295c0":"markdown","ffdb1f96":"markdown","27040a42":"markdown","f89da551":"markdown","9dee1718":"markdown","d6d898e7":"markdown"},"source":{"13a77942":"import pandas as pd","6c078596":"import os\nos.listdir(\"..\/input\/\")","469a5193":"# set filepath of dataset to a variable\nmelbourne_filepath = \"..\/input\/melbourne-housing-snapshot\/melb_data.csv\"\n\n# read the data and store into DataFrame\nmelbourne_data = pd.read_csv(melbourne_filepath)\n\n# show some statistics about data (numerical variables)\nmelbourne_data.describe()","2c1597c5":"melbourne_data.head()","1d79ec2b":"import pandas as pd\n\nmelbourne_file_path = '..\/input\/melbourne-housing-snapshot\/melb_data.csv'\nmelbourne_data = pd.read_csv(melbourne_file_path) \n# show all fields\/columns in melbourne_data DataFrame\nmelbourne_data.columns","9f76364a":"# Melbourne Housing Data has some missing values\n# For now we will drop missing values\n\nmelbourne_data = melbourne_data.dropna(axis=0)","7d9990ab":"# selecting the prediction target\ny = melbourne_data.Price","d421a63b":"# choosing features\nmelbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']","45e41d41":"X = melbourne_data[melbourne_features]","4448cc80":"X.describe()","2f6fa0d3":"X.head()","aeb224f5":"from sklearn.tree import DecisionTreeRegressor\n\n# define model, define random_state to reproduce same results\nmelbourne_model = DecisionTreeRegressor(random_state=1)\n\n# fit model\nmelbourne_model.fit(X, y)","45f37b0d":"# Making predictions\n\nprint(\"Making predictions for the following 5 houses\")\nprint(X.head())\nprint(\"\\nThe predictions are: \")\nprint(melbourne_model.predict(X.head()))","8cac9f3a":"# Data Loading Code Hidden Here\nimport pandas as pd\n\n# Load data\nmelbourne_file_path = '..\/input\/melbourne-housing-snapshot\/melb_data.csv'\nmelbourne_data = pd.read_csv(melbourne_file_path) \n# Filter rows with missing price values\nfiltered_melbourne_data = melbourne_data.dropna(axis=0)\n# Choose target and features\ny = filtered_melbourne_data.Price\nmelbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n                        'YearBuilt', 'Lattitude', 'Longtitude']\nX = filtered_melbourne_data[melbourne_features]\n\nfrom sklearn.tree import DecisionTreeRegressor\n# Define model\nmelbourne_model = DecisionTreeRegressor()\n# Fit model\nmelbourne_model.fit(X, y)","9adadfd5":"from sklearn.metrics import mean_absolute_error\n\npredicted_prices = melbourne_model.predict(X)\nmean_absolute_error(y, predicted_prices)","ad27be51":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)\n\n# Define Model\nmelbourne_model = DecisionTreeRegressor(random_state=0)\n# Fit Model\nmelbourne_model.fit(train_X, train_y)\n\n# Predict on Validation Data\npredicted_prices = melbourne_model.predict(val_X)\n# Print Mean Absolute Error on Validation Data\nprint(mean_absolute_error(val_y, predicted_prices))","ee16fa41":"# Now we will use \"max_leaf_nodes\" parameter of \"DecisionTreeRegressor\" to set depth of tree\n# and compare results of different values of \"max_leaf_nodes\"\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\n\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return mae","1926b872":"import pandas as pd\n    \n# Load data\nmelbourne_file_path = '..\/input\/melbourne-housing-snapshot\/melb_data.csv'\nmelbourne_data = pd.read_csv(melbourne_file_path) \n# Filter rows with missing values\nfiltered_melbourne_data = melbourne_data.dropna(axis=0)\n# Choose target and features\ny = filtered_melbourne_data.Price\nmelbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n                        'YearBuilt', 'Lattitude', 'Longtitude']\nX = filtered_melbourne_data[melbourne_features]\n\nfrom sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both features and target\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)","e2c7e587":"# compare mae with different values of \"max_leaf_nodes\"\n\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(f\"Max leaf nodes: {max_leaf_nodes}\\t\\tMean Absolute Error: {mae:.0f}\")","da806108":"import pandas as pd\n    \n# Load data\nmelbourne_file_path = '..\/input\/melbourne-housing-snapshot\/melb_data.csv'\nmelbourne_data = pd.read_csv(melbourne_file_path) \n# Filter rows with missing values\nmelbourne_data = melbourne_data.dropna(axis=0)\n# Choose target and features\ny = melbourne_data.Price\nmelbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n                        'YearBuilt', 'Lattitude', 'Longtitude']\nX = melbourne_data[melbourne_features]\n\nfrom sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both features and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)","354d585c":"# we will import \"RandomForestRegressor\" class instead of \"DecisionTreeRegressor\"\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor(random_state=1)\nforest_model.fit(train_X, train_y)\nmelb_pred = forest_model.predict(val_X)\nmae = mean_absolute_error(melb_pred, val_y)\nprint(f\"{mae:.0f}\")","22ee30f1":"[**Machine Learning Micro Course Homepage**](https:\/\/www.kaggle.com\/learn\/intro-to-machine-learning)\n\n[Open this Notebook in Kaggle](https:\/\/www.kaggle.com\/mahendrabishnoi2\/05-intro-to-ml)\n\n---","0e790fd4":"Now calculate mean absolute error:","39236180":"## Building Model","219814e2":"# Model Validation\nMeasuring quality of the model.\n\nFirst of all create a model.","d62e4aa6":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-model-validation)\n\n---","a9ca0293":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-underfitting-and-overfitting)\n\n---","412c183f":"# Random Forests\nThe random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters.","2caac53c":"# Basic Data Exploration\n\n## Using Pandas to Get Familiar with Data\nWe'll look at data about home prices in Melbourne, Australia.","ea3b93de":"---","5d5295c0":"## train_test_split","ffdb1f96":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-your-first-machine-learning-model)\n\n---","27040a42":"# First Machine Learning Model\n\n## Selecting Data for Modelling\nThere are a lot of columns in `melbourne_data`. So first we will print all column names and then select a few columns to use for training our first model.","f89da551":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-explore-your-data)\n\n---","9dee1718":"# Underfitting and Overfitting\n\n**Overfitting**: When a model matches the training data almost perfectly, but does poorly in validation and other new data. \n\n**Underfitting**: When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data.\n\nSince we care about accuracy on new data, which we estimate from our validation data, we want to find the sweet spot between underfitting and overfitting. Visually, we want the low point of the (red) validation curve.\n<img src=\"http:\/\/i.imgur.com\/2q85n9s.png\"\/>","d6d898e7":"Exercises of this tutorial are solved [here](https:\/\/www.kaggle.com\/mahendrabishnoi2\/exercise-random-forests)\n\n---"}}