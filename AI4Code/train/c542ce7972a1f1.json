{"cell_type":{"8c7f2b66":"code","25e4ae3a":"code","e93fcc24":"code","3193ff3a":"code","093bb52a":"code","1da8a254":"code","a21748d2":"code","cf581b51":"code","8f48db57":"code","83b2614a":"code","790daab7":"code","ea271213":"code","8bafc894":"code","c1cc44fb":"code","bc1ee72b":"code","a7d5fd24":"code","17bac6ac":"code","514c2af8":"code","7f4a05a7":"code","41eea7ba":"code","a6baeb25":"code","b102280e":"code","92d6270a":"code","f550da2f":"code","11e13548":"code","1f2d51c0":"code","3db9f7a2":"markdown","da9a84a6":"markdown","881d115a":"markdown","5f3bf034":"markdown","41839738":"markdown","e2cc42e2":"markdown","84a996db":"markdown","cd6e9122":"markdown","298b8b25":"markdown","19cd78fd":"markdown","5c19f38e":"markdown","1351aeab":"markdown","09e393d7":"markdown","944a5a7d":"markdown","8cc9c70b":"markdown","5a1db71d":"markdown","b0cc288b":"markdown","0d0c2e56":"markdown","8e30b854":"markdown","1040250b":"markdown","42d7d5fc":"markdown","286777f8":"markdown","90c3f654":"markdown","87316250":"markdown"},"source":{"8c7f2b66":"import numpy as np \nimport pandas as pd \n\ndb = pd.read_csv('\/kaggle\/input\/ecommerce-users-of-a-french-c2c-fashion-store\/6M-0K-99K.users.dataset.public.csv')\ndb.head()","25e4ae3a":"db.info()","e93fcc24":"#checking if there is any missing value\ndb.isna().sum()","3193ff3a":"db.skew() # skew() function is used to check skewness in data","093bb52a":"%matplotlib inline\nimport matplotlib as plt\nfrom matplotlib import pyplot\ngroup_names=['False','True']\nq=pyplot.bar(group_names, db['hasAnyApp'].value_counts())\n\n# set x\/y labels and plot title\nplt.pyplot.xlabel(\"hasAnyApp\")\nplt.pyplot.ylabel(\"Count\")\nplt.pyplot.title(\"hasAnyApp Bins\")","1da8a254":"df_group_two = db[['hasAnyApp','productsBought','productsSold']]\ndf_group_two = df_group_two.groupby(['hasAnyApp'],as_index=False).agg([np.sum,np.mean])\ndf_group_two","a21748d2":"%matplotlib inline\nimport matplotlib as plt\nfrom matplotlib import pyplot\ngroup_names=['mrs','mr','miss']\npyplot.bar(group_names, height=db['civilityTitle'].value_counts())\n\n# set x\/y labels and plot title\nplt.pyplot.xlabel(\"civilityTitle\")\nplt.pyplot.ylabel(\"Count\")\nplt.pyplot.title(\"civilityTitle Bins\")","cf581b51":"df_group_one = db[['civilityTitle','productsBought','productsSold']]\ndf_group_one = df_group_one.groupby(['civilityTitle'],as_index=False).agg([np.sum,np.mean])\ndf_group_one","8f48db57":"%matplotlib inline\nimport matplotlib as plt\nfrom matplotlib import pyplot\ngroup_names=['en', 'fr', 'it', 'de', 'es']\nq=pyplot.bar(group_names, db['language'].value_counts())\n\n# set x\/y labels and plot title\nplt.pyplot.xlabel(\"language using on the site\")\nplt.pyplot.ylabel(\"Count\")\nplt.pyplot.title(\"language Bins\")","83b2614a":"df_group_three = db[['language','productsBought','productsSold']]\ndf_group_three = df_group_three.groupby(['language'],as_index=False).agg([np.sum,np.mean])\ndf_group_three","790daab7":"import seaborn as sns\nsns.countplot(x='language',data=db,hue='civilityTitle') ","ea271213":"repeat_columns = []\n# unused and repeated metadata are dropped\nrepeat_columns += ['identifierHash', 'type','country','gender','civilityTitle']\ndb1=db.drop(repeat_columns,axis=1)\ndb1.head()","8bafc894":"from sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\n\nstring_columns = ['language','countryCode','hasAnyApp','hasAndroidApp','hasIosApp','hasProfilePicture']\n\nfor var in string_columns:\n    var_cat = db[[var]] #use double brakets to make sure i'm taking a dataframe \n    var_cat_encoded = ordinal_encoder.fit_transform(var_cat)\n    var_cat_df = pd.DataFrame(var_cat_encoded)\n    var_cat_df.columns = [var + '_encoded'] \n    db1 = db1.merge(var_cat_df, how = 'inner', left_index = True, right_index = True)\n\ndb2 = db1.drop(string_columns, axis = 1)\ndb2.head()\ndb2.info()","c1cc44fb":"import seaborn as sns\na=sns.heatmap(db2.corr()) \na.set_title('Heatmap of Correlation Matrix for All Users', fontsize = 20)","bc1ee72b":"#remove variables with no correlations\nno_columns=['seniority','seniorityAsMonths','seniorityAsYears']\n\ndb3 = db2.drop(no_columns, axis = 1)","a7d5fd24":"sns.pairplot(db3) # Parplot helps to get one to one relation between all attributes in dataset","17bac6ac":"print(\"Original dataset before filtering\", db.shape)\nprint(\"Remainging data after filtering variables with no correlations:\\n\",db3.shape)\ndb_final = db3.sample(frac = 0.3)\nprint(\"\\n Final shrinking columns: \\n\",db_final.columns)\nprint(\"\\n Final shrinking data: \\n\",db_final.shape)","514c2af8":"import matplotlib.pyplot as plt\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import AgglomerativeClustering\nfig = plt.figure(figsize = (11, 8))\ndendogram = sch.dendrogram(sch.linkage(db_final,method = 'ward'))","7f4a05a7":"# using Jeffrey's Helpers to filter dataframes \n\ndef helper_has_fields_compared_to(df, columns, target, what, operator):\n   \n    #Helper to compare several columns to the same value.\n\n    col = columns[0]\n    if operator == '>':\n        res = (df[col] > target)\n    elif operator == '>=':\n        res = (df[col] >= target)\n    elif operator == '<=':\n        res = (df[col] <= target)\n    elif operator == '<':\n        res = (df[col] < target)\n    elif operator == '==':\n        res = (df[col] == target)\n    elif operator == '!=':\n        res = (df[col] != target)  \n    for col in columns[1:]:\n        if operator == '>':\n            tmp = (df[col] > target)\n        elif operator == '>=':\n            tmp = (df[col] >= target)\n        elif operator == '<=':\n            tmp = (df[col] <= target)\n        elif operator == '<':\n            tmp = (df[col] < target)\n        elif operator == '==':\n            tmp = (df[col] == target)\n        elif operator == '!=':\n            tmp = (df[col] != target)\n        if what == 'all':\n            res = res & tmp\n        elif what in ['any']:\n            res = res | tmp\n    return res\n\ndef helper_has_any_field_greater_than(df, columns, target):\n    #Returns lines of the dataframe where any of value of the specified columns is greater than the target.\n    res = helper_has_fields_compared_to(df, columns, target, 'any', '>')\n    return res\n\ndef helper_has_any_field_smaller_than(df, columns, target):\n    #Returns lines of the dataframe where any of value of the specified columns is smaller than the target.\n    res = helper_has_fields_compared_to(df, columns, target, 'any', '<')\n    return res\n\ndef helper_has_all_field_greater_than(df, columns, target):\n    #Returns lines of the dataframe where all of value of the specified columns is smaller than the target.\n    res = helper_has_fields_compared_to(df, columns, target, 'all', '>')\n    return res\n\ndef helper_has_all_field_smaller_than(df, columns, target):\n    #Returns lines of the dataframe where all of value of the specified columns is smaller than the target.\n    res = helper_has_fields_compared_to(df, columns, target, 'all', '<')\n    return res\n\ndef helper_has_all_field_equal_to(df, columns, target):\n    #Returns lines of the dataframe where all of value of the specified columns is equal to the target.\n    res = helper_has_fields_compared_to(df, columns, target, 'all', '==')\n    return res","41eea7ba":"# Total Users\nprint(f\"Total users: {db3.shape[0]} records with {db3.shape[1]} columns\")\n\n# Inactive Users\nInactive_db=db3[helper_has_all_field_smaller_than(db3,['socialProductsLiked', 'productsListed',\n      'productsPassRate', 'productsWished', 'productsListed','productsSold','productsBought'],1)]\nInactive_db.dataframeName = \"Inactive Users\"\nprint(f\"Inactive users: {Inactive_db.shape[0]} records with {Inactive_db.shape[1]} columns\")\n#Inactive_db.sample(12)\n\n# Active Users\nActive_db=db3[helper_has_any_field_greater_than(db3,['socialProductsLiked', 'productsListed',\n      'productsPassRate', 'productsWished', 'productsListed','productsSold','productsBought'],0)]\nInactive_db.dataframeName = \"Active Users\"\nprint(f\"Active users: {Active_db.shape[0]} records with {Active_db.shape[1]} columns\")\n","a6baeb25":"# Actual Users with at least one bought or sold\nUsers_db = db3[helper_has_any_field_greater_than(db3,['productsSold','productsBought'],0)]\nprint(f\"Actual Users: {Users_db.shape[0]} \")\n#Users_db.sample(12)\n\n# Active Actual Users with social interaction except transaction\nAActive_db = Users_db[helper_has_any_field_greater_than(Users_db,['socialProductsLiked', 'productsListed',\n       'productsPassRate', 'productsWished'], 0)]\nAActive_db.dataframeName = \"Active Actual Users\"\nprint(f\"Actal Active Users: {AActive_db.shape[0]}\")\n#Active_db.sample(12)\n\n## Actual Buyers\nbuyers_db = db3[db3.productsBought > 0]\nbuyers_db.dataframeName = \"Buyers\"\nprint(\"Actual buyers: \", buyers_db.shape[0])\n\n\n## Sellers\nsellers_db = db3[(db3.productsListed > 0) | (db3.productsSold > 0)]\nsellers_db.dataframeName = \"Prospecting Sellers\"\nprint(\"Prospecting sellers: \",sellers_db.shape[0])\n\n### actual sellers (at least 1 product sold)\nsuccessful_sellers_db = db3[db3.productsSold > 0]\nsuccessful_sellers_db.dataframeName = \"Actual sellers\"\nprint(\"Actual sellers: \", successful_sellers_db.shape[0])\n\n# Social Users with no transaction but social interaction\n#by looking at the data, we could easily conclude that \n# each new account is automatically assigned 3 followers and 8 accounts to follow\nsocial_db = db3[ (db3['socialNbFollowers'] != 3) | (db3['socialNbFollows'] != 8) ]\nsocial_db1=social_db[helper_has_all_field_smaller_than(social_db,['productsSold','productsBought'],1)]\n#Among those social users, filter only those active on products \nmarket_social_db = social_db1[helper_has_any_field_greater_than(social_db1, ['socialProductsLiked', 'productsListed',\n       'productsPassRate', 'productsWished'], 0)]\nprint(f\"Potential Social Users: {market_social_db.shape[0]}\")\n#market_social_db.sample(12)","b102280e":"print(f\"\"\"In average, buyers buy {buyers_db.productsBought.sum() \/ buyers_db.shape[0] :.2f} products. Details are as follows:\"\"\")\n\n#successful buyers\nSbuyers_db = db3[db3.productsBought >= 3]\nSbuyers_db.dataframeName = \"SBuyers\"\nprint(\"Accordingly, Successful buyers: \", Sbuyers_db.shape[0])\nbuyers_db.productsBought.describe()","92d6270a":"#include= ['socialNbFollowers','socialNbFollows', 'productsWished','socialProductsLiked']\nSbuyers_db.socialNbFollowers.describe()","f550da2f":"print(f\"\"\"In average, actual sellers sell {successful_sellers_db.productsSold.sum() \/ successful_sellers_db.shape[0] :.2f} products. Details are as follows:\"\"\")\n#successful sellers\nSsellers_db = db3[db3.productsSold >= 6]\nSsellers_db.dataframeName = \"SSellers\"\nprint(\"Accordingly, Successful sellers: \", Ssellers_db.shape[0])\nsuccessful_sellers_db.productsSold.describe()","11e13548":"productsH_db = db3[db3.productsPassRate >= 90]\nproductsH_db.dataframeName = \"Best quality's store\"\nprint(\"Numbers of sellers with the highest quality: \", productsH_db.shape[0])\n\nproductsMh_db = db3[(db3.productsPassRate >= 80) & (db3.productsPassRate < 90)]\nproductsMh_db.dataframeName = \"medium-high quality's store\"\nprint(\"Numbers of sellers with the Medium-high quality: \", productsMh_db.shape[0])\n\nproductsS_db = db3[(db3.productsPassRate >= 60) &  (db3.productsPassRate < 80)]\nproductsS_db.dataframeName = \"Standard qualisty's store\"\nprint(\"Numbers of sellers with the stadard quality: \", productsS_db.shape[0])\n\nproductsU_db = db3[(db3.productsPassRate < 60) &  (db3.productsPassRate > 0)]\nproductsU_db.dataframeName = \"Unqualified store\"\nprint(\"Numbers of sellers with low quality: \", productsU_db.shape[0]+\n      (successful_sellers_db.shape[0]-productsH_db.shape[0]-productsMh_db.shape[0]-productsS_db.shape[0]-productsU_db.shape[0]))","1f2d51c0":"print(f\"\"\"In average, active low quality sellers sell {productsU_db.productsSold.sum() \/ sellers_db.shape[0] :.2f} \"\"\")\nprint(f\"\"\"In average, active standard quality sellers sell {productsS_db.productsSold.sum() \/ sellers_db.shape[0] :.2f} \"\"\")\nprint(f\"\"\"In average, active medium-high quality sellers sell {productsMh_db.productsSold.sum() \/ sellers_db.shape[0] :.2f} \"\"\")\nprint(f\"\"\"In average, active high quality sellers sell {productsH_db.productsSold.sum() \/ sellers_db.shape[0] :.2f} products. Details are as follows:\"\"\")\nproductsH_db.productsSold.describe()","3db9f7a2":"Although single female is the smallest group of users, its buying power is the highest","da9a84a6":"### Products\n% of products meeting the product description. (Sold products are reviewed by the store's team before being shipped to the buyer.)\nHere, we used variable productsPassRate, the percentage of products meeting the product description (The\nstore's team reviews sold products before being shipped to the buyer.) as a critical metric. We defined sellers\nwith product pass rate greater than and equal to 90% as sellers with the highest quality, sellers with product\npass rate greater than and equal to 80% and smaller than 90% as sellers with the medium-high quality, sellers\nwith product pass rate greater than and equal to 60% and smaller than 80% as sellers with the standard quality,\nsellers with product pass rate smaller than 60% as sellers with low quality. ","881d115a":"Customer retention:\n70% actual users are active users that have social interaction, these are the group of people that the website should value the most. It also implies that having social connection between sellers and buyers improve the loyalty of users.\n3679 users have high potential to transform as actual users since they have strong social interaction.","5f3bf034":"variable daysSinceLastLogin & hasProfilePicture: seem to be negatively correlated to every other variable. However, only 1.95% users did not have profile picture.\n\nvariable socialNbFollowers &socialNBFollows & socialproductsLiked & productsListed & productsSold & productsPassRate & productsWished seem to positively related to each other.\n\nvariable seniority seem to be uncorrelated with every other variable.\n\nvariable language and country seem to be negatively correlated, have week correlation with variable hasAnyApp & hasIosApp & hasAndroidApp; but have almost no correation with other variables. For now, we could keep these variables for further analysis.","41839738":"# IMPORT DATA","e2cc42e2":"## 4. Sample choosing for dendogram\nSince this dataset is too large for drawing dendrogram, we could choose 30% of the data randomly.","84a996db":"Most of the users did not use the mobile app","cd6e9122":"# Data Pre-visualization\nFinding the related attributes for further analysis using correlation matrix","298b8b25":"## 1. Remove variables","19cd78fd":"# DATA CLEANING \n   1. Check missing values and the skewness of the data\n   2. Data pre-visualization","5c19f38e":"## 3. Correlation matrix","1351aeab":"Users with mobile app have sightly higher buying power;\nBuyers without mobile app tend to have slightly higher selling power","09e393d7":"countplot tells us that there are more married females users globally.","944a5a7d":"## 2. Encode variables","8cc9c70b":"# Segement the users\nDetermine the number of recommended clusters by using a dendogram:\n   1. Remove redundant variable identifier hash: since this is unique for each row of data\n   \n        & variable type: since this remains the same for all data\n\n        & variable country: since we could use the countryCode for analysis\n        \n        & variable gender & civilityTitle: since we could use civilityGenderId for analysis\n   \n   2. Encode string variable language, and countryCode; and boolean variables\n   \n   3. Draw the correlation matrix of filtered dataset\n   \n   4. Sample choosing for agglomerative dendogram drawing\n   \n   5. Define filter function","5a1db71d":"Basic information of users ","b0cc288b":"According to the dendrogram plot, the numbers of recommended clusters would be two.\nWe could then segment users into two main clusters(Active\/Inactive).\nHowever, it also seems that we group the data into smaller clusters.","0d0c2e56":"Users' first prefer language is English, and the second one is French\nHowever, they did not have the highest average productsBought and productsSold.","8e30b854":"### Active Users","1040250b":"The higher the productsPassRate, the higher the chance the store got higher sell. It also implies that the store's regulation on passing products is good.\nWe computed the average products sold for sellers with different product quality. We could\nconclude that the higher the products' pass rate, the higher the chance the store got a higher sale.\nIt also implies that this site's regulation on passing products is good enough for buyers to be\nsatisfied with the product the site passed.\n","42d7d5fc":"Married women seem to be the most active users on this site","286777f8":"## 2. Data pre-visualiztion","90c3f654":"## 5. Define filter function","87316250":"## 1. Data checking"}}