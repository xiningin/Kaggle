{"cell_type":{"ded3fbee":"code","106514d9":"code","7d2a622d":"code","fb124b7b":"code","22dfc691":"code","6796c289":"code","f4c4f266":"code","92356ed5":"code","6c1604e9":"code","4f992d8f":"code","0895090f":"code","ae00b2e9":"code","ead5cd9b":"code","bb517a9e":"code","bfaf7750":"code","4cfce642":"code","22e31c15":"code","1aed0c7f":"code","458feeb2":"code","61ca7dcf":"code","8fc915f6":"code","65ac1a44":"code","a9523f11":"code","782331e7":"code","a57aa744":"code","8d13c392":"code","544118ec":"code","aaacd050":"code","7903fe7d":"code","1572b6f3":"code","253cd57a":"code","801741e6":"code","ffdab10c":"code","a2b41fd7":"code","4005b31a":"code","564ad6fc":"code","2ee237ce":"code","47110445":"code","ce253ddb":"code","545b329d":"code","2ff5e2c2":"code","080add6c":"code","f98b96c5":"code","97437bef":"code","bb281cb7":"code","583b09e2":"code","879d5465":"code","1ef00471":"code","4c07cbf5":"code","f9098e6c":"code","e5fecb3b":"code","f9b34cc5":"markdown","47dac146":"markdown","0380a213":"markdown","e0ab2d46":"markdown","f0af9d84":"markdown","c5f319f2":"markdown","75b0f8ab":"markdown","693d6583":"markdown","545d5378":"markdown","1a17a0c0":"markdown","66ca24a3":"markdown","7177528a":"markdown","40ff7d78":"markdown","5da58c90":"markdown","0660bad3":"markdown","2966a5e0":"markdown","f150f573":"markdown","bab47ff9":"markdown","3630cbe2":"markdown","999f90ed":"markdown","710efa45":"markdown","4d20745a":"markdown","a6eb0c66":"markdown","2b25bba1":"markdown","6faa7e9e":"markdown","6f3d0798":"markdown","e7031a3b":"markdown","76edf126":"markdown","db279c47":"markdown","640295b3":"markdown","378c8427":"markdown","2f3e3f1f":"markdown","37eb9837":"markdown","c6161a65":"markdown","824cfee6":"markdown","8b5e5e38":"markdown","751e5ce7":"markdown","d5eb03bf":"markdown","92d61fba":"markdown","5e3f1f5b":"markdown","e36219ba":"markdown","42a172ec":"markdown","954fa40f":"markdown","24bcf0c0":"markdown","813ad5fd":"markdown","41313ea0":"markdown","f48d2d67":"markdown","9ed422eb":"markdown","6c3a1e8e":"markdown","5929df37":"markdown","02422df6":"markdown","f689d475":"markdown","fbdea0e6":"markdown","48fbf7f2":"markdown","4cb08d41":"markdown","9a7d364e":"markdown","42e0fc54":"markdown","11a483c8":"markdown","69980ab9":"markdown","3197e036":"markdown","b53a8336":"markdown","2ed63f79":"markdown","933851be":"markdown","9785c56f":"markdown","23fe860b":"markdown","5f8553e9":"markdown","3b0e1685":"markdown","7d4a09a0":"markdown","30b2e28c":"markdown","9d57a1f0":"markdown","f691b933":"markdown","98124f56":"markdown","bd140df7":"markdown"},"source":{"ded3fbee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n!pip install openpyxl\n!pip install statmodels\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy as sp\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 14})\n\nimport re, datetime, openpyxl\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\nsample_us_state_abbrev = [\"AZ\", \"CA\", \"CT\", \"DC\", \"FL\", \"IL\", \"IN\", \"MA\", \"MI\", \"MN\", \"MO\", \"NH\", \\\n        \"NJ\", \"NY\", \"NC\", \"ND\", \"OH\", \"TN\", \"TX\", \"UT\", \"VA\", \"WA\", \"WI\"]","106514d9":"districts_info_raw = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\n\n# Drop observation which does not contain state information\ndistricts_info = districts_info_raw[districts_info_raw.state.notna()].reset_index(drop=True)\n\n# Rename columns\ndistricts_info.columns = ['leaid', 'state', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'connection_ratio', 'pp_totexp']\n\n# Add a column for state name abbreviation\ndistricts_info['st'] = districts_info['state'].apply(lambda x: us_state_abbrev[str(x)])\n\n# Add a column for region of each states based on Census Regions\n# NE, MW, S, W order\nregion = [['NH', 'MA', 'CT', 'NY', 'NJ', 'PA'], ['OH', 'MI', 'WI', 'IL', 'MN', 'ND', 'MO', 'IN'], ['DC', 'VA', 'NC', 'TN', 'FL', 'TX'], ['AZ', 'UT', 'CA', 'WA' ]]\ndistricts_info['region'] = districts_info['st'].apply(lambda x: 'NE' if x in region[0] else ('MW' if x in region[1] else ('S' if x in region[2] else 'W')))\n\n# Convert categorical column into CategoricalDtype\ndistricts_info['region'] = districts_info['region'].astype(pd.api.types.CategoricalDtype(list(districts_info['region'].unique())))\ndistricts_info['locale'] = districts_info['locale'].astype(pd.api.types.CategoricalDtype(list(districts_info['locale'].unique())))\n\n# Convert interval data into single value\ndistricts_info['blkhis_ratio'] = districts_info['blkhis_ratio'].apply(lambda x: float(str(x).split(',')[0][1:]) if str(x) != 'nan' else np.nan)\ndistricts_info['freereduced_ratio'] = districts_info['freereduced_ratio'].apply(lambda x: float(str(x).split(',')[0][1:]) if str(x) != 'nan' else np.nan)\ndistricts_info['connection_ratio'] = districts_info['connection_ratio'].apply(lambda x: float(str(x).split(',')[0][1:]) if str(x) != 'nan' else np.nan)\ndistricts_info['pp_totexp'] = districts_info['pp_totexp'].apply(lambda x: int(str(x).split(',')[0][1:]) if str(x) != 'nan' else np.nan)\n\n# Convert pp_totexp into 6 categories (delta: 4000)\ndistricts_info['pp_totexp_raw'] = districts_info['pp_totexp']\ndistricts_info['pp_totexp'] = districts_info['pp_totexp'].apply(lambda x: 4000 if x<=6000 else (x if ((8000 <= x) & (x < 18000)) else (18000 if x>=18000 else np.nan)))\n\nprint(f'There are {len(districts_info_raw)} of districts, while \\\n{len(districts_info_raw[districts_info_raw.state.isna()])} have dropped due to missing values.\\n')\nprint(f'Distributions of connection_ratio: ')\nprint(districts_info_raw['county_connections_ratio'].value_counts(),'\\n')\ndistricts_info.head()","7d2a622d":"PATH = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \nengagement_raw = pd.DataFrame()\n\nfor district in districts_info.leaid.unique():\n    df = pd.read_csv(f'{PATH}\/{district}.csv', index_col=None, header=0)\n    df['leaid'] = district\n    \n    # Dropped data whose engagement index is np.nan\n    df = df[df.engagement_index.notna()].reset_index(drop=True)\n    \n    engagement_raw = pd.concat([engagement_raw, df])\n\nengagement_day = engagement_raw #may be drop na??\n\n# Generate `year`, `month`, `day` variables\nengagement_day['year'] = engagement_day['time'].apply(lambda x: int(str(x)[:4]) if str(x) != 'nan' else np.nan)\nengagement_day['month'] = engagement_day['time'].apply(lambda x: int(str(x)[5:7]) if str(x) != 'nan' else np.nan)\nengagement_day['day'] = engagement_day['time'].apply(lambda x: int(str(x)[8:]) if str(x) != 'nan' else np.nan)\nengagement_day['time'] = pd.to_datetime(engagement_day['time'], format='%Y-%m-%d', errors='coerce')\nengagement_day['week'] = engagement_day['time'].dt.week\n\n# Aggregate into `district x product x month` level\nengagement_month = engagement_day.groupby(['year', 'month', 'leaid', 'lp_id'])['pct_access', 'engagement_index'].mean().reset_index()\n\nengagement_month.head()","fb124b7b":"products_info_raw = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\nproducts_info = products_info_raw[['LP ID', 'Product Name', 'Provider\/Company Name', 'Sector(s)',\n       'Primary Essential Function']]\n\n# Split 'Primary Essential Function'\nproducts_info = products_info[products_info['Primary Essential Function'].notna()].reset_index(drop=True) #drop products which has no info\nproducts_info['mainfunction'] = products_info['Primary Essential Function'].apply(lambda x: str(x).split(' - ')[0])\nproducts_info['mainfunction'] = products_info['mainfunction'].astype(pd.api.types.CategoricalDtype(list(products_info['mainfunction'].unique())))\nproducts_info['subfunction'] = products_info['Primary Essential Function'].apply(lambda x: str(x).split(' - ')[0]+\":\"+str(x).split(' - ')[1])\nproducts_info['subfunction'] = products_info['subfunction'].astype(pd.api.types.CategoricalDtype(list(products_info['subfunction'].unique())))\n\n# Generate dummies for each sector\nsectors_dummies = products_info['Sector(s)'].str.get_dummies(sep=\"; \")\nsectors_dummies.columns = [f\"{re.sub(' ', '', x)}\" for x in sectors_dummies.columns]\nproducts_info = products_info.join(sectors_dummies)\nproducts_info.drop(\"Sector(s)\", axis=1, inplace=True)\n\n# Synchronize values in 'Primary Essential Function LEV2'\nproducts_info['subfunction'] = products_info['subfunction'].replace({'LC:Sites, Resources & References' : 'LC:Sites, Resources & Reference'})\nproducts_info.drop(\"Primary Essential Function\", axis=1, inplace=True)\n\n# Rename columns\nproducts_info.columns = ['lp_id', 'product_name', 'provider_name', 'mainfunction', 'subfunction', 'corporate', 'higher', 'prek12']\n\nproducts_info.head()","22dfc691":"infection_raw = pd.read_csv(\"..\/input\/opportunity-insights-real-time-economic-tracker-us\/data\/COVID - State - Daily.csv\")\ninfection_raw = infection_raw[infection_raw['year']==2020]\ninfection_day = infection_raw[['year', 'month', 'day', 'statefips', 'case_count', 'death_count']]\ninfection_day = infection_day.rename(columns = {'case_count': 'cum_cases', 'death_count': 'cum_deaths'})\ninfection_day['date'] = infection_day[['year', 'month', 'day']].apply(lambda x: '-'.join(x.values.astype(str)), axis=\"columns\")\ninfection_day['date'] = pd.to_datetime(infection_day['date'], format='%Y-%m-%d', errors='coerce')\ninfection_day['week'] = infection_day['date'].dt.week\n\n# Convert `statefips` into `st`\ngeoid = pd.read_csv(\"..\/input\/opportunity-insights-real-time-economic-tracker-us\/data\/GeoIDs - State.csv\")\ngeoid = geoid[['statefips', 'stateabbrev', 'state_pop2019']]\ngeoid = geoid.rename(columns = {'stateabbrev': 'st', 'state_pop2019': 'st_pop'})\n# geoid = geoid[['statefips', 'stateabbrev']]\n# geoid = geoid.rename(columns = {'stateabbrev': 'st'})\ninfection_day = pd.merge(infection_day, geoid, on = 'statefips')\ninfection_day = infection_day[infection_day['st'].isin(sample_us_state_abbrev)].reset_index(drop=True)\n\n# Replace '.' as np.nan\ninfection_day['cum_cases'] = infection_day['cum_cases'].apply(lambda x: np.nan if str(x) == \".\" else int(x))\ninfection_day['cum_deaths'] = infection_day['cum_deaths'].apply(lambda x: np.nan if str(x) == \".\" else int(x))\n\n# To construct the monthly data, keep observations which are recorded at the last day of each month\ninfection_day = infection_day.join(infection_day.groupby(['statefips', 'month'])['day'].max(), on=['statefips', 'month'], rsuffix='_max')\ninfection_month = infection_day[(infection_day['day'] == infection_day['day_max']) & (infection_day['year'] == 2020)]\n\n# Compute new cases and death in state x month level\ninfection_month = infection_month.sort_values(by = ['statefips', 'month']).reset_index(drop=True)\ninfection_month['new_cases'] = infection_month.groupby(['statefips'])['cum_cases'].diff()\ninfection_month['new_death'] = infection_month.groupby(['statefips'])['cum_deaths'].diff()\n\ninfection_day = infection_day.sort_values(by = ['statefips', 'month', 'day']).reset_index(drop=True)\ninfection_day['new_cases'] = infection_day.groupby(['statefips'])['cum_cases'].diff()\ninfection_day['new_death'] = infection_day.groupby(['statefips'])['cum_deaths'].diff()\n\n# Rename and cleean dataset\ninfection_day = infection_day.drop(columns = ['day_max'])\ninfection_month = infection_month.drop(columns = ['day_max', 'day', 'date', 'week'])\n\ninfection_month.head()","6796c289":"policy_raw = pd.read_csv(\"..\/input\/uscovidpolicy\/data\/OxCGRT_US_latest.csv\")\npolicy_day = policy_raw[['RegionCode', 'Date', 'C1_School closing', 'C2_Workplace closing', \\\n                    'C3_Cancel public events', 'C4_Restrictions on gatherings', \\\n                    'C5_Close public transport', 'C6_Stay at home requirements', \\\n                    'C7_Restrictions on internal movement', 'C8_International travel controls', \\\n                    'StringencyIndex']]\n\n# Drop national level observation\npolicy_day = policy_day[policy_day['RegionCode'].notna()].reset_index(drop=True)\n\n# Rename columns\npolicy_day.columns = ['st', 'date', 'school', 'work', 'publicEvent', 'gathering', \\\n                  'publicTrans', 'stayHome', 'interMove', 'travelControl', \\\n                  'stringency']\n\n# Generate variables (date)\npolicy_day['st'] = policy_day['st'].apply(lambda x: str(x)[3:5])\npolicy_day['year'] = policy_day['date'].apply(lambda x: int(str(x)[:4]))\npolicy_day['month'] = policy_day['date'].apply(lambda x: int(str(x)[4:6]))\npolicy_day['day'] = policy_day['date'].apply(lambda x: int(str(x)[6:]))\npolicy_day['date'] = pd.to_datetime(policy_day['date'], format='%Y%m%d', errors='coerce')\npolicy_day['week'] = policy_day['date'].dt.week\n\n# Convert flag variable into dummy\nfor var in policy_day.columns[2:10]:\n#     policy[var + '_alter'] =  policy[var].apply(lambda x: 1 if x >= 1 else 0)\n    policy_day[var] =  policy_day[var].apply(lambda x: 1 if x >= 2 else 0)\n\npolicy_day = policy_day.sort_values(by = ['st', 'year', 'month', 'day']).reset_index(drop=True)\npolicy_month = policy_day.groupby(['year', 'month', 'st'])\\\n            ['school', 'work', 'publicEvent', 'gathering', 'publicTrans', 'stayHome', 'interMove', \\\n             'travelControl', 'stringency'].mean().reset_index()\n\npolicy_month.head()","f4c4f266":"main_day = pd.merge(engagement_day, districts_info, on = 'leaid')\nmain_day = pd.merge(main_day, products_info, on = 'lp_id')\nmain_day = pd.merge(main_day, infection_day, on = ['year', 'month', 'day', 'st'])\nmain_day = pd.merge(main_day, policy_day, on = ['year', 'month', 'day', 'st'])\n\nmain_month = pd.merge(engagement_month, districts_info, on = 'leaid')\nmain_month = pd.merge(main_month, products_info, on = 'lp_id')\nmain_month = pd.merge(main_month, infection_month, on = ['year', 'month', 'st'])\nmain_month = pd.merge(main_month, policy_month, on = ['year', 'month', 'st'])\n\nmain_month.head()","92356ed5":"perform = pd.read_csv(\"..\/input\/seda41studentperformance\/seda_geodist_pool_gcs_4.1.csv\")\nperform = perform[perform.gcs_mn_avg_eb.notna()]\nperform = perform[(perform['stateabb'].isin(sample_us_state_abbrev)) & (perform['subcat'] == 'all')].reset_index(drop=True)\nperform['avg_test_score'] = perform['gcs_mn_avg_eb'] - perform['gradecenter'] #unit: grade level\nperform = perform[['sedalea', 'avg_test_score']]\nperform = perform.rename(columns = {'sedalea': 'leaid'})\n\nperform.head()","6c1604e9":"lea_info = pd.read_csv(\"..\/input\/seda41studentperformance\/seda_cov_geodist_pool_4.1.csv\")\nlea_info = lea_info[lea_info.perhsp.notna()].reset_index(drop=True)\nlea_info = lea_info[lea_info['stateabb'].isin(sample_us_state_abbrev)].reset_index()\nlea_info = lea_info[['sedalea', 'perhsp', 'perblk', 'perell', 'perspeced', 'lninc50avgall', 'baplusavgall']]\nlea_info = lea_info.rename(columns={'sedalea': 'leaid'})\nfor var in ['perhsp', 'perblk', 'perell', 'perspeced', 'baplusavgall']:\n    lea_info[var] = lea_info[var].apply(lambda x: x*100)\n\nlea_info.head()","4f992d8f":"#location\nlocale = {1: 'City', 2: 'Suburb', 3: 'Town', 4: 'Rural'}\nccd_location = pd.read_excel('..\/input\/commoncoredatalea1819\/locale_ccd_1819_sch.xlsx', index_col=None, header=0, sheet_name=0, engine='openpyxl')\nccd_location.columns = [str(x).lower() for x in ccd_location.columns]\nccd_location = ccd_location[ccd_location['state'].isin(sample_us_state_abbrev)]\nccd_location['region'] = ccd_location['state'].apply(lambda x: 'NE' if x in region[0] else ('MW' if x in region[1] else ('S' if x in region[2] else 'W')))\nccd_location['locale'] = ccd_location['locale'].apply(lambda x: locale[int(str(x)[:1])])\nccd_location['region'] = ccd_location['region'].astype(pd.api.types.CategoricalDtype(list(ccd_location['region'].unique())))\nccd_location['locale'] = ccd_location['locale'].astype(pd.api.types.CategoricalDtype(list(ccd_location['locale'].unique())))\nccd_location = ccd_location.rename(columns={'state': 'st', 'name': 'leaname', 'stfip': 'fipst'})\nccd_location = ccd_location[['leaid', 'leaname', 'st', 'fipst', 'locale']]\n\n#ethnicity\nccd_enrollment_raw = pd.read_csv(\"..\/input\/commoncoredatalea1819\/enrollment_ccd_1819_sch.csv\")\nccd_enrollment_raw.columns = [str(x).lower() for x in ccd_enrollment_raw.columns]\nccd_enrollment_raw = ccd_enrollment_raw[ccd_enrollment_raw['st'].isin(sample_us_state_abbrev)]\n\nccd_enrollment1 = ccd_enrollment_raw[(ccd_enrollment_raw['total_indicator'] == \\\n                                 'Derived - Education Unit Total minus Adult Education Count') & \\\n                                     (ccd_enrollment_raw['dms_flag'] != 'Missing')]\nccd_enrollment1 = ccd_enrollment1[['leaid', 'student_count']]\n\nccd_enrollment2 = ccd_enrollment_raw[(ccd_enrollment_raw['total_indicator'] == \\\n                                 'Derived - Subtotal by Race\/Ethnicity and Sex minus Adult Education Count') & \\\n                                     ((ccd_enrollment_raw['race_ethnicity'] == 'Black or African American') | \\\n                                      (ccd_enrollment_raw['race_ethnicity'] == 'Hispanic\/Latino'))]\nccd_enrollment2 = ccd_enrollment2.groupby(['leaid', 'race_ethnicity'])['student_count'].sum().reset_index()\nccd_enrollment2 = ccd_enrollment2.pivot_table(index = ['leaid'], columns='race_ethnicity', values='student_count').reset_index()\n\n#free\/reduced lunch\nccd_lunch_raw = pd.read_csv(\"..\/input\/commoncoredatalea1819\/lunch_ccd_sch_033_1819_l_1a_091019.csv\", encoding='cp1252')\nccd_lunch_raw.columns = [str(x).lower() for x in ccd_lunch_raw.columns]\nccd_lunch_raw = ccd_lunch_raw[ccd_lunch_raw['st'].isin(sample_us_state_abbrev)]\n\nccd_lunch = ccd_lunch_raw[(ccd_lunch_raw['data_group'] == 'Free and Reduced-price Lunch Table') &\n                      (ccd_lunch_raw['total_indicator'] == 'Education Unit Total') &\n                      (ccd_lunch_raw['dms_flag'] != 'Missing')]\nccd_lunch = ccd_lunch.groupby(['leaid'])['student_count'].sum().reset_index()\nccd_lunch.columns = ['leaid', 'freereduced']\n\n#expenditure\nPATH = '..\/input\/nerdst2021' \nnerd = pd.DataFrame()\n\nfor district in sample_us_state_abbrev[:11] + sample_us_state_abbrev[12:]: # exclude 'NH'\n    df = pd.read_excel(f'{PATH}\/{district}_1819_final_August_1st_21.xlsx', index_col=None, header=0, sheet_name=0, engine='openpyxl')\n    df = df[['state', 'ncesdistid', 'ncesid', 'ncesenroll', f'pp_total_raw_{district}']]\n    df.columns = ['st', 'leaid', 'schoolid', 'enrollment', 'pp_total_raw']\n    df.leaid = df.schoolid.apply(lambda x: int(str(x)[:7]) if str(x) != 'nan' else np.nan)\n    nerd = pd.concat([nerd, df.groupby(['leaid'])['pp_total_raw'].mean().reset_index()])\n\n#merge into a single dataset\ndist_info = pd.merge(ccd_location, ccd_enrollment1, on = 'leaid')\ndist_info = pd.merge(dist_info, ccd_enrollment2, on = 'leaid')\ndist_info = pd.merge(dist_info, ccd_lunch, on = 'leaid')\ndist_info = pd.merge(dist_info, nerd, on = 'leaid')\n\ndist_info['blkhis_ratio_raw'] = (dist_info['Black or African American'] + dist_info['Hispanic\/Latino']) \/ dist_info['student_count']\ndist_info['freereduced_ratio_raw'] = dist_info['freereduced'] \/ dist_info['student_count']\n\ndist_info['blkhis_ratio'] = dist_info['blkhis_ratio_raw'].apply(lambda x: int(x\/0.2)*0.2 if str(x) != 'nan' else np.nan)\ndist_info['freereduced_ratio'] = dist_info['freereduced_ratio_raw'].apply(lambda x: int(x\/0.2)*0.2 if (str(x) != 'nan') & (x < np.inf) else np.nan)\ndist_info['pp_totexp'] = dist_info['pp_total_raw'].apply(\n    lambda x: 4000 if x < 8000 else(8000 if x < 10000 else(10000 if x < 12000 else(12000 if x < 14000 else(14000 if x < 16000 else(16000 if x<18000 else 18000))))))\n\ndist_info = dist_info[['st', 'locale', 'leaid', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp', 'student_count']]\ndist_info.head()","0895090f":"def q1(x):\n    return x.quantile(0.25)\n\ndef q3(x):\n    return x.quantile(0.75)\n\n# merge school district information with dist_info\nlea_info_merged = pd.merge(lea_info, dist_info, on = 'leaid')\nlea_info_merged = pd.merge(lea_info_merged, perform, on = 'leaid')\nlea_info_collapsed_mean, lea_info_collapsed_median, lea_info_collapsed_min, lea_info_collapsed_max = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n\nsttype1 = ['AZ', 'OH'] #id = ['st', 'locale', 'blkhis_ratio']\nsttype2 = ['CA', 'CT', 'ND', 'NH', 'NY', 'OH'] #id = ['st', 'locale', 'blkhis_ratio', 'freereduced_ratio']\nsttype3 = ['DC', 'MA', 'TN'] #id = ['st', 'locale', 'blkhis_ratio', 'pp_totexp']\nsttype4 = ['FL', 'IL', 'IN', 'MI', 'MN', 'MO', 'NC', 'NJ', 'NY', 'TX', 'UT', 'VA', 'WA', 'WI'] #id = ['st', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp']\n\nagg_var_lea = dict()\n# cols = list()\ngroup_cols = ['st', 'locale', 'leaid', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp']\ncol = list(lea_info_merged.columns)\ncol = [x for x in col if x not in group_cols]\n\n#mean\nfor x in col:\n    agg_var_lea.update({x: 'mean'})\nlea_info_collapsed1 = lea_info_merged[lea_info_merged['st'].isin(sttype1)].groupby(['st', 'locale', 'blkhis_ratio']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed2 = lea_info_merged[lea_info_merged['st'].isin(sttype2)].groupby(['st', 'locale', 'blkhis_ratio', 'freereduced_ratio']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed3 = lea_info_merged[lea_info_merged['st'].isin(sttype3)].groupby(['st', 'locale', 'blkhis_ratio', 'pp_totexp']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed4 = lea_info_merged[lea_info_merged['st'].isin(sttype4)].groupby(['st', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed_mean = pd.concat([lea_info_collapsed1, lea_info_collapsed2])\nlea_info_collapsed_mean = pd.concat([lea_info_collapsed_mean, lea_info_collapsed3])\nlea_info_collapsed_mean = pd.concat([lea_info_collapsed_mean, lea_info_collapsed4])\n\n#median\nfor x in col:\n    agg_var_lea.update({x: 'median'})\nlea_info_collapsed1 = lea_info_merged[lea_info_merged['st'].isin(sttype1)].groupby(['st', 'locale', 'blkhis_ratio']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed2 = lea_info_merged[lea_info_merged['st'].isin(sttype2)].groupby(['st', 'locale', 'blkhis_ratio', 'freereduced_ratio']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed3 = lea_info_merged[lea_info_merged['st'].isin(sttype3)].groupby(['st', 'locale', 'blkhis_ratio', 'pp_totexp']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed4 = lea_info_merged[lea_info_merged['st'].isin(sttype4)].groupby(['st', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed_median = pd.concat([lea_info_collapsed1, lea_info_collapsed2])\nlea_info_collapsed_median = pd.concat([lea_info_collapsed_median, lea_info_collapsed3])\nlea_info_collapsed_median = pd.concat([lea_info_collapsed_median, lea_info_collapsed4])\n\n#min\nfor x in col:\n    agg_var_lea.update({x: q1})\nlea_info_collapsed1 = lea_info_merged[lea_info_merged['st'].isin(sttype1)].groupby(['st', 'locale', 'blkhis_ratio']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed2 = lea_info_merged[lea_info_merged['st'].isin(sttype2)].groupby(['st', 'locale', 'blkhis_ratio', 'freereduced_ratio']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed3 = lea_info_merged[lea_info_merged['st'].isin(sttype3)].groupby(['st', 'locale', 'blkhis_ratio', 'pp_totexp']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed4 = lea_info_merged[lea_info_merged['st'].isin(sttype4)].groupby(['st', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed_min = pd.concat([lea_info_collapsed1, lea_info_collapsed2])\nlea_info_collapsed_min = pd.concat([lea_info_collapsed_min, lea_info_collapsed3])\nlea_info_collapsed_min = pd.concat([lea_info_collapsed_min, lea_info_collapsed4])\n\n#max\nfor x in col:\n    agg_var_lea.update({x: q3})\nlea_info_collapsed1 = lea_info_merged[lea_info_merged['st'].isin(sttype1)].groupby(['st', 'locale', 'blkhis_ratio']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed2 = lea_info_merged[lea_info_merged['st'].isin(sttype2)].groupby(['st', 'locale', 'blkhis_ratio', 'freereduced_ratio']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed3 = lea_info_merged[lea_info_merged['st'].isin(sttype3)].groupby(['st', 'locale', 'blkhis_ratio', 'pp_totexp']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed4 = lea_info_merged[lea_info_merged['st'].isin(sttype4)].groupby(['st', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp']).agg(agg_var_lea).dropna(subset=['student_count']).reset_index()\nlea_info_collapsed_max = pd.concat([lea_info_collapsed1, lea_info_collapsed2])\nlea_info_collapsed_max = pd.concat([lea_info_collapsed_max, lea_info_collapsed3])\nlea_info_collapsed_max = pd.concat([lea_info_collapsed_max, lea_info_collapsed4])\n\nlea_info_collapsed_mean.head()","ae00b2e9":"plots = [['blkhis_ratio', 0, 'Share on Black\/Hispanic Students'], ['freereduced_ratio', 1, 'Share on Eligibility for the Lunch Program'], ['connection_ratio', 2, 'Share on High-Speed Internet Access']]\n\nfig, ax = plt.subplots(1, 3, figsize = (22, 8))\n\nfor plot in plots:\n    labels = list(districts_info[plot[0]].value_counts().sort_index(ascending=False).index)\n    sizes = districts_info[plot[0]].value_counts().sort_index(ascending=False).values\n    explode = []\n    for i in range(len(sizes)):\n        explode.append(0.05)\n    explode = tuple(explode)\n    ax[plot[1]].pie(sizes, explode=explode, labels=labels, startangle=60, autopct='%1.2f%%', pctdistance=0.7, colors=[\"#FFE0AE\",\"#FF4500\",\"#6C8255\",\"#FFA303\"])\n    ax[plot[1]].set_title('Distribution of '+ plot[2], size=15)\n\nplt.show()","ead5cd9b":"plots = [['pp_totexp_raw', 0, 'Total Edu Expenditure per Pupil (raw)'], ['pp_totexp', 1, 'Total Edu Expenditure per Pupil (modified)']]\n\nfig, ax = plt.subplots(1, 2, figsize = (15, 8))\n\nfor plot in plots:\n    labels = list(districts_info[plot[0]].value_counts().sort_index(ascending=False).index)\n    sizes = districts_info[plot[0]].value_counts().sort_index(ascending=False).values\n    explode = []\n    for i in range(len(sizes)):\n        explode.append(0.05)\n    explode = tuple(explode)\n    ax[plot[1]].pie(sizes, explode=explode, labels=labels, startangle=60, autopct='%1.2f%%', pctdistance=0.7, colors=[\"#FFE0AE\",\"#FF4500\",\"#6C8255\",\"#FFA303\"])\n    ax[plot[1]].set_title('Distribution of '+ plot[2], size=15)\n\nplt.show()","bb517a9e":"plots = [['st', 0, 'States'], ['region', 1, 'Census Region of the US'], ['locale', 2, 'Locale']]\n\nfig, ax = plt.subplots(1, 3, figsize = (22, 8))\n\nfor plot in plots:\n    labels = list(districts_info[plot[0]].value_counts(ascending=True).index)\n    sizes = districts_info[plot[0]].value_counts(ascending=True).values\n    explode = []\n    for i in range(len(sizes)):\n        explode.append(0.05)\n    explode = tuple(explode)\n    ax[plot[1]].pie(sizes, explode=explode, labels=labels, startangle=60, autopct='%1.2f%%', pctdistance=0.7, colors=[\"#FFE0AE\",\"#FF4500\",\"#6C8255\",\"#FFA303\"])\n    ax[plot[1]].set_title('Distribution of '+plot[2], size=15)\nplt.show()\n\nsns.displot(data=districts_info.sort_values(['st']), y='st', hue='locale', hue_order=['City', 'Suburb', 'Rural', 'Town'], height=8, aspect=3, multiple='stack')\nplt.show()\n\nfig, ax = plt.subplots(figsize = (22, 8))\ndata = districts_info.groupby(['region', 'locale']).count()\ndata.columns = data.columns.astype(str)\ndata1 = data.groupby(['region'])['st'].sum()\ndata = pd.merge(data.reset_index(), data1.reset_index(), on='region')\ndata['value'] = data['st_x']\/data['st_y']\nsns.barplot(data=data, x='value', y='region', hue='locale', hue_order=['City', 'Suburb', 'Rural', 'Town'])\nplt.show()","bfaf7750":"plots = [['blkhis_ratio', 'freereduced_ratio', 0], ['blkhis_ratio', 'pp_totexp', 1], ['freereduced_ratio', 'pp_totexp', 2]]\nfig, ax = plt.subplots(1, 3, figsize = (22, 8))\n\nfor c in plots:\n    data = districts_info.groupby([c[0], c[1]]).count().st.reset_index(drop=False).fillna(0)\n    data['st'] = data['st'].apply(lambda x: x \/ float(data.st.sum()))\n    data = data.pivot_table(index=c[0], columns=c[1])\n    sns.heatmap(data=data, annot=True, ax = ax[c[2]])\n\nplt.show()","4cfce642":"fig, ax = plt.subplots(1, 2, figsize = (15, 8))\n\nlabels = ['Corporate', 'Higer-Ed', 'PreK-12']\nsizes = [products_info['corporate'].mean()*100, products_info['higher'].mean()*100, products_info['prek12'].mean()*100]\nexplode = (0.05, 0.05, 0.05)\nax[0].pie(sizes, explode=explode, labels=labels, startangle=60, autopct='%1.2f%%', pctdistance=0.7, colors=[\"#FFE0AE\",\"#FF4500\",\"#6C8255\",\"#FFA303\"])\nax[0].set_title('Distribution of Sector of Products', size = 15)\n\nlabels = ['Learning &\\nCurriculum', 'Classroom\\nManagement', 'School & District\\nOperations', 'All']\nsizes = products_info['mainfunction'].value_counts().values\nexplode = (0.05, 0.05, 0.05, 0.05)\nax[1].pie(sizes, explode=explode, labels=labels, startangle=60, autopct='%1.2f%%', pctdistance=0.7, colors=[\"#FFE0AE\",\"#FF4500\",\"#6C8255\",\"#FFA303\"])\nax[1].set_title('Distribution of Main Function of Products', size=15)\nplt.show()\n\nfig, ax = plt.subplots(figsize = (15, 8))\np1=sns.barplot(data=products_info.groupby(['subfunction']).count().reset_index().sort_values(by = ['product_name'], ascending=False), x='product_name', y='subfunction')\np1.set_xlabel(\"# of Products\", fontsize = 10)\np1.set_ylabel(\"Sub Functions\", fontsize = 10)\np1.set_title(\"# of Products by Sub-functions\", fontsize = 15)\nplt.show()","22e31c15":"plots = [['pct_access', 'Access Ratio (Unit: %)'], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)']]\n\nfor p in plots:\n    fig, ax = plt.subplots(1, 2, figsize = (15, 8), sharex=False,sharey=False)\n    fig.suptitle(f'Annual Average of {p[1]} in 2020', fontsize=20)\n    data = main_day.groupby(['lp_id'])[p[0]].mean().reset_index()\n\n    ### histogram\n    ax[0].title.set_text('Distribution')\n    breaks = np.quantile(data, q=np.linspace(0, 1, 11))\n    sns.distplot(data[p[0]], hist=True, kde=True, kde_kws={\"shade\": True}, ax=ax[0])\n    description = data[p[0]].describe()\n    ax[0].axvline(description[\"mean\"], ls='--')\n    ax[0].grid(True)\n    description = round(description, 2).apply(lambda x: str(x))\n    box = '\\n'.join((\"min:\" + description[\"min\"], \"25%:\" + description[\"25%\"], \n                     \"mean:\" + description[\"mean\"], \"75%:\" + description[\"75%\"], \n                     \"max:\" + description[\"max\"]))\n    ax[0].text(0.95, 0.95, box,transform=ax[0].transAxes,fontsize=15, va='top', ha=\"right\",\n               bbox=dict(boxstyle='round', facecolor='white', alpha=1))\n\n    ### boxplot\n    ax[1].title.set_text('Outliers (ln scale)')\n    data[p[0]] = np.log(data[p[0]])\n    data.boxplot(column=p[0],ax=ax[1])\n\n    plt.show()","1aed0c7f":"plots = [['pct_access', 'Access Ratio (Unit: %)'], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)']]\n\nfor p in plots:\n    fig, ax = plt.subplots(1, 3, figsize = (22, 8), sharex=False,sharey=False)\n    fig.suptitle(f'Annual Average {p[1]} in 2020 by Function', fontsize=20)\n    data = main_day.groupby(['lp_id', 'mainfunction'])[p[0]].mean().dropna().reset_index()\n\n    ### distribution\n    ax[0].title.set_text('Distribution')\n    labels = []\n    for i in ['LC', 'CM', 'SDO', 'LC\/CM\/SDO']:\n        sns.distplot(data[data['mainfunction']==i][p[0]], hist=False, label=i, ax=ax[0])\n        labels.append(i)\n    ax[0].legend(labels=labels)\n    ax[0].grid(True)\n\n    ### stacked\n    ax[1].title.set_text('Bins')\n    breaks = np.quantile(data[p[0]], q=np.linspace(0,1,11))\n    tmp = data.groupby(['mainfunction', pd.cut(data[p[0]], breaks, duplicates='drop')]).size().unstack().T\n    tmp = tmp[['LC', 'CM', 'SDO', 'LC\/CM\/SDO']]\n    tmp[\"tot\"] = tmp.sum(axis=1)\n    for col in tmp.drop(\"tot\", axis=1).columns:\n        tmp[col] = tmp[col] \/ tmp[\"tot\"]\n    tmp.drop(\"tot\", axis=1).plot(kind='bar', stacked=True, ax=ax[1], grid=True)\n    \n    ### average bar plots by function\n    ax[2].title.set_text('Average')\n    sns.barplot(data=main_day.groupby(['mainfunction'])[p[0]].mean().reset_index()\n                .sort_values(by = [p[0]], ascending=False), ax=ax[2], y=p[0], x='mainfunction')\n    ax[2].grid(True)\n    plt.show()","458feeb2":"plots = [['pct_access', 'Access Ratio (Unit: %)'], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)']]\n\nfor p in plots:\n    fig, ax = plt.subplots(1, 1, figsize = (22, 8), sharex=False,sharey=False)\n    fig.suptitle(f'Annual Average {p[1]} in 2020 by Subfunction', fontsize=20)\n    data = main_day.groupby(['lp_id', 'subfunction'])[p[0]].mean().reset_index()\n    \n    ### average bar plots by function\n    ax.title.set_text('Average')\n    sns.barplot(data=main_day.groupby(['subfunction'])[p[0]].mean().reset_index()\n                .sort_values(by = [p[0]], ascending=False), x=p[0], y='subfunction')\n    ax.grid(True)\n\n    ### boxplot\n    data[p[0]] = np.log(data[p[0]])\n    g = sns.catplot(data=data, kind=\"box\", y='subfunction', x=p[0])\n    g.set_axis_labels(p[1]+'(ln scale)', 'Subfunction')\n    \n    plt.show()","61ca7dcf":"fig, ax = plt.subplots(1, 2, figsize = (15, 8))\nlabels = ['Learning &\\nCurriculum', 'Classroom\\nManagement', 'School & District\\nOperations', 'All']\nsizes = products_info['mainfunction'].value_counts().values\nexplode = (0.05, 0.05, 0.05, 0.05)\nax[0].pie(sizes, explode=explode, labels=labels, startangle=60, autopct='%1.2f%%', pctdistance=0.7, colors=[\"#FFE0AE\",\"#FF4500\",\"#6C8255\",\"#FFA303\"])\nax[0].set_title('Distribution of Main Function of Products (unweighted)', size=15)\n\ndata = main_day.groupby(['mainfunction'])['engagement_index'].sum().reset_index()\nlabels = ['Learning &\\nCurriculum', 'Classroom\\nManagement', 'School & District\\nOperations', 'All']\nsizes = data['engagement_index']\nexplode = (0.05, 0.05, 0.05, 0.05)\nax[1].pie(sizes, explode=explode, labels=labels, startangle=60, autopct='%1.2f%%', pctdistance=0.7, colors=[\"#FFE0AE\",\"#FF4500\",\"#6C8255\",\"#FFA303\"])\nax[1].set_title('Distribution of Main Function of Products (weighted)', size=15)\nplt.show()","8fc915f6":"plots = [['pct_access', 'Annual Average Access Ratio (Unit: %)', 'Accessed'], \\\n         ['engagement_index', 'Annual Average Engagement Index (Unit: page-loads per 1K students)', 'Engaged']]\n\nfor p in plots:\n    fig, ax = plt.subplots(figsize = (15, 8))\n    plot = sns.barplot(data=main_day.groupby(['product_name'])[p[0]].mean().reset_index().sort_values(by = [p[0]], ascending=False)[:20], x=p[0], y='product_name')\n    plot.set_xlabel(p[1], fontsize = 10)\n    plot.set_ylabel('Product Name', fontsize = 10)\n    plot.set_title(f'Top 20 Most {p[2]} Tools in 2020', fontsize = 15)\n    plt.show()","65ac1a44":"top = [20, 50]\nvar = [['pct_access', 'Access Ratio', 0],['engagement_index', 'Page Loads per 1K students', 1]]\n\nfor t in top:\n    fig, ax = plt.subplots(1, 2, figsize = (15, 8))\n    for v in var:\n        labels = ['Learning &\\nCurriculum', 'Classroom\\nManagement', 'School & District\\nOperations', 'All']\n        sizes = main_day.groupby(['product_name', 'mainfunction'])[v[0]].mean().reset_index().sort_values(by = v[0], ascending=False)[:t].mainfunction.value_counts().values\n        explode = (0.05, 0.05, 0.05, 0.05)\n        ax[v[2]].pie(sizes, explode=explode, labels=labels, startangle=60, autopct='%1.2f%%', pctdistance=0.7, colors=[\"#FFE0AE\",\"#FF4500\",\"#6C8255\",\"#FFA303\"])\n        ax[v[2]].set_title(f'Distribution of Main Function of \\nTop {t} Products ({v[1]})', size = 15)","a9523f11":"plots = [['pct_access', 'Access Ratio (Unit: %)'], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)']]\n\nfor x in [20, 50]:\n    for p in plots:\n        fig, ax = plt.subplots(1, 3, figsize = (22, 8), sharex=False,sharey=False)\n        fig.suptitle(f'Annual Average {p[1]} in 2020 by Function (Top {x})', fontsize=20)\n        data = main_day.groupby(['lp_id', 'mainfunction'])[p[0]].mean().reset_index().sort_values(by = p[0], ascending=False)[:x]\n        \n        ### distribution\n        ax[0].title.set_text('Distribution')\n        labels = []\n        for i in ['LC', 'CM', 'SDO', 'LC\/CM\/SDO']:\n            sns.distplot(data[data['mainfunction']==i][p[0]], hist=False, label=i, ax=ax[0])\n            labels.append(i)\n        ax[0].legend(labels=labels)\n        ax[0].grid(True)\n\n        ### stacked\n        ax[1].title.set_text('Bins')\n        breaks = np.quantile(data[p[0]], q=np.linspace(0,1,11))\n        tmp = data.groupby(['mainfunction', pd.cut(data[p[0]], breaks, duplicates='drop')]).size().unstack().T\n        tmp = tmp[['LC', 'CM', 'SDO', 'LC\/CM\/SDO']]\n        tmp[\"tot\"] = tmp.sum(axis=1)\n        for col in tmp.drop(\"tot\", axis=1).columns:\n            tmp[col] = tmp[col] \/ tmp[\"tot\"]\n        tmp.drop(\"tot\", axis=1).plot(kind='bar', stacked=True, ax=ax[1], grid=True)\n\n        ### average bar plots by function\n        ax[2].title.set_text('Average')\n        ax[2].set_xlabel(plots[0][1], fontsize = 15)\n        ax[2].set_ylabel('Functions', fontsize = 15)\n        sns.barplot(data=data.groupby(['mainfunction'])[p[0]].mean().reset_index()\n                    .sort_values(by = [p[0]], ascending=False), ax=ax[2], y=p[0], x='mainfunction')\n        ax[2].grid(True)\n        plt.show()","782331e7":"plots = [['pct_access', 'Access Ratio (Unit: %)'], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)']]\n\nfor p in plots:\n    ### bin plot\n    data = main_day.groupby(['lp_id'])['new_cases', p[0]].mean().reset_index()\n    breaks = np.quantile(data['new_cases'], q=np.linspace(0, 1, 11))\n    groups = data.groupby([pd.cut(data['new_cases'], bins=breaks, duplicates='drop')])[p[0]].agg(['mean','median','size'])\n    fig, ax = plt.subplots(figsize=(22, 8))\n    fig.suptitle(f'Distribution of {p[1]} by New Covid-19 Cases', fontsize=20)\n    groups[[\"mean\", \"median\"]].plot(kind=\"line\", ax=ax)\n    groups[\"size\"].plot(kind=\"bar\", ax=ax, rot=45, secondary_y=True,\n                        color=\"grey\", alpha=0.3, grid=True)\n    ax.set(ylabel=p[1])\n    ax.right_ax.set_ylabel(\"Observations in each bin\")\n    plt.show()\n\nfor p in plots:\n    data = main_day.groupby(['lp_id'])['new_cases', p[0]].mean().reset_index()\n    ### scatter plot\n    sns.jointplot(x='new_cases', y=p[0], data=data, dropna=True, kind='reg',\n                 height=6)\n    plt.show()","a57aa744":"plots = [['pct_access', 'Access Ratio (Unit: %)'], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)']]\n\nfor p in plots:\n    ### bin plot\n    data = main_day.groupby(['lp_id'])['school', p[0]].mean().reset_index()\n    breaks = np.quantile(data['school'], q=np.linspace(0, 1, 11))\n    groups = data.groupby([pd.cut(data['school'], bins=breaks, duplicates='drop')])[p[0]].agg(['mean','median','size'])\n    fig, ax = plt.subplots(figsize=(22, 8))\n    fig.suptitle(f'Distribution of {p[1]} by School Closure policy', fontsize=20)\n    groups[[\"mean\", \"median\"]].plot(kind=\"line\", ax=ax)\n    groups[\"size\"].plot(kind=\"bar\", ax=ax, rot=45, secondary_y=True,\n                        color=\"grey\", alpha=0.3, grid=True)\n    ax.set(ylabel=p[1])\n    ax.right_ax.set_ylabel(\"Observations in each bin\")\n    plt.show()\n\nfor p in plots:\n    data = main_day.groupby(['lp_id'])['school', p[0]].mean().reset_index()\n    ### scatter plot\n    sns.jointplot(x='school', y=p[0], data=data, dropna=True, kind='reg',\n                 height=6)\n    plt.show()","8d13c392":"plots = [['pct_access', 'Access Ratio (Unit: %)', 0], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)', 1]]\n\nfor p in plots:\n    fig, ax = plt.subplots(1, 3, figsize = (22, 8), sharex=False,sharey=False)\n    fig.suptitle(f'Annual Average {p[1]} in 2020 by Ethnicity', fontsize=20)\n    data = main_day.groupby(['lp_id', 'blkhis_ratio'])[p[0]].mean().reset_index()\n\n    ### distribution\n    ax[0].title.set_text('Distribution')\n    labels = []\n    for i in data['blkhis_ratio'].unique():\n        sns.distplot(data[data['blkhis_ratio']==i][p[0]], hist=False, label=i, ax=ax[0])\n        labels.append(i)\n    ax[0].legend(labels=labels)\n    ax[0].grid(True)\n\n    ### stacked\n    ax[1].title.set_text('Bins')\n    breaks = np.quantile(data[p[0]], q=np.linspace(0,1,11))\n    tmp = data.groupby(['blkhis_ratio', pd.cut(data[p[0]], breaks, duplicates='drop')]).size().unstack().T\n    tmp[\"tot\"] = tmp.sum(axis=1)\n    for col in tmp.drop(\"tot\", axis=1).columns:\n        tmp[col] = tmp[col] \/ tmp[\"tot\"]\n    tmp.drop(\"tot\", axis=1).plot(kind='bar', stacked=True, ax=ax[1], grid=True)\n    \n    ### average bar plots by blkhis_ratio\n    ax[2].title.set_text('Average')\n    sns.barplot(data=main_day.groupby(['blkhis_ratio'])[p[0]].mean().reset_index()\n                .sort_values(by = [p[0]], ascending=False), ax=ax[2], y=p[0], x='blkhis_ratio')\n    ax[2].grid(True)\n    plt.show()\n\n### average bar plots by function x blkhis_ratio\nfig, ax = plt.subplots(1, 2, figsize = (22, 8))\ndata = main_day.groupby(['blkhis_ratio', 'mainfunction']).mean()\ndata.columns = data.columns.astype(str)\n\nfor p in plots:\n    sns.barplot(data=data.reset_index(), x='mainfunction', ax=ax[p[2]], y=p[0], hue='blkhis_ratio')\n    ax[p[2]].title.set_text(p[1])\nplt.show()","544118ec":"plots = [['pct_access', 'Access Ratio (Unit: %)', 0], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)', 1]]\n\nfor p in plots:\n    fig, ax = plt.subplots(1, 3, figsize = (22, 8), sharex=False,sharey=False)\n    fig.suptitle(f'Annual Average {p[1]} in 2020 by Economic Status', fontsize=20)\n    data = main_day.groupby(['lp_id', 'freereduced_ratio'])[p[0]].mean().reset_index()\n\n    ### distribution\n    ax[0].title.set_text('Distribution')\n    labels = []\n    for i in data['freereduced_ratio'].unique():\n        sns.distplot(data[data['freereduced_ratio']==i][p[0]], hist=False, label=i, ax=ax[0])\n        labels.append(i)\n    ax[0].legend(labels=labels)\n    ax[0].grid(True)\n\n    ### stacked\n    ax[1].title.set_text('Bins')\n    breaks = np.quantile(data[p[0]], q=np.linspace(0,1,11))\n    tmp = data.groupby(['freereduced_ratio', pd.cut(data[p[0]], breaks, duplicates='drop')]).size().unstack().T\n    tmp[\"tot\"] = tmp.sum(axis=1)\n    for col in tmp.drop(\"tot\", axis=1).columns:\n        tmp[col] = tmp[col] \/ tmp[\"tot\"]\n    tmp.drop(\"tot\", axis=1).plot(kind='bar', stacked=True, ax=ax[1], grid=True)\n    \n    ### average bar plots by freereduced_ratio\n    ax[2].title.set_text('Average')\n    sns.barplot(data=main_day.groupby(['freereduced_ratio'])[p[0]].mean().reset_index()\n                .sort_values(by = [p[0]], ascending=False), ax=ax[2], y=p[0], x='freereduced_ratio')\n    ax[2].grid(True)\n    plt.show()\n\n### average bar plots by function x freereduced_ratio\nfig, ax = plt.subplots(1, 2, figsize = (22, 8))\ndata = main_day.groupby(['freereduced_ratio', 'mainfunction']).mean()\ndata.columns = data.columns.astype(str)\n\nfor p in plots:\n    sns.barplot(data=data.reset_index(), x='mainfunction', ax=ax[p[2]], y=p[0], hue='freereduced_ratio')\n    ax[p[2]].title.set_text(p[1])\nplt.show()","aaacd050":"plots = [['pct_access', 'Access Ratio (Unit: %)', 0], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)', 1]]\n\nfor p in plots:\n    fig, ax = plt.subplots(1, 3, figsize = (22, 8), sharex=False,sharey=False)\n    fig.suptitle(f'Annual Average {p[1]} in 2020 by Education Expenditure per pupil', fontsize=20)\n    data = main_day.groupby(['lp_id', 'pp_totexp'])[p[0]].mean().reset_index()\n\n    ### distribution\n    ax[0].title.set_text('Distribution')\n    labels = []\n    for i in data['pp_totexp'].unique():\n        sns.distplot(data[data['pp_totexp']==i][p[0]], hist=False, label=i, ax=ax[0])\n        labels.append(i)\n    ax[0].legend(labels=labels)\n    ax[0].grid(True)\n\n    ### stacked\n    ax[1].title.set_text('Bins')\n    breaks = np.quantile(data[p[0]], q=np.linspace(0,1,11))\n    tmp = data.groupby(['pp_totexp', pd.cut(data[p[0]], breaks, duplicates='drop')]).size().unstack().T\n    tmp[\"tot\"] = tmp.sum(axis=1)\n    for col in tmp.drop(\"tot\", axis=1).columns:\n        tmp[col] = tmp[col] \/ tmp[\"tot\"]\n    tmp.drop(\"tot\", axis=1).plot(kind='bar', stacked=True, ax=ax[1], grid=True)\n    \n    ### average bar plots by pp_totexp\n    ax[2].title.set_text('Average')\n    sns.barplot(data=main_day.groupby(['pp_totexp'])[p[0]].mean().reset_index()\n                .sort_values(by = [p[0]], ascending=False), ax=ax[2], y=p[0], x='pp_totexp')\n    ax[2].grid(True)\n    plt.show()\n\n### average bar plots by function x pp_totexp\nfig, ax = plt.subplots(1, 2, figsize = (22, 8))\ndata = main_day.groupby(['pp_totexp', 'mainfunction']).mean()\ndata.columns = data.columns.astype(str)\n\nfor p in plots:\n    sns.barplot(data=data.reset_index(), x='mainfunction', ax=ax[p[2]], y=p[0], hue='pp_totexp')\n    ax[p[2]].title.set_text(p[1])\nplt.show()","7903fe7d":"plots = [['pct_access', 'Access Ratio (Unit: %)', 0], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)', 1]]\n\nfor p in plots:\n    fig, ax = plt.subplots(1, 3, figsize = (22, 8), sharex=False,sharey=False)\n    fig.suptitle(f'Annual Average {p[1]} in 2020 by Locale', fontsize=20)\n    data = main_day.groupby(['lp_id', 'locale'])[p[0]].mean().reset_index()\n\n    ### distribution\n    ax[0].title.set_text('Distribution')\n    labels = []\n    for i in data['locale'].unique():\n        sns.distplot(data[data['locale']==i][p[0]], hist=False, label=i, ax=ax[0])\n        labels.append(i)\n    ax[0].legend(labels=labels)\n    ax[0].grid(True)\n\n    ### stacked\n    ax[1].title.set_text('Bins')\n    breaks = np.quantile(data[p[0]], q=np.linspace(0,1,11))\n    tmp = data.groupby(['locale', pd.cut(data[p[0]], breaks, duplicates='drop')]).size().unstack().T\n    tmp[\"tot\"] = tmp.sum(axis=1)\n    for col in tmp.drop(\"tot\", axis=1).columns:\n        tmp[col] = tmp[col] \/ tmp[\"tot\"]\n    tmp.drop(\"tot\", axis=1).plot(kind='bar', stacked=True, ax=ax[1], grid=True)\n    \n    ### average bar plots by locale\n    ax[2].title.set_text('Average')\n    sns.barplot(data=main_day.groupby(['locale'])[p[0]].mean().reset_index()\n                .sort_values(by = [p[0]], ascending=False), ax=ax[2], y=p[0], x='locale')\n    ax[2].grid(True)\n    plt.show()\n    \n### average bar plots by function x locale\nfig, ax = plt.subplots(1, 2, figsize = (22, 8))\ndata = main_day.groupby(['locale', 'mainfunction']).mean()\ndata.columns = data.columns.astype(str)\n\nfor p in plots:\n    sns.barplot(data=data.reset_index(), x='mainfunction', ax=ax[p[2]], y=p[0], hue='locale')\n    ax[p[2]].title.set_text(p[1])\nplt.show()","1572b6f3":"plots = [['pct_access', 'Access Ratio (Unit: %)', 0], ['engagement_index', 'Engagement Index (Unit: page-loads per 1K students)', 1]]\n\nfor p in plots:\n    fig, ax = plt.subplots(1, 3, figsize = (22, 8), sharex=False,sharey=False)\n    fig.suptitle(f'Annual Average {p[1]} in 2020 by Region', fontsize=20)\n    data = main_day.groupby(['lp_id', 'region'])[p[0]].mean().dropna().reset_index()\n\n    ### distribution\n    ax[0].title.set_text('Distribution')\n    labels = []\n    for i in ['MW', 'W', 'S', 'NE']:\n        sns.distplot(data[data['region']==i][p[0]], hist=False, label=i, ax=ax[0])\n        labels.append(i)\n    ax[0].legend(labels=labels)\n    ax[0].grid(True)\n\n    ### stacked\n    ax[1].title.set_text('Bins')\n    breaks = np.quantile(data[p[0]], q=np.linspace(0,1,11))\n    tmp = data.groupby(['region', pd.cut(data[p[0]], breaks, duplicates='drop')]).size().unstack().T\n    tmp[\"tot\"] = tmp.sum(axis=1)\n    for col in tmp.drop(\"tot\", axis=1).columns:\n        tmp[col] = tmp[col] \/ tmp[\"tot\"]\n    tmp.drop(\"tot\", axis=1).plot(kind='bar', stacked=True, ax=ax[1], grid=True)\n    \n    ### average bar plots by census region\n    ax[2].title.set_text('Average')\n    sns.barplot(data=main_day.groupby(['region'])[p[0]].mean().reset_index()\n                .sort_values(by = [p[0]], ascending=False), ax=ax[2], y=p[0], x='region')\n    ax[2].grid(True)\n    plt.show()\n    \n### average bar plots by function x census region\nfig, ax = plt.subplots(1, 2, figsize = (22, 8))\ndata = main_day.groupby(['region', 'mainfunction']).mean()\ndata.columns = data.columns.astype(str)\n\nfor p in plots:\n    sns.barplot(data=data.reset_index(), x='mainfunction', ax=ax[p[2]], y=p[0], hue='region')\n    ax[p[2]].title.set_text(p[1])\nplt.show()","253cd57a":"# For x-axis labels\nmonth={1: (4, ''), 2: (6,'Feb'), 3: (10,'Mar'),\n      4: (15,'Apr'), 5: (19,'May'),6: (23, 'Jun'),\n      7: (28,'Jul'), 8: (32,'Aug'), 9: (37,'Sep'),\n      10: (41,'Oct'), 11: (45,'Nov'), 12: (50,'Dec')}\nxticks = [i+4 for i in range(50)]\nxtick_label = ['' for i in range(50)]\nfor i in range(12):\n    xtick_label[int(month[i+1][0])-4] = month[i+1][1]\n\n# Covid-19 trends\ndata2 = infection_day.groupby(['week']).agg({'new_cases': 'sum'}).reset_index()\n\n#for policy dependent background\ndata3 = policy_day.groupby(['week']).agg({'school': 'mean'}).reset_index()\ndata2['background'] = data3['school'].apply(lambda x: 0 if x<0.50 else (1 if x<0.75 else 2)) #50%, 75%\ndata2['tmp'] = data2['background'].diff().apply(lambda x: 1 if (str(x) == 'nan') or (x != 0) else 0)\ntmp = data2[data2['tmp'] == 1]\ntmp['background_new'] = np.nan\nfor i in range(len(tmp)):\n    tmp['background_new'].iloc[i] = i\ndata2 = pd.concat([data2, tmp['background_new']], axis=1).fillna(method='ffill')\nranges = data2.groupby('background_new').agg({'week': ['min', 'max'], 'background': 'mean'})\nranges['label'] = ranges.index\nranges['label'] = ranges['label'].apply(lambda x: 0 if x in [0, 1, 3] else 1)\nlabels_background = {0: '<50% school closed', \n                     1: '50-75% school closed',\n                     2: '>=75% closure policy adopted'}","801741e6":"#national\nsns.set(rc = {'figure.figsize':(15,8)}, style = 'white')\ndata = main_day.groupby(['week']).agg({'engagement_index': 'mean', 'pct_access': 'mean', 'new_cases': 'sum'}).reset_index()\n\n#draw lineplot\nfig, ax = plt.subplots(figsize = (15, 8))\nax = sns.lineplot(data=data, x='week', y='engagement_index', color=\"b\", linewidth=2, label='Engagement Index')\nax2=ax.twinx()\nsns.lineplot(data=data2, x='week', y='new_cases', color=\"r\", linewidth=5, ax=ax2, label='Weekly New Covid-19 Confirmed')\nfor i, row in ranges.iterrows():\n    ax.axvspan(xmin=row[('week','min')], xmax=row[('week','max')]+1, \n               facecolor='C'+row[('background', 'mean')].astype(int).astype(str), \n               alpha=0.3, label=\"_\"*int(row[('label')]) + labels_background[int(row[('background', 'mean')])])\nplt.grid()\nax.legend(loc='lower left')\nax.set_xticks(xticks)\nax.set_xticklabels(xtick_label)\nax.set_xlabel(\"Months\")\nax.set_ylabel(r\"Engagement Index (Unit: page-loads per 1K students)\")\nax2.set_ylabel(r\"New Covid-19 Confirmed Case (Unit: 1M)\")\nplt.title('Evolution of National Weekly Average Engagement Index', size=20)\nplt.show()\n\n#draw lineplot\nfig, ax = plt.subplots(figsize = (15, 8))\nax = sns.lineplot(data=data, x='week', y='pct_access', color=\"b\", linewidth=2, label='% Access')\nax2=ax.twinx()\nsns.lineplot(data=data2, x='week', y='new_cases', color=\"r\", linewidth=5, ax=ax2, label='Weekly New Covid-19 Confirmed')\nfor i, row in ranges.iterrows():\n    ax.axvspan(xmin=row[('week','min')], xmax=row[('week','max')]+1, \n               facecolor='C'+row[('background', 'mean')].astype(int).astype(str), \n               alpha=0.3, label=\"_\"*int(row[('label')]) + labels_background[int(row[('background', 'mean')])])\nplt.grid()\nax.legend(loc='lower left')\nax.set_xticks(xticks)\nax.set_xticklabels(xtick_label)\nax.set_xlabel(\"Months\")\nax.set_ylabel(r\"Access Ratio\")\nax2.set_ylabel(r\"New Covid-19 Confirmed Case (Unit: 1M)\")\nplt.title('Evolution of National Weekly Average Acess Ratio', size=20)\nplt.show()","ffdab10c":"#various factors\nfactors = [('region', 'Region'), ('locale', 'Locale')]\n\nfor f in factors:\n    sns.set(rc = {'figure.figsize':(15,8)}, style = 'white')\n    data1 = main_day.groupby(['week', f[0]]).agg({'engagement_index': 'mean', 'pct_access': 'mean', 'new_cases': 'sum'}).reset_index()\n\n    #draw lineplot\n    fig, ax = plt.subplots(figsize = (15, 8))\n    ax = sns.lineplot(data=data1, x='week', y='engagement_index', hue=f[0], linewidth=2)\n    ax2=ax.twinx()\n    sns.lineplot(data=data2, x='week', y='new_cases', color=\"r\", linewidth=5, ax=ax2, label='Weekly New Covid-19 Confirmed')\n    for i, row in ranges.iterrows():\n        ax.axvspan(xmin=row[('week','min')], xmax=row[('week','max')]+1, \n                   facecolor='C'+row[('background', 'mean')].astype(int).astype(str), \n                   alpha=0.3, label=\"_\"*int(row[('label')]) + labels_background[int(row[('background', 'mean')])])\n    plt.grid()\n    ax.legend(loc='lower left')\n    ax.set_xticks(xticks)\n    ax.set_xticklabels(xtick_label)\n    ax.set_xlabel(\"Months\")\n    ax.set_ylabel(r\"Engagement Index (Unit: page-loads per 1K students)\")\n    ax2.set_ylabel(r\"New Covid-19 Confirmed Case (Unit: 1M)\")\n    plt.title(f'Evolution of Weekly Average Engagement Index (by {f[1]})', size=20)\n    plt.show()","a2b41fd7":"factors = [('blkhis_ratio', 'Student Ethnicity')]\n\nfor f in factors:\n    sns.set(rc = {'figure.figsize':(15,8)}, style = 'white')\n    data1 = main_day.groupby(['week', f[0]]).agg({'engagement_index': 'mean', 'pct_access': 'mean', 'new_cases': 'sum'}).reset_index()\n\n    #draw lineplot\n    fig, ax = plt.subplots(figsize = (15, 8))\n    ax = sns.lineplot(data=data1, x='week', y='engagement_index', hue=f[0], linewidth=2)\n    ax2=ax.twinx()\n    sns.lineplot(data=data2, x='week', y='new_cases', color=\"r\", linewidth=5, ax=ax2, label='Weekly New Covid-19 Confirmed')\n    for i, row in ranges.iterrows():\n        ax.axvspan(xmin=row[('week','min')], xmax=row[('week','max')]+1, \n                   facecolor='C'+row[('background', 'mean')].astype(int).astype(str), \n                   alpha=0.3, label=\"_\"*int(row[('label')]) + labels_background[int(row[('background', 'mean')])])\n    plt.grid()\n    ax.legend(loc='lower left')\n    ax.set_xticks(xticks)\n    ax.set_xticklabels(xtick_label)\n    ax.set_xlabel(\"Months\")\n    ax.set_ylabel(r\"Engagement Index (Unit: page-loads per 1K students)\")\n    ax2.set_ylabel(r\"New Covid-19 Confirmed Case (Unit: 1M)\")\n    plt.title(f'Evolution of Weekly Average Engagement Index (by {f[1]})', size=20)\n    plt.show()","4005b31a":"factors = [('freereduced_ratio', 'Lunch program Eligibility')]\n\nfor f in factors:\n    sns.set(rc = {'figure.figsize':(15,8)}, style = 'white')\n    data1 = main_day.groupby(['week', f[0]]).agg({'engagement_index': 'mean', 'pct_access': 'mean', 'new_cases': 'sum'}).reset_index()\n\n    #draw lineplot\n    fig, ax = plt.subplots(figsize = (15, 8))\n    ax = sns.lineplot(data=data1, x='week', y='engagement_index', hue=f[0], linewidth=2)\n    ax2=ax.twinx()\n    sns.lineplot(data=data2, x='week', y='new_cases', color=\"r\", linewidth=5, ax=ax2, label='Weekly New Covid-19 Confirmed')\n    for i, row in ranges.iterrows():\n        ax.axvspan(xmin=row[('week','min')], xmax=row[('week','max')]+1, \n                   facecolor='C'+row[('background', 'mean')].astype(int).astype(str), \n                   alpha=0.3, label=\"_\"*int(row[('label')]) + labels_background[int(row[('background', 'mean')])])\n    plt.grid()\n    ax.legend(loc='lower left')\n    ax.set_xticks(xticks)\n    ax.set_xticklabels(xtick_label)\n    ax.set_xlabel(\"Months\")\n    ax.set_ylabel(r\"Engagement Index (Unit: page-loads per 1K students)\")\n    ax2.set_ylabel(r\"New Covid-19 Confirmed Case (Unit: 1M)\")\n    plt.title(f'Evolution of Weekly Average Engagement Index (by {f[1]})', size=20)\n    plt.show()","564ad6fc":"factors = [('pp_totexp', 'Total Edu Expenditure per Pupil')]\n\nfor f in factors:\n    sns.set(rc = {'figure.figsize':(15,8)}, style = 'white')\n    data1 = main_day.groupby(['week', f[0]]).agg({'engagement_index': 'mean', 'pct_access': 'mean', 'new_cases': 'sum'}).reset_index()\n\n    #draw lineplot\n    fig, ax = plt.subplots(figsize = (15, 8))\n    ax = sns.lineplot(data=data1, x='week', y='engagement_index', hue=f[0], linewidth=2)\n    ax2=ax.twinx()\n    sns.lineplot(data=data2, x='week', y='new_cases', color=\"r\", linewidth=5, ax=ax2, label='Weekly New Covid-19 Confirmed')\n    for i, row in ranges.iterrows():\n        ax.axvspan(xmin=row[('week','min')], xmax=row[('week','max')]+1, \n                   facecolor='C'+row[('background', 'mean')].astype(int).astype(str), \n                   alpha=0.3, label=\"_\"*int(row[('label')]) + labels_background[int(row[('background', 'mean')])])\n    plt.grid()\n    ax.legend(loc='lower left')\n    ax.set_xticks(xticks)\n    ax.set_xticklabels(xtick_label)\n    ax.set_xlabel(\"Months\")\n    ax.set_ylabel(r\"Engagement Index (Unit: page-loads per 1K students)\")\n    ax2.set_ylabel(r\"New Covid-19 Confirmed Case (Unit: 1M)\")\n    plt.title(f'Evolution of Weekly Average Engagement Index (by {f[1]})', size=20)\n    plt.show()","2ee237ce":"import statsmodels.formula.api as smf\nfrom IPython.core.display import HTML\nfrom statsmodels.iolib.summary2 import summary_col, summary_model\n\ndef short_summary(est):\n    return HTML(est.summary().tables[1].as_html())\n\nfor x in ['new_cases', 'pct_access', 'engagement_index']:\n    main_month[\"ln_\"+x] = np.log1p(main_month[x])\n\nexclude_function = ['CM:Teacher Resources', \n                    'LC:Career Planning & Job Search', \n                    'SDO:Admissions, Enrollment & Rostering', \n                    'SDO:Environmental, Health & Safety (EHS) Compliance',\n                    'SDO:Human Resources', \n                    'SDO:Large-Scale & Standardized Testing',\n                    'SDO:Other']\n\ndata = main_month[~main_month['subfunction'].isin(exclude_function)]\ndata = data.dropna(subset=['ln_new_cases', 'freereduced_ratio', 'pp_totexp'])\ndata['wgt'] = data['st_pop'].apply(lambda x: round(x\/3000000))\nfor i in range(2,30):\n    df_tmp = data[data['wgt'] == i]\n    data = data.append([df_tmp]*(i-1), ignore_index=True)\n\ndatamean = pd.merge(data, lea_info_collapsed_mean, on=['st', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp'])\ndatamean = datamean.dropna(subset=['perhsp', 'perblk', 'perell', 'perspeced', 'lninc50avgall', 'baplusavgall', 'avg_test_score'])\n\ndatamed = pd.merge(data, lea_info_collapsed_median, on=['st', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp'])\ndatamed = datamed.dropna(subset=['perhsp', 'perblk', 'perell', 'perspeced', 'lninc50avgall', 'baplusavgall', 'avg_test_score'])\n\ndatamin = pd.merge(data, lea_info_collapsed_min, on=['st', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp'])\ndatamin = datamin.dropna(subset=['perhsp', 'perblk', 'perell', 'perspeced', 'lninc50avgall', 'baplusavgall', 'avg_test_score'])\n\ndatamax = pd.merge(data, lea_info_collapsed_max, on=['st', 'locale', 'blkhis_ratio', 'freereduced_ratio', 'pp_totexp'])\ndatamax = datamax.dropna(subset=['perhsp', 'perblk', 'perell', 'perspeced', 'lninc50avgall', 'baplusavgall', 'avg_test_score'])","47110445":"result = list()\n\nfor y in ['ln_pct_access', 'ln_engagement_index']:\n    result.append(sm.OLS.from_formula(f'{y} ~ ln_new_cases + C(locale) + C(blkhis_ratio) + C(freereduced_ratio) + C(pp_totexp) + C(mainfunction) + C(subfunction) + work + stayHome + stringency + corporate + higher + prek12 + C(month) + C(st)',\n                  data=data, missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data['st']}))","ce253ddb":"regressors = ['ln_new_cases', 'N', 'R2']\n\ntable = summary_col([result[0], result[1]], float_format='%.3f', stars=True, \n                  model_names=['% Access\\n(1)','Engagement\\n(2)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)","545b329d":"result = list()\n\nfor y in ['ln_pct_access', 'ln_engagement_index']:\n    result.append(sm.OLS.from_formula(y + ' ~ ln_new_cases + school + C(locale) + C(blkhis_ratio) + C(freereduced_ratio) + C(pp_totexp)+  C(subfunction) + work + stayHome + stringency + corporate + higher + prek12 + C(month) + C(st)',\n                  data=data, missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data['st']}))\n\n    result.append(sm.OLS.from_formula(y + ' ~ ln_new_cases + school + ln_new_cases * school + C(locale) + C(blkhis_ratio) + C(freereduced_ratio) + C(pp_totexp)+ C(subfunction) + work + stayHome + stringency + corporate + higher + prek12 + C(month) + C(st)',\n                  data=data, missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data['st']}))","2ff5e2c2":"regressors = ['ln_new_cases', 'school', 'ln_new_cases:school', 'N', 'R2']\n\ntable = summary_col([result[0], result[1], result[2], result[3]], float_format='%.3f', stars=True, \n                  model_names=['% Access\\n(1)','% Access\\n(2)','Engagement\\n(3)', 'Engagement\\n(4)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)","080add6c":"result = list()\n#'unempavgall', 'snapavgall', 'single_momavgall'\nadd_controls = ['perhsp', 'perblk', 'perell', 'perspeced', 'lninc50avgall', 'baplusavgall', 'avg_test_score']\nadd_controls_str = '+'\nfor var in add_controls:\n    add_controls_str = add_controls_str + ' ' + var + ' + '\n\nfor y in ['ln_pct_access', 'ln_engagement_index']:\n    for df in [datamean, datamed, datamin, datamax]:\n        result.append(sm.OLS.from_formula(y + f' ~ ln_new_cases + school + C(locale) + C(blkhis_ratio) + C(freereduced_ratio) + C(pp_totexp)+  C(subfunction) + work + stayHome + stringency + corporate + higher + prek12 {add_controls_str} C(month) + C(st)',\n                      data=df, missing='drop').fit(cov_type='cluster', cov_kwds={'groups': df['st']}))\n    for df in [datamean, datamed, datamin, datamax]:\n        result.append(sm.OLS.from_formula(y + f' ~ ln_new_cases + school + ln_new_cases * school + C(locale) + C(blkhis_ratio) + C(freereduced_ratio) + C(pp_totexp)+ C(subfunction) + work + stayHome + stringency + corporate + higher + prek12 {add_controls_str} C(month) + C(st)',\n                      data=df, missing='drop').fit(cov_type='cluster', cov_kwds={'groups': df['st']}))","f98b96c5":"regressors = ['ln_new_cases', 'school', 'ln_new_cases:school', 'perhsp', 'perblk', 'perell', 'perspeced', 'lninc50avgall', 'baplusavgall', 'avg_test_score', 'N', 'R2']\n\ntable = summary_col([result[0], result[1], result[2], result[3]], float_format='%.3f', stars=True, \n                  model_names=['% Access\\nMean\\n(1)','% Access\\nMedian\\n(2)','% Access\\nMin\\n(3)', '% Access\\nMax\\n(4)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)\n\ntable = summary_col([result[4], result[5], result[6], result[7]], float_format='%.3f', stars=True, \n                  model_names=['% Access\\nInteraction\\nMean\\n(5)','% Access\\nInteraction\\nMedian\\n(6)','% Access\\nInteraction\\nMin\\n(7)', '% Access\\nInteraction\\nMax\\n(8)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)","97437bef":"table = summary_col([result[8], result[9], result[10], result[11]], float_format='%.3f', stars=True, \n                  model_names=['Engagement\\nMean\\n(1)','Engagement\\nMedian\\n(2)','Engagement\\nMin\\n(3)', 'Engagement\\nMax\\n(4)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)\n\ntable = summary_col([result[12], result[13], result[14], result[15]], float_format='%.3f', stars=True, \n                  model_names=['Engagement\\nInteraction\\nMean\\n(5)','Engagement\\nInteraction\\nMedian\\n(6)','Engagement\\nInteraction\\nMin\\n(7)', 'Engagement\\nInteraction\\nMax\\n(8)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)","bb281cb7":"result = list()\n\nfor x in ['blkhis_ratio', 'freereduced_ratio', 'pp_totexp', 'locale']:\n    for y in ['ln_pct_access', 'ln_engagement_index']:\n        result.append(sm.OLS.from_formula(f'{y} ~ ln_new_cases + school + C({x}) * school + C(locale) + C(blkhis_ratio) + C(freereduced_ratio) + C(pp_totexp)+ C(mainfunction) + work + stayHome + stringency + corporate + higher + prek12 + C(month) + C(st)',\n                      data=data,  missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data['st']}))\n        \n        result.append(sm.OLS.from_formula(f'{y} ~ ln_new_cases + school + C({x}) * school * ln_new_cases + C(locale) + C(blkhis_ratio) + C(freereduced_ratio) + C(pp_totexp)+ C(mainfunction) + work + stayHome + stringency + corporate + higher + prek12 + C(month) + C(st)',\n              data=data, missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data['st']}))","583b09e2":"#blkhis\nregressors = ['ln_new_cases', 'school', 'ln_new_cases:school', 'C(blkhis_ratio)[T.0.2]', 'C(blkhis_ratio)[T.0.4]', \n              'C(blkhis_ratio)[T.0.6]', 'C(blkhis_ratio)[T.0.8]', 'C(blkhis_ratio)[T.0.2]:school',\n              'C(blkhis_ratio)[T.0.4]:school', 'C(blkhis_ratio)[T.0.6]:school', 'C(blkhis_ratio)[T.0.8]:school',\n              'C(blkhis_ratio)[T.0.2]:school:ln_new_cases', 'C(blkhis_ratio)[T.0.4]:school:ln_new_cases',\n              'C(blkhis_ratio)[T.0.6]:school:ln_new_cases', 'C(blkhis_ratio)[T.0.8]:school:ln_new_cases', 'N', 'R2']\n\ntable = summary_col([result[0], result[1], result[2], result[3]], float_format='%.3f', stars=True, \n                  model_names=['% Access\\n(1)','% Access\\n(2)','Engagement\\n(3)', 'Engagement\\n(4)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)","879d5465":"#freereduced lunch\nregressors = ['ln_new_cases', 'school', 'ln_new_cases:school', 'C(freereduced_ratio)[T.0.2]', 'C(freereduced_ratio)[T.0.4]', \n              'C(freereduced_ratio)[T.0.6]', 'C(freereduced_ratio)[T.0.8]', 'C(freereduced_ratio)[T.0.2]:school',\n              'C(freereduced_ratio)[T.0.4]:school', 'C(freereduced_ratio)[T.0.6]:school', 'C(freereduced_ratio)[T.0.8]:school',\n              'C(freereduced_ratio)[T.0.2]:school:ln_new_cases', 'C(freereduced_ratio)[T.0.4]:school:ln_new_cases',\n              'C(freereduced_ratio)[T.0.6]:school:ln_new_cases', 'C(freereduced_ratio)[T.0.8]:school:ln_new_cases', \n              'N', 'R2']\n\ntable = summary_col([result[4], result[5], result[6], result[7]], float_format='%.3f', stars=True, \n                  model_names=['% Access\\n(1)','% Access\\n(2)','Engagement\\n(3)', 'Engagement\\n(4)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)","1ef00471":"#tot exp\nregressors = ['ln_new_cases', 'school', 'ln_new_cases:school', 'C(pp_totexp)[T.8000.0]', 'C(pp_totexp)[T.10000.0]', \n              'C(pp_totexp)[T.12000.0]', 'C(pp_totexp)[T.14000.0]', 'C(pp_totexp)[T.16000.0]',\n              'C(pp_totexp)[T.18000.0]', 'C(pp_totexp)[T.8000.0]:school', 'C(pp_totexp)[T.10000.0]:school', \n              'C(pp_totexp)[T.12000.0]:school', 'C(pp_totexp)[T.14000.0]:school', 'C(pp_totexp)[T.16000.0]:school',\n              'C(pp_totexp)[T.18000.0]:school', 'C(pp_totexp)[T.8000.0]:school:ln_new_cases', 'C(pp_totexp)[T.10000.0]:school:ln_new_cases', \n              'C(pp_totexp)[T.12000.0]:school:ln_new_cases', 'C(pp_totexp)[T.14000.0]:school:ln_new_cases', 'C(pp_totexp)[T.16000.0]:school:ln_new_cases',\n              'C(pp_totexp)[T.18000.0]:school:ln_new_cases', 'N', 'R2']\n\ntable = summary_col([result[8], result[9], result[10], result[11]], float_format='%.3f', stars=True, \n                    model_names=['% Access\\n(1)','% Access\\n(2)','Engagement\\n(3)', 'Engagement\\n(4)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)","4c07cbf5":"#locale\nregressors = ['ln_new_cases', 'school', 'ln_new_cases:school', 'C(locale)[T.Rural]', 'C(locale)[T.City]', \n              'C(locale)[T.Town]', 'C(locale)[T.Rural]:school', 'C(locale)[T.City]:school', \n              'C(locale)[T.Town]:school', 'C(locale)[T.Rural]:school:ln_new_cases', 'C(locale)[T.City]:school:ln_new_cases',\n              'C(locale)[T.Town]:school:ln_new_cases', 'N', 'R2']\n\ntable = summary_col([result[12], result[13], result[14], result[15]], float_format='%.3f', stars=True, \n                    model_names=['% Access\\n(1)','% Access\\n(2)','Engagement\\n(3)', 'Engagement\\n(4)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)","f9098e6c":"result = list()\n\nfor y in ['ln_pct_access', 'ln_engagement_index']:\n    result.append(sm.OLS.from_formula(f'{y} ~ ln_new_cases + school + C(mainfunction) * school + C(locale) + C(blkhis_ratio) + C(freereduced_ratio) + C(pp_totexp)+ C(mainfunction) + work + stayHome + stringency + corporate + higher + prek12 + C(month) + C(st)',\n                  data=data,  missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data['st']}))\n\n    result.append(sm.OLS.from_formula(f'{y} ~ ln_new_cases + school + C(mainfunction) * school + C(locale) + C(blkhis_ratio) + C(freereduced_ratio) + C(pp_totexp)+ C(mainfunction)*month + work + stayHome + stringency + corporate + higher + prek12 + C(month) + C(st)',\n                  data=data,  missing='drop').fit(cov_type='cluster', cov_kwds={'groups': data['st']}))","e5fecb3b":"regressors = ['ln_new_cases', 'school', 'C(mainfunction)[T.CM]', 'C(mainfunction)[T.SDO]', \n              'C(mainfunction)[T.LC\/CM\/SDO]', 'C(mainfunction)[T.CM]:school', 'C(mainfunction)[T.SDO]:school', \n              'C(mainfunction)[T.LC\/CM\/SDO]:school', 'C(mainfunction)[T.CM]:month', 'C(mainfunction)[T.SDO]:month', \n              'C(mainfunction)[T.LC\/CM\/SDO]:month', 'N', 'R2']\n\ntable = summary_col([result[0], result[1], result[2], result[3]], float_format='%.3f', stars=True, \n                    model_names=['% Access\\n(1)','% Access\\nLinear Trend\\n(2)', 'Engagement\\n(3)', 'Engagement\\nLinear Trend\\n(4)'],\n                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n                             'R2':lambda x: \"{:.2f}\".format(x.rsquared)},\n                  regressor_order=regressors)\ntable.tables[0]['regressor'] = [i for sublist in [[j]*2 for j in table.tables[0].index[0::2]] for i in sublist]\ntable.tables[0] = table.tables[0][table.tables[0]['regressor'].isin(regressors)]\ndel table.tables[0]['regressor']\nprint(table)","f9b34cc5":"# <font color=\"#6C8255\">Overview<\/font>\n---\n* <font size=3> We found that the spread of 'Covid-19' and the implementation of 'school closure policy' <b>increased on online learning engagement<\/b>. (i.e., additional new Covid-19 infection and implementation of school closure policy increased engagement by 0.031%, and 253% respectively.)<\/font><br>\n<br>\n* <font size=3>The impact of 'school closure' increased as more 'Covid-19' cases appeared, and this implies that <b>students living in the district where 'Covid-19' is highly infected, would access and engage more on online learning products when school is closed.<\/b><\/font><br>\n<br>\n* <font size=3><b>There is a heterogeneous impact on online learning engagement along with socioeconomic characteristics of students.<\/b><\/font>\n\n    - (1) Higher **black and Hispanic share** tends to **access and engage less**. (decreased engagement index by 3.6\\~5.2% per 1% increase)\n    - (2) More **economically disadvantaged students** (proxied by the eligibility of free lunch program, and median income in district) tends to **engage less** than those who are not on average.\n    - (3) Larger **expenditure on education** does **not necessarily increase** online learning product.\n    - (4) Districts in **rural and suburb** tend to **engage less** relative to city and town.\n    - (5) More **ELL (English Language Learner) students** are likely to **access and engage more** in online learning. (increased by 7.7\\~11.4% per 1% increase)\n    - (6) Higher **test score** on average tends to **access and engage more** in digital learning product<br>\n<br>\n* <font size=3><b>There is also a heterogeneous on online learning engagement along the type of products<\/b><\/font>\n    - (1) **'School and Districts Operation'** (e.g., Google Classroom) tends to be accessed less by 10.8% during school closure, and engagement has been decreased most rapidly compared to any other product type.\n    - (2) **'Classroom Management Tools'** (e.g., 'Zoom' and 'Google Hangout') was engaged and accessed 65.7% and 12.6% more respectively.<br>\n<br>","47dac146":"### <font color=\"#6C8255\">3.1.1. Districts Information<\/font>\nWe started from collecting districts information. The data provides `state`, `locale`, `pct_black\/hispanic`, `pct_free\/reduced`, `county_connections_ratio`, `pp_total_raw`.\n\n* **Dropped some districts information** which does not provide state information. Its frequency is 57, which is nearly 25%.\n* Added state **abbreviation column** for further convenience.\n* There is a **very small variation in `country_connections_ratio`**, where there is only 1 district with `[1,2[`, while others are all `[0.18, 1[`, which we would not use on our analysis.\n* **Converted `pp_total_raw` columns** into 7 groups as it is separated in detailed level. (See [Section 4.1.1.](#--Share-of-High-Speed-Internet-Connection) for detailed distribution)","0380a213":"## <font color=\"#6C8255\">- Model<\/font>\nWe investigated **whether the degree of Covid-19 and policy related to pandemic affects differently by each product type** by interacting dummy variables for product type with $School\\ Closure$. \n\nFurthermore, we included product type-specific linear time trends to see **whether there are different trends along with each product type** would capture the slope difference between the given product type and the baseline group (i.e., omitted group).\n\n<br>\n\n$$ln(Y_{i,s,p,m})=\\alpha + \\beta \\cdot ln(Covid\\ 19_{i,s,p,m}) + \\gamma\\cdot School\\ Closure_{i,s,p,m} + \\Sigma_{j\\in Product_j}\\gamma_j\\cdot School\\ Closure_{i,s,p,m}\\times 1(i \\in Product_j) +\\mathbf{\\theta\\ X}_{i,s,p,m}+\\iota_m+\\kappa_s+\\epsilon_{i,s,p,m}$$\n\n$$ln(Y_{i,s,p,m})=\\alpha + \\beta \\cdot ln(Covid\\ 19_{i,s,p,m}) + \\gamma\\cdot School\\ Closure_{i,s,p,m} + \\Sigma_{j\\in Product_j}\\gamma_j\\cdot School\\ Closure_{i,s,p,m}\\times 1(i \\in Product_j) + \\theta_j \\cdot 1(i \\in Product_j) \\times m +\\mathbf{\\theta\\ X}_{i,s,p,m}+\\iota_m+\\kappa_s + \\epsilon_{i,s,p,m}$$\n\n<br>\n\n* Our variable of interest is $ School\\ Closure_{i,s,p,m}\\times 1(i \\in Product_j) $ which captures the different impact of `school closure` policy relative to the base group. **This can be interpreted as closing school completely for an entire month increase dependent variable by $\\gamma_j \\times 100$ % more relative to the base group**\n\n* While, $ \\theta_j $ estimates **the heterogeneous linear time trend of each product type relative to the omitted group.**\n\n* We further included **socioeconomic factors** (e.g.,`share of black or Hispanic students`, `share of free or reduced-priced lunch program eligible students`, `total expenditure on education per pupil`, and `locale`), **product characteristics** (e.g., `function of products`, `sector` as a vector `$\\mathbf{X}$'. \n\n* Finally, $\\iota_m$ and $\\kappa_s$ capture month-, state-fixed effects to rule out unobserved characteristics within month and state.\n\n* Standard errors are **clustered in state-level**, and **weighted each observation by the population of the state** where the district is belonged to, as previous analysis.","e0ab2d46":"### <font color=\"#6C8255\">- Distribution of States and Locale<\/font>\n\nFollowing pie charts and bar graphs provide information on the distribution of states and locale of our sample.\n\n* Although several states are over-sampled (e.g., CT, UT, MA, IL which have over 10%), **in terms of the region it is balanced (around 30% each)**, except for the southern part of the U.S. \n\n\n* For locale **over half of the sample are suburb area**, followed by rural (18.75%), city (16.48%), and town (5.68%). Even the data seems biased toward suburb area, it is quite similar with the population, in terms of ranking of total enrollment by locale, as there are around 35% of total enrollment lives in a suburb area, followed by rural, city and town ([NCES](https:\/\/nces.ed.gov\/surveys\/ruraled\/tables\/b.1.a.-2.asp), 2014)\n","f0af9d84":"## <font color=\"#6C8255\">- Regional \/ Locale Trend<\/font>\n\n* Trends goes similar with the national trends\n\n* **Regional**: Northeast region has the highest engagement, while Southern and Western regions have the lowest engagement on online learning products. Engagement decreased in the Mid-West and Southern part of the U.S., while increased in other regions between March and April 2020.\n\n* **Locale**: Students living in the rural area have the most engaged while those living in the city and town are least engaged compared to others. Students in town had a high index at the beginning of 2020, but it collapsed during late 2020.","c5f319f2":"### <font color=\"#6C8255\">- Overall Distribution of Online Learning Engagements<\/font>\nThe following figures are histograms and box plots for each `percent access` and `engagement index` respectively. The vertical dotted line indicates the mean of each variable - 0.68% and 147.31-page load events. \n\n- Both variables are **skewed left** mostly lies below the average. (i.e., the value of the third quartile (75%) is lower than the average value)\n\n- **Outliers in `percent access` and `engagement index` have different behavior**. The former one mostly lies near each other, while the latter varies a lot.","75b0f8ab":"# <font color=\"#6C8255\">4.3. Evolution of Online Learning Engagement: How trend changed over time?<\/font>\n<font size=3> In this sub-section, we have investigated <b>how 'acess ratio' and 'engagment index' have been changed over time relative to 'Covid-19 spread' and 'school closure' policy<\/b> which seems to be the most direct factor that affects the online learning engagement behavior. <\/font>\n\n<br>\n\n**To exclude the weekday fixed effect** (i.e., Since student tends to engage less during weekends, there will be oscillations in graph making difficult to read the overall trends), we **aggregated up the data into weekly level**. Hence each row contains `weekly average engagement information`, and `weekly new Covid-19 confirmed cases`.","693d6583":"## <font color=\"#6C8255\">- Economic Status (Lunch Program Eligibility)<\/font>\n\n* Trends goes similar with the national trends\n\n* Districts where most of students are **economically challenged (over 80% are eligible for free or reduced-price lunch) has the most highly engaged**. On the other hand, those living in **slightly better area (6-80% of students are eligible for free or reduced-price lunch) are engaged the least** compared to others.","545d5378":"## <font color=\"#6C8255\">- Model<\/font>\nIn this subsection, we investigated whether the degree of Covid-19 have affected the online learning engagement of studnets, if so what extent. To do so, we implemetned following model as follows:\n\n$$ln(Y_{i,s,p,m})=\\alpha + \\beta \\cdot ln(Covid\\ 19_{i,s,p,m}) + \\mathbf{\\theta\\ X}_{i,s,p,m}+\\iota_m+\\kappa_s +\\epsilon_{i,s,p,m}$$\n\nwhere $Y_{i,s,p,m}$ indicates `access raito` and `engagement index` in distict `i`, state `s`, product `p`, and month `m`. \n\n* Our variable of interest is `Coivd-19` in this sub-section which estimates the impact of new monthly Covid-19 confirmed cases. As we have log-transformed both independent and dependent variables, **this can be interpreted as a 1% increase in new monthly confirmed cases increase a dependent variable by $\\beta$ %** \n\n* We further included **socioeconomic factors** (e.g.,`share of black or hispanic studnets`, `share of free or reduced priced lunch program eligible students`, `totel expenditure on education per pupil`, and `locale`), **product characteristics** (e.g., `function of products`, `sector` as a vector $\\mathbf{X}_{i,s,p,m}$. \n\n* Finally, $\\iota_m$ and $\\kappa_s$ capture month-, state-fixed effects to rule out unobserved characteristics within month and state.\n\n* Standard errors are **clustered in state-level**, which considers the heteroskedasticity within a state cluster. Furthermore, as each observation is considered equally even each row represents districts with different size, we, therefore, **weighted each observation by the population of the state** where the district is belonged to.","1a17a0c0":"## <font color=\"#6C8255\">4.1.2. Online Learning Products Information<\/font>","66ca24a3":"### <font color=\"#6C8255\">- Distribution of Function<\/font>\n\nThe following pie charts show the distribution of product types among the top 20 and top 50 products. Those are measured by `access ratio` and `engagement index`.\n\n- **Top 20**\n\nSimilar to our conjecture based on the previous graph, **there are many 'Classroom Management' and 'School and District Operations' products are included in the top 20**, even those categories do not consist the majority of the whole product types (both consists 9.66%, and 8.52% among whole products respectively)\n\n- **Top 50**\n\nThe trends changed if we look at the top 50 products, as **majority of products are from 'Learning and Curriculum' which consists 77.27% of total services.**","7177528a":"### <font color=\"#6C8255\">3.1.2. Engagement Data<\/font>\nThe data consists student's daily engagment data on each product (`pct_access`, `engagement_index`). Since the data does not consist of `district_id` we added from the title of each data (`leaid`).\n\n* Aggregated the data into `district x product x month` level, which will allow us to analyze the impact of Covid-19 more in a more robust manner (i.e., reduce noise due to high-frequency data)","40ff7d78":"## <font color=\"#6C8255\">- Model<\/font>\nWe investigated **whether the degree of Covid-19 and policy related to pandemic affects differently by each socio-economic group** by interacting dummy variables for a socioeconomic group with $Covid-19 \\times School\\ Closure$. This coefficient would capture the difference between the given group and the baseline group (i.e., omitted group).\n\n<br>\n\n$$ln(Y_{i,s,p,m})=\\alpha + \\beta \\cdot ln(Covid\\ 19_{i,s,p,m}) + \\gamma\\cdot School\\ Closure_{i,s,p,m} + \\Sigma_{j\\in Group}\\gamma_j\\cdot School\\ Closure_{i,s,p,m}\\times 1(i \\in Group_j) +\\mathbf{\\theta\\ X}_{i,s,p,m}+\\iota_m+\\kappa_s+\\epsilon_{i,s,p,m}$$\n\n$$ln(Y_{i,s,p,m})=\\alpha + \\beta \\cdot ln(Covid\\ 19_{i,s,p,m}) + \\gamma\\cdot School\\ Closure_{i,s,p,m} + \\Sigma_{j\\in Group}\\gamma_j\\cdot School\\ Closure_{i,s,p,m}\\times 1(i \\in Group_j) + \\theta\\cdot School\\ Closure_{i,s,p,m} \\times ln(Covid\\ 19_{i,s,p,m}) + \\Sigma_{j\\in Group}\\theta_j\\cdot School\\ Closure_{i,s,p,m} \\times ln(Covid\\ 19_{i,s,p,m}) \\times 1(i \\in Group_j) +\\mathbf{\\theta\\ X}_{i,s,p,m}+\\iota_m+\\kappa_s + \\epsilon_{i,s,p,m}$$\n\n<br>\n\n* Our variable of interest is $ School\\ Closure\\ \\times\\ 1(i\\in Group_j)$ which captures the different impact of `school closure` policy relative to the base group. **This can be interpreted as closing school completely for an entire month increase dependent variable by $\\gamma_j \\times 100$ % more relative to the base group**\n\n* While, $ School\\ Closure\\times ln(Covid-19) \\times 1(i \\in Group_j) $ estimates **the heterogeneous impact of the policy by Covid-19, realative to the ommitted group.**\n\n* We further included **socioeconomic factors** (e.g.,`share of black or Hispanic students`, `share of free or reduced-priced lunch program eligible students`, `total expenditure on education per pupil`, and `locale`), **product characteristics** (e.g., `function of products`, `sector` as a vector `$\\mathbf{X}$'. \n\n* Finally, $\\iota_m$ and $\\kappa_s$ capture month-, state-fixed effects to rule out unobserved characteristics within month and state.\n\n* Standard errors are **clustered in state-level**, and **weighted each observation by the population of the state** where the district is belonged to, as previous analysis.","5da58c90":"## <font color=\"#6C8255\">4.2.2. Socioeconomic Factors<\/font>\nWe have investigated **whether there is a different trend in engagement behavior for each socioeconomic group**. Moreover, we further analyzed **whether this behavior changes over product types**.","0660bad3":"### <font color=\"#6C8255\">3.2.4. Merge Dataset<\/font>\nThen we have constructed a cell by `State x Locale x blkhis_rate x freereduced_rate x pp_totexp`, which creates 1382 cells from 6844 total districts available. Using this information, we aggregated up the district-level information acquired from sections [3.2.1](#3.2.1.-Student-Performance:-SEDA-4.1-(The-Educational-Opportunity-Project-at-Stanford-University) to [3.2.2.](#3.2.2.-School-District-Information:-SEDA-4.1-(The-Educational-Opportunity-Project-at-Stanford-University) including student's performance by `mean`, `median`, `max`, `min` to see the overall trends of such variable on the outcome variable.","2966a5e0":"## <font color=\"#6C8255\">4.2.1. Covid-19 and Related Policy<\/font>\n\n### <font color=\"#6C8255\">- New Covid-19 Confirmed Cases<\/font>\nThe following figures depict the relationship between new monthly Covid-19 confirmed cases with the monthly average `percent access` and `engagement index` respectively. The above two graphs show the `mean` and `median` of each variable of each decile group defined by `number of monthly average new Covid-19 cases`. Latter two scatter plots depict the relationship between our variable of interest and Covid-19. \n\n<br>\n\nAs shown in the figure, there is **a decreasing relationship between Covid-19 and both `percent access` and `engagement index`**. This is different from our general conjecture that Covid-19 might increase online learning products engagement.\n\nThis may due to the fact that there might be other factors which is correlated with the Covid-19 spread, and affects this product, we should further control other factors to rule out such a case, and to confirm this trend. To do so, we are going to implement a multivariate linear regression model in [section 5.1](#5.1.-Impact-of-COVID-19)","f150f573":"### <font color=\"#6C8255\">- Distribution of Online Learning Engagements (By Function) <\/font>\nWe again plotted several figures to check whether the distribution of variables - `percent access` and `engagement index` - behaves differently along with the type of products.\n\n- **Access Ratio**\n\n**Products for 'School District Operations' have the highest `percent access`** followed by 'Classroom Management', 'All' and 'Learning and Curriculum'.\n\n- **Engagement Index**\n\nThe trend is similar to the previous figure. However the **difference of annual average `engagement index` between the highest and the second is larger** compared to the access ratio. The annual average index of 'School District Operation' is almost tripled compared to those of 'Classroom Management'.","bab47ff9":"<div id=\"1\"><\/div>\n\n# <font color=\"#6C8255\">1. Introduction<\/font>\n---","3630cbe2":"## <font color=\"#6C8255\">- Findings<\/font>\n\nOdd columns show the results without linear trend for each product type while even columns include linear trend for each product type. **Baseline group is the Learning and Curriculum product type.**\n\n* In column (1) and (3), where there is no product type-specific linear trend term, both **`Covid-19` and `School Closure` has positively correlated with online engagement**, even it is still not statistically significant at the conventional level. 'School and Districts Operation' products such as Google Classroom tend to be used more on average, but this gets decreased as a school has been closed by 10.8% in access ratio. On the other hand, 'Classroom Management Tools' such as 'Zoom' and 'Google Hangout' are likely to have lower usage on average but it increases when school is closed by 12.6% in access ratio and 65.7&.\n\n* Remaining columns (2), (4), we introduced **product-specific time trends to capture whether each product has different time trends along as pandemic progress**. Even we include such variables, the result holds constant which implies the model is robust. One thing to note is that 'School and Districts Operation' products tend to decrease most fast compared to the baseline group (i.e., Learning and Curriculum product)","999f90ed":"## <font color=\"#6C8255\">1.1. Problem Statement<\/font>\nThe COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America\u2019s most vulnerable learners continue to grow.\n\n* What is the picture of digital connectivity and engagement in 2020?\n\n* What is the effect of the COVID-19 pandemic on online and distance learning, and how might this also evolve in the future?\n\n* How does student engagement with different types of education technology change over the course of the pandemic?\n\n* How does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race\/ethnicity, ESL, learning disability)? Learning context? Socioeconomic status?\n\n* Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?","710efa45":"# <font color=\"#6C8255\">5.2. Impact of COVID-19 Policy<\/font>\n<font size=3><b>\"Do certain state interventions, practices or policies correlate with the increase or decrease online engagement?\"<\/b><\/font>","4d20745a":"### <font color=\"#6C8255\">3.1.6. Merge Dataset<\/font>\nWe finally constructed dataset using the data given from the compeitions and state level information.\n\n* Observation unit is `district(leaid) x month x product(lp_id)`\n* Data set that were originally given was merged using `district(leaid)` and `lp_id(product)`.\n* State level information were merged using `state name(st)`","a6eb0c66":"## <font color=\"#6C8255\"> 3.2. Adding School District Level Data Source<\/font>\n### <font color=\"#6C8255\">3.2.1. Student Performance: SEDA 4.1 (The Educational Opportunity Project at Stanford University)<\/font>\nThe dataset provides `average test score` and `learning rate` from each school district (LEA) level which is evaluated in 2018\/19.\n\n* Drop district without test score data","2b25bba1":"## <font color=\"#6C8255\">3.1. Main Dataset with State level information<font>\nWe first constructed `engagement data` by appending multiple datasets in `.\/engagement_data` directory. We then merged `districts_info.csv` and `products_info.csv`. We used `district_id` and `lp_id` as primary keys to merge.","6faa7e9e":"### <font color=\"#6C8255\">- Locale<\/font>\n\n- Districts **located in a rural area has the highest `percent access` and `engagement index`** compared to other locales. This is followed by districts in suburbs, towns, and cities.\n\n- This trend holds for all types of product types but, again **the trend is distinctive in 'Classroom Management' and 'School and District Operations' products**.","6f3d0798":"# <font color=\"#6C8255\">5.1. Impact of COVID-19<\/font>\n<font size = 3><b>\"What is the effect of the COVID-19 pandemic on online and distance learning?\"<\/b><\/font>","e7031a3b":"# <font color=\"#6C8255\">5.4. Heterogeneity of socio-economic factor<\/font>\n<font size=3><b>\"How does student engagement with online learning platforms relate to different geography?\"<\/b><\/font>","76edf126":"### <font color=\"#6C8255\">3.2.2. School District Information: SEDA 4.1 (The Educational Opportunity Project at Stanford University)<\/font>\nThe dataset provides various characteristics from the school district level including student demographics, economic status, family backgrounds. Followings are detailed information on each variable.\n\n| Name | Description |\n| :--- | :----------- |\n| sedalea | The unique identifier of the school districts |\n| perhsp | % Hispanics in the district |\n| perblk | % Blacks in the district |\n| perell | % of all Students in District that are ELL |\n| perspeced | % of all students in District that are Special Ed |\n| lninc50avgall | log(Median of Household Income in the district) |\n| baplusavgall | % of BA+ Degree Population |","db279c47":"<div id=\"3\"><\/div>\n\n# <font color=\"#6C8255\">3. Data Cleaning<\/font>\n---\n<font size=3><b>In this stage, we have elaborated how we merged numerous datasets into a single data frame and extract samples that can be used for our analysis.<\/b><\/font>\n\n<br>\n\nWe first **constructed the main dataset using data provided by the competition**, then **merged state-level information** such as `Covid-19 infection` and `Policy` data which can be directly merged to our original data using `state` as a primary key. \n\nUsing this dataset, we analyzed the impact of Covid-19 infection and policy on online learning engagement. Moreover, we exploited this data for preliminary analysis on the heterogeneous impact of Covid-19 along with the socioeconomic factors such as race composition, economic status proxied by the rate of students for free lunch program eligible, and the total expenditure on education.\n\nSecondly, we further **constructed school district-level data** using `Student Performance` and `School Districts Information` data, we then aggregated up to the cell defined by `state x locale x blkhis_ratio x freereduced_ratio x pp_tot_exp` to match with school districts which lie in the identical cell.","640295b3":"### <font color=\"#6C8255\">4.1.3.2. Sub sample: Mostly Used Products<\/font>\nIn this sub-section, we sub-sampled part of products which was highly used by students. We exploited top 20 and 50 products based on both `access ratio` and `engagement index`.","378c8427":"<div id=\"2\"><\/div>\n\n# <font color=\"#6C8255\">2. Data<\/font>\n---\n<font size=3><b>In this section, we described on the data used in our analysis.<\/b> <br><br> We first explained data provided by the competition, including <b>engagement, districts and product information<\/b>. Then in the second sub-section, we introduced about <b>additional data we used to analyze the impact of Covid-19 and various policy<\/b> on studnet's engagment toward the product.<\/font>\n\n## <font color=\"#6C8255\">2.1. Main Data<\/font>\n### <font color=\"#6C8255\">2.1.1. Data Description<\/font>\nThe challenge provided following three datasets.\n\n#### <font color=\"#6C8255\">- Engagement<\/font>\nEngagement on each digital learning products on each school districts in the U.S. in 2020.\n\n<br>\n\n| Name | Description |\n| :--- | :----------- |\n| time | date in \"YYYY-MM-DD\" |\n| lp_id | The unique identifier of the product |\n| pct_access | Percentage of students in the district have at least one page-load event of a given product and on a given day |\n| engagement_index | Total page-load events per one thousand students of a given product and on a given day |\n\n<br>\n\n#### <font color=\"#6C8255\">- Products Information<\/font>\n\nGeneral information of digital learning products including `name of the product`, `provider`, `sector`, and `type of product`. This data provides information about the characteristics of the top 372 products with most users in 2020. \n\n<br>\n\n| Name | Description |\n| :--- | :----------- |\n| LP ID| The unique identifier of the product |\n| URL | Web Link to the specific product |\n| Product Name | Name of the specific product |\n| Provider\/Company Name | Name of the product provider |\n| Sector(s) | Sector of education where the product is used |\n| Primary Essential Function | The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled |\n\n<br>\n\n#### <font color=\"#6C8255\">- District Information<\/font>\n\nGeneral information of each school districts with various socio-economic aspects. This includes information about the characteristics of school districts, including data from [NCES](https:\/\/nces.ed.gov\/) (2018-19), [FCC](https:\/\/www.fcc.gov\/) (Dec 2018), and [Edunomics Lab](https:\/\/edunomicslab.org\/). \n\n<br>\n\n| Name | Description |\n| :--- | :----------- |\n| district_id | The unique identifier of the school district |\n| state | The state where the district resides in |\n| locale | NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See [Locale Boundaries User's Manual](https:\/\/eric.ed.gov\/?id=ED577162) for more information. |\n| pct_black\/hispanic | Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data |\n| pct_free\/reduced | Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data |\n| county_connections_ratio | `ratio` (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See [FCC data](https:\/\/www.fcc.gov\/form-477-county-data-internet-access-services) for more information. |\n| pp_total_raw | Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district. |","2f3e3f1f":"## <font color=\"#6C8255\">- Findings<\/font>\n\nOdd columns show the results without interaction term while even columns include interaction of Covid-19 and school closure policy. \n\n* In columns (1) and (3), where there is no interaction term, both **`Covid-19` and `School Closure` has positively correlated with online engagement**, although it is still not statistically significant at the conventional level, except for `School Closure` in column (3). This implies that **closing school for a whole month would increase 21.9% more engagement on average**.\n\n* Remaining columns (2), (4), we introduced **the interaction term between `Covid-19` and `school closure` to capture whether the impact varies along other impact** (i.e., check whether impact of school closure varies if the spread of Covid-19 differs). By doing so, the coefficient of `Covid-19` and `school closure` become negative and statistically significant on conventional level. However this does not necesaily implies that Covid-19 decreased student's engagment, rather we should also take into account the additional term - `Covid-19 x School Closure` which pulls out the interaction impact when both variable appears together by adding all in following manner:\n    $$Impact = \\beta \\cdot ln(Covid\\ cases_{i,s,p,m}) + \\gamma\\cdot School\\ Closure_{i,s,p,m} + \\eta\\cdot School\\ Closure_{i,s,p,m} \\times ln(Covid\\ cases_{i,s,p,m})$$\n\n* The coefficient for the interaction term indicates that **additional 1% increase in new monthly `Covid-19` cases would increase the impact of `school closure` by 0.11%** and this is **statistically significant at 1% level**, which clearly shows that **the impact of `school closure` would be increased as more `Covid-19` case appeases.**","37eb9837":"## <font color=\"#6C8255\">- Model<\/font>\nIn this sub-section, we again analyzed the degree of **Covid-19 and policy related to pandemic** have affected the online learning engagement of students with **additional control variables in district level**. \n\nTherefore we added several control variables of each school districts on `demographics` (e.g., share of Black and Hispanic of overall population; share of studentes who are ELL (English Langauage Learner) or who requires Special Education), `socio-economic status` (e.g., Median Income, share of B.A. degree holder), and `student's performance` (e.g., average test score).\n\nNote that our additional district information are merged to the main dataset by choosing a single value among mean, median, min, and max within a cell, defined as `state x locale x blkhis student ratio x freereduced lunch ratio x edu expenditure per pupil`. Thus we should focus on the overall trend of how additional district information correlated with outcome variable, and how our variable of interest changes, rather than the exact estimation.\n<br>\n\n$$ln(Y_{i,s,p,m})=\\alpha + \\beta \\cdot ln(Covid\\ 19_{i,s,p,m}) + \\gamma\\cdot School\\ Closure_{i,s,p,m} +\\mathbf{\\theta\\ X}_{i,s,p,m}+\\iota_m+\\kappa_s+\\epsilon_{i,s,p,m}$$\n\n$$ln(Y_{i,s,p,m})=\\alpha + \\beta \\cdot ln(Covid\\ 19_{i,s,p,m}) + \\gamma\\cdot School\\ Closure_{i,s,p,m} + \\eta\\cdot School\\ Closure_{i,s,p,m} \\times ln(Covid\\ 19_{i,s,p,m})+\\mathbf{\\theta\\ X}_{i,s,p,m}+\\iota_m+\\kappa_s+\\epsilon_{i,s,p,m}$$\n\n<br>\n\n* Again our variable of interest in this model is `Coivd-19` and `School Closure` which measures the new monthly Covid-19 cases and share of closed dates of school among a given month respectively. **This can be interpreted as 1% increase in new monthly Covid-19 case would increase a dependent variable by $\\beta$ %, while closing school completely for an entire month would increase by $\\gamma \\times 100$ %**, while $\\eta$ estimates the heterogeneous impact of policy by Covid-19 spread.\n\n* We further included **further socioeconomic factors (e.g.,`ethnic demographic`, `student's learning background`, `socio-economic status` and `student's performance`)**, in addition to existing socioeconomic factors (e.g., `share of black or Hispanic students`, `share of free or reduced-priced lunch program eligible students`, `total expenditure on education per pupil`, `locale`) and **product characteristics** (e.g., `function of products`, `sector` as a vector $\\mathbf{X}_{i,s,p,m}$ similar to our previous model. \n\n* Finally, $\\iota_m$ and $\\kappa_s$ capture month-, state-fixed effects to rule out unobserved characteristics within month and state.\n\n* Standard errors are **clustered in state-level**, and **weighted each observation by the population of the state** where the district is belonged to, as previous analysis.","c6161a65":"## <font color=\"#6C8255\">- Findings<\/font>\n\nThe first four columns show the results without interaction term while the last four columns include interaction of Covid-19 and school closure policy. \n\n* The most notable result is that the coefficient which measures the impact of `Covid-19` and `School Closure` policy now become **statistically significant with positive sign**. This provides concrete evidence that **the additional new Covid-19 infection and closing school do increase the student's engagement in digital learning**.<br>\n    * `Covid-19` infection **increased access ratio by 0.012%, while 0.031% on engagement** for every additional 1% new monthly Covid-19 infection.\n    * `Closing school` for an entire month **increased access ratio and engagement index by 50-52%, and 247-253% respectively**.<br><br>\n   \n* There are some different trend along with a socioeconomic status for each district as follow:\n    * **`Demographics`**\n        * We found that **additional share of Hispanics or Blacks population in a school district reduces access on digital learning products by 0.7\\~1.2%; and engagement by 3.6\\~5.2%**. This trend is different from what we have found from previous data. (i.e., inverse U shaped)<br><br>\n        \n    * **`Student's learning Background`**\n        * Districts with 1% more students who are **`ELL(English Language Learner)`** tend to **access and engage more by 1.1\\~1.9% and 7.7\\~11.4%** respectively.\n        * Having more students who require `special education` are likely to correlate positively with access ratio and engagement on online learning products. However, it is not statistically significant on a conventional level, to emphasize the result. <br><br>\n        \n    * **`Socio-economic status`**\n        * Having **favorable socioeconomic condition does not necessarily guarantee higher access or engagement** on online learning products.\n        * Students living in a district whose **`median income` is higher tends to access and engage more in digital learning**, but the degree is **not statistically different from 0** on the conventional level. \n        * On the other hand, the impact of having more **`B.A. degree holders` in a district is negatively correlated with student's engagement in digital learning**, but still **not statistically significant**. <br><br>\n        \n    * **`Student's Performance`**\n        * District which previously had **higher `test score` on average tends to access and engage more on online education product** on average. However, the coefficients are not statistically significant, and stable regardless of the type of specification.","824cfee6":"### <font color=\"#6C8255\">3.2.3. Data for Identifying School Districts: CCD, NERD\\$<\/font>\n\nSince we do not have an exact district ID for main data, we again collected the original data for the district's information on `blkhis_rate`, `freereduced_rate`, and `pp_totexp` from CCD and NERD data. Using the data we constructed the same categories as first provided.","8b5e5e38":"### <font color=\"#6C8255\">- Census Region<\/font>\n\n- Districts **located in the northwest part of the US has the highest `percent access` and `engagement index`** compared to other census regions. This is followed by districts in the mid-west, west, and south.\n\n- This trend holds for all types of product types but, again **the trend is distinctive except in 'Learning and Curriculum' products**.","751e5ce7":"## <font color=\"#6C8255\">4.1.3. Online Learning Engagement Information<\/font>\nIn this section, we analyzed information on online learning engagement information in two samples:\n\n* **All Sample**: Exploit information from all 352 products\n\n* **Sub Sample**: Using information from the product which was mostly used by students measured in both `percent access` and `engagement index` respectively. Moreover, we chose `top 20 and 50 products` to see whether the trend is stable.","d5eb03bf":"### <font color=\"#6C8255\">2.2.2. Issue on Data Construction and Our Approach: Identifying School District of the Original Data<\/font>\n\nFor state-level data such as `Covid-19 infection` and `Policy` data is possible to merge with the main data using `state` and `date` as a key variable. \n\nHowever, as original district information is provided with many missing data for privacy concern, it is difficult to identify the exact school-district. Hence we further acquired following data which is announced as an original source of 'district information' for each column for district identification. (Since internet connection data has small variation - mostly 0.18, we do not utilize the column for identification purpose)\n\n#### <font color=\"#6C8255\">- Student enrollment data (by race\/ethnicity, free\/reduced lunch program)<\/font>\n* **Source**: Common Core of Data (CCD) from [National Center for Education Statistics (NCES)](https:\/\/nces.ed.gov\/ccd\/)\n\n\n#### <font color=\"#6C8255\">- Per pupil government expenditure on education<\/font>\n* **Source**: National Education Resource Database on Schools \\(NERD\\$\\) from [Edunomics Lab](https:\/\/edunomicslab.org\/nerds\/)","92d61fba":"## <font color=\"#6C8255\">- Model<\/font>\nIn this subsection, we further analyzed whether the degree of Covid-19 and **policy related to pandemic** have affected the online learning engagement of students, if so what extent. We added several control variables -- `School`, `work`, `stayHome`, and `Stringency` on the equation described above.\n\n<br>\n\n$$ln(Y_{i,s,p,m})=\\alpha + \\beta \\cdot ln(Covid\\ 19_{i,s,p,m}) + \\gamma\\cdot School\\ Closure_{i,s,p,m} +\\mathbf{\\theta\\ X}_{i,s,p,m}+\\iota_m+\\kappa_s+\\epsilon_{i,s,p,m}$$\n\n$$ln(Y_{i,s,p,m})=\\alpha + \\beta \\cdot ln(Covid\\ 19_{i,s,p,m}) + \\gamma\\cdot School\\ Closure_{i,s,p,m} + \\eta\\cdot School\\ Closure_{i,s,p,m} \\times ln(Covid\\ 19_{i,s,p,m})+\\mathbf{\\theta\\ X}_{i,s,p,m}+\\iota_m+\\kappa_s+\\epsilon_{i,s,p,m}$$\n\n<br>\n\n* Our variable of interest in this model is `School Closure` which measures the share of closed dates of school among a given month. **This can be interpreted as closing school completely for an entire month would increase a dependent variable by $\\gamma \\times 100$ %**, while $\\eta$ estimates the heterogeneous impact of policy by Covid-19 spread.\n\n* We further included **log of `Coivd-19`**, **socioeconomic factors** (e.g.,`share of black or Hispanic students`, `share of free or reduced-priced lunch program eligible students`, `total expenditure on education per pupil`, and `locale`), and **product characteristics** (e.g., `function of products`, `sector` as a vector $\\mathbf{X}_{i,s,p,m}$ as the previous model. \n\n* Finally, $\\iota_m$ and $\\kappa_s$ capture month-, state-fixed effects to rule out unobserved characteristics within month and state.\n\n* Standard errors are **clustered in state-level**, and **weighted each observation by the population of the state** where the district is belonged to, as previous analysis.","5e3f1f5b":"### <font color=\"#6C8255\">- Distribution of Functions weighted by Engagement Behavior<\/font>\n\nThe following pie charts show the importance of considering `engagement index` to wholly understand online learning habits. The figure on the left side is identical to those in the previous section - unweighted distribution of the main function of products, while the right figure describes how students are engaged on each product function, by drawing a pie chart of products weighted by engagement index.\n\n* Although **School and Districts Operations** consists less than 10% of total products, it now becomes 20% after considering student engagement. This clearly shows that students on average use more on each **School and Districts Operations** products relative to **Learning and Curriculum** and **Classroom Management** products whose share decreased - i.e., students use such products more intensely compare to another type of products.\n\n* In similar logic, the share of **Classroom Management Tools** decreased as **School and Districts Operations**. This indicates that during the pandemic era, virtual classroom services such as `Zoom`, and `Google Hangout` did not use much as other sectors compared to other online learning tools.","e36219ba":"### <font color=\"#6C8255\">- Distribution of Online Learning Engagements (By Sub-Function)<\/font>\nThe following plots describe the distribution of student's engagement for each sub-function.\n\n- **Access Ratio**\n\nAmong 'School District Operations' product which has the highest `percent access`, **'Learning Management System' and 'School Mangamgnet Sotfware' had the highest index compared to other product types.** Those access ratios are at least 50% higher than any other product type.\n\n- **Engagement Index**\n\nThe trend is similar to the previous figure. However the **difference of annual average `engagement index` between the highest and the second is larger** compared to the access ratio. (i.e., more than 300%).","42a172ec":"### <font color=\"#6C8255\">3.1.3. Products Information<\/font>\nThe data provides information on products including `lp_id`, `url`, `product_name`, `provider_name`, `sectors`, `primary_function`.\n\n* Generated dummy variables for each sector (i.e., mark whether the product is used for K-12)\n* Split the `primary_function` into 2 levels as it is separated in a very detailed level.\n* Synchronized `primary_function` value which is not consistent even they are alike (e.g., 'Sites, Resources & References' -> 'Sites, Resources & Reference')","954fa40f":"### <font color=\"#6C8255\">3.1.5. COVID-19 Policy Measure: OxCGT (Blavatnik School of Government, U of Oxford)<\/font>\nThe dataset tracks 18 government policy responses in three different policy areas. We kept only containment related policies (i.e., 8 policies `school`, `work`, `publicEvent`, `gathering`, `publicTrans`, `stayHome`, `interMove`, `travelControl`) and three indices which measures the degree for each area - containment, economic support and overall index (`stringency`, `govtResponse`, `econSupport`) in daily basis.\n\n* Replace `.` as `np.nan`\n* Aggregated the data into `state x month` level, which will allow us to analyze the impact of Covid-19 in `monthly` level. (e.g., If the given `state x month` has the value `0.45` in `school` column, then it implies that school was closed for `45%` of the month in a given state.)","24bcf0c0":"## <font color=\"#6C8255\">- Public Investment on Education (Expenditure on Education per pupil)<\/font>\n\n* Trend goes similar with the national trend\n\n* **Having more education investment tends to have a higher engagement index**, but its deviation also gets bigger.","813ad5fd":"### <font color=\"#6C8255\">- Ethnicity (% Black, Hispanic Students)<\/font>\n\n- There is a generally **decreasing trend on both `percent access` and `engagement index` as more black and Hispanic students consist majority**.\n\n- Although there is a little district where **80% of students are black and Hispanic** (4.55% of the total sample), its **`percent access` and `engagement index` is the highest** among any other districts.\n\n- This trend holds for all types of product types but, **the trend is distinctive in 'Classroom Management' and 'School and District Operations' products**\n","41313ea0":"<div align='center'><font size=\"6\" color=\"#6C8255\">Impacts of Covid-19 on Digital Learning<\/font><\/div>\n<div align='center'><font size=\"4\" color=\"#6C8255\">Heterogeneous Impact of Covid-19, School Closure, and Socioeconomic Status on Online Learning Engagements<\/font><\/div>\n<div align='center'><font size=\"3\" color=\"#6C8255\">Soohyung Lee, Minhyuk Nam<\/font><\/div>\n<hr>\n\n## <font color=\"#6C8255\">Contents:<\/font>\n<a href='#1'>1. Introduction<\/a>   \n<a href='#2'>2. Data<\/a>   \n<a href='#3'>3. Data Cleaning<\/a>   \n<a href='#4'>4. Explanatory Data Analysis (EDA)<\/a>   \n<a href='#5'>5. Multivariate Linear Regression Analysis<\/a>","f48d2d67":"## <font color=\"#6C8255\">- Locale<\/font>\n\nOdd columns show the results without heterogeneous interaction terms while even columns include heterogeneous interaction terms of Covid-19 and school closure policy. **Baseline group is the district in the Suburb area.**\n\nUnlike our figures drawn previously, **being rural had lower student's online learning participation, while high in city and town relative to suburb area**. Therefore the reverse results may be due to the different Covid-19 trends by each locale.\n\n* **Column (2)**:  **District in a rural area tends to have a lower access ratio by 5.2%, while the town has a higher rate by 68.6% relative to the baseline which is Suburb area**. This directly rebuffs our bar plot on annual average engagement information for each category in [section 4.2.2](#--Economic-Status-(Lunch-Program-Eligibility)).\n\n* **Column (4)**: Similar to column (2), **district in rural is likely to have lower engagement by 12.6%, while city and town are higher by 20.6% and 213.0% respectively.**","9ed422eb":"<div id=\"5\"><\/div>\n\n# <font color=\"#6C8255\">5. Multivariate Linear Regression Analysis<\/font>\n---\n\n<font size=3><b>\"Does Covid-19 matter on student's online engagement even after considering various factors?, if so for what extent?\"<\/b><\/font>\n\n<br>\n\n<font size=3>So far, we have seen the relationship between engagement and single factors that might affect through graphs. However, it was difficult to conclude whether each factor affects the student's online learning engagement. This is because various factors that might have affected the engagement and spread of Covid-19 have highly correlated in each district. <b>Hence, we exploited the linear regression model to rigorously estimate the impact of Covid-19 and various socio-economic factors on student's learning participation.<\/b><\/font>","6c3a1e8e":"## <font color=\"#6C8255\">- Economic Status (Lunch Program Eligibility)<\/font>\nOdd columns show the results without heterogeneous interaction terms while even columns include heterogeneous interaction terms of Covid-19 and school closure policy. **Baseline group is the district where there is only 0-20% of students are eligible for free, reduced-price lunch.**\n\nOverall, the districts with **more students who are economically disadvantaged (proxied by the eligibility of free lunch program) tend to engage less than those who are not**. However, the trend is reversed for a district with the majority (over 80%) are eligible for the free lunch program.\n\n* **Column (2)**: **District with 2-40%, and 6-80% of students are eligible for the free lunch tends to access fewer online products by 7.5%, 7.9%. While districts with over 80% students are economically disadvantaged are likely to increase by 15.4% compared to our baseline group**. This directly reflects the inverse U-shaped bar plot for annual average engagement information for each category in [section 4.2.2](#--Economic-Status-(Lunch-Program-Eligibility)).\n\n* **Column (4)**: Again, this also depicts the U-shaped bar plot for annual average engagement information for each category as in column (2).","5929df37":"### <font color=\"#6C8255\">- Total Expenditure on Education per Pupil<\/font>\n\n**Left figure shows the distribution of the expenditure on education per pupil which was originally provided.** As shown in the chart, there are numerous outliers at the bottom (less than \\\\$8,000) and the top (above \\$20,000). If we exploit this value as given then the dummy variables for each category would capture the district fixed effect rather than the impact of total expenditure itself. \n\nHence we **modified the values as the right figure shows**, by merging the categories into single which are below `$8,000` and above `$18,000`. By doing so, each category became balanced.","02422df6":"## <font color=\"#6C8255\">- Ethnicity<\/font>\n\n* Trend goes similar with the national trends\n\n* District with over **80% black or Hispanic students have the highest engaged level** but it **varies a lot** as time went by. Especially there is a big spike between March and April, unlike other groups.","f689d475":"### <font color=\"#6C8255\">- List of Top 20 Products<\/font>\n\nThe following figures describe `access ratio` and `engagement index` of the top 20 products. All values are the annual average of each product.","fbdea0e6":"# <font color=\"#6C8255\">4.2. Bivariate Analysis: Can such factor explain online learning engagment?<\/font>\n<font size=3> In this sub-section, we have studyed <b>how 'acess ratio' and 'engagment index' is different along the various socioeconomic factors<\/b> to see whether such factor is correlated with the online learning engagement behavior. <\/font>","48fbf7f2":"### <font color=\"#6C8255\">2.1.2. Notes on Data Construction<\/font>\nAs our main aim is to find out whether the COVID-19 pandemic has affected on online learning engagements, we are going to merge `products information` and `district information` to the `engagement` data. This will allow us to analyze engagement by controlling various product-specific and district information. By doing so, we can estimate the true impact of our interest (e.g., the spread of COVID-19, etc.) under the same circumstance including race composition, economic status, government expenditure on education.","4cb08d41":"### <font color=\"#6C8255\">4.1.3.1. All sample<\/font>\nTo see the distribution of engagement information, **we took a simple average for each product**. By doing so, we acquired annual average `percent access` and `engagement index` for 352 products.","9a7d364e":"### <font color=\"#6C8255\">- Distribution of Online Learning Products<\/font>\n\nFollowing pie charts and bar graphs implies the distribution of 352 mostly used products.\n\n* Considering multiple categories (e.g., If the product was made for both PreK-12 and Higher Education, we count both for each category), **over half (54.04%) of total products were intended to be used by PreK-12 students**, and this clearly shows that **our analysis lies on the K-12 student's online learning experience**.\n\n* Among 352 products, **over three quarter (77.27%) were `Learning and Curriculum products`** including Digital Learning Platforms (e.g., `myLexia`, `ALEKS`), Sites, Resources and Reference (e.g., `Wikipedia`, `CNN Student News`, `Dictionary.com`), and Study Tools (e.g., `Grammarly`, `Google Translate`, `Quora`), followed by **`Classroom Management Tools`** (e.g., `Zoom`, `Google Hangout` as a virtual classroom, and `Google Groups`, `Google Forms` as a classroom engagement tools), and **`School and Districts Operations`** (e.g., `Google Classroom`, `Blackboard` as a learning management systems, and `Clever`, `ClassLink` as a school management software)\n\n* **Almost half of the products are classified into `Sites, References and Reference` and `Digital Learning Platform`** such as `myLexia`, `ALEKS`, `Wikipedia`, `CNN Student News`, and `Dictionary.com` which were the most conventional online learning tools before the Covid-19 pandemic.","42e0fc54":"## <font color=\"#6C8255\">2.2. Additional Data<\/font>\n### <font color=\"#6C8255\">2.2.1. Data Description<\/font>\nTo rule out the possibility of biased result estimating the impact of Covid-19 pandemic, due to the **omitted variable bias**, we exploit additional data. Following are the list of data with its source and description:\n\n#### <font color=\"#6C8255\">- Covid-19 infection (State-level)<\/font>\n* **Source**: Economic Tracker data provided by [Opportunity Insights](https:\/\/opportunityinsights.org\/)\n* **Description**: Provides daily Covid-19 epidemiological data including the number of confirmed and death cases at the state level.\n\n#### <font color=\"#6C8255\">- Policy (State level)<\/font>\n* **Source**: Coronavirus Government Response Tracker (OxCGRT), provided by the [Blavatnik School of Government at the University of Oxford](https:\/\/www.bsg.ox.ac.uk\/research\/research-projects\/covid-19-government-response-tracker)\n* **Description**: Contains overall state government response toward Covid-19 daily. The dataset tracks 18 government policy responses in three different policy areas including `containment` (e.g., restriction in movement, closure of workplace or school), `health system` (e.g., accessibility of Covid-19 testing, amount of vaccine investment), and `economic support` (e.g., income support, debt relief to citizens). The dataset then provides a single index number for each area, normalized between 0 and 100. \n\n#### <font color=\"#6C8255\">- Student Performance (School district level)<\/font>\n* **Source**:  Stanford Education Data Archive (SEDA) 4.1 data provided by [The Educational Opportunity Project at Stanford University](https:\/\/edopportunity.org\/)\n* **Description**: Provides student's academic performance data at the school district level. Metrics include `test score` and `learning rates`, using federal standardized test results from all students in grades 3-8 in each year in math and RLA (i.e., Reading Language Arts) We utilized data collected during 2017-18 which is the most recent data available.\n\n#### <font color=\"#6C8255\">- School District Information (School district level)<\/font>\n* **Source**:  Stanford Education Data Archive (SEDA) 4.1 data provided by [The Educational Opportunity Project at Stanford University](https:\/\/edopportunity.org\/)\n* **Description**: Includes the characteristics of school districts such as demographic composition of students (e.g., ethnicity, special education etc.) and socio-economic status (e.g., income level, education attainment, employment status)","11a483c8":"### <font color=\"#6C8255\">3.1.4. COVID-19 Infection: Economic Tracker (Opportunity Insights)<\/font>\nThe data consists of the number of Covid-19 infections (`case_count`, `death_count`) in each state on daily basis.\n* Replace `.` as `np.nan`\n* Aggregated the data into `state x month` level, which will allow us to analyze the impact of Covid-19 in `monthly` level","69980ab9":"## <font color=\"#6C8255\">- Findings<\/font>\n\n* As shown in the table, the new monthly Covid-19 infection case is **positively correlated with student's engagement behavior** unlike our previous graphical analysis in [section 4.2.1](#--New-Covid-19-Confirmed-Cases). \n\n* However, it is worth noting that it is **not statistically significant on conventional level**. This implies that Covid-19 itself has **high probability that there is no impact on online learning engagement on average**.","3197e036":"## <font color=\"#6C8255\">- Results<\/font>\nSimilar to our previous results, **`Covid-19` itself is negatively correlated with online engagement**, and **`school closure` is positively correlated with overall online learning engagement behavior**. This implies that online engagement increases when students cannot go to school.\n\nIn columns (2) and (4), we introduced the heterogeneous interaction term between `Covid-19` and `school closure`. However, the variable of interest (i.e., `Covid-19` and `School Closure`) does not change its direction, which **guarantees the robustness of our model**. Followings are the overall results by each variable:\n\n* **Ethnicity**: **Composition of ethnicity does not affect the student's online learning participation** unless the district is consists of the majority (over 80%) of black and Hispanic students. However, the impact is substantial in the district with over 80% are black and Hispanic students.\n\n* **Economic Status**: Districts with **more students who are economically disadvantaged (proxied by the eligibility of free lunch program) tend to engage less than those who are not**. However, the trend is reversed for districts with the majority (over 80%) are eligible for the free lunch program.\n\n* **Education Expenditure**: Unlike our previous figures, there is **no impact of getting more total expenditure on education per pupil on online learning behavior**. Therefore the increasing engagement along the expenditure might due to the different Covid-19 trends by each category or duee to state fixed effects.\n\n* **Locale**: Far from our graphics, **being rural had lower student's online learning participation, while high in city and town relative to suburb area**. Therefore the reverse results may be due to the different Covid-19 trends by each locale.","b53a8336":"### <font color=\"#6C8255\">- Annual Average Online Learning Engagements<\/font>\nAs we sub-sampled the most engaged products, the variation of engagement information reduced for top 20. However it was not the case for top 50.","2ed63f79":"# <font color=\"#6C8255\">5.5. Heterogenious Time trend along Products<\/font>\n<font size=3><b>\"How does student engagement with different types of education technology change over the course of the pandemic?\"<\/b><\/font>","933851be":"### <font color=\"#6C8255\">- Relationship between Variables<\/font>\nFollowing heatmaps describe the distribution of each combination of two socioeconomic variables. A similar colored figure indicates that the distribution is quite uniform, while distinctive bright color implies higher density than other combinations.\n\nAs shown in figures, bright reddish color appears in a district with 0-20% black and Hispanic students. This is because almost two-third (65.91%) lie in this category. **This implies that the distribution of the sample is quite skewed left in terms of ethnic information.** ","9785c56f":"## <font color=\"#6C8255\">1.2. Overview<\/font>\n\n### <font color=\"#6C8255\">- Data<\/font>\nIn this notebook **we exploited additional data source** provided by [Opportunity Insights](https:\/\/opportunityinsights.org\/), [Blavatnik School of Government at the University of Oxford](https:\/\/www.bsg.ox.ac.uk\/research\/research-projects\/covid-19-government-response-tracker), [The Educational Opportunity Project at Stanford University](https:\/\/edopportunity.org\/) which measures spread of Covid-19, state government's response toward pandemic, and various characteristics on school districts especially student's performance and additional socio-economic factors such as ESL learners, income level and overall educational backgrounds. \n\n<br>\n\n### <font color=\"#6C8255\">- Methodology<\/font>\nUsing our rich dataset, **we studied how recent pandemics have been affected students' learning behavior and analyzed whether it varies along with the socioeconomic background.** We utilized **multivariate regression model with time and location fixed effect** because this allows us to control unobserved factors which vary within a time and location unit, even the data provided lacks information on district characteristics.\n\nWe tried to merge additional information (such as income level, educational attainment, student's previous performance, etc.) even we were not able to identify the district using the given information. To tackle this problem, we **tried to identify the district by generating a cell** (i.e., `state x locale x blkhis student ratio x freereduced lunch ratio x edu expenditure per pupil`) **by acquiring the original dataset for district information from the source** -- [National Center for Education Statistics (NCES)](https:\/\/nces.ed.gov\/ccd\/), and [Edunomics Lab](https:\/\/edunomicslab.org\/nerds\/). This allowed us to find out which districts lie in each cell. By using this information we have added various representative values (i.e., mean, median, min, max) of additional district information within a cell level. \n\nAmong 176 districts in the whole sample, we used 93 that report five variables - state, locale, blkhis ratio, freereduced ratio, and expenditure per pupil - which are needed to construct a cell. Using those districts, we classified them into 65 unique cells, to match with our additional data acquired.\n\n<br>\n\n### <font color=\"#6C8255\">- Findings<\/font>\nWe have found followings:\n* We found that the spread of `Covid-19` and the implementation of `school closure policy` **are positively affected on online learning engagement**.\n\n* The impact of `school closure` gets increased as more Covid-19 cases appear, which implies that **students living in the district where 'Covid-19' is highly infected, would access and engage more on online learning products when school is closed.**\n\n* There is a heterogeneous on online learning engagement along with socioeconomic characteristics of students -- (1) having more black and Hispanic student tends to access and engage less, (2) and **economically disadvantaged students (proxied by the eligibility of free lunch program or median income level in district) tends to engage less than those who are not** on average as well. (3) Districts with **more expenditure on education does not necessarily increase online learning product**, (4) but districts in **rural and suburb area tend to engage less** relative to city and town area. (5) More ELL (English Language Learner) students and (6) districts that had higher average test scores are likely to access and engage more in online learning.\n    \n* There is also a heterogeneous on online learning engagement along with the type of products -- **'School and Districts Operation'** (e.g., Google Classroom) tends to be **accessed less by 10.8% during school closure**, and engagement has been **decreased most rapidly** compared to any other product types. However, **'Classroom Management Tools'** (e.g., 'Zoom' and 'Google Hangout') was **engaged and accessed 65.7% and 12.6% more respectively.**","23fe860b":"## <font color=\"#6C8255\">1.3. Section Overview<\/font>\nBased on the problem statement provided by `LearnPlatform`, we have structured our notebook as follows:\n- **Data \/ Data Cleaning**\n- **Explanatory Data Analysis**\n- **Multivariate Linear Regression Analysis**\n\n### <font color=\"#6C8255\">- Data \/ Data Cleaning<\/font>\nIn this section, we described on data that we have used in our analysis, and how we cleaned and merged separated raw data into single dataframe.\n\n### <font color=\"#6C8255\">- Explanatory Data Analysis<\/font>\nWe have plotted some figures in various ways -- univariate, bivariate and time trend -- to see **how each variable is distributed, whether each variable is correlated with outcome variable, and how it evolves over time.**\n\n### <font color=\"#6C8255\">- Multivariate Linear Regression Analysis<\/font>\nFinally we have reported several regression results in conventional manners to answer following questions:\n* **Impact of COVID-19**: What is the effect of the COVID-19 pandemic on online and distance learning?\n* **Impact of COVID-19 Policy**: Do certain state interventions, practices or policies (e.g., stimulus, reopening, eviction moratorium) correlate with the increase or decrease online engagement?\n* **Heterogeneity of socio-economic factor**: How does student engagement with online learning platforms relate to different geography? Demographic context (e.g., race\/ethnicity, ESL, learning disability)? Learning context (e.g., previous performance, race\/economic diversity etc.) ? Socioeconomic status (e.g., race\/ethnicity, income level, BA+ degree etc.)?\n* **Heterogenious Time trend along Products**: How does student engagement with different types of education technology change throughout the pandemic?","5f8553e9":"## <font color=\"#6C8255\">- National Trend<\/font>\n\n* Both indexes **varies along with semester**; which indicates that the index increased with a new semester, and decreased as vacation starts.\n\n* Overall online engagement has been **increased compared to the first semester (i.e., Jan-Jun) with pandemic**; This implies that students become more familiar as time passes.\n    \n*  **Difficult to detect the direct relationship of spread of Covid-19 and school closure policy toward engagement** without controlling other factors.","3b0e1685":"## <font color=\"#6C8255\">- Ethnicity<\/font>\n\nOdd columns show the results without heterogeneous interaction terms while even columns include heterogeneous interaction terms of `Covid-19` and `school closure` policy. **Baseline group is the district where there is only 0-20% of black and Hispanic students.**\n\nOverall, **composition of ethnicity does not affect the student's online learning participation** unless the district is consist of the majority (over 80%) of black and Hispanic students, but the degree is minute which is 0.019% and 0.069% increase for additional 1% increase in new monthly Covid-19 cases.\n\n* **Column (2)**: District with 2-40% of students who are black or Hispanic tend to access more by 5.4% relative to the baseline group. However, when new Covid-19 cases increased by 1% while school is completely closed, districts with over 80% of students who are black or Hispanic, tends to increase 0.019% more access on online learning product on average relative to the baseline group. \n\n* **Column (4)**: In a district where 80% of students are black or Hispanic, 1% additional Covid-19 cases when school is closed completely, tend to engage 0.069% more to the product on average compared to the baseline group under complete school closure policy.","7d4a09a0":"### <font color=\"#6C8255\">- School Closure Policy<\/font>\nHere we plotted the relationship between the `school closure` policy and `student's engagement` toward the online learning products. Each observation is the annual average of each variable. Again, the upper two figures show the `mean` and `median` of each variable of each decile group defined by `percentage of days that the school was closed`. Latter two scatter plots depict the relationship between our variable of interest and the policy.\n\n<br>\n\nAs shown in the figure, there is **an increasing relationship between the policy and both `percent access` and `engagement index`**, which is similar to our general conjecture that making students attend less school has increased students' engagement on online learning product. However, still, it is likely that other factors  might be correlated with the policy so that the relationship might have been led from the other variable. Hence, we will revisit this issue by utilizing the multivariate linear regression model in [section 5.2.](#5.2.-Impact-of-COVID-19-Policy)","30b2e28c":"### <font color=\"#6C8255\">- Economic Status (Lunch Program Eligibility)<\/font>\n\n- Similar to ethnicity, there is a generally **decreasing trend on both `percent access` and `engagement index` as more students are eligible for the lunch program**.\n\n- Although there are a few districts where **80% of students are eligible for the program** (2.70% of the total sample), its **`percent access` and `engagement index` is the highest** among any other districts. \n\n- Conditional on the proportion of black and Hispanic students is over 80%, 74% of districts have over 80% of lunch program eligibility. Hence the similarity with previous results seem reasonable.\n\n- This trend holds for all types of product types but, **it is distinctive in 'Classroom Management' and 'School and District Operations' products**","9d57a1f0":"# <font color=\"#6C8255\">5.3. Impact of COVID-19 and Policy Revisited (with Additional Controls)<\/font>\n<font size=3><b>\"Do certain state interventions, practices or policies STILL correlate with the increase or decrease online engagement EVEN AFTER CONTROLLING ADDITIONAL VARIABLES?\"<\/b><\/font>","f691b933":"## <font color=\"#6C8255\">- Public Investment on Education (Expenditure on Education per pupil)<\/font>\n\nOdd columns show the results without heterogeneous interaction terms while even columns include heterogeneous interaction terms of Covid-19 and school closure policy. **Baseline group is the district where total expenditure per pupil is \\$4,000**\n\nUnlike our figures in the previous section, **getting additional total expenditure on education per pupil does not necessarily increase online learning behavior**. Therefore the increased engagement along the education expenditure might be due to the different Covid-19 trends by each group and state fixed effects.","98124f56":"<div id=\"4\"><\/div>\n\n# <font color=\"#6C8255\">4. Explanatory Data Analysis<\/font>\n---\n\n<font size=3><b>\"What is the picture of digital connectivity and engagement in 2020?\"<\/b><\/font>\n\n<br>\n\n<font size=3>We first <b>analyzed our data for each variable to see how each variable is distributed<\/b>. Then we moved on to <b>see the relationship between a socioeconomic variable and our output variable<\/b> namely 'percent access' and 'engagement index', to see whether those variables are positively or negatively correlated. Finally, we end up plotting <b>the evolution of 'engagement index' by each socioeconomic group<\/b> to test whether each group behaves differently as time goes.<\/font>\n\n# <font color=\"#6C8255\">4.1. Univaiate Analysis: How does the sample look like?<\/font>\n## <font color=\"#6C8255\"> 4.1.1. Districts Information<\/font>\nFollowing pie charts show distribution of characteristics on `Share of black\/hispanic students`, `Share of free\/reduced price lunch eligible students`, `Share of high-speed internet connection`, and `Total expenditure on education per pupil`.\n\n<br>\n\n### <font color=\"#6C8255\">- Share of Black\/Hispanic Students<\/font>\n\n**There are 0-20% of black and Hispanic students in almost two-third of the districts (65.91%)**, while there is a similar portion for other categories.\n\n\n### <font color=\"#6C8255\">- Share of Free, Reduced Price Lunch Eligible Students<\/font>\n\n**Distribution on each group is quite balanced as there is a similar proportion each (around 30%)**. However, there are few districts (11.48%) where the majority of students (i.e., 6-80%, and above 80%) were eligible for the lunch program.\n\n\n### <font color=\"#6C8255\">- Share of High-Speed Internet Connection<\/font>\n\n**There is a very small variation in this variable**, as the majority of our districts has `[0.18, 1.0[` value while only 0.62% has over `[1.0[`. Therefore we would not take this variable seriously to see the heterogeneity derived from it. (i.e., only 1 district takes the value `[1.0[`)","bd140df7":"### <font color=\"#6C8255\">- Public Investment on Education (Expenditure on Education per pupil)<\/font>\n\n- There is a **clear increasing trend on both `percent access` and `engagement index` as there is more investment toward the education**.\n\n- This trend holds for all types of product types but, again **the trend is distinctive in 'Classroom Management' and 'School and District Operations' products**"}}