{"cell_type":{"6920ee60":"code","b2c2d5b2":"code","3596c375":"code","3903ed8a":"code","ee57a385":"code","367e8982":"code","b9f90016":"code","8a896122":"code","9013ebc8":"markdown","5c3d1cf0":"markdown","bbe51881":"markdown","a173ad10":"markdown"},"source":{"6920ee60":"import numpy as np\nimport pandas as pd\nimport random\nimport time\nimport gc\nimport os\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nimport xgboost as xgb\nimport optuna\nimport warnings\nprint('done!')","b2c2d5b2":"\ndata = {\n    \"train\" : \"..\/input\/tabular-playground-series-sep-2021\/train.csv\",\n    \"test\"  : \"..\/input\/tabular-playground-series-sep-2021\/test.csv\",\n    \"sample\": \"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\"\n}\n\ntrain  = pd.read_csv(data[\"train\"])\ntest   = pd.read_csv(data[\"test\"])\nsample = pd.read_csv(data[\"sample\"])\n\n\ndf1 = pd.read_csv(\"..\/input\/tabular-sep-21\/train_pred_1.csv\")\ndf2 = pd.read_csv(\"..\/input\/tabular-sep-21\/train_pred_2.csv\")\ndf3 = pd.read_csv(\"..\/input\/tabular-sep-21\/train_pred_3.csv\")\ndf4 = pd.read_csv(\"..\/input\/tabular-sep-21\/train_pred_4.csv\")\ndf5 = pd.read_csv(\"..\/input\/tabular-sep-21\/train_pred_5.csv\")\ndf6 = pd.read_csv(\"..\/input\/tabular-sep-21\/train_pred_6.csv\")\n\ndf_t1 = pd.read_csv(\"..\/input\/tabular-sep-21\/test_pred_1.csv\")\ndf_t2 = pd.read_csv(\"..\/input\/tabular-sep-21\/test_pred_2.csv\")\ndf_t3 = pd.read_csv(\"..\/input\/tabular-sep-21\/test_pred_3.csv\")\ndf_t4 = pd.read_csv(\"..\/input\/tabular-sep-21\/test_pred_4.csv\")\ndf_t5 = pd.read_csv(\"..\/input\/tabular-sep-21\/test_pred_5.csv\")\ndf_t6 = pd.read_csv(\"..\/input\/tabular-sep-21\/test_pred_6.csv\")\n\n","3596c375":"features = [col for col in train.columns if col not in ('id', 'claim')]\nTARGET   = 'claim'\ntarget   = train[TARGET].copy()\n\ntrain[\"min\"] = train[features].min(axis=1)\ntest[\"min\"]  = test[features].min(axis=1)\n\ntrain[\"max\"] = train[features].max(axis=1)\ntest[\"max\"]  = test[features].max(axis=1)\n\ntrain[\"std\"] = train[features].std(axis=1)\ntest[\"std\"]  = test[features].std(axis=1)\n\ntrain[\"n_missing\"] = train[features].isna().sum(axis=1)\ntest[\"n_missing\"]  = test[features].isna().sum(axis=1)\n\nfeatures += ['std', 'n_missing']\n\nn_missing = train[\"n_missing\"].copy()\n\n","3903ed8a":"train[features] = train[features].fillna(train[features].mean())\ntest[features]  = test[features].fillna(test[features].mean())\n\n# scaler = StandardScaler()\nscaler = RobustScaler()\n# scaler = MinMaxScaler()\n\ntrain[features] = scaler.fit_transform(train[features])\ntest[features]  = scaler.transform(test[features])\n\nN_SPLITS = 5\nN_ESTIMATORS = 500\nEARLY_STOPING_ROUND = 200\nVERBOSE = 1000\nSEED = 2021\n\nN_BINS = 20\n\ndef seed_everything(seed = 42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything(SEED)","ee57a385":"df = train.copy()\n\ndf = df.merge(df1, on=\"id\", how=\"left\")\ndf = df.merge(df2, on=\"id\", how=\"left\")\ndf = df.merge(df3, on=\"id\", how=\"left\")\ndf = df.merge(df4, on=\"id\", how=\"left\")\ndf = df.merge(df5, on=\"id\", how=\"left\")\ndf = df.merge(df6, on=\"id\", how=\"left\")\n\ndf_test = test.copy()\n\ndf_test = df_test.merge(df_t1, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_t2, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_t3, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_t4, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_t5, on=\"id\", how=\"left\")\ndf_test = df_test.merge(df_t6, on=\"id\", how=\"left\")\n\n\nnew_features = [col for col in df.columns if col.startswith('pred')]\n\n","367e8982":"lgb_oof  = np.zeros(train.shape[0])\nlgb_pred = np.zeros(test.shape[0])\n\n\nlgb_params = {    \n    'objective': 'binary',\n    'n_estimators': N_ESTIMATORS,\n    'random_state': SEED,\n    'num_leaves': 1024,\n    'colsample_bytree': 0.9936205081531161,\n    'learning_rate': 0.11148211208623116,\n    'max_depth': 4,\n    'min_child_samples': 25,\n    'min_child_weight': 6,\n    'reg_alpha': 2.7099507331966978e-06,\n    'reg_lambda': 0.00020521474176137927,\n    'subsample': 0.9600566076878911,\n    \n    'gpu_id': 0,\n    'predictor': 'gpu_predictor',\n    'tree_method': 'gpu_hist',\n    'objective': 'reg:squarederror'\n}","b9f90016":"features = features + new_features\n\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nvalid_predictions = {}\ntest_predictions  = []\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X = df, y = n_missing)):\n    print(f\"===== fold {fold} =====\")\n\n    xtrain, ytrain = df.iloc[trn_idx], df[TARGET].iloc[trn_idx]\n    xvalid, yvalid = df.iloc[val_idx], df[TARGET].iloc[val_idx]\n\n    xtest = df_test[features]\n\n    valid_ids = xvalid.id.values.tolist()\n\n    xtrain = xtrain[features]\n    xvalid = xvalid[features]\n        \n    \n    start = time.time()\n\n    model = xgb.XGBClassifier(**lgb_params)\n    model.fit(\n        xtrain, ytrain,\n        eval_set=[(xvalid, yvalid)],\n        eval_metric='auc',\n        early_stopping_rounds = EARLY_STOPING_ROUND,\n        verbose = VERBOSE\n    )\n    \n\n    val_pred = model.predict_proba(xvalid)[:, -1]\n    test_pred= model.predict_proba(xtest)[:, -1]\n\n    lgb_oof[val_idx] = val_pred\n    lgb_pred += test_pred \/ N_SPLITS\n\n    test_predictions.append(test_pred)\n    valid_predictions.update(dict(zip(valid_ids, val_pred)))\n\n    elapsed = time.time() - start\n    auc = roc_auc_score(yvalid, lgb_oof[val_idx])\n\n    print(f\"fold {fold} - lgb auc: {auc: .6f}, elapsed time: {elapsed:.2f}sec\\n\")\n\nprint(f\"oof lgb roc = {roc_auc_score(train[TARGET], lgb_oof)}\")\n\n","8a896122":"output = sample.copy()\noutput.claim = np.mean(np.column_stack(test_predictions), axis=1)\noutput.to_csv(\"submission.csv\", index=False)","9013ebc8":"## Fit","5c3d1cf0":"## Data","bbe51881":"## Feature","a173ad10":"## Tuning"}}