{"cell_type":{"578ceb73":"code","52137318":"code","b90d6450":"code","5fc386ae":"code","a31611ed":"code","27de8254":"code","c5fc0336":"code","6a106fde":"code","49649947":"code","fdc7328c":"code","a558fa7b":"code","2761143d":"code","5e0c80d3":"markdown","0e249929":"markdown","595c314b":"markdown","897d95dc":"markdown","e4a8f9ad":"markdown","6ab01780":"markdown","ae9d04f7":"markdown","94df17e8":"markdown","884e1b1b":"markdown","75dafb1e":"markdown","88a874e8":"markdown","3d2da181":"markdown","d8b50d89":"markdown","24afaacb":"markdown","ec6444c9":"markdown"},"source":{"578ceb73":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","52137318":"df = pd.read_csv('..\/input\/sensor.csv', engine='python', sep = ',', decimal = '.')\ndf['timestamp'] =  pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S' ,utc='True')\ndf.head()\n","b90d6450":"d = df['timestamp'].diff()\nplt.plot(d[1:])","5fc386ae":"df.drop(['Unnamed: 0'], axis=1, inplace=True)","a31611ed":"\nprint(df.shape)\nnan_stats = df.isnull().sum().sort_values(ascending = False)\/df.shape[0]\nnan_stats","27de8254":"df.drop(['sensor_15'], axis=1, inplace=True)","c5fc0336":"# plot in two windows with status - to asses nan's presence according to pump state.\n# divide sesnro values by its max to get better scaling to status (actual values are not of our interest here)\n\nfig, (ax1, ax2, ax3) = plt.subplots(3,1)\nax1.set_ylabel(nan_stats.index[1])\nax1.plot(df['timestamp'],df['machine_status'])\nax1.plot(df['timestamp'],df[nan_stats.index[1]]\/max(df[nan_stats.index[1]]))\nax2.set_ylabel(nan_stats.index[2])\nax2.plot(df['timestamp'],df['machine_status'])\nax2.plot(df['timestamp'],df[nan_stats.index[2]]\/max(df[nan_stats.index[2]]))\nax3.set_ylabel(nan_stats.index[3])\nax3.plot(df['timestamp'],df['machine_status'])\nax3.plot(df['timestamp'],df[nan_stats.index[3]]\/max(df[nan_stats.index[3]]))\nplt.show()\n\n\nfig, (ax1, ax2, ax3) = plt.subplots(3,1)\nax1.set_ylabel(nan_stats.index[4])\nax1.plot(df['timestamp'],df['machine_status'])\nax1.plot(df['timestamp'],df[nan_stats.index[4]]\/max(df[nan_stats.index[4]]))\nax2.set_ylabel(nan_stats.index[5])\nax2.plot(df['timestamp'],df['machine_status'])\nax2.plot(df['timestamp'],df[nan_stats.index[5]]\/max(df[nan_stats.index[5]]))\nax3.set_ylabel(nan_stats.index[6])\nax3.plot(df['timestamp'],df['machine_status'])\nax3.plot(df['timestamp'],df[nan_stats.index[6]]\/max(df[nan_stats.index[6]]))\nplt.show()\n","6a106fde":"df.drop(['sensor_50'], axis=1, inplace=True)","49649947":"# features extractor for columns\ndef get_column_features(df):\n    \n    df_features = pd.DataFrame()\n    col_list = ['Col','Max','Min','q_0.25','q_0.50','q_0.75']\n    \n    for column in df:\n        tmp_q = df[column].quantile([0.25,0.5,0.75])\n        tmp1 = pd.Series([column,max(df[column]),min(df[column]),tmp_q[0.25],tmp_q[0.5],tmp_q[0.75]],name='d')\n        tmp1.index = col_list\n        df_features = df_features.append(tmp1)\n        \n    return df_features\n\n# get list os signal columns without timestamp and status:\nsignal_columns = [c for c in df.columns if c not in ['timestamp', 'machine_status']]\nget_column_features(df[signal_columns])","fdc7328c":"corr = df[signal_columns].corr()\nsns.heatmap(corr)","a558fa7b":"#locate indices of failure events and recovering and normal state\nnormal_idx = df.loc[df['machine_status'] == 'NORMAL'].index\nfailure_idx = df.loc[df['machine_status'] == 'BROKEN'].index\nrecovering_idx = df.loc[df['machine_status'] == 'RECOVERING'].index\n\nbef_failure_idx = list()\nfor j in failure_idx:\n    for i in range(24*60):\n        bef_failure_idx.append(j-i)\n\nbef_failure_idx.sort()\n\n#locate timestamps of failures:\nfailures_timestamps = df.loc[failure_idx,'timestamp']\nprint(failures_timestamps)","2761143d":"for i in range(10):\n    fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5,1)\n    \n    ax1.set_ylabel(signal_columns[i*5])\n    ax1.plot(df[signal_columns[i*5]],linewidth=1)\n    ax1.plot(df.loc[list(recovering_idx),signal_columns[i*5]],linestyle='none',marker='.',color='red',markersize=4)\n    ax1.plot(df.loc[bef_failure_idx,signal_columns[i*5]],linestyle='none',marker='.',color='orange',markersize=4)\n        \n    ax2.set_ylabel(signal_columns[i*5+1])\n    ax2.plot(df[signal_columns[i*5+1]],linewidth=1)\n    ax2.plot(df.loc[list(recovering_idx),signal_columns[i*5+1]],linestyle='none',marker='.',color='red',markersize=4)\n    ax2.plot(df.loc[bef_failure_idx,signal_columns[i*5+1]],linestyle='none',marker='.',color='orange',markersize=4)\n    \n    ax3.set_ylabel(signal_columns[i*5+2])\n    ax3.plot(df[signal_columns[i*5+2]],linewidth=1)\n    ax3.plot(df.loc[list(recovering_idx),signal_columns[i*5+2]],linestyle='none',marker='.',color='red',markersize=4)\n    ax3.plot(df.loc[bef_failure_idx,signal_columns[i*5+2]],linestyle='none',marker='.',color='orange',markersize=4)\n    \n    ax4.set_ylabel(signal_columns[i*5+3])\n    ax4.plot(df[signal_columns[i*5+3]],linewidth=1)\n    ax4.plot(df.loc[list(recovering_idx),signal_columns[i*5+3]],linestyle='none',marker='.',color='red',markersize=4)\n    ax4.plot(df.loc[bef_failure_idx,signal_columns[i*5+3]],linestyle='none',marker='.',color='orange',markersize=4)\n    \n    ax5.set_ylabel(signal_columns[i*5+4])\n    ax5.plot(df[signal_columns[i*5+4]],linewidth=1)\n    ax5.plot(df.loc[list(recovering_idx),signal_columns[i*5+4]],linestyle='none',marker='.',color='red',markersize=4)\n    ax5.plot(df.loc[bef_failure_idx,signal_columns[i*5+4]],linestyle='none',marker='.',color='orange',markersize=4)\n    plt.show()\n\n","5e0c80d3":"**3. Correlation check**\n\nNow lets check if some of the sensors are correlated:","0e249929":"Now lets check NaNs:","595c314b":"We can see that first 6 failures happened during late evening\/night - only 7th was at 14pm.\nLets check the sensors behaviour before the failure and during the recovering state:","897d95dc":"Initially there was 52 sensors, we removed the 15th and 50th. Now we have 50 sensors and we don't know what kind of sensors they are (temperature, flow, pressure, vibration, pump motor current?). Lets investigate data ranges etc:","e4a8f9ad":"Sensor 15 has no data - we can drop the column:","6ab01780":"This phase is focused on simple analysis techniques - to get more info about the system.","ae9d04f7":"We can see strongly correlated group of sensors - from sensor_14 to sensor_26.\nThere also some other correlated groups but not as strong as the mentioned one.\n","94df17e8":"**1. Load and convert data types**\n\nFirst load the data and convert timesetamps","884e1b1b":"dt is equal - we can treat every column as evenly sampled series of data - wich simplifies analysis. We can drop Unnamed column with row numbers:\n","75dafb1e":"First findings:\n* sensor 37 has diminishing trend and its behaviour its a bit odd. Also has saturated readings on the botton of the scale\n\nto be continued - but before digging into real datascience and ML stuff some info about the system\/failure modes\/repair& maintenance policies\/constraints would be helpful","88a874e8":"**2. Preliminary investigation**\n\nCheck if the dt is equal","3d2da181":"By these features we can see, that:\n* all these sensors are analog sensors (no relays with only 0 and 1 values, binary switches etc). All of them have positive values.\n* we can also see that some of the sensors have max values expressed as whole numbers. For analog sensors - it can be symptom of reading truncated at scale end. We remember sensors 50 and 51 from nan's investigation - and by going by to plots we can see that nan's periods (failures of these sensors?) are preceded by achieving value of 1000 (saturated sensor\/electrical problems\/ loose cable connection?)\n\nWe will have all of that in mind during further investigation\n","d8b50d89":"We can see that:\n* sensor 50 fails after 6th failure of the pump and its reading are not available until the end of our dataframe. Maybe its not crucial for system operation and its repair is not economicaly justified.\n* Sensor 51 fails before 5th failure of the pump but during recovering from that failure gets back to normal operation\n* Sensors 00, 07, 08, 06 - have significant period of nan's during recovering state after 5th failure of the pump, but we may assume that their data coverage for failure prediction is OK\n\nFrom these plots we can also assume that 5th failure may correspond to different failure mode than the others - but we don't have any confirmation of that fact.\n\nLets remove also the sensor_50 - we don't have 1\/3 of the data and to reproduce the missing ones - we would have to estimate nearly 2 months of readings:","24afaacb":"We will also check the sensors that have more than 2% of nans - lets see it together with the machine status:","ec6444c9":"**4. Failure data investigation**\n\nLets locate the failure events:"}}