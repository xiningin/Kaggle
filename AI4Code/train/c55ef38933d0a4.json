{"cell_type":{"770aae45":"code","9af8b3f6":"code","68c29209":"code","8e2d051a":"code","01ba19a6":"code","988dbb8f":"code","6cc12ee8":"code","0fc87a66":"code","d6abacdc":"code","9f102f62":"code","53e30079":"code","8a64003b":"code","78b7d977":"code","de95f574":"code","9245a1d9":"markdown","644741d4":"markdown","f50a217e":"markdown","8e6414cf":"markdown"},"source":{"770aae45":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\nimport skimage\nfrom skimage.morphology import convex_hull_image, erosion\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D,\\\nZeroPadding2D, Convolution2D, ZeroPadding2D, Conv2DTranspose,ReLU, UpSampling2D, Concatenate, Conv2DTranspose\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\nfrom keras import backend\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","9af8b3f6":"MAIN_IMAGE_PATH = Path(\"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/train_val\/images\")\nMAIN_MASK_PATH = Path(\"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/train_val\/masks\")\n\nOBJECT_PATH = list(MAIN_IMAGE_PATH.glob(r\"*.jpg\"))\nMASK_PATH = list(MAIN_MASK_PATH.glob(r\"*.bmp\"))\n\nOBJECT_PATH = sorted(OBJECT_PATH)\nMASK_PATH = sorted(MASK_PATH)\n\nOBJECT_SERIES = pd.Series(OBJECT_PATH,name=\"OBJECTS\").astype(str)\nMASK_SERIES = pd.Series(MASK_PATH,name=\"MASK\").astype(str)\n\nMAIN_DATA = pd.concat([OBJECT_SERIES,MASK_SERIES],axis=1)\n\nMASK_MAIN_TRANSFORMATION = []\nOBJECT_MAIN_TRANSFORMATION = []\nADD_MAIN_TRANSFORMATION = []\n\nfor x_image,x_mask in zip(MAIN_DATA.OBJECTS,MAIN_DATA.MASK):\n    \n    IMAGE_X = cv2.cvtColor(cv2.imread(x_image),cv2.COLOR_BGR2RGB)\n    MASK_X = cv2.cvtColor(cv2.imread(x_mask),cv2.COLOR_BGR2RGB)\n    \n    RESIZED_X_IMAGE = cv2.resize(IMAGE_X,(300,300))\n    RESIZED_X_MASK = cv2.resize(MASK_X,(300,300))\n    \n    ADD_X = cv2.addWeighted(RESIZED_X_IMAGE,0.6,RESIZED_X_MASK,0.6,0.5)\n    \n    RESIZED_X_ADD = cv2.resize(ADD_X,(300,300))\n    \n    MASK_MAIN_TRANSFORMATION.append(RESIZED_X_MASK)\n    OBJECT_MAIN_TRANSFORMATION.append(RESIZED_X_IMAGE)\n    ADD_MAIN_TRANSFORMATION.append(RESIZED_X_ADD)\n    \nprint(\"WHEN IT IS ARRAY IMAGE SHAPE: \",np.shape(np.array(OBJECT_MAIN_TRANSFORMATION)))\nprint(\"WHEN IT IS ARRAY MASK SHAPE: \",np.shape(np.array(MASK_MAIN_TRANSFORMATION)))\nprint(\"WHEN IT IS ARRAY ADD SHAPE: \",np.shape(np.array(ADD_MAIN_TRANSFORMATION)))\n\nTransformation_Image = np.array(OBJECT_MAIN_TRANSFORMATION,dtype=\"float32\")\nTransformation_Mask = np.array(MASK_MAIN_TRANSFORMATION,dtype=\"float32\")\nTransformation_Add = np.array(ADD_MAIN_TRANSFORMATION,dtype=\"float32\")\n\nTransformation_Image = Transformation_Image \/ 255.\nTransformation_Mask = Transformation_Mask \/ 255.\nTransformation_Add = Transformation_Add \/ 255.\n\nprint(\"TRAIN: \",Transformation_Image.shape)\nprint(\"TRANSFORMATION MASK: \",Transformation_Mask.shape)\nprint(\"TRANSFORMATION ADD: \",Transformation_Add.shape)","68c29209":"compile_loss = \"binary_crossentropy\"\ncompile_optimizer = Adam(lr=0.000001)\noutput_class = 3\n\nCheckpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=True,\n                                                      filepath=\".\/modelcheck\")","8e2d051a":"Encoder_B = Sequential()\nEncoder_B.add(Conv2D(32,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_B.add(BatchNormalization())\nEncoder_B.add(ReLU())\n#\nEncoder_B.add(Conv2D(64,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_B.add(BatchNormalization())\nEncoder_B.add(ReLU())\n#\nEncoder_B.add(Conv2D(128,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_B.add(BatchNormalization())\nEncoder_B.add(ReLU())\n\n\nDecoder_B = Sequential()\n#\nDecoder_B.add(Conv2DTranspose(64,(2,2),padding = \"same\",use_bias = True))\nDecoder_B.add(BatchNormalization())\nDecoder_B.add(ReLU())\n#\nDecoder_B.add(Conv2DTranspose(32,(2,2),padding = \"same\",use_bias = True))\nDecoder_B.add(BatchNormalization())\nDecoder_B.add(ReLU())\n#\nDecoder_B.add(Conv2DTranspose(output_class,(2,2),padding = \"same\",use_bias = True))\nDecoder_B.add(BatchNormalization())\nDecoder_B.add(ReLU())","01ba19a6":"Auto_Encoder = Sequential([Encoder_B,Decoder_B])\nAuto_Encoder.compile(loss=compile_loss,optimizer=compile_optimizer,metrics=[\"mse\"])","988dbb8f":"Model_AutoEncoder = Auto_Encoder.fit(Transformation_Image,Transformation_Mask,epochs=50,callbacks=[Checkpoint_Model])","6cc12ee8":"Prediction_Seen = Auto_Encoder.predict(Transformation_Image[:10])","0fc87a66":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 1\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","d6abacdc":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 3\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","9f102f62":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 5\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","53e30079":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","8a64003b":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/d_r_129_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","78b7d977":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/d_r_384_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","de95f574":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/f_r_1220_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","9245a1d9":"### MODEL 4","644741d4":"# AUTO-ENCODER PROCESS \/ AE","f50a217e":"# PACKAGES AND LIBRARIES","8e6414cf":"# PATH \/ LABEL \/ DATA TRANSFORMATION PROCESS"}}