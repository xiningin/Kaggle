{"cell_type":{"cd8f6ebb":"code","15631da6":"code","4624cc3e":"code","ff34646b":"code","b34e5743":"code","78a63694":"code","895a9953":"code","be10245c":"code","91392646":"code","b714b8c0":"code","83339311":"code","af1d5d44":"code","61e69073":"code","4dbb818c":"code","2c876d71":"code","14052286":"markdown","a7f16ee9":"markdown","5b243b4d":"markdown","6d0fa4eb":"markdown","cfe98f7c":"markdown","a6ab0cfa":"markdown"},"source":{"cd8f6ebb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier","15631da6":"data = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')","4624cc3e":"data","ff34646b":"correlation_matrix = data.corr()","b34e5743":"plt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, vmin=-1.0, vmax=1.0, cmap='mako')\nplt.show()","78a63694":"age_ct = pd.crosstab(pd.qcut(data['Age'], q=4, labels=['Youngest', 'Younger', 'Older', 'Oldest']), data['Outcome'])\nage_ct_avgs = age_ct[1] \/ (age_ct[0] + age_ct[1])\n\nage_ct = pd.concat([age_ct, age_ct_avgs], axis=1)\nage_ct.columns = ['Negative', 'Positive', '% Positive']\n\nage_ct","895a9953":"scaler = StandardScaler()\nscaled_columns = data.iloc[:, :-1]\nscaled_columns = pd.DataFrame(scaler.fit_transform(scaled_columns), columns=scaled_columns.columns)\n\nplt.figure(figsize=(18, 10))\nfor column in scaled_columns.columns:\n    sns.kdeplot(scaled_columns[column], shade=True)\nplt.show()","be10245c":"y = data.loc[:, 'Outcome']\nX = data.drop('Outcome', axis=1)","91392646":"X = scaler.fit_transform(X)","b714b8c0":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=24)","83339311":"log_model = LogisticRegression()\nsvm_model = SVC(C=1.0)\nann_model = MLPClassifier(hidden_layer_sizes=(16, 16))","af1d5d44":"log_model.fit(X_train, y_train)\nsvm_model.fit(X_train, y_train)\nann_model.fit(X_train, y_train)","61e69073":"log_acc = log_model.score(X_test, y_test)\nsvm_acc = svm_model.score(X_test, y_test)\nann_acc = ann_model.score(X_test, y_test)","4dbb818c":"fig = px.bar(\n    x=['Logistic Regression', 'Support Vector Machine', 'Neural Network'],\n    y=[log_acc, svm_acc, ann_acc],\n    color=['Logistic Regression', 'Support Vector Machine', 'Neural Network']\n)\n\nfig.show()","2c876d71":"print(\"   Logistic Regression:\", log_acc)\nprint(\"Support Vector Machine:\", svm_acc)\nprint(\"        Neural Network:\", ann_acc)","14052286":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/YlEXc6Kwoqc","a7f16ee9":"# Getting Started","5b243b4d":"# EDA\/Data Visualization","6d0fa4eb":"# Training and Results","cfe98f7c":"# Task for Today  \n\n***\n\n## Diabetes Prediction  \n\nGiven *medical data about patients*, let's try to predict whether a given patient will have **diabetes** or not.  \n  \nWe will use logistic regression, support vector machine, and neural network models to make our predictions.","a6ab0cfa":"# Splitting and Scaling"}}