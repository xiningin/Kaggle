{"cell_type":{"2db967e9":"code","1b55e790":"code","cfd1bd1e":"code","6b812d2b":"code","e2628b12":"code","09509fee":"code","9cc81bd4":"code","529f0692":"code","7a029ade":"code","637a630e":"code","e08cff9e":"code","44f674c6":"code","d3c9d919":"code","1a8e94a8":"code","0b16be45":"code","57234cab":"code","407053e1":"code","14abf29d":"code","6f0c6b9b":"code","2b732d96":"code","1705572f":"code","91c7459e":"code","391fcf68":"code","a2cf643e":"code","e7d04726":"code","9dcf5ef0":"code","9ff3542f":"code","5f9dc911":"code","3e3e3f08":"code","131504e3":"code","0b8c1cf0":"code","74e63873":"markdown","4b1b9ed8":"markdown","9d7a50fc":"markdown","264f7403":"markdown"},"source":{"2db967e9":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np \nimport pandas as pd\nfrom pylab import rcParams","1b55e790":"df = pd.read_csv('..\/input\/students-performance-in-exams\/StudentsPerformance.csv')","cfd1bd1e":"df.head(10)","6b812d2b":"df.describe()","e2628b12":"df.info()","09509fee":"# to check presence of missing observations\ndf.isna().sum()","9cc81bd4":"# to print unique values in all columns\nunique_columns = [col+\" \"+df[col].unique() for col in df.select_dtypes(exclude=np.number)]\nunique_columns","529f0692":"#Creating a column Gender1 - where it assumes value 1 when gender = female\n\ngender1 = [1 if each == \"female\" else 0 for each in df.gender]\n\ndf['Gender1']=gender1\n\ndf.head(10)","7a029ade":"# correlation b\/w variables\n\ncorr = df.corr()\nprint(corr)\n\nsns.heatmap(corr, annot=True)\nplt.show()","637a630e":"# Plotting densities for female vs male basis score in various subjects\nf=df[['math score','reading score','writing score','Gender1']]\ndef plot_densities(data):\n    '''\n    Plot features densities depending on the outcome values\n    '''\n    # change fig size to fit all subplots\n    rcParams['figure.figsize'] = 20, 7\n    fig, axs = plt.subplots(3, 1)\n    plt.subplots_adjust(left = 0.25, right = 0.9, bottom = 0.1, top = 0.95,\n                        wspace = 0.2, hspace = 0.9)\n\n    # plot densities\n    for column_name in names[:-1]: \n        ax = axs[names.index(column_name)]\n        data[data['Gender1'] == 0][column_name].plot(kind='density', ax=ax, subplots=True, \n                                    sharex=False, color=\"red\", legend=True,\n                                    label=column_name + ' for Male')\n        data[data['Gender1'] == 1][column_name].plot(kind='density', ax=ax, subplots=True, \n                                     sharex=False, color=\"green\", legend=True,\n                                     label=column_name + ' for Female')\n        ax.set_xlabel(column_name + ' values')\n        ax.set_title(column_name + ' density')\n        ax.grid('on')\n    plt.show()\n\nnames = list(f.columns)\n\n# plot correlation & densities\nplot_densities(f)","e08cff9e":"# distribution of test preparation\ndf['average score']=df[['math score','reading score','writing score']].mean(axis=1)\nprint(df.std())\n\n\n\nsns.catplot(x=\"average score\", y=\"test preparation course\", hue=\"gender\",\n            kind=\"violin\", inner=\"stick\", split=True,\n            palette=\"pastel\", data=df)\n\nsns.catplot(x=\"average score\", y=\"parental level of education\", hue=\"gender\",\n            kind=\"violin\", inner=\"stick\", split=True,\n            palette=\"pastel\", data=df)\nsns.catplot(x=\"average score\", y=\"lunch\", hue=\"gender\",\n            kind=\"violin\", inner=\"stick\", split=True,\n            palette=\"pastel\", data=df)\nsns.catplot(x=\"average score\", y=\"race\/ethnicity\", hue=\"gender\",\n            kind=\"violin\", inner=\"stick\", split=True,\n            palette=\"pastel\", data=df)","44f674c6":"\nsns.pairplot(f,hue = 'Gender1')","d3c9d919":"#Creating Dummy Values\ndummy = pd.get_dummies(df[['race\/ethnicity','lunch','test preparation course']])\ndummy.head(10)","1a8e94a8":"# concatenate dummy df with original df\ndf1 = pd.concat([df, dummy], axis = 1)\ndf1.info()","0b16be45":"# average of values by gender\ndf_group = df1.groupby('gender').mean()\ndf_group","57234cab":"# drop columns for which dummies are created and y variables\nx = df1.drop(['race\/ethnicity', 'lunch', 'test preparation course', 'parental level of education','gender','average score','Gender1'], axis = 1)\n\n#standardize data\nx= (x-np.min(x)) \/ (np.max(x)-np.min(x))\n\nx.head()","407053e1":"y = df['Gender1']\ny.head()","14abf29d":"# split into train \/ test data\nfrom sklearn.model_selection import train_test_split\nx_train , x_test , y_train, y_test = train_test_split(x,y,test_size = 0.2 , random_state = 21)","6f0c6b9b":"from sklearn.tree import DecisionTreeClassifier","2b732d96":"classifier = DecisionTreeClassifier(criterion = 'gini', random_state= 0,max_depth=10 )\nclassifier.fit(x_train, y_train)\ny_pre = classifier.predict(x_test)\n","1705572f":"from sklearn.metrics import classification_report, confusion_matrix\ncm = confusion_matrix(y_test, y_pre)\nsum1 = np.sum(cm, axis=1, keepdims=True)\nperc1 = cm \/ sum1.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\n\nnrows, ncols = cm.shape\nfor i in range(nrows):\n            for j in range(ncols):\n                c = cm[i, j]\n                p = perc1[i, j]\n                if i == j:\n                    s = sum1[i]\n                    annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n                elif c == 0:\n                    annot[i, j] = ''\n                else:\n                    annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n\nsns.heatmap(cm, annot=annot, fmt='')\n","91c7459e":"print(classification_report(y_test,y_pre))","391fcf68":"from sklearn import tree\ntext_representation = tree.export_text(classifier)\nprint(text_representation)","a2cf643e":"with open(\"decistion_tree.log\", \"w\") as fout:\n    fout.write(text_representation)\nfig = plt.figure(figsize=(40,20))\n_ = tree.plot_tree(classifier, filled=True)","e7d04726":"from sklearn.neighbors import KNeighborsClassifier\n","9dcf5ef0":"error = []\nfor i in range(2,20):\n \n knn = KNeighborsClassifier(n_neighbors=i)\n knn.fit(x_train,y_train)\n pred = knn.predict(x_test)\n error.append(np.mean(pred != y_test))\nplt.figure(figsize=(10,6))\nplt.plot(range(2,20),error,color='blue', linestyle='dashed', marker='o',\n markerfacecolor='red', markersize=10)\nplt.title('Error vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error')\n\n#optimal neighbour count=7\nknn = KNeighborsClassifier(n_neighbors=7)\nknn.fit(x_train,y_train)\ny_pre = knn.predict(x_test)","9ff3542f":"cm = confusion_matrix(y_test, y_pre)\nsum1 = np.sum(cm, axis=1, keepdims=True)\nperc1 = cm \/ sum1.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\n\nnrows, ncols = cm.shape\nfor i in range(nrows):\n            for j in range(ncols):\n                c = cm[i, j]\n                p = perc1[i, j]\n                if i == j:\n                    s = sum1[i]\n                    annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n                elif c == 0:\n                    annot[i, j] = ''\n                else:\n                    annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n\nsns.heatmap(cm, annot=annot, fmt='')\n","5f9dc911":"print(classification_report(y_test,y_pre))","3e3e3f08":"error=[]\nfrom sklearn.ensemble import RandomForestClassifier\n\nfor i in range(1,100):\n rfc = RandomForestClassifier(n_estimators = i,random_state = 21,bootstrap = \"False\",criterion=\"gini\",min_samples_split = 10 , min_samples_leaf = 2)\n rfc.fit(x_train,y_train)\n pred = rfc.predict(x_test)\n error.append(np.mean(pred != y_test))\nplt.figure(figsize=(10,6))\nplt.plot(range(1,100),error,color='blue', linestyle='dashed', marker='o',\n markerfacecolor='red', markersize=10)\nplt.title('Error vs. No of Trees')\nplt.xlabel('No of Trees')\nplt.ylabel('Error')\n\nrfc = RandomForestClassifier(n_estimators = 50,random_state = 21,bootstrap = \"False\",criterion=\"gini\",min_samples_split = 10 , min_samples_leaf = 2)\nrfc.fit(x_train,y_train)\ny_pre = rfc.predict(x_test)","131504e3":"cm = confusion_matrix(y_test, y_pre)\nsum1 = np.sum(cm, axis=1, keepdims=True)\nperc1 = cm \/ sum1.astype(float) * 100\nannot = np.empty_like(cm).astype(str)\n\nnrows, ncols = cm.shape\nfor i in range(nrows):\n            for j in range(ncols):\n                c = cm[i, j]\n                p = perc1[i, j]\n                if i == j:\n                    s = sum1[i]\n                    annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n                elif c == 0:\n                    annot[i, j] = ''\n                else:\n                    annot[i, j] = '%.1f%%\\n%d' % (p, c)\n\n\n\nsns.heatmap(cm, annot=annot, fmt='')","0b8c1cf0":"print(classification_report(y_test,y_pre))","74e63873":"# KNN Classification","4b1b9ed8":"# Random Forest","9d7a50fc":"# Decision Tree","264f7403":"# Data Processing"}}