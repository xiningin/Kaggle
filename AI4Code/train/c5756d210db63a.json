{"cell_type":{"356e1738":"code","d6b4ebde":"code","2e905551":"code","f062b93a":"code","235df21d":"code","00a18aab":"code","49cbd030":"code","bc7f6c01":"markdown","c04ba2df":"markdown","40c7172c":"markdown"},"source":{"356e1738":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d6b4ebde":"# importing all the required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport skimage.io as io\nfrom skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms","2e905551":"def imshow(img, transform):\n    \"\"\"helper function to show data augmentation\n    :param img: path of the image\n    :param transform: data augmentation technique to apply\"\"\"\n    \n    img = PIL.Image.open(img)\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    ax[0].set_title(f'original image {img.size}')\n    ax[0].imshow(img)\n    img = transform(img)\n    ax[1].set_title(f'transformed image {img.size}')\n    ax[1].imshow(img)","f062b93a":"loader_transform = transforms.Resize((140, 140))\n\nimshow('..\/input\/mechanical-tools-dataset\/Mechanical Tools Image dataset\/Wrench\/000024.jpg', loader_transform)","235df21d":"loader_transform = transforms.CenterCrop(140)\nimshow('..\/input\/mechanical-tools-dataset\/Mechanical Tools Image dataset\/Wrench\/000024.jpg', loader_transform)","00a18aab":"from fastai.vision import *","49cbd030":"tfms = get_transforms(max_rotate=25)","bc7f6c01":"#How can I fix the `get_transforms` above?\n\nI would appreciate any help. It's a pity that I\u00b4ll not be able to use that script any longer. It was perfect: many images and few codes.  Maximum\/fast result with low effort.","c04ba2df":"#In fact, I would like to use the snippets below. \n\nSince my `get_transforms` aren't defined after using them over and over, I wish I could fix (or anybody give me a hint on how to make it). Maybe the Bionic Wrench could help me. ","40c7172c":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRj5UFfdAYn1ZORW1DbQrTpYiwa-qmYZz5BjA&usqp=CAU)pinterest.com"}}