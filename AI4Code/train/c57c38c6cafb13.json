{"cell_type":{"abeaa395":"code","6011daec":"code","84d02177":"code","28da1a25":"code","6ccaf97e":"code","1883673d":"code","48ca6312":"code","8e6f9be7":"code","8d0d8a2e":"code","3882a34c":"code","1dc91ba6":"code","84e1c4c9":"code","47d9a94d":"code","ed425b54":"code","22a7c906":"code","5731cd78":"code","066006e9":"code","15b8e2b9":"code","51658122":"code","17a4d2c3":"markdown","b2c831f4":"markdown","11a25cfc":"markdown"},"source":{"abeaa395":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom fastai.vision import *\nfrom fastai.metrics import accuracy\nfrom fastai.basic_data import *\nfrom skimage.util import montage\nimport pandas as pd\nfrom torch import optim\nimport re\n\nfrom utils import *","6011daec":"df = pd.read_csv('..\/input\/train.csv')\ndf.head()","84d02177":"im_count = df[df.Id != 'new_whale'].Id.value_counts()\nim_count.name = 'sighting_count'\ndf = df.join(im_count, on='Id')\nval_fns = set(df.sample(frac=1)[(df.Id != 'new_whale') & (df.sighting_count > 1)].groupby('Id').first().Image)","28da1a25":"# pd.to_pickle(val_fns, 'data\/val_fns')\n#val_fns = pd.read_pickle('data\/val_fns')","6ccaf97e":"fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}","1883673d":"SZ = 224\nBS = 64\nNUM_WORKERS = 0\nSEED=0","48ca6312":"path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)","8e6f9be7":"df = df[df.Id != 'new_whale']","8d0d8a2e":"df.shape","3882a34c":"df.sighting_count.max()","1dc91ba6":"df_val = df[df.Image.isin(val_fns)]\ndf_train = df[~df.Image.isin(val_fns)]\ndf_train_with_val = df","84e1c4c9":"df_val.shape, df_train.shape, df_train_with_val.shape","47d9a94d":"%%time\n\nres = None\nsample_to = 15\n\nfor grp in df_train.groupby('Id'):\n    n = grp[1].shape[0]\n    additional_rows = grp[1].sample(0 if sample_to < n  else sample_to - n, replace=True)\n    rows = pd.concat((grp[1], additional_rows))\n    \n    if res is None: res = rows\n    else: res = pd.concat((res, rows))","ed425b54":"%%time\n\nres_with_val = None\nsample_to = 15\n\nfor grp in df_train_with_val.groupby('Id'):\n    n = grp[1].shape[0]\n    additional_rows = grp[1].sample(0 if sample_to < n  else sample_to - n, replace=True)\n    rows = pd.concat((grp[1], additional_rows))\n    \n    if res_with_val is None: res_with_val = rows\n    else: res_with_val = pd.concat((res_with_val, rows))","22a7c906":"res.shape, res_with_val.shape","5731cd78":"pd.concat((res, df_val))[['Image', 'Id']].to_csv('oversampled_train.csv', index=False)\nres_with_val[['Image', 'Id']].to_csv('oversampled_train_and_val.csv', index=False)","066006e9":"df = pd.read_csv('oversampled_train.csv')","15b8e2b9":"data = (\n    ImageItemList\n        .from_df(df[df.Id != 'new_whale'], '..\/input\/train', cols=['Image'])\n        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n        .label_from_func(lambda path: fn2label[path2fn(path)])\n        .add_test(ImageItemList.from_folder('..\/input\/test'))\n        .transform(get_transforms(do_flip=False, max_zoom=1, max_warp=0, max_rotate=2), size=SZ, resize_method=ResizeMethod.SQUISH)\n        .databunch(bs=BS, num_workers=NUM_WORKERS, path='..\/input')\n        .normalize(imagenet_stats)\n)","51658122":"data","17a4d2c3":"## Prepare data","b2c831f4":"The naming here is not very fortunate, but the idea is that `oversampled_train` has single entries for images in `val_fns` and `oversampled_train_and_val` is both `val` and `train` combined. Meaning, `oversampled_train_and_val` is one we might want to use when retraining on the entire train set.","11a25cfc":"Our training set increased 6-fold, but that is still an amount of data that is okay. I don't think it makes sense to worry about breaking up the data into smaller epochs."}}