{"cell_type":{"74a43572":"code","fe66c77d":"code","1d261bf4":"code","4e277e2d":"code","a333fe35":"code","2f555880":"code","318f6c1a":"code","5c6999e8":"code","fe05e8e0":"code","465bcda0":"code","3c1db4f5":"code","41c27573":"code","7fb3b47c":"code","235a0b2f":"code","724b0745":"code","e59bf5b7":"code","b199847f":"code","4a952588":"code","6306dcaa":"code","250b1c9e":"code","bb63dadc":"code","bfdaa356":"code","345d6319":"code","d4a80d0d":"code","416c4d5a":"code","c03b3647":"code","a90e5354":"code","a3c0f3b3":"code","171cf7d9":"code","654ccf37":"code","b69c99c8":"code","40aa5a2a":"code","4ec11611":"code","c8c858f0":"code","df08489d":"code","43e376b8":"code","d737f397":"code","65b9000a":"code","4f95401a":"code","1f57723d":"code","5de24a63":"code","f4c69d77":"code","a3ef057e":"code","88cdc921":"code","17a161f8":"code","34938a92":"code","ef37fc86":"code","d91b0738":"code","ae677da1":"code","6b312cf5":"code","a9dee72c":"code","4f4f0169":"code","4bab9b3e":"code","bb0a4f67":"code","a9f811e5":"code","aa666611":"code","851fb753":"code","996842f9":"code","927e2cf8":"code","2e73f88c":"code","1f24d90b":"code","3d45ddf3":"code","2499da73":"code","b6ab3d3f":"code","364b3cae":"code","531279bb":"code","86d7343d":"code","2bd90157":"code","dc24bb16":"code","991c6464":"markdown","d89d601c":"markdown"},"source":{"74a43572":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","fe66c77d":"import tensorflow as tf\n# import tensorflow_hub as hub\nfrom datetime import datetime\nimport time\nimport pickle\nimport warnings\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nimport cv2\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics.classification import accuracy_score, log_loss\nfrom sklearn.linear_model import SGDClassifier\nfrom scipy.sparse import hstack\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\n# from sklearn.cross_validation import StratifiedKFold \nfrom collections import Counter, defaultdict\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport math\nfrom sklearn.metrics import normalized_mutual_info_score\nfrom sklearn.ensemble import RandomForestClassifier\nwarnings.filterwarnings(\"ignore\")\nfrom PIL import Image\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.regularizers import l1\nfrom tensorflow.keras import backend\nfrom keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense,GlobalAvgPool2D,Input,BatchNormalization,GlobalMaxPooling1D,GRU,LSTM,Activation,Bidirectional,TimeDistributed,Reshape\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Embedding,Dropout,SpatialDropout1D,Flatten,LeakyReLU,Conv2DTranspose\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.initializers import Constant\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam,SGD\nfrom keras import backend as K\n\nfrom tqdm import tqdm, trange","1d261bf4":"# read = lambda imname: np.asarray(Image.open(imname).convert(\"\"))\nread = lambda imname: mpimg.imread(imname)","4e277e2d":"folder_benign_train = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/train\/benign\/'\nfolder_malignant_train = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/train\/malignant'\n\nfolder_benign_test = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/test\/benign'\nfolder_malignant_test = '\/kaggle\/input\/skin-cancer-malignant-vs-benign\/test\/malignant'","a333fe35":"ims_benign = [read(os.path.join(folder_benign_train, filename)) for filename in os.listdir(folder_benign_train)]","2f555880":"X_benign = np.array(ims_benign, dtype='uint8')\nims_malignant = [read(os.path.join(folder_malignant_train, filename)) for filename in os.listdir(folder_malignant_train)]\nX_malignant = np.array(ims_malignant, dtype='uint8')","318f6c1a":"ims_benign = [read(os.path.join(folder_benign_test, filename)) for filename in os.listdir(folder_benign_test)]\nX_benign_test = np.array(ims_benign, dtype='uint8')\nims_malignant = [read(os.path.join(folder_malignant_test, filename)) for filename in os.listdir(folder_malignant_test)]\nX_malignant_test = np.array(ims_malignant, dtype='uint8')\n","5c6999e8":"y_benign = np.zeros(X_benign.shape[0])\ny_malignant = np.ones(X_malignant.shape[0])\n\ny_benign_test = np.zeros(X_benign_test.shape[0])\ny_malignant_test = np.ones(X_malignant_test.shape[0])\n\n\n# Merge data \nX_train = np.concatenate((X_benign, X_malignant), axis = 0)\ny_train = np.concatenate((y_benign, y_malignant), axis = 0)\n\nX_test = np.concatenate((X_benign_test, X_malignant_test), axis = 0)\ny_test = np.concatenate((y_benign_test, y_malignant_test), axis = 0)\n","fe05e8e0":"X_train,y_train = shuffle(X_train,y_train)","465bcda0":"X_test,y_test = shuffle(X_test,y_test)","3c1db4f5":"y_train","41c27573":"plt.imshow(X_train[y_train==0][np.random.randint(0,10),:,:])\nplt.figure(figsize=(5,50))","7fb3b47c":"cols = 5\nnum_classes = 2\nfig,axs = plt.subplots(nrows = num_classes,ncols = cols,figsize = (10,10))\nfor i in range(num_classes):\n    for j in range(cols):\n        if i == 0:\n            axs[i][j].set_title(\"benign\")\n        else:\n            axs[i][j].set_title(\"malignant\")\n        x_selected = X_train[y_train==i]\n        axs[i][j].imshow(x_selected[np.random.randint(0,10),:,:])\n        axs[i][j].axis(\"off\")","235a0b2f":"def grayScale(img):\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    return img","724b0745":"img = grayScale(X_train[10])\nplt.imshow(img)","e59bf5b7":"def equalizationOfImage(img):\n#this func will equalize image which means the brightness of image is flattened\n    return cv2.equalizeHist(img)","b199847f":"img = equalizationOfImage(img)\nplt.imshow(img)","4a952588":"def imgPreprocessing(img):\n    img = grayScale(img)\n    img = equalizationOfImage(img)\n    img = img\/255\n    return img","6306dcaa":"X_train1 = np.array(list(map(imgPreprocessing,X_train)))\nX_test1 = np.array(list(map(imgPreprocessing,X_test)))","250b1c9e":"plt.imshow(X_train[100])\nX_train1[100].shape","bb63dadc":"X_train2 = X_train1.reshape(X_train1.shape[0],X_train1.shape[1],X_train1.shape[2],1)\nX_test2 = X_test1.reshape(X_test1.shape[0],X_test1.shape[1],X_test1.shape[2],1)","bfdaa356":"X_train2,X_validation2,y_train2,y_validation2 = train_test_split(X_train2,y_train,test_size=0.2,random_state=42)","345d6319":"X_train2.shape","d4a80d0d":"def building_model():\n    model = Sequential()\n    model.add(Conv2D(32,(5, 5),input_shape=X_train2.shape[1:],activation=\"relu\",kernel_initializer = \"RandomNormal\",bias_initializer=\"zeros\"))\n    model.add(Conv2D(32,(5,5), activation = 'relu',kernel_initializer = \"RandomNormal\",bias_initializer=\"zeros\"))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(64,(5,5),activation=\"relu\",kernel_initializer = \"RandomNormal\",bias_initializer=\"zeros\"))\n    model.add(Conv2D(64,(5,5),activation=\"relu\",kernel_initializer = \"RandomNormal\",bias_initializer=\"zeros\"))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.2))\n    model.add(Conv2D(128,(3,3),activation=\"relu\",kernel_initializer = \"RandomNormal\",bias_initializer=\"zeros\"))\n    model.add(Conv2D(128,(3,3),activation=\"relu\",kernel_initializer = \"RandomNormal\",bias_initializer=\"zeros\"))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Flatten())\n    model.add(Dense(128,activation=\"relu\",kernel_initializer = \"RandomNormal\",bias_initializer=\"zeros\"))\n    model.add(Dropout(0.2))\n    model.add(Dense(1,activation=\"sigmoid\"))\n    model.compile(loss=\"binary_crossentropy\",optimizer=Adam(lr=0.001),metrics=[\"accuracy\"])\n    return model","416c4d5a":"model = building_model()","c03b3647":"filepath=\"\/kaggle\/input\/kaggle\/working\/model.h5\"\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\ncallbackList = [checkpoint]","a90e5354":"history = model.fit(X_train2,y_train2,validation_data=(X_validation2,y_validation2),batch_size=210,epochs = 50,callbacks=callbackList)","a3c0f3b3":"generator = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,rotation_range=30,horizontal_flip=True,vertical_flip=True)","171cf7d9":"generator.fit(X_train2)","654ccf37":"for X_batch, y_batch in generator.flow(X_train2, y_train2, batch_size=9):\n    print(y_batch[5])\n    for i in range(0, 9):\n        plt.subplot(330 + 1 + i)\n        plt.imshow(X_batch[i].reshape(224,224))\n    plt.show()\n    break","b69c99c8":"param = {\n    'theta':30,\n    'shear':30,\n    'flip_vertical':True,\n    'flip_horizontal':True\n}","40aa5a2a":"generated_img = np.array([generator.apply_transform(x,param) for x in X_train2])","4ec11611":"generated_img.shape","c8c858f0":"plt.imshow(X_train2[1].reshape(224,224))","df08489d":"plt.imshow(generated_img[1].reshape(224,224))","43e376b8":"X_train3 = np.concatenate([X_train2,generated_img])","d737f397":"X_train3.shape","65b9000a":"y_train3 = np.concatenate([y_train2,y_train2])\ny_train3.shape","4f95401a":"X_train3,y_train3 = shuffle(X_train3,y_train3)","1f57723d":"model = building_model()\nfilepath=\"\/kaggle\/output\/kaggle\/working\/model.h5\"\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\ncallbackList = [checkpoint]","5de24a63":"model.fit(X_train3,y_train3,\n          validation_data=(X_validation2,y_validation2),batch_size=210,epochs = 20,callbacks=callbackList,shuffle=True)","f4c69d77":"X_test3 = X_test1.reshape(X_test1.shape[0],X_test1.shape[1],X_test1.shape[2],1)\nX_test3.shape","a3ef057e":"y_test3 = y_test.reshape(y_test.shape[0],1)","88cdc921":"model.evaluate(X_test3,y_test3)","17a161f8":"X_validation1 = np.array([generator.apply_transform(x,param) for x in X_validation2])","34938a92":"X_validation1.shape","ef37fc86":"model_gen = building_model()","d91b0738":"filepath=\"model_gen.h5\"\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True, mode='max')\ncallbackList = [checkpoint]","ae677da1":"history = model_gen.fit_generator(generator.flow(X_train2,y_train2),validation_data=(X_validation1,y_validation2),\n                                  steps_per_epoch=X_train1.shape[0]\/50,epochs = 50,callbacks=callbackList)\n","6b312cf5":"def make_descriminator(inputShape=(224,224,1)):\n    model = Sequential()\n    model.add(Conv2D(32,(5, 5),padding=\"same\",input_shape=inputShape))\n    model.add(LeakyReLU(0.01))\n    model.add(Conv2D(64,(5,5)))\n    model.add(LeakyReLU(0.01))\n    model.add(MaxPooling2D((2,2)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(128,(3,3)))\n    model.add(LeakyReLU(0.01))\n    model.add(Conv2D(128,(3,3)))\n    model.add(LeakyReLU(0.01))\n#     model.add(GlobalAvgPool2D())\n    model.add(Flatten())\n    model.add(Dense(1))\n    model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n\n    return model","a9dee72c":"def make_generator():\n    model = Sequential()\n    model.add(Dense(128*28*28,input_shape=(100,)))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(0.1))\n    model.add(Reshape((28,28,128)))\n#     assert model.output_shape == (None, 28, 28, 128)\n    model.add(Conv2DTranspose(64,(4,4),padding=\"same\",strides=(2,2)))\n#     assert model.output_shape == (None, 56, 56, 64)\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(0.1))\n    model.add(Conv2DTranspose(32,(4,4),padding=\"same\",strides=(2,2)))\n#     assert model.output_shape == (None, 112, 112, 32)\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(0.1))\n    model.add(Conv2DTranspose(1,(4,4),activation=\"tanh\",strides=(2,2),padding=\"same\"))\n#     assert model.output_shape == (None, 223, 224, 1)\n    return model\n    \n              ","4f4f0169":"generator = make_generator()\nnoise = tf.random.normal([1,100])\ngenerated_img = generator(noise,training=False)\nplt.imshow(generated_img[0, :, :, 0], cmap='gray')","4bab9b3e":"discriminator = make_descriminator()\ndecision = discriminator(generated_img)\nprint(decision)","bb0a4f67":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","a9f811e5":"def discriminator_loss(real_output,y_real,fake_output,y_fake):\n    real_loss = cross_entropy(y_real,real_output)\n    fake_loss = cross_entropy(y_fake, fake_output)\n#     fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","aa666611":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output),fake_output)","851fb753":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\ncheckpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","996842f9":"noise_dim = 100\nnum_examples_to_generate = 8\n\n# We will reuse this seed overtime (so it's easier)\n# to visualize progress in the animated GIF)\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","927e2cf8":"def generate_fake_images(generator,noise,n_samples):\n    generated_images = generator(noise,training=True)\n    y = np.zeros((n_samples,1))\n    return generated_images,y","2e73f88c":"def generate_real_images(real_images,labels,n_samples):\n#     real_images,labels = dataset\n    ix = np.random.randint(0,real_images.shape[0],n_samples)\n    X,labels = real_images[ix],labels[ix]\n    \n    return X,labels","1f24d90b":"def generate_latent_points(latent_dim, n_samples):\n    z_input = np.random.randn(latent_dim * n_samples)\n    z_input = z_input.reshape(n_samples, latent_dim)\n    return z_input","3d45ddf3":"def train(X_train,y_train,noise_dim,epochs,n_batches = 100):\n    \n    batch_per_epochs = int(X_train.shape[0]\/n_batches)\n    n_steps = batch_per_epochs * epochs\n    half_batch = int(n_batches \/ 2)\n    \n    for i in range(n_steps):\n        noise = tf.random.normal([half_batch, noise_dim])\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n            X_real,y_real = generate_real_images(X_train,y_train,half_batch)\n    #         d_loss,d_acc = d_model.train_on_batch(X_real,y_real)\n            real_output = discriminator(X_real,training=True)\n            X_fake,y_fake = generate_fake_images(generator,noise,half_batch)\n            fake_output = discriminator(X_fake,training=True)\n            \n            d_loss = discriminator_loss(real_output,y_real,fake_output,y_fake)\n            g_loss = generator_loss(fake_output)\n            \n            gradient_of_gen = gen_tape.gradient(g_loss,generator.trainable_variables)\n            gradient_of_dis = disc_tape.gradient(d_loss,discriminator.trainable_variables)\n        generator_optimizer.apply_gradients(zip(gradient_of_gen,generator.trainable_variables))\n        discriminator_optimizer.apply_gradients(zip(gradient_of_dis,discriminator.trainable_variables))\n            \n\n#             X_gan,y_gan = generate_latent_points(100,n_batches),np.ones((n_batches,1))\n#             g_loss = gan_model.train_on_batch(X_gan,y_gan)\n\n        if (i+1) % (batch_per_epochs * 1) == 0:\n            print('>%d, c[%.3f], g[%.3f]' % (i+1, d_loss, g_loss))\n","2499da73":"y_train.shape","b6ab3d3f":"X_train4 = X_train1.reshape(X_train1.shape[0],X_train1.shape[1],X_train1.shape[2],1)\ny_train4 = y_train.reshape(y_train.shape[0],1)\nnoise_DIM = 100\nEPOCHS = 50","364b3cae":"train(X_train=X_train4,y_train=y_train4,noise_dim=noise_DIM,epochs=EPOCHS)","531279bb":"y_test4 = y_test.reshape(y_test.shape[0],1)\ny_test4.shape","86d7343d":"X_test4 = X_test1.reshape(X_test1.shape[0],X_test1.shape[1],X_test1.shape[2],1)","2bd90157":"X_test4.shape","dc24bb16":"discriminator.evaluate(X_test4,y_test4)","991c6464":"for generating train and test dataset, I reffered https:\/\/www.kaggle.com\/fanconic\/cnn-for-skin-cancer-detection","d89d601c":"GAN"}}