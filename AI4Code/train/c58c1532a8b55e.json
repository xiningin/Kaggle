{"cell_type":{"718498b8":"code","22aad7bb":"code","fac19dc9":"code","68df5a62":"code","07c8fcda":"code","35d74aa6":"code","52f03882":"code","02cf3024":"code","f6516a03":"code","115a4e49":"markdown","6facd501":"markdown","ab88c7b4":"markdown","7daf49f9":"markdown","2237bdbe":"markdown","50fecf7a":"markdown","d5747449":"markdown","1c778895":"markdown","ca4a1607":"markdown","14b62e00":"markdown","0aa4e364":"markdown","ae5caed0":"markdown"},"source":{"718498b8":"!pip install ..\/input\/detectron-05\/whls\/pycocotools-2.0.2\/dist\/pycocotools-2.0.2.tar --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/fvcore-0.1.5.post20211019\/fvcore-0.1.5.post20211019 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/antlr4-python3-runtime-4.8\/antlr4-python3-runtime-4.8 --no-index --find-links ..\/input\/detectron-05\/whls \n!pip install ..\/input\/detectron-05\/whls\/detectron2-0.5\/detectron2 --no-index --find-links ..\/input\/detectron-05\/whls ","22aad7bb":"import detectron2\nimport torch\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom PIL import Image\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom fastcore.all import *\ndetectron2.__version__","fac19dc9":"# From https:\/\/www.kaggle.com\/stainsby\/fast-tested-rle\ndef rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef get_masks(fn, predictor):\n    im = cv2.imread(str(fn))\n    pred = predictor(im)\n    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n    take = pred['instances'].scores >= THRESHOLDS[pred_class]\n    pred_masks = pred['instances'].pred_masks[take]\n    pred_masks = pred_masks.cpu().numpy()\n    res = []\n    used = np.zeros(im.shape[:2], dtype=int) \n    for mask in pred_masks:\n        mask = mask * (1-used)\n        if mask.sum() >= MIN_PIXELS[pred_class]: # skip predictions with small area\n            used += mask\n            res.append(rle_encode(mask))\n    return res","68df5a62":"Dir_testdata=Path('..\/input\/sartorius-cell-instance-segmentation')\nids, masks=[],[]\ntest_image_names = (Dir_testdata\/'test').ls()","07c8fcda":"cfg = get_cfg()\n#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\n#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")) #2--57\n#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_101_C4_3x.yaml\")) #3--58\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_101_FPN_3x.yaml\")) #4--59\n\n\ncfg.INPUT.MASK_FORMAT='bitmask'\ncfg.MODEL.WEIGHTS = \"..\/input\/sartorius-segmentation-la\/output\/model_best.pth\"\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.40\ncfg.TEST.DETECTIONS_PER_IMAGE = 1000\npredictor = DefaultPredictor(cfg)\nTHRESHOLDS = [.18, .38, .58]\nMIN_PIXELS = [75, 150, 75]","35d74aa6":"for fn in test_image_names:\n    encoded_masks = get_masks(fn, predictor)\n    for enc in encoded_masks:\n        ids.append(fn.stem)\n        masks.append(enc)","52f03882":"print(\"id\",\",\",\"predicted\")\nprint(ids[0],\",\",masks[0])","02cf3024":"encoded_masks = get_masks(test_image_names[0], predictor)\n_, axs = plt.subplots(1,2, figsize=(40,30))\naxs[1].imshow(cv2.imread(str(test_image_names[0])))\naxs[1].axis(\"off\")\nmask = np.zeros((520, 704, 1))\nfor enc in encoded_masks:\n    mask += rle_decode(enc, shape=(520, 704, 1))\n    \nmask = mask.clip(0, 1)\naxs[0].imshow(mask)\naxs[0].axis(\"off\")","f6516a03":"pd.DataFrame({'id':ids, 'predicted':masks}).to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()","115a4e49":"# References\n* https:\/\/www.kaggle.com\/slawekbiel\/positive-score-with-detectron-3-3-inference","6facd501":"# Functions","ab88c7b4":"# Detectron2 \nDetectron2 is Facebook AI Research's next generation software system that implements state-of-the-art object detection algorithms. It is a ground-up rewrite of the previous version, Detectron, and it originates from maskrcnn-benchmark\n\n","7daf49f9":"# Submission","2237bdbe":"# Visualize predictions","50fecf7a":"## Install Detectron2 offline","d5747449":"### Hi kagglers, This is `Training` notebook using `Detectron2`.\n[Sartorius Segmentation - Detectron2 [training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-detectron2-training) \n### Please if this kernel is useful, <font color='red'>please upvote !!<\/font>","1c778895":"## Other notebooks in this competition \n- [Sartorius Segmentation - Keras U-Net[Training]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-keras-u-net-training)\n- [Sartorius Segmentation - Keras U-Net[Inference]](https:\/\/www.kaggle.com\/ammarnassanalhajali\/sartorius-segmentation-keras-u-net-inference\/edit)","ca4a1607":"# importing libraries","14b62e00":"# Sartorius Segmentation - Detectron2 [Inference]","0aa4e364":"# Predicting","ae5caed0":"# Load Model"}}