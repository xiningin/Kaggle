{"cell_type":{"9713fbe3":"code","04b82231":"code","f35e73a3":"code","cd6f8ba2":"code","a8132b8a":"code","dedc2b18":"code","7ff87f02":"code","6b2199c2":"code","1770bfeb":"code","75e656a7":"code","3e566bec":"code","bc995b77":"code","9a34102e":"code","5fec2594":"code","47b2f360":"code","871f7394":"code","44bc72fc":"code","a8df42e4":"code","de542efb":"code","69be5348":"code","32f52f28":"code","9c398339":"code","c85f7ecd":"code","156c9cc2":"code","3b4806d2":"code","29b92bff":"code","88e45508":"code","a924708d":"markdown","1670bb5b":"markdown","85aa3ef9":"markdown","2ab3ca4a":"markdown","19d64637":"markdown","ed4e101f":"markdown","7e9f9473":"markdown","a7d03e7f":"markdown","6b0dd2c9":"markdown","662a1c0f":"markdown","fec2e82c":"markdown","8852224a":"markdown","ff3b1ec6":"markdown","b0812291":"markdown","5c65918a":"markdown"},"source":{"9713fbe3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","04b82231":"!pip install bs4","f35e73a3":"#First we get all the pictures from a web site\nfrom urllib.request import urlopen\nfrom bs4 import BeautifulSoup\nimport re\n\nhtml = urlopen(\"https:\/\/www.producebluebook.com\/2021\/02\/16\/the-fresh-market-automates-fresh-ordering\/#\")\nbs = BeautifulSoup(html, 'html.parser')\nimages = bs.find_all('img', {'src':re.compile('.jpg')})\nimage_list= list()\nfor image in images: \n    print(image['src']+'\\n')\n    image_list.append(image['src'])","cd6f8ba2":"#Then we will visualize the one I want to show\nurl = \"https:\/\/www.producebluebook.com\/wp-content\/uploads\/2021\/02\/the-fresh-market.jpg\"\nfrom PIL import Image\nimport requests\nimport matplotlib.pyplot as plt\n\nresponse = requests.get(url, stream=True)\nimg = Image.open(response.raw)\nplt.figure(figsize=(15,10))\nplt.imshow(img)\nplt.show()","a8132b8a":"plt.imshow(plt.imread(\"..\/input\/capture1\/Capture1.PNG\"))","dedc2b18":"plt.figure(figsize=(15,12))\nplt.imshow(plt.imread(\"..\/input\/capture-2\/Capture1.PNG\"))","7ff87f02":"df= pd.read_csv(\"..\/input\/market-basket-optimization\/Market_Basket_Optimisation.csv\",header=None)\n#By default, pd.read_csv function treats first row as header.\n#To get rid of this problem, add header=None option to pd.read_csv function, as shown above:\ndf.head()","6b2199c2":"popular=df[0].value_counts().head(70) #Here we list the most popular items\npopular","1770bfeb":"plt.figure(figsize=(18,8))\ncolor = plt.cm.copper(np.linspace(0, 1, 40))\ndf[0].value_counts().head(40).plot.bar(color = color)\nplt.title('frequency of most popular items', fontsize = 20)\nplt.xticks(rotation = 90 )\nplt.grid()\nplt.show()","75e656a7":"popular = pd.DataFrame(popular)\npopular","3e566bec":"popular.index","bc995b77":"import squarify\nplt.figure(figsize=(18,12))\ncolor = plt.cm.cool(np.linspace(0, 1, 50))\nsquarify.plot(sizes = popular.values,label = popular.index , alpha=.8, color = color)\nplt.title('Visualization of Popular Items')\nplt.axis('off')\nplt.show()\n#Here we visualize the most 70. popular items","9a34102e":"#First we transforn dataframe into a list of transactions\nproducts= list()\nfor i in range(0,7501):\n    products.append([str(df.values[i,j]) for j in range(20)])\n\n","5fec2594":"products[1] #This is our first transaction in python list","47b2f360":"!pip install apyori","871f7394":"from apyori import apriori","44bc72fc":"21\/7500","a8df42e4":"model= apriori(transactions=products, # This represents list of string of my products to work on\n              min_support= 0.003, # This represents minimum support of relations\n              min_confidence= 0.2, # This represents minimum confidence of relations\n              min_lift=3, # This represents minimum lift of relations\n              min_length = 2 , # This represents minimum length of the relation\n              max_length = 2 ) # This represents maximum length of the relation","de542efb":"results = list(model)\nresults","69be5348":"pd.DataFrame(results)","32f52f28":"bought_item = [tuple(result[2][0][0])[0] for result in results]\nwill_buy_item = [tuple(result[2][0][1])[0] for result in results]\nsupport_values = [result[1] for result in results]\nconfidences = [result[2][0][2] for result in results]\nlift_values = [result[2][0][3] for result in results]","9c398339":"new_data = list(zip(bought_item,will_buy_item,support_values,confidences,lift_values))\nnew_data","c85f7ecd":"new_df=pd.DataFrame(new_data,columns=[\"Boungt Item\", \"Expected To Be Bought\", \"Support\", \"Confidence\",\"Lift\"])\nnew_df","156c9cc2":"new_df.nlargest(n=10,columns=\"Lift\") # n parameter determines how many rows we want to get, \n                                    # columns parameter determines which will be based to organize data\n#we list the our data according to the LiftColumn","3b4806d2":"new_df.nlargest(n=10,columns=\"Confidence\") #Now we list the our data according to the Confidence Column\n# This means that if a customer buy a tomato sauce, the posibility ot buy ground beef is %37","29b92bff":"model2= apriori(transactions=products, # This represents list of string of my products to work on\n              min_support= 0.004, # This represents minimum support of relations\n              min_confidence= 0.5, # This represents minimum confidence of relations\n              min_lift=3, # This represents minimum lift of relations\n              min_length = 2 , # This represents minimum length of the relation\n              max_length = 3 ) # This represents maximum length of the relation","88e45508":"results2 = list(model2)\nresults2","a924708d":"<font color= \"blue\">\n2.Confidence: Confidence refers to the likelihood that an item B is also bought if item A is bought. It can be calculated by finding the number of transactions where A and B are bought together, divided by total number of transactions where A is bought\n    \nExample: In the picture above, there are 3 transactions which contain both apple and bear among all apple transactions. Therefore;\n    \n                Confidence= 3\/4= %75(The possibility of buying bear among apple buyers is %75)-(In apple-bear example in the figure above)","1670bb5b":"## 1. General Information About Association Rule Learning","85aa3ef9":"<font color=\"blue\">\nThe support value for the first rule is 0.004533. This number is calculated by dividing the number of transactions containing light cream divided by total number of all transactions. The confidence level for the rule is 0.290598 which shows that out of all the transactions that contain light cream, 29.0598% of the transactions also contain chicken. Finally, the lift of 4.84 tells us that chicken is 4.84 times more likely to be bought by the customers who buy light cream compared to the default likelihood of the sale of chicken.","2ab3ca4a":"## 4. Training the Apriori Model","19d64637":"<font color= \"blue\">\n1.Support: Support refers to the default popularity of an item and can be calculated by finding number of transactions containing a particular item divided by total number of transactions.The number of an Specific Item`s transactions among all of the transactions:\n    \nFor example: the support of {apple} is 4 out of 8. \n                \n                                                Support= 4\/8 = %50","ed4e101f":"<font color= \"blue\">\nThe apriori class requires some parameter values to work. The first parameter is the list of list that you want to extract rules from. The second parameter is the min_support parameter. This parameter is used to select the items with support values greater than the value specified by the parameter. Next, the min_confidence parameter filters those rules that have confidence greater than the confidence threshold specified by the parameter. Similarly, the min_lift parameter specifies the minimum lift value for the short listed rules. Finally, the min_length parameter specifies the minimum number of items that you want in your rules.","7e9f9473":"<font color=\"blue\">\nNow we will change some parameters","a7d03e7f":"<font color= \"blue\">\nThe table above reveals the users that make the market transactions that contain the products purchased. The aim is to put some potential rules from the dataset. Websites like Netflix, IMDB, and Youtube use some more complex type of Apriori model and make some recommendations like \u201cPeople watch this movie also watch these ones\u201d.","6b0dd2c9":"<font color= \"blue\">\nLet's suppose that we want rules for only those items that are purchased at least 3 times a day, or 7 x 3 = 21 times in one week, since our dataset is for a one-week time period. The support for those items can be calculated as 21\/7500 = 0.0028. We will rool to 0.003. The minimum confidence for the rules is 20% or 0.2. Similarly, we specify the value for lift as 3 and finally min_length is 2 since we want at least two products in our rules. We will also use max_length parameter because we want only to see birelations between items. Lets assume that the market will make a marketting campaign that will promote one item as a target and the other one as a free gift when the target item are bought. ","662a1c0f":"## 2. How Apriori Works","fec2e82c":"<font color= \"blue\">\n\n*Association rule learning is a rule-based machine learning method for discovering interesting relations between variables in large data\n    \n*For example, the rule {onions,potatoes} => {burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as, e.g., promotional pricing or product placements.","8852224a":"<font color= \"blue\">\nApriori Algorithm contains 5 steps:\n\n1) Transfrom Your Data into A List:\n    The algorithm in the apyori package is implemented in such a way that the input to the algorithm is a list of lists rather than a data frame. So we need to convert the data into a list of lists.\n    \n2) Set minimum support and confidence\n    \n3) Take all the subsets of the transactions that have higher support than minimum support.\n    \n4) Take all the rules of the subsets that have higher confidence than minimum confidence.\n    \n5) Sort the rules by decreasing lift","ff3b1ec6":"<font color= \"blue\">\n3.Lift: Lift(A -> B) refers to the increase in the ratio of sale of B when A is sold. Lift(A \u2013> B) can be calculated by dividing Confidence(A -> B) divided by Support(B).It is the division of Confidence by Support:\n    \n                            Lift = Confidence\/Support = %75\/%50= 0.75:0.5= 1.5 (In apple-bear example)\n\nLift basically tells us that the likelihood of buying a bear and apple together is 1.5 times more than the likelihood of just buying the apple. A Lift of 1 means there is no association between products A and B. Lift of greater than 1 means products A and B are more likely to be bought together. Finally, Lift of less than 1 refers to the case where two products are unlikely to be bought together.","b0812291":"<font color= \"blue\">\nThe Apriori library we use requires our dataset to be in the form of a list of lists, where the whole dataset is a big list and each transaction in the dataset is an inner list within the outer big list. ","5c65918a":"## 3. Data Analysis"}}