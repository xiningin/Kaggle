{"cell_type":{"0ab2c66b":"code","649e69b9":"code","ee77e4f8":"code","628a50fc":"code","397b7ada":"code","2d36caa8":"code","18d71860":"code","92879efa":"code","d61340dd":"markdown","58e1bd1f":"markdown","f5b923ec":"markdown","b331d360":"markdown","f75c51de":"markdown","cdfb1c29":"markdown","b24c25d1":"markdown","1310227f":"markdown","c12d5c49":"markdown","0d987cd1":"markdown","f8b83040":"markdown","87d334ef":"markdown","ac10c220":"markdown","259d385b":"markdown"},"source":{"0ab2c66b":"! pip install fastNLP","649e69b9":"import torch\nfrom fastNLP import Vocabulary\nfrom transformers import BertTokenizer, AdamW\nfrom collections import defaultdict\nfrom random import choice\nimport json\n\n\nclass Config:\n    \"\"\"\n    \u53e5\u5b50\u6700\u957f\u957f\u5ea6\u662f294 \u8fd9\u91cc\u5c31\u4e0d\u8bbe\u53c2\u6570\u9650\u5236\u957f\u5ea6\u4e86,\u6bcf\u4e2abatch \u81ea\u9002\u5e94\u957f\u5ea6\n    \"\"\"\n\n    def __init__(self):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.bert_path = '..\/input\/huggingface-bert\/bert-base-chinese'\n\n        self.num_rel = 18  # \u5173\u7cfb\u7684\u79cd\u7c7b\u6570\n\n        self.train_data_path = '..\/input\/baidurelationshipextraction\/train.json'\n        self.dev_data_path = '..\/input\/baidurelationshipextraction\/dev.json'\n        self.test_data_path = '..\/input\/baidurelationshipextraction\/test.json'\n\n        self.batch_size = 16\n\n        self.rel_dict_path = '..\/input\/baidurelationshipextraction\/rel.json'\n        id2rel = json.load(open(self.rel_dict_path, encoding='utf8'))\n        self.rel_vocab = Vocabulary(unknown=None, padding=None)\n        self.rel_vocab.add_word_lst(list(id2rel.values()))  # \u5173\u7cfb\u5230id\u7684\u6620\u5c04\n\n        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        self.learning_rate = 1e-5\n        self.bert_dim = 768\n        self.epochs = 10\n","ee77e4f8":"from torch.utils.data import Dataset, DataLoader\nimport json\n\n\ndef collate_fn(batch):\n    #  batch\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u5176\u4e2d\u662f\u4e00\u4e2a\u4e00\u4e2a\u7684\u5143\u7ec4\uff0c\u6bcf\u4e2a\u5143\u7ec4\u662fdataset\u4e2d_getitem__\u7684\u7ed3\u679c\n    batch = list(zip(*batch))\n    text = batch[0]\n    triple = batch[1]\n    del batch\n    return text, triple\n\n\nclass MyDataset(Dataset):\n    def __init__(self, path):\n        super().__init__()\n        self.dataset = []\n        with open(path, encoding='utf8') as F:\n            for line in F:\n                line = json.loads(line)\n                self.dataset.append(line)\n\n    def __getitem__(self, item):\n        content = self.dataset[item]\n        text = content['text']\n        spo_list = content['spo_list']\n        return text, spo_list\n\n    def __len__(self):\n        return len(self.dataset)\n\n\ndef create_data_iter(config):\n    train_data = MyDataset(config.train_data_path)\n    dev_data = MyDataset(config.dev_data_path)\n    test_data = MyDataset(config.test_data_path)\n\n    train_iter = DataLoader(train_data, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    dev_iter = DataLoader(dev_data, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    test_iter = DataLoader(test_data, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n\n    return train_iter, dev_iter, test_iter\n\n\nclass Batch:\n    def __init__(self, config):\n        self.tokenizer = config.tokenizer\n        self.num_relations = config.num_rel\n        self.rel_vocab = config.rel_vocab\n        self.device = config.device\n\n    def __call__(self, text, triple):\n        text = self.tokenizer(text, padding=True).data\n        batch_size = len(text['input_ids'])\n        seq_len = len(text['input_ids'][0])\n        sub_head = []\n        sub_tail = []\n        sub_heads = []\n        sub_tails = []\n        obj_heads = []\n        obj_tails = []\n        sub_len = []\n        sub_head2tail = []\n\n        for batch_index in range(batch_size):\n            inner_input_ids = text['input_ids'][batch_index]  # \u5355\u4e2a\u53e5\u5b50\u53d8\u6210\u7d22\u5f15\u540e\n            inner_triples = triple[batch_index]\n            inner_sub_heads, inner_sub_tails, inner_sub_head, inner_sub_tail, inner_sub_head2tail, inner_sub_len, inner_obj_heads, inner_obj_tails = \\\n                self.create_label(inner_triples, inner_input_ids, seq_len)\n            sub_head.append(inner_sub_head)\n            sub_tail.append(inner_sub_tail)\n            sub_len.append(inner_sub_len)\n            sub_head2tail.append(inner_sub_head2tail)\n            sub_heads.append(inner_sub_heads)\n            sub_tails.append(inner_sub_tails)\n            obj_heads.append(inner_obj_heads)\n            obj_tails.append(inner_obj_tails)\n\n        input_ids = torch.tensor(text['input_ids']).to(self.device)\n        mask = torch.tensor(text['attention_mask']).to(self.device)\n        sub_head = torch.stack(sub_head).to(self.device)\n        sub_tail = torch.stack(sub_tail).to(self.device)\n        sub_heads = torch.stack(sub_heads).to(self.device)\n        sub_tails = torch.stack(sub_tails).to(self.device)\n        sub_len = torch.stack(sub_len).to(self.device)\n        sub_head2tail = torch.stack(sub_head2tail).to(self.device)\n        obj_heads = torch.stack(obj_heads).to(self.device)\n        obj_tails = torch.stack(obj_tails).to(self.device)\n\n        return {\n                   'input_ids': input_ids,\n                   'mask': mask,\n                   'sub_head2tail': sub_head2tail,\n                   'sub_len': sub_len\n               }, {\n                   'sub_heads': sub_heads,\n                   'sub_tails': sub_tails,\n                   'obj_heads': obj_heads,\n                   'obj_tails': obj_tails\n               }\n\n    def create_label(self, inner_triples, inner_input_ids, seq_len):\n\n        inner_sub_heads, inner_sub_tails = torch.zeros(seq_len), torch.zeros(seq_len)\n        inner_sub_head, inner_sub_tail = torch.zeros(seq_len), torch.zeros(seq_len)\n        inner_obj_heads = torch.zeros((seq_len, self.num_relations))\n        inner_obj_tails = torch.zeros((seq_len, self.num_relations))\n        inner_sub_head2tail = torch.zeros(seq_len)  # \u968f\u673a\u62bd\u53d6\u4e00\u4e2a\u5b9e\u4f53\uff0c\u4ece\u5f00\u5934\u4e00\u4e2a\u8bcd\u5230\u672b\u5c3e\u8bcd\u7684\u7d22\u5f15\n\n        # \u56e0\u4e3a\u6570\u636e\u9884\u5904\u7406\u4ee3\u7801\u8fd8\u5f85\u4f18\u5316,\u4f1a\u6709\u4e0d\u5b58\u5728\u5173\u7cfb\u4e09\u5143\u7ec4\u7684\u60c5\u51b5\uff0c\n        # \u521d\u59cb\u5316\u4e00\u4e2a\u4e3b\u8bcd\u7684\u957f\u5ea6\u4e3a1\uff0c\u5373\u6ca1\u6709\u4e3b\u8bcd\u9ed8\u8ba4\u4e3b\u8bcd\u957f\u5ea6\u4e3a1\uff0c\n        # \u9632\u6b62\u96f6\u9664\u62a5\u9519,\u521d\u59cb\u5316\u4efb\u4f55\u975e\u96f6\u6570\u5b57\u90fd\u53ef\u4ee5\uff0c\u6ca1\u6709\u4e3b\u8bcd\u5206\u5b50\u662f\u5168\u96f6\u77e9\u9635\n        inner_sub_len = torch.tensor([1], dtype=torch.float)\n        # \u4e3b\u8bcd\u5230\u8c13\u8bcd\u7684\u6620\u5c04\n        s2ro_map = defaultdict(list)\n        for inner_triple in inner_triples:\n\n            inner_triple = (\n                self.tokenizer(inner_triple['subject'], add_special_tokens=False)['input_ids'],\n                self.rel_vocab.to_index(inner_triple['predicate']),\n                self.tokenizer(inner_triple['object'], add_special_tokens=False)['input_ids']\n            )\n\n            sub_head_idx = self.find_head_idx(inner_input_ids, inner_triple[0])\n            obj_head_idx = self.find_head_idx(inner_input_ids, inner_triple[2])\n\n            if sub_head_idx != -1 and obj_head_idx != -1:\n                sub = (sub_head_idx, sub_head_idx + len(inner_triple[0]) - 1)\n                # s2ro_map\u4fdd\u5b58\u4e3b\u8bed\u5230\u8c13\u8bed\u7684\u6620\u5c04\n                s2ro_map[sub].append(\n                    (obj_head_idx, obj_head_idx + len(inner_triple[2]) - 1, inner_triple[1]))  # {(3,5):[(7,8,0)]} 0\u662f\u5173\u7cfb\n\n        if s2ro_map:\n            for s in s2ro_map:\n                inner_sub_heads[s[0]] = 1\n                inner_sub_tails[s[1]] = 1\n\n            sub_head_idx, sub_tail_idx = choice(list(s2ro_map.keys()))\n            inner_sub_head[sub_head_idx] = 1\n            inner_sub_tail[sub_tail_idx] = 1\n            inner_sub_head2tail[sub_head_idx:sub_tail_idx + 1] = 1\n            inner_sub_len = torch.tensor([sub_tail_idx + 1 - sub_head_idx], dtype=torch.float)\n            for ro in s2ro_map.get((sub_head_idx, sub_tail_idx), []):\n                inner_obj_heads[ro[0]][ro[2]] = 1\n                inner_obj_tails[ro[1]][ro[2]] = 1\n\n        return inner_sub_heads, inner_sub_tails, inner_sub_head, inner_sub_tail, inner_sub_head2tail, inner_sub_len, inner_obj_heads, inner_obj_tails\n\n    @staticmethod\n    def find_head_idx(source, target):\n        target_len = len(target)\n        for i in range(len(source)):\n            if source[i: i + target_len] == target:\n                return i\n        return -1\n\n","628a50fc":"import torch.nn as nn\nimport torch\nfrom transformers import BertModel\n\n\nclass CasRel(nn.Module):\n    def __init__(self, config):\n        super(CasRel, self).__init__()\n        self.config = config\n        self.bert = BertModel.from_pretrained(self.config.bert_path)\n        self.sub_heads_linear = nn.Linear(self.config.bert_dim, 1)\n        self.sub_tails_linear = nn.Linear(self.config.bert_dim, 1)\n        self.obj_heads_linear = nn.Linear(self.config.bert_dim, self.config.num_rel)\n        self.obj_tails_linear = nn.Linear(self.config.bert_dim, self.config.num_rel)\n        self.alpha = 0.25\n        self.gamma = 2\n\n    def get_encoded_text(self, token_ids, mask):\n        encoded_text = self.bert(token_ids, attention_mask=mask)[0]\n        return encoded_text\n\n    def get_subs(self, encoded_text):\n        pred_sub_heads = torch.sigmoid(self.sub_heads_linear(encoded_text))\n        pred_sub_tails = torch.sigmoid(self.sub_tails_linear(encoded_text))\n        return pred_sub_heads, pred_sub_tails\n\n    def get_objs_for_specific_sub(self, sub_head2tail, sub_len, encoded_text):\n        # sub_head_mapping [batch, 1, seq] * encoded_text [batch, seq, dim]\n        sub = torch.matmul(sub_head2tail, encoded_text)  # batch size,1,dim\n        sub_len = sub_len.unsqueeze(1)\n        sub = sub \/ sub_len  # batch size, 1,dim\n        encoded_text = encoded_text + sub\n        #  [batch size, seq len,bert_dim] -->[batch size, seq len,relathion counts]\n        pred_obj_heads = torch.sigmoid(self.obj_heads_linear(encoded_text))\n        pred_obj_tails = torch.sigmoid(self.obj_tails_linear(encoded_text))\n        return pred_obj_heads, pred_obj_tails\n\n    def forward(self, input_ids, mask, sub_head2tail, sub_len):\n        \"\"\"\n\n        :param token_ids:[batch size, seq len]\n        :param mask:[batch size, seq len]\n        :param sub_head:[batch size, seq len]\n        :param sub_tail:[batch size, seq len]\n        :return:\n        \"\"\"\n        encoded_text = self.get_encoded_text(input_ids, mask)\n        pred_sub_heads, pred_sub_tails = self.get_subs(encoded_text)\n        sub_head2tail = sub_head2tail.unsqueeze(1)  # [[batch size,1, seq len]]\n        pred_obj_heads, pre_obj_tails = self.get_objs_for_specific_sub(sub_head2tail, sub_len, encoded_text)\n\n        return {\n            \"pred_sub_heads\": pred_sub_heads,\n            \"pred_sub_tails\": pred_sub_tails,\n            \"pred_obj_heads\": pred_obj_heads,\n            \"pred_obj_tails\": pre_obj_tails,\n            'mask': mask\n        }\n\n    def compute_loss(self, pred_sub_heads, pred_sub_tails, pred_obj_heads, pred_obj_tails, mask, sub_heads,\n                     sub_tails, obj_heads, obj_tails):\n        rel_count = obj_heads.shape[-1]\n        rel_mask = mask.unsqueeze(-1).repeat(1, 1, rel_count)\n        loss_1 = self.loss_fun(pred_sub_heads, sub_heads, mask)\n        loss_2 = self.loss_fun(pred_sub_tails, sub_tails, mask)\n        loss_3 = self.loss_fun(pred_obj_heads, obj_heads, rel_mask)\n        loss_4 = self.loss_fun(pred_obj_tails, obj_tails, rel_mask)\n        return loss_1 + loss_2 + loss_3 + loss_4\n\n    def loss_fun(self, logist, label, mask):\n        count = torch.sum(mask)\n        logist = logist.view(-1)\n        label = label.view(-1)\n        mask = mask.view(-1)\n        \n        alpha_factor = torch.where(torch.eq(label,1), 1- self.alpha,self.alpha)\n        focal_weight = torch.where(torch.eq(label,1),1-logist,logist)\n        \n        loss = -(torch.log(logist) * label + torch.log(1 - logist) * (1 - label)) * mask\n        return torch.sum(focal_weight * loss) \/ count\n\n","397b7ada":"def load_model(config):\n    device = config.device\n    model = CasRel(config)\n    model.to(device)\n\n    # prepare optimzier\n    param_optimizer = list(model.named_parameters())\n\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_grouped_parameters = [\n        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}]\n\n    optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate, eps=10e-8)\n    sheduler = None\n\n    return model, optimizer, sheduler, device\n","2d36caa8":"import pandas as pd\nfrom tqdm import tqdm\n\ndef train_epoch(model, train_iter, dev_iter, optimizer, batch, best_triple_f1, epoch):\n    for step, (text, triple) in enumerate(train_iter):\n        model.train()\n        inputs, labels = batch(text, triple)\n        logist = model(**inputs)\n        loss = model.compute_loss(**logist, **labels)\n        model.zero_grad()\n        loss.backward()\n        optimizer.step()\n        if step % 500 == 1:\n            sub_precision, sub_recall, sub_f1, triple_precision, triple_recall, triple_f1, df = test(model, dev_iter,\n                                                                                                     batch)\n            if triple_f1 > best_triple_f1:\n                best_triple_f1 = triple_f1\n                torch.save(model.state_dict(), 'best_f1.pth')\n                print(\n                    'epoch:{},step:{},sub_precision:{:.4f}, sub_recall:{:.4f}, sub_f1:{:.4f}, triple_precision:{:.4f}, triple_recall:{:.4f}, triple_f1:{:.4f},train loss:{:.4f}'.format(\n                        epoch, step, sub_precision, sub_recall, sub_f1, triple_precision, triple_recall, triple_f1,\n                        loss.item()))\n                print(df)\n\n    return best_triple_f1\n\n\ndef train(model, train_iter, dev_iter, optimizer, config):\n    epochs = config.epochs\n    best_triple_f1 = 0\n    for epoch in range(epochs):\n        best_triple_f1 = train_epoch(model, train_iter, dev_iter, optimizer, batch, best_triple_f1, epoch)\n\n\ndef test(model, dev_iter, batch):\n    model.eval()\n    df = pd.DataFrame(columns=['TP', 'PRED', \"REAL\", 'p', 'r', 'f1'], index=['sub', 'triple'])\n    df.fillna(0, inplace=True)\n\n    for text, triple in tqdm(dev_iter):\n        inputs, labels = batch(text, triple)\n        logist = model(**inputs)\n        \n        pred_sub_heads = convert_score_to_zero_one(logist['pred_sub_heads'])\n        pred_sub_tails = convert_score_to_zero_one(logist['pred_sub_tails'])\n\n        sub_heads = convert_score_to_zero_one(labels['sub_heads'])\n        sub_tails = convert_score_to_zero_one(labels['sub_tails'])\n        batch_size = inputs['input_ids'].shape[0]\n\n        obj_heads = convert_score_to_zero_one(labels['obj_heads'])\n        obj_tails = convert_score_to_zero_one(labels['obj_tails'])\n        pred_obj_heads = convert_score_to_zero_one(logist['pred_obj_heads'])\n        pred_obj_tails = convert_score_to_zero_one(logist['pred_obj_tails'])\n\n        for batch_index in range(batch_size):\n            pred_subs = extract_sub(pred_sub_heads[batch_index].squeeze(), pred_sub_tails[batch_index].squeeze())\n            true_subs = extract_sub(sub_heads[batch_index].squeeze(), sub_tails[batch_index].squeeze())\n\n            pred_ojbs = extract_obj_and_rel(pred_obj_heads[batch_index], pred_obj_tails[batch_index])\n            true_objs = extract_obj_and_rel(obj_heads[batch_index], obj_tails[batch_index])\n\n            df['PRED']['sub'] += len(pred_subs)\n            df['REAL']['sub'] += len(true_subs)\n            for true_sub in true_subs:\n                if true_sub in pred_subs:\n                    df['TP']['sub'] += 1\n\n            df['PRED']['triple'] += len(pred_ojbs)\n            df['REAL']['triple'] += len(true_objs)\n            for true_obj in true_objs:\n                if true_obj in pred_ojbs:\n                    df['TP']['triple'] += 1\n\n    df.loc['sub','p'] = df['TP']['sub'] \/ (df['PRED']['sub'] + 1e-9)\n    df.loc['sub','r'] = df['TP']['sub'] \/ (df['REAL']['sub'] + 1e-9)\n    df.loc['sub','f1'] = 2 * df['p']['sub'] * df['r']['sub'] \/ (df['p']['sub'] + df['r']['sub'] + 1e-9)\n    \n    sub_precision = df['TP']['sub'] \/ (df['PRED']['sub'] + 1e-9)\n    sub_recall = df['TP']['sub'] \/ (df['REAL']['sub'] + 1e-9)\n    sub_f1 = 2 * sub_precision * sub_recall  \/ (sub_precision + sub_recall  + 1e-9)\n\n    df.loc['triple','p'] = df['TP']['triple'] \/ (df['PRED']['triple'] + 1e-9)\n    df.loc['triple','r'] = df['TP']['triple'] \/ (df['REAL']['triple'] + 1e-9)\n    df.loc['triple','f1'] = 2 * df['p']['triple'] * df['r']['triple'] \/ (\n            df['p']['triple'] + df['r']['triple'] + 1e-9)\n    \n    \n    triple_precision = df['TP']['triple'] \/ (df['PRED']['triple'] + 1e-9)\n    triple_recall = df['TP']['triple'] \/ (df['REAL']['triple'] + 1e-9)\n    triple_f1 = 2 * triple_precision * triple_recall \/ (\n            triple_precision + triple_recall + 1e-9)\n\n    return sub_precision, sub_recall,sub_f1, triple_precision, triple_recall, triple_f1, df\n\n\ndef extract_sub(pred_sub_heads, pred_sub_tails):\n    subs = []\n    heads = torch.arange(0, len(pred_sub_heads))[pred_sub_heads == 1]\n    tails = torch.arange(0, len(pred_sub_tails))[pred_sub_tails == 1]\n\n    for head, tail in zip(heads, tails):\n        if tail >= head:\n            subs.append((head.item(), tail.item()))\n    return subs\n\n\ndef extract_obj_and_rel(obj_heads, obj_tails):\n    obj_heads = obj_heads.T\n    obj_tails = obj_tails.T\n    rel_count = obj_heads.shape[0]\n    obj_and_rels = []  # [(rel_index,strart_index,end_index),(rel_index,strart_index,end_index)]\n\n    for rel_index in range(rel_count):\n        obj_head = obj_heads[rel_index]\n        obj_tail = obj_tails[rel_index]\n\n        objs = extract_sub(obj_head, obj_tail)\n        if objs:\n            for obj in objs:\n                start_index, end_index = obj\n                obj_and_rels.append((rel_index, start_index, end_index))\n    return obj_and_rels\n\n\ndef convert_score_to_zero_one(tensor):\n    tensor[tensor>=0.5] = 1\n    tensor[tensor<0.5] = 0\n    return tensor","18d71860":"if __name__ == '__main__':\n    config = Config()\n    train_data = MyDataset(config.train_data_path)\n\n    model, optimizer, sheduler, device = load_model(config)\n    train_iter, dev_iter, test_iter = create_data_iter(config)\n    batch = Batch(config)\n    train(model, train_iter, dev_iter, optimizer, config)\n","92879efa":"# len(train_iter)  3498","d61340dd":"![image.png](attachment:e590d570-8ac3-465f-aa6b-f7aa4538ea54.png)","58e1bd1f":"Jackie R Brown was born in washington, the capital city if united states of Amarica .<\/br>\n\u4e00\u5171\u8ba1\u7b97\u56db\u4e2a\u635f\u5931<\/br>\n\u524d\u4e24\u4e2a\u7b80\u5355\u7684\u635f\u5931\uff1a<\/br>\n- label \u7684\u6784\u5efa\uff1a\n![image.png](attachment:3446574e-70d0-4f3e-866f-13847f5b455e.png)\n- predct \u8ba1\u7b97:<\/br>\n\u6574\u4e2a\u53e5\u5b50\u7ecf\u8fc7bert\u7f16\u7801\u540e\u53d8\u4e3a`[seq len, bert dim]` \u7ecf\u8fc7\u4e24\u4e2a\u7ebf\u6027\u5c42\u7136\u540esigmoid\u540e\u53d8\u4e3a \u4e24\u4e2a`[seq len, 1]` \u8fd9\u4e24\u4e2apredict \u8ddflabel\u8d8a\u63a5\u8fd1\u8d8a\u597d <\/br>\n\n\u540e\u4e24\u4e2a\u635f\u5931\n\u5047\u5982\u73b0\u5728\u5173\u7cfb\u53ea\u6709\u4e09\u79cd:\u51fa\u751f\u5730\uff0c\u5de5\u4f5c\u5730\uff0c\u9996\u90fd <\/br>\n\u73b0\u5728\u6211\u8981\u5bfb\u627eJackie R Brown\u7684\u6240\u6709\u5173\u7cfb<\/br>\n\u53ef\u4ee5\u53d6\u51faJackie\u548c Brown\u7684\u7f16\u7801\u53d6\u5e73\u5747`[1,bert_dim]`\u7136\u540e\u8ddf\u6574\u4e2a\u53e5\u5b50\u76f8\u52a0`[seq len,bert_dim]` <\/br>\n\u7136\u540e\u7ecf\u8fc7\u4e00\u4e2a\u7ebf\u6027\u5c42\u540e\u71c3sigmiod \u53d8\u4e3a`[seq len,3*2]`<\/br>\n![image.png](attachment:5f9ea6a3-1df5-468c-a15b-7a53b413429d.png)","f5b923ec":"# \u8bba\u6587\u7b80\u4ecb\n","b331d360":"# \u6570\u636e\u9884\u5904\u7406","f75c51de":"[\u8bba\u6587\u94fe\u63a5](https:\/\/arxiv.org\/pdf\/1909.03227.pdf)\n[\u4ee3\u7801\u94fe\u63a5](https:\/\/github.com\/weizhepei\/CasRel)\n[\u672c\u7bc7\u53c2\u8003\u94fe\u63a5](https:\/\/github.com\/Onion12138\/CasRelPyTorch)","cdfb1c29":"## \u7f3a\u9677  \n\u4e0d\u80fd\u641e\u5b9a\u5d4c\u5957\u547d\u540d\u5b9e\u4f53\u8bc6\u522b","b24c25d1":"### \u8fd9\u4e2a\u6a21\u578b\u8981\u89e3\u51b3\u7684\u95ee\u9898\uff1a\n![image.png](attachment:e45b183b-50de-4ca3-bd65-b6e7025817da.png)","1310227f":"```json\n{\"text\": \"\u7b14       \u540d\uff1a\u6728\u65a7\u539f       \u540d\uff1a\u6768\u8386\u66fe  \u7528  \u540d\uff1a\u7a46\u65b0\u6587\u3001\u7267\u7f8a\u3001\u5bd2\u767d\u3001\u6d0b\u6f3e\u51fa\u751f\u65e5\u671f\uff1a1931\u2014\u804c       \u4e1a\uff1a\u4f5c\u5bb6\u3001\u8bd7\u4eba\u6027    \u522b\uff1a \u7537\u6c11    \u65cf\uff1a \u56de\u65cf\u653f\u6cbb\u9762\u8c8c\uff1a\u4e2d\u5171\u515a\u5458 \u7956       \u7c4d\uff1a\u56fa\u539f\u53bf\u51fa  \u751f  \u5730\uff1a\u6210\u90fd\", \"spo_list\": [{\"predicate\": \"\u6c11\u65cf\", \"object_type\": \"\u6587\u672c\", \"subject_type\": \"\u4eba\u7269\", \"object\": \"\u56de\u65cf\", \"subject\": \"\u6728\u65a7\"}, {\"predicate\": \"\u51fa\u751f\u65e5\u671f\", \"object_type\": \"\u65e5\u671f\", \"subject_type\": \"\u4eba\u7269\", \"object\": \"1931\", \"subject\": \"\u6728\u65a7\"}, {\"predicate\": \"\u51fa\u751f\u5730\", \"object_type\": \"\u5730\u70b9\", \"subject_type\": \"\u4eba\u7269\", \"object\": \"\u6210\u90fd\", \"subject\": \"\u6728\u65a7\"}]}\n```","c12d5c49":"# train","0d987cd1":"# \u6570\u636e\u96c6\u683c\u5f0f","f8b83040":"# main","87d334ef":"# model","ac10c220":"\u4ee5\u5f80\u7684\u6a21\u578b\u662f\u7b2c\u4e00\u79cd\u3002\n\u4f46\u662f\u4e00\u4e2a\u4eba\u65e2\u662f\u4e00\u4e2a\u7535\u5f71\u7684\u5bfc\u6f14\u4f18\u52bf\u4e00\u4e2a\u7535\u5f71\u7684\u6f14\u5458,\u5c31\u4e0d\u592a\u597d\u5904\u7406\u3002\n\u4e00\u4e2a\u4eba\u540c\u65f6\u51fa\u751f\u4e8e\u4e2d\u56fd\u548c\u5317\u4eac\u4e5f\u4e0d\u597d\u5904\u7406","259d385b":"### \u6a21\u578b\u67b6\u6784"}}