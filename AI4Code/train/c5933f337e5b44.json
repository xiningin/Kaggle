{"cell_type":{"440169f0":"code","705b14d8":"code","6b1f04d0":"code","41ffb210":"code","a0ca8996":"code","82a11b5b":"code","b765f562":"code","95d48b08":"code","a3fb08e1":"markdown","4b34356b":"markdown","d0f2f790":"markdown","20a65a2f":"markdown","651f99b2":"markdown","2c0b1af5":"markdown","865bf408":"markdown","47df351a":"markdown","4280a6c2":"markdown","d0c994d3":"markdown","ac3145ad":"markdown","f9a3a39e":"markdown"},"source":{"440169f0":"!pip install -q quick-ml","705b14d8":"import tensorflow as tf\nimport quick_ml","6b1f04d0":"from quick_ml.tfrecords_maker import create_split_tfrecords_data","41ffb210":"outfile1name = 'training.tfrecords'\noutfile2name = 'validation.tfrecords'\noutput1folder = 'train'\noutput2folder = 'val'\nDATA_DIR = '\/kaggle\/input\/iucn-animals-dataset\/data'\n\nsplit_size_ratio = 0.8\n\n\ncreate_split_tfrecords_data(DATA_DIR, outfile1name, output1folder, outfile2name, output2folder, split_size_ratio,num_parts1 = 1, num_parts2 = 1, IMAGE_SIZE = (192,192))","a0ca8996":"dictionary_labeled = \"{'image' : tf.io.FixedLenFeature([], tf.string), 'label' : tf.io.FixedLenFeature([], tf.int64)}\"\nIMAGE_SIZE = \"192,192\"\n\n\nfrom quick_ml.begin_tpu import get_labeled_tfrecord_format\nget_labeled_tfrecord_format(dictionary_labeled, IMAGE_SIZE)","82a11b5b":"from quick_ml.visualize_and_check_data import check_one_image_and_label, check_batch_and_labels, check_one_image_and_id, check_batch_and_ids","b765f562":"tfrecord_filename = '\/kaggle\/working\/train\/training.tfrecords'\n\nn_examples = 9\ngrid_rows = 3\ngrid_columns = 3\n\ncheck_batch_and_labels(tfrecord_filename, n_examples, grid_rows, grid_columns, grid_size = (10,10))","95d48b08":"tfrecord_filename = '\/kaggle\/working\/val\/validation.tfrecords'\n\nn_examples = 9\ngrid_rows = 3\ngrid_columns = 3\n\ncheck_batch_and_labels(tfrecord_filename, n_examples, grid_rows, grid_columns, grid_size = (10,10))","a3fb08e1":"## Summary -> <br>\nIn this notebook, we'll learn how to generate TFRecords Dataset for classification. This notebook will be on the similar lines of a previous similar work which can be found [here](https:\/\/www.kaggle.com\/antoreepjana\/quick-ml-tfrecords-maker). ","4b34356b":"Define the necessary parameters\n<br><br>\n* outfile1name - name of the 1st part of the split generated\n* outfile2name - name of the 2nd part of the split generated\n* output1folder - where to store the output for part1 (subdirectory in the output)\n* output2folder - where to store the output for part2 (subdirectory in the output)\n* DATA_DIR - original source of the dataset from which TFRecords Dataset are to be generated\n* split_size_ratio - Ratio in which the dataset is to be split. eg. 0.8 means 80 % part1 & remaining 20% for part2","d0f2f790":"Learn more about visualizing your TFRecords Dataset here -> https:\/\/www.quickml.info\/visualize-check-data","20a65a2f":"## Visualizing the TFRecords Dataset","651f99b2":"quick_ml also provides with the fascility for visualizing your TFRecords Datasets generated using quick_ml.","2c0b1af5":"Before you can read any dataset using quick_ml, you need to defined the TFRecord Format (for both labeled & unlabeled). Since,we just generated Labeled TFRecords Dataset (training.tfrecords & validation.tfrecords), we'll only have to define the **labeled_tfrecord_format** using **get_labeled_tfrecord_format**. This can be found at https:\/\/www.quickml.info\/begin-working-w-tpu by scrolling down to get_labeled_tfrecord_format","865bf408":"Please ensure the order of imports.\n\n* Import Tensorflow then quick_ml\n* After successful import, you must receive an output message indicating the status of \"Tensorflow import & the latest version\" supported by quick_ml","47df351a":"To begin visualizing your dataset, you'd need visualize_and_check_data utility of quick_ml. <br>\n<br>\n*Note*:-Please note the difference between the words label & id. Label refers to the classification label. Id refers to file name or number.\n<br><br>It provides the following four functionalities -> <br>\n* check_one_image_and_label - display one image & it's corresponding label\n* check_batch_and_labels - display a batch of images & their corresponding labels \n* check_one_image_and_id - display one image & it's corresponding id\n* check_batch_and_ids - display a batch of images & their corresponding ids","4280a6c2":"Official Website of quick_ml -> https:\/\/www.quickml.info","d0c994d3":"### Installation & Necessary Imports","ac3145ad":"In this notebook, we'll be generating two parts of the entire dataset, namely, the training and validation dataset. <br>\nTo do so, we'll be using **create_split_tfrecords_data** which can help you generate two parts\/splits of the entire dataset as our dataset follows the structure of <br>\ndata |<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-> Class 1 folder <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-> Class 2 folder <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|-> Class N folder <br>\n<br><br>This can be found at https:\/\/www.quickml.info\/making-custom-datasets-tfrecords under Labeled Data Section (B)","f9a3a39e":"## Generate TFRecords Dataset"}}