{"cell_type":{"445f7c70":"code","b1902e2a":"code","7abea0c7":"code","77fe89d4":"code","76f3999b":"code","a8f9ff3e":"code","849ee428":"code","36d0778b":"code","f0f9dea2":"code","4419298c":"code","5fa52bfa":"code","17b24e33":"code","58c5e77a":"code","daca3315":"code","98b3db1f":"code","74763756":"code","af46fa93":"code","e2cca7af":"code","474be91e":"code","2900cf13":"markdown","e583748d":"markdown","e94a3b87":"markdown"},"source":{"445f7c70":"# import libraries\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom kaggle_datasets import KaggleDatasets\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE","b1902e2a":"# Detect hardware, return appropriate distribution strategy\n\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n    \nprint(\"replocas: \", strategy.num_replicas_in_sync)","7abea0c7":"# Get the GCS path\nGCS_PATH = KaggleDatasets().get_gcs_path()\nprint(GCS_PATH)\n\ntrain_path = GCS_PATH + '\/train\/train\/'\nprint(train_path)","77fe89d4":"# Load the image path name and convert it to a numpy array\nimage_file_path = np.array(tf.io.gfile.glob(train_path + '*.jpg'))\n\n# Generate a label based on the first three letters of the image name, (cat-->0, dog-->1)\nlabels = np.array([\n    0 if name.split('\/')[-1].startswith('cat') else 1\n    for name in image_file_path\n])\n\nprint(len(image_file_path),len(labels))","76f3999b":"# Stratified ShuffleSplit Dataset\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\n# The data set is divided into train_set and other_set according to 8:2\ntrain_val_sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2021)\n\nfor train_index, val_index in train_val_sss.split(image_file_path, labels):\n    train_path, val_path = image_file_path[train_index],image_file_path[val_index]\n    train_labels, val_labels = labels[train_index],labels[val_index]\n    \n\n# The data set is divided into val_set and test_set according to 1:1\nval_test_sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=2021)\n\nfor val_index, test_index in val_test_sss.split(val_path, val_labels):\n    val_path, test_path = val_path[val_index],val_path[test_index]\n    val_labels, test_labels = val_labels[val_index],val_labels[test_index]\n    \n# You will end up with 8: 1: 1 training sets, validation sets, and test sets,\n# each of which has the same ratio of cats and dogs","a8f9ff3e":"print(len(train_path),len(train_labels),train_labels.sum())\nprint(len(val_path),len(val_labels),val_labels.sum())\nprint(len(test_path),len(test_labels),test_labels.sum())","849ee428":"image_size = [512,512]\nchannels = 3\nbatch_size = 16 * strategy.num_replicas_in_sync","36d0778b":"# load and process image\n\ndef load_image(path,label):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image,channels=channels)\n    \n    # This function will normalize the image\n    image = tf.image.convert_image_dtype(image, tf.float32) \n    \n    image = tf.image.resize(image, image_size)\n    return image, label\n\n\ndef augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    return image, label","f0f9dea2":"# Get dataset\ntrain_ds = tf.data.Dataset.from_tensor_slices((train_path,train_labels))\ntrain_ds = train_ds.map(load_image, num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.cache().shuffle(2048).batch(batch_size).prefetch(AUTOTUNE)\n\n\nval_ds = tf.data.Dataset.from_tensor_slices((val_path,val_labels))\nval_ds = val_ds.map(load_image, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.cache().batch(batch_size).prefetch(AUTOTUNE)\n\n\ntest_ds = tf.data.Dataset.from_tensor_slices((test_path,test_labels))\ntest_ds = test_ds.map(load_image, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.cache().batch(batch_size).prefetch(AUTOTUNE)","4419298c":"# Show some training dataset pictures\n\nimage,label = next(iter(train_ds))\n\nplt.figure(figsize=(20,20))\n\nfor i in range(36):\n    plt.subplot(6,6,i+1)\n    plt.imshow(image[i])\n    plt.xticks([])\n    plt.yticks([])\n    plt.xlabel('cat' if label[i]==0 else 'dog')\nplt.show()","5fa52bfa":"with strategy.scope():\n    ResNet152V2 = keras.applications.ResNet152V2(include_top=False)\n    model = keras.Sequential([\n        layers.InputLayer(input_shape=[*image_size,channels]),\n        ResNet152V2,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(1000,activation='relu'),\n        layers.Dropout(0.2),\n        layers.Dense(1,activation='sigmoid')\n    ])\n    \n    model.compile(\n        optimizer=keras.optimizers.Adam(lr=0.001),\n        loss=keras.losses.BinaryCrossentropy(),\n        metrics=[\n            'accuracy',\n            keras.metrics.Precision(name='precision'),\n            keras.metrics.Recall(name='recall'),\n        ]\n    )\n    \n    callbacks = [\n        keras.callbacks.EarlyStopping(monitor='val_accuracy',mode='max',patience=10,\n                                      verbose=1,restore_best_weights=True),\n        keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',mode='max',\n                                      factor=0.5,patience=6,verbose=1)\n    ]\n    \n    model.fit(train_ds,batch_size=batch_size,epochs=50,\n              validation_data=val_ds,callbacks=callbacks)","17b24e33":"# test model\nmodel.evaluate(test_ds)","58c5e77a":"# save model\nmodel.save('Dogs_Vs_Cats_ResNet152V2.h5')","daca3315":"# Predicted pictures are not labeled\ndef load_predict_image(path):\n    image = tf.io.read_file(path)\n    image = tf.image.decode_jpeg(image,channels=channels)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, image_size)\n    return image","98b3db1f":"predict_path = GCS_PATH + '\/test\/test\/'\nfile_names = tf.io.gfile.glob(predict_path+'*.jpg')","74763756":"# get predicted image dataset\n\npredict_ds = tf.data.Dataset.from_tensor_slices(file_names)\npredict_ds = predict_ds.map(load_predict_image, num_parallel_calls=AUTOTUNE)\npredict_ds = predict_ds.batch(batch_size)","af46fa93":"# take one batch image to predict\npredict_images = next(iter(predict_ds))","e2cca7af":"# We will get a matrix of (batch_size, 1) and use `reshape(-1)` to convert to (batch_size,).\npredict_result = model.predict(predict_images).reshape(-1)","474be91e":"# Show some predictions\n\nplt.figure(figsize=(20,20))\n\nfor i in range(36):\n    plt.subplot(6,6,i+1)\n    plt.imshow(predict_images[i])\n    plt.xticks([])\n    plt.yticks([])\n    plt.xlabel('cat' if predict_result[i]<=0.5 else 'dog')\nplt.show()","2900cf13":"# Load data","e583748d":"# Build Model\n\n* Use ResNet152V2 as base model\n* Use EarlyStopping to stop training early when val_accuracy was not improved for 10 consecutive times\n* Use ReduceLROnPlateau to halve the learning rate when val_accuracy was not improved for 6 consecutive times","e94a3b87":"# Predict"}}