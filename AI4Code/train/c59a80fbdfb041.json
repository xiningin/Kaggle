{"cell_type":{"19fad3b0":"code","b0a16676":"code","445b8cd7":"code","7be9369a":"code","7f889919":"code","fc3ba4bf":"code","4b37aa3f":"code","809ad30b":"code","2d75f08a":"code","c8432581":"code","4e7318c7":"code","c7c9d265":"code","3a2ceff2":"code","f247bcc2":"code","9c673ad0":"code","e2718409":"code","173cbb92":"code","6546cba8":"code","005119e1":"markdown","595411b0":"markdown","6b713f81":"markdown","2b08c3c8":"markdown","07c70487":"markdown"},"source":{"19fad3b0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import (\n    confusion_matrix, accuracy_score, precision_score,\n    recall_score, f1_score, precision_recall_curve,\n    roc_auc_score\n)\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer, SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n\n","b0a16676":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","445b8cd7":"train.head()","7be9369a":"test.tail()","7f889919":"print(train.shape)\nprint(test.shape)","fc3ba4bf":"X = train.drop(['Survived'], axis=1)\nY = train.Survived","4b37aa3f":"# Total missing values in each columns\ntrain.isnull().sum(axis=0)","809ad30b":"# percentage of missing values in each columns\ntest.isnull().sum(axis=0)","2d75f08a":"pipeline1 = ColumnTransformer([\n    ('drop', 'drop', ['PassengerId', 'Name', 'Cabin', 'Ticket']),\n    ('ageimputer', IterativeImputer(max_iter=10, random_state=27), ['Age', 'Fare']),\n    ('embarkedimputer', SimpleImputer(strategy='most_frequent'), ['Embarked'])],\n    remainder='passthrough'\n)\n\npipeline2 = ColumnTransformer([\n    ('scaler', MinMaxScaler(), [0, 1, 5, 6]),\n    ('onehot', OneHotEncoder(), [2, 3, 4])\n])\n\npipeline = make_pipeline(pipeline1, pipeline2)","c8432581":"pipeline.fit(X)\nX_train = pipeline.transform(X)\nX_test = pipeline.transform(test)","4e7318c7":"pd.DataFrame(X_train).sample(5)","c7c9d265":"pd.DataFrame(X_test).sample(5)","3a2ceff2":"lr = LogisticRegression(penalty='l1', verbose=2)\nrr = SGDClassifier(penalty='l2', n_jobs=4, loss='log')\nls = SGDClassifier(penalty='l1', n_jobs=4, loss='log')\nen = SGDClassifier(penalty='elasticnet', n_jobs=4, loss='log')","f247bcc2":"metrics.SCORERS.keys()","9c673ad0":"cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=27)\n\ngrid_ridge_lasso = {\n    'alpha': np.arange(0, 1, 0.05),\n    'learning_rate': np.array(['constant']),\n    'eta0': np.array([0.1, 0.01, 0.001])\n}\n\ngrid_elastic = {\n    'alpha': np.arange(0, 1, 0.05),\n    'l1_ratio': np.arange(0, 1, 0.05),\n    'learning_rate': np.array(['constant']),\n    'eta0': np.array([0.1, 0.01, 0.001])\n}\n\nlr_score = cross_val_score(lr, X_train, Y, cv=cv, scoring='accuracy')\n\nrr_search = GridSearchCV(rr, grid_ridge_lasso, cv=cv, scoring='accuracy')\nrr_score = rr_search.fit(X_train, Y)\n\nls_search = GridSearchCV(ls, grid_ridge_lasso, cv=cv, scoring='accuracy')\nls_score = ls_search.fit(X_train, Y)\n\nen_search = GridSearchCV(en, grid_elastic, cv=cv, scoring='accuracy')\nen_score = en_search.fit(X_train, Y)","e2718409":"print(np.mean(lr_score))\nprint(rr_score.best_score_)\nprint(ls_score.best_score_)\nprint(en_score.best_score_)","173cbb92":"predictions = en_score.best_estimator_.predict(X_test)","6546cba8":"pd.DataFrame({\n    'PassengerId': test.PassengerId,\n    'Survived': predictions\n}).to_csv('submission.csv', index=False)","005119e1":"# Load Data","595411b0":"# Data preprocessing using pipeline","6b713f81":"# Import Libraries\n","2b08c3c8":"# Model Fitting","07c70487":"Name: **Sazid Nur Ratul**\n\nID: **181-35-346**\n"}}