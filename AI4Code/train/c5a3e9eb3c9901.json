{"cell_type":{"82176fbd":"code","d0537b54":"code","8fb27f4e":"code","3495dad4":"code","ef2f92c0":"code","00099189":"code","62539385":"code","2ef7b902":"code","568fd614":"code","2033f153":"code","4ca2452b":"code","674881d7":"code","71a964a9":"code","8be4a25c":"code","1bc8fd9b":"code","da6df3b7":"code","ee0e66d8":"code","bae05e35":"code","4b5bd9ed":"code","efbf1df3":"code","15286ddc":"code","b4c7d9c2":"code","873e759b":"code","c5dccaec":"code","c123115a":"code","ed74cdc8":"code","3026ace3":"code","5de5aa0c":"code","727001be":"code","db2da1a2":"code","075fa69e":"code","622d0d77":"code","8e78dbec":"code","72f44653":"markdown","78d894e3":"markdown","1ec55c06":"markdown","d4eebe9f":"markdown","c9eec1be":"markdown","1c626623":"markdown","5a977628":"markdown","c8fe7774":"markdown","6fe5438a":"markdown","bf2cc58e":"markdown","20eacd9e":"markdown","222663e4":"markdown","f031e0d2":"markdown","14195f1d":"markdown","3d6a036a":"markdown","81c0cb6b":"markdown","25c1edee":"markdown"},"source":{"82176fbd":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV\nimport warnings\n","d0537b54":"train=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")\ntest2=pd.read_csv(\"..\/input\/test.csv\")\ntitanic=pd.concat([train, test], sort=False)\nlen_train=train.shape[0]","8fb27f4e":"titanic.dtypes.sort_values()","3495dad4":"titanic.select_dtypes(include='int').head()","ef2f92c0":"titanic.select_dtypes(include='object').head()","00099189":"titanic.select_dtypes(include='float').head()","62539385":"titanic.isnull().sum()[titanic.isnull().sum()>0]","2ef7b902":"train.Fare=train.Fare.fillna(train.Fare.mean())\ntest.Fare=test.Fare.fillna(train.Fare.mean())","568fd614":"train.Cabin=train.Cabin.fillna(\"unknow\")\ntest.Cabin=test.Cabin.fillna(\"unknow\")","2033f153":"train.Embarked=train.Embarked.fillna(train.Embarked.mode()[0])\ntest.Embarked=test.Embarked.fillna(train.Embarked.mode()[0])","4ca2452b":"train['title']=train.Name.apply(lambda x: x.split('.')[0].split(',')[1].strip())\ntest['title']=test.Name.apply(lambda x: x.split('.')[0].split(',')[1].strip())","674881d7":"newtitles={\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"}","71a964a9":"train['title']=train.title.map(newtitles)\ntest['title']=test.title.map(newtitles)","8be4a25c":"train.groupby(['title','Sex']).Age.mean()","1bc8fd9b":"def newage (cols):\n    title=cols[0]\n    Sex=cols[1]\n    Age=cols[2]\n    if pd.isnull(Age):\n        if title=='Master' and Sex==\"male\":\n            return 4.57\n        elif title=='Miss' and Sex=='female':\n            return 21.8\n        elif title=='Mr' and Sex=='male': \n            return 32.37\n        elif title=='Mrs' and Sex=='female':\n            return 35.72\n        elif title=='Officer' and Sex=='female':\n            return 49\n        elif title=='Officer' and Sex=='male':\n            return 46.56\n        elif title=='Royalty' and Sex=='female':\n            return 40.50\n        else:\n            return 42.33\n    else:\n        return Age ","da6df3b7":"train.Age=train[['title','Sex','Age']].apply(newage, axis=1)\ntest.Age=test[['title','Sex','Age']].apply(newage, axis=1)","ee0e66d8":"warnings.filterwarnings(action=\"ignore\")\nplt.figure(figsize=[12,10])\nplt.subplot(3,3,1)\nsns.barplot('Pclass','Survived',data=train)\nplt.subplot(3,3,2)\nsns.barplot('SibSp','Survived',data=train)\nplt.subplot(3,3,3)\nsns.barplot('Parch','Survived',data=train)\nplt.subplot(3,3,4)\nsns.barplot('Sex','Survived',data=train)\nplt.subplot(3,3,5)\nsns.barplot('Ticket','Survived',data=train)\nplt.subplot(3,3,6)\nsns.barplot('Cabin','Survived',data=train)\nplt.subplot(3,3,7)\nsns.barplot('Embarked','Survived',data=train)\nplt.subplot(3,3,8)\nsns.distplot(train[train.Survived==1].Age, color='green', kde=False)\nsns.distplot(train[train.Survived==0].Age, color='orange', kde=False)\nplt.subplot(3,3,9)\nsns.distplot(train[train.Survived==1].Fare, color='green', kde=False)\nsns.distplot(train[train.Survived==0].Fare, color='orange', kde=False)","bae05e35":"train['Relatives']=train.SibSp+train.Parch\ntest['Relatives']=test.SibSp+test.Parch\n\ntrain['Ticket2']=train.Ticket.apply(lambda x : len(x))\ntest['Ticket2']=test.Ticket.apply(lambda x : len(x))\n\ntrain['Cabin2']=train.Cabin.apply(lambda x : len(x))\ntest['Cabin2']=test.Cabin.apply(lambda x : len(x))\n\ntrain['Name2']=train.Name.apply(lambda x: x.split(',')[0].strip())\ntest['Name2']=test.Name.apply(lambda x: x.split(',')[0].strip())","4b5bd9ed":"warnings.filterwarnings(action=\"ignore\")\nplt.figure(figsize=[12,10])\nplt.subplot(3,3,1)\nsns.barplot('Relatives','Survived',data=train)\nplt.subplot(3,3,2)\nsns.barplot('Ticket2','Survived',data=train)\nplt.subplot(3,3,3)\nsns.barplot('Cabin2','Survived',data=train)\n","efbf1df3":"#droping features I won't use in model\n#train.drop(['PassengerId','Name','Ticket','SibSp','Parch','Ticket','Cabin']\ntrain.drop(['PassengerId','Name','Ticket','SibSp','Parch','Ticket','Cabin'],axis=1,inplace=True)\ntest.drop(['PassengerId','Name','Ticket','SibSp','Parch','Ticket','Cabin'],axis=1,inplace=True)","15286ddc":"titanic=pd.concat([train, test], sort=False)","b4c7d9c2":"titanic=pd.get_dummies(titanic)","873e759b":"train=titanic[:len_train]\ntest=titanic[len_train:]","c5dccaec":"# Lets change type of target\ntrain.Survived=train.Survived.astype('int')\ntrain.Survived.dtype","c123115a":"xtrain=train.drop(\"Survived\",axis=1)\nytrain=train['Survived']\nxtest=test.drop(\"Survived\", axis=1)","ed74cdc8":"RF=RandomForestClassifier(random_state=1)\nPRF=[{'n_estimators':[10,100],'max_depth':[3,6],'criterion':['gini','entropy']}]\nGSRF=GridSearchCV(estimator=RF, param_grid=PRF, scoring='accuracy',cv=2)\nscores_rf=cross_val_score(GSRF,xtrain,ytrain,scoring='accuracy',cv=5)","3026ace3":"np.mean(scores_rf)","5de5aa0c":"svc=make_pipeline(StandardScaler(),SVC(random_state=1))\nr=[0.0001,0.001,0.1,1,10,50,100]\nPSVM=[{'svc__C':r, 'svc__kernel':['linear']},\n      {'svc__C':r, 'svc__gamma':r, 'svc__kernel':['rbf']}]\nGSSVM=GridSearchCV(estimator=svc, param_grid=PSVM, scoring='accuracy', cv=2)\nscores_svm=cross_val_score(GSSVM, xtrain.astype(float), ytrain,scoring='accuracy', cv=5)","727001be":"np.mean(scores_svm)","db2da1a2":"model=GSSVM.fit(xtrain, ytrain)","075fa69e":"pred=model.predict(xtest)","622d0d77":"output=pd.DataFrame({'PassengerId':test2['PassengerId'],'Survived':pred})","8e78dbec":"output.to_csv('submission.csv', index=False)","72f44653":"### 1.4 Feature Engineering","78d894e3":"### 1.1 - Imports","1ec55c06":"### SVM","d4eebe9f":"## 1- Preprocessing and exploring","c9eec1be":"### Embarked","1c626623":"SibSp and Parch don't seem to have a clear relationship with the target, so put them together can be a good idea.\nFor Ticket and Cabin a good strategie can be count the number of caracteres.","5a977628":"### Cabin","c8fe7774":"# Titanic: on the top with a simple model\nIn this kernel I intend to use nested cross validation to choose between Random Forest and SVM. \n\n\n#### <span style ='color: purple'> Please, upvote if you find useful! Also, check my other kernel about classification: <\/span> [Classification: Review with Python](http:\/\/www.kaggle.com\/goldens\/classification-review-with-python) \n\n\n### Steps:\n* 1- Preprocessing and exploring\n    * 1.1- Imports\n    * 1.2- Types\n    * 1.3 - Missing Values\n    * 1.4 - Exploring\n    * 1.5 - Feature Engineering\n    * 1.6 - Prepare for models\n* 2- Nested Cross Validation\n* 3- Submission\n    \n   \n","6fe5438a":"# 2 - Nested Cross Validation","bf2cc58e":"## 1.2 - Missing values","20eacd9e":"### 1.3 - Exploring","222663e4":"### Fare","f031e0d2":"### Age\nConsidering title\nInspired on: https:\/\/medium.com\/i-like-big-data-and-i-cannot-lie\/how-i-scored-in-the-top-9-of-kaggles-titanic-machine-learning-challenge-243b5f45c8e9","14195f1d":"# 3 - Submission","3d6a036a":"### Random Forest","81c0cb6b":"### 1.2 - Types","25c1edee":"### 1.4 - Prepare for model"}}