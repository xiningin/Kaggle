{"cell_type":{"a1578e8f":"code","c58b0eaf":"code","45ecca4a":"code","8dd32210":"code","46ba6cad":"code","1571e1ed":"code","0637dac1":"code","e8236355":"code","46eb7325":"code","d32215c1":"code","6b48a391":"code","cd46f126":"code","5a10da63":"code","cbe83e66":"code","3fafda68":"code","5cc9687b":"code","e87c233a":"code","27bca06a":"code","13d97a30":"code","0faac08d":"code","26e3ce98":"code","2b7bcf43":"code","84b6ba68":"markdown","82485f40":"markdown","9ea5760f":"markdown","de0b076e":"markdown","bf7fff5a":"markdown","6f365dfc":"markdown","2cbdedbe":"markdown","ad6de284":"markdown","5637f970":"markdown","9367e694":"markdown","4f63aa82":"markdown","cbfd063a":"markdown"},"source":{"a1578e8f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c58b0eaf":"!pip install gdown\n!gdown https:\/\/drive.google.com\/uc?id=1eToBctRfz2b83KgP25xRsJ2mZAeqYtHB\n!gdown https:\/\/drive.google.com\/uc?id=1DL6Shq1GQtUvPCxJkPSBUQs9YzMlb15H\n!gdown https:\/\/drive.google.com\/uc?id=171mXX58ZT9XxOCGdAQfDYZe7nL5Vt9Qs\n!unzip \/kaggle\/working\/data_semantic_segmentation_baseline.zip\n!pip install albumentations","45ecca4a":"import shutil\n\n!mkdir \/kaggle\/working\/model\nshutil.unpack_archive('\/kaggle\/working\/model_train(11).zip', '\/kaggle\/working\/model')","8dd32210":"import cv2\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nmask_id, image_ = [], []\nmask_V, image_V = [], []\nmask_T, image_T = [], []\n\ndef get_paths():\n    for file in sorted(os.listdir('\/kaggle\/working\/masks\/train')):\n        mask_id.append(os.path.join('\/kaggle\/working\/masks\/train', file))\n    for file in sorted(os.listdir('\/kaggle\/working\/imgs\/train')):\n        image_.append(os.path.join('\/kaggle\/working\/imgs\/train', file))\n    for file in sorted(os.listdir('\/kaggle\/working\/masks\/validation')):\n        mask_V.append(os.path.join('\/kaggle\/working\/masks\/validation', file))\n    for file in sorted(os.listdir('\/kaggle\/working\/imgs\/validation')):\n        image_V.append(os.path.join('\/kaggle\/working\/imgs\/validation', file))\n    for file in sorted(os.listdir('\/kaggle\/working\/masks\/test')):\n        mask_T.append(os.path.join('\/kaggle\/working\/masks\/test', file))\n    for file in sorted(os.listdir('\/kaggle\/working\/imgs\/test')):\n        image_T.append(os.path.join('\/kaggle\/working\/imgs\/test', file))\n\nget_paths()","46ba6cad":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nfrom pylab import rcParams\nfrom tqdm import tqdm\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom pandas.plotting import register_matplotlib_converters\nimport random\nfrom albumentations import (\n    Compose, RandomBrightness, JpegCompression, HueSaturationValue, RandomContrast, HorizontalFlip,\n    Rotate\n)\nfrom IPython.display import Image, display\nfrom tensorflow.keras.preprocessing.image import load_img\nimport PIL\nfrom PIL import ImageOps, Image\n\n\nimage_transforms = Compose([\n            RandomBrightness(limit=0.1),\n            JpegCompression(quality_lower=85, quality_upper=100, p=0.5),\n            HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n            RandomContrast(limit=0.2, p=0.5),\n            HorizontalFlip(),\n])\nmask_transforms = Compose([\n            Rotate(limit=90),\n            HorizontalFlip()\n])\ndef aug_fn(image, img_size, mask=False):\n    data = {\"image\":image}\n    if mask is False:\n        aug_data = image_transforms(**data)\n    else:\n        aug_data = mask_transforms(**data)\n    aug_img = aug_data[\"image\"]\n    aug_img = tf.cast(aug_img \/ 255, tf.float32)\n    if mask is False:\n        aug_img = tf.image.resize(aug_img, size=[img_size, img_size])\n    return aug_img\nimg_idx = 0\nfor i in range(1, len(image_)):\n    img_path, mask_path = image_[i], mask_id[i]\n    img_load = cv2.imread(img_path)\n    mask_load = cv2.imread(mask_path, 0)\n    transformed_img = np.asarray(aug_fn(np.asarray(img_load), 896))\n    transformed_mask = np.asarray(aug_fn(np.asarray(mask_load), 896, mask=True))\n    filename = '\/kaggle\/working\/imgs\/train\/augmented_img_' + str(img_idx) + '.png'\n    cv2.imwrite(filename, transformed_img)\n    filename = '\/kaggle\/working\/masks\/train\/augmented_mask_' + str(img_idx + 1) + '.png'\n    cv2.imwrite(filename, transformed_mask)\n    rotate_90_img = np.asarray(cv2.rotate(img_load, cv2.ROTATE_90_CLOCKWISE))\n    rotate_90_mask = np.asarray(cv2.rotate(mask_load, cv2.ROTATE_90_CLOCKWISE))\n    img = Image.fromarray(rotate_90_img)\n    mask = Image.fromarray(rotate_90_mask)\n    filename = 'augmented_img_' + str(img_idx + 2) +'.png'\n    img.save('\/kaggle\/working\/imgs\/train\/{0}'.format(filename), 'PNG')\n    filename = 'augmented_mask_' + str(img_idx + 3) + '.png'\n    mask.save('\/kaggle\/working\/masks\/train\/{0}'.format(filename), 'PNG')\n    rotate_180_img = np.asarray(cv2.rotate(img_load, cv2.ROTATE_180))\n    rotate_180_mask = np.asarray(cv2.rotate(img_load, cv2.ROTATE_180))\n    filename = 'augmented_img_' + str(img_idx + 4) + '.png'\n    img.save('\/kaggle\/working\/imgs\/train\/{0}'.format(filename), 'PNG')\n    filename = 'augmented_mask_' + str(img_idx + 5) + '.png'\n    mask.save('\/kaggle\/working\/imgs\/train\/{0}'.format(filename), 'PNG')\n    img_idx += 6\n\nget_paths()","1571e1ed":"from IPython.display import Image, display\nfrom tensorflow.keras.preprocessing.image import load_img\nimport PIL\nfrom PIL import ImageOps, Image\n\nimg = Image.open(image_[-1])\nimg = img.resize((896,896))\ndisplay(img)\nimg = PIL.ImageOps.autocontrast(load_img(mask_id[-1]))\ndisplay(img)","0637dac1":"from tensorflow import keras\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import load_img\nimport sys\nimport numpy\nnumpy.set_printoptions(threshold=sys.maxsize)\n\nclass SugarBeets(keras.utils.Sequence):\n    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.input_img_paths = input_img_paths\n        self.target_img_paths = target_img_paths\n    \n    def __len__(self):\n        return len(self.target_img_paths) \/\/ self.batch_size\n    \n    def __getitem__(self, idx):\n        i = idx * self.batch_size\n        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n        for j, path in enumerate(batch_target_img_paths):\n            img = np.array(load_img(path, target_size=self.img_size))\n            x[j] = img\n        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n        for j, path in enumerate(batch_target_img_paths):\n            img = np.array(load_img(path, target_size=self.img_size, color_mode=\"grayscale\"))\n            img = np.expand_dims(img, 2)\n            img[np.where(img == 39)] = 1\n            img[np.where(img == 78)] = 2\n            y[j] = img\n        return x,y","e8236355":"train_gen = SugarBeets(2, (896, 896), image_, mask_id)\nval_gen = SugarBeets(2, (896, 896), image_V, mask_V)\ntest_gen = SugarBeets(2, (896,896), image_T, mask_T)","46eb7325":"import tensorflow as tf\nif tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"Please install GPU version of TF\")","d32215c1":"from keras import backend as K\nfrom tensorflow.keras.metrics import MeanIoU\nm = MeanIoU(num_classes=3)\ndef iou_coeff(y_true, y_pred):\n    y_true = float(y_true)\n    y_pred = K.argmax(y_pred, axis=-1)\n    y_pred = float(K.reshape(y_pred, (2,896,896,1)))\n    m.update_state(y_true, y_pred)\n    return m.result()\n\ndef iou_coef_loss(y_true, y_pred):\n    return 1 - iou_coef(y_true, y_pred)","6b48a391":"from tensorflow.keras import layers\n\n\ndef get_model(img_size, num_classes):\n    inputs = keras.Input(shape=img_size + (3,))\n\n    ### First half of network: Encoder\n\n\n    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n\n    previous_block_activation = x  # Set aside residual\n\n    # Blocks 1, 2, 3 are identical apart from the feature depth.\n    for filters in [64, 128, 256]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    ### [Second half of the network: upsampling inputs] ###\n\n    for filters in [256, 128, 64, 32]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.UpSampling2D(2)(x)\n\n        # Project residual\n        residual = layers.UpSampling2D(2)(previous_block_activation)\n        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n\n    # Add a per-pixel classification layer\n    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n\n    # Define the model\n    model = keras.Model(inputs, outputs)\n    return model\n\n","cd46f126":"import tensorflow as tf\nfrom tensorflow.compat.v1.keras.backend import set_session\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.metrics import MeanIoU\n\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.log_device_placement = True\nsess = tf.compat.v1.Session(config=config)\nset_session(sess)\nmodel=get_model((896, 896), 3)\nmodel.summary()\nmodel.compile(optimizer=\"rmsprop\", loss='sparse_categorical_crossentropy', metrics=[iou_coeff])\n\nmodel.fit(train_gen, validation_data=val_gen,epochs=40)","5a10da63":"val_preds = model.predict(test_gen) \ndef display_mask(i):\n    mask = np.argmax(val_preds[i], axis=-1)\n    mask = np.expand_dims(mask, axis=-1).astype('float32')\n    img_size = (1024, 768)\n    mask = cv2.resize(mask, img_size)\n    mask = np.expand_dims(mask, axis=-1)\n    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n    display(img)","cbe83e66":"from IPython.display import Image, display\nfrom tensorflow.keras.preprocessing.image import load_img\nimport PIL\nfrom PIL import ImageOps\ni = 2\n\n# Display input image\ndisplay(Image(filename=image_T[i]))\n# Display ground-truth target mask\nimg = PIL.ImageOps.autocontrast(load_img(mask_T[i]))\ndisplay(img)\n# Display predicted mask\ndisplay_mask(i)  ","3fafda68":"from sklearn.metrics import confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nimport numpy as np\n\nmodel = tf.keras.models.load_model('\/kaggle\/working\/model', custom_objects = {\"iou_coeff\": iou_coeff})\nmodel.compile(optimizer=\"rmsprop\", loss='sparse_categorical_crossentropy', metrics=[iou_coeff])","5cc9687b":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_fscore_support\npred = model.predict(test_gen)\n\nf1 = 0\n\nweed_iou = 0\nweed_precision = 0\nweed_recall = 0\nweed_dice = 0\n\ncrop_iou = 0\ncrop_precision = 0\ncrop_recall = 0\ncrop_dice = 0\n\nbackground_iou = 0\nbackground_precision = 0\nbackground_recall = 0\nbackground_dice = 0","e87c233a":"def labelIoU(pred, label, mask, mask_val):\n    label_pred = np.zeros([768, 1024])\n    label_pred[np.where(pred == label)] = 1\n    label_pred = np.reshape(label_pred, (1*768*1024*1, 1))\n    label_mask = np.zeros([768, 1024])\n    label_mask[np.where(mask == mask_val)] = 1\n    label_mask = np.reshape(label_mask, (1*768*1024*1, 1))\n    if np.array_equal(label_pred, label_mask):\n        return 1\n    tn, fp, fn, tp = confusion_matrix(label_mask, label_pred).ravel()\n    return (tp \/ (tp + fn + fp))","27bca06a":"for i in range(len(image_T)):\n    pred_i = np.argmax(pred[i], axis=-1)\n    pred_i = np.expand_dims(pred_i, axis=-1).astype('float32')\n    img_size = (1024, 768)\n    pred_i = cv2.resize(pred_i, img_size)\n    mask = np.array(load_img(mask_T[i], color_mode=\"grayscale\"))\n    # calculate crop IoU\n    weed_iou += labelIoU(pred_i, 2, mask, 78)\n    # calculate weed IoU\n    crop_iou += labelIoU(pred_i, 1, mask, 39)\n    # calculate background IoU\n    background_iou += labelIoU(pred_i, 0, mask, 0)\n    # calculate mean IoU, precision, recall, F1\n    mask[np.where(mask==39)] = 1\n    mask[np.where(mask==78)] = 2\n    pred_i = np.reshape(pred_i, (1*768*1024*1, 1)).astype('uint8')\n    mask = np.reshape(mask, (1*768*1024*1, 1)).astype('uint8')\n    f1 += f1_score(mask, pred_i, average='micro')\n    res = precision_recall_fscore_support(mask, pred_i, average=None, labels=[0, 1, 2], zero_division=1)\n    #calculate precision recall and dice score for each class \n    background_precision += res[0][0];\n    background_recall += res[1][0];\n    background_dice += res[2][0];\n    \n    crop_precision += res[0][1];\n    crop_recall += res[1][1];\n    crop_dice += res[2][1];\n    \n    weed_precision += res[0][2];\n    weed_recall += res[1][2];\n    weed_dice += res[2][2];\n    ","13d97a30":"print('Weed IoU: {0}, Weed Precision: {1}, Weed Recall: {2}, Weed Dice score: {3}'.format(weed_iou \/ 100.0, weed_precision \/ 100.0, weed_recall \/ 100.0, weed_dice \/ 100.0))\nprint('Crop IoU: {0}, Crop Precision: {1}, Crop Recall: {2}, Crop Dice score: {3}'.format(crop_iou \/ 100.0, crop_precision \/ 100.0, crop_recall \/ 100.0, crop_dice \/ 100.0))\nprint('Background IoU: {0}, Background Precision: {1}, Background Recall: {2}, Background Dice score: {3}'.format(background_iou \/ 100.0, background_precision \/ 100.0, background_recall \/ 100.0, background_dice \/ 100.0))\nprint('Mean F1 score \/ Dice coefficient: {0}'.format(f1 \/ 100))","0faac08d":"model.evaluate(test_gen)","26e3ce98":"import tensorflow.keras as keras\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import  BatchNormalization, Activation, Dropout\nfrom tensorflow.keras.layers import Conv2D, UpSampling2D\nfrom tensorflow.keras.layers import MaxPooling2D\n\ndef segnet(\n        input_size = (896,896,3), num_classes=3):\n    # Block 1\n    inputs = keras.layers.Input(input_size)\n    x = keras.layers.Conv2D(64, (3, 3),activation='relu',padding='same',name='block1_conv1',kernel_initializer = 'he_normal')(inputs)\n    x = keras.layers.Conv2D(64, (3, 3),activation='relu',padding='same',name='block1_conv2',kernel_initializer = 'he_normal')(x)\n    x=keras.layers.BatchNormalization()(x)\n    pool_1 = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n    # Block 2\n    x = keras.layers.Conv2D(128, (3, 3), activation='relu',padding='same',name='block2_conv1',kernel_initializer = 'he_normal')(pool_1)\n    x = keras.layers.Conv2D(128, (3, 3),activation='relu',padding='same',name='block2_conv2',kernel_initializer = 'he_normal')(x)\n    x=keras.layers.BatchNormalization()(x)\n    pool_2 = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n     # Block 3\n    x = keras.layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv1',kernel_initializer = 'he_normal')(pool_2)\n    x = keras.layers.Conv2D(256, (3, 3),activation='relu',padding='same',name='block3_conv2',kernel_initializer = 'he_normal')(x)\n    x = keras.layers.Conv2D(512, (3, 3),activation='relu',padding='same',name='block3_conv3',kernel_initializer = 'he_normal')(x)\n    x=keras.layers.BatchNormalization()(x)\n    pool_3 = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n    # Block 4\n    x = keras.layers.Conv2D(512, (3, 3),activation='relu',padding='same',name='block4_conv1',kernel_initializer = 'he_normal')(pool_3)\n    x = keras.layers.Conv2D(512, (3, 3),activation='relu',padding='same',name='block4_conv2',kernel_initializer = 'he_normal')(x)\n    x = keras.layers.Conv2D(512, (3, 3),activation='relu',padding='same',name='block4_conv3',kernel_initializer = 'he_normal')(x)\n    x=keras.layers.BatchNormalization()(x)\n    pool_4 = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n    # Block 5\n    x = keras.layers.Conv2D(512, (3, 3),activation='relu',padding='same',name='block5_conv1',kernel_initializer = 'he_normal')(pool_4)\n    x = keras.layers.Conv2D(512, (3, 3),activation='relu',padding='same',name='block5_conv2',kernel_initializer = 'he_normal')(x)\n    x = keras.layers.Conv2D(512, (3, 3),activation='relu', padding='same',name='block5_conv3',kernel_initializer = 'he_normal')(x)\n    x=keras.layers.BatchNormalization()(x)\n    pool_5 = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n    #DECONV_BLOCK\n    #Block_1\n    unpool_1=keras.layers.UpSampling2D(size = (2,2))(pool_5)\n    conv_14= keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(unpool_1)\n    conv_15 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_14)\n    conv_16 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_15)\n    conv_16= keras.layers.BatchNormalization()(conv_16)\n    #Block_2\n    unpool_2 = keras.layers.UpSampling2D(size = (2,2))(conv_16)  \n    conv_17= keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(unpool_2)\n    conv_18 = keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_17)\n    conv_19 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_18)\n    conv_19= keras.layers.BatchNormalization()(conv_19)\n    #Block_3\n    unpool_3 =  keras.layers.UpSampling2D(size = (2,2))(conv_19)   \n    conv_20= keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(unpool_3)\n    conv_21 = keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_20)\n    conv_22 = keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_21)\n    conv_22= keras.layers.BatchNormalization()(conv_22)\n    #Block_4\n    unpool_4 = keras.layers.UpSampling2D(size = (2,2))(conv_22)  \n    conv_23= keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(unpool_4)\n    conv_24 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_23)\n    conv_24 = keras.layers.BatchNormalization()(conv_24) \n    #BLock_5\n    unpool_5 =keras.layers.UpSampling2D(size = (2,2))(conv_24) \n    conv_25= keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(unpool_5)\n    conv_26 = keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same',kernel_initializer = 'he_normal')(conv_25)\n    conv_26 = keras.layers.BatchNormalization()(conv_26)\n    #out=keras.layers.Conv2D(2,1, activation = 'sigmoid', padding = 'same',kernel_initializer = 'he_normal')(conv_26)\n    out = keras.layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(conv_26)\n    model = keras.models.Model(inputs=inputs, outputs=out, name=\"SegNet\")\n    return model","2b7bcf43":"import tensorflow as tf\nfrom tensorflow.compat.v1.keras.backend import set_session\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.metrics import MeanIoU\n\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\nconfig.log_device_placement = True\nsess = tf.compat.v1.Session(config=config)\nset_session(sess)\nmodel = segnet()\nmodel.compile(optimizer=\"rmsprop\", loss='sparse_categorical_crossentropy', metrics=[iou_coeff])\nprint(model.summary())\nmodel.fit(train_gen, validation_data=val_gen,epochs=20)\n","84b6ba68":"**Define Model**","82485f40":"**Define IoU metric**","9ea5760f":"**Compute F1 score, weed IoU and Crop IoU**","de0b076e":"**Initialize training and validation data**","bf7fff5a":"**Visualize predictions**","6f365dfc":"**Visualize image and it's corresponding mask**","2cbdedbe":"**Compute mean IoU**","ad6de284":"**Train model**","5637f970":"**Define SegNet**","9367e694":"**Augment training images with transformations**","4f63aa82":"**Load model**","cbfd063a":"**Define data loader**"}}