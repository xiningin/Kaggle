{"cell_type":{"8ab5d818":"code","da56c3b2":"code","3b5589df":"code","803904bd":"code","fb982b96":"code","67ecb892":"code","a073fb8d":"code","34b44c89":"code","0d2dcd87":"code","969fecdb":"code","29a54820":"code","d936d226":"code","5eb02951":"code","54efd401":"code","2ed5755f":"code","dc72faa1":"code","62810774":"code","6f9f8db1":"code","55428948":"code","bb985a41":"markdown"},"source":{"8ab5d818":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da56c3b2":"# define and move to dataset directory\ndatasetdir = '\/kaggle\/input\/trashnet-dataset\/dataset-resized\/'\nimport os\nos.chdir(datasetdir)","3b5589df":"# import the needed packages\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nfrom tensorflow import keras\nimport tensorflow.keras as keras\nimport numpy as np\n# shortcut to the ImageDataGenerator class\nImageDataGenerator = keras.preprocessing.image.ImageDataGenerator","803904bd":"#At first look at the Trash categories dataset\nplt.subplot(1,2,1)\nplt.imshow(img.imread('metal\/metal151.jpg'))\nplt.subplot(1,2,2)\nplt.imshow(img.imread('glass\/glass501.jpg'))","fb982b96":"#let's be more specific and print some information about our images:\nimages = []\nfor i in range(5,15):\n    im = img.imread('glass\/glass{}.jpg'.format(i))\n    images.append(im)\n    print('image shape', im.shape, 'maximum color level', im.max())","67ecb892":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nbatch_size = 30\n\ndef generators(shape, preprocessing): \n    '''Create the training and validation datasets for \n    a given image shape.\n    '''\n    imgdatagen = ImageDataGenerator(\n        preprocessing_function = preprocessing,\n        horizontal_flip = True, \n        validation_split = 0.2\n        ,\n    )\n\n    height, width = shape\n\n    train_dataset = imgdatagen.flow_from_directory(\n        os.getcwd(),\n        target_size = (height, width), \n        classes = ('cardboard','glass','metal','paper','plastic','trash'),\n        batch_size = batch_size,\n        subset = 'training', \n    )\n\n    val_dataset = imgdatagen.flow_from_directory(\n        os.getcwd(),\n        target_size = (height, width), \n        classes = ('cardboard','glass','metal','paper','plastic','trash'),\n        batch_size = batch_size,\n        subset = 'validation'\n    )\n    return train_dataset, val_dataset\n    ","a073fb8d":"def plot_history(history, yrange):\n    '''Plot loss and accuracy as a function of the epoch,\n    for the training and validation datasets.\n    '''\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    # Get number of epochs\n    epochs = range(len(acc))\n\n    # Plot training and validation accuracy per epoch\n    plt.plot(epochs, acc)\n    plt.plot(epochs, val_acc)\n    plt.title('Training and validation accuracy')\n    plt.ylim(yrange)\n    \n    # Plot training and validation loss per epoch\n    plt.figure()\n\n    plt.plot(epochs, loss)\n    plt.plot(epochs, val_loss)\n    plt.title('Training and validation loss')\n    \n    plt.show()","34b44c89":"resnet50 = keras.applications.resnet50\ntrain_dataset, val_dataset = generators((224,224), preprocessing=resnet50.preprocess_input)","0d2dcd87":"conv_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\nfor layer in conv_model.layers:\n    layer.trainable = False\nx = keras.layers.Flatten()(conv_model.output)\nx = keras.layers.Dense(100, activation='relu')(x)\nx = keras.layers.Dense(100, activation='relu')(x)\nx = keras.layers.Dense(100, activation='relu')(x)\npredictions = keras.layers.Dense(6, activation='softmax')(x)\nfull_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)\nfull_model.summary()","969fecdb":"full_model.compile(loss='categorical_crossentropy',\n                  optimizer=keras.optimizers.Adamax(lr=0.001),\n                  metrics=['acc'])\nhistory = full_model.fit_generator(\n    train_dataset, \n    validation_data = val_dataset,\n    workers=10,\n    epochs=10,\n)","29a54820":"plot_history(history, yrange=(0.5,1))","d936d226":"## Saving and loading a Keras model\nfull_model.save('\/kaggle\/working\/resnet50.h5')","5eb02951":"## Saving and loading a Keras model\nfull_model.save_weights('\/kaggle\/working\/resnet50weights.h5')","54efd401":"from keras.models import load_model\nmodel = load_model('\/kaggle\/working\/resnet50.h5')","2ed5755f":"from keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input\n\nimg_path = 'plastic\/plastic34.jpg'\nimg = image.load_img(img_path, target_size=(224,224))\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nprint(model.predict(x))\nplt.imshow(img)","dc72faa1":"def show_confusion_matrix(validations, predictions):\n\n    matrix = metrics.confusion_matrix(validations, predictions)\n    plt.figure(figsize=(6, 4))\n    sns.heatmap(matrix,\n                cmap='coolwarm',\n                linecolor='white',\n                linewidths=1,\n                xticklabels=LABELS,\n                yticklabels=LABELS,\n                annot=True,\n                fmt='d')\n    plt.title('Confusion Matrix')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.show()\n\ny_pred_test = model.predict(x_test)\n# Take the class with the highest probability from the test predictions\nmax_y_pred_test = np.argmax(y_pred_test, axis=1)\nmax_y_test = np.argmax(y_test, axis=1)\n\nshow_confusion_matrix(max_y_test, max_y_pred_test)\n\nprint(classification_report(max_y_test, max_y_pred_test))","62810774":"!pip install coremltools","6f9f8db1":"labels = list((k) for k,v in train_dataset.class_indices.items())\nlabels.sort()\ncoreml_model = coremltools.converters.tensorflow.convert(model,\n  input_names=['image'],\n  output_names=['output'],\n  image_input_names='image',\n  class_labels=labels,\n  image_scale=1\/255.0\n)\ncoreml_model.save('\/kaggle\/working\/TrashClassifier.mlmodel')","55428948":"import coremltools\nscale= 1\/255\n\noutput_labels = ['cardboard','glass','metal','paper','plastic','trash']\ncoreml_model = coremltools.converters.tensorflow.convert('\/kaggle\/working\/resnet50.h5',\n                                                   input_name_shape_dict={'input_1': (1, 224, 224, 3)},\n                                                   input_names='image',\n                                                   image_input_names='image',\n                                                   output_names='output',\n                                                   class_labels=output_labels,\n                                                   image_scale=scale)\n\ncoreml_model.author = 'fati mouhsini'\ncoreml_model.license = 'BSD'\ncoreml_model.short_description = 'Model to predict trash categories'\n\n#coreml_model.input_description['image'] = 'image of trash to predict'\n#coreml_model.output_description['output'] = 'trash type'\n\ncoreml_model.save('\/kaggle\/working\/trash-classes.mlmodel')","bb985a41":"ResetNet 50"}}