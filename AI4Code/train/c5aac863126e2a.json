{"cell_type":{"a15f7e3a":"code","3592f72a":"code","6547c2e4":"code","a005462f":"code","135f41d3":"code","3d156518":"code","c1642d26":"code","9d75152c":"code","05d84189":"code","fd4b2318":"code","93d0c47c":"code","88476137":"code","e2e36ea1":"code","73f942cd":"code","0358c217":"code","caad0384":"code","fcf02b37":"code","149fcb7e":"code","1d590bfc":"code","246dbcf3":"code","ff4e1bd7":"code","d529123c":"code","dca31be3":"code","6c364b34":"code","c5cefa40":"code","b5e83064":"code","70fceb6c":"code","62d034c5":"code","8d509b13":"code","b21aeb6d":"code","590a9366":"code","5d54570d":"code","42c35d6c":"code","cc89ab1b":"code","af633ee5":"code","0ca2ea21":"code","86b73d4a":"code","870e2523":"code","1a3a32b6":"code","397f95ec":"code","6c68b265":"code","51681233":"code","3dc9cf40":"code","0fb38e67":"code","ca756655":"code","a5937dd6":"code","29892c53":"code","5bad2ed1":"code","1d6666bc":"code","d040cf51":"code","b98ba41c":"code","2e45e5f0":"code","8ed72c8e":"code","62327ba0":"code","6214c560":"code","ee9748b2":"code","859ca42f":"code","f7016719":"code","da156114":"code","ca7c9fa3":"code","00a7a003":"markdown","00c2db1a":"markdown","9264e7c0":"markdown","7d448123":"markdown","d5d48ca5":"markdown","4cb746c2":"markdown","0dc9b332":"markdown","c351fc0c":"markdown","f338c7e4":"markdown","8ed4d187":"markdown","3ab35b5a":"markdown","6dbad803":"markdown","19ac4d25":"markdown","507c0c33":"markdown","78b67464":"markdown","c0f4f658":"markdown","fd488d1c":"markdown","a2c5b97f":"markdown","5c7a6001":"markdown","deae0de3":"markdown","12cc1fc8":"markdown","fc0c88d8":"markdown","ae4fa6e5":"markdown","076b379d":"markdown","8244ccfe":"markdown","96f07c6c":"markdown","2324d74c":"markdown","f12f6155":"markdown","957730d5":"markdown"},"source":{"a15f7e3a":"ls","3592f72a":"# !pip list\n# !conda list","6547c2e4":"import seaborn as sns\nimport pandas as pd\npd.set_option('display.max_columns', 100)\npd.set_option('display.width', 1000)\npd.set_option('display.float_format', '{:.2f}'.format)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format='retina'","a005462f":"%pip install sodapy","135f41d3":"from sodapy import Socrata\nclient = Socrata(\"data.cityofnewyork.us\", None)\nquery = \"\"\"\nselect * \nwhere\n    created_date between '2020-03-22T00:00:00.000' \n    and '2020-07-19T00:00:00.000'\nlimit 2270937 \n\"\"\" \n# random huge number set in the limit to overcome 1000 api limit\nres = client.get(\"erm2-nwe9\", query=query)\ndf = pd.DataFrame.from_records(res)\ndf.head()","3d156518":"df.head()","c1642d26":"df.info()","9d75152c":"before = df.memory_usage(deep=True).sum()\/float(1<<20)\nprint(before)\n# print ('{:,.0f}'.format(df.memory_usage().sum()\/float(1<<20))+\" MB\")","05d84189":"%%time\nfor col in [\n        'created_date', 'closed_date', 'resolution_action_updated_date','due_date']:\n    df[col] = pd.to_datetime(df[col])\n    for col in [\n            'unique_key', 'incident_zip', 'x_coordinate_state_plane',\n            'y_coordinate_state_plane', 'latitude', 'longitude','bbl']:\n        df[col] = df[col].astype('float')\n        for col in df.loc[:, ~df.columns.isin(['created_date', 'closed_date',\n                                       'resolution_action_updated_date', 'due_date',\n                                       'unique_key','incident_zip','bbl','x_coordinate_state_plane',\n                                         'y_coordinate_state_plane','latitude','longitude','location'])]:\n            df[col] = df[col].astype('string')","fd4b2318":"df.info()","93d0c47c":"after = df.memory_usage(deep=True).sum()\/float(1<<20)\nprint(after)","88476137":"round((before - after) \/ after * 100,2)","e2e36ea1":"df","73f942cd":"df.describe(datetime_is_numeric=True).T","0358c217":"df['descriptor'].value_counts()","caad0384":"df['complaint_type'].value_counts().iloc[:30]","fcf02b37":"df[df['complaint_type'].str.contains(\"Noise\")].groupby(['complaint_type']).size().sort_values(ascending=False).to_frame()","149fcb7e":"df[df['complaint_type'].str.contains(\"Noise\")].groupby('agency').agg(\n    'count')['complaint_type'].to_frame()","1d590bfc":"df[df['complaint_type'].str.contains(\"Noise\")].groupby(\n    ['complaint_type',\n     'agency']).size().sort_values(ascending=False).to_frame()","246dbcf3":"df[df['complaint_type'].str.contains(\"Noise\")].groupby(\n    ['complaint_type', 'agency',\n     'borough']).size().sort_values(ascending=False).iloc[:20].to_frame()","ff4e1bd7":"df[df['complaint_type'].str.contains(\"Noise\")].groupby([\n    'agency', 'borough', 'complaint_type'\n]).size().sort_values(ascending=False).iloc[:20].to_frame()","d529123c":"df['complaint_type'].value_counts().iloc[:10].plot(kind='barh',\n                                                   figsize=(20, 12));","dca31be3":"df.groupby(['complaint_type',\n            'borough']).size().sort_values(ascending=False).iloc[:10]\\\n.plot(kind='barh',figsize=(20,12))","6c364b34":"df[df['complaint_type'].str.contains(\"Noise\").notna()].groupby(\n    by=['latitude'])['longitude'].value_counts().sort_values(ascending=False).iloc[:10]\\\n.plot(kind='barh',figsize=(20,12))","c5cefa40":"df[df['complaint_type'].str.contains(\"Noise\")]\\\n.plot(kind='hexbin', x='longitude', y='latitude',\n      gridsize=60,sharex=False,colormap = 'jet',mincnt=1,title = 'Noise issues across NYC\\n',\n      figsize=(15,9)).axis('equal');","b5e83064":"plt.figure(figsize=(20, 15))\nsns.scatterplot(x='longitude',\n                y='latitude',\n                data=df.loc[df['complaint_type'].str.contains(\"Noise\")],\n                hue=\"agency\",\n                style='complaint_type',\n                legend='brief')\nplt.show()","70fceb6c":"sns.relplot(x='longitude', y='latitude',\n                data=df[df['complaint_type'].str.contains(\"Noise\")],\n                col=\"agency\",hue='complaint_type',style='complaint_type',kind='scatter')\nplt.figure(figsize=(20, 20));","62d034c5":"plt.figure(figsize=(20, 15))\nsns.scatterplot(x='longitude', y='latitude',\n                data=df[df['complaint_type'].str.contains(\"Noise\")],\n                hue='borough',style='complaint_type',\n                size=df[df['complaint_type'].str.contains(\"Noise\")]['agency']);","8d509b13":"import plotly.express as px\nfig = px.scatter_mapbox(df[df['complaint_type'].str.contains(\"Noise\")],\n                    lon='longitude',\n                        lat='latitude',color='complaint_type',\n                        zoom=9)\nfig.update_layout(mapbox_style=\"open-street-map\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n                  mapbox=dict(pitch=60,bearing=0))\nfig.show()","b21aeb6d":"sns.jointplot(data=df.loc[df['complaint_type'].str.contains(\"Noise\")],\n              x='longitude',\n                y='latitude', hue='complaint_type',height=15,shade=True, alpha=.5,kind=\"kde\")","590a9366":"pd.to_datetime(df.loc[df['complaint_type'].str.contains(\"Noise\")]['created_date']).dt.isocalendar().value_counts()","5d54570d":"pd.to_datetime(df.loc[df['complaint_type'].str.contains(\"Noise\")]['created_date']).dt.isocalendar().week.value_counts()","42c35d6c":"df.loc[df['complaint_type'].str.contains(\"Noise\")].\\\ngroupby(pd.to_datetime(df.loc[df['complaint_type'].str.contains(\"Noise\")]\\\n                       ['created_date']).dt.isocalendar().week).size().plot(title='The most complaints by weeks')","cc89ab1b":"df.loc[df['complaint_type'].str.contains(\"Noise\")].\\\ngroupby(pd.to_datetime(df.loc[df['complaint_type'].str.contains(\"Noise\")]\\\n                       ['created_date']).dt.isocalendar().day).size().plot(title='The most complaints by days')","af633ee5":"df.loc[df['complaint_type'].str.contains(\"Noise\")].\\\ngroupby(pd.to_datetime(df.loc[df['complaint_type'].str.contains(\"Noise\")]\\\n                       ['created_date']).dt.hour).size().plot(title='The most complaints by days hours');","0ca2ea21":"df.loc[df['complaint_type'].str.contains(\"Noise\")].\\\ngroupby(pd.to_datetime(df.loc[df['complaint_type'].str.contains(\"Noise\")]\\\n                       ['created_date']).dt.minute).size().plot(title='The most complaints by days mintues');","86b73d4a":"round(df.isnull().mean()*100,2) ","870e2523":"plt.subplots(figsize = (12,8))\nsns.heatmap(df.loc[df['complaint_type'].str.contains(\"Noise\")].isnull().sample(1000),cbar=False,\n            cmap=sns.color_palette(['g','r']));","1a3a32b6":"df_ = df.loc[(df['complaint_type'].str.contains(\"Noise\")) & (df['complaint_type'] !='Noise')]","397f95ec":"df_.head()","6c68b265":"df_[['longitude','latitude','incident_zip','bbl','complaint_type']].isnull().value_counts()","51681233":"df_ = df_[['longitude','latitude','incident_zip','bbl','complaint_type']]","3dc9cf40":"df_","0fb38e67":"df_['complaint_type'].value_counts()","ca756655":"df_ = df_.dropna()","a5937dd6":"df_.isna().sum()","29892c53":"df_.dtypes","5bad2ed1":"X = df_[['longitude','latitude','incident_zip','bbl']]\ny = df_[['complaint_type']]","1d6666bc":"X,y","d040cf51":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0,stratify=y)\n\nprint(len(df_))\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","b98ba41c":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nclf = DecisionTreeClassifier().fit(X_train,y_train)\nclf","2e45e5f0":"clf.classes_","8ed72c8e":"import graphviz\ndtree_viz = export_graphviz(clf,out_file=None,\n                            feature_names = X.columns,\n                             filled=True,class_names=['Noise - Commercial', 'Noise - Helicopter',\n       'Noise - House of Worship', 'Noise - Park', 'Noise - Residential',\n       'Noise - Street\/Sidewalk', 'Noise - Vehicle'],\n                            special_characters=True,\n                            impurity=True,proportion=True,\n                            node_ids=True,rounded=True,rotate=True,max_depth=3)\n# Draw graph\ngraph = graphviz.Source(dtree_viz)\ngraph","62327ba0":"print('Accuracy of classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))\nprint('Accuracy of classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))","6214c560":"X_test,y_test","ee9748b2":"from sklearn.metrics import plot_confusion_matrix\nfig, ax = plt.subplots(figsize=(20, 10))\nplot_confusion_matrix(clf, X_test, y_test, normalize='true', cmap=plt.cm.Blues, ax=ax,xticks_rotation='vertical')\nplt.show()","859ca42f":"Xnew_input = [[-73.863,40.89,1356.00 ,4041350020.00]]\n# make a prediction\nynew_predict = clf.predict(Xnew_input)\nprint(\"X=%s, Predicted=%s\" % (Xnew_input[0], ynew_predict[0]))","f7016719":"df_.loc[X.index.isin([-73.863,40.89,1356.00 ,4041350020.00])]","da156114":"clf.predict_proba([[-73.863,40.89,1356.00 ,4041350020.00]])","ca7c9fa3":"for i,v in enumerate(clf.feature_importances_):\n    print('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nplt.bar([x for x in range(len(clf.feature_importances_))], clf.feature_importances_);","00a7a003":"### Interactive map representation","00c2db1a":"source: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/basics.html#basics-dtypes","9264e7c0":"## Data split\n\n<img src=\"https:\/\/stanford.edu\/~shervine\/teaching\/cs-229\/illustrations\/train-val-test-en.png?0949795ac868562e193efdc249ae1066\" width=\"600px\">\n\n\n\n\nsource: https:\/\/stanford.edu\/~shervine\/teaching\/cs-229\/cheatsheet-machine-learning-tips-and-tricks\n","7d448123":"# Table of Content\n* [Intro to NYC 311 Dataset](#section-one)\n* [The coding enviroment](#section-two)\n* [Data analysis](#section-three)\n* [Data cleaning](#section-four)\n* [Creating a model to predict](#section-five)","d5d48ca5":"<a id=\"section-one\"><\/a>\n# NYC OPEN DATA PORTAL\n\n\n## ABOUT NYC 311\n\nNYC311 is free public data that\u2019s published by Government of New York City, Which made as a public in 2011\nand it aims to benefit New Yorkers by making data available to the public usage, And to create opportunities\nfor people to work with the data, such as Business Analysts, statisticians, and data scientists. . . .etc, to make\ncreative usage of the data and help government entities to support their decisions using various types of\nAnalysis. Here we would explore the dataset in the past lockdown period to see what can we find.\n\n* sources lockdown dates:\n>- https:\/\/www.investopedia.com\/historical-timeline-of-covid-19-in-new-york-city-5071986\n\n\n- Reference to the dataset can be obtained from:\n>- https:\/\/nycopendata.socrata.com\/Social-Services\/311-Service-Requests-from-2010-to-Present\/erm2-nwe9\n","4cb746c2":"## Decision tree model\n\nIn Decision Trees. All the data automatically divided to yes\/no questions. They could sound a bit weird from a human perspective, e.g., whether the creditor earns more than $128.12? Though, the machine comes up with such questions to split the data best at each step. The higher the branch \u2014 the broader the question.\n\nDecision trees are widely used in high responsibility spheres: diagnostics, medicine, and finance.\n\n\n<img src=\"https:\/\/i.vas3k.ru\/7w3.jpg\" width=\"600px\">\n\n- source: http:\/\/www.r2d3.us\/visual-intro-to-machine-learning-part-1\/","0dc9b332":"## Grouping","c351fc0c":"### Testing the classifier on an unseen set.\n\nHere we will test the model on unseen set to see how realistic are the results.\nby entering the input variables. \n\n['longitude'  'latitude'  'incident_zip'   'bbl']","f338c7e4":"## Time series analysis","8ed4d187":"<a id=\"section-five\"><\/a>\n\n# Creating a model","3ab35b5a":"# PRACTICAL PART\n\n![](https:\/\/media1.tenor.com\/images\/1e7a90f2a12b7a3b87b3972aeddb78a1\/tenor.gif?itemid=13322953)","6dbad803":"# Importing libraries","19ac4d25":"## Summary statistics","507c0c33":"## The coding environment\n\n\n![](https:\/\/www.anaconda.com\/imager\/assetsdo\/Products\/8031\/open-source-logos2x_680db6b6f11f9cc710dd7defae241cd3.png)","78b67464":"## CLASSIFICATION METRICS\n\n### CONFUSION METRICS\n\nConfusion matrix The confusion matrix is used to have a more complete picture when assessing the performance of a model. It is defined as follows:\n\n<img src=\"https:\/\/cs230.stanford.edu\/doks-theme\/assets\/images\/section\/9\/confusion.png\" width=\"600px\">\n\nwhere:\n\n\n\n- $Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$","c0f4f658":"# WHAT IS ML\n\nDEFINITON: \n\nIn 1959, Arthur Samuel defined machine learning as a \"Field of study that gives computers the ability to learn without being explicitly programmed\".\n\nA machine learning algorithm is an algorithm that is able to learn from data. But what do we mean by learning? Mitchell (1997) provides a succinct de\ufb01nition:\u201cA computer program is said to learn from experience E with respect to someclass of tasks T and performance measure P, if its performance at tasks in T, asmeasured by P, improves with experience E.\n\n\n### The diffrence between Ml and classical programming\n\n![image.png](https:\/\/www.oreilly.com\/library\/view\/deep-learning-with\/9781788624336\/assets\/27c1671a-61d3-46e1-ac66-e3dbd5683ab2.png)\n\n\n\nsource: https:\/\/www.oreilly.com\/library\/view\/deep-learning-with\/9781788624336\/a7a045c6-b0e2-437c-892d-1e61c11446bf.xhtml","fd488d1c":"# Exploratory Data Analaysis","a2c5b97f":"https:\/\/jakevdp.github.io\/blog\/2017\/12\/05\/installing-python-packages-from-jupyter\/","5c7a6001":"## Visulizations","deae0de3":"| Pandas dtype  | Python type  | NumPy type                                                     | Usage                                        |\n|---------------|--------------|----------------------------------------------------------------|----------------------------------------------|\n| object        | str or mixed | string_, unicode_, mixed types                                 | Text or mixed numeric and non-numeric values |\n| int64         | int          | int_, int8, int16, int32, int64, uint8, uint16, uint32, uint64 | Integer numbers                              |\n| float64       | float        | float_, float16, float32, float64                              | Floating point numbers                       |\n| bool          | bool         | bool_                                                          | True\/False values                            |\n| datetime64    | datetime     | datetime64[ns]                                                 | Date and time values                         |\n| timedelta[ns] | NA           | NA                                                             | Differences between two datetimes            |\n| category      | NA           | NA                                                             | Finite list of text values                   |\n","12cc1fc8":"## Generating maps","fc0c88d8":"<img src=\"https:\/\/portal.311.nyc.gov\/nyc311-logo.png\" width=\"300px\">\n\n\n\n\n\n# WELCOME !\n* The workshop will cover the NYC311 complaints geographical location across NYC city lockdown announcement, and through that, a model will be built to predict the locations that have not sent complaints yet. the outcome can assist the development of the city to overcome complaints of interest that can be predicted and grouped successfully within selected areas.\n\n","ae4fa6e5":"<a id=\"section-three\"><\/a>\n\n# Understanding datatypes.","076b379d":"<a id=\"section-four\"><\/a>\n\n# DATA CLEANING","8244ccfe":"A low standard deviation means that most of the numbers are close to the average, while a high standard deviation means that the numbers are more spread out","96f07c6c":"## Extracting dataset from api endpoint.\nThe Socrata Open Data API allows you to programmatically access a wealth of open data resources from governments, non-profits, and NGOs around the world. Click the link below and try a live example right now.\n\n- source: https:\/\/dev.socrata.com\/\n- api refrence: https:\/\/dev.socrata.com\/foundry\/data.cityofnewyork.us\/erm2-nwe9","2324d74c":"<a id=\"section-two\"><\/a>\n\n# Python data science stack\n- The enviroment: https:\/\/jupyter.org\/\n- **used libraries**\n>- pandas\n>- matplotlib\n>- seaborn\n>- plotly\n>- sodapy","f12f6155":"Here we validate the prediction by locating the crosspunding original data.","957730d5":"### KDE plot\n\nA histogram aims to approximate the underlying probability density function that generated the data by binning and counting observations. Kernel density estimation (KDE) presents a different solution to the same problem. Rather than using discrete bins, a KDE plot smooths the observations with a Gaussian kernel, producing a continuous density estimate\n\nsource: https:\/\/seaborn.pydata.org\/tutorial\/distributions.html#kernel-density-estimation\n\n"}}