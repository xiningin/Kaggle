{"cell_type":{"75e4dae0":"code","6ed9332e":"code","5c4d2b9d":"code","07d10f64":"code","39af4ae4":"code","4f61ced4":"code","e7a7437e":"code","bb9eab36":"code","4fb9352d":"code","17569559":"code","5b87d24d":"code","7bd3bced":"code","f9f7fdd8":"code","a0cd7bd2":"code","cee8fc15":"code","f0c5aed8":"code","14d0d737":"code","7f1fc49d":"code","7a78ab0c":"code","3cd2e664":"code","8e7a8e36":"code","490e4c03":"code","6cc1f7a1":"code","6bf16cdd":"code","a9c48e5d":"code","a7d89e21":"code","98a7f852":"code","90860cfa":"code","8297e277":"code","50e5ad3f":"code","eaaad9b9":"code","6c56d9ab":"code","5a7c94ba":"code","94c9de4d":"code","49964ee1":"code","b0c2e6a4":"code","3c3202fa":"code","763c8ca7":"code","c57d2093":"code","9e1ecb26":"code","765fb5c2":"markdown","c7f9360d":"markdown","661d49e5":"markdown","99376f6d":"markdown","8dc2407a":"markdown","8ed9171d":"markdown","78607ee3":"markdown","b331b823":"markdown","ae37f019":"markdown","adfd5753":"markdown","08a62fee":"markdown","8d56709d":"markdown","f94c9615":"markdown","f72701d6":"markdown","ae2e1475":"markdown","27bfc9ad":"markdown","0fab2dcb":"markdown","9cb42731":"markdown","5a9c6d7d":"markdown","b08e2c24":"markdown","82c063e8":"markdown","1e6b1334":"markdown","1b81ef07":"markdown","9d89ed74":"markdown","bdf95be1":"markdown","87ab0c92":"markdown","985d1146":"markdown","3967bf44":"markdown","e70b1f7c":"markdown","48e5b719":"markdown","2acad952":"markdown","87a26bc9":"markdown","e168469b":"markdown","1306e03d":"markdown","677c5fe2":"markdown","cbd2cd4b":"markdown","b9c432f3":"markdown","81e451fa":"markdown","b781ca6f":"markdown","770fc541":"markdown","4418119a":"markdown","2c943334":"markdown","4cf0a285":"markdown","5fed48ce":"markdown","17a1a7f3":"markdown","8c5c3f0e":"markdown","be9f8857":"markdown","ed813599":"markdown","348abfd1":"markdown","6efe25ea":"markdown","7eaa032f":"markdown","2aadc5af":"markdown","21007577":"markdown","82ff23b4":"markdown","04fc107e":"markdown","c956eec2":"markdown","5854d44b":"markdown","b32a717b":"markdown"},"source":{"75e4dae0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.decomposition import PCA\nimport keras\nfrom keras.models import Sequential  \nfrom keras.layers.core import Dense\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import roc_curve,confusion_matrix,precision_score,recall_score,classification_report\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6ed9332e":"dataset = pd.read_csv('..\/input\/Admission_Predict_Ver1.1.csv')\ndataset.head()","5c4d2b9d":"dataset.sort_values(by = 'Chance of Admit ',ascending = False).head(int(20\/100*len(dataset)))[99:]\n# 20% is 100 students according to our data.","07d10f64":"dataset['Admit'] = dataset['Chance of Admit '].apply(lambda x: 1 if x >= 0.80 else 0 )\ndataset.head() # Required Dataset","39af4ae4":"dataset.drop(['Serial No.','Chance of Admit '],axis = 1,inplace = True)\ndataset.columns = ['GRE','TOEFL','University Rating','SOP','LOR','CGPA','Research','Admit']\ndataset.head()","4f61ced4":"corr_matrix = dataset.corr()\nplt.rcParams['figure.figsize'] = 15,10\nsns.heatmap(corr_matrix,annot = True)","e7a7437e":"X = dataset.iloc[:,:-1].values\nY = dataset.iloc[:,7].values\ntrain_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size = 0.2,random_state = 27)\ntest_Y","bb9eab36":"model_logistic = LogisticRegression(random_state = 0)\nmodel_logistic.fit(train_X,train_Y)","4fb9352d":"pred_logistic = model_logistic.predict(test_X)","17569559":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_logistic))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_logistic))\n\n#Confusion Matrix\ncm_logistic = confusion_matrix(test_Y,pred_logistic)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_logistic))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_logistic[0,0] + cm_logistic[1,1])\/\n      (cm_logistic[0,0] + cm_logistic[1,1] + cm_logistic[0,1] + cm_logistic[1,0]))\n\nplt.rcParams['figure.figsize'] = 10,10\nsns.heatmap(cm_logistic,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\npred_logistic_train = model_logistic.predict(train_X)\ncm = confusion_matrix(train_Y,pred_logistic_train)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 7,7\nfpr,tpr,threshold = roc_curve(test_Y,pred_logistic)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","5b87d24d":"model_svc_linear = SVC(kernel = 'linear',random_state = 0 , C = 1)\nmodel_svc_linear.fit(train_X,train_Y)","7bd3bced":"pred_svc_linear = model_svc_linear.predict(test_X)","f9f7fdd8":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_svc_linear))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_svc_linear))\n\n#Confusion Matrix\ncm_svc_linear = confusion_matrix(test_Y,pred_svc_linear)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_svc_linear))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_svc_linear[0,0] + cm_svc_linear[1,1])\/\n      (cm_svc_linear[0,0] + cm_svc_linear[1,1] + cm_svc_linear[0,1] + cm_svc_linear[1,0]))\n\nplt.rcParams['figure.figsize'] = 10,10\nsns.heatmap(cm_svc_linear,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\n\npred_svc_linear_train = model_svc_linear.predict(train_X)\ncm = confusion_matrix(train_Y,pred_svc_linear_train)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 7,7\nfpr,tpr,threshold = roc_curve(test_Y,pred_svc_linear)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","a0cd7bd2":"model_svc_rbf = SVC(kernel = 'rbf',random_state = 0 , C = 100, gamma = 0.01)\nmodel_svc_rbf.fit(train_X,train_Y)","cee8fc15":"pred_svc_rbf = model_svc_rbf.predict(test_X)","f0c5aed8":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_svc_rbf))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_svc_rbf))\n\n#Confusion Matrix\ncm_svc_rbf = confusion_matrix(test_Y,pred_svc_rbf)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_svc_rbf))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_svc_rbf[0,0] + cm_svc_rbf[1,1])\/\n      (cm_svc_rbf[0,0] + cm_svc_rbf[1,1] + cm_svc_rbf[0,1] + cm_svc_rbf[1,0]))\n\nplt.rcParams['figure.figsize'] = 10,10\nsns.heatmap(cm,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\n\npred_svc_rbf_train = model_svc_rbf.predict(train_X)\ncm = confusion_matrix(train_Y,pred_svc_rbf_train)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 7,7\nfpr,tpr,threshold = roc_curve(test_Y,pred_svc_rbf)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","14d0d737":"model_dtree = DecisionTreeClassifier(criterion = 'entropy',random_state = 0,max_features = 5,max_depth = 11\n                                    ,min_samples_split = 5)\nmodel_dtree.fit(train_X,train_Y)","7f1fc49d":"pred_dtree = model_dtree.predict(test_X)","7a78ab0c":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_dtree))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_dtree))\n\n#Confusion Matrix\ncm_dtree = confusion_matrix(test_Y,pred_dtree)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_dtree))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_dtree[0,0] + cm_dtree[1,1])\/\n      (cm_dtree[0,0] + cm_dtree[1,1] + cm_dtree[0,1] + cm_dtree[1,0]))\n\nplt.rcParams['figure.figsize'] = 10,10\nsns.heatmap(cm_dtree,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\npred_dtree_train = model_dtree.predict(train_X)\ncm = confusion_matrix(train_Y,pred_dtree_train)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 7,7\nfpr,tpr,threshold = roc_curve(test_Y,pred_dtree)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","3cd2e664":"model_rforest = RandomForestClassifier(n_estimators = 500,random_state = 0,max_depth = 5\n                                      ,max_features = 5,min_samples_split = 10, \n                                       criterion = 'entropy')\nmodel_rforest.fit(train_X,train_Y)","8e7a8e36":"pred_rforest = model_rforest.predict(test_X)","490e4c03":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_rforest))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_rforest))\n\n#Confusion Matrix\ncm_rforest = confusion_matrix(test_Y,pred_rforest)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_rforest))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_rforest[0,0] + cm_rforest[1,1])\/\n      (cm_rforest[0,0] + cm_rforest[1,1] + cm_rforest[0,1] + cm_rforest[1,0]))\n\nplt.rcParams['figure.figsize'] = 10,10\nsns.heatmap(cm_rforest,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\npred_rforest_train = model_rforest.predict(train_X)\ncm = confusion_matrix(train_Y,pred_rforest_train)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 7,7\nfpr,tpr,threshold = roc_curve(test_Y,pred_rforest)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","6cc1f7a1":"model_nb = GaussianNB()\nmodel_nb.fit(train_X,train_Y)","6bf16cdd":"pred_nb = model_nb.predict(test_X)","a9c48e5d":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_nb))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_nb))\n\n#Confusion Matrix\ncm_nb = confusion_matrix(test_Y,pred_nb)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_nb))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_nb[0,0] + cm_nb[1,1])\/\n      (cm_nb[0,0] + cm_nb[1,1] + cm_nb[0,1] + cm_nb[1,0]))\n\nplt.rcParams['figure.figsize'] = 7,7\nsns.heatmap(cm_nb,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\npred_nb_train = model_nb.predict(train_X)\ncm = confusion_matrix(train_Y,pred_nb_train)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 10,10\nfpr,tpr,threshold = roc_curve(test_Y,pred_nb)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","a7d89e21":"model_knn = KNeighborsClassifier(n_neighbors= 5,metric = 'minkowski',p = 2)\nmodel_knn.fit(train_X,train_Y)","98a7f852":"pred_knn = model_knn.predict(test_X)","90860cfa":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_knn))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_knn))\n\n#Confusion Matrix\ncm_knn = confusion_matrix(test_Y,pred_knn)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_knn))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_knn[0,0] + cm_knn[1,1])\/\n      (cm_knn[0,0] + cm_knn[1,1] + cm_knn[0,1] + cm_knn[1,0]))\n\nplt.rcParams['figure.figsize'] = 7,7\nsns.heatmap(cm_knn,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\npred_knn_train = model_nb.predict(train_X)\ncm = confusion_matrix(train_Y,pred_knn_train)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 10,10\nfpr,tpr,threshold = roc_curve(test_Y,pred_knn)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","8297e277":"pca = PCA(n_components = None)\ntrain_X_pca = pca.fit_transform(train_X)\ntest_X_pca = pca.fit(test_X)\nexplained_variance = pca.explained_variance_ratio_","50e5ad3f":"for x in explained_variance:\n    print(round(x,2))","eaaad9b9":"pca = PCA(n_components = 2)\ntrain_X_pca = pca.fit_transform(train_X)\ntest_X_pca = pca.transform(test_X)\nmodel_pca = LogisticRegression()\nmodel_pca.fit(train_X_pca,train_Y)","6c56d9ab":"pred_pca = model_pca.predict(test_X_pca)","5a7c94ba":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_pca))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_pca))\n\n#Confusion Matrix\ncm_pca = confusion_matrix(test_Y,pred_pca)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_pca))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_pca[0,0] + cm_pca[1,1])\/\n      (cm_pca[0,0] + cm_pca[1,1] + cm_pca[0,1] + cm_pca[1,0]))\n\nplt.rcParams['figure.figsize'] = 10,10\nsns.heatmap(cm_pca,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\npred_pca_train = model_pca.predict(train_X_pca)\ncm = confusion_matrix(train_Y,pred_pca_train)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 7,7\nfpr,tpr,threshold = roc_curve(test_Y,pred_pca)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","94c9de4d":"model_ann = Sequential()\n# Input Layer and First Hidden Layer\nmodel_ann.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu',input_dim = 7))\n\n#Second Hidden Layer\nmodel_ann.add(Dense(output_dim = 6,init = 'uniform',activation = 'relu'))\n\n#Final Layer\nmodel_ann.add(Dense(output_dim = 1,init = 'uniform',activation = 'sigmoid'))\n\n#Compiling ANN\nmodel_ann.compile(optimizer = 'adam', loss = 'binary_crossentropy',metrics = ['accuracy'])\n\nmodel_ann.fit(train_X,train_Y,batch_size = 5,nb_epoch = 100)\n","49964ee1":"pred_ann = model_ann.predict(test_X)\npred_ann = (pred_ann > 0.5)","b0c2e6a4":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_ann))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_ann))\n\n#Confusion Matrix\ncm_ann = confusion_matrix(test_Y,pred_ann)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_ann))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_ann[0,0] + cm_ann[1,1])\/\n      (cm_ann[0,0] + cm_ann[1,1] + cm_ann[0,1] + cm_ann[1,0]))\n\nplt.rcParams['figure.figsize'] = 10,10\nsns.heatmap(cm_ann,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\npred_ann_train = model_ann.predict(train_X)\ncm = confusion_matrix(train_Y,pred_ann_train > 0.5)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 7,7\nfpr,tpr,threshold = roc_curve(test_Y,pred_ann)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","3c3202fa":"model_xgb = XGBClassifier(max_depth = 5,learning_rate = 0.05,n_estimators = 500,nthread = -1)\nmodel_xgb.fit(train_X,train_Y)","763c8ca7":"pred_xgb = model_xgb.predict(test_X)","c57d2093":"#Precision\nprint(\"Precision Score : \",precision_score(test_Y,pred_xgb))\n\n#Recall\nprint(\"Recall Score : \",recall_score(test_Y,pred_xgb))\n\n#Confusion Matrix\ncm_xgb = confusion_matrix(test_Y,pred_xgb)\n\n#Classification Report\nprint(\"Classification Report: \")\nprint(classification_report(test_Y,pred_xgb))\n#Accuracy\nprint(\"Accuracy for Test: \",(cm_xgb[0,0] + cm_xgb[1,1])\/\n      (cm_xgb[0,0] + cm_xgb[1,1] + cm_xgb[0,1] + cm_xgb[1,0]))\n\nplt.rcParams['figure.figsize'] = 10,10\nsns.heatmap(cm_xgb,annot = True)\nplt.title('Test Dataset')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\n\npred_xgb_train = model_xgb.predict(train_X)\ncm = confusion_matrix(train_Y,pred_xgb_train > 0.5)\nprint(\"Accuracy for Train: \",(cm[0,0] + cm[1,1])\/(cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0]))\n\n#ROC Curve\nplt.figure()\nplt.rcParams['figure.figsize'] = 7,7\nfpr,tpr,threshold = roc_curve(test_Y,pred_xgb)\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.plot(fpr, tpr, marker='.')\nplt.xlabel('FPR',fontsize = 20)\nplt.ylabel('TPR',fontsize = 20)\nplt.title('ROC Curve',fontsize = 20)\nplt.show()","9e1ecb26":"index = ['LogisticRegression','SupportVectorClassifier(Linear)','SupportVectorClassifier(Gaussian)',\n        'DecisionTree','RandomForest','PrincipalComponent','NaiveBayes','KNearestNeighbors',\n        'AritficialNeuralNetwork','XGBoost']\n\ndata = [[precision_score(test_Y,pred_logistic),recall_score(test_Y,pred_logistic),\n         (cm_logistic[0,0] + cm_logistic[1,1])\/(cm_logistic[0,0]+cm_logistic[0,1]+cm_logistic[1,0]+cm_logistic[1,1])],\n        [precision_score(test_Y,pred_svc_linear),recall_score(test_Y,pred_svc_linear),\n         (cm_svc_linear[0,0] + cm_svc_linear[1,1])\/(cm_svc_linear[0,0]+cm_svc_linear[0,1]+cm_svc_linear[1,0]+cm_svc_linear[1,1])],\n        [precision_score(test_Y,pred_svc_rbf),recall_score(test_Y,pred_svc_rbf),\n         (cm_svc_rbf[0,0] + cm_svc_rbf[1,1])\/(cm_svc_rbf[0,0]+cm_svc_rbf[0,1]+cm_svc_rbf[1,0]+cm_svc_rbf[1,1])],\n        [precision_score(test_Y,pred_dtree),recall_score(test_Y,pred_dtree),\n         (cm_dtree[0,0] + cm_dtree[1,1])\/(cm_dtree[0,0]+cm_dtree[0,1]+cm_dtree[1,0]+cm_dtree[1,1])],\n        [precision_score(test_Y,pred_rforest),recall_score(test_Y,pred_rforest),\n         (cm_rforest[0,0] + cm_rforest[1,1])\/(cm_rforest[0,0]+cm_rforest[0,1]+cm_rforest[1,0]+cm_rforest[1,1])],\n        [precision_score(test_Y,pred_pca),recall_score(test_Y,pred_pca),\n         (cm_pca[0,0] + cm_pca[1,1])\/(cm_pca[0,0]+cm_pca[0,1]+cm_pca[1,0]+cm_pca[1,1])],\n        [precision_score(test_Y,pred_nb),recall_score(test_Y,pred_nb),\n         (cm_nb[0,0] + cm_nb[1,1])\/(cm_nb[0,0]+cm_nb[0,1]+cm_nb[1,0]+cm_nb[1,1])],\n        [precision_score(test_Y,pred_knn),recall_score(test_Y,pred_knn),\n         (cm_knn[0,0] + cm_knn[1,1])\/(cm_knn[0,0]+cm_knn[0,1]+cm_knn[1,0]+cm_knn[1,1])],\n        [precision_score(test_Y,pred_ann),recall_score(test_Y,pred_ann),\n         (cm_ann[0,0] + cm_ann[1,1])\/(cm_ann[0,0]+cm_ann[0,1]+cm_ann[1,0]+cm_ann[1,1])],\n        [precision_score(test_Y,pred_xgb),recall_score(test_Y,pred_xgb),\n         (cm_xgb[0,0] + cm_xgb[1,1])\/(cm_xgb[0,0]+cm_xgb[0,1]+cm_xgb[1,0]+cm_xgb[1,1])]]\n\naccuracy = pd.DataFrame(data = data,index = index,columns = ['Precision','Recall','Accuracy'])\naccuracy.sort_values(by = ['Accuracy','Precision','Recall'],ascending = False)","765fb5c2":"Lets dive straight into it with our first classification model.","c7f9360d":"Considering the Acceptance Rate of the college is 20%. We would take the Chance of Admit at the 20th percentile as our threshold. Taking 20% because that is what i got when i looked for the college admission rate on google.","661d49e5":"### ***Training the Dataset***","99376f6d":"## **Artifical Neural Network**","8dc2407a":"## **XGBoost Classifier**","8ed9171d":"### ***Training the Dataset***\n","78607ee3":"### ***Predicting the Outcome***","b331b823":"### ***Checking for Accuracy***","ae37f019":"So we get an accuracy of around 0.91 i.e. we are able to make correct predictions 91 times out of 100.","adfd5753":"### ***Predicing the Outcome***","08a62fee":"### ***Training the Dataset***","8d56709d":"## ***Decision Tree Classification***","f94c9615":"### ***Predicting the Outcome***","f72701d6":"As we can see we have slightly improved the accuracy as compared to the Logistic Regression Model on both the testing and the training dataset.","ae2e1475":"### ***Checking for Accuracy***","27bfc9ad":"## **K Nearest Neighbors**","0fab2dcb":"### ***Predicting the Outcome***","9cb42731":"# **Classification**","5a9c6d7d":"## **Principal Component Classification**","b08e2c24":"### ***Training the Dataset***","82c063e8":"Though most of the variance is explained by first two parameters, we see that the model does not give great output on the test dataset.","1e6b1334":"Some metrics we will look at to check the accuracy.\n1. Precision = TP \/(TP + FP)\n2. Recall = TP\/(TP + FN)\n3. Classification Report. Tells us about the Precision, Recall and F1 score.\n3. Confusion Matrix\n4. Accuracy of correct prediction = (TP  + TN)\/(TP + FP + TN + FN)\n5. ROC Curve","1b81ef07":"### ***Checking for Accuracy***","9d89ed74":"## ***Support Vector Classification - Gaussian Kernel***","bdf95be1":"### ***Checking for Accuracy***","87ab0c92":"Find the Exploratory Analysis and the Regression approach of this dataset [here](https:\/\/www.kaggle.com\/kenil020\/graduate-admission-eda-and-regression\/notebook)\n.Now we will look at the Classification approach to the dataset.","985d1146":"Preparing the dataset i.e. Converting the continuous variable Chance of Admit into a discrete variable.","3967bf44":"### ***Predicting the Outcome***","e70b1f7c":"### ***Checking the Accuracy***","48e5b719":"### ***Checking for Accuracy***","2acad952":"So lets say we take our threshold as 0.80 for the dataset.","87a26bc9":"### ***Training the Dataset***","e168469b":"As you can see we have almost narrowed it down on the 100% accuracy for the dataset.","1306e03d":"### ***Training the Dataset***","677c5fe2":"Before that we would look at the correlation matrix","cbd2cd4b":"Let us now split the dataset into train and test for our Classification models.","b9c432f3":"### ***Training the Dataset***","81e451fa":"### ***Checking for Accuracy***","b781ca6f":"This sums up all the model that i wanted to train. Now lets look at thei performance\n","770fc541":"### ***Checking for Accuracy***","4418119a":"As we can the variance explained by the first two components is enough and the other components can be ignored. Now using this components to create the new logistic regression model","2c943334":"### ***Checking for Accuracy***","4cf0a285":"### ***Predicting the Outcome***","5fed48ce":"### ***Predicting the Outcome***","17a1a7f3":"## **Logistic Regression**","8c5c3f0e":"### ***Checking the Accuracy***","be9f8857":"### ***Training the model***","ed813599":"### ***Training the Dataset***","348abfd1":"### ***Predicting the Outcomes***","6efe25ea":"### ***Predicting the Outcome***","7eaa032f":"## **Random Forest Classification**","2aadc5af":"### ***Training the Model***","21007577":"## ***Support Vector Classification - Linear Kernel***","82ff23b4":"## **Naive Bayes Classifier**","04fc107e":"We can see that the Accuracy for train and test are nearby, but the difference might suggest that we are overfitting the dataset.","c956eec2":"### ***Finding the Principal Component***","5854d44b":"### ***Predicting the Outcome***","b32a717b":"Let us now remove the columns that are not required and then rename few columns"}}