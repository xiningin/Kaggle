{"cell_type":{"dcb868dc":"code","4675b216":"code","c70f528a":"code","743b4c5d":"code","897dde1f":"code","d893ce0b":"code","86f4a41f":"code","31bcf69c":"code","b1c6dda5":"code","31b03df0":"code","bc95366f":"code","174b932f":"code","b31324a0":"markdown","c478bef1":"markdown"},"source":{"dcb868dc":"# No.1\n# \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\nimport pandas as pd\nimport pandas_profiling\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Jupyter Notebook\u306e\u4e2d\u3067\u30a4\u30f3\u30e9\u30a4\u30f3\u8868\u793a\u3059\u308b\u5834\u5408\u306e\u8a2d\u5b9a\uff08\u3053\u308c\u304c\u7121\u3044\u3068\u5225\u30a6\u30a3\u30f3\u30c9\u30a6\u3067\u30b0\u30e9\u30d5\u304c\u958b\u304f\uff09\n%matplotlib inline\n\n# \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n","4675b216":"#\u3000No.6\n# \u6587\u5b57\u5217\u3092\u30e9\u30d9\u30eb\u5316\u3057\u305f\u6570\u5024\u306b\u5909\u63db\u3059\u308b\u70ba\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\nfrom sklearn.preprocessing import LabelEncoder\n\n# \u30c7\u30fc\u30bf\u30bf\u30a4\u30d7\u304cobject\u306e\u5217\u306e\u5024\u3092\u30e9\u30d9\u30eb\u5316\u3057\u305f\u6570\u5024\u306b\u5909\u63db\nfor i in range(train.shape[1]):\n    if train.iloc[:,i].dtypes == object:\n        lbl = LabelEncoder()\n        lbl.fit(list(train.iloc[:,i].values) + list(test.iloc[:,i].values))\n        train.iloc[:,i] = lbl.transform(list(train.iloc[:,i].values))\n        test.iloc[:,i] = lbl.transform(list(test.iloc[:,i].values))","c70f528a":"# No.10\n# keep ID for submission\ntrain_ID = train['Id']\ntest_ID = test['Id']\n\n# split data for training\ny_train = train['SalePrice']\nX_train = train.drop(['Id','SalePrice'], axis=1)\nX_test = test.drop('Id', axis=1)\n\n# dealing with missing data\nXmat = pd.concat([X_train, X_test])\n# \u6b20\u640d\u5024\u306e\u591a\u3044\u30ab\u30e9\u30e0\u3092\u524a\u9664\nXmat = Xmat.drop(['LotFrontage','MasVnrArea','GarageYrBlt'], axis=1)\n# \u6b20\u640d\u5024\u306e\u5c11\u306a\u3044\u30ab\u30e9\u30e0\u306eNaN\u306f\u4e2d\u592e\u5024(median)\u3067\u57cb\u3081\u308b\nXmat = Xmat.fillna(Xmat.median())\n\n# check whether there are still nan\nXmat_nan = Xmat.isnull().sum()\nXmat_nan = Xmat_nan[Xmat_nan > 0]\nXmat_nan","743b4c5d":"# No.11\nXmat[\"TotalSF\"] = Xmat[\"TotalBsmtSF\"] + Xmat[\"1stFlrSF\"] + Xmat[\"2ndFlrSF\"]","897dde1f":"# No.15\n# \u5bfe\u6570\u8a08\u7b97\u3092\u5b9f\u65bd\n# \u6570\u5b57\u306e\u3070\u3089\u3064\u304d\u3001\u504f\u308a\u3092\u5c0f\u3055\u304f\u3059\u308b\ny_train = np.log(y_train)\n\nsns.distplot(y_train)\nplt.show()","d893ce0b":"# No.16\n# train\u30c7\u30fc\u30bf\u3068test\u30c7\u30fc\u30bf\u3092\u542b\u3093\u3067\u3044\u308bXmat\u3092\u3001\u518d\u5ea6train\u30c7\u30fc\u30bf\u3068test\u30c7\u30fc\u30bf\u306b\u5206\u5272\nX_train = Xmat.iloc[:train.shape[0],:]\nX_test = Xmat.iloc[train.shape[0]:,:]\n\n# \u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators=80, max_features='auto')\nrf.fit(X_train, y_train)\nprint(\"Training done using Random Forest\")\n\n# np.argsort()\u306f\u30bd\u30fc\u30c8\u7d50\u679c\u306e\u914d\u5217\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u8fd4\u3059\u3002\u5f15\u6570\u306e\u982d\u306b\"-\"\u3092\u3064\u3051\u308b\u3068\u964d\u9806\u3002\n# \u3064\u307e\u308a\"-rf.feature_importances_\"\u3092\u5f15\u6570\u306b\u3059\u308b\u4e8b\u3067\u91cd\u8981\u5ea6\u306e\u9ad8\u3044\u9806\u306b\u30bd\u30fc\u30c8\u3057\u305f\u914d\u5217\u306e\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u8fd4\u3059\u3002\nranking = np.argsort(-rf.feature_importances_)\nf, ax = plt.subplots(figsize=(11, 9))\nsns.barplot(x=rf.feature_importances_[ranking], y=X_train.columns.values[ranking], orient='h')\nax.set_xlabel(\"feature importance\")\nplt.tight_layout()\nplt.show()","86f4a41f":"# No.17\n# use the top 30 features only\nX_train = X_train.iloc[:,ranking[:30]]\nX_test = X_test.iloc[:,ranking[:30]]\n\n# interaction between the top 2\nX_train[\"Interaction\"] = X_train[\"TotalSF\"] * X_train[\"OverallQual\"]\nX_test[\"Interaction\"] = X_test[\"TotalSF\"] * X_test[\"OverallQual\"]","31bcf69c":"# No.18\n# z-score\u306b\u3066\u6a19\u6e96\u5316\n# (\u5024 - \u5e73\u5747) \/ \u6a19\u6e96\u504f\u5dee\nX_train = (X_train - X_train.mean()) \/ X_train.std()\nX_test = (X_test - X_test.mean()) \/ X_test.std()","b1c6dda5":"# No.19\n# relation to the target\nfig = plt.figure(figsize=(12,7))\nfor i in np.arange(30):\n    ax = fig.add_subplot(5,6,i+1)\n    sns.regplot(x=X_train.iloc[:,i], y=y_train)\n\nplt.tight_layout()\nplt.show()","31b03df0":"# No.20\n# outlier deletion\nXmat = X_train\nXmat['SalePrice'] = y_train\nXmat = Xmat.drop(index = Xmat[(Xmat['TotalSF'] > 5) & (Xmat['SalePrice'] < 12.5)].index)\nXmat = Xmat.drop(index = Xmat[(Xmat['GrLivArea'] > 5) & (Xmat['SalePrice'] < 13)].index)\n\n# recover\ny_train = Xmat['SalePrice']\nX_train = Xmat.drop(['SalePrice'], axis=1)","bc95366f":"intergrate_result = pd.DataFrame(index = [x for x in test.index], columns = ['liner', 'lasso', 'ridge', 'xgb', 'EN', 'LGB'])\ntrain_result = pd.DataFrame(index = [x for x in X_train.index], columns = ['liner', 'lasso', 'ridge', 'xgb', 'EN', 'LGB'])\n# \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306b\u7dda\u5f62\u56de\u5e30(Linear Regression)\u3092\u63a1\u7528\nslr = LinearRegression()\n\n# fit\u95a2\u6570\u3067\u5b66\u7fd2\u958b\u59cb\nslr.fit(X_train,y_train)\ntrain_result['liner'] = np.exp(slr.predict(X_train))\nintergrate_result['liner'] = np.exp(slr.predict(X_test))\nsubmission = np.exp(slr.predict(X_test))","174b932f":"sub = pd.DataFrame()\nsub['Id'] = test_ID\nsub['SalePrice'] = submission\nsub.to_csv('submission.csv',index=False)","b31324a0":"## \u5bfe\u6570\u8a08\u7b97\u3068\u306f\n\u4f55\u4e57\u3059\u308c\u3070\u3088\u3044\u304b\u3092\u6c42\u3081\u308b\u8a08\u7b97\n\n### e.g.\nlog10(100) = 10\u3092\u4f55\u4e57\u3059\u308c\u3070100\u306b\u306a\u308b\u304b\uff1f = 2\n\n### \u4eca\u56de\u306e\u8a08\u7b97\nlog(y_train) = log np.e(y_train)\n\n\u203bnp.e=2.718281828459045(Numpy\u306e\u5b9a\u6570\u3068\u3057\u3066\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b)\n\nlog2.718281828459045(755000) = 13.534473\n\nlog2.718281828459045(140000) = 11.849398","c478bef1":"# \u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3067\u7279\u5fb4\u91cf\u306e\u91cd\u8981\u5ea6\u306b\u30a2\u30af\u30bb\u30b9\n\u76f8\u95a2\u4fc2\u6570\u3067Feature\u306e\u91cd\u8981\u5ea6\u3092\u5224\u65ad\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u6a5f\u68b0\u5b66\u7fd2\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3067\u3042\u308b\u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\u3067Feature\u306e\u91cd\u8981\u5ea6\u3092\u5224\u65ad\u3002"}}