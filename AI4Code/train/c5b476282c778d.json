{"cell_type":{"031f38a0":"code","ea3243be":"code","93b9333f":"code","a6a805d7":"code","6af9e935":"code","1cbe7133":"code","5da7fa19":"code","aa223348":"code","9067b0d1":"code","8c7fa6a8":"code","22f5914b":"code","4f1adc53":"code","43bd4bcc":"code","52aa76bb":"code","52c1d28b":"code","8ac10f7e":"code","96ee7d6d":"code","b9b37940":"code","3deee160":"code","544fc60d":"code","f8ecc6f0":"code","d6cca7dd":"code","b989c933":"code","798697b9":"code","ffbe540a":"code","12b04284":"code","4435e41c":"code","d4b54369":"code","8d4a52aa":"code","e77b10d0":"code","1c14235e":"code","26eb0e55":"code","b6c5b39f":"code","56b98c75":"code","16dde6d4":"code","957eef78":"code","39a5d9fe":"code","ad230f41":"code","71eb9ebd":"code","6c450c7b":"markdown","cdf775e5":"markdown","2fff20a0":"markdown","4a884bc0":"markdown","968d9f56":"markdown","5eb6d613":"markdown","2b5e5633":"markdown","25391806":"markdown","922c49c9":"markdown","af70e1cf":"markdown","62c90bbf":"markdown","88072f64":"markdown","f7e5312b":"markdown","956209e1":"markdown","de55187e":"markdown","7c0c5386":"markdown","d19d2247":"markdown","0a9dece0":"markdown","1dd8da75":"markdown","f721ba39":"markdown","850b8d21":"markdown","4ed296e8":"markdown","078f8170":"markdown","c52b4597":"markdown","f4278c94":"markdown","03588ed2":"markdown","f2bc6d73":"markdown","38a01fb8":"markdown","23983345":"markdown","c6adccdf":"markdown","79b856b6":"markdown"},"source":{"031f38a0":"# installlation required\n!pip install Lifetimes\n!pip install openpyxl\n# libraries\nfrom sqlalchemy import create_engine\nimport datetime as dt\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom lifetimes import BetaGeoFitter\nfrom lifetimes import GammaGammaFitter\nfrom lifetimes.plotting import plot_period_transactions\nfrom sklearn.preprocessing import MinMaxScaler\nimport squarify  # treemap \nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ea3243be":"\ndf_2010_2011 = pd.read_excel(\"..\/input\/online-retail-ii-data-set-from-ml-repository\/online_retail_II.xlsx\", sheet_name = \"Year 2010-2011\")\n\n#online_retail = pd.read_csv(\"\/kaggle\/input\/online-retail-ii-data-set-from-ml-repository\/Year 2010-2011.csv\", sep=\";\")\ndf = df_2010_2011.copy()\ndf.head()","93b9333f":"# We deal with purchases in our analysis. Therefore, we have excluded returns from the data.\ndf = df[~df[\"Invoice\"].str.contains(\"C\", na=False)]\ndf.shape","a6a805d7":"def check_df(dataframe):\n    print(\"################ Shape ####################\")\n    print(dataframe.shape)\n    print(\"############### Columns ###################\")\n    print(dataframe.columns)\n    print(\"############### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"############### Head ######################\")\n    print(dataframe.head())\n    print(\"############### Tail ######################\")\n    print(dataframe.tail())\n    print(\"############### Describe ###################\")\n    print(dataframe.describe().T)\n\ncheck_df(df)","6af9e935":"df.isnull().sum()","1cbe7133":"df.dropna(inplace=True)\ndf.isnull().sum()","5da7fa19":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\nreplace_with_thresholds(df, \"Quantity\")\nreplace_with_thresholds(df, \"Price\")","aa223348":"cat_cols = [col for col in df.columns if df[col].dtypes ==\"O\"]\ncat_but_car = [col for col in df.columns if df[col].nunique() > 100 and df[col].dtypes == \"O\"]\ncat_cols = [col for col in cat_cols if col not in cat_but_car]\ncat_cols","9067b0d1":"def cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\")\n    if plot:\n        fig_dims = (15, 5)\n        fig, ax = plt.subplots(figsize=fig_dims)\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.xticks(rotation = 45, ha = 'right')\n        plt.show()\n\ncat_summary(df, \"Country\", plot=True)","8c7fa6a8":"num_cols = [col for col in df.columns if df[col].dtypes != 'O' and col not in \"Customer ID\"]\nnum_cols","22f5914b":"def num_summary(dataframe, numerical_col, plot=False):\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n\n    if plot:\n        dataframe[numerical_col].hist(bins=20)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.show()\n\nfor col in num_cols:\n    num_summary(df, col, plot=True)","4f1adc53":"# unique product\ndf[\"StockCode\"].nunique()","43bd4bcc":"# How many sales for each product?\ndf_product = df.groupby(\"Description\").agg({\"Quantity\":\"count\"})\ndf_product.reset_index(inplace=True)\ndf_product","52aa76bb":"# Top 10 Products\ntop_pr= df_product.sort_values(by=\"Quantity\",ascending=False).head(10)\n\nsns.barplot(x=\"Description\", y=\"Quantity\", data=top_pr)\nplt.xticks(rotation=90)\nplt.show()","52c1d28b":"# total price per invoice\ndf[\"TotalPrice\"] = df[\"Price\"] * df[\"Quantity\"]","8ac10f7e":"# Determining the analysis date for the recency\ndf[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\ndf[\"InvoiceDate\"].max()\ntoday_date = dt.datetime(2011, 12, 11)","96ee7d6d":"# Generating RFM metrics\nrfm = df.groupby(\"Customer ID\").agg({\"InvoiceDate\": lambda Inv\u0131iceDate: (today_date- Inv\u0131iceDate.max()).days,\n                                    \"Invoice\": lambda Invoice: Invoice.nunique(),\n                                    \"TotalPrice\": lambda TotalPrice: TotalPrice.sum()})\n\nrfm.columns = [\"recency\",\"frequency\",\"monetary\"]\nrfm.describe().T","b9b37940":"# monetary, the min value of the total money paid can't be 0\n# let's remove them from the data\n\nrfm = rfm[rfm[\"monetary\"] > 0]\nrfm.describe().T","3deee160":"# recency_score\nrfm[\"recency_score\"] = pd.qcut(rfm['recency'], 5, labels=[5, 4, 3, 2, 1])\n# frequency_score\nrfm[\"frequency_score\"] = pd.qcut(rfm[\"frequency\"].rank(method=\"first\"), 5, labels=[1, 2, 3, 4, 5])\n# monetary_score\nrfm[\"monetary_score\"] = pd.qcut(rfm[\"monetary\"], 5, labels=[1, 2, 3, 4, 5])\n\n#  RFM Score\nrfm[\"RFM_SCORE\"] = (rfm[\"recency_score\"].astype(str) + rfm[\"frequency_score\"].astype(str))\nrfm.head(10)","544fc60d":"seg_map = {\n    r'[1-2][1-2]': 'hibernating',\n    r'[1-2][3-4]': 'at_Risk',\n    r'[1-2]5': 'cant_loose',\n    r'3[1-2]': 'about_to_sleep',\n    r'33': 'need_attention',\n    r'[3-4][4-5]': 'loyal_customers',\n    r'41': 'promising',\n    r'51': 'new_customers',\n    r'[4-5][2-3]': 'potential_loyalists',\n    r'5[4-5]': 'champions'\n}\nrfm['segment'] = rfm['RFM_SCORE'].replace(seg_map, regex=True)\nrfm.head(10)","f8ecc6f0":"# Let's group RFM mean and frequency values according to segments\nrfm[[\"segment\", \"recency\", \"frequency\", \"monetary\"]].groupby(\"segment\").agg([\"mean\", \"count\"])","d6cca7dd":"sgm= rfm[\"segment\"].value_counts()\nplt.figure(figsize=(10,7))\nsns.barplot(x=sgm.index,y=sgm.values)\nplt.xticks(rotation=45)\nplt.title('Customer Segments',color = 'blue',fontsize=15)\nplt.show()","b989c933":"# Treemap Visualization\ndf_treemap = rfm.groupby('segment').agg('count').reset_index()\ndf_treemap.head()","798697b9":"fig, ax = plt.subplots(1, figsize = (10,10))\n\nsquarify.plot(sizes=df_treemap['RFM_SCORE'], \n              label=df_treemap['segment'], \n              alpha=.8,\n              color=['tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray']\n             )\nplt.axis('off')\nplt.show()\n#plt.savefig('treemap.png')","ffbe540a":"# Determining the analysis date for the recency\ndf[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])\ndf[\"InvoiceDate\"].max()\ntoday_date = dt.datetime(2011, 12, 11)","12b04284":"cltv_df = df.groupby('Customer ID').agg({'InvoiceDate': [lambda date: (date.max() - date.min()).days,\n                                                         lambda date: (today_date - date.min()).days],\n                                         'Invoice': lambda num: num.nunique(),\n                                         'TotalPrice': lambda TotalPrice: TotalPrice.sum()})\n\n\ncltv_df.columns = cltv_df.columns.droplevel(0)\ncltv_df.columns = ['recency', 'T', 'frequency', 'monetary']\ncltv_df.head()","4435e41c":"# monetary de\u011ferini toplam totalPrice olarak hesaplam\u0131\u015ft\u0131k.\n# bu a\u015famada moneary de\u011ferini sat\u0131n alma ba\u015f\u0131na ortalama kazan\u00e7 olarak ifade edece\u011fiz\ncltv_df[\"monetary\"] = cltv_df[\"monetary\"] \/ cltv_df[\"frequency\"]\n\n# monetary nin s\u0131f\u0131rdan b\u00fcy\u00fck olanlar\u0131n\u0131n se\u00e7elimesi\ncltv_df = cltv_df[cltv_df[\"monetary\"] > 0]\n\n# BGNBD i\u00e7in recency ve T'nin haftal\u0131k cinsten ifade edilmesi\ncltv_df[\"recency\"] = cltv_df[\"recency\"] \/ 7\ncltv_df[\"T\"] = cltv_df[\"T\"] \/ 7\n\n# frequency nin 1 den b\u00fcy\u00fck olanlar\u0131n\u0131n se\u00e7ilmesi\ncltv_df = cltv_df[(cltv_df['frequency'] > 1)]\ncltv_df.head()","d4b54369":"bgf = BetaGeoFitter(penalizer_coef=0.001)\nbgf.fit(cltv_df['frequency'],\n        cltv_df['recency'],\n        cltv_df['T'])","8d4a52aa":"# 1 week expected purchase (transaction)\ncltv_df[\"expected_purc_1_week\"] = bgf.predict(1,\n                                               cltv_df['frequency'],\n                                               cltv_df['recency'],\n                                               cltv_df['T'])\n\ncltv_df.sort_values(\"expected_purc_1_week\", ascending=False).head(10)","e77b10d0":"# 1 month expected purchase\ncltv_df[\"expected_purc_1_month\"] = bgf.predict(4,\n                                               cltv_df['frequency'],\n                                               cltv_df['recency'],\n                                               cltv_df['T'])\n\ncltv_df.sort_values(\"expected_purc_1_month\", ascending=False).head(10)","1c14235e":"ggf = GammaGammaFitter(penalizer_coef=0.01)\nggf.fit(cltv_df['frequency'], cltv_df['monetary'])","26eb0e55":"cltv_df[\"expected_average_profit\"] = ggf.conditional_expected_average_profit(cltv_df['frequency'],\n                                                                             cltv_df['monetary'])\n\ncltv_df.sort_values(\"expected_average_profit\", ascending=False).head(20)","b6c5b39f":"cltv = ggf.customer_lifetime_value(bgf,\n                                   cltv_df['frequency'],\n                                   cltv_df['recency'],\n                                   cltv_df['T'],\n                                   cltv_df['monetary'],\n                                   time=6,  # 6 ayl\u0131k\n                                   freq=\"W\",  # T'nin frekans bilgisi.\n                                   discount_rate=0.01)","56b98c75":"# Reset index\ncltv = cltv.reset_index()\n# Merging the main table and the forecast values table\ncltv_final = cltv_df.merge(cltv, on=\"Customer ID\", how=\"left\")\n# sorting\ncltv_final.sort_values(by=\"clv\", ascending=False).head(10)","16dde6d4":"# 1 Month CLTV:\ncltv_1 = ggf.customer_lifetime_value(bgf,\n                                   cltv_df['frequency'],\n                                   cltv_df['recency'],\n                                   cltv_df['T'],\n                                   cltv_df['monetary'],\n                                   time=1,  # 1 month\n                                   freq=\"W\",  # frequency of T\n                                   discount_rate=0.01)\n\ncltv_1.head()\ncltv_1= cltv_1.reset_index()\ncltv_1 = cltv_df.merge(cltv_1, on=\"Customer ID\", how=\"left\")\ncltv_1.sort_values(by=\"clv\", ascending=False).head(10)","957eef78":"# 12 Month CLTV Forecast:\n\ncltv_12 = ggf.customer_lifetime_value(bgf,\n                                   cltv_df['frequency'],\n                                   cltv_df['recency'],\n                                   cltv_df['T'],\n                                   cltv_df['monetary'],\n                                   time=12,  # 1 ayl\u0131k\n                                   freq=\"W\",  # T'nin frekans bilgisi\n                                   discount_rate=0.01)\n\ncltv_12.head()\ncltv_12 = cltv_12.reset_index()\ncltv_12 = cltv_df.merge(cltv_12, on=\"Customer ID\", how=\"left\")\ncltv_12.sort_values(by=\"clv\", ascending=False).head(10)","39a5d9fe":"# Normalization 0-1 Range For CLV Values\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(cltv_final[[\"clv\"]])\ncltv_final[\"scaled_clv\"] = scaler.transform(cltv_final[[\"clv\"]])\n\ncltv_final.sort_values(by=\"scaled_clv\", ascending=False).head()","ad230f41":"# Segmentation of Customers\ncltv_final[\"segment\"] = pd.qcut(cltv_final[\"scaled_clv\"], 4, labels=[\"D\", \"C\", \"B\", \"A\"])\ncltv_final.head()\n\ncltv_final.head()","71eb9ebd":"# Examination of Segments\ncltv_final.groupby(\"segment\").agg({\"count\", \"mean\", \"sum\"})","6c450c7b":"<a id = \"3\"><\/a><br>\n# Cohort Analysis\nCohort analysis is a type of behavioral analytics that separates the data in a data set into comparable groups before analysis. These units, or cohorts, are usually characterized by similar qualities or events over a specific timespan. \n\nAnalysis of a customer's (or user's) behavior across the lifecycle might reveal important trends. By breaking down customers into smaller groups, you can better see patterns throughout each customer's life cycle rather than just looking at all clients uniformly without regard for the natural cycle that a client goes through.\n\n**Cohort:** A group of people with common characteristics.\n\n**Cohort Analysis:** It is the analysis of the behavior of a group of people with common characteristics.\n\n**Note:** Chort analysis and KPI Analysis is not the place for Python. Power Bl, Data Studio, Tableu, Clickview are their places. This is not the job of a data scientist. It is the job of the business analyst, it is the job of the crm analyst.","cdf775e5":"<a id = \"15\"><\/a><br>\n# Preparation of RFM Metrics\n* **recency:** the difference between today and the customer's last purchase date, in days\n* **frequency:** customer's shopping frequency\n* **monetary:** total money paid by the customer","2fff20a0":"<a id = \"12\"><\/a><br>\n## Categorical Variables","4a884bc0":"<a id = \"6\"><\/a><br>\n## Variables\n* **InvoiceNo**: Invoice number. The unique number of each transaction, namely the invoice. Aborted operation if it starts with C.\n* **StockCode**: Product code. Unique number for each product.\n* **Description**: Product name\n* **Quantity**: Number of products. It expresses how many of the products on the invoices have been sold.\n* **InvoiceDate**: Invoice date and time.\n* **UnitPrice**: Product price (in GBP)\n* **CustomerID**: Unique customer number\n* **Country**: The country where the customer lives.","968d9f56":"<a id = \"7\"><\/a><br>\n# LIBRARIES","5eb6d613":"<a id = \"14\"><\/a><br>\n# Customer Segmentation With RFM\n## WHAT IS RFM?\n\nThe RFM method is a tool for assessing consumer value. It's frequently utilized in database marketing and direct marketing, as well as retail and professional services.\n\nRFM stands for the three dimensions:\n\n* **Recency:** How recently did the customer purchase?\n* **Frequency:** How often do they purchase?\n* **Monetary Value:** How much do they spend?\n","2b5e5633":"<a id = \"9\"><\/a><br>\n## Data Preprocessing","25391806":"<a id = \"16\"><\/a><br>\n## Generating RFM Scores","922c49c9":"* E refers to the expected value\n* | refers to that this probability is conditional (conditional expected number of transactions)\n* x refers to frequency for each customer who purchased at least 2 times.\n* tx refers to recency for each customer. In this case, we will assume the recency will be based on weeks. The time from the last purchasing date to the first purchasing date (weeks).\n* T refers to the time from today\u2019s date to the last purchasing date (weeks).\n* r,\u03b1 comes from the gamma distribution (buy process). Transaction rate of the mass.\n* a,b comes from the beta distribution (till you die process). The dropout rate of the mass.\n* Y(t) refers to the expected number of transactions for each customer.","af70e1cf":"### Formula\n$E(M|p, q, \\gamma, m_x, x) = \n\\frac{(\\gamma + m_xx)p}{px + q -1} = \n\\left( \\frac {q-1}{px + q - 1} \\right) \n\\frac{\\gamma p}{q - 1} + \\left( \\frac{px}{px + q -1} \\right)\nm_x$","62c90bbf":"An e-commerce company wants to segment its customers and determine marketing strategies according to these segments. For example, it is desired to organize different campaigns for new customers and different campaigns in order to retain customers that are very profitable for the company.","88072f64":"<a id = \"8\"><\/a><br>\n# Load and Check Data\nWe've copied the path from the output above. ","f7e5312b":"<a id = \"4\"><\/a><br>\n# Business Problem\n","956209e1":"<a id = \"20\"><\/a><br>\n## Preparation-Data Structure of CLTV\n* **recency**: the difference between the customer's last purchase and his first purchase\n* **T**: the age of the client in the company\n* **frequency**: total number of repeat purchases\n* **monetary_value**: average earnings per purchase","de55187e":"<a id = \"23\"><\/a><br>\n## BG-NBD and GG Model For Prediction","7c0c5386":"<a id = \"10\"><\/a><br>\n## Outlier Observations","d19d2247":"<a id = \"21\"><\/a><br>\n# BG-NBD Model\n\nBG \/ NBD (Beta Geometric \/ Negative Binominal Distribution) = Expected Number of Transaction\n\n### Buy Till You Die\n\nThe BG\/NBD Model probabilistically models two processes for the Expected Number of Transaction.\n> Transaction Process (Buy) + Dropout Process (Till You Die)\n\n#### Transaction Process (Buy)\n* As long as it is alive, the number of transactions to be performed by a client in a given time period is poisson distributed with the transaction rate parameter.\n* As long as a customer is alive, they will continue to make random purchases around their transaction rate.\n* Transaction rates vary according to each customer. They are **gamma dispersed** for the entire audience (r, a).\n\n\nSo the buy process of the BG\/NBD model indicates; I am modeling the purchasing activity of the whole audience with the gamma distribution. \n\n#### Dropout Process (Till You Die)\n* Each customer has a dropout rate (dropout probability) with probability p.\n* A customer drops with a certain probability after making a purchase. This is not a full churn, it may return after a certain time.\n* Dropout rates vary for each client and **beta is distributed** for the entire audience (a, b).","0a9dece0":"<a id = \"11\"><\/a><br>\n# Exploratory Data Analysis","1dd8da75":"<a id = \"25\"><\/a><br>\n# References\n* https:\/\/github.com\/mvahit\n* https:\/\/www.veribilimiokulu.com\/\n* https:\/\/www.linkedin.com\/in\/vahitkeskin\/\n* https:\/\/github.com\/mathchi\n* https:\/\/www.kaggle.com\/haticeebraralc\/crm-analytics\n* https:\/\/github.com\/hebraralici\n* https:\/\/en.wikipedia.org\/wiki\/Customer_lifetime_value\n* https:\/\/en.wikipedia.org\/wiki\/RFM_(market_research)\n* https:\/\/mebaysan.medium.com\/customer-life-time-value-prediction-by-using-bg-nbd-gamma-gamma-models-and-applied-example-in-997a5ee481ad","f721ba39":"<a id = \"17\"><\/a><br>\n# Segmenting Customers Based on RFM Scores\n","850b8d21":"<a id = \"13\"><\/a><br>\n## Numerical Variables","4ed296e8":"<a id = \"18\"><\/a><br>\n# Visualization of RFM Segments","078f8170":"<a id = \"22\"><\/a><br>\n# Gamma Gamma Model\nIt is used to estimate how much profit a customer can generate on average per transaction.\n\n****What will the gamma gamma model do? ****\n\nIt will output the Expected Average Profit. This means; The Expected Average Profit distribution will be modeled over the whole audience, and the Gamma Gamma Submodel will be conditionally giving us the Expected Average Profit for a person, taking into account the distribution of the whole audience, according to the characteristics of the person himself.","c52b4597":"# Introduction\nCustomer Relationship Management (CRM) system is an information management and analysis tool that can help businesses and other organizations manage their interactions with customers. \n\nCRMs were originally designed to target large corporations, but the internet has allowed small business owners to take advantage of these tools as well. Customer data is collected in a CRM database, which allows for advanced analysis such as customer segmentation and contact history. \n\nIn this notebook, we will be explaining how you can apply your customer relationship management system to analyze your customer base in order to increase revenue through better marketing campaigns!\n\n<font color = 'blue'>\nContent: \n\n1. [CRM - Customer Relationship Management](#1)\n1. [Key Performance Indicators](#2)\n1. [Cohort Analysis](#3)\n1. [Business Problem](#4)\n    * [Dataset Story](#5)\n    * [Variables](#6)\n1. [Libraries](#7)\n1. [Load and Check Data](#8)\n    * [Data Preprocessing](#9)\n    * [Outlier Observations](#10)\n1. [Exploratory Data Analysis](#11)\n    * [Categorical Variables](#12)\n    * [Numerical Variables](#13)\n1. [Customer Segmentation With RFM](#14)\n    * [Preparation of RFM Metrics](#15)\n    * [Generating RFM Scores](#16)\n    * [Segmenting Customers Based on RFM Scores](#17)\n    * [Visualization of RFM Segments](#18)\n1. [CLTV - Customer Lifetime Value](#19)\n    * [Preparation Data Structure of CLTV](#20)\n    * [BG - NBD Model](#21)\n    * [Gamma Gamma Model](#22)\n    * [BG - NBD and GG Model For Prediction](#23)\n    * [Segmentation on CLTV Forecasts](#24)\n1. [References](#25)\n\n\n","f4278c94":"<a id = \"24\"><\/a><br>\n# Segmentation on CLTV Forecasts","03588ed2":"<a id = \"5\"><\/a><br>\n## Dataset Story\n* The dataset includes sales between 01\/12\/2009 - 09\/12\/2011.\n* In this project, the years 2010-2011 will be examined.\n* The product catalog of this company includes souvenirs.\n* The vast majority of the company's customers are corporate customers.","f2bc6d73":"<a id = \"19\"><\/a><br>\n# Customer Lifetime Value\nCustomer lifetime value (CLV), a term sometimes used interchangeably with customer lifetime value, is the prediction of a company's net profit contributed to its overall future relationship with a customer. The model can be simple or sophisticated, depending on how complex the predictive analytics techniques are.\n\nLifetime value is a critical metric because it represents the maximum amount that customers may be expected to spend in order to acquire new ones. As a result, it's crucial in determining the payback of marketing expenses used in marketing mix modeling.\n\n### Definition of CLTV\n> *The present value of the future cash flows attributed to the customer during his\/her entire relationship with the company.!*\n\n\nThis account represents a single time period. It represents the time when the analysis was done. Let me give such a projection that we can evaluate the issue with 3-month and 6-month projections. \n\nHow can I make my inference? We will realize lifetime value with medium and long-term projections for individuals by including the specific pattern of the whole population, by extracting the conditional probability distribution, and generalizing them in terms of the characteristics of a particular individual.\n\n### Formula\nProbabilistic lifetime value estimation with time projection\n\n> CLTV =( Customer Value \/ Churn Rate) * Profit Margin\n\n> Customer Value = Purchase Frequency * Average Order Value\n\n> CLTV = Expected Number of Transaction * Expected Average Profit\n\nAbove, purchase frequency and number of transaction mean the same thing. Likewise, Average Order Value and Average Profit mean the same thing. It differs with the Expected part that happens to them. \n\n**CAUTION**: It will add a probabilistic distribution. Expected statement refers to this part. Expected number of purchases, expected profitability.\n\n* BG \/ NBD = Expected Transaction\n* Gamma Gamma = Expected Profit\n\n## So How Do We Do That?\nWe will add statistics and probability pattern to the above formula.\nThere will be BG \/ NBD and Gamma Gamma models that will make this happen to us. These models will do such a thing that they will model the purchasing behavior of all customers of this company, after modeling the purchasing behavior of all customers, they will replace the individual's personal characteristics in this model and reduce the expected number of sales to the person from the general audience pattern.\n\nBG NBD and Gamma Gamma models are statistical models, not machine learning models. In fact, these models have the expression \"Conditional\" at the beginning.\n","38a01fb8":"* E refers to the expected value\n* x refers to frequency for each customer\n* mx refers to the monetary for each customer\n* M refers to the expected value of transactions (expected average profit)\n* p,q,\u03b3 comes from the gamma distribution","23983345":"<a id = \"1\"><\/a><br>\n# Customer Relationship Management\n### Definition of CRM\n> Customer relationship management (CRM) is a process in which a business or other organization administers its interactions with customers, typically using data analysis to study large amounts of information.\n\n\n## CRM Analytic\n* Customer lifecycle optimizations: Refers to the customer's journey. It starts from the time of contacting the company. Initial points of contact: registration process, social media post etc.\n* Internal and External Communications: Language, colour, images, campaigns\n* Customer acquisition\n* Customer retention (abandonment\/churn) \n* Cross-sell, up-sell\n* Customer segmentation studies: These are strategy development studies by dividing customers into groups.\n\n**Purpose:** It is an effort to make the entire customer relations process more efficient based on data. Sometimes it means effort, time, strategy development, more work with less effort, process optimization.","c6adccdf":"### Formula\n$E(Y(t)|X = x, t_x, T, r, \\alpha, a, b)=\\frac{a + b + x - 1}{a-1} X \\frac{ \\left[1 - \\left(\\frac{\\alpha + T}{\\alpha + T + t} \\right)^{r+x} 2F_1(r + x, b + x; a + b + x - 1; \\frac{t}{\\alpha + T + t} \\right]}\n{1 + \\partial_{(x>0)} \\frac{\\alpha}{b + x -1} \n\\left( \\frac{\\alpha + T}{alpha + t_x}   \\right)^{r+x}    } $","79b856b6":"<a id = \"2\"><\/a><br>\n# KPIs - KEY PERFORMANCE INDICATORS\nA performance indicator or key performance indicator (KPI) is a sort of performance measurement that assesses the success of an organization or a specific activity (such as projects, programs, products, and other initiatives). KPIs evaluate the efficacy of an organization or any other activity in which it participates.\n\n* Customer Acquisition Rate \n* Customer Retention Rate \n* Customer Churn Rate \n* Conversion Rate \n"}}