{"cell_type":{"2295ce8f":"code","fde29f3f":"code","43cabb8c":"code","cc8bd507":"code","514fba43":"code","347d6e49":"code","9decbb99":"code","e3484126":"code","7d8ee484":"code","b259343d":"code","e4aadd52":"code","26180d26":"code","ae8f9131":"code","874664b3":"code","6bcc357d":"code","163f2cf2":"code","5d525577":"code","154ed00c":"code","0e0573d9":"code","8f93fae6":"code","7ed632da":"code","583182f2":"code","83261550":"code","0e12fd8d":"code","9b48d020":"markdown","4298766b":"markdown","03a660fa":"markdown","990306e6":"markdown","482fe2b5":"markdown","46f4149d":"markdown","3aab5664":"markdown","f0a1eba5":"markdown","9d00fc37":"markdown","4a0efd31":"markdown","738ccf0e":"markdown","5b7ae365":"markdown"},"source":{"2295ce8f":"import numpy as np\nimport pandas as pd\n\nfrom datetime import datetime, date, time, timedelta\n\nfrom tqdm import tqdm, trange","fde29f3f":"def convert2datetime(text):\n    if not text:\n        return np.nan\n    month, day, year = [int(el) for el in text.split('\/')]\n    if year < 30:\n        year = 2000+year\n    else:\n        year = 1900+year\n    \n    return date(year, month, day)\n\ndef timedelta2month(timedelta):\n    return round(timedelta.days\/30.5)","43cabb8c":"employees = pd.read_csv('\/kaggle\/input\/softserve-ds-hackathon-2020\/employees.csv', converters={'HiringDate':convert2datetime,'DismissalDate':convert2datetime})\nhistory = pd.read_csv('\/kaggle\/input\/softserve-ds-hackathon-2020\/history.csv', converters={'Date':convert2datetime})\nsubmission = pd.read_csv('\/kaggle\/input\/softserve-ds-hackathon-2020\/submission.csv')\n\ncategory_cols = ['PositionID', 'CustomerID', 'ProjectID', 'DevCenterID', 'SBUID', 'FunctionalOfficeID', 'CompetenceGroupID', 'PaymentTypeId',]\nboolean_cols = ['IsTrainee', 'IsInternalProject', 'OnSite']\ncontinious_cols = ['Utilization', 'WageGross', 'BonusOneTime']\nordinal_cols = ['PositionLevel', 'LanguageLevelID', 'HourVacation', 'HourMobileReserve', 'HourLockedReserve', 'MonthOnPosition', 'MonthOnSalary', 'APM']\nother_cols = ['EmployeeID', 'Date']","cc8bd507":"dismissal_date = history['EmployeeID'].map(employees.set_index('EmployeeID')['DismissalDate'])\ndays2dismissal = (dismissal_date - history['Date'])\ndays2dismissal = days2dismissal.fillna(timedelta(days=9999))\nmonth2dismissal = days2dismissal.apply(timedelta2month)\nhistory['target'] = (month2dismissal <= 3).astype(int)\nhistory.loc[history['Date'] > date(2018, 11, 1), 'target'] = None","514fba43":"history['ProjectID'] = history['ProjectID'].fillna('other')","347d6e49":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nhistory['CustomerID'] = le.fit_transform(history['CustomerID'])\nhistory['ProjectID'] = le.fit_transform(history['ProjectID'])","9decbb99":"employees_dismissal_date = employees[employees['DismissalDate'].notna()].set_index('EmployeeID')['DismissalDate']\nbad_history_mask = history['Date'] >= history['EmployeeID'].map(employees_dismissal_date)\nhistory = history[~bad_history_mask].reset_index(drop=True)","e3484126":"employees_start = employees.set_index('EmployeeID')['HiringDate']\nhistory_employees_start = history['EmployeeID'].map(employees_start)\nhistory['company_work_time'] = (history['Date'] - history_employees_start).map(timedelta2month)\nhistory.loc[history['company_work_time'] >= 12*10, 'company_work_time'] = 12*10\n\nhistory = history[history['company_work_time'] >= 4].reset_index()","7d8ee484":"history.groupby('Date')['MonthOnSalary'].mean().plot(figsize=(10, 5));","b259343d":"%%time\nold_employees = employees.loc[employees['HiringDate'] < date(2017, 7, 1), 'EmployeeID']\nfor emp in old_employees:\n    emp_history = history[history['EmployeeID'] == emp]\n    \n    old_value = 0\n    for el in emp_history['MonthOnSalary']:\n        if el > old_value:\n            old_value = el\n        else:\n            break\n          \n    moth_from_salary = max(0, 12-old_value)\n    \n    history.loc[emp_history.index[:old_value], 'MonthOnSalary'] += moth_from_salary\n    \nhistory.loc[history['MonthOnSalary'] > 13, 'MonthOnSalary'] = 14","e4aadd52":"history.groupby('Date')['MonthOnSalary'].mean().plot(figsize=(10, 5));","26180d26":"history.groupby('Date')['MonthOnPosition'].mean().plot(figsize=(10, 5));","ae8f9131":"%%time\n\ntime_from_hiring = (date(2017, 7, 1)-employees.set_index('EmployeeID')['HiringDate']).map(timedelta2month).map(lambda x: max(0,x))\ntime_from_hiring \/= 2.5\ntime_from_hiring = time_from_hiring.round().astype(int)\n\nold_employees = employees.loc[employees['HiringDate'] < date(2017, 7, 1), 'EmployeeID']\nfor emp in old_employees:\n    emp_history = history[history['EmployeeID'] == emp]\n\n    old_value = 0\n    for el in emp_history['MonthOnPosition']:\n        if el > old_value:\n            old_value = el\n        else:\n            break\n            \n    history.loc[emp_history.index[:old_value], 'MonthOnPosition'] += time_from_hiring[emp]\n\nhistory.loc[history['MonthOnPosition'] > 5*12, 'MonthOnPosition'] = 5*12","874664b3":"history.groupby('Date')['MonthOnPosition'].mean().plot(figsize=(10, 5));","6bcc357d":"def normalize(col):\n    return (col - col.mean())\/col.std()\n\nnorm_cols = ['WageGross', 'BonusOneTime', 'HourVacation', 'HourMobileReserve', 'HourLockedReserve']#, 'APM', 'Utilization', 'MonthOnPosition', 'MonthOnSalary']\nfor month in history['Date'].unique():\n    date_idx = history.index[history['Date'] == month]\n    for col in norm_cols:\n        history.loc[date_idx, col] = normalize(history.loc[date_idx, col])","163f2cf2":"test_date = date(2019, 2, 1)\ntrain_date = [date(2018, 11, 1), date(2018, 8, 1)]\n\ntest = history[(history['Date'] == test_date) & history['EmployeeID'].isin(submission['EmployeeID'])]\ntest = test.sort_values('EmployeeID').reset_index(drop=True)\n\ntrain = history[(history['Date'] <= train_date[0])&(history['Date'] >= train_date[1])].reset_index(drop=True)","5d525577":"cv_dates = [(date(2018, 8, 1), date(2018, 5, 1), date(2018, 11, 1)), \n            (date(2018, 7, 1), date(2018, 4, 1), date(2018, 10, 1)),\n            (date(2018, 6, 1), date(2018, 3, 1), date(2018, 9, 1)),\n            (date(2018, 5, 1), date(2018, 2, 1), date(2018, 8, 1)),\n            (date(2018, 4, 1), date(2018, 1, 1), date(2018, 7, 1)),\n            (date(2018, 3, 1), date(2017, 12, 1), date(2018, 6, 1)),\n           ]\n\ncv_data = []\nfor cv_date  in cv_dates:\n    fold_train = history[(history['Date'] <= cv_date[0])&(history['Date'] >= cv_date[1])].reset_index(drop=True)\n    fold_val = history[history['Date'] == cv_date[2]].reset_index(drop=True)\n    cv_data.append((fold_train, fold_val))","154ed00c":"train_drop_cols = ['target','Date','EmployeeID']#, 'CustomerID', 'ProjectID', 'DevCenterID', 'SBUID', 'PositionID']","0e0573d9":"X_test = test.drop(columns=train_drop_cols)\n\nX_train = train.drop(columns=train_drop_cols)\ny_train = train['target']","8f93fae6":"cv_X_y = []\nfor fold_train, fold_val  in cv_data:\n    fold_train_X = fold_train.drop(columns=train_drop_cols)\n    fold_train_y = fold_train['target']\n    \n    fold_val_X = fold_val.drop(columns=train_drop_cols)\n    fold_val_y = fold_val['target']\n    \n    cv_X_y.append(((fold_train_X, fold_train_y), (fold_val_X, fold_val_y)))","7ed632da":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import fbeta_score\n\n\ndef f1_7(estimator, X, y):\n    return fbeta_score(y, (estimator.predict_proba(X)[:,1] > 0.5).astype(int), 1.7)\n\n\ndef calk_best_score(true, pred):\n    max_score = 0\n    best_tresh = 0\n    for tresh in np.arange(0.01, 1, 0.01):\n        pred_0_1 = pred>tresh\n        if any(pred_0_1):\n            score = fbeta_score(true, pred_0_1, 1.7, labels=[0,1])\n            if score > max_score:\n                max_score = score\n                best_tresh = tresh\n\n    return max_score, best_tresh\n\ndef validate_model(model, cv_X_y, n=5):\n    best_score_mass = []\n    tresh_mass = []\n    predict_proba_mass = []\n    \n    for (fold_train_X, fold_train_y), (fold_val_X, fold_val_y) in cv_X_y:\n        fold_scores = []\n        fold_tresh = []\n        fold_proba = []\n        for i in range(n):\n            model.fit(fold_train_X, fold_train_y)\n            predict_proba = model.predict_proba(fold_val_X)[:,1]\n            max_score, best_tresh = calk_best_score(fold_val_y, predict_proba)\n            \n            fold_scores.append(max_score)\n            fold_tresh.append(best_tresh)\n            fold_proba.append(predict_proba)\n\n        best_score_mass.append(fold_scores)\n        tresh_mass.append(fold_tresh)\n        predict_proba_mass.append(fold_proba)\n\n    tresh_mass = np.array(tresh_mass)\n    best_score_mass = np.array(best_score_mass)\n    \n\n    mean_tresh = tresh_mass.mean()\n    \n    score_mass = []\n    for fold_proba, (_, (_, fold_val_y)) in zip(predict_proba_mass, cv_X_y):\n        fold_score_mass = []\n        for proba in fold_proba:\n            score = fbeta_score(fold_val_y, proba>mean_tresh, 1.7, labels=[0,1])\n            fold_score_mass.append(score)\n        score_mass.append(fold_score_mass)\n    score_mass = np.array(score_mass)\n    \n    return mean_tresh, score_mass, best_score_mass, tresh_mass\n    \n    \ndef validate_result_vizualize(mean_tresh, score_mass, best_score_mass, tresh_mass):\n    print('Best score by fold:')\n    print(best_score_mass)\n    print('Score by sample:')\n    print(score_mass)\n    print('Tresh by sample:')\n    print(tresh_mass)\n    print()\n    print('Best score by fold:')\n    print(best_score_mass.mean(axis=1))\n    print('Score by fold:')\n    print(score_mass.mean(axis=1))\n    print('Tresh by fold:')\n    print(tresh_mass.mean(axis=1))\n    print()\n    print('Best score std:')\n    print(best_score_mass.mean(axis=1).std())\n    print('Score std:')\n    print(score_mass.mean(axis=1).std())\n    print('Tresh std:')\n    print(tresh_mass.mean(axis=1).std())\n    print()\n    print(f'Best score mean: {best_score_mass.mean()}')\n    print(f'Score mean     : {score_mass.mean()}')\n    print(f'Tresh mean: {mean_tresh}')\n\n    \ndef create_sub(name, model, submission, X_train, y_train, X_test, tresh):\n    model.fit(X_train, y_train)\n    pred_proba = model.predict_proba(X_test)[:,1]\n    test_prediction = (pred_proba > tresh).astype(int)\n    submission['target'] = test_prediction\n    submission.to_csv(name, index=False)\n    return submission","583182f2":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators=1000, \n                             class_weight='balanced',\n                             max_leaf_nodes=64,\n                             max_depth=12,\n                             max_features=5, \n                             min_samples_split=5, \n                             min_samples_leaf=3,\n                             criterion='gini',#'entropy', \n                             n_jobs=-1)\n\nmean_tresh, score_mass, best_score_mass, tresh_mass = validate_model(model, cv_X_y, n=5)\nvalidate_result_vizualize(mean_tresh, score_mass, best_score_mass, tresh_mass)","83261550":"model.n_estimators = 30000","0e12fd8d":"sub = create_sub('submission.csv', model, submission, X_train, y_train, X_test, mean_tresh)\nprint(sub['target'].mean())\nsub","9b48d020":"# Train | Val | Test split","4298766b":"Read data","03a660fa":"### remove untrainable data","990306e6":"### MonthOnSalary Fix","482fe2b5":"### convert all data to numeric values","46f4149d":"### fix nan","3aab5664":"### Remove time based info","f0a1eba5":"# Target","9d00fc37":"# Model","4a0efd31":"### MonthOnPosition Fix","738ccf0e":"# X | y","5b7ae365":"# Preprocessing"}}