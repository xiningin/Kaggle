{"cell_type":{"5e6eaab4":"code","6c83d06d":"code","78b5236d":"code","1628a9ee":"code","a561cf1d":"code","f40a807a":"code","0c65fcf4":"code","bacd18e4":"code","5ec52db0":"code","0e2c5a84":"code","82f833f9":"code","beedbbd2":"code","5221b5da":"code","edddca37":"code","305cf2cc":"code","621b481a":"code","00fdb9c0":"code","0fde5a71":"code","957ac2d0":"code","8ccb75ea":"markdown","b754d213":"markdown","8255e1ad":"markdown","cd0013bf":"markdown","03592a53":"markdown","43680242":"markdown","300e1e5e":"markdown","8c7f89cf":"markdown","092e8197":"markdown","e6521ea9":"markdown","ab5d0b1b":"markdown","95675a60":"markdown","cf5707c0":"markdown","adc82294":"markdown","c70ace8f":"markdown","37091bec":"markdown","defb27dd":"markdown","074b3a95":"markdown","91ac787d":"markdown","6c2ccab8":"markdown"},"source":{"5e6eaab4":"# Standard libraries\nimport os\nimport sys\nimport pickle\nimport numpy as np\nimport random as rn\nimport pandas as pd\nfrom tqdm import tqdm # Progress Bar\n\n# Dimensionality reduction\nfrom sklearn.decomposition import TruncatedSVD\n\n# Specify Paths\nBASE_PATH = '..\/input\/digit-recognizer\/'\nTRAIN_PATH = BASE_PATH + 'train.csv'\nTEST_PATH = BASE_PATH + 'test.csv'\n\n# Seed for reproducability\nseed = 1234\nnp.random.seed(seed)\nrn.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)","6c83d06d":"# File sizes and specifications\nprint('\\n# Files and file sizes')\nfor file in os.listdir(BASE_PATH):\n    print('{}| {} MB'.format(file.ljust(30), \n                             str(round(os.path.getsize(BASE_PATH + file) \/ 1000000, 2))))","78b5236d":"# Load in training and testing data\ntrain_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\nsample_sub = pd.read_csv(BASE_PATH + 'sample_submission.csv')\n\nfeatures = [col for col in train_df.columns if col.startswith('pixel')]","1628a9ee":"# The byte count for our baseline (Standard Pandas Dataframe with Int64 types)\nbase_byte_count_train = sys.getsizeof(train_df)\nbase_byte_count_test = sys.getsizeof(test_df[features])\nprint(f'The standard byte count for train_df is: {base_byte_count_train}')\nprint(f'The standard byte count for test_df is: {base_byte_count_test}')","a561cf1d":"print(\"Distribution description for select pixel values:\")\ntrain_df[['pixel100', 'pixel200', 'pixel300', 'pixel500', 'pixel600', 'pixel700']].describe()","f40a807a":"print(\"Training Dataframe:\")\ntrain_df.head(3)","0c65fcf4":"# Convert all values to unsigned 8-bit integers\ntrain_df = train_df.astype(np.uint8)\ntest_df = test_df.astype(np.uint8)\nlabels = list(train_df['label'])\nlabel_byte_count = sys.getsizeof(labels)","bacd18e4":"uint8_byte_count_train = sys.getsizeof(train_df)\nuint8_byte_count_test = sys.getsizeof(test_df[features])\n\nprint(f'Once we convert all integers to uint8 we are left with a byte count of {uint8_byte_count_train} for train_df and\\n\\\n{uint8_byte_count_test} bytes for test_df.\\n\\n\\\nThis is a reduction of (compared to a basic Pandas DataFrame):\\n\\\n{round(((uint8_byte_count_train - base_byte_count_train)\/base_byte_count_train)*100,2)}% for the train_df and\\n\\\n{round(((uint8_byte_count_test - base_byte_count_test)\/base_byte_count_test)*100,2)}% for the test_df.')","5ec52db0":"print(f'The cost of storing the index in a Pandas DataFrame is: {test_df.index.memory_usage()} bytes')","0e2c5a84":"concat_uint8 = pd.concat([train_df, test_df])\nn_components = 15\n# Perform Truncated Singular Value Decomposition (TSVD) on all features\ntsvd = TruncatedSVD(n_components=n_components).fit_transform(concat_uint8[features])\n# Split up the t-SNE results in training and testing data\ncomponents = [f\"Component_{_}\" for _ in range(n_components)]\ntsvd_train = pd.DataFrame(tsvd[:len(train_df)], columns=components)\ntsvd_test = pd.DataFrame(tsvd[len(train_df):], columns=components)\ntsvd_train['label'] = labels","82f833f9":"print('TSVD features: ')\ntsvd_train.head(3)","beedbbd2":"print(f'Once we perform TSVD we are left with a byte count of\\n\\\n{sys.getsizeof(tsvd_train)} for train_df and\\n\\\n{sys.getsizeof(tsvd_test)} bytes for test_df.\\n\\n\\\nThis is a reduction of (compared to Pandas DataFrame with uint8):\\n\\\n{round(((sys.getsizeof(tsvd_train) - uint8_byte_count_train)\/uint8_byte_count_train)*100,2)}% for the train_df and\\n\\\n{round(((sys.getsizeof(tsvd_test) - uint8_byte_count_test)\/uint8_byte_count_test)*100,2)}% for the test_df.')","5221b5da":"# Convert all values to 0 and 1\nfor df in [train_df, test_df]:\n    for col in features:\n        df[col] = np.where(df[col]<127, 0, 1)","edddca37":"train_array = []\ntest_array = []\n# Encode every image to a ascii bitstring\nfor i in tqdm(range(len(train_df))):\n    train_array.append(train_df.iloc[i][features].astype(str).sum().encode('ascii'))\nfor i in tqdm(range(len(test_df))):\n    test_array.append(test_df.iloc[i][features].astype(str).sum().encode('ascii'))","305cf2cc":"bitcount_train = sys.getsizeof(train_array)\nbitcount_test = sys.getsizeof(test_array)\nprint(f'Once we convert all integers to bits we are left with a byte count of \\n\\\n{bitcount_train} for train_df and\\n\\\n{bitcount_test} bytes for test_df.\\n\\n\\\nThis is a further reduction (compared to Pandas DataFrame with uint8) of:\\n\\\n{round((((bitcount_train+label_byte_count) - uint8_byte_count_train)\/uint8_byte_count_train)*100,2)}% for the train_df and\\n\\\n{round(((bitcount_test - uint8_byte_count_test)\/uint8_byte_count_test)*100,2)}% for the test_df.')","621b481a":"def display_digit_bytes(text, lineLength):\n    \"\"\"\n    Visualize a 784-bit representation of an MNIST Image\n    \n    text: The bitstring that you want to represent\n    lineLength: The length at which to jump to a new line \n    (28 in the case of MNIST images)\n    \"\"\"\n    if len(text) <= lineLength:\n        return text\n    else:\n        # Print line and next line recursively\n        print(text[:lineLength])\n        return display_digit_bytes(text[lineLength:], lineLength)","00fdb9c0":"print(f'Label = {labels[3]}\\n')\ndisplay_digit_bytes(train_array[3], 28)","0fde5a71":"# Add labels to training data\ntrain_array.append(labels)\n# Save data as pickle files\nwith open('training_data.pkl','wb') as file:\n    pickle.dump(train_array, file)\nwith open('test_data.pkl','wb') as file:\n    pickle.dump(test_array, file)","957ac2d0":"print(f\"File size for pickled training data: {os.path.getsize('training_data.pkl')}\")\nprint(f\"File size for pickled test data: {os.path.getsize('training_data.pkl')}\")","8ccb75ea":"In this kernel we will compress MNIST images as far as we can without losing information. We will calculate the byte count for each manipulation and compare them with each other.\n\nThis kernel is the 2nd in a series I am doing on MNIST. The first is a kernel on the power of dimensionality reduction combined with simple algorithms such as decision trees. [You can check out the 1st kernel in this series here.](https:\/\/www.kaggle.com\/carlolepelaars\/97-on-mnist-with-a-single-decision-tree-t-sne)\n\nMNIST series:\n\n1. [97% on MNIST with a single decision tree (+ t-SNE)](97% on MNIST with a single decision tree (+ t-SNE))\n2. [Compressing MNIST Images (to 784 bits)](https:\/\/www.kaggle.com\/carlolepelaars\/compressing-mnist-images-to-784-bits)\n3. An end-to-end neural network using only NumPy (Work in progress)","b754d213":"## Conclusion <a id=\"7\"><\/a>","8255e1ad":"We store we smallest data format we have as a [pickle file](https:\/\/docs.python.org\/3\/library\/pickle.html).","cd0013bf":"## Dependencies <a id=\"1\"><\/a>","03592a53":"## Baseline <a id=\"3\"><\/a>","43680242":"Since different grayscale values don't play a very large role in MNIST we can round all numbers smaller than 127 to 0 and clip all values larger or equal to 127 to 1. In this way we can reduce every image to an array of 784 bytes (0s and 1s). We will also need 42128 bytes more for the training set because we have to store the labels as uint8. From here on out we all lose the Pandas DataFrame format. We save another 128 bytes because we don't have to store the index anymore.\n\nTo reduce the byte count we store every image as a bitstring and then encode it to ASCII.","300e1e5e":"And we are done! Please let me know if you know more tricks to compress (MNIST) images or to store image data more efficiently.\n\nIf you like this Kaggle kernel, feel free to give an upvote and leave a comment! I will try to implement your suggestions in this kernel!","8c7f89cf":"## Uint8 <a id=\"4\"><\/a>","092e8197":"## Table of contents","e6521ea9":"TSVD is a technique that can be used to compress sparse data, like MNIST Images. We can decide ourselves how much we want to reduce the dimensionality. In this example we reduce the 28x28 images to 15x15 (15 components)\n\nFor more information about dimensionality reduction on MNIST I suggest you check out [this Kaggle kernel](https:\/\/www.kaggle.com\/carlolepelaars\/97-on-mnist-with-a-single-decision-tree-t-sne).","ab5d0b1b":"As you can see there are many ways to compress grayscale images without losing much information. However, a bitstring is not really suitable for training machine learning models. NumPy arrays are very practical and therefore I suggest compressing the images so they can be used with the uint8 type (values between 0 and 255). It is also beneficial to consider dimensionality reduction techniques if you need to compress the data even further. [Dimensionality reduction techniques can even increase performance of simple models as illustrated in this Kaggle kernel](https:\/\/www.kaggle.com\/carlolepelaars\/97-on-mnist-with-a-single-decision-tree-t-sne).","95675a60":"# Compressing MNIST Images","cf5707c0":"Since all values in this DataFrame are between 0 and 255 we can store the data as unsigned integers of 8 bytes (uint8). This will save 56 bytes on every value.","adc82294":"TL;DR: Use NumPy arrays with uint8. Consider dimensionality reduction to compress data.","c70ace8f":"## TSVD <a id=\"5\"><\/a>","37091bec":"## Bitstring and ASCII encoding <a id=\"6\"><\/a>","defb27dd":"## Preparation <a id=\"2\"><\/a>","074b3a95":"Wow! Now we're talking. Note that we can still visualize the digit even though it is stored in an unintuitive way. Here is how we can easily print the representation as a 28x28 representation.","91ac787d":"We will try to reduce the byte count as much as we can before training a model on MNIST. Below are the baselines from where we will be working. Pandas stores every integer automatically as int64 so the initial byte count is quite large.","6c2ccab8":"- [Dependencies](#1)\n- [Preparation](#2)\n- [Baseline](#3)\n- [Uint8](#4)\n- [TSVD](#5)\n- [Bitstring and ASCII Encoding](#6)\n- [Conclusion](#7)"}}