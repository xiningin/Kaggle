{"cell_type":{"aefffbd3":"code","fb046ec2":"code","bc6c5010":"code","8362a5ea":"code","f40cbc8c":"code","ca739185":"code","08146ce3":"code","f976ba54":"code","43acee65":"code","80a80e1e":"code","8147d21d":"code","6296b9e8":"markdown","51e6006d":"markdown","e8bc2577":"markdown"},"source":{"aefffbd3":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.util.montage import montage2d as montage\nmontage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nship_dir = '..\/input'\ntrain_image_dir = os.path.join(ship_dir, 'train')\ntest_image_dir = os.path.join(ship_dir, 'test')\nimport gc; gc.enable() # memory is tight\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list):\n    # Take the individual ship masks and create a single mask array for all ships\n    all_masks = np.zeros((768, 768), dtype = np.int16)\n    #if isinstance(in_mask_list, list):\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks += rle_decode(mask)\n    return np.expand_dims(all_masks, -1)","fb046ec2":"masks = pd.read_csv(os.path.join('..\/input\/',\n                                 'train_ship_segmentations.csv'))\nprint(masks.shape[0], 'masks found')\nprint(masks['ImageId'].value_counts().shape[0])","bc6c5010":"import dask.array as da\nimport dask\nimport dask.diagnostics as diag\nfrom multiprocessing.pool import ThreadPool\nimport h5py\nfrom bokeh.io import output_notebook\nfrom bokeh.resources import CDN\noutput_notebook(CDN, hide_banner=True)","8362a5ea":"all_batches = list(masks.groupby('ImageId'))","f40cbc8c":"all_ids = pd.DataFrame({'ImageId': [id for id, _ in all_batches]})\nall_ids.to_csv('image_ids.csv', index=False)\nall_ids.sample(2)","ca739185":"def dask_read_seg(in_batches, max_items = None):\n    d_mask_fun = dask.delayed(masks_as_image)\n    if max_items is None:\n        max_items = len(in_batches)\n    lazy_images = [d_mask_fun(c_masks['EncodedPixels'].values) \n                   for _, (_, c_masks) in zip(range(max_items), in_batches)\n                  ]     # Lazily evaluate on each group\n    s_img = lazy_images[0].compute()\n    arrays = [da.from_delayed(lazy_image,           # Construct a small Dask array\n                              dtype=s_img.dtype,   # for every lazy value\n                              shape=s_img.shape)\n              for lazy_image in lazy_images]\n\n    return da.stack(arrays, axis=0)                # Stack all small Dask arrays into one","08146ce3":"tiny_img_ds = dask_read_seg(all_batches, 20)\ntiny_img_ds","f976ba54":"with diag.ProgressBar(), diag.Profiler() as prof, diag.ResourceProfiler(0.5) as rprof:\n    with dask.config.set(pool=ThreadPool(4)):\n        tiny_img_ds.to_hdf5('tiny_segmentions.h5', '\/image', compression = 'lzf')\n!ls -lh *.h5","43acee65":"# larger chunks are more efficient for writing\/compressing and make the paralellization more efficient\nlarger_chunker = lambda x: x.rechunk({0: x.shape[0]\/\/400, 1: -1, 2: -1, 3: -1})","80a80e1e":"all_img_ds = larger_chunker(dask_read_seg(all_batches))\nall_img_ds","8147d21d":"with diag.ProgressBar(), diag.Profiler() as prof, diag.ResourceProfiler(0.5) as rprof:\n    with dask.config.set(pool=ThreadPool(4)):\n        all_img_ds.to_hdf5('segmentions.h5', '\/image', compression = 'lzf')\n!ls -lh *.h5","6296b9e8":"# Prepare the dask-processing code\nHere we have the code to run the preprocessing and packaging in a more efficient distributed manner","51e6006d":"# Now Package Everything\ninstead of just using a small portion of the dataset we export all the results.","e8bc2577":"# Overview\nGoing from RLE in a data.frame to segmentation image is a somewhat expensive step and so we can make training easier if we preprocess the RLE data and generate masks that we can load in."}}