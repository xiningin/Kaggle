{"cell_type":{"df08634e":"code","3e34c3a6":"code","3cfaf61b":"code","a48fe499":"code","861cb023":"code","b8a6ae92":"code","83ade8ab":"code","be3da9d1":"code","53634d6e":"code","a32a3f6f":"code","fc2c5ea2":"code","64520a52":"code","cc4f4221":"code","4a2a02e7":"code","53754a0a":"code","ee8d5591":"code","afed5d0d":"code","9ac09a60":"code","bfda8305":"code","e7fa1549":"code","ec0f6f50":"code","bf769389":"code","e0b5687d":"markdown","1058de1c":"markdown","bf84b572":"markdown","a286494d":"markdown","25316843":"markdown","988aca86":"markdown","09d7c947":"markdown"},"source":{"df08634e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","3e34c3a6":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3cfaf61b":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","a48fe499":"os.chdir('\/kaggle\/input\/buildingdatagenomeproject2')\nos.listdir()","861cb023":"meta = pd.read_csv('metadata.csv')\nprint(meta.shape)\nmeta.head()","b8a6ae92":"meta.info()","83ade8ab":"meta.describe()","be3da9d1":"for col in meta.columns:\n    if(meta[col].dtype == 'O'):\n        data = meta[col].fillna('NaN')\n        unique, counts = np.unique(data, return_counts=True)\n        if(len(unique) < 20):  \n            size = [16,4]\n            if(len(unique)==2): \n                size = [16,1]\n            \n            plt.figure(figsize=size)\n            plt.title(col)\n            plt.barh(unique, counts)\n            plt.grid(axis='x')\n            plt.show()","53634d6e":"for col in meta.columns:\n    data = meta[col]\n    if(data.dtype == 'float64'):\n        data = meta[col]\n        plt.figure(figsize=[16,4])\n        plt.plot(data)\n        plt.title(col)\n        plt.grid()\n        plt.show()        ","a32a3f6f":"weather = pd.read_csv('weather.csv')\nprint(weather.shape)\nweather.head()","fc2c5ea2":"values, counts = np.unique(weather.site_id, return_counts=True)\nplt.figure(figsize=[16,4])\nplt.barh(values, counts)\nplt.grid(axis='x')\nplt.show()","64520a52":"for col in weather.columns:\n    if(col not in ['timestamp', 'site_id']):\n        plt.figure(figsize=[16,5])\n        plt.title(col)\n        plt.plot(weather[col])\n        plt.grid()\n        plt.show()","cc4f4221":"files = [f for f in os.listdir('.') if f not in ['metadata.csv', 'weather.csv']]\nfiles","4a2a02e7":"data = {}\n\nfor file in files:\n    key = file.split('_')[0]\n    data[key] = pd.read_csv(os.path.join(file))\n    print(\"Key: {:15s} Shape: {}\".format(key, data[key].shape))","53754a0a":"data['chilledwater'].describe().T","ee8d5591":"data['electricity'].describe().T","afed5d0d":"data['gas'].describe().T","9ac09a60":"data['hotwater'].describe().T","bfda8305":"data['irrigation'].describe().T","e7fa1549":"data['solar'].describe().T","ec0f6f50":"data['steam'].describe().T","bf769389":"data['water'].describe().T","e0b5687d":"# Datasets","1058de1c":"# Overview and getting started\n\n","bf84b572":"# Weather","a286494d":"# Preliminary","25316843":"## Examining the Numerical Variables","988aca86":"## Examining the categorical varaibles","09d7c947":"# Metadata"}}