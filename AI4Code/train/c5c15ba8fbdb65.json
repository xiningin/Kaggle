{"cell_type":{"c7f10175":"code","ffa836ce":"code","963b3553":"code","96d19284":"code","9683477e":"code","a74c4f49":"code","6a07e05d":"code","1e09e41b":"code","43713ec2":"code","2ac16969":"code","d412cca9":"code","d64f67d6":"code","1eb9f6c4":"code","af222715":"code","982ad819":"code","9d6c1ae6":"code","59151f90":"code","409d20e4":"code","270790f1":"code","25aef15e":"code","1f974312":"code","371f99b3":"code","e13b8af6":"code","012d549b":"code","48e603be":"code","e1e5a50a":"code","a63abd6a":"code","6da525d0":"code","45b32fea":"code","e2ecf7c1":"code","e260b52f":"code","e3b79d51":"code","0b707594":"code","c058295c":"code","9f18ff60":"code","adf29b36":"code","7a6427a6":"code","d2920702":"code","08644531":"code","188bb23f":"code","89c55b59":"code","3ee57297":"code","ce468c84":"code","91f09ac9":"code","3c47d5bb":"code","e93695d7":"code","ed7db762":"code","1d7d4766":"code","72b529c4":"code","1016aabf":"code","7c6c2a6e":"code","e5025ecb":"code","48a83d73":"markdown","e2e77e60":"markdown","4268c8ff":"markdown","cedf1269":"markdown","241498c4":"markdown","6899dafa":"markdown","61c7fa3c":"markdown","3fa772ee":"markdown","7ee8210f":"markdown","5010ea56":"markdown","9088d9f0":"markdown","1d4977c6":"markdown","7504c8ea":"markdown","880cf503":"markdown","5cccda41":"markdown","fe337a1b":"markdown","e2a37d52":"markdown"},"source":{"c7f10175":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ffa836ce":"auto=pd.read_csv(\"..\/input\/autompg-dataset\/auto-mpg.csv\")","963b3553":"auto.head()","96d19284":"9 + 3*8 + 4*302 + b3x3... = 10","9683477e":"auto[\"car name\"].value_counts()","a74c4f49":"auto.shape","6a07e05d":"auto.dtypes","1e09e41b":"auto.cylinders.astype(\"category\")","43713ec2":"auto=auto.rename(columns={\"model year\":\"model_year\",\"car name\":\"car_name\"})\nauto.columns","2ac16969":"fig, ax = plt.subplots()\nax.scatter(auto.weight, auto.mpg, c=auto.cylinders)\nplt.legend()\nplt.show()","d412cca9":"auto.isnull().any()","d64f67d6":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set_palette(\"RdBu\")\ncorrelation=auto.corr()\nsns.heatmap(correlation)\nplt.show()","1eb9f6c4":"auto.head()","af222715":"auto.origin.unique()","982ad819":"auto.info()","9d6c1ae6":"auto.info()","59151f90":"auto","409d20e4":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ncar_name_le = pd.DataFrame(le.fit_transform(auto[[\"car_name\"]]), columns=[\"car_name_encoded\"])\ncar_name_le","270790f1":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(handle_unknown = \"ignore\")\ncar_name_ohe = ohe.fit_transform(auto)\ncar_name_ohe_df = pd.DataFrame(data = car_name_ohe.toarray())\nprint(car_name_ohe_df)\n","25aef15e":"car_name_df=pd.concat([auto, pd.get_dummies(auto[\"car_name\"],prefix=\"model\")], axis=1)\ncar_name_df","1f974312":"auto=auto.drop(columns=[\"car_name\"])","371f99b3":"auto.horsepower=auto.horsepower.replace(\"?\",\"165\")","e13b8af6":"auto.horsepower=auto.horsepower.astype(\"int\")","012d549b":"auto.shape","48e603be":"auto.origin.astype(\"category\")","e1e5a50a":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(auto)","a63abd6a":"auto_scaled = pd.DataFrame(scaler.fit_transform(auto), columns=auto.columns)\nprint(auto_scaled)","6da525d0":"from sklearn.preprocessing import StandardScaler\nsscaler = StandardScaler()\nauto_sscaled = pd.DataFrame(sscaler.fit_transform(auto), columns=auto.columns)","45b32fea":"auto_sscaled","e2ecf7c1":"X = auto_scaled.loc[:,auto.columns!=\"mpg\"]\ny = auto_scaled.mpg","e260b52f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","e3b79d51":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,y_train)","0b707594":"from sklearn.metrics import r2_score\nlr_predict = lr.predict(X_test)\nr2_score(lr_predict, y_test)","c058295c":"from sklearn.metrics import mean_squared_error\nmean_squared_error(lr_predict, y_test)","9f18ff60":"from tpot import TPOTRegressor\ntpotr = TPOTRegressor(generations=5, verbosity=3)\ntpotr.fit(X_train, y_train)","adf29b36":"tpotr.score(X_test,y_test)","7a6427a6":"tpotr.export(\"regresyon_raporu\")","d2920702":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train, y_train)\npredlr = lr.predict(X_test)\nfrom sklearn.metrics import r2_score\nprint(r2_score(predlr, y_test))","08644531":"import matplotlib.pyplot as plt\nimport seaborn as sns \n\ns=sns.relplot(x=\"weight\",y=\"mpg\", data=auto, kind=\"scatter\", hue=\"cylinders\")\nplt.show()","188bb23f":"auto.info()","89c55b59":"auto.drop(auto[auto.horsepower==\"?\"].index, inplace=True)","3ee57297":"auto[\"horsepower\"]=auto[\"horsepower\"].astype(\"int64\")","ce468c84":"auto.cylinders=auto.cylinders.astype(\"category\")","91f09ac9":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\nauto[\"cylinders_label\"]=le.fit_transform(auto[\"cylinders\"])\nauto\nauto=auto.drop(columns=[\"cylinders\"])\nauto.cylinders_label=auto.cylinders_label.astype(\"category\")","3c47d5bb":"Y=auto.cylinders_label\nauto=auto.drop(columns=[\"cylinders_label\"])","e93695d7":"import pandas as pd    \nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nauto_scaled = pd.DataFrame(scaler.fit_transform(auto),columns = auto.columns)\nauto_scaled","ed7db762":"X=auto_scaled.iloc[:, auto.columns!=\"cylinders\"]\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2)","1d7d4766":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5,metric='minkowski')\nknn.fit(X_train,y_train)\npredknn = knn.predict(X_test)","72b529c4":"from sklearn.metrics import classification_report\nprint(classification_report(predknn,y_test))","1016aabf":"Ayn\u0131s\u0131n\u0131 karar a\u011fa\u00e7lar\u0131 algoritmas\u0131 i\u00e7in de yap\u0131yorum.","7c6c2a6e":"from sklearn.tree import DecisionTreeClassifier\ndec=DecisionTreeClassifier(criterion=\"entropy\", max_depth=None)\ndec.fit(X_train,y_train)\npreddt = dec.predict(X_test)","e5025ecb":"print(classification_report(preddt, y_test))","48a83d73":"Burada KNN algoritmas\u0131n\u0131 kullanmak i\u00e7in sklearn.neighbors k\u00fct\u00fcphanesinden KNeighborsClassifier'\u0131 import ettim. \nArd\u0131ndan, bu classifier'\u0131n parametrelerini knn'e koydum. Training verisini knn'de fit ettim (benim i\u00e7in bir model olu\u015fturmu\u015f oldu) sonra bu modele test verisini verdim, .predict'le benim i\u00e7in tahminde bulunup predknn'e koydu.","e2e77e60":"Beygir g\u00fcc\u00fc kolonu obje \u015feklinde tutulmu\u015f ve \"?\" yaz\u0131l\u0131 de\u011ferler var, onlar\u0131 d\u00fc\u015f\u00fcr\u00fcp kolonu integer'a \u00e7eviriyorum.","4268c8ff":"Modeli de\u011ferlendirmek i\u00e7in scikitlearn.metrics'ten classification report'u import ettim.","cedf1269":"\u015eimdilik silindir_sayisi_label kolonunu d\u00fc\u015f\u00fcr\u00fccem, category olarak veri tipi versem bile MinMaxScaler onu say\u0131 olarak alg\u0131lay\u0131p normalize etmeye \u00e7al\u0131\u015facak. Normalize ederse hedef kolon 1'le 0 aras\u0131 continuous de\u011ferler olu\u015facak, haliyle s\u0131n\u0131fland\u0131rma problemi bunu \u00e7\u00f6zemeyecek, bunu istemiyoruz.","241498c4":"Veri setinde kay\u0131p veri olup olmad\u0131\u011f\u0131na bakt\u0131m.","6899dafa":"Verisetinin en tepesindeki be\u015f sat\u0131ra .head()'le bak\u0131yoruz.","61c7fa3c":"Modeli olu\u015fturmadan \u00f6nce verileri normalize edicem, sklearn.preprocessing k\u00fct\u00fcphanesinden MinMaxScaler'\u0131 import ediyorum bunun i\u00e7in.","3fa772ee":"Model silindir say\u0131s\u0131 kolonunu numerik olarak g\u00f6r\u00fcp say\u0131sal alg\u0131layacak ve regresyon problemi \u00e7\u00f6zmeye \u00e7al\u0131\u015ft\u0131\u011f\u0131m\u0131z\u0131 d\u00fc\u015f\u00fcnecek. 1,5 silindirli araba diye bir \u015fey yok sonu\u00e7ta :) Bu kolonun veri tipini kategorik yap\u0131yorum.","7ee8210f":"S\u0131n\u0131fland\u0131rma problemindeki s\u0131n\u0131flar\u0131m\u0131n (2, 4, 6, ve 8 silindirli arabalar) a\u011f\u0131rl\u0131k ve km'de yakt\u0131\u011f\u0131 benzin aras\u0131ndaki ba\u011flant\u0131daki yerini scatter plot'la g\u00f6zlemledim. ","5010ea56":"Veri setindeki korelasyonu seaborn'un heatmap'iyle g\u00f6rselle\u015ftiriyorum.","9088d9f0":"Veri setini pandas'\u0131n read_csv attribute'uyla okuyup dataframe'e \u00e7eviriyoruz. ","1d4977c6":"Train test split i\u00e7in tahmin etmeye \u00e7al\u0131\u015ft\u0131\u011f\u0131m kolonu (silindir say\u0131s\u0131) ay\u0131r\u0131p Y'ye koymu\u015ftum zaten, kalan kolonlar\u0131 X'e koydum, ard\u0131ndan %20 oranla training ve test i\u00e7in b\u00f6ld\u00fcm. ","7504c8ea":"StandardScaler","880cf503":"Makine \u00f6\u011frenmesine sokaca\u011f\u0131m b\u00fct\u00fcn kolonlar\u0131n numerik olmas\u0131 gerekiyor, son kez kolonlar\u0131n veri tiplerine bak\u0131yorum.","5cccda41":"TPOT","fe337a1b":"MinMaxScaler","e2a37d52":"Bu kolonu da kategorik hale getirdi\u011fim i\u00e7in ve bu bizim hedef kolonumuz oldu\u011fundan label encoding yap\u0131yorum. Ard\u0131ndan orijinal kolonu d\u00fc\u015f\u00fcr\u00fcyorum."}}