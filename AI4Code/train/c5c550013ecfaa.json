{"cell_type":{"0552d022":"code","31acbdc0":"code","51501188":"code","7b089987":"code","7abb5ba2":"code","6b060fe5":"code","1ac8704d":"code","51a85e65":"code","8052fb39":"code","2a7cf5ba":"code","1f1d2cf4":"code","fa0584bb":"markdown"},"source":{"0552d022":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy\nimport scipy.io.wavfile as wavfile\nimport sklearn\nimport sklearn.metrics\nimport seaborn as sns\nimport random\nimport math\nimport sklearn.utils\nimport sklearn.metrics\nimport matplotlib.pyplot as plt\nimport glob\nimport os\nimport scipy\nimport scipy.signal\nimport tensorflow as tf\nfrom imblearn.over_sampling import RandomOverSampler\nimport IPython","31acbdc0":"WAVE_FOLDER = '..\/input\/cats_dogs'\nFRAMERATE = 16000\nMAX_WAV_SAMPLES = 20*FRAMERATE\nDOWNSAMPLING_SCALE = 1\n\ndf = pd.read_csv(\"..\/input\/train_test_split.csv\")\ntest_cat = df[['test_cat']].dropna().rename(index=str, columns={\"test_cat\": \"file\"}).assign(label=0)\ntest_dog = df[['test_dog']].dropna().rename(index=str, columns={\"test_dog\": \"file\"}).assign(label=1)\ntrain_cat = df[['train_cat']].dropna().rename(index=str, columns={\"train_cat\": \"file\"}).assign(label=0)\ntrain_dog = df[['train_dog']].dropna().rename(index=str, columns={\"train_dog\": \"file\"}).assign(label=1)\n\ntest_df = pd.concat([test_cat, test_dog]).reset_index(drop=True)\ntrain_df = pd.concat([train_cat, train_dog]).reset_index(drop=True)","51501188":"def plot_spectrogram(file):\n    x = wavfile.read(file)[1]\n    f, t, Sxx = scipy.signal.spectrogram(x)\n    plt.pcolormesh(t, f, Sxx)\n    plt.ylabel('Frequency [Hz]')\n    plt.xlabel('Time [sample]')\n\n\nplt.figure(figsize=(50,50))\nfor i in range(0,10,2):\n    plt.subplot(5,2,i+1)\n    plot_spectrogram(os.path.join(WAVE_FOLDER, test_cat.iloc[i]['file']))\n    plt.subplot(5,2,i+2)\n    plot_spectrogram(os.path.join(WAVE_FOLDER, test_dog.iloc[i]['file']))","7b089987":"#wave_raw = wavfile.read(os.path.join(WAVE_FOLDER, test_files[1]))[1]\n#wave = np.pad(wave_raw, pad_width=((0, MAX_WAV_SAMPLES-len(wave_raw))), mode='wrap')\n#wave = scipy.signal.decimate(wave, 2)\n#IPython.display.Audio(wave, rate=FRAMERATE\/\/2)","7abb5ba2":"train_df['label'].plot.hist(bins=2);","6b060fe5":"random_oversampler = RandomOverSampler()\nidx = np.arange(0, len(train_df)).reshape(-1, 1)\nidx_sampled, _ = random_oversampler.fit_sample(idx, train_df['label'])\ntrain_files, train_labels = train_df.iloc[idx_sampled.flatten()]['file'].values, train_df.iloc[idx_sampled.flatten()]['label'].values\ntrain_files, train_labels = sklearn.utils.shuffle(train_files, train_labels)\ntest_files, test_labels = test_df['file'].values, test_df['label'].values","1ac8704d":"pd.Series(train_labels).plot.hist(bins=2);","51a85e65":"def fit_generator(train_files, train_labels, wavs_per_batch=20, augments=5):\n    while True:\n        maxidx = len(train_files)\n        for i in range(0, maxidx, wavs_per_batch):\n            waves_batch = []\n            labels_batch = []\n            for j in range(i, min(maxidx, i+wavs_per_batch)):\n                file, label = train_files[j], train_labels[j]\n                wave_raw = wavfile.read(os.path.join(WAVE_FOLDER, file))[1]\n                wave_raw = wave_raw\/np.std(wave_raw)\n                length = len(wave_raw)\n                waves_batch.append(np.pad(wave_raw, pad_width=((0, MAX_WAV_SAMPLES - length)), mode='wrap'))\n                labels_batch.append(label)\n                for _ in range(augments):\n                    wave_rotated = np.roll(wave_raw, random.randint(0, length))\n                    while random.choice([True, False]):\n                        wave_rotated += np.roll(wave_raw, random.randint(0, length))\n                    wave = np.pad(wave_rotated, pad_width=((0, MAX_WAV_SAMPLES - length)), mode='wrap')\n                    #wave = scipy.signal.decimate(wave, DOWNSAMPLING_SCALE)\n                    waves_batch.append(wave)\n                    labels_batch.append(label)\n            yield np.array(waves_batch), np.array(labels_batch)\n\ndef validate_generator(test_files, test_labels, wavs_per_batch=20):\n    while True:\n        maxidx = len(test_files)\n        for i in range(0, maxidx, wavs_per_batch):\n            waves_batch = []\n            labels_batch = []\n            for j in range(i, min(maxidx, i+wavs_per_batch)):\n                file, label = test_files[j], test_labels[j]\n                wave_raw = wavfile.read(os.path.join(WAVE_FOLDER, file))[1]\n                wave_raw = wave_raw\/np.std(wave_raw)\n                length = len(wave_raw)\n                left = 0\n                right = MAX_WAV_SAMPLES - left - length\n                wave = np.pad(wave_raw, pad_width=((left, right)), mode='wrap')\n                #wave = scipy.signal.decimate(wave, DOWNSAMPLING_SCALE)\n                waves_batch.append(wave)\n                labels_batch.append(label)\n            yield np.array(waves_batch), np.array(labels_batch)\n            \ndef steps_per_epoch(wavs_per_epoch, wavs_per_batch):\n    return int(math.ceil(wavs_per_epoch\/wavs_per_batch))","8052fb39":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Reshape((MAX_WAV_SAMPLES\/\/DOWNSAMPLING_SCALE,1), input_shape=(MAX_WAV_SAMPLES\/\/DOWNSAMPLING_SCALE,)))\nfor i in range(14):\n    model.add(tf.keras.layers.Conv1D(32, kernel_size=5, \n                                     padding='same',\n                                     activation='relu',\n                                     kernel_initializer=tf.keras.initializers.Orthogonal(),\n                                    ))\n    model.add(tf.keras.layers.MaxPooling1D(pool_size=3, strides=2))\n    model.add(tf.keras.layers.BatchNormalization())\n\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dense(2, activation='softmax'))\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.0005),\n              loss=tf.keras.losses.sparse_categorical_crossentropy,\n              metrics=['accuracy']\n             )","2a7cf5ba":"WAVS_PER_BATCH = 3\nAUGMENTS = 10\nEPOCHS=15\nmodel.fit_generator(fit_generator(train_files, train_labels, WAVS_PER_BATCH, AUGMENTS),\n                    steps_per_epoch=steps_per_epoch(len(train_files), WAVS_PER_BATCH),\n                    epochs = EPOCHS,\n                    validation_data=validate_generator(test_files, test_labels, WAVS_PER_BATCH),\n                    validation_steps=steps_per_epoch(len(test_files), WAVS_PER_BATCH),\n                    verbose=2)","1f1d2cf4":"predicted_probs = model.predict_generator(\n    validate_generator(test_files, test_labels, WAVS_PER_BATCH),\n    steps=steps_per_epoch(len(test_files), WAVS_PER_BATCH))\npredicted_classes = np.argmax(predicted_probs, axis=1)\nprint(sklearn.metrics.accuracy_score(predicted_classes, test_labels))\nsns.heatmap(sklearn.metrics.confusion_matrix(predicted_classes, test_labels), annot=True);","fa0584bb":"Each wav file is used as a step. Each wav is extended to a uniform length: 20s. "}}