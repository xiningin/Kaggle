{"cell_type":{"e79abf54":"code","aa67548e":"code","43cb856f":"code","5ee051c6":"code","dec58f54":"code","a0474d04":"code","4d4b5e9a":"code","fcb43f1f":"code","e5e87d87":"code","f12311d6":"code","2d0ccb46":"code","bd993c6c":"code","275a5565":"code","721b2bde":"code","1673562f":"code","d64035fc":"code","48581e19":"code","3b0b71f8":"code","8cf1ed78":"code","92c6528c":"code","c0a6d178":"code","f7e9e10f":"code","6cb4f8c7":"code","ce87e56b":"code","d423c2dd":"code","5acde265":"code","3ac49c8f":"code","c0e1134f":"code","b5c8b029":"code","10f863cd":"code","0ac3662a":"code","590b1115":"code","3929d890":"code","3037c9c1":"code","8cc10ec3":"code","57c7cb39":"code","9f6e894d":"code","fded4ebb":"code","d37ecb5c":"code","dff8124f":"code","7c46d1de":"code","20e8312e":"code","9b186ce5":"code","1a10ca7d":"code","126b6f18":"code","160df257":"code","41b578f5":"code","3a16d84c":"code","3cb5ca59":"code","8d0cd5f4":"code","ecf8ef94":"code","5264e38b":"code","1657b2ae":"code","befa87b5":"code","d757ae1f":"code","487b5b8a":"code","8186cbe2":"code","dd234154":"code","eb51c652":"code","030af248":"code","4da182a6":"code","fffe677f":"code","3c45c622":"code","b2736e80":"code","d2582c28":"code","8ac5911c":"code","4b175fc2":"code","aed1cd53":"code","6e773717":"code","ca05bef2":"code","6e5f146e":"code","d4cd356c":"code","dd724485":"code","8f14a50c":"code","53a1a624":"code","b0b87d78":"code","a9ae6fe2":"code","48f20ec5":"code","6145f06d":"code","bce829fe":"code","e97bb355":"code","1f93c148":"code","e9215cdf":"code","c985bd56":"code","4f7d98bc":"code","2c50f74c":"code","f1a4be2c":"code","56594645":"code","1e636086":"code","f8001e6e":"code","6e3b3c9e":"code","84916335":"code","5a345366":"code","2839b0d4":"code","f06a2ef0":"code","8e2a976a":"code","8b42eb75":"code","9b987e11":"code","fc6511fc":"code","ef0d3dee":"code","37282ffe":"code","87732027":"code","be2cef67":"code","b61e54a8":"code","7d4492bb":"code","4ea12ae7":"code","902f7545":"code","5a29e36e":"code","570583e8":"code","3141c485":"code","9973c47c":"code","20e8125e":"markdown","391f5ec1":"markdown","ae120a27":"markdown","bca33330":"markdown","5b3c6225":"markdown","dfe787c4":"markdown","0abe0421":"markdown","6f52a334":"markdown","946f20b6":"markdown","57794418":"markdown"},"source":{"e79abf54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib  inline\n\nimport numpy as np\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","aa67548e":"'''\nimport os \nimport zipfile\n# file name \nlocal_zip ='house-prices-advanced-regression-techniques.zip'\n#Class with methods to open, read, write, close, list zip files.\nzip_ref = zipfile.ZipFile(file=local_zip,mode='r')\n\nzip_ref.extractall('house-price')\n'''","43cb856f":"#keep_default_na=False to prevent panda to interpreting na NaN , Na IS No Basement \ndf = pd.read_csv('..\/input\/train.csv', keep_default_na=True,\n                 na_values=['-1.#IND', '1.#QNAN',\n                            '1.#IND', '-1.#QNAN','', '#N\/A',       \n                             'N\/A',  '#NA', 'NULL', 'NaN', '-NaN', 'nan', '-nan'])\n","5ee051c6":"df.head()","dec58f54":"df.drop(labels='Id',axis=1,inplace=True)","a0474d04":"df['SalePrice'].describe()\n# check min >0","4d4b5e9a":"sns.distplot(df['SalePrice'])\n# positive skewness","fcb43f1f":"print('skewness %f'%df['SalePrice'].skew())\nprint('Kurtosis %f'%df['SalePrice'].kurt())","e5e87d87":"plt.figure(figsize=(20,20))\ntest=df.corr()['SalePrice']\ntest.sort_values(ascending=False)","f12311d6":"#SalePriceis perpostional to OverallQual\ndata = pd.concat([df['SalePrice'], df['OverallQual']], axis=1)\nfig = sns.boxplot(x='OverallQual', y=\"SalePrice\", data=data)\n#plt.savefig('SalePricevsOverallQual')","2d0ccb46":"data = pd.concat([df['SalePrice'], df['GarageCars']], axis=1)\nfig = sns.boxplot(x='GarageCars', y=\"SalePrice\", data=data)","bd993c6c":"plt.figure(figsize=(12,8))\nsns.heatmap(df.corr())","275a5565":"df.isnull().sum()[df.isnull().sum()>0].sort_values(ascending=False)","721b2bde":"plt.figure(figsize=(19,10))\nsns.heatmap(data=df.isnull())\n#plt.savefig('Missing_value')","1673562f":"# remove 'MiscFeature','PoolQC','Fence','Alley'... very large number of value are missing \ndf=df.drop(labels=['MiscFeature','PoolQC','Fence','Alley','FireplaceQu','LotFrontage'],axis=1)\ndf.shape","d64035fc":"plt.figure(figsize=(19,10))\nsns.heatmap(data=df.isnull())\n# few null are still remaning","48581e19":"#y=df.isnull().sum()\n#y2 = pd.DataFrame(data=y)\n#y2[y2[0]>0]\n#All null value in decending order\ndf.isnull().sum()[df.isnull().sum()>0].sort_values(ascending=False)","3b0b71f8":"#correlation with SalePrice\na=df.corr()['SalePrice']\na.sort_values(ascending=False)[:20]","8cf1ed78":"df[a.sort_values(ascending=False)[:20].index].isnull().sum()","92c6528c":"# fill most frequent year:\n#Year garage was built\ndf['GarageYrBlt'].fillna(value=df['GarageYrBlt'].mode()[0],inplace=True)\ndf[a.sort_values(ascending=False)[:20].index].isnull().sum()\n#Masonry veneer area in square feet\ndf['MasVnrArea'].fillna(value=df['MasVnrArea'].mode()[0],inplace=True)\ndf[a.sort_values(ascending=False)[:20].index].isnull().sum()","c0a6d178":"# only string type value has null\nplt.figure(figsize=(19,10))\nsns.heatmap(data=df.isnull())","f7e9e10f":"#col which has null value\ntotal_null=df.isnull().sum()\n#All null value in decending order\nnull=df.isnull().sum()[total_null>0].sort_values(ascending=False)\n# take index\nindex=null.index\n# store in new file\nnew_null=df[index]\nnew_null.head()\n","6cb4f8c7":"sns.heatmap(new_null.isnull())","ce87e56b":"new_null.isnull().sum()","d423c2dd":"#Electrical only one null\nsns.countplot(x='Electrical',data=df)","5acde265":"df['Electrical'].fillna(value='SBrkr',inplace=True)","3ac49c8f":"# 8 missing value  , ,Masonry veneer type\nsns.countplot('MasVnrType',data=df)","c0e1134f":"sns.heatmap(new_null.isnull())","b5c8b029":"df['MasVnrType'].fillna(value='None',inplace=True)","10f863cd":"#BsmtQual: Evaluates the height of the basement\n#37 missing value\n#Ex\tExcellent (100+ inches)\n# Gd\tGood (90-99 inches)\n# TA\tTypical (80-89 inches)\n# Fa\tFair (70-79 inches)\n# Po\tPoor (<70 inches\n# NA\tNo Basement\nsns.countplot(x='BsmtQual',data=df)","0ac3662a":"\n# no Basement same for BsmtFinType2    38\n#BsmtExposure    38\n#BsmtFinType1    37\n#BsmtCond\ncol=['BsmtFinType1','BsmtCond','BsmtExposure','BsmtFinType2','BsmtQual'];\nfor i in col:\n    df[i].fillna(value='NA',inplace=True)","590b1115":"sns.countplot(x='GarageCond',data=df)","3929d890":"sns.countplot(x='GarageQual',data=df)","3037c9c1":"col=['GarageCond','GarageQual','GarageFinish','GarageType'];\nfor i in col:\n    df[i].fillna(value='NA',inplace=True)\n    ","8cc10ec3":"#col which has null value()\nnull_value=df[df.isnull().sum()[df.isnull().sum()>0].sort_values(ascending=False).index]\nnull_value.head()\n","57c7cb39":"# no null value \nplt.figure(figsize=(19,10))\nsns.heatmap(data=df.isnull())","9f6e894d":"plt.figure(figsize=(19,10))\nsns.heatmap(data=df.isnull())","fded4ebb":"plt.figure(figsize=(30,12))\nsns.heatmap(df.corr(),annot=True)","d37ecb5c":"#Multicollinearity (remove)\n\ndf.drop(labels=[\"2ndFlrSF\",\"1stFlrSF\",\"GarageArea\",\"TotRmsAbvGrd\",\"GarageYrBlt\"],axis=1,inplace=True)","dff8124f":"plt.figure(figsize=(30,12))\nsns.heatmap(df.drop(labels='SalePrice',axis=1).corr(),annot=True)","7c46d1de":"'''\ndf['MSZoning']=df['MSZoning'].map( {'A':0,'C':1,'FV':2,'I':3,'RH':4,'RL':5,'RP':6,'RM':7},na_action=True)\n\ndf['Street'] =df['Street'].map({'Grvl':0,'Pave':1})\ndf['LotShape']=df['LotShape'].map({'Reg':0,'IR1':1,'IR2':2,'IR3':3})\ndf['LandContour']= df['LandContour'].map({'Lvl':0,'Bnk':1,'HLS':2,'Low':3})\ndf['Utilities']=df['Utilities'].map({'AllPub':0,'NoSewr':1,'NoSeWa':2,'ELO':3})\ndf['LotConfig']=df['LotConfig'].map({'Inside':0,'Corner':1,'CulDSac':2,'FR2':3,'FR3':4})\n''' ","20e8312e":"test_df = pd.read_csv('..\/input\/test.csv')\ntest_df.shape\ntest_df.drop(labels='Id',axis=1,inplace=True)\n#no first element is null\ntest_df[df.columns[:68]].head()\n","9b186ce5":"test_df = pd.read_csv('..\/input\/test.csv')\ntest_df.shape\ntest_df.drop(labels='Id',axis=1,inplace=True)\ndf_u_col=df[df.columns[:68]].append(test_df[df.columns[:68]])\np=list(df_u_col['MSZoning'].unique())\n\nfor_nan =p[5]\nfor_nan","1a10ca7d":"p.remove(for_nan)\np","126b6f18":"# add test and train to find unique string in col\ntest_df = pd.read_csv('..\/input\/test.csv')\ntest_df.shape\ntest_df.drop(labels='Id',axis=1,inplace=True)\ndf_u_col=df[df.columns[:68]].append(test_df[df.columns[:68]])\n\n\ndefault_data={}\n#find unique string\nlist_col=df.columns\nfor col in list_col:\n    # only str colums\n\n    if(isinstance(df[col].iloc[1], str)):\n          print(col)\n    else:\n        continue\n    #find unique string\n    p=list(df_u_col[col].unique())\n    #check if null value \n    if (df_u_col[col].isnull().any()):\n        p.remove(for_nan)\n    print(p)\n    \n    l=len(p)\n    j=0\n    for j in range(l):\n        default_data.update({p.pop():j})\n       \n    #print(default_data)\n    \n    df[col]=df[col].map(default_data)\n    default_data={}    \n\n\n\nplt.figure(figsize=(19,10))\nsns.heatmap(data=df.isnull())\n\n\n\n","160df257":"df.isnull().sum()","41b578f5":"#df=pd.get_dummies(df)","3a16d84c":"df=df[df.corr().columns]\n","3cb5ca59":"plt.figure(figsize=(19,10))\nsns.heatmap(data=df.isnull())\n","8d0cd5f4":"print(df['SalePrice'].skew())\nprint(df['SalePrice'].kurt())","ecf8ef94":"\n#df['SalePrice']=np.log(np.log(df['SalePrice']))\n\nsns.distplot(np.log((df['SalePrice'])))\ndf['SalePrice']=np.log(df['SalePrice'])","5264e38b":"#find unique string","1657b2ae":"print(df['SalePrice'].skew())\nprint(df['SalePrice'].kurt())","befa87b5":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, confusion_matrix,classification_report\nfrom sklearn.linear_model import  Ridge, RidgeCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n\nX=df.drop(labels='SalePrice',axis=1)\ny=df['SalePrice']\n#X=X[X.columns[1:20]]\n\n\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.20)\n\n\ndef model_eval(model):\n    print(model)\n    X=x_train\n    y=y_train\n    print('train--data')\n    model_fit = model.fit(X, y)\n    R2 = cross_val_score(model_fit, X, y, cv=10 , scoring='r2').mean()\n    MSE = -cross_val_score(model_fit, X, y, cv=10 , scoring='neg_mean_squared_error').mean()\n    print('R2 Score:', R2, '|', 'MSE:', MSE)\n    X=x_test\n    y=y_test\n    print('test--data')\n    y_pred=model.predict(X)\n    R2 = cross_val_score(model_fit, X, y_test, cv=10 , scoring='r2').mean()\n    MSE = -cross_val_score(model_fit, X, y, cv=10 , scoring='neg_mean_squared_error').mean()\n    print('R2 Score:', R2, '|', 'MSE:', MSE)\n\nlr=LinearRegression()\nri = Ridge(alpha=0.1, normalize=False)\nricv = RidgeCV(cv=5)\ngdb = GradientBoostingRegressor(n_estimators=300,learning_rate=0.1)\n\nfor model in [lr,ri,ricv,gdb]:\n    print('model =={}'.format(model))\n    model_eval(model)\n    \n\n\nprint('on traning data')\n#lr.fit(x_train,y_train)\ny_pred=ri.predict(X)\nscore = cross_val_score(ri.fit(x_train,y_train), x_train, y_train, cv=10 , scoring='r2').mean()\nprint(score)\nX=df.drop(labels='SalePrice',axis=1)\ny=df['SalePrice']\n\ngdb.fit(X,y)","d757ae1f":"gdb.predict(X)","487b5b8a":"gdb.feature_importances_\nplt.figure(figsize=(30,12))\nplt.bar(range(len(gdb.feature_importances_)), gdb.feature_importances_)","8186cbe2":"# WORKING ON NEURAL NETWORK ","dd234154":"import tensorflow as tf\nmodel= tf.keras.models.Sequential(\n    layers=[\n        #input layer\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(units=10,activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=10,activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=10,activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=10,activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=10,activation=tf.nn.relu),\n       tf.keras.layers.Dense(units=10,activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=10,activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=10,activation=tf.nn.relu),\n       tf.keras.layers.Dense(units=10,activation=tf.nn.relu),\n        \n        # price\n        \n        \n        tf.keras.layers.Dense(units=1,activation=tf.nn.relu)\n    ]\n)\n\n","eb51c652":"model.compile(loss='mse', optimizer='adam',\n              metrics=['mse'])","030af248":"X=df.drop(labels='SalePrice',axis=1)\ny=df['SalePrice']\nhist=model.fit(x=np.array(X),y=np.array(y),batch_size=32,epochs=1000,verbose=2,validation_split=0.2,shuffle=True)\n\nhist","4da182a6":"y_predion=model.predict(np.array(X))","fffe677f":"score = r2_score(y_true=np.array(y),y_pred=y_predion)\nscore","3c45c622":"a=list(hist.params.values())\nsize=np.array(a)\nsize=size[1]\nsize","b2736e80":"y_predion","d2582c28":"fig = plt.figure(figsize=(25,12))\nloss=hist.history['loss']\nval_loss=hist.history['val_loss']\ny1=np.arange(1,size+1)\nplt.plot(y1,loss,'b',label='train')\nplt.plot(y1,val_loss,'r',label='val')\nplt.xlabel('epoch')\nplt.ylabel('loss')\n#plt.xlim(0,3900)\nplt.legend()\n\nplt.legend()","8ac5911c":"import xgboost\nfrom xgboost import XGBRegressor\nX=df.drop(labels='SalePrice',axis=1)\ny=df['SalePrice']\n#X=X[X.columns[1:20]]\n\n\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.20)\n\nxgb = XGBRegressor(n_estimators=500,learning_rate=0.1)\n\nmodel_eval(xgb)","4b175fc2":"from xgboost import plot_importance\nf ,ax =plt.subplots(figsize=(30,30))\n\nplot_importance(xgb,ax=ax,importance_type='weight')","aed1cd53":"x_test.columns","6e773717":"xgb.feature_importances_","ca05bef2":"importance =list(zip(x_test.columns,xgb.feature_importances_))\nimportance\nimportance.sort(key= lambda t : t[1])\nimportance","6e5f146e":"importance =importance[10:]","d4cd356c":"name , name2 =map(list,zip(*importance))\nname","dd724485":"x_train=x_train[name]\nx_test =x_test[name]\nimport xgboost\nfrom xgboost import XGBRegressor\nxgb = XGBRegressor(n_estimators=500,learning_rate=0.1)\nX=x_train\ny=y_train\nprint('train--data')\nxgb = xgb.fit(X, y)\nR2 = cross_val_score(xgb, X, y, cv=10 , scoring='r2').mean()\nMSE = -cross_val_score(lr, X, y, cv=10 , scoring='neg_mean_squared_error').mean()\nprint('R2 Score:', R2, '|', 'MSE:', MSE)\nX=x_test\ny=y_test\nprint('test--data')\ny_pred=xgb.predict(X)\nR2 = cross_val_score(xgb, X, y_test, cv=10 , scoring='r2').mean()\nMSE = -cross_val_score(xgb, X, y, cv=10 , scoring='neg_mean_squared_error').mean()\nprint('R2 Score:', R2, '|', 'MSE:', MSE)\nprint('full--data')\nX=df.drop(labels='SalePrice',axis=1)[name]\ny=df['SalePrice']\ny_pred=xgb.predict(X)\nR2 = cross_val_score(xgb, X, y, cv=10 , scoring='r2').mean()\nMSE = -cross_val_score(xgb, X, y, cv=10 , scoring='neg_mean_squared_error').mean()\nprint('R2 Score:', R2, '|', 'MSE:', MSE)\n","8f14a50c":"from xgboost import plot_importance\nf ,ax =plt.subplots(figsize=(30,30))\nplot_importance(xgb,ax=ax)","53a1a624":"xgb.feature_importances_","b0b87d78":"xgb.predict(X)","a9ae6fe2":"print(df['SalePrice'].skew())\nprint(df['SalePrice'].kurt())","48f20ec5":"df['SalePrice'].isnull().sum()","6145f06d":"df.head()","bce829fe":"test_df = pd.read_csv('..\/input\/test.csv')\ntest_df.shape\ntest_df.drop(labels='Id',axis=1,inplace=True)","e97bb355":"test_df=test_df.drop(labels=['MiscFeature','PoolQC','Fence','Alley','FireplaceQu','LotFrontage'],axis=1)","1f93c148":"test_df.corr().index","e9215cdf":"test_df.shape","c985bd56":"# fill most frequent year:\n#Year garage was built\ntest_df['GarageYrBlt'].fillna(value=test_df['GarageYrBlt'].mode()[0],inplace=True)\n#tMasonry veneer area in square feet\ntest_df['MasVnrArea'].fillna(value=test_df['MasVnrArea'].mode()[0],inplace=True)","4f7d98bc":"sns.heatmap(test_df.isnull())","2c50f74c":"#Multicollinearity (remove)\ntest_df.drop(labels=[\"GarageArea\",\"TotRmsAbvGrd\",\"2ndFlrSF\",\"1stFlrSF\",\"GarageYrBlt\"],axis=1,inplace=True)","f1a4be2c":"#test_df=test_df[test_df.corr().columns]\n\n#test_df = pd.get_dummies(test_df)\nsns.heatmap(test_df.isnull())","56594645":"test_df.shape","1e636086":"X.shape","f8001e6e":"test_df['BsmtHalfBath'].fillna(value=test_df['BsmtHalfBath'].mode()[0],inplace=True)\ntest_df['GarageCars'].fillna(value=test_df['GarageCars'].mode()[0],inplace=True)\ntest_df['BsmtFullBath'].fillna(value=test_df['BsmtFullBath'].mode()[0],inplace=True)\ntest_df['BsmtFinSF1'].fillna(value=test_df['BsmtFinSF1'].mode()[0],inplace=True)\ntest_df['BsmtFinSF2'].fillna(value=test_df['BsmtFinSF2'].mode()[0],inplace=True)\ntest_df['BsmtUnfSF'].fillna(value=test_df['BsmtUnfSF'].mode()[0],inplace=True)\ntest_df['TotalBsmtSF'].fillna(value=test_df['TotalBsmtSF'].mode()[0],inplace=True)\n","6e3b3c9e":"sns.countplot('Exterior2nd',data=test_df)","84916335":"a=test_df.isnull().sum()\na.sort_values(ascending=False)[:20]\n","5a345366":"col =['MasVnrType','MSZoning','Functional','Utilities','SaleType','Exterior1st','KitchenQual','Exterior2nd']\nfor col_i in col:\n    test_df[col_i].fillna(value=test_df[col_i].mode()[0],inplace=True)\n","2839b0d4":"a=test_df.isnull().sum()\na.sort_values(ascending=False)[:20]","f06a2ef0":"plt.figure(figsize=(22,8))\n\ncol=['GarageCond','GarageQual','GarageFinish','GarageType'];\nfor i in col:\n    test_df[i].fillna(value='NA',inplace=True)\n    col=['BsmtFinType1','BsmtCond','BsmtExposure','BsmtFinType2','BsmtQual'];\nfor i in col:\n    test_df[i].fillna(value='NA',inplace=True)\nsns.heatmap(test_df.isnull())","8e2a976a":"len(test_df.columns)","8b42eb75":"\n# add test and train to find unique string in col\ndf =test_df\ntest_df = pd.read_csv('..\/input\/train.csv')\ndf_u_col=df[df.columns[:68]].append(test_df[df.columns[:68]])\ndefault_data={}\n#find unique string\nlist_col=df.columns\n\n\nfor col in list_col:\n    # only str colums\n\n    if(isinstance(df[col].iloc[1], str)):\n          print(col)\n    else:\n        continue\n    #find unique string\n    p=list(df_u_col[col].unique())\n    #check if null value \n    if (df_u_col[col].isnull().any()):\n        p.remove(for_nan)\n    print(p)\n    \n    l=len(p)\n    j=0\n    for j in range(l):\n        default_data.update({p.pop():j})\n       \n    #print(default_data)\n    \n    df[col]=df[col].map(default_data)\n    default_data={}    \n\n\n\nplt.figure(figsize=(19,10))\nsns.heatmap(data=df.isnull())\n\ntest_df=df","9b987e11":"\na=test_df.isnull().sum()\na.sort_values(ascending=False)[:20]","fc6511fc":"test_pred = model.predict(test_df)\ntest_df.shape","ef0d3dee":"predicted_prices=np.exp(test_pred)\npredicted_prices.reshape(1459)","37282ffe":"for_id = pd.read_csv('..\/input\/test.csv')\n\nmy_submission = pd.DataFrame({'Id':for_id.Id, 'SalePrice': predicted_prices.reshape(1459)})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_nn.csv', index=False)","87732027":"test_pred =gdb.predict(test_df)\npredicted_prices=np.exp(test_pred)\npredicted_prices.reshape(1459)","be2cef67":"for_id = pd.read_csv('..\/input\/test.csv')\n\nmy_submission = pd.DataFrame({'Id':for_id.Id, 'SalePrice': predicted_prices.reshape(1459)})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_gdb.csv', index=False)","b61e54a8":"test_pred =xgb.predict(test_df[name])\npredicted_prices=np.exp(test_pred)\npredicted_prices.reshape(1459)","7d4492bb":"for_id = pd.read_csv('..\/input\/test.csv')\n\nmy_submission = pd.DataFrame({'Id':for_id.Id, 'SalePrice': predicted_prices.reshape(1459)})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_xgb.csv', index=False)","4ea12ae7":"test_pred =lr.predict(test_df)\npredicted_prices=np.exp(test_pred)\npredicted_prices.reshape(1459)","902f7545":"for_id = pd.read_csv('..\/input\/test.csv')\n\nmy_submission = pd.DataFrame({'Id':for_id.Id, 'SalePrice': predicted_prices.reshape(1459)})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_lr.csv', index=False)","5a29e36e":"test_pred =ri.predict(test_df)\npredicted_prices=np.exp(test_pred)\npredicted_prices.reshape(1459)","570583e8":"for_id = pd.read_csv('..\/input\/test.csv')\n\nmy_submission = pd.DataFrame({'Id':for_id.Id, 'SalePrice': predicted_prices.reshape(1459)})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_ri.csv', index=False)","3141c485":"test_pred =ricv.predict(test_df)\npredicted_prices=np.exp(test_pred)\npredicted_prices.reshape(1459)","9973c47c":"for_id = pd.read_csv('..\/input\/test.csv')\n\nmy_submission = pd.DataFrame({'Id':for_id.Id, 'SalePrice': predicted_prices.reshape(1459)})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_ricv.csv', index=False)","20e8125e":"# change string value to numerical","391f5ec1":"#by plotting graph for \n#BsmtQual 38\n#BsmtFinType2    38\n#BsmtExposure    38\n#BsmtFinType1    37\n#BsmtCond\neach has no record of 'No Basement'  so NaN can be 'No Basement' ","ae120a27":"# Garage missing value\n#GarageCond      81\n#GarageQual      81\n#GarageFinish    81\n#GarageType      81\n","bca33330":"# create submission file","5b3c6225":"# checking Missing  value(Nan)","dfe787c4":"no detail about NA\tNo Garage case \nnake nan as Na(No Garage)","0abe0421":"https:\/\/stats.stackexchange.com\/questions\/181\/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\/1097#1097","6f52a334":"# Convert string to int","946f20b6":"->OverallQual Rates the overall material and finish of the house(1-10 rating)\n->GrLivArea  above (ground) living area square feet\n->GarageCars: Size of garage in car capacity\n->GarageArea: Size of garage in square feet\n->GarageQual: Garage quality","57794418":"**xgboost**"}}