{"cell_type":{"97f3bc91":"code","788962ba":"code","cb70140b":"code","f2bdbbd4":"code","e77c3f4f":"code","a6514018":"code","1173df89":"code","0cc0ad79":"code","32ee07e4":"code","6abde1e7":"code","180d53c1":"code","40b66ad7":"code","09640d92":"code","a5b554e5":"markdown","d6f20377":"markdown","f7c976ab":"markdown"},"source":{"97f3bc91":"import numpy as np\nimport pandas as pd \nimport matplotlib.pylab as plt\nimport tensorflow as tf\n\nfrom keras.applications.vgg16 import VGG16\n\n#Importing libraries for CNN architecture models,linear algebra and data visualization.","788962ba":"import scipy.io as sio\n#read data from .mat file\ntrain_data = sio.loadmat('..\/input\/svhndataset\/train_32x32.mat')\ntest_data = sio.loadmat('..\/input\/svhndataset\/test_32x32.mat')\nextra_data = sio.loadmat('..\/input\/svhndataset\/extra_32x32.mat')\n\n#X are the pixels of the images and y are the corresponding labels,which means that this is supervised learning data.\nX_train, y_train = train_data['X'], train_data['y']\nX_test, y_test = test_data['X'], test_data['y']\nX_extra, y_extra = extra_data['X'], extra_data['y']\n\n# defining classes as it is a classfication problem\nclasses = [0,1,2,3,4,5,6,7,8,9]\nnum_classes = 10\nno_classes=11\n","cb70140b":"#Here we are transforming the input data so that each instance of data represents pixels values of each image in all of three channels(RGB)\n#which will act as an input to first layer of CNN.\nX_train = np.transpose(X_train,(3,0,1,2))\nX_test = np.transpose(X_test,(3,0,1,2))\nX_extra = np.transpose(X_extra,(3,0,1,2))\n\n#we add the extra data with the training set\nX_train = np.concatenate([X_train, X_extra])\ny_train = np.concatenate([y_train, y_extra])\n\n#Here we normalize the pixel values to the same range so that model can perform better.\nX_train = X_train.astype('float32') \/ 255\nX_test = X_test.astype('float32') \/ 255","f2bdbbd4":"from keras.utils import to_categorical\n\n#Here we convert the label to category from 1-10 to match with CNN format\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\n","e77c3f4f":"#Resnet50 Model\nfrom tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization\nmodel = Sequential()\nmodel.add(ResNet50(include_top=True, pooling='avg', weights=None,input_shape=X_train[0].shape, classes=no_classes))\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',      \n              metrics=['acc'])","a6514018":"#VGG16 model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n\nmodel = Sequential()\nmodel.add(VGG16(include_top=True, weights=None, input_shape=X_train[0].shape, pooling='max', classes=no_classes))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',      \n              metrics=['acc'])","1173df89":"#VGG19 model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n\nfrom keras.applications.vgg19 import VGG19\nmodel = Sequential()\nmodel.add(VGG19(include_top=True, weights=None, input_shape=X_train[0].shape, pooling='max', classes=no_classes))\n\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',      \n              metrics=['acc'])","0cc0ad79":"# CNN model with 2 convolutional layers,one pooling layer and fully connected layer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=4, activation='relu', input_shape=X_train[0].shape))\nmodel.add(MaxPooling2D(pool_size=3))\nmodel.add(Conv2D(64, kernel_size=4, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(len(y_train[0]), activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',      \n              metrics=['acc'])","32ee07e4":"#it shows the architecture of the model\nmodel.summary()","6abde1e7":"#for CNN network training\n#Here model is being trained on the data with batch size 200 and epochs 10 and data split 10%\nmodel_history = model.fit(X_train, y_train, batch_size=200, epochs=10, validation_split = 0.1)","180d53c1":"#for VGG16 and VGG19 training and Resnet 50 training\n#Here model is being trained on the data with batch size 200 and epochs 10 and data split 10%\nmodel_history = model.fit(X_train, y_train, batch_size=500, epochs=5, validation_split = 0.2)","40b66ad7":"#Here we plot the performance of the model on the training and validation data.\nplt.plot(model_history.history[\"acc\"])\nplt.plot(model_history.history['val_acc'])\nplt.title('Accuracy of ResNet50 Model')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['Train data', 'Validation Data'], loc='bottom right')\nplt.show()","09640d92":"#Here we calculate the accuracy of the model\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])","a5b554e5":"Depending upon which model you chose, train that model.","d6f20377":"Below are the four models:\n* Resnet50\n* VGG16\n* VGG19\n* CNN\n\nexecute anyone model at a time.","f7c976ab":"We can safely say that by increasing the model layers too much degrades our model performance maybe?"}}