{"cell_type":{"29fe2893":"code","1b2b9d00":"code","cec61d6f":"code","f2c676b7":"code","5f5cd9c4":"code","7141e04b":"code","0f1cb2b8":"code","1986213f":"code","16a28fef":"code","a18586e8":"code","e71fbb12":"code","3c0f2dcf":"code","73dd39d9":"code","01120472":"markdown"},"source":{"29fe2893":"!pip install efficientnet_pytorch","1b2b9d00":"import torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport cv2\nimport numpy as np\nimport time\nimport random\nfrom tqdm import tqdm as tqdm\nimport pandas as pd\nimport os\n\n\nfrom efficientnet_pytorch import EfficientNet\n\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms\nfrom albumentations.pytorch import ToTensorV2\nfrom torchvision import models\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)","cec61d6f":"cfg = {\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'epochs':25,\n    'batch_size':42,\n    'lr':0.0001,\n    'input_size':256,\n    \n}\n\nbackbone = models.resnet50(pretrained=True)\nmodules = list(backbone.children())[:-2]\nbackbone = nn.Sequential(*modules)\nprint(backbone)\n","f2c676b7":"class CLASSIFIER(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.effn = backbone\n        self.average = nn.AvgPool2d((8,8))\n        self.flatten = nn.Flatten()\n    def forward(self,x):\n        x = self.effn(x)\n        x = self.average(x)\n        x = self.flatten(x)\n        return x\n    \nclass MODEL(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = CLASSIFIER()\n        if cfg['device']=='cuda':\n            self.backbone.load_state_dict(torch.load('..\/input\/simsaim-weights\/I_am_trained_14.pt'))\n        else:\n            self.backbone.load_state_dict(torch.load('..\/input\/simsaim-weights\/I_am_trained_14.pt',map_location='cpu'))\n        self.dense = nn.Linear(2048,5)\n    def forward(self,x):\n        x = self.backbone(x)\n        x = self.dense(x)\n        return x\n\nmodel = MODEL()\nx = torch.randn((1,3,256,256))\ny = model(x)\nprint(y.size())","5f5cd9c4":"class CASSAVA(Dataset):\n    def __init__(self,\n                 imagenames,\n                 csv,\n                 root_dir,\n                 input_size=cfg['input_size'],\n                 transforms=None,\n                 train=True):\n        self.imagenames = imagenames\n        self.csv = csv\n        self.root_dir = root_dir\n        self.input_size = input_size\n        self.transforms = transforms\n        self.train = train\n    def __len__(self):\n        return len(imagenames)\n    def get_onehot(self,label):\n        onehot = np.zeros(5)\n        onehot[label] = 1\n        return onehot\n    def __getitem__(self,idx):\n        imagename = self.imagenames[idx]\n        label = self.csv[self.csv['image_id']==imagename]['label']\n        label = self.get_onehot(label)\n        image = cv2.imread(self.root_dir+'\/'+imagename)\n        image = cv2.resize(image,(self.input_size,self.input_size))\n        if self.transforms is not None:\n            image_aug = self.transforms(image=image)['image']\n        else:\n            image_aug = image\n        image_aug = normalize_and_to_tensor(image_aug)\n        label = torch.from_numpy(label)\n        return image_aug,label","7141e04b":"train_dir= '..\/input\/cassava-leaf-disease-classification\/train_images'\ntest_dir = '..\/input\/cassava-leaf-disease-classification\/test_images'\nimagenames = [name for name in os.listdir(train_dir)]\ncsv = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\nprint(csv.head(10))\nprint(csv['label'].unique())","0f1cb2b8":"t_dataset = CASSAVA(imagenames,csv,train_dir,transforms = None)\ntrain_loader = DataLoader(dataset=t_dataset, batch_size=cfg['batch_size'], shuffle=True, num_workers=0)","1986213f":"def normalize_and_to_tensor(img):\n    transform = Compose([Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n                       ToTensorV2(p=1.0)],p=1.0)\n    return transform(image=img)['image']\ntotal_features = []\ny = []\nmodel.to(cfg['device'])\nfor X,Y in tqdm(train_loader):\n    X = X.to(cfg['device'])\n    y = y + list(np.argmax(Y.numpy(),axis=-1))\n    features = model(X)\n    #print(features.size())\n    features = features\/(features.norm(dim=-1)[:,None]+1e-6)\n    features = features.detach().cpu().numpy()\n    features = list(features)\n    total_features+=features","16a28fef":"total_features = np.asarray(total_features)\nprint(total_features.shape)","a18586e8":"print(len(y))","e71fbb12":"from sklearn.manifold import TSNE\nX_embedded = TSNE(n_components=2,n_iter=1000,verbose=1).fit_transform(total_features)","3c0f2dcf":"color_dict = dict({0:'brown',\n                  1:'green',\n                  2: 'orange',\n                  3: 'black',\n                   4: 'dodgerblue'})\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\ndf_subset = {}\ny = np.asarray(y)\ndf_subset['tsne-2d-one'] = X_embedded[:,0]\ndf_subset['tsne-2d-two'] = X_embedded[:,1]\ndf_subset['y'] = y\ndf_subset = pd.DataFrame.from_dict(df_subset)\nplt.figure(figsize=(16,10))\nsns.scatterplot(\n    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n    hue='y',\n    data=df_subset,\n    legend=\"full\",\n    palette=color_dict,\n    alpha=0.3\n)","73dd39d9":"'''import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\ndf = {}\ny = np.asarray(y)\ndf['tsne-2d-one'] = X_embedded[:,0]\ndf['tsne-2d-two'] = X_embedded[:,1]\ndf['tsne-2d-three'] = X_embedded[:,2]\ndf['y'] = y\nax = plt.figure(figsize=(16,10)).gca(projection='3d')\nax.scatter(\n    xs=df[\"tsne-2d-one\"], \n    ys=df[\"tsne-2d-two\"], \n    zs=df[\"tsne-2d-three\"], \n    c=df[\"y\"], \n    cmap='tab10'\n)\nax.set_xlabel('tsne-2d-one')\nax.set_ylabel('tsne-2d-two')\nax.set_zlabel('tsne-2d-three')\nplt.show()'''","01120472":"## Visualizing the Representations:\nI have trained a ResNet50 based architecture to learn meaningful representations from our data [here](https:\/\/www.kaggle.com\/saimanojakondi\/simsaim\/notebook) using SIMSAIM. This notebook uses T-SNE to extract important features and visualize the embeddings."}}