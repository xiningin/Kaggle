{"cell_type":{"604267ae":"code","1b32ff2e":"code","a7d7d26e":"code","3350fb0d":"code","ea0f434b":"code","29c70ba8":"code","ce1021cf":"code","1cc43868":"code","37a3824f":"code","6a3f0cf6":"code","83d79fbf":"code","200d089b":"code","8328b6a5":"code","8de7ce96":"code","02795de7":"code","7e6b15e3":"code","10e424d7":"code","01cb5322":"code","3be2a44c":"code","27a2fc45":"markdown","2711ab87":"markdown","21dc7e04":"markdown","410ef7ed":"markdown","cf1103dd":"markdown","cad4e83a":"markdown","3e085dbc":"markdown","638f7b3f":"markdown","c7d98b8e":"markdown"},"source":{"604267ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","1b32ff2e":"from sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","a7d7d26e":"df = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')","3350fb0d":"sns_plot = sns.pairplot(df, hue='Species')","ea0f434b":"df.head()","29c70ba8":"df.shape\nX = df.iloc[:, 1:5]\ny = df[['Species']]","ce1021cf":"X.head()","1cc43868":"y.head()","37a3824f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)","6a3f0cf6":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","83d79fbf":"classifier = KNeighborsClassifier()\nclassifier.fit(X_train, y_train)","200d089b":"pred = classifier.predict(X_test)","8328b6a5":"accuracy = accuracy_score(y_test, pred)\nprint(accuracy)","8de7ce96":"error = []\nk_value = []","02795de7":"for k in range(40):\n    k_value.append(k+1)\n    # Using KNN\n    knn = KNeighborsClassifier(n_neighbors=k+1)\n    print(knn.fit(X_train, y_train))\n    pred = knn.predict(X_test)\n\n    error_ = 1 - accuracy_score(y_test, pred)\n    error.append(error_)\n\n    # %%\n    # confusion_matrix_ = confusion_matrix(y_test, pred)\n    # print(confusion_matrix_)\n    # classification_report_ = classification_report(y_test, pred)\n    # print(classification_report_)","7e6b15e3":"# %%\nplt.plot(k_value, error)\nplt.xlabel('K value')\nplt.ylabel('Error')\nplt.show()","10e424d7":"def knn_fun(k):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    print(knn.fit(X_train, y_train))\n    pred = knn.predict(X_test)\n\n    error_ = 1 - accuracy_score(y_test, pred)\n    error.append(error_)\n\n    confusion_matrix_ = confusion_matrix(y_test, pred)\n    print(confusion_matrix_)\n    classification_report_ = classification_report(y_test, pred)\n    print(classification_report_)","01cb5322":"error_np = np.array(error)\nk_value_np = np.array(k_value)\n\nerror_min_index = error_np.argmin().item() # numpy int to python int\nk_value_ = k_value_np[error_min_index]\n\n#%%\n# for minimum error\nprint('knn for k={}'.format(k_value_, knn_fun(k_value_)))","3be2a44c":"print('Best K_value is {}.'.format(k_value_))","27a2fc45":"## Importing the libraries","2711ab87":"## Importing the dataset","21dc7e04":"## Plot Error and k_value","410ef7ed":"**EDA**","cf1103dd":"## Splitting into train and test sets","cad4e83a":"## Let's find best k_value for KNeighborsClassifier().","3e085dbc":"**Predicted Value**","638f7b3f":"## KNeighborsClassifier model","c7d98b8e":"## Accuracy"}}