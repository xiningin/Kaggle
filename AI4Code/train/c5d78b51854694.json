{"cell_type":{"b84642bd":"code","3236e438":"code","47301c46":"code","e117df5e":"code","bdcbaa00":"code","43cba579":"code","665a5dd4":"code","9d3a0b20":"code","f26dc2b0":"code","afe30681":"code","8b8809e3":"code","c831fe79":"code","d0740048":"code","1a7d0f45":"code","98533497":"code","3ff44116":"code","7fab2133":"code","21d11741":"code","a9205b89":"code","5e8ba89b":"code","c3c3c82e":"code","e8cb7799":"code","0ee6ccf1":"code","d49b28ac":"code","0a8502a4":"code","7df24278":"code","644ddb94":"code","2f275a04":"markdown","eb4cc1fc":"markdown","0b45e4f0":"markdown","b691a589":"markdown","aa93b0ec":"markdown"},"source":{"b84642bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3236e438":"# Lets import the csv file in pandas dataframe first\ndata = pd.read_csv('\/kaggle\/input\/ttc4900\/7allV03.csv', encoding='utf-8')","47301c46":"#check data\ndata.head()","e117df5e":"print(len(data))","bdcbaa00":"#learn unique category \nprint(data.category.unique())","43cba579":"# convert string labels to integers for bert classification\ndata['labels'] = pd.factorize(data.category)[0]","665a5dd4":"data.head()","9d3a0b20":"#data split for train and test\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(data, test_size=0.2, random_state=42)","f26dc2b0":"train.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)","afe30681":"train.head()","8b8809e3":"test.head()","c831fe79":"#Data prepare for fasttext format for train\ntrain[\"label_format\"]=0\nfor i in range(len(train)):\n    train.label_format[i]=\"__label__\"+str(train.category[i])+\" \"+str(train.text[i])","d0740048":"#Data prepare for fasttext format for test\ntest[\"label_format\"]=0\nfor i in range(len(test)):\n    test.label_format[i]=\"__label__\"+str(test.category[i])+\" \"+str(test.text[i])","1a7d0f45":"train.label_format.to_csv('fasttext_train.txt',index=None,header=None)","98533497":"test.label_format.to_csv('fasttext_test.txt',index=None,header=None)","3ff44116":"import fasttext","7fab2133":"#train classifier model\nmodel = fasttext.train_supervised('fasttext_train.txt',epoch=50,lr=0.05,label_prefix='__label__',dim=300)","21d11741":"#test fasttext model\nmodel.test('fasttext_test.txt')","a9205b89":"result = model.test('fasttext_train.txt')\nvalidation = model.test('fasttext_test.txt')\n\n\n# DISPLAY ACCURACY OF TRAINED MODEL\ntext_line =  \"accuracy:\" + str(result[1])  + \",validation:\" + str(validation[1]) + '\\n' \nprint(text_line)","5e8ba89b":"!pip install simpletransformers","c3c3c82e":"from simpletransformers.classification import ClassificationModel","e8cb7799":"#for bert text column should be string and label column should be int\ntrain[\"text\"]=train[\"text\"].apply(lambda r: str(r))\ntrain['labels']=train['labels'].astype(int)","0ee6ccf1":"#create model with turkish bert\nmodel = ClassificationModel('bert', 'dbmdz\/bert-base-turkish-uncased', num_labels=7, \n                            args={'reprocess_input_data': True, 'overwrite_output_dir': True, 'num_train_epochs': 3, \"train_batch_size\": 64 , \"fp16\":False, \"output_dir\": \"bert_model\"})","d49b28ac":"#train model\nmodel.train_model(train)","0a8502a4":"result, model_outputs, wrong_predictions = model.eval_model(test)","7df24278":"predictions = model_outputs.argmax(axis=1)\nactuals = test.labels.values","644ddb94":"from sklearn import metrics\nprint(metrics.classification_report(actuals, predictions, digits=3))","2f275a04":"I used this notebook in this work, thanks\n[https:\/\/www.kaggle.com\/ayhanc\/bert-multilingual-for-turkish-text-classification](http:\/\/) \n\nExamine simpletransformers in detail from github\n[https:\/\/github.com\/ThilinaRajapakse\/simpletransformers](http:\/\/)","eb4cc1fc":"I compared Bert and Fasttext classifiers and achieved higher success with Bert :)","0b45e4f0":"Bert Text Classification with Bert Turkish Model","b691a589":"[https:\/\/fasttext.cc\/docs\/en\/supervised-tutorial.html](http:\/\/)","aa93b0ec":"Fasttext Text Classification\n"}}