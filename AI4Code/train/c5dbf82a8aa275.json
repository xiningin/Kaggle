{"cell_type":{"48ffa2fb":"code","2f66c53a":"code","ef4ef576":"code","96e32e0c":"code","f44c7708":"code","d6a7c15e":"code","39931dc4":"code","766712ca":"code","dabd3525":"code","b88c948d":"code","4625b89c":"code","e1e1be96":"code","7293a679":"markdown","59975bf4":"markdown","50b2474f":"markdown","4f1e0e6e":"markdown","7609e402":"markdown"},"source":{"48ffa2fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","2f66c53a":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchtext\nimport nltk\nimport time\nfrom datetime import timedelta\nimport numpy as np\nfrom sklearn import metrics\n\n\ndef save_model(model, model_path):\n    \"\"\"Save model.\"\"\"\n    torch.save(model.state_dict(), model_path)\n\n\ndef load_model(model, model_path, use_cuda=False):\n    \"\"\"Load model.\"\"\"\n    map_location = 'cpu'\n    if use_cuda and torch.cuda.is_available():\n        map_location = 'cuda:0'\n    model.load_state_dict(torch.load(model_path, map_location))\n    return model","ef4ef576":"class TextCNN(nn.Module):\n    \"\"\"Text classification model by character CNN, the implementation of paper\n    'Yoon Kim. 2014. Convolution Neural Networks for Sentence\n    Classification.'\n    \"\"\"\n\n    def __init__(self, args):\n        super(TextCNN, self).__init__()\n\n        vocab_size = args[\"vocab_size\"]\n        pretrained_embed = args[\"pretrained_embed\"]\n        padding_idx = args[\"padding_idx\"]\n        num_classes = 1\n        kernel_nums = [100, 100, 100]\n        kernel_sizes = [3, 4, 5]\n        embed_dim = 300\n        hidden_dim = 100\n        drop_prob = 0.5\n\n        # no support for pre-trained embedding currently\n        if pretrained_embed is None:\n            self.embed = nn.Embedding(vocab_size, embed_dim)\n        else:\n            self.embed = nn.Embedding.from_pretrained(\n                pretrained_embed, freeze=False)\n        self.embed.padding_idx = padding_idx\n        self.convs = nn.ModuleList(\n            [nn.Conv1d(embed_dim, kn, ks)\n             for kn, ks in zip(kernel_nums, kernel_sizes)])\n        self.fc = nn.Linear(sum(kernel_nums), hidden_dim)\n        self.drop = nn.Dropout(drop_prob)\n        self.out = nn.Linear(hidden_dim, num_classes)\n\n        self.loss = nn.BCEWithLogitsLoss()\n\n    def forward(self, word_seq):\n        # embed\n        e = self.drop(self.embed(word_seq))  # [b,msl]->[b,msl,e]\n\n        # conv and pool, [b,msl,e]->[b,h,msl]\n        e = e.transpose(1, 2)  # [b,msl,e]->[b,e,msl]\n        ps = []\n        for conv in self.convs:\n            c = conv(e)  # [b,e,msl]->[b,h,msl-k]\n            p = F.max_pool1d(c, kernel_size=c.size(-1)).squeeze(-1)  # [b,h]\n            ps.append(p)\n        p = torch.cat(ps, dim=1)  # [b,h]\n\n        # feed-forward, [b,h]->[b]\n        f = self.drop(self.fc(p))\n        logits = self.out(f).squeeze(-1)\n\n        return logits\n\n\nclass Trainer(object):\n    \"\"\"Trainer.\"\"\"\n\n    def __init__(self, **kwargs):\n        self.n_epochs = kwargs[\"epochs\"]\n        self.batch_size = kwargs[\"batch_size\"]\n        self.validate = kwargs[\"validate\"]\n        self.save_best_dev = kwargs[\"save_best_dev\"]\n        self.use_cuda = kwargs[\"use_cuda\"]\n        self.print_every_step = kwargs[\"print_every_step\"]\n        self.optimizer = kwargs[\"optimizer\"]\n        self.model_path = kwargs[\"model_path\"]\n        self.eval_metrics = kwargs[\"eval_metrics\"]\n\n        self._best_accuracy = 0.0\n\n        self.device = 'cpu'\n        if torch.cuda.is_available() and self.use_cuda:\n            self.device = 'cuda:0'\n\n    def train(self, network, train_data, dev_data=None):\n        # transfer model to gpu if available\n        network = network.to(self.device)\n\n        # define batch iterator\n        train_iter = torchtext.data.Iterator(\n            dataset=train_data, batch_size=self.batch_size,\n            train=True, shuffle=True, sort=False,\n            device=self.device)\n\n        # define Tester over dev data\n        if self.validate:\n            default_valid_args = {\n                \"batch_size\": max(8, self.batch_size \/\/ 10),\n                \"use_cuda\": self.use_cuda}\n            validator = Tester(**default_valid_args)\n\n        start = time.time()\n        for epoch in range(1, self.n_epochs + 1):\n            # turn on network training mode\n            network.train()\n\n            # initialize iterator\n            train_iter.init_epoch()\n\n            # one forward and backward pass\n            self._train_step(\n                train_iter, network, start=start,\n                n_print=self.print_every_step, epoch=epoch)\n\n            # validation\n            if self.validate:\n                if dev_data is None:\n                    raise RuntimeError(\n                        \"self.validate is True in trainer, \"\n                        \"but dev_data is None.\"\n                        \" Please provide the validation data.\")\n                eval_results = validator.test(network, dev_data)\n\n                if self.save_best_dev and self.best_eval_result(eval_results):\n                    save_model(network, self.model_path)\n                    print(\"Saved better model selected by validation.\")\n\n    def _train_step(self, data_iterator, network, **kwargs):\n        \"\"\"Training process in one epoch.\n        \"\"\"\n        step = 0\n        for batch in data_iterator:\n            text, target = batch.text, batch.target\n\n            self.optimizer.zero_grad()\n            logits = network(text)\n            loss = network.loss(logits, target.float())\n            loss.backward()\n            self.optimizer.step()\n\n            if kwargs[\"n_print\"] > 0 and step % kwargs[\"n_print\"] == 0:\n                end = time.time()\n                diff = timedelta(seconds=round(end - kwargs[\"start\"]))\n                print_output = \"[epoch: {:>3} step: {:>4}]\" \\\n                    \" train loss: {:>4.6} time: {}\".format(\n                        kwargs[\"epoch\"], step, loss.item(), diff)\n                print(print_output)\n\n            step += 1\n\n    def best_eval_result(self, eval_results):\n        \"\"\"Check if the current epoch yields better validation results.\n\n        :param eval_results: dict, format {metrics_name: value}\n        :return: bool, True means current results on dev set is the best.\n        \"\"\"\n        assert self.eval_metrics in eval_results, \\\n            \"Evaluation doesn't contain metrics '{}'.\" \\\n            .format(self.eval_metrics)\n\n        accuracy = eval_results[self.eval_metrics]\n        if accuracy > self._best_accuracy:\n            self._best_accuracy = accuracy\n            return True\n        else:\n            return False\n\n\nclass Tester(object):\n    \"\"\"Tester.\"\"\"\n\n    def __init__(self, **kwargs):\n        self.batch_size = kwargs[\"batch_size\"]\n        self.use_cuda = kwargs[\"use_cuda\"]\n        self.device = 'cpu'\n        if torch.cuda.is_available() and self.use_cuda:\n            self.device = 'cuda:0'\n\n    def test(self, network, dev_data, threshold=0.33):\n        # transfer model to gpu if available\n        network = network.to(self.device)\n\n        # turn on the testing mode; clean up the history\n        network.eval()\n        output_list = []\n        truth_list = []\n\n        # define batch iterator\n        data_iter = torchtext.data.Iterator(\n            dataset=dev_data, batch_size=self.batch_size,\n            train=False, device=self.device, sort=False)\n\n        # predict\n        for batch in data_iter:\n            text, target = batch.text, batch.target\n\n            with torch.no_grad():\n                prediction = network(text)\n\n            output_list.append(prediction.detach())\n            truth_list.append(target.detach())\n\n        # evaluate\n        eval_results = self.evaluate(output_list, truth_list, threshold)\n        print(\"[tester] {}\".format(self.print_eval_results(eval_results)))\n\n        return eval_results\n\n    def evaluate(self, predict, truth, threshold=0.33):\n        \"\"\"Compute evaluation metrics.\n\n        :param predict: list of Tensor\n        :param truth: list of dict\n        :param threshold: threshold of positive probability\n        :return eval_results: dict, format {name: metrics}.\n        \"\"\"\n        y_trues, y_preds = [], []\n        for y_true, logit in zip(truth, predict):\n            y_pred = (torch.sigmoid(logit) > threshold).long().cpu().numpy()\n            y_true = y_true.cpu().numpy()\n            y_trues.append(y_true)\n            y_preds.append(y_pred)\n        y_true = np.concatenate(y_trues, axis=0)\n        y_pred = np.concatenate(y_preds, axis=0)\n\n        precision = metrics.precision_score(y_true, y_pred, pos_label=1)\n        recall = metrics.recall_score(y_true, y_pred, pos_label=1)\n        f1 = metrics.f1_score(y_true, y_pred, pos_label=1)\n\n        metrics_dict = {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n\n        return metrics_dict\n\n    def print_eval_results(self, results):\n        \"\"\"Override this method to support more print formats.\n        :param results: dict, (str: float) is (metrics name: value)\n        \"\"\"\n        return \", \".join(\n            [str(key) + \"=\" + \"{:.4f}\".format(value)\n             for key, value in results.items()])\n\n\nclass Predictor(object):\n    \"\"\"An interface for predicting outputs based on trained models.\n    \"\"\"\n\n    def __init__(self, batch_size=8, use_cuda=False):\n        self.batch_size = batch_size\n        self.use_cuda = use_cuda\n\n        self.device = 'cpu'\n        if torch.cuda.is_available() and self.use_cuda:\n            self.device = 'cuda:0'\n\n    def predict(self, network, data, threshold=0.33):\n        # transfer model to gpu if available\n        network = network.to(self.device)\n\n        # turn on the testing mode; clean up the history\n        network.eval()\n        batch_output = []\n\n        # define batch iterator\n        data_iter = torchtext.data.Iterator(\n            dataset=data, batch_size=self.batch_size,\n            train=False, device=self.device, sort=False)\n\n        for batch in data_iter:\n            text = batch.text\n\n            with torch.no_grad():\n                prediction = network(text)\n\n            batch_output.append(prediction.detach())\n\n        return self._post_processor(batch_output, threshold)\n\n    def _post_processor(self, batch_output, threshold=0.33):\n        \"\"\"Convert logit tensor to label.\"\"\"\n        y_preds = []\n        for logit in batch_output:\n            y_pred = (torch.sigmoid(logit) > threshold).long().cpu().numpy()\n            y_preds.append(y_pred)\n        y_pred = np.concatenate(y_preds, axis=0)\n\n        return y_pred","96e32e0c":"train_path = '..\/input\/train.csv'\ntest_path = '..\/input\/test.csv'\nembed_path = '..\/input\/embeddings\/glove.840B.300d\/glove.840B.300d.txt'\nsubmission_path = '.\/submission.csv'\nmodel_path = '.\/default_model.pkl'","f44c7708":"def pre():\n    \"\"\"Pre-process model.\"\"\"\n\n    print(\"Pre-processing...\")\n\n    # load data\n    fix_length = 100\n    text = torchtext.data.Field(\n        sequential=True, use_vocab=True, lower=True,\n        tokenize=nltk.word_tokenize, batch_first=True,\n        is_target=False, fix_length=fix_length)\n    target = torchtext.data.Field(\n        sequential=False, use_vocab=False,\n        batch_first=True, is_target=True)\n    dataset = torchtext.data.TabularDataset(\n        train_path, format='csv',\n        fields={\"question_text\": ('text', text),\n                \"target\": ('target', target)})\n    data_test = torchtext.data.TabularDataset(\n        test_path, format='csv',\n        fields={\"question_text\": ('text', text)})\n\n    # build vocab\n    text.build_vocab(dataset, data_test, min_freq=3)\n    text.vocab.load_vectors(torchtext.vocab.Vectors(embed_path))\n    vocab_size = len(text.vocab.itos)\n    padding_idx = text.vocab.stoi[text.pad_token]\n\n    # split data\n    data_train, data_val = dataset.split(split_ratio=0.9)\n\n    print(\"train set size:\", len(data_train))\n    print(\"val set size:\", len(data_val))\n    print(\"test set size:\", len(data_test))\n    print(\"vocab size:\", len(text.vocab.itos))\n    print(\"embed shape:\", text.vocab.vectors.shape)\n    print('')\n\n    # # save data\n    # save_pickle(data_train, pickle_path, 'data_train.pkl')\n    # save_pickle(data_val, pickle_path, 'data_val.pkl')\n    # print('')\n\n    args_dict = {\n        \"data_train\": data_train, \"data_val\": data_val,\n        \"data_test\": data_test, \"vocab_size\": vocab_size,\n        \"padding_idx\": padding_idx}\n\n    return args_dict","d6a7c15e":"args = pre()","39931dc4":"def train(**args):\n    \"\"\"Train model.\n    \"\"\"\n\n    print(\"Training...\")\n\n    # load data and embed\n    data_train = args[\"data_train\"]\n    pretrained_embed = data_train.fields[\"text\"].vocab.vectors\n\n    # define model\n    model_args = {\n        \"vocab_size\": args[\"vocab_size\"],\n        \"padding_idx\": args[\"padding_idx\"],\n        \"pretrained_embed\": pretrained_embed,\n    }\n    model = TextCNN(model_args)\n\n    # define trainer\n    trainer_args = {\n        \"epochs\": 10,\n        \"batch_size\": 128,\n        \"validate\": True,\n        \"save_best_dev\": True,\n        \"use_cuda\": True,\n        \"print_every_step\": 1000,\n        \"optimizer\": torch.optim.Adam(model.parameters(), lr=1e-3),\n        \"model_path\": model_path,\n        \"eval_metrics\": \"f1\",\n    }\n    trainer = Trainer(**trainer_args)\n\n    # train\n    data_val = args[\"data_val\"]\n    trainer.train(model, data_train, dev_data=data_val)\n\n    print('')","766712ca":"train(**args)","dabd3525":"def test(**args):\n    \"\"\"Train model.\n    \"\"\"\n\n    print(\"Testing...\")\n\n    # define model\n    model_args = {\n        \"vocab_size\": args[\"vocab_size\"],\n        \"padding_idx\": args[\"padding_idx\"],\n        \"pretrained_embed\": None,\n    }\n    model = TextCNN(model_args)\n    load_model(model, model_path, use_cuda=True)\n\n    # define tester\n    tester_args = {\n        \"batch_size\": 128,\n        \"use_cuda\": True,\n    }\n    tester = Tester(**tester_args)\n\n    # test and threshold selection\n    data_val = args[\"data_val\"]\n    best_thresh, best_f1 = 0., 0.\n    for thresh in np.arange(0.1, 0.501, 0.01):\n        thresh = np.round(thresh, 2)\n        f1 = tester.test(model, data_val, threshold=thresh)[\"f1\"]\n        print(\"threshold: {:>.2f} f1: {:>.4f}\".format(thresh, f1))\n        if f1 > best_f1:\n            best_thresh, best_f1 = thresh, f1\n\n    args[\"threshold\"] = best_thresh\n\n    print(\"best f1 on dev: {:>.4f} threshold: {:>.2f}\".format(\n        best_f1, best_thresh))\n    print('')\n\n    return args","b88c948d":"    args = test(**args)","4625b89c":"def infer(**args):\n    \"\"\"Inference using model.\n    \"\"\"\n\n    print(\"Predicting...\")\n\n    # define model\n    model_args = {\n        \"vocab_size\": args[\"vocab_size\"],\n        \"padding_idx\": args[\"padding_idx\"],\n        \"pretrained_embed\": None,\n    }\n    model = TextCNN(model_args)\n    load_model(model, model_path, use_cuda=True)\n\n    # define predictor\n    predictor = Predictor(batch_size=128, use_cuda=False)\n\n    # predict\n    data_test = args[\"data_test\"]\n    threshold = args[\"threshold\"]\n    y_pred = predictor.predict(model, data_test, threshold=threshold)\n\n    # submit result\n    test_df = pd.read_csv(test_path, index_col=False, header=0)\n    data = {\"qid\": test_df[\"qid\"], \"prediction\": y_pred}\n    subm_df = pd.DataFrame(data=data)\n    subm_df.to_csv(submission_path, header=True, index=False)\n\n    print(\"submission saved as {}.\".format(submission_path))\n    print('')","e1e1be96":"infer(**args)","7293a679":"## Predict","59975bf4":"## Pre-process","50b2474f":"## Define model, trainer, predictor","4f1e0e6e":"## Train","7609e402":"## Test and model selection"}}