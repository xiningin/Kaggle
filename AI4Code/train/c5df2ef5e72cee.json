{"cell_type":{"417dea9a":"code","d4f0de49":"code","bb31ebfb":"code","53d30129":"code","0d8607a7":"code","601eaafc":"code","f28038f6":"code","16972179":"code","d79ec0c1":"code","68630b1c":"code","b5d29679":"code","76ef9621":"code","44b37286":"code","29a92dc0":"code","d961d8e2":"markdown","2ae3e522":"markdown","7a75b936":"markdown","9455f1f8":"markdown","84d2fa15":"markdown","26520e8c":"markdown"},"source":{"417dea9a":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","d4f0de49":"data = pd.read_csv('..\/input\/strategeion-resume-skills\/resumes_development.csv')","bb31ebfb":"data","53d30129":"data.info()","0d8607a7":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop the index column\n    df = df.drop('Unnamed: 0', axis=1)\n    \n    # Split df into X and y\n    y = df['Interview']\n    X = df.drop('Interview', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test ","601eaafc":"X_train, X_test, y_train, y_test  = preprocess_inputs(data)","f28038f6":"X_train","16972179":"y_train.value_counts()","d79ec0c1":"models = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"      Decision Tree\": DecisionTreeClassifier(),\n    \"      Random Forest\": RandomForestClassifier()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    print(name + \" trained.\")","68630b1c":"for name, model in models.items():\n    print(name + \" Accuracy: {:.2f}%\".format(model.score(X_test, y_test) * 100))","b5d29679":"n_components = 5\n\npca = PCA(n_components=n_components)\npca.fit(X_train)\n\nX_train_reduced = pd.DataFrame(pca.transform(X_train), index=X_train.index, columns=[\"PC\" + str(i) for i in range(1, n_components + 1)])\nX_test_reduced = pd.DataFrame(pca.transform(X_test), index=X_test.index, columns=[\"PC\" + str(i) for i in range(1, n_components + 1)])","76ef9621":"X_train_reduced","44b37286":"models = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"      Decision Tree\": DecisionTreeClassifier(),\n    \"      Random Forest\": RandomForestClassifier()\n}\n\nfor name, model in models.items():\n    model.fit(X_train_reduced, y_train)\n    print(name + \" trained.\")","29a92dc0":"for name, model in models.items():\n    print(name + \" Accuracy: {:.2f}%\".format(model.score(X_test_reduced, y_test) * 100))","d961d8e2":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/BhlR-kHxc3E","2ae3e522":"# Training\/Results With Dimensionality Reduction","7a75b936":"# Preprocessing","9455f1f8":"# Training\/Results","84d2fa15":"# Task for Today  \n\n***\n\n## Interview Success Prediction  \n\nGiven *data about resumes*, let's try to predict whether a candidate will **pass their interview** based on their resume.\n\nWe will use three models to make our predictions and PCA for dimensionality reduction to make our predictions.","26520e8c":"# Getting Started"}}