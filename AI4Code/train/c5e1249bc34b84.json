{"cell_type":{"f494906f":"code","e5ac5937":"code","943230f9":"code","e971a1ac":"code","69ce2e8b":"code","cbff3784":"code","9db8f34f":"code","de74eadb":"code","a109b5aa":"code","8ad7eb12":"code","a9e6b2ac":"code","20a9b8f5":"code","7c815710":"code","f2b20669":"code","15af6955":"code","fa52685e":"code","f724f5cd":"code","f7332923":"code","21d7e427":"code","b79ab7d2":"code","5523aa2c":"code","8fa89592":"code","bc67568c":"code","bfc1939a":"code","2c1b9f3a":"code","fac3cf2f":"code","6f53ae62":"code","bdbcb734":"code","3106d91e":"code","4687b730":"code","09fc3b90":"code","b2fee3ab":"code","633bf8dd":"code","ba09ddc6":"code","efae9186":"code","eecf7024":"code","59830f14":"code","32f23158":"code","40675fba":"code","14597e23":"code","9fd020d8":"code","0500ae1d":"code","7f0a8159":"code","1392399a":"code","338e28c9":"code","e555f13c":"code","85bb62d3":"markdown"},"source":{"f494906f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e5ac5937":"df = pd.read_excel('\/kaggle\/input\/work2210\/1.xlsx')\ndf","943230f9":"df.drop(['\u041d\u043e\u043c\u0435\u0440', '\u0418\u0441\u0445\u043e\u0434\u043d\u044b\u0439 \u043f\u0440\u043e\u0444\u0438\u043b\u044c', '\u041f\u0440\u043e\u0444\u0438\u043b\u044c'], axis=1, inplace=True)\ndf","e971a1ac":"df['\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439 \u043d\u0430 \u0432\u0445\u043e\u0434\u0435'] = df['\u0412\u0445\u043e\u0434\u043d\u0430\u044f \u0432\u044b\u0441\u043e\u0442\u0430, \u043f\u0438\u043a\u0441\u0435\u043b\u0438'] * df['\u0412\u0445\u043e\u0434\u043d\u0430\u044f \u0448\u0438\u0440\u0438\u043d\u0430, \u043f\u0438\u043a\u0441\u0435\u043b\u0438']\ndf['\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439 \u043d\u0430 \u0432\u044b\u0445\u043e\u0434\u0435'] = df['\u0412\u044b\u0445\u043e\u0434\u043d\u0430\u044f \u0432\u044b\u0441\u043e\u0442\u0430, \u043f\u0438\u043a\u0441\u0435\u043b\u0438'] * df['\u0412\u044b\u0445\u043e\u0434\u043d\u0430\u044f \u0448\u0438\u0440\u0438\u043d\u0430, \u043f\u0438\u043a\u0441\u0435\u043b\u0438']\ndf.drop(['\u0412\u0445\u043e\u0434\u043d\u0430\u044f \u0432\u044b\u0441\u043e\u0442\u0430, \u043f\u0438\u043a\u0441\u0435\u043b\u0438', '\u0412\u0445\u043e\u0434\u043d\u0430\u044f \u0448\u0438\u0440\u0438\u043d\u0430, \u043f\u0438\u043a\u0441\u0435\u043b\u0438', '\u0412\u044b\u0445\u043e\u0434\u043d\u0430\u044f \u0432\u044b\u0441\u043e\u0442\u0430, \u043f\u0438\u043a\u0441\u0435\u043b\u0438', '\u0412\u044b\u0445\u043e\u0434\u043d\u0430\u044f \u0448\u0438\u0440\u0438\u043d\u0430, \u043f\u0438\u043a\u0441\u0435\u043b\u0438'], \n        axis=1, inplace=True)\ndf","69ce2e8b":"df['\u041e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0435 \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439'] = df['\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439 \u043d\u0430 \u0432\u044b\u0445\u043e\u0434\u0435'] \/ df['\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439 \u043d\u0430 \u0432\u0445\u043e\u0434\u0435']\ndf.drop(['\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439 \u043d\u0430 \u0432\u044b\u0445\u043e\u0434\u0435', '\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0438\u043a\u0441\u0435\u043b\u0435\u0439 \u043d\u0430 \u0432\u0445\u043e\u0434\u0435'], axis=1, inplace=True)\ndf","cbff3784":"df['\u0420\u0430\u0437\u043c\u0435\u0440, \u041c\u0431'] = df['\u0420\u0430\u0437\u043c\u0435\u0440, \u041c\u0431'].astype(np.float32)\ndf['\u0422\u0430\u0440\u0433\u0435\u0442'] = df['\u0422\u0430\u0440\u0433\u0435\u0442'].astype(np.float32)\n\ndf","9db8f34f":"df = pd.get_dummies(data=df, columns=['\u041a\u043e\u0434\u0435\u043a', '\u0411\u0438\u0442\u0440\u0435\u0439\u0442'])\ndf","de74eadb":"df.info()","a109b5aa":"df['\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'].unique(), df['\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'].unique()","8ad7eb12":"df['\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'] = df.apply(lambda row: 0 if row['\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'] == '-' else row['\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'], axis=1)\ndf['\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'] = df.apply(lambda row: 0 if row['\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'] == '-' else row['\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'], axis=1)\ndf","a9e6b2ac":"df['\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'].unique(), df['\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'].unique()","20a9b8f5":"df['\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'] = df['\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'].astype(np.int32)\ndf['\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'] = df['\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'].astype(np.int32)\ndf","7c815710":"df.drop(['\u0414\u043b\u0438\u043d\u0430, \u0441\u0435\u043a\u0443\u043d\u0434\u044b'], axis=1, inplace=True)\ndf","f2b20669":"Y = df['\u0422\u0430\u0440\u0433\u0435\u0442'].values\ndf.drop(['\u0422\u0430\u0440\u0433\u0435\u0442'], axis=1, inplace=True)\ndf","15af6955":"df['\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'] \/= df['\u041a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'].max()\ndf['\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'] \/= df['\u0421\u043a\u043e\u0440\u043e\u0441\u0442\u044c \u0431\u0438\u0442\u0440\u0435\u0439\u0442\u0430'].max()\ndf","fa52685e":"df.info()","f724f5cd":"df.iloc[:, 4:] = df.iloc[:, 4:].astype(np.int32)\ndf.info()","f7332923":"X = df.values\n# X = X.astype(np.float32)","21d7e427":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)","b79ab7d2":"X_train.shape","5523aa2c":"Y_train","8fa89592":"import keras\nfrom keras.models import Sequential, load_model \nfrom keras.layers import Dense, Dropout, LSTM, BatchNormalization, RepeatVector, TimeDistributed, Input\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras import models, optimizers, Model\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\n\nmodel = Sequential()\n\nmodel.add(Dense(20, kernel_initializer='normal', activation='relu', input_shape=(X_train.shape[1],) ))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(100, kernel_initializer='normal', activation='relu'))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(80, kernel_initializer='normal', activation='relu'))\nmodel.add(Dropout(0.8))\n\n# model.add(Dense(40, kernel_initializer='normal', activation='relu'))\n# model.add(Dropout(0.6))\n\n# model.add(Dense(40, kernel_initializer='normal', activation='relu'))\n# model.add(Dropout(0.5))\n\nmodel.add(Dense(1, activation='linear'))\nmodel.compile(optimizer=optimizers.Adam(lr=1e-2), loss='mse', metrics=['mape'])\n\nmodel.summary()","bc67568c":"from keras.callbacks import ModelCheckpoint\n\ndef lr_scheduler(epoch, lr):\n    return lr * 0.95\n\ncheckpoint_path = 'bestmodel.hdf5'\n\ncheckpoint = ModelCheckpoint(checkpoint_path, monitor='val_mse', verbose=0, save_best_only=True, mode='min')\n\nscheduler = LearningRateScheduler(lr_scheduler, verbose=0)\n\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=7, mode='min', verbose=1)\n\ntqdm_callback = tfa.callbacks.TQDMProgressBar(leave_epoch_progress=False, \n                                              leave_overall_progress=True, \n                                              show_epoch_progress=False,\n                                              show_overall_progress=True)\n\ncallbacks_list = [\n    checkpoint, \n    scheduler, \n    early_stop, \n#    tqdm_callback\n]\n\nhistory = model.fit(X_train, Y_train, epochs=100, batch_size=8, callbacks=callbacks_list, verbose=1, validation_split=0.2)","bfc1939a":"import matplotlib.pyplot as plt\n\ndef graph_plot(history):\n    fig = plt.figure(figsize=(16, 24))\n    for i in history.history.keys():\n        print(f'{i} = [{min(history.history[i])}; {max(history.history[i])}]\\n')\n    \n    epoch = len(history.history['loss'])\n    # \u043d\u0430 \u043a\u0430\u0436\u0434\u0443\u044e: (train, val) + lr\n    size = len(history.history.keys()) \/\/ 2 + 1\n    \n    i = 1\n    for k in list(history.history.keys()):\n        if 'val' not in k:\n            fig.add_subplot(size, 1, i)\n            plt.plot(history.history[k])\n            if k != 'lr':\n                plt.plot(history.history['val_' + k])\n            plt.title(k, fontsize=10)\n\n            plt.ylabel(k)\n            plt.xlabel('epoch')\n            plt.grid()\n\n            plt.yticks(fontsize=10, rotation=30)\n            plt.xticks(fontsize=10, rotation=30)\n            plt.legend(['train', 'valid'], loc='upper left', fontsize=10, title_fontsize=15)\n            i += 1\n#         plt.show()\n\ngraph_plot(history)","2c1b9f3a":"from sklearn.linear_model import LinearRegression","fac3cf2f":"reg = LinearRegression().fit(X_train, Y_train)\nreg.score(X_train, Y_train)","6f53ae62":"reg.predict(X_test)","bdbcb734":"Y_test","3106d91e":"from sklearn.ensemble import RandomForestRegressor","4687b730":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {\n        'n_estimators': range(3, 41, 1),\n        'max_features': range(3, 13, 1),\n        'bootstrap': [True, False]\n\n    }\n]\n\nforest_reg = RandomForestRegressor()\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\ngrid_search.fit(X_train, Y_train)","09fc3b90":"grid_search.best_params_ ","b2fee3ab":"grid_search.best_estimator_ ","633bf8dd":"best = grid_search.best_estimator_ ","ba09ddc6":"pred = best.predict(X_test)\npred","efae9186":"Y_test","eecf7024":"from sklearn.metrics import mean_absolute_percentage_error","59830f14":"def mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","32f23158":"mean_absolute_percentage_error(Y_test, pred)","40675fba":"df","14597e23":"X_test2 = np.array([[116, 30 \/ 31, 0.0, 1.0, 1, 0, 0, 0, 0, 1, 0, 0]])","9fd020d8":"best.predict(X_test2)","0500ae1d":"from xgboost import XGBRegressor\n\n\nparams = {\n    'min_child_weight': range(2, 6, 1), \n    'gamma': list(np.logspace(-4, -1, 4)),\n    'subsample': [i \/ 10.0 for i in range(6, 11)],\n    'colsample_bytree': [i \/ 10.0 for i in range(6, 21)], \n    'max_depth': range(2, 9, 1),\n    'learning_rate': np.logspace(-4, -1, 4),\n    'n_estimators': [10, 100]\n}\n\n\nxgb = XGBRegressor(nthread=-1) \n\ngrid = GridSearchCV(xgb, params, cv=4, n_jobs=-1, scoring='neg_mean_squared_error')\ngrid.fit(X_train, Y_train)","7f0a8159":"pred = grid.best_estimator_.predict(X_test)","1392399a":"mean_absolute_percentage_error(Y_test, pred)","338e28c9":"grid.best_estimator_.predict(X_test2)","e555f13c":"grid.best_params_","85bb62d3":"898"}}