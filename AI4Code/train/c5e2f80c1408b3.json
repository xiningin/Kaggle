{"cell_type":{"d5673514":"code","e311b631":"code","05ac4299":"code","d3e6001a":"code","bc433f26":"code","535d1363":"code","c3a407c7":"code","ea13af99":"code","c488f8f2":"code","759a3b8e":"code","7d1f2abc":"code","25e6058a":"code","d47b2ec7":"code","567278cb":"code","8da18c3e":"code","45f32f40":"code","8b18a399":"code","f7e7dfea":"code","dacb2743":"code","3cbde349":"code","8184af63":"code","7a7a9dba":"code","f15b1094":"code","929c18f4":"code","0d30ee90":"code","39e66148":"code","6ff49d5c":"code","15d91824":"code","5ebecdcd":"code","433a89d5":"code","a6940211":"code","55228c38":"code","5f20f3bf":"code","67aeafe8":"code","f230d425":"code","53697dee":"markdown","db6233cd":"markdown","73ee0a49":"markdown","54822c3b":"markdown","8af6b24a":"markdown","a3ccb4db":"markdown","342cefb3":"markdown","966df9e8":"markdown","0e6fef2d":"markdown","edf7966d":"markdown","c8977802":"markdown","99c014c6":"markdown","ac1591e3":"markdown","40b83254":"markdown","e90917cf":"markdown","87fee7fc":"markdown","d7af195b":"markdown","433d3af9":"markdown","b3206668":"markdown","4267b8cd":"markdown"},"source":{"d5673514":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# !pip3 install arabic-reshaper\n# import arabic_reshaper\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e311b631":"sales_data = pd.read_csv('\/kaggle\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 4.csv', encoding = 'utf-8') #read a comma separate file\nsales_data.head(50) # Show top 50 entries","05ac4299":"print('Rows: ', sales_data.shape[0])\nprint('Cols: ', sales_data.shape[1])","d3e6001a":"new_cols = ['order_num','order_status','book_name','order_date','billing_city']\nsales_data.columns = new_cols\nsales_data.head(20)","bc433f26":"# Check for missing data\nsales_data.isnull().sum()","535d1363":"# Lets find out index of missing values in book_name column\nsales_data[sales_data['book_name'].isna()]","c3a407c7":"# Lets find out index of missing values in billing_city column\nsales_data[sales_data['billing_city'].isna()]","ea13af99":"# Lets check data consistency\nsales_data['order_status'].unique()","c488f8f2":"sales_data[sales_data['order_num'].duplicated() == True]","759a3b8e":"sales_data['book_name'].nunique()","7d1f2abc":"sales_data['book_name'].head(20)","25e6058a":"sales_data['billing_city'].nunique()","d47b2ec7":"sales_data['billing_city'].unique()","567278cb":"# Check irregular data in billing_city column.\nsales_data[sales_data.billing_city.str.contains(r'[^\\w\\s]',na=False)]","8da18c3e":"# Check irregular data in book_name column.\nsales_data[sales_data.book_name.str.contains(r'[^\\w\\s]',na=False)]","45f32f40":"# We cannot replace this missing data.\n# So we are going to drop rows with Na values.\nsales_data = sales_data.dropna()\n# Lets see how many rows and columns we have now.\nprint('Rows: ', sales_data.shape[0])\nprint('Cols: ', sales_data.shape[1])\n","8b18a399":"sales_data.isnull().any()","f7e7dfea":"# Remove duplicates from order_number column. \nsales_data = sales_data.drop_duplicates()\nsales_data[sales_data['order_num'].duplicated()]","dacb2743":"# Remove leading and trailing white spaces\nsales_data['order_status'] = sales_data['order_status'].str.strip()\nsales_data['book_name'] = sales_data['book_name'].str.strip()\nsales_data['billing_city'] = sales_data['billing_city'].str.strip()\nsales_data.head(50)","3cbde349":"# Convert categorical data to upper case\nsales_data['order_status'] = sales_data['order_status'].str.upper()\nsales_data['book_name'] = sales_data['book_name'].str.upper()\nsales_data['billing_city'] = sales_data['billing_city'].str.upper()\nsales_data.head(50)","8184af63":"# Find location of entries with (?) in billing_city column and drop such entries\n# because we have no data to replace with.\nsales_data.loc[sales_data['billing_city'].str.contains('^[?]'), 'billing_city'] = np.nan\nsales_data = sales_data.dropna()","7a7a9dba":"# Lets check number of cities now\nsales_data['billing_city'].nunique()","f15b1094":"# Multiple book entries to one entry per row.\nprint('Before split:',sales_data.shape[0])\n# Pre-processing\nsales_data = (sales_data.set_index(['order_num', 'order_date', 'order_status', 'billing_city'])\n   .apply(lambda x: x.str.split('\/').explode())\n   .reset_index())\nprint('After split: ',sales_data.shape[0])","929c18f4":"# We noticed that some book names are repeated with additional text to their name\nsales_data[sales_data['book_name'].str.match('^R KA.*') == True]","0d30ee90":"# Lets replace these book names.\nurd = [sales_data['book_name'][32717], sales_data['book_name'][31235], sales_data['book_name'][31239]]\nprint(urd)\nsales_data['book_name'].replace({urd[0]: \"R KA TAARUF\", \n                         \"PYTHON PROGRAMMING- RELEASE DATE: AUGUST 14, 2020\": \"PYTHON PROGRAMMING\",\n                         \"Linux - An Introduction  (Release Data - October 3, 2020)\": \"LINUX - AN INTRODUCTION\",\n                         urd[1] : \"(C++)\",\n                        \"BOOK BAND KAMRON KI MUHABBAT\": \"BAND KAMRON KI MUHABBAT\",\n                        urd[2]: \"MOLO MASALI\"}, inplace=True)","39e66148":"# Found another issue of multiple books on single row.\nsales_data['book_name'][12729]","6ff49d5c":"# Solve aforementioned issue\nprint('Before split:',sales_data.shape[0])\n# Pre-processing\nsales_data = (sales_data.set_index(['order_num', 'order_date', 'order_status', 'billing_city'])\n   .apply(lambda x: x.str.split('\u061f-').explode())\n   .reset_index())\nprint('After split: ',sales_data.shape[0])","15d91824":"# Set value of value of N to return top-N\nN = 5\n# Best-selling book\ntopn_best_sell = sales_data[sales_data['order_status'] == 'COMPLETED']['book_name'].value_counts(ascending=False).nlargest(N).to_frame()\nprint('The best-selling book is %s with %d sales'%(topn_best_sell.index[0], topn_best_sell.iloc[0][0]))","5ebecdcd":"# Plot Top-N cities which orderd best selling book\ncmap = [['C%d'%(d) for d in range(N)]]\nax = topn_best_selling_city.plot.bar(figsize=(12,8), width=0.8, color=cmap, legend=False,title='Top-%d cities which ordered best selling %s book'%(N, topn_best_sell.index[0]))\nax.set_xlabel(\"Billing Cities\")\nax.set_ylabel(\"Number of Orders\")","433a89d5":"print(sales_data.order_status.value_counts())\nsales_data.order_status.value_counts().to_frame().plot.bar( figsize=(12,8), width=0.5, legend=False, color=[['C0','C1','C2']], title='Order Status Frequency')\nax.set_xlabel(\"Billing Cities\")\nax.set_ylabel(\"Number of Orders\")","a6940211":"# Some more insights into data\nprint('The best selling book %s has %d returned orders.'%(topn_best_sell.index[0], sales_data[(sales_data['order_status'] == 'RETURNED') & (sales_data['book_name'] ==  topn_best_sell.index[0])].shape[0]))\nprint('The best selling book %s has %d cancelled orders.'%(topn_best_sell.index[0], sales_data[(sales_data['order_status'] == 'CANCELED') & (sales_data['book_name'] ==  topn_best_sell.index[0])].shape[0]))\nprint('\\n')\n# Most returned book\ntopn_most_returned = sales_data[sales_data['order_status'] == 'RETURNED']['book_name'].value_counts(ascending = False).nlargest(N).to_frame()\nprint('The most returned book is %s with %d returns.'%(topn_most_returned.index[0], topn_most_returned.iloc[0][0]))\nprint('\\n')\n# Book with most cancelled orders\ntopn_most_cancelled = sales_data[sales_data['order_status'] == 'CANCELED']['book_name'].value_counts(ascending=False).nlargest(N).to_frame()\nprint('The book having most cancelled orders is %s with %d cancelled orders.'%(topn_most_cancelled.index[0], topn_most_cancelled.iloc[0][0]))\n\n","55228c38":"# Some more insights on best-selling book\n# Find city with most completed orders of best-selling book.\ntopn_best_selling_city = sales_data[(sales_data['book_name'] == topn_best_sell.index[0]) & (sales_data['order_status'] == 'COMPLETED')]['billing_city'].value_counts().nlargest(N).to_frame()\nprint('Best-Selling book (%s) has: \\nmost COMPLETED orders from: %s (%d orders)'%(topn_best_sell.index[0],topn_best_selling_city.index[0], topn_best_selling_city.iloc[0][0]))\n\n# Find city with most returned orders of best-selling book\ntopn_most_returned_city = sales_data[(sales_data['book_name'] == topn_best_sell.index[0]) & (sales_data['order_status'] == 'RETURNED')]['billing_city'].value_counts().nlargest(N).to_frame()\nprint('most RETURNED orders from: %s (%d orders)'%(topn_most_returned_city.index[0], topn_most_returned_city.iloc[0][0]))\n\n# Find city with most returned orders of best-selling book\ntopn_most_cancelled_city = sales_data[(sales_data['book_name'] == topn_best_sell.index[0]) & (sales_data['order_status'] == 'CANCELED')]['billing_city'].value_counts().nlargest(N).to_frame()\nprint('most CANCELLED orders from: %s (%d orders)'%(topn_most_cancelled_city.index[0], topn_most_cancelled_city.iloc[0][0]))","5f20f3bf":"# Plot Top-N best selling books\ncmap = [['C%d'%(d) for d in range(N)]]\nax = topn_best_sell.plot.bar(figsize=(12,8), width=0.8, color=cmap, legend=False,title='Top-%d selling books: COMPLETED order_status'%(N))\nax.set_xlabel(\"Book Name\")\nax.set_ylabel(\"Number of Orders\")","67aeafe8":"# Plot Top-N returned books\ncmap = [['C%d'%(d) for d in range(N)]]\nax = topn_most_returned.plot.bar(figsize=(12,8), width=0.8, color=cmap, legend=False,title='Top-%d RETURNED order_status books'%(N))\nax.set_xlabel(\"Book Name\")\nax.set_ylabel(\"Number of Orders\")","f230d425":"# Plot Top-N cancelled order books\ncmap = [['C%d'%(d) for d in range(N)]]\nax = topn_most_cancelled.plot.bar(figsize=(12,8), width=0.8, color=cmap, legend=False,title='Top-%d CANCELLED order_status books'%(N))\nax.set_xlabel(\"Book Name\")\nax.set_ylabel(\"Number of Orders\")","53697dee":"**Q2. Visualize order status frequency.**","db6233cd":"Now we can see our rows have increased from 19184 to 33091.","73ee0a49":"There are not that much cities in Pakistan.","54822c3b":"This does not look good. There are white-spaces around city names. There are certain rows with question marks in billing_city and some contain non-alphabet characters like full-stops, commas, question marks etc. For example:","8af6b24a":"We have missing values in book_name and billing_city.","a3ccb4db":"It is important to notice here that we have dropped the billing_city entries with (????). Moreover we are selecting the best-selling based on COMPLETED order_status.","342cefb3":"# TODO\n* Solve city name problem: Shorkot\n * Shorkot\n * Shorkot Cantt\n * Shorkot Cantt.\n    *** I am looking for a solution for this problem: will update soon ***\n\nNow we are done with pre-processing and our data is in good shape for EDA.\n\n# EDA\n\n**Task 1: What is the best-selling book?**\n","966df9e8":"So we have reduced unique billing_city entries from 4082 to 3441. But this is still far from perfect.","0e6fef2d":"# PreProcessing\n\nWe have seen multiple problems with our data in previous exampeles. So we need to clean (pre-process) our data for efficient EDA.\nFor accurate analysis we will perform following steps:\n \n* Drop rows with missing data.\n* Remove duplicates from order_number column. \n* Remove leading and trailing white-spaces from entries.\n* Convert categorical data to UPPER case.\n* Drop entries with (????) in billing_city column.\n* Multiple book entries to one entry per row.\n* Solve city name problem: Shorkot\n * Shorkot\n * Shorkot Cantt\n * Shorkot Cantt.\n        *** I am looking for a solution for last problem: will update soon ***","edf7966d":"**Task 4. Find a correlation between city and order status.**","c8977802":"There are multiple books ordered per city. Such entries are separated by '\/' e.g. row 11.","99c014c6":"We are good to go. Duplicates removed.","ac1591e3":"**Task 6. Can we predict number of orders, or book names in advance?**","40b83254":"nan\/null values removed.","e90917cf":"Data cleaning is a mechanical process. So we checked for more data incosistencies manually and replaced with correct data as required.","87fee7fc":"# Data consistency\nIn this stage we are going to look for missing, incorrect or irrelevant data in our data frame.","d7af195b":"# Tasks\n* What is the best-selling book?\n* Visualize order status frequency.\n* Find a correlation between date and time with order status.\n* Find a correlation between city and order status.\n* Find any hidden patterns that are counter-intuitive for a layman.\n* Can we predict number of orders, or book names in advance?","433d3af9":"We have a duplicates in \"order_num\".","b3206668":"**Task 3. Find a correlation between date and time with order status.**","4267b8cd":"**Task 5. Find any hidden patterns that are counter-intuitive for a layman.**"}}