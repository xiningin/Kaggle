{"cell_type":{"d990334a":"code","c8678b9b":"code","85d34218":"code","28e89981":"code","adef1c6e":"code","40fe81eb":"code","152e5a27":"code","6b1078f6":"code","90ef8bed":"code","a76e3223":"code","0544e37d":"code","755c63a4":"code","c352c817":"code","0a2bad87":"code","1b87f7f4":"code","04d9081a":"code","192de712":"code","1bbe7f4e":"code","466fe58c":"code","2640545f":"code","1bdd56cf":"code","f684e3d9":"markdown","e54ea474":"markdown","2568c4d7":"markdown","566428f3":"markdown","92484838":"markdown","68763996":"markdown","d9f0d336":"markdown","3a9f5f8c":"markdown"},"source":{"d990334a":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt","c8678b9b":"# Train.csv has the Field_IDs needed to find the npy files\ntrain = pd.read_csv('Train.csv')\ntrain.head()","85d34218":"# Look at a sample:\nfid = train['Field_ID'].sample().values[0]\nfn = f'image_arrays_train\/{fid}.npy' # File name based on Field_ID\nprint(f'Loading {fn} as an array')\narr = np.load(fn) # Loading the data with numpy\nprint('Array shape:', arr.shape) # 360 bands, images 40 or 41px a side\nrgb_jan = np.stack([arr[4], arr[3], arr[2]], axis=-1) # Combine three bands for viewing\nrgb_jan = rgb_jan \/ np.max(rgb_jan) # Scale band values to (0, 1) for easy image display\nplt.imshow(rgb_jan) # View with matplotlib","28e89981":"# View false colour images from each month in the year:\nfig, axs = plt.subplots(3, 4, figsize=(12, 8), facecolor='w', edgecolor='k')\nfig.subplots_adjust(hspace = .5, wspace=.001)\naxs = axs.ravel()\nfor i in range(12):\n  rgb = np.stack([arr[i*30 + 8], arr[i*30 + 4], arr[i*30 + 3]], axis=-1) # False colour (band 8, 4 and 3)\n  rgb = rgb \/ 4000 # Scaling consistently \n  axs[i].imshow(rgb.clip(0, 1))\n  axs[i].set_title(str(i+1))","adef1c6e":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset","40fe81eb":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train['Field_ID'], train['Yield'], random_state=42)\n","152e5a27":"batch_size =128\nn_epochs = 20","6b1078f6":"class CropYield(Dataset):\n    def __init__(self, df, target, folder, transform=None):\n        self.df = df\n        self.length = len(df)\n        self.transform = transform\n        self.folder = folder\n        self.target = target\n    def __getitem__(self, index):\n        img = np.load(f'{self.folder}\/{self.df[index]}.npy').astype(np.float64)\n        img.resize(360, 32, 32) # Reshaping the image to a 32* 32 px \n\n        # if not self.transform:\n        img = torch.from_numpy(img)\n        return img, torch.tensor(self.target[index])\n    def __len__(self):\n        return self.length","90ef8bed":"training_set = CropYield(X_train.reset_index(drop=True), y_train.reset_index(drop=True), 'image_arrays_train')\nvalidation_set  = CropYield(X_test.reset_index(drop=True), y_test.reset_index(drop=True), 'image_arrays_train')\n","a76e3223":"train_loader = DataLoader(training_set, batch_size, shuffle=True)\nvalidation_set = DataLoader(validation_set, batch_size=len(X_test), shuffle=True)","0544e37d":"class Net(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.conv1 = nn.Conv2d(in_channels=360, out_channels=450, kernel_size=3, padding=1)\n    self.conv2 = nn.Conv2d(in_channels= 450, out_channels = 200, kernel_size=3, padding=1)\n    self.linear1 = nn.Linear(in_features=200*6*6, out_features=256)\n    self.dropout1 = nn.Dropout(0.4)\n    self.linear2 = nn.Linear(in_features=256, out_features=128)\n    self.dropout2 = nn.Dropout(0.4)\n    self.linear3 =  nn.Linear(in_features=128, out_features=64)\n    self.dropout3 = nn.Dropout(0.4)\n    self.out = nn.Linear(in_features=64, out_features=1)\n\n  def forward(self, t):\n    #layer1\n    t = self.conv1(t)\n    t = F.relu(t)\n    t = F.max_pool2d(t, kernel_size=4, stride=2)\n    #layer2\n    t = self.conv2(t)\n    t = F.relu(t)\n    t = F.max_pool2d(t, kernel_size=5, stride=2)\n    #Flatten and layer3 \n    t = t.reshape(-1, 200 * 6 * 6)\n    t = self.linear1(t)\n    t = F.relu(t)\n    #Layer4\n    t = self.dropout1(t)\n    #layer5\n    t= self.linear2(t)\n    t = F.relu(t)\n    #layer6\n    t =self.dropout2(t)\n    #layer7\n    t = self.linear3(t)\n    t = F.relu(t)\n    #layer8\n    t = self.dropout3(t)\n    #output\n    return self.out(t)","755c63a4":"model = Net()\nmodel.double()\noptimizer = optim.Adam(model.parameters(), lr=0.01)\nmodel.to('cuda')","c352c817":"\nfor i in range(n_epochs):\n  total_loss = 0\n  for batch in train_loader: # Get Batch\n    images, values = batch \n    images = images.to('cuda')  # missing line from original code\n    values = values.to('cuda')\n    preds = model(images) # Pass Batch\n    mse_loss = nn.MSELoss()\n    loss = mse_loss(preds.reshape(values.shape[0]), values) # Calculate Loss\n\n    optimizer.zero_grad()\n    loss.backward() # Calculate Gradients\n    optimizer.step() # Update Weights\n    total_loss += loss.item()\n\n  print(\n      \n      \"epoch:\", i,  \n      \"loss:\", total_loss\/len(train_loader)\n  ) \n","0a2bad87":"torch.save(model.state_dict(), 'model.pth')\n","1b87f7f4":"for each in validation_set:\n    images, values = each \n    images = images.to('cuda')  # missing line from original code\n    values = values.to('cuda')\n    #optimizer = optimizer\n    valid_preds = model(images) # Pass Batch\n    mse_loss = nn.MSELoss()\n    loss = mse_loss(valid_preds.reshape(values.shape[0]), values)\n    print(loss)","04d9081a":"ss = pd.read_csv('\/content\/drive\/MyDrive\/Colab Notebooks\/crop yield\/SampleSubmission.csv')\ntest_set  = CropYield(ss['Field_ID'].reset_index(drop=True), ss['Yield'].reset_index(drop=True), 'image_arrays_test')\ntest_loader = DataLoader(test_set, len(ss))","192de712":"model.load_state_dict(torch.load('model.pth'))\n","1bbe7f4e":"\nfor each in test_loader:\n    images, values = each \n    images = images.to('cuda')  # missing line from original code\n    values = values.to('cuda')\n    #optimizer = optimizer\n    test_values = model(images) # Pass Batch\n    ","466fe58c":"test_values = test_values.cpu()","2640545f":"ss['Yield'] = test_values.detach().numpy()","1bdd56cf":"ss.to_csv('Sub.csv', index=False)\n","f684e3d9":"**CNN model**","e54ea474":"**Testing**","2568c4d7":"**This is my first CNN based model using pytorch**\n\nPlease upvote if you like it and open for suggestions\n\n* This kernel is an overvew of out the CNN approach\n* Please make the changes to the dataset paths based on your needs\n* The prediction on the test data as to be done separately as the GPU memory is not getting clearing after training and validation datasets(still exploring this)","566428f3":"**Training**","92484838":"**Splitting the data**","68763996":"**Data Loader for train and validation sets**","d9f0d336":"**Validation**","3a9f5f8c":"Crop yield data is arguably the most important measure of agricultural productivity and production, and is used to monitor global and national food security, and to help determine effective agricultural policy.\n\nDue to the physical challenges and high costs associated with the collection of crop-cut yield estimates, few datasets exist and even fewer are regularly sampled every season. For this reason, developing new methods to estimate crop yields at scale using the limited data available has been a prominent research priority.\n\nOne of the most promising yield estimation methods has been to use available crop-cut datasets to calibrate mathematical models to estimate crop yields from satellite imagery.\n\nThe aim of this challenge is to create a model capable of estimating the crop-cut maize yield for fields in East Africa. Given a time-series of Sentinel 2 imagery and climate variables, your model must output a predicted yield in tons per acre.\n\nThese models often need to be applied at scale, so large ensembles are discouraged. To incentivise more lightweight solutions, we are adding an additional submission criteria: your submission should take a reasonable time to train and run inference. Specifically, we should be able to re-create your submission on a single-GPU machine (eg Nvidia P100) with less than 8 hours training and two hours inference.\n\nAbout CGIAR (cgiar.org):\n\n\nThe CGIAR (formerly the Consultative Group for International Agricultural Research) is a consortium of international agricultural research centers scattered across the world who focus on issues related to agricultural productivity, food security, poverty, and the environment. The CGIAR is made up of 15 research centers and operates in dozens of countries across Asia, Africa, and Latin America.\n\nAbout The Platform for Big Data in Agriculture (bigdata.cgiar.org)\n\n\nThe CGIAR Platform for Big Data in Agriculture is a cross-center platform of the CGIAR with the goal of leveraging and harnessing the power of big data to accelerate and enhance the impact of international agricultural research. This 5-year platform (2017 - 2021) will provide global leadership in organizing open data, convening partners to develop innovative ideas, and demonstrating the power of big data analytics through inspiring projects. It is where information becomes power: power to predict, prescribe, and produce more food, more sustainably. It democratizes decades of agricultural data empowering analysts, statisticians, programmers and more to mine information for trends and quirks, and develop rapid, accurate and compelling recommendations for farmers, researchers and policymakers.\n\nAbout The Big Data in Agriculture Convention (bigdata.cgiar.org\/virtual-convention-2020)\n\nThis year\u2019s Convention will be held online from 19 - 23 October, with the theme of digital dynamism for adaptive food systems.\n\nThis convention is the third annual event to bring together the people and organizations that make the Big Data Platform successful, a mix of scientists, policy makers, entrepreneurs, technologists, and agriculturalists. Three days of focused, action-based discussion to find commonalities across research institutes, governments, and private organizations sets the stage for a productive and data-driven year ahead!\n\nAbout The Alliance of Bioversity and the International Center for Tropical Agriculture (CIAT) (bioversityinternational.org\/alliance)\n\n\nCIAT (International Center for Tropical Agriculture) works in collaboration with hundreds of partners to help developing countries make farming more competitive, profitable, and resilient through smarter, more sustainable natural resource management. We help policymakers, scientists, and farmers respond to some of the most pressing challenges of our time, including food insecurity and malnutrition, climate change, and environmental degradation.\n\nAbout The International Food Policy Research Institute (IFPRI) (ifpri.org)\n\n\nThe International Food Policy Research Institute (IFPRI) provides research-based policy solutions to sustainably reduce poverty and end hunger and malnutrition in developing countries. Established in 1975, IFPRI currently has more than 600 employees working in over 50 countries. It is a research center of CGIAR, a worldwide partnership engaged in agricultural research for development.\n\nAbout Amazon Web Services (https:\/\/aws.amazon.com)\n\n\nAmazon Web Services (AWS) is the world\u2019s most comprehensive and broadly adopted cloud platform, offering over 175 fully featured services from data centers globally, including Cape Town, South Africa. Millions of customers, including academic and research institutions like CGIAR, are using AWS to lower costs, become more agile, and innovate faster."}}