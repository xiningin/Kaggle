{"cell_type":{"1c7e75f9":"code","18c1c757":"code","a20c96e9":"code","d3f2ac6a":"code","50f6064f":"code","65445ab1":"code","48ed0f6b":"code","6023a18d":"code","8ef2c483":"code","2797f6b8":"code","1ce2b6b7":"code","01ea0703":"code","34a7bb88":"code","28ccd12d":"code","d873bdff":"code","7afe9c17":"code","bae77677":"code","0c79f846":"code","30f8f46e":"code","b6570876":"code","053991de":"code","84d96d7a":"code","abcb8362":"code","1097c899":"code","2c3e86fc":"code","f5c93a63":"code","d82fc773":"code","7e1228ca":"code","fde6547d":"code","f516a58b":"code","1ab88cb0":"code","6d4aa8e5":"code","16c32680":"code","13971bb6":"code","83701eaf":"code","35882384":"code","47be32df":"code","8858c689":"code","5ab94310":"code","91a0a847":"code","7045311e":"code","5c5833b5":"code","4c0f314f":"code","9e6fbb47":"code","53becf91":"code","4cc1942f":"code","870b44a6":"code","8d1eeea9":"code","f70400aa":"code","64f485e1":"markdown","62571ced":"markdown","43fc405d":"markdown","029e10fe":"markdown","7a987cf8":"markdown","c26cedff":"markdown","fb434117":"markdown","33204240":"markdown","3eb2068e":"markdown","f8f71a8b":"markdown","acf8ca6d":"markdown","2d2435fb":"markdown","5c39fecb":"markdown","b8af2f6c":"markdown","a70fe145":"markdown","897d01de":"markdown","a703e96e":"markdown","e73af396":"markdown","e00b2e6e":"markdown","e0ccd91f":"markdown","d7ea0fa3":"markdown"},"source":{"1c7e75f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","18c1c757":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a20c96e9":"stroke = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","d3f2ac6a":"stroke.head()","50f6064f":"stroke.info()","65445ab1":"stroke.nunique()","48ed0f6b":"cat_cols = stroke.nunique()[stroke.nunique()<6].index\ncat_cols","6023a18d":"for i in cat_cols:\n    print('The unique values in',i,'are:',stroke[i].unique())","8ef2c483":"stroke['gender'].value_counts()","2797f6b8":"for i in cat_cols:\n    stroke[i].value_counts().plot.bar()\n    plt.title(i)\n    plt.show()","1ce2b6b7":"for i in cat_cols:\n    print('The % of each unique value having a stroke by',i,'is:')\n    print(stroke.groupby(i)['stroke'].mean())\n    print('-'*100)","01ea0703":"stroke.drop(columns='id').describe()","34a7bb88":"int_cols = list(set(stroke.columns)-set(cat_cols))\nint_cols.remove('id')\nint_cols ","28ccd12d":"stroke[stroke.bmi>50]['stroke'].value_counts()","d873bdff":"sns.heatmap(stroke.corr(),annot=True)","7afe9c17":"stroke[stroke['work_type']=='children']['age'].max()","bae77677":"stroke[stroke['age']==17]['work_type'].value_counts()","0c79f846":"stroke_drop = stroke[stroke['work_type']!='Never_worked']","30f8f46e":"stroke_drop = stroke_drop[stroke_drop['gender']!='Other']","b6570876":"stroke_drop[stroke_drop['stroke'] == 1]['stroke'].count()","053991de":"stroke_drop['smoking_status']=stroke_drop['smoking_status'].replace({'formerly smoked':'smokes'})","84d96d7a":"stroke_drop.groupby('smoking_status')['stroke'].mean()","abcb8362":"stroke_drop['bmi'].describe()","1097c899":"bmi_na = stroke_drop[stroke_drop.bmi.isna()]\nbmi_na.head()","2c3e86fc":"bmi_na.describe()","f5c93a63":"print('Avg BMI of people with hypertension is:',stroke.groupby('hypertension')['bmi'].mean()[1])\nprint('Median BMI of people with hypertension is:',stroke.groupby('hypertension')['bmi'].median()[1])","d82fc773":"print('Avg BMI of people who have had a stroke is:',stroke.groupby('stroke')['bmi'].mean()[1])\nprint('Median BMI of people who have had a stroke is:',stroke.groupby('stroke')['bmi'].median()[1])","7e1228ca":"print('Avg BMI of people with heart disease is:',stroke.groupby('heart_disease')['bmi'].mean()[1])\nprint('Median BMI of people with heart disease is:',stroke.groupby('heart_disease')['bmi'].median()[1])","fde6547d":"stroke_drop['bmi'] = stroke_drop['bmi'].fillna(28)","f516a58b":"stroke_drop.isna().sum()","1ab88cb0":"X = stroke_drop.drop(columns='stroke')\ny = stroke_drop['stroke']","6d4aa8e5":"X.nunique()","16c32680":"X = pd.get_dummies(X)","13971bb6":"X.head()","83701eaf":"X = X.drop(columns = ['id','gender_Female','ever_married_No','Residence_type_Rural'])","35882384":"X[int_cols].skew()","47be32df":"from sklearn.preprocessing import PowerTransformer","8858c689":"pt = PowerTransformer(method='box-cox')","5ab94310":"X[['avg_glucose_level','bmi']] = pt.fit_transform(X[['avg_glucose_level','bmi']])","91a0a847":"X[int_cols].skew()","7045311e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score,train_test_split","5c5833b5":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=42)","4c0f314f":"logreg = LogisticRegression(max_iter=1000)","9e6fbb47":"logreg.fit(X_train,y_train)","53becf91":"print('Training score:',logreg.score(X_train,y_train))\nprint('Training score:',logreg.score(X_test,y_test))","4cc1942f":"from sklearn.metrics import classification_report","870b44a6":"y_pred = logreg.predict(X_test)","8d1eeea9":"print(classification_report(y_test,y_pred))","f70400aa":"np.sum(y_pred)","64f485e1":"#### According to this dataset, there are 79 people with a BMI of over 50, but only 1 of them have had a stroke. This doesn't seem right to me since a higher BMI is generally linked to an increased chance for a stroke. A record of the heights\/weights of these people would help solve this issue","62571ced":"* 23% of the people without a bmi have had hypertension, which is much larger than the 9% in the df. \n* 16% had heart diseas compared to the 5% in the df. \n* Almost 20% of these people have also had a stroke.","43fc405d":"I will plug in the average for all the missing values in bmi.","029e10fe":"* In gender there is only 1 record having the label 'Other'.\n* 'never_worked' also has a similar problem where only a few records have that label. \n* I might drop all records that contain these labels just to make the columns more stratified.\n* Number of people who have had a stroke is way too little","7a987cf8":"95% accuracy on our testing set, wow!\nNot going to lie, this feels weird because the correlation between the variables was very low. In addition to this, the % of people who had a stroke in the dataset was almost 5, which is really low too. I was expecting a very bad model.","c26cedff":"And now we see why! Our model isn't predicting any 1s at all. This is definitely because of how unbalanced the dataset is. There are some potential solutions to this and I would like to visit them at another time. ","fb434117":"## Analyzing Categorical Columns","33204240":"\n* There are 12 columns, of which 7 are numerical and 5 are categorical\n* Right off the bat we can see that BMI is the only column with Null values, all the other columns don't seem to have any.\n* id is a useless column for modeling as it is unique for all 5110 rows. \n* There are 5 object columns (gender, ever_married, work_type, residence_type, and smoking_status) that will need to be converted before we can create a model.","3eb2068e":"* Funnily enough, married people are more likely to have a stroke! None of the other columns have such stark differences in mean","f8f71a8b":"No missing values left","acf8ca6d":"Dropped all the redundant columns because they contain the same information as the columns already in the table","2d2435fb":"Seems like all (except 3 people) aged 17 have jobs","5c39fecb":"Children go up till the age of 16 and stop there","b8af2f6c":"Columns like glucose levels and bmi seem to be pretty skewed, but age is fine","a70fe145":"This was done to reduce unnecessary clutering in the number of categories. I combined the people who currently smoke and formerly smoked into one.","897d01de":"The above codes drop all the values of people who have never worked and are not male\/female. This does not result in loss of information since all these people have not had strokes","a703e96e":"## Analyzing Numerical Columns","e73af396":"* Interestingly, gender has 3 unique values, which should be checked out in case it indicates some sort of missing values.\n* Smoking status has 4 unique values that probably need to be checked out","e00b2e6e":"This takes care of the skewness problem and makes our data more normally distributed.\nNow it's time to make the model!","e0ccd91f":"* The ages of the patients range from 0.08 to 82 years old. Mean and median are pretty close so there isn't a lot of skew.\n* The mean for hypertension 0.097, so only 9.7% of the 5110 records have high blood pressure. The heart_disease and stroke  columns also have the same issue. This indicates a class imbalance.\n* avg_glucose levels are around 106 and 75% of the data is below 114, so I'll assume that this was taken after a meal. The normal range after a meal 70-140.\n* Median bmi of 28 is concerning because that means over half the dataset is overweight\n* Max of bmi is 97.6 which is wild and should be looked into","d7ea0fa3":"* Looking at the values above, all the columns check out so far, although maybe the number of unique values in smoking_status can be reduced  "}}