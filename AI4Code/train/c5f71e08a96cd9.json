{"cell_type":{"e5bcce21":"code","7ab4e598":"code","a14bc674":"code","e5f5d10b":"code","4ab54bcc":"code","c3b6d2a0":"code","f84d8a49":"code","0c78a86b":"code","33d96c2c":"code","52ff0cc7":"code","7e5f4856":"code","232c3011":"code","26d25320":"code","acc5e453":"code","20123191":"code","1881f4bf":"code","f8435a60":"code","d9c906ef":"code","914fdb49":"code","e35c51ef":"code","dc932aec":"code","7f6c5db0":"code","23126f90":"code","2eb54bd8":"code","8affc182":"code","04d79fa8":"code","3ee52dc0":"code","edd3f804":"code","91b807b0":"code","1903a2af":"code","931d5745":"code","65aa9e24":"code","0d091f3c":"code","350d8dcb":"code","0b6659bb":"code","005b4112":"code","6068a0ff":"code","5ef4b1d5":"code","23aec2f7":"code","3c0cbdb7":"code","cbff024f":"code","0a6809bc":"code","4e426ffe":"code","a107409e":"code","9db463b7":"code","5527640a":"code","f795fab3":"code","de3b57f1":"code","4ab2b352":"code","15003e45":"code","409f0644":"code","6276787e":"code","fb94faad":"code","12c63c4c":"code","5af7993a":"code","95324a72":"code","9b515584":"code","d64ae941":"code","2ef373f1":"code","68a88c5d":"code","96ee526e":"code","d4215227":"code","3b91cfa2":"code","a04eaad0":"code","71b5148c":"code","69fac7d4":"code","96f64f25":"code","18461ab7":"code","47add39e":"code","9e03448d":"code","5b063db3":"code","54d243b4":"code","1f0dce50":"code","63ef30c2":"code","cc342c4b":"code","d47770d5":"code","ad77cbda":"code","cbfee199":"code","0a1455e9":"code","f61f4f13":"code","602afbe7":"code","95a7ccb9":"code","97351a39":"code","d9cbad9e":"code","9259f72e":"code","5bc18627":"code","32b46d5e":"code","c74f2f31":"code","802a6051":"code","712424cb":"code","9c59d09e":"code","900409a8":"code","22d57b2e":"code","7f1a61fc":"code","34ca7004":"code","6608760f":"code","90e70b16":"code","b9142600":"code","e19f9b4e":"code","277d0bd4":"code","ceb2bc47":"code","227eab5c":"code","3cd9d60f":"code","4ab2c481":"code","8a5395e2":"code","63a671e4":"code","9377fe25":"code","8b842d79":"code","bfccc061":"code","2788270d":"code","1a85125d":"code","87d4f93d":"code","8ac05f14":"code","698b3005":"code","badccdb2":"code","932331aa":"code","8754d105":"code","1c477a8d":"code","e63b58f1":"code","be9e3b2f":"code","2706922b":"code","7de6bd65":"code","24a5521c":"code","7c59288a":"code","b399df89":"code","3bbfc726":"code","80e3b093":"code","bb0a3b3f":"code","67f322a8":"code","dd042aac":"code","ba8b84ea":"code","937d6964":"code","7e15de32":"code","c1b7819a":"code","cd12f0a8":"code","1c861ab2":"code","f43e4260":"code","24ee4daa":"code","cc1e6e0d":"code","2ad54426":"code","57ade173":"code","e517676f":"code","5ba4f1fc":"code","6056db0a":"code","381a12f0":"code","76a0c424":"markdown","0e8ca057":"markdown","e77261eb":"markdown","ed2ddf66":"markdown","2805157c":"markdown","5c7f3c3c":"markdown","1c6c0ba9":"markdown","6b50367d":"markdown","53d6ff0d":"markdown","1655bace":"markdown","54a161f4":"markdown","3705df54":"markdown","37f1419c":"markdown","dd08b27e":"markdown","d9928efc":"markdown","2ed3d980":"markdown","39fb16e2":"markdown","460bffb1":"markdown","657a999e":"markdown","4fdef42d":"markdown","ef6a5985":"markdown","876e8d94":"markdown","a6302000":"markdown","30ad22b2":"markdown","38926c77":"markdown","8798bebb":"markdown","2bfc8d4a":"markdown","0269a2c4":"markdown","24bedb7b":"markdown","03f22529":"markdown","b761beb3":"markdown","843743fa":"markdown","d44db63a":"markdown","d84c7b12":"markdown","7dff62ac":"markdown","d7eb3e2c":"markdown","7710b99a":"markdown","e1a2326c":"markdown","247c81e5":"markdown","20dbd4e5":"markdown","512d3378":"markdown","d1f264db":"markdown","cd755094":"markdown","c5dc7e77":"markdown","c7a678fb":"markdown","b7bafaa4":"markdown","4fb381e1":"markdown","60e80674":"markdown","172f2281":"markdown","ae347d43":"markdown","f4390da8":"markdown"},"source":{"e5bcce21":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ab4e598":"import numpy as np \nimport pandas as pd\nimport datetime\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n# Plotly Libraris\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","a14bc674":"loan_data=pd.read_csv(\"\/kaggle\/input\/loan-eligible-dataset\/loan-train.csv\")\ndf_train=loan_data.copy()\ndf_train.head()","e5f5d10b":"# Size Of Data Set\ndf_train.shape","4ab54bcc":"# Columns Names\ndf_train.columns","c3b6d2a0":"# Columns Types\ndf_train.dtypes","f84d8a49":"#Info\ndf_train.info()","0c78a86b":"# Duplicated data\ndf_train[df_train.duplicated() == True]","33d96c2c":"df_train.describe().T","52ff0cc7":"df_train.isnull().values.any()","7e5f4856":"df_train.isnull().sum()","232c3011":"def missing_data(data):\n    total = data.isnull().sum().sort_values(ascending = False)\n    percent = (data.isnull().sum()\/data.isnull().count()*100).sort_values(ascending = False)\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data(df_train)","26d25320":"df_train_clean=df_train.copy()\ndf_train_clean=df_train_clean.dropna()\ndf_train_clean.drop(['Loan_ID'],inplace=True,axis=1)\ndf_train_clean.info()","acc5e453":"# Unique Value\n{column: list(df_train_clean[column].unique()) for column in df_train_clean.select_dtypes('object').columns}","20123191":"df_gender=df_train_clean['Gender'].value_counts().to_frame().reset_index().rename(columns={'index':'Gender','Gender':'count'})\n\n\nfig = go.Figure([go.Pie(labels=df_gender['Gender'], values=df_gender['count'], pull=[0,0.2],hole=0.4)])\n\nfig.update_traces(hoverinfo='label+percent', textinfo='value+percent', textfont_size=12,insidetextorientation='radial')\n\nfig.update_layout(title=\"Gender Count\",title_x=0.5)\nfig.show()","1881f4bf":"df_gender=df_train_clean['Gender'].value_counts().to_frame().reset_index().rename(columns={'index':'Gender','Gender':'count'})\n\n\nfig = go.Figure([go.Pie(labels=df_gender['Gender'], values=df_gender['count'])])\n\nfig.update_traces(hoverinfo='label+percent', textinfo='value+percent', textfont_size=12,insidetextorientation='radial')\n\nfig.update_layout(title=\"Gender Count\",title_x=0.5)\nfig.show()","f8435a60":"df_gender=df_train_clean['Gender'].value_counts().to_frame().reset_index().rename(columns={'index':'Gender','Gender':'count'})\n\nfig = go.Figure(go.Bar(\n    x=df_gender['Gender'],y=df_gender['count'],\n    marker={'color': df_gender['count'], \n    'colorscale': 'Viridis'},  \n    text=df_gender['count'],\n    textposition = \"outside\",\n))\nfig.update_layout(title_text='Gender Distribution',xaxis_title=\"Gender\",yaxis_title=\"Count \",title_x=0.5)\nfig.show()","d9c906ef":"df_Married=df_train_clean['Married'].value_counts().to_frame().reset_index().rename(columns={'index':'Married','Married':'count'})\n\n\nfig = go.Figure([go.Pie(labels=df_Married['Married'], values=df_Married['count'],hole=0.2)])\n\nfig.update_traces(hoverinfo='label+percent', textinfo='value+percent', textfont_size=12,insidetextorientation='radial')\n\nfig.update_layout(title=\"Married Count\",title_x=0.5)\nfig.show()","914fdb49":"df_M_and_G=df_train_clean.groupby(by =['Gender','Married'])['Dependents'].count().to_frame().reset_index().rename(columns={'Gender':'Gender','Married':'Married','Dependents':'Count'})\ndf_M_and_G\n\nfig = px.bar(df_M_and_G, x=\"Married\", y=\"Count\",color=\"Gender\",barmode=\"group\",\n             \n             )\nfig.update_layout(title_text='Married Count With Gender',title_x=0.5,\n                 )\nfig.show()","e35c51ef":"import seaborn as sns\n\nax = sns.countplot(x=\"Married\", data=df_train_clean)","dc932aec":"ax = sns.countplot(x=\"Married\",hue=\"Gender\", data=df_train_clean)","7f6c5db0":"df_Education=df_train_clean['Education'].value_counts().to_frame().reset_index().rename(columns={'index':'Education','Education':'count'})\n\n\nfig = go.Figure([go.Pie(labels=df_Education['Education'], values=df_Education['count'],hole=0.2)])\n\nfig.update_traces(hoverinfo='label+percent', textinfo='value+percent', textfont_size=12,insidetextorientation='radial')\n\nfig.update_layout(title=\"Education Count\",title_x=0.5)\nfig.show()","23126f90":"df_M_and_G_and_E=df_train_clean.groupby(by =['Gender','Education','Married'])['Dependents'].count().to_frame().reset_index().rename(columns={'Gender':'Gender','Married':'Married','Dependents':'count'})\n\nfig = px.bar(df_M_and_G_and_E, x=\"Gender\", y=\"count\", color=\"Married\", barmode=\"group\",\n             facet_col=\"Education\"\n             )\nfig.update_layout(title_text='Education Count With Gender,Married',title_x=0.5,\n                  hoverlabel=dict(\n                  bgcolor=\"white\",\n                  font_size=16,\n                  font_family=\"Rockwell\",\n                                \n     )\n  )\nfig.show()","2eb54bd8":"ax = sns.countplot(x=\"Education\", data=df_train_clean)","8affc182":"g = sns.FacetGrid(df_train_clean, col=\"Married\", row=\"Gender\")\ng.map_dataframe(sns.countplot, x=\"Education\")\ng.set_axis_labels(\" \", \"Count\");","04d79fa8":"df_Self_Employed=df_train_clean['Self_Employed'].value_counts().to_frame().reset_index().rename(columns={'index':'Self_Employed','Self_Employed':'count'})\n\nfig = go.Figure([go.Pie(labels=df_Self_Employed['Self_Employed'], values=df_Self_Employed['count'],hole=0.2)])\n\nfig.update_traces(hoverinfo='label+percent', textinfo='value+percent', textfont_size=12,insidetextorientation='radial')\n\nfig.update_layout(title=\"Self Employed Count\",title_x=0.5)\nfig.show()","3ee52dc0":"df_M_and_G_and_E=df_train_clean.groupby(by =['Gender','Self_Employed'])['Dependents'].count().to_frame().reset_index().rename(columns={'Gender':'Gender','Self_Employed':'Self_Employed','Dependents':'count'})\n\nfig = px.bar(df_M_and_G_and_E, x=\"Gender\", y=\"count\", color=\"Self_Employed\", barmode=\"group\",\n             \n             )\nfig.update_layout(title_text='Self Employed Count With Gender',title_x=0.5,\n                  hoverlabel=dict(\n                  bgcolor=\"white\",\n                  font_size=16,\n                  font_family=\"Rockwell\",\n                                \n     )\n  )\nfig.show()","edd3f804":"ax = sns.countplot(x=\"Self_Employed\",hue=\"Gender\", data=df_train_clean)","91b807b0":"df_train_clean.ApplicantIncome.describe().T","1903a2af":"fig = go.Figure(data=[go.Histogram(x=df_train_clean['ApplicantIncome'],  # To get Horizontal plot ,change axis - \n                                  marker_color=\"Crimson\",\n                       xbins=dict(\n                      start=0, #start range of bin\n                      end=25000,  #end range of bin\n                      size=1000   #size of bin\n                      ))])\nfig.update_layout(title=\"Distribution Of Applicant Income\",xaxis_title=\"Applicant Income\",yaxis_title=\"Counts\",title_x=0.5)\nfig.show()","931d5745":"fig = go.Figure()\nfig.add_trace(go.Box(\n    y=df_train_clean['ApplicantIncome'],\n    marker_color='royalblue',\n    boxmean=True # represent mean\n))\nfig.update_layout(title_text='Applicant Income',yaxis_title=\"Count\",title_x=0.5)\nfig.show()","65aa9e24":"fig = px.box(df_train_clean, x=\"Self_Employed\", y=\"ApplicantIncome\")\nfig.update_layout(title_text='Applicant Income With Self Employed',xaxis_title=\"Self Employed\",yaxis_title=\"Applicant Income\",title_x=0.5)\nfig.show()","0d091f3c":"# Multiple Bullet\n\nmin_income=df_train_clean.ApplicantIncome.min()\n\nmax_income=df_train_clean.ApplicantIncome.max()\n\nmean_income=df_train_clean.ApplicantIncome.mean()\n\n\nfig = go.Figure()\n\nfig.add_trace(go.Indicator(\n    mode = \"number+gauge\", value =  min_income,\n    domain = {'x': [0.25, 1], 'y': [0.4, 0.5]},\n    title = {'text': \"Min Income\",'font':{'color': 'black','size':15}},\n     number={'font':{'color': 'black'}},\n    gauge = {\n        'shape': \"bullet\",\n        'axis': {'range': [None, 200]},\n        'bar': {'color': \"blue\"}}))\n\nfig.add_trace(go.Indicator(\n    mode = \"number+gauge\", value = max_income,\n    domain = {'x': [0.25, 1], 'y': [0.6, 0.7]},\n    title = {'text': \"Max Income\",'font':{'color': 'black','size':15}},\n    number={'font':{'color': 'black'}},\n    gauge = {\n        'shape': \"bullet\",\n        'axis': {'range': [None,100500]},\n        'bar': {'color': \"cyan\"}}))\n\nfig.add_trace(go.Indicator(\n    mode = \"number+gauge\", value = mean_income,\n    domain = {'x': [0.25, 1], 'y': [0.8, 0.9]},\n    title = {'text' :\"Mean Income\",'font':{'color': 'black','size':15}},\n     number={'font':{'color': 'black'}},\n    gauge = {\n        'shape': \"bullet\",\n        'axis': {'range': [None,6000]},\n        'bar': {'color': \"darkblue\"}}\n))\n\nfig.update_layout(title=\"Applicant Income Statistics \",title_x=0.5)\nfig.show()","350d8dcb":"SE_Y_income=df_train_clean[df_train_clean[\"Self_Employed\"]==\"Yes\"]\nSE_N_income=df_train_clean[df_train_clean[\"Self_Employed\"]==\"No\"]\n\n\nminY_income=SE_Y_income.ApplicantIncome.min()\n\nmaxY_income=SE_Y_income.ApplicantIncome.max()\n\nmeanY_income=SE_Y_income.ApplicantIncome.mean()\n\nminN_income=SE_N_income.ApplicantIncome.min()\n\nmaxN_income=SE_N_income.ApplicantIncome.max()\n\nmeanN_income=SE_N_income.ApplicantIncome.mean()\n\nfig = go.Figure()\n\nfig.add_trace(go.Indicator(\n    mode = \"number+gauge\", value =  minY_income,\n    domain = {'x': [0.25, 1], 'y': [0.05, 0.15]},\n    title = {'text': \"Self Employed Min Income \",'font':{'color': 'black','size':12}},\n     number={'font':{'color': 'black'}},\n    gauge = {\n        'shape': \"bullet\",\n        'axis': {'range': [None, 1500]},\n        'bar': {'color': \"blue\"}}))\n\nfig.add_trace(go.Indicator(\n    mode = \"number+gauge\", value = maxY_income,\n    domain = {'x': [0.25, 1], 'y': [0.22, 0.32]},\n    title = {'text': \"Self Employed Max Income\",'font':{'color': 'black','size':12}},\n    number={'font':{'color': 'black'}},\n    gauge = {\n        'shape': \"bullet\",\n        'axis': {'range': [None,42500]},\n        'bar': {'color': \"cyan\"}}))\n\nfig.add_trace(go.Indicator(\n    mode = \"number+gauge\", value = meanY_income,\n    domain = {'x': [0.25, 1], 'y': [0.39, 0.49]},\n    title = {'text' :\"Self Employed Mean Income\",'font':{'color': 'black','size':12}},\n     number={'font':{'color': 'black'}},\n    gauge = {\n        'shape': \"bullet\",\n        'axis': {'range': [None,8000]},\n        'bar': {'color': \"darkblue\"}}\n))\nfig.add_trace(go.Indicator(\n    mode = \"number+gauge\", value = minN_income,\n    domain = {'x': [0.25, 1], 'y': [0.55, 0.65]},\n    title = {'text' :\"Not Self Employed Min Income\",'font':{'color': 'black','size':12}},\n     number={'font':{'color': 'black'}},\n    gauge = {\n        'shape': \"bullet\",\n        'axis': {'range': [None,200]},\n        'bar': {'color': \"darkcyan\"}}\n))\nfig.add_trace(go.Indicator(\n    mode = \"number+gauge\", value = maxN_income,\n    domain = {'x': [0.25, 1], 'y': [0.72,0.82]},\n    title = {'text' :\"Not Self Employed Max Income\",'font':{'color': 'black','size':12}},\n     number={'font':{'color': 'black'}},\n    gauge = {\n        'shape': \"bullet\",\n        'axis': {'range': [None,90000]},\n        'bar': {'color': \"red\"}}\n))\nfig.add_trace(go.Indicator(\n    mode = \"number+gauge\", value = meanN_income,\n    domain = {'x': [0.25, 1], 'y': [0.88,0.98]},\n    title = {'text' :\"Not Self Employed Mean Income\",'font':{'color': 'black','size':12}},\n     number={'font':{'color': 'black'}},\n    gauge = {\n        'shape': \"bullet\",\n        'axis': {'range': [None,6000]},\n        'bar': {'color': \"red\"}}\n))\nfig.update_layout(title=\" Self Employed And Not Self Employed Applicant Income Statistics \",title_x=0.5)\nfig.show()","0b6659bb":"df_Property_Area=df_train_clean['Property_Area'].value_counts().to_frame().reset_index().rename(columns={'index':'Property_Area','Property_Area':'count'})\n\nfig = go.Figure(data=[go.Scatter(\n    x=df_Property_Area['Property_Area'], y=df_Property_Area['count'],\n    mode='markers',\n    marker=dict(\n        color=df_Property_Area['count'],\n        size=df_Property_Area['count']*0.3, # Multiplying by 0.3 to reduce size and stay uniform accross all points\n        showscale=True\n    ))])\n\nfig.update_layout(title='Property Area',xaxis_title=\"Property Area \",yaxis_title=\"Number Of Property \",title_x=0.5)\nfig.show()","005b4112":"df_Property_Area=df_train_clean['Property_Area'].value_counts().to_frame().reset_index().rename(columns={'index':'Property_Area','Property_Area':'count'})\n\ncolors=['cyan','darkblue',\"darkcyan\"]\n\nfig = go.Figure([go.Pie(labels=df_Property_Area['Property_Area'], values=df_Property_Area['count'])])\nfig.update_traces(hoverinfo='label+percent', textinfo='percent+value', textfont_size=15,\n                 marker=dict(colors=colors, line=dict(color='#000000', width=2)))\nfig.update_layout(title=\"Property Area Count\",title_x=0.5)\nfig.show()","6068a0ff":"df_Property_Area=df_train_clean['Property_Area'].value_counts().to_frame().reset_index().rename(columns={'index':'Property_Area','Property_Area':'count'})\n\n\nfig = go.Figure(go.Bar(\n    x=df_Property_Area['Property_Area'],y=df_Property_Area['count'],\n    marker={'color': df_Property_Area['count'], \n    'colorscale': 'Viridis'},  \n    text=df_Property_Area['count'],\n    textposition = \"outside\",\n))\nfig.update_layout(title_text='Property Area Count',xaxis_title=\"Property Area\",yaxis_title=\"Number Of Property \",title_x=0.5)\nfig.show()","5ef4b1d5":"df_PA_mean=df_train_clean.groupby(by =['Property_Area'])['ApplicantIncome'].mean().to_frame().reset_index().rename(columns={'Property_Area':'Property_Area','ApplicantIncome':'mean'})\ndf_PA_min=df_train_clean.groupby(by =['Property_Area'])['ApplicantIncome'].min().to_frame().reset_index().rename(columns={'Property_Area':'Property_Area1','ApplicantIncome':'min'})\ndf_PA_max=df_train_clean.groupby(by =['Property_Area'])['ApplicantIncome'].max().to_frame().reset_index().rename(columns={'Property_Area':'Property_Area2','ApplicantIncome':'max'})\nresult = pd.concat([df_PA_mean, df_PA_min,df_PA_max], axis=1)\nresult.drop(['Property_Area1','Property_Area2'],inplace=True,axis=1)\n\n\nfig = make_subplots(rows=3, cols=1,\n                   subplot_titles=(\"Mean Applicant Income\",\n                                   \"Min Applicant Income\",\n                                   \"Max  Applicant Income\"))  # Subplot titles\n\nfig.add_trace(go.Bar(\n    x=result['Property_Area'],y=result['mean'],\n    marker={'color': result['mean'], \n    'colorscale': 'fall'},  \n    text=result['mean'],\n    textposition = \"inside\"),\n    row=1, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Property_Area'],y=result['min'],\n    marker={'color': result['min'], \n    'colorscale': 'fall'},  \n    text=result['min'],\n    textposition = \"inside\"),\n    row=2, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Property_Area'],y=result['max'],\n    marker={'color': result['max'], \n    'colorscale': 'fall'},  \n    text=result['max'],\n    textposition = \"inside\"),\n    row=3, col=1           \n)\nfig.update_layout(title = \"Property Area With Applicant Income\",title_x=0.5)\nfig.show()","23aec2f7":"df_PA=df_train_clean.groupby(by =['Property_Area'])['ApplicantIncome'].mean().to_frame().reset_index().rename(columns={'Property_Area':'Property_Area','ApplicantIncome':'mean'})\n\nfig = go.Figure(go.Bar(\n    x=df_PA['Property_Area'],y=df_PA['mean'],\n    marker={'color': df_PA['mean'], \n    'colorscale': 'twilight'},  \n    text=df_PA['mean'],\n    textposition = \"outside\",\n))\nfig.update_layout(title_text='Property Area With Applicant Mean Income',xaxis_title=\"Property Area\",yaxis_title=\"Applicant Income\",title_x=0.5)\nfig.show()","3c0cbdb7":"df_PA_mean=df_train_clean.groupby(by =['Property_Area'])['LoanAmount'].mean().to_frame().reset_index().rename(columns={'Property_Area':'Property_Area','LoanAmount':'mean'})\ndf_PA_min=df_train_clean.groupby(by =['Property_Area'])['LoanAmount'].min().to_frame().reset_index().rename(columns={'Property_Area':'Property_Area1','LoanAmount':'min'})\ndf_PA_max=df_train_clean.groupby(by =['Property_Area'])['LoanAmount'].max().to_frame().reset_index().rename(columns={'Property_Area':'Property_Area2','LoanAmount':'max'})\nresult = pd.concat([df_PA_mean, df_PA_min,df_PA_max], axis=1)\nresult.drop(['Property_Area1','Property_Area2'],inplace=True,axis=1)\n\n\nfig = make_subplots(rows=3, cols=1,\n                   subplot_titles=(\"Mean Loan Amount\",\n                                   \"Min Loan Amount\",\n                                   \"Max  Loan Amount\"))  # Subplot titles\n\nfig.add_trace(go.Bar(\n    x=result['Property_Area'],y=result['mean'],\n    marker={'color': result['mean'], \n    'colorscale': 'curl'},  \n    text=result['mean'],\n    textposition = \"inside\"),\n    row=1, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Property_Area'],y=result['min'],\n    marker={'color': result['min'], \n    'colorscale': 'curl'},  \n    text=result['min'],\n    textposition = \"inside\"),\n    row=2, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Property_Area'],y=result['max'],\n    marker={'color': result['max'], \n    'colorscale': 'curl'},  \n    text=result['max'],\n    textposition = \"inside\"),\n    row=3, col=1           \n)\nfig.update_layout(title = \"Property Area With Loan Amount\",title_x=0.5)\nfig.show()","cbff024f":"fig = px.scatter(df_train_clean, x='ApplicantIncome', y='LoanAmount',color=\"Property_Area\")\nfig.update_layout(title='Applicant Income Vs Loan Amount With Property Area ',xaxis_title=\"Applicant Income\",yaxis_title=\"Loan Amount \",title_x=0.5)\nfig.show()","0a6809bc":"df_C_H=df_train_clean['Credit_History'].value_counts().to_frame().reset_index().rename(columns={'index':'Credit_History','Credit_History':'count'})\n\n\nfig = go.Figure([go.Pie(labels=df_C_H['Credit_History'], values=df_C_H['count'],pull=[0,0.3])])\n\nfig.update_traces(hoverinfo='label+percent', textinfo='value+percent', textfont_size=12,insidetextorientation='radial')\n\nfig.update_layout(title=\"Credit History Count \",title_x=0.5)\nfig.show()","4e426ffe":"df_C_H=df_train_clean['Credit_History'].value_counts().to_frame().reset_index().rename(columns={'index':'Credit_History','Credit_History':'count'})\n\nfig = go.Figure(go.Bar(\n    x=df_C_H['Credit_History'],y=df_C_H['count'],\n    marker={'color': df_C_H['count'], \n    'colorscale': 'Viridis'},  \n    text=df_C_H['count'],\n    textposition = \"outside\",\n))\nfig.update_layout(title_text='Credit History Distribution',xaxis_title=\"Result\",yaxis_title=\"Count \",title_x=0.5)\nfig.show()","a107409e":"df_CH_mean=df_train_clean.groupby(by =['Credit_History'])['Loan_Amount_Term'].mean().to_frame().reset_index().rename(columns={'Credit_History':'Credit_History','Loan_Amount_Term':'mean'})\ndf_CH_min=df_train_clean.groupby(by =['Credit_History'])['Loan_Amount_Term'].min().to_frame().reset_index().rename(columns={'Credit_History':'Credit_History1','Loan_Amount_Term':'min'})\ndf_CH_max=df_train_clean.groupby(by =['Credit_History'])['Loan_Amount_Term'].max().to_frame().reset_index().rename(columns={'Credit_History':'Credit_History2','Loan_Amount_Term':'max'})\nresult = pd.concat([df_CH_mean, df_CH_min,df_CH_max], axis=1)\nresult.drop(['Credit_History1','Credit_History2'],inplace=True,axis=1)\n\n\nfig = make_subplots(rows=3, cols=1,\n                   subplot_titles=(\"Mean Loan Amount Term\",\n                                   \"Min Loan Amount Term\",\n                                   \"Max  Loan Amount Term\"))  # Subplot titles\n\nfig.add_trace(go.Bar(\n    x=result['Credit_History'],y=result['mean'],\n    marker={'color': result['mean'], \n    'colorscale': 'balance'},  \n    text=result['mean'],\n    textposition = \"inside\"),\n    row=1, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Credit_History'],y=result['min'],\n    marker={'color': result['min'], \n    'colorscale': 'balance'},  \n    text=result['min'],\n    textposition = \"inside\"),\n    row=2, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Credit_History'],y=result['max'],\n    marker={'color': result['max'], \n    'colorscale': 'balance'},  \n    text=result['max'],\n    textposition = \"inside\"),\n    row=3, col=1           \n)\nfig.update_layout(title = \"Credit History With Loan Amount Term\",title_x=0.5)\nfig.show()","9db463b7":"df_CH_mean=df_train_clean.groupby(by =['Credit_History'])['ApplicantIncome'].mean().to_frame().reset_index().rename(columns={'Credit_History':'Credit_History','ApplicantIncome':'mean'})\ndf_CH_min=df_train_clean.groupby(by =['Credit_History'])['ApplicantIncome'].min().to_frame().reset_index().rename(columns={'Credit_History':'Credit_History1','ApplicantIncome':'min'})\ndf_CH_max=df_train_clean.groupby(by =['Credit_History'])['ApplicantIncome'].max().to_frame().reset_index().rename(columns={'Credit_History':'Credit_History2','ApplicantIncome':'max'})\nresult = pd.concat([df_CH_mean, df_CH_min,df_CH_max], axis=1)\nresult.drop(['Credit_History1','Credit_History2'],inplace=True,axis=1)\n\n\nfig = make_subplots(rows=3, cols=1,\n                   subplot_titles=(\"Mean Applicant Income\",\n                                   \"Min Applicant Income\",\n                                   \"Max  Applicant Income\"))  # Subplot titles\n\nfig.add_trace(go.Bar(\n    x=result['Credit_History'],y=result['mean'],\n    marker={'color': result['mean'], \n    'colorscale': 'balance'},  \n    text=result['mean'],\n    textposition = \"inside\"),\n    row=1, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Credit_History'],y=result['min'],\n    marker={'color': result['min'], \n    'colorscale': 'balance'},  \n    text=result['min'],\n    textposition = \"inside\"),\n    row=2, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Credit_History'],y=result['max'],\n    marker={'color': result['max'], \n    'colorscale': 'balance'},  \n    text=result['max'],\n    textposition = \"inside\"),\n    row=3, col=1           \n)\nfig.update_layout(title = \"Credit History With Applicant Income\",title_x=0.5)\nfig.show()","5527640a":"df_CH_mean=df_train_clean.groupby(by =['Credit_History'])['LoanAmount'].mean().to_frame().reset_index().rename(columns={'Credit_History':'Credit_History','LoanAmount':'mean'})\ndf_CH_min=df_train_clean.groupby(by =['Credit_History'])['LoanAmount'].min().to_frame().reset_index().rename(columns={'Credit_History':'Credit_History1','LoanAmount':'min'})\ndf_CH_max=df_train_clean.groupby(by =['Credit_History'])['LoanAmount'].max().to_frame().reset_index().rename(columns={'Credit_History':'Credit_History2','LoanAmount':'max'})\nresult = pd.concat([df_CH_mean, df_CH_min,df_CH_max], axis=1)\nresult.drop(['Credit_History1','Credit_History2'],inplace=True,axis=1)\n\n\nfig = make_subplots(rows=3, cols=1,\n                   subplot_titles=(\"Mean Loan Amount \",\n                                   \"Min Loan Amount \",\n                                   \"Max  Loan Amount \"))  # Subplot titles\n\nfig.add_trace(go.Bar(\n    x=result['Credit_History'],y=result['mean'],\n    marker={'color': result['mean'], \n    'colorscale': 'balance'},  \n    text=result['mean'],\n    textposition = \"inside\"),\n    row=1, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Credit_History'],y=result['min'],\n    marker={'color': result['min'], \n    'colorscale': 'balance'},  \n    text=result['min'],\n    textposition = \"inside\"),\n    row=2, col=1         \n)\nfig.add_trace(go.Bar(\n    x=result['Credit_History'],y=result['max'],\n    marker={'color': result['max'], \n    'colorscale': 'balance'},  \n    text=result['max'],\n    textposition = \"inside\"),\n    row=3, col=1           \n)\nfig.update_layout(title = \"Credit History With Loan Amount \",title_x=0.5)\nfig.show()","f795fab3":"df_L_S=df_train_clean['Loan_Status'].value_counts().to_frame().reset_index().rename(columns={'index':'Loan_Status','Loan_Status':'count'})\n\n\nfig = go.Figure([go.Pie(labels=df_L_S['Loan_Status'], values=df_L_S['count'],pull=[0,0.2])])\n\nfig.update_traces(hoverinfo='label+percent', textinfo='value+percent', textfont_size=12,insidetextorientation='radial')\n\nfig.update_layout(title=\"Loan Status Count \",title_x=0.5)\nfig.show()","de3b57f1":"df_L_S=df_train_clean['Loan_Status'].value_counts().to_frame().reset_index().rename(columns={'index':'Loan_Status','Loan_Status':'count'})\n\nfig = go.Figure(go.Bar(\n    x=df_L_S['Loan_Status'],y=df_L_S['count'],\n    marker={'color': df_L_S['count'], \n    'colorscale': 'Viridis'},  \n    text=df_L_S['count'],\n    textposition = \"outside\",\n))\nfig.update_layout(title_text='Loan Status Distribution',xaxis_title=\"Result\",yaxis_title=\"Count \",title_x=0.5)\nfig.show()","4ab2b352":"g = sns.FacetGrid(df_train_clean, col=\"Credit_History\",)\ng.map_dataframe(sns.countplot, x=\"Loan_Status\")\ng.set_axis_labels(\" \", \"Count\");","15003e45":"df_M_and_G_and_E=df_train_clean.groupby(by =['Loan_Status','Property_Area'])['Dependents'].count().to_frame().reset_index().rename(columns={'Property_Area':'Property_Area','Loan_Status':'Loan_Status','Dependents':'count'})\nfig = px.bar(df_M_and_G_and_E, x=\"Property_Area\", y=\"count\", color=\"Loan_Status\", barmode=\"group\",\n             \n             )\nfig.update_layout(title_text='Loan Status With Property Area',title_x=0.5,\n                  hoverlabel=dict(\n                  bgcolor=\"white\",\n                  font_size=16,\n                  font_family=\"Rockwell\",\n                                \n     )\n  )\nfig.update_layout(xaxis_title=\"Property Area\",yaxis_title=\"Count\")\nfig.show()","409f0644":"df_M_and_G_and_E=df_train_clean.groupby(by =['Loan_Status','Education'])['Dependents'].count().to_frame().reset_index().rename(columns={'Education':'Education','Loan_Status':'Loan_Status','Dependents':'count'})\n\nfig = px.bar(df_M_and_G_and_E, x=\"Loan_Status\", y=\"count\", color=\"Education\", barmode=\"group\",\n             \n             )\nfig.update_layout(title_text='Loan Status With Education ',title_x=0.5,\n                  hoverlabel=dict(\n                  bgcolor=\"white\",\n                  font_size=16,\n                  font_family=\"Rockwell\",\n                                \n     )\n  )\nfig.update_layout(xaxis_title=\"Education\",yaxis_title=\"Count\")\nfig.show()","6276787e":"fig = px.scatter(df_train_clean, x='ApplicantIncome', y='LoanAmount',color=\"Loan_Status\")\nfig.update_layout(title='Applicant Income Vs Loan Amount With Loan Status ',xaxis_title=\"Applicant Income\",yaxis_title=\"Loan Amount \",title_x=0.5)\nfig.show()","fb94faad":"df_CM_train=df_train_clean.copy()","12c63c4c":"Gender_map= {'Male':0,'Female':1}\nMarried_map= {'Yes':1,'No':0}\nEducation_map= {'Graduate':1,'Not Graduate':0}\nSelf_Employed_map= {'Yes':1,'No':0}\nDependents_map= {'0':0,'1':1,'2':2,'3+':3}\nLoan_Status_map= {'Y':1,'N':0}\nRural_map={'Rural':1,'Urban':0,'Semiurban':0}\nUrban_map={'Rural':0,'Urban':1,'Semiurban':0}\nSemiurban_map={'Rural':0,'Urban':0,'Semiurban':1}","5af7993a":"df_CM_train[\"Gender\"]=df_CM_train[\"Gender\"].map(Gender_map)\ndf_CM_train[\"Married\"]=df_CM_train[\"Married\"].map(Married_map)\ndf_CM_train[\"Education\"]=df_CM_train[\"Education\"].map(Education_map)\ndf_CM_train[\"Dependents\"]=df_CM_train[\"Dependents\"].map(Dependents_map)\ndf_CM_train[\"Self_Employed\"]=df_CM_train[\"Self_Employed\"].map(Self_Employed_map)\ndf_CM_train[\"Loan_Status\"]=df_CM_train[\"Loan_Status\"].map(Loan_Status_map)\ndf_CM_train[\"Rural_Area\"]=df_CM_train[\"Property_Area\"].map(Rural_map)\ndf_CM_train[\"Urban_Area\"]=df_CM_train[\"Property_Area\"].map(Urban_map)\ndf_CM_train[\"Semiurban_Area\"]=df_CM_train[\"Property_Area\"].map(Semiurban_map)","95324a72":"df_CM_train","9b515584":"df_CM_train['Loan_Status1']=df_CM_train['Loan_Status']\ndf_CM_train.drop(['Loan_Status'],inplace=True,axis=1)\ndf_CM_train","d64ae941":"print(\"Correlation Matrix\")\nplt.rcParams['figure.figsize']=(12,8)\nsns.heatmap(df_CM_train.corr(),cmap='coolwarm',linewidths=.5,fmt=\".2f\",annot = True);","2ef373f1":"df_Dependents=df_CM_train['Dependents'].value_counts().to_frame().reset_index().rename(columns={'index':'Dependents','Dependents':'count'})\n\nfig = go.Figure(go.Bar(\n    x=df_Dependents['Dependents'],y=df_Dependents['count'],\n    marker={'color': df_Dependents['count'], \n    'colorscale': 'Viridis'},  \n    text=df_Dependents['count'],\n    textposition = \"outside\",\n))\nfig.update_layout(title_text='Dependents Distribution',xaxis_title=\"Dependents\",yaxis_title=\"Count \",title_x=0.5)\nfig.show()","68a88c5d":"df_M_and_G_and_E=df_CM_train.groupby(by =['Dependents','Loan_Status1'])['Education'].count().to_frame().reset_index().rename(columns={'Dependents':'Dependents','Loan_Status':'Loan_Status','Education':'count'})\ndf_M_and_G_and_E['Loan_Status1']=df_M_and_G_and_E['Loan_Status1'].astype('category')\n\nfig = px.bar(df_M_and_G_and_E, x=\"Dependents\", y=\"count\", color=\"Loan_Status1\", barmode=\"group\",\n             \n             )\nfig.update_layout(title_text='Loan Status With Dependents ',title_x=0.5,\n                  hoverlabel=dict(\n                  bgcolor=\"white\",\n                  font_size=16,\n                  font_family=\"Rockwell\",\n                                \n     )\n  )\nfig.update_layout(xaxis_title=\"Dependents\",yaxis_title=\"Count\")\nfig.show()","96ee526e":"df_M_and_G=df_CM_train.groupby(by =['Dependents'])['ApplicantIncome'].mean().to_frame().reset_index().rename(columns={'Dependents':'Dependents','ApplicantIncome':'Mean'})\ndf_M_and_G[\"deneme\"]=[1,2,3,4]\ndf_M_and_G[\"per_capita_income\"]=df_M_and_G['Mean']\/df_M_and_G['deneme']\n\nfig = go.Figure(go.Bar(\n    x=df_M_and_G['Dependents'],y=df_M_and_G['per_capita_income'],\n    marker={'color': df_M_and_G['per_capita_income'], \n    'colorscale': 'Viridis'},  \n    text=df_M_and_G['per_capita_income'],\n    textposition = \"outside\",\n))\nfig.update_layout(title_text=' Mean Per Capita Income Distribution With Dependents ',xaxis_title=\"Dependents\",yaxis_title=\"Income \",title_x=0.5)\nfig.show()","d4215227":"df_M_and_G=df_CM_train.groupby(by =['Dependents'])['ApplicantIncome'].median().to_frame().reset_index().rename(columns={'Dependents':'Dependents','ApplicantIncome':'Median'})\n\nfig = go.Figure(go.Bar(\n    x=df_M_and_G['Dependents'],y=df_M_and_G['Median'],\n    marker={'color': df_M_and_G['Median'], \n    'colorscale': 'Viridis'},  \n    text=df_M_and_G['Median'],\n    textposition = \"outside\",\n))\nfig.update_layout(title_text=' Median Applicant Income Distribution With Dependents ',xaxis_title=\" Dependents\",yaxis_title=\"Income \",title_x=0.5)\nfig.show()","3b91cfa2":"df_NMV_train=df_train_clean.copy()","a04eaad0":"Gender_map= {'Male':0,'Female':1}\nMarried_map= {'Yes':1,'No':0}\nEducation_map= {'Graduate':1,'Not Graduate':0}\nSelf_Employed_map= {'Yes':1,'No':0}\nDependents_map= {'0':0,'1':1,'2':2,'3+':3}\nLoan_Status_map= {'Y':1,'N':0}\nRural_map={'Rural':1,'Urban':0,'Semiurban':0}\nUrban_map={'Rural':0,'Urban':1,'Semiurban':0}\nSemiurban_map={'Rural':0,'Urban':0,'Semiurban':1}","71b5148c":"df_NMV_train[\"Gender\"]=df_NMV_train[\"Gender\"].map(Gender_map)\ndf_NMV_train[\"Married\"]=df_NMV_train[\"Married\"].map(Married_map)\ndf_NMV_train[\"Education\"]=df_NMV_train[\"Education\"].map(Education_map)\ndf_NMV_train[\"Dependents\"]=df_NMV_train[\"Dependents\"].map(Dependents_map)\ndf_NMV_train[\"Self_Employed\"]=df_NMV_train[\"Self_Employed\"].map(Self_Employed_map)\ndf_NMV_train[\"Loan_Status\"]=df_NMV_train[\"Loan_Status\"].map(Loan_Status_map)\ndf_NMV_train[\"Rural_Area\"]=df_NMV_train[\"Property_Area\"].map(Rural_map)\ndf_NMV_train[\"Urban_Area\"]=df_NMV_train[\"Property_Area\"].map(Urban_map)\ndf_NMV_train[\"Semiurban_Area\"]=df_NMV_train[\"Property_Area\"].map(Semiurban_map)","69fac7d4":"df_NMV_train","96f64f25":"df_NMV_train.drop(['Property_Area'],inplace=True,axis=1)\ndf_NMV_train.head()","18461ab7":"from sklearn.neighbors import LocalOutlierFactor\nclf = LocalOutlierFactor(n_neighbors = 20, contamination = 0.1)","47add39e":"df_out=df_NMV_train.copy()\nclf.fit_predict(df_out)\ndf_scores = clf.negative_outlier_factor_","9e03448d":"np.sort(df_scores)[0:70]","5b063db3":"threshold_value = np.sort(df_scores)[14]\nthreshold_value","54d243b4":"Outlier_df= df_out[df_scores < threshold_value]\nindexs=Outlier_df.index\nOutlier_df","1f0dce50":"# Kick Outliers\nfor i in indexs:\n    df_NMV_train.drop(i, axis = 0,inplace = True)","63ef30c2":"df_NMV_train.info()","cc342c4b":"y=df_NMV_train['Loan_Status']\nX=df_NMV_train.drop('Loan_Status',axis=1)\n\nprint('X shape :',X.shape)\nprint('y shape :',y.shape)","d47770d5":"X = (X - np.min(X)) \/ (np.max(X) - np.min(X)).values\nX.head()","ad77cbda":"from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nX_train,X_test,y_train,y_test=train_test_split(X,y,\n                                               test_size=0.2,\n                                               random_state=42)","cbfee199":"print('X_train :',X_train.shape)\nprint('X_test :',X_test.shape)\nprint('y_train :',y_train.shape)\nprint('y_test :',y_test.shape)","0a1455e9":"from sklearn.linear_model import LogisticRegression\nloj = LogisticRegression(solver = \"liblinear\")\nloj_model = loj.fit(X_train,y_train)\nloj_model","f61f4f13":"y_pred_loj = loj_model.predict(X_test)","602afbe7":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report","95a7ccb9":"accuracy_score(y_test, y_pred_loj)","97351a39":"# Cofusion Matrix\ncm = confusion_matrix(y_test, y_pred_loj)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')","d9cbad9e":"print(\"Training Accuracy :\", loj_model.score(X_train, y_train))\n\nprint(\"Testing Accuracy :\", loj_model.score(X_test, y_test))","9259f72e":"cross_val_score(loj_model, X_test, y_test, cv = 10).mean()","5bc18627":"print(classification_report(y_test, y_pred_loj))","32b46d5e":"from sklearn.metrics import roc_auc_score,roc_curve\n\nlogit_roc_auc = roc_auc_score(y, loj_model.predict(X))\n\nfpr, tpr, thresholds = roc_curve(y, loj_model.predict_proba(X)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Oran\u0131')\nplt.ylabel('True Positive Oran\u0131')\nplt.title('ROC')\nplt.show()","c74f2f31":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn_model = knn.fit(X_train, y_train)\nknn_model","802a6051":"y_pred_knn = knn_model.predict(X_test)","712424cb":"accuracy_score(y_test, y_pred_knn)","9c59d09e":"# Cofusion Matrix\ncm = confusion_matrix(y_test, y_pred_knn)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')","900409a8":"print(classification_report(y_test, y_pred_knn))","22d57b2e":"knn_params = {\"n_neighbors\": np.arange(1,50)}","7f1a61fc":"knn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, knn_params, cv=10)\nknn_cv.fit(X_train, y_train)","34ca7004":"print(\"Best score:\" + str(knn_cv.best_score_))\nprint(\"Best params: \" + str(knn_cv.best_params_))","6608760f":"knn = KNeighborsClassifier(8)\nknn_tuned = knn.fit(X_train, y_train)","90e70b16":"knn_tuned.score(X_test, y_test)","b9142600":"y_pred_tuned = knn_tuned.predict(X_test)","e19f9b4e":"# Cofusion Matrix\ncm = confusion_matrix(y_test, y_pred_tuned)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')","277d0bd4":"from sklearn.neural_network import MLPClassifier\nmlpc = MLPClassifier().fit(X_train, y_train)","ceb2bc47":"y_pred_mlpc = mlpc.predict(X_test)\naccuracy_score(y_test,y_pred_mlpc)","227eab5c":"accuracy_score(y_test, y_pred_mlpc)","3cd9d60f":"# Cofusion Matrix\ncm = confusion_matrix(y_test, y_pred_mlpc)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')","4ab2c481":"print(classification_report(y_test, y_pred_mlpc))","8a5395e2":"mlpc_params = {\"alpha\": [0.1, 0.01, 0.02, 0.005, 0.0001,0.00001],\n              \"hidden_layer_sizes\": [(10,10,10),\n                                     (100,100,100),\n                                     (100,100),\n                                     (3,5), \n                                     (5, 3)],\n              \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\n              \"activation\": [\"relu\",\"logistic\"]}\n","63a671e4":"mlpc = MLPClassifier()\nmlpc_cv_model = GridSearchCV(mlpc, mlpc_params, \n                         cv = 10, \n                         n_jobs = -1,\n                         verbose = 2)\n\nmlpc_cv_model.fit(X_train, y_train)","9377fe25":"print(\"Best params: \" + str(mlpc_cv_model.best_params_))","8b842d79":"mlpc_tuned = MLPClassifier(activation = \"relu\", \n                           alpha = 0.0001, \n                           hidden_layer_sizes = (10,10,10),\n                          solver = \"adam\")","bfccc061":"mlpc_tuned.fit(X_train, y_train)","2788270d":"y_pred_mlpc = mlpc_tuned.predict(X_test)\naccuracy_score(y_test, y_pred_mlpc)","1a85125d":"# Cofusion Matrix\ncm = confusion_matrix(y_test, y_pred_mlpc)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')","87d4f93d":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier().fit(X_train, y_train)","8ac05f14":"y_pred_rf = rf_model.predict(X_test)\naccuracy_score(y_test, y_pred_rf)","698b3005":"# Cofusion Matrix\ncm = confusion_matrix(y_test, y_pred_rf)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')","badccdb2":"print(classification_report(y_test, y_pred_rf))","932331aa":"Importance = pd.DataFrame({\"Importance\": rf_model.feature_importances_*100},\n                         index = X_train.columns)","8754d105":"Importance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"Variable Significance Levels\")","1c477a8d":"rf_params = {\"max_depth\": [2,5,8,10],\n            \"max_features\": [2,5,8],\n            \"n_estimators\": [10,500,1000],\n            \"min_samples_split\": [2,5,10]}","e63b58f1":"rf_model = RandomForestClassifier()\n\nrf_cv = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 10, \n                           n_jobs = -1, \n                           verbose = 2) \nrf_cv_model=rf_cv.fit(X_train, y_train)","be9e3b2f":"print(\"Best params: \" + str(rf_cv_model.best_params_))","2706922b":"rf_tuned= RandomForestClassifier(max_depth = 8, \n                                  max_features = 2, \n                                  min_samples_split = 10,\n                                  n_estimators = 1000)\n\nrf_tuned.fit(X_train, y_train)","7de6bd65":"y_pred_tuned = rf_tuned.predict(X_test)\naccuracy_score(y_test, y_pred_tuned)","24a5521c":"# Cofusion Matrix\ncm = confusion_matrix(y_test, y_pred_tuned)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')","7c59288a":"from sklearn.naive_bayes import GaussianNB\nnb = GaussianNB()\nnb_model = nb.fit(X_train, y_train)\nnb_model","b399df89":"y_pred_nb = nb_model.predict(X_test)","3bbfc726":"accuracy_score(y_test, y_pred_nb)","80e3b093":"# Cofusion Matrix\ncm = confusion_matrix(y_test, y_pred_nb)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')","bb0a3b3f":"print(classification_report(y_test, y_pred_nb))","67f322a8":"cross_val_score(nb_model, X_test, y_test, cv = 10).mean()","dd042aac":"from sklearn.svm import SVC\nsvm_model = SVC(kernel = \"linear\").fit(X_train, y_train)","ba8b84ea":"y_pred = svm_model.predict(X_test)","937d6964":"accuracy_score(y_test, y_pred)","7e15de32":"print(classification_report(y_test, y_pred_mlpc))","c1b7819a":"# Cofusion Matrix\ncm = confusion_matrix(y_test, y_pred_nb)\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')","cd12f0a8":"models = [\n    loj_model,\n    knn_tuned,\n    mlpc_tuned,   \n    rf_tuned,\n    nb_model,\n    svm_model\n      \n]\n\nfor model in models:\n    names = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"-\"*28)\n    print(names + \":\" )\n    print(\"Accuracy: {:.4%}\".format(accuracy))","1c861ab2":"results = pd.DataFrame(columns= [\"Models\",\"Accuracy\"])\n\nfor model in models:\n    names = model.__class__.__name__\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)    \n    result = pd.DataFrame([[names, accuracy*100]], columns= [\"Models\",\"Accuracy\"])\n    results = results.append(result)\n    \n    \nsns.barplot(x= 'Accuracy', y = 'Models', data=results, color=\"r\")\nplt.xlabel('Accuracy %')\nplt.title('Accuracy Ratios of Models');  ","f43e4260":"Gender_map= {'Male':0,'Female':1}\nMarried_map= {'Yes':1,'No':0}\nEducation_map= {'Graduate':1,'Not Graduate':0}\nSelf_Employed_map= {'Yes':1,'No':0}\nDependents_map= {'0':0,'1':1,'2':2,'3+':3}\nLoan_Status_map= {'Y':1,'N':0}\nRural_map={'Rural':1,'Urban':0,'Semiurban':0}\nUrban_map={'Rural':0,'Urban':1,'Semiurban':0}\nSemiurban_map={'Rural':0,'Urban':0,'Semiurban':1}","24ee4daa":"df_test=pd.read_csv(\"\/kaggle\/input\/loan-eligible-dataset\/loan-test.csv\")","cc1e6e0d":"df_test[\"Gender\"]=df_test[\"Gender\"].map(Gender_map)\ndf_test[\"Married\"]=df_test[\"Married\"].map(Married_map)\ndf_test[\"Education\"]=df_test[\"Education\"].map(Education_map)\ndf_test[\"Dependents\"]=df_test[\"Dependents\"].map(Dependents_map)\ndf_test[\"Self_Employed\"]=df_test[\"Self_Employed\"].map(Self_Employed_map)\ndf_test[\"Rural_Area\"]=df_test[\"Property_Area\"].map(Rural_map)\ndf_test[\"Urban_Area\"]=df_test[\"Property_Area\"].map(Urban_map)\ndf_test[\"Semiurban_Area\"]=df_test[\"Property_Area\"].map(Semiurban_map)","2ad54426":"df_test.drop(['Property_Area','Loan_ID'],inplace=True,axis=1)","57ade173":"df_test=df_test.dropna()","e517676f":"sample_df=df_test.sample(20)\nsample_df.head()","5ba4f1fc":"df_test.info()","6056db0a":"df_test.head()","381a12f0":"models = [\n    loj_model,\n    knn_tuned,\n    mlpc_tuned,   \n    rf_tuned,\n    nb_model,\n    svm_model\n]\n #test sonuclar\u0131 yok neyle k\u0131yal\u0131caz Sadge\nfor model in models:\n    names = model.__class__.__name__\n    y_pred = model.predict(sample_df)\n    print(\"-\"*28)\n    print(names + \":\" )\n    print(\" Sunuclar:\" )\n    print(y_pred)","76a0c424":"## Test Data Preparation","0e8ca057":"## Conclusion 4 \n* Self Employed rate in people 14%\n* self Employed rate in for men 14%\n* self Employed rate in for women 14%","e77261eb":"# <a id='2'> 2.Data <\/a>\n\n## Data Columns Means\nLoan_ID --------------> Unique Loan ID. <br>\nGender --------------> Male\/ Female (cinsiyet) <br>\nMarried --------------> Applicant married (medeni hali) (Y\/N) <br>\nDependents ------------> Number of dependents (bakmas\u0131 gereken ki\u015fi say\u0131s\u0131) <br>\nEducation -------------> Applicant Education  (egitim durumu) (Graduate\/ Under Graduate) <br>\nSelf_Employed ---------> Self-employed (kendi i\u015finde \u00e7al\u0131\u015fan) (Y\/N) <br>\nApplicantIncome -------> Applicant income  (basvuru yapan\u0131n geliri)<br>\nCoapplicantIncome -----> Coapplicant income (basvuru yapan\u0131n e\u015finin geliri) <br>\nLoanAmount -----------> Loan amount in thousands (1 bin kars\u0131 odeditleri miktar) <br>\nLoan_Amount_Term ------> Term of a loan in months ( ka\u00e7 ayl\u0131k ) <br>\nCredit_History --------> Credit history meets guidelines (kredi gecmi\u015fi kosular\u0131 sagl\u0131yor mu,kara liste  ) <br>\nProperty_Area ---------> Urban\/ Semi-Urban\/ Rural (evlerin mekanlar\u0131) <br>\nLoan_Status -----------> Loan approved (Y\/N) (kredi onay) <br>","ed2ddf66":"<font size=\"+2\" color=\"LIGHTSEAGREEN\"><b>My Other Kernels<\/b><\/font><br>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/lego-transfer-cnn-classification\" class=\"btn btn-primary\" style=\"color:white;\">Lego Transfer-CNN Classification<\/a>\n\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/face-image-classification\" class=\"btn btn-primary\" style=\"color:white;\">Face Image Classification<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/book-review-ratings-data-analysis-visualization\" class=\"btn btn-primary\" style=\"color:white;\">Book Review Ratings Analysis & Visualization<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/insurance-prediction-lgbm-gbm-xgboost-eda\" class=\"btn btn-primary\" style=\"color:white;\">Insurance Prediction- LGBM,GBM,XGBoost EDA<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/fish-market-data-visualisation-machine-learning\" class=\"btn btn-primary\" style=\"color:white;\">Fish Market Data Visualisation & Machine Learning<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/seabron-plotly-for-beginners\" class=\"btn btn-primary\" style=\"color:white;\">Seabron & Plotly For Beginners<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/basketball-players-stats-data-visualisation\" class=\"btn btn-primary\" style=\"color:white;\">Basketball Players Stats Data Visualisation<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/women-s-football-results-visualization\" class=\"btn btn-primary\" style=\"color:white;\">Women's Football Results Visualization<\/a>\n\n<a href=\"https:\/\/www.kaggle.com\/drfrank\/us-police-shootings-data-visualisation\" class=\"btn btn-primary\" style=\"color:white;\">Us Police Shootings Data Visualisation<\/a>","2805157c":"* Exploratory Data Analysis refers to the critical process of performing \ninitial investigations on data so as to discover patterns,to spot anomalies, \nto test hypothesis and to check assumptions with\nthe help of summary statistics and graphical representations. <br>\n\n* Your goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which graphs, models, or transformations to make.<br>\n\n* Generate questions about your data.<br>\n\n* Search for answers by visualising, transforming, and modelling your data. <br>\n\n* Use what you learn to refine your questions and\/or generate new questions. <br>\n\n* EDA is not a formal process with a strict set of rules.<br> \n* More than anything, EDA  is a state of mind.<br> \n* During the initial phases of EDA you should feel free to investigate every idea that occurs to you.<br> \n* Some of these ideas will pan out, and some will be dead ends.<br>\n* As your exploration continues, you will home in on a few particularly productive areas that you\u2019ll eventually write up and communicate to others.<br>\n\n* Let's start exploring our data","5c7f3c3c":"## **Conclusion** 7\n\n* 85 percent of accepted applications have a positive credit history\n","1c6c0ba9":" ## <a id='25'> 19.Random Forest <\/a>","6b50367d":"## **Conclusion** 8\n\n* Rate of accepted applications 70 meaning that the data set is unbalanced\n","53d6ff0d":"## <a id='30'><font color=\"LIGHTSEAGREEN\" size=+2.5><b>24.End Note<\/b><\/font> <\/a>\n\nI hope you enjoyed my kernel.If you like this notebook, an <font color=\"DARKCYAN\"><b>Upvote<\/b><\/font> would be great ! :)\n\nI am new with data science. Please <font color=\"GREEN\"><b>comments<\/b><\/font> me your <font color=\"GREEN\"><b>feedbacks<\/b><\/font> to help me improve myself. \n    \nThanks for your time","1655bace":"## <a id='29'>23.Conclusion <\/a>\n\n* As you can see our models are overfeeding.<br>\n* We have little data. <br>\n* Learning is less because the dataset is unstable.<br>\n* We either approve or reject all incoming loan applications <br>\n* We can create new data columns. <br>\n* We can drop the columns that are not important. <br>\n* We need do feature engineering.<br>\n\n\n**Models**\n\n![ ](https:\/\/media.giphy.com\/media\/l22ysLe54hZP0wubek\/giphy.gif) \n                    \n","54a161f4":"## <a id='8'> 5.Married <\/a>\n* How is the marriage distribution? <br>\n* How is the distribution of marriage by gender? <br>","3705df54":"# Table Of Contents\n- ## <a href='#0'>  Dataset Introduction <\/a> \n- ## <a href='#1'>1. Importing Libraries and Dataset <\/a> \n- ## <a href='#2'>2. Data <\/a> \n- ## <a href='#3'>3.Exploratory Data Analysis <\/a> \n- ### <a href='#4'>3.1 Describe Function  <\/a> \n- ### <a href='#5'>3.2 Missing Value <\/a>\n- ### <a href='#6'>3.3 Questions <\/a> \n- ## <a href='#7'>4.Gender  <\/a> \n- ## <a href='#8'>5.Marriage   <\/a>\n- ## <a href='#9'>6.Education  <\/a>\n- ## <a href='#10'>7.Self Employed  <\/a>\n- ## <a href='#11'>8.Applicant Income <\/a>\n- ## <a href='#12'>9.Location Of The Houses <\/a>\n- ## <a href='#13'>10.Credit History <\/a>\n- ## <a href='#14'>11.Loan Status <\/a>\n- ## <a href='#15'>12.Correlation Matrix <\/a>\n- ## <a href='#16'>13.Dependents  <\/a> \n- ## <a href='#17'>14.Summary Conclusion <\/a>\n- ## <a href='#18'>15.Machine Learning <\/a>\n- ### <a href='#19'>15.1 Data Preprocessing <\/a>\n- ### <a href='#20'>15.2 Local Outlier Factor <\/a>\n- ### <a href='#21'>15.3 Normalize <\/a> \n- ## <a href='#22'>16.Logistic Regression <\/a>\n- ## <a href='#23'>17.KNN <\/a>\n- ## <a href='#24'>18.Artificial Neural Networks <\/a>\n- ## <a href='#25'>19.Random Forest <\/a>\n- ## <a href='#26'>20.Gaussian Naive Bayes <\/a>\n- ## <a href='#27'>21.SVC <\/a>\n- ## <a href='#28'>22.Model Comparison <\/a>\n- ## <a href='#29'>23.Conclusion<\/a>\n- ## <a href='#30'>24.End Note<\/a>","37f1419c":"## <a id='17'> <font size=\"+2\" color=\"LIGHTSEAGREEN\"><b>Reference<\/b><\/font><br>\n* https:\/\/seaborn.pydata.org\/api.html\n* https:\/\/plotly.com\/python\/\n* https:\/\/stackoverflow.com \n* https:\/\/towardsdatascience.com\/exploratory-data-analysis-8fc1cb20fd15 <br>\n* https:\/\/r4ds.had.co.nz\/exploratory-data-analysis.html#introduction-3  <br>\n* https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/index.html <br>\n* https:\/\/www.displayr.com\/what-is-a-correlation-matrix\/ <br>\n* https:\/\/medium.com\/towards-artificial-intelligence\/differences-between-ai-and-machine-learning-and-why-it-matters-1255b182fc6 <br>\n* http:\/\/www.cs.cmu.edu\/afs\/cs.cmu.edu\/user\/mitchell\/ftp\/mlbook.html <br>","dd08b27e":"### Model Tuning","d9928efc":"## <a id='14'> 11.Loan Status <\/a>\n* How is the Loan Status Distribution ?\n* How is the Loan Status Distribution with credit history?","2ed3d980":"## Conclusion 3\n* Education rate in people 80% <br>\n* The education rate for men is 78% <br>\n* The education rate for women is 84% <br>","39fb16e2":"## Model Tuning","460bffb1":"# <a id='1'> 1. Importing Libraries and Dataset<\/a>","657a999e":"* Data has only float,object and integer values.<br>\n* Variable column has null\/missing values. <br>","4fdef42d":"## <a id='16'> 13.Dependents <\/a>\n* How is the Dependents Distribution ?\n* How much is the per capita income ?","ef6a5985":"## <a id='12'> 9.Location Of The Houses <\/a>\n* How is the location of the houses? <br>\n* How much is the income of the applicants distributed according to the location of the houses?<br>\n* How much is the Loan Amount of the applicants distributed according to the location of the houses?<br>","876e8d94":"## <a id='17'> 14.Summary Conclusion <\/a>\n\n* We will work in an area where men are dominant.\n\n* More than half of the people are married\n\n* Education rate in people 80%\n\n* Self Employed rate in people 14%\n\n* Min Income =150\n\n* Max Income =81k\n\n* Mean Income =5350\n\n* 40 percent of homes are in semi-urban areas\n\n* 31 percent of homes are in urban areas\n\n* 29 percent of homes are in rural areas\n\n* 85 percent of accepted applications have a positive credit history\n\n* Rate of accepted applications 70 meaning that the data set is unbalanced\n\n","a6302000":" ## <a id='28'> 22.Model Comparison <\/a>","30ad22b2":" ## <a id='21'> 15.3  Normalize<\/a>\n","38926c77":" ## <a id='26'> 20.Gaussian Naive Bayes <\/a>","8798bebb":"## <a id='13'> 10.Credit History <\/a>\n* How is the Credit History Distribution ?\n* How does the credit history relate to applicant income,loan amount,loan amount term?(min,max mean) <br>\n","2bfc8d4a":"## <a id='11'> 8.Applicant Income <\/a>\n* How is the  applicant income distribution? <br>\n* How much is the average,min,max applicant income?<br>\n* How much is the average,min,max applicant income by self employed?<br>","0269a2c4":"# <a id='6'> 3.3 Questions<\/a>\n* Generate questions about your data.\n* Find answer and visualize it.make inferences\n* Q1.How is the gender distribution?\n* Q2.How is the marriage distribution?\n* Q3.How is the distribution of marriage by gender?\n* Q4.How is the education distribution?\n* Q5.How is the distribution of education by gender,marriage?\n* Q6.How is the self employed distribution?\n* Q7.How is the distribution of self employed by gender?\n* Q8.How is the  applicant income distribution? \n* Q9.How much is the average,min,max applicant income?\n* Q9.How much is the average,min,max applicant income by self employed?\n* Q10.How is the location of the houses? \n* Q11.How much is the income of the applicants distributed according to the location of the houses?\n* Q12.How much is the Loan Amount of the applicants distributed according to the location of the houses?\n* Q13.How is the Credit History Distribution ?\n* Q14.How does the credit history relate to applicant income,loan amount,loan amount term?(min,max mean)\n* Q15.How is the Credit History Distribution ?\n* Q16.How does the credit history relate to applicant income,loan amount,loan amount term?(min,max mean)\n* .....","24bedb7b":"## Conclusion 2 \n* More than half of the people are married <br>\n* The marriage rate for men is 72% <br>\n* The marriage rate for women is 30% <br>","03f22529":" ## <a id='23'> 17.KNN <\/a>","b761beb3":"**Conclude Q1**\n* Most of the people who apply are men.<br>\n* We will work in an area where men are dominant. <br>\n","843743fa":"## Conclusion 5\n\n* Min Income =150\n* Max Income =81k\n* Mean Income =5350\n* Self Employed Min Income =1000\n* Self Employed Max Income =39.1k\n* Self Employed Mean Income =7790\n* Employed Min Income =150\n* Employed Max Income =81k\n* Employed Mean Income =4980","d44db63a":"# <a id='3'> 3.Exploratory Data Analysis<\/a>\n","d84c7b12":" ## <a id='22'> 16.Logistic Regression <\/a>\n","7dff62ac":"## **Conclusion** 6\n\n* Number of houses in **Semiurban** Area:191 \n* Number of houses in **Rural** Area:139 \n* Number of houses in **Urban** Area:150\n<br>\n<br>\n* Applicant Income with **Rural** Area\n* **mean**=5764,**min**=150, **max**=81000\n* Applicant Income with **Semiurban** Area \n* **mean**=5368,**min**=1500, **max**=39999\n* Applicant Income with **Urban** Area\n* **mean**=4988,**min**=1000, **max**=18333\n<br>\n<br>\n* Loan Amount with **Semiurban** Area:\n* **mean**=146,**min**=25, **max**=600\n* Loan Amount with **Rural** Area:\n* **mean**=155,**min**=40, **max**=570\n* Loan Amount with **Urban** Area:\n* **mean**=132,**min**=9, **max**=500\n<br>\n<br>\n* Loan Amount Term with **Semiurban** Area:\n* **mean**=344,**min**=36, **max**=480\n* Loan Amount Term with **Rural** Area:\n* **mean**=345,**min**=84, **max**=480\n* Loan Amount Term with **Urban** Area:\n* **mean**=336,**min**=60, **max**=480","d7eb3e2c":" ## <a id='19'> 15.1 Data Preprocessing<\/a>\n","7710b99a":" ## <a id='18'> 15.Machine Learning <\/a>\n![](https:\/\/miro.medium.com\/max\/700\/1*1NNRxaTDtmZFF51JZOd-Cw.jpeg)\n\n* Applications range from datamining programs that discover general rules in large data sets, to information filtering systems that automatically learn users' interests.\n","e1a2326c":"\n# <a id='4'> 3.1 Describe Function<\/a>\n\n* Generate descriptive statistics.<br>\n* Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset\u2019s distribution, excluding NaN values.<br>\n* The **describe**() function in pandas is very handy\nin getting various **summary statistics**.<br>\n* This function returns the **count**, **mean**, **standard deviation**,\n**minimum** and **maximum** **values** and the **quantiles of the data**.<br>","247c81e5":" ## <a id='27'> 21.SVC<\/a>","20dbd4e5":"* We don't have duplicated data ","512d3378":"## <a id='9'> 6.Education <\/a>\n* How is the Education distribution? <br>\n* How is the distribution of education by gender,marriage? <br>","d1f264db":" ## <a id='24'> 18.Artificial Neural Networks <\/a>\n \n \n ","cd755094":"## <a id='7'> 4.Gender <\/a>\n\n* How is the gender distribution? <br>\n","c5dc7e77":"# <a id='5'> 3.2 Missing Value<\/a>\n\n* Missing data is a big topic, I'll try to explain it at another time. <br>\n* In this project, I will remove all of the missing data from the data set. <br>","c7a678fb":"### Data split","b7bafaa4":"## <a id='15'> 12.Correlation Matrix <\/a>\n\n* A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables.<br>\n* A correlation matrix is used to summarize data, as an input into a more advanced analysis, and as a diagnostic for advanced analyses.<br>\n\n* **There are three broad reasons for computing a correlation matrix** <br>\n\n* To summarize a large amount of data where the goal is to see patterns. <br>\n\n* To input into other analyses. For example, people commonly use correlation matrixes as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise. <br>\n\n* As a diagnostic when checking other analyses. For example, with linear regression, a high amount of correlations suggests that the linear regression estimates will be unreliable.<br>","4fb381e1":" ## <a id='20'> 15.2 Local Outlier Factor<\/a>\n\n![](http:\/\/upload.wikimedia.org\/wikipedia\/commons\/4\/4e\/LOF-idea.svg)\n*  The local outlier factor is based on a concept of a local density, where locality is given by k nearest neighbors, whose distance is used to estimate the density. By comparing the local density of an object to the local densities of its neighbors, one can identify regions of similar density, and points that have a substantially lower density than their neighbors. These are considered to be outliers.","60e80674":"# <a id='0'> Dataset Introduction <\/a>","172f2281":"![](https:\/\/media.giphy.com\/media\/5xtDarqCp0eomZaFJW8\/giphy.gif)\n\n * Let's Say, You are the owner of the **Housing Finance Company** and you want to<br> build your own model to predict the customers are applying for the home loan and<br> company want to check and validate the customer are eligible for the home loan.<br>\n * Company wants to make automate the Loan Eligibility Process in a real time<br>  scenario related to customer's detail provided while applying <br>application for home loan forms.<br>\n * We will try to build a model using data from loan applications. <br>\n * Let's start <br>\n \n","ae347d43":"## <a id='10'> 7.Self Employed <\/a>\n* How is the Self Employed distribution? <br>\n* How is the distribution of education by gender? <br>","f4390da8":"* Dataset comprises of 614 observations and 13 characteristics.<br>\n* Out of which one is dependent variable and rest 12 are independent variables <br>"}}