{"cell_type":{"e3f2f9f9":"code","112904eb":"code","5b76cdba":"code","d7231175":"code","9773f561":"code","2a45b748":"code","5eedcb0c":"code","52b053f1":"code","93268cfb":"code","7a6a65e7":"code","2aecbac4":"code","613a25dd":"code","9980bc50":"code","5bda3629":"markdown","4dc4710b":"markdown","03b30279":"markdown","b7b862f6":"markdown","833bf48b":"markdown","a29ac1e6":"markdown","a1f65ef7":"markdown","6d0d588e":"markdown","e06d22d8":"markdown","1a865277":"markdown"},"source":{"e3f2f9f9":"import pandas as pd\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom tqdm import tqdm, tqdm_notebook\nfrom pathlib import Path","112904eb":"df = pd.read_csv('..\/input\/quotes-from-goodread\/all_quotes.csv')\ndf = df[['Quote', 'Author', 'Main Tag']]\ndf['Author'] = df['Author'].fillna('')\nls= []\nfor i in range(len(df['Author'])):\n    if(df['Main Tag'][i] == 'happiness'):\n        ls.append(1)\n    else:\n        ls.append(0)\ndf.dropna(axis=0,inplace=True)\ndf['Happiness'] = ls","5b76cdba":"from sklearn.utils import shuffle\ndf = shuffle(df)","d7231175":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df['Quote'], df['Happiness'], test_size=0.3, random_state=101)","9773f561":"class Sequences(Dataset):\n    def __init__(self, x, y):\n        x = x\n        y = y\n        self.vectorizer = CountVectorizer(stop_words='english', max_df=0.99, min_df=0.005)\n        self.sequences = self.vectorizer.fit_transform(x.tolist())\n        self.labels = y.tolist()\n        self.token2idx = self.vectorizer.vocabulary_\n        self.idx2token = {idx: token for token, idx in self.token2idx.items()}\n        \n    def __getitem__(self, i):\n        return self.sequences[i, :].toarray(), self.labels[i]\n    \n    def __len__(self):\n        return self.sequences.shape[0]","2a45b748":"dataset = Sequences(X_train, y_train)\ntrain_loader = DataLoader(dataset, batch_size=100)\n\nprint(dataset[5][0].shape)","5eedcb0c":"class BagOfWordsClassifier(nn.Module):\n    def __init__(self, vocab_size, hidden1, hidden2):\n        super(BagOfWordsClassifier, self).__init__()\n        self.fc1 = nn.Linear(vocab_size, hidden1)\n        self.fc2 = nn.Linear(hidden1, hidden2)\n        self.fc3 = nn.Linear(hidden2, 1)\n    \n    def forward(self, inputs):\n        x = F.relu(self.fc1(inputs.squeeze(1).float()))\n        x = F.relu(self.fc2(x))\n        return self.fc3(x)","52b053f1":"model = BagOfWordsClassifier(len(dataset.token2idx), 128, 64)\nmodel","93268cfb":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.005)","7a6a65e7":"model.train()\ntrain_losses = []\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    progress_bar = tqdm_notebook(train_loader, leave=False)\n    losses = []\n    total = 0\n    for inputs, target in progress_bar:\n        model.zero_grad()\n\n        output = model(inputs)\n        loss = criterion(output.squeeze(), target.float())\n        \n        loss.backward()\n              \n        nn.utils.clip_grad_norm_(model.parameters(), 3)\n\n        optimizer.step()\n        \n        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n        \n        losses.append(loss.item())\n        total += 1\n    \n    epoch_loss = sum(losses) \/ total\n    train_losses.append(epoch_loss)\n        \n    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}')","2aecbac4":"def predict_class(text):\n    model.eval()\n    with torch.no_grad():\n        test_vector = torch.LongTensor(dataset.vectorizer.transform([text]).toarray())\n\n        output = model(test_vector)\n        prediction = torch.sigmoid(output).item()\n\n        if prediction > 0.5:\n            return(1,prediction)\n        else:\n            return(0,prediction)","613a25dd":"len(X_test)\nindex_ls = []\nfor i in range(len(X_test)):\n    index_ls.append(i)\nX_test.index = index_ls\ny_test.index = index_ls","9980bc50":"correct = 0\ntotal = len(X_test)\nls_pred = []\n\nfor i in range(len(X_test)):\n    output = predict_class(X_test[i])\n    label = output[0]\n    prediction = output[1]\n    if(label == y_test[i]):\n        correct+=1\n    ls_pred.append(prediction)\n\n# print(f'Prediction Accuracy : {sum(ls_pred)\/len(ls_pred)*100}')\nprint(f'Accuracy : {correct\/total*100}')","5bda3629":"# Shuffling Data","4dc4710b":"# Dataset","03b30279":"# Evaluating The Model","b7b862f6":"# Import Statements","833bf48b":"# Loading Data","a29ac1e6":"# Model","a1f65ef7":"# Loss Function And Optimizer","6d0d588e":"# Train Test Split","e06d22d8":"# Predition Function","1a865277":"# Training"}}