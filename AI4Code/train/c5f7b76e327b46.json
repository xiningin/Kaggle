{"cell_type":{"c4d01bbb":"code","9e8327ae":"code","d03a7c3e":"code","3347a3d2":"code","bfead3dc":"code","60874f3e":"code","7c789531":"code","9d2a926a":"code","77233254":"code","dad3c962":"code","0848917f":"code","2fbdf2de":"code","56e3aa64":"code","62d42a9f":"markdown","e918290e":"markdown","abecf145":"markdown","ae92b636":"markdown","c6d5fdaa":"markdown","62de4d5d":"markdown"},"source":{"c4d01bbb":"import os\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\n\n%matplotlib inline","9e8327ae":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","d03a7c3e":"# Kaggle\u3067\u306f\u3001\u3042\u308bNotebook\u306e\u51fa\u529b\u3092\u3001\u3042\u308bNotebook\u306e\u5165\u529b\u3068\u3057\u3066\u6271\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n# \u53f3\u5074\u30bf\u30d6\u306e\"+Add data\"\u304b\u3089\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u6307\u5b9a\u306eNotebook\u3092\u9078\u629e\u3057\u307e\u3059\u3002\n# Kernel Output Files --> Your Work\n# \u3053\u306eNotebook\u3067\u306f\u8a13\u7df4\u6e08\u307fCNN\uff08\u30e2\u30c7\u30eb\u5b9a\u7fa9\u306f\u4ee5\u4e0b\uff09\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3044\u304d\u307e\u3059\u3002\n\n\nINPUT_DIR = '..\/input\/ailab-ml-training-1\/'\nARTIFACT_DIR = '..\/input\/getting-started-cnn-for-error-analysis\/'\n\nPATH = {\n    'train': os.path.join(INPUT_DIR, 'train.csv'),\n    'submission': os.path.join(INPUT_DIR, 'sample_submission.csv'),\n    'train_image_dir': os.path.join(INPUT_DIR, 'train_images\/train_images'),\n    'test_image_dir': os.path.join(INPUT_DIR, 'test_images\/test_images'),\n    'state_dict': os.path.join(ARTIFACT_DIR, 'best_state_dict.pth'),\n    'predictions': os.path.join(ARTIFACT_DIR, 'predictions.npy'),\n}\n\nID = 'fname'\nTARGET = 'label'\n\nSEED = 42\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nseed_everything(SEED)","3347a3d2":"train_df = pd.read_csv(PATH['train'])\nsubmission_df = pd.read_csv(PATH['submission'])","bfead3dc":"# \u30e2\u30c7\u30eb\u5b9a\u7fa9\u306f\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3068\u540c\u3058\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\n\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 32, 3, stride=1, padding=1, bias=True),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, stride=1, padding=1, bias=True),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, stride=1, padding=1, bias=True),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d((1, 1)),\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(128, 10, bias=True),\n        )\n    \n    def forward(self, x):\n        x = self.conv(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x","60874f3e":"model = Model().to(DEVICE)\nmodel.load_state_dict(torch.load(PATH['state_dict'], map_location=DEVICE))\nmodel.eval()\nprint(model)","7c789531":"# GradCam\u306fConvolution\u5c64\u306e\u6700\u7d42\u51fa\u529b\u306e\u7279\u5fb4\u91cf\u30de\u30c3\u30d7\u3068\u52fe\u914d\u60c5\u5831\u3092\u5fc5\u8981\u3068\u3059\u308b\n# \u305d\u306e\u305f\u3081\u300c\u30e2\u30c7\u30eb\u306e\u9806\u4f1d\u64ad\u6642\u306b\u6700\u7d42\u51fa\u529b\u306e\u7279\u5fb4\u91cf\u30de\u30c3\u30d7\u304a\u3088\u3073\u52fe\u914d\u60c5\u5831\u3092\u4fdd\u5b58\u3057\u3066\u304a\u304f\u300d\u305f\u3081\u306e\u51e6\u7406\u3092\u5b9f\u88c5\u3059\u308b\n# \u4ee5\u4e0b\u3067\u306f__call__\u95a2\u6570\u5185\u3067(conv)(7)\u3092\u4fdd\u5b58\u3057\u3064\u3064\u9806\u4f1d\u64ad\u3092\u884c\u3063\u3066\u3044\u308b\n\n# NOTE: Extractor\u30af\u30e9\u30b9\u306f\u30e2\u30c7\u30eb\u306e\u5b9f\u88c5\u306b\u3088\u3063\u3066\u5909\u3048\u308b\u5fc5\u8981\u304c\u3042\u308b\nclass Extractor:\n    def __init__(self, model):\n        self.model = model.eval()\n        self.gradients = []\n    \n    def get_gradients(self):\n        return self.gradients\n    \n    def save_gradient(self, grad):\n        self.gradients.append(grad)\n    \n    # TODO: refacta\n    def __call__(self, x):\n        features = []\n        self.gradients = []\n        for name, module in self.model.conv._modules.items():\n            x = module(x)\n            if name == '7':\n                x.register_hook(self.save_gradient)\n                features.append(x)\n        output = self.model.fc.forward(x.view(x.size(0), -1))\n        return features, output\n    \n\n# NOTE: GradCam\u30af\u30e9\u30b9\u306f\u7279\u5225\u306a\u7406\u7531\u304c\u306a\u3044\u9650\u308a\u5909\u66f4\u306e\u5fc5\u8981\u304c\u306a\u3044\nclass GradCam:\n    def __init__(self, extractor):\n        self.extractor = extractor\n\n    def __call__(self, x, index=None):\n        \"\"\"\n        Args:\n            - x: input, (1, C, H, W).\n            - index: class index, (1,).\n\n        Returns:\n            - class activation map, (H', W').\n            - extractor.model output, (1, C).\n\n        \"\"\"\n        _, _, h, w = x.size()\n        \n        features, output = self.extractor(x)\n        if index is None:\n            index = output.argmax(dim=1).item()\n\n        onehot = torch.zeros((1, output.size(1)), dtype=torch.float32, device=x.device)\n        onehot[0,index] = 1.0\n        onehot.requires_grad_(True)\n        onehot = torch.sum(onehot * output)\n        \n        self.extractor.model.zero_grad()\n        onehot.backward(retain_graph=True)\n        \n        grads = self.extractor.get_gradients()\n        grads = grads[-1].detach().cpu().numpy()\n        weights = np.mean(grads, axis=(2, 3), keepdims=True)\n        features = features[-1].detach().cpu().numpy()\n        cam = weights * features\n        cam = np.sum(cam, axis=(0, 1))\n\n        return cam, output","9d2a926a":"extractor = Extractor(model)\ngrad_cam = GradCam(extractor)","77233254":"class KmnistDataset(Dataset):\n    def __init__(\n        self,\n        fname_list,\n        label_list,\n        image_dir,\n        transform=None,\n        with_memory_cache=False,\n    ):\n        super().__init__()\n\n        self.fname_list = fname_list\n        self.label_list = label_list\n        self.image_dir = image_dir\n        self.transform = transform\n        self.with_memory_cache = with_memory_cache\n\n        if with_memory_cache:\n            self.image_list = [None,] * len(fname_list)\n    \n    def load_image(self, fname):\n        image = cv2.imread(os.path.join(self.image_dir, fname))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = image.reshape(image.shape[0], image.shape[1], 1)\n        \n        return image\n    \n    def __len__(self):\n        return len(self.fname_list)\n    \n    def __getitem__(self, idx):\n        if self.with_memory_cache:\n            image = self.image_list[idx]\n            if image is None:\n                fname = self.fname_list[idx]\n                image = self.load_image(fname)\n                self.image_list[idx] = image\n        else:\n            fname = self.fname_list[idx]\n            image = self.load_image(fname)\n            \n        label = self.label_list[idx]\n        \n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        \n        return image, label","dad3c962":"def get_dataloader(\n    X,\n    Y,\n    image_dir,\n    transform=None,\n    with_memory_cache=False,\n    batch_size=32,\n    shuffle=False,\n    num_workers=0,\n    pin_memory=True,\n):\n    dataset = KmnistDataset(\n        X,\n        Y,\n        image_dir,\n        transform=transform,\n        with_memory_cache=with_memory_cache,\n    )\n    \n    loader = DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        num_workers=num_workers,\n        pin_memory=pin_memory,\n    )\n    \n    return loader","0848917f":"num_samples_per_class = 10\n\nsample = train_df.groupby(TARGET).apply(lambda df: df.sample(num_samples_per_class))\nfnames = sample[ID].to_list()\nlabels = sample[TARGET].to_list()\n\ntransform = A.Compose([\n    A.Normalize((48.89935\/255,), (86.269\/255,)),\n    ToTensorV2(),\n])\n\nloader = get_dataloader(\n    fnames, labels, PATH['train_image_dir'],\n    transform=transform, batch_size=1,\n)","2fbdf2de":"index = None\n\nfig, axes = plt.subplots(10, num_samples_per_class)\nfig.set_size_inches(2*num_samples_per_class,2*10)\n\nfor i, (x, y) in enumerate(loader):\n    cam, output = grad_cam(x)\n    cam = (cam - np.min(cam)) \/ (np.max(cam) - np.min(cam))\n    cam = cv2.resize(cam, (28, 28))\n    \n    if index is not None:\n        proba = F.softmax(output, dim=1)[0,index]\n        pred = torch.tensor((1,index))\n    else:\n        proba, pred = torch.max(F.softmax(output, dim=1), dim=1)\n\n    ax = axes[i\/\/num_samples_per_class,i%num_samples_per_class]\n    ax.imshow(x[0,0].cpu().numpy(), 'gray')\n    ax.imshow(cam, alpha=0.5, cmap='jet')\n    ax.axis('off')\n    ax.set_title(f'{y[0]} - {pred[0]} ({proba[0]:.5f})')\n\nplt.show()","56e3aa64":"index = 0\n\nfig, axes = plt.subplots(10, num_samples_per_class)\nfig.set_size_inches(2*num_samples_per_class,2*10)\n\nfor i, (x, y) in enumerate(loader):\n    cam, output = grad_cam(x, index)\n    cam = (cam - np.min(cam)) \/ (np.max(cam) - np.min(cam))\n    cam = cv2.resize(cam, (28, 28))\n    \n    if index is not None:\n        proba = F.softmax(output, dim=1)[:,index]\n        pred = torch.tensor((1,index))\n    else:\n        proba, pred = torch.max(F.softmax(output, dim=1), dim=1)\n\n    ax = axes[i\/\/num_samples_per_class,i%num_samples_per_class]\n    ax.imshow(x[0,0].cpu().numpy(), 'gray')\n    ax.imshow(cam, alpha=0.5, cmap='jet')\n    ax.axis('off')\n    ax.set_title(f'{y[0]} - {pred[0]} ({proba[0]:.5f})')\n\nplt.show()","62d42a9f":"## dataset, dataloader","e918290e":"# Libraries","abecf145":"## model","ae92b636":"## utils","c6d5fdaa":"# GradCAM Example","62de4d5d":"# Loading"}}