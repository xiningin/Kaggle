{"cell_type":{"1096f16a":"code","6fbf6e4c":"code","9f671f59":"code","697fbd2c":"code","40f263b7":"code","916f1db3":"code","0a35e5a0":"code","a66b6de3":"code","b43050bb":"code","8b897bca":"code","eb086905":"code","38a40fe1":"code","26202c87":"code","6f934fbc":"code","14ff9371":"code","881793d4":"code","75ab9b50":"code","ad157a9a":"code","5c11c452":"code","903dbc91":"code","e247a3da":"code","7916bc19":"code","122cddfb":"code","a572e5f0":"code","b02b7925":"code","d3a86dce":"code","4b4eb29a":"markdown"},"source":{"1096f16a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6fbf6e4c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nimport cv2\nfrom glob import glob","9f671f59":"train_dir = \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\"\nval_dir = \"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\"\ntest_dir = '\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test'","697fbd2c":"os.listdir(train_dir)","40f263b7":"import tqdm","916f1db3":"x_data = [] \ny_data = [] \nfor category in glob(train_dir+'\/*'):\n    for file in glob(category+'\/*'):\n        img_array=cv2.imread(file)\n        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n        x_data.append(img_array) \n        y_data.append(category.split(\"\/\")[-1])\ndata=pd.DataFrame({'image': x_data,'label': y_data})","0a35e5a0":"data.head()","a66b6de3":"plt.figure(figsize=(20,15))\nfor i in range(9):\n    plt.subplot(4,3,(i%12)+1)\n    index=np.random.randint(10000)\n    plt.title( data.loc[index]['label'] )\n    plt.imshow(data.image[index])\n    plt.tight_layout()","b43050bb":"def show_image(path):\n    plt.figure(figsize=(15, 8))\n    for i in range(10):\n        plt.subplot(2, 5, i+1)\n        img = random.choice(os.listdir(path))\n        image = load_img(os.path.join(path, img))\n        label = path.split('\/')[-1]\n        if label == \"WithoutMask\":\n            plt.suptitle(\"Without mask\")\n        else:\n            plt.suptitle(\"With mask\")\n        plt.imshow(image)","8b897bca":"show_image(\"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask\")","eb086905":"show_image(\"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Validation\/WithoutMask\")","38a40fe1":"show_image(\"\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithMask\")","26202c87":"train_datagen = ImageDataGenerator(train_dir,\n                                   rescale = 1.\/255,\n                                   zoom_range = 0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range = 0.2,\n                                   horizontal_flip = True,\n                                   rotation_range = 35)\nval_datagen = ImageDataGenerator(val_dir)\n\ntest_datagen = ImageDataGenerator(test_dir)","6f934fbc":"train_data = train_datagen.flow_from_directory(directory=train_dir, target_size=(121, 121), class_mode = 'binary')\nval_data = val_datagen.flow_from_directory(directory=val_dir, target_size=(121, 121), class_mode='binary')\ntest_data = test_datagen.flow_from_directory(directory=test_dir, target_size=(121, 121), class_mode='binary')","14ff9371":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(121, 121, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","881793d4":"model.summary()","75ab9b50":"checkpoint = ModelCheckpoint(\"Gender.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\nearlystop = EarlyStopping(monitor='acc',mode='max', patience=3, verbose=1)","ad157a9a":"model.compile(optimizer='Adam', metrics=['acc'], loss='binary_crossentropy')","5c11c452":"model.fit(train_data,epochs=30, callbacks = [checkpoint, earlystop], steps_per_epoch=30, validation_data=val_data)","903dbc91":"cascade = cv2.CascadeClassifier(\"..\/input\/haarcascade-frontlface-default\/haarcascade_frontlface_default.xml\")\n\n\ndef detect_mask(image_path):\n    label = label = {0:\"Mask\",1:\"Without mask\"} \n    image = cv2.imread(image_path)\n    imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#     gray   = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    faces = cascade.detectMultiScale(imgRGB, 1.1, 7)\n    if faces is None:\n        print(\"face not detected\")\n    for x,y,w,h in faces:\n        face = image[y:y+h,x:x+w]\n#         print(face.shape)\n        face = cv2.resize(face, (121, 121))\n        img_scaled = face\/255.0\n        reshape = np.reshape(img_scaled, (1,121,121,3))\n        img = np.vstack([reshape])\n        result = model.predict(img)\n        print(result)\n        if result < 0.5:\n            cv2.rectangle(image,(x-10,y),(x+w,y+h),(0,255,0),4)\n            cv2.rectangle(image,(x-10,y-50),(x+w,y),(255,0,0),-1)\n            cv2.putText(image,label[0],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2)\n            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n            plt.suptitle(\"With mask\")\n            plt.imshow(image)\n        elif result >= 0.5:\n            cv2.rectangle(image,(x-10,y),(x+w,y+h),(0,255,0),4)\n            cv2.rectangle(image,(x-10,y-50),(x+w,y),(255,0,0),-1)\n            cv2.putText(image,label[1],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2)\n            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n            plt.suptitle(\"Without mask\")\n            plt.imshow(image)","e247a3da":"detect_mask('\/kaggle\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Test\/WithoutMask\/4352.png')","7916bc19":"model.save('my_model.h5')","122cddfb":"model.evaluate(test_data)","a572e5f0":"model.evaluate(val_data)","b02b7925":"model.evaluate(train_data)","d3a86dce":"# import cv2\n# import numpy\n# import pandas\n# import tensorflow as tf\n# import numpy as np\n# import matplotlib.pyplot as plt\n# from tensorflow import keras\n\n# model = keras.models.load_model('my_model.h5')\n\n# cap = cv2.VideoCapture(0)\n# cascade = cv2.CascadeClassifier(\"..\/input\/haarcascade-frontlface-default\/haarcascade_frontlface_default.xml\")\n\n# while True:\n#     success, img = cap.read()\n#     # imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n#     faces = cascade.detectMultiScale(img)\n#     if faces is None:\n#         print(\"face not detected\")\n#     for x, y, w, h in faces:\n#         face = img[y:y + h, x:x + w]\n#         face = cv2.resize(face, (121, 121))\n#         img_scaled = face \/ 255.0\n#         # print(img_scaled.shape)\n#         reshape = np.reshape(img_scaled, (1, 121, 121, 3))\n#         face = np.vstack([reshape])\n#         result = model.predict(face)\n#         print(result)\n\n#         if result >= 0.5:\n#             cv2.rectangle(img, (x - 10, y), (x + w, y + h), (0, 255, 0), 4)\n#             cv2.rectangle(img, (x - 10, y - 50), (x + w, y), (255, 0, 0), -1)\n#             cv2.putText(img, \"With mask\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n\n#         elif result < 0.5:\n#             cv2.rectangle(img, (x - 10, y), (x + w, y + h), (0, 255, 0), 4)\n#             cv2.rectangle(img, (x - 10, y - 50), (x + w, y), (255, 0, 0), -1)\n#             cv2.putText(img, \"Without mask\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2)\n\n#     cv2.imshow(\"Image\", img)\n#     if cv2.waitKey(1) & 0xFF == ord('q'):\n#         break\n# cap.release()\n# cv2.destroyAllWindows()\n","4b4eb29a":"For real-time face mask detection save this code in .py file and run"}}