{"cell_type":{"1ab6f98f":"code","26053e88":"code","0bb5e00a":"code","84a8f56e":"code","58ebe4c0":"code","24cf78b4":"code","355d20bb":"code","d0b346a7":"code","732d5fcd":"markdown","9feb0549":"markdown"},"source":{"1ab6f98f":"%%writefile submission.py\n\nimport time\nimport os\nimport random\nimport numpy as np\nfrom typing import List, Dict\nfrom xgboost import XGBClassifier\n\n\ndef random_agent(observation, configuration):\n    return random.randint(0, configuration.signs-1)\n\ndef rock_agent(observation, configuration):\n    return 0\n\ndef paper_agent(observation, configuration):\n    return 1\n\ndef scissors_agent(observation, configuration):\n    return 2\n\ndef sequential_agent(observation, configuration):\n    return observation.step % configuration.signs\n\n\n\ndef get_winstats(history) -> Dict[str,int]:\n    total = len(history['action'])\n    wins = 0\n    draw = 0\n    loss = 0 \n    for n in range(total):\n        if   history['action'][n] == history['opponent'][n] + 1: wins +=  1\n        elif history['action'][n] == history['opponent'][n]:     draw +=  1\n        elif history['action'][n] == history['opponent'][n] - 1: loss +=  1\n    return { \"wins\": wins, \"draw\": draw, \"loss\": loss }\n\ndef get_winrate(history):\n    winstats = get_winstats(history)\n    winrate  = winstats['wins'] \/ (winstats['wins'] + winstats['loss']) if (winstats['wins'] + winstats['loss']) else 0\n    return winrate\n    \n    \n# Initialize starting history\nhistory = {\n    \"step\":        [],\n    \"prediction1\": [],\n    \"prediction2\": [],\n    \"expected\":    [],\n    \"action\":      [],\n    \"opponent\":    [],\n}\n\n# NOTE: adding statistics causes the DecisionTree to make random moves \ndef get_statistics(values) -> List[float]:\n    values = np.array(values)\n    return [\n        np.count_nonzero(values == n) \/ len(values)\n        if len(values) else 0.0\n        for n in [0,1,2]\n    ]\n\n\n# observation   =  {'step': 1, 'lastOpponentAction': 1}\n# configuration =  {'episodeSteps': 10, 'agentTimeout': 60, 'actTimeout': 1, 'runTimeout': 1200, 'isProduction': False, 'signs': 3}\ndef decision_tree_agent(observation, configuration, window=8, stages=2, random_freq=0.0, max_samples=1000, warmup_period=0):   # 6,2,0.0,1000,0  \n    global history\n    warmup_period   = warmup_period  # if os.environ.get('KAGGLE_KERNEL_RUN_TYPE','') != 'Interactive' else 0\n    models          = [ None ] + [ XGBClassifier(n_jobs=1) ] * stages\n    \n    time_start      = time.perf_counter()\n    actions         = list(range(configuration.signs))  # [0,1,2]\n    \n    step            = observation.step\n    last_action     = history['action'][-1]          if len(history['action']) else 2\n    opponent_action = observation.lastOpponentAction if observation.step > 0   else 2\n        \n    if observation.step > 0:\n        history['opponent'].append(opponent_action)\n        \n    winrate  = get_winrate(history)\n    winstats = get_winstats(history)\n    \n    # Set default values     \n    prediction1 = random.randint(0,2)\n    prediction2 = random.randint(0,2)\n    prediction3 = random.randint(0,2)\n    expected    = random.randint(0,2)\n\n    # We need at least some turns of history for XGBoost to work\n    if observation.step >= window:\n        # First we try to predict the opponents next move based on move history\n        # TODO: create windowed history\n        try:\n            n_start = max(1, len(history['opponent']) - window - max_samples) \n            # print('stats: ', { key: get_statistics(history[key]) for key in history.keys() })\n            if stages >= 1:\n                X = np.stack([\n                    np.array([\n                        # get_statistics(history['action'][:n+window]),\n                        # get_statistics(history['opponent'][:n-1+window]),\n                        history['action'][n:n+window], \n                        history['opponent'][n:n+window]\n                    ]).flatten()\n                    for n in range(n_start,len(history['opponent'])-window) \n                ])\n                Y = np.array([\n                    history['opponent'][n+window]\n                    for n in range(n_start,len(history['opponent'])-window) \n                ])  \n                Z = np.array([\n                    # get_statistics(history['action']),\n                    # get_statistics(history['opponent']),\n                    history['action'][-window+1:] + [ last_action ], \n                    history['opponent'][-window:] \n                ]).flatten().reshape(1, -1)\n\n                # TODO: save xgb_model to continue training - https:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html#xgboost.XGBRegressor.fit\n                models[1].fit(X, Y)\n                expected = prediction1 = models[1].predict(Z)[0]\n\n            if stages >= 2:\n                # Now retrain including prediction history\n                X = np.stack([\n                    np.array([\n                        # get_statistics(history['action'][:n+window]),\n                        # get_statistics(history['prediction1'][:n+window]),\n                        # get_statistics(history['opponent'][:n-1+window]),\n                        history['action'][n:n+window], \n                        history['prediction1'][n:n+window],\n                        history['opponent'][n:n+window],\n                    ]).flatten()\n                    for n in range(n_start,len(history['opponent'])-window) \n                ])\n                Y = np.array([\n                    history['opponent'][n+window]\n                    for n in range(n_start,len(history['opponent'])-window) \n                ])  \n                Z = np.array([\n                    # get_statistics(history['action']),\n                    # get_statistics(history['prediction1']),\n                    # get_statistics(history['opponent']),\n                    history['action'][-window+1:]      + [ last_action ], \n                    history['prediction1'][-window+1:] + [ prediction1 ],\n                    history['opponent'][-window:] \n                ]).flatten().reshape(1, -1)\n\n                models[2].fit(X, Y)\n                expected = prediction2 = models[2].predict(Z)[0]\n\n            if stages >= 3:\n                # Now retrain including prediction history\n                X = np.stack([\n                    np.array([\n                        # get_statistics(history['action'][:n+window]),\n                        # get_statistics(history['prediction1'][:n+window]),\n                        # get_statistics(history['prediction2'][:n+window]),\n                        # get_statistics(history['opponent'][:n-1+window]),\n                        history['action'][n:n+window], \n                        history['prediction1'][n:n+window],\n                        history['prediction2'][n:n+window],\n                        history['opponent'][n:n+window],\n                    ]).flatten()\n                    for n in range(n_start,len(history['opponent'])-window) \n                ])\n                Y = np.array([\n                    history['opponent'][n+window]\n                    for n in range(n_start,len(history['opponent'])-window) \n                ])  \n                Z = np.array([\n                    # get_statistics(history['action']),\n                    # get_statistics(history['prediction1']),\n                    # get_statistics(history['prediction2']),\n                    # get_statistics(history['opponent']),\n                    history['action'][-window+1:]      + [ last_action ], \n                    history['prediction1'][-window+1:] + [ prediction1 ],\n                    history['prediction2'][-window+1:] + [ prediction2 ],\n                    history['opponent'][-window:] \n                ]).flatten().reshape(1, -1)\n\n                models[3].fit(X, Y)\n                expected = prediction3 = models[3].predict(Z)[0]\n        \n        except Exception as exception:\n            print(exception)\n                    \n    # During the warmup period, play random to get a feel for the opponent \n    if (observation.step <= max(warmup_period,window)):\n        actor  = 'warmup'\n        action = random_agent(observation, configuration)    \n    \n    # # Play a purely random move occasionally, which will hopefully distort any opponent statistics\n    # elif (random.random() <= random_freq):\n    #     actor  = 'random'\n    #     action = random_agent(observation, configuration)\n        \n    # But mostly use XGBoost to predict the next move\n    else:\n        actor  = 'XGBoost'\n        action = (expected + 1) % configuration.signs\n    \n    # Persist state\n    history['step'].append(step)\n    history['prediction1'].append(prediction1)\n    history['prediction2'].append(prediction2)\n    history['expected'].append(expected)\n    history['action'].append(action)\n    if observation.step == 0:  # keep arrays equal length\n        history['opponent'].append(random.randint(0, 2))\n\n\n    # Print debug information\n    time_taken = time.perf_counter() - time_start\n    # print(f'{1000*time_taken:3.0f}ms | {step:4d} | opp = {opponent_action} | pred1 = {prediction1} | pred2 = {prediction2} | exp = {expected} | act = {action} | {winrate:.2f} {actor:7s}')    \n    print(f'{1000*time_taken:3.0f}ms | {step:4d} | opp = {opponent_action} | exp = {expected} | act = {action} | {actor:7s} | {100*winrate:5.1f}% {winstats}')    \n    return int(action)","26053e88":"%run -i 'submission.py'","0bb5e00a":"from kaggle_environments import make\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 100}, debug=False)\n# env.run([\"submission.py\", lambda obs, conf: random.randint(0, 2)])\nenv.run([\"submission.py\", \"submission.py\"])\nenv.render(mode=\"ipython\", width=600, height=600)","84a8f56e":"from kaggle_environments import make\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 100}, debug=False)\n# env.run([\"submission.py\", lambda obs, conf: random.randint(0, 2)])\nenv.run([\"submission.py\", rock_agent])\nenv.render(mode=\"ipython\", width=600, height=600)","58ebe4c0":"from kaggle_environments import make\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 100}, debug=False)\n# env.run([\"submission.py\", lambda obs, conf: random.randint(0, 2)])\nenv.run([\"submission.py\", sequential_agent])\nenv.render(mode=\"ipython\", width=600, height=600)","24cf78b4":"from kaggle_environments import make\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 100}, debug=False)\nenv.run([\"submission.py\", random_agent])\nenv.render(mode=\"ipython\", width=600, height=600)","355d20bb":"from kaggle_environments import make\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 100}, debug=False)\nenv.run([\"submission.py\", '..\/input\/rock-paper-scissors-statistical-prediction\/submission.py'])\nenv.render(mode=\"ipython\", width=600, height=600)","d0b346a7":"from kaggle_environments import make\n\nenv = make(\"rps\", configuration={\"episodeSteps\": 100}, debug=False)\nenv.run([\"submission.py\", '..\/input\/rock-paper-scissors-decision-tree\/submission.py'])\nprint(env.render(mode=\"ipython\", width=600, height=600))","732d5fcd":"# Further Reading\n\nThis notebook is part of a series exploring Rock Paper Scissors:\n- [Rock Paper Scissors - PI Bot](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-pi-bot)\n- [Rock Paper Scissors - De Bruijn Sequence](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-de-bruijn-sequence)\n- [Rock Paper Scissors - Random Agent](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-random-agent)\n- [Rock Paper Scissors - Weighted Random Agent](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-weighted-random-agent)\n- [Rock Paper Scissors - Statistical Prediction](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-statistical-prediction)\n- [Rock Paper Scissors - Random Seed Search](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-random-seed-search)\n- [Rock Paper Scissors - RNG Statistics](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-rng-statistics)\n- [Rock Paper Scissors - XGBoost](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-xgboost)\n- [Rock Paper Scissors - Decision Tree](https:\/\/www.kaggle.com\/jamesmcguigan\/rock-paper-scissors-decision-tree)","9feb0549":"# Rock Paper Scissors - XGBoost\n\nThis agent records a history of previous moves, opponent moves and the correctness of our predictions. \n\nThis dataset is passed into XGBoost to predict our opponents move. The process is applied iteratively: \n- first we predict the opponents next move based purely off move history\n- then we add our history of first-stage predictions to the dataset\n- we repeat this process a third time, incase our opponent is trying to predict our predictions"}}