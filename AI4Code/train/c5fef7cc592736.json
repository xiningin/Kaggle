{"cell_type":{"bba6a7a3":"code","aff91eb9":"code","9a32a8d4":"code","c1edd439":"code","229e5259":"code","13f5baba":"code","1e1338b0":"code","b1c53056":"code","f885ba10":"code","d4d5f2c3":"code","5fd344ec":"code","79513b7a":"code","f36fa236":"code","646f2653":"code","e1f95087":"code","d1ebb658":"code","bff61ff9":"code","8997114c":"code","bdd213ca":"code","5b519515":"code","4263fb9e":"code","e9e4915e":"markdown","451c24d3":"markdown","98dcec27":"markdown","f7ce7705":"markdown","27f450bf":"markdown","1e363c23":"markdown","8d8ab21e":"markdown","dadee13d":"markdown","b959d959":"markdown","8b914bcd":"markdown","1d532b69":"markdown"},"source":{"bba6a7a3":"# This Python 3 environment comes with many helpful analytics libraries installedd\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aff91eb9":"from fastai.vision.all import *\nfrom fastai.data.all import *\nnp.random.seed(42)\ntorch.random.seed = 42","9a32a8d4":"train_df = pd.read_csv(dirname+'\/train.csv')\ntest_df = pd.read_csv(dirname + '\/test.csv')\ntrain_df.head()","c1edd439":"train = train_df.to_numpy()\ntest = test_df.to_numpy()","229e5259":"\n# How to get the label? Just picking the first element of the array\n@Transform\ndef get_label(a):\n    return a[0]\n\n# How to get the input data? getting all the last  28*28 elements of the array, these are all the pixels. It is done this way because \n# we can reuse this function in the test array and get all the pixels even there is no label. If we did a[1:] with the test dataset \n# it wouldn't have worked\n@Transform\ndef get_x(a):\n    return a[-28*28:]\n    \n# In this we transform each array to a image tensor with the apropiate dimensions, 1 chanel and 28x28 pixels\n@Transform\ndef nums_to_tensor(a):\n    return TensorImageBW(torch.from_numpy(a).view(1,28,28))\n","13f5baba":"x_tfms = [get_x,nums_to_tensor, ]\ny_tfms = [get_label, Categorize]\ncut = int(len(train)*0.8)\nsplits = [list(range(cut)), list(range(cut,len(train)-1))]\nbs = 128","1e1338b0":"dsets = Datasets(train,[x_tfms, y_tfms], splits = splits)\ndls = dsets.dataloaders(bs=bs, after_batch=[IntToFloatTensor(),*aug_transforms(do_flip=False,batch=True, ), Normalize.from_stats(*mnist_stats)])","b1c53056":"test_dl =dls.test_dl(test)","f885ba10":"model = xresnet18(c_in=1,n_out=10, sa=True, act_cls=Mish)","d4d5f2c3":"model","5fd344ec":"learn = Learner(dls,model, loss_func=CrossEntropyLossFlat(), metrics=accuracy,)","79513b7a":"lr_min, lr_steep = learn.lr_find();lr_min, lr_steep","f36fa236":"learn.fit_one_cycle(20,lr_min)","646f2653":"learn.save('20epoch_Xresnet18-sa')","e1f95087":"learn = learn.load('20epoch_Xresnet18-sa')","d1ebb658":"learn.fit_one_cycle(2,lr_min\/50)","bff61ff9":"learn.save('20+2epoch_Xresnet18-sa')","8997114c":"preds,targets = learn.tta()\naccuracy(preds,targets)","bdd213ca":"preds,_ = learn.tta(dl=test_dl)","5b519515":"class_preds =np.argmax(preds,axis=1)\npred_submission = [dls.vocab[i] for i in class_preds]","4263fb9e":"submission = pd.read_csv(dirname+'\/sample_submission.csv')\nsubmission['Label']=pred_submission\nsubmission.to_csv('submission.csv',index=False)","e9e4915e":"We add the test dataset for inference. All the transforms applied to the valid dataset will be applied to the test dataset","451c24d3":"In this to objects we have the data ready for the `DataLoaders`. Now we need to create the transforamtions to tell the dataloader how to convert it to usefull tensors for the training.\nWe use the decorator `@Transform` to indicate all of this fucntions are transforms","98dcec27":"Saving the model before some extra epochs for fine tuning","f7ce7705":"# DIGIT RECOGNITION WITH FASTAI\n\nIn this notebook I will show how to arrange the data from this competition using fast.ai mid-level API. Many notebooks manipulate the data converting the columns to numeric vectors to images and the images to tensors, while it is a valid solution it takes extra steps not required. Here the vectors from the dataframes are arranged directly to tensors. ","27f450bf":"## Data Preparation","1e363c23":"Once we have the model created we use the standard procedure with fastai leaner","8d8ab21e":"The first step is to get our data. Data is organized in 2 files, `train.csv` and `test.csv`. In both files each row is an image containing a digit and each column contains the 8bit value for the pixel. Additionally `train.csv` has a column indicating the label of each image","dadee13d":"## Training\n\nLet's create the model. We need to change the first layer because it expects an image with 3 channels but we are using a BW image with just one channel and adjust the number of outputs because it is adjusted to 1000 categories by default","b959d959":"The first step will be to convert the DataFrames to numpy arrays. For me its easier to work with them from the beginning","8b914bcd":"With the numpy array, the transforms and the splits we create the training and validation `Datasets` object. \n\nWith the datasets we can create the dataloader and we add some batch transforms to improve accuracy. \n\n* IntToFloatTensor() converts the tensor we had until now that was composed of 8bit values to float.\n* aug_transform() helps generating larger training dataset from the current batch [more info about data augmentation in fastai](https:\/\/docs.fast.ai\/vision.augment.html)\n* Normalize() normalize the input it is very usefull when using pretrained models but even on not pretrained model like this it helps improve the performance","1d532b69":"With all transforms defined we can create the lists of tranforms for inputs and labels and prepare the splits between training and validation set"}}