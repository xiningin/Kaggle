{"cell_type":{"7debe6d6":"code","d3b784ab":"code","751ed2d8":"code","a0de4eba":"code","987d1306":"code","5a3abada":"code","62ee378e":"code","8b8b9b36":"code","1065cd5b":"code","6bb75660":"code","c01640f3":"code","a7042dc0":"code","f865a5a4":"code","a59275c1":"code","1e135289":"code","386831cf":"code","61deca66":"markdown","39d3f17f":"markdown","c08f3e9c":"markdown","fbf8f5f8":"markdown","be13832d":"markdown","6bb557c6":"markdown","6999193a":"markdown","4cd28af9":"markdown","d736baca":"markdown","14685562":"markdown","6047dc2e":"markdown","821bf98a":"markdown","90c6dbed":"markdown","1cda1655":"markdown","0d187476":"markdown","d982fec3":"markdown","60bf87b7":"markdown","430d13f3":"markdown","2f70af4a":"markdown"},"source":{"7debe6d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d3b784ab":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","751ed2d8":"df = pd.read_csv('\/kaggle\/input\/restaurant-reviews\/Restaurant_Reviews.tsv', delimiter = '\\t', quoting = 3)\ndf.head()","a0de4eba":"# Getting the shape of data\ndf.shape","987d1306":"vocab_size = 500\nembedding_dim = 16\nmax_length = 100\ntrunc_type='post'\npadding_type='post'\noov_tok = \"<OOV>\"\ntraining_size = 900","5a3abada":"sentences = df['Review'].tolist()\nlabels  = df['Liked'].tolist()","62ee378e":"training_sentences = sentences[0:training_size]\ntesting_sentences = sentences[training_size:]\ntraining_labels = labels[0:training_size]\ntesting_labels = labels[training_size:]","8b8b9b36":"tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(training_sentences)\n\nword_index = tokenizer.word_index\n\ntraining_sequences = tokenizer.texts_to_sequences(training_sentences)\ntraining_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n\ntesting_sequences = tokenizer.texts_to_sequences(testing_sentences)\ntesting_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)","1065cd5b":"import numpy as np\ntraining_padded = np.array(training_padded)\ntraining_labels = np.array(training_labels)\ntesting_padded = np.array(testing_padded)\ntesting_labels = np.array(testing_labels)","6bb75660":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","c01640f3":"# Getting Summary\nmodel.summary()","a7042dc0":"num_epochs = 50\nhistory = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)","f865a5a4":"import matplotlib.pyplot as plt\n\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")","a59275c1":"reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n\ndef decode_sentence(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n\nprint(decode_sentence(training_padded[0]))\nprint(training_sentences[0])\nprint(labels[0])","1e135289":"for n in range(10):\n    print(testing_sentences[n],': ',testing_labels[n])","386831cf":"# Checking Predictions\nsentence = [\"Awesome Pizza\", \"I will come here everytime!!!\", \"Dont come here ever, Worst Food\"]\nsequences = tokenizer.texts_to_sequences(sentence)\npadded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\nprint(model.predict(padded))","61deca66":"# Adding Basic Liberaries","39d3f17f":"> As we can see here the testing was all perfect!!!!!\n\n> Bad Reviews are marked as 0\n\n> Good reviews are marked as 1","c08f3e9c":"# Resturant Reviews\n","fbf8f5f8":"# Loading the Data","be13832d":"# Getting Training and Testing Data","6bb557c6":"# Fiting CNN Model","6999193a":"***Seperating data column to sentences and Labels***","4cd28af9":"* **Setting Parameters**","d736baca":"***DataDescription***\n> The data consists of 2 columns Review and Liked\n> \n> Review: The reviews on resturants were in the Review Column\n> \n> Liked: The Good and Bad Review are denoted in the Liked column in the form of 0 and 1 \n> \n> 0- Bad Review\n> \n> 1- Good Review","14685562":"# Plotting accuracy and loss Graph","6047dc2e":"***Converting data into arrays***","821bf98a":"# Creating CNN model\n# Adding Layers\n# Compiling Models","90c6dbed":"* The 1st Graph Show the Difference B\/w Increase in accuracy and val_accuracy \n* The 2nd Graph show the difference b\/w decrease in loss and val_loss","1cda1655":"# Prediction on Testing Data","0d187476":"***Please Leave your Valuable feedback in the comments below!!!!!!***","d982fec3":"# Setting Tokenizer And Padding data","60bf87b7":"* As we can see the sentences i created randomly were Predicted almost perfectly\n* the **First 2 reviews** were **good** to they got score which is **almost equals** to **1**\n* The **3rd review** was the **bad** one so as we can see its score is **almost equal** to **0**","430d13f3":"# Getting Prediction with Randomly Created Reviews","2f70af4a":"***Decoding Sentences*** "}}