{"cell_type":{"ab2c1ce3":"code","d2e5df96":"code","f74165f7":"code","3b6b7ca7":"code","c847b96e":"code","2f41cf76":"code","896b5c42":"code","8b6a09ac":"code","eedb81c8":"code","3642bac7":"code","9ceb714d":"code","6b81d227":"markdown","0e838118":"markdown","298b8b84":"markdown","e236383a":"markdown","aea6afb7":"markdown","b782206e":"markdown","50e0198d":"markdown","74ec584d":"markdown","21325c3d":"markdown","26b040b9":"markdown","c5dd7d39":"markdown"},"source":{"ab2c1ce3":"import tensorflow as tf\nimport tensorflow.keras as ks\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle","d2e5df96":"def unpickle(file):\n    import pickle\n    with open(file, 'rb') as fo:\n        dicty = pickle.load(fo, encoding='bytes')\n    return dicty\n\nqmnist = unpickle(\"..\/input\/qmnist-the-extended-mnist-dataset-120k-images\/MNIST-120k\")","f74165f7":"data = qmnist['data']\nlabels = qmnist['labels']\n","3b6b7ca7":"img = plt.imshow(data[0])\nplt.axis('off')\nplt.show()","c847b96e":"data.shape","2f41cf76":"def map_image(image):\n    image = image \/ 255.0\n    image = tf.reshape(image, shape=(784, ))\n    return image\n\nnew_x = map(map_image, data)","896b5c42":"new_x = np.array(new_x)","8b6a09ac":"def simple_autoencoder(inputs):\n    encoder = ks.layers.Dense(units=32, activation='relu')(inputs)\n    decoder = ks.layers.Dense(units=784, activation='sigmoid')(encoder)\n    \n    return encoder, decoder\n\ninputs = ks.layers.Input(shape=(784, ))\n\nencoder_output, decoder_output = simple_autoencoder(inputs)\n\nencoder_model = ks.Model(inputs=inputs, outputs=encoder_output)\nautoencoder_model = ks.Model(inputs=inputs, outputs=decoder_output)\n\nautoencoder_model.compile(optimizer = ks.optimizers.Adam(), loss='binary_crossentropy')\n\n\nbatch_size = 128\ntrain_steps = 120000 \/\/ batch_size\n\nautoencoder_history = autoencoder_model.fit(x=new_x[:110000],y=new_x[:110000], steps_per_epoch=train_steps, epochs=50, verbose=0)","eedb81c8":"loss = autoencoder_history.history['loss']\n\nplt.figure(figsize=(6, 5))\nplt.plot(loss, range(1,51), color='red',label='training loss')\nplt.title('Training loss')\nplt.legend()\nplt.show()","3642bac7":"def display_one_row(disp_images, offset, shape=(28, 28)):\n    for idx, test_image in enumerate(disp_images):\n        plt.subplot(3, 10, offset + idx + 1)\n        plt.xticks([])\n        plt.yticks([])\n        test_img = np.reshape(test_image, shape)\n        plt.imshow(test_img, cmap='gray')\n        \ndef display_results(disp_input_images, disp_encoded, disp_predicted, enc_shape=(8, 4)):\n    plt.figure(figsize=(15, 5))\n    display_one_row(disp_input_images, 0, shape=(28, 28))\n    display_one_row(disp_encoded, 10, shape=enc_shape)\n    display_one_row(disp_predicted, 20, shape=(28, 28))\n        ","9ceb714d":"test_images = new_x[110000:]\noutput_samples = test_images\n\nencoded_predicted = encoder_model.predict(test_images)\ndecoded_predicted = autoencoder_model.predict(test_images)\n\ndisplay_results(output_samples[:10], encoded_predicted[:10], decoded_predicted[:10])\n    ","6b81d227":"## *Its time for evaluating the model with visuals*","0e838118":"## *unpickling the data from the file*","298b8b84":"## *Importing the libraries*","e236383a":"### *Lets visualize a single image to confirm that the image is a mnist*","aea6afb7":"## *After 50 epochs the autoencoder model has trained better which we can judge by looking at its loss value*","b782206e":"## *prepare the data for autoencoding where we do not need their labels. so we just preprocess the image alone by normalizing and reshaping it to a single dimension*","50e0198d":"## *After extraction we get the label and the pixel data's of all 120k images*","74ec584d":"## *The extracted data consist of about 120000 28x28 images* ","21325c3d":"# *Mnist Autoencoder* ","26b040b9":"## *here a simple autoencoder is built with only two layers,  one for encoding and one for decoding . we train the model by keeping both x and y as new_x which is the preprocessed image*","c5dd7d39":"## *Below you can visualize the input image to the model -> encoded image -> decoded image*"}}