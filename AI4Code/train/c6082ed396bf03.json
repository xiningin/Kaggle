{"cell_type":{"4992c29f":"code","5b6924d1":"code","655aa4bd":"code","aabd045e":"code","50bee4d0":"code","a3a99f8b":"code","183275e0":"code","f647ecf6":"code","6bc38687":"code","3fddd65c":"code","eae6dc85":"code","56bce2d3":"code","ee5f278e":"code","10322590":"code","a340c114":"code","e06f73a3":"code","eafa3789":"code","be2c03b8":"code","cf129fd9":"code","d11186cc":"code","800131f4":"code","548028cf":"code","41c576d5":"code","70746b1d":"code","687ba387":"code","c267f3ad":"code","8c3f5741":"code","1f158b0e":"code","dccb8707":"code","97ea17a7":"code","1fd872d7":"code","aef51125":"code","74c9b2e7":"code","005e12a4":"code","a553e8f7":"code","1486e88a":"code","c45592ff":"code","3bde806f":"code","1d160ee0":"code","86180930":"code","50fe5422":"code","23fa831f":"code","e9621f97":"code","b0aa3e80":"code","f9dcd072":"code","2fa0ee7b":"code","33921bc9":"code","404d5a3d":"code","7da1c0f6":"code","0fc111ac":"code","6e36e6d4":"code","299008d9":"code","bd9f0471":"markdown","27730a2b":"markdown","d7bc7ebd":"markdown","cd188d08":"markdown","2f95ec7e":"markdown","104f7565":"markdown","c87694b7":"markdown","24108435":"markdown","ddb2c9c1":"markdown","e334c872":"markdown","44c50956":"markdown","fe53f11d":"markdown","234622ae":"markdown","acc04700":"markdown","4a619f96":"markdown","2b156465":"markdown","42d78ddb":"markdown","4cf8cce2":"markdown","6e5ddc1f":"markdown","4e703d9e":"markdown","1a21bfc3":"markdown","d197c1e5":"markdown","aa812258":"markdown","4cccbbd4":"markdown","9945b5b1":"markdown","6de1468d":"markdown","0632cf54":"markdown","670ffe87":"markdown"},"source":{"4992c29f":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,  mean_squared_error, f1_score, roc_auc_score\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel = LabelEncoder()","5b6924d1":"pd.options.display.max_columns = None","655aa4bd":"train_df = pd.read_csv(\"\/kaggle\/input\/zindi-data\/Train.csv\")","aabd045e":"train_df.shape","50bee4d0":"train_df.sample(5)","a3a99f8b":"sns.countplot(train_df[\"target\"])","183275e0":"train_df.age.describe()","f647ecf6":"sns.set(rc={'figure.figsize':(20,8)})\nsns.displot(train_df, x=\"age\")","6bc38687":"sns.displot(train_df, x=\"age\", hue=\"target\")","3fddd65c":"sns.set(rc={'figure.figsize':(16,8)})\nsns.countplot(train_df[\"race\"])","eae6dc85":"sns.countplot(x=\"race\", hue=\"target\", data=train_df)","56bce2d3":"sns.countplot(y=\"marital_st\", hue=\"target\", data=train_df)","ee5f278e":"sns.countplot(x=\"nationality\", hue=\"target\", data=train_df)","10322590":"sns.countplot(y=\"Education\", hue=\"target\", data=train_df)","a340c114":"sns.countplot(x=\"nature_of_work\", hue=\"target\", data=train_df)","e06f73a3":"train_df.dtypes","eafa3789":"train_df['gender'] = label.fit_transform(train_df['gender'])\ntrain_df['race'] = label.fit_transform(train_df['race'])\ntrain_df['dwelling'] = label.fit_transform(train_df['dwelling'])\ntrain_df['dwelling_type'] = label.fit_transform(train_df['dwelling_type'])\ntrain_df['province_code'] = label.fit_transform(train_df['province_code'])\ntrain_df['metro_code'] = label.fit_transform(train_df['metro_code'])\ntrain_df['nationality'] = label.fit_transform(train_df['nationality'])\ntrain_df['RTH'] = label.fit_transform(train_df['RTH'])\ntrain_df['marital_st'] = label.fit_transform(train_df['marital_st'])\ntrain_df['Lang_inside'] = label.fit_transform(train_df['Lang_inside'])\ntrain_df['Lang_outside'] = label.fit_transform(train_df['Lang_outside'])\ntrain_df['Education'] = label.fit_transform(train_df['Education'])\ntrain_df['lw_work'] = label.fit_transform(train_df['lw_work'])\ntrain_df['lw_business'] = label.fit_transform(train_df['lw_business'])\ntrain_df['help_on_household'] = label.fit_transform(train_df['help_on_household'])\ntrain_df['job_or_business'] = label.fit_transform(train_df['job_or_business'])\ntrain_df['nature_of_work'] = label.fit_transform(train_df['nature_of_work'])","be2c03b8":"%matplotlib inline\nsns.set(rc={'figure.figsize':(20,30)})\nsns.heatmap(train_df.corr()[['target']].sort_values(\n    by='target', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')","cf129fd9":"mask = np.triu(np.ones_like(train_df.corr(), dtype=np.bool))\nheatmap = sns.heatmap(train_df.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')","d11186cc":"# spliting the data, 70% train set and 30% val set\ntrain_set, val_set = train_test_split(train_df, test_size=0.30, random_state=2)","800131f4":"print('train set shape : %s' % str(train_set.shape))\nprint('validation set shape : %s' % str(val_set.shape))","548028cf":"X_train_set = train_set.drop([\"target\", \"ID\"], axis=1) # feature columns\ny_train_set = train_set[\"target\"] # the label\/target column","41c576d5":"LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr')","70746b1d":"LR.fit(X_train_set, y_train_set)","687ba387":"X_val_set = val_set.drop([\"target\", \"ID\"], axis=1)\ny_val_set = val_set[\"target\"]","c267f3ad":"y_pred = LR.predict(X_val_set)","8c3f5741":"roc_auc_score(y_val_set, y_pred)","1f158b0e":"X_train_set = train_set.drop([\"target\", \"ID\", \"gender\"], axis=1) # feature columns","dccb8707":"LR.fit(X_train_set, y_train_set)","97ea17a7":"X_val_set = val_set.drop([\"target\", \"ID\", \"gender\"], axis=1)\ny_pred_1 = LR.predict(X_val_set)","1fd872d7":"roc_auc_score(y_val_set, y_pred_1)","aef51125":"from sklearn.ensemble import RandomForestClassifier\n\nRF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\nRF.fit(X_train_set, y_train_set)","74c9b2e7":"y_pred_2 = RF.predict(X_val_set)","005e12a4":"roc_auc_score(y_val_set, y_pred_2)","a553e8f7":"from sklearn.neural_network import MLPClassifier\n\nNN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\nNN.fit(X_train_set, y_train_set)\ny_pred_3 = NN.predict(X_val_set)","1486e88a":"roc_auc_score(y_val_set, y_pred_3)","c45592ff":"from sklearn.preprocessing import StandardScaler  \n\nscaler = StandardScaler() \nscaler.fit(X_train_set) \nX_train_set = scaler.transform(X_train_set)  \nX_val_set = scaler.transform(X_val_set)  ","3bde806f":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nimport tensorflow as tf","1d160ee0":"model = Sequential()\nmodel.add(Dense(32, input_dim=18, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC()])","86180930":"model.fit(X_train_set, y_train_set, epochs=250, batch_size=10)","50fe5422":"model.evaluate(X_val_set, y_val_set)","23fa831f":"test_df = pd.read_csv(\"\/kaggle\/input\/zindi-data\/Test.csv\")\n\n# preprocessing\ntest_df['gender'] = label.fit_transform(test_df['gender'])\ntest_df['race'] = label.fit_transform(test_df['race'])\ntest_df['dwelling'] = label.fit_transform(test_df['dwelling'])\ntest_df['dwelling_type'] = label.fit_transform(test_df['dwelling_type'])\ntest_df['province_code'] = label.fit_transform(test_df['province_code'])\ntest_df['metro_code'] = label.fit_transform(test_df['metro_code'])\ntest_df['nationality'] = label.fit_transform(test_df['nationality'])\ntest_df['RTH'] = label.fit_transform(test_df['RTH'])\ntest_df['marital_st'] = label.fit_transform(test_df['marital_st'])\ntest_df['Lang_inside'] = label.fit_transform(test_df['Lang_inside'])\ntest_df['Lang_outside'] = label.fit_transform(test_df['Lang_outside'])\ntest_df['Education'] = label.fit_transform(test_df['Education'])\ntest_df['lw_work'] = label.fit_transform(test_df['lw_work'])\ntest_df['lw_business'] = label.fit_transform(test_df['lw_business'])\ntest_df['help_on_household'] = label.fit_transform(test_df['help_on_household'])\ntest_df['job_or_business'] = label.fit_transform(test_df['job_or_business'])\ntest_df['nature_of_work'] = label.fit_transform(test_df['nature_of_work'])","e9621f97":"test_df.sample(5)","b0aa3e80":"test_ = test_df.drop([\"ID\", \"gender\"], axis=1)\ntest_ = scaler.transform(test_)  ","f9dcd072":"### predict on the test data\ntest_predictions = model.predict(test_)\nsubmission_df = pd.DataFrame()\nsubmission_df[\"ID\"] = test_df[\"ID\"]\nsubmission_df[\"target\"] = test_predictions\n# file\nsubmission_df.to_csv(\"submission.csv\", index=False)","2fa0ee7b":"submission_df.sample(5)","33921bc9":"model2 = Sequential()\nmodel2.add(Dense(10, input_dim=18, kernel_initializer='normal', activation='relu'))\nmodel2.add(Dropout(0.25))\nmodel2.add(Dense(10, kernel_initializer='normal', activation='relu'))\nmodel2.add(Dropout(0.25))\nmodel2.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n# Compile model. We use the the logarithmic loss function, and the Adam gradient optimizer.\nmodel2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","404d5a3d":"model2.fit(X_train_set, y_train_set, epochs=100, batch_size=10)","7da1c0f6":"model2.evaluate(X_val_set, y_val_set)","0fc111ac":"val_predictions = model2.predict(X_val_set)\nprint(roc_auc_score(y_val_set, val_predictions))","6e36e6d4":"test_predictions = model2.predict(test_)\nsubmission_df = pd.DataFrame()\nsubmission_df[\"ID\"] = test_df[\"ID\"]\nsubmission_df[\"target\"] = test_predictions\n# file\nsubmission_df.to_csv(\"submission1.csv\", index=False)","299008d9":"submission_df.sample(5)","bd9f0471":"Let's train a model.","27730a2b":"Let's try Random Forest Classifier.","d7bc7ebd":"Let's look at the **nature of work** column.","cd188d08":"Not much has improved...","2f95ec7e":"It looks like **Black African** women are way more likely to be victims of gender-based crimes.","104f7565":"It looks like women between 20 and 40 y.o are more likely to be victims of gender-based crimes.","c87694b7":"The features in the dataset are:\n\n\n*  **gender :**\tgender\t\t\t\n*  **age :**\tIndividual age\t\t\t\n*  **race :**\tIndividual race\t\t\t\n*  **dwelling :**\tThe dwelling\/house the person occupies\t\t\t\n*  **dwelling_type :**\tIs the dwelling formal or informal(Yes-formal, No-Informal)\t\t\t\n*  **province_code :**\tProvince code\t\t\t\n*  **metro_code :**\tMetro code\t\t\t\n*  **psu :**\tPrimary sampling unit of the survey\t\t\t\n*  **nationality :**\tIndividual Nationality\t\t\t\n*  **RTH :**\tIndividual Relationship to the head of the household\t\t\t\n*  **marital_st :**\tMarital status\t\t\t\n*  **Lang_inside :**\tThe main language the person speaks in the house\t\t\t\n*  **Lang_outside :**\tThe main language that is spoken outside the house.\t\t\t\n*  **Education :**\tEducation attainment\t\t\t\n*  **lw_work :**\tsalary\/wages\/any payment for work done in the last week\t\t\t\n*  **lw_business :**\tRun\/do any kind of a business in the last week\t\t\t\n*  **help_on_household :**\tHelp on household\/ business without any pay in the last week\t\t\t\n*  **nature_of_work :**\tThe nature of work(permanent, contract, fixed, etc)\n\nAnd the target column is:\n*  **Target :**\tCrime happenning in the last 5 years to individual\t\t\t\n\n","24108435":"Let's explore the **Education** column.","ddb2c9c1":"Let's look at **marital status**.","e334c872":"First, let's see our datatypes:","44c50956":"Let's use Keras.","fe53f11d":"Let's make a submission.","234622ae":"Let's see the at what ages women are more likely to be a victim.","acc04700":"Let's make our data numerical.","4a619f96":"The training set contains 7700+ input examples and 21 features.","2b156465":"Error metric.","42d78ddb":"Let's improve our model.","4cf8cce2":"Let's explore the **race** column.","6e5ddc1f":"Let's drop the **gender** columns.","4e703d9e":"Women with Grade 12 and 11 education are more at risk.","1a21bfc3":"Let's handle all categorical data.","d197c1e5":"Validate the model.","aa812258":"Now, let's look at how all the columns correlate with the target.","4cccbbd4":"It looks like single women are the most likely to be victims of these types of crimes.","9945b5b1":"Let's visualize the ratio of the **target** column.","6de1468d":"Let's look at **nationality**.","0632cf54":"Let's split the data","670ffe87":"Let's explore the **age** column."}}