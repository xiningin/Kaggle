{"cell_type":{"fca95223":"code","a63eff75":"code","54cae52f":"code","a4e6ff47":"code","bd798e9a":"code","40a3ee71":"code","4d796ae8":"code","e18fd79b":"code","490cb799":"code","29dc4df6":"code","0a60bc8a":"code","b3b6d68a":"code","2b710af4":"code","cd7ea998":"code","f4979b3d":"code","e1b55221":"code","adfa6bb2":"code","2b25ff48":"code","8ccab88d":"code","ab76d5af":"code","51d83d6e":"code","000ef7a5":"code","221ec195":"code","84ba9669":"code","0ff0f5a9":"code","cc57526b":"code","11962088":"code","4c0b4359":"code","59e7b690":"code","1b338b4e":"code","572e71db":"code","75b9894c":"code","2480484a":"markdown","ea11d2f4":"markdown"},"source":{"fca95223":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\nfrom keras.layers.merge import concatenate, add\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","a63eff75":"print(os.listdir(\"..\/input\"))","54cae52f":"# Set some parameters\nim_width = 128\nim_height = 128\nborder = 5\npath_train = '..\/input\/train\/'\npath_test = '..\/input\/test\/'","a4e6ff47":"# Get and resize train images and masks\ndef get_data(path, train=True):\n    ids = next(os.walk(path + \"images\"))[2]\n    X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n    if train:\n        y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n    print('Getting and resizing images ... ')\n    for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n        # Load images\n        img = load_img(path + '\/images\/' + id_, grayscale=True)\n        x_img = img_to_array(img)\n        x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n\n        # Load masks\n        if train:\n            mask = img_to_array(load_img(path + '\/masks\/' + id_, grayscale=True))\n            mask = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\n        # Save images\n        X[n, ..., 0] = x_img.squeeze() \/ 255\n        if train:\n            y[n] = mask \/ 255\n    print('Done!')\n    if train:\n        return X, y\n    else:\n        return X\n    \nX, y = get_data(path_train, train=True)","bd798e9a":"# Split train and valid\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=2018)","40a3ee71":"# Check if training data looks all right\nix = random.randint(0, len(X_train))\nhas_mask = y_train[ix].max() > 0\n\nfig, ax = plt.subplots(1, 2, figsize=(20, 10))\n\nax[0].imshow(X_train[ix, ..., 0], cmap='seismic', interpolation='bilinear')\nif has_mask:\n    ax[0].contour(y_train[ix].squeeze(), colors='k', levels=[0.5])\nax[0].set_title('Seismic')\n\nax[1].imshow(y_train[ix].squeeze(), interpolation='bilinear', cmap='gray')\nax[1].set_title('Salt');","4d796ae8":"def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n    # first layer\n    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n               padding=\"same\")(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    # second layer\n    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n               padding=\"same\")(x)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x","e18fd79b":"def get_unet(input_img, n_filters=16, dropout=0.5, batchnorm=True):\n    # contracting path\n    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n    p1 = MaxPooling2D((2, 2)) (c1)\n    p1 = Dropout(dropout*0.5)(p1)\n\n    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n    p2 = MaxPooling2D((2, 2)) (c2)\n    p2 = Dropout(dropout)(p2)\n\n    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n    p3 = MaxPooling2D((2, 2)) (c3)\n    p3 = Dropout(dropout)(p3)\n\n    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n    p4 = Dropout(dropout)(p4)\n    \n    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n    \n    # expansive path\n    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    u6 = Dropout(dropout)(u6)\n    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n\n    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n\n    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n\n    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n    \n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    return model","490cb799":"input_img = Input((im_height, im_width, 1), name='img')\nmodel = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n\nmodel.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","29dc4df6":"callbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n    ModelCheckpoint('model-tgs-salt.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","0a60bc8a":"results = model.fit(X_train, y_train, batch_size=32, epochs=100, callbacks=callbacks,\n                    validation_data=(X_valid, y_valid))","b3b6d68a":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"loss\"], label=\"loss\")\nplt.plot(results.history[\"val_loss\"], label=\"val_loss\")\nplt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend()","2b710af4":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"acc\"], label=\"acc\")\nplt.plot(results.history[\"val_acc\"], label=\"val_acc\")\nplt.plot( np.argmin(results.history[\"val_acc\"]), np.min(results.history[\"val_acc\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend()","cd7ea998":"# Load best model\nmodel.load_weights('model-tgs-salt.h5')","f4979b3d":"# Evaluate on validation set (this must be equals to the best log_loss)\nmodel.evaluate(X_valid, y_valid, verbose=1)","e1b55221":"# Predict on train, val and test\npreds_train = model.predict(X_train, verbose=1)\npreds_val = model.predict(X_valid, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)","adfa6bb2":"def plot_sample(X, y, preds, binary_preds, ix=None):\n    if ix is None:\n        ix = random.randint(0, len(X))\n\n    has_mask = y[ix].max() > 0\n\n    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n    if has_mask:\n        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[0].set_title('Seismic')\n\n    ax[1].imshow(y[ix].squeeze())\n    ax[1].set_title('Salt')\n\n    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[2].set_title('Salt Predicted')\n    \n    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[3].set_title('Salt Predicted binary');","2b25ff48":"# Check if training data looks all right\nplot_sample(X_train, y_train, preds_train, preds_train_t, ix=13)","8ccab88d":"# Check if valid data looks all right\nplot_sample(X_valid, y_valid, preds_val, preds_val_t, ix=19)","ab76d5af":"# Set some parameters\nim_width = 128\nim_height = 128\nborder = 5\npath_train = '..\/input\/train\/'\npath_test = '..\/input\/test\/'","51d83d6e":"X, y = get_data(path_train, train=True)\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=2018)","000ef7a5":"input_img = Input((im_height, im_width, 1), name='img')\nmodel = get_unet(input_img, n_filters=16, dropout=0., batchnorm=True)\n\nmodel.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","221ec195":"data_gen_args = dict(horizontal_flip=True,\n                     vertical_flip=True)\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen = ImageDataGenerator(**data_gen_args)\n\nseed = 2018\nbs = 32\n\nimage_generator = image_datagen.flow(X_train, seed=seed, batch_size=bs, shuffle=True)\nmask_generator = mask_datagen.flow(y_train, seed=seed, batch_size=bs, shuffle=True)\n\n# Just zip the two generators to get a generator that provides augmented images and masks at the same time\ntrain_generator = zip(image_generator, mask_generator)","84ba9669":"callbacks = [\n    EarlyStopping(patience=10, verbose=1),\n    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.000001, verbose=1),\n    ModelCheckpoint('model-tgs-salt.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","0ff0f5a9":"results = model.fit_generator(train_generator, steps_per_epoch=(len(X_train) \/\/ bs), epochs=100, callbacks=callbacks,\n                              validation_data=(X_valid, y_valid))","cc57526b":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"loss\"], label=\"loss\")\nplt.plot(results.history[\"val_loss\"], label=\"val_loss\")\nplt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","11962088":"# Load best model\nmodel.load_weights('model-tgs-salt.h5')","4c0b4359":"# Evaluate on validation set (this must be equals to the best log_loss)\nmodel.evaluate(X_valid, y_valid, verbose=1)","59e7b690":"# Predict on train, val and test\npreds_train = model.predict(X_train, verbose=1)\npreds_val = model.predict(X_valid, verbose=1)\n","1b338b4e":"def show_flipped_images(x):\n    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n    ax[0].imshow(x[:,:,0], cmap='seismic')\n    ax[0].set_title('original')\n    ax[1].imshow(np.fliplr(x[:,:,0]), cmap='seismic')\n    ax[2].imshow(np.flipud(x[:,:,0]), cmap='seismic')\n    ax[3].imshow(np.fliplr(np.flipud(x[:,:,0])), cmap='seismic')","572e71db":"def plot_sample(X, y, preds, preds_tta, binary_preds, ix=None):\n    if ix is None:\n        ix = random.randint(0, len(X))\n\n    has_mask = y[ix].max() > 0\n\n    fig, ax = plt.subplots(1, 5, figsize=(20, 10))\n    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n    if has_mask:\n        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[0].set_title('Seismic')\n\n    ax[1].imshow(y[ix].squeeze())\n    ax[1].set_title('Salt')\n\n    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[2].set_title('Salt Predicted')\n\n    ax[3].imshow(preds_tta[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[3].set_title('Salt Predicted TTA')\n\n    ax[4].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[4].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[4].set_title('Salt Predicted binary');","75b9894c":"# Check if training data looks all right\nplot_sample(X_train, y_train, preds_train, preds_train_tta, preds_train_tta>0.5, ix=14)\n","2480484a":"### Load the images","ea11d2f4":"### With data augmentation"}}