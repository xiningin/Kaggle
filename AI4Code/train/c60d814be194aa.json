{"cell_type":{"f8702a11":"code","20eceea9":"code","091b945f":"code","5920e0e5":"code","b820f92d":"code","d0099d77":"code","d5caa074":"code","b7bf4bc5":"code","b2f5c234":"code","8ffef51b":"code","3b3c073b":"code","2d759181":"code","00d3706d":"code","76ebd719":"code","6670bcc8":"code","77e7d968":"code","3b21f0f2":"code","9f319472":"code","fbf4d9d2":"code","eba3c46c":"code","b110a32c":"code","62961a6c":"code","17065fca":"code","972edce9":"code","58595085":"code","391b7185":"code","50052ed8":"code","566fb04f":"code","fa0c22b3":"code","73b51ed6":"code","d2a5f996":"code","8d75e6e9":"code","24fd6ec2":"code","dd372ccd":"code","8b5672ea":"code","c2ec4259":"code","2cc52f77":"code","925ec0b8":"code","8c5231bc":"code","c9b9e253":"code","fa12315a":"code","75175632":"code","f5f58d45":"code","f7312d37":"code","20baca39":"code","285756ef":"code","8285c56f":"code","00e7d0a4":"code","e20ac36f":"code","0ffebf5f":"code","c96577e4":"code","51dc08e9":"code","de841521":"code","620d1d23":"code","dcf3a20b":"code","2269bba1":"code","97fd2b38":"code","96b42bc4":"code","07be3721":"code","98dde30b":"code","b1926063":"code","8df6b9cf":"code","f911911b":"code","14a20c28":"code","52c068e7":"code","37b27ea7":"code","6218077f":"markdown","c8820143":"markdown","ab49a11c":"markdown","d0cd93f8":"markdown"},"source":{"f8702a11":"import pandas as pd\nimport numpy as np\nimport scipy as sp\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nsns.set_theme()\nprint(\"imported\")","20eceea9":"data = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndata.head()","091b945f":"data.T.head(60)","5920e0e5":"data.T.tail(20)","b820f92d":"nulls = ((data.isnull().sum()\/len(data))*100).to_frame().rename(columns = {0:\"null_percent\"})\n\n# -- checking for features which are having more than 40 percentage of null values\nnulls[nulls[\"null_percent\"] > 40]","d0099d77":" # -- columns which has more than 40 percent null values in it are dropped\n\ndata.drop(nulls[nulls[\"null_percent\"] > 40].index, axis = 1, inplace = True)","d5caa074":"x = data.groupby([\"MSSubClass\"])[\"SalePrice\"].mean().to_frame().sort_values(\"SalePrice\").reset_index()\n\nplt.figure(figsize = (15,5))\nplt.subplot(1,2,1)\nsns.barplot(x[\"MSSubClass\"], x[\"SalePrice\"], \n            order = x.sort_values(\"SalePrice\", ascending = False).MSSubClass, \n            color = \"black\")\n\nplt.subplot(1,2,2)\nsns.countplot(data[\"MSSubClass\"], color = \"black\", \n              order = data[\"MSSubClass\"].value_counts().index)\n\nplt.show()","b7bf4bc5":"neigh = data.groupby([\"Neighborhood\"])[[\"SalePrice\"]].mean().reset_index()\nplt.figure(figsize = (15,5))\nsns.barplot(neigh[\"Neighborhood\"], neigh[\"SalePrice\"], \n            order = neigh.sort_values(\"SalePrice\", ascending = False).Neighborhood,\n            palette = \"ocean_d\")\nplt.xticks(rotation = 90)\nplt.show()","b2f5c234":"pd.crosstab(data[\"YrSold\"], data[\"Neighborhood\"]).T","8ffef51b":"data.groupby([\"Neighborhood\", \"OverallQual\", \"OverallCond\"])[[\"SalePrice\"]].mean()","3b3c073b":"cross = pd.crosstab(data[\"YrSold\"], data[\"Neighborhood\"]).T\ncross.plot(kind = \"bar\", stacked = True, figsize = (15,8))\nplt.show()","2d759181":"data.groupby([\"Neighborhood\",\"ExterQual\",\"ExterCond\",\n              \"Foundation\",\"BsmtQual\",\"BsmtCond\",\n              \"BsmtExposure\",\"BsmtFinType1\",\n              \"BsmtFinType2\"])[[\"SalePrice\"]].mean().head(60)","00d3706d":"data.groupby([\"OverallQual\",\"OverallCond\"])[[\"SalePrice\"]].mean()","76ebd719":"data.groupby([\"Neighborhood\",\"MSZoning\", \"LandContour\", \"Street\", \"LotFrontage\", \"Condition1\", \"Condition2\", \"Utilities\"])[[\"SalePrice\"]].mean()","6670bcc8":"data.groupby([\"YearBuilt\",\"YrSold\"])[[\"SalePrice\"]].mean()","77e7d968":"df = data[[\"YearBuilt\",\"YrSold\",\"SalePrice\"]]\ndf[\"YrDiff\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\ndf.groupby([\"YearBuilt\", \"YrSold\", \"YrDiff\"])[[\"SalePrice\"]].mean()","3b21f0f2":"df.groupby([\"YrDiff\"])[[\"SalePrice\"]].mean().plot(kind = \"line\", color = \"blue\", figsize = (35,7))\nplt.show()","9f319472":"df2 = df.groupby([\"YearBuilt\",\"YrDiff\"])[[\"SalePrice\"]].mean().reset_index()\n\nplt.figure(figsize = (20,5))\nsns.lineplot(data = df2, x = \"YearBuilt\", y = \"SalePrice\", hue = \"YrDiff\", palette = \"rainbow\")\nplt.show()","fbf4d9d2":"data.groupby(\"MSZoning\")[[\"SalePrice\"]].mean().plot(kind = \"bar\", color = \"blue\", figsize = (7,5))\nplt.show()","eba3c46c":"df3 = pd.DataFrame()\ndf3 = df3.append(((data.isnull().sum()\/len(data))*100).to_frame()).rename(columns = {0:\"Null Percentage\"})\ndf3[\"Total_null_count\"] = data.isnull().sum()\ndf3[\"Total_count\"] = len(data)\ndf3","b110a32c":"df3[(df3[\"Null Percentage\"] > 0)&(df3[\"Null Percentage\"] <= 10)]","62961a6c":"data[data.isnull().any(True)]","17065fca":"indx = df3[df3[\"Null Percentage\"]>0].index\ntotal_rows = data.shape[0]\n\na,b,c = 5,5,1\nfig = plt.figure(figsize = (25,30))\nfor i in indx:\n    plt.subplot(a,b,c)\n    value1 = data[i].isnull().sum()\n    value2 = total_rows - value1\n    plt.pie(x = [value1, value2], labels = [\"nulls\", \"non-nulls\"],\n            radius = 1,autopct = \"%.2f\")\n    plt.title(i.upper())\n    c = c+1\nplt.show()\n    ","972edce9":"v1 = data[data.isnull().any(True)].shape[0]\nv2 = data.shape[0] - v1\n\nplt.figure(figsize = (15,7))\nplt.subplot(1,2,1)\nplt.pie(x = [v1, v2], labels = [\"nulls\", \"non-nulls\"],\n       radius = 1, explode = [0.01,0],\n       autopct = \"%.2f\")\n\nplt.subplot(1,2,2)\nv1 = data[data[[\"Electrical\",\"MasVnrArea\",\"MasVnrType\"]].isnull().any(True)].shape[0]\nv2 = data.shape[0] - v1\nplt.pie(x = [v1, v2], labels = [\"nulls\", \"non-nulls\"],\n       radius = 1, explode = [0.01,0],\n       autopct = \"%.2f\")\n\nplt.show()","58595085":"nulls = df3[df3[\"Null Percentage\"]>0]\ncolumn_names = df3[df3[\"Null Percentage\"]>0].index\nnulls[\"datatype\"] = data[column_names].dtypes\nnulls","391b7185":"nulls[nulls[\"datatype\"] == \"float\"]","50052ed8":"data[nulls[nulls[\"datatype\"] == \"float\"].index].skew()","566fb04f":"def find_similar_features(feature):\n    correlation = dict()\n    for i in data.select_dtypes(\"number\").columns:\n        if i!=feature:\n            correlation.update({i:data[feature].corr(data[i])})\n    keys, values = list(correlation.keys()), list(correlation.values())\n    max_value = max(values)\n    for i,j in correlation.items():\n        if j == max_value:\n            print(f\"{feature} has high correlation with a feature {i} : {j}\")\n            \nfind_similar_features(\"GarageYrBlt\")","fa0c22b3":"plt.figure(figsize = (17,5))\nplt.subplot(1,2,1)\nsns.histplot(data[\"GarageYrBlt\"], kde=True)\n\nplt.subplot(1,2,2)\nsns.scatterplot(data[\"GarageYrBlt\"], data[\"YearBuilt\"])\nplt.show()","73b51ed6":"print(data[data[[\"GarageYrBlt\",\"YearBuilt\"]].isnull().any(True)][[\"GarageYrBlt\",\"YearBuilt\"]].shape[0])\nprint(data[data[[\"GarageYrBlt\",\"YearBuilt\"]].isnull().any(True)][[\"GarageYrBlt\",\"YearBuilt\"]][\"GarageYrBlt\"].isnull().sum())","d2a5f996":"'''\n\n    Both the features \"GarageYrBlt\" and \"YearBuilt\" has the same characteristics and represents the same thing in the dataframe.\n    \n    Hence, one of them has to be dropped. Since, \"GarageYrBlt\" had more number of null values in it, I dropped it by retaining\n    \n    the feature with lower null percentage \"YearBuilt\".\n\n'''\n\ndata.drop(\"GarageYrBlt\", axis = 1, inplace = True)","8d75e6e9":"find_similar_features(\"MasVnrArea\")","24fd6ec2":"plt.figure(figsize = (17,5))\nplt.subplot(1,2,1)\nsns.histplot(data[\"MasVnrArea\"], kde=True)\n\ndata_df = data.groupby([\"MasVnrType\"])[\"MasVnrArea\"].mean().reset_index()\n\nplt.subplot(1,2,2)\n#sns.barplot(data_df[\"MasVnrType\"],data_df[\"MasVnrArea\"])\nsns.scatterplot(data[\"SalePrice\"],data[\"MasVnrArea\"])\nplt.show()","dd372ccd":"data_df = data.groupby([\"MasVnrType\"])[\"SalePrice\"].mean().reset_index()\n\nsns.barplot(data_df[\"MasVnrType\"],data_df[\"SalePrice\"])\n\nplt.show()","8b5672ea":"a,b,c = 13,3,1\nplt.figure(figsize = (30,100))\nfor i in data.select_dtypes(\"object\").columns:\n    plt.subplot(a,b,c)\n    sns.boxplot(data[i], data[\"MasVnrArea\"])\n    plt.xticks(rotation = 45)\n    c = c+1\nplt.show()\n    ","c2ec4259":"from sklearn.impute import KNNImputer\n\nknn_imputed = pd.DataFrame(KNNImputer().fit_transform(data[data.drop(\"Id\", axis = 1).select_dtypes(\"number\").columns]))\nknn_imputed.columns = data.drop(\"Id\", axis = 1).select_dtypes(\"number\").columns\ndata[knn_imputed.columns] = knn_imputed\ndata","2cc52f77":"nulls_object = nulls[nulls[\"datatype\"] == \"object\"]\nnulls_object","925ec0b8":"null_cat = data[data[nulls_object.index].isnull().any(True)][nulls_object.index]\nnull_cat[:60]","8c5231bc":"null_cat[60:120]","c9b9e253":"null_cat[-2:]","fa12315a":"(data[data[nulls_object.index].isnull().any(True)].shape[0]\/data.shape[0])*100","75175632":"data.dropna(inplace = True)","f5f58d45":"data.isnull().sum().sum()","f7312d37":"data.describe().T","20baca39":"def outliers(df):\n    a,b,c = 10,4,1\n    plt.figure(figsize = (50,100))\n    for i in df.columns:\n        plt.subplot(a,b,c)\n        sns.boxplot(df[i])\n        plt.title(i.upper())\n        c = c+1\n    plt.show()","285756ef":"outliers(data.select_dtypes(\"number\"))","8285c56f":"'''\n\nFeatures with unusual outliers :\n\n--> BsmtFinSF2: Type 2 finished square feet\n--> LowQualFinSF: Low quality finished square feet (all floors)\n--> BsmtHalfBath: Basement half bathrooms\n--> KitchenAbvGr : -- no info\n--> EnclosedPorch: Enclosed porch area in square feet\n--> 3SsnPorch: Three season porch area in square feet\n--> ScreenPorch: Screen porch area in square feet\n--> PoolArea: Pool area in square feet\n--> MiscVal: $Value of miscellaneous feature\n\nLooking at the outliers of all of the above features, it's clear that most of the values in the data are 0. But, considering the nature of the features, there is no way 0 can be a part of those values.\nHence, I conidered all those zero's as either nulls or mistakenly entered data. Upon considering all the zeros as nulls, I've decided to drop those feratures since there is no way we can impute them considering their proportion w.r to the overall data.\n\n\nbelow are the outliers representation of the above mentioned features.\n\n'''\n\nfeature = [\"BsmtFinSF2\",\"LowQualFinSF\",\"BsmtHalfBath\",\"KitchenAbvGr\",\n           \"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\"]\n\na,b,c = 2,5,1\n\nplt.figure(figsize = (50,20))\nfor i in feature:\n    plt.subplot(a,b,c)\n    sns.boxplot(data[i])\n    plt.title(i.upper(), fontsize = 15)\n    c = c+1\nplt.show()","00e7d0a4":"data.drop(feature, axis = 1, inplace = True)","e20ac36f":"outliers(data.select_dtypes(\"number\"))","0ffebf5f":"# -- filtering out features with outliers :\n\nfeatures = data.select_dtypes(\"number\").columns\noutlier_features = dict()\nfor i in features:\n    n25, n50, n75 = np.percentile(data[i], [25,50,75])\n    iqr = n75 - n25\n    lb = n25 - (1.5*iqr)\n    ub = n75 + (1.5*iqr)\n    outliers  = len(data[(data[i]<lb)|(data[i]>ub)])\n    if outliers>0:\n        plt.figure(figsize = (15,5))\n        sns.violinplot(data[i])\n        outlier_features.update({i:outliers})\n    plt.show()","c96577e4":"x = pd.DataFrame(outlier_features, index = [0]).T.rename(columns = {0:\"outlier\"})\nx[\"total_length\"] = data.shape[0]\nx.T","51dc08e9":"features = data.select_dtypes(\"number\").columns\nfor i in features:\n    n1,n25, n50, n75, n99 = np.percentile(data[i], [1,25,50,75,99])\n    iqr = n75 - n25\n    lb = n25 - (1.5*iqr)\n    ub = n75 + (1.5*iqr)\n    outliers = len(data[(data[i]<lb)|(data[i]>ub)])\n    if outliers>0:\n        indx = data[(data[i]<lb)|(data[i]>ub)].index\n        for j in indx:\n            if j<round(data.shape[0]):\n                data.loc[j,i] = data[i].mean()\n            else:\n                data.loc[j,i] = data[i].mean()","de841521":"# -- filtering out features with outliers :\n\nfeatures = data.select_dtypes(\"number\").columns\noutlier_features = dict()\nfor i in features:\n    n25, n50, n75 = np.percentile(data[i], [25,50,75])\n    iqr = n75 - n25\n    lb = n25 - (1.5*iqr)\n    ub = n75 + (1.5*iqr)\n    outliers  = len(data[(data[i]<lb)|(data[i]>ub)])\n    if outliers>0:\n        plt.figure(figsize = (15,5))\n        sns.violinplot(data[i])\n        outlier_features.update({i:outliers})\n    plt.show()","620d1d23":"features = [\"MasVnrArea\",\"OpenPorchSF\"]\nfor i in features:\n    n25, n50, n75 = np.percentile(data[i], [25,50,75])\n    iqr = n75 - n25\n    lb = n25 - (1.5*iqr)\n    ub = n75 + (1.5*iqr)\n    outliers = len(data[(data[i]<lb)|(data[i]>ub)])\n    if outliers>0:\n        indx = data[(data[i]<lb)|(data[i]>ub)].index\n        for j in indx:\n            data.drop(j, axis = 0, inplace = True)","dcf3a20b":"feature = data.select_dtypes(\"number\").columns\n\na,b,c = 6,5,1\n\nplt.figure(figsize = (50,50))\nfor i in feature:\n    plt.subplot(a,b,c)\n    sns.boxplot(data[i])\n    plt.title(i.upper(), fontsize = 15)\n    c = c+1\nplt.show()","2269bba1":"data.drop(\"MasVnrArea\", axis = 1, inplace = True)","97fd2b38":"features = data.select_dtypes(\"number\").columns\nfor i in features:\n    n25, n50, n75 = np.percentile(data[i], [25,50,75])\n    iqr = n75 - n25\n    lb = n25 - (1.5*iqr)\n    ub = n75 + (1.5*iqr)\n    outliers = len(data[(data[i]<lb)|(data[i]>ub)])\n    if outliers>0:\n        indx = data[(data[i]<lb)|(data[i]>ub)].index\n        for j in indx:\n            data.drop(j, axis = 0, inplace = True)","96b42bc4":"feature = data.select_dtypes(\"number\").columns\n\na,b,c = 6,5,1\n\nplt.figure(figsize = (50,50))\nfor i in feature:\n    plt.subplot(a,b,c)\n    sns.boxplot(data[i])\n    plt.title(i.upper(), fontsize = 15)\n    c = c+1\nplt.show()","07be3721":"obj_feat = data.select_dtypes(\"object\").columns\nunique_categories = dict()\nfor i in obj_feat:\n    count = data[i].nunique()\n    unique_categories.update({i:count})\n\nlength = pd.DataFrame(unique_categories, index = [\"count\"]).T\nmore_unique = length[length[\"count\"] >= 10].index\n\nfor i in more_unique:\n    data.drop(i, axis = 1, inplace = True)","98dde30b":"final_table = pd.get_dummies(data, drop_first = True)\nfinal_table","b1926063":"final_table[\"SalePrice\"]","8df6b9cf":"from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import LinearSVR\nfrom sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport statsmodels.api as sm","f911911b":"np.array(final_table.columns)","14a20c28":"x = final_table.drop([\"SalePrice\",\"Id\"], axis = 1)\nscaled = StandardScaler().fit_transform(x)\nx[x.columns] = scaled\nx = sm.add_constant(x)\ny = final_table[\"SalePrice\"]\nmodel = sm.OLS(y,x).fit()\nmodel.summary()","52c068e7":"x = final_table[['LotArea','OverallCond', 'YearRemodAdd', 'BsmtFinSF1',\n       'TotalBsmtSF', 'GrLivArea','Fireplaces','MSZoning_FV', \n       'MSZoning_RL', 'RoofMatl_CompShg', 'ExterQual_Gd', 'ExterQual_TA',\n       'BsmtQual_Fa', 'BsmtQual_TA', 'CentralAir_Y',\n       'GarageFinish_Unf']]\nscaled = StandardScaler().fit_transform(x)\nx[x.columns] = scaled\nx = sm.add_constant(x)\ny = final_table[\"SalePrice\"]\nmodel = sm.OLS(y,x).fit()\nmodel.summary()","37b27ea7":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nfor i in range(len(x.columns)):\n    vif = variance_inflation_factor(x.values,i)\n    print(i, x.columns[i], vif)","6218077f":"## ***CONTINUE...***","c8820143":"## **NULL VALUES LOG**","ab49a11c":"### **NULL HANDLING ON NUMERICAL COLUMNS**","d0cd93f8":"### **NULL HANDLING ON CATEGORICAL COLUMNS**"}}