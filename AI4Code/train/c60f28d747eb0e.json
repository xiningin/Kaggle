{"cell_type":{"ebee6a7d":"code","2e23eb1f":"code","3285c617":"code","6592fcb3":"code","3c097f97":"code","04dc9318":"code","3799c750":"code","435449c3":"code","fa59e05a":"code","1de8ba6e":"code","f375d2dd":"code","d542f34b":"code","d6c11df9":"code","63e74528":"code","a0f04561":"code","76bbf88e":"code","651d9c5b":"code","b7601b2a":"code","7f2c14aa":"code","86ac0768":"code","27bc067a":"code","4c88fba8":"markdown","b7be9484":"markdown","34c1ad4c":"markdown","aa38e9f1":"markdown","00777961":"markdown","afec8026":"markdown","daf08c16":"markdown","b6a84cc1":"markdown","e2d1348d":"markdown","4341efcb":"markdown","543aa427":"markdown"},"source":{"ebee6a7d":"import spacy\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf","2e23eb1f":"ds_train = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\nds_test = pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")","3285c617":"ds_train.head()","6592fcb3":"ds_test.head()","3c097f97":"sequence_length = ds_train.text.map(lambda x: len(x)).max()\nprint('Train max length sentence', ds_train.text.map(lambda x: len(x)).max())\nprint('Test max length sentence', ds_test.text.map(lambda x: len(x)).max())","04dc9318":"vectorization_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n    standardize='lower_and_strip_punctuation',\n    output_mode='int'\n)\nvectorization_layer.adapt(np.array(ds_train.text))","3799c750":"nlp = spacy.load('en_core_web_lg')\nembedding_dim=len(nlp('and').vector)\nvocab_size = len(vectorization_layer.get_vocabulary())\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\n\nfor i, word in enumerate(vectorization_layer.get_vocabulary()):\n        embedding_matrix[i] = nlp(word).vector","435449c3":"print('Vocabulary sample', vectorization_layer.get_vocabulary()[:20])\nprint('Vocabulary length', len(vectorization_layer.get_vocabulary()))","fa59e05a":"model = tf.keras.Sequential([\n    vectorization_layer,\n    tf.keras.layers.Embedding(\n        vocab_size,\n        embedding_dim,\n        embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True)),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","1de8ba6e":"class F1_Score(tf.keras.metrics.Metric):\n\n    def __init__(self, name='f1_score', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.f1 = self.add_weight(name='f1', initializer='zeros')\n        self.precision_fn = tf.metrics.Precision(thresholds=0.5)\n        self.recall_fn = tf.metrics.Recall(thresholds=0.5)\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        p = self.precision_fn(y_true, y_pred)\n        r = self.recall_fn(y_true, y_pred)\n        self.f1.assign(2 * ((p * r) \/ (p + r + 1e-6)))\n\n    def result(self):\n        return self.f1\n\n    def reset_states(self):\n        self.precision_fn.reset_states()\n        self.recall_fn.reset_states()\n        self.f1.assign(0)","f375d2dd":"opt = tf.keras.optimizers.Nadam(0.01)\nmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', F1_Score()])","d542f34b":"X, y = np.array(ds_train.text), np.array(ds_train.target)\nX.shape, y.shape","d6c11df9":"history = model.fit(\n    X, y, \n    epochs=100, \n    batch_size=128, \n    validation_split=.1,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(monitor='val_f1_score', mode='max', patience=5, restore_best_weights=True)\n    ]\n)","63e74528":"import matplotlib.pyplot as plt","a0f04561":"# plot some data\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.legend()\nplt.show()","76bbf88e":"# Plotting accuracies\nplt.plot(history.history['accuracy'], label='acc')\nplt.plot(history.history['val_accuracy'], label='val_acc')\nplt.legend()\nplt.show()","651d9c5b":"plt.plot(history.history['f1_score'], label='f1_score')\nplt.plot(history.history['val_f1_score'], label='val_f1_score')\nplt.legend()\nplt.show()","b7601b2a":"prediction_scores = model.predict(np.array(ds_test.text))\nprediction_classes = prediction_scores > 0.5 ","7f2c14aa":"submission = pd.DataFrame({'id': ds_test.id, 'target': prediction_classes.flatten().astype(int)})","86ac0768":"submission.to_csv('submission.csv', index=False)","27bc067a":"pd.read_csv('submission.csv')","4c88fba8":"**Loss**","b7be9484":"**Accuracy**","34c1ad4c":"# Make Predictions","aa38e9f1":"# Make some analysis on validation predictions","00777961":"**F1 Score**\n\nThis is the most important metric for this competition as it will represent better the public score","afec8026":"# Get the Data","daf08c16":"**build embedding matrix**","b6a84cc1":"# Plot History","e2d1348d":"The competition uses F1 score to evaluate submissions so we use that as a better metric","4341efcb":"# Build Model","543aa427":"We can safely conclude that the model overfits as more epochs pass"}}