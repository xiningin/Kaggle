{"cell_type":{"989c98d5":"code","70d8a89d":"code","e4a14420":"code","89d3c1a4":"code","6a5dd6ab":"code","e507c24a":"code","b39d01e5":"code","bd346d8a":"code","e98cc733":"code","ce935113":"code","fc00ad64":"code","ce83afc4":"code","e5480e45":"code","512ba0a5":"code","2d2ad605":"markdown","da6ae80d":"markdown","02a3d2a7":"markdown","19ef239a":"markdown"},"source":{"989c98d5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport glob\nimport os\nimport re\nsns.set()\n%matplotlib inline\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","70d8a89d":"df = pd.read_csv('\/kaggle\/input\/texas-winter-strom-2021-tweets\/tweets_txwx2021.csv', index_col=None)","e4a14420":"df.shape","89d3c1a4":"df.info()","6a5dd6ab":"df.head()","e507c24a":"df[['user_name','text','created','user_followers']]","b39d01e5":"sns.heatmap(df.isnull())","bd346d8a":"sns.histplot(np.log1p(df['user_followers']),color='g')","e98cc733":"df['tweet_length'] = df['text'].apply(lambda x : len(x))\nsns.histplot(df['tweet_length'], color='g')","ce935113":"def clean_text(text):\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('<.*?>+', '', text)\n    return text","fc00ad64":"df['clean_text'] = df['text'].apply(clean_text)","ce83afc4":"def generate_wc(fig_size=(10,10), \n                 text_series = df['text'], \n                 stop_words = None, \n                 max_font_size = 100,\n                 max_words = 150,\n                 background_color = 'white',\n                 color_map = 'inferno',\n                 inter_polation = 'bilinear'\n                ):\n    \n    from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n    all_words = \" \".join(word for word in text_series)\n    fig, ax = plt.subplots(1, 1, figsize  = fig_size)\n    # Create and generate a word cloud image:\n    stopwords = set(STOPWORDS)\n    if stop_words != None:\n        stopwords.update(stop_words)\n    wordcloud_ALL = WordCloud(max_font_size=max_font_size,\n                              collocations=False,\n                              stopwords=stopwords, \n                              max_words=max_words, \n                              background_color=background_color,\n                              colormap=color_map).generate(all_words)\n    # Display the generated image:\n    ax.imshow(wordcloud_ALL, interpolation=inter_polation)\n    ax.axis('off')","e5480e45":"stop_words = ['RT','Texas','state','people','Texan','Texans','week','now','U','via','s','amp','let','one', 't', 'de','la','en','el', 'las','ola', 'winter','storm', 'will']\ngenerate_wc(fig_size=(15,15), \n                 text_series = df['clean_text'][df['user_followers'] > 100000], \n                 stop_words = stop_words, \n                 max_font_size = 100,\n                 max_words = 150,\n                 background_color = 'white',\n                 color_map = 'magma',\n                 inter_polation = 'bilinear'\n            )","512ba0a5":"stop_words = ['m','ga','re','two','RT','Texas','state','people','Texan','Texans','week','now','U','via','s','amp','let','one', 't', 'de','la','en','el', 'las','ola', 'winter','storm', 'will']\ngenerate_wc(fig_size=(15,15), \n                 text_series = df['clean_text'], \n                 stop_words = stop_words, \n                 max_font_size = 100,\n                 max_words = 150,\n                 background_color = '#f5f5f5',\n                 color_map = 'twilight',\n                 inter_polation = 'bilinear'\n            )\n\nax.axis('off')","2d2ad605":"## Word Cloud of all tweets","da6ae80d":"## Missing values","02a3d2a7":"## Work in Progress","19ef239a":"## Word Cloud of tweets from users with more than 100K followers"}}