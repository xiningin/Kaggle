{"cell_type":{"374d663b":"code","25734b4b":"code","03333709":"code","b40f5f26":"code","612c7ea7":"code","184d6797":"code","bb2fb7e8":"code","4967c0c3":"code","4d5b0cbf":"code","4e1b9c31":"code","fcf36efd":"code","1f6c3d26":"code","2aded75a":"code","f4a1fd48":"code","08cba8da":"code","964782db":"code","21b227e7":"code","08276927":"code","8cf1c240":"code","775c9244":"code","9cfbffe2":"code","a4e4feeb":"code","61aaccc0":"code","4cb986b2":"code","671cac4e":"code","7f51794d":"code","8b4b1ee6":"code","f34124aa":"code","8e2992c1":"code","f98d6148":"code","30341893":"code","32f829a2":"code","60679311":"code","348f1454":"code","4bef400a":"code","0a42f7c7":"code","79d23018":"code","09446e23":"code","9941e7f4":"code","bc3f9f1d":"code","eac39ca2":"code","79b5a6b2":"code","87887e3e":"code","c6fda5e5":"code","05483fc4":"code","25938904":"code","3d41bcb3":"code","f7f1779f":"code","54bb940d":"code","b4db2653":"code","4d9e8ba4":"code","3c1e7dc5":"code","362423ad":"code","5abf4b68":"code","a8f1cc37":"code","c27cd244":"code","b707a2fc":"code","8e8c959a":"code","c634631e":"markdown","1379b9b0":"markdown","f6991394":"markdown","cb3ba2ac":"markdown","95be6230":"markdown","397d9082":"markdown","bb271f02":"markdown","755bbed1":"markdown","6f0f28ca":"markdown","5eeac313":"markdown","1bfad367":"markdown","32eb3e55":"markdown","5f57f890":"markdown","0f55383a":"markdown","2cafaf1a":"markdown","4e706957":"markdown","d1c0c383":"markdown","01110d69":"markdown","6f255249":"markdown","ed752b10":"markdown","090240fd":"markdown","2f0592c7":"markdown","4df056e7":"markdown","523dfc6e":"markdown","56f4b71d":"markdown","09334dc3":"markdown","697ad0fb":"markdown","b5ae7bd5":"markdown","f2eb95f7":"markdown","0f613acb":"markdown","621c2f1b":"markdown","965131d2":"markdown","2ae65279":"markdown","8defdcab":"markdown","29ec44ac":"markdown","60b93e0d":"markdown","ad4541c2":"markdown","5ce15e3d":"markdown"},"source":{"374d663b":"import numpy as np\nimport pandas as pd\n\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n#import seaborn as sns\n%matplotlib inline\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\n\nimport warnings\nwarnings.filterwarnings('ignore')","25734b4b":"import collections\n\nfrom IPython.display import display\n\nclass Exploration(object):\n    \"\"\"\n        How to run:\n                    fa = Exploration(df).DescribeAnalysis(True)\n    \"\"\"\n\n    def __init__(self, dataframe):\n\n        self.dataframe = dataframe\n\n    def _getFirstNumericalColNameIndex(self,tem_df):\n        for col in tem_df.columns:\n            col_type = tem_df[col].dtype\n            if (col_type != 'object') and (col_type != 'datetime64') and (col_type != 'bool'):\n\n                first_numerical_col_name = col\n#                     print(tem_df.columns.get_loc(col))\n                break\n        return tem_df.columns.get_loc(col)\n\n\n    def DescribeAnalysis(self, dis=False):\n\n        \"\"\"\n            Input:\n                    DataFrame\n            Output:\n                    Dataframe:\n                        Features: Name of Features\n                        Dtype: type of data\n                        Nunique: number of unique value\n                        freq1: most frequent value\n                        freq1_val: number of occurance of the most frequent value\n                        freq2: second most frequent value\n                        freq2_val: number of occurance of the second most frequent value\n                        freq3: 3rd most frequent value, if available\n                        freq3_val: number of occurance of the thrid most frequent value, if available\n                        describe stats: the following ones are the stat offer by our best friend .describe methods.\n        \"\"\"\n\n\n        # get input column dataframe name\n        cols = self.dataframe.columns\n\n        # set name of output dataframe\n        stat_cols= ['Dtype', 'Nunique', 'nduplicate', 'freq1', 'freq1_val', 'freq2', 'freq2_val',\n             'freq3', 'freq3_val'] + self.dataframe[cols[self._getFirstNumericalColNameIndex(self.dataframe)]].describe().index.tolist()[1:]\n        stat_cols = ['Features']+stat_cols\n\n        feature_stat = pd.DataFrame(columns=stat_cols)\n        i = 0\n\n        for col in cols:\n            col_type = self.dataframe[col].dtype\n            if (col_type != 'object') and (col_type != 'datetime64[ns]') and (col_type != 'bool'):\n                stat_vals = []\n\n                # get stat value\n                stat_vals.append(col)\n                # Data type\n                stat_vals.append(self.dataframe[col].dtype)\n                # number of unique\n                stat_vals.append(self.dataframe[col].nunique())\n                # nduplicate\n                stat_vals.append(self.dataframe.shape[0]-self.dataframe[col].nunique())\n                # 'freq1' & freq1_val'\n                stat_vals.append(self.dataframe[col].value_counts().index[0])\n                stat_vals.append(self.dataframe[col].value_counts().iloc[0])\n                #'freq2', 'freq2_val'\n                try:\n                    stat_vals.append(self.dataframe[col].value_counts().index[1])\n                    stat_vals.append(self.dataframe[col].value_counts().iloc[1])\n                except Exception:\n                    stat_vals.append(np.nan)\n                    stat_vals.append(np.nan)\n                # 'freq3', 'freq3_val'\n                if len(self.dataframe[col].value_counts())>2:\n                    stat_vals.append(self.dataframe[col].value_counts().index[2])\n                    stat_vals.append(self.dataframe[col].value_counts().iloc[2])\n                else:\n                    stat_vals.append(np.nan)\n                    stat_vals.append(np.nan)\n\n                stat_vals += self.dataframe[col].describe().tolist()[1:]\n                feature_stat.loc[i] = stat_vals\n                i += 1\n\n        # dipslay dataframe\n        if dis:\n            # display(nunique_duplicate)\n            display(feature_stat)\n\n        return feature_stat\n","03333709":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\npy.init_notebook_mode(connected=True)\n\n\n\nclass PlotingMissingValues(object):\n    \"\"\"\n    input:\n    df: dataframe\n    verbosity: show the resul of finding missing values\n    output:\n        list of tuple of missitng value and key: [(key,value)]\n\n    Methods:\n        FindingMissingValue(Ture shows the result)\n        PlotMissingValue: show the plot of miasing value\n    \"\"\"\n\n    def __init__(self, df):\n        self.df =  df\n\n    def FindingMissingValue(self, verbosity =True):\n        df_size = self.df.shape[0]\n\n        if self.df.isnull().values.any():\n            if  verbosity:\n                print(self.df.isnull().sum())\n\n            value, key = [], []\n            for col in self.df.columns:\n                value.append(round(self.df[col].isnull().sum()\/df_size *100,2))\n                key.append(col)\n                missingValue = list(zip(key,value))\n\n            return missingValue\n\n        else:\n            print('There is no NAN in dataframe')\n            return None\n\n\n    def __getListofTupleValues(self,listOfTuple):\n        \"\"\"\n         input:\n             [(key,value)]\n         output:\n             list of keys & list of values\n        \"\"\"\n        key = [listOfTuple[i][0] for i in range(len(listOfTuple))]\n        value = [listOfTuple[i][1] for i in range(len(listOfTuple))]\n        return key,value\n\n    def __Plot(self,key, value):\n        data_array = value\n        hist_data = np.histogram(data_array)\n        x = value\n        y = key\n        \"\"\"\n            x: list of value\n            y : list of key\n        \"\"\"\n        data = [go.Bar(\n                x=x,\n                y=y,\n                text=x,\n                orientation = 'h',\n                textposition = 'auto',\n                marker=dict(\n                    color='rgb(227,67,45)',\n                    line=dict(\n                        color='rgb(8,48,107)',\n                        width=2.5),\n                ),\n                opacity=0.6\n            )]\n        layout = go.Layout(\n            title='Missing Values',\n            autosize=False,\n            width=600,\n            height=1200,\n            margin=go.Margin(\n                l=200,\n                r=0,\n                b=100,\n                t=100,\n                pad=4\n            )\n        )\n\n        fig = go.Figure(data=data, layout=layout)\n        py.iplot(fig, filename='bar-direct-labels')\n\n    def PlotMissingValue(self):\n        finding_missing_values= self.FindingMissingValue(False)\n        if finding_missing_values==None:\n            pass\n        else:\n            key, value = self.__getListofTupleValues(finding_missing_values)\n            self.__Plot(key, value)\n","b40f5f26":"def wordFrequencyPlot(df,colname):\n    temp = df[colname].value_counts()\n    trace = go.Bar(\n        y=temp.index[::-1],\n        x=(temp \/ temp.sum() * 100)[::-1],\n        orientation = 'h',\n        marker=dict(\n            color='blue',\n        ),\n    )\n\n    layout = go.Layout(\n        title = colname + \" Top  (%)\",\n        xaxis=dict(\n            title=' count',\n            tickfont=dict(size=14,)),\n        yaxis=dict(\n#             title='',\n            titlefont=dict(size=16),\n            tickfont=dict(\n                size=14)),\n        margin=dict(\n        l=200,\n    ),\n\n    )\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig)","612c7ea7":"from scipy.stats import skew\nfrom scipy.stats import kurtosis\ndef plotBarCat(df,feature,target,nbins=2):\n    \n    \n    \n    x0 = df[df[target]==0][feature]\n    x1 = df[df[target]==1][feature]\n\n    trace1 = go.Histogram(\n        x=x0,\n        nbinsx =nbins, \n        opacity=0.75\n    )\n    trace2 = go.Histogram(\n        x=x1,\n        nbinsx = nbins, \n        opacity=0.75\n    )\n\n    data = [trace1, trace2]\n    layout = go.Layout(barmode='overlay',\n                      title=feature,\n                       yaxis=dict(title='Count'\n        ))\n    fig = go.Figure(data=data, layout=layout)\n\n    py.iplot(fig, filename='overlaid histogram')\n    \n    def DescribeFloatSkewKurt(df,target):\n        \"\"\"\n            A fundamental task in many statistical analyses is to characterize\n            the location and variability of a data set. A further\n            characterization of the data includes skewness and kurtosis.\n            Skewness is a measure of symmetry, or more precisely, the lack\n            of symmetry. A distribution, or data set, is symmetric if it\n            looks the same to the left and right of the center point.\n            Kurtosis is a measure of whether the data are heavy-tailed\n            or light-tailed relative to a normal distribution. That is,\n            data sets with high kurtosis tend to have heavy tails, or\n            outliers. Data sets with low kurtosis tend to have light\n            tails, or lack of outliers. A uniform distribution would\n            be the extreme case\n        \"\"\"\n        print('-*-'*25)\n        print(\"{0} mean : \".format(feature), np.mean(df[feature]))\n        print(\"{0} var  : \".format(feature), np.var(df[feature]))\n        print(\"{0} skew : \".format(feature), skew(df[feature]))\n        print(\"{0} kurt : \".format(feature), kurtosis(df[feature]))\n        print('-*-'*25)\n    \n    DescribeFloatSkewKurt(df,feature)\n","184d6797":"def piePlot(sizes,labels,title):\n\n\n    fig1, ax1 = plt.subplots(figsize=(8,8))\n    plt.rcParams.update({'font.size': 22})\n    ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n            shadow=True, startangle=90)\n    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n    plt.title(title)\n    plt.show()\n    \ndef piePlotLables(df,col,target,v_target):\n    select_df = df[[col, target]]\n    \n    col_isFraud =  select_df[select_df[target]==v_target].groupby(col).count().reset_index(drop=False)\n    \n    labels = col_isFraud[col].tolist()\n    sizes =  col_isFraud[target].tolist()\n    \n    return sizes, labels ","bb2fb7e8":"path = '..\/input\/'\ntrain_identity    = pd.read_csv(path+'train_identity.csv')\ntrain_transaction = pd.read_csv(path+'train_transaction.csv')\n\ntest_identity     = pd.read_csv(path+'test_identity.csv')\ntest_transaction  = pd.read_csv(path+'test_transaction.csv')","4967c0c3":"print('Shape:')\nprint('train_identity.shape {} train_transaction.shape {}'.format(train_identity.shape, train_transaction.shape))\nprint('test_identity.shape {} test_transaction.shape {}'.format(test_identity.shape, test_transaction.shape))","4d5b0cbf":"train_identity.head().T","4e1b9c31":"train_identity.describe(include=['O']).T","fcf36efd":"train_identity_col_cat = train_identity.describe(include=['O']).columns","1f6c3d26":"feature_info_train_identity  = Exploration(train_identity).DescribeAnalysis(True)","2aded75a":"PlotingMissingValues(train_identity).PlotMissingValue()","f4a1fd48":"wordFrequencyPlot(train_identity,train_identity_col_cat[0])","08cba8da":"# wordFrequencyPlot(train_identity,train_identity_col_cat[1])","964782db":"# wordFrequencyPlot(train_identity,train_identity_col_cat[2])","21b227e7":"# wordFrequencyPlot(train_identity,train_identity_col_cat[3])","08276927":"# wordFrequencyPlot(train_identity,train_identity_col_cat[4])","8cf1c240":"# wordFrequencyPlot(train_identity,train_identity_col_cat[5])","775c9244":"# wordFrequencyPlot(train_identity,train_identity_col_cat[6])","9cfbffe2":"# wordFrequencyPlot(train_identity,train_identity_col_cat[7])","a4e4feeb":"# wordFrequencyPlot(train_identity,train_identity_col_cat[8])","61aaccc0":"wordFrequencyPlot(train_identity,train_identity_col_cat[15])","4cb986b2":"# wordFrequencyPlot(train_identity,train_identity_col_cat[16])","671cac4e":"col_remain = train_transaction.columns[17:]\nff=set()\nfor col in col_remain:\n    ff.add(col[0])\n    \nprint('Columns: ', ff)\n\n\ncol_remain = train_transaction.columns[17:]\nC_col = []\nD_col = []\nM_col = []\nV_col = []\n\nrest_col = []\n\nfor col in col_remain:\n    if col[0] == 'C':\n        C_col.append(col)\n    elif col[0] == 'D':\n        D_col.append(col)\n    elif col[0] == 'M':\n        M_col.append(col)\n    elif col[0] =='V':\n        V_col.append(col)\n    else:\n        rest_col.append(col)\n        \nprint('len C: {}, D: {}, M: {}, V: {}'.format(len(C_col),len(D_col),len(M_col),len(V_col)))","7f51794d":"train_transaction_16=train_transaction[train_transaction.columns[0:17]]\ntrain_transaction_16.head().T","8b4b1ee6":"feature_info_train_transaction_16  = Exploration(train_transaction_16).DescribeAnalysis(True)","f34124aa":"# train_transaction_16['log_TransactionAmt'] = train_transaction_16['TransactionAmt'].apply(np.log)\n# plotBarCat(train_transaction_16,'log_TransactionAmt','isFraud',40)","8e2992c1":"feature = 'TransactionAmt'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","f98d6148":"feature = 'TransactionAmt'\nplt.boxplot(train_transaction_16[train_transaction_16[feature]<300][feature].dropna(),vert=False)\nplt.title(feature)","30341893":"# plotBarCat(train_transaction_16,'isFraud','isFraud')","32f829a2":"print('  {:.4f}% of Transactions that are fraud in train '.format(train_transaction['isFraud'].mean() * 100))","60679311":"feature = 'TransactionDT'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","348f1454":"feature = 'card1'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","4bef400a":"feature = 'card2'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","0a42f7c7":"feature = 'card5'\nplt.boxplot(train_transaction_16[feature].dropna(),vert=False)\nplt.title(feature)","79d23018":"train_transaction_16.describe(include=['O']).T","09446e23":"# wordFrequencyPlot(train_transaction_16,'ProductCD')","9941e7f4":"col = 'ProductCD'\ntarget = 'isFraud'    \nsizes, labels = piePlotLables(train_transaction_16,col,target,0)\npiePlot(sizes,labels,'Not Fraud(0)')","bc3f9f1d":"col = 'ProductCD'\ntarget = 'isFraud'    \nsizes, labels = piePlotLables(train_transaction_16,col,target,1)\npiePlot(sizes,labels,'Fraud(1)')","eac39ca2":"# wordFrequencyPlot(train_transaction_16,'card4')","79b5a6b2":"wordFrequencyPlot(train_transaction_16,'card6')","87887e3e":"wordFrequencyPlot(train_transaction_16,'P_emaildomain')","c6fda5e5":"# wordFrequencyPlot(train_transaction_16,'R_emaildomain')","05483fc4":"# PlotingMissingValues(train_transaction_16).PlotMissingValue()","25938904":"train_transaction[C_col].head()","3d41bcb3":"C_col_info = Exploration(train_transaction[C_col]).DescribeAnalysis(True)","f7f1779f":"PlotingMissingValues(train_transaction[C_col]).PlotMissingValue()","54bb940d":"train_transaction[D_col].head()","b4db2653":"D_col_info = Exploration(train_transaction[D_col]).DescribeAnalysis(True)","4d9e8ba4":"# PlotingMissingValues(train_transaction[D_col]).PlotMissingValue()","3c1e7dc5":"train_transaction[M_col].head()","362423ad":"train_transaction[M_col].describe(include=['O'])","5abf4b68":"wordFrequencyPlot(train_transaction[M_col],'M4')","a8f1cc37":"col = 'M4'\ntarget = 'isFraud'    \nsizes, labels = piePlotLables(train_transaction,col,target,0)\npiePlot(sizes,labels,'NOT Fraud(0)')","c27cd244":"col = 'M4'\ntarget = 'isFraud'    \nsizes, labels = piePlotLables(train_transaction,col,target,1)\npiePlot(sizes,labels,'Fraud(1)')","b707a2fc":"from sklearn import base\nfrom sklearn.model_selection import KFold\n\nclass KFoldMeanEncoder(base.BaseEstimator, base.TransformerMixin):\n\n    def __init__(self, colnames,targetName,n_fold=5,verbosity=True,discardOriginal_col=False):\n\n        self.colnames = colnames\n        self.targetName = targetName\n        self.n_fold = n_fold\n        self.verbosity = verbosity\n        self.discardOriginal_col = discardOriginal_col\n\n    def fit(self, X, y=None):\n        return self\n\n\n    def transform(self,X):\n\n        assert(type(self.targetName) == str)\n        assert(type(self.colnames) == list)\n\n        mean_of_target = X[self.targetName].mean()\n        kf = KFold(n_splits = self.n_fold, shuffle = False)\n\n        for col in self.colnames:\n\n            col_mean_name = col + '_' + 'KfoldMeanEnc'\n            X[col_mean_name] = np.nan\n\n            for tr_ind, val_ind in kf.split(X):\n                X_tr, X_val = X.iloc[tr_ind], X.iloc[val_ind]\n                X.loc[X.index[val_ind], col_mean_name] = X_val[col].map(X_tr.groupby(col)[self.targetName].mean())\n\n            X[col_mean_name].fillna(mean_of_target, inplace = True)\n\n            if self.verbosity:\n                #print correlation\n                encoded_feature = X[col_mean_name].values\n                print('Correlation between the new feature, {} and, {} is {:.4f}.'.format(col_mean_name,\n                                                                                      self.targetName,\n                                                                                      np.corrcoef(X[self.targetName].values, encoded_feature)[0][1]))\n        if self.discardOriginal_col:\n            X = X.drop(self.targetName, axis=1)\n\n        return X","8e8c959a":"KFME= KFoldMeanEncoder(['ProductCD','card4','card6','P_emaildomain','R_emaildomain',\n                       'M1','M2','M3','M4','M5','M6','M7','M8','M9'],'isFraud')\ntrain_transaction_KFME = KFME.fit_transform(train_transaction)","c634631e":"## id_29","1379b9b0":"## id_15","f6991394":"## ProductCD","cb3ba2ac":"**Becasue of Kernel uploading Plotly plots limitation, Please uncomment the command lines, you might find something intersting **","95be6230":"## isFraud","397d9082":"# Data Prepration & Descriptive Analysis","bb271f02":"## M4","755bbed1":"## Device Type","6f0f28ca":"## Train Identity","5eeac313":"# First 16 Columns Train Transaction","1bfad367":"## Missing Value","32eb3e55":"## R_emaildomain","5f57f890":"## id_33\nBecause of Kernel limitation countinue by yourself","0f55383a":"## id_27","2cafaf1a":"## Device Info","4e706957":"## Card4","d1c0c383":"## M-Columns","01110d69":"## TransactionAmt","6f255249":"## C-columns","ed752b10":"## Card6","090240fd":"## id_12","2f0592c7":"## Card2","4df056e7":"## id_23","523dfc6e":"# Codes\nyou can skip this part if you are just interested in results","56f4b71d":"## D-Columns","09334dc3":"# Categorical","697ad0fb":"## id_28","b5ae7bd5":"## Card5","f2eb95f7":"## Transaction DT\nThe TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp).","0f613acb":"## Card1","621c2f1b":"## id_30","965131d2":"## id_16","2ae65279":"## id_31","8defdcab":"# Train Identity Categorical","29ec44ac":"## P_emaildomain","60b93e0d":"# K-Fold Target Encoding","ad4541c2":"### Reading","5ce15e3d":"# Train Transaction"}}