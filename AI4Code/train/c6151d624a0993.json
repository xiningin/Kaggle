{"cell_type":{"15be4017":"code","58625f30":"code","f2d521b8":"code","a71393f9":"code","a95158c8":"code","65fe5f05":"code","3b2ba88f":"code","80ae17af":"code","1091a3d8":"code","48afe626":"code","c6f1ac9c":"code","369d981e":"code","26b1ac3e":"code","231749b5":"code","b2bae85f":"code","5caa51a9":"code","f55496cd":"code","2d171ac0":"code","36da5444":"code","75eebe95":"code","043b5652":"code","9356f27f":"code","74925a3d":"code","3dcb4a65":"code","9fbd5a77":"code","414de161":"code","18e30ff3":"code","cf619587":"code","120a10b4":"markdown","564edaac":"markdown","3d904527":"markdown","537b0c4f":"markdown","d181a14b":"markdown"},"source":{"15be4017":"import pandas as pd\nTRAIN_CSV_PATH = \"..\/input\/steam-game-reviews\/game_rvw_csvs\/107410_Arma3.csv\" # \u532f\u5165csv\ntrain = pd.read_csv(TRAIN_CSV_PATH, index_col=0).astype(str)\n\ntrain['review'] = train['review'].str.lower() # \u5c07\u8a55\u8ad6\u8f49\u5c0f\u5beb\ntrain.head()","58625f30":"train['voted_up'].value_counts()","f2d521b8":"train['review'].shape","a71393f9":"train.drop(columns=['recommendationid','language','timestamp_created','timestamp_updated','votes_up','votes_funny','weighted_vote_score','comment_count','steam_purchase','received_for_free','written_during_early_access','author.steamid','author.num_games_owned','author.num_reviews','author.playtime_forever','author.playtime_last_two_weeks','author.playtime_at_review','author.last_played'],inplace=True)\ntrain.head()\nx_test_review = train","a95158c8":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', -1)\nx_test_review[51517:51537]","65fe5f05":"import nltk\nfrom nltk.tokenize import word_tokenize \ntext = \"word tokenize test\"\nword_tokenize(text)","3b2ba88f":"train['review_tokenized'] = train['review'].apply(word_tokenize)","80ae17af":"train.head()","1091a3d8":"import keras\nMAX_NUM_WORDS = 10000 # \u9650\u5236\u5b57\u5178\u53ea\u80fd\u5305\u542b10000\u500b\u8a5e\u5f59\ntokenizer = keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS)","48afe626":"corpus_x1 = train.review_tokenized # \u5efa\u7acbtext corpus\ncorpus = pd.concat([corpus_x1])\ncorpus.shape","c6f1ac9c":"tokenizer.fit_on_texts(corpus) # \u67e5\u770btext corpus\u5f8c\u5efa\u7acb\u5b57\u5178","369d981e":"x_train = tokenizer.texts_to_sequences(corpus_x1) # x1_train\u70ba\u4e00\u500blist\u5305\u542b\u6bcf\u4e00\u689dreview\u7684\u6578\u5b57\u5e8f\u5217","26b1ac3e":"len(x_train)","231749b5":"x_train[:1] # \u6aa2\u67e5row1\u7684\u6578\u5b57\u5e8f\u5217","b2bae85f":"for seq in x_train[:1]:\n    print([tokenizer.index_word[idx] for idx in seq]) # \u5c07\u7d22\u5f15\u6578\u5b57\u5c0d\u61c9\u56de\u672c\u4f86\u7684\u8a5e\u5f59","5caa51a9":"import numpy as np \n\n# \u5b9a\u7fa9\u6bcf\u4e00\u500b\u5206\u985e\u5c0d\u61c9\u5230\u7684\u7d22\u5f15\u6578\u5b57\nlabel_to_index = {\n    'False': 0, \n    'True': 1\n}\n\n# \u5c07\u5206\u985e\u6a19\u7c64\u5c0d\u61c9\u5230\u525b\u5b9a\u7fa9\u7684\u6578\u5b57\ny_train = train.voted_up.apply(\n    lambda x: label_to_index[x])\n\ny_train = np.asarray(y_train) \\\n            .astype('float32')\n\ny_train[:5]","f55496cd":"x_test = x_train[51517:]\nx_train = x_train[:51517]","2d171ac0":"y_test = y_train[51517:]\ny_train = y_train[:51517]","36da5444":"len(y_train)","75eebe95":"len(y_test)","043b5652":"len(x_train)","9356f27f":"len(x_test)","74925a3d":"x_train = tokenizer.sequences_to_matrix(x_train) #\u2190\u5c07\u8a13\u7df4\u6a23\u672c\u505a multi-hot \u7de8\u78bc\nx_test  = tokenizer.sequences_to_matrix(x_test)  #\u2190\u5c07\u6e2c\u8a66\u6a23\u672c\u505a multi-hot \u7de8\u78bc","3dcb4a65":"#\u5efa\u7acb\u6a21\u578b\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential()                       #\u2190\u5efa\u7acb\u6a21\u578b\u7269\u4ef6\nmodel.add(Dense(16, activation='relu', input_dim=10000))  #\u2190\u8f38\u5165\u5c64\nmodel.add(Dense(16, activation='relu'))    #\u2190\u96b1\u85cf\u5c64\nmodel.add(Dense(1, activation='sigmoid'))  #\u2190\u8f38\u51fa\u5c64\n\n#\u7de8\u8b6f\u6a21\u578b\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['acc'])\n\n#\u8a13\u7df4\u53ca\u9a57\u8b49\u6a21\u578b\nhistory = model.fit(x_train, y_train,\n                    batch_size=512,  #\u2190\u6bcf\u6279\u6b21 512 \u7b46\u6a23\u672c\n                    epochs=10,       #\u2190\u5171\u8a13\u7df4 10 \u9031\u671f\n                    verbose = 2,     #\u2190\u986f\u793a\u7cbe\u7c21\u8a0a\u606f (\u7121\u9032\u5ea6\u689d)\n                    validation_split=0.2)\n                             #\u2191\u7531\u8a13\u7df4\u8cc7\u6599\u5f8c\u9762\u5207\u51fa 20% \u505a\u70ba\u9a57\u8b49\u7528\n\nimport sys\nsys.path.append(r\"..\/input\/util2py\")\n\nimport util2 as u\n\nu.plot(history.history,\n       ('loss', 'val_loss'),          #\u2190\u6b77\u53f2\u8cc7\u6599\u4e2d\u7684 key\n       'Training & Validation Loss',  #\u2190\u7dda\u5716\u7684\u6a19\u984c\n       ('Epoch','Loss'))              #\u2190x,y \u8ef8\u7684\u540d\u7a31\nu.plot(history.history,\n       ('acc', 'val_acc'),            #\u2190\u6b77\u53f2\u8cc7\u6599\u4e2d\u7684 key\n       'Training & Validation Acc',   #\u2190\u7dda\u5716\u7684\u6a19\u984c\n       ('Epoch','Acc'))               #\u2190x,y \u8ef8\u7684\u540d\u7a31","9fbd5a77":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential()                       #\u2190\u5efa\u7acb\u6a21\u578b\u7269\u4ef6\nmodel.add(Dense(16, activation='relu', input_dim=10000))  #\u2190\u8f38\u5165\u5c64\nmodel.add(Dense(16, activation='relu'))    #\u2190\u96b1\u85cf\u5c64\nmodel.add(Dense(1, activation='sigmoid'))  #\u2190\u8f38\u51fa\u5c64\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['acc'])\n\nhistory = model.fit(x_train, y_train,\n                    batch_size=512,\n                    epochs=3,      # \u53ea\u8a13\u7df4 5 \u9031\u671f\n                    verbose=2)     # \u4e0d\u986f\u793a\u9032\u5ea6\u689d\n\nloss, acc = model.evaluate(x_test, y_test, verbose=2)  # \u7528\u6e2c\u8a66\u8cc7\u6599\u8a55\u4f30\u5be6\u969b\u7684\u6210\u6548\nprint('\u6e96\u78ba\u7387\uff1a', acc)","414de161":"model.predict(x_test[:20])","18e30ff3":"model.predict_classes(x_test[:20])","cf619587":"y_test[:20].astype(int)","120a10b4":"# model creation","564edaac":"# split data to train-data & test-data","3d904527":"# dealing label","537b0c4f":"# dealing review","d181a14b":"# import data"}}