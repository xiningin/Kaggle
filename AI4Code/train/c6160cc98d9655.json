{"cell_type":{"4085e43c":"code","a4e9b6fd":"code","f74d5e9e":"code","d446c5e0":"code","df3f487a":"code","0c7a07d5":"code","efdf52df":"code","87e6b2c6":"code","206c86b0":"code","28d4c079":"markdown","77ada39d":"markdown","92d5ebdd":"markdown","a0180efe":"markdown","bc1a96af":"markdown"},"source":{"4085e43c":"!pip install efficientnet -q\n!pip install blackcellmagic -q\n%load_ext blackcellmagic","a4e9b6fd":"import sys\nsys.path.append('..\/input\/utilities')","f74d5e9e":"from kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import KFold\nfrom dataset import TFRecordDataset\nimport efficientnet.tfkeras as efn\nimport matplotlib.pyplot as plt\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport os","d446c5e0":"class Config:\n\n    seed = 42\n    img_size = 640\n    verbose = 2\n\n    index = {\n        \"StudyInstanceUID\": tf.io.FixedLenFeature([], tf.string),\n        \"id\": tf.io.FixedLenFeature([], tf.string),\n    }\n    \n    target = {\n        \"Negative for Pneumonia\": tf.io.FixedLenFeature([], tf.float32),\n        \"Typical Appearance\": tf.io.FixedLenFeature([], tf.float32),\n        \"Indeterminate Appearance\": tf.io.FixedLenFeature([], tf.float32),\n        \"Atypical Appearance\": tf.io.FixedLenFeature([], tf.float32),\n    }\n    \n#     train_path = 'siimcovid-v2-tfrecords'\n#     train_path = 'siimcovid-vit-tfrecords'\n    train_path = 'siimcovid-b7-tfrecords'\n    gcs_train_path = KaggleDatasets().get_gcs_path(train_path)\n    \n    val_path = 'siimcovid-tfrecords'\n    gcs_val_path = KaggleDatasets().get_gcs_path(val_path)\n    \n    folds = 5\n    used_folds = [0]\n    \n    epochs = 100\n    patience = [7, 3]\n    factor = 0.1\n    min_lr = 1e-6\n    \n    def _detect_accelerator(self) -> None:\n        try:\n            self.tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            tf.config.experimental_connect_to_cluster(self.tpu)\n            tf.tpu.experimental.initialize_tpu_system(self.tpu)\n            self.strategy = tf.distribute.experimental.TPUStrategy(self.tpu)\n        except:\n            self.tpu = None\n            if self.mixed_precision:\n                tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n            self.strategy = tf.distribute.get_strategy()\n\n    def __init__(\n        self, debug: bool = False, mixed_precision: bool = True\n    ) -> None:\n        self.debug = debug\n        if self.debug:\n            self.used_folds = [0]\n            self.epochs = 1\n            self.verbose = 1\n        self.mixed_precision = mixed_precision\n        self._detect_accelerator()\n        if self.img_size > 640:\n            self.batch_size = 8 * self.strategy.num_replicas_in_sync\n        else:\n            self.batch_size = 16 * self.strategy.num_replicas_in_sync\n        self.lr = 1e-3 \/ 128 * self.batch_size\n        print(f\"Running on {self.strategy.num_replicas_in_sync} core(s).\")\n\n\nconfig = Config()","df3f487a":"def count_data_items(filenames: list) -> int:\n    \"\"\"\n    Return number of training samples given filenames\n    \"\"\"\n    return np.sum([int(x[:-6].split(\"-\")[-1]) for x in filenames])\n\n\ndef augmentation_function(image: tf.Tensor) -> tf.Tensor:\n    \"\"\"\n    Return augmented image\n    \"\"\"\n    image = tf.image.random_flip_left_right(image, seed=config.seed)\n    image = tf.image.random_flip_up_down(image, seed=config.seed)\n    image = tf.image.random_hue(image, 0.01, seed=config.seed)\n    image = tf.image.random_saturation(image, 0.7, 1.3, seed=config.seed)\n    image = tf.image.random_contrast(image, 0.8, 1.2, seed=config.seed)\n    image = tf.image.random_brightness(image, 0.1, seed=config.seed)\n    return image\n\n\ndef get_model(weights: str = \"noisy-student\") -> tf.keras.models.Model:\n    \"\"\"\n    Return tf.keras.models.Model initialized with given weights\n\n    Args\n\n        weights: one of \"imagenet\", \"noisy-student\", \"nih\"\n\n    \"\"\"\n    model = tf.keras.models.Sequential(name=\"EfficientNet\")\n\n    if weights == \"nih\":\n        source_model = tf.keras.models.load_model(\"..\/input\/nih-models\/model_0.h5\")\n        for layer in source_model.layers[:-1]:\n            model.add(layer)\n    else:\n        model.add(\n            efn.EfficientNetB7(\n                include_top=False,\n                input_shape=(config.img_size, config.img_size, 3),\n                weights=weights,\n                pooling=\"avg\",\n            )\n        )\n        model.add(\n            tf.keras.layers.Dense(\n                len(config.target),\n                kernel_initializer=tf.keras.initializers.RandomUniform(seed=config.seed),\n                bias_initializer=tf.keras.initializers.Zeros(),\n                name=\"dense_top\",\n            )\n        )\n        \n    model.add(tf.keras.layers.Activation(\"softmax\", dtype=\"float32\"))\n\n    model.compile(\n        loss=\"categorical_crossentropy\",\n        optimizer=tf.keras.optimizers.Adam(lr=config.lr),\n        metrics=[tf.keras.metrics.AUC(multi_label=True, name=\"auc\")],\n    )\n\n    return model","0c7a07d5":"histories = [None] * config.folds\nscores = [None] * config.folds\ndf_oof = pd.DataFrame(\n    data=None, columns=list(config.index.keys()) + list(config.target.keys())\n)\ndf_test = pd.DataFrame(\n    data=None, columns=list(config.index.keys()) + list(config.target.keys())\n)\n\nkfold = KFold(n_splits=config.folds, shuffle=True, random_state=config.seed)\n\nfor i, (train_index, val_index) in enumerate(kfold.split(range(config.folds))):\n\n    if i not in config.used_folds:\n        continue\n\n    with config.strategy.scope():\n        model = get_model(weights=\"nih\")\n\n    # collect filenames\n    train_filenames = np.ravel(\n        [\n            tf.io.gfile.glob(\n                os.path.join(\n                    config.gcs_train_path, \"train\", \"*\", f\"fold_{x}\", \"*.tfrec\"\n                )\n            )\n            for x in train_index\n        ]\n    )\n\n    val_filenames = np.ravel(\n        [\n            tf.io.gfile.glob(\n                os.path.join(config.gcs_val_path, \"train\", f\"fold_{x}\", \"*.tfrec\")\n            )\n            for x in val_index\n        ]\n    )\n\n    test_filenames = tf.io.gfile.glob(\n        os.path.join(config.gcs_val_path, \"test\", \"*.tfrec\")\n    )\n\n    # create datasets\n    train_dataset = TFRecordDataset(\n        train_filenames,\n        target=config.target,\n        img_size=(config.img_size, config.img_size),\n        batch_size=config.batch_size,\n        seed=config.seed,\n        ordered=False,\n        shuffled=True,\n        repeated=True,\n    ).dataset\n\n    val_dataset = TFRecordDataset(\n        val_filenames,\n        target=config.target,\n        img_size=(config.img_size, config.img_size),\n        batch_size=config.batch_size,\n        seed=config.seed,\n        cached=True,\n    ).dataset\n\n    # count steps\n    steps_per_epoch = count_data_items(train_filenames) \/\/ (\n        len(os.listdir(os.path.join(\"..\/input\", config.train_path, \"train\")))\n        * config.batch_size\n    )\n    validation_steps = count_data_items(val_filenames) \/\/ config.batch_size\n\n    # fit\n    history = model.fit(\n        train_dataset,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_dataset,\n        validation_steps=validation_steps,\n        callbacks=[\n            tf.keras.callbacks.EarlyStopping(\n                monitor=\"val_auc\",\n                mode=\"max\",\n                patience=config.patience[0],\n                restore_best_weights=True,\n            ),\n            tf.keras.callbacks.ReduceLROnPlateau(\n                monitor=\"val_auc\",\n                mode=\"max\",\n                patience=config.patience[1],\n                min_lr=config.min_lr,\n                verbose=2,\n            ),\n        ],\n        epochs=config.epochs,\n        verbose=config.verbose,\n    ).history\n\n    # save model and scores\n    model.save_weights(f\"model_{i}.h5\")\n    histories[i] = pd.DataFrame(history)\n    scores[i] = histories[i][\"val_auc\"].max()\n\n    # write oof predictions\n    dataset = TFRecordDataset(\n        val_filenames,\n        index=config.index,\n        img_size=(config.img_size, config.img_size),\n        batch_size=config.batch_size,\n    ).dataset\n\n    predicts = model.predict(dataset.map(lambda x, y: x))\n    ids = list(dataset.map(lambda x, y: y).unbatch().as_numpy_iterator())\n    ids = np.array([[y.decode() for y in x] for x in ids])\n\n    df_oof = df_oof.append(\n        pd.DataFrame(\n            data=np.c_[ids, predicts],\n            columns=list(config.index.keys()) + list(config.target.keys()),\n        )\n    )\n\n    # write test set predictions\n    dataset = TFRecordDataset(\n        test_filenames,\n        index=config.index,\n        img_size=(config.img_size, config.img_size),\n        batch_size=config.batch_size,\n    ).dataset\n\n    predicts = model.predict(dataset.map(lambda x, y: x)) \/ config.folds\n    ids = list(dataset.map(lambda x, y: y).unbatch().as_numpy_iterator())\n    ids = np.array([[y.decode() for y in x] for x in ids])\n\n    df_test = df_test.append(\n        pd.DataFrame(\n            data=np.c_[ids, predicts],\n            columns=list(config.index.keys()) + list(config.target.keys()),\n        )\n    )","efdf52df":"scores_df = pd.DataFrame(\n    {\"fold\": np.arange(config.folds), \"auc\": scores}\n).dropna()\n\nwith pd.option_context(\"display.max_rows\", config.folds):\n    display(scores_df)\n\nprint(\"CV %.4f\" % scores_df[\"auc\"].mean())","87e6b2c6":"figure, axes = plt.subplots(1, config.folds, figsize=(config.folds * 5, 5))\n\nfor i in range(config.folds):\n\n    if histories[i] is not None:\n        axes[i].plot(histories[i].loc[:, \"auc\"], label=\"train\")\n        axes[i].plot(histories[i].loc[:, \"val_auc\"], label=\"val\")\n        axes[i].legend()\n\n    axes[i].set_title(f\"fold {i}\")\n    axes[i].set_xlabel(\"epochs\")\n\nplt.show()","206c86b0":"df_test = df_test.groupby(list(config.index.keys())).sum()\ndf_oof.to_csv(\".\/oof.csv\", index=False)\ndf_test.to_csv(\".\/test.csv\", index=False)","28d4c079":"### Run training loop","77ada39d":"### Auxiliary functions","92d5ebdd":"### Configurations","a0180efe":"### Imports","bc1a96af":"### Results"}}