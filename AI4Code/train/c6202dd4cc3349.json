{"cell_type":{"f0df75fc":"code","66475801":"code","5c6744c2":"code","48707d5e":"code","34b09bc0":"code","bd9c12b1":"code","92d1f6f6":"code","92f1b661":"code","b4d2a7f2":"code","cf6c4bea":"code","64e50d4f":"code","13d1de59":"code","ca93763c":"code","fcb80b88":"code","b7ac08c9":"code","979d7cc8":"code","b1dc5f10":"code","6c3c6b33":"code","4e43bfea":"markdown","c8ad21f0":"markdown","b71a3319":"markdown"},"source":{"f0df75fc":"import re\nimport cufflinks\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom nltk import word_tokenize\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nfrom plotly.offline import iplot\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nlemmatizer = WordNetLemmatizer()\nstemmer = PorterStemmer() \n\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","66475801":"data = pd.read_csv('\/kaggle\/input\/cyberbullying-classification\/cyberbullying_tweets.csv')","5c6744c2":"data.head()","48707d5e":"data['cyberbullying_type'].value_counts()","34b09bc0":" def preprocess(sentence):\n    sentence = str(sentence)\n    sentence = sentence.lower()\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, '', sentence)\n    rem_num = re.sub('[0-9]+', '', cleantext)\n    tokenizer = RegexpTokenizer(r'\\w+')\n    tokens = tokenizer.tokenize(rem_num)  \n    filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n    stem_words = [stemmer.stem(w) for w in filtered_words ]\n    lemma_words = [lemmatizer.lemmatize(w) for w in stem_words]\n    return \" \".join(filtered_words)","bd9c12b1":"data['tweet_text'] = data['tweet_text'].map(lambda s:preprocess(s))","92d1f6f6":"data[\"tweet_text\"].duplicated().sum()","92f1b661":"data.drop_duplicates(\"tweet_text\", inplace=True)","b4d2a7f2":"data = data[data[\"cyberbullying_type\"]!=\"other_cyberbullying\"]","cf6c4bea":"from wordcloud import WordCloud\n\nplt.figure(figsize=(20,10))\nsubset1 = data[data['cyberbullying_type'] == 'gender']\ntext_gender = subset1.tweet_text.values\ncloud1 = WordCloud(background_color='black',colormap=\"cool\",collocations=False,width=2000,height=1000).generate(\" \".join(text_gender))\n\nplt.axis('off')\nplt.title(\"Gender\",fontsize=40)\nplt.imshow(cloud1)","64e50d4f":"labels = {\"not_cyberbullying\":0,\"gender\":1,\"ethnicity\":2,\"religion\":3,\"age\":4}\nlabels","13d1de59":"corpus, target_labels, target_names = (data['tweet_text'], [labels[label] for label in data['cyberbullying_type']],data['cyberbullying_type'])\ndf_new = pd.DataFrame({\"text_clean\":corpus,\"sentiment Label\": target_labels,\"sentiment names\": target_names})\ndf_new","ca93763c":"df_new['sentiment Label'].value_counts()","fcb80b88":"X_train, X_test, y_train, y_test = train_test_split(np.array(df_new[\"text_clean\"]),np.array(df_new[\"sentiment Label\"]), test_size=0.25, random_state=0)\ndisplay(X_train.shape)\ndisplay(X_test.shape)","b7ac08c9":"(unique, counts) = np.unique(y_train, return_counts=True)\nnp.asarray((unique, counts)).T","979d7cc8":"tfidf = TfidfVectorizer(use_idf=True, tokenizer=word_tokenize,min_df=0.00002,max_df=0.70)\nX_train_tf = tfidf.fit_transform(X_train.astype('U'))\nX_test_tf = tfidf.transform(X_test.astype('U'))\n\nprint(f\"TF_IDF Model: Train features shape:{X_train_tf.shape} and Test features shape:{X_test_tf.shape}\")","b1dc5f10":"rf = RandomForestClassifier(random_state=42)\ngb = GradientBoostingClassifier(random_state=42)\nlgb = LGBMClassifier(random_state=42)\nxgb = XGBClassifier(eval_metric=\"mlogloss\",random_state=42)\nmlp = MLPClassifier(random_state=42)\n\nclfs = {\n    \"Random Forest\": rf,\n    \"Gradient Boosting\":gb,\n    \"LightGBM\": lgb,\n    \"XGBoost\": xgb,\n    \"Multilayer Perceptron\":mlp\n}\n\ndef fit_model(clf,x_train,y_train,x_test, y_test):\n    clf.fit(x_train,y_train)\n    y_pred = clf.predict(x_test)\n    accuracy = accuracy_score(y_pred, y_test)\n    return accuracy\n\naccuracys = []\n\nfor name,clf in clfs.items():\n    curr_acc = fit_model(clf,X_train_tf,y_train,X_test_tf,y_test)\n    accuracys.append(curr_acc)","6c3c6b33":"models_df = pd.DataFrame({\"Models\":clfs.keys(),\"Accuracy Scores\":accuracys}).sort_values('Accuracy Scores',ascending=False)\nmodels_df","4e43bfea":"# Preprocessing","c8ad21f0":"# Import Libraries","b71a3319":"# wip"}}