{"cell_type":{"ce1d91d8":"code","0641ca83":"code","e17ba113":"code","a1ebf49e":"code","93a7ece6":"code","99852e64":"code","6439dc7f":"code","884fb2e8":"code","d59d9b2c":"code","4325922b":"code","dbd87af3":"code","856979e9":"code","061c0383":"code","7d04425b":"code","1540768a":"code","62fd3df5":"code","7fcf4fa8":"code","34e57fdc":"code","6d7941dd":"code","0ab4bce1":"code","e49b9c11":"code","6dc64fc0":"code","7aa6859d":"markdown","59c4f225":"markdown","d444ef24":"markdown"},"source":{"ce1d91d8":"!pip install pyspark\n!pip install findspark","0641ca83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport findspark\nfindspark.init\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e17ba113":"from pyspark.sql import SparkSession # required to created a dataframe\nspark=SparkSession.builder.appName(\"Basics\").getOrCreate() \n#spark=SparkSession.builder.appName(\"Basics\").config(\"spark.executor.memory\", \"70g\").config(\"spark.driver.memory\", \"50g\").config(\"spark.memory.offHeap.enabled\",True).config(\"spark.memory.offHeap.size\",\"16g\").getOrCreate() \n\nimport pyspark.sql.functions","a1ebf49e":"file = '..\/input\/bitcoin-tweets-20160101-to-20190329\/tweets.csv'\ndf = spark.read.csv(file, sep=\";\",inferSchema=True, header=True,multiLine=True)","93a7ece6":"df.show(10)","99852e64":"df.printSchema()","6439dc7f":"from pyspark.sql.types import IntegerType\nfrom pyspark.sql.functions import *\ndf = df.withColumn(\"id\", df[\"id\"].cast(IntegerType()))\ndf = df.withColumn(\"replies\", df[\"replies\"].cast(IntegerType()))\ndf = df.withColumn(\"likes\", df[\"likes\"].cast(IntegerType()))\ndf = df.withColumn(\"retweets\", df[\"retweets\"].cast(IntegerType()))\ndf = df.withColumn(\"timestamp\",to_timestamp(\"timestamp\"))","884fb2e8":"df.printSchema()","d59d9b2c":"like_sort=df.orderBy(col(\"likes\").desc(),col(\"retweets\").desc())","4325922b":"like_sort.select(\"timestamp\",\"likes\",\"retweets\",\"text\").show()","dbd87af3":"common_time=df.groupBy(\"timestamp\").count()","856979e9":"common_time.orderBy(col(\"count\").desc()).where(col('timestamp').isNotNull()).show()","061c0383":"df1=df.withColumn('month',month(\"timestamp\"))","7d04425b":"df1.show()","1540768a":"common_month=df1.groupBy(\"month\").count().orderBy(col(\"month\"))\ncommon_month.where(col('month').isNotNull()).show()","62fd3df5":"common_month_df =common_month.where(col('month').isNotNull()).toPandas()\ncommon_month_df.plot.bar(x='month',y='count',color=['red','royalblue'],rot=0)","7fcf4fa8":"#month_name=['Jan','Feb','Mar','Apr','May','June','July','Aug','Sep','Oct','Nov','Dec']","34e57fdc":"import pyspark.sql.functions as f\nmy_list = common_month.select(f.collect_list('month')).first()[0]","6d7941dd":"my_list","0ab4bce1":"import datetime\nmonth_name=[]\nfor i in my_list:\n    datetime_object = datetime.datetime.strptime(str(i),\"%m\")\n    month_name.append(datetime_object.strftime(\"%B\"))","e49b9c11":"from pyspark.sql.types import StringType\nmonth_df=spark.createDataFrame(month_name, StringType())\n","6dc64fc0":"common_month.withColumn(\"month_name\",month_df.select(\"value\"))","7aa6859d":"**COMMON MONTH**","59c4f225":"**COMMON TIME**","d444ef24":"**FAMOUS TWEETS**"}}