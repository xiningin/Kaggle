{"cell_type":{"07fe8fba":"code","516b8ea0":"code","51b2da15":"code","d68578ea":"code","be105725":"code","3e79cec7":"code","72eda374":"code","16b13ad3":"code","33166c93":"code","bacdb3e6":"code","34849046":"code","9a88b617":"code","65fef07c":"code","996c1ae8":"code","35adbb22":"code","5e4e6c91":"code","08bfd084":"code","b1ed7e72":"code","c9a9f125":"code","6c95062c":"code","6c0db6ac":"code","bb5c3c17":"code","4cfa398d":"code","e2863637":"code","0797385c":"code","17db9acb":"code","1144ec71":"code","f58fd42b":"code","e567baa0":"code","15cae97a":"code","677fcaba":"code","743b8884":"code","2bdcbfc8":"code","e16cb826":"code","e5a8823a":"code","a294c1a3":"code","dedd1b38":"code","78e9951a":"code","5a7f4aa4":"code","9b8c2b46":"code","32336d2d":"code","698590e8":"markdown","112d6c92":"markdown","f80eb806":"markdown","4a33ff44":"markdown","65e76f7d":"markdown","ca0a9e38":"markdown","0b94e8f2":"markdown","5cc1318e":"markdown","f07eeaef":"markdown","4301869d":"markdown","61c96de3":"markdown","4e35fe1e":"markdown","e320b148":"markdown","9da1df49":"markdown","2e33281d":"markdown","65a0bb58":"markdown","d05e4ed3":"markdown","6d224533":"markdown","e7c3c35f":"markdown","83c47ae2":"markdown","b7960e79":"markdown","f458192b":"markdown","43cf5b8b":"markdown","a8d5b8c1":"markdown","cefa29ca":"markdown","0b69792a":"markdown"},"source":{"07fe8fba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","516b8ea0":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","51b2da15":"item_cat=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nitem = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\nsales_train=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nshops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ntest = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')","d68578ea":"item_cat.head()","be105725":"item.head()","3e79cec7":"sales_train.head()","72eda374":"shops.head()","16b13ad3":"test.head()","33166c93":"sales_train.shape","bacdb3e6":"sales_train.info()","34849046":"sales_train[\"date\"]=pd.to_datetime(sales_train[\"date\"])","9a88b617":"sales_train.head()","65fef07c":"import datetime as dt\nsales_train['day'] = sales_train['date'].dt.day\nsales_train['month'] = sales_train[\"date\"].dt.month\nsales_train['year'] = sales_train[\"date\"].dt.year","996c1ae8":"sales_train.head()","35adbb22":"monthly_sales = sales_train.groupby([\"date_block_num\",\"shop_id\",\"item_id\"]).agg({\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\n\nmonthly_sales.head()","5e4e6c91":"allover_sales_by_date = sales_train.groupby([\"date\"])[\"item_cnt_day\"].sum()\nallover_sales_by_date.plot(kind=\"line\",\n                     xlabel=\"Days\",\n                     ylabel=\"Sales\",\n                     title= \"Allover Sales by Date\",\n                     figsize=(26,8));","08bfd084":"mom_sales =  sales_train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\n\nmom_sales.plot(kind=\"line\",\n                     xlabel=\"Days\",\n                     ylabel=\"Sales\",\n                     title= \"Month-over-Month Total Daily Sales\",\n                     figsize=(16,8));","b1ed7e72":"plt.subplot(121)\nmom_sales.rolling(window = 12).mean().plot(figsize=(25,5), \n                                                 color=\"tab:blue\", \n                                                 title=\"Rolling Mean Over 12 Month Period\", \n                                                 legend = True);\nplt.subplot(122)\nmom_sales.rolling(window = 12).std().plot(color=\"tab:orange\", \n                                                title=\"Rolling Variance Over 12 Month Period\", \n                                                legend=True);","c9a9f125":"from statsmodels.tsa.seasonal import seasonal_decompose\n\ndecompose_result = seasonal_decompose(mom_sales, freq=12, model=\"additive\")\ntrend = decompose_result.trend\nseasonal = decompose_result.seasonal\nresidual = decompose_result.resid\n\ndecompose_result.plot();","6c95062c":"from statsmodels.tsa.stattools import adfuller\n\ndef test_stationarity(timeseries):\n    \n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['1.Test Statistic','2.p-value','3.Lags Used','4.Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['5.Critical Value (%s)'%key] = value\n    print (dfoutput)\n\ntest_stationarity(mom_sales)","6c0db6ac":"# create a differencing series to remove trend\n\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return pd.Series(diff)\n","bb5c3c17":"ts=sales_train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,16))\nplt.subplot(311)\nplt.title('Original Time Series')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts)\n\nplt.subplot(312)\nplt.title('After Removing Trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts)\nplt.plot(new_ts)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After Removing Seasonality')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts,12)       # assuming the seasonality is 12 months long\nplt.plot(new_ts)\nplt.plot()","4cfa398d":"# now testing the stationarity again after removing trend and seasonality\n\ntest_stationarity(new_ts)\n","e2863637":"import statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\n\ndef tsplot(y, lags=None, figsize=(10, 8), style='bmh',title=''):\n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n    with plt.style.context(style):    \n        fig = plt.figure(figsize=figsize)\n        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n        layout = (3, 2)\n        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1, 0))\n        pacf_ax = plt.subplot2grid(layout, (1, 1))\n        qq_ax = plt.subplot2grid(layout, (2, 0))\n        pp_ax = plt.subplot2grid(layout, (2, 1))\n        \n        y.plot(ax=ts_ax)\n        ts_ax.set_title(title)\n        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n        sm.qqplot(y, line='s', ax=qq_ax)\n        qq_ax.set_title('QQ Plot')        \n        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n\n        plt.tight_layout()\n    return ","0797385c":"# Simulate an AR(1) process with alpha = 0.6\nnp.random.seed(1)\nn_samples = int(1000)\na = 0.6\nx = w = np.random.normal(size=n_samples)\n\nfor t in range(n_samples):\n    x[t] = a*x[t-1] + w[t]\nlimit=12    \n_ = tsplot(x, lags=limit,title=\"AR(1)process\")","17db9acb":"# Simulate an AR(2) process\n\nn = int(1000)\nalphas = np.array([.444, .333])\nbetas = np.array([0.])\n\n# Python requires us to specify the zero-lag value which is 1\n# Also note that the alphas for the AR model must be negated\n# We also set the betas for the MA equal to 0 for an AR(p) model\n# For more information see the examples at statsmodels.org\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nar2 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \n_ = tsplot(ar2, lags=12,title=\"AR(2) process\")","1144ec71":"# Simulate an MA(1) process\nn = int(1000)\n# set the AR(p) alphas equal to 0\nalphas = np.array([0.])\nbetas = np.array([0.8])\n# add zero-lag and negate alphas\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\nma1 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \nlimit=12\n_ = tsplot(ma1, lags=limit,title=\"MA(1) process\")","f58fd42b":"# Simulate MA(2) process with betas 0.6, 0.4\nn = int(1000)\nalphas = np.array([0.])\nbetas = np.array([0.6, 0.4])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nma3 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n)\n_ = tsplot(ma3, lags=12,title=\"MA(2) process\")","e567baa0":"# Simulate an ARMA(2, 2) model with alphas=[0.5,-0.25] and betas=[0.5,-0.3]\nmax_lag = 12\n\nn = int(5000) # lots of samples to help estimates\nburn = int(n\/10) # number of samples to discard before fit\n\nalphas = np.array([0.8, -0.65])\nbetas = np.array([0.5, -0.7])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\narma22 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n, burnin=burn)\n_ = tsplot(arma22, lags=max_lag,title=\"ARMA(2,2) process\")","15cae97a":"# pick best order by aic \n# smallest aic value wins\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(arma22, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))","677fcaba":"# pick best order by aic \n# smallest aic value wins\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(new_ts.values, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))","743b8884":"# adding the dates to the Time-series as index\nts=sales_train.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.index=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nts=ts.reset_index()\nts.head()","2bdcbfc8":"from fbprophet import Prophet\n#prophet reqiures a pandas df at the below config \n# ( date column named as DS and the value column as Y)\nts.columns=['ds','y']\nmodel = Prophet( yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel.fit(ts) #fit the model with your dataframe","e16cb826":"# predict for five months in the furure and MS - month start is the frequency\nfuture = model.make_future_dataframe(periods = 5, freq = 'MS')  \n# now lets make the forecasts\nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","e5a8823a":"model.plot(forecast)","a294c1a3":"model.plot_components(forecast)","dedd1b38":"total_sales=sales_train.groupby(['date_block_num'])[\"item_cnt_day\"].sum()\ndates=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\n\ntotal_sales.index=dates\ntotal_sales.head()","78e9951a":"monthly_shop_sales=sales_train.groupby([\"date_block_num\",\"shop_id\"])[\"item_cnt_day\"].sum()\n# get the shops to the columns\nmonthly_shop_sales=monthly_shop_sales.unstack(level=1)\nmonthly_shop_sales=monthly_shop_sales.fillna(0)\nmonthly_shop_sales.index=dates\nmonthly_shop_sales=monthly_shop_sales.reset_index()\nmonthly_shop_sales.head()","5a7f4aa4":"import time\nstart_time=time.time()\n\n# Calculating the base forecasts using prophet\n# From HTSprophet pachage -- https:\/\/github.com\/CollinRooney12\/htsprophet\/blob\/master\/htsprophet\/hts.py\nforecastsDict = {}\nfor node in range(len(monthly_shop_sales)):\n    # take the date-column and the col to be forecasted\n    nodeToForecast = pd.concat([monthly_shop_sales.iloc[:,0], monthly_shop_sales.iloc[:, node+1]], axis = 1)\n#     print(nodeToForecast.head())  # just to check\n# rename for prophet compatability\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[0] : 'ds'})\n    nodeToForecast = nodeToForecast.rename(columns = {nodeToForecast.columns[1] : 'y'})\n    growth = 'linear'\n    m = Prophet(growth, yearly_seasonality=True)\n    m.fit(nodeToForecast)\n    future = m.make_future_dataframe(periods = 1, freq = 'MS')\n    forecastsDict[node] = m.predict(future)","9b8c2b46":"#predictions = np.zeros([len(forecastsDict[0].yhat),1]) \nnCols = len(list(forecastsDict.keys()))+1\nfor key in range(0, nCols-1):\n    f1 = np.array(forecastsDict[key].yhat)\n    f2 = f1[:, np.newaxis]\n    if key==0:\n        predictions=f2.copy()\n       # print(predictions.shape)\n    else:\n       predictions = np.concatenate((predictions, f2), axis = 1)","32336d2d":"prediction=predictions[-1]\nprediction","698590e8":"# -IV.PREDICTIVE ANALYSIS \/ FORECASTING- ","112d6c92":"    Now after the transformations, our p-value for the Dickey Fuller Test is within 5 %. So we can assume Stationarity of the series.","f80eb806":"## MA(2) process -- has ACF cut off at lag=2","4a33ff44":"## Middle out:\n\n    Let's predict for the store level","65e76f7d":"# 1. Types of Time-Series\n\nTime-series are of generally two types:\n\n    * Additive Time-Series: Additive time-series is time-series where components (trend, seasonality, noise) are added to generate time series.\n    \n        Time-Series = trend + seasonality + noise\n        \n    * Multiplicative Time-Series: Multiplicative time-series is time-series where components (trend, seasonality, noise) are multiplied to generate time series. One can notice an increase in the amplitude of seasonality in multiplicative time-series.\n    \n        Time-Series = trend * seasonality * noise\n\n\n\n### MoM Total Daily Sales (continous \/ time series)","ca0a9e38":"## Remove Trend and Seasonality\n\n    There are various ways like differencing, power transformation, log transformation, etc. to remove trends from data as we have discussed above. \n    \n    We'll practice differencing.","0b94e8f2":"## AR, MA and ARMA (Autoregressive Moving Average) models:","5cc1318e":"# -III.DATA PREPROCESSING-","f07eeaef":"## Allover Daily Sales","4301869d":"## Prophet:\n\n    Recently open-sourced by Facebook research. It's a very promising tool, that is often a very handy and quick solution to the frustrating flatline.\n    \n    Sure, one could argue that with proper pre-processing and carefully tuning the parameters the above graph would not happen.\n\n    But the truth is that most of us don't either have the patience or the expertise to make it happen.\n\n    Also, there is the fact that in most practical scenarios- there is often a lot of time-series that needs to be predicted. Eg: This competition. It requires us to predict the next month sales for the Store - item level combinations which could be in the thousands.(ie) predict 1000s of parameters!\n\n    Another neat functionality is that it follows the typical sklearn syntax.\n\n    At its core, the Prophet procedure is an additive regression model with four main components:\n\n    A piecewise linear or logistic growth curve trend. Prophet automatically detects changes in trends by selecting changepoints from the data.\n    A yearly seasonal component modeled using Fourier series.\n    A weekly seasonal component using dummy variables.\n    A user-provided list of important holidays.\n\n   Resources for learning more about prophet:\n\n   https:\/\/www.youtube.com\/watch?v=95-HMzxsghY \\\n   https:\/\/facebook.github.io\/prophet\/docs\/quick_start.html#python-api \\\n   https:\/\/research.fb.com\/prophet-forecasting-at-scale\/ \\\n   https:\/\/blog.exploratory.io\/is-prophet-better-than-arima-for-forecasting-time-series-fa9ae08a5851\n","61c96de3":"# -I.DATA UNDERSTANDING-","4e35fe1e":"    The trend and seasonality from Prophet look similar to the ones that we had earlier using the traditional methods.","e320b148":"## AR(2) process -- has ACF tailing out and PACF cutting off at lag=2","9da1df49":"## We've correctly identified the order of the simulated process as ARMA(2,2)\n\n     Lets use it for the sales time-series.","2e33281d":"## AR(1) process -- has ACF tailing out and PACF cutting off at lag=1","65a0bb58":"## MA(1) process -- has ACF cut off at lag=1","d05e4ed3":"### Simply use best_mdl.predict() to predict the next values","6d224533":"# 3. Decompose Time Series To Its Components\n\n    Normally there is 2 decompose model as \"multiplicative\" model and \"additive\" model. We will prefer additive model assessing no multiplative condition in the serie.","e7c3c35f":"# -II.DATA ANALYSIS-","83c47ae2":"## Montly Sales","b7960e79":"It is seen that there is a descending additive trend in mean whereas ascending and increasing multivative trend in variance.","f458192b":"## 4. Stationary Testing with Dicky-Fuller ","43cf5b8b":"# 2. Trend, Seasonality and Stationary\n\n\n## a.Trend:\n\n    The trends represent an increase or decrease in time-series value over time. If we notice that the value of measurement over time is increasing or decreasing then we can say that it has an upward or downward trend.\n    \n    How to remove trend from time-series data?\n\n    There are various ways to de-trend a time series. We have explained a few below.\n\n    1. Log Transformation.\n    2. Power Transformation.\n    3. Local Smoothing - Applying moving window functions to time-series data.\n    4. Differencing a time-series.\n    5. Linear Regression.\n    \n    \n## b.Seasonality:  \n\n    The seasonality represents variations in measured value which repeats over the same time interval regularly. If we notice that particular variations in value are happening every week, month, quarter or half-yearly then we can say that time series has some kind of seasonality.\n    \n    How to remove seasonality from time-series data?\n    \n    Average de-trended values.\n    Differencing a time-series.\n    Use the loess method.\n\n    (There are various ways to remove seasonality. The task of removing seasonality is a bit complicated. We have explained a few ways below to remove seasonality.)\n\n    \n    \n## c.Stationary \n    \n    If there is a upward or downward trend, or multiplative waving condition, or irregular waving trend in time series, it points to a Non-Stationary time serie. \n    To proceed the analysis, we need to convert it to Stationary timeseries.\n    \n    There are multiple tests that can be used to check stationarity as well.\n\n    1. ADF( Augmented Dicky Fuller Test)\n    2. KPSS\n    3. PP (Phillips-Perron test)\n\n    \n\n\n\n- Let's check the trend seasonality and stationarity of our time serie visualizing its mean and standard deviation \n","a8d5b8c1":"## Hierarchical time series:","cefa29ca":"    We can interpret above results based on p-values of result.\n    1. p-value > 0.05 - This implies that time-series is non-stationary.\n    2. p-value <=0.05 - This implies that time-series is stationary\n                \n    Since P-value is greater than 0.05, our time-series is not stationary. It has time-dependent components present that we need to remove.                ","0b69792a":"- Its not very clear\/straight-forward. Let's use a systematic approach to finding the order of AR and MA processes."}}