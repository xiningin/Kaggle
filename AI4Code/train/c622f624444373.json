{"cell_type":{"d154848d":"code","27f73583":"code","5b6ca31c":"code","e7faf083":"code","84f3ca0d":"code","9891a772":"code","a4960e6d":"code","04c86f35":"code","6f8cda07":"code","5606df8c":"code","13c8b464":"code","81822851":"code","58fdfc56":"code","cf0b983a":"code","1dc17b3d":"code","edfc4d3b":"code","450432f0":"code","a5683966":"code","79db24d4":"code","21fe827c":"code","0b5ebb40":"code","82791da9":"code","264d16cc":"code","28eef68e":"code","ef0de65f":"code","72fc0f1f":"code","3f6bc5c6":"code","fa1c5a38":"code","b027651c":"code","bc4a3fd6":"code","0a01ba9b":"code","2f4ede5b":"code","1d57df09":"code","499b283b":"code","7889eae6":"code","d87f4a11":"code","b25e725d":"code","9dca5b23":"code","5717c999":"code","8a977a7d":"code","4e15c04e":"code","4b1aeb88":"code","94727e8c":"code","569492b9":"code","190ad73b":"code","4351b276":"code","d2167fef":"code","099cd8a8":"code","d4d84b60":"code","ae39b374":"code","86b2647c":"markdown","dc4194b9":"markdown","0f7af320":"markdown","9c3ea5c0":"markdown","f6706cf7":"markdown","e6baabe4":"markdown","3832362a":"markdown","6238ad89":"markdown","a3d84ca6":"markdown","d30678b1":"markdown","442e2bdf":"markdown","783fd3cd":"markdown","9b7c4bd1":"markdown","1c17f342":"markdown","9b8cb75b":"markdown","e561fca4":"markdown","79117ac8":"markdown","9fa5fa64":"markdown","7b15e467":"markdown","f321c963":"markdown","c3f5b588":"markdown","bf8a76cb":"markdown","c7b58873":"markdown","7c985eb8":"markdown","835e0eaa":"markdown","899f09fb":"markdown","8c17385e":"markdown","da25c07f":"markdown","32628541":"markdown","f125c98e":"markdown","99ccf442":"markdown","9451c29a":"markdown","27789c24":"markdown","a93b7dd0":"markdown","2cc0e517":"markdown","073c4edc":"markdown"},"source":{"d154848d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\n\n%matplotlib inline","27f73583":"data = pd.read_csv('..\/input\/passenger-list-for-the-estonia-ferry-disaster\/estonia-passenger-list.csv')","5b6ca31c":"data.head()","e7faf083":"data.info()","84f3ca0d":"data.describe()","9891a772":"data.shape","a4960e6d":"data.tail()","04c86f35":"data.Country.unique()","6f8cda07":"data.Sex.unique()","5606df8c":"data.Category.unique()","13c8b464":"data =  data.drop(['Firstname', 'Lastname'], axis = 1)","81822851":"data.head()","58fdfc56":"label = LabelEncoder()\ndata[\"Country\"] = label.fit_transform(data[\"Country\"])\ndata[\"Sex\"] = label.fit_transform(data[\"Sex\"])\ndata[\"Category\"] = label.fit_transform(data[\"Category\"])","cf0b983a":"data.head()","1dc17b3d":"data.hist(figsize = (10, 10))\nplt.show()","edfc4d3b":"print(\"Heatmap\")\nsns.heatmap(data.corr(), center = 0,  annot = True, linewidth = .5)\nplt.show()","450432f0":"X = data.iloc[:, 0:5].values\ny = data.iloc[:, 5].values","a5683966":"sns.countplot(data[\"Survived\"])","79db24d4":"X","21fe827c":"\nprint(\"X array has Shape\", X.shape)\nprint(\"Y array has shape\", y.shape)","0b5ebb40":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom datetime import datetime\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score","82791da9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","264d16cc":"params = {\n    'n_estimators' : [60, 70, 100, 110, 120],\n    'criterion'    : ['gini', 'entropy'],\n    'max_depth'    : [1, 2, 3, 4],\n    'min_samples_split' : [0.1, 0.7, 0.9, 1, 2],\n    'min_samples_leaf' : [0.1, 0.6, 0.9, 1, 2],\n    'min_weight_fraction_leaf' : [0.0, 0.1, 0.2, 0.3, 0.4],\n    'max_features' : ['auto', 'sqrt', 'log2'],\n    'max_leaf_nodes' : [1, 2, 3, 4, 5],\n    'min_impurity_decrease' : [0.1, 0.0, 0.2, 0.3],\n    'bootstrap' : [True, False],\n    'oob_score' : [True, False],\n    'verbose' : [0, 1, 2, 3],\n    'warm_start' : [True, False],\n    'class_weight' : ['balanced', 'balanced_subsample'],\n    'max_samples' : [1, 2, 3, 4, 5]\n}","28eef68e":"def timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))","ef0de65f":"classifier = RandomForestClassifier()","72fc0f1f":"random_search=RandomizedSearchCV(classifier,\n                                 param_distributions=params,\n                                 n_iter=10,\n                                 scoring='roc_auc',\n                                 n_jobs=10,\n                                 cv=7,verbose=3)","3f6bc5c6":"start_time = timer(None) \nrandom_search.fit(X_train,y_train)\ntimer(start_time) ","fa1c5a38":"random_search.best_estimator_","b027651c":"random_search.best_params_","bc4a3fd6":"classifier = RandomForestClassifier(class_weight='balanced_subsample', max_depth=2,\n                       max_leaf_nodes=4, max_samples=2,\n                       min_impurity_decrease=0.3, min_samples_leaf=2,\n                       min_weight_fraction_leaf=0.3, n_estimators=70,\n                       verbose=2)","0a01ba9b":"score=cross_val_score(classifier , X_train, y_train ,cv=10)","2f4ede5b":"score","1d57df09":"score.mean()","499b283b":"classifier.fit(X_train, y_train)","7889eae6":"y_pred = classifier.predict(X_test)","d87f4a11":"f1_score(y_test, y_pred, average='weighted')","b25e725d":"params_decision_tree = {\n    'criterion' : ['gini', 'entropy'],\n    'splitter'  : ['best', 'random'],\n    'max_features' : [0, 1, 2, 3],\n    'min_samples_split' : [2, 3, 4 ,5],\n    'min_samples_leaf' : [1, 2, 3, 4],\n    'random_state' : [0]\n}","9dca5b23":"classifier_decision = DecisionTreeClassifier()","5717c999":"random_search_dt=RandomizedSearchCV(classifier_decision,\n                                 param_distributions=params_decision_tree,\n                                 n_iter=10,\n                                 scoring='roc_auc',\n                                 n_jobs=10,\n                                 cv=7,verbose=3)","8a977a7d":"start_time = timer(None) \nrandom_search_dt.fit(X_train,y_train)\ntimer(start_time) ","4e15c04e":"random_search_dt.best_estimator_","4b1aeb88":"random_search_dt.best_params_","94727e8c":"classifier_decision = DecisionTreeClassifier(criterion='entropy', max_features=2, min_samples_leaf=4,\n                       min_samples_split=4, random_state=0, splitter='random')","569492b9":"score=cross_val_score(classifier_decision , X_train, y_train ,cv=10)","190ad73b":"score","4351b276":"score.mean()","d2167fef":"classifier_decision.fit(X_train, y_train)","099cd8a8":"y_pred_dt = classifier_decision.predict(X_test)","d4d84b60":"y_pred_dt","ae39b374":"f1_score(y_test, y_pred_dt, average='weighted')","86b2647c":"We have to find the F1 score so we have to find the predictions.","dc4194b9":"We can see that there are 989 values or rows and 8 columns. ","0f7af320":"Here we go. Tuning is in progress.","9c3ea5c0":"Looks like our dataset first and then we will decide whether there is a need of preprocessing or not.","f6706cf7":"Just call the classifier and find the accuracy of that.","e6baabe4":"As we need to import some packages. And these packages are very common in use. ","3832362a":"Hey guys, We all know about the Estonia Disaster. The Estonia disaster occurred on Wednesday, 28 September 1994, between about 00:55 and 01:50 (UTC+2). Today we are gonna to discuss about this disaster not the history of that but we are going to discuss on how many persons were alive in this disaster and how many are not. As come this dataset, there are six columns in that :\n* PassengerID\n* Country\n* FirstName\n* LastName\n* Sex\n* Age\n* Category\n* Survived\n\nBy the name of the columns we can easily understand what is the content and type of column. Supoose there is a Country column in that different countries are there from which countries people belonged. Hope you guys have an idea of that what we gonna to do it in that notebook. Right ?","6238ad89":"![](https:\/\/www.dw.com\/image\/49657763_304.jpg)","a3d84ca6":"**Splittion of Dataset into TRAIN and TEST**","d30678b1":"OH ! we finally find it. It is not bad but good.","442e2bdf":"Here is the **List of Parameters**","783fd3cd":"So guys we have to do some preprocessing in it because there are still some categorical variables in this. \n\nSo let's start.","9b7c4bd1":"We have to divide the dataset into its features part and the labelling part. I divide it into X which has all features and y which has labels of the features.","1c17f342":"So now we have gone through the preprocessing part now our dataset is looks like :","9b8cb75b":"By this plot, we can see that most of the people are dead in this disaster and very few people are alive.","e561fca4":"# Estonia | Person: survived or not ?  ","79117ac8":"Now our dataset looks like :","9fa5fa64":"Guys, Info part of data tells clearly about the dataset because it tells about the index, name of column, how many nulls values it have, and the most important part of the columns are its data type. ","7b15e467":"Guys, we are not going to use the library and find its accuarcy because it is very common method we all are used it. In this first I tuned some parameters and then by the tuned classifier we are going to find the accuarcy of that model.","f321c963":"For doing modelling part, we have to do import some essential libraries. In this we are going to use the Random Forest Classifier and find its accuracy and F1 score.","c3f5b588":"So here is the quick look at the dataset and this is just a hist graph but by heatmap we clearly understand which feature has more importances.","bf8a76cb":"OH ! F1 score is high. As we all know if a model have highest F1 scores then it will be supposed to be a good model. So as come to the conclusion part, Decision Tree Classifier is suitable for this dataset than the Ranodm Forest Classifier.","c7b58873":"Hope you like this notebook very much and upvote if you like this please. Till then **Enjoy Machine Learning**","7c985eb8":"So there are five categorical variables our eight. And the name of these :\n* Country\n* Firstname\n* Lastname\n* Age\n* Sex\n* Category\n\n\nCome to making model of predicting a person is survived or not it is clear Firstname and Lastname has no effect on the predictive column.\n\nSo we drop these columns by using drop function. ","835e0eaa":"And the process is same as Random Forest Classifier.","899f09fb":"We have done with RandomForestClassifier and we are looking forward to DecisionTreeClassifier.\nHere is the parameters of Decision Tree Classifier we are going to use random search cv.","8c17385e":"By this dataset, there are 16 countries affected by this disaster and the name of these countries are as following :","da25c07f":"**Use the RandomSearchCV for tuning the classifier**","32628541":"We find the accuracy by **Cross Val Score Method** :","f125c98e":"In the category column of dataset there are two classes i.e P and C. It means\n* P - Passenger\n* C - Crew","99ccf442":"**Best Tuned Parameters** :","9451c29a":"**NOT GOOD BUT STILL OKAY**","27789c24":"By the function **timer** we can see the starting time and end time of tuning parameters.","a93b7dd0":"Now we have done with the decision tree classifier and we find the accuracy scores and then f1 scores.","2cc0e517":"So these are the shape of X and y which explain how many rows we are going to insert in the dataset.","073c4edc":"Oops, 1% loss of accuracy in Decision Tree Classifier. So by looking at accuracy only Random Forest is best than Decision Tree Classifier. But we have to look at F1 scores of Decision Tree."}}