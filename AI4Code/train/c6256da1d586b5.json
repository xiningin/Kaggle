{"cell_type":{"f9e5658b":"code","b7bcd882":"code","994ac051":"code","6d734fe1":"code","bf046505":"code","39269854":"code","1438a105":"code","c93c4135":"code","8f05f4c9":"code","a495ac31":"code","5fd5dfb2":"code","f1d3a506":"code","34c72636":"code","5e4c944d":"code","7446eda4":"code","605f5f0b":"code","97c702e3":"code","4f7f6dd8":"code","efba45c1":"code","4eb84b45":"code","b53af5c1":"code","f2370d55":"code","e8f76c67":"code","6db87c31":"code","216c1bd3":"code","ad4a070d":"code","3783d428":"code","d3c65555":"code","2a1083de":"code","81dac81f":"code","9e3d1bf6":"code","44b0d347":"code","020d6081":"code","142a2cb8":"code","2f875f83":"code","8a35653a":"code","4145fb1b":"code","8669be05":"code","a1d2b1f8":"code","f757a7c5":"code","5c0238f2":"code","46e213ad":"markdown"},"source":{"f9e5658b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b7bcd882":"import math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","994ac051":"# Load the data\n\npassengers = pd.read_csv('..\/input\/train.csv')\npassengers.head()","6d734fe1":"passengers_test = pd.read_csv('..\/input\/test.csv')\npassengers_test.head()","bf046505":"gender_submission = pd.read_csv('..\/input\/gender_submission.csv')\ngender_submission.head()","39269854":"passengers.shape","1438a105":"passengers.info()","c93c4135":"passengers.head()","8f05f4c9":"passengers.describe()","a495ac31":"passengers.corr()","5fd5dfb2":"def correlation_matrix(df):\n   from matplotlib import pyplot as plt\n   from matplotlib import cm as cm\n\n   fig = plt.figure(figsize=(25,12))\n   ax1 = fig.add_subplot(111)\n   cmap = cm.get_cmap('binary', 30)\n   cax = ax1.imshow(df.corr(), interpolation=\"nearest\", cmap=cmap)\n   ax1.grid(True)\n   plt.title('Feature Correlation')\n   labels=list(df.columns)\n   #ax1.set_xticklabels(labels,fontsize=5)\n   #ax1.set_yticklabels(labels,fontsize=5)\n   # Add colorbar, make sure to specify tick locations to match desired ticklabels\n   fig.colorbar(cax, ticks=[.75,.8,.85,.90,.95,1])\n   plt.show()\n\ncorrelation_matrix(passengers) # Good to see the current numeric features are not too correlated","f1d3a506":"# Fill the nan values in the age column\nprint(passengers['Age'].values)\n\n","34c72636":"#Calculate the percentage of entries with nan age in the entries with ground truth label of \"not-survived\".\n\nnumber_nan_age = passengers['Age'].isna().sum()\nprint(number_nan_age\/len(passengers['Age']))\n","5e4c944d":"\nprint(passengers.isnull().sum())\n","7446eda4":"# Fill the nan values with the average of that column for some other features\n\ndef preprocessing(passengers):\n    \n    passengers['Age_old'] = passengers['Age']\n    \n    passengers['Age'].fillna(value = passengers.Age.mean(), inplace = True) #\n    \n    #passengers['Sex'] = passengers['Sex'].apply(lambda x: 1 if x=='male' else 0)\n    passengers['Sex'] = passengers['Sex'].map({\"male\":1, \"female\":0})\n    \n    passengers['Cabin_old'] = passengers['Cabin']\n\n    #mean_SibSp = passengers.SibSp.mean()\n    \n    #passengers['SibSp'].fillna(value = mean_SibSp, inplace = True)\n\n    #mean_Parch = passengers.Parch.mean()\n    #passengers['Parch'].fillna(value = mean_Parch, inplace = True)\n\n    mean_Fare = passengers.Fare.mean()\n    passengers['Fare'].fillna(value = mean_Fare, inplace = True)\n\n    # Create a Upper column\n    passengers['Upper'] = passengers['Pclass'].apply(lambda x: 1 if x==1 else 0)\n\n    # Create a Middle column\n    passengers['Middle'] = passengers['Pclass'].apply(lambda x: 1 if x==2 else 0)\n\n    # Create a Lower column\n    passengers['Lower'] = passengers['Pclass'].apply(lambda x: 1 if x==3 else 0)\n\n    # Create a Have_Age column\n    passengers['Have_Age'] = passengers['Age_old'].isnull().apply(lambda x: 1 if not x else 0)\n\n    # Create a Have_Cabin column\n    passengers['Have_Cabin'] = passengers['Cabin'].isnull().apply(lambda x: 1 if not x else 0)\n    \n    return passengers\n\npassengers = preprocessing(passengers)\n","605f5f0b":"passengers.head()","97c702e3":"passengers.describe()","4f7f6dd8":"correlation_matrix(passengers)","efba45c1":"print(passengers.isna().sum())","4eb84b45":"print(passengers['Have_Cabin'].sum())","b53af5c1":"# Select the desired features\nselected_features = ['Have_Age',  'Have_Cabin', 'Sex', 'Parch', 'Fare', 'Middle',  'Upper', 'Lower', 'SibSp',  'Age'] #,\n\n\n# Select the desired features\nfeatures = passengers[selected_features]\nsurvival = passengers['Survived']","f2370d55":"print(\"{percentage}% of total passengers in test data don't survive!!!\".format(percentage=(len(survival)-survival.sum())\/len(survival)))","e8f76c67":"cnt=0\nfor i in range(len(passengers['Survived'])):\n    if passengers['Age_old'].isnull()[i] and passengers['Survived'][i]==0:\n        cnt +=1\nprint(\"{percentage}% of total passengers in test data BOTH don't have age information AND don't survive!!!\".format(percentage=100*cnt\/len(passengers['Survived']))) #14%\nprint(\"{percentage}% of non-survived passengers don't have age information!!!\".format(percentage=100*cnt\/(len(survival)-survival.sum())))","6db87c31":"cnt=0\nfor i in range(len(passengers['Survived'])):\n    if passengers['Cabin_old'].isnull()[i] and passengers['Survived'][i]==0:\n        cnt +=1\nprint(\"{percentage}% of total passengers in test data BOTH don't have cabin information AND don't survive!!!\".format(percentage=100*cnt\/len(passengers['Survived']))) #14%\nprint(\"{percentage}% of non-survived passengers don't have cabin information!!!\".format(percentage=100*cnt\/(len(survival)-survival.sum())))","216c1bd3":"# Perform train, test, split\n\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, survival, train_size = 0.25)\n\n# Scale the feature data so it has mean = 0 and standard deviation = 1\nnormalize = StandardScaler()\ntrain_features = normalize.fit_transform(train_features)\ntest_features = normalize.transform(test_features)\n\n# Create and train the model\nmodel = LogisticRegression(random_state=200, solver='saga', max_iter=1000)\nmodel.fit(train_features, train_labels)\n\n# Score the model \nprint(\"Score on the training data is {score_train} and score on the test data is {score_test} \".\n      format(score_train=model.score(train_features, train_labels), score_test=model.score(test_features, test_labels)))\n\n","ad4a070d":"# Analyze the coefficients\n\nprint(model.coef_)\nprint(list(zip(selected_features, model.coef_[0])))\n\nplt.figure(figsize=(15,12))\nplt.bar(selected_features,  model.coef_[0])\nplt.xlabel(\"feature\")\nplt.ylabel(\"model coefficient\")\nplt.title(\"Impacts of different features in our model\")\nplt.show()\n","3783d428":"# Process test data\n\n# Update sex column to numerical\n\npassengers_test","d3c65555":"passengers_test=preprocessing(passengers_test)\n\n# Select the desired features\nfeatures_test = passengers_test[selected_features]\n\n\npassengers_test.isnull().sum()","2a1083de":"features_test = normalize.transform(np.array(features_test)) \nprint(features_test)","81dac81f":"my_predict_survival = model.predict(features_test)\n\nprint(my_predict_survival)\n\n","9e3d1bf6":"print(model.predict_proba(features_test))","44b0d347":"import xgboost as xgb\n\nX=train_features\ny=train_labels\n\n#Decision trees as base learners\n# Create the training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n\n# Instantiate the XGBRegressor: xg_reg\nxg_reg = xgb.XGBClassifier(n_estimators=1000, seed=123, objective=\"binary:logistic\",booster=\"gbtree\", n_jobs=10)\n\n# Fit the regressor to the training set\nxg_reg.fit(X_train, y_train)\n\n# Predict the labels of the test set: preds\npreds = xg_reg.predict(X_test)\n\n\n#Evaluating model quality\n\n# Create the DMatrix\ndmatrix = xgb.DMatrix(data=X_test, label=y_test)\n\n# Create the parameter dictionary: params\nparams = {\"objective\":\"reg:logistic\", \"max_depth\":4}\n\n# Perform cross-validation: cv_results\ncv_results = xgb.cv(dtrain=dmatrix, params=params, nfold=5, num_boost_round=50, metrics=\"error\", as_pandas=True, seed=123)\n\n# Print cv_results\nprint(cv_results)\n\n# Extract and print final boosting round metric\nprint((cv_results[\"test-error-mean\"]).tail(1))\nprint(\"accuracy:\", 1-(cv_results[\"test-error-mean\"]).tail(1)) \n\n\n","020d6081":"# Plot the tree\nxgb.plot_tree(xg_reg)\nplt.show()\n","142a2cb8":"# Plot the feature importances\nxgb.plot_importance(xg_reg)\nplt.show()","2f875f83":"# Predict the labels of the unknown set: preds_unknown\npreds_unknown = xg_reg.predict(features_test)\n\nnp.array(preds_unknown)","8a35653a":"my_predict_survival","4145fb1b":"my_submission = [('PassengerId', list(gender_submission.PassengerId)),\n         ('Survived', list(my_predict_survival)),\n         ]\nmy_submission = pd.DataFrame.from_items(my_submission)\n\n\nmy_submission_xgb = [('PassengerId', list(gender_submission.PassengerId)),\n         ('Survived', list(np.array(preds_unknown))),\n         ]\nmy_submission_xgb = pd.DataFrame.from_items(my_submission_xgb)\n","8669be05":"\nmy_submission","a1d2b1f8":"my_submission_xgb","f757a7c5":"my_submission.to_csv('my_submission.csv', index= False, header=True)\nmy_submission_xgb.to_csv('my_submission_xgb.csv', index= False, header=True)","5c0238f2":"#Future work: Include other features such as embark location.","46e213ad":"**This notebook, as a simple benchmark submission for the Titanic competition, was originally for a course project to create a Logistic Regression model that predicts which passengers survived the sinking of the Titanic, based on features like age and class. In my official submission that achieves my highest score in the LeaderBoard, more advanced models and methods have been investigated, which will not be made public until the competition officially ends.**"}}