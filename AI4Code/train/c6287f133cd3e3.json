{"cell_type":{"9be6f011":"code","f8349d15":"code","241a8728":"code","2279f007":"code","21edc378":"code","edda32cc":"code","491448f4":"code","0bdad851":"code","a0fe9af2":"code","02f347c4":"code","e87468b3":"code","7ae18c78":"code","85ad5838":"code","4605aa8a":"code","c8f00214":"code","a4704992":"code","e9142003":"code","633c5148":"code","ed22b50b":"code","c35efa1a":"code","c49685b7":"code","f2ee2a08":"code","ca4c9483":"code","6ca7d4cb":"code","23a69f99":"code","4ee2abdb":"code","4f75366f":"code","fe0f1492":"code","99bc1d18":"code","0c265bf6":"code","fa86b50c":"code","9e3db9bc":"code","89b04eb8":"code","89fef0c6":"code","b8fab7cb":"code","3de51223":"code","b8bc521a":"code","04c795ae":"code","5927b38b":"markdown","7570bac4":"markdown","bbc49dad":"markdown","a27759b1":"markdown","019e3db4":"markdown","2ea46d4d":"markdown","aa2a2251":"markdown","d62b8738":"markdown"},"source":{"9be6f011":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","f8349d15":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import LeakyReLU\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport matplotlib.pyplot as plt ","241a8728":"train = pd.read_csv('\/kaggle\/input\/Kannada-MNIST\/train.csv')\ntest = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/test.csv\")\nDig_MNIST = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/Dig-MNIST.csv\")","2279f007":"sample_sub = pd.read_csv(\"\/kaggle\/input\/Kannada-MNIST\/sample_submission.csv\")","21edc378":"print(\"Train set shape = \" +str(train.shape))\nprint(\"Test set shape = \" +str(test.shape))\nprint(\"Dif set shape = \" +str(Dig_MNIST.shape))","edda32cc":"train.head()","491448f4":"X=train.iloc[:,1:].values \nY=train.iloc[:,0].values \nY[:10]","0bdad851":"X = X.reshape(X.shape[0], 28, 28,1) \nprint(X.shape)\n","a0fe9af2":"Y = keras.utils.to_categorical(Y, 10) \nprint(Y.shape)","02f347c4":"test.head()","e87468b3":"x_test=test.drop('id', axis=1).iloc[:,:].values\nx_test = x_test.reshape(x_test.shape[0], 28, 28,1)\nx_test.shape","7ae18c78":"Dig_MNIST.head()","85ad5838":"x_dig=Dig_MNIST.drop('label',axis=1).iloc[:,:].values\nprint(x_dig.shape)\nx_dig = x_dig.reshape(x_dig.shape[0], 28, 28,1)\nx_dig.shape","4605aa8a":"y_dig=Dig_MNIST.label\ny_dig.shape","c8f00214":"X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size = 0.10, random_state=42) ","a4704992":"train_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 10,\n                                   width_shift_range = 0.25,\n                                   height_shift_range = 0.25,\n                                   shear_range = 0.1,\n                                   zoom_range = 0.25,\n                                   horizontal_flip = False)","e9142003":"valid_datagen = ImageDataGenerator(rescale=1.\/255) ","633c5148":"def lr_decay(epoch):#lrv\n    return initial_learningrate * 0.99 ** epoch","ed22b50b":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n    tf.keras.layers.BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),    \n    \n    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n \n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\nmodel.summary()","c35efa1a":"initial_learningrate=2e-3\nbatch_size = 1024\nepochs = 50\ninput_shape = (28, 28, 1)","c49685b7":"es = EarlyStopping(monitor='val_loss', verbose=1, patience=10)","f2ee2a08":"model.compile(loss=\"categorical_crossentropy\",\n              optimizer=RMSprop(lr=initial_learningrate),\n              metrics=['accuracy'])","ca4c9483":"from sklearn import metrics\n","6ca7d4cb":"history = model.fit_generator(\n      train_datagen.flow(X_train,Y_train, batch_size=batch_size),\n      steps_per_epoch=100,\n      epochs=epochs,\n      callbacks=[LearningRateScheduler(lr_decay),\n                 es\n               ],\n      validation_data=valid_datagen.flow(X_valid,Y_valid),\n      validation_steps=50,  \n      verbose=2)","23a69f99":"preds_dig=model.predict_classes(x_dig\/255)\nmetrics.accuracy_score(preds_dig, y_dig)","4ee2abdb":"accuracy = history.history['acc']\nval_accuracy = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Test accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","4f75366f":"plt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Test loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","fe0f1492":"keras.backend.clear_session()","99bc1d18":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(28, 28, 1)),\n    tf.keras.layers.BatchNormalization(momentum=0.5, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Conv2D(64,  (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),    \n    \n    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.1, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n\n    \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n","0c265bf6":"initial_learningrate=2e-3\nbatch_size = 1024\nepochs = 50\ninput_shape = (28, 28, 1)","fa86b50c":"model.compile(loss=\"categorical_crossentropy\",\n              optimizer=RMSprop(lr=initial_learningrate),\n              metrics=['accuracy'])","9e3db9bc":"history = model.fit_generator(\n      train_datagen.flow(X,Y, batch_size=batch_size),\n      steps_per_epoch=100,\n      epochs=epochs,\n      callbacks=[LearningRateScheduler(lr_decay)           \n               ],\n      validation_data=valid_datagen.flow(X_valid,Y_valid),\n      validation_steps=50,  \n      verbose=2)","89b04eb8":"preds_dig=model.predict_classes(x_dig\/255)\nmetrics.accuracy_score(preds_dig, y_dig)","89fef0c6":"predictions = model.predict_classes(x_test\/255.)","b8fab7cb":"submission = pd.read_csv('..\/input\/Kannada-MNIST\/sample_submission.csv')","3de51223":"submission['label'] = predictions","b8bc521a":"submission.head()","04c795ae":"submission.to_csv(\"submission.csv\",index=False)","5927b38b":"Let's fit the model on the whole training set.","7570bac4":"We split the data into training and validation set.","bbc49dad":"We slice the dataframes to define the features and the labels","a27759b1":"Let's load the data.","019e3db4":"Now we convert the labels to categorical.","2ea46d4d":"The next function reduces the learning rate as the training advances.","aa2a2251":"Now we must reshape the date to make it Keras friendly.","d62b8738":"We use Keras ImageDataGenerator to artificially increase our training set."}}