{"cell_type":{"39f4dc0d":"code","4773d28b":"code","03fa868b":"code","f7beb9dd":"code","485bf7e5":"code","9db966bd":"code","f7aa2aa9":"markdown","1258ecc0":"markdown","9a4341cc":"markdown","0ba92494":"markdown","76922195":"markdown","140840b2":"markdown","90863637":"markdown","68c27889":"markdown","3e1c6eb6":"markdown"},"source":{"39f4dc0d":"!pip install -qq torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html\n!pip install -qq --upgrade wandb timm==0.3.2 six tensorboardX","4773d28b":"!git clone https:\/\/github.com\/facebookresearch\/ConvNeXt","03fa868b":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"WANDB_KEY\")\n    wandb.login(key=secret_value_0)\nexcept:\n    print('To use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https:\/\/wandb.ai\/authorize')","f7beb9dd":"path_to_dataset = '..\/..\/input\/happywhale-train-by-class\/train_images_by_class'","485bf7e5":"%cd ConvNeXt\/\n!wget https:\/\/dl.fbaipublicfiles.com\/convnext\/convnext_tiny_1k_224_ema.pth","9db966bd":"!python main.py --epochs 10 \\\n                --model convnext_tiny \\\n                --data_set image_folder \\\n                --data_path ..\/..\/input\/happywhale-train-by-class\/train_images_by_class\/ \\\n                --disable_eval true \\\n                --nb_classes 30 \\\n                --num_workers 8 \\\n                --warmup_epochs 0 \\\n                --save_ckpt true \\\n                --output_dir model_ckpt \\\n                --finetune convnext_tiny_1k_224_ema.pth \\\n                --cutmix 0 \\\n                --mixup 0 --lr 4e-4 \\\n                --enable_wandb true --wandb_ckpt true --project happywhale_convnext","f7aa2aa9":"# \ud83c\udfc0 Download the Dataset\n\nTo finetune on any custom dataset the format of the dataset should be as shown below:\n\n```\n\/path\/to\/dataset\/\n  train\/\n    class1\/\n      img1.jpeg\n    class2\/\n      img2.jpeg\n  val\/\n    class1\/\n      img3.jpeg\n    class2\/\n      img4.jpeg\n```\n\nI have created the dataset for you all: https:\/\/www.kaggle.com\/ayuraj\/happywhale-train-by-class","1258ecc0":"> Note: We ain't using any validation set in this example. We will thus finetune only for 10 epochs. You can use this notebook and train with a validation set as well.","9a4341cc":"Install Weights and Biases for experiment tracking. ","0ba92494":"Use this notebook to finetune a ConvNeXt-tiny model on this competition dataset. The [official ConvNeXt repository](https:\/\/github.com\/facebookresearch\/ConvNeXt) is instrumented with [Weights and Biases](https:\/\/wandb.ai\/site). You can now easily log your train\/test metrics and version control your model checkpoints to Weigths and Biases.\n\n**The trained model checkpoint can be used to extract image embeddings.** ","76922195":"# \ud83c\udfd0 Conclusion\n\n* The ConvNeXt repository comes with modern training regimes and is easy to finetune on any dataset. \n* The finetune model should learn good image features.. \n\nI have also created this [colab notebook](https:\/\/colab.research.google.com\/drive\/1ijAxGthE9RENJJQRO17v9A7PTd1Tei9F?usp=sharing) to finetune on CIFAR-10 dataset.","140840b2":"Download the official ConvNeXt respository. ","90863637":"# \ud83c\udfbe Train with Weights and Biases\n\nIf you want to log the train and evaluation metrics using Weights and Biases pass `--enable_wandb true`. \n\nYou can also save the finetuned checkpoints as version controlled W&B [Artifacts](https:\/\/docs.wandb.ai\/guides\/artifacts) if you pass `--wandb_ckpt true`.\n\nIf you want to pass a directory of validation images use the argument `--eval_data_path`. \n","68c27889":"# \u26bd\ufe0f Installation and Setup\n\nThe following installation instruction is based on [INSTALL.md](https:\/\/github.com\/facebookresearch\/ConvNeXt\/blob\/main\/INSTALL.md) provided by the official ConvNeXt repository. ","3e1c6eb6":"# \ud83c\udfc8 Download Pretrained Weights\n\nWe will be finetuning the ConvNeXt Tiny model pretrained on ImageNet 1K dataset."}}