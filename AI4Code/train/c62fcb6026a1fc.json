{"cell_type":{"8b617e84":"code","0e73e167":"code","afd9ec75":"code","78a167fd":"code","db428fbb":"code","9b4de41f":"code","4ec4eef2":"code","adcb6561":"code","9ff79b3e":"code","0c010419":"code","9d1bec3c":"code","21cafbb1":"code","925ed65b":"code","13ecb64a":"code","36b18df0":"code","91e8acf0":"code","8254d3b3":"code","37c751fe":"code","9f67b2a4":"code","c90b0630":"code","ec0cddc3":"code","1f52b08a":"code","9570514c":"code","6cc82153":"code","93208223":"code","7a15a705":"code","46613020":"code","1749d13b":"code","a671bf3a":"code","d3962077":"code","9377eb2d":"code","317e9fef":"code","062139fd":"code","f2e340a4":"code","e83d9f65":"markdown","fd4f87c1":"markdown","2646eede":"markdown","b5c05417":"markdown","f1a38e92":"markdown","85da04e3":"markdown","7fb1d4e9":"markdown","fd7f85a8":"markdown","2be9ac7f":"markdown","a666d064":"markdown","51675586":"markdown","40757669":"markdown","7bdc98f6":"markdown","9a47660b":"markdown","311cdf8b":"markdown","59cca5a1":"markdown","f2f17a98":"markdown","71de8cc8":"markdown","e20bab09":"markdown","f4ab6b2d":"markdown"},"source":{"8b617e84":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e73e167":"df = pd.read_csv(\"..\/input\/airpressure\/Folds5x2_pp.csv\")\ndf.head()","afd9ec75":"df.rename(columns={'AT': 'Average Temperature', 'V': 'Exhaust Vacuum','AP': 'Ambient Pressure',\n                   'RH': 'Relative Humidity ','PE': 'Net Hourly Electrical Energy Output'}, inplace=True)\ndf.head()","78a167fd":"df.isnull().sum()","db428fbb":"df.info()","9b4de41f":"df.describe()","4ec4eef2":"df.corr()[\"Net Hourly Electrical Energy Output\"].sort_values(ascending=False)","adcb6561":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(12,10))\nmask = np.zeros_like(df.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(data=df.corr(), cmap=\"jet\", annot=True,linewidths=1, linecolor='white',mask=mask)","9ff79b3e":"sns.set_style(\"darkgrid\")","0c010419":"plt.figure(figsize=(12,10))\nsns.histplot(data=df,x=\"Net Hourly Electrical Energy Output\",color=\"red\",kde=True)\nplt.axvline(x=df[\"Net Hourly Electrical Energy Output\"].mean(),ymax=0.55,color=\"green\",linestyle='--',label=\"Mean\")\nplt.axvline(x=df[\"Net Hourly Electrical Energy Output\"].median(),ymax=0.56,color=\"purple\",linestyle='--',label=\"Median\")\nplt.legend()\nplt.title(\"Histogram of the Target Column\")","9d1bec3c":"plt.figure(figsize = (12,10))\nsns.histplot(df[\"Net Hourly Electrical Energy Output\"],kde=True,bins=40,color=\"red\",cumulative=True)\nplt.title(\"Cumulative of the Target Column\")","21cafbb1":"sns.pairplot(df,\n                 markers=\"+\",\n                 kind='reg',\n                 diag_kind=\"auto\",\n                 plot_kws={'line_kws':{'color':'#aec6cf'},\n                           'scatter_kws': {'alpha': 0.5,\n                                           'color': '#82ad32'}},\n               \n                 diag_kws= {'color': '#82ad32'})","925ed65b":"sns.pairplot(df,\n                 markers=\"+\",\n                 kind='reg',\n                 diag_kind=\"kde\",\n                 plot_kws={'line_kws':{'color':'#aec6cf'},\n                           'scatter_kws': {'alpha': 0.5,\n                                           'color': '#82ad32'}},\n               corner=True,\n                 diag_kws= {'color': '#82ad32'})","13ecb64a":"plt.figure(figsize = (15,10))\nsns.regplot(data=df, x=\"Average Temperature\", y=\"Net Hourly Electrical Energy Output\",color=\"red\")","36b18df0":"plt.figure(figsize = (15,10))\nsns.regplot(data=df, x=\"Exhaust Vacuum\", y=\"Net Hourly Electrical Energy Output\",color=\"orange\")","91e8acf0":"plt.figure(figsize = (15,10))\nsns.regplot(data=df, x=\"Ambient Pressure\", y=\"Net Hourly Electrical Energy Output\",color=\"purple\")","8254d3b3":"X = df.drop(\"Net Hourly Electrical Energy Output\", axis=1).values\ny = df[\"Net Hourly Electrical Energy Output\"].values\nprint(X)\nprint(y)","37c751fe":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","9f67b2a4":"from sklearn.preprocessing import StandardScaler\nss = StandardScaler()\nX_train = ss.fit_transform(X_train)\nX_test = ss.transform(X_test)\nprint(X_train)\nprint(X_test)","c90b0630":"plt.figure(figsize=(12,10))\nplt.imshow(plt.imread(\"..\/input\/aritificialneural-network\/ann.png\"))","ec0cddc3":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping","1f52b08a":"ann = Sequential()                          # Initializing the ANN\nann.add(Dense(units=6, activation=\"relu\"))  #Adding First Hidden Layer\nann.add(Dense(units=6, activation=\"relu\"))  # Adding Second Hidden Layer\nann.add(Dense(units=1))   # Adding Output Layer\n#If we make a regression with neural networks, we do not need to add an activation function compared to classification problems","9570514c":"ann.compile(optimizer=\"adam\",loss=\"mean_squared_error\")","6cc82153":"ann.fit(x=X_train, y=y_train, epochs=100, batch_size=32,validation_data=(X_test,y_test),callbacks=EarlyStopping(monitor='val_loss',patience=4))","93208223":"pd.DataFrame(ann.history.history)","7a15a705":"plt.style.use(\"ggplot\")\npd.DataFrame(ann.history.history).plot(figsize=(12,10))","46613020":"ann.evaluate(X_train,y_train)","1749d13b":"ann.evaluate(X_test,y_test)","a671bf3a":"predictions = ann.predict(X_test)\npredictions_df = pd.DataFrame(np.ravel(predictions),columns=[\"Predictions\"])\ncomparison_df = pd.concat([pd.DataFrame(y_test,columns=[\"Real Values\"]), predictions_df],axis=1)\ncomparison_df ","d3962077":"print(y_test.shape)       # The actual values are 1D arrays\nprint(predictions.shape)  # The predictions are 2D arrays","9377eb2d":"# here I will visualize the real test values(y_test) versus the predicted values.\nplt.figure(figsize=(12,10))\nsns.scatterplot(np.ravel(predictions),y_test)\nplt.title(\"The Scatterplot of Relationship between Actual Values and Predictions\")\nplt.xlabel(\"Predictions\")\nplt.ylabel(\"Actual Values\")\n#It seems that our model predicts very well","317e9fef":"# We will evaluate our model performance by calculating the residual sum of squares and the explained variance score\nfrom sklearn import metrics\nprint(\"MAE:\",metrics.mean_absolute_error(y_test,predictions))\nprint (\"MSE:\",metrics.mean_squared_error(y_test,predictions))\nprint(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test,predictions)))","062139fd":"#Evaluation of  the explained variance score (R^2)\nmetrics.explained_variance_score(y_test,predictions) #This shows our model predict %93 of the target correctly","f2e340a4":"#Now we will visualize the differences between our predictions and actual y test data\nplt.figure(figsize=(12,10))\nsns.distplot(y_test-predictions,bins=50) #this figure also proves that our model fits very good\n#There is no huge differences between our predictions and actual y data","e83d9f65":"## 2.1. Preparing the Data for the Model","fd4f87c1":"<font color=\"green\">\nThe Mean Absolute Error is just 3.6 which is so small which shows that the model is almost as the actual values.","2646eede":"<font color=\"green\">\nAs seen above there is strong positive correlation between Net Hourly Electrical Energy Output and Ambient Pressure while very strong negative correlation between Net Hourly Electrical Energy Output and Average Temperature or Exhaust Vacuum. Lets visualize this correlation with seaborn heatmap below:","b5c05417":"## 3.MAKING PREDICTIONS AND EVALUATING THE MODEL PERFORMANCE","f1a38e92":"## 2.PREPARING AND TRAINING THE MODEL","85da04e3":"<font color=\"green\">\nAs seen in the figure above, our deep learning model performs very well.","7fb1d4e9":"<font color=\"green\">\nThe dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Average Temperature (AT), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP) of the plant.\nA combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, he other three of the ambient variables effect the GT performance.\nFor comparability with our baseline studies, and to allow 5x2 fold statistical tests be carried out, we provide the data shuffled five times. For each shuffling 2-fold CV is carried out and the resulting 10 measurements are used for statistical testing.\nWe provide the data both in .ods and in .xlsx formats.\n\n\nAttribute Information:\n\nFeatures consist of hourly average ambient variables\n- Temperature (T) in the range 1.81\u00b0C and 37.11\u00b0C,\n- Ambient Pressure (AP) in the range 992.89-1033.30 milibar,\n- Relative Humidity (RH) in the range 25.56% to 100.16%\n- Exhaust Vacuum (V) in teh range 25.36-81.56 cm Hg\n- Net hourly electrical energy output (EP) 420.26-495.76 MW\nThe averages are taken from various sensors located around the plant that record the ambient variables every second. The variables are given without normalization.\nLets change the column names with its more understandable fashion as follows:","fd7f85a8":"## 2.2. Building and Training the Neural Network Model","2be9ac7f":"<font color=\"green\">\nCompiling and Training the ANN:","a666d064":"<font color=\"green\">\nInitializing the ANN and Adding Layers:","51675586":"<font color=\"green\">\nThis is the visual representation of the artificial neural networks we will build:","40757669":"<font color=\"green\">\nWe can see all the statistical information for all features and the target column below:","7bdc98f6":"<font color=\"green\">\nAll the values are numerical and continuous values,so there is not need to transform the data into numerical values as seen below:","9a47660b":"<font color=\"green\">\nAs seen above in the comparison dataframe, the predictions of the model is very close to the actual values.","311cdf8b":"<font color=\"green\">\nWe need to make feature scaling before feeding the data to artificial neural networks","59cca5a1":"## 1. EXPLORATORY DATA ANALYSIS","f2f17a98":"## 1.1. Dealing With the Missing Values:","71de8cc8":"## 1.1. Descriptive Statistical Data Analysis","e20bab09":"## 1.2.Data Visualization","f4ab6b2d":"<font color=\"green\">\nThere is no any missing value in the data set as seen below:"}}