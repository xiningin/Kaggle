{"cell_type":{"d484a845":"code","357e020a":"code","6ddb41d2":"code","e86618da":"code","385aa66a":"code","cfdf882a":"code","2707f43a":"code","58271ea3":"code","4f2f55c0":"code","5dfd6465":"code","c8c40134":"code","384bae12":"code","dc6c898d":"code","c22b080a":"code","93968bf9":"code","5acc86a8":"code","78a68196":"code","da012056":"code","700fcf40":"code","3162e65b":"code","6669e9de":"code","8cf2057e":"code","8957e026":"code","dab4df10":"code","bd838e2d":"code","04285c9e":"code","1977bf5d":"code","930ad6c7":"code","7ee73311":"code","acb5c352":"code","0535665f":"code","89c022f1":"code","6cab27db":"code","69e64216":"code","eab7ac6c":"code","f42112c8":"code","b67d842b":"code","a0d5bf07":"code","0e44d0b9":"code","f7d24e48":"code","a43e2074":"code","31e746dd":"code","e1c1b216":"code","8f3fa626":"code","acc28d84":"code","a0d0fce7":"code","3592a26e":"code","43a32417":"code","77af890e":"code","0ab56949":"code","2ae3c635":"code","5a2544e2":"code","1c4bc8c6":"code","c4b6cbd5":"code","00c12960":"code","3dd2c3e0":"code","af9c0733":"code","2b1b9f91":"code","e0237135":"code","f5ab9f40":"code","def7e636":"code","3b509da7":"code","95d09af7":"code","e1886923":"code","a4bf4607":"code","86993d9f":"code","5aa3f978":"markdown","13d17c6a":"markdown","a0eb745b":"markdown","cd04e2d2":"markdown","4f31ffdc":"markdown","91f66c35":"markdown","463c5f77":"markdown","3316d92b":"markdown","4b952046":"markdown","09ee4acf":"markdown","9b5ef851":"markdown","04c7c88a":"markdown","5ceeb6d8":"markdown","af1d7f55":"markdown"},"source":{"d484a845":"import pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nfrom timeit import default_timer as timer\n%matplotlib inline","357e020a":"import seaborn as sns\nsns.set(rc={'figure.figsize':(11, 4)})\n\n#pandas option to display all columns\npd.set_option('max_columns',None)","6ddb41d2":"#Read the data files\ntrain_df=pd.read_csv('..\/input\/train.csv')\ntrain_df.head()","e86618da":"#Read the test dataset\ntest_df=pd.read_csv('..\/input\/test.csv')\ntest_df.head()","385aa66a":"#Check if there are any nulls\ntrain_df.isnull().sum(axis=0) >0","cfdf882a":"train_df.describe()","2707f43a":"#define a function to draw the image\n#x-> dataframe with data\n#y-> dataframe with labels\ndef draw_digit(x,y, label='Actual'):\n    plt.figure(figsize=(20,5))\n    #check the length of input dataset and divide by 8 to print 10 digits on each line\n    nrows=(len(x)\/\/10)+1\n    #ncols=(len(x)%10)\n    ncols=10\n    print('Lenght of input: {}, nrows: {}, ncols: {}, label: {}'.format(len(x), nrows, ncols, y.shape))\n    #print(x.shape)\n    #iterate over all the digits passed in the array\n   \n    for idx,i in enumerate(x.index):\n        #loop to iterate over blocks of 10 digits            \n            plt.subplot(nrows,10,idx+1)  #subplots start with 1\n            plt.subplots_adjust(top=1.3)\n            plt.imshow(x.loc[i].values.reshape(28,28), cmap=plt.cm.gray, interpolation='nearest',clim=(0, 255))\n            plt.title(label+' %i\\n' % y.iloc[idx,:].values, fontsize = 11)\n            #plt.title('Actual {}\\n'.format(y.iloc[idx,:].values), fontsize = 11)\n           \n    plt.show()","58271ea3":"#Display image of digits\ndraw_digit(train_df.iloc[:15,1:], train_df.iloc[:15,:1],'Actual')","4f2f55c0":"#check the distribution of dataset labels\nsns.countplot(train_df['label'], palette='viridis')\n","5dfd6465":"import random\nsubset_percent=25","c8c40134":"#np.floor(len(digi_df)*21\/100), len(digi_df)*21\/100\n#list(digi_df.index)\nint(len(train_df)*subset_percent\/100)","384bae12":"print ('Sampling {}% of training, Labels and test data'.format(subset_percent))\ntrain_idx=random.sample(list(train_df.index),int(len(train_df)*subset_percent\/100))\ntest_idx=random.sample(list(test_df.index),int(len(test_df)*subset_percent\/100))","dc6c898d":"print('Training Data size: {}, test data size: {}'.format(len(train_idx), len(test_idx)))","c22b080a":"train_df.iloc[train_idx].head()","93968bf9":"train_df.loc[train_idx,'label'].head()","5acc86a8":"#Seprate the label from the training data \ntrain_label=train_df['label']\ntrain_df.drop('label', axis=1, inplace=True)","78a68196":"print('Data: {}, Label: {}'.format(train_df.shape, train_label.shape))","da012056":"from sklearn.model_selection import train_test_split\n# from the original data, we will take a subset (25% calculated above) and split this subset into training and validation set\n\ntrain_x, test_x, train_y, test_y = train_test_split(train_df.iloc[train_idx], train_label.iloc[train_idx], \\\n                                                    train_size=0.7, test_size=0.3, random_state=4)\n\n","700fcf40":"print('Data - training Set: {}, test set: {}'.format(train_x.shape, test_x.shape))\nprint('Label - training Set: {}, test set: {}'.format(train_y.shape, test_y.shape))","3162e65b":"from sklearn.model_selection import GridSearchCV","6669e9de":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()","8cf2057e":"#Range of different hyperparameters\n#kernel=['rbf','linear','poly']\n#C=[0.001,0.01,0.1,1.0,10]\n#gamma=[0.001,0.01,0.1,1.0]\n\nkernel=['rbf']\nC=[0.001, 0.01, 1, 10,30]\ngamma=[0.001, .01, 1, 10]\n\nparams={'SVM__kernel':kernel, 'SVM__C':C, 'SVM__gamma':gamma}","8957e026":"#Prepare a pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC","dab4df10":"#instantiate a class of SVM\nsvm = SVC(cache_size=7000, random_state=42)","bd838e2d":"#Prepare a pipeline\nsteps=[('Scaler',StandardScaler()), ('SVM',svm)]\npipeline=Pipeline(steps)","04285c9e":"#use GridSearch for hyperparameter tuning\ngrid=GridSearchCV(n_jobs=-1, \n                  estimator=pipeline,\n                  param_grid=params,\n                  return_train_score=True,                   \n                  cv=3, \n                  verbose=1)","1977bf5d":"grid.estimator.get_params","930ad6c7":"#\nstart=timer()\n#Train on traning dataset\ngrid.fit(train_x, train_y)\nend=timer()","7ee73311":"print('Time taken to fit on train data (in min): {} '.format((end-start)\/60))","acb5c352":"grid.best_params_","0535665f":"grid.best_score_, grid.best_params_['SVM__C'], grid.best_params_['SVM__gamma']","89c022f1":"cv_result= pd.DataFrame(grid.cv_results_)\ncv_result.head()","6cab27db":"cv_result.columns","69e64216":"cv_result[['rank_test_score','mean_test_score','mean_train_score','param_SVM__C','param_SVM__gamma']].sort_values(by='rank_test_score')","eab7ac6c":"#Use the above values of C and gamma to train the model\nsvm_1 = SVC(C=grid.best_params_['SVM__C'], gamma=grid.best_params_['SVM__gamma'], kernel='rbf', random_state=21)","f42112c8":"#Re-create the pipeline model, with the SVM class corresponding to one with best parameters\nsteps=[('Scaler',StandardScaler()), ('SVM',svm_1)]\npipeline=Pipeline(steps)","b67d842b":"start=timer()\npipeline.fit(train_x, train_y)\nend=timer()","a0d5bf07":"print('Time taken to fit on train data using best hyperparameter (in min): {} '.format((end-start)\/60))","0e44d0b9":"test_pred=pipeline.predict(test_x)","f7d24e48":"from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report, accuracy_score","a43e2074":"cmat=confusion_matrix(test_y, test_pred)","31e746dd":"cmat","e1c1b216":"accuracy_score(test_y, test_pred)","8f3fa626":"pd.options.display.float_format= '${:,.4f}'.format","acc28d84":"plt.figure(figsize=(15,8))\nsns.heatmap(cmat, annot=True, fmt='g')","a0d0fce7":"print(classification_report(test_y, test_pred))","3592a26e":"test_result=pd.concat([test_y, pd.Series(test_pred, name='predicted', index=test_y.index)],axis=1)","43a32417":"test_result.head()","77af890e":"test_x.head()","0ab56949":"test_result.iloc[:21,1:]","2ae3c635":"train_df.iloc[:15,:1].shape[1], test_result.iloc[:15,1:].shape[1]","5a2544e2":"#Let's visualize how the predictions come out to be\ndraw_digit(test_x.iloc[:21,:],test_result.iloc[:21,1:],'Predicted')\n#draw_digit(train_df.iloc[:15,1:], train_df.iloc[:15,:1])","1c4bc8c6":"#digits that were incorrectly classified\nincorrect_dig=test_result[test_result.label != test_result['predicted']].index\n#draw_digit(test_x.iloc[:21,:],test_result.iloc[:21][['predicted']])","c4b6cbd5":"test_xypred=pd.concat([test_x, test_result], axis=1)","00c12960":"test_xypred.head()","3dd2c3e0":"test_xypred[test_xypred.label != test_xypred.predicted].head()","af9c0733":"draw_digit(test_xypred[test_xypred.label != test_xypred.predicted].iloc[:21,:784],\\\n           test_xypred[test_xypred.label != test_xypred.predicted].iloc[:21,785:],'Predicted')","2b1b9f91":"#Save the model for further testing\nfrom joblib import dump, load\ndump(pipeline, 'mnist_svm_pipeline.joblib') ","e0237135":"test_df.head()","f5ab9f40":"start=timer()\ntest_predict=test_pred=pipeline.predict(test_df)\nend=timer()","def7e636":"print('Time take to predict: {}'.format((end-start)\/60))","3b509da7":"test_predict","95d09af7":"test_df.index","e1886923":"submit_df =pd.concat([pd.Series(test_df.index, name='ImageId'), pd.Series(test_predict, name='Label')], axis=1)","a4bf4607":"submit_df.head()","86993d9f":"submit_df.to_csv('..\/submission.csv')","5aa3f978":"We see that there is a uniform distribution of different classes, and there is no class imbalance or skewness.","13d17c6a":"## Basic Data Quality Check","a0eb745b":"# MNIST - Digit Recognizer with SVM","cd04e2d2":"Since the pixel values can vary bewteen 0 and 255, there is not much we can gather from the above table. But we notice that the pixels number 0-11, 16-31, 52-57 etc are all 0's. This is because most of the digits are centerd and the spaces in the corners are blank. These pixels correspond to such spaces where there is nothing written.","4f31ffdc":"**Images of digits that were incorrectly predicted by the algorithm**","91f66c35":"There doesn't appear to be any rows that have null values or any columns that have null values","463c5f77":"### We will use a Pipeline with feature scaling and model training as it's steps","3316d92b":"## Split the training dataset into training and validation\n","4b952046":"## Take a subset of data.\n__Since the data set is quite large, and tuning all the hyperparameters will be expensive, we will run the training on a subset of this data.__","09ee4acf":"### Standardize the training and validation dataset","9b5ef851":"'**micro'**: Calculate metrics globally by counting the total true positives, false negatives and false positives.<br>\n**'macro':** Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.","04c7c88a":"## Use Cross Validation to train the model\n\n__We already have a test set, but to tune the hyperparameters, we will use K-fold cross validaton on the training set__","5ceeb6d8":"### Check the distribution of labels","af1d7f55":"~190 (out of 7000) digits were incorrectly predicted"}}