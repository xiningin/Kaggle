{"cell_type":{"b3af917d":"code","fc00f026":"code","549feebe":"code","5a3ad5d1":"code","eae02b07":"code","8e634348":"code","2cc09e7f":"code","bd226a17":"code","f225cabb":"code","1a00e1b3":"code","f94a3a86":"code","d1757910":"code","eb4653ad":"code","4c421478":"code","95a1a6af":"code","c8089478":"code","13a782f9":"code","cc70c34e":"code","91941e5a":"code","7e5609f7":"code","a3876e34":"code","fe6df859":"code","d5fb356b":"code","98740b98":"code","70f75e37":"code","ad7807bf":"code","e4daa232":"code","a85ae07c":"code","9145fc8e":"code","bb703b70":"code","f5d7dc17":"code","a3e0dc17":"code","4259e732":"code","5e5fa308":"code","3072b1d2":"code","c8df7049":"code","062413c5":"code","084378c0":"code","bfb06831":"code","96e9b490":"code","fdf552fd":"code","0313a22e":"code","f45d0c69":"code","ea51ef59":"code","379dbbf1":"code","08ae79fe":"code","28bff672":"code","7e60c9cb":"code","867d71cb":"code","ea89b104":"code","56d1c480":"code","734c2794":"code","b87ab56d":"code","14e53c20":"code","b6ffdf34":"code","4502f57e":"code","efc99393":"code","45feee0f":"code","88a1a51a":"code","e2b0f7d8":"code","3e5ac4cb":"code","5468fd6a":"code","a00f498c":"code","53d7953f":"code","57dff99b":"code","2feb1e62":"markdown","61adc7ff":"markdown","dbe87685":"markdown","353e7323":"markdown","cef2fa82":"markdown","5a7a589d":"markdown"},"source":{"b3af917d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc00f026":"#Importing all Necessary libraries For EDA\n\nimport numpy as np\nimport pandas as pd\npd.set_option(\"display.max_columns\",None)\npd.set_option(\"display.max_rows\",None)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set()\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# univariate lstm example\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Flatten","549feebe":"#Reading Required Data\n\ndf = pd.read_csv(\"..\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 4.csv\",encoding=\"utf-8\", delimiter=',')\ndf.head()","5a3ad5d1":"df.info()","eae02b07":"df.shape","8e634348":"statistics_of_data = []\nfor col in df.columns:\n  statistics_of_data.append((col,\n                             df[col].nunique(),\n                             df[col].isnull().sum()*100\/df.shape[0],\n                             df[col].value_counts(normalize=True, dropna=False).values[0] * 100, \n                             df[col].dtype\n                             ))\nstats_df = pd.DataFrame(statistics_of_data, columns=['Feature', 'Uniq_val', 'missing_val', 'val_biggest_cat', 'type'])","2cc09e7f":"stats_df.sort_values('Uniq_val', ascending=False)","bd226a17":"df.dropna(inplace=True)","f225cabb":"df1 = df.copy()","1a00e1b3":"### Renaming columns name\ndf1 = df1.rename(columns={'Order Number': 'Ord_num','Order Date':'Ord_Date','City (Billing)':'City',\n                          'Book Name':'Book_Name','Order Status':'Ord_Status'\n                         \n                         })\ndf1.head()","f94a3a86":"df1.shape","d1757910":"#Shout out muhammadismail99 for this function\n\nfrom itertools import chain\n\n# return list from series of comma-separated strings\ndef chainer(s):\n    return list(chain.from_iterable(s.str.split('\/')))\n\n# calculate lengths of splits\ndf2 = df1.copy()\nlens = df2['Book_Name'].str.split('\/').map(len)\n\n# create new dataframe, repeating or chaining as appropriate\ndf2 = pd.DataFrame({'Ord_num': np.repeat(df2['Ord_num'], lens),\n                    'Ord_Status': np.repeat(df2['Ord_Status'], lens),\n                    'Book_Name': chainer(df2['Book_Name']),\n                    'Ord_Date': np.repeat(df2['Ord_Date'], lens),\n                    'City': np.repeat(df2['City'], lens)})","eb4653ad":"df2.shape","4c421478":"df2['City'] = df2['City'].str.lower()\ndf2['City'] = df2['City'].apply(lambda x: x.strip(''))\ncity_stats = df2['City'].value_counts(ascending=False)\ncity_stats.head()","95a1a6af":"def ReplaceString(searchterm,replacedWith,data):\n    search_terms = searchterm\n    matches = []\n    for memo_string in data:#df['City (Billing)']:\n        for word in search_terms.split(\" \"):\n            if word not in memo_string:\n                break\n            else:\n                #df['City (Billing)'].replace(memo_string,'karachi',inplace=True)\n                data.replace(memo_string,replacedWith,inplace=True)\n                matches.append(memo_string) # triggers when the for loop doesn't break","c8089478":"df3 = df2.copy()","13a782f9":"ReplaceString('karachi','karachi',df3['City'])","cc70c34e":"ReplaceString('lahore','lahore',df3['City'])","91941e5a":"ReplaceString('islamabad','islamabad',df3['City'])","7e5609f7":"ReplaceString('rawalpindi','rawalpindi',df3['City'])","a3876e34":"ReplaceString('faisalabad','faisalabad',df3['City'])","fe6df859":"ReplaceString('multan','multan',df3['City'])","d5fb356b":"ReplaceString('hyderabad','hyderabad',df3['City'])","98740b98":"ReplaceString('????? ??? ??? ???? ??????','unknown',df3['City'])\nReplaceString('???????','unknown',df3['City'])\nReplaceString('??? ???','unknown',df3['City'])\nReplaceString('????????','unknown',df3['City'])\nReplaceString('?????','unknown',df3['City'])\nReplaceString('????','unknown',df3['City'])\nReplaceString('??????','unknown',df3['City'])\nReplaceString('???????','unknown',df3['City'])","70f75e37":"df3.shape","ad7807bf":"len(df3['City'].unique()) ## Everything ('2869') is validated till here","e4daa232":"df4 = df3.copy()","a85ae07c":"## Cities having orders less than 12 cardinality are termed as others\n\ncity_stats_less_than_12 = city_stats[city_stats<=12]\n\ndf4['City'] =df4['City'].apply(lambda x: 'other' if x in city_stats_less_than_12 else x)\nlen(df4['City'].unique()) ##Everything ('195') is validated till here","9145fc8e":"# Formatting Order Status Feature\ndf5 = df4.copy()\ncombine = [df5]\ntitlemapping = {'Canceled':0, 'Completed':1,'Returned':2}\nfor row in combine:\n    row[\"Ord_Status\"] = row[\"Ord_Status\"].map(titlemapping)\n    row['Ord_Status'] = row['Ord_Status'].fillna(0)\n    row['Ord_Status'] = row['Ord_Status'].astype(int)","bb703b70":"df5.shape","f5d7dc17":"df6 = df5.copy()","a3e0dc17":"# #Thanks to @hussainsaddam12 & @mnavaidd for this codeblock idea\ndf6[\"Ord_Date\"] = pd.DatetimeIndex(df6[\"Ord_Date\"])\ndf6['date'] = df6['Ord_Date'].dt.date\ndf6['time'] = df6['Ord_Date'].dt.time\ndf6[\"Day_Name\"] = df6[\"Ord_Date\"].dt.day_name()\ndf6[\"Month_Name\"] = df6[\"Ord_Date\"].dt.month_name()\ndf6['year'] = df6[\"Ord_Date\"].dt.year","4259e732":"df6.head()","5e5fa308":"df6.shape  ## 5 columns added ## Everything till here is validated (33091,10)","3072b1d2":"len(df6['Book_Name'].unique())","c8df7049":"#lets take an average of 500 rupees (PKR) as cost of each book\ndf6['Avgprice'] = 500\ndf6.head()","062413c5":"#Average sale per month\n\n#Books Sold in jan\ndf7 = df6.copy()\ndf7 =df7[['Month_Name','Avgprice','Book_Name','Ord_Status','year']]\ndf7.head()","084378c0":"df7['Month_Name'].unique()","bfb06831":"def AvgSale(df, month,year):\n    df = df[(df['Month_Name'] == month) & (df['Ord_Status'] == 1) & (df['year'] == year)] ##Order status = success\n    AvgSale22 = 500*len(df)\n    return AvgSale22\n","96e9b490":"#Testing\njan2020_AvgSale = AvgSale(df7,'January',2020)\njan2020_AvgSale ","fdf552fd":"jan2019_AvgSale = AvgSale(df7,'January',2019)\nfeb2019_AvgSale = AvgSale(df7,'February',2019)\nmar2019_AvgSale = AvgSale(df7,'March',2019)\napr2019_AvgSale = AvgSale(df7,'April',2019)\nmay2019_AvgSale = AvgSale(df7,'May',2019)\njune2019_AvgSale = AvgSale(df7,'June',2019)\njuly2019_AvgSale = AvgSale(df7,'July',2019)\naug2019_AvgSale = AvgSale(df7,'August',2019)\nsept2019_AvgSale = AvgSale(df7,'September',2019)\noct2019_AvgSale = AvgSale(df7,'October',2019)\nnov2019_AvgSale = AvgSale(df7,'November',2019)\ndec2019_AvgSale = AvgSale(df7,'December',2019)\n\n\n\njan2020_AvgSale = AvgSale(df7,'January',2020)\nfeb2020_AvgSale = AvgSale(df7,'February',2020)\nmar2020_AvgSale = AvgSale(df7,'March',2020)\napr2020_AvgSale = AvgSale(df7,'April',2020)\nmay2020_AvgSale = AvgSale(df7,'May',2020)\njune2020_AvgSale = AvgSale(df7,'June',2020)\njuly2020_AvgSale = AvgSale(df7,'July',2020)\naug2020_AvgSale = AvgSale(df7,'August',2020)\nsept2020_AvgSale = AvgSale(df7,'September',2020)\noct2020_AvgSale = AvgSale(df7,'October',2020)\nnov2020_AvgSale = AvgSale(df7,'November',2020)\ndec2020_AvgSale = AvgSale(df7,'December',2020)\n\n\njan2021_AvgSale = AvgSale(df7,'January',2021)","0313a22e":"d = {'Month': ['2019-01-01', '2019-02-01','2019-03-01','2019-04-01','2019-05-01',\n               '2019-06-01','2019-07-01','2019-08-01','2019-09-01','2019-10-01',\n               '2019-11-01','2019-12-01',\n               \n               '2020-01-01', '2020-02-01','2020-03-01','2020-04-01','2020-05-01',\n               '2020-06-01','2020-07-01','2020-08-01','2020-09-01','2020-10-01',\n               '2020-11-01','2020-12-01',\n               \n               '2021-01-01'], 'AvgSales': [jan2019_AvgSale,feb2019_AvgSale, mar2019_AvgSale,apr2019_AvgSale,may2019_AvgSale,\n                                       \n                                       june2019_AvgSale,july2019_AvgSale,aug2019_AvgSale,sept2019_AvgSale,oct2019_AvgSale,\n                                        \n                                       nov2019_AvgSale,dec2019_AvgSale,\n                                        \n                                        jan2020_AvgSale,feb2020_AvgSale,mar2020_AvgSale,apr2020_AvgSale,may2020_AvgSale,\n                                        \n                                        june2020_AvgSale,july2020_AvgSale,aug2020_AvgSale,sept2020_AvgSale,oct2020_AvgSale,\n                                        nov2020_AvgSale,dec2020_AvgSale,jan2021_AvgSale\n                                        \n                                       ]}","f45d0c69":"df8 = pd.DataFrame(data=d)","ea51ef59":"df8.head(20)","379dbbf1":"df8.tail(10)","08ae79fe":"df8.describe()","28bff672":"#Visualizing data\n\ndf8.plot()","7e60c9cb":"# preparing independent and dependent features\ndef prepare_data(timeseries_data, n_features):\n\tX, y =[],[]\n\tfor i in range(len(timeseries_data)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_features\n\t\t# check if we are beyond the sequence\n\t\tif end_ix > len(timeseries_data)-1:\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn np.array(X), np.array(y)","867d71cb":"# define input sequence\ntimeseries_data = df8['AvgSales']\n# choose a number of time steps\nn_steps = 3\n# split into samples\nX, y = prepare_data(timeseries_data, n_steps)","ea89b104":"print(X),print(y)","56d1c480":"X.shape","734c2794":"## reshaping\n\nn_features = 1\nX = X.reshape((X.shape[0],X.shape[1],n_features))","b87ab56d":"X.shape","14e53c20":"\n# define model\nmodel = Sequential()\nmodel.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\nmodel.add(LSTM(50, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mse')\n# fit model\nmodel.fit(X, y, epochs=300, verbose=1)","b6ffdf34":"# demonstrate prediction for next 10 Months\nx_input = np.array([1722000, 2404000, 3136000])\ntemp_input=list(x_input)\nlst_output=[]\ni=0\nwhile(i<10):\n    \n    if(len(temp_input)>3):\n        x_input=np.array(temp_input[1:])\n        print(\"{} Months input {}\".format(i,x_input))\n        #print(x_input)\n        x_input = x_input.reshape((1, n_steps, n_features))\n        #print(x_input)\n        yhat = model.predict(x_input, verbose=0)\n        print(\"{} Month output {}\".format(i,yhat))\n        temp_input.append(yhat[0][0])\n        temp_input=temp_input[1:]\n        #print(temp_input)\n        lst_output.append(yhat[0][0])\n        i=i+1\n    else:\n        x_input = x_input.reshape((1, n_steps, n_features))\n        yhat = model.predict(x_input, verbose=0)\n        print(yhat[0])\n        temp_input.append(yhat[0][0])\n        lst_output.append(yhat[0][0])\n        i=i+1\n    \n\nprint(lst_output)","4502f57e":"timeseries_data","efc99393":"len(timeseries_data)","45feee0f":"lst_output","88a1a51a":"lst_output","e2b0f7d8":"day_new=np.arange(1,26)\nday_pred=np.arange(26,36)","3e5ac4cb":"timeseries_data","5468fd6a":"day_new","a00f498c":"day_pred","53d7953f":"plt.plot(day_new,timeseries_data)\nplt.plot(day_pred,lst_output)","57dff99b":"lst_output","2feb1e62":"### Sales Forecasting For Gufhtugu Publishers","61adc7ff":"### Visualizaing The Output","dbe87685":"Thats all for Average sales prediction (Taking an average of 500 PKR per Book) for Gufhtugu Publishers, Up vote it if you liked it.","353e7323":"### Building LSTM Model","cef2fa82":"### Above is the sale prediction of gufhtugu publishers for next 10 months (From Feb 2021 - Nov 2021)","5a7a589d":"### Yup, Growth is amazing"}}