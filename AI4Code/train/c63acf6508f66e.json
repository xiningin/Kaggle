{"cell_type":{"212046e6":"code","6ea4d7a0":"code","08d0bce2":"code","446aee0e":"code","695022f4":"code","7d14a210":"code","15c582cc":"code","8ebabe6b":"code","9e594dc4":"code","7126cace":"code","5e63b986":"code","edb0636b":"code","9cfa7c23":"code","0ce1d1f4":"code","d36be967":"code","a62f6a72":"code","57488f23":"code","7342dfcd":"code","45c95b02":"code","7e44f338":"code","4b22ed53":"markdown","895f2c62":"markdown","d661604e":"markdown","8e41a8bd":"markdown","2c4d6355":"markdown","23bc481f":"markdown","31d55856":"markdown","0fa6a932":"markdown","bb7676b6":"markdown","e8404ae2":"markdown","406b64ff":"markdown","52bc479a":"markdown","17e83a96":"markdown","c25c4cd2":"markdown","c1fa08a2":"markdown"},"source":{"212046e6":"!pip3 install faiss-gpu","6ea4d7a0":"import time\n\nimport faiss\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import pairwise","08d0bce2":"def create_data(n_train=1600, n_dev=100, n_test=250, d=768, n_label_fns=10, abstain_prob=0.8):\n    np.random.seed(137)  # make reproducible\n    train_embeddings = np.random.normal(scale=0.1, size=(n_train, d)).astype('float32')\n    L_train = np.random.choice([0, -1, 1], size=(n_train, n_label_fns), replace=True, \n                               p=[abstain_prob, (1 - abstain_prob) \/ 2, (1 - abstain_prob) \/ 2])\n\n    np.random.seed(138)\n    dev_embeddings = np.random.normal(scale=0.1, size=(n_dev, d)).astype('float32')\n    L_dev = np.random.choice([0, -1, 1], size=(n_dev, n_label_fns), replace=True, \n                             p=[abstain_prob, (1 - abstain_prob) \/ 2, (1 - abstain_prob) \/ 2])\n\n    np.random.seed(139)\n    test_embeddings = np.random.normal(scale=0.1, size=(n_test, d)).astype('float32')\n    L_test = np.random.choice([0, -1, 1], size=(n_test, n_label_fns), replace=True, \n                              p=[abstain_prob, (1 - abstain_prob) \/ 2, (1 - abstain_prob) \/ 2])\n    \n    return train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test","446aee0e":"def faiss_init(train_embeddings, L_train, gpu=False):\n    \"\"\"One time setup.\"\"\"\n    \n    # Create one index for each labeling function\n    d = train_embeddings.shape[1]\n    m = L_train.shape[1]\n    label_fn_indexes = [faiss.IndexFlatL2(d) for i in range(m)]\n    if gpu:\n        res = faiss.StandardGpuResources()  # use a single GPU\n        label_fn_indexes = [faiss.index_cpu_to_gpu(res, 0, x) for x in label_fn_indexes]\n    \n    # Add the embeddings to the index for which the labeling function is supported\n    for i in range(m):\n        support = np.argwhere(L_train[:, i] != 0).flatten()\n        label_fn_indexes[i].add(train_embeddings[support])\n        \n    return label_fn_indexes\n\n\ndef faiss_nn_query(indexes, embs_mat, L_mat):\n    \"\"\"Helper function to perform nearest-neighbor queries reusing indexes.\"\"\"\n    \n    m = L_mat.shape[1]\n    \n    mat_abstains = [\n        np.argwhere(L_mat[:, i] == 0).flatten()\n        for i in range(m)\n    ]\n    res = [indexes[i].search(embs_mat[mat_abstains[i]], 1) for i in range(m)]\n    return res, sum(len(mat_abstains[i]) for i in range(m))","695022f4":"def old_nn_query(L_train, embs_train, L_mat, embs_mat):\n    mat_to_train_sims = pairwise.euclidean_distances(embs_mat, embs_train)\n    \n    m = L_mat.shape[1]\n    expanded_L_mat = np.copy(L_mat)\n\n    train_support_pos = [\n        np.argwhere(L_train[:, i] == 1).flatten()\n        for i in range(m)\n    ]\n    train_support_neg = [\n        np.argwhere(L_train[:, i] == -1).flatten()\n        for i in range(m)\n    ]\n\n    mat_abstains = [\n        np.argwhere(L_mat[:, i] == 0).flatten()\n        for i in range(m)\n    ]\n\n    pos_dists = [\n        mat_to_train_sims[mat_abstains[i]][:, train_support_pos[i]]\n        for i in range(m)\n    ]\n    neg_dists = [\n        mat_to_train_sims[mat_abstains[i]][:, train_support_neg[i]]\n        for i in range(m)\n    ]\n\n    closest_pos = [\n        np.max(pos_dists[i], axis=1)\n        if pos_dists[i].shape[1] > 0 else np.full(mat_abstains[i].shape, -1)\n        for i in range(m)\n    ]\n    closest_neg = [\n        np.max(neg_dists[i], axis=1)\n        if neg_dists[i].shape[1] > 0 else np.full(mat_abstains[i].shape, -1)\n        for i in range(m)\n    ]\n\n    return mat_abstains, closest_pos, closest_neg","7d14a210":"sizes = list(range(1600, 25600, 800)) + list(range(25600, 102400, 1600)) + list(range(102400, 204801, 3200))\ntimes_old = []\ntimes_faiss = []\ntimes_faiss_gpu = []\nfor sz in sizes:\n    train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=sz,\n                                                                                            n_dev=int(0.05*sz),\n                                                                                            n_test=int(0.10*sz))\n    print('size:', sz)\n    \n    if sz <= 25600:\n        start = time.time()\n        old_nn_query(L_train, train_embeddings, L_train, train_embeddings)\n        old_nn_query(L_train, train_embeddings, L_dev, dev_embeddings)\n        old_nn_query(L_train, train_embeddings, L_test, test_embeddings)\n        end = time.time()\n        times_old.append(end - start)\n        print('old:', times_old[-1])\n    \n    if sz <= 49600:\n        start = time.time()\n        indexes = faiss_init(train_embeddings, L_train)\n        faiss_nn_query(indexes, train_embeddings, L_train)\n        faiss_nn_query(indexes, dev_embeddings, L_dev)\n        faiss_nn_query(indexes, test_embeddings, L_test)\n        end = time.time()\n        times_faiss.append(end - start)\n        print('cpu:', times_faiss[-1])\n    \n    start = time.time()\n    indexes = faiss_init(train_embeddings, L_train, gpu=True)\n    faiss_nn_query(indexes, train_embeddings, L_train)\n    faiss_nn_query(indexes, dev_embeddings, L_dev)\n    faiss_nn_query(indexes, test_embeddings, L_test)\n    end = time.time()\n    times_faiss_gpu.append(end - start)\n    print('gpu:', times_faiss_gpu[-1])","15c582cc":"# plt.plot(sizes[:len(times_old)], times_old, 'o')\n# plt.plot(sizes[:len(times_old)], times_faiss[:len(times_old)], 'o')\n# # plt.plot(sizes[:len(times_faiss_gpu)], times_faiss_gpu, 'o')\n# plt.legend(['old', 'FAISS cpu'])\n# plt.ylabel('seconds')\n# plt.xlabel('size of training set')\n# plt.show()\n\na2, a1, a0 = np.polyfit(sizes[:len(times_old)], times_old, 2)\nb2, b1, b0 = np.polyfit(sizes[:len(times_faiss)], times_faiss, 2)\nc2, c1, c0 = np.polyfit(sizes[:len(times_faiss_gpu)], times_faiss_gpu, 2)\nplt.plot(sizes, a2 * (np.array(sizes)**2) + a1 * np.array(sizes) + a0)\nplt.plot(sizes, b2 * (np.array(sizes)**2) + b1 * np.array(sizes) + b0)\nplt.plot(sizes, c2 * (np.array(sizes)**2) + c1 * np.array(sizes) + c0)\nplt.title('Projections (actual times for GPU)')\nplt.legend(['old', 'FAISS cpu', 'FAISS gpu'])\nplt.ylabel('seconds')\nplt.xlabel('size of training set')\nplt.show()","8ebabe6b":"n_label_fns = range(1, 258, 8)\ntimes = []\nfor n in n_label_fns:\n    train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_label_fns=n)\n    start = time.time()\n    indexes = faiss_init(train_embeddings, L_train)\n    _, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\n    end = time.time()\n    times.append(end - start)\n    print(end-start)\n    print(n_queries)\n    \ngpu_times = []\nfor n in n_label_fns:\n    train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_label_fns=n)\n    start = time.time()\n    indexes = faiss_init(train_embeddings, L_train, gpu=True)\n    _, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\n    end = time.time()\n    gpu_times.append(end - start)\n    print(end-start)\n    print(n_queries)","9e594dc4":"m1, b1 = np.polyfit(n_label_fns, times, 1)\nplt.plot(n_label_fns, times, 'o')\n\nm2, b2 = np.polyfit(n_label_fns, gpu_times, 1)\nplt.plot(n_label_fns, gpu_times, 'o')\n\nplt.plot(n_label_fns, m1 * np.array(n_label_fns) + b1)\nplt.plot(n_label_fns, m2 * np.array(n_label_fns) + b2)\nplt.legend(['cpu', 'gpu', f'y={m1:.3}x+{b1:.3}', f'y={m2:.3}x+{b2:.3}'])\nplt.xlabel('number of labeling functions')\nplt.ylabel('seconds')\nplt.show()","7126cace":"sizes = range(1600, 100001, 800)\ntimes = []\nfor sz in sizes:\n    train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=sz)\n    start = time.time()\n    indexes = faiss_init(train_embeddings, L_train)\n    _, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\n    end = time.time()\n    times.append(end - start)\n    print(end-start)\n    print(n_queries)\n    \ngpu_times = []\nfor sz in sizes:\n    train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=sz)\n    start = time.time()\n    indexes = faiss_init(train_embeddings, L_train, gpu=True)\n    _, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\n    end = time.time()\n    gpu_times.append(end - start)\n    print(end-start)\n    print(n_queries)","5e63b986":"m1, b1 = np.polyfit(sizes, times, 1)\nplt.plot(sizes, times, 'o')\n\nm2, b2 = np.polyfit(sizes, gpu_times, 1)\nplt.plot(sizes, gpu_times, 'o')\n\nplt.plot(sizes, m1 * np.array(sizes) + b1)\nplt.plot(sizes, m2 * np.array(sizes) + b2)\nplt.legend(['cpu', 'gpu', f'y={m1:.3}x+{b1:.3}', f'y={m2:.3}x+{b2:.3}'])\nplt.xlabel('size of training set')\nplt.ylabel('seconds')\nplt.show()","edb0636b":"dims = range(600, 3200, 100)\ntimes = []\nfor d in dims:\n    train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=10000, d=d)\n    start = time.time()\n    indexes = faiss_init(train_embeddings, L_train)\n    _, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\n    end = time.time()\n    times.append(end - start)\n    print(end-start)\n    print(n_queries)\n    \ngpu_times = []\nfor d in dims:\n    train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=10000, d=d)\n    start = time.time()\n    indexes = faiss_init(train_embeddings, L_train)\n    _, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\n    end = time.time()\n    gpu_times.append(end - start)\n    print(end-start)\n    print(n_queries)","9cfa7c23":"m1, b1 = np.polyfit(dims, times, 1)\nplt.plot(dims, times, 'o')\n\nm2, b2 = np.polyfit(dims, gpu_times, 1)\nplt.plot(dims, gpu_times, 'o')\n\nplt.plot(dims, m1 * np.array(dims) + b1)\nplt.plot(dims, m2 * np.array(dims) + b2)\nplt.legend(['cpu', 'gpu', f'y={m1:.3}x+{b1:.3}', f'y={m2:.3}x+{b2:.3}'])\nplt.xlabel('dimension of embeddings')\nplt.ylabel('seconds')\nplt.show()","0ce1d1f4":"sizes = range(1600, 12800, 800)\ntimes = []\nqueries = []\nfor sz in sizes:\n    train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=12800, n_test=sz)\n    start = time.time()\n    indexes = faiss_init(train_embeddings, L_train)\n    _, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\n    end = time.time()\n    times.append(end - start)\n    queries.append(n_queries)\n    print(end-start)\n    print(n_queries)\n    \ngpu_times = []\ngpu_queries = []\nfor sz in sizes:\n    train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=12800, n_test=sz)\n    start = time.time()\n    indexes = faiss_init(train_embeddings, L_train, gpu=True)\n    _, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\n    end = time.time()\n    gpu_times.append(end - start)\n    gpu_queries.append(n_queries)\n    print(end-start)\n    print(n_queries)","d36be967":"m1, b1 = np.polyfit(queries, times, 1)\nplt.plot(queries, times, 'o')\n\nm2, b2 = np.polyfit(queries, gpu_times, 1)\nplt.plot(queries, gpu_times, 'o')\n\nplt.plot(queries, m1 * np.array(queries) + b1)\nplt.plot(queries, m2 * np.array(queries) + b2)\nplt.legend(['cpu', 'gpu', f'y={m1:.3}x+{b1:.3}', f'y={m2:.3}x+{b2:.3}'])\nplt.xlabel('number of queries')\nplt.ylabel('seconds')\nplt.show()","a62f6a72":"train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=1586, n_label_fns=10, n_test=1922, abstain_prob=0.837)\nstart = time.time()\nindexes = faiss_init(train_embeddings, L_train)\n_, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\nend = time.time()\nprint('cpu:', end-start)\n\nstart = time.time()\nindexes = faiss_init(train_embeddings, L_train, gpu=True)\n_, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\nend = time.time()\nprint('gpu:', end-start)\n# print(n_queries)","57488f23":"train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=17970, n_label_fns=4, n_test=20245, abstain_prob=0.507)\nstart = time.time()\nindexes = faiss_init(train_embeddings, L_train)\n_, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\nend = time.time()\nprint('cpu:', end-start)\n\nstart = time.time()\nindexes = faiss_init(train_embeddings, L_train, gpu=True)\n_, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\nend = time.time()\nprint('gpu:', end-start)\n# print(n_queries)","7342dfcd":"train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=187, n_label_fns=103, n_test=290, abstain_prob=0.912)\nstart = time.time()\nindexes = faiss_init(train_embeddings, L_train)\n_, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\nend = time.time()\nprint('cpu:', end-start)\n\nstart = time.time()\nindexes = faiss_init(train_embeddings, L_train, gpu=True)\n_, n_queries = faiss_nn_query(indexes, test_embeddings, L_test)\nend = time.time()\nprint('gpu:', end-start)\n# print(n_queries)","45c95b02":"def faiss_init(train_embeddings, L_train, metric='L2', gpu=False):\n    \"\"\"One time setup.\"\"\"\n    \n    if metric == 'cosine':\n        # Copy because faiss.normalize_L2() modifies the original\n        train_embeddings = np.copy(train_embeddings)\n        \n        # Normalize the vectors before adding to the index\n        faiss.normalize_L2(train_embeddings)\n    \n    d = train_embeddings.shape[1]\n    m = L_train.shape[1]\n    \n    if metric == 'cosine':\n        label_fn_indexes = [faiss.IndexFlatIP(d) for i in range(m)]  # use IndexFlatIP (inner product)\n    else:  # 'L2':\n        label_fn_indexes = [faiss.IndexFlatL2(d) for i in range(m)]\n        \n    if gpu:\n        res = faiss.StandardGpuResources()\n        label_fn_indexes = [faiss.index_cpu_to_gpu(res, 0, x) for x in label_fn_indexes]\n    \n    for i in range(m):\n        support = np.argwhere(L_train[:, i] != 0).flatten()\n        label_fn_indexes[i].add(train_embeddings[support])\n        \n    return label_fn_indexes\n\n\ndef faiss_nn_query(indexes, embs_mat, L_mat, metric='L2'):\n    \"\"\"Helper function to perform nearest-neighbor queries reusing indexes.\"\"\"\n    \n    m = L_mat.shape[1]\n    \n    mat_abstains = [\n        np.argwhere(L_mat[:, i] == 0).flatten()\n        for i in range(m)\n    ]\n    \n    res = []\n    for i in range(m):\n        if metric == 'cosine':\n            embs_query = np.copy(embs_mat[mat_abstains[i]])\n            faiss.normalize_L2(embs_query)\n        else: # 'L2'\n            embs_query = embs_mat[mat_abstains[i]]\n        res.append(indexes[i].search(embs_query, 1))\n        \n    return res, sum(len(mat_abstains[i]) for i in range(m))","7e44f338":"train_embeddings, L_train, dev_embeddings, L_dev, test_embeddings, L_test = create_data(n_train=10000)\nindexes = faiss_init(train_embeddings, L_train, metric='cosine')\nres, n_queries = faiss_nn_query(indexes, test_embeddings, L_test, metric='cosine')\n# res is a list of length 2, where the first element is an array of distances,\n# and the second element is a list of indices of the nearest neighbors","4b22ed53":"For convenience, I've reproduced the old (technically current) solution here.","895f2c62":"\n## Weather:\n\n- 187 training points\n- 103 labeling functions\n- 91.2% abstain rate\n- 768 dimension embeddings\n- 27,328 queries","d661604e":"\n## Basketball:\n\n- 17,970 training points\n- 4 labeling functions\n- 50.7% abstain rate\n- 2048 dimension embeddings\n- 41,186 queries","8e41a8bd":"# Scalable Nearest Neighbor for Mayan Shell\/Epoxy with FAISS\u00b6","2c4d6355":"## Cosine Similarity with FAISS\n\nA modified `faiss_init` to show cosine similarity.","23bc481f":"# Perfomance\n\nWe will evaluate the performance and costs with respect to 1) the number of labeling functions, 2) the size of the training set, 3) the dimension of the embeddings, and each with and without GPU acceleration.\n","31d55856":"## Number of queries\n\nWe vary the number of queries performed by increasing the size of the target set, while keeping the size of the training set fixed. Here the GPU acceleration particularly shines.","0fa6a932":"Normalize all vectors before querying.","bb7676b6":"We'll generate sample data for testing with the following function. We can vary the sizes of the train, dev, and test sets, the dimension of the embeddings, the number of labeling functions, and the probability that a labeling function abstains (affecting the number of queries).","e8404ae2":"# Reference to sample tasks\n\n## Spam:\n\n- 1586 training points\n- 10 labeling functions\n- 83.7% abstain rate\n- 786 dimension embeddings\n- 16,136 queries","406b64ff":"We define two functions to facilitate the new solution using FAISS, one to build and train the indexes that will be reused, and one to perform the nearest neighbor query.\n\nFor each labeling function $j$, for each point where $j$ abstains in the target set, find the closest point in the training set where $j$ did not abstain. We also need to be able to get the distance to that point, as well as the vote for $j$ on that point.\n\nThis is accomplished by created one index per labeling function, trained on only the points in the training set for which the labeling function did not abstain.\n\nIn actual implementation, the behavior of these two functions will need to be split across the Mayan Shell and Epoxy packages in a manner yet to be determined. We will also need to determine the best interface for the indexes in terms of whether they are owned by the user or the package, and further how they should be abstracted within the package.\n\n`faiss.IndexFlatL2` performs an exact nearest neighbors search. This document does not currently explore the approximation support provided, but FAISS provides many avenues for approximate algorithms and lossy compression of vectors.","52bc479a":"## Size of training set\n\nWe vary the size of the training set from 1600 to 100,000 datapoints, keeping the number of queries constant (2004 queries).","17e83a96":"## Dimension of the embeddings\n\nWe vary the dimension of the embeddings from 600 to 3200.","c25c4cd2":"## Number of labeling functions\n\nWe vary the number of labeling functions from 1 to 257. The training size remains fixed at 1600, and the number of queries goes up correspondingly from 200 to 50,000.","c1fa08a2":"First, we'll just establish that this is significantly faster than the old solution, and then we'll evaluate it's performance in a more fine-grained manner."}}