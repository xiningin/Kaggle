{"cell_type":{"2ee7dc99":"code","66c47ca7":"code","01d19421":"code","960fe910":"code","f9cc2ff7":"code","d5bc1adf":"code","663385b8":"code","046d765b":"code","0b5a28f5":"code","fe441d1e":"code","6a566696":"code","e4f28207":"code","8690e812":"code","ac05b24b":"code","99c56d49":"code","89757238":"markdown","9f3acebd":"markdown","d65879e9":"markdown","7532345f":"markdown","b135df64":"markdown"},"source":{"2ee7dc99":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","66c47ca7":"data = pd.read_csv(\"\/kaggle\/input\/biomechanical-features-of-orthopedic-patients\/column_2C_weka.csv\")\ndata.info()","01d19421":"data.head(10)","960fe910":"# x is all data except 'class' column\nx = data.loc[:,data.columns != 'class']\nprint(x)","f9cc2ff7":"# y is only 'class' column\ny = data['class']\nprint(y)","d5bc1adf":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n\n#y_train = y_train.reshape(-1,1)\n#y_test = y_test.reshape(-1,1)\n\nprint(\"x_train shape: \",x_train.shape)\nprint(\"x_test shape: \",x_test.shape)\nprint(\"y_train shape: \",y_train.shape)\nprint(\"y_test shape: \",y_test.shape)","663385b8":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=5)\n# predict\nknn.fit(x,y)\npredicts = knn.predict(x)\nprint(\"Predicts: \", predicts)","046d765b":"knn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(x_train, y_train)\nprediction = knn.predict(x_test)\nprint(\"KNN K = {} accuracy: {}\".format(5, knn.score(x_test, y_test)))","0b5a28f5":"test_list = []\ntrain_list = []\nfor k in range(1,30):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(x_train, y_train)\n    train_list.append(knn.score(x_train, y_train))\n    test_list.append(knn.score(x_test, y_test))\n\n# Graph\nplt.figure()\nplt.plot(range(1,30), test_list, label = \"Test Accuracies\")\nplt.plot(range(1,30), train_list, label = \"Train Accuracies\")\nplt.xlabel(\"Neighbors\")\nplt.ylabel(\"Accuracies\")\nplt.show()\n\nprint(\"Best accuracy: {} and number of neighbors: {}\".format(np.max(test_list), test_list.index(np.max(test_list))+1))","fe441d1e":"data.head()","6a566696":"# data create\ndata1 = data[data['class'] =='Abnormal']\nx =  np.array(data1.loc[:,'lumbar_lordosis_angle']).reshape(-1,1)\ny = np.array(data1.loc[:,'sacral_slope']).reshape(-1,1)","e4f28207":"print(min(x),max(x), min(y), max(y))","8690e812":"# show labels\nplt.figure(figsize=[8,8])\nplt.scatter(x=x,y=y)\nplt.xlabel('lumbar_lordosis_angle')\nplt.ylabel('sacral_slope')\nplt.show()","ac05b24b":"# Linear Regression Model\nfrom sklearn.linear_model import LinearRegression\nlr = LinearRegression()\n\npre = np.linspace(min(x), max(x)).reshape(-1,1)\n\nlr.fit(x,y)\n\npredicted = lr.predict(pre)\n\nprint(\"R_square : \",lr.score(x,y))","99c56d49":"plt.plot(pre, predicted, color='red', linewidth=3)\nplt.scatter(x=x,y=y)\nplt.xlabel('lumbar_lordosis_angle')\nplt.ylabel('sacral_slope')\nplt.show()","89757238":"Find the best accuracy:","9f3acebd":"K-NEAREST NEIGHBORS (KNN)\n    KNN is a classification method.\n    First we need to allocate our data for train and test.\n    ","d65879e9":"X axis is features and Y axis is class variebles.","7532345f":"**REGRESS\u0130ON**","b135df64":"### Conclusion\nWe try KNN algorithm and Linear Regression with biomechanical dataset."}}