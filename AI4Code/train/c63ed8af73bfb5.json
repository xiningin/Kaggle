{"cell_type":{"bc7a6d58":"code","f603a1f0":"code","67311412":"code","c799ee22":"code","ad2c3f3d":"code","01517daf":"code","20e76101":"code","637ac1d3":"code","5809e7c0":"code","5b241261":"code","354bc22d":"code","c36d43ce":"code","31276a6a":"code","299c412f":"code","b5e58678":"code","51500ebe":"code","0ddd9883":"code","f74d9de5":"markdown","36ff4a26":"markdown","9f2f241f":"markdown","bb45e598":"markdown","8bc7f6f5":"markdown","bfaac654":"markdown","d3654811":"markdown","6e2697ec":"markdown","823d880b":"markdown","e600ca9f":"markdown","6b480bd4":"markdown","2f038ca5":"markdown","7f6f5d11":"markdown","1fe37466":"markdown","deb79509":"markdown"},"source":{"bc7a6d58":"import seaborn as sns\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","f603a1f0":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# column_2C.csv may have more rows in reality, but we are only loading\/previewing the first 1000 rows\ndf1 = pd.read_csv('\/kaggle\/input\/column_2C.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'column_2C.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","67311412":"df1.head(5)","c799ee22":"nRowsRead = 1000 # specify 'None' if want to read whole file\n# column_3C.csv may have more rows in reality, but we are only loading\/previewing the first 1000 rows\ndf2 = pd.read_csv('\/kaggle\/input\/column_3C.csv', delimiter=',', nrows = nRowsRead)\ndf2.dataframeName = 'column_3C.csv'\nnRow, nCol = df2.shape\nprint(f'There are {nRow} rows and {nCol} columns')","ad2c3f3d":"df2.head(5)","01517daf":"sns.pairplot(df2, hue=\"class\", size=3, diag_kind=\"kde\")","20e76101":"df2['class'] = df2['class'].map({'Normal': 0, 'Hernia': 1, 'Spondylolisthesis': 2})\ndf1['class'] = df1['class'].map({'Normal': 0, 'Abnormal': 1})\n","637ac1d3":"from sklearn.model_selection import train_test_split\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nX = df1[['pelvic_incidence','pelvic_tilt','lumbar_lordosis_angle','sacral_slope', 'pelvic_radius','degree_spondylolisthesis']]\nY = df1['class']\n# split data into train and test sets\nseed = 2020\ntest_size = 0.33\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n","5809e7c0":"import xgboost as xgb\n\n# fit model no training data\nmodel = xgb.XGBClassifier()\nmodel.fit(X_train, y_train)\n# save model to file\nmodel.save_model(\"model.bst\")","5b241261":"# make predictions for test data\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))","354bc22d":"y_test.shape, X_test.shape","c36d43ce":"X_test.min()","31276a6a":"X_test.max()","299c412f":"X_test.mean()","b5e58678":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n# CV model\nmodel = xgb.XGBClassifier()\nkfold = KFold(n_splits=10, random_state=2020)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))","51500ebe":"xgb.__version__","0ddd9883":"from platform import python_version\n\nprint(python_version())","f74d9de5":"## <a id='3'>3. Modeling<\/a>\n","36ff4a26":"### Let's check 2nd file: \/kaggle\/input\/column_3C.csv","9f2f241f":"<html>\n<body>\n\n<p><font size=\"4\" color=\"Blue\">Remember the upvote button is next to the fork button, and it's free too! ;)<\/font><\/p>\n<p><font size=\"3\" color=\"Purple\">Don't hesitate to give your suggestions in the comment section<\/font><\/p>\n\n<\/body>\n<\/html>\n","bb45e598":"### Let's check 1st file: \/kaggle\/input\/column_2C.csv","8bc7f6f5":"# Final","bfaac654":"![](https:\/\/miro.medium.com\/max\/875\/1*r-M-roewYGxXpgvv_NDKhw.gif)\n#### [source](https:\/\/medium.com\/@miamarketplace\/mia-tutorial-part-i-uploading-a-model-b4c82ed1777) ","d3654811":"\n# Vertebral Column DataSet\n[Crisl\u00e2nio Mac\u00eado](https:\/\/medium.com\/sapere-aude-tech) -  Created May, 01th, 2020. Last Update, May, 01th, 2020\n\nKernel: [Vertebral Column Analysis ](https:\/\/www.kaggle.com\/caesarlupum\/starter-vertebral-column-dataset\/)\n\n\n- [**Github**](https:\/\/github.com\/crislanio)\n- [**Linkedin**](https:\/\/www.linkedin.com\/in\/crislanio\/)\n- [**Medium**](https:\/\/medium.com\/sapere-aude-tech)\n- [**Quora**](https:\/\/www.quora.com\/profile\/Crislanio)\n- [**Ensina.AI**](https:\/\/medium.com\/ensina-ai\/an%C3%A1lise-dos-dados-abertos-do-governo-federal-ba65af8c421c)\n- [**Hackerrank**](https:\/\/www.hackerrank.com\/crislanio_ufc?hr_r=1)\n- [**Blog**](https:\/\/medium.com\/@crislanio.ufc)\n- [**Personal Page**](https:\/\/crislanio.wordpress.com\/about)\n- [**Twitter**](https:\/\/twitter.com\/crs_macedo)\n\n----------\n----------","6e2697ec":"# Vertebral Column DataSet\n\nDownload: Data Folder-http:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00212\/\n\nData Set Description, http:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00212\/\n\n- Abstract: Data set containing values for six biomechanical features used to classify orthopaedic patients into 3 classes (normal, disk hernia or spondilolysthesis) or 2 classes (normal or abnormal).\n\n- **Data Set Characteristics**: Multivariate\n- **Attribute Characteristics**: Real\n- **Associated Tasks**: Classification\n- **Number of Instances**: 310\n- **Number of Attributes**: 6\n- **Missing Values?** N\/A\n- **Area**: N\/A\n- **Date Donated**: 2011-08-09\n","823d880b":"![](https:\/\/miro.medium.com\/max\/1773\/1*QuP5nFnvBNg-IrHvQ2-hCA.png)\n[mia is a platform for building and sharing machine learning apps](https:\/\/miamarketplace.com\/)","e600ca9f":"Let's take a quick look at what the data looks like:","6b480bd4":"Running this example summarizes the performance of the model on the test set","2f038ca5":"# XGBoost","7f6f5d11":"Let's take a quick look at what the data looks like:","1fe37466":"# Target Definition","deb79509":"# Bivariate relationship between the features"}}