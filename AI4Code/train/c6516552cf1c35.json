{"cell_type":{"9daaf5c2":"code","960552d5":"code","24738b6d":"code","13b16ed4":"code","b57baeca":"code","04db30f6":"code","dea82da6":"code","d7f5023b":"code","57aed9af":"code","e70aec96":"code","e8e2b322":"code","8f345133":"code","84610700":"code","098a2d03":"code","e0b88d28":"code","bf381e85":"code","b07a2b64":"code","a1aead47":"code","324cc1d0":"code","16f3b1f7":"code","f43b7f06":"code","a354bbed":"code","1bb5c883":"code","a49faa1a":"code","5ec6b12a":"code","168af20f":"code","ac641e61":"code","5c598c62":"code","72401c72":"code","b2f046a0":"code","d273ca1b":"code","9e8a8180":"code","fe31581f":"code","b77c0dea":"code","8a928972":"code","2552d54a":"code","bf63b635":"code","60c75955":"code","884ef3ef":"code","3da7578b":"code","740fccbe":"code","56803917":"code","7b3e2471":"code","9307018f":"code","11625e56":"code","bbcf6b8a":"code","a99fb4d2":"code","e364d914":"code","bb0ba6d9":"code","68866ae1":"code","7a0c5b82":"code","db01b59b":"code","23cd03d4":"code","88cb7694":"code","928698cc":"code","951cb00c":"code","3e8fa52b":"code","dc442f01":"code","ec2852ea":"code","72dc0db3":"code","ed234f82":"code","92798776":"code","05096182":"code","de8a46b5":"code","356dfce2":"code","6ebe6150":"code","a818be2f":"code","0af0e856":"code","9dc4794b":"code","32dd9b95":"code","81f14352":"code","4af16b84":"code","4865f105":"code","01c7fb63":"code","fb1f51a0":"code","0f3eced8":"code","7040c03f":"code","3d160156":"code","21a88c7b":"code","ddf11907":"code","b5fdd5df":"code","72d6a810":"code","fe2f913f":"code","6f948464":"code","fdd759c0":"code","33264314":"code","80960dc8":"code","fd90f9ac":"code","f03a4297":"markdown","2f21cd8e":"markdown","92d1cef4":"markdown","18a46456":"markdown","225b856c":"markdown","b77306d3":"markdown","19a70b2a":"markdown","73904827":"markdown","cc3478ab":"markdown","8b2c982e":"markdown","eced3d10":"markdown","9ba82c84":"markdown","98490b08":"markdown","2e863a27":"markdown","85844b6d":"markdown","25906412":"markdown","85c96c45":"markdown","331e047c":"markdown","5f57f79a":"markdown","98236d7e":"markdown","f4acd14e":"markdown","d8b39068":"markdown","52327ea9":"markdown","8bda209d":"markdown","05c6b544":"markdown","d4d95a4b":"markdown","ebfd8d40":"markdown","56881c1d":"markdown","5bfabbd5":"markdown","a266ad66":"markdown","f6006d90":"markdown","24fa143a":"markdown","925111e9":"markdown","d5991d14":"markdown","1b95f1aa":"markdown","13e5b490":"markdown","9015e979":"markdown","4ea4ae39":"markdown","41ade008":"markdown","aa1ab15f":"markdown","a93b76cf":"markdown","cea8be1a":"markdown","620e05ec":"markdown","fe02225d":"markdown","c50b5525":"markdown","37938736":"markdown","e00050f1":"markdown","7327c2cc":"markdown"},"source":{"9daaf5c2":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n\n%matplotlib inline\n\ninit_notebook_mode(connected=True)","960552d5":"df_anime = pd.read_csv('..\/input\/anime-recommendations-database\/anime.csv')","24738b6d":"df_anime","13b16ed4":"df_rating = pd.read_csv('..\/input\/anime-recommendations-database\/rating.csv')","b57baeca":"df_rating","04db30f6":"df_anime.isna().sum(), df_anime.isnull().sum()","dea82da6":"df_anime = df_anime.dropna()","d7f5023b":"df_anime.isna().sum(), df_anime.isnull().sum()","57aed9af":"df_rating.isna().sum(), df_rating.isnull().sum()","e70aec96":"unknown_index = df_anime[df_anime['episodes']=='Unknown'].index.to_list()","e8e2b322":"df_anime.loc[unknown_index,'episodes'] = 0\ndf_anime[df_anime['episodes']==0]","8f345133":"df_anime['episodes'] = df_anime['episodes'].astype('int')","84610700":"df_anime['episodes'].describe()","098a2d03":"df_anime.loc[unknown_index,'episodes'] = df_anime['episodes'].median()","e0b88d28":"df_anime['episodes'].describe()","bf381e85":"df_anime","b07a2b64":"len(df_anime['anime_id'].unique())","a1aead47":"#first of all get all genres \nall_genres = ''\nfor genre in df_anime['genre'].to_list():\n    all_genres += str(genre) + ', '","324cc1d0":"all_genres = all_genres.split(',')","16f3b1f7":"all_genres = list(map(lambda x: x.strip() ,all_genres))","f43b7f06":"all_genres = set(all_genres)","a354bbed":"all_genres.remove('')","1bb5c883":"for genre_name in all_genres:\n    list_code = list(map(lambda x: 1 if x.find(genre_name)+1 else 0,df_anime['genre'].to_list()))\n    df_anime.loc[:,'genre_%s'%genre_name] =list_code ","a49faa1a":"df_anime = df_anime.drop('genre',axis=1)","5ec6b12a":"count_genres = {genre: df_anime['genre_%s'%genre].sum() for genre in all_genres}","168af20f":"count_genres = {key: value for key, value in sorted(count_genres.items(),key=lambda x: x[1],reverse=True)}","ac641e61":"x = list(count_genres.keys())[:10]\ny = [count_genres[key] for key in x]","5c598c62":"plt.figure(figsize=(10,10))\nsns.barplot(x=x,y=y)","72401c72":"\nrate_genres = [(genre,df_anime[df_anime['genre_%s'%genre]==1]['rating'].mean()) for genre in all_genres]","b2f046a0":"rate_genres = sorted(rate_genres, key=lambda x: x[1], reverse=True)","d273ca1b":"len(rate_genres)","9e8a8180":"plt.figure(figsize=(11,10))\nplt.xlabel('Genre')\nplt.ylabel('Mean rating')\nsns.barplot(x=list(map(lambda x: x[0],rate_genres[:10])), y=list(map(lambda x: x[1],rate_genres[:10])))","fe31581f":"values = df_anime['type'].value_counts()","b77c0dea":"labels = values.index.to_list()\nvalues = values.to_list()\nvalues,labels","8a928972":"plt.figure(figsize=(10,10))\nplt.pie(values, labels=labels,autopct='%1.1f%%')\n_ = plt.legend(labels)","2552d54a":"rate_type = [(type_name, df_anime[df_anime['type']==type_name]['rating'].mean()) for type_name in df_anime['type'].unique()]","bf63b635":"rate_type = sorted(rate_type, key=lambda x: x[1],reverse=True)","60c75955":"plt.figure(figsize=(10,10))\nplt.xlabel('type')\nplt.ylabel('mean rating')\nsns.barplot(x=list(map(lambda x: x[0],rate_type)), y=list(map(lambda x: x[1],rate_type)))","884ef3ef":"sns.violinplot(df_anime['rating'])","3da7578b":"df_anime['rating'].describe()","740fccbe":"top5 = df_anime.sort_values(by=['members'], ascending=False)[:5]\ndown5 = df_anime.sort_values(by=['members'], ascending=False)[-5:]","56803917":"plt.figure(figsize=(10,10))\na = sns.barplot(x=top5['name'],y=top5['members'])\n_ = plt.xticks(a.get_xticks(), rotation=90)","7b3e2471":"plt.figure(figsize=(10,10))\na = sns.barplot(x=top5['name'],y=top5['rating'])\n_ = plt.xticks(a.get_xticks(), rotation=90)","9307018f":"plt.figure(figsize=(10,10))\na = sns.barplot(x=down5['name'],y=down5['members'])\n_ = plt.xticks(a.get_xticks(), rotation=90)","11625e56":"plt.figure(figsize=(10,10))\na = sns.barplot(x=down5['name'],y=down5['rating'])\n_ = plt.xticks(a.get_xticks(), rotation=90)","bbcf6b8a":"df_rating","a99fb4d2":"#find number of unique user\nlen(df_rating['user_id'].unique())","e364d914":"#find number of unique anime\nlen(df_rating['anime_id'].unique())","bb0ba6d9":"df_rating['mean_rating'] = df_rating.groupby('user_id')['rating'].transform('mean')\ndf_rating","68866ae1":"a = df_rating[df_rating['rating']>=df_rating['mean_rating']].apply(lambda x: 1,axis=1)","7a0c5b82":"index_liked = a.index.to_list()","db01b59b":"df_rating_liked = df_rating.iloc[index_liked,:]","23cd03d4":"\ndf_rating_liked = df_rating_liked.drop(['rating','mean_rating'], axis=1)","88cb7694":"df_rating_liked","928698cc":"anime_index = {df_anime.loc[idx,'anime_id']:idx for idx in df_anime.index}","951cb00c":"df_anime_clusterize = df_anime.drop(['name','anime_id'],axis=1)","3e8fa52b":"df_anime_clusterize = pd.get_dummies(df_anime_clusterize)","dc442f01":"num_cols= df_anime_clusterize[['episodes','rating','members']]\ncat_cols = df_anime_clusterize.drop(['episodes','rating','members'], axis=1)","ec2852ea":"scaler = StandardScaler()","72dc0db3":"num_cols = pd.DataFrame(scaler.fit_transform(num_cols))","ed234f82":"num_cols.columns = ['episodes_scale','rating_scale','members_scale']","92798776":"df_anime_clusterize = pd.concat([num_cols, cat_cols], axis=1, join='inner')","05096182":"scores = []\ninertia_list = np.empty(11)\n\nfor i in range(2,11):\n    print(i)\n    kmeans = MiniBatchKMeans(n_clusters=i, batch_size=50)\n    kmeans.fit(df_anime_clusterize)\n    inertia_list[i] = kmeans.inertia_\n    scores.append(silhouette_score(df_anime_clusterize, kmeans.labels_))","de8a46b5":"\n\nplt.plot(range(0,11),inertia_list,'-o')\nplt.xlabel('Number of cluster')\nplt.axvline(x=4, color='blue', linestyle='--')\nplt.ylabel('Inertia')\nplt.show()\n\n","356dfce2":"\n\nplt.plot(range(2,11), scores);\nplt.title('Results KMeans')\nplt.xlabel('n_clusters');\nplt.axvline(x=4, color='blue', linestyle='--')\nplt.ylabel('Silhouette Score');\nplt.show()\n\n","6ebe6150":"kmeans =  MiniBatchKMeans(n_clusters=4,batch_size=40)\nkmeans = kmeans.fit(df_anime_clusterize)\nclusters = kmeans.predict(df_anime_clusterize)\ndf_anime_clusterize['cluster'] = clusters\ndf_anime_clusterize['cluster'].value_counts()","a818be2f":"plot_df = pd.DataFrame(np.array(df_anime_clusterize.sample(4000)))\nplot_df.columns = df_anime_clusterize.columns","0af0e856":"perplexity = 30","9dc4794b":"tsne_2d = TSNE(n_components=2, perplexity=perplexity)\n\ntsne_3d = TSNE(n_components=3, perplexity=perplexity)","32dd9b95":"TCs_2d = pd.DataFrame(tsne_2d.fit_transform(plot_df.drop([\"cluster\"], axis=1)))\nTCs_3d = pd.DataFrame(tsne_3d.fit_transform(plot_df.drop([\"cluster\"], axis=1)))","81f14352":"TCs_2d.columns = [\"TC1_2d\",\"TC2_2d\"]\n\nTCs_3d.columns = [\"TC1_3d\",\"TC2_3d\",\"TC3_3d\"]","4af16b84":"plot_df = pd.concat([plot_df,TCs_2d,TCs_3d], axis=1, join='inner')","4865f105":"plot_df[\"1d_y\"] = 0","01c7fb63":"clusters = {}\nfor cluster_label in plot_df['cluster'].unique():\n    clusters[cluster_label] = plot_df[plot_df[\"cluster\"] == cluster_label]","fb1f51a0":"data = []\nfor key in clusters.keys():\n    data.append(go.Scatter(\n                    x = clusters[key][\"TC1_2d\"],\n                    y = clusters[key][\"TC2_2d\"],\n                    mode = \"markers\",\n                    name = \"Cluster %s\"%key,\n                    text = None))\n\ntitle = \"Visualizing Clusters in Two Dimensions Using T-SNE (perplexity=\" + str(perplexity) + \")\"\n\nlayout = dict(title = title,\n              xaxis= dict(title= 'TC1',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'TC2',ticklen= 5,zeroline= False)\n             )\n\nfig = dict(data = data, layout = layout)\n\niplot(fig)","0f3eced8":"data = []\nfor key in clusters.keys():\n    data.append(go.Scatter3d(\n                    x = clusters[key][\"TC1_3d\"],\n                    y = clusters[key][\"TC2_3d\"],\n                    z = clusters[key][\"TC3_3d\"],\n                    mode = \"markers\",\n                    name = \"Cluster %s\"%key,\n                    text = None))\n\n\ntitle = \"Visualizing Clusters in Three Dimensions Using T-SNE (perplexity=\" + str(perplexity) + \")\"\n\nlayout = dict(title = title,\n              xaxis= dict(title= 'TC1',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'TC2',ticklen= 5,zeroline= False)\n             )\nplt.figure(figsize=(20,20))\nfig = dict(data = data, layout = layout)\n\niplot(fig)","7040c03f":"anime_clusters = {i: [] for i in range(4)}\nfor anime_id, c_pred in zip(df_anime['anime_id'], df_anime_clusterize['cluster']):\n    anime_clusters[c_pred] +=[anime_id]","3d160156":"def find_user_centroid(data):\n    data = data[data['cluster']==data['cluster'].mode()[0]]\n    data = data.drop(['user_id','anime_id','cluster'], axis=1,errors='ignore')\n    return pd.DataFrame(data.mean(axis=0)).T","21a88c7b":"data = df_rating_liked[:100000]\ngrouped = data.groupby('user_id')","ddf11907":"train_data = {'user_id': [],'anime_id': []}\ntest_data = {'user_id': [],'anime_id': []}\nfor name,group in grouped:\n    if len(group)>1:\n        \n        train, test = train_test_split(group['anime_id'],test_size=0.2,random_state=42)\n\n        train_data['user_id']+=[name for _ in range(len(train))]\n        train_data['anime_id']+= list(train)\n\n        test_data['user_id']+=[name for _ in range(len(test))]\n        test_data['anime_id']+= list(test)\n    \n    ","b5fdd5df":"len(train_data['user_id']),len(test_data['user_id'])","72d6a810":"df_train = pd.DataFrame(train_data)\ndf_test = pd.DataFrame(test_data)\n","fe2f913f":"df_train = df_train.join(df_anime_clusterize, how='inner')","6f948464":"train_centroids = pd.DataFrame(columns = ['user_id']+list(df_anime_clusterize.columns))\n\nfor name,group in df_train.groupby('user_id'):\n    user_centroid = find_user_centroid(group)\n    user_centroid['user_id'] = name\n    user_centroid['cluster'] = group['cluster'].mode()[0]\n    train_centroids = train_centroids.append(user_centroid,ignore_index=True)\n#     print(group['cluster'])\ntrain_centroids","fdd759c0":"result = {}\nfor user_id in train_centroids['user_id'][:10]:\n    print('User id %s'%user_id)\n    user = train_centroids[train_centroids['user_id']==user_id]\n    result_dist = []\n   \n    for anime_id in anime_clusters[user['cluster'].iloc[0]]:\n        #iterate by all points in cluster. find 10 closer points to user centroid\n        \n        anime_point = df_anime_clusterize.loc[anime_index[anime_id],:].drop('cluster').to_numpy()\n        \n        result_dist.append((anime_id, np.linalg.norm(user.drop(['cluster','user_id'],axis=1)-anime_point)))\n        \n    \n    result[user_id] = sorted(result_dist,key=lambda x: x[1])[:10]","33264314":"test_data = pd.DataFrame(test_data)","80960dc8":"error_recom = {}\nfor user_id in list(result.keys())[:10]:\n    test_centroid = find_user_centroid(test_data[test_data['user_id']==user_id].join(df_anime_clusterize,how='inner'))\n    index = list(map(lambda x: anime_index[x[0]],result[user_id]))\n    result_centroid = find_user_centroid(df_anime_clusterize.iloc[index,:])\n    error_recom[user_id]  = np.linalg.norm(test_centroid-result_centroid)","fd90f9ac":"error_recom","f03a4297":"# Explore anime dataframe","2f21cd8e":"Top rating genres. Make plot","92d1cef4":"Build count plot top5 ","18a46456":"3d plot","225b856c":"Pick 4000 rows, to reduce time of a calculation","b77306d3":"The idea is that we first clusterize df_anime according to its parameters(without anime_id). Then, for example, we take the first user and his anime which he \u201cliked\u201d. We build the \"user centroid\" according to his anime. And then we look for the nearest points through the centroids of the clusters","19a70b2a":"Check missing values in df_rating","73904827":"Create dummy variables. we check if genre name in genre list -> column genre, then set 1 in other case set 0","cc3478ab":"Explore amount of ratings","8b2c982e":"Function that find mean vector \"user centroid\" of their view history","eced3d10":"Make plot of rating down5","9ba82c84":"Column \"episodes\" has a value \"Unknown\". it does not suit us.We replace this value by median.","98490b08":"make rating\\type plot","2e863a27":"2d plot","85844b6d":"# Prepare data for clusterize","25906412":"Scale numericals columns","85c96c45":"# In this notebook I tried to build a recommendation system that would recommend similar anime based on the user's browsing history","331e047c":"Define numerical and categorical columns","5f57f79a":"From theses result, i decide to pick 4 number of clusters","98236d7e":"Explore anime_id","f4acd14e":"# Display clusters","d8b39068":"Explore user_id","52327ea9":"Build dict with key cluster and a list of values anime in this cluster","8bda209d":"Explore genre","05c6b544":"Check missing values","d4d95a4b":"We have some missing values, i decide to drop rows. their number is small, our completeness of information has not suffered much","ebfd8d40":"Number of unique anime","56881c1d":"determine which anime the user liked, by determine mean user rating and if single rating bigger than mean, then user like this anime","5bfabbd5":"Imports:","a266ad66":"Make count plot","f6006d90":"# find the closest anime to user's liked anime","24fa143a":"Make plot of down5","925111e9":"Pick this value of perplexity. because return good result with good time of a calculation","d5991d14":"Top count genres. Make plot","1b95f1aa":"Work with genre. make dummy variables with one hot code","13e5b490":"Explore members","9015e979":"# Make clusters by MiniBatchKMeans","4ea4ae39":"Plan:\n* Explore the data\n* Check and clean the missing values\n* Prepare data for clustering\n* Make clusters(use minbatchkmeans)\n* Display clusters(use t-SNE)\n* Find nearest neighbors\n* Test our model","41ade008":"Create experiment data. take 100k from df_rating rows so it would take less time to calculate.","aa1ab15f":"Read the data","a93b76cf":"Make plot of rating top5","cea8be1a":"When we find users centroids, next step find nearest global centroid. we find distance to each centroids and sort them ascending=True, and pick top 3 centroids.","620e05ec":"# Explore rating dataframe","fe02225d":"Explore type anime. dummy variables make later","c50b5525":"When we create dummy variables, no longer needed a column \"genre\"","37938736":"create tsne for 2d and 3d plots","e00050f1":"When we get our recommendation let's check it","7327c2cc":"Structure of experiment data. we group by data by user, and take 75% to build recommendations, and other 25% we check how to close our recommendations to true value(anime which liked our user)"}}