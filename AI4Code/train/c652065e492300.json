{"cell_type":{"67ccf635":"code","6e020159":"code","60870b26":"code","d776eb76":"code","08819ada":"code","5dd0ad3d":"code","f8890767":"code","87c983a2":"code","22ce3f0d":"code","be467fb1":"code","f8244946":"code","5f584ff2":"code","ab545464":"code","1e1753fa":"code","e61b5b11":"code","cc16e973":"code","f1b91d8c":"code","1bb0ac49":"code","2bb5647f":"code","07ac12f3":"code","93c93b96":"code","ac9c285c":"code","6e6331f3":"code","20f1cd2f":"code","8e4629c0":"code","6ae16255":"code","7e26b932":"code","c9d9a1f0":"code","a93879de":"code","7676f50d":"code","d325f8b3":"code","82ee9230":"code","22871cfa":"code","88b8258b":"code","3e9f55e3":"code","ac6608f8":"code","bacfeb96":"code","efc45fce":"code","a6177ff3":"code","1f295bd4":"code","e7001914":"code","d7fb2b1d":"code","02c8beb6":"code","63549200":"code","bc0541bd":"code","0451daf1":"code","149faa1f":"code","ce1573e9":"code","1e943db5":"code","27cdc7ad":"code","d4bc3f65":"code","379475c4":"code","e26a9e38":"code","8715a8e3":"code","27a5112a":"code","fa8346ca":"code","442236c4":"code","f3838170":"code","334d6a8a":"code","fd6ba22e":"code","f86c2d52":"code","b3fcedcc":"code","c1834b0a":"code","e1a33d75":"code","d35d6e5d":"code","a1eb842a":"code","82083b13":"code","a8410b3b":"code","d693c87c":"code","f5c5b96d":"markdown","57f8cdc7":"markdown","56dce584":"markdown","b5a5f403":"markdown","a914b172":"markdown","8c1d063e":"markdown","1df21b10":"markdown","a7f87a33":"markdown","97aefcea":"markdown","d370927e":"markdown","6f0e288e":"markdown","88c659f9":"markdown","6ff7fd07":"markdown","0942e97f":"markdown","09df862e":"markdown","4c2fcbbd":"markdown","1a11fa25":"markdown","d887db9a":"markdown","5649abb6":"markdown","7f90adcb":"markdown","5a333ae5":"markdown","27c08dcd":"markdown","64d1f17d":"markdown","64818aff":"markdown","355fd1dc":"markdown","4888eecc":"markdown","93968f41":"markdown","6d2c4077":"markdown","1e36391b":"markdown","c002227c":"markdown","02a74169":"markdown","9023a39f":"markdown","b0c7774a":"markdown","94494e03":"markdown","2c8198cf":"markdown","29e0800e":"markdown","bd030372":"markdown","06f11c4a":"markdown","14e7d664":"markdown","a5c43817":"markdown","d009a88f":"markdown","4ebd21f9":"markdown","b0eb4696":"markdown","31b81f09":"markdown","d07c4c67":"markdown","7a157c15":"markdown","d90c0b30":"markdown","1aff286f":"markdown","0a2bae5b":"markdown","5f4090e0":"markdown","bd9177ed":"markdown","af43acf1":"markdown","af3219a8":"markdown","1a32a6d5":"markdown","0c296085":"markdown","a20aa60f":"markdown","f3beff92":"markdown","c85e403c":"markdown","d0daae33":"markdown","e0df95f0":"markdown","20b69368":"markdown","3b5cb873":"markdown","c492c75d":"markdown","c623422c":"markdown","5ea3ea61":"markdown","c2b701e4":"markdown","cbcbbf1e":"markdown","65dd4aa6":"markdown","0ca93992":"markdown","fbfb5b4f":"markdown","e1889083":"markdown","758e6f4f":"markdown","041cf4d6":"markdown","bc87abcf":"markdown","7963c190":"markdown","37577571":"markdown","bbb4daa8":"markdown"},"source":{"67ccf635":"import numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","6e020159":"train_data = pd.read_csv(\"..\/input\/titanic\/train.csv\")","60870b26":"train_data.head()","d776eb76":"train_data.tail()","08819ada":"train_data.columns","5dd0ad3d":"print('lenght of data is', len(train_data))","f8890767":"train_data.shape","87c983a2":"train_data.info()","22ce3f0d":"train_data.dtypes","be467fb1":"train_data[train_data.isnull().any(axis=1)].head()","f8244946":"np.sum(train_data.isnull().any(axis=1))","5f584ff2":"train_data.isnull().values.any()","ab545464":"train_data.isnull().sum()","1e1753fa":"NANColumns=[]\ni=-1\nfor a in train_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(train_data.columns[i],a)\n        NANColumns.append(train_data.columns[i])","e61b5b11":"carrier_count = train_data[\"Pclass\"].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of pclass')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('pclass', fontsize=12)\nplt.show()","cc16e973":"train_data[\"Pclass\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","f1b91d8c":"carrier_count = train_data[\"Survived\"].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of survived    ')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('survived    ', fontsize=12)\nplt.show()","1bb0ac49":"train_data[\"Survived\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","2bb5647f":"train_data[\"Sex\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","07ac12f3":"train_data[\"Age\"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","93c93b96":"train_data[\"Embarked\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","ac9c285c":"train_data.hist(figsize=(15,12),bins = 20, color=\"#107009AA\")\nplt.title(\"Features Distribution\")\nplt.show()","6e6331f3":"test_data = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nids_test_data = test_data['PassengerId'].values","20f1cd2f":"test_data.head()","8e4629c0":"test_data.tail()","6ae16255":"test_data.columns","7e26b932":"print('lenght of data is', len(test_data))","c9d9a1f0":"test_data.shape","a93879de":"test_data.info()","7676f50d":"test_data.dtypes","d325f8b3":"test_data[test_data.isnull().any(axis=1)].head()","82ee9230":"np.sum(test_data.isnull().any(axis=1))","22871cfa":"test_data.isnull().values.any()","88b8258b":"test_data.isnull().sum()","3e9f55e3":"NANColumns=[]\ni=-1\nfor a in test_data.isnull().sum():\n    i+=1\n    if a!=0:\n        print(test_data.columns[i],a)\n        NANColumns.append(test_data.columns[i])","ac6608f8":"carrier_count = test_data[\"Pclass\"].value_counts()\nsns.set(style=\"darkgrid\")\nsns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)\nplt.title('Frequency Distribution of pclass')\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('pclass', fontsize=12)\nplt.show()","bacfeb96":"test_data[\"Pclass\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","efc45fce":"test_data[\"Sex\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","a6177ff3":"test_data[\"Age\"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","1f295bd4":"test_data[\"Embarked\"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()","e7001914":"test_data.hist(figsize=(15,12),bins = 20, color=\"#107009AA\")\nplt.title(\"Features Distribution\")\nplt.show()","d7fb2b1d":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_data.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","02c8beb6":"train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","63549200":"train_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","bc0541bd":"train_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","0451daf1":"train_data[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","149faa1f":"g = sns.FacetGrid(train_data, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","ce1573e9":"grid = sns.FacetGrid(train_data, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","1e943db5":"grid = sns.FacetGrid(train_data, row='Embarked', col='Survived', size=2.2, aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","27cdc7ad":"y = train_data[\"Survived\"]","d4bc3f65":"all_data = pd.concat([train_data,test_data],axis=0).reset_index(drop=True)","379475c4":"all_data = all_data.drop([\"Survived\",\"PassengerId\"],axis=1)","e26a9e38":"def missing_value(df):\n    number = df.isnull().sum().sort_values(ascending=False)\n    number = number[number > 0]\n    percentage = df.isnull().sum() *100 \/ df.shape[0]\n    percentage = percentage[percentage > 0].sort_values(ascending=False)\n    return  pd.concat([number,percentage],keys=[\"Total\",\"Percentage\"],axis=1)\nmissing_value(all_data)","8715a8e3":"## Imputing the missing values with the Mode because mode fill the values with the most accuring values and best for the categorical features\nall_data[\"Cabin\"] = all_data[\"Cabin\"].transform(lambda x: x.fillna(x.mode()[0]))","27a5112a":"## Imputing the missing values with the Mode because mode fill the values with the most accuring values and best for the categorical features\nall_data[\"Embarked\"] = all_data[\"Embarked\"].transform(lambda x: x.fillna(x.mode()[0]))","fa8346ca":"#Mapping the Age into 5 groups from 0 to 4\nall_data['Age']=all_data.loc[ all_data['Age'] <= 16, 'Age'] = 0\nall_data['Age']=all_data.loc[(all_data['Age'] > 16) & (all_data['Age'] <= 32), 'Age'] = 1\nall_data['Age']=all_data.loc[(all_data['Age'] > 32) & (all_data['Age'] <= 48), 'Age'] = 2\nall_data['Age']=all_data.loc[(all_data['Age'] > 48) & (all_data['Age'] <= 64), 'Age'] = 3\nall_data['Age']=all_data.loc[ all_data['Age'] > 64, 'Age'] = 4 ","442236c4":"#Mapping the Fare into 5 groups from 0 to 4\nall_data['Fare']=all_data.loc[ all_data['Fare'] <= 7.91, 'Fare'] = 0\nall_data['Fare']=all_data.loc[(all_data['Fare'] > 7.91) & (all_data['Fare'] <= 14.454), 'Fare'] = 1\nall_data['Fare']=all_data.loc[(all_data['Fare'] > 14.454) & (all_data['Fare'] <= 31), 'Fare']   = 2\nall_data['Fare']=all_data.loc[ all_data['Fare'] > 31, 'Fare'] = 3\nall_data['Fare']=all_data['Fare'] = all_data['Fare'].astype(int)","f3838170":"#Checking missing values now\nmissing_value(all_data)","334d6a8a":"all_data = pd.get_dummies(all_data).reset_index(drop=True)","fd6ba22e":"n = len(y)\ntrain_data = all_data[:n]\ntest_data = all_data[n:]","f86c2d52":"X = np.array(train_data)\ny = np.array(y)","b3fcedcc":"rf = RandomForestClassifier(min_samples_leaf=1, min_samples_split=2)\nkf = KFold(n_splits=5)\noutcomes1 = []\nClassR=0\nConM=0\nfold = 0\ni=0\nconf_matrix_list_of_arrays = []\nfor train_index, test_index in kf.split(X,y):\n    i=i+1\n    print(\"KFold Split:\",i)\n    print('\\n')\n    fold += 1\n    Xtrain, Xtest = X[train_index], X[test_index]\n    ytrain, ytest = y[train_index], y[test_index]\n    print('Running time of algorithm')\n    %time rf.fit(Xtrain, ytrain)\n    predictions = rf.predict(Xtest)\n    accuracy = accuracy_score(ytest, predictions)\n    outcomes1.append(accuracy)\n    print(\"Accuracy of KFold \",i, \"is: \",accuracy)\n    print('\\n')\n    print(\"Classification Report of KFold \",i,\" is following:\")\n    print('\\n')\n    CR=classification_report(ytest, predictions)\n    print(CR)\n    print('\\n')\n    print(\"Confusion Matrix of KFold \",i,\" is following:\")\n    print('\\n')\n    CM=confusion_matrix(ytest, predictions)\n    conf_matrix_list_of_arrays.append(CM)\n    print(CM)\n    print('\\n')\n    print('\\n')\n\nprint('\\n')\nprint('Average Confusion Matrix')\naa = np.mean(conf_matrix_list_of_arrays, axis=0)\n\naaa = np.ceil(aa)\n\nb=pd.DataFrame(aaa)\nb=b.astype(int)\nlabels =['Not Survived','Survived']\n\nc=np.array(b)\n\nfig, ax = plot_confusion_matrix(conf_mat=c,figsize=(10, 10),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.show()\nprint('\\n')\nprint('\\n')\nmean_outcome1 = np.mean(outcomes1)\nprint(\"Total Average Accuracy of Random Forest Classifier is : {0}\".format(mean_outcome1)) ","c1834b0a":"rf = KNeighborsClassifier(n_neighbors=2)\nkf = KFold(n_splits=5)\noutcomes2 = []\nClassR=0\nConM=0\nfold = 0\ni=0\nconf_matrix_list_of_arrays = []\nfor train_index, test_index in kf.split(X,y):\n    i=i+1\n    print(\"KFold Split:\",i)\n    print('\\n')\n    fold += 1\n    Xtrain, Xtest = X[train_index], X[test_index]\n    ytrain, ytest = y[train_index], y[test_index]\n    print('Running time of algorithm')\n    %time rf.fit(Xtrain, ytrain)\n    predictions = rf.predict(Xtest)\n    accuracy = accuracy_score(ytest, predictions)\n    outcomes2.append(accuracy)\n    print(\"Accuracy of KFold \",i, \"is: \",accuracy)\n    print('\\n')\n    print(\"Classification Report of KFold \",i,\" is following:\")\n    print('\\n')\n    CR=classification_report(ytest, predictions)\n    print(CR)\n    print('\\n')\n    print(\"Confusion Matrix of KFold \",i,\" is following:\")\n    print('\\n')\n    CM=confusion_matrix(ytest, predictions)\n    conf_matrix_list_of_arrays.append(CM)\n    print(CM)\n    print('\\n')\n    print('\\n')\n\nprint('\\n')\nprint('Average Confusion Matrix')\naa = np.mean(conf_matrix_list_of_arrays, axis=0)\n\naaa = np.ceil(aa)\n\nb=pd.DataFrame(aaa)\nb=b.astype(int)\nlabels =['Not Survived','Survived']\n\nc=np.array(b)\n\nfig, ax = plot_confusion_matrix(conf_mat=c,figsize=(10, 10),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.show()\nprint('\\n')\nprint('\\n')\nmean_outcome2 = np.mean(outcomes2)\nprint(\"Total Average Accuracy of KNN Classifier is : {0}\".format(mean_outcome2)) ","e1a33d75":"rf = DecisionTreeClassifier(random_state=10)\nkf = KFold(n_splits=5)\noutcomes3 = []\nClassR=0\nConM=0\nfold = 0\ni=0\nconf_matrix_list_of_arrays = []\nfor train_index, test_index in kf.split(X,y):\n    i=i+1\n    print(\"KFold Split:\",i)\n    print('\\n')\n    fold += 1\n    Xtrain, Xtest = X[train_index], X[test_index]\n    ytrain, ytest = y[train_index], y[test_index]\n    print('Running time of algorithm')\n    %time rf.fit(Xtrain, ytrain)\n    predictions = rf.predict(Xtest)\n    accuracy = accuracy_score(ytest, predictions)\n    outcomes3.append(accuracy)\n    print(\"Accuracy of KFold \",i, \"is: \",accuracy)\n    print('\\n')\n    print(\"Classification Report of KFold \",i,\" is following:\")\n    print('\\n')\n    CR=classification_report(ytest, predictions)\n    print(CR)\n    print('\\n')\n    print(\"Confusion Matrix of KFold \",i,\" is following:\")\n    print('\\n')\n    CM=confusion_matrix(ytest, predictions)\n    conf_matrix_list_of_arrays.append(CM)\n    print(CM)\n    print('\\n')\n    print('\\n')\n\nprint('\\n')\nprint('Average Confusion Matrix')\naa = np.mean(conf_matrix_list_of_arrays, axis=0)\n\naaa = np.ceil(aa)\n\nb=pd.DataFrame(aaa)\nb=b.astype(int)\nlabels =['Not Survived','Survived']\n\nc=np.array(b)\n\nfig, ax = plot_confusion_matrix(conf_mat=c,figsize=(10, 10),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.show()\nprint('\\n')\nprint('\\n')\nmean_outcome3 = np.mean(outcomes3)\nprint(\"Total Average Accuracy of Decision Trees Classifier is : {0}\".format(mean_outcome3)) ","d35d6e5d":"a=pd.DataFrame()\na['outcomes1']=outcomes1\na['outcomes2']=outcomes2\na['outcomes3']=outcomes3\n\nplt.figure(figsize=(25, 10))\nplt.subplot(1,1,1)\nplt.plot(a.outcomes1.values,color='blue',label='Random Forest')\nplt.plot(a.outcomes2.values,color='green',label='KNN')\nplt.plot(a.outcomes3.values,color='red',label='Decision Trees')\nplt.title('Algorithms Comparison')\nplt.xlabel('Number of time')\nplt.ylabel('Accuracy')\nplt.legend(bbox_to_anchor=(1, 1))\nplt.show()","a1eb842a":"a=a.rename(columns={'outcomes1':'Random Forest', 'outcomes2':'KNN','outcomes3':'Decision Tree'})\na.plot(kind='bar',figsize=(25, 10))","82083b13":"a","a8410b3b":"final_model = RandomForestClassifier(min_samples_leaf=1, min_samples_split=2)\nfinal_model = final_model.fit(X,y)","d693c87c":"submission_results = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsubmission_results.iloc[:,1] = np.floor(np.expm1(final_model.predict(test_data)))\nsubmission_results.to_csv('submission_results', index=False)","f5c5b96d":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>As we can see from the graphs, features has good correlation with Pclass<\/strong><\/center><\/h2>\n        \n<\/div>","57f8cdc7":"# Frequency Distribution of pclass","56dce584":"# Five last records of data","b5a5f403":"- As we can see that most of old age peoples not survived","a914b172":"# Correlation Survived with Parch","8c1d063e":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong> Best Model is Random Forest as we can see that it performed well on cross validation<\/strong><\/center><\/h2>\n        \n<\/div>","1df21b10":"# Looking at correlated features with Survived ","a7f87a33":"# Decision Trees Machine Algorithm","97aefcea":"# Checking missing Values","d370927e":"# Shape of data","6f0e288e":"# Count of missing values","88c659f9":"# Looking at the test data missing values.","6ff7fd07":"# Exploratory data analysis of test data","0942e97f":"<div class=\"alert alert-block alert-success\">  \n<h1><center><strong> Submitting the classifications on test data<\/strong><\/center><\/h1>\n        \n<\/div>","09df862e":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong> Applying Cross Vaildation on each algorithm<\/strong><\/center><\/h2>\n        \n<\/div>","4c2fcbbd":"# Length of data","1a11fa25":"# <img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/6\/6e\/St%C3%B6wer_Titanic.jpg\">","d887db9a":"# Correlation Survived with Pclass","5649abb6":"1. # Importing Python Libraries \ud83d\udcd5 \ud83d\udcd7 \ud83d\udcd8 \ud83d\udcd9","7f90adcb":"- Higher fare paying passengers had better survival.\n- Port of embarkation correlates with survival rates. ","5a333ae5":"- Pclass=3 had most passengers, however most did not survive.\n- Infant passengers in Pclass=2 and Pclass=3 mostly survived. \n- Most passengers in Pclass=1 survived. \n- Pclass varies in terms of Age distribution of passengers.","27c08dcd":"# KNN Machine Algorithm","64d1f17d":"<div class=\"alert alert-block alert-danger\">  \n    <h1><strong>Loading training data<\/strong><\/h1>\n    <i><\/i>\n<\/div>","64818aff":"<div class=\"alert alert-block alert-info\">  \n<h2><center><strong>Features engineering and preparation<\/strong><\/center><\/h2>\n        \n<\/div>","355fd1dc":"# Looking at the train data missing values.","4888eecc":"# All features of train data distrubution ","93968f41":"# Exploratory data analysis of train data","6d2c4077":"# Frequency Distribution of top 10 age","1e36391b":"- We can see that the siblling with 1 is high correlated with survival but others are lower and zero","c002227c":"# Frequency Distribution of top 10 age","02a74169":"# Is there any missing values?","9023a39f":"# Comparison of all algorithms Results","b0c7774a":"- We can see that the correlation of Sex with survived is more than 0.5 among Sex=female so we are going to add this feature in training","94494e03":"# Coloumns\/features in data","2c8198cf":"# Five last records of data","29e0800e":"## Combining the train and test dataset","bd030372":"# Random Forest Machine Algorithm","06f11c4a":"# Shape of data","14e7d664":"<div class=\"alert alert-block alert-info\">  \n<h2><center><strong> Building the models for training and testing<\/strong><\/center><\/h2>\n        \n<\/div>","a5c43817":"## A function for checking the missing values","d009a88f":"# Counts of missing values in each column","4ebd21f9":"# Data information","b0eb4696":"# Age plot","31b81f09":"# Length of data","d07c4c67":"# Embarked plot","7a157c15":"# Data information","d90c0b30":"# Is there any missing values?","1aff286f":"## Imputing the Missing Values of all data","0a2bae5b":"## Extract the Survived out from the train data","5f4090e0":"# Correlation Survived with SEX","bd9177ed":"# Data types of all coloumns","af43acf1":"# Frequency Distribution of sex","af3219a8":"# Frequency Distribution of pclass","1a32a6d5":"# Data types of all coloumns","0c296085":"# Frequency Distribution of survived","a20aa60f":"# All features of test data distrubution ","f3beff92":"# Five top records of data","c85e403c":"- We can see that the Parch with 1 and 2 is high correlated with survival but others are lower and zero","d0daae33":"# Comparison of all algorithms Results","e0df95f0":"## Now splitting the data for training and testing with same index ID's","20b69368":"# Frequency Distribution of embarked","3b5cb873":"# Correlation Survived with SibSp","c492c75d":"# Count of missing values","c623422c":"## Coverting the categorical features into numeric form by applying the get_dummies function","5ea3ea61":"# Pclass plot","c2b701e4":"# Counts of missing values in each column","cbcbbf1e":"# Frequency Distribution of sex","65dd4aa6":"# <img src=\"https:\/\/thumbs.dreamstime.com\/t\/bright-colorful-thank-you-banner-vector-overlapping-letters-118244535.jpg\">","0ca93992":"# Getting Started with Titanic - Machine Learning from Disaster","fbfb5b4f":"### int = numrical features \n### object = categorical features ","e1889083":"# Checking missing Values","758e6f4f":"# Five top records of data","041cf4d6":"# Coloumns\/features in data","bc87abcf":"## Drop the Survived & PassengerId  columns","7963c190":"# Frequency Distribution of embarked","37577571":"- We can see that the correlation of pclass with survived is more than 0.5 among Pclass=1 so we are going to add this feature in training","bbb4daa8":"<div class=\"alert alert-block alert-danger\">  \n    <h1><strong>Loading testing data<\/strong><\/h1>\n    <i><\/i>\n<\/div>"}}