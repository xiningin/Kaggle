{"cell_type":{"085ae1d6":"code","438b1c1d":"code","7ce62b96":"code","ed020ebc":"code","a4f6b82b":"code","113977ea":"code","580e9fa0":"code","7cbaeefa":"code","15683568":"code","2836f7ea":"code","f738f93e":"code","9c2f2fc0":"code","1b4034c9":"code","e154eaf0":"code","665d6d15":"code","4ad12654":"markdown"},"source":{"085ae1d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","438b1c1d":"df=pd.read_csv('\/kaggle\/input\/logistic-regression\/Social_Network_Ads.csv')\ndf.head()","7ce62b96":"df.info()","ed020ebc":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndf['Gender']=le.fit(df['Gender']).transform(df['Gender'])","a4f6b82b":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(),annot=True,cmap='plasma')","113977ea":"df[['Purchased']].value_counts()","580e9fa0":"sns.pairplot(df)","7cbaeefa":"from sklearn.model_selection import train_test_split\nX=df.drop(['Purchased','User ID'],axis=1)\nY=df['Purchased']\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=4)","15683568":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(X_train,y_train)","2836f7ea":"yhat=lr.predict(X_test)","f738f93e":"from sklearn.metrics import accuracy_score,confusion_matrix\nax=confusion_matrix(yhat,y_test)\nsns.heatmap(ax,annot=True,cmap='plasma')\nplt.xlabel('Predict')\nplt.ylabel('Actual')","9c2f2fc0":"print(\"Model Score : \",accuracy_score(yhat,y_test))","1b4034c9":"from sklearn.neighbors import KNeighborsClassifier","e154eaf0":"def Kneigh(X_train,X_test,y_train,y_test):\n    \n    score=[]\n    \n    for i in range(1,10):\n        KN=KNeighborsClassifier(n_neighbors=i)\n        KN.fit(X_train,y_train)\n        KN_pred=KN.predict(X_test)\n        score.append(accuracy_score(KN_pred,y_test))\n    \n    max_score=max(score)\n    max_score_index=score.index(max_score)+1\n    print(f\"maximum score is {max_score} for neighbors ={max_score_index}\")","665d6d15":"Kneigh(X_train,X_test,y_train,y_test)","4ad12654":"# **Conclusion**\n**Best Model is K Nearest Neighbors with accuracy score 0.85 when we take neighbors =7**"}}