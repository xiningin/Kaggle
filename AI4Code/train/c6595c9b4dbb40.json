{"cell_type":{"89716fc1":"code","81ebc801":"code","66080212":"code","e717d9c2":"code","322f349c":"code","0404cafc":"code","97a38d7e":"code","54fcb82f":"code","b3ca5fb8":"code","22515ac8":"code","4ce207ac":"code","e24525d0":"code","db4a2f44":"code","ee0160dc":"code","5da4c39b":"code","6cc50056":"code","03976ef7":"code","bc846d5a":"markdown","18df8b1d":"markdown","00f0cfba":"markdown","529e4e74":"markdown","3d9812d1":"markdown","10f6e16c":"markdown"},"source":{"89716fc1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import datetime\nfrom sklearn.metrics import mean_squared_log_error\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\npaths = []\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        paths.append(os.path.join(dirname, filename))\n        #print(os.path.join(dirname, filename))\n        \nsorted(paths)","81ebc801":"train_df = pd.read_csv(sorted(paths)[2])\ntest_df = pd.read_csv(sorted(paths)[1])\nsubmission = pd.read_csv(sorted(paths)[0])","66080212":"train_df.head()","e717d9c2":"test_df.head()","322f349c":"submission.head()","0404cafc":"from statsmodels.tsa.statespace.sarimax import SARIMAX","97a38d7e":"count_len = len(train_df[train_df['Country_Region'] == 'Russia'])\n\ntrain_cc = []\ntrain_f = []\ncount = 0\nfor i in range(int(len(train_df) \/ count_len)):\n    train_cc.append(train_df.ConfirmedCases[count:count+count_len].values.tolist())\n    train_f.append(train_df.Fatalities[count:count+count_len].values.tolist())\n    count += count_len","54fcb82f":"from datetime import date\ndelta = (date(2020, 4, 15) - date(2020, 4, 2)).days","b3ca5fb8":"test_count = len(test_df[test_df['Country_Region'] == 'Russia']) - delta - 1\npredicted_cc = []\n\nfor i in range(len(train_cc)):\n    try:\n        data1 = train_cc[i]\n        model1 =  SARIMAX(data1, order=(1,1,0), seasonal_order=(1,1,0,12), measurement_error=True)\n        model1_fit = model1.fit(disp=False)\n        predicted1 = model1_fit.predict(len(data1), len(data1)+test_count)\n        predicted_cc.append(predicted1.tolist())\n    except:\n        data1 = train_cc[i]\n        model1 =  SARIMAX(data1,order=(1,1,0),seasonal_order=(1,1,0,12),measurement_error=True,enforce_stationarity=False)\n        model1_fit = model1.fit(disp=False)\n        predicted1 = model1_fit.predict(len(data1), len(data1)+test_count)\n        predicted_cc.append(predicted1.tolist())","22515ac8":"predicted_f = []\nfor i in range(len(train_f)):\n    try:\n        data2 = train_f[i]\n        model2 =  SARIMAX(data2,order=(1,1,0), seasonal_order=(1,1,0,12), measurement_error=True)\n        model2_fit = model2.fit(disp=False)\n        predicted2 = model2_fit.predict(len(data2), len(data2)+test_count)\n        predicted_f.append(predicted2.tolist())\n    except:\n        data2 = train_f[i]\n        model2 =  SARIMAX(data2,order=(1,1,0),seasonal_order=(1,1,0,12),measurement_error=True,enforce_stationarity=False)\n        model2_fit = model2.fit(disp=False)\n        predicted2 = model2_fit.predict(len(data2), len(data2)+test_count)\n        predicted_f.append(predicted2.tolist())","4ce207ac":"check_lenght = len(train_cc[0][-delta:]) + len(predicted_cc[0])\nif check_lenght == 43:\n    print('Check OK')\nelse:\n    print('Check failed')","e24525d0":"import itertools\n\npredicted_ConfirmedCases = []\npredicted_Fatalities = []\nfor i in range(int(len(train_df) \/ count_len)):\n    predicted_ConfirmedCases.append(train_cc[i][-delta:])\n    predicted_ConfirmedCases.append(predicted_cc[i])\n    predicted_Fatalities.append(train_f[i][-delta:])\n    predicted_Fatalities.append(predicted_f[i])\n    \npredicted_ConfirmedCases = list(itertools.chain.from_iterable(predicted_ConfirmedCases))\npredicted_Fatalities = list(itertools.chain.from_iterable(predicted_Fatalities))","db4a2f44":"submission['ConfirmedCases'] = predicted_ConfirmedCases\nsubmission['Fatalities'] = predicted_Fatalities\nsubmission.to_csv('submission.csv', index=False)","ee0160dc":"submission.head()","5da4c39b":"concl_df = pd.read_csv(sorted(paths)[1])\nconcl_feats = ['ForecastId', 'Country_Region', 'Date']\nconclusion = pd.concat([concl_df[concl_feats], submission[['ConfirmedCases', 'Fatalities']]], axis=1)","6cc50056":"region = 'Russia'\nconclusion[conclusion['Country_Region'] == region]","03976ef7":"day_cc = conclusion[conclusion['Country_Region'] == region]['ConfirmedCases'].values\n\nperday_cc = []\nfor i in range(1, len(day_cc)):\n    perday_cc.append(day_cc[i] - day_cc[i-1])\n    \nperday_cc_df = pd.DataFrame(perday_cc, columns=['CC_per_day'])\nperday_cc_df['Date'] = conclusion[conclusion['Country_Region'] == region]['Date'].values[1:]\n\nperday_cc_df.plot(x='Date', y='CC_per_day', kind='bar', grid=True, figsize=(14, 6), title=region);","bc846d5a":"# Train dataset creation","18df8b1d":"# SARIMAX models and predictions\nmodified concept from https:\/\/www.kaggle.com\/skeller\/arima-influenza-baselines","00f0cfba":"# Predictions example and some conclusions","529e4e74":"# Load Data","3d9812d1":"# Submission","10f6e16c":"### Russia for example: "}}