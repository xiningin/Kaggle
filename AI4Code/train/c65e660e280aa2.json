{"cell_type":{"1e2e3218":"code","3f87a436":"code","a488b829":"code","2e3262ba":"code","4330ac54":"code","f76013e2":"code","bd45a2f3":"code","c7859363":"code","b57483c7":"code","977fb9c0":"code","ef3296a9":"code","c110b978":"code","21c19663":"code","3415b075":"code","a10cf49c":"code","17668884":"code","11878efa":"code","f3eba61a":"code","8ffd42d8":"code","8ecc2d07":"code","acac5c31":"code","c8ef0ee4":"code","3cbcb636":"code","bb2222b9":"code","afdf875a":"code","bac404af":"code","268f9707":"code","ee8d6dbc":"code","e87dce56":"code","b53af3e8":"code","3743d157":"code","c721cb2b":"code","31486269":"code","74800f71":"code","52137f64":"code","be550c81":"code","bd1031a7":"code","489f8f24":"code","bc7f944f":"code","864f6423":"code","36675118":"code","236441e2":"code","c85aa118":"code","ff75fd7c":"code","52f0f9ec":"code","187bcdc9":"markdown","edfa2093":"markdown","b01bf3fa":"markdown","76d7a4a8":"markdown","5822e28e":"markdown","daaaf032":"markdown","21040f24":"markdown","2ef10049":"markdown","142812a0":"markdown","d27d5dd4":"markdown","ed68166e":"markdown","60272fff":"markdown","d0e0ca57":"markdown","2edf0f22":"markdown","3e6ca07e":"markdown","323f4865":"markdown","b77e6499":"markdown","d44b2bce":"markdown","bc2286cf":"markdown","7576148e":"markdown","c9b6dad9":"markdown","50ae2fbc":"markdown","ece77e90":"markdown","f5e9479f":"markdown","8ad21c0e":"markdown","71071941":"markdown","86ec6863":"markdown","cbee2f65":"markdown"},"source":{"1e2e3218":"# manipulation data\nimport pandas as pd\nimport numpy as np\n\n#visualiation data\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport matplotlib\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\n\n#default theme\nplt.style.use('ggplot')\nsns.set(context='notebook', style='darkgrid', palette='colorblind', font='sans-serif', font_scale=1, rc=None)\nmatplotlib.rcParams['figure.figsize'] =[8,8]\nmatplotlib.rcParams.update({'font.size': 15})\nmatplotlib.rcParams['font.family'] = 'sans-serif'","3f87a436":"train = pd.read_csv('..\/input\/black-friday\/train.csv')\ntest = pd.read_csv('..\/input\/black-friday\/test.csv')\ntrain.head(5)","a488b829":"train.shape","2e3262ba":"train.info()","4330ac54":"train.dtypes.value_counts().plot.pie(explode=[0.1,0.1,0.1],autopct='%1.2f%%',shadow=True)\nplt.title('type of our data');","f76013e2":"# show the numirical values\n\nnum_columns = [f for f in train.columns if train.dtypes[f] != 'object']\nnum_columns.remove('Purchase')\nnum_columns.remove('User_ID')\nnum_columns","bd45a2f3":"# show the categorical values\n\ncat_columns = [f for f in train.columns if train.dtypes[f] == 'object']\ncat_columns","c7859363":"train.describe(include='all')","b57483c7":"missing_values=train.isnull().sum()\npercent_missing = train.isnull().sum()\/train.shape[0]*100\n\nvalue = {\n    'missing_values':missing_values,\n    'percent_missing':percent_missing\n}\nframe=pd.DataFrame(value)\nframe","977fb9c0":"missing_values = train.isnull().sum()\nmissing_values = missing_values[missing_values > 0]\nmissing_values.sort_values(inplace=True)\nmissing_values.plot.pie(explode=[0.1,0.1],autopct='%1.1f%%',shadow=True)\nplt.title('our missing values');","ef3296a9":"train.Product_Category_2.value_counts()","c110b978":"train.Product_Category_2.describe()","21c19663":"# Replace using median \nmedian = train['Product_Category_2'].median()\ntrain['Product_Category_2'].fillna(median, inplace=True)","3415b075":"train.Product_Category_3.value_counts()","a10cf49c":"# drop Product_Category_3 \ntrain=train.drop('Product_Category_3',axis=1)","17668884":"missing_values=train.isnull().sum()\npercent_missing = train.isnull().sum()\/train.shape[0]*100\n\nvalue = {\n    'missing_values':missing_values,\n    'percent_missing':percent_missing\n}\nframe=pd.DataFrame(value)\nframe","11878efa":"train.hist(edgecolor='black',figsize=(12,12));","f3eba61a":"train.columns","8ffd42d8":"# pie chart \n\nsize = train['Gender'].value_counts()\nlabels = ['Male', 'Female']\ncolors = ['#C4061D', 'green']\nexplode = [0, 0.1]\n\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.pie(size, colors = colors, labels = labels, shadow = True, explode = explode, autopct = '%.2f%%')\nplt.title('A Pie Chart representing the gender gap', fontsize = 20)\nplt.axis('off')\nplt.legend()\nplt.show()","8ecc2d07":"sns.countplot(x=train.Gender)\nplt.title('Gender per transaction');","acac5c31":"ageData = sorted(list(zip(train.Age.value_counts().index, train.Age.value_counts().values)))\nage, productBuy = zip(*ageData)\nage, productBuy = list(age), list(productBuy)\nageSeries = pd.Series((i for i in age))\n\ndata = [go.Bar(x=age, \n               y=productBuy, \n               name=\"How many products were sold\",\n               marker = dict(color=['black', 'yellow', 'green', 'blue', 'red', 'gray', '#C4061D'],\n                            line = dict(color='#7C7C7C', width = .5)),\n              text=\"Age: \" + ageSeries)]\nlayout = go.Layout(title= \"How many products were sold by ages\")\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","c8ef0ee4":"palette=sns.color_palette(\"Set2\")","3cbcb636":"\nplt.rcParams['figure.figsize'] = (18, 9)\nsns.countplot(train['Occupation'], palette = palette)\nplt.title('Distribution of Occupation across customers', fontsize = 20)\nplt.xlabel('Occupation')\nplt.ylabel('Count')\nplt.show()","bb2222b9":"spent_by_occ = train.groupby(by='Occupation').sum()['Purchase']\nplt.figure(figsize=(20, 7))\n\nsns.barplot(x=spent_by_occ.index,y=spent_by_occ.values)\nplt.title('Total Money Spent per Occupation')\nplt.show()","afdf875a":"plt.rcParams['figure.figsize'] = (18, 9)\nsns.countplot(train['City_Category'], palette = palette)\nplt.title('Distribution of Cities across customers', fontsize = 20)\nplt.xlabel('Cities')\nplt.ylabel('Count')\nplt.show()","bac404af":"plt.figure(figsize=(20,6))\nprod_by_cat = train.groupby('Product_Category_1')['Product_ID'].nunique()\n\nsns.barplot(x=prod_by_cat.index,y=prod_by_cat.values, palette=palette)\nplt.title('Number of Unique Items per Category')\nplt.show()","268f9707":"category = []\nmean_purchase = []\n\n\nfor i in train['Product_Category_1'].unique():\n    category.append(i)\ncategory.sort()\n\nfor e in category:\n    mean_purchase.append(train[train['Product_Category_1']==e]['Purchase'].mean())\n\nplt.figure(figsize=(20,6))\n\nsns.barplot(x=category,y=mean_purchase)\nplt.title('Mean of the Purchases per Category')\nplt.xlabel('Product Category')\nplt.ylabel('Mean Purchase')\nplt.show()","ee8d6dbc":"# visualizing the different product categories\n\nplt.rcParams['figure.figsize'] = (15, 25)\nplt.style.use('ggplot')\n\nplt.subplot(4, 1, 1)\nsns.countplot(train['Product_Category_1'], palette = palette)\nplt.title('Product Category 1', fontsize = 20)\nplt.xlabel('Distribution of Product Category 1')\nplt.ylabel('Count')\n\nplt.subplot(4, 1, 2)\nsns.countplot(train['Product_Category_2'], palette = palette)\nplt.title('Product Category 2', fontsize = 20)\nplt.xlabel('Distribution of Product Category 2')\nplt.ylabel('Count')\n\n\nplt.show()","e87dce56":"# importing important libraries\nfrom scipy import stats\nfrom scipy.stats import norm","b53af3e8":"# plotting a distribution plot for the target variable\nplt.rcParams['figure.figsize'] = (20, 7)\nsns.distplot(train['Purchase'], color = 'green', fit = norm)\n\n# fitting the target variable to the normal curve \nmu, sigma = norm.fit(train['Purchase']) \nprint(\"The mu {} and Sigma {} for the curve\".format(mu, sigma))\n\nplt.title('A distribution plot to represent the distribution of Purchase')\nplt.legend(['Normal Distribution ($mu$: {}, $sigma$: {}'.format(mu, sigma)], loc = 'best')\nplt.show()\n","3743d157":"train = train.drop(['Product_ID','User_ID'],axis=1)","c721cb2b":"# checking the new shape of data\nprint(train.shape)\ntrain","31486269":"df_Gender = pd.get_dummies(train['Gender'])\ndf_Age = pd.get_dummies(train['Age'])\ndf_City_Category = pd.get_dummies(train['City_Category'])\ndf_Stay_In_Current_City_Years = pd.get_dummies(train['Stay_In_Current_City_Years'])\n\ndata_final= pd.concat([train, df_Gender, df_Age, df_City_Category, df_Stay_In_Current_City_Years], axis=1)\n\ndata_final.head()","74800f71":"data_final = data_final.drop(['Gender','Age','City_Category','Stay_In_Current_City_Years'],axis=1)\ndata_final","52137f64":"data_final.dtypes","be550c81":"from sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score","bd1031a7":"x=data_final.drop('Purchase',axis=1)\ny=data_final.Purchase","489f8f24":"print(x.shape)\nprint(y.shape)","bc7f944f":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)","864f6423":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","36675118":"from sklearn.linear_model import LinearRegression\n\nlm = LinearRegression()\nlm.fit(x_train, y_train)\nprint(lm.fit(x_train, y_train))","236441e2":"LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n         normalize=False)","c85aa118":"print('Intercept parameter:', lm.intercept_)\ncoeff_df = pd.DataFrame(lm.coef_, x.columns, columns=['Coefficient'])\nprint(coeff_df)","ff75fd7c":"predictions = lm.predict(x_test)\nprint(\"Predicted purchases (in dollars) for new costumers:\", predictions)","52f0f9ec":"from sklearn import metrics\n\nprint('MAE:', metrics.mean_absolute_error(y_test, predictions))\nprint('MSE:', metrics.mean_squared_error(y_test, predictions))","187bcdc9":"#### Product_Category_2","edfa2093":"# 3. data visualization","b01bf3fa":"### d) City_Category","76d7a4a8":"### B) Age","5822e28e":"## the purchase attribute which is our target variable","daaaf032":"## Black Friday Sales Prediction\n\nThis dataset comprises of sales transactions captured at a retail store. It\u2019s a classic dataset to explore and expand your feature engineering skills and day to day understanding from multiple shopping experiences. This is a regression problem. The dataset has 550,069 rows and 12 columns.\n\nProblem: Predict purchase amount.\n\n### Data Overview\nDataset has 537577 rows (transactions) and 12 columns (features) as described below:\n\n* User_ID: Unique ID of the user. There are a total of 5891 users in the dataset.\n* Product_ID: Unique ID of the product. There are a total of 3623 products in the dataset.\n* Gender: indicates the gender of the person making the transaction.\n* Age: indicates the age group of the person making the transaction.\n* Occupation: shows the occupation of the user, already labeled with numbers 0 to 20.\n* City_Category: User's living city category. Cities are categorized into 3 different categories 'A', 'B' and 'C'.\n* Stay_In_Current_City_Years: Indicates how long the users has lived in this city.\n* Marital_Status: is 0 if the user is not married and 1 otherwise.\n* Product_Category_1 to _3: Category of the product. All 3 are already labaled with numbers.\n* Purchase: Purchase amount.\n\n![](https:\/\/bestblackfridaydeal.net\/wp-content\/uploads\/2018\/08\/blackfriday-predictions-2018.jpg)","21040f24":"#### *Total Money Spent per Occupation*","2ef10049":"## finding missing values","142812a0":"### C) the occupation of customers","d27d5dd4":"### E) Products","ed68166e":"first we gonna drop the :\n1. User_ID\t\n2. Product_ID","60272fff":"## label encoding","d0e0ca57":"## split data","2edf0f22":"Category labels 1, 5, and 8 clearly have the most items within them. This could mean the store is known for that item, or that the category is a broad one.","3e6ca07e":"### Predicting the Amount Spent\n\nwe will use one of the simplest machine learning models, i.e. the linear regression model, to predict the amount spent by the customer on Black Friday.\n\nLinear regression represents a very simple method for supervised learning and it is an effective tool for predicting quantitative responses. You can find basic information about it right here: Linear Regression in Python\n\nThis model, like most of the supervised machine learning algorithms, makes a prediction based on the input features. The predicted output values are used for comparisons with desired outputs and an error is calculated. The error signal is propagated back through the model and model parameters are updating in a way to minimize the error. Finally, the model is considered to be fully trained if the error is small enough. This is a very basic explanation and we are going to analyze all these processes in details in future articles.","323f4865":"# data selection ","b77e6499":"Here we explore the products themselves. This is important, as we do not have labeled items in this dataset. Theoretically, a customer could be spending $5,000 on 4 new TVs, or 10,000 pens. This difference matters for stores, as their profits are affected. Since we do not know what the items are, let's explore the categories of the items.","d44b2bce":"### A) Gender","bc2286cf":"like we c her we had \n* 550068 rows \n* 12 coluns","7576148e":"A basic observation is that:\n\n* Product P00265242 is the most popular product.\n* Most of the transactions were made by men.\n* Age group with most transactions was 26-35.\n* City Category with most transactions was B\n\nbut we will cover each of these in more depth later","c9b6dad9":"# 1. import library","50ae2fbc":"Only Product_Category_2 and Product_Category_3 have null values which is good news. \nHowever Product_Category_3 is null for nearly 70% of transactions so it can't give us much information.\nso we gonna drop Product_Category_3","ece77e90":"## 1) LinearRegression","f5e9479f":"#### Product_Category_3","8ad21c0e":"Once again, the distribution of the mean amount spent within each occupation appears to mirror the distribution of the amount of people within each occupation. This is fortunate from a data science perspective, as we are not working with odd or outstanding features. Our data, in terms of age and occupation seems to simply make sense.","71071941":"### Feature Scaling","86ec6863":"![](https:\/\/img.ifunny.co\/images\/02d40d2464a8bf0aa895202243a08c1b39811c87e1a610b67801bd56afbcb683_3.jpg)","cbee2f65":"# 2. data analysis"}}