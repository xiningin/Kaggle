{"cell_type":{"0b6f7d07":"code","852e6a01":"code","a414aa68":"code","b8ee8652":"code","46328647":"code","fdb57de4":"code","7c29ff06":"code","d6f234bc":"code","39cca0df":"code","b00363b5":"code","a7885808":"code","c648baca":"code","76b0e80d":"code","421e4512":"code","4de19c49":"code","ca054e00":"code","9e7aa8f4":"code","b64a29ee":"code","d5e31a51":"code","becfbfaa":"code","1bd32560":"code","a923cb84":"code","8e067776":"code","3879ea2d":"code","6826c681":"code","5d3124c1":"code","9de46294":"code","c087d9ea":"code","20148071":"code","0c115f74":"code","6ea55d2b":"code","42e59b16":"code","573fb8ac":"code","3356a124":"markdown","a858631e":"markdown","722a4a84":"markdown","3b78f33a":"markdown","1bfdb3c2":"markdown","51b70937":"markdown","519d4414":"markdown","6a00efc8":"markdown","f1eb1575":"markdown","eac1876c":"markdown","516062e2":"markdown","220f700b":"markdown","102b3a32":"markdown","4fe2b065":"markdown","ba865ae7":"markdown","d04c7722":"markdown","07ca0cdf":"markdown","ffc77594":"markdown","179404ba":"markdown","c16c7efd":"markdown","8c80a47f":"markdown","2de1b709":"markdown","c5e01f3b":"markdown","eb44723c":"markdown","ac177e0e":"markdown","04523d6c":"markdown","54daea23":"markdown","2e51b280":"markdown","1b64e99d":"markdown","f28c9232":"markdown","66ad84b7":"markdown","60622867":"markdown","e033988f":"markdown"},"source":{"0b6f7d07":"# Import required libraries\nfrom scipy.stats import norm\nfrom scipy.stats import t\nimport numpy as np\nimport pandas as pd\nfrom numpy.random import seed\nimport matplotlib.pyplot as plt\nimport seaborn as sns","852e6a01":"# Import the csv file that was cleaned in the prior project:\ndf = pd.read_csv('\/kaggle\/input\/us-accidents\/US_Accidents_Dec19.csv')","a414aa68":"#Check the head of the DataFrame\ndf.head()","b8ee8652":"# Check the name and the type of each column\ndf.info()","46328647":"# Percent of severity\nf,ax=plt.subplots(1,2,figsize=(9,4))\ndf['Severity'].value_counts().plot.pie(explode=[0,0,0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Percentage Severity Distribution')\nax[0].set_ylabel('Count')\nsns.countplot('Severity',data=df,ax=ax[1],order=df['Severity'].value_counts().index)\nax[1].set_title('Count of Severity')\nplt.show()","fdb57de4":"# Now we will make a HeatMap by using Seaborn Library\nfig=sns.heatmap(df[['TMC','Severity','Start_Lat','Start_Lng','Distance(mi)','Temperature(F)','Wind_Chill(F)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(mph)','Precipitation(in)']].corr().round(2),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':10})\n# Seaborn Heatmap cuts the top and bottom rows to half,to fix the error, y_lims are changed\nbottom, top = fig.get_ylim()\nfig.set_ylim(bottom + 0.5, top - 0.5)\nfig=plt.gcf()\nfig.set_size_inches(12,12)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","7c29ff06":"# Firstly, we will check the distribution of the accidents ove the states\nplt.figure(figsize=(18,6))\ndf['State'].value_counts().plot(kind='bar', edgecolor = 'k')","d6f234bc":"# We will find 10 states with the highest number of accidents:\ndf.State.value_counts().head(10)","39cca0df":"# We will draw pieplots and barplots for the distributions of severities in each of these 10 states.\n# We will perform a for loop to choose the date for these states\nfor s in [\"CA\",\"TX\", \"FL\",\"NY\",\"PA\",\"SC\", \"MI\",\"NC\",\"GA\",\"IL\"]:\n    plt.subplots(1,2,figsize=(12,5))\n    plt.suptitle('Accident Severity in ' + s,fontsize=16)\n    plt.subplot(1,2,1)\n    df.loc[df[\"State\"] == s]['Severity'].value_counts().plot.bar(width=0.5,color='y',edgecolor='k',align='center',linewidth=1)\n    plt.xlabel('Severity',fontsize=16)\n    plt.ylabel('Accident Count',fontsize=16)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.subplot(1,2,2)\n    df.loc[df[\"State\"] == s]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","b00363b5":"# We will define the top severity state by getting the mean of the severities of each states\ndf_top_Severity_State = df.groupby('State').agg({'Severity': 'mean'}).sort_values('Severity').reset_index()","a7885808":"# Now we can show the mean severities of each state on a bar graph\nplt.figure(figsize=(18,6))\nsns.barplot(y=\"Severity\", x=\"State\", data=df_top_Severity_State,edgecolor='k')\nplt.title(\"Mean Severity of Each State\", fontsize=20)\nplt.show()","c648baca":"# Let'scheck the accident data on a map by coloring each state with a different color\nplt.figure(figsize=(12,8))\nsns.scatterplot(x='Start_Lng', y='Start_Lat',hue='State', data=df, s=10, legend = False)\nplt.xlabel('Longitude')\nplt.ylabel('Latitude)')\nplt.show()","76b0e80d":"# If we remove 'hue'=State, we can observe which areas and which roads have more accidents than the others\nplt.figure(figsize=(18,12))\nplt.title('Most Hits per Area', fontsize=20)\nplt.xlabel('Start Longitude')\nplt.ylabel('Start Latitude')\nplt.plot(df.Start_Lng, df.Start_Lat, \".\", alpha=0.5, ms=1)\nplt.show()","421e4512":"# Here we can see the map of the severity of the accidents in Texas colorcoded with the severity of the accidents\nplt.figure(figsize=(10,8))\nsns.scatterplot(x='Start_Lng', y='Start_Lat',hue='Severity', data=df.loc[df.State=='TX'], s=10)\nplt.xlabel('Longitude')\nplt.ylabel('Latitude)')\nplt.title('Severity of Accidents in Texas', fontsize=20)\nplt.show()","4de19c49":"# Here we can see the map of the severity of the accidents in Los Angeles colorcoded with the severity of the accidents\nplt.figure(figsize=(10,8))\nsns.scatterplot(x='Start_Lng', y='Start_Lat',hue='Severity', data=df.loc[df.City=='Los Angeles'], s=10)\nplt.xlabel('Longitude')\nplt.ylabel('Latitude)')\nplt.title('Severity of Accidents in Los Angeles', fontsize=20)\nplt.show()","ca054e00":"# Now, we will plot a bar plot to visualize to see which cities have the highest number of accidents\ntop_ten_cities = df['City'].value_counts().head(10)\nfig, ax=plt.subplots(figsize=(16,7))\ntop_ten_cities.plot.bar(width=0.5,edgecolor='k',align='center',linewidth=2)\nplt.xlabel('Cities',fontsize=20)\nplt.ylabel('Number of Accidents',fontsize=20)\nax.tick_params(labelsize=20)\nplt.title('10 US Cities with the Highest Number of Accidents',fontsize=25)\nplt.grid()","9e7aa8f4":"# Sort the cities according to the amount of accidents\ncity_vals = df['City'].value_counts()\n# Choose the cities with more than 100 accidents\nbig_cities = city_vals.index.values[city_vals>100]\ndf_top_Severity_City = df.groupby('City').agg({'Severity': 'mean'})\n\n# Create a dictionary with city as a key and mean severity as values\nbig_city_severities ={}\nfor city, row in df_top_Severity_City.iterrows():\n    if city in big_cities:\n        big_city_severities[city] = row['Severity'] \n        \n# Convert the dictionary to Pandas Series\nx = pd.Series(big_city_severities)\n\n#Plot the graph. We will use logyscale since the mean values are preety close to each other\nfig, ax=plt.subplots(figsize=(16,7))\nx.sort_values(ascending = False).head(20).plot(kind = 'bar', logy=True)\nplt.title(\"Top 10 Cities with Highest Mean Severities\", fontsize=20)","b64a29ee":"# Top 10 Accident conditions\nf,ax=plt.subplots(1,2,figsize=(12,6))\ndf_top_weather_conditions = df.groupby('Weather_Condition').size().sort_values(ascending=False).iloc[:10]\ndf_top_weather_conditions.plot.pie(explode=[0,0,0.1,0,0,0,0,0,0,0],ax=ax[0],autopct='%1.1f%%',shadow=True)\nax[0].set_title('Weather Conditions')\nax[0].set_ylabel('Count')\ndf['Weather_Condition'].value_counts().sort_values(ascending=False).head(10).plot.bar(width=0.5,ax=ax[1],edgecolor='k',align='center',linewidth=2)\nax[1].set_title('Weather Conditions')\nax[1].set_ylabel('Count')\nplt.show()","d5e31a51":"# This table shows the number of accidents for each conditions\npd.DataFrame(df_top_weather_conditions) ","becfbfaa":"# We will perform a for loop to plot one pieplot and one bar plot for each conditions\nfor s in [\"Clear\",\"Overcast\",\"Mostly Cloudy\",\"Partly Cloudy\",\"Scattered Clouds\",\"Light Rain\",\"Haze\",\"Light Snow\",\"Rain\",\"Fog\",\"Heavy Rain\",\"Snow\"]:\n    plt.subplots(1,2,figsize=(12,5))\n    plt.suptitle('Accident Severity Under ' + s,fontsize=16)\n    plt.subplot(1,2,1)\n    df.loc[df[\"Weather_Condition\"] == s]['Severity'].value_counts().plot.bar(width=0.5,color='y',edgecolor='k',align='center',linewidth=1)\n    plt.xlabel('Severity',fontsize=16)\n    plt.ylabel('Accident Count',fontsize=16)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.subplot(1,2,2)\n    df.loc[df[\"Weather_Condition\"] == s]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","1bd32560":"# Percent of Side Types\nf,ax=plt.subplots(1,2,figsize=(9,4))\ndf['Side'].value_counts().plot.pie(explode=[0,0.1,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Side types')\nax[0].set_ylabel('Count')\nsns.countplot('Side',data=df,ax=ax[1],order=df['Side'].value_counts().index)\nax[1].set_title('Count of Side')\nplt.show()","a923cb84":"for s in [\"R\",\"L\"]:\n    plt.subplots(1,2,figsize=(12,5))\n    plt.suptitle('Accident Severity on ' + s+\" Side\",fontsize=16)\n    plt.subplot(1,2,1)\n    df.loc[df[\"Side\"] == s]['Severity'].value_counts().plot.bar(width=0.5,color='y',edgecolor='k',align='center',linewidth=1)\n    plt.xlabel('Severity',fontsize=16)\n    plt.ylabel('Accident Count',fontsize=16)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.subplot(1,2,2)\n    df.loc[df[\"Side\"] == s]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","8e067776":"# Firstly we will identify columns with boolean datatypes\nbool_cols = [col for col in df.columns if df[col].dtype ==np.dtype('bool')]\nbools = df[bool_cols].sum(axis=0)\n\n# Now we will plot a pieplot.\nbools.plot.pie(autopct='%1.1f%%',shadow=True,figsize=(10,10))\nplt.ylabel('')\nplt.title('Proximity to Traffic Object');","3879ea2d":"not_one_hot = df[bool_cols][df[bool_cols].sum(axis=1) > 1]\nprint('There are {} non one hot metadata rows, which are {:.1f}% of the data'.format(len(not_one_hot),100*len(not_one_hot)\/len(df)))","6826c681":"# Now we will check how the distribution of severity differs for True and False values for each booleans.\ndf_list=[]\ndef  bool_severity(col):\n    df_bool = df.groupby([col,'Severity'])['ID'].count()\n    df_bool = df_bool.unstack(col)\n    df_list.append(df_bool)\nfor col in bool_cols:\n    bool_severity(col)\nfor i in range(len(bool_cols)):\n    plt.tight_layout()\n    df_list[i].plot(kind='pie',subplots=True,autopct='%.1f%%',pctdistance=1.4,figsize=(10,10),title = bool_cols[i])","5d3124c1":"df['Start_Time'] = pd.to_datetime(df['Start_Time'], format=\"%Y\/%m\/%d %H:%M:%S\")\ndf['DayOfWeekNum'] = df['Start_Time'].dt.dayofweek\ndf['DayOfWeek'] = df['Start_Time'].dt.weekday_name\ndf['MonthDayNum'] = df['Start_Time'].dt.day\ndf['HourOfDay'] = df['Start_Time'].dt.hour","9de46294":"fig, ax=plt.subplots(figsize=(12,6))\ndf['DayOfWeek'].value_counts(ascending=False).plot.bar(width=0.5,edgecolor='k',align='center',linewidth=2)\nplt.xlabel('Day of the Week',fontsize=16)\nplt.ylabel('Number of accidents',fontsize=16)\nax.tick_params(labelsize=20)\nplt.title('Accident on Different Days of Week',fontsize=20)\nplt.grid()\nplt.show()","c087d9ea":"# We will check the severity distribution of the accidents on Day Of Weeks\nfor s in [\"Monday\",\"Tuesday\",\"Wednesday\", \"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]:\n    plt.subplots(1,2,figsize=(12,5))\n    plt.suptitle('Accident Severity on ' + s,fontsize=16)\n    plt.subplot(1,2,1)\n    df.loc[df[\"DayOfWeek\"] == s]['Severity'].value_counts().plot.bar(width=0.5,color='y',edgecolor='k',align='center',linewidth=1)\n    plt.xlabel('Severity',fontsize=16)\n    plt.ylabel('Accident Count',fontsize=16)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.subplot(1,2,2)\n    df.loc[df[\"DayOfWeek\"] == s]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","20148071":"# Sketch a Boxplot for Severity vs. Wind Chill(F)\nplt.figure(figsize=(12,6))\nsns.boxplot(x=\"Severity\", y=\"Wind_Chill(F)\", data=df)\nplt.ylabel('Wind_Chill(F)', fontsize=12)\nplt.xlabel('Severity', fontsize=12)\nplt.xticks(rotation='vertical')\nplt.title(\"Severity - Wind Chill(F)\",fontsize=20)\nplt.show()","0c115f74":"# Sketch a Violin Plot for Severity vs. Temperature(F)\nplt.figure(figsize=(12,6))\nsns.violinplot(x='Severity', y='Temperature(F)', data=df)\nplt.xlabel('Severity', fontsize=12)\nplt.ylabel('Temperature(F)', fontsize=12)\nplt.title(\"Severity - Temperature(F)\",fontsize=20)\nplt.show()","6ea55d2b":"factors = ['Temperature(F)','Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)']\n\nfor factor in factors:\n    # remove some of the extreme values\n    factorMin = df[factor].quantile(q=0.0001)\n    factorMax = df[factor].quantile(q=0.9999)\n    # print df[\"Severity\"].groupby(pd.cut(df[factor], np.linspace(factorMin,factorMax,num=20))).count()\n    plt.subplots(figsize=(12,6))\n    for s in np.arange(1,5):\n        df[\"Severity\"].groupby(pd.cut(df[factor], np.linspace(factorMin,factorMax,num=20))).mean().plot()\n        plt.title(\"Mean Severity as a Function of \" + factor, fontsize=16)\n        plt.xlabel(factor + \" Range\", fontsize=16)\n        plt.ylabel(\"Mean Severity\", fontsize=16)\n        plt.xticks(fontsize=11)\n        plt.yticks(fontsize=16)","42e59b16":"# We will import the libraries\nfrom scipy import stats\nfrom scipy.stats import ttest_ind","573fb8ac":"stats.ttest_ind(df['Severity'][df['Junction'].astype(bool)].dropna(), df['Severity'][~df['Junction'].astype(bool)].dropna(), equal_var=False)","3356a124":"The problem of the project is to predict the severity of the car accident from the other given variables. Prior to this step of the project, we have cleaned and the data of the US Car Accidents 2016-2019. In this step, we will observe some visualization techniques that which variables may affect the severity of the accidents more.","a858631e":"Severity is a discrete numerical variable in ordinal level, so mean severity my have meaning in the context:","722a4a84":"These graphs clearly state that the severity distribution differs from state to state. So state is a variable that may affect the severity of an accident.","3b78f33a":"The other question is how the amount of accidents are distributed in different weather condions. also, we would like to see how some common weather conditions affect the severity of accidents","1bfdb3c2":"Even though this graph can shows the distribution of the accidents in each state, it does not clearly shows the clusters.","51b70937":"Now, we will check which cities have the highest mean of severities. One of the problem is many cities have only one car accident data, and if their accident's severity is 4, their mean will be 4, which will be misleading. We will sort the cities which has more than 100 car accidents to see which cities have a high number of accidents with a high mean severity.","519d4414":"This distribution suggest that the majority of the severities of accidents are labeled as 2 or 3.","6a00efc8":"### 6. How the Number of Accidents & Severities are Associated with Days of Week?","f1eb1575":"### 7. Visualization of Severity vs. Contnious Numeric Variables","eac1876c":"Firstly we will check how the distribution of the severity","516062e2":"These graphs suggest that the waether conditions have a significant impact on severity of an accident.","220f700b":"### 2. What is the relationship between location and the severity of accidents?","102b3a32":"The graph above shows all the accidents in the USA, and we can easily see that the accidents are clustered in metropolitan areas and major highways. However, it does not indicate the severity of accidents.","4fe2b065":"We can observe from this graph that the number of accidents significantly differ from state to state. However, the other part of the question is whether the severity of an accident is associated with the state or not. In order to answer this question, we will check the distribution of the severities of the accidents in 10 states with the highest number of accidents.","ba865ae7":"This graph suggest that more accidents happens on right side. However, does the side have an affect on the severity?","d04c7722":"### 3. Severity of Accidents with different weather conditions","07ca0cdf":"The second question is how the number and severity of accidents are associated with the location. The first graph we used to see the number of accidents for each state:","ffc77594":"One problem about this pie chart is, some of the accidents may have more than one boolean values.","179404ba":"In order to show the severity of an accident, we choose the State of Texas to see how more severe accidents are clustered:","c16c7efd":"The graph above suggest that the number of accidents on weekdays are pretty close, but there are significantly less accidents on the weekends.","8c80a47f":"In this dataset, there are some boolean values that determines whether the accident happened near a traffic signal, stop sign, etc. We will See how proximity to an object affects the accident number and severity","2de1b709":"This heatmap does not suggest any strong correlation between a numerical variable and severity of an accident.","c5e01f3b":"According to the graphs, the accident severity changes between the weekdays slightly. However, the severity distribution on weekends are significantly different than the weekdays. We can perform similar analysis for other cyclical variables as months, hour, etc.","eb44723c":"### 8. Perform a t-test ","ac177e0e":"### 4. Does Side Type Has an Effect on Accidents & Severity? ","04523d6c":"### 5. How does Boleans Affect the Accident & Severity","54daea23":"We can perform a similar scatter plots to see the distibution of severities of accidents in each city. I chose Los Angeles, since Los Angeles is a unique name for Los Angeles, CA in this dataset","2e51b280":"This graph suggests that the Left Side accidents are more likely to be less severe.","1b64e99d":"We can perform a heatmap to check which of the \"float64\" and \"int64\"(not dummy variables) columns are correlated with the severity the most.","f28c9232":"## Capstone Project: Statistical Data Anlaysis","66ad84b7":"We can perform t-test to see if the severity changes significantly between two groups. However, the dataset is very large with more than 1 million values, which makes the standard error very small. We expect to get very large t-values. Just to see the significance, I will perform a","60622867":"### 1. What is the correlation between numerical variables and severity","e033988f":"In the following graph, we will observe how the mean severity changes with respect to some continuous variables:"}}