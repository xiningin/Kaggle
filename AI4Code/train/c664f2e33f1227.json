{"cell_type":{"bcb03ea4":"code","b5400159":"code","6d6c881b":"code","140f5e29":"code","af116b47":"code","b4bdc664":"code","800f21ad":"code","dfd731e0":"code","6b21994b":"code","b5308788":"code","9811a2d4":"code","f45f2884":"code","94a609c3":"code","bd79c164":"code","43dac20d":"code","ccd16216":"code","882c32a5":"code","3167fe67":"code","c0a6638e":"code","3dc68702":"code","5c16bdc0":"code","5669521e":"code","ccfbef0e":"code","77d6f665":"code","417dd276":"code","1fc934de":"markdown","d54eccc0":"markdown"},"source":{"bcb03ea4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5400159":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nimport warnings\nimport datetime\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nwarnings.filterwarnings(action='ignore')","6d6c881b":"tas = pd.read_csv('..\/input\/chile-temperature-daily-stations-2018\/cr2_tasDaily_2018.csv')\ntas.head(15)","140f5e29":"for n in range(0,14):\n        print(tas['codigo_estacion'][n],':',tas['330021'][n])","af116b47":"def data_processing(df,station):\n    df = df[14:] #drop\n    df=df.replace(float(-9999),np.nan)\n    df=df.replace('-9999',np.nan)\n    print(df['01202012'].isna().sum(),' NaN values of ',df.shape[0])\n    df = df[['codigo_estacion',station]]\n    df['codigo_estacion'] =  pd.to_datetime(df['codigo_estacion'], format='%Y-%m-%d')\n    df=df.dropna().reset_index().drop(columns=['index']).rename(columns={'codigo_estacion':'datetime'}).set_index('datetime')\n    \n    return df","b4bdc664":"df=data_processing(tas,'330021')","800f21ad":"plt.style.use('fivethirtyeight')\n# Color pallete for plotting\ncolor_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\",\n             \"#00BA38\", \"#00C19F\", \"#00B9E3\",\n             \"#619CFF\", \"#DB72FB\"]\ndf.plot(style='.', figsize=(15,15), color=color_pal[0], title='Temperature')\nplt.show()","dfd731e0":"split_date = datetime.date(2002, 1, 1).isoformat()\nX_train = df.loc[df.index <= split_date].copy()\nX_test = df.loc[df.index > split_date].copy()","6b21994b":"X_test \\\n.rename(columns={'330021': 'TEST SET'}) \\\n.join(X_train.rename(columns={'330021': 'TRAINING SET'}),how='outer') \\\n.plot(figsize=(15,5), title='Temperature Chile station', style='.')\nplt.show()","b5308788":"X_train = X_train.reset_index().rename(columns={'datetime':'ds','330021':'y' })\nX_test = X_test.reset_index().rename(columns={'datetime':'ds','330021':'y' })","9811a2d4":"print(len(X_train))\nprint(len(X_test))","f45f2884":"model = Prophet()\nmodel.fit(X_train)\n\ntas_predict = model.predict(X_test)\ntas_predict.head()\n","94a609c3":"# Plot the forecast\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nfig = model.plot(tas_predict,\n                 ax=ax)\nplt.show()","bd79c164":"# Plot the components of the model\nfig = model.plot_components(tas_predict)","43dac20d":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(X_test['ds'], X_test['y'], color='r')\nfig = model.plot(tas_predict, ax=ax)","ccd16216":"def mean_absolute_percentage_error(y_true, y_pred): \n    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\nprint('RMSE '+ str(round(mean_squared_error(y_true=X_test['y'],y_pred=tas_predict['yhat']),3)))\nprint('MAE '+ str(round(mean_absolute_error(y_true=X_test['y'], y_pred=tas_predict['yhat']),3)))\nprint('MAPE ' +str(round(mean_absolute_percentage_error(y_true=X_test['y'], y_pred=tas_predict['yhat']),3))+'%')","882c32a5":"PASOS=7\n\n# convert series to supervised learning\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = pd.DataFrame(data)\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n    # forecast sequence (t, t+1, ... t+n)\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n        if i == 0:\n            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n        else:\n            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg\n \n# load dataset\nvalues = df.values\n# ensure all data is float\nvalues = values.astype('float32')\n# normalize features\nscaler = MinMaxScaler(feature_range=(-1, 1))\nvalues=values.reshape(-1, 1) # esto lo hacemos porque tenemos 1 sola dimension\nscaled = scaler.fit_transform(values)\n# frame as supervised learning\nreframed = series_to_supervised(scaled, PASOS, 1)\nreframed.head()","3167fe67":"reframed.shape","c0a6638e":"# split into train and test sets\nvalues = reframed.values\nn_train_days = 12612\ntrain = values[:n_train_days, :]\ntest = values[n_train_days:, :]\n# split into input and outputs\nx_train, y_train = train[:, :-1], train[:, -1]\nx_val, y_val = test[:, :-1], test[:, -1]\n# reshape input to be 3D [samples, timesteps, features]\nx_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\nx_val = x_val.reshape((x_val.shape[0], 1, x_val.shape[1]))\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n","3dc68702":"def crear_modeloFF():\n    model = Sequential() \n    model.add(Dense(PASOS, input_shape=(1,PASOS),activation='tanh'))\n    model.add(Flatten())\n    model.add(Dense(1, activation='tanh'))\n    model.compile(loss='mean_absolute_error',optimizer='Adam',metrics=[\"mse\"])\n    model.summary()\n    return model","5c16bdc0":"EPOCHS=40\n \nmodel = crear_modeloFF()\n \nhistory=model.fit(x_train,y_train,epochs=EPOCHS,validation_data=(x_val,y_val),batch_size=PASOS)","5669521e":"X_test= X_test[7:] #Delete first 7 days of data test.","ccfbef0e":"results=model.predict(x_val)\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nplt.scatter(X_train['ds'], y_train, c= 'b')\nplt.scatter(X_test['ds'],y_val,c='g')\nplt.scatter(X_test['ds'],results,c='r')\nplt.title('validate')\nplt.show()","77d6f665":"f, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n# summarize history for accuracy\nplt.plot(history.history['mse'])\nplt.plot(history.history['val_mse'])\nplt.title('model mse')\nplt.ylabel('mse')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","417dd276":"f, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","1fc934de":"# Compare Forecast results with real values of temperature.","d54eccc0":"# Neuronal Network"}}