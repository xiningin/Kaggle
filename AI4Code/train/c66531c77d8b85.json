{"cell_type":{"5c34f262":"code","7a8e28dc":"code","c8b774ac":"code","e76c9f75":"code","79790c3a":"code","556a20a2":"code","4b541713":"code","114475c2":"code","9996188f":"markdown"},"source":{"5c34f262":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7a8e28dc":"from bs4 import BeautifulSoup\nimport requests","c8b774ac":"def scrape_lib(data_block):\n    property_lib={}\n    \n    try:\n        name = data_block.find('a').get_text()\n\n        name_split = name.split('-')\n        \n        house_type = name_split[1]\n        property_lib['house_type'] = house_type\n        \n        house_address = name_split[0]\n        property_lib['house_address'] = house_address\n\n        house_location = house_address.split(',')[0]\n        property_lib['house_location'] = house_location\n        \n        house_city = house_address.split(',')[1]\n        property_lib['house_city'] = house_city\n    except:\n        pass\n\n    try:\n        date = data_block.find('span').get_text()\n        property_lib['date'] = date\n    except:            \n        pass\n        \n    try:\n        price = data_block.find('label',{'class':'price clearfix'}).find_next('a').get_text()\n        property_lib['price'] = price\n    except:\n          pass\n        \n    try:\n        size_price = data_block.find('label',{'class':'price clearfix'}).find_next('span').find_next('span').get_text()\n        property_lib['size_price'] = size_price\n    except:\n        pass\n        \n    try:\n        bedroom = data_block.find('div', {'class':'clearfix bb-det mar-bot-15'}).find_next('label',{'class' : 'pull-left'}).get_text()\n        property_lib['bedroom'] = bedroom\n    except:\n        pass\n        \n    try:\n        bathroom = data_block.find('div', {'class':'clearfix bb-det mar-bot-15'}).find_next('label',{'class' : 'pull-left'}).find_next('label',{'class' : 'pull-left'}).get_text()\n        property_lib['bathroom'] = bathroom\n    except:\n        pass\n        \n    try:\n        parking = data_block.find('div', {'class':'clearfix bb-det mar-bot-15'}).find_next('label',{'class' : 'pull-left'}).find_next('label',{'class' : 'pull-left'}).find_next('label',{'class' : 'pull-left'}).get_text()\n        property_lib['parking'] = parking\n    except:\n        pass\n        \n    try:\n        size = data_block.find('div',{'class': 'clearfix cla-det'}).find_next('div', {'class' : 'clearfix cla-det-line'}).find_next('p',{'class':'clearfix'}).find_next('label').find_next('label').find_next('label').get_text()\n        property_lib['size'] = size\n    except:\n        pass\n        \n    try:\n        furnish = data_block.find('div',{'class': 'clearfix cla-det'}).find_next('div', {'class' : 'clearfix cla-det-line'}).find_next('div', {'class' : 'clearfix cla-det-line'}).find_next('label').find_next('label').find_next('label').get_text()\n        property_lib['furnish'] = furnish\n    except:\n        pass\n        \n    return property_lib\n","e76c9f75":"def scrape_page(data_block):\n    page_property_data=[]\n    num_blocks = len(data_block)\n    \n    for block in range(num_blocks):\n        page_property_data.append(scrape_lib(data_block[block]))\n        \n    return page_property_data","79790c3a":"def scrape(link, pageToGet):\n    base_url = link\n    target = pageToGet\n    \n    current_page_num = 1\n    remain = target - current_page_num\n    \n    next_page_num = 1\n    \n    property_data = []\n    \n    while remain > 0:\n        \n        print('currently scraping data from page : ',current_page_num,' | remaining page: ',remain)\n        \n        url = base_url + str(next_page_num)\n        \n        source = requests.get(url).text\n        soup = BeautifulSoup(source, 'html.parser')\n        \n        data_block = soup.findAll('div',{'class' : 'clearfix buy-cla-ad'})\n        \n        property_data.extend(scrape_page(data_block))\n        \n        current_page_num += 1\n        \n        remain = target - current_page_num\n        \n        \n        next_page_num = next_page_num + 1\n        \n    print('Finish!')\n    return property_data","556a20a2":"base_link = 'https:\/\/www.durianproperty.com.my\/buy\/search\/?keyword=&city=&propertytype=&minprice=&maxprice=&minbedroom=&maxbedroom=&minbath=&maxbath=&minsize=&maxsize=&mincarpark=&maxcarpark=&dateposted=&funishingtype=&tenure=&onlywithphoto=0&bllat=&bllong=&trlat&trlong=&sortby=&pg='\n\npagecount =  960\n\ndata = scrape(base_link,int(pagecount))\n\ndf = pd.DataFrame(data)\n\ndf.head()","4b541713":"df.tail()","114475c2":"df.to_csv('durianproperty.csv',index=False)","9996188f":"This style does work perfectly ! Compare to looping version [Learn Scrape Durianproperty looping style](https:\/\/www.kaggle.com\/arifaimanisa\/learn-scrape-durianproperty-looping-style)"}}