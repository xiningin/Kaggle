{"cell_type":{"ea818e87":"code","de32c7e1":"code","43f2adb6":"code","5156f0cd":"code","7d6fdd66":"code","e2a4f4ab":"code","e8079919":"code","5ebec3ba":"code","71b2db6e":"code","868a159b":"code","b47bf84e":"code","aa0504b3":"code","1f0fa736":"code","c386cd6b":"code","312263ed":"code","75e4b18a":"code","a5010284":"code","51e56d12":"code","19af4f46":"code","4528128c":"code","f2aa129a":"code","579aa32e":"code","559ba7fa":"code","d97c9922":"code","74f6ca1b":"code","838e824c":"code","bfb75bd6":"markdown","99f8878f":"markdown","6e092608":"markdown","e17b68ba":"markdown","5922a8ff":"markdown","ef569c5f":"markdown","9b1b212a":"markdown","e2429ee3":"markdown","3604d727":"markdown","d797ab59":"markdown","79e4ff74":"markdown","d33726d9":"markdown","b0cd02c4":"markdown","4889fe42":"markdown","8d5fad3e":"markdown","7457f4ad":"markdown","00bc5504":"markdown","7734950c":"markdown","a9e19426":"markdown","c9e90fa4":"markdown","05680ec9":"markdown"},"source":{"ea818e87":"# installs the covid19_inference library\n!pip install git+https:\/\/github.com\/Priesemann-Group\/covid19_inference.git@v0.1.8","de32c7e1":"import datetime\nimport time as time_module\nimport sys\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport scipy.stats\nimport theano\nimport theano.tensor as tt\nimport pymc3 as pm\nimport seaborn as sns\nimport covid19_inference as cov19\nfrom sklearn.model_selection import train_test_split","43f2adb6":"# Using the covid19_inference to download data from John Hopkins University (JHU) \njhu = cov19.data_retrieval.JHU()\njhu.download_all_available_data()","5156f0cd":"# getting the Kenyan confirmed, recovered, deaths numbers from JHU data\ndfKe = jhu.get_total_confirmed_deaths_recovered(country=\"Kenya\")\n\n# get the rows where the number of cases are more than a 100\ndfKe100 = dfKe.loc[dfKe['confirmed'] >= 100]\ndfKe100.tail(10)","7d6fdd66":"# Check if the date column has null values\ndfKe100.reset_index()['date'].isna().sum()","e2a4f4ab":"# confirmed - recovered - death trends\nplt.figure(figsize = (10,6))\nsns.lineplot(x=dfKe100.index, y=dfKe100.confirmed)\nsns.lineplot(x=dfKe100.index, y=dfKe100.recovered)\nsns.lineplot(x=dfKe100.index, y=dfKe100.deaths)\nplt.xticks(rotation = 50)\n\nplt.legend(['confirmed', 'death', 'recovered'])","e8079919":"a = dfKe100.copy()\na.loc['total'] = a.sum()  #add a totals row\n\nfig = plt.figure(figsize =(9, 6)) \nexplode = (0.05, 0.05, 0.05) \nplt.pie(a.loc['total'], labels = a.columns, explode = explode)\nplt.title('A pie chart showing the number of cases in each category')\nplt.show()","5ebec3ba":"bd = datetime.datetime(2020, 4, 2)  # For the date filter (The first day with more than a 100 confirmed cases)\ned = datetime.datetime.now()\n\n# geting the number of new cases for each day\nnew_cases_obs = jhu.get_new(\n    value=\"confirmed\", country=\"Kenya\", data_begin=bd, data_end=ed\n)","71b2db6e":"X = new_cases_obs\nX_train, X_test = train_test_split(X, test_size=0.2, shuffle=False)","868a159b":"print(X_test.shape)  #forecasting days","b47bf84e":"# Creating the priors for change points and other configuration\n\ndiff_data_sim = 16  # should be significantly larger than the expected delay, in\nnum_days_forecast = 26\n\n# We set the priors for the changepoints here\nprior_date_mild_dist_begin = datetime.datetime(2020, 4, 6)\nprior_date_strong_dist_begin = datetime.datetime(2020, 5, 7)\nprior_date_contact_ban_begin = datetime.datetime(2020, 7, 6)\n\nchange_points = [\n    dict(\n        pr_mean_date_transient=prior_date_mild_dist_begin,\n        pr_sigma_date_transient=3,\n        pr_median_lambda=0.2,\n        pr_sigma_lambda=1,\n    ),\n    dict(\n        pr_mean_date_transient=prior_date_strong_dist_begin,\n        pr_sigma_date_transient=1.5,\n        pr_median_lambda=1 \/ 8,\n        pr_sigma_lambda=1,\n    ),\n    dict(\n        pr_mean_date_transient=prior_date_contact_ban_begin,\n        pr_sigma_date_transient=1.5,\n        pr_median_lambda=1 \/ 8 \/ 2,\n        pr_sigma_lambda=1,\n    ),\n]","aa0504b3":"\"\"\"\n    Next, we create the model! There are default values for most of the function arguments,\n    but we will try to explicitly set all kwargs for the sake of this example.\n\"\"\"\nparams_model = dict(\n    new_cases_obs=X_train[:],\n    data_begin=bd,\n    fcast_len=num_days_forecast,\n    diff_data_sim=diff_data_sim,\n    N_population=50e6,\n)\n\n# Median of the prior for the delay in case reporting, we assume 3 days\npr_delay = 3\n\n\"\"\"\n    The model is specified in a context. Each function in this context\n    has access to the model parameters set.\n\"\"\"\nwith cov19.model.Cov19Model(**params_model) as this_model:\n    # Create the an array of the time dependent infection rate lambda\n    lambda_t_log = cov19.model.lambda_t_with_sigmoids(\n        pr_median_lambda_0=0.4,\n        pr_sigma_lambda_0=0.5,\n        change_points_list=change_points,  # The change point priors we constructed earlier\n        name_lambda_t=\"lambda_t\",  # Name for the variable in the trace (see later)\n    )\n\n    # set prior distribution for the recovery rate\n    mu = pm.Lognormal(name=\"mu\", mu=np.log(1 \/ 8), sigma=0.2)\n\n    # This builds a decorrelated prior for I_begin for faster inference.\n    # It is not necessary to use it, one can simply remove it and use the default argument\n    # for pr_I_begin in cov19.SIR\n    prior_I = cov19.model.uncorrelated_prior_I(\n        lambda_t_log=lambda_t_log,\n        mu=mu,\n        pr_median_delay=pr_delay,\n        name_I_begin=\"I_begin\",\n        name_I_begin_ratio_log=\"I_begin_ratio_log\",\n        pr_sigma_I_begin=2,\n        n_data_points_used=5,\n    )\n\n    # Use lambda_t_log and mu to run the SIR model\n    new_cases = cov19.model.SIR(\n        lambda_t_log=lambda_t_log,\n        mu=mu,\n        name_new_I_t=\"new_I_t\",\n        name_I_t=\"I_t\",\n        name_I_begin=\"I_begin\",\n        pr_I_begin=prior_I,\n    )\n\n    # Delay the cases by a lognormal reporting delay\n    new_cases = cov19.model.delay_cases(\n        cases=new_cases,\n        name_cases=\"delayed_cases\",\n        name_delay=\"delay\",\n        name_width=\"delay-width\",\n        pr_mean_of_median=pr_delay,\n        pr_sigma_of_median=0.2,\n        pr_median_of_width=0.3,\n    )\n\n    # Modulate the inferred cases by a abs(sin(x)) function, to account for weekend effects\n    # Also adds the \"new_cases\" variable to the trace that has all model features.\n    new_cases = cov19.model.week_modulation(\n        cases=new_cases,\n        name_cases=\"new_cases\",\n        name_weekend_factor=\"weekend_factor\",\n        name_offset_modulation=\"offset_modulation\",\n        week_modulation_type=\"abs_sine\",\n        pr_mean_weekend_factor=0.3,\n        pr_sigma_weekend_factor=0.5,\n        weekend_days=(6, 7),\n    )\n\n    # Define the likelihood, uses the new_cases_obs set as model parameter\n    cov19.model.student_t_likelihood(new_cases)\n","1f0fa736":"\"\"\"## MCMC sampling\n\n    After the model is built, it is sampled using an MCMC sampler.\n    The number of parallel runs can be set with the argument `cores=`.\n    In particular, due to a bug in Theano, Windows users should set `cores=1`.\n    The sampling can take a long time.\n\"\"\"\n\ntrace = pm.sample(model=this_model, tune=500, draws=1000, init=\"advi+adapt_diag\")","c386cd6b":"\"\"\"## Plotting\n    Plotting tools are rudimentary right now. But one can always write custom plotting function\n    by accessing the samples stored in the trace.\n\n    ### Distributions\n\"\"\"\nfig, axes = plt.subplots(6, 3, figsize=(6, 6.4))\n\n# Get the free Random Variables\nvarnames = this_model.untransformed_freeRVs\nprint(varnames)\n\n# Plot them\nfor i, key in enumerate(\n    # left column\n    [\"weekend_factor\", \"mu\", \"lambda_0\", \"lambda_1\", \"lambda_2\", \"lambda_3\"]\n):\n    cov19.plot._distribution(this_model, trace, key, ax=axes[i, 0])\n\nfor i, key in enumerate(\n    # mid column\n    [\n        \"offset_modulation\",\n        \"sigma_obs\",\n        \"I_begin\",\n        \"transient_day_1\",\n        \"transient_day_2\",\n        \"transient_day_3\",\n    ]\n):\n    cov19.plot._distribution(this_model, trace, key, ax=axes[i, 1])\n\nfor i, key in enumerate(\n    # right column\n    [\"delay\", \"transient_len_1\", \"transient_len_2\", \"transient_len_3\",]\n):\n    cov19.plot._distribution(this_model, trace, key, ax=axes[i + 2, 2])\n\nfig.tight_layout()\nfig","312263ed":"\"\"\"### Timeseries\n    timeseries overview, for now needs an offset variable to get cumulative cases\n\"\"\"\nfig, axes = cov19.plot.timeseries_overview(this_model, trace, offset=-3000)","75e4b18a":"# Getting the forecast values from the model\nfcast_x, fcast_y = cov19.plot._get_array_from_trace_via_date(this_model, trace, 'new_cases', this_model.fcast_begin, this_model.fcast_end )","a5010284":"# # Evaluating the models performance i.e how accurate is the model\n# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n# mean_squared_error(X_test.head(26), fcast_x[0])**0.5","51e56d12":"# # Create a multiplot\n# fig1, axes1 = plt.subplots(2,1, figsize=(12,6))\n\n# # Visual representation of the models performance\n# cov19.plot._timeseries(x=X_test.head(26).index, y=X_test.head(26), ax=axes1[0], what='model')\n# cov19.plot._timeseries(x=fcast_y, y=fcast_x[0],ax=axes1[1], what='model')\n\n# # Label the plots\n\n# axes1[0].set_title(\"accurate values\")\n\n# axes1[1].set_title(\"forecasted values\")\n\n# # Show the figure\n# fig1.show()\n# fig1","19af4f46":"# On the same plot\nplt.figure(figsize = (10,6))\nsns.lineplot(x=X_test.index, y=X_test, legend = 'brief')\nsns.lineplot(x=fcast_y, y=fcast_x[0], legend = 'full')\nplt.legend(['actual values', 'forecasted values'])","4528128c":"# Creating the priors for change points and other configuration\n\ndiff_data_sim = 16  # should be significantly larger than the expected delay, in\n# order to always fit the same number of data points.\nnum_days_forecast = 7 # prediction days\n\n# We set the priors for the changepoints here\nprior_date_mild_dist_begin = datetime.datetime(2020, 4, 6)\nprior_date_strong_dist_begin = datetime.datetime(2020, 5, 7)\nprior_date_contact_ban_begin = datetime.datetime(2020, 7, 6)\n\nchange_points = [\n    dict(\n        pr_mean_date_transient=prior_date_mild_dist_begin,\n        pr_sigma_date_transient=3,\n        pr_median_lambda=0.2,\n        pr_sigma_lambda=1,\n    ),\n    dict(\n        pr_mean_date_transient=prior_date_strong_dist_begin,\n        pr_sigma_date_transient=1.5,\n        pr_median_lambda=1 \/ 8,\n        pr_sigma_lambda=1,\n    ),\n    dict(\n        pr_mean_date_transient=prior_date_contact_ban_begin,\n        pr_sigma_date_transient=1.5,\n        pr_median_lambda=1 \/ 8 \/ 2,\n        pr_sigma_lambda=1,\n    ),\n]\n","f2aa129a":"\"\"\"\n    Next, we create the model! There are default values for most of the function arguments,\n    but we will try to explicitly set all kwargs for the sake of this example.\n\"\"\"\nparams_model = dict(\n    new_cases_obs=X[:], # Data Change\n    data_begin=bd,\n    fcast_len=num_days_forecast,\n    diff_data_sim=diff_data_sim,\n    N_population=50e6,\n)\n\n# Median of the prior for the delay in case reporting, we assume 3 days\npr_delay = 3\n\n\"\"\"\n    The model is specified in a context. Each function in this context\n    has access to the model parameters set.\n\"\"\"\nwith cov19.model.Cov19Model(**params_model) as this_model:\n    # Create the an array of the time dependent infection rate lambda\n    lambda_t_log = cov19.model.lambda_t_with_sigmoids(\n        pr_median_lambda_0=0.4,\n        pr_sigma_lambda_0=0.5,\n        change_points_list=change_points,  # The change point priors we constructed earlier\n        name_lambda_t=\"lambda_t\",  # Name for the variable in the trace (see later)\n    )\n\n    # set prior distribution for the recovery rate\n    mu = pm.Lognormal(name=\"mu\", mu=np.log(1 \/ 8), sigma=0.2)\n\n    # This builds a decorrelated prior for I_begin for faster inference.\n    # It is not necessary to use it, one can simply remove it and use the default argument\n    # for pr_I_begin in cov19.SIR\n    prior_I = cov19.model.uncorrelated_prior_I(\n        lambda_t_log=lambda_t_log,\n        mu=mu,\n        pr_median_delay=pr_delay,\n        name_I_begin=\"I_begin\",\n        name_I_begin_ratio_log=\"I_begin_ratio_log\",\n        pr_sigma_I_begin=2,\n        n_data_points_used=5,\n    )\n\n    # Use lambda_t_log and mu to run the SIR model\n    new_cases = cov19.model.SIR(\n        lambda_t_log=lambda_t_log,\n        mu=mu,\n        name_new_I_t=\"new_I_t\",\n        name_I_t=\"I_t\",\n        name_I_begin=\"I_begin\",\n        pr_I_begin=prior_I,\n    )\n\n    # Delay the cases by a lognormal reporting delay\n    new_cases = cov19.model.delay_cases(\n        cases=new_cases,\n        name_cases=\"delayed_cases\",\n        name_delay=\"delay\",\n        name_width=\"delay-width\",\n        pr_mean_of_median=pr_delay,\n        pr_sigma_of_median=0.2,\n        pr_median_of_width=0.3,\n    )\n\n    # Modulate the inferred cases by a abs(sin(x)) function, to account for weekend effects\n    # Also adds the \"new_cases\" variable to the trace that has all model features.\n    new_cases = cov19.model.week_modulation(\n        cases=new_cases,\n        name_cases=\"new_cases\",\n        name_weekend_factor=\"weekend_factor\",\n        name_offset_modulation=\"offset_modulation\",\n        week_modulation_type=\"abs_sine\",\n        pr_mean_weekend_factor=0.3,\n        pr_sigma_weekend_factor=0.5,\n        weekend_days=(6, 7),\n    )\n\n    # Define the likelihood, uses the new_cases_obs set as model parameter\n    cov19.model.student_t_likelihood(new_cases)\n","579aa32e":"\"\"\"## MCMC sampling\n\n    After the model is built, it is sampled using an MCMC sampler.\n    The number of parallel runs can be set with the argument `cores=`.\n    In particular, due to a bug in Theano, Windows users should set `cores=1`.\n    The sampling can take a long time.\n\"\"\"\n\ntrace = pm.sample(model=this_model, tune=500, draws=1000, init=\"advi+adapt_diag\")","559ba7fa":"\"\"\"## Plotting\n    Plotting tools are rudimentary right now. But one can always write custom plotting function\n    by accessing the samples stored in the trace.\n\n    ### Distributions\n\"\"\"\nfig, axes = plt.subplots(6, 3, figsize=(6, 6.4))\n\n# Get the free Random Variables\nvarnames = this_model.untransformed_freeRVs\nprint(varnames)\n\n# Plot them\nfor i, key in enumerate(\n    # left column\n    [\"weekend_factor\", \"mu\", \"lambda_0\", \"lambda_1\", \"lambda_2\", \"lambda_3\"]\n):\n    cov19.plot._distribution(this_model, trace, key, ax=axes[i, 0])\n\nfor i, key in enumerate(\n    # mid column\n    [\n        \"offset_modulation\",\n        \"sigma_obs\",\n        \"I_begin\",\n        \"transient_day_1\",\n        \"transient_day_2\",\n        \"transient_day_3\",\n    ]\n):\n    cov19.plot._distribution(this_model, trace, key, ax=axes[i, 1])\n\nfor i, key in enumerate(\n    # right column\n    [\"delay\", \"transient_len_1\", \"transient_len_2\", \"transient_len_3\",]\n):\n    cov19.plot._distribution(this_model, trace, key, ax=axes[i + 2, 2])\n\nfig.tight_layout()\nfig","d97c9922":"\"\"\"### Timeseries\n    timeseries overview, for now needs an offset variable to get cumulative cases\n\"\"\"\nfig, axes = cov19.plot.timeseries_overview(this_model, trace, offset=-3000)","74f6ca1b":"# ## the week of August 10th predictions\nfcast_x, fcast_y = cov19.plot._get_array_from_trace_via_date(this_model, trace, 'new_cases', this_model.fcast_begin, this_model.fcast_end )\nc = pd.DataFrame([fcast_y, fcast_x[0]])\nc = c.transpose()\nc.columns = ['date', 'predicted new_cases']\nc['predicted new_cases'] = c['predicted new_cases'].astype(int)\nc","838e824c":"pm.save_trace(trace)","bfb75bd6":"#### Date Range and Specific Data","99f8878f":"## Table of Contents\n* [Prerequisites](#The-Model-Module)\n* [Libraries](#Libraries)\n* [Dataset and Preprocessing](#Dataset-+-Preprocessing)\n* [Visualisations](#Visualisations)\n* [Model Specifics (Train set)](#Model-Specifics)\n    1. [Date Range and Getting Specific Data](#Date-Range-and-Specific-Data)\n    2. [Train and Validation sets](#Train-and-Validation-sets)\n    3. [Change points priors](#Change-points-priors)\n    4. [Model Creation and Parameters Tuning](#Model-Creation-and-Hyperparameters-tuning.)\n    5. [Model Fitting](#Model-Fitting)\n    6. [Distributions](#Distributions)\n    7. [Predictions Time Series plot](#Predictions-time-series-plot)\n    8. [Model Evaluation](#Model-Evaluation)\n* [Model Rerun (Final Predictions)](#Reruning-the-model-with-the-whole-dataset-and-predict-until-10th-August.)","6e092608":"The plots above show the change in the spreading rate at different change points (intervention points)\/times and initially (prior).\nSpecifics can be found in the report.","e17b68ba":"#### Model Fitting","5922a8ff":"#### Change points priors","ef569c5f":"### Libraries","9b1b212a":"### Visualisations","e2429ee3":"### Model Specifics","3604d727":"#### Predictions time series plot","d797ab59":"### Dataset + Preprocessing","79e4ff74":"#### Model Evaluation","d33726d9":"The trend predictions are not good, but overally the model highlights rises and falls at the right ranges. (The peaks and falls predictions do not match the actual figures though.) But all in all, the scale is not bad. \nThis is the best prediction the group could come up with at the moment after retuning some parameters and rerunning the model over and over again. ","b0cd02c4":"The plots above show the change in the spreading rate at different change points (intervention points) and initially (prior).\n","4889fe42":"Total confirmed cases is bound to have the largest percentage given the natural progression of the situation. From infection to recovery or death. \nThe number of deaths is approximately at least a tenth of the number of recovered cases, this indicates a low mortality rate of the disease.","8d5fad3e":"#### Train and Validation sets","7457f4ad":"## Introduction\n* The task at hand is to quantify the impact of the Kenyan government policy interventions to  slow the spread of the current pandemic: COVID19.\n* The **'behind the scenes'** of the model used is in this [repository](https:\/\/github.com\/Priesemann-Group\/covid19_inference\/blob\/master\/scripts\/interactive\/example_one_bundesland.ipynb). The repo takes care of all the steps from data scraping to model formulation. Credits to [Jonas Dehning](https:\/\/science.sciencemag.org\/content\/369\/6500\/eabb9789), [Michael Wibral](https:\/\/science.sciencemag.org\/content\/369\/6500\/eabb9789) et.al.\n* Find the reserach publication [here](https:\/\/science.sciencemag.org\/content\/369\/6500\/eabb9789).\n* Find the project report draft [here](https:\/\/github.com\/ada-k\/ChangePointAnalysis_Covid19Interventions\/blob\/master\/report.pdf).\n* An overview of the model:  It performs bayesian inferencing for the central  epidemiological parameters of an SIR model using MCMC sampling  to compute the posterior distribution of the parameters and to sample from it for forecasting.The SIR  model is generalized with stationary spreading rate for change point(interventions) detection. \n* The interventions explored are:\n    * 6th April 2020 \u2013 Ban on movement in Nairobi, Kilifi, Kwale, and Mombasa counties and imposing of the dusk to dawn curfew\n    * 7th May 2020 - Lockdown in Eastleigh (Nairobi) and Old Town (Mombasa city)\n    * 6th July 2020  - Movement restrictions  lifted in Nairobi, Mombasa, and Mandera counties.","00bc5504":"### Reruning the model with the whole dataset and predict until 10th August.","7734950c":"#### Distributions","a9e19426":"### The Model Module","c9e90fa4":"#### Model Creation and Hyperparameters tuning.","05680ec9":"[Back to top](#Introduction)"}}