{"cell_type":{"3c57fa38":"code","7ccf8e66":"code","98438ded":"code","ab7c0c1a":"code","0d78132b":"code","c4872c80":"code","277f490c":"code","9daa0983":"code","3ab45c0c":"code","6a984c6e":"code","2c4b826d":"code","50390f0b":"code","4c58e062":"code","173349f3":"code","4ef13ff7":"code","c4b091b3":"code","09cbf818":"code","08dfbdaa":"code","f19a6d68":"code","930d0b6f":"code","1a688214":"code","b8572f81":"code","bdcb1668":"code","5a028e21":"code","9ff63750":"code","0524e875":"code","756bbeca":"code","ec51b04b":"code","c1aacea5":"code","c4034a8f":"code","15bc221a":"code","b090abc9":"code","f15c32b9":"code","c41352d9":"code","1fefeb93":"code","93487766":"code","fc154e07":"code","5ae7ed5d":"code","47511eef":"code","b6a67acd":"code","805b3829":"code","c7a03b73":"code","a4aa7ee7":"code","fde61e93":"code","6d5c60e7":"code","ba26674d":"code","56eb5dc7":"code","8a776440":"code","4e66c5f9":"code","51244a70":"code","4e2b19f4":"markdown","eb3a2f96":"markdown","32b7536c":"markdown","6c3fb060":"markdown","db5d5e5a":"markdown","169fdc94":"markdown","17d1f50f":"markdown","42bb3a79":"markdown","164a397d":"markdown","adb3d9af":"markdown","1d5b8919":"markdown","15daf334":"markdown","fffb4c20":"markdown","ff403d69":"markdown","b14e84cf":"markdown","cc488f6e":"markdown","ecd59d0e":"markdown","948a22d5":"markdown","82613b39":"markdown","8fcf816b":"markdown","2a716708":"markdown","d4f05941":"markdown","2ceb3dc5":"markdown","2a1779d0":"markdown","5a66d74b":"markdown","3200eaf5":"markdown","701aca9e":"markdown","c2fa4249":"markdown","a1755774":"markdown"},"source":{"3c57fa38":"# Supressing the warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","7ccf8e66":"# Reading the dataset\nimport pandas as pd\nimport numpy as np\nZomatoData=pd.read_csv('..\/input\/zomatodata\/ZomatoData.csv', encoding='latin')\nprint('Shape before deleting duplicate values:', ZomatoData.shape)\n\n# Removing duplicate rows if any\nZomatoData=ZomatoData.drop_duplicates()\nprint('Shape After deleting duplicate values:', ZomatoData.shape)\n\n# Printing sample data\n# Start observing the Quantitative\/Categorical\/Qualitative variables\nZomatoData.head(10)","98438ded":"%matplotlib inline\n# Creating Bar chart as the Target variable is Continuous\nZomatoData['Rating'].hist()","ab7c0c1a":"ZomatoData.head()","0d78132b":"ZomatoData.info()","c4872c80":"ZomatoData.describe(include='all')","277f490c":"ZomatoData.nunique()","9daa0983":"# Function to count the number of cuisines\ndef cuisine_counter(inpStr):\n    NumCuisines=len(str(inpStr).split(','))\n    return(NumCuisines)","3ab45c0c":"# Creating a new feature in data\n# We will further explore the new feature just like other features\nZomatoData['CuisineCount']=ZomatoData['Cuisines'].apply(cuisine_counter)\nZomatoData.head()","6a984c6e":"# Deleting those columns which are not useful in predictive analysis because these variables are qualitative\nUselessColumns = ['Restaurant ID', 'Restaurant Name','City','Address',\n                  'Locality', 'Locality Verbose','Cuisines']\nZomatoData = ZomatoData.drop(UselessColumns,axis=1)\nZomatoData.head()\n","2c4b826d":"def PlotBarCharts(inpData, colsToPlot):\n    %matplotlib inline\n    \n    import matplotlib.pyplot as plt\n    \n    # Generating multiple subplots\n    fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(20,5))\n    fig.suptitle('Bar charts of: '+ str(colsToPlot))\n\n    for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):\n        inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])","50390f0b":"# Calling the function\nPlotBarCharts(inpData=ZomatoData, colsToPlot=[\n    'Country Code', 'Currency', 'Has Table booking', 'Has Online delivery', 'Is delivering now',\n    'Switch to order menu','Price range'])","4c58e062":"# Plotting histograms of multiple columns together\nZomatoData.hist(['Longitude', 'Latitude', \n                 'Votes', 'Average Cost for two'], figsize=(18,10))","173349f3":"# Finding nearest values to 4000 mark\nZomatoData['Votes'][ZomatoData['Votes']<4000].sort_values(ascending=False)","4ef13ff7":"# Replacing outliers with nearest possibe value\nZomatoData['Votes'][ZomatoData['Votes']>4000] =3986","c4b091b3":"# Finding nearest values to 50000 mark\nZomatoData['Average Cost for two'][ZomatoData['Average Cost for two']<50000].sort_values(ascending=False)","09cbf818":"# Replacing outliers with nearest possibe value\nZomatoData['Average Cost for two'][ZomatoData['Average Cost for two']>50000] =8000","08dfbdaa":"ZomatoData.hist(['Votes', 'Average Cost for two'], figsize=(18,5))","f19a6d68":"# Finding how many missing values are there for each column\nZomatoData.isnull().sum()","930d0b6f":"ContinuousCols=['Longitude', 'Latitude', 'Votes', 'Average Cost for two']\n\n# Plotting scatter chart for each predictor vs the target variable\nfor predictor in ContinuousCols:\n    ZomatoData.plot.scatter(x=predictor, y='Rating', figsize=(10,5), title=predictor+\" VS \"+ 'Rating')","1a688214":"# Calculating correlation matrix\nContinuousCols=['Rating','Longitude', 'Latitude', 'Votes', 'Average Cost for two']\n\n# Creating the correlation matrix\nCorrelationData=ZomatoData[ContinuousCols].corr()\nCorrelationData","b8572f81":"# Filtering only those columns where absolute correlation > 0.5 with Target Variable\n# reduce the 0.5 threshold if no variable is selected like in this case\nCorrelationData['Rating'][abs(CorrelationData['Rating']) > 0.2 ]","bdcb1668":"# Box plots for Categorical Target Variable \"Rating\" and continuous predictors\nCategoricalColsList=['Has Table booking', 'Has Online delivery', 'Price range']\n\nimport matplotlib.pyplot as plt\nfig, PlotCanvas=plt.subplots(nrows=1, ncols=len(CategoricalColsList), figsize=(18,5))\n\n# Creating box plots for each continuous predictor against the Target Variable \"Rating\"\nfor PredictorCol , i in zip(CategoricalColsList, range(len(CategoricalColsList))):\n    ZomatoData.boxplot(column='Rating', by=PredictorCol, figsize=(5,5), vert=True, ax=PlotCanvas[i])","5a028e21":"# Defining a function to find the statistical relationship with all the categorical variables\ndef FunctionAnova(inpData, TargetVariable, CategoricalPredictorList):\n    from scipy.stats import f_oneway\n\n    # Creating an empty list of final selected predictors\n    SelectedPredictors=[]\n    \n    print('##### ANOVA Results ##### \\n')\n    for predictor in CategoricalPredictorList:\n        CategoryGroupLists=inpData.groupby(predictor)[TargetVariable].apply(list)\n        AnovaResults = f_oneway(*CategoryGroupLists)\n        \n        # If the ANOVA P-Value is <0.05, that means we reject H0\n        if (AnovaResults[1] < 0.05):\n            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n            SelectedPredictors.append(predictor)\n        else:\n            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n    \n    return(SelectedPredictors)","9ff63750":"# Calling the function to check which categorical variables are correlated with target\n# Calling the function to check which categorical variables are correlated with target\nCategoricalPredictorList=['Has Table booking', 'Has Online delivery', 'Price range']\nFunctionAnova(inpData=ZomatoData, \n              TargetVariable='Rating', \n              CategoricalPredictorList=CategoricalPredictorList)","0524e875":"SelectedColumns=['Votes','Average Cost for two','Has Table booking',\n                 'Has Online delivery','Price range']\n\n# Selecting final columns\nDataForML=ZomatoData[SelectedColumns]\nDataForML.head()","756bbeca":"DataForML.to_pickle('DataForML.pkl')","ec51b04b":"# Converting the binary nominal variable sex to numeric\nDataForML['Has Table booking'].replace({'Yes':1, 'No':0}, inplace=True)\nDataForML['Has Online delivery'].replace({'Yes':1, 'No':0}, inplace=True)","c1aacea5":"# Treating all the nominal variables at once using dummy variables\nDataForML_Numeric=pd.get_dummies(DataForML)\n\n# Adding Target Variable to the data\nDataForML_Numeric['Rating']=ZomatoData['Rating']\n\n# Printing sample rows\nDataForML_Numeric.head()","c4034a8f":"# Printing all the column names for our reference\nDataForML_Numeric.columns","15bc221a":"# Separate Target Variable and Predictor Variables\nTargetVariable='Rating'\nPredictors=['Votes', 'Average Cost for two', 'Has Table booking',\n           'Has Online delivery', 'Price range']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)","b090abc9":"### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","f15c32b9":"# Sanity check for the sampled data\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","c41352d9":"# Multiple Linear Regression\nfrom sklearn.linear_model import LinearRegression\nRegModel = LinearRegression()\n\n# Printing all the parameters of Linear regression\nprint(RegModel)\n\n# Creating the model on Training Data\nLREG=RegModel.fit(X_train,y_train)\nprediction=LREG.predict(X_test)\n\n# Taking the standardized values to original scale\n\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, LREG.predict(X_train)))\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Rating']-TestingDataResults['PredictedRating']))\/TestingDataResults['Rating'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","1fefeb93":"# Decision Trees (Multiple if-else statements!)\nfrom sklearn.tree import DecisionTreeRegressor\nRegModel = DecisionTreeRegressor(max_depth=6,criterion='mse')\n# Good Range of Max_depth = 2 to 20\n\n# Printing all the parameters of Decision Tree\nprint(RegModel)\n\n# Creating the model on Training Data\nDT=RegModel.fit(X_train,y_train)\nprediction=DT.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, DT.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(DT.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Rating']-TestingDataResults['PredictedRating']))\/TestingDataResults['Rating'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","93487766":"# Random Forest (Bagging of multiple Decision Trees)\nfrom sklearn.ensemble import RandomForestRegressor\nRegModel = RandomForestRegressor(max_depth=2, n_estimators=400,criterion='mse')\n# Good range for max_depth: 2-10 and n_estimators: 100-1000\n\n# Printing all the parameters of Random Forest\nprint(RegModel)\n\n# Creating the model on Training Data\nRF=RegModel.fit(X_train,y_train)\nprediction=RF.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, RF.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(RF.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Rating']-TestingDataResults['PredictedRating']))\/TestingDataResults['Rating'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","fc154e07":"# Adaboost (Boosting of multiple Decision Trees)\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Choosing Decision Tree with 1 level as the weak learner\nDTR=DecisionTreeRegressor(max_depth=3)\nRegModel = AdaBoostRegressor(n_estimators=500, base_estimator=DTR ,learning_rate=0.04)\n\n# Printing all the parameters of Adaboost\nprint(RegModel)\n\n# Creating the model on Training Data\nAB=RegModel.fit(X_train,y_train)\nprediction=AB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, AB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(AB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Rating']-TestingDataResults['PredictedRating']))\/TestingDataResults['Rating'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","5ae7ed5d":"# Xtreme Gradient Boosting (XGBoost)\nfrom xgboost import XGBRegressor\nRegModel=XGBRegressor(max_depth=2, \n                      learning_rate=0.1, \n                      n_estimators=1000, \n                      objective='reg:linear', \n                      booster='gbtree')\n\n# Printing all the parameters of XGBoost\nprint(RegModel)\n\n# Creating the model on Training Data\nXGB=RegModel.fit(X_train,y_train)\nprediction=XGB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, XGB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(XGB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Rating']-TestingDataResults['PredictedRating']))\/TestingDataResults['Rating'])\n\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","47511eef":"# K-Nearest Neighbor(KNN)\nfrom sklearn.neighbors import KNeighborsRegressor\nRegModel = KNeighborsRegressor(n_neighbors=3)\n\n# Printing all the parameters of KNN\nprint(RegModel)\n\n# Creating the model on Training Data\nKNN=RegModel.fit(X_train,y_train)\nprediction=KNN.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, KNN.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n# The variable importance chart is not available for KNN\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Rating']-TestingDataResults['PredictedRating']))\/TestingDataResults['Rating'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","b6a67acd":"# Support Vector Machines(SVM)\nfrom sklearn import svm\nRegModel = svm.SVR(C=5, kernel='rbf', degree=20, gamma=0.01)\n\n# Printing all the parameters\nprint(RegModel)\n\n# Creating the model on Training Data\nSVM=RegModel.fit(X_train,y_train)\nprediction=SVM.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, SVM.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n# The built in attribute SVM.coef_ works only for linear kernel\n%matplotlib inline\n#feature_importances = pd.Series(SVM.coef_[0], index=Predictors)\n#feature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Rating']-TestingDataResults['PredictedRating']))\/TestingDataResults['Rating'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","805b3829":"# Separate Target Variable and Predictor Variables\nTargetVariable='Rating'\n\n# Selecting the final set of predictors for the deployment\n# Based on the variable importance charts of multiple algorithms above\nPredictors=['Votes', 'Average Cost for two', 'Price range']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\nprint(X.shape)\nprint(y.shape)","c7a03b73":"# choose from different tunable hyper parameters\n# Decision Trees (Multiple if-else statements!)\nfrom sklearn.tree import DecisionTreeRegressor\nRegModel = DecisionTreeRegressor(max_depth=6,criterion='mse')\n\n# Training the model on 100% Data available\nFinalDecisionTreeModel=RegModel.fit(X,y)","a4aa7ee7":"# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(FinalDecisionTreeModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","fde61e93":"import pickle\nimport os\n\n# Saving the Python objects as serialized files can be done using pickle library\n# Here let us save the Final ZomatoRatingModel\nwith open('FinalDecisionTreeModel.pkl', 'wb') as fileWriteStream:\n    pickle.dump(FinalDecisionTreeModel, fileWriteStream)\n    # Don't forget to close the filestream!\n    fileWriteStream.close()\n    \nprint('pickle file of Predictive Model is saved at Location:',os.getcwd())","6d5c60e7":"# This Function can be called from any from any front end tool\/website\ndef FunctionPredictResult(InputData):\n    import pandas as pd\n    Num_Inputs=InputData.shape[0]\n    \n    # Making sure the input data has same columns as it was used for training the model\n    # Also, if standardization\/normalization was done, then same must be done for new input\n    \n    # Appending the new data with the Training data\n    DataForML=pd.read_pickle('DataForML.pkl')\n    InputData=InputData.append(DataForML)\n    \n    # Generating dummy variables for rest of the nominal variables\n    InputData=pd.get_dummies(InputData)\n            \n    # Maintaining the same order of columns as it was during the model training\n    Predictors=['Votes', 'Average Cost for two', 'Price range']\n    \n    # Generating the input values to the model\n    X=InputData[Predictors].values[0:Num_Inputs]\n    \n    # Generating the standardized values of X since it was done while model training also\n    X=PredictorScalerFit.transform(X)\n    \n    # Loading the Function from pickle file\n    import pickle\n    with open('FinalDecisionTreeModel.pkl', 'rb') as fileReadStream:\n        PredictionModel=pickle.load(fileReadStream)\n        # Don't forget to close the filestream!\n        fileReadStream.close()\n            \n    # Genrating Predictions\n    Prediction=PredictionModel.predict(X)\n    PredictionResult=pd.DataFrame(Prediction, columns=['Prediction'])\n    return(PredictionResult)","ba26674d":"# Calling the function for new sample data\nNewSampleData=pd.DataFrame(\ndata=[[314,1100,3],\n     [591,1200,4]],\ncolumns=['Votes', 'Average Cost for two', 'Price range'])\n\nprint(NewSampleData)\n\n# Calling the Function for prediction\nFunctionPredictResult(InputData= NewSampleData)","56eb5dc7":"# Creating the function which can take inputs and return predictions\ndef FunctionGeneratePrediction(inp_Votes, inp_Average_Cost, inp_Price_range):\n    \n    # Creating a data frame for the model input\n    SampleInputData=pd.DataFrame(\n     data=[[inp_Votes , inp_Average_Cost, inp_Price_range]],\n     columns=['Votes', 'Average Cost for two', 'Price range'])\n\n    # Calling the function defined above using the input parameters\n    Predictions=FunctionPredictResult(InputData= SampleInputData)\n\n    # Returning the prediction\n    return(Predictions.to_json())\n\n# Function call\nFunctionGeneratePrediction(  inp_Votes=591,\n                             inp_Average_Cost =1200,\n                             inp_Price_range=4\n                             )","8a776440":"from flask import Flask, request, jsonify\nimport pickle\nimport pandas as pd\nimport numpy","4e66c5f9":"app = Flask(__name__)\n\n@app.route('\/prediction_api', methods=[\"GET\"])\ndef prediction_api():\n    try:\n        # Getting the paramters from API call\n        Votes_value = float(request.args.get('Votes'))\n        Average_Cost_value=float(request.args.get('Average_Cost'))\n        Price_range_value=float(request.args.get('Price_range'))\n                \n        # Calling the funtion to get predictions\n        prediction_from_api=FunctionGeneratePrediction(\n                                                     inp_Votes=Votes_value,\n                                                     inp_Average_Cost=Average_Cost_value,\n                                                     inp_Price_range=Price_range_value\n                                                )\n\n        return (prediction_from_api)\n    \n    except Exception as e:\n        return('Something is not right!:'+str(e))","51244a70":"import os\nif __name__ ==\"__main__\":\n    \n    # Hosting the API in localhost\n    app.run(host='127.0.0.1', port=8080, threaded=True, debug=True, use_reloader=False)\n    # Interrupt kernel to stop the API","4e2b19f4":"# Replacing outliers for 'Votes'","eb3a2f96":"# Random Forest","32b7536c":"# XGBoost","6c3fb060":"I am choosing Decision Trees as the final model since it is very fast for this data!","db5d5e5a":"# Deployment of the Model","169fdc94":"# Machine Learning: Splitting the data into Training and Testing sample","17d1f50f":"# Starting the API engine","42bb3a79":"# Replacing outliers for 'Average Cost for two'","164a397d":"# Creating Flask API","adb3d9af":"# Selecting final predictors for Machine Learning","1d5b8919":"# KNN","15daf334":"# Looking at the distribution of Target variable","fffb4c20":"# Feature Selection","ff403d69":"# Converting the nominal variable to numeric using get_dummies()","b14e84cf":"# Basic Data Exploration","cc488f6e":"# Standardization\/Normalization of data","ecd59d0e":"# Feature Engineering","948a22d5":"# Visualize distribution of all the Continuous Predictor variables in the data using histograms","82613b39":"# AdaBoost","8fcf816b":"# Statistical Feature Selection (Categorical Vs Continuous) using ANOVA test","2a716708":"# Function for predictions API","d4f05941":"# Multiple Linear Regression","2ceb3dc5":"# Visual Exploratory Data Analysis","2a1779d0":"# Decision Trees","5a66d74b":"# Statistical Feature Selection (Continuous Vs Continuous) using Correlation value","3200eaf5":"Data description\nThe business meaning of each column in the data is as below\n\nRestaurant ID: The id for each restaurant\n\nRestaurant Name: The brand\/restaurant name\n\nCountry Code: In which country the restaurant is operating\n\nCity: In which city the restaurant is operating\n\nAddress: What is the address of the restaurant\n\nLocality: What is the locality of the restaurant\n\nLocality Verbose: Detailed locality description\n\nLongitude: GPS longitude location\n\nLatitude: GPS latitude location\n\nCuisines: Various type of food offered\n\nCurrency: The business currency\n\nHas Table booking: Is advance table booking facility available?\n\nHas Online delivery: Does they take online food orders?\n\nIs delivering now: Is is open now?\n\nSwitch to order menu: Whether switch to order menu is available?\n\nPrice range: The price range of the restaurant\n\nVotes: The number of people who voted for the rating\n\nAverage Cost for two: The typical cost for two people\n\nRating: The final rating of the restaurant\n","701aca9e":"# Relationship exploration: Categorical Vs Continuous -- Box Plots","c2fa4249":"# Removing useless columns from the data","a1755774":"# SVM"}}