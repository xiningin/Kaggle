{"cell_type":{"eb836671":"code","ef31df9e":"code","e7d3511b":"code","42ec636a":"code","8e846a4e":"code","fa77ee73":"code","07acb0e9":"code","fb0c1dc3":"code","808941c0":"code","564e1b6a":"code","4bb0f638":"code","303a410d":"code","0e72b840":"code","458f3dd7":"code","5bf2598d":"code","da9d6896":"code","ec9ff7b7":"code","65d3f5dd":"code","2581940b":"code","2c4efd88":"code","deb6286e":"code","8063de89":"code","f104747c":"markdown","3916c732":"markdown","e8044919":"markdown","ad601c01":"markdown","b2b77f78":"markdown","275ecb80":"markdown","7d4d047b":"markdown","c6021ca8":"markdown","ade52d72":"markdown","89516faa":"markdown","a6b8b0c4":"markdown","9c1c8c80":"markdown","af6b0dd8":"markdown"},"source":{"eb836671":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport random\n\nrandom.seed(224)\nwarnings.filterwarnings('ignore')","ef31df9e":"df = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\nprint(df.shape)\ndf.head()","e7d3511b":"df.info()","42ec636a":"# Renaming columns\ndf.columns = ['Age', 'Sex', 'ChestPainType', 'RestingBloodPressure', 'Cholesterol', 'FastingBloodSugar', 'RestingECG', 'MaxHeartRate',\n       'ExerciseInducedAngina', 'PreviousPeak', 'Slope', 'MajorBloodVessels', 'ThalRate', 'ProbHA']\n\ncategoricals = ['Sex', 'ChestPainType', 'FastingBloodSugar', 'RestingECG', 'ExerciseInducedAngina', 'Slope', 'ThalRate', 'ProbHA']\nnumericals = [i for i in df.columns if i not in categoricals]","8e846a4e":"for col in df[categoricals]:\n    print(f'We have {len(df[col].unique())} unique values in --{col}-- column: {df[col].unique()}')","fa77ee73":"# Count plots for categorical features\nx=0\nfig=plt.figure(figsize=(15,10),constrained_layout =True)\nplt.subplots_adjust(wspace = 0.5)\nplt.suptitle(\"Count of the Categorical Variables\",y=0.95, family='Sherif', size=18, weight='bold')\nfor i in df[categoricals]:\n    ax = plt.subplot(241+x)\n    ax = sns.countplot(data=df, x=i, color = 'salmon')\n    plt.grid(axis='y')\n    x+=1","07acb0e9":"df[numericals].describe()","fb0c1dc3":"corr = df.corr()\n\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nwith sns.axes_style('white'):\n    fig, ax = plt.subplots(figsize=(18,10))\n    sns.heatmap(corr,  mask=mask, cmap='YlGnBu', annot=True, center=0, vmin=-1, vmax=0.8,\n                square=True, cbar_kws={'shrink':.5, 'orientation': 'vertical'}, linewidth=.02)","808941c0":"x=0\nfig=plt.figure(figsize=(15,10),constrained_layout =True)\nplt.subplots_adjust(wspace = 0.5)\nplt.suptitle(\"Distribution of numerical variables\",y=0.95, family='Sherif', size=18, weight='bold')\nfor i in df[numericals]:\n    ax = plt.subplot(231+x)\n    ax = sns.boxplot(data=df, y=i, color = 'salmon')\n    x+=1","564e1b6a":"df.drop(df[df['Cholesterol'] > 500].index, inplace = True)\ndf.drop(df[df['MaxHeartRate'] < 80].index, inplace = True)\ndf.shape[0]","4bb0f638":"print(df['ProbHA'].value_counts())\n\npie, ax = plt.subplots(figsize=[15,10])\nlabels = ['More chance to HA', 'Less chance to HA']\ncolors = ['#ff8533', '#7070db']\nplt.pie(x = df['ProbHA'].value_counts(), autopct='%.2f%%', explode=[0.02]*2, labels=labels, pctdistance=0.5, textprops={'fontsize': 14}, colors = colors)\nplt.title('Distributin of target variable in %')\nplt.show()","303a410d":"x=0\nfig=plt.figure(figsize=(15,10),constrained_layout =True)\nplt.subplots_adjust(wspace = 0.5)\nplt.suptitle(\"Count of the categorical variables by target variable\",y=0.95, family='Sherif', size=18, weight='bold')\nfor i in df[categoricals]:\n    ax = plt.subplot(241+x)\n    ax = sns.countplot(data=df, x=i, hue='ProbHA', palette = colors)\n    ax.legend_.remove()\n    plt.grid(axis='y')\n    x+=1","0e72b840":"x=0\nfig=plt.figure(figsize=(15,10),constrained_layout =True)\nplt.subplots_adjust(wspace = 0.5)\nplt.suptitle(\"Distribution of numerical variables by target variable\",y=0.95, family='Sherif', size=18, weight='bold')\nfor i in df[numericals]:\n    ax = plt.subplot(231+x)\n    ax = sns.histplot(data=df, x=i, hue='ProbHA', palette=colors, element='poly')\n    ax.legend_.remove()\n    x+=1","458f3dd7":"x=0\nfig=plt.figure(figsize=(15,10),constrained_layout =True)\nplt.subplots_adjust(wspace = 0.5)\nplt.suptitle(\"Relationships between age and numerical features by target variable\",y=0.95, family='Sherif', size=18, weight='bold')\nfor i in df[numericals[1:]]:\n    ax = plt.subplot(231+x)\n    ax = sns.scatterplot(data=df, x='Age', y=i, hue='ProbHA', palette=colors)\n    ax.legend_.remove()\n    x+=1","5bf2598d":"# Split into features & target; train & test\n# Normalize features\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import Normalizer\ny = df['ProbHA']\nX = df.drop('ProbHA', axis = 1)\n\nnormalize = Normalizer()\nX = normalize.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123, shuffle = True, stratify = y)\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","da9d6896":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\nmodels = [('DT', DecisionTreeClassifier()),\n          ('LR', LogisticRegression()), \n          ('SGDC', SGDClassifier()), \n          ('SVC', SVC())]\n\n# Baseline models trainining and evaluation\nfor name, model in models:\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    acc = accuracy_score(y_test, preds)\n    print(f'The accuracy of {name} is {acc:.3f}')","ec9ff7b7":"import xgboost as xgb\n\n# Basline XGBClassifier\nxgb_cl = xgb.XGBClassifier()\nxgb_cl.fit(X_train, y_train)\npreds = xgb_cl.predict(X_test)\nscore = accuracy_score(y_test, preds)\nprint(f'The accuracy of XGBClassifier is {score:.3f}')","65d3f5dd":"# Grid search\nfrom sklearn.model_selection import GridSearchCV\n\nparams_grid = {'learning_rate':[0.01, 0.1, 0.5, 0.9],\n              'n_estimators':[100,200,300],\n              'subsample':[0.3, 0.5, 0.9],\n               'max_depth':[2,3,4],\n               'colsample_bytree':[0.3,0.5,0.7,1]}\ngrid = GridSearchCV(estimator=xgb_cl, param_grid=params_grid, scoring='accuracy', cv = 10)\n\ngrid.fit(X_train, y_train)\nprint(f'Best params found for XGBoost are: {grid.best_params_}')\nprint(f'Best accuracy obtained by the best params: {grid.best_score_}')","2581940b":"preds = grid.best_estimator_.predict(X_test)\nprint(accuracy_score(y_test, preds))","2c4efd88":"from sklearn.metrics import confusion_matrix, plot_confusion_matrix, roc_curve, auc\n# Confusion matrix\nconfusion_matrix(y_test, preds)","deb6286e":"plot_confusion_matrix(grid.best_estimator_, X_test, y_test)","8063de89":"probs = grid.best_estimator_.predict_proba(X_test)\npred = probs[:,1]\nfpr, tpr, threshold = roc_curve(y_test, pred)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(12,8))\nplt.title('ROC')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0,1], [0,1], 'r--')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","f104747c":"## Hyperparameters tuning for XGBoost","3916c732":"# Data preparation","e8044919":"Out of 61 samples, the XGBoost misscassified 6","ad601c01":"# Modeling","b2b77f78":"# Investigate numerical features","275ecb80":"Outlier: Cholesterol > 500; MaxHeartRate < 80\n","7d4d047b":"# <p style=\"background-color:  #ff8080; font-family: Helvetica, fantasy; line-height: 1.3; font-size: 26px; letter-spacing: 3px; text-align: center; color: #ffffff\">Heart Attack Prediction using Extreme Gradient Boosting (XGBoost)<\/p>\n\n![](https:\/\/hips.hearstapps.com\/hmg-prod.s3.amazonaws.com\/images\/pink-porcelain-anatomical-heart-royalty-free-image-1597338342.jpg)","c6021ca8":"# Investigate categorical features","ade52d72":"## AUC evaluation of XGBoost","89516faa":"# Exploratory Data Analysis (EDA)","a6b8b0c4":"## Ensembling with XGBoost (Extreme Gradient Boosting)","9c1c8c80":"<p style=\"background-color:  #ff8080; font-family: Helvetica, fantasy; line-height: 1.3; font-size: 26px; letter-spacing: 3px; text-align: center; color: #ffffff\">Dataset description<\/p>\n\n- age : Age of the patient\n- Sex : 1 = male; 0 = female\n- exng: exercise induced angina (1 = yes; 0 = no)\n- oldpeak: ST depression induced by exercise relative to rest\n- slp: the slope of the peak exercise ST segment (2 = upsloping; 1 = flat; 0 = downsloping)\n- thall: 2 = normal; 1 = fixed defect; 3 = reversable defect.\n- caa: number of major vessels (0-3)\n- cp : Chest Pain type chest pain type\n - Value 0: typical angina\n - Value 1: atypical angina\n - Value 2: non-anginal pain\n - Value 3: asymptomatic\n- trtbps : resting blood pressure (in mm Hg)\n- chol : cholestoral in mg\/dl fetched via BMI sensor\n- fbs : (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n- restecg : resting electrocardiographic results\n - Value 0: normal\n - Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n- thalachh : maximum heart rate achieved\n- output: target : 0 = less chance of heart attack 1 = more chance of heart attack","af6b0dd8":"Insights:\n - The number of males that are more likely to have a HA from the number of total males is higher than females.\n - The individuals who present a typical angina chest type are more likely to have a HA.\n - The individuals with normal (0) resting electrocardiographic results (Resting ECG) appear to be more likely to suffer a HA.\n - If angina is exercise induced, is more likely to suffer a HA.\n - If the slope of the peak exercise ST segment is flat, is more likely to suffer a HA.\n - If the thal rate is reversable defect, is more likely to suffer a HA. "}}