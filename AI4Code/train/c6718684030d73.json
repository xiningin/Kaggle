{"cell_type":{"8411cac2":"code","5aaa0bd7":"code","492e8b1c":"code","1e778c00":"code","1c3802ff":"code","d68664b1":"code","85066bca":"code","cce1fbe7":"code","7d9356d3":"code","2f49c238":"code","644871e2":"code","40839797":"code","66f5d936":"code","2e770511":"code","bc6ecafa":"code","a095af25":"code","7cf7b8c7":"code","560e739d":"code","c921e7b0":"code","9eb5b12c":"code","03162949":"code","69e07a45":"code","a519a2ee":"code","986cb16e":"code","c76cc7ff":"code","22c1f627":"code","1cf48a6f":"code","9485ec05":"markdown","63d46600":"markdown","70482701":"markdown","ad40bffd":"markdown","0b0950e5":"markdown","7e31aecf":"markdown","d338bf3c":"markdown","e3719664":"markdown","ed2c69ec":"markdown","8e014b7c":"markdown","7c884964":"markdown","abd66ea3":"markdown","fa2d09a1":"markdown","258af1a7":"markdown","735f6b7c":"markdown","935b14dd":"markdown","fe4afce8":"markdown","4cddc2df":"markdown","758691ea":"markdown","ed653d99":"markdown"},"source":{"8411cac2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nfrom sklearn import preprocessing, metrics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM,Dropout\nfrom keras.layers import RepeatVector,TimeDistributed\nfrom numpy import array\nfrom keras.models import Sequential, load_model\n#import utils_paths\nimport re\nfrom tqdm import tqdm\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5aaa0bd7":"train_sales = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\ncalendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')\nsell_prices = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv')\nsubmission_file = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sample_submission.csv')","492e8b1c":"num = 30490 # number of traindata","1e778c00":"def transform(data):\n    \n    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n    for feature in nan_features:\n        data[feature].fillna('unknown', inplace = True)\n        \n    cat = ['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']\n    for feature in cat:\n        encoder = preprocessing.LabelEncoder()\n        data[feature] = encoder.fit_transform(data[feature])\n    \n    return data\n","1c3802ff":"days = range(1, 1970)\ntime_series_columns = [f'd_{i}' for i in days]\ntransfer_cal = pd.DataFrame(calendar[['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']].values.T, index=['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI'], columns= time_series_columns)\ntransfer_cal = transfer_cal.fillna(0)\nevent_name_1_se = transfer_cal.loc['event_name_1'].apply(lambda x: x if re.search(\"^\\d+$\", str(x)) else np.nan).fillna(10)\nevent_name_2_se = transfer_cal.loc['event_name_2'].apply(lambda x: x if re.search(\"^\\d+$\", str(x)) else np.nan).fillna(10)\n","d68664b1":"calendar['date'] = pd.to_datetime(calendar['date'])\ncalendar = calendar[calendar['date']>= '2016-1-27']  #reduce memory\ncalendar= transform(calendar)\n# Attempts to convert events into time series data.\ntransfer_cal = pd.DataFrame(calendar[['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI']].values.T,\n                            index=['event_name_1','event_type_1','event_name_2','event_type_2','snap_CA','snap_TX','snap_WI'])\ntransfer_cal","85066bca":"price_fea = calendar[['wm_yr_wk','date']].merge(sell_prices, on = ['wm_yr_wk'], how = 'left')\nprice_fea['id'] = price_fea['item_id']+'_'+price_fea['store_id']+'_validation'\ndf = price_fea.pivot('id','date','sell_price')","cce1fbe7":"price_df = train_sales.merge(df,on=['id'],how= 'left').iloc[:,-145:]\nprice_df.index = train_sales.id\nprice_df.head()","7d9356d3":"days = range(1, 1913 + 1)\ntime_series_columns = [f'd_{i}' for i in days]\ntime_series_data = train_sales[time_series_columns]  #Get time series data","2f49c238":"#show last 28days\nfigsize = (25, 5)\ntime_series_data.iloc[15, -28:].plot(figsize=figsize)\n\nplt.grid()\n#The last 28 days\nprint(time_series_data.iloc[0, 1885:].shape)","644871e2":"def min_max(df):\n    return (df-df.mean())\/df.std()  #scale","40839797":"calendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')","66f5d936":"for i in range(2,6):\n    price_sell = calendar.merge(sell_prices[sell_prices.item_id=='HOBBIES_1_00'+str(i)][sell_prices.store_id=='CA_1'], on = ['wm_yr_wk'], how = 'left')\n    fig =plt.figure(figsize= (20, 5))\n    ax = fig.add_subplot(1, 1, 1)\n    ax.plot(min_max(time_series_data.iloc[i].values))\n    ax.plot(min_max(price_sell.sell_price),'-o')\n    plt.legend(['sale','price'])\n    ax.set_title(str(i))\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Sales')","2e770511":"for i in range(5,10):\n    fig =plt.figure(figsize= (20, 5))\n    ax = fig.add_subplot(1, 1, 1)\n    #ax.bar(x = range(len(transfer_cal.loc['snap_WI'][1500:1800].values)),height = transfer_cal.loc['snap_TX'][1500:1800].values,label='snap_TX',facecolor='red')\n    ax.plot(time_series_data.iloc[i, 500:800].values,label='sales')\n    ax.bar(x = range(300),height = event_name_1_se[500:800].values*0.05*time_series_data.iloc[i, 500:800].values.max(),label='type_1',facecolor='black',width=1.2)\n    ax.bar(x = range(300),height = event_name_2_se[500:800].values*0.05*time_series_data.iloc[i, 500:800].values.max(),label='type_2',facecolor='orange',width=1.2)\n    plt.legend(['sale','event_1','event_2'])\n    ax.set_title(str(i))\n\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Sales')","bc6ecafa":"for i in train_sales.cat_id.unique():\n    fig =plt.figure(figsize= (20, 5))\n    for j in range(10):\n        ax = fig.add_subplot(1, 1, 1)\n        ax.plot(train_sales[train_sales.cat_id==i].iloc[j, :][time_series_columns].values)\n        ax.set_title(str(i))\n        ax.set_xlabel('Time')\n        ax.set_ylabel('Sales')","a095af25":"for i in train_sales.dept_id.unique():\n    fig =plt.figure(figsize= (20, 5))\n    for j in range(10):\n        ax = fig.add_subplot(1, 1, 1)\n        ax.plot(train_sales[train_sales.dept_id==i].iloc[j, :][time_series_columns].values)\n        ax.set_title(str(i))\n        ax.set_xlabel('Time')\n        ax.set_ylabel('Sales')","7cf7b8c7":"for i in train_sales.store_id.unique():\n    fig =plt.figure(figsize= (20, 5))\n    for j in range(10):\n        ax = fig.add_subplot(1, 1, 1)\n        ax.plot(train_sales[train_sales.store_id==i].iloc[j, :][time_series_columns].values)\n        ax.set_title(str(i))\n        ax.set_xlabel('Time')\n        ax.set_ylabel('Sales')","560e739d":"\nX = []   #build a data with two features(salse and event1)\nfor i in tqdm(range(time_series_data.shape[0])):\n    X.append([list(t) for t in zip(transfer_cal.loc['event_name_1'][-(100+28):-(28)],\n                                   transfer_cal.loc['event_type_1'][-(100+28):-(28)],\n                                   transfer_cal.loc['event_name_2'][-(100+28):-(28)],     #emmmm.....Those features didn't work for me...\n                                   transfer_cal.loc['event_type_2'][-(100+28):-(28)],\n                                   transfer_cal.loc['snap_CA'][-(100+28):-(28)],\n                                   transfer_cal.loc['snap_TX'][-(100+28):-(28)],\n                                   transfer_cal.loc['snap_WI'][-(100+28):-(28)],\n                                   price_df.iloc[i][-(100+28):-(28)],\n                                   time_series_data.iloc[i][-100:])]) \n\nX = np.asarray(X, dtype=np.float32)","c921e7b0":"\ndef Normalize(list):\n    list = np.array(list)\n    low, high = np.percentile(list, [0, 100])\n    delta = high - low\n    if delta != 0:\n        for i in range(0, len(list)):\n            list[i] = (list[i]-low)\/delta\n    return  list,low,high\n\ndef FNoramlize(list,low,high):\n    delta = high - low\n    if delta != 0:\n        for i in range(0, len(list)):\n            list[i] = list[i]*delta + low\n    return list\n\ndef Normalize2(list,low,high):\n    list = np.array(list)\n    delta = high - low\n    if delta != 0:\n        for i in range(0, len(list)):\n            list[i] = (list[i]-low)\/delta\n    return  list\n","9eb5b12c":"np.random.seed(7)\n\n ## I only use the last 56 days for train_data.\nif __name__ == '__main__':\n    n_steps = 28\n    train_n,train_low,train_high = Normalize(X[:,-(n_steps*2):,:])\n    X_train = train_n[:,-28*2:-28,:]\n    y = train_n[:,-28:,8]  #     \n    # reshape from [samples, timesteps] into [samples, timesteps, features]\n    n_features = 9\n    n_out_seq_length =28\n    num_y = 1\n    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n    y = y.reshape((y.shape[0], y.shape[1], 1))\n    print(X_train.shape)\n    # define model\n\n    model = Sequential()\n\n    \n    model.add(LSTM(128, activation='relu', input_shape=(28, n_features),return_sequences=False))\n    model.add(RepeatVector(n_out_seq_length))\n    model.add(LSTM(32, activation='relu',return_sequences=True))\n   #model.add(Dropout(0.1))  \n    model.add(TimeDistributed(Dense(num_y)))   # num_y means the shape of y,in some problem(like translate), it can be many.\n                                                #In that case, you should set the  activation= 'softmax'\n    model.compile(optimizer='adam', loss='mse')\n    # demonstrate prediction\n    model.fit(X_train, y, epochs=10, batch_size=1000)","03162949":"x_input = array(X_train[:,-n_steps*1:])\nx_input = x_input.reshape((num, n_steps*1, n_features))\nprint(x_input.shape)\n#x_input = Normalize2(x_input,train_low,train_high)\nyhat = model.predict(x_input[:,-n_steps:], verbose=0)\nx_input=np.concatenate((x_input[:,:,8].reshape(x_input.shape[0],x_input.shape[1]),yhat.astype(np.float32).reshape(x_input.shape[0],x_input.shape[1])),axis=1).reshape((x_input.shape[0],x_input.shape[1]+28,1))\n#print(yhat)\nprint(x_input.shape)","69e07a45":"x_input = FNoramlize(x_input,train_low,train_high)\nx_input = np.rint(x_input)","a519a2ee":"forecast = pd.DataFrame(x_input.reshape(x_input.shape[0],x_input.shape[1])).iloc[:,-28:]\nforecast.columns = [f'F{i}' for i in range(1, forecast.shape[1] + 1)]\nforecast[forecast < 0] =0\nforecast.head()","986cb16e":"validation_ids = train_sales['id'].values\nevaluation_ids = [i.replace('validation', 'evaluation') for i in validation_ids]","c76cc7ff":"ids = np.concatenate([validation_ids, evaluation_ids])","22c1f627":"predictions = pd.DataFrame(ids, columns=['id'])\nforecast = pd.concat([forecast]*2).reset_index(drop=True)\npredictions = pd.concat([predictions, forecast], axis=1)","1cf48a6f":"predictions.to_csv('submission.csv', index=False)  #Generate the csv file.","9485ec05":"## **Try to visualize the relationship between event and sales ** <a id=\"2.3\"><\/a>","63d46600":"# **Import libraries and load dataset** <a id=\"1\"><\/a>","70482701":"This notebook is based on the notebook by RDizzl3 : https:\/\/www.kaggle.com\/rdizzl3\/eda-and-baseline-model\n\nContent structure from https:\/\/www.kaggle.com\/tarunpaparaju\/m5-competition-eda-models  by @tarunpaparaju\n\nEncoder-Decoder LSTM:https:\/\/machinelearningmastery.com\/learn-add-numbers-seq2seq-recurrent-neural-networks\/\n--Jason Brownlee\n\nTimeDistributed:https:\/\/keras.io\/zh\/layers\/wrappers\/\n\nBecause I wanted to make a simple version first, So I only used the last 56 days for training.\n\n<font size=3 color=\"red\">This is my first public notebook,Welcome to upvote,Thanks! I will keep improve the model.<\/font>\n","ad40bffd":"##  **Try to visualize the relationship between prices and sales ** <a id=\"2.2\"><\/a>","0b0950e5":"# **Contents**\n\n* [<font size=4>Import libraries and load dataset<\/font>](#1)\n\n\n* [<font size=4>Visualizing the Time Series(EDA)<\/font>](#2)\n    * [Preparing the time series](#2.1)\n    * [Visualizing the relationship between prices and sales](#2.2)\n    * [Visualizing the relationship between event and sales](#2.3)\n    * [Comparing the values under each category label](#2.4)\n\n    \n* [<font size=4>Build a LSTM Model<\/font>](#3)\n    * [Normalize](#3.1)\n    * [Why Use a TimeDistributed Layer?](#3.2)\n    * [Why Use a RepeatVector Layer?](#3.3)\n\n\n* [<font size=4>Make prediction<\/font>](#4)\n","7e31aecf":"# Conclusion:\n* The encode-decode model and more features didn's improve score a lot. \n* But it is also an attempt,maybe this architecture can help you guys in other problems.","d338bf3c":"**So far, we have eight features from calendar and sell_prices: **\n> 1. event_name_1\n> 2. event_type_1\n> 3. event_name_2\n> 4. event_type_2\n> 5. snap_CA\n> 6. snap_TX\n> 7. snap_WI\n> 8. sell_price","e3719664":"##  Comparing the values under each category label <a id=\"2.4\"><\/a>\n* We need to find the groups that have the larger variance.","ed2c69ec":"# Build a LSTM Model <a id=\"3\"><\/a>\n\n* We build a network with a lstm layer and a dense layer.\n* Input with 2 features,and only use the last 56days as train data.","8e014b7c":"##  **Preparing the time series** <a id=\"2.1\"><\/a>","7c884964":"\n# **M5 competition: Predict Future sales **\n![timg.jpg](attachment:timg.jpg)\n# Introduction\uff1a\n### In this notebook, we will forecast future sales from the perspective of time series\n* **The historical sales volume of each commodity is used as a separate data set to predict the future sales volume**\n* We build an Encoder-Decoder LSTM.\n* The input has 9 features,and only use 56 days for trainning. \n* I use the first 28days(of the last 56days) for trainning and the last 28days(of the last 56days) as labels\n\n![image.png](attachment:image.png)","abd66ea3":"*  Due to the large difference of input data, we need to use normalization.\n\nThe low and high is use to remember the lowest and highest values of train date to translate the prediction to normal size.","fa2d09a1":"** Notice ** : I made a 28 days delay for event features.\n\nBeacause I think if I want to predict the sales of 28days late, I need to give the model features from the 28days later.","258af1a7":"#### It seems that there is no obvious relationship between price and sales volume, and adding price is not easy to deal with, we temporarily give up the price feature.","735f6b7c":"## Why Use a RepeatVector Layer? <a id=\"3.3\"><\/a>\n\n*    That is, one output for each LSTM at each input sequence time step rather than one output for each LSTM for the whole input sequence.\n\n*    An output for each step of the input sequence gives the decoder access to the intermediate representation of the input sequence each step. This may or may not be useful. Providing the final LSTM output at the end of the input sequence may be more logical as it captures information about the entire input sequence, ready to map to or calculate an output.\n","935b14dd":"# Make prediction <a id=\"4\"><\/a>\n* We are using the last 28days to predict the future.","fe4afce8":"# Visualizing the Time Series <a id=\"2\"><\/a>\n\nBelow I make a simple plot of the first time series in the data.","4cddc2df":"## Why Use a TimeDistributed Layer? <a id=\"3.2\"><\/a>\n![](https:\/\/ae01.alicdn.com\/kf\/H0d1d47c633fb4964804a53d6ad248967T.jpg)\n* In fact, the TimeDistributed layer gives the model a one-to-many, many-to-many capability and also adds dimension to the model.","758691ea":"##  Normalize <a id=\"3.1\"><\/a>","ed653d99":"* ### It looks like The values under category Dept_id  vary greatly."}}