{"cell_type":{"1245853f":"code","9e2be274":"code","08fc9f6c":"code","23f11ec7":"code","465ef963":"code","175cd460":"code","67a4e584":"code","5f35df81":"code","ea853f2d":"code","4b0f6c21":"code","be10d02d":"code","2b5cd317":"code","6b4dfe59":"code","f2ab3d2c":"code","2a9bb11d":"code","1c67c4cc":"code","d9c715df":"code","6678f304":"code","08d439e8":"code","d4943579":"code","ca2728b7":"code","c51a4892":"code","9f180f02":"code","33a0a0ae":"code","97e8c5f3":"markdown","7ceb1b7f":"markdown","2a435ca2":"markdown","1ddf1cd4":"markdown","0098b185":"markdown","7e628234":"markdown"},"source":{"1245853f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n    \n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9e2be274":"!pip install tensorflow==2.5.0","08fc9f6c":"pip install -U tensorflow_decision_forests","23f11ec7":"pip install wurlitzer","465ef963":"tf.__version__","175cd460":"import tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dense, Activation, Reshape, BatchNormalization, Add,Dropout, Concatenate, Average, Embedding,  Flatten, Conv1D, MaxPooling1D\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, QuantileTransformer, OneHotEncoder, KBinsDiscretizer\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.cluster import KMeans\nfrom tensorflow import keras\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom tensorflow.keras import backend as K\nimport tensorflow_decision_forests as tfdf\nfrom wurlitzer import sys_pipes","67a4e584":"pd.set_option('display.max_rows',150)","5f35df81":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/train.csv')\nX_test =  pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/test.csv')\ntrain.pop('id')\n\ny = train['loss']\ntrain.pop('loss')\n\nX_test.pop('id')\nX=train","ea853f2d":"X_train, X_val, y_train, y_val  = train_test_split(X,y,test_size=0.05,random_state=2021,stratify=y)","4b0f6c21":"# X_train_cat=X_train[['f1','f16','f27','f55','f86']]\n# X_val_cat=X_val[['f1','f16','f27','f55','f86']]\n# X_test_cat=X_test[['f1','f16','f27','f55','f86']]\n# X_train.drop(['f1','f16','f27','f55','f86'], axis=1)\n# X_val.drop(['f1','f16','f27','f55','f86'], axis=1)\n# X_test.drop(['f1','f16','f27','f55','f86'], axis=1)\n","be10d02d":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\nX_test = scaler.transform(X_test)","2b5cd317":"qt = QuantileTransformer(n_quantiles=60, output_distribution='uniform')\n\nX_train = qt.fit_transform(X_train)\nX_val = qt.transform(X_val)\nX_test = qt.transform(X_test)\n","6b4dfe59":"bin = KBinsDiscretizer(n_bins=60, encode='ordinal',strategy='uniform')\nX_train = bin.fit_transform(X_train)\nX_val = bin.transform(X_val)\nX_test = bin.transform(X_test)\n# X = bin.fit_transform(X)\n# X_test = bin.transform(X_test)","f2ab3d2c":"# bin_cat = KBinsDiscretizer(n_bins=10, encode='ordinal',strategy='uniform')\n# X_train_cat = bin_cat.fit_transform(X_train_cat)\n# X_val_cat = bin_cat.transform(X_val_cat)\n# X_test_cat = bin_cat.transform(X_test_cat)","2a9bb11d":"# X_train_cat.shape","1c67c4cc":"\ndef RegModel(input_shape):\n\n    \n\n    X_input = Input(input_shape)\n    X = Embedding (input_dim=60, output_dim=30)(X_input)\n    X = Flatten()(X)\n    X = Dropout(0.5)(X)\n\n    ll = Dense(40, kernel_initializer=tf.keras.initializers.GlorotNormal(), activation='swish')(X)\n#     X = BatchNormalization()(X)\n    X = Dropout(0.5)(ll)\n    X = Dense(1, kernel_initializer=tf.keras.initializers.GlorotNormal(),activation='swish', name='output2')(X)\n    model = Model(inputs = X_input, outputs = X, name='RegModel')\n    regmodel_wo_head = Model(inputs=model.inputs, outputs=ll)\n\n    df_and_nn_model = tfdf.keras.GradientBoostedTreesModel(preprocessing=regmodel_wo_head,\n                                                task=tfdf.keras.Task.REGRESSION,\n                                                num_trees=300,\n                                                max_depth=8,\n                                                max_num_nodes=-1,\n                                                min_examples=512,\n                                                validation_ratio=0.5,\n                                                l2_regularization=0.5,\n                                                subsample=0.8,\n                                                early_stopping='MIN_LOSS_FINAL',\n                                                shrinkage=0.008,\n                                                growing_strategy='BEST_FIRST_GLOBAL')\n    return model, regmodel_wo_head , df_and_nn_model\n","d9c715df":"BATCH_SIZE=64\nSHUFFLE_BUFFER_SIZE = 100\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train,np.float32((y_train))))\nval_dataset = tf.data.Dataset.from_tensor_slices((X_val,np.float32((y_val))))\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\nval_dataset = val_dataset.batch(BATCH_SIZE)\ntest_dataset = tf.data.Dataset.from_tensor_slices(X_test)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","6678f304":"train_dataset.take(1)","08d439e8":"checkpoint_filepath = '\/kaggle\/working\/ckpt1'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True)","d4943579":"regmodel, regmodel_wo_head, df_and_nn_model  = RegModel(X_train.shape[1:])\n\nregmodel.compile(loss=tf.keras.losses.Huber(38), optimizer = keras.optimizers.Adam(learning_rate=0.0001), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n        \nregmodel.fit(train_dataset,\n        epochs = 10, \n        validation_data=val_dataset,\n        callbacks=[model_checkpoint_callback])","ca2728b7":"#regmodel.load_weights(checkpoint_filepath)\ndf_and_nn_model.compile(metrics=[tf.keras.metrics.RootMeanSquaredError()])\nwith sys_pipes():\n    df_and_nn_model.fit(train_dataset, validation_data=val_dataset)","c51a4892":"main_pred = df_and_nn_model.predict(test_dataset)","9f180f02":"main_pred[:50]","33a0a0ae":"sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-aug-2021\/sample_submission.csv')\nsub.iloc[:,1]=main_pred\nsub=sub.set_index('id')\nsub.to_csv('noise_prediction.csv')","97e8c5f3":"## LESS IS MORE :) Thing i learned from Laurent Pourchot","7ceb1b7f":"#### I have tried many models and it is my best result with Tensorflow library i think. Many Thanks to Laurent Pourchot for his notebook [Less is more](https:\/\/www.kaggle.com\/pourchot\/only-one-hidden-layer-for-neural-network). All in All this competetition is not adding much because we are predicting noise behaviour so there will be again big shakeup in LB. But lets have fun :)","2a435ca2":"# For 1 - fold predictions","1ddf1cd4":"## Introduction","0098b185":"## Binning the features in 60 categories","7e628234":"### Note for Huber loss, the higher delta the more MSE the lower delte the more MAE, in 20th runs i found out that delta ~34-46 making best scores"}}