{"cell_type":{"5e4a9efb":"code","1b2dc47b":"code","527e0b1c":"code","83a9c176":"code","a728c4ce":"code","9acde828":"code","7a877ffd":"code","ca7981c9":"code","7e3c80ef":"code","5bcf9c73":"code","b3fd01b9":"code","23adc245":"code","bca218a3":"code","223667a9":"code","a0f7ac98":"code","3ab3accd":"code","f1bc70dc":"code","fb8dd83c":"code","5d48c50d":"code","1dac27a7":"code","76618488":"code","ffb4523d":"code","00929349":"code","f665944e":"code","08a680d7":"code","e74e6f48":"code","808d86ad":"code","8f4f5d5d":"code","0366a078":"code","c2502fa0":"code","089423f3":"code","780e4bbb":"code","76fee6ef":"code","698ae2dc":"code","d77dea74":"code","870c8b19":"code","de337d7d":"code","d5e72c44":"code","5598341b":"code","ac58821a":"code","f23dbac0":"code","18a266e3":"code","69483bdc":"code","d67651ab":"code","3cfdaa8e":"code","853f334c":"code","a4f1e653":"code","9110681c":"code","19680a23":"code","41a38740":"code","5e271c4f":"code","e76fdbda":"code","c6614620":"code","1edfa95b":"code","93ea8bdb":"code","58c43c5d":"code","58f5fa29":"code","d4b29996":"code","60696d3f":"code","994ff5aa":"code","5723e3a9":"code","270663de":"code","18b04542":"code","797426ea":"code","9ccc1727":"code","fbd932c0":"code","1d161ce0":"code","5fb98ea2":"code","e360c23c":"code","8f9c602c":"code","ba415444":"code","69c75fd2":"code","b3513022":"code","e4a7540d":"code","06e183ad":"code","72d189ad":"code","5865b042":"code","56256d2a":"code","74ded060":"code","8ea4a12a":"code","79e95b27":"code","b978e070":"code","10b7a3f0":"code","2bcf1823":"code","30410c28":"code","7937880f":"code","b5ac1674":"code","80f41a29":"code","3cb5b1a4":"code","6002065d":"code","346ba1e5":"code","9e631fd3":"code","a227478c":"code","4ac51998":"code","f4238415":"code","e61a9e6a":"code","3faa2022":"code","5e33c49f":"code","c5f04627":"code","011e3915":"code","bf7cfff6":"code","625db3b0":"code","355f0795":"code","2cf0a1c4":"code","7093ba7c":"code","2c75b791":"code","5ce94feb":"code","a88b2f9d":"code","1445eb0f":"code","49a08fe0":"code","9ddfca7b":"code","0c0f9225":"code","c8949e55":"code","c86d7e21":"code","25c68ad4":"code","a18fd585":"code","c65257f3":"markdown","a1a37b6e":"markdown","37633fa8":"markdown","0f5dad99":"markdown","b4b7dffb":"markdown","565cd83e":"markdown","7d1dff40":"markdown","b7393403":"markdown","f95296cd":"markdown","ad403d8a":"markdown","e892de53":"markdown","e3e828c0":"markdown","bc20bd76":"markdown","c5ea6034":"markdown","57ae485d":"markdown","f55f03ee":"markdown","6418f0e8":"markdown","aae2b5d2":"markdown","86912c42":"markdown","80b409cc":"markdown","fc9c29c9":"markdown","4cb17023":"markdown","edcebe81":"markdown","4a7eaddb":"markdown","61706106":"markdown","e49fe436":"markdown","4d81e75a":"markdown","ca580318":"markdown","8dfc7c67":"markdown","1d5989a1":"markdown","a72f7065":"markdown","b469ad4c":"markdown","fb87cbae":"markdown","fe225dcc":"markdown","7a99aace":"markdown","a1f898fb":"markdown","bac08017":"markdown","108538b4":"markdown","2585a9c7":"markdown","6a9a4eff":"markdown","cc903cc4":"markdown","60822688":"markdown","e488274b":"markdown","d864e1ba":"markdown","90d7108a":"markdown","c1ffa1b8":"markdown","0d7a9bd0":"markdown","a20e7603":"markdown","ecaf9933":"markdown","3542ddef":"markdown","3d7de951":"markdown","88fcbc8d":"markdown","2bfed8d0":"markdown","2f98058a":"markdown","3eab297e":"markdown","b18188dc":"markdown","58db4a53":"markdown","60d2f127":"markdown","d2932701":"markdown","a72e325d":"markdown","ae61f2c4":"markdown","eb1c3581":"markdown","6456aba4":"markdown","c30451ef":"markdown","182e1d9c":"markdown","af460cbf":"markdown","1faa9d5f":"markdown","4a9a2b35":"markdown","6e78a614":"markdown","71f5f7a8":"markdown","70addc2d":"markdown","c2446d76":"markdown","9ccd2dde":"markdown","155767bb":"markdown","b2ec47e7":"markdown","89988caa":"markdown","a11b9549":"markdown","ae2cefad":"markdown","85785dd0":"markdown","407b09ab":"markdown","916f4256":"markdown","f2cc25ec":"markdown","9c10610b":"markdown","5db713d4":"markdown","305cef4f":"markdown","97f1be6f":"markdown","97ed256d":"markdown","f338c4a8":"markdown","36c89d10":"markdown","e77ea00b":"markdown","3ba73293":"markdown","09d2fc3a":"markdown","08227d2f":"markdown","e9026e35":"markdown","3c901adf":"markdown","b3e2f851":"markdown","766706ab":"markdown","f15978d2":"markdown","7ff511d9":"markdown","b9d4143a":"markdown","9df2d117":"markdown","46309cd7":"markdown","c31ccb8d":"markdown","2dc0d7e1":"markdown","8b3a7644":"markdown","1be86821":"markdown","3b810d83":"markdown","e9bba01f":"markdown","2d09600a":"markdown","be85e2bb":"markdown","39f17492":"markdown","abd42dfa":"markdown","5f713bf3":"markdown","719b1c6a":"markdown"},"source":{"5e4a9efb":"# Importing necessary libraries\n\nimport numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nimport shutil\ncolumns = shutil.get_terminal_size().columns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import average_precision_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import RidgeClassifier\n\nimport imblearn\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\n\nfrom IPython.display import Javascript\nfrom IPython.display import display","1b2dc47b":"# The dataset\n\ndata = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndata","527e0b1c":"features = list(data.columns)\nfeatures.remove('Class')","83a9c176":"# Statistical descriptions of the features\n\nfeatures_stat = data.drop(['Class'], axis = 1)\nfeatures_stat.describe()","a728c4ce":"EvalMetricLabels = ['MCC', 'F1-Score', 'F2-Score', 'Recall', 'Precision',\n                    'FM index', 'Specificity', 'G-mean', 'F0.5-Score', 'Accuracy']","9acde828":"# Separating independent variables and target variable\n\ny = data['Class'] # target variable\nX = data.drop('Class', axis = 1) # independent variables\n\n# Constructing training set and testing set\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 25)","7a877ffd":"z = list(y_train)\n\ncount0 = 0\ncount1 = 0\n\nfor i in z:\n    if i == 0:\n        count0 = count0 + 1\n    elif i == 1:\n        count1 = count1 + 1\n\n# Class frequencies\n\nclass_label_train = ['Authentic', 'Fraud']\nclass_frequency_train = [count0, count1]\n\nfig1 = px.pie(values = class_frequency_train,\n             names = class_label_train,\n             title = 'Frequency comparison of authentic and fraudulent transactions in the training dataset',\n             template = 'ggplot2'\n            )\nfig1.show()","ca7981c9":"data_train = pd.concat([X_train, y_train], axis = 1)\ndata_train_authentic = data_train[data_train['Class'] == 0]\ndata_train_fraudulent = data_train[data_train['Class'] == 1]","7e3c80ef":"# Amount vs Time for authentic and fraudulent transactions in the training set\n\nclass_list_train = list(y_train)\nfraud_status_train = []\nfor i in range(len(class_list_train)):\n    fraud_status_train.append(bool(class_list_train[i]))\n\nfig1 = px.scatter(data_train,\n                 x = 'Time',\n                 y = 'Amount', \n                 facet_col = fraud_status_train,\n                 color = fraud_status_train,\n                 title = 'Amount vs Time for the training set',\n                 template = 'ggplot2'\n                )\nfig1.show()","5bcf9c73":"data_train_authentic_under = data_train_authentic.sample(len(data_train_fraudulent))\ndata_train_under = pd.concat([data_train_authentic_under, data_train_fraudulent], axis = 0)\n\nX_train_under = data_train_under.drop('Class', axis = 1)\ny_train_under = data_train_under['Class']\n\nprint('Class frequencies after under-sampling:')\nprint(y_train_under.value_counts())\ny_train_under.value_counts().plot(kind = 'bar', title = 'Class frequencies after under-sampling')","b3fd01b9":"# Amount vs Time for authentic and fraudulent transactions in the training set after random under-sampling\n\nclass_list = list(y_train_under)\nfraud_status = []\nfor i in range(len(class_list)):\n    fraud_status.append(bool(class_list[i]))\n\nfig1 = px.scatter(data_train_under,\n                 x = 'Time',\n                 y = 'Amount', \n                 facet_col = fraud_status,\n                 color = fraud_status,\n                 title = 'Amount vs Time for the training set after random under-sampling',\n                 template = 'ggplot2'\n                )\nfig1.show()","23adc245":"data_train_fraudulent_over = data_train_fraudulent.sample(len(data_train_authentic), replace = 'True')\ndata_train_over = pd.concat([data_train_authentic, data_train_fraudulent_over], axis = 0)\n\nX_train_over = data_train_over.drop('Class', axis = 1)\ny_train_over = data_train_over['Class']\n\nprint('Class frequencies after over-sampling:')\nprint(y_train_over.value_counts())\ny_train_over.value_counts().plot(kind = 'bar', title = 'Class frequencies after over-sampling')","bca218a3":"# Amount vs Time for authentic and fraudulent transactions in the training set after random over-sampling\n\nclass_list = list(y_train_over)\nfraud_status = []\nfor i in range(len(class_list)):\n    fraud_status.append(bool(class_list[i]))\n\nfig1 = px.scatter(data_train_over,\n                 x = 'Time',\n                 y = 'Amount', \n                 facet_col = fraud_status,\n                 color = fraud_status,\n                 title = 'Amount vs Time',\n                 template = 'ggplot2'\n                )\nfig1.show()","223667a9":"imblearn_rus = RandomUnderSampler(random_state = 40, replacement = True)\nX_train_rus, y_train_rus = imblearn_rus.fit_resample(X_train, y_train)\n\nX_train_rus = pd.DataFrame(X_train_rus)\nX_train_rus.columns = features\n\ny_train_rus = pd.DataFrame(y_train_rus)\ny_train_rus.columns = ['Class']\n\ndata_train_under_imblearn = pd.concat([X_train_rus, y_train_rus], axis = 1)\n\nX_train_under_imblearn = data_train_under_imblearn.drop('Class', axis = 1)\ny_train_under_imblearn = data_train_under_imblearn['Class']\n\nprint('Class frequencies after under-sampling via imbalanced-learn library:')\nprint(y_train_under_imblearn.value_counts())\ny_train_under_imblearn.value_counts().plot(kind = 'bar',\n                                           title = 'Class frequencies after under-sampling via imbalanced-learn library')","a0f7ac98":"# Amount vs Time for authentic and fraudulent transactions in the training set after random under-sampling via imblearn\n\nclass_list = list(y_train_under_imblearn)\nfraud_status = []\nfor i in range(len(class_list)):\n    fraud_status.append(bool(class_list[i]))\n\nfig1 = px.scatter(data_train_under_imblearn,\n                 x = 'Time',\n                 y = 'Amount', \n                 facet_col = fraud_status,\n                 color = fraud_status,\n                 title = 'Amount vs Time',\n                 template = 'ggplot2'\n                )\nfig1.show()","3ab3accd":"imblearn_ros = RandomOverSampler(random_state = 40)\nX_train_ros, y_train_ros = imblearn_ros.fit_resample(X_train, y_train)\n\nX_train_ros = pd.DataFrame(X_train_ros)\nX_train_ros.columns = features\n\ny_train_ros = pd.DataFrame(y_train_ros)\ny_train_ros.columns = ['Class']\n\ndata_train_over_imblearn = pd.concat([X_train_ros, y_train_ros], axis = 1)\n\nX_train_over_imblearn = data_train_over_imblearn.drop('Class', axis = 1)\ny_train_over_imblearn = data_train_over_imblearn['Class']\n\nprint('Class frequencies after over-sampling via imbalanced-learn library:')\nprint(y_train_over_imblearn.value_counts())\ny_train_over_imblearn.value_counts().plot(kind = 'bar',\n                                          title = 'Class frequencies after over-sampling via imbalanced-learn library')","f1bc70dc":"# Amount vs Time for authentic and fraudulent transactions in the training set after random over-sampling via imblearn\n\nclass_list = list(y_train_over_imblearn)\nfraud_status = []\nfor i in range(len(class_list)):\n    fraud_status.append(bool(class_list[i]))\n\nfig1 = px.scatter(data_train_over_imblearn,\n                 x = 'Time',\n                 y = 'Amount', \n                 facet_col = fraud_status,\n                 color = fraud_status,\n                 title = 'Amount vs Time',\n                 template = 'ggplot2'\n                )\nfig1.show()","fb8dd83c":"smote = SMOTE()\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\nX_train_smote = pd.DataFrame(X_train_smote)\nX_train_smote.columns = features\nX_train_smote\n\ny_train_smote = pd.DataFrame(y_train_smote)\ny_train_smote.columns = ['Class']\ny_train_smote\n\ndata_train_over_smote = pd.concat([X_train_smote, y_train_smote], axis = 1)\n\nX_train_over_smote = data_train_over_smote.drop('Class', axis = 1)\ny_train_over_smote = data_train_over_smote['Class']\n\nprint('Class frequencies after over-sampling via SMOTE:')\nprint(y_train_over_smote.value_counts())\ny_train_over_smote.value_counts().plot(kind = 'bar', title = 'Class frequencies after over-sampling via SMOTE')","5d48c50d":"# Amount vs Time for authentic and fraudulent transactions in the training set after over-sampling via SMOTE\n\nclass_list = list(y_train_over_smote)\nfraud_status = []\nfor i in range(len(class_list)):\n    fraud_status.append(bool(class_list[i]))\n\nfig1 = px.scatter(data_train_over_smote,\n                 x = 'Time',\n                 y = 'Amount', \n                 facet_col = fraud_status,\n                 color = fraud_status,\n                 title = 'Amount vs Time',\n                 template = 'ggplot2'\n                )\nfig1.show()","1dac27a7":"nm = NearMiss()\nX_train_nm, y_train_nm = nm.fit_resample(X_train, y_train)\n\nX_train_nm = pd.DataFrame(X_train_nm)\nX_train_nm.columns = features\nX_train_nm\n\ny_train_nm = pd.DataFrame(y_train_nm)\ny_train_nm.columns = ['Class']\ny_train_nm\n\ndata_train_under_nm = pd.concat([X_train_nm, y_train_nm], axis = 1)\n\nX_train_under_nm = data_train_under_nm.drop('Class', axis = 1)\ny_train_under_nm = data_train_under_nm['Class']\n\nprint('Class frequencies after under-sampling via NearMiss:')\nprint(y_train_under_nm.value_counts())\ny_train_under_nm.value_counts().plot(kind = 'bar', title = 'Class frequencies after under-sampling via NearMiss')","76618488":"# Amount vs Time for authentic and fraudulent transactions in the training set after random under-sampling via NearMiss\n\nclass_list = list(y_train_under_nm)\nfraud_status = []\nfor i in range(len(class_list)):\n    fraud_status.append(bool(class_list[i]))\n\nfig1 = px.scatter(data_train_under_nm,\n                 x = 'Time',\n                 y = 'Amount', \n                 facet_col = fraud_status,\n                 color = fraud_status,\n                 title = 'Amount vs Time',\n                 template = 'ggplot2'\n                )\nfig1.show()","ffb4523d":"TrainingSets = ['Unaltered', 'RUS', 'ROS', 'RUS-IL', 'ROS-IL', 'SMOTE', 'NM']","00929349":"scaling = MinMaxScaler(feature_range = (-1,1)).fit(X_train)\n\nX_train_scaled_minmax = scaling.transform(X_train)\nX_train_under_scaled_minmax = scaling.transform(X_train_under)\nX_train_over_scaled_minmax = scaling.transform(X_train_over)\nX_train_under_imblearn_scaled_minmax = scaling.transform(X_train_under_imblearn)\nX_train_over_imblearn_scaled_minmax = scaling.transform(X_train_over_imblearn)\nX_train_over_smote_scaled_minmax = scaling.transform(X_train_over_smote)\nX_train_under_nm_scaled_minmax = scaling.transform(X_train_under_nm)\n\nX_test_scaled_minmax = scaling.transform(X_test)","f665944e":"logreg = LogisticRegression(max_iter = 1000)","08a680d7":"# Computation of confusion matrix, evaluation metrics and visualization of classes\n\ndef classification(model, X_train, y_train, X_test, y_test):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    y_test = list(y_test)\n    y_pred = list(y_pred)\n\n    # Confusion matrix\n    \n    class_names = ['Authentic', 'Fraudulent']\n    tick_marks_y = [0.25, 1.2]\n    tick_marks_x = [0.5, 1.5]\n\n    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n    confusion_matrix_df = pd.DataFrame(confusion_matrix, range(2), range(2))\n    plt.figure(figsize = (6, 4.75))\n    sns.set(font_scale = 1.4) # label size\n    plt.title(\"Confusion Matrix\")\n    sns.heatmap(confusion_matrix_df, annot = True, annot_kws = {\"size\": 16}, fmt = 'd') # font size\n    plt.yticks(tick_marks_y, class_names, rotation = 'vertical')\n    plt.xticks(tick_marks_x, class_names, rotation = 'horizontal')\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.grid(False)\n    plt.show()\n\n    # Evaluation metrics\n\n    TN = confusion_matrix[0, 0]\n    FP = confusion_matrix[0, 1]\n    FN = confusion_matrix[1, 0]\n    TP = confusion_matrix[1, 1]\n\n    accuracy = (TP + TN)\/(TP + FN + TN + FP)\n    \n    if (FP + TP == 0):\n        precision = float('NaN')\n    else:\n        precision = TP\/(TP + FP)\n        \n    if (TP + FN == 0):\n        recall = float('NaN')\n    else:\n        recall = TP\/(TP + FN)\n    \n    FM_index = np.sqrt(precision * recall) # Fowlkes-Mallows index\n\n    if (TP == 0):\n        F0_5_score = float('NaN')\n        F1_score = float('NaN')\n        F2_score = float('NaN')\n    else:\n        F0_5_score = (1.25 * precision * recall)\/((0.25 * precision) + recall)\n        F1_score = (2 * precision * recall)\/(precision + recall)\n        F2_score = (5 * precision * recall)\/((4 * precision) + recall)\n    \n    if (TN + FP == 0):\n        specificity = float('NaN')\n    else:\n        specificity = TN\/(TN + FP)\n\n    G_mean = np.sqrt(recall * specificity)\n\n    MCC_num = (TN * TP) - (FP * FN)\n    MCC_denom = np.sqrt((FP + TP) * (FN + TP) * (TN + FP) * (TN + FN))\n    \n    if (MCC_denom == 0):\n        MCC = float('NaN')\n    else:\n        MCC = MCC_num \/ MCC_denom # Matthews Correlation Coefficient\n    \n    # Summary\n\n    EvalMetricLabels = ['MCC', 'F1-Score', 'F2-Score', 'Recall', 'Precision',\n                        'FM index', 'Specificity', 'G-mean', 'F0.5-Score', 'Accuracy']\n    EvalMetricValues = [MCC, F1_score, F2_score, recall, precision, FM_index, specificity, G_mean, F0_5_score, accuracy]\n    \n    global summary\n    summary = pd.DataFrame(columns = ['Metric', 'Performance score'])\n    summary['Metric'] = EvalMetricLabels\n    summary['Performance score'] = EvalMetricValues\n    \n    # Performance of the model through confusion matrix\n    \n    fig1 = make_subplots(rows = 1, cols = 2, specs = [[{\"type\": \"pie\"}, {\"type\": \"pie\"}]])\n\n    fig1.add_trace(go.Pie(\n        labels = ['TP', 'FN'],\n        values = [TP, FN],\n        domain = dict(x = [0, 0.4]),\n        name = 'Positive Class'), \n        row = 1, col = 1)\n\n    fig1.add_trace(go.Pie(\n        labels = ['TN', 'FP'],\n        values = [TN, FP],\n        domain = dict(x = [0.4, 0.8]),\n        name = 'Negative Class'),\n        row = 1, col = 2)\n\n    fig1.update_layout(height = 450, showlegend = True)\n    fig1.show()","e74e6f48":"# Elements of confusion matrix\n\nclassification(logreg, X_train, y_train, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_logreg_unaltered = summary.copy()\nsummary_logreg_unaltered.set_index('Metric')\n\ny_score = logreg.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_logreg_unaltered_extended = summary.copy()\nsummary_logreg_unaltered_extended.loc[len(summary_logreg_unaltered_extended.index)] = ['AP', average_precision]\nsummary_logreg_unaltered_extended.loc[len(summary_logreg_unaltered_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_logreg_unaltered_extended.set_index('Metric')\n\nsummary_logreg_unaltered_index = summary_logreg_unaltered_extended.T\nsummary_logreg_unaltered_index.columns = summary_logreg_unaltered_index.iloc[0]\nsummary_logreg_unaltered_index.drop(summary_logreg_unaltered_index.index[0], inplace = True)\nsummary_logreg_unaltered_index","808d86ad":"# Elements of confusion matrix\n\nclassification(logreg, X_train_under, y_train_under, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_logreg_under = summary\nsummary_logreg_under.set_index('Metric')\n\ny_score = logreg.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_logreg_under_extended = summary.copy()\nsummary_logreg_under_extended.loc[len(summary_logreg_under_extended.index)] = ['AP', average_precision]\nsummary_logreg_under_extended.loc[len(summary_logreg_under_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_logreg_under_extended.set_index('Metric')\n\nsummary_logreg_under_index = summary_logreg_under_extended.T\nsummary_logreg_under_index.columns = summary_logreg_under_index.iloc[0]\nsummary_logreg_under_index.drop(summary_logreg_under_index.index[0], inplace = True)\nsummary_logreg_under_index","8f4f5d5d":"# Elements of confusion matrix\n\nclassification(logreg, X_train_over, y_train_over, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_logreg_over = summary\nsummary_logreg_over.set_index('Metric')\n\ny_score = logreg.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_logreg_over_extended = summary.copy()\nsummary_logreg_over_extended.loc[len(summary_logreg_over_extended.index)] = ['AP', average_precision]\nsummary_logreg_over_extended.loc[len(summary_logreg_over_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_logreg_over_extended.set_index('Metric')\n\nsummary_logreg_over_index = summary_logreg_over_extended.T\nsummary_logreg_over_index.columns = summary_logreg_over_index.iloc[0]\nsummary_logreg_over_index.drop(summary_logreg_over_index.index[0], inplace = True)\nsummary_logreg_over_index","0366a078":"# Elements of confusion matrix\n\nclassification(logreg, X_train_under_imblearn, y_train_under_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_logreg_under_imblearn = summary\nsummary_logreg_under_imblearn.set_index('Metric')\n\ny_score = logreg.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_logreg_under_imblearn_extended = summary.copy()\nsummary_logreg_under_imblearn_extended.loc[len(summary_logreg_under_imblearn_extended.index)] = ['AP', average_precision]\nsummary_logreg_under_imblearn_extended.loc[len(summary_logreg_under_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_logreg_under_imblearn_extended.set_index('Metric')\n\nsummary_logreg_under_imblearn_index = summary_logreg_under_imblearn_extended.T\nsummary_logreg_under_imblearn_index.columns = summary_logreg_under_imblearn_index.iloc[0]\nsummary_logreg_under_imblearn_index.drop(summary_logreg_under_imblearn_index.index[0], inplace = True)\nsummary_logreg_under_imblearn_index","c2502fa0":"# Elements of confusion matrix\n\nclassification(logreg, X_train_over_imblearn, y_train_over_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_logreg_over_imblearn = summary\nsummary_logreg_over_imblearn.set_index('Metric')\n\ny_score = logreg.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_logreg_over_imblearn_extended = summary.copy()\nsummary_logreg_over_imblearn_extended.loc[len(summary_logreg_over_imblearn_extended.index)] = ['AP', average_precision]\nsummary_logreg_over_imblearn_extended.loc[len(summary_logreg_over_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_logreg_over_imblearn_extended.set_index('Metric')\n\nsummary_logreg_over_imblearn_index = summary_logreg_over_imblearn_extended.T\nsummary_logreg_over_imblearn_index.columns = summary_logreg_over_imblearn_index.iloc[0]\nsummary_logreg_over_imblearn_index.drop(summary_logreg_over_imblearn_index.index[0], inplace = True)\nsummary_logreg_over_imblearn_index","089423f3":"# Elements of confusion matrix\n\nclassification(logreg, X_train_over_smote, y_train_over_smote, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_logreg_over_smote = summary\nsummary_logreg_over_smote.set_index('Metric')\n\ny_score = logreg.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_logreg_over_smote_extended = summary.copy()\nsummary_logreg_over_smote_extended.loc[len(summary_logreg_over_smote_extended.index)] = ['AP', average_precision]\nsummary_logreg_over_smote_extended.loc[len(summary_logreg_over_smote_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_logreg_over_smote_extended.set_index('Metric')\n\nsummary_logreg_over_smote_index = summary_logreg_over_smote_extended.T\nsummary_logreg_over_smote_index.columns = summary_logreg_over_smote_index.iloc[0]\nsummary_logreg_over_smote_index.drop(summary_logreg_over_smote_index.index[0], inplace = True)\nsummary_logreg_over_smote_index","780e4bbb":"# Elements of confusion matrix\n\nclassification(logreg, X_train_under_nm, y_train_under_nm, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_logreg_under_nm = summary\nsummary_logreg_under_nm.set_index('Metric')\n\ny_score = logreg.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_logreg_under_nm_extended = summary.copy()\nsummary_logreg_under_nm_extended.loc[len(summary_logreg_under_nm_extended.index)] = ['AP', average_precision]\nsummary_logreg_under_nm_extended.loc[len(summary_logreg_under_nm_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_logreg_under_nm_extended.set_index('Metric')\n\nsummary_logreg_under_nm_index = summary_logreg_under_nm_extended.T\nsummary_logreg_under_nm_index.columns = summary_logreg_under_nm_index.iloc[0]\nsummary_logreg_under_nm_index.drop(summary_logreg_under_nm_index.index[0], inplace = True)\nsummary_logreg_under_nm_index","76fee6ef":"summary_logreg = pd.DataFrame(columns = ['Metric'])\n\nsummary_logreg['Metric'] = EvalMetricLabels\nsummary_logreg_list = [summary_logreg_unaltered, summary_logreg_under, summary_logreg_over, summary_logreg_under_imblearn,\n                       summary_logreg_over_imblearn, summary_logreg_over_smote, summary_logreg_under_nm]\n\nfor i in summary_logreg_list:\n    summary_logreg = pd.merge(summary_logreg, i, on = 'Metric')\n    \nTrainingSetsMetric = TrainingSets.copy()\nTrainingSetsMetric.insert(0, 'Metric')\n\nsummary_logreg.columns = TrainingSetsMetric\nsummary_logreg.set_index('Metric', inplace = True)\nsummary_logreg","698ae2dc":"# Function to visually compare performances of the model applied on different training sets through evaluation metrics\n\ndef summary_visual(summary_model):\n  fig1 = make_subplots(rows = 2, cols = 4, shared_yaxes = True, subplot_titles = EvalMetricLabels)\n\n  fig1.add_trace(go.Bar(x = list(summary_model.columns), y = list(summary_model.loc['MCC'])), 1, 1)\n  fig1.add_trace(go.Bar(x = list(summary_model.columns), y = list(summary_model.loc['F1-Score'])), 1, 2)\n  fig1.add_trace(go.Bar(x = list(summary_model.columns), y = list(summary_model.loc['F2-Score'])), 1, 3)\n  fig1.add_trace(go.Bar(x = list(summary_model.columns), y = list(summary_model.loc['Recall'])), 1, 4)\n  fig1.add_trace(go.Bar(x = list(summary_model.columns), y = list(summary_model.loc['Precision'])), 2, 1)\n  fig1.add_trace(go.Bar(x = list(summary_model.columns), y = list(summary_model.loc['FM index'])), 2, 2)\n  fig1.add_trace(go.Bar(x = list(summary_model.columns), y = list(summary_model.loc['Specificity'])), 2, 3)\n  fig1.add_trace(go.Bar(x = list(summary_model.columns), y = list(summary_model.loc['Accuracy'])), 2, 4)\n\n  fig1.update_layout(height = 600, width = 1000, coloraxis = dict(colorscale = 'Bluered_r'), showlegend = False)\n  fig1.show()","d77dea74":"# Visual comparison of the model applied on different training sets through evaluation metrics\n\nsummary_visual(summary_logreg)","870c8b19":"k = 29\nknn = KNeighborsClassifier(n_neighbors = k, n_jobs = -1)","de337d7d":"# Elements of confusion matrix\n\nclassification(knn, X_train_scaled_minmax, y_train, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_knn_unaltered = summary\nsummary_knn_unaltered.set_index('Metric')\n\ny_pred_proba = knn.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_knn_unaltered_extended = summary.copy()\nsummary_knn_unaltered_extended.loc[len(summary_knn_unaltered_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_knn_unaltered_extended.set_index('Metric')\n\nsummary_knn_unaltered_index = summary_knn_unaltered_extended.T\nsummary_knn_unaltered_index.columns = summary_knn_unaltered_index.iloc[0]\nsummary_knn_unaltered_index.drop(summary_knn_unaltered_index.index[0], inplace = True)\nsummary_knn_unaltered_index","d5e72c44":"# Elements of confusion matrix\n\nclassification(knn, X_train_under_scaled_minmax, y_train_under, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_knn_under = summary\nsummary_knn_under.set_index('Metric')\n\ny_pred_proba = knn.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_knn_under_extended = summary.copy()\nsummary_knn_under_extended.loc[len(summary_knn_under_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_knn_under_extended.set_index('Metric')\n\nsummary_knn_under_index = summary_knn_under_extended.T\nsummary_knn_under_index.columns = summary_knn_under_index.iloc[0]\nsummary_knn_under_index.drop(summary_knn_under_index.index[0], inplace = True)\nsummary_knn_under_index","5598341b":"# Elements of confusion matrix\n\nclassification(knn, X_train_over_scaled_minmax, y_train_over, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_knn_over = summary\nsummary_knn_over.set_index('Metric')\n\ny_pred_proba = knn.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_knn_over_extended = summary.copy()\nsummary_knn_over_extended.loc[len(summary_knn_over_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_knn_over_extended.set_index('Metric')\n\nsummary_knn_over_index = summary_knn_over_extended.T\nsummary_knn_over_index.columns = summary_knn_over_index.iloc[0]\nsummary_knn_over_index.drop(summary_knn_over_index.index[0], inplace = True)\nsummary_knn_over_index","ac58821a":"# Elements of confusion matrix\n\nclassification(knn, X_train_under_imblearn_scaled_minmax, y_train_under_imblearn, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_knn_under_imblearn = summary\nsummary_knn_under_imblearn.set_index('Metric')\n\ny_pred_proba = knn.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_knn_under_imblearn_extended = summary.copy()\nsummary_knn_under_imblearn_extended.loc[len(summary_knn_under_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_knn_under_imblearn_extended.set_index('Metric')\n\nsummary_knn_under_imblearn_index = summary_knn_under_imblearn_extended.T\nsummary_knn_under_imblearn_index.columns = summary_knn_under_imblearn_index.iloc[0]\nsummary_knn_under_imblearn_index.drop(summary_knn_under_imblearn_index.index[0], inplace = True)\nsummary_knn_under_imblearn_index","f23dbac0":"# Elements of confusion matrix\n\nclassification(knn, X_train_over_imblearn_scaled_minmax, y_train_over_imblearn, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_knn_over_imblearn = summary\nsummary_knn_over_imblearn.set_index('Metric')\n\ny_pred_proba = knn.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_knn_over_imblearn_extended = summary.copy()\nsummary_knn_over_imblearn_extended.loc[len(summary_knn_over_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_knn_over_imblearn_extended.set_index('Metric')\n\nsummary_knn_over_imblearn_index = summary_knn_over_imblearn_extended.T\nsummary_knn_over_imblearn_index.columns = summary_knn_over_imblearn_index.iloc[0]\nsummary_knn_over_imblearn_index.drop(summary_knn_over_imblearn_index.index[0], inplace = True)\nsummary_knn_over_imblearn_index","18a266e3":"# Elements of confusion matrix\n\nclassification(knn, X_train_over_smote_scaled_minmax, y_train_over_smote, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_knn_over_smote = summary\nsummary_knn_over_smote.set_index('Metric')\n\ny_pred_proba = knn.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_knn_over_smote_extended = summary.copy()\nsummary_knn_over_smote_extended.loc[len(summary_knn_over_smote_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_knn_over_smote_extended.set_index('Metric')\n\nsummary_knn_over_smote_index = summary_knn_over_smote_extended.T\nsummary_knn_over_smote_index.columns = summary_knn_over_smote_index.iloc[0]\nsummary_knn_over_smote_index.drop(summary_knn_over_smote_index.index[0], inplace = True)\nsummary_knn_over_smote_index","69483bdc":"# Elements of confusion matrix\n\nclassification(knn, X_train_under_nm_scaled_minmax, y_train_under_nm, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_knn_under_nm = summary\nsummary_knn_under_nm.set_index('Metric')\n\ny_pred_proba = knn.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_knn_under_nm_extended = summary.copy()\nsummary_knn_under_nm_extended.loc[len(summary_knn_under_nm_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_knn_under_nm_extended.set_index('Metric')\n\nsummary_knn_under_nm_index = summary_knn_under_nm_extended.T\nsummary_knn_under_nm_index.columns = summary_knn_under_nm_index.iloc[0]\nsummary_knn_under_nm_index.drop(summary_knn_under_nm_index.index[0], inplace = True)\nsummary_knn_under_nm_index","d67651ab":"summary_knn = pd.DataFrame(columns = ['Metric'])\n\nsummary_knn['Metric'] = EvalMetricLabels\nsummary_knn_list = [summary_knn_unaltered, summary_knn_under, summary_knn_over, summary_knn_under_imblearn,\n                    summary_knn_over_imblearn, summary_knn_over_smote, summary_knn_under_nm]\n\nfor i in summary_knn_list:\n    summary_knn = pd.merge(summary_knn, i, on = 'Metric')\n    \nTrainingSetsMetric = TrainingSets.copy()\nTrainingSetsMetric.insert(0, 'Metric')\n\nsummary_knn.columns = TrainingSetsMetric\nsummary_knn.set_index('Metric', inplace = True)\nsummary_knn","3cfdaa8e":"# Visual comparison of the model applied on different training sets through various evaluation metrics\n\nsummary_visual(summary_knn)","853f334c":"dt = DecisionTreeClassifier()","a4f1e653":"# Elements of confusion matrix\n\nclassification(dt, X_train, y_train, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_dt_unaltered = summary\nsummary_dt_unaltered.set_index('Metric')\n\ny_pred_proba = dt.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_dt_unaltered_extended = summary.copy()\nsummary_dt_unaltered_extended.loc[len(summary_dt_unaltered_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_dt_unaltered_extended.set_index('Metric')\n\nsummary_dt_unaltered_index = summary_dt_unaltered_extended.T\nsummary_dt_unaltered_index.columns = summary_dt_unaltered_index.iloc[0]\nsummary_dt_unaltered_index.drop(summary_dt_unaltered_index.index[0], inplace = True)\nsummary_dt_unaltered_index","9110681c":"# Elements of confusion matrix\n\nclassification(dt, X_train_under, y_train_under, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_dt_under = summary\nsummary_dt_under.set_index('Metric')\n\ny_pred_proba = dt.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_dt_under_extended = summary.copy()\nsummary_dt_under_extended.loc[len(summary_dt_under_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_dt_under_extended.set_index('Metric')\n\nsummary_dt_under_index = summary_dt_under_extended.T\nsummary_dt_under_index.columns = summary_dt_under_index.iloc[0]\nsummary_dt_under_index.drop(summary_dt_under_index.index[0], inplace = True)\nsummary_dt_under_index","19680a23":"# Elements of confusion matrix\n\nclassification(dt, X_train_over, y_train_over, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_dt_over = summary\nsummary_dt_over.set_index('Metric')\n\ny_pred_proba = dt.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_dt_over_extended = summary.copy()\nsummary_dt_over_extended.loc[len(summary_dt_over_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_dt_over_extended.set_index('Metric')\n\nsummary_dt_over_index = summary_dt_over_extended.T\nsummary_dt_over_index.columns = summary_dt_over_index.iloc[0]\nsummary_dt_over_index.drop(summary_dt_over_index.index[0], inplace = True)\nsummary_dt_over_index","41a38740":"# Elements of confusion matrix\n\nclassification(dt, X_train_under_imblearn, y_train_under_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_dt_under_imblearn = summary\nsummary_dt_under_imblearn.set_index('Metric')\n\ny_pred_proba = dt.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_dt_under_imblearn_extended = summary.copy()\nsummary_dt_under_imblearn_extended.loc[len(summary_dt_under_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_dt_under_imblearn_extended.set_index('Metric')\n\nsummary_dt_under_imblearn_index = summary_dt_under_imblearn_extended.T\nsummary_dt_under_imblearn_index.columns = summary_dt_under_imblearn_index.iloc[0]\nsummary_dt_under_imblearn_index.drop(summary_dt_under_imblearn_index.index[0], inplace = True)\nsummary_dt_under_imblearn_index","5e271c4f":"# Elements of confusion matrix\n\nclassification(dt, X_train_over_imblearn, y_train_over_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_dt_over_imblearn = summary\nsummary_dt_over_imblearn.set_index('Metric')\n\ny_pred_proba = dt.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_dt_over_imblearn_extended = summary.copy()\nsummary_dt_over_imblearn_extended.loc[len(summary_dt_over_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_dt_over_imblearn_extended.set_index('Metric')\n\nsummary_dt_over_imblearn_index = summary_dt_over_imblearn_extended.T\nsummary_dt_over_imblearn_index.columns = summary_dt_over_imblearn_index.iloc[0]\nsummary_dt_over_imblearn_index.drop(summary_dt_over_imblearn_index.index[0], inplace = True)\nsummary_dt_over_imblearn_index","e76fdbda":"# Elements of confusion matrix\n\nclassification(dt, X_train_over_smote, y_train_over_smote, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_dt_over_smote = summary\nsummary_dt_over_smote.set_index('Metric')\n\ny_pred_proba = dt.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_dt_over_smote_extended = summary.copy()\nsummary_dt_over_smote_extended.loc[len(summary_dt_over_smote_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_dt_over_smote_extended.set_index('Metric')\n\nsummary_dt_over_smote_index = summary_dt_over_smote_extended.T\nsummary_dt_over_smote_index.columns = summary_dt_over_smote_index.iloc[0]\nsummary_dt_over_smote_index.drop(summary_dt_over_smote_index.index[0], inplace = True)\nsummary_dt_over_smote_index","c6614620":"# Elements of confusion matrix\n\nclassification(dt, X_train_under_nm, y_train_under_nm, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_dt_under_nm = summary\nsummary_dt_under_nm.set_index('Metric')\n\ny_pred_proba = dt.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_dt_under_nm_extended = summary.copy()\nsummary_dt_under_nm_extended.loc[len(summary_dt_under_nm_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_dt_under_nm_extended.set_index('Metric')\n\nsummary_dt_under_nm_index = summary_dt_under_nm_extended.T\nsummary_dt_under_nm_index.columns = summary_dt_under_nm_index.iloc[0]\nsummary_dt_under_nm_index.drop(summary_dt_under_nm_index.index[0])\nsummary_dt_under_nm_index","1edfa95b":"summary_dt = pd.DataFrame(columns = ['Metric'])\n\nEvalMetricLabels_dt = EvalMetricLabels\nsummary_dt['Metric'] = EvalMetricLabels\nsummary_dt_list = [summary_dt_unaltered, summary_dt_under, summary_dt_over, summary_dt_under_imblearn,\n                    summary_dt_over_imblearn, summary_dt_over_smote, summary_dt_under_nm]\n\nfor i in summary_dt_list:\n    summary_dt = pd.merge(summary_dt, i, on = 'Metric')\n    \nTrainingSetsMetric = TrainingSets.copy()\nTrainingSetsMetric.insert(0, 'Metric')\n\nsummary_dt.columns = TrainingSetsMetric\nsummary_dt.set_index('Metric', inplace = True)\nsummary_dt","93ea8bdb":"# Visual comparison of the model applied on different training sets through various evaluation metrics\n\nsummary_visual(summary_dt)","58c43c5d":"svm_linear = svm.SVC(kernel = 'linear')","58f5fa29":"# Elements of confusion matrix\n\nclassification(svm_linear, X_train_scaled_minmax, y_train, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_svm_linear_unaltered = summary\nsummary_svm_linear_unaltered.set_index('Metric')\n\nsummary_svm_linear_unaltered_index = summary_svm_linear_unaltered.T\nsummary_svm_linear_unaltered_index.columns = summary_svm_linear_unaltered_index.iloc[0]\nsummary_svm_linear_unaltered_index.drop(summary_svm_linear_unaltered_index.index[0], inplace = True)\nsummary_svm_linear_unaltered_index\n\n# classification(svm_linear, X_train, y_train, X_test, y_test) # TP = 37, FN = 75, TN = 56840, FP = 10","d4b29996":"# Elements of confusion matrix\n\nclassification(svm_linear, X_train_under_scaled_minmax, y_train_under, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_svm_linear_under = summary\nsummary_svm_linear_under.set_index('Metric')\n\nsummary_svm_linear_under_index = summary_svm_linear_under.T\nsummary_svm_linear_under_index.columns = summary_svm_linear_under_index.iloc[0]\nsummary_svm_linear_under_index.drop(summary_svm_linear_under_index.index[0], inplace = True)\nsummary_svm_linear_under_index","60696d3f":"# Elements of confusion matrix\n\nclassification(svm_linear, X_train_over_scaled_minmax, y_train_over, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_svm_linear_over = summary\nsummary_svm_linear_over.set_index('Metric')\n\nsummary_svm_linear_over_index = summary_svm_linear_over.T\nsummary_svm_linear_over_index.columns = summary_svm_linear_over_index.iloc[0]\nsummary_svm_linear_over_index.drop(summary_svm_linear_over_index.index[0], inplace = True)\nsummary_svm_linear_over_index","994ff5aa":"# Elements of confusion matrix\n\nclassification(svm_linear, X_train_under_imblearn_scaled_minmax, y_train_under_imblearn, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_svm_linear_under_imblearn = summary\nsummary_svm_linear_under_imblearn.set_index('Metric')\n\nsummary_svm_linear_under_imblearn_index = summary_svm_linear_under_imblearn.T\nsummary_svm_linear_under_imblearn_index.columns = summary_svm_linear_under_imblearn_index.iloc[0]\nsummary_svm_linear_under_imblearn_index.drop(summary_svm_linear_under_imblearn_index.index[0], inplace = True)\nsummary_svm_linear_under_imblearn_index","5723e3a9":"# Elements of confusion matrix\n\nclassification(svm_linear, X_train_over_imblearn_scaled_minmax, y_train_over_imblearn, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_svm_linear_over_imblearn = summary\nsummary_svm_linear_over_imblearn.set_index('Metric')\n\nsummary_svm_linear_over_imblearn_index = summary_svm_linear_over_imblearn.T\nsummary_svm_linear_over_imblearn_index.columns = summary_svm_linear_over_imblearn_index.iloc[0]\nsummary_svm_linear_over_imblearn_index.drop(summary_svm_linear_over_imblearn_index.index[0], inplace = True)\nsummary_svm_linear_over_imblearn_index","270663de":"# Elements of confusion matrix\n\nclassification(svm_linear, X_train_over_smote_scaled_minmax, y_train_over_smote, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_svm_linear_over_smote = summary\nsummary_svm_linear_over_smote.set_index('Metric')\n\nsummary_svm_linear_over_smote_index = summary_svm_linear_over_smote.T\nsummary_svm_linear_over_smote_index.columns = summary_svm_linear_over_smote_index.iloc[0]\nsummary_svm_linear_over_smote_index.drop(summary_svm_linear_over_smote_index.index[0], inplace = True)\nsummary_svm_linear_over_smote_index","18b04542":"# Elements of confusion matrix\n\nclassification(svm_linear, X_train_under_nm_scaled_minmax, y_train_under_nm, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_svm_linear_under_nm = summary\nsummary_svm_linear_under_nm.set_index('Metric')\n\nsummary_svm_linear_under_nm_index = summary_svm_linear_under_nm.T\nsummary_svm_linear_under_nm_index.columns = summary_svm_linear_under_nm_index.iloc[0]\nsummary_svm_linear_under_nm_index.drop(summary_svm_linear_under_nm_index.index[0], inplace = True)\nsummary_svm_linear_under_nm_index","797426ea":"summary_svm_linear = pd.DataFrame(columns = ['Metric'])\n\nsummary_svm_linear['Metric'] = EvalMetricLabels\nsummary_svm_linear_list = [summary_svm_linear_unaltered, summary_svm_linear_under, summary_svm_linear_over,\n                           summary_svm_linear_under_imblearn, summary_svm_linear_over_imblearn,\n                           summary_svm_linear_over_smote, summary_svm_linear_under_nm]\n\nfor i in summary_svm_linear_list:\n    summary_svm_linear = pd.merge(summary_svm_linear, i, on = 'Metric')\n\nTrainingSetsMetric = TrainingSets.copy()\nTrainingSetsMetric.insert(0, 'Metric')\n\nsummary_svm_linear.columns = TrainingSetsMetric\nsummary_svm_linear.set_index('Metric', inplace = True)\nsummary_svm_linear","9ccc1727":"# Visual comparison of the model applied on different training sets through various evaluation metrics\n\nsummary_visual(summary_svm_linear)\n\nfig1 = make_subplots(rows = 4, cols = 2, shared_yaxes = True, subplot_titles = EvalMetricLabels)\n\nfig1.add_trace(go.Bar(x = list(summary_svm_linear.columns), y = list(summary_svm_linear.loc['MCC'])), 1, 1)\nfig1.add_trace(go.Bar(x = list(summary_svm_linear.columns), y = list(summary_svm_linear.loc['F1-Score'])), 1, 2)\nfig1.add_trace(go.Bar(x = list(summary_svm_linear.columns), y = list(summary_svm_linear.loc['F2-Score'])), 2, 1)\nfig1.add_trace(go.Bar(x = list(summary_svm_linear.columns), y = list(summary_svm_linear.loc['Recall'])), 2, 2)\nfig1.add_trace(go.Bar(x = list(summary_svm_linear.columns), y = list(summary_svm_linear.loc['Precision'])), 3, 1)\nfig1.add_trace(go.Bar(x = list(summary_svm_linear.columns), y = list(summary_svm_linear.loc['FM index'])), 3, 2)\nfig1.add_trace(go.Bar(x = list(summary_svm_linear.columns), y = list(summary_svm_linear.loc['Accuracy'])), 4, 1)\nfig1.add_trace(go.Bar(x = list(summary_svm_linear.columns), y = list(summary_svm_linear.loc['Specificity'])), 4, 2)\n\nfig1.update_layout(height = 2000, width = 800, coloraxis = dict(colorscale='Bluered_r'), showlegend = False)\nfig1.show()","fbd932c0":"nb = GaussianNB()","1d161ce0":"# Elements of confusion matrix\n\nclassification(nb, X_train, y_train, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_nb_unaltered = summary.copy()\nsummary_nb_unaltered.set_index('Metric')\n\ny_pred_proba = nb.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_nb_unaltered_extended = summary.copy()\nsummary_nb_unaltered_extended.loc[len(summary_nb_unaltered_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_nb_unaltered_extended.set_index('Metric')\n\nsummary_nb_unaltered_index = summary_nb_unaltered_extended.T\nsummary_nb_unaltered_index.columns = summary_nb_unaltered_index.iloc[0]\nsummary_nb_unaltered_index.drop(summary_nb_unaltered_index.index[0], inplace = True)\nsummary_nb_unaltered_index","5fb98ea2":"# Elements of confusion matrix\n\nclassification(nb, X_train_under, y_train_under, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_nb_under = summary.copy()\nsummary_nb_under.set_index('Metric')\n\ny_pred_proba = nb.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_nb_under_extended = summary.copy()\nsummary_nb_under_extended.loc[len(summary_nb_under_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_nb_under_extended.set_index('Metric')\n\nsummary_nb_under_index = summary_nb_under_extended.T\nsummary_nb_under_index.columns = summary_nb_under_index.iloc[0]\nsummary_nb_under_index.drop(summary_nb_under_index.index[0], inplace = True)\nsummary_nb_under_index","e360c23c":"# Elements of confusion matrix\n\nclassification(nb, X_train_over, y_train_over, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_nb_over = summary.copy()\nsummary_nb_over.set_index('Metric')\n\ny_pred_proba = nb.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_nb_over_extended = summary.copy()\nsummary_nb_over_extended.loc[len(summary_nb_over_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_nb_over_extended.set_index('Metric')\n\nsummary_nb_over_index = summary_nb_over_extended.T\nsummary_nb_over_index.columns = summary_nb_over_index.iloc[0]\nsummary_nb_over_index.drop(summary_nb_over_index.index[0], inplace = True)\nsummary_nb_over_index","8f9c602c":"# Elements of confusion matrix\n\nclassification(nb, X_train_under_imblearn, y_train_under_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_nb_under_imblearn = summary.copy()\nsummary_nb_under_imblearn.set_index('Metric')\n\ny_pred_proba = nb.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_nb_under_imblearn_extended = summary.copy()\nsummary_nb_under_imblearn_extended.loc[len(summary_nb_under_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_nb_under_imblearn_extended.set_index('Metric')\n\nsummary_nb_under_imblearn_index = summary_nb_under_imblearn_extended.T\nsummary_nb_under_imblearn_index.columns = summary_nb_under_imblearn_index.iloc[0]\nsummary_nb_under_imblearn_index.drop(summary_nb_under_imblearn_index.index[0], inplace = True)\nsummary_nb_under_imblearn_index","ba415444":"# Elements of confusion matrix\n\nclassification(nb, X_train_over_imblearn, y_train_over_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_nb_over_imblearn = summary.copy()\nsummary_nb_over_imblearn.set_index('Metric')\n\ny_pred_proba = nb.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_nb_over_imblearn_extended = summary.copy()\nsummary_nb_over_imblearn_extended.loc[len(summary_nb_over_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_nb_over_imblearn_extended.set_index('Metric')\n\nsummary_nb_over_imblearn_index = summary_nb_over_imblearn_extended.T\nsummary_nb_over_imblearn_index.columns = summary_nb_over_imblearn_index.iloc[0]\nsummary_nb_over_imblearn_index.drop(summary_nb_over_imblearn_index.index[0], inplace = True)\nsummary_nb_over_imblearn_index","69c75fd2":"# Elements of confusion matrix\n\nclassification(nb, X_train_over_smote, y_train_over_smote, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_nb_over_smote = summary.copy()\nsummary_nb_over_smote.set_index('Metric')\n\ny_pred_proba = nb.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_nb_over_smote_extended = summary.copy()\nsummary_nb_over_smote_extended.loc[len(summary_nb_over_smote_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_nb_over_smote_extended.set_index('Metric')\n\nsummary_nb_over_smote_index = summary_nb_over_smote_extended.T\nsummary_nb_over_smote_index.columns = summary_nb_over_smote_index.iloc[0]\nsummary_nb_over_smote_index.drop(summary_nb_over_smote_index.index[0], inplace = True)\nsummary_nb_over_smote_index","b3513022":"# Elements of confusion matrix\n\nclassification(nb, X_train_under_nm, y_train_under_nm, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_nb_under_nm = summary.copy()\nsummary_nb_under_nm.set_index('Metric')\n\ny_pred_proba = nb.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_nb_under_nm_extended = summary.copy()\nsummary_nb_under_nm_extended.loc[len(summary_nb_under_nm_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_nb_under_nm_extended.set_index('Metric')\n\nsummary_nb_under_nm_index = summary_nb_under_nm_extended.T\nsummary_nb_under_nm_index.columns = summary_nb_under_nm_index.iloc[0]\nsummary_nb_under_nm_index.drop(summary_nb_under_nm_index.index[0], inplace = True)\nsummary_nb_under_nm_index","e4a7540d":"summary_nb = pd.DataFrame(columns = ['Metric'])\n\nsummary_nb['Metric'] = EvalMetricLabels\nsummary_nb_list = [summary_nb_unaltered, summary_nb_under, summary_nb_over, summary_nb_under_imblearn,\n                       summary_nb_over_imblearn, summary_nb_over_smote, summary_nb_under_nm]\n\nfor i in summary_nb_list:\n    summary_nb = pd.merge(summary_nb, i, on = 'Metric')\n    \nTrainingSetsMetric = TrainingSets.copy()\nTrainingSetsMetric.insert(0, 'Metric')\n\nsummary_nb.columns = TrainingSetsMetric\nsummary_nb.set_index('Metric', inplace = True)\nsummary_nb","06e183ad":"# Visual comparison of the model applied on different training sets through various evaluation metrics\n\nsummary_visual(summary_nb)","72d189ad":"rf = RandomForestClassifier(n_estimators = 100)","5865b042":"# Elements of confusion matrix\n\nclassification(rf, X_train, y_train, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_rf_unaltered = summary.copy()\nsummary_rf_unaltered.set_index('Metric')\n\ny_pred_proba = rf.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_rf_unaltered_extended = summary.copy()\nsummary_rf_unaltered_extended.loc[len(summary_rf_unaltered_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_rf_unaltered_extended.set_index('Metric')\n\nsummary_rf_unaltered_index = summary_rf_unaltered_extended.T\nsummary_rf_unaltered_index.columns = summary_rf_unaltered_index.iloc[0]\nsummary_rf_unaltered_index.drop(summary_rf_unaltered_index.index[0], inplace = True)\nsummary_rf_unaltered_index","56256d2a":"# Elements of confusion matrix\n\nclassification(rf, X_train_under, y_train_under, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_rf_under = summary.copy()\nsummary_rf_under.set_index('Metric')\n\ny_pred_proba = rf.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_rf_under_extended = summary.copy()\nsummary_rf_under_extended.loc[len(summary_rf_under_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_rf_under_extended.set_index('Metric')\n\nsummary_rf_under_index = summary_rf_under_extended.T\nsummary_rf_under_index.columns = summary_rf_under_index.iloc[0]\nsummary_rf_under_index.drop(summary_rf_under_index.index[0], inplace = True)\nsummary_rf_under_index","74ded060":"# Elements of confusion matrix\n\nclassification(rf, X_train_over, y_train_over, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_rf_over = summary.copy()\nsummary_rf_over.set_index('Metric')\n\ny_pred_proba = rf.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_rf_over_extended = summary.copy()\nsummary_rf_over_extended.loc[len(summary_rf_over_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_rf_over_extended.set_index('Metric')\n\nsummary_rf_over_index = summary_rf_over_extended.T\nsummary_rf_over_index.columns = summary_rf_over_index.iloc[0]\nsummary_rf_over_index.drop(summary_rf_over_index.index[0], inplace = True)\nsummary_rf_over_index","8ea4a12a":"# Elements of confusion matrix\n\nclassification(rf, X_train_under_imblearn, y_train_under_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_rf_under_imblearn = summary.copy()\nsummary_rf_under_imblearn.set_index('Metric')\n\ny_pred_proba = rf.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_rf_under_imblearn_extended = summary.copy()\nsummary_rf_under_imblearn_extended.loc[len(summary_rf_under_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_rf_under_imblearn_extended.set_index('Metric')\n\nsummary_rf_under_imblearn_index = summary_rf_under_imblearn_extended.T\nsummary_rf_under_imblearn_index.columns = summary_rf_under_imblearn_index.iloc[0]\nsummary_rf_under_imblearn_index.drop(summary_rf_under_imblearn_index.index[0], inplace = True)\nsummary_rf_under_imblearn_index","79e95b27":"# Elements of confusion matrix\n\nclassification(rf, X_train_over_imblearn, y_train_over_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_rf_over_imblearn = summary.copy()\nsummary_rf_over_imblearn.set_index('Metric')\n\ny_pred_proba = rf.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_rf_over_imblearn_extended = summary.copy()\nsummary_rf_over_imblearn_extended.loc[len(summary_rf_over_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_rf_over_imblearn_extended.set_index('Metric')\n\nsummary_rf_over_imblearn_index = summary_rf_over_imblearn_extended.T\nsummary_rf_over_imblearn_index.columns = summary_rf_over_imblearn_index.iloc[0]\nsummary_rf_over_imblearn_index.drop(summary_rf_over_imblearn_index.index[0], inplace = True)\nsummary_rf_over_imblearn_index","b978e070":"# Elements of confusion matrix\n\nclassification(rf, X_train_over_smote, y_train_over_smote, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_rf_over_smote = summary.copy()\nsummary_rf_over_smote.set_index('Metric')\n\ny_pred_proba = rf.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_rf_over_smote_extended = summary.copy()\nsummary_rf_over_smote_extended.loc[len(summary_rf_over_smote_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_rf_over_smote_extended.set_index('Metric')\n\nsummary_rf_over_smote_index = summary_rf_over_smote_extended.T\nsummary_rf_over_smote_index.columns = summary_rf_over_smote_index.iloc[0]\nsummary_rf_over_smote_index.drop(summary_rf_over_smote_index.index[0], inplace = True)\nsummary_rf_over_smote_index","10b7a3f0":"# Elements of confusion matrix\n\nclassification(rf, X_train_under_nm, y_train_under_nm, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_rf_under_nm = summary.copy()\nsummary_rf_under_nm.set_index('Metric')\n\ny_pred_proba = rf.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_rf_under_nm_extended = summary.copy()\nsummary_rf_under_nm_extended.loc[len(summary_rf_under_nm_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_rf_under_nm_extended.set_index('Metric')\n\nsummary_rf_under_nm_index = summary_rf_under_nm_extended.T\nsummary_rf_under_nm_index.columns = summary_rf_under_nm_index.iloc[0]\nsummary_rf_under_nm_index.drop(summary_rf_under_nm_index.index[0], inplace = True)\nsummary_rf_under_nm_index","2bcf1823":"summary_rf = pd.DataFrame(columns = ['Metric'])\n\nsummary_rf['Metric'] = EvalMetricLabels\nsummary_rf_list = [summary_rf_unaltered, summary_rf_under, summary_rf_over, summary_rf_under_imblearn,\n                   summary_rf_over_imblearn, summary_rf_over_smote, summary_rf_under_nm]\n\nfor i in summary_rf_list:\n    summary_rf = pd.merge(summary_rf, i, on = 'Metric')\n    \nTrainingSetsMetric = TrainingSets.copy()\nTrainingSetsMetric.insert(0, 'Metric')\n\nsummary_rf.columns = TrainingSetsMetric\nsummary_rf.set_index('Metric', inplace = True)\nsummary_rf","30410c28":"# Visual comparison of the model applied on different training sets through various evaluation metrics\n\nsummary_visual(summary_rf)","7937880f":"lda = LinearDiscriminantAnalysis()","b5ac1674":"# Elements of confusion matrix\n\nclassification(lda, X_train, y_train, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_lda_unaltered = summary.copy()\nsummary_lda_unaltered.set_index('Metric')\n\ny_score = lda.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = lda.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_lda_unaltered_extended = summary.copy()\nsummary_lda_unaltered_extended.loc[len(summary_lda_unaltered_extended.index)] = ['AP', average_precision]\nsummary_lda_unaltered_extended.loc[len(summary_lda_unaltered_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_lda_unaltered_extended.set_index('Metric')\n\nsummary_lda_unaltered_index = summary_lda_unaltered_extended.T\nsummary_lda_unaltered_index.columns = summary_lda_unaltered_index.iloc[0]\nsummary_lda_unaltered_index.drop(summary_lda_unaltered_index.index[0], inplace = True)\nsummary_lda_unaltered_index","80f41a29":"# Elements of confusion matrix\n\nclassification(lda, X_train_under, y_train_under, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_lda_under = summary\nsummary_lda_under.set_index('Metric')\n\ny_score = lda.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = lda.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_lda_under_extended = summary.copy()\nsummary_lda_under_extended.loc[len(summary_lda_under_extended.index)] = ['AP', average_precision]\nsummary_lda_under_extended.loc[len(summary_lda_under_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_lda_under_extended.set_index('Metric')\n\nsummary_lda_under_index = summary_lda_under_extended.T\nsummary_lda_under_index.columns = summary_lda_under_index.iloc[0]\nsummary_lda_under_index.drop(summary_lda_under_index.index[0], inplace = True)\nsummary_lda_under_index","3cb5b1a4":"# Elements of confusion matrix\n\nclassification(lda, X_train_over, y_train_over, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_lda_over = summary\nsummary_lda_over.set_index('Metric')\n\ny_score = lda.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = lda.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_lda_over_extended = summary.copy()\nsummary_lda_over_extended.loc[len(summary_lda_over_extended.index)] = ['AP', average_precision]\nsummary_lda_over_extended.loc[len(summary_lda_over_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_lda_over_extended.set_index('Metric')\n\nsummary_lda_over_index = summary_lda_over_extended.T\nsummary_lda_over_index.columns = summary_lda_over_index.iloc[0]\nsummary_lda_over_index.drop(summary_lda_over_index.index[0], inplace = True)\nsummary_lda_over_index","6002065d":"# Elements of confusion matrix\n\nclassification(lda, X_train_under_imblearn, y_train_under_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_lda_under_imblearn = summary\nsummary_lda_under_imblearn.set_index('Metric')\n\ny_score = lda.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = lda.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_lda_under_imblearn_extended = summary.copy()\nsummary_lda_under_imblearn_extended.loc[len(summary_lda_under_imblearn_extended.index)] = ['AP', average_precision]\nsummary_lda_under_imblearn_extended.loc[len(summary_lda_under_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_lda_under_imblearn_extended.set_index('Metric')\n\nsummary_lda_under_imblearn_index = summary_lda_under_imblearn_extended.T\nsummary_lda_under_imblearn_index.columns = summary_lda_under_imblearn_index.iloc[0]\nsummary_lda_under_imblearn_index.drop(summary_lda_under_imblearn_index.index[0], inplace = True)\nsummary_lda_under_imblearn_index","346ba1e5":"# Elements of confusion matrix\n\nclassification(lda, X_train_over_imblearn, y_train_over_imblearn, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_lda_over_imblearn = summary\nsummary_lda_over_imblearn.set_index('Metric')\n\ny_score = lda.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = lda.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_lda_over_imblearn_extended = summary.copy()\nsummary_lda_over_imblearn_extended.loc[len(summary_lda_over_imblearn_extended.index)] = ['AP', average_precision]\nsummary_lda_over_imblearn_extended.loc[len(summary_lda_over_imblearn_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_lda_over_imblearn_extended.set_index('Metric')\n\nsummary_lda_over_imblearn_index = summary_lda_over_imblearn_extended.T\nsummary_lda_over_imblearn_index.columns = summary_lda_over_imblearn_index.iloc[0]\nsummary_lda_over_imblearn_index.drop(summary_lda_over_imblearn_index.index[0], inplace = True)\nsummary_lda_over_imblearn_index","9e631fd3":"# Elements of confusion matrix\n\nclassification(lda, X_train_over_smote, y_train_over_smote, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_lda_over_smote = summary\nsummary_lda_over_smote.set_index('Metric')\n\ny_score = lda.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = lda.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_lda_over_smote_extended = summary.copy()\nsummary_lda_over_smote_extended.loc[len(summary_lda_over_smote_extended.index)] = ['AP', average_precision]\nsummary_lda_over_smote_extended.loc[len(summary_lda_over_smote_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_lda_over_smote_extended.set_index('Metric')\n\nsummary_lda_over_smote_index = summary_lda_over_smote_extended.T\nsummary_lda_over_smote_index.columns = summary_lda_over_smote_index.iloc[0]\nsummary_lda_over_smote_index.drop(summary_lda_over_smote_index.index[0], inplace = True)\nsummary_lda_over_smote_index","a227478c":"# Elements of confusion matrix\n\nclassification(lda, X_train_under_nm, y_train_under_nm, X_test, y_test)\n\n# Summary of evaluation metrics\n\nsummary_lda_under_nm = summary\nsummary_lda_under_nm.set_index('Metric')\n\ny_score = lda.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\ny_pred_proba = lda.predict_proba(X_test)[::,1]\nroc_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n\nsummary_lda_under_nm_extended = summary.copy()\nsummary_lda_under_nm_extended.loc[len(summary_lda_under_nm_extended.index)] = ['AP', average_precision]\nsummary_lda_under_nm_extended.loc[len(summary_lda_under_nm_extended.index)] = ['ROC-AUC', roc_auc]\nsummary_lda_under_nm_extended.set_index('Metric')\n\nsummary_lda_under_nm_index = summary_lda_under_nm_extended.T\nsummary_lda_under_nm_index.columns = summary_lda_under_nm_index.iloc[0]\nsummary_lda_under_nm_index.drop(summary_lda_under_nm_index.index[0], inplace = True)\nsummary_lda_under_nm_index","4ac51998":"summary_lda = pd.DataFrame(columns = ['Metric'])\n\nsummary_lda['Metric'] = EvalMetricLabels\nsummary_lda_list = [summary_lda_unaltered, summary_lda_under, summary_lda_over, summary_lda_under_imblearn,\n                    summary_lda_over_imblearn, summary_lda_over_smote, summary_lda_under_nm]\n\nfor i in summary_lda_list:\n    summary_lda = pd.merge(summary_lda, i, on = 'Metric')\n    \nTrainingSetsMetric = TrainingSets.copy()\nTrainingSetsMetric.insert(0, 'Metric')\n\nsummary_lda.columns = TrainingSetsMetric\nsummary_lda.set_index('Metric', inplace = True)\nsummary_lda","f4238415":"# Visual comparison of the model applied on different training sets through various evaluation metrics\n\nsummary_visual(summary_lda)","e61a9e6a":"sgd = SGDClassifier(loss = 'hinge')","3faa2022":"# Elements of confusion matrix\n\nclassification(sgd, X_train_scaled_minmax, y_train, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_sgd_unaltered = summary.copy()\nsummary_sgd_unaltered.set_index('Metric')\n\ny_score = sgd.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_sgd_unaltered_extended = summary.copy()\nsummary_sgd_unaltered_extended.loc[len(summary_sgd_unaltered_extended.index)] = ['AP', average_precision]\nsummary_sgd_unaltered_extended.set_index('Metric')\n\nsummary_sgd_unaltered_index = summary_sgd_unaltered_extended.T\nsummary_sgd_unaltered_index.columns = summary_sgd_unaltered_index.iloc[0]\nsummary_sgd_unaltered_index.drop(summary_sgd_unaltered_index.index[0], inplace = True)\nsummary_sgd_unaltered_index","5e33c49f":"# Elements of confusion matrix\n\nclassification(sgd, X_train_under_scaled_minmax, y_train_under, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_sgd_under = summary\nsummary_sgd_under.set_index('Metric')\n\ny_score = sgd.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_sgd_under_extended = summary.copy()\nsummary_sgd_under_extended.loc[len(summary_sgd_under_extended.index)] = ['AP', average_precision]\nsummary_sgd_under_extended.set_index('Metric')\n\nsummary_sgd_under_index = summary_sgd_under_extended.T\nsummary_sgd_under_index.columns = summary_sgd_under_index.iloc[0]\nsummary_sgd_under_index.drop(summary_sgd_under_index.index[0], inplace = True)\nsummary_sgd_under_index","c5f04627":"# Elements of confusion matrix\n\nclassification(sgd, X_train_over_scaled_minmax, y_train_over, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_sgd_over = summary\nsummary_sgd_over.set_index('Metric')\n\ny_score = sgd.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_sgd_over_extended = summary.copy()\nsummary_sgd_over_extended.loc[len(summary_sgd_over_extended.index)] = ['AP', average_precision]\nsummary_sgd_over_extended.set_index('Metric')\n\nsummary_sgd_over_index = summary_sgd_over_extended.T\nsummary_sgd_over_index.columns = summary_sgd_over_index.iloc[0]\nsummary_sgd_over_index.drop(summary_sgd_over_index.index[0], inplace = True)\nsummary_sgd_over_index","011e3915":"# Elements of confusion matrix\n\nclassification(sgd, X_train_under_imblearn_scaled_minmax, y_train_under_imblearn, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_sgd_under_imblearn = summary\nsummary_sgd_under_imblearn.set_index('Metric')\n\ny_score = sgd.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_sgd_under_imblearn_extended = summary.copy()\nsummary_sgd_under_imblearn_extended.loc[len(summary_sgd_under_imblearn_extended.index)] = ['AP', average_precision]\nsummary_sgd_under_imblearn_extended.set_index('Metric')\n\nsummary_sgd_under_imblearn_index = summary_sgd_under_imblearn_extended.T\nsummary_sgd_under_imblearn_index.columns = summary_sgd_under_imblearn_index.iloc[0]\nsummary_sgd_under_imblearn_index.drop(summary_sgd_under_imblearn_index.index[0], inplace = True)\nsummary_sgd_under_imblearn_index","bf7cfff6":"# Elements of confusion matrix\n\nclassification(sgd, X_train_over_imblearn_scaled_minmax, y_train_over_imblearn, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_sgd_over_imblearn = summary\nsummary_sgd_over_imblearn.set_index('Metric')\n\ny_score = sgd.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_sgd_over_imblearn_extended = summary.copy()\nsummary_sgd_over_imblearn_extended.loc[len(summary_sgd_over_imblearn_extended.index)] = ['AP', average_precision]\nsummary_sgd_over_imblearn_extended.set_index('Metric')\n\nsummary_sgd_over_imblearn_index = summary_sgd_over_imblearn_extended.T\nsummary_sgd_over_imblearn_index.columns = summary_sgd_over_imblearn_index.iloc[0]\nsummary_sgd_over_imblearn_index.drop(summary_sgd_over_imblearn_index.index[0], inplace = True)\nsummary_sgd_over_imblearn_index","625db3b0":"# Elements of confusion matrix\n\nclassification(sgd, X_train_over_smote_scaled_minmax, y_train_over_smote, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_sgd_over_smote = summary\nsummary_sgd_over_smote.set_index('Metric')\n\ny_score = sgd.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_sgd_over_smote_extended = summary.copy()\nsummary_sgd_over_smote_extended.loc[len(summary_sgd_over_smote_extended.index)] = ['AP', average_precision]\nsummary_sgd_over_smote_extended.set_index('Metric')\n\nsummary_sgd_over_smote_index = summary_sgd_over_smote_extended.T\nsummary_sgd_over_smote_index.columns = summary_sgd_over_smote_index.iloc[0]\nsummary_sgd_over_smote_index.drop(summary_sgd_over_smote_index.index[0], inplace = True)\nsummary_sgd_over_smote_index","355f0795":"# Elements of confusion matrix\n\nclassification(sgd, X_train_under_nm_scaled_minmax, y_train_under_nm, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_sgd_under_nm = summary\nsummary_sgd_under_nm.set_index('Metric')\n\ny_score = sgd.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_sgd_under_nm_extended = summary.copy()\nsummary_sgd_under_nm_extended.loc[len(summary_sgd_under_nm_extended.index)] = ['AP', average_precision]\nsummary_sgd_under_nm_extended.set_index('Metric')\n\nsummary_sgd_under_nm_index = summary_sgd_under_nm_extended.T\nsummary_sgd_under_nm_index.columns = summary_sgd_under_nm_index.iloc[0]\nsummary_sgd_under_nm_index.drop(summary_sgd_under_nm_index.index[0], inplace = True)\nsummary_sgd_under_nm_index","2cf0a1c4":"summary_sgd = pd.DataFrame(columns = ['Metric'])\n\nsummary_sgd['Metric'] = EvalMetricLabels\nsummary_sgd_list = [summary_sgd_unaltered, summary_sgd_under, summary_sgd_over, summary_sgd_under_imblearn,\n                    summary_sgd_over_imblearn, summary_sgd_over_smote, summary_sgd_under_nm]\n\nfor i in summary_sgd_list:\n    summary_sgd = pd.merge(summary_sgd, i, on = 'Metric')\n    \nTrainingSetsMetric = TrainingSets.copy()\nTrainingSetsMetric.insert(0, 'Metric')\n\nsummary_sgd.columns = TrainingSetsMetric\nsummary_sgd.set_index('Metric', inplace = True)\nsummary_sgd","7093ba7c":"# Visual comparison of the model applied on different training sets through various evaluation metrics\n\nsummary_visual(summary_sgd)","2c75b791":"ridge = RidgeClassifier()","5ce94feb":"# Elements of confusion matrix\n\nclassification(ridge, X_train_scaled_minmax, y_train, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_ridge_unaltered = summary.copy()\nsummary_ridge_unaltered.set_index('Metric')\n\ny_score = ridge.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_ridge_unaltered_extended = summary.copy()\nsummary_ridge_unaltered_extended.loc[len(summary_ridge_unaltered_extended.index)] = ['AP', average_precision]\nsummary_ridge_unaltered_extended.set_index('Metric')\n\nsummary_ridge_unaltered_index = summary_ridge_unaltered_extended.T\nsummary_ridge_unaltered_index.columns = summary_ridge_unaltered_index.iloc[0]\nsummary_ridge_unaltered_index.drop(summary_ridge_unaltered_index.index[0], inplace = True)\nsummary_ridge_unaltered_index","a88b2f9d":"# Elements of confusion matrix\n\nclassification(ridge, X_train_under_scaled_minmax, y_train_under, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_ridge_under = summary.copy()\nsummary_ridge_under.set_index('Metric')\n\ny_score = ridge.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_ridge_under_extended = summary.copy()\nsummary_ridge_under_extended.loc[len(summary_ridge_under_extended.index)] = ['AP', average_precision]\nsummary_ridge_under_extended.set_index('Metric')\n\nsummary_ridge_under_index = summary_ridge_under_extended.T\nsummary_ridge_under_index.columns = summary_ridge_under_index.iloc[0]\nsummary_ridge_under_index.drop(summary_ridge_under_index.index[0], inplace = True)\nsummary_ridge_under_index","1445eb0f":"# Elements of confusion matrix\n\nclassification(ridge, X_train_over_scaled_minmax, y_train_over, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_ridge_over = summary.copy()\nsummary_ridge_over.set_index('Metric')\n\ny_score = ridge.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_ridge_over_extended = summary.copy()\nsummary_ridge_over_extended.loc[len(summary_ridge_over_extended.index)] = ['AP', average_precision]\nsummary_ridge_over_extended.set_index('Metric')\n\nsummary_ridge_over_index = summary_ridge_over_extended.T\nsummary_ridge_over_index.columns = summary_ridge_over_index.iloc[0]\nsummary_ridge_over_index.drop(summary_ridge_over_index.index[0], inplace = True)\nsummary_ridge_over_index","49a08fe0":"# Elements of confusion matrix\n\nclassification(ridge, X_train_under_imblearn_scaled_minmax, y_train_under_imblearn, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_ridge_under_imblearn = summary.copy()\nsummary_ridge_under_imblearn.set_index('Metric')\n\ny_score = ridge.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_ridge_under_imblearn_extended = summary.copy()\nsummary_ridge_under_imblearn_extended.loc[len(summary_ridge_under_imblearn_extended.index)] = ['AP', average_precision]\nsummary_ridge_under_imblearn_extended.set_index('Metric')\n\nsummary_ridge_under_imblearn_index = summary_ridge_under_imblearn_extended.T\nsummary_ridge_under_imblearn_index.columns = summary_ridge_under_imblearn_index.iloc[0]\nsummary_ridge_under_imblearn_index.drop(summary_ridge_under_imblearn_index.index[0], inplace = True)\nsummary_ridge_under_imblearn_index","9ddfca7b":"# Elements of confusion matrix\n\nclassification(ridge, X_train_over_imblearn_scaled_minmax, y_train_over_imblearn, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_ridge_over_imblearn = summary.copy()\nsummary_ridge_over_imblearn.set_index('Metric')\n\ny_score = ridge.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_ridge_over_imblearn_extended = summary.copy()\nsummary_ridge_over_imblearn_extended.loc[len(summary_ridge_over_imblearn_extended.index)] = ['AP', average_precision]\nsummary_ridge_over_imblearn_extended.set_index('Metric')\n\nsummary_ridge_over_imblearn_index = summary_ridge_over_imblearn_extended.T\nsummary_ridge_over_imblearn_index.columns = summary_ridge_over_imblearn_index.iloc[0]\nsummary_ridge_over_imblearn_index.drop(summary_ridge_over_imblearn_index.index[0], inplace = True)\nsummary_ridge_over_imblearn_index","0c0f9225":"# Elements of confusion matrix\n\nclassification(ridge, X_train_over_smote_scaled_minmax, y_train_over_smote, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_ridge_over_smote = summary.copy()\nsummary_ridge_over_smote.set_index('Metric')\n\ny_score = ridge.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_ridge_over_smote_extended = summary.copy()\nsummary_ridge_over_smote_extended.loc[len(summary_ridge_over_smote_extended.index)] = ['AP', average_precision]\nsummary_ridge_over_smote_extended.set_index('Metric')\n\nsummary_ridge_over_smote_index = summary_ridge_over_smote_extended.T\nsummary_ridge_over_smote_index.columns = summary_ridge_over_smote_index.iloc[0]\nsummary_ridge_over_smote_index.drop(summary_ridge_over_smote_index.index[0], inplace = True)\nsummary_ridge_over_smote_index","c8949e55":"# Elements of confusion matrix\n\nclassification(ridge, X_train_under_nm_scaled_minmax, y_train_under_nm, X_test_scaled_minmax, y_test)\n\n# Summary of evaluation metrics\n\nsummary_ridge_under_nm = summary.copy()\nsummary_ridge_under_nm.set_index('Metric')\n\ny_score = ridge.decision_function(X_test)\naverage_precision = average_precision_score(y_test, y_score)\n\nsummary_ridge_under_nm_extended = summary.copy()\nsummary_ridge_under_nm_extended.loc[len(summary_ridge_under_nm_extended.index)] = ['AP', average_precision]\nsummary_ridge_under_nm_extended.set_index('Metric')\n\nsummary_ridge_under_nm_index = summary_ridge_under_nm_extended.T\nsummary_ridge_under_nm_index.columns = summary_ridge_under_nm_index.iloc[0]\nsummary_ridge_under_nm_index.drop(summary_ridge_under_nm_index.index[0], inplace = True)\nsummary_ridge_under_nm_index","c86d7e21":"summary_ridge = pd.DataFrame(columns = ['Metric'])\n\nsummary_ridge['Metric'] = EvalMetricLabels\nsummary_ridge_list = [summary_ridge_unaltered, summary_ridge_under, summary_ridge_over, summary_ridge_under_imblearn,\n                      summary_ridge_over_imblearn, summary_ridge_over_smote, summary_ridge_under_nm]\n\nfor i in summary_ridge_list:\n    summary_ridge = pd.merge(summary_ridge, i, on = 'Metric')\n    \nTrainingSetsMetric = TrainingSets.copy()\nTrainingSetsMetric.insert(0, 'Metric')\n\nsummary_ridge.columns = TrainingSetsMetric\nsummary_ridge.set_index('Metric', inplace = True)\nsummary_ridge","25c68ad4":"# Visual comparison of the model applied on different training sets through various evaluation metrics\n\nsummary_visual(summary_ridge)","a18fd585":"# Comparison of classification models\n\n\"\"\"\nIn the final table, models are sorted in decreasing order of their performance on the testing set, measured in F2-Score\n\nThe training set which is fed to a classifier is mentioned in parenthesis following the name of that classifier\n\nUnaltered: unaltered training set\nROS-IL: random over-sampling of minority class via imbalanced-learn library\nSMOTE: Over-sampling of minority class via synthetic minority over-sampling technique (SMOTE)\n\"\"\"\n\nmodels = ['Logistic Regression (Unaltered)', 'KNN (Unaltered)', 'Decision Tree (ROS-IL)',\n          'Linear SVM (Unaltered)', 'Naive Bayes (SMOTE)', 'Random Forest (SMOTE)',\n          'LDA (Unaltered)', 'SGD (Unaltered)', 'Ridge Classifier (Unaltered)']\nmetrics = ['F2-Score', 'MCC', 'Recall']\ncols = ['Classification model'] + metrics\n\nmodel_comparison = pd.DataFrame(columns = cols)\nmodel_comparison['Classification model'] = models\n\nsummary_list = [summary_logreg_unaltered_index, summary_knn_unaltered_index, summary_dt_over_imblearn_index,\n                summary_svm_linear_unaltered_index, summary_nb_over_smote_index, summary_rf_over_smote_index,\n                summary_lda_unaltered_index, summary_sgd_unaltered_index, summary_ridge_unaltered_index]\n\nF2_score = []\nMCC = []\nRecall = []\n\nfor i in summary_list:\n  F2_score.append(float(i['F2-Score']))\n  MCC.append(float(i['MCC']))\n  Recall.append(float(i['Recall']))\n\nmodel_comparison['F2-Score'] = F2_score\nmodel_comparison['MCC'] = MCC\nmodel_comparison['Recall'] = Recall\n\nmodel_comparison.set_index('Classification model', inplace = True)\nmodel_comparison_descending_F2 = model_comparison.sort_values(by = ['F2-Score'], ascending = False)\nmodel_comparison_descending_F2","c65257f3":"## Summary of random forest models","a1a37b6e":"## Synthetic minority over-sampling technique (SMOTE)","37633fa8":"## Synthetic minority over-sampling technique (SMOTE)","0f5dad99":"## Under-sampling via NearMiss","b4b7dffb":"## Random over-sampling with imbalanced-learn library","565cd83e":"<a name='1.-Introduction'><\/a>\n# 1. Introduction","7d1dff40":"## Under-sampling via NearMiss","b7393403":"<a name='8.-SVM'><\/a>\n# 8. Support Vector Machine (SVM)","f95296cd":"## Unaltered training set","ad403d8a":"## Unaltered training set","e892de53":"## Unaltered training set","e3e828c0":"## Random under-sampling","bc20bd76":"### Random over-sampling with imbalanced-learn library (ROS-IL)","c5ea6034":"<a name='6.-KNN'><\/a>\n# 6. $k$-Nearest Neighbors ($k$-NN)","57ae485d":"### Synthetic minority over-sampling technique (SMOTE)","f55f03ee":"## Random over-sampling","6418f0e8":"## Under-sampling via NearMiss","aae2b5d2":"## Unaltered training set","86912c42":"## Random over-sampling with imbalanced-learn library","80b409cc":"<a name='9.-Naive-Bayes'><\/a>\n# 9. Naive Bayes","fc9c29c9":"<a name='2.-Evaluation-Metrics'><\/a>\n# 2. Evaluation Metrics","4cb17023":"## Random over-sampling","edcebe81":"### Random over-sampling (ROS)","4a7eaddb":"## Random over-sampling with imbalanced-learn library","61706106":"## Random under-sampling","e49fe436":"## Random over-sampling with imbalanced-learn library","4d81e75a":"## Random over-sampling","ca580318":"## Under-sampling via NearMiss","8dfc7c67":"## Unaltered training set","1d5989a1":"## Summary of linear SVM classification models","a72f7065":"## Random over-sampling","b469ad4c":"From the left plot it is clear that the majority class is not represented accurately in the under-sampling scheme via NearMiss.","fb87cbae":"## Synthetic minority over-sampling technique (SMOTE)","fe225dcc":"## Random under-sampling","7a99aace":"## Random under-sampling","a1f898fb":"<h1><center> Credit Card Fraud Detection <\/center><\/h1>\n<h2><center> Part 2. Classification Models <\/center><\/h2>\n<h2><center> Sugata Ghosh and Shyambhu Mukherjee <\/center><\/h2>","bac08017":"## Synthetic minority over-sampling technique (SMOTE)","108538b4":"## Balancing the training set","2585a9c7":"## Random under-sampling","6a9a4eff":"## Random under-sampling with imbalanced-learn library","cc903cc4":"## Synthetic minority over-sampling technique (SMOTE)","60822688":"## Under-sampling via NearMiss","e488274b":"<a name='10.-Random-Forest'><\/a>\n# 10. Random Forest","d864e1ba":"## Unaltered training set","90d7108a":"## Random over-sampling","c1ffa1b8":"## Random over-sampling with imbalanced-learn library","0d7a9bd0":"### Under-sampling via NearMiss (NM)","a20e7603":"## Under-sampling via NearMiss","ecaf9933":"<a name='4.-Feature-Scaling'><\/a>\n# 4. Feature Scaling","3542ddef":"<a name='5.-Logistic-Regression'><\/a>\n# 5. Logistic Regression","3d7de951":"It may be natural for one of the features to contribute to the classification process more than another. But often this is caused artificially by the difference of range of values that the features take (often due to the units in which the features are measured). Many algorithms, especially the tree-based ones like decision tree and random forest, as well as graphical model-based classifiers like linear discriminant analysis and naive Bayes are invariant to scaling and hence are indifferent to feature scaling. On the other hand, the algorithms based on distances or similarities, which include $k$-nearest neighbours, support vector machine and stochastic gradient descent are sensitive to scaling. This necessitates the practitioner to scale the features appropriately before feeding the data to such classifiers.","88fcbc8d":"<a name='7.-Decision-Tree'><\/a>\n# 7. Decision Tree","2bfed8d0":"### Random under-sampling (RUS)\n\nWe take a subset of the majority class to balance the training dataset.\n\n**Advantage:** Improves run-time and solves any storage issue due to large learning dataset.\n\n**Disadvantage:** Ignores a chunk of information that could be impactful in the analysis and uses only a sample representative of the majority class which is not guarunteed to reflect the same accurately.","2f98058a":"# Contents\n\n- [Introduction](#1.-Introduction)\n- [Evaluation Metrics](#2.-Evaluation-Metrics)\n- [Train-Test Split](#3.-Train-Test-Split)\n- [Feature Scaling](#4.-Feature-Scaling)\n- [Logistic Regression](#5.-Logistic-Regression)\n- [$k$-Nearest Neighbors ($k$-NN)](#6.-KNN)\n- [Decision Tree](#7.-Decision-Tree)\n- [Support Vector Machine (SVM)](#8.-SVM)\n- [Naive Bayes](#9.-Naive-Bayes)\n- [Random Forest](#10.-Random-Forest)\n- [Linear Discriminant Analysis (LDA)](#11.-LDA)\n- [Stochastic Gradient Descent (SGD)](#12.-SGD)\n- [Ridge Classifier](#13.-Ridge-Classifier)\n- [Conclusion](#14.-Conclusion)","3eab297e":"## Random under-sampling with imbalanced-learn library","b18188dc":"Comparing with the same plots for full dataset, we see that high-amount authentic transactions are not represented in the sample taken from the majority class. This indicates a general drawback of the under-sampling techniques which throws away a major chunk of information from the majority class and suffers from not representing the same accurately.","58db4a53":"## Synthetic minority over-sampling technique (SMOTE)","60d2f127":"<a name='3.-Train-Test-Split'><\/a>\n# 3. Train-Test Split","d2932701":"## Random over-sampling","a72e325d":"### Separating the training set by class","ae61f2c4":"## Random under-sampling with imbalanced-learn library","eb1c3581":"## Random over-sampling with imbalanced-learn library","6456aba4":"## Random over-sampling with imbalanced-learn library","c30451ef":"The Random Forest classifier employs multiple decision trees, thereby avoiding the reliance upon feature selection of a singular decision tree.","182e1d9c":"## Random under-sampling","af460cbf":"<a name='12.-SGD'><\/a>\n# 12. Stochastic Gradient Descent (SGD)","1faa9d5f":"## Random over-sampling","4a9a2b35":"## Random under-sampling with imbalanced-learn library","6e78a614":"**In this part we shall classify transactions as authentic or fraudulent based on the information available on independent features (time, amount and the transformed variables V1-V28). One issue with the dataset is that it is highly imbalanced in terms of the target variable Class. Thus we run into the risk of training the models with a representative sample of fraudulent transactions of extremely small size. We employ different approaches to deal with this problem. The performance of each model is checked through various evaluation metrics and is summarized in tabulated form.**","71f5f7a8":"We choose the training set for each model on which it performs best and tabulate their performance in terms of **F2-Score**, which considers the facts that the dataset is imbalanced, the positive class (fraudulent transactions) is more important than the negative class (authentic transactions) and also that false negatives are more costly than false positives. Additionally, we report **MCC** (captures all-round performance across classes) and **Recall** (focuses only on the crucial postive class).","70addc2d":"<a name='13.-Ridge-Classifier'><\/a>\n# 13. Ridge Classifier","c2446d76":"## Unaltered training set","9ccd2dde":"## Unaltered training set","155767bb":"## Random over-sampling","b2ec47e7":"## Unaltered training set","89988caa":"## Synthetic minority over-sampling technique (SMOTE)","a11b9549":"## Summary of logistic regression models","ae2cefad":"## Random over-sampling with imbalanced-learn library","85785dd0":"## Summary of $k$-NN classification models","407b09ab":"## Random under-sampling","916f4256":"<a name='11.-LDA'><\/a>\n# 11. Linear discriminant analysis (LDA)","f2cc25ec":"**Note:** A potential issue with $k$-NN classification models, which is relevant in this project is that, they are affected by **curse of dimensionality**, as well as **presence of outliers in the feature variables**. Despite that, it performs fairly well when applied on the unaltered (imbalanced) training set, in particular with respect to **MCC**, but **F2-score** as well.","9c10610b":"## Under-sampling via NearMiss","5db713d4":"<a name='14.-Conclusion'><\/a>\n# 14. Conclusion","305cef4f":"## Random under-sampling with imbalanced-learning library","97f1be6f":"## Summary of naive Bayes models","97ed256d":"Keeping in mind that the dataset is highly imbalanced and that the positive class (fraudulent transactions) is more important than the negative class (authentic transactions), we report **MCC**, **F1-Score**, **F2-Score** and **Recall** for each model considered. Additionally we report **Precision**, **FM index**, **Accuracy** and **Specificity**.","f338c4a8":"### Random under-sampling with imbalanced-learn library (RUS-IL)","36c89d10":"## Random under-sampling with imbalanced-learn library","e77ea00b":"## Random under-sampling with imbalanced-learn library","3ba73293":"## Summary of decision tree classification models","09d2fc3a":"## Splitting the data into training set and testing set","08227d2f":"## Random under-sampling","e9026e35":"## Random under-sampling with imbalanced-learn library","3c901adf":"## Random over-sampling","b3e2f851":"## Random under-sampling with imbalanced-learn library","766706ab":"## Random over-sampling with imbalanced-learning library","f15978d2":"The **Random Forest** algorithm applied on the training set obtained after oversampling the minority class (fraudulent transactions) via **SMOTE** appears to be the best classification model for the problem at hand.\n\n**SMOTE** is one of the best choices to oversample the minority class when the data is imbalanced. It is not surprising that **Random Forest** turns out to be one of the most suitable classifiers for the problem due to the following reasons:\n\n- The algorithm works well in dealing with large datasets with high dimensions.\n\n- It is less affected by the presence of outliers in feature variables compared to other algorithms.\n\n- It does not make any distributional assumption on the feature variables.\n\n- It handles collinearity (linear dependence among features) implicitly.\n\n- It automatically ignores the features which are not useful, effectively doing feature selection on its own.","7ff511d9":"## Random under-sampling","b9d4143a":"The plot indicates extremely high imbalance between the two classes in the training set which may lead to producing misleading models.","9df2d117":"Any prediction about a binary categorical target variable  falls into one of the four categories:\n- True Positive: The classification model correctly predicts the output to be positive\n- True Negative: The classification model correctly predicts the output to be negative\n- False Positive: The classification model incorrectly predicts the output to be positive\n- False Negative: The classification model incorrectly predicts the output to be negative\n\n| $\\downarrow$ Actual state \/ Predicted state $\\rightarrow$ | Positive | Negative |\n| :---: | :---: | :---: |\n| Positive | True Positive | False Negative |\n| Negative | False Positive | True Negative |\n\nLet **TP**, **TN**, **FP** and **FN** respectively denote the number of **true positives**, **true negatives**, **false positives** and **false negatives** among the predictions made by a particular classification model. Below we give the definitions of some evaluation metrics based on these four quantities.\n\n$$\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Number of total predictions}} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n\n- **Precision-Recall Metrics**\n\n\\begin{align*}\n&\\text{Precision} = \\frac{\\text{Number of true positive predictions}}{\\text{Number of total positive predictions}} = \\frac{TP}{TP + FP}\\\\\\\\\n&\\text{Recall} = \\frac{\\text{Number of true positive predictions}}{\\text{Number of total positive cases}} = \\frac{TP}{TP + FN}\\\\\\\\\n&\\text{Fowlkes-Mallows index (FM)} = \\text{Geometric mean of Precision and Recall} = \\sqrt{\\text{Precision} \\times \\text{Recall}}\\\\\\\\\n&F_1\\text{-Score} = \\text{Harmonic mean of Precision and Recall} = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\\\\\\\\\n&F_{\\beta}\\text{-Score} = \\frac{\\left(1 + \\beta^2\\right) \\times \\text{Precision} \\times \\text{Recall}}{\\left(\\beta^2 \\times \\text{Precision}\\right) + \\text{Recall}},\n\\end{align*}\n\nwhere $\\beta$ is a positive factor, chosen such that Recall is $\\beta$ times as important as Precision in the analysis. Popular choices of $\\beta$ are $0.5$, $1$ and $2$.\n\n- **Sensitivity-Specificity Metrics**\n\n\\begin{align*}\n&\\text{Sensitivity} = \\frac{\\text{Number of true positive predictions}}{\\text{Number of total positive cases}} = \\frac{TP}{TP + FN}\\\\\\\\\n&\\text{Specificity} = \\frac{\\text{Number of true negative predictions}}{\\text{Number of total negative cases}} = \\frac{TN}{TN + FP}\\\\\\\\\n&\\text{G-mean} = \\text{Geometric mean of Sensitivity and Specificity} = \\sqrt{\\text{Sensitivity} \\times \\text{Specificity}}\n\\end{align*}\n\n- **Area Under Curve (AUC) Metrics**\n\nConsider the following quantities:\n\n\\begin{align*}\n&\\text{True Positive Rate (TPR)} = \\frac{\\text{Number of true positive predictions}}{\\text{Number of total positive cases}} = \\frac{TP}{TP + FN}\\\\\\\\\n&\\text{False Positive Rate (FPR)} = \\frac{\\text{Number of false positive predictions}}{\\text{Number of total negative cases}} = \\frac{FP}{FP + TN}\n\\end{align*}\n\nThe Receiver Operating Characteristic (ROC) curve is obtained by plotting TPR against FPR for a number of threshold probability values. The area under ROC curve (ROC-AUC) serves as a valid evaluation metric.\n\nSimilarly, the Precision-Recall (PR) curve is obtained by plotting Precision against Recall for a number of threshold probability values. The area under PR curve (PR-AUC) is also a valid evaluation metric. Another widely used metric in this regard is the Average Precision (AP), which is a weighted mean of precisions at each threshold, with the weights being increase in recall from the previous threshold.\n\n- **Other Metrics**\n\n\\begin{align*}\n&\\text{Matthews Correlation Coefficient (MCC)} = \\frac{\\left(TP \\times TN\\right) - \\left(FP \\times FN\\right)}{\\sqrt{\\left(TP + FP\\right) \\times \\left(TP + FN\\right) \\times \\left(TN + FP\\right) \\times \\left(TN + FN\\right)}}\n\\end{align*}\n\nUnlike the previous metrics, **MCC** varies from $-1$ (worst case scenario) to $1$ (best case scenario: perfect prediction).\n\nNote that **Recall** and **Sensitivity** are essentially the same quantity.\n\nAmong the discussed metrics, some good choices to evaluate models, in particular for imbalanced dataset are **MCC** and **$F_1$-Score**, while **Precision** and **Recall** also give useful information. We shall not give much importance to the **Accuracy** metric in this project as it produces misleading conclusion when the classes are not balanced. In the problem at hand, false negative (a fraudulent transaction being classified as authentic) is more dangerous than false positive (an authentic transaction being classified as fraudulent) as in the former case, the fraudster can cause further financial damage, while in the latter case the bank can cross-verify the authenticity of the transaction from the card-user after taking necessary steps to secure the card. Considering this fact, we give **$F_2$-Score** special importance in evaluating the models.","46309cd7":"## Synthetic minority over-sampling technique (SMOTE)","c31ccb8d":"## Under-sampling via NearMiss","2dc0d7e1":"## Data","8b3a7644":"**Observation:** While logistic regression model on unaltered training set performs exceedingly well on the negative class (authentic transactions), it does not work so well with the critical positive class (fraudulent transactions) as it misclassifies more than one-third of the transactions in that class.","1be86821":"## Synthetic minority over-sampling technique (SMOTE)","3b810d83":"## Summary of ridge classifiers","e9bba01f":"Source: https:\/\/www.kaggle.com\/mlg-ulb\/creditcardfraud\n\nThe dataset contains information on the transactions made using credit cards by European cardholders, in two particular days of September $2013$. It presents a total of $284807$ transactions, of which $492$ were fraudulent. Clearly, the dataset is highly imbalanced, the positive class (fraudulent transactions) accounting for only $0.173\\%$ of all transactions.\n\nFor a particular transaction, the feature **Time** represents the time (in seconds) elapsed between the transaction and the very first transaction, **Amount** represents the amount of the transaction and **Class** represents the status of the transaction with respect to authenticity. The class of an authentic (resp. fraudulent) transaction is taken to be $0$ (resp. $1$). Rest of the variables (**V1** to **V28**) are obtained from principle component analysis (PCA) transformation on original features that are not available due to confidentiality.","2d09600a":"## Objectives of the project\n\n### Primary objective:\n\n**Classification of transactions as authentic or fraudulent**. To be prcise, given the data on **Time**, **Amount** and transformed features **V1** to **V28** for a particular transaction, our goal is to correctly classify the transaction as **authentic** or **fraudulent**. We employ different techniques to build classification models and compare them by various evaluation metrics.\n\n### Secondary objectives:\n\nAnswering the following questions using machine learning and statistical tools and techniques.\n\n- When a fraudulent transaction is made, is it followed soon by one or more such fraudulent transactions? In other words, do the attackers make consecutive fraudulent transactions in a short span of time?\n\n\n- Is the amount of a fraudulent transaction generally larger than that of an authentic transaction?\n\n\n- Is there any indication in the data that fraudulent transactions occur at high-transaction period?\n\n\n- It is seen from the data that the number of transactions are high in some time intervals and low in between. Does the occurance of frauds related to these time intervals?\n\n\n- There are a few time-points which exhibits high number of fraud transactions. Is it due to high number of total transactions or due to some other reason?","be85e2bb":"These plots resemble the corresponding *Amount vs Time* plots for the full dataset much more accurately than the corresponding plots for the training set obtained from random under-sampling.","39f17492":"We use normalised features as the ridge classifier employs $l^2$ regularization through an additive penalty term in the objective function.","abd42dfa":"## Summary of LDA models","5f713bf3":"## Under-sampling via NearMiss","719b1c6a":"## Summary of SGD models"}}