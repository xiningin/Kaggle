{"cell_type":{"1810f0c1":"code","d0a6c18c":"code","65a0b3eb":"code","95418e06":"code","c4234856":"code","9f106b6b":"code","388b3e95":"code","43a831a6":"code","7c00cb65":"code","84b75d90":"code","c50ca678":"code","7031346c":"code","4ad1cbfb":"code","0f02ed1d":"code","3f4bacb4":"code","d6fa96d5":"code","28fa178d":"code","6db4dd95":"code","93f897c0":"code","d3e61134":"code","e809fba1":"code","b2b54dfd":"markdown","7cadac38":"markdown","55e1c9c5":"markdown","b2b242de":"markdown","e9daabf8":"markdown","e31d62e7":"markdown","f534aa43":"markdown","3708659a":"markdown","889b3aee":"markdown","307b9623":"markdown","7d23f44a":"markdown","304dbba4":"markdown","edd796f7":"markdown","ffec1305":"markdown","f52aa375":"markdown","0e19030a":"markdown","28dd423a":"markdown","36b7bd9e":"markdown","49573505":"markdown","8db60a33":"markdown","e34484d6":"markdown","1a667135":"markdown","2af2695d":"markdown","2e7418ef":"markdown","23ac2e30":"markdown","85bdc006":"markdown"},"source":{"1810f0c1":"s=\"Hello Kaggle!\"\nprint(s)","d0a6c18c":"!ls ..\/input\/male-daan-schnell-mal-klassifizieren\/","65a0b3eb":"import numpy as np # linear algebra","95418e06":"import numpy as np # lineare Algebra\nimport pandas as pd # Datenverarbeitung, CSV-Dateiimport (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","c4234856":"!dir ..\/input\/male-daan-schnell-mal-klassifizieren","9f106b6b":"!ls ..\/input\/male-daan-schnell-mal-klassifizieren","388b3e95":"!head ..\/input\/male-daan-schnell-mal-klassifizieren\/train.csv","43a831a6":"import pandas as pd\ndftrain = pd.read_csv('..\/input\/male-daan-schnell-mal-klassifizieren\/train.csv',index_col='Id')\ndftest = pd.read_csv('..\/input\/male-daan-schnell-mal-klassifizieren\/test.csv',index_col='Id')\n\ndftrain.head()","7c00cb65":"dftrain.X1**2","84b75d90":"dftrain['X1 quadriert']=dftrain.X1**2\ndftrain.head()","c50ca678":"dftrain[['X1','X2']].plot.scatter('X1','X2',color=dftrain.y,colormap='viridis',s=1);\n#Den Warnhinweis bitte ignorieren. Er ist m.E. ungerechtfertigt.","7031346c":"#Wir laden einen Klassifikator:\nfrom sklearn.dummy import DummyClassifier\n#Hilfe gibt's immer mit dem \"?\", mehr Hilfe mit \"??\"\n#Mit ESC geht das Fenster weg\nDummyClassifier?\n#oder: \n#from sklearn.tree import DecisionTreeClassifier","4ad1cbfb":"#Wir instanziieren ihn:\nmyfirst_clf = DummyClassifier()\n#myfirst_clf = DecisionTreeClassifier(max_depth=9)","0f02ed1d":"#Wir trainieren den Klassifikator auf den Trainingsdaten:\nXtrain=dftrain[['X1','X2']]\nytrain=dftrain['y']\nmyfirst_clf.fit(Xtrain,ytrain)","3f4bacb4":"Xtrain","d6fa96d5":"yhat_train = myfirst_clf.predict(Xtrain)\nyhat_test = myfirst_clf.predict(dftest.values)","28fa178d":"logische_Bedingung=True\nassert logische_Bedingung, \"Die Dimensionen von X und y sind nicht kompatibel\"","6db4dd95":"import matplotlib.pyplot as plt\n#plt.subplots?\n\nfig,ax = plt.subplots(nrows=1,ncols=2,figsize=(15,5)) #erzeugt 1 Zeile, 2 Spalten von Bildern. \ndftrain[['X1','X2']].plot.scatter('X1','X2',color=dftrain.y,colormap='viridis',s=1,ax=ax[0]);\ndftrain[['X1','X2']].plot.scatter('X1','X2',color=yhat_train,colormap='viridis',s=1,ax=ax[1]);\nplt.title('max_depth=9')","93f897c0":"from sklearn.metrics import accuracy_score\n#accuracy_score(dftrain.y,yhat_train) #?? das ergibt viel zu viele Kommastellen und suggeriert eine Scheingenauigkeit!\n#Besser, wir runden selber:\nprint('{0:1.2f}'.format(accuracy_score(dftrain.y,yhat_train)))","d3e61134":"my_submission = pd.Series(yhat_test,name='y') #Wandelt die DataFrame-Spalte in eine Series um und benennt die y-Spalte\npd.DataFrame(my_submission).to_csv('Submission.csv',header=True,index_label='Id' ) #Export mit korrektem Header","e809fba1":"#So sieht unsere hochzuladende Datei aus:\n!head Submission.csv","b2b54dfd":"## Feature Engineering","7cadac38":"Das praktische an diesen Dataframes ist, dass wir nun auf die einzelnen Spalten und deren Werte einfach zugreifen k\u00f6nnen. Z.B. k\u00f6nnen wir die mit `dftrain.X1` auf die Spalte `X1` zugreifen. Indem wir diese quadrieren, quadrieren wir jeden einzelnen Wert:","55e1c9c5":"Der folgende Code zeigt Ihnen, wie ein Klassifikator trainiert wird:","b2b242de":"Den rohen Inhalt der Datei k\u00f6nnen wir wieder mit einem Linuxbefehl ansehen:","e9daabf8":"Das Notebook gliedert sich in die wichtigsten Schritte einer Teilnahme bei einer Kaggle-Competition:\n\n- Wir laden die Daten,\n- wir f\u00fchren einen Daten-Preprocessing durch, ev. auch mit Feature-Engineering\n- an Hand des Trainingsdatensatzes trainieren wir einen Klassifikator und optimieren die Hyperparameter\n- Wir erstellen eine Vorhersage f\u00fcr die Testdaten und [Submitten sie an die Kaggle-Competition](https:\/\/www.kaggle.com\/c\/male-daan-schnell-mal-klassifizieren\/submit).\n\nAnschliessend sind Sie dran. Optimieren Sie Ihre Vorhersage und gewinnen Sie die Kaggle Competition!","e31d62e7":"Eine Vorhersage m\u00fcssen wir auf der Datei test.csv erstellen. Schreiben Sie eine Zeile, welche die Testdatei (sie liegt im gleichen Verzeichnis) ausgibt. Inwiefern unterscheidet sie sich von `train.csv`?\n","f534aa43":"## Ihre Aufgabe:\n- Nehmen Sie eine substantielle Verbesserung an obigem Klassifikator vor, und nehmen Sie ernsthaft an der Competition teil. W\u00e4hlen Sie daf\u00fcr einen anderen Scikit-Learn-Klassifikator. [Auswahl haben Sie reichlich](https:\/\/scikit-learn.org\/stable\/user_guide.html)!\n- Das obige Vorgehen ergibt vermutlich ein befriedigendes Ergebnis. \u00dcberlegen Sie, wie Sie dieses Vorgehen beschreiben w\u00fcrden, und wo die wesentlichen Verbesserungsm\u00f6glichkeiten liegen.\n- Stellen Sie sich ein Optimierungsschema vor, das folgendes tut: \n    1. Es beginnt mit der Vorhersage von \"alle Labels 0\". Es setzt i=1\n    2. Die Genauigkeit wird gemessen, einmal mit dem i-ten Label = 0, einmal = 1\n    3. Behalte in allen folgenden Schritten f\u00fcr das i-te Label jene Vorhersage, f\u00fcr welche in Schritt 2 die Genauigkeit h\u00f6her war.\n    4. Breche ab, wenn i=Anzahl der n\u00f6tigen Vorhersagen. Ansonsten setze i->i+1 und gehe zu Schritt 2.\n  \n  Ist das nicht wunderbar? Dieses Schema wird eine Genauigkeit von 100% erreichen! Erkl\u00e4ren Sie, warum dies alles Andere als wunderbar ist, und wie Sie systematisch verhindern, dass Sie die selbe Entt\u00e4uschung bei der Kaggle-Competition erleben. (Tipp: Kaggle wertet nur einen Teil Ihrer Submission aus, um Ihnen ihren aktuellen Score und Rang mitzuteilen. F\u00fcr die endg\u00fcltige Platzierung werden frische Daten verwendet.)","3708659a":"Um diese Datei nun f\u00fcr den Wettbewerb einzureichen, klicken Sie auf Commit. Suchen Sie das Register \"Output\" und dr\u00fccken anschliessend den Knopf \"Submit to competition\"! Falls Sie dieses Notebook nicht in einem Kaggle-Kernel ausgef\u00fchrt haben, so lokalisieren Sie einfach die Datei Submission.csv und laden diese auf der Submissionseite des Wettbewerbs hoch. Aber Achtung! Sie d\u00fcrfen pro Tag nur zwei Submissions vornehmen. Also \u00fcberlegen Sie sich gut, welche zwei Ihrer Modelle wohl die besten sind...\n\nDiese Vorlage benutzte einen \"DummyClassifier\", der also nicht besser ist als ein zuf\u00e4lliges Raten. Wenn Sie nun diesen Klassifikator durch einen besseren ersetzen (z.B. einen Entscheidungsbaum), dann sollten die Resultate deutlich besser werden. ","889b3aee":"Schauen wir uns an, wie gut der Klassifikator ist!","307b9623":"Dr\u00fccken Sie Shift-Enter, um eine Zelle auszuwerten!","7d23f44a":"\n* [Schauen Sie sich hier insbesondere die Dimensionen von X und y an!](https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.ndarray.shape.html) Die erste Dimension von X und y m\u00fcssen \u00fcbereinstimmen, damit der Klassifikator funktioniert: Es m\u00fcssen gleich viele Featurevektoren wie Trainingslabels vorhanden sein.\n* Wieviele Trainingsbeispiele haben wir?\n* Wie viele Features sind vorhanden?\n* Welches Klassenverh\u00e4ltnis liegt vor? Dabei wird Ihnen die Funktion [np.mean](https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.sum.html) helfen.\n\nWir benutzen den trainierten Klassifikator um Vorhersagen (auf den Trainings- und Testdaten) zu machen:","304dbba4":"## Machine Learning mit Scikit-Learn","edd796f7":"*Feature-Engineering* geht genau so: Wir erstellen ein neues Feature (eine Spalte im Dataframe) aus den gegebenen. Die n\u00e4chste Zelle zeigt, wie das geht:","ffec1305":"## Let's get started!\nZun\u00e4chst importieren wir Numpy und Pandas zum arbeiten mit Arrays und Datens\u00e4tzen (dataframes).\nAuch Matplotlib ist essentiell- die Bibliothek zum Generieren von Visualisierungen.  \nEine Kurzeinf\u00fchrung zu diesen Tools habe ich Ihnen [hier](https:\/\/www.kaggle.com\/toedtli\/scipy-crashkurs) erstellt: [https:\/\/www.kaggle.com\/toedtli\/scipy-crashkurs](https:\/\/www.kaggle.com\/toedtli\/scipy-crashkurs). \"Forken\" Sie Ihre eigene Kopie und basteln Sie an dem Code herum. Sie k\u00f6nnen nichts kaputtmachen.","f52aa375":"Weitere super-n\u00fctzliche Methoden eines Dataframes: `.shape`, `.summary()`, `.plot.scatter()`, ` .values`, `.columns`, `.to_csv()`  \nProbieren Sie sie aus! Hier auch nochmals der Verweis auf den [Pandas-Abschnitt in meinem Scipy-Crashkurs](https:\/\/www.kaggle.com\/toedtli\/scipy-crashkurs#Pandas).","0e19030a":"Hier werden einige Grundlagen der objektorientierten Programmierung ben\u00f6tigt: `DummyClassifier` ist eine Klasse, `myfirst_clf` eine Instanz der Klasse `DummyClassifier`.`DummyClassifier()` ist ein Konstruktor, welche konkrete Dummyklassifikatoren (also Instanzen) erstellt. Die zwei Instanzen `clf1` und `clf2` z.B.:\n\n    clf1=DummyClassifier()\n    clf2=DummyClassifier()\n    \nk\u00f6nnen unabh\u00e4ngig voneinander auf unterschiedlichen Datens\u00e4tzen trainiert werden.\n\nWenn Sie einen besseren Klassifikator w\u00e4hlen (z.B. ein DecisionTreeClassifier), so besitzt dieser Hyperparameter, die Sie w\u00e4hlen m\u00fcssen! So hat der\n[DecisionTreeClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html) z.B. eine w\u00e4hlbare Tiefe (z.B. `DecisionTreeClassifier(max_depth=999)`). \n* Informieren Sie sich in der Dokumentation, welches die relevanten Parameter des DecisionTree-Klassifikators sein k\u00f6nnten.\n  W\u00e4re `random_state` beispielsweise ein sinnvoller Hyperparameter?","28dd423a":"* Die Aufgabe besteht darin, `y` basierend auf den Features `X1` und `X2` vorherzusagen. Jede Zeile enth\u00e4lt ein Beispiel. `dftest` enth\u00e4lt neue Beispiele mit `X1` und `X2`-Werten, aber keine `y`-Werten. In der Kaggle-Competition geht es darum, wer die beste Vorhersage f\u00fcr `ytest` (den `y`-Werten auf dem Testdatensatz) macht. Versuchen Sie zumindest eine Vorhersage.\n\nDies geht so:\n\n   - Laden Sie einen Klassifikator und trainieren Sie ihn auf den Trainingsdaten\n   - Erstellen Sie Vorhersagen f\u00fcr die Daten in `test.csv`\n   - schreiben Sie diese in eine Datei `Submission.csv`\n   - Laden Sie diese Vorhersage hier hoch: https:\/\/www.kaggle.com\/c\/male-daan-schnell-mal-klassifizieren\/submit\n  \nWenn Sie in einem mit der Competition assoziierten Kaggle Notebook arbeiten, klicken Sie auf \"Commit\" und danach im Reiter \u00fcber erstellte Dateien (`Submission.csv`) auf \"Submit to competition\".\nIm Folgenden der Code, der Ihnen dabei hilft. Passen Sie diesen so an, dass er eine m\u00f6glichst gute Vorhersage produziert!","36b7bd9e":"# Einf\u00fchrung in Kaggle-Competitions mit Scikit-Learn\nAutor: Dr. B.T\u00f6dtli","49573505":"Ziemlich offensichtlich ist die Klassifikationsgenauigkeit noch j\u00e4mmerlich! Aber wie berechnen wir die Genauigkeit?","8db60a33":"Nun generieren wir die `Submission.csv`-Datei, wie in der [Wettbewerbsdokumentation](https:\/\/www.kaggle.com\/c\/male-daan-schnell-mal-klassifizieren\/data) beschrieben:","e34484d6":"Die Ausgabe der vorherigen Zelle sollte in etwa so aussehen:\n\n    Id,y\n    0,0\n    1,1\n    2,1\n    3,1\n    4,0\n    5,0\n    6,0\n    \n(Die Werte 0 oder 1 hinter dem Komma d\u00fcrfen andere sein)\n    \n    ","1a667135":"Nun laden wir diese Daten in je ein Pandas Dataframe:","2af2695d":"# Willkommen!\nWir lernen hier, mit Scikit-Learn an einer Kaggle-Competition teilzunehmen. Nat\u00fcrlich ist das Lernen von Scikit-Learn ein ehrgeiziges Projekt, wenn Sie noch nie in Python programmiert haben. Ich empfehle Ihnen folgende Quelle f\u00fcr die Python Grundlagen: \n<center>https:\/\/www.python-kurs.eu\/python3_kurs.php   <\/center>  \nAber vorerst[](http:\/\/) werden Sie nur an wenigen Stellen den vorgegebenen Code ab\u00e4ndern m\u00fcssen.","2e7418ef":"## Teilnehmen an der Kaggle-Competition","23ac2e30":"`yhat_test` (eigentlich $\\hat{y}_{\\mathrm{test}}$) enth\u00e4lt nun die Vorhersagen, die wir auf Kaggle hochladen wollen. \n\n* \u00dcberpr\u00fcfen Sie, dass der Numpy-Array `yhat_test` die korrekte Anzahl von Eintr\u00e4gen hat. Ersetzen Sie in der n\u00e4chsten Zeile \"True\" durch einen Ausdruck in X und y, welcher die Anzahl Zeilen in `yhat_test` mit den Anzahl Zeilen in `Xtest` vergleicht.","85bdc006":"### Daten laden mit Pandas\nSchauen wir uns die Daten mal an. Dies sollte *immer* der erste Schritt in einem Data Science\/Business Intelligence-Projekt sein.  \nDas Ausrufezeichen im n\u00e4chsten Befehl bedeutet, dass anschliessend nicht ein Pythonbefehl folgt, sondern ein Linuxbefehl: Hier werden die Dateien im angegebenen Verzeichnis aufgelistet:"}}