{"cell_type":{"27759635":"code","c65466d0":"code","c60a085f":"code","b1114240":"code","956069da":"code","97d249ad":"code","6065116b":"code","544343bd":"code","4327d107":"code","71dbf19f":"code","a842cb23":"code","9aa49d39":"code","287449ff":"code","b6bab9b6":"code","6bea7b3f":"code","c964dcdf":"code","4693cec6":"code","aa6319f2":"code","a23ba865":"markdown","630deeb0":"markdown","12ccd0c8":"markdown","6e093309":"markdown","4d0dc50f":"markdown","1de65554":"markdown","8c817894":"markdown","f18f1861":"markdown","4efa2c51":"markdown","c104b23d":"markdown","9510cc05":"markdown","cb7ee836":"markdown","53301148":"markdown","80186899":"markdown","c8157a71":"markdown"},"source":{"27759635":"#Importing necessary tools:\n\n#from alpha_vantage.timeseries import TimeSeries\n#rom alpha_vantage.foreignexchange import ForeignExchange    ------> (this part I'll do in my pc, and only will explain here)\n\nimport pandas as pd #We all love pandas\nimport numpy as np #Linear Algebra\nimport matplotlib.pyplot as plt #plot\nimport seaborn as sns #more ploting\nimport datetime \n\nfrom sklearn.linear_model import LinearRegression #sklearn for our regression models\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import preprocessing, svm\nfrom sklearn.model_selection import train_test_split\nimport statsmodels.api as sm","c65466d0":"df = pd.read_csv(\"..\/input\/stock_itausa.csv\", index_col='date')","c60a085f":"df.head()","b1114240":"df.info()","956069da":"# Histogram of the daily price change percent of Adj_Close \nplt.figure(figsize=(7,7))\ndf['4. close'].pct_change().plot.hist(bins=50)\nplt.xlabel('1-day percent change')\nplt.show()","97d249ad":"forecast_out = int(15) # predicting 15 days into future\ndf['Prediction'] = df[['4. close']].shift(-forecast_out) #  label column with data shifted 30 units up\ntarget = df[['4. close']][-forecast_out:]","6065116b":"# Maybe the day of week help us:\ndf.index = pd.to_datetime(df.index)\ndays_of_week = pd.get_dummies(df.index.day_name())\ndays_of_week.index = df.index\ndf = pd.concat([df, days_of_week], axis=1)\n","544343bd":"#Let's see our boxplot of features:\ndf.plot(kind='box', figsize=(7,7))","4327d107":"#This isn't looking good... We should normalize it.\nX = np.array(df.drop(['Prediction'], 1))\nX = preprocessing.scale(X)\n\nX_forecast = X[-forecast_out:] \nX = X[:-forecast_out] \n\ntest = pd.DataFrame(X)\ntest.plot(kind='box', figsize=(7,7))","71dbf19f":"y = np.array(df['Prediction'])\ny = y[:-forecast_out]","a842cb23":"    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n    # Training\n    clf = LinearRegression()\n    clf.fit(X_train,y_train)\n    # Testing\n    confidence = clf.score(X_test, y_test)\n    print(\"confidence: \", confidence)","9aa49d39":"# random forest model\nrfr = RandomForestRegressor(n_estimators=200, max_depth=3, max_features=4, random_state=42)\nrfr.fit(X_train, y_train)\ntrain_predictions = rfr.predict(X_train)\ntest_predictions = rfr.predict(X_test)\n\n# scatter plot with train and test actual vs predictions\nplt.figure(figsize=(7,7))\nplt.scatter(y_train, train_predictions, label='train')\nplt.scatter(y_test, test_predictions, label='test')\nplt.legend()\nplt.show()\n","287449ff":"# Get feature importances from our random forest model\nimportances = rfr.feature_importances_\nlabels = df.drop('Prediction', axis=1).columns.values\nplt.figure(figsize=(7,7))\nplt.bar(np.arange(10), importances, tick_label=labels)\nplt.xticks(rotation=90)","b6bab9b6":"model = MLPRegressor(random_state=42, solver='lbfgs', activation='logistic')\nto_plot_predict = []\nto_plot_real = []\n\nfor i in range(50, len(X), 1):\n    X2_train = X[:i]\n    X2_test = X[i].reshape(1, -1)\n    y2_train = y[:i]\n    y2_test = y[i].reshape(1, -1)\n\n\n    model.fit(X2_train, y2_train)\n    predictions = model.predict(X2_test)\n\n    to_plot_predict.append(predictions[0])\n    to_plot_real.append(y2_test[0][0])","6bea7b3f":"plt.clf()\nplt.figure(figsize=(9,9))\nplt.subplot()\nplt.plot(to_plot_predict, c='red', label='predictions')\nplt.plot(to_plot_real, c='blue', label='real')\nplt.title('Real x Prediction')\nplt.legend()\nplt.show()","c964dcdf":"results = {'Predict':to_plot_predict,'Real':to_plot_real}\nresults = pd.DataFrame(results)\nresults['Predictvar'] = results['Predict'].pct_change()\nresults['Realvar'] = results['Real'].pct_change()","4693cec6":"results['decision_predict'] = results.apply(lambda row: row.Realvar * row.Predictvar, axis=1)\ndef decision_predict(result):\n    if result >= 0:\n        return 'good_prediction'\n    else:\n        return 'bad_prediction'\nresults['decision_predict'] = results['decision_predict'].apply(lambda x: decision_predict(x))\nresults.drop(results.head(1).index, inplace=True)","aa6319f2":"results['decision_predict'].value_counts()","a23ba865":"# We have 500 entries, each one represents a day, and the time-range is from start 2017 to end 2018","630deeb0":"## What about using a machine learning model now?","12ccd0c8":"The two API's are:\n\n## quandl\n\n## alpha_vantage\n\nThe first thing we have to do is get an access token, just need an email and a login in these links:\n\n[https:\/\/www.alphavantage.co\/](http:\/\/)\n\n[https:\/\/www.quandl.com\/](http:\/\/)\n\nHere I'm addressing the alphavatage token as:\n\n    My_Key = \"put your key here\"\n\nAnd quandl as:\n\n    quandl_Key = \"put your other key here\"\n\nfor quandl, we just call the lines below and it's all set:\n\n    #AUTHENTICATION\n    import quandl\n    quandl.ApiConfig.api_key = My_Other_Key","6e093309":"### P.S.: Unhappy, we cannot run the code bellow here in Kaggle, but I'll continue the process, and import the already extracted DataSe further ahead. ^^","4d0dc50f":"# In the test above, we used train_test_split of sklearn package... but this method divide our data in a random order... would be better for a time series splitting the data using the following logic:\n\n    train_features = feature[:train_size]\n    train_targets = target[:train_size]\n\n    test_features = feature[train_size:]\n    test_targets = target[train_size:]\n  ","1de65554":"    \n    #Choose a Stock\n    stock = 'ITSA4.SA'\n    \n    #Stock collection:\n    ts = TimeSeries(key=My_Key, output_format='pandas')\n    data, meta_data = ts.get_daily(symbol=stock, outputsize='full')\n    df_stock = data['2016':'2019']\n    df_stock['var'] = df_stock['4. close'].pct_change() * 100\n    target = []\n    for i in range(len(df_stock)):\n        if i == len(df_stock)-1:\n            break\n        target.append(df_stock['var'].iloc[i + 1])\n    target.append(np.nan)\n    df_stock['target'] = target\n    df_stock.fillna(method='ffill', inplace=True)\n    df_stock = df_stock.drop(['1. open', '2. high', '3. low', '5. volume'], axis=1)","8c817894":"\n    #Time Period\n    start = datetime.datetime(2016, 1, 5)\n    end = (2018, 12, 27)\n\n\n    #Bovespa Data Colection:\n    ts = TimeSeries(key=My_Key, output_format='pandas')\n    data, meta_data = ts.get_daily(symbol=Indice_BOVESPA, outputsize='full')\n    bovespa = data['2016':'2018']\n    bovespa['var'] = bovespa['4. close'].pct_change() * 100\n    target = []\n    for i in range(len(bovespa)):\n        if i == len(bovespa)-1:\n            break\n        target.append(bovespa['var'].iloc[i + 1])\n    target.append(np.nan)\n    bovespa['target'] = target\n    bovespa = bovespa.replace([np.inf, -np.inf], np.nan)\n    bovespa = bovespa.replace(0, np.nan)\n    bovespa.fillna(method='ffill', inplace=True)","f18f1861":"# Ok, now I'll import a Dataset that I collected doing the steps above, so we can do some other tests... ","4efa2c51":"# Apparently, it's terrible... But would be good to analyse in an investors perspective. \n\n# did our model predict the percent change direction correct?","c104b23d":"## Testing a Randon Forest model: ","9510cc05":"## Since our weekday is not relevant to the model, we can remove it...","cb7ee836":"# Hello!\n\nI often have difficulties to collect **market data** from **Bovespa** (brazil stocks).\n\nSo, in this Kernel, I'll show two API's that I'm using to get some info and some example of analysis\n\nFeel free to comment or ask anything!\n:D","53301148":"\n    #concatenating all data\n    df = df_stock.join(bovespa)\n    df = df.join(forex)\n    df.fillna(method='ffill', inplace=True)","80186899":"# Our model made 226 good predictions against 208 bad prediction, we still have a lot to improve!","c8157a71":"    #Dolar to Reais (USD to BRL)\n    forex = quandl.get('FRED\/DEXBZUS', start_date=start, end_date=end)\n    forex['dolar_var'] = forex['Value'].pct_change() * 100"}}