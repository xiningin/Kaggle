{"cell_type":{"8b3b454e":"code","cd4158a5":"code","16f838e3":"code","2062f9db":"code","633f4b8c":"code","94d4c2fd":"code","4094e639":"code","11b5a714":"code","9e134023":"code","4a117044":"code","7e625afc":"code","66d1fed3":"code","9cbe0594":"code","097df066":"code","80672e29":"code","80f936f9":"code","27dc9297":"code","3ad1b474":"code","448ecd51":"code","56895d22":"code","ff7d08d3":"code","28a43fc0":"code","8ebb2863":"code","987ebf9b":"code","c6b6a50f":"code","18ab16e9":"code","cf1406f0":"code","a6d6d028":"code","cb1717e6":"code","7c10d2d1":"code","55c1b71c":"code","e176adda":"code","cd5271e8":"code","59cd8a0a":"code","f98d4433":"code","8cd1d108":"code","5a08635c":"code","74cdb991":"code","6c2069e3":"code","f08fd1d8":"code","8abb6537":"code","710c06a9":"code","e11fa459":"code","6595125a":"code","157d6243":"code","3cbba373":"code","36da8249":"code","9ae41e6f":"code","422817e1":"code","19b64ede":"code","7aa03d42":"code","d0656633":"code","6cc2de6e":"code","d9edf10f":"code","a59eefbe":"code","d4fd93b2":"code","10f1fc01":"code","6cae5875":"code","e05d62dc":"code","e94d64e1":"code","db6cece6":"code","ac5a3466":"code","f4e3351b":"code","146151ba":"code","97f87a7e":"code","d5d2e6fc":"code","570db913":"code","91d844d6":"code","83b7e0bb":"code","4669a15b":"code","7e6ab956":"code","cb93416f":"code","2e2c8709":"code","133b06bd":"code","41c57b93":"code","dcb20367":"code","1a4907ca":"code","d06ae1ed":"code","0be2e785":"code","bb2dae62":"code","3e606cdd":"code","2a26bb06":"code","f8aa5671":"code","aa5a2b52":"code","f6296270":"code","fd7aadd7":"code","0a120f62":"code","f4530ff4":"code","5bca7fb9":"code","6eed071e":"code","c80e300f":"code","966387a3":"code","11606303":"code","1fce4380":"code","89486ed3":"code","2804e46e":"code","6f1948eb":"code","3ea88de3":"code","47dc8c71":"code","39213a16":"code","0e75c89a":"code","ed5bcb2f":"code","f51c6a44":"code","136975e4":"code","7474e239":"code","316bf4b2":"code","1abd3fa3":"code","a57bf700":"code","fd44034f":"code","bd211a8d":"code","134b784e":"code","4a9c9a6b":"code","3a2e5172":"code","086805f6":"code","00e92322":"code","e291eaf5":"code","240992d5":"code","526321bd":"code","b834c219":"code","cb52a6d6":"code","d6873c92":"code","4e1c0e77":"code","f52b37fe":"code","3844083d":"code","3831dd6d":"code","e388eaaf":"code","1ac1df78":"code","48f9692a":"code","7b6190b1":"code","bc8e43d2":"code","ce6fcb02":"code","febb8b46":"markdown","b98da180":"markdown","6f25019b":"markdown","89a77a5c":"markdown","5daca49c":"markdown","73934626":"markdown","6bca6997":"markdown","a318a3ca":"markdown","95580c76":"markdown","f50b61bd":"markdown","99c0f6c5":"markdown","4c53d54e":"markdown","df10d852":"markdown","e7202371":"markdown","c14c2f71":"markdown","13bd5e3d":"markdown","988ab829":"markdown","67dbf20e":"markdown","84ebabb4":"markdown","c6c815f8":"markdown","40527893":"markdown","9d2289e7":"markdown","f16df351":"markdown","2e68b972":"markdown","f555e319":"markdown","22f089ba":"markdown","354c78b5":"markdown","7ca6f34f":"markdown","cc4b7a7f":"markdown","9635bba3":"markdown","aa92f6ab":"markdown","cd823b08":"markdown","74b18d67":"markdown","329da78a":"markdown","be6d9f9f":"markdown","2ca13447":"markdown","14fcee1c":"markdown","ff25f0e3":"markdown","12bdcd0f":"markdown","44ded893":"markdown","946441bc":"markdown","e8227f2b":"markdown","80479663":"markdown","fd2d2937":"markdown","36c9535d":"markdown","89e0e369":"markdown"},"source":{"8b3b454e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cd4158a5":"data=pd.read_csv(\"\/kaggle\/input\/videogamesales\/vgsales.csv\")\ndf=data.copy()","16f838e3":"display(df.head())\ndisplay(df.tail())","2062f9db":"df.info()","633f4b8c":"df.isnull().sum()","94d4c2fd":"df.Publisher.fillna('Unknown', inplace=True)","4094e639":"df.Year.fillna(df.Year.mode()[0], inplace=True) #we fill Year as mode of year","11b5a714":"df.Year=df.Year.astype('int64')\ndf.info()","9e134023":"#Lets look at values or kategories of variables.\ndisplay(df.Platform.unique())\ndisplay(df.Genre.unique())\ndisplay(df.Year.unique())","4a117044":"df['Platform'].replace('2600', 'Atari', inplace=True)\ndisplay(df.Platform.unique())","7e625afc":"df[\"Year\"].value_counts()","66d1fed3":"df=df[df[\"Year\"]<2017]","9cbe0594":"df.corr()","097df066":"df.describe()","80672e29":"import matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport seaborn as sns\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go","80f936f9":"# we can see correlation on heatmap.\nf,ax = plt.subplots(figsize=(16, 16))\nsns.heatmap(df.corr(), annot=True, linewidths=.5, fmt= '.2f',ax=ax)\nplt.show()","27dc9297":"#Here,we can see with regression line \nsns.pairplot(df,kind=\"reg\")","3ad1b474":"df1=df.head(100)","448ecd51":"trace1 = go.Scatter(\n                    x = df1.Rank,\n                    y = df1.NA_Sales,\n                    mode = \"markers\",\n                    name = \"North America\",\n                    marker = dict(color = 'rgba(28, 149, 249, 0.8)',size=8),\n                    text= df.Name)\n\ntrace2 = go.Scatter(\n                    x = df1.Rank,\n                    y = df1.EU_Sales,\n                    mode = \"markers\",\n                    name = \"Europe\",\n                    marker = dict(color = 'rgba(249, 94, 28, 0.8)',size=8),\n                    text= df1.Name)\ntrace3 = go.Scatter(\n                    x = df1.Rank,\n                    y = df1.JP_Sales,\n                    mode = \"markers\",\n                    name = \"Japan\",\n                    marker = dict(color = 'rgba(150, 26, 80, 0.8)',size=8),\n                    text= df.Name)\ntrace4 = go.Scatter(\n                    x = df1.Rank,\n                    y = df1.Other_Sales,\n                    mode = \"markers\",\n                    name = \"Other\",\n                    marker = dict(color = 'lime',size=8),\n                    text= df.Name)\n                    \n\ndata = [trace1, trace2,trace3,trace4]\nlayout = dict(title = 'North America, Europe, Japan and Other Sales of Top 100 Video Games',\n              xaxis= dict(title= 'Rank',ticklen= 5,zeroline= False,zerolinewidth=1,gridcolor=\"white\"),\n              yaxis= dict(title= 'Sales(In Millions)',ticklen= 5,zeroline= False,zerolinewidth=1,gridcolor=\"white\",),\n              paper_bgcolor='rgb(243, 243, 243)',\n              plot_bgcolor='rgb(243, 243, 243)' )\nfig = dict(data = data, layout = layout)\niplot(fig)","56895d22":"#BILGISAYAR KASTI\n# plt.figure(figsize=(10,7))\n# plt.title('Global Sales (in Millions) throughout the Year', color = 'g', size = 13)\n# plt.xlabel('Year', color = \"c\");\n# plt.ylabel('Global_Sales', color = \"r\");\n\n# plt.bar(df.Year, df.Global_Sales, width=0.7, color=\"y\", edgecolor=\"r\", linewidth=2,\n#        yerr=0.01, ecolor=\"m\", hatch=\"*\")\n# plt.show()\n","ff7d08d3":"sns.jointplot(df.Year,df.Global_Sales,size=8, ratio=9, color=\"blue\")\nplt.show()","28a43fc0":"# Scatter Plot \ndf.plot(kind='scatter', x='NA_Sales', y='EU_Sales',alpha = 0.5,color = 'red')\nplt.xlabel('NA_Sales')              # label = name of label\nplt.ylabel('EU_Sales')\nplt.title('NA_Sales EU_Sales Scatter Plot')            # title = title of plot\nplt.show()","8ebb2863":"sns.barplot(x=\"Year\",y = 'Global_Sales',data=df);\nplt.xticks(rotation=30);","987ebf9b":"#Games according to Genre\nlabels=df.Genre.value_counts().index\nexplode = [0,0,0,0,0,0,0,0,0,0,0,0]\nsizes = df.Genre.value_counts().values\n# visual\nplt.figure(figsize = (7,7))\nplt.pie(sizes, explode=explode, labels=labels, colors=sns.color_palette('Set2'), autopct='%1.1f%%')\nplt.title('Games According to Genre',fontsize = 17,color = 'green');","c6b6a50f":"# Count of Platforms\nplt.subplots(figsize = (15,8))\nsns.countplot(df.Platform)\nplt.title(\"Platform\",color = 'blue',fontsize=20);","18ab16e9":"style.use('seaborn-poster')\n\nf, ax = plt.subplots()\nplatform_releases = df['Platform'].value_counts()\n\nsns.barplot(x=platform_releases.values, y=platform_releases.index, ec='Black')\nax.set_title('Platforms with the Most Releases', fontweight='bold', fontsize=23)\nax.set_xlabel('Releases', fontsize=18)\nax.set_xlim(0, max(platform_releases.values)+130)\nax.set_ylabel('Platform', fontsize=18)\nplt.show()","cf1406f0":"genre_global_sales = df.groupby(['Genre'])['Global_Sales'].sum().sort_values(ascending=False)\nprint(genre_global_sales)\nsns.barplot(x=genre_global_sales.index, y=genre_global_sales.values, ec='Black', palette='twilight')\nplt.xticks(rotation=20, fontsize=12)\nplt.xlabel('Genre', fontsize=18)\nplt.ylabel('Global Sales (in Millions)', fontsize=18)\nplt.title('Global Sales of Genres from 1980-2016', fontweight='bold', fontsize=22)\nplt.tight_layout()\nplt.show()","a6d6d028":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom PIL import Image\n\nstopwords = set(STOPWORDS)\n\nfor x in df.Genre.unique():\n    wc = WordCloud(background_color=\"white\", max_words=2000, \n                   stopwords=stopwords, max_font_size=40, random_state=42)\n    wc.generate(df.Name[df.Genre == x].to_string())\n    plt.imshow(wc)\n    plt.title(x)\n    plt.axis(\"off\")\n    plt.show()","cb1717e6":"fig,ax = plt.subplots(figsize=(8,5))\ndf['Genre'].value_counts(sort=False).plot(kind='bar',ax=ax,rot =90)\nplt.title('Genre Distribution',fontsize=15)\nplt.xlabel('Genre',fontsize=15)\nplt.ylabel('Number of sales',fontsize=15)","7c10d2d1":"from collections import Counter\ngenre = Counter(df['Genre'].dropna().tolist()).most_common(10)   #top 10 genre\ngenre_name = [name[0] for name in genre]\ngenre_counts = [name[1] for name in genre]\n\nfig,ax = plt.subplots(figsize=(8,5))\nsns.barplot(x=genre_name,y=genre_counts,ax=ax)\nplt.title('Top ten Genre',fontsize=15)\nplt.xlabel('Genre',fontsize=15)\nplt.ylabel('Number of genre',fontsize=15)\nticks = plt.setp(ax.get_xticklabels(),fontsize=15,rotation=60)","55c1b71c":"platform = Counter(df['Platform'].dropna().tolist()).most_common(10)  #ten top platform\nplatform_name = [name[0] for name in platform]\nplatform_count = [name[1] for name in platform]\n\nfig,ax = plt.subplots(figsize=(8,6))\nsns.barplot(x=platform_name,y=platform_count,ax=ax)\nplt.title('Top ten platform',fontsize=15)\nplt.ylabel('Number of platform',fontsize=15)\nplt.xlabel('Platform',fontsize=15)\nticks = plt.setp(ax.get_xticklabels(),fontsize=15,rotation=60)","e176adda":"publisher = Counter(df['Publisher'].dropna().tolist()).most_common(10) #ten top publisher\npublisher_name = [name[0] for name in publisher]\npublisher_count = [name[1] for name in publisher]\n\nfig,ax = plt.subplots(figsize=(8,6))\nsns.barplot(x=publisher_name,y=publisher_count,ax=ax)\nplt.title('Top ten publisher',fontsize=15)\nplt.ylabel('number of publisher',fontsize=15)\nplt.xlabel('publisher',fontsize=15)\nticks = plt.setp(ax.get_xticklabels(),fontsize=15,rotation=90)","cd5271e8":"#preparing data frame\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\ndf1 = df.iloc[:100,:]\n\n#import graph objects as \"go\"\nimport plotly.graph_objs as go\n\n#creating trace1\ntrace1 = go.Scatter(\n                    x = df1.Rank,\n                    y = df1.NA_Sales,\n                    mode = \"lines\",\n                    name = \"NA Sales\",\n                    marker = dict(color=\"rgba(166,11,2,0.8)\"),\n                    text = df1.Name)\n#creating trace2\ntrace2 = go.Scatter(\n                    x = df1.Rank,\n                    y = df1.EU_Sales,\n                    mode = \"lines+markers\",\n                    name = \"EU Sales\",\n                    marker = dict(color = \"rgba(80,12,160,0.5)\"),\n                    text = df.Name)\ndata = [trace1,trace2]\nlayout = dict(title = \"Global Sales of Top 100 Games\",\n                xaxis = dict(title=\"Rank\",ticklen= 5, zeroline=False)\n             )\nfig = dict(data = data, layout = layout)\npy.offline.iplot(fig)","59cd8a0a":"x2016 = df.Genre[df.Year == 2016]      #Number of genres 2016 to 2010\nx2006 = df.Genre[df.Year == 2010]\n\ntrace1 = go.Histogram(\n                        x = x2016,\n                        opacity = 0.75,\n                        name = \"2016\",\n                        marker = dict(color=\"rgba(162,50,70,0.9)\"))\ntrace2 = go.Histogram(\n                        x = x2006,\n                        opacity = 0.75,\n                        name = \"2010\",\n                        marker = dict(color=\"rgba(24,68,200,0.6)\"))\n\ndata = [trace1,trace2]\nlayout = go.Layout(barmode = \"overlay\",\n                    title = \"Number of Genres in 2016 and 2010 \",\n                  xaxis = dict(title=\"Genre\"),\n                  yaxis = dict(title = \"Count\"),\n                  )\nfig = go.Figure(data=data,layout=layout)\npy.offline.iplot(fig)","f98d4433":"# Plot for games' count on each platform (classic bar plot)\nx=df.Platform.unique()\ny=df.Platform.value_counts()\nplt.figure(figsize=(24,12))\nsns.barplot(x=x,y=y,edgecolor=\"black\")\nplt.xlabel(\"Platforms\")\nplt.ylabel(\"Games count\")\nplt.show()","8cd1d108":"# Sequential bar plot for games' genre count\nx=df.Genre.unique()\ny=df.Genre.value_counts().sort_values(ascending=True)\nplt.figure(figsize=(16,9))\nsns.barplot(x=x,y=y,palette=\"rocket\")\nplt.xlabel(\"Genres\")\nplt.ylabel(\"Games count\")\nplt.show()","5a08635c":"from sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\nimport statsmodels.api as sm \nimport statsmodels.formula.api as smf \nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score","74cdb991":"from sklearn.preprocessing import LabelEncoder\n# label encoding of categorical variables\nlbe = LabelEncoder()\ndf['Genre_Cat'] = lbe.fit_transform(df['Genre'])\ndf['Platform_Cat'] = lbe.fit_transform(df['Platform'])\ndf['Publisher_Cat'] = lbe.fit_transform(df['Publisher'])\ndf.sample(3)","6c2069e3":"df1 = df.loc[:,'Global_Sales':]\ndf1.head()","f08fd1d8":"y = df1.Global_Sales.values\nx_dat = df1.drop(['Global_Sales'], axis = 1)\nx=(x_dat-np.min(x_dat))\/(np.max(x_dat)-np.min(x_dat)).values","8abb6537":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state= 42)","710c06a9":"import statsmodels.api as sm  ","e11fa459":"x = sm.add_constant(x)","6595125a":"\nx=x.drop([\"const\"],axis=1)","157d6243":"x[0:5]","3cbba373":"y[0:5]","36da8249":"lm = sm.OLS(y,x)\nmodel = lm.fit()\nmodel.summary()","9ae41e6f":"model.params","422817e1":"model.summary().tables[1]","19b64ede":"model.conf_int()  #confident intervaL","7aa03d42":"model.f_pvalue","d0656633":"print(\"f_pvalue: \", \"%.4f\" % model.f_pvalue)","6cc2de6e":"print(\"fvalue: \", \"%.2f\" % model.fvalue)","d9edf10f":"print(\"tvalue: \", \"%.2f\" % model.tvalues[0:1])","a59eefbe":"model.rsquared_adj","d4fd93b2":"model.fittedvalues[0:5]  #prediction values","10f1fc01":"y[0:5] #Real values","6cae5875":"mse = mean_squared_error(y, model.fittedvalues)\nmse","e05d62dc":"rmse = np.sqrt(mse)\nrmse","e94d64e1":"from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict","db6cece6":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state= 42)","ac5a3466":"lm = LinearRegression()\nmodel_multi = lm.fit(x_train, y_train)","f4e3351b":"# Coefficients\nmodel_multi.coef_","146151ba":"model_multi.intercept_","97f87a7e":"y_multipred=model_multi.predict(x_test)[0:10]\ny_multipred","d5d2e6fc":"multi_reg_rmse = np.sqrt(mean_squared_error(y_train, model.predict(x_train)))\nmulti_reg_rmse  # it is 1.4104046948894693","570db913":"np.sqrt(mean_squared_error(y_train, model.predict(x_train))) #TRAIN ERROR IS 1.4104046948894693","91d844d6":"np.sqrt(mean_squared_error(y_test, model.predict(x_test))) #TEST ERROR IS 2.0467221073976525","83b7e0bb":"model_multi.score(x_train, y_train) #R2 VALUE IS 0.0008389037527712916","4669a15b":"-cross_val_score(model_multi, x_train, y_train, cv = 10, scoring = \"r2\").mean()","7e6ab956":"multi_tuned_rmse_train=np.sqrt(-cross_val_score(model_multi, \n                x_train, \n                y_train, \n                cv = 10, \n                scoring = \"neg_mean_squared_error\")).mean()\nmulti_tuned_rmse_train","cb93416f":"multi_tuned_rmse_test=np.sqrt(-cross_val_score(model_multi, \n                x_test, \n                y_test, \n                cv = 10, \n                scoring = \"neg_mean_squared_error\")).mean()\nmulti_tuned_rmse_test #RMSE_MULTI_TUNED=1.759670817591785\n","2e2c8709":"r2_score(y_test, y_pred) #R2SCORE_MULTI_TUNED=0.0011145467577804435","133b06bd":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale","41c57b93":"x_train, x_test, y_train, y_test = train_test_split(x, \n                                                    y, \n                                                    test_size=0.20, \n                                                    random_state=42)","dcb20367":"pca = PCA()\nx_reduced_train = pca.fit_transform(scale(x_train))\nx_reduced_train[0:1,:]","1a4907ca":"np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)[0:2] #We can see succesful of choices","d06ae1ed":"lm = LinearRegression()\npcr_model = lm.fit(x_reduced_train, y_train)","0be2e785":"pcr_model.intercept_","bb2dae62":"pcr_model.coef_","3e606cdd":"y_pred = pcr_model.predict(x_reduced_train)\ny_pred[0:5]","2a26bb06":"rmse_pcr=np.sqrt(mean_squared_error(y_train, y_pred))\nrmse_pcr","f8aa5671":"df[\"Global_Sales\"].mean()","aa5a2b52":"r2score_pcr=r2_score(y_train, y_pred)\nr2score_pcr","f6296270":"pca2 = PCA()\nx_reduced_test = pca2.fit_transform(scale(x_test))","fd7aadd7":"y_pred = pcr_model.predict(x_reduced_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","0a120f62":"lm = LinearRegression()\npcr_model = lm.fit(x_reduced_train[:,0:10], y_train)  #burdaki 0:10 bilesen sayisi degistikce hata da degisiyor\ny_pred = pcr_model.predict(x_reduced_test[:,0:10])\nprint(np.sqrt(mean_squared_error(y_test, y_pred)))","f4530ff4":"from sklearn import model_selection  #cross validation icin uygun bilesen saysisini bulma islemi\ncv_10 = model_selection.KFold(n_splits = 10,  #10 katli cross validation\n                             shuffle = True,  #gruplarin karistirilip karistirilmayacagi\n                             random_state = 1)\ncv_10","5bca7fb9":"lm = LinearRegression()\nRMSE = []\nfor i in np.arange(1, x_reduced_train.shape[1] + 1):\n    \n    score = np.sqrt(-1*model_selection.cross_val_score(lm, \n                                                       x_reduced_train[:,:i], \n                                                       y_train.ravel(), \n                                                       cv=cv_10, \n                                                       scoring='neg_mean_squared_error').mean())\n    RMSE.append(score)\n#Her bir bilesen sayisi icin 10 katli cross validation uygulayip hatalara bakip hangi bilesen sayisinda daha az hata var onu buluyoruz\nplt.plot(RMSE, '-v')\nplt.xlabel('Bile\u015fen Say\u0131s\u0131')\nplt.ylabel('RMSE')\nplt.title('Prediction for PCR Model Tuning');\n","6eed071e":"lm = LinearRegression()\npcr_model = lm.fit(x_reduced_train[:,0:2], y_train)  #en dusuk hata bilesen sayisi 2 oldugunda cikti\ny_pred = pcr_model.predict(x_reduced_train[:,0:2])\nprint(np.sqrt(mean_squared_error(y_train, y_pred)))","c80e300f":"y_pred = pcr_model.predict(x_reduced_test[:,0:2])\nprint(np.sqrt(mean_squared_error(y_test, y_pred))) #rmse_pcr_tuned=2.0488329468861872","966387a3":"r2_score(y_test, y_pred) #R2SCORE_PCR_TUNED=0.0011145467577804435","11606303":"from sklearn.cross_decomposition import PLSRegression, PLSSVD\npls_model = PLSRegression().fit(x_train, y_train)\npls_model.coef_  #bunlar her zaman degisken sayisi kadar cikar zaten ,biz bunlari carpistirip indirgeme yapiyoruz PCR da da ayni","1fce4380":"x_train.head()","89486ed3":"pls_model.predict(x_train)[0:10]","2804e46e":"y_pred = pls_model.predict(x_train)\nnp.sqrt(mean_squared_error(y_train, y_pred)) # RMSE_PLS_TRAIN=1.4037266722286532","6f1948eb":"r2_score(y_train, y_pred)  #R2SCORE_PLS=0.0008389010941547426","3ea88de3":"y_pred = pls_model.predict(x_test)\nnp.sqrt(mean_squared_error(y_test, y_pred)) #RMSE_PLS_TEST=2.048013316263683","47dc8c71":"cv_10 = model_selection.KFold(n_splits=10, shuffle=True, random_state=1)\nRMSE = []\nfor i in np.arange(1, x_train.shape[1] + 1):\n    pls = PLSRegression(n_components=i)\n    score = np.sqrt(-1*cross_val_score(pls, x_train, y_train, cv=cv_10, scoring='neg_mean_squared_error').mean())\n    RMSE.append(score)\n\n#Sonu\u00e7lar\u0131n G\u00f6rselle\u015ftirilmesi\nplt.plot(np.arange(1, x_train.shape[1] + 1), np.array(RMSE), '-v', c = \"r\")\nplt.xlabel('Bile\u015fen Say\u0131s\u0131')\nplt.ylabel('RMSE')\nplt.title('Global_Sales');","39213a16":"pls_model = PLSRegression(n_components = 3).fit(x_train, y_train) #3 IS BETER FOR N_COMPONENTS\ny_pred = pls_model.predict(x_test)\nnp.sqrt(mean_squared_error(y_test, y_pred)) #RMSE_PLS_TUNED=2.048013783230342","0e75c89a":"r2_score(y_test, y_pred) #R2SCORE__PLS_TUNED=0.0019131351293203425","ed5bcb2f":"from sklearn.linear_model import Ridge\nridge_model = Ridge(alpha = 0.1).fit(x_train, y_train)  #alfa dedigimiz sey lambda.\nridge_model","f51c6a44":"ridge_model.coef_","136975e4":"10**np.linspace(10,-2,100)*0.5","7474e239":"lambdalar = 10**np.linspace(10,-2,100)*0.5 \n\nridge_model = Ridge()\nkatsayilar = []\n\nfor i in lambdalar:\n    ridge_model.set_params(alpha = i)\n    ridge_model.fit(x_train, y_train) \n    katsayilar.append(ridge_model.coef_) \n    \n\n    \nax = plt.gca()\nax.plot(lambdalar, katsayilar) \nax.set_xscale('log') \n\nplt.xlabel('Lambda(Alpha) Values')\nplt.ylabel('Coefficients \/ weights')\nplt.title('Ridge Coefficients as a Function of Regularization');","316bf4b2":"y_pred = ridge_model.predict(x_test)\nnp.sqrt(mean_squared_error(y_test, y_pred)) #RMSE_RIDGE=2.04801379183374","1abd3fa3":"#R2SCORE_RIDGE= 0.001913126743694149\nr2_score(y_test, y_pred)","a57bf700":"lambdalar = 10**np.linspace(10,-2,100)*0.5 \nlambdalar[0:5]","fd44034f":"from sklearn.linear_model import RidgeCV\nridge_cv = RidgeCV(alphas = lambdalar, \n                   scoring = \"neg_mean_squared_error\",\n                   normalize = True)\nridge_cv.fit(x_train, y_train)","bd211a8d":"ridge_cv.alpha_","134b784e":"#RMSE_RIDGE_TUNED=2.048436910707652\nridge_tuned = Ridge(alpha = ridge_cv.alpha_, \n                   normalize = True).fit(x_train,y_train)\nnp.sqrt(mean_squared_error(y_test, ridge_tuned.predict(x_test)))  #icindeki y_pred degeri,ayni sey( ridge_tuned.predict(x_test)=y_pred)","4a9c9a6b":"r2_score(y_test, ridge_tuned.predict(x_test)) #R2SCORE_RIDGE_TUNED=0.0015006754017719004","3a2e5172":"from sklearn.linear_model import Lasso\nlasso_model = Lasso(alpha = 0.1).fit(x_train, y_train)\nlasso_model","086805f6":"lasso_model.coef_","00e92322":"lasso = Lasso()\nlambdalar = 10**np.linspace(10,-2,100)*0.5 \nkatsayilar = []\n\nfor i in lambdalar:\n    lasso.set_params(alpha=i)\n    lasso.fit(x_train, y_train)\n    katsayilar.append(lasso.coef_)\n    \nax = plt.gca()\nax.plot(lambdalar*2, katsayilar)\nax.set_xscale('log')\nplt.axis('tight')\nplt.xlabel('alpha')\nplt.ylabel('weights')","e291eaf5":"lasso_model.predict(x_test)\ny_pred = lasso_model.predict(x_test)\nnp.sqrt(mean_squared_error(y_test, y_pred)) #RMSE_LASSO=2.050443578753031","240992d5":"#R2SCORE_LASSO=-0.00045656143377237335\nr2_score(y_test, y_pred)","526321bd":"from sklearn.linear_model import LassoCV\nlasso_cv_model = LassoCV(alphas = None, \n                         cv = 10, \n                         max_iter = 10000, \n                         normalize = True)\nlasso_cv_model.fit(x_train,y_train)","b834c219":"lasso_cv_model.alpha_","cb52a6d6":"lasso_tuned = Lasso(alpha = lasso_cv_model.alpha_)\nlasso_tuned.fit(x_train, y_train)","d6873c92":"y_pred = lasso_tuned.predict(x_test)\nnp.sqrt(mean_squared_error(y_test, y_pred)) #RMSE_LASSO_TUNED=2.04801384684936","4e1c0e77":"r2_score(y_test, y_pred) #R2_LASSO_TUNED=0.0019130731206485896","f52b37fe":"from sklearn.linear_model import ElasticNet\nenet_model = ElasticNet().fit(x_train, y_train)\nenet_model","3844083d":"enet_model.coef_","3831dd6d":"enet_model.intercept_","e388eaaf":"enet_model.predict(x_test)\ny_pred = enet_model.predict(x_test)\nnp.sqrt(mean_squared_error(y_test, y_pred)) # RMSE_ELASTICNET=2.050443578753031","1ac1df78":"r2_score(y_test, y_pred) # R2SCORE_ELSTICNET=-0.00045656143377237335","48f9692a":"from sklearn.linear_model import ElasticNetCV\nenet_cv_model = ElasticNetCV(cv = 10, random_state = 0).fit(x_train, y_train)\nenet_cv_model","7b6190b1":"enet_cv_model.alpha_","bc8e43d2":"enet_tuned = ElasticNet(alpha = enet_cv_model.alpha_).fit(x_train,y_train)\ny_pred = enet_tuned.predict(x_test)\nnp.sqrt(mean_squared_error(y_test, y_pred)) #RMSE_ELASTICNET_TUNED=2.0480524706030367","ce6fcb02":"# R2SCORE_ELASTICNET_TUNED=0.001875426669009972\nr2_score(y_test, y_pred)","febb8b46":"### EDA","b98da180":"## SKLEARN LIBRARY ","6f25019b":"* We researched 2600,then we obtained that it is Atari.","89a77a5c":"### A ) Test-train splitting","5daca49c":"### A ) Modeling of lasso regression","73934626":"### D ) Model Tuning of multiLinear Regression","6bca6997":"### B ) Prediction of Lasso Regression","a318a3ca":"* We have 11 variables and 16598 observations.","95580c76":"* Counts of year 2017 and 2020 are very few.We will  drop them.","f50b61bd":"## Data contains;\nIn this data set there are 11 columns. Their names and data types as follows:\n\n* Rank - Ranking of overall sales, integer\n\n* Name - The games name, object\n\n* Platform - Platform of the games release (i.e. PC,PS4, etc.), object\n\n* Year - Year of the game's release, float\n\n* Genre - Genre of the game ,object\n\n* Publisher - Publisher of the game\n\n* NA_Sales - Sales in North America (in millions)\n\n* EU_Sales - Sales in Europe (in millions)\n\n* JP_Sales - Sales in Japan (in millions)\n \n* Other_Sales - Sales in the rest of the world (in millions)\n\n* Global_Sales - Total worldwide sales.","99c0f6c5":"### C ) Model Tuning of Ridge regression","4c53d54e":"### NORMALIZATION","df10d852":"## READING DATA , EDA , DATA CLEANING","e7202371":"### B ) Modeling of PCR","c14c2f71":"### C ) Prediction of PCR ","13bd5e3d":"## If you find this kernel helpful, Please UPVOTES !!!","988ab829":"* We have 271 NaN values for Year and 58 NaN values for Publisher.","67dbf20e":"## 3 ) PLS Regression","84ebabb4":" ## 1 ) Multilinear Regression with sklearn","c6c815f8":"## 2 ) PCR\n* Lets see PCR method","40527893":"#### ScatterPlot Matrix shows relationships between top 100 Video Games according to Year, Platform, North America and Europe Sales.","9d2289e7":"### C ) PREDICTION OF MULTI-LINEAR-LEGRESSION","f16df351":"### Visualization of Top 100 Video Games","2e68b972":"## 6 ) ElasticNet Regresyonu","f555e319":"### C ) Model Tuning of Lasso regression","22f089ba":"* Our dependent variable is global sales.We will make predictions through different linear regression models.\n* we need to convert our categorical variables, Platform, Genre and Publisher, into numerical variables and use them in the regression models.Because Regional sales are just the sub-totals of global sales.","354c78b5":"### A ) Test-Train splitting","7ca6f34f":"### B ) Prediction of ElasticNet Regresyonu","cc4b7a7f":"### B ) MODELING OF MULTILINEAR REGGRESSION","9635bba3":"### B ) Prediction of Ridge regression","aa92f6ab":"## MACHINE LEARNING METHODS OF LINEAR REGRESSION\nWE will use \n\n*","cd823b08":"* we can see correlation of global sales between NA,EU,JP,other sales are strong.But high possibly; sum of NA,EU,JP and other sales is equal to global sales","74b18d67":"## Problem Definition\n### Examine the effect of variables on Global_sales.For our prediction,we will use \"linear regression and cousins\" methods...","329da78a":"## CONCLUSION\nWE CAN SEE R2 SCORES AND RMSE OF PREDICTION ALL MODELS\n* R2SCORE_ELASTICNET_TUNED=0.001875426669009972\n* RMSE_ELASTICNET_TUNED=2.0480524706030367\n************************************************\n* R2_LASSO_TUNED=0.0019130731206485896\n* RMSE_LASSO_TUNED=2.04801384684936\n************************************************\n* R2SCORE_RIDGE_TUNED=0.0015006754017719004\n* RMSE_RIDGE_TUNED=2.048436910707652\n************************************************\n* RMSE_PLS_TUNED=2.048013783230342\n* R2SCORE_PLS_TUNED=0.0019131351293203425\n************************************************\n* RMSE_PCR_TUNED=2.0488329468861872\n* R2SCORE_PCR_TUNED=0.0011145467577804435\n************************************************\n* RMSE_MULTI_TUNED=1.75967081759178\n* R2SCORE_MULTI_TUNED=0.0011145467577804435","be6d9f9f":"### A ) Modeling of elasticnet regression","2ca13447":"### B ) Prediction of PLS","14fcee1c":"## SOME OF VISUALIZATION ","ff25f0e3":"### A ) MODELING OF PLS","12bdcd0f":"## 5 ) Lasso Regresyon","44ded893":"### C ) Model Tuning of PLS","946441bc":"### A ) Test-train splittinf of PCR","e8227f2b":"### Statmodels\n* Firstly,lets use statsmodel library to see summary table and other parameters.it is useful for it.","80479663":"### A ) Modeling of ridge regression","fd2d2937":"## 4 ) Ridge Regresyon","36c9535d":"### C ) Model Tuning of ElasticNet Regresyonu","89e0e369":"### D ) Model Tuning of PCR"}}