{"cell_type":{"a1e19247":"code","4aeb4295":"code","01bba90f":"code","77b6633f":"code","2ef585ab":"code","4dbefe84":"code","1c16d05f":"code","f58259e5":"code","793cd8b8":"code","b5a7b713":"code","f1e9eb4b":"code","4073f076":"code","2c2c9eb2":"code","95bf2450":"code","223d9bc0":"code","1f549a08":"code","5516eddf":"code","2ff2dbbc":"code","744d16f3":"code","5ad1893e":"markdown","d6c955ba":"markdown","e3f50c9d":"markdown","8cfb014d":"markdown","546a441b":"markdown","095c4214":"markdown","46b3dc3c":"markdown","0c51bdb6":"markdown","b3745128":"markdown","fd9b05a4":"markdown","cd0572c7":"markdown"},"source":{"a1e19247":"\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","4aeb4295":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","01bba90f":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","77b6633f":"train.head()","2ef585ab":"# labels distribution\nsns.countplot(train[\"label\"])","4dbefe84":"X = train.drop(\"label\", axis = 1)\ny = train[\"label\"]","1c16d05f":"plt.imshow(X.iloc[0].values.reshape(28,28), cmap=\"gray\")","f58259e5":"X = X \/ 255.0\ntest = test \/ 255.0","793cd8b8":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX = X.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","b5a7b713":"from keras.utils.np_utils import to_categorical\nY_train = to_categorical(y, num_classes = 10)","f1e9eb4b":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y_train, test_size = 0.2)","4073f076":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\nmodel.summary()","2c2c9eb2":"from keras.optimizers import RMSprop\nmodel.compile(optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0) , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","95bf2450":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","223d9bc0":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","1f549a08":"history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=28),\n                              epochs = 30, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ 28\n                              , callbacks=[learning_rate_reduction])","5516eddf":"for k in history.history:\n    print (k)","2ff2dbbc":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","744d16f3":"results = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"submission.csv\",index=False)","5ad1893e":"# Reshape","d6c955ba":"# data augumentation","e3f50c9d":"# train test split","8cfb014d":"# Model\nCombining convolutional and pooling layers, CNN are able to combine local features and learn more global features of the image.","546a441b":"https:\/\/www.youtube.com\/watch?v=eBmU1ONJ-os simulated annealing explained","095c4214":"# target","46b3dc3c":"# Evaluation","0c51bdb6":"# Submission","b3745128":"# train","fd9b05a4":"# X and y","cd0572c7":"# normalise"}}