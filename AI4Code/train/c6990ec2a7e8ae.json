{"cell_type":{"f9946ec7":"code","79eadd96":"code","867a3fc5":"code","797a53b3":"code","c845b786":"code","ea836502":"code","7a776579":"code","d12c0838":"code","7cf54944":"code","43c37558":"code","35a213d5":"code","519ec7b2":"code","6f489339":"code","85c205ad":"code","06cfd098":"code","5923dd41":"code","78d55fa9":"code","29f3e136":"code","73a9c456":"code","1e39683f":"code","8be2563b":"code","23f76cf7":"code","71f3fd39":"code","500db3cf":"code","ce95b69a":"code","0761a033":"code","88e70087":"code","b25bdba7":"code","89bce44f":"code","3d5b105b":"code","9191beb1":"markdown","8be5cea4":"markdown","8bc77567":"markdown","ea75a8a0":"markdown","ffad09ce":"markdown","6290145a":"markdown","7f9b61da":"markdown","2172ba55":"markdown","2fe2232c":"markdown","da6de9aa":"markdown","dbc2ca91":"markdown","2a85557e":"markdown","27602229":"markdown","3abdbccc":"markdown","2e9545ae":"markdown"},"source":{"f9946ec7":"import os\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.image as mpimg\nplt.style.use('fivethirtyeight')\nsns.set_style('whitegrid')\n\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\n\nimport sklearn\nfrom sklearn.preprocessing import minmax_scale\n\nimport warnings\nwarnings.filterwarnings('ignore')","79eadd96":"train_folder = '..\/input\/birdsong-recognition\/train_audio'\nbirds = [path for path in os.listdir(os.path.join(train_folder))][-5:]","867a3fc5":"sample_sound = {}\n\nfor i,bird in enumerate(birds):\n    folder = os.path.join(train_folder, bird)\n    for path in os.listdir(os.path.join(folder)):\n        #get 1 sample sound per bird\n        sample_sound[bird] = os.path.join(folder, path)\n        break","797a53b3":"sample_sound","c845b786":"print(birds[0], ' sample sound.')\nipd.Audio(sample_sound[birds[0]])","ea836502":"print(birds[1], ' sample sound.')\nipd.Audio(sample_sound[birds[1]])","7a776579":"print(birds[2], ' sample sound.')\nipd.Audio(sample_sound[birds[2]])","d12c0838":"print(birds[3], ' sample sound.')\nipd.Audio(sample_sound[birds[3]])","7cf54944":"print(birds[4], ' sample sound.')\nipd.Audio(sample_sound[birds[4]])","43c37558":"sound_data = {}\n\nfor i, val in enumerate(sample_sound.values()):\n    y, sr = librosa.load(val)\n    sound_data[birds[i]] = {'y':y, 'sr': sr}","35a213d5":"sound_data","519ec7b2":"for i in range(len(birds)):\n    print('X shape: ', sound_data[birds[i]]['y'].shape)\n    print('Sampling Rate (KHz): ', sound_data[birds[i]]['sr'])\n    print('='*50)","6f489339":"#function to generate random color\ndef gen_color():\n    color = \"%06x\" % random.randint(0, 0xFFFFFF)\n    color = '#'+ color\n    return color","85c205ad":"fig, ax = plt.subplots(len(birds),1,figsize=(14,10))\nplt.tight_layout(3)\n\nfor i in range(len(birds)):\n    librosa.display.waveplot(y = sound_data[birds[i]]['y'],\n                             sr = sound_data[birds[i]]['sr'],\n                             ax = ax[i], color = gen_color())\n    ax[i].set_title(birds[i].capitalize())","06cfd098":"for i in range(len(birds)):\n    #perform a short fourier transform on signal amplitude\n    sound_data[birds[i]]['stft'] = librosa.stft(sound_data[birds[i]]['y'])\n    # convert to db\n    sound_data[birds[i]]['ydb'] = librosa.amplitude_to_db(abs(sound_data[birds[i]]['stft']))","5923dd41":"#show data\nsound_data[birds[1]]","78d55fa9":"fig, ax = plt.subplots(len(birds),1,figsize=(20,15))\nplt.tight_layout(3)\n\nfor i in range(len(birds)):\n    librosa.display.specshow(sound_data[birds[i]]['ydb'],\n                             sr = sound_data[birds[i]]['sr'],\n                             x_axis='time', y_axis='hz',\n                             ax = ax[i])\n    ax[i].set_title(birds[i].capitalize())","29f3e136":"for i in range(len(birds)):\n    sound_data[birds[i]]['zcr'] = librosa.zero_crossings(sound_data[birds[i]]['y'], pad=False).sum()","73a9c456":"for i in range(len(birds)):\n    print(birds[i].capitalize(), 'Zero Crossing Rate: ', sound_data[birds[i]]['zcr'])","1e39683f":"for i in range(len(birds)):\n    sound_data[birds[i]]['spec_c'] = librosa.feature.spectral_centroid(sound_data[birds[i]]['y'], sr= sound_data[birds[i]]['sr'])[0]\n    frames = range(len(sound_data[birds[i]]['spec_c']))\n    sound_data[birds[i]]['t_frame'] = librosa.frames_to_time(frames)","8be2563b":"fig, ax = plt.subplots(len(birds),1,figsize=(14,15))\nplt.tight_layout(3)\n\nfor i in range(len(birds)):\n    librosa.display.waveplot(y = sound_data[birds[i]]['y'],\n                             sr = sound_data[birds[i]]['sr'],\n                             ax = ax[i], color = gen_color())\n    # Normalising the spectral centroid for visualisation\n    ax[i].plot(sound_data[birds[i]]['t_frame'], minmax_scale(sound_data[birds[i]]['spec_c'], axis=0), lw=1)\n    ax[i].set_title(birds[i].capitalize())\n    ax[i].legend(['Spectral Centroid', 'SoundWave'], loc ='upper left');","23f76cf7":"for i in range(len(birds)):\n    sound_data[birds[i]]['spec_r'] = librosa.feature.spectral_rolloff(sound_data[birds[i]]['y'], sr= sound_data[birds[i]]['sr'])[0]\n    frames = range(len(sound_data[birds[i]]['spec_r']))\n    sound_data[birds[i]]['tr_frame'] = librosa.frames_to_time(frames)","71f3fd39":"fig, ax = plt.subplots(len(birds),1,figsize=(14,15))\nplt.tight_layout(3)\n\nfor i in range(len(birds)):\n    librosa.display.waveplot(y = sound_data[birds[i]]['y'],\n                             sr = sound_data[birds[i]]['sr'],\n                             ax = ax[i], color = gen_color())\n    # Normalising the spectral centroid for visualisation\n    ax[i].plot(sound_data[birds[i]]['tr_frame'], minmax_scale(sound_data[birds[i]]['spec_r'], axis=0), lw=1)\n    ax[i].set_title(birds[i].capitalize())\n    ax[i].legend(['Spectral Roll-off', 'SoundWave'], loc ='upper left');","500db3cf":"for i in range(len(birds)):\n    sound_data[birds[i]]['bpm'] = librosa.beat.beat_track(sound_data[birds[i]]['y'], sr=sound_data[birds[i]]['sr'])[0]\n    print(birds[i],' BPM: ',sound_data[birds[i]]['bpm'])","ce95b69a":"for i in range(len(birds)):\n    sound_data[birds[i]]['y_harm'], sound_data[birds[i]]['y_perc'] = librosa.effects.hpss(sound_data[birds[i]]['y'])","0761a033":"fig, ax = plt.subplots(len(birds),1, figsize=(10,15))\nplt.tight_layout(3)\nfor i in range(len(birds)):\n    ax[i].set_title(birds[i].capitalize())\n    ax[i].plot(sound_data[birds[i]]['y_perc'], color= 'steelblue', lw=1);\n    ax[i].plot(sound_data[birds[i]]['y_harm'], color= 'salmon', lw=1);\n","88e70087":"for i in range(len(birds)):\n    base =  sound_data[birds[i]]\n    base['ch_fr'] = librosa.feature.chroma_stft(base['y'], sr = base['sr'])\n    print(birds[i], ' Chromogram Shape: ', base['ch_fr'].shape)","b25bdba7":"fig, ax = plt.subplots(len(birds), 1 , figsize=(10,15))\nplt.tight_layout(3)\n\nfor i in range(len(birds)):\n    ax[i].set_title(birds[i].capitalize())\n    librosa.display.specshow(sound_data[birds[i]]['ch_fr'], x_axis='time', y_axis='chroma', cmap='cividis', ax = ax[i])","89bce44f":"for i in range(len(birds)):\n    base =  sound_data[birds[i]]\n    base['mfcc'] = librosa.feature.mfcc(base['y'], sr = base['sr'])\n    print(birds[i], ' MFCC Shape: ', base['mfcc'].shape)","3d5b105b":"fig, ax = plt.subplots(len(birds), 1 , figsize=(10,15))\nplt.tight_layout(3)\n\nfor i in range(len(birds)):\n    ax[i].set_title(birds[i].capitalize())\n    librosa.display.specshow(sound_data[birds[i]]['mfcc'], x_axis='time', y_axis='log', cmap='viridis', ax = ax[i])","9191beb1":"\n### SPECTOGRAM\n* A spectrogram is a visual representation of the spectrum of frequencies of sound or other signals as they vary with time. It\u2019s a representation of frequencies changing with respect to time for given music signals.","8be5cea4":"### SPECTRAL ROLLOFF\n* Spectral rolloff is the frequency below which a specified percentage of the total spectral energy, e.g. 85%, lies.","8bc77567":"### BPM","ea75a8a0":"*  STFT(Short Time Fourier Transform) converts signal such that we can know the amplitude of given frequency at a given time. Using STFT we can determine the amplitude of various frequencies playing at a given time of an audio signal. ","ffad09ce":"### CHROMA FREQUENCIES\n*  Chroma-based features are a powerful tool for analyzing music whose pitches can be meaningfully categorized (often into twelve categories) and whose tuning approximates to the equal-tempered scale. One main property of chroma features is that they capture harmonic and melodic characteristics of music, while being robust to changes in timbre and instrumentation.","6290145a":"### MFCC\n* The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10\u201320) which concisely describe the overall shape of a spectral envelope.","7f9b61da":"### ZERO CROSSING RATE\n* The zero crossing rate is the rate of sign-changes along a signal, i.e., the rate at which the signal changes from positive to negative or back. This feature has been used heavily in both speech recognition and music information retrieval.","2172ba55":"### LET'S HEAR SOME BIRDS","2fe2232c":"### SPECTRAL CENTROID\n*  If the frequencies in music are same throughout then spectral centroid would be around a centre and if there are high frequencies at the end of sound then the centroid would be towards its end.","da6de9aa":"### INTRODUCTION\n* Extraction of features is a very important part in analyzing and finding relations between different things. The data provided of audio cannot be understood by the models directly to convert them into an understandable format feature extraction is used. It is a process that explains most of the data but in an understandable way. Feature extraction is required for classification, prediction and recommendation algorithms.\n\n### PACKAGES TO BE USED\n* We\u2019ll be using librosa for analyzing and extracting features of an audio signal. For playing audio we will use pyAudio so that we can play music on jupyter directly.","dbc2ca91":"### HARMONICS AND PERCEPTUAL\n\n*  Harmonics - Partial tones that are whole multiples of the fundamental frequency.\n*  Perceptrual shock wave -  Represents the sound rhythm and emotion.","2a85557e":"### FEATURE EXTRACTION AND VISUALIZATION\n---","27602229":"### REFERENCE\n* https:\/\/towardsdatascience.com\/how-to-apply-machine-learning-and-deep-learning-methods-to-audio-analysis-615e286fcbbc\n* https:\/\/en.wikipedia.org","3abdbccc":"### SOUNDWAVES\n* Waveplots let us know the loudness of the audio at a given time.","2e9545ae":"### LOAD THE SAMPLES AND CHECK INFO."}}