{"cell_type":{"7818fd72":"code","e13687c0":"code","84ce753d":"code","8ff31c2f":"code","2fdefdf1":"code","effc2a84":"code","bef5d414":"code","f96108aa":"code","ce44db00":"code","9b71729a":"code","a37a391a":"code","2b8415cd":"code","ee4275f4":"code","05ba77f9":"code","0f12c08f":"code","df865979":"code","dbc2bcc2":"code","3f468b10":"code","2353d228":"code","120d7811":"code","941d03fd":"code","0b35ba0d":"code","4330c6dc":"code","b843f30d":"code","351b1665":"code","3c42f926":"markdown","4f335a93":"markdown","d2fb3add":"markdown","2c11f26a":"markdown","192a3454":"markdown","bdfb41f4":"markdown","9ec7d336":"markdown","c8ad0cf1":"markdown","335d4444":"markdown","2dc0a87e":"markdown","f379c781":"markdown","5ce4fb79":"markdown","22877526":"markdown","91383429":"markdown"},"source":{"7818fd72":"import pandas as pd\nimport numpy as np\nfrom keras.utils import np_utils\nfrom sentiment_module import tokenize_stem\n\ndf = pd.read_csv(\"..\/input\/sentiment-analysis-for-financial-news\/all-data.csv\", header = None, encoding='latin-1', names=[\"Sentiment\", \"Headlines\"])\ndf['Sentiment'] = df['Sentiment'].replace(\"negative\",0).replace(\"neutral\",1).replace(\"positive\",2)\n\ncorpus = []\nfor item in df['Headlines']:\n    corpus.append(tokenize_stem(item))\n\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX = cv.fit_transform(corpus).toarray()\ny = df.iloc[:, 0].values","e13687c0":"print(X.shape)\nprint(y.shape)","84ce753d":"# transform column y to categorical data\ny = np_utils.to_categorical(y, num_classes=3)","8ff31c2f":"# Splitting into training sets and validation sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","2fdefdf1":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding\nfrom keras.utils import np_utils\n\nmodel = Sequential()\nmodel.add(Dense(128, input_dim=(X_train.shape[1]), activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(16, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, epochs=20, batch_size=32)","effc2a84":"model.evaluate(x=X_test, y=y_test, batch_size=None, verbose=1, sample_weight=None)","bef5d414":"from part1_cleaning import get_clean_data\ndf1, df2, df3 = get_clean_data()","f96108aa":"from sentiment_module import tokenize_stem\n\n# Predicting Headlines\ncorpus_hl1 = []\nfor item in df1['Headlines']:\n    corpus_hl1.append(tokenize_stem(item))\npred_hl1 = cv.transform(corpus_hl1).toarray()\ny_pred_hl1 = model.predict(pred_hl1)","ce44db00":"print(y_pred_hl1.shape)\nprint(y_pred_hl1[0:10])","9b71729a":"from sentiment_module import cluster_extraction\n\n# Clustering Headlines\nhl_sentiment = cluster_extraction(y_pred_hl1)\nhl_sentiment[0:10]","a37a391a":"# Predicting Descriptions\/Previews\ncorpus_ds1 = []\nfor item in df1['Description']:\n    corpus_ds1.append(tokenize_stem(item))\npred_ds1 = cv.transform(corpus_ds1).toarray()\ny_pred_ds1 = model.predict(pred_ds1)","2b8415cd":"print(y_pred_ds1.shape)\nprint(y_pred_ds1[0:10])","ee4275f4":"# Clustering Descriptions\/Previews\nds_sentiment = cluster_extraction(y_pred_ds1)\nds_sentiment[0:10]","05ba77f9":"from sentiment_module import combine_sentiments\nann_c_sentiment = combine_sentiments(hl_sentiment, ds_sentiment)\nann_c_sentiment[0:10]","0f12c08f":"# Headlines\ncorpus_hl2 = []\nfor item in df2['Headlines']:\n    corpus_hl2.append(tokenize_stem(item))\npred_hl2 = cv.transform(corpus_hl2).toarray()\ny_pred_hl2 = model.predict(pred_hl2)\nprint(y_pred_hl2.shape)","df865979":"print(y_pred_hl2.shape)\nprint(y_pred_hl2[0:10])","dbc2bcc2":"# Clustering Headlines\nhl_sentiment = cluster_extraction(y_pred_hl2)\nhl_sentiment[0:10]","3f468b10":"# Descriptions\/Previews\ncorpus_ds2 = []\nfor item in df2['Description']:\n    corpus_ds2.append(tokenize_stem(item))\npred_ds2 = cv.transform(corpus_ds2).toarray()\ny_pred_ds2 = model.predict(pred_ds2)\nprint(y_pred_ds2.shape)","2353d228":"print(y_pred_ds2.shape)\nprint(y_pred_ds2[0:10])","120d7811":"# Clustering Descriptions\/Previews\nds_sentiment = cluster_extraction(y_pred_ds2)\nds_sentiment[0:10]","941d03fd":"from sentiment_module import combine_sentiments\nann_r_sentiment = combine_sentiments(hl_sentiment, ds_sentiment)\nann_r_sentiment[0:10]","0b35ba0d":"# Headlines\ncorpus_hl3 = []\nfor item in df3['Headlines']:\n    corpus_hl3.append(tokenize_stem(item))\npred_hl3 = cv.transform(corpus_hl3).toarray()\ny_pred_hl3 = model.predict(pred_hl3)\nprint(y_pred_hl3.shape)","4330c6dc":"print(y_pred_hl3.shape)\nprint(y_pred_hl3[0:10])","b843f30d":"# Clustering Headlines\nhl_sentiment = cluster_extraction(y_pred_hl3)\nhl_sentiment[0:10]","351b1665":"# The Guardian's headline sentiment is the only variavle dictate the sentiment of the Guardian's articles\nann_g_sentiment = hl_sentiment","3c42f926":"## The Guardian Headlines and Previews","4f335a93":"# Fitting the model to generate sentiment predictions","d2fb3add":"## CNBC Headlines and Previews","2c11f26a":"# Sentiment Prediction Using Deep Learning - Artificial Neural Network","192a3454":"## Import data","bdfb41f4":"Finally, to determine the sentiment of the article, I am going to evaluate based on both the sentiment of the headline as well as the sentiment of the preview. Firstly, if at least at least 1 out of 2 (headline and preview) is positive and the other isnt negative, the article is assigned as positive. Secondly, if the 2 are both neutral or one is negative, the other is positive and vice versa, the article is assigned as neutral. Thirdly, if at least 1 out of 2 (headline and preview) is negative and the other isnt positive, the article is assigned as negative.","9ec7d336":"## Reuters Headlines and Previews","c8ad0cf1":"Similar to CNBC data, I am going to evaluate each article's sentiment based on both the sentiment of its headline as well as the sentiment of its preview.","335d4444":"### Combining","2dc0a87e":"### Predicting","f379c781":"# Create an Artificial Neural Network","5ce4fb79":"In this section, I want to create a Artificial Neural Network (ANN), train, and test it on a dataset retrieved from https:\/\/www.kaggle.com\/ankurzing\/sentiment-analysis-for-financial-news\/kernels. This ANN will then fitted to the all 3 given datasets (CNBC, Reuters, and the Guardian) to evaluate whether the headline\/preview is positive, neutral, or negative.","22877526":"### Combining","91383429":"### Predicting"}}