{"cell_type":{"a1477f48":"code","0aca91c8":"code","e8bd4cd8":"code","e846b9e0":"code","5c935af6":"code","3806f0e2":"code","ab3df1d0":"code","3cc6f984":"code","5369855b":"code","9d6e8407":"code","75ce56bd":"code","3fac4f13":"code","36a675ea":"code","2d938dab":"code","cf819712":"code","a45c5d24":"code","ccfcfc2f":"code","72d4fd9a":"code","c28d9397":"code","c5269b0e":"code","3354b916":"code","b1c8332c":"code","49349965":"code","43253913":"code","24507dbd":"code","ef11ed37":"code","8d1303ea":"code","3e4dc86c":"code","16cadd54":"code","d8999096":"code","7e703c44":"code","9605ba47":"code","ca9a8209":"code","d9a75f36":"code","0b438f7e":"code","20c2d668":"code","b668f494":"code","17804c1e":"code","6c83e271":"code","e9e69c80":"code","45da6bb7":"code","df04bc64":"code","a0305d0d":"code","aca01377":"code","af1243b5":"code","acf0d780":"code","a6493a04":"code","988ba2f6":"code","e55939f5":"code","3438a2f0":"code","57fc946b":"code","7c0628e4":"code","625a73f3":"code","66af5763":"code","ad43df82":"code","950873ab":"code","256df8dc":"code","ff39589a":"code","aa5c34d3":"code","540c1d3f":"code","323026f8":"code","687f7595":"code","1fba423e":"code","beabc3a3":"code","7da27a29":"code","18264bff":"code","c8c87987":"code","f28b02c4":"code","80154a60":"code","6f67fde3":"code","32b0b693":"code","05c9ba33":"code","16e48ca9":"code","cad7cb1b":"code","81a4a5a2":"code","4af56690":"code","943d85f8":"code","97eb813e":"markdown","0d2ae7ef":"markdown","81a28e11":"markdown","d606d3a9":"markdown","911915a3":"markdown","ddc0b9ae":"markdown","4185b5e8":"markdown","4046a182":"markdown","00673c75":"markdown","866a6e9f":"markdown","59fb8e35":"markdown","52a0f5ab":"markdown","88c33e47":"markdown","3fadcb25":"markdown","e74827a1":"markdown","38837eef":"markdown","d7b5289e":"markdown","e15595be":"markdown","8b4cf317":"markdown","e5c5f94d":"markdown","50e7ea5e":"markdown","5bd37c00":"markdown","74ff7df9":"markdown","5e5638a1":"markdown","1eb5fcd6":"markdown","d5cdfa96":"markdown","d7a1f889":"markdown","4d85b0d4":"markdown","e08a8d82":"markdown","b2bfed38":"markdown","73e0c161":"markdown","93f33706":"markdown","c8009181":"markdown","c367d3cf":"markdown","4a4a3d44":"markdown","307daffa":"markdown","84faadab":"markdown","3ad50f62":"markdown","1c815b2a":"markdown"},"source":{"a1477f48":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nfrom pandasql import sqldf\nfrom imblearn.over_sampling import SMOTE\nimport scipy.stats as stats\nfrom tabulate import tabulate\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_tree\nfrom xgboost import plot_importance\n\n# import packages for hyperparameters tuning\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nimport hyperopt.pyll\nfrom hyperopt.pyll import scope\nfrom hpsklearn import HyperoptEstimator\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import plot_tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\n\nfrom category_encoders.ordinal import OrdinalEncoder\nfrom category_encoders.binary import BinaryEncoder\nfrom category_encoders.one_hot import OneHotEncoder\n","0aca91c8":"df = pd.read_csv('..\/input\/vehicle-claim-fraud-detection\/fraud_oracle.csv')\nprint('The data constain ', len(df),' observations.')\ndf.head()","e8bd4cd8":"df.dtypes","e846b9e0":"#Tried using the loop below to check for unique values, it appears that all features are being \n#interpreted as series data. Haven't figured out how to pull values from series. \n#I resorted to printing each individually and inspecting the results.\n\n#for i in df.columns:\n#    print(i)\n#    print(' ')\n#    print('Unique values of {}'.format(i), df[str(i)].unique)\n    \nprint('Month',df['Month'].unique())\nprint('WeekOfMonth',df['WeekOfMonth'].unique())\nprint('DayOfWeek',df['DayOfWeek'].unique())\nprint('Make',df['Make'].unique())\nprint('AccidentArea',df['AccidentArea'].unique())\nprint('DayOfWeekClaimed',df['DayOfWeekClaimed'].unique())\nprint('MonthClaimed',df['MonthClaimed'].unique())\nprint('WeekOfMonthClaimed',df['WeekOfMonthClaimed'].unique())\nprint('Sex',df['Sex'].unique())\nprint('MaritalStatus',df['MaritalStatus'].unique())\nprint('Age',df['Age'].unique())\nprint('Fault',df['Fault'].unique())\nprint('PolicyType',df['PolicyType'].unique())\nprint('VehicleCategory',df['VehicleCategory'].unique())\nprint('VehiclePrice',df['VehiclePrice'].unique())\nprint('FraudFound_P',df['FraudFound_P'].unique())\nprint('PolicyNumber',df['PolicyNumber'].unique())\nprint('RepNumber',df['RepNumber'].unique())\nprint('Deductible',df['Deductible'].unique())\nprint('DriverRating',df['DriverRating'].unique())\nprint('Days_Policy_Accident', df['Days_Policy_Accident'].unique())\nprint('Days_Policy_Claim',df['Days_Policy_Claim'].unique())\nprint('PastNumberOfClaims',df['PastNumberOfClaims'].unique())\nprint('AgeOfVehicle',df['AgeOfVehicle'].unique())\nprint('AgeOfPolicyHolder',df['AgeOfPolicyHolder'].unique())\nprint('PoliceReportFiled',df['PoliceReportFiled'].unique())\nprint('WitnessPresent',df['WitnessPresent'].unique())\nprint('AgentType',df['AgentType'].unique())\nprint('NumberOfSuppliments',df['NumberOfSuppliments'].unique())\nprint('AddressChange_Claim',df['AddressChange_Claim'].unique())\nprint('NumberOfCars',df['NumberOfCars'].unique())\nprint('Year',df['Year'].unique())\nprint('BasePolicy',df['BasePolicy'].unique())","5c935af6":"print(df['PolicyNumber'].sum())\nprint((len(df['PolicyNumber'])*(len(df['PolicyNumber']) +1 ))\/2 )\ndf['PolicyNumber']","3806f0e2":"#Investigate the 0 in DayOfWeekClaimed and MonthClaimed\nprint('DayOfWeekClaimed has ', len(df.loc[(df['DayOfWeekClaimed']=='0')]), ' row(s) with a 0')\nprint('MonthClaimed has ',len(df.loc[(df['MonthClaimed']=='0')]),' row(s) with a 0') \nprint(' ')\n\n#We see there is only one row where either the DayOfWeekClaimed or MonthClaimed are 0. \n#So now we compare them.\nprint(df.loc[(df['DayOfWeekClaimed']=='0')])\nprint(df.loc[(df['MonthClaimed']=='0')])\n\n# Both are zero in the same row (row 1516). ","ab3df1d0":"#Since both DayOfWeekClaimed and MonthClaimed are 0 for the same entry, I will drop\ndf2 = df.loc[df['DayOfWeekClaimed']!='0']","3cc6f984":"#Resets the index on our new dataframe, df2, so we can iterate through the rows\n#If we didn't do this, attempting to access df2.loc[1516] would throw a keyerror\n#This suggests that df2 does not have a row 1516, which is just plain silly\ndf2.reset_index(drop=True, inplace=True)\nlen(df2)","5369855b":"#There are 319 rows where the feature Age is assigned a zero, \nprint(len(df2[df2['Age']==0]))\n\n#though for the displayed rows the policy holder is said to be between 16 and 17 years old. \ndf2.loc[df2['Age']==0, 'AgeOfPolicyHolder']\n\n#Need to check the policy holders age and then reassign a value.\ndf2_age0_idx = (df2['Age']==0)\n","9d6e8407":"#confirms that every row with Age=0, has a Policy Holder that is aged between 16 and 17 years.\ndf2.loc[(df2['Age']==0),'AgeOfPolicyHolder'].unique()","75ce56bd":"#splits the AgeOfPolicyHolder column into substrings so we\n#can check that the age variable is in range for policyholder\n\ngroupings = []\nfor holder in df2['AgeOfPolicyHolder']:\n    if 'to' in holder :\n        temp = holder.split()\n        nr=[int(temp[0]),int(temp[2])]\n        groupings.append(nr)\n    else :\n        temp = holder.split()\n        nr = [int(temp[1]),129]\n        groupings.append(nr)\n                        ","3fac4f13":"#does the comparision of value for age to the value of the AgeOfPolicyHolder\nage_idx = []\nrw_idx = []\nfor r in range(len(df2['Age'])):\n    if (df2.loc[r,'Age']>= groupings[r][0]) & (df2.loc[r,'Age']<= groupings[r][1]):\n        age_idx.append(0)\n    else:\n        age_idx.append(1)\n        rw_idx.append(r)","36a675ea":"print(len(df2.loc[list(rw_idx),('Age','AgeOfPolicyHolder')]))\ndf2.loc[list(rw_idx),('Age','AgeOfPolicyHolder')].head()","2d938dab":"#Assigns an age of 16 to all rows with missing Age values\ndf2.loc[list(df2_age0_idx),'Age']=16.5","cf819712":"#Confirms that there are no Ages equal to 0.\nprint(df2['Age'].unique()==0)\nlen(df2[df2['Age']==0])","a45c5d24":"#Since the length of the df2 is the same as the df2.drop_duplicates, this tells us\n#there are no duplicate rows\nprint(len(df2.drop_duplicates())==len(df2))","ccfcfc2f":"df2_chi_result=[]\nfor feat in df2.columns:\n    chi2_val, p_val, dof2, ex1 = stats.chi2_contingency(pd.crosstab(df2[feat], df2['FraudFound_P']))\n    df2_chi_result.append([feat,chi2_val,p_val])\n    \nchi_df = pd.DataFrame(df2_chi_result, columns=['Features', 'Chi2 val', 'p-val'])\nchi_df.sort_values(by='p-val',ascending=True, inplace=True)    \n#Printing on the variables that had a p-val less than 0.05\nprint(tabulate(chi_df[chi_df['p-val']<0.05], headers=['Feature', 'Chi2 val', 'p-val']))","72d4fd9a":"#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('PolicyType').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('PolicyType').agg('count').reset_index()\n\nfig, (ax1,ax2) = plt.subplots(2,1,figsize=(22, 6))\nsns.barplot(x='PolicyType', y='FraudFound_P', data = gpd_val1, ax=ax1)\nsns.barplot(x='PolicyType', y='FraudFound_P', data=gpd_val2, ax=ax2)\n\nax2.set(ylabel='Total counts')\n\nNone\n\ntotal_list = pd.concat([gpd_val1, gpd_val2['FraudFound_P'].rename('Total Accidents')],axis=1)\ntotal_list['Percentage by PolicyType']= round((total_list['FraudFound_P']\/total_list['Total Accidents'])*100,3)\ntotal_list['Percentage by Total'] = round((total_list['FraudFound_P']\/sum(total_list['Total Accidents']))*100,3)\n\nax2.set(ylabel='Total counts')\n\ndata = [['Column total'],\n        [sum(total_list['FraudFound_P'])], \n        [sum(total_list['Total Accidents'])], \n        [sum(total_list['Percentage by PolicyType'])], \n        [sum(total_list['Percentage by Total'])]]\n\nnr = pd.DataFrame(data)\n\nnr1 = nr.transpose()\nnr1.rename(columns={0:'PolicyType',1:'FraudFound_P',2:'Total Accidents',3:'Percentage by PolicyType',4:'Percentage by Total'}, inplace=True)\npd.concat([total_list,nr1],ignore_index=True)\n","c28d9397":"#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('VehicleCategory').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val6=df2.groupby('VehicleCategory').agg('count').reset_index()\ngpd_val3=df2.groupby('BasePolicy').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val7=df2.groupby('BasePolicy').agg('count').reset_index()\n\nfig, (ax1, ax3) = plt.subplots(1,2,figsize=(22, 6))\nsns.barplot(x='VehicleCategory', y='FraudFound_P', data = gpd_val1, ax=ax1)\n#sns.barplot(x='VehicleCategory', y='FraudFound_P', data = gpd_val2, ax=ax2)\nsns.barplot(x='BasePolicy', y='FraudFound_P', data = gpd_val3, ax=ax3)\n#sns.barplot(x='BasePolicy', y='FraudFound_P', data = gpd_val4, ax=ax4)\nNone\n\n\ntotal_list1 = pd.concat([gpd_val1, gpd_val6['FraudFound_P'].rename('Total Accidents')],axis=1)\ntotal_list1['Percentage by VehicleCategory']= round((total_list1['FraudFound_P']\/total_list1['Total Accidents'])*100,3)\ntotal_list1['Percentage by Total'] = round((total_list1['FraudFound_P']\/sum(total_list1['Total Accidents']))*100,3)\n\ntotal_list2 = pd.concat([gpd_val3, gpd_val7['FraudFound_P'].rename('Total Accidents')],axis=1)\ntotal_list2['Percentage by BasePolicy']= round((total_list2['FraudFound_P']\/total_list2['Total Accidents'])*100,3)\ntotal_list2['Percentage by Total'] = round((total_list2['FraudFound_P']\/sum(total_list2['Total Accidents']))*100,3)\n\ndata1 = [['Column total'],\n        [sum(total_list1['FraudFound_P'])], \n        [sum(total_list1['Total Accidents'])], \n        [sum(total_list1['Percentage by VehicleCategory'])], \n        [sum(total_list1['Percentage by Total'])]]\n\ndata2 = [['Column total'],\n        [sum(total_list2['FraudFound_P'])], \n        [sum(total_list2['Total Accidents'])], \n        [sum(total_list2['Percentage by BasePolicy'])], \n        [sum(total_list2['Percentage by Total'])]]\n\nnr1 = pd.DataFrame(data1)\nnr1 = nr1.transpose()\nnr1.rename(columns={0:'VehicleCategory',1:'FraudFound_P',2:'Total Accidents',3:'Percentage by VehicleCategory',4:'Percentage by Total'}, inplace=True)\ntl1=pd.concat([total_list1,nr1],ignore_index=True)\n\nnr2 = pd.DataFrame(data2)\nnr2 = nr2.transpose()\nnr2.rename(columns={0:'BasePolicy',1:'FraudFound_P',2:'Total Accidents',3:'Percentage by BasePolicy',4:'Percentage by Total'}, inplace=True)\ntl2=pd.concat([total_list2,nr2],ignore_index=True)\n\nprint(tabulate(tl1, headers=tl1.columns))\nprint(' ')\nprint(tabulate(tl2, headers=tl2.columns))\n\n","c5269b0e":"#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('Fault').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('Deductible').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val3=df2.groupby('AddressChange_Claim').agg({'FraudFound_P':'sum'}).reset_index()\n\ngpd_valc1=df2.groupby('Fault').agg('count').reset_index()\ngpd_valc2=df2.groupby('Deductible').agg('count').reset_index()\ngpd_valc3=df2.groupby('AddressChange_Claim').agg('count').reset_index()\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(22, 6))\nsns.barplot(x='Fault', y='FraudFound_P', data = gpd_val1, ax=ax1)\nsns.barplot(x='Deductible', y='FraudFound_P', data = gpd_val2, ax=ax3)\nsns.barplot(x='AddressChange_Claim', y='FraudFound_P', data = gpd_val3, ax=ax2)\n\npart_list=[gpd_val1, gpd_val2, gpd_val3]\ncounts_lst=[gpd_valc1,gpd_valc2,gpd_valc3]\nsrch_gp=['Fault','Deductible','AddressChange_Claim']\ntotal_list=[]\nfor i in range(len(counts_lst)):\n    temp1 = counts_lst[i]\n    gby=srch_gp[i]\n    temp2=  pd.concat([part_list[i], temp1['FraudFound_P'].rename('Total Accidents')],axis=1) \n    temp2['Percentage by {}'.format(gby)]= round((temp2['FraudFound_P']\/temp2['Total Accidents'])*100,3)\n    temp2['Percentage by Total'] = round((temp2['FraudFound_P']\/sum(temp2['Total Accidents']))*100,3)\n    \n    temp3 = [['Column total'],\n        [sum(temp2['FraudFound_P'])], \n        [sum(temp2['Total Accidents'])], \n        [sum(temp2['Percentage by {}'.format(gby)])], \n        [sum(temp2['Percentage by Total'])]]\n\n    nr1 = pd.DataFrame(temp3)\n    nr1 = nr1.transpose()\n    nr1.rename(columns={0:'{}'.format(gby),1:'FraudFound_P',2:'Total Accidents',3:'Percentage by {}'.format(gby),4:'Percentage by Total'}, inplace=True)\n    total_list.append(pd.concat([temp2,nr1],ignore_index=True))\n\nfor ii in range(len(total_list)):\n    print(tabulate(total_list[ii], headers=total_list[ii].columns))\n    print(' ')","3354b916":"#VehiclePrice, PastNumberOfClaims, MonthCalimed\ngpd_val1=df2.groupby('VehiclePrice').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('PastNumberOfClaims').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val3=df2.groupby('MonthClaimed').agg({'FraudFound_P':'sum'}).reset_index()\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(22, 6))\ngrph1=sns.barplot(x='VehiclePrice', y='FraudFound_P', data = gpd_val1, ax=ax1)\nsns.barplot(x='PastNumberOfClaims', y='FraudFound_P', data = gpd_val2, ax=ax2)\nsns.barplot(x='MonthClaimed', y='FraudFound_P', data = gpd_val3, ax=ax3)\n\ngrph1.set_xticklabels(grph1.get_xticklabels(),\n                    rotation=45,\n                    horizontalalignment='right'\n                    )\nNone","b1c8332c":"#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('Make').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('Make').agg('count').reset_index()\n\nfig, (ax1,ax2) = plt.subplots(2,1,figsize=(22, 6))\nsns.barplot(x='Make', y='FraudFound_P', data = gpd_val1,ax=ax1)\nsns.barplot(x='Make', y='FraudFound_P', data = gpd_val2,ax=ax2)\n\ntotal_list = pd.concat([gpd_val1, gpd_val2['FraudFound_P'].rename('Total Accidents')],axis=1)\ntotal_list['Percentage by Make']= round((total_list['FraudFound_P']\/total_list['Total Accidents'])*100,3)\ntotal_list['Percentage by Total'] = round((total_list['FraudFound_P']\/sum(total_list['Total Accidents']))*100,3)\n\nax2.set(ylabel='Total counts')\n\ndata = [['Column total'],\n        [sum(total_list['FraudFound_P'])], \n        [sum(total_list['Total Accidents'])], \n        [sum(total_list['Percentage by Make'])], \n        [sum(total_list['Percentage by Total'])]]\n\nnr = pd.DataFrame(data)\n\nnr1 = nr.transpose()\nnr1.rename(columns={0:'Make',1:'FraudFound_P',2:'Total Accidents',3:'Percentage by Make',4:'Percentage by Total'}, inplace=True)\npd.concat([total_list,nr1],ignore_index=True)\n                   \n#print(tabulate(total_list, headers=total_list.columns))\n                   \n                   ","49349965":"#AccidentArea, AgeOfPolicyHolder, Sex\ngpd_val1=df2.groupby('AccidentArea').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('AgeOfPolicyHolder').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val3=df2.groupby('Sex').agg({'FraudFound_P':'sum'}).reset_index()\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(22, 6))\nsns.barplot(x='AccidentArea', y='FraudFound_P', data = gpd_val1, ax=ax1)\ngrph2 = sns.barplot(x='AgeOfPolicyHolder', y='FraudFound_P', data = gpd_val2, ax=ax2)\nsns.barplot(x='Sex', y='FraudFound_P', data = gpd_val3, ax=ax3)\n\ngrph2.set_xticklabels(grph2.get_xticklabels(),\n                    rotation=45,\n                    horizontalalignment='right'\n                    )\nNone","43253913":"#NumberOfSuppliements, Month, AgeOfVehicle\ngpd_val1=df2.groupby('NumberOfSuppliments').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('Month').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val3=df2.groupby('AgeOfVehicle').agg({'FraudFound_P':'sum'}).reset_index()\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(22, 6))\nsns.barplot(x='NumberOfSuppliments', y='FraudFound_P', data = gpd_val1, ax=ax1)\nsns.barplot(x='Month', y='FraudFound_P', data = gpd_val2, ax=ax2)\ngrph1 = sns.barplot(x='AgeOfVehicle', y='FraudFound_P', data = gpd_val3, ax=ax3)\n\ngrph1.set_xticklabels(grph1.get_xticklabels(),\n                    rotation=45,\n                    horizontalalignment='right'\n                    )\nNone","24507dbd":"#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('Age').agg({'FraudFound_P':'sum'}).reset_index()\nprint(gpd_val1['FraudFound_P'].sum())\n\nfig, (ax1) = plt.subplots(1,1,figsize=(22, 8))\ngrph1=sns.barplot(x='Age', y='FraudFound_P', data = gpd_val1, ax=ax1)\n\ngrph1.set_xticklabels(grph1.get_xticklabels(),\n                    rotation=45,\n                    horizontalalignment='right'\n                    )\nNone","ef11ed37":"#AgentType, Year, Days_Policy_Accident\n#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('AgentType').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('Year').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val3=df2.groupby('Days_Policy_Accident').agg({'FraudFound_P':'sum'}).reset_index()\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(22, 6))\nsns.barplot(x='AgentType', y='FraudFound_P', data = gpd_val1, ax=ax1)\nsns.barplot(x='Year', y='FraudFound_P', data = gpd_val2, ax=ax2)\nsns.barplot(x='Days_Policy_Accident', y='FraudFound_P', data = gpd_val3, ax=ax3)","8d1303ea":"#PoliceReportFiled, Days_Policy_Claim, DayOfWeek\n#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('PoliceReportFiled').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('Days_Policy_Claim').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val3=df2.groupby('DayOfWeek').agg({'FraudFound_P':'sum'}).reset_index()\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(22, 6))\nsns.barplot(x='PoliceReportFiled', y='FraudFound_P', data = gpd_val1, ax=ax1)\nsns.barplot(x='Days_Policy_Claim', y='FraudFound_P', data = gpd_val2, ax=ax2)\nsns.barplot(x='DayOfWeek', y='FraudFound_P', data = gpd_val3, ax=ax3)","3e4dc86c":"#WitnessPresent, WeekOfMonthClaimed, DayOfWeekClaimed\n#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('WitnessPresent').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('WeekOfMonthClaimed').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val3=df2.groupby('DayOfWeekClaimed').agg({'FraudFound_P':'sum'}).reset_index()\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(22, 6))\nsns.barplot(x='WitnessPresent', y='FraudFound_P', data = gpd_val1, ax=ax1)\nsns.barplot(x='WeekOfMonthClaimed', y='FraudFound_P', data = gpd_val2, ax=ax2)\nsns.barplot(x='DayOfWeekClaimed', y='FraudFound_P', data = gpd_val3, ax=ax3)","16cadd54":"#DriverRating, WeekOfMonth, NumberOfCars\n#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('DriverRating').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val2=df2.groupby('WeekOfMonth').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_val3=df2.groupby('NumberOfCars').agg({'FraudFound_P':'sum'}).reset_index()\n\n\nfig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(22, 6))\nsns.barplot(x='DriverRating', y='FraudFound_P', data = gpd_val1, ax=ax1)\nsns.barplot(x='WeekOfMonth', y='FraudFound_P', data = gpd_val2, ax=ax2)\nsns.barplot(x='NumberOfCars', y='FraudFound_P', data = gpd_val3, ax=ax3)","d8999096":"#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val2=df2.groupby('RepNumber').agg({'FraudFound_P':'sum'}).reset_index()\ngpd_valt2=df2.groupby('RepNumber').agg({'FraudFound_P':'sum'}).reset_index()\n\nfig, (ax2) = plt.subplots(1,1,figsize=(22, 6))\nsns.barplot(x='RepNumber', y='FraudFound_P', data = gpd_val2, ax=ax2)","7e703c44":"#plotting by FraudFound, looking to see if there are anything obvious that correlates to fraud\ngpd_val1=df2.groupby('MaritalStatus').agg({'FraudFound_P':'sum'}).reset_index()\n#gpd_val2=df2.groupby('MaritalStatus').agg('count').reset_index()\n\nfig, (ax1) = plt.subplots(1,1,figsize=(12, 6))\nsns.barplot(x='MaritalStatus', y='FraudFound_P', data = gpd_val1, ax=ax1)\n#sns.barplot(x='MaritalStatus', y='FraudFound_P', data = gpd_val2, ax=ax2)\n","9605ba47":"X=df2.drop('FraudFound_P',axis=1).copy()\ny=df2['FraudFound_P'].copy()","ca9a8209":"cols = ['AccidentArea', 'Sex', 'Fault', 'PoliceReportFiled', 'WitnessPresent', 'AgentType']\ny_val = ['Urban','Female','Policy Holder', 'Yes', 'Yes','External']\nx_val = ['Rural', 'Male', 'Third Party', 'No', 'No', 'Internal']\n\nfor i in range(len(cols)):\n    X_idx1 = X[cols[i]]==y_val[i]\n    X_idx2 = X[cols[i]]==x_val[i]\n\n    X.loc[list(X_idx1),cols[i]]=1\n    X.loc[list(X_idx2),cols[i]]=0","d9a75f36":"for i in range(len(cols)):\n    X[cols[i]] = X[cols[i]].astype('int')","0b438f7e":"X.dtypes","20c2d668":"col_ordering = [{'col':'Month','mapping':{'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}},\n    {'col':'DayOfWeek','mapping':{'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6,'Sunday':7}},\n    {'col':'DayOfWeekClaimed','mapping':{'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6,'Sunday':7}},\n    {'col':'MonthClaimed','mapping':{'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}},\n    {'col':'PastNumberOfClaims','mapping':{'none':0 ,'1':1,'2 to 4':2,'more than 4':5 }},\n    {'col':'NumberOfSuppliments','mapping':{'none':0,'1 to 2':1,'3 to 5':3,'more than 5':6}}, \n    {'col':'VehiclePrice','mapping':{'more than 69000':69001,'20000 to 29000':24500,'30000 to 39000':34500,'less than 20000':19999,\n                                     '40000 to 59000':49500,'60000 to 69000':64500}},\n    {'col':'AgeOfVehicle','mapping':{'3 years':3,'6 years':6,'7 years':7,'more than 7':8,'5 years':5,'new':0,'4 years':4,'2 years':2}},\n]\nord_encoder = OrdinalEncoder(mapping = col_ordering, return_df=True)","b668f494":"X2 = ord_encoder.fit_transform(X)","17804c1e":"col_map = [{'Days_Policy_Accident':{'more than 30':31,'15 to 30':22.5,'none':0,'1 to 7':4,'8 to 15':11.5}},\n    {'Days_Policy_Claim':{'more than 30':31,'15 to 30':22.5,'8 to 15':11.5,'none':0}},\n    {'AgeOfPolicyHolder':{'26 to 30':28,'31 to 35':33,'41 to 50':45.5,'51 to 65':58,'21 to 25':23,'36 to 40':38,'16 to 17':16.5,\n                                          'over 65':66,'18 to 20':19}},\n    {'AddressChange_Claim':{'1 year':1,'no change':0,'4 to 8 years':6,'2 to 3 years':2.5,'under 6 months':0.5}},\n    {'NumberOfCars':{'3 to 4':3.5,'1 vehicle':1,'2 vehicles':2,'5 to 8':6.5,'more than 8':9}},\n]\n\nX3 = X2.copy()\nfor i in range(len(col_map)):\n    X3.replace(col_map[i], inplace=True)","6c83e271":"X3.dtypes","e9e69c80":"#implementing one-hot encoding\none_hot_encoder = OneHotEncoder(cols = ['Make','MaritalStatus','PolicyType','VehicleCategory','BasePolicy'],use_cat_names=True, return_df=True) \n\n#implementing label encoding, with random assignment of integers to each label\n# assumes no natrual underlying order to the feature labels\nord_encoder1 = OrdinalEncoder(cols = ['Make','MaritalStatus','PolicyType','VehicleCategory','BasePolicy'],return_df=True)\n\n#implementing binary encoding\n#represents the data \nbi_encoder = BinaryEncoder(cols = ['Make','MaritalStatus','PolicyType','VehicleCategory','BasePolicy'], return_df=True)\n","45da6bb7":"#implimented a simple switch to change how I wanted to encode the variables\n#Allowed for a updating the independet variables quickly and not missing a code box\n\nswitch_val = 0\nif switch_val ==0:\n    X4 = one_hot_encoder.fit_transform(X3)\nelif switch_val==1:\n    X4 = ord_encoder1.fit_transform(X3)\nelse:\n    X4 = bi_encoder.fit_transform(X3)\n","df04bc64":"X4.dtypes\n","a0305d0d":"chi_result=[]\nfor feat in X4.columns:\n    chi2, p, dof, ex = stats.chi2_contingency(pd.crosstab(X4[feat], y))\n    chi_result.append([feat,chi2,p])\n\nch_df = pd.DataFrame(chi_result, columns=['Feature', 'Chi2 val', 'p-val'])\nch_df.sort_values(by=['p-val'], inplace=True)\n\nprint(tabulate(ch_df, headers=['Feature', 'Chi2 val', 'p-val']))","aca01377":"tempy_x4 = pd.DataFrame(X4.corrwith(y,axis=0 ).sort_values(ascending=False))\nprint(tabulate(tempy_x4, headers=['Feature', 'Pearson Correlation']))\n","af1243b5":"#X5 = X4.drop(columns=['VehicleCategory','BasePolicy'])\n#X5.dtypes","acf0d780":"#this code takes our data after cleaning and splits it into the testing set and training set\n\nX_train, X_test, y_train, y_test = train_test_split(X4, y,stratify=y, random_state=42)\nclf_dt_m1 = DecisionTreeClassifier(random_state=42)\nclf_dt1 = clf_dt_m1.fit(X_train, y_train)\n","a6493a04":"y_pred_gini = clf_dt1.predict(X_test)\n\nprint('Gini stats')\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_gini))\nprint(\"balanced_accuracy:\",metrics.balanced_accuracy_score(y_test, y_pred_gini))\nprint(\"brier_score_loss:\",metrics.brier_score_loss(y_test, y_pred_gini))\nprint(\"f1_score:\",metrics.f1_score(y_test,y_pred_gini))\nprint(\"recall_score:\",metrics.recall_score(y_test, y_pred_gini))\nprint(\"precision_score:\",metrics.precision_score(y_test, y_pred_gini))\nprint(\"roc_auc_score:\",metrics.roc_auc_score(y_test, y_pred_gini))\n","988ba2f6":"precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred_gini)\n\n#this code plots the confusion matrix of our niave implementation of a decision tree\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\nfig.tight_layout(pad=5.0)\nmetrics.plot_confusion_matrix(clf_dt1, X_test, y_test, display_labels=[\"Not Fraudulent Claim\", \"Fraudulent Claim\"], ax=ax1)\ntn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred_gini).ravel()\n\nax2.step(recall, precision, color='b', alpha=0.2, where='post')\nax2.fill_between(recall, precision, step='post', alpha=0.2, color='b')\nax2.set_xlabel('Recall')\nax2.set_ylabel('Precision')\nax2.set_ylim([0.0, 1.05])\nax2.set_xlim([-0.005, 1.0])\nax2.set_title('Precision-Recall curve:')\n\n\nprint('True Negatives:', tn)\nprint('False Postives:', fp)\nprint('False Negatives:', fn)\nprint('True Positive:', tp)\nprint('Recall:', tp\/(fn+tp))\nprint('Precision:', tp\/(fp+tp))\nprint('Prevalence:', (fn+tp)\/(tn+fp+fn+tp))","e55939f5":"important_tree_features = clf_dt1.feature_importances_\n\nindices = np.argsort(important_tree_features)\n\nfig, ax = plt.subplots(figsize=(15, 18))\nax.barh(range(len(important_tree_features)), important_tree_features[indices])\nax.set_yticks(range(len(important_tree_features)))\n_ = ax.set_yticklabels(np.array(X_train.columns)[indices])","3438a2f0":"classifiers = {\n    'DecisionTreeClassifier': DecisionTreeClassifier(),\n    'RandomForestClassifier': RandomForestClassifier(),\n    'AdaBoostClassifier': AdaBoostClassifier(),\n    \"XGBClassifier\": XGBClassifier(use_label_encoder=False, objective= 'binary:logistic',eval_metric='aucpr'),\n}","57fc946b":"df_models = pd.DataFrame(columns = ['model', \n                                    'run_time', \n                                    'avg_accy',\n                                    'avg_accy_std',  \n                                    'avg_recall',\n                                    'avg_recall_std',\n                                    'avg_precision',\n                                    'avg_precision_std',\n                                    'avg_f1',\n                                    'avg_f1_std',\n                                    'avg_matthew_corcoef',\n                                    'avg_matthew_corcoef_std',\n                                    'avg_roc_auc',\n                                    'avg_roc_auc_std', \n                                     ])\n\n\nscorer = {'accuracy_score':metrics.make_scorer(metrics.accuracy_score),\n          'f1_score':metrics.make_scorer(metrics.f1_score),\n          'recall_score':metrics.make_scorer(metrics.recall_score),\n          'precision_score':metrics.make_scorer(metrics.average_precision_score),\n          'matthew_corrcoef':metrics.make_scorer(metrics.matthews_corrcoef),\n          'roc_auc_score':metrics.make_scorer(metrics.roc_auc_score) \n         }\n\nfor key in classifiers:\n    print('*', key)\n    start_time = time.time()\n    classifier = classifiers[key]\n    model = classifier.fit(X_train,y_train)\n    cvs = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n    cv_scores = cross_validate(model, X_test, y_test, cv=cvs, scoring = scorer)\n    y_pred = model.predict(X_test)\n    \n    row = {\n        'model': key,\n        'run_time': format(round((time.time() - start_time)\/60,2)),\n        'avg_accy': cv_scores['test_accuracy_score'].mean(),\n        'avg_accy_std': cv_scores['test_accuracy_score'].std(),\n        'avg_recall': cv_scores['test_recall_score'].mean(),\n        'avg_recall_std': cv_scores['test_recall_score'].std(),\n        'avg_precision': cv_scores['test_precision_score'].mean(),\n        'avg_precision_std': cv_scores['test_precision_score'].std(),\n        'avg_f1': cv_scores['test_f1_score'].mean(),\n        'avg_f1_std': cv_scores['test_f1_score'].std(),\n        'avg_matthew_corcoef': cv_scores['test_matthew_corrcoef'].mean(),\n        'avg_matthew_corcoef_std': cv_scores['test_matthew_corrcoef'].std(),\n        'avg_roc_auc': cv_scores['test_roc_auc_score'].mean(),\n        'avg_roc_auc_std': cv_scores['test_roc_auc_score'].std(),\n    }\n    \n    df_models = df_models.append(row, ignore_index=True)\n    ","7c0628e4":"df_models.head()","625a73f3":"sm = SMOTE(random_state=42)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n\nprint(y_train.value_counts())\nprint(y_train_res.value_counts())","66af5763":"df_models_smote = pd.DataFrame(columns = ['model', \n                                    'run_time', \n                                    'avg_accy',\n                                    'avg_accy_std',  \n                                    'avg_recall',\n                                    'avg_recall_std',\n                                    'avg_precision',\n                                    'avg_precision_std',\n                                    'avg_f1',\n                                    'avg_f1_std',\n                                    'avg_matthew_corcoef',\n                                    'avg_matthew_corcoef_std',\n                                    'avg_roc_auc',\n                                    'avg_roc_auc_std', \n                                     ])\n\n\nscorer = {'accuracy_score':metrics.make_scorer(metrics.accuracy_score),\n          'f1_score':metrics.make_scorer(metrics.f1_score),\n          'recall_score':metrics.make_scorer(metrics.recall_score),\n          'precision_score':metrics.make_scorer(metrics.precision_score),\n          'matthew_corrcoef':metrics.make_scorer(metrics.matthews_corrcoef),\n          'roc_auc_score':metrics.make_scorer(metrics.roc_auc_score) \n         }\n\nfor key in classifiers:\n    print('*', key)\n    start_time = time.time()\n    classifier = classifiers[key]\n    model = classifier.fit(X_train_res,y_train_res)     #<--- pass the SMOTE generate training data set\n    #scorer = metrics.make_scorer(metrics.recall_score)\n    #cv_scores = cross_val_score(model, X_test, y_test, cv=5, scoring=scorer)\n    cvs = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n    cv_scores = cross_validate(model, X_test, y_test, cv=cvs, scoring = scorer)   #<--- tested the SMOTE trained model on original testing data\n    y_pred = model.predict(X_test)\n    \n    #print(model.get_params())\n    \n    row = {\n        'model': key,\n        'run_time': format(round((time.time() - start_time)\/60,2)),\n        'avg_accy': cv_scores['test_accuracy_score'].mean(),\n        'avg_accy_std': cv_scores['test_accuracy_score'].std(),\n        'avg_recall': cv_scores['test_recall_score'].mean(),\n        'avg_recall_std': cv_scores['test_recall_score'].std(),\n        'avg_precision': cv_scores['test_precision_score'].mean(),\n        'avg_precision_std': cv_scores['test_precision_score'].std(),\n        'avg_f1': cv_scores['test_f1_score'].mean(),\n        'avg_f1_std': cv_scores['test_f1_score'].std(),\n        'avg_matthew_corcoef': cv_scores['test_matthew_corrcoef'].mean(),\n        'avg_matthew_corcoef_std': cv_scores['test_matthew_corrcoef'].std(),\n        'avg_roc_auc': cv_scores['test_roc_auc_score'].mean(),\n        'avg_roc_auc_std': cv_scores['test_roc_auc_score'].std(),\n    }\n    \n    df_models_smote = df_models_smote.append(row, ignore_index=True)","ad43df82":"df_models.head()\n","950873ab":"df_models_smote.head()","256df8dc":"space={\n    'objective': 'binary:logistic',\n    #objective= 'binary:logistic', \n    'use_label_encoder': False,\n    #use_label_encoder= False, \n    'base_score': 0.5,\n    #base_score= 0.5, \n    'booster': 'gbtree',\n    #booster= 'gbtree', \n    'colsample_bylevel' : 1,\n    #colsample_bylevel= 1, \n    'colsample_bynode' : 1,\n    #colsample_bynode= 1, \n    'colsample_bytree' : 1,\n    #colsample_bytree= 1, \n    'enable_categorical': False,\n    #enable_categorical= False, \n    'gamma': hp.uniform('gamma', 0,10),\n    #gamma= 0, \n    'gpu_id': -1,\n    #gpu_id= -1,\n    'importance_type': None,\n    #importance_type= None, \n    'interaction_constraints': '',\n    #interaction_constraints= '', \n    'learning_rate': 0.300000012,\n    #learning_rate= 0.300000012, \n    'max_delta_step': 0,\n    #max_delta_step= 0, \n    'max_depth': hp.randint(\"max_depth\", 10)+3,\n    #max_depth= 6, \n    'min_child_weight' : hp.randint('min_child_weight', 4)+1,\n    #min_child_weight= 1, \n    #missing= 'nan', \n    'monotone_constraints': '()',\n    #monotone_constraints= '()',\n    'n_estimators': hp.randint('n_estimators', 150)+50,\n    #n_estimators= 100, \n    'n_jobs': 4,\n    #n_jobs= 4, \n    'num_parallel_tree':1,\n    #num_parallel_tree= 1, \n    'predictor':'auto',\n    #predictor= 'auto', \n    'random_state': 0,\n    #random_state= 0, \n    'reg_alpha' : hp.randint('reg_alpha', 10),\n    #reg_alpha= 0, \n    'reg_lambda' : hp.randint('reg_lambda', 10),\n    #reg_lambda= 1, \n    'scale_pos_weight': 1,\n    #scale_pos_weight= 1, \n    'subsample': 1,\n    #subsample= 1, \n    'tree_method': 'exact',\n    #tree_method= 'exact', \n    'validate_parameters':1,\n    #validate_parameters= 1, \n    'verbosity': None,\n    #verbosity= None, \n    'eval_metric': 'aucpr'\n    #eval_metric= 'aucpr'\n    }\n","ff39589a":"high_roc_scores = {}\n#model_num = 0\n\ndef objective(space):\n    #model_num +=1\n    clf_model=XGBClassifier(**space)\n    fitted_model=clf_model.fit(X_train, y_train)\n    pred = fitted_model.predict(X_test)\n    \n    tn, fp, fn, tp = metrics.confusion_matrix(y_test, pred).ravel()\n    accuracy = metrics.accuracy_score(y_test, pred)\n    precision = metrics.precision_score(y_test, pred)\n    recall = metrics.recall_score(y_test, pred)\n    f1 = metrics.f1_score(y_test,pred)\n    matthew_corrcoef = metrics.matthews_corrcoef(y_test,pred),\n    roc_auc = metrics.roc_auc_score(y_test,pred)\n    avg_precision = metrics.average_precision_score(y_test, pred)\n    \n    rows = {'model': ' XGBClassifier',\n        'tp': [tp],\n        'tn': [tn],\n        'fp': [fp],\n        'fn': [fn],\n        'accuracy': [round(accuracy,3)],\n        'precision': [round(precision,3)],\n        'recall':[ round(recall,3)],\n        'f1': [round(f1,3)],\n        'matthews_coef': [round(matthew_corrcoef[0],3)],\n        'roc_auc': [round(roc_auc,3)],\n        'avg_pre': [round(avg_precision,3)],\n    }\n     \n    score_vals = pd.DataFrame(rows)\n    print(tabulate(score_vals, headers=score_vals.columns))\n    print(' ')\n    if round(roc_auc,3)>0.7:\n        high_roc_scores['Trial_model_{}'.format(time.time())]= [fitted_model.get_params(), score_vals]\n        print(' ')\n        print(fitted_model.get_params())\n        print(' ')\n        print(' ')\n        print(' ')\n    \n    return {'loss': -roc_auc, 'status': STATUS_OK }","aa5c34d3":"trials=Trials()\nbest_hyperparams = fmin(fn = objective,\n                        space = space,\n                        algo = tpe.suggest,\n                        max_evals = 100,\n                       trials=trials)","540c1d3f":"print(\"The best hyperparameters are : \",\"\\n\")\nprint(best_hyperparams)\n\nprint(\"Record best are:\", \"\\n\")\nprint(high_roc_scores)","323026f8":"clf_optimal = XGBClassifier(\n    objective= 'binary:logistic', \n    use_label_encoder= False, \n    base_score= 0.5, \n    booster= 'gbtree', \n    colsample_bylevel= 1, \n    colsample_bynode= 1, \n    colsample_bytree= 1, \n    enable_categorical= False, \n    gamma= best_hyperparams['gamma'], \n    gpu_id= -1, \n    importance_type= None, \n    interaction_constraints= '', \n    learning_rate= 0.300000012, \n    max_delta_step= 0, \n    max_depth= best_hyperparams['max_depth'], \n    min_child_weight= best_hyperparams['min_child_weight'], \n   # missing= 'nan', \n    monotone_constraints= '()',\n    n_estimators= best_hyperparams['n_estimators'], \n    n_jobs= 4, \n    num_parallel_tree= 1, \n    predictor= 'auto', \n    random_state= 0, \n    reg_alpha= best_hyperparams['reg_alpha'], \n    reg_lambda= best_hyperparams['reg_lambda'], \n    scale_pos_weight= 1, \n    subsample= 1, \n    tree_method= 'exact', \n    validate_parameters= 1, \n    verbosity= None, \n    eval_metric= 'aucpr'\n)","687f7595":"print(clf_optimal.get_params())","1fba423e":"\nstart_time = time.time()\noptimal_model = clf_optimal.fit(X_train,y_train)\n\n# set random_state = 42\n#The idea was, if I have the optimal parameters, then using the same cross-validation state as during my initial testing\n#should produce far better results.... it didn't   :**(\n\ncvs = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\ncv_scores = cross_validate(optimal_model, X_test, y_test, cv=cvs, scoring = scorer)\ny_pred_optimal = optimal_model.predict(X_test)\n\nrow2 = {'model': ['Optimized XGBClassifier'],\n       'run_time': [format(round((time.time() - start_time)\/60,2))],\n       'avg_accy': [cv_scores['test_accuracy_score'].mean()],\n       #'avg_accy_std': cv_scores['test_accuracy_score'].std(),\n       'avg_recall': [cv_scores['test_recall_score'].mean()],\n       #'avg_recall_std': cv_scores['test_recall_score'].std(),\n       'avg_precision': [cv_scores['test_precision_score'].mean()],\n       #'avg_precision_std': cv_scores['test_precision_score'].std(),\n       'avg_f1': [cv_scores['test_f1_score'].mean()],\n       #'avg_f1_std': cv_scores['test_f1_score'].std(),\n       'avg_matthew_corcoef': [cv_scores['test_matthew_corrcoef'].mean()],\n       #'avg_matthew_corcoef_std': cv_scores['test_matthew_corrcoef'].std(),\n       'avg_roc_auc':[ cv_scores['test_roc_auc_score'].mean()],\n       #'avg_roc_auc_std': cv_scores['test_roc_auc_score'].std(),\n      }\n \nscores2 = pd.DataFrame(row2)\nprint(tabulate(scores2, headers=scores2.columns))\n#df_models = df_models.append(row, ignore_index=True)","beabc3a3":"scores3 = scores2.copy()\nr_idx = df_models.loc[df_models['model'] =='XGBClassifier']\nscores3.append(r_idx[scores2.columns])\n#r_idx2 = df_models_smote.loc[df_models['model'] =='XGBClassifier']\n#scores3.append(r_idx2[scores2.columns])\n","7da27a29":"cv_scores","18264bff":"cv_idx =list(range(len(cv_scores['fit_time'])))\n\nfig = plt.figure()\nfig.set_figwidth(15)\nfig.set_figheight(6)\nfor test_score in cv_scores.keys():\n    if (test_score !='fit_time') & (test_score !='score_time'):\n        plt.plot(cv_idx, cv_scores[test_score], label='{}'.format(test_score))\n    \nplt.legend(loc='upper right')","c8c87987":"tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred_optimal).ravel()\naccuracy = metrics.accuracy_score(y_test, y_pred_optimal)\nprecision = metrics.precision_score(y_test, y_pred_optimal)\nrecall = metrics.recall_score(y_test, y_pred_optimal)\nf1 = metrics.f1_score(y_test,y_pred_optimal)\nmatthew_corrcoef = metrics.matthews_corrcoef(y_test,y_pred_optimal),\nroc_auc = metrics.roc_auc_score(y_test,y_pred_optimal)\navg_precision = metrics.average_precision_score(y_test, y_pred_optimal)\n\nrow3 = {'model': 'Optimized XGB-No SMOTE',\n        'tp': [tp],\n        'tn': [tn],\n        'fp': [fp],\n        'fn': [fn],\n        'correct': [tp+tn],\n        'incorrect': [fp+fn],\n        'accuracy': [round(accuracy,3)],\n        'precision': [round(precision,3)],\n        'recall': [round(recall,3)],\n        'f1': [round(f1,3)],\n        'matthews_coef': [round(matthew_corrcoef[0],3)],\n        'roc_auc': [round(roc_auc,3)],\n        'avg_pre': [round(avg_precision,3)],\n    }\n\nscores3 = pd.DataFrame(row3)\nprint(tabulate(scores3, headers=scores3.columns))\n\n","f28b02c4":"for key in cv_scores.keys():\n    print('key {}:score {}'.format(key,cv_scores[key][-1] ))","80154a60":"high_roc_scores","6f67fde3":"potential_opt_params = pd.DataFrame(columns = ['gamma', \n                                              'max_depth', \n                                              'min_child_weight',\n                                              'n_estimators', \n                                              'reg_alpha', \n                                              'reg_lambda',\n                                              'precision',\n                                              'recall',\n                                              'f1',\n                                              'matthews_coef',\n                                              'roc_auc'])\n\nrow_idx = 0\nfor key in high_roc_scores.keys():\n    param_dict = high_roc_scores[key]\n    #print(key)\n    \n    temp1 = param_dict[0]\n    temp2 = param_dict[1]\n    for param in potential_opt_params.columns:\n        if param in temp1.keys():\n            potential_opt_params.at[row_idx, param] = temp1[param]\n        elif param in temp2.columns:\n            potential_opt_params.at[row_idx, param] = temp2[param]\n    \n    row_idx = row_idx + 1\n\n    \n#sort value isnt working at the moment returns the following error\n# \n#The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n\n#potential_opt_params.sort_values('roc_auc',axis = 0,ascending=False, inplace=True)\nprint(tabulate(potential_opt_params, headers=potential_opt_params.columns))","32b0b693":"#not sortin\npotential_opt_params.iloc[0]['gamma']","05c9ba33":"clf_optimal2 = XGBClassifier(\n    objective= 'binary:logistic', \n    use_label_encoder= False, \n    base_score= 0.5, \n    booster= 'gbtree', \n    colsample_bylevel= 1, \n    colsample_bynode= 1, \n    colsample_bytree= 1, \n    enable_categorical= False, \n    gamma= potential_opt_params.iloc[0]['gamma'], \n    gpu_id= -1, \n    importance_type= None, \n    interaction_constraints= '', \n    learning_rate= 0.300000012, \n    max_delta_step= 0, \n    max_depth= potential_opt_params.iloc[0]['max_depth'], \n    min_child_weight= potential_opt_params.iloc[0]['min_child_weight'], \n   # missing= 'nan', \n    monotone_constraints= '()',\n    n_estimators= potential_opt_params.iloc[0]['n_estimators'], \n    n_jobs= 4, \n    num_parallel_tree= 1, \n    predictor= 'auto', \n    random_state= 0, \n    reg_alpha= potential_opt_params.iloc[0]['reg_alpha'], \n    reg_lambda= potential_opt_params.iloc[0]['reg_lambda'], \n    scale_pos_weight= 1, \n    subsample= 1, \n    tree_method= 'exact', \n    validate_parameters= 1, \n    verbosity= None, \n    eval_metric= 'aucpr'\n)","16e48ca9":"\nstart_time = time.time()\noptimal_model2 = clf_optimal2.fit(X_train,y_train)\n\n# set random_state = 42\n#The idea was, if I have the optimal parameters, then using the same cross-validation state as during my initial testing\n#should produce far better results.... it didn't   :**(\n\ncvs = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\ncv_scores2 = cross_validate(optimal_model2, X_test, y_test, cv=cvs, scoring = scorer)\ny_pred_optimal2 = optimal_model2.predict(X_test)\n\nrow4 = {'model': ['Optimized XGBClassifier'],\n       'run_time': [format(round((time.time() - start_time)\/60,2))],\n       'avg_accy': [cv_scores2['test_accuracy_score'].mean()],\n       #'avg_accy_std': cv_scores2['test_accuracy_score'].std(),\n       'avg_recall': [cv_scores2['test_recall_score'].mean()],\n       #'avg_recall_std': cv_scores2['test_recall_score'].std(),\n       'avg_precision': [cv_scores2['test_precision_score'].mean()],\n       #'avg_precision_std': cv_scores2['test_precision_score'].std(),\n       'avg_f1': [cv_scores2['test_f1_score'].mean()],\n       #'avg_f1_std': cv_scores2['test_f1_score'].std(),\n       'avg_matthew_corcoef': [cv_scores2['test_matthew_corrcoef'].mean()],\n       #'avg_matthew_corcoef_std': cv_scores2['test_matthew_corrcoef'].std(),\n       'avg_roc_auc':[ cv_scores2['test_roc_auc_score'].mean()],\n       #'avg_roc_auc_std': cv_scores2['test_roc_auc_score'].std(),\n      }\n \nscores4 = pd.DataFrame(row4)\nprint(tabulate(scores4, headers=scores4.columns))\n#df_models = df_models.append(row, ignore_index=True)","cad7cb1b":"tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred_optimal2).ravel()\naccuracy = metrics.accuracy_score(y_test, y_pred_optimal2)\nprecision = metrics.precision_score(y_test, y_pred_optimal2)\nrecall = metrics.recall_score(y_test, y_pred_optimal2)\nf1 = metrics.f1_score(y_test,y_pred_optimal2)\nmatthew_corrcoef = metrics.matthews_corrcoef(y_test,y_pred_optimal2),\nroc_auc = metrics.roc_auc_score(y_test,y_pred_optimal2)\navg_precision = metrics.average_precision_score(y_test, y_pred_optimal2)\n\nrow5 = {'model': 'Optimized XGB-No SMOTE',\n        'tp': [tp],\n        'tn': [tn],\n        'fp': [fp],\n        'fn': [fn],\n        'correct': [tp+tn],\n        'incorrect': [fp+fn],\n        'accuracy': [round(accuracy,3)],\n        'precision': [round(precision,3)],\n        'recall': [round(recall,3)],\n        'f1': [round(f1,3)],\n        'matthews_coef': [round(matthew_corrcoef[0],3)],\n        'roc_auc': [round(roc_auc,3)],\n        'avg_pre': [round(avg_precision,3)],\n    }\n\nscores5 = pd.DataFrame(row3)\nprint(tabulate(scores5, headers=scores5.columns))","81a4a5a2":"precision_opt2, recall_opt2, thresholds = metrics.precision_recall_curve(y_test, y_pred_optimal2)\n\n#this code plots the confusion matrix of our niave implementation of a decision tree\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\nfig.tight_layout(pad=5.0)\nmetrics.plot_confusion_matrix(optimal_model2, X_test, y_test, display_labels=[\"Not Fraudulent Claim\", \"Fraudulent Claim\"], ax=ax1)\ntn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred_optimal2).ravel()\n\nax2.step(recall_opt2, precision_opt2, color='b', alpha=0.2, where='post')\nax2.fill_between(recall_opt2, precision_opt2, step='post', alpha=0.2, color='b')\nax2.set_xlabel('Recall')\nax2.set_ylabel('Precision')\nax2.set_ylim([0.0, 1.05])\nax2.set_xlim([-0.005, 1.0])\nax2.set_title('Precision-Recall curve:')","4af56690":"plot_importance(optimal_model2, max_num_features=15)\n\n","943d85f8":"#fig, ax = plt.subplots(figsize=(30, 30))\n#plot_tree(optimal_model, num_trees=0, ax=ax)\n#plt.show()","97eb813e":"Need to convert the following features to a numeric.\n* Make\n* MaritalStatus\n* PolicyType\n\nI am currently looking into the best way to encode this features. For the time being I am simply using One-hot encoding.\n","0d2ae7ef":"To get a feel for the challenge we face and how the dataset behaves, I decided to implement a basic Decision Tree.","81a28e11":"# **PART 1 & 2:** Importing the libraries and data","d606d3a9":"Looking at the above metrics, it is clear that our tree is having trouble identifying the true positves (recall score of .372). This led me to the decision try applying some ensemble and boosting methods to get better results.","911915a3":"# **PART 7:** Encoding the data.   \n       ","ddc0b9ae":"The process of getting the hyperparameters tuned was a long fight for me. I found lots of blog posts and code that 'demonstrated' how to do it, but either part of the code or all of the code didn't work or made no sense. I am firm believer that there are no magic bullets, so if I find code that 'works' but makes no sense in how it generates the results I assume it is useless. \n\nMy first attempt I used GridSearchCV to work the parameter space but took a god-awful amount of time (based on https:\/\/machinelearningmastery.com\/hyperparameters-for-classification-machine-learning-algorithms\/). I very quickly abandonded that idea and went search for a better\/faster method. I came across the following article, (https:\/\/blog.cambridgespark.com\/hyperparameter-tuning-in-xgboost-4ff9100a3b2f), and the method actually work very fast, but I didn't understand why\/how it worked and when I went to compare the results to the previous methods I had difficulty extracting the optimal parameters for a separate verification using XGBClassifier (as opposed to using dmatrix and xgb). \n\nAfter further searching and reading I came across two articles which lead me to Hyperopt and is what the following code is based on. The first being the most helpful, strongly recommend anyone interested to read through it.\n* https:\/\/www.kaggle.com\/prashant111\/a-guide-on-xgboost-hyperparameters-tuning \n* https:\/\/machinelearningmastery.com\/hyperopt-for-automated-machine-learning-with-scikit-learn\/\n\nBelow I created the parameter space for my XGBClassifier. There were inconsistencies in results so I opted to explicitly define all the parameters that XGBClassifier takes.\n","4185b5e8":"We have handled the 0 in the 'DayOfWeekClaimed' and 'MonthClaimed', next we need to investigate the 'Age' of 0.","4046a182":"Applied SMOTE to the training data and confirmed the new train set has an equal distribution of target feature.","00673c75":"Next we convert the following features to be numeric, we will use ordinal encoder from catergory_encoders.ordinal (I discovered that this produces an intger encoding even if I specified a float with an explicit mapping. To get around this I used the replace() method to encode the features I needed as floats).\n* Month\n* DayOfWeek\n* DayOfWeekClaimed\n* MonthClaimed\n* PastNumberOfClaims\n* NumberOfSuppliments\n* VehiclePrice\n* Day_Policy_Accident\n* Days_Policy_Claim\n* AgeOfVehicle\n* AgeOfPolicyHolder\n* AddressChange_Claim\n* NumberOfCars\n","866a6e9f":"# **PART 5:** Further investigation for insights - possible features\n\nThe goal here is to gather some insight into the relationship between our observations and the desired predicted feature, 'FraudFound_P'.","59fb8e35":"# **PART 9:** Comparing Decision Trees, Random Forest, AdaBoost, and XGBoost","52a0f5ab":"# **PART 6:** Splitting data into dependent and independent variables.\n\nWe split the data into the dependent feature ('FraudFound_P') and the independent features (everything else).","88c33e47":"We now take care of the 0 in the 'MonthClaimed' and 'DayOfWeekClaimed' features, then we tackle the 'Age' of 0 problem.","3fadcb25":"This is where I noticed there was an issue. Comparing the results of using the optimal parameters to our previous results we notice a difference in the metric values. I set the cross_validation random state to be the same as our original cross-validation, so we can test the optimal parameters against the original. We would expect better results from using the optimized values or at least similar, since we are training on the same cross-validation random_state. I did not see this behavior in any of my runs.","e74827a1":"# **PART 11:** Tuning the hyperparameters of XGBoost","38837eef":"Next I checked the metrics based on the comparison of the y_test data set and the predicted results (y_pred_optimal). The y_pred_optimal should have been the last prediction from the cross-validation run and match the last entries in cv_cores. Looking below, it is clear they are not.\n\nNeed to look further into why this is happening, there is likely a random state that isn't set properly that needs to be adjusted to attain consistency.","d7b5289e":"Now we repeat the tests from before and compare results.","e15595be":"In graph you can see the different scores across all of the cross-validation runs. It was clear that for no single run did we achieve a score compariable to the best observed during the optimization process. This tells us the fmin function isn't optimizing the same metric we were looking at. So either we figure out how to change the metric or we come up with a different. I chose the later since reading through the documentation proved fruitless (if you know how to change the metric I would appreciate the secret).","8b4cf317":"First, we will look into the 'PolicyNumber'. As mentioned above, I suspect that the 'PolicyNumber' is simply the row number minus 1. I check this by summing the policy numbers, and then using the summation identity: sum(i)(for i to n) = n(n+1)\/2, where I take n to be the number of rows. If they come out the same then there are no missing or duplicate PolicyNumbers.","e5c5f94d":"We have taken care of missing values in Age, DayOfWeekClaimed, and MonthClaimed.\nNext, we will convert the following features to 1's and 0's.\n* AccidentArea:        \n    * 1=Urban,         0=Rural\n* Sex:\n    * 1=Female,        0=Male\n* Fault: \n    * 1=Policy Holder, 0=Third Party\n* PoliceReportFiled: \n    * 1=Yes,           0=No\n* WitnessPresent: \n    * 1=Yes,           0=No\n* AgentType:   \n    * 1=External       0=Internal","50e7ea5e":"Looking over the two results, we can see that using SMOTE with the DecisionTreeClassifier resulted in a similar F1 score as to the non-SMOTE model (during testing I have seen both a slight increase and decrease in performance, which is expected since we randomly selecting the dataset during the cross-validation process). The ensemble methods showed no change in the F1 score or Matthew Correlation Coefficient. This is where I decided to continue bulding a model using the XGBClassifier because of the consistency of the F1 score and Matthew Correlation Coefficient.","5bd37c00":"# **Issues in data to investigate first**\n* DayOfWeekClaimed - contains a 0 instead of a day of the week\n* MonthClaimed - contains a 0 instead of the month\n* Age - contains a 0 instead of the necessary age\n* PolicyType - appears to be a concatenation of VehicleCategory and BasePolicy\n* PolicyNumber - determine if they are the same as the row number minus 1\n\n# **Thoughts\/questions to look into**\n* Are representatives fixed to a specific geographic region? \n    * i.e. will rep 1 always be rural vs urban?\n* Are they fixed as always being internal or external?\n    * i.e. would rep 1 always be considered internal vs external?\n* Should 'Age' always fall in the range of 'AgeOfPolicyHolder'?\n* PolicyType appears to contain the same information as VehicleCategroy and BasePolicy\n    * Should they match? Do they always match?\n    * Can we eliminate one or two of these features?\n* Is a driver rated as 1 better or worse of a driver rated as a 4? Or is it a measure of Risk? Meaning a driver rated at 1 is at a higher risk of an accident than driver rated at 4?\n* Are certain Months\/Days of the week more prone to accidents than others?\n","74ff7df9":"# **PART 4:** Reworking the data - missing values, dropping duplicates, etc.\n\n","5e5638a1":"# **PART 3:** Initial Investigation of the data\nI decided to look at unique values within the data as a fast way to identify any missing or interesting values.","1eb5fcd6":"# **PART 8:** Build preliminary classification tree\n","d5cdfa96":"# Classifying Fraud by Decision Trees\n\n\nTable of Contents:\n1. Importing the libraries and modules\n2. Importing the data\n3. Initial investigation the data\n4. Reworking the data - missing values, dropping duplicates, etc.\n5. Further investigation for insights - possible features\n6. Splitting data into dependent and independent variables\n7. Enoding the data\n8. Build preliminary classification tree\n9. Comparing Decision Trees, Random Forest, AdaBoost, and XGBoost\n10. Comparing DT, RF, Ada, XGB with SMOTE\n11. Tuning the hyperparameters of XGBoost\n12. Building, evaluating, drawing, and interpretation of final classification model\n\n**This is a work in progress. I am currently working through parts 8-11 and will need to add a new section on feature selection between part 8 and 9.**","d7a1f889":"Comparing the different methods and metrics we see that the Decision Tree Classifier and XGBClassifier were the most successful, judged by the average F1 score and Matthew Correlation Coefficient from the 10-fold cross-validation. Of the four methods tested the DecisionTreeClassifier and XGBClassifier are the top candidates for our model.\n\nA common recommendation online for improving performance is to over-sample the minorty class or under-sample the majority class or both. In the next experiment I retest the four methods with a training set on which I applied the SMOTE algorithm. Perhaps this would change the results and we would see a clear winner from one of the methods.","4d85b0d4":"I established that hyperopt wasn't optimizing on  our desired metric, and I was unable to sort out how to change that metric. So I decided to store all parameters from the hyperopt search where the calculated roc_auc was greater than 0.7. From here the thought was, if I can get these values that are satsifying the threshold value then I can pull the parameters that generated the largest roc_auc (or whatever your desired metric is). All of these values were saved to the dictionary high_roc_scores.","e08a8d82":"Sorting on the desired metric (roc_auc in this case), we can grab the parameters that did generate the largest value.","b2bfed38":"# **PART 10:** Comparing DT, RF, Ada, XGB with SMOTE","73e0c161":"The results of our nieve implementation of a Decision tree has return underwhelming results in terms of identifying fraud cases. ","93f33706":"During our investigation of the feature 'Age' being set to 0, we have established that there are 7241 rows out 15419, which is roughly 46.96% of the data, who's 'Age' does not correspond to the age range for 'AgeOfPolicyHolder'. A discrepancy this prevalent feels unlikely to be a typo. A somewhat reasonable assumption, is that the individual driving at the time of the accident was not the policy holder, but another individual.\n\nThis doesn't give us any clear indication on the direction to go. Therefore I will opt to replace the 0 with the mean value of the interval.","c8009181":"We could assign a value to 'Age' in one of the following ways\n1. We could assign based on the lowest value in the range\n2. We could assign based on the highest value in the range\n3. We could assign based on the mean value in the range\n4. We could drop all of those rows\n\nTo make this decision I felt it would best to investigate the relationship between 'Age' and 'AgeOfPolicyHolder' first. (Though my initial instinct is to replace with the mean of the range.","c367d3cf":"# **PART 12:** Building, evaluating, drawing, and interpretation of final classification model","4a4a3d44":"During testing I noticed that the method isn't actually pulling the optimal parameters. Or at least what I would judge the optimal parameters to be, based on the output of the function (see below). I have looked that the documentation (http:\/\/hyperopt.github.io\/hyperopt\/) to try and find how to change the metric fmin is judging the best result by, but was unsucceful. So I created the dictionary to store the parameters of all sample runs which had a roc_auc score greater than 0.70 and printed to screen the parameters of those test runs. This would allow for visual verification\/ comparision of the \"optimal\" values.","307daffa":"When I used the optimized parameters I received an average F1 score, Matthew Correlation Coefficient and ROC AUC different from those printed during the testing. So we need to investigate. My first thought was that since I am taking the mean of the scores, perhaps I have some values that are pulling the score down. After print the scores from the cross-validation runs (see below) it is clear that is not the case, something else is going on. ","84faadab":"# **Data Dictionary (at first glance)**\nResults of printing the unique values from each feature. Things I noticed about each feature.\n1. **Month** - object\n    * contains 3 letter abbreviations for the months of the year \n    * Are these the months in which the accident occured?\n2. **WeekOfMonth** - int64\n    * provides the week in the month the accident occured?\n3. **DayOfWeek** - object\n    * contains days of the week - are these the days of the week the accident occured on?\n4. **Make** - object\n    * contains a list of 19 car manufacturers\n5. **AccidentArea** - object\n    * classifies area for accident as \"Urban\" or \"Rural\"\n6. **DayOfWeekClaimed** - object\n    * contains the day of the week the claim was filed\n    * also contains '0' - need to check how many of these there are and see about \"fixing\" - missing data?\n7. **MonthClaimed** - object\n    * contains 3 letter abbreviations for the months of the year \n    * contains '0' - need to check how many there are and what they mean - missing data?\n8. **WeekOfMonthClaimed** - int64\n    * contains weeks in the month that the claimed in filed\n9. **Sex** - object\n    * gender of individual making claim?\n    * binary data, convert to 1 or 0\n10. **MaritalStatus** - object\n    * marital status of individual making claim?\n11. **Age** - int64\n    * ages of individual making claim?\n    * there is at least one individual with age 0 - missing data?\n12. **Fault** - object\n    * categorization of who was deemed at fault.\n    * convert to binary, 1 or 0\n13. **PolicyType** - object\n    * contains two pieces of info - \n        * the type of insurance on the car - liability, all perils, collision\n        * category of the vehicle - sport, sedan, utility\n14. **VehicleCategory** - object\n    * contains the categorization of the vehicle (see PolicyType)\n15. **VehiclePrice** - object\n    * contains ranges for the value of the vehicle\n    * replace ranges with mean value of range and convert to float\n16. **FraudFound_P** - int64\n    * indicats whether the claim was fraudulant (1) or not (0)\n    * **this is what we want to predict**\n17. **PolicyNumber** - int64\n    * the masked policy number, appears to be the same as row number minus 1\n18. **RepNumber** - int64\n    * rep number is  integer from 1 - 16\n19. **Deductible** - int64\n    * the deductible amount\n    * integer values\n20. **DriverRating** - int64\n    * the scale is 1, 2, 3, 4\n    * the name DriverRating implies the data is ordinal, but is it interval as well?\n21. **Days_Policy_Accident** - object\n    * as a guess, this is the number of days between when the policy was purchased and the accident occured\n    * each value is again a range of values\n    * change these to be mean of the range and make float\n22. **Days_Policy_Claim** - object\n    * another guess, this is the number of days that pass between the policy was purchased and the claim was filed\n    * each value is a range\n    * change these to be the mean of the ranges and make float\n23. **PastNumberOfClaims** - object\n    * previous number of claims filed by policy holder (or claimant?)\n24. **AgeOfVehicle** - object\n    * represents age of vehicle at time of the accident?\n    * each value is a range of years\n    * change these to be the mean of the ranges and make float\n25. **AgeOfPolicyHolder** - object\n    * each value is a range of ages\"\n    * change these to be the mean of the ranges and make float\n26. **PoliceReportFiled** - object\n    * indicates whether a police report was filed for the accident\n    * convert to binary\n27. **WitnessPresent** - object\n    * indicted whether a witness was present\n    * conver to binary\n28. **AgentType** -  object\n    * this classifies an agent who is handling the claim as internal vs external\n    * what does this mean? \n    * change to binary\n29. **NumberOfSuppliments** - object\n    * probably not the number of vitamins taken daily\n    * not sure what a suppliment is in insurance\n30. **AddressChange_Claim** - object\n    * guess, time from claim was filled to when person moved (i.e. filed an address change)\n    * replace each interval with mean value of range\n31. **NumberOfCars** - object\n    * guess, number of cars involved in accident OR number of cars covered under policy\n    * replace each interval with mean value of range\n32. **Year** - int64\n    * guess, year accident occured\n33. **BasePolicy** - object\n    * type of insurance coverage (see PolicyType)\n","3ad50f62":"Next we are going to check if there are any duplicate rows.","1c815b2a":"# **References**\n* Reference for hyperopt\n    * http:\/\/hyperopt.github.io\/hyperopt\/\n* Reference for XGBoost \n    * https:\/\/xgboost.readthedocs.io\/en\/stable\/parameter.html\n    * https:\/\/machinelearningmastery.com\/hyperparameters-for-classification-machine-learning-algorithms\/\n    * https:\/\/machinelearningmastery.com\/hyperopt-for-automated-machine-learning-with-scikit-learn\/\n    * https:\/\/www.analyticsvidhya.com\/blog\/2016\/03\/complete-guide-parameter-tuning-xgboost-with-codes-python\/\n    * https:\/\/www.kaggle.com\/prashant111\/a-guide-on-xgboost-hyperparameters-tuning\n    * https:\/\/blog.cambridgespark.com\/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n    * https:\/\/proceedings.neurips.cc\/paper\/2011\/file\/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf\n\n* References for decision trees:\n    * https:\/\/scikit-learn.org\/stable\/modules\/tree.html\n    * https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n    * https:\/\/www.analyticsvidhya.com\/blog\/2020\/08\/types-of-categorical-data-encoding\/\n    * https:\/\/www.analyticsvidhya.com\/blog\/2015\/11\/easy-methods-deal-categorical-variables-predictive-modeling\/?utm_source=blog&utm_medium=Categorical_data_encoding\n    * https:\/\/medium.com\/data-design\/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931\n  \n* Selecting metrics\/scoring rules for trees\n    * https:\/\/practicaldatascience.co.uk\/machine-learning\/how-to-use-smote-for-imbalanced-classification\n    * https:\/\/stats.stackexchange.com\/questions\/312780\/why-is-accuracy-not-the-best-measure-for-assessing-classification-models\n    * https:\/\/www.fharrell.com\/post\/class-damage\/\n    * https:\/\/stats.stackexchange.com\/questions\/91088\/when-is-a-proper-scoring-rule-a-better-estimate-of-generalization-in-a-classific\n    * https:\/\/contrib.scikit-learn.org\/category_encoders\/count.html\n    * https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html\n    \n* Kaggle Notebooks I found useful\n    * https:\/\/www.kaggle.com\/pmarcelino\/data-analysis-and-feature-extraction-with-python\n    \n* Using seaborn\n    * https:\/\/drawingfromdata.com\/seaborn\/matplotlib\/visualization\/rotate-axis-labels-matplotlib-seaborn.html\n    * https:\/\/stackoverflow.com\/questions\/43214978\/seaborn-barplot-displaying-values\n\n* Papers\n    * https:\/\/pubmed.ncbi.nlm.nih.gov\/28574989\/"}}