{"cell_type":{"052602e2":"code","e2b7750d":"code","f5b39bf5":"code","6504bda7":"code","40247cc8":"code","b2601c44":"code","35a465d0":"code","60f0f49d":"code","84975836":"code","698e2e38":"code","c380c763":"code","917a8e42":"code","b2976f27":"code","747b6d1c":"code","67eb7e37":"code","4359a689":"code","682df0c8":"code","ad6e2d35":"code","cc43123d":"code","6d14705f":"code","9b71a2f3":"code","286ad21b":"code","54092093":"code","b4c32f53":"code","1b799c78":"code","d3833d59":"code","c300acb9":"code","0ea122e7":"code","29795d28":"code","267fb2f8":"code","80d09e6f":"code","5f1a53f4":"markdown","099a7496":"markdown","db3929e4":"markdown","0888124c":"markdown"},"source":{"052602e2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tensorflow import keras\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e2b7750d":"fashion_mnist=keras.datasets.fashion_mnist\n(train_images,train_label),(test_images,test_label)=fashion_mnist.load_data()","f5b39bf5":"print(len(train_images),len(train_label))\nprint(len(test_images),len(test_label))","6504bda7":"import matplotlib.pyplot as plt\nplt.imshow(train_images[0],cmap ='gray')","40247cc8":"train_label[0:10]","b2601c44":"train_images[0].shape","35a465d0":"pt_x_train = []\npt_y_train = []\npt_x_test = []\npt_y_test = []\n\ntl_x_train =[]\ntl_y_train = []\ntl_x_test = []\ntl_y_test = []","60f0f49d":"length = 60000\nfor i in range(length):\n    if train_label[i]<5:\n        pt_x_train.append(train_images[i]\/255)\n        pt_y_train.append(train_label[i])\n    else:\n        tl_x_train.append(train_images[i]\/255)\n        tl_y_train.append(train_label[i])\n\nlength = 10000\nfor i in range(length):\n    if test_label[i] < 5:\n        pt_x_test.append(test_images[i]\/255)\n        pt_y_test.append(test_label[i])\n    else:\n        tl_x_test.append(test_images[i]\/255)\n        tl_y_test.append(test_label[i])\n        \n        \n        \n     ","84975836":"pt_x_train = np.asarray(pt_x_train)\npt_x_test = np.asarray(pt_x_test)\npt_y_test = np.asarray(pt_y_test)\npt_y_train = np.asarray(pt_y_train)\n\ntl_x_train = np.asarray(tl_x_train)\ntl_x_test = np.asarray(tl_x_test)\ntl_y_test = np.asarray(tl_y_test)\ntl_y_train = np.asarray(tl_y_train)","698e2e38":"print(pt_x_train.shape,pt_y_train.shape)\nprint(pt_x_test.shape,pt_y_test.shape)","c380c763":"print(tl_x_train.shape,tl_y_train.shape)\nprint(tl_x_test.shape,tl_y_test.shape)","917a8e42":"from keras.utils import np_utils ","b2976f27":"pt_y_train = np_utils.to_categorical(pt_y_train)\npt_y_test  = np_utils.to_categorical(pt_y_test)\n\ntl_y_train = np_utils.to_categorical(tl_y_train)\ntl_y_test  = np_utils.to_categorical(tl_y_test)\n\nprint(pt_y_train.shape,pt_y_test.shape)\nprint(tl_y_train.shape,tl_y_test.shape)","747b6d1c":"pt_x_train = pt_x_train.reshape(-1,28,28,1)\npt_x_test =  pt_x_test.reshape(-1,28,28,1)\n\ntl_x_train = tl_x_train.reshape(-1,28,28,1)\ntl_x_test =  tl_x_test.reshape(-1,28,28,1)\n\nprint(pt_x_train.shape,pt_x_test.shape)\nprint(tl_x_train.shape,tl_x_test.shape)","67eb7e37":"from keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Dropout,Flatten","4359a689":"model = Sequential()\n\nmodel.add(Conv2D(32,5,input_shape=(28,28,1),activation='relu'))\nmodel.add(Conv2D(16,5,activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(8,3,activation='relu'))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dense(5,activation='softmax'))\nmodel.summary()","682df0c8":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics =['accuracy'])","ad6e2d35":"model.fit(pt_x_train,pt_y_train,validation_data=(pt_x_test,pt_y_test),epochs=10,batch_size=100,verbose =2)","cc43123d":"model.layers","6d14705f":"for layer in model.layers[:6]:\n    layer.trainable = False\n    \nfor layer in model.layers:\n    print(layer.trainable)","9b71a2f3":"tl_model = Sequential(model.layers[:6])\n\ntl_model.add(Dense(128,activation='relu'))\ntl_model.add(Dense(64,activation='relu'))\ntl_model.add(Dense(10,activation='softmax'))\n\n             \ntl_model.summary()             ","286ad21b":"tl_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","54092093":"tl_model.fit(tl_x_train,tl_y_train,validation_data=(tl_x_test,tl_y_test),epochs=10,batch_size=100,verbose=2)","b4c32f53":"y_pred = tl_model.predict(tl_x_test)","1b799c78":"np.argmax(y_pred[0])","d3833d59":"y_pred.shape","c300acb9":"predictions = []\nfor i in range(5000):\n    predictions.append(np.argmax(y_pred[i]))\n    ","0ea122e7":"predictions[0]","29795d28":"np.argmax(tl_y_test[0])\n","267fb2f8":"predictions[:10]","80d09e6f":"plt.imshow(tl_x_test[np.argmax(y_pred[0])].reshape(28,28))","5f1a53f4":"After Creating pt_x_train, tl_x_train, pt_x_test,tl_x_test\n* Shape of pt_x_train=(30000,28,28)\n* Shape of tl_x_train=(30000,28,28)\n* Shape of pt_x_test=(5000,28,28)\n* Shape of tl_x_test=(5000,28,28)","099a7496":"**Loading Dataset**","db3929e4":"# Pre-trained Model on Data Labels 0-4","0888124c":"# Transfer Learning on Data Labels 5-9 using the lower layers of Pre-trained model"}}