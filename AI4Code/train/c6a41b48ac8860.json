{"cell_type":{"354d3ec4":"code","53ee2cce":"code","f64e3308":"code","6d9cc300":"code","774490cc":"code","2459e3c0":"code","97669f3f":"code","3056a2ca":"code","9580b373":"code","8f7efcac":"code","bebd05a1":"code","35b969ab":"code","85e53308":"code","86fe34fa":"code","7056d9f4":"code","f67265f6":"code","02b417ce":"code","f85ca33d":"code","f73068ab":"code","acef488b":"code","955b6250":"code","0b132faf":"code","217319a4":"code","2156464a":"code","95c34700":"code","231b6da7":"code","da5bbca5":"code","39c5be75":"code","855a0ec8":"code","c825ea85":"code","0285846a":"code","38922278":"code","be249bb6":"code","5b94d5e2":"code","fec344bd":"code","75ae7265":"code","b00de5b6":"code","230a9136":"code","69889fbf":"code","57d41ddf":"code","a7c233f9":"markdown","740698a6":"markdown","8e31c3d0":"markdown","ab99302e":"markdown","3a4fffce":"markdown","1aa3a7ec":"markdown","9bd8dc4f":"markdown","70c545ac":"markdown","a7b780a8":"markdown","0ddebc95":"markdown","59438055":"markdown","685504f3":"markdown"},"source":{"354d3ec4":"import pandas as pd\nimport numpy as np\nimport re\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nimport seaborn as sns\nimport matplotlib.pyplot as plt","53ee2cce":"# Importing dataset from csv files\n\ntrain_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')","f64e3308":"train_data.head()","6d9cc300":"# Checking columns for missing values\n# train_data - Null values exist in columns Age, Cabin and Embarked\n\ntrain_data.isna().sum()","774490cc":"test_data.isna().sum()","2459e3c0":"print(train_data[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean())","97669f3f":"sns.barplot(x = \"Pclass\", y = \"Survived\", data = train_data);","3056a2ca":"print(train_data[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean())","9580b373":"sns.barplot(x = 'Sex', y = 'Survived', data = train_data);","8f7efcac":"# Feature Engineering with the help of SibSp and Parch\n# New feature can be Family Size \n\ntrain_data['family_size'] = 0\ntest_data['family_size'] = 0\n\ntrain_data['family_size'] = train_data['SibSp'] + train_data['Parch'] + 1\ntest_data['family_size'] = test_data['SibSp'] + test_data['Parch'] + 1\n\nprint(train_data[[\"family_size\",\"Survived\"]].groupby([\"family_size\"], as_index = False).mean())","bebd05a1":"train_data.head()","35b969ab":"# Creating a new column 'is_alone' to check survival of passengers travelling alone\n\ndef check_alone(row): \n    \"\"\"Check whether a passenger travelled alone (returns 1) or with family (returns 0).\n    \n    \"\"\"\n    if row['family_size'] == 1:\n        return 1\n    else:\n        return 0\n    \ntrain_data['is_alone'] = train_data.apply(check_alone, axis = 1)\ntest_data['is_alone'] = test_data.apply(check_alone, axis = 1)","85e53308":"print(train_data[[\"is_alone\", \"Survived\"]].groupby([\"is_alone\"], as_index = False).mean())","86fe34fa":"sns.barplot(x = 'is_alone', y = 'Survived', data = train_data);","7056d9f4":"# TODO: Fill the 2 NaN values\n\ne = train_data[train_data.Embarked.isna()]\ne","f67265f6":"# Both rows have the same Fare value\n# Range of values for 'C' satisfies the given fare values.\n# Setting a limit on the range of the y-axis\n\nplt.ylim(0,200)\nax = sns.boxplot(x = train_data['Embarked'], y = train_data['Fare'], palette = 'GnBu')\nplt.show()","02b417ce":"# Fill NaN values with 'C'\ntrain_data['Embarked'] = train_data[\"Embarked\"].fillna('C')","f85ca33d":"train_data.iloc[[61,829],:]","f73068ab":"print(train_data[['Embarked','Survived']].groupby(['Embarked'], as_index = False).mean())","acef488b":"# NaN values filled with random number between (avg - avg std. deviation) and (avg + avg std. deviation)\n# 177\n\navg = train_data['Age'].mean()\nstd = train_data['Age'].std()\nrandom = np.random.randint(avg - std, avg + std, size = 177) \ntrain_data.loc[train_data.Age.isna(), 'Age'] = random    # fill with random age values","955b6250":"# TODO: repeat for test_data\n\navg = test_data['Age'].mean()\nstd = test_data['Age'].std()\nrandom = np.random.randint(avg - std, avg + std, size = 86)\ntest_data.loc[test_data.Age.isna(), 'Age'] = random\ntest_data.Age.isna().sum()","0b132faf":"# pd.cut() - useful for going from a continuous variable to a categorical variable. \n# Used here to convert ages to groups of age ranges.\n\ntrain_data.Age = train_data['Age'].astype(int)    # convert to int to create bins easily\ntest_data.Age = test_data['Age'].astype(int)\ntrain_data['category_age'] = pd.cut(train_data['Age'], 5)    # 5 bins\nprint(train_data[[\"category_age\",\"Survived\"]].groupby([\"category_age\"], as_index = False).mean())","217319a4":"sns.catplot(x = 'Survived', y = 'Age', data = train_data, kind = 'violin');","2156464a":"train_data['category_fare'] = pd.qcut(train_data['Fare'], 4)\nprint(train_data[['category_fare', 'Survived']].groupby([\"category_fare\"], as_index = False).mean())","95c34700":"sns.distplot(train_data['Fare'], color = 'b');","231b6da7":"# Replace NaN in test_data Fare column\n\nprint(test_data.loc[test_data.Fare.isna(), 'Embarked'])    # Get Embarked value for NaN Fare\nmean = train_data.loc[train_data.Embarked == 'S', 'Fare'].mean()    # Calculate mean for 'S' fares\ntest_data.loc[test_data.Fare.isna(), 'Fare'] = mean","da5bbca5":"def get_title(row):\n    name = row['Name']\n    title_search = re.search('([A-Za-z]+)\\.', name)    # start with any letter, end with period\n    if title_search:\n        return title_search.group(1)    # .group() returns the strings that were matches\n    return \"\"\n\ntrain_data['Title'] = train_data.apply(get_title, axis = 1)\ntest_data['Title'] = test_data.apply(get_title, axis = 1)\ntrain_data.head()","39c5be75":"print(train_data[['Title','Survived']].groupby(['Title'], as_index = False).mean())","855a0ec8":"# Narrowing the titles down further\n\ntrain_data['Title'] = train_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],'Other')\ntrain_data['Title'] = train_data['Title'].replace(['Mlle', 'Ms'], 'Miss')\ntrain_data['Title'] = train_data['Title'].replace(['Mme'], 'Mrs')\n\ntest_data['Title'] = test_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],'Other')\ntest_data['Title'] = test_data['Title'].replace(['Mlle', 'Ms'], 'Miss')\ntest_data['Title'] = test_data['Title'].replace(['Mme'], 'Mrs')","c825ea85":"train_data.Title.value_counts()","0285846a":"print(train_data[['Title','Survived']].groupby(['Title'], as_index = False).mean())","38922278":"# Sex\nsex_map = {'female': 0, 'male': 1}\ntrain_data['Sex'] = train_data.Sex.map(sex_map).astype(int)\ntest_data['Sex'] = test_data.Sex.map(sex_map).astype(int)\n\n# Title\ntitle_map = {'Master': 0, 'Miss': 1, 'Mr': 2, 'Mrs': 3, 'Other': 4}\ntrain_data[\"Title\"] = train_data.Title.map(title_map).astype(int)\ntest_data[\"Title\"] = test_data.Title.map(title_map).astype(int)\n\n# Embarked\nemb_map = {'C': 0, 'Q': 1, 'S': 2}\ntrain_data[\"Embarked\"] = train_data.Embarked.map(emb_map).astype(int)\ntest_data[\"Embarked\"] = test_data.Embarked.map(emb_map).astype(int)","be249bb6":"train_data.head(5)","5b94d5e2":"# 1. Cast to pandas categorical datatype\n# 2. get dummies\n# 3. Avoiding dummy variable trap by dropping first column for each category\n\ncategories = ['Pclass', 'Sex', 'Embarked', 'is_alone', 'Title']\n\nfor category in categories:\n    train_data[category] = pd.Categorical(train_data[category])\n    test_data[category] = pd.Categorical(test_data[category])\n    train_data = pd.concat([train_data, pd.get_dummies(train_data[category], prefix = category, drop_first = True)], axis = 1)\n    test_data = pd.concat([test_data, pd.get_dummies(test_data[category], prefix = category, drop_first = True)], axis = 1)\n\n# Dropping unecessary rows\n# Remember, the submissions file must contain passenger id\n\npassenger_ids = test_data['PassengerId']\ntrain_data = train_data.drop(['PassengerId', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'category_age', 'category_fare', 'Embarked', 'is_alone', 'Title'], axis = 1)\ntest_data = test_data.drop(['PassengerId', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'is_alone', 'Title'], axis = 1)\ntrain_data.head()    ","fec344bd":"test_data.head()","75ae7265":"# Split data into train and test sets\n\nX_train = train_data.drop(['Survived'], axis = 1)\ny_train = train_data[\"Survived\"]\nX_test = test_data.copy()","b00de5b6":"# Performing hyperparameter optimisation\n\nrf = RandomForestClassifier()\ngrid_params = {\"criterion\": ['gini', 'entropy'],\n              \"n_estimators\": [30, 50, 100, 200, 500],\n              \"min_samples_leaf\": [1, 5, 10],\n              \"min_samples_split\": [2,4,8,10]}\ngrid_cv = GridSearchCV(estimator = rf, param_grid = grid_params, scoring = 'accuracy', cv = 3, verbose = 3)\ngrid_cv = grid_cv.fit(X_train, y_train)\nprint(\"Best accuracy: \",grid_cv.best_score_)\nprint(\"Best params: \", grid_cv.best_params_)","230a9136":"# Fit Random Forest Classifier to train set with best params from GridSearch\n\nclassifier = RandomForestClassifier(n_estimators = 100, criterion = 'gini', min_samples_leaf = 1, min_samples_split = 10, random_state = 0)\nclassifier.fit(X_train, y_train)","69889fbf":"# Predict test set results\ny_pred = classifier.predict(X_test)","57d41ddf":"# Creating the submissions file\n\nsubmission = pd.DataFrame({\n    'PassengerId': passenger_ids,\n    'Survived': y_pred\n})\n\nsubmission.to_csv('submissions.csv', index = False)","a7c233f9":"### Fare","740698a6":"This is my first Kaggle competition and this notebook is my attempt at applying basic Random Forest Classification on the famous Titanic dataset from Kaggle.\n\nReferences: https:\/\/towardsdatascience.com\/your-first-kaggle-competition-submission-64da366e48cb","8e31c3d0":"### Passenger Class","ab99302e":"### Modelling","3a4fffce":"### One Hot Encoding","1aa3a7ec":"### Embarked","9bd8dc4f":"### Label Encoding","70c545ac":"### Age","a7b780a8":"### Sex","0ddebc95":"### New feature - is the passenger alone?","59438055":"### New feature - Family Size","685504f3":"### Name"}}