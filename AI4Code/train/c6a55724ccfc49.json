{"cell_type":{"52e552ff":"code","446f08a5":"code","e309014b":"code","f7ec5de3":"code","8e080ae7":"code","f38490e7":"code","4b38519e":"code","91a1f5ed":"code","5deef3ee":"code","53db4823":"code","29b1b155":"code","90dc2b0e":"code","dd927c2d":"code","e241ed9f":"code","5a0cc2e1":"code","a6f3550d":"code","f2b1fcb8":"code","e8a2280d":"code","e4837785":"code","a9c34bfc":"code","337db3d3":"code","9f16c695":"code","cd75da44":"code","aec7a0bf":"code","9b5b0f6d":"code","8692fc9b":"code","a897c8cd":"code","e31963eb":"code","16122e23":"code","441a05da":"markdown","47ad38e9":"markdown","cef7e075":"markdown","293e7b6c":"markdown","801fd1ba":"markdown"},"source":{"52e552ff":"# importing what we will need\nimport pandas as pd\nimport numpy as np\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport seaborn as sns","446f08a5":"#reading data\nrawdata = pd.read_csv(\"..\/input\/perth-house-prices\/all_perth_310121.csv\")\nrawdata.head()","e309014b":"# Inspection of data\nrawdata.isna().sum()","f7ec5de3":"# Let's fill missing values. For GARAGE it makes sense to fill the missing values with \"0\", the BUILD YEAR with the mean value\nrawdata.GARAGE = rawdata.GARAGE.fillna(0)\nrawdata.BUILD_YEAR = rawdata.BUILD_YEAR.fillna(rawdata.BUILD_YEAR.mean())\n","8e080ae7":"# Let's fill the school rank. It should depend on location and district.\n# Create a subset with potentially relevant values\nschool = rawdata.drop([\"ADDRESS\", \"SUBURB\", \"NEAREST_STN\", \"NEAREST_SCH\", \"DATE_SOLD\", \"BUILD_YEAR\"], axis=1)\n\n#Here we will store all schools with known rating\nschool_nona = school.dropna(axis = 0)\n\n#And here all schools with unknown rating which we will fill\nschool_predict = school[school.NEAREST_SCH_RANK.isna()]","f38490e7":"# A correlation matrix should show which parameters are the most important\ncorr = school_nona.corr()\nsns.heatmap(corr);","4b38519e":"# creating X and y for regression\nX = school_nona.drop(\"NEAREST_SCH_RANK\", axis=1)\ny = school_nona.NEAREST_SCH_RANK\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)","91a1f5ed":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nRFR = RandomForestRegressor()\nRFR.fit(X_train, y_train)\nRFR.score(X_test,y_test)","5deef3ee":"cross_val_score(RFR, X,y,cv=5)","53db4823":"X_pred = school_predict.drop(\"NEAREST_SCH_RANK\", axis=1)\nschool_predict.drop(\"NEAREST_SCH_RANK\", axis=1)\nschool_predict[\"NEAREST_SCH_RANK\"]=RFR.predict(X_pred)\n#There is a warning but I do not know why :(","29b1b155":"school_predict[\"NEAREST_SCH_RANK\"]","90dc2b0e":"#putting the predicted ratings to the main dataset\nrawdata.NEAREST_SCH_RANK.fillna(school_predict[\"NEAREST_SCH_RANK\"], inplace=True)","dd927c2d":"# Data set is clean and nice!\nrawdata.isna().sum()","e241ed9f":"# Dealing with date\ndate_sold = pd.to_datetime(rawdata.DATE_SOLD)\nrawdata[\"MONTH_SOLD\"] = date_sold.apply(lambda x: x.month)\nrawdata[\"YEAR_SOLD\"] = date_sold.apply(lambda x: x.year)","5a0cc2e1":"# Getting rid of non-numeric data\n# As Suburb, Postcode, Latitude, Longitude are all related to geographical location, I decided to keep only the postcode and geographical coordinates\ndata = rawdata.drop([\"ADDRESS\", \"SUBURB\", \"NEAREST_SCH\", \"NEAREST_STN\", \"DATE_SOLD\"], axis=1)\ndata.head()","a6f3550d":"# Looking for outliers\nfig, axes = plt.subplots(3, 4, figsize=(25, 8))\n\nfig.suptitle('Box plots for the data')\n\nsns.boxplot(ax=axes[0, 0], data=data, y='PRICE')\nsns.boxplot(ax=axes[0, 1], data=data, y='BEDROOMS')\nsns.boxplot(ax=axes[0, 2], data=data, y='BATHROOMS')\nsns.boxplot(ax=axes[0, 3], data=data, y='GARAGE')\nsns.boxplot(ax=axes[1, 0], data=data, y='LAND_AREA')\nsns.boxplot(ax=axes[1, 1], data=data, y='FLOOR_AREA')\nsns.boxplot(ax=axes[1, 2], data=data, y='BUILD_YEAR')\nsns.boxplot(ax=axes[1, 3], data=data, y='CBD_DIST')\nsns.boxplot(ax=axes[2, 0], data=data, y='NEAREST_STN_DIST')\nsns.boxplot(ax=axes[2, 1], data=data, y='NEAREST_SCH_DIST')\nsns.boxplot(ax=axes[2, 2], data=data, y='NEAREST_SCH_RANK')\nsns.boxplot(ax=axes[2, 3], data=data, y='YEAR_SOLD');","f2b1fcb8":"# to detect outliers, we will use zscore. Normally, an outlier will have the zscore >3, but they should not be more than 3% of the set\nfrom scipy import stats\nstats.zscore(data).describe(percentiles=[0.01, 0.02, 0.03,0.05,0.95,0.97,0.98,0.99]).round(5)","e8a2280d":"#delete outliers\ndata_num_clear = data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\ndata_num_clear.head()","e4837785":"# set X, y and split them for the model\nX = data_num_clear.drop(\"PRICE\", axis=1)\ny = data_num_clear.PRICE\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)","a9c34bfc":"RFR = RandomForestRegressor()\nRFR.fit(X_train, y_train)\nRFR.score(X_test,y_test)","337db3d3":"cross_val_score(RFR, X,y,cv=5)","9f16c695":"y_pred = RFR.predict(X_test)","cd75da44":"from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n# Mean absolute error (MAE)\nmae = mean_absolute_error(y_test, y_pred)\n\n# Mean squared error (MSE)\nmse = mean_squared_error(y_test, y_pred)\n\n# R-squared scores\nr2 = r2_score(y_test, y_pred)\n\n# Print metrics\nprint('Mean Absolute Error:', round(mae, 2))\nprint('Mean Squared Error:', round(mse, 2))\nprint('R-squared scores:', round(r2, 2))","aec7a0bf":"test = pd.DataFrame(X_test)\ntest[\"PREDICTED_PRICE\"] = y_pred\ntest[\"PRICE\"] = y_test\n# calculate error in % of price\ntest[\"QUALITY\"] = np.abs((test[\"PREDICTED_PRICE\"]-test[\"PRICE\"]))\/test[\"PRICE\"]*100","9b5b0f6d":"test","8692fc9b":"test.QUALITY.describe()","a897c8cd":"from bokeh.plotting import figure\nfrom bokeh.tile_providers import get_provider, WIKIMEDIA, CARTODBPOSITRON, STAMEN_TERRAIN, STAMEN_TONER, ESRI_IMAGERY, OSM\nfrom bokeh.io import output_notebook, show\nfrom bokeh.layouts import row\nfrom bokeh.transform import linear_cmap\nfrom bokeh.palettes import Turbo256, RdYlGn, Inferno256\nfrom bokeh.models import ColorBar, ColumnDataSource, LinearColorMapper, BasicTicker\nimport math\nfrom bokeh.io import export_png","e31963eb":"# Convert long-lat in mercator coordinates\ndef geographic_to_web_mercator(x_lon, y_lat):     \n    if abs(x_lon) <= 180 and abs(y_lat) < 90:          \n        num = x_lon * 0.017453292519943295         \n        x = 6378137.0 * num         \n        a = y_lat * 0.017453292519943295          \n        x_mercator = x         \n        y_mercator = 3189068.5 * math.log((1.0 + math.sin(a)) \/ (1.0 - math.sin(a)))         \n        return x_mercator, y_mercator      \n    else:         \n        print('Invalid coordinate values for conversion')      \nlons, lats = [], []\nfor lon, lat in list(zip(test.LONGITUDE, test.LATITUDE)):\n    x, y = geographic_to_web_mercator(lon,lat)\n    lons.append(x)\n    lats.append(y)\n","16122e23":"# This we will need to have the generated pics in the notebook\noutput_notebook()\n\ncartod = get_provider(CARTODBPOSITRON)\nsource = ColumnDataSource(dict(x=lons,y=lats))\nsource.data[\"color\"] = test.QUALITY\nfig = figure(plot_width=500, plot_height=500,\n           x_range=(12900000, 12916000), y_range=(-3825558, -3692302),\n           x_axis_type=\"mercator\", y_axis_type=\"mercator\", toolbar_location=None)\nmapper=linear_cmap(\"color\", palette=\"Inferno256\", low=0, high=25)\ncolor_mapper = LinearColorMapper(palette=\"Inferno256\", low=0, high=25)\n\nfig.circle(x=\"x\", y=\"y\", radius=300, alpha=0.5, fill_color=mapper, line_width=0, source=source)\n\ncolor_bar = ColorBar(color_mapper=color_mapper, ticker= BasicTicker(),\n                     location=(0,0), width=10, title=\"Root Mean Squared Error\",\n                    major_label_overrides = { 25:\">25\"})\nfig.add_tile(cartod)\nfig.add_layout(color_bar, 'right')\n\nshow(fig)","441a05da":"**We have a model with passable metrics**","47ad38e9":"*Let's visualize the locations of properties with badly predicted price*","cef7e075":"**There is no obvious geographic dependance of badly predicted prices. Probably a bit more in the centre?**","293e7b6c":"### Perth house prediction (Regression model)\nI am a beginner in data science and took this set just to play around. I have made 2 different things: 1) visualizing of geographical data - can be found [here](https:\/\/www.kaggle.com\/pavelivanov89\/perth-suburb-ranking-and-visualization); 2) regression to predict the price. This is the notebook for 2). \nI would be very thankfull for comments and remarks","801fd1ba":"**Not bad: we have a huge score, let's fill all the missing ranks with it**"}}