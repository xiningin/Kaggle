{"cell_type":{"8cd0688a":"code","592337f9":"code","4bb57b76":"code","011b79e1":"code","126f5041":"code","09fffdbb":"code","56bf4c5e":"code","96e4de67":"code","e1bfea1f":"code","92fea9bd":"code","163a9f5a":"code","24a1be70":"code","8e59b69a":"code","4507af41":"code","7a7868cb":"code","e684de21":"code","c8c3eb90":"code","5dc174c9":"code","f9794e8c":"code","06162a18":"code","c4f62c5b":"code","e94098b6":"code","674d27ed":"code","972ef76b":"code","b1114b26":"code","e690c1ba":"code","d91bc0c8":"code","064210c6":"code","37dcd135":"code","2521b2b4":"code","48f7cbcb":"code","c0055025":"code","6b20af40":"code","bda00d1a":"code","b9234843":"code","7df0fd8f":"code","1301ca2f":"code","d0c226f7":"code","c428cfe9":"code","63cac910":"code","c649339a":"code","bd55d18a":"code","6cf343ca":"code","a4a5b586":"code","8d95e0bc":"code","0765e793":"code","abec3595":"code","253e71cf":"markdown","3b86ac27":"markdown","5943227b":"markdown","fdb7c456":"markdown","3a38a10e":"markdown","2c79f79b":"markdown","51632aee":"markdown","d2c4a7c3":"markdown","211452c5":"markdown","47b474e6":"markdown","2197aeb2":"markdown","40cd4ee4":"markdown","827fd776":"markdown","2faae03d":"markdown","db8dbfe3":"markdown","da38b0ee":"markdown","ff7be567":"markdown","b7a8bdb3":"markdown","81444ad4":"markdown","cceb450b":"markdown","284988a3":"markdown","eda42172":"markdown","cccbbcf8":"markdown","6f9d8876":"markdown","18b0f46f":"markdown","9e084904":"markdown"},"source":{"8cd0688a":"#import necessary modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#load data\ndf=pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")","592337f9":"#check the beginning\ndf.head()","4bb57b76":"#check for missing values\ndf.isnull().sum()    \n\n# we notice that there are no missing values","011b79e1":"# investigate data types\ndf.info()","126f5041":"#change data type for the indicated columns\n\ncat_cols=[\"anaemia\",\"diabetes\",\"high_blood_pressure\",\"sex\",\"smoking\",\"DEATH_EVENT\"]\n\ndf[cat_cols]=df[cat_cols].astype(\"category\")\n","09fffdbb":"#rename DEATH_EVENT column\ndf.rename({\"DEATH_EVENT\":\"death\"},axis=1,inplace=True)","56bf4c5e":"#check statistical measures of the data\ndf.describe()","96e4de67":"#import matplotlib and seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#create correlation matrix\ncor_mat=df.corr()\n\n# set figure size\nplt.figure(figsize=(9,7))\n\n#create the heatmap\nax=sns.heatmap(cor_mat,cmap=\"Blues\",linewidths=2, linecolor='black',annot=True)\nax.set_ylim([0,7])\nplt.show()","e1bfea1f":"#set the style of the plots\nsns.set_style(\"darkgrid\")","92fea9bd":"#plot age\nplt.figure(figsize=(6,6))\nsns.distplot(df.age,bins=10)\nplt.xlabel(\"Age of the patients\")\nplt.ylabel(\"Number of patients\")","163a9f5a":"#plot creatinine_phosphokinase\nplt.figure(figsize=(6,6))\nsns.distplot(df.creatinine_phosphokinase,bins=10)\nplt.xlabel(\"Level of creatinine phosphokinase\")\nplt.ylabel(\"Number of patients\")","24a1be70":"#plot ejection_fraction\nplt.figure(figsize=(6,6))\nsns.distplot(df.ejection_fraction,bins=10)\nplt.xlabel(\"Ejection fraction\")\nplt.ylabel(\"Number of patients\")","8e59b69a":"#plot platelets\nplt.figure(figsize=(6,6))\nsns.distplot(df.platelets,bins=10)\nplt.xlabel(\"Concentration of platelets\")\nplt.ylabel(\"Number of patients\")","4507af41":"#plot serum_creatinine\nplt.figure(figsize=(6,6))\nsns.distplot(df.serum_creatinine,bins=10)\nplt.xlabel(\"Level of creatinine\")\nplt.ylabel(\"Number of patients\")","7a7868cb":"#plot serum_sodium\nplt.figure(figsize=(6,6))\nsns.distplot(df.serum_sodium,bins=10)\nplt.xlabel(\"Level of sodium\")\nplt.ylabel(\"Number of patients\")","e684de21":"#plot anaemia for each sex\nplt.figure(figsize=(6,6))\nsns.set_style(\"darkgrid\")\nsns.catplot(x=\"anaemia\",hue=\"death\",data=df,kind=\"count\",col=\"sex\",palette=\"colorblind\")\nplt.show()","c8c3eb90":"#plot diabetes for each sex\nplt.figure(figsize=(6,6))\nsns.set_style(\"darkgrid\")\nsns.catplot(x=\"diabetes\",hue=\"death\",data=df,kind=\"count\",col=\"sex\",palette=\"colorblind\")\nplt.show()","5dc174c9":"#plot smoking for each sex\nplt.figure(figsize=(6,6))\nsns.set_style(\"darkgrid\")\nsns.catplot(x=\"smoking\",hue=\"death\",data=df,kind=\"count\",col=\"sex\",palette=\"colorblind\")\nplt.show()","f9794e8c":"#plot high_blood_pressure for each sex\nplt.figure(figsize=(6,6))\nsns.set_style(\"darkgrid\")\nsns.catplot(x=\"high_blood_pressure\",hue=\"death\",data=df,kind=\"count\",col=\"sex\",palette=\"colorblind\")\nplt.show()","06162a18":"#the graphs in this section will be produced using plotly\nimport plotly.express as px","c4f62c5b":"#plot platelets vs creatinine_phosphokinase\nfig=px.scatter(df,x=\"platelets\",y=\"creatinine_phosphokinase\",color=\"death\",template=\"plotly_dark\",width=1000,height=500)\nfig.update_traces(marker=dict(size=12, line=dict(width=1,color='LightBlue')),selector=dict(mode='markers'))","e94098b6":"#plot serum_creatinine vs serum_sodium\nfig=px.scatter(df,x=\"serum_creatinine\",y=\"serum_sodium\",color=\"death\",template=\"plotly_dark\",width=1000,height=500)\nfig.update_traces(marker=dict(size=12, line=dict(width=1,color='LightBlue')),selector=dict(mode='markers'))","674d27ed":"#plot serum_creatinine vs creatinine_phosphokinase \nfig=px.scatter(df,x=\"serum_creatinine\",y=\"creatinine_phosphokinase\",color=\"death\",template=\"plotly_dark\",width=1000,height=500)\nfig.update_traces(marker=dict(size=12, line=dict(width=1,color='LightBlue')),selector=dict(mode='markers'))","972ef76b":"# boxplot of the age variable \npx.box(df, x=\"smoking\", y=\"age\",width=1000,height=500,facet_col=\"high_blood_pressure\",color_discrete_sequence=['darkorchid']\n)","b1114b26":"# boxplot of the ejection_fraction variable \npx.box(df, x=\"smoking\", y=\"ejection_fraction\",width=1000,height=500,color=\"high_blood_pressure\",\n       color_discrete_sequence=['crimson','yellow']\n)","e690c1ba":"#boxplot of ejection_fraction variable|\npx.box(df, x=\"smoking\", y=\"creatinine_phosphokinase\",width=1000,height=500,color=\"high_blood_pressure\",\n       color_discrete_sequence=['darkgreen','blue']\n)","d91bc0c8":"# boxplot of the platelets variable \npx.box(df, x=\"smoking\", y=\"platelets\", color=\"sex\",width=1000,height=500)","064210c6":"#scaling our data\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler=StandardScaler()\n\ncolumns=[\"age\",\"creatinine_phosphokinase\",\"ejection_fraction\",\"platelets\",\"serum_creatinine\",\"serum_sodium\",\"time\"]\n\nfor column in columns:\n    df[column]=scaler.fit_transform(df[column].values.reshape(-1,1))","37dcd135":"#split into train and test\n\nfrom sklearn.model_selection import train_test_split\n\nX=df.drop(\"death\",axis=1)\ny=df.death\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=10,test_size=0.3,stratify=y)","2521b2b4":"#import modules needed for hyperparameter tunning\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV,cross_val_score\n\n#import modules needed for performance check\nfrom sklearn.metrics import confusion_matrix, classification_report","48f7cbcb":"#import the model\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#instantiate the classifier\nknn=KNeighborsClassifier()\n\n#define parameter range\nparam_grid_knn={\"n_neighbors\":range(1,15)}\n\n#run gridsearch \ncv_knn=GridSearchCV(knn,param_grid_knn,cv=10)\ncv_knn.fit(X_train,y_train)","c0055025":"#get the best estimator\nbest_knn=cv_knn.best_estimator_\n\n#get the predicted classes\ny_pred_knn=best_knn.predict(X_test)\n\n#get the score for the test set\nprint(\"The score for the tuned KNN model is {}\".format(best_knn.score(X_test,y_test)))","6b20af40":"#get the metrics for the two classes\nprint(pd.DataFrame(classification_report(y_test,y_pred_knn,output_dict=True)))","bda00d1a":"#plot the heatmap corresponding to the confusion matrix\nax=sns.heatmap(confusion_matrix(y_test,y_pred_knn),annot=True,cmap=\"GnBu\")\nax.set_ylim([0,2])","b9234843":"#import the model\nfrom sklearn.linear_model import LogisticRegression\n\n#instantiate the classifier\nlogreg=LogisticRegression(random_state=10,solver='liblinear')\n\n#define parameter range\nparam_grid_logreg={\"C\":np.logspace(-4, 4, 20),'penalty' : ['l1', 'l2']}\n\n#run gridsearch \ncv_logreg=GridSearchCV(logreg,param_grid_logreg,cv=10)\ncv_logreg.fit(X_train,y_train)","7df0fd8f":"#get the best estimator\nbest_logreg=cv_logreg.best_estimator_\n\n#get the predicted classes\ny_pred_logreg=best_logreg.predict(X_test)\n\n#get the score for the test set\nprint(\"The score for the tuned Logistic Regression is {}\".format(best_logreg.score(X_test,y_test)))","1301ca2f":"#get the metrics for the two classes\nprint(pd.DataFrame(classification_report(y_test,y_pred_logreg,output_dict=True)))","d0c226f7":"#plot the heatmap corresponding to the confusion matrix\nax=sns.heatmap(confusion_matrix(y_test,y_pred_logreg),annot=True,cmap=\"GnBu\")\nax.set_ylim([0,2])","c428cfe9":"#import the model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#instantiate the classifier\nrf=RandomForestClassifier(random_state=10)\n\n#define parameter range\nparam_grid_rf={\"n_estimators\":range(100,401,50),\"criterion\":[\"gini\",\"entropy\"],\"max_depth\":range(2,10),\n               \"min_samples_leaf\":np.arange(0.1,0.51,0.1),\"max_features\":[\"auto\",\"sqrt\",\"log2\"]\n              }\n\n#run randomized search \ncv_rf=RandomizedSearchCV(rf,param_grid_rf,cv=10)\ncv_rf.fit(X_train,y_train)","63cac910":"#get the best estimator\nbest_rf=cv_rf.best_estimator_\n\n#get the predicted classes\ny_pred_rf=best_rf.predict(X_test)\n\n#get the score for the test set\nprint(\"The score for the tuned Random Forest is {}\".format(best_rf.score(X_test,y_test)))","c649339a":"#get the metrics for the two classes\nprint(pd.DataFrame(classification_report(y_test,y_pred_rf,output_dict=True)))","bd55d18a":"#plot the heatmap corresponding to the confusion matrix\nax=sns.heatmap(confusion_matrix(y_test,y_pred_rf),annot=True,cmap=\"GnBu\")\nax.set_ylim([0,2])","6cf343ca":"#import the model\nfrom sklearn.ensemble import AdaBoostClassifier\n\n#instantiate the classifier\nada=AdaBoostClassifier(random_state=10)\n\n#range for number of estimators\nparam_grid_ada={\"n_estimators\":range(50,401,50)}\n\n#run the gridsearch\ncv_ada=GridSearchCV(ada,param_grid_ada,cv=3)\ncv_ada.fit(X_train,y_train)","a4a5b586":"#get the best estimator\nbest_ada=cv_ada.best_estimator_\nbest_ada","8d95e0bc":"#get the predicted classes\ny_pred_ada=best_ada.predict(X_test)\n\n#get the score for the test set\nprint(\"The score for the tuned AdaBoost model is {}\".format(best_ada.score(X_test,y_test)))","0765e793":"#get the metrics for the two classes\nprint(pd.DataFrame(classification_report(y_test,y_pred_ada,output_dict=True)))","abec3595":"#plot the heatmap corresponding to the confusion matrix\nax=sns.heatmap(confusion_matrix(y_test,y_pred_ada),annot=True,cmap=\"GnBu\")\nax.set_ylim([0,2])","253e71cf":"### 3.4 Relational Plots","3b86ac27":"# Heart Failure Project","5943227b":"As we can see, KNeighbours model does not have high performance. By increasing the number of considered neighbours, the algorithm\ntends to classify all the labels as 0 due to class imbalance. This leads to high recall for the majority class (ie. __0__ ) and \nlow recall and precision for the minority class (ie. __1__)","fdb7c456":"The AdaBoost model has fairly good results, having misclassified only a relatively small number of patients.","3a38a10e":"We can see that the Logistic Regression does a significantly better job. It has not only higher score for the test sets, but also \nhigher precision and recall for each class","2c79f79b":"It appears that AdaBooster has the highest performance compared to the other 3 models we fitted.\nHowever, apart from the KNeighbors algorithm, they all generated fairly good results, with accuracies for the test set of over 80%. \n\nThis type of methods could provide effective support to doctors for assessing the severity of the patient's condition. However, more sophisticated models should be buit for them to be reliable.\n","51632aee":"### 3.2 Histograms","d2c4a7c3":"Compared to the Logistic Regression model, the Random Forest has higher score for the test set. However, the recall for class __1__ is particularly low, which is confirmed by the confusion matrix.","211452c5":"### 4.3 Random Forest","47b474e6":"### 4.2 Logistic Regression","2197aeb2":"## 2. Data Cleaning","40cd4ee4":"The heatmap shows no strong correlation between any two variables. Furthermore, we can see that only the numerical variables have been included.","827fd776":"This is the best score we got so far for the test set.","2faae03d":"### 3.1 Correlation matrix","db8dbfe3":"In this part we will first scale our data and split it into train and test sets. Next, we will use several classification algorithms and record thei performances:\n    1. K-Neighbours\n    2. Logistic Regression\n    3. Random Forest\n    4. AdaBoost","da38b0ee":"### 4.1 K-Neighbors","ff7be567":"## 1. Loading Data","b7a8bdb3":"## 3. Exploratory Data Analysis","81444ad4":"We notice that the columns regarding __anemia__, __diabetes__, __high blood pressure__, __sex__, __smoking__ and __death__ should have categorical values instead of int64. We now change this.\n","cceb450b":"Description: In this project we will use 12 factors ( among which age, blood pressure, smoking )  to predict heart failure in various patients. For this purspose, we will explore the Kaggle dataset \"Heart Failure Prediction\"","284988a3":"We will use histograms to grasp an idea about the distribution of the numerical variables","eda42172":"### 3.3 Countplots","cccbbcf8":"## 4. Model creation","6f9d8876":"## 5. Final Comments","18b0f46f":"### 3.5 Boxplots ","9e084904":"### 4.4 AdaBoost"}}