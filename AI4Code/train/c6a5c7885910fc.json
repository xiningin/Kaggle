{"cell_type":{"a555324e":"code","13804017":"code","ff9b6af8":"code","ddb261d1":"code","00f48980":"code","6e8aa19f":"code","6a1fcacd":"code","091dd94d":"code","602808f1":"code","f7c1231d":"code","f2795804":"code","fcdeca1a":"code","4f154b41":"code","e04b106c":"code","aa7e3a9b":"code","30abf9f9":"code","44a55601":"code","75cd0e6d":"code","1f6f9f2e":"code","4082591f":"code","da2a5feb":"code","333176c2":"code","5a2faa65":"code","1408ffff":"markdown","39cc8840":"markdown","614a498f":"markdown","67c62be7":"markdown","4eb7784f":"markdown","36618f55":"markdown","fd78bddf":"markdown","0fa5142e":"markdown","a125c577":"markdown","66ed3ad8":"markdown","8e4fd272":"markdown","09d4de8a":"markdown","e43e28a6":"markdown","e6c586cd":"markdown","c76d107a":"markdown","10eb79d3":"markdown","ba7d4a12":"markdown","d2b9beeb":"markdown","3d6573fa":"markdown","79fc51bb":"markdown","55b8d657":"markdown","c2f51333":"markdown","18dbd084":"markdown","0d3284d0":"markdown","4a8c1390":"markdown"},"source":{"a555324e":"!pip install --upgrade wandb","13804017":"import os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda import amp\n\nfrom sklearn.preprocessing import QuantileTransformer\n\nfrom tqdm import tqdm\nfrom collections import defaultdict","ff9b6af8":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=api_key)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https:\/\/wandb.ai\/authorize')","ddb261d1":"df_train = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/train.csv\")\ndf_train.head()","00f48980":"df_test = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/test.csv\")\ndf_test.head()","6e8aa19f":"df = pd.concat([df_train, df_test], axis=0)\ndf.shape","6a1fcacd":"del df_train, df_test","091dd94d":"feature_cols = [col for col in df.columns if col not in ['Id', 'Cover_Type']]\ntarget_cols = ['Cover_Type']\n\ncat_cols = [col for col in feature_cols if df[col].nunique() < 10]\ncont_cols = [col for col in feature_cols if df[col].nunique() >= 10]","602808f1":"CONFIG = {\n    \"seed\": 42,\n    \"epochs\": 10,\n    \"train_batch_size\": 1024,\n    \"learning_rate\": 1e-3,\n    \"T_max\": 2000,\n    \"min_lr\": 1e-5,\n    \"cat_weight\": 1.\/3,\n    \"cont_weight\": 2.\/3,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n}","f7c1231d":"def set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG[\"seed\"])","f2795804":"qt = QuantileTransformer(output_distribution='normal')\ndf[cont_cols] = qt.fit_transform(df[cont_cols])","fcdeca1a":"class TPSDecDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.cat_features = df[cat_cols].values\n        self.cont_features = df[cont_cols].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        X_cat = self.cat_features[index]\n        X_cont = self.cont_features[index]\n        \n        return X_cat, X_cont","4f154b41":"class DenoisingAutoEncoder(nn.Module):\n    def __init__(self):\n        super(DenoisingAutoEncoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(len(cat_cols) + len(cont_cols), 100),\n            nn.BatchNorm1d(100),\n            nn.ReLU(),\n            nn.Linear(100, 200)\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(200, 100),\n            nn.BatchNorm1d(100),\n            nn.ReLU(),\n        )\n        self.decoder_cat_head = nn.Linear(100, len(cat_cols))\n        self.decoder_cont_head = nn.Linear(100, len(cont_cols))\n        \n    def extract(self, x):\n        features = self.encoder(x)\n        return features\n        \n    def forward(self, x):\n        features = self.encoder(x)\n        output = self.decoder(F.relu(features))\n        cat_output = self.decoder_cat_head(output)\n        cont_output = self.decoder_cont_head(output)\n        \n        return cat_output, cont_output\n    \nmodel = DenoisingAutoEncoder()\nmodel.to(CONFIG['device']);","e04b106c":"def cat_criterion(cat_outputs, cat_targets):\n    return nn.BCEWithLogitsLoss()(cat_outputs, cat_targets)\n\ndef cont_criterion(cont_outputs, cont_targets):\n    return nn.MSELoss()(cont_outputs.view(-1), cont_targets.view(-1))","aa7e3a9b":"def add_swap_noise(X, ratio=.15, return_mask=False):\n    obfuscation_mask = torch.bernoulli(ratio * torch.ones(X.shape)).to(X.device)\n    obfuscated_X = torch.where(obfuscation_mask == 1, X[torch.randperm(X.shape[0])], X)\n    \n    if return_mask:\n        return obfuscated_X, obfuscation_mask\n    \n    return obfuscated_X","30abf9f9":"def test_swap_noise():\n    X_rand = torch.randn(6, 8)\n    print(\"Original Array\")\n    print(X_rand)\n    \n    X_noise = add_swap_noise(X_rand)\n    print(\"Array after noise\")\n    print(X_noise)\n    \ntest_swap_noise()","44a55601":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    scaler = amp.GradScaler()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (X_cat, X_cont) in bar:         \n        X_cat = X_cat.to(device, dtype=torch.float)\n        X_cont = X_cont.to(device, dtype=torch.float)\n        \n        batch_size = X_cat.size(0)\n        \n        X_cat_noise = add_swap_noise(X_cat)\n        X_cat_noise = X_cat_noise.to(device, dtype=torch.float)\n        X_cont_noise = add_swap_noise(X_cont)\n        X_cont_noise = X_cont_noise.to(device, dtype=torch.float)\n        \n        with amp.autocast(enabled=True):\n            X_noise = torch.cat([X_cat_noise, X_cont_noise], dim=1)\n            cat_outputs, cont_outputs = model(X_noise)\n            cat_loss = cat_criterion(cat_outputs, X_cat)\n            cont_loss = cont_criterion(cont_outputs, X_cont)\n            loss = CONFIG['cat_weight']*cat_loss + CONFIG['cont_weight']*cont_loss\n\n        wandb.log({\"Categorical Loss\": cat_loss})\n        wandb.log({\"Continuous Loss\": cont_loss})\n        wandb.log({\"Total Loss\": loss})\n        \n        scaler.scale(loss).backward()\n        \n        scaler.step(optimizer)\n        scaler.update()\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n        \n        if scheduler is not None:\n            scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss \/ dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss","75cd0e6d":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    # To automatically log gradients\n    wandb.watch(model, log_freq=100)\n    \n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    \n    for epoch in range(1, num_epochs + 1):\n            train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n                                               train_loader, device, epoch)\n            print()\n            \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 3600, (time_elapsed % 3600) \/\/ 60, (time_elapsed % 3600) % 60))\n    \n    torch.save(model.state_dict(), 'model.bin')\n    \n    return model","1f6f9f2e":"train_dataset = TPSDecDataset(df)\ntrain_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                          num_workers=2, shuffle=True, pin_memory=True)","4082591f":"optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['T_max'], eta_min=CONFIG['min_lr'])","da2a5feb":"run = wandb.init(project='TPS-Dec', \n                 config=CONFIG,\n                 job_type='Train',\n                 anonymous='must')","333176c2":"model = run_training(model, optimizer, scheduler, \n                     device=CONFIG['device'], \n                     num_epochs=CONFIG['epochs'])","5a2faa65":"run.finish()","1408ffff":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Normalize Continuous Features using Quantile Transformer<\/span>. \n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\"> Check the official documentation <a href=\"https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.QuantileTransformer.html\">here<\/a><\/span>","39cc8840":"# <h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Read the Data \ud83d\udcd6<\/h1>","614a498f":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Dataset Class<\/h1><\/span>","67c62be7":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Swap Noise<\/h1><\/span>","4eb7784f":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Run Training<\/h1><\/span>","36618f55":"<img src=\"https:\/\/i.imgur.com\/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" \/>\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\"> Weights & Biases (W&B) is a set of machine learning tools that helps you build better models faster. <strong>Kaggle competitions require fast-paced model development and evaluation<\/strong>. There are a lot of components: exploring the training data, training different models, combining trained models in different combinations (ensembling), and so on.<\/span>\n\n> <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">\u23f3 Lots of components = Lots of places to go wrong = Lots of time spent debugging<\/span>\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">W&B can be useful for Kaggle competition with it's lightweight and interoperable tools:<\/span>\n\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Quickly track experiments,<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Version and iterate on datasets, <br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Evaluate model performance,<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Reproduce models,<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Visualize results and spot regressions,<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Share findings with colleagues.<\/span>\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">To learn more about Weights and Biases check out this <strong><a href=\"https:\/\/www.kaggle.com\/ayuraj\/experiment-tracking-with-weights-and-biases\">kernel<\/a><\/strong>.<\/span>","fd78bddf":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Function<\/h1><\/span>","0fa5142e":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Swap Noise: Randomly swap values within a column of a dataframe with a specified noise ratio.<\/span> \n\n<blockquote> \u201c15% Swap Noise is a good start value.\u201d <br> \n    - <strong>Michael Jahrer<\/strong>, Porto Seguro Safe Driver Competition Winner\n <\/blockquote>   \n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Implementation borrowed from <a href=\"https:\/\/www.kaggle.com\/c\/tabular-playground-series-jan-2021\/discussion\/216070\">here<\/a><\/span>","a125c577":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Loss Function<\/h1><\/span>","66ed3ad8":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Start Training<\/span>","8e4fd272":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Import Required Libraries \ud83d\udcda<\/h1><\/span>","09d4de8a":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Training Configuration \u2699\ufe0f<\/h1><\/span>","e43e28a6":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">In this Notebook we will: <\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Train a simple Denoising Autoencoder<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Add Swap noise for injecting noise in the data<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Use MSE loss for continuous features<br><\/span>\n* <span style=\"color: #000508; font-family: Segoe UI; font-size: 1.2em; font-weight: 300;\">Use BCE loss for continuous features<br><\/span>","e6c586cd":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Set Seed for Reproducibility<\/h1><\/span>","c76d107a":"![Upvote!](https:\/\/img.shields.io\/badge\/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)","10eb79d3":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Visualization<\/h1><\/span>\n\n<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\"><a href=\"https:\/\/wandb.ai\/dchanda\/TPS-Dec\/runs\/9iw31x0f\">View the Complete Dashboard Here \u2b95<\/a><\/span>","ba7d4a12":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Pipeline<\/h1><\/span>\n\n![](https:\/\/i.imgur.com\/yVWGsOJ.png)","d2b9beeb":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/28007\/logos\/header.png?t=2021-06-30-01-10-51)","3d6573fa":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Model Gradients<\/span>\n![](https:\/\/i.imgur.com\/JvHoqdg.jpg)","79fc51bb":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Create Model<\/h1><\/span>","55b8d657":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Prepare Dataloader<\/span>","c2f51333":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Define Optimizer & Scheduler<\/span>","18dbd084":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Loss Curves<\/span>\n\n![](https:\/\/i.imgur.com\/nkNjiwP.jpg)","0d3284d0":"# <span><h1 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #f6f5f5; color :#fe346e; border-radius: 100px 100px; text-align:center\">Install Required Libraries<\/h1><\/span>","4a8c1390":"<br>\n<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">TPS-December DAE Starter<\/h1>\n<br>"}}