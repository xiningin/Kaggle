{"cell_type":{"d0823562":"code","b6e40a8f":"code","226c504b":"code","527e4af2":"code","d6809a26":"code","aee92a8e":"code","2ab33e58":"code","e61e03ff":"code","b735b28e":"code","dae2251e":"code","051230d7":"code","47ea2a97":"code","32ecd21a":"code","5e8517fb":"code","9e4c2869":"code","7de6f545":"code","87f00f30":"code","74caa781":"code","317a8e22":"code","8c3c4e9d":"code","49d1f616":"code","7c300cf1":"code","f95c4359":"code","9bcda980":"code","ad18e854":"code","5edd474e":"code","5984db47":"code","7a652c92":"code","2b48c434":"code","c53a35b8":"code","831ffbf0":"code","34a16b31":"code","7d9a32c1":"code","bd786469":"code","8a10ccc2":"code","e2e83581":"code","a1fb1a35":"code","f59da7ae":"code","a57eb27b":"code","6e03a748":"code","f9484c37":"code","c6d9e6bf":"markdown","4fc0c365":"markdown","08139f08":"markdown","fa9c0c59":"markdown","16903d8b":"markdown","5cd3870f":"markdown","7f107383":"markdown","7bad9219":"markdown","7e18d5c6":"markdown","5158e026":"markdown","231dff72":"markdown","fdea058e":"markdown","6f4efe2c":"markdown","ad3e4ada":"markdown","e5e3a1f9":"markdown","0bfa983a":"markdown"},"source":{"d0823562":"\nimport re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch","b6e40a8f":"df=pd.read_csv(\"..\/input\/sms-spam-collection-dataset\/spam.csv\",encoding = \"latin\")","226c504b":"# Display top 5 data\ndf.head()","527e4af2":"df.info()","d6809a26":"df.describe()","aee92a8e":"df.shape","2ab33e58":"df.dtypes","e61e03ff":"df.isnull().sum()","b735b28e":"df.isnull().all()","dae2251e":"df.columns","051230d7":"df=df.drop([ 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1)","47ea2a97":"df","32ecd21a":"#rename\ndf=df.rename({'v1':'Class','v2':'SMS'},axis=1)","5e8517fb":"df","9e4c2869":"#remove duplicate\ndf_duplicate=df[df.duplicated()]\ndf_duplicate","7de6f545":"df.groupby('Class').describe().T","87f00f30":"#Let's make a new column to detect how long the text messages are:\ndf['length'] = df['SMS'].apply(len)\ndf.head()","74caa781":"plt.figure(figsize = (10, 5))\nx=df.Class.value_counts()\nsns.countplot(x= \"Class\",data= df)","317a8e22":"#let's check length of SMS\nplt.figure(figsize = (10, 5))\nbins = 1.15**(np.arange(0,50))\nplt.hist(df[df['Class']=='ham']['length'],bins=bins,alpha=0.8)\nplt.hist(df[df['Class']=='spam']['length'],bins=bins,alpha=0.8)\nplt.legend(('ham','spam'))\nplt.show()","8c3c4e9d":"# get all the ham and spam emails\nham_msg = df[df.Class =='ham']\nspam_msg = df[df.Class=='spam']\n\n# For ham and spam messages, create numpy list to visualize using wordcloud\nham_msg_text = \" \".join(ham_msg.SMS.to_numpy().tolist())\nspam_msg_text = \" \".join(spam_msg.SMS.to_numpy().tolist())","49d1f616":"# Generate a word cloud image\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nstopwords = set(STOPWORDS)\nmask = np.array(Image.open(\"..\/input\/input-img\/email_mask1.png\"))\n\n\nwordcloud_ham = WordCloud(stopwords=stopwords, background_color=\"white\", mode=\"RGBA\", max_words=1000, mask=mask).generate(ham_msg_text)\n\n# create coloring from image\nimage_colors = ImageColorGenerator(mask)\nplt.figure(figsize=[15,18])\nplt.imshow(wordcloud_ham.recolor(color_func=image_colors), interpolation=\"bilinear\")\nplt.title(\"WordCloud of ham\")\nplt.axis(\"off\")\n\n# store to file\nplt.savefig(\"ham.png\", format=\"png\")\n\nplt.show()","7c300cf1":"# Generate a word cloud image\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nstopwords = set(STOPWORDS)\nmask = np.array(Image.open(\"..\/input\/input-img\/color_email_mask.png\"))\n\n\nwordcloud_ham = WordCloud(stopwords=stopwords, background_color=\"white\", mode=\"RGBA\", max_words=1000, mask=mask).generate(spam_msg_text)\n\n# create coloring from image\nimage_colors = ImageColorGenerator(mask)\nplt.figure(figsize=[15,18])\nplt.imshow(wordcloud_ham.recolor(color_func=image_colors), interpolation=\"bilinear\")\n\nplt.axis(\"off\")\n\n# store to file\nplt.savefig(\"spam.png\", format=\"png\")\nplt.title(\"WordCloud of spam\")\nplt.show()","f95c4359":"from string import punctuation\nfrom nltk import PorterStemmer\nfrom nltk import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n#from gensim.utils import lemmatize\nfrom string import punctuation\nimport re\nfrom string import punctuation\nimport nltk\nfrom nltk.stem.porter import *\nps=PorterStemmer()\n\n\nSTOPWORDS=set(stopwords.words('english'))\n\n#Remove Punctuation\ndef remove_punctuation(word):\n    result = ''.join(c for c in word if c not in punctuation)\n    return result\n\n\n#Vectorize the sentance\ndef tockenize(word):\n    result=re.split('\\W+',word)\n    return result  \n\n\n#Remove stop words\ndef remove_stop_words(words):\n    result = [c for c in words if c not in STOPWORDS]\n    return result    \n\n\ndef stemming(tokenized_row):\n    stemmed_text=[ps.stem(char) for char in tokenized_row]\n    return stemmed_text","9bcda980":"df['remove_punc']= df['SMS'].apply(remove_punctuation)\ndf['tokenized_row']=df['remove_punc'].apply(lambda row:tockenize(row.lower()))\ndf['remove_sword']= df['tokenized_row'].apply(remove_stop_words)\ndf['stemmed_text']=df['remove_sword'].apply(lambda char :stemming(char))\n\ndf[['SMS','stemmed_text']].head()","ad18e854":"def final_text(stemmed_text):\n    final_text=\" \".join(char for char in stemmed_text)\n    return final_text","5edd474e":"df['final_text']=df['stemmed_text'].apply(lambda x:final_text(x))","5984db47":"df.head()","7a652c92":"df=df.drop(['remove_punc','tokenized_row','remove_sword','stemmed_text'],axis=1)","2b48c434":"df.head()","c53a35b8":"def dictionary(check):\n    check = check.str.extractall('([a-zA_Z]+)')\n    check.columns = ['check']\n    b = check.reset_index(drop=True)\n    check = b['check'].value_counts()\n    \n    dictionary = pd.DataFrame({'word': check.index, 'freq': check.values})\n    dictionary.index = dictionary['word']\n    dictionary.drop('word', axis = 1, inplace=True)\n    dictionary.sort_values('freq', inplace= True, ascending= False)\n    \n    return dictionary\n\ndictionary_clean = dictionary(df['final_text'])\ndictionary_clean[:20].plot(kind = 'barh',figsize = (10,10))","831ffbf0":"x=df.drop(['Class'],axis=1)\ny=df['Class']","34a16b31":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","7d9a32c1":"from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\ncv=CountVectorizer(max_features=500)\ntemp_train=cv.fit_transform(x_train['final_text']).toarray()\ntemp_test=cv.transform(x_test['final_text']).toarray()","bd786469":"tf=TfidfTransformer()\ntemp_train=tf.fit_transform(temp_train)\ntemp_test=tf.transform(temp_test)","8a10ccc2":"temp_train=pd.DataFrame(temp_train.toarray(),index=x_train.index)\ntemp_test=pd.DataFrame(temp_test.toarray(),index=x_test.index)\nx_train=pd.concat([x_train,temp_train],axis=1,sort=False)\nx_test=pd.concat([x_test,temp_test],axis=1,sort=False)","e2e83581":"x_train.head()","a1fb1a35":"x_train.drop(['SMS','final_text'],axis=1,inplace=True)\nx_test.drop(['SMS','final_text'],axis=1,inplace=True)\nx_train.head()","f59da7ae":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score","a57eb27b":"from sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier()\nmodel.fit(x_train,y_train)\ny_pred=model.predict(x_test)\nprint(\"Accuracy_Score:\",accuracy_score(y_test,y_pred))","6e03a748":"from sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier()\nmodel.fit(x_train,y_train)\ny_pred=model.predict(x_test)\nprint(\"Accuracy_score:\",accuracy_score(y_test,y_pred))","f9484c37":"model.score(x_test,y_test)","c6d9e6bf":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">1. Import Libraries \ud83d\udcc1<\/h1> Lets import the Python libraries","4fc0c365":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">Happy Learnig!!  \ud83d\ude0a<\/h1>","08139f08":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">5. Data Pre-Processing\u2699\ufe0f<\/h1>","fa9c0c59":"![Capture1.JPG](attachment:1ba8addf-9326-46ee-b8fa-5e5e68899300.JPG)<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">Introduction \ud83d\udcda <\/h1>\nToday's era internet and social media have become fastest way to communication. SMS is easiest way of billion mobile users for sharing information. To have effective communication, spam filtering is one of the important feature.","16903d8b":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">Problem Statement  \ud83c\udfaf <\/h1>In this notebook , we will explore and understand the process of classifying emails as spam or not spam.","5cd3870f":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">6.Data Modeling \u26cf\ufe0f<\/h1>","7f107383":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">2. Load dataset \ud83d\udcc1<\/h1> It contains 5573 rows and 2 columns. Each row represents the message in the text is spam or ham(not spam).","7bad9219":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">\ud83d\udcc8 4.Data Visualization \ud83d\udcc8<\/h1>","7e18d5c6":"**cleaning data**","5158e026":"**Words Frequency**\n\nCan be used to check whether or not there are still words frequantly occur but not meaningful","231dff72":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">If you find it is useful, please give appreciation with an UPVOTE!! \ud83d\udc4d  <\/h1>","fdea058e":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\">3. Exploratory Data Analysis(EDA)\ud83d\ude80<\/h1>","6f4efe2c":"<h1 style=\"background-color:ffffff;font-size:20px;font-family:Courier;color:#045F5F;font-weight : bold;text-align:left\"> WordCloud Image \u2601\ufe0f<\/h1>","ad3e4ada":"**you can visit my notebook [Custom Word Cloud](http:\/\/https:\/\/www.kaggle.com\/tarzon\/custom-word-cloud), This notebook explained in detail how to create custom word cloud. You can also download the mask images from [Word cloud mask image](http:\/\/https:\/\/www.kaggle.com\/tarzon\/input-img)**","e5e3a1f9":"<h6 style=\"background-color:ffffff;font-size:40px;font-family:Courier;color:#045F5F;font-weight:bold;text-align: center; \"> Spam \ud83d\udce7 Detection \ud83c\udf73 <\/h6>","0bfa983a":"**Data Splitting**"}}