{"cell_type":{"cc0862fb":"code","8e7247a9":"code","8978b82c":"code","3b65598b":"code","1b07ed69":"code","1085536e":"code","2414aa59":"code","6d276c4e":"code","7605c30f":"code","90b0e6ef":"code","0e60b9aa":"code","1bb17cf8":"code","d516d7ff":"code","fcc4dadd":"code","84086cfe":"code","39fb1412":"code","85c4a5d9":"code","5454f9eb":"code","167862d8":"code","87b2710d":"code","e98d29c1":"code","50126dda":"code","107acc50":"code","59d058cb":"code","4ded0688":"code","ac35d245":"code","b0862661":"code","885e7519":"code","81bf5e80":"markdown","368560fe":"markdown","0900e1a5":"markdown","4ce797e9":"markdown","e3c77cb1":"markdown","cfa9963a":"markdown","61f52074":"markdown","161269d4":"markdown","7c7a3c05":"markdown"},"source":{"cc0862fb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8e7247a9":"df=pd.read_csv(\"..\/input\/creditcard.csv\")\ndf.describe()","8978b82c":"df.head(10)","3b65598b":"import seaborn as sns\nsns.heatmap(df.isnull())\nprint(\"NULL VALUES COUNT:\\n\",df.isnull().sum())","1b07ed69":"import seaborn as sns\nsns.heatmap(df.corr())","1085536e":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize = (20, 25))\nj = 0\n#Droping_Characters and string coloums because graph donot support them\n\nfor i in df.columns:\n    plt.subplot(6, 6, j+1)\n    j += 1\n    sns.distplot(df[i][df['Class']==1], color='g', label = 'Normal')\n    sns.distplot(df[i][df['Class']==0], color='r', label = 'Fruad')\n    plt.legend(loc='best')\nfig.suptitle('Fruad detection ')\nfig.tight_layout()\nfig.subplots_adjust(top=0.95)\nplt.show()","2414aa59":"from matplotlib.pyplot import pie, axis, show\nfruad=len(df[df.Class==1])\nnormal=len(df[df.Class==0])\npie([fruad,normal], labels=[\"fruad:  \"+str(fruad\/(fruad+normal)),\"Normal: \"+str(normal\/(fruad+normal))], pctdistance=1.1, labeldistance=1.2);\nshow()","6d276c4e":"for column in df:\n    plt.figure()\n    sns.boxplot(x=df[column])","7605c30f":"\nNormal_df=df.drop(\"Class\",axis=1)\nNormal_df=Normal_df.drop(\"Amount\",axis=1)\n\nfor column in Normal_df:\n    plt.figure()\n    sns.boxplot(x=Normal_df[column])","90b0e6ef":"print(Normal_df.shape)\nz_Scored_df=pd.DataFrame(Normal_df)\nfrom scipy import stats\nz_Scored_df=z_Scored_df[(np.abs(stats.zscore(Normal_df)) <1).all(axis=1)]\nz_Scored_df.shape","0e60b9aa":"df_y=df[\"Class\"]\nz_Scored_df=z_Scored_df.merge(df_y.to_frame(), left_index=True, right_index=True)\nz_Scored_df.shape\n\nfor i in z_Scored_df:\n    plt.figure()\n    sns.boxplot(x=z_Scored_df[i])","1bb17cf8":"z_Scored_df=z_Scored_df.merge(df[\"Amount\"].to_frame(), left_index=True, right_index=True)\nz_Scored_df.shape","d516d7ff":"#appending Fraud examples with normal\ndf_fruad=df[df.Class ==1]\nz_Scored_df=z_Scored_df.append(df_fruad)\nlen(z_Scored_df)","fcc4dadd":"from matplotlib.pyplot import pie, axis, show\nfruad=len(z_Scored_df[z_Scored_df.Class==1])\nnormal=len(z_Scored_df[z_Scored_df.Class==0])\npie([fruad,normal], labels=[\"fruad:  \"+str(fruad\/(fruad+normal)),\"Normal: \"+str(normal\/(fruad+normal))], pctdistance=1.1, labeldistance=1.2);\nshow()","84086cfe":"x=z_Scored_df.drop(\"Class\",axis=1)\ny=z_Scored_df[\"Class\"]","39fb1412":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n   x,y, test_size=0.3, random_state=0)","85c4a5d9":"sns.heatmap(x.isnull())","5454f9eb":"from sklearn import ensemble\n\nclf=ensemble.AdaBoostClassifier()\nclf.fit(X_train,y_train)","167862d8":"from sklearn import metrics\ny_pred=clf.predict(X_test)\ndf_confusion=metrics.confusion_matrix(y_test, y_pred)","87b2710d":"from sklearn.metrics import confusion_matrix\nprediction=clf.predict(X_test)\ny_pred=[]\nfor i in prediction:\n    y_pred.append(i.argmax())\ny_pred=np.asarray(y_pred)\ntrue_negative,false_positive,false_negative,true_positive=confusion_matrix(y_test, y_pred).ravel()\n\nprint(\"true_negative: \",true_negative)\nprint(\"false_positive: \",false_positive)\nprint(\"false_negative: \",false_negative)\nprint(\"true_positive: \",true_positive)\nprint(\"\\n\\n Accuracy Measures\\n\\n\")\nSensitivity=true_positive\/(true_positive+false_negative)\nprint(\"Sensitivity: \",Sensitivity)\n\nFalse_Positive_Rate=false_positive\/(false_positive+true_negative)\nprint(\"False_Positive_Rate: \",False_Positive_Rate)\n\nSpecificity=true_negative\/(false_positive + true_negative)\nprint(\"Specificity: \",Specificity)\n\n#FDR \u00e0 0 means that very few of our predictions are wrong\nFalse_Discovery_Rate=false_positive\/(false_positive+true_positive)\nprint(\"False_Discovery_Rate: \",False_Discovery_Rate)\n\nPositive_Predictive_Value =true_positive\/(true_positive+false_positive)\nprint(\"Positive_Predictive_Value: \",Positive_Predictive_Value)","e98d29c1":"from sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import average_precision_score\nfrom matplotlib import pyplot\nfrom sklearn.metrics import auc\nf1 = f1_score(y_test,prediction)\n# calculate precision-recall AUC\nprecision, recall, thresholds = precision_recall_curve(y_test, prediction)\nauc = auc(recall, precision)\n\nap = average_precision_score(y_test,prediction)\nprint('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))\n# plot no skill\npyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n# plot the roc curve for the model\npyplot.plot(recall, precision, marker='.')\n# show the plot\npyplot.show()","50126dda":"from sklearn.metrics import classification_report,accuracy_score\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\ndf=pd.read_csv(\"..\/input\/creditcard.csv\")\n","107acc50":"Fraud = df[df['Class']==1]\n\nValid = df[df['Class']==0]\n\noutlier_fraction = len(Fraud)\/float(len(Valid))\n","59d058cb":"from sklearn.model_selection import train_test_split\nx=df.drop(\"Class\",axis=1)\ny=df[\"Class\"]\nstate = np.random.RandomState(42)\nX_outliers = state.uniform(low=0, high=1, size=(x.shape[0], x.shape[1]))\nX_train, X_test, y_train, y_test = train_test_split(\n   x,y, test_size=0.1, random_state=0)","4ded0688":"classifiers = {\n    \n    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=10, algorithm='auto', \n                                              leaf_size=30, metric='euclidean',\n                                              p=2, metric_params=None,  novelty=True,contamination=0.023)\n    \n}","ac35d245":"n_outliers = len(Fraud)\nfor i, (clf_name,clf) in enumerate(classifiers.items()):\n    #Fit the data and tag outliers\n    if clf_name == \"Local Outlier Factor\":\n        clf.fit(X_train)\n        y_pred =clf.predict(X_train)\n        scores_prediction = clf.negative_outlier_factor_\n        \n        \n   #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n    y_pred[y_pred == 1] = 0\n    y_pred[y_pred == -1] = 1\n    n_errors = (y_pred != y_train).sum()\n    # Run Classification Metrics\n    print(\"{}: {}\".format(clf_name,n_errors))\n    print(\"Accuracy Score :\")\n    print(accuracy_score(y_train,y_pred))\n    print(\"Classification Report :\")\n    print(classification_report(y_train,y_pred))","b0862661":"from sklearn.metrics import confusion_matrix\ny_pred=clf.predict(X_test)\n\ny_pred[y_pred == 1] = 0\ny_pred[y_pred == -1] = 1\ntrue_negative,false_positive,false_negative,true_positive=confusion_matrix(y_test,y_pred).ravel()\n\nprint(\"true_negative: \",true_negative)\nprint(\"false_positive: \",false_positive)\nprint(\"false_negative: \",false_negative)\nprint(\"true_positive: \",true_positive)\nprint(\"\\n\\n Accuracy Measures\\n\\n\")\nAccuracy=(true_positive+true_negative)\/(true_positive+false_negative+true_negative+false_positive)\nprint(\"Accuracy: \",Sensitivity)\n\nSensitivity=true_positive\/(true_positive+false_negative)\nprint(\"Sensitivity: \",Sensitivity)\n\nFalse_Positive_Rate=false_positive\/(false_positive+true_negative)\nprint(\"False_Positive_Rate: \",False_Positive_Rate)\n\nSpecificity=true_negative\/(false_positive + true_negative)\nprint(\"Specificity: \",Specificity)\n\n#FDR \u00e0 0 means that very few of our predictions are wrong\nFalse_Discovery_Rate=false_positive\/(false_positive+true_positive)\nprint(\"False_Discovery_Rate: \",False_Discovery_Rate)\n\nPositive_Predictive_Value =true_positive\/(true_positive+false_positive)\nprint(\"Positive_Predictive_Value: \",Positive_Predictive_Value)","885e7519":"plt.title(\"Local Outlier Factor (LOF)\")\nplt.scatter(X_train.iloc[:, 1], X_train.iloc[:, 2], color='k', s=3., label='Data points')\n# plot circles with radius proportional to the outlier scores\nradius = (scores_prediction.max() - scores_prediction) \/ (scores_prediction.max() - scores_prediction.min())\nplt.scatter(X_train.iloc[:, 1], X_train.iloc[:, 2], s=1000 * radius, edgecolors='r',\n            facecolors='none', label='Outlier scores')\nplt.axis('tight')\n\nplt.xlabel(\"prediction errors: %d\" % (n_errors))\nlegend = plt.legend(loc='upper left')\nlegend.legendHandles[0]._sizes = [10]\nlegend.legendHandles[1]._sizes = [20]\nplt.show()","81bf5e80":"**Lets see for outliers so that we can reduce some rows from data that might be helpful**","368560fe":"**Introduction.**\n* Visualization\n    * Missing  Values analysis\n    * Co-Relation Analysis\n    * Outlier Analysis\n    *  LOF Classifier Example","0900e1a5":"**Clustring**","4ce797e9":"**Removing Outliers with Z-Scores **\nNormally outliers Z_Score are greater than 3 but I am going to select only values whose Z_scores are smaller than 2","e3c77cb1":"**To much unstable dataset**","cfa9963a":"Lets see how much examples we have are positive(fraud) and how much are negative (normal)","61f52074":"**Lets see The Distribution of the  frauds **","161269d4":"**Problem:**\nthese outliers are useful because we are also searching for outliers. \n**Remeber  normal transaction are not our intresrt \nother than normal (fraud) is our Area of Intrest**\n\n**Solution:**\nWe will only take outliers from normal data and prune outliers from that data\nWe will also drop colum amount because high and low both amout  can be happen in frauds  ","7c7a3c05":"Dataframe Descibe function.\nif you have\n* Categorical values\n* String\n* Objects\n[Link](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.describe.html)"}}