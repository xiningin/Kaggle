{"cell_type":{"db8134e1":"code","c55c13ab":"code","6f5d8819":"code","722a2214":"code","c6b89baf":"code","2393aad7":"code","e62a92a5":"code","190e8937":"code","787ee835":"code","540a2eb9":"code","e8ca6b4e":"code","a94e3219":"code","1798d7b6":"code","35f2bbb3":"code","7350046e":"code","79848711":"code","f9c23e1e":"code","8b365b02":"markdown","17240ab5":"markdown","ab259706":"markdown","9c9730de":"markdown","6fd0b700":"markdown","542fc887":"markdown","375728ac":"markdown","08879add":"markdown","dddc0dd7":"markdown","343bcff7":"markdown","b520e5c1":"markdown","873c3c87":"markdown"},"source":{"db8134e1":"import pandas as pd\nimport nltk \nnltk.download('stopwords')                 # download the stopwords from NLTK\n\nimport re                                  # library for regular expression operations\nimport string                              # for string operations\n\nfrom nltk.corpus import stopwords          # module for stop words that come with NLTK\nfrom nltk.stem import PorterStemmer        # module for stemming\nfrom nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n\nfrom sklearn.linear_model import LogisticRegression  \nfrom sklearn.feature_extraction.text import CountVectorizer  \nfrom sklearn.model_selection import train_test_split  \nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt            # library for visualization\nimport seaborn as sns","c55c13ab":"df = pd.read_csv('..\/input\/amazon-alexa\/amazon_alexa.csv')\ndf","6f5d8819":"df = df.drop(['rating', 'date', 'variation'], axis = 1)\ndf","722a2214":"df.isnull().any()  # checking for null values","c6b89baf":"df.info()","2393aad7":"def process_rev(rev):\n    \"\"\"Process review function.\n    Input:\n        rev: a string containing a review\n    Output:\n        rev_clean: a list of words containing the processed review\n\n    \"\"\"\n    stemmer = PorterStemmer()\n    stopwords_english = stopwords.words('english')\n    # tokenize reviews\n    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n                               reduce_len=True)\n    rev_tokens = tokenizer.tokenize(rev)\n\n    rev_clean = []\n    for word in rev_tokens:\n        if (word not in stopwords_english and  # remove stopwords\n                word not in string.punctuation):  # remove punctuation\n            # rev_clean.append(word)\n            stem_word = stemmer.stem(word)  # stemming word\n            rev_clean.append(stem_word)\n\n    return rev_clean","e62a92a5":"# using the process_rev function for:\n# 1. Removing stop words\n# 2. Tokenization\n# 3. Stemming\nA = []\na = df['verified_reviews']\nfor i in a:\n  i = process_rev(i)\n  A.append(i)\ndf['verified_reviews'] = A\ndf","190e8937":"cv = CountVectorizer(max_features=1500, analyzer='word', lowercase=False) ","787ee835":"df['verified_reviews'] = df['verified_reviews'].apply(lambda x: \" \".join(x) )  # to join all words in the lists\nX = cv.fit_transform(df['verified_reviews'])  # predictor variable 'X'","540a2eb9":"df","e8ca6b4e":"y = pd.DataFrame(df['feedback'])  # respose variable 'y'\ny.head()","a94e3219":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)  # splitting in the ratio 80:20","1798d7b6":"classifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","35f2bbb3":"y_pred = classifier.predict(X_test)\ny_pred","7350046e":"roc_auc_score(y_test, y_pred)","79848711":"cm = confusion_matrix(y_test, y_pred)\ncm","f9c23e1e":"plt.figure(figsize=(6,6))\nsns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=0.5, square = True, cmap = 'Pastel1')\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nall_sample_title = 'Accuracy Score: {0}'.format(roc_auc_score(y_test, y_pred))\nplt.title(all_sample_title, size = 15)","8b365b02":"### Data Preprocessing","17240ab5":"### Model","ab259706":"# Amazon Alexa Reviews Analysis","9c9730de":"### Checking Accuracy","6fd0b700":"# Predictions are 68.25% accurate.","542fc887":"### Results' Visualization","375728ac":"### Getting our Data","08879add":"### Making Predictions","dddc0dd7":"### Importing Libraries","343bcff7":"### Vectorizing","b520e5c1":"### Splitting for Training and Testing","873c3c87":"### The aim is to analyse Alexa's reviews by NLP. If the feedback is positive, the result is 1, else it is 0. Using logistic regression, I have tried to classify the feedback as positive or negative."}}