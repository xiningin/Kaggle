{"cell_type":{"df9f20b7":"code","7bcc0583":"code","c14942c4":"code","c6e3c91c":"code","cebca199":"code","111fbf56":"code","8a6669f4":"code","10085abe":"code","b450cf2e":"code","82a5ca20":"code","2c6f6f0d":"code","cd0fdebb":"code","a1d8fc0f":"code","75a3fb3f":"code","a44bd376":"code","8cbebbcb":"code","d63c95a0":"code","16ecf948":"code","6fa2731b":"code","c73c8b59":"code","ac5d814f":"code","84667c9a":"code","a350cccf":"code","b299a29c":"code","62a98dc9":"code","68555bf4":"code","9b0d7ff8":"code","8203faa0":"code","51fe9ac6":"code","cb457dfd":"code","fef99191":"code","c34a2c3e":"code","72496152":"code","f1f9a3ed":"code","9db6831c":"code","8465f1bc":"code","6ce93c21":"code","d973b331":"code","621b7b3c":"code","e9ff1eec":"code","6c038177":"code","36afadbc":"code","329b64fc":"code","662e5086":"code","2b32822d":"code","830a0c1f":"code","8d3e1b06":"code","f3b3a4ed":"code","64302b52":"code","700cb00f":"code","460e7113":"code","3e23da4d":"code","fe00c01d":"code","7c412eba":"code","5d5ea152":"code","a6e1614d":"code","1f4fdcdc":"code","4e33f0b4":"code","d11b6ad0":"code","39db1aa7":"code","2713a793":"code","2c16de4a":"code","56ef7fd5":"code","c78200e7":"code","b62be30a":"code","5582ef00":"code","90d05fa6":"code","f8ae9158":"code","262a8b27":"code","657d53b5":"code","a774cac4":"code","6bab9f68":"code","36e1c1cc":"code","1ff6fa7f":"code","a45221f7":"markdown","e47cd8d2":"markdown","0d7aa081":"markdown","17e26420":"markdown","cd47acc6":"markdown","c7873347":"markdown","2160904b":"markdown","6223bb38":"markdown","f0aed6fc":"markdown","17cddc4d":"markdown","f52d9848":"markdown","530363dd":"markdown","91382a29":"markdown","0eefb33d":"markdown","06de8c42":"markdown","be900f59":"markdown","4dcc8215":"markdown","b87f7260":"markdown"},"source":{"df9f20b7":"# Bu Python 3 ortam\u0131, y\u00fckl\u00fc bir\u00e7ok yard\u0131mc\u0131 analiz kitapl\u0131\u011f\u0131 ile birlikte gelir\n# Kaggle\/python Docker g\u00f6r\u00fcnt\u00fcs\u00fc ile tan\u0131mlan\u0131r: https:\/\/github.com\/kaggle\/docker-python\n# \u00d6rne\u011fin, y\u00fcklenecek birka\u00e7 yard\u0131mc\u0131 paket var\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Giri\u015f verileri dosyalar\u0131 salt okunur \"..\/input\/\" dizininde bulunur\n# \u00d6rne\u011fin, bunu \u00e7al\u0131\u015ft\u0131rmak (\u00e7al\u0131\u015ft\u0131r'\u0131 t\u0131klatarak veya Shift+Enter tu\u015flar\u0131na basarak) giri\u015f dizini alt\u0131ndaki t\u00fcm dosyalar\u0131 listeleyecektir.\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# \"Save & Run All\" se\u00e7ene\u011fini kullanarak bir s\u00fcr\u00fcm olu\u015fturdu\u011funuzda \u00e7\u0131kt\u0131 olarak korunan ge\u00e7erli dizine (\/kaggle\/working\/) 5GB'a kadar yazabilirsiniz.\n# \/kaggle\/temp\/ dizinine ge\u00e7ici dosyalar da yazabilirsiniz, ancak bunlar ge\u00e7erli oturumun d\u0131\u015f\u0131nda kaydedilmez\n\nimport statsmodels.api as sm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning) \n\n%config InlineBackend.figure_format = 'retina'\n\n# t\u00fcm s\u00fctunlar\u0131 ve sat\u0131rlar\u0131 g\u00f6r\u00fcnt\u00fclemek i\u00e7in:\npd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);  # to display all columns and rows\npd.set_option('display.float_format', lambda x: '%.2f' % x) # The number of numbers that will be shown after the comma.\n","7bcc0583":"#Veri setini okuma\ndf = pd.read_csv(\"..\/input\/diabetes-data-set\/diabetes.csv\")","c14942c4":"#Veri Setinin boyutu\ndf.shape","c6e3c91c":"#belirtilen de\u011ferlere g\u00f6re veri setiyle ilgili istatistiki veriler\ndf.describe([0.10,0.25,0.50,0.75,0.90,0.95,0.99]).T","cebca199":"##Veri setinin y\u00fczde ka\u00e7\u0131 diabet hastas\u0131(1) y\u00fczde ka\u00e7\u0131 diabet hastas\u0131 de\u011fil(0)\ndf[\"Outcome\"].value_counts()*100\/len(df)","111fbf56":"#Diabet olan ve diabet olmayanlar\u0131n say\u0131s\u0131n\u0131 \u00f6\u011frendik. 268 ki\u015fi diabet hastas\u0131 ve 500 ki\u015fi diabet hastas\u0131 de\u011fil\ndf.Outcome.value_counts()","8a6669f4":"#Ya\u015f aral\u0131\u011f\u0131na g\u00f6re da\u011f\u0131l\u0131m\ndf[\"Age\"].hist(edgecolor = \"black\");","10085abe":"#Burda her kolonda ka\u00e7 bo\u015f de\u011fer var bunun kontrol\u00fcn\u00fc yapt\u0131k. Hi\u00e7 bo\u015f de\u011fer g\u00f6r\u00fcnm\u00fcyor.\ndf.isnull().sum()","b450cf2e":"#Burda ise verdi\u011fimiz s\u00fctunlarda de\u011feri 0 olan alanlar\u0131 NaN olarak de\u011fi\u015ftirdik.\ndf[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0, np.NaN)","82a5ca20":"#Her kolondaki bo\u015f de\u011ferlerin toplam\u0131\ndf.isnull().sum()","2c6f6f0d":"#Her s\u00fctun i\u00e7in dolu ve eksik de\u011ferleri g\u00f6steren da\u011f\u0131l\u0131m grafi\u011fi\nimport missingno as msno\nmsno.bar(df);","cd0fdebb":"def carp(x,y):\n    \n    z = x*y\n    \n    return z\n","a1d8fc0f":"carp(4,5)","75a3fb3f":"# Eksik de\u011ferler bu fonksiyon ile her bir de\u011fi\u015fkenin medyan de\u011ferleri ile doldurulacakt\u0131r.\n\ndef median_target(var):   \n    \n    temp = df[df[var].notnull()]\n    \n    temp = temp[[var, 'Outcome']].groupby(['Outcome'])[[var]].median().reset_index()\n    \n    return temp","a44bd376":"columns = df.columns\n\ncolumns = columns.drop(\"Outcome\")","8cbebbcb":"columns","d63c95a0":"# median_target fonksiyonu ile eksik de\u011ferlere dolu de\u011ferlerin medyan\u0131n\u0131 atad\u0131k ve outcome'a g\u00f6re gruplad\u0131k.\nmedian_target('Glucose')","16ecf948":"# Eksik g\u00f6zlemler i\u00e7in verilecek de\u011ferlere hasta olmayanlar\u0131n ortanca de\u011feri ve hasta olanlar\u0131n ortanca de\u011ferleri verilir.\ncolumns = df.columns\n\ncolumns = columns.drop(\"Outcome\")\n\nfor col in columns:\n    \n    df.loc[(df['Outcome'] == 0 ) & (df[col].isnull()), col] = median_target(col)[col][0]\n    df.loc[(df['Outcome'] == 1 ) & (df[col].isnull()), col] = median_target(col)[col][1]","6fa2731b":"#Hasta olmayanlar\u0131n(0) Pregnancies(Gebelik) de\u011feri bo\u015f olanlar\u0131 g\u00f6steriyor. Yokmu\u015f.\ndf.loc[(df['Outcome'] == 0 ) & (df[\"Pregnancies\"].isnull()), \"Pregnancies\"]","c73c8b59":"#Hasta olmayanlar\u0131n(0) BloodPressure(diyastolik kan bas\u0131nc\u0131) de\u011feri bo\u015f olanlar\u0131 g\u00f6steriyor.\ndf[(df['Outcome'] == 0 ) & (df[\"BloodPressure\"].isnull())]","ac5d814f":"Q1 = df[\"BloodPressure\"].quantile(0.25) #\u0130stenen s\u00fctunda verilen nicelikteki de\u011ferleri d\u00f6nd\u00fcr\u00fcr yani BloodPressure alan\u0131 0.25 olanlar\u0131 d\u00f6nd\u00fcrecek.\nQ3 = df[\"BloodPressure\"].quantile(0.75) #Burdada BloodPressure alan\u0131 0.75 olanlar\u0131 d\u00f6nd\u00fcrecek.\nIQR = Q3-Q1 #0.75 de\u011ferlerin say\u0131s\u0131 - 0.25 de\u011ferler\nlower = Q1 - 1.5*IQR #0.25 de\u011ferler - 1.5*aradaki fark(IQR)\nupper = Q3 + 1.5*IQR #0.75 de\u011ferler - 1.5*aradaki fark(IQR)","84667c9a":"lower","a350cccf":"upper","b299a29c":"#Burda .any ile 104.0 de\u011ferinden daha b\u00fcy\u00fck de\u011ferler var m\u0131 yok mu onu kontrol ettik ve True d\u00f6nd\u00fcrd\u00fc yani daha b\u00fcy\u00fck de\u011fer var. \ndf[(df[\"BloodPressure\"] > upper)].any(axis=None) ","62a98dc9":"for feature in df:\n    print(feature)","68555bf4":"for feature in df:\n    \n    Q1 = df[feature].quantile(0.05)\n    Q3 = df[feature].quantile(0.95)\n    IQR = Q3 - Q1\n    lower = Q1 - 1.5*IQR\n    upper = Q3 + 1.5*IQR\n    \n    if df[(df[feature] > upper)].any(axis=None):\n        print(feature,\"yes\")\n    else:\n        print(feature, \"no\")","9b0d7ff8":"df.head()","8203faa0":"df.shape","51fe9ac6":"# BMI'ye g\u00f6re baz\u0131 aral\u0131klar belirlendi ve kategorik de\u011fi\u015fkenler atand\u0131.\nNewBMI = pd.Series([\"Underweight\", \"Normal\", \"Overweight\", \"Obesity 1\", \"Obesity 2\", \"Obesity 3\"], dtype = \"category\")\n#Yukarda kategoriler belirlendi ve a\u015fa\u011f\u0131daki kodlarla hangi aral\u0131\u011fa hangi kategori gelece\u011fi belirlendi.\ndf[\"NewBMI\"] = NewBMI\n\ndf.loc[df[\"BMI\"] < 18.5, \"NewBMI\"] = NewBMI[0]\n\ndf.loc[(df[\"BMI\"] > 18.5) & (df[\"BMI\"] <= 24.9), \"NewBMI\"] = NewBMI[1]\ndf.loc[(df[\"BMI\"] > 24.9) & (df[\"BMI\"] <= 29.9), \"NewBMI\"] = NewBMI[2]\ndf.loc[(df[\"BMI\"] > 29.9) & (df[\"BMI\"] <= 34.9), \"NewBMI\"] = NewBMI[3]\ndf.loc[(df[\"BMI\"] > 34.9) & (df[\"BMI\"] <= 39.9), \"NewBMI\"] = NewBMI[4]\ndf.loc[df[\"BMI\"] > 39.9 ,\"NewBMI\"] = NewBMI[5]","cb457dfd":"df.head()","fef99191":"def set_insulin(row):\n    if row[\"Insulin\"] >= 16 and row[\"Insulin\"] <= 166: #df insulin de\u011feri 16 dan b\u00fcy\u00fcke\u015fit ve 166 dan k\u00fc\u00e7\u00fcke\u015fitse Normal yazd\u0131r de\u011filse Abnormal yazd\u0131r.\n        return \"Normal\"\n    else:\n        return \"Abnormal\"     ","c34a2c3e":"df.head()","72496152":"#NewInsulinScore ad\u0131nda yeni bir s\u00fctunda ins\u00fclini normal ve abnormal olanlar\u0131n de\u011ferlerini g\u00f6sterdik.\ndf[\"NewInsulinScore\"] = df.apply(set_insulin, axis=1) ","f1f9a3ed":"df.head()","9db6831c":"#df.drop(\"NewInsulinScore\", inplace = True, axis = 1)\n#df.head()","8465f1bc":"# Glikoz de\u011fi\u015fkenine g\u00f6re baz\u0131 aral\u0131klar belirlenmi\u015f ve bunlara kategorik de\u011fi\u015fkenler atanm\u0131\u015ft\u0131r.\nNewGlucose = pd.Series([\"Low\", \"Normal\", \"Overweight\", \"Secret\", \"High\"], dtype = \"category\")\n\ndf[\"NewGlucose\"] = NewGlucose\n\ndf.loc[df[\"Glucose\"] <= 70, \"NewGlucose\"] = NewGlucose[0]\n\ndf.loc[(df[\"Glucose\"] > 70) & (df[\"Glucose\"] <= 99), \"NewGlucose\"] = NewGlucose[1]\n\ndf.loc[(df[\"Glucose\"] > 99) & (df[\"Glucose\"] <= 126), \"NewGlucose\"] = NewGlucose[2]\n\ndf.loc[df[\"Glucose\"] > 126 ,\"NewGlucose\"] = NewGlucose[3]","6ce93c21":"df.head()","d973b331":"df = pd.get_dummies(df, columns =[\"NewBMI\",\"NewInsulinScore\", \"NewGlucose\"], drop_first = True)","621b7b3c":"df.head()","e9ff1eec":"categorical_df = df[['NewBMI_Obesity 1','NewBMI_Obesity 2', 'NewBMI_Obesity 3', 'NewBMI_Overweight','NewBMI_Underweight',\n                     'NewInsulinScore_Normal','NewGlucose_Low','NewGlucose_Normal', 'NewGlucose_Overweight', 'NewGlucose_Secret']]","6c038177":"y = df[\"Outcome\"]\nX = df.drop([\"Outcome\",'NewBMI_Obesity 1','NewBMI_Obesity 2', 'NewBMI_Obesity 3', 'NewBMI_Overweight','NewBMI_Underweight',\n                     'NewInsulinScore_Normal','NewGlucose_Low','NewGlucose_Normal', 'NewGlucose_Overweight', 'NewGlucose_Secret'], axis = 1)\ncols = X.columns\nindex = X.index","36afadbc":"y.head()","329b64fc":"X.head()","662e5086":"cols","2b32822d":"index","830a0c1f":"from sklearn.preprocessing import RobustScaler\ntransformer = RobustScaler().fit(X)\nX = transformer.transform(X)\nX = pd.DataFrame(X, columns = cols, index = index)","8d3e1b06":"X.head()","f3b3a4ed":"X = pd.concat([X, categorical_df], axis = 1)","64302b52":"X.head()","700cb00f":"models = []\nmodels.append(('LR', LogisticRegression(random_state = 12345)))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier(random_state = 12345)))\nmodels.append(('RF', RandomForestClassifier(random_state = 12345)))\nmodels.append(('SVM', SVC(gamma='auto', random_state = 12345)))\nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345)))\n\n# s\u0131rayla her modeli de\u011ferlendirin\nresults = []\nnames = []\n\nfor name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 12345)\n        \n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \n# boxplot algorithm comparison\nfig = plt.figure(figsize=(15,10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()\n\n","460e7113":"rf_params = {\"n_estimators\" :[100,200,500,1000], \n             \"max_features\": [3,5,7], \n             \"min_samples_split\": [2,5,10,30],\n            \"max_depth\": [3,5,8,None]}\n\n","3e23da4d":"rf_model = RandomForestClassifier(random_state = 12345)","fe00c01d":"gs_cv = GridSearchCV(rf_model, \n                    rf_params,\n                    cv = 10,\n                    n_jobs = -1,\n                    verbose = 2).fit(X, y)\n","7c412eba":"gs_cv.best_params_","5d5ea152":"rf_tuned = RandomForestClassifier(**gs_cv.best_params_)","a6e1614d":"rf_tuned = rf_tuned.fit(X,y)","1f4fdcdc":"cross_val_score(rf_tuned, X, y, cv = 10).mean()","4e33f0b4":"feature_imp = pd.Series(rf_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Significance Score Of Variables')\nplt.ylabel('Variables')\nplt.title(\"Variable Severity Levels\")\nplt.show()","d11b6ad0":"lgbm = LGBMClassifier(random_state = 12345)","39db1aa7":"lgbm_params = {\"learning_rate\": [0.01, 0.03, 0.05, 0.1, 0.5],\n              \"n_estimators\": [500, 1000, 1500],\n              \"max_depth\":[3,5,8]}\n","2713a793":"gs_cv = GridSearchCV(lgbm, \n                     lgbm_params, \n                     cv = 10, \n                     n_jobs = -1, \n                     verbose = 2).fit(X, y)","2c16de4a":"gs_cv.best_params_","56ef7fd5":"lgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X,y)","c78200e7":"cross_val_score(lgbm_tuned, X, y, cv = 10).mean()","b62be30a":"feature_imp = pd.Series(lgbm_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Significance Score Of Variables')\nplt.ylabel('Variables')\nplt.title(\"Variable Severity Levels\")\nplt.show()","5582ef00":"xgb = GradientBoostingClassifier(random_state = 12345)","90d05fa6":"xgb_params = {\n    \"learning_rate\": [0.01, 0.1, 0.2, 1],\n    \"min_samples_split\": np.linspace(0.1, 0.5, 10),\n    \"max_depth\":[3,5,8],\n    \"subsample\":[0.5, 0.9, 1.0],\n    \"n_estimators\": [100,1000]}","f8ae9158":"xgb_cv_model  = GridSearchCV(xgb,xgb_params, cv = 10, n_jobs = -1, verbose = 2).fit(X, y)","262a8b27":"xgb_cv_model.best_params_","657d53b5":"xgb_tuned = GradientBoostingClassifier(**xgb_cv_model.best_params_).fit(X,y)","a774cac4":"cross_val_score(xgb_tuned, X, y, cv = 10).mean()","6bab9f68":"feature_imp = pd.Series(xgb_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index)\nplt.xlabel('Significance Score Of Variables')\nplt.ylabel('Variables')\nplt.title(\"Variable Severity Levels\")\nplt.show()","36e1c1cc":"models = []\n\nmodels.append(('RF', RandomForestClassifier(random_state = 12345, max_depth = 8, max_features = 7, min_samples_split = 2, n_estimators = 500)))\nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345, learning_rate = 0.1, max_depth = 5, min_samples_split = 0.1, n_estimators = 100, subsample = 1.0)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345, learning_rate = 0.01,  max_depth = 3, n_estimators = 1000)))\n\n# s\u0131rayla her modeli de\u011ferlendirin\nresults = []\nnames = []","1ff6fa7f":"for name, model in models:\n    \n        kfold = KFold(n_splits = 10, random_state = 12345)\n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \n# kutu grafi\u011fi algoritmas\u0131 kar\u015f\u0131la\u015ft\u0131rmas\u0131\nfig = plt.figure(figsize=(15,10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","a45221f7":"## 8. Model","e47cd8d2":"### 9.2. LightGBM Model Tuning","0d7aa081":"## 2. EDA (Exploratory of Data Analysis) (Veri Analizinin Ke\u015ffi)\n\n### 2.1. Data Preperation (Veri Haz\u0131rlama)","17e26420":"### 9.2.1 LightGBM Final Model","cd47acc6":"## Diyabet\nBu veri seti aslen Ulusal Diyabet ve Sindirim ve B\u00f6brek Hastal\u0131klar\u0131 Enstit\u00fcs\u00fc'nden al\u0131nm\u0131\u015ft\u0131r. Ama\u00e7, bir hastan\u0131n diyabetli olup olmad\u0131\u011f\u0131n\u0131 tan\u0131sal \u00f6l\u00e7\u00fcmlere dayanarak tahmin etmektir.\n\n## \u0130\u00e7erik\nBu \u00f6rneklerin daha b\u00fcy\u00fck bir veritaban\u0131ndan se\u00e7ilmesine \u00e7e\u015fitli k\u0131s\u0131tlamalar getirildi. \u00d6zellikle, buradaki t\u00fcm hastalar, Pima K\u0131z\u0131lderili miras\u0131na sahip en az 21 ya\u015f\u0131nda kad\u0131nlard\u0131r.\n\n- Pregnancies: Hamile kalma say\u0131s\u0131\n- Glucose:  Plazma glikoz konsantrasyonu, bir oral glikoz tolerans testinde 2 saat\n- BloodPressure: Diyastolik kan bas\u0131nc\u0131 (mm Hg)\n- SkinThickness: Triceps deri k\u0131vr\u0131m kal\u0131nl\u0131\u011f\u0131 (mm)\n- Insulin: 2 saatlik serum ins\u00fclini (mu U\/ml)\n- BMI: V\u00fccut kitle indeksi (kg cinsinden a\u011f\u0131rl\u0131k\/(m cinsinden boy)^2)\n- DiabetesPedigreeFunction: Diyabet soya\u011fac\u0131 i\u015flevi\n- Age: Ya\u015f (y\u0131l)\n- Outcome: S\u0131n\u0131f de\u011fi\u015fkeni (0 veya 1)\n\n\u0130lgili bilgiler:\n  Bu \u00f6rneklerin se\u00e7imine \u00e7e\u015fitli k\u0131s\u0131tlamalar getirildi. \n  \u00d6zellikle, buradaki t\u00fcm hastalar kad\u0131nd\u0131r.\n  \n- \u00d6rnek Say\u0131s\u0131: 768\n- Nitelik Say\u0131s\u0131: 8 art\u0131 s\u0131n\u0131f\n\nHer Nitelik i\u00e7in: (t\u00fcm\u00fc say\u0131sal de\u011ferli)\n- Hamile kalma say\u0131s\u0131\n- Plazma glikoz konsantrasyonu, bir oral glikoz tolerans testinde 2 saat\n- Diyastolik kan bas\u0131nc\u0131 (mm Hg)\n- Triceps deri k\u0131vr\u0131m kal\u0131nl\u0131\u011f\u0131 (mm)\n- 2 saatlik serum ins\u00fclini (mu U\/ml)\n- V\u00fccut kitle indeksi (kg cinsinden a\u011f\u0131rl\u0131k\/(m cinsinden boy)^2)\n- Diyabet soya\u011fac\u0131 i\u015flevi Ya\u015fam y\u0131llar\u0131)\n- S\u0131n\u0131f de\u011fi\u015fkeni (0 veya 1)\n\n## Missing Values (Eksik \u00d6zellik De\u011ferleri): Evet\n## S\u0131n\u0131f Da\u011f\u0131l\u0131m\u0131: (s\u0131n\u0131f de\u011feri 1, \" i\u00e7in \u015feker hastal\u0131\u011f\u0131 pozitif test edildi\" olarak yorumlan\u0131r\")","c7873347":"## 4. Outliers Analysis","2160904b":"## 3. Missing Value Analysis ((Eksik De\u011fer Analizi)","6223bb38":"## 9. Model Optimizasyonu (Model Tunning)","f0aed6fc":"### 9.1.1. RF Final Model","17cddc4d":"## 11. Sonu\u00e7\n\nBu \u00e7al\u0131\u015fman\u0131n amac\u0131, diyabet veri seti i\u00e7in s\u0131n\u0131fland\u0131rma modelleri olu\u015fturmak ve modeller kurarak bir ki\u015finin hasta olup olmad\u0131\u011f\u0131n\u0131 tahmin etmek ve kurulan modellerde maksimum validasyon puanlar\u0131n\u0131 elde etmektir. Yap\u0131lan i\u015f a\u015fa\u011f\u0131daki gibidir:\n\n1) Diyabet Veri Seti okundu.\n\n2) Ke\u015ffedici Veri Analizi ile; \nVeri setinin yap\u0131sal verileri kontrol edildi. Veri setindeki de\u011fi\u015fken t\u00fcrleri incelenmi\u015ftir. Veri setinin boyut bilgilerine ula\u015f\u0131ld\u0131. Veri setindeki 0 de\u011ferleri eksik de\u011ferlerdir. \u00d6ncelikle bu 0 de\u011ferleri NaN de\u011ferleri ile de\u011fi\u015ftirildi. Veri setinin tan\u0131mlay\u0131c\u0131 istatistikleri incelendi.\n\n3) Veri \u00d6n \u0130\u015fleme b\u00f6l\u00fcm\u00fc; \ndf for: NaN de\u011ferleri eksik g\u00f6zlemler, her bir de\u011fi\u015fkenin hasta olup olmad\u0131\u011f\u0131na ili\u015fkin medyan de\u011ferlerle dolduruldu. Ayk\u0131r\u0131 de\u011ferler LOF taraf\u0131ndan belirlendi ve d\u00fc\u015f\u00fcr\u00fcld\u00fc. X de\u011fi\u015fkenleri rubost y\u00f6ntemi ile standardize edilmi\u015ftir.\n\n4) Model Olu\u015fturma S\u0131ras\u0131nda; \nLojistik Regresyon, KNN, SVM, CART, Random Forests, XGBoost, LightGBM gibi makine \u00f6\u011frenme modelleri kullan\u0131larak \u00c7apraz Do\u011frulama Puan\u0131 hesaplanm\u0131\u015ft\u0131r. Daha sonra Rastgele Ormanlar, XGBoost, LightGBM hiperparametre optimizasyonlar\u0131 \u00c7apraz Do\u011frulama de\u011ferini art\u0131rmak i\u00e7in optimize edildi.\n\n5) Sonu\u00e7; \nLightBM hiperparametre optimizasyonu sonucunda olu\u015fturulan model, \u00c7apraz Do\u011frulama Puan\u0131 de\u011feri en y\u00fcksek model olmu\u015ftur. (0.89)\n\n","f52d9848":"## 7. Feature Standartization","530363dd":"## 1. Installing","91382a29":"### 9.3. XGBoost Model Tuning","0eefb33d":"### 9.1. Random Forests Tuning","06de8c42":"### 9.3.1. XGBoost Final Model","be900f59":"## 10. Comparison of Final Models","4dcc8215":"## 6. One-hot Encoding","b87f7260":"## 5. Feature Engineering"}}