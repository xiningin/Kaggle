{"cell_type":{"68580a9f":"code","91fcb4df":"code","fc40d98a":"code","a9e1b788":"code","b84d19b8":"code","7fd5bf3a":"code","ee6eaf54":"code","bfc8da21":"code","00ac86d3":"code","936db1c5":"code","86bd967b":"code","7e2d4c63":"code","67df5922":"code","c339b2a8":"code","236562cd":"code","44f885a7":"code","e1d3e7e9":"code","c645d456":"code","853e228a":"code","873c53e2":"code","27457c51":"code","6ebba58c":"code","b475040f":"code","10b55c28":"code","4e6e9cec":"code","790f2f7c":"code","0be7076c":"code","627c77fa":"code","1e032296":"code","129e6480":"code","04f70ec9":"code","518b3572":"code","69f50dab":"code","862b9218":"code","54c30693":"code","91b1718f":"code","a89f0f13":"code","934e778b":"code","22ced432":"code","0d265231":"code","4d00df25":"code","015fd1ee":"code","7e86865b":"code","b2a6297d":"code","d32bfab3":"code","263fccd5":"code","b1cc6ae7":"code","707a90c1":"code","1a2c25a6":"code","67946997":"code","2f34080d":"code","5e53806c":"code","e29b68a9":"code","bffaf20c":"code","2e98e6f1":"code","5c28d641":"code","29556941":"code","644ae033":"code","ac60f5cb":"code","8ab4e390":"code","4f57decd":"code","e9294eb2":"code","bbef8586":"markdown","e68bf5b6":"markdown","501d71d1":"markdown","189f70ca":"markdown","9a6c1105":"markdown","6f49a978":"markdown","0b88073c":"markdown","d5ce3fbe":"markdown","f0828934":"markdown","483a4ad5":"markdown","320f2ae1":"markdown","e5824d58":"markdown","2e9330ca":"markdown","ca5a7f9e":"markdown"},"source":{"68580a9f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","91fcb4df":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler","fc40d98a":"# Carregando os dados\ndf = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/test.csv')\nentrega = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/sample_submission.csv')\n\ndf.shape, test.shape, entrega.shape","a9e1b788":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","b84d19b8":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}","7fd5bf3a":"df_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","ee6eaf54":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","bfc8da21":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# na coluna dependency\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","00ac86d3":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","936db1c5":" # Verificando os valores de aluguel (v2a1) para os chefes\/as de familia (parentesco1 = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","86bd967b":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","7e2d4c63":"df['v2a1'].fillna(-1, inplace=True)","67df5922":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","c339b2a8":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","236562cd":"# Prenchendo com -1 os valores nulos de SQBmeaned, meaneduc e rez_esc\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","44f885a7":"pared = df_all.filter(regex='^pared',axis=1)\n\npared_sum = pared.sum()\n\nparede = pared_sum.to_frame()\n\nnomes_paredes = ['Concreto ou tijolo', 'Parede revestida', 'Pr\u00e9-fabricada ou cimento', \n                 'Material reciclado', 'Madeira', 'Zinco', 'Fibras naturais', 'Outros']\n\npared_sum.index = nomes_paredes\n\nplt.figure(figsize=(15,10))\n\nplt.bar(pared_sum.index.values, pared_sum)","e1d3e7e9":"ec = df_all.filter(regex='^estadocivil',axis=1)\n\nec = ec.sum()\n\nnomes_ec = ['Menos de 10 anos de idade', 'Uni\u00e3o est\u00e1vel', 'Casado', \n            'Divorciado', 'Separado', 'Vi\u00favo(a)', 'Solteiro']\n\nec.index = nomes_ec\n\nplt.figure(figsize=(15,10))\n\nplt.bar(ec.index.values, ec)","c645d456":"lixo = df_all.filter(regex='^elimbasu',axis=1)\n\nlixo = lixo.sum()\n\nnomes_lixo = ['Caminh\u00e3o de lixo', 'Buraco ou enterrado', 'Cremado', \n              'Espa\u00e7o n\u00e3o ocupado', 'Jogado em rio, lagoa ou mar', 'Outro']\nlixo.index = nomes_lixo\n\nplt.figure(figsize=(15,10))\n\nplt.bar(lixo.index.values, lixo)","853e228a":"sanitario = df_all.filter(regex='^sanitario',axis=1)\n\nsanitario = sanitario.sum()\n\nnomes_sanitario = ['Sem sistema sanit\u00e1rio', 'Esgoto', 'Tanque s\u00e9ptico', 'Latrina', 'Outro sistema']\nsanitario.index = nomes_sanitario\n\nplt.figure(figsize=(15,10))\n\nplt.bar(sanitario.index.values, sanitario)","873c53e2":"agua = df_all.filter(regex='^abastagua',axis=1)\n\nagua = agua.sum()\n\nnomes_agua = ['Abastecimento interno', 'Abastecimento externo', 'Sem \u00e1gua']\nagua.index = nomes_agua\n\nplt.figure(figsize=(10,10))\n\nplt.bar(agua.index.values, agua)","27457c51":"teto = df_all.filter(regex='^techo',axis=1)\n\nteto = teto.sum()\n\nnomes_teto = ['Folha laminada ou zinco', 'Fibra de cimento, mezanino', 'Fibras naturais', 'Outros']\n\nteto.index = nomes_teto\n\nplt.figure(figsize=(15,10))\n\nplt.bar(teto.index.values, teto)","6ebba58c":"piso = df_all.filter(regex='^piso',axis=1)\n\npiso = piso.sum()\n\nnomes_piso = ['Mosaico, cer\u00e2mica ou porcelanato', 'Cimento', 'Outro', 'Material Natural', 'Sem piso', 'Madeira']\n\npiso.index = nomes_piso\n\nplt.figure(figsize=(15,10))\n\nplt.bar(piso.index.values, piso)","b475040f":"parentesco = df_all.filter(regex='^parentesco',axis=1)\n\nparentesco = parentesco.sum()\n\nnomes_parentesco = ['Chefe da casa', 'Esposo\/parceiro', 'Filho(a)',\n                    'Enteado(a)', 'Noro(a)', 'Neto(a)', 'M\u00e3e\/pai', \n                    'Sogro(a)', 'Irm\u00e3(o)', 'Cunhado(a)', \n                    'Outro parente', 'Outra pessoa']\n\nparentesco.index = nomes_parentesco\n\nplt.figure(figsize=(20,10))\n\nplt.bar(parentesco.index.values, parentesco)","10b55c28":"escol = df_all.filter(regex='^instlevel',axis=1)\n\nescol = escol.sum()\n\nnomes_escol = ['Sem educa\u00e7\u00e3o', 'Prim\u00e1rio incompleto', 'Prim\u00e1rio completo', \n               'Secund\u00e1rio incompleto', 'Secund\u00e1rio completo', 'T\u00e9cnico incompleto',\n               'T\u00e9cnico completo', 'Ensino superior', 'P\u00f3s-gradua\u00e7\u00e3o']\n               \nescol.index = nomes_escol\n\nplt.figure(figsize=(20,10))\n\nplt.bar(escol.index.values, escol)","4e6e9cec":"casa = df_all.filter(regex='^tipovivi',axis=1)\n\ncasa = casa.sum()\n\nnomes_casa = ['Casa pr\u00f3pria', 'Casa pr\u00f3pria, mas pagando', 'Alugada', 'Prec\u00e1ria', 'Outro']\n\ncasa.index = nomes_casa\n\nplt.figure(figsize=(15,10))\n\nplt.bar(casa.index.values, casa)","790f2f7c":"lugar = df_all.filter(regex='^lugar',axis=1)\n\nlugar = lugar.sum()\n\nnomes_lugar = ['Central', 'Chorotega', 'Pac\u00edfico Central', 'Brunca',\n              'Huetar Atl\u00e1ntica', 'Huetar Norte']\n\nlugar.index = nomes_lugar\n\nplt.figure(figsize=(15,10))\n\nplt.bar(lugar.index.values, lugar)","0be7076c":"area = df_all.filter(regex='^area',axis=1)\n\narea = area.sum()\n\nnomes_area = ['\u00c1rea urbana', '\u00c1rea Rural']\n\narea.index = nomes_area\n\nplt.figure(figsize=(5,10))\n\nplt.bar(area.index.values, area)","627c77fa":"df_all['Idade'] = df_all['age']\n\nplt.figure(figsize=(20,12))\nsns.histplot(data=df_all, x='Idade')\nplt.show()","1e032296":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","129e6480":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\nX_train, Y_train = train[feats], train[['Target']]\nX_test, Y_test = test[feats], test[['Target']]\n\ntrain.shape, test.shape, X_test.shape, Y_test.shape","04f70ec9":"train = train.drop(['Id', 'idhogar'], axis=1)","518b3572":"# Instanciando o random forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)","69f50dab":"# Treinando o modelo\n\n#rf.fit(train[feats], train['Target'])","862b9218":"# Prever o Target de teste usando o modelo treinado\n\n#test['Target'] = rf.predict(test[feats]).astype(int)","54c30693":"# Criando o arquivo para submiss\u00e3o\n# test[['Id', 'Target']].to_csv('submission.csv', index=False)","91b1718f":"ros = RandomOverSampler(random_state = 42)\nX_ros, y_ros = ros.fit_resample(X_train, Y_train)","a89f0f13":"rf = RandomForestClassifier(n_jobs=1, n_estimators=200, random_state=42)\nrf.fit(X_ros,y_ros)","934e778b":"# test['Target'] = rf.predict(test[feats]).astype(int)","22ced432":"# test[['Id', 'Target']].to_csv('submission.csv', index=False)","0d265231":"# from sklearn.feature_selection import SelectKBest, f_regression","4d00df25":"## a vari\u00e1vel ID tem que ser dropada, pois causa erro na pr\u00f3xima tentativa\n\n## x = train.drop(['Target', 'Id', 'idhogar'], axis=1)\n## y = train.Target","015fd1ee":"### seleciona as melhores K vari\u00e1veis para o modelo\n\n## variaveis = SelectKBest(score_func = f_regression, k = 80)\n## novas_variaveis = variaveis.fit_transform(x,y)","7e86865b":"## var_selec = variaveis.get_support()","b2a6297d":"## len(var_selec)","d32bfab3":"## var_teste = train.columns\n## var_teste","263fccd5":"# var_teste = list(var_teste)\n\n# del var_teste[len(var_teste)-1]\n\n# var_teste = list(var_teste)\n\n# del var_teste[len(var_teste)-1]\n\n# var_teste = list(var_teste)\n\n# del var_teste[len(var_teste)-1]","b1cc6ae7":"# len(var_teste)","707a90c1":"# var = []\n# for i in range (len(var_teste)):\n  #  if var_selec[i] == True:\n   #     var.append(var_teste[i])","1a2c25a6":"# teste = train[var]","67946997":"# var.append('Target')","2f34080d":"# treino = train[var]","5e53806c":"# from sklearn.model_selection import train_test_split\n# X_train, X_val, y_train, y_val = train_test_split (test, test.Target, test_size = 0.3, random_state = 42)","e29b68a9":"# from sklearn.ensemble import RandomForestRegressor \n\n# florestarandomica = RandomForestRegressor(n_estimators = 200, criterion='mse', random_state=42, max_depth = 15)","bffaf20c":"# florestarandomica.fit(X_train, y_train)","2e98e6f1":"# y_pred = florestarandomica.predict(X_val)\n\n# from sklearn.metrics import mean_squared_error\n\n# mean_squared_error(y_pred,y_val)","5c28d641":"# tentativa1 = florestarandomica.predict(teste)","29556941":"# entrega['Target'].astype(int)","644ae033":"# entrega.to_csv('submission.csv', index=False)","ac60f5cb":"rus = RandomUnderSampler(random_state = 42)\nX_under, y_under = rus.fit_resample(X_train, Y_train)","8ab4e390":"rf = RandomForestClassifier(n_jobs=1, n_estimators=200, random_state=42)\nrf.fit(X_under,y_under)","4f57decd":"test['Target'] = rf.predict(test[feats]).astype(int)","e9294eb2":"test[['Id', 'Target']].to_csv('submission.csv', index=False)","bbef8586":"##### Aparentemente, o Under Sample \u00e9 melhor do que regress\u00e3o e que Over Sample para o problema.","e68bf5b6":"##### Para as vari\u00e1veis bin\u00e1rias, eu realizei um agrupamento delas com o total de entradas de cada vari\u00e1vel, vendo a distribui\u00e7\u00e3o delas em histogramas","501d71d1":"##### A partir daqui, tentamos utilizar Over Sampling para poder tratar o desbalanceamento dos dados.","189f70ca":"##### Over Sampling n\u00e3o \u00e9 a melhor maneira de lidar com os dados. Vamos tentar regress\u00e3o .","9a6c1105":"#### Fiz o mesmo que foi realizado em aula com o dataset de treino","6f49a978":"##### Aqui eu realizei o mesmo drop que foi realizado acima para poder rodar as bases de teste e treino durante o predict.","0b88073c":"### An\u00e1lise Explorat\u00f3ria de algumas vari\u00e1veis","d5ce3fbe":"### Tratando os dados desbalanceados e utilizando Random Forest para a vari\u00e1vel Target ","f0828934":"##### A pr\u00f3xima c\u00e9lula \u00e9 repetiva, mas ela foi feita da seguinte maneira, pois o length da vari\u00e1vel var_teste tem que ter o mesmo lenght da vari\u00e1vel var_selec.","483a4ad5":"##### As primeiras c\u00e9lulas foram retiradas do notebook criado na aula. As c\u00e9lulas seguintes foram baseadas nesse notebook e em outras submiss\u00f5es da competi\u00e7\u00e3o.","320f2ae1":"#### A maioria das vari\u00e1veis com missing values foram substitu\u00eddas por -1, pois n\u00e3o podemos assumir que os valores ausentes s\u00e3o 0. Eles v\u00e3o interferir nos dados. J\u00e1 a vari\u00e1vel 'v18q1' \u00e9 a quantidade de tablets dentro de uma resid\u00eancia. Comparando ela com a vari\u00e1vel v18q, podemos concluir que os valores ausentes s\u00e3o as resid\u00eancias que n\u00e3o possuem tablets. Logo, esses valores ausentes podem ser substitu\u00eddos por 0.","e5824d58":"##### Vamos tentar utilizar regress\u00e3o para conseguir as vari\u00e1veis Target.","2e9330ca":"#### As c\u00e9lulas abaixo est\u00e3o como coment\u00e1rio para rodar apenas o \u00faltimo resultado","ca5a7f9e":"##### O score obtido atrav\u00e9s dessa tentativa \u00e9 menor que 0.20. Vamos tentar mudar a maneira como geramos os dados da vari\u00e1vel Target. Vamos tentar Under Sampling."}}