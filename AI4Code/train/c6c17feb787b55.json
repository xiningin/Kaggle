{"cell_type":{"c6720d29":"code","54b33649":"code","52e341ef":"code","76dcb4f9":"code","b4de8efc":"code","4baf7388":"code","69c60756":"code","189e5d84":"code","1c243d90":"code","70bf1903":"code","6d08645a":"code","5cdc9439":"code","7a267a6a":"code","94830820":"code","0ab570f6":"code","ad75bbb5":"code","22b5290d":"code","443d49e5":"code","7bd646bc":"code","3c4921d1":"code","230bfbfd":"code","4b9e258f":"code","99e1363b":"code","7a0d7009":"code","4dc28f8b":"code","38920159":"code","df3d0170":"code","53559666":"code","4da462c9":"code","3366f53a":"code","ad6c01f7":"code","81bdca74":"code","7eeba8e4":"code","b52cd266":"code","5b51a425":"code","ee79be9c":"code","eebf292d":"code","bcb2719c":"code","56773750":"code","4cbcf268":"code","d253eb7c":"code","498a9e74":"code","3d22959e":"code","85d706c5":"code","63c0963d":"code","62c4338d":"code","373a2850":"code","7837b233":"code","e049b069":"code","62f56993":"code","1a3d568b":"code","562988b4":"code","3491ea20":"code","71d43dd7":"code","8269c408":"code","03e6e2d9":"code","cb1335cd":"code","5cdfaf22":"code","09b3a0bd":"code","7d57b96b":"markdown","7ee384dc":"markdown","0da505b9":"markdown","a1754f6d":"markdown","f5236b15":"markdown","58101a12":"markdown","60252ea0":"markdown","8ce614a7":"markdown","d50b8dcd":"markdown","2f6cb838":"markdown","0cc1b250":"markdown","06cbc3fd":"markdown","08cf3e71":"markdown","dfadf17d":"markdown","7c824d82":"markdown","cdc0cf15":"markdown","169a8a9b":"markdown","8a443769":"markdown","6311ac15":"markdown","efaba110":"markdown","e7536f88":"markdown","3459000e":"markdown","cdbc14df":"markdown","593a29f6":"markdown"},"source":{"c6720d29":"# installation of libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression  \nfrom sklearn.neighbors import KNeighborsClassifier  \nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error, r2_score, roc_auc_score, roc_curve, classification_report\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom catboost import CatBoostClassifier\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=FutureWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning) \n\n%config InlineBackend.figure_format = 'retina'\n\n# to display all columns and rows:\npd.set_option('display.max_columns', None); pd.set_option('display.max_rows', None);\n","54b33649":"df = pd.read_csv(\"..\/input\/predicting-churn-for-bank-customers\/Churn_Modelling.csv\", index_col=0)","52e341ef":"df.head()","76dcb4f9":"df.shape","b4de8efc":"# dataframe's index dtype and column dtypes, non-null values and memory usage information\ndf.info()","4baf7388":"# explanatory statistics values of the observation units corresponding to the specified percentages\ndf.describe([0.10,0.25,0.50,0.75,0.90,0.95,0.99]).T\n# transposition of the df table was taken to facilitate the evaluation","69c60756":"# seeing the distribution of age of people who have an account in the bank\nsns.distplot(df.Age, bins = 10)\nplt.show()","189e5d84":"sns.distplot(df.Balance, bins = 10)\nplt.show()","1c243d90":"sns.boxplot(data = df, x= 'Geography', y = 'Age')\nplt.show()","70bf1903":"df.groupby(\"Gender\")['Gender'].count()","6d08645a":"sns.barplot(x=\"Geography\", y=\"Exited\", hue = 'Gender', data=df)\nplt.show()","5cdc9439":"df['Exited'].value_counts() # mostly not exited customers","7a267a6a":"sns.countplot(df['Exited'], palette='Set1')\nplt.title('Counts of Two Types of Customers')\n# as expected, most customers did not churn","94830820":"f, ax = plt.subplots(1,1, figsize=(8,8))\n\ncolors = [\"darkturquoise\", \"red\"]\nlabels =\"Did not exit\", \"Exit\"\n\nplt.suptitle('Information on Customer Churn', fontsize=20)\n\ndf[\"Exited\"].value_counts().plot.pie(explode=[0,0.25], autopct='%1.2f%%', ax=ax, shadow=True, colors=colors, labels=labels, fontsize=12, startangle=25)","0ab570f6":"#Create figure\nf, ax = plt.subplots(figsize = (12,12))\n\n#Create and plot correlation matrix\ncorr = df.corr()\nsns.heatmap(corr, ax=ax, linewidths= 1, linecolor='white',annot = True, cmap = 'coolwarm',center = 0);","ad75bbb5":"# create figure\nf, ax = plt.subplots(figsize = (10,7))\n\n# plot target\ndf.groupby(['Geography','Gender'])['Exited'].agg({'count','sum'}).plot(kind = 'bar', ax = ax, color = ['orange', 'grey'])\n\ncats = ['France\\nWomen','France\\nMen','Germany\\nWomen','Germany\\nMen','Spain\\nWomen','Spain\\nMen']\n# ax.set_xticks(cats)\nax.set_xticklabels(cats)\nplt.xticks(rotation=0)\n\n# set plot aesthetics\nax.set_title('Churn Distributions', style = 'italic')\nax.set_xlabel('')\nax.set_ylabel('Count', style = 'italic')\nax.legend(['Exited', 'Stayed'], shadow = True, frameon = True)\nax.grid(axis = 'x',b=False)\nax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n","22b5290d":"# no missing data in the data set\ndf.isnull().sum()","443d49e5":"# Outlier Observation Analysis\nfor feature in df[['CreditScore','Tenure', 'Balance','EstimatedSalary']]:\n    \n    Q1 = df[feature].quantile(0.25)\n    Q3 = df[feature].quantile(0.75)\n    IQR = Q3-Q1\n    lower = Q1- 1.5*IQR\n    upper = Q3 + 1.5*IQR\n    \n    if df[(df[feature] > upper)].any(axis=None):\n        print(feature,\"yes\")\n    else:\n        print(feature, \"no\")","7bd646bc":"df[\"NewAGT\"] = df[\"Age\"] - df[\"Tenure\"]\ndf[\"New_CreditsScore\"] = pd.qcut(df['CreditScore'], 10, labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ndf[\"AgeScore\"] = pd.qcut(df['Age'], 8, labels = [1, 2, 3, 4, 5, 6, 7, 8])\ndf[\"BalanceScore\"] = pd.qcut(df['Balance'].rank(method=\"first\"), 10, labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ndf[\"EstSalaryScore\"] = pd.qcut(df['EstimatedSalary'], 10, labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\ndf[\"NewEstimatedSalary\"] = df[\"EstimatedSalary\"] \/ 12 ","3c4921d1":"df.head()","230bfbfd":"df = pd.get_dummies(df, columns =[\"Geography\", \"Gender\"], drop_first = True)","4b9e258f":"df.head()","99e1363b":"df = df.drop([\"CustomerId\",\"Surname\"], axis = 1)","7a0d7009":"df.head()","4dc28f8b":"cat_df = df[[\"Geography_Germany\", \"Geography_Spain\", \"Gender_Male\", \"HasCrCard\",\"IsActiveMember\"]]","38920159":"cat_df.head()","df3d0170":"y = df[\"Exited\"]\nX = df.drop([\"Exited\",\"Geography_Germany\", \"Geography_Spain\", \"Gender_Male\", \"HasCrCard\",\"IsActiveMember\"], axis = 1)\ncols = X.columns\nindex = X.index","53559666":"X.head()    ","4da462c9":"from sklearn.preprocessing import RobustScaler\ntransformer = RobustScaler().fit(X)\nX = transformer.transform(X)\nX = pd.DataFrame(X, columns = cols, index = index)","3366f53a":"X = pd.concat([X,cat_df], axis = 1)","ad6c01f7":"X.head()","81bdca74":"# Splitting the dataset into Training and Testing Data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state = 42)","7eeba8e4":"models = []\nmodels.append(('LR', LogisticRegression(random_state = 12345)))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier(random_state = 12345)))\nmodels.append(('RF', RandomForestClassifier(random_state = 12345)))\nmodels.append(('SVM', SVC(gamma='auto', random_state = 12345)))\nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345)))\nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345)))\nmodels.append((\"CatBoost\", CatBoostClassifier(random_state = 12345, verbose = False)))\n\n# evaluate each model in turn\nresults = []\nnames = []\n\nfor name, model in models:\n        \n        cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n        results.append(cv_results)\n        names.append(name)\n        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n        print(msg)\n        \n# comparison of algorithms with boxplot\nfig = plt.figure(figsize=(15,10))\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\nplt.boxplot(results,\n            vert=True, # vertical box alignment\n            patch_artist=True) # fill with color\n                         \nax.set_xticklabels(names)\nplt.show()","b52cd266":"rf_params = {\"n_estimators\" :[100,200], \n             \"max_features\": [3,5], \n            \"max_depth\": [3,5]}","5b51a425":"rf_model = RandomForestClassifier(random_state = 12345)","ee79be9c":"gs_cv = GridSearchCV(rf_model, \n                    rf_params,\n                    cv = 10,\n                    n_jobs = -1,\n                    verbose = 2).fit(X, y)","eebf292d":"gs_cv.best_params_","bcb2719c":"rf_tuned = RandomForestClassifier(**gs_cv.best_params_)\nrf_tuned = rf_tuned.fit(X,y)\ncross_val_score(rf_tuned, X, y, cv = 10).mean()","56773750":"feature_imp = pd.Series(rf_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index, palette=\"Blues_d\")\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Feature Severity Levels\")\nplt.show()","4cbcf268":"xgb = GradientBoostingClassifier(random_state = 12345)","d253eb7c":"xgb_params = {\n    \"learning_rate\": [0.01, 0.1, 1],\n    \"max_depth\":[3,5],\n    \"subsample\":[0.5, 0.9],\n    \"n_estimators\": [100,200]}","498a9e74":"xgb_cv = GridSearchCV(xgb,xgb_params, cv = 10, n_jobs = -1, verbose = 2).fit(X, y)","3d22959e":"xgb_cv.best_params_","85d706c5":"xgb_tuned = GradientBoostingClassifier(**xgb_cv.best_params_).fit(X,y)\ncross_val_score(xgb_tuned, X, y, cv = 10).mean()","63c0963d":"feature_imp = pd.Series(xgb_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index, palette=\"Blues_d\")\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Feature Severity Levels\")\nplt.show()","62c4338d":"lgbm = LGBMClassifier(random_state = 12345)\nlgbm_params = {\"learning_rate\": [0.01, 0.03, 0.05, 0.1, 0.5],\n              \"n_estimators\": [500, 1000, 1500],\n              \"max_depth\":[3,5,8]}","373a2850":"gs_cv = GridSearchCV(lgbm, \n                     lgbm_params, \n                     cv = 10, \n                     n_jobs = -1, \n                     verbose = 2).fit(X, y)","7837b233":"gs_cv.best_params_","e049b069":"lgbm_tuned = LGBMClassifier(**gs_cv.best_params_).fit(X,y)\ncross_val_score(lgbm_tuned, X, y, cv = 10).mean()","62f56993":"feature_imp = pd.Series(lgbm_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index, palette=\"Blues_d\")\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Feature Severity Levels\")\nplt.show()","1a3d568b":"catboost = LGBMClassifier(random_state = 12345)","562988b4":"catboost_params = {\"learning_rate\": [0.01, 0.03, 0.05, 0.1, 0.5],\n              \"n_estimators\": [500, 1000, 1500],\n              \"max_depth\":[3,5,8]}","3491ea20":"gs_cv = GridSearchCV(catboost, \n                     catboost_params, \n                     cv = 10, \n                     n_jobs = -1, \n                     verbose = 2).fit(X, y)","71d43dd7":"gs_cv.best_params_","8269c408":"catboost_tuned = CatBoostClassifier(**gs_cv.best_params_).fit(X,y)\ncross_val_score(catboost_tuned, X, y, cv = 10).mean()","03e6e2d9":"feature_imp = pd.Series(catboost_tuned.feature_importances_,\n                        index=X.columns).sort_values(ascending=False)\n\nsns.barplot(x=feature_imp, y=feature_imp.index, palette=\"Blues_d\")\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Feature Severity Levels\")\nplt.show()","cb1335cd":"models = []\n\nmodels.append(('RF', RandomForestClassifier(random_state = 12345, max_depth = 8,max_features = 7, min_samples_split = 10,n_estimators = 500))) \nmodels.append(('XGB', GradientBoostingClassifier(random_state = 12345,learning_rate = 0.1, max_depth = 3, min_samples_split = 0.1, n_estimators = 500, subsample = 0.9))) \nmodels.append((\"LightGBM\", LGBMClassifier(random_state = 12345, learning_rate = 0.01, max_depth = 5, n_estimators = 1000))) \nmodels.append((\"CatBoost\", CatBoostClassifier(random_state = 12345, learning_rate = 0.01, max_depth = 5, n_estimators = 1000)))\n\nresults = [] \nnames = []","5cdfaf22":"for name, model in models:\n\n    cv_results = cross_val_score(model, X, y, cv = 10, scoring= \"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","09b3a0bd":"# comparison of algorithms with boxplot\nfig = plt.figure(figsize=(15,10))\nfig.suptitle('Algorithm Comparison') \nax = fig.add_subplot(111) \nplt.boxplot(results, \n            vert=True, # vertical box alignment\n            patch_artist=True) # fill with color\n\nax.set_xticklabels(names) \nplt.show()","7d57b96b":"### Target Variable - Exited","7ee384dc":"### Installation of Final Model","0da505b9":"## Comparison of Final Models","a1754f6d":"### LightGBM Tuning","f5236b15":"## Feature Engineering","58101a12":"# Modelling","60252ea0":"# Model Optimization\n\n\n## Model Tuning\n","8ce614a7":"Females are more likely to leave the bank from all the mentioned states","d50b8dcd":"### CatBoost Tuning","2f6cb838":"### Installation of Final Model","0cc1b250":"### Random Forests Tuning","06cbc3fd":"- Exited=0 active customer\n- Exited=1 churned customer","08cf3e71":"From the heatmap , we find that teh Age, Balance and the Geography of the Customer are Most important features","dfadf17d":"# Data Understanding","7c824d82":"# Data Pre-Processing","cdc0cf15":"## One Hot Encoding","169a8a9b":"### Installation of Final Model","8a443769":"### Installation of Final Model","6311ac15":"### **Correlation Matrix**","efaba110":"## Missing Data Analysis","e7536f88":"### **Countplot by country and gender**","3459000e":"## Scaling","cdbc14df":"### XGBoost Tuning","593a29f6":"# Business Problem\n\n- The aim is to predict whether a bank's customers leave the bank or not.\n- The event that defines customer cancellation is the customer closing his bank account.\n\n**Data Set Information:**\n\n- It consists of 10000 observations and 12 variables.\n- Independent variables contain information about customers.\n- Dependent variable expresses customer churn status.\n\n**Attribute Information:**\n\n- Surname : Customers' surname\n- CreditScore : Credit score achieved\n- Geography : Germany, France, Spain\n- Gender : Female, Male\n- Age : Customers' age\n- Tenure : Number of years\n- Balance : Money\n- NumOfProducts : Number of bank products used\n- HasCrCard : The state of having credit card or not\n- IsActiveMember : The state of active membership\n- EstimatedSalary : Customer's estimated salary\n- Exited : Churn or not\n"}}