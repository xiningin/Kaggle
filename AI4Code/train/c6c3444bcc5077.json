{"cell_type":{"d19119fa":"code","4d5b4cdb":"code","83b5ffa3":"code","de2f4843":"code","968bb998":"code","5dcf8886":"code","fbffd155":"code","6e644c03":"code","086e67d5":"code","1771a944":"code","8b4f0a01":"code","ed495733":"code","56152933":"code","d87a8bd7":"code","816f2aa8":"code","9065202e":"code","24ee8276":"markdown","18d7a187":"markdown","40ce4f33":"markdown","c4959d1e":"markdown","c209f04c":"markdown","04104935":"markdown","877c5ef8":"markdown","a6e33b74":"markdown","8eca8e6a":"markdown","54233bf1":"markdown","eec9ab50":"markdown","2be3b69c":"markdown","a7bcf890":"markdown","1865373d":"markdown","418451c2":"markdown","db1d0d6c":"markdown","fe605a70":"markdown","1ef21529":"markdown","69630470":"markdown","4fecc432":"markdown","7bbe597c":"markdown","c5da1319":"markdown","13bc48c0":"markdown","f1f33ec4":"markdown"},"source":{"d19119fa":"from IPython.display import clear_output\n!pip install keras-ocr\nclear_output()","4d5b4cdb":"import pytesseract\nimport keras_ocr\nimport easyocr\nimport matplotlib.pyplot as plt\nimport cv2\n%matplotlib inline","83b5ffa3":"url = [\n    \"https:\/\/raw.githubusercontent.com\/sanskar-hasija\/ocr-comparision\/main\/test_images\/image1.png\",\n    \"https:\/\/raw.githubusercontent.com\/sanskar-hasija\/ocr-comparision\/main\/test_images\/image2.png\",\n    \"https:\/\/raw.githubusercontent.com\/sanskar-hasija\/ocr-comparision\/main\/test_images\/image3.png\",\n    \"https:\/\/raw.githubusercontent.com\/sanskar-hasija\/ocr-comparision\/main\/test_images\/image4.png\"\n]\nimages = [ keras_ocr.tools.read(i) for i in url]","de2f4843":"fig = plt.figure(figsize=(16,10))\nrows = 2\ncolumns = 2\n\nfig.add_subplot(rows, columns, 1)\nplt.imshow(images[0])\nplt.axis('off')\nplt.title(\"First Image\")\n\nfig.add_subplot(rows, columns, 2)\nplt.imshow(images[1])\nplt.axis('off')\nplt.title(\"Second Image\")\n\nfig.add_subplot(rows, columns, 3)\nplt.imshow(images[2])\nplt.axis('off')\nplt.title(\"Third Image\")\n\nfig.add_subplot(rows, columns, 4)\nplt.imshow(images[3])\nplt.axis('off')\nplt.title(\"Fourth Image\");","968bb998":"pipline = keras_ocr.pipeline.Pipeline() #Creting a pipline \nkerasocr_preds = pipline.recognize(images)","5dcf8886":"fig,axs = plt.subplots(nrows = 4 , figsize = (30,30))\nfor ax , image,  prediction in zip(axs , images , kerasocr_preds):\n    keras_ocr.tools.drawAnnotations(image, prediction, ax)","fbffd155":"text_reader = easyocr.Reader(['en']) #Initialzing the ocr","6e644c03":"results = text_reader.readtext(images[0] )\nfor (bbox, text, prob) in results:\n    print(text)\nplt.imshow(images[0])\nplt.title(\"First Image\");","086e67d5":"results = text_reader.readtext(images[1] )\nfor (bbox, text, prob) in results:\n    print(text)\nplt.imshow(images[1])\nplt.title(\"Second Image\");","1771a944":"results = text_reader.readtext(images[2] )\nfor (bbox, text, prob) in results:\n    print(text)\nplt.imshow(images[2])\nplt.title(\"Third Image\");","8b4f0a01":"results = text_reader.readtext(images[3] )\nfor (bbox, text, prob) in results:\n    print(text)\nplt.imshow(images[3])\nplt.title(\"Fourth Image\");","ed495733":"tesseract_preds = []\nfor img in images:\n    tesseract_preds.append(pytesseract.image_to_string(img))","56152933":"print(tesseract_preds[0])\nplt.imshow(images[0])\nplt.title(\"First Image\");","d87a8bd7":"print(tesseract_preds[1])\nplt.imshow(images[1])\nplt.title(\"Second Image\");","816f2aa8":"print(tesseract_preds[2])\nplt.imshow(images[2])\nplt.title(\"Third Image\");","9065202e":"print(tesseract_preds[3])\nplt.imshow(images[3])\nplt.title(\"Fourth Image\");","24ee8276":"### First Image","18d7a187":"### * Keras-OCR is image specific OCR tool. If text is inside the image and their fonts and colors are unorganized, Keras-ocr consumes time if used on CPU\n### * EasyOCR is lightweight model which is giving a good performance for receipt or PDF conversion. It is giving more accurate results with organized texts like pdf files, receipts, bills. EasyOCR also performs well on noisy images\n### * Pytesseract is performing well for high-resolution images. Certain morphological operations such as dilation, erosion, OTSU binarization can help increase pytesseract performance. It also provides better results on handwritten text as compared to EasyOCR\n### * All these results can be further improved by performing specific image operations.","40ce4f33":"### Third Image","c4959d1e":"### Second Image","c209f04c":"## TEST IMAGES","04104935":"# <center> Keras-OCR VS EasyOCR VS PYTESSERACT <\/center>","877c5ef8":"### [1. KERAS-OCR](#kerasocr) ###\n### [2. EASYOCR](#easyocr) ###\n### [3. PYTESSERACT](#pytesseract) ###\n##    [Conclusions](#conclusions) ##","a6e33b74":"##  Results of Pytesseract","8eca8e6a":"## Results of Keras-OCR","54233bf1":"## Image 3","eec9ab50":"<a id=\"pytesseract\"><\/a>\n# Pytesseract","2be3b69c":"## Results of EASY OCR","a7bcf890":"### Fourth Image","1865373d":"<a id=\"kerasocr\"><\/a>\n# KERAS_OCR","418451c2":"### Image 2","db1d0d6c":"## IMPORTS","fe605a70":"### Keras-ocr plots boxes of detected text with annotations on the input image.","1ef21529":"## Installing Keras-ocr","69630470":"### Image 1 ","4fecc432":"## Image 4","7bbe597c":"<a id=\"easyocr\"><\/a>\n# EASYOCR","c5da1319":"# <center>If you find this notebook useful, support with an upvote!<\/center>","13bc48c0":"<a id=\"conclusions\"><\/a>\n# CONCLUSIONS","f1f33ec4":"\n**Created by Sanskar Hasija**\n\n**Keras-OCR VS EasyOCR VS PYTESSERACT**\n\n**24 August 2021**\n"}}