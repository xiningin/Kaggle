{"cell_type":{"f40ca163":"code","d0b19094":"code","b750a67a":"code","ebaddd0c":"code","522bc5f7":"code","1afaad0e":"code","1d84759f":"code","629e47c9":"code","10b6ddaa":"code","9fd19cf3":"code","6b00d773":"code","2e73f679":"code","aa412800":"code","e7d8ed31":"code","f344f157":"code","3c618b23":"code","e3fdebe3":"code","d3b4f63c":"code","85f5ea8a":"code","2df31e60":"code","02394363":"code","731aabbd":"code","1c28fd45":"code","064f504e":"code","41006db7":"code","7aea5725":"code","33f6b77f":"code","e11152fe":"code","277e82af":"code","2b6705d4":"code","56aab7f3":"code","66234c3e":"code","8fdb9875":"code","417309c6":"code","3d366947":"code","7fecc6ab":"code","a59cfa0e":"code","77014b9f":"code","e6f3ccc9":"markdown","db1f7c7d":"markdown","532fd46e":"markdown","bdaf7ec8":"markdown","0c73d45a":"markdown","54e029f4":"markdown","db698ed4":"markdown","bcb516a4":"markdown","2d549a2d":"markdown","4b425f09":"markdown","e1aefcad":"markdown","bf8475eb":"markdown","369301ed":"markdown","acaf15b9":"markdown","bca09127":"markdown","d4bf13b6":"markdown","13881f43":"markdown","5a4ce5fe":"markdown","191b3015":"markdown","e48c74c0":"markdown"},"source":{"f40ca163":"#This is my first ML Solo proyect.  I'll appreciate some advices or corrections you can give me. \n# I'm concern about the Durbin-Watson and the Cond.No but I couldn't fix it so any ideas will be extremly heplful and welcomed. \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sns\nsns.set()","d0b19094":"raw_data = pd.read_csv(\"..\/input\/suicide-rates-overview-1985-to-2016\/master.csv\")\nraw_data.describe(include='all')","b750a67a":"#Drop unnecesary features, country-year because is repeated and HDI because is not enought. \ndata= raw_data.drop(['country-year', 'HDI for year'], axis=1)\ndata.describe(include='all')","ebaddd0c":"#No missing values\ndata.isnull().sum()","522bc5f7":"data.rename(columns={'population':'pop', 'gdp_per_capita ($)':'gdp_per_capita', ' gdp_for_year ($) ':'gdp_for_year'}, inplace=True)\ndata.gdp_for_year = data.gdp_for_year.apply(lambda x: float(''.join(x.split(','))))\ndata.age = data.age.apply(lambda x: x.replace(\"years\", \"\"))\ndata.describe(include='all')","1afaad0e":"#Creating a col % of population comited suicide\ndata['suicides\/pop'] = data['suicides_no']*100\/data['pop']\ndata_suicides_country = data.groupby('country', as_index=False)['suicides\/pop'].mean().sort_values(by='suicides\/pop', ascending=False)\n\ndata_suicides_country","1d84759f":"plt.figure(figsize=(8,32))\nsns.barplot(y=data_suicides_country.country, x=data_suicides_country['suicides\/pop'])\nplt.xlabel(\"suicides \/ population\")\nplt.ylabel(\"country\")\nplt.title(\"suicides\/pop vs country (1985-2016)\")\nplt.show()","629e47c9":"#Cheking the difference between men and women over the years\nplt.figure(figsize=(9,6))\nplt.title('Suicide number by Gender (1985-2016)', fontsize=20)\ndata_men = data[data['sex'] == 'male']\ndata_women = data[data['sex'] == 'female']\nsns.lineplot(data_men.year, data_men.suicides_no, ci = None)\nsns.lineplot(data_women.year, data_women.suicides_no, ci = None)\nplt.legend(['men','women'])\nplt.show()","10b6ddaa":"data_age = data.groupby(['year', 'age'])['suicides_no', 'pop'].sum()\ndata_reset = data_age.copy().reset_index()\nplt.figure(figsize=(9,6))\nplt.title('Suicide number by Age (1985-2016)', fontsize=20)\nsns.lineplot('year', data_reset.suicides_no*100\/data_reset['pop'], hue='age',\n            data=data_reset, linewidth=2.5, style='age')\nplt.show()","9fd19cf3":"data_generation =  data.groupby('generation', as_index=False)['suicides_no'].sum().sort_values(by='suicides_no', ascending=False)\ndata_generation ","6b00d773":"plt.figure(figsize=(6,6))\nplt.title('Suicide number (1985-2016)', fontsize=20)\nplt.pie(data_generation.suicides_no, explode =(0.05, 0.05, 0.05, 0.05, 0.05, 0.05), labels=data_generation.generation, autopct='%1.1f%%')\nplt.show()","2e73f679":"# suicide_no, gdp_per_capita, suicides\/100k pop and pop have Outliers\n# Convert sex, age and generation into dummy variables\ndata.describe(include='all')","aa412800":"q1 = data['suicides_no'].quantile(0.99)\ndata_1 = data[data['suicides_no']<q1]\n\nq2 = data_1['gdp_per_capita'].quantile(0.99)\ndata_2 = data_1[data['gdp_per_capita']<q2]\n\n\nq3 = data_2['suicides\/100k pop'].quantile(0.99)\ndata_3 = data_2[data['suicides\/100k pop']<q3]\n\nq4 = data_3['pop'].quantile(0.99)\ndata_4 = data_3[data['pop']<q4]","e7d8ed31":"f, axes = plt.subplots(1, 4, figsize= (25,6))\n\nsns.distplot(data_1['suicides_no'], ax=axes[0])\nsns.distplot(data_2['gdp_per_capita'], ax=axes[1])\nsns.distplot(data_3['suicides\/100k pop'], ax=axes[2])\nsns.distplot(data_4['pop'], ax=axes[3])\n\nplt.show()","f344f157":"#Reset index of values left and drops the old index\n#cln = cleaned\ndata_cln = data_4.reset_index(drop=True)\ndata_cln.describe(include='all')","3c618b23":"f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize= (25,6))\nax1.scatter(data_cln['pop'], data_cln['suicides_no'], alpha=0.2)\nax1.set_title('population and suicides_no')\nax2.scatter(data_cln['suicides\/100k pop'], data_cln['suicides_no'], alpha=0.2)\nax2.set_title('suicides\/100k pop and suicides_no')\nax3.scatter(data_cln['gdp_per_capita'], data_cln['suicides_no'], alpha=0.2)\nax3.set_title('gdp_per_capita ($) and suicides_no')\n\nplt.show()","e3fdebe3":"data_cln['log pop'] = np.log(data_cln['pop'].replace(0,np.nan))\ndata_cln['log suicides\/100k pop'] = np.log(data_cln['suicides\/100k pop'].replace(0,np.nan))\ndata_cln['log gdp_per_capita'] = np.log(data_cln['gdp_per_capita'].replace(0,np.nan))\ndata_cln['log suicides_no'] = np.log(data_cln['suicides_no'].replace(0,np.nan))\n\nf, axes = plt.subplots(1, 4, figsize= (25,6))\n\nsns.distplot(data_cln['log suicides_no'], ax=axes[0])\nsns.distplot(data_cln['log pop'], ax=axes[1])\nsns.distplot(data_cln['log gdp_per_capita'], ax=axes[2])\nsns.distplot(data_cln['log suicides\/100k pop'], ax=axes[3])\n\nplt.show()","d3b4f63c":"data_cln.describe(include='all')","85f5ea8a":"f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize= (25,6))\nax1.scatter(data_cln['log pop'], data_cln['suicides_no'], alpha=0.2)\nax1.set_title('log population and log suicides_no')\nax2.scatter(data_cln['log suicides\/100k pop'], data_cln['suicides_no'], alpha=0.2)\nax2.set_title('log suicides\/100k pop and log suicides_no')\nax3.scatter(data_cln['log gdp_per_capita'], data_cln['suicides_no'], alpha=0.2)\nax3.set_title('log gdp_per_capita ($) and suicides_no')\n\nplt.show()","2df31e60":"data_dummy = data_cln.drop(['country'], axis=1)\ndata_dummy = pd.get_dummies(data_dummy, drop_first=True)\ndata_dummy.columns.values","02394363":"from statsmodels.stats.outliers_influence import variance_inflation_factor\n\nvif = pd.DataFrame()\nvariables = data_dummy.drop(['suicides_no', 'suicides\/100k pop', 'gdp_for_year', 'log pop', 'log suicides\/100k pop', 'log gdp_per_capita', 'log suicides_no'], axis=1)\n\nvif['VIF'] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\nvif['Features'] = variables.columns\nvif","731aabbd":"# Drop year beacuse it's over 10\n# Drop all features that won't use because we have the transformed features\ndata_preprocessed = data_dummy.drop(['suicides\/100k pop', 'pop', 'gdp_per_capita', 'log suicides_no', 'year', 'log suicides\/100k pop',], axis=1)\ndata_preprocessed.describe(include='all').T","1c28fd45":"targets = data_preprocessed['suicides_no']\n\ninputs = data_preprocessed.drop(['suicides_no'], axis=1)\ninputs.columns.values","064f504e":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(inputs)\n\ninputs_scaled = scaler.transform(inputs)","41006db7":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(inputs_scaled, targets, test_size=0.2, random_state=42)","7aea5725":"reg = LinearRegression()\nreg.fit(x_train, y_train)","33f6b77f":"y_hat = reg.predict(x_train)","e11152fe":"#The errors are normally distribuited\nsns.distplot(y_train - y_hat)\nplt.title(\"Residuals PDF\", size=18)","277e82af":"# We're trying to predict human behavior so we can expect R squares less than 50%\nreg.score(x_train,y_train)","2b6705d4":"#bias\nreg.intercept_","56aab7f3":"#features weights\nreg.coef_","66234c3e":"reg_summary = pd.DataFrame(inputs.columns.values, columns=['Features'])\nreg_summary['Weights'] = reg.coef_\ndf_bias = pd.DataFrame(['bias'], columns=['Features'])\ndf_bias['Weights'] = reg.intercept_\nreg_summary = reg_summary.append(df_bias, ignore_index=True)\nreg_summary\n","8fdb9875":"#male sex has more weight on the prediction and it's the benchmark\ndata_cln.sex.unique()","417309c6":"# age-15-24 is the benchmark\ndata_cln.age.unique()","3d366947":"#Boomers are the benchmark\ndata_cln.generation.unique()","7fecc6ab":"y_hat_test = reg.predict(x_test)\ndf_predict = pd.DataFrame(y_hat_test, columns=['Prediction'])\n\ny_test = y_test.reset_index(drop=True)\ndf_predict['Target'] = y_test\ndf_predict","a59cfa0e":"# We have almost same means between Prediction and Target and the standard deviation si not so different\n#\ndf_predict['Residual'] = df_predict['Target'] - df_predict['Prediction']\ndf_predict['Difference%'] = np.absolute(df_predict['Residual']\/df_predict['Target']*100)\ndf_predict.describe()","77014b9f":"#Drop this features because they are not useful\ninputs_new = data_preprocessed.drop(['suicides_no', 'age_55-74 ', 'generation_G.I. Generation'], axis=1)\n\nresults = sm.OLS(targets,inputs_new).fit()\nresults.summary()\n# By the Durbin_watson > 2 we can see there is some Possitive Autocorrelation","e6f3ccc9":"### Multicollinearity","db1f7c7d":"## By Age","532fd46e":"## Multiple Linear Regression\n### Declare inputs and targets\n","bdaf7ec8":"### Loading the Raw Data","0c73d45a":"## Relaxing Assumptions","54e029f4":"## Plot the Data\n### By Country","db698ed4":"### By Generation","bcb516a4":"# Import Relevant Libraries","2d549a2d":"## Dummy Variables","4b425f09":"## Cheking the OLS assumptins","e1aefcad":"### By Gender \/ Pop \/ Year","bf8475eb":"## Dealing with Outliers","369301ed":"### Finding Weights and Bias","acaf15b9":"## Create Regression","bca09127":"## Testing","d4bf13b6":"## Exploring PDF's","13881f43":"## Preprocessing","5a4ce5fe":"### Changing col names","191b3015":"### Scale the Data","e48c74c0":"### Train Test Split"}}