{"cell_type":{"da095e96":"code","77fbbb9b":"code","b9d202b8":"code","f1a34b79":"code","76e480b4":"code","f8f14478":"code","e66421aa":"code","86c80683":"code","9933a04e":"code","25dc220d":"code","c54e64d4":"code","19b2beaf":"code","4740e3fe":"code","71b3858d":"code","02928218":"code","bfc4a6ad":"code","33adfd1e":"code","6ed1117e":"code","cadbb561":"code","9ec50771":"code","9f07cb6d":"code","71c42de4":"code","1cd7d00d":"code","768703cc":"code","3153cba0":"code","d33b2080":"code","bd9fe849":"code","df2867eb":"code","bb4863d4":"code","48b91539":"code","454e4c9b":"code","b944680c":"code","2ce4e07b":"code","11e3fc36":"code","17f153b2":"code","a9ebe441":"code","277ed137":"markdown","97a6fc00":"markdown","c551fb9b":"markdown","471feefb":"markdown"},"source":{"da095e96":"import os\nimport sys\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\n%matplotlib inline","77fbbb9b":"working_directory_path = \"\/kaggle\/input\/ieee-fraud-detection\/\"\nout_dir = \"\/kaggle\/working\/\"\nos.chdir(working_directory_path)","b9d202b8":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\n# Timing decorator\nfrom functools import wraps\nfrom time import time\n\ndef timing(f):\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        start = time()\n        result = f(*args, **kwargs)\n        end = time()\n        print('Elapsed time: {:.2f} Sec'.format(end-start))\n        return result\n    return wrapper","f1a34b79":"\n# Read CSV and return df\n@timing\ndef data_load():\n    train_identity = pd.read_csv(\"train_identity.csv\")\n    train_transaction = pd.read_csv(\"train_transaction.csv\")\n\n    test_identity = pd.read_csv(\"test_identity.csv\")\n    test_transaction = pd.read_csv(\"test_transaction.csv\")\n\n    train_df = pd.merge(train_identity, train_transaction, on = 'TransactionID', how='right')\n    test_df = pd.merge(test_identity, test_transaction, on = 'TransactionID', how='right')\n    \n    print(\"INFO - Data load and merge complete\")\n    print(\"INFO - Train - \", train_df.shape)\n    print(\"INFO - Submission - \", test_df.shape)\n    \n    return train_df, test_df\n\n@timing\ndef data_info(df):\n    columns = df.columns\n    \n# Create Metadata object for df\n@timing\ndef data_df_metadata(df):\n    \n    total_rows = len(df.index)\n    na_count = df.isna().sum().to_list()\n    na_pct =  list(map(lambda x: round(x \/ total_rows * 100) , na_count))\n    unique_count = list(map(lambda x: len(df[x].unique()) , df.columns))\n    memory = round((df.memory_usage(index=False, deep=False)\/1024**2),2).to_list()\n    \n    print(len(df.columns.to_list()), len(df.dtypes.to_list()), len(df.isna().sum().to_list()), len(na_pct), len(unique_count), len(memory))\n    \n    metadata_dict = {'column': df.columns.to_list(), \n                     'dtype': df.dtypes.to_list(),\n                     'na_count': na_count, \n                     'na_pct': na_pct,\n                     'unique_count': unique_count,\n                     'memory': memory}\n    return pd.DataFrame(metadata_dict)\n\n# Save data as pickle\ndef data_save_pkl(train_df, submission_df):\n    train_df.to_pickle(out_dir + \"train_df.pkl\")\n    print(\"INFO - train_df saved as pkl\")\n    submission_df.to_pickle(out_dir + \"submission_df.pkl\")\n    print(\"INFO - submission_df saved as pkl\")\n\n# Print Categorical info\ndef data_print_categorical(df):\n    for col in df.columns:\n        if (df[col].dtype == 'object'):\n            print(\"---------- ---------- ----------\")\n            print(df[col].describe())\n            print(\"----------\")\n            print(df[col].value_counts(dropna=False))\n            \n            \n# Load equal no.of target class data\n@timing\ndef data_load_equal_target_count(train_df):\n    positive_train_df = train_df[train_df.isFraud == 1]\n    negative_train_df = train_df[train_df.isFraud == 0].sample(n=positive_train_df.shape[0], random_state=10)\n    \n    combine_df = positive_train_df.append(negative_train_df).sample(frac=1, random_state=10)\n    print(positive_train_df.shape, negative_train_df.shape, combine_df.shape)\n    \n    return combine_df","76e480b4":"input_train_df, input_test_df = data_load()","f8f14478":"train_df = data_load_equal_target_count(input_train_df)\ntest_df = input_test_df\n# del input_train_df","e66421aa":"# sample_train_df = input_train_df.sample(frac=0.2)","86c80683":"# # sample_train_df.columns.to_list()\n\n# cols_show = ['TransactionDT',\n#  'TransactionAmt',\n#  'ProductCD',\n#  'card1',\n#  'card2',\n#  'card3',\n#  'card4',\n#  'card5',\n#  'card6',\n#  'addr1',\n#  'addr2',\n#  'dist1',\n#  'dist2',\n#  'P_emaildomain',\n#  'R_emaildomain']\n\n# sample_train_df[cols_show]\n\n# sample_train_df['D5'].unique()\n# # sample_train_df['id_03'].hist()","9933a04e":"# train_df = reduce_mem_usage(train_df)\n# test_df = reduce_mem_usage(test_df)\n\n# data_save_pkl(train_df, submission_df)","25dc220d":"# msno.bar(train_df, figsize=(60, 10))\n# msno.matrix(train_df, figsize=(40, 10))","c54e64d4":"# train_df.info()","19b2beaf":"# Drop columns which have > 10% NAN\nmetadata_df = data_df_metadata(train_df)\ncolumns_to_drop = metadata_df[metadata_df['na_pct']>53].column.to_list()\ntrain_df = train_df.drop(columns_to_drop, axis=1)\n# columns_to_drop.remove('isFraud')\ntest_df = test_df.drop(columns_to_drop, axis=1)\n\nmetadata_df = data_df_metadata(train_df)\n","4740e3fe":"# submission_df.info()\nsubmission_df = test_df['TransactionID']\nsubmission_df","71b3858d":"# data_print_categorical(train_df)\ntrain_df = train_df.drop('TransactionID', axis=1)\ntest_df = test_df.drop('TransactionID', axis=1)\n\ntrain_df = train_df.drop('P_emaildomain', axis=1)\ntest_df = test_df.drop('P_emaildomain', axis=1)","02928218":"# train_df","bfc4a6ad":"data_print_categorical(train_df)","33adfd1e":"# train_df = reduce_mem_usage(train_df)\n# test_df = reduce_mem_usage(test_df)","6ed1117e":"train_df.fillna(-999, inplace=True)\ntest_df.fillna(-999, inplace=True)","cadbb561":"from sklearn.preprocessing import LabelEncoder \n\nmetadata_df = data_df_metadata(train_df)\ncol_list = metadata_df[metadata_df['dtype'] == 'object'].column.to_list()\nprint(col_list)\n\nencoders = {}\n\n@timing\ndef setup_encoders(df, col_list):\n    encoders = {}\n    for col in col_list:\n        print('processing: ', col)\n        LE = LabelEncoder() \n        encoders[col] = LE.fit(list(df[col].astype(str).values))\n    return encoders\n\n@timing\ndef encode_data(df, col_list, encoders):\n    for col in col_list:\n        print('processing: ', col)\n        LE = encoders[col]\n        df[col] = LE.transform(list(df[col].astype(str).values)) \n    return df\n\nencoders = setup_encoders(train_df, col_list)\n\ntrain_df = encode_data(train_df, col_list, encoders)\ntest_df = encode_data(test_df, col_list, encoders)","9ec50771":"test_df","9f07cb6d":"# train_df\nfrom sklearn.model_selection import train_test_split\nX_train, X_test = train_test_split(train_df, test_size = 0.4, random_state = 0)","71c42de4":"Y_train = X_train['isFraud']\nX_train = X_train.drop(['isFraud'], axis=1)\n\nY_test = X_test['isFraud']\nX_test = X_test.drop(['isFraud'], axis=1)","1cd7d00d":"# X_train","768703cc":"# from sklearn.preprocessing import RobustScaler\n\n# scaler = RobustScaler()\n\n# def data_scalar(train_df, test_df, sub_df):\n#     scaled_train_df = scaler.fit_transform(train_df)\n#     scaled_test_df = scaler.fit_transform(test_df)\n#     scaled_sub_df = scaler.fit_transform(sub_df)\n    \n#     return pd.DataFrame(scaled_train_df), pd.DataFrame(scaled_test_df), pd.DataFrame(scaled_train_df), \n\n# X_train, X_test, test_df = data_scalar(X_train, X_test, test_df)","3153cba0":"# %%time\n\n# from sklearn import decomposition\n\n# def run_pca(df):\n#     pca = decomposition.PCA(n_components=20)\n#     pca.fit(df)\n#     print(pca.explained_variance_ratio_)\n#     return pca.transform(df)\n# X_pca = run_pca(X_train)\n# X_sub_pca = run_pca(submission_df)","d33b2080":"from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import metrics\nimport lightgbm as lgb\n\n@timing\ndef get_model_MNB(X, target, alpha=1):\n    model = MultinomialNB(alpha=alpha).fit(X, target)\n    return model\n\n@timing\ndef get_model_BNB(X, target, alpha=1):\n    model = BernoulliNB(alpha=alpha).fit(X, target)\n    return model\n\n@timing\ndef get_model_GNB(X, target, alpha=1):\n    model = GaussianNB().fit(X, target)\n    return model\n\n@timing\ndef get_model_RF(X, target):\n    model = RandomForestClassifier()\n    return model.fit(X, target)\n\n@timing\ndef get_model_XGB_simple(X, target):\n    model = xgb.XGBClassifier()\n    return model.fit(X, target)\n\n@timing\ndef get_model_XGB_custom(X, target):\n    model = xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1, subsample=0.5)\n    return model.fit(X, target)\n\n@timing\ndef get_model_lgb(lgb_train, lgb_val):\n    parameters = {\n        'application': 'binary',\n        'objective': 'binary',\n        'metric': 'auc',\n        'is_unbalance': 'true',\n        'boosting': 'gbdt',\n        'num_leaves': 31,\n        'feature_fraction': 0.5,\n        'bagging_fraction': 0.5,\n        'bagging_freq': 20,\n        'learning_rate': 0.05,\n        'verbose': 2\n    }\n    model = lgb.train(parameters,\n                       lgb_train,\n                       valid_sets=lgb_val,\n                       num_boost_round=2000,\n                       early_stopping_rounds=100)\n    return model\n\n@timing\ndef get_model_SGD(X, target):\n    model = SGDClassifier(loss='log', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)\n    return model.fit(X, target)\n\n@timing\ndef run_exp(model, X_test, Y_test):\n    prediction = model.predict_proba(X_test)\n    score = prediction[:, 1].round(1)\n    plt.hist(score)\n#     print(metrics.classification_report(Y_test, score))\n    print(\"ROC_AUC: \", metrics.roc_auc_score(Y_test, score))\n    return model, prediction\n\n@timing\ndef run_exp_lgb(model, X_test, Y_test):\n    prediction = model.predict(X_test, num_iteration=model.best_iteration)\n    print(prediction)\n    plt.hist(prediction)\n    return model, prediction\n\n@timing\ndef run_all_exp():\n    model_BernoulliNB  = get_model_BNB(X_train, Y_train, 1)\n    print(\"BernoulliNB\", run_exp(model_BernoulliNB, X_test, Y_test))\n    print(\"---------- ----------\")\n    model_RF  = get_model_RF(X_train, Y_train)\n    print(\"RF\", run_exp(model_RF, X_test, Y_test))\n    print(\"---------- ----------\")\n    model_SGD  = get_model_SGD(X_train, Y_train)\n    print(\"SGD\", run_exp(model_SGD, X_test, Y_test))\n    print(\"---------- ----------\")\n#     model_RF  = get_model_RF(X_train, Y_train)\n#     print(\"RF\", run_exp(model_RF, X_test, Y_test))\n#     print(\"---------- ----------\")\n#     model_RF  = get_model_RF(X_train, Y_train)\n#     print(\"RF\", run_exp(model_RF, X_test, Y_test))\n#     print(\"---------- ----------\")\n\n@timing\ndef save_submission(model, X_test, X_sub, name, isLGB = False):\n    prediction = []\n    if (isLGB):\n        prediction = model.predict(X_test)\n        score = prediction.round(1)\n    else:\n        prediction = model.predict_proba(X_test)\n        score = prediction[:, 1].round(1)\n    print(score)\n    print(len(score))\n    plt.hist(score)\n    submission_dict = {'TransactionID': X_sub, 'isFraud': score}\n    out_df = pd.DataFrame(submission_dict) \n\n    # saving the dataframe \n    os.chdir(out_dir)\n    out_df.to_csv(name, index=False)\n    return score\n    ","bd9fe849":"model_BernoulliNB  = get_model_BNB(X_train, Y_train, 1)\n_, pred = run_exp(model_BernoulliNB, X_test, Y_test)","df2867eb":"model_RF  = get_model_RF(X_train, Y_train)\n_, pred = run_exp(model_RF, X_test, Y_test)","bb4863d4":"# get_model_XGB_simple\n# model_XGB_simple  = get_model_XGB_simple(X_train, Y_train)\n# _, pred = run_exp(model_XGB_simple, X_test, Y_test)","48b91539":"model_XGB_custom  = get_model_XGB_custom(X_train, Y_train)\n_, pred = run_exp(model_XGB_custom, X_test, Y_test)","454e4c9b":"lgb_train = lgb.Dataset(X_train, Y_train)\nlgb_eval = lgb.Dataset(X_test, Y_test)\n\nmodel_lgb = get_model_lgb(lgb_train, lgb_eval)\n_, pred = run_exp_lgb(model_lgb, X_test, Y_test)","b944680c":"# model_SGD  = get_model_SGD(X_train, Y_train)\n# _, pred = run_exp(model_SGD, X_test, Y_test)","2ce4e07b":"# run_all_exp()","11e3fc36":"score = save_submission(model_XGB_custom, test_df, submission_df, '24_XGB_2204_submsission.csv')","17f153b2":"score = save_submission(model_lgb, test_df, submission_df, '24_LGB_2204_submsission.csv', True)","a9ebe441":"# import autosklearn.classification\n# import sklearn.model_selection\n# import sklearn.metrics\n\n# automl = autosklearn.classification.AutoSklearnClassifier()\n# automl.fit(X_train, Y_train)\n# Y_hat = automl.predict(X_test)\n# print(\"Accuracy score\", sklearn.metrics.accuracy_score(Y_test, Y_hat))","277ed137":"## Reference\n\n* https:\/\/www.kaggle.com\/suoires1\/fraud-detection-eda-and-modeling","97a6fc00":"## DATA Load \/ Processing","c551fb9b":"## Imports","471feefb":"## Utils"}}