{"cell_type":{"5df7f4a3":"code","2ac238f4":"code","ab74947f":"code","efb19df8":"code","d47bbf23":"code","87d3d4e7":"code","1ffa6434":"code","23d8c27e":"code","ef2eafe4":"code","53c54404":"code","0cd44b77":"code","8b84826b":"code","c3c4a74a":"code","7697b07b":"code","4ddfcf53":"code","8e0c9e3b":"code","6bcf44d3":"code","8acb4e46":"code","8229714f":"code","29e89c90":"code","d2d74652":"code","4be0b51f":"code","3beb6aff":"code","81c862ef":"code","d2cb8657":"code","2a0d5aed":"code","5f830a3e":"code","3256adc4":"code","283d1fa4":"code","27c5e7ee":"code","d28536e1":"code","68359065":"code","04534045":"code","aa6b50ee":"code","570a0a47":"code","0f51cef6":"code","665cf4bf":"code","0600974e":"code","fff5b5c0":"code","3f34f819":"code","d655bce9":"markdown","88958d03":"markdown","69dbf72c":"markdown","3bbd1f29":"markdown"},"source":{"5df7f4a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2ac238f4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport string\nimport seaborn as sns\nimport spacy\n\nnlp = spacy.load('en')\n\n%matplotlib inline","ab74947f":"# Reading data\ntweets_df = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')","efb19df8":"# Displaying top 5 rows of the data\ntweets_df.head()","d47bbf23":"print(f'We have {tweets_df.shape[0]} rows of data')","87d3d4e7":"print(f'We have {tweets_df.keyword.nunique()} unique values in keyword and {tweets_df.location.nunique()} unique values in location.')","1ffa6434":"print(f'There are {tweets_df.target.value_counts()[0]} tweets that are not disaster and {tweets_df.target.value_counts()[1]} tweets that are real disaster')","23d8c27e":"# Pie chart showing distribution of tweets (disaster and no disaster)\ntarget = ['Disaster', 'No Disater']\ncolors = ['r', 'g']\nplt.pie(tweets_df.target.value_counts(), labels=target, colors=colors, startangle=90, autopct='%.1f%%')\nplt.show()","ef2eafe4":"lens = tweets_df.text.str.len()\nlens.mean(), lens.std(), lens.max()","53c54404":"lens.hist();","0cd44b77":"def remove_URL(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ntweets_df['text'] = tweets_df['text'].apply(remove_URL)","8b84826b":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ntweets_df['text'] = tweets_df['text'].apply(remove_html)","c3c4a74a":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ntweets_df['text'] = tweets_df['text'].apply(remove_emoji)","7697b07b":"tweets_df['text'] = tweets_df['text'].str.lower()","4ddfcf53":"def remove_stop_words_and_punct(text):\n    doc = nlp(text)\n    return ' '.join([str(token) for token in doc if not token.is_stop and not token.is_punct])\n\ntweets_df['text'] = tweets_df['text'].apply(remove_stop_words_and_punct)","8e0c9e3b":"def lammetize(text):\n    doc = nlp(text)\n    return ' '.join([str(token.lemma_) for token in doc]).replace('-PRON-', 'I')\n\ntweets_df['text'] = tweets_df['text'].apply(lammetize)","6bcf44d3":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression as LR\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix","8acb4e46":"df = tweets_df[['text', 'target']]","8229714f":"X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'], test_size=0.2)","29e89c90":"lr = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', LR())])\n\nlr = lr.fit(X_train, y_train)\n\nlr_predicted = lr.predict(X_test)\n\nprint(f1_score(y_test, lr_predicted))\nprint(accuracy_score(y_test, lr_predicted))\nprint(confusion_matrix(y_test, lr_predicted))","d2d74652":"rf = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', RandomForestClassifier())])\n\nrf = rf.fit(X_train, y_train)\n\nprint(f1_score(y_test, rf.predict(X_test)))\nprint(accuracy_score(y_test, rf.predict(X_test)))\nprint(confusion_matrix(y_test, rf.predict(X_test)))","4be0b51f":"et = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', ExtraTreesClassifier())])\n\net = et.fit(X_train, y_train)\n\nprint(f1_score(y_test, et.predict(X_test)))\nprint(accuracy_score(y_test, et.predict(X_test)))\nprint(confusion_matrix(y_test, et.predict(X_test)))","3beb6aff":"ada = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', AdaBoostClassifier())])\n\nada = ada.fit(X_train, y_train)\n\nprint(f1_score(y_test, ada.predict(X_test)))\nprint(accuracy_score(y_test, ada.predict(X_test)))\nprint(confusion_matrix(y_test, ada.predict(X_test)))","81c862ef":"gb = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode', \n                           use_idf=1,smooth_idf=1, sublinear_tf=1,max_features=None)), ('clf', GradientBoostingClassifier())])\n\ngb = gb.fit(X_train, y_train)\n\nprint(f1_score(y_test, gb.predict(X_test)))\nprint(accuracy_score(y_test, gb.predict(X_test)))\nprint(confusion_matrix(y_test, gb.predict(X_test)))","d2cb8657":"pred_df = pd.DataFrame([lr.predict(X_test), rf.predict(X_test), et.predict(X_test), ada.predict(X_test), gb.predict(X_test)]).T\npred_df.columns = ['LR', 'RF', 'ET', 'ADA', 'GB']","2a0d5aed":"import statistics","5f830a3e":"pred_df['Mode'] = pred_df.apply(statistics.mode, axis=1)","3256adc4":"print(f1_score(y_test, pred_df['Mode']))\nprint(accuracy_score(y_test, pred_df['Mode']))\nprint(confusion_matrix(y_test, pred_df['Mode']))","283d1fa4":"df_test = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","27c5e7ee":"def remove_URL(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ndf_test['text'] = df_test['text'].apply(remove_URL)","d28536e1":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ndf_test['text'] = df_test['text'].apply(remove_html)","68359065":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ndf_test['text'] = df_test['text'].apply(remove_emoji)","04534045":"df_test['text'] = df_test['text'].str.lower()","aa6b50ee":"def remove_stop_words_and_punct(text):\n    doc = nlp(text)\n    return ' '.join([str(token) for token in doc if not token.is_stop and not token.is_punct])\n\ndf_test['text'] = df_test['text'].apply(remove_stop_words_and_punct)","570a0a47":"def lammetize(text):\n    doc = nlp(text)\n    return ' '.join([str(token.lemma_) for token in doc]).replace('-PRON-', 'I')\n\ndf_test['text'] = df_test['text'].apply(lammetize)","0f51cef6":"dfte = df_test['text']","665cf4bf":"test_pred_df = pd.DataFrame([lr.predict(dfte), rf.predict(dfte), et.predict(dfte), ada.predict(dfte), gb.predict(dfte)]).T\ntest_pred_df.columns = ['LR', 'RF', 'ET', 'ADA', 'GB']\n\nimport statistics\n\ntest_pred_df['Mode'] = test_pred_df.apply(statistics.mode, axis=1)","0600974e":"df_subm = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')","fff5b5c0":"df_subm['target'] = test_pred_df['Mode']","3f34f819":"df_subm.to_csv('submission.csv', index=False)","d655bce9":"# Dataset","88958d03":"# Submission","69dbf72c":"# Data Cleaning","3bbd1f29":"# EDA"}}