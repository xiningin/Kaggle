{"cell_type":{"948109d8":"code","771f2c73":"code","3ae12271":"code","46d8ca1d":"code","9b7a3091":"code","3312465c":"code","349876cb":"markdown","425b3f2c":"markdown","f22a7c5c":"markdown","1ebb86ae":"markdown","f2cf2f84":"markdown","b76f53da":"markdown","e7f11007":"markdown","5505879d":"markdown","d6d8498f":"markdown","99224f07":"markdown","c44a4d2d":"markdown","e4fa3315":"markdown","b89d80a5":"markdown","ff08516a":"markdown","bc781df0":"markdown"},"source":{"948109d8":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\n# _______________________________________\n\n# Kernels Data (Public Score & File Path)\n\ndfk = pd.DataFrame({ \n    'Kernel ID': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M'],  \n    'Score':     [14.763, 13.168, 11.600, 10.959, 9.773, 9.530, 8.500, 8.418, 8.333, 8.309, 8.073, 7.745, 7.661],   \n    'File Path': ['..\/input\/indoor14763\/Indoor14763.csv', '..\/input\/indoor13168\/Indoor13168.csv', '..\/input\/indoor11600\/Indoor11600.csv', '..\/input\/indoor10959\/Indoor10959.csv', '..\/input\/indoor9773\/Indoor9773.csv', '..\/input\/indoor9530\/Indoor9530.csv', '..\/input\/indoor8500\/Indoor8500.csv', '..\/input\/indoor8418\/Indoor8418.csv', '..\/input\/indoor8333\/Indoor8333.csv', '..\/input\/indoor8309\/Indoor8309.csv', '..\/input\/indoor8073\/Indoor8073.csv', '..\/input\/indoornav7745sub\/submission.csv', '..\/input\/indoor7661\/Indoor7661.csv']     \n})    \n    \ndfk   ","771f2c73":"ff1x = 0.50   # Hyperparameter\nff1y = 0.50   # Hyperparameter\n\nff2x = 0.95   # Hyperparameter\nff2y = 0.95   # Hyperparameter\n\nff3x = 0.90   # Hyperparameter\nff3y = 0.90   # Hyperparameter\n\nmain = pd.read_csv(dfk.iloc[12, 2]) \nsupport = pd.read_csv(dfk.iloc[11, 2])\n\nrx , ry = [] , []\ngenerated  = main.copy()  \n\nmx , my , mz = [] , [] , []\nmx = main.iloc[:, 2].tolist()\nmy = main.iloc[:, 3].tolist()\nmz = main.iloc[:, 1].tolist()\n\nsx , sy = [] , []\nsx = support.iloc[:, 2].tolist()\nsy = support.iloc[:, 3].tolist()\n\nkx = [[],[],[],[],[],[],[],[],[],[],[]]\nky = [[],[],[],[],[],[],[],[],[],[],[]]\nfor n in range (11):\n    kernel   = pd.read_csv(dfk.iloc[n, 2])  \n    kx[n] = kernel.iloc[:, 2].tolist()\n    ky[n] = kernel.iloc[:, 3].tolist()\n\nfor j in range(len(main)):\n    \n    ex = (mx[j] * ff1x) + (sx[j] * (1.- ff1x))\n    ey = (my[j] * ff1y) + (sy[j] * (1.- ff1y))\n    \n    if (mx[j] >= sx[j]):\n        a = mx[j]\n        b = sx[j]\n    else: \n        a = sx[j]\n        b = mx[j]\n        \n    if (my[j] >= sy[j]):\n        c = my[j]\n        d = sy[j]\n    else: \n        c = sy[j]\n        d = my[j]    \n\n    for k in range (5):            \n        if ((b <= kx[k][j] <= a) and (d <= ky[k][j] <= c)):\n            \n            ex = (ex * ff2x) + (kx[k][j] * (1.- ff2x))\n            ey = (ey * ff2y) + (ky[k][j] * (1.- ff2y))\n            \n            print(f'Row:{j}\\t Kernel Number:{k}\\t Floor:{mz[j]}')\n            print(f'Main:({mx[j]},{my[j]})\\nSupport:({sx[j]},{sy[j]})\\nKernel:({kx[k][j]},{ky[k][j]})\\nResult:({ex},{ey})\\n')\n            \n    for k in range (5, 11):            \n        if ((b <= kx[k][j] <= a) and (d <= ky[k][j] <= c)):\n            \n            ex = (ex * ff3x) + (kx[k][j] * (1.- ff3x))\n            ey = (ey * ff3y) + (ky[k][j] * (1.- ff3y))\n            \n            print(f'Row:{j}\\t Kernel Number:{k}\\t Floor:{mz[j]}')\n            print(f'Main:({mx[j]},{my[j]})\\nSupport:({sx[j]},{sy[j]})\\nKernel:({kx[k][j]},{ky[k][j]})\\nResult:({ex},{ey})\\n')            \n            \n    rx.append(ex)\n    ry.append(ey)    \n\ngenerated.iloc[:, 2] = rx\ngenerated.iloc[:, 3] = ry\n","3ae12271":"import json\nimport matplotlib.pylab as plt\n","46d8ca1d":"def split_col(df):\n    \"\"\"\n    Split submission site\/path\/timestamp into individual columns.\n    \"\"\"\n    df = pd.concat(\n        [\n            df[\"site_path_timestamp\"]\n            .str.split(\"_\", expand=True)\n            .rename(columns={0: \"site\", 1: \"path\", 2: \"timestamp\"}),\n            df,\n        ],\n        axis=1,\n    ).copy()\n    return df\n\n\ndef plot_preds(\n    site,\n    floorNo,\n    sub=None,\n    true_locs=None,\n    base=\"..\/input\/indoor-location-navigation\",\n    show_train=True,\n    show_preds=True,\n):\n    \"\"\"\n    Plots predictions on floorplan map.\n    \"\"\"\n    # Prepare width_meter & height_meter (taken from the .json file)\n    floor_plan_filename = f\"{base}\/metadata\/{site}\/{floorNo}\/floor_image.png\"\n    json_plan_filename = f\"{base}\/metadata\/{site}\/{floorNo}\/floor_info.json\"\n    with open(json_plan_filename) as json_file:\n        json_data = json.load(json_file)\n\n    width_meter = json_data[\"map_info\"][\"width\"]\n    height_meter = json_data[\"map_info\"][\"height\"]\n\n    floor_img = plt.imread(f\"{base}\/metadata\/{site}\/{floorNo}\/floor_image.png\")\n\n    fig, ax = plt.subplots(figsize=(12, 12))\n    plt.imshow(floor_img)\n\n    if show_train:\n        true_locs[\"x_\"] = true_locs[\"x\"] * floor_img.shape[0] \/ height_meter\n        true_locs[\"y_\"] = (\n            true_locs[\"y\"] * -1 * floor_img.shape[1] \/ width_meter\n        ) + floor_img.shape[0]\n        true_locs.query(\"site == @site and floorNo == @floorNo\").groupby(\"path\").plot(\n            x=\"x_\",\n            y=\"y_\",\n            style=\"+\",\n            ax=ax,\n            label=\"train waypoint location\",\n            color=\"grey\",\n            alpha=0.5,\n        )\n\n    if show_preds:\n        sub[\"x_\"] = sub[\"x\"] * floor_img.shape[0] \/ height_meter\n        sub[\"y_\"] = (\n            sub[\"y\"] * -1 * floor_img.shape[1] \/ width_meter\n        ) + floor_img.shape[0]\n        for path, path_data in sub.query(\n            \"site == @site and floorNo == @floorNo\"\n        ).groupby(\"path\"):\n            path_data.plot(\n                x=\"x_\",\n                y=\"y_\",\n                style=\".-\",\n                ax=ax,\n                title=f\"{site} - floor - {floorNo}\",\n                alpha=1,\n                label=path,\n            )\n    return fig, ax\n","9b7a3091":"sub = split_col(generated)\n\ntrue_locs = pd.read_csv(\"..\/input\/indoor-location-train-waypoints\/train_waypoints.csv\")\n\n# Add floor No to sub file\nsub = sub.merge(true_locs[[\"site\", \"floor\", \"floorNo\"]].drop_duplicates())\n\n\nfor (site, floorNo), d in sub.groupby([\"site\", \"floorNo\"]):\n    fig, ax = plot_preds(site, floorNo, sub, true_locs)\n    # Remove duplicate labels\n    handles, labels = ax.get_legend_handles_labels()\n    by_label = dict(zip(labels, handles))\n    plt.legend(\n        by_label.values(), by_label.keys(), loc=\"center left\", bbox_to_anchor=(1, 0.5)\n    )\n    plt.show()\n    ","3312465c":"sub = generated\n\nsub.to_csv(\"submission.csv\", index=False)\n","349876cb":"<div class=\"alert alert-success\">  \n<\/div>","425b3f2c":"<div>\n    <h1 align=\"center\"> Comparative Method - Part(A)<\/h1><\/h1>\n    <h2 align=\"center\">Identify the position of a smartphone in a shopping mal<\/h2>\n    <h3 align=\"center\">By: Somayyeh Gholami & Mehran Kazeminia<\/h3>\n<\/div>","f22a7c5c":"### - In this notebook we have used the results of thirteen general notebooks. These results have been used for \"Ensembling\" and \"Comparative Method\". Thanks to everyone who shared their notebooks, the addresses of some of the used notebooks are as follows:\n\nhttps:\/\/www.kaggle.com\/kokitanisaka\/lstm-by-keras-with-unified-wi-fi-feats\n\nhttps:\/\/www.kaggle.com\/oxzplvifi\/indoor-gbm-postprocessing-xy-prediction\n\nhttps:\/\/www.kaggle.com\/nigelhenry\/simple-99-accurate-floor-model\n\nhttps:\/\/www.kaggle.com\/ghaiyur\/lightgbm-regressor\n\nhttps:\/\/www.kaggle.com\/hiro5299834\/wifi-features-with-lightgbm-kfold\n\n### - For \"Ensembling\", we used two notebooks with scores of 7.661 and 7.745. And for the \"Comparative Method\" we got help from the remaining eleven notebooks. If you read the code carefully, you will see that we have only allowed some of the results of these eleven notebooks to affect the overall result. That is, they can only be effective if their X and Y values are between the X and Y of the two main notebooks. This is a very important point.\n\n### - In public notebooks, the best \"Floor Prediction\" seems to have been done in the lower notebook. Because we \"Submit\" many public notebooks again with the same prediction and get a better score. The end result of this notebook is done with the same prediction. Thanks again for sharing this great notebook.\n\nhttps:\/\/www.kaggle.com\/nigelhenry\/simple-99-accurate-floor-model\n\n### - \"Data Visualization\" is of particular importance in this challenge. Because the location of the corridors is important. There are two great notebooks with which we can improve our notebook score. Of course, we will use the first notebook in \"Part B\". Thanks for sharing these notebooks:\n\nhttps:\/\/www.kaggle.com\/robikscube\/indoor-navigation-snap-to-grid-post-processing\n\nhttps:\/\/www.kaggle.com\/rafaelcartenet\/scaled-floors-geojsons-new-dataset\n\n### - If you upgrade the score of all notebooks with \"Data Visualization\" method before \"Ensembling\" and then perform the \"Ensembling\" operation, all the errors will add up and you will not get a good result. This means using the \"Data Visualization\" method only in the last step. We will do the same in \"Part B\". The reason we publish two notebooks is that at the end of this challenge we want to look at the public scores and the private scores for each of the methods and examine the so-called \"Overfitting\".\n\n### - You can definitely mix your notebook results with the results of this notebook and get better results. You can also get better results by changing the hyperparameters of this notebook.\n\n## >>> Good Luck <<<\n\n","1ebb86ae":"<div class=\"alert alert-success\">  \n<\/div>","f2cf2f84":"# Description:","b76f53da":"# Data Visualization","e7f11007":"# Import & Data Set","5505879d":"# If you find this work useful, please don't forget upvoting :)","d6d8498f":"<div class=\"alert alert-success\">  \n<\/div>","99224f07":"# submission","c44a4d2d":"# Ensembling & Comparative Method","e4fa3315":"<div class=\"alert alert-success\">  \n<\/div>","b89d80a5":"<div class=\"alert alert-success\">  \n<\/div>","ff08516a":"<div class=\"alert alert-success\">  \n<\/div>","bc781df0":"<div class=\"alert alert-success\">  \n<\/div>"}}