{"cell_type":{"8618c216":"code","158a0e22":"code","d64a44df":"code","816b4705":"code","9cfb7301":"code","1f5238f8":"code","733ea130":"code","0abeb7ce":"code","8caf0611":"code","b54e6df7":"code","dc6f110a":"code","03f08cfe":"code","b358da7d":"code","d90e5ccd":"code","88a78f55":"code","4565d635":"code","d0b26d03":"code","d9525463":"code","8ba9556d":"markdown","959c23d2":"markdown","2e58221b":"markdown","c5ba3d51":"markdown","fcc03b01":"markdown","5e722a1c":"markdown","cae46994":"markdown"},"source":{"8618c216":"import os\n# TRAIN_ABLE_FALSE=True\n# if TRAIN_ABLE_FALSE:\n#     os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\nimport numpy as np\nimport pandas as pd\nimport sklearn.metrics as mtr\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda,BatchNormalization,LeakyReLU,PReLU,ELU,ThresholdedReLU,Concatenate\nfrom keras.models import Model\nimport keras.backend as K\nfrom keras.callbacks import Callback\nfrom  keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom tqdm import tqdm_notebook\nfrom functools import partial\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\nTRAIN_OFFLINE = False\n\n\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 150)","158a0e22":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d64a44df":"# train = pd.read_csv('\/kaggle\/input\/nfl-big-data-bowl-2020\/train.csv', dtype={'WindSpeed': 'object'})\nif TRAIN_OFFLINE:\n    train = pd.read_csv('..\/input\/train.csv', dtype={'WindSpeed': 'object'})\nelse:\n    train = pd.read_csv('\/kaggle\/input\/nfl-big-data-bowl-2020\/train.csv', dtype={'WindSpeed': 'object'})\n    ","816b4705":"outcomes = train[['GameId','PlayId','Yards']].drop_duplicates()","9cfb7301":"train.head()","1f5238f8":"def strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])\/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef orientation_to_cat(x):\n    x = np.clip(x, 0, 360 - 1)\n    try:\n        return str(int(x\/15))\n    except:\n        return \"nan\"\ndef preprocess(train):\n    ## GameClock\n    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n\n    ## Height\n    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    ## Time\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m\/%d\/%Y\"))\n\n    ## Age\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()\/seconds_in_year, axis=1)\n    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n\n    ## WindSpeed\n    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))\/2 if not pd.isna(x) and '-' in x else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))\/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n\n    ## Weather\n    train['GameWeather_process'] = train['GameWeather'].str.lower()\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n\n    ## Rusher\n    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n    train = train.merge(temp, on = \"PlayId\")\n    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n    ## dense -> categorical\n    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n    # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n    # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n    # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n\n    ## Orientation and Dir\n    train[\"Orientation_ob\"] = train[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n    train[\"Dir_ob\"] = train[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n    train[\"Orientation_sin\"] = train[\"Orientation\"].apply(lambda x : np.sin(x\/360 * 2 * np.pi))\n    train[\"Orientation_cos\"] = train[\"Orientation\"].apply(lambda x : np.cos(x\/360 * 2 * np.pi))\n    train[\"Dir_sin\"] = train[\"Dir\"].apply(lambda x : np.sin(x\/360 * 2 * np.pi))\n    train[\"Dir_cos\"] = train[\"Dir\"].apply(lambda x : np.cos(x\/360 * 2 * np.pi))\n\n    ## diff Score\n    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n\n    ## Turf\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four\/Seven Turf':'Artificial', 'natural grass':'Natural'} \n    train['Turf'] = train['Turf'].map(Turf)\n\n    ## OffensePersonnel\n    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffensePersonnelSplit(x)))\n    temp.columns = [\"Offense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## DefensePersonnel\n    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefensePersonnelSplit(x)))\n    temp.columns = [\"Defense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## sort\n#     train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n    return train","733ea130":"def create_features(df, deploy=False):\n    def new_X(x_coordinate, play_direction):\n        if play_direction == 'left':\n            return 120.0 - x_coordinate\n        else:\n            return x_coordinate\n\n    def new_line(rush_team, field_position, yardline):\n        if rush_team == field_position:\n            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n            return 10.0 + yardline\n        else:\n            # half the field plus the yards between midfield and the line of scrimmage\n            return 60.0 + (50 - yardline)\n\n    def new_orientation(angle, play_direction):\n        if play_direction == 'left':\n            new_angle = 360.0 - angle\n            if new_angle == 360.0:\n                new_angle = 0.0\n            return new_angle\n        else:\n            return angle\n\n    def euclidean_distance(x1,y1,x2,y2):\n        x_diff = (x1-x2)**2\n        y_diff = (y1-y2)**2\n\n        return np.sqrt(x_diff + y_diff)\n\n    def back_direction(orientation):\n        if orientation > 180.0:\n            return 1\n        else:\n            return 0\n\n    def update_yardline(df):\n        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n\n        return new_yardline\n\n    def update_orientation(df, yardline):\n        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n\n        df = df.drop('YardLine', axis=1)\n        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n\n        return df\n\n    def back_features(df):\n        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n        carriers = carriers.rename(columns={'X':'back_X',\n                                            'Y':'back_Y'})\n        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n\n        return carriers\n\n    def features_relative_to_back(df, carriers):\n        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n                                         .reset_index()\n        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n                                   'min_dist','max_dist','mean_dist','std_dist']\n\n        return player_distance\n\n    def defense_features(df):\n        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        defense = defense.groupby(['GameId','PlayId'])\\\n                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n                         .reset_index()\n        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n\n        return defense\n\n    def static_features(df):\n        \n        \n        add_new_feas = []\n\n        ## Height\n        df['PlayerHeight_dense'] = df['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n        \n        add_new_feas.append('PlayerHeight_dense')\n\n        ## Time\n        df['TimeHandoff'] = df['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n        df['TimeSnap'] = df['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n        df['TimeDelta'] = df.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n        df['PlayerBirthDate'] =df['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m\/%d\/%Y\"))\n\n        ## Age\n        seconds_in_year = 60*60*24*365.25\n        df['PlayerAge'] = df.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()\/seconds_in_year, axis=1)\n        add_new_feas.append('PlayerAge')\n\n        ## WindSpeed\n        df['WindSpeed_ob'] = df['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n        df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))\/2 if not pd.isna(x) and '-' in x else x)\n        df['WindSpeed_ob'] = df['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))\/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n        df['WindSpeed_dense'] = df['WindSpeed_ob'].apply(strtofloat)\n        add_new_feas.append('WindSpeed_dense')\n\n        ## Weather\n        df['GameWeather_process'] = df['GameWeather'].str.lower()\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n        df['GameWeather_process'] = df['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n        df['GameWeather_dense'] = df['GameWeather_process'].apply(map_weather)\n        add_new_feas.append('GameWeather_dense')\n#         ## Rusher\n#         train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n#         train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n#         temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n#         train = train.merge(temp, on = \"PlayId\")\n#         train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n        ## dense -> categorical\n#         train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n#         train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n#         train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n#         train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n        # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n        # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n        # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n\n        ## Orientation and Dir\n        df[\"Orientation_ob\"] = df[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n        df[\"Dir_ob\"] = df[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n        df[\"Orientation_sin\"] = df[\"Orientation\"].apply(lambda x : np.sin(x\/360 * 2 * np.pi))\n        df[\"Orientation_cos\"] = df[\"Orientation\"].apply(lambda x : np.cos(x\/360 * 2 * np.pi))\n        df[\"Dir_sin\"] = df[\"Dir\"].apply(lambda x : np.sin(x\/360 * 2 * np.pi))\n        df[\"Dir_cos\"] = df[\"Dir\"].apply(lambda x : np.cos(x\/360 * 2 * np.pi))\n        add_new_feas.append(\"Dir_sin\")\n        add_new_feas.append(\"Dir_cos\")\n\n        ## diff Score\n        df[\"diffScoreBeforePlay\"] = df[\"HomeScoreBeforePlay\"] - df[\"VisitorScoreBeforePlay\"]\n        add_new_feas.append(\"diffScoreBeforePlay\")\n        \n    \n    \n        static_features = df[df['NflId'] == df['NflIdRusher']][add_new_feas+['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n#         static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n        static_features.fillna(-999,inplace=True)\n#         for i in add_new_feas:\n#             static_features[i] = static_features[i].fillna(np.mean(static_features[i]))\n            \n\n        return static_features\n\n\n    def combine_features(relative_to_back, defense, static, deploy=deploy):\n        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n\n        if not deploy:\n            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n\n        return df\n    \n    yardline = update_yardline(df)\n    df = update_orientation(df, yardline)\n    back_feats = back_features(df)\n    rel_back = features_relative_to_back(df, back_feats)\n    def_feats = defense_features(df)\n    static_feats = static_features(df)\n    basetable = combine_features(rel_back, def_feats, static_feats, deploy=deploy)\n    \n    return basetable","0abeb7ce":"%time train_basetable = create_features(train, False)","8caf0611":"X = train_basetable.copy()\nyards = X.Yards\n\ny = np.zeros((yards.shape[0], 199))\nfor idx, target in enumerate(list(yards)):\n    y[idx][99 + target] = 1\n\nX.drop(['GameId','PlayId','Yards'], axis=1, inplace=True)","b54e6df7":"scaler = StandardScaler()\nX = scaler.fit_transform(X)","dc6f110a":"from keras.layers import Dense,Input,Flatten,concatenate,Dropout,Lambda\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nimport keras.backend as K\nimport re\nfrom keras.losses import binary_crossentropy\nfrom  keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\nimport codecs\nfrom keras.utils import to_categorical\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import KFold\n\nclass CRPSCallback(Callback):\n    \n    def __init__(self,validation, predict_batch_size=20, include_on_batch=False, verbose=0):\n        super(CRPSCallback, self).__init__()\n        self.validation = validation\n        self.predict_batch_size = predict_batch_size\n        self.include_on_batch = include_on_batch\n        self.verbose = verbose\n        \n        if self.verbose != 0:\n            print('validation shape',len(self.validation))\n\n    def on_batch_begin(self, batch, logs={}):\n        pass\n\n    def on_train_begin(self, logs={}):\n        if not ('CRPS_score_val' in self.params['metrics']):\n            self.params['metrics'].append('CRPS_score_val')\n\n    def on_batch_end(self, batch, logs={}):\n        if (self.include_on_batch):\n            logs['CRPS_score_val'] = float('-inf')\n\n    def on_epoch_end(self, epoch, logs={}):\n        logs['CRPS_score_val'] = float('-inf')\n            \n        if (self.validation):\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid)\n            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) \/ (199 * X_valid.shape[0])\n            val_s = np.round(val_s, 6)\n            logs['CRPS_score_val'] = val_s","03f08cfe":"# Calculate CRPS score\ndef crps_score(y_prediction, y_valid, shape=X.shape[0]):\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_prediction, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) \/ (199 * shape)\n    crps = np.round(val_s, 6)\n    \n    return crps","b358da7d":"def get_nn(x_tr, y_tr, x_val, y_val, shape, u1_x8=128, u2_x8=64, u3_x8=32, d1=0.5, d2=0.5, d3=0.5):\n    u1 = max(int(u1_x8 * 8), 8)\n    u2 = max(int(u2_x8 * 8), 8)\n    u3 = max(int(u3_x8 * 8), 8)\n    \n    K.clear_session()\n    inp = Input(shape = (x_tr.shape[1],))\n    x = Dense(u1, input_dim=X.shape[1], activation='relu')(inp)\n    x = Dropout(d1)(x)\n    x = BatchNormalization()(x)\n    x = Dense(u2, activation='relu')(x)\n    x = Dropout(d2)(x)\n    x = BatchNormalization()(x)\n    x = Dense(u3, activation='relu')(x)\n    x = Dropout(d3)(x)\n    x = BatchNormalization()(x)\n    \n    out = Dense(199, activation='softmax')(x)\n    model = Model(inp,out)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[])\n    \n    es = EarlyStopping(monitor='CRPS_score_val', \n                       mode='min',\n                       restore_best_weights=True, \n                       verbose=0, \n                       patience=10)\n\n    mc = ModelCheckpoint('best_model.h5',monitor='CRPS_score_val',mode='min',\n                                   save_best_only=True, verbose=0, save_weights_only=True)\n    \n    bsz = 1024\n    steps = x_tr.shape[0]\/bsz\n\n    model.fit(x_tr, y_tr,callbacks=[CRPSCallback(validation = (x_val,y_val)),es,mc], epochs=100, batch_size=bsz,verbose=0)\n    model.load_weights(\"best_model.h5\")\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    crps = crps_score(y_pred, y_valid, shape=shape)\n\n    return model, crps\n\ndef fit_nn(X=X, y=y, fold=5, u1_x8=128, u2_x8=64, u3_x8=32, d1=0.5, d2=0.5, d3=0.5):\n    crps_csv_nn = []  \n    kfold = KFold(fold, random_state = 42, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n        tr_x, tr_y = X[tr_inds], y[tr_inds]\n        val_x, val_y = X[val_inds], y[val_inds]\n        \n        # Train NN\n        _, crps_nn = get_nn(tr_x, tr_y, val_x, val_y, shape=val_x.shape[0], \n                            u1_x8=u1_x8, u2_x8=u2_x8, u3_x8=u3_x8, d1=d1, d2=d2, d3=d3)\n        crps_csv_nn.append(crps_nn)\n        \n    return -np.mean(crps_csv_nn)","d90e5ccd":"from bayes_opt import BayesianOptimization\n\npbounds = {\n           'u1_x8': (15.9, 256.1),\n           'u2_x8': (15.9, 256.1),\n           'u3_x8': (15.9, 256.1),\n           'd1': (0, 0.9),\n           'd2': (0, 0.9),\n           'd3': (0, 0.9),\n          }\n\noptimizer_nn = BayesianOptimization(\n    f=fit_nn,\n    pbounds=pbounds,\n    verbose=2,\n    random_state=42,\n)\n\noptimizer_nn.maximize(init_points=10, n_iter=50)","88a78f55":"print('Best Number of Neurons 1: ', max(int(optimizer_nn.max['params']['u1_x8'] * 8), 8))\nprint('Best Number of Neurons 2: ', max(int(optimizer_nn.max['params']['u2_x8'] * 8), 8))\nprint('Best Number of Neurons 3: ', max(int(optimizer_nn.max['params']['u3_x8'] * 8), 8))\nprint('Best Dropout Rate 1: ', round(optimizer_nn.max['params']['d1'], 5))\nprint('Best Dropout Rate 2: ', round(optimizer_nn.max['params']['d2'], 5))\nprint('Best Dropout Rate 3: ', round(optimizer_nn.max['params']['d3'], 5))","4565d635":"from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n\ndef get_rf(x_tr, y_tr, x_val, y_val, shape, mf=0.3, msl=15, mss=8, ne=50):\n    msl = int(msl)\n    mss = int(mss)\n    ne = int(ne)\n    \n    model = RandomForestRegressor(bootstrap=False, max_features=0.3, min_samples_leaf=15, \n                                  min_samples_split=8, n_estimators=50, n_jobs=-1, random_state=42)\n    model.fit(x_tr, y_tr)\n    \n    y_pred = model.predict(x_val)\n    y_valid = y_val\n    crps = crps_score(y_pred, y_valid, shape=shape)\n    \n    return model, crps\n\ndef fit_rf(X=X, y=y, fold=5, mf=0.3, msl=15, mss=8, ne=50):\n    crps_csv_rf = []  \n    kfold = KFold(fold, random_state = 42, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(yards)):\n        tr_x, tr_y = X[tr_inds], y[tr_inds]\n        val_x, val_y = X[val_inds], y[val_inds]\n        \n        # Train NN\n        _, crps_rf = get_rf(tr_x, tr_y, val_x, val_y, shape=val_x.shape[0], \n                            mf=mf, msl=msl, mss=mss, ne=ne)\n        crps_csv_rf.append(crps_rf)\n        \n    return -np.mean(crps_csv_rf)","d0b26d03":"# pbounds = {\n#            'mf': (0.1, 1.0),\n#            'msl': (0.9, 20.1),\n#            'mss': (1.9, 15.1),\n#            'ne': (39.9, 80.1),\n#           }\n\n# optimizer_rf = BayesianOptimization(\n#     f=fit_rf,\n#     pbounds=pbounds,\n#     verbose=2,\n#     random_state=42,\n# )\n\n# optimizer_rf.maximize(init_points=5, n_iter=10)","d9525463":"# print('max_features: ', round(optimizer_rf.max['params']['mf'], 5))\n# print('min_samples_leaf: ', int(optimizer_rf.max['params']['msl']))\n# print('min_samples_split: ', int(optimizer_rf.max['params']['mss']))\n# print('Best n_estimators: ', int(optimizer_rf.max['params']['ne']))","8ba9556d":"## RF","959c23d2":"## Functions for anchoring offense moving left from {0,0}","2e58221b":"## Define Callbacks and CRPS score calculator","c5ba3d51":"# Let's split our data into train\/val","fcc03b01":"# About this kernel\n\nIn this kernel, I would like to try bayesian optimisation for hyperparameter tuning for neural network (NN) and random forest (RF). I will apply the results to my another public kernel [Blending NN and RF][1]. The feature engineering and NN parts are copied from bestpredict's kernel [Location EDA 8eb410][2] whilst the random forest (RF) regressor is proposed in Dimension's kernel [[NFL] - [001]- [Feature selection]][3]. Please correct me if you have found any mistake. Thank you very much.\n\n[1]: https:\/\/www.kaggle.com\/gogo827jz\/blending-nn-and-rf\n[2]: https:\/\/www.kaggle.com\/bestpredict\/location-eda-8eb410\n[3]: https:\/\/www.kaggle.com\/coolcoder22\/nfl-001-feature-selection","5e722a1c":"## NN","cae46994":"# Bayesian Optimisation Hyperparameter Tuning\n\nThe basic idea of Bayesian hyperparameter tuning is to estimate the posterior distribution of the objective function by a non-parametric regression model such as the Gaussian Process (GP), and then sequentially generates query points to find the optimal hyperparameter set. As more points have been generated, the estimated posterior distribution is closer to the real distribution.\n\nTo use this method, we need to build a function which takes the hyperparameters as the input and the mean cross-validation (CV) score as the output.\n\n![gp_model_with_one_more_point.png](attachment:gp_model_with_one_more_point.png)"}}