{"cell_type":{"6775853b":"code","b3032349":"code","99393e04":"code","74bcdf28":"code","987789a5":"code","62429422":"code","a33ad666":"code","16ef1d9b":"code","29449453":"code","53b78ff1":"code","be275dcd":"code","a2f203dc":"code","2d8c8dd5":"code","ab16bf3f":"code","b213d336":"code","8c1f915e":"code","e386b7de":"code","ef631beb":"code","ddf21a74":"code","1609416a":"code","fc91cb8c":"code","8c17bd8c":"code","e480b668":"code","54a3ed6c":"markdown","b94addb4":"markdown","bbefd59e":"markdown","1edd866c":"markdown","8d00ab91":"markdown"},"source":{"6775853b":"!pip install trnlp","b3032349":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport nltk\nfrom nltk.stem import SnowballStemmer\nimport re\nfrom gensim import utils\nfrom gensim.models import Doc2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom trnlp import *\nfrom sklearn.decomposition import TruncatedSVD\nimport numpy as np\nfrom nltk.corpus import stopwords\nimport warnings\nwarnings.filterwarnings(\"ignore\")","99393e04":"df_basvuru_final = pd.read_csv('..\/input\/who-gets-the-job-docs\/basvuru_final_t.csv') # Aday datasetlerin string k\u0131s\u0131mlar\u0131n\u0131n birlestirilmis hali.\nilan_final = pd.read_csv('..\/input\/who-gets-the-job-docs\/ilan_final_tnew.csv',lineterminator='\\n') # \u0130lan datasetinin string k\u0131s\u0131mlar\u0131n\u0131n birlestirilmis hali.\nbasvuru_df = pd.read_csv('\/kaggle\/input\/datathon-who-gets-the-job\/Datathon_Basvuru.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/datathon-who-gets-the-job\/test.csv')\naccepted_df = pd.read_csv('\/kaggle\/input\/datathon-who-gets-the-job\/Datathon_Basvuru_iseAlinanlar.csv')\ndf_ilan = pd.read_csv('..\/input\/datathon-who-gets-the-job\/Datathon_ilan.csv')","74bcdf28":"df_basvuru_final.drop('Unnamed: 0',1,inplace=True)\nilan_final.drop('Unnamed: 0',1,inplace=True)","987789a5":"import string\ntable = str.maketrans('', '', string.punctuation)\ndf_basvuru_final['pos_sek_city_new'] = df_basvuru_final['pos_sek_city_new'].str.translate(table)\nilan_final['pos_lok_sek_nitelik_desc'] = ilan_final['pos_lok_sek_nitelik_desc'].str.translate(table)","62429422":"basvuru_df['Aday_Count'] = basvuru_df['ilanId'].groupby(basvuru_df['AdayId']).transform('count')\nbasvuru_df['ilan_Count'] = basvuru_df['AdayId'].groupby(basvuru_df['ilanId']).transform('count')","a33ad666":"basvuru_df = basvuru_df[basvuru_df['Aday_Count']<60]","16ef1d9b":"test_ilanlar = test_df.ilanId.unique()\nbasvurular = basvuru_df.groupby('ilanId').AdayId.apply(list).reset_index()","29449453":"test_ilanlar = test_df.ilanId.unique()\nbasvurular = basvuru_df.groupby('ilanId').AdayId.apply(list).reset_index()","53b78ff1":"tum_ilanlar = ilan_final.ilanId.unique()","be275dcd":"tum_ilanlar = ilan_final.ilanId.unique()\ntrain_ilanlar = np.array(list(set(tum_ilanlar) - set(test_ilanlar)))\ntrain_ilanlar","a2f203dc":"train_accepted  = accepted_df[accepted_df.ilanId.isin(train_ilanlar)]","2d8c8dd5":"train_basvuru_df = basvuru_df[basvuru_df.ilanId.isin(train_ilanlar)]\ntrain_basvuru_df","ab16bf3f":"\nstop = stopwords.words('turkish')\nstop_eng = stopwords.words('english')\ntable = str.maketrans('', '', string.punctuation)\n\n# Kelimele gruplar\u0131n\u0131 temizle. \ndef tokenize_stem(series):\n    series = series.apply(lambda x: x.replace(\"\\n\", ' '))\n    series = series.apply(lambda x: word_token(x))\n\n    series = series.apply(lambda x: [word for word in x if word not in (stop_eng)])    \n    series = series.apply(lambda x: [w.translate(table) for w in x])\n    series = series.apply(lambda x: ' '.join(x))\n    return series\n\n\n\ndef return_topics(series, aday_series,num_topics, model, vectorizer):\n    # Topicleri olu\u015fturma Fonksiyonu. \n    \n    #\u0130lanlar serilere d\u00f6n\u00fc\u015ft\u00fcr.\n    series = tokenize_stem(series)\n    aday_series = tokenize_stem(aday_series)\n    vec = vectorizer(stop_words = stop,ngram_range = (1,2))\n\n    doc_word = vec.fit_transform(series)\n\n    # Modeli kur.\n    def_model = model(num_topics)\n    def_model = def_model.fit(doc_word)\n    doc_topic = def_model.transform(doc_word)\n    \n    \n    doc_word = vec.transform(aday_series)\n    aday_def = def_model.transform(doc_word)\n \n    return doc_topic, aday_def, def_model, vec  \n\n\n\ndef process_data():\n    \n    # Topicleri olu\u015fturur, ve datay\u0131 ona g\u00f6re d\u00fczenler.\n    jobs_df = ilan_final\n    aday_df = df_basvuru_final\n    doc, aday_doc,topic_model, vec  = return_topics(jobs_df['pos_lok_sek_nitelik_desc'],aday_df['pos_sek_city_new'],512, TruncatedSVD, TfidfVectorizer)\n\n    topic_df = pd.DataFrame(doc)\n    topic_df.columns = ['Topic ' + str(i+1) for i in range(len(topic_df.columns)) ]\n    \n    adaylar = pd.DataFrame(aday_doc)\n    adaylar.columns = ['Topic ' + str(i+1) for i in range(len(topic_df.columns)) ]\n    adaylar['Aday'] = aday_df.AdayId\n    adaylar.to_csv('aday_df.csv')\n    \n    topic_df['job'] = jobs_df.ilanId\n    topic_df.to_csv('topic_df.csv')\n    return topic_df, adaylar,topic_model, vec\n","b213d336":"jobs_df, aday_df, model, vec =  process_data()","8c1f915e":"aday_df","e386b7de":"\n #removing stopwords and applying potter stemming\nimport gc\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics.pairwise import cosine_similarity\nrecommendation = pd.DataFrame(columns = ['AdayId', 'ilanId','pred'])\ncount = 0\nfor ilan in train_ilanlar:\n    total_adaylar = np.array(list(basvurular[basvurular.ilanId == ilan].AdayId))\n    final_basvurulari = aday_df[aday_df.Aday.isin(total_adaylar.reshape(-1))]\n    final_basvurulari.Aday = final_basvurulari.Aday.astype('int')\n    aday_final  = final_basvurulari.copy()\n\n    ilan_topic = jobs_df[jobs_df['job']== ilan]\n    ilan_topic.drop('job',1,inplace=True)\n    ilan_embeds = ilan_topic.values\n    \n    aday_final.drop('Aday',1,inplace=True)\n    doc = aday_final.values\n\n    output = map(lambda x: np.corrcoef(ilan_embeds, x)[0,1],doc)\n    output_array = np.array(list(output))\n    top = sorted(range(len(output_array)), key=lambda i: output_array[i], reverse=True)[:5] \n    for i in top:\n        recommendation.at[count,'ilanId'] = ilan\n        recommendation.at[count,'AdayId'] = final_basvurulari.iloc[i]['Aday']\n        count += 1\n    gc.collect()","ef631beb":"train_accepted['target'] = 1\ntrain_results = pd.merge(recommendation,train_accepted,on=['AdayId','ilanId'],how='left')\ntrain_results.fillna(0,inplace=True)\ntrain_results['target'] = train_results['target'].astype('int')\ntrain_results = train_results.drop(460)\ncount = 6931\nfor i in range(4):\n    train_results.at[count,'ilanId'] = 2235529\n    train_results.at[count,'AdayId'] = count\n    train_results.at[count,'pred'] = 0\n    train_results.at[count,'target'] = 0\n    count += 1\n    print(count)\ntrain_results.at[count,'ilanId'] = 2335339\ntrain_results.at[count,'AdayId'] = count\ntrain_results.at[count,'pred'] = 0\ntrain_results.at[count,'target'] = 0\n\ntrain_results['Count'] = train_results['pred'].groupby(train_results['ilanId']).transform('count')\ntrain_results.sort_values(by='Count')\npreds = train_results.groupby('ilanId').pred.apply(np.array)\ntargets = train_results.groupby('ilanId').target.apply(np.array)\n\n","ddf21a74":"predictions = np.empty((1,5))\nreals = np.empty((1,5))\nfor i in range(len(preds)):\n    predictions = np.concatenate((predictions,preds.iloc[i].reshape(1,-1)))\n    reals = np.concatenate((reals,targets.iloc[i].reshape(1,-1)))\nfrom sklearn.metrics import ndcg_score\nndcg_score(reals,predictions)","1609416a":"\nimport gc\nfrom nltk.corpus import stopwords\nfrom scipy.spatial.distance import cosine \nrecommendation = pd.DataFrame(columns = ['AdayId', 'ilanId'])\ncount = 0\nids = []\ntf_pearson = []\nbert_pearson = []\nfor ilan in test_ilanlar:\n    random_list = list(basvurular[basvurular.ilanId == ilan].AdayId)\n    random_list = np.array(random_list)\n    accepted_users = accepted_df[accepted_df['ilanId'] == ilan]['AdayId']\n    total_adaylar = np.array(list(set(random_list.reshape(-1)) - set(accepted_users)))\n    final_basvurulari = aday_df[aday_df.Aday.isin(total_adaylar)]\n    final_basvurulari.Aday = final_basvurulari.Aday.astype('int')\n    aday_final  = final_basvurulari.copy()\n  \n    #pos_sek_city_new = tokenize_stem(aday_final['pos_sek_city_new'])\n    ilan_topic = jobs_df[jobs_df['job']== ilan]\n    ilan_topic.drop('job',1,inplace=True)\n    ilan_embeds = ilan_topic.values\n    \n    aday_final.drop('Aday',1,inplace=True)\n    doc = aday_final.values\n    #doc = tokenize_stem(pos_sek_city_new)\n    #doc = vec.transform(doc)\n    #doc = model.transform(doc)\n    \n    \n    output = map(lambda x: np.corrcoef(ilan_embeds, x)[0,1],doc)\n    output_cos = map(lambda x: 1 - cosine(ilan_embeds, x),doc)\n    output_array = np.array(list(output))\n    output_cos_array = np.array(list(output_cos))\n    top = sorted(range(len(output_array)), key=lambda i: output_array[i], reverse=True)[:5]\n    for i in top:\n        recommendation.at[count,'ilanId'] = ilan\n        recommendation.at[count,'AdayId'] = final_basvurulari.iloc[i]['Aday']\n        recommendation.at[count,'pearson'] = output_array[i]\n        recommendation.at[count,'cos'] = output_cos_array[i]\n        count += 1\n    gc.collect()","fc91cb8c":"recommendation","8c17bd8c":"recommender = recommendation[['ilanId','AdayId']]\nrecommender.AdayId = recommender.AdayId.astype(int) \nrecommender","e480b668":"recommender.to_csv('submission_topic_model.csv',index=False)","54a3ed6c":"# UTILS","b94addb4":"# Ba\u015fl\u0131k Modelleme\n\u0130lanlar\u0131n\u0131n kelimeler k\u00fcmesine bak\u0131larak, benzer kelimeleri bir ba\u015fl\u0131k alt\u0131nda toplan\u0131yor. Her bir aday kelimeler k\u00fcmesine bakarak bu ba\u015fl\u0131klara g\u00f6re a\u011f\u0131rl\u0131k verilerek, ilan ve ba\u015fvuran adaylar aras\u0131ndaki benzerlik hesaplanm\u0131\u015ft\u0131r.","bbefd59e":"# Preprocess Data","1edd866c":"### Test","8d00ab91":"# Train"}}