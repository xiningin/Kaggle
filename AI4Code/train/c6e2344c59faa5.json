{"cell_type":{"2e670843":"code","9e52ca72":"code","224a155a":"code","3c845020":"code","9dbade88":"code","e2b185e8":"code","aa64bbd0":"code","fd189a1c":"code","9225f10a":"code","0062db87":"code","27ad3668":"code","18fbf0cb":"code","29b9f3f5":"code","7fa64ce7":"code","fb643fff":"code","55041744":"code","082c6c1a":"code","d7ebfaa3":"code","0f4ee493":"code","f032a88e":"code","3ac2a7f1":"code","f9158588":"code","80f677eb":"code","f65025e0":"code","d293ec41":"markdown","b52b5e2a":"markdown"},"source":{"2e670843":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import date\nfrom sklearn.preprocessing import StandardScaler, normalize\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score #Evaluate the model\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9e52ca72":"#Load data\ndata = pd.read_table('\/kaggle\/input\/customer-personality-analysis\/marketing_campaign.csv')","224a155a":"data.shape","3c845020":"data.columns\nprint(data.isnull().any())","9dbade88":"#drop missing data\ndata.dropna(subset = ['Income'], inplace = True)\ndata.shape\nprint(data.isnull().any())","e2b185e8":"data.Marital_Status.unique()","aa64bbd0":"# Data Cleaning \ndata.Education.unique()\ndata['Education'] = data['Education'].replace({'Basic':'Undergraduate', '2n Cycle':'Undergraduate'})\ndata['Marital_Status'] = data['Marital_Status'].replace({'Single':'Alone', 'Married':'Together','Divorced':'Alone','Widow':'Alone','Absurd':'Alone','YOLO':'Alone'})\ndata['Children'] = data['Kidhome'] + data['Teenhome']\ndata['HasChild'] = np.where(data['Children']>0, 'HasChild', 'NoChild')\n","fd189a1c":"data.rename(columns = {'MntMeatProducts':'Meat','MntFishProducts':'Fish','MntSweetProducts':'Sweet','MntGoldProds':'Gold','MntWines':'Wines','MntFruits':'Fruits'},inplace = True)","9225f10a":"data.columns","0062db87":"data['Spendings'] = data['Wines']+data['Fruits']+data['Meat']+data['Fish']+data['Sweet']+data['Gold']\n#data['Spendings'] = data[['Wines','Fruits','Meat','Fish','Sweet','Gold']].sum(axis = 1)","27ad3668":"\ndata['Dt_Customer'] = pd.to_datetime(data['Dt_Customer'], dayfirst = True)\ndata.Dt_Customer.max()","18fbf0cb":"last_date = date(2014,12,31)\nlast_date","29b9f3f5":"data['Age'] = last_date.year-data['Year_Birth']\ndata['Age']","7fa64ce7":"data['lasted_time'] = data['Dt_Customer'].dt.date.apply(lambda x: (last_date-x)).dt.days\/30\ndata['lasted_time']","fb643fff":"features = ['Income', 'lasted_time', 'Spendings']\ndt_Kmeans = data[features]\ndt_Kmeans.head()\n","55041744":"scaler = StandardScaler()\nX_scaled = scaler.fit_transform(dt_Kmeans)\nX=X_scaled\n#X = normalize(X_scaled, norm = 'l2')","082c6c1a":"#Kmeans\nmodel = KMeans(n_clusters= 4, random_state=0, max_iter = 10000)\nmodel.fit(X)\nlabels = model.predict(X)\nlabels","d7ebfaa3":"kmeans_score = silhouette_score(X, labels)\nprint(\"This Model Score is %.3f\"%(kmeans_score))","0f4ee493":"dt_Kmeans['Cluster'] = labels","f032a88e":"data = pd.merge(data, dt_Kmeans['Cluster'], left_index = True, right_index = True)\ndata.columns","3ac2a7f1":"group_by_cluster = dt_Kmeans.groupby(['Cluster']).describe().T\ngroup_by_cluster","f9158588":"group_by_cluster_mean = dt_Kmeans.groupby(['Cluster']).mean().T\ngroup_by_cluster_mean\n#0:Low Income,Hight lated time,low spending\n#1:Medium to High Income, High lasted time,high spending\n#2:High Income, low Lasted time , high spending\n#3:Low Income, low lsated time, low spending\n# We can make 0:rank_3,1: rank_2, 2:rank_1, 3:rank_4","80f677eb":"data['Cluster'].unique()","f65025e0":"data['Cluster'] = data['Cluster'].map({0:'Rank_3',1:'Rank_2',2:'Rank_1',3:'Rank_4'})\ndata.head()","d293ec41":"score 1 is best, so ,it's not so good,but not so bad","b52b5e2a":"Since the score is 0.509 is greater than 0.47 without normalize. so drop the normalize"}}