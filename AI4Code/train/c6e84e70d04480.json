{"cell_type":{"316b624c":"code","0e44c5ea":"code","f8adeb48":"code","a6143ddb":"code","c8279d8b":"code","a2463f54":"code","b23f1747":"code","b467a68d":"code","7f1c957c":"code","292d27a6":"code","f91a0f98":"code","ffd3e61c":"code","8039e2c9":"code","674b8a28":"code","6499d404":"code","432fabd3":"code","576f3d3b":"code","e640e0e2":"code","7d20e7d6":"code","d8a114cc":"code","31ffd5f4":"code","3eabfa9e":"code","f9690eeb":"code","768eeedd":"code","adc87268":"code","51b2221e":"code","b8872d1a":"code","351eda47":"code","e89111dd":"code","8dabe26e":"code","eaf6fbf9":"code","8b67fcc7":"code","7fcad236":"code","3f500c98":"code","b6b0c813":"code","97c433a5":"code","3a1a1125":"code","4c9b6d7a":"code","6f5a7ac8":"code","2a534106":"code","fdc27452":"code","b57642dc":"code","3e0d23b0":"code","f54259c5":"code","09c66584":"code","ec7a29d5":"code","fcb1fd9e":"code","940c34db":"markdown","4fef8815":"markdown","79b4d4dd":"markdown","7722ddad":"markdown","2bae257b":"markdown","d8bb24f6":"markdown","3a4520ee":"markdown","6a712912":"markdown","782d8931":"markdown","2f9244cf":"markdown","4f2d46c1":"markdown","4d9d126b":"markdown","8bc58069":"markdown","28c83bcb":"markdown","ed11d29c":"markdown","10e7ea37":"markdown","8e1bef97":"markdown","afcf4611":"markdown","b769626e":"markdown","a44cbdfa":"markdown","5edd08ab":"markdown","d9cbdfca":"markdown","0bc8e85b":"markdown","dc02690f":"markdown","e06d5b99":"markdown","78420503":"markdown","c729c854":"markdown","74a8d2f6":"markdown","8f5a4d69":"markdown","d030e143":"markdown","eac05f2e":"markdown","833ee81f":"markdown","d2504e42":"markdown","296d7987":"markdown","432a42e6":"markdown","273e5bf3":"markdown","b2ac4e85":"markdown","10692246":"markdown","30e54afb":"markdown","9804d81a":"markdown","2d48d341":"markdown","f2980c30":"markdown","ca391355":"markdown","e37fd936":"markdown","a0c31002":"markdown","f502ff02":"markdown","a077c9e9":"markdown","50d8b0d4":"markdown","74607479":"markdown","74b0c7a8":"markdown","443b3084":"markdown","118b428f":"markdown","3741313e":"markdown","7ae0747b":"markdown","a0a2acb4":"markdown","75e9755f":"markdown","9016eaf3":"markdown","16e2771e":"markdown","3013956a":"markdown","78e74b35":"markdown","00c67077":"markdown","af67dd92":"markdown","5f6ac90f":"markdown","8543c056":"markdown","38a808a3":"markdown","f2a5cf62":"markdown","f3ab5b31":"markdown","52db6273":"markdown","f156c48f":"markdown","52ff0185":"markdown","87b743e2":"markdown","220bbb09":"markdown","b2e777b2":"markdown","78b2cbeb":"markdown","e067951d":"markdown","a95992d6":"markdown","e4c18238":"markdown","684f6f7e":"markdown","ea0dc83e":"markdown","f3c1864b":"markdown","74cc550f":"markdown","c83d40d1":"markdown"},"source":{"316b624c":"# data manipulation & plot\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# pytorch\nimport torch\nimport torch.nn as nn\n\n# disable warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","0e44c5ea":"arr = np.array([1,2,3,4,5,])\nprint(arr)\nprint(arr.dtype)\ntype(arr)","f8adeb48":"# using torch.from_numpy()\nx = torch.from_numpy(arr)\nprint(x)\nprint(x.dtype)\nprint(type(x))","a6143ddb":"# using torch.as_tensor()\nx = torch.as_tensor(arr)\nprint(x)\nprint(x.dtype)\nprint(type(x))","c8279d8b":"arr = np.array([1,2,3,4,5,])\nprint(\"Numpy array    : \",arr)\nx = torch.from_numpy(arr)\nprint(\"PyTorch tensor : \",x)\n\n# chaning the 0th index of arr\narr[0] = 999\nprint(\"Numpy array    : \",arr)\nprint(\"PyTorch tensor : \",x)","a2463f54":"# using torch.tensor()\narr = np.array([1,2,3,4,5,])\nprint(\"Numpy array    : \",arr)\nx = torch.tensor(arr)\nprint(\"PyTorch tensor : \",x)\n\n# chaning the 0th index of arr\narr[0] = 999\nprint(\"Numpy array    : \",arr)\nprint(\"PyTorch tensor : \",x)","b23f1747":"torch.empty(4,2)","b467a68d":"torch.zeros(4,3)","7f1c957c":"torch.ones(3,4)","292d27a6":"torch.arange(0,50,10)","f91a0f98":"torch.linspace(0,50,10)","ffd3e61c":"my_tensor = torch.tensor([1,2,3])\nprint(my_tensor)\nprint(my_tensor.dtype)\ntype(my_tensor)","8039e2c9":"torch.rand(4,3)","674b8a28":"torch.randn(4,3)","6499d404":"torch.randint(low=0,high=10,size=(5,5))","432fabd3":"x = torch.zeros(2,5)\nprint(\"Shape of incoming tensor\")\nprint(x.shape)\nprint(\"-\"*50)\nprint(\"Random tensor with uniform distribution\")\nprint(torch.rand_like(x))\nprint(\"-\"*50)\nprint(\"Random tensor with standard normal uniform distribution\")\nprint(torch.randn_like(x))\nprint(\"-\"*50)\nprint(\"Random tensor with integers\")\nprint(torch.randint_like(x,low=0,high=10))","576f3d3b":"print(\"The tensor\")\nprint(x)\n\narr = x.numpy()\nprint(\"-\"*50)\nprint(\"The numpy array\")\nprint(arr)\nprint(arr.dtype)\nprint(type(arr))","e640e0e2":"x = torch.arange(10)\nprint(\"Reshaped tensor\")\nprint(x.reshape(2,5))\nprint(\"-\"*50)\nprint(\"Original tensor\")\nprint(x)","7d20e7d6":"x = torch.arange(10)\nprint(\"Reshaped tensor\")\nprint(x.view(2,5))\nprint(\"-\"*50)\nprint(\"Original tensor\")\nprint(x)","d8a114cc":"x = torch.arange(10)\nprint(x.shape)\nprint(\"-\"*50)\nz = x.view(2,-1)\nprint(z)\nprint(z.shape)","31ffd5f4":"x = torch.arange(6).reshape(3,2)\nprint(x)\nprint(x[1,1])\ntype(x[1,1])","3eabfa9e":"x = torch.arange(6).reshape(3,2)\nprint(x)\nprint(\"_\"*50)\nprint(x[:,1])\nprint(x[:,1].shape)\nprint(\"_\"*50)\nprint(x[:,1:])\nprint(x[:,1:].shape)","f9690eeb":"a = torch.tensor([1.,2.,3.])\nb = torch.tensor([4.,5.,6.])\nprint(a+b)\nprint(torch.add(a,b))","768eeedd":"a = torch.tensor([1.,2.,3.])\nb = torch.tensor([4.,5.,6.])\na.add_(b)\nprint(a)","adc87268":"a = torch.tensor([1,2,3,4])\nb = torch.tensor([1,1,1,1])\nprint(a-b)\nprint(torch.sub(a,b))","51b2221e":"a = torch.ones(2,2)\nb = torch.zeros(2,2)\nprint(a*b)\nprint(torch.mul(a,b))","b8872d1a":"a = torch.ones(2,2)\nb = torch.zeros(2,2)\nprint(a\/b)\nprint(torch.div(a,b))","351eda47":"a = torch.arange(1,11,1,dtype=torch.float64)\nprint(a.mean(dim=0))","e89111dd":"a = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nprint(a.std(dim=0))","8dabe26e":"x = torch.tensor([2],dtype=torch.float64, requires_grad = True)\nx","eaf6fbf9":"y = 5 * ((x + 1)**2)\ny","8b67fcc7":"y.backward()\nx.grad","7fcad236":"x = torch.ones(2,requires_grad = True)\nx","3f500c98":"y = 5 * ((x + 1)**2)\ny","b6b0c813":"o = 0.5 * torch.sum(y)\no","97c433a5":"o.backward()\nx.grad","3a1a1125":"x = np.arange(0,11,1,dtype=np.float32) # creating an independent variable x\ny = 2 * x + 1                          # creating a dependent variable y\nprint(x.shape)\nprint(y.shape)\nprint(x)\nprint(y)","4c9b6d7a":"x=x.reshape(-1,1)\ny=y.reshape(-1,1)\nprint(x.shape, y.shape)","6f5a7ac8":"plt.scatter(x,y)\nplt.plot(x,y,color=\"Orange\",linewidth=2)\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\nplt.title(\"Y = 2X + 1\")\nplt.show()","2a534106":"class LinearRegressionModel(nn.Module):\n    \n    def __init__(self,input_dim, output_dim):\n        super(LinearRegressionModel,self).__init__()\n        self.linear = nn.Linear(input_dim, output_dim)\n        \n    def forward(self,x):\n        out = self.linear(x)\n        return out","fdc27452":"input_dim=1\noutput_dim=1\nmodel = LinearRegressionModel(input_dim,output_dim)","b57642dc":"criterion=nn.MSELoss() # loss function\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)","3e0d23b0":"epochs = 100\nfor epoch in range(epochs):\n    \n    # convert numpy arrays to tensors\n    inputs=torch.tensor(x,dtype=torch.float32, requires_grad=True)\n    labels=torch.tensor(y,dtype=torch.float32)\n    \n    # clear the gradients\n    optimizer.zero_grad()\n    \n    # forward to get output\n    outputs=model(inputs)\n    \n    # calculating loss\n    loss=criterion(outputs,labels)\n    \n    # backpropagation\n    loss.backward()\n    \n    # updating parameters\n    optimizer.step()\n    \nprint(\"Training complete...\")","f54259c5":"y","09c66584":"predicted = model(torch.tensor(x,requires_grad=True)).data.numpy()\npredicted","ec7a29d5":"# Plot true data\nplt.plot(x, y, 'go', color=\"Blue\",label='True data',)\n\n# Plot predictions\nplt.plot(x, predicted, '--',color=\"Red\", label='Predictions')\n\n# Legend and plot\nplt.legend(loc='best')\nplt.show()","fcb1fd9e":"torch.save(model.state_dict(),'linear_regression_model.pkl')","940c34db":"#### 5.1 Example using a single value <a id=17><\/a>","4fef8815":"#### 4.1 Addition <a id=10><\/a>","79b4d4dd":"##### 6.3.3 Plot predictions and true value","7722ddad":"#### 6.1 Building a simple dataset <a id=20><\/a>\n[back to top](#100)","2bae257b":"##### 3.1.1 Using `reshape()`","d8bb24f6":"$$\ndy\/dx = 10(x+1)\n$$\n\n$$\ndy\/dx = 10(2+1) = 30 \n$$","3a4520ee":"Linear Regression allows to understand the relationship between 2 continuous variables. For example `x` is an independent variable and `y` is dependent upon x, then the linear equation would be as follows with `a` as the slope of the equation and `b` as the intercept.\n$$\ny = ax+b\n$$\nIn this part of notebook, I'm creating a Linear Regression model in PyTorch.","6a712912":"$$\no = 1\/2 * \\sum_{n=x_i}^{x_n} 5(x_i+1)^2\n$$\n\n$$\ndo\/dx_i = 1\/2 * 10(x_i+1)\n$$\n\n$$\ndo\/dx_1 = 1\/2 * 10(1+1) = 10\n$$","782d8931":"##### 2.2.1 Allocate space in memory for tensor","2f9244cf":"##### 3.2.2 Selecting","4f2d46c1":"##### 5.1.1 Defining a 1-D tensor `x` with a single value","4d9d126b":"##### 5.1.2 Calculating a function `y` depending upon `x`","8bc58069":"##### 4.1.1 Element-wise addition","28c83bcb":"##### 5.2.2 Calculating a function `y` depending upon `x`","ed11d29c":"##### 2.1.1 Numpy arrays","10e7ea37":"##### 6.2.3 Instantiate optimizer and loss","8e1bef97":"##### 5.1.3 Calculating the gradient of `y` wrt `x`","afcf4611":"##### 4.1.2 In-place addition ","b769626e":"#### 2.3 Numpy array from tensor <a id=5><\/a>","a44cbdfa":"##### 5.2.3 Calculating the gradient of `o` wrt `x`","5edd08ab":"#### 3.2 Indexing <a id=8><\/a>","d9cbdfca":"### I'll be updating it regularly. If it helped you, consider giving an upvote. \u270c\ud83c\udffc\n[back to top](#100)\n\nCheck my other notebooks\n1. https:\/\/www.kaggle.com\/namanmanchanda\/asl-detection-99-accuracy\n2. https:\/\/www.kaggle.com\/namanmanchanda\/rnn-in-pytorch\n3. https:\/\/www.kaggle.com\/namanmanchanda\/heart-attack-eda-prediction-90-accuracy\n4. https:\/\/www.kaggle.com\/namanmanchanda\/stroke-eda-and-ann-prediction\n\nThe code in this notebook has been referenced from various sources available online, some of which are\n1. https:\/\/www.deeplearningwizard.com\n2. https:\/\/www.udemy.com\/course\/pytorch-for-deep-learning-with-python-bootcamp\/","0bc8e85b":"The predicted values are","dc02690f":"#### 6.2 Building the model <a id=21><\/a>\n[back to top](#100)","e06d5b99":"Similar to `numpy` functions such as `ones`, `eye` & `arange` etc, `torch` provides some handy functions to work with.","78420503":"#### 4.4 Division <a id=13><\/a>","c729c854":"##### 6.1.3 Plotting the linear curve","74a8d2f6":"##### 5.2.1 Defining a 1-D tensor `x` with more than 1 value","8f5a4d69":"### 6. Linear Regression <a id=19><\/a>\n[back to top](#100)","d030e143":"##### 6.2.2 Instantiate the model","eac05f2e":"##### 3.1.2 Using `view()`","833ee81f":"The tensor contains `inf` since any number divided by `0` is infinity.","d2504e42":"#### 4.4 Mean <a id=14><\/a>","296d7987":"#### 6.3 Save the model <a id=23><\/a>\n[back to top](#100)","432a42e6":"$$\ny = 5(x+1)^2\n$$","273e5bf3":"As in the above case, if we put `-1` as the second dimension, it will itelf infer the same provided it makes sense. Try changing the above code to get a shape of `(3,-1)` which will provide an error; since a tensor of size 10 can't be reshaped to a tensor with first dimension as 3.","b2ac4e85":"##### 6.1.2 Reshaping arrays for PyTorch model","10692246":"##### 6.3.1 The training loop","30e54afb":"$$\ny = 5(x+1)^2\n$$","9804d81a":"A gradient, also called slope is simply defined as the rate of change of the functon at a particular point. PyTorch can easily calculate gradients and accumulate them. Just a single parameter `requires_grad` is used while defining tensors to track the gradient.","2d48d341":"##### 6.3.2 Predictions","f2980c30":"#### 4.3 Multiplication <a id=12><\/a>","ca391355":"For both of the above mentioned methods, there's a little caveat to understand. `torch.from_numpy()` and `torch.as_tensor()` creates a direct link between the numpy array and the tensor. Any change in the numpy array will affect the tensor. Following is an example.","e37fd936":"#### 6.3 Training the model <a id=22><\/a>\n[back to top](#100)","a0c31002":"#### 3.1 Reshaping <a id=7><\/a>","f502ff02":"#### 2.1 Tensors from Numpy arrays <a id=3><\/a>","a077c9e9":"### 2. Matrices <a id=2><\/a>\n[back to top](#100)","50d8b0d4":"##### 2.2.5 Evenly spaced numbers over a specified interval","74607479":"### 4. Tensor arithmetic <a id=9><\/a>\n[back to top](#100)","74b0c7a8":"$$\no = 1\/2 * \\sum_{n=x_i}^{x_n} y_i\n$$","443b3084":"Table of Contents: <a id=100><\/a>\n1. [Packages](#1) \n2. [Matrices](#2)\n    - 2.1 [Tensors from numpy arrays](#3)\n    - 2.2 [Tensors from scratch](#4)\n    - 2.3 [Numpy array from tensor](#5)\n3. [Tensor operations](#6)\n    - 3.1 [Reshaping](#7)\n    - 3.2 [Indexing](#8)\n4. [Tensor arithmetic](#9)\n    - 4.1 [Addition](#10)\n    - 4.2 [Subtraction](#11)\n    - 4.3 [Multipliciation](#12)\n    - 4.4 [Division](#13)\n    - 4.5 [Mean](#14)\n    - 4.6 [Standard Deviation](#15)\n5. [Gradients](#16)\n    - 5.1 [Example using a single value](#17)\n    - 5.2 [Example using 1-D tensor](#18)\n6. [Linear Regression](#19)\n    - 6.1 [Building a simple dataset](#20)\n    - 6.2 [Building the model](#21)\n    - 6.3 [Training the model](#22)\n    - 6.4 [Save the model](#23)","118b428f":"We can observe that `y` is also a tensor with more than one value. But `backward` can only be called on a scaler or a 1-element tensor. We can create another function let's say `o` depending upon `y`.","3741313e":"##### 6.1.1 Defining values","7ae0747b":"The true values are","a0a2acb4":"##### 2.2.3 Tensor of Ones","75e9755f":"#### 5.2 Example using 1-D tensor <a id=18><\/a>","9016eaf3":"The in-place arithmetic is applicable for all operations - `add_`, `sub_`, `mul_` etc.","16e2771e":"##### 2.2.8 Random number from standard normal uniform distribution - mean 0 and standard deviation 1","3013956a":"##### 3.1.3 Shape inference","78e74b35":"##### 2.2.7 Random number from uniform distribution","00c67077":"Many loss functions can be used according to the problem statement. Linear regression mostly uses MSE or RMSE. I'll be using MSE for this case i.e Mean square error and its formula is as follows.\n$$\nMSE = 1\/n \\sum_{n=1}^{n} (y_p - y_i)^2\n$$","af67dd92":"##### 2.2.2 Tensor of Zeros","5f6ac90f":"##### 2.2.4 Evenly spaced values within a given interval","8543c056":"### 5. Gradients <a id=16><\/a>\n[back to top](#100)","38a808a3":"##### 2.2.10 Random tensor with same shape as incoming tensor","f2a5cf62":"#### 4.2 Subtraction <a id=11><\/a>","f3ab5b31":"##### 2.1.2 Numpy arrays to Tensors ","52db6273":"`a = torch.arange(1,11,1).mean(dim=0)` won't work since this would create a tensor of `int` and the `mean` can only be calculated for `float` in PyTorch.","f156c48f":"This is the plot of the equation that states `y=2x+1`.","52ff0185":"#### 4.5 Standard Deviation <a id=15><\/a>","87b743e2":"##### 3.2.1 Indexing","220bbb09":"After this step, you may check out `.\/linear_regression_model.pkl` file path, where the model would be saved.","b2e777b2":"<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/9\/96\/Pytorch_logo.png\" alt=\"PyTorch 101\" style=\"display: block;margin-left: auto;margin-right: auto; width:50%\">","78b2cbeb":"### 1. Packages <a id=1><\/a>\n[back to top](#100)","e067951d":"There are multiple ways to do arithmetic. Direct operators as well as torch functions can be used.","a95992d6":"There are multiple ways to convert **numpy array** to a **tensor**. The different ways are:\n- `torch.from_numpy()` - This converts a numpy array to a tensor.\n- `torch.as_tensor()` - This is a general way to convert an object to tensor.\n- `torch.tensor()` - This creates a copy of the object as a tensor.","e4c18238":"### 3. Tensor operations <a id=6><\/a>\n[back to top](#100)","684f6f7e":"##### 2.2.6 Python list to tensor","ea0dc83e":"##### 6.2.1 Model Class","f3c1864b":"It shows that though `torch.from_numpy()` converts the array to tensor, but it creates a reference to the same object. To create a copy of the array, `torch.tensor()` can be used.","74cc550f":"##### 2.2.9 Random integers","c83d40d1":"#### 2.2 Tensors from scratch <a id=4><\/a>"}}