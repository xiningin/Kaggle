{"cell_type":{"38f9ed32":"code","5d3adeb4":"code","89503730":"code","86dde7fb":"code","bbe2771f":"code","301cd5b1":"code","7d3c1f93":"code","da00b399":"code","8a5317e7":"code","93c71d7c":"code","c3fb56d2":"code","59bb505a":"code","2f4dd329":"code","7fe4cd63":"code","36dff0ab":"code","2aa17260":"code","a445b4f5":"code","5d75277e":"code","a8397ccb":"code","08dc32e1":"code","8e7cdcfd":"code","088ba832":"code","febe900f":"code","ccdb7391":"code","f2ce741a":"code","1f10a3d3":"code","b395f602":"code","c855327e":"code","ca8d7436":"code","4ee7a2d5":"code","15b9b844":"code","9ae28d2a":"code","ec4c1ad0":"code","9f4ce6a4":"code","8c3ec798":"code","5c61e67b":"code","2d2784d6":"code","db3dca4b":"code","dbcfec49":"code","bcc84cea":"code","c2dd8748":"code","f33e0cdf":"code","50df251b":"code","e180d1ed":"code","a8aa7c84":"code","95b698dd":"code","531a2fbb":"code","ee74a890":"code","a9580a72":"code","10c3f951":"code","b2002867":"code","a59575ac":"code","d9f80f0e":"code","e5e6188e":"code","94e71153":"code","638b8795":"code","f759adc0":"code","15687009":"code","7db18957":"code","4cabe77c":"code","f06e57ec":"code","5903898e":"code","d6fd9e47":"code","fcbc25cd":"code","4e4f6d98":"code","effc6e3b":"code","646c1813":"code","ca21ed87":"code","f389724d":"code","7b145f00":"code","f3d7045e":"code","9289d1b6":"code","dcf00a03":"code","0be953ac":"code","7625868a":"code","b01a7e54":"code","720b1944":"code","770770c3":"code","c2e178f1":"code","e9a4cbcf":"code","0930b6e3":"code","9d2379de":"code","c914d777":"code","bf2e4c5e":"code","a7fa5891":"code","4d3cd441":"code","56588e5b":"code","75f9fedc":"code","f046f26a":"code","a5aca5c8":"code","13daef37":"code","69f87b1a":"code","445c8d2d":"code","aaa810f9":"code","f188bd42":"code","55cdeb2c":"code","f2866887":"code","abc8f8b2":"code","e7c72453":"code","79ca5708":"code","10d067fb":"code","131171eb":"code","d4686b50":"code","346af164":"code","3cba8154":"code","f532077e":"code","8584e8b6":"code","80cd8ace":"code","4dcc2d63":"code","2452cf90":"code","bf8a484f":"code","6b02c26c":"code","2319e831":"code","0a3e189e":"code","8e6b2423":"code","acca0923":"code","e4341c00":"code","7cf48e22":"code","1f3b9294":"code","2e00cc2a":"code","b0e58ef6":"code","b721f62c":"code","033587c2":"code","8aa76e24":"code","68ade6c7":"code","4438b941":"code","a720d06c":"code","43d61795":"code","035334d1":"code","5c8d5c53":"code","4ded383b":"code","1e88c0f9":"code","bc54b308":"code","4b2aacdb":"code","6dcf71a6":"code","2fe43693":"code","024bcd12":"code","77bb0907":"code","a3591ba2":"code","4030aae1":"code","6f335e72":"code","ce11fcd6":"code","b861a141":"code","8d899f27":"code","406d9d4f":"code","b0147f8a":"code","7409483c":"code","978c00fa":"code","d7144fdd":"code","50e889e2":"code","8c11a99e":"code","b8aeaaf0":"code","4f3644bb":"code","d0ed30d3":"code","0dbdee90":"code","e78fbf3e":"code","af9df0f0":"code","5723721b":"code","7ad07219":"code","a0e61977":"code","6bcc787d":"code","e96b713f":"code","93a89fe8":"code","23391cde":"markdown","afc8a974":"markdown","ed5501e0":"markdown","6beb26d7":"markdown","05958e3b":"markdown","be8a075e":"markdown","83b290a8":"markdown","8babf93d":"markdown","a6495789":"markdown","fea3470b":"markdown","0567e937":"markdown","c1e51531":"markdown","c3386c2c":"markdown","42691bb6":"markdown","cd5d13bd":"markdown","2a0bb390":"markdown","33891d15":"markdown","1628f80a":"markdown","5697820c":"markdown","c660fe96":"markdown","8e19dc73":"markdown","1a325206":"markdown","6f82dcb2":"markdown","448b34fc":"markdown","1831b834":"markdown","0ce3845b":"markdown","44cd259c":"markdown","27114c97":"markdown","9667f38b":"markdown","0f4d94f6":"markdown","548d5e3f":"markdown","320e0902":"markdown","5f49d0e3":"markdown","a96e89af":"markdown","f678f9f5":"markdown","f96f49a8":"markdown","464962fc":"markdown","18c22dee":"markdown","10ec7f9e":"markdown","ec6455b9":"markdown","9b4d16ba":"markdown","a4ab7d17":"markdown","c2c9b48e":"markdown","f4e4c72d":"markdown","d84b3f2f":"markdown","300aa440":"markdown","f03a18ff":"markdown","26222bad":"markdown","10b3350f":"markdown"},"source":{"38f9ed32":"# data processing\n\nimport numpy as np\nimport pandas as pd \n\n# data visualization\n\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler,minmax_scale\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option(\"display.max_columns\", None)\n","5d3adeb4":"train= pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest= pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_d = train.copy()\ntest_d = test.copy()","89503730":"train.describe(include=\"all\")","86dde7fb":"test.describe(include=\"all\")","bbe2771f":"train.head()","301cd5b1":"test.head()","7d3c1f93":"train.dtypes","da00b399":"train.shape","8a5317e7":"test.shape","93c71d7c":"train.info()","c3fb56d2":"test.info()","59bb505a":"train.mean()","2f4dd329":"print(train.columns)","7fe4cd63":"print(test.columns)","36dff0ab":"train[\"Pclass\"].value_counts()","2aa17260":"test[\"Pclass\"].value_counts()","a445b4f5":"#draw a bar plot of survival by Pclass\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train)\n\ntotal_survived_plcass1 = train[train.Pclass == 1][\"Survived\"].sum()\ntotal_survived_plcass2 = train[train.Pclass == 2][\"Survived\"].sum()\ntotal_survived_plcass3 = train[train.Pclass == 3][\"Survived\"].sum()\n#print percentage of people by Pclass that survived\nprint(\"Total Pclass1 survived is: \" + str((total_survived_plcass1)))\nprint(\"Total Pclass2 survived is: \" + str((total_survived_plcass2)))\nprint(\"Total Pclass3 survived is: \" + str((total_survived_plcass3)))\nprint(\"Total Pclass  survived is: \" + str((total_survived_plcass1+total_survived_plcass2+total_survived_plcass3)))\nprint(\"Percentage of Pclass = 1 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Pclass = 2 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of Pclass = 3 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)","5d75277e":"train[\"Sex\"].value_counts()","a8397ccb":"test[\"Sex\"].value_counts()","08dc32e1":"sns.barplot(x=\"Sex\", y=\"Survived\",data=train)\n\n#print percentages of females vs. males that survive\n\ntotal_survived_females = train[train.Sex == \"female\"][\"Survived\"].sum()\ntotal_survived_males = train[train.Sex == \"male\"][\"Survived\"].sum()\n\n\nprint(\"Total female survived is: \" + str((total_survived_females )))\nprint(\"Total   male survived is: \" + str(( total_survived_males)))\nprint(\"Total people survived is: \" + str((total_survived_females + total_survived_males)))\nprint(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == \"female\"].value_counts(normalize = True)[1]*100)\nprint(\"Percentage  of  males who survived:\", train[\"Survived\"][train[\"Sex\"] == \"male\"].value_counts(normalize = True)[1]*100)","8e7cdcfd":"sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\")\n#help(sns.barplot)\ntrain[[\"Sex\",\"Survived\"]].groupby(\"Sex\").mean()\n","088ba832":"sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=train)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\")","febe900f":"train[\"SibSp\"].value_counts()","ccdb7391":"test[\"SibSp\"].value_counts()","f2ce741a":"#draw a bar plot for SibSp vs. survival\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train)\n\ntotal_survived_sibs0 = train[train.SibSp == 0][\"Survived\"].sum()\ntotal_survived_sibs1 = train[train.SibSp == 1][\"Survived\"].sum()\ntotal_survived_sibs2 = train[train.SibSp == 2][\"Survived\"].sum()\ntotal_survived_sibs3 = train[train.SibSp == 3][\"Survived\"].sum()\ntotal_survived_sibs4 = train[train.SibSp == 4][\"Survived\"].sum()\nprint(\"Total SibSb 0 survived is: \" + str((total_survived_sibs0 )))\nprint(\"Total SibSb 1 survived is: \" + str((total_survived_sibs1 )))\nprint(\"Total SibSb 2 survived is: \" + str((total_survived_sibs2 )))\nprint(\"Total SibSb 3 survived is: \" + str((total_survived_sibs3 )))\nprint(\"Total SibSb 4 survived is: \" + str((total_survived_sibs4 )))\nprint(\"Percentage of SibSp = 0 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of SibSp = 1 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of SibSp = 2 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of SibSp = 3 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 3].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of SibSp = 4 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 4].value_counts(normalize = True)[1]*100)","1f10a3d3":"train[\"Parch\"].value_counts()","b395f602":"test[\"Parch\"].value_counts()","c855327e":"#draw a bar plot for Parch vs. survival\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train)\nplt.show()","ca8d7436":"train[\"Embarked\"].value_counts()","4ee7a2d5":"test[\"Embarked\"].value_counts()","15b9b844":"#draw a bar plot for Embarked vs. survival\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=train)\nplt.show()","9ae28d2a":"train[\"Age\"].describe()","ec4c1ad0":"test[\"Age\"].describe()","9f4ce6a4":"sns.boxplot(x=train[\"Age\"]);","8c3ec798":"sns.boxplot(x=test[\"Age\"]);","5c61e67b":"train[\"Fare\"].describe()","2d2784d6":"test[\"Fare\"].describe()","db3dca4b":"sns.boxplot(x=train[\"Fare\"]);","dbcfec49":"sns.boxplot(x=test[\"Fare\"]);","bcc84cea":"free_ticket_train=train[train[\"Fare\"] == 0][\"PassengerId\"].count()","c2dd8748":"free_ticket_test=test[train[\"Fare\"] == 0][\"PassengerId\"].count()","f33e0cdf":"free_ticket_total=free_ticket_train+free_ticket_test","50df251b":"print(\"Free Tickets Total:\"+str(free_ticket_total))","e180d1ed":"print(\"Fare free who survived:\", train[\"Survived\"][train[\"Fare\"] == 0].value_counts(normalize = True))","a8aa7c84":"train.isnull().sum()","95b698dd":"import missingno as msno","531a2fbb":"msno.matrix(train);","ee74a890":"msno.matrix(test);","a9580a72":"train[\"Embarked\"].value_counts()","10c3f951":"#replacing the missing values in the Embarked feature with S\ntrain = train.fillna({\"Embarked\": \"S\"})\ntest = train.fillna({\"Embarked\": \"S\"})","b2002867":"def create_Title(train):\n    titles = {\n        \"Mr\" :         \"Mr\",\n        \"Mme\":         \"Mrs\",\n        \"Ms\":          \"Mrs\",\n        \"Mrs\" :        \"Mrs\",\n        \"Master\" :     \"Master\",\n        \"Mlle\":        \"Miss\",\n        \"Miss\" :       \"Miss\",\n        \"Capt\":        \"Rare\",\n        \"Col\":         \"Rare\",\n        \"Major\":       \"Rare\",\n        \"Dr\":          \"Rare\",\n        \"Rev\":         \"Rare\",\n        \"Jonkheer\":    \"Rare\",\n        \"Don\":         \"Rare\",\n        \"Sir\" :        \"Rare\",\n        \"Countess\":    \"Rare\",\n        \"Dona\":        \"Rare\",\n        \"Lady\" :       \"Rare\"\n    }\n    extracted_titles =train[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    train[\"Title\"] = extracted_titles.map(titles)","a59575ac":"create_Title(train)\n","d9f80f0e":"def create_Title(test):\n    titles = {\n        \"Mr\" :         \"Mr\",\n        \"Mme\":         \"Mrs\",\n        \"Ms\":          \"Mrs\",\n        \"Mrs\" :        \"Mrs\",\n        \"Master\" :     \"Master\",\n        \"Mlle\":        \"Miss\",\n        \"Miss\" :       \"Miss\",\n        \"Capt\":        \"Rare\",\n        \"Col\":         \"Rare\",\n        \"Major\":       \"Rare\",\n        \"Dr\":          \"Rare\",\n        \"Rev\":         \"Rare\",\n        \"Jonkheer\":    \"Rare\",\n        \"Don\":         \"Rare\",\n        \"Sir\" :        \"Rare\",\n        \"Countess\":    \"Rare\",\n        \"Dona\":        \"Rare\",\n        \"Lady\" :       \"Rare\"\n    }\n    extracted_titles =test[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    test[\"Title\"] = extracted_titles.map(titles)","e5e6188e":"create_Title(test)","94e71153":"a=list(train[\"Age\"][train[\"Age\"].isnull()].index)","638b8795":"train[\"Title\"].iloc[a] ","f759adc0":"train.head()\n","15687009":"train.groupby(\"Title\")[\"Age\"].mean()","7db18957":"train.groupby(\"Title\")[\"Age\"].median()","4cabe77c":"train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"mean\"),inplace = True )","f06e57ec":"train[\"Title\"].iloc[a] ","5903898e":"test[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"mean\"),inplace = True )","d6fd9e47":"train = train.drop([\"Cabin\"], axis = 1)\ntest = test.drop([\"Cabin\"], axis = 1)","fcbc25cd":"train.isnull().sum()","4e4f6d98":"msno.matrix(train);","effc6e3b":"test.isnull().sum()","646c1813":"train = train.drop([\"Ticket\"], axis = 1)\ntest = test.drop([\"Ticket\"], axis = 1)","ca21ed87":"test[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"mean\"),inplace = True )","f389724d":"msno.matrix(test);","7b145f00":"train_fare=train[\"Fare\"]","f3d7045e":"sns.boxplot(x=train_fare);","9289d1b6":"Q1 = train_fare.quantile(0.05)\nQ3 = train_fare.quantile(0.95)\nIQR = Q3-Q1","dcf00a03":"low_limit = Q1-1.5*IQR\nup_limit= Q3 + 1.5*IQR","0be953ac":"low_limit","7625868a":"up_limit","b01a7e54":"(train_fare > up_limit)","720b1944":"train.loc[train[\"Fare\"] > up_limit,\"Fare\"] = up_limit\ntest.loc[test[\"Fare\"] > up_limit,\"Fare\"] = up_limit","770770c3":"sns.boxplot(x=train_fare);","c2e178f1":"lbe = LabelEncoder()\nlbe.fit_transform(train[\"Sex\"])\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\nlbe.fit_transform(test[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","e9a4cbcf":"train.head()","0930b6e3":"test.head()","9d2379de":"embarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain[\"Embarked\"] = train[\"Embarked\"].map(embarked_mapping)\ntest[\"Embarked\"] = test[\"Embarked\"].map(embarked_mapping)","c914d777":"train.head()","bf2e4c5e":"test.head()","a7fa5891":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","4d3cd441":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\ntrain[\"Title\"] = train[\"Title\"].map(title_mapping)\n","56588e5b":"train.head(100)","75f9fedc":"test[\"Title\"] = test[\"Title\"].map(title_mapping)\n","f046f26a":"test.head()","a5aca5c8":"train = train.drop([\"Name\"], axis = 1)\ntest = test.drop([\"Name\"], axis = 1)","13daef37":" ## Map Fare values into groups of numerical values:\ntrain[\"FareBand\"] = pd.qcut(train[\"Fare\"], 4, labels = [1, 2, 3, 4])\ntest[\"FareBand\"] = pd.qcut(test[\"Fare\"], 4, labels = [1, 2, 3, 4])","69f87b1a":"# Drop Fare values:\ntrain = train.drop([\"Fare\"], axis = 1)\ntest = test.drop([\"Fare\"], axis = 1)","445c8d2d":"train.head()","aaa810f9":"test.head()","f188bd42":"train.head()","55cdeb2c":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1","f2866887":"test[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","abc8f8b2":"# Create new feature of family size:\n\n#train[\"Single\"] = train[\"FamilySize\"].map(lambda s: 1 if s == 1 else 0)\n#train[\"SmallFam\"] = train[\"FamilySize\"].map(lambda s: 1 if  s == 2  else 0)\n#train[\"MedFam\"] = train[\"FamilySize\"].map(lambda s: 1 if 3 <= s <= 4 else 0)\n#train[\"LargeFam\"] = train[\"FamilySize\"].map(lambda s: 1 if s >= 5 else 0)","e7c72453":"train.head()","79ca5708":"# Create new feature of family size:\n\n#test[\"Single\"] = test[\"FamilySize\"].map(lambda s: 1 if s == 1 else 0)\n#test[\"SmallFam\"] = test[\"FamilySize\"].map(lambda s: 1 if  s == 2  else 0)\n#test[\"MedFam\"] = test[\"FamilySize\"].map(lambda s: 1 if 3 <= s <= 4 else 0)\n#test[\"LargeFam\"] = test[\"FamilySize\"].map(lambda s: 1 if s >= 5 else 0)","10d067fb":"test.head()","131171eb":"train.corr()[\"Survived\"].abs().sort_values(ascending=False)\n","d4686b50":"#train = train.drop([\"FamilySize\"], axis = 1)\n#test = test.drop([\"FamilySize\"], axis = 1)","346af164":"corr = train.corr()","3cba8154":"corr","f532077e":"train = pd.get_dummies(train, columns = [\"Embarked\"], prefix=\"Em\")","8584e8b6":"train.head()","80cd8ace":"test = pd.get_dummies(test, columns = [\"Embarked\"], prefix=\"Em\")","4dcc2d63":"test.head()","2452cf90":"train.corr()[\"Survived\"].abs().sort_values(ascending=False)\n","bf8a484f":"train = pd.get_dummies(train, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Title\"])\n","6b02c26c":"train.head()","2319e831":"# Create categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")\n","0a3e189e":"train.head()","8e6b2423":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")","acca0923":"test.head()","e4341c00":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n\ny = train[\"Survived\"]\nx= train.drop(['Survived'], axis=1)\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,\n                                                    test_size = 0.20, random_state = 42)","7cf48e22":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier().fit(x_train, y_train)\ny_pred = rf_model.predict(x_test)\nacc_randomforest = round(accuracy_score(y_test, y_pred) * 100, 2)\nprint(acc_randomforest)","1f3b9294":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbm_model = GradientBoostingClassifier().fit(x_train, y_train)\n\ny_pred = gbm_model.predict(x_test)\nacc_gbm = round(accuracy_score(y_test,y_pred) * 100, 2)\nprint(acc_gbm)","2e00cc2a":"nb = GaussianNB()\nnb_model=nb.fit(x_train, y_train)\nnb_model\nnb_model.predict(x_test)\n","b0e58ef6":"y_pred = nb_model.predict(x_test)","b721f62c":"acc_gnb = round(accuracy_score(y_test, y_pred)*100,2)\nprint(acc_gnb)","033587c2":"round(cross_val_score(nb_model, x_test, y_test, cv = 10).mean()*100,2)","8aa76e24":"from sklearn.tree import DecisionTreeClassifier","68ade6c7":"cart = DecisionTreeClassifier()\ncart_model = cart.fit(x_train, y_train)\n\ncart_model","4438b941":"!pip install skompiler\nfrom skompiler import skompile\nprint(skompile(cart_model.predict).to(\"python\/code\"))","a720d06c":"y_pred = cart_model.predict(x_test)\nacc_dt=round(accuracy_score(y_test, y_pred)*100,2)","43d61795":"print(acc_dt)","035334d1":"knn= KNeighborsClassifier()\nknn_model=knn.fit(x_train, y_train)\ny_pred = knn_model.predict(x_test)\nacc_knn = round(accuracy_score(y_test, y_pred)*100,2)\nprint(acc_knn)","5c8d5c53":"loj= LogisticRegression(solver=\"liblinear\")\nloj_model=loj.fit(x_train, y_train)\n\npred_logreg = loj_model.predict(x_test)\nacc_logreg = round(accuracy_score(y_test, pred_logreg)*100,2)\n\nprint(acc_logreg)","4ded383b":"model_performance = pd.DataFrame({\n    \"Model\": [\"Random Forest\", \"Gradient Boosting\", \"Gaussian NB\", \n               \"K Nearest Neighbors\",\"Logistic Regression\",  \n              \"Decision Tree\"],\n    \"Accuracy\": [acc_randomforest, acc_gbm, acc_gnb, \n               acc_knn,acc_logreg,acc_dt]\n})\n\nmodel_performance.sort_values(by=\"Accuracy\", ascending=False)","1e88c0f9":"knn_params = {\"n_neighbors\": np.arange(1,50)}","bc54b308":"knn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, knn_params, cv=10)\nknn_cv.fit(x_train, y_train)","4b2aacdb":"print(\"Best Score:\" + str(knn_cv.best_score_))\nprint(\"Best parametrs: \" + str(knn_cv.best_params_))","6dcf71a6":"knn = KNeighborsClassifier(22)\nknn_tuned=knn.fit(x_train, y_train)","2fe43693":"round(knn_tuned.score(x_test, y_test)*100,2)","024bcd12":"y_pred=knn_tuned.predict(x_test)","77bb0907":"round(accuracy_score(y_test, y_pred)*100,2)","a3591ba2":"gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n             \"n_estimators\": [100,500,100],\n             \"max_depth\": [3,5,10],\n             \"min_samples_split\": [2,5,10]}","4030aae1":"gbm = GradientBoostingClassifier()\n\ngbm_cv = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 2)","6f335e72":"gbm_cv.fit(x_train, y_train)","ce11fcd6":"print(\"Best Paramters: \" + str(gbm_cv.best_params_))","b861a141":"gbm = GradientBoostingClassifier(learning_rate = 0.1, \n                                 max_depth = 3,\n                                min_samples_split =10 ,\n                                n_estimators = 500)","8d899f27":"gbm_tuned =  gbm.fit(x_train,y_train)","406d9d4f":"y_pred = gbm_tuned.predict(x_test)\nround(accuracy_score(y_test, y_pred)*100,2)","b0147f8a":"cart_grid = {\"max_depth\": range(1,10),\n            \"min_samples_split\" : list(range(2,50)) }","7409483c":"cart = DecisionTreeClassifier()\ncart_cv = GridSearchCV(cart, cart_grid, cv = 10, n_jobs = -1, verbose = 2)\ncart_cv_model = cart_cv.fit(x_train, y_train)","978c00fa":"print(\"Best Paramters: \" + str(cart_cv_model.best_params_))","d7144fdd":"cart = DecisionTreeClassifier(max_depth = 3, min_samples_split = 2)\ncart_tuned = cart.fit(x_train, y_train)","50e889e2":"y_pred = cart_tuned.predict(x_test)\nround(accuracy_score(y_test, y_pred)*100,2)","8c11a99e":"rf_params = {\"max_depth\": [2,5,8,10],\n            \"max_features\": [2,5,8],\n            \"n_estimators\": [10,500,1000],\n            \"min_samples_split\": [2,5,10]}","b8aeaaf0":"rf_model = RandomForestClassifier()\n\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 10, \n                           n_jobs = -1, \n                           verbose = 2) ","4f3644bb":"rf_cv_model.fit(x_train, y_train)","d0ed30d3":"print(\"Best Paramters: \" + str(rf_cv_model.best_params_))","0dbdee90":"rf_tuned = RandomForestClassifier(max_depth = 5, \n                                  max_features = 5, \n                                  min_samples_split = 2,\n                                  n_estimators = 10)\n\nrf_tuned.fit(x_train, y_train)","e78fbf3e":"y_pred = rf_tuned.predict(x_test)\nround(accuracy_score(y_test, y_pred)*100,2)","af9df0f0":"Importance = pd.DataFrame( {\"Importance\": rf_tuned.feature_importances_*100},\n                         index = x_train.columns)","5723721b":"Importance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"Variable Importance Level\")","7ad07219":"train[\"Survived\"].value_counts().plot.barh();","a0e61977":"train[\"Survived\"].value_counts()","6bcc787d":"models = [\n    knn_tuned,\n    loj_model,\n    nb_model,\n    cart_tuned,\n    rf_tuned,\n    gbm_tuned,\n   \n    \n    \n]\n\n\nfor model in models:\n    names = model.__class__.__name__\n    y_pred = model.predict(x_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"-\"*28)\n    print(names + \":\" )\n    print(\"Accuracy: {:.4%}\".format(accuracy))","e96b713f":"result = []\n\nresults = pd.DataFrame(columns= [\"Models\",\"Accuracy\"])\n\nfor model in models:\n    names = model.__class__.__name__\n    y_pred = model.predict(x_test)\n    accuracy = accuracy_score(y_test, y_pred)    \n    result = pd.DataFrame([[names, accuracy*100]], columns= [\"Models\",\"Accuracy\"])\n    results = results.append(result)\n    \n    \nsns.barplot(x= \"Accuracy\", y = \"Models\", data=results, color=\"green\")\nplt.xlabel(\"Accuracy %\")\nplt.title(\"Accuracy Rate of Models\");    ","93a89fe8":"#set ids as PassengerId and predict survival \nids = test[\"PassengerId\"]\npredictions = gbm_tuned.predict(test.drop(\"PassengerId\", axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ \"PassengerId\" : ids, \"Survived\": predictions })\noutput.to_csv(\"submission.csv\", index=False)","23391cde":"#### Age Feature","afc8a974":"## Data Analysis","ed5501e0":"##### Random Forest","6beb26d7":"##### KNN Tuning","05958e3b":"### Title Feature","be8a075e":"  With Pandas, we can load both the training and testing set that we wil later use to train and test our model. Before we begin, we should take a look at our data table to see the values that we'll be working with. We can use the head and describe function to look at some sample data and statistics. We can also look at its keys and column names.","83b290a8":"# Contents: \n## 1.Import Necessary Libraries \n##  2.Read In and Explore the Data \n##  3.Data Analysis \n##  4.Data Visualization \n   ####  -Pclass Feature\n   ####  -Sex Feature\n   ####  -SibSp Feature\n   ####  -Parch Feature\n   ####  -Embarked Feature\n   ####  -Age Feature\n   ####  -Fare Feature\n##  5.Cleaning Data \n### Missing Value\n   ####  -Embarked Feature\n   ####  -Age Feature\n   ####  -Cabin Feature\n   ####  -Ticket Feature\n   ####  -Fare Feature\n### Outliers\n##  6.Variable Transformation\n   ####  -Sex Feature\n   ####  -Embarked Feature\n   ####  -Title Feature\n   ####  -Fare Feature\n##  7.Feature Engineering\n   #### Family Size Feature\n   #### Embarked Fature\n   #### Title Feature\n   #### Pclass Feature\n##  8.Choosing the Best Model \n### Modeling,\n   #### Random Forest\n   #### Gradient Boosting\n   #### Gaussian NB\n   #### Decission Tree\n   #### KNN\n   #### Logistic Regression Model\n### Model Tuning\n   #### KNN\n   #### Gradient Boosting\n   #### Decission Tree\n   #### Random Forest\n##  9.Creating Submission File \n   ","8babf93d":"#### Sex Feature","a6495789":"#### LogisiticRegression Model\n\n","fea3470b":"### Embarked","0567e937":"#### Random Forest","c1e51531":"## Cleaning Data","c3386c2c":"#### Pclass Feature","42691bb6":"### Embarked Feature","cd5d13bd":"### Family Size","2a0bb390":"####  Gradient Boosting","33891d15":"#### Embarked Feature","1628f80a":"##### Gaussian NB","5697820c":"### Comparison of All Models","c660fe96":"### Outliers","8e19dc73":"I thought if free passengers could have ship personnel. But I think this number too low.But most of the free passengers are dead.\n","1a325206":"##### Gradient Boosting","6f82dcb2":"#### DecisionTree Model","448b34fc":"### Modelling","1831b834":"#### Age Feature","0ce3845b":"#### Cabin Feature","44cd259c":"It's clear that the majority of people embarked in Southampton (S). Let's go ahead and fill in the missing values with S.","27114c97":"### Fare Feature","9667f38b":"#### Fare Feature","0f4d94f6":"## Creating Submission File","548d5e3f":"### Sex Feature","320e0902":"## Variable Transformation\n","5f49d0e3":"##### Decision Tree","a96e89af":"## Feature Engineering","f678f9f5":"### Pclass Feature","f96f49a8":"#### KNN ","464962fc":"##  Importing Libraries","18c22dee":"## Choosing the Best Model","10ec7f9e":"#### Embarked Feature","ec6455b9":"  ### Missing Value\n\n","9b4d16ba":"## Read in and Explore the Data","a4ab7d17":"## Data Visualization \n","c2c9b48e":"### Title Feature","f4e4c72d":"### Model Tuning","d84b3f2f":"#### Fare Feature","300aa440":"#### GaussianNB Model","f03a18ff":"#### Ticket Feature","26222bad":"#### SibSp Feature","10b3350f":"#### Parch Feature"}}