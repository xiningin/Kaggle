{"cell_type":{"7860a636":"code","5b82fc59":"code","d61d9963":"code","38944f13":"code","6e16056d":"code","11508dda":"code","5ccfba7a":"code","a8a1b145":"code","b0331dd9":"code","d985fa2e":"code","791bb249":"code","3c035af8":"code","c9c22fa8":"code","d6e01d6f":"code","15e51511":"code","a7b56932":"code","931ac8d4":"code","9286d871":"code","a6b130e8":"code","84fa51c9":"code","65766de5":"code","20043861":"code","33e5f86c":"code","ec51600c":"code","93e6a04b":"code","72965c78":"code","ec7e12b1":"code","ec24faf2":"code","fca24804":"code","8e25e56b":"code","3f4f174c":"code","40e2ce7f":"code","19158384":"code","347fe092":"code","6207fa84":"code","4366a572":"markdown","f3254a49":"markdown","408eb292":"markdown","b722c9d9":"markdown","42d81fef":"markdown","565a2867":"markdown","a9af2592":"markdown","fd63e7e3":"markdown","a5d278be":"markdown","250e489e":"markdown","f6e0edc2":"markdown","05fd539b":"markdown"},"source":{"7860a636":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","5b82fc59":"import fastai\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nimport cv2\n\nimport pandas as pd\nimport matplotlib.pyplot as plt","d61d9963":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/tmp\/.cache\/torch\/checkpoints\/'):\n        os.makedirs('\/tmp\/.cache\/torch\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth'\n!cp '..\/input\/resnet152\/resnet152.pth' '\/tmp\/.cache\/torch\/checkpoints\/resnet152-b121ed2d.pth'\n#!cp '..\/input\/densenet161\/densenet161-8d451a50.pth' '\/tmp\/.cache\/torch\/checkpoints\/densenet161-8d451a50.pth'","38944f13":"import os\nos.listdir('..\/input')","6e16056d":"#print('Make sure cudnn is enabled:', torch.backends.cudnn.enabled)","11508dda":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 1667\nseed_everything(SEED)","5ccfba7a":"base_image_dir = os.path.join('..', 'input\/aptos2019-blindness-detection\/')\ntrain_dir = os.path.join(base_image_dir,'train_images\/')\ndf = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\ndf['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\ndf = df.drop(columns=['id_code'])\ndf = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ndf.head(10)","a8a1b145":"len_df = len(df)\nprint(f\"There are {len_df} images\")","b0331dd9":"df['diagnosis'].hist(figsize = (10, 5))","d985fa2e":"IMG_SIZE = 256\ndef crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n\ndef load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image\n\ndef _load_format(path, convert_mode, after_open)->Image:\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0), 10) ,-4 ,128)\n                    \n    return Image(pil2tensor(image, np.float32).div_(255)) #return fastai Image format\n\nvision.data.open_image = _load_format","791bb249":" bs=32  \nsrc = (ImageList.from_df(df=df,path='.\/',cols='path') #get dataset from dataset\n        .split_by_rand_pct(0.2, seed=42) #Splitting the dataset\n        .label_from_df(cols='diagnosis',label_cls=FloatList) #obtain labels from the level column\n      )\nsrc","3c035af8":"tfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.3, max_warp=0.0, max_lighting=0.2)\ndata = (\n    src.transform(tfms,size=128)\n    .databunch(bs=bs)\n    .normalize(imagenet_stats)\n)\ndata","c9c22fa8":"from sklearn.metrics import cohen_kappa_score\ndef quadratic_kappa(y_hat, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')","d6e01d6f":"learn = cnn_learner(data, base_arch=models.resnet50 ,metrics=[quadratic_kappa],model_dir='\/kaggle',pretrained=True,\ncallback_fns=[partial(EarlyStoppingCallback, monitor='quadratic_kappa', min_delta=0.01, patience=3)])","15e51511":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","a7b56932":"learn.fit_one_cycle(4, 1e-2)\n","931ac8d4":"learn.save('stage1')","9286d871":"learn.recorder.plot_losses()\nlearn.recorder.plot_metrics()","a6b130e8":"data = (\n    src.transform(tfms,size=224)\n    .databunch(bs=bs)\n    .normalize(imagenet_stats)\n)\ndata","84fa51c9":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","65766de5":"learn.fit_one_cycle(4, 1e-2)","20043861":"learn.recorder.plot_losses()\nlearn.recorder.plot_metrics()","33e5f86c":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","ec51600c":"learn.fit_one_cycle(10, max_lr=slice(1e-6,1e-3))  #wd=1e-3","93e6a04b":"learn.recorder.plot_losses()\nlearn.recorder.plot_metrics()","72965c78":"learn.export()\nlearn.save('stage2')\n","ec7e12b1":"learn.show_results(ds_type=DatasetType.Train, rows=4, figsize=(8,10))","ec24faf2":"valid_preds = learn.get_preds(ds_type=DatasetType.Valid)","fca24804":"import numpy as np\nimport pandas as pd\nimport os\nimport scipy as sp\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json","8e25e56b":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","3f4f174c":"optR = OptimizedRounder()\noptR.fit(valid_preds[0],valid_preds[1])","40e2ce7f":"coefficients = optR.coefficients()\nprint(coefficients)","19158384":"from fastai.core import *\nfrom fastai.basic_data import *\nfrom fastai.basic_train import *\nfrom fastai.torch_core import *\ndef _tta_only(learn:Learner, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10) -> Iterator[List[Tensor]]:\n    \"Computes the outputs for several augmented inputs for TTA\"\n    dl = learn.dl(ds_type)\n    ds = dl.dataset\n    old = ds.tfms\n    aug_tfms = [o for o in learn.data.train_ds.tfms]\n    try:\n        pbar = master_bar(range(num_pred))\n        for i in pbar:\n            ds.tfms = aug_tfms\n            yield get_preds(learn.model, dl, pbar=pbar)[0]\n    finally: ds.tfms = old\n\nLearner.tta_only = _tta_only\n\ndef _TTA(learn:Learner, beta:float=0, ds_type:DatasetType=DatasetType.Valid, num_pred:int=10, with_loss:bool=False) -> Tensors:\n    \"Applies TTA to predict on `ds_type` dataset.\"\n    preds,y = learn.get_preds(ds_type)\n    all_preds = list(learn.tta_only(ds_type=ds_type, num_pred=num_pred))\n    avg_preds = torch.stack(all_preds).mean(0)\n    if beta is None: return preds,avg_preds,y\n    else:            \n        final_preds = preds*beta + avg_preds*(1-beta)\n        if with_loss: \n            with NoneReduceOnCPU(learn.loss_func) as lf: loss = lf(final_preds, y)\n            return final_preds, y, loss\n        return final_preds, y\n\nLearner.TTA = _TTA","347fe092":"sample_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')\nsample_df.head()","6207fa84":"learn.data.add_test(ImageList.from_df(sample_df,'..\/input\/aptos2019-blindness-detection',folder='test_images',suffix='.png'))\npreds,y = learn.TTA(ds_type=DatasetType.Test)\ntest_predictions = optR.predict(preds, coefficients)\nsample_df.diagnosis = test_predictions.astype(int)\nsample_df.head()\nsample_df.to_csv('submission.csv',index=False)","4366a572":"## Fine Tune","f3254a49":"## Submission\nLet's now create a submission","408eb292":"## Optimize the Metric\n\nOptimizing the quadratic kappa metric was an important part of the top solutions in the previous competition. Thankfully, @abhishek has already provided code to do this for us. We will use this to improve the score.","b722c9d9":"## EDA","42d81fef":"Checking the distribution of labels and basic EDA..\n\nTodo: Training with old competition data","565a2867":"we will be using a variable learning rate for the various layers. Using 'slice'  takes a start value and a stop value and train the very first layers at a learning rate of 1e-6, and the very last layers at a rate of 1e-4, and distribute all the other layers across that (i.e. between those two values equally).","a9af2592":"##References\n\nhttps:\/\/course.fast.ai\n\nhttps:\/\/www.kaggle.com\/demonplus\/fast-ai-starter-with-resnet-50","fd63e7e3":"The Kaggle competition used the Cohen's quadratically weighted kappa so I have that here to compare. This is a better metric when dealing with imbalanced datasets like this one, and for measuring inter-rater agreement for categorical classification (the raters being the human-labeled dataset and the neural network predictions). Here is an implementation based on the scikit-learn's implementation, but converted to a pytorch tensor, as that is what fastai uses.","a5d278be":"## TTA\n\nTest-time augmentation, or TTA, is a commonly-used technique to provide a boost in your score, and is very simple to implement. Fastai already has TTA implemented, but it is not the best for all purposes, so I am redefining the fastai function and using my custom version.","250e489e":"## Progressive resizing","f6e0edc2":"**Training:**\n\nWe use transfer learning, where we retrain the last layers of a pretrained neural network. I use the ResNet and Densenet architectures trained on the ImageNet dataset, which has been commonly used for pre-training applications in computer vision. Fastai makes it quite simple to create a model and train.\n* Pretrained Weights have to be from publicly available datasets from Kaggle and not from internet.","05fd539b":"## Training (Transfer learning)"}}