{"cell_type":{"b83e6585":"code","c07833bc":"code","4a766c64":"code","f410c706":"code","6b90d939":"code","998da4ca":"code","31945261":"code","164cb251":"code","cd45fbb6":"code","24f9b1fa":"code","1339e457":"code","ce5967d1":"code","777df0a3":"code","26d39bd6":"code","dc15f5c9":"code","bab96bcd":"code","d0020735":"code","828078b7":"code","bfe12722":"code","d9c21766":"code","2598750a":"code","d786db3d":"code","7f84419b":"code","316c0916":"code","dc5128ce":"code","3ca84c29":"code","b97806ea":"code","13cff4a4":"code","3166a6ec":"code","9d5c7f40":"code","182cf542":"code","c5cabf7b":"code","03f21e5a":"code","439d5fb9":"code","3b98d843":"code","b1ef3f17":"code","3e7f2e7c":"code","4ac82a33":"code","6a670efe":"code","241fb9e2":"code","ea3e18b0":"code","cdd8f56d":"code","3c08eef3":"code","af485127":"code","1b6c0f61":"code","6b5c6bb7":"code","26bbcda1":"code","a5f2c1e3":"code","07821ae9":"code","08ef0cca":"code","ba14665a":"code","a1c604ea":"code","56b8ffb4":"code","2ef64fef":"code","bdeaafc3":"code","58b4a3fb":"code","9e3ab4c5":"code","9680870f":"code","8fd42532":"code","79026b53":"markdown","514068bb":"markdown","ea24c266":"markdown","0da12445":"markdown","fe735017":"markdown","16d5ca2d":"markdown","76b6fa33":"markdown","afb1ccdc":"markdown","36c6d8ec":"markdown","cb543524":"markdown","f2d8f479":"markdown","4cb401ce":"markdown","8a6c7737":"markdown","86fb977e":"markdown","5f53eab9":"markdown","cdac6b4c":"markdown","331956d5":"markdown","0b67a641":"markdown","15dbdea4":"markdown","6e3f5a82":"markdown","650bd615":"markdown","067ba5ed":"markdown"},"source":{"b83e6585":"#IMPORTING THE DEPENDENCIES\n\nimport numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n","c07833bc":"df_train = pd.read_csv(\"..\/input\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/test.csv\")","4a766c64":"df_train.shape","f410c706":"df_train.head()","6b90d939":"df_train.info()","998da4ca":"df_test.head()","31945261":"df_test.shape","164cb251":"df_test.info()","cd45fbb6":"import missingno as mn","24f9b1fa":"print(\"\\t\\tMISSING VALUES IN TRAINING DATA\")\nfor i in df_train.columns:\n    print(\"Missing Values In {} : {}\".format(i,df_train[i].isnull().sum()))","1339e457":"mn.matrix(df_train)","ce5967d1":"mn.bar(df_train)","777df0a3":"print(\"\\t\\tMISSING VALUES IN TESTING DATA\")\nfor i in df_test.columns:\n    print(\"Missing Values In {} : {}\".format(i,df_test[i].isnull().sum()))","26d39bd6":"mn.matrix(df_test)","dc15f5c9":"mn.bar(df_test)","bab96bcd":"print(\"\\tTRAINING DATA\")\nprint(\"The number of missing values in Cabin: {}\".format(df_train['Cabin'].isnull().sum()))\nprint(\"The percentage of missing values in Cabin: {} %\".format(df_train['Cabin'].isnull().sum()*100\/891))\nprint(\"\")\nprint(\"\\tTESTING DATA\")\nprint(\"The number of missing values in Cabin: {}\".format(df_test['Cabin'].isnull().sum()))\nprint(\"The percentage of missing values in Cabin: {} %\".format(df_test['Cabin'].isnull().sum()*100\/418))\n","d0020735":"#Filling the unknown cabin with 'U'\ndf_train['Cabin'].fillna(value='U',inplace=True)","828078b7":"#Using only the letter of the Cabin without the number\ndf_train['CabinType'] = df_train['Cabin'].apply(lambda i: i[:1])","bfe12722":"#Similar for testing Data\ndf_test['Cabin'].fillna(value='U',inplace=True)\n#Using only the letter of the Cabin without the number\ndf_test['CabinType'] = df_test['Cabin'].apply(lambda i: i[:1])","d9c21766":"print(\"\\tTRAINING DATA\")\nprint(\"The number of missing values in Embarked: {}\".format(df_train['Embarked'].isnull().sum()))\nprint(\"The percentage of missing values in Embarked: {} %\".format(df_train['Embarked'].isnull().sum()*100\/891))\nprint(\"\")\nprint(\"\\tTESTING DATA\")\nprint(\"The number of missing values in Embarked: {}\".format(df_test['Embarked'].isnull().sum()))\nprint(\"The percentage of missing values in Embarked: {} %\".format(df_test['Embarked'].isnull().sum()*100\/418))\n","2598750a":"embarked_common = df_train['Embarked'].value_counts().index[0]\ndf_train['Embarked'].fillna(value=embarked_common,inplace=True)","d786db3d":"print(\"\\tTRAINING DATA\\t\")\nprint(\"The number of missing values in Fare: {}\".format(df_train['Fare'].isnull().sum()))\nprint(\"The percentage of missing values in Fare: {}\".format(df_train['Fare'].isnull().sum()*100\/889))\n\nprint(\"\")\nprint(\"\\tTESTING DATA\\t\")\nprint(\"The number of missing values in Fare: {}\".format(df_test['Fare'].isnull().sum()))\nprint(\"The percentage of missing values in Fare: {}\".format(df_test['Fare'].isnull().sum()*100\/418))\n","7f84419b":"df_test['Fare'] = df_test['Fare'].fillna(df_test['Fare'].median())","316c0916":"df_train['Title'] = df_train['Name'].apply(lambda i: i.split(',')[1].split('.')[0].strip())\ndf_train.head()","dc5128ce":"standardized_titles = {\n    \"Capt\":       \"Officer\",\n    \"Col\":        \"Officer\",\n    \"Major\":      \"Officer\",\n    \"Jonkheer\":   \"Royalty\",\n    \"Don\":        \"Royalty\",\n    \"Sir\" :       \"Royalty\",\n    \"Dr\":         \"Officer\",\n    \"Rev\":        \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Dona\":       \"Royalty\",\n    \"Mme\":        \"Mrs\",\n    \"Mlle\":       \"Miss\",\n    \"Ms\":         \"Mrs\",\n    \"Mr\" :        \"Mr\",\n    \"Mrs\" :       \"Mrs\",\n    \"Miss\" :      \"Miss\",\n    \"Master\" :    \"Master\",\n    \"Lady\" :      \"Royalty\"\n}","3ca84c29":"df_train['Title'] = df_train['Title'].map(standardized_titles)","b97806ea":"df_train.head()","13cff4a4":"#Grouping Sex,Pclass and Title Together\ndf_grouped = df_train.groupby(['Sex','Pclass', 'Title'])","3166a6ec":"df_grouped['Age'].median()","9d5c7f40":"df_train['Age'] = df_grouped['Age'].apply(lambda i: i.fillna(i.median()))          ","182cf542":"#Same procedure for testing data's Age column\n\ndf_test['Title'] = df_test['Name'].apply(lambda i: i.split(',')[1].split('.')[0].strip())\ndf_test['Title'] = df_test['Title'].map(standardized_titles)\ndf_grouped_test = df_test.groupby(['Sex','Pclass', 'Title'])\ndf_test['Age'] = df_grouped_test['Age'].apply(lambda i: i.fillna(i.median()))          \ndf_test['Age'].isnull().sum()","c5cabf7b":"print(\"\\t\\tMISSING VALUES IN TRAINING DATA\")\nfor i in df_train.columns:\n    print(\"Missing Values In {} : {}\".format(i,df_train[i].isnull().sum()))\n    \nprint(\"\")\nprint(\"\\t\\tMISSING VALUES IN TESTING DATA\")\nfor i in df_test.columns:\n    print(\"Missing Values In {} : {}\".format(i,df_test[i].isnull().sum()))","03f21e5a":"#Storing the passengerId for future submissions.\npassengerId = df_test['PassengerId']","439d5fb9":"df_titanic = pd.DataFrame()\ndf_titanic = df_train.append(df_test)","3b98d843":"train_index = len(df_train)\ntest_index = len(df_titanic) - len(df_test)","b1ef3f17":"df_titanic.head()","3e7f2e7c":"print(\"\\t\\tMISSING VALUES IN COMBINED DATA\")\nfor i in df_titanic.columns:\n    print(\"Missing Values In {} : {}\".format(i,df_titanic[i].isnull().sum()))","4ac82a33":"df_titanic['FamilySize'] = df_titanic['Parch'] + df_titanic['SibSp'] + 1","6a670efe":"df_titanic['Sex'] = df_titanic['Sex'].map({\"male\": 0, \"female\":1})","241fb9e2":"PClass_dummy = pd.get_dummies(df_titanic['Pclass'], prefix=\"Pclass\")\nTitle_dummy = pd.get_dummies(df_titanic['Title'], prefix=\"Title\")\nCabinType_dummy = pd.get_dummies(df_titanic['CabinType'], prefix=\"CabinType\")\nEmbarked_dummy = pd.get_dummies(df_titanic['Embarked'], prefix=\"Embarked\")","ea3e18b0":"df_titanic_final = pd.DataFrame()\ndf_titanic_final = pd.concat([df_titanic, PClass_dummy, Title_dummy, Embarked_dummy,CabinType_dummy], axis=1)","cdd8f56d":"df_titanic_final.head()","3c08eef3":"df_train_final = df_titanic_final[ :train_index]\ndf_test_final = df_titanic_final[test_index: ]","af485127":"#If not converted to 'int', can result in 0 score after submission as it doesn't get converted to boolean.\ndf_train_final.Survived = df_train_final.Survived.astype(int)","1b6c0f61":"df_train_final.head()","6b5c6bb7":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n","26bbcda1":"df_train_final.columns","a5f2c1e3":"df_test_final.columns","07821ae9":"\nX = df_train_final.drop(['Cabin', 'CabinType', 'Embarked','Name',\n       'PassengerId', 'Pclass','Survived', 'Ticket', 'Title'], axis=1).values \nY = df_train_final['Survived'].values","08ef0cca":"df_test_final.columns","ba14665a":"X_test = df_test_final.drop(['Cabin', 'CabinType', 'Embarked','Name',\n       'PassengerId', 'Pclass','Survived', 'Ticket', 'Title'], axis=1).values","a1c604ea":"parameters_dict = dict(     \n    max_depth = [n for n in range(10, 21)],     \n    min_samples_split = [n for n in range(5, 11)], \n    min_samples_leaf = [n for n in range(2, 5)],     \n    n_estimators = [n for n in range(10, 70, 10)],\n)","56b8ffb4":"rfc = RandomForestClassifier()","2ef64fef":"forest_gridcv = GridSearchCV(estimator=rfc, param_grid=parameters_dict, cv=5) \nforest_gridcv.fit(X, Y)","bdeaafc3":"print(\"Best score: {}\".format(forest_gridcv.best_score_))\nprint(\"Optimal params: {}\".format(forest_gridcv.best_estimator_))","58b4a3fb":"rfc_predictions = forest_gridcv.predict(X_test)","9e3ab4c5":"rfc_predictions","9680870f":"kaggle_final = pd.DataFrame({'PassengerId': passengerId, 'Survived': rfc_predictions})","8fd42532":"#save to csv\nkaggle_final.to_csv('mysubmission3.csv', index=False)","79026b53":"The Cabin columns contains the maximum missing values as compared to Age and Embarked columns.","514068bb":"# Machine Learning For Titanic Dataset","ea24c266":"### 3. Feature Engineering","0da12445":"### 1. Data Cleaning ","fe735017":"* Converting Features to Categorical or Numerical for modeling.","16d5ca2d":"4. Age Column<br>","76b6fa33":"Predicting whether a passenger will survive or not.","afb1ccdc":"The missingno package allows to visualize and analyse the missing values through graphical representations.","36c6d8ec":"1. Cabin Column<br>\nThe cabin values can be treated but can add noise to our data as it is of high proportion in the data.","cb543524":"2. Embarked Column","f2d8f479":"* Separating the data back into training and testing","4cb401ce":"1. Family Size","8a6c7737":"1. Data Cleaning\n2. Feature Engineering\n3. Building Machine Learning Classifiers\/Models.","86fb977e":"* Checking for Missing Values in data","5f53eab9":"* MISSING VALUES IN TRAINING DATA","cdac6b4c":"The Cabin value will not be considered.<br>\nThe 418 values in Survived are to be predicted.","331956d5":"### 3. Building Machine Learning Models","0b67a641":"The age's missing values are of decent proportion which can be treated for both the training and testing data.<br>\n\nThe approach to impute Age column is studied from the following blog.<br>\nhttps:\/\/medium.com\/i-like-big-data-and-i-cannot-lie\/how-i-scored-in-the-top-9-of-kaggles-titanic-machine-learning-challenge-243b5f45c8e9\n","15dbdea4":"3. Fare Column <br>\n","6e3f5a82":"Columns with Missing Values<br>\n1. Cabin\n2. Embarked\n3. Fare\n4. Age\n","650bd615":"Combining the data for feature engineering","067ba5ed":"* Missing Values in Testing Data"}}