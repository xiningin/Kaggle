{"cell_type":{"d7daf758":"code","5384bc2d":"code","72277cea":"code","6a77fba0":"code","467669dd":"code","ebc71252":"code","0f388fd3":"code","cb17b5b7":"code","5b48eef2":"code","1cb30e7b":"code","bdc7ac7e":"code","d52f08d9":"code","7464f9ff":"code","36ba6f48":"code","5e9ac736":"code","20367d03":"code","38778755":"code","cf1ed284":"code","67b73fbb":"code","c65f340b":"code","8ff3d21b":"code","699fc035":"code","407902c4":"code","8d7c5e30":"code","f82f6bc2":"code","22dee962":"markdown"},"source":{"d7daf758":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\n\nimport keras\nfrom keras.layers.convolutional import Conv2DTranspose\nfrom keras.layers.merge import concatenate\nfrom keras.layers import UpSampling2D, Conv2D, Activation, Input, Dropout, MaxPooling2D\nfrom keras import Model\nfrom keras import backend as K\nfrom keras.layers.core import Lambda","5384bc2d":"tr = pd.read_csv('..\/input\/train.csv')\nprint(len(tr))\ntr.head()","72277cea":"df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\nprint(len(df_train))\ndf_train.head()","6a77fba0":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","467669dd":"img_size = 256","ebc71252":"def keras_generator(batch_size):\n    while True:\n        x_batch = []\n        y_batch = []\n        \n        for i in range(batch_size):            \n            fn = df_train['ImageId_ClassId'].iloc[i].split('_')[0]\n            img = cv2.imread( '..\/input\/train_images\/'+fn )\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)            \n            \n            mask = rle2mask(df_train['EncodedPixels'].iloc[i], img.shape)\n            \n            img = cv2.resize(img, (img_size, img_size))\n            mask = cv2.resize(mask, (img_size, img_size))\n            \n            x_batch += [img]\n            y_batch += [mask]\n                                    \n        x_batch = np.array(x_batch)\n        y_batch = np.array(y_batch)\n\n        yield x_batch, np.expand_dims(y_batch, -1)","0f388fd3":"for x, y in keras_generator(4):\n    break\n    \nprint(x.shape, y.shape)","cb17b5b7":"plt.imshow(x[3])","5b48eef2":"plt.imshow(np.squeeze(y[3]))","1cb30e7b":"#Model\n\ninputs = Input((256, 256, 3))\ns = Lambda(lambda x: x \/ 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\nc1 = Dropout(0.1) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\nc2 = Dropout(0.1) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\nc3 = Dropout(0.2) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\nc4 = Dropout(0.2) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\nc5 = Dropout(0.3) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\nc6 = Dropout(0.2) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\nc7 = Dropout(0.2) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\nc8 = Dropout(0.1) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\nc9 = Dropout(0.1) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy')","bdc7ac7e":"%%time\n# Fit model\nbatch_size = 16\nresults = model.fit_generator(keras_generator(batch_size), \n                              steps_per_epoch=100,\n                              epochs=20) ","d52f08d9":"pred = model.predict(x)\nplt.imshow(np.squeeze(pred[3]))","7464f9ff":"testfiles=os.listdir(\"..\/input\/test_images\/\")\nlen(testfiles)","36ba6f48":"%%time\ntest_img = []\nfor fn in tqdm_notebook(testfiles):\n        img = cv2.imread( '..\/input\/test_images\/'+fn )\n        img = cv2.resize(img,(img_size,img_size))       \n        test_img.append(img)","5e9ac736":"%%time\npredict = model.predict(np.asarray(test_img))\nprint(len(predict))","20367d03":"def mask2rle(img):\n    tmp = np.rot90( np.flipud( img ), k=3 )\n    rle = []\n    lastColor = 0;\n    startpos = 0\n    endpos = 0\n\n    tmp = tmp.reshape(-1,1)   \n    for i in range( len(tmp) ):\n        if (lastColor==0) and tmp[i]>0:\n            startpos = i\n            lastColor = 1\n        elif (lastColor==1)and(tmp[i]==0):\n            endpos = i-1\n            lastColor = 0\n            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n    return \" \".join(rle)","38778755":"%%time\npred_rle = []\nfor img in predict:      \n    img = cv2.resize(img, (1600, 256))\n    tmp = np.copy(img)\n    tmp[tmp<np.mean(img)] = 0\n    tmp[tmp>0] = 1\n    pred_rle.append(mask2rle(tmp))","cf1ed284":"img_t = cv2.imread( '..\/input\/test_images\/'+ testfiles[4])\nplt.imshow(img_t)","67b73fbb":"mask_t = rle2mask(pred_rle[4], img.shape)\nplt.imshow(mask_t)","c65f340b":"sub = pd.read_csv( '..\/input\/sample_submission.csv' )\nsub.head()","8ff3d21b":"%%time\nfor fn, rle in zip(testfiles, pred_rle):\n    sub['EncodedPixels'][sub['ImageId_ClassId'].apply(lambda x: x.split('_')[0]) == fn] = rle","699fc035":"sub.head(8)","407902c4":"img_s = cv2.imread( '..\/input\/test_images\/'+ sub['ImageId_ClassId'][16].split('_')[0])\nplt.imshow(img_s)","8d7c5e30":"mask_s = rle2mask(sub['EncodedPixels'][16], (256, 1600))\nplt.imshow(mask_s)","f82f6bc2":"sub.to_csv('submission.csv', index=False)","22dee962":"Simple example of U-net for segmentation in Keras"}}