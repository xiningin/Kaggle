{"cell_type":{"f008d9f5":"code","f702df9a":"code","c9e5b37b":"code","f08fd7bc":"code","2ad0081a":"code","f2ad8d8c":"code","24dae368":"code","7abc1345":"code","20ddcceb":"code","e1c3b751":"code","b1987159":"markdown","9e8fa662":"markdown","6166257b":"markdown","87b1ce6b":"markdown","4d1f5d8a":"markdown","7166fc90":"markdown","f007c991":"markdown","e85b09e2":"markdown","e7e4faa5":"markdown","4286f00a":"markdown"},"source":{"f008d9f5":"import pandas as pd\nfrom tqdm import tqdm\nfrom collections import Counter, defaultdict\nfrom gensim.models.word2vec import Word2Vec\nfrom nltk.tokenize import word_tokenize\nimport spacy\nimport numpy as np\nimport pylab as pl\nimport seaborn as sns\nimport random\nimport math\n\nsns.set()\ntqdm.pandas()\n\nen = spacy.load('en')\n\ndf = pd.read_csv('..\/input\/17k-apple-app-store-strategy-games\/appstore_games.csv')\nprint(df.columns)","f702df9a":"def is_nan(value):\n    try:\n        return math.isnan(value)\n    except TypeError:\n        return False\n\ndf['In-app Purchases'] = df['In-app Purchases'].apply(lambda r: r if is_nan(r) else [float(i) for i in r.split(', ')])\npd.to_numeric(df['Average User Rating'])\n\ndf['name_doc'] = df.Name.progress_apply(lambda r: en(r.replace('\\\\n', ' ')))\ndf['name_clean'] = df.name_doc.progress_apply(lambda r: [str(i).lower() for i in r if not (i.is_stop or i.is_punct)])\n\ndf['desc_doc'] = df.Description.progress_apply(lambda r: en(r.replace('\\\\n', ' ')))\ndf['desc_clean'] = df.desc_doc.progress_apply(lambda r: [str(i).lower() for i in r if not (i.is_stop or i.is_punct)])\n\n\nprint(df[['Name', 'name_clean']].head(10))\n\n","c9e5b37b":"df['price_in_app'] = df.apply(lambda r: 1.0 if r['Price'] and not is_nan(r['In-app Purchases']) else np.nan, axis=1)\n# somehow sometimes NaN is loaded as float-NaN and sometimes as np.NaN. math.isnan is consistent\nmapping = {\n    'Average User Rating': ('rating', None),\n    'Price': ('price', lambda x: x <= 0.0),\n    'In-app Purchases': ('in_app', None),\n    'User Rating Count': ('rate_count', None),\n    'price_in_app': ('price_in_app', None),\n}\n\n\ndef update_sdict(_d, words, value, key, cutoff_rule=None):\n    if is_nan(value):\n        return\n    if str(value).lower() == 'nan':\n        return\n    if cutoff_rule is not None and cutoff_rule(value):\n        return\n    try:\n        value = max(value)\n    except TypeError:\n        pass\n    for w in words:\n        if value is np.nan:\n            print(value)\n        _d[w][key].append(value)\n\ndef make_aggreg_df(df, mapping, word_source='name_clean'):\n    x = defaultdict(lambda: {v[0]: [] for v in mapping.values()})\n    c = Counter()\n    null = df[word_source].apply(lambda r: c.update(set(r)))\n    for k, v in c.items():\n        x[k]['nb'] = v\n    for key in mapping.keys():\n        null = df.apply(lambda r: update_sdict(x, set(r[word_source]), r[key], mapping[key][0], mapping[key][1]), axis=1)\n    for k, v in x.items():\n        v['word'] = k\n    agg_df = pd.DataFrame([r for w, r in x.items()])\n    for v in mapping.values():\n        agg_df['nb_%s' % v[0]] = agg_df[v[0]].apply(len)\n        agg_df['avg_%s' % v[0]] = agg_df[v[0]].apply(np.mean)\n        agg_df['std_%s' % v[0]] = agg_df[v[0]].apply(np.std)\n    agg_df['nb_price_only'] = agg_df.nb_price - agg_df.nb_price_in_app\n    agg_df['nb_in_app_only'] = agg_df.nb_in_app - agg_df.nb_price_in_app\n    agg_df['nb_free'] = agg_df.nb - agg_df.nb_price - agg_df.nb_in_app + agg_df.nb_price_in_app\n    agg_df['nb_pay'] = agg_df.nb_price + agg_df.nb_in_app - agg_df.nb_price_in_app\n    return agg_df\n\nagg_df = make_aggreg_df(df, mapping)\nprint(agg_df[['word', 'nb', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app']].head(10))\n","f08fd7bc":"sub = agg_df.sort_values(by='nb', ascending=False)\nsub = sub[sub.nb > 50]\nsub.set_index('word', inplace=True)\nflatui = [\"#0974f6\", \"#f6b709\", \"#f67809\", \"#f64009\"]\ncmap = sns.color_palette(flatui, 4)","2ad0081a":"f, (a0, a1) = pl.subplots(2, 1, gridspec_kw={'height_ratios': [1, 5]})\nsub[['nb_free', 'nb_in_app_only', 'nb_price_only', 'nb_price_in_app']].div(sub.nb, axis='index').head(30).plot(\n    kind='bar',\n    stacked=True,\n    color=cmap,\n    figsize=(20, 16),\n    ax=a1\n\n)\nsub['nb'].head(30).plot(\n    kind='bar',\n    ax=a0\n)\na1.set_xlabel('Most commonly found words')\na1.set_ylabel('nb of games, per category (stacked)')\na0.set_ylabel('word occurences')\na1.legend(['100% free', 'in-app purchases only', 'buy only', 'buy AND in-app purchases'])\npl.suptitle('Game monetization for the most common words found in the game title - normalized')","f2ad8d8c":"ax = sub[['nb_free', 'nb_in_app_only', 'nb_price_only', 'nb_price_in_app']].div(sub.nb, axis='index').sort_values(by='nb_free', ascending=False).head(30).plot(\n    kind='bar',\n    stacked=True,\n    color=cmap,\n    figsize=(20, 16),\n    title='Frequent title words the most associated with a TRUE free game - normalized',\n)\nax.set_xlabel('Frequent title words sorted by FREE ratio')\nax.set_ylabel('monetization type proportion')\nax.legend(['100% free', 'in-app purchases only', 'buy only', 'buy AND in-app purchases'])","24dae368":"ax = sub[['nb_free', 'nb_in_app_only', 'nb_price_only', 'nb_price_in_app', 'nb_pay']].div(sub.nb, axis='index').sort_values(by='nb_pay', ascending=False).head(50)[['nb_free', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app']].head(30).plot(\n    kind='bar',\n    stacked=True,\n    color=cmap,\n    figsize=(20, 16),\n    title='Frequent title words the most associated with a pay for game - normalized',\n)\nax.set_xlabel('Frequent title words sorted by all NON-FREE ratio')\nax.set_ylabel('monetization type proportion')\nax.legend(['100% free', 'in-app purchases only', 'buy only', 'buy AND in-app purchases'])","7abc1345":"ax = sub[['nb_free', 'nb_in_app_only', 'nb_price_only', 'nb_price_in_app']].head(30).plot(\n    kind='bar',\n    stacked=True,\n    color=cmap,\n    figsize=(20, 16),\n    title='Game monetization for the most common words found in the game title',\n)\nax.set_xlabel('Most commonly found words')\nax.set_ylabel('nb of games, per category (stacked)')\nax.legend(['100% free', 'in-app purchases only', 'buy only', 'buy AND in-app purchases'])","20ddcceb":"fig, axes = pl.subplots(nrows=3, ncols=3, figsize=(20, 16))\nsub[['nb_free', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app']].div(sub.nb, axis='index').sort_values(by='nb_free', ascending=False).head(10).plot(kind='bar', stacked=True, color=cmap, ax=axes[0,0])\nsub[['nb_free', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app']].head(10).plot(kind='bar', stacked=True, color=cmap, ax=axes[0,1])\nsub[['nb']].head(10).plot(kind='bar', stacked=True, ax=axes[0,2])\nsub[['nb_free', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app']].div(sub.nb, axis='index').sort_values(by='nb_price_only', ascending=False).head(10).plot(kind='bar', stacked=True, color=cmap, ax=axes[1,0])\nsub[['nb_free', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app']].div(sub.nb, axis='index').sort_values(by='nb_in_app_only', ascending=False).head(10).plot(kind='bar', stacked=True, color=cmap, ax=axes[1,1])\nsub[['nb_free', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app']].div(sub.nb, axis='index').sort_values(by='nb_price_in_app', ascending=False).head(10).plot(kind='bar', stacked=True, color=cmap, ax=axes[1,2])\nsub[['nb_free', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app', 'nb_pay']].div(sub.nb, axis='index').sort_values(by='nb_pay', ascending=False).head(10)[['nb_free', 'nb_pay']].plot(kind='bar', stacked=True, color=cmap, ax=axes[2,0])\nsub[['nb_free', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app', 'nb_price']].div(sub.nb, axis='index').sort_values(by='nb_price', ascending=False).head(10)[['nb_free', 'nb_price', 'nb_in_app_only']].plot(kind='bar', stacked=True, color=cmap, ax=axes[2,1])\nsub[['nb_free', 'nb_price_only', 'nb_in_app_only', 'nb_price_in_app', 'nb_in_app']].div(sub.nb, axis='index').sort_values(by='nb_in_app', ascending=False).head(10)[['nb_free', 'nb_price_only', 'nb_in_app']].plot(kind='bar', stacked=True, color=cmap, ax=axes[2,2])\n","e1c3b751":"class MarkovTextGenerator:\n    def __init__(self):\n        self.model = None\n\n    def train(self, texts):\n        model = defaultdict(Counter)\n        STATE_LEN = 2\n        for text in tqdm(texts):\n            for i in range(len(text) - STATE_LEN):\n                state = text[i:i + STATE_LEN]\n                next = text[i + STATE_LEN]\n                model[' '.join(state)][next] += 1\n        self.model = model\n\n    def run(self, max_len=25):\n        state = random.choice(list(self.model)).split()\n        out = list(state)\n        for i in range(max_len):\n            try:\n                x = random.choices(list(self.model.get(' '.join(state))), self.model.get(' '.join(state)).values())\n            except TypeError:\n                break\n            out.extend(x)\n            state = state[1:]\n            state.append(out[-1])\n        return ' '.join(out)\n\n    \nmodel = MarkovTextGenerator()\nmodel.train(df.desc_doc.progress_apply(lambda r: [str(i).lower() for i in r]))\n\nfor i in range(10):\n    print(model.run(50))\n    print()\n","b1987159":"A graph of everything at once (sorted by all possible monetization combinations)","9e8fa662":"What do we see? A few interesting things, such as:\n- Pretty much all games containing the word 'free' are free in the sense that you don't have to buy the game to play it, but an important proportion of these contain in-app purchases.\n- The word 'Pro' is a good indicator of a game that you will have to buy, even tho in additionj to that a fair amound of these also include in-app purchases\n- 'heroes' is likely a \"free\" game including in-app purchases (I don't think this will surprise anyone that is a bit familiar with the gane section on mobile app stores)\n- words indication an improvement on something or a quality (2, HD, 3D) are more frequently buy-to-play (Even tho '3' does not follow that rule)\n\nFinally the graph for words occurences in all games titles is here to show that:\n- the world 'game' is by far the most frequently found in a game title... original\n- the numbers of titles taken into account is rather high for each word, so I don't think all of this is due to chance","6166257b":"Data loading and setup\n----\nPretty classic, pandas for data processing, matplotlib+seaborn for visualisation, spacy, nltk and gensim for NLP tasks. I will be using mostly spacy even tho it is a lot slower than NLTK for my task given this setup (kaggle), but the point here is not performance but ease of use and reproductibility (I assume more people might be familiar with spacy nowadays).\nFor faster re-runs, I saved the NLP-processed data","87b1ce6b":"Data and text cleaning\n----\n1.\/ **Data correction:** After digging into the data I found thge types that were not what I expected: quick corrections. (ex: list of floats loaded as strings and not as lists)\n\n2.\/ **Text pre-processing:** game name and description: no caps, no stopwords (the, or, with etc...), no punctuation and data cleaning (bad encoding such as '\\\\n'). This is pretty basic and most of my following uses cases don't need anything more advanced. The main idea here is to reduce the vocabulary size (number of words \/ tokens) without losing too much semantic information.\n\nNOTE: *you can see the processing time using spacy on 1cpu (using tqdm\/progress_apply)... Pretty slow but you can go faster with a custom setup.*","4d1f5d8a":"2.\/ Let's generate stuff\n----\nBasic markow chain game description generator (results not garanted)\n\nWIP","7166fc90":"A few obvious notes again:\n- 'pro' and even more 'premium' are the kings of 'purchase to play' games (with still a fair part of these including in-app pruchases too)\n- once again the top in-app purchase words will probably not surprise many of you: evolution, heroes, rpg, empire, age, kingdom, clicker","f007c991":"Not sure what to take of this graph... Except 'lite' being mostly free games and 'tic' 'tac' 'toe' as three very similar monetization distributions... when one would have done the job (let's blame the tokenizer)","e85b09e2":"3.\/ Coming next (WIP):\n----\n- in depth analysis of certain words\n- a word2vec on the titles and descriptions (I tried it and to my surprise it performs rather well)\n- a study of ratings\n","e7e4faa5":"Data aggregation","4286f00a":"1.\/ Title words and app pricing relationship\n----\nThe objective here might seem weird but the idea is to look if certain words in a strategy game title cane be an indication of the pricing policy of the game (free, pay, in-app purchases, both)."}}