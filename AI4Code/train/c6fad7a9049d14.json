{"cell_type":{"5822f535":"code","250611cd":"code","bf0cd34f":"code","1a4184c3":"code","e5410df7":"code","a5e2f738":"code","85b504ac":"code","344bbf83":"code","77417c38":"code","7ec6660e":"code","2e7f946c":"code","e62e5b69":"code","1f390bd1":"code","6966958a":"code","3af9736d":"markdown","00e0838f":"markdown","5b8a391a":"markdown","82482895":"markdown"},"source":{"5822f535":"#import all libs needed for this project\n\nfrom bs4 import BeautifulSoup\nimport urllib\nimport urllib.request\nimport pandas as pd\nprint ('ok')","250611cd":"#make the request to check the connection to website is ok.\nwith urllib.request.urlopen('https:\/\/www.goodreads.com\/author\/quotes\/12008.Peter_F_Drucker') as response:\n    html = response.read()","bf0cd34f":"#creates a bs4 object to parse the html and confirms it is a bs4 object.\n\npage_soup = BeautifulSoup(html, 'html.parser')\ntype(page_soup)","1a4184c3":"print(page_soup.prettify())","e5410df7":"#Run the following code to exam the page structure.\n#We can see that the quotes, category and books are within the quote container. \n#Therefore, we will assess the structure of this `div`.\n\nquotes = page_soup.find('div', class_ = 'quote')\nprint(quotes.prettify())\n\n#as you can see, there is a lot more than we need, but, everything we need inside this container.","a5e2f738":"#now, lets verify the text of the container.\n\nprint(quotes.text)\n\n#we can see that it brings all the text, but we want to extract the quotes, category and books, in separated columns. \n#Also, you may have noticed that we can not find the book information inside this container.\n# that is because the find() only return the first occurrency of the tag during the search. \n#If you go the the website, you will see that the book reference only appears on the 5th quote. \n#but dont worry about it for now. We will get there.","85b504ac":"#now, lets star to isolate the variables we want.\n#to get the quotes, lets create a variable to do that\nquote = quotes.find('div', {'class' : 'quoteText'})\n\nprint(quote.text)","344bbf83":"#the output of this is not what we expected.\n#so, we need to extract only the text inside the first tag 'div', not the entire text (including its children)\n#we can fix it by using the content[0]\nquote = quotes.find('div', class_ = 'quoteText').contents[0]\nprint(quote.text)","77417c38":"#now we will extract the author.\n\nauthor = quotes.find('span', class_='authorOrTitle').text.replace(',','')\nprint(author)","7ec6660e":"#now we will extract the Category.\ncategory = quotes.find('div', class_='greyText smallText left')\nprint(category.text)\n# you can see that the `tags:` name is following the category. We have to get ride of it.\ncategory_clean = category.text.replace('tags:','')\nprint(category_clean)\n\n#done deal!!","2e7f946c":"#finally, we will get the book variable.\nbook = quotes.find('a', class_='authorOrTitle')\nprint(book)\n# you can see it is returning none, because it can not find any <a> tag inside the first block of the variable quotes.","e62e5b69":"#so now, we got everything we need. Lets take a look at it.\n\nprint(quote, author, category_clean, book)","1f390bd1":"#ok, so now, we have to get all the 30 quotes we have on the website.\n#to do that, we have to create a for loop, to iterate on all containers of the page.\n\nquotes_list = []       #first we create a empty list to store the values.\n\nquoteses = page_soup.find_all('div', class_ = 'quote')\nfor quotess in quoteses:\n    quotes = quotess.find('div', class_ = 'quoteText').contents[0].get_text(strip=True)\n    #this version of BS4 accepts the get_text() method to be passed on a navigablestring obj. It is possible very recent\n    #versions of BS4 only from 4.10.002. If you are using a earlier version, you should convert the quotes to a string and \n    #than pass the strip() function.\n    author = quotess.find('span', class_='authorOrTitle')\n    author_clean = author.get_text(strip=True).replace(',','')\n    category = quotess.find('div', class_='greyText smallText left')\n    #if you are following this notebook, you will remember that we got a `None` value on out [12]. I promissed that we would get\n    #back to it. And I am a man of my word. \n    # so, if you check the website from where we are extracting the data, you will notice that not all the quotes have \n    #categories or book name. This is a problem for bs4. It is a problem because when it doesnt encounter the references\n    #you a passing as parameters, it return `None` value and the methods we are using return error when applied to `None` values.\n    #to solve this, we have to stablish a condition. When bs4 finds a category, it get and clean it for us, else, it return empty.\n    if category:\n        category_clean = category.get_text(strip=True).replace('tags:','')\n    else:\n        category_clean=''\n        #print(category_clean)\n    book = quotess.find('a', class_='authorOrTitle')\n    if book:\n        #print(book.text)\n        book_clean = book.text\n        if category_clean:\n            quotes_list.append([quotes, author_clean, book_clean, category_clean])\n        else:\n            quotes_list.append([quotes, author_clean, book_clean, ''])\n    else:\n        quotes_list.append([quotes, author_clean, ' ', category_clean])\nprint(quotes_list)\n","6966958a":"#This cel criates a DF and save it to a excel file.\n\nquotes_df = pd.DataFrame(quotes_list, columns = ['Quotes', 'Author', 'Book', 'Category'])\n#quotes_df.to_excel('quotes_PeterDrucker.xlsx', index=False )\n#uncomment this last line, so you may be able to create the excel file in your system","3af9736d":"\n#### In my case, my coleague wanted to have a excel file so He could navigate on the list of quotes.\nThe following codes create as xls file from your code.\n\n---","00e0838f":"## <span style='color:green'> Introduction: the problem <\/span>\n\nThis project was created to help a friend. He needed to **get all the quotes from the same Author on a certain website**. For this first notebook, I will get all the quotes for the first page. \n\n<span style='color:green'> If you are interested in this kind of problem, take a look at this notebook, and leave your comments on how I could improve it.\n<\/span>\n\nI hope you enjoy this notebook! Many thanks!\n\nFeel welcome to get in touch!\n\n\n[My LinkedIn link ](https:\/\/www.linkedin.com\/in\/felipedutra\/)\n\n---\n","5b8a391a":"### Inspecting the html code\n\n**This is importante**\nYou should inspect the hmtl code in order to identify where the text \/ information you want is located (atributes) of the tags. \nRemember, we want from this site the following information:\n\nQuotes, category and book.\n\nTo do that, right-click on the text you want to inspect on the website. A window will pop-up. Click on inspect.\n\nA right section on your browser will open.\n\n---","82482895":"#### Voil\u00e1!! The excel file is ready! \n\n![](https:\/\/static.wixstatic.com\/media\/e9c9fb_a391f9ae55b64105ba177c6bb25dadd9~mv2.png\/v1\/fill\/w_460,h_370,al_c,q_85,usm_0.66_1.00_0.01\/Captura%20de%20Tela%202021-11-25%20%C3%A0s%2013_16_40.webp)\n\n#### So that is it folks! Hope you have enjoyed this notebook!!"}}