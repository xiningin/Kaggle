{"cell_type":{"ba63f6e6":"code","6ec8564e":"code","be9b3664":"code","e54a1658":"code","d06b1127":"code","7e36419b":"code","094e32d3":"code","6fd30cf5":"code","c7a62b65":"code","62ea08bb":"code","38cf052c":"code","03eea50d":"code","fc4e6ad8":"code","5fb371be":"code","55646d62":"code","e897aa34":"code","9b4dc496":"code","f13b7e27":"code","80fbcc77":"code","94aabf8d":"code","cf64378e":"code","327a27ab":"code","1a1a40c5":"code","48b1a2f1":"code","0d0ccbfe":"code","c68c00e3":"code","235e86dd":"code","a604e18e":"code","85df2db6":"code","b5af64bb":"code","28a4e5ce":"code","9c862386":"code","58b79362":"code","6178f786":"code","f04303b6":"code","9a482450":"code","20497e59":"code","78548819":"code","3dff6ff8":"code","2ccc0d3f":"code","f5486c15":"markdown","c3b9b0c4":"markdown","f539d1e8":"markdown","446f6d74":"markdown","3ed6b3a6":"markdown","d3b2369e":"markdown","6ae07803":"markdown","381554d4":"markdown"},"source":{"ba63f6e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6ec8564e":"#used libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler as Scaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.svm import SVC","be9b3664":"#load data\ndata_set=pd.read_csv(\"..\/input\/pima-indians-diabetes-database\/diabetes.csv\")","e54a1658":"data_set.head()","d06b1127":"data_set.info()","7e36419b":"#rows x columns\ndata_set.shape","094e32d3":"#statistics of the data\ndata_set.describe()","6fd30cf5":"#check duplicates\ndata_set.duplicated().sum()","c7a62b65":"#check null values\ndata_set.isnull().sum()","62ea08bb":"#data distribution? \ndata_set.hist(figsize = (20,20))","38cf052c":"# Calculate the median value for BMI\nmedian_BMI = data_set['BMI'].median()\nprint(median_BMI)\n# Substitute it in the BMI column of the\n# dataset where values are 0\ndata_set['BMI'] = data_set['BMI'].replace(\n    to_replace=0, value=median_BMI)\n","03eea50d":"# Calculate the median value for BloodPressure\nmedian_BD = data_set['BloodPressure'].median()\nprint(median_BD)\ndata_set['BloodPressure'] = data_set['BloodPressure'].replace(\n    to_replace=0, value=median_BD)\n","fc4e6ad8":"# Calculate the median value for Glucose\nmedian_Glucose = data_set['Glucose'].median()\nprint(median_Glucose)\ndata_set['Glucose'] = data_set['Glucose'].replace(\n    to_replace=0, value=median_Glucose)\n","5fb371be":"# Calculate the median value for SkinThickness\nmedian_STH = data_set['SkinThickness'].median()\nprint(median_STH)\ndata_set['SkinThickness'] = data_set['SkinThickness'].replace(\n    to_replace=0, value=median_STH)\n","55646d62":"# Calculate the median value for Insulin\nmedian_Insulin = data_set['Insulin'].median()\nprint(median_Insulin)\ndata_set['Insulin'] = data_set['Insulin'].replace(\n    to_replace=0, value=median_Insulin)\n","e897aa34":"#how many women with 0 Pregnancies?\n(data_set[\"Pregnancies\"]==0).sum()","9b4dc496":"data_set.describe()","f13b7e27":"data_set.hist(figsize = (20,20))","80fbcc77":"OUTCOMES=pd.Series(data_set['Outcome'].value_counts(ascending = False))\nOUTCOMES","94aabf8d":"OUTCOMES.plot.pie()","cf64378e":"corr = data_set.corr()\ncorr","327a27ab":"plt.figure(figsize=(12,10))\np=sns.heatmap(corr, annot=True)\n","1a1a40c5":"#x-->input(features) \nx=data_set.iloc[:,:-1].values\n#y-->output(has diab or not)\ny=data_set.iloc[:,-1].values","48b1a2f1":"# Split the training dataset in 2\/3 \/ 1\/3\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=1\/3,random_state=42)","0d0ccbfe":"# Apply a scaler\nscaler = Scaler()\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","c68c00e3":"KNN1=KNeighborsClassifier(n_neighbors=14)\nKNN1.fit(x_train,y_train)","235e86dd":"#predict x_test\ny_pred_KNN_1=KNN1.predict(x_test)","a604e18e":"#show result\ncn1=confusion_matrix(y_test,y_pred_KNN_1)\ncn1","85df2db6":"#training better KNN model\nKNN2=KNeighborsClassifier(leaf_size=10, n_neighbors=25, p=1,weights='uniform',algorithm='auto')\nKNN2.fit(x_train,y_train)\n#predict & show result\ny_pred_KNN_2=KNN2.predict(x_test)\ncn=confusion_matrix(y_test,y_pred_KNN_2)\ncn","b5af64bb":"#visualize result\nfrom sklearn import metrics\ncnf_matrix = metrics.confusion_matrix(y_test, y_pred_KNN_2)\np = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True,fmt='g')\nplt.title('Confusion matrix')","28a4e5ce":"#classification_report\nprint(classification_report(y_test,y_pred_KNN_2))","9c862386":"model_svc=SVC(C=10.0,kernel='rbf',gamma='auto')\nmodel_svc.fit(x_train,y_train)\ny_pred_SVC=model_svc.predict(x_test)\ncn=confusion_matrix(y_test,y_pred_SVC)\ncn","58b79362":"cnf_matrix_2 = metrics.confusion_matrix(y_test, y_pred_SVC)\np = sns.heatmap(pd.DataFrame(cnf_matrix_2), annot=True,fmt='g')\nplt.title('Confusion matrix')","6178f786":"print(classification_report(y_test,y_pred_SVC))","f04303b6":"#extrnal data\n#SVC_model\nnew_df = pd.DataFrame([[6, 168, 72, 35, 0, 43.6, 0.627, 65]])\nnew_df_scaled = scaler.transform(new_df)\nprediction_SVC_1 = model_svc.predict(new_df_scaled)\nprediction_SVC_1","9a482450":"#KNN_model\nprediction_KNN_1 = KNN2.predict(new_df_scaled)\nprediction_KNN_1","20497e59":"#random row from data\n#SVC_model\nrow_3 = pd.DataFrame([[1,89,66,23,94,28.1,0.167,21]])\nrow_3_scaled=scaler.transform(row_3)\nprediction_SVC_2 = model_svc.predict(row_3_scaled)\nprediction_SVC_2","78548819":"#KNN_model\nprediction_KNN_2 = KNN2.predict(row_3_scaled)\nprediction_KNN_2","3dff6ff8":"import pickle\nPkl_Filename = \"KNN.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(KNN2, file)\n# Load the Model back from file\nwith open(Pkl_Filename, 'rb') as file:  \n    Pickled_LR_Model = pickle.load(file)\n\nPickled_LR_Model.predict(x_test)","2ccc0d3f":"Pkl_Filename_2 = \"SVC.pkl\"  \n\nwith open(Pkl_Filename_2, 'wb') as file:  \n    pickle.dump(model_svc, file)\n# Load the Model back from file\nwith open(Pkl_Filename_2, 'rb') as file:  \n    Pickled_LR_Model_2 = pickle.load(file)\n\nPickled_LR_Model_2.predict(x_test)","f5486c15":"# data visualization","c3b9b0c4":"# train a KNN model","f539d1e8":"# train a SVC model","446f6d74":"# Data Cleaning","3ed6b3a6":"# save models","d3b2369e":"# Test models","6ae07803":"# Splitting Data & Feature Scaling","381554d4":"# Exploring Data"}}