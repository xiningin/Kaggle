{"cell_type":{"fb912c58":"code","e75dbe74":"code","0e8c7f77":"code","a5e451a6":"code","87efa69c":"code","4dca4f5e":"code","1630ffc5":"code","504a8a69":"code","17f98483":"code","28323a90":"code","440aaecc":"code","5d497efe":"code","2b2d9abd":"code","b0c2b840":"code","45e13f3e":"code","552a4cef":"code","ba0b1177":"code","f6d29aec":"code","4440f566":"code","c2a73e72":"code","a65a262e":"code","9f705c03":"code","cc237360":"code","3194d18e":"code","011df932":"code","765ddcf9":"code","31ca2ae4":"code","096dcb72":"code","8df7069f":"code","88658fa7":"code","cd406aa0":"code","499f3ca2":"code","95b1443b":"code","5161626a":"code","093edbbd":"code","26483c52":"code","327389ec":"code","87fbac90":"code","5f20cf26":"code","f59b27b7":"code","04d4323a":"code","f2106b59":"code","7b1f00b0":"code","5cdb65d5":"code","ab0672b0":"code","9d02035b":"code","8b130c3e":"code","e7f3f9bb":"code","ddc55b9d":"code","3dd83a0f":"code","f64dd382":"code","e7a98fcc":"code","217e109a":"code","0bfaeca3":"code","234f355c":"code","203331ae":"code","1084a543":"code","22832f0c":"code","2a93c899":"code","9c872aa5":"code","62ec27a9":"code","c42ac86d":"markdown","0a018c8c":"markdown","e051ee61":"markdown","fc24e580":"markdown","1bdaa63a":"markdown","8ee853ef":"markdown","5f37c42b":"markdown","a895006e":"markdown","9a862fba":"markdown","0317d014":"markdown","aef65b45":"markdown","d501e33d":"markdown","c745c462":"markdown","0069174d":"markdown","fb04743c":"markdown","67e54fbb":"markdown","1ffbcec1":"markdown","40633a73":"markdown","bf296713":"markdown","891d1ba9":"markdown","0c4e5af7":"markdown","fd9609ae":"markdown","01da3276":"markdown","80260cca":"markdown","ade3b49b":"markdown","59274246":"markdown","56af138f":"markdown","4ff594e2":"markdown","68765322":"markdown","30537fee":"markdown","ad9faa9e":"markdown"},"source":{"fb912c58":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns \nfrom collections import Counter\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e75dbe74":"!pip install spark","0e8c7f77":"!pip install pyspark","a5e451a6":"from pyspark.sql import SparkSession\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import QuantileDiscretizer","87efa69c":"spark = SparkSession \\\n    .builder \\\n    .appName(\"Spark ,ML and Basic Analysis For Titanic\") \\\n    .getOrCreate()","4dca4f5e":"Erdem_data = \"\/kaggle\/input\/titanic\/train.csv\"","1630ffc5":"titanic_df = spark.read.csv(Erdem_data,header = 'True',inferSchema='True')","504a8a69":"display(titanic_df)","17f98483":"titanic_df.printSchema()","28323a90":"passengers_count = titanic_df.count()\nprint(passengers_count)","440aaecc":"titanic_df.show(5)","5d497efe":"titanic_df.describe().show()","2b2d9abd":"titanic_df.printSchema()","b0c2b840":"titanic_df.select(\"Survived\",\"Pclass\",\"Embarked\").show()","45e13f3e":"titanic_df.groupBy(\"Survived\").count().show()","552a4cef":"groupBy_output = titanic_df.groupBy(\"Survived\").count()\ndisplay(groupBy_output)","ba0b1177":"# Sex & Survived\ntitanic_df.groupBy(\"Sex\",\"Survived\").count().show()","f6d29aec":"Fare_order=titanic_df.filter(titanic_df.SibSp > 0).groupby(\"SibSp\").sum(\"Fare\")","4440f566":"# SibSp & Fare  (Visualization)\nFifth = titanic_df.groupBy(\"SibSp\")\nFifth.agg({'Fare':'sum'}).show()\n\nVis_fifth=Fare_order.toPandas()\nVis_fifth=Vis_fifth.reset_index()\nFare=sns.factorplot(data=Vis_fifth,x=\"SibSp\",y=\"sum(Fare)\",kind=\"bar\",size=5)\nplt.show()","c2a73e72":"# Pclass & Age (Visualization)\nSixth_vis=titanic_df.toPandas()\nPclass=sns.factorplot(data=Sixth_vis,x=\"Pclass\",y=\"Age\",kind=\"bar\",size=4)\nplt.show()","a65a262e":"def null_value_count(df):\n  null_columns_counts = []\n  numRows = df.count()\n  for k in df.columns:\n    nullRows = df.where(col(k).isNull()).count()\n    if(nullRows > 0):\n      temp = k,nullRows\n      null_columns_counts.append(temp)\n  return(null_columns_counts)","9f705c03":"null_columns_count_list = null_value_count(titanic_df)","cc237360":"spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()","3194d18e":"mean_age = titanic_df.select(mean('Age')).collect()[0][0]\nprint(mean_age)","011df932":"titanic_df.select(\"Name\").show()","765ddcf9":"titanic_df = titanic_df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))","31ca2ae4":"titanic_df.show()","096dcb72":"titanic_df.select(\"Initial\").distinct().show()","8df7069f":"titanic_df = titanic_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])","88658fa7":"titanic_df.select(\"Initial\").distinct().show()","cd406aa0":"titanic_df.groupby('Initial').avg('Age').collect()","499f3ca2":"titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Miss\") & (titanic_df[\"Age\"].isNull()), 22).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Other\") & (titanic_df[\"Age\"].isNull()), 46).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Master\") & (titanic_df[\"Age\"].isNull()), 5).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mr\") & (titanic_df[\"Age\"].isNull()), 33).otherwise(titanic_df[\"Age\"]))\ntitanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mrs\") & (titanic_df[\"Age\"].isNull()), 36).otherwise(titanic_df[\"Age\"]))","95b1443b":"titanic_df.filter(titanic_df.Age==46).select(\"Initial\").show()","5161626a":"titanic_df.select(\"Age\").show()","093edbbd":"titanic_df.groupBy(\"Embarked\").count().show()","26483c52":"titanic_df = titanic_df.na.fill({\"Embarked\" : 'S'})","327389ec":"titanic_df = titanic_df.drop(\"Cabin\")\ntitanic_df.printSchema()","87fbac90":"titanic_df = titanic_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))","5f20cf26":"titanic_df.groupBy(\"Family_Size\").count().show()","f59b27b7":"titanic_df = titanic_df.withColumn('Alone',lit(0))","04d4323a":"titanic_df = titanic_df.withColumn(\"Alone\",when(titanic_df[\"Family_Size\"] == 0, 1).otherwise(titanic_df[\"Alone\"]))","f2106b59":"titanic_df.columns","7b1f00b0":"indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(titanic_df) for column in [\"Sex\",\"Embarked\",\"Initial\"]]\npipeline = Pipeline(stages=indexers)\ntitanic_df = pipeline.fit(titanic_df).transform(titanic_df)","5cdb65d5":"titanic_df.show()","ab0672b0":"titanic_df.printSchema()","9d02035b":"titanic_df = titanic_df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Sex\",\"Initial\")\ntitanic_df.show()","8b130c3e":"feature = VectorAssembler(inputCols=titanic_df.columns[1:],outputCol=\"features\")\nfeature_vector= feature.transform(titanic_df)","e7f3f9bb":"feature_vector.show()","ddc55b9d":"(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)","3dd83a0f":"from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\")\n#Training algo\nlrModel = lr.fit(trainingData)\nlr_prediction = lrModel.transform(testData)\nlr_prediction.select(\"prediction\", \"Survived\", \"features\").show()\nevaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")","f64dd382":"lr_accuracy = evaluator.evaluate(lr_prediction)\nprint(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\nprint(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))","e7a98fcc":"from pyspark.ml.classification import DecisionTreeClassifier\ndt = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\ndt_model = dt.fit(trainingData)\ndt_prediction = dt_model.transform(testData)\ndt_prediction.select(\"prediction\", \"Survived\", \"features\").show()","217e109a":"dt_accuracy = evaluator.evaluate(dt_prediction)\nprint(\"Accuracy of DecisionTreeClassifier is = %g\"% (dt_accuracy))\nprint(\"Test Error of DecisionTreeClassifier = %g \" % (1.0 - dt_accuracy))","0bfaeca3":"from pyspark.ml.classification import RandomForestClassifier\nrf = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\nrf_model = rf.fit(trainingData)\nrf_prediction = rf_model.transform(testData)\nrf_prediction.select(\"prediction\", \"Survived\", \"features\").show()","234f355c":"rf_accuracy = evaluator.evaluate(rf_prediction)\nprint(\"Accuracy of RandomForestClassifier is = %g\"% (rf_accuracy))\nprint(\"Test Error of RandomForestClassifier  = %g \" % (1.0 - rf_accuracy))","203331ae":"from pyspark.ml.classification import GBTClassifier\ngbt = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\",maxIter=10)\ngbt_model = gbt.fit(trainingData)\ngbt_prediction = gbt_model.transform(testData)\ngbt_prediction.select(\"prediction\", \"Survived\", \"features\").show()","1084a543":"gbt_accuracy = evaluator.evaluate(gbt_prediction)\nprint(\"Accuracy of Gradient-boosted tree classifie is = %g\"% (gbt_accuracy))\nprint(\"Test Error of Gradient-boosted tree classifie %g\"% (1.0 - gbt_accuracy))","22832f0c":"from pyspark.ml.classification import NaiveBayes\nnb = NaiveBayes(labelCol=\"Survived\", featuresCol=\"features\")\nnb_model = nb.fit(trainingData)\nnb_prediction = nb_model.transform(testData)\nnb_prediction.select(\"prediction\", \"Survived\", \"features\").show()","2a93c899":"nb_accuracy = evaluator.evaluate(nb_prediction)\nprint(\"Accuracy of NaiveBayes is  = %g\"% (nb_accuracy))\nprint(\"Test Error of NaiveBayes  = %g \" % (1.0 - nb_accuracy))","9c872aa5":"from pyspark.ml.classification import LinearSVC\nsvm = LinearSVC(labelCol=\"Survived\", featuresCol=\"features\")\nsvm_model = svm.fit(trainingData)\nsvm_prediction = svm_model.transform(testData)\nsvm_prediction.select(\"prediction\", \"Survived\", \"features\").show()","62ec27a9":"svm_accuracy = evaluator.evaluate(svm_prediction)\nprint(\"Accuracy of Support Vector Machine is = %g\"% (svm_accuracy))\nprint(\"Test Error of Support Vector Machine = %g \" % (1.0 - svm_accuracy))","c42ac86d":"# LogisticRegression","0a018c8c":"### Embarked feature has only two missining values. Let's check values within Embarked","e051ee61":"# Support Vector Machine","fc24e580":"## We can create a new feature called \"Family_size\" and \"Alone\" and analyse it. This feature is the summation of Parch(parents\/children) and SibSp(siblings\/spouses). It gives us a combined data so that we can check if survival rate have anything to do with family size of the passengers","1bdaa63a":"# Read File\n","8ee853ef":"# ***Machine Learning***","5f37c42b":"# **Checking Null Values**","a895006e":"# ------------------------------------------------------------------","9a862fba":"### Using the Regex \"\"[A-Za-z]+).\" we extract the initials from the Name. It looks for strings which lie between A-Z or a-z and followed by a .(dot).","0317d014":"#  **Basic Analysis & Visualization**","aef65b45":"## Lets convert Sex, Embarked & Initial columns from string to number using StringIndexer","d501e33d":"### There are some misspelled Initials like Mlle or Mme that stand for Miss. I will replace them with Miss and same thing for other values.","c745c462":"## Here is the list of few Classification Algorithms from Spark ML\n\n### -LogisticRegression\n### -DecisionTreeClassifier\n### -RandomForestClassifier\n### -Gradient-boosted tree classifier\n### -NaiveBayes\n### -Support Vector Machine","0069174d":"## Drop columns which are not required","fb04743c":"### Let's impute missing values in age feature based on average age of Initials","67e54fbb":"# Installation for Spark","1ffbcec1":"### Count of Passengers","40633a73":"# RandomForestClassifier","bf296713":"### Now that the data is all set, let's split it into training and test. I'll be using 80% of it.","891d1ba9":"### Let's put all features into vector","0c4e5af7":"### Check the imputation","fd9609ae":"# Modelling","01da3276":"# Gradient-boosted tree classifier","80260cca":"### Age feature has 177 null values.","ade3b49b":"### Lets check the average age by Initials","59274246":"# DecisionTreeClassifier","56af138f":"### We can drop Cabin features as it has lots of null values","4ff594e2":"### We can check the Name feature. Looking upon the feature, we can see that the names have a salutation like Mr or Mrs. Thus we can assign the mean values of Mr and Mrs to the respective groups****","68765322":"### To replace these NaN values, we can assign them the mean age of the dataset.But the problem is, there were many people with many different ages. We just cant assign a 4 year kid with the mean age that is 29 years.","30537fee":"# NaiveBayes","ad9faa9e":"### Majority Passengers boarded from \"S\". We can impute with \"S\""}}