{"cell_type":{"15cfd1ee":"code","654832cf":"code","bf7d7d40":"code","6572fde2":"code","6275c252":"code","1e677218":"code","8cb0c58c":"code","e8269ea7":"code","73ff1754":"code","a641f5b8":"code","a7c603aa":"code","f60d77fd":"code","b4169a21":"code","7b71dfc7":"code","ff3b350c":"code","fa157dfa":"code","4f40c4ac":"code","c592da26":"code","36078087":"code","39eb1442":"code","4150eab7":"code","65a12cf9":"code","04314880":"code","87502d58":"code","11bbbd67":"code","9b41ac03":"code","bbe32c2b":"code","aac7838e":"code","20dedc1a":"code","8ca7fb7d":"code","3735a8de":"code","4a8f802b":"code","eb836e1e":"code","e14ba12e":"code","9435fb15":"code","cab8f7c2":"code","e8e37b2e":"code","1f048e55":"code","d4c34de7":"code","3170218b":"code","c27baf29":"code","4e65bda1":"code","36aa7466":"code","9a6d3776":"code","0f04e165":"code","4a5ac7b4":"code","780ca6aa":"code","f1f0cbea":"code","bd5f2127":"code","e3bf75e9":"markdown","3c32c74a":"markdown"},"source":{"15cfd1ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","654832cf":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold\n\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')\n\nSEED = 42","bf7d7d40":"def concat_df(train_data, test_data):\n    # Returns a concatenated df of training and test set on axis 0\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n\ndef divide_df(all_data):\n    # Returns divided dfs of training and test set\n    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\n\ndf_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ndf_all = concat_df(df_train, df_test)\n\ndf_train.name = 'Training Set'\ndf_test.name = 'Test Set'\ndf_all.name = 'All Set' \n\ndfs = [df_train, df_test]\n\nprint('Number of Training Examples = {}'.format(df_train.shape[0]))\nprint('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\nprint('Training X Shape = {}'.format(df_train.shape))\nprint('Training y Shape = {}\\n'.format(df_train['Survived'].shape[0]))\nprint('Test X Shape = {}'.format(df_test.shape))\nprint('Test y Shape = {}\\n'.format(df_test.shape[0]))\nprint(df_train.columns)\nprint(df_test.columns)","6572fde2":"df_all\n","6275c252":"def display_missing(df):    \n    for col in df.columns.tolist():          \n        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n    print('\\n')\n    \nfor df in dfs:\n    print('{}'.format(df.name))\n    display_missing(df)","1e677218":"df_all_corr = df_all.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=True).reset_index()\ndf_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\ndf_all_corr[df_all_corr['Feature 1'] == 'Age']","8cb0c58c":"age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\nage_by_pclass_sex","e8269ea7":"# Filling the missing values in Age with the medians of Sex and Pclass groups\ndf_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))","73ff1754":"df_all[df_all['Embarked'].isnull()]\n","a641f5b8":"# Filling the missing values in Embarked with S\ndf_all['Embarked'] = df_all['Embarked'].fillna('S')","a7c603aa":"df_all[df_all['Fare'].isnull()]","f60d77fd":"df_all['Fare'] = df_all['Fare'].fillna(df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0])","b4169a21":"df_train.groupby(['Parch','Pclass']).Survived.mean()*100","7b71dfc7":"# Creating Deck column from the first letter of the Cabin column (M stands for Missing)\ndf_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\ndf_all=df_all.drop(['Cabin'],axis=1)\n","ff3b350c":"df_all","fa157dfa":"df_all['Deck'] = df_all['Deck'].replace(['A', 'B', 'C'], 'ABC')\ndf_all['Deck'] = df_all['Deck'].replace(['D', 'E'], 'DE')\ndf_all['Deck'] = df_all['Deck'].replace(['F', 'G'], 'FG')","4f40c4ac":"df_all","c592da26":"df_train, df_test = divide_df(df_all)","36078087":"# Seaborn visualization library\nimport seaborn as sns\n# Create the default pairplot\nsns.pairplot(df_train,hue='Survived')","39eb1442":"plt.figure(figsize=(10,10))\nsns.heatmap(df_train.corr(),\n            vmin=-1,\n            annot=True);\n\nplt.title('Correlation matrix')\nplt.show()\n","4150eab7":"#test set\nplt.figure(figsize=(10,10))\nsns.heatmap(df_test.corr(),\n            vmin=-1,\n            annot=True);\n\nplt.title('Correlation matrix')\nplt.show()","65a12cf9":"#split fares in quartiles\ndf_all['Fare'] = pd.qcut(df_all['Fare'], 13)\n","04314880":"df_all","87502d58":"fig, axs = plt.subplots(figsize=(25, 10))\nsns.countplot(x='Fare', hue='Survived', data=df_all)\nplt.legend(['Not Survived', 'Survived'])\nplt.show()","11bbbd67":"df_all['Age'] = pd.qcut(df_all['Age'], 7)","9b41ac03":"fig, axs = plt.subplots(figsize=(25, 10))\nsns.countplot(x='Age', hue='Survived', data=df_all)\nplt.legend(['Not Survived', 'Survived'])\nplt.show()","bbe32c2b":"df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\ndf_all","aac7838e":"family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\ndf_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\ndf_all.drop(['Family_Size'],inplace=True,axis=1)\n","20dedc1a":"df_all","8ca7fb7d":"fig, axs = plt.subplots(figsize=(15, 7))\nsns.barplot(x=df_all['Family_Size_Grouped'].value_counts().index, y=df_all['Family_Size_Grouped'].value_counts().values)\nplt.show()","3735a8de":"df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')\ndf_all","4a8f802b":"fig, axs = plt.subplots(figsize=(12, 9))\nsns.countplot(x='Ticket_Frequency', hue='Survived', data=df_all)\nplt.show()","eb836e1e":"df_all['Title']=df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]","e14ba12e":"df_all.Title.unique()","9435fb15":"df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss\/Mrs\/Ms')\ndf_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr\/Military\/Noble\/Clergy')\ndf_all.Title.unique()","cab8f7c2":"fig, axs = plt.subplots(figsize=(12, 9))\nsns.countplot(x='Title', hue='Survived', data=df_all)\nplt.show()","e8e37b2e":"df_all","1f048e55":"df_train = df_all.loc[:890]\ndf_test = df_all.loc[891:]\ndfs = [df_train, df_test]","d4c34de7":"non_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n\nfor df in dfs:\n    for feature in non_numeric_features:        \n        df[feature] = LabelEncoder().fit_transform(df[feature])\n  \n\n        ","3170218b":"df_test.drop(['Name','PassengerId','Ticket','Survived'], axis=1,inplace=True)  \ndf_train.drop(['Name','PassengerId','Ticket'], axis=1,inplace=True)  ","c27baf29":"df_test","4e65bda1":"X_train=df_train.drop(['Survived'],axis=1)\ny_train=df_train['Survived'].values\n\nX_test=df_test\n\nprint('X_train shape: {}'.format(X_train.shape))\nprint('y_train shape: {}'.format(y_train.shape))\nprint('X_test shape: {}'.format(X_test.shape))","36aa7466":"X_train_scaled = StandardScaler().fit_transform(X_train)\nX_test_scaled = StandardScaler().fit_transform(X_test)","9a6d3776":"single_best_model = RandomForestClassifier(criterion='gini', \n                                           n_estimators=1100,\n                                           max_depth=5,\n                                           min_samples_split=4,\n                                           min_samples_leaf=5,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           random_state=SEED,\n                                           n_jobs=-1,\n                                           verbose=1)\n\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n                 'n_estimators': [1200, 1000, 1100,1300,1400,1250,1150],\n                 'max_depth': [2,3, 5,6, 7,8, 9]\n             }\ngrid_clf = GridSearchCV(single_best_model, param_grid, cv=10)\ngrid_clf.fit(X_train, y_train)","0f04e165":"grid_clf.best_score_ ","4a5ac7b4":"grid_clf.best_params_","780ca6aa":"rfc_prediction = grid_clf.predict(X_test)\nY_pred=rfc_prediction.astype(int)","f1f0cbea":"Y_pred","bd5f2127":"submission = pd.DataFrame({\n        \"PassengerId\": df_all.loc[891:]['PassengerId'],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission_gxboost_search_ird_cv5.csv', index=False)","e3bf75e9":"### Correlations in train set","3c32c74a":"# ML"}}