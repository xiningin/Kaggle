{"cell_type":{"d5a58e6f":"code","36bf66cc":"code","009303a8":"code","ea59ea05":"code","943b9fb4":"code","eae206bd":"code","2b938306":"code","cf84312c":"code","bb7e0b82":"code","ba0781d2":"code","c7d285f2":"code","3dc6c6b4":"code","0d306a6e":"code","5504df3b":"code","2424e5a6":"code","c2a571c9":"code","ad62efac":"code","35e780ea":"code","a27253f3":"code","5c342508":"code","8f238544":"code","a614200f":"code","c6440955":"code","6529c1bb":"code","5a72384b":"code","fabac53f":"code","1440e91b":"code","ab625ce1":"code","9e7b5863":"code","da4d4bd9":"code","7f49c87c":"code","cc2363b9":"code","d301036c":"code","786860a0":"code","97aa8fc9":"code","a0c22982":"code","f2da8599":"code","4a98c301":"code","efd2d96f":"code","c9c4e9a1":"code","e95b61c3":"code","4ed2631e":"code","9f8435cb":"code","d70353d4":"code","265e4a5e":"code","22f35155":"code","09079e68":"code","1dd9a810":"code","76f9f2a3":"code","ce9f82ab":"code","dbcc98d2":"code","27e5c4ba":"code","553319a1":"code","126dc923":"code","32fcc90f":"code","895be01c":"code","2afb0fbd":"code","3e2a7f74":"code","8d277f4f":"code","0ea28149":"code","63475d9c":"code","2965931b":"code","a3e9b3b6":"code","558da99c":"code","83601283":"markdown","9793e4df":"markdown","95120d47":"markdown","463ef4d6":"markdown","b77ca0d6":"markdown","a54ae614":"markdown","077be840":"markdown","340658cc":"markdown","cb4ce930":"markdown","4ba6f47b":"markdown","eee3c563":"markdown","bf1dced8":"markdown","67cd6f90":"markdown","cfdbd9a0":"markdown","12c1d9b6":"markdown","2dc2d7dc":"markdown","2f8f160a":"markdown","17f3e6da":"markdown","9b2f4196":"markdown","41dcb3b5":"markdown","79d024e0":"markdown","8a4980cd":"markdown","25ffa36e":"markdown","fa935992":"markdown","8ae8a80f":"markdown","6c69dad1":"markdown","d543ec32":"markdown","f3e286b7":"markdown","23b22158":"markdown","7f87b35d":"markdown","382cbb73":"markdown","364517ca":"markdown","75d0124c":"markdown","413bb78e":"markdown","3f5b962f":"markdown","76ee151a":"markdown","5870e8b9":"markdown","d4ff20c7":"markdown","57734a93":"markdown","4142eea6":"markdown","61f62890":"markdown","d7a4aca4":"markdown","01fa43cf":"markdown","002bdc05":"markdown","f766adb4":"markdown","d239c924":"markdown","ab0d0248":"markdown","764e1e0d":"markdown","0b0633b0":"markdown","6d1c5903":"markdown","91548211":"markdown","9c640dd2":"markdown"},"source":{"d5a58e6f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36bf66cc":"import warnings\nwarnings.filterwarnings('ignore')","009303a8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","ea59ea05":"df = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\ndf.head(3)","943b9fb4":"df.info()","eae206bd":"print('Number of rows in the dataset: ',df.shape[0])\nprint('Number of columns in the dataset: ',df.shape[1])","2b938306":"df.isnull().sum()","cf84312c":"df.describe()","bb7e0b82":"male =len(df[df['sex'] == 1])\nfemale = len(df[df['sex']== 0])\n\nplt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'Male','Female'\nsizes = [male,female]\ncolors = ['skyblue', 'yellowgreen']\nexplode = (0, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=90)\n \nplt.axis('equal')\nplt.show()","ba0781d2":"plt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'Chest Pain Type:0','Chest Pain Type:1','Chest Pain Type:2','Chest Pain Type:3'\nsizes = [len(df[df['cp'] == 0]),len(df[df['cp'] == 1]),\n         len(df[df['cp'] == 2]),\n         len(df[df['cp'] == 3])]\ncolors = ['skyblue', 'yellowgreen','orange','gold']\nexplode = (0, 0,0,0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=180)\n \nplt.axis('equal')\nplt.show()","c7d285f2":"plt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'fasting blood sugar < 120 mg\/dl','fasting blood sugar > 120 mg\/dl'\nsizes = [len(df[df['fbs'] == 0]),len(df[df['cp'] == 1])]\ncolors = ['skyblue', 'yellowgreen','orange','gold']\nexplode = (0.1, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=180)\n \nplt.axis('equal')\nplt.show()","3dc6c6b4":"plt.figure(figsize=(8,6))\n\n# Data to plot\nlabels = 'No','Yes'\nsizes = [len(df[df['exang'] == 0]),len(df[df['exang'] == 1])]\ncolors = ['skyblue', 'yellowgreen']\nexplode = (0.1, 0)  # explode 1st slice\n \n# Plot\nplt.pie(sizes, explode=explode, labels=labels, colors=colors,\nautopct='%1.1f%%', shadow=True, startangle=90)\n \nplt.axis('equal')\nplt.show()","0d306a6e":"sns.set_style('whitegrid')","5504df3b":"plt.figure(figsize=(14,8))\nsns.heatmap(df.corr(), annot = True, cmap='coolwarm',linewidths=.1)\nplt.show()","2424e5a6":"sns.distplot(df['thalach'],kde=False,bins=30,color='violet')","c2a571c9":"sns.distplot(df['chol'],kde=False,bins=30,color='red')\nplt.show()","ad62efac":"sns.distplot(df['trestbps'],kde=False,bins=30,color='blue')\nplt.show()","35e780ea":"plt.figure(figsize=(15,6))\nsns.countplot(x='age',data = df, hue = 'target',palette='GnBu')\nplt.show()","a27253f3":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='chol',y='thalach',data=df,hue='target')\nplt.show()","5c342508":"plt.figure(figsize=(8,6))\nsns.scatterplot(x='trestbps',y='thalach',data=df,hue='target')\nplt.show()","8f238544":"X= df.drop('target',axis=1)\ny=df['target']","a614200f":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state=42)","c6440955":"from sklearn.preprocessing import StandardScaler","6529c1bb":"scaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_train = pd.DataFrame(X_train_scaled)\n\nX_test_scaled = scaler.transform(X_test)\nX_test = pd.DataFrame(X_test_scaled)","5a72384b":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nknn =KNeighborsClassifier()\nparams = {'n_neighbors':list(range(1,20)),\n    'p':[1, 2, 3, 4,5,6,7,8,9,10],\n    'leaf_size':list(range(1,20)),\n    'weights':['uniform', 'distance']\n         }","fabac53f":"model = GridSearchCV(knn,params,cv=3, n_jobs=-1)","1440e91b":"model.fit(X_train,y_train)\nmodel.best_params_           #print's parameters best values","ab625ce1":"predict = model.predict(X_test)","9e7b5863":"from sklearn.metrics import accuracy_score,confusion_matrix\nprint('Accuracy Score: ',accuracy_score(y_test,predict))\nprint('Using k-NN we get an accuracy score of: ',\n      round(accuracy_score(y_test,predict),5)*100,'%')","da4d4bd9":"\ncnf_matrix = confusion_matrix(y_test,predict)\ncnf_matrix","7f49c87c":"class_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for k-Nearest Neighbors Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","cc2363b9":"from sklearn.metrics import classification_report","d301036c":"print(classification_report(y_test,predict))","786860a0":"from sklearn.metrics import roc_auc_score,roc_curve","97aa8fc9":"#Get predicted probabilites from the model\ny_probabilities = model.predict_proba(X_test)[:,1]","a0c22982":"#Create true and false positive rates\nfalse_positive_rate_knn,true_positive_rate_knn,threshold_knn = roc_curve(y_test,y_probabilities)","f2da8599":"#Plot ROC Curve\nplt.figure(figsize=(10,6))\nplt.title('Revceiver Operating Characterstic')\nplt.plot(false_positive_rate_knn,true_positive_rate_knn)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.show()","4a98c301":"#Calculate area under the curve\nroc_auc_score(y_test,y_probabilities)","efd2d96f":"from sklearn.linear_model import LogisticRegression\nlog = LogisticRegression()","c9c4e9a1":"# Setting parameters for GridSearchCV\nparams = {'penalty':['l1','l2'],\n         'C':[0.01,0.1,1,10,100],\n         'class_weight':['balanced',None]}\nlog_model = GridSearchCV(log,param_grid=params,cv=10)","e95b61c3":"log_model.fit(X_train,y_train)\n\n# Printing best parameters choosen through GridSearchCV\nlog_model.best_params_","4ed2631e":"predict = log_model.predict(X_test)","9f8435cb":"from sklearn.metrics import accuracy_score\nprint('Accuracy Score: ',accuracy_score(y_test,predict))\nprint('Using Logistic Regression we get an accuracy score of: ',\n      round(accuracy_score(y_test,predict),5)*100,'%')","d70353d4":"from sklearn.metrics import recall_score,precision_score,classification_report,roc_auc_score,roc_curve\nprint(classification_report(y_test,predict))","265e4a5e":"cnf_matrix = confusion_matrix(y_test,predict)\ncnf_matrix","22f35155":"class_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Logisitic Regression Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","09079e68":"#Get predicted probabilites\ntarget_probailities_log = log_model.predict_proba(X_test)[:,1]","1dd9a810":"#Create true and false positive rates\nlog_false_positive_rate,log_true_positive_rate,log_threshold = roc_curve(y_test,\n                                                             target_probailities_log)","76f9f2a3":"#Plot ROC Curve\nsns.set_style('whitegrid')\nplt.figure(figsize=(10,6))\nplt.title('Reciver Operating Characterstic Curve')\nplt.plot(log_false_positive_rate,log_true_positive_rate)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')\nplt.show()","ce9f82ab":"#Calculate area under the curve\nroc_auc_score(y_test,target_probailities_log)","dbcc98d2":"from sklearn.tree import DecisionTreeClassifier\ndtree= DecisionTreeClassifier(random_state=7)","27e5c4ba":"#Setting parameters for GridSearchCV\nparams = {'max_features': ['auto', 'sqrt', 'log2'],\n          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11]}\ntree_model = GridSearchCV(dtree, param_grid=params, n_jobs=-1)","553319a1":"tree_model.fit(X_train,y_train)\n#Printing best parameters selected through GridSearchCV\ntree_model.best_params_","126dc923":"predict = tree_model.predict(X_test)","32fcc90f":"from sklearn.metrics import accuracy_score\nprint('Accuracy Score: ',accuracy_score(y_test,predict))\nprint('Using Decision Tree we get an accuracy score of: ',\n      round(accuracy_score(y_test,predict),5)*100,'%')","895be01c":"from sklearn.metrics import classification_report,roc_auc_score,roc_curve","2afb0fbd":"print(classification_report(y_test,predict))","3e2a7f74":"cnf_matrix = confusion_matrix(y_test,predict)\ncnf_matrix","8d277f4f":"class_names = [0,1]\nfig,ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks,class_names)\nplt.yticks(tick_marks,class_names)\n\n#create a heat map\nsns.heatmap(pd.DataFrame(cnf_matrix), annot = True, cmap = 'YlGnBu',\n           fmt = 'g')\nax.xaxis.set_label_position('top')\nplt.tight_layout()\nplt.title('Confusion matrix for Decision Tree Model', y = 1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","0ea28149":"#Get predicted probabilites\ntarget_probailities_tree = tree_model.predict_proba(X_test)[:,1]","63475d9c":"#Create true and false positive rates\ntree_false_positive_rate,tree_true_positive_rate,tree_threshold = roc_curve(y_test,\n                                                             target_probailities_tree)","2965931b":"#Plot ROC Curve\nsns.set_style('whitegrid')\nplt.figure(figsize=(10,6))\nplt.title('Reciver Operating Characterstic Curve')\nplt.plot(tree_false_positive_rate,tree_true_positive_rate)\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')\nplt.show()","a3e9b3b6":"#Calculate area under the curve\nroc_auc_score(y_test,target_probailities_tree)","558da99c":"#Plot ROC Curve\nsns.set_style('whitegrid')\nplt.figure(figsize=(10,6))\nplt.title('Reciver Operating Characterstic Curve')\nplt.plot(false_positive_rate_knn,true_positive_rate_knn,label='k-Nearest Neighbor')\nplt.plot(log_false_positive_rate,log_true_positive_rate,label='Logistic Regression')\nplt.plot(tree_false_positive_rate,tree_true_positive_rate,label='Decision Tree')\nplt.plot([0,1],ls='--')\nplt.plot([0,0],[1,0],c='.5')\nplt.plot([1,1],c='.5')\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')\nplt.legend()\nplt.show()","83601283":"# <span style=\"color:blue\">**Please Upvote If You Like, Use Or Learn From This.**\n\n# <span style=\"color:blue\">**Also Comment For Improvisation Of The Notebook.**\n\n\n# <span style=\"color:blue\">**Thank You!!!**\n\n","9793e4df":"### **Exploratory Data Analysis**","95120d47":"# 2. Logistic Regression","463ef4d6":"#### **1. Sex**","b77ca0d6":"**5. Scatterplot for thalach vs. chol**","a54ae614":"**Making predictions**","077be840":"**6. Scatterplot for thalach vs. trestbps**","340658cc":"# Dataset:\n\nThe Dataset contains the following features:<br>\n\n**1. age(in years)**<br>\n**2. sex:** (1 = male; 0 = female)<br>\n**3. cp:** chest pain type<br>\n**4. trestbps:** resting blood pressure (in mm Hg on admission to the hospital)<br>\n**5. chol:** serum cholestoral in mg\/dl<br>\n**6. fbs:** (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)<br>\n**7. restecg:** resting electrocardiographic results<br>\n**8. thalach:** maximum heart rate achieved<br>\n**9. exang:** exercise induced angina (1 = yes; 0 = no)<br>\n**10. oldpeak**: ST depression induced by exercise relative to rest<br>\n**11. slope:** the slope of the peak exercise ST segment<br>\n**12. ca:** number of major vessels (0-3) colored by flourosopy<br>\n**13. thal:** 3 = normal; 6 = fixed defect; 7 = reversable defect<br>\n**14. target:** 1 or 0 <br>","cb4ce930":"**Confusion Matrix**","4ba6f47b":"# Making Predictions","eee3c563":"**Classification Report**","bf1dced8":"#### **3. trestbps: resting blood pressure (in mm Hg on admission to the hospital)**","67cd6f90":"**2.chol: serum cholestoral in mg\/dl**","cfdbd9a0":"### **Loading the data**","12c1d9b6":"## **3. Decision Tree**","2dc2d7dc":"# Dimensions of the dataset","2f8f160a":"# Content:\n\n\n* **INTRODUCTION**\n* **DATASET COLUMNS FEATURE EXPLAIN**\n* **INVESTIGATING THE DATA and EXPLORATORY DATA ANALSIS**\n* **One Visualization to Rule Them All**\n* **Age Analysis**\n* **Sex (Gender) Analysis**\n* **Chest Pain Type Analysis**\n* **Age Range Analysis**\n* **Thalach Analysis**\n* **Thal Analysis**\n* **Target Analysis**\n* **MODEL, TRAINING and TESTING**\n* **Logistic Regression**\n* **K-Nearest Neighbors**","17f3e6da":"**Accuracy Metrics**","9b2f4196":"# Checking features of various attributes","41dcb3b5":"#### **1. thalach: maximum heart rate achieved**","79d024e0":"# 1. k-Nearest Neighor Algorithm","8a4980cd":"### **Importing required libraries**","25ffa36e":"**The features described in the above data set are:**\n\n**1. Count** tells us the number of NoN-empty rows in a feature.<br>\n\n**2. Mean** tells us the mean value of that feature.<br>\n\n**3. Std** tells us the Standard Deviation Value of that feature.<br>\n\n**4. Min** tells us the minimum value of that feature.<br>\n\n**5. 25%**, **50%**, and **75%** are the percentile\/quartile of each features.<br>\n\n**6. Max** tells us the maximum value of that feature.<br>\n","fa935992":"#### **2. Chest Pain Type**","8ae8a80f":"There are no null values in the dataset","6c69dad1":"# Introduction:\n\n> We have a data which classified if patients have heart disease or not according to features in it. We will try to use this data to create a model which tries predict if a patient has this disease or not. In this kernel I have performed Exploratory Data Analysis on the Heart Diseases UCI and tried to identify relationship between heart disease  and various other features. After EDA data pre-processing is done I have applied k-NN(k-Nearest Neighbors) method and Logistic Regression Algorithm to make the predictions.\n","d543ec32":"**Splitting the dataset into training and test set**","f3e286b7":"# Confusion Matrix","23b22158":"**Making predictions**","7f87b35d":"<img style=\"float: center;\" src=\"https:\/\/timesofindia.indiatimes.com\/thumb\/msid-71058199,width-1200,height-900,resizemode-4\/.jpg\" width=\"500px\"\/>","382cbb73":"#### **3. fbs: (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)**","364517ca":"**World Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases. Half the deaths in the United States and other developed countries are due to cardio vascular diseases. The early prognosis of cardiovascular diseases can aid in making decisions on lifestyle changes in high risk patients and in turn reduce the complications. This research intends to pinpoint the most relevant\/risk factors of heart disease as well as predict the overall risk using logistic regression.**","75d0124c":"**Implementing GridSearchCv to select best parameters and applying k-NN Algorithm**","413bb78e":"**Receiver Operating Characterstic(ROC) Curve**","3f5b962f":"**Receiver Operating Characterstic(ROC) Curve**","76ee151a":"**4. Number of people who have heart disease according to age**","5870e8b9":"**Accuracy Metrics**","d4ff20c7":"# Making predictions","57734a93":"**Confusion Matrix**","4142eea6":"#### **4.exang: exercise induced angina (1 = yes; 0 = no)**","61f62890":"#### **1. Heatmap**","d7a4aca4":"#### **Plotting the distribution of various attribures**","01fa43cf":"# Checking accuracy","002bdc05":"# Problem Definition:\n \nGiven clinical parameters about a patient, can we predict whether or not they have heart disease?","f766adb4":"# **<span style=\"color:blue\">HEART DISEASE PREDICTION**\ud83d\udd25\ud83d\udd25","d239c924":"### **Features of the data set**","ab0d0248":"**<span style=\"color:blue\">Please Upvote If You Like, Use Or Learn From This. If you have any idea that might improve this kernel, please be sure to comment, or fork and experiment as you like. If you don't understand any part, feel free to ask in the comment section.**\ud83d\ude4c\ud83d\ude4c\ud83d\ude4c","764e1e0d":"**Classification report**","0b0633b0":"# Checking for null values in the dataset","6d1c5903":"**Receiver Operating Characterstic(ROC) Curve**","91548211":"# Preprocessing - Scaling the features","9c640dd2":"**Comparing ROC Curve of k-Nearest Neighbors, Logistic Regression and Decision Tree**"}}