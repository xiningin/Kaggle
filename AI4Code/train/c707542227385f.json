{"cell_type":{"48bd75fc":"code","2855e3e6":"code","c7443354":"code","7e2802a6":"code","91cdd874":"code","cb37ccb4":"code","a834477e":"code","243fac01":"code","e1ccfe97":"code","eedb0881":"code","17d72174":"code","662a0758":"code","48562aae":"code","ccd0403e":"code","da9917a8":"code","ae12da25":"code","a00a63b5":"code","58692b7b":"code","6b1cc2d0":"code","b0863db9":"code","7b42893b":"code","f4c71eac":"code","c143b2bd":"code","5a84a1c9":"code","ab3fe2f7":"code","fe25c728":"code","d1f975ea":"code","76a0698a":"code","35fed8ca":"code","27774852":"code","9f08b97a":"code","aa4e5ac5":"code","61c4158a":"markdown","2efe1f7a":"markdown","87b680a3":"markdown","111e790f":"markdown","df738121":"markdown"},"source":{"48bd75fc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2855e3e6":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\nimport matplotlib.pyplot as plt\n\n!pip install underthesea\n!pip install openpyxl\nfrom underthesea import word_tokenize\nimport regex as re\n\ndevice = torch.device(\"cuda\")\nprint('success')","c7443354":"import wandb\nimport os\nos.environ[\"WANDB_API_KEY\"] = \"351cc1ebc0d966d49152a4c1937915dd4e7b4ef5\"\n\nwandb.login(key=\"351cc1ebc0d966d49152a4c1937915dd4e7b4ef5\")\n","7e2802a6":"wandb.init(project = \"DataScience Sentiment Analysis\")","91cdd874":"\n\npath_dataset = \"\/kaggle\/input\/datasetfull\/Dataset_23_12.xlsx\"\ndataframe = pd.read_excel(path_dataset, sheet_name = 'Dataset')\ndataframe.head()","cb37ccb4":"train_text, tmp_text, train_labels, tmp_labels = train_test_split(dataframe['Review'], dataframe['Label'], \n                                                                    random_state=2021, \n                                                                    test_size=0.2, \n                                                                    stratify=dataframe['Label'])\n\n\nval_text, test_text, val_labels, test_labels = train_test_split(tmp_text, tmp_labels, \n                                                                    random_state=2021, \n                                                                    test_size=0.5, \n                                                                    stratify=tmp_labels)\n\ntrain_text = train_text.astype(str)\nval_text = val_text.astype(str)\ntest_text = test_text.astype(str)\nprint(len(train_text), len(val_text), len(test_text))\n# train_text = train_text.apply(preprocessing)\n# val_text = val_text.apply(preprocessing)","a834477e":"train_text.head(5)","243fac01":"val_text.head(5)","e1ccfe97":"# dataframe[dataframe.label_id==1].shape[0] \/ dataframe.shape[0] ","eedb0881":"# from sklearn.feature_extraction.text import TfidfVectorizer\n\n# vectorizer = TfidfVectorizer()\n# X = vectorizer.fit_transform(train_text.values)\n# y = train_labels","17d72174":"# X_val = vectorizer.transform(val_text.values)\n# y_val = val_labels","662a0758":"# from sklearn import svm\n\n# cls = svm.SVC(random_state=2021, kernel='rbf',C=5, cache_size=8000)\n# cls.fit(X,y)\n\n# y_predict = cls.predict(X_val)","48562aae":"# from sklearn.metrics import classification_report\n\n# print(classification_report(y_val,y_predict))","ccd0403e":"!pip install transformers\nimport torch\nfrom transformers import AutoModel, AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"vinai\/phobert-base\", use_fast=False)","da9917a8":"class PhoBert_Classification(torch.nn.Module):\n    def __init__(self, num_class):\n        super(PhoBert_Classification, self).__init__()\n        self.backbone = AutoModel.from_pretrained(\"vinai\/phobert-base\")\n        \n        self.dense_1 = torch.nn.Linear(in_features = 768, out_features = 128, bias=True)\n        self.dense_2 = torch.nn.Linear(in_features = 128, out_features = num_class, bias=True)\n        self.dropout1 = nn.Dropout(0.6)\n        self.relu =  nn.ReLU()\n        self.dropout2 = nn.Dropout(0.6)\n        #softmax activation function (Log softmax)\n        self.softmax = nn.LogSoftmax(dim=1)\n    \n    def forward(self, sent_id,mask):\n\n        #get pooler_output of ['CLS'] token from bert output\n        cls_hs= self.backbone(sent_id, attention_mask=mask).pooler_output\n        x = self.dropout1(cls_hs)\n        x = self.dense_1(cls_hs)\n\n        x = self.relu(x)\n\n        x = self.dropout2(x)\n\n        # output layer\n        x = self.dense_2(x)\n\n        x = self.softmax(x)\n\n        return x\n","ae12da25":"model = PhoBert_Classification(2)","a00a63b5":"# tokenize and encode sequences in the training set\nMAX_LENGTH = 200\ntokens_train = tokenizer.batch_encode_plus(\n    train_text.tolist(),\n    max_length = MAX_LENGTH,\n    pad_to_max_length=True,\n    truncation=True\n)\n\n# tokenize and encode sequences in the validation set\ntokens_val = tokenizer.batch_encode_plus(\n    val_text.tolist(),\n    max_length = MAX_LENGTH,\n    pad_to_max_length=True,\n    truncation=True\n)\n\n# # tokenize and encode sequences in the test set\ntokens_test = tokenizer.batch_encode_plus(\n    test_text.tolist(),\n    max_length = MAX_LENGTH,\n    pad_to_max_length=True,\n    truncation=True\n)","58692b7b":"train_seq = torch.tensor(tokens_train['input_ids'])\ntrain_mask = torch.tensor(tokens_train['attention_mask'])\ntrain_y = torch.tensor(train_labels.tolist())\n\nval_seq = torch.tensor(tokens_val['input_ids'])\nval_mask = torch.tensor(tokens_val['attention_mask'])\nval_y = torch.tensor(val_labels.tolist())\n\ntest_seq = torch.tensor(tokens_test['input_ids'])\ntest_mask = torch.tensor(tokens_test['attention_mask'])\ntest_y = torch.tensor(test_labels.tolist())","6b1cc2d0":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\nbatch_size = 32\n\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\n\ntrain_sampler = RandomSampler(train_data)\n\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nval_data = TensorDataset(val_seq, val_mask, val_y)\n\nval_sampler = SequentialSampler(val_data)\n\nval_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n\n\ntest_data = TensorDataset(test_seq, test_mask, test_y)\ntest_sampler = SequentialSampler(test_data)\n\ntest_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)","b0863db9":"device = torch.device(\"cuda\")\nmodel = model.to(device)","7b42893b":"from transformers import AdamW\noptimizer = AdamW(model.parameters(), lr = 1e-5) ","f4c71eac":"from sklearn.utils.class_weight import compute_class_weight\n\n#compute the class weights\nclass_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n\nprint(\"Class Weights:\",class_weights)","c143b2bd":"# converting list of class weights to a tensor\nweights= torch.tensor(class_weights,dtype=torch.float)\n\n# push to GPU\nweights = weights.to(device)\n\n# define the loss function\ncross_entropy  = nn.NLLLoss(weight=weights) \n\n# number of training epochs\n# epochs = 20","5a84a1c9":"def train(model):\n  model.train()\n  total_loss, total_accuracy = 0, 0\n  total_preds=[]\n  for step,batch in enumerate(train_dataloader):\n    if step % 50 == 0 and not step == 0:\n      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n    batch = [r.to(device) for r in batch]\n \n    sent_id, mask, labels = batch\n    model.zero_grad()        \n    preds = model(sent_id, mask)\n    loss = cross_entropy(preds, labels)\n    total_loss = total_loss + loss.item()\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n    optimizer.step()\n    preds=preds.detach().cpu().numpy()\n    total_preds.append(preds)\n\n  avg_loss = total_loss \/ len(train_dataloader)\n  total_preds  = np.concatenate(total_preds, axis=0)\n\n  return avg_loss, total_preds","ab3fe2f7":"from sklearn.metrics import precision_score, \\\n    recall_score, confusion_matrix, classification_report, \\\n    accuracy_score, f1_score","fe25c728":"def evaluate(model, t_dataset_loader):\n  \n    print(\"\\nEvaluating...\")\n\n    # deactivate dropout layers\n    model.eval()\n\n    total_loss, total_accuracy = 0, 0\n\n    # empty list to save the model predictions\n    total_preds = []\n    total_groundtruth = []\n\n    # iterate over batches\n    for step,batch in enumerate(t_dataset_loader):\n\n        # Progress update every 50 batches.\n        if step % 50 == 0 and not step == 0:\n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n\n        # push the batch to gpu\n        batch = [t.to(device) for t in batch]\n\n        sent_id, mask, labels = batch\n\n\n        # deactivate autograd\n        with torch.no_grad():\n\n            # model predictions\n            preds = model(sent_id, mask)\n\n            # compute the validation loss between actual and predicted values\n            loss = cross_entropy(preds,labels)\n\n            total_loss = total_loss + loss.item()\n\n            preds = preds.detach().cpu().numpy()\n\n            total_preds.append(preds)\n            \n            out_labels = labels.detach().cpu().numpy()\n            total_groundtruth.append(out_labels)\n\n    # compute the validation loss of the epoch\n    avg_loss = total_loss \/ len(val_dataloader) \n\n    # reshape the predictions in form of (number of samples, no. of classes)\n    total_preds  = np.concatenate(total_preds, axis=0,)\n    total_preds = np.argmax(total_preds, axis=1)\n    total_preds = np.array(total_preds, dtype = np.int16)\n    total_groundtruth = np.concatenate(total_groundtruth, axis = 0)\n    total_groundtruth = np.array(total_groundtruth, dtype = np.int16)\n\n    #F1 score\n    focus_f1 = f1_score(total_groundtruth, total_preds)\n    print(\"Accuracy: \", accuracy_score(total_groundtruth, total_preds))\n    print(\"F1 score: \", focus_f1)\n    print('Recall:', recall_score(total_groundtruth, total_preds))\n    print('Precision:', precision_score(total_groundtruth, total_preds))\n    print('\\n clasification report:\\n', classification_report(total_groundtruth,total_preds))\n    print('\\n confussion matrix:\\n',confusion_matrix(total_groundtruth, total_preds))\n#     wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n#                         y_true=total_groundtruth, preds=total_preds,\n#                         class_names=[\"Negative\", \"Positive\"])})\n\n\n    return avg_loss, total_preds, focus_f1","d1f975ea":"# set initial loss to infinite\nbest_valid_loss = float('inf')\nbest_valid_f1 = 0\n\n# empty lists to store training and validation loss of each epoch\ntrain_losses=[]\nvalid_losses=[]\nn_epochs = []\nd = 0\n\nwarmup_nepochs = 10\nfinetune_nepochs = 150\nfor param in model.backbone.parameters():\n    param.requires_grad = False\n        \n#for each epoch\nfor epoch in range(warmup_nepochs):\n    print(\"Start\")\n    print('\\n Warmup Epoch {:} \/ {:}'.format(epoch + 1, warmup_nepochs))\n    \n    #train model\n    train_loss, _ = train(model)\n    print({\"Loss train\": train_loss})\n    \n    #evaluate model\n    valid_loss, _, f1_value = evaluate(model, val_dataloader)\n    print({\"Loss val\": valid_loss})\n    \n    print({\"F1 score\": f1_value})\n    wandb.log({\"Loss train\": train_loss})\n    wandb.log({\"Loss val\": valid_loss})\n    wandb.log({\"F1 score\": f1_value})\n    \n    #save the best model\n    if f1_value > best_valid_f1:\n        best_valid_f1 = f1_value\n        torch.save(model.state_dict(), '\/kaggle\/working\/Best_weights_f1.pt')\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n    torch.save(model.state_dict(), '\/kaggle\/working\/Lass_weights_f1.pt')\n    \n    # append training and validation loss\n    d+=1\n    n_epochs.append(d)\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    \n    print(f'\\nTraining Loss: {train_loss:.3f}')\n    print(f'Validation Loss: {valid_loss:.3f}')\n    \n\nfor param in model.backbone.parameters():\n    param.requires_grad = True\n        \nfor epoch in range(finetune_nepochs):\n    print(\"Start\")\n    print('\\n FineTune Epoch {:} \/ {:}'.format(epoch + 1, finetune_nepochs))\n\n    #train model\n    train_loss, _ = train(model)\n    print({\"Loss train\": train_loss})\n    #evaluate model\n    valid_loss, _, f1_value = evaluate(model, val_dataloader)\n    print({\"Loss val\": valid_loss})\n    print({\"F1 score\": f1_value})\n    wandb.log({\"Loss train\": train_loss})\n    wandb.log({\"Loss val\": valid_loss})\n    wandb.log({\"F1 score\": f1_value})\n    #save the best model\n    if f1_value > best_valid_f1:\n        best_valid_f1 = f1_value\n        torch.save(model.state_dict(), '\/kaggle\/working\/Best_weights_f1.pt')\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n    torch.save(model.state_dict(), '\/kaggle\/working\/Lass_weights_f1.pt')\n    \n    # append training and validation loss\n    d+=1\n    n_epochs.append(d)\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    \n    print(f'\\nTraining Loss: {train_loss:.3f}')\n    print(f'Validation Loss: {valid_loss:.3f}')","76a0698a":"def test_evaluate(model, t_dataset_loader):\n  \n    print(\"\\nEvaluating...\")\n\n    # deactivate dropout layers\n    model.eval()\n\n    total_loss, total_accuracy = 0, 0\n\n    # empty list to save the model predictions\n    total_preds = []\n    total_groundtruth = []\n\n    # iterate over batches\n    for step,batch in enumerate(t_dataset_loader):\n\n        # Progress update every 50 batches.\n        if step % 50 == 0 and not step == 0:\n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n\n        # push the batch to gpu\n        batch = [t.to(device) for t in batch]\n\n        sent_id, mask, labels = batch\n\n\n        # deactivate autograd\n        with torch.no_grad():\n\n            # model predictions\n            preds = model(sent_id, mask)\n\n            # compute the validation loss between actual and predicted values\n            loss = cross_entropy(preds,labels)\n\n            total_loss = total_loss + loss.item()\n\n            preds = preds.detach().cpu().numpy()\n\n            total_preds.append(preds)\n            \n            out_labels = labels.detach().cpu().numpy()\n            total_groundtruth.append(out_labels)\n\n    # compute the validation loss of the epoch\n    avg_loss = total_loss \/ len(val_dataloader) \n\n    # reshape the predictions in form of (number of samples, no. of classes)\n    total_preds  = np.concatenate(total_preds, axis=0,)\n    total_preds = np.argmax(total_preds, axis=1)\n    total_preds = np.array(total_preds, dtype = np.int16)\n    total_groundtruth = np.concatenate(total_groundtruth, axis = 0)\n    total_groundtruth = np.array(total_groundtruth, dtype = np.int16)\n\n    #F1 score\n    focus_f1 = f1_score(total_groundtruth, total_preds)\n    print(\"Accuracy: \", accuracy_score(total_groundtruth, total_preds))\n    print(\"F1 score: \", focus_f1)\n    print('Recall:', recall_score(total_groundtruth, total_preds))\n    print('Precision:', precision_score(total_groundtruth, total_preds))\n    print('\\n clasification report:\\n', classification_report(total_groundtruth,total_preds))\n    print('\\n confussion matrix:\\n',confusion_matrix(total_groundtruth, total_preds))\n    wandb.log({\"Evaluate conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n                        y_true=total_groundtruth, preds=total_preds,\n                        class_names=[\"Negative\", \"Positive\"])})\n\n\n    return avg_loss, total_preds, focus_f1","35fed8ca":"device = torch.device(\"cuda\")\npath_best_weight = \"\/kaggle\/working\/Best_weights_f1.pt\"\nmodel_test = PhoBert_Classification(2)\nmodel_test.load_state_dict(torch.load(path_best_weight))\nmodel_test.to(device)\n","27774852":"avg_loss, total_preds, focus_f1 = test_evaluate(model_test, test_dataloader)\nprint(\"F1 test: \", focus_f1)\nwandb.log({\"Evaluate F1 score\": focus_f1})","9f08b97a":"# wandb.log({\"Best F1\": f1_value})","aa4e5ac5":"# fig, ax = plt.subplots(figsize=(16, 8))\n# ax.plot(n_epochs, train_losses, label='train_loss')\n# ax.plot(n_epochs, valid_losses, label='val_loss') \n# ax.set_xlabel('n-epochs')  \n# ax.legend()","61c4158a":"# **Evaluate**","2efe1f7a":"# **Build Model**","87b680a3":"## PhoBERT","111e790f":"# **DATA & PREPROCCESS**","df738121":"## Tf_idf + SVM"}}