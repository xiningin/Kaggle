{"cell_type":{"5abe8f61":"code","0ed3d754":"code","224d107a":"code","fb3964e6":"code","2bc15777":"code","40653706":"code","e7a125d5":"code","71466a16":"code","276ac99e":"code","6e12b13a":"code","36f53efc":"code","6ada0634":"code","a3940698":"code","0ab7b471":"code","9ccf283f":"code","5f6c576d":"code","ad08e448":"code","7e46ead9":"code","81b3e646":"code","c32430d7":"code","5d3cfcae":"code","e19d226a":"code","1856054f":"code","8a6ca039":"code","129f3799":"code","b8d774ff":"code","0f105cec":"code","bb90fa63":"code","15be25a7":"code","44b4d98a":"code","6ee3a7bb":"code","2c2fa9c0":"code","062a9752":"code","a76d423d":"code","aa4a6d1a":"code","f3d3f8eb":"code","dae4f4d2":"code","eebe13d7":"code","dfb5d3c8":"code","bddf007c":"code","94780a2b":"code","3e3c665d":"code","12c7822b":"code","e89cc3ed":"markdown","4f6b7a6b":"markdown","ae980ac2":"markdown","6d948338":"markdown","be883206":"markdown","0aef52d1":"markdown","6c1beed1":"markdown","3f4db549":"markdown","046fad63":"markdown","91f97cd4":"markdown","99bbe23c":"markdown","f32dc5f9":"markdown","e994c790":"markdown","f744206d":"markdown","a465c529":"markdown","0495faeb":"markdown","7d79aa1a":"markdown","0569d8b6":"markdown","d98679c9":"markdown","eb2b4be0":"markdown","b6a08f92":"markdown","9047ef5b":"markdown","a2d26f46":"markdown","21e5b6d2":"markdown","ed37be59":"markdown","9befc5fa":"markdown","f31252c1":"markdown","f004a3e0":"markdown","c4a6e2f4":"markdown","cc3a751a":"markdown","48c4e5c5":"markdown","ae68e476":"markdown"},"source":{"5abe8f61":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py \nimport plotly.graph_objs as go\nimport scipy.cluster.hierarchy as shc\nfrom plotly.offline import init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nfrom sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation\nfrom sklearn.preprocessing import StandardScaler\nimport os\n\ndf = pd.read_csv(\"..\/input\/world-foodfeed-production\/FAO.csv\",  encoding = \"ISO-8859-1\")\ndf.head()","0ed3d754":"df.dtypes[:20]","224d107a":"#In order to not have problems of consistency:\ndf['Area'].replace(['Swaziland'], 'Eswatini', inplace=True)\ndf['Area'].replace(['The former Yugoslav Republic of Macedonia'], 'North Macedonia', inplace=True)\n\n#GET NEW DATA\ndf_pop = pd.read_csv(\"..\/input\/world-population\/FAOSTAT_data_6-13-2019.csv\")\ndf_area = pd.read_csv(\"..\/input\/countries-area-2013\/countries_area_2013.csv\")\ndf_pop = pd.DataFrame({'Area': df_pop['Area'] , 'Population': df_pop['Value'] })\ndf_area = pd.DataFrame({'Area' : df_area['Area'], 'Surface': df_area['Value']})\n#add missing line\ndf_area = df_area.append({'Area' : 'Sudan' , 'Surface' : 1886} , ignore_index=True)\n\n#MERGE OF TABLES\nd1 = pd.DataFrame(df.loc[:, ['Area', 'Item', 'Element']])\ndata = pd.merge(d1, df_pop, on='Area', how='left')\nnew_data = pd.merge(data, df_area, on='Area', how='left')\n\nd2 = df.loc[:, 'Y1961':'Y2013']\ndata = new_data.join(d2)\ndata.head()","fb3964e6":"print('Number of different Countries: ' , df['Area'].unique().size)\nprint('Number of different Items: ' , df['Item'].unique().size)","2bc15777":"#Graph of missing values\nsns.heatmap(data.isnull(),cbar=False,cmap='viridis')   \nplt.show()","40653706":"# Total number of missing values per year\nprint('YEAR  MISSING VALUES')\nprint (df.loc[:, 'Y1961':'Y2013'].isnull().sum())","e7a125d5":"df1 = data[data.isna().any(axis=1)]\ndf1.head()","71466a16":"#Total number of missing values for Area\nvalues_per_area = data.pivot_table(index=['Area'], aggfunc='size')\ndf1 = data[data.isna().any(axis=1)]\ndf_missing_area = df1.pivot_table(index=['Area'], aggfunc='size')\ndf_missing_area","276ac99e":"year_list = list(df.iloc[:,10:].columns)\ndf_new = df.pivot_table(values=year_list,columns = 'Element', index=['Area'], aggfunc='sum') #for each country sum over years separatly Food&Feed\ndf_fao = df_new.T\ndf_fao.head()","6e12b13a":"# Finding the Top 5 producer of Feed and Food from 1961 to 2013\ndf_fao_tot = df_fao.sum(axis=0).sort_values(ascending=False).head()\ndf_fao_tot.plot(kind='bar', title='Top 5 Food & Feed producer', color='g')","36f53efc":"#Producer of just Food\ndf_food = df_fao.xs('Food', level=1, axis=0)\ndf_food_tot = df_food.sum(axis=0).sort_values(ascending=False).head()\n#Producer of just Feed\ndf_feed = df_fao.xs('Feed', level=1, axis=0)\ndf_feed = df_feed.sum(axis=0).sort_values(ascending=False).head()\n\n#Plot\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\ndf_food_tot.plot(kind='bar', title='Top 5 Food producer', color='g', ax=ax1)\ndf_feed.plot(kind='bar', title='Top 5 Feed producer', color='g', ax=ax2 )","6ada0634":"#Rank of most Produced Items \ndf_item = df.pivot_table(values=year_list, columns='Element',index=['Item'], aggfunc='sum')\ndf_item = df_item.T\n#FOOD\ndf_food_item = df_item.xs('Food', level=1, axis=0)\ndf_food_item = df_food_item.sum(axis=0).sort_values(ascending=False).head()\n#FEED\ndf_feed_item = df_item.xs('Feed', level=1, axis=0)\ndf_feed_item = df_feed_item.sum(axis=0).sort_values(ascending=False).head()\n#Plot\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\ndf_food_item.plot(kind='bar', title='Top 5 Food produced item', color='g', ax=ax1)\ndf_feed_item.plot(kind='bar', title='Top 5 Feed produced item', color='g' , ax=ax2)","a3940698":"# Visualization of the top 5 producer countries among years\nplt.figure(figsize = (10,6))\ntop_5 = []\nfor i in df_food_tot.index:\n    year = df_food[i]\n    top_5.append(year)\n    plt.plot(year, marker='p')\n    plt.xticks(df_food.index, rotation='vertical')\n    plt.legend(loc='right')","0ab7b471":"fig, ax = plt.subplots(figsize=(10,7))\nsns.heatmap(data=pd.DataFrame(top_5),linewidths=0, ax=ax)\nplt.show()","9ccf283f":"d3 = df.loc[:, 'Y1993':'Y2013'] #take only last 20 years\ndata1 = new_data.join(d3) #recap: new_data does not contains years data\n\nd4 = data1.loc[data1['Element'] == 'Food'] #get just food\nd5 = d4.drop('Element', axis=1)\nd5 = d5.fillna(0) #substitute missing values with 0\n\nyear_list = list(d3.iloc[:,:].columns)\nd6 = d5.pivot_table(values=year_list, index=['Area'], aggfunc='sum')\n\nitaly = d4[d4['Area'] == 'Italy']\nitaly = italy.pivot_table(values=year_list, index=['Item'], aggfunc='sum')\nitaly = pd.DataFrame(italy.to_records())\n\nitem = d5.pivot_table(values=year_list, index=['Item'], aggfunc='sum')\nitem = pd.DataFrame(item.to_records())\n\nd5 = d5.pivot_table(values=year_list, index=['Area', 'Population', 'Surface'], aggfunc='sum')\narea = pd.DataFrame(d5.to_records())\nd6.loc[:, 'Total'] = d6.sum(axis=1)\nd6 = pd.DataFrame(d6.to_records())\nd = pd.DataFrame({'Area' : d6['Area'] , 'Total': d6['Total'] , 'Population': area['Population'], 'Surface': area['Surface']})","5f6c576d":"d.head()","ad08e448":"data_ = dict(type = 'choropleth',\nlocations = d['Area'],\nlocationmode = 'country names',\nz = d['Total'],\ntext = d['Area'],\ncolorbar = {'title':'Tons of food'})\nlayout = dict(title = 'Total Production of Food 1993-2013',\ngeo = dict(showframe = False,\nprojection = {'type': 'mercator'}))\nchoromap3 = go.Figure(data = [data_], layout=layout)\niplot(choromap3)","7e46ead9":"data_ = dict(type = 'choropleth',\nlocations = d['Area'],\nlocationmode = 'country names',\nz = d['Population'],\ntext = d['Area'],\ncolorbar = {'title':'Tons of food'})\nlayout = dict(title = 'World Population of 2013',\ngeo = dict(showframe = False,\nprojection = {'type': 'mercator'}))\nchoromap3 = go.Figure(data = [data_], layout=layout)\niplot(choromap3)","81b3e646":"data_ = dict(type = 'choropleth',\nlocations = d['Area'],\nlocationmode = 'country names',\nz = d['Surface'],\ntext = d['Area'],\ncolorbar = {'title':'Tons of food'})\nlayout = dict(title = 'World Surface',\ngeo = dict(showframe = False,\nprojection = {'type': 'mercator'}))\nchoromap3 = go.Figure(data = [data_], layout=layout)\niplot(choromap3)","c32430d7":"italy.head()","5d3cfcae":"area.head()","e19d226a":"item.head()","1856054f":"X = pd.DataFrame({'Total': d['Total'], 'Surface' : d['Surface'], 'Population' : d['Population']})\nX.head()","8a6ca039":"X.describe()","129f3799":"fig = plt.figure(figsize=(20,26))\n\nax1 = fig.add_subplot(231)\nax1=sns.boxplot(x='Total',data=X, orient='v') \nax2 = fig.add_subplot(232)\nax2=sns.boxplot(x='Surface',data=X,orient='v')\nax3 = fig.add_subplot(233)\nax3=sns.boxplot(x='Population',data=X, orient='v')","b8d774ff":"f,ax = plt.subplots(figsize=(6, 6))\nsns.heatmap(X.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","0f105cec":"wcss = []\nfor i in range(1,8):\n    kmeans = KMeans(n_clusters=i,init='k-means++',max_iter=300,n_init=7,random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,8),wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","bb90fa63":"def K_Means(X, n):\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n    model = KMeans(n)\n    model.fit(X)\n    clust_labels = model.predict(X)\n    cent = model.cluster_centers_\n    return (clust_labels, cent)","15be25a7":"clust_labels, cent = K_Means(X, 2)\nkmeans = pd.DataFrame(clust_labels)\nX.insert((X.shape[1]),'kmeans',kmeans)","44b4d98a":"def Plot3dClustering(n, X, type_c): \n    data = []\n    clusters = []\n    colors = ['rgb(228,26,28)','rgb(55,126,184)','rgb(77,175,74)']\n\n    for i in range(n):\n        name = i\n        color = colors[i]\n        x = X[ X[type_c] == i ]['Total']\n        y = X[ X[type_c] == i ]['Population']\n        z = X[ X[type_c] == i ]['Surface']\n\n        trace = dict(\n            name = name,\n            x = x, y = y, z = z,\n            type = \"scatter3d\",    \n            mode = 'markers',\n            marker = dict( size=4, color=color, line=dict(width=0) ) )\n        data.append( trace )\n\n        cluster = dict(\n            color = color,\n            opacity = 0.1,\n            type = \"mesh3d\", \n            alphahull = 7,\n            name = \"y\",\n            x = x, y = y, z = z )\n        data.append( cluster )\n\n    layout = dict(\n        width=800,\n        height=550,\n        autosize=False,\n        title='3D Clustering Plot',\n        scene=dict(\n            xaxis=dict(\n                gridcolor='rgb(255, 255, 255)',\n                zerolinecolor='rgb(255, 255, 255)',\n                showbackground=True,\n                title='Total Production',\n                backgroundcolor='rgb(230, 230,230)'\n            ),\n            yaxis=dict(\n                gridcolor='rgb(255, 255, 255)',\n                zerolinecolor='rgb(255, 255, 255)',\n                showbackground=True,\n                title='Population',\n                backgroundcolor='rgb(230, 230,230)'\n            ),\n            zaxis=dict(\n                gridcolor='rgb(255, 255, 255)',\n                zerolinecolor='rgb(255, 255, 255)',\n                showbackground=True,\n                title='Surface Area',\n                backgroundcolor='rgb(230, 230,230)'\n            ),\n            aspectratio = dict( x=1, y=1, z=0.7 ),\n            aspectmode = 'manual'        \n        ),\n    )\n\n    fig = dict(data=data, layout=layout)\n    iplot(fig, filename='total_surface_population_plot', validate=False)\n","6ee3a7bb":"Plot3dClustering(n=2, X=X , type_c='kmeans')","2c2fa9c0":"cluster1 = pd.DataFrame(d[ X['kmeans'] == 1 ]['Area'])\ncluster1","062a9752":"clust_labels, cent = K_Means(X, 3)\nkmeans = pd.DataFrame(clust_labels)\ndel X['kmeans']\nX.insert((X.shape[1]),'kmeans',kmeans)\nPlot3dClustering(n=3, X=X, type_c='kmeans')","a76d423d":"cluster2 = pd.DataFrame(d[ X['kmeans'] == 2 ]['Area'])\ncluster2","aa4a6d1a":"new_d = d.drop(d[d.Total > 1e7].index)\nnew_d = new_d.drop(new_d[new_d.Surface > 5e5].index)\nnew_d = new_d.drop(new_d[new_d.Population > 5e5].index)\nX_f = pd.DataFrame({'Total': new_d['Total'], 'Surface' : new_d['Surface'], 'Population' : new_d['Population']})","f3d3f8eb":"clust_labels, cent = K_Means(X_f, 2)\nkmeans = pd.DataFrame(clust_labels)\nX_f.insert((X_f.shape[1]),'kmeans',kmeans)","dae4f4d2":"Plot3dClustering(n=2,X=X_f, type_c='kmeans')","eebe13d7":"cluster1 = pd.DataFrame(new_d[ X_f['kmeans'] == 1 ]['Area'])\ncluster1.head()","dfb5d3c8":"cluster2 = pd.DataFrame(new_d[ X_f['kmeans'] == 0 ]['Area'])\ncluster2","bddf007c":"def Agglomerative(X, n): #number of clusters is not necessary but Python provides an option of providing the same for easy and simple use.\n    scaler = StandardScaler()\n    X = scaler.fit_transform(X)\n    model = AgglomerativeClustering(n_clusters=n, affinity = 'euclidean', linkage = 'ward')\n    clust_labels1 = model.fit_predict(X)\n    return (clust_labels1)","94780a2b":"clust_labels1 = Agglomerative(X, 2)\nagglomerative = pd.DataFrame(clust_labels1)\nX.insert((X.shape[1]),'agglomerative',agglomerative)\nPlot3dClustering(n=3, X=X, type_c='agglomerative')","3e3c665d":"cluster0 = pd.DataFrame(d[ X['agglomerative'] == 0 ]['Area'])\ncluster0","12c7822b":"plt.figure(figsize=(25, 15))\nplt.title(\"Customer Dendograms\")\ndend = shc.dendrogram(shc.linkage(X, method='ward'))","e89cc3ed":"# K-MEANS CLUSTERING\nK-Means clustering is one of the simplest and most commonly used clustering algorithms.\nIt tries to find cluster centers that are representative of certain regions of the\ndata. The algorithm alternates between two steps: assigning each data point to the\nclosest cluster center, and then setting each cluster center as the mean of the data\npoints that are assigned to it. The algorithm is finished when the assignment of\ninstances to clusters no longer changes.\n\nIt's a partitional complete approach, it requires a metric (how to measure distance) and data needs to be normalized. \nThe most common way to measure distances is with sum of squared error: \n\n$$\nSSE = \\sum_{i=0}^n d(x_i, c_j)^2\n$$\n\nK-Means has the advantage that it\u2019s pretty fast, as all we\u2019re really doing is computing the distances between points and group centers. It thus has a linear complexity O(n)","4f6b7a6b":"### DATA FOR CLUSTERING","ae980ac2":"## RANK FOR JUST FOOD OR FEED","6d948338":"### BOXPLOT","be883206":"### CORRELATION OF VARIABLES\nThe correlation matrix is simply a table of correlations. The most common correlation coefficient is Pearson\u2019s correlation coefficient, which compares two interval variables or ratio variables, and it's used in this case.","0aef52d1":"## K-MEANS","6c1beed1":"### FILTERING OUTLIERS \n\n","3f4db549":"### N_CLUSTER = 2","046fad63":"## RANK OF MOST PRODUCED ITEMS","91f97cd4":"## ELBOW METHOD\nIt's possible to find the best value of K on a plot of SSE at varing of number of K, from the graph you choose the value of K for which there is the higher slope in our case K=2","99bbe23c":"## N_CLUSTER = 3","f32dc5f9":"#### COMMENT:\nFrom the calculation appears how Milk is the most produced item in the world from 1960 to 2013, followed by cereals and vegetables, regarding feed intended to animals, Cereals and Maize are the most produced items.\n","e994c790":"### COMMENT\nConsiderng a number of cluster equal to 3 a new cluster comes out represented by green dots. \n\nChina and India still form a single cluster.","f744206d":"# RANKING\n\n","a465c529":"From this graph is possible to visualize missing values represented by yellow lines, only the last two years doesn't contains missing values.","0495faeb":"# DATA CLEANING\n\nDatasets of this kind mostly of the time contains missing values, represented by NaN. \n\nLet's see if there are some missing values on this dataset. Each yellow line represent some missing values, is possible to understand that there are a lot of them, the biggest part are before 1991. \nThis is because in those period (end of cold war) a lot of new countries were born. \n\nAccording to this constraint different ways of proceeding may be taken into consideration, one is to compute analysis only from 1993 where there are a less amount of missing values and computing analisys only for the last 2 decade 1993-2013. \nThe other way is to considering all the years removing from analysis the missing rows and so the missing countries.\nThere is even the possibility to substitute NaN with 0\n\n\nI decide to substitute missing values with 0 in order to make ranking and then considering only the last 20 years for the clustering analysis, due to a less amount of missing values limiting this constraint.\n\nLet's visualize bettere those missing values.","7d79aa1a":"# CLUSTERING\nClustering is an unsupervised learning method used in order to find new groups from data such that intra-cluster distances are minimized and inter-cluster distances are maximised. \nIt doesn't not require any knowledge about the data,\nsimilarly to classification algorithms, clustering algorithms assign (or predict) a number to each data\npoint, indicating which cluster a particular point belongs to.\nThere are two different type of clusering:\n*                                              PARTITIONAL\n*                                              HIERARCHICAL\n\nHierarchical clustering requires only a similarity measure, while partitional clustering requires stronger assumptions such as number of clusters and the initial centers. Hierarchical clustering returns a much more meaningful and subjective division of clusters but partitional clustering results in exactly k clusters. \n\nMost common clustering algorithm are: K-Means, Hierarchical, Density-based (DBSCAN).","0569d8b6":"**Statistical overview of the data**\n\nThe following statistical measures can be seen for each column using the describe-function of DataFrame of the pandas library:\n\n* count: number of samples\n* mean: the mean of this attribute among all samples\n* std: the standard deviation of this attribute\n* min: the minimal value of this attribute\n* 25%: the lower percentile\n* 50%: the median\n* 75%: the upper percentile\n* max: the maximal value of this attribute","d98679c9":"#### COMMENT:\n\nFrom the analysis **China** and **India** results as outlier. They are both big, popolous and producer countries, and they form a single cluster by them self. ","eb2b4be0":"# FOOD ANALYSIS\nIn this kernel I'll provide an overview on FAO dataset. In particular, after a cleaning of the dataset, I'll show the most productive countries and items providing an overview and description of the dataset. I'll also apply clustering algorithms on a subset of the full dataset in order to find if something interesting comes out.","b6a08f92":"### ADDITION OF POPULATION AND SURFACE DIMENSIONS\n\nIn order to make analysis richer I've decided to add to this dataset information about the population and the surface area of each country. \n\nData is taken again from FAO stats website, considering the year of 2013.  \n\nPopulation data is specify as Million of people.\nSurface area instead as 1000 acres.\n\nDatasets are merged with existing dataset considering 'Area' as key.\n","9047ef5b":"Countries shown in the list above represent the one for which there are missing values. \n\nThe biggest part are countries born after the dissolve of Jugoslavia and URSS","a2d26f46":"#### COMMENT:\nThe graph on the left contains only countries producer of Food for humans, is the same as before and this means that Feed production is irrelevant on the total amount. The right graph instead contains only Feed for animals, here is disappeared **India**, probably because the biggest part of Feed is intended for cattle (cows) and those animals are considered sacred there.","21e5b6d2":"Population and Total sum of productive have a correlation value of ** 0.9 **<br>\nThis means that countries that are a lot populous produce a lot of food in order to feed them all.\n\nPopulation and Surface instead have a correlation value of ** 0.4 **<br>\nIs reasonable to unsterstand why they are not correlated\n\nTotal amount of Food and Surface have a correlation value of ** 0.5 **<br>\nNot all the surface of a country is cultivable","ed37be59":"## RANK FOR FOOD AND FEED","9befc5fa":"## OTHER RESULTS\n\n* Appling clustering on Items has come out a distinction between most produced and less produced items.<br>\n  Most produced items are: **Cereals, Fruits, Milk, Rice, Starchy Roots, Vegetables, Wheat**\n\n\n* Appling clustering on **Italy**'s Items emerge: **Milk** is the most produced Item (forming a cluster alone by itself)<br> Followed by **Vegetables, Cereals, Fruits, Meat, Alcoholic Beverages and Wine** \n\n\n* Considering all years (Y1993-Y2013) instead of Total results does not change.\n ","f31252c1":"# HIERARCHICAL CLUSTERING\n\nAlso known as Agglomerative clustering, does not require the user to specify the number of clusters.\nInitially, each point is considered as a separate cluster, then it recursively clusters the points together depending upon the distance between them. The points are clustered in such a way that the distance between points within a cluster is minimum and distance between the cluster is maximum. Commonly used distance measures are Euclidean distance, Manhattan distance or Mahalanobis distance. Unlike k-means clustering, it is \"bottom-up\" approach, because starting from the leaves and combining clusters up to the trunk.\n\n\nThe approach in small words: \n*  Start with each point in its own cluster.\n* Identify the closest two clusters and merge them. \u2022 Repeat.\n* Ends when all points are in a single cluster.\n\n![](https:\/\/www.statisticshowto.datasciencecentral.com\/wp-content\/uploads\/2016\/11\/clustergram.png)","f004a3e0":"#### COMMENT: \nIt not surprisingly appeared as China is the country with the biggest amount of Food and Feed production, it is the most populous country in the world and also one of the biggest, with over 1 billion people to feed, there are a lot of food to produce. China is followed by USA and India respectively 3rd and 2nd most populous countries. \nIt is logical to think that this rank isn't affected only by the amount of population of a country, but also by GDP, total cultivable area, and geographical position.","c4a6e2f4":"## SHOWING DEVELOPING COUNTRIES ","cc3a751a":"#### COMMENT\n\nFrom boxplot graphs is possible to see that there are some **outliers** that will surely affect the clustering. \n\nIn order to cluster better the Countries a solution could be to cut-off bigger outliers, for example China and India","48c4e5c5":"## DATA PREPARATION\n\nConsidering that initially not all the countries of the world are included in the dataset (due probably to political problems) and considering that there are some missing values for existing countries, I've decided to use only information about the last 20 years avalaible (1993-2013) in order also to simplify the amount of data. Remaining missing values are filled with 0 (Belgium, Luxembourg, Montenegro, Serbia, Sudan)\n\n\nI provide different data structures:  \n\n* COUNTRY - POPULATION - SURFACE - Y1993 ------ Y2013\n* COUNTRY - POPULATION - SURFACE - TOTAL \n* ITEM    - Y1993 ------ Y2013 (world wide)\n* ITEM    - Y1993 ------ Y2013 (for **Italy**)","ae68e476":"# DATA DESCRIPTION\n\nEach row of this dataset contains the amount (values represent 1000 tonnes) of Feed\/Food produced by each country ( 'Area' ) from 1961 to 2013 for a particular Item. \n\nMore metadata are included such as Area Abbreviation, Area\/Item\/Element Code, latitude, longitude, not used in this analysis. \n\nThe dataset is reduced containg only columns: Area, Item, Element, Y1961-Y2013"}}