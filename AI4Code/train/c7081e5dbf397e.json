{"cell_type":{"51e619dd":"code","b1c3c454":"code","20e714ca":"code","567da52a":"code","0a784bf4":"code","2252c33a":"code","e01c47db":"code","c1f99322":"code","548837e4":"code","4450fc00":"code","e8d7d208":"code","4363de98":"code","5205f470":"code","49021b70":"code","143d4726":"code","5624bf4a":"code","e4cd1743":"code","0bd46e29":"code","476fdf74":"code","68c544af":"code","fb5a6e17":"code","1bdff39a":"code","ab8ad5fd":"code","7fd315ef":"code","1cf8cb53":"code","5b4dced5":"code","19243861":"code","830d94f6":"code","54a2d3a2":"code","56e8431d":"code","e6c1dc0c":"code","abf86979":"code","4a8da708":"code","d4c06664":"code","edcefa0d":"code","4988c570":"code","7fca36ef":"code","7396b6e2":"code","2be9beda":"code","e992fdc4":"code","09c06da4":"code","9e444610":"code","58ac5831":"code","f5dae37e":"code","447803c5":"code","146ba20d":"code","e49916e7":"code","31136b67":"code","0bc7bac3":"code","f66c12a9":"code","22be54c3":"code","56d4a59e":"code","fe92b373":"code","b6eec9e8":"code","2659466a":"code","7b424889":"code","6bc4ca8b":"code","a789133a":"code","894afffa":"code","36ddf5d2":"code","2226132d":"code","ee60ec85":"code","a8216cab":"code","64c1189d":"code","c12990ec":"code","5c39e27e":"code","80f86635":"code","a459f297":"code","d4c77eb7":"code","070e6801":"code","5d1e13b7":"code","ed1a3724":"code","d0bec6ce":"code","64fb6c10":"code","2fd79952":"code","1d644adb":"code","97b93b81":"markdown","df956cd1":"markdown","882dd170":"markdown","07163765":"markdown","fa783c9d":"markdown","592e5f41":"markdown","899dbdef":"markdown","59022a23":"markdown","66079579":"markdown","68ebc4e4":"markdown","129ffce9":"markdown","95c37b49":"markdown","4a3dd8e6":"markdown","948c7b12":"markdown","eb74371b":"markdown","178552c5":"markdown","9532f01f":"markdown","0dc29c95":"markdown","7fed4484":"markdown","45d0dc2f":"markdown","e771b159":"markdown","39d0f5ce":"markdown","b7675e59":"markdown","3ed0e233":"markdown"},"source":{"51e619dd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom seaborn import countplot,lineplot, barplot\nimport math\nimport lightgbm as lgb\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom mlxtend.classifier import SoftmaxRegression\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom numpy import argmax\nfrom sklearn.metrics import accuracy_score\nfrom keras.regularizers import l1\nfrom scipy import stats\nfrom keras.layers import Dropout\nimport statistics\nimport os\nimport random\nprint(os.listdir(\"..\/input\"))","b1c3c454":"xtest = pd.read_csv(\"..\/input\/X_test.csv\")\nxtrain = pd.read_csv(\"..\/input\/X_train.csv\")\nytrain = pd.read_csv(\"..\/input\/y_train.csv\")\nssb = pd.read_csv(\"..\/input\/sample_submission.csv\")","20e714ca":"xtest.shape, xtrain.shape, ytrain.shape, ssb.shape","567da52a":"print('Number of surface: {}'.format(ytrain.surface.nunique()))\ncountplot(y = 'surface', data = ytrain)\nplt.show()","0a784bf4":"xtrain.head()","2252c33a":"ytrain.shape","e01c47db":"xtest.head()","c1f99322":"resultant_velocity = (xtrain['angular_velocity_X']**2+\nxtrain['angular_velocity_Y']**2+  \nxtrain['angular_velocity_Z']**2)**.5\nresultant_velocity= pd.DataFrame(resultant_velocity, columns = ['resultant_velocity'])\n#sc_x = StandardScaler()\n#resultant_velocity_n = pd.DataFrame(sc_x.fit_transform(resultant_velocity),columns=resultant_velocity.columns, index=resultant_velocity.index )\n#resultant_velocity_n = np.array(resultant_velocity_n)\nresultant_velocity.shape\nresultant_velocity.head()","548837e4":"resultant_acc = (xtrain['linear_acceleration_X']**2+\nxtrain['linear_acceleration_Y']**2+  \nxtrain['linear_acceleration_Z']**2)**.5\n#resultant_acc= np.transpose(np.matrix(np.array(resultant_acc.T)))\nresultant_acc= pd.DataFrame(resultant_acc, columns = ['resultant_acc'])\n#sc_y = StandardScaler()\n#resultant_acc = pd.DataFrame(sc_x.fit_transform(resultant_acc),columns=resultant_acc.columns, index=resultant_acc.index )\nresultant_acc.head()","4450fc00":"power=resultant_velocity['resultant_velocity']*resultant_acc['resultant_acc']\n#As floor is fuction of friction, To estimate the friction factor differ force eq is required. Power is one of the factor on which friction force depends\npower= pd.DataFrame(power, columns = ['power'])\npower.head()\n#xtrain_new = np.hstack((xtrain,resultant_velocity,resultant_acc,power))","e8d7d208":"#x, y, z, w = xtrain['orientation_X'].tolist(), xtrain['orientation_Y'].tolist(), xtrain['orientation_Z'].tolist(), xtrain['orientation_W'].tolist()\n#t0 = 2*np.multiply(x,y)","4363de98":"#x = xtrain.iloc[:,3].values\n#y = xtrain.iloc[:,4].values\n#z = xtrain.iloc[:,5].values\n#w = xtrain.iloc[:,6].values\n\n#a0 = +2.0 * (np.multiply(w,x) + np.multiply(y , z))\n#a1 = +1.0 - 2.0 * (np.multiply(x , x) + np.multiply(y , y))\n#A = np.arctan2(a0,a1)\n\n#a2 = +2.0 * (np.multiply(w , y) - np.multiply(z , x))\n#B = np.arcsin(a2)\n\n#a3 = +2.0 * (np.multiply(w , z) + np.multiply(x , y))\n#a4 = +1.0 - 2.0 * (np.multiply(y , y) + np.multiply(z , z))\n#C = np.arctan2(a3, a4)\n","5205f470":"#A.shape, B.shape, C.shape","49021b70":"#xtrain['euler_rotation_x'] = A\n#xtrain['euler_rotation_y'] = B\n#xtrain['euler_rotation_z'] = C\n#xtrain['resultant_angle'] = (xtrain['euler_rotation_x'] ** 2 + xtrain['euler_rotation_y'] ** 2 + xtrain['euler_rotation_z'] ** 2)** .5","143d4726":"xtrain_new= pd.concat([xtrain,resultant_velocity, resultant_acc, power], axis=1)\nxtrain_new.shape\nxtrain_new.head()","5624bf4a":"merged = xtrain_new.merge(ytrain, on='series_id')\nmerged.shape","e4cd1743":"merged.head()","0bd46e29":"y =merged.iloc[:,16:18].values","476fdf74":"#y = pd.DataFrame(y)\n#y.head()","68c544af":"labelencoder = LabelEncoder()\ny[:,1] = labelencoder.fit_transform(y[:, 1])\n#y.shape\nonehotencoder = OneHotEncoder(categorical_features = [1])\ny = onehotencoder.fit_transform(y).toarray()\n#y = onehotencoder.fit_transform(ytrain).toarray()\n#Y_Train_f = Y_Train_f[:, 1:]","fb5a6e17":"y_train = y[:,0:9]\ny_train.shape\ny_Train = pd.DataFrame(y_train)\ny_Train.head()","1bdff39a":"y_train.shape","ab8ad5fd":"x = xtrain_new.iloc[:,3:16]\nx.shape","7fd315ef":"X = pd.DataFrame(x)\nX.head()","1cf8cb53":"sc = StandardScaler()\nx = sc.fit_transform(x)\nx=pd.DataFrame(x)\nx.head()","5b4dced5":"ytrain_new = xtrain_new.groupby('series_id')['power','resultant_velocity','resultant_acc'].mean()\nytrain_new = pd.DataFrame(ytrain_new).reset_index()\nytrain_new.columns = ['serie_id','avg_power','avg_velocity','avg_acc']\nytrain_new['surface'] = ytrain.surface\nytrain_new['group_id'] = ytrain.group_id","19243861":"f, axes = plt.subplots(figsize=(10, 5))\nsns.boxplot(x='surface',y='avg_power',data=ytrain_new, ax=axes)\nplt.title('avg_power vs surface')","830d94f6":"f, axes = plt.subplots(figsize=(10, 5))\nsns.boxplot(x='surface',y='avg_acc',data=ytrain_new, ax=axes)\nplt.title('avg_acc vs surface')","54a2d3a2":"# Plot power vs velocity\nf, axes = plt.subplots(figsize=(10, 5))\nsns.lineplot(data=ytrain_new, x='avg_acc', y='avg_power', hue='surface',ax=axes)\nplt.show()","56e8431d":"f, axes = plt.subplots(figsize=(10, 5))\nsns.lineplot(data=ytrain_new, x='avg_velocity', y='avg_power', hue='surface',ax=axes)","e6c1dc0c":"f, axes = plt.subplots(figsize=(10, 5))\nsns.lineplot(data=ytrain_new, x='avg_velocity', y='avg_acc', hue='surface',ax=axes)","abf86979":"f, axes = plt.subplots(figsize=(10, 5))\nsns.boxplot(x='surface',y='avg_power',data=ytrain_new, ax=axes)\nplt.title('avg_power vs surface')","4a8da708":"X_train, X_test, Y_train, Y_test = train_test_split(x, y_train, test_size = 0.3, random_state = 0)","d4c06664":"Y_Test = pd.DataFrame(Y_test)\nY_Test.head()","edcefa0d":"Y_TEST = Y_Test.idxmax(axis=1)\nY_TEST.head()","4988c570":"random.seed(30)","7fca36ef":"    #initializing ANN\nclassifier = Sequential()\n\n    # Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim = 20, init = 'uniform', activation = 'relu', input_dim = 13 ))\n\n    # Adding the second hidden layer\nclassifier.add(Dense(output_dim = 20, init = 'uniform', activation = 'tanh',))\n\n#classifier.add(Dropout(0.2))\n\n    # Adding the third hidden layer\nclassifier.add(Dense(output_dim = 20, init = 'uniform', activation = 'tanh'))\n\n#classifier.add(Dropout(0.2))\n\n    # Adding the output layer\nclassifier.add(Dense(output_dim = 9, init = 'uniform', activation = 'softmax'))\n\n    # Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    \nclassifier.fit(X_train, Y_train, batch_size = 50, nb_epoch = 25)","7396b6e2":"y_pred = classifier.predict(X_test, verbose=True)\ny_pred =pd.DataFrame(y_pred)","2be9beda":"y_Pred = y_pred.idxmax(axis=1)\ny_Pred.head()","e992fdc4":"print(\"Accuracy in Test set=\",accuracy_score(Y_TEST, y_Pred))","09c06da4":"resultant_velocity1 = (xtest['angular_velocity_X']**2+ xtest['angular_velocity_Y']**2+ xtest['angular_velocity_Z']**2)**.5\nresultant_velocity1= pd.DataFrame(resultant_velocity1, columns = ['resultant_velocity1'])\nresultant_acc1 = (xtest['linear_acceleration_X']**2+\nxtest['linear_acceleration_Y']**2+  \nxtest['linear_acceleration_Z']**2)**.5\n#resultant_acc= np.transpose(np.matrix(np.array(resultant_acc.T)))\nresultant_acc1= pd.DataFrame(resultant_acc1, columns = ['resultant_acc1'])\npower1=resultant_velocity1['resultant_velocity1']*resultant_acc1['resultant_acc1']\n#As floor is fuction of friction, To estimate the friction factor differ force eq is required. Power is one of the factor on which friction force depends\npower1= pd.DataFrame(power1, columns = ['power1'])\n","9e444610":"resultant_velocity1.head()","58ac5831":"resultant_acc1.head()","f5dae37e":"power1.head()","447803c5":"#xt = xtest.iloc[:,3].values\n#yt = xtest.iloc[:,4].values\n#zt = xtest.iloc[:,5].values\n#wt = xtest.iloc[:,6].values\n\n#b0 = +2.0 * (np.multiply(wt,xt) + np.multiply(yt , zt))\n#b1 = +1.0 - 2.0 * (np.multiply(xt , xt) + np.multiply(yt , yt))\n#b1.shape\n#Xt = np.arctan2(b0,b1)\n\n#b2 = +2.0 * (np.multiply(wt , yt) - np.multiply(zt , xt))\n\n#Yt = np.arcsin(b2)\n\n#b3 = +2.0 * (np.multiply(wt , zt) + np.multiply(xt , yt))\n#b4 = +1.0 - 2.0 * (np.multiply(yt , yt) + np.multiply(zt , zt))\n#Zt = np.arctan2(b3, b4)","146ba20d":"#Xt.shape, Yt.shape, Zt.shape","e49916e7":"#xtest['euler_rotation_x'] = Xt\n#xtest['euler_rotation_y'] = Yt\n#xtest['euler_rotation_z'] = Zt  \n#xtest['resultant_angle'] = (xtest['euler_rotation_x'] ** 2 + xtest['euler_rotation_y'] ** 2 + xtest['euler_rotation_z'] ** 2) ** .5","31136b67":"xtest_new= pd.concat([xtest,resultant_velocity1, resultant_acc1, power1], axis=1)\nx3 = xtest_new\nxtest_new.head()\n\n","0bc7bac3":"x3.head()","f66c12a9":"xtest_new = xtest_new.iloc[:, 3:16]\nxtest_new = pd.DataFrame(xtest_new)\nxtest_new.head()","22be54c3":"xtest_new.shape","56d4a59e":"#xtest_new = xtest_new.groupby('series_id')['orientation_X','orientation_Y','orientation_Z','orientation_W', 'linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z', 'angular_velocity_X','angular_velocity_Y','angular_velocity_Z','resultant_velocity1','resultant_acc1','power1',].mean()\n#xtest_new.head()\n#xtest_new.shape","fe92b373":"sc = StandardScaler()\nxtest_new = sc.fit_transform(xtest_new)\nxtest_new= pd.DataFrame(xtest_new)\nxtest_new.head()\n","b6eec9e8":"Y_test_final = classifier.predict(xtest_new)\nY_test_final=pd.DataFrame(Y_test_final)\nY_test_final.head()","2659466a":"Y_test_final.shape","7b424889":"Y_test_final.columns = ['carpet','concrete','fine_concrete','hard_tiles', 'hard_tiles_large_space', 'soft_pvc', 'soft_tiles','tiled','wood']","6bc4ca8b":"Y_test_final.head()","a789133a":"Y_test_final.shape","894afffa":"Y_test_final = Y_test_final.idxmax(axis=1)\nY_test_final.head()","36ddf5d2":"Y_test_final= pd.DataFrame(Y_test_final, columns = ['surface'])\nY_test_final.head()","2226132d":"seriesid_f = x3.iloc[:,1]\nseriesid_f.head()","ee60ec85":"seriesid_f= pd.DataFrame(seriesid_f, columns = ['series_id'])\nseriesid_f.head()","a8216cab":"Y_test_final1 = pd.concat([seriesid_f, Y_test_final], axis=1)\nY_test_final1.head()","64c1189d":"Y_test_final1.shape","c12990ec":"#Y_test_final3 = Y_test_final1.pivot_table(values=[\"surface\"], index=[\"series_id\"], aggfunc=pd.mode)\nY_test_final3 = Y_test_final1.pivot_table(values=[\"surface\"],\n                                   index=[\"series_id\"],\n                                   aggfunc=lambda x: x.mode().iat[0])\n","5c39e27e":"Y_test_final3.shape","80f86635":"Y_test_final3.head()","a459f297":"#Y_test_final4= Y_test_final3.iloc[:,0]\n","d4c77eb7":"#Y_test_final2 = Y_test_final1.groupby('series_id')['surface'].mode\n#Y_test_final2.head()","070e6801":"#Y_test_final = Y_test_final.iloc[:, [1,17,18,19,20,21,22,23,24,25] ].values","5d1e13b7":"#Y_test_final.head()","ed1a3724":"#Y_test_final = Y_test_final.groupby('series_id')['surface'].mode()\n","d0bec6ce":"#Y_test_final.columns = ['carpet','concrete','fine_concrete','hard_tiles', 'hard_tiles_large_space', 'soft_pvc', 'soft_tiles','tiled','wood']","64fb6c10":"#Y_test_final = Y_test_final.idxmax(axis=1)\n#Y_test_final.head()","2fd79952":"#Y_test_final = pd.DataFrame(Y_test_final, columns = ['surface'])\n#Y_test_final = Y_test_final.reset_index()\n#Y_test_final.columns[0] = 'series_id'\n#Y_test_final['series_id'] = Y_test_final.index\n#Y_test_final.head()","1d644adb":"Y_test_final3.to_csv(\"prediction.csv\", index = True, index_label = 'series_id')","97b93b81":"**Creating labelencoder matrix of our outcomes of training sample**","df956cd1":"To select our model, we will first start obseving relaion between our different inputs.\nCheck the behaviour of power w.r.t different surface","882dd170":"From the chart we found that hard_tiles has very less number of dataset which might effect out our model prediction on hard_tiles observation. To develop better model it suggested to gather more data for Hard_tile floor. On the other hand cocrete contains the maximum dataset which results better prediction on concrete. As the difference between the dataset of concrete and hard_tile is very high it can lead us under fitting the resul on hard_tile and overfitting the result on concrete ","07163765":"**Normalising our generated Training data set**","fa783c9d":"Extracting type of floor from our created matrix","592e5f41":"As we know robot is free to move in all 3 direction and final movement velocity depends on resultant velocity of robot. \nW = Wx+Wy+Wz\nTo increase the accuracy of our model first we will list down all the required parameter that will affect robot movement","899dbdef":"**Read the Data**","59022a23":"From the plot we found that its difficult to distinguish between different surface on the basis of power, similary we will see the relation between different independent variable\n","66079579":"**Check our imported dataset**","68ebc4e4":"**Results** - \n\n***Accuracy on Train dataset = 96%***\n\n***Accuracy on Test dataset = 86%***\n","129ffce9":"Resultant acceleration = sq.root(Ax^2+Ay^2+Az^2)","95c37b49":"As we see its not possible to identify the surface from any single parameter.\nWe will use all the identified parameter and built a ANN model to identify the surface","4a3dd8e6":"We spilt our test into training and test in the ratio of 60 to 40. To avoid under fitting problem we divide our data set (60:40). As we need more test set to verify our result","948c7b12":"**Combine calculated parameter in a matrix**","eb74371b":"We built our model with folowing confrigation-\n\nHidden layer = 4\n\nBy heat and trial method we founnd that maximum for accuracy occured with folowing activation function\n\nFirst Layer - relu\nSecond layer - tanh\nThird Layer - tanh\n\nAs we have multiple outputs (9 surfaces) we used the softmax function in the output layer\n\nWe need an optimize epoch size, if epoch size is less then it create underfitting problem and if epoch size is high it consume high processing power and create overfitting problem.\nreverse is valid as for batch size","178552c5":"**Predict our result over created test sample**","9532f01f":"**Check our imported test data**","0dc29c95":"For robot, Difference between different floor is fiction provided by different floor. All 9 floor mentioned in problem statement has different frictional resistance.\n\n**Friction:**  \n\u2022 The resistance between two surfaces when attempting to slide one object across the other.  \n\u2022 Friction is due to interactions at molecular level where \u201crough edges\u201d bond together:\n\u2022 Friction is always opposite to the direction of motion\nAs the robot overcome the friction force by its internal power. Power is a fuction of mass, acceleration and velocity of moving object. Hence we consider power as one of factor for our model\n\n\n","7fed4484":"From the data set we found that train sample result is given on the basis of series_id. To increase the training sample we expand our result as per out training dataset","45d0dc2f":"**Check the different type of floor present**","e771b159":"**Creating dataset for to predict result on test set**","39d0f5ce":"![](http:\/\/)![](http:\/\/)Importing the required library","b7675e59":"**Check the shape of our test set result**","3ed0e233":"![](http:\/\/)![](http:\/\/)**Check the shape of imported data**"}}