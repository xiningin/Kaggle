{"cell_type":{"9566570f":"code","2f9ec199":"code","d3df0383":"code","fc933b13":"code","c01fcfae":"code","7d58cd56":"code","04bfd50a":"code","a3145146":"code","79b6f19b":"code","9a61f0ea":"code","9f0ec586":"code","4633e5dc":"code","f0ae5e65":"code","8cbaa6e8":"code","a1d3a775":"code","94d1996e":"code","1dbe6b92":"code","541382d0":"code","05d4515f":"code","36c7468d":"code","7189f56c":"code","2d4e91d2":"code","65f9d231":"code","9a7353a5":"code","a40f67af":"code","6a3205d8":"code","7e94aaf8":"markdown","49bfae40":"markdown","0b21d693":"markdown","798ec73a":"markdown","d392a40d":"markdown","0b14a709":"markdown","73d6f3b0":"markdown","d6675003":"markdown","3360715b":"markdown","93495808":"markdown"},"source":{"9566570f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport seaborn as sns\nimport os\nimport glob as gb\nimport random\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Flatten, Dense, Dropout\nfrom zipfile import ZipFile\nimport matplotlib.image as mpimg\nimport warnings\n\nsns.set()\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")","2f9ec199":"ZipFile(\"\/kaggle\/input\/dogs-vs-cats\/train.zip\",\"r\").extractall()\nZipFile(\"\/kaggle\/input\/dogs-vs-cats\/test1.zip\", \"r\").extractall()","d3df0383":"train_path = \".\/train\"\ntest_path = \".\/test1\"","fc933b13":"filenames = os.listdir(train_path)\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(category)\n    else:\n        categories.append(category)\n\ndf = pd.DataFrame({\n    'Image': filenames,\n    'Category': categories})\ndf.head(-5)","c01fcfae":"df['Category'].value_counts().plot.bar()","7d58cd56":"df_train, df_validation = train_test_split(df, test_size=0.1, random_state=18)\ndf_train = df_train.reset_index(drop=True)\ndf_validation = df_validation.reset_index(drop=True)\ndf_train['Category'].value_counts().plot.bar()\nplt.show()\ndf_validation['Category'].value_counts().plot.bar()","04bfd50a":"sample = random.choice(df['Image'])\nplt.imshow(plt.imread((\".\/train\/\"+sample)))","a3145146":"size  = 150\nchannels = 3\nbatch = 128\nepochs = 50","79b6f19b":"datagen = ImageDataGenerator(rescale=1.\/255,\n                             zoom_range=0.2,\n                             width_shift_range=.2, height_shift_range=.2,\n                             rotation_range=30,\n                             brightness_range=[0.8, 1.2],\n                             horizontal_flip=True)\n\ndatagenValidation = ImageDataGenerator(rescale=1.\/255)","9a61f0ea":"X_train = datagen.flow_from_dataframe(\n    df_train, \n    directory = train_path, \n    x_col = 'Image',\n    y_col = 'Category',\n    target_size= (size,size),\n    class_mode = 'binary',\n    shuffle = True,\n    batch_size = batch)\n\nX_validation = datagenValidation.flow_from_dataframe(\n    df_validation, \n    directory = train_path, \n    x_col = 'Image',\n    y_col = 'Category',\n    target_size= (size,size),\n    class_mode = 'binary',\n    shuffle = True,\n    batch_size = batch)","9f0ec586":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in X_train:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\n# plt.tight_layout()\nplt.show()","4633e5dc":"checkpoint_filepath = 'best_model.hdf5'\n\ncallback_checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False, monitor='val_accuracy', mode='max', save_best_only=True)\ncallback_learningrate = ReduceLROnPlateau(monitor='val_accuracy', mode='max', min_delta=0.03, patience=3, factor=.5, min_lr=0.00001, verbose=1)\n\ncallbacks = [callback_checkpoint, callback_learningrate]","f0ae5e65":"Model = Sequential([Conv2D(filters=32,  kernel_size=(3,3), activation=\"relu\", input_shape=(size,size,channels)),\n                    BatchNormalization(),\n                    MaxPool2D(2,2),\n                    Dropout(0.2),\n                 \n                    Conv2D(filters=64,  kernel_size=(5,5), activation=\"relu\"),\n                    BatchNormalization(),\n                    MaxPool2D(3,3),\n                    Dropout(0.2),\n                \n                    Conv2D(filters=128, kernel_size=(7,7), activation=\"relu\"),\n                    BatchNormalization(),\n                    MaxPool2D(4,4),\n                    Dropout(0.2),\n                 \n                    Flatten(),\n                    \n                    Dense(units=4096, activation=\"relu\"),                 \n                    BatchNormalization(),\n                    Dropout(0.4),\n                    \n                    Dense(units=1024, activation=\"relu\"),\n                    BatchNormalization(),\n                    Dropout(0.3),\n                    \n                                        \n                    Dense(units=2, activation=\"relu\"),\n                    BatchNormalization(),\n                    Dropout(0.5),\n                    \n                    Dense(units=1, activation=\"sigmoid\"),\n])\n\n\nModel.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\nModel.summary()","8cbaa6e8":"history = Model.fit(X_train, validation_data=X_validation, epochs=epochs, callbacks=callbacks)","a1d3a775":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","94d1996e":"Model = tf.keras.models.load_model('best_model.hdf5')","1dbe6b92":"filenames = os.listdir(test_path)\ndf_test = pd.DataFrame({'Image':filenames})\n\ndf_test.head(-5)","541382d0":"X_test = datagenValidation.flow_from_dataframe(\n    df_test, \n    directory=test_path, \n    x_col='Image',\n    y_col=None,\n    class_mode=None,\n    target_size= (size,size),\n    batch_size=batch,\n    shuffle=False\n)","05d4515f":"X_train.class_indices","36c7468d":"y_pred = Model.predict(X_test)","7189f56c":"y_pred = np.where(y_pred > .5, \"Dog\", \"Cat\")\ny_pred","2d4e91d2":"plt.figure(figsize=(15,15))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    plt.imshow(X_test[0][i])\n    plt.xlabel(y_pred[i])\n    \nplt.show()","65f9d231":"label = np.where(y_pred==\"Cat\", 0, 1)\nlabel","9a7353a5":"df_submission = pd.read_csv('..\/input\/dogs-vs-cats\/sampleSubmission.csv')\ndf_submission['label'] = label\ndf_submission.head(-5)","a40f67af":"df_submission.to_csv('submission.csv', index=False)","6a3205d8":"submission = pd.read_csv('.\/submission.csv')\nsubmission.head(-5)","7e94aaf8":"# 5- Setup Callbacks","49bfae40":"# 4- Data Augmentation\nLet's make augmentation on training data and only scaling validation and test data.","0b21d693":"# 9- Let's submit","798ec73a":"# 2- Prepare Data\nImport **train** and **test** data as dataframes by extracting images from zip files and add images names in dataframe.","d392a40d":"# 3- Setup Variables\nDefine the size of image and its channel, batch size  and the number of epochs.","0b14a709":"# 6- Design the Neural Network","73d6f3b0":"# 7- Let's train","d6675003":"Let's check our images.","3360715b":"# 8- Let's predict","93495808":"# 1- Hello Friends\n\nHello Future Engineers, Nice to meet you!\n\nFirst we import our libraries that will we need."}}