{"cell_type":{"be0187a5":"code","ffb413a1":"code","41b8d588":"code","deb26751":"code","b9bbe040":"code","2489468f":"code","67e5d713":"code","1af53a5b":"code","1bb97784":"code","606ef1e9":"code","4dd3c703":"code","d2019fbe":"code","ff20a444":"code","410b685e":"markdown","e8e3d342":"markdown","876ec10c":"markdown","d7754827":"markdown","e74710c7":"markdown","008b01ed":"markdown"},"source":{"be0187a5":"!pip install segmentation_models_pytorch\n!git clone https:\/\/github.com\/Bjarten\/early-stopping-pytorch.git\n!mv .\/early-stopping-pytorch .\/lib","ffb413a1":"import torch, torchvision\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nimport random\nimport os \nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n\nimport math\nimport sys\nimport cv2\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as mpplot\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\n\nimport segmentation_models_pytorch as smp\nfrom lib.pytorchtools import *\n\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\ntorch.backends.cudnn.deterministic = True","41b8d588":"path = \"\/kaggle\/input\/ultrasound-nerve-segmentation\/\"\n\ntrain_path = os.path.join(path, \"train\")\ntest_path = os.path.join(path, \"test\")\n\nmasks = [os.path.join(train_path,i) for i in os.listdir(train_path) if \"mask\" in i]\nimgs = [i.replace(\"_mask\",\"\") for i in masks]\n\ndf = pd.DataFrame({\"images\":imgs,\"masks\":masks})\n\ntrain_df, val_df = train_test_split(df,test_size = 0.20)\n\ntrain_df.head()","deb26751":"class Dataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.images = df.images.tolist()\n        self.masks = df.masks.tolist()\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n            \n        image_name = self.images[idx]\n        mask_name = self.masks[idx]\n       \n        image = Image.open(image_name)\n        mask = Image.open(mask_name)  \n    \n        if self.transform:\n            image = self.transform(image)\n            mask = self.transform(mask)\n    \n        return image, mask","b9bbe040":"data_transforms = transforms.Compose([\n    transforms.Resize(size=(224, 224)),\n    transforms.ToTensor()\n])\n\nbatch_size = 16\n\ntrain_dataset = Dataset(train_df, data_transforms)\nval_dataset = Dataset(val_df, data_transforms)\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\n\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint('train', len(train_dataloader), len(train_dataset))\nprint('val', len(val_dataloader), len(val_dataset))","2489468f":"def show_input(data, n):\n    fig = plt.figure(figsize=(5, 5))\n        \n    for i in range(1, n + 1):\n        img_ax = fig.add_subplot(2, n, i)\n        msk_ax = fig.add_subplot(2, n, i + n)\n        \n        image = data[i-1][0].permute(1, 2, 0).numpy()\n        mask = data[i-1][1].permute(1, 2, 0).numpy()\n        \n        img_ax.imshow(image, cmap='gray')\n        msk_ax.imshow(mask, cmap='gray')\n        \n    fig.show()\n\nshow_input(train_dataset, 5)","67e5d713":"model = smp.Unet(\n    encoder_name='resnet34',\n    encoder_weights='imagenet',\n    in_channels=1,\n    classes=1,\n    activation='sigmoid'\n)\n\nloss = smp.utils.losses.DiceLoss()\nmetrics = [smp.utils.metrics.IoU()]\n\nlearning_rate = 0.001\nepochs = 50\n\nstopper = EarlyStopping(patience=3)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n\nloss_function = smp.utils.losses.DiceLoss()\n\ntrain_epoch = smp.utils.train.TrainEpoch(model,\n                                          loss=loss_function,\n                                          optimizer=optimizer,\n                                          metrics=metrics,\n                                          device=device,\n                                          verbose=True)\nval_epoch = smp.utils.train.ValidEpoch(model,\n                                          loss=loss_function,\n                                          metrics=metrics,\n                                          device=device,\n                                          verbose=True)","1af53a5b":"model.to(device)\ntrain_loss_history = []\nval_loss_history= []\n\ntrain_iou_history = []\nval_iou_history = []\n\nfor epoch in range(epochs):\n    print('\\nEpoch: {}'.format(epoch))\n    train_log = train_epoch.run(train_dataloader)\n    val_log = val_epoch.run(val_dataloader)\n\n    scheduler.step()\n\n    train_loss_history.append(train_log[loss_function.__name__])\n    val_loss_history.append(val_log[loss_function.__name__])\n\n    train_iou_history.append(train_log['iou_score']) \n    val_iou_history.append(val_log['iou_score'])\n\n    stopper(val_log[loss_function.__name__], model)\n    if stopper.early_stop:\n        break","1bb97784":"def visualize_train(train, val, title):\n    plt.plot(range(len(train)), train, label = 'Train')\n    plt.plot(range(len(val)), val, label = 'Val')\n    \n    plt.ylabel(title)\n    plt.xlabel('epoch')\n    \n    plt.legend(title)\n    plt.show()","606ef1e9":"visualize_train(train_loss_history, val_loss_history, 'Loss')","4dd3c703":"visualize_train(train_iou_history, val_iou_history, 'IoU')","d2019fbe":"def rle_encoding(x):\n    dots = np.where(x.T.flatten()==1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b+1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths","ff20a444":"imgs = [f for f in os.listdir(test_path)]\nimgs = sorted( imgs, key=lambda s: int(s.split('.')[0]))\n\nsubmission_df = pd.DataFrame(columns=['img', 'pixels'])\nmodel.to(device)\nmodel.eval()\n\nfor i, img in enumerate(tqdm(imgs)):\n    x = Image.open(os.path.join(test_path, img))\n\n    x = data_transforms(x)\n\n    x = x.unsqueeze(0).to(device)\n    prediction = model.predict(x)\n\n    prediction = prediction.cpu()\n    prediction = transforms.Resize(size=(420, 580))(prediction)\n\n    encoding = rle_encoding(prediction)\n\n    pixels = ' '.join(map(str, encoding))\n    submission_df.loc[i] = [str(i+1), pixels]\n\nsubmission_df.to_csv('submission.csv', index=False)","410b685e":"### Vizualize","e8e3d342":"### Imports","876ec10c":"### Model","d7754827":"### Dataset","e74710c7":"### Installs","008b01ed":"### Train"}}