{"cell_type":{"d65bb70d":"code","0d3b3999":"code","6027a0d9":"code","34e38c76":"code","d1181cb6":"code","0b9079d2":"code","13333514":"code","9d1bb420":"code","2cb6fdf4":"code","9e61e894":"code","5e28a388":"code","2ee73eac":"code","80e02e05":"code","caf2c60d":"code","9817980d":"code","c610bece":"code","e794c41e":"code","5d9a4429":"code","ac44b8d1":"code","28f501c6":"code","6100cd9f":"code","7dd74ef5":"code","de431cdb":"code","374caf58":"code","90c50b7d":"markdown","366babd5":"markdown","c069b168":"markdown","3b224bce":"markdown","e108c36b":"markdown","687b908a":"markdown","17a7e3eb":"markdown","6e24db14":"markdown"},"source":{"d65bb70d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0d3b3999":"data = pd.read_csv(\"\/kaggle\/input\/did-it-rain-in-seattle-19482017\/seattleWeather_1948-2017.csv\")","6027a0d9":"data.head(20)\n","34e38c76":"data.info()","d1181cb6":"index_nan = list(data[\"PRCP\"][data[\"PRCP\"].isnull()].index)\ndata.drop(index_nan,inplace=True)","0b9079d2":"date = data.DATE","13333514":"T = data[data[\"RAIN\"] == True]\nF = data[data[\"RAIN\"] == False]","9d1bb420":"data[\"RAIN\"] = [1 if i==True else 0 for i in data[\"RAIN\"] ]","2cb6fdf4":"data.head()","9e61e894":"y = data.RAIN.values","5e28a388":"x_data = data.drop([\"RAIN\"],axis=1,inplace=True)\nx_data = data.drop([\"DATE\"],axis=1)\n","2ee73eac":"x = ((x_data - np.min(x_data) )\/(np.max(x_data)-np.min(x_data)))","80e02e05":"from sklearn.model_selection import train_test_split\nx_train , x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=2)","caf2c60d":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train,y_train)\ny_predictknn = knn.predict(x_test)\nprint(\"acc = \", knn.score(x_test,y_test))\n\nsupervised =[\"KNN\"]\nscore=[knn.score(x_test,y_test)]","9817980d":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test,y_predictknn)\nimport seaborn as sns\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()\n","c610bece":"from sklearn.svm import SVC\n\nsvm = SVC(random_state=2)\nsvm.fit(x_train,y_train)\ny_predictsvm = svm.predict(x_test)\nprint(\"acc = \", svm.score(x_test,y_test))\n\nsupervised =supervised+[\"SVM\"]\nscore=score+[svm.score(x_test,y_test)]\n","e794c41e":"cm = confusion_matrix(y_test,y_predictsvm)\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","5d9a4429":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\n\nnb.fit(x_train,y_train)\ny_predictnb=nb.predict(x_test)\nprint(\"acc = \", nb.score(x_test,y_test))\nsupervised =supervised+[\"NB\"]\nscore=score+[nb.score(x_test,y_test)]\n","ac44b8d1":"cm = confusion_matrix(y_test,y_predictnb)\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","28f501c6":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\n\ndt.fit(x_train,y_train)\ny_predictdt=dt.predict(x_test)\n\nprint(\"acc = \", dt.score(x_test,y_test))\nsupervised =supervised+[\"Dt\"]\nscore=score+[dt.score(x_test,y_test)]","6100cd9f":"cm = confusion_matrix(y_test,y_predictdt)\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","7dd74ef5":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\n\nrf.fit(x_train,y_train)\ny_predictrf=rf.predict(x_test)\n\nprint(\"acc = \", rf.score(x_test,y_test))\nsupervised =supervised+[\"Rf\"]\nscore=score+[rf.score(x_test,y_test)]","de431cdb":"cm = confusion_matrix(y_test,y_predictrf)\nf , ax = plt.subplots(figsize=(5,5))\n\nsns.heatmap(cm,annot = True,linewidths =0.5,linecolor =\"Red\",fmt=\".0f\",ax=ax)\nplt.xlabel(\"y_pred\")\nplt.ylabel(\"y_true\")\nplt.show()","374caf58":"plt.plot(supervised,score)\nplt.show()","90c50b7d":"<a id=\"7\" >\n## Random Forest ","366babd5":"<a id=\"6\" >\n## Decision Tree Class","c069b168":"<a id =\"1\" >\n# Data Load and Check","3b224bce":"<a id=\"4\" >\n## SVM","e108c36b":"<a id =\"2\">\n    \n# SUPERVISED LEARNING","687b908a":"1. [Data Load and Check](#1)\n2. [Supervised Learning](#2)\n   * [KNN](#3)\n   * [SVM](#4)\n   * [Naive Bayes](#5)\n   * [Decision Tree](#6)\n   * [Random Forest](#7)\n","17a7e3eb":"<a id=\"3\" >\n## KNN","6e24db14":"<a id=\"5\" >\n## Naive Bayes\n "}}