{"cell_type":{"e82f28c5":"code","4afdcb25":"code","d1b14a1e":"code","d16916a0":"code","b0b98a28":"code","36939eb4":"code","55fb63d1":"code","d37a0688":"code","cebaeae6":"code","515b2567":"code","d87dd9ef":"code","0fa6cac3":"code","a41cd9a2":"code","7b62a895":"code","41f514b4":"code","4923f767":"code","06edaf8c":"code","c4029393":"code","b23abe19":"code","a0a79308":"code","b6131b26":"code","dbd289b9":"code","bb510ea6":"code","a976a800":"code","2241997c":"code","9f21956a":"code","9fecaf3c":"code","d8d4353b":"code","f884b6b6":"code","9ee99c8c":"code","7f1b73d0":"code","6ee53748":"code","51a14dc9":"code","58c4cbe0":"code","e31bb0f7":"code","30c7f375":"code","afd739f5":"code","cb61cdb1":"code","5dcabbee":"markdown","892ba5b0":"markdown","a1b6c7c3":"markdown","4623443b":"markdown","925cd6de":"markdown","5fa917a1":"markdown","709ddb75":"markdown","9b8039a3":"markdown"},"source":{"e82f28c5":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import classification_report","4afdcb25":"# Loading data\ndf_train = pd.read_csv('..\/input\/home-credit-engineeredhome-credit-competition\/home_credit_train_engineered.csv')\n\ndf_train.dropna(inplace=True)\n","d1b14a1e":"# Obtaining features\nfeatures = [f for f in df_train.columns if f not in ['Unnamed: 0','TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n","d16916a0":"# Getting train test splits and scaling data\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n\nx_train, x_test, y_train, y_test = train_test_split(\ndf_train[features], df_train['TARGET'], test_size=0.33, random_state=42)\n\nscaler = StandardScaler()\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","b0b98a28":"# Getting undersampled data\nfrom imblearn.under_sampling import RandomUnderSampler\n\nrus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable\nx_u, y_u = rus.fit_resample(x_train, y_train)\n\nprint('Original train set shape:', len(x_train))\nprint('Resample train set shape :', len(x_u))\n","36939eb4":"# Getting oversampled data\n\nfrom imblearn.over_sampling import SMOTE \n\nsm = SMOTE(random_state=42)\n\nx_o, y_o = sm.fit_resample(x_train, y_train)\n\nprint('Original train set shape:', len(x_train))\nprint('Resample train set shape :', len(x_o))\n\n\n\n# print('\\nBalance of positive and negative classes (%):')\n# y_sm.value_counts(normalize=True) * 100","55fb63d1":"# Experimenting with classifiers","d37a0688":"import joblib","cebaeae6":"def normal_classifier(clf,x_train = x_train,y_train = y_train,x_test = x_test,y_test = y_test):\n    \n    print(\"Classification on data from dataset\\n\")\n    clf.fit(x_train,y_train)\n    print(\"\\n\\nTraining report\")\n    train_report = classification_report(y_train,clf.predict(x_train))\n    print(train_report)\n    print(\"\\n\\nTesting report\")\n    test_report = classification_report(y_test,clf.predict(x_test))\n    print(test_report)\n","515b2567":"def undersampled_classifier(clf,x_u = x_u,y_u = y_u,x_test = x_test,y_test = y_test):\n    print(\"Classification on undersampled data\\n\")\n    clf.fit(x_u,y_u)\n    print(\"\\n\\nTraining report\")\n    train_report = classification_report(y_u,clf.predict(x_u))\n    print(train_report)\n    print(\"\\n\\nTesting report\")\n    test_report = classification_report(y_test,clf.predict(x_test))\n    print(test_report)\n","d87dd9ef":"def oversampled_classifier(clf,x_o=x_o,y_=y_o,x_test=x_test,y_test=y_test):\n    print(\"\\n\\n For Oversampled data\\n\")\n    clf.fit(x_o,y_o)\n    print(\"\\n\\nTraining report\")\n    train_report = classification_report(y_o,clf.predict(x_o))\n    print(train_report)\n    print(\"\\n\\nTesting report\")\n    test_report = classification_report(y_test,clf.predict(x_test))\n    print(test_report)\n\n","0fa6cac3":"# LightGBM classifier\nimport lightgbm as ltb\nmodel = ltb.LGBMClassifier()","a41cd9a2":"normal_classifier(model)","7b62a895":"undersampled_classifier(model)","41f514b4":"oversampled_classifier(model)","4923f767":"from sklearn.svm import SVC\nmodel = SVC(gamma='auto')","06edaf8c":"normal_classifier(model)","c4029393":"undersampled_classifier(model)","b23abe19":"oversampled_classifier(model)","a0a79308":"from sklearn import tree\nmodel = tree.DecisionTreeClassifier()","b6131b26":"normal_classifier(model)","dbd289b9":"undersampled_classifier(model)","bb510ea6":"oversampled_classifier(model)","a976a800":"import tensorflow as tf\n# Without sampling\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Input(shape=x_train[0].shape),\n    tf.keras.layers.Dense(100,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(50,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\nmodel.compile(metrics = 'accuracy',optimizer='adam',loss='binary_crossentropy')","2241997c":"history = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=10,verbose = 4)","9f21956a":"c = classification_report(y_train,model.predict_classes(x_train))\nprint(\"\\n\\nTraining\\n\",c)\nc = classification_report(y_test,model.predict_classes(x_test))\nprint(\"Testing\\n\",c)","9fecaf3c":"# With undersampling\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Input(shape=x_u[0].shape),\n    tf.keras.layers.Dense(100,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(50,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\n\n\nmodel.compile(metrics = 'accuracy',optimizer='adam',loss='binary_crossentropy')\nmodel.fit(x_u,y_u,validation_data=(x_test,y_test),epochs=10,verbose = 5)\n \n\n","d8d4353b":"c = classification_report(y_u,model.predict_classes(x_u))\nprint(\"Training\\n\",c)\nc = classification_report(y_test,model.predict_classes(x_test))\nprint(\"Testing\\n\",c)","f884b6b6":"# With oversampling\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Input(shape=x_o[0].shape),\n    tf.keras.layers.Dense(100,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(50,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\n\n\nmodel.compile(metrics = 'accuracy',optimizer='adam',loss='binary_crossentropy')\nmodel.fit(x_o,y_o,validation_data=(x_test,y_test),epochs=10,verbose = 5)\n ","9ee99c8c":"c = classification_report(y_o,model.predict_classes(x_o))\nprint(\"Training\\n\",c)\nc = classification_report(y_test,model.predict_classes(x_test))\nprint(\"Testing\\n\",c)","7f1b73d0":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()","6ee53748":"normal_classifier(model)","51a14dc9":"undersampled_classifier(model)","58c4cbe0":"oversampled_classifier(model)","e31bb0f7":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()","30c7f375":"normal_classifier(model)","afd739f5":"undersampled_classifier(model)","cb61cdb1":"oversampled_classifier(model)","5dcabbee":"# Neural Networks","892ba5b0":"# Decision trees","a1b6c7c3":"# Logistic regression","4623443b":"# Obtaining Undersampled and Oversampled Data","925cd6de":"## Defining necessary functions to maintain DRY code\n#### as much as possible","5fa917a1":"# LightGBM classifier","709ddb75":"# Random Forest","9b8039a3":"# SVM"}}