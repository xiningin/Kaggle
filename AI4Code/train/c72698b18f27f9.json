{"cell_type":{"9a28b229":"code","da8ce2a2":"code","87ab0c91":"code","21d9c915":"code","5ee79a41":"code","1b1edb9e":"code","47a28f6a":"code","5a462afb":"code","40a994de":"code","32385b39":"code","0c199c3f":"code","595ed672":"code","77ef1d62":"code","a5feceec":"code","ad61e163":"code","7bd3e2a0":"code","f27d1727":"markdown","72a7948a":"markdown","b5b9d920":"markdown"},"source":{"9a28b229":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","da8ce2a2":"import seaborn as sns\nimport os\nimport sys\nimport tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pydicom\nimport glob\nimport os\nfrom typing import Dict, List","87ab0c91":"def visualize_one_image(image_files: List[str]) -> None:\n    # Take only the first 12 images in the list for ID00165637202237320314458\n    \n    fig, axes = plt.subplots(4, 3, figsize=(20, 16))\n    axes = axes.flatten()\n    image_index=0\n    for image_file in image_files:\n        # Load the DICOM image and convert to pixel array\n        if 'ID00165637202237320314458' in image_file:\n            image_data = pydicom.read_file(image_file).pixel_array\n            axes[image_index].imshow(image_data, cmap=plt.cm.bone)\n            image_name = '-'.join(image_file.split('\/')[-2:])\n            axes[image_index].set_title(f'{image_name}')\n            image_index+=1\ntrain_image_path = '\/kaggle\/input\/osic-pulmonary-fibrosis-progression\/train'\ntrain_image_files = sorted(glob.glob(os.path.join(train_image_path, '*', '*.dcm')))","21d9c915":"list_files=glob.glob(os.path.join(train_image_path, '*','*.dcm'))\ndf_im=pd.DataFrame()\ndf_im['files']=list_files\ndf_im['folder_name']=df_im['files'].apply(lambda x: x.split('\/')[-2])","5ee79a41":"df_im['folder_name'].value_counts().hist()","1b1edb9e":"df_im['folder_name'].value_counts()","47a28f6a":"visualize_one_image(train_image_files)","5a462afb":"sorted(train_image_files)","40a994de":"import gc\ngc.collect()","32385b39":"import pydicom\nimport os\nimport numpy\nfrom skimage.transform import resize\nIMG_PX_SIZE = 512\n\n\nlstFilesDCM = train_image_files  # create an empty list            \n# Get ref file\nRefDs = pydicom.read_file(lstFilesDCM[0])\n\n# Load dimensions based on the number of rows, columns, and slices (along the Z axis)\nConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(lstFilesDCM))\n\nprint(ConstPixelDims)\n# Load spacing values (in mm)\nConstPixelSpacing = (float(RefDs.PixelSpacing[0]), float(RefDs.PixelSpacing[1]))\n\n# The array is sized based on 'ConstPixelDims'\nArrayDicom = []\n\n# loop through all the DICOM files\nfor index,filenameDCM in tqdm.tqdm(enumerate(lstFilesDCM)):\n    try:\n        # read the filet\n        ds = pydicom.read_file(filenameDCM)\n        img=np.array(ds.pixel_array)\n        # store the raw image data\n        resized_img = resize(img, (IMG_PX_SIZE, IMG_PX_SIZE), anti_aliasing=True,preserve_range=True)\n        ArrayDicom[:, :, lstFilesDCM.index(filenameDCM)] = resized_img\n        del ds,resized_img,img\n    except Exception as e:\n        continue","0c199c3f":"def extract_dicom_meta_data(filename: str) -> Dict:\n    # Load image\n    \n    image_data = pydicom.read_file(filename)\n    img=np.array(image_data.pixel_array).flatten()\n    row = {\n        'Patient': image_data.PatientID,\n        'body_part_examined': image_data.BodyPartExamined,\n        'image_position_patient': image_data.ImagePositionPatient,\n        'image_orientation_patient': image_data.ImageOrientationPatient,\n        'photometric_interpretation': image_data.PhotometricInterpretation,\n        'rows': image_data.Rows,\n        'columns': image_data.Columns,\n        'pixel_spacing': image_data.PixelSpacing,\n        'window_center': image_data.WindowCenter,\n        'window_width': image_data.WindowWidth,\n        'modality': image_data.Modality,\n        'StudyInstanceUID': image_data.StudyInstanceUID,\n        'SeriesInstanceUID': image_data.StudyInstanceUID,\n        'StudyID': image_data.StudyInstanceUID, \n        'SamplesPerPixel': image_data.SamplesPerPixel,\n        'BitsAllocated': image_data.BitsAllocated,\n        'BitsStored': image_data.BitsStored,\n        'HighBit': image_data.HighBit,\n        'PixelRepresentation': image_data.PixelRepresentation,\n        'RescaleIntercept': image_data.RescaleIntercept,\n        'RescaleSlope': image_data.RescaleSlope,\n        'img_min': np.min(img),\n        'img_max': np.max(img),\n        'img_mean': np.mean(img),\n        'img_std': np.std(img)}\n\n    return row","595ed672":"meta_data_df = []\nfor filename in tqdm.tqdm(train_image_files):\n    try:\n        meta_data_df.append(extract_dicom_meta_data(filename))\n    except Exception as e:\n        continue","77ef1d62":"296226","a5feceec":"meta_data_df = pd.DataFrame.from_dict(meta_data_df)\nmeta_data_df.head()","ad61e163":"meta_data_df.to_csv('meta_data.csv',index=False)","7bd3e2a0":"Conclusion:\nOut of 33026 images provides, 296226 images are proper.","f27d1727":"### distribution of images in each folder","72a7948a":"### Load the images and resize the image to 512 x 512 preserving the range\nthis is memory intensive, we can change this to load into batches ","b5b9d920":"### Load the metadata of each file"}}