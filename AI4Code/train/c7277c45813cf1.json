{"cell_type":{"889a4e44":"code","bb1b1e2c":"markdown","1e1c0506":"markdown","3c00b75a":"markdown"},"source":{"889a4e44":"#Cat Boost Classifier\n\nimport catboost\nfrom catboost import CatBoostClassifier, Pool\nimport numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\ntrain['Surname'], test['Surname'] = [df.Name.str.split(',').str[0] for df in [train, test]]\n\ntrain['Title'], test['Title'] = [df.Name.str.split(',').str[1] for df in [train, test]]\n\ntrain['Title'], test['Title'] = [df.Title.str.split('.').str[0] for df in [train, test]]\n\n#print(train)\n\nmodel = catboost.CatBoostClassifier(iterations=100, random_seed=0, verbose=False)\n\npool = Pool(train[['Pclass', 'Sex', 'Embarked', 'Surname', 'Title']].fillna(''),train['Survived'], cat_features=[0,1,2,3,4])\n\nmodel.fit(pool)\n\npredicted = model.predict(test[['Pclass', 'Sex', 'Embarked', 'Surname', 'Title']].fillna('')).astype('int')\n\npd.concat([test['PassengerId'], pd.DataFrame(predicted, columns=['Survived'])], axis=1).to_csv('submission_catboost.csv', index=False)\n","bb1b1e2c":"**It was quite surprising to see the above produce such a high result as follows: -**\n\n![image.png](attachment:ce01f7ed-c8fe-4922-913b-6e161b151dd5.png)\n\nJust for info, here is the training data after the \"mean encoding\" which is a really interesting way of scaling the data so that each category is accorded better prioritisation.  See [here](https:\/\/towardsdatascience.com\/why-you-should-try-mean-encoding-17057262cd0) for some further info.\n\n![image.png](attachment:e71ab5e8-ce3a-46ec-9abe-6fa30925510e.png)","1e1c0506":"Finally, just for info, I fitted a tensorflow Sequential model against the same data above, but could only achieve 0.76 \/ 0.77 on submission.\n\n**THANKS FOR READING**","3c00b75a":"![horizon-ga2709f14a_1920.jpg](attachment:6c5e1a1b-152d-4046-9222-077155b585f2.jpg)\n                                                            \nI have been trying for a long time to actually achieve a good score on Titanic.  Big long notebooks.  Intricate preparation.  No improvement.  Then I saw a post by Pavlo Fesenko - post [here](https:\/\/www.kaggle.com\/pavlofesenko\/simplest-top-10-titanic-0-80861) - on the Catboost classifier.  \n\nThere is some further background [here](https:\/\/medium.com\/nerd-for-tech\/catboost-quickstart-ml-classification-f1d7fb70fea8). \n\nThe catboost classifier produced, with only a few features, a better result than I had managed in a billion years of trying.\n\n(Sunset image by [Maxx Girr](https:\/\/pixabay.com\/users\/maxxgirr-3565425\/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=2679252))"}}