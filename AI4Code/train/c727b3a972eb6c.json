{"cell_type":{"70cbcffa":"code","e1739438":"code","39fc111d":"code","fb60f696":"code","844255dd":"code","fe90b1e1":"code","f958d3ce":"code","4f5469cf":"code","c98fe7f3":"code","8122281e":"code","65336b16":"code","5892b690":"code","447295da":"code","a88f8cee":"code","fd524769":"code","0e6d7284":"code","e7b15b89":"code","5cb65668":"code","6c9987a6":"code","dee7b36f":"markdown","e35c7e3e":"markdown","cc309f5a":"markdown","86c78ecd":"markdown","da8d545d":"markdown"},"source":{"70cbcffa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix,accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tensorflow.python.keras.utils import np_utils\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import BatchNormalization\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e1739438":"df = pd.read_csv(\"..\/input\/heartbeat\/mitbih_test.csv\", header = None, index_col = False)\ndf.head()","39fc111d":"df[187].unique()","fb60f696":"type_a = [\"Non Ectopic beats (Normal beats)\",'Supraventrical ectopic beats',\"Ventricular ectopic beats\",'Fusion beats','Unknown beats']\ndf.loc[df[187] == 0, 'name_match'] = type_a[0]  \ndf.loc[df[187] == 1, 'name_match'] = type_a[1]\ndf.loc[df[187] == 2, 'name_match'] = type_a[2]\ndf.loc[df[187] == 3, 'name_match'] = type_a[3]  \ndf.loc[df[187] == 3, 'name_match'] = type_a[4]  ","844255dd":"df['name_match'].value_counts().plot(kind = 'bar', rot = 75)\nplt.show()\ndf['name_match'].value_counts().plot(kind = 'pie', ylabel = \"\")\nplt.show()","fe90b1e1":"cond = df[187].unique()\ntype_a = [\"Non Ectopic beats (Normal beats)\",'Supraventrical ectopic beats',\"Ventricular ectopic beats\",'Fusion beats','Unknown beats']\nfor a in cond:\n    df1 = df[df[187] == a].head(1)\n    aa = df1.loc[:,0:186].to_numpy()\n    xx = np.arange(0,187)\n    plt.plot(xx,aa[0])\n    plt.title(type_a[int(a)])\n    plt.show()","f958d3ce":"x = df.loc[:,0:186]\ny = df.loc[:,187]","4f5469cf":"# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\nencoded_Y = encoder.transform(y)\n# convert integers to dummy variables (i.e. one hot encoded)\ndummy_y = np_utils.to_categorical(encoded_Y)\ndummy_y","c98fe7f3":"X_train, X_test, y_train, y_test = train_test_split(x,dummy_y, test_size=0.01, random_state=42)","8122281e":"batchnorm_model = Sequential()\n# Add the first layer\nbatchnorm_model.add(Dense(50, activation='sigmoid',input_shape=(187,), kernel_initializer='normal'))\nbatchnorm_model.add(Dense(50, activation='sigmoid', kernel_initializer='normal'))\nbatchnorm_model.add(Dense(50, activation='sigmoid', kernel_initializer='normal'))\nbatchnorm_model.add(Dense(50, activation='sigmoid', kernel_initializer='normal'))\nbatchnorm_model.add(Dense(5, activation='softmax', kernel_initializer='normal'))","65336b16":"# Compile your model with sgd\nbatchnorm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n# Train the batch normalized model you recently built, store its history callback\nh2_callback = batchnorm_model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=10, verbose=0)","5892b690":"preds = batchnorm_model.predict(X_test)\npreds_rounded = np.round(preds)\npreds\naccuracy2 = batchnorm_model.evaluate(X_test, y_test)\naccuracy2[1]","447295da":"batchnorm_model.summary()","a88f8cee":"print(classification_report(np.argmax(y_test, axis=1), np.argmax(preds, axis = 1)))","fd524769":"df1 = pd.read_csv(\"..\/input\/heartbeat\/mitbih_test.csv\", header = None, index_col = False)\nx_test1 = df1.loc[:,0:186]\ny_test1 = df1.loc[:,187]\n\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y_test1)\nencoded_Y = encoder.transform(y_test1)\n# convert integers to dummy variables (i.e. one hot encoded)\ndummy_y_test = np_utils.to_categorical(encoded_Y)\ndummy_y_test","0e6d7284":"accuracy_test = batchnorm_model.evaluate(x_test1, dummy_y_test)\npreds_1 = batchnorm_model.predict(x_test1)\nprint(classification_report(np.argmax(dummy_y_test, axis=1), np.argmax(preds_1, axis = 1)))","e7b15b89":"ch1 = pd.DataFrame(np.rint(preds_1))\nch1.head()\n\nch1.loc[ch1[0] == 1.0 , 'pred'] = 0  \nch1.loc[ch1[1] == 1.0, 'pred'] = 1  \nch1.loc[ch1[2] == 1.0, 'pred'] = 2  \nch1.loc[ch1[3] == 1.0, 'pred'] = 3  \nch1.loc[ch1[4] == 1.0, 'pred'] = 4  \nch1.loc[(ch1[1] == 0) & (ch1[2] == 0) & (ch1[3] == 0) & (ch1[4] == 0), 'pred'] = 0\nch1.pred\n\ndf1_test = pd.concat([df1,ch1['pred']],axis = 1)\n\ndf1_test['compare'] = np.where(df1_test['pred']==df1_test[187], \n                                           'yes', 'no')","5cb65668":"df1_test_1 = df1_test[df1_test[\"compare\"]=='no']\ndf1_test_1.head()","6c9987a6":"for i in range(10):\n    aa = df1_test_1.loc[:,0:186].to_numpy()\n    aa1 = df1_test_1.loc[:,187:'pred'].to_numpy()\n    xx = np.arange(0,187)\n    plt.plot(xx,aa[i])\n    plt.title(\"Actual: {} \/ Prediction: {}\".format(aa1[i][0],aa1[i][1]))\n    plt.show()","dee7b36f":"## Test Dataset","e35c7e3e":"# Data Head","cc309f5a":"# Wrong Predictions Analysis","86c78ecd":"# EDA","da8d545d":"# Neural Network"}}