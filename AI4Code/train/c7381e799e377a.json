{"cell_type":{"42885b15":"code","da8436e3":"code","076b182e":"code","359385b3":"code","4d5c0789":"code","a4959071":"code","8080a3c7":"code","8e4ee786":"code","d589c415":"code","4dd16b5c":"code","8f7e7ecc":"code","4b441055":"code","4ee880e8":"code","8e758493":"code","58fc9ca5":"code","ca91c3fb":"code","60aaeb52":"code","2dd3029e":"code","862f750d":"code","44cc2112":"code","3662ddf3":"markdown","7a7bf038":"markdown","401acdad":"markdown","77be08ed":"markdown","db951668":"markdown","4a2eca67":"markdown","57682b2f":"markdown","f94831af":"markdown"},"source":{"42885b15":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\nfrom keras.datasets import mnist\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","da8436e3":"#  Load pre-shuffled MNIST data into train and test sets\nimport matplotlib.pyplot as plt\n%matplotlib inline\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nplt.imshow(X_train[0])","076b182e":"num_pixels = X_train.shape[1] * X_train.shape[2]\nX_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\nX_train = X_train \/ 255\nX_test = X_test \/ 255\n\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1]","359385b3":"def baseline_model():\n    model = Sequential()\n    model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal',\n    activation='relu'))\n    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","4d5c0789":"#build the model\nmodel = baseline_model()\n# Fit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200,\nverbose=2)\n# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))","a4959071":"from keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers import Embedding\nfrom keras.layers import Conv1D, GlobalMaxPooling1D\nfrom keras.datasets import imdb","8080a3c7":"#  Load pre-shuffled MNIST data into train and test sets\nimport matplotlib.pyplot as plt\n%matplotlib inline\n(X_train, y_train), (X_test, y_test) = mnist.load_data()","8e4ee786":"# set parameters:\nmax_features = 5000\nmaxlen = 784\nbatch_size = 32\nembedding_dims = 50\nfilters = 250\nkernel_size = 3\nhidden_dims = 250\nepochs = 2","d589c415":"num_pixels = X_train.shape[1] * X_train.shape[2]\n#num_pixels 28*28=784","4dd16b5c":"num_pixels = X_train.shape[1] * X_train.shape[2]\n#num_pixels 28*28=784\nX_train = X_train.reshape(X_train.shape[0],num_pixels).astype('float32')\nX_test = X_test.reshape(X_test.shape[0],num_pixels).astype('float32')\nX_train.shape","8f7e7ecc":"X_train = X_train \/ 255\nX_test = X_test \/ 255\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1] \ny_train.shape","4b441055":"print('x_train shape:', X_train.shape)\nprint('x_test shape:', X_test.shape)\nprint('Build model...')","4ee880e8":"model = Sequential()\nmodel.add(Embedding(max_features,\n                    embedding_dims,\n                    input_length=maxlen))\nmodel.add(Conv1D(filters,\n                 kernel_size,\n                 padding='valid',\n                 activation='relu',\n                 strides=1))\n# we use max pooling:\nmodel.add(GlobalMaxPooling1D())\n# We project onto a single unit output layer, and squash it with a sigmoid:\nmodel.add(Dense(10))\nmodel.add(Activation('softmax'))","8e758493":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(X_test, y_test))","58fc9ca5":"#But this is not CNN its simple multi perceptron that are working as a CNN classifier\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils","ca91c3fb":"from keras import backend as K\nK.set_image_dim_ordering('th')","60aaeb52":"import matplotlib.pyplot as plt\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n%matplotlib inline\nplt.imshow(X_train[0])","2dd3029e":"import numpy \n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# load data\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n# reshape to be [samples][channels][width][height]\nX_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n# normalize inputs from 0-255 to 0-1\nX_train = X_train \/ 255\nX_test = X_test \/ 255\n# one hot encode outputs\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1]\nplt.imshow(X_train[2232,0,:,:])","862f750d":"def baseline_model():\n# create model\n    model = Sequential()\n    model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","44cc2112":"model = baseline_model()\n# Fit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))","3662ddf3":"Now Build and run the model.","7a7bf038":"When we enter into the world of computer vision we have to understand how a computer understands an image. A colored image has three channels and a 2D data in each channel. When the image size increases Machine learning start suffering from the curse of dimensionality, in order to overcome from this Deep learning comes up with a special type of Feedforward neural network known as CNN- Convolutional Neural Network.","401acdad":"Article : http:\/\/www.machineintellegence.com\/cnn-convolution-neural-network\/","77be08ed":"Now Create a model in Deep learning using Keras,","db951668":"## CNN-Convolution Neural Network","4a2eca67":"# Conv1D\nImport the libraries,","57682b2f":"Load Data,","f94831af":"# Conv2D\nLoad Libraries,"}}