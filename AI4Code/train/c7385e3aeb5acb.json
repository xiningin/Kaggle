{"cell_type":{"1c038a9f":"code","7cd5421b":"code","881a5809":"code","0af41d82":"code","fa4ed340":"code","1d809b52":"code","33eaa1f5":"code","112a51c8":"code","b25338e0":"code","ed1c5526":"code","cadc5715":"code","af4607c8":"code","9c0c7abe":"code","14db7b46":"code","d8862673":"code","cc645adc":"code","b6468c56":"code","1d2928a6":"code","725e0839":"code","0d5a33ae":"code","58f25ae6":"code","ad957a73":"code","9c324d5b":"code","5f18f7d8":"code","8c6355f3":"code","3b705a65":"code","a36d7e4f":"code","d775555a":"code","ca5c4bf0":"markdown","1caa83bd":"markdown","87442d54":"markdown","29e51e45":"markdown","b95ca29f":"markdown","1720764b":"markdown","193cc890":"markdown"},"source":{"1c038a9f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold, GridSearchCV, StratifiedKFold\n\nfrom sklearn.metrics import *\nfrom sklearn import metrics\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom pathlib import Path\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n\nimport sys, os\nimport random \n\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\n    \nfrom IPython import display, utils\n\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_columns', 300)\npd.set_option('max_colwidth', 400)\n\n\ndef set_seed(seed=4242):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\nset_seed()","7cd5421b":"def make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    \n\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()\/np.sum(cf)]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) \/ float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] \/ sum(cf[:,1])\n            recall    = cf[1,1] \/ sum(cf[1,:])\n            f1_score  = 2*precision*recall \/ (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)","881a5809":"def read_data():\n    train = pd.read_csv('..\/input\/flu-data\/H1N1_Flu_Vaccines.csv')\n    #display(train.head())\n    \n    del train['respondent_id']\n   \n    \"\"\"cats = train.describe(include=['O']).columns\n    for c in cats:\n        le=LabelEncoder()\n        le.fit(list(train[c].astype(str)) + list(test[c].astype(str)))\n        train[c] = le.transform(train[c].astype(str))\n        test[c] = le.transform(test[c].astype(str))\"\"\"\n    return train","0af41d82":"train = read_data()","fa4ed340":"sns.countplot(train.h1n1_vaccine)","1d809b52":"sns.countplot(train.seasonal_vaccine)","33eaa1f5":"train.describe(include=['O'])","112a51c8":"missing = train.isnull().sum()\nmissing = missing[missing>0]\n\nmiss = pd.DataFrame(missing, columns=['missing'])\n\nmiss = miss.reset_index()\n\nprint(miss.columns)\n\nmiss.sort_values(by='missing', ascending=False, inplace=True)\n\nplt.figure(figsize=(15, 10))\nsns.barplot(y = miss['index'], x= miss.missing, palette='bone')","b25338e0":"cats = [c for c in train.columns if train[c].dtypes=='object']\n\nnums = train.select_dtypes(exclude='object').columns\n\nnums","ed1c5526":"for c in cats:\n    le=LabelEncoder()\n    train[c] = le.fit_transform(train[c].astype(str)) \n    ","cadc5715":"train.head().T","af4607c8":"import matplotlib.style as style\nstyle.use('seaborn-poster')\nsns.set_style('ticks')\nplt.subplots(figsize = (27,20))\n## Plotting heatmap. \n\n# Generate a mask for the upper triangle (taken from seaborn example gallery)\nmask = np.zeros_like(train.corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nsns.heatmap(train.corr(), cmap=sns.diverging_palette(20, 220, n=200), annot=True, mask=mask, center = 0, );\n## Give title. \nplt.title(\"Heatmap of all the Features\", fontsize = 25);","9c0c7abe":"del train['h1n1_vaccine']\ntarget = train.pop('seasonal_vaccine')\n\ntrain.shape\n\n","14db7b46":"train.fillna(-999, inplace=True)","d8862673":"model = Sequential()\nmodel.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\nmodel.add(Dense(8,  activation= 'relu' ))\nmodel.add(Dense(1,  activation= 'sigmoid' ))\nmodel.summary()","cc645adc":"model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])","b6468c56":"model.fit(train, target, validation_split=0.33 , epochs=15, batch_size=10)","1d2928a6":"scores = model.evaluate(train, target)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","725e0839":"from sklearn.model_selection import KFold, StratifiedKFold\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncvscores = []\nfor train_ind, test_ind in kfold.split(train, target):\n# create model\n    model = Sequential()\n    model.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dense(8,  activation= 'relu' ))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n    # Fit the model\n    model.fit(train.iloc[train_ind], target.iloc[train_ind], epochs=15, batch_size=10, verbose=1)\n    # evaluate the model\n    scores = model.evaluate(train.iloc[test_ind], target.iloc[test_ind], verbose=1)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\n","0d5a33ae":"print(\"%.2f%% (+\/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))","58f25ae6":"import gc\nimport tensorflow as tf\nfrom keras.layers import Dense, Input\nfrom collections import Counter\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.models import Model, load_model\nfrom keras import callbacks\nfrom keras import backend as K\nfrom keras.layers import Dropout\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=45)\ncvscores = []\nauc_score = []\noof_nn= np.zeros((len(train)))\nfor fold_, (train_ind, test_ind) in enumerate(folds.split(train, target)):\n# create model\n    print('fold : --------------', fold_)\n    \n    trn_x, trn_y = train.iloc[train_ind], target.iloc[train_ind]\n    val_x, val_y = train.iloc[test_ind], target.iloc[test_ind]\n\n    model = Sequential()\n    model.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dense(8,  activation= 'relu' ))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n    # Fit the model\n    model.fit(train.iloc[train_ind], target.iloc[train_ind], epochs=5, batch_size=10, verbose=1)\n    val_preds = model.predict(val_x)\n    \n    print(\"AUC = {}\".format(metrics.roc_auc_score(val_y,val_preds)))\n    auc_score.append(metrics.roc_auc_score(val_y,val_preds))\n    scores = model.evaluate(train.iloc[test_ind], target.iloc[test_ind], verbose=1)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    oof_nn[test_ind] =  val_preds.ravel()\n    print(oof_nn[0:10])\n    \n    cvscores.append(scores[1] * 100)\nK.clear_session()\ngc.collect()\nprint(\"Accuracy Mean: ------->\" , (np.mean(cvscores)))\nprint('AUC mean: ------->', np.mean(auc_score))","ad957a73":"ss= StandardScaler()\ntrain = ss.fit_transform(train)","9c324d5b":"from sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import metrics \nimport gc\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=45)\ncvscores = []\nauc_score = []\noof_nn= np.zeros((len(train)))\nfor fold_, (train_ind, test_ind) in enumerate(folds.split(train, target)):\n# create model\n    print('fold : --------------', fold_)\n    \n    trn_x, trn_y = train[train_ind], target.iloc[train_ind]\n    val_x, val_y = train[test_ind], target.iloc[test_ind]\n\n    model = Sequential()\n    model.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dense(8,  activation= 'relu' ))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy' ])\n    # Fit the model\n    model.fit(train[train_ind], target.iloc[train_ind], epochs=5, batch_size=10, verbose=1)\n    val_preds = model.predict(val_x)\n    \n    print(\"AUC = {}\".format(metrics.roc_auc_score(val_y,val_preds)))\n    auc_score.append(metrics.roc_auc_score(val_y,val_preds))\n    scores = model.evaluate(train[test_ind], target.iloc[test_ind], verbose=1)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    oof_nn[test_ind] =  val_preds.ravel()\n    print(oof_nn[0:10])\n    \n    cvscores.append(scores[1] * 100)\nK.clear_session()\ngc.collect()\nprint(\"Accuracy Mean: ------->\" , (np.mean(cvscores)))\nprint('AUC mean: ------->', np.mean(auc_score))","5f18f7d8":"def fallback_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except:\n        return 0.5\n\n\ndef auc(y_true, y_pred):\n    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)","8c6355f3":"from sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import metrics \nimport gc\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=45)\ncvscores = []\nauc_score = []\noof_nn= np.zeros((len(train)))\nfor fold_, (train_ind, test_ind) in enumerate(folds.split(train, target)):\n# create model\n    print('fold : --------------', fold_)\n    \n    trn_x, trn_y = train[train_ind], target.iloc[train_ind]\n    val_x, val_y = train[test_ind], target.iloc[test_ind]\n\n    model = Sequential()\n    model.add(Dense(12, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dense(8,  activation= 'relu' ))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[auc])\n    # Fit the model\n    model.fit(train[train_ind], target.iloc[train_ind], epochs=5, batch_size=10, verbose=1)\n    val_preds = model.predict(val_x)\n    \n    print(\"AUC = {}\".format(metrics.roc_auc_score(val_y,val_preds)))\n    auc_score.append(metrics.roc_auc_score(val_y,val_preds))\n    scores = model.evaluate(train[test_ind], target.iloc[test_ind], verbose=1)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    oof_nn[test_ind] =  val_preds.ravel()\n    print(oof_nn[0:10])\n    \n    cvscores.append(scores[1] * 100)\nK.clear_session()\ngc.collect()\nprint(\"Accuracy Mean: ------->\" , (np.mean(cvscores)))\nprint('AUC mean: ------->', np.mean(auc_score))","3b705a65":"import gc\nimport tensorflow as tf\nfrom keras.layers import Dense, Input\nfrom collections import Counter\nfrom keras.layers import BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.models import Model, load_model\nfrom keras import callbacks\nfrom keras import backend as K\nfrom keras.layers import Dropout\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=142)\ncvscores = []\nauc_score = []\noof_nn= np.zeros((len(train)))\n\nfor fold_, (train_ind, test_ind) in enumerate(folds.split(train, target)):\n# create model\n    print('fold : |||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||>', fold_)\n    \n    trn_x, trn_y = train[train_ind], target.iloc[train_ind]\n    val_x, val_y = train[test_ind], target.iloc[test_ind]\n\n    model = Sequential()\n    model.add(Dense(64, input_shape=(train.shape[1],),   activation= 'relu' ))\n    model.add(Dropout(0.2))\n    model.add(Dense(16,  activation= 'relu' ))\n    model.add(Dropout(0.2))\n    model.add(Dense(1,  activation= 'sigmoid' ))\n    # Compile model\n    #opt = keras.optimizers.Adam(learning_rate=0.01)\n    model.compile(loss= 'binary_crossentropy' , optimizer= 'Adam' , metrics=[auc])\n    # Fit the model\n    cp = callbacks.ModelCheckpoint(filepath=\"cp.hdf5\", monitor=\"val_auc\",  verbose=0,\n        save_best_only=False, save_weights_only=False,  mode=\"auto\")\n    \n    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=20,\n                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\n\n    rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n                                      patience=3, min_lr=1e-6, mode='max', verbose=1)\n    \n    model.fit(trn_x, trn_y, validation_data=(val_x, val_y),callbacks= [cp, es, rlr],  epochs=100, batch_size=16, verbose=0)\n    val_preds = model.predict(val_x)\n    \n    \n    print(\"AUC = {}\".format(metrics.roc_auc_score(val_y,val_preds)))\n    auc_score.append(metrics.roc_auc_score(val_y,val_preds))\n    #scores = model.evaluate(val_x, val_y, verbose=1)\n    #print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    oof_nn[test_ind] =  val_preds.ravel()\n    print(oof_nn[0:10])\n    \n    model.save_weights(\"model.h5\")\n    \n    \nK.clear_session()\ngc.collect()\n\nprint('AUC mean: ------->', np.mean(auc_score))","a36d7e4f":"oof_nn","d775555a":"oof_nn_rd = np.where(oof_nn > 0.5, 1, 0)\ncf_matrix = confusion_matrix(target, oof_nn_rd) \n\nlabels = ['True Neg','False Pos','False Neg','True Pos']\ncategories = ['Zero', 'One']\nplt.style.use('seaborn-poster')\nsns.set(font_scale=1.4)\nmake_confusion_matrix(cf_matrix, \n                      group_names=labels,\n                      categories=categories, \n                      cmap='vlag', figsize=(12, 8))","ca5c4bf0":"### AUC","1caa83bd":"### KFold Cross Validation","87442d54":">### **This notebook is an evolitionary review of building nn models with keras. I just focussed on base modeling.**\n>### **Final model can improve by EDA, Missing Value imputation, Feat eng, transformation and model tuning.**","29e51e45":"### Flu Vaccine Binary","b95ca29f":"### AUC through epoches","1720764b":"### Scale data ","193cc890":"### Better Network Topology"}}