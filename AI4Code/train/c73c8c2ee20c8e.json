{"cell_type":{"0437b8de":"code","0661c1c1":"code","9202fac3":"code","4a5dddd9":"code","dd8a3dd5":"code","20acc6db":"markdown","b2c2b8a2":"markdown","557ad68f":"markdown","96ab1579":"markdown"},"source":{"0437b8de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import classification_report, plot_confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0661c1c1":"df = pd.read_csv(\"..\/input\/gender-classification\/Transformed Data Set - Sheet1.csv\")\ndf.describe()","9202fac3":"X = df.iloc[:, 0:4]\ny = df.iloc[:, 4]","4a5dddd9":"clf = Pipeline(steps=[\n    (\"onehot\", OneHotEncoder(handle_unknown='ignore', sparse=False)),\n    (\"scaler\", StandardScaler()),\n    (\"model\", GaussianNB()),\n])","dd8a3dd5":"clf.fit(X, y)\nprint(classification_report(y, clf.predict(X)))\nprint(plot_confusion_matrix(clf, X, y, cmap=plt.cm.Blues,\n                            display_labels=['Male', 'Female']))\n","20acc6db":"# Dependent and Independent Variables","b2c2b8a2":"# After checking the description of the table, it looks like there are no missing columns and all columns are categorical","557ad68f":"Creating pipeline for handling categorical columns through **OneHotEncoder**, apply **feature scaling** on them and modelling through **GaussianNB** later on.","96ab1579":"# Importing dataset"}}