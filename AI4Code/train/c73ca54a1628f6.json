{"cell_type":{"c88a9c49":"code","65d3b752":"code","0bd35355":"code","c1995324":"code","ea126bb4":"code","e536a9d5":"code","884ec168":"code","f9563a5c":"code","6a477b37":"markdown","3ace17fe":"markdown","dd731273":"markdown","53510e95":"markdown","0508a9dd":"markdown"},"source":{"c88a9c49":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","65d3b752":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","0bd35355":"df = pd.read_csv('..\/input\/voicegender\/voice.csv')\ndf.head().T","c1995324":"df['label'] = df['label'].map({\"male\":0, \"female\":1})","ea126bb4":"X = df.drop(['label'], axis=1)\ny = df['label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","e536a9d5":"model = Sequential()\nmodel.add(Dense(1, activation=\"sigmoid\"))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\ntrain = model.fit(X_train , y_train , validation_data=(X_test,y_test), epochs=3000, verbose=1)","884ec168":"y_ann = (model.predict(X_test) > 0.5).astype(\"int32\").flatten()\ny_ann","f9563a5c":"print('Confusion Matrix:')\nprint(confusion_matrix(y_test,y_ann))\n\nprint('')\nprint('Accuracy Score:')\nprint(accuracy_score(y_test,y_ann))\n\nprint('')\nprint('Classification Report:')\nprint(classification_report(y_test,y_ann))\n\nplot_scores(train)","6a477b37":"## Librairies et fonctions utiles","3ace17fe":"Cette base de donn\u00e9es a \u00e9t\u00e9 cr\u00e9\u00e9e pour identifier une voix comme masculine ou f\u00e9minine, sur la base des propri\u00e9t\u00e9s acoustiques de la voix et de la parole. L'ensemble de donn\u00e9es est constitu\u00e9 de 3 168 \u00e9chantillons de voix enregistr\u00e9es, provenant de locuteurs masculins et f\u00e9minins. Les \u00e9chantillons de voix sont pr\u00e9trait\u00e9s par une analyse acoustique dans R \u00e0 l'aide des paquets seewave et tuneR, avec une gamme de fr\u00e9quences analys\u00e9es de 0hz-280hz (gamme vocale humaine).","dd731273":"# Analyse du dataset : \"Gender Recognition by Voice\"\n\n##### \n##### Pr\u00e9diction de genre des personnes sur le dataset :\n##### https:\/\/www.kaggle.com\/primaryobjects\/voicegender\n\n###### \n###### En utilisant des m\u00e9thodes sur le notebook :\n###### https:\/\/www.kaggle.com\/pyim59\/cancer-neurone","53510e95":"## Le dataset voicegender","0508a9dd":"## R\u00e9seaux denses (Keras\/Tensorflow)"}}