{"cell_type":{"6b09b776":"code","653cfd7b":"code","0fed2f95":"code","a100844f":"code","0f8cb511":"code","3c505b98":"code","38e179ab":"code","af30b1b8":"code","46c0c7df":"code","4c9b16b8":"code","44275d9a":"code","e45af409":"code","0275f90b":"markdown","331e0f21":"markdown","d9b8fb55":"markdown","f137bcce":"markdown","57c96a0d":"markdown","acf57672":"markdown","ff5e163c":"markdown","5c8692e5":"markdown","3fa44127":"markdown","8aebc03e":"markdown","4c888948":"markdown","56b6f8c1":"markdown"},"source":{"6b09b776":"import matplotlib.pyplot as plt # plotting\nimport matplotlib.image as im\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nimport re\nimport cv2\nimport csv\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras.models import Sequential, save_model, load_model\nimport urllib.request as urlrq\nimport certifi\nimport ssl\nimport shutil","653cfd7b":"\nclass_names = ['ferry_boat','gondola','sailboat','cruise_ship','kayak','inflatable_boat','paper_boat','buoy','freight_boat']\nenc = preprocessing.LabelEncoder()\nenc.fit(class_names)\nclass_nums = enc.transform(class_names)\nclass_nums = class_nums.reshape(-1, 1)\nenc = preprocessing.OneHotEncoder()\nenc.fit(class_nums)\nlabels_oh =enc.transform(class_nums).toarray()\nnum_of_new_images_per_image = 10\nnb_classes = len(class_names)\nepoch_num = 40\nIMAGE_SIZE = (256, 256)\nbatch_size = 32\nimages_num_per_class = 600\ncnt = 0\nmapit = {}# dict to convert value into its text label\nfor i in class_nums:\n  num = i[0]\n  mapit[num] = class_names[cnt]\n  cnt+=1\n","0fed2f95":"dir_path = '\/kaggle\/input\/Train'\nship_num_by_indx = []\nship_num_per_type = {}\nfor folder in class_names:\n    files = os.listdir(os.path.join(dir_path, folder))\n    ship_num_by_indx.append(len(files))\n    ship_num_per_type[folder] = len(files)\nplt.hist(ship_num_by_indx)\nplt.show()\nprint(ship_num_per_type, )\nfor folder in class_names:\n    print(ship_num_per_type[folder])","a100844f":"\ndef add_data(src_dir, folder, num_of_images_to_produce):\n  dir_path = '\/kaggle\/working\/'  \n  dst_path = os.path.join(dir_path, folder)    \n  if  os.path.isdir(dst_path):\n    shutil.rmtree(dst_path)\n  os.mkdir(dst_path)\n  aug = ImageDataGenerator(\n      rotation_range=30,\n      zoom_range=0.15,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.15,\n      horizontal_flip=True,\n      fill_mode=\"nearest\")   \n  \n  # construct the actual Python generator\n  print(\"[INFO] generating additional\" , num_of_images_to_produce, \" images for \", folder, \" at \", dst_path)\n  print(ship_num_per_type[folder])\n  batch_step = num_of_images_to_produce \/\/ ship_num_per_type[folder]\n  print(\"with batch_step = \", batch_step, \" for \", folder, \"num = \", ship_num_per_type[folder])\n  for indx , fname in enumerate(os.listdir(src_dir)):      \n      img_path = os.path.join(src_dir, fname)\n      image = image_preprocess(img_path)\n      image = np.expand_dims(image, axis=0)\n      i = 0\n      for batch in  aug.flow(image, batch_size=1, save_to_dir=dst_path, save_prefix=\"image\", save_format=\"jpg\"):\n            i += 1\n            if i > batch_step:\n                break\n  files = os.listdir(dst_path)\n  print(folder , \" after augmentation: \", dst_path, \" = \", len(files))\n","0f8cb511":"def image_preprocess(img_path):\n    # Open and resize the img\n    image = cv2.imread(img_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, IMAGE_SIZE)\n    return image\n\n\ndef images_reader(dir_path, label):\n    images = []\n    labels = []\n    cnt = 400\n    for file in os.listdir(dir_path):\n        if cnt > 0:\n            cnt-=1\n            # Get the full path name of the image\n            img_path = os.path.join(dir_path, file)\n            image = image_preprocess(img_path)\n            # Append the image and its corresponding label to the output\n            images.append(image)  # holds all the ships images\n            labels.append(label)  # holds the appropriate ships labels\n    return images, labels","3c505b98":"\ndef load_data(add_path = '\/kaggle\/working'):\n    datasets = ['\/kaggle\/input\/Train', add_path]# paths of the training data\n    output = []\n\n    # Iterate through training and test sets\n    for dataset in datasets:\n        images = np.array([])\n        labels = np.array([])\n        val_img = np.array([])\n        tst_img = np.array([])\n        val_lbl = np.array([])\n        tst_lbl = np.array([])\n        print(\"Loading {}\".format(dataset))\n        # Iterate through each folder corresponding to a category\n        for indx,folder in enumerate(os.listdir(dataset)):\n                    print(folder)\n                    if folder in class_names:\n                        indx = class_names.index(folder)\n                        label = labels_oh[indx]  # get number id for each folder\n                        if re.search(\"Train\", dataset):\n                            # Iterate through each image in our folder\n                            dir_path = os.path.join(dataset, folder)\n                            num_of_images_to_produce = images_num_per_class - ship_num_by_indx[indx]\n                            add_data(dir_path, folder, num_of_images_to_produce)\n                        else:\n                            dir_path = os.path.join(add_path, folder)\n\n                        x,y = images_reader(dir_path, label)\n                        images_tmp, vimages, labels_tmp, vlabels = train_test_split(x, y, test_size=0.4, random_state=4)\n                        images_tmp = np.array(images_tmp,dtype='float32')\n                        labels_tmp = np.array(labels_tmp, dtype='float32')\n                        if images.shape[0]<4:\n                            images=images_tmp\n                            labels=labels_tmp\n                        else:\n                            images=np.append(images, images_tmp,axis=0)\n                            labels=np.append(labels, labels_tmp,axis=0)\n                        val_img_tmp = np.array(vimages, dtype='float32')\n                        val_lbl_tmp = np.array(vlabels, dtype='float32')\n                        if val_img.shape[0]<4:\n                            val_img=val_img_tmp\n                            val_lbl=val_lbl_tmp\n                        else:\n                            val_img=np.append(val_img, val_img_tmp, axis=0)\n                            val_lbl=np.append(val_lbl, val_lbl_tmp, axis=0)\n    output.append(images)\n    output.append(labels)\n    output.append(val_img)\n    output.append(val_lbl)\n    return output\n\n\n(train_images, train_labels, validation_images, validation_labels) = load_data()\n\nn_train = train_labels.shape[0]\n\nprint (\"Number of training examples: {}\".format(n_train))\nprint (\"Each image is of size: {}\".format(IMAGE_SIZE))\n","38e179ab":"train_images = train_images \/ 255.0 # normalize the data\nvalidation_images = validation_images \/ 255.0","af30b1b8":"\nconv_net = VGG16(input_shape=(256, 256, 3), weights='imagenet', include_top=False)\n# don't train existing weights\nfor layer in conv_net.layers:\n    layer.trainable = False\nmodel = tf.keras.Sequential([\n     conv_net,\n     tf.keras.layers.Flatten(),\n     tf.keras.layers.Dense(200, activation=tf.nn.relu),  \n     tf.keras.layers.Dense(nb_classes, activation=tf.nn.softmax)\n ])\nmodel.summary()","46c0c7df":"# initialize an our data augmenter as an \"empty\" image data generator\nopt = Adam(lr=0.00001)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_images, train_labels, validation_data=(validation_images, validation_labels), epochs=epoch_num, verbose=2)\nloss_values = history.history['loss']\nepochs = range(1, len(loss_values)+1)\n\nplt.plot(epochs, loss_values, label='Training Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","4c9b16b8":"save_model(model,'\/kagglw\/working\/final_ship_model.h5')","44275d9a":"path = '\/kaggle\/input\/TEST'\nx, y = images_reader(path, 0)\ntst = np.array(x, dtype='float32')\ntest_images = tst \/ 255.0\npredictions = model.predict(test_images)\nclasses = np.argmax(predictions, axis=1)\nfig, ax = plt.subplots()\nfig.set_size_inches(25, 25)\nax.set_axis_off()\nfor i in range(25):\n    a = fig.add_subplot(5, 5, i+1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    plt.imshow(test_images[i])\n    plt.xlabel(mapit[classes[i]])","e45af409":"dirs = os.listdir(path )\nfilename = []\nfor file in dirs:\n   filename.append(file)\n# field names\nfields = ['File Name', 'Class']\n\n# data rows of csv file\nrows =['0']*test_images.shape[0]\nfor i in range(test_images.shape[0]):\n    num, _ = filename[i].split('.')\n    rows[int(num)-1] = ([filename[i], mapit[classes[i]]])\n# name of csv file\nfilename = '\/kaggle\/working\/results.csv' \n# writing to csv file\nwith open(filename, 'w', newline='') as csvfile:\n    # creating a csv writer object\n    csvwriter = csv.writer(csvfile)\n    # writing the fields\n    csvwriter.writerow(fields)\n\n    # writing the data rows\n    csvwriter.writerows(rows)","0275f90b":"# Train the model\nI used ImageDataGenerator to reduce overfitting by training the model on more examples than the given. The chosen optimizer was adam which is reomended for this kind of tasks. Ths chosen Loss function was categorical crossentropy for classification since each images belongs to one class only. Visualization of loss as function of epoch is shown below\n","331e0f21":"# Introduction\n\n In this notebook, I will try the process of implementing CNN with Keras in order to classify ships images\nThe flow of work is as following:\n\n1. import usefull packages.\n2. prepare hyperparameters and parameters\n3. extend the training data\n3. load the data and preprocess it.\n4. build a CNN model and train it\n5. evaluate its performances.\n6. use the pre trained model to classify ships images.","d9b8fb55":"# create csv file that contains the model predictions to all test images","f137bcce":"# Check if dataset is balanced\nwe get count of images per class. the expectation is to have equal amount of images per class in order to fit the model and get appropriate classification. We create histogram to get the dataset shape wrt class","57c96a0d":"# Read Images And Preprocess ","acf57672":"# Extend Training Data\nThe original training data in this task is not balanced. There are classes with more than 300 sampels, while there are classes with less than 90 sampels. This may lead to a faulty model which will prioritize the many samples classes. Thus the data was extended to have many more samples per class, and enable the model to learn each class attributes. ","ff5e163c":"## Conclusion\nThe model seems to work fine on the test images with accuracy rate of more than 90% on the test images","5c8692e5":"# Test The Model\napply the test images and check that prediction meets the real test image content. I selected 25 images to show the appropriate prediction, since there are no test labels to compare the predictions to. \n","3fa44127":"# Build The Model\nI choose VGG16 model for image classification, using transfer learning layers in order to get the best model for this task.\nI made several iterations in order to find the best value for the dense layer width.\n","8aebc03e":"#  Import Packages\n","4c888948":"# Loading the Data\nload_data function loads the images and labels from two folders: the original data and the augmented data. 60% of the loadded data is for training, and the other 40% are for validation of the model.","56b6f8c1":"# preapare hyper parameters and parameters\nCNN model needs labels data to be a numeric type. There is **no** ordinal relationship exists in the class label. Thus to avoid poor performance or unexpected results class labels are one-hot encodded."}}