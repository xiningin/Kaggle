{"cell_type":{"3c9dc469":"code","4038279f":"code","5a50fda9":"code","921f8243":"code","7f7d7259":"code","ee16d1ce":"code","bd65793e":"code","7a5e9f2d":"code","42bd3df0":"code","fba5207a":"code","44b05836":"code","c6574bcf":"code","7a98970e":"markdown","2bf91fef":"markdown","a0c80880":"markdown","306b6150":"markdown","73e89b17":"markdown","08327236":"markdown","4a78d541":"markdown","a8f17c39":"markdown","3631f3a0":"markdown","6579d25c":"markdown","a6665872":"markdown"},"source":{"3c9dc469":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","4038279f":"dataset = pd.read_csv('..\/input\/social-network-ads\/Social_Network_Ads.csv')\nprint(\"Num examples = \", len(dataset))\ndataset.head()","5a50fda9":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","921f8243":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","7f7d7259":"print(\"Train set size = \",len(X_train),len(y_train))\nprint(\"Test set size = \",len(X_test),len(y_test))","ee16d1ce":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","bd65793e":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","7a5e9f2d":"print(classifier.predict(sc.transform([[30,87000]])))","42bd3df0":"y_pred = classifier.predict(X_test)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))","fba5207a":"from sklearn.metrics import confusion_matrix, accuracy_score\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","44b05836":"from matplotlib.colors import ListedColormap\nX_set, y_set = sc.inverse_transform(X_train), y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\nplt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistic Regression (Training set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","c6574bcf":"from matplotlib.colors import ListedColormap\nX_set, y_set = sc.inverse_transform(X_test), y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 0.25),\n                     np.arange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 0.25))\nplt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\nplt.title('Logistic Regression (Test set)')\nplt.xlabel('Age')\nplt.ylabel('Estimated Salary')\nplt.legend()\nplt.show()","7a98970e":"## Visualising the Test set results","2bf91fef":"## Making the Confusion Matrix","a0c80880":"## Feature Scaling","306b6150":"## Predicting the Test set results","73e89b17":"# Logistic Regression","08327236":"## Training the Logistic Regression model on the Training set","4a78d541":"## Visualising the Training set results","a8f17c39":"## Splitting the dataset into the Training set and Test set","3631f3a0":"## Importing the dataset","6579d25c":"## Importing the libraries","a6665872":"## Predicting a new result"}}