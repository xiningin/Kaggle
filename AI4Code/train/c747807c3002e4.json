{"cell_type":{"5c11d971":"code","8c193202":"code","3533254b":"code","3fd560e4":"code","574ce8ba":"code","9131e432":"code","bc8b8db6":"code","9a2e24f4":"code","f229557d":"code","5dfff653":"code","ac0afe7b":"code","810be7e5":"code","8a755b79":"code","9bcbbb4a":"code","227c9765":"code","7ea437bf":"code","c501af22":"code","1eef4640":"code","5df9f83c":"code","0b1c4041":"code","92bb9dbf":"code","cb15f8e7":"markdown","991a8e3e":"markdown","0878ffc0":"markdown","9c4aae62":"markdown","2c8a9acc":"markdown","0deb7fc6":"markdown","e2bed129":"markdown","bccb7beb":"markdown","b4664568":"markdown","dba4fe23":"markdown","3923d865":"markdown","976b5010":"markdown","3dc52bcf":"markdown","d899a638":"markdown"},"source":{"5c11d971":"import numpy as np\nimport pandas as pd\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nimport statsmodels.api as sm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, roc_curve, plot_roc_curve","8c193202":"df = pd.read_csv(\"..\/input\/diabetes-dataset\/diabetes2.csv\")","3533254b":"df.head()","3fd560e4":"df.info()","574ce8ba":"X = df.iloc[:,:-1]\ny = df.iloc[:,-1]\n\nx_names = X.columns\ny_name = y.name","9131e432":"df_X_train, df_X_test, y_train, y_test = train_test_split(X, y,test_size=0.25, random_state=0)","bc8b8db6":"sc = StandardScaler()\nX_train = sc.fit_transform(df_X_train)\nX_test = sc.transform(df_X_test)\n\n# # what means scaling?\ndisplay(\n    df_X_train.describe(),\n    # mean -> 0, std.dev. -> 1\n    pd.DataFrame(data=X_train, index=df_X_train.index, columns=df_X_train.columns).describe()\n)","9a2e24f4":"train_index = y_train.index\ntest_index = y_test.index","f229557d":"if False: # takes some time\n# if True: \n    _ = sns.pairplot(hue=y_name, data=df.loc[train_index]) #, kind='reg')","5dfff653":"_, axs = plt.subplots(1, 2, figsize=(14, 6))\n\nfor i, X in enumerate([df_X_train, df_X_test]):\n    with sns.axes_style(\"white\"):\n        corr = X.corr()\n        mask = np.zeros_like(corr)\n        mask[np.triu_indices_from(mask)] = True\n        sns.heatmap(corr, robust=True, cmap='viridis', mask=mask, ax=axs[i])","ac0afe7b":"logit_model = sm.Logit(y_train, X_train)\n\nresult = logit_model.fit()\n\nresult.summary()","810be7e5":"y_pred_proba_sm = result.predict()\ny_pred_sm = (y_pred_proba_sm > 0.5).astype(int)","8a755b79":"cols = df_X_train.columns","9bcbbb4a":"_, axs = plt.subplots(2, len(cols)\/\/2, figsize=(14, 6), tight_layout=True)\nfor i, col in enumerate(cols):\n    ax = axs[i % 2][i \/\/ 2]\n    df_X_train.join(y_train).plot.scatter(x=col, y='Outcome', ax=ax)\n    ax.plot(df_X_train[col], y_pred_proba_sm, '.c')\n    ax.plot(df_X_train[col], y_pred_sm, '.r')\n    ax.set_title(f'x{i+1}')","227c9765":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nlogreg.coef_","7ea437bf":"y_pred = logreg.predict(X_test)\ny_pred_proba = logreg.predict_proba(X_test)[:, 1]","c501af22":"_, axs = plt.subplots(2, len(cols)\/\/2, figsize=(14, 6), tight_layout=True)\nfor i, col in enumerate(cols):\n    ax = axs[i % 2][i \/\/ 2]\n    df_X_test.join(y_test).plot.scatter(x=col, y='Outcome', ax=ax)\n    ax.plot(df_X_test[col], y_pred_proba, '.c')\n    ax.plot(df_X_test[col], y_pred, '.r')\n    ax.set_title(f'coef #{i+1}')","1eef4640":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\nconfusion_matrix_result = confusion_matrix(y_test, y_pred)\naccuracy_score_result = accuracy_score(y_test,y_pred)\nclassification_report_result = classification_report(y_test, y_pred)\n\ndisplay(\n    confusion_matrix_result,\n    accuracy_score_result,\n)\n\nprint(classification_report_result)","5df9f83c":"support_0 = confusion_matrix_result[0, :].sum()\nsupport_1 = confusion_matrix_result[1, :].sum()\ncnt_pred_0 = confusion_matrix_result[:, 0].sum()\ncnt_pred_1 = confusion_matrix_result[:, 1].sum()\n\ndisplay(\n    f'support of \"0\" -> {support_0}',\n    f'support of \"1\" -> {support_1}',\n    # Negative Predicitve Value\n    f'precision of \"0\" = NPV -> {confusion_matrix_result[0, 0] \/ cnt_pred_0 :.2f}',\n    # Positive Predicitive Value\n    f'precision of \"1\" = PPV -> {confusion_matrix_result[1, 1] \/ cnt_pred_1 :.2f}',\n    # True Negative Rate, specificity\n    f'recall of \"0\" = TNR -> {confusion_matrix_result[0, 0] \/ support_0 :.2f}',\n    # True Positive Rate, sensitivity\n    f'recall of \"1\" = TPR -> {confusion_matrix_result[1, 1] \/ support_1 :.2f}',\n    # False Negative Rate, misses\n    f'FNR = 1 - TPR -> {confusion_matrix_result[1, 0] \/ support_1 :.2f}',\n    # False Positive Rate, fall-out\n    f'FPR = 1 - TNR -> {confusion_matrix_result[0, 1] \/ support_0 :.2f}',\n)\n\nfit_FPR = confusion_matrix_result[0, 1] \/ support_0\nfit_TPR = confusion_matrix_result[1, 1] \/ support_1","0b1c4041":"logit_roc_auc = roc_auc_score(y_test, y_pred_proba)\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n\nfig, axs = plt.subplots(2, 1, sharex=True, figsize=(6, 8), tight_layout=True)\nax = axs[0]\nax.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nax.plot([0, 1], [0, 1],'k:')\nax.plot(fit_FPR, fit_TPR, 'ro')\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.05])\nax.set_ylabel('True Positive Rate')\nax.set_title('Receiver Operating Characteristic')\nax.legend(loc=\"lower right\")\n\n# index of 0.5 threshold\nidx_thres_05 = np.where(thresholds <= 0.5)[0][0]\n\nax = axs[1]\nax.plot(fpr, thresholds)\nax.axvline(fpr[idx_thres_05], color='r', ls=':')\nax.set_ylim(0, 1)\nax.set_title('Thresholds')\nax.set_xlabel('False Positive Rate')\n\nfig.savefig('Log_ROC')","92bb9dbf":"ax = plt.figure().gca()\n_ = plot_roc_curve(logreg, X_test, y_test, ax=ax)","cb15f8e7":"#### using `statsmodels`","991a8e3e":"# Diabetes Prediction\n\n## Logistic regression fit with classification performance analysis, e.g. ROC curve\n\n*with some explanations*","0878ffc0":"* If Outcome is 1,then person has diabetes.\n* If Outcome is 0,then person has not diabetes.","9c4aae62":"### Importing Libraries","2c8a9acc":"### Model: fit and predict","0deb7fc6":"##### ToDo\neventually extend with cross validation like [scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_roc_crossval.html](https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_roc_crossval.html)","e2bed129":"#### understanding the classification performance","bccb7beb":"### ROC curve (variant 2)\n\nusing `plot_roc_curve`","b4664568":"### Plotting Data - Visualization","dba4fe23":"### Data Preparation and pre-processing\n\n  - define endogene and exogene data \n  - split data to clealy separate train and test sub-population\n  - scale data for prediction\n","3923d865":"### ROC curve (variant 1)","976b5010":"#### Confusion Matrix, accuracy score and classification report","3dc52bcf":"### Loading Data","d899a638":"#### using `sklearn`\n\nand make use of train and test split"}}