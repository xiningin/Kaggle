{"cell_type":{"9e97d2a8":"code","bf7cc5b8":"code","1a53d0b7":"code","c532dd48":"code","be474411":"code","f44f97b8":"code","accef96e":"code","296d298b":"code","a7c694a5":"code","c0578b42":"code","5abbaa5b":"code","e725111a":"code","cb1f39df":"code","65ac03e5":"code","1e6d34ad":"code","339263dc":"code","6a1f52c1":"code","992a5fd9":"code","6b8e6db5":"code","fac0c63b":"code","bb31c8a2":"code","38e5206f":"code","a3f6d66b":"code","257e36e3":"markdown","e9301f7d":"markdown","35511956":"markdown","0c9684ab":"markdown","de92a1a5":"markdown","c598a617":"markdown","b6011625":"markdown","54719519":"markdown","680a5682":"markdown","a9352bbe":"markdown"},"source":{"9e97d2a8":"## Inintialize\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Data for training\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\n# Data for testign\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n# Data to submit\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\n\n","bf7cc5b8":"train.head()","1a53d0b7":"test.head()","c532dd48":"gender_submission.head()","be474411":"# The amount of data\nprint(\"train \" + str(len(train)))\nprint(\"test \" + str(len(test)))","f44f97b8":"# Connvert\ndata = pd.concat([train, test], sort=False)\ndata.head()","accef96e":"# Null\ndata.isnull().sum()","296d298b":"data_analyze = data.copy()\ndata_analyze.head()","a7c694a5":"data_analyze.describe()","c0578b42":"import seaborn as sns\n\nsns.countplot(x='Pclass', data=data_analyze, hue='Survived')\n","5abbaa5b":"\ndata_analyze['FamilySize'] = data_analyze['Parch'] + data_analyze['SibSp'] + 1\nsns.countplot(x='FamilySize', data=data_analyze, hue='Survived')\n","e725111a":"# memo in_place\u306f\u526f\u4f5c\u7528\u304c\u3042\u308b\ndata['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\n\n# \u6b20\u640d\u5024\u3092\u611a\u76f4\u306b\u57cb\u3081\u308b\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map({ 'S': 0, 'C': 1, 'Q': 2 }).astype(int)\n\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\n\nage_avg = data['Age'].mean()\nage_std = data['Age'].std()\n## TODO: \u3053\u308c\u306e\u610f\u5473\u7406\u89e3\u3057\u305f\u3044\ndata['Age'].fillna(np.random.randint(age_avg - age_std, age_avg + age_std), inplace=True)\n\n## \u307c\u3063\u3061\u304b\u3069\u3046\u304b\n# \u52a0\u5de5\ndata['FamilySize'] = data['Parch'] + data['SibSp'] + 1\n# \u7279\u5fb4\u91cf\u751f\u6210\ndata['IsAlone'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n\n# Mr.\u7b49\u306e\u52a0\u5de5\ndata['Title'] = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ndata['Title'] = data['Title'].map(title_mapping)\ndata['Title'] = data['Title'].fillna(0)    \n\ndelete_columns = ['Name', 'PassengerId', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'FamilySize']\ndata.drop(delete_columns, axis=1, inplace=True)\ndata.head()","cb1f39df":"train = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)","65ac03e5":"y_train.head()","1e6d34ad":"X_train.head()","339263dc":"X_test.head()","6a1f52c1":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nfrom sklearn.metrics import log_loss\n\ndef getCategoricalFeatures():\n    return ['Embarked', 'Pclass', 'Sex']\n\ndef makeModel(X_train, y_train, X_valid, y_valid):\n    categorical_features = getCategoricalFeatures()\n    \n    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature=categorical_features)\n    lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train, categorical_feature=categorical_features)\n    \n    params = {\n        'objective': 'binary',\n        'max_bin': 427,\n        'learning_rate': 0.05,\n        'num_leaves': 79,\n    }\n    \n    model = lgb.train(params, lgb_train,\n                     valid_sets=[lgb_train, lgb_eval],\n                     verbose_eval=10,\n                     num_boost_round=1000,\n                     early_stopping_rounds=10)\n    \n    return model\n","992a5fd9":"import optuna\nfrom sklearn.model_selection import train_test_split\n\nXX_train, XX_valid, yy_train, yy_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0, stratify=y_train)\n\ndef objective(trial):\n    params = {\n        'objective': 'binary',\n        'max_bin': trial.suggest_int('max_bin', 255, 500),\n        'learning_rate': 0.05,\n        'num_leaves': trial.suggest_int('num_leaves', 32, 128),\n    }\n    \n    categorical_features = getCategoricalFeatures()\n    \n    lgb_train = lgb.Dataset(XX_train, yy_train, categorical_feature=categorical_features)\n    lgb_eval = lgb.Dataset(XX_valid, yy_valid, reference=lgb_train, categorical_feature=categorical_features)\n    \n    model = lgb.train(params, lgb_train,\n                     valid_sets=[lgb_train, lgb_eval],\n                     verbose_eval=10,\n                     num_boost_round=1000,\n                     early_stopping_rounds=10)\n        \n    yy_pred_valid = model.predict(XX_valid, num_iteration=model.best_iteration)\n    score = log_loss(yy_valid, yy_pred_valid)\n    return score\n    \n","6b8e6db5":"def studyHyPara():\n    study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=0))\n    study.optimize(objective, n_trials=40)\n    return study.best_params","fac0c63b":"# studyHyPara()","bb31c8a2":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss, accuracy_score\n","38e5206f":"def validation(X_train, y_train):\n    y_preds = []\n    models = []\n    oof_train = np.zeros((len(X_train)))\n    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n    \n    for train_index, valid_index in cv.split(X_train):\n        X_tr = X_train.loc[train_index, :]\n        X_val = X_train.loc[valid_index, :]\n        y_tr = y_train[train_index]\n        y_val = y_train[valid_index]\n    \n        model = makeModel(X_tr, y_tr, X_val, y_val)\n        \n        oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n        y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n        \n        y_preds.append(y_pred)\n        models.append(model)\n    \n    scores = [\n        m.best_score['valid_1']['binary_logloss'] for m in models\n    ]\n    score = sum(scores) \/ len(scores)\n    print('===CV scores===')\n    print(scores)\n    print(score)    \n    \n    pd.DataFrame(oof_train).to_csv('oof_train_kfold.csv', index=False)\n    \n    y_pred_oof = (oof_train > 0.5).astype(int)\n    print('===Score===')\n    print(accuracy_score(y_train, y_pred_oof))\n    \n    # For submission\n    y_sub = sum(y_preds) \/ len(y_preds)\n    y_sub = (y_sub > 0.5).astype(int)\n    return y_sub\n        \ny_pred = validation(X_train, y_train)","a3f6d66b":"sub = gender_submission.copy()\nsub['Survived'] = y_pred\ny_pred[:10]\nsub.to_csv(\"submission.csv\", index=False)","257e36e3":"## Submit","e9301f7d":"### Analyzing data","35511956":"### Machine Leaning","0c9684ab":"## Validation","de92a1a5":"## \u7279\u5fb4\u91cf\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0\n\n\u81ea\u5206\u3067\u8003\u3048\u308b\n\n### \u4f7f\u3048\u305d\u3046\n\n- pclass\n- sex\n- age\n- sibsp\n- parch\n- cabin\n\n### \u4f7f\u3048\u306a\u305d\u3046\n\n- ticket\n    - \u305f\u3060\u306e\u4e71\u6570\u3063\u307d\u3044\u6c17\u304c\u3059\u308b\n    - \u756a\u53f7\u304c\u82e5\u3044\u3068\u5165\u308a\u53e3\u304c\u8fd1\u3044\u3001\u3068\u304b\u306a\u3089\u95a2\u4fc2\u3042\u308a\u305d\u3046\uff1f\n- embarked\n    - \u95a2\u4fc2\u3042\u308b\u306e\u304b\u306a","c598a617":"# Initializing","b6011625":"\u5bb6\u65cf\u304c\u3044\u308b\u304b\u3069\u3046\u304b","54719519":"## \u5206\u6790","680a5682":"## Hyper Parameter","a9352bbe":"### \u5ba2\u5e2d\u30e9\u30f3\u30af\n\nPclass\u304c3\u304b\u3069\u3046\u304b\u304c\u904b\u547d\u306e\u5206\u304b\u308c\u76ee\u306b\u306a\u3063\u3066\u3044\u305d\u3046"}}