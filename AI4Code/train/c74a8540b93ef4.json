{"cell_type":{"aa03d685":"code","b881a736":"code","8e7e64c8":"code","9d4264e3":"code","a39c7975":"code","e0b6bf5c":"code","d4e32e55":"code","35b26455":"code","fd7bd2bf":"code","1cd0148a":"code","0754cd02":"code","7aa9651b":"code","b8b01fbc":"code","7d5a53c4":"code","0e2185f9":"code","a8940f31":"code","eb3a1005":"code","b69acccb":"code","3f4da7d1":"code","b0aa558f":"code","4c6561cf":"code","69ad929d":"code","aa077e3d":"code","b4f6ad6a":"code","e3fcc17b":"code","6f32ef57":"code","cff43aed":"code","dc68bab7":"code","b2612ea6":"code","75214018":"code","eecfc66e":"code","bfda606c":"code","07fe0a68":"code","2e79208f":"code","c1096587":"code","8e792c42":"code","ddffaa1a":"code","4b60081f":"code","1f153bec":"code","a9ba444e":"code","9a642080":"code","32b0816f":"code","77140b3f":"markdown","5949e23a":"markdown","03e566ce":"markdown","cc2639b9":"markdown","9206a940":"markdown","adf557c1":"markdown","bdabf5e1":"markdown","da3a11d4":"markdown","953141ea":"markdown","d9691371":"markdown","d44682dc":"markdown","a59ff3ad":"markdown","7f5acf9a":"markdown","43243c02":"markdown","f5e0ea88":"markdown","ccd32fe7":"markdown","f5b0e9c5":"markdown","23898c0d":"markdown","7db52a89":"markdown","443340e9":"markdown","77a32614":"markdown"},"source":{"aa03d685":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b881a736":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n","8e7e64c8":"data = pd.read_csv(\"\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","9d4264e3":"data","a39c7975":"data.columns","e0b6bf5c":"data.info()","d4e32e55":"data.describe()","35b26455":"data.isnull().sum()","fd7bd2bf":"data.corr()","1cd0148a":"data.quality.unique()","0754cd02":"sns.countplot(data[\"quality\"])","7aa9651b":"corr = data.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(10, 8))\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr, cmap='coolwarm', annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","b8b01fbc":"sns.distplot(data[\"fixed acidity\"])","7d5a53c4":"sns.distplot(data[\"volatile acidity\"])","0e2185f9":"sns.distplot(data[\"citric acid\"])","a8940f31":"sns.distplot(data[\"residual sugar\"])","eb3a1005":"sns.distplot(data[\"chlorides\"])","b69acccb":"sns.distplot(data[\"free sulfur dioxide\"])","3f4da7d1":"sns.distplot(data[\"total sulfur dioxide\"])","b0aa558f":"sns.distplot(data[\"density\"])","4c6561cf":"sns.distplot(data[\"pH\"])","69ad929d":"sns.distplot(data[\"sulphates\"])","aa077e3d":"sns.distplot(data[\"alcohol\"])","b4f6ad6a":"sns.distplot(data[\"quality\"])","e3fcc17b":"plt.scatter(data[\"quality\"],data[\"fixed acidity\"])","6f32ef57":"plt.scatter(data[\"quality\"],data[\"volatile acidity\"])","cff43aed":"plt.scatter(data[\"quality\"],data[\"citric acid\"])","dc68bab7":"plt.scatter(data[\"quality\"],data[\"residual sugar\"])","b2612ea6":"plt.scatter(data[\"quality\"],data[\"chlorides\"])","75214018":"bins = (1, 6, 10)\ngroup_names = ['bad', 'good']\ndata['quality'] = pd.cut(data['quality'], bins = bins, labels = group_names)","eecfc66e":"\nle = LabelEncoder()\ndata[\"quality\"] = le.fit_transform(data[\"quality\"])","bfda606c":"X = data.iloc[:,:-1].values\ny = data.iloc[:,-1].values\nsc_X = StandardScaler()\nX = sc_X.fit_transform(X)","07fe0a68":"data.quality.unique()","2e79208f":"X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)","c1096587":"model1 = LogisticRegression()\nmodel1.fit(X_train,y_train)\ny_pred = model1.predict(X_test)\nlog = accuracy_score(y_test,y_pred)*100\nprint(\"Accuracy Score:\",accuracy_score(y_test,y_pred)*100,\"%\")\nprint(\"Recall Score:\",recall_score(y_test,y_pred)*100,\"%\")\nprint(\"Precision Score:\",precision_score(y_test,y_pred)*100,\"%\")\nprint(\"F1 Score:\",f1_score(y_test,y_pred)*100,\"%\")\npd.crosstab(y_pred,y_test)","8e792c42":"clf = KNeighborsClassifier()\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)\nknn = accuracy_score(y_test,y_pred)*100\nprint(\"Accuracy Score:\",accuracy_score(y_test,y_pred)*100,\"%\")\nprint(\"Recall Score:\",recall_score(y_test,y_pred)*100,\"%\")\nprint(\"Precision Score:\",precision_score(y_test,y_pred)*100,\"%\")\nprint(\"F1 Score:\",f1_score(y_test,y_pred)*100,\"%\")\npd.crosstab(y_pred,y_test)","ddffaa1a":"k_range = range(1,100)\nscores = {}\nscores_list = []\nfor k in k_range:\n    clf = KNeighborsClassifier(n_neighbors = k)\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    scores[k] = accuracy_score(y_test,y_pred)\n    scores_list.append(accuracy_score(y_test,y_pred))","4b60081f":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\nplt.plot(k_range,scores_list)\nplt.xlabel(\"Value of K\")\nplt.ylabel(\"Accuracy\")\nplt.show()","1f153bec":"clf = KNeighborsClassifier(n_neighbors = 4)\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)\nknn_4 = accuracy_score(y_test,y_pred)*100\nprint(\"Accuracy Score:\",accuracy_score(y_test,y_pred)*100,\"%\")\nprint(\"Recall Score:\",recall_score(y_test,y_pred)*100,\"%\")\nprint(\"Precision Score:\",precision_score(y_test,y_pred)*100,\"%\")\nprint(\"F1 Score:\",f1_score(y_test,y_pred)*100,\"%\")\npd.crosstab(y_pred,y_test)","a9ba444e":"clf = SVC(kernel=\"rbf\")\nclf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)\nsvc_rbf = accuracy_score(y_test,y_pred)*100\nprint(\"Accuracy Score:\",accuracy_score(y_test,y_pred)*100,\"%\")\nprint(\"Recall Score:\",recall_score(y_test,y_pred)*100,\"%\")\nprint(\"Precision Score:\",precision_score(y_test,y_pred)*100,\"%\")\nprint(\"F1 Score:\",f1_score(y_test,y_pred)*100,\"%\")\npd.crosstab(y_pred,y_test)","9a642080":"classifier = GaussianNB()\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\ngus = accuracy_score(y_test,y_pred)*100\nprint(\"Accuracy Score:\",accuracy_score(y_test,y_pred)*100,\"%\")\nprint(\"Recall Score:\",recall_score(y_test,y_pred)*100,\"%\")\nprint(\"Precision Score:\",precision_score(y_test,y_pred)*100,\"%\")\nprint(\"F1 Score:\",f1_score(y_test,y_pred)*100,\"%\")\npd.crosstab(y_pred,y_test)","32b0816f":"print(\"Logistic_model\",log)\nprint(\"KNN_model\",knn)\nprint(\"KNN_4_model\",knn_4)\nprint(\"SVC_RBF\",svc_rbf)\nprint(\"Gaussian_model\",gus)","77140b3f":"# ***Checking Null Values***","5949e23a":"# > ***Support Vector Machine Using \"RBF\" function***","03e566ce":"# > ***Gaussian Naive Bayes Classifier***","cc2639b9":"# K = 4 for Optimal Classifier","9206a940":"Data Spliting under target and independent Columns","adf557c1":"# Coverting all values","bdabf5e1":"# Description of dataset","da3a11d4":"**1-6 -> \"bad\"\n7-10 -> \"good\"**","953141ea":"# Data Visualization","d9691371":"# Columns in dataset","d44682dc":"# Encoding Process on target Column","a59ff3ad":"# **Import Dataset**","7f5acf9a":"**Information of dataset**","43243c02":"# ***Importing Libraries***","f5e0ea88":"> # ***KNN Classifier Simple***","ccd32fe7":"# Checking Correlation Between each of them","f5b0e9c5":"# > ***Evaluation of All Models***","23898c0d":"# > *** Logistic Regression***","7db52a89":"# > ***Finding Optimal K value for KNN***","443340e9":"# Split Training and Testing Dataset","77a32614":"# **Finding unique values of Target column**"}}