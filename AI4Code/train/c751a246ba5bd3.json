{"cell_type":{"fc7dc083":"code","6c7b92d9":"code","3418d9fd":"code","ba1e03a8":"code","cc00e3ef":"code","f1ac91a8":"code","17d6a0d7":"code","264af066":"code","ad471a5d":"code","73ca4869":"code","f3b923da":"code","38197867":"code","252d93ae":"code","1c392f28":"code","36618c97":"code","5d17e5ef":"code","844fdd78":"code","f0d1c513":"code","97741bdb":"code","d7914a8f":"code","8cbb2c12":"code","699485f8":"code","f6330657":"code","3d1e4480":"code","1981be31":"code","244d72dd":"code","53706d74":"code","104a70af":"code","b8b9aa2e":"code","ec095fb3":"markdown","61f525e4":"markdown","a84abda8":"markdown","9bced475":"markdown","a9c09210":"markdown"},"source":{"fc7dc083":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6c7b92d9":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","3418d9fd":"zoo_dir = \"\/kaggle\/input\/zoo-animal-classification\/zoo.csv\"\nclass_dir = \"\/kaggle\/input\/zoo-animal-classification\/class.csv\"\n\ndata_zoo = pd.read_csv(zoo_dir)\ndata_class = pd.read_csv(class_dir)","ba1e03a8":"display(data_zoo.head())\ndisplay(data_class)","cc00e3ef":"class_types = list(data_class['Class_Type'])\nclass_types","f1ac91a8":"class_map = {}\nfor i in range(data_class.shape[0]):        \n    class_map[data_class['Class_Number'].iloc[i]] = data_class['Class_Type'].iloc[i]\n    \nclass_map","17d6a0d7":"print(f\"Total animals in zoo data is {len(data_zoo['animal_name'].unique())}\")\nprint(f\"Total animal in class data is {data_class['Number_Of_Animal_Species_In_Class'].sum()}\")","264af066":"data = pd.merge(data_zoo, data_class, how='left', left_on='class_type', right_on='Class_Number')\ndata.head()","ad471a5d":"## Droping columns that are repeating and not useful\ndata.drop(['Class_Number', 'Number_Of_Animal_Species_In_Class', 'Animal_Names'], axis=1, inplace=True)\ndata.head()","73ca4869":"plt.figure(figsize = (12,8))\nplt.grid(True)\nax = sns.countplot(x='Class_Type', data=data, palette='Spectral_r')\nfor p in ax.patches:\n        ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()+0.5))","f3b923da":"# Seperating all the categories of animals in a dictionary\nanimal_type = {}\nanimal_category = data.Class_Type.unique()\nprint(\"Seperating Categories...\")\nfor category in animal_category:\n    animal_type[category] = data[data['Class_Type']==category]\nprint(\"Seperation completed\")","38197867":"#Here we will split every category into trainig and test data\nSPLIT = 0.85\ntrain = pd.DataFrame() #to combine all the splited traning data from all categories\ntest = pd.DataFrame() #to combine all the splited test data from all categories\nfor category_name in animal_type:\n    m = int(animal_type[category_name].shape[0] * SPLIT)\n    train = pd.concat([train, animal_type[category_name].iloc[: m, :]])\n    test = pd.concat([test, animal_type[category_name].iloc[m:, :]])\n\n#Shuffling the train and test data randomly\ntrain = train.sample(frac=1)\ntest = test.sample(frac=1)","252d93ae":"print(f\"Training data shape = {train.shape}\")\nprint(f\"Training data shape = {test.shape}\")","1c392f28":"plt.figure(figsize=(16,12))\nmatrix = np.triu(train.corr())\nsns.heatmap(train.corr(), cmap='coolwarm', annot=True, fmt='.1g', mask=matrix)\nplt.plot()","36618c97":"train.head()","5d17e5ef":"# We have already split the data into 85% train and 15% test data\nX_train = train.iloc[:,1:-2] # not using animal_name and class_type and Class_Type(category of animal)\ny_train = train.iloc[:, -2] # class_type is the dependent feature\nX_test = test.iloc[:, 1:-2]\ny_test = test.iloc[:, -2]","844fdd78":"clf = DecisionTreeClassifier()\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)","f0d1c513":"np.unique(y_pred), np.unique(y_test)\n#To simply understand whether the prediction are atleast covering all the classes or not","97741bdb":"print(f\"Accuracy = {metrics.accuracy_score(y_test, y_pred)}\")\nprint(metrics.classification_report(y_test, y_pred))","d7914a8f":"result = [class_map[i] for i in y_pred]\nprint(\"prediction values\")\nprint(result)\nprint()\nprint(\"Real test y values\")\nprint([class_map[i] for i in list(y_test)])","8cbb2c12":"final_prediction_df = X_test\nfinal_prediction_df['class_type'] = [class_map[i] for i in y_test]\nfinal_prediction_df['pred_class_type'] = [class_map[i] for i in y_pred]\nfinal_prediction_df","699485f8":"X_train.columns","f6330657":"X_train.head(1)","3d1e4480":"#tried manually with human feature values\npredd = {}\npredd['HAIR'] = 1\npredd['FEATHERS'] = 0\npredd['EGGS'] = 0\npredd['MILK'] = 1\npredd['AIRBORNE'] = 0\npredd['AQUATIC'] = 0\npredd['PREDATOR'] = 1\npredd['TOOTHED'] = 1\npredd['BACKBONE'] = 1\npredd['BREATHES'] = 1\npredd['VENOMOIS'] = 0\npredd['FINS'] = 0\npredd['LEGS'] = 2\npredd['TAIL'] = 0\npredd['DOMESTIC'] = 0\npredd['CATSIZE'] = 0\n\npred_df = pd.DataFrame(data=predd, index=['value'])\ncustom_pred = clf.predict(pred_df)","1981be31":"class_map[custom_pred[0]]","244d72dd":"class_map","53706d74":"from sklearn.tree import plot_tree\n\nfig = plt.figure(figsize=(25,20))\n_ = plot_tree(clf, feature_names=X_train.columns,  \n                class_names=class_types, filled=True)\n","104a70af":"from sklearn.tree import export_graphviz\nimport graphviz\n# DOT data\ndot_data = export_graphviz(clf, out_file=None, \n                                feature_names=X_train.columns,  \n                                class_names=class_types,\n                                filled=True)\n\n# Draw graph\ngraph = graphviz.Source(dot_data, format=\"png\") \ngraph\n","b8b9aa2e":"graph.render(\"decision_tree_graphivz\")","ec095fb3":"## Classification using Decision Tree Classifier","61f525e4":"#### The zoo data from each class needs to be equally ditributed among Train and Test Data ","a84abda8":"## Equal division of data w.r.t animal Type\n\nWhile normall Splitting the data into Training and Test sets , there might be a case when all <br\/>\nthe 4 Amphibians are in Train set or all the Amphibians are in Test set which will reduce our accuracy<br\/>\nSo, what we will do is seprately split the data acoording to the animal type.\n","9bced475":"# And this is how we are getting a perfect accuracy of 100% with split of 0.8 or greater\nDidn't try for split<0.8 You can check and update in the comment<br\/>\nThough sometimes the accuracy might lower but there's a very small difference between the amphibian and reptiles.<br\/>\nBut restarting the kernel and running all again can make the accuracy back to 100%! \n### If you like this notebook Do UPVOTE!!!","a9c09210":"# This Notebook is using Decision Tree Classifier\n# with Accuracy of 100%"}}