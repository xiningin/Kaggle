{"cell_type":{"61b300ff":"code","f5e4e075":"code","52a4afe0":"code","4823ad51":"code","d5dc697f":"code","9bd72cbe":"code","ac7c38c5":"code","b7b46bdb":"code","c9470afc":"code","cd86b73d":"code","2f50b1d9":"code","fe4421d7":"code","6f47c444":"code","33cebc24":"code","dccf07f8":"code","1002071f":"code","cf7c13ea":"code","f81d8ecd":"code","a3e9ca13":"code","9d17dc93":"code","088ceec2":"code","e4dd4662":"code","7d3fc63e":"code","bf5aa253":"code","eabe21cb":"markdown","939e7ffc":"markdown","64cabf8f":"markdown","f11d68a0":"markdown","fb2bfaa9":"markdown","13957093":"markdown","36dcbf13":"markdown","c9a6d2ec":"markdown","5aa49419":"markdown","068aff3d":"markdown"},"source":{"61b300ff":"import sys\nsys.path = [\n    '..\/input\/geffnet-20200820'  \n] + sys.path\n\nimport numpy as np, pandas as pd, gc\nimport cv2, matplotlib.pyplot as plt\nimport cudf, cuml, cupy\nfrom cuml.feature_extraction.text import TfidfVectorizer\nfrom cuml.neighbors import NearestNeighbors\n\nimport albumentations\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport geffnet\nfrom transformers import *","f5e4e075":"COMPUTE_CV = True\n\ntest = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')","52a4afe0":"train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ntmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\ntrain['target'] = train.label_group.map(tmp)\nprint('train shape is', train.shape )\ntrain.head()","4823ad51":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof'] = train.image_phash.map(tmp)","d5dc697f":"def getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]) )\n        return 2*n \/ (len(row.target)+len(row[col]))\n    return f1score","9bd72cbe":"train['f1'] = train.apply(getMetric('oof'),axis=1)\nprint('CV score for baseline =',train.f1.mean())","ac7c38c5":"if COMPUTE_CV:\n    test = pd.read_csv('..\/input\/shopee-folds\/train_fold.csv')\n#     test = test[test.fold==0]\n    test_gf = cudf.DataFrame(test)\n    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )\nelse:\n    test = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    test_gf = cudf.read_csv('..\/input\/shopee-product-matching\/test.csv')\n    print('Test shape is', test_gf.shape )\ntest_gf.head()","b7b46bdb":"import os\n\ndef get_transforms(img_size=256):\n    return  albumentations.Compose([\n                albumentations.Resize(300, 300),\n                albumentations.CenterCrop(img_size,img_size, p=1.0),\n#                 albumentations.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n                albumentations.Normalize()\n            ])\n\n\nclass LandmarkDataset(Dataset):\n    def __init__(self, csv, split, mode, transforms=get_transforms(img_size=256), tokenizer=None):\n\n        self.csv = csv.reset_index()\n        self.split = split\n        self.mode = mode\n        self.transform = transforms\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        \n        text = row.title\n        \n        image = cv2.imread(row.filepath)\n        image = image[:, :, ::-1]\n        \n        res0 = self.transform(image=image)\n        image0 = res0['image'].astype(np.float32)\n        image = image0.transpose(2, 0, 1)        \n\n        text = self.tokenizer(text, padding='max_length', truncation=True, max_length=16, return_tensors=\"pt\")\n        input_ids = text['input_ids'][0]\n        attention_mask = text['attention_mask'][0]\n\n        if self.mode == 'test':\n            return torch.tensor(image), input_ids, attention_mask\n        else:\n            return torch.tensor(image), input_ids, attention_mask, torch.tensor(row.label_group)","c9470afc":"tokenizer = AutoTokenizer.from_pretrained('..\/input\/bert-base-uncased')","cd86b73d":"if not COMPUTE_CV: \n    df_sub = pd.read_csv('..\/input\/shopee-product-matching\/test.csv')\n\n    df_test = df_sub.copy()\n    df_test['filepath'] = df_test['image'].apply(lambda x: os.path.join('..\/input\/shopee-product-matching\/', 'test_images', x))\n\n    dataset_test = LandmarkDataset(df_test, 'test', 'test', transforms=get_transforms(img_size=256), tokenizer=tokenizer)\n    test_loader = DataLoader(dataset_test, batch_size=16, num_workers=4)\n\n    print(len(dataset_test),dataset_test[0])\nelse:\n    df_sub = test\n\n    df_test = df_sub.copy()\n    df_test['filepath'] = df_test['image'].apply(lambda x: os.path.join('..\/input\/shopee-product-matching\/', 'train_images', x))\n\n    dataset_test = LandmarkDataset(df_test, 'test', 'test', transforms=get_transforms(img_size=256), tokenizer=tokenizer)\n    test_loader = DataLoader(dataset_test, batch_size=16, num_workers=4)\n\n    print(len(dataset_test),dataset_test[0])","2f50b1d9":"class ArcMarginProduct_subcenter(nn.Module):\n    def __init__(self, in_features, out_features, k=3):\n        super().__init__()\n        self.weight = nn.Parameter(torch.FloatTensor(out_features*k, in_features))\n        self.reset_parameters()\n        self.k = k\n        self.out_features = out_features\n        \n    def reset_parameters(self):\n        stdv = 1. \/ math.sqrt(self.weight.size(1))\n        self.weight.data.uniform_(-stdv, stdv)\n        \n    def forward(self, features):\n        cosine_all = F.linear(F.normalize(features), F.normalize(self.weight))\n        cosine_all = cosine_all.view(-1, self.out_features, self.k)\n        cosine, _ = torch.max(cosine_all, dim=2)\n        return cosine \n    \nsigmoid = torch.nn.Sigmoid()\n\nclass Swish(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\nclass Swish_module(nn.Module):\n    def forward(self, x):\n        return Swish.apply(x)\n\n    \n \n    \nclass enet_arcface_FINAL(nn.Module):\n\n    def __init__(self, enet_type, out_dim):\n        super(enet_arcface_FINAL, self).__init__()\n        self.bert = AutoModel.from_pretrained('..\/input\/bert-base-uncased')\n        self.enet = geffnet.create_model(enet_type.replace('-', '_'), pretrained=None)\n        self.feat = nn.Linear(self.enet.classifier.in_features+self.bert.config.hidden_size, 512)\n        self.swish = Swish_module()\n        self.dropout = nn.Dropout(0.5)\n        self.metric_classify = ArcMarginProduct_subcenter(512, out_dim)\n        self.enet.classifier = nn.Identity()\n \n    def forward(self, x,input_ids, attention_mask):\n        x = self.enet(x)\n        text = self.bert(input_ids=input_ids, attention_mask=attention_mask)[1]\n        x = torch.cat([x, text], 1)\n        x = self.swish(self.feat(x))\n        return F.normalize(x), self.metric_classify(x)\n    \ndef load_model(model, model_file):\n    state_dict = torch.load(model_file)\n    if \"model_state_dict\" in state_dict.keys():\n        state_dict = state_dict[\"model_state_dict\"]\n    state_dict = {k[7:] if k.startswith('module.') else k: state_dict[k] for k in state_dict.keys()}\n#     del state_dict['metric_classify.weight']\n    model.load_state_dict(state_dict, strict=True)\n    print(f\"loaded {model_file}\")\n    model.eval()    \n    return model","fe4421d7":"import math\nfrom tqdm import tqdm\n\nWGT = '..\/input\/shopee-b0-bert\/b0ns_256_bert_20ep_fold0_epoch27.pth'\n\nmodel = enet_arcface_FINAL('tf_efficientnet_b0_ns', out_dim=11014).cuda()\nmodel = load_model(model, WGT)\n\n\nembeds = []\n\nwith torch.no_grad():\n    for img, input_ids, attention_mask in tqdm(test_loader): \n        img, input_ids, attention_mask = img.cuda(), input_ids.cuda(), attention_mask.cuda()\n        feat, _ = model(img, input_ids, attention_mask)\n        image_embeddings = feat.detach().cpu().numpy()\n        embeds.append(image_embeddings)\n\n    \ndel model\n_ = gc.collect()\nimage_embeddings = np.concatenate(embeds)\nprint('image embeddings shape',image_embeddings.shape)","6f47c444":"KNN = 50\nif len(test)==3: KNN = 2\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(image_embeddings)","33cebc24":"image_embeddings = cupy.array(image_embeddings)\npreds = []\nCHUNK = 1024*4\n\nprint('Finding similar images...')\nCTS = len(image_embeddings)\/\/CHUNK\nif len(image_embeddings)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(image_embeddings))\n    print('chunk',a,'to',b)\n   \n    cts = cupy.matmul(image_embeddings, image_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n#         print(sorted(cts[k,], reverse=True))\n        IDX = cupy.where(cts[k,]>0.5)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)","dccf07f8":"test['preds2'] = preds\ntest.head()","1002071f":"print('Computing text embeddings...')\nmodel = TfidfVectorizer(stop_words=None, \n                        binary=True, \n                        max_features=25000)\ntext_embeddings = model.fit_transform(test_gf.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","cf7c13ea":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(test)\/\/CHUNK\nif len(test)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(test))\n    print('chunk',a,'to',b)\n    \n    #COSINE SIMILARITY DISTANCE\n    cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        IDX = cupy.where(cts[k,]>0.75)[0]\n        o = test.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)","f81d8ecd":"test['preds'] = preds\ntest.head()","a3e9ca13":"tmp = test.groupby('image_phash').posting_id.agg('unique').to_dict()\ntest['preds3'] = test.image_phash.map(tmp)\ntest.head()","9d17dc93":"def combine_for_sub(row):\n    x = np.concatenate([row.preds, row.preds2, row.preds3])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.preds, row.preds2, row.preds3])\n    return np.unique(x)","088ceec2":"if COMPUTE_CV:\n    tmp = test.groupby('label_group').posting_id.agg('unique').to_dict()\n    test['target'] = test.label_group.map(tmp)\n    test['oof'] = test.apply(combine_for_cv,axis=1)\n    test['f1'] = test.apply(getMetric('oof'),axis=1)\n    print('CV Score =', test.f1.mean() )\n\ntest['matches'] = test.apply(combine_for_sub,axis=1)","e4dd4662":"print(\"CV for image :\", round(test.apply(getMetric('preds2'),axis=1).mean(), 3))\nprint(\"CV for text  :\", round(test.apply(getMetric('preds'),axis=1).mean(), 3))\nprint(\"CV for phash :\", round(test.apply(getMetric('preds3'),axis=1).mean(), 3))","7d3fc63e":"test","bf5aa253":"test[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","eabe21cb":"# Use Phash Feature\nWe will predict all items with the same phash as duplicates","939e7ffc":"# Use Image Embeddings\nTo prevent memory errors, we will compute image embeddings in chunks. And we will find similar images with RAPIDS cuML KNN in chunks.","64cabf8f":"# Load Train Data\nFirst we load the train data and create a target column of ground truths to help us compute CV score. Note how the variable `COMPUTE_CV` will change to `False` when we **submit** this notebook but it is `True` now because you are reading a **commit** notebook.","f11d68a0":"# Load Libraries","fb2bfaa9":"# Use Text Embeddings\nTo prevent memory errors, we will find similar titles in chunks. To faciliate this, we will use cosine similarity between text embeddings instead of KNN.","13957093":"# Compute CV Score\nThis simple model scores a high CV of 0.700+!","36dcbf13":"thanks to https:\/\/www.kaggle.com\/cdeotte\/part-2-rapids-tfidfvectorizer-cv-0-700","c9a6d2ec":"# Compute RAPIDS Model CV and Infer Submission\nWe will now use image embeddings, text embeddings, and phash to create a better model with better CV. We will also infer submission csv.\n\nNote how the variable `COMPUTE_CV` is only `True` when we **commit** this notebook. Right now you are reading a **commit** notebook, so we see test replaced with train and computed CV score. When we **submit** this notebook, the variable `COMPUTE_CV` will be `False` and the **submit** notebook will **not** compute CV. Instead it will load the real test dataset with 70,000 rows and find duplicates in the real test dataset.","5aa49419":"# Compute Baseline CV Score\nA baseline is to predict all items with the same `image_phash` as being duplicate. Let's calcuate the CV score for this submission.","068aff3d":"# Write Submission CSV\nIn this notebook, the submission file below looks funny containing train information. But when we submit this notebook, the size of `test.csv` dataframe will be longer than 3 rows and the variable `COMPUTE_CV` will subsequently set to `False`. Then our submission notebook will compute the correct matches using the real test dataset and our submission csv for LB will be ok."}}