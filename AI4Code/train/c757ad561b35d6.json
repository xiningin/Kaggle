{"cell_type":{"10c8c34a":"code","d12fd592":"code","27a10f16":"code","d3b008d1":"code","55f8fcf5":"code","d532e8dc":"code","9992e1d7":"code","ce178552":"code","dd5cb761":"code","8e8d3737":"code","06a9fbe2":"markdown","dfa472b2":"markdown","48b581ff":"markdown","e1a4c5e6":"markdown","3192f98b":"markdown","5f066f99":"markdown","94e68649":"markdown","4d9cdd3e":"markdown","8aba89f7":"markdown"},"source":{"10c8c34a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d12fd592":"import tensorflow as tf\n\ntf.__version__","27a10f16":"def load_data():\n    with np.load(\"..\/input\/mnist.npz\") as f:\n        x_train, y_train = f['x_train'], f['y_train']\n        x_test, y_test = f['x_test'], f['y_test']\n    return (x_train, y_train), (x_test, y_test)\n\n(x_train, y_train), (x_test, y_test) = load_data()\nprint(x_train[0])","d3b008d1":"import matplotlib.pyplot as plt\n\nplt.imshow(x_train[0], cmap = plt.cm.binary)\nplt.show();","55f8fcf5":"x_train = tf.keras.utils.normalize(x_train, axis=1)\nx_test = tf.keras.utils.normalize(x_test, axis=1)\nprint(x_train[0])","d532e8dc":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\nmodel.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))","9992e1d7":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","ce178552":"model.fit(x_train, y_train, epochs=10)","dd5cb761":"val_loss, val_acc = model.evaluate(x_test, y_test)\nprint(val_loss, val_acc)\n\n# Saving Model\n# model.save('num_reader.model')\n\n# Loading Model\n# model = tf.keras.models.load_models('num_reader.model')","8e8d3737":"predictions = model.predict([x_test])\n\nprint(np.argmax(predictions[35]))\nplt.imshow(x_test[35], cmap=plt.cm.binary)\nplt.show();","06a9fbe2":"## Model Predictions","dfa472b2":"## Plot Data\nThis is to show the shape of the sample set` x_train[0]`.","48b581ff":"## Build the Model","e1a4c5e6":"## Model Evaluation ","3192f98b":"## Model Parameters ","5f066f99":"## Scale the Data\nNormalizing the MNIST dataset","94e68649":"# MNIST - TensorFlow Basics\n\nThe objective of this notebook is to build a basic model for MNIST dataset using TensorFlow. This code is from [pythonprogramming.net](https:\/\/pythonprogramming.net\/introduction-deep-learning-python-tensorflow-keras\/)","4d9cdd3e":"## Train the Model","8aba89f7":"## MNIST Data\nLoad MNIST dataset. MNIST data is a 28 x 28 images of hand-written digits from 0 to 9."}}