{"cell_type":{"35d9792c":"code","6806ba58":"code","4ca411eb":"code","94459163":"code","792bb22d":"code","b7093706":"code","bc0f68a3":"code","d1de435a":"code","ca39f86f":"code","eeae1531":"markdown","f016b262":"markdown","53d64529":"markdown","943075c8":"markdown","47f6be31":"markdown","a9621506":"markdown","c81f9f6d":"markdown","5a114528":"markdown","af44331b":"markdown","5ea4f13e":"markdown"},"source":{"35d9792c":"import numpy as np\nfrom sklearn.metrics import confusion_matrix\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os\n%matplotlib inline\n\nimport tensorflow\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n\nprint(f'Tensorflow version: {tensorflow.__version__}')\nprint(f'Keras version: {keras.__version__}')","6806ba58":"# Images are in \"\/kaggle\/input\/images-of-geometric-shapes-circlesquaretriangle\/shapes\/\" folder\ndata_folder = '\/kaggle\/input\/images-of-geometric-shapes-circlesquaretriangle\/shapes\/'\n\n# Get the class names\nclasses = os.listdir(data_folder)\nclasses.sort()\nprint(f'Total classes are: {len(classes)}')\n\n# Show the first image in each folder\nfig = plt.figure(figsize=(10,6))\ni = 0\nfor sub_dir in os.listdir(data_folder):\n    i+=1\n    img_file = os.listdir(os.path.join(data_folder,sub_dir))[0]\n    img_path = os.path.join(data_folder, sub_dir, img_file)\n    img = mpimg.imread(img_path)\n    a = fig.add_subplot(1, len(classes), i)\n    a.axis('off')\n    imgplot = plt.imshow(img)\n    a.set_title(img_file)\nplt.show()                       ","4ca411eb":"# Here we are going to use tensorflow \"ImageDataGenerator\" module.\n\nimg_size = (128, 128)\nbatch_size = 30\n\nprint(\"Getting Data...\")\ndatagen = ImageDataGenerator(rescale=1.\/255, # normalize pixel values\n                             validation_split=0.3) # hold back 30% of the images for validation\n\nprint(\"Preparing training dataset...\")\ntrain_generator = datagen.flow_from_directory(\n    data_folder,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training') # set as training data\n\nprint(\"Preparing validation dataset...\")\nvalidation_generator = datagen.flow_from_directory(\n    data_folder,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation') # set as validation data\n\nclassnames = list(train_generator.class_indices.keys())\nprint('Data generators ready')","94459163":"# Define a CNN classifier network\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n\n# Define the model as a sequence of layers\nmodel = Sequential()\n\n# The input layer accepts an image and applies a convolution that uses 32 6x6 filters and a rectified linear unit activation function\nmodel.add(Conv2D(32, (6, 6), input_shape=train_generator.image_shape, activation='relu'))\n\n# Next we'll add a max pooling layer with a 2x2 patch\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# We can add as many layers as we think necessary - here we'll add another convolution and max pooling layer\nmodel.add(Conv2D(32, (6, 6), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# And another set\nmodel.add(Conv2D(32, (6, 6), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# A dropout layer randomly drops some nodes to reduce inter-dependencies (which can cause over-fitting)\nmodel.add(Dropout(0.2))\n\n# Flatten the feature maps \nmodel.add(Flatten())\n\n# Generate a fully-cpnnected output layer with a predicted probability for each class\n# (softmax ensures all probabilities sum to 1)\nmodel.add(Dense(train_generator.num_classes, activation='softmax'))\n\n# With the layers defined, we can now compile the model for categorical (multi-class) classification\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nprint(model.summary())","792bb22d":"# Train the model over 5 epochs using 30-image batches and using the validation holdout dataset for validation\nnum_epochs = 5\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ batch_size,\n    epochs = num_epochs)","b7093706":"epoch_nums = range(1,num_epochs+1)\ntraining_loss = history.history[\"loss\"]\nvalidation_loss = history.history[\"val_loss\"]\nplt.figure(figsize=(10,6))\nplt.plot(epoch_nums, training_loss)\nplt.plot(epoch_nums, validation_loss)\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['training', 'validation'], loc='upper right')\nplt.show()","bc0f68a3":"# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n\nprint(\"Generating predictions from validation data...\")\n# Get the image and label arrays for the first batch of validation data\nx_test = validation_generator[0][0]\ny_test = validation_generator[0][1]\n\n# Use the model to predict the class\nclass_probabilities = model.predict(x_test)\n\n# The model returns a probability value for each class\n# The one with the highest probability is the predicted class\npredictions = np.argmax(class_probabilities, axis=1)\n\n# The actual labels are hot encoded (e.g. [0 1 0], so get the one with the value 1\ntrue_labels = np.argmax(y_test, axis=1)\n\n# Plot the confusion matrix\ncm = confusion_matrix(true_labels, predictions)\nplt.figure(figsize=(10,6))\nplt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\nplt.colorbar()\ntick_marks = np.arange(len(classnames))\nplt.xticks(tick_marks, classnames, rotation=85)\nplt.yticks(tick_marks, classnames)\nplt.xlabel(\"Actual Shape\")\nplt.ylabel(\"Predicted Shape\")\nplt.show()","d1de435a":"# Save the trained model\nmodelFileName = 'shape_classifier.h5'\nmodel.save(modelFileName)\ndel model  # deletes the existing model variable\nprint('model saved as', modelFileName) # Save it at \/kaggle\/working\/shape_classifier.h5","ca39f86f":"from tensorflow.keras import models\nimport numpy as np\nfrom random import randint\n\n# Function to predict the class of an image\ndef predict_image(classifier, image):\n    from tensorflow import convert_to_tensor\n    # The model expects a batch of images as input, so we'll create an array of 1 image\n    imgfeatures = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n\n    # We need to format the input to match the training data\n    # The generator loaded the values as floating point numbers\n    # and normalized the pixel values, so...\n    imgfeatures = imgfeatures.astype('float32')\n    imgfeatures \/= 255\n    \n    # Use the model to predict the image class\n    class_probabilities = classifier.predict(imgfeatures)\n    \n    # Find the class predictions with the highest predicted probability\n    index = int(np.argmax(class_probabilities, axis=1)[0])\n    return index\n\n# Function to create a random image (of a square, circle, or triangle)\ndef create_image (size, shape):\n    from random import randint\n    import numpy as np\n    from PIL import Image, ImageDraw\n    \n    xy1 = randint(10,40)\n    xy2 = randint(60,100)\n    col = (randint(0,200), randint(0,200), randint(0,200))\n\n    img = Image.new(\"RGB\", size, (255, 255, 255))\n    draw = ImageDraw.Draw(img)\n    \n    if shape == 'circle':\n        draw.ellipse([(xy1,xy1), (xy2,xy2)], fill=col)\n    elif shape == 'triangle':\n        draw.polygon([(xy1,xy1), (xy2,xy2), (xy2,xy1)], fill=col)\n    else: # square\n        draw.rectangle([(xy1,xy1), (xy2,xy2)], fill=col)\n    del draw\n    \n    return np.array(img)\n\n# Create a random test image\nclassnames = os.listdir(os.path.join('\/kaggle\/input\/images-of-geometric-shapes-circlesquaretriangle', 'shapes'))\nclassnames.sort()\nimg = create_image ((128,128), classnames[randint(0, len(classnames)-1)])\nplt.axis('off')\nplt.imshow(img)\n\n# Use the classifier to predict the class\nmodel = models.load_model('\/kaggle\/working\/shape_classifier.h5') # loads the saved model\nclass_idx = predict_image(model, img)\nprint (classnames[class_idx])","eeae1531":"# Load and Explore the Data","f016b262":"# Evaluate model performance\nWe can see the final accuracy based on the test data, but typically we'll want to explore performance metrics in a little more depth. Let's plot a confusion matrix to see how well the model is predicting each class.","53d64529":"# View the loss history\nWe tracked average training and validation loss history for each epoch. We can plot these to verify that loss reduced as the model was trained, and to detect overfitting (which is indicated by a continued drop in training loss after validation loss has levelled out or started to increase).","943075c8":"# Use the trained model\nWhen you have a new image, you can use the saved model to predict its class.","47f6be31":"# Prepare the Data\n* Before we can train the model, we need to prepare the data. We'll divide the feature values by 255 to normalize them as floating point values between 0 and 1, and we'll split the data so that we can use 70% of it to train the model, and hold back 30% to validate it. \n* When loading the data, the data generator will assing \"hot-encoded\" numeric labels to indicate which class each image belongs to based on the subfolders in which the data is stored. In this case, there are three subfolders - circle, square, and triangle, so the labels will consist of three 0 or 1 values indicating which of these classes is associated with the image - for example the label [0 1 0] indicates that the image belongs to the second class (square).","a9621506":"# Train the model\nWith the layers of the CNN defined, we're ready to train the model using our image data. In the example below, we use 5 iterations (epochs) to train the model in 30-image batches, holding back 30% of the data for validation. After each epoch, the loss function measures the error (loss) in the model and adjusts the weights (which were randomly generated for the first iteration) to try to improve accuracy.","c81f9f6d":"# Introduction\nA convolutional neural network is a kind of neural network that extracts features from matrices of numeric values (often images) by convolving multiple filters over the matrix values to apply weights and identify patterns, such as edges, corners, and so on in an image. The numeric representations of these patterns are then passed to a fully-connected neural network layer to map the features to specific classes.\n\nThere are several commonly used frameworks for creating CNNs. In this notebook, we'll build a simple example CNN using Tensorflow.\n\nIn this exercise, we will train a CNN-based classification model that can classify images of geometric shapes (Circle, Square, Triangle)\n\nNote: This is my study notebook, for original notebook please refer https:\/\/github.com\/satishgunjal\/ml-basics\/blob\/master\/05b%20-%20Convolutional%20Neural%20Networks%20(Tensorflow).ipynb\n\n# Import the Libraries","5a114528":"# Save the Trained model\nNow that you've trained a working model, you can save it (including the trained weights) for use later.","af44331b":"# Challenge: Safari Image Classification\nHopefully this notebook has shown you the main steps in training and evaluating a CNN. Why not put what you've learned into practice with our Safari image classification challenge in the [\/challenges\/05 - Safari CNN Challenge.ipynb](https:\/\/render.githubusercontent.com\/view\/challenges\/05%20-%20Safari%20CNN%20Challenge.ipynb) notebook?","5ea4f13e":"# Define the CNN\nNow we're ready to create our model. This involves defining the layers for our CNN, and compiling them for multi-class classification."}}