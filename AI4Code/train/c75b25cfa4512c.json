{"cell_type":{"4ffbf353":"code","b5cecff3":"code","369bd5a7":"code","85ea9ac1":"code","b3e049bc":"code","2aec9eaf":"code","d53d331d":"code","9554048d":"code","96b8cbb5":"code","17777a33":"code","698f24a2":"code","4527353f":"code","e65b1757":"code","5d475c35":"code","bd6295f1":"code","49448f59":"markdown","b8f41c96":"markdown","21da5298":"markdown","309bd50a":"markdown","28292125":"markdown","60a5d1e1":"markdown","c8ea7ecb":"markdown","4e700eea":"markdown","5739921a":"markdown","ec8d22bd":"markdown","fb38f8b6":"markdown","f10ce292":"markdown","290fdaae":"markdown","f9fad63f":"markdown","16ce1ebd":"markdown"},"source":{"4ffbf353":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nimport cv2\nfrom glob import glob\n\nimport tensorflow as tf\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","b5cecff3":"# Set parameters\nIMAGE_SIZE = (256, 256)","369bd5a7":"mask_files = glob('..\/input\/lgg-mri-segmentation\/kaggle_3m\/*\/*_mask*')\ntrain_files = [file.replace('_mask', '') for file in mask_files]","85ea9ac1":"def diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    return '1' if value > 0 else '0'\ndf = pd.DataFrame({\"image_path\": train_files,\n                   \"mask_path\": mask_files,\n                  \"diagnosis\":[diagnosis(x) for x in mask_files]})\ndf.head()","b3e049bc":"ax = df['diagnosis'].value_counts().plot(kind='bar', stacked=True, figsize=(10,6), color=['blue', 'red'])\nax.set_title('Data Distribution')\nax.set_ylabel('Total Images', fontsize=15)\nax.set_xticklabels(['No Tumor', 'Tumor'], fontsize=12, rotation=0)\nfor i, rows in enumerate(df['diagnosis'].value_counts().values):\n    ax.annotate(int(rows), xy=(i, rows+12), ha='center', fontweight='bold', fontsize=15)","2aec9eaf":"df_positive = df[df['diagnosis']=='1'].sample(5).values\ndf_negative = df[df['diagnosis']=='0'].sample(5).values\n\ndef show_data(df, positive=True):\n    images = []\n    masks = []\n    for data in df:\n        img = cv2.imread(data[0])\n        mask = cv2.imread(data[1])\n        images.append(img)\n        masks.append(mask)\n    images = np.hstack(np.array(images))\n    masks = np.hstack(np.array(masks))\n    \n    fig = plt.figure(figsize=(25,25))\n    if positive:\n        grid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.5)\n    else:\n        grid = ImageGrid(fig, 111, nrows_ncols=(2,1), axes_pad=0.5)\n    grid[0].imshow(images)\n    grid[0].set_title('Images', fontsize=15)\n    grid[0].axis('off')\n    grid[1].imshow(masks)\n    grid[1].set_title('Masks', fontsize=15)\n    grid[1].axis('off')\n    if positive:\n        grid[2].imshow(images)\n        grid[2].imshow(masks, alpha=0.4)\n        grid[2].set_title('Brain MRI with mask', fontsize=15)\n        grid[2].axis('off')\n        \nshow_data(df_positive)\nshow_data(df_negative, positive=False)","d53d331d":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.15)\ndf_train, df_val = train_test_split(df_train, test_size=0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","9554048d":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"image_path\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask_path\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img \/ 255.\n    mask = mask \/ 255.\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","96b8cbb5":"smooth=1.\n\ndef dice_coef(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    union = K.sum(y_true) + K.sum(y_pred)\n    return (2.0 * intersection + smooth) \/ (union + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef bce_dice_loss(y_true, y_pred):\n    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return jac","17777a33":"def unet(input_size=(256,256,3)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n\n    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n\n    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n\n    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","698f24a2":"# Set parameters\nEPOCHS = 150\nBATCH_SIZE = 16\nlearning_rate = 1e-4","4527353f":"train_generator_args = dict(rotation_range=0.1,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=IMAGE_SIZE)\n    \nval_gen = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\n    \nmodel = unet(input_size=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n\n\n\nopt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\nmodel.compile(optimizer=opt, loss=bce_dice_loss, metrics=[iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('unet_brainMRI_seg.hdf5', verbose=0, save_best_only=True),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-11),\n            EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=15)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) \/ BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = val_gen,\n                    validation_steps=len(df_val) \/ BATCH_SIZE)","e65b1757":"plt.figure(figsize=(8,15))\nplt.subplot(3,1,1)\nplt.plot(model.history.history['loss'], 'b-', label='train_loss')\nplt.plot(model.history.history['val_loss'], 'r-', label='val_loss')\nplt.legend(loc='best')\nplt.title('Loss')\n\nplt.subplot(3,1,2)\nplt.plot(model.history.history['iou'], 'b-', label='train_iou')\nplt.plot(model.history.history['val_iou'], 'r-', label='val_iou')\nplt.legend(loc='best')\nplt.title('IoU')\n\nplt.subplot(3,1,3)\nplt.plot(model.history.history['dice_coef'], 'b-', label='train_dice_coef')\nplt.plot(model.history.history['val_dice_coef'], 'r-', label='val_dice_coef')\nplt.legend(loc='best')\nplt.title('Dice Coef')","5d475c35":"test_gen = train_generator(df_test, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\nresults = model.evaluate(test_gen, steps=len(df_test) \/ BATCH_SIZE)\nprint(\"Test IOU: \",results[1])\nprint(\"Test Dice Coefficent: \",results[2])","bd6295f1":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['image_path'].iloc[index])\n    img = cv2.resize(img ,IMAGE_SIZE)\n    img = img \/ 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","49448f59":"### Define UNet Model","b8f41c96":"## 4. Training","21da5298":"## 5. Evaluate the model","309bd50a":"### Segmentation Quality Metric","28292125":"### Visualize the Result","60a5d1e1":"### Visualize the model performance","c8ea7ecb":"![](https:\/\/www.pyimagesearch.com\/wp-content\/uploads\/2016\/09\/iou_equation.png)![](https:\/\/d3i71xaburhd42.cloudfront.net\/8575e8beef47bd2880c92f54a749f933db983e56\/2-Table1-1.png)","4e700eea":"### If you find this work useful, please don't forget upvoting","5739921a":"## 1. Import necessary libraries","ec8d22bd":"![](https:\/\/i.imgur.com\/lKZGO0C.png)","fb38f8b6":"### Visualize MRI with Mask","f10ce292":"### Split data into Train, Validation and Test Set","290fdaae":"## 3. U-Net Model","f9fad63f":"## 2. Create DataFrame","16ce1ebd":"### Data Generator, Data Augmentation and Adjust Data"}}