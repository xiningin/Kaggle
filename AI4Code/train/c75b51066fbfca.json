{"cell_type":{"a88a2dfa":"code","bb6550b9":"code","ca547dd0":"code","4d2d99fe":"code","c6abbd93":"code","1a58d07c":"code","670c37f1":"code","4276d209":"code","def74d24":"code","0daf91a8":"code","b0ac874e":"code","98ad4d0e":"code","16191c2b":"code","c8c4ac79":"markdown"},"source":{"a88a2dfa":"!pip install efficientnet_pytorch\nfrom prettytable import PrettyTable\n\ndef count_parameters(model):\n    table = PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in model.named_parameters():\n        if not parameter.requires_grad: continue\n        param = parameter.numel()\n        table.add_row([name, param])\n        total_params+=param\n    print(table)\n    print(f\"Total Trainable Params: {total_params}\")\n    return total_params","bb6550b9":"import torch\nfrom torch import nn\nimport cv2\nimport numpy as np\nimport time\nimport random\nfrom tqdm import tqdm_notebook as tqdm\nimport pandas as pd\nimport os\n\nfrom efficientnet_pytorch import EfficientNet\nfrom torchvision import models\nfrom torch.nn import functional as F\n\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\nimport albumentations as A","ca547dd0":"#paramters\ntrain_dir= '..\/input\/cassava-leaf-disease-classification\/train_images'\ntest_dir = '..\/input\/cassava-leaf-disease-classification\/test_images'\ncfg = {\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'epochs':25,\n    'batch_size':68,\n    'lr':0.0001,\n    'input_size':256,\n    \n}","4d2d99fe":"imagenames = [name for name in os.listdir(train_dir)]\ncsv = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\nprint(csv.head(10))\nprint(csv['label'].unique())","c6abbd93":"def add_guassian_noise(image): \n    return IAAAdditiveGaussianNoise(p=1.0,loc=1.3,scale=(0,255),per_channel=True)(image=image)['image']\ndef cutout(image):\n    return A.augmentations.transforms.Cutout(num_holes=10, max_h_size=10, max_w_size=10, fill_value=0, always_apply=False, p=1.0)(image=image)['image']\ndef get_train_transforms():\n    return Compose([\n            RandomResizedCrop(cfg['input_size'], cfg['input_size'],scale=(0.3,1)),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.2),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n        ], p=1.)\n\ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(cfg['input_size'], cfg['input_size'], p=1.),\n            Resize(cfg['input_size'], cfg['input_size']),\n        ], p=1.)\n\n\ndef normalize_and_to_tensor(img):\n    transform = Compose([Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n                       ToTensorV2(p=1.0)],p=1.0)\n    return transform(image=img)['image']\n\n\nclass CASSAVA(Dataset):\n    def __init__(self,\n                 imagenames,\n                 csv,\n                 root_dir,\n                 input_size=cfg['input_size'],\n                 transforms=None,\n                 train=True,\n                contrastive = True):\n        self.imagenames = imagenames\n        self.csv = csv\n        self.root_dir = root_dir\n        self.input_size = input_size\n        self.transforms = transforms\n        self.train = train\n        self.contrastive = contrastive\n    def __len__(self):\n        return len(imagenames)\n    def get_onehot(self,label):\n        onehot = np.zeros(5)\n        onehot[label] = 1\n        return onehot\n    def __getitem__(self,idx):\n        imagename = self.imagenames[idx]\n        label = self.csv[self.csv['image_id']==imagename]['label']\n        label = self.get_onehot(label)\n        image = cv2.imread(self.root_dir+'\/'+imagename)\n        image = cv2.resize(image,(self.input_size,self.input_size))\n        image_aug1 = self.transforms(image=image)['image']\n        image_aug2 = self.transforms(image=image)['image']\n        if random.choice([1,2])==1:\n            image_aug1 = add_guassian_noise(image_aug1)\n            image_aug2 = cutout(image_aug2)\n        else:\n            image_aug2 = add_guassian_noise(image_aug2)\n            image_aug1 = cutout(image_aug1)\n        label = torch.from_numpy(label)\n        image = normalize_and_to_tensor(image)\n        image_aug1 = normalize_and_to_tensor(image_aug1)\n        image_aug2 = normalize_and_to_tensor(image_aug2)\n        #image_aug3 = normalize_and_to_tensor(image_aug3)\n        return image,image_aug1,image_aug2,label","1a58d07c":"train_transforms = get_train_transforms()\nt_dataset = CASSAVA(imagenames,csv,train_dir,transforms = train_transforms)\ntrain_loader = DataLoader(dataset=t_dataset, batch_size=cfg['batch_size'], shuffle=True, num_workers=2)","670c37f1":"backbone = models.resnet50(pretrained=False)\nmodules = list(backbone.children())[:-2]\nbackbone = nn.Sequential(*modules)\nprint(backbone)","4276d209":"class CLASSIFIER(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.effn = backbone\n        self.average = nn.AvgPool2d((8,8))\n        self.flatten = nn.Flatten()\n        \n    def forward(self,x):\n        x = self.effn(x)\n        x = self.average(x)\n        x = self.flatten(x)\n        #x = F.relu(self.projection(x))\n        return x\n    \nclass HEAD(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.dense1 = nn.Linear(2048,512)\n        self.dense2 = nn.Linear(512,2048)\n    def forward(self,x):\n        x = F.relu(self.dense1(x))\n        x = F.relu(self.dense2(x))\n        return x\n\nHead = HEAD()\nx = torch.randn((1,2048))\ny = Head(x)\nprint(y.size())\n\nmodel = CLASSIFIER()\nx = torch.randn((1,3,256,256))\ny = model(x)\nprint(y.size())","def74d24":"count_parameters(model)\nprint(\"##\"*12,'head')\ncount_parameters(Head)","0daf91a8":"def cosine_similarity(y_true,y_pred):\n    y_pred = y_pred.detach()\n    y_true = y_true\/(y_true.norm(dim=-1)[:,None]+1e-6)\n    y_pred = y_pred\/(y_pred.norm(dim=-1)[:,None]+1e-6)\n    loss = y_true*y_pred\n    loss = loss.sum(dim=-1)\n    return -loss","b0ac874e":"optimizer = torch.optim.Adam(model.parameters(), lr=cfg['lr'])\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, verbose=True)\nmodel.to(cfg['device'])\nHead.to(cfg['device'])\nfor epoch in range(cfg['epochs']):\n    \n    #epoch parameters\n    epoch_loss = 0\n    model.train()\n    start = time.time()\n    \n    for i,(image2,image3,image4,label) in enumerate(tqdm(train_loader,total=train_loader.__len__(),ncols = 500)):\n        \n        #image1 = image1.to(cfg['device'])\n        image2 = image2.to(cfg['device'])\n        image3 = image3.to(cfg['device'])\n        image4=  image4.to(cfg['device'])\n        #represent\n        rep3,rep4 =model(image3),model(image4)\n        h3,h4 = Head(rep3),Head(rep4)\n        \n        #negativity similarity\n        loss = (cosine_similarity(h3,rep4)+cosine_similarity(h4,rep3))\/2\n\n        #backprop\n        optimizer.zero_grad()\n        loss.mean().backward()\n        optimizer.step()\n        \n        epoch_loss+=loss.mean().item()\n\n    scheduler.step(epoch_loss\/(i+1))\n    print('Epoch {:03}: | Loss: {:.3f} | Training time: {}'.format(\n            epoch + 1,  \n            epoch_loss\/(i+1), \n            str(time.time() - start)[:7]))\n    torch.save(model.state_dict(), 'I_am_trained_{}_{}.pt'.format(epoch,epoch_loss\/(i+1)))","98ad4d0e":"del model, optimizer, train_loader, scheduler,Head\ntorch.cuda.empty_cache()","16191c2b":"csv.shape","c8c4ac79":"Hi I am Manoj Akondi from National Institute of technology, Calicut.\n## Intro to notebook:\nIn this notebook, I am trying for a contrastive learning approach to learn cool representations of our data. This notebook uses a new state of the art method [SIMSAIM](https:\/\/arxiv.org\/abs\/2011.10566).<br\/>\nSIMSAIM is a simple method where same network is used twice to compute the representations of different augmentations of same image and the similarity between the computed representations is maximized. While backpropagating through whole the network, the gradient flow is detached for one of the branch as shown below.\n![d.PNG](attachment:d.PNG)<br\/>\nSince we have lot of noise in our data, I thought of visualizing how noisy the data is!\nSo, I used t-sne on the representations obtained from this model and visualized in [this notebook](https:\/\/www.kaggle.com\/saimanojakondi\/explore-the-rep)."}}