{"cell_type":{"1608ae4a":"code","1d7e1ae9":"code","a4ec48d3":"code","9d1bb5f4":"code","94166887":"code","090d1ce5":"code","e52b850d":"code","b10fed34":"code","17b68994":"code","e7f379bf":"markdown","1ad3cf2b":"markdown","f48562c4":"markdown","6fc1d62a":"markdown","a2c535bd":"markdown","e0741621":"markdown"},"source":{"1608ae4a":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nimport random, math, cv2\nfrom tqdm import tqdm_notebook as tqdm\n\nimport torch\nfrom torch import nn\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import Compose, ToTensor\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport warnings\nwarnings.filterwarnings(\"ignore\")","1d7e1ae9":"MNIST_DATA_DIR = Path('\/kaggle\/working')\nMODEL_FILE = Path('best_source_weights_mnist.pth')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nbatch_size = 64\nepochs = 5","a4ec48d3":"def visualize_digits(dataset, k=80, mnistm=False, cmap=None, title=None):\n    \n    ncols = 20\n    indices = random.choices(range(len(dataset)), k=k)\n    nrows = math.floor(len(indices)\/ncols)\n    \n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(ncols,nrows+0.4), gridspec_kw=dict(wspace=0.1, hspace=0.1), subplot_kw=dict(yticks=[], xticks=[]))\n    axes_flat = axes.reshape(-1)\n    fig.suptitle(title, fontsize=20)\n    \n    for list_idx, image_idx in enumerate(indices[:ncols*nrows]):\n        ax = axes_flat[list_idx]\n        image = dataset[image_idx][0]\n        image = image.numpy().transpose(1, 2, 0)\n        ax.imshow(image, cmap=cmap)\n        \nclass GrayscaleToRgb:\n    \"\"\"Convert a grayscale image to rgb\"\"\"\n    def __call__(self, image):\n        image = np.array(image)\n        image = np.dstack([image, image, image])\n        return Image.fromarray(image)","9d1bb5f4":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.feature_extractor = nn.Sequential(\n            nn.Conv2d(3, 10, kernel_size=5),\n            nn.MaxPool2d(2),\n            nn.ReLU(),\n            nn.Conv2d(10, 20, kernel_size=5),\n            nn.MaxPool2d(2),\n            nn.Dropout2d(),\n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(320, 50),\n            nn.ReLU(),\n            nn.Dropout(),\n            nn.Linear(50, 10),\n            nn.LogSoftmax(),\n        )\n\n    def forward(self, x):\n        features = self.feature_extractor(x)\n        features = features.view(x.shape[0], -1)\n        logits = self.classifier(features)\n        return logits","94166887":"source_model = Net().to(device)\nif MODEL_FILE.exists():\n    source_model.load_state_dict(torch.load(MODEL_FILE))\n\ntrain_dataset = MNIST(MNIST_DATA_DIR \/ 'mnist', train=True, download=True, transform=Compose([GrayscaleToRgb(), ToTensor()]))\ntest_dataset = MNIST(MNIST_DATA_DIR \/ 'mnist', train=False, download=True, transform=Compose([GrayscaleToRgb(), ToTensor()]))\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=32, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=32, pin_memory=True)\n\nsource_optim = torch.optim.Adam(source_model.parameters(), lr=0.002)\ncriterion = nn.NLLLoss()","090d1ce5":"visualize_digits(dataset=train_dataset, k=120, cmap='gray', title='Sample MNIST Images')","e52b850d":"train_losses, train_accuracies, train_counter = [], [], []\ntest_losses, test_accuracies = [], []\ntest_counter = [idx*len(train_loader.dataset) for idx in range(0, epochs+1)]\n\ndef train(epoch):\n    train_loss, train_accuracy = 0, 0\n    source_model.train()\n    tqdm_bar = tqdm(train_loader, desc=f'Training Epoch {epoch} ', total=int(len(train_loader)))\n    for idx, (images, labels) in enumerate(tqdm_bar):\n        images, labels = images.to(device), labels.to(device)\n        source_optim.zero_grad()\n        with torch.set_grad_enabled(True):\n            outputs = source_model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            source_optim.step()\n        train_loss += loss.item()\n        train_losses.append(loss.item())\n        outputs = torch.argmax(outputs, dim=1).type(torch.FloatTensor).to(device)\n        train_batch_accuracy = torch.mean((outputs == labels).type(torch.FloatTensor)).item()\n        train_accuracy += train_batch_accuracy\n        train_accuracies.append(train_batch_accuracy)\n        tqdm_bar.set_postfix(train_loss=(train_loss\/(idx+1)), train_accuracy=train_accuracy\/(idx+1))\n        train_counter.append(idx*batch_size + images.size(0) + epoch*len(train_dataset))\n\ndef test():\n    test_loss, test_accuracy = 0, 0\n    source_model.eval()\n    tqdm_bar = tqdm(test_loader, desc=f'Testing ', total=int(len(test_loader)))\n    for idx, (images, labels) in enumerate(tqdm_bar):\n        images, labels = images.to(device), labels.to(device)\n        with torch.no_grad():\n            outputs = source_model(images)\n            loss = criterion(outputs, labels)\n        test_loss += loss.item()\n        outputs = torch.argmax(outputs, dim=1).type(torch.FloatTensor).to(device)\n        test_accuracy += torch.mean((outputs == labels).type(torch.FloatTensor)).item()\n        tqdm_bar.set_postfix(test_loss=(test_loss\/(idx+1)), test_accuracy=test_accuracy\/(idx+1))\n    test_losses.append(test_loss\/len(test_loader))\n    test_accuracies.append(test_accuracy\/len(test_loader))\n    if np.argmax(test_accuracies) == len(test_accuracies)-1:\n        torch.save(source_model.state_dict(), 'best_source_weights_mnist.pth')\n        \ntest()\nfor epoch in range(epochs):\n    train(epoch)\n    test()","b10fed34":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=train_counter, y=train_losses, mode='lines', name='Train loss'))\nfig.add_trace(go.Scatter(x=test_counter, y=test_losses, marker_symbol='star-diamond', \n                         marker_color='orange', marker_line_width=1, marker_size=9, mode='markers', name='Test loss'))\nfig.update_layout(\n    width=1000,\n    height=500,\n    title=\"Train vs. Test Loss\",\n    xaxis_title=\"Number of training examples seen\",\n    yaxis_title=\"Negative Log Likelihood loss\"),\nfig.show()","17b68994":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=train_counter, y=train_accuracies, mode='lines', name='Train loss'))\nfig.add_trace(go.Scatter(x=test_counter, y=test_accuracies, marker_symbol='star-diamond', \n                         marker_color='orange', marker_line_width=1, marker_size=9, mode='markers', name='Test Accuracy'))\nfig.update_layout(\n    width=1000,\n    height=500,\n    title=\"Train vs. Test Accuracy\",\n    xaxis_title=\"Number of training examples seen\",\n    yaxis_title=\"Accuracy\")\nfig.show()","e7f379bf":"### Get Dataset & Dataloaders","1ad3cf2b":"### Visualize Training & Testing Results \ud83d\udcc8","f48562c4":"### Visualize MNIST Data \ud83d\uddbc\ufe0f","6fc1d62a":"### Libraries \ud83d\udcda\u2b07","a2c535bd":"### Train Source Model on MNIST","e0741621":"## Introduction\n\n### In this notebook, we train a source model on MNIST (source dataset) to be used later for performing Domain Adaptation on MNIST-M dataset.\n### [[Domain Adaptation notebook](https:\/\/www.kaggle.com\/balraj98\/adversarial-discriminative-domain-adaptation)]"}}