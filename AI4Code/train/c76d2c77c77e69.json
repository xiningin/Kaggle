{"cell_type":{"1da8e49a":"code","45ceca9f":"code","5566b380":"code","3e14018c":"code","7b6707d4":"code","9495fe29":"code","9557c4a6":"code","334896b0":"code","fb0d4474":"code","9778de30":"code","0fa48ce4":"code","66f67c26":"code","29272d04":"code","96f4624b":"code","efbdb3ac":"code","859407b2":"markdown","3052e7b1":"markdown","afc638ff":"markdown","7e7b8444":"markdown","b5c0c6eb":"markdown","d21f4218":"markdown","1a5f7f57":"markdown","e105916d":"markdown","589f565e":"markdown","68dc8efb":"markdown","3b5717c4":"markdown"},"source":{"1da8e49a":"import pandas as pd\nimport numpy as np\nimport plotly as py\nfrom statistics import mean\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected = True)\nimport seaborn as sns\nimport random\nimport time\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.model_selection import StratifiedKFold, KFold\n\nfrom sklearn.ensemble import VotingClassifier\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom xgboost import XGBClassifier\n\nfrom scipy.stats import mode\n\nimport warnings\nwarnings.simplefilter('ignore')","45ceca9f":"train = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2022\/train.csv\")\ntrain = train[0:30000]\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2022\/test.csv\")\n#submission = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2022\/sample_submission.csv\")","5566b380":"target = 'target'\ntarget_encoded = 'target_encoded'\nfeatures = [col for col in test.columns if 'id' not in col]","3e14018c":"le = LabelEncoder()\ntrain[target_encoded] = le.fit_transform(train[target])","7b6707d4":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n\n    return df","9495fe29":"reduce_mem_usage(train)","9557c4a6":"reduce_mem_usage(test)","334896b0":"paramsXGB = {'max_depth': 5, 'learning_rate': 0.1, 'n_estimators': 400, 'min_child_weight': 2, 'gamma': 0, 'colsample_bytree': 0.6, 'subsample': 0.5,\n             #'tree_method': 'gpu_hist',\n             'booster': 'gbtree'}","fb0d4474":"extratree_params = {\n    'n_estimators' : 1000,\n    'random_state' : 42,\n    'verbose' : 1,\n    'n_jobs' : -1\n}\nextratree_params1 = {\n    'n_estimators' : 1000,\n    'random_state' : 64,\n    'verbose' : 1,\n    'n_jobs' : -1\n}","9778de30":"xgb_model = XGBClassifier(**paramsXGB)\nextratree_model = ExtraTreesClassifier(**extratree_params)\nextratree_model1 = ExtraTreesClassifier(**extratree_params1)","0fa48ce4":"X=train[features]\ny=train[target_encoded]\nX_test = test[features]\ndel train,test","66f67c26":"pred = []\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (trn_idx, val_idx) in enumerate(tqdm(skf.split(X, y), total=5)):\n    X_train = X.iloc[trn_idx]\n    y_train = y.iloc[trn_idx]\n    X_valid = X.iloc[val_idx]\n    y_valid = y.iloc[val_idx]\n\n    start = time.time()\n    model = VotingClassifier(\n            estimators = [\n                ('xgb', xgb_model),\n                ('extratree', extratree_model), \n                #('extratree1', extratree_model1)\n            ],\n            voting = 'soft',\n            weights = [0.4, 0.6],\n            n_jobs = -1\n        )\n    model.fit(X_train, y_train)\n\n    pred.append(model.predict(X_test))\n\n    elapsed = time.time() - start","29272d04":"del model,X_train,X_valid","96f4624b":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-feb-2022\/sample_submission.csv\")","efbdb3ac":"pred_decoded = le.inverse_transform(mode(pred).mode[0])\nsubmission[target] = pred_decoded\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","859407b2":"<p>In the above voting classifier you can use multiple models(i.e. xgb,cb,lgmb,extratree,etc)<\/p>","3052e7b1":"This notebook uses codes from an excellent notebook, TPS Feb 2022 ExtraTreeClassifier, by BIZEN.","afc638ff":"<h3>Upvote, if this notebook was helpful<\/h3>","7e7b8444":"<h2>ExtraTreeClassifier<\/h2>","b5c0c6eb":"<h2>Dataset<\/h2>","d21f4218":"<h2>Preprocessing<\/h2>","1a5f7f57":"<h2>XGB<\/h2>","e105916d":"<h2>Voting<\/h2>","589f565e":"<h2>Submission<\/h2>","68dc8efb":"<h1> Libraries<\/h1","3b5717c4":"<h1>If you found this notebook interesting & helpful, please consider to upvote!!<\/h1>"}}