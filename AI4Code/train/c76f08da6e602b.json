{"cell_type":{"19446e2f":"code","0f6ac477":"code","c1128a78":"code","a4828d84":"code","7335add3":"code","3c0a6983":"code","63f261c3":"code","32890be5":"code","46cee4ee":"code","147a4d04":"code","5531bd65":"code","ffb28086":"code","c6e3e8d7":"code","638fd72c":"code","07d78cbf":"code","f26ec422":"code","3212e47e":"code","d3aab306":"code","b6e26375":"markdown","43f87a66":"markdown","f6e04ff6":"markdown","11849be5":"markdown","4b5844ad":"markdown","eb78d1a0":"markdown","6c0486ab":"markdown","403ada22":"markdown","e1b26adf":"markdown","ec504c30":"markdown","06020163":"markdown","10848992":"markdown","d54bb2aa":"markdown","14c75c8a":"markdown","4409cf07":"markdown","a62d577b":"markdown","357b0787":"markdown","d73a358e":"markdown","7a6d2c15":"markdown"},"source":{"19446e2f":"import pandas as pd\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.compose import make_column_selector\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.impute import SimpleImputer\n\nfrom skopt import BayesSearchCV\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier","0f6ac477":"test = pd.read_csv('..\/input\/titanic\/test.csv', index_col='PassengerId')\ntrain = pd.read_csv('..\/input\/titanic\/train.csv', index_col='PassengerId')","c1128a78":"train","a4828d84":"train.select_dtypes(exclude='object').describe()","7335add3":"train.select_dtypes(include='object').describe()","3c0a6983":"train.Embarked.value_counts()","63f261c3":"train = train.drop(['Cabin', 'Name', 'Ticket'], axis='columns')\ntest = test.drop(['Cabin', 'Name', 'Ticket'], axis='columns')","32890be5":"X = train.drop(['Survived'], axis='columns')\ny = train.Survived","46cee4ee":"X.head()","147a4d04":"y.head()","5531bd65":"categorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median'))\n])\n\npreprocessor = ColumnTransformer(transformers=[\n    ('cat', categorical_transformer, make_column_selector(dtype_include='object')),\n    ('num', numeric_transformer, make_column_selector(dtype_exclude='object'))\n])","ffb28086":"xgb_pipe = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n])\n\nrf_pipe = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('model', RandomForestClassifier())\n])","c6e3e8d7":"rf_space = {\n    'model__n_estimators': (100, 500),\n    'model__max_depth': (1, 30),\n    'model__max_features': (0.1, 1.0),\n    'model__min_samples_leaf': (0.001, 0.1)\n}\n\nxgb_space = {\n    'model__n_estimators': (200, 600),\n    'model__max_depth': (1, 15),\n    'model__learning_rate': (0.01, 0.1),\n    'model__colsample_bytree': (0.1, 1.0),\n    'model__min_child_weight': (0, 50)\n}","638fd72c":"inner_cv = StratifiedKFold(n_splits=4, shuffle=True)\nouter_cv = StratifiedKFold(n_splits=4, shuffle=True)","07d78cbf":"rf_bayes = BayesSearchCV(rf_pipe, rf_space, n_iter=15, cv=inner_cv, n_jobs=-1)\nrf_bayes_nest = cross_val_score(rf_bayes, X, y, cv=outer_cv, n_jobs=2)\nrf_bayes_nest.mean()","f26ec422":"rf_bayes.fit(X, y)\nrf_bayes.best_score_","3212e47e":"rf_bayes.best_params_","d3aab306":"rf_preds = rf_bayes.predict(test)\nrf_output = pd.DataFrame({'PassengerId': test.index, 'Survived': rf_preds})\nrf_output.to_csv('rf_submission.csv', index=False)\nrf_output","b6e26375":"Before we start, I should warn you that the last scikit-learn version (>=0.24.0) is incompatible with the current `BayesSearCV()` of scikit-optimize because of a deprecated argument which causes a bug (https:\/\/github.com\/scikit-optimize\/scikit-optimize\/issues\/978). To run this notebook, you can do it in a Kaggle kernel (scikit-learn 0.23.2 by default) or pass the following command in your local notebook to downgrade scikit-learn: `pip install scikit-learn~=0.23.0`. If you're not sure about your version, use `pip show scikit-learn` in your notebook. I'm not sure the last version of Python supports scikit-learn~=0.23.0, I personnally had to downgrade Python to install it locally.","43f87a66":"In this section, I tune and compare:\n- A random forest (scikit-learn)\n- And boosted trees (XGBoost)\n\nI made this choice in order to stay concise, with two decision trees ensembles known to have good perfomances and easy preprocessing. Nested cross-validation is used to compare tuned models to each other without overfitting (that is, with a good generalizabily).","f6e04ff6":"## Pipelines and search spaces","11849be5":"The preprocessing consists in two steps. First, we impute missing values for *each* feature. Indeed, if we use the final model for a futur test set (not the one provided for submission), we don't now in advance in wich column a missing value can take place (ok there is only one Titanic, this precaution is optional). I chose a simple imputation method : the median for numerical features, and the mode for categorical ones. The second preprocessing step is to one hot encode the categorical predictors.\n\nWe can easily add other models to that workflow. For most of them (notably logistic regression, KNN and SVM), a normalization step is requiered in the preprocess. If you choose to use a logistic regression *without* regularization (in a prediction setting, why would you?), think about dropping one category when one hot encoding (`drop='first'`).","4b5844ad":"Now, let's build our outer and inner loops for the nested CV.","eb78d1a0":"Thank you for reading this notebook! If it helped you in anyway, please upvote! You can also check the one I've made about AutoKeras for automated deep learning: https:\/\/www.kaggle.com\/gruben117\/titanic-deep-learning-with-autokeras","6c0486ab":"When the dataset is small, a validation set strategy can give highly variable results when comparing tuned models. Nested cross-validation is a good unbiased alternative, but is computationally greedy. That's where bayesian optimization comes to rescue us.\n\nTo learn more about nested cross-validation, please check these links:\n\nhttps:\/\/www.kdnuggets.com\/2020\/10\/nested-cross-validation-python.html\n\nhttps:\/\/machinelearningmastery.com\/nested-cross-validation-for-machine-learning-with-python\/\n\nhttps:\/\/mlr.mlr-org.com\/articles\/tutorial\/nested_resampling.html","403ada22":"# Bayesian optimization and nested CV","e1b26adf":"# Predictions of the best model","ec504c30":"The first cell outputs the nested cross-validation accuracy, which will allow us to compare models later. We ask the second cell to give the classical cross-validation accuracy, just because we are curious (this value is useless in our workflow). Theoretically, the only goal of simple cross-validation for tunable models is to find the best hyperparameters.","06020163":"# Preparation","10848992":"## XGBoost","d54bb2aa":"Here is a little pitfall: when specifying hyperparameters search space (it's also true when using the standard `GridSearchCV`) intended to be used with a `Pipeline()` (not just the model alone), don't forget to write `model__` (if this is the name you gave to your model in the pipeline), with 2 underscores, before every hyperparameter name.","14c75c8a":"Note that nested cross-validation scores are usually lower than cross-validation ones, but not always. For an illustrative example, see https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_nested_cross_validation_iris.html\n\nNext, we extract the best parameters found during bayesian optimization (because we are curious!).","4409cf07":"Then I do the usual preparation after some data exploration (the code and outputs are hidden to shorten the notebook). This preparation consists in:\n- Dropping the \"Cabin\" variable because of to much NaN\n- Dropping the \"Name\" variable because of almost n unique values and the common knowlegde telling us that the title (Mr., Mrs., Dr...) is closely related to the variables \"Sex\" and \"PClass\"\n- Dropping the \"Ticket\" variable because of too much unique values and the fact that I don't know how to handle this feature easily and worthily","a62d577b":"Unfortunately, Kaggle's Python Docker seems to be incompatible with this part of the procedure given the librairies I use (Python's librairies...). On my laptop, XGBoost's nested CV gave the same results as the random forest's one (depending on the random seed). Below this cell, I give the code for the XGBoost model.","357b0787":"## Random forest","d73a358e":"`xgb_bayes = BayesSearchCV(xgb_pipe, xgb_space, n_iter=15, cv=inner_cv, n_jobs=-1)`\n\n`xgb_bayes_nest = cross_val_score(xgb_bayes, X, y, cv=outer_cv, n_jobs=2)`\n\n`xgb_bayes_nest.mean()`\n\n`xgb_bayes.fit(X, y)`\n\n`xgb_bayes.best_score_`\n\n`xgb_bayes.best_params_`","7a6d2c15":"As the two models gave similar performances (and we had a bug with the XGBoost's model...), let's use the random forest's predictions for submission."}}