{"cell_type":{"92b24502":"code","49a5579e":"code","867d9912":"code","b24a587d":"code","fd9b5dae":"code","5a3f1838":"code","77ed5fe1":"code","36d111f2":"code","4a1f3608":"code","861581a8":"code","52c298b2":"code","c2def135":"code","e0391781":"code","06bf064c":"code","d0930c34":"code","9b70a875":"code","f7a7e1fe":"code","11fe54fe":"code","1c8fb294":"code","850e8232":"code","bff66695":"code","7a1453c6":"markdown","15e50d57":"markdown","6d07004d":"markdown","e42a7d49":"markdown","b18ee437":"markdown","7f64020d":"markdown","cce6005b":"markdown","f54f0fcf":"markdown","4efc2e51":"markdown","98843861":"markdown","f7517124":"markdown","1f55dd60":"markdown","085119fe":"markdown","80152a06":"markdown","e1a708a9":"markdown"},"source":{"92b24502":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import confusion_matrix","49a5579e":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","867d9912":"train_csv = pd.read_csv(\"..\/input\/fashion-mnist_train.csv\")\ntest_csv = pd.read_csv(\"..\/input\/fashion-mnist_test.csv\")","b24a587d":"class FashionDataset(Dataset):\n    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n    \n    def __init__(self, data, transform = None):\n        \"\"\"Method to initilaize variables.\"\"\" \n        self.fashion_MNIST = list(data.values)\n        self.transform = transform\n        \n        label = []\n        image = []\n        \n        for i in self.fashion_MNIST:\n             # first column is of labels.\n            label.append(i[0])\n            image.append(i[1:])\n        self.labels = np.asarray(label)\n        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n\n    def __getitem__(self, index):\n        label = self.labels[index]\n        image = self.images[index]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, label\n\n    def __len__(self):\n        return len(self.images)","fd9b5dae":"# Transform data into Tensor that has a range from 0 to 1\ntrain_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\ntest_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n\ntrain_loader = DataLoader(train_set, batch_size=100)\ntest_loader = DataLoader(train_set, batch_size=100)","5a3f1838":"\"\"\"\ntrain_set = torchvision.datasets.FashionMNIST(\".\/data\", download=True, transform=\n                                                transforms.Compose([transforms.ToTensor()]))\ntest_set = torchvision.datasets.FashionMNIST(\".\/data\", download=True, train=False, transform=\n                                               transforms.Compose([transforms.ToTensor()]))  \n\"\"\"                                               ","77ed5fe1":"\"\"\"\ntrain_loader = torch.utils.data.DataLoader(train_set, \n                                           batch_size=100)\ntest_loader = torch.utils.data.DataLoader(test_set,\n                                          batch_size=100)\n\"\"\"                                          ","36d111f2":"def output_label(label):\n    output_mapping = {\n                 0: \"T-shirt\/Top\",\n                 1: \"Trouser\",\n                 2: \"Pullover\",\n                 3: \"Dress\",\n                 4: \"Coat\", \n                 5: \"Sandal\", \n                 6: \"Shirt\",\n                 7: \"Sneaker\",\n                 8: \"Bag\",\n                 9: \"Ankle Boot\"\n                 }\n    input = (label.item() if type(label) == torch.Tensor else label)\n    return output_mapping[input]","4a1f3608":"a = next(iter(train_loader))\na[0].size()","861581a8":"len(train_set)","52c298b2":"image, label = next(iter(train_set))\nplt.imshow(image.squeeze(), cmap=\"gray\")\nprint(label)","c2def135":"demo_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n\nbatch = next(iter(demo_loader))\nimages, labels = batch\nprint(type(images), type(labels))\nprint(images.shape, labels.shape)","e0391781":"grid = torchvision.utils.make_grid(images, nrow=10)\n\nplt.figure(figsize=(15, 20))\nplt.imshow(np.transpose(grid, (1, 2, 0)))\nprint(\"labels: \", end=\" \")\nfor i, label in enumerate(labels):\n    print(output_label(label), end=\", \")\n","06bf064c":"class FashionCNN(nn.Module):\n    \n    def __init__(self):\n        super(FashionCNN, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n        self.drop = nn.Dropout2d(0.25)\n        self.fc2 = nn.Linear(in_features=600, out_features=120)\n        self.fc3 = nn.Linear(in_features=120, out_features=10)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n        out = self.drop(out)\n        out = self.fc2(out)\n        out = self.fc3(out)\n        \n        return out\n","d0930c34":"model = FashionCNN()\nmodel.to(device)\n\nerror = nn.CrossEntropyLoss()\n\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nprint(model)","9b70a875":"num_epochs = 5\ncount = 0\n# Lists for visualization of loss and accuracy \nloss_list = []\niteration_list = []\naccuracy_list = []\n\n# Lists for knowing classwise accuracy\npredictions_list = []\nlabels_list = []\n\nfor epoch in range(num_epochs):\n    for images, labels in train_loader:\n        # Transfering images and labels to GPU if available\n        images, labels = images.to(device), labels.to(device)\n    \n        train = Variable(images.view(100, 1, 28, 28))\n        labels = Variable(labels)\n        \n        # Forward pass \n        outputs = model(train)\n        loss = error(outputs, labels)\n        \n        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n        optimizer.zero_grad()\n        \n        #Propagating the error backward\n        loss.backward()\n        \n        # Optimizing the parameters\n        optimizer.step()\n    \n        count += 1\n    \n    # Testing the model\n    \n        if not (count % 50):    # It's same as \"if count % 50 == 0\"\n            total = 0\n            correct = 0\n        \n            for images, labels in test_loader:\n                images, labels = images.to(device), labels.to(device)\n                labels_list.append(labels)\n            \n                test = Variable(images.view(100, 1, 28, 28))\n            \n                outputs = model(test)\n            \n                predictions = torch.max(outputs, 1)[1].to(device)\n                predictions_list.append(predictions)\n                correct += (predictions == labels).sum()\n            \n                total += len(labels)\n            \n            accuracy = correct * 100 \/ total\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n        \n        if not (count % 500):\n            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))\n","f7a7e1fe":"plt.plot(iteration_list, loss_list)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"Iterations vs Loss\")\nplt.show()","11fe54fe":"plt.plot(iteration_list, accuracy_list)\nplt.xlabel(\"No. of Iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Iterations vs Accuracy\")\nplt.show()","1c8fb294":"class_correct = [0. for _ in range(10)]\ntotal_correct = [0. for _ in range(10)]\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        test = Variable(images)\n        outputs = model(test)\n        predicted = torch.max(outputs, 1)[1]\n        c = (predicted == labels).squeeze()\n        \n        for i in range(100):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            total_correct[label] += 1\n        \nfor i in range(10):\n    print(\"Accuracy of {}: {:.2f}%\".format(output_label(i), class_correct[i] * 100 \/ total_correct[i]))","850e8232":"from itertools import chain \n\npredictions_l = [predictions_list[i].tolist() for i in range(len(predictions_list))]\nlabels_l = [labels_list[i].tolist() for i in range(len(labels_list))]\npredictions_l = list(chain.from_iterable(predictions_l))\nlabels_l = list(chain.from_iterable(labels_l))","bff66695":"import sklearn.metrics as metrics\n\nconfusion_matrix(labels_l, predictions_l)\nprint(\"Classification report for CNN :\\n%s\\n\"\n      % (metrics.classification_report(labels_l, predictions_l)))","7a1453c6":"### Printing the Confusion Matrix ","15e50d57":"### 1.    Using a Dataset class.\n    \n   *   First load the data from the disk using pandas read_csv() method.\n\n   *   Now inherit Dataset class in your own class that you are building,    lets say FashionData.\n\n        *  It has 2 methods: __get_item__( ) and __len__().\n        * __get_item__( ) return the images and labels and __len__( ) returns the number of items in a dataset.","6d07004d":"### If the GPU is available use it for the computation otherwise use the CPU.","e42a7d49":"### This is the tutorial of deep learning on FashionMNIST dataset using Pytorch. We will build a Convolutional Neural Network for predicting the classes of Dataset. I am assuming you know the basics of deep leanrning like layer architecture... convolution concepts. Without further ado... Lets start the tutorial.","b18ee437":"There are 2 ways to load the Fashion MNIST dataset. \n\n\n    1.   Load csv and then inherite Pytorch Dataset class .\n    2.   Use Pytorch module torchvision.datasets. It has many popular datasets like MNIST, FashionMNIST, CIFAR10 e.t.c.\n    \n    \n\n*   We use DataLoader class from torch.utils.data to load data in batches  in both method.\n* Comment out the code of a method which you are not using. \n\n\n\n\n","7f64020d":"### This is my implementation of deep learning in FashionMNIST dataset using Pytorch. I've achieved 93% test accuracy. Change those layer architecture or parameters to make it better. \n***I hope you like it. Give your feedback. It helps me to a lot. Thank you. :)***","cce6005b":"### Looking the Accuracy in each class of FashionMNIST dataset","f54f0fcf":"### Visualizing the Loss and Accuracy with Iterations\n","4efc2e51":"# **Importing Important Libraries**","98843861":"## Building a CNN \n\n\n*   Make a model class (FashionCNN in our case)\n    * It inherit nn.Module class that is a super class for all the neural networks in Pytorch.\n* Our Neural Net has following layers:\n    * Two Sequential layers each consists of following layers-\n        * Convolution layer that has kernel size of 3 * 3, padding = 1 (zero_padding) in 1st layer and padding = 0 in second one. Stride of 1 in both layer.\n        * Batch Normalization layer.\n        * Acitvation function: ReLU.\n        * Max Pooling layer with kernel size of 2 * 2 and stride 2.\n     * Flatten out the output for dense layer(a.k.a. fully connected layer).\n     * 3 Fully connected layer  with different in\/out features.\n     * 1 Dropout layer that has class probability p = 0.25.\n  \n     * All the functionaltiy is given in forward method that defines the forward pass of CNN.\n     * Our input image is changing in a following way:\n        * First Convulation layer : input: 28 \\* 28 \\* 3, output: 28 \\* 28 \\* 32\n        * First Max Pooling layer : input: 28 \\* 28 \\* 32, output: 14 \\* 14 \\* 32\n        * Second Conv layer : input : 14 \\* 14 \\* 32, output: 12 \\* 12 \\* 64\n        * Second Max Pooling layer : 12 \\* 12 \\* 64, output:  6 \\* 6 \\* 64\n    * Final fully connected layer has 10 output features for 10 types of clothes.\n\n> Lets implementing the network...\n\n\n\n","f7517124":"### We have 10 types of clothes in FashionMNIST dataset.\n\n\n> Making a method that return the name of class for the label number.\nex. if the label is 5, we return Sandal.\n\n","1f55dd60":"## Training a network and Testing it on test dataset","085119fe":"### Playing with data and displaying some images using matplotlib imshow() method.\n\n\n\n","80152a06":"### 2. Using FashionMNIST class from torchvision module.\n\n\n*   It will download the dataset first time.\n\n\n","e1a708a9":"### Making a model of our CNN class\n\n*   Creating a object(model in the code)\n*   Transfering it into GPU if available.\n*  Defining a Loss function. we're using CrossEntropyLoss() here.\n*  Using Adam algorithm for optimization purpose.\n\n"}}