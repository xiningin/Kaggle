{"cell_type":{"1041785d":"code","d800f4f0":"code","8971dba6":"code","b9792392":"code","ec4e1e9e":"code","5520904f":"code","60dd9c49":"code","de14d776":"code","33772b04":"code","18d588a7":"code","47f8c2bc":"code","ec9ff522":"code","74568572":"code","26496055":"code","3ce87737":"code","8b786287":"code","4956ea8e":"code","47270c39":"code","af7677aa":"code","5c1498b9":"code","0c2ed222":"code","b721f031":"code","93f4c7ac":"code","d7ed153a":"code","e35ef65c":"code","015ce3e6":"code","49fe3f3f":"code","c91d8c35":"code","bd16b81d":"code","aab729f6":"code","cdd58f05":"code","a9813ca3":"code","1e57e4e0":"code","449ba67c":"code","e7ad673d":"code","e1a3163f":"code","2dd91e42":"code","7d5fa834":"code","4d50fdc4":"code","8dba3b39":"code","d5f82652":"code","b309245b":"code","f694c66e":"code","caee45cc":"code","236ae3a9":"code","2c9c43a7":"code","73dbdee6":"code","8d34341b":"code","fadca097":"code","f04a84e2":"code","db390d46":"code","510632f4":"code","c23f1e10":"code","8e5e4ee9":"code","6d10570b":"code","5281c8a2":"code","ea2c9d28":"code","4eb2e375":"code","ef2057a9":"code","df913202":"code","f67d8d5d":"code","b2ff8b8a":"code","fd2c1c62":"code","44079789":"code","eee083d0":"code","e0285027":"code","3b108db4":"code","17640292":"code","bda8005e":"code","e83ddc91":"code","9eafdbe3":"code","d83edebf":"code","a3a97dbb":"code","1a2e0f55":"code","b118441a":"code","cf6ad1da":"code","b69eb43a":"code","4b870f3d":"code","b5305944":"code","77d75e8b":"code","cc90d455":"code","5477d7fa":"code","2757b3ee":"code","89e02b60":"code","0bcd1545":"code","2dda43f3":"code","794bbf14":"code","a755e7f7":"code","7e008c55":"code","64d228c9":"code","60c293e2":"code","e19037d7":"markdown","bae9956a":"markdown","54849b3f":"markdown","f946a028":"markdown","18f84203":"markdown","c4ca5745":"markdown","1bf96fbe":"markdown","e38c3bc3":"markdown","031ed739":"markdown","7bed017f":"markdown","e53e0555":"markdown","2c383cff":"markdown","fda4e8e7":"markdown","b1aea1cf":"markdown","2ad5eb37":"markdown","624e4de5":"markdown","6fbb8b0a":"markdown","fc68f695":"markdown","6d0c8619":"markdown","f84e82e8":"markdown","e309f0ce":"markdown","1beeebde":"markdown","069a8748":"markdown","cf30a53b":"markdown","56db576a":"markdown","b376e512":"markdown","46c3303a":"markdown","43650bc5":"markdown","f0d0cf4b":"markdown","c467a89a":"markdown","1b710437":"markdown","8a9da9b6":"markdown","87968827":"markdown","a7a8311b":"markdown","6e8e2019":"markdown","2a9f0524":"markdown"},"source":{"1041785d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler, LabelEncoder\n\nfrom prettytable import PrettyTable\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error, accuracy_score, r2_score, mean_absolute_error, mean_squared_log_error\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge","d800f4f0":"df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf.head(5)","8971dba6":"#COlumns available\ndf.columns","b9792392":"#Shape of DataFrame\nprint(f\"Shape of Dataframe: {df.shape}\")","ec4e1e9e":"#The target Variable\ndf[\"SalePrice\"].describe()","5520904f":"#Distribution plot of Traget Variable\nsns.set_style(style=\"whitegrid\")\nsns.distplot(df[\"SalePrice\"])\nplt.title(\"Distribution plot\")\nplt.show()","60dd9c49":"print(f\"The skewness is: {df['SalePrice'].skew()}\")\nprint(f\"The kurtosis is: {df['SalePrice'].kurt()}\")","de14d776":"#Variable which have data types int64 and float64\nprint(df.dtypes[df.dtypes!=object])\nprint(f\"Total Numbers of Numerical Variables: {len(df.dtypes[df.dtypes!=object])}\")","33772b04":"#Variable which have data types int64 and float64\nvar_num = df.dtypes[df.dtypes!=object].index.values.tolist()","18d588a7":"##df_num = df[var_num]\ndf_num = df[['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n       'MiscVal', 'MoSold', 'YrSold', 'SalePrice']]","47f8c2bc":"#Dataframe with numerical values\ndf_num.head(5)","ec9ff522":"len(df)","74568572":"##Seperating variable w.r.t the contunuous and discrete values\nvar_list_continuous = []\nvar_list_discrete = []\nfor i in df_num.columns:\n    count = len(df_num[i].value_counts())\n    if count>=15:\n        var_list_continuous.append(i)\n    else:\n        var_list_discrete.append(i)","26496055":"print(f\"Continuous Features: {var_list_continuous}\")\nprint(f\"Discrete Features: {var_list_discrete}\")","3ce87737":"print(f\"Length of variable having continuous values: {len(var_list_continuous)}\")","8b786287":"# Create new dataframe with continuous values.\ndf_continuous = df_num[var_list_continuous]\ndf_continuous.head(5)","4956ea8e":"## Correlation Coeficiant \n#Heatmap of corelation of Numerical Variables.\nplt.figure(figsize=(15,15))\nsns.heatmap(df_continuous.corr(), cmap=\"Blues\", annot=True)\nplt.show()","47270c39":"#HIghest correlated variables with SalePrice ie greater than 0.4\ncorrelation_threshold = 0.4\n\ndf_continuous.corr()[\"SalePrice\"][~df_continuous.corr()[\"SalePrice\"].between(-correlation_threshold, correlation_threshold)]","af7677aa":"imp_var = list(df_continuous.corr()[\"SalePrice\"][~df_continuous.corr()[\"SalePrice\"].between(-correlation_threshold, correlation_threshold)].keys())\nimp_var.remove(\"SalePrice\")","5c1498b9":"plt.figure(1)\nfig_no = 1\nn_row = len(imp_var)\/3 if len(imp_var)%3==0 else int(len(imp_var)\/3)+1\nplt.figure(figsize=(20,20))\nfor i in imp_var:\n    plt.subplot(n_row,3,fig_no)\n    fig_no+=1\n    sns.scatterplot(df_num[i], df_num[\"SalePrice\"])\nplt.show()","0c2ed222":"len(var_list_continuous)","b721f031":"#To find the outliers.\n\nplt.figure(1)\nfig_no = 1\nplt.figure(figsize=(20,15))\nfor i in var_list_continuous:\n    plt.subplot(6,4,fig_no)\n    fig_no+=1\n    sns.boxplot(y=df_num[i])\nplt.show()","93f4c7ac":"outliers_var = ['LotArea', 'BsmtFinSF2', 'LowQualFinSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'MiscVal']\ndf_outlier = df_num[outliers_var]","d7ed153a":"from scipy import stats\nimport numpy as np\nz = np.abs(stats.zscore(df_outlier))\nprint(z)","e35ef65c":"## Filter the value which is greater than 3. \nthreshold=3.0\ndf_outliers = pd.DataFrame(z, columns=outliers_var)>threshold\n\n## Find the number of index where we have atleast a single outlier value in any feature.\nlist_outliers = []\nfor i in range(0, len(df_outliers)):\n    for val in df_outliers.loc[i]:\n        if val:\n            list_outliers.append(i)","015ce3e6":"print(f\"Total number of rows which having atleast a single outlier value: {len(set(list_outliers))}\")\nprint(f\"Percent of total rows we need to drop due to outliers: {np.round(len(set(list_outliers))\/len(df_num)*100, 2)}%\")","49fe3f3f":"df_discrete = df_num[var_list_discrete]\ndf_discrete[\"SalePrice\"] = df_num[\"SalePrice\"]\ndf_discrete.head(5)","c91d8c35":"print(f\"Number of features with discrete values: {len(var_list_discrete)}\")","bd16b81d":"plt.figure(figsize=(15,15))\nplt.title(\"Heatmap of Correlation Coefficient of each variables\")\nsns.heatmap(df_discrete.corr(), cmap=\"Blues\", annot=True)\nplt.show()","aab729f6":"#Correlation which is greater than threshold.\ncorrelation_threshold = 0.4\ndf_discrete.corr()[\"SalePrice\"][~df_discrete.corr()[\"SalePrice\"].between(-correlation_threshold, correlation_threshold)]","cdd58f05":"imp_var = list(df_discrete.corr()[\"SalePrice\"][~df_discrete.corr()[\"SalePrice\"].between(-correlation_threshold, correlation_threshold)].keys())\nimp_var.remove(\"SalePrice\")","a9813ca3":"plt.figure(1)\nfig_no = 1\nn_row = len(imp_var)\/3 if len(imp_var)%3==0 else int(len(imp_var)\/3)+1\nplt.figure(figsize=(20,20))\nfor i in imp_var:\n    plt.subplot(n_row,3,fig_no)\n    fig_no+=1\n    sns.boxplot(df_num[i], df_num[\"SalePrice\"])\nplt.show()","1e57e4e0":"#Variable which have data types object\nvar_cat = df.dtypes[df.dtypes==object].index.values.tolist()\n#Number of variable which have dtype object.\nprint(f\"Number of variables with datatypes object: {len(var_cat)}\")","449ba67c":"#Dataframe with object datatype variables\ndf_cat = df[var_cat]\ndf_cat.head(5)","e7ad673d":"plt.figure(1)\nfig_no = 1\nplt.figure(figsize=(20,20))\nfor i in df_cat.columns.values.tolist():\n    plt.subplot(11,4,fig_no)\n    fig_no+=1\n    sns.boxplot(df_cat[i], df[\"SalePrice\"])\nplt.show()","e1a3163f":"#Dealing with NULL values\ndf_null = pd.DataFrame(df.isnull().sum()[df.isnull().sum()>0], columns=[\"Sum of Null Values\"])\ndf_null[\"Percent of NULL (%)\"] = df.isnull().mean().round(4)[df.isnull().mean()>0]*100\ndf_null","2dd91e42":"#Removing variables having more than 40% of NULL values.\ndf = df[(df.isnull().mean()[df.isnull().mean()<0.4]).keys().tolist()]","7d5fa834":"df_num = df[['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n       'MiscVal', 'MoSold', 'YrSold', 'SalePrice']]","4d50fdc4":"#Dealing with NULL values\ndf_null = pd.DataFrame(df_num.isnull().sum()[df_num.isnull().sum()>0], columns=[\"Sum of Null Values\"])\ndf_null[\"Percent of NULL (%)\"] = df_num.isnull().mean().round(4)[df_num.isnull().mean()>0]*100\ndf_null","8dba3b39":"#Since there are possible outliers, we can impute missing value with median rather than mean.\n\nimp = SimpleImputer(strategy=\"median\")\ndf_num = pd.DataFrame(imp.fit_transform(df_num), columns=df_num.columns, index=df_num.index)\n\n#Display the NULL values\ndf_null_num = pd.DataFrame(df_num.isnull().sum()[df_num.isnull().sum()>0], columns=[\"NULL sum\"])\ndf_null_num[\"Percent of NULL (%)\"] = (df_num.isnull().mean()[df_num.isnull().mean()>0])*100\ndf_null_num","d5f82652":"#Variable which have data types object\nvar_cat = df.dtypes[df.dtypes==object].index.values.tolist()\n#Dataframe with object datatype variables\ndf_cat = df[var_cat]\ndf_cat.head(5)","b309245b":"#Dealing with NULL values\ndf_null = pd.DataFrame(df_cat.isnull().sum()[df_cat.isnull().sum()>0], columns=[\"Sum of Null Values\"])\ndf_null[\"Percent of NULL (%)\"] = df_cat.isnull().mean().round(4)[df_cat.isnull().mean()>0]*100\ndf_null","f694c66e":"#Replace the NULL value with the most frequent values.\nimp = SimpleImputer(strategy=\"most_frequent\")\ndf_cat = pd.DataFrame(imp.fit_transform(df_cat), columns=df_cat.columns, index=df_cat.index)\n\n#Display the NULL values.\nperc_Df = pd.DataFrame(df_cat.isnull().sum()[df_cat.isnull().sum()>0], columns=[\"NULL sum\"])\nperc_Df[\"NULL percent\"] = (df_cat.isnull().mean()[df_cat.isnull().mean()>0])*100\nperc_Df","caee45cc":"encode = OneHotEncoder(drop='first',sparse=False)\nencode.fit(df_cat)\n\ndf_cat_dummies = encode.transform(df_cat)\ndf_cat_dummies = pd.DataFrame(df_cat_dummies, columns=encode.get_feature_names(), index=df_cat.index)\ndf_cat_dummies.head(5)","236ae3a9":"print(f\"The shape of Numerical variable: {df_num.shape}\")\nprint(f\"The shape of categorical variable: {df_cat.shape}\")\nprint(f\"The shape of categoricall dummy variables: {df_cat_dummies.shape}\")","2c9c43a7":"df_cat_dummies[\"SalePrice\"] = df_num[\"SalePrice\"]\n\ndf_cat_dummies.corr()[\"SalePrice\"][df_cat_dummies.corr()[\"SalePrice\"]>=correlation_threshold]","73dbdee6":"print(list(df_cat_dummies.corr()[\"SalePrice\"][df_cat_dummies.corr()[\"SalePrice\"]>=correlation_threshold].keys()))","8d34341b":"df_all_var = df_num.join(df_cat_dummies.drop(\"SalePrice\", axis=1))\n\nprint(f\"Shape of Final ALL variable Dataframe: {df_all_var.shape}\")","fadca097":"X = df_all_var.drop('SalePrice', axis=1)\ny = df_all_var[\"SalePrice\"]\n\nprint(f\"X Train dataset shape: {X.shape}\")\nprint(f\"Y train dataset shape: {y.shape}\")\n\nr2 = make_scorer(r2_score, greater_is_better=True)\nrmse = make_scorer(mean_squared_error,greater_is_better=False,squared=False)","f04a84e2":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")","db390d46":"model_name = \"LinearRegression\"\nmodel=LinearRegression()\n\nparam_grid = [{model_name+'__fit_intercept':[True,False]}]\npipeline = Pipeline([(model_name, model)])\nregressor = GridSearchCV(pipeline,param_grid,cv=5, scoring=rmse, n_jobs=-1)","510632f4":"regressor.fit(X_train, y_train)\nprint(f\"Best score: {regressor.best_score_}\")\nprint(f\"Best params: {regressor.best_params_}\")","c23f1e10":"y_pred = regressor.predict(X_test)\n\nmae_linear = mean_absolute_error(y_test, y_pred)\nprint(\"Model 1 MAE: %d\" % (mae_linear))\n\nr2_val_linear = r2_score(y_test, y_pred)\nprint(f\"R2 Score: {r2_val_linear}\")","8e5e4ee9":"pd.DataFrame({\"y_test\":y_test, \"y_pred\":y_pred}).head(5)","6d10570b":"model_name = \"Lasso\"\nmodel=Lasso()\n\nalpha = [2**i for i in range(-5, 15)]\nparam_grid = [  {model_name+'__'+'alpha': alpha}]","5281c8a2":"pipeline = Pipeline([(model_name, model)])\n\nreg=GridSearchCV(pipeline,param_grid,cv=5, scoring=rmse, n_jobs=-1)\nreg.fit(X_train,y_train.to_numpy())","ea2c9d28":"print('best training param:',reg.best_params_)\nprint('best training score rmse', reg.best_score_)","4eb2e375":"y_pred = reg.predict(X_test)\nmae_lasso, rmsle_lasso = mean_absolute_error(y_test, y_pred), np.sqrt(mean_squared_log_error(y_test, y_pred))\nprint(\"Model 1 MAE: %d, RMSLE: %f\" % (mae_lasso, rmsle_lasso))\n\nr2_value_lasso = r2_score(y_test, y_pred)\nprint(f\"R2 Score: {r2_value_lasso}\")","ef2057a9":"pd.DataFrame({\"y_test\":y_test, \"y_pred\":y_pred}).head(5)","df913202":"model_name = \"Ridge\"\nmodel=Ridge()\n\nalpha = [2**i for i in range(-5, 15)]\nparam_grid = [{model_name+'__'+'alpha': alpha}]","f67d8d5d":"pipeline = Pipeline([(model_name, model)])\n\n\nreg=GridSearchCV(pipeline,param_grid,cv=5, scoring=rmse, n_jobs=-1)\nreg.fit(X_train,y_train.to_numpy())","b2ff8b8a":"print('best training param:',reg.best_params_)\nprint('best training score rmse', reg.best_score_)","fd2c1c62":"y_pred = reg.predict(X_test)\n\nmae_ridge, rmsle_ridge = mean_absolute_error(y_test, y_pred), np.sqrt(mean_squared_log_error(y_test, y_pred))\nprint(\"Model 1 MAE: %d, RMSLE: %f\" % (mae_ridge, rmsle_ridge))\n\nr2_value_ridge = r2_score(y_test, y_pred)\nprint(f\"R2 Score: {r2_value_ridge}\")","44079789":"pd.DataFrame({\"y_test\":y_test, \"y_pred\":y_pred}).head(5)","eee083d0":"table = PrettyTable()\ntable.field_names = [\"Model\", \"MAE\", \"RMSLE\", \"R-Squared Value\"]\ntable.add_row([\"Linear Regression\", mae_linear, \"NA\", r2_val_linear])\ntable.add_row([\"LASSO Regression\", mae_lasso, rmsle_lasso, r2_value_lasso])\ntable.add_row([\"RIDGE Regression\", mae_ridge, rmsle_ridge, r2_value_ridge])\n\nprint(table)","e0285027":"imp_var_dis = list(df_discrete.columns)\n\n#Variable with higher correlation coefficiant\nimp = ['OverallQual', 'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'SalePrice' ]\n\n#Removing variable having higher correlation coefficiant\nfor i in imp:\n    imp_var_dis.remove(i)","3b108db4":"new_df_discrete = df_discrete[imp_var_dis]\nnew_df_discrete.head(5)","17640292":"## Changing the numerical values of discrete variables into string. So that the columns would never \n## repeat while One hot encoding.\nfor col in new_df_discrete.columns:\n    for i in range(len(new_df_discrete[col])):\n        new_df_discrete[col][i] = col+str(new_df_discrete[col][i])\n        #new_df_discrete[col][]","bda8005e":"new_df_discrete.head(5)","e83ddc91":"## Introducing OneHotEncoding\nencode = OneHotEncoder(drop='first',sparse=False)\nencode.fit(new_df_discrete)\n\ndf_discrete_dummies = encode.transform(new_df_discrete)\ndf_discrete_dummies = pd.DataFrame(df_discrete_dummies, columns=encode.get_feature_names(), index=new_df_discrete.index)\ndf_discrete_dummies.head(5)","9eafdbe3":"## Join the one hot encoded variable with the variables having highest correlation.\ndf_final_discrete = df_discrete[imp].join(df_discrete_dummies)\ndf_final_cont = df_num[list(df_continuous.columns)]\n\n# Drop Target Variable from dataframe\ndf_final_discrete = df_final_discrete.drop(\"SalePrice\", axis=1)\nprint(df_final_discrete.shape)\n# Drop Target Variable from dataframe\ndf_final_cont = df_final_cont.drop(\"SalePrice\", axis=1)\nprint(df_final_cont.shape)\nprint(df_cat_dummies.shape)","d83edebf":"# Concatenate all the dataframes to form final DF for modeling \ndf_final = df_final_discrete.join(df_final_cont.join(df_cat_dummies))","a3a97dbb":"## Normalise final dataframe using RobustScaler.\n\ndef normalise_encode(dataframe):\n    columns = list(dataframe.columns)\n    target_var = dataframe[\"SalePrice\"]\n    dataframe = dataframe.drop(\"SalePrice\", axis=1)\n\n    scaler = RobustScaler()\n    dataframe = scaler.fit_transform(dataframe)\n    dataframe = pd.DataFrame(dataframe, columns=columns.remove(\"SalePrice\"))\n    dataframe[\"SalePrice\"] = target_var\n    \n    return dataframe\n\n#df_final = normalise_encode(df_final)","1a2e0f55":"X = df_final.drop(\"SalePrice\", axis=1)\ny = df_final[\"SalePrice\"]\nprint(X.shape)\nprint(y.shape)","b118441a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")","cf6ad1da":"r2 = make_scorer(r2_score, greater_is_better=True)\nrmse = make_scorer(mean_squared_error,greater_is_better=False,squared=False)","b69eb43a":"model_name = \"LinearRegression\"\nmodel=LinearRegression()\n\nparam_grid = [{model_name+'__fit_intercept':[True,False]}]\npipeline = Pipeline([(model_name, model)])\nregressor = GridSearchCV(pipeline,param_grid,cv=5, scoring=rmse, n_jobs=-1)","4b870f3d":"regressor.fit(X_train, y_train)\nprint(f\"Best score: {regressor.best_score_}\")\nprint(f\"Best params: {regressor.best_params_}\")","b5305944":"y_pred = regressor.predict(X_test)\n\nmae_linear_enc = mean_absolute_error(y_test, y_pred)\nprint(\"Model 1 MAE: %d\" % (mae_linear_enc))\n\nr2_val_linear_enc = r2_score(y_test, y_pred)\nprint(f\"R2 Score: {r2_val_linear_enc}\")","77d75e8b":"pd.DataFrame({\"y_test\":y_test, \"y_pred\":y_pred}).head(5)","cc90d455":"model_name = \"Lasso\"\nmodel=Lasso()\n\nalpha = [2**i for i in range(-5, 15)]\nparam_grid = [  {model_name+'__'+'alpha': alpha}]","5477d7fa":"pipeline = Pipeline([(model_name, model)])\n\nreg=GridSearchCV(pipeline,param_grid,cv=5, scoring=rmse, n_jobs=-1)\nreg.fit(X_train,y_train.to_numpy())","2757b3ee":"print('best training param:',reg.best_params_)\nprint('best training score rmse', reg.best_score_)","89e02b60":"y_pred = reg.predict(X_test)\nmae_lasso_enc, rmsle_lasso_enc = mean_absolute_error(y_test, y_pred), np.sqrt(mean_squared_log_error(y_test, y_pred))\nprint(\"Model 1 MAE: %d, RMSLE: %f\" % (mae_lasso_enc, rmsle_lasso_enc))\n\nr2_value_lasso_enc = r2_score(y_test, y_pred)\nprint(f\"R2 Score: {r2_value_lasso_enc}\")","0bcd1545":"pd.DataFrame({\"y_test\":y_test, \"y_pred\":y_pred}).head(5)","2dda43f3":"model_name = \"Ridge\"\nmodel=Ridge()\n\nalpha = [2**i for i in range(-5, 15)]\n\nparam_grid = [{model_name+'__'+'alpha': alpha}]","794bbf14":"pipeline = Pipeline([(model_name, model)])\n\n\nreg=GridSearchCV(pipeline,param_grid,cv=5, scoring=rmse, n_jobs=-1)\nreg.fit(X_train,y_train.to_numpy())","a755e7f7":"print('best training param:',reg.best_params_)\nprint('best training score rmse', reg.best_score_)","7e008c55":"y_pred = reg.predict(X_test)\n\nmae_ridge_enc, rmsle_ridge_enc = mean_absolute_error(y_test, y_pred), np.sqrt(mean_squared_log_error(y_test, y_pred))\nprint(\"Model 1 MAE: %d, RMSLE: %f\" % (mae_ridge_enc, rmsle_ridge_enc))\n\nr2_value_ridge_enc = r2_score(y_test, y_pred)\nprint(f\"R2 Score: {r2_value_ridge_enc}\")","64d228c9":"pd.DataFrame({\"y_test\":y_test, \"y_pred\":y_pred}).head(5)","60c293e2":"table = PrettyTable()\ntable.field_names = [\"Model\", \"MAE\", \"RMSLE\", \"R-Squared Value\"]\ntable.add_row([\"Linear Regression\", mae_linear_enc, \"NA\", r2_val_linear_enc])\ntable.add_row([\"LASSO Regression\", mae_lasso_enc, rmsle_lasso_enc, r2_value_lasso_enc])\ntable.add_row([\"RIDGE Regression\", mae_ridge_enc, rmsle_ridge_enc, r2_value_ridge_enc])\n\nprint(table)","e19037d7":"For the reference for a normal distribution Skewness would be 0 and kurtosis would be 3.","bae9956a":"Here we are dividing the numerical variable into two different set for the better understading of the data. One is the continuous data variable and other discrete data variable.\n\n1. We have a total of 1460 datapoints.\n2. If we have a feature which having less than 15 unique values. Then we can take it as discrete feature. \n3. If we have feature which having greater than 15 unique value, we can take it as continuous feature.\n\nNote: This is just for Visualization and data analysis. We are not going to use it for prediction.","54849b3f":"## Linear Regression","f946a028":"As you can see the above graph are left or positive skewed. Which means people are more interested in small budget houses or in other word less people can afford expensive houses.","18f84203":"As we can see from the above image, features **'LotArea', 'BsmtFinSF2', 'LowQualFinSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'MiscVal'** are having outliers.\nThe steps that are required to follow inorder to get rid of this outliers problems are:\n1. Drop the outlier value: It is the most common method of get rid of outliers, we can simply drop the outlier data from the dataframe.\n2. Cap the outlier value: In this case, if the feature having lesser influence over the target feature, its better to cap the outlier value.\n3. Impute the outlier value: This method is very similar when we usually have a NULL value. We can either impute the outlier value with mean\/median or can predict the value with simple regression technique.\n\n**There are several techniques inorder to find the outliers, like z-score, finding IQR and so on. Here we are using Z score to find Outliers**","c4ca5745":"## Encoding Categorical Features\nEncoding the categorical features with OneHotEncoders","1bf96fbe":"As we can see that, 5 variables have more than 40% of NULL values. Which is better to drop at ths point.","e38c3bc3":"Observation: Model Lasso Regression is the best fit for the data, with an R-squared value of 0.90\nWe can achieve better accuracy by:\n* Introducing more feature engineering\n* Using RandomBoost or XGBoost algorithms\n* Select best Hyperparameters using RandomizedSearchCV and GridSearchCV on RandomForest and XGB\n\nThank you for your concentration. If you found any mistake in my analysis, please let me know.","031ed739":"# Modeling - Linear Regression","7bed017f":"# Exploratory Data Analysis","e53e0555":"## Relationship with Categorical Variable","2c383cff":"## Numerical Features with Continuous Values","fda4e8e7":"### Deal with Outliers","b1aea1cf":"## Modeling with Encoded variables","2ad5eb37":"## Analysing the results","624e4de5":"## Regression LASSO","6fbb8b0a":"### NULL in Numerical Values","fc68f695":"# Data Pre-Processing\nLets handle the numerical variable at the very first place.","6d0c8619":"Now the null values in categorical features are not significantly greater, we can replace it with the most frequent one.","f84e82e8":"As we cann see that ***'OverallQual', 'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars'*** has the highest correlation with ***'SalePrice'***","e309f0ce":"## Numerical Features with Discrete Values","1beeebde":"## Processing final dataframe for modeling","069a8748":"**Train Test Split**","cf30a53b":"# House Predict  Regression Analysis\n\n### About Data\n* data_description:\n* sample_submission.csv\n* test.csv\n* train.csv","56db576a":"# Linear Regression - Ridge","b376e512":"### NULL in Categorical Values","46c3303a":"Since we have 14% of total rows have atleast a single outlier value. So it is not a great idea to drop the row, as well as to impute the outlier value.","43650bc5":"# Encoding values in Discrete Variables","f0d0cf4b":"Since the number of NULL values are not significantly greater, on the other hand, there are possible outliers, we can impute missing value with median rather than mean.","c467a89a":"## Regression Ridge","1b710437":"## Linear Regression","8a9da9b6":"## Dealing with NULL Values\n### Finding NULL values in Entire Dataset","87968827":"## Linear Regression - LASSO","a7a8311b":"As we can see that ***'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea'***  variables has highest correlation with ***'SalePrice'***. ","6e8e2019":"## Taking all variables","2a9f0524":"## Relationship with Numerical Variable"}}