{"cell_type":{"4aef7502":"code","a9b5fce9":"code","5c0772cf":"code","ff479fa4":"code","972ea6e6":"code","41ec5ac8":"code","b0b5be37":"code","802eb104":"code","d7627c2e":"code","2fecd9cc":"code","39eb2bb8":"code","29aa1eb8":"code","b3e19a89":"code","5673d414":"code","9d4f0528":"code","d6087adf":"code","29b4c54b":"code","1a5d4a8b":"code","8dd254e6":"code","c98ea9b1":"code","7967ae6a":"code","d1397f4b":"code","5b53e7d9":"code","c5e4f9ef":"code","59f48ae6":"code","71bf8c6c":"code","75e4a109":"code","fa4b5126":"code","fc86110e":"code","6aa6ff98":"code","ca922521":"code","1d075bc5":"markdown","be3a8a63":"markdown","35c2b0a8":"markdown","3ed250de":"markdown","b837bf6b":"markdown","0c663c9b":"markdown"},"source":{"4aef7502":"import os\nimport time\nimport torch\nimport spacy\nimport random\nimport wordcloud\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport random\n\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nfrom tqdm import tqdm\nfrom sklearn.model_selection import *\nfrom transformers import *\n\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nplt.style.use('ggplot')\n\npd.set_option('display.max_columns', None)\npd.set_option('max_colwidth', None)\npd.set_option('max_rows', None)","a9b5fce9":"train_dir = \"..\/input\/feedback-prize-2021\/train\"\ntest_dir = \"..\/input\/feedback-prize-2021\/test\"\ntrain_files = os.listdir(train_dir)\ntest_files = os.listdir(test_dir)\n\nfor file in range(len(train_files)):\n    train_files[file] = str(train_dir) + \"\/\" +  str(train_files[file])\nfor file in range(len(test_files)):\n    test_files[file] = str(test_dir) + \"\/\" +  str(test_files[file])\n    \ntrain = pd.read_csv(\"..\/input\/feedback-prize-2021\/train.csv\")","5c0772cf":"test_df = pd.read_csv('..\/input\/feedback-prize-2021\/sample_submission.csv')\ntest_df","ff479fa4":"print(f'The training set has {train.shape[0]} rows and {train.shape[1]} columns')","972ea6e6":"train.head(3)","41ec5ac8":"print(f\"We have {train['id'].nunique()} essays\")","b0b5be37":"f = open(train_files[0], \"r\")\nprint(f.read())","802eb104":"f = open(test_files[4], \"r\")\nprint(f.read())","d7627c2e":"train.isnull().sum()","2fecd9cc":"color_discrete_map = {'German Shephfard': 'rgb(255,0,0)'}\nfig = px.bar(x = np.unique(train[\"discourse_type\"]),\n             y = [list(train[\"discourse_type\"]).count(i) for i in np.unique(train[\"discourse_type\"])] , \n             color = np.unique(train[\"discourse_type\"]),\n             color_discrete_map=color_discrete_map) \n\nfig.update_xaxes(title=\"Assets\")\nfig.update_yaxes(title = \"Number of Rows\")\nfig.update_layout(showlegend = True,title = {\n    'text': 'Discourse Type Distribution ',\n    'y':0.95,\n    'x':0.5,\n    'xanchor': 'center',\n    'yanchor': 'top'})\n\nfig.show()","39eb2bb8":"color_discrete_map = {'German Shephard': 'rgb(255,0,0)'}\nfig = px.bar(x = np.unique(train[\"discourse_type_num\"]),\n             y = [list(train[\"discourse_type_num\"]).count(i) for i in np.unique(train[\"discourse_type_num\"])] , \n             color = np.unique(train[\"discourse_type_num\"]),\n             color_discrete_map=color_discrete_map) \n\nfig.update_xaxes(title=\"Assets\")\nfig.update_yaxes(title = \"Number of Rows\")\nfig.update_layout(showlegend = True,title = {\n    'text': 'Discourse Element Distribution ',\n    'y':0.95,\n    'x':0.5,\n    'xanchor': 'center',\n    'yanchor': 'top'})\n\nfig.show()","29aa1eb8":"train[\"discourse_len\"] = train[\"discourse_end\"] - train[\"discourse_start\"]\nfig = px.box(data_frame= train, x=\"discourse_len\")\nfig.show()","b3e19a89":"train['full_text'] = train['discourse_text'].groupby(train['id']).transform(lambda x: ' '.join(x)) # obviously we will have duplicates","5673d414":"text_length = train['full_text'].drop_duplicates().apply(len)\n\nfig = plt.figure(figsize=(10,8))\n\nax1 = text_length.plot(kind='hist', color = \"#120f7a\", bins=100)\nax1.set_title('Essay Length Distribution')\nax1.set_xlabel(\"Essay Length\")\nax1.set_ylabel(\"Frequency\")\n\nplt.show()","9d4f0528":"word_count = train['full_text'].drop_duplicates().apply(lambda x: len(str(x).split()))\n\nfig = plt.figure(figsize=(10,8))\n\nax1 = word_count.plot(kind='hist', color = \"#120f7a\", bins=100)\nax1.set_title('Word Count Distribution')\nax1.set_xlabel(\"Word Count\")\nax1.set_ylabel(\"Frequency\")\n\nplt.show()","d6087adf":"wordcloud = wordcloud.WordCloud(stopwords=wordcloud.STOPWORDS, max_font_size=80, max_words=5000,\n                      width = 600, height = 400,\n                      background_color='black').generate(' '.join(txt for txt in train[\"discourse_text\"]))\nfig, ax = plt.subplots(figsize=(14,10))\nax.imshow(wordcloud, interpolation='bilinear')\nax.set_axis_off()\nplt.imshow(wordcloud);","29b4c54b":"CFG = {\n    'fold_num': 5, \n    'seed': 42,\n    'model': '..\/input\/roberta-base',\n    'max_len': 512,\n    'epochs': 5,\n    'train_bs': 24,\n    'valid_bs': 32,\n    'lr': 2e-5,\n    'num_workers': 0,\n    'weight_decay': 1e-6,\n}","1a5d4a8b":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(CFG['seed'])\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","8dd254e6":"test_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('..\/input\/feedback-prize-2021\/test'))):\n    test_names.append(f.replace('.txt', ''))\n    test_texts.append(open('..\/input\/feedback-prize-2021\/test\/' + f, 'r').read())\ntest_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\ntest_texts['text'] = test_texts['text'].apply(lambda x:x.split())\ntest_texts","c98ea9b1":"tokenizer = AutoTokenizer.from_pretrained(CFG['model'], add_prefix_space=True)","7967ae6a":"class MyDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        text = self.df.text.values[idx]\n        \n        return text","d1397f4b":"def collate_fn(data):\n    input_ids, attention_mask = [], []\n    \n    tokenized_inputs = tokenizer(\n        data,\n        max_length=CFG['max_len'],\n        padding='max_length',\n        truncation=True,\n        is_split_into_words=True,\n        return_tensors='pt'\n    )\n\n    words = []\n    for i in range(len(data)):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        words.append(word_ids)\n\n    tokenized_inputs[\"word_ids\"] = words\n    \n    return tokenized_inputs","5b53e7d9":"test_loader = DataLoader(MyDataset(test_texts), batch_size=CFG['valid_bs'], collate_fn=collate_fn, shuffle=False, num_workers=4)\nbatch = next(iter(test_loader))","c5e4f9ef":"batch","59f48ae6":"model =  AutoModelForTokenClassification.from_pretrained(CFG['model'], num_labels=15).to(device)\nmodel.load_state_dict(torch.load('..\/input\/feedback-roberta\/roberta-base_fold_0.pt'))\nmodel.eval()","71bf8c6c":"y_pred = []\nwords = []\n\nwith torch.no_grad():\n    tk = tqdm(test_loader, total=len(test_loader), position=0, leave=True)\n    for step, batch in enumerate(tk):\n        word_ids = batch['word_ids']\n        words.extend(word_ids)\n        batch = {k: v.to(device) for k, v in batch.items() if k != 'word_ids'}\n\n        output = model(**batch).logits\n\n        y_pred.extend(output.argmax(-1).cpu().numpy())\n        \ny_pred = np.array(y_pred)","75e4a109":"labels = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']","fa4b5126":"final_preds = []\n\nfor i in tqdm(range(len(test_texts))):\n    idx = test_texts.id.values[i]\n    pred = ['']*len(test_texts.text.values[i])\n\n    for j in range(len(y_pred[i])):\n        if words[i][j] != None:\n            pred[words[i][j]] = labels[y_pred[i][j]]\n\n    pred = [x.replace('B-','').replace('I-','') for x in pred]\n\n    preds = []\n    j = 0\n    while j < len(pred):\n        cls = pred[j]\n        if cls == 'O':\n            j += 1\n        end = j + 1\n        while end < len(pred) and pred[end] == cls:\n            end += 1\n            \n        if cls != 'O' and cls != '' and end - j > 10:\n            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n        \n        j = end","fc86110e":"final_preds[1]","6aa6ff98":"sub = pd.DataFrame(final_preds)\nsub.columns = test_df.columns\nsub","ca922521":"sub.to_csv('submission.csv', index=False)","1d075bc5":"# FEEDBACK PRIZE - EDA\n\nIf you find this notebook useful, support with an upvote\ud83d\udc4d\n\nModel Training Reference:\n* https:\/\/www.kaggle.com\/zzy990106\/pytorch-ner-infer\/notebook","be3a8a63":"# Modeling","35c2b0a8":"**The column descriptions are:**\n\n* id - ID code for essay response\n* discourse_id - ID code for discourse element\n* discourse_start - character position where discourse element begins in the essay response\n* discourse_end - character position where discourse element ends in the essay response\n* discourse_text - text of discourse element\n* discourse_type - classification of discourse element\n* discourse_type_num - enumerated class label of discourse element\n* predictionstring - the word indices of the training sample, as required for predictions","3ed250de":"**The 7 different Discourse Type**\n\n* Lead - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader\u2019s attention and point toward the thesis\n* Position - an opinion or conclusion on the main question\n* Claim - a claim that supports the position\n* Counterclaim - a claim that refutes another claim or gives an opposing reason to the position\n* Rebuttal - a claim that refutes a counterclaim\n* Evidence - ideas or examples that support claims, counterclaims, or rebuttals.\n* Concluding Statement - a concluding statement that restates the claims","b837bf6b":"Thank you.","0c663c9b":"### Import Libraries"}}