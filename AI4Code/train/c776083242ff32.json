{"cell_type":{"2dd8ca37":"code","1ef5d086":"code","95a707c0":"code","6193108f":"code","88e7dbb3":"code","e621d832":"code","e434adf3":"code","83516e6a":"code","2c908971":"code","60d016dc":"code","7d1ea44f":"code","3b9394f0":"code","6d5187c0":"code","0a56bf64":"code","83815242":"code","3e508061":"code","ff9ed75a":"code","6dcb1eb8":"code","0e3561d4":"code","361b9270":"code","617d2cc0":"code","6b315b09":"code","8ae3e59e":"code","b7fe9ab8":"code","fc297da9":"markdown","9fe2cc1e":"markdown","e43aa675":"markdown","b07d611c":"markdown","0a1dacb9":"markdown","4fa13952":"markdown","647adc84":"markdown","bf2b7962":"markdown","dc5675ec":"markdown","202bf7cf":"markdown","760f7c9e":"markdown","f3df947b":"markdown","077398a0":"markdown"},"source":{"2dd8ca37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1ef5d086":"# necessary libraries\nimport os\nimport pandas as pd\n\n# visualizations libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.image import imread\n%matplotlib inline\n\n# tensorflow libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras import optimizers\n\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\n\n# model evaluation libraries\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom mlxtend.plotting import plot_confusion_matrix","95a707c0":"base_dir= \"\/kaggle\/input\/tuberculosis-tb-chest-xray-dataset\/TB_Chest_Radiography_Database\"\nos.listdir(base_dir)","6193108f":"tuberculosis_data= \"\/kaggle\/input\/tuberculosis-tb-chest-xray-dataset\/TB_Chest_Radiography_Database\/Tuberculosis\"\nprint(\"tuberculosis images :\\n\" ,os.listdir(tuberculosis_data)[:5])\n\nnormal_data= \"\/kaggle\/input\/tuberculosis-tb-chest-xray-dataset\/TB_Chest_Radiography_Database\/Normal\"\nprint(\"\\nnormal images :\\n\" ,os.listdir(normal_data)[:5])","88e7dbb3":"print(\"no. of tuberculosis images :\" ,len(os.listdir(tuberculosis_data)))\nprint(\"\\nno. of normal images :\" ,len(os.listdir(normal_data)))","e621d832":"nrows= 4\nncols= 4\npic_index= 0\n\nfig= plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\npic_index+=8\n\ntuberculosis_img = [os.path.join(tuberculosis_data, image) for image in os.listdir(tuberculosis_data)[pic_index-8:pic_index]]\nnormal_img = [os.path.join(normal_data, image) for image in os.listdir(normal_data)[pic_index-8:pic_index]]\n\nfor i, image_path in enumerate(tuberculosis_img+normal_img):\n    sp = plt.subplot(nrows, ncols, i + 1)\n    sp.axis('Off') \n\n    img = mpimg.imread(image_path)\n    plt.imshow(img)\n\nplt.show()","e434adf3":"image= imread(\"\/kaggle\/input\/tuberculosis-tb-chest-xray-dataset\/TB_Chest_Radiography_Database\/Tuberculosis\/Tuberculosis-2422.png\")\nimage.shape","83516e6a":"# generating training data\nprint(\"training data :\")\ntrain_datagen= ImageDataGenerator(rescale=1\/255, zoom_range=0.3, rotation_range=50, width_shift_range= 0.2, height_shift_range=0.2, shear_range=0.2, \n                                   horizontal_flip=True, fill_mode='nearest', validation_split = 0.2)\n\ntrain_data = train_datagen.flow_from_directory(base_dir, \n                                              target_size= (300, 300),\n                                              class_mode= \"binary\",\n                                              batch_size=20,\n                                              subset= \"training\"\n                                              )\n\n# genarating validation data\nprint(\"\\nvalidation data :\")\nval_datagen= ImageDataGenerator(rescale= 1\/255, validation_split= 0.2)\n\nval_data= train_datagen.flow_from_directory(base_dir, \n                                              target_size= (300, 300),\n                                              class_mode= \"binary\",\n                                              batch_size=20,\n                                              shuffle= False,\n                                              subset= \"validation\"\n                                              )","2c908971":"train_data.class_indices","60d016dc":"# inceptionV3 model, with include_top= False we are not using fully connected layer of the inceptionV3 model, instead we\n#  will create our own Fully Connected and Output Layer according to our training data\ninception_model= InceptionV3(input_shape= (300, 300,3), include_top= False, weights=\"imagenet\")\n\n# Since we are creating our own fully connected layer we need output of the last inception model layer and flatten them \nlast_output= inception_model.layers[-1].output\n\n# Flattening the last output\nlast_output= Flatten()(last_output)\n\n# Our pretrained model\npretrained_model= Model(inception_model.input, last_output)    ","7d1ea44f":"pretrained_model.summary()","3b9394f0":"# layer 1\nx= Dense(units=512, activation=\"relu\")(last_output)\nx=Dropout(0.2)(x)\n\n# layer 2\nx= Dense(units=128, activation=\"relu\")(x)\nx=Dropout(0.2)(x)\n\n# output layer\nx= Dense(units=1, activation=\"sigmoid\")(x)\n\n# final model\nmodel= Model(pretrained_model.input, x)\n\nmodel.summary()","6d5187c0":"# compile model\nmodel.compile(loss=\"binary_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"accuracy\"])\n\n# Since the layers of InceptionV3 model are already trained, we don't want them to be trained again. \n# So we will freeze these layers\nfor layer in pretrained_model.layers:\n    layer.trainable= False\n\n# model fitting\nhistory= model.fit(train_data,\n                   steps_per_epoch= train_data.samples\/\/train_data.batch_size,\n                   validation_data= val_data,\n                   validation_steps= val_data.samples\/\/val_data.batch_size,\n                   epochs= 10,\n                   verbose=2 \n                  )","0a56bf64":"# model_1= Sequential()\n\n# model_1.add(Conv2D(filters= 16, kernel_size=(3,3), activation=\"relu\", input_shape=(300, 300, 3)))\n# model_1.add(MaxPooling2D(pool_size=(2,2)))\n\n# model_1.add(Conv2D(filters= 32, kernel_size=(3,3), activation=\"relu\"))\n# model_1.add(MaxPooling2D(pool_size=(2,2)))\n\n# model_1.add(Conv2D(filters= 64, kernel_size=(3,3), activation=\"relu\"))\n# model_1.add(MaxPooling2D(pool_size=(2,2)))\n\n# model_1.add(Conv2D(filters= 128, kernel_size=(3,3), activation=\"relu\"))\n# model_1.add(MaxPooling2D(pool_size=(2,2)))\n\n# model_1.add(Flatten())\n# model_1.add(Dense(units= 512, activation='relu'))\n# model_1.add(Dropout(0.2))\n\n# model_1.add(Dense(units=1, activation=\"sigmoid\"))\n\n# model_1.summary()","83815242":"# # model compiling\n# model_1.compile(loss= \"binary_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"accuracy\"])\n\n# history= model_1.fit(train_data,\n#                    steps_per_epoch= train_data.samples\/\/train_data.batch_size,\n#                    validation_data= val_data,\n#                    validation_steps= val_data.samples\/\/val_data.batch_size,\n#                    epochs= 10,\n#                    verbose=2 \n#                   )","3e508061":"history.history.keys()","ff9ed75a":"epochs= range(1, len(history.history[\"accuracy\"])+1)\n\nplt.plot(epochs, history.history[\"accuracy\"], color=\"purple\")\nplt.plot(epochs, history.history[\"val_accuracy\"], color=\"pink\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"accuracy\")\nplt.title(\"Accuracy plot\")\nplt.legend([\"train_acc\", \"val_acc\"])\nplt.show()\n\nplt.plot(epochs, history.history[\"loss\"], color=\"purple\")\nplt.plot(epochs, history.history[\"val_loss\"], color=\"pink\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"loss\")\nplt.title(\"Loss plot\")\nplt.legend([\"train_loss\", \"val_loss\"])\nplt.show()","6dcb1eb8":"prediction= model.predict(val_data, steps=np.ceil(val_data.samples\/val_data.batch_size), verbose=2)\nprediction= (prediction > 0.5)\nprediction","0e3561d4":"val_labels=val_data.classes\nval_labels","361b9270":"prediction.shape","617d2cc0":"val_labels.shape","6b315b09":"cm= confusion_matrix(val_data.classes, prediction)\nplot_confusion_matrix(cm, figsize=(5,5))\n\nprint(accuracy_score(val_data.classes, prediction))\nprint(classification_report(val_data.classes, prediction))","8ae3e59e":"model.save(\"tuberculosis.h5\")","b7fe9ab8":"# saving 1st model\n# model_1.save(\"bbb.h5\")","fc297da9":"# <span style=\"color:blue; font-family:monospace;\"> Model Building <\/span>","9fe2cc1e":"# <span style=\"color:blue; font-family:monospace;\"> Generating Train and Validation set using Data Augmentation <\/span>","e43aa675":"<center>\n<span style=\"color:crimson; font-size:25px;\"> InceptionV3 Model<\/span>\n<\/center>  ","b07d611c":"## <span style=\"color:blue; font-family:monospace;\"> Checking Model Performance<\/span>","0a1dacb9":"## <span style=\"color:blue; font-family:monospace;\"> Transfer Learning- InceptionV3 Model<\/span>","4fa13952":"### <span style=\"color:blue; font-family:monospace;\"> Class Labels <\/span>","647adc84":"## <span style=\"color:blue; font-family:monospace;\">Creating Dense Layers <\/span>","bf2b7962":"# <span style=\"color:blue; font-family:monospace;\"> Model Evaluation<\/span>","dc5675ec":"![istockphoto-1195893424-612x612.jpeg](attachment:9f141e8d-8522-4c12-9d7d-d5fa55c67294.jpeg)","202bf7cf":"# <span style=\"color:blue; font-family:monospace;\"> Explore Dataset <\/span>","760f7c9e":"### <span style=\"color:blue; font-family:monospace;\"> Let's have a look at the images <\/span>","f3df947b":"<center>\n<span style=\"color:crimson; font-size:42px;\"> Tuberculosis (TB) Chest X-ray Database <\/span>\n<\/center>    ","077398a0":"# <span style=\"color:blue; font-family:monospace;\"> Import libraries <\/span>"}}