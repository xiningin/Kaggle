{"cell_type":{"4e55a709":"code","e4f7ebfc":"code","b90076c9":"code","b32775b8":"code","91833d48":"code","bc0499fc":"code","72c60334":"code","d9cea209":"code","11257a0e":"code","2d49d8b7":"code","09281c47":"code","35d031fd":"code","e4883513":"code","bf3ed30b":"markdown","c04ba979":"markdown","bdfcca26":"markdown","b07c5ec8":"markdown","867655b2":"markdown","5d710065":"markdown","ae759efe":"markdown","4596d05c":"markdown","55e3925b":"markdown","a29f1952":"markdown","14d1e046":"markdown","1de46065":"markdown"},"source":{"4e55a709":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Load in data\nDS = pd.read_csv('\/kaggle\/input\/kaggle-survey-2019\/multiple_choice_responses.csv', delimiter = ',')\n#DS.head()\nDS['Q3'] = DS['Q3'].astype('category')\nDS['Q4'] = DS['Q4'].astype('category')\nDS['Q2'] = DS['Q2'].astype('category')\nDS['Q1'] = DS['Q1'].astype('category')\nDS['Q5'] = DS['Q5'].astype('category')\nDS['Q10'] = DS['Q10'].astype('category')\nDS['Q14'] = DS['Q14'].astype('category')\nHighestPaid = DS[(DS.Q10 == \"> $500,000\") | (DS.Q10 == \"100,000-124,999\") | (DS.Q10 == \"125,000-149,999\") | (DS.Q10 == \"150,000-199,999\") | (DS.Q10 == \"200,000-249,999\") | (DS.Q10 == \"250,000-299,999\") | (DS.Q10 == \"300,000-500,000\")]\n#HighestPaid.head()","e4f7ebfc":"GCP = HighestPaid['Q29_Part_1'].count() \nAWS = HighestPaid['Q29_Part_2'].count() \nMicrosoftAzure = HighestPaid['Q29_Part_3'].count() \nIBMCloud = HighestPaid['Q29_Part_4'].count() \nAlibabaCloud = HighestPaid['Q29_Part_5'].count() \nSalesforceCloud = HighestPaid['Q29_Part_6'].count() \nOracleCloud = HighestPaid['Q29_Part_7'].count() \nSAPCloud = HighestPaid['Q29_Part_8'].count() \nVMwareCloud = HighestPaid['Q29_Part_9'].count() \nRedHatCloud = HighestPaid['Q29_Part_10'].count() \n\nnsum = GCP + AWS + MicrosoftAzure + IBMCloud + AlibabaCloud + SalesforceCloud + OracleCloud + SAPCloud + VMwareCloud + RedHatCloud\n\nGCP = GCP \/ nsum\nAWS = AWS \/ nsum\nMicrosoftAzure = MicrosoftAzure \/ nsum\nIBMCloud = IBMCloud \/ nsum\nAlibabaCloud = AlibabaCloud \/ nsum\nSalesforceCloud = SalesforceCloud \/nsum \nOracleCloud = OracleCloud \/ nsum\nSAPCloud = SAPCloud \/ nsum\nVMwareCloud = VMwareCloud \/ nsum\nRedHatCloud = RedHatCloud \/ nsum\n\n############\n\nGCP1 = DS['Q29_Part_1'].count() \nAWS1 = DS['Q29_Part_2'].count() \nMicrosoftAzure1 = DS['Q29_Part_3'].count() \nIBMCloud1 = DS['Q29_Part_4'].count() \nAlibabaCloud1 = DS['Q29_Part_5'].count() \nSalesforceCloud1 = DS['Q29_Part_6'].count() \nOracleCloud1 = DS['Q29_Part_7'].count() \nSAPCloud1 = DS['Q29_Part_8'].count() \nVMwareCloud1 = DS['Q29_Part_9'].count() \nRedHatCloud1 = DS['Q29_Part_10'].count() \n\nnsum = GCP1 + AWS1 + MicrosoftAzure1 + IBMCloud1 + AlibabaCloud1 + SalesforceCloud1 + OracleCloud1 + SAPCloud1 + VMwareCloud1 + RedHatCloud1\n\nGCP1 = GCP1 \/ nsum\nAWS1 = AWS1 \/ nsum\nMicrosoftAzure1 = MicrosoftAzure1 \/ nsum\nIBMCloud1 = IBMCloud1 \/ nsum\nAlibabaCloud1 = AlibabaCloud1 \/ nsum\nSalesforceCloud1 = SalesforceCloud1 \/nsum \nOracleCloud1 = OracleCloud1 \/ nsum\nSAPCloud1 = SAPCloud1 \/ nsum\nVMwareCloud1 = VMwareCloud1 \/ nsum\nRedHatCloud1 = RedHatCloud1 \/ nsum\n\nplt.style.use('ggplot')\n\nx = ['Google Cloud Platform GCP', 'Amazon Web Services (AWS)', 'Microsoft Azure', 'IBM Cloud', 'Alibaba Cloud', 'Salesforce Cloud', 'Oracle Cloud', 'SAP Cloud', 'VMware Cloud', 'Red Hat Cloud']\nenergy = [GCP, AWS, MicrosoftAzure , IBMCloud, AlibabaCloud , SalesforceCloud, OracleCloud , SAPCloud, VMwareCloud, RedHatCloud]\nenergy1 = [GCP1, AWS1, MicrosoftAzure1 , IBMCloud1, AlibabaCloud1 , SalesforceCloud1, OracleCloud1 , SAPCloud1, VMwareCloud1, RedHatCloud1]\n\nN = 10\nind = np.arange(N) \nwidth = 0.35  \n\n#x_pos = [i for i, _ in enumerate(x)]\n\nplt.bar(ind + width, energy, width, color='Blue')\nplt.bar(ind, energy1, width, color='Green')\nplt.xlabel(\"Platform\")\nplt.ylabel(\"Percent of People\")\nplt.title(\"Which of the following cloud computing platforms do you use on a regular basis?\")\n\nplt.xticks(ind, x, rotation=40, ha=\"right\")\n\nplt.show()","b90076c9":"Scikitlearn  = DS['Q28_Part_1'].count() \nTensorFlow = DS['Q28_Part_2'].count() \nKeras  = DS['Q28_Part_3'].count() \nRandomForest = DS['Q28_Part_4'].count() \nXgboost = DS['Q28_Part_5'].count() \nPyTorch = DS['Q28_Part_6'].count() \nCaret = DS['Q28_Part_7'].count() \nLightGBM = DS['Q28_Part_8'].count() \nSparkMLib = DS['Q28_Part_9'].count() \nFastai = DS['Q28_Part_10'].count() \n\nnsum = Scikitlearn + TensorFlow + Keras + RandomForest + Xgboost + PyTorch + Caret + LightGBM + SparkMLib + Fastai\n\nScikitlearn  = Scikitlearn \/ nsum\nTensorFlow = TensorFlow \/ nsum\nKeras  = Keras\/ nsum\nRandomForest = RandomForest\/ nsum\nXgboost = Xgboost \/ nsum\nPyTorch = PyTorch\/ nsum\nCaret = Caret \/ nsum \nLightGBM = LightGBM \/ nsum \nSparkMLib = SparkMLib \/ nsum \nFastai = Fastai \/ nsum\n\n########################\n\nScikitlearn1  = HighestPaid['Q28_Part_1'].count() \nTensorFlow1 = HighestPaid['Q28_Part_2'].count() \nKeras1  = HighestPaid['Q28_Part_3'].count() \nRandomForest1 = HighestPaid['Q28_Part_4'].count() \nXgboost1 = HighestPaid['Q28_Part_5'].count() \nPyTorch1 = HighestPaid['Q28_Part_6'].count() \nCaret1 = HighestPaid['Q28_Part_7'].count() \nLightGBM1 = HighestPaid['Q28_Part_8'].count() \nSparkMLib1 = HighestPaid['Q28_Part_9'].count() \nFastai1 = HighestPaid['Q28_Part_10'].count() \n\nnsum1 = Scikitlearn1 + TensorFlow1 + Keras1 + RandomForest1 + Xgboost1 + PyTorch1 + Caret1 + LightGBM1 + SparkMLib1 + Fastai1\n\nScikitlearn1  = Scikitlearn1 \/ nsum1\nTensorFlow1 = TensorFlow1 \/ nsum1\nKeras1  = Keras1 \/ nsum1\nRandomForest1 = RandomForest1 \/ nsum1\nXgboost1 = Xgboost1 \/ nsum1\nPyTorch1 = PyTorch1 \/ nsum1\nCaret1 = Caret1 \/ nsum1\nLightGBM1 = LightGBM1 \/ nsum1\nSparkMLib1 = SparkMLib1 \/ nsum1\nFastai1 = Fastai1 \/ nsum1\n\nplt.style.use('ggplot')\n\nx = ['Scikit-learn', 'TensorFlow', 'Keras', 'RandomForest', 'Xgboost', 'PyTorch', 'Caret', 'LightGBM', 'Spark MLib', 'Fast.ai ']\nenergy = [Scikitlearn, TensorFlow , Keras, RandomForest, Xgboost, PyTorch, Caret, LightGBM, SparkMLib , Fastai ]\nenergy1 = [Scikitlearn1, TensorFlow1 , Keras1, RandomForest1, Xgboost1, PyTorch1, Caret1, LightGBM1, SparkMLib1, Fastai1]\n\nN = 10\nind = np.arange(N) \nwidth = 0.35  \n\n#x_pos = [i for i, _ in enumerate(x)]\n\nplt.bar(ind, energy, width, color='Green')\nplt.bar(ind + width, energy1, width, color='Blue')\nplt.xlabel(\"Framework\")\nplt.ylabel(\"Percent of People\")\nplt.title(\"Which of the following machine learning frameworks do you use on a regular basis?\")\n\nplt.xticks(ind, x, rotation=40, ha=\"right\")\n\nplt.show()","b32775b8":"KaggleNotebooks = DS['Q17_Part_1'].count() \nGoogleColab  = DS['Q17_Part_2'].count() \nMicrosoftAzureNotebooks  = DS['Q17_Part_3'].count() \nGoogleNotebooks = DS['Q17_Part_4'].count() \nPaperspaceGradient  = DS['Q17_Part_5'].count() \nFloydHub = DS['Q17_Part_6'].count() \nBinderJupyterHub  = DS['Q17_Part_7'].count() \nIBMWatsonStudio = DS['Q17_Part_8'].count() \nCodeOcean  = DS['Q17_Part_9'].count() \nAWSNotebookProducts = DS['Q17_Part_10'].count() \n\nnsum = KaggleNotebooks + GoogleColab + MicrosoftAzureNotebooks + GoogleNotebooks + PaperspaceGradient + FloydHub + BinderJupyterHub + IBMWatsonStudio + CodeOcean + AWSNotebookProducts\n\nKaggleNotebooks = KaggleNotebooks \/ nsum\nGoogleColab  = GoogleColab \/ nsum\nMicrosoftAzureNotebooks  =  MicrosoftAzureNotebooks \/ nsum\nGoogleNotebooks =  GoogleNotebooks \/ nsum\nPaperspaceGradient  = PaperspaceGradient \/ nsum\nFloydHub = FloydHub \/ nsum\nBinderJupyterHub  =  BinderJupyterHub \/ nsum\nIBMWatsonStudio =  IBMWatsonStudio \/ nsum\nCodeOcean  =  CodeOcean \/ nsum\nAWSNotebookProducts =  AWSNotebookProducts \/ nsum\n\n##############33\n\nKaggleNotebooks1 = HighestPaid['Q17_Part_1'].count() \nGoogleColab1  = HighestPaid['Q17_Part_2'].count() \nMicrosoftAzureNotebooks1  = HighestPaid['Q17_Part_3'].count() \nGoogleNotebooks1 = HighestPaid['Q17_Part_4'].count() \nPaperspaceGradient1  = HighestPaid['Q17_Part_5'].count() \nFloydHub1 = HighestPaid['Q17_Part_6'].count() \nBinderJupyterHub1  = HighestPaid['Q17_Part_7'].count() \nIBMWatsonStudio1 = HighestPaid['Q17_Part_8'].count() \nCodeOcean1  = HighestPaid['Q17_Part_9'].count() \nAWSNotebookProducts1 = HighestPaid['Q17_Part_10'].count() \n\nnsum1 = KaggleNotebooks1 + GoogleColab1 + MicrosoftAzureNotebooks1 + GoogleNotebooks1 + PaperspaceGradient1 + FloydHub1 + BinderJupyterHub1 + IBMWatsonStudio1 + CodeOcean1 + AWSNotebookProducts1\n\nKaggleNotebooks1 = KaggleNotebooks1 \/ nsum1\nGoogleColab1  = GoogleColab1 \/ nsum1\nMicrosoftAzureNotebooks1  =  MicrosoftAzureNotebooks1 \/ nsum1\nGoogleNotebooks1 =  GoogleNotebooks1 \/ nsum1\nPaperspaceGradient1  = PaperspaceGradient1 \/ nsum1\nFloydHub1 = FloydHub1 \/ nsum1\nBinderJupyterHub1  =  BinderJupyterHub1 \/ nsum1\nIBMWatsonStudio1 =  IBMWatsonStudio1 \/ nsum1\nCodeOcean1  =  CodeOcean1 \/ nsum1\nAWSNotebookProducts1 =  AWSNotebookProducts1 \/ nsum1\n\nplt.style.use('ggplot')\n\nx = ['Kaggle Notebooks', 'Google Colab ', 'Microsoft Azure Notebooks ', 'Google Cloud Notebook Products', 'Paperspace \/ Gradient ', 'FloydHub', 'Binder \/ JupyterHub', 'IBM Watson Studio', 'Code Ocean', 'AWS Notebook Products']\nenergy = [KaggleNotebooks, GoogleColab, MicrosoftAzureNotebooks, GoogleNotebooks, PaperspaceGradient, FloydHub, BinderJupyterHub, IBMWatsonStudio, CodeOcean, AWSNotebookProducts]\nenergy1 = [KaggleNotebooks1, GoogleColab1, MicrosoftAzureNotebooks1, GoogleNotebooks1, PaperspaceGradient1, FloydHub1, BinderJupyterHub1, IBMWatsonStudio1, CodeOcean1, AWSNotebookProducts1]\n\nN = 10\nind = np.arange(N) \nwidth = 0.35  \n\n#x_pos = [i for i, _ in enumerate(x)]\n\nplt.bar(ind, energy, width, color='Green')\nplt.bar(ind + width, energy1, width, color='Blue')\nplt.xlabel(\"Notebook\")\nplt.ylabel(\"Percent of People\")\nplt.title(\"Which of the following hosted notebook products do you use on a regular basis?\")\n\nplt.xticks(ind, x, rotation=40, ha=\"right\")\n\nplt.show()","91833d48":"Udacity = DS['Q13_Part_1'].count() \nCoursera = DS['Q13_Part_2'].count() \nedX = DS['Q13_Part_3'].count() \nDataCamp = DS['Q13_Part_4'].count() \nDataQuest = DS['Q13_Part_5'].count() \nKaggleCourses = DS['Q13_Part_6'].count() \nFastai = DS['Q13_Part_7'].count() \nUdemy = DS['Q13_Part_8'].count() \nLinkedinLearning = DS['Q13_Part_9'].count() \nUniversityCourses = DS['Q13_Part_10'].count() \n\nnsum = Udacity + Coursera + edX + DataCamp + DataQuest + KaggleCourses + Fastai + Udemy + LinkedinLearning + UniversityCourses\n\nUdacity = Udacity \/ nsum\nCoursera = Coursera \/ nsum\nedX = edX \/ nsum\nDataCamp = DataCamp \/ nsum\nDataQuest = DataQuest \/ nsum\nKaggleCourses = KaggleCourses \/ nsum\nFastai = Fastai \/ nsum\nUdemy = Udemy \/ nsum\nLinkedinLearning = LinkedinLearning \/ nsum\nUniversityCourses = UniversityCourses \/ nsum\n\n##############\n\nUdacity1 = HighestPaid['Q13_Part_1'].count() \nCoursera1 = HighestPaid['Q13_Part_2'].count() \nedX1 = HighestPaid['Q13_Part_3'].count() \nDataCamp1 = HighestPaid['Q13_Part_4'].count() \nDataQuest1 = HighestPaid['Q13_Part_5'].count() \nKaggleCourses1 = HighestPaid['Q13_Part_6'].count() \nFastai1 = HighestPaid['Q13_Part_7'].count() \nUdemy1 = HighestPaid['Q13_Part_8'].count() \nLinkedinLearning1 = HighestPaid['Q13_Part_9'].count() \nUniversityCourses1 = HighestPaid['Q13_Part_10'].count() \n\nnsum1 = Udacity1 + Coursera1 + edX1 + DataCamp1 + DataQuest1 + KaggleCourses1 + Fastai1 + Udemy1 + LinkedinLearning1 + UniversityCourses1\n\nUdacity1 = Udacity1 \/ nsum1\nCoursera1 = Coursera1 \/ nsum1\nedX1 = edX1 \/ nsum1\nDataCamp1 = DataCamp1 \/ nsum1\nDataQuest1 = DataQuest1 \/ nsum1\nKaggleCourses1 = KaggleCourses1 \/ nsum1\nFastai1 = Fastai1 \/ nsum1\nUdemy1 = Udemy1 \/ nsum1\nLinkedinLearning1 = LinkedinLearning1 \/ nsum1\nUniversityCourses1 = UniversityCourses1 \/ nsum1\n\nplt.style.use('ggplot')\n\nx = ['Udacity', 'Coursera', 'edX', 'DataCamp', 'DataQuest', 'Kaggle Courses', 'Fast.ai', 'Udemy', 'Linkedin Learning', 'University Courses']\nenergy = [Udacity, Coursera, edX, DataCamp, DataQuest, KaggleCourses, Fastai, Udemy, LinkedinLearning, UniversityCourses]\nenergy1 = [Udacity1, Coursera1, edX1, DataCamp1, DataQuest1, KaggleCourses1, Fastai1, Udemy1, LinkedinLearning1, UniversityCourses1]\n\nN = 10\nind = np.arange(N) \nwidth = 0.35  \n\nplt.bar(ind, energy, width, color='Green')\nplt.bar(ind + width, energy1, width, color='Blue')\nplt.xlabel(\"Platform\")\nplt.ylabel(\"Percent of People\")\nplt.title(\"On which platforms have Highly Paid Professionals begun or completed data science courses?\")\n\nplt.xticks(ind, x, rotation=40, ha=\"right\")\n\nplt.show()","bc0499fc":"Jupyter = DS['Q16_Part_1'].count() \nRStudio = DS['Q16_Part_2'].count() \nPyCharm = DS['Q16_Part_3'].count() \nAtom = DS['Q16_Part_4'].count() \nMATLAB = DS['Q16_Part_5'].count() \nVisualStudio = DS['Q16_Part_6'].count() \nSpyder = DS['Q16_Part_7'].count() \nVimEmacs = DS['Q16_Part_8'].count() \nNotePad = DS['Q16_Part_9'].count() \nSublimeText = DS['Q16_Part_10'].count() \n\nnsum = Jupyter + RStudio + PyCharm + Atom + MATLAB + VisualStudio + Spyder + VimEmacs + NotePad + SublimeText\n\nJupyter = Jupyter \/ nsum\nRStudio = RStudio \/ nsum\nPyCharm = PyCharm \/ nsum\nAtom = Atom \/ nsum\nMATLAB = MATLAB \/ nsum\nVisualStudio = VisualStudio \/ nsum\nSpyder = Spyder \/ nsum\nVimEmacs = VimEmacs \/ nsum\nNotePad = NotePad \/ nsum\nSublimeText = SublimeText \/ nsum\n\n##############\n\nJupyter1 = HighestPaid['Q16_Part_1'].count() \nRStudio1 = HighestPaid['Q16_Part_2'].count() \nPyCharm1 = HighestPaid['Q16_Part_3'].count() \nAtom1 = HighestPaid['Q16_Part_4'].count() \nMATLAB1 = HighestPaid['Q16_Part_5'].count() \nVisualStudio1 = HighestPaid['Q16_Part_6'].count() \nSpyder1 = HighestPaid['Q16_Part_7'].count() \nVimEmacs1 = HighestPaid['Q16_Part_8'].count() \nNotePad1 = HighestPaid['Q16_Part_9'].count() \nSublimeText1 = HighestPaid['Q16_Part_10'].count() \n\nnsum1 = Jupyter1 + RStudio1 + PyCharm1 + Atom1 + MATLAB1 + VisualStudio1 + Spyder1 + VimEmacs1 + NotePad1 + SublimeText1\n\nJupyter1 = Jupyter1 \/ nsum1\nRStudio1 = RStudio1 \/ nsum1\nPyCharm1 = PyCharm1 \/ nsum1\nAtom1 = Atom1 \/ nsum1\nMATLAB1 = MATLAB1 \/ nsum1\nVisualStudio1 = VisualStudio1 \/ nsum1\nSpyder1 = Spyder1 \/ nsum1\nVimEmacs1 = VimEmacs1 \/ nsum1\nNotePad1 = NotePad1 \/ nsum1\nSublimeText1 = SublimeText1 \/ nsum1\n\nplt.style.use('ggplot')\n\nx = ['Jupyter', 'RStudio', 'PyCharm', 'Atom', 'MATLAB', 'Visual Studio', 'Spyder', 'Vim \/ Emacs', 'NotePad++', 'Sublime Text']\nenergy = [Jupyter, RStudio, PyCharm, Atom, MATLAB, VisualStudio, Spyder, VimEmacs, NotePad, SublimeText]\nenergy1 = [Jupyter1, RStudio1, PyCharm1, Atom1, MATLAB1, VisualStudio1, Spyder1, VimEmacs1, NotePad1, SublimeText1]\n\nN = 10\nind = np.arange(N) \nwidth = 0.35  \n\nplt.bar(ind, energy, width, color='Green')\nplt.bar(ind + width, energy1, width, color='Blue')\nplt.xlabel(\"IDE\")\nplt.ylabel(\"Percent of People\")\nplt.title(\"Which of the following IDE's do you use on a regular basis?\")\n\nplt.xticks(ind, x, rotation=40, ha=\"right\")\n\nplt.show()","72c60334":"Python = DS['Q18_Part_1'].count() \nR  = DS['Q18_Part_2'].count() \nSQL  = DS['Q18_Part_3'].count() \nC = DS['Q18_Part_4'].count() \nCplusplus = DS['Q18_Part_5'].count() \nJava = DS['Q18_Part_6'].count() \nJavascript  = DS['Q18_Part_7'].count() \nTypeScript = DS['Q18_Part_8'].count() \nBash  = DS['Q18_Part_9'].count() \nMATLAB = DS['Q18_Part_10'].count() \n\nnsum = Python + R + SQL + C + Cplusplus + Java + Javascript + TypeScript + Bash + MATLAB\n\nPython = Python \/ nsum\nR  = R \/ nsum\nSQL = SQL \/ nsum\nC =  C \/ nsum\nCplusplus = Cplusplus \/ nsum\nJava = Java \/ nsum\nJavascript = Javascript \/ nsum\nTypeScript = TypeScript \/ nsum\nBash = Bash \/ nsum\nMATLAB = MATLAB \/ nsum\n\n########\n\nhPython = HighestPaid['Q18_Part_1'].count() \nhR  = HighestPaid['Q18_Part_2'].count() \nhSQL  = HighestPaid['Q18_Part_3'].count() \nhC = HighestPaid['Q18_Part_4'].count() \nhCplusplus = HighestPaid['Q18_Part_5'].count() \nhJava = HighestPaid['Q18_Part_6'].count() \nhJavascript  = HighestPaid['Q18_Part_7'].count() \nhTypeScript = HighestPaid['Q18_Part_8'].count() \nhBash  = HighestPaid['Q18_Part_9'].count() \nhMATLAB = HighestPaid['Q18_Part_10'].count() \n\nnsumh = hPython + hR + hSQL + hC + hCplusplus + hJava + hJavascript + hTypeScript + hBash + hMATLAB\n\nhPython = hPython \/ nsumh\nhR  = hR \/ nsumh\nhSQL = hSQL \/ nsumh\nhC =  hC \/ nsumh\nhCplusplus = hCplusplus \/ nsumh\nhJava = hJava \/ nsumh\nhJavascript = hJavascript \/ nsumh\nhTypeScript = hTypeScript \/ nsumh\nhBash = hBash \/ nsumh\nhMATLAB = hMATLAB \/ nsumh\n\n\nplt.style.use('ggplot')\n\nx = ['Python', 'R', 'SQL', 'C', 'C++', 'Java', 'Javascript', 'TypeScript', 'Bash', 'MATLAB']\nenergy = [Python, R, SQL, C, Cplusplus, Java, Javascript, TypeScript, Bash, MATLAB]\nenergy1 = [hPython, hR, hSQL, hC, hCplusplus, hJava, hJavascript, hTypeScript, hBash, hMATLAB]\n\nN = 10\nind = np.arange(N) \nwidth = 0.35  \n\nplt.bar(ind, energy, width, color='Green')\nplt.bar(ind + width, energy1, width, color='Blue')\nplt.xlabel(\"Language\")\nplt.ylabel(\"Percent of People\")\nplt.title(\"What programming languages do you use on a regular basis?\")\n\nplt.xticks(ind, x, rotation=40, ha=\"right\")\n\nplt.show()","d9cea209":"Ggplotggplot2 = DS['Q20_Part_1'].count() \nMatplotlib = DS['Q20_Part_2'].count() \nAltair  = DS['Q20_Part_3'].count() \nShiny = DS['Q20_Part_4'].count() \nD3js = DS['Q20_Part_5'].count() \nPlotlyPlotlyExpress = DS['Q20_Part_6'].count() \nBokeh = DS['Q20_Part_7'].count() \nSeaborn = DS['Q20_Part_8'].count() \nGeoplotlib = DS['Q20_Part_9'].count() \nLeafletFolium  = DS['Q20_Part_10'].count() \n\nnsum = Ggplotggplot2 + Matplotlib + Altair + Shiny + D3js + PlotlyPlotlyExpress + Bokeh + Seaborn + Geoplotlib + LeafletFolium\n\nGgplotggplot2 =  Ggplotggplot2 \/ nsum\nMatplotlib =  Matplotlib \/ nsum\nAltair = Altair \/ nsum\nShiny =  Shiny \/ nsum\nD3js = D3js \/ nsum\nPlotlyPlotlyExpress = PlotlyPlotlyExpress \/ nsum\nBokeh = Bokeh \/ nsum\nSeaborn = Seaborn \/ nsum\nGeoplotlib = Geoplotlib \/ nsum\nLeafletFolium  = LeafletFolium \/ nsum\n\n##################\n\nhGgplotggplot2 = HighestPaid['Q20_Part_1'].count() \nhMatplotlib = HighestPaid['Q20_Part_2'].count() \nhAltair  = HighestPaid['Q20_Part_3'].count() \nhShiny = HighestPaid['Q20_Part_4'].count() \nhD3js = HighestPaid['Q20_Part_5'].count() \nhPlotlyPlotlyExpress = HighestPaid['Q20_Part_6'].count() \nhBokeh = HighestPaid['Q20_Part_7'].count() \nhSeaborn = HighestPaid['Q20_Part_8'].count() \nhGeoplotlib = HighestPaid['Q20_Part_9'].count() \nhLeafletFolium  = HighestPaid['Q20_Part_10'].count() \n\nnsumh = hGgplotggplot2 + hMatplotlib + hAltair + hShiny + hD3js + hPlotlyPlotlyExpress + hBokeh + hSeaborn + hGeoplotlib + hLeafletFolium\n\nhGgplotggplot2 =  hGgplotggplot2 \/ nsumh\nhMatplotlib =  hMatplotlib \/ nsumh\nhAltair = hAltair \/ nsumh\nhShiny =  hShiny \/ nsumh\nhD3js = hD3js \/ nsumh\nhPlotlyPlotlyExpress = hPlotlyPlotlyExpress \/ nsumh\nhBokeh = hBokeh \/ nsumh\nhSeaborn = hSeaborn \/ nsumh\nhGeoplotlib = hGeoplotlib \/ nsumh\nhLeafletFolium  = hLeafletFolium \/ nsumh\n\n\nplt.style.use('ggplot')\n\nx = ['Ggplot \/ ggplot2', 'Matplotlib', 'Altair', 'Shiny', 'D3.js', 'Plotly \/ Plotly Express', 'Bokeh', 'Seaborn', 'Geoplotlib ', 'Leaflet \/ Folium ']\nenergy = [Ggplotggplot2, Matplotlib , Altair, Shiny, D3js, PlotlyPlotlyExpress, Bokeh, Seaborn, Geoplotlib , LeafletFolium ]\nenergy1 = [hGgplotggplot2, hMatplotlib , hAltair, hShiny, hD3js, hPlotlyPlotlyExpress, hBokeh, hSeaborn, hGeoplotlib , hLeafletFolium ]\n\nN = 10\nind = np.arange(N) \nwidth = 0.35  \n\nplt.bar(ind, energy, width, color='Green')\nplt.bar(ind + width, energy1, width, color='Blue')\nplt.xlabel(\"Library\")\nplt.ylabel(\"Percent of People\")\nplt.title(\"What data visualization libraries or tools do you use on a regular basis?\")\n\nplt.xticks(ind, x, rotation=40, ha=\"right\")\n\nplt.show()","11257a0e":"ax = sns.countplot(x=\"Q5\", data=DS)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","2d49d8b7":"ax = sns.countplot(x=\"Q5\", data=HighestPaid)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","09281c47":"ax = sns.countplot(x=\"Q14\", data=DS)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","35d031fd":"ax = sns.countplot(x=\"Q14\", data=HighestPaid)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","e4883513":"ax = sns.countplot(x=\"Q19\", data=HighestPaid)\n\nax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\nplt.tight_layout()\nplt.show()","bf3ed30b":"We have seen several coorelations between data science skills, tools, and high salaries. Learning advanced technologies and finding areas to specialize is one good approach to increase your value. Another conclusion we have drawn is that cloud technologies are on the rise, and skills or experience in AWS are highly valued. Learning to do things that others find difficult is a great way to increase your earning potential.","c04ba979":"A larger percentage of the general population uses Scikit-learn, TensorFlow, Keras, and other cloud computing platforms than highly paid people. However, people with large salaries are more likely to use Xgboost on a regular basis.\nXgboost is an open source machine learning framework that is effecient, and flexible. It is a good choice for data scientists, and if you aren't familiar with it you may want to consider studying it. It is a popular choice among highly paid data scientists.","bdfcca26":"This analyses again shows that highly paid professionals tend to favor AWS products much more than \nthe typical person. They were also more likely to use other products such as Binder \/ JupyterHub, or Google Colab than others. The majority of average respondants favored Kaggle Notebooks, which makes sense since the people taking this survey were all kagglers.\nExpanding the toolkit of hosted notebook products you use seems to be a good way to increase your value as a data scientist.","b07c5ec8":"Survey participants were asked, \"what do you recommend to learn first?\" and the results of the highly paid professionals are shown below. Python was the overwhelming recommendation followed by R and SQL. If you are new to data science, these are the areas to start your study. ","867655b2":"The graph above compares the platforms people have completed data science courses on. Coursera is a very reputable platform for learning data science topics and we can see that it is the most popular platform across the board. \nAnother trend we see is that after Coursera, the top three choices are consistent among the groups, but in opposite orders. The general population uses Kaggle Courses, Udemy, and University Courses in that order. Highly educated professionals favor the same three platforms but in the order of University Courses, Udemy, and Kaggle Courses.","5d710065":"Which IDEs do people use? And which IDEs do people with high salaries use? The chart above examines this and we can see the percentage of people that use each IDE is fairly consistent with a few exeptions. RStudio and VimEmacs are used more frequently by highly paid professionals than by the general population. \nRStudio has a steeper learning curve than Jupyter products but also has more data science capabilities. Vim and Emacs also show a larger adoption by highly paid professionals. Specializing in tools, especially tools that have advanced capabilities but are difficult to learn can really pay off. ","ae759efe":"The visualization above compares which programming languages are used on a regular basis. We can see the general survey participant uses Python more frequently than highly paid professionals. However, highly paid professionals use SQL, R, and Bash more frequently. Bash has the biggest difference in the percentage of users. Bash can be very useful in data science, especially for activities such as creating data pipelines. Learning tools and skills that separate you from the rest of the pack, such as Bash scripting can impress your boss and peers and appears to be coorelated with high salarys.","4596d05c":"The chart above shows the primary tool used at work or school to analyze data. We can see that the most common tools used are local development environment and basic statistical software such as excel. This differs from the tools used by highly paid professionals which are shown below. \nHighly paid professionals most commonly use local development environments and cloud-based software. Again, we can see a clear trend that understanding how to use cloud-based products such as AWS give you a clear advantage when it comes to more money. Common tools such are excel require less skill to use and that could explain why we see the average person is more likely to use them than a highly paid person. \nIt would be advantageous to expand your skill set to include cloud-based software.","55e3925b":"We want to see what the highest paid data science skills are.\n\nIn each visualization below we compare the percentages of all survey participants with the percenatages of highly paid survey participants to see which data science tools and skills are most valuable.\n\nIn the visualizations below, highly paid survey participants are represented in blue and the general population are represented in green. (highly paid survey participants are those with an annual salary over $100,000).","a29f1952":"In the visualization above we can see that a larger proportion of  highly paid professionals use Amazon Web Services. Organizations are willing to pay for people who have skills in AWS. Companies are moving to the cloud and are desperate for people who can help them leverage the benefits of cloud computing.","14d1e046":"The cell above shows the number of people that associate with each role. This compares with the graph below which shows the number of highly paid professionals that associate with each role. We can see that no highly paid professionals classify themselves as students. We can also see there is a smaller proportion of business and data analysts among the highly paid. The majority of both groups identify as data scientists.","1de46065":"The graph above compares which data visualization tools are used on a regular basis. The general population favors Matplotlib and Seaborn more than the group of highly paid professionals. These are very common, popular, and effective tools. We can also see that the group of highly paid people are more likely to use the less well known tools such as Shiny, D3.js, and Bokeh. Shiny and D3.js are visualization tools for R scripts. While Bokeh is commonly used with Python and easily be integrated into django applications. These tools all show promise as emerging data science technologies. There again seems to be a consistent coorelation with high salaries and skills in less common tools. "}}