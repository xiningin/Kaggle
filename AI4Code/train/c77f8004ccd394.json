{"cell_type":{"dde0a10d":"code","0f2692b0":"code","8b49720b":"code","c484de9e":"code","7e561e90":"code","7145d7ee":"code","6fe0c266":"code","6d452c6e":"code","b0d4df48":"code","6b2b28f2":"code","9717d49d":"code","ef856a6b":"code","ce5c5f0d":"code","5f7ffc4f":"code","cb647522":"code","9879e81f":"code","68bb6552":"code","c684367b":"code","0a140622":"code","326bc850":"code","cf67a23b":"code","f1572a5b":"code","1972e08a":"markdown","e2987a46":"markdown","9fab8baa":"markdown","efe83512":"markdown","d79ee6a1":"markdown","101be0e2":"markdown","9256346d":"markdown","3ee737a2":"markdown","e42c914c":"markdown","beda0554":"markdown","d9a45e21":"markdown","8975f9df":"markdown","ff2648a1":"markdown","7376c722":"markdown"},"source":{"dde0a10d":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom numpy.random import RandomState\nimport pickle\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import plot_confusion_matrix\n\n# CLASSIFIERS FOR TRAINING\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression","0f2692b0":"df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv', header = 0)","8b49720b":"df.head(7) # look for first 7 rows","c484de9e":"df.shape # print size of dataframe","7e561e90":"# convert from float64 to float32 to reduce memory size\ndf = df.astype({col: 'float32' for col in df.select_dtypes('float64').columns}) \ndf = df.astype({col: 'int32' for col in df.select_dtypes('int64').columns}) \n# df.dtypes # print types of df","7145d7ee":"count_classes = df['Class'].value_counts()\nplt.title(\"Records in each class\")\ncount_classes.plot(kind='bar', color='c')\nplt.xticks(rotation='horizontal')\nplt.xlabel(\"Class\")\nplt.ylabel(\"Count\")\nplt.show()","6fe0c266":"# all time was divided to 4 different intervals\nbins = [0, max(df['Time'])\/4, max(df['Time'])\/2, 3*max(df['Time'])\/4, max(df['Time'])] \ntime_intervals = pd.cut(df['Time'], bins=bins)","6d452c6e":"# and then we group data by class\ndf_grouped2 = df.groupby(['Class', time_intervals]).size().reset_index(name='Count')\ndf_grouped2","b0d4df48":"# creating masks\nmask1 = df_grouped2['Class']==0\nmask2 = df_grouped2['Class']==1\n\n# applying masks\ndf_sliced1 = df_grouped2.loc[mask1]\ndf_sliced2 = df_grouped2.loc[mask2]","6b2b28f2":"# creating plot with 2 subplots\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,3))\n\n# setting colormaps for each subplot\ncolor1 = plt.cm.spring(np.linspace(0, 1, len(df_sliced1['Time'].unique())))\ncolor2 = plt.cm.winter(np.linspace(0, 1, len(df_sliced1['Time'].unique())))\n\n# drawing plots\ndf_sliced1.plot(x='Time', y='Count', kind = 'bar', color=color1, title='Class 0', ax=axes[0])\ndf_sliced2.plot(x='Time', y='Count', kind = 'bar', color=color2, title='Class 1', ax=axes[1])\n\nplt.show()","9717d49d":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,3))\n\n# titles for plots\naxes[0].title.set_text('Class 0')\naxes[1].title.set_text('Class 1')\n\n# colors for drawing boxplots (used for 'patch_artist' below)\ncolor1 = dict(boxes=\"pink\")\ncolor2 = dict(boxes=\"tan\")\n\nbplot1 = df_sliced1.boxplot(column=['Count'], grid=False, ax=axes[0], color=color1, patch_artist=True)\nbplot2 = df_sliced2.boxplot(column=['Count'], grid=False, ax=axes[1], color=color2, patch_artist=True)\n\nplt.show()","ef856a6b":"scaler = MinMaxScaler(feature_range=(0, 1))\nnormed = scaler.fit_transform(df)\ndf_normed = pd.DataFrame(data=normed, columns=df.columns)\ndf_normed.head()","ce5c5f0d":"rng = RandomState()\n\ntrain = df_normed.sample(frac=0.7, random_state=rng)\nval = df_normed.loc[~df_normed.index.isin(train.index)]\n\ntrain.reset_index(drop=True, inplace=True)\nval.reset_index(drop=True, inplace=True)","5f7ffc4f":"print(\"\u2666 TRAIN SET:\")\ntrain.head(3)","cb647522":"print(\"\u2666 VALIDATION SET:\")\nval.head(3)","9879e81f":"# form 'x' and 'y' data\nx_columns = df.columns[:-1]\ny_column = df.columns[-1]","68bb6552":"# create 'x' and 'y' data for train\nx_raw_train = train[x_columns]\ny_raw_train = train[y_column]\n\nX_train = x_raw_train.copy()\nY_train = y_raw_train.copy()","c684367b":"# create 'x' and 'y' data for validation\nx_raw_val = val[x_columns]\ny_raw_val = val[y_column]\n\nX_val = x_raw_val.copy()\nY_val = y_raw_val.copy()","0a140622":"# list of all classifiers whick will be used for our data\nall_classifers = [\n    KNeighborsClassifier(2),\n    SVC(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()\n]","326bc850":"# there we will store accuracies to build plots and for choosing the best classifier\nall_acc = {}","cf67a23b":"# learn all classifiers, write accuracy and save trained models in pickle-format\n\nfor classifier in all_classifers:\n    \n    # get the classifier name \n    classfier_name = classifier.__class__.__name__ \n    \n    # train model\n    model = classifier\n    model.fit(X_train, Y_train)\n    \n    # validate model\n    model_pred = model.predict(X_val)\n    model_acc = accuracy_score(Y_val, model_pred)\n    \n    # calculate confusion matrix for train and val subsets\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,6))\n    # titles for plots (1 common and 2 for subplots)\n    plt.suptitle(classfier_name, fontsize=14)\n    axes[0].title.set_text('Confusion Matrix (Train)')\n    axes[1].title.set_text('Confusion Matrix (Val)')\n    plot_confusion_matrix(model, X_train, Y_train, cmap=plt.cm.RdPu, ax=axes[0])\n    plot_confusion_matrix(model, X_val, Y_val, cmap=plt.cm.GnBu, ax=axes[1])\n    \n    \n    # save its accuracy\n    all_acc[classfier_name] = model_acc\n    \n    # save model\n    filename = classfier_name + '_model.pickle'\n    pickle.dump(model, open(filename, 'wb'))  \n    \n    # load model\n    loaded_model = pickle.load(open(filename, 'rb'))\n    result = loaded_model.score(X_val, Y_val)     \n    \n    # print results\n    print(\"\u2666 {:<30} = {:<12} {:>10} = {:>12}\".format(classfier_name, round(model_acc, 7),\n                                                   \"loaded_model score\", round(result, 7)))\n    \n    \n    \nplt.show() # show plots in the end ","f1572a5b":"# sort accuracies from biggest to smallest\nall_acc = dict(sorted(all_acc.items(), key=lambda item: item[1], reverse=True))\n\n# get keys and values as parameters to build plot\nkeys = all_acc.keys()\nvalues = all_acc.values()\n\n# color map for bar chart\ncolor = plt.cm.cool(np.linspace(0, 1, len(keys)))\n\n# plot\nplt.figure(figsize=(5,5))\nplt.title('ACCURACY OF CLASSIFIERS')\nplt.xlabel('classifiers')\nplt.ylabel('accuracy')\nplt.bar(keys, values, color=color)\nplt.xticks(rotation = 'vertical')\nplt.show()","1972e08a":"# 6. Split dataset to input and output variables (x and y)\nHere we can see, that we should predicit *'Class'* variable, so it will be our 'y' and another columns will represent 'x'.","e2987a46":"Also, we can **draw boxplots** to see, how the data is distributed.","9fab8baa":"After that, we can build **bar charts** for each class.","efe83512":"# 2. Read data","d79ee6a1":"# 5. Split to train and val subsets\nHere we're going to split data to train and validation subsets as **70% to 30%** respectively *(parameter frac=70)*.","101be0e2":"# 8. Conclusion\nThank you for reading my new article! Hope, you liked it and it was interesting for you! There are some more my articles:\n\n* [Neural Network for beginners with keras](https:\/\/www.kaggle.com\/maricinnamon\/neural-network-for-beginners-with-keras)\n* [Fetal Health Classification for beginners sklearn](https:\/\/www.kaggle.com\/maricinnamon\/fetal-health-classification-for-beginners-sklearn)\n* [Retail Trade Report Department Stores (LSTM)](https:\/\/www.kaggle.com\/maricinnamon\/retail-trade-report-department-stores-lstm)\n* [Market Basket Analysis for beginners](https:\/\/www.kaggle.com\/maricinnamon\/market-basket-analysis-for-beginners)","9256346d":"After that we can check, **how many records were in each class during all the time**.","3ee737a2":"# 3. Visualize data\nFirstly, lets see **how many records each class have**.","e42c914c":"After training, we can build **bar chart** to compare the training results and choose the best trained model with the biggest accuracy score.","beda0554":"# CREDIT CARD FRAUD DETECTION\nHello everyone! In this notebook we are going to learn classifiers to predict fraud in transactions.","d9a45e21":"# 4. Normalize data\nWe will apply **min-max normalization** for our data.","8975f9df":"# 7. Classification itself\nHere we are going learn our classificators. ","ff2648a1":"![image.png](attachment:57eaa374-6230-4dba-9043-96b72f86cc0b.png)","7376c722":"# 1. Import libraries\nFor classifying tasks we will use [sklearn](https:\/\/scikit-learn.org\/stable\/) library."}}