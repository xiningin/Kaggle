{"cell_type":{"9bde76c0":"code","796c4041":"code","1621ee3a":"code","0aed6e11":"code","8a10b391":"code","73bb3fa0":"code","4d7e61cd":"code","fd7a9605":"code","4e036995":"code","89070e57":"code","fa78ca4f":"code","6c18c854":"code","7e34d6e1":"code","99b3a9fb":"code","b7b1671e":"code","f70a0c3f":"code","56d64154":"code","b29db20d":"code","a55b6813":"code","54c13726":"code","e4cbd46e":"code","7c0aca05":"code","bbd339a4":"code","0e7822fc":"code","adfd73fe":"code","217b7f94":"code","9a2e46c3":"code","a1f5434e":"code","c9c900b3":"code","29048b6a":"code","aec4ba5d":"code","c940ddf0":"code","e3bcf4e3":"code","29b27e48":"code","c61f3809":"code","b378bb97":"code","6abcd91d":"code","9dea3f43":"code","acd775a1":"code","d91ba747":"code","279a7d0a":"code","077f93a4":"code","b2bf4c10":"code","5061d4fa":"code","eed43d45":"code","4605b95f":"code","2834b64a":"code","2a54b255":"code","78e29b7d":"code","4ce900d2":"code","cb018a00":"code","8948e51b":"code","85461fd4":"code","b51abdc1":"code","81412539":"code","0d71bd8c":"code","dbb87738":"code","482d1553":"code","7bd2e0e8":"markdown","25fa1e8c":"markdown","bf9dfcc3":"markdown","7d6806b7":"markdown","dd30bc42":"markdown","5c7ba302":"markdown","9ec5761e":"markdown","f5942352":"markdown","2ee2189b":"markdown","bb47c222":"markdown","3c984eab":"markdown","c6eee27b":"markdown","5940b3b8":"markdown","21ab476b":"markdown","f8633aed":"markdown","11b6bbc3":"markdown","c03a6d2d":"markdown","53603da8":"markdown","b820254c":"markdown"},"source":{"9bde76c0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm \nimport sklearn\nfrom sklearn.model_selection import train_test_split","796c4041":"cars_data = pd.read_csv(\"..\/input\/car-price-prediction\/CarPrice_Assignment.csv\")   #Importing the data\ncars_data.head()","1621ee3a":"cars_data.columns   ","0aed6e11":"cars_data.shape  # 205 data-points and 26 variables","8a10b391":"cars_data.info()   #No null-values","73bb3fa0":"cars_data.describe()   ","4d7e61cd":"# Lets verify the correlation between various variables\nplt.figure(figsize=(20,10))\nsns.heatmap(cars_data.corr(),annot = True)    \nplt.show()","fd7a9605":"# Dropping the variables\ncars_data.drop(['car_ID','carwidth','curbweight','wheelbase','highwaympg'],axis=1,inplace=True)","4e036995":"cars_data['CarName'] = cars_data['CarName'].str.replace('-', ' ')\ncars_data['CarName'] = cars_data['CarName'].apply(lambda x : x.split(' ',1)[0])\ncars_data['CarName'].unique()","89070e57":"cars_data['CarName'].value_counts()","fa78ca4f":"cars_data['CarName'] = cars_data['CarName'].replace({\"toyouta\":\"toyota\",\"maxda\":\"mazda\",\"Nissan\":\"nissan\",\"vw\":\"volkswagen\",\"vokswagen\":\"volkswagen\",\"porcshce\":\"porsche\"})","6c18c854":"cars_data['CarName'].value_counts()","7e34d6e1":"cars_data.head()","99b3a9fb":"cars_data['fueltype'].value_counts()   #converting into binary variables","b7b1671e":"cars_data['fueltype'] = cars_data['fueltype'].apply(lambda x : 1 if x=='gas' else 0)\ncars_data['fueltype'].value_counts()","f70a0c3f":"cars_data['aspiration'].value_counts()   #converting into binary variables","56d64154":"cars_data['aspiration'] = cars_data['aspiration'].apply(lambda x : 1 if x=='std' else 0)\ncars_data['aspiration'].value_counts()","b29db20d":"cars_data['doornumber'].value_counts()   #converting into binary variables","a55b6813":"cars_data['doornumber'] = cars_data['doornumber'].apply(lambda x : 2 if x=='four' else 1)\ncars_data['doornumber'].value_counts()","54c13726":"cars_data['enginelocation'].value_counts()   #converting into binary variables","e4cbd46e":"cars_data['enginelocation'] = cars_data['enginelocation'].apply(lambda x : 1 if x=='front' else 0)\ncars_data['enginelocation'].value_counts()","7c0aca05":"cars_data['cylindernumber'].value_counts()","bbd339a4":"# Creating dummy variabels for left out categorical variables\ncars_data = pd.get_dummies(cars_data)  \ncars_data.head()","0e7822fc":"cars_data.info()","adfd73fe":"from sklearn.preprocessing import MinMaxScaler  #Lets use min max scaler\nscaler = MinMaxScaler()","217b7f94":"#Scaling the numeric varibles only\nnum_vars = ['symboling', 'carlength', 'carheight','enginesize', 'boreratio', 'stroke', 'compressionratio','horsepower', 'peakrpm', 'citympg', 'price']\n\ncars_data[num_vars] = scaler.fit_transform(cars_data[num_vars])\n\n","9a2e46c3":"cars_data.describe()","a1f5434e":"#Spliting the data into train(70%) and test(30%)\nfrom sklearn.model_selection import train_test_split\ndf_train,df_test = train_test_split(cars_data,train_size=0.7,test_size = 0.3,random_state=100)","c9c900b3":"y_train = df_train.pop('price')  #Result variable\nX_train = df_train               #Predictor variables","29048b6a":"from sklearn.feature_selection import RFE \nfrom sklearn.linear_model import LinearRegression","aec4ba5d":"lm = LinearRegression()          \nlm.fit(X_train, y_train)\nrfe = RFE(lm, 15)     #Taking 15 variables \nrfe = rfe.fit(X_train, y_train)","c940ddf0":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","e3bcf4e3":"rfe_drop = X_train.columns[~rfe.support_]\nrfe_drop","29b27e48":"X_train = X_train.drop(rfe_drop,axis=1)  #Removing the unwanted variables\nX_train.columns","c61f3809":"import statsmodels.api as sm        \nX_train_rfe_lm = sm.add_constant(X_train)","b378bb97":"#First model\nlm_1 = sm.OLS(y_train,X_train_rfe_lm).fit()\nlm_1.summary()","6abcd91d":"df_VIF= cars_data.drop(rfe_drop,axis=1)","9dea3f43":"#Function to find the VIF values of the variables\ndef vif_cal(input_data, dependent_col):\n    vif_df = pd.DataFrame( columns = ['Var', 'Vif'])\n    x_vars=input_data.drop([dependent_col], axis=1)\n    xvar_names=x_vars.columns\n    for i in range(0,xvar_names.shape[0]):\n        y=x_vars[xvar_names[i]] \n        x=x_vars[xvar_names.drop(xvar_names[i])]\n        rsq=sm.OLS(y,x).fit().rsquared  \n        vif=round(1\/(1-rsq),2)\n        vif_df.loc[i] = [xvar_names[i], vif]\n    return vif_df.sort_values(by = 'Vif', axis=0, ascending=False, inplace=False)","acd775a1":"vif_cal(input_data=df_VIF, dependent_col=\"price\")","d91ba747":"#Removing 'enginetype_rotor' variable\nX_train2 = X_train.drop(['enginetype_rotor'],axis=1)\nX_train_rfe_lm2 = sm.add_constant(X_train2)","279a7d0a":"#Second Model\nlm_1 = sm.OLS(y_train,X_train_rfe_lm2).fit()\nlm_1.summary()","077f93a4":"#Again checking the VIF values for 2nd model\ndf_VIF = df_VIF.drop('enginetype_rotor', axis =1)\nvif_cal(input_data=df_VIF, dependent_col=\"price\")","b2bf4c10":"df_VIF.columns","5061d4fa":"#Checking the Correlations between all the remaining variables\nplt.figure(figsize=(20,10))\nsns.heatmap(df_VIF.corr(),annot=True)\nplt.show()","eed43d45":"df_VIF =df_VIF.drop(['enginesize','boreratio','stroke'],axis=1)\n#Lets check the VIF tables again\nvif_cal(input_data=df_VIF, dependent_col=\"price\")","4605b95f":"X_train2.columns","2834b64a":"X_train3 = X_train2.drop(['enginesize','boreratio','stroke'],axis=1)\n\n#Third model\nX_train_rfe_lm3 = sm.add_constant(X_train3)\nlm_2 = sm.OLS(y_train,X_train_rfe_lm3).fit()\nlm_2.summary()\n","2a54b255":"#Making predicitions on training data\ny_train_predict = lm_2.predict(X_train_rfe_lm3)","78e29b7d":"#Plotting error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_predict), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \n","4ce900d2":"df_test.head()","cb018a00":"#Separating result and predictor variables\ny_test = df_test.pop('price')\nX_test = df_test","8948e51b":"X_test.head()","85461fd4":"#Adding constant term for statsmodels.api\nX_test_new = X_test[X_train3.columns]\nX_test_new = sm.add_constant(X_test_new)","b51abdc1":"X_test_new.head()","81412539":"#Predicting...\ny_test_pred = lm_2.predict(X_test_new)\ny_test_pred.head()","0d71bd8c":"y_test.head()","dbb87738":"#Finally plotting the predicted y with y_test\nfig = plt.figure()\nplt.scatter(y_test,y_test_pred)\nfig.suptitle('y_test vs y_pred', fontsize=20)              \nplt.xlabel('y_test', fontsize=18)                          \nplt.ylabel('y_pred', fontsize=16) ","482d1553":"from sklearn.metrics import r2_score\nr2_score(y_test, y_test_pred)","7bd2e0e8":"**Here there are some company names that are spelled wrong. Hence we need to correct those**\n1. Toyota\n2. Mazda\n3. Nissan\n4. Volkswagan\n5. Porsche","25fa1e8c":"**The CarName column is in the format 'Company_name-Car_name'.**\n1. Lets keep company name only for the further analysis\n2. Changing 'Alpha-Romero' to 'Alpha' ","bf9dfcc3":"**The variables with value '1' are the top 15 variable that we will be considering**","7d6806b7":"## Data Preparation -","dd30bc42":"**Feature Scaling needs to be done as price column has a high value as compared to other columns**","5c7ba302":"**Observations**\n1. R-squared and Adj.R-squared values have reduced but are still high values\n2. As these values are high, model explains the variance of the data properly.\n3. VIF tables has values less than '5' so multicollinear variables are handeled.","9ec5761e":"**Lets use statsmodels to build the model so as to use summary function to get into depth of the model**","f5942352":"**We will be using mixed approach to find the best predictor variables**\n***Recurrsive Feature Elimination and Manual feature reduction***","2ee2189b":"**Observations**\n1. R-squared and Adj. R-squared are not affected alot.\n2. Lets check the VIF table again","bb47c222":"**The R-Squared value of the prediction is = 0.88. Hence 88.6% of the variance of data is explained by the model**","3c984eab":"**Observation**\n1. 'car_ID' variable is irrelavent\n2. Some variable show a high correlation between each other which will affect the final mode\n","c6eee27b":"## Model Building -","5940b3b8":"## Residual Check - ","21ab476b":"**Observations**\n1. Good r-squared value\n2. Adj. r-squared value is close to r-squared value\n**Lets check the VIF values as well**","f8633aed":"## Data Understanding -","11b6bbc3":"**There are high correlation valaues between some variables, hence removing them**","c03a6d2d":"**'enginetype_rotor' and 'cylindernumber_two' has a large VIF values which means they is multicollinear with other variables**","53603da8":"## Predictions -","b820254c":"**Error terms follow a normal distribution**"}}