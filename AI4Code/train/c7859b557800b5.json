{"cell_type":{"3ab6b662":"code","93de6ccb":"code","0152e7cf":"code","a86bb21a":"code","fe9a0b3d":"code","9aabdf06":"code","bc5ff19f":"code","3e11575d":"code","0167b252":"code","43bed5d8":"code","19f49112":"code","6a0514ae":"code","be971269":"code","3b7d32e4":"code","601f7cdc":"code","e64bb8ab":"code","15a6310e":"code","c6bef01b":"code","9adff04b":"code","b59bd635":"code","74d06821":"code","c26dea5d":"code","fb3bf803":"code","12113488":"code","45e40ee4":"code","460c66b3":"code","5f18b5fa":"code","ac4d1cea":"code","ef38d6c6":"code","af9ce1bc":"code","dedfc8b4":"code","dd1a1e7e":"code","47b00453":"code","e29f564e":"code","191a11e4":"code","e3f5ab75":"code","6f216e7d":"code","9c84b4e4":"code","0113a1d6":"code","b0473cae":"code","2f8a59b8":"code","c5e63c8f":"code","45850a0f":"code","efe84949":"code","24ebc543":"code","2401e12c":"code","ac768c91":"code","88c5b3f6":"code","f0c05ab5":"markdown","5ba6a99b":"markdown","b25b1384":"markdown","28b2d8fe":"markdown","64aa3b13":"markdown","ea36f6a0":"markdown","47dc0484":"markdown","b6e5d3bd":"markdown","f8aa5516":"markdown","c065f3cc":"markdown","254cf013":"markdown","03119f8d":"markdown","0b07fe9c":"markdown","d4cb6dde":"markdown","7d687fd8":"markdown","08ba62bf":"markdown","257f8b33":"markdown","597deaac":"markdown","088a9c8e":"markdown","da26a3ec":"markdown","cedb8480":"markdown","d78f8de8":"markdown","d6125291":"markdown","596e254d":"markdown","62a5792b":"markdown"},"source":{"3ab6b662":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","93de6ccb":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","0152e7cf":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","a86bb21a":"train.info()","fe9a0b3d":"train.describe()","9aabdf06":"test.info()","bc5ff19f":"# Study Pclass\npd.pivot_table(train, index = 'Pclass', values = ['Survived'])","3e11575d":"# Study name\ntrain.Name.head(10)","0167b252":"# Split the name into family and title\ntrain['Title'] = train.Name.apply(lambda x: x.split(',')[1].split('.')[0])\ntrain['Family'] = train.Name.apply(lambda x: x.split(',')[0])\n\nprint('Title values')\nprint(train.Title.value_counts())\nprint('Family values')\nprint(train.Family.value_counts())","43bed5d8":"train = train.drop('Family',axis=1)\npd.pivot_table(train, index = 'Title', values = ['Survived'])","19f49112":"train['Title'] = train.Title.apply(lambda x: x.replace('Mlle','Miss').replace('Mme','Mrs').replace('Col','Others').replace('Major','Others').replace('Don','Others').replace('Lady','Others').replace('Sir','Others').replace('Capt','Others').replace('the Countess','Others').replace('Ms','Others').replace('Jonkheer','Others'))\npd.pivot_table(train, index = 'Title', values = ['Survived'])\n\n","6a0514ae":"# I apply all this to the test dataset\ntest['Title'] = test.Name.apply(lambda x: x.split(',')[1].split('.')[0])\ntest['Title'] = test.Title.apply(lambda x: x.replace('Mlle','Miss').replace('Mme','Mrs').replace('Col','Others').replace('Major','Others').replace('Don','Others').replace('Lady','Others').replace('Sir','Others').replace('Capt','Others').replace('the Countess','Others').replace('Ms','Others').replace('Jonkheer','Others'))\ntest.head()","be971269":"# I will remove Name from both datasets\ntrain = train.drop('Name',axis = 1)\ntest = test.drop('Name',axis = 1)","3b7d32e4":"# Study sex\npd.pivot_table(train, index = 'Sex', values = ['Survived'])\n","601f7cdc":"# Study Age,SibSp ,Parch and Fare\n# Isolate survivors\nsurv = train.copy()\nsurv.drop(surv[surv['Survived']==0].index, inplace=True)\nnum = ['Age','SibSp','Parch','Fare']\nfor x in num:\n    fig = plt.figure(figsize=(15,15))\n    ax1 = plt.subplot2grid((3,2),(0,0))\n    plt.hist(train[x])\n    plt.title(x +' Total')\n    ax1 = plt.subplot2grid((3,2),(0,1))\n    plt.hist(surv[x])\n    plt.title(x + ' Survived')\n    plt.show()\n\n","e64bb8ab":"print('Total')\nprint(train[num].describe())\nprint('Survived')\nprint(surv[num].describe())","15a6310e":"# Check the correlations\nnum.append('Survived')\nprint(train[num].corr())\nsns.heatmap(train[num].corr())","c6bef01b":"ageMean = train.groupby('Title')['Age'].median()\nmeanDr = ageMean[0]\nmeanMaster = ageMean[1]\nmeanMiss = ageMean[2]\nmeanMr = ageMean[3]\nmeanMrs = ageMean[4]\nmeanOthers = ageMean[5]\nmeanRev = ageMean[6]\nageMean\n","9adff04b":"# Fill NA with the mean based on his Title\nfor x in range(len(train[\"Age\"])):\n    if pd.isna(train[\"Age\"][x]):\n        title = train[\"Title\"][x]\n        title = title.strip() # This is for remove spaces\n        if(title == 'Dr'):\n            train[\"Age\"][x] = meanDr\n           \n        elif(title == \"Master\"):\n            train[\"Age\"][x] = meanMaster\n           \n        elif(title == \"Miss\"):\n            train[\"Age\"][x] = meanMiss\n\n        elif(title ==\"Mr\"):\n            train[\"Age\"][x] = meanMr\n        elif(title == \"Mrs\"):\n            train[\"Age\"][x] = meanMrs\n        elif(title == \"Others\"):\n            train[\"Age\"][x] = meanOthers\n        elif(title == \"Rev\"):\n            train[\"Age\"][x] = meanRev\n            \nfor x in range(len(test[\"Age\"])):\n    if pd.isna(test[\"Age\"][x]):\n        title = test[\"Title\"][x]\n        title = title.strip() # This is for remove spaces\n        if(title == 'Dr'):\n            test[\"Age\"][x] = meanDr\n           \n        elif(title == \"Master\"):\n            test[\"Age\"][x] = meanMaster\n           \n        elif(title == \"Miss\"):\n            test[\"Age\"][x] = meanMiss\n\n        elif(title ==\"Mr\"):\n            test[\"Age\"][x] = meanMr\n        elif(title == \"Mrs\"):\n            test[\"Age\"][x] = meanMrs\n        elif(title == \"Others\"):\n            test[\"Age\"][x] = meanOthers\n        elif(title == \"Rev\"):\n            test[\"Age\"][x] = meanRev\n","b59bd635":"# Group by age\ntrain['AgeGroup'] = train.Age.apply(lambda x: 'Baby' if x <= 5 else ('Child' if x <= 12 else('Teenager' if x <= 18 else ('Young') if x <= 24 else ('Young Adult' if x <= 35 else ('Adult' if x <= 60 else 'Senior')))) )\nprint(pd.pivot_table(train, index = 'AgeGroup', values = ['Survived']))\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train)\nplt.show()","74d06821":"test['AgeGroup'] = test.Age.apply(lambda x: 'Baby' if x <= 5 else ('Child' if x <= 12 else('Teenager' if x <= 18 else ('Young') if x <= 24 else ('Young Adult' if x <= 35 else ('Adult' if x <= 60 else 'Senior')))) )\n","c26dea5d":"# Study Ticket\ntrain.Ticket","fb3bf803":"\ntrain['NumericTicket'] = train.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\npd.pivot_table(train, index = 'NumericTicket', values = ['Survived'])","12113488":"\ntrain = train.drop('NumericTicket',axis=1)\ntrain = train.drop('Ticket',axis=1)\ntest = test.drop('Ticket',axis=1)","45e40ee4":"# Study Cabin\ntrain.Cabin","460c66b3":"\ntrain['has_cabin'] = train.Cabin.apply(lambda x: 0 if pd.isna(x) else 1)\ntrain['CabinLetter'] = train.Cabin.apply(lambda x: str(x)[0])\ntrain.head()","5f18b5fa":"# Check if has_cabin is useful\nprint(pd.pivot_table(train, index = 'has_cabin', values = ['Survived']))\nsns.barplot(x=\"has_cabin\", y=\"Survived\", data=train)\nplt.show()","ac4d1cea":"print(pd.pivot_table(train, index = 'CabinLetter', values = ['Survived']))\nsns.barplot(x=\"CabinLetter\", y=\"Survived\", data=train)\nplt.show()","ef38d6c6":"test['has_cabin'] = test.Cabin.apply(lambda x: 0 if pd.isna(x) else 1)\ntest['CabinLetter'] = test.Cabin.apply(lambda x: str(x)[0])\n#Remove Cabin\ntrain = train.drop('Cabin',axis=1)\ntest = test.drop('Cabin',axis=1)","af9ce1bc":"# Study embarked and what to do with the NA values\nprint(pd.pivot_table(train, index = 'Embarked', values = ['Survived']))\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=train)\nplt.show()\nprint('Total of passengers for each port')\nprint(train.Embarked.value_counts())","dedfc8b4":"\ntrain = train.fillna({\"Embarked\": \"S\"})","dd1a1e7e":"train.info()","47b00453":"test.info()","e29f564e":"test = test.fillna({\"Fare\": train.Fare.mean()})\n","191a11e4":"# Study and correct (if it is necessary) the skewness and kurtosis.\nprint(\"Train\")\nprint(\"Skewness:\", train['Fare'].skew())\nprint(\"Kurtosis: \",train['Fare'].kurt())\n\nplt.hist(train.Fare, bins=10, color='mediumpurple',alpha=0.5)\nplt.show()\n\nprint(\"Test\")                         \nprint(\"Skewness:\", test['Fare'].skew())\nprint(\"Kurtosis: \",test['Fare'].kurt())\n\nplt.hist(test.Fare, bins=10, color='mediumpurple',alpha=0.5)\nplt.show()","e3f5ab75":"train[\"Fare\"] = np.log1p(train[\"Fare\"])\ntest[\"Fare\"] = np.log1p(test[\"Fare\"])\n\nprint(\"Train\")\nprint(\"Skewness:\", train['Fare'].skew())\nprint(\"Kurtosis: \",train['Fare'].kurt())\n\nplt.hist(train.Fare, bins=10, color='mediumpurple',alpha=0.5)\nplt.show()\n\nprint(\"Test\")                         \nprint(\"Skewness:\", test['Fare'].skew())\nprint(\"Kurtosis: \",test['Fare'].kurt())\n\nplt.hist(test.Fare, bins=10, color='mediumpurple',alpha=0.5)\nplt.show()\n","6f216e7d":"train = train.drop(\"Age\",axis=1)\ntest = test.drop(\"Age\",axis=1)","9c84b4e4":"to_cat = ['Pclass','SibSp','Parch','has_cabin','Sex','Embarked','Title','AgeGroup','CabinLetter']\nfor x in to_cat:\n    train[x] = train[x].astype('category')\n    test[x] = test[x].astype('category')\n","0113a1d6":"train.info()","b0473cae":"train.describe(include='category')","2f8a59b8":"sh_train = train.shape\nc1 = pd.concat((train, test), sort=False).reset_index(drop=True)\nc = pd.get_dummies(c1)\ntrain = c[:sh_train[0]] #sh_train is the shape of train_d\ntest = c[sh_train[0]:]\n#test = pd.get_dummies(test)","c5e63c8f":"# Scale data \nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\n\ntrain[['Fare']]= scale.fit_transform(train[['Fare']])\ntest[['Fare']]= scale.fit_transform(test[['Fare']])","45850a0f":"#Split to train\nfrom sklearn.model_selection import train_test_split\n\npred = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nX_train, X_valid, y_train, y_valid = train_test_split(pred, target, test_size = 0.20, random_state = 0)\n","efe84949":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\ny_pred = logreg.predict(X_valid)\nacc_logreg = round(accuracy_score(y_pred, y_valid) * 100, 2)\nprint(acc_logreg)","24ebc543":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(X_train, y_train)\ny_pred = randomforest.predict(X_valid)\nacc_randomforest = round(accuracy_score(y_pred, y_valid) * 100, 2)\nprint(acc_randomforest)","2401e12c":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ninput_shape = [X_valid.shape[1]]\nmodel = keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(25,kernel_initializer='he_uniform', activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(12,kernel_initializer='he_uniform', activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(1, kernel_initializer='glorot_uniform',activation='sigmoid'),\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=512,\n    epochs=200,\n    callbacks=[early_stopping],\n)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\nhistory_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")","ac768c91":"\nynew = model.predict_classes(test.drop(['PassengerId','Survived'], axis=1))","88c5b3f6":"\nids = test['PassengerId']\n#predictions = randomforest.predict(test.drop(['PassengerId','Survived'], axis=1))\npredictions = ynew.flatten()\n#predictions = predictions.astype(int)\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","f0c05ab5":"Sex is a very strong feature because females survive a way more than males.","5ba6a99b":"Looks like Title can be an interesting feature but Family has too many unique values so I don\u00b4t think that It will be usefull.","b25b1384":"The last step before start with the model selection is Normalize the fare and scale the data","28b2d8fe":"### Few ideas that I can assume based on this results:\n* Younger people survived more. It will be interesting to group by age.\n* People with kids on board died more.\n* People with parents on board survived more.\n* Rich people survived more. It will be interesting to try to normalize this feature","64aa3b13":"From here on is the part that I really want to improve. I wanna refresh my studies on both methods and do a good param selection.\nI also want to add more models. Which ones do you think I should study ??","ea36f6a0":"Edit v2: I have implemented the changes because now I Know that this is a better way to approach the problem: remove Age because I have age_cat and change de datatype from object to category to this categorical data with not a lot of levels.","47dc0484":"Last check to see if everything is correct.","b6e5d3bd":"Thank\u00b4s to all that read my notebook. Don't forget to help me to improve this project :)","f8aa5516":"I will fill the null values with S","c065f3cc":"Has cabin or not is a very useful feature. Let\u00b4s check cabin letter","254cf013":"It has letter + num. Split it and study it. Study aswell if has_cabin can be useful.","03119f8d":"In this case I wanted to study feature by feature. I know It can be a bit messy but for this particular notebook I thougth that was the best way.","0b07fe9c":"Based on the results I will use Random Forest. I also will generate the csv.\n\nEdit v2: I have decided to implement neural network based on the knowledge that I am getting from the Kaggle course and the Krish Naik\u00b4s deep learning course.\n","d4cb6dde":"Here I get familiar with the data","7d687fd8":"Hi everybody ! This is my 2nd project in Kaggle. As in the first one I would appreciate a lot any suggestion or advice. I will add new versions of this notebook because the last part (model) is not good enough. I didn't have time to study properly the logistic regression and the random forest but I will do it as soon as possible.\n\nI want to give credit to 2 notebooks that helped me a lot:\n\n\n* https:\/\/www.kaggle.com\/kenjee\/titanic-project-example (This one is from one youtuber and I totally recommend his yt channel https:\/\/www.youtube.com\/c\/KenJee1\/videos )\n\n\n* https:\/\/www.kaggle.com\/nadintamer\/titanic-survival-predictions-beginner\n\n\n*Important: Every time You see this label (\"Edit v2\") means that this are changes that I recently did.\n\nEdit v2: I have decided to create my first neural network following the kaggle micro course and the Krish Naik\u00b4s deep learning playlist (link below). I know there is a lot to improve but this is just a first attemp to build something prodcutive. I recommend every noob on deep learning like me to watch out the deep learning playlist.\nI am aware that there are some changes that needs to be made in the data cleaning stage, I will do it as soon as possible :)\n\nhttps:\/\/www.youtube.com\/playlist?list=PLZoTAELRMXVPGU70ZGsckrMdr0FteeRUi\n\n","08ba62bf":"As we can observe, 1st class passengers have more chances for survive","257f8b33":"Seems that can be helpful, so I will keep it and apply it to the test ds too","597deaac":"I think it can be useful as well. I will drop Cabin and keep this 2 new ones","088a9c8e":"Before group by age I have to fill the NA values in this feature. A good idea for that is fill every NA with the mean of his Title because this mean would be more accurate","da26a3ec":"### Important:\n    If you know a better way to fill the Age NA values based on the title let me know. I hate how I did it, it is soooo dirty but I didn't find another way. Please help me haha","cedb8480":"Definitely, this is an interesting feature but I think It will be even more usefull if I group more the titles because there are some of them with just 1 member and other are just weird.\nDoing a brief research I discovered that:\n* Mlle = Miss\n* Mme = Mrs\n\nSo I will group all the Titles that have 2 or less members into a new group renamed as Others, except for Mlle and Mme.\n","d78f8de8":"There are some with numbers + letters and other ones with just numbers.Let\u00b4s study this","d6125291":"I will fill the Fare with the mean  because It is just one row.","596e254d":"It has the same ratio so I don't think that this new feature can be usefull. I will drop this and ticket","62a5792b":"The first word indicates the family name and the 2nd the title. It may be interesting split the name into this categories"}}