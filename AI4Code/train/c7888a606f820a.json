{"cell_type":{"b2b4f3f0":"code","11fa0ef6":"code","a42f3fd3":"code","0bb71eb2":"code","e4e862a6":"code","39ebaf3d":"code","09c605fe":"code","3dc017a2":"code","a1357265":"code","0cdb1524":"code","f61f7128":"code","8272e6af":"code","99ea0d71":"code","0b70c931":"code","2685d526":"code","0ebb5b36":"code","fc1b86d3":"code","0f3f61a5":"code","bf496d28":"code","c4d63f65":"code","3aff1302":"code","21227654":"code","70fe5733":"code","02bcaac2":"code","61791fb2":"code","8d36ec87":"code","91201781":"code","7d8b9bf8":"code","d99c204e":"code","4a7a1d78":"code","04c61cd9":"code","77cf7fdd":"code","121c9888":"code","0c6d3c2f":"code","6f000b5a":"code","72b03a60":"code","66cc9031":"code","9da321eb":"code","9d544835":"code","3078db7a":"code","84495ced":"code","c7910cb9":"code","eff85ee2":"code","ea04f6b3":"code","bd4872e4":"code","1051f685":"code","b82cd9b3":"code","74a7a875":"code","c0d89e94":"code","118e9132":"code","7aee720e":"code","240c78f0":"code","6d0527c6":"code","13f68f7f":"code","bacc866a":"code","0dd058f5":"code","daa5b71c":"code","dc905324":"code","cf0bfb59":"code","43ba1ee2":"code","84f25512":"code","b23117e0":"code","95f8340f":"code","5d658ce1":"code","8f1da008":"code","f9f24aa2":"code","d05604b1":"code","5515017c":"code","b2f4de67":"code","68338920":"code","dff13e3b":"markdown","9e38b26c":"markdown","170431cf":"markdown","5de0673a":"markdown","88124426":"markdown","ea5fac0b":"markdown","fa148ebf":"markdown","3cc9c0e8":"markdown","3b07179b":"markdown","bc9875ff":"markdown","bdb4ab15":"markdown","84401efb":"markdown","31a7a8cd":"markdown","afa1a3d7":"markdown","1c82df94":"markdown","e2494b46":"markdown","1cb28364":"markdown","d713aed0":"markdown","8754cdbb":"markdown","d573de74":"markdown","94b1c454":"markdown","adb88cf8":"markdown","85c00558":"markdown","ee543f0a":"markdown","a8a84893":"markdown","b8ba7088":"markdown","54d14558":"markdown","a8d3f217":"markdown","6bf7aad4":"markdown","4d1ba180":"markdown","ae260a00":"markdown","0c4cc9a2":"markdown","2fb27eac":"markdown","bf8fa962":"markdown","deec2bc3":"markdown","d0e512f7":"markdown","9353f2d2":"markdown","85d494dd":"markdown","b8fee5ab":"markdown","9a1af3a6":"markdown","f3e488a5":"markdown","b9498dfa":"markdown","6bcc1076":"markdown","8686ac2b":"markdown","929f21e6":"markdown","8d9a3504":"markdown","67933a3b":"markdown"},"source":{"b2b4f3f0":"# Import numpy and pandas two essential libraries.\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom matplotlib import pyplot as plt","11fa0ef6":"#data = pd.read_csv(\"C:\/Users\/DASLAB Hareland 3\/Desktop\/atashnezhad-ai-interview-code-amin-2a2ca6bbf490\/data.csv\")\n#data.head()\n#data = pd.read_csv(\"C:\/Users\/Farshid\/Documents\/ai-interview-code-amin\/data.csv\")\n#data.head()\ndata = pd.read_csv(\"..\/input\/data.csv\")\ndata.head()","a42f3fd3":"data.tail()","0bb71eb2":"data.shape","e4e862a6":"# Import Pandas\nimport pandas as pd\n#Import Numpy for numerical computation\nimport numpy as np\n# Import matplotlib & seaborn for visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport scipy.stats as st\nfrom sklearn import ensemble, tree, linear_model\nimport missingno as msno","39ebaf3d":"numeric_features = data.select_dtypes(include=[np.number])\nnumeric_features.columns","09c605fe":"categorical_features = data.select_dtypes(include=[np.object])\ncategorical_features.columns","3dc017a2":"#Estimate Skewness and Kurtosis\n#data.skew(), data.kurt()","a1357265":"data.describe()","0cdb1524":"print(data.keys())","f61f7128":"def null_table(data):\n    print(\"Training Data Frame\")\n    print(pd.isnull(data).sum()) \n    print(\" \")\n    \nnull_table(data)","8272e6af":"data.drop(labels = [\"ID\",\"name\"], axis = 1, inplace = True)\nnull_table(data)","99ea0d71":"import copy\ndata2=copy.deepcopy(data)\ndata2 = data2[np.isfinite(data2['usd pledged'])]\nnull_table(data2)\ndata2.describe()","0b70c931":"data2.drop(labels = [\"deadline\",\"launched\",\"currency\"], axis = 1, inplace = True)\ndata2.head()","2685d526":"#NumOfDays = pd.read_csv(\"C:\/Users\/DASLAB Hareland 3\/Desktop\/atashnezhad-ai-interview-code-amin-2a2ca6bbf490\/diff.csv\")\n#NumOfDays.head()\n#NumOfDays = pd.read_csv(\"C:\/Users\/Farshid\/Documents\/ai-interview-code-amin\/diff.csv\")\nNumOfDays = pd.read_csv(\"..\/input\/diff.csv\")\nNumOfDays.head()","0ebb5b36":"import copy\ndata3=copy.deepcopy(data2)\ndata3['NumOfDays']=NumOfDays\ndata3.head()","fc1b86d3":"#data3.describe()\ndata3.head()","0f3f61a5":"data_obj = data3.select_dtypes(include=['object']).copy()\ndata_obj.head()","bf496d28":"# Just Doule check null values. Number of null values in data_obj. which were filtered already.\nprint(data_obj.isnull().values.sum())\n# Doule check null values. Number of null values in data_obj by taking the columns into account. \nprint(data_obj.isnull().sum())","c4d63f65":"print(data_obj['category'].value_counts().count())\nprint(data_obj['main_category'].value_counts().count())\nprint(data_obj['state'].value_counts().count())\nprint(data_obj['country'].value_counts().count())","3aff1302":"#from matplotlib import rcParams\n# figure size in inches\n#rcParams['figure.figsize'] = 15.7,8.27\n#visualizing main_category\n#main_category_count = data_obj['main_category'].value_counts()\n#sns.set(style=\"darkgrid\")\n#sns.barplot(main_category_count.index, main_category_count.values, alpha=0.9)\n#plt.title('Frequency Distribution of main_category')\n#plt.ylabel('Number of Occurrences', fontsize=12)\n#plt.xlabel('main_category', fontsize=12)\n#plt.show()","21227654":"labels = data_obj['category'].astype('category').cat.categories.tolist()\nreplace_map_comp1 = {'category' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\nprint(replace_map_comp1)\ndata_obj.replace(replace_map_comp1, inplace=True)\nprint(data_obj.head())\n\nlabels = data_obj['main_category'].astype('category').cat.categories.tolist()\nreplace_map_comp2 = {'main_category' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\nprint(replace_map_comp2)\ndata_obj.replace(replace_map_comp2, inplace=True)\nprint(data_obj.head())\n\nlabels = data_obj['state'].astype('category').cat.categories.tolist()\nreplace_map_comp3 = {'state' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\nprint(replace_map_comp3)\ndata_obj.replace(replace_map_comp3, inplace=True)\nprint(data_obj.head())\n\nlabels = data_obj['country'].astype('category').cat.categories.tolist()\nreplace_map_comp4 = {'country' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\nprint(replace_map_comp4)\ndata_obj.replace(replace_map_comp4, inplace=True)\nprint(data_obj.head())","70fe5733":"data3['category']=copy.deepcopy(data_obj['category'])\ndata3['main_category']=copy.deepcopy(data_obj['main_category'])\ndata3['state']=copy.deepcopy(data_obj['state'])\ndata3['country']=copy.deepcopy(data_obj['country'])\ndata3.head()","02bcaac2":"data3.describe()","61791fb2":"%matplotlib inline\nimport math\nfrom matplotlib.pyplot import figure\nTTT=copy.deepcopy(data3)\nTTT=TTT.astype(float)\nTTT.head()\nfrom matplotlib import pyplot\nplt.figure(figsize=(18,6))\npyplot.hist(np.log((TTT['backers']+0.0000001)), bins=200, color='red', label='Log Transformation')\npyplot.hist((TTT['backers']**(1\/5)), bins=200, color='blue', label='Power {} Transformation'.format(1\/5))\n\npyplot.title(\"Transformation for backers\")\npyplot.legend(loc='upper right')\npyplot.show()","8d36ec87":"%matplotlib inline\nfrom matplotlib import pyplot\nfor i in[1,10]:\n    pyplot.hist(data3['NumOfDays']**(1\/i), bins=40)\n    pyplot.title(\"Transformation NumOfDays: 1\/{}\".format(str(i)))\n    pyplot.show() \n    \nfor i in[1,15]:\n    pyplot.hist(data3['usd_pledged_real']**(1\/i), bins=40)\n    pyplot.title(\"Transformation usd_pledged_real: 1\/{}\".format(str(i)))\n    pyplot.show() \n\nfor i in[1,15]:\n    pyplot.hist(data3['usd pledged']**(1\/i), bins=40)\n    pyplot.title(\"Transformation pledged: 1\/{}\".format(str(i)))\n    pyplot.show()  \n    \nfor i in[1,20]:\n    pyplot.hist(data3['goal']**(1\/i), bins=40)\n    pyplot.title(\"Transformation goal: 1\/{}\".format(str(i)))\n    pyplot.show()  \n\nfor i in[1,15]:\n    pyplot.hist(data3['pledged']**(1\/i), bins=40)\n    pyplot.title(\"Transformation pledged: 1\/{}\".format(str(i)))\n    pyplot.show()\n    \nfor i in[1,10]:\n    pyplot.hist(data3['backers']**(1\/i), bins=40)\n    pyplot.title(\"Transformation backers: 1\/{}\".format(str(i)))\n    pyplot.show()\n    \nfor i in[1,15]:\n    pyplot.hist(data3['usd_goal_real']**(1\/i), bins=40)\n    pyplot.title(\"Transformation usd_goal_real: 1\/{}\".format(str(i)))\n    pyplot.show() ","91201781":"import seaborn as sns\nsns.set()\n#columns = ['category','main_category','goal','pledged','state','backers','country','usd pledged','usd_pledged_real','usd_goal_real','NumOfDays']\nsns.pairplot(data3[columns],size = 2 ,kind ='scatter',diag_kind='kde',hue=\"state\")\nplt.show()","7d8b9bf8":"dataTrans=copy.deepcopy(data3)\ndata3.head()","d99c204e":"dataTrans['goal']=dataTrans['goal']**(1\/20)\ndataTrans['backers']=dataTrans['backers']**(1\/10)\ndataTrans['pledged']=dataTrans['pledged']**(1\/15)\ndataTrans['usd pledged']=dataTrans['usd pledged']**(1\/15)\ndataTrans['usd_pledged_real']=dataTrans['usd_pledged_real']**(1\/15)\ndataTrans['NumOfDays']=dataTrans['NumOfDays']**(1\/10)\ndataTrans['usd_goal_real']=dataTrans['usd_goal_real']**(1\/15)\ndataTrans.head()","4a7a1d78":"print(replace_map_comp3)","04c61cd9":"dataTrans['state'] = np.where(dataTrans['state'] == 4, 1, 0)\ndataTrans.head()","77cf7fdd":"#some visualizations\n\"\"\"\nplt.figure(figsize=(18,6))\nplt.subplot(2, 1, 1)\npyplot.hist(dataTrans[dataTrans['state']==0]['backers'], alpha=0.5, normed=True, label='unsuccessful')\npyplot.hist(dataTrans[dataTrans['state']==1]['backers'], alpha=0.5, normed=True, label='successful')\npyplot.legend(loc='upper right')\npyplot.title(\"backers\")\npyplot.show()\n\nplt.figure(figsize=(18,6))\nplt.subplot(2, 1, 2)\npyplot.hist(dataTrans[dataTrans['state']==0]['goal'], alpha=0.5, normed=True, label='unsuccessful')\npyplot.hist(dataTrans[dataTrans['state']==1]['goal'], alpha=0.5, normed=True, label='successful')\npyplot.legend(loc='upper right')\npyplot.title(\"goal\")\npyplot.show()\n\"\"\"","121c9888":"# Some visualizations\n#plt.figure(figsize = (12, 6))\n#sns.countplot(x = 'main_category', data = dataTrans)\n#xt = plt.xticks(rotation=45)\nimport seaborn as sns\nsns.set()\ncolumns = ['category','main_category','goal','pledged','state','backers','country','usd pledged','usd_pledged_real','usd_goal_real','NumOfDays']\n#sns.pairplot(dataTrans[columns],size = 2 ,kind ='scatter',diag_kind='kde',hue=\"state\")\nplt.show()","0c6d3c2f":"dataTrans.head(2)","6f000b5a":"data4=copy.deepcopy(dataTrans)\ndata4.head(2)\n#data4['NumOfDays']=NumOfDays\n#data4.head()\nstate=copy.deepcopy(data4['state'])\nstate.head(10)","72b03a60":"data4.drop(labels = [\"state\"], axis = 1, inplace = True)\ndata4.head(2)","66cc9031":"from sklearn import datasets, linear_model\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt","9da321eb":"# create training and testing vars\nX_train, X_test, y_train, y_test = train_test_split(data4, state, test_size=0.2)\nprint (X_train.shape, y_train.shape)\nprint (X_test.shape, y_test.shape)","9d544835":"from sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier","3078db7a":"from sklearn.model_selection import train_test_split #to create validation data set\nX_training, X_valid, y_training, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0) #X_valid and y_valid are the validation sets","84495ced":"from sklearn.metrics import make_scorer, accuracy_score ","c7910cb9":"knn_clf = KNeighborsClassifier()\nknn_clf.fit(X_training, y_training)\npred_knn = knn_clf.predict(X_valid)\nacc_knn = accuracy_score(y_valid, pred_knn)\nprint(acc_knn)","eff85ee2":"from sklearn import metrics","ea04f6b3":"# save confusion matrix and slice into four pieces\nconfusion = metrics.confusion_matrix(y_valid, pred_knn)\nprint(confusion)\n#[row, column]\nTP = confusion[1, 1]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]","bd4872e4":"#how often is the classifier correct?\n# use float to perform true division, not integer division\nprint((TP + TN) \/ float(TP + TN + FP + FN))\nprint(metrics.accuracy_score(y_valid, pred_knn))","1051f685":"# Precision: When a positive value is predicted, how often is the prediction correct? Precision = TP\/TP+FP\nprecision = TP \/ float(TP + FP)\nprint(precision)\nprint((TP + TN) \/ float(TP + TN + FP + FN))","b82cd9b3":"# Sensitivity: When the actual value is positive, how often is the prediction correct?\nsensitivity = TP \/ float(FN + TP)\nprint(sensitivity)\nprint((TP + TN) \/ float(TP + TN + FP + FN))","74a7a875":"# F1 Score = 2*(sensitivity * Precision) \/ (sensitivity + Precision)\nF1_Score = 2*(sensitivity * precision) \/ (sensitivity + precision)\nprint(F1_Score)\nprint((TP + TN) \/ float(TP + TN + FP + FN))","c0d89e94":"# Specificity: When the actual value is negative, how often is the prediction correct?\nspecificity = TN \/ (TN + FP)\nprint(specificity)\nprint((TP + TN) \/ float(TP + TN + FP + FN))","118e9132":"# False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\nfalse_positive_rate = FP \/ float(TN + FP)\nprint(false_positive_rate)\n# and false negative rate\nprint(1 - specificity)","7aee720e":"rf_clf = RandomForestClassifier(n_estimators=50, n_jobs=-1) # increase the number of trees to get better results\nrf_model=rf_clf.fit(X_training, y_training)\npred_rf = rf_clf.predict(X_valid)\nacc_rf = accuracy_score(y_valid, pred_rf)\nprint(acc_rf)","240c78f0":"#print(dir(RandomForestClassifier))\n#print(RandomForestClassifier())","6d0527c6":"# metrics confusion\nfrom sklearn import metrics\nprint(metrics.confusion_matrix(y_valid, pred_knn))","13f68f7f":"sorted(zip(rf_model.feature_importances_, X_train.columns), reverse=True)[0:10]","bacc866a":"print(dir(LogisticRegression())) #check out what feather is provided ","0dd058f5":"logreg_clf = LogisticRegression()\nlogreg_clf.fit(X_training, y_training)\npred_logreg = logreg_clf.predict(X_valid)\nacc_logreg = accuracy_score(y_valid, pred_logreg)\nprint(acc_logreg)","daa5b71c":"# metrics confusion\nfrom sklearn import metrics\nprint(metrics.confusion_matrix(y_valid, pred_logreg))","dc905324":"print(dir(DecisionTreeClassifier())) #check out what feather is provided ","cf0bfb59":"dt_clf = DecisionTreeClassifier()\ndt_clf.fit(X_training, y_training)\npred_dt = dt_clf.predict(X_valid)\nacc_dt = accuracy_score(y_valid, pred_dt)\nprint(acc_dt)","43ba1ee2":"# metrics confusion\nfrom sklearn import metrics\nprint(metrics.confusion_matrix(y_valid, pred_dt))","84f25512":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nmatplotlib.style.use('fivethirtyeight')\n\nfrom sklearn import tree\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom subprocess import check_output\n\nwith open(\"tree1.dot\", 'w') as f:\n     f = tree.export_graphviz(dt_clf,\n                              out_file=f,\n                              max_depth = 3,\n                              impurity = False,\n                              feature_names = X_test.columns.values,\n                              class_names = ['No', 'Yes'],\n                              rounded = True,\n                              filled= True )\n        \n#Convert .dot to .png to allow display in web notebook\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n# Annotating chart with PIL\nimg = Image.open(\"tree1.png\")\ndraw = ImageDraw.Draw(img)\nimg.save('sample-out.png')\nPImage(\"sample-out.png\")","b23117e0":"gnb_clf = GaussianNB()\ngnb_clf.fit(X_training, y_training)\npred_gnb = gnb_clf.predict(X_valid)\nacc_gnb = accuracy_score(y_valid, pred_gnb)\nprint(acc_gnb)","95f8340f":"# metrics confusion\nfrom sklearn import metrics\nprint(metrics.confusion_matrix(y_valid, pred_gnb))","5d658ce1":"linsvc_clf = LinearSVC()\nlinsvc_clf.fit(X_training, y_training)\npred_linsvc = linsvc_clf.predict(X_valid)\nacc_linsvc = accuracy_score(y_valid, pred_linsvc)\nprint(acc_linsvc)","8f1da008":"# metrics confusion\nfrom sklearn import metrics\nprint(metrics.confusion_matrix(y_valid, pred_linsvc))","f9f24aa2":"model_performance = pd.DataFrame({\n    \"Model\": [\"Linear SVC\", \"Random Forest\", \n              \"Logistic Regression\", \"K Nearest Neighbors\", \"Gaussian Naive Bayes\",  \n              \"Decision Tree\"],\n    \"Accuracy\": [acc_linsvc, acc_rf, \n              acc_logreg, acc_knn, acc_gnb, acc_dt]\n})\n\nmodel_performance.sort_values(by=\"Accuracy\", ascending=False)","d05604b1":"pred_rf = rf_clf.predict(X_test)\nacc_rf = accuracy_score(y_test, pred_rf)\nprint(acc_rf)","5515017c":"#import pickle\n# save the model to current working directory\n#filename = 'rf_amin_model.sav'\n#pickle.dump(rf_clf, open(filename, 'wb'))","b2f4de67":"# load the model from disk\n#loaded_model = pickle.load(open(filename, 'rb'))\n#result = loaded_model.score(X_test, Y_test)\n#print(result)","68338920":"print(replace_map_comp1)\nprint(replace_map_comp2)\nprint(replace_map_comp3)\nprint(replace_map_comp4)","dff13e3b":"# Dealing with NaN Values (Imputation)\n\nSee if there are null\/ missing\/NaN in data. ","9e38b26c":"### Precision","170431cf":"# Linear SVC Model","5de0673a":"# KNeighbors Model","88124426":"Once the new data was prepared, the model can be applied for prediction.","ea5fac0b":"Load the csv data file and visualize paramters.","fa148ebf":"# Data2\n\nFeed data to new dataframe (data2) and drop those rows that missed. droping the whole column is not accepted. ","3cc9c0e8":"# Data3","3b07179b":"The name of project and the ID do not affect a project final results. \nDrop name and project ID. In addition, the currency should be taken out of data becasue the pledges were provided in USD.","bc9875ff":"usd_pledged_real\nbackers\nusd_goal_real\n usd pledged\n  pledged\n  goal","bdb4ab15":"Done. Good Luck everyone! :)","84401efb":"Evaluate the model performanceusing make_scorere and accuracy_score function from sklearn metrics.","31a7a8cd":"Begin Data Featuring. Replace Values with digits. The models work with digits.","afa1a3d7":"Upload the diff.csv file which provides the number of days for each projest.","1c82df94":"check out the frequency distribution of categories within the feature","e2494b46":"# DecisionTree Model","1cb28364":"In this toturial we dont use the log transformation but you may try it and evalute the results. Just make sure that the min value of the columns should not be zero. You may add some constant (small non zero value) and evalute the prediction accuray. If you comapre the distribution plots, you can see that the log transformation will generate more distribution than the other type which is promising! You also may check how different between power and log transformation at the following:","d713aed0":"# Split data to train and test","8754cdbb":"# Apply the Random Forest to test data to see how much it works","d573de74":"### Sensitivity or Recall","94b1c454":"# Filtering column \"state\" with zero and 1 values\nThe object of the moel is to determine Whether  a project is succsful or not. Therefore the \"4\" in the column \"state\" is replace with 1 and the rest of values are assigned to zero. ","adb88cf8":"The Model uses below columns and formats to predicc the state of each project. Before applying model following points shoulb be taken into account.\n\nThe columns that are fed into the model are:\n'category', 'main_category', 'goal', 'pledged', 'backers', 'country', 'usd pledged', 'usd_pledged_real', 'usd_goal_real' and 'NumOfDays'\n\nNumber of inputs = 10\nNumber of Outputs = 1 (state) 1==succesful, 0 == Not Succesful\n\nThe 'NumOfDays' column was generated by subtracting the deadline from launched date in csv file and it was saved and uploaded seperatly.\nThe columns 'category', 'main_category', 'state' and 'country' were objects that were replaced with values. \nThe above codes can be applied to any data before usign the model for prediction. The replaced values are seen by runing below lines.\n\nDon not forget to transfor your new data using the sme trasformer that we applied here before using the model for prediction.","85c00558":"Transforming parameters including: goal, backers, pledged, usd pledged, usd_pledged_real and NumberOfDats.","ee543f0a":"# GaussianNB Model","a8a84893":"Check out what feathers are important in the model.","b8ba7088":"# Feature Engineering\n\nTake the objects out of data and save it as data_obj\n\nReplace the data 3 objects into the data_obj and work with data_obj to make sure original data is kept.","54d14558":"### F1 score\n\nThis score takes both false positives and false negatives into account.\nIntuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it\u2019s better to look at both Precision and Recall (see reff).\n","a8d3f217":"# data4 ","6bf7aad4":"You should always apply some evaluations on the model depend on what you looking for. Depend on your project you may try to reduce FP or FN. Then you may try to tune your ML to achieve your goal (tuning effective paramters). To zoom on Fraudulent transaction recognization, optimize the sensitivity. To get email spam optimze your model to achive the high precision or specificity. and so on...","4d1ba180":"### Accuracy ","ae260a00":"# Save Your Model ","0c4cc9a2":"The deadline time and time that a project is lunched are not important itself. subtract these two to find out how much time was avalabe for each project. Use the csv file and subtracted these two columns to achive the number of days. The diff.csv file was uploaded and columns including 'launched' and 'dedline' and'currency' were deleted. The data2 is turne to data3 now with a new diff column (without launched, currency and deadline columns).","2fb27eac":"# LogisiticRegression Model","bf8fa962":"Some Resources:\n\n1) https:\/\/www.ritchieng.com\/machine-learning-evaluate-classification-model\/\n\n2) https:\/\/www.kaggle.com\/pavansanagapati\/a-simple-tutorial-on-exploratory-data-analysis\n\n3) https:\/\/www.kaggle.com\/ialimustafa\/titanic-beginner-s-guide-with-sklearn\n\n4) http:\/\/blog.exsilio.com\/all\/accuracy-precision-recall-f1-score-interpretation-of-performance-measures\/","deec2bc3":"Data has lot of skews. The random foreset, descion tree are used to model these data. before that some works should be done on data.\nFinal cumulative graph of a pair plot that shows the relations between all of the different features.","d0e512f7":"# Model Fitting and Predicting\nImporting different classifiers from sklearn. \nLets try different types of models (ML) to see which one gives the best accuracy for its predictions.\n","9353f2d2":"Fix the data3 values by repalcing data_obj into the data3.","85d494dd":"It is seen that paramters like usd_pledged_real, usd_pledged, backers, pledged are good for estimation projects state.","b8fee5ab":"It is seen that the Random Forest is the best model.","9a1af3a6":"You may load the model and apply to new data sometimes later.","f3e488a5":"# Transformation \nFind those paramters that have bias and try to reduce the bias using some trasformations like power.","b9498dfa":"# RandomForest Model","6bcc1076":"# Plotting and Visualizing Data","8686ac2b":"# Validation Data Set","929f21e6":"Check out  the paramters distributions before transforming.","8d9a3504":"## In this toturial I applied some ML algorithms to data. \nThe codes resources were provided at the end of this toturial. \nI think everyone can easily find the tools online and just arrange for them to achieve their desired goal. \nIn this work, You will learn how to handle:\n\n1. Missed values\n2. Adding a new column to data\n3. Delete some useless columns\n4. Visualization\n5. Parameters Featuring and Transforming (Dealing with those parameters that are an object not digit)\n6. Splitting data (train, validate and test)\n7. Fitting ML models (Random Forest, Logistic Regression, Decision Tree, Gaussian, Linear SVC)\n8. Accuracy, Precision, Sensitivity or Recall, F1 score concepts\n9. Evaluating Model Performances\n10. Saving your model\n11. Uploading your model and how to apply it to other data\nYou may use docker for this Notebook. \n(docker pull atashnezhad\/datasciencenotebook)","67933a3b":"# Evaluating Model Performances"}}