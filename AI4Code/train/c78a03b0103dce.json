{"cell_type":{"333148dc":"code","e6ba8eca":"code","5fc7ec01":"code","bb262304":"code","4e8aac4a":"code","1aa56abf":"code","bdb19f7a":"code","306a173e":"code","7287503a":"code","9f0f2279":"code","8ee8f05e":"code","8c76f835":"code","47a6542e":"code","ccd04564":"code","2f200fce":"code","151718f1":"code","8e65f265":"code","2bf10fe7":"code","c913fe7e":"code","2bbec135":"code","2b9d5dd8":"code","e0e0c2c5":"code","4031b96d":"code","bbd76afd":"code","0dc2ceff":"code","48d57078":"code","c0c93109":"code","e883ac5f":"code","cad69b47":"code","c6172b34":"markdown","f5053719":"markdown","879e8ff5":"markdown","1220015f":"markdown","aede6efb":"markdown","34062c00":"markdown","04698c56":"markdown","6f4ecc2c":"markdown","fe0d8cd5":"markdown","0fb110a8":"markdown","0693e662":"markdown","e0488235":"markdown"},"source":{"333148dc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# load dataset\ndataset = pd.read_csv('..\/input\/TrainingData.csv', header=0)","e6ba8eca":"dataset.head()","5fc7ec01":"dataset.tail()","bb262304":"dataset.shape","4e8aac4a":"# trim and transform to floats\nvalues = dataset.values\ndata = values[:, 6:].astype('float32')","1aa56abf":"# summarize amount of missing data\ntotal_missing = np.count_nonzero(np.isnan(data))\npercent_missing = total_missing \/ data.size * 100\nprint('Total Missing: %d\/%d (%.1f%%)' % (total_missing, data.size, percent_missing))","bdb19f7a":"# split data into chunks\n# split the dataset by 'chunkID', return a dict of id to rows\ndef to_chunks(values, chunk_ix=1):\n    chunks = dict()\n    # get the unique chunk ids\n    chunk_ids = np.unique(values[:, chunk_ix])\n    # group rows by chunk id\n    for chunk_id in chunk_ids:\n        selection = values[:, chunk_ix] == chunk_id\n        chunks[chunk_id] = values[selection, :]\n    return chunks","306a173e":"# plot distribution of chunk durations\ndef plot_chunk_durations(chunks):\n    # chunk durations in hours\n    chunk_durations = [len(v) for k,v in chunks.items()]\n    # boxplot\n    plt.subplot(2, 1, 1)\n    plt.boxplot(chunk_durations)\n    # histogram\n    plt.subplot(2, 1, 2)\n    plt.hist(chunk_durations)\n    # histogram\n    plt.show()","7287503a":"# group data by chunks\nvalues = dataset.values\nchunks = to_chunks(values)\nprint('Total Chunks: %d' % len(chunks))","9f0f2279":"plt.figure(figsize=(15,8))\n# plot chunk durations\nplot_chunk_durations(chunks)","8ee8f05e":"# plot chunks that do not have all data\ndef plot_discontiguous_chunks(chunks, row_in_chunk_ix=2):\n    n_steps = 8 * 24\n    for c_id,rows in chunks.items():\n        # skip chunks with all data\n        if rows.shape[0] == n_steps:\n            continue\n        # create empty series\n        series = [np.nan for _ in range(n_steps)]\n        # mark all rows with data\n        for row in rows:\n            # convert to zero offset\n            r_id = row[row_in_chunk_ix] - 1\n            # mark value\n            series[r_id] = c_id\n            # plot\n        plt.plot(series)\n    plt.show()","8c76f835":"# group data by chunks\nvalues = dataset.values\nchunks = to_chunks(values)\n# plot discontiguous chunks\nplt.figure(figsize=(15,8))\nplot_discontiguous_chunks(chunks)","47a6542e":"# plot distribution of chunk start hour\ndef plot_chunk_start_hour(chunks, hour_in_chunk_ix=5):\n    # chunk start hour\n    chunk_start_hours = [v[0, hour_in_chunk_ix] for k,v in chunks.items() if len(v)==192]\n    # boxplot\n    plt.subplot(2, 1, 1)\n    plt.boxplot(chunk_start_hours)\n    # histogram\n    plt.subplot(2, 1, 2)\n    plt.hist(chunk_start_hours, bins=24)\n    # histogram\n    plt.show()","ccd04564":"# group data by chunks\nvalues = dataset.values\nchunks = to_chunks(values)\n# plot distribution of chunk start hour\nplt.figure(figsize=(15,8))\nplot_chunk_start_hour(chunks)","2f200fce":"# plot all inputs for one or more chunk ids\ndef plot_chunk_inputs(chunks, c_ids):\n    plt.figure(figsize=(15,8))\n    inputs = range(6, 56)\n    for i in range(len(inputs)):\n        ax = plt.subplot(len(inputs), 1, i+1)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        column = inputs[i]\n        for chunk_id in c_ids:\n            rows = chunks[chunk_id]\n            plt.plot(rows[:,column])\n    plt.show()","151718f1":"# group data by chunks\nvalues = dataset.values\nchunks = to_chunks(values)\n# plot inputs for some chunks\nplot_chunk_inputs(chunks, [1])","8e65f265":"plot_chunk_inputs(chunks, [1, 3 ,5])","2bf10fe7":"# boxplot for input variables for a chuck\ndef plot_chunk_input_boxplots(chunks, c_id):\n    rows = chunks[c_id]\n    plt.boxplot(rows[:,6:56])\n    plt.show()","c913fe7e":"# group data by chunks\nvalues = dataset.values\nchunks = to_chunks(values)\n# boxplot for input variables\nplt.figure(figsize=(15,8))\nplot_chunk_input_boxplots(chunks, 1)","2bbec135":"# plot all targets for one or more chunk ids\ndef plot_chunk_targets(chunks, c_ids):\n    plt.figure(figsize=(15,8))\n    targets = range(56, 95)\n    for i in range(len(targets)):\n        ax = plt.subplot(len(targets), 1, i+1)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        column = targets[i]\n        for chunk_id in c_ids:\n            rows = chunks[chunk_id]\n            plt.plot(rows[:,column])\n    plt.show()\n    ","2b9d5dd8":"# group data by chunks\nvalues = dataset.values\nchunks = to_chunks(values)\n# plot targets for some chunks\nplot_chunk_targets(chunks, [1])","e0e0c2c5":"# plot targets for some chunks\nplot_chunk_targets(chunks, [1, 3 ,5])","4031b96d":"# boxplot for target variables for a chuck\ndef plot_chunk_targets_boxplots(chunks, c_id):\n    rows = chunks[c_id]\n    plt.boxplot(rows[:,56:])\n    plt.show()","bbd76afd":"# group data by chunks\nvalues = dataset.values\nchunks = to_chunks(values)\n# boxplot for target variables\nplt.figure(figsize=(15,8))\nplot_chunk_targets_boxplots(chunks, 1)","0dc2ceff":"# boxplot for all target variables\ndef plot_target_boxplots(values):\n    plt.boxplot(values[:,56:])\n    plt.show()\n# boxplot for target variables\nvalues = dataset.values\nplt.figure(figsize=(15,8))\nplot_target_boxplots(values)","48d57078":"# bar chart of the ratio of missing data per column\ndef plot_col_percentage_missing(values, ix_start=5):\n    ratios = list()\n    # skip early columns, with meta data or strings\n    for col in range(ix_start, values.shape[1]):\n        col_data = values[:, col].astype('float32')\n        ratio = np.count_nonzero(np.isnan(col_data)) \/ len(col_data) * 100\n        ratios.append(ratio)\n        if ratio > 90.0:\n            print(ratio)\n    col_id = [x for x in range(ix_start, values.shape[1])]\n    plt.bar(col_id, ratios)\n    plt.show()","c0c93109":"# plot ratio of missing data per column\nvalues = dataset.values\nplt.figure(figsize=(15,8))\nplot_col_percentage_missing(values)","e883ac5f":"# plot distribution of targets for one or more chunk ids\ndef plot_chunk_targets_hist(chunks, c_ids):\n    plt.figure(figsize=(15,8))\n    targets = range(56, 95)\n    for i in range(len(targets)):\n        ax = plt.subplot(len(targets), 1, i+1)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        column = targets[i]\n        for chunk_id in c_ids:\n            rows = chunks[chunk_id]\n            # extract column of interest\n            col = rows[:,column].astype('float32')\n            # check for some data to plot\n            if np.count_nonzero(np.isnan(col)) < len(rows):\n                # only plot non-nan values\n                plt.hist(col[~np.isnan(col)], bins=100)\n    plt.show()","cad69b47":"# group data by chunks\nvalues = dataset.values\nchunks = to_chunks(values)\n# plot targets for some chunks\nplot_chunk_targets_hist(chunks, [1])","c6172b34":"## Chunk Contiguousness","f5053719":"1. Reference: [machinelearningmastery.com](https:\/\/machinelearningmastery.com\/how-to-load-visualize-and-explore-a-complex-multivariate-multistep-time-series-forecasting-dataset\/)","879e8ff5":"## Daily Coverage Within Chunks\n\nThe discontiguous nature of the chunks also suggests that it may be important to look at the hours covered by each chunk.","1220015f":"## Chunk Data Structure","aede6efb":"## Load Dataset","34062c00":"## Problem Description\n\nThe EMC Data Science Global Hackathon dataset, or the \u2018Air Quality Prediction\u2018 dataset for short, describes weather conditions at multiple sites and requires a prediction of air quality measurements over the subsequent three days.","04698c56":"## Boxplot Distribution of Target Variables","6f4ecc2c":"## Input Data Distribution\n\nLet's look at the distribution of input variables crudely using box and whisker plots.","fe0d8cd5":"## Apparently Empty Target Columns","0fb110a8":"## Temporal Structure of Targets for a Chunk","0693e662":"## Temporal Structure of Inputs for a Chunk","e0488235":"## Histogram Distribution of Target Variables"}}