{"cell_type":{"57fc3284":"code","81bda1ed":"code","71d4eaea":"code","44e85667":"code","6e21994b":"code","d44b82b6":"code","548e14da":"code","3343a6d1":"code","1daa27fe":"code","d6b67e51":"code","f4d12770":"code","bdf4b35e":"code","27d43edb":"code","81a2ccae":"markdown"},"source":{"57fc3284":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing, model_selection, metrics\nimport lightgbm as lgb\ncolor = sns.color_palette()\n%matplotlib inline","81bda1ed":"train_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nprint('train rows {} and cols {}'.format(train_df.shape[0],train_df.shape[1]))\nprint('test rows {} and cols {}'.format(test_df.shape[0],test_df.shape[1]))\ndtype_counts = train_df.get_dtype_counts()\nprint('Train dtype counts \\n',dtype_counts)\ndtype_columns = train_df.drop('target',axis=1).dtypes.reset_index()\nprint('---------------------\\n')\nprint('Test info \\n',test_df.info())","71d4eaea":"''' If you look closely the datatype of all columns of test_df is float64 except ID.\nI first tried to merge the train and test data and then typecast the int_cols to int64\nbut that line of code got stuck for about 20 minutes.So i stopped the kernel and decided to typecast test_data separately \nand then concat them.'''\n'''Also passing the dictionary to datatype when reading test.csv doesnt work'''","44e85667":"dtype_columns.columns = ['Cols','datatype'] ##change column names\nint_cols = dtype_columns.Cols.loc[dtype_columns.datatype=='int64'].values.copy() \nTest_IntCols = test_df[int_cols].astype('int64',copy=False).copy() ##new view of data\ntest_df.drop(int_cols,axis=1,inplace=True) ## drop the columns in new view","6e21994b":"test_df = test_df.merge(Test_IntCols,left_index=True,right_index=True) ##took around 3 seconds!! \nprint(test_df.info()) ##sucessful conversion of datatypes\ntarget = train_df.target.values.copy()\ntrain_df.drop('target',axis=1,inplace=True)\nprint(train_df.info())\n## column datatypes matched!!","d44b82b6":"test_df = pd.concat((train_df,test_df),axis=0) ##around 8 seconds!! HURRY!","548e14da":"test_df.info(memory_usage='deep')","3343a6d1":"##checking the missing values - should have done before merging i think\nmissing_values_df = test_df.isnull().sum(axis=0).reset_index()\nmissing_values_df.columns = ['cols','count']\nmissing_df = missing_values_df.loc[missing_values_df['count'] > 0]\nprint(missing_df)","1daa27fe":"unique_col_df = test_df.nunique().reset_index()\nunique_col_df.columns = ['cols','unique_values']\n# one_unique_element_cols = unique_col_df.loc[unique_col_df.unique_values==1]\nunique_col_df = unique_col_df.sort_values(by='unique_values')\nprint(unique_col_df.head())","d6b67e51":"## Hmm! I dont believe it. The other kernels showed that train data has 256 columns which contains only 1 categorical element!\n## Let's check the train data","f4d12770":"unique_elem_col = test_df[int_cols].iloc[:target.__len__()].nunique().reset_index()\nunique_elem_col.columns = ['cols','count']\nunique_elem_col = unique_elem_col.sort_values(by='count').reset_index()\nprint(unique_elem_col.head())","bdf4b35e":"test_df['eb6bb7ce1'].unique()","27d43edb":"## taken from @srk's kernel\nplt.figure(figsize=(8,6))\nplt.scatter(range(target.__len__()),sorted(target))\nplt.xlabel('Index')\nplt.ylabel('Transaction value')\nplt.tight_layout()\nplt.show()\n\n## exponential target values - this may be the reason for choosing RMSLE metric\n\n##histogram plot\nplt.figure(figsize=(8,6))\nsns.distplot(target,bins=50,kde=False)\nplt.xlabel('Transactions')\nplt.ylabel('count')\nplt.title('Target Histogram')\n\n## This is right skewed Distribution\n## Let's try log here\n##histogram plot\nplt.figure(figsize=(8,6))\nsns.distplot(np.log1p(target),bins=50,kde=False)\nplt.xlabel('Transactions')\nplt.ylabel('count')\nplt.title('Target Histogram')","81a2ccae":"This kernel is incomplete . To be continued.."}}