{"cell_type":{"fbbe3995":"code","5b3a2a93":"code","0ee9dc4e":"code","6dab3098":"code","53483950":"code","98d5643b":"code","68efc623":"code","2dea80ce":"markdown","c998825a":"markdown","d3c97dcf":"markdown","84b51bd7":"markdown"},"source":{"fbbe3995":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nimport xgboost as xgb\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\nfrom sklearn.metrics import roc_auc_score\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5b3a2a93":"train = pd.read_csv(\"..\/input\/data-preparation-binning-and-imputaion\/train_clean_RobustScaler.csv\", index_col = 'TransactionID')","0ee9dc4e":"# Label Encoding\ncols = [c for c in train if c not in ['isFraud', 'TransactionID', 'TransactionDT']]\n\nfor f in train[cols].columns:\n    if train[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(train[f].values))\n        train[f] = lbl.transform(list(train[f].values))\n\ncols = [c for c in train if c not in ['isFraud', 'TransactionID', 'TransactionDT']]\ny=np.array(train['isFraud'])\nX=np.array(train[cols])","6dab3098":"# Time series split\ntscv = TimeSeriesSplit(n_splits=2)\n\nfor train_index, test_index in tscv.split(train):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \ndel train","53483950":"dtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test)\n\n# %% [code]\nparams = {\n    'objective': 'binary:logistic',\n    'max_depth' : 8,\n    'silent': 1,\n    'eta':1\n}\nnum_rounds=5\n\nbst=xgb.train(params, dtrain, num_rounds)\ny_test_preds = (bst.predict(dtest) > 0.5).astype('int')\n\n\npd.crosstab(\n    pd.Series(y_test, name='Actual'),\n    pd.Series(y_test_preds, name='Predicted'),\n    margins=True\n)\n\n\nprint('Accuracy: {0:.2f}'.format(accuracy_score(y_test, y_test_preds)))\nprint('Precision: {0:.2f}'.format(precision_score(y_test, y_test_preds)))\nprint('Recall: {0:.2f}'.format(recall_score(y_test, y_test_preds)))\nprint('AUC ROC: {0:.2f}'.format(roc_auc_score(y_test, y_test_preds)))\n","98d5643b":"params = {\n    'objective': 'binary:logistic',\n    'max_depth' : 8,\n    'silent': 1,\n    'eta':1\n}\nnum_rounds=5\n\nweights = np.zeros(len(y_train))\nweights[y_train == 0] = 1\nweights[y_train == 1] = 5\n\ndtrain = xgb.DMatrix(X_train, label=y_train, weight=weights) # weight added\ndtest = xgb.DMatrix(X_test)\n\n\nbst=xgb.train(params, dtrain, num_rounds)\ny_test_preds = (bst.predict(dtest) > 0.5).astype('int')\n\n\npd.crosstab(\n    pd.Series(y_test, name='Actual'),\n    pd.Series(y_test_preds, name='Predicted'),\n    margins=True\n)\n\nprint('Accuracy: {0:.2f}'.format(accuracy_score(y_test, y_test_preds)))\nprint('Precision: {0:.2f}'.format(precision_score(y_test, y_test_preds)))\nprint('Recall: {0:.2f}'.format(recall_score(y_test, y_test_preds)))\nprint('AUC ROC: {0:.2f}'.format(roc_auc_score(y_test, y_test_preds)))","68efc623":"params = {\n    'objective': 'binary:logistic',\n    'max_depth' : 8,\n    'silent': 1,\n    'eta':1\n}\nnum_rounds=5\n\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test)\n\n# %% [code]\ntrain_labels = dtrain.get_label()\nratio= float(np.sum(train_labels == 0)) \/ np.sum(train_labels == 1)\nparams['scale_pos_weight'] = ratio\n\n# %% [code]\nbst=xgb.train(params, dtrain, num_rounds)\ny_test_preds = (bst.predict(dtest) > 0.5).astype('int')\n\npd.crosstab(\n    pd.Series(y_test, name='Actual'),\n    pd.Series(y_test_preds, name='Predicted'),\n    margins=True\n)\n\n# %% [code]\nprint('Accuracy: {0:.2f}'.format(accuracy_score(y_test, y_test_preds)))\nprint('Precision: {0:.2f}'.format(precision_score(y_test, y_test_preds)))\nprint('Recall: {0:.2f}'.format(recall_score(y_test, y_test_preds)))\nprint('AUC ROC: {0:.2f}'.format(roc_auc_score(y_test, y_test_preds)))\n","2dea80ce":"### [Base line Xgboost](#1)<a id=\"1\"><\/a> <br>\n\n* Here a simple xgboost. Here we do not account for the class imbalance.","c998825a":"The purpose of this notbook is to perform the following tasks:\n \n 1. [Baseline Xgboost](#1)\n 2. [Custom Weight Xgboost](#2)\n 3. [scale_pos_weight Xgboost](#3)\n \nThe idea is to show how to use custom weight or scale_pos_weight to balance the target feature for Xgboost. The parameters are not optimized because the purpose is to demonstrate the use of scale_pos_weight and custom weight. The input data comes from the [here](https:\/\/www.kaggle.com\/wti200\/data-preparation-binning-and-imputaion).","d3c97dcf":"### [scale_pos_weight](#3)<a id=\"3\"><\/a> <br>\n\n* Scale_pos_weight is the ratio of number of negative class to the positive class. ","84b51bd7":"### [Custom Weight Xgboost](#2)<a id=\"2\"><\/a> <br>\n* Explicitly tell the algorithme to assign more weight to minority class by using the weight argument.\n"}}