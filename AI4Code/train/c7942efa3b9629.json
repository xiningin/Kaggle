{"cell_type":{"36abe9fe":"code","8a80761e":"code","0b4bc25f":"code","2362cb98":"code","502188ca":"code","9c1704c6":"code","7e48e53f":"code","cb284e8f":"code","32bc36ba":"code","0ad5c267":"code","f44089c1":"code","1febbb40":"code","67a20527":"code","8dcbed06":"code","79d3a3a1":"code","11f36b67":"code","9ae6a7c7":"code","da5b308f":"code","791e8d1c":"code","1f31e9c5":"code","ff7c8543":"code","18095f04":"code","d9d23663":"code","e08e365c":"code","38af33ad":"code","aa150cfe":"code","c2861dc9":"code","c0c98ae6":"code","17b178bf":"code","6908fe9b":"code","ba6eaa0c":"code","b83ec293":"code","c62c607f":"code","0667c44a":"code","5c47a903":"code","4cd47575":"code","a97d8b73":"code","49b949d8":"code","daf3652e":"code","e752976d":"code","68753b62":"code","fdd48556":"markdown","0a0741b5":"markdown","b736ebc1":"markdown","ed4c91ea":"markdown","1194981f":"markdown","5a656c79":"markdown","8569db7b":"markdown","980a1605":"markdown","cd57be1d":"markdown","65dd4120":"markdown","138779c4":"markdown","d50f0b9e":"markdown","d5b781bd":"markdown","8233a2db":"markdown","542bd52f":"markdown","0a17191b":"markdown","42667a68":"markdown","34aee560":"markdown"},"source":{"36abe9fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # For Visualization\nimport matplotlib.pyplot as plt # For visualization\nimport plotly.express as px # for high resulotion charts \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8a80761e":"dt = pd.read_csv(\"\/kaggle\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 5.csv\")\n\ndt.head(10)","0b4bc25f":"dt = dt.rename(columns={'Order Number': 'Order_Number',\"Order Status\":\"Order_Status\", \n                        \"Book Name\":\"Book_Name\",\"Order Date & Time\":\"Order_Date\",\"City\":\"City\",\n                        \"Payment Method\":\"Payment_Method\",\"Total items\":\"Total_items\",\"Total weight (grams)\":\"grams\" })","2362cb98":"dt.head()","502188ca":"dt.isna().sum()\n","9c1704c6":"print(\" checking for nulll values\")\n\nmiss_value = dt[dt.isnull().any(axis=1)]\nmiss_value.head()","7e48e53f":"# This code show the Max value,so we will replace the NaN with the Max count value\ndt['Book_Name'].value_counts()\n","cb284e8f":"#so we select the 0 index value which is the max value, so we fill the miss value \ndt['Book_Name'].value_counts().index[0]","32bc36ba":"#this code fill NaN missing values with '\u0627\u0646\u0679\u0631\u0646\u06cc\u0679 \u0633\u06d2 \u067e\u06cc\u0633\u06c1 \u06a9\u0645\u0627\u0626\u06cc\u06ba'\ndt['Book_Name'].fillna(dt[\"Book_Name\"].value_counts().index[0], inplace=True)","0ad5c267":"# Now this code will check the Max value of Payment Method which will be replace with the Missing value\ndt['Payment_Method'].value_counts()","f44089c1":"# This code will select 0 index value to replace with missing value \ndt[\"Payment_Method\"].value_counts().index[0]\n","1febbb40":"# The code will fill the missing value NaN with \"Cash on delivery\"\ndt['Payment_Method'].fillna(dt['Payment_Method'].value_counts().index[0], inplace= True)","67a20527":"# This code will fill the missing value in the city\ndt['City'].value_counts()","8dcbed06":"# The code will fill the missing value NaN with \"Karachi\"\ndt[\"City\"].fillna(dt['City'].value_counts().index[0], inplace= True)","79d3a3a1":"dt.isna().sum()","11f36b67":"dt.City.value_counts()[:10]","9ae6a7c7":"top_city = dt.groupby('City')['Order_Number'].count().reset_index().sort_values('Order_Number', ascending = False)\ntop_city.head(20)","da5b308f":"# this code convert the city column data into upercase\ndt['City'] = dt['City'].str.upper()\n","791e8d1c":"# this code show the repeation is clean and also show the max oder oder done from which city\ndt.groupby('City')['Order_Number'].count().reset_index().sort_values('Order_Number', ascending = False).head(20)\n#dt.City.value_counts()[:10]","1f31e9c5":"dt[\"Order_Date\"] = pd.DatetimeIndex(dt[\"Order_Date\"])\ndt['Date'] = dt['Order_Date'].dt.date\ndt['Time'] = dt['Order_Date'].dt.time\ndt['Year'] = dt['Order_Date'].dt.year\ndt['Month'] = dt['Order_Date'].dt.month_name()\ndt['Day'] = dt['Order_Date'].dt.day_name()","ff7c8543":"split_data = dt.drop('Book_Name', axis=1).join(dt['Book_Name'].str.split('\/', expand=True).stack().reset_index(level=1, drop=True).rename('Book_Name'))\nsplit_data.head(10)\n","18095f04":"# remove the repeation \n#The code will replace the name of same book name which were repeated, As we know python is case sensetive  \n\nsplit_data['Book_Name'] = split_data['Book_Name'].replace(['(C++) ++\u0633\u06cc\/\u0633\u06cc++', '\u0633\u06cc\/\u0633\u06cc (C++) ++','(C++)', '(C++) ++\u0633\u06cc', '\u0633\u06cc'], 'C++')\nsplit_data['Book_Name'] = split_data['Book_Name'].replace(['\u0688\u06cc\u0679\u0627 \u0633\u0627\u0626\u0646\u0633 \u06d4 \u0627\u06cc\u06a9 \u062a\u0639\u0627\u0631\u0641' , '\u0688\u06cc\u0679\u0627 \u0633\u0627\u0626\u0646\u0633'], 'Data Science')\nsplit_data['Book_Name'] = split_data['Book_Name'].replace(['\u0628\u0644\u0627\u06a9 \u0686\u06cc\u0646 \u0627\u0648\u0631 \u06a9\u0631\u067e\u0679\u0648 \u06a9\u0631\u0646\u0633\u06cc'], 'Blockchain, Cryptocurrency And Bitcoin')\nsplit_data[\"Book_Name\"] = split_data[\"Book_Name\"].replace(['\u0627\u0646\u0679\u0631\u0646\u06cc\u0679 \u0633\u06d2 \u067e\u06cc\u0633\u06c1 \u06a9\u0645\u0627\u0626\u06cc\u06ba\u061f- \u0645\u0633\u062a\u062d\u0642\u06cc\u0646 \u0632\u06a9\u0648\u0627\u0629'], '\u0627\u0646\u0679\u0631\u0646\u06cc\u0679 \u0633\u06d2 \u067e\u06cc\u0633\u06c1 \u06a9\u0645\u0627\u0626\u06cc\u06ba')\nsplit_data['Book_Name'] = split_data['Book_Name'].replace(['R ka Taaruf', 'R ka Taaruf \u0622\u0631 \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641'], 'R ka Taaruf \u0622\u0631 \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641')\nsplit_data['Book_Name'] = split_data['Book_Name'].replace(['molo masali - \u0645\u0648\u0644\u0648 \u0645\u0635\u0644\u06cc' ], 'molo masali')\nsplit_data['Book_Name'] = split_data['Book_Name'].replace([\"python programming- release date: august 14, 2020\"], \"python programming\")\n\n# best selling book group\nsplit_data.groupby('Book_Name')['Order_Number'].count().reset_index().sort_values('Order_Number', ascending = False).head(10)\n\n","d9d23663":"split_data[\"Book_Name\"] = split_data[\"Book_Name\"].apply(lambda x: x.strip(''))\nbook_stats = split_data[\"Book_Name\"].value_counts(ascending=False)\nbook_stats.head()","e08e365c":"Best_sell_Book = split_data[\"Book_Name\"].value_counts().nlargest(15).to_frame()\n\nfig = px.bar(Best_sell_Book, y =Best_sell_Book['Book_Name'], \n             x = Best_sell_Book.index, color=Best_sell_Book.Book_Name, height=650, title = 'Best 15 most Selling Books',\n             custom_data=[Best_sell_Book['Book_Name'],\n             Best_sell_Book.index])\n\nfig.update_xaxes(title=\"Best 15 Selling Books in Guftugu Publications\",\n                 title_font=dict(size=18, family='Courier'), \n                 linecolor='Black', mirror=True)\n\nfig.update_yaxes(title=\"Books Selling Count\",title_font=dict(size=18, family='Courier', ),\n                 linecolor='gray', mirror=True)\n\nfig.update_traces(texttemplate='%{y}', textposition='outside') \n\n# fig.update_traces(marker_color='#ff7c43',\n#                   hovertemplate=\"<br>\".join([\"Book_Name: %{x}\", \"Count: %{y}\",\n \n                                            \n#     ]))\n\n#fig.update_layout(hovermode=\"x unified\")\nfig.show()","38af33ad":"#This code will check the Order_Status for completed order, cancel, and Return.\ndt.groupby('Order_Status')['Order_Status'].agg('count')\n","aa150cfe":"# code is to visualized the Order_status of complete order, cancelled, and Returned.\npx.histogram(dt, x=dt.Order_Status, color=dt.Order_Status, width = 700, height = 500, title= 'Order Status Frequency', marginal='rug',\n             hover_name='Order_Number', hover_data=dt.columns)","c2861dc9":"Year_Data= dt.groupby([\"Year\"])[\"Order_Number\"].count().reset_index()\nfig=px.pie(Year_Data, values=Year_Data.Order_Number, names=Year_Data['Year'])\nfig.update_traces(hole=.4)\nfig.update_layout(\n    title_text=\"Year Wise total Orders\",\n    # Add annotations in the center of the donut pies.\n    annotations=[dict(text='Order_Status',  font_size=20, showarrow=False),\n                 ])\nfig.show()","c0c98ae6":"df= dt[\"Month\"].value_counts().nlargest(12).to_frame()\ndf.head()\n\n#df = px.data.gapminder().query(\"country=='Canada'\")\nfig = px.histogram(df, x=df.index, y=df['Month'], color=df.index, title='Most successful Months For Gufhtugu Publishers', )\n\nfig.update_xaxes(title=\"Best Month For Gufhtugu Publishers\",\n                 title_font=dict(size=18, family='Courier'), \n                 linecolor='Black', mirror=True)\n\nfig.update_yaxes(title=\"Books Selling Count\",title_font=dict(size=18, family='Courier', ),\n                 linecolor='gray', mirror=True)\n\nfig.show()","17b178bf":"plt.figure(figsize=(10,6))\nax=sns.countplot(x =dt['Year'], hue = 'Year', data = dt)\nax.set_title(\"The Most Orders By Year \", fontsize = 20)\nplt.xlabel(\"Year \",fontsize=17)\nplt.ylabel(\"Number of Orders\", fontsize=17)\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}', (p.get_x() + 0.12, p.get_height()), color='black', size=15, ha=\"center\")","6908fe9b":"plt.figure(figsize = (15,7))\nax = sns.countplot(x=dt.Day,  data=dt, hue = 'Order_Status')\n\nax.set_title(\"The Most Orders by Day \", fontsize = 20)\nplt.xlabel(\"Day name of the most orders \",fontsize=17)\nplt.ylabel(\"Number of Orders\", fontsize=17)\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}', (p.get_x() + 0.1, p.get_height()), color='black', size=15, ha=\"center\")","ba6eaa0c":"Most_orderBy_city = dt.City.value_counts()[:10]\nMost_orderBy_city.head()","b83ec293":"city_count  = dt['City'].value_counts()\ncity_count = city_count[:10,]\nplt.figure(figsize=(15,7))\nax= sns.barplot(city_count.index, city_count.values)\nplt.title('Books Orders in top 10 cities in the Pakistan', fontsize=15)\nplt.ylabel('Number of Orders', fontsize=15)\nplt.xlabel('Cities Names', fontsize=15)\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}', (p.get_x () + 0.4, p.get_height()), color='black', size=15, ha=\"center\")\nplt.show()","c62c607f":"dt.groupby('Payment_Method')['Order_Number'].agg('count')","0667c44a":"# this code clean the repeation of the above Cash on Delivery(COD) with Cash on delivery\ndt['Payment_Method'] = dt['Payment_Method'].replace(['Cash on Delivery (COD)'], 'Cash on delivery')\n","5c47a903":"#Now the Payment_Method is clean and count max\ndt.groupby('Payment_Method')['Order_Number'].agg('count')","4cd47575":"plt.figure(figsize=(15,7))\nax=sns.countplot(x=\"Order_Status\",hue=\"Payment_Method\", data=dt, palette=\"Set2\")\nplt.title('Payment Method', fontsize=15)\nplt.ylabel('Number of Orders', fontsize=15)\nplt.xlabel('Order Status', fontsize=15)\nfor p in ax.patches:\n    ax.annotate(f'\\n{p.get_height()}', (p.get_x () + 0.1, p.get_height()), color='black', size=15, ha=\"center\")\nplt.show()\n","a97d8b73":"Top_Book_year_wise=dt.groupby([\"Book_Name\",\"Year\" ])[\"Order_Number\"].count().reset_index().sort_values(\"Order_Number\", ascending=False)\nTop_Book_year_wise.head()","49b949d8":"# this slicing we help in prediction\nYear_books=dt[['Book_Name','Year']].value_counts().rename_axis(['Book','Year']).reset_index(name='counts')","daf3652e":"# Best selled book in 2019\nplt.figure(figsize=(15,8))\nYear2019=Year_books[Year_books['Year']==2019].nlargest(10, 'counts')\nYear2019.head()\n\npx.bar( Year2019, x= Year2019.Book, y='counts', title='Top_10 Books In 2019', color='Book', )","e752976d":"# Best selled book in 2020\nYear2020=Year_books[Year_books['Year']==2020].nlargest(10, 'counts')\npx.bar( Year2020, x= Year2020.Book, y='counts', title='Top_10 Books In 2020')","68753b62":"# Best selled book in 2021\nYear2021=Year_books[Year_books['Year']==2021].nlargest(10, 'counts')\npx.bar( Year2021, x= Year2021.Book, y='counts', title='Top_10 Books In 2021', color='Book')","fdd48556":"In the above set we clearly see the repeation of data, like 'Karachi' and 'karachi' both are the same city. for easy conversion we all convert into the upercase ","0a0741b5":"code will check the order status for cities where max orders done","b736ebc1":"According to dataset the orders of the first month of 2021 is 2679 which mean if the orders ration remain the same through out the year then their is the chance at the end of 2021 the orders count will be around 32148. so the prediction of the Best book will be the Lucky Draw -Free Book with chance of orders 5844, and the second( \u0627\u0646\u0679\u0631\u0646\u06cc\u0679 \u0633\u06d2 \u067e\u06cc\u0633\u06c1 \u06a9\u0645\u0627\u0626\u06cc\u06ba) with orders 4542. ","ed4c91ea":"The Reason for using this data is to check the deep analysis of the order_statuse. So the code will count the number of order completed, cancelled, and Returned. ","1194981f":"## Find a correlation between date and time with order status","5a656c79":"## Can we predict number of orders, or book names in advance?","8569db7b":"## **Read The data**","980a1605":"## What is the best-selling book?","cd57be1d":"The Reason for split the Book Column is to count every book. beacuse as we seen in data some order item is more then 2 item, so in that case the whole order come in single row, so split column help to count evey book.","65dd4120":"## Visualize order status frequency","138779c4":"## Find a correlation between city and order status","d50f0b9e":"##  **Here Two Approches to fill Missing values, 1) is mean\/median in case of numerical values. 2) Max Count in case of Categorical variable**\n\nSo we will use the second one approch because we have missing values in \"Payment Method\", \"Book Name\" and \"city\". ","d5b781bd":"Now The Data is fill for missing values","8233a2db":"## **Checking for null values and Try to fill Missing values**","542bd52f":"If you like then don't forget to upvote","0a17191b":"Now we clearly see the missing data. Here will check the formate of the missing vaules. Beacuse Pandas only know the missing as 'NaN'.","42667a68":"The below code is about to predict the number of orders, or book name in advance. So the first task is to check the most selling book year wise.","34aee560":"## Introduction:\n**Dataset:** The dataset contains detailed information of 200,000 online book orders in Pakistan from January 2019 to January 2021. It contains order number, order status (completed, cancelled, returned), order date and time, book name and city address. This is the most detailed dataset about e-commerce orders in Pakistan that you can find in the Public domain.\n \n **Variables:** The dataset contains order number, order status, book name, order date, order time and city of the customer.\n \n **using Machine Learning and Data Sciences to explore these ideas:**\n*  What is the best-selling book?\n*  Visualize order status frequency\n*  Find a correlation between date and time with order status\n*  Find a correlation between city and order status\n*  Find any hidden patterns that are counter-intuitive for a layman\n*  Can we predict number of orders, or book names in advance?"}}