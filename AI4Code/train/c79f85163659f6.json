{"cell_type":{"bc4f1590":"code","f8f0e739":"code","08fe1838":"code","fd5afc71":"code","c3ee0ab0":"code","6b279652":"code","2ecfcbeb":"code","1e462220":"code","c5a88787":"code","a0b215ab":"markdown","58fccc15":"markdown","5c656597":"markdown","ebfd8214":"markdown","bb09fced":"markdown"},"source":{"bc4f1590":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nfrom sklearn import metrics\nimport sklearn.preprocessing, sklearn.kernel_ridge, sklearn.model_selection, sklearn.linear_model\nimport multiprocessing\nimport seaborn as sns\nimport scipy.stats\n","f8f0e739":"submission = pd.read_csv('..\/input\/sample_submission.csv')\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint(f'Shape of the train {train.shape}')\nprint(f'Shape of the test {test.shape}')\ntest.head()\n","08fe1838":"data = train.iloc[:, 2:].values\nref = train['target'].values\n#train['target'].value_counts()\n#plt.figure()\nsns.countplot(train['target'])\n#plt.show()","fd5afc71":"model_default = sklearn.linear_model.LogisticRegression()\nmodel_default.fit(data, ref)\n\npredict_test = model_default.predict_proba(test.iloc[:, 1:].values)\nsubmission['target'] = predict_test\nsubmission.to_csv('submission_logreg_default.csv', index=False)\n\nmodel = sklearn.linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nmodel.fit(data, ref)\n\npredict_test = model.predict_proba(test.iloc[:, 1:].values)\nsubmission['target'] = predict_test\nsubmission.to_csv('submission_logreg_l1.csv', index=False)","c3ee0ab0":"def cross_validation(X, y, model, parameters, pname, nfold=10):\n    cv_method = sklearn.model_selection.KFold(n_splits=nfold, shuffle=True, random_state=13)\n    rgr = sklearn.model_selection.GridSearchCV(model, parameters, n_jobs=multiprocessing.cpu_count()-1, cv=cv_method, scoring='roc_auc')\n    rgr.fit(X, y)\n    plt.semilogx(parameters[pname], rgr.cv_results_['mean_test_score'], 'o-r')\n    plt.xlabel(pname)\n    plt.ylabel('ROC-AUC')\n    plt.title(f'{nfold}-Fold cross validation')\n    print(f\"The best {pname} parameter is {rgr.best_params_[pname]}\")\n    return rgr\n","6b279652":"model = sklearn.linear_model.LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear')\nparameters = {'C': np.logspace(-2, 5, 40)}\nrgr = cross_validation(data, ref, model, parameters, 'C', nfold=10)\n","2ecfcbeb":"predict_test = rgr.best_estimator_.predict_proba(test.iloc[:, 1:].values)\nsubmission['target'] = predict_test\nsubmission.to_csv('submission_logreg_cv_l1.csv', index=False)","1e462220":"def cross_validation_average(X, y, X_test, model, nfold=10):\n    scores = []\n    y_test = 0\n    folds = sklearn.model_selection.StratifiedKFold(n_splits=nfold, shuffle=True, random_state=13)\n    for idx, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        X_train, X_valid = X[train_index], X[valid_index]\n        y_train, y_valid = y[train_index], y[valid_index]\n        print(f'Process fold no {idx}: train\/validation={len(y_train)}\/{len(y_valid)}')\n\n        model = model\n        model.fit(X_train, y_train)\n        y_pred_valid = model.predict(X_valid).reshape(-1,)\n        score = metrics.roc_auc_score(y_valid, y_pred_valid)\n        y_test += model.predict_proba(X_test)[:, 1]\n        scores.append(score)\n\n    plt.plot(range(nfold), scores, 'o-r')\n    plt.xlabel('N-Fold')\n    plt.ylabel('ROC-AUC')\n    plt.title(f'{nfold}-Fold cross validation scores')\n    print(f\"Results: Max={np.max(scores)}, Mean={np.mean(scores)}, STD={np.std(scores)}\")\n    return scores, y_test\/nfold\n\n","c5a88787":"scores, predict_test = cross_validation_average(data, ref, test.iloc[:, 1:].values, rgr.best_estimator_, nfold=10)\nsubmission['target'] = predict_test\nsubmission.to_csv('submission_logreg_cv_l1_average.csv', index=False)\n","a0b215ab":"# DON'T Overfit: A step-by-step quest to solution\n\nThe plan is as follows:\n- As a first step I will explore the Logistic regression (right now it achieved 0.844)\n- Next, will deal with the feature selection\n- After that I will try to understand the difference between the train and the test sets ","58fccc15":"### Next: Averaging the model\n","5c656597":"Summarizing the results of submitting the LogisticRegression:\n- Averaging over 10 folds of the same model gives the result 0.842 - not an improvement comparing to the previous result","ebfd8214":"### The first shot: Logistic regression\nWe train the Logistic regression with different parameters, including optimizing the regularization strength","bb09fced":"### Summarizing the results of submitting the LogisticRegression:\n- A default Logistic regression trained on the train set and all the features gives 0.274 score in the leaderboard of the competition - much worse than the 0.5 of the completely random submission\n- A Logistic regressoin with the parameters: 'class_weight='balanced', penalty='l1', C=0.1, solver='liblinear'' gives score of 0.844\n- Optimizing the parameter C with the 40-fold cross-validation doesn't improve the score: 0.843"}}