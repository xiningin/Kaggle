{"cell_type":{"261f0b50":"code","7c3f8a3b":"code","e485b534":"code","9b74da2b":"code","511e8e4e":"code","ee1c5261":"code","970aab78":"code","0cafd711":"code","7c62bf44":"code","8430589e":"code","4ae55cfb":"code","9f65c193":"code","1f947404":"code","d3b2486d":"code","8a7f04f8":"code","1e738b76":"markdown","d8a927a2":"markdown","7e7c266e":"markdown","eec760f7":"markdown","334d7801":"markdown","4b3060cf":"markdown"},"source":{"261f0b50":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c3f8a3b":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils","e485b534":"df = pd.read_csv('\/kaggle\/input\/devanagari-character-set\/data.csv')","9b74da2b":"df.size","511e8e4e":"X = df.iloc[:, :-1]\ny = df.iloc[:, -1]","ee1c5261":"from sklearn.preprocessing import LabelBinarizer\nbinencoder = LabelBinarizer()\ny = binencoder.fit_transform(y)","970aab78":"X_images = X.values.reshape((92000),32,32)\nimport matplotlib.pyplot as plt\nplt.imshow(X_images[0])\nplt.show()","0cafd711":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_images, y, test_size = 0.2, random_state=90)\n","7c62bf44":"X_train = X_train\/255\nX_test = X_test\/255\n\n#change the dimension from 3 to 5\nX_train = X_train.reshape(X_train.shape[0], 32,32,1).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 32,32,1).astype('float32')","8430589e":"conv_model = Sequential()\n\n#add first Conv layer wit max pooling\nconv_model.add(\nConv2D(32,(4,4),\n      input_shape = (32,32,1),\n      activation = 'relu',\n      name= 'firstConv'\n      )\n)\n\nconv_model.add(\nMaxPooling2D(pool_size=(2,2),\n            name='FirstPool'\n            )\n)\n\n#add second CONv and maxpool\nconv_model.add(\nConv2D(64,(3,3),\n      activation = 'relu',\n      name= 'secondConv'\n      )\n)\n\nconv_model.add(\nMaxPooling2D(pool_size=(2,2),\n            name='SecondPool'\n            )\n)\n\nconv_model.add(Dropout(0.2))   #it will prevent overfitting","4ae55cfb":"# Building Dense neural net on outputs of the Conv Net\n\n# Input Layer : Flattening the Outputs of the Conv Nets\nconv_model.add(Flatten())\n\n# Two Dense Layers 128 Neuraons and 50 Neurons\nconv_model.add(\n    Dense(128,\n          activation='relu',\n          name=\"dense_1\"\n         )\n)\nconv_model.add(\n    Dense(50, \n          activation='relu', \n          name=\"dense_2\"\n         )\n)\n\n# Output Layer with 46 Unique Outputs\nconv_model.add(\n    Dense(46, \n          activation='softmax', \n          name=\"modeloutput\"\n         )\n)\n\nconv_model.compile(\n    loss='categorical_crossentropy', \n    optimizer='adam',\n    metrics=['accuracy']\n)","9f65c193":"conv_model.summary()","1f947404":"result = conv_model.fit(X_train, y_train, validation_split =0.2, epochs = 10, batch_size = 92, verbose=2)","d3b2486d":"scores = conv_model.evaluate(X_test, y_test, verbose=0)\n\nprint(\"Accuracy: %.2f%%\" %(scores[1]*100))\n","8a7f04f8":"num = 5555\nplt.imshow(X_images[num])\nplt.show()\n\n\nimgTrans = X_images[num].reshape(1,32,32,1)\nimgTrans.shape\n\npredictions = conv_model.predict(imgTrans)\nbinencoder.classes_[np.argmax(predictions)]","1e738b76":"# check the model in testing data`","d8a927a2":"# lets run epoches\n\nIn every epoch the loss will be decreasign and accuracy is increasing.","7e7c266e":"# Lets build the convolutional model","eec760f7":"## lets perform train_test_split","334d7801":"#### References\n\n1. Medium Blog\n2. Github\n3. Kaggle Dataset","4b3060cf":"# Yeah!!!! We have made the Recognizer"}}