{"cell_type":{"54b6f101":"code","d3e610ea":"code","6d6ebdd9":"code","d186a37f":"code","0e15b3b9":"code","6d8fa5b6":"code","36c341b0":"code","1b87b8be":"code","20c2bed5":"code","22823f72":"code","8f8d9af4":"code","51fdb443":"code","17119fb4":"code","0eb6106d":"markdown","134fe104":"markdown","773415e0":"markdown","38bde19d":"markdown"},"source":{"54b6f101":"pip install jcopdl","d3e610ea":"import torch\nfrom torchvision import datasets, transforms\nfrom torchvision.models import mobilenet_v2\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nfrom tqdm.auto import tqdm\nfrom jcopdl.callback import Callback, set_config\n\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nimport numpy as np\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","6d6ebdd9":"bs = 128\ncrop_size = 224\n\ntrain_transform = transforms.Compose([\n    transforms.RandomRotation(10),\n    transforms.RandomResizedCrop(crop_size, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(230),\n    transforms.CenterCrop(crop_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\ntrain_set = datasets.ImageFolder(\"..\/input\/kue-indonesia\/train\/\", transform=train_transform)\ntrainloader = DataLoader(train_set, batch_size=bs, shuffle=True)\n\ntest_set = datasets.ImageFolder(\"..\/input\/kue-indonesia\/validation\", transform=test_transform)\ntestloader = DataLoader(test_set, batch_size=bs, shuffle=True)","d186a37f":"label2cat = train_set.classes\nlabel2cat","0e15b3b9":"class CustomMobileNetv2(nn.Module):\n  def __init__(self, output_size):\n    super().__init__()\n    self.mnet = mobilenet_v2(pretrained=True)\n    self.freeze()\n\n    self.mnet.classifier = nn.Sequential(\n        nn.Linear(1280, output_size),\n        nn.LogSoftmax()\n    )\n\n  def forward(self, x):\n    return self.mnet(x)\n  \n  def freeze(self):\n    for param in self.mnet.parameters():\n      param.requires_grad = False\n\n  def unfreeze(self):\n    for param in self.mnet.parameters():\n      param.requires_grad = True","6d8fa5b6":"config = set_config({\n    'batch_size': bs,\n    'crop_size': crop_size,\n    'output_size': len(train_set.classes)\n})","36c341b0":"model = CustomMobileNetv2(config.output_size).to(device)\ncriterion = nn.NLLLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.001)\ncallback = Callback(model, config, early_stop_patience=2, outdir='model')","1b87b8be":"def loop_fn(mode, dataset, dataloader, model, criterion, optimizer, device):\n  if mode == 'train':\n    model.train()\n  elif mode == 'test':\n    model.eval()\n  \n  cost = correct = 0\n  for feature, target in tqdm(dataloader, desc=mode.title()):\n    feature, target = feature.to(device), target.to(device)\n    output = model(feature)\n    loss = criterion(output, target)\n\n    if mode == 'train':\n      loss.backward()\n      optimizer.step()\n      optimizer.zero_grad()\n    \n    cost += loss.item() * feature.shape[0]\n    correct += (output.argmax(1) == target).sum().item()\n  cost = cost\/len(dataset)\n  acc = correct\/len(dataset)\n  return cost, acc","20c2bed5":"while True:\n  train_cost, train_score = loop_fn('train', train_set, trainloader, model, criterion, optimizer, device)\n  with torch.no_grad():\n    test_cost, test_score = loop_fn('test', test_set, testloader, model, criterion, optimizer, device)\n\n  # Logging\n  callback.log(train_cost, test_cost, train_score, test_score)\n\n  # Checkpoint\n  callback.save_checkpoint()\n\n  # Runtime Plotting\n  callback.cost_runtime_plotting()\n  callback.score_runtime_plotting()\n\n  # Early Stopping\n  if callback.early_stopping(model, monitor='test_score'):\n    callback.plot_cost()\n    callback.plot_score()\n    break","22823f72":"model.unfreeze()\noptimizer = optim.AdamW(model.parameters(), lr=1e-5)\n\ncallback.reset_early_stop()\ncallback.early_stop_patience = 5","8f8d9af4":"while True:\n  train_cost, train_score = loop_fn('train', train_set, trainloader, model, criterion, optimizer, device)\n  with torch.no_grad():\n    test_cost, test_score = loop_fn('test', test_set, testloader, model, criterion, optimizer, device)\n\n  # Logging\n  callback.log(train_cost, test_cost, train_score, test_score)\n\n  # Checkpoint\n  callback.save_checkpoint()\n\n  # Runtime Plotting\n  callback.cost_runtime_plotting()\n  callback.score_runtime_plotting()\n\n  # Early Stopping\n  if callback.early_stopping(model, monitor='test_score'):\n    callback.plot_cost()\n    callback.plot_score()\n    break","51fdb443":"feature, target = next(iter(testloader))\nfeature, target = feature.to(device), target.to(device)\nwith torch.no_grad():\n  model.eval()\n  output = model(feature)\n  preds = output.argmax(1)\npreds","17119fb4":"fig, axes = plt.subplots(6, 6, figsize=(24, 24))\nfor img, label, pred, ax in zip(feature, target, preds, axes.flatten()):\n  ax.imshow(img.permute(1,2,0).cpu())\n  font = {\"color\":'r'} if label != pred else {\"color\": 'g'}\n  label, pred = label2cat[label.item()], label2cat[pred.item()]\n  ax.set_title(f\"Label: {label}\\nPred: {pred}\", fontdict=font);\n  ax.axis(\"off\");","0eb6106d":"# **Architecture & Config**","134fe104":"# **Dataset & Dataloader**","773415e0":"# **Fine-Tuning**","38bde19d":"# **Adaptation**"}}