{"cell_type":{"e92107b9":"code","64f8a4c0":"code","47e788cf":"code","ec67ae24":"code","b9266e8e":"code","4a075643":"code","8a712d55":"code","4dbd6812":"code","39dd1c71":"code","5d1bcddb":"code","e75c935e":"code","5cb54c13":"code","3dd753cb":"code","71a416b0":"code","1a539e67":"code","d4cad574":"code","8652bd4b":"code","1a0a2255":"code","fd21ba78":"code","1bcf67f7":"code","ba38ba28":"code","b6ec2dd2":"code","7afe6b86":"code","5777c8af":"code","3115ce11":"code","377ade61":"code","5ada6d6d":"code","f0ffcace":"code","c6dd877b":"code","dff3153f":"code","b1e97f8b":"code","2260c0ef":"code","7e8604ae":"code","a5aee5d4":"code","7bc58361":"code","02064388":"code","0b54dde0":"code","02486edf":"code","ba97f546":"code","0b7b9080":"code","db4c807d":"code","5ec966bd":"code","a8777209":"code","d8e16f81":"code","a34ec454":"code","41884c71":"code","a1f8b41f":"code","78846a25":"code","30bf9f38":"code","aa168b33":"code","05af9200":"code","e29c8070":"code","c993e911":"code","81b212d8":"code","39409f10":"code","23bb37ba":"code","f77a815b":"code","16eaa244":"markdown","73d0a41d":"markdown","1c4141b7":"markdown","97cab767":"markdown","34823133":"markdown","56be6448":"markdown","4ac35b13":"markdown","718c7363":"markdown","dbe2dc18":"markdown","207896ce":"markdown","e127bb51":"markdown","2fffe5b8":"markdown"},"source":{"e92107b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport seaborn as sns\nfrom sklearn.preprocessing import scale \nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.metrics import roc_auc_score,roc_curve\nimport statsmodels.formula.api as smf\nfrom sklearn.linear_model import LogisticRegression\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","64f8a4c0":"import pandas as pd\ndf = pd.read_csv(\"..\/input\/breast-cancer-wisconsin-data\/data.csv\")\ndata = df.copy()\ndata.drop([\"Unnamed: 32\", \"id\"], axis=1, inplace=True)                  # Unnamed: 32 sutunu veriye baktigimizda nan lardan olusuyor ondan drop edelim\ndata.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]   # binary yani 0 ile 1 degerlerden olusturmamiz gerekiyor. object lerden olusuyor bunun yerine 0 ile 1 lerden olurmali. cunku bize int veya float lazim\ndata.head()","47e788cf":"data.describe()","ec67ae24":"y = data.diagnosis.values\nx_data = data.drop([\"diagnosis\"], axis=1)","b9266e8e":"# x degerlerimiz baktigimizda degerlerin cok buyuk oldugu gorulur. Dolayisiyla verimizi normallestirmemiz gerekiyor\n\n#*** Normalize ***#\nx = (x_data - np.min(x_data))\/(np.max(x_data) - np.min(x_data)).values","4a075643":"X_train, X_test, y_train, y_test = train_test_split(x, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","8a712d55":"# statsmodels araciligiyla model kurup fit yapalim. Burda bize modelin anlamliligi ve hangi degiskenin ne kadar etki ettigi bu tablodan cikiyor\n\nloj = sm.Logit(y, x)\nloj_model= loj.fit()\nloj_model.summary()","4dbd6812":"from sklearn.linear_model import LogisticRegression\nloj = LogisticRegression(solver = \"liblinear\")\nloj_model = loj.fit(x,y)\nloj_model","39dd1c71":"# sabit degeri\nloj_model.intercept_","5d1bcddb":"# butun bagimsiz degiskenlerin katsayi degerleri\nloj_model.coef_","e75c935e":"# tahmini yapalim\ny_pred = loj_model.predict(x)","5cb54c13":"# Gercekte 1 iken 1(PP) olanlar 1 iken 0(PN) olanlar, gercekte 0 iken 1(NP) olanlar 0 iken 0(NN) olanlar\nconfusion_matrix(y, y_pred)","3dd753cb":"# accuracy degerine bakalim\naccuracy_score(y, y_pred)","71a416b0":"# en detayli bir siniflandirma algoritmasinin sonuclarini degerlendirecek ciktilardan biri\nprint(classification_report(y, y_pred))","1a539e67":"# ilk 10 model tahmini\nloj_model.predict(x)[0:10]","d4cad574":"# yukarda 1 ve 0 verdigi degerlerden ziyade asil degerlerini versin istiyorsak 'predict_proba' modulunu kullanarak gercek degerleri\n# matriste 0. indexinde veya sol tarafi 0 a ait degerleri, 1. indexinde veya sag tarafi 1 e ait degerleri verir \nloj_model.predict_proba(x)[0:10][:,0:2]                # ilk 10","8652bd4b":"# simdi yukardaki 'predict_proba' on tahmin olasilik degerlerini model haline getirmeye calisalim\ny_probs = loj_model.predict_proba(x)\ny_probs = y_probs[:,1]","1a0a2255":"y_probs[0:10]               # ilk 10","fd21ba78":"# burdaki tahmin degerlerimizi donguye sokup 0.5 ten buyuklere 1 ve kucuk olanlara 0 versin\ny_pred = [1 if i > 0.5 else 0 for i in y_probs]","1bcf67f7":"# yukardaki degere baktigimizda degisikligi farketmis oluruz ama burda degisiklik yok cunku dogrulanmasi gereken cok bir deger yokmus demekki. Bunu yapma amacimiz modelimizi dogrulamaktir.\ny_pred[0:10]","ba38ba28":"confusion_matrix(y, y_pred)","b6ec2dd2":"accuracy_score(y, y_pred)","7afe6b86":"print(classification_report(y, y_pred))","5777c8af":"# bunu yukarda yaptik ilk 5 eleman gorunsun\nloj_model.predict_proba(x)[:,1][0:5]","3115ce11":"logit_roc_auc = roc_auc_score(y, loj_model.predict(x))","377ade61":"fpr, tpr, thresholds = roc_curve(y, loj_model.predict_proba(x)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Oran\u0131')\nplt.ylabel('True Positive Oran\u0131')\nplt.title('ROC')\nplt.show()\n# mavi cizgi kurmus oldugumuz model ile ilgili basarimizin grafigi\n# kirmizi cizgi hicbirsey yapmasak modelimiz bu sekilde olacak\n\n\n# Sekilde goruldugu gibi cok degistirilmesi veya dogrulanmasi gereken deger bulamadi bu veride.\n\n","5ada6d6d":"# test train ayirma islemine tabi tutalim\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 42)","f0ffcace":"# Modelimizi olusturup fit edelim\nloj = LogisticRegression(solver = \"liblinear\")\nloj_model = loj.fit(X_train,y_train)\nloj_model","c6dd877b":"# dogrulanma skorunu bulalim\naccuracy_score(y_test, loj_model.predict(X_test))","dff3153f":"# dogrulanmis modelin CV skoru bulalim\ncross_val_score(loj_model, X_test, y_test, cv = 10).mean()","b1e97f8b":"# model kurma\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\nknn_model = knn.fit(X_train, y_train)\nknn_model","2260c0ef":"# tahmin degeri\ny_pred = knn_model.predict(X_test)","7e8604ae":"accuracy_score(y_test, y_pred)","a5aee5d4":"# detayli ciktimizida alalim. \nprint(classification_report(y_test, y_pred))","7bc58361":"# KNN parametrelerini bulma\nknn_params = {\"n_neighbors\": np.arange(1,50)}","02064388":"# siniflandirmasi ve CV ile fit yapalim\nknn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn, knn_params, cv=10)\nknn_cv.fit(X_train, y_train)","0b54dde0":"# bunu sadece gozlemlemek icin yapiyoruz. Final modeli onemli bizim icin\nprint(\"En iyi skor:\" + str(knn_cv.best_score_))\nprint(\"En iyi parametreler: \" + str(knn_cv.best_params_))","02486edf":"# yukarida ciktida ortaya cikan n_neighbors 11 cikmisti bunu kullanarak KNN olusturulup tuned edelim\nknn = KNeighborsClassifier(11)\nknn_tuned = knn.fit(X_train, y_train)","ba97f546":"# simdide test in tuned score una bakalim\nknn_tuned.score(X_test, y_test)","0b7b9080":"# tahmin degeri\ny_pred = knn_tuned.predict(X_test)","db4c807d":"accuracy_score(y_test, y_pred)","5ec966bd":"# model ve nesne olusturma fit ile beraber yapalim\nfrom sklearn.svm import SVC\n\nsvm_model = SVC(kernel = \"linear\").fit(X_train, y_train)","a8777209":"svm_model","d8e16f81":"y_pred = svm_model.predict(X_test)","a34ec454":"accuracy_score(y_test, y_pred)","41884c71":"# C parametresi olusturulacak olan dogrunun veya ayrimin olusturulmasiyla ilgili bir kontrol etme imkani saglayan parametredir\n# C degeri 0 olamaz hata verir ondan 1 den baslasin\n\nsvc_params = {\"C\": np.arange(1,10)}","a1f8b41f":"svc = SVC(kernel = \"linear\")","78846a25":"\nsvc_cv_model = GridSearchCV(svc,svc_params, \n                            cv = 10, \n                            n_jobs = -1, \n                            verbose = 2 )\n\nsvc_cv_model.fit(X_train, y_train)","30bf9f38":"# en iyi parametre degerleri\nprint(\"En iyi parametreler: \" + str(svc_cv_model.best_params_))","aa168b33":"# tuned edip fit leyelim\nsvc_tuned = SVC(kernel = \"linear\", C = 5).fit(X_train, y_train)","05af9200":"# simdi gercek deger ile tahmin edilen degerin karsilastirma islemini yapalim\ny_pred = svc_tuned.predict(X_test)\naccuracy_score(y_test, y_pred)","e29c8070":"from sklearn.naive_bayes import GaussianNB","c993e911":"nb = GaussianNB()\nnb_model = nb.fit(X_train, y_train)\nnb_model","81b212d8":"# tahmin islemini yapalim\nnb_model.predict(X_test)[0:10]","39409f10":"y_pred = nb_model.predict(X_test)","23bb37ba":"accuracy_score(y_test, y_pred)","f77a815b":"cross_val_score(nb_model, X_test, y_test, cv = 10).mean()","16eaa244":"##  MODEL TUNNING ","73d0a41d":"## MODEL TUNNING","1c4141b7":"# Naive Bayes Model\n\n* Olasilik temelli bir modelleme teknigidir. Amac belirli bir ornegin her bir sinifa ait olma olasiliginin kosullu olasilik temelli hesaplanmasidir.\n\n* e-ticaret veya cok sinifli veri setlerinde gayet iyi calistigi gorulmustur. \n\n*Ornek aylik geliri 2000 olan bu kisi krediyi odeyebilir mi?\nbu tarz orneklerde gayet uygun bir modeldir.","97cab767":"# Logistic Regresyon\n\n* Amac henuz gozlenmemis bir x deger seti geldiginde bunun sonucunda olusacak olan sinifi ortaya cikarmak tahmin etmek bir siniflandirici cikarmaktir.\n* Siniflandirma problemi icin bagimli ve bagimsiz degiskenler arasindaki iliskiyi tanimlayan linear bir model kurmaktir.\n* Bagimli degiskenin 1 yada 0 olmasi durumuyla ilgilenir yada evet veya hayir durumu\n* Bize int veya float degerlerle is yapar","34823133":"## PREDICT and MODEL TUNNING","56be6448":"## MODEL, TAHMIN VE MODEL TUNNING","4ac35b13":"## MODEL\n","718c7363":"### As we can see between 4 models(Logistic Regresyon, KNN, SVC and Naive Bayes) SVC is most suitable model in Breast Cancer Wisconsin data. SVC model can explain accuracy score 98% of this data.\n\n","dbe2dc18":"* Tahminler gozlem benzerligine gore yapilir. Bana arkadasini soyle sana kim oldugunu soyleyeyeyim mantigi ile calisir.\n\n* Bagimsiz degiskenler ile diger degiskenler arasindaki uzaklik hesaplanir. en yakin k adet gozlemi bulup bunun icin en yakin gozlenen sinif model sinifidir.","207896ce":"# SVC (Support Vector for Classification)","e127bb51":"# KNN (K-Nearst Neigbourhood)\n","2fffe5b8":"* Amac iki sinif arasindaki ayrimin(marjinin) optimum olmasini saglayacak hiper-duzlemi bulmaktir\n\n* Linear ve NonLinear SVM ler mevcut."}}