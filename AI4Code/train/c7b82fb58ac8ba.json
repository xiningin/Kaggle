{"cell_type":{"d42c3aa2":"code","c6c27161":"code","90fd01ae":"code","52484f93":"code","518c0652":"code","8467d9db":"code","c01623e4":"code","17d817ab":"code","9c87c510":"code","5c0e5d48":"code","288d196b":"code","663f33ea":"code","f7030d2e":"code","659c0133":"code","bd234c35":"code","760df909":"code","af03ae88":"code","880936aa":"code","d3522cbb":"code","42c48509":"code","caa66ff4":"code","4572bb9a":"code","d936cc3c":"code","d5741ba5":"code","89d76f67":"code","a6f5e727":"code","bba04b3e":"code","4bb109f8":"code","928b25f6":"code","29214ca7":"code","ee6f32dc":"code","26f3635b":"code","e3d98f35":"code","f8555190":"code","1feec9ab":"code","1cc2b916":"code","af814a43":"code","1fed7723":"code","e64e17c4":"code","5f036122":"code","8e39c5b5":"code","f4b63656":"markdown","94eb7c4d":"markdown","81cc109d":"markdown","52b9b0d6":"markdown","b9cc0920":"markdown","8db0300d":"markdown","d8fe2288":"markdown","b9b6c339":"markdown","2e320d55":"markdown","afaf965f":"markdown","854693bf":"markdown","f8409995":"markdown","d892858c":"markdown","1119f142":"markdown","f9fbcf7c":"markdown","ed3b1717":"markdown","5abeb19d":"markdown","73ec4a84":"markdown","e922ae3b":"markdown"},"source":{"d42c3aa2":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","c6c27161":"%matplotlib inline","90fd01ae":"training = pd.read_csv('..\/input\/titanic\/train.csv')\ntesting = pd.read_csv('..\/input\/titanic\/test.csv')","52484f93":"training.info()","518c0652":"testing.info()","8467d9db":"training.head()","c01623e4":"training.describe()","17d817ab":"training['Sex'].value_counts()","9c87c510":"sns.catplot('Sex',data=training , kind='count')","5c0e5d48":"sns.catplot('Pclass',data=training,hue='Sex' , kind='count')","288d196b":"training['Age'].hist(bins=20)","663f33ea":"training['Age'].plot.kde()","f7030d2e":"training[\"Survivor\"] = training.Survived.map({0: \"No\", 1: \"Yes\"})\n\n \nsns.catplot('Survivor',data=training, kind = 'count')","659c0133":"training.isnull().sum()","bd234c35":"mean = training['Age'].mean()\nstd = training['Age'].std()\n\nlow  = mean - std\nhigh = mean + std\nAge_missing = training['Age'].isnull().sum()\n\nAge_rand = np.random.randint(low=low , high=high , size =Age_missing)\n\ntraining['Age'][np.isnan(training['Age'])]=Age_rand\ntraining['Age'] = training['Age'].astype(int)","760df909":"\ntraining['Age'].isnull().sum()","af03ae88":"training['Embarked'].value_counts()","880936aa":"training['Embarked'] = training['Embarked'].fillna('S')","d3522cbb":"training['Embarked'].isnull().sum()","42c48509":"#training['Fare']=training['Fare'].astype(int)\ntesting.isnull().sum()","caa66ff4":"mean_test = testing['Age'].mean()\nstd_test = testing['Age'].std()\n\nlow_test  = mean_test - std_test\nhigh_test = mean + std\nAge_missing_test = testing['Age'].isnull().sum()\n\nAge_rand = np.random.randint(low=low_test , high=high_test , size =Age_missing_test)\n\ntesting['Age'][np.isnan(testing['Age'])]=Age_rand\ntesting['Age'] = testing['Age'].astype(int)","4572bb9a":"testing['Fare'].plot.kde()","d936cc3c":"\ntesting['Fare']=testing['Fare'].fillna(testing['Fare'].median())","d5741ba5":"testing['Age'].isnull().sum()","89d76f67":"training = pd.get_dummies(training , columns = ['Pclass' , 'Sex' , 'Embarked' ] , drop_first = True)","a6f5e727":"training.head()","bba04b3e":"X = training.iloc[:, [3 ,4,5,7,10,11,12,13,14]].values\ny = training.iloc[:, 1].values","4bb109f8":"testing = pd.get_dummies(testing , columns = ['Pclass' , 'Sex' , 'Embarked' ] , drop_first = True)","928b25f6":"testing.head()","29214ca7":"X_test = testing.iloc[:, [2,3 ,4,6,8,9,10,11,12]].values","ee6f32dc":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)\nX_test = sc.transform(X_test)","26f3635b":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X, y)","e3d98f35":"survived_test = classifier.predict(X_test)","f8555190":"from sklearn.svm import SVC\nclassifier = SVC(random_state = 0)","1feec9ab":"classifier.fit(X, y)","1cc2b916":"survived_test = classifier.predict(X_test)","af814a43":"len(survived_test)","1fed7723":"df = pd.DataFrame({'PassengerId':testing['PassengerId'],'survived':survived_test })","e64e17c4":"df.rename({'PassengerId':'PassengerId','suvivied':'survived_test'},inplace='True')","5f036122":"df.shape","8e39c5b5":"df.to_csv('Titanic_prediction.csv',index=False)","f4b63656":"The distribution for the 'Fare' in testing dataset shows that there is right skewness , so we will impute the 'Fare' with the median ","94eb7c4d":"The most frequent value is: 'S'. \nSo, we can impute missing values of 'Embarked' with S","81cc109d":"# This is My Submission for Titanic competition","52b9b0d6":"A Machine learning Project Pipeline consists of:\n1. Loading the Required Libraries.\n2. Loading the dataset.\n3. Exploration of the dataset including Visualization.\n4. Data Preprocessing and Feature Engineering.\n5. Building the Model.\n6. Evaluation of the Model.\n7. Model Selection if needed.","b9cc0920":"\nWe need to make dummy variables for the categorical variables that we need to build the model","8db0300d":"From the previous table we can observe the 'Age' has 714 non-null data , thus: 177 missing values.","d8fe2288":"## Loading the Required Libraries","b9b6c339":"Let's check for number of men and women on the ship and the relative classes","2e320d55":"Let's deal with missing values","afaf965f":"Let's analyze the survived and dead passengers ","854693bf":"## Data Preprocessing and Feature Engineering.","f8409995":"##  Exploration of the dataset including Visualization","d892858c":"Here in our Strategy in dealing with missing values , We see that we have 3 columns that have missing values with different volumes.\n'Age'has 177 missing values.\n'cabin' has 687 missing values.\nAnd finally'Embarked' has 2 missing values.\n\nSo , for 'Age' we saw the distribution of 'Age' which allow us to impute these values with random values around the mean.\nWhile for 'Embarked' , it is ok to impute with  the most frequent.\nWhile for cabin , 687 is very high number , so it is better to remove it or not to consider this feature in training our model.","1119f142":"Check for Testing dataset","f9fbcf7c":"Trying SVM","ed3b1717":"## Building the Model","5abeb19d":"##  Loading the dataset.\n","73ec4a84":"Try Logistic Regression","e922ae3b":"Now check for that 'Age' is imputed"}}