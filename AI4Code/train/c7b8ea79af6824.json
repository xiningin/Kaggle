{"cell_type":{"e32f38f7":"code","ef8ddddc":"code","443a976c":"code","d6b9b0d7":"code","2330f8c4":"code","8c6b421d":"code","b3f53be5":"code","92017103":"code","69a69ba9":"code","88ba3ea0":"code","a7461130":"code","a46d9a2a":"code","450cebdf":"code","22993dea":"code","802953dd":"code","a3b52a68":"code","f3c88239":"code","e74568c9":"code","8cb9a001":"code","52fcbb72":"code","da446e50":"code","84f787dc":"code","97ffb575":"code","a2baeec6":"code","6e2a7966":"markdown","f2115fe4":"markdown","e75e3919":"markdown","10fc9112":"markdown","6ec05eb6":"markdown","3413c2cd":"markdown","84f83c3c":"markdown"},"source":{"e32f38f7":"# Import Important Libraries\nimport os # To investigate the data\n\n#Tensorflow\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers, Sequential\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport pathlib\n#plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# Mathematical operation\nimport numpy as np","ef8ddddc":"# data directories\ntrain_root = \"..\/input\/fruits-360_dataset\/fruits-360\/Training\"\ntest_root = \"..\/input\/fruits-360_dataset\/fruits-360\/Test\"","443a976c":"# Investigate our data to acetain that number of classes in training ser equal testing set\nlen(os.listdir(train_root)),len(os.listdir(test_root))","d6b9b0d7":"# load a sample image\nimage_path = train_root + \"\/Apple Braeburn\/0_100.jpg\"\ndef image_load(image_path):\n    loaded_image = image.load_img(image_path)\n    image_rel = pathlib.Path(image_path).relative_to(train_root)\n    print(image_rel)\n    return loaded_image","2330f8c4":"image_load(image_path)","8c6b421d":"# Loading the data into our model\ntrain_generator = ImageDataGenerator(rescale=1\/255) # Training set\ntest_generator = ImageDataGenerator(rescale=1\/255) # Testing set\n\ntrain_image_data = train_generator.flow_from_directory(str(train_root),target_size=(224,224))\ntest_image_data = test_generator.flow_from_directory(str(test_root), target_size=(224,224))","b3f53be5":"# Model url\nfeature_extractor_url = \"https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_100_224\/feature_vector\/2\"","92017103":"# Create the model and check expected Image size\ndef feature_extractor(x):\n  feature_extractor_module = hub.Module(feature_extractor_url)\n  return feature_extractor_module(x)\n\nIMAGE_SIZE = hub.get_expected_image_size(hub.Module(feature_extractor_url))\nIMAGE_SIZE","69a69ba9":"# Check the images shape for train set\nfor image_batch, label_batch in train_image_data:\n    print(\"Image batch shape:\",image_batch.shape)\n    print(\"Label batch shape:\",label_batch.shape)\n    break","88ba3ea0":"# Check the images shape for testing set\nfor test_image_batch, test_label_batch in test_image_data:\n    print(\"Image batch shape:\",test_image_batch.shape)\n    print(\"Label batch shape:\",test_label_batch.shape)\n    break","a7461130":"# Wrap the the module in a keras layer\nfeature_extractor_layer = layers.Lambda(feature_extractor,input_shape=IMAGE_SIZE+[3])","a46d9a2a":"# Freeze the variables in the feature extractor so that training only modifies the new classifier layer\nfeature_extractor_layer.trainable = False","450cebdf":"# Attach a classification head\nmodel = Sequential([\n    feature_extractor_layer,\n    layers.Dense(train_image_data.num_classes, activation = \"softmax\")\n    ])\nmodel.summary()","22993dea":"# Initialize the TFHub module\nsess = K.get_session()\ninit = tf.global_variables_initializer()\n\nsess.run(init)","802953dd":"# Test a siingle batch to see that the result comes back with the expected shape\nresult = model.predict(image_batch)\nresult.shape","a3b52a68":"# Compile the model with an optimizer\nmodel.compile(\n    optimizer = tf.train.AdamOptimizer(),\n    loss = \"categorical_crossentropy\",\n    metrics = ['accuracy']\n    )","f3c88239":"# create a custom callback to visualize the training progress during every epoch\nclass CollectBatchStats(tf.keras.callbacks.Callback):\n  def __init__(self):\n    self.batch_losses = []\n    self.batch_acc = []\n    \n  def on_batch_end(self, batch, logs=None):\n    self.batch_losses.append(logs['loss'])\n    self.batch_acc.append(logs['acc'])\n    \n# Implementing early stopping to stop the training if the loss starts to increase and also avoid overvitting\nes = EarlyStopping(patience=2,monitor=\"val_loss\")","e74568c9":"# Calculate appropriate steps per epoch\nsteps_per_epoch = train_image_data.samples\/\/train_image_data.batch_size\nsteps_per_epoch","8cb9a001":"# Using CallBacks to record accuracy and loss\nbatch_stats = CollectBatchStats()\n# fit model\nmodel.fit((item for item in train_image_data), epochs = 3,\n         steps_per_epoch=1528,\n         callbacks = [batch_stats, es],validation_data=test_image_data)","52fcbb72":"# Visualize the results\nplt.figure()\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Training Steps\")\nplt.plot(batch_stats.batch_losses)\nplt.savefig(\"Model Loss\")\n\nplt.figure()\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Training Steps\")\nplt.plot(batch_stats.batch_acc)\nplt.show()","da446e50":"# Get the ordered list of labels\nlabel_names = sorted(train_image_data.class_indices.items(), key=lambda pair:pair[1])\nlabel_names = np.array([key.title() for key, value in label_names])\nlabel_names","84f787dc":"# Run predictions for the test patch\nresult_batch = model.predict(test_image_batch)\n\nlabels_batch = label_names[np.argmax(result_batch, axis=-1)]\nlabels_batch","97ffb575":"# Show predicted results\nplt.figure(figsize=(13,10))\nfor n in range(30):\n  plt.subplot(6,5,n+1)\n  plt.imshow(test_image_batch[n])\n  plt.title(labels_batch[n])\n  plt.axis('off')\n  plt.suptitle(\"Model predictions\")","a2baeec6":"# Save model for later \nmodel_path = tf.contrib.saved_model.save_keras_model(model, \".\/saved_models\")\nprint(model_path)\n","6e2a7966":"TensorFlow Hub also distributes models without the top classification layer, we wil be using\n\"feature_extractor\" for our transfer learning.","f2115fe4":"**Tensorflow is one of the top deep learning libraries by google. Originally I used Pytorch as my major \nbut recently I decided to explore tensorflow because it's abit smooth to deploy trained models to mobile.\nIt relies on Keras as its high level API. In this code walkthrough am going to use [TFHub](https:\/\/www.tensorflow.org\/tutorials\/images\/hub_with_keras) with tranfer learning to classify fruits.**\n\nI am going to use [Fruit dataset](https:\/\/www.kaggle.com\/moltean\/fruits).\n\n**Lets dive in **","e75e3919":"# *What next*\n\n**Pick an image dataset and try it out**\n\n# **Good Luck**","10fc9112":"**Be sure to commit your code to save outputs**","6ec05eb6":"# Training the model","3413c2cd":"# Cheking predictions","84f83c3c":"# Wow we achieving a very high accuracy"}}