{"cell_type":{"8c7d99fb":"code","d2cbeb21":"code","a5404497":"code","6fe9c9d7":"code","2abe2928":"code","e895544f":"code","f4b906ad":"code","76917713":"code","5804d706":"code","fe05adef":"code","c99be568":"code","49b10bab":"code","69b4c2f8":"code","f6256551":"code","deef6dae":"markdown","f62dbb8a":"markdown","1b6e2851":"markdown","2b648ac0":"markdown","cedaefbe":"markdown","d1df887c":"markdown"},"source":{"8c7d99fb":"import torch\nimport torchvision\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as functional\nimport torchvision.transforms as transforms\nfrom torch.utils.data import random_split\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import FashionMNIST\nimport torch.nn.functional as F \nimport pandas as pd\n","d2cbeb21":"#Hyperparameters\nbatch_size = 128\nlearning_rate = 0.001\n\n#Constants\ninput_size = 28*28\nnum_classes = 10","a5404497":"dataset = FashionMNIST(root = 'data\/', train = True, transform = transforms.ToTensor(), download = True)\ntest_ds = FashionMNIST(root = 'data\/', train = False, transform = transforms.ToTensor())\ntrain_ds , val_ds = random_split(dataset, [50000, 10000])\n","6fe9c9d7":"train_loader = DataLoader(train_ds, batch_size, shuffle = True)\nval_loader = DataLoader(val_ds, batch_size*2)\ntest_loader = DataLoader(test_ds, batch_size*2)","2abe2928":"class MnistModel(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.linear = nn.Linear(input_size, num_classes)\n\n  def forward(self, xb):\n    xb = xb.reshape(-1, 784)\n    out = self.linear(xb)\n    return out\n\n  def training_step(self, batch):\n    images, labels = batch\n    out = self(images)\n    loss = F.cross_entropy(out, labels)\n    return loss\n\n  def validation_step(self, batch):\n    images, labels = batch\n    out = self(images)\n    loss = F.cross_entropy(out, labels)\n    acc = accuracy(out, labels)\n    return {'val_loss': loss.detach(), 'val_acc': acc.detach()}\n\n  def validation_epoch_end(self, outputs):\n    batch_losses = [x['val_loss'] for x in outputs]\n    epoch_loss = torch.stack(batch_losses).mean()\n    batch_acc = [x['val_acc'] for x in outputs]\n    epoch_acc = torch.stack(batch_acc).mean()\n    return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\n  def epoch_end(self, epoch, result):\n    print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n\nmodel = MnistModel()","e895544f":"def accuracy(outputs, labels):\n  _, preds = torch.max(outputs, dim = 1)\n  return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","f4b906ad":"def evaluate(model, val_loader):\n  outputs = [model.validation_step(batch) for batch in val_loader]\n  return model.validation_epoch_end(outputs)","76917713":"def fit(epochs, lr, model, train_loader, val_loader, opt_fun = torch.optim.SGD):\n  history = []\n  optimizer = opt_fun(model.parameters(), lr)\n  for epoch in range(epochs):\n    #Training Phase\n    for batch in train_loader:\n      loss = model.training_step(batch)\n      loss.backward()\n      optimizer.step()\n      optimizer.zero_grad()\n    \n    # Validation Phase\n    result = evaluate(model, val_loader)\n    model.epoch_end(epoch, result)\n    history.append(result)\n\n  return history","5804d706":"evaluate(model, val_loader)","fe05adef":"history = fit(10, 0.0001, model, train_loader, val_loader)","c99be568":"accuracies = [r['val_acc'] for r in history]\nplt.plot(accuracies, '-x')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No of epochs');","49b10bab":"result = evaluate(model, test_loader)\nresult","69b4c2f8":"def predict_image(img, model):\n  xb = img.unsqueeze(0)\n  yb = model(xb)\n  _, preds = torch.max(yb, dim = 1)\n  return preds[0].item()","f6256551":"img, label = test_ds[5]\nplt.imshow(img[0], cmap = 'gray')\nprint('Label:', label,', predicted:', predict_image(img,model))","deef6dae":"# Step3:Create a Logistic Regression Model","f62dbb8a":"# Step4:Train The Model to Fit the Data","1b6e2851":"# Step1:Download and Explor Data","2b648ac0":"# Step5:Making predictions using the trained model","cedaefbe":"# Step2:Prepare The Data for Training","d1df887c":"# Dependencies "}}