{"cell_type":{"43862211":"code","4e9583b0":"code","fe1d9aa5":"code","be66e7dd":"code","f43c008c":"code","381d8854":"code","0c88245e":"code","898a68d0":"code","1421869b":"code","14aff63a":"code","a638590d":"code","efaff545":"code","2fbd2f58":"code","d7756bf5":"code","591c0141":"code","f4a9d142":"code","1c1e437f":"code","135b3a38":"code","f2015c8a":"code","8677ffa1":"code","8a2dc4a6":"code","6f11d31d":"code","5f8ec036":"code","a0fe50eb":"code","f9c10884":"code","351019d5":"code","3448e34b":"code","2ebb84d3":"code","6714e79c":"code","dda0a2ce":"code","31f330f9":"code","48e1d4ce":"code","2d588012":"code","9bbaa2fc":"code","d227dba3":"code","b411a295":"code","a4b01fca":"code","c934c517":"code","d94868cf":"code","35edd394":"code","bc1bfa2d":"code","e211de94":"code","7d69e734":"code","5650be31":"code","9eea9dd7":"code","ab31a052":"code","312dced8":"code","73ed1274":"code","1b366030":"code","17697f1c":"code","f71709ef":"code","e60ca805":"code","9e19d99c":"code","911ce0ac":"code","a1c2b6ff":"code","d4f78597":"code","529e9f65":"code","698938a5":"markdown","d495037e":"markdown","961463cb":"markdown","bd130210":"markdown","e6e487d9":"markdown","51382e2b":"markdown","a5c14cd5":"markdown","6d215d4a":"markdown","9116d3bf":"markdown","4b7c3fa5":"markdown","caf7aa20":"markdown","ef188a98":"markdown","062f8f1a":"markdown","8b43d5c0":"markdown","18efcbf2":"markdown","ba301cf5":"markdown","e9df3fe2":"markdown"},"source":{"43862211":"import numpy as np\nimport pandas as pd\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom scipy.stats import kurtosis\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\nfrom sklearn.metrics import mean_squared_error, r2_score","4e9583b0":"df=pd.read_csv(\"\/kaggle\/input\/automobile-dataset\/Automobile_data.csv\", na_values=['?', ' ?', '? '])","fe1d9aa5":"data=df.copy()","be66e7dd":"df.head()","f43c008c":"df.columns","381d8854":"df.shape","0c88245e":"df.info()","898a68d0":"print(f'Row numbers: {df.shape[0]}')\nprint(f'column numbers: {df.shape[1]}')\nprint(f'Missing values: {df.isnull().sum().sum()}')","1421869b":"# descriptive statistics\ndf.describe().T","14aff63a":"df.isnull().sum()","a638590d":"msno.bar(df)","efaff545":"total=df.isnull().sum().sort_values(ascending=False)\npercentage=((total\/df.shape[0])*100).sort_values(ascending=False)\nmissing_data=pd.concat([total, percentage], axis=1, keys=['total', 'percentage'])","2fbd2f58":"missing_data.head(10)","d7756bf5":"missing_columns=missing_data[missing_data['percentage']>0.05].index","591c0141":"print(missing_columns)","f4a9d142":"df.drop(\"normalized-losses\",axis=1,inplace=True)","1c1e437f":"df.drop(df[df['price'].isnull()].index,inplace=True)","135b3a38":"df.isnull().sum()","f2015c8a":"df['num-of-doors'].value_counts()","8677ffa1":"df['num-of-doors'].replace({'four':4, 'two':2}, inplace=True)","8a2dc4a6":"df['num-of-doors'].value_counts()","6f11d31d":"#filling missing value using fillna\ndf['num-of-doors'].fillna(df['num-of-doors'].mode()[0], inplace=True)\ndf['horsepower'].fillna(df['horsepower'].mean(), inplace=True)\ndf['bore'].fillna(df['bore'].mean(), inplace=True)\ndf['stroke'].fillna(df['stroke'].mean(), inplace=True)\ndf['peak-rpm'].fillna(df['peak-rpm'].mode()[0], inplace=True)","5f8ec036":"df.isnull().sum()","a0fe50eb":"for col in df.columns:\n    print(f'########################{col}######################')\n    print(df[col].value_counts())","f9c10884":"df['symboling'] = df['symboling'].astype('object')","351019d5":"df['num-of-doors']=df['symboling'].astype(int)","3448e34b":"df.corr()","2ebb84d3":"f, ax = plt.subplots(figsize= [20,15])\nsns.heatmap(df.corr(), annot=True, fmt=\".2f\", ax=ax, cmap = \"magma\" )\nax.set_title(\"Correlation Matrix\", fontsize=20)\nplt.show()","6714e79c":"#finding numeric column from data\nnum_cols=list(df._get_numeric_data().columns)\nprint(f\"Numeric variable numbers: {len(num_cols)}\")","dda0a2ce":"def hist_for_nums(df, num_cols):\n    for col in num_cols:\n        df[col].hist(bins=20)\n        plt.xlabel(col)\n        plt.title(col)\n        plt.show()","31f330f9":"hist_for_nums(df, num_cols)","48e1d4ce":"cat_cols=list(set(df.columns)-set(num_cols))\nprint(f\"Categoric variable numbers: {len(cat_cols)}\")","2d588012":"#count total value in every catgorical feature\nfor col in cat_cols:\n    print(f'##########{col}##########')\n    print(df[col].value_counts(normalize=True))","9bbaa2fc":"plt.figure(figsize=(8,6))\ndf['make'].value_counts().plot(kind='barh')\nplt.xlabel('Number of models')\nplt.ylabel('Companies')\nplt.title(\"Company model frequency diagram\")\nplt.show()","d227dba3":"for col in num_cols:\n    sns.boxplot(df[col])\n    plt.show()","b411a295":"def outliers(df, num_cols):\n    for col in num_cols:\n        Q1=df[col].quantile(0.05)\n        Q3=df[col].quantile(0.95)\n        IQR=Q3-Q1\n        lower_bound=Q1-1.5*IQR\n        upper_bound=Q3+1.5*IQR\n        df.loc[df[col]<lower_bound, col]=lower_bound\n        df.loc[df[col]>upper_bound, col]=upper_bound\n    return df","a4b01fca":"df=outliers(df, num_cols)","c934c517":"sns.distplot(df['price'])","d94868cf":"sns.distplot(df['price'], fit=norm)","35edd394":"print(\"Skewness coeff. is: %f\" % df['price'].skew())\nprint(\"Kurtosis coeff. is: %f\" % df['price'].kurt())","bc1bfa2d":"df['price']=np.log1p(df['price'])","e211de94":"sns.distplot(df['price'], fit=norm)","7d69e734":"skewed_feats = df[num_cols].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)","5650be31":"skewed_feats","9eea9dd7":"numerical=num_cols[:-1]\nscaler = MinMaxScaler()\ndf[numerical]=scaler.fit_transform(df[numerical])","ab31a052":"df=pd.get_dummies(df, drop_first=True)","312dced8":"df.head()","73ed1274":"X=df.drop('price', axis=1)\nY=df[['price']]","1b366030":"X","17697f1c":"def model(X, Y, algo, split_share=0.33):\n    X_train, X_test, Y_train, Y_test=train_test_split(X, Y, random_state=42, test_size=split_share)\n    m=algo().fit(X_train, Y_train)\n    train_rmse=np.sqrt(mean_squared_error(Y_train, m.predict(X_train)))\n    test_rmse=np.sqrt(mean_squared_error(Y_test, m.predict(X_test)))\n    return (type(algo()).__name__, train_rmse, test_rmse)","f71709ef":"models=[LinearRegression, Lasso, Ridge, ElasticNet]\nresults={'model':[], 'train_rmse':[], 'test_rmse':[]}\nfor algo in models:\n    res=model(X, Y, algo)\n    results['model'].append(res[0])\n    results['train_rmse'].append(res[1])\n    results['test_rmse'].append(round(res[2], 5))","e60ca805":"results=pd.DataFrame(results)\nresults","9e19d99c":"results.set_index('model').plot(kind='barh')","911ce0ac":"def model_tuning(X, Y, algo, algo_cv, grid, split_share=0.33, cv=10):\n    X_train, X_test, Y_train, Y_test=train_test_split(X, Y, random_state=42, test_size=split_share)\n    model_cv=algo_cv(alphas=grid, cv=cv)\n    model_cv.fit(X_train, Y_train)\n    model_tuned=algo(alpha=model_cv.alpha_)\n    model_tuned.fit(X_train, Y_train)\n    train_rmse=np.sqrt(mean_squared_error(Y_train, model_tuned.predict(X_train)))\n    test_rmse=np.sqrt(mean_squared_error(Y_test, model_tuned.predict(X_test)))\n    return (type(algo()).__name__, train_rmse, test_rmse) ","a1c2b6ff":"models={Ridge: RidgeCV, Lasso:LassoCV, ElasticNet:ElasticNetCV}\nresults_tuned={'model':[], 'train_rmse':[], 'test_rmse':[]}\nalphas = [0.1,0.01, 0.005, 0.05, 0.001,0.2,0.3,0.5,0.8,0.9]\nfor model in models:\n    res=model_tuning(X, Y, model, models[model], alphas)\n    results_tuned['model'].append(res[0])\n    results_tuned['train_rmse'].append(res[1])\n    results_tuned['test_rmse'].append(res[2])","d4f78597":"results_tuned=pd.DataFrame(results_tuned)\nresults_tuned","529e9f65":"results_tuned.set_index('model').plot(kind='barh')","698938a5":"# Encode categorical features","d495037e":"# Model tuning","961463cb":"# Correlation","bd130210":"# Dependent variable analysis","e6e487d9":"# Missing values","51382e2b":"# Variable Analysis","a5c14cd5":"# Categorical Variable Analysis","6d215d4a":"# Import libraries","9116d3bf":"# Spliting data for X and Y","4b7c3fa5":"# Independent variable analysis","caf7aa20":"# Numerical Variable Analysis","ef188a98":"# Model","062f8f1a":"# Scaling numerical values using Standard Scaler","8b43d5c0":"# Reading dataset","18efcbf2":"# Outliers","ba301cf5":"# Summary of Dataset","e9df3fe2":"# Exploratory Data Analysis"}}