{"cell_type":{"311908a9":"code","a3314bf7":"code","4489e285":"code","e83afc1e":"code","fae95122":"code","a3c34f28":"code","cef8f07d":"code","9231198b":"code","4218a104":"code","767705f7":"code","9caa4e75":"code","301acf0c":"code","09035d25":"code","67161bd5":"code","54eaf383":"code","3002f767":"code","846b6596":"code","6c998af3":"markdown","83782b89":"markdown","a93dc340":"markdown","90199fb1":"markdown","ebf17a9e":"markdown","a6e09eab":"markdown","cc2f4175":"markdown","86ced8fc":"markdown","3184a39b":"markdown","78d347ac":"markdown","dbae4b07":"markdown","2335fd24":"markdown","b1517842":"markdown","2268e6dd":"markdown","3a814b3e":"markdown","218d3001":"markdown","78ede10c":"markdown"},"source":{"311908a9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pickle\nimport matplotlib.pyplot as plt\nfrom math import sqrt, ceil\nfrom timeit import default_timer as timer\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir('..\/input'))\n\n# Any results we write to the current directory are saved as output\n","a3314bf7":"# Opening file for reading in binary mode\nwith open('..\/input\/traffic-signs-preprocessed\/data2.pickle', 'rb') as f:\n    data = pickle.load(f, encoding='latin1')  # dictionary type\n\n# Preparing y_train and y_validation for using in Keras\ndata['y_train'] = to_categorical(data['y_train'], num_classes=43)\ndata['y_validation'] = to_categorical(data['y_validation'], num_classes=43)\n\n# Making channels come at the end\ndata['x_train'] = data['x_train'].transpose(0, 2, 3, 1)\ndata['x_validation'] = data['x_validation'].transpose(0, 2, 3, 1)\ndata['x_test'] = data['x_test'].transpose(0, 2, 3, 1)\n\n# Showing loaded data from file\nfor i, j in data.items():\n    if i == 'labels':\n        print(i + ':', len(j))\n    else: \n        print(i + ':', j.shape)\n\n# x_train: (86989, 32, 32, 3)\n# y_train: (86989, 43)\n# x_test: (12630, 32, 32, 3)\n# y_test: (12630,)\n# x_validation: (4410, 32, 32, 3)\n# y_validation: (4410, 43)\n# labels: 43\n","4489e285":"%matplotlib inline\n\n# Preparing function for ploting set of examples\n# As input it will take 4D tensor and convert it to the grid\n# Values will be scaled to the range [0, 255]\ndef convert_to_grid(x_input):\n    N, H, W, C = x_input.shape\n    grid_size = int(ceil(sqrt(N)))\n    grid_height = H * grid_size + 1 * (grid_size - 1)\n    grid_width = W * grid_size + 1 * (grid_size - 1)\n    grid = np.zeros((grid_height, grid_width, C)) + 255\n    next_idx = 0\n    y0, y1 = 0, H\n    for y in range(grid_size):\n        x0, x1 = 0, W\n        for x in range(grid_size):\n            if next_idx < N:\n                img = x_input[next_idx]\n                low, high = np.min(img), np.max(img)\n                grid[y0:y1, x0:x1] = 255.0 * (img - low) \/ (high - low)\n                next_idx += 1\n            x0 += W + 1\n            x1 += W + 1\n        y0 += H + 1\n        y1 += H + 1\n\n    return grid\n\n\n# Visualizing some examples of training data\nexamples = data['x_train'][:81, :, :, :]\nprint(examples.shape)  # (81, 32, 32, 3)\n\n# Plotting some examples\nfig = plt.figure()\ngrid = convert_to_grid(examples)\nplt.imshow(grid.astype('uint8'), cmap='gray')\nplt.axis('off')\nplt.gcf().set_size_inches(15, 15)\nplt.title('Some examples of training data', fontsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('training_examples.png')\nplt.close()\n","e83afc1e":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(32, 32, 3)))\nmodel.add(MaxPool2D(pool_size=2))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(43, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","fae95122":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 10\n\nh = model.fit(data['x_train'][:100], data['y_train'][:100],\n              batch_size=5, epochs = epochs,\n              validation_data = (data['x_validation'], data['y_validation']),\n              callbacks=[annealer], verbose=1)\n","a3c34f28":"print('Epochs={0:d}, training accuracy={1:.5f}, validation accuracy={2:.5f}'.\\\n      format(epochs, max(h.history['acc']), max(h.history['val_acc'])))\n","cef8f07d":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 5.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['font.family'] = 'Times New Roman'\n\nfig = plt.figure()\nplt.plot(h.history['acc'], '-o', linewidth=3.0)\nplt.plot(h.history['val_acc'], '-o', linewidth=3.0)\n# plt.plot(h.history['val_loss'], '-o', linewidth=3.0)\nplt.title('Overfitting small data', fontsize=22)\nplt.legend(['train', 'validation'], loc='upper left', fontsize='xx-large') #'validation loss'\nplt.xlabel('Epoch', fontsize=20)\nplt.ylabel('Accuracy', fontsize=20)\nplt.tick_params(labelsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('overfitting_small_data.png')\nplt.close()\n","9231198b":"print('Epochs={0:d}, training accuracy={1:.5f}, validation accuracy={2:.5f}'.\\\n      format(epochs, max(h.history['acc']), max(h.history['val_acc'])))\n","4218a104":"filters = [3, 5, 9, 13, 15] #, 19, 23, 25, 31\nmodel = [0] * len(filters)\n\nfor i in range(len(model)):\n    model[i] = Sequential()\n    model[i].add(Conv2D(32, kernel_size=filters[i], padding='same', activation='relu', input_shape=(32, 32, 3)))\n    model[i].add(MaxPool2D(pool_size=2))\n    model[i].add(Flatten())\n    model[i].add(Dense(500, activation='relu'))\n    model[i].add(Dense(43, activation='softmax'))\n    model[i].compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","767705f7":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + epochs))\nepochs = 5\n\nh = [0] * len(model)\n\nfor i in range(len(h)):\n    h[i] = model[i].fit(data['x_train'][:10000], data['y_train'][:10000],\n                        batch_size=5, epochs = epochs,\n                        validation_data = (data['x_validation'], data['y_validation']),\n                        callbacks=[annealer], verbose=0)\n    \n    print('Model with filters {0:d}x{0:d}, epochs={1:d}, training accuracy={2:.5f}, validation accuracy={3:.5f}, validation loss={4:.5f}'.\\\n      format(filters[i], epochs, max(h[i].history['acc']), max(h[i].history['val_acc']), max(h[i].history['val_loss'])))\n","9caa4e75":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 15.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['font.family'] = 'Times New Roman'\n\n# Plotting history of training accuracy\nfig = plt.figure()\nplt.subplot(2, 2, 1)\n#plt.plot(h[8].history['acc'], '-o', linewidth=3.0)\n#plt.plot(h[7].history['acc'], '-s', linewidth=3.0)\n#plt.plot(h[6].history['acc'], '-D', linewidth=3.0)\n#plt.plot(h[5].history['acc'], '-D', linewidth=3.0)\nplt.plot(h[4].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[3].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[2].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[1].history['acc'], '-o', linewidth=3.0)\nplt.plot(h[0].history['acc'], '-o', linewidth=3.0)\nplt.legend(['filter 15', 'filter 13', 'filter 9', 'filter 5', 'filter 3'], loc='lower right', fontsize='xx-large', borderpad=2) #'filter 31', 'filter 25', 'filter 23', 'filter 19', \nplt.xlabel('Epoch', fontsize=20, fontname='Times New Roman')\nplt.ylabel('Training Accuracy', fontsize=20, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.85, 1.0)\nplt.xlim(0.5, 5.3) \nplt.title('Accuracy for different sizes of filters', fontsize=22)\nplt.tick_params(labelsize=18)\n\nplt.subplot(2, 2, 2)\n# plt.gca().set_title('Validation accuracy')\n#plt.plot(h[8].history['val_acc'], '-o', linewidth=3.0)\n#plt.plot(h[7].history['val_acc'], '-s', linewidth=3.0)\n#plt.plot(h[6].history['val_acc'], '-D', linewidth=3.0)\n#plt.plot(h[5].history['val_acc'], '-D', linewidth=3.0)\nplt.plot(h[4].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[3].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[2].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[1].history['val_acc'], '-o', linewidth=3.0)\nplt.plot(h[0].history['val_acc'], '-o', linewidth=3.0)\nplt.legend(['filter 15', 'filter 13', 'filter 9', 'filter 5', 'filter 3'], loc='lower right', fontsize='xx-large', borderpad=2) #'filter 31', 'filter 25', 'filter 23', 'filter 19', \nplt.xlabel('Epoch', fontsize=20, fontname='Times New Roman')\nplt.ylabel('Validation Accuracy', fontsize=20, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.75, 0.9)\nplt.xlim(0.5, 5.3)\nplt.tick_params(labelsize=18)\n\nplt.subplot(2, 2, 3)\n# plt.gca().set_title('Validation loss')\n#plt.plot(h[8].history['val_acc'], '-o', linewidth=3.0)\n#plt.plot(h[7].history['val_acc'], '-s', linewidth=3.0)\n#plt.plot(h[6].history['val_acc'], '-D', linewidth=3.0)\n#plt.plot(h[5].history['val_acc'], '-D', linewidth=3.0)\nplt.plot(h[4].history['val_loss'], '-o', linewidth=3.0)\nplt.plot(h[3].history['val_loss'], '-o', linewidth=3.0)\nplt.plot(h[2].history['val_loss'], '-o', linewidth=3.0)\nplt.plot(h[1].history['val_loss'], '-o', linewidth=3.0)\nplt.plot(h[0].history['val_loss'], '-o', linewidth=3.0)\nplt.legend(['filter 15', 'filter 13', 'filter 9', 'filter 5', 'filter 3'], loc='upper right', fontsize='xx-large', borderpad=2) #'filter 31', 'filter 25', 'filter 23', 'filter 19', \nplt.xlabel('Epoch', fontsize=20, fontname='Times New Roman')\nplt.ylabel('Validation Loss', fontsize=20, fontname='Times New Roman')\nplt.yscale('linear')  # {\"linear\", \"log\", \"symlog\", \"logit\", ...}\nplt.ylim(0.75, 1.7)\nplt.xlim(0.5, 5.3)\nplt.tick_params(labelsize=18)\n\n# Showing the plot\nplt.show()\n\n# Saving the plot\nfig.savefig('models_accuracy.png')\nplt.close()\n\n\n# Showing values of accuracy for different filters\nfor i in range(len(h)):\n    print('data2 filter {0:d} training accuracy = {1:.5f}'.\\\n          format(filters[i], np.max(h[i].history['acc'])))\n\nprint()\n\nfor i in range(len(h)):\n    print('data2 filter {0:d} validation accuracy = {1:.5f}'.\\\n          format(filters[i], np.max(h[i].history['val_acc'])))\n","301acf0c":"for i in range(len(model)):\n    temp = model[i].predict(data['x_test'])\n    temp = np.argmax(temp, axis=1)\n\n    # We compare predicted class with correct class for all input images\n    # And calculating mean value among all values of following numpy array\n    # By saying 'testing_accuracy == data['y_test']' we create numpy array with True and False values\n    # 'np.mean' function will return average of the array elements\n    # The average is taken over the flattened array by default\n    temp = np.mean(temp == data['y_test'])\n    \n    print('data2 filter {0:d} testing accuracy = {1:.5f}'.format(filters[i], temp))\n","09035d25":"# Getting scores from forward pass of one input image\n# Scores are given for each image with 43 numbers of predictions for each class\n# Measuring at the same time execution time\n\nfor i in range(len(model)):\n    start = timer()\n    temp = model[i].predict(data['x_test'][:1, :, :, :])\n    end = timer()\n    \n    print('data2 filter {0:d} classification time = {1:.5f}'.format(filters[i], end - start))\n","67161bd5":"for i in range(len(model)):\n    w = model[i].get_weights()\n    print(w[0].shape)\n    # print(model[i].get_config())\n    # l = model[i].layers\n    # print(l[0].get_weights()[0].shape)\n\n    # Visualizing filters\n    temp = w[0].transpose(3, 0, 1, 2)\n    print(temp.shape)  # (81, 32, 32, 3)\n\n    # Plotting\n    fig = plt.figure()\n    grid = convert_to_grid(temp)\n    plt.imshow(grid.astype('uint8'), cmap='gray')\n    plt.axis('off')\n    plt.gcf().set_size_inches(10, 10)\n    name = 'Trained filters ' + str(filters[i]) + 'x' + str(filters[i])\n    plt.title(name, fontsize=18)\n    \n    # Showing the plot\n    plt.show()\n\n    # Saving the plot\n    name = 'filters-' + str(filters[i]) + 'x' + str(filters[i]) + '.png'\n    fig.savefig(name)\n    plt.close()\n","54eaf383":"%matplotlib inline\n\n# Preparing image for predicting from test dataset\nparam = 25\n\nx_input = data['x_test'][param:(param+1)]\nprint(x_input.shape)\ny_input = data['y_test'][param:(param+1)]\nprint(y_input)\n\nplt.rcParams['figure.figsize'] = (2.5, 2.5) # Setting default size of plots\nplt.imshow(x_input[0, :, :, :])\nplt.axis('off')\n\n# Showing the plot\nplt.show()\n\n# Getting scores from forward pass of input image\nscores = model[0].predict(x_input)\nprint(scores[0].shape) # (43,)\n\n# Scores is given for image with 43 numbers of predictions for each class\n# Getting only one class with maximum value\nprediction = np.argmax(scores)\nprint('ClassId:', prediction)\n\n# Defining function for getting texts for every class - labels\ndef label_text(file):\n    # Defining list for saving label in order from 0 to 42\n    label_list = []\n    \n    # Reading 'csv' file and getting image's labels\n    r = pd.read_csv(file)\n    # Going through all names\n    for name in r['SignName']:\n        # Adding from every row second column with name of the label\n        label_list.append(name)\n    \n    # Returning resulted list with labels\n    return label_list\n\n\n# Getting labels\nlabels = label_text('..\/input\/traffic-signs-preprocessed\/label_names.csv')\n\n# Printing label for classified Traffic Sign\nprint('Label:', labels[prediction])\n","3002f767":"print(scores)","846b6596":"for i in range(len(model)):\n    name = 'model-' + str(filters[i]) + 'x' + str(filters[i]) + '.h5'\n    model[i].save(name)\n\n# # Saving model locally without committing\n# from IPython.display import FileLink\n\n# FileLink('model-3x3.h5')\n","6c998af3":"# Building set of models of CNN with Keras\n## Trying different models with different dimensions of filters","83782b89":"# Importing needed libraries","a93dc340":"# Saving models","90199fb1":"# Plotting history results for overfitting small data","ebf17a9e":"# Visualizing filters of convolutional layer","a6e09eab":"# Plotting comparison results for accuracy","cc2f4175":"# Trying small data","86ced8fc":"# Showing some examples","3184a39b":"## Related Paper\nSichkar V. N. Effect of various dimension convolutional layer filters on traffic sign classification accuracy. *Scientific and Technical Journal of Information Technologies, Mechanics and Optics*, 2019, vol. 19, no. 3, pp. DOI: 10.17586\/2226-1494-2019-19-3-546-552 (Full-text available on ResearchGate here: [Effect of various dimension convolutional layer filters on traffic sign classification accuracy](https:\/\/www.researchgate.net\/publication\/334074308_Effect_of_various_dimension_convolutional_layer_filters_on_traffic_sign_classification_accuracy))\n","78d347ac":"# Loading dataset data2.pickle with RGB examples","dbae4b07":"# Traffic Signs Classification with CNN","2335fd24":"# Predicting with one image from test dataset","b1517842":"# Calculating accuracy with testing dataset","2268e6dd":"# Time for classification","3a814b3e":"Sprawdzanie modelu z bardzo ma\u0142\u0105 ilo\u015bci\u0105 ucz\u0105cych danych","218d3001":"# Building model of CNN with Keras\n## Trying one model with filters of size 3x3","78ede10c":"# Training set of models of CNN with Keras\n## And with different dimensions of filters"}}