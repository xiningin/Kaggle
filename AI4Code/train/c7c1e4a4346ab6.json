{"cell_type":{"fb03ff4a":"code","050f79fc":"code","14ee5cda":"code","68347b37":"code","7e48a981":"code","5eb3aaa9":"code","54d56043":"code","d21538e6":"code","e92e337f":"code","25903d60":"code","4d29b2db":"code","42a12b49":"code","2aa556e6":"code","872554de":"code","6cb158a7":"code","b88e9306":"code","6d47f316":"code","7067e274":"code","485c048d":"code","75714dfc":"code","7c59de2e":"code","65b60396":"code","5f9daecd":"code","04256a8d":"code","3b696731":"code","2a7237fb":"code","0203fdf0":"code","2f9af6a6":"markdown","7accd349":"markdown","04b6c2ae":"markdown","29ff129e":"markdown","cd54bc9b":"markdown","ca3af977":"markdown","c59f3363":"markdown","8ff66d17":"markdown"},"source":{"fb03ff4a":"import os\nimport PIL\nimport numpy as np\nimport pandas as pd","050f79fc":"df_train = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/train.csv\")\ndf_train.head()","14ee5cda":"df_train[df_train['annotations'] != \"[]\"].head()","68347b37":"# Cast annotations to list of dictionaries\ndf_train['annotations'] = df_train['annotations'].apply(eval)\ndf_train[df_train['annotations'].str.len() > 1].iloc[0]['annotations']","7e48a981":"df_train['n_objects'] = df_train['annotations'].str.len()\ndf_train.value_counts(\"n_objects\").plot.bar(figsize=(10, 5), alpha=0.5, rot=0, title=\"# images per number of objects in them\");","5eb3aaa9":"(df_train['n_objects'] == 0).value_counts(normalize=True).rename({True: \"No objects\", False: \"At least one object\"})\\\n                            .plot.bar(figsize=(10, 5), alpha=0.5, rot=0, title=\"Has objects?\");","54d56043":"df_test = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/test.csv\")\ndf_test.head()","d21538e6":"!ls -l ..\/input\/tensorflow-great-barrier-reef\/train_images\/","e92e337f":"imgs_0 = os.listdir(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_0\")\nimgs_1 = os.listdir(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_1\")\nimgs_2 = os.listdir(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/video_2\")","25903d60":"len(imgs_0)","4d29b2db":"len(imgs_1)","42a12b49":"len(imgs_2)","2aa556e6":"len(df_train)","872554de":"\nlen(imgs_0) + len(imgs_1) + len(imgs_2)","6cb158a7":"imgs_0[0]","b88e9306":"df_train['image_path'] = \"video_\" + df_train['video_id'].astype(str) + \"\/\" + df_train['video_frame'].astype(str) + \".jpg\"\ndf_train.head()","6d47f316":"df_train['image_path'].apply(lambda f_name: os.path.isfile(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/\"+ f_name)).all()","7067e274":"def show_image(df_train, idx):\n    f_name = df_train.iloc[idx]['image_path']\n    return PIL.Image.open(\"..\/input\/tensorflow-great-barrier-reef\/train_images\/\"+f_name)","485c048d":"show_image(df_train, 0).resize((400, 256))","75714dfc":"show_image(df_train, 16000).resize((400, 256))","7c59de2e":"pixels = np.load(\"..\/input\/tensorflow-great-barrier-reef\/example_test.npy\")","65b60396":"pixels.shape","5f9daecd":"PIL.Image.fromarray(pixels[0, :]).resize((400, 256))","04256a8d":"PIL.Image.fromarray(pixels[2, :]).resize((400, 256))","3b696731":"df_sub = pd.read_csv(\"..\/input\/tensorflow-great-barrier-reef\/example_sample_submission.csv\")\ndf_sub.head()","2a7237fb":"import greatbarrierreef\nenv = greatbarrierreef.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission","0203fdf0":"for (pixel_array, df_pred) in iter_test:  # iterate through all test set images\n    print(f\"Pixels shape: {pixel_array.shape}\")\n    print(f\"df_pred shape: {df_pred.shape}\")\n    \n    img = PIL.Image.fromarray(pixel_array).resize((400, 256))\n    display(img)\n    \n    display(df_pred.head())\n    df_pred['annotations'] = '0.5 123 456 10 10'  # make your predictions here\n    env.predict(df_pred)   # register your predictions","2f9af6a6":"# Imports","7accd349":"# There is one row per image. Only 3 videos for training.","04b6c2ae":"# Check `df_train` vs `train_images` folder","29ff129e":"# Check the submission API\n\n## See: [Great Barrier Reef API Tutorial](https:\/\/www.kaggle.com\/sohier\/great-barrier-reef-api-tutorial)","cd54bc9b":"# \ud83d\udc20 Coral Reef - Minimalistic EDA\n\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/31703\/logos\/header.png)\n\n## Hello! This is just a functional check for some simple conditions in the input data and the submission API.\n\n# Please, _DO_ upvote if you found it useful!!","ca3af977":"# Please, _DO_ upvote if you found it useful!!","c59f3363":"# Check the npy file","8ff66d17":"# Most images have no objects in them"}}