{"cell_type":{"19dec1a3":"code","bb40d052":"code","80d27012":"code","359605a2":"code","92bb47be":"code","53f721b2":"code","182e126e":"code","e2e050a9":"code","67530407":"code","ed2d39bb":"code","3d54f318":"code","b399be8a":"code","9fd8bc12":"code","f6cc5779":"code","fb84689b":"code","fd1f7a02":"code","4f5af10b":"markdown","b937914d":"markdown","24f356ba":"markdown","7898168b":"markdown","a7ac165e":"markdown","74cd16b1":"markdown","37caebda":"markdown","4fd7500e":"markdown","ed35a5b3":"markdown"},"source":{"19dec1a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bb40d052":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport sqlite3\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n","80d27012":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\npath = \"..\/input\/\"  #Insert path here\ndatabase = path + 'Chinook_Sqlite.sqlite'","359605a2":"## creating a connection\nconn = sqlite3.connect(database)\n\n## importing tables \ntables = pd.read_sql(\"\"\"SELECT *\n                        FROM sqlite_master\n                        WHERE type='table';\"\"\", conn)\n\ntables","92bb47be":"## Getting the primary key of the album table\n\nalbum_primary_keys= pd.read_sql(\"\"\"PRAGMA table_info(album);\"\"\",conn)\nalbum_primary_keys\n\n## so primary keys are albumid","53f721b2":"## Extracting the album table\nalbum = pd.read_sql(\"\"\"SELECT *\n                        FROM album\n                        ;\"\"\", conn)\nalbum","182e126e":"# number of rows in album column\n\ncount_rows= pd.read_sql(\"\"\"SELECT COUNT(*)FROM album;\"\"\",conn)\ncount_rows","e2e050a9":"# Unique album\n\nunique_ablum= pd.read_sql(\"\"\"SELECT DISTINCT(Title) FROM album;\"\"\",conn)\nunique_ablum","67530407":"## checking null value is there or not\n\nnull_check_album= pd.read_sql(\"\"\" SELECT * FROM album WHERE title IS NULL;\"\"\",conn )\nnull_check_album","ed2d39bb":"## checking longest name of album\n\nlongest_name_album= pd.read_sql(\"\"\"SELECT title,max(LENGTH(title)) FROM album;\"\"\",conn)\nlongest_name_album","3d54f318":"## order by alphabetical order of title of album\n\norder_title_desc_alphabetical= pd.read_sql(\"\"\"SELECT AlbumId,title,length(title),ArtistId from album order by title desc;\"\"\",conn)\norder_title_desc_alphabetical\n","b399be8a":"## info about the three tables\n\nalbum_info= pd.read_sql(\"\"\"PRAGMA table_info(album);\"\"\",conn)\nprint('album: ',album_info)\n\nprint('\\n')\nartist_info= pd.read_sql(\"\"\"PRAGMA table_info(artist);\"\"\",conn)\nprint('artist: ',artist_info)\n\nprint('\\n')\ngenre_info= pd.read_sql(\"\"\"PRAGMA table_info(genre);\"\"\",conn)\nprint('genre: ',genre_info)\n\n\nprint('\\n')\ncustomer_info= pd.read_sql(\"\"\"PRAGMA table_info(customer);\"\"\",conn)\nprint('customer: ',customer_info)\n\nprint(\"\\n\")\n\nemployee_info= pd.read_sql(\"\"\"PRAGMA table_info(employee);\"\"\",conn)\nprint('employee:',employee_info)\n\nprint(\"\\n\")\ninvoice_info= pd.read_sql(\"\"\"PRAGMA table_info(Invoice);\"\"\",conn)\nprint('invoice:',invoice_info)\n","9fd8bc12":"## join album and artist as both have common column albumid for join\n\nartist_album_join=pd.read_sql(\"\"\"SELECT album.AlbumId,NAME,album.Title FROM ARTIST  JOIN ALBUM ON ALBUM.ARTISTID= ARTIST.ARTISTID;\"\"\",conn)\nartist_album_join","f6cc5779":"## join customer and invoice as both have common column customerid for join\n\ncustomer_invoice_join=pd.read_sql(\"\"\"SELECT customer.customerid,InvoiceDate,Total  FROM invoice  JOIN customer ON customer.customerid= invoice.customerid;\"\"\",conn)\ncustomer_invoice_join.info()","fb84689b":"## change invoice date to datetime object\n\ncustomer_invoice_join['InvoiceDate']=pd.to_datetime(customer_invoice_join['InvoiceDate'])\n\n\n## Timeseries plot\n\nsns.lineplot(x='InvoiceDate',y='Total',data=customer_invoice_join)\n\nplt.show()","fd1f7a02":"## data distribution of total\n\nsns.distplot(customer_invoice_join['Total'], kde=False, color='red', bins=10)\nplt.show()","4f5af10b":"# Connection setup\n\nCreating an connection between sqllite and python script for extraction of datasets.","b937914d":"# -------------------------------------------\n\noperations on album table","24f356ba":"# Data Model\n\nThe Chinook data model represents a digital media store, including tables for artists, albums, media tracks, invoices and customers.","7898168b":"# Join the 3 tables ablum,artist,genre,customer \n\nThe purpose of creating such table is to get insights out of data , how many albums are being and who were the artist and their genre to understand\nthe type of customer and recommending him future with the type of music he\/she likes.","a7ac165e":"# Select the Album Table\n","74cd16b1":"# Data source description\n\nMedia related data was created using real data from an iTunes Library. It is possible for you to use your own iTunes Library to generate the SQL scripts, see instructions below. Customer and employee information was manually created using fictitious names, addresses that can be located on Google maps, and other well formatted data (phone, fax, email, etc.). Sales information is auto generated using random data for a four year period.","37caebda":"# Importing database into kaggle","4fd7500e":"# Importing libraries\n","ed35a5b3":"# Purpose of SQL\n\nAs a data scientist we often use databases as source of extracting data. And sql is the common tool use of this purpose. But to incorporate the power of sql with help of python is immense. This notebook is just a representation of that power using chinook database"}}