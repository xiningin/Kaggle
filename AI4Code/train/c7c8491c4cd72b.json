{"cell_type":{"d4a4157a":"code","2cf83652":"code","6205f9ce":"code","b973382f":"code","a1e97263":"code","94a66400":"code","b89eeace":"code","d2e95179":"code","4cc7cf98":"code","870f6e64":"code","6f36513c":"code","4018498d":"code","4337a1b0":"code","d93532b9":"code","015aa288":"code","61cbabe5":"code","d8d6e9e5":"code","96ce4687":"code","0c1ea57a":"markdown","0355085c":"markdown","be7099cc":"markdown"},"source":{"d4a4157a":"import numpy as np\nimport pandas as pd\nimport h5py\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport tensorflow as tf","2cf83652":"h5data = h5py.File('\/kaggle\/input\/street-view-house-nos-h5-file\/SVHN_single_grey1.h5' )\nh5data.keys()","6205f9ce":"x_train = h5data['X_train']\nx_val = h5data['X_val']\nx_test = h5data['X_test']\ny_train = h5data['y_train']\ny_val = h5data['y_val']\ny_test = h5data['y_test']","b973382f":"print('train size -->', x_train.shape[0])\nprint('val size -->', x_val.shape[0])\nprint('test size -->', x_test.shape[0])","a1e97263":"fig=plt.figure(figsize=(10,10))\ncolumns=10\nrows=10\nfor i in range(1, columns*rows+1):\n    img=x_train[i]\n    fig.add_subplot(rows,columns,i)\n    plt.imshow(img,cmap='gray')\nplt.show()","94a66400":"plt.imshow(x_train[10],cmap='gray')    \nplt.show()\nprint('Label: ', y_train[10])","b89eeace":"plt.figure(figsize=(10, 1))\nfor i in range(10):\n    plt.subplot(1, 10, i+1)\n    plt.imshow(x_train[i].reshape(32,32),cmap='gray')\n    plt.axis('off')\nplt.show()\nprint('Image label: %s' % (y_train[0:10]))","d2e95179":"x_train = np.asarray(x_train).reshape(42000,1024)\nx_test = np.asarray(x_test).reshape(18000,1024)\nx_val = np.asarray(x_val).reshape(60000,1024)","4cc7cf98":"y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\ny_val = tf.keras.utils.to_categorical(y_val, num_classes=10)","870f6e64":"print('train size -->', x_train.shape)\nprint('val size -->', x_val.shape)\nprint('test size -->', x_test.shape)\n","6f36513c":"def create_nn():\n    model_input = tf.keras.layers.Input(x_train.shape[1], name='parameters_input')\n    x = tf.keras.layers.Dense( 50, kernel_initializer='he_normal',activation= 'relu')(model_input)\n    x = tf.keras.layers.Dense( 30, activation= 'relu')(x)\n    x = tf.keras.layers.Dense( 15, activation= 'relu')(x) \n    model_output = tf.keras.layers.Dense( 10, activation= 'softmax', name='digits')(x)\n    model = tf.keras.Model( model_input, model_output)\n    \n    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics = ['accuracy'])\n    return model","4018498d":"model = create_nn()\nhistory = model.fit(x_train, y_train, validation_data=(x_val,y_val),batch_size = 50, epochs = 50, verbose = 1)","4337a1b0":"result = model.evaluate(x_test, y_test)\nprint('Val_acc using sgd : ', result[1])\nout_df = pd.DataFrame({'model': ['NN with sgd'], 'score': [result[1] ] })\nout_df","d93532b9":"plt.plot(history.history[ 'accuracy'])\nplt.plot(history.history[ 'val_accuracy'])\nplt.title( 'train vs val accuracy')\nplt.xlabel('epocs')\nplt.ylabel('accuracy')\nplt.legend( ['train', 'val'])\nplt.show()","015aa288":"def create_nn2():\n    model_input = tf.keras.layers.Input(x_train.shape[1], name='parameters_input')\n    x = tf.keras.layers.Dense( 1024, kernel_initializer='he_normal',activation= 'relu')(model_input)\n    x = tf.keras.layers.Dropout(0.2)(x)\n\n    x = tf.keras.layers.Dense( 512, activation= 'relu')(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n\n    x = tf.keras.layers.Dense( 256, activation= 'relu')(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n\n    x = tf.keras.layers.Dense( 128, activation= 'relu')(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    \n    x = tf.keras.layers.Dense( 64, activation= 'relu')(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    \n    model_output = tf.keras.layers.Dense( 10, activation= 'softmax', name='digits')(x)\n    model = tf.keras.Model( model_input, model_output)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n    return model","61cbabe5":"model = create_nn2()\nhistory = model.fit(x_train, y_train, validation_data=(x_val,y_val),batch_size = 50, epochs = 50, verbose = 1)","d8d6e9e5":"plt.plot(history.history[ 'accuracy'])\nplt.plot(history.history[ 'val_accuracy'])\nplt.title( 'train vs val accuracy')\nplt.xlabel('epocs')\nplt.ylabel('accuracy')\nplt.legend( ['train', 'val'])\nplt.show()","96ce4687":"result = model.evaluate(x_test, y_test)\nprint('Val_acc using Dropout adam : ', result[1])\nout = pd.DataFrame({'model': ['NN with adam'], 'score': [result[1] ] })\npd.concat( [out_df, out] )","0c1ea57a":"- increasing number of neurons from dense layers\n- adding dropout layer","0355085c":"### optimizing","be7099cc":"# Build Model"}}