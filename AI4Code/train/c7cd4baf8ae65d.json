{"cell_type":{"d4415752":"code","c642d756":"code","d1c8c1e8":"code","22507fae":"code","391601a0":"code","758e367c":"code","3cb16cc5":"code","a20b29a3":"code","d8d4a84e":"code","318fcec5":"code","28d8ff34":"code","4dae85ff":"code","e44693ab":"code","e767e5b3":"code","c7f10fe3":"code","94c25b2d":"code","ea6fe5b2":"code","5a095625":"code","3ad5a6be":"code","c4f45ddb":"code","ac8e62d6":"code","3f5699f7":"code","2b34975f":"code","68da6531":"code","57ad41cf":"code","3f962eb4":"code","127f4bb7":"code","8db2240a":"code","394da402":"code","9b138069":"code","5322187c":"code","765be46b":"code","ffa04e87":"code","337fcdf2":"code","a8912e42":"code","7e963e5b":"code","cf6c0579":"code","123c397c":"code","4710b83c":"code","9b7b1164":"code","9d53eec3":"code","c056b4a9":"code","2b8a78dc":"code","21b1557d":"code","1b74dfd7":"code","4d825220":"code","c70c2fb1":"code","79823371":"code","c01d4d3e":"code","f269d158":"code","016c1c6c":"code","98ef6fb3":"code","4b974855":"code","9d838391":"code","b3121017":"markdown","6bb7dbab":"markdown","1c41da8c":"markdown","ce46e450":"markdown","f7e4d80c":"markdown","e7497f72":"markdown","4c0bc4d5":"markdown","57aa3066":"markdown","2972427c":"markdown","654c5073":"markdown","5a5d0dcc":"markdown","39656737":"markdown","34124170":"markdown","833669df":"markdown","5b67e227":"markdown","2527409d":"markdown","eebf1728":"markdown","7b676b1a":"markdown","d3ed21f5":"markdown","5916b03c":"markdown","ca3cb25f":"markdown","1ce26c39":"markdown","1147f7e9":"markdown","67c7af4c":"markdown","75218c65":"markdown","b81924a1":"markdown","6153a2cc":"markdown","e5d35ea8":"markdown","cb538eb3":"markdown","445916f1":"markdown","0deb4195":"markdown","83ff8997":"markdown","72d2dc0f":"markdown","ab008c97":"markdown","14af2e0f":"markdown","3e8ee649":"markdown","6940bdf5":"markdown","62005943":"markdown","01c21b70":"markdown","bedfe6a9":"markdown","c6e7fd4b":"markdown","b9b20a03":"markdown","b4b561da":"markdown","fc85c74c":"markdown","b2f5df57":"markdown","0b1cef86":"markdown","48463acc":"markdown","26baaad4":"markdown","6cce71b7":"markdown","72b85c58":"markdown","a29d05e4":"markdown","12f04220":"markdown","4a844c89":"markdown","5df6389a":"markdown","d8bd5d76":"markdown","08a0c8e8":"markdown","c8620137":"markdown","b4fe3a8b":"markdown","650ad9a8":"markdown","c63c1951":"markdown","f99d1c0d":"markdown","5d19b7f2":"markdown","b36b9b47":"markdown","6c3c61e7":"markdown","e55de2f6":"markdown","4b04b000":"markdown"},"source":{"d4415752":"# Use this cell to set up import statements for all of the packages that youplan to use.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport requests \nimport os\n\n%matplotlib inline\nsns.set() # to set graph style to seaborn style","c642d756":"# Load your data \nfile_name ='\/kaggle\/input\/tmdb-movies-dataset\/tmdb-movies.csv'\ndf = pd.read_csv(file_name)\n\nprint(\"the data set has {} row af data and {} column of data \".format(df.shape[0] , df.shape[1]))","d1c8c1e8":"df.head()","22507fae":"## check for data type  \ndf.info()","391601a0":"#check null values\ndf.isnull().sum() [df.isnull().sum() != 0]","758e367c":"#check duplicated raw \nprint(\"there is {} duplicate raw so i will delet it\".format(df.duplicated().sum()))","3cb16cc5":"# check valid data \ndf[df.columns.tolist()[1:]].describe( )","a20b29a3":"## make a copy for cleaning \n\ndf_clean = df.copy()","d8d4a84e":"#check befor deleting \ndf_clean.columns","318fcec5":"df_clean.drop([ 'id' , 'imdb_id' , 'homepage' , 'overview' , 'tagline' ] , axis=1 , inplace = True )","28d8ff34":"# check after deleting \ndf_clean.columns","4dae85ff":"# check the type befor converting \ndf_clean['release_date'].dtype","e44693ab":"df_clean['release_date']= pd.to_datetime(df_clean['release_date'])","e767e5b3":"# check the type after converting \ndf_clean['release_date'].dtype","c7f10fe3":"# count the dupliated befor deleting them \ndf_clean.duplicated().sum()","94c25b2d":"df_clean.drop_duplicates(inplace = True)","ea6fe5b2":"# count the dupliated after deleting them \ndf_clean.duplicated().sum()","5a095625":"# count any movie with budget less then 1000 dolars\ndf_clean[df_clean['budget'] < 1000 ].count()[0]","3ad5a6be":"# count any movie with revenue less then 100 dolars\ndf_clean[df_clean['revenue'] < 500 ].count()[0]","c4f45ddb":"# count any movie with time 0 minutes \ndf_clean[df_clean['runtime'] == 0 ].count()[0]","ac8e62d6":"# count any movie with time more than 5 hours  \ndf_clean[df_clean['runtime'] > 300 ].count()[0]","3f5699f7":"df_clean = df_clean[df_clean['budget'] > 1000]\ndf_clean = df_clean[df_clean['revenue'] > 500]\ndf_clean = df_clean[df_clean['runtime'] != 0]\ndf_clean = df_clean[df_clean['runtime'] < 300]","2b34975f":"df_clean[df_clean['budget'] < 1000 ].count()[0]","68da6531":"df_clean[df_clean['revenue'] < 500 ].count()[0]","57ad41cf":"df_clean[df_clean['runtime'] == 0 ].count()[0]","3f962eb4":"df_clean[df_clean['runtime'] > 300 ].count()[0]","127f4bb7":"df_clean[\"gain\"] = df_clean['revenue'] \/ df_clean['budget']\ndf_clean = df_clean[df_clean['gain'] < 100] # removing outlayers\n","8db2240a":"df_clean['release_month'] = df_clean['release_date'].dt.month\ndf_clean.drop('release_date' , inplace=True , axis=1)","394da402":"#main hero  represent the first person in cast\ndf_clean['main_hero'] = df_clean.cast.str.split(\"|\" , expand =True).iloc[:,:1]\n\n#get the first onr genres only\ndf_clean[['genere1']] = df_clean.genres.str.split(\"|\",expand=True).iloc[:,:1]\n\n#get the first two gemres only\ndf_clean[['company1']] = df_clean.production_companies.str.split(\"|\",expand=True).iloc[:,:1]\n        \n\ndf_clean.drop( ['production_companies' , 'cast' , 'keywords' , 'genres' , 'production_companies' ], inplace=True , axis=1)\n","9b138069":"df_clean.head()","5322187c":"print ( \"the cleaned data shape is \" , df_clean.shape )\n\ndf_clean.to_csv( \"cleaned_data\" , index = 0)\n\ndf_clean.head(1)","765be46b":"year_count = df_clean['release_year'].value_counts().sort_index()\n\nplt.bar(year_count.index , year_count.values) \nplt.title(\"count of movies across diffrent years \")\nplt.xlabel('years')\nplt.ylabel('number of movies')\n\nprint(\"the year with the muximum number of movies is \" , df_clean['release_year'].mode()[0] )\nprint(\"the year with the minimum number of movies is \" , df_clean['release_year'].value_counts().sort_values().index.tolist()[0] )","ffa04e87":"rev_sum = df_clean.groupby('release_year').sum()['revenue_adj']\n\nfig, (ax1, ax2 ) = plt.subplots(1, 2 , figsize=(15,7) )\n                              \nax1.plot(rev_sum.index , rev_sum.values ) ; \nax1.set_title(\" years vs total adjustable revenue \")\nax1.set_xlabel('year')\nax1.set_ylabel('total revenue')\n\nrev_sum = df_clean.groupby('release_year').median()['gain']\nax2.plot(rev_sum.index , rev_sum , label= 'gain = revenue \/ budget') ; \nax2.set_title(\" years vs total gain \");\nax2.set_xlabel('year');\nax2.set_ylabel('gain');\nax2.legend()\n\nprint('high gain was in ', rev_sum.sort_values().index[-1] )","337fcdf2":"rev_sum = df_clean.groupby('release_month').sum()['revenue_adj']\n\nfig, (ax1, ax2 ) = plt.subplots(1, 2 , figsize=(15,7) )\n\nax1.plot(rev_sum.index , rev_sum) ; \nax1.set_title(\" months vs total adjustable revenue \")\nax1.set_xlabel('month')\nax1.set_ylabel('total revenue')\n\nrev_sum = df_clean.groupby('release_month').median()['gain']\nax2.plot(rev_sum.index , rev_sum , label= 'gain = revenue \/ budget') ; \nax2.set_title(\" month vs total gain \");\nax2.set_xlabel('month');\nax2.set_ylabel('gain');\n\nprint('high gain was in ', rev_sum.sort_values().index[-1] )\nprint('low gain was in ', rev_sum.sort_values().index[0] )","a8912e42":"month_count = df_clean['release_month'].value_counts().sort_index()\n\nplt.bar(month_count.index , month_count.values) \nplt.title(\"count of movies across diffrent months \")\nplt.xlabel('month')\nplt.ylabel('number of movies')\n\nprint(\"the month with the muximum number of movies is \" , df_clean['release_month'].mode()[0] )\nprint(\"the month with the minimum number of movies is \" , df_clean['release_month'].value_counts().sort_values().index.tolist()[0] )","7e963e5b":"votes_year = df_clean.groupby('release_year').median()[['vote_average' , 'vote_count']]\n\nfig, (ax1, ax2 ) = plt.subplots(1, 2 , figsize=(10,5) )\n\nax1.plot( votes_year.index , votes_year['vote_average'] , 'ro')\nax1.set_title('votes average vs years')\nax2.plot( votes_year.index , votes_year['vote_count'],'o')\nax2.set_title('votes counts vs years')\n","cf6c0579":"plt.hist(df_clean['runtime'] , bins=20)\nplt.title('run time_distriburtion')\ndf_clean['runtime'].mean() , df_clean['runtime'].median()","123c397c":"print(\"best_movies\")\nprint( 'the higher revenue is--> ',df_clean[df_clean.revenue_adj == df_clean.revenue_adj.max() ]['original_title'].values[0])\nprint('the higher vote is -->  ',df_clean[df_clean.vote_average == df_clean.vote_average.max() ]['original_title'].values[0])\nprint( 'the is higher profit --> ' ,df_clean[ (df_clean.revenue_adj-df_clean.budget_adj) == (df_clean.revenue_adj-df_clean.budget_adj).max() ]['original_title'].values[0])\nprint('the higher gain is --> ' , df_clean[df_clean.gain == df_clean.gain.max() ]['original_title'].values[0])\n","4710b83c":"print('the Worst movies ')\n# \nprint('the lower revenue is --> ' ,df_clean[df_clean.revenue_adj == df_clean.revenue_adj.min() ]['original_title'].values[0])\nprint( 'the lower vote is ' , df_clean[df_clean.vote_average == df_clean.vote_average.min() ]['original_title'].values[0])\nprint( 'the lower profit is --> ' , df_clean[ (df_clean.revenue_adj-df_clean.budget_adj) == (df_clean.revenue_adj-df_clean.budget_adj).min() ]['original_title'].values[0])\nprint( 'the lower gain is --> ' , df_clean[df_clean.gain == df_clean.gain.min() ]['original_title'].values[0])","9b7b1164":"dir_names = df_clean['director'].value_counts()[df_clean['director'].value_counts() > 15 ]\n\nplt.xticks(rotation='vertical')\nplt.bar( dir_names.index ,  dir_names.values , color='rgbkymc'    )\n\nplt.title('common direcrors with number of their movies')\n\ndir_names","9d53eec3":"df_clean['company1'].value_counts()[df_clean['company1'].value_counts() > 50 ]","c056b4a9":"df_clean.groupby('director').median().loc[dir_names.index.tolist()][['budget_adj' , 'revenue_adj' , 'gain' , 'vote_average' ]].sort_values('revenue_adj', ascending=False)","2b8a78dc":"actor_names = df_clean['main_hero'].value_counts()[df_clean['main_hero'].value_counts() > 20 ]\n\nplt.xticks(rotation='vertical')\nplt.bar( actor_names.index ,  actor_names.values  ) ;\n\nplt.title('common actors with number of their movies');\n\n\ndf_clean.groupby('main_hero').mean().loc[actor_names.index.tolist()][['budget_adj' , 'revenue_adj' , 'gain' , 'vote_average' ]].sort_values('gain', ascending=False)","21b1557d":"df_clean.groupby(['main_hero' , 'director']).count()['popularity'][df_clean.groupby(['main_hero' , 'director']).count()['popularity']>5]","1b74dfd7":"data = df_clean.groupby(['main_hero' , 'release_month']).count()['popularity'][df_clean.groupby(['main_hero' , 'release_month']).count()['popularity']>5]\ndata.unstack().plot(kind='bar', stacked=True  , figsize=(20,6));\nplt.show()","4d825220":"df_clean.groupby([ 'company1' , 'main_hero' , 'director']).count()['popularity'][df_clean.groupby([ 'company1' , 'main_hero' , 'director']).count()['popularity']>3]","c70c2fb1":"data = df_clean.groupby(['release_year' , 'genere1']).count()['popularity'][df_clean.groupby(['release_year' , 'genere1']).count()['popularity']>30]\ndata.unstack().plot(kind='bar', stacked=True  , figsize=(20,6));\n","79823371":"data = df_clean['genere1'].value_counts()[df_clean['genere1'].value_counts() > 50 ]\nplt.pie( data.values , labels = data.index ,startangle =0 , radius=2 );","c01d4d3e":"data = df_clean.groupby(['genere1']).median()\nprint(\"best_generes\")\nprint( 'the higher revenue is--> ',data[data.revenue_adj == data.revenue_adj.max()].index[0] ) \nprint('the higher vote is -->  ',data[data.vote_average == data.vote_average.max() ].index[0])\nprint( 'the is higher profit --> ' ,data[ (data.revenue_adj-data.budget_adj) == (data.revenue_adj-data.budget_adj).max() ].index[0])\nprint('the higher gain is --> ' , data[data.gain == data.gain.max() ].index[0])","f269d158":"data = df_clean.groupby(['genere1']).median()\nprint(\"worest_movies\")\nprint( 'the lower revenue is--> ',data[data.revenue_adj == data.revenue_adj.min()].index[0] ) \nprint('the lower vote is -->  ',data[data.vote_average == data.vote_average.min() ].index[0])\nprint( 'the is lower profit --> ' ,data[ (data.revenue_adj-data.budget_adj) == (data.revenue_adj-data.budget_adj).min() ].index[0])\nprint('the lowe gain is --> ' , data[data.gain == data.gain.min() ].index[0])","016c1c6c":"data = df_clean.groupby([ 'company1' , 'genere1']).count()['popularity'][df_clean.groupby([ 'company1' , 'genere1' ]).count()['popularity']>20]\ndata.unstack().plot(kind='bar'  , figsize=(20,6) );\n","98ef6fb3":"data = df_clean.groupby([ 'director' , 'genere1']).count()['popularity'][df_clean.groupby([ 'director' , 'genere1' ]).count()['popularity']>5]\ndata.unstack().plot(kind='bar'  , figsize=(20,6) );\n","4b974855":"data = df_clean.groupby([ 'main_hero' , 'genere1']).count()['popularity'][df_clean.groupby([ 'main_hero' , 'genere1' ]).count()['popularity']>10]\ndata.unstack().plot(kind='bar'  , figsize=(20,6) );\n","9d838391":"from subprocess import call\ncall(['python', '-m', 'nbconvert', 'Investigate_a_Dataset.ipynb'])","b3121017":"- release_date data type is object it need to be a date","6bb7dbab":"### save the cleaned data to a file ","1c41da8c":"## add extra columns for month of releasing then delete the date ","ce46e450":"## mainpulate genre , cast , production_comapny ","f7e4d80c":"<a id='intro'><\/a>\n## Introduction\n\n> **data overview**:\nThis data set contains information about 10,000 movies collected from The Movie Database (TMDb), including user ratings and revenue\n","e7497f72":"- Run time has no obvious relation with any variable . \n- Run time mean :-  109 \n- Run time median :-   106 ","4c0bc4d5":"##### define \n- there is invalid data in revenue , budget , run_time , maximum in run time","57aa3066":"## what is the year with biggest total adjustable revenue and the year with high gain ?\n\n","2972427c":"### visual assesing\n    i use excel to asses the data too","654c5073":"- There is a relation between the month of release and the actor there is actors that release their movie in the same month  such as Robert De Niro  love month 9 \n","5a5d0dcc":"- Its clearly that the distribution is left skewed  that\u2019s mean the number of movie increase every year with exponential relation ","39656737":"## companies that work with the same actor and director more than 3 time ","34124170":"- Its wired but over years number of votes increase but the average votes decrease.  \n","833669df":"\n# Project: Investigate a Dataset (TMDb movie data)\n\n## Table of Contents\n<ul>\n<li><a href=\"#intro\">Introduction<\/a><\/li>\n<li><a href=\"#wrangling\">Data Wrangling<\/a><\/li>\n<li><a href=\"#eda\">Exploratory Data Analysis<\/a><\/li>\n<li><a href=\"#conclusions\">Conclusions<\/a><\/li>\n<\/ul>\n\n\n<h3 style=\"color:red\" >you can see the all project file and my report for the analysis <u><a href=\"https:\/\/github.com\/Abdelmenam-Tarek-Abdelmenam\/Investigate-a-Dataset\"> here <\/a> <\/u><\/h3>\n\n","5b67e227":"##### test","2527409d":"### company\n- some companies prefer genre and doesn't prefere the rest ","eebf1728":"##  run time \n","7b676b1a":"- id , imdb_id , homepage, overview , tagline i will not use them in the analysis so i will drop them \n- revenue and budjet are defined twice as revenue_adj and budjet_adj","d3ed21f5":"## the relation between genre and other parameters","5916b03c":"## movies distribution over years","ca3cb25f":"##### code","1ce26c39":"##### code","1147f7e9":"- there is no many null values so i may keep them  ","67c7af4c":"##### define \n- convert release_date data type from string to date ","75218c65":"## Genres with high profit ","b81924a1":"## movies per month distrbution ","6153a2cc":"- It\u2019s wired but Sylvester Stallone is the director for the movies he act in \n","e5d35ea8":"- Its wired but actors that there name starts with tom are the best \n","cb538eb3":"## find the best month ","445916f1":"#### find the popular genre in each year ","0deb4195":"## the relation between years and votes\n","83ff8997":"- It seems that the companies doesn\u2019t  know the best month because as you see \n","72d2dc0f":"- the most commo genere is drama  ","ab008c97":"## find the most popular director with more than15 movies ","14af2e0f":"<a id='wrangling'><\/a>\n## Data Wrangling\n\n> **Tip**: In this section of the report, i will load in the data, check for cleanliness, and then trim and clean your dataset for analysis. Make sure that you document your steps carefully and justify your cleaning decisions.\n\n# data gathering ","3e8ee649":"## the most popular director with more than 50 movies\n","6940bdf5":"## analysis the first person in the cast","62005943":"- That\u2019s because they gain more revenue whith each other \n","01c21b70":"## assesing report \n> **not important column**: id , imdb_id , homepage , overview , tagline\n\n> **wrong data type**: convert release_date to date\n\n> **duplicate**: delet the duplicate data raw\n\n> **invalid data**: minimun in revenue , budjet , run_time  , maximum in run time \n\n> **add extra column**: release month  , gain which equal to revenue \/ budjet  movie_hero\n\n> **split columns**: genere , production_company\n\n\/\n\n# Data Cleaning","bedfe6a9":"###### ther is some data that doesn't make sense \n- 0 revenue , budjet , run_time \n- 900 in run time mean 15 hour ","c6e7fd4b":"## add an extra column represent the precentage of revenue to budget","b9b20a03":"<a id='eda'><\/a>\n## Exploratory Data Analysis\n\n> **Tip**: Now that you've trimmed and cleaned your data, you're ready to move on to exploration. Compute statistics and create visualizations with the goal of addressing the research questions that you posed in the Introduction section. It is recommended that you be systematic with your approach. Look at one variable at a time, and then follow it up by looking at relationships between variables.\n\n","b4b561da":"##### define\n- drop the notimportant columns  id , imdb_id , homepage , overview , tagline","fc85c74c":"- its clearly that the revenue has an exponential distribution and that make sense because many reasons such as marketing , income m peoples interests , number of movies  \u2026etc .\n","b2f5df57":"### Research Question 2  (best and Worst movies )","0b1cef86":"## genre study","48463acc":"## common genere ","26baaad4":"# ^^\n> **Tip**: you will find all analysis exlanation in EDA_REPORT\n","6cce71b7":"##### define\ndelete the duplicated data raw","72b85c58":"### director thet love spacefic actor to work with\n#### i studied the case that the actor wotk with the same director more than 5 times","a29d05e4":"## actors\n- as you see there is some directors as sylvester stallone prefer action and woody adam sandler prefer comedy","12f04220":"- This gain graph show that the heist gain was in 1972 that mean you could use small budget to gain high revenue but now to get more revenue you should but more budget .\n","4a844c89":"##### code \ndelete that movies","5df6389a":"# data assesing ","d8bd5d76":"### progrmatic assesing","08a0c8e8":"# SUUMARRY :-\n\n### all result and explanation is  in EDA_REPORT.PDF\n### The extrnal resources\n- search in stack overflow to find error's solution and some usful function parameter\n- i read the comment on the data in kaggle to know column documentation","c8620137":"##### test ","b4fe3a8b":"#### get the most popular actors with movies more than 20 \n","650ad9a8":"- there is a relation as every year has a common movie category ","c63c1951":"###### code ","f99d1c0d":"#### dowlnod the data set ","5d19b7f2":"##### test","b36b9b47":"## directors \n- as you see there is some directors as martin scorsese prefer drama and woody allen prefer comedy","6c3c61e7":"- Obviously the best month to publish your movie is 6 or 12  because you have more chance to gain more revenue . \n\n- Don\u2019t take the risk and publish your movie in month with low gain because you maybe will gain little revenue \n","e55de2f6":"- The best director is Steven Spielberg \n","4b04b000":"##### test"}}