{"cell_type":{"4d849e30":"code","7715b35f":"code","d909d9d7":"code","9dafdfac":"code","0b105576":"code","32933a52":"code","3e7e1dd5":"code","99f83a8c":"code","681026fe":"code","fa645657":"code","43823877":"code","a9ed13ef":"code","838df41a":"code","d2faa459":"code","6a641759":"code","c9d351da":"code","00b0689b":"code","97925e1c":"code","925bb418":"code","774dbba4":"code","f64fa5e8":"code","cbd38293":"code","d85eb0c8":"code","e4f7e766":"code","acce80f8":"code","c167b733":"code","46e93858":"code","91bebaaa":"code","994ab527":"code","bd5682d0":"code","dd336fc4":"code","988a0505":"code","1e0cb188":"code","70c52adf":"code","88ae42e5":"code","976396d6":"code","7c39a1cc":"code","edf2c60e":"code","60e56a4d":"code","2a5537d3":"code","6744c62d":"code","64bf231f":"code","ca572203":"code","4e7d3ccf":"code","08dcfc97":"code","8fa3760b":"code","4d886963":"code","699d54d2":"code","c9f95d84":"code","7336def9":"code","98ed5ad8":"code","25654daa":"code","9b3f0ce1":"code","f8825cf0":"code","8876bfac":"code","e8bd49ff":"code","a7e3b51b":"code","17abecf4":"code","d88e8f57":"code","78ed89af":"code","f9b064f2":"code","0b1e9998":"code","1db8d591":"code","c2961565":"code","0ac43713":"code","ae475f21":"code","0f16d1cd":"code","8e5c8de3":"code","583ba7dc":"code","944b2dff":"code","7f2d0630":"code","fa3a73c3":"code","93fa0131":"code","e7db5a15":"code","a0a89446":"code","85ebdd9f":"code","5a977eb0":"code","cbc7b383":"code","878d8f0f":"code","19dac9a6":"code","33143d7a":"code","7a0ad26d":"markdown","f842a4ac":"markdown","00a42fa6":"markdown","16e3c5dd":"markdown","c6296270":"markdown","66cc1ae2":"markdown","b19795ce":"markdown","743c3c77":"markdown","312a6a13":"markdown","b346c3c4":"markdown","7fd14e5b":"markdown","5eba783a":"markdown","b56c8714":"markdown","517c93fa":"markdown","6f77ad84":"markdown","5cb8069c":"markdown","4076a57f":"markdown","324d5715":"markdown","c0b778f4":"markdown","85525d08":"markdown","20b5433e":"markdown"},"source":{"4d849e30":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7715b35f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n# Mansno\nimport missingno as msno \n","d909d9d7":"df=pd.read_csv('..\/input\/delhi-crime-data\/Delhi Accident Data.csv')\ndf.head()","9dafdfac":"df=df.drop([\"Unnamed: 7\",\"Unnamed: 8\",\"Unnamed: 9\"], axis=1)\n","0b105576":"df.head()\n","32933a52":"df.isnull().sum()","3e7e1dd5":"df.info()\n","99f83a8c":"msno.matrix(df)\nplt.show()","681026fe":"df.columns","fa645657":"col = \"TYPE OF ACCIDENT\"\ngrouped = df[col].value_counts().reset_index()\ngrouped = grouped.rename(columns = {col : \"count\", \"index\" : col})\n\n## plot\ntrace = go.Pie(labels=grouped[col], values=grouped['count'], pull=[0.05, 0], marker=dict(colors=[\"#6ad49b\", \"#a678de\"]))\nlayout = go.Layout(title=\"\", height=600, legend=dict(x=0.1, y=1.1))\nfig = go.Figure(data = [trace], layout = layout)\niplot(fig)","43823877":"col=['YEAR', 'DISTRICT', 'VEHICLE AT FAULT', 'VICTIM','# INJURED', '# KILLED ']\n","a9ed13ef":"dff=df[df['TYPE OF ACCIDENT']!='NON INJURY']","838df41a":"dff.head()","d2faa459":"col = \"TYPE OF ACCIDENT\"\ngrouped = dff[col].value_counts().reset_index()\ngrouped = grouped.rename(columns = {col : \"count\", \"index\" : col})\n\n## plot\ntrace = go.Pie(labels=grouped[col], values=grouped['count'], pull=[0.05, 0], marker=dict(colors=[\"#6ad49b\", \"#a678de\"]))\nlayout = go.Layout(title=\"Response variable\", height=600, legend=dict(x=0.1, y=1.1))\nfig = go.Figure(data = [trace], layout = layout)\niplot(fig)","6a641759":"target_count = dff['TYPE OF ACCIDENT'].value_counts()\nprint('Class 0:', target_count[0])\nprint('Class 1:', target_count[1])\nprint('Proportion:', round(target_count[0] \/ target_count[1], 2), ': 1')\n\ntarget_count.plot(kind='bar', title='Count (target)');","c9d351da":"dff.head()","00b0689b":"one_hot_encoded_data = pd.get_dummies(dff, columns = ['DISTRICT'])\nprint(one_hot_encoded_data.head())","97925e1c":"one_hot_encoded_data.columns","925bb418":"from sklearn import preprocessing\nlabel_encoder = preprocessing.LabelEncoder()\ndff['TYPE OF ACCIDENT']=label_encoder.fit_transform(dff['TYPE OF ACCIDENT'])\ndff.head()","774dbba4":"one_hot_encoded_data['TYPE OF ACCIDENT']=label_encoder.fit_transform(one_hot_encoded_data['TYPE OF ACCIDENT'])\none_hot_encoded_data.head()","f64fa5e8":"one_hot_encoded_data.columns","cbd38293":"col=['DISTRICT_CENTRAL DELHI', 'DISTRICT_EAST DELHI',\n       'DISTRICT_NEW DELHI', 'DISTRICT_NORTH DELHI(ROHINI)',\n       'DISTRICT_NORTH EAST DELHI', 'DISTRICT_NORTH WEST DELHI',\n       'DISTRICT_OUTER', 'DISTRICT_SHAHDARA', 'DISTRICT_SOUTH DELHI',\n       'DISTRICT_SOUTH EAST DELHI', 'DISTRICT_SOUTH WEST DELHI',\n       'DISTRICT_UNK', 'DISTRICT_WEST DELHI']","d85eb0c8":"X=one_hot_encoded_data[col]\ny=one_hot_encoded_data['TYPE OF ACCIDENT']","e4f7e766":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay","acce80f8":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf","c167b733":"X_train, x_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","46e93858":"lr=LogisticRegression()\nlr.fit(X_train, y_train)","91bebaaa":"import statsmodels.api as sm\nlr_model=sm.Logit(y, X)\nresult=lr_model.fit()\nprint(result.summary())","994ab527":"print(lr.intercept_)","bd5682d0":"y_pred=lr.predict(X_train)","dd336fc4":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","988a0505":"y_test_pred=lr.predict(x_test)","1e0cb188":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","70c52adf":"cfm=confusion_matrix(y_test, y_test_pred)","88ae42e5":"disp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=lr.classes_)\ndisp.plot()","976396d6":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","7c39a1cc":"y_test_pred_prob=lr.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","edf2c60e":"print(y_test_pred_prob)\nlen(y_test_pred_prob)\n\n","60e56a4d":"metrics.roc_auc_score(y_test, y_test_pred_prob)","2a5537d3":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","6744c62d":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","64bf231f":"year_feature=pd.get_dummies(dff, columns=['YEAR'])\nyear_feature.head()","ca572203":"year_feature.columns","4e7d3ccf":"col=['YEAR_2008', 'YEAR_2009', 'YEAR_2010',\n       'YEAR_2011', 'YEAR_2012', 'YEAR_2013', 'YEAR_2014', 'YEAR_2015',\n       'YEAR_2016', 'YEAR_2017']","08dcfc97":"X=year_feature[col]\nx=year_feature['TYPE OF ACCIDENT']","8fa3760b":"X_train, x_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","4d886963":"lr=LogisticRegression()\nlr.fit(X, y)","699d54d2":"import statsmodels.api as sm\nlr_model=sm.Logit(y, X)\nresult=lr_model.fit()\nprint(result.summary())","c9f95d84":"print(lr.intercept_)","7336def9":"y_pred=lr.predict(X_train)","98ed5ad8":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","25654daa":"y_test_pred=lr.predict(x_test)","9b3f0ce1":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","f8825cf0":"cfm=confusion_matrix(y_test, y_test_pred)","8876bfac":"disp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=lr.classes_)\ndisp.plot()","e8bd49ff":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","a7e3b51b":"y_test_pred_prob=lr.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","17abecf4":"y_test_pred_prob\n","d88e8f57":"metrics.roc_auc_score(y_test, y_test_pred_prob)","78ed89af":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","f9b064f2":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","0b1e9998":"df.columns","1db8d591":"year_feature=pd.get_dummies(dff, columns=['YEAR', 'DISTRICT'])\nyear_feature.head()","c2961565":"year_feature.columns","0ac43713":"col=['YEAR_2008', 'YEAR_2009', 'YEAR_2010', 'YEAR_2011',\n       'YEAR_2012', 'YEAR_2013', 'YEAR_2014', 'YEAR_2015', 'YEAR_2016',\n       'YEAR_2017', 'DISTRICT_CENTRAL DELHI', 'DISTRICT_EAST DELHI',\n       'DISTRICT_NEW DELHI', 'DISTRICT_NORTH DELHI(ROHINI)',\n       'DISTRICT_NORTH EAST DELHI', 'DISTRICT_NORTH WEST DELHI',\n       'DISTRICT_OUTER', 'DISTRICT_SHAHDARA', 'DISTRICT_SOUTH DELHI',\n       'DISTRICT_SOUTH EAST DELHI', 'DISTRICT_SOUTH WEST DELHI',\n       'DISTRICT_UNK', 'DISTRICT_WEST DELHI']","ae475f21":"X=year_feature[col]\nx=year_feature['TYPE OF ACCIDENT']","0f16d1cd":"X_train, x_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)\n","8e5c8de3":"lr=LogisticRegression()\nlr.fit(X, y)","583ba7dc":"import statsmodels.api as sm\nlr_model=sm.Logit(y, X)\nresult=lr_model.fit()\nprint(result.summary())","944b2dff":"print(lr.intercept_)","7f2d0630":"y_pred=lr.predict(X_train)\n","fa3a73c3":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","93fa0131":"y_test_pred=lr.predict(x_test)\n","e7db5a15":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","a0a89446":"cfm=confusion_matrix(y_test, y_test_pred)\n","85ebdd9f":"disp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=lr.classes_)\ndisp.plot()","5a977eb0":"y_test_pred_prob=lr.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve","cbc7b383":"y_test_pred_prob","878d8f0f":"metrics.roc_auc_score(y_test, y_test_pred_prob)\n","19dac9a6":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","33143d7a":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","7a0ad26d":"# Explanatory variables","f842a4ac":"# Dataset detais\n* YEAR- it is showing the year when data was recorded\n* DISTRICT- Districts of Delhi\n* VEHICLE AT FAULT-\n* VICTIM- Those whe were hit\n* TYPE OF ACCIDENT- Accident is fata or not\n* No OF INJURED- Number of injuries during the accident\n* NO OF KILLED- Number of persons were killed after the accidents","00a42fa6":"# To Test of Individual Regression Coefficients\n* Hypothesis is stated as\n* Ho- bj=0\n* H1:- bj !=0\n* The test statistic for testing above hypothesis is t-test\n* \ud835\udc610 =(bj-0)\/s.e(bj) * s.e is standard error","16e3c5dd":"# To Test of Individual Regression Coefficients\n* Hypothesis is stated as\n* Ho- bj=0\n* H1:- bj !=0\n* The test statistic for testing above hypothesis is t-test\n* \ud835\udc610 =(bj-0)\/s.e(bj) * s.e is standard error","c6296270":"# Observation\n* As we can see that we have the list of the coefficient of the all the districts,\n* Beside that I have found that which districts have better impact on the fatality rate. \n* On the basis of the hypothesis we came up on the conclusion that District outer and Unk can be removed as these two as statistically unsignificant.\n* Since all the coefficient are real and positive . After performing the hypothesis those features which are left, more the coefficient more is the important featurs.","66cc1ae2":"# Sample random Sample ","b19795ce":"# Taking Year and Districts as features","743c3c77":"# Find the Missing value","312a6a13":"# Plotting the missing values ","b346c3c4":"# 2 outcome of the response variables","7fd14e5b":"# Logistic Regression","5eba783a":"# Taking Year as featurs","b56c8714":"# Obs\n* It is the case of imbalanced dataset. \n* We need to perform sampling in ordert to make it balanced dataset.","517c93fa":"# Dataset information","6f77ad84":"# To Test of Individual Regression Coefficients\n* Hypothesis is stated as\n* Ho- bj=0\n* H1:- bj !=0\n* The test statistic for testing above hypothesis is t-test\n* \ud835\udc610 =(bj-0)\/s.e(bj) * s.e is standard error\n","5cb8069c":"# Label Encoding the response variables","4076a57f":"# Obs\n* As we can see that All the features are quite important. ","324d5715":"# One-Hot Encoding","c0b778f4":"# Response Variable","85525d08":"# To find the intercept","20b5433e":"# Obs\n* Since the Non injury is very less so we can remove that one\n* We make it as a binary problem."}}