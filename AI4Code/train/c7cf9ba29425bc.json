{"cell_type":{"68af3604":"code","266c05da":"code","eebdd493":"code","754bdd34":"code","d2c1109e":"code","4ba2fb1f":"code","683e3e58":"code","b7d168b1":"code","3cf4d3f2":"code","46a513d0":"code","8f958677":"code","b16059d1":"code","d6401a8a":"markdown","8435c5b0":"markdown","e9f98b60":"markdown"},"source":{"68af3604":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport cv2 # IMAGE PROCESSING - OPENCV\nfrom glob import glob # FILE OPERATIONS\nimport itertools\n\n# KERAS AND SKLEARN MODULES\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.utils import to_categorical\n\nfrom sklearn import preprocessing\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","266c05da":"image_dir = '..\/input\/train\/*\/*.png'\nimages = glob(image_dir)\ntraining_images = []\ntraining_labels = []\nnum = len(images)\ncount = 1\n\n#READING IMAGES AND RESIZING THEM\nfor i in images:\n    print(str(count)+'\/'+str(num),end='\\r')\n    training_images.append(cv2.resize(cv2.imread(i),(128,128)))\n    training_labels.append(i.split('\/')[-2])\n    count=count+1\ntraining_images = np.asarray(training_images)\ntraining_labels = pd.DataFrame(training_labels)","eebdd493":"training_labels.rename(columns={0: 'sappling'}, inplace=True)\ntraining_labels.sappling.value_counts()\nplt.figure(figsize=(20,10))\nsns.barplot(x=training_labels.sappling.unique(), y=training_labels.sappling.value_counts())","754bdd34":"\nfig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2)\nfig.suptitle('Sharing x per column, y per row')\nax1.imshow(training_images[3])\nax2.imshow(training_images[4])\nax3.imshow(training_images[5])\nax4.imshow(training_images[6])\nax5.imshow(training_images[7])\nax6.imshow(training_images[8])\n","d2c1109e":"new_train = []\nsets = []; getEx = True\nfor i in training_images:\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n    #GREEN PARAMETERS\n    lower = (25,40,50)\n    upper = (75,255,255)\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    boolean = mask>0\n    new = np.zeros_like(i,np.uint8)\n    new[boolean] = i[boolean]\n    new_train.append(new)\n    \n    if getEx:\n        plt.subplot(2,3,1);plt.imshow(i) # ORIGINAL\n        plt.subplot(2,3,2);plt.imshow(blurr) # BLURRED\n        plt.subplot(2,3,3);plt.imshow(hsv) # HSV CONVERTED\n        plt.subplot(2,3,4);plt.imshow(mask) # MASKED\n        plt.subplot(2,3,5);plt.imshow(boolean) # BOOLEAN MASKED\n        plt.subplot(2,3,6);plt.imshow(new) # NEW PROCESSED IMAGE\n        plt.show()\n        getEx = False\nnew_train = np.asarray(new_train)\n\n# CLEANED IMAGES\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    plt.imshow(new_train[i])","4ba2fb1f":"def createModel():\n    model = Sequential()\n    \n    model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(128, 128, 3), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(BatchNormalization(axis=3))\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(BatchNormalization(axis=3))\n    model.add(Dropout(0.1))\n    \n\n    model.add(Flatten())\n\n    model.add(Dense(4096, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(4096, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(12, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    model.summary()\n    \n    return model","683e3e58":"from sklearn.preprocessing import LabelEncoder\nle = preprocessing.LabelEncoder()\n\n\n# 2\/3. FIT AND TRANSFORM\n# use df.apply() to apply le.fit_transform to all columns\ntraining_labels = training_labels.apply(le.fit_transform)\nprint(training_labels.head(20))\nprint(type(training_labels))\n\n","b7d168b1":"training_labels = np.array(training_labels)","3cf4d3f2":"training_labels = to_categorical(training_labels)","46a513d0":"sappling_model = createModel()\nhistory = sappling_model.fit(training_images, training_labels, batch_size=32, epochs=20, verbose=1)","8f958677":"def save_model(model):\n    sappling_model_json = model.to_json()\n    with open(\"sappling_model.json\", \"w\") as json_file:\n        json_file.write(sappling_model_json)\n    # serialize weights to HDF5\n    model.save_weights(\"sappling_model.h5\")\n    print(\"Saved model to disk\")","b16059d1":"save_model(sappling_model)","d6401a8a":"> Resize the images in the dataset","8435c5b0":"# Convolutional Neural Network Model\n\nThe CNN model that we define here using keras is based on the VGG16 architecture.","e9f98b60":"# Display some of the images in the dataset"}}