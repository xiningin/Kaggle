{"cell_type":{"47542bfd":"code","7b2b97aa":"code","d64fbd29":"code","b41db903":"code","5a6c1ef7":"code","fb0e68ef":"code","dd35d586":"code","3c816000":"code","c5dd8d53":"code","13d10f5b":"code","cf7a039a":"code","785893d8":"code","e1fad291":"code","1342e588":"code","5907e4da":"code","a3df2850":"code","ba2f2b8f":"code","cd301428":"code","4eb55f53":"code","a5be53c1":"code","0278fad3":"code","f4f1b579":"code","74fc0ddc":"code","ec6f9bd4":"code","243430a2":"code","b3db5f0b":"code","2d810455":"markdown","bd35d933":"markdown","58dad313":"markdown","254a2b3e":"markdown","43b2affd":"markdown"},"source":{"47542bfd":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","7b2b97aa":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))\n\n\nSentence_1 = 'Today is Friday'\nSentence_2 = 'Tomorrow is Saturday'\nSentence_3 = 'Day After Tomorrow is Sunday'\n\nprint(jaccard(Sentence_1,Sentence_2))\nprint(jaccard(Sentence_1,Sentence_3))\nprint(jaccard(Sentence_2,Sentence_3))","d64fbd29":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\n!pip install chart_studio\n!pip install textstat\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# text processing libraries\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n\n# Visualisation libraries\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport chart_studio.plotly as py\nimport plotly.figure_factory as ff\nfrom plotly.offline import iplot\nfrom collections import Counter\nfrom string import *\nimport cufflinks\ncufflinks.go_offline()\ncufflinks.set_config_file(world_readable=True, theme='pearl')\n\n# sklearn \nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n\n# File system manangement\nimport os\n\n# Pytorch\nimport torch\n\n#Transformers\nfrom transformers import BertTokenizer\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')","b41db903":"train = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","5a6c1ef7":"print(train.shape)\nprint(test.shape)","fb0e68ef":"train.info()","dd35d586":"test.info()","3c816000":"train.head()","c5dd8d53":"train.describe()","13d10f5b":"train['sentiment'].value_counts()","cf7a039a":"train['sentiment'].value_counts().iplot(kind='bar',\n                                                      yTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='red',\n                                                      theme='pearl',\n                                                      bargap=0.6,\n                                                      gridcolor='white',\n                                                      title='Distribution of Sentiment column from the train dataset')","785893d8":"test['sentiment'].value_counts().iplot(kind='bar',yTitle='Percentage', \n                                                      linecolor='black', \n                                                      opacity=0.7,\n                                                      color='green',\n                                                      theme='pearl',\n                                                      bargap=0.6,\n                                                      gridcolor='white',\n                                                      title='Distribution  of Sentiment column from the test dataset')","e1fad291":"train['NoOfSelectedTextWords'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain['NoOfTextWords'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ntrain['DifferenceOfTextWordsToSelectedTextWords'] = train['NoOfTextWords'] - train['NoOfSelectedTextWords'] #Difference in Number of words text and Selected Text","1342e588":"train.head()","5907e4da":"def clean_text(text):\n    '''Convert text to lowercase,remove punctuation, remove words containing numbers, ,remove links and remove text in square brackets,.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    return text","a3df2850":"train['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))","ba2f2b8f":"train.head()","cd301428":"train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())","4eb55f53":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))","a5be53c1":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Purples')","0278fad3":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.rcParams['text.color'] = 'black'\nplt.pie(temp['count'], labels=temp['Common_words'], colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('Common_words')\nplt.show()","f4f1b579":"def text_preprocessing(text):\n    \"\"\"\n    Parsing the text and removing stop words.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(tokenized_text)\n    return combined_text","74fc0ddc":"#train['text'] = train['text'].apply(lambda x:clean_text(x))\n#train['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))","ec6f9bd4":"positive_text = train[train['sentiment'] == 'positive']['selected_text']\nnegative_text = train[train['sentiment'] == 'negative']['selected_text']\nneutral_text = train[train['sentiment'] == 'neutral']['selected_text']","243430a2":"positive_text_clean = positive_text.apply(lambda x: text_preprocessing(x))\nnegative_text_clean = negative_text.apply(lambda x: text_preprocessing(x))\nneutral_text_clean = neutral_text.apply(lambda x: text_preprocessing(x))","b3db5f0b":"from wordcloud import WordCloud\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\nwordcloud1 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(positive_text_clean))\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title('Positive text',fontsize=40);\n\nwordcloud2 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(negative_text_clean))\nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title('Negative text',fontsize=40);\n\nwordcloud3 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(neutral_text_clean))\nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title('Neutral text',fontsize=40);","2d810455":"### Number of rows and Number of columns present in dataset","bd35d933":"### Jaccard Index Metric","58dad313":"### Reading Data ","254a2b3e":"# Cleaning Text","43b2affd":"# WordCloud"}}