{"cell_type":{"b87c38ff":"code","2a883354":"code","6359e1da":"code","2e81fdf5":"code","6422d126":"code","1202d1f4":"code","615c1c7a":"code","8a581663":"code","43f56a88":"code","a871f6ed":"code","2ad120d4":"code","4137508e":"code","72e9ad6b":"code","f1b7b0f5":"code","61731625":"code","91492d6f":"code","dd5518a1":"code","74b199cd":"code","ba2260d1":"code","e018d1f9":"code","67c9bc51":"code","84d882a1":"code","dc2e6d22":"code","3f44651d":"code","c2c1298f":"code","51a4043d":"code","c6e7672a":"code","58c1c3bc":"code","a0cf2207":"code","22e691a8":"code","859ad359":"code","df6759c8":"code","244e8058":"code","8f224e98":"code","b38612e7":"code","bbb039f4":"code","c0aa6a8a":"code","875b61dc":"markdown","f3ab6f40":"markdown","a71c7a2c":"markdown","672ebaa7":"markdown","7ac36aa4":"markdown","3f2d1614":"markdown","114fc915":"markdown","9379a05d":"markdown","7343717a":"markdown","9c62b7be":"markdown"},"source":{"b87c38ff":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport os\n\nsns.set_style('darkgrid')\nsns.set_palette('bone')\npd.options.display.float_format = '{:,.2f}'.format\n\nprint(os.listdir(\"..\/input\"))","2a883354":"train = pd.read_table('..\/input\/train.tsv')\ntest = pd.read_table('..\/input\/test_stg2.tsv')\n\nprint(train.shape, test.shape)","6359e1da":"train.info()","2e81fdf5":"train.head()","6422d126":"train['train_id'] = train['train_id'].astype(str)\ntest['test_id'] = test['test_id'].astype(str)","1202d1f4":"print(train['price'].describe())","615c1c7a":"plt.subplot(1, 2, 1)\ntrain['price'].plot.hist(bins=50, edgecolor='white', range=[0,200], figsize=(15,5))\nplt.xlabel('price')\nplt.ylabel('frequency')\nplt.title('Price Distribution')\n\nplt.subplot(1, 2, 2)\nnp.log1p(train['price']).plot.hist(bins=50, edgecolor='white')\nplt.xlabel('log(price+1)')\nplt.ylabel('frequency')\nplt.title('Log(Price) Distribution')\nplt.show()","8a581663":"# correcting skew\ntrain['price'] = np.log1p(train['price'])","43f56a88":"train['name'].to_frame().head(10)","a871f6ed":"print('unique name count:', train['name'].nunique(), 'of', len(train))","2ad120d4":"print('unique brand count:', train['brand_name'].nunique())","4137508e":"df = train['brand_name'].value_counts().to_frame('brand_count')\ndf.head(10)","72e9ad6b":"train['category_name'].head(10).to_frame()","f1b7b0f5":"catsCount = train['category_name'].apply(lambda x: len(str(x).split('\/')))\nmaxCount = max(catsCount)\nprint('max categories:', maxCount)\nprint(train['category_name'][catsCount == maxCount].unique())\n\ndel catsCount","61731625":"# separate category\ndef separate_category_feat(df):\n    df['general_cat'], df['subcat_1'], df['subcat_2'] = \\\n        zip(*df['category_name'].apply(lambda x: str(x).split('\/',3) if x == x else ('None', 'None', 'None')))","91492d6f":"subset = train['category_name'].to_frame().copy()\nseparate_category_feat(subset)\n    \nsubset[['category_name','general_cat','subcat_1','subcat_2']].head(10)","dd5518a1":"for c in ['general_cat','subcat_1','subcat_2']:\n    print(f'unique {c} count:', subset[c].nunique())\n    \nsubset['general_cat'].value_counts().plot.bar()\n\ndel subset","74b199cd":"train['item_description'].to_frame().head(10)","ba2260d1":"# remove missing values in item description (in train)\ntrain = train[pd.notnull(train['train_id']) & pd.notnull(train['item_description'])]","e018d1f9":"all_df = pd.concat([train, test], sort=False)\n\ndel train,test","67c9bc51":"# fillna\nall_df['brand_name'].fillna('None', inplace=True)\nall_df['item_description'].fillna('None', inplace=True)","84d882a1":"separate_category_feat(all_df)","dc2e6d22":"all_df['nm_word_len'] = all_df['name'].map(lambda x: len(x.split()))\nall_df['desc_word_len'] = all_df['item_description'].map(lambda x: len(x.split()))\nall_df['nm_len'] = all_df['name'].map(lambda x: len(x))\nall_df['desc_len'] = all_df['item_description'].map(lambda x: len(x))","3f44651d":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(stop_words='english', \n                             min_df=100,\n                             max_features=50000,\n                             #tokenizer=tokenize,\n                             ngram_range=(1, 2))\nall_desc = all_df['item_description'].values\nvz = vectorizer.fit_transform(list(all_desc))","c2c1298f":"tfidf = pd.DataFrame(index=vectorizer.get_feature_names(), data=vectorizer.idf_, columns=['tfidf'])\ntfidf.sort_values(by=['tfidf'], ascending=True).head(10)","51a4043d":"del all_desc\ngc.collect()","c6e7672a":"from sklearn.cluster import MiniBatchKMeans\n\nnum_clusters = 30 # need to be selected wisely\n\nkmeans_model = MiniBatchKMeans(n_clusters=num_clusters,\n                               init='k-means++',\n                               n_init=1,\n                               init_size=1000, batch_size=1000, verbose=0, max_iter=1000)\nall_df['kmeans_cluster30'] = kmeans_model.fit_predict(vz)\n\nsorted_centroids = kmeans_model.cluster_centers_.argsort()[:, ::-1]\nterms = vectorizer.get_feature_names()\nfor i in range(num_clusters):\n    print(\"Cluster %d:\" % i)\n    aux = ''\n    for j in sorted_centroids[i, :10]:\n        aux += terms[j] + ' | '\n    print(aux)\n    print()","58c1c3bc":"del kmeans_model, vz, vectorizer\ngc.collect()","a0cf2207":"all_df.drop(['item_description'], axis=1, inplace=True)","22e691a8":"all_df.info()\nall_df.drop(['name'], axis=1, inplace=True)\nall_df.drop(['brand_name'], axis=1, inplace=True)\nall_df.drop(['category_name'], axis=1, inplace=True)","859ad359":"import sys\nprint(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True)[:10])","df6759c8":"cols = [c for c in all_df.columns if c not in ['train_id','test_id','price']]\nfor i, t in all_df.loc[:, cols].dtypes.iteritems():\n    if t == object:\n        #all_df = pd.concat([all_df, pd.get_dummies(all_df[i].astype(str), prefix=i)], axis=1)\n        #all_df.drop(i, axis=1, inplace=True)\n        all_df[i] = pd.factorize(all_df[i])[0]","244e8058":"train = all_df[all_df['price'].notnull()].drop(['test_id'], axis=1)\ntest = all_df[all_df['price'].isnull()].drop(['train_id','price'], axis=1)\n\nX_train = train.drop(['price','train_id'], axis=1)\nY_train = train['price']\nX_test  = test.drop(['test_id'], axis=1)\ntrain_id  = train['train_id']\ntest_id  = test['test_id']\n\nprint(X_train.shape, X_test.shape)","8f224e98":"del train, test, all_df\ngc.collect()","b38612e7":"from sklearn.model_selection import StratifiedKFold, GroupKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nparams={'learning_rate': 0.2,\n        'objective':'regression',\n        'metric':'rmse',\n        'num_leaves': 31,\n        'verbose': 1,\n        'random_state':42,\n        'bagging_fraction': 0.7,\n        'feature_fraction': 0.7\n       }\n\nfolds = GroupKFold(n_splits=5)\n\noof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\nfor fold_, (trn_, val_) in enumerate(folds.split(X_train, Y_train, groups=train_id)):\n    trn_x, trn_y = X_train.iloc[trn_], Y_train.iloc[trn_]\n    val_x, val_y = X_train.iloc[val_], Y_train.iloc[val_]\n    \n    reg = lgb.LGBMRegressor(**params, n_estimators=3000)\n    reg.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], early_stopping_rounds=50, verbose=500)\n    \n    oof_preds[val_] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    sub_preds += reg.predict(X_test, num_iteration=reg.best_iteration_) \/ folds.n_splits\n\npred = sub_preds","bbb039f4":"submission = pd.DataFrame({\n    \"test_id\": test_id,\n    \"price\": np.expm1(pred),\n})\nsubmission.to_csv(\".\/submission.csv\", index=False)","c0aa6a8a":"submission.head(10)","875b61dc":"## Price","f3ab6f40":"## Brand Name","a71c7a2c":"## Name","672ebaa7":"* name - the title of the listing. Note that we have cleaned the data to remove text that look like prices to avoid leakage. These removed prices are represented as [rm]\n* item_condition_id - the condition of the items provided by the seller\n* category_name - category of the listing brand_name\n* price - the price that the item was sold for. This is the target variable that you will predict. The unit is USD. This column doesn't exist in test.tsv since that is what you will predict.\n* shipping - 1 if shipping fee is paid by seller and 0 by buyer\n* item_description - the full description of the item. Note that we have cleaned the data to remove text that look like prices to avoid leakage. These removed prices are represented as [rm]","7ac36aa4":"## Predict","3f2d1614":"## Item description","114fc915":"# Feature Engineering","9379a05d":"## Category Name","7343717a":"# Data Analysis","9c62b7be":"# Load data"}}