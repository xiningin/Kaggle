{"cell_type":{"eb3d5874":"code","72a4fd62":"code","74eb3a48":"code","35de1fe1":"code","45881c04":"code","ea8cb7e8":"code","6c6d07bf":"code","cf91e49b":"code","6beb0f5a":"code","c06cdb5e":"code","d19a132d":"code","a45acf74":"code","8ff8639f":"code","e2fb23f8":"code","d63ee0c1":"code","3549af6c":"code","cfb1513e":"code","0d254704":"code","081ce392":"code","3279d22a":"code","fb665838":"code","fbba54b9":"code","43dce2ce":"code","21d46ff0":"code","891968f1":"code","d1654187":"code","982c49ae":"code","0af32002":"code","f1389315":"code","7539b795":"code","250c7a4a":"code","c3481e10":"code","5dd82c35":"code","51f831fa":"code","3d0cd077":"code","514b55fd":"code","21e95f21":"code","c8feede4":"code","d6db8cde":"code","63a63812":"code","1a50b044":"code","7181a338":"code","75eece11":"code","84cb6e86":"code","b82988ba":"code","0cc8639c":"code","b328e52e":"code","fa11b09a":"code","e46092f7":"code","f87196cc":"code","62451489":"code","3cead8b7":"code","e486c5f8":"code","3dcda84d":"code","48d5e4ea":"code","a96ec9f6":"code","fbf34506":"code","2120eb25":"code","31950a3b":"code","0a11193c":"code","8a24d664":"code","39a2ac87":"code","72cfa73f":"code","45ae8306":"code","bbdcee5e":"code","9a2b83b7":"code","2570d295":"code","f697a308":"code","fa1f878f":"code","c2b33d64":"code","d6ec051b":"markdown","d854144d":"markdown","c7f3d28b":"markdown","e8165b0e":"markdown","692edf63":"markdown","096e4352":"markdown","901a4af2":"markdown","da596b25":"markdown"},"source":{"eb3d5874":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier","72a4fd62":"df=pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","74eb3a48":"df","35de1fe1":"df.head()","45881c04":"df.columns","ea8cb7e8":"df.shape","6c6d07bf":"df.skew()","cf91e49b":"df.corr()","6beb0f5a":"#Global declartions of function names\nglobal Head\nglobal Size\nglobal Column_names\nglobal Describe\nglobal Shape\nglobal Count\nglobal Value_count\nglobal ISNULL\nglobal Tail\nglobal Ndim\nglobal Nunique\nglobal Memory_usage\nglobal Duplicated\nglobal ISNA\nglobal DTYPES\nglobal CORR\nglobal Info\nglobal operations\n        \n\n        \n        ","c06cdb5e":" def Tail():\n    print('\\033[1m'+\"The last five rows of the dataframe are\"+'\\033[0m')\n    co3=df.tail()\n    return(co3)\n    print(\"--------------------------------------------------------------------------\")\nTail()\n","d19a132d":"def Describe():\n    print('\\033[1m'+\"The Description of our dataset is:\"+'\\033[0m')\n    des=df.describe()\n    return(des)\n    print(\"--------------------------------------------------------------------------\")\nDescribe()","a45acf74":"def Count():\n    print('\\033[1m'+\"The count of non null values are:\"+'\\033[0m')\n    co=df.count()\n    print(co,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nCount()\n","8ff8639f":"def Memory_usage():\n    print('\\033[1m'+\"The total memory used is :\"+'\\033[0m')\n    co6=df.memory_usage()\n    print(co6,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nMemory_usage()","e2fb23f8":"def DTYPES():\n    print('\\033[1m'+\"The datatypes are :\"+'\\033[0m')\n    co9=df.dtypes\n    print(co9,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nDTYPES()","d63ee0c1":"def Info():\n    print('\\033[1m'+\"The info of data set is :\"+'\\033[0m')\n    co11=df.info()\n    print(\"--------------------------------------------------------------------------\")\nInfo()","3549af6c":"def operations(df,x):\n    if df[x].dtype==\"float64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is :\\n\",df[x].mean())\n        print(\"The median is :\\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 :\\n \",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n \",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n\n            print(\"--------------------------------------------------------------------------\")\n\n\n    elif df[x].dtype==\"int64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is : \\n\",df[x].mean())\n        print(\"The median is : \\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 : \\n\",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n\",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n            print(\"--------------------------------------------------------------------------\")\n\n\n\n\n\n\n\n    else:\n\n        print('\\033[1m'+\"The data is Qualitative \\n\"+'\\033[0m')\n\n\n        if df[x].nunique()==1:\n            print('\\033[1m'+\"The data is singular \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()==2:\n            print('\\033[1m'+\"The data is Binary \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()>2:\n            print('\\033[1m'+\"The data is Multi \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n\n        print(\"--------------------------------------------------------------------------\")\n\nc=df.columns\nfor i in c:\n    operations(df,i)\n    print(\"\\n\")\n\n\n","cfb1513e":"def Summary():\n        print('\\033[1m'+\"The Summary of data is  \\n\"+'\\033[0m')\n        print(\"The shape of the datset is :\",df.shape)\n        print(\"The sixe o the data set is :\",df.size)\n        print(\"The dimensions of the dataset are:\",df.ndim)\n        print(\"The memory usage of the data set are\",df.memory_usage())\n        print(\"The data types of the dataset are:\",df.dtypes)\n        print(\"--------------------------------------------------------------------------\")\n\nSummary()     \n","0d254704":" def Column_Summary():\n        print('\\033[1m'+\"The Column wise Summary of data is  \\n\"+'\\033[0m')\n        k=df.columns\n        for i in k:\n            print('\\033[1m'+'', i, 'rows'+'\\033[0m')\n            print(\"The Shape of the column \",i,\"is \",df[i].shape)\n            print(\"The Size of the column \",i,\"is \",df[i].size)\n            print(\"The Dimensions of the column \",i,\"is \",df[i].ndim)\n            print(\"The Memory used by the column \",i,\"is \",df[i].memory_usage())\n            print(\"The Data types  of the column \",i,\"is \",df[i].dtypes)\n            print(\"--------------------------------------------------------------------------\")\nColumn_Summary()","081ce392":"k=df['Location'].values","3279d22a":"m=np.unique(k)\n","fb665838":"m","fbba54b9":"Avg_mintemp=[]\nfor i in m:\n    b=df[df['Location']==i]['MinTemp'].mean()\n    Avg_mintemp.append(b)\n    ","43dce2ce":"Avg_maxtemp=[]\nfor i in m:\n    b=df[df['Location']==i]['MaxTemp'].mean()\n    Avg_maxtemp.append(b)\n    \n","21d46ff0":"Avg_Rainfall=[]\nfor i in m:\n    b=df[df['Location']==i]['Rainfall'].mean()\n    Avg_Rainfall.append(b)\n    ","891968f1":"Avg_Evaporation=[]\nfor i in m:\n    b=df[df['Location']==i]['Evaporation'].mean()\n    Avg_Evaporation.append(b)\n    ","d1654187":"Avg_Sunshine=[]\nfor i in m:\n    b=df[df['Location']==i]['Sunshine'].mean()\n    Avg_Sunshine.append(b)\n    ","982c49ae":"Avg_WindGustSpeed=[]\nfor i in m:\n    b=df[df['Location']==i]['WindGustSpeed'].mean()\n    Avg_WindGustSpeed.append(b)\n    ","0af32002":"Avg_WindSpeed9am=[]\nfor i in m:\n    b=df[df['Location']==i]['WindSpeed9am'].mean()\n    Avg_WindSpeed9am.append(b)\n    ","f1389315":"Avg_WindSpeed3pm=[]\nfor i in m:\n    b=df[df['Location']==i]['WindSpeed3pm'].mean()\n    Avg_WindSpeed3pm.append(b)\n    ","7539b795":"Avg_Humidity9am=[]\nfor i in m:\n    b=df[df['Location']==i]['Humidity9am'].mean()\n    Avg_Humidity9am.append(b)\n    ","250c7a4a":"Avg_Humidity3pm=[]\nfor i in m:\n    b=df[df['Location']==i]['Humidity3pm'].mean()\n    Avg_Humidity3pm.append(b)\n    ","c3481e10":"Avg_Cloud9am=[]\nfor i in m:\n    b=df[df['Location']==i]['Cloud9am'].mean()\n    Avg_Cloud9am.append(b)","5dd82c35":"Avg_Cloud3pm=[]\nfor i in m:\n    b=df[df['Location']==i]['Cloud3pm'].mean()\n    Avg_Cloud3pm.append(b)","51f831fa":"Avg_Temp9am=[]\nfor i in m:\n    b=df[df['Location']==i]['Temp9am'].mean()\n    Avg_Temp9am.append(b)","3d0cd077":"Avg_Temp3pm=[]\nfor i in m:\n    b=df[df['Location']==i]['Temp3pm'].mean()\n    Avg_Temp3pm.append(b)","514b55fd":"data={'name':m,'Avg_mintemp':Avg_mintemp,'Avg_maxtemp':Avg_maxtemp,'Avg_Rainfall':Avg_Rainfall,'Avg_Evaporation':Avg_Evaporation,'Avg_Sunshine':Avg_Sunshine,'Avg_WindGustSpeed':Avg_WindGustSpeed,'Avg_WindSpeed9am':Avg_WindSpeed9am,'Avg_WindSpeed3pm':Avg_WindSpeed3pm,'Avg_Humidity9am':Avg_Humidity9am,'Avg_Humidity3pm':Avg_Humidity3pm,'Avg_Cloud9am':Avg_Cloud9am,'Avg_Cloud3pm':Avg_Cloud3pm,'Avg_Temp9am':Avg_Temp9am,'Avg_Temp3pm':Avg_Temp3pm}","21e95f21":"new = pd.DataFrame.from_dict(data)","c8feede4":"new","d6db8cde":"df2=new.drop('name',axis=1)\n","63a63812":"df2","1a50b044":"m1=df2.columns","7181a338":"import plotly.express as px\nfor i in m1:\n    fig = px.bar(x=new['name'],y=new[i])\n    fig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\n    fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n    fig.show()\n    ","75eece11":"plt.figure(figsize=(10,16))\nax = sns.heatmap(df.corr(),annot = True, cmap = 'viridis')\nplt.show()","84cb6e86":"df.isnull().sum()","b82988ba":"def median_null(df):\n    cateogry_columns=df.select_dtypes(include=['object']).columns.tolist()\n    integer_columns=df.select_dtypes(include=['int64','float64']).columns.tolist()\n    for column in df:\n        if df[column].isnull().any():\n            if(column in integer_columns):\n                df[column]=df[column].fillna(df[column].median())\n        else:\n            df[column]=df[column].fillna(df[column].mode()[0])    \n    return df       ","0cc8639c":"median_null(df)","b328e52e":"df.isnull().sum()","fa11b09a":"def LABEL_ENCODING(c1):\n    from sklearn import preprocessing\n    # label_encoder object knows how to understand word labels.\n    label_encoder = preprocessing.LabelEncoder()\n \n    # Encode labels in column 'species'.\n    df[c1]= label_encoder.fit_transform(df[c1].astype(str))\n \n    df[c1].unique()\n    return df","e46092f7":"LABEL_ENCODING('Location')","f87196cc":"LABEL_ENCODING('WindGustDir')","62451489":"LABEL_ENCODING('RainToday')","3cead8b7":"LABEL_ENCODING('RainTomorrow')","e486c5f8":"LABEL_ENCODING('WindDir9am')","3dcda84d":"LABEL_ENCODING('WindDir3pm')","48d5e4ea":"df['Date'] =pd.to_datetime(df['Date'])","a96ec9f6":"\ndf.dtypes","fbf34506":"df.isnull().sum()","2120eb25":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df.drop('Date',axis=1))","31950a3b":"feature=df.drop(['RainTomorrow','Date'],axis=1)","0a11193c":"feature","8a24d664":"label=df['RainTomorrow']","39a2ac87":"X_train,X_test,y_train,y_test=train_test_split(feature,label,test_size=.3)","72cfa73f":"print(X_train.shape,y_train.shape)","45ae8306":"print(X_test.shape,y_test.shape)","bbdcee5e":"knn = KNeighborsClassifier()","9a2b83b7":"knn.fit(X_train,y_train)","2570d295":"pred = knn.predict(X_test)\npred","f697a308":"from sklearn.metrics import classification_report, confusion_matrix","fa1f878f":"print(classification_report(y_test,pred))","c2b33d64":"cmat = confusion_matrix(y_test,pred)\nprint('TN - True Negative {}'.format(cmat[0,0]))\nprint('FP - False Positive {}'.format(cmat[0,1]))\nprint('FN - False Negative {}'.format(cmat[1,0]))\nprint('TP - True Positive {}'.format(cmat[1,1]))\nprint('Accuracy Rate: {}'.format(np.divide(np.sum([cmat[0,0],cmat[1,1]]),np.sum(cmat))))\nprint('Misclassification Rate: {}'.format(np.divide(np.sum([cmat[0,1],cmat[1,0]]),np.sum(cmat))))","d6ec051b":"# Feature Selection and Extraction","d854144d":"1)Location Darwin has highest average minimum temparture\n\n2)Location Katherin has highest average maximum temperature\n\n3)Location Carins has highest average Rainfall\n\n4)Location Woomera has highest average Evaporation\n\n5)Location Alicesprings has highest average Sunshine\n\n6)Location Hobart has highest average WindGustSpeed\n\n7)Location Melbourne Airport has highest average WindSpeed9am\n\n8)Location GoldCoast has highest average WindSpeed3pm\n\n9)Location Dartmoor has highest average Humidity9am\n\n10)Location Mountginnini has highest average Humidity3pm\n\n11)Location Albury has highest average Cloud9am\n\n12)Location Ballarat has highest average Cloud3pm\n\n13)Location Darwin has highest average Temp9am\n\n14)Location Katherine has highest average Temp3pm","c7f3d28b":"# Data Modelling","e8165b0e":"## Querying the Data","692edf63":"# Data Cleaning and Preproccessing","096e4352":"# Exploratory Data Ananlysis","901a4af2":"# Data Visualization ","da596b25":"# EDA Summary"}}