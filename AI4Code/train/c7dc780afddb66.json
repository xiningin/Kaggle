{"cell_type":{"12b8e736":"code","80ed6f18":"code","17062a08":"code","45815b76":"code","c4ecbbd4":"code","ab333a20":"code","b345380b":"code","7aa4fa6a":"code","0f88ab6e":"code","6a3799e0":"code","4ecc3a78":"code","17c289c5":"code","28cfa489":"code","e343ffb8":"code","2f6a4be1":"code","aaadac00":"code","4dec9721":"code","65bbe5d3":"markdown","3036a906":"markdown","c50b3660":"markdown","080d67be":"markdown","e28e2153":"markdown","c99692ae":"markdown","9c7e6d6e":"markdown"},"source":{"12b8e736":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pydicom\nfrom PIL import Image\nimport os\nimport cv2\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n","80ed6f18":"BASE_PATH = \"..\/input\/rsna-intracranial-hemorrhage-detection\/rsna-intracranial-hemorrhage-detection\/\"\nTRAIN_DIR = \"stage_2_train\/\"\n\ntrain_df = pd.read_csv(BASE_PATH + 'stage_2_train.csv')\ntrain_df['filename'] = train_df['ID'].apply(lambda st: \"ID_\" + st.split('_')[1] + \".png\")\ntrain_df['type'] = train_df['ID'].apply(lambda st: st.split('_')[2])\ntrain_df['id'] = train_df['ID'].apply(lambda st: st.split('_')[1])\n\n","17062a08":"fig, ax = plt.subplots(figsize=(15, 10))\nsns.countplot(train_df.Label,ax=ax)\nax.set_xlabel(\"Label\")\nax.set_ylabel(\"Count\")\nax.set_title(\"Label distribution\")","45815b76":"fig, ax = plt.subplots(figsize=(15, 10))\nplt.rcParams['axes.labelsize'] = 20\nplt.rcParams['axes.titlesize'] = 20\ntype_counts = train_df.groupby(\"type\").Label.value_counts().unstack()\ntrue_cases = type_counts.loc[:,1] \/ train_df.groupby(\"type\").size() * 100\nsns.barplot(x=true_cases.index,y=true_cases.values,ax=ax)\nplt.yticks(rotation=0,size=15)\nplt.xticks(rotation=0,size=15)\nax.set_xlabel(\"ICH Type\")\nax.set_ylabel(\"%\")\nax.set_title(\"Type distribution\",pad=20)","c4ecbbd4":"fig, ax = plt.subplots(figsize=(15, 10))\nmulti_count = train_df.groupby(\"id\").Label.sum()\nsns.countplot(multi_count,ax=ax)\nax.set_title(\"Co-occurences\")\nax.set_xlabel(\"Targets per image\")\nax.set_ylabel(\"Frequency\")","ab333a20":"df = train_df[['Label', 'filename', 'type']].drop_duplicates().pivot(\n    index='filename', columns='type', values='Label').reset_index()","b345380b":"df[df['any']==1]['any'].count()","7aa4fa6a":"df[df['any']==0]['any'].count()","0f88ab6e":"df.count()","6a3799e0":"\ncols = ['epidural','intraparenchymal','intraventricular','subarachnoid','subdural']\nlabels = df[cols]\noutput = pd.DataFrame(\n{x:[(df[x] & df[y]).sum() for y in cols] for x in cols},\nindex=cols)\noutput\n","4ecc3a78":"#output\noutput[\"epidural\"][output[\"epidural\"].index != \"epidural\"].sum()","17c289c5":"normalized_df = output.copy().astype(np.float32)\nfor col in cols:\n    total = output[col][col]\n    total_col = total - output[col][output[col].index != col].sum()\n    normalized_df[col][col] = total_col \/ total\n    for other in cols:\n        if other == col:\n            continue\n        normalized_df[col][other] = output[col][other] \/ total\nnormalized_df","28cfa489":"sum(normalized_df['epidural'])","e343ffb8":"normalized_df = normalized_df.rename({\n    \"epidural\":\"EDH\",\n    \"intraparenchymal\":\"IPH\",\n    \"intraventricular\":\"IVH\",\n    \"subarachnoid\":\"SAH\",\n    \"subdural\":\"SDH\"\n},axis=\"index\")\nnormalized_df = normalized_df.rename(index=str,columns={\n    \"epidural\":\"EDH\",\n    \"intraparenchymal\":\"IPH\",\n    \"intraventricular\":\"IVH\",\n    \"subarachnoid\":\"SAH\",\n    \"subdural\":\"SDH\"\n})","2f6a4be1":"plt.rcParams['axes.labelsize'] = 40\nplt.rcParams['axes.titlesize'] = 20\nfig, ax = plt.subplots(figsize=(15, 10))\n\nsns.heatmap(normalized_df,ax=ax,annot=True,annot_kws={\"size\": 20})\nfor i in np.arange(0,5,1.0):\n    ax.axvline(i, color='white', lw=10)\nplt.yticks(rotation=0,size=20)\nplt.xticks(rotation=0,size=20)\nax.set_title(\"Co-occurring haemorrhages matrix\",pad=20)\n#ax.set_title(\"Co-occurence Matrix\")","aaadac00":"ax.get_xticks()","4dec9721":"#for i in range(type_list):\n#    title = cols[i]\n#    dataset = type_list[i]\n#    fig,ax = plt.subplots()\n#    sns.countplot(dataset,ax=ax)\n#    plt.show()","65bbe5d3":"**Label distribution plot**","3036a906":"CSV file is read in here and transformed for processing later.\n\nAdditional columns are generated to make later operations easier","c50b3660":"**Type distribution plot**","080d67be":"**Label co-occurence matrix**","e28e2153":"**Exploratory Data Analysis and Graph generation**\n\nMany thanks to Laura Fink and her EDA notebooks which can be found [here](https:\/\/www.kaggle.com\/allunia\/rsna-ih-detection-eda)\n\n*Abdullah Hasan*","c99692ae":"**Label co-occurence plot**","9c7e6d6e":"**Co-occurence matrix plot**"}}