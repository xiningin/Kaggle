{"cell_type":{"87b638e8":"code","244936cf":"code","a06305b1":"code","8ba6ad2c":"code","266d1c0a":"code","3994c5d6":"code","1b8cdc9a":"code","1a027ef4":"code","a461e726":"code","c8ee5221":"code","efa85367":"code","e6466b1a":"markdown","db2f5dd3":"markdown","e5629ead":"markdown","dc075801":"markdown","075acf51":"markdown","ede8a151":"markdown","ec5be3d6":"markdown","cdc601c9":"markdown"},"source":{"87b638e8":"import numpy as np\nimport pandas as pd\nfrom textblob import TextBlob\nimport matplotlib.pyplot as plt","244936cf":"#https:\/\/stackoverflow.com\/questions\/18171739\/unicodedecodeerror-when-reading-csv-file-in-pandas-with-python\ntweets = pd.read_csv('..\/input\/TweetsNBA.csv', encoding = \"ISO-8859-1\")\ntweets = tweets.loc[tweets['lang'] == 'en']","a06305b1":"#https:\/\/textblob.readthedocs.io\/en\/dev\/quickstart.html\n#https:\/\/textblob.readthedocs.io\/en\/dev\/api_reference.html#textblob.en.sentiments.PatternAnalyzer\ntweets['polarity'] = tweets['text'].apply(lambda x: TextBlob(x).polarity)","8ba6ad2c":"tweets['subjectivity'] = tweets['text'].apply(lambda x: TextBlob(x).subjectivity)","266d1c0a":"Unverified = tweets.loc[tweets['verified'] == False]\nVerified = tweets.loc[tweets['verified'] == True]\nprint('Verified Subjectivity: {}'.format(Verified['subjectivity'].mean()))\nprint('Unverified Subjectivity: {}'.format(Unverified['subjectivity'].mean()))","3994c5d6":"#https:\/\/stackoverflow.com\/questions\/35595710\/splitting-timestamp-column-into-seperate-date-and-time-columns\ntweets['created_at'] = pd.to_datetime(tweets['created_at'])","1b8cdc9a":"#https:\/\/stackoverflow.com\/questions\/16266019\/python-pandas-group-datetime-column-into-hour-and-minute-aggregations\/32066997\nGame3 = tweets.groupby(tweets['created_at'].dt.minute)['polarity'].mean()\n\nplt.figure(figsize = (20,10))\nplt.suptitle('Total Game 3 Polarity', fontsize = 24)\nplt.xlabel('Time', fontsize = 20)\nplt.ylabel(\"Polarity\", fontsize = 20)\nplt.plot(Game3)\nplt.gcf().autofmt_xdate()\nplt.show()","1a027ef4":"tweets['cavs'] = tweets['text'].str.contains('cav',regex = False, case = False)\nCavs_Tweets = tweets.loc[tweets['cavs'] == True]","a461e726":"tweets['warriors'] = tweets['text'].str.contains('warriors',regex = False, case = False)\nWarriors_Tweets = tweets.loc[tweets['warriors'] == True]","c8ee5221":"Game3_Cavs = Cavs_Tweets.groupby(Cavs_Tweets['created_at'].dt.minute)['polarity'].mean()\n\nplt.figure(figsize = (20,10))\nplt.suptitle('Cavs Game 3 Polarity', fontsize = 24)\nplt.xlabel('Time', fontsize = 20)\nplt.ylabel(\"Polarity\", fontsize = 20)\nplt.plot(Game3_Cavs)\nplt.gcf().autofmt_xdate()\nplt.show()","efa85367":"Games3_Warriors = Warriors_Tweets.groupby(Warriors_Tweets['created_at'].dt.minute)['polarity'].mean()\n\nplt.figure(figsize = (20,10))\nplt.suptitle('Warriors Game 3 Polarity', fontsize = 24)\nplt.xlabel('Time', fontsize = 20)\nplt.ylabel(\"Polarity\", fontsize = 20)\nplt.plot(Games3_Warriors)\nplt.gcf().autofmt_xdate()\nplt.show()","e6466b1a":"The next two lines of code help to create new columns in our dataset for polarity and subjectivity of each tweet. Polarity is a number measured between -1 and 1, with -1 being very negative, 0 being neutral, and 1 being very positive. Subjectivity is a number measured between 0 and 1 with 0 being \"very objective\" and 1 being \"very subjective.\"\n\nMore information: https:\/\/textblob.readthedocs.io\/en\/dev\/quickstart.html#sentiment-analysis","db2f5dd3":"Below are the average polarities of each team grouped by time. ","e5629ead":"Since I am not very familiar with Twitter data, or text data in general, leave comments down below as to how you would improve this analysis, ideas for future analysis, or if there is anything that I missed.","dc075801":"#Introduction\n\nWith the NBA season coming up soon, I wanted to do a fun analysis on NBA Twitter data. This is the first time I can remember working with Twitter data so this kernel contained a huge learning curve for me. This kernel will use Textblob (https:\/\/textblob.readthedocs.io\/en\/dev\/), which I am slightly familiar with, in order to measure the polarity and subjectivity of tweets from Game 3 of the 2018 NBA Finals.","075acf51":"Let's take a look at the difference in subjectivity between verified and unverifeid Twitter accounts. It appears that verified accounts are slightly more subjective on average than unverified accounts.  With all of this being said, we still do not know if this difference is statistically significant. The issue of statistical significance could be solved by using a potential t-test or other forms of hypothesis testing.","ede8a151":"The next two graphs attempt to look at tweets that contain Cavaliers and Warriors specifically. The goal of the code below is to filter out tweets that contain the text \"cav\" and \"warriors\" which corresponds with the Twitter handle of each team.","ec5be3d6":"After changing the created_at column to datetime we can now group the data by minute and see how polarity changes. Very early on in the game there seems to be a big increase in the average polarity which could potentially be because of a dunk by Lebron James. \n\nVideo of Dunk: https:\/\/www.youtube.com\/watch?v=oDBLGk12zB4 \n\nFurther Reading: https:\/\/www.kaggle.com\/xvivancos\/eda-tweets-during-cavaliers-vs-warriors","cdc601c9":"Now let's attempt to make a graph that measures how polarity changes over time. To do this we must change the created_at column to datetime (https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.to_datetime.html)."}}