{"cell_type":{"b9904be3":"code","dd1b2299":"code","59b15b69":"code","8a975d6a":"code","83d14c02":"code","29ce9804":"code","3d749ff8":"code","3d5ea811":"code","49ef80cc":"code","58cf97ff":"code","8b7bb705":"code","051fe056":"markdown","6797d64a":"markdown","e79bcdf9":"markdown"},"source":{"b9904be3":"import numpy as np\nimport cv2\nimport os\nimport keras\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import *\nfrom keras import optimizers\nfrom keras.models import Sequential, Model\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import EfficientNetB7\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import classification_report, confusion_matrix","dd1b2299":"Path_train = '..\/input\/pile-burn-ic\/Data_Fire\/Training'\n\nX = []\nY = []\n\nfor labels in os.listdir(Path_train):\n    path = os.path.join(Path_train, labels)\n    for images in os.listdir(path):\n        path1 = os.path.join(path,images)\n        img = cv2.imread(path1)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (112,112), interpolation = cv2.INTER_AREA)\n        img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n        img_hsv[:,:,2] = cv2.equalizeHist(img_hsv[:,:,2])\n        img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n        X.append(img)\n        Y.append(labels)","59b15b69":"plt.figure(figsize=(12,12))\nplt.subplot(1,2,1)\nplt.imshow(X[1])\nplt.title(Y[1])\nplt.subplot(1,2,2)\nplt.imshow(X[20000])\nplt.title(Y[20000])","8a975d6a":"X = np.array(X)\nX = X.reshape(X.shape[0],112,112,3)\nlabel = LabelEncoder()\nY = label.fit_transform(Y)\nY = to_categorical(Y,2)\nprint(X.shape)\nprint(Y.shape)","83d14c02":"x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)","29ce9804":"EfficientNetB7_ = EfficientNetB7(include_top = False, input_shape = (112,112,3), pooling='avg')\nEfficientNetB7_.trainable = False\nmodel = Sequential()\nmodel.add(EfficientNetB7_)\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(units=2, activation='softmax'))","3d749ff8":"checkpoint = ModelCheckpoint('.\/model_3.h5',\n                             monitor = 'val_loss',\n                             mode = 'min',\n                             save_best_only=True,\n                             verbose = 1\n                            )\n\ncallbacks = [checkpoint]\noptimizers = keras.optimizers.Adam(0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizers, metrics=[\"accuracy\"])\n\nhistory = model.fit(x = x_train, y = y_train, epochs=10, batch_size = 8, validation_data=(x_test,y_test), callbacks =callbacks, verbose = 1)","3d5ea811":"from keras.models import load_model\nmodel = load_model('.\/model_3.h5')","49ef80cc":"y_test_ = np.argmax(y_test, axis=1)\ny_pred_ = model.predict_classes(x_test)\n\nprint('Classification Report \\n')\nprint(classification_report(y_test_, y_pred_, target_names = ['Fake','Real']))","58cf97ff":"import itertools\nplt.figure(figsize=(8,8))\n\nclasses = 2\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n\nconfusion_mtx = confusion_matrix(y_test_, y_pred_) \nplot_confusion_matrix(confusion_mtx, classes = range(2))","8b7bb705":"Path_test = '..\/input\/pile-burn-ic\/Data_Fire\/Test'\n\nX = []\nY = []\n\nfor labels in os.listdir(Path_test):\n    path = os.path.join(Path_test, labels)\n    for images in os.listdir(path):\n        path1 = os.path.join(path,images)\n        img = cv2.imread(path1)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (112,112), interpolation = cv2.INTER_AREA)\n        img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n        img_hsv[:,:,2] = cv2.equalizeHist(img_hsv[:,:,2])\n        img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n        X.append(img)\n        Y.append(labels)\n        \nX = np.array(X)\nX = X.reshape(X.shape[0],112,112,3)\n#X = X\/255\nlabel = LabelEncoder()\nY = label.fit_transform(Y)\nY = to_categorical(Y,2)\n\nScore = model.evaluate(X,Y)\nprint('Test Accuracy:', Score[1])","051fe056":"# Drone-based Pile Burn Image Classification for \u2019Fire-vs-No Fire\u2019","6797d64a":"# Testing","e79bcdf9":"### Loading Libraries"}}