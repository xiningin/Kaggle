{"cell_type":{"715d46fc":"code","10935f8e":"code","6f353a2e":"code","6d8a5526":"code","21ee35a2":"code","3d99a996":"code","822a749b":"code","c95bccfe":"code","612c0327":"code","667f770a":"code","e399e00f":"code","032d5c23":"code","ab9d088d":"code","ce8018b0":"code","56c1532d":"code","4ec01baf":"code","527da921":"code","d4e3fc35":"code","9eed78ca":"code","6217b4e8":"code","f6b95cbe":"code","11d1cfb5":"code","20ff8523":"code","98c33a7e":"code","7943174e":"code","c3048933":"code","cc36cfc3":"code","5ae7f0c9":"code","ada13b58":"code","d449a8f5":"code","8cc00bca":"code","6fc1ca2d":"code","22dacca7":"code","ec110e4b":"code","0e133582":"code","8bca2276":"code","2ec44c4e":"code","4237dd09":"markdown","d4a82005":"markdown","2b4910d1":"markdown","9366906a":"markdown","a8a7e2f5":"markdown","4a12c7a0":"markdown","738cb45b":"markdown","1f13595a":"markdown","6a8b9263":"markdown","56ee9c66":"markdown","cdbe52ec":"markdown","a6e1c870":"markdown","72519bbd":"markdown","45123599":"markdown","9cb6de80":"markdown","790a1cca":"markdown","31980cea":"markdown","34eedd22":"markdown","9aafae32":"markdown","0ccd7679":"markdown","3852b97f":"markdown"},"source":{"715d46fc":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport scipy as sp\nimport string\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","10935f8e":"data = pd.read_csv(\"..\/input\/tweets-sentiment-analysis\/train.csv\", encoding='ISO-8859-1')","6f353a2e":"data","6d8a5526":"data.head()","21ee35a2":"data.info()","3d99a996":"data.describe()","822a749b":"data.value_counts()","c95bccfe":"data.dtypes","612c0327":"data.shape","667f770a":"data.columns","e399e00f":"data.describe().transpose()\n","032d5c23":"data.var()","ab9d088d":"data.isnull().sum()\n","ce8018b0":"data.isnull().any()\n","56c1532d":"data.corr()","4ec01baf":"plt.figure(figsize = (16,10))\n\nsns.heatmap(data.corr(), annot =True)\n","527da921":"data.hist(figsize=(18,12))\nplt.show()\n","d4e3fc35":"plt.style.use(\"default\")\nsns.barplot(x=\"ItemID\", y=\"SentimentText\",data=data[180:190])\nplt.title(\"ItemID vs SentimentText\",fontsize=15)\nplt.xlabel(\"ItemID\")\nplt.ylabel(\"SentimentText\")\nplt.show()","9eed78ca":"sns.set_palette(\"Paired\")\nsns.pairplot(data,hue='Sentiment',height=5.5,palette='colorblind')\nplt.show()\n","6217b4e8":"data.columns","f6b95cbe":"\nplt.figure(figsize=(14,10))\nsns.set_style(style='darkgrid')\nplt.subplot(2,3,1)\nsns.boxplot(x='Sentiment',data=data)\nplt.subplot(2,3,2)\nsns.boxplot(x='ItemID',data=data)\n","11d1cfb5":"plt.style.use(\"ggplot\")\nplt.figure(figsize=(12,8))\nplt.xlabel('Sentiment')\nplt.ylabel('SentimentText')\nsns.kdeplot(data['Sentiment'],shade=True,color='blue')\nplt.show()\n","20ff8523":"import nltk\nimport scikitplot as skplt\nimport re\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nSTOPWORDS = stopwords.words('english')\n","98c33a7e":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^0-9a-zA-Z]', ' ', text)\n    text = re.sub(r'\\s+', ' ', text)\n    text = \" \".join(word for word in text.split() if word not in STOPWORDS)\n    return text\n","7943174e":"data['clean_text'] = data['SentimentText'].apply(clean_text)\ndata.head()\n","c3048933":"X = data['clean_text']\ny = data['Sentiment']\n","cc36cfc3":"from nltk.stem import PorterStemmer\nfrom nltk.tokenize import sent_tokenize,word_tokenize\nps=PorterStemmer\nwords=word_tokenize('clean_text')\n","5ae7f0c9":"#importing the CountVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n#lemmatizer=WordNetLemmatizer()\n","ada13b58":"#define a function to get rid of stopwords present in the messages\ndef message_text_process(mess):\n    # Check characters to see if there are punctuations \n    no_punctuation=[char for char in mess if char not in string.punctuation]\n    # now form the sentence\n    no_punctuation=''.join(no_punctuation)\n    # Now eliminate any stopwords\n    return[word for word in no_punctuation.split() if word.lower() not in stopwords.words('english')]\n","d449a8f5":"data['SentimentText'].head(5).apply(message_text_process)\n","8cc00bca":"# start text processing with vectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer","6fc1ca2d":"from sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer","22dacca7":"def classify(model, X, y):\n    # train test split\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True, stratify=y)\n    # model training\n    pipeline_model = Pipeline([('vect', CountVectorizer()),\n                              ('tfidf', TfidfTransformer()),\n                              ('clf', model)])\n    pipeline_model.fit(x_train, y_train)\n    \n    print('Accuracy:', pipeline_model.score(x_test, y_test)*100)\n    \n    print(\"Training Score:\\n\",pipeline_model.score(x_train,y_train)*100)\n\n\n    y_pred = pipeline_model.predict(x_test)\n    y_probas =pipeline_model.predict_proba(x_test)\n    skplt.metrics.plot_roc(y_test,y_probas,figsize=(10,6),title_fontsize=14,text_fontsize=12)\n    plt.show()\n    skplt.metrics.plot_precision_recall(y_test,y_probas,figsize=(10,6),title_fontsize=14,text_fontsize=12)\n    plt.show()\n    skplt.estimators.plot_learning_curve(pipeline_model, X,y,figsize=(10,6),title_fontsize=14,text_fontsize=12)\n    plt.show()\n    skplt.metrics.plot_lift_curve(y_test,y_probas,figsize=(10,6),title_fontsize=14,text_fontsize=12)\n    plt.show()\n    skplt.metrics.plot_confusion_matrix(y_test,y_pred,figsize=(10,6),title_fontsize=14,text_fontsize=12,cmap=plt.cm.Pastel1)\n    plt.show()\n    print(classification_report(y_test, y_pred))\n","ec110e4b":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nclassify(model, X, y)\n","0e133582":"from sklearn import tree\ntree_clf = tree.DecisionTreeClassifier(max_depth = 2)\nclassify(tree_clf,X,y)\ntree.plot_tree(tree_clf)\n","8bca2276":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()\nclassify(model, X, y)\n\n","2ec44c4e":"from sklearn.ensemble import AdaBoostClassifier\nmodel= AdaBoostClassifier(base_estimator = None)\nclassify(model, X, y)\n","4237dd09":"# IMPORTING THE LIBRARIES","d4a82005":"# **Tweets Sentiment Analysis**","2b4910d1":"# LOADING THE DATASET","9366906a":"**BOXPLOT**\n\n**A boxplot is a standardized way of displaying the distribution of data based on a five number summary (\u201cminimum\u201d, first quartile (Q1), median, third quartile (Q3), and \u201cmaximum\u201d). ... It can also tell you if your data is symmetrical, how tightly your data is grouped, and if and how your data is skewed.**","a8a7e2f5":"**NAIVE BAYES**\n\n**Na\u00efve Bayes algorithm is a supervised learning algorithm, which is based on Bayes theorem and used for solving classification problems. ... Na\u00efve Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building the fast machine learning models that can make quick predictions.**\n\n**In Naive Bayes we can use :**\n\n*** GaussianNB**\n\n*** BernoulliNB**\n\n*** MultinomialNB**\n\n\n","4a12c7a0":"**PAIRPLOT**\n\n**pairplot() : To plot multiple pairwise bivariate distributions in a dataset, you can use the pairplot() function. This shows the relationship for (n, 2) combination of variable in a DataFrame as a matrix of plots and the diagonal plots are the univariate plots.**","738cb45b":"**Decision Tree Classifier**\n\n**Decision Trees are a non-parametric supervised learning method used for both classification and regression tasks. ... Tree models where the target variable can take a discrete set of values are called classification trees.**\n","1f13595a":"**BARPLOT**\n\n**A barplot (or barchart) is one of the most common types of graphic. It shows the relationship between a numeric and a categoric variable. Each entity of the categoric variable is represented as a bar. The size of the bar represents its numeric value.**\n","6a8b9263":"# **Exploratory Data Analysis**","56ee9c66":"# NLTK","cdbe52ec":"![](https:\/\/miro.medium.com\/max\/1000\/1*vp1M37AGMOFwCvLxVm62IA.jpeg)","a6e1c870":"**ADA BOOST CLASSIFIER**\n\n**Ada-boost or Adaptive Boosting is one of ensemble boosting classifier proposed by Yoav Freund and Robert Schapire in 1996. It combines multiple classifiers to increase the accuracy of classifiers. ... Any machine learning algorithm can be used as base classifier if it accepts weights on the training set.**","72519bbd":"**LOGISTIC REGRESSION**\n\n**Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).**\n","45123599":"# **Checking Null Values**","9cb6de80":"**KDE PLOT**\n\n**Kdeplot is a Kernel Distribution Estimation Plot which depicts the probability density function of the continuous or non-parametric data variables i.e. we can plot for the univariate or multiple variables altogether. Using the Python Seaborn module, we can build the Kdeplot with various functionality added to it.**\n","790a1cca":"**A heatmap is a graphical representation of data in two-dimension, using colors to demonstrate different factors. Heatmaps are a helpful visual aid for a viewer, enabling the quick dissemination of statistical or data-driven information.**","31980cea":"**Conclusion**\n\n**From executing all the algorithms , Naive Bayes got a training accuracy of 88% , then logistic regression with 84% training accuracy score which is quite well for the given dataset**","34eedd22":"**HEATMAP**","9aafae32":"# **MODEL BUILDING**","0ccd7679":"**HISTPLOT**\n\n**Histograms represent the data distribution by forming bins along the range of the data and then drawing bars to show the number of observations that fall in each bin. Seaborn comes with some datasets and we have used few datasets in our previous chapters.**\n","3852b97f":"**Thank You**"}}