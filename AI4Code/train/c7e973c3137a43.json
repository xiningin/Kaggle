{"cell_type":{"aff04481":"code","3ae81db6":"code","9274daac":"code","27b95df9":"code","9e4450fe":"code","7024e874":"code","e913908f":"code","de2a07e0":"code","897d0548":"code","d303499d":"code","4270442b":"code","e0bc0136":"code","0ca2e21f":"code","fcf38e5f":"code","ffc7f8c4":"code","4279aee2":"code","7fdd5220":"code","c8f2b84c":"code","7a3eab3b":"code","daa60417":"code","60445760":"code","bf38300e":"code","d9e2508a":"code","e5137e32":"code","fb1dbc22":"code","32114788":"code","cb0f2fd9":"code","bfa0b887":"code","b2e2b098":"code","7c0a68a5":"code","cb37c495":"code","f787f11f":"code","6e06b64a":"code","112ef7d8":"code","a6b98da6":"code","fb2b601e":"code","3d93ffaa":"code","e7f7b392":"code","e6566763":"code","1a417930":"code","be7e038c":"code","3f0c93c7":"code","0b5fe52b":"code","0cf8a670":"code","528626fc":"code","df1f5a83":"code","048d6889":"code","24970051":"code","5a3406e5":"code","3b5f3057":"code","6c31f0c8":"markdown","790bc375":"markdown","e8a74ad1":"markdown","bd869c0a":"markdown","b8cd30be":"markdown","0c207327":"markdown","6f67e050":"markdown","310f1122":"markdown","169ed169":"markdown","b702571e":"markdown","23d51947":"markdown","5ca26d0a":"markdown","6f0e0b53":"markdown","3f3f0154":"markdown","be6b3f68":"markdown","eb301e38":"markdown","e160fd4a":"markdown","7c7955f0":"markdown","3227a7ec":"markdown","7a84af17":"markdown","ccb1890f":"markdown","ec5b891a":"markdown","27f972df":"markdown","34ce69e0":"markdown","f8c4f5d2":"markdown","3a156797":"markdown","bf69409b":"markdown","5d61da6b":"markdown","83e5b877":"markdown","1080aad8":"markdown","fd808651":"markdown","eaf6a8b4":"markdown","2a7d3409":"markdown","19ca0d7d":"markdown","0f932b40":"markdown","be252b89":"markdown","c3080b83":"markdown"},"source":{"aff04481":"from warnings import filterwarnings\nfilterwarnings('ignore')\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy as sp\nfrom sklearn.cluster import KMeans","3ae81db6":"df = pd.read_csv('..\/input\/customer-segmentation\/customer_segmentation.csv').copy()","9274daac":"df.head()","27b95df9":"df.shape","9e4450fe":"df.info()","7024e874":"df.isna().sum()","e913908f":"df.describe().T","de2a07e0":"df.hist(figsize = (10,10));","897d0548":"kmeans = KMeans()\nkmeans","d303499d":"k_means_model = kmeans.fit(df)","4270442b":"k_means_model.n_clusters","e0bc0136":"k_means_model.cluster_centers_","0ca2e21f":"k_means_model.labels_","fcf38e5f":"from yellowbrick.cluster import KElbowVisualizer\nkmeans = KMeans()\nvisualizer = KElbowVisualizer(kmeans, k=(2,11))\nvisualizer.fit(df) \nvisualizer.poof()","ffc7f8c4":"sonuclar = []","4279aee2":"for i in range(1,11):\n    k_means = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n    k_means.fit(df)\n    sonuclar.append(k_means.inertia_)","7fdd5220":"sonuclar","c8f2b84c":"plt.plot(range(1,11), sonuclar)\nplt.show()","7a3eab3b":"kmeans = KMeans(n_clusters = 4)\nkmeans","daa60417":"k_means_model = kmeans.fit(df)","60445760":"k_means_model.n_clusters","bf38300e":"k_means_model.cluster_centers_","d9e2508a":"k_means_model.labels_","e5137e32":"kumeler = k_means_model.labels_","fb1dbc22":"plt.scatter(df[\"maas\"], df[\"aylik_harcama\"], c = kumeler, s = 50, cmap = \"rainbow\")\n\nmerkezler = k_means_model.cluster_centers_\n\nplt.scatter(merkezler[:,0], merkezler[:,1], c = \"black\", s = 200, alpha = 0.5);","32114788":"from mpl_toolkits.mplot3d import Axes3D","cb0f2fd9":"fig = plt.figure()\nfig.set_size_inches(24, 20, 24)\nax = Axes3D(fig)\nax.scatter(df[\"maas\"], df[\"aylik_harcama\"], df[\"yas\"], c=kumeler,  cmap = \"rainbow\")\nax.scatter(merkezler[:, 0], merkezler[:, 1], merkezler[:, 3], \n           marker='*', \n           c='#050505',\n           cmap = \"rainbow\",\n           s=1000);\nplt.show()","bfa0b887":"df_kumelenmis = df.copy()","b2e2b098":"df_kumelenmis[\"kume_no\"] = kumeler","7c0a68a5":"df_kumelenmis.head(10)","cb37c495":"from sklearn.cluster import AgglomerativeClustering","f787f11f":"ac = AgglomerativeClustering(n_clusters=4, affinity=\"euclidean\", linkage=\"ward\")\nac_model = ac.fit(df)","6e06b64a":"kumeler_ac = ac_model.labels_","112ef7d8":"plt.scatter(df[\"maas\"], df[\"aylik_harcama\"], c = kumeler_ac, s = 50, cmap = \"rainbow\")","a6b98da6":"import scipy.cluster.hierarchy as sch","fb2b601e":"dendogram = sch.dendrogram(sch.linkage(df, method=\"ward\"))\nplt.show()","3d93ffaa":"dendogram = sch.dendrogram(sch.linkage(df, method=\"ward\"), truncate_mode = \"lastp\", p = 4)\nplt.show()","e7f7b392":"kumeler_ac","e6566763":"df_kumelenmis[\"kume_no_ac\"] = kumeler_ac","1a417930":"df_kumelenmis.head(10)","be7e038c":"farklilik = 0\nfor i in df_kumelenmis.index:\n    if df_kumelenmis.loc[i,\"kume_no\"] != df_kumelenmis.loc[i,\"kume_no_ac\"]:\n        farklilik = farklilik + 1\n    else:\n        continue\nprint(farklilik, \"g\u00f6zlem farkl\u0131 k\u00fcmelenmi\u015ftir.\")","3f0c93c7":"plt.scatter(df[\"maas\"], df[\"aylik_harcama\"], c = kumeler_ac, s = 50, cmap = \"rainbow\")\nplt.show()\nplt.scatter(df[\"maas\"], df[\"aylik_harcama\"], c = kumeler, s = 50, cmap = \"rainbow\")\nplt.show()","0b5fe52b":"from sklearn.preprocessing import StandardScaler\n\ndf = StandardScaler().fit_transform(df)\ndf[0:6,0:5]","0cf8a670":"from sklearn.decomposition import PCA\npca = PCA(n_components = 3)\npca_fit = pca.fit_transform(df)","528626fc":"pca_fit[:5,:5]","df1f5a83":"bilesen_df = pd.DataFrame(data = pca_fit, \n                          columns = [\"component_1\",\"component_2\",\"component_3\"])","048d6889":"bilesen_df.head()","24970051":"pca.explained_variance_ratio_","5a3406e5":"pca = PCA().fit(df)","3b5f3057":"plt.plot(np.cumsum(pca.explained_variance_ratio_))","6c31f0c8":"G\u00f6rselle\u015ftime i\u015flemine ge\u00e7meden \u00f6nce optimum K de\u011ferimizi bulal\u0131m.","790bc375":"G\u00fczel optimum k\u00fcme say\u0131m\u0131z\u0131 da belirledi\u011fimize g\u00f6re modelimizi tekrardan fit edip \u00e7al\u0131\u015ft\u0131ral\u0131m ve g\u00f6rselle\u015ftimne yapal\u0131m.","e8a74ad1":"**Dendogram** nedir biraz bahsedelim Dendogram bizim verilerimizin (g\u00f6zlemlerimizin) birbirine olan mesafelerine g\u00f6re bir a\u011fa\u00e7 yap\u0131s\u0131nda ifade edilmesidir. Ka\u00e7 adet k\u00fcme ile verilerimizi k\u00fcmelememiz gerekti\u011fi konusunda bize bilgi veren bir g\u00f6rseldir en uzun bacak genelde en ideal k\u00fcme say\u0131s\u0131n\u0131 verir.","bd869c0a":"Peki \u00f6yleyse yava\u015ftan verimizi k\u00fcmelemeye ge\u00e7elim.","b8cd30be":"Temel fikir \u00e7ok de\u011fi\u015fkenli verinin ana \u00f6zelliklerini daha az say\u0131da de\u011fi\u015fken ile ifade etmektir. Buradaki olay Feature Selection'dan farkl\u0131d\u0131r \u00e7\u00fcnk\u00fc orada olan \u00f6zniteliklerin bir ka\u00e7\u0131n\u0131n se\u00e7ilmesiydi fakat burada bir se\u00e7im i\u015flemi yok kendimiz istedi\u011fimiz say\u0131da de\u011fi\u015fken yarat\u0131p daha az de\u011fi\u015fken ile kontrol edilebilir i\u015flem yapmam\u0131z\u0131 sa\u011flar. Fakat bir miktar bilgi kayb\u0131 olmaktad\u0131r.","0c207327":"# Modelin Tekrardan Fit Edilip G\u00f6rselle\u015ftirilmesi","6f67e050":"# K-MEANS Modeli","310f1122":"Bu kadar anlat\u0131m yeter art\u0131k kodlamaya ge\u00e7elim.","169ed169":"Ne yapt\u0131m k\u0131saca bahsedeyim sonu\u00e7lar diye bir liste olu\u015fturup. WCSS de\u011ferlerini 1 ile 11 aras\u0131nda her k\u00fcme de\u011feri i\u00e7in deniyoruz. burada bir random_state belirttim onun hikmeti de \u015fu, k\u00fcmeleme yaparken bir rasgele nokta se\u00e7ip t\u00fcm i\u015flemlere ba\u015flar ama biz bir random state belirleyerek her modelde bunun ayn\u0131 kalmas\u0131n\u0131 sa\u011flam\u0131\u015f olduk.","b702571e":"Tabi k\u00fcmeler aras\u0131ndaki mesafeyi \u00f6l\u00e7me y\u00f6ntemimiz dendogram\u0131n ve k\u00fcmelenmi\u015f verilerin g\u00f6r\u00fcn\u00fcm\u00fcn\u00fc de\u011fi\u015ftirecektir. K\u00fcmeler aras\u0131 mesafeyi \u00f6l\u00e7mek i\u00e7in minimum maksimum veya ortalama olan uzakl\u0131klar\u0131n\u0131 baz alabiliriz ama ben \"ward\" denilen daha \u00f6ncesinde bahsetti\u011fim WCSS de\u011ferlerinin hesaplanmas\u0131 ile bir sonu\u00e7 d\u00f6d\u00fcren ve buna g\u00f6re i\u015flem yapan bir paramtre ben onu kullanmay\u0131 tercih ettim.","23d51947":"3 boyutlu olarak da maa\u015f, ayl\u0131k_harcama ve ya\u015f \u00f6zniteliklerinin nas\u0131l k\u00fcmelendi\u011fini de bu \u015fekilde g\u00f6stermi\u015f olal\u0131m.","5ca26d0a":"Peki k\u00fcmelemeyi neye g\u00f6re yap\u0131yor algoritma asl\u0131nda 5 ad\u0131mdan olu\u015fuyor:\n\n**1)** \u00d6ncelikle ka\u00e7 tane k\u00fcmeye ay\u0131rmak istedi\u011fimizi belirliyoruz. \n\n**2)** Se\u00e7ilen k\u00fcme say\u0131s\u0131 kadar rastgele bir k\u00fcme merkezi (centroid) se\u00e7milir. \n\n**3)**  Se\u00e7ilen bu k\u00fcme merkezlerine en yak\u0131n noktalar\u0131 bulunur ve ilgili k\u00fcmeye atan\u0131r.\n\n**4)**  Yeni bir k\u00fcme merkezi hesaplan\u0131r. \n\n**5)** 3. ve 4. ad\u0131mlar optimum seviyeye ula\u015fana kadar ger\u00e7ekle\u015fir.","6f0e0b53":"**within cluster sum of squares (WCSS)** de\u011feri ile optimum k\u00fcme say\u0131m\u0131z\u0131 belileyece\u011fiz \u015fu \u015fekilde \u00e7al\u0131\u015f\u0131yor bu kural: Her noktan\u0131n merkeze olan uzakl\u0131\u011f\u0131n\u0131n kareleri al\u0131n\u0131p toplan\u0131yor bu da bize WCSS de\u011ferini veriyor. Mesela t\u00fcm verilerin tek bir k\u00fcme i\u00e7inde oldu\u011funu varsayal\u0131m t\u00fcm verilerin o k\u00fcmenin merkezine olan uzakl\u0131\u011f\u0131n\u0131n toplanmas\u0131 ile bulunuyor, \u015fimdi k\u00fcme say\u0131m\u0131z\u0131n art\u0131\u011f\u0131n\u0131 d\u00fc\u015f\u00fcnelim iki farkl\u0131 k\u00fcme oldu\u011funu haliyle k\u00fcmenin merkez noktalar\u0131 ile verierlin uzakl\u0131klar\u0131 karesi toplam\u0131 WCSS'in azalmas\u0131n\u0131 bekleriz hatta daha a\u00e7\u0131klay\u0131c\u0131 olmas\u0131 bak\u0131m\u0131dan her veri bir k\u00fcme olsayd\u0131 hepsinin merkezi kendisi olaca\u011f\u0131ndan WCSS de\u011feri 0 olacakt\u0131. Tabi WCSS de\u011ferinin az olmas\u0131 marifet de\u011fil az \u00f6ncesinde de bahsetmi\u015ftim \u00f6nemli olan \u00e7ok say\u0131lda k\u00fcme olmas\u0131 de\u011filidir. Burada i\u015fte \"Dirsek Y\u00f6ntemi\" bize yard\u0131mc\u0131 oluyor.    ","3f3f0154":"# Clustering (K-MEANS & Hierarchical Clustering)","be6b3f68":"G\u00f6r\u00fcld\u00fc\u011f\u00fc gibi k\u00fcmelenmi\u015f veriler farkl\u0131 renklerde g\u00f6z\u00fck\u00fcyor. Ayn\u0131 \u015fekilde bu k\u00fcmelerin merkezlerini g\u00f6rmek isteyebiliriz ben onlar\u0131 da siyah bir renkle g\u00f6sterdim.","eb301e38":"De\u011finmek istedi\u011fim bir di\u011fer nokta 1. bile\u015fen verimizi %63.7 oran\u0131nda 2. bile\u015fen %23.1 oran\u0131nda temsil edebiliyor ama 2 bile\u015fen kulland\u0131\u011f\u0131m\u0131zda toplamlar\u0131 %86.8 oran\u0131nda temsil ediyor olacakt\u0131r. Zaten az sonra yapaca\u011f\u0131m grafikte bunlar\u0131 g\u00f6steriyor olaca\u011f\u0131m.","e160fd4a":"Par\u00e7adan b\u00fct\u00fcne giden yakla\u015f\u0131m ile bir k\u00fcmeleme yakla\u015f\u0131m\u0131 olan AgglomerativeClustering'i kullanmay\u0131 tercih ettim. \"n_clusters\" de\u011ferine k-means'te buldu\u011fum de\u011feri yazd\u0131m 4 olarak affinity \u00f6klid, mahattan gibi uzakl\u0131k hesaplama metriklerini kullanabiliriz fakat ben \u00f6klid se\u00e7tim \u00e7\u00fcnk\u00fc linkage ward se\u00e7iminde bir zorunluluktur \u00f6klid se\u00e7imi. Linkage de \u00f6nceden anlatt\u0131\u011f\u0131m mesafe \u00f6l\u00e7mek i\u00e7in WCSS kullanan metriktir.","7c7955f0":"\u00d6ncelikle verimizi inceleyerek ba\u015flayal\u0131m veri setimiz Murat Hocam\u0131z haz\u0131rlam\u0131\u015ft\u0131r (https:\/\/www.kaggle.com\/murats) adresten bu data setinin orjinal haline ula\u015fabilirsiniz. Data seti 2889 g\u00f6zlemden olu\u015fan ve 4 \u00f6zniteli\u011fe sahip bir veri seti isminden de anla\u015f\u0131laca\u011f\u0131 gibi bir m\u00fc\u015fteri segmentasyonu i\u00e7in olu\u015fturulmu\u015f bir veri seti maa\u015f, ayl\u0131k harcama, cinsiyet ve ya\u015f de\u011fi\u015fkenlerinden olu\u015fuyor  \"df.info()\" ile t\u00fcm de\u011fi\u015fkenlerimizin say\u0131sal de\u011fi\u015fkenler oldu\u011funu g\u00f6r\u00fcyoruz. Bu g\u00fczel bu sayede \u015fu anl\u0131k bir d\u00f6n\u00fc\u015ft\u00fcrme i\u015flemi yapmam\u0131za gerek olmayacak. Herhangi bo\u015f bir de\u011fer de yok bu sayde doldurmam\u0131z gereken bir veri de yok ayl\u0131k harcamaya bakt\u0131\u011f\u0131m\u0131zda max harcama 4637 tl olarak g\u00f6r\u00fcyoruz min ise 0 yani hi\u00e7 harcama yapmam\u0131\u015f bu ayl\u0131k bazda olan bir harcama verisi olabilir \u00e7\u00fcnk\u00fc kay\u0131tl\u0131 kullan\u0131c\u0131 hi\u00e7 harcama yapmam\u0131\u015f belki bizi tercih etmiyor dahi olabilir bunun bir s\u00fcr\u00fc sebebi olabilir. Ama verilerimize bakt\u0131\u011f\u0131m\u0131zda herhangi bir yanl\u0131\u015fl\u0131k olmad\u0131\u011f\u0131n\u0131 s\u00f6yleyebiliriz tutarl\u0131 hepsi.","3227a7ec":"Bir di\u011fer g\u00f6zetimsiz \u00f6\u011frenme modelimiz Hiyerar\u015fik K\u00fcmelemedir. \u0130ki farkl\u0131 yakla\u015f\u0131m kullanarak k\u00fcmeleme i\u015flemi yapar. Bunlar: Agglomerative (Par\u00e7adan b\u00fct\u00fcne) ve Divisive (B\u00fct\u00fcnden par\u00e7aya) d\u0131r. algotritam\u0131n \u00e7al\u0131\u015fma mant\u0131\u011f\u0131ndan birazc\u0131k bahsedeyim: Agglomerative algortitma \u015fu \u015fekilde \u00e7al\u0131\u015f\u0131r her veri bir k\u00fcme kabul edilir sonra bu k\u00fcmeler kendilerine en yak\u0131n k\u00fcme ile birle\u015firler ve yeni bir k\u00fcme olu\u015fur 1. durumda n adet k\u00fcmemiz varsa 2. durumda n-1 ile n\/2 aras\u0131nda k\u00fcmemiz olu\u015fur. Sonras\u0131nda birbirine yak\u0131n k\u00fcmeler tekar tekar bu i\u015fleme tabi tutulur 1 K\u00fcme olana kadar. Divisive algoritmas\u0131 da bunun tam tersi bir k\u00fcme olarak t\u00fcm elemanlar ba\u015flar ve sonras\u0131nda b\u00f6l\u00fcne b\u00f6l\u00fcne her eleman bir k\u00fcmeyi ifade eder.","7a84af17":"Tabi \u015fu anda olu\u015fturdu\u011fumuz k\u00fcmelerimizi veri \u00e7er\u00e7evesi i\u00e7inde de g\u00f6sterebiliriz. Bunu bir exel haline getirip gerekli birime g\u00f6nderebiliriz.","ccb1890f":"# Hiyerar\u015fik B\u00f6l\u00fctleme (Hierarchical Clustering)","ec5b891a":"\u015eimdi \u00fcstteki grafik zaten optimum k\u00fcme de\u011ferini 4 olarak bize a\u00e7\u0131k\u00e7a s\u00f6yl\u00fcyor biz alttaki grafikten bunu nas\u0131l \u00e7\u0131karaca\u011f\u0131z. dirsek Y\u00f6temi i\u015fte burada kullan\u0131yoruz grafik bir dirse\u011fe bezedi\u011fi i\u00e7in. Peki ben 3 m\u00fc se\u00e7eyim 4 m\u00fc 5 mi \u015fimdi 3 ile 4 \u00fc inceleyelim WCSS de\u011feri 4 te daha az yani olu\u015facak k\u00fcmeler kendi i\u00e7inde daha benzer olacakt\u0131r. fakat 4 ile 5'i d\u00fc\u015f\u00fcnelim \u00e7ok da fazla bir fark s\u00f6z konusu de\u011fil 1 tane daha k\u00fcme olu\u015fturup i\u015flem y\u00fck\u00fc olu\u015fturmak ne kadar do\u011frudur.","27f972df":"Bir histogram ile verilerimizi inceledi\u011fimizde m\u00fc\u015fterilerimizin b\u00fcy\u00fck \u00e7o\u011funlu\u011funun 2000 civar\u0131 bir maa\u015f ald\u0131\u011f\u0131n\u0131 s\u00f6yleyebiliriz. Genelde gen\u00e7 m\u00fc\u015fterilere hizmet ediyor ve bu m\u00fc\u015fterilerin ayl\u0131k harcamalar\u0131 da a\u011f\u0131rl\u0131kl\u0131 olarak 0-1500 aras\u0131da. Cinsiyet bak\u0131m\u0131mdan ise hemen hemen e\u015fit bir da\u011f\u0131l\u0131m s\u00f6z konusu.","34ce69e0":"Bu kernelde data setimiz \u00fczerinde bir k\u00fcmeleme i\u015flemi uygulayaca\u011f\u0131z. K\u00fcmelemden biraz bahsetmek gerekirse her hangi bir etiket belirlemeden verilerimizi birbiriyle ili\u015fkili olanlar\u0131n\u0131 bir araya getirip k\u00fcmeleme olu\u015fturdu\u011fumuz yap\u0131d\u0131r. Bir denetimsiz \u00f6\u011frenme metodudur. \u0130ki farkl\u0131 k\u00fcmeleme algoritams\u0131 kullanarak verimizi k\u00fcmeleme yapaca\u011f\u0131z bu algoritmalar sklearn k\u00fct\u00fcphanesi i\u00e7erisinde bulunan K-MEANS ve Hiyerar\u015fik K\u00fcmeleme algoritmalar\u0131 \u00f6yleyse \u00f6ncelikle k\u00fct\u00fcphanelerimizi ve verimizi import edelim sonras\u0131nda bu algoritmalar nas\u0131l i\u015fliyor inceleyelim.","f8c4f5d2":"Burada merkez noktas\u0131n\u0131 g\u00f6stermek gibi bir durum yok \u00e7\u00fcnk\u00fc hiyerar\u015fik b\u00f6l\u00fctlemede bir merkez noktas\u0131 yoktur.","3a156797":"Bu iki y\u00f6ntemi de yapt\u0131ktan sonra bunlar\u0131 bir kar\u015f\u0131la\u015ft\u0131ral\u0131m. K\u00fcmeleme yaparken ne gibi farkl\u0131l\u0131klar mevcut bunu yapmak i\u00e7in daha \u00f6ncesinde df_kumelenmis ad\u0131nda olu\u015fturdu\u011fum veri \u00e7er\u00e7eveme hiyerar\u015fik k\u00fcmeleme sonucunda olu\u015fan yeni de\u011ferleride ekleyelim.","bf69409b":"K-MEANS'te en ideal k\u00fcme say\u0131s\u0131n\u0131 bulmam\u0131zda bize yard\u0131m eden bir y\u00f6ntem var \"**Dirsek Y\u00f6ntemi**\" bu y\u00f6ntemi ilerleyen sat\u0131rlarda tekrardan bahsedece\u011fim.","5d61da6b":"Dendogram olu\u015fumunda da altta \u00e7ok fazla de\u011fer oldu\u011fu i\u00e7in bu de\u011ferleri 4 baca\u011f\u0131n her birinde ne kadar veri oldu\u011funu yazarak daha basit \u015fekilde ifade etmeye \u00e7al\u0131\u015ft\u0131m. ","83e5b877":"Bundan biraz bahsediyim ne anlam ifade ediyor bu center ifadesi t\u00fcm i\u015flemler bittikten sonra ki 300 iterasyon yap\u0131ld\u0131\u011f\u0131 yukar\u0131da g\u00f6r\u00fcl\u00fcyor. atanan merkez noktalar\u0131 bu noktalard\u0131r alt alta 8 sat\u0131r 8 k\u00fcmenin merkez noktas\u0131 ve yan yana olan 4 de\u011ferlerde her bir \u00f6znitelikte kar\u015f\u0131l\u0131k gelen noktas\u0131d\u0131r. Mesela bunu \u015f\u00f6yle d\u00fc\u015f\u00fcnebiliriz 2 boyutlu bir uzayda bir noktan\u0131n kordinay\u0131 (x,y) ikilisinden meydana geilyor de\u011fil mi? burada da ayn\u0131 \u015fekilde 4 boyutlu o y\u00fczden 4 parametresi var.","1080aad8":"K-MEANS algoritams\u0131ndan birazc\u0131k bahsedeyim. K-MEANS belirtilen bir K (k\u00fcme say\u0131s\u0131) de\u011feri girilerek bu kadar say\u0131da k\u00fcmeye verimizi k\u00fcmeleme i\u015flemini sa\u011flar. Tabi bu bir problemdir hangi k de\u011ferini vermeliz burada iki fakt\u00f6r vard\u0131r 1.si i\u015f yapt\u0131\u011f\u0131m\u0131z \u015firket kurum yada her neyse bir k\u00fcme say\u0131s\u0131 belirlemi\u015ftir biz ona uygun olan\u0131 yapabiliriz bu en optimal sonu\u00e7 olmayabilir. 2.si de en iyi K de\u011ferini se\u00e7mek. En iyi K de\u011ferini se\u00e7mekten kast\u0131m \u015fudur k\u00fcmelemede verilerimizi k\u00fcme i\u00e7inde olabildi\u011fince benzer yapmal\u0131 ve k\u00fcmeler aras\u0131ndaki benzerli\u011fi de olabildi\u011fince az yapmal\u0131y\u0131z. Mesela optimumdan az bir k\u00fcme say\u0131s\u0131 se\u015fersek ayn\u0131 k\u00fcme i\u00e7erisinde farkl\u0131 asl\u0131nda birbirine o kadar benzemeyen veriler bulundurmu\u015f oluruz. Yada daha fazla say\u0131da k\u00fcme olu\u015fturusak bu sefer de ayn\u0131 birbirine \u00e7ok benzer verileri ba\u015fka k\u00fcmelere koyup i\u015flemler yapm\u0131\u015f oluruz. ","fd808651":"Herhangi bir parametre belirtmedi\u011fimde \"n_clusters=8\" yani K de\u011ferini 8 olarak atam\u0131\u015f. \"init='k-means++'\" olarak atamas\u0131ndaki \u00f6nem de \u015fu K-Means++\u2019a g\u00f6re rastgele ba\u015flang\u0131\u00e7 noktas\u0131 se\u00e7ildikten sonra di\u011fer t\u00fcm veriler ile aras\u0131ndaki mesafe hesaplan\u0131r. Bu mesafenin karesi al\u0131n\u0131p belli hesaplamalar yaparak yeni ba\u015flang\u0131\u00e7 noktalar\u0131 se\u00e7ilir.  ","eaf6a8b4":"Verilerin yar\u0131s\u0131nda farkl\u0131 bir k\u00fcmeleme yapm\u0131\u015f.","2a7d3409":"B\u00f6yle altalta koyarak da fark\u0131 g\u00f6relim istedim.","19ca0d7d":"# Optimum Kume Say\u0131s\u0131n\u0131n Belirlenmesi","0f932b40":"D\u00f6n\u00fc\u015ft\u00fcrmeden \u00f6nce scale etmeliyiz verimizi.","be252b89":"# TEMEL B\u0130LE\u015eEN ANAL\u0130Z\u0130 (PCA)","c3080b83":"Varyans de\u011feri en b\u00fcy\u00fck olan bile\u015fenimiz veriyi en iyi ifade eden bile\u015fenimizdir. Bak\u0131n 3. olan baya k\u00fc\u00e7\u00fck bir de\u011fer yani gittik\u00e7e daha az ifade etmeye ba\u015flad\u0131 verimizi bile\u015fenlerimiz."}}