{"cell_type":{"3a6f79de":"code","124d2291":"code","3e04f28d":"code","fe1a3a8e":"code","d90f3f82":"code","3a28d464":"code","9f5933f4":"code","c589d8e0":"code","a7f18d35":"code","3048e3e1":"code","6c90b7d7":"code","4f68c049":"code","9d3b97ef":"code","4ec262b2":"code","08dfaece":"code","ec8071a4":"code","c84ac951":"code","74738e49":"code","bd3fd186":"code","ffb83772":"code","05211298":"code","de3d9dcd":"code","57b49faf":"code","5d8e70d5":"code","a2b78471":"code","1fa7659e":"code","6fda1629":"code","3f80ee3b":"code","98fb3605":"code","96695fa0":"code","4ad69b64":"markdown","e59d24e0":"markdown","a498a4ea":"markdown","5587f0cd":"markdown","db29b957":"markdown","ce3ad4a5":"markdown","76b8bd3a":"markdown"},"source":{"3a6f79de":"!pip install -q imageio\n!pip install -q git+https:\/\/github.com\/tensorflow\/docs","124d2291":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport tensorflow_docs.vis.embed as embed\nimport os\nfrom os.path import isfile, join\nimport time\nimport glob\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport imageio\nfrom PIL import Image\nfrom IPython import display","3e04f28d":"data_dir = '..\/input\/minecraft-skins-24k-skins\/images'\nskin_paths = [join(data_dir, f) for f in os.listdir(data_dir)]\nlen(skin_paths)","fe1a3a8e":"def load_image(path):\n    img = Image.open(path)\n    return np.array(img)\n\n\ndef normalize(img):\n    img = (img - 127.5) \/ 127.5\n    return img\n\n\ndef denormalize(img):\n    img = np.array(img)\n    img = img * 127.5 + 127.5\n    return img.astype('uint8')\n\n\ndef show(img):\n    plt.axis('off')\n    plt.imshow(img)","d90f3f82":"skins = []\nfor p in skin_paths:\n    try:\n        im = load_image(p)\n        if im.shape[0] == 64:\n            skins.append(im)\n    except:\n        continue\nskins = np.array(skins)\nskins.shape","3a28d464":"skins = normalize(skins)","9f5933f4":"BUFFER_SIZE = 60000\nBATCH_SIZE = 256","c589d8e0":"skins = tf.data.Dataset.from_tensor_slices(skins).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","a7f18d35":"noise_dim = 100","3048e3e1":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(8 * 8 * 256, use_bias=False, input_shape=(noise_dim,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((8, 8, 256)))\n    assert model.output_shape == (None, 8, 8, 256)\n\n    model.add(layers.Conv2DTranspose(128, 4, strides=1, padding='same', use_bias=False))\n    assert model.output_shape == (None, 8, 8, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, 4, strides=2, padding='same', use_bias=False))\n    assert model.output_shape == (None, 16, 16, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(32, 4, strides=2, padding='same', use_bias=False))\n    assert model.output_shape == (None, 32, 32, 32)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(4, 4, strides=2, padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 64, 64, 4)\n\n    return model","6c90b7d7":"generator = make_generator_model()\ngenerator.summary()","4f68c049":"noise = tf.random.normal([1, noise_dim])\ngenerated_image = generator(noise, training=False)\nshow(denormalize(generated_image[0]))\nnp.array(denormalize(generated_image[0])).min(), np.array(denormalize(generated_image[0])).max()","9d3b97ef":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, 4, strides=2, padding='same',\n                                     input_shape=[64, 64, 4]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, 4, strides=2, padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(256, 4, strides=2, padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","4ec262b2":"discriminator = make_discriminator_model()\ndiscriminator.summary()","08dfaece":"decision = discriminator(generated_image)\nprint(decision)","ec8071a4":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","c84ac951":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","74738e49":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","bd3fd186":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","ffb83772":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = join(checkpoint_dir, 'ckpt')\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","05211298":"num_examples_to_generate = 16\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","de3d9dcd":"@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","57b49faf":"def train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n\n        for image_batch in dataset:\n            train_step(image_batch)\n\n        # Produce images for the GIF as you go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator, epoch + 1, seed)\n\n        # Save the model every 15 epochs\n        if (epoch + 1) % 15 == 0:\n            checkpoint.save(file_prefix = checkpoint_prefix)\n\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n\n    # Generate after the final epoch\n    display.clear_output(wait=True)\n    generate_and_save_images(generator, epochs, seed)","5d8e70d5":"def generate_and_save_images(model, epoch, test_input):\n    predictions = model(test_input, training=False)\n\n    fig = plt.figure(figsize=(8, 8))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i + 1)\n        pred = predictions[i] \/ 2 + 0.5\n        plt.imshow(pred)\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","a2b78471":"EPOCHS = 250","1fa7659e":"train(skins, EPOCHS)","6fda1629":"def display_image(epoch_no):\n    return Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","3f80ee3b":"display_image(EPOCHS)","98fb3605":"anim_file = 'skins.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n    filenames = glob.glob('image*.png')\n    filenames = sorted(filenames)\n    for filename in filenames:\n        image = imageio.imread(filename)\n        writer.append_data(image)\n    image = imageio.imread(filename)\n    writer.append_data(image)","96695fa0":"embed.embed_file(anim_file)","4ad69b64":"# Create GIF","e59d24e0":"# The Discriminator","a498a4ea":"# The training loop","5587f0cd":"# The Generator","db29b957":"# Train the model","ce3ad4a5":"# Loss and optimizers","76b8bd3a":"# Save checkpoints"}}