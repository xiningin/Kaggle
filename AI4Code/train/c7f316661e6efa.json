{"cell_type":{"bcf636b2":"code","1a5ce174":"code","deded9e2":"code","431535e1":"code","8a543502":"code","0619a7d6":"code","cc4d7488":"code","5b73db18":"code","64b63a7e":"code","ac2e0751":"code","4770f3b2":"code","1784824e":"code","fb22a155":"code","b795613b":"code","d83b35e6":"code","b59783f9":"code","f546e6bf":"code","886c8a06":"code","319c4be7":"code","dc6644e1":"code","47c14be3":"code","01dd8532":"code","33e7e5e7":"code","4bebe975":"code","c73d6407":"code","46102160":"code","cc1b5c93":"code","bb947e39":"code","3a021821":"code","8e2859fb":"code","6300e3a0":"code","d7bcc39d":"code","e1d2288a":"code","0ccd2050":"code","167b3416":"code","eec651f0":"code","94bc0599":"code","f050012f":"code","50240818":"markdown","78d971b2":"markdown","50061b33":"markdown","4841268c":"markdown","77c2a7b6":"markdown","b258bf84":"markdown","436096bc":"markdown","209f9a72":"markdown","525e9088":"markdown","6844031a":"markdown","fb398db0":"markdown","bd336cd9":"markdown","f303c4ed":"markdown","8597723e":"markdown","1e5034a1":"markdown","faf9dd8c":"markdown","9bcc4b1d":"markdown","782dc517":"markdown","56c2c8d2":"markdown","c461ea64":"markdown","5d07468f":"markdown","fc91fb2e":"markdown","0be7b5e8":"markdown","4453773c":"markdown"},"source":{"bcf636b2":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport os","1a5ce174":"import warnings\nwarnings.filterwarnings(\"ignore\")","deded9e2":"os.listdir('..\/input\/riiid-test-answer-prediction')","431535e1":"lectures_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/lectures.csv\")\nexample_test_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/example_test.csv\")\ntrain_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/train.csv\", low_memory=False, nrows=1000000)\nquestions_csv = pd.read_csv(\"..\/input\/riiid-test-answer-prediction\/questions.csv\")","8a543502":"train_csv.head()","0619a7d6":"train_csv.nunique()","cc4d7488":"train_csv.info()","5b73db18":"train_csv.describe()[['timestamp', 'user_answer', 'answered_correctly', 'prior_question_elapsed_time']]","64b63a7e":"train_csv.isnull().sum()","ac2e0751":"# train_csv[\"prior_question_elapsed_time\"] = train_csv.groupby([\"user_id\", \"content_id\"]).transform(lambda x: x.fillna(x.mean()))\n# train_csv[\"prior_question_had_explanation\"] = train_csv.groupby([\"user_id\", \"content_id\"]).transform(lambda x: x.fillna(x.mean()))\n\n\n# train_csv.dropna(inplace=True)","4770f3b2":"train_csv['timestamp'].hist(bins = 50)","1784824e":"plt.figure(figsize=(15, 7))\nax = sns.countplot(train_csv.groupby('user_id')['user_answer'].count().value_counts(), palette=\"hls\")\nplt.title(\"Count of answers per user\", fontsize=12)\nplt.xticks(rotation=90, fontsize=13)\nplt.ylabel('Number of answers')\nplt.xlabel('Count of users')","fb22a155":"plt.figure(figsize=(15, 7))\nax = sns.countplot(train_csv.user_answer)\nplt.title(\"Distribution of Mean's answer per user\", fontsize=12)\nplt.xticks(rotation=90, fontsize=13)\nplt.ylabel('Frequency')\nplt.xlabel('Average answer')","b795613b":"plt.figure(figsize=(15, 7))\nax = sns.distplot(train_csv.groupby('user_id')['answered_correctly'].mean())\nplt.title(\"Distribution of correct's answer per user\", fontsize=12)\nplt.xticks(rotation=90, fontsize=13)\nplt.ylabel('Frequency')\nplt.xlabel('Average correct answer')","d83b35e6":"train_csv.groupby('user_id')['answered_correctly'].mean().median()","b59783f9":"plt.figure(figsize=(15, 7))\nax = sns.countplot(train_csv.answered_correctly)\nplt.title(\"Distribution of correct answer\", fontsize=12)\nplt.xticks(rotation=90, fontsize=13)\nplt.ylabel('Frequency')\nplt.xlabel('Answer')","f546e6bf":"s = train_csv.groupby('content_id')['user_answer'].count().sort_values(ascending=False)","886c8a06":"s[:20]","319c4be7":"zz = train_csv.groupby('content_id')['user_answer'].count().sort_values(ascending=False)\nplt.figure(figsize=(15, 7))\nax = sns.lineplot(y=zz, x=range(0, len(zz)))\nplt.title(\"Count of answers per content_id\", fontsize=12)\nplt.locator_params(nbins=12)\nplt.ylabel('Number of answers')\nplt.xlabel('Number of content_id')","dc6644e1":"zz[:15]","47c14be3":"plt.figure(figsize=(15, 7))\nax = sns.distplot(train_csv.groupby('user_id')['prior_question_elapsed_time'].mean())\nplt.title(\"Distribution of Mean's prior_question_elapsed_time per user\", fontsize=12)\nplt.xticks(rotation=90, fontsize=13)\nplt.ylabel('Frequency')\nplt.xlabel('Average prior_question_elapsed_time')","01dd8532":"questions_csv.head()","33e7e5e7":"questions_csv.nunique()","4bebe975":"questions_csv.isnull().sum()","c73d6407":"def split_tags(x):\n    try: return [int(i) for i in str(x).split()]\n    except: return [0]","46102160":"questions_csv.tags = questions_csv.tags.apply(lambda x: split_tags(x))","cc1b5c93":"unique, counts = np.unique(questions_csv.tags.sum(), return_counts=True)","bb947e39":"plt.figure(figsize=(15, 7))\nax = sns.barplot(x=unique, y=counts)\nplt.title(\"Count of tag\", fontsize=12)\nplt.tick_params(axis='x',which='both', bottom=False, top=False, labelbottom=False)\nplt.ylabel('Count')\nplt.xlabel('Tag')","3a021821":"idx = np.argsort(counts)[::-1]\nprint(f\"most frequently tags are: {unique[idx[:5]]}\")","8e2859fb":"plt.figure(figsize=(15, 7))\nax = sns.countplot(questions_csv['correct_answer'], palette=\"hls\")\nplt.title(\"Count of correct answer per each choice\", fontsize=12)\nplt.xticks(rotation=90, fontsize=12)\nplt.ylabel('Count')\nplt.xlabel('Correct answer')","6300e3a0":"plt.figure(figsize=(15, 7))\nax = sns.countplot(questions_csv.groupby('bundle_id').count()['question_id'], palette=\"hls\")\nplt.title(\"Count of questions per bundle_id\", fontsize=12)\nplt.xticks(rotation=90, fontsize=12)\nplt.ylabel('Number of bundle')\nplt.xlabel('Number of question')","d7bcc39d":"plt.figure(figsize=(15, 7))\nax = sns.countplot(questions_csv['part'], palette=\"hls\")\nplt.title(\"Distribution of Path\", fontsize=12)\nplt.xticks(rotation=90, fontsize=12)\nplt.ylabel('Count')\nplt.xlabel('Path')","e1d2288a":"questions_csv.groupby(['part', 'correct_answer']).count()['question_id']","0ccd2050":"lectures_csv.head()","167b3416":"lectures_csv.nunique()","eec651f0":"lectures_csv.isnull().sum()","94bc0599":"plt.figure(figsize=(15, 7))\nax = sns.countplot(lectures_csv['part'], palette=\"hls\")\nplt.title(\"Distribution of Path\", fontsize=12)\nplt.xticks(rotation=90, fontsize=12)\nplt.ylabel('Count')\nplt.xlabel('Path')","f050012f":"plt.figure(figsize=(15, 7))\nax = sns.countplot(lectures_csv['type_of'], palette=\"hls\")\nplt.title(\"Distribution of Path\", fontsize=12)\nplt.xticks(rotation=90, fontsize=12)\nplt.ylabel('Count')\nplt.xlabel('Path')","50240818":"Most bundle have only 1 question","78d971b2":"## 1.2 ```'questions.csv'```","50061b33":"### Check data available","4841268c":"Let's take another look at our parameters:\n\n- ```lecture_id```: foreign key for the train\/test content_id column, when the content type is lecture (1).\n\n- ```part```: top level category code for the lecture.\n\n- ```tag```: one tag codes for the lecture. The meaning of the tags will not be provided, but these codes are sufficient for clustering the lectures together.\n\n- ```type_of```: brief description of the core purpose of the lecture","77c2a7b6":"It can be argued that users are more likely to respond **correctly**. Let's implement another plot to estimate this opinion","b258bf84":"Answer 1 is almost 2 times more often correct than 0","436096bc":"Let's explore each of the datasets!","209f9a72":"Approximately 2000 contents have more than 200 questions\n\nWe can find **most popular content**","525e9088":"We see that users in principle equally likely to answer questions using answers 0,1,3. There are some -1 values\n","6844031a":"Type \"5\" is more frequent","fb398db0":"Let's take another look at our parameters:\n\n- ```row_id```: (int64) ID code for the row.\n\n- ```timestamp```: (int64) the time between this user interaction and the first event from that user.\n\n- ```user_id```: (int32) ID code for the user.\n\n- ```content_id```: (int16) ID code for the user interaction\n\n- ```content_type_id```: (int8) 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.\n\n- ```task_container_id```: (int16) Id code for the batch of questions or lectures. For example, a user might see three questions in a row before seeing the explanations for any of them. Those three would all share a task_container_id. Monotonically increasing for each user.\n\n- ```user_answer```: (int8) the user's answer to the question, if any. Read -1 as null, for lectures.\n\n- ```answered_correctly```: (int8) if the user responded correctly. Read -1 as null, for lectures.\n\n- ```prior_question_elapsed_time```: (float32) How long it took a user to answer their previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Note that the time is the total time a user took to solve all the questions in the previous bundle.\n\n- ```prior_question_had_explanation```: (bool) Whether or not the user saw an explanation and the correct response(s) after answering the previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback.","bd336cd9":"You can see that many users have a period of \"stagnation\" now.","f303c4ed":"We can single out one user who answered much more times than other students. Almost all users answered up to 30 times","8597723e":"In avarage, each user needs 20000 to answer their previous question bundle, ignoring any lectures in between.\n\nNote: Note that the time is the total time a user took to solve all the questions in the previous bundle.\n","1e5034a1":"## 1.1 ```'train.csv'```","faf9dd8c":"We can conclude that ```answered_correctly```, ```prior_question_had_explanation``` are a nominative features; ```user_answer``` is a rank variable; ```timestamp```, ```prior_question_elapsed_time```  are quantitative.","9bcc4b1d":"We have 4 datasets at our disposal","782dc517":"## Import necessary libraries","56c2c8d2":"The easiest way is to delete rows that contain nan values, but in this case we may lose important information. Alternatively, it can be replaced by the average value of the group, where the group is calculated taking into user's id and the content's id.","c461ea64":"Let's check the Nan values","5d07468f":"In each part approximately the same distribution of the answer variant","fc91fb2e":"## 1.3 ```'lectures.csv'```","0be7b5e8":"We can compare what is the significant difference in the number of different types of lectures","4453773c":"Let's take another look at our parameters:\n\n- ```question_id```: foreign key for the train\/test content_id column, when the content type is question (0).\n\n- ```bundle_id```: code for which questions are served together.\n\n- ```correct_answer```: the answer to the question. Can be compared with the train user_answer column to check if the user was right.\n\n- ```part```: top level category code for the question.\n\n- ```tags```: one or more detailed tag codes for the question. The meaning of the tags will not be provided, but these codes are sufficient for clustering the questions together."}}