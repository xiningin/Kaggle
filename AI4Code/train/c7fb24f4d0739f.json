{"cell_type":{"61cecfab":"code","d0b8a023":"code","dd187017":"code","2eacafb6":"code","e662b088":"code","43dd8320":"code","40caa884":"code","b91b5034":"code","8221274c":"code","e5fe3cfa":"code","e1d7ce9e":"code","3ffd26ff":"code","aaad3d55":"code","858fcac0":"code","21dd4b0f":"code","398f250d":"code","5a719bdf":"code","aee5b53e":"markdown"},"source":{"61cecfab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d0b8a023":"import pandas as pd\n\n## Load dataset\ndf = pd.read_csv(\"\/kaggle\/input\/order-brushing-shopee-code-league\/order_brush_order.csv\") ","dd187017":"df.head()","2eacafb6":"## Quick analysis\ndf.describe()","e662b088":"## Number of unique seller\ndf['shopid'].nunique()","43dd8320":"## Number of unique seller\ndf['userid'].nunique()","40caa884":"## Average trx each shop has\ndf.groupby('shopid')['orderid'].count().mean()","b91b5034":"## Minimum time \ndf[df['event_time'] == df['event_time'].min()]","8221274c":"## Set event_time as index \ndf_time = df.set_index(pd.DatetimeIndex(df['event_time'])).drop('event_time', axis=1)\ndf_time = df_time.sort_index()\n\n## Groupby shopid, userid, and event_time 60 min intervals, count order(s)\ngrouped_orders = df_time.groupby(['shopid', 'userid', pd.Grouper(freq='60min', label='left', base=0)]).count()","e5fe3cfa":"## Find shopid that possibly do order brushing, given a threshold\npossible_brush = grouped_orders[grouped_orders.orderid > 2]\n\nuserids = []\npossible_brush.reset_index().groupby('shopid')['userid'].apply(lambda x: userids.append(x.values))\nlen(userids)","e1d7ce9e":"possible_brush.reset_index().shopid.nunique()","3ffd26ff":"def concat_and(arr):\n    res = '&'.join(str(x) for x in arr)\n    return res\n\nconcat_userids = []\nfor element in userids:\n    concat_userids.append(concat_and(element))\n\nres_df = pd.DataFrame({\"shopid\": possible_brush.reset_index()['shopid'].unique(), \"userid\": concat_userids})\nres_df.head()","aaad3d55":"## Final answer\ndefault_df = pd.DataFrame({'shopid': df['shopid'].unique(), 'userid': 0})\ndefault_df.head()","858fcac0":"res_df.head()","21dd4b0f":"res_df.shape","398f250d":"## Export Result\nsol_df = pd.concat([default_df[~default_df.shopid.isin(res_df.shopid)], res_df])\nsol_df.to_csv(\"solution_3.csv\", index=False)","5a719bdf":"## Check result\npd.read_csv(\"solution_3.csv\")","aee5b53e":"**Note**:\nThis notebook still needs improvement though. It didn't count the concentrate rate at all and didn't account for all possibility time interval of a merchant. It only achieve a weighted score of 0.7388 out of 1.0."}}