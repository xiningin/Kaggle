{"cell_type":{"909b5364":"code","67ea5e0f":"code","6017463d":"code","a1b8b643":"code","24147b5b":"code","e27df1fa":"code","b2474053":"code","501ef214":"code","a21d2639":"code","a059a6ee":"code","0e7fa9d4":"code","690fc813":"code","c4b4cd66":"code","d148b20c":"code","0113cedc":"code","f74fbb30":"code","43055a0a":"code","b7ca7564":"code","7989c03b":"code","3e1703bb":"code","cfc200d8":"code","41fb31c2":"code","511237aa":"code","90261f1e":"code","0ce821cf":"code","20515c27":"code","6536ce48":"code","8b8b1664":"code","f4590ee5":"code","1ed7817e":"code","08addb8e":"code","6273653d":"code","a8d9ea3f":"code","95eadf2e":"code","e3d6c245":"code","4c05d8ba":"markdown","421447ea":"markdown","0f4cda9c":"markdown","a729bf2e":"markdown","ae6c5906":"markdown","18819465":"markdown","9b2acaab":"markdown","3d60d839":"markdown","93eb913f":"markdown","25680312":"markdown","caccd10b":"markdown"},"source":{"909b5364":"import os\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport fnmatch\nfrom glob import glob\nimport gc\n%matplotlib inline ","67ea5e0f":"import keras\nimport tensorflow\nfrom keras import backend as K\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization,Conv2D,MaxPool2D,MaxPooling2D\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,accuracy_score","6017463d":"ls ..\/input\/IDC_regular_ps50_idx5\/ ","a1b8b643":"ls ..\/input\/IDC_regular_ps50_idx5\/14305","24147b5b":"images=glob('..\/input\/IDC_regular_ps50_idx5\/**\/*.png',recursive=True)\nfor fileindex,filename in enumerate(images):\n    if fileindex==10:\n        break\n    print(filename)","e27df1fa":"image_9075=cv2.imread('..\/input\/IDC_regular_ps50_idx5\/9075\/1\/9075_idx5_x1751_y351_class1.png')","b2474053":"plt.figure(figsize=(15,15))\nplt.imshow(image_9075)","501ef214":"plt.imshow(cv2.cvtColor(image_9075,cv2.COLOR_BGR2RGB))","a21d2639":"plt.rcParams['figure.figsize'] = (10.0, 10.0)\nfor singleIndex,singleImage in enumerate(images[:25]):\n    im = cv2.imread(singleImage)\n    im = cv2.resize(im, (50, 50)) \n    plt.subplot(5, 5, singleIndex+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n    plt.axis('off')","a059a6ee":"patternZero = '*class0.png'\npatternOne = '*class1.png'\nclassZero = fnmatch.filter(images, patternZero)\nclassOne = fnmatch.filter(images, patternOne)\nprint(\"IDC(-)\\n\\n\",classZero[0:5],'\\n')\nprint(\"IDC(+)\\n\\n\",classOne[0:5])","0e7fa9d4":"def process_images(lowerIndex,upperIndex):\n    x = []\n    y = []\n    WIDTH = 50\n    HEIGHT = 50\n    for img in images[lowerIndex:upperIndex]:\n        full_size_image = cv2.imread(img)\n        x.append(cv2.resize(full_size_image, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n        if img in classZero:\n            y.append(0)\n        elif img in classOne:\n            y.append(1)\n        else:\n            return\n    return x,y\n\nX,Y=process_images(0,90000)","690fc813":"X[:6]","c4b4cd66":"X1=np.array(X)","d148b20c":"X1.shape","0113cedc":"df = pd.DataFrame()\ndf[\"images\"]=X\ndf[\"labels\"]=Y","f74fbb30":"X2=df[\"images\"]\nY2=df[\"labels\"]","43055a0a":"X2=np.array(X2)","b7ca7564":"X2[:5]","7989c03b":"X2.shape","3e1703bb":"# Separation of classes of images\nimgs0=[]\nimgs1=[]\nimgs0 = X2[Y2==0]\nimgs1 = X2[Y2==1] ","cfc200d8":"print('Total number of images: {}'.format(len(X2)))\nprint('Number of Class 0 images: {}'.format(np.sum(Y2==0)))\nprint('Number of class 1 Images: {}'.format(np.sum(Y2==1)))\nprint('Image shape (Width, Height, Channels): {}'.format(X1[0].shape))","41fb31c2":"X=np.array(X)\n\n#Standarizing the data for the model \nX=X\/255.0\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)","511237aa":"del X,X1,X2,Y2\ngc.collect()","90261f1e":"X_train.shape,X_test.shape","0ce821cf":"df['labels'].value_counts()","20515c27":"sns.countplot(df['labels'])","6536ce48":"y_trainCat=to_categorical(Y_train,num_classes=2)\ny_testCat=to_categorical(Y_test,num_classes=2)","8b8b1664":"# Helper Functions  Learning Curves and Confusion Matrix\n\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('.\/accuracy_curve.png')\n    #plt.clf()\n    # summarize history for loss\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('.\/loss_curve.png')","f4590ee5":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=20,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)  # randomly flip images","1ed7817e":"batch_size = 128\nnum_classes = 2\nepochs = 8\nimg_rows,img_cols=50,50\ninput_shape = (img_rows, img_cols, 3)\ne = 2","08addb8e":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape,strides=e))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))","6273653d":"model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])","a8d9ea3f":"# model.fit_generator(datagen.flow(X_train,y_trainCat,batch_size=16),steps_per_epoch=X_train\/32,epochs=epochs,validation_data=[X_test,y_testCat])","95eadf2e":"history = model.fit_generator(datagen.flow(X_train,y_trainCat, batch_size=32),\n                        steps_per_epoch=len(X_train) \/ 32, \n                              epochs=epochs,validation_data = [X_test, y_testCat],\n                              callbacks = [MetricsCheckpoint('logs')])","e3d6c245":"y_pred=model.predict(X_test)","4c05d8ba":"Importing Essential pyhton Libraries","421447ea":"Now let's resize the images using cv2 library","0f4cda9c":"Now lets look at all the other sample images","a729bf2e":"Importing Machine learning Libraries","ae6c5906":"Now, lets separate images ","18819465":"Now, lets Implement the one hot encoding for the categorical variables","9b2acaab":"Now let's look at the Statisitcs of all the images we have","3d60d839":"As opencv uses BGR format initially, So we have to convert the image to RGB format","93eb913f":"Now's lets split the data into train test split","25680312":"As we can conculde from the above figure that there is an uneven distribution in the labels, as the number of sample images of class 0 is greater","caccd10b":"Now lets filter and differentiate different classes by using fnmatch library which supports wildcards"}}