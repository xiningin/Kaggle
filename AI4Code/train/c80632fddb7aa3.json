{"cell_type":{"61928962":"code","7ac136cf":"code","4b2efb4d":"code","b5c1a5f5":"code","61b03afd":"code","d8744bce":"code","9dc9f48c":"code","e29564ab":"code","a1ae17e7":"code","6f7ff93c":"code","dd12b8a5":"code","8ffb854e":"code","51305041":"code","8e812ba9":"code","cdf0fef2":"code","5d110a4c":"code","cbe54da8":"code","d0b22d5c":"code","405a67dc":"code","bb28aceb":"code","a475b4af":"code","cb6947bd":"code","91e64555":"code","12b7e348":"code","5f293e3d":"markdown","176341d9":"markdown","3d0acdae":"markdown","92c6a146":"markdown","b1d75a1c":"markdown","639ac679":"markdown","2f88318c":"markdown","01530a79":"markdown","efc05c8d":"markdown","99085d63":"markdown","29b494a6":"markdown","a46da3cf":"markdown","8c28c913":"markdown","2961daea":"markdown","542f4736":"markdown","e2e14e85":"markdown","7100d9e0":"markdown","6f43748f":"markdown","bf212cc4":"markdown","43284635":"markdown","0132f9c2":"markdown","cef3ad2f":"markdown"},"source":{"61928962":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ac136cf":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler","4b2efb4d":"pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.width', 500)","b5c1a5f5":"def load(dataset_path):\n    data = pd.read_csv(dataset_path)\n    return data\n\ndef check_df(dataframe, head=5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n\n    print(\"##################### Head #####################\")\n    print(dataframe.head(head))\n\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(head))\n\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ndef grab_col_names(dataframe, cat_th=10, car_th=20):\n    \"\"\"\n\n    Veri setindeki kategorik, numerik ve kategorik fakat kardinal de\u011fi\u015fkenlerin isimlerini verir.\n    Not: Kategorik de\u011fi\u015fkenlerin i\u00e7erisine numerik g\u00f6r\u00fcn\u00fcml\u00fc kategorik de\u011fi\u015fkenler de dahildir.\n\n    Parameters\n    ------\n        dataframe: dataframe\n                De\u011fi\u015fken isimleri al\u0131nmak istenilen dataframe\n        cat_th: int, optional\n                numerik fakat kategorik olan de\u011fi\u015fkenler i\u00e7in s\u0131n\u0131f e\u015fik de\u011feri\n        car_th: int, optinal\n                kategorik fakat kardinal de\u011fi\u015fkenler i\u00e7in s\u0131n\u0131f e\u015fik de\u011feri\n\n    Returns\n    ------\n        cat_cols: list\n                Kategorik de\u011fi\u015fken listesi\n        num_cols: list\n                Numerik de\u011fi\u015fken listesi\n        cat_but_car: list\n                Kategorik g\u00f6r\u00fcn\u00fcml\u00fc kardinal de\u011fi\u015fken listesi\n\n    Examples\n    ------\n        import seaborn as sns\n        df = sns.load_dataset(\"iris\")\n        print(grab_col_names(df))\n\n\n    Notes\n    ------\n        cat_cols + num_cols + cat_but_car = toplam de\u011fi\u015fken say\u0131s\u0131\n        num_but_cat cat_cols'un i\u00e7erisinde.\n        Return olan 3 liste toplam\u0131 toplam de\u011fi\u015fken say\u0131s\u0131na e\u015fittir: cat_cols + num_cols + cat_but_car = de\u011fi\u015fken say\u0131s\u0131\n\n    \"\"\"\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car\n\ndef cat_summary(dataframe, col_name, plot=False):\n\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\")\n\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()\n\ndef num_summary(dataframe, numerical_col, plot=False):\n\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n\n    print(dataframe[numerical_col].describe(quantiles).T)\n\n    if plot:\n        dataframe[numerical_col].hist(bins=20)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.show(block=True)\n\ndef target_summary_with_cat(dataframe, target, categorical_col):\n\n    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")\n\ndef target_summary_with_num(dataframe, target, numerical_col):\n    print(dataframe.groupby(target).agg({numerical_col: \"mean\"}), end=\"\\n\\n\\n\")\n\n\ndef outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False\n\ndef grab_outliers(dataframe, col_name, index=False):\n    low, up = outlier_thresholds(dataframe, col_name)\n\n    if dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].shape[0] > 10:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].head())\n    else:\n        print(dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))])\n\n    if index:\n        outlier_index = dataframe[((dataframe[col_name] < low) | (dataframe[col_name] > up))].index\n        return outlier_index\n\ndef missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n\n    if na_name:\n        return na_columns\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\ndef label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe\n\ndef one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe\n\ndef plot_importance(model, features, num, save=False):\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                      ascending=False)[0:num])\n    plt.title('Features')\n    plt.tight_layout()\n    plt.show()\n    if save:\n        plt.savefig('importances.png')","61b03afd":"df = load(\"\/kaggle\/input\/diabetes\/diabetes.csv\")\ncheck_df(df)\n# get categorik,numerik and cat but cardinal columns.\ncat_cols, num_cols, cat_but_car = grab_col_names(df)","d8744bce":"for col in num_cols:\n    num_summary(df, col, plot=True)","9dc9f48c":"for col in num_cols:\n    target_summary_with_num(df, \"Outcome\", col)","e29564ab":"for col in num_cols:\n    print(f\"{col} : {check_outlier(df,col)}\")\n    grab_outliers(df, col)","a1ae17e7":"missing_values_table(df,True)","6f7ff93c":"df.describe().T","dd12b8a5":"df.loc[df[\"Glucose\"]==0,\"Glucose\"] = float('NaN')\ndf[\"Glucose\"].isnull().sum()\n\ndf.loc[df[\"BloodPressure\"]==0,\"BloodPressure\"] = float('NaN')\ndf[\"BloodPressure\"].isnull().sum()\n\ndf.loc[df[\"SkinThickness\"]==0,\"SkinThickness\"] = float('NaN')\ndf[\"SkinThickness\"].isnull().sum()\n\ndf.loc[df[\"Insulin\"]==0,\"Insulin\"] = float('NaN')\ndf[\"Insulin\"].isnull().sum()\n\ndf.loc[df[\"BMI\"]==0,\"BMI\"] = float('NaN')\ndf[\"BMI\"].isnull().sum()\n","8ffb854e":"missing_column = missing_values_table(df,True)","51305041":"for column in missing_column:\n    df.loc[(df[\"Outcome\"] == 0) & (df[column].isnull()), column] = df[df[\"Outcome\"] == 0][column].median()\n    df.loc[(df[\"Outcome\"] == 1) & (df[column].isnull()), column] = df[df[\"Outcome\"] == 1][column].median()\n","8e812ba9":"missing_column = missing_values_table(df,True)","cdf0fef2":"for col in num_cols:\n    replace_with_thresholds(df, col)","5d110a4c":"for col in num_cols:\n    print(check_outlier(df,col))","cbe54da8":"df[\"age_bmi_ratio\"] = df[\"Age\"]\/df[\"BMI\"]\ndf[\"pregnancies_age_ratio\"] = df[\"Pregnancies\"]\/df[\"Age\"]\ndf[\"glucose_age_ratio\"] = df[\"Glucose\"]\/df[\"Age\"]\ndf[\"skinthickness_age_ratio\"] = df[\"SkinThickness\"]\/df[\"Age\"]\ndf[\"insulin_age_ratio\"] = df[\"Insulin\"]\/df[\"Age\"]\ndf[\"glocose_square\"] = df[\"Glucose\"]**2\ndf[\"glocose_dot_insulin_sqaure\"] = (df[\"Glucose\"]*df[\"Insulin\"])**2\ndf[\"pregnancies_age_ratio_flag\"] = pd.qcut(df['pregnancies_age_ratio'], 3 , labels=[\"Low\",\"Medium\",\"High\"])\ndf[\"age_flag\"] = pd.qcut(df['Age'], 3, labels=[\"young\",\"middle_aged\",\"old\"])","d0b22d5c":"df.head()","405a67dc":"cat_cols, num_cols, cat_but_car = grab_col_names(df)\n\nohe_cols = [col for col in df.columns if 10 >= df[col].nunique() > 2]\n\ndf = one_hot_encoder(df, ohe_cols)\ndf.head()","bb28aceb":"scaler = RobustScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])\ndf.head()","a475b4af":"import lightgbm as lgbm","cb6947bd":"y = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=17)","91e64555":"lgbm_model = lgbm.LGBMClassifier().fit(X_train, y_train)\ny_pred = lgbm_model.predict(X_test)\naccuracy_score(y_pred, y_test)","12b7e348":"plot_importance(lgbm_model,X_train,len(X))","5f293e3d":"### Lets make target variable analysis.\n","176341d9":"As we noted in the analysis, the most important variables were insulin and glucose.\n5 of the top 10 most important variables appear to be the ones we created.We achieved 0.90 accuracy score. Higher scores can also be achieved with hyperparameter optimization.","3d0acdae":"#### Missing Value Analysis\n\n","92c6a146":"#### Feature Engineering","b1d75a1c":"#### Result","639ac679":"### Data Preperation","2f88318c":"Glucose, bloodpressure,skinthickness,insulin and bmi can not be 0 normally. These are missing value.","01530a79":"The only categorical column is the target column. Therefore, there is no need to do categorical column analysis.\n\n### Let's do a numerical column analysis.","efc05c8d":"# Lets analyse data","99085d63":"#### Outlier Processing","29b494a6":"#### Outlier Analysis","a46da3cf":"#### Feature Scaling","8c28c913":"### Build Model","2961daea":" Variables with the highest target explanatory are insulin and glucose.","542f4736":"#### Label Encoding","e2e14e85":"Auxiliary functions used in the study:","7100d9e0":"Missing value does not exist. :)","6f43748f":"## Diabetes Prediction\n\n![Ekran Resmi 2022-01-16 20.18.50.png](attachment:cb0604bb-df46-4122-899c-989f726395a4.png)\n\n\n### Business Problem : \n\nIt is desired to develop a machine learning model that can predict whether people have diabetes when their characteristics are specified.\n\n### Dataset Story\n\nThe dataset is part of the large dataset held at the National Institutes of Diabetes-Digestive-Kidney Diseases in the USA. Data used for diabetes research on Pima Indian women aged 21 and over living in Phoenix, the 5th largest city of the State of Arizona in the USA.\nThe target variable is specified as \"outcome\"; 1 indicates positive diabetes test result, 0 indicates negative.\n\nNumber of variables: 9, Number of observation : 768\n\n### Variables:\n\nPregnancies: Number of pregnancies <br>\nGlucose : 2-hour plasma glucose concentration in the oral glucose tolerance test<br>\nBlood Pressure : Blood Pressure (minor blood pressure) (mm Hg)<br>\nSkinThickness : Skin Thickness<br>\nInsulin: 2-hour serum insulin (mu U\/ml)<br>\nDiabetesPedigreeFunction : Function (2-hour plasma glucose concentration in oral glucose tolerance test)<br>\nBMI : Body mass index<br>\nAge : Age (years)<br>\nOutcome : Have the disease (1) or not (0)<br>","bf212cc4":"Let's check the outlier again.","43284635":"Plot variable importance.","0132f9c2":"#### Missing Value Processing","cef3ad2f":"All variable have outlier."}}