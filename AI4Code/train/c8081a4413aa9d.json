{"cell_type":{"d73c3ad1":"code","4a87d1b3":"code","303d9b37":"code","8b574af6":"code","0faa8aa3":"code","66f85ccc":"code","10b1bbe2":"code","1d085a80":"code","d6000ddb":"code","31f3dc86":"code","939adfb2":"code","be65ffc4":"code","12076326":"code","da23f62b":"code","d45886d1":"code","f7f0fd42":"code","a7272e86":"code","2c44132e":"code","12f7efd8":"code","f0d9ff6a":"code","13fc07c0":"code","efd96cc5":"code","1e625052":"code","f38146d5":"code","b930a2b8":"code","ebb39fea":"code","20334eb2":"code","20104cad":"code","cd01fa03":"code","e9f18853":"code","863b108f":"code","2c7f1c5f":"code","300a6c47":"code","4156432d":"code","5793cbcd":"code","a33de76f":"code","4aa2fcec":"code","4c802b82":"code","c7fbe925":"markdown","b15efdf8":"markdown","be47403f":"markdown","4636f368":"markdown","f8ba11cf":"markdown","eb4abb69":"markdown","2d186dfe":"markdown","05e76f8c":"markdown","486fa435":"markdown","41ff4b32":"markdown","4a0a4d1c":"markdown","a9c1473f":"markdown","036f2b18":"markdown","1aad1438":"markdown","a833e3bc":"markdown","f5227712":"markdown","996da8ed":"markdown"},"source":{"d73c3ad1":"import numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom sklearn.metrics import confusion_matrix\n# np.random.seed(2)\n\nfrom keras.utils.np_utils import to_categorical\n\nimport itertools\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","4a87d1b3":"train_path = \"..\/input\/indian-dance-form-classification\/train\/\"\ntest_path = \"..\/input\/indian-dance-form-classification\/test\/\"\n\nkathak = \"..\/input\/indian-dance-form-classification\/train\/kathak\/\"\nodissi = \"..\/input\/indian-dance-form-classification\/train\/odissi\/\"\nsattriya = \"..\/input\/indian-dance-form-classification\/train\/sattriya\/\"\n\nkathak_path = os.listdir(kathak)\nsattriya_path = os.listdir(sattriya)\nodissi_path = os.listdir(odissi)","303d9b37":"def load_img(path):\n    image = cv2.imread(path)\n    image = cv2.resize(image, (224, 224))\n#     print(labels)\n    return image[...,::-1]\n\n\nplt.imshow(load_img(kathak + kathak_path[2]), cmap='gray')","8b574af6":"plt.imshow(load_img(odissi + odissi_path[2]), cmap='gray')","0faa8aa3":"plt.imshow(load_img(sattriya + sattriya_path[2]), cmap='gray')","66f85ccc":"training_data = []\nIMG_SIZE = 224\n\ndatadir = \"..\/input\/indian-dance-form-classification\/train\/\"\n\n\ncategories = ['bharatanatyam', 'kathak', 'kathakali', 'kuchipudi',  'manipuri', 'mohiniyattam', 'odissi', 'sattriya']\n\ndef create_training_data():\n    for category in categories:\n        path = os.path.join(datadir, category)\n        class_num = categories.index(category)\n        for img in os.listdir(path):\n            try:\n                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_UNCHANGED)\n                new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n                training_data.append([new_array,class_num])\n            except:\n                pass\ncreate_training_data()","10b1bbe2":"training_data = np.array(training_data)\nprint(training_data.shape)","1d085a80":"import random\n\nnp.random.shuffle(training_data)\nfor sample in training_data[:10]:\n    print(sample[1])","d6000ddb":"X = []\ny = []\n\nfor features,label in training_data:\n    X.append(features)\n    y.append(label)\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\ny = np.array(y)","31f3dc86":"print(X.shape)\nprint(y.shape)","939adfb2":"print(np.unique(y, return_counts = True))\n\nprint(y[1:10])","be65ffc4":"a,b = np.unique(y, return_counts = True)\nprint(a)\nprint(b)\nprint(categories)","12076326":"import plotly.graph_objs as go \nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode()\n\ntrace = go.Bar(x = categories, y = b)\ndata = [trace]\nlayout = {\"title\":\"Categories vs Images Distribution\",\n         \"xaxis\":{\"title\":\"Categories\",\"tickangle\":0},\n         \"yaxis\":{\"title\":\"Number of Images\"}}\nfig = go.Figure(data = data,layout=layout)\niplot(fig)","da23f62b":"X = X\/255.0","d45886d1":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.08, random_state=42)","f7f0fd42":"print(\"Shape of test_x: \",X_train.shape)\nprint(\"Shape of train_y: \",y_train.shape)\nprint(\"Shape of test_x: \",X_test.shape)\nprint(\"Shape of test_y: \",y_test.shape)","a7272e86":"y_train = to_categorical(y_train, num_classes = 8)\ny_test = to_categorical(y_test, num_classes = 8)","2c44132e":"print(\"Shape of test_x: \",X_train.shape)\nprint(\"Shape of train_y: \",y_train.shape)\nprint(\"Shape of test_x: \",X_test.shape)\nprint(\"Shape of test_y: \",y_test.shape)","12f7efd8":"print(np.unique(y_train, return_counts = True))\nprint(np.unique(y_test, return_counts = True))","f0d9ff6a":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n\ntrain_x = tf.keras.utils.normalize(X_train,axis=1)\ntest_x = tf.keras.utils.normalize(X_test, axis=1)","13fc07c0":"import numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D, Dropout,Activation\nfrom keras.layers.core import Dense, Flatten\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\n\n# For interupt the training when val loss is stagnant\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","efd96cc5":"model = keras.applications.VGG16(input_shape = (224,224,3), weights = 'imagenet',include_top=False)\n\nfor layer in model.layers:\n    layer.trainable = False\n\nlast_layer = model.output\n\n# add a global spatial average pooling layer\nx = GlobalAveragePooling2D()(last_layer)\n\n# add fully-connected & dropout layers\nx = Dense(4096, activation='relu',name='fc-1')(x)\nx = Dropout(0.2)(x)\nx = Dense(4096, activation='relu',name='fc-2')(x)\nx = Dropout(0.2)(x)\n\n# x = Dense(4096, activation='relu',name='fc-3')(x)\n# x = Dropout(0.2)(x)\n\n# a softmax layer for 8 classes\nnum_classes = 8\nout = Dense(num_classes, activation='softmax',name='output_layer')(x)\n\n# this is the model we will train\nmodel2 = Model(inputs=model.input, outputs=out)\n\nmodel2.summary()","1e625052":"model2.compile(optimizer='adam',\n              loss ='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n\n\n# hist = model2.fit(X_train,y_train, batch_size=30, epochs = 100, validation_data = (X_test,y_test), callbacks=[early_stopping])\nhist = model2.fit(X_train,y_train, batch_size=30, epochs = 30, validation_data = (X_test,y_test))","f38146d5":"# Visualizing the training. \n\nepochs = 30\n\n# The uncomment everything in this cell and run it.\n\ntrain_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nxc = range(epochs)\n\nplt.figure(1,figsize=(7,5))\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('num of Epochs')\nplt.ylabel('loss')\nplt.title('train_loss vs val_loss')\nplt.grid(True)\nplt.legend(['train','val'])\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])\n\nplt.figure(2,figsize=(7,5))\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('num of Epochs')\nplt.ylabel('accuracy')\nplt.title('train_acc vs val_acc')\nplt.grid(True)\nplt.legend(['train','val'],loc=4)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])","b930a2b8":"import numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D, Dropout,Activation\nfrom keras.layers.core import Dense, Flatten\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\n\n# For interupt the training when val loss is stagnant\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","ebb39fea":"model = keras.applications.VGG19(input_shape = (224,224,3), weights = 'imagenet',include_top=False)\n\nfor layer in model.layers:\n    layer.trainable = False\n\nlast_layer = model.output\n# add a global spatial average pooling layer\n\n\nx = GlobalAveragePooling2D()(last_layer)\n# add fully-connected & dropout layers\nx = Dense(4096, activation='relu',name='fc-1')(x)\nx = Dropout(0.5)(x)\nx = Dense(4096, activation='relu',name='fc-2')(x)\nx = Dropout(0.5)(x)\n# x = Dense(4096, activation='relu',name='fc-3')(x)\n# x = Dropout(0.5)(x)\n\n# a softmax layer for 8 classes\nnum_classes = 8\nout = Dense(num_classes, activation='softmax',name='output_layer')(x)\n\n# this is the model we will train\nmodel2 = Model(inputs=model.input, outputs=out)\n\nmodel2.summary()","20334eb2":"model2.compile(optimizer='adam',\n              loss ='categorical_crossentropy',\n              metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=4)\n\n\nhist = model2.fit(X_train,y_train, batch_size=30, epochs = 15, validation_data = (X_test,y_test))","20104cad":"## Uncomment everything once you find the number of epochs.\n\nepochs = 15 # should be equal to the number of epochs that the training had took place.\ntrain_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nxc = range(epochs)\n\nplt.figure(1,figsize=(7,5))\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('num of Epochs')\nplt.ylabel('loss')\nplt.title('train_loss vs val_loss')\nplt.grid(True)\nplt.legend(['train','val'])\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])\n\nplt.figure(2,figsize=(7,5))\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('num of Epochs')\nplt.ylabel('accuracy')\nplt.title('train_acc vs val_acc')\nplt.grid(True)\nplt.legend(['train','val'],loc=4)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])","cd01fa03":"import numpy as np\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import GlobalAveragePooling2D, Dropout,Activation\nfrom keras.layers.core import Dense, Flatten\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","e9f18853":"## Just replace Xception with ResNet50 and ResNet101 for trying these models. Honestly both models \n## performed poorly on this dataset.\n\nmodel = keras.applications.Xception(input_shape = (224,224,3), weights = 'imagenet',include_top=False)\nmodel.summary()\n\nfor layer in model.layers:\n\tlayer.trainable = False\n\nlast_layer = model.output\n# add a global spatial average pooling layer\n\n\nx = GlobalAveragePooling2D()(last_layer)\n# add fully-connected & dropout layers\n\nx = Dense(4096, activation='relu',name='fc-1')(x)\nx = Dropout(0.5)(x)\n# x = Dense(4096, activation='relu',name='fc-2')(x)\n# x = Dropout(0.2)(x)\n\n\n# a softmax layer for 8 classes\nnum_classes = 8\nout = Dense(num_classes, activation='softmax',name='output_layer')(x)\n\n# this is the model we will train\nmodel2 = Model(inputs=model.input, outputs=out)\n\n# model2.summary()\n\n","863b108f":"model2.compile(optimizer='adam',\n              loss ='categorical_crossentropy',\n              metrics=['accuracy'])\n\nhist = model2.fit(X_train,y_train, batch_size=10, epochs = 20, validation_data = (X_test, y_test))","2c7f1c5f":"epochs = 20\ntrain_loss = hist.history['loss']\nval_loss = hist.history['val_loss']\ntrain_acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\nxc = range(epochs)\n\nplt.figure(1,figsize=(7,5))\nplt.plot(xc,train_loss)\nplt.plot(xc,val_loss)\nplt.xlabel('num of Epochs')\nplt.ylabel('loss')\nplt.title('train_loss vs val_loss')\nplt.grid(True)\nplt.legend(['train','val'])\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])\n\nplt.figure(2,figsize=(7,5))\nplt.plot(xc,train_acc)\nplt.plot(xc,val_acc)\nplt.xlabel('num of Epochs')\nplt.ylabel('accuracy')\nplt.title('train_acc vs val_acc')\nplt.grid(True)\nplt.legend(['train','val'],loc=4)\n#print plt.style.available # use bmh, classic,ggplot for big pictures\nplt.style.use(['classic'])","300a6c47":"# test_data = []\n# img_id = []\n# IMG_SIZE = 224\n\n\n# def create_testing_data():\n#     path = \"..\/input\/indian-dance-form-classification\/test\/\"\n#     for img in os.listdir(path):\n#         try:\n#             img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_UNCHANGED)\n#             new_array = cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n#             test_data.append([new_array])\n#             img_id.append([img])\n#         except:\n#             pass\n# create_testing_data()","4156432d":"# print(len(test_data))\n# test_data = np.array(test_data)\n# test_data =  test_data.reshape(156,224,224,3)\n# print(test_data.shape)\n# test_data = test_data\/255\n\n# ## ID of Images.\n# print(img_id[0])","5793cbcd":"# import pandas as pd\n# image = []\n# for i in img_id:\n#     image.append(i[0])\n\n# image = np.array(image)\n# print(image.shape)\n# test = pd.DataFrame(image, columns = ['Image'])\n# test.head()","a33de76f":"# import pandas as pd\n\n# predict = model2.predict(test_data)\n# predict = np.argmax(predict,axis = 1)\n# predict = np.array(predict)\n# print(predict.shape)\n\n# print(np.unique(predict,return_counts = True))\n","4aa2fcec":"# x = ['bharatanatyam', 'kathak', 'kathakali', 'kuchipudi',  'manipuri', 'mohiniyattam','odissi','sattriya']\n# y = []\n# for i in predict:\n#     y.append(x[i])\n\n# print(y)\n# y = np.array(y)\n# pred = pd.DataFrame(y, columns = ['target'])\n# pred.head()\n\n","4c802b82":"# test_csv = pd.concat([test,pred], axis=1)\n# # df.sort_values(by=['col1'])\n# new = test_csv.sort_values(by=['Image'])\n# print(new.head())\n\n# new.to_csv(\"test.csv\",columns = list(test_csv.columns),index=False)","c7fbe925":"## References:\n\n- [Hackerearth Deep Learning Challenge Identify Dance Form](https:\/\/www.hackerearth.com\/challenges\/competitive\/hackerearth-deep-learning-challenge-identify-dance-form\/)\n\n- [Keras FAQ](https:\/\/keras.io\/getting_started\/faq\/)\n\n- [Keras.io](https:\/\/keras.io\/api\/)\n\n- [Keras Applications](https:\/\/keras.io\/api\/applications\/)\n\n","b15efdf8":"## [Keras Applications](https:\/\/keras.io\/api\/applications\/)\n\n- Keras Applications are deep learning models that are made available alongside pre-trained weights. These models can be used for   prediction, feature extraction, and fine-tuning.\n\n","be47403f":"**The data is quite well distributed. I had done some data Augmentation and reorganized it and then uploaded on kaggle.**\n\n- [My Updated Dataset](https:\/\/www.kaggle.com\/aditya48\/indian-dance-form-classification)\n\n- Original dataset can be found [here](https:\/\/www.hackerearth.com\/challenges\/competitive\/hackerearth-deep-learning-challenge-identify-dance-form\/).","4636f368":"## Analysing the Training Data:","f8ba11cf":"## [VGG 19](https:\/\/keras.io\/api\/applications\/vgg\/#vgg19-function)\n\n","eb4abb69":"**This is the End of the notebook from tutorial standpoint. After this it was specifically for the competition.**","2d186dfe":"## ResNet 50:\n\n- Proved to be useless in this case.\n- Maybe I'm doing some mistake.\n- Probably Overfitting.\n\n## Xception:","05e76f8c":"## MODELS:\n\n**I will try out.**\n\n- [VGG16](https:\/\/keras.io\/api\/applications\/vgg\/#vgg16-function)\n- [VGG19](https:\/\/keras.io\/api\/applications\/vgg\/#vgg19-function)\n- [ResNet50](https:\/\/keras.io\/api\/applications\/vgg\/#resnet50-function)\n- [ResNet101](https:\/\/keras.io\/api\/applications\/vgg\/#resnet101-function)\n- [Xception](https:\/\/keras.io\/api\/applications\/xception\/)\n ","486fa435":"![dance.jpg](attachment:dance.jpg)","41ff4b32":"### Model Conclusion:\n\n- VGG16 performed pretty well with some additional layers.\n- ResNet50 was way to bigger gun for this problem.\n- Trying out VGG19 for better results.\n- Other options would be: ResNet18 and 34, Xception.","4a0a4d1c":"**Do Upvote if you found this kernel useful and feel free to copy and edit. Also if I missed something let me know in the comments.**","a9c1473f":"### [keras.model.fit](https:\/\/keras.rstudio.com\/reference\/fit.html)","036f2b18":"\n## 1. VGG-16:\n","1aad1438":"## [Train Test Split](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html)","a833e3bc":"## Visualizing the Data.","f5227712":"# Indian Dance Form Classification.\n\nThis notebook is my attempt of the Hackerearth deep learning contest of identifying Indian dance forms. All the credits of dataset goes to them. Although I have made some changes in the dataset. Originally there were 364 images for training data.  \n\n\n*********************************************************************\n\n### Official Details of the Contest:\n\n- [Hackerearth Deep Learning Challenge Identify Dance Form](https:\/\/www.hackerearth.com\/challenges\/competitive\/hackerearth-deep-learning-challenge-identify-dance-form\/)\n\n#### ABOUT CHALLENGE\n\n#### Problem statement\n\nThis International Dance Day, an event management company organized an evening of Indian classical dance performances to celebrate the rich, eloquent, and elegant art of dance. Post the event, the company planned to create a microsite to promote and raise awareness among the public about these dance forms. However, identifying them from images is a tough nut to crack.\n\nYou have been appointed as a Machine Learning Engineer for this project. Build an image tagging Deep Learning model that can help the company classify these images into eight categories of Indian classical dance.\n\nThe dataset consists of 364 images belonging to 8 categories, namely **manipuri, bharatanatyam, odissi, kathakali, kathak, sattriya, kuchipudi, and mohiniyattam.**\n\n*********************************************************************\n\n### Things to look forward to:\n\n- Preparation of Training Data.\n\n- Fine Tuning of Multiple models.\n\n- Early stopping.\n\n- Freezing of layers in base model \n\n- Addition of layers in fine tuned model0.\n\n**This Notebok will give you an enhanced view of transfer learning with multiple pretrained models for Multiclass Image Classification using Keras.**\n","996da8ed":"## Preparing Training Data"}}