{"cell_type":{"cb839f2d":"code","b08b8b6d":"code","b2f4782b":"code","950b2fca":"code","660511d6":"code","6c077146":"code","a5dc2e8d":"code","e859e504":"code","ca194246":"code","74452451":"markdown","a48ecab6":"markdown","82097520":"markdown","1f35b773":"markdown","85c5b35d":"markdown","3610adce":"markdown","dd9165b2":"markdown"},"source":{"cb839f2d":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport pandas as pd \nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GridSearchCV\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks\ncufflinks.go_offline(connected=True)\ninit_notebook_mode(connected=True)\n","b08b8b6d":"data = pd.read_csv('..\/input\/heart.csv')\ncolumns = data.columns\nprint(columns)\n\n# Count Nan values in each column \nnan_values = pd.isna(data).sum()\nif nan_values.sum() == 0:\n    print(\"Aucune valeur manquante n'a \u00e9t\u00e9 d\u00e9tect\u00e9e.\")    \ndata.hist()\ndata\n    \n","b2f4782b":"correlation = data.corr()\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(correlation,cmap='hot', vmin=-1, vmax=1)\nfig.colorbar(cax)\nticks = np.arange(0,len(data.columns),1)\nax.set_xticks(ticks)\nplt.xticks(rotation=90)\nax.set_yticks(ticks)\nax.set_xticklabels(data.columns)\nax.set_yticklabels(data.columns)\nplt.show()\n","950b2fca":"X = data.drop(columns = ['target'])\ny = data[['target']].astype(\"category\")\nX = StandardScaler().fit_transform(X)\n\n\nX = data[['cp','slope','restecg','thalach','exang','oldpeak','ca']]\nX\n","660511d6":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1\/3)\nlogistic_regressor = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)\ny_pred = logistic_regressor.predict(X_test)\nmatrice_confusion = confusion_matrix(y_test, y_pred)\ntaux = sum(np.diag(matrice_confusion))\/sum(sum(matrice_confusion))\nprint(matrice_confusion)\nprint(taux)\nprint('\\n')","6c077146":"mlp = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(5, ), max_iter = 100)\nmlp.fit(X_train, y_train)\ny_pred = mlp.predict(X_test)","a5dc2e8d":"matrice_confusion = confusion_matrix(y_test, y_pred)\ntaux = sum(np.diag(matrice_confusion))\/sum(sum(matrice_confusion))\nprint(matrice_confusion)\nprint(taux)","e859e504":"parameter_space = {\n    'hidden_layer_sizes': [(5,), (10,), (7,)],\n    'activation': ['tanh', 'relu'],\n    'alpha': [0.0001, 0.001, 0.01],\n}\n\nclf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\nclf.fit(X_train, y_train)\n\nprint('Best parameters found:\\n', clf.best_params_)\n\nmeans = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\nfor mean, std, params in zip(means, stds, clf.cv_results_['params']):\n    print(\"%0.3f (+\/-%0.03f) for %r\" % (mean, std * 2, params))","ca194246":"mlp = MLPClassifier(solver='lbfgs', alpha=0.0001, hidden_layer_sizes=(10, ), activation = 'relu')\nmlp.fit(X_train, y_train)\ny_pred = mlp.predict(X_test)\nmatrice_confusion = confusion_matrix(y_test, y_pred)\ntaux = sum(np.diag(matrice_confusion))\/sum(sum(matrice_confusion))\nprint(matrice_confusion)\nprint(taux)","74452451":"Maintenant, on applique le PMC. Les param\u00e8tres du PMC \u00e0 savoir le pas d'apprentissage et le nombre de couches cach\u00e9es sont choisis de fa\u00e7on arbitraire.","a48ecab6":"On s\u00e9pare la base de donn\u00e9es en jeu d'entra\u00eenement et jeu de tests. On souhaite r\u00e9aliser une r\u00e9gression logistique et utiliser un perceptron multicouches et ensuite faire une comparaison entre les deux m\u00e9thodes.  ","82097520":"On remarque que la variable \"target\" est positivement corr\u00e9l\u00e9e avec les variables *cp*, *restecg*, *thalach* et *slope*. Elle est n\u00e9gativement corr\u00e9l\u00e9e avec les variables *exang*, *oldpeak* et *ca*. Pour r\u00e9aliser l'apprentissage dans le but de classifier les donn\u00e9es, on va uniquement travailler avec les sept variables explicatives pr\u00e9c\u00e9dentes. \n\nToujours pour le pr\u00e9traitement des donn\u00e9es, les variables vont \u00eatre centr\u00e9es r\u00e9duites. On peut r\u00e9aliser une analyse en composantes principales (ACP) mais on va se contenter de travailler avec les variables qu'on a. ","1f35b773":"Comme on pouvait s'y attendre, le taux de succ\u00e8s est meilleur que celui obtenu pr\u00e9c\u00e9demment. \n\nOn peut aussi voir que le taux de succ\u00e8s avec le PMC est meilleur que celui obtenu avec le r\u00e9gresseur logistique. Il est important de pr\u00e9ciser qu'on ne peut jamais affirmer qu'un mod\u00e8le est mieux qu'un autre que si on d\u00e9finit une application et un contexte d'\u00e9tudes. Dans le cas pr\u00e9sent, on peut dire que notre jeu de donn\u00e9es et notre application s'adapte mieux \u00e0 un PMC qu'\u00e0 un regresseur logistique. ","85c5b35d":"On doit maintenant trouver les param\u00e8tres optimaux pour avoir le mod\u00e8le le plus adapt\u00e9 \u00e0 la base de donn\u00e9es ainsi qu'\u00e0 l'application. On d\u00e9finit donc un espace de param\u00e8tres sur lesquels on souhaite tester l'optimalit\u00e9 du perceptron multicouches et on affiche les meilleurs param\u00e8tres \u00e0 utiliser. Par la suite, on utilise encore une fois un perceptron multicouches en prenant en compte cette fois-ci les nouveaux param\u00e8tres. ","3610adce":"On s'int\u00e9resse au dataset \"Heart Disease UCI\" disponible sur Kaggle dans les donn\u00e9es de la comp\u00e9tition correspondante. Le jeu de donn\u00e9es contient 14 variables et on s'int\u00e9resse \u00e0 la variable \"target\". Il s'agit d'une variable binaire indiquant la pr\u00e9sence ou non d'une maladie cardiaque chez le patient. On commence d'abord par charger les donn\u00e9es, chercher s'il y a des valeurs manquantes et repr\u00e9senter les histogrammes de nos variables.  ","dd9165b2":"L'objectif du projet est de cr\u00e9er un mod\u00e8le suffisamment bon pour pr\u00e9dire si le patient est en effet atteint ou non d'une maladie cardiaque. Avant de s'int\u00e9resser \u00e0 l'apprentissage, on doit d'abord analyser les variables. \n\nOn commence d'abord par regarder la correlation entre les variables."}}