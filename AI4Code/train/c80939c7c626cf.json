{"cell_type":{"bfa0fdbe":"code","05337a74":"code","0b9c2b10":"code","8860911e":"code","f2fbd46e":"code","60805d34":"code","4a1586d1":"code","d508df0c":"code","f107d2d7":"code","b9c3b411":"code","c746b6e5":"code","b49fa02e":"code","43550c68":"code","af97d3f2":"code","f09dceb6":"code","c61bfd99":"code","7851fb0f":"code","83125e97":"code","cc0cc4eb":"code","c2e69d1c":"code","56507ba9":"code","2fd36c60":"code","1cfd57c9":"code","4bdac73f":"code","c7dae18a":"code","f682777c":"code","471698d7":"code","4b69384d":"code","295b8cce":"code","ff74593f":"code","38ae2927":"code","b0419acf":"code","d9e4c354":"code","ce77881c":"code","2a7367b3":"code","b903418c":"code","dac6f1d8":"code","5a45438d":"code","6223d4e5":"code","49a6b68b":"code","1e904faa":"code","942f130d":"code","7d2adfff":"code","ebe8b6c9":"code","71405a91":"code","8007a580":"code","6bf86ca5":"code","a4ead806":"code","cdf71520":"code","3815fd39":"code","933cfcdc":"code","4e4d7e5d":"code","6e94bc2b":"code","1e21df29":"code","831e8145":"code","723d0658":"code","81c2ecee":"code","8226a46f":"code","d8d1b1f6":"code","06c95336":"code","6c7b4c20":"code","2326ca86":"code","5268fae9":"code","a59acefc":"code","1c04b41a":"code","7914fc97":"code","39daabc5":"code","043e7a83":"code","1a17d71d":"code","40a0d8f0":"code","b0938e87":"code","5e48660f":"code","0f6db166":"code","fe14a493":"code","37530400":"code","d58250f5":"code","2d5623d8":"code","03748c53":"code","3d4f353f":"code","a4759630":"code","cec55686":"code","aee659b4":"code","5989473f":"code","e0bb141f":"code","eb033337":"markdown","07f86d60":"markdown","3bf77e82":"markdown","8f21e826":"markdown","26376afe":"markdown","7b67c62a":"markdown","189e26c6":"markdown","aa85742d":"markdown","5a88700f":"markdown","bbeab188":"markdown","b15024ee":"markdown","0759873f":"markdown","f00c2e3e":"markdown","cecc298e":"markdown","474fbeeb":"markdown","486eda97":"markdown","c0caebc3":"markdown","57b52890":"markdown","a6c208e6":"markdown","51f00096":"markdown","a5821085":"markdown","06f2119e":"markdown","14094e9d":"markdown","9719dc86":"markdown","6525a343":"markdown","6c3ae7d8":"markdown","cab19a96":"markdown","4af84c5c":"markdown","a3144a7f":"markdown","9ea46481":"markdown","1fa92bc0":"markdown","e0c7aa6b":"markdown","c457ca72":"markdown","b0713d81":"markdown","2f9d6290":"markdown","d52a6097":"markdown","03396025":"markdown","f556878d":"markdown","e2021f2f":"markdown","cdb3bc83":"markdown","7a26ec15":"markdown","828ba143":"markdown","98272a4d":"markdown","86ac2bc9":"markdown","2afec16b":"markdown","30f0b65a":"markdown","ff845fd0":"markdown","decc6460":"markdown","cf840141":"markdown","c35c4945":"markdown","52f75989":"markdown","ccc2940c":"markdown","ef307c0a":"markdown"},"source":{"bfa0fdbe":"import pandas as pd\nimport numpy as np\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","05337a74":"train.head()","0b9c2b10":"test.head()","8860911e":"train.shape","f2fbd46e":"test.shape","60805d34":"train.info","4a1586d1":"test.info","d508df0c":"train.isnull().sum()","f107d2d7":"test.isnull().sum()","b9c3b411":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() # default for plots","c746b6e5":"def bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df =pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","b49fa02e":"bar_chart('Sex')","43550c68":"bar_chart('Pclass')","af97d3f2":"bar_chart('SibSp')","f09dceb6":"bar_chart('Parch')","c61bfd99":"train.head(10)","7851fb0f":"train_test_data = [train, test] # combining train and test dataset\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","83125e97":"train['Title'].value_counts()","cc0cc4eb":"test['Title'].value_counts()","c2e69d1c":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","56507ba9":"train.head()","2fd36c60":"test.head()","1cfd57c9":"bar_chart('Title')","4bdac73f":"# delete unnecessary feature from dataset\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","c7dae18a":"train.head()","f682777c":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","471698d7":"train.head()","4b69384d":"bar_chart('Sex')","295b8cce":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","ff74593f":"train.head()","38ae2927":"test.head()","b0419acf":"train.tail()","d9e4c354":"test.tail()","ce77881c":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\n \nplt.show()","2a7367b3":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","b903418c":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","dac6f1d8":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(30, 40)","5a45438d":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 80)","6223d4e5":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(60)","49a6b68b":"train.info()","1e904faa":"test.info()","942f130d":"for dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","7d2adfff":"train.head()","ebe8b6c9":"bar_chart('Age')","71405a91":"Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","8007a580":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","6bf86ca5":"train.head()","a4ead806":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","cdf71520":"train.head()","3815fd39":"# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head(20)","933cfcdc":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n \nplt.show()","4e4d7e5d":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","6e94bc2b":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 30)","1e21df29":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0)","831e8145":"for dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","723d0658":"train.head()","81c2ecee":"train.Cabin.value_counts()","8226a46f":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","d8d1b1f6":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","06c95336":"# Cabin mapping\ncabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","6c7b4c20":"# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","2326ca86":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","5268fae9":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","a59acefc":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","1c04b41a":"train.head()","7914fc97":"test.head()","39daabc5":"# Drop unwanted features\nfeatures_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","043e7a83":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","1a17d71d":"train_data.head()","40a0d8f0":"# We need to import Classifier modules\/Packages\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC","b0938e87":"train.info()","5e48660f":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","0f6db166":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","fe14a493":"#KNN Score\nround(np.mean(score)*100, 2)","37530400":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","d58250f5":"# decision tree Score\nround(np.mean(score)*100, 2)","2d5623d8":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","03748c53":"# Random Forest Score\nround(np.mean(score)*100, 2)","3d4f353f":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","a4759630":"# Naive Bayes Score\nround(np.mean(score)*100, 2)","cec55686":"clf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","aee659b4":"clf = SVC()\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","5989473f":"# Submit the data \nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","e0bb141f":"submission = pd.read_csv('submission.csv')\nsubmission.head()","eb033337":"# This chart confirms Women more likely survived than Men","07f86d60":"# Now we know that some Age columns have missing values\nStatistically we can use Title Median age","3bf77e82":"# 12 Random Forest","8f21e826":"# 7 Cabin","26376afe":"# I have given diff values above you can give your values\nThis is called feature Scaling\nthese above values are convinient because\nML Classifiers use Euclidian distances","7b67c62a":"# There are some missing fields in test data","189e26c6":"# Here there are different types of titles but I am going to use Mr ,Miss Mrs and other categories to Others","aa85742d":"# This chart confirms that passengers having 3rd class tickets were dead in large quantity ","5a88700f":"# 11 Descison Tree","bbeab188":"# This chart cannot specify any data because other titles may be maleor female","b15024ee":"# Score","0759873f":"Bar chart for categorical features","f00c2e3e":"# Here last column is created for Title and values are assigned\n","cecc298e":"# This chart confirms that Passengers with more than 2 siblings or spouse more likely survived","474fbeeb":"We will now begin the most important part of Machine Learning ","486eda97":"# Score","c0caebc3":"#  3 Feature Engineering","57b52890":"# 2 Exploratory Data Analysis\nfirst five rows of train dataset","a6c208e6":"Trainig data has 891 rows and 12 columns","51f00096":"#  *Now I am going to combine train and test data set and create a Title Feature\/Column and extract whether Mr\/Mrs using regular Expression.*","a5821085":"# Score","06f2119e":"Test data has 418 rows and 11 columns","14094e9d":"# 10 K- Nearest Neighbours","9719dc86":"# 5 Age","6525a343":"# Data Dictionary\n\nSurvived 0= Dead, 1 = Alive\nPclass = (Ticket) 1st class, 2nd class or 3rd class \nSibSp = sibling or spouse\nParch = parents or children with passenger\nEmbarked = Port of loadnig passenger(S= Southampton,C = Cheroburg,Q=Queenstown)","6c3ae7d8":"# Similarly count of null values in test data is done below","cab19a96":"# Above we got the acuracy","4af84c5c":"# 8 Family Size","a3144a7f":"# load train and test data sets using pandas","9ea46481":"# Now  we should know that How Titanic Sank?\nActually Titanic sank from the part where Passengers of 3rd class category were located","1fa92bc0":"# 6 Embarked \/ Boarding Place\nFind the missing values\n","e0c7aa6b":"# There are some missing fields in test data","c457ca72":"# Score","b0713d81":"# 7 Fare\/ Ticket Price","2f9d6290":"# 4 Name","d52a6097":"# Modelling\nThis is the most important step in ML","03396025":"# male= 0, female = 1","f556878d":"# Now we should delete unnecessary data","e2021f2f":"# We now need to change the values of Sex because ML algorithms cannot classify with \"male\" or \"female\"","cdb3bc83":"# Until 16 yrs of age there is high chance to survive\nwe can use limits in above code to see the exact age range of survival","7a26ec15":"Assign using these values\nMr : 0\nMiss : 1\nMrs: 2\nOthers: 3 ","828ba143":"# Testing \nTesting our Model is the most importnt step because it tests the accuracy\/prescision of the model","98272a4d":"# 1 Collecting the data\nDownload from kaggle directly https:\/\/www.kaggle.com\/c\/3136\/download-all","86ac2bc9":"more than 50% of 1st class are from S embark\n\nmore than 50% of 2nd class are from S embark\n\nmore than 50% of 3rd class are from S embark","2afec16b":"Feature Engineering is the process of using domain knowledge of the data\nto create features( vectors ) where ML algorithms work\n\n# Features can be said as columns of the data!","30f0b65a":"# Total count of Null values in train data is done below","ff845fd0":"# Now we need to visualise the data","decc6460":"# The Chart confirms a person aboarded alone are more likely dead","cf840141":"# This is the accuracy and the data we have obtained from the Dirty Data ","c35c4945":"# Now we need to convert Age to categorical variable\nchild: 0\nyoung: 1\nadult: 2\nmid-age: 3\nsenior: 4","52f75989":"# 9 Cross Validation (K-fold)\nIn ML we cannot fit the model on training data also we cannot say model will work on final data\nWe must assure our model is not too noisy and got correct pattern","ccc2940c":"# 13 Naive Bayes","ef307c0a":"# 14 SVM"}}