{"cell_type":{"dad7a3e4":"code","63dddf13":"code","5a27183f":"code","dd28745c":"code","f89abc97":"code","13949d28":"code","0609bbac":"code","ee608c8b":"code","9d87101c":"code","84d94d12":"code","0ac47897":"code","67ca788c":"code","261b30ff":"code","49aefa53":"code","f4c2f918":"code","24b3e0ea":"code","fe538033":"code","5b38a900":"code","b6011253":"code","00b4697f":"code","4d73ee4a":"code","35b49614":"code","55392e5e":"code","78c36b9c":"code","97f0db12":"code","00e5a8ff":"code","e01d24ea":"code","cc1ef3a3":"code","415f421e":"code","26a7f0ec":"code","89c66e01":"code","26ee1ced":"code","f164ac90":"code","ce8d20a8":"code","54d919c5":"code","7d6ae9d2":"code","4e17ae72":"code","7f06e9c9":"code","ed2d9fa7":"code","db17fcee":"code","d622e333":"code","b41a7ada":"code","3a60ff67":"code","3f02aaf2":"code","9985551b":"code","21a90416":"code","0fa28ca9":"code","672ed98f":"code","acb2cec4":"code","8f226da0":"code","4c4812d2":"code","4186789c":"code","1bc770e4":"code","b24b9459":"code","491f6466":"code","eca6fda1":"code","b172165b":"code","d45e4129":"code","b900fe3c":"code","72657fae":"code","7e8d03d1":"code","bfc5dbcf":"code","26e4be05":"code","6fd4476c":"code","711a0838":"code","cd1ad001":"code","cdde8760":"code","c6e5e798":"code","694a6ed7":"code","dfee1b69":"code","a94c5e12":"code","f9850367":"code","04524593":"code","461444f1":"code","92f0c1a3":"code","5e5e179f":"code","96f35ce2":"code","fe130fea":"code","38bccb43":"code","e424ef8a":"code","50dd5b9c":"code","ae8c0e44":"code","d7034996":"code","b8f52fcb":"markdown","f8204ff6":"markdown","7bd67542":"markdown","cf23522e":"markdown","17415c6f":"markdown","60017556":"markdown","d63feb31":"markdown","00166b0a":"markdown","e4050100":"markdown","494bfcf2":"markdown","225a634b":"markdown","a9e2f625":"markdown","1696f119":"markdown","51ed0c01":"markdown","f8187b5b":"markdown","0476af5b":"markdown","d0f4f0f8":"markdown","df939288":"markdown","2b0ee423":"markdown","ab46c54a":"markdown"},"source":{"dad7a3e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nprint(\"NumPy version: {}\". format(np.__version__))\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nprint(\"pandas version: {}\". format(pd.__version__))\nimport seaborn as sns\n\nprint(\"seaborn version: {}\". format(sns.__version__))\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","63dddf13":"train = pd.read_csv('..\/input\/train.csv')  # training dataframe\ntest = pd.read_csv('..\/input\/test.csv')  # testing dataframe\ntrain.head()","5a27183f":"#\ubb38\uc790\uc5f4\ub85c \uad6c\uc131\ub418\uc5b4\uc788\ub294 \uc5f4\uacfc, \ubcf4\uba74 count\uac00 \ub2e4\ub978 Age\uc5f4\ucc98\ub7fc \uacb0\uce21\uac12 \uc874\uc7ac\ud558\ub294 \uc5f4\ub3c4 \uc788\uc74c.\ntrain.describe()","dd28745c":"#test \ub370\uc774\ud130 \ub294 \ub300\ub7b5\uc801\uc73c\ub85c 418\uac1c\uc758 \ub370\uc774\ud130\uac00 \uc874\uc7ac \ud558\uba70, \uacb0\uce21\uac12 \ub610\ud55c \ubcf4\uc778\ub2e4.\ntest.describe()","f89abc97":"#Age, Cabin, Embarked \uac01\uac01 null\uac12\uc774 \uc874\uc7ac.\ntrain.isnull().sum()","13949d28":"test.isnull().sum()","0609bbac":"\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#subplot\uc73c\ub85c \uadf8\ub798\ud504\ub97c 1\ud589 2\uc5f4\ub85c 2\uac1c \uc0dd\uc131\ud55c\ub2e4.\nf, ax=plt.subplots(1, 2, figsize=(18,8))\n\n#\uc0dd\uc874\ud55c \uc0ac\ub78c\uacfc \uc0ac\ub9dd\ud55c \uc0ac\ub78c\uc758 \ube44\uc728\uc744 \uc6d0\uadf8\ub798\ud504\ub85c \ubcf4\uc5ec\uc900\ub2e4.\ntrain['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Survived')\nax[0].set_ylabel('')\n\n#\uc0dd\uc874\ud55c \uc0ac\ub78c\uacfc \uc0ac\ub9dd\ud55c \uc0ac\ub78c\uc744 count\ud558\uc5ec \ub9c9\ub300\uadf8\ub798\ud504\ub85c \ubcf4\uc5ec\uc900\ub2e4.\nsns.countplot('Survived',data=train, ax=ax[1])\nax[1].set_title('Survived')\nplt.show()\n\n#\uc57d 61.6%\uac00 \uc0ac\ub9dd\ud558\uc600\uace0, \uc57d 38.4%\uac00 \uc0dd\uc874\ud558\uc600\ub2e4.","ee608c8b":"train['Age'].hist(bins=20, figsize= (15, 6), grid=False)","9d87101c":"plt.figure(figsize=(10, 10))\nsns.heatmap(train.corr(), linewidths=0.01, square= True,\n           annot = True, cmap= plt.cm.viridis, linecolor = 'white')\nplt.title('Correlation between Features')\nplt.show()","84d94d12":"#\ubaa8\ub378\ub9c1\ud55c \ub370\uc774\ud130\ub4e4\uc744 Feature Engineering\uc744 \ud558\uac8c \ub418\uba74, test\ub370\uc774\ud130\ub3c4 \ub611\uac19\uc774 \uc218\uc815\ud574\uc57c\ud558\uae30 \ub54c\ubb38\uc5d0 \ud3b8\ub9ac\uc131\uc744 \uc704\ud574 \uc2e4\ud589\uc2dc\ud0a4\uaca0\uc2b5\ub2c8\ub2e4.\n#\uc6d0\ubcf8\uc758 \ub370\uc774\ud130\ub97c \uac74\ub4dc\ub294 \uac83\uc774\uae30 \ub54c\ubb38\uc5d0, train_test_data\ub97c \uc218\uc815\ud558\uba74 \uc6d0\ubcf8\uc758 \ub370\uc774\ud130\ub3cb\ub3c4 \uac19\uc774 \uc218\uc815\ub429\ub2c8\ub2e4.\ntrain_test_data = [train, test]","0ac47897":"f,ax=plt.subplots(1,3,figsize=(18,5))\n#\uac01 \uc131\ubcc4\uc5d0 \ub530\ub77c\uc11c Survived \ube44\uc728\uc744 \uadf8\ub798\ud504\ub85c \ub098\ud0c0\ub0b8\ub2e4.\ntrain['Survived'][train['Pclass']==1].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\ntrain['Survived'][train['Pclass']==2].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[1],shadow=True)\ntrain['Survived'][train['Pclass']==3].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[2],shadow=True)\nax[0].set_title('Survived (Pclass : 1)')\nax[1].set_title('Survived (Pclass : 2)')\nax[2].set_title('Survived (Pclass : 3)')\nplt.show()\n\n#Pclass\uac00 1\uc778 \uacbd\uc6b0\ub294 63%\uac00 \uc0b4\uc558\uc73c\ub098, 2\uc640 3\uc740 \uac01\uac01 52.7%, 75.8%\uac00 \uc8fd\uc5c8\ub2e4.","67ca788c":"train.groupby('Pclass').mean()","261b30ff":"f,ax=plt.subplots(1,2,figsize=(18,8))\n#\uac01 \uc131\ubcc4\uc5d0 \ub530\ub77c\uc11c Survived \ube44\uc728\uc744 \uadf8\ub798\ud504\ub85c \ub098\ud0c0\ub0b8\ub2e4.\ntrain['Survived'][train['Sex']=='male'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\ntrain['Survived'][train['Sex']=='female'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[1],shadow=True)\nax[0].set_title('Survived (male)')\nax[1].set_title('Survived (female)')\nplt.show()\n\n#male\uc758 Survived \ube44\uc728\uc740 \uc57d 81.1%\uac00 \uc0ac\ub9dd\ud558\uc600\uace0, \uc57d 18.9%\uac00 \uc0dd\uc874\ud558\uc600\ub2e4.\n#female\uc758 Survived \ube44\uc728\uc740 \uc57d 25.8%\uac00 \uc0ac\ub9dd\ud558\uc600\uace0, \uc57d 74.2%\uac00 \uc0dd\uc874\ud558\uc600\ub2e4. \n\n#\ub0a8\uc790\ub294 \uc57d 81%\uac00 \uc0ac\ub9dd\ud558\uc600\uace0, \uc5ec\uc790\ub294 26%\uac00 \uc0ac\ub9dd\ud558\uc600\ub2e4.\n#\ub0a8\uc790\uac00 \ub354 \ub9ce\uc774 \uc0ac\ub9dd\ud55c \uac83\uc73c\ub85c \ubcf4\uc544 Lady - first\uac00 \uc2dc\ud589\ub418\uc5c8\uc744 \uac83\uc774\ub2e4.","49aefa53":"from sklearn.preprocessing import LabelBinarizer\n#\uba3c\uc800 \uc591\uc801\ubcc0\uc218\ub85c \ubc14\uafd4 \uc904 \ud568\uc218 \ud638\ucd9c\nencoder=LabelBinarizer()\n#\ubcc0\ud658\ub41c \uc5f4\uc744 \uc0dd\uc131\ud558\uc5ec \uc801\uc6a9\ntrain['Sex']=encoder.fit_transform(train['Sex'])\ntest['Sex']=encoder.fit_transform(test['Sex'])\ntrain.head(10)\n#\uc774\ub807\uac8c \ud558\uba74 male \uc989, \ub0a8\uc790\uac00 1 \uc5ec\uc790\uac00 0 \uc774 \ub41c\ub2e4.","f4c2f918":"#\uc774\ub984 \uc804\uccb4\ub97c \ud574\uc11d\ud558\uae30 \ub09c\ud574\ud558\uae30 \ub54c\ubb38\uc5d0 \uc0ac\ub78c\uc5d0\uac8c \ubd99\ub294 \ud638\uce6d\uc73c\ub85c \ubd84\uc11d\uc744 \ud558\uace0\uc790 \ud568.\nfor dataset in train_test_data:\n    dataset['Name'] = dataset['Name'].str.extract('([A-Za-z]+)\\.', expand=True)","24b3e0ea":"titles=train['Name'].unique()\ntitles","fe538033":"titles_test=test['Name'].unique()\ntitles_test","5b38a900":"#Mr\ubd80\ud130 Rev\uae4c\uc9c0\ub294 \uc5b4\ub290 \uc815\ub3c4\uc758 \uc778\uc6d0\uc774 \uc788\uc73c\ubbc0\ub85c \ub2e4\ub978 \uc778\uc6d0\ub4e4\uc740 \ube44\uc2b7\ud55c \ud638\uce6d\uc73c\ub85c \ud1b5\uc77c \uc2dc\ucf1c\uc900\ub2e4.\ntrain['Name'].value_counts()","b6011253":"replace_name = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}","00b4697f":"train.replace({'Name' : replace_name}, inplace=True)","4d73ee4a":"test.replace({'Name' : replace_name}, inplace=True)","35b49614":"#\uac01 Name\uc5d0 \ub530\ub77c \uc0dd\uc874\ud655\ub960\uc5d0 \ub530\ub77c \uc0dd\uc874\ud655\ub960\uc774 \ub192\uc744 \uc218\ub85d \ub192\uc740 \uc810\uc218\ub97c \ub9e4\uae34\ub2e4.\ntrain[['Name', 'Survived']].groupby(['Name'], as_index=False).mean()","55392e5e":"#\uc0ac\uc6a9 \uc2dc 'Rev'\uc778 \uacbd\uc6b0 \uc778\uc2dd\uc744 \ud558\uc9c0 \ubabb\ud568. \uaf2d \"\"(\ud070\ub530\uc74c\ud45c) \ub85c \uac10\uc2f8\uc904 \uac83\nscore_name = {\"Rev\" : 0, \"Mr\" : 1, \"Dr\" : 2, \"Master\" : 3, \"Miss\" : 4, \"Mrs\" : 5}\nfor dataset in train_test_data:\n    dataset['Name'] = dataset['Name'].map(score_name)\ntrain.head(10)","78c36b9c":"#\uba3c\uc800 \uc774\ub984\uc5d0 \ub530\ub77c\uc11c \ub098\uc774\uc5d0 Null \uac12\uc744 \ucc44\uc6cc \uc900\ub2e4.\ntitles = [0,1,2,3,4,5]\nfor title in titles:\n    age_to_impute = train.groupby('Name')['Age'].median()[titles.index(title)]\n    train.loc[(train['Age'].isnull()) & (train['Name'] == title), 'Age'] = age_to_impute\ntrain['Age'].isnull().sum()","97f0db12":"for title in titles:\n    age_to_impute = train.groupby('Name')['Age'].median()[titles.index(title)]\n    test.loc[(test['Age'].isnull()) & (test['Name'] == title), 'Age'] = age_to_impute\ntest['Age'].isnull().sum()","00e5a8ff":"#\ub098\uc774\uc640 \uc0dd\uc874\uc5d0 \uad00\ud55c histogram\n\nf, ax = plt.subplots(1, 1, figsize=(12, 5))\nsns.kdeplot(train[train['Survived'] == 1]['Age'], ax=ax)\nsns.kdeplot(train[train['Survived'] == 0]['Age'], ax=ax)\nplt.legend(['Survived == 1', 'Survived == 0'])\nplt.show()\n\n#\ub098\uc774\uc5d0 \ub530\ub77c\uc11c 20~30\ub300 \uc77c\uc218\ub85d \ub9ce\uc774 \uc0dd\uc874\ud558\uae30\ub3c4 \ud588\uc73c\uba70 \ub610\ud55c \ub9ce\uc774 \uc8fd\uae30\ub3c4 \ud588\ub2e4.\n#\ub098\uc774\uac00 \uc5b4\ub9b4\uc218\ub85d \uc0dd\uc874\ud655\ub960\uc774 \ub192\ub2e4.","e01d24ea":"#\ub098\uc774 \uad6c\uac04\uc744 \ub098\ub204\uc5b4 \uc900\ub2e4.\nfor dataset in train_test_data:\n    dataset['Age_bin'] = pd.cut(train['Age'], 5)","cc1ef3a3":"train[['Age_bin','Survived']].groupby(['Age_bin'], as_index=False).mean().sort_values(by='Survived')","415f421e":"group_names = [4,1,3,2,0]\n#Age\ub97c score\ub85c \ud658\uc0b0\ud55c\ub2e4.\nfor dataset in train_test_data:\n    dataset['Age'] = pd.cut(train['Age'], 5, labels=group_names)","26a7f0ec":"#\ub9ce\uc774 \uc0b4\uc558\uc744 \uc218\ub85d \uc810\uc218\uac00 \ub354 \ub192\uc740 \uac83\uc744 \ud655\uc778 \ud560 \uc218 \uc788\ub2e4.\ntrain[['Age','Survived']].groupby(['Age'], as_index=False).mean().sort_values(by='Survived')","89c66e01":"#Embarked\uac19\uc740 \uacbd\uc6b0 2\uba85\uc758 null\uac12\uc774 \uc788\ub294\ub370 \uc774\ub294 S\uc5d0\uc11c \ud0d1\uc2b9\ud55c \uc778\uc6d0\uc774 \uc81c\uc77c \ub9ce\uae30 \ub54c\ubb38\uc5d0 S\ub85c \ucc44\uc6cc\ub123\uaca0\uc2b5\ub2c8\ub2e4.\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","26ee1ced":"#\ub9ce\uc774 \uc0b4\uc558\uc744 \uc218\ub85d \uc810\uc218\uac00 \ub354 \ub192\uc740 \uac83\uc744 \ud655\uc778 \ud560 \uc218 \uc788\ub2e4.\ntrain[['Embarked','Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived')","f164ac90":"#\uc774\uac83\ub3c4 \uc0dd\uc874\uc728\uc774 \ub192\uc744 \uc218\ub85d \ub192\uc740 \uc810\uc218\ub97c \ud560\ub2f9 \ud55c\ub2e4.\nembarked_mapping = {\"S\": 0, \"Q\": 1, \"C\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","ce8d20a8":"train['FamilySize'] = train['SibSp'] + train['Parch'] + 1 # \uc790\uc2e0\uc744 \ud3ec\ud568\ud574\uc57c\ud558\ub2c8 1\uc744 \ub354\ud569\ub2c8\ub2e4\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1 # \uc790\uc2e0\uc744 \ud3ec\ud568\ud574\uc57c\ud558\ub2c8 1\uc744 \ub354\ud569\ub2c8\ub2e4","54d919c5":"train[['FamilySize','Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived')","7d6ae9d2":"replace_family = {8 : 0, 11 : 0, 6:1, 5: 2, 1:3, 7:4, 2 : 5, 3 :6, 4:7}","4e17ae72":"for dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].apply(lambda x: replace_family.get(x))","7f06e9c9":"test['Fare'].fillna(train['Fare'].median(), inplace = True)","ed2d9fa7":"train","db17fcee":"for dataset in train_test_data:\n    dataset['Fare_bin'] = pd.cut(train['Fare'], 4)","d622e333":"train[['Fare_bin','Survived']].groupby(['Fare_bin'], as_index=False).mean().sort_values(by='Survived')","b41a7ada":"group_fare = [0,2,1,3]\nfor dataset in train_test_data:\n    dataset['Fare'] = pd.cut(train['Fare'], 4, labels=group_fare)","3a60ff67":"train[['Fare','Survived']].groupby(['Fare'], as_index=False).mean()","3f02aaf2":"train['Cabin'].value_counts().sort_index()","9985551b":"#Cabin\uc758 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud558\uae30\uc704\ud574 \uc81c\uc77c \uc55e \uc54c\ud30c\ubcb3\ub9cc \uc774\uc6a9\uc744 \ud568.\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","21a90416":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf=pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class', '2nd class', '3rd class']\ndf.plot(kind='bar', stacked=True, figsize=(10,5))","0fa28ca9":"# fill missing Fare with median fare for each Pclass\ntrain.loc[(train['Cabin'].isnull())&(train['Pclass']==1), 'Cabin'] = 'E'\ntrain.loc[(train['Cabin'].isnull())&(train['Pclass']==2), 'Cabin'] = 'D'\ntrain.loc[(train['Cabin'].isnull())&(train['Pclass']==3), 'Cabin'] = 'F'\ntest.loc[(test['Cabin'].isnull())&(test['Pclass']==1), 'Cabin'] = 'E'\ntest.loc[(test['Cabin'].isnull())&(test['Pclass']==2), 'Cabin'] = 'D'\ntest.loc[(test['Cabin'].isnull())&(test['Pclass']==3), 'Cabin'] = 'F'","672ed98f":"Survived_1 = train[train['Survived']==1]['Cabin'].value_counts()\nSurvived_0 = train[train['Survived']==0]['Cabin'].value_counts()\ndf=pd.DataFrame([Survived_1, Survived_0])\ndf.index = ['1', '0']\ndf.plot(kind='bar', stacked=True, figsize=(10,5))","acb2cec4":"cabin_mapping = {\"B\": 0,  \"C\": 1 , \"A\": 2, \"T\": 3, \"E\": 4, \"D\": 5, \"F\": 6, \"G\": 7}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","8f226da0":"train.head(10)","4c4812d2":"features_drop = ['Ticket', 'SibSp', 'Parch', 'Age_bin', 'Fare_bin']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)","4186789c":"train.tail(10)","1bc770e4":"test.head(10)","b24b9459":"train.to_csv('train.csv', index=False)\ntest.to_csv('test.csv', index=False)","491f6466":"train['Age'] = train['Age'].astype(int)\ntest['Age'] = test['Age'].astype(int)\ntrain['Fare'] = train['Fare'].astype(int)\ntest['Fare'] = test['Fare'].astype(int)","eca6fda1":"train.info()","b172165b":"test.info()","d45e4129":"# Importing Classifier Modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","b900fe3c":"import tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nnp.random.seed(42)\n\nprint('tensorflow version : ', tf.__version__)\nprint('keras version : ', keras.__version__)","72657fae":"#\ubaa8\ub378\ub9c1\uc758 \uac04\ud3b8\ud654\ub97c \uc704\ud574..\ntrain = train.drop(['PassengerId'], axis=1)","7e8d03d1":"train.info()","bfc5dbcf":"x_data = train.values[:, 1:]\ny_data = train.values[:, 0]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(x_data, y_data, test_size = 0.3, random_state = 42)","26e4be05":"model = Sequential()\nmodel.add(Dense(255, input_shape=(8, ), activation = 'relu'))\nmodel.add(Dense((1), activation = 'sigmoid'))\nmodel.compile(loss='mse', optimizer='Adam', metrics = ['accuracy'])\nmodel.summary()","6fd4476c":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))","711a0838":"hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100)","cd1ad001":"plt.figure(figsize=(12,8))\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.plot(hist.history['acc'])\nplt.plot(hist.history['val_acc'])\nplt.legend(['loss','val_loss', 'acc','val_acc'])\nplt.show()","cdde8760":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","c6e5e798":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\ntrain_data.shape, target.shape","694a6ed7":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","dfee1b69":"# kNN Score\nround(np.mean(score)*100, 2)","a94c5e12":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","f9850367":"# decision tree Score\nround(np.mean(score)*100, 2)","04524593":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","461444f1":"# Random Forest Score\nround(np.mean(score)*100, 2)","92f0c1a3":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","5e5e179f":"# Naive Bayes Score\nround(np.mean(score)*100, 2)","96f35ce2":"#SVC\ub294 C\uc640 gamma\uc5d0 \ub530\ub77c \uc870\uae08 \uc529 \ub2ec\ub77c\uc9c0\ub294\ub370 \uc774\ub54c C=10\uc77c\ub54c accuracy\uac00 \ub354 \ub192\uac8c \ub098\uc634.\nclf = SVC(C=10)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","fe130fea":"round(np.mean(score)*100,2)","38bccb43":"model.fit(train_data, target)\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = model.predict(test_data)","e424ef8a":"prediction = pd.Series(prediction.reshape(418, )).map(lambda x: 1 if x >= 0.5 else 0)","50dd5b9c":"prediction","ae8c0e44":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","d7034996":"submission = pd.read_csv('submission.csv')\nsubmission.head(10)","b8f52fcb":"## 3.5 SVC","f8204ff6":"### \uc608\uce21\ud558\uace0\uc790 \ud558\ub294 Survived\uc758 \ube44\uc728 \uc2dc\uac01\ud654","7bd67542":"# 3. Modelling","cf23522e":"## 2.2 \uc131\ubcc4 (Sex)","17415c6f":"* \uac01 Cabin\ub9c8\ub2e4 \uc810\uc218\ub97c \ud560\ub2f9\ud55c\ub2e4.\n* 1st \uc774\uba74\uc11c \uc0dd\uc874\ube44\uc728 \ub192\uc740 \uc21cB = 0, C = 1, A = 2, T = 3\n* 1st\uc640 2nd \uacb9\uce58\uba74\uc11c \uc0dd\uc874\ube44\uc728 \ub192\uc740 \uc21cE = 4, D = 5\n* 2nd\uc640 3rd\uac00 \uacb9\uce58\uba74\uc11c \uc0dd\uc874 \ube44\uc728 \ub192\uc740 \uc21c F = 6, G=7\n* 1st class : C, B, D, E, A, T\n* 2nd class : D,E,F\n* 3rd class : E,F,G","60017556":"## 2.1 \uac1d\uc2e4\ub4f1\uae09 (Pclass)","d63feb31":"# 2. Preprocessing","00166b0a":"## 2.7 Fare (\uc694\uae08)","e4050100":"## 2.8 Cabin (\uc120\uc2e4)","494bfcf2":"## 2.6 SibSp(\ud615\uc81c \uc790\ub9e4) \uc640 Parch(\ubd80\ubaa8, \uc790\ub140)\n### \uc5ec\uae30\uc11c Family =  SibSp(\ud615\uc81c \uc790\ub9e4) + Parch(\ubd80\ubaa8, \uc790\ub140) \uc774\ubbc0\ub85c Family\ub85c \uc804\ucc98\ub9ac\ub97c \ud55c \ub2e4\uc74c\uc5d0 \ud655\uc778","225a634b":"* \uc804\ucc98\ub9ac\uacfc\uc815\uc774 \ub05d\ub0ac\uc73c\uba70, \uc774\uc81c \ubaa8\ub378\ub9c1\uc744 \ud569\ub2c8\ub2e4.","a9e2f625":"## 3.4 GaussianNB","1696f119":"## 2.3 \uc774\ub984 (Name)","51ed0c01":"## 2.5 \uc2b9\uc120\uc704\uce58 (Embarked)","f8187b5b":"## 3.2 DecisionTreeClassfier(\uacb0\uc815\ud2b8\ub9ac\ubd84\ub958\ubaa8\ud615)","0476af5b":"# 1. Titanic Data Set \ubd88\ub7ec\uc624\uae30\n### Data \ud0d0\uad6c (Exploration)","d0f4f0f8":"* 1st class : C, B, D, E, A, T\n* 2nd class : D,E,F\n* 3rd class : E,F,G\n* \ubaa8\ub4e0 \uac1d\uc2e4\ub4f1\uae09\uc5d0 E\uac00 \uacb9\uce58\uba70, 1st\uc640 2nd\ub294 D, 2nd\uc640 3rd\ub294 F\uac00 \uacb9\uce5c\ub2e4.\n* \ubaa8\ub4e0\uac00\ub2a5\uc131\uc744 \uc5f4\uc5b4\ub450\uae30\uc704\ud574 \uacb9\uce58\ub294 \uc54c\ud30c\ubcb3\uc73c\ub85c null\uac12\uc740 Pclass1\uc740  E \ub85c\ucc44\uc6cc\ub123\uace0 , Pclass2\ub294 D, Pclass3\uc740 F\ub85c \ucc44\uc6cc\ub123\uae30\ub85c \ud55c\ub2e4.","df939288":"## 3.1 KNN","2b0ee423":"## 3.3 Random Forest","ab46c54a":"## 2.4 \ub098\uc774 (Age)"}}