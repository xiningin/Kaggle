{"cell_type":{"d7389300":"code","71c400f2":"code","60ed3ad1":"code","735cbcc8":"code","206bdc27":"code","9856eb48":"code","5f9330a9":"code","6d0c5aa3":"code","04dd46cd":"code","161b7e86":"code","51b9afcf":"code","2af427dc":"code","d4f80ccf":"code","6a7b5249":"code","0ac79ec9":"code","e2f90b7c":"code","c9d1f826":"code","60d10aea":"code","fec754cb":"code","8356cde4":"code","bb8e97eb":"code","f80113d7":"code","c57a03ef":"code","c8c4e54c":"code","3cd463e4":"code","8d955236":"code","85202ad0":"code","8ad2747d":"code","cdaeb14c":"code","2f0fb03a":"code","5d55fdba":"code","1f0b31e1":"code","beace258":"code","6d32e75a":"code","f229aa8e":"code","4c02f554":"code","e43d0bae":"code","82add589":"code","cd1b956f":"code","7220d5e2":"code","78be6c98":"code","b5482b44":"code","c9f45356":"code","e0512f95":"code","bf241805":"code","524716c7":"code","221001c9":"code","1773d8ba":"code","a109bf76":"code","68edf682":"code","527f8945":"code","fc2438f5":"code","9d26a694":"code","82a31eec":"code","6d5b1d9f":"code","74136fd2":"code","116d4f25":"code","d8e7c545":"code","74883fc6":"code","1a4ce4d4":"code","05565e3e":"code","cc3925e8":"code","d44279dc":"code","f70771f7":"code","9c9d06fa":"code","d2701d51":"code","429d114e":"code","e9cd31af":"code","4a3c8c7d":"code","257c9e6c":"code","2c97fe68":"code","868d0b88":"code","2de87639":"code","181e057a":"code","2ae40735":"code","b533e6d3":"code","7f1af3ce":"code","9632da1e":"code","60d73774":"code","4d6f5c93":"code","7c557239":"code","12300f8d":"code","59ed26ae":"code","ade1737e":"code","69fb1cb0":"code","1f7a719b":"code","7fa668b0":"code","36ecc0fe":"code","40ee6eb7":"code","9b469aba":"code","87b815e5":"code","3842aceb":"code","df3d7a20":"code","58bc2846":"code","9b9bfdd5":"code","f9314fab":"code","121e5773":"code","3773ae0f":"code","911f4332":"code","4e574317":"code","60e2e24e":"code","eec83fb5":"code","f0b1dfa2":"code","03bc6386":"code","7c8352f3":"code","f0260fd0":"code","e78747bd":"code","9dc405f0":"code","0f817020":"code","72bcf05a":"code","9ed06b7a":"code","76ced8d4":"code","6eb0f680":"code","28b5ddf6":"code","e3a95ae8":"code","f79577fb":"code","1523a973":"code","b814f0b8":"code","ec077956":"code","6d727c3a":"code","5bb5406c":"code","d67a41fd":"code","7c105abf":"code","73d2b18d":"code","ca8ee0d0":"code","9f69914f":"code","fbd5b389":"code","44bce58a":"code","644c1afb":"code","e9502c69":"code","d3c9a110":"code","fa87d77b":"code","13a09407":"code","f152eb8a":"code","bb107e95":"code","c255863b":"code","43d9aab8":"code","54dde0ce":"code","67b07fa7":"code","164adf1a":"code","800726d6":"code","3ff78074":"code","0122eff1":"code","7d00b123":"code","73221f65":"code","88027333":"code","aa16084c":"code","224a68df":"code","105235de":"code","533e9155":"code","d1e5cbf1":"code","0cf3486a":"code","9c65b256":"code","4fe2247d":"code","70cb9ebe":"code","b8ed28cd":"code","51161101":"code","b2667b43":"code","b2d6630c":"code","5ba8e809":"code","c85e6a65":"code","bbb6ee0c":"code","e4292b59":"code","f7397488":"code","91b6077d":"code","b7a44146":"code","e30146f6":"code","cca83f1b":"code","a32b6348":"code","fe35ba72":"code","8849eff3":"code","4fd217f9":"code","5b286353":"code","4858734f":"code","b224c28c":"code","7f5a8c21":"code","8c4dfa1d":"code","2749ea17":"code","7b70c00e":"code","5bd7186d":"code","64f9e9e5":"code","89c10bb5":"code","21393556":"code","2906ccd2":"code","37e1bc30":"code","38b41a2b":"code","94a2e266":"code","67eb7628":"code","9c970552":"code","c18bdb7e":"code","16669fc2":"code","b496a4ee":"code","a6422df7":"code","fc102805":"code","168b741d":"code","855663cb":"code","315d8575":"code","d7d814b7":"code","bd3b5ae4":"code","997cdaeb":"code","99d9b20d":"code","6a6cb26f":"code","143e4ef8":"code","b741e14f":"code","b7120a0b":"code","06d06878":"code","333ad7a0":"code","18a8b99e":"code","6e696f2c":"code","50b9c305":"code","efde5509":"code","2a0e01c4":"code","9ecbfb1e":"code","0dfc9100":"code","8ad62595":"code","1555facd":"code","4a40a220":"code","43b9c1ca":"code","0e1811a1":"code","0f804793":"code","450a8538":"code","a5bde00b":"code","0bd36fd0":"code","f7f5c982":"code","b77438a2":"code","9d6a3d69":"code","a826fb3d":"code","0d88434a":"code","96313a52":"code","c04822b7":"code","41e3cd6d":"code","45368129":"code","34a20bc4":"code","9317e738":"code","4aebd058":"code","f9e4c326":"code","93d36d62":"code","c109f7b7":"code","61cb65ce":"code","33c514b5":"code","6dcbe444":"code","1089a15d":"code","cdbdb638":"code","44661caf":"code","37e7694b":"code","56b430dd":"code","2bb91712":"code","dd3dea75":"code","62b8e82c":"code","f87dad54":"code","131e6613":"code","e6560996":"code","c6f12c36":"code","224d3adf":"code","016a3dd0":"code","355ccde6":"code","0898a5f3":"code","307eb1d3":"code","002d9b41":"code","cc4a0c87":"code","b845b8a0":"code","218a888f":"code","5013a7ba":"code","08bfc127":"code","a6583a19":"code","fce5ce84":"code","ead7c060":"code","a1d5d3ed":"code","6421112d":"code","06dae3b6":"code","1a7d0e3d":"code","aa1b5099":"code","c87b7603":"code","bf390986":"code","73713884":"code","6fac1bde":"code","7f455549":"code","c0751c15":"code","9ae91585":"code","b08e4aad":"code","496d55d1":"code","4dd4e9fa":"code","fd0c7c97":"code","8e32ee1c":"code","08652fbe":"code","604c32a4":"code","59812f06":"code","7ce670c5":"code","812bf6f2":"code","962e8c74":"code","9b4b50e6":"code","5690a7da":"code","4b1de4dd":"code","fc1ee9a8":"code","86b1e370":"code","e0d691ad":"code","856eecfe":"code","15f3c2e7":"code","52b45e2d":"code","7b1202a7":"code","797fb46d":"code","8113f091":"code","9ebbc96e":"code","057b12ee":"code","3bba0e57":"code","00a5fc1f":"code","98767a4d":"code","e052c2ac":"code","6fa50627":"code","86dbb0df":"code","126eda85":"code","9a667f37":"code","edb7a6c9":"code","b3903a7d":"code","b5ce52f9":"code","b19beb81":"code","34fbacb3":"code","708007d3":"code","dae912b0":"code","47797634":"code","2f973d21":"code","95a1ae57":"code","411e3853":"code","5a6c5c04":"code","8818714c":"code","e1eefaff":"code","d6d28842":"code","a393754b":"code","d8699b6e":"code","f14b7014":"code","7742bcf1":"code","d534399f":"code","8b967a2d":"code","69e26d3c":"code","359452c1":"code","501d5fb3":"code","83b09dde":"code","2342caee":"code","1ecf988d":"code","b9d3bfce":"code","671998a4":"code","b2ecfc29":"code","614db558":"code","9f2c5d47":"code","6146e066":"code","f57e1049":"code","b72395db":"code","5b7b21cd":"code","073bd85d":"code","14abf02c":"code","883b51fb":"code","9a95de2e":"code","21e51d79":"code","09677672":"code","135ca536":"code","32099f8d":"code","271fbc7e":"code","209ad608":"code","d78a2b68":"code","fd85b97a":"code","a4dc6243":"code","5da2ab45":"code","5c16ea50":"code","62070ec1":"code","418f36fd":"code","402a107d":"code","93e999f5":"code","2887abbc":"code","dc3f1a17":"code","f1ae8641":"code","c6430309":"code","63874eae":"code","699ff704":"code","dc0e0e1a":"code","34137223":"code","49e88e7d":"code","e21b1d7b":"code","583110d9":"code","c6b1b6ec":"code","d0d94610":"code","8a33717a":"code","8e1cba99":"code","ffae528a":"code","26eaea30":"code","0bddb8ba":"code","36614edb":"code","d1ae2280":"code","ffb5b381":"code","f8e3f256":"code","3ba89f19":"code","5f3861d5":"code","c7cb1417":"code","e01ebc96":"code","0aa979f7":"code","caa11218":"code","26e1a8c0":"code","0548a10f":"code","c6e285e7":"code","ffcf060e":"code","f47f0bbb":"code","3d1ca54c":"code","3064ea49":"code","87719c91":"code","eba89d99":"code","4e661417":"code","19ad4b89":"code","7506ed97":"code","96fe1c71":"code","bf407b38":"code","01649f71":"code","a1516ee5":"code","7f9a822c":"code","1519597f":"code","f933f9a7":"code","8fc06824":"code","7a5ef189":"code","0bfb1345":"code","bcd096e8":"code","cd0cc99c":"code","0a1aea8c":"code","80f691fe":"code","fea0dde0":"code","fd287b50":"code","52e71bd4":"code","26c64f27":"code","fd03b0b0":"code","dfbb2ee3":"markdown","c9d46a21":"markdown","77e17881":"markdown","78dcd5bf":"markdown","c5b25a33":"markdown","33327336":"markdown","e06e0ddb":"markdown","4178500b":"markdown","72f8d23d":"markdown","e3ae9316":"markdown","d9213a5c":"markdown","be42028c":"markdown","c1408c38":"markdown","ce8b64c2":"markdown","606cf2b3":"markdown","fedbc9d7":"markdown","996dc55f":"markdown","1c9ca72a":"markdown","fadca7e6":"markdown","207b9418":"markdown","2181122e":"markdown","c869bd59":"markdown","c8a8f20e":"markdown","bdc72143":"markdown","11addd20":"markdown","9251de68":"markdown","8ddccb4c":"markdown","7d45ee2d":"markdown","76681c06":"markdown","07ccb159":"markdown","05f88537":"markdown","335c2138":"markdown","7076e6f5":"markdown","c9cbee8e":"markdown","65a89e61":"markdown","9fc0e379":"markdown","06066cc6":"markdown","5ae9651e":"markdown","a941f6fb":"markdown","8009c5d6":"markdown","bb3dfe84":"markdown","a60363d2":"markdown","c7a67a61":"markdown","c1858281":"markdown","77ef9a8d":"markdown","c3f0ae59":"markdown","a98f1129":"markdown","c8264aad":"markdown","03f6fc8f":"markdown","5c867c68":"markdown","586cb52c":"markdown","1abc646d":"markdown","e5c0d910":"markdown","35812339":"markdown","def2ccfa":"markdown","50fad830":"markdown","44c6db88":"markdown","7ed01a38":"markdown","b0fb96b1":"markdown","63392f44":"markdown","e05b24ca":"markdown","2e5e1933":"markdown","0a431736":"markdown","b05f5996":"markdown","6cbcf722":"markdown","aee0c51a":"markdown","a2ef2779":"markdown","01b68dcc":"markdown","807bc0d5":"markdown","4bab8c35":"markdown","b3b93ed8":"markdown","2e3d3dc7":"markdown","024b67bb":"markdown","c54b8885":"markdown","850f64a7":"markdown","5f5f0746":"markdown","2e146ae1":"markdown","9f348284":"markdown","c079a3d4":"markdown","960fb6b8":"markdown","7ab377ce":"markdown","b20fb5f5":"markdown","4d170f79":"markdown","39de50cc":"markdown","0d1c88f3":"markdown","f113c585":"markdown","1747e3ff":"markdown","8b5ead9c":"markdown","2a3608cc":"markdown","44f3970d":"markdown","8c1e0ea7":"markdown","d16b6fd5":"markdown","dcabb72f":"markdown","71d09b01":"markdown","334a3d2e":"markdown","9655a8db":"markdown","26e0e7b9":"markdown","9190bac5":"markdown","74e34858":"markdown","fc7fc2e7":"markdown","5923d3b9":"markdown","aecf8c24":"markdown","5f49cac9":"markdown","eee3fa9d":"markdown","dc8ee106":"markdown","b9126129":"markdown","0501c997":"markdown","6cbb94ae":"markdown","c213d17d":"markdown","1aaa0da7":"markdown","952fb2a3":"markdown","9077c38d":"markdown","1832bbaa":"markdown","62b6149e":"markdown","836136d2":"markdown","c2bbcfc8":"markdown","c171d5fb":"markdown","acc334e1":"markdown","ac65bf71":"markdown","672aee6f":"markdown","8587c4fe":"markdown","d53f6170":"markdown","0bb392df":"markdown","1810fdb1":"markdown","af7a21f6":"markdown","b1739cd5":"markdown","4f723ec3":"markdown","41b6fc7c":"markdown","2445563b":"markdown","94e846da":"markdown","f0b17e37":"markdown","72a30567":"markdown","66705131":"markdown","86645148":"markdown","56798043":"markdown","b73d6bac":"markdown","73596a44":"markdown","01b4bca8":"markdown","03ba9daf":"markdown","245b7146":"markdown","4629045b":"markdown","f2cdd380":"markdown","59207b50":"markdown","a4af7923":"markdown","17d3cf37":"markdown","dfd04e3d":"markdown","699e86f1":"markdown","5b270a7c":"markdown","362a8fe3":"markdown","33abdfc4":"markdown","b68a2f73":"markdown","e631a3dc":"markdown","e5aa34c9":"markdown","ed25497c":"markdown","a34b03a3":"markdown","4214e7a7":"markdown","d6ca0bb6":"markdown","b6510dfb":"markdown","3cfd1a46":"markdown","ea2327d5":"markdown","fca09823":"markdown","b49877ef":"markdown","4df40230":"markdown","aca21d2d":"markdown","9af292a4":"markdown","62bd485a":"markdown","409c57a4":"markdown","67f79a54":"markdown","608bea2e":"markdown","acc27c34":"markdown","58ed608d":"markdown","efe9e3ed":"markdown","cadadb40":"markdown","bcef108a":"markdown","1452a4ef":"markdown","e9f6e68e":"markdown","d4352e90":"markdown","37fcb633":"markdown","3df52827":"markdown","c105513c":"markdown","b27be3f9":"markdown"},"source":{"d7389300":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","71c400f2":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","60ed3ad1":"from sklearn.impute import SimpleImputer, KNNImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler,RobustScaler\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.covariance import EllipticEnvelope\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.model_selection import StratifiedKFold\nimport optuna\nfrom optuna import Trial, visualization\n\nfrom optuna.samplers import TPESampler\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.decomposition import PCA\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import ADASYN\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.over_sampling import SVMSMOTE\nfrom eli5.sklearn import PermutationImportance\nfrom eli5 import show_weights\nfrom eli5 import show_prediction\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport shap\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import PowerTransformer","735cbcc8":"df = pd.read_csv('..\/input\/iba-ml1-mid-project\/train.csv')\ndftest = pd.read_csv('..\/input\/iba-ml1-mid-project\/test.csv')","206bdc27":"df.head()","9856eb48":"df['credit_line_utilization'] = (df['credit_line_utilization'].replace(',','.', regex=True)\n                        .astype(float))","5f9330a9":"X1 = df[['age', 'number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income', 'credit_line_utilization',  \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]\ny = df['defaulted_on_loan']","6d0c5aa3":"dftest['credit_line_utilization'] = (dftest['credit_line_utilization'].replace(',','.', regex=True)\n                        .astype(float))","04dd46cd":"X_testfull = dftest[['age', 'number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income','credit_line_utilization', \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]","161b7e86":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y)","51b9afcf":"X2 = df[['age', 'number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income', \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]\ny = df['defaulted_on_loan']","2af427dc":"X2_train, X2_test, y_train, y_test = train_test_split(X2,y)","d4f80ccf":"modelkn1 = Pipeline(steps=[\n    ('impute', SimpleImputer()),\n    ('classification', KNeighborsClassifier())\n])\nparam_space = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__n_neighbors': range(5, 101, 2)\n}\ngridsearchkn1 = GridSearchCV(modelkn1, param_space, cv=5)","6a7b5249":"gridsearchkn1.fit(X2_train, y_train)","0ac79ec9":"rocaucscorekn1 = roc_auc_score(y_test, gridsearchkn1.predict_proba(X2_test)[:, 1])\nrocaucscorekn1","e2f90b7c":"#MinMaxScaler is added to see the impact on the result\n\nmodelkn2 = Pipeline(steps=[\n    ('scaler', MinMaxScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', KNeighborsClassifier())    \n])\nparam_space = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__n_neighbors': range(5, 101, 2)\n}\ngridsearchkn2 = GridSearchCV(modelkn2, param_space, cv=5)","c9d1f826":"gridsearchkn2.fit(X2_train, y_train)","60d10aea":"rocaucscorekn2 = roc_auc_score(y_test, gridsearchkn2.predict_proba(X2_test)[:, 1])\nrocaucscorekn2","fec754cb":"modelbag = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', BaggingClassifier(DecisionTreeClassifier()))  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__base_estimator__max_depth' : [1, 2, 3, 4, 5],\n    'classification__max_samples' : [0.05, 0.1, 0.2, 0.5],\n    'classification__n_estimators':[100, 200, 300]\n}\ngridsearchbag = GridSearchCV(modelbag, param_grid, cv=5)","8356cde4":"gridsearchbag.fit(X2_train, y_train)","bb8e97eb":"rocaucscorebag = roc_auc_score(y_test, gridsearchbag.predict_proba(X2_test)[:, 1])\nrocaucscorebag","f80113d7":"#Preparing test set without credit line utilization column, in order to make submission\nX_test = dftest[['age', 'number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income', \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]","c57a03ef":"submission1 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchbag.predict_proba(X_test)[:, 1]})\nsubmission1.to_csv('submissionanar1.csv',index=False)","c8c4e54c":"#Added scoring = 'roc_auc' to gridsearch\nmodelrf1 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', RandomForestClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__max_depth' : [20, 30, 40, 50],\n    'classification__min_samples_split':[2, 3],\n    'classification__min_samples_leaf': [3, 5],\n    'classification__n_estimators':[100, 200, 300]\n}\ngridsearchrf1 = GridSearchCV(modelrf1, param_grid, cv=5, scoring = 'roc_auc')","3cd463e4":"gridsearchrf1.fit(X2_train, y_train)","8d955236":"rocaucscorerf1 = roc_auc_score(y_test, gridsearchrf1.predict_proba(X2_test)[:, 1])\nrocaucscorerf1","85202ad0":"submission2 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchrf1.predict_proba(X_test)[:, 1]})\nsubmission2.to_csv('submissionanar2.csv',index=False)","8ad2747d":"modelgb = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', GradientBoostingClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__max_depth' : [2],\n    'classification__n_estimators':[100]\n}\ngridsearchgb = GridSearchCV(modelgb, param_grid, cv=5, scoring = 'roc_auc')","cdaeb14c":"gridsearchgb.fit(X2_train, y_train)","2f0fb03a":"rocaucscoregb = roc_auc_score(y_test, gridsearchgb.predict_proba(X2_test)[:, 1])\nrocaucscoregb","5d55fdba":"submission3 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchgb.predict_proba(X_test)[:, 1]})\nsubmission3.to_csv('submissionanar3.csv',index=False)","1f0b31e1":"#I chose simpler model at first, since GridSearch took a long time to run.\nmodelxgb1 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__max_depth' : [2],\n    'classification__n_estimators':[100]\n}\ngridsearchxgb1 = GridSearchCV(modelxgb1, param_grid, cv=5, scoring = 'roc_auc')","beace258":"gridsearchxgb1.fit(X2_train, y_train)","6d32e75a":"rocaucscorexgb1 = roc_auc_score(y_test, gridsearchxgb1.predict_proba(X2_test)[:, 1])\nrocaucscorexgb1","f229aa8e":"submission4 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchxgb1.predict_proba(X_test)[:, 1]})\nsubmission4.to_csv('submissionanar4.csv',index=False)","4c02f554":"# I want to see what parameters modelxgb1 has and add make comprehensive gridsearch.\nprint(modelxgb1.get_params().keys())","e43d0bae":"modelxgb2 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1, 0.01, 0.001],\n    'classification__gamma':[0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n    'classification__max_depth' : [1, 2],\n    'classification__n_estimators':[100]\n}\ngridsearchxgb2 = GridSearchCV(modelxgb2, param_grid, cv=5, scoring = 'roc_auc')","82add589":"gridsearchxgb2.fit(X2_train, y_train)","cd1b956f":"rocaucscorexgb2 = roc_auc_score(y_test, gridsearchxgb2.predict_proba(X2_test)[:, 1])\nrocaucscorexgb2","7220d5e2":"submission5 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchxgb2.predict_proba(X_test)[:, 1]})\nsubmission5.to_csv('submissionanar5.csv',index=False)","78be6c98":"modellgb = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', lgb.LGBMClassifier(silent=False))  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1, 0.01, 0.001],\n    'classification__reg_alpha':[0, 0.5, 1],\n    'classification__reg_lambda':[1, 1.5, 2, 3, 4.5],\n    'classification__max_depth' : [1, 2],\n    'classification__n_estimators':[100]\n}\ngridsearchlgb = GridSearchCV(modellgb, param_grid, cv=5, n_jobs = -1, scoring = 'roc_auc')","b5482b44":"gridsearchlgb.fit(X2_train, y_train)","c9f45356":"rocaucscorelgb = roc_auc_score(y_test, gridsearchlgb.predict_proba(X2_test)[:, 1])\nrocaucscorelgb","e0512f95":"modelcat = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', cb.CatBoostClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    \n}\ngridsearchcat = GridSearchCV(modelcat, param_grid, cv=5, n_jobs = -1, scoring = 'roc_auc')","bf241805":"gridsearchcat.fit(X2_train, y_train)","524716c7":"rocaucscorecat = roc_auc_score(y_test, gridsearchcat.predict_proba(X2_test)[:, 1])\nrocaucscorecat","221001c9":"modelada = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', AdaBoostClassifier(DecisionTreeClassifier()))  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__base_estimator__max_depth' : [1, 2],\n    'classification__n_estimators':[100]\n}\ngridsearchada = GridSearchCV(modelada, param_grid, cv=5, n_jobs = -1, scoring = 'roc_auc')","1773d8ba":"gridsearchada.fit(X2_train, y_train)","a109bf76":"rocaucscoreada = roc_auc_score(y_test, gridsearchada.predict_proba(X2_test)[:, 1])\nrocaucscoreada","68edf682":"#Hyperparameters was chosen after applying model.get_params.(keys) in the next cell\nmodelxgb3 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1, 0.01, 0.001],\n    'classification__gamma':[0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n    'classification__reg_alpha':[0, 0.5, 1],\n    'classification__colsample_bytree':[0.3, 0.6, 0.8, 1.0],\n    'classification__reg_lambda':[1, 1.5, 2, 3, 4.5],\n    'classification__max_depth' : [1, 2, 3],\n    'classification__subsample':[0.2, 0.4, 0.5, 0.6, 0.7],\n    'classification__min_child_weight':[1, 3, 5, 7],\n    'classification__n_estimators':[100, 150, 200]\n}\nrandomsearchxgb3 = RandomizedSearchCV(modelxgb3, param_grid, cv=5, n_jobs = -1, scoring = 'roc_auc')","527f8945":"print(modelxgb3.get_params().keys())","fc2438f5":"randomsearchxgb3.fit(X2_train, y_train)","9d26a694":"rocaucscorexgb3 = roc_auc_score(y_test, randomsearchxgb3.predict_proba(X2_test)[:, 1])\nrocaucscorexgb3","82a31eec":"#replacing commas with dots and converting to float\ndf['credit_line_utilization'] = (df['credit_line_utilization'].replace(',','.', regex=True)\n                        .astype(float))","6d5b1d9f":"df['credit_line_utilization'].head()","74136fd2":"df.info()","116d4f25":"X1 = df[['age', 'number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income', 'credit_line_utilization',  \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]\ny = df['defaulted_on_loan']","d8e7c545":"#Same comma-dot-float conversion in test file\ndftest['credit_line_utilization'] = (dftest['credit_line_utilization'].replace(',','.', regex=True)\n                        .astype(float))","74883fc6":"X_testfull = dftest[['age', 'number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income','credit_line_utilization', \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]","1a4ce4d4":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y)","05565e3e":"modelnb = Pipeline(steps=[\n    ('impute', SimpleImputer()),\n    ('scaler', RobustScaler()),\n    ('classification', GaussianNB())\n    \n])\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__var_smoothing':np.linspace(1e-9, 2e-9,100)\n}\ngridsearchnb = GridSearchCV(modelnb, param_grid, cv=5, scoring = 'roc_auc')","cc3925e8":"gridsearchnb.fit(X1_train, y_train)","d44279dc":"rocaucscorenb = roc_auc_score(y_test, gridsearchnb.predict_proba(X1_test)[:, 1])\nrocaucscorenb","f70771f7":"modellog = Pipeline(steps=[\n    ('impute', SimpleImputer()),\n    ('scaler', StandardScaler()),\n    ('classification', LogisticRegression())\n    \n])\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__C' : np.logspace(-4, 4, 20)\n}\ngridsearchlog = GridSearchCV(modellog, param_grid, cv=5, scoring = 'roc_auc')","9c9d06fa":"gridsearchlog.fit(X1_train, y_train)","d2701d51":"rocaucscorelog = roc_auc_score(y_test, gridsearchlog.predict_proba(X1_test)[:, 1])\nrocaucscorelog","429d114e":"#The same model for submission 5 file is applied to full dataset\nmodelxgb4 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__max_depth' : [2],\n    'classification__n_estimators':[100]\n}\ngridsearchxgb4 = GridSearchCV(modelxgb4, param_grid, cv=5, scoring = 'roc_auc')","e9cd31af":"gridsearchxgb4.fit(X1_train, y_train)","4a3c8c7d":"rocaucscorexgb4 = roc_auc_score(y_test, gridsearchxgb4.predict_proba(X1_test)[:, 1])\nrocaucscorexgb4","257c9e6c":"submission6 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchxgb4.predict_proba(X_testfull)[:, 1]})\nsubmission6.to_csv('submissionanar6.csv',index=False)","2c97fe68":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y, test_size=0.3)","868d0b88":"#The same model above is applied\ngridsearchxgb4t03 = GridSearchCV(modelxgb4, param_grid, cv=5, scoring = 'roc_auc')","2de87639":"gridsearchxgb4t03.fit(X1_train, y_train)","181e057a":"rocaucscorexgb4t03 = roc_auc_score(y_test, gridsearchxgb4t03.predict_proba(X1_test)[:, 1])\nrocaucscorexgb4t03","2ae40735":"submission7 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchxgb4t03.predict_proba(X_testfull)[:, 1]})\nsubmission7.to_csv('submissionanar7.csv',index=False)","b533e6d3":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y)","7f1af3ce":"#I constructed the following model after several trials\nmodelxgb5 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1],\n    'classification__max_depth' : [2],\n    'classification__n_estimators':[150],\n    'classification__colsample_bytree':[0.4],\n    'classification__scale_pos_weight':[10]\n}\ngridsearchxgb5 = GridSearchCV(modelxgb5, param_grid, cv=5, scoring = 'roc_auc')","9632da1e":"gridsearchxgb5.fit(X1_train, y_train)","60d73774":"rocaucscorexgb5 = roc_auc_score(y_test, gridsearchxgb5.predict_proba(X1_test)[:, 1])\nrocaucscorexgb5","4d6f5c93":"submission8 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchxgb5.predict_proba(X_testfull)[:, 1]})\nsubmission8.to_csv('submissionanar8.csv',index=False)","7c557239":"#After playing with figures of colsample_by_tree several times I get the following model\nmodelxgb6 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1],\n    'classification__max_depth' : [3],\n    'classification__n_estimators':[200],\n    'classification__colsample_bytree':[0.2],\n    'classification__scale_pos_weight':[10]\n}\ngridsearchxgb6 = GridSearchCV(modelxgb6, param_grid, cv=5, scoring = 'roc_auc')","12300f8d":"gridsearchxgb6.fit(X1_train, y_train)","59ed26ae":"rocaucscorexgb6 = roc_auc_score(y_test, gridsearchxgb6.predict_proba(X1_test)[:, 1])\nrocaucscorexgb6","ade1737e":"submission9 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchxgb6.predict_proba(X_testfull)[:, 1]})\nsubmission9.to_csv('submissionanar9.csv',index=False)","69fb1cb0":"modelxgb7 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1],\n    'classification__max_depth' : [3],\n    'classification__n_estimators':[200],\n    'classification__colsample_bytree':[0.2],\n    'classification__min_child_weight':[3],\n    'classification__scale_pos_weight':[10],\n    'classification__reg_lambda':[0.725] \n  \n}\ngridsearchxgb7 = GridSearchCV(modelxgb7, param_grid, cv=5, scoring = 'roc_auc')","1f7a719b":"gridsearchxgb7.fit(X1_train, y_train)","7fa668b0":"rocaucscorexgb7 = roc_auc_score(y_test, gridsearchxgb7.predict_proba(X1_test)[:, 1])\nrocaucscorexgb7","36ecc0fe":"submission10 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchxgb7.predict_proba(X_testfull)[:, 1]})\nsubmission10.to_csv('submissionanar10.csv',index=False)","40ee6eb7":"X1.isnull().sum()","9b469aba":"##Outlier detection do not work with NaN values so I fill missing values with median\nX1_imp = X1.fillna(X1.median())","87b815e5":"X1_imp.info()","3842aceb":"# Converting dataframe to array\nX1_impval = X1_imp.values\ny_val = y.values","df3d7a20":"print(X1_impval.shape)\nprint(y_val.shape)","58bc2846":"X1_val_train, X1_val_test, y_val_train, y_val_test = train_test_split(X1_impval, y_val)","9b9bfdd5":"print(X1_val_train.shape)\nprint(X1_val_test.shape)\nprint(y_val_train.shape)\nprint(y_val_test.shape)","f9314fab":"iso = IsolationForest()\noutl_pred = iso.fit_predict(X1_val_train)\n(outl_pred == -1).mean()","121e5773":"mask = outl_pred != -1\nX1_val_train_out, y_val_train_out = X1_val_train[mask, :], y_val_train[mask]","3773ae0f":"#The result will show the removal of around 3000 rows\nprint(X1_val_train_out.shape)\nprint(y_val_train_out.shape)","911f4332":"model33 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1],\n    'classification__max_depth' : [3],\n    'classification__n_estimators':[200],\n    'classification__colsample_bytree':[0.2],\n    'classification__min_child_weight':[3],\n    'classification__scale_pos_weight':[10],\n    'classification__reg_lambda':[0.725] \n  \n}","4e574317":"gridsearch33iso = GridSearchCV(model33, param_grid, cv=5, scoring = 'roc_auc')","60e2e24e":"gridsearch33iso.fit(X1_val_train_out, y_val_train_out)","eec83fb5":"rocaucscore33iso = roc_auc_score(y_val_test, gridsearch33iso.predict_proba(X1_val_test)[:, 1])\nrocaucscore33iso","f0b1dfa2":"ee = EllipticEnvelope(contamination=0.01)\noutl_pred2 = ee.fit_predict(X1_val_train)\n(outl_pred2 == -1).mean()","03bc6386":"mask = outl_pred2 != -1\nX1_val_train_out2, y_val_train_out2 = X1_val_train[mask, :], y_val_train[mask]","7c8352f3":"# The result will show the removal of approximately 500 rows\nprint(X1_val_train_out2.shape)\nprint(y_val_train_out2.shape)","f0260fd0":"gridsearch33ee = GridSearchCV(model33, param_grid, cv=5, scoring = 'roc_auc')\ngridsearch33ee.fit(X1_val_train_out2, y_val_train_out2)","e78747bd":"rocaucscore33ee = roc_auc_score(y_val_test, gridsearch33ee.predict_proba(X1_val_test)[:, 1])\nrocaucscore33ee","9dc405f0":"lof = LocalOutlierFactor()\noutl_pred3 = lof.fit_predict(X1_val_train)\n(outl_pred3 == -1).mean()","0f817020":"mask = outl_pred3 != -1\nX1_val_train_out3, y_val_train_out3 = X1_val_train[mask, :], y_val_train[mask]","72bcf05a":"# The result will show the removal of approximately 3000 rows\nprint(X1_val_train_out3.shape)\nprint(y_val_train_out3.shape)","9ed06b7a":"gridsearch33lof = GridSearchCV(model33, param_grid, cv=5, scoring = 'roc_auc')\ngridsearch33lof.fit(X1_val_train_out3, y_val_train_out3)","76ced8d4":"rocaucscore33lof = roc_auc_score(y_val_test, gridsearch33lof.predict_proba(X1_val_test)[:, 1])\nrocaucscore33lof","6eb0f680":"oneclass = OneClassSVM(nu=0.01)\noutl_pred4 = oneclass.fit_predict(X1_val_train)\n(outl_pred4 == -1).mean()","28b5ddf6":"mask = outl_pred4 != -1\nX1_val_train_out4, y_val_train_out4 = X1_val_train[mask, :], y_val_train[mask]","e3a95ae8":"# The result will show the removal of approximately 500 rows\nprint(X1_val_train_out4.shape)\nprint(y_val_train_out4.shape)","f79577fb":"gridsearch33ocs = GridSearchCV(model33, param_grid, cv=5, scoring = 'roc_auc')\ngridsearch33ocs.fit(X1_val_train_out4, y_val_train_out4)","1523a973":"rocaucscore33ocs = roc_auc_score(y_val_test, gridsearch33ocs.predict_proba(X1_val_test)[:, 1])\nrocaucscore33ocs","b814f0b8":"#I apply Gridsearch with LightGBM to compare with XGBoost\nmodellgb2 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', lgb.LGBMClassifier(silent=False))  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1, 0.01, 0.001],\n    'classification__reg_alpha':[0, 0.5, 1],\n    'classification__reg_lambda':[1, 1.5, 2, 3, 4.5],\n    'classification__max_depth' : [1, 2],\n    'classification__n_estimators':[100]\n}\ngridsearchlgb2 = GridSearchCV(modellgb2, param_grid, cv=5, scoring = 'roc_auc')","ec077956":"gridsearchlgb2.fit(X1_train, y_train)","6d727c3a":"rocaucscorelgb2 = roc_auc_score(y_test, gridsearchlgb2.predict_proba(X1_test)[:, 1])\nrocaucscorelgb2","5bb5406c":"# I get the following model after trying several numbers to get best result\nmodelgb2 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', GradientBoostingClassifier()) \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1],\n    'classification__max_depth' : [3],\n    'classification__n_estimators':[200],\n    'classification__subsample': [0.8]\n}\ngridsearchgb2 = GridSearchCV(modelgb2, param_grid, cv=5, scoring = 'roc_auc')","d67a41fd":"gridsearchgb2.fit(X1_train, y_train)","7c105abf":"rocaucscoregb2 = roc_auc_score(y_test, gridsearchgb2.predict_proba(X1_test)[:, 1])\nrocaucscoregb2","73d2b18d":"#I remove age column in order to see the impact on results\nX1noage = df[['number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income', 'credit_line_utilization',  \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]\ny = df['defaulted_on_loan']","ca8ee0d0":"X_testnoage = dftest[['number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income','credit_line_utilization', \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]","9f69914f":"X1_noage_train, X1_noage_test, y_train, y_test = train_test_split(X1noage, y)","fbd5b389":"modelxgbnoage = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.1],\n    'classification__max_depth' : [3],\n    'classification__n_estimators':[200],\n    'classification__colsample_bytree':[0.2],\n    'classification__min_child_weight':[3],\n    'classification__scale_pos_weight':[10],\n    'classification__reg_lambda':[0.725]\n  \n}\ngridsearchxgbnoage = GridSearchCV(modelxgbnoage, param_grid, cv=5, scoring = 'roc_auc')","44bce58a":"gridsearchxgbnoage.fit(X1_noage_train, y_train)","644c1afb":"rocaucscorexgbnoage = roc_auc_score(y_test, gridsearchxgbnoage.predict_proba(X1_noage_test)[:, 1])\nrocaucscorexgbnoage","e9502c69":"submission11 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchxgbnoage.predict_proba(X_testnoage)[:, 1]})\nsubmission11.to_csv('submissionanar11.csv',index=False)","d3c9a110":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y)","fa87d77b":"#I changed scaling method to RobustScaler\nmodelxgbrob = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__learning_rate':[0.08],\n    'classification__max_depth' : [3],\n    'classification__n_estimators':[200],\n    'classification__colsample_bytree':[0.2],\n    'classification__min_child_weight':[3],\n    'classification__scale_pos_weight':[10],\n    'classification__reg_lambda':[0.725]   \n  \n}\ngridsearchxgbrob = GridSearchCV(modelxgbrob, param_grid, cv=5, scoring = 'roc_auc')","13a09407":"gridsearchxgbrob.fit(X1_train, y_train)","f152eb8a":"rocaucscorexgbrob = roc_auc_score(y_test, gridsearchxgbrob.predict_proba(X1_test)[:, 1])\nrocaucscorexgbrob","bb107e95":"submission12 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchxgbrob.predict_proba(X_testfull)[:, 1]})\nsubmission12.to_csv('submissionanar12.csv',index=False)","c255863b":"#Trying Optuna with few parameters\ndef objective(trial):\n    params = {\n\n        'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n\n    }\n\n\n\n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)","43d9aab8":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=300)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","54dde0ce":"#Creating model with suggested optimal parameters by Optuna\nmodelxgbop1 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth= 3, n_estimators= 596, learning_rate= 0.03148348658423117))  \n])\n    ","67b07fa7":"modelxgbop1.fit(X1_train, y_train)  ","164adf1a":"rocaucscorexgbop1 = roc_auc_score(y_test, modelxgbop1.predict_proba(X1_test)[:, 1])\nrocaucscorexgbop1","800726d6":"submission13 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbop1.predict_proba(X_testfull)[:, 1]})\nsubmission13.to_csv('submissionanar13.csv',index=False)","3ff78074":"#Optuna with comprehensive XGBoost parameters\ndef objective(trial):\n    params = {\n\n        'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10), \n        \n        \n\n    }\n    \n   \n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)             \n                ","0122eff1":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","7d00b123":"modelxgbop2 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 5,  n_estimators = 458,\\\n                                         learning_rate = 0.01873527965476452,\\\n                                         reg_alpha =2.509999590996414, \\\n                                         reg_lambda = 0.7410520778456283,\\\n                                         gamma = 2.730528656184071,\\\n                                         min_child_weight = 0, \\\n                                         colsample_bytree = 0.6369191472978636,\\\n                                         subsample = 0.7906281128300413, \\\n                                         scale_pos_weight = 4))  \n])","73221f65":"modelxgbop2.fit(X1_train, y_train)","88027333":"rocaucscorexgbop2 = roc_auc_score(y_test, modelxgbop2.predict_proba(X1_test)[:, 1])\nrocaucscorexgbop2","aa16084c":"submission14 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbop2.predict_proba(X_testfull)[:, 1]})\nsubmission14.to_csv('submissionanar14.csv',index=False)","224a68df":"def objective(trial):\n    params = {\n\n        'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10), \n        \n        \n\n    }\n    \n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('pca', PCA(n_components=3)),    \n    ('classification', xgb.XGBClassifier(**params))  \n])\n\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)             ","105235de":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=200)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","533e9155":"X1.isnull().sum()","d1e5cbf1":"#Outlier detection do not work with NaN values so I fill missing values with median\nX1_imp = X1.fillna(X1.median())","0cf3486a":"X1_imp.isnull().sum()","9c65b256":"# Converting dataframe to array\nX1_impval = X1_imp.values\ny_val = y.values","4fe2247d":"X1_val_train, X1_val_test, y_val_train, y_val_test = train_test_split(X1_impval, y_val)","70cb9ebe":"iso = IsolationForest()\noutl_pred = iso.fit_predict(X1_val_train)\n(outl_pred == -1).mean()","b8ed28cd":"mask = outl_pred != -1\nX1_val_train_out, y_val_train_out = X1_val_train[mask, :], y_val_train[mask]","51161101":"def objective(trial):\n    params = {\n\n        'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,12), \n        \n        \n\n    }\n    \n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n\n    model.fit(X1_val_train_out, y_val_train_out)\n    rocaucscore = roc_auc_score(y_val_test, model.predict_proba(X1_val_test)[:, 1])\n\n    return (rocaucscore)             ","b2667b43":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=300)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","b2d6630c":"modelxgbopiso = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 4,  n_estimators = 999,\\\n                                         learning_rate = 0.0075242468566527314,\\\n                                         reg_alpha =4.354286053847354, \\\n                                         reg_lambda = 0.9199571426936122,\\\n                                         gamma = 0.9839092658599847,\\\n                                         min_child_weight = 3, \\\n                                         colsample_bytree = 0.45131617131904217,\\\n                                         subsample = 0.6339525196563881, \\\n                                         scale_pos_weight = 3))  \n])","5ba8e809":"modelxgbopiso.fit(X1_val_train_out, y_val_train_out)","c85e6a65":"rocaucscorexgbopiso = roc_auc_score(y_val_test, modelxgbopiso.predict_proba(X1_val_test)[:, 1])\nrocaucscorexgbopiso","bbb6ee0c":"submission15 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopiso.predict_proba(X_testfull)[:, 1]})\nsubmission15.to_csv('submissionanar15.csv',index=False)","e4292b59":"ee = EllipticEnvelope(contamination=0.01)\noutl_pred2 = ee.fit_predict(X1_val_train)\n(outl_pred2 == -1).mean()","f7397488":"mask = outl_pred2 != -1\nX1_val_train_out2, y_val_train_out2 = X1_val_train[mask, :], y_val_train[mask]","91b6077d":"def objective(trial):\n    params = {\n\n        'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,12) \n        \n        \n\n    }\n    \n    \n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n\n    model.fit(X1_val_train_out2, y_val_train_out2)\n    rocaucscore = roc_auc_score(y_val_test, model.predict_proba(X1_val_test)[:, 1])\n\n    return (rocaucscore)   ","b7a44146":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=800)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","e30146f6":"modelxgbopee = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 6,  n_estimators = 693,\\\n                                         learning_rate = 0.007176038747116481,\\\n                                         reg_alpha =3.5926372549862626, \\\n                                         reg_lambda = 1.793572299371195,\\\n                                         gamma = 1.808351514785053,\\\n                                         min_child_weight = 3, \\\n                                         colsample_bytree = 0.4181179083919801,\\\n                                         subsample = 0.684051369474389, \\\n                                         scale_pos_weight = 3))  \n])","cca83f1b":"modelxgbopee.fit(X1_val_train_out2, y_val_train_out2)","a32b6348":"rocaucscorexgbopee = roc_auc_score(y_val_test, modelxgbopee.predict_proba(X1_val_test)[:, 1])\nrocaucscorexgbopee","fe35ba72":"submission16 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopee.predict_proba(X_testfull)[:, 1]})\nsubmission16.to_csv('submissionanar16.csv',index=False)","8849eff3":"#Filling missing values with median\nX1_imp = X1.fillna(X1.median())","4fd217f9":"#applying SMOTE to whole sample\noversample = SMOTE()\nX1_sm, y_sm = oversample.fit_resample(X1_imp, y)","5b286353":"print(X1_sm.shape)\nprint(y_sm.shape)","4858734f":"X1_sm_train, X1_sm_test, y_sm_train, y_sm_test = train_test_split(X1_sm,y_sm)","b224c28c":"modelgrsm = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('classification', GradientBoostingClassifier())  \n])\n\nparam_grid = {\n    'classification__max_depth' : [2],\n    'classification__n_estimators':[100]\n}\ngridsearchgrsm = GridSearchCV(modelgrsm, param_grid, cv=5, scoring = 'roc_auc')","7f5a8c21":"gridsearchgrsm.fit(X1_sm_train, y_sm_train)","8c4dfa1d":"rocaucscoregrsm = roc_auc_score(y_sm_test, gridsearchgrsm.predict_proba(X1_sm_test)[:, 1])\nrocaucscoregrsm","2749ea17":"# I need fill X_testfull NaNs with medians\nX_test_imp = X_testfull.fillna(X_testfull.median())","7b70c00e":"submission17 = pd.DataFrame({'Id':dftest['Id'],'Predicted':gridsearchgrsm.predict_proba(X_test_imp)[:, 1]})\nsubmission17.to_csv('submissionanar17.csv',index=False)","5bd7186d":"#This time first I train-test split data and then apply SMOTE to train part\nX1_train, X1_test, y_train, y_test = train_test_split(X1_imp,y, test_size=0.4)","64f9e9e5":"X1_sm_train, y_sm_train = oversample.fit_resample(X1_train, y_train)","89c10bb5":"print(X1_sm_train.shape)\nprint(y_sm_train.shape)","21393556":"gridsearchgrsm.fit(X1_sm_train, y_sm_train)","2906ccd2":"rocaucscoregrsm2 = roc_auc_score(y_test, gridsearchgrsm.predict_proba(X1_test)[:, 1])\nrocaucscoregrsm2","37e1bc30":"X1_imp = X1.fillna(X1.median())\nX1_train, X1_test, y_train, y_test = train_test_split(X1_imp,y, test_size=0.4)\novers = ADASYN()\nX1_ad_train, y_ad_train = overs.fit_resample(X1_train, y_train)","38b41a2b":"print(X1_ad_train.shape)\nprint(y_ad_train.shape)","94a2e266":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,12)\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_ad_train, y_ad_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)   ","67eb7628":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=150)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","9c970552":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y, test_size = 0.3)","c18bdb7e":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,12)\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)   ","16669fc2":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=1000)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","b496a4ee":"modelxgbopt03 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 7,  n_estimators = 461,\\\n                                         learning_rate = 0.012102687004164054,\\\n                                         reg_alpha =0.33828384558257274, \\\n                                         reg_lambda = 0.9566220605331344,\\\n                                         gamma = 1.7935102902137234,\\\n                                         min_child_weight = 5, \\\n                                         colsample_bytree = 0.5838267588505452,\\\n                                         subsample = 0.18909399556829531, \\\n                                         scale_pos_weight = 2))  \n])","a6422df7":"modelxgbopt03.fit(X1_train, y_train)","fc102805":"rocaucscorexgbopt03 = roc_auc_score(y_test, modelxgbopt03.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt03","168b741d":"submission18 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt03.predict_proba(X_testfull)[:, 1]})\nsubmission18.to_csv('submissionanar18.csv',index=False)","855663cb":"modelxgbpca = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('pca', PCA()),\n    ('classification', xgb.XGBClassifier())  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'pca__n_components': [2,3,4],\n    'classification__learning_rate':[0.1, 0.01, 0.001],\n    'classification__gamma':[0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n    'classification__reg_alpha':[0, 0.5, 1],\n    'classification__colsample_bytree':[0.2,0.4, 0.6, 0.8, 1.0],\n    'classification__reg_lambda': [1, 1.5, 2, 3, 4.5],\n    'classification__max_depth' : range(1,10),\n    'classification__subsample':[0.2, 0.4, 0.5, 0.6, 0.7],\n    'classification__min_child_weight':[1, 3, 5, 7],\n    'classification__n_estimators':[100, 150, 200],\n    'classification__scale_pos_weight': range(1,10)\n}","315d8575":"randomsearchxgbpca = RandomizedSearchCV(modelxgbpca, param_grid, cv=5, scoring = 'roc_auc')\nrandomsearchxgbpca.fit(X1_train, y_train)","d7d814b7":"rocaucscorexgbpca = roc_auc_score(y_test, randomsearchxgbpca.predict_proba(X1_test)[:, 1])\nrocaucscorexgbpca","bd3b5ae4":"#Displaying the importance of features\nmodelfeatimp = xgb.XGBClassifier()\nmodelfeatimp.fit(X1, y)\n# feature importance\nprint(modelfeatimp.feature_importances_)\n# plot\nplt.bar(range(len(modelfeatimp.feature_importances_)), modelfeatimp.feature_importances_)\nplt.show()","997cdaeb":"modelfsel = xgb.XGBClassifier()\nmodelfsel.fit(X1_train, y_train)\n# make predictions for test data and evaluate\nrocaucscorefsel = roc_auc_score(y_test, modelfsel.predict_proba(X1_test)[:, 1])\nprint(\"ROC_AUC score: %.4f\" % (rocaucscorefsel))","99d9b20d":"thresholds = np.sort(modelfsel.feature_importances_)\nfor thresh in thresholds:\n    # select features using threshold\n    selection = SelectFromModel(modelfsel, threshold=thresh, prefit=True)\n    select_X1_train = selection.transform(X1_train)\n    # train model\n    selection_model = xgb.XGBClassifier()\n    selection_model.fit(select_X1_train, y_train)\n    # eval model\n    select_X1_test = selection.transform(X1_test)\n    rocaucscorefsel = roc_auc_score(y_test, modelfsel.predict_proba(select_X1_test)[:, 1])\n    print(\"Thresh=%.3f,n=%d,ROC_AUC score: %.4f\" % (thresh,select_X1_train.shape[1],rocaucscorefsel))","6a6cb26f":"#I decide to try with test-size=0.15 to see the impact on the results\nX1_train, X1_test, y_train, y_test = train_test_split(X1,y, test_size = 0.15)","143e4ef8":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore) ","b741e14f":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","b7120a0b":"modelxgbopt0151 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 312,\\\n                                         learning_rate = 0.016746750322560486,\\\n                                         reg_alpha = 3.476291462282377, \\\n                                         reg_lambda = 0.9040779882994547,\\\n                                         gamma = 1.8472359123150892,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5785034024536645,\\\n                                         subsample = 0.6213610589899163, \\\n                                         scale_pos_weight = 1))  \n])","06d06878":"modelxgbopt0151.fit(X1_train, y_train)","333ad7a0":"rocaucscorexgbopt0151 = roc_auc_score(y_test, modelxgbopt0151.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt0151","18a8b99e":"rocaucscorexgbopt0151train = roc_auc_score(y_train, modelxgbopt0151.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt0151train","6e696f2c":"submission19 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt0151.predict_proba(X_testfull)[:, 1]})\nsubmission19.to_csv('submissionanar19.csv',index=False)","50b9c305":"modelxgbopt0152 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 318,\\\n                                         learning_rate = 0.017908175298544122,\\\n                                         reg_alpha = 3.7371173636198085, \\\n                                         reg_lambda = 0.9902194985058221,\\\n                                         gamma = 3.023979501244473,\\\n                                         min_child_weight = 2, \\\n                                         colsample_bytree = 0.5159364079662955,\\\n                                         subsample = 0.8027346577264907, \\\n                                         scale_pos_weight = 1))  \n])","efde5509":"modelxgbopt0152.fit(X1_train, y_train)","2a0e01c4":"rocaucscorexgbopt0152 = roc_auc_score(y_test, modelxgbopt0152.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt0152","9ecbfb1e":"rocaucscorexgbopt0152train = roc_auc_score(y_train, modelxgbopt0152.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt0152train","0dfc9100":"submission20 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt0152.predict_proba(X_testfull)[:, 1]})\nsubmission20.to_csv('submissionanar20.csv',index=False)","8ad62595":"modelxgbopt0153 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 399,\\\n                                         learning_rate = 0.012979680717830167,\\\n                                         reg_alpha = 3.3177028575140413, \\\n                                         reg_lambda = 0.9555749913763867,\\\n                                         gamma = 2.015329097514138,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5696916019994976,\\\n                                         subsample = 0.6315283824585797, \\\n                                         scale_pos_weight = 1))  \n])","1555facd":"modelxgbopt0153.fit(X1_train, y_train)","4a40a220":"rocaucscorexgbopt0153 = roc_auc_score(y_test, modelxgbopt0153.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt0153","43b9c1ca":"rocaucscorexgbopt0153train = roc_auc_score(y_train, modelxgbopt0153.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt0153train","0e1811a1":"submission21 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt0153.predict_proba(X_testfull)[:, 1]})\nsubmission21.to_csv('submissionanar21.csv',index=False)","0f804793":"modelxgbopt0154 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 327,\\\n                                         learning_rate = 0.013412592953757106,\\\n                                         reg_alpha = 3.8925729506282796, \\\n                                         reg_lambda = 0.7446243687721962,\\\n                                         gamma = 2.1209209431304976,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5296202834259912,\\\n                                         subsample = 0.537537971538095, \\\n                                         scale_pos_weight = 1))  \n])","450a8538":"modelxgbopt0154.fit(X1_train, y_train)","a5bde00b":"rocaucscorexgbopt0154 = roc_auc_score(y_test, modelxgbopt0154.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt0154","0bd36fd0":"rocaucscorexgbopt0154train = roc_auc_score(y_train, modelxgbopt0154.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt0154train","f7f5c982":"submission22 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt0154.predict_proba(X_testfull)[:, 1]})\nsubmission22.to_csv('submissionanar22.csv',index=False)","b77438a2":"modelxgbopt0155 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 7,  n_estimators = 336,\\\n                                         learning_rate = 0.016352213661148213,\\\n                                         reg_alpha = 3.427217533409418, \\\n                                         reg_lambda = 0.8865539283370905,\\\n                                         gamma = 1.8532528994184325,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5790529591584722,\\\n                                         subsample = 0.6449716171283588, \\\n                                         scale_pos_weight = 1))  \n])","9d6a3d69":"modelxgbopt0155.fit(X1_train, y_train)","a826fb3d":"rocaucscorexgbopt0155 = roc_auc_score(y_test, modelxgbopt0155.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt0155","0d88434a":"rocaucscorexgbopt0155train = roc_auc_score(y_train, modelxgbopt0155.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt0155train","96313a52":"submission23 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt0155.predict_proba(X_testfull)[:, 1]})\nsubmission23.to_csv('submissionanar23.csv',index=False)","c04822b7":"modelxgbopt0156 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 288,\\\n                                         learning_rate = 0.015985831087973842,\\\n                                         reg_alpha = 3.77591910797815, \\\n                                         reg_lambda = 0.8202893066103732,\\\n                                         gamma = 1.750233724761267,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5099779174424808,\\\n                                         subsample = 0.4579355571721199, \\\n                                         scale_pos_weight = 1))  \n])","41e3cd6d":"modelxgbopt0156.fit(X1_train, y_train)","45368129":"rocaucscorexgbopt0156 = roc_auc_score(y_test, modelxgbopt0156.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt0156","34a20bc4":"rocaucscorexgbopt0156train = roc_auc_score(y_train, modelxgbopt0156.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt0156train","9317e738":"submission24 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt0156.predict_proba(X_testfull)[:, 1]})\nsubmission24.to_csv('submissionanar24.csv',index=False)","4aebd058":"modelxgbopt0157 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 409,\\\n                                         learning_rate = 0.010767534452745777,\\\n                                         reg_alpha = 3.2748756229031324, \\\n                                         reg_lambda = 1.0581935243838259,\\\n                                         gamma = 1.9931020897909857,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5625691353586992,\\\n                                         subsample = 0.6356078782322601, \\\n                                         scale_pos_weight = 1))  \n])","f9e4c326":"modelxgbopt0157.fit(X1_train, y_train)","93d36d62":"rocaucscorexgbopt0157 = roc_auc_score(y_test, modelxgbopt0157.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt0157","c109f7b7":"rocaucscorexgbopt0157train = roc_auc_score(y_train, modelxgbopt0157.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt0157train","61cb65ce":"submission25 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt0157.predict_proba(X_testfull)[:, 1]})\nsubmission25.to_csv('submissionanar25.csv',index=False)","33c514b5":"modelxgbopt0158 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 355,\\\n                                         learning_rate = 0.01685235236424297,\\\n                                         reg_alpha = 3.844468296610564, \\\n                                         reg_lambda = 0.9493853052568106,\\\n                                         gamma = 2.7522144967169977,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5328630351108505,\\\n                                         subsample = 0.739153395084266, \\\n                                         scale_pos_weight = 1))  \n])","6dcbe444":"modelxgbopt0158.fit(X1_train, y_train)","1089a15d":"rocaucscorexgbopt0158 = roc_auc_score(y_test, modelxgbopt0158.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt0158","cdbdb638":"rocaucscorexgbopt0158train = roc_auc_score(y_train, modelxgbopt0158.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt0158train","44661caf":"submission26 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt0158.predict_proba(X_testfull)[:, 1]})\nsubmission26.to_csv('submissionanar26.csv',index=False)","37e7694b":"modelxgbopt0159 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 335,\\\n                                         learning_rate = 0.014800865216521946,\\\n                                         reg_alpha = 3.2075559008865087, \\\n                                         reg_lambda = 0.8962717178947177,\\\n                                         gamma = 1.8425457797871765,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5803261999172643,\\\n                                         subsample = 0.6080602992696397, \\\n                                         scale_pos_weight = 1))  \n])","56b430dd":"modelxgbopt0159.fit(X1_train, y_train)","2bb91712":"rocaucscorexgbopt0159 = roc_auc_score(y_test, modelxgbopt0159.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt0159","dd3dea75":"rocaucscorexgbopt0159train = roc_auc_score(y_train, modelxgbopt0159.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt0159train","62b8e82c":"submission27 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt0159.predict_proba(X_testfull)[:, 1]})\nsubmission27.to_csv('submissionanar27.csv',index=False)","f87dad54":"modelxgbopt01510 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 375,\\\n                                         learning_rate = 0.014347834529320648,\\\n                                         reg_alpha = 3.499373975280538, \\\n                                         reg_lambda = 0.9984391921356766,\\\n                                         gamma = 1.658097856305046,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5639072449604189,\\\n                                         subsample = 0.6344904061063109, \\\n                                         scale_pos_weight = 1))  \n])","131e6613":"modelxgbopt01510.fit(X1_train, y_train)","e6560996":"rocaucscorexgbopt01510 = roc_auc_score(y_test, modelxgbopt01510.predict_proba(X1_test)[:, 1])\nrocaucscorexgbopt01510","c6f12c36":"rocaucscorexgbopt01510train = roc_auc_score(y_train, modelxgbopt01510.predict_proba(X1_train)[:, 1])\nrocaucscorexgbopt01510train","224d3adf":"submission28 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgbopt01510.predict_proba(X_testfull)[:, 1]})\nsubmission28.to_csv('submissionanar28.csv',index=False)","016a3dd0":"##Outlier detection do not work with NaN values so I fill missing values with median\nX1_imp = X1.fillna(X1.mean())\nX1_impval = X1_imp.values\ny_val = y.values\nX1_val_train, X1_val_test, y_val_train, y_val_test = train_test_split(X1_impval, y_val)","355ccde6":"oneclass = OneClassSVM(nu=0.01)\noutl_predsvm = oneclass.fit_predict(X1_val_train)\n(outl_predsvm == -1).mean()","0898a5f3":"mask = outl_predsvm != -1\nX1_val_train_outsvm, y_val_train_outsvm = X1_val_train[mask, :], y_val_train[mask]","307eb1d3":"#Applying Optuna\ndef objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        \n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_val_train_outsvm, y_val_train_outsvm)\n    rocaucscore = roc_auc_score(y_val_test, model.predict_proba(X1_val_test)[:, 1])\n\n    return (rocaucscore) ","002d9b41":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","cc4a0c87":"#Best parameters suggested by Optuna\nmodelxgboptsvm = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 6,  n_estimators = 741,\\\n                                         learning_rate = 0.019086201642840257,\\\n                                         reg_alpha =3.2249153978434157, \\\n                                         reg_lambda = 0.9627137063542834,\\\n                                         gamma = 3.498857822042145,\\\n                                         min_child_weight = 4, \\\n                                         colsample_bytree = 0.5452484080239985,\\\n                                         subsample = 0.28908004140065185, \\\n                                         scale_pos_weight = 1))  \n])","b845b8a0":"modelxgboptsvm.fit(X1_val_train_outsvm, y_val_train_outsvm)","218a888f":"rocaucscorexgboptsvm = roc_auc_score(y_val_test, modelxgboptsvm.predict_proba(X1_val_test)[:, 1])\nrocaucscorexgboptsvm","5013a7ba":"submission29 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelxgboptsvm.predict_proba(X_testfull)[:, 1]})\nsubmission29.to_csv('submissionanar29.csv',index=False)","08bfc127":"#Regular train-test split\nX1_train, X1_test, y_train, y_test = train_test_split(X1,y)","a6583a19":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 20),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n        \n        'min_samples_leaf':trial.suggest_int('min_samples_leaf', 1, 100),\n        \n        'min_samples_split':trial.suggest_int('min_sample_split', 2, 100),\n        \n              \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', RandomForestClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore) ","fce5ce84":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","ead7c060":"#Best parameters suggested by Optuna\nmodelrfop = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', RandomForestClassifier(max_depth = 12,  n_estimators = 255,\\\n                                              min_samples_leaf = 63, min_samples_split = 59))\n])\n","a1d5d3ed":"modelrfop.fit(X1_train, y_train)","6421112d":"rocaucscorerfop = roc_auc_score(y_test, modelrfop.predict_proba(X1_test)[:, 1])\nrocaucscorerfop","06dae3b6":"rocaucscorerfoptr = roc_auc_score(y_train, modelrfop.predict_proba(X1_train)[:, 1])\nrocaucscorerfoptr","1a7d0e3d":"submission30 = pd.DataFrame({'Id':dftest['Id'],'Predicted':modelrfop.predict_proba(X_testfull)[:, 1]})\nsubmission30.to_csv('submissionanar30.csv',index=False)","aa1b5099":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y, test_size = 0.15)","c87b7603":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer(strategy = 'most_frequent')),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore) ","bf390986":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","73713884":"model_xgb_freq1 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer(strategy = 'most_frequent')),\n    ('classification', xgb.XGBClassifier(max_depth = 4,  n_estimators = 878,\\\n                                         learning_rate = 0.015532109980800565,\\\n                                         reg_alpha = 5.727012764616641, \\\n                                         reg_lambda = 0.16645420188092208,\\\n                                         gamma = 3.236186830530936,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.7238816503155192,\\\n                                         subsample = 0.8150585925401352, \\\n                                         scale_pos_weight = 1))  \n])","6fac1bde":"model_xgb_freq1.fit(X1_train, y_train)","7f455549":"rocaucscore_xgb_freq1 = roc_auc_score(y_test, model_xgb_freq1.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_freq1","c0751c15":"rocaucscore_xgb_freq1_train = roc_auc_score(y_train, model_xgb_freq1.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_freq1_train","9ae91585":"submission31 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_freq1.predict_proba(X_testfull)[:, 1]})\nsubmission31.to_csv('submissionanar31.csv',index=False)","b08e4aad":"model_xgb_freq2 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer(strategy = 'most_frequent')),\n    ('classification', xgb.XGBClassifier(max_depth = 4,  n_estimators = 889,\\\n                                         learning_rate = 0.011407607971054917,\\\n                                         reg_alpha = 5.453768076888355, \\\n                                         reg_lambda = 0.3943838715788702,\\\n                                         gamma = 2.4204959442193617,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.9214164466731976,\\\n                                         subsample = 0.7412530310144796, \\\n                                         scale_pos_weight = 2))  \n])","496d55d1":"model_xgb_freq2.fit(X1_train, y_train)","4dd4e9fa":"rocaucscore_xgb_freq2 = roc_auc_score(y_test, model_xgb_freq2.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_freq2","fd0c7c97":"rocaucscore_xgb_freq2_train = roc_auc_score(y_train, model_xgb_freq2.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_freq2_train","8e32ee1c":"#I make another submission file\nsubmission32 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_freq2.predict_proba(X_testfull)[:, 1]})\nsubmission32.to_csv('submissionanar32.csv',index=False)","08652fbe":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y, test_size = 0.15)","604c32a4":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', KNNImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)","59812f06":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","7ce670c5":"model_xgb_knnimp1 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', KNNImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 6,  n_estimators = 527,\\\n                                         learning_rate = 0.005808144448718826,\\\n                                         reg_alpha = 0.2228143923707242, \\\n                                         reg_lambda = 1.7830077950248768,\\\n                                         gamma = 3.669868844535821,\\\n                                         min_child_weight = 2, \\\n                                         colsample_bytree = 0.3538690330598881,\\\n                                         subsample = 0.43494219232507625, \\\n                                         scale_pos_weight = 5))  \n])","812bf6f2":"model_xgb_knnimp1.fit(X1_train, y_train)","962e8c74":"rocaucscore_xgb_knnimp1 = roc_auc_score(y_test, model_xgb_knnimp1.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_knnimp1","9b4b50e6":"rocaucscore_xgb_knnimp1_train = roc_auc_score(y_train, model_xgb_knnimp1.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_knnimp1_train","5690a7da":"submission33 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_knnimp1.predict_proba(X_testfull)[:, 1]})\nsubmission33.to_csv('submissionanar33.csv',index=False)","4b1de4dd":"X1_imp = X1.fillna(X1.mean()) #Filling missing values with mean\nX1_train, X1_test, y_train, y_test = train_test_split(X1_imp,y)\novers = SVMSMOTE()\nX1_svm_train, y_svm_train = overs.fit_resample(X1_train, y_train)","fc1ee9a8":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        \n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_svm_train, y_svm_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore) ","86b1e370":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","e0d691ad":"#Creating model with best parameters\nmodel_xgb_svmsmt = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 4,  n_estimators = 761,\\\n                                         learning_rate = 0.026016367357660598,\\\n                                         reg_alpha = 0.6550261423574074, \\\n                                         reg_lambda = 1.7716849899581917,\\\n                                         gamma = 3.601339816653538,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.8834199698097142,\\\n                                         subsample = 0.2809368385855923, \\\n                                         scale_pos_weight = 6))  \n])","856eecfe":"model_xgb_svmsmt.fit(X1_svm_train, y_svm_train)","15f3c2e7":"rocaucscore_xgb_svmsmt = roc_auc_score(y_test, model_xgb_svmsmt.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_svmsmt","52b45e2d":"rocaucscore_xgb_svmsmt_train = roc_auc_score(y_svm_train, model_xgb_svmsmt.predict_proba(X1_svm_train)[:, 1])\nrocaucscore_xgb_svmsmt_train","7b1202a7":"submission34 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_svmsmt.predict_proba(X_testfull)[:, 1]})\nsubmission34.to_csv('submissionanar34.csv',index=False)","797fb46d":"#I make train-test split with stratify=y option in order to see the impact\nX1_train, X1_test, y_train, y_test = train_test_split(X1,y, stratify=y)","8113f091":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', KNNImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)","9ebbc96e":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=2000)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","057b12ee":"#Creating the model with best results\nmodel_xgb_strf = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 5,  n_estimators = 427,\\\n                                         learning_rate = 0.010108981441907772,\\\n                                         reg_alpha = 4.655854073334678, \\\n                                         reg_lambda = 1.7510648237565016,\\\n                                         gamma = 2.0956296271110526,\\\n                                         min_child_weight = 0, \\\n                                         colsample_bytree = 0.5803500678731535,\\\n                                         subsample = 0.7090257993252369, \\\n                                         scale_pos_weight = 6))  \n])","3bba0e57":"model_xgb_strf.fit(X1_train, y_train)","00a5fc1f":"rocaucscore_xgb_strf = roc_auc_score(y_test, model_xgb_strf.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_strf","98767a4d":"rocaucscore_xgb_strf_train = roc_auc_score(y_train, model_xgb_strf.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_strf_train","e052c2ac":"#Out of interest I make submission\nsubmission35 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_strf.predict_proba(X_testfull)[:, 1]})\nsubmission35.to_csv('submissionanar35.csv',index=False)","6fa50627":"#Permutation importance applied to best model (highest public score of 0.85491)\nmodelxgbopt01510 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 375,\\\n                                         learning_rate = 0.014347834529320648,\\\n                                         reg_alpha = 3.499373975280538, \\\n                                         reg_lambda = 0.9984391921356766,\\\n                                         gamma = 1.658097856305046,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5639072449604189,\\\n                                         subsample = 0.6344904061063109, \\\n                                         scale_pos_weight = 1))  \n])","86dbb0df":"modelxgbopt01510.fit(X1_train, y_train)","126eda85":"perm = PermutationImportance(modelxgbopt01510).fit(X1_test, y_test)","9a667f37":"show_weights(perm, feature_names=X1.columns.tolist())","edb7a6c9":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1, y)\n    rocaucscore = roc_auc_score(y, model.predict_proba(X1)[:, 1])\n\n    return (rocaucscore)","b3903a7d":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","b5ce52f9":"#I build the model with best results\nmodel_xgb_full = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 832,\\\n                                         learning_rate = 0.03118953758333564,\\\n                                         reg_alpha = 0.5096177330931144, \\\n                                         reg_lambda = 0.9767482758344794,\\\n                                         gamma = 2.2938178921696317,\\\n                                         min_child_weight = 4, \\\n                                         colsample_bytree = 0.8049318512971987,\\\n                                         subsample = 0.7676773153856727, \\\n                                         scale_pos_weight = 6))  \n])","b19beb81":"model_xgb_full.fit(X1, y)","34fbacb3":"rocaucscore_full = roc_auc_score(y, model_xgb_full.predict_proba(X1)[:, 1])\nrocaucscore_full","708007d3":"submission36 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_full.predict_proba(X_testfull)[:, 1]})\nsubmission36.to_csv('submissionanar36.csv',index=False)","dae912b0":"modelada = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', AdaBoostClassifier(DecisionTreeClassifier()))  \n])\n\nparam_grid = {\n    'impute__strategy': ['mean', 'median'],\n    'classification__base_estimator__max_depth' : [1, 2, 3, 4, 5],\n        'classification__n_estimators':[100, 200, 300]\n}\nrandomsearchada = RandomizedSearchCV(modelada, param_grid, cv=5)","47797634":"randomsearchada.fit(X1_train, y_train)","2f973d21":"rocaucscore_ada = roc_auc_score(y_test, randomsearchada.predict_proba(X1_test)[:, 1])\nrocaucscore_ada","95a1ae57":"rocaucscore_ada_tr = roc_auc_score(y_train, randomsearchada.predict_proba(X1_train)[:, 1])\nrocaucscore_ada_tr","411e3853":"submission37 = pd.DataFrame({'Id':dftest['Id'],'Predicted':randomsearchextra.predict_proba(X_testfull)[:, 1]})\nsubmission37.to_csv('submissionanar37.csv',index=False)","5a6c5c04":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y, test_size = 0.2)","8818714c":"#I divide features into two parts and apply two different imputation strategies\ndef objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10), \n        \n        \n\n    }\n    \n    \n    numeric_features1 = ['age',  'monthly_income', 'ratio_debt_payment_to_income', 'credit_line_utilization' ]\n    numeric_features2 = ['number_dependent_family_members', 'number_of_credit_lines',\\\n                         'real_estate_loans',  'number_of_previous_late_payments_up_to_59_days',\\\n                         'number_of_previous_late_payments_up_to_89_days',\\\n                         'number_of_previous_late_payments_90_days_or_more']\n    \n    model = Pipeline(steps=[\n    ('preprocessing', ColumnTransformer(transformers=[\n        ('numeric1', Pipeline(steps=[\n            ('impute', SimpleImputer(strategy='mean')),\n            ('scale', RobustScaler())\n        ]), numeric_features1),\n        ('numeric2', Pipeline(steps=[\n            ('impute', SimpleImputer(strategy='constant')),\n            ('scale', RobustScaler())\n        ]), numeric_features2)\n    ])),\n    ('classification', xgb.XGBClassifier(**params))\n])\n    \n   \n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)","e1eefaff":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","d6d28842":"numeric_features1 = ['age',  'monthly_income', 'ratio_debt_payment_to_income', 'credit_line_utilization' ]\nnumeric_features2 = ['number_dependent_family_members', 'number_of_credit_lines',\\\n                         'real_estate_loans',  'number_of_previous_late_payments_up_to_59_days',\\\n                         'number_of_previous_late_payments_up_to_89_days',\\\n                         'number_of_previous_late_payments_90_days_or_more']\nmodel_xgb_duo = Pipeline(steps=[\n    ('preprocessing', ColumnTransformer(transformers=[\n        ('numeric1', Pipeline(steps=[\n            ('impute', SimpleImputer(strategy='mean')),\n            ('scale', RobustScaler())\n        ]), numeric_features1),\n        ('numeric2', Pipeline(steps=[\n            ('impute', SimpleImputer(strategy='constant')),\n            ('scale', RobustScaler())\n        ]), numeric_features2)\n    ])),\n    ('classification', xgb.XGBClassifier(max_depth = 9,  n_estimators = 873,\\\n                                         learning_rate = 0.0002242391176709268,\\\n                                         reg_alpha = 1.2815442407471886, \\\n                                         reg_lambda = 0.790376062949395,\\\n                                         gamma = 1.6279346304238707,\\\n                                         min_child_weight = 5, \\\n                                         colsample_bytree = 0.6630381865166305,\\\n                                         subsample = 0.26909908559177403, \\\n                                         scale_pos_weight = 5))\n])","a393754b":"model_xgb_duo.fit(X1_train,y_train)","d8699b6e":"rocaucscore_duo = roc_auc_score(y_test, model_xgb_duo.predict_proba(X1_test)[:, 1])\nrocaucscore_duo","f14b7014":"rocaucscore_duo_tr = roc_auc_score(y_train, model_xgb_duo.predict_proba(X1_train)[:, 1])\nrocaucscore_duo_tr","7742bcf1":"submission38 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_duo.predict_proba(X_testfull)[:, 1]})\nsubmission38.to_csv('submissionanar38.csv',index=False)","d534399f":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y, test_size=0.15)","8b967a2d":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('impute', SimpleImputer()),\n    ('scaler', QuantileTransformer()),    \n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)","69e26d3c":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","359452c1":"#Building model with best parameters\nmodel_xgb_qt = Pipeline(steps=[\n    ('impute', SimpleImputer()),\n    ('scaler', QuantileTransformer()),\n    ('classification', xgb.XGBClassifier(max_depth = 5,  n_estimators = 911,\\\n                                         learning_rate = 0.015660301421354304,\\\n                                         reg_alpha = 0.5870438730166121, \\\n                                         reg_lambda = 1.3732946283248497,\\\n                                         gamma = 0.5467700575738224,\\\n                                         min_child_weight = 0, \\\n                                         colsample_bytree = 0.4332007285578733,\\\n                                         subsample = 0.8788090451838982, \\\n                                         scale_pos_weight = 5))  \n])","501d5fb3":"model_xgb_qt.fit(X1_train, y_train)","83b09dde":"rocaucscore_xgb_qt = roc_auc_score(y_test, model_xgb_qt.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_qt","2342caee":"rocaucscore_xgb_qt_tr = roc_auc_score(y_train, model_xgb_qt.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_qt_tr","1ecf988d":"submission39 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_qt.predict_proba(X_testfull)[:, 1]})\nsubmission39.to_csv('submissionanar39.csv',index=False)","b9d3bfce":"#Scaling method - Power Transformer\ndef objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('impute', SimpleImputer()),\n    ('scaler', PowerTransformer()),    \n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)","671998a4":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","b2ecfc29":"model_xgb_pt = Pipeline(steps=[\n    ('impute', SimpleImputer()),\n    ('scaler', PowerTransformer()),\n    ('classification', xgb.XGBClassifier(max_depth = 4,  n_estimators = 172,\\\n                                         learning_rate = 0.18463989567170103,\\\n                                         reg_alpha = 1.002495849485967, \\\n                                         reg_lambda = 0.9461452045569956,\\\n                                         gamma = 1.9119004195706677,\\\n                                         min_child_weight = 2, \\\n                                         colsample_bytree = 0.4942743657574854,\\\n                                         subsample = 0.9076687936626322, \\\n                                         scale_pos_weight = 7))  \n])","614db558":"model_xgb_pt.fit(X1_train, y_train)","9f2c5d47":"rocaucscore_xgb_pt = roc_auc_score(y_test, model_xgb_pt.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_pt","6146e066":"rocaucscore_xgb_pt_tr = roc_auc_score(y_train, model_xgb_pt.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_pt_tr","f57e1049":"submission40 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_pt.predict_proba(X_testfull)[:, 1]})\nsubmission40.to_csv('submissionanar40.csv',index=False)","b72395db":"#Scaling method - Normalizer\ndef objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('impute', SimpleImputer()),\n    ('scaler', Normalizer()),    \n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)","5b7b21cd":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","073bd85d":"model_xgb_nr = Pipeline(steps=[\n    ('impute', SimpleImputer()),\n    ('scaler', Normalizer()),\n    ('classification', xgb.XGBClassifier(max_depth = 5,  n_estimators = 511,\\\n                                         learning_rate = 0.01759119018165347,\\\n                                         reg_alpha = 5.321052738318551, \\\n                                         reg_lambda = 1.7989336517024013,\\\n                                         gamma = 3.5501678573365374,\\\n                                         min_child_weight = 3, \\\n                                         colsample_bytree = 0.5706753804548877,\\\n                                         subsample = 0.2501425867159268, \\\n                                         scale_pos_weight = 3))  \n])","14abf02c":"model_xgb_nr.fit(X1_train, y_train)","883b51fb":"rocaucscore_xgb_nr = roc_auc_score(y_test, model_xgb_nr.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_nr","9a95de2e":"rocaucscore_xgb_nr_tr = roc_auc_score(y_train, model_xgb_nr.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_nr_tr","21e51d79":"submission41 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_nr.predict_proba(X_testfull)[:, 1]})\nsubmission41.to_csv('submissionanar41.csv',index=False)","09677672":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y )","135ca536":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10), \n        \n        \n\n    }\n    \n    \n    numeric_features1 = ['age',  'monthly_income', 'ratio_debt_payment_to_income', \\\n                         'credit_line_utilization','real_estate_loans' ]\n    numeric_features2 = ['number_dependent_family_members', 'number_of_credit_lines',\\\n                         'number_of_previous_late_payments_up_to_59_days',\\\n                         'number_of_previous_late_payments_up_to_89_days',\\\n                         'number_of_previous_late_payments_90_days_or_more']\n    \n    model = Pipeline(steps=[\n    ('preprocessing', ColumnTransformer(transformers=[\n        ('numeric1', Pipeline(steps=[\n            ('impute', SimpleImputer(strategy='mean')),\n            ('scale', RobustScaler())\n        ]), numeric_features1),\n        ('numeric2', Pipeline(steps=[\n            ('impute', SimpleImputer(strategy='constant')),\n            ('scale', RobustScaler())           \n        ]), numeric_features2)\n    ])),\n    ('classification', xgb.XGBClassifier(**params))\n])\n    \n   \n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)","32099f8d":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","271fbc7e":"#Building model with best parameter\nnumeric_features1 = ['age',  'monthly_income', 'ratio_debt_payment_to_income', \\\n                         'credit_line_utilization','real_estate_loans' ]\nnumeric_features2 = ['number_dependent_family_members', 'number_of_credit_lines',\\\n                         'number_of_previous_late_payments_up_to_59_days',\\\n                         'number_of_previous_late_payments_up_to_89_days',\\\n                         'number_of_previous_late_payments_90_days_or_more']\nmodel_xgb_duonew = Pipeline(steps=[\n    ('preprocessing', ColumnTransformer(transformers=[\n        ('numeric1', Pipeline(steps=[\n            ('impute', SimpleImputer(strategy='mean')),\n            ('scale', RobustScaler())\n        ]), numeric_features1),\n        ('numeric2', Pipeline(steps=[\n            ('impute', SimpleImputer(strategy='constant')),\n            ('scale', RobustScaler())\n        ]), numeric_features2)\n    ])),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 616,\\\n                                         learning_rate = 0.0008478162883470763,\\\n                                         reg_alpha = 0.12492376516785927, \\\n                                         reg_lambda = 0.5481816803477964,\\\n                                         gamma = 3.6602590949207845,\\\n                                         min_child_weight = 5, \\\n                                         colsample_bytree = 0.5699446284130814,\\\n                                         subsample = 0.4396606794774216, \\\n                                         scale_pos_weight = 3))\n])","209ad608":"model_xgb_duonew.fit(X1_train, y_train)","d78a2b68":"rocaucscore_xgb_duonew = roc_auc_score(y_test, model_xgb_duonew.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_duonew","fd85b97a":"rocaucscore_xgb_duonew_tr = roc_auc_score(y_train, model_xgb_duonew.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_duonew_tr","a4dc6243":"submission42 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_duonew.predict_proba(X_testfull)[:, 1]})\nsubmission42.to_csv('submissionanar42.csv',index=False)","5da2ab45":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y, test_size = 0.15)","5c16ea50":"\ndef objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1200),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,10),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,10),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 10),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,10),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10), \n        \n        \n\n    }\n    \n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore)             ","62070ec1":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=1000)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","418f36fd":"model_xgb_lc = Pipeline(steps=[\n     ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 5,  n_estimators = 910,\\\n                                         learning_rate = 0.007958379961867717,\\\n                                         reg_alpha = 3.856579821957383, \\\n                                         reg_lambda = 2.0073301427382986,\\\n                                         gamma = 7.129213680598777,\\\n                                         min_child_weight = 5, \\\n                                         colsample_bytree = 0.585610607277932,\\\n                                         subsample = 0.6491860154349435, \\\n                                         scale_pos_weight = 3))  \n])","402a107d":"model_xgb_lc.fit(X1_train, y_train)","93e999f5":"rocaucscore_xgb_lc = roc_auc_score(y_test, model_xgb_lc.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_lc","2887abbc":"rocaucscore_xgb_lc_tr = roc_auc_score(y_train, model_xgb_lc.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_lc_tr","dc3f1a17":"submission43 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_lc.predict_proba(X_testfull)[:, 1]})\nsubmission43.to_csv('submissionanar43.csv',index=False)","f1ae8641":"model_xgb_lc2 = Pipeline(steps=[\n     ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 5,  n_estimators = 897,\\\n                                         learning_rate = 0.008934186255945237,\\\n                                         reg_alpha = 2.047927494823898, \\\n                                         reg_lambda = 7.524666945492921,\\\n                                         gamma = 5.344031490317096,\\\n                                         min_child_weight = 4, \\\n                                         colsample_bytree = 0.722412869229583,\\\n                                         subsample = 0.6442764223958304, \\\n                                         scale_pos_weight = 2))  \n])","c6430309":"model_xgb_lc2.fit(X1_train, y_train)","63874eae":"rocaucscore_xgb_lc2 = roc_auc_score(y_test, model_xgb_lc2.predict_proba(X1_test)[:, 1])\nrocaucscore_xgb_lc2","699ff704":"rocaucscore_xgb_lc2_tr = roc_auc_score(y_train, model_xgb_lc2.predict_proba(X1_train)[:, 1])\nrocaucscore_xgb_lc2_tr","dc0e0e1a":"submission44 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_lc2.predict_proba(X_testfull)[:, 1]})\nsubmission44.to_csv('submissionanar44.csv',index=False)","34137223":"quantile = df['ratio_debt_payment_to_income'].quantile(0.995)","49e88e7d":"dfqratio = df[df['ratio_debt_payment_to_income']<quantile]","e21b1d7b":"X1_qr = dfqratio[['age', 'number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income', 'credit_line_utilization',  \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]\ny_qr = dfqratio['defaulted_on_loan']","583110d9":"X1_qr_train, X1_qr_test, y_qr_train, y_qr_test = train_test_split(X1_qr,y_qr, test_size= 0.15)","c6b1b6ec":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_qr_train, y_qr_train)\n    rocaucscore = roc_auc_score(y_qr_test, model.predict_proba(X1_qr_test)[:, 1])\n\n    return (rocaucscore) ","d0d94610":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","8a33717a":"model_xgb_qu = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 4,  n_estimators = 828,\\\n                                         learning_rate = 0.020491833101880214,\\\n                                         reg_alpha =2.7687034971602347, \\\n                                         reg_lambda = 0.18012748333524534,\\\n                                         gamma = 0.246621491309686,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.6440242134725043,\\\n                                         subsample = 0.8666143452528458, \\\n                                         scale_pos_weight = 9))  \n])","8e1cba99":"model_xgb_qu.fit(X1_qr_train, y_qr_train)","ffae528a":"rocaucscorexgbqu_tr = roc_auc_score(y_qr_train, model_xgb_qu.predict_proba(X1_qr_train)[:, 1])\nrocaucscorexgbqu_tr","26eaea30":"submission45 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_qu.predict_proba(X_testfull)[:, 1]})\nsubmission45.to_csv('submissionanar45.csv',index=False)","0bddb8ba":"std = df['ratio_debt_payment_to_income'].std()\nmean = df['ratio_debt_payment_to_income'].mean()","36614edb":"lower, upper = mean-std*3, mean+std*3","d1ae2280":"trimmed_df = df[(df['ratio_debt_payment_to_income'] > lower) \\\n& (df['ratio_debt_payment_to_income'] < upper)]","ffb5b381":"trimmed_df.shape","f8e3f256":"X1_trd = trimmed_df[['age', 'number_dependent_family_members', 'monthly_income', 'number_of_credit_lines',\\\n        'real_estate_loans', 'ratio_debt_payment_to_income', 'credit_line_utilization',  \\\n        'number_of_previous_late_payments_up_to_59_days', 'number_of_previous_late_payments_up_to_89_days',\\\n        'number_of_previous_late_payments_90_days_or_more']]\ny_trd = trimmed_df['defaulted_on_loan']","3ba89f19":"X1_trd_train, X1_trd_test, y_trd_train, y_trd_test = train_test_split(X1_trd,y_trd)","5f3861d5":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_trd_train, y_trd_train)\n    rocaucscore = roc_auc_score(y_trd_test, model.predict_proba(X1_trd_test)[:, 1])\n\n    return (rocaucscore)","c7cb1417":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","e01ebc96":"#Outlier detection do not work with NaN values so I fill missing values with median\nX1_imp = X1.fillna(X1.mean())","0aa979f7":"# Converting dataframe to array\nX1_impval = X1_imp.values\ny_val = y.values","caa11218":"ee = EllipticEnvelope(contamination=0.01)\noutl_pred = ee.fit_predict(X1_impval)\n(outl_pred == -1).mean()","26e1a8c0":"mask = outl_pred != -1\nX1_val_out, y_val_out = X1_impval[mask, :], y_val[mask]","0548a10f":"X1_val_train, X1_val_test, y_val_train, y_val_test = train_test_split(X1_val_out, y_val_out, test_size = 0.15)","c6e285e7":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_val_train, y_val_train)\n    rocaucscore = roc_auc_score(y_val_test, model.predict_proba(X1_val_test)[:, 1])\n\n    return (rocaucscore) ","ffcf060e":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","f47f0bbb":"model_xgb_eel = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 5,  n_estimators = 756,\\\n                                         learning_rate = 0.009887282649687638,\\\n                                         reg_alpha =3.3476153538722686, \\\n                                         reg_lambda = 1.072046971799001,\\\n                                         gamma = 2.2019764549152407,\\\n                                         min_child_weight = 3, \\\n                                         colsample_bytree = 0.48251293667207357,\\\n                                         subsample = 0.5371108505218619, \\\n                                         scale_pos_weight = 3))  \n])","3d1ca54c":"model_xgb_eel.fit(X1_val_train, y_val_train)","3064ea49":"rocaucscorexgbeel = roc_auc_score(y_val_test, model_xgb_eel.predict_proba(X1_val_test)[:, 1])\nrocaucscorexgbeel","87719c91":"rocaucscorexgbeel_tr = roc_auc_score(y_val_train, model_xgb_eel.predict_proba(X1_val_train)[:, 1])\nrocaucscorexgbeel_tr","eba89d99":"submission46 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_eel.predict_proba(X_testfull)[:, 1]})\nsubmission46.to_csv('submissionanar46.csv',index=False)","4e661417":"X1_train, X1_test, y_train, y_test = train_test_split(X1, y, test_size = 0.15)","19ad4b89":"def objective(trial):\n    params = {\n\n        #'objective': 'binary:logistic',\n\n        'max_depth': trial.suggest_int('max_depth', 1, 9),\n\n        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n        \n        'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n        \n        'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n        \n         'gamma':trial.suggest_uniform('gamma', 0, 4),\n        \n        'min_child_weight':trial.suggest_int('min_child_weight',0,5),    \n        \n        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,10)\n        \n        #'max_delta_step':trial.suggest_int('max_delta_step',1,10),\n        \n        \n\n    }\n    model = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(**params))  \n])\n    model.fit(X1_train, y_train)\n    rocaucscore = roc_auc_score(y_test, model.predict_proba(X1_test)[:, 1])\n\n    return (rocaucscore) ","7506ed97":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","96fe1c71":"model_xgb_st1 = Pipeline(steps=[\n     ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 4,  n_estimators = 238,\\\n                                         learning_rate = 0.05881210002713285,\\\n                                         reg_alpha = 1.538597513959298, \\\n                                         reg_lambda = 1.8637680678882098,\\\n                                         gamma = 2.6094201329668545,\\\n                                         min_child_weight = 5, \\\n                                         colsample_bytree = 0.7226852763695746,\\\n                                         subsample = 0.5661613870804465, \\\n                                         scale_pos_weight = 4))  \n])","bf407b38":"model_xgb_st1.fit(X1_train, y_train)","01649f71":"rocaucscorexgst1 = roc_auc_score(y_test, model_xgb_st1.predict_proba(X1_test)[:, 1])\nrocaucscorexgst1","a1516ee5":"rocaucscorexgst1_tr = roc_auc_score(y_train, model_xgb_st1.predict_proba(X1_train)[:, 1])\nrocaucscorexgst1_tr","7f9a822c":"submission47 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_st1.predict_proba(X_testfull)[:, 1]})\nsubmission47.to_csv('submissionanar47.csv',index=False)","1519597f":"model_xgb_st2 = Pipeline(steps=[\n     ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 3,  n_estimators = 197,\\\n                                         learning_rate = 0.1315842043724514,\\\n                                         reg_alpha = 3.531086346058657, \\\n                                         reg_lambda = 1.8974173083008758,\\\n                                         gamma = 2.3542594492718645,\\\n                                         min_child_weight = 5, \\\n                                         colsample_bytree = 0.7627407508027603,\\\n                                         subsample = 0.5483814494883694, \\\n                                         scale_pos_weight = 5))  \n])","f933f9a7":"model_xgb_st2.fit(X1_train, y_train)","8fc06824":"rocaucscorexgst2 = roc_auc_score(y_test, model_xgb_st2.predict_proba(X1_test)[:, 1])\nrocaucscorexgst2","7a5ef189":"rocaucscorexgst2_tr = roc_auc_score(y_train, model_xgb_st2.predict_proba(X1_train)[:, 1])\nrocaucscorexgst2_tr","0bfb1345":"submission48 = pd.DataFrame({'Id':dftest['Id'],'Predicted':model_xgb_st2.predict_proba(X_testfull)[:, 1]})\nsubmission48.to_csv('submissionanar48.csv',index=False)","bcd096e8":"shap.initjs()","cd0cc99c":"X1_train, X1_test, y_train, y_test = train_test_split(X1,y, test_size = 0.15)","0a1aea8c":"modelxgbopt01510 = Pipeline(steps=[\n    ('scaler', RobustScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', xgb.XGBClassifier(max_depth = 8,  n_estimators = 375,\\\n                                         learning_rate = 0.014347834529320648,\\\n                                         reg_alpha = 3.499373975280538, \\\n                                         reg_lambda = 0.9984391921356766,\\\n                                         gamma = 1.658097856305046,\\\n                                         min_child_weight = 1, \\\n                                         colsample_bytree = 0.5639072449604189,\\\n                                         subsample = 0.6344904061063109, \\\n                                         scale_pos_weight = 1))  \n])","80f691fe":"modelxgbopt01510.fit(X1_train, y_train)","fea0dde0":"medians = X1_train.median().values.reshape((1, -1))\nexplainer = shap.KernelExplainer(lambda x: modelxgbopt01510.predict_proba(x)[:, 1], medians)","fd287b50":"medians = X1_train.median().values.reshape((1, -1))\nexplainer = shap.KernelExplainer(lambda x: modelxgbopt01510.predict_proba(x)[:, 1], medians)","52e71bd4":"shap_values_single = explainer.shap_values(X1_test.iloc[1,:], nsamples=1000)","26c64f27":"shap.force_plot(explainer.expected_value, shap_values_single, X1_test.iloc[1,:])","fd03b0b0":"shap_values_single = explainer.shap_values(X1_test.iloc[0,:], nsamples=1000)\nshap.force_plot(explainer.expected_value, shap_values_single, X1_test.iloc[0,:])","dfbb2ee3":"The following codes for conversion is added later for convenience. I did not include credit_line_utilization column at first. I added the column later, but it was difficult to find codes in the middle of notebook so I added them to the beginning of the notebook.","c9d46a21":"ROC_AUC for train data is 0.8633. I make another submission file.","77e17881":"ROC_AUC score with above gives the result of 0.8481. So I make a new submission file.                   \nPublic leaderboard score after submission is 0.85055.","78dcd5bf":"The ROC_AUC score above is 0.8235 , which is a slight improvement, so I can make my fourth submission     \nPublic score after submission is 0.82887.","c5b25a33":"## Local Outlier Factor","33327336":"ROC_AUC above is 0.85341","e06e0ddb":"## XGBoost Classifier with test_size=0.3 (GridSearch)","4178500b":"ROC_AUC score above is 0.8522. Public score is 0.85475.","72f8d23d":"The ROC_AUC score above is 0.7961 , which is a quite improvement, so I can make my first submission.    \nPublic score after submission is 0.8098.","e3ae9316":"I create model with best parameters suggested by Optuna","d9213a5c":"ROC_AUC score above is 0.85275","be42028c":"## Gradient Booosting Classifier (GridSearch)","c1408c38":"ROC_AUC score for training data is 0.8613","ce8b64c2":"ROC_AUC above is 0.8714","606cf2b3":"## Correcting credit_line_utilization column and applying models to full dataset","fedbc9d7":"I decide to try most_frequent imputation strategy","996dc55f":"ROC_AUC score with above parameters is 0.848751 - just slight improvement - I make submission10 file. Public score is 0.85057","1c9ca72a":"## Applying SelectFromModel XGBoost Classifier (default parameters)","fadca7e6":"Result is 0.8561 - so I make another submission file                                                      \nPublic submission score is 0.83932 - quite low","207b9418":"## Applying Outlier detection to whole dataset and then make train-test split","2181122e":"## SHAP values applied to model with highest public score","c869bd59":"## XGBoost with imputation strategy KNN Imputation (Optuna)","c8a8f20e":"The ROC_AUC score above is 0.8386, so I make new submission file.                                       \nPublic score after submission is 0.85050","bdc72143":"ROC_AUC score for train data above is 0.8624","11addd20":"ROC_AUC for test is 0.8520. Public submission result is 0.8542","9251de68":"ROC_AUC score is 0.85658                                                                                      \nPublic submission score is 0.85117","8ddccb4c":"ROC_AUC score above is 0.8528 Public score is 0.77427.","7d45ee2d":"## Applying ADASYN to XGBoost with Optuna","76681c06":"The ROC_AUC score above is 0.8223, which is less than LightGBM, so I do not make submission file.","07ccb159":"ROC_AUC score above is 0.8524. Public score is 0.85491.","05f88537":"## Starting without credit-line utilisation column.","335c2138":"## Gradient Boosting Classifier (GridSearch)","7076e6f5":"ROC_AUC score for training data is 0.8741 - so I will make another submission file.","c9cbee8e":"ROC_AUC score for train data is 0.8683.","65a89e61":"ROC_AUC score above is 0.85335 Public submission score is 0.85049","9fc0e379":"## Model explainability - Eli5 - permutation importance","06066cc6":"ROC_AUC above is 0.86386","5ae9651e":"The above ROC_AUC score was 0.8341","a941f6fb":"ROC_AUC above is 0.7069, so I will not make a submission file.","8009c5d6":"## Minimum Covariance Determinant","bb3dfe84":"## Displaying importance of features by removing features one-by-one with Select From Model","a60363d2":"ROC_AUC score above is 0.5784, which is very low, so I try further.","c7a67a61":"## Random Forest Classification (GridSearch)","c1858281":"ROC_AUC score above is 0.85184. Public score is 0.85386","77ef9a8d":"ROC_AUC score for train data is 0.8603. Although this is low, I decide to make a submission file","c3f0ae59":"The ROC_AUC score above is 0.8246 , which is a slight improvement, so I can make my fifth submission.     \nPublic score after submission is 0.8260, which is a bit lower than previous score.","a98f1129":"## Gaussian NB","c8264aad":"Just for sake of testing I decide to apply Optuna to whole dataset and see how it plays out.","03f6fc8f":"Public submission score is lower - 0.84649","5c867c68":"## Applying PCA to XGBoost model with Optuna","586cb52c":"## OneClassSVM ","1abc646d":"ROC_AUC score train is 0.8576. Although it is less than ROC_AUC train scores of previous submissions, I decide to make submission file just to see the impact on submission score.","e5c0d910":"## Applying SMOTE with Gradient Boost just to try","35812339":"ROC_AUC for train data is 0.8670","def2ccfa":"ROC_AUC score with above gives the result of 0.8471. Although it is not different from previous score, I make a new submission file, since it was the end of day. I do not expect an improvement of score.\nPublic score after submission is 0.85031","50fad830":"The result is 0.8415, which is closer to Minimal Covariance Determinant, but still less than 0.84875, so for now I will not make submission file on the basis of outlier removal","44c6db88":"## Adding colsample_by_tree feature to XGBoost","7ed01a38":"Public submission score is 0.85283","b0fb96b1":"Best ROC_AUC score is 0.8337 - so I do not make submission file.","63392f44":"ROC_AUC score above for train data is 0.8640.","e05b24ca":"## RandomForest Classifier and Optuna","2e5e1933":"The ROC_AUC score above is 0.8213 , which is a quite improvement, so I can make my third submission\nPublic score after submission is 0.82365.","0a431736":"Public submission score is lower - 0.84256","b05f5996":"## Standard deviation method - ratio debt to payment\n","6cbcf722":"ROC_AUC score above is 0.85193 Public score is 0.85332","aee0c51a":"ROC_AUC score above is 0.85989","a2ef2779":"ROC_AUC score above for train data is 0.8610","01b68dcc":"Above ROC_AUC score is 0.8391, which is less than 0.848751 (max result so far), so for now I will not make submission file.","807bc0d5":"The ROC_AUC score above is 0.6516, which is a slight improvement, but is still low. So I try another model.","4bab8c35":"ROC_AUC score above is 0.85223. Public submisssion result is 0.85465","b3b93ed8":"Public submission score is 0.84615","2e3d3dc7":"Resampling did not improve result, so I revert to regular train-test splits.","024b67bb":"ROC_AUC score for train set is 0.8736","c54b8885":"## Outlier removal with OneClassSVM and XGBoost with Optuna","850f64a7":"## Minimal Covariance Determinant with XGBoost Optuna","5f5f0746":"## Applying PCA to XGBoost with RandomizedSearch","2e146ae1":"Now, I got more realistic result of 0.8299. Score is low, so I will not make a submission.","9f348284":"ROC_AUC score above is 0.85321 Public Submission score is 0.85042","c079a3d4":"I take two high results and construct the models.","960fb6b8":"ROC_AUC score above is 0.85639","7ab377ce":"ROC_AUC score above is 0.8502 - so I make submission12 file. Public submission score is 0.8506","b20fb5f5":"Best result is 0.85658 I make another submisssion file","4d170f79":"ROC_AUC above for train data is 0.88365. There is much overfitting, nevertheless I make a submission file, since it is last day.","39de50cc":"## Trying several parameters of XGBoost with regular train test split","0d1c88f3":"ROC_AUC score above is 0.851969. Public score is 0.85419.","f113c585":"## AdaBoost Classifier (Randomized Search)","1747e3ff":"## Expanding Optuna XG Boost search ranges","8b5ead9c":"The following lines of codes are the same at the beginning of notebook. They were first written here, then copied to above.","2a3608cc":"Best result is 0.8410 - I will not make submission","44f3970d":"## Applying XGBoost Classifier to full dataset ","8c1e0ea7":"ROC_AUC score above is 0.6784, so I will not make a submission file.","d16b6fd5":"ROC_AUC score above is 0.8467, which is lower than LGBM and XGBoost results.","dcabb72f":"Removing no age increased showed result of 0.8499 - so I can make new submission                            \nPublic submission score is 0.8466","71d09b01":"Optuna trial of XGBoost gave result of 0.8512 - so I make another submission.                                                                                                                         Public Leaderboard score is 0.85060\n","334a3d2e":"## Logistic Regression","9655a8db":"ROC_AUC score above is 0.8537","26e0e7b9":"ROC_AUC score for above result is 0.8536. So, I make another submission file Public submission score is 0.84911.","9190bac5":"## XGBooster Optuna (test size 0.15, imputation strategy most_frequent)","74e34858":"## XGBoostClassifier with RandomizedSearch","fc7fc2e7":"## Conversion of credit_line_utilization column into float","5923d3b9":"The ROC_AUC score above is 0.823, which is less than in XG Boost, so I do not make submission.","aecf8c24":"## XGBoost with Optuna with test-size=0.15","5f49cac9":"ROC_AUC score with test size 0.3 above gives the result of 0.847 - so I make submission7 file.                \nPublic score after submission is 0.84873.","eee3fa9d":"## Applying Optuna with test_size = 0.3 for XGBoost ","dc8ee106":"Best result is 0.8381, so I do not make a submission file","b9126129":"ROC_AUC score above is 0.85197\nPublic submission result is 0.85478. I decide to see the result of training data to understand calculation of scores.","0501c997":"ROC_AUC score above for train data is 0.86397","6cbb94ae":"ROC_AUC train is 0.8648","c213d17d":"## XGBoost Classifier with Outlier detection and removal","1aaa0da7":"## Last attempts to improve score\nI changed Robust Scaler to Standard Scaler and run Optuna with XGBoost","952fb2a3":"## AdaBoostClassifier base estimator DecisionTree (GridSearch)","9077c38d":"## Isolation Forest","1832bbaa":"ROC_AUC score above for train data is 0.8670.","62b6149e":"## Optuna 1 XGBoost (finding optimal parameters with Optuna)","836136d2":"ROC_AUC above is 0.8551","c2bbcfc8":"ROC_AUC above is 0.8682","c171d5fb":"## Optuna XGBoost with Outlier removals","acc334e1":"My initial start was from here.","ac65bf71":"## Applying Optuna XGBoost to whole train set without splitting","672aee6f":"## Applying different scaling to data (XG Boost with Optuna)\n\n## Quantile Transformer, Power Transformer, Normalizer","8587c4fe":"## XGBoost Classifier with Robust Scaler (GridSearch)","d53f6170":"## XGBoost Classifier: Adding min_child_weight and reg_lambda and playing with hyperparameters","0bb392df":"Public submission score is 0.84645","1810fdb1":"ROC_AUC above is 0.8542 Public submission score is 0.85328","af7a21f6":"ROC_AUC train score is 0.9896. I make a submission file out of curiosity. I do not expect improvement of the score.","b1739cd5":"ROC_AUC score above for train data is 0.86523.","4f723ec3":"ROC_AUC score is 0.8509. Public score is 0.8531, which is quite an improvement.","41b6fc7c":"My strategy is to start from simpler models and find out which one gives the best result","2445563b":"ROC_AUC above is 0.8639","94e846da":"## CatBoost Classification (GridSearch)","f0b17e37":"First filling missing values with median and create train tests","72a30567":"ROC_AUC after submission is 0.8514","66705131":"## Manual removal of outliers\n## Applying Quantile to ratio-debt-payment column","86645148":"The above result is 0.8442, which is less than 0.84875, so I will not make new submission file.","56798043":"Result for features - according to index [0.03671711 0.03316094 0.0357593 0.03552493 0.040126 0.03849819 0.09809432 0.12488537 0.11564484 0.44158903]","b73d6bac":"ROC_AUC for train data above is 0.86419","73596a44":"## XGBoost train-test size with stratify=y with Optuna","01b4bca8":"Public submission score is 0.84824","03ba9daf":"The result of above code                                                                                    \nThresh=0.041, n=9, ROC_AUC score: 0.6166                                                                      \nThresh=0.042, n=8, ROC_AUC score: 0.6407                                                                     \nThresh=0.044, n=6, ROC_AUC score: 0.4500                                                                    \nThresh=0.045, n=5, ROC_AUC score: 0.5397                                                                  \nThresh=0.104, n=4, ROC_AUC score: 0.6580                                                                    \nThresh=0.125, n=3, ROC_AUC score: 0.4455                                                                   \nThresh=0.132, n=2, ROC_AUC score: 0.3996                                                               \nThresh=0.382, n=1, ROC_AUC score: 0.4955","245b7146":"Public submission result is 0.85292","4629045b":"This time I pick several models with results between 0.8519 and 0.8524 and make several submission files","f2cdd380":"ROC_AUC score above is 0.8570 Public submission score is 0.85295","59207b50":"Interestingly, results for train set are lower than for test set. I would like to see actual results, therefore I make a new submission file\n","a4af7923":"## Optuna 2 with XG Boost Classifier","17d3cf37":"ROC_AUC score above is 0.9759. I was misled by that and decided to make submission file\nPublic leaderboard score is 0.83932. Probable reason is that I applied SMOTE to whole sample.","dfd04e3d":"The result is 0.8418, which is better than IsoForest, but still less than 0.84875.","699e86f1":"Public submission score is 0.83678","5b270a7c":"ROC_AUC for train data is 0.8925. Here also there is much overfitting. Nevertheless, I make a submission file.","362a8fe3":"ROC_AUC result above is 0.8518 Public submission result is 0.8539","33abdfc4":"The ROC_AUC score above is 0.8238, which is sligthly less than GridSearch result, so I do not make submission file.","b68a2f73":"## Bagging Classifier with Decision Tree as base (GridSearch)","e631a3dc":"The best result is 0.8495 - I will make another submission file","e5aa34c9":"## IsolationForest with XGBoost (Optuna)","ed25497c":"The ROC_AUC score above is even lower than above scores, so I do not make submission file.","a34b03a3":"ROC_AUC score train is 0.8619 ","4214e7a7":"ROC_AUC for train data is 0.8683. I make another submission","d6ca0bb6":"The result is worse than Minimum Covariance Determinant","b6510dfb":"ROC_AUC score for train set is 0.8458","3cfd1a46":"\n\nROC_AUC for train data is 0.8711. I decide to make another submission file\n","ea2327d5":"ROC_AUC score above is 0.8557, I will check score for training data, too. Public submission score is 0.8516.","fca09823":"XGBoost showed better results, now I want to try it with RandomizedSearch, since GridSearch takes too much time.","b49877ef":"ROC_AUC score is 0.8495.                                                                                    \nPublic submission score is 0.85123.","4df40230":"## LightGBM Classifier (GridSearch)","aca21d2d":"## Light GBM Classifier (GridSearch)","9af292a4":"ROC_AUC score above for train data is 0.8668","62bd485a":"Public submission score is 0.85186","409c57a4":"ROC_AUC above is 0.85916","67f79a54":"## Optuna XGBoost (applying different strategies to dataset)","608bea2e":"## KNeighborsClassifier (GridSearch)","acc27c34":"ROC_AUC for train data is 0.8886. There is too much overfitting","58ed608d":"## Oversampling with SVMSMOTE XGBoost Optuna","efe9e3ed":"\n\nROC_AUC above is 0.8533\n","cadadb40":"ROC_AUC score is 0.9784, so I make a new submission file to see actual public submission score.","bcef108a":"ROC_AUC score above is 0.79. Poor result so I will not make submission file","1452a4ef":"## Removing age from dataset (both train and test and playing with figures XG Boost)","e9f6e68e":"ROC_AUC score above is 0.85195. Public score is 0.85417.","d4352e90":"The ROC_AUC score above is 0.8131 , which is a quite improvement, so I can make my second submission.   \nPublic score after submission is 0.81428","37fcb633":"## XGBoost with features divided into two parts (Optuna)","3df52827":"## XGBoost Classifier (GridSearch)","c105513c":"I create the model with best parameteres and make another submission","b27be3f9":"Outlier removals did not improve results, so I did not apply any of them"}}