{"cell_type":{"203746a2":"code","0ac85891":"code","7780c118":"code","ea427897":"code","d9272c77":"code","dc5f685e":"code","2ec8adc1":"code","f471803b":"code","2ababe26":"code","0cd634f2":"code","3ebe121f":"code","c9b6fef8":"code","77de0e2a":"code","d6d01c7c":"code","bf739584":"code","87d48ddf":"code","a8b23ac2":"code","a5135264":"code","e4809684":"code","9665c2d2":"code","7bbf22f8":"code","0ad4853e":"code","5beceb79":"code","3a057029":"code","48522bb1":"code","12914c93":"code","c8bb2ff9":"code","7a489862":"code","0528d4ae":"code","ab0d4b60":"code","d228fffe":"code","8ce09aae":"code","825d3d15":"code","428f9b57":"code","b0b42ba1":"code","0b38ebd1":"code","42554679":"code","166ee0b7":"code","e0f41ce0":"code","ff25721e":"code","bd26a725":"code","aaef8c62":"code","340a0929":"code","d677ff2e":"code","80160fda":"code","29bc16d0":"code","060c9abf":"code","40cd0c89":"code","5e861900":"code","c35918b7":"code","50249f04":"markdown","dcf1f64a":"markdown","d98c6a5e":"markdown","5dbab734":"markdown","f6fdddd1":"markdown","4ba0b694":"markdown","48c9e3d5":"markdown","43bfb884":"markdown","7097fb15":"markdown","5358fde3":"markdown","f85ae1b5":"markdown","46de2f0a":"markdown","d76e7d3f":"markdown","57c60575":"markdown","6be84490":"markdown","f10ac19b":"markdown","2ec193d5":"markdown","76afc92e":"markdown","59dac588":"markdown","f06f5363":"markdown","4a6d36e6":"markdown"},"source":{"203746a2":"#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nsns.set(style=\"ticks\")\nimport gc\nimport itertools\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.simplefilter(\"ignore\")\npd.set_option('display.max_columns', 100)\nnp.random.seed(42)\nimport plotly\nfrom datetime import datetime, timedelta\nimport plotly.offline as pyoff\nimport plotly.graph_objs as go\n#initiate visualization library for jupyter notebook \nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\npyoff.init_notebook_mode(connected=True)\n%matplotlib inline\n\n\n\n#defining visualizaition functions\ndef format_spines(ax, right_border=True):\n    \n    ax.spines['bottom'].set_color('#666666')\n    ax.spines['left'].set_color('#666666')\n    ax.spines['top'].set_visible(False)\n    if right_border:\n        ax.spines['right'].set_color('#FFFFFF')\n    else:\n        ax.spines['right'].set_color('#FFFFFF')\n    ax.patch.set_facecolor('#FFFFFF')\n    \n\ndef count_plot(feature, df, colors='Blues_d', hue=False, ax=None, title=''):\n    \n    # Preparing variables\n    ncount = len(df)\n    if hue != False:\n        ax = sns.countplot(x=feature, data=df, palette=colors, hue=hue, ax=ax)\n    else:\n        ax = sns.countplot(x=feature, data=df, palette=colors, ax=ax)\n        \n    format_spines(ax)\n\n    # Setting percentage\n    for p in ax.patches:\n        x=p.get_bbox().get_points()[:,0]\n        y=p.get_bbox().get_points()[1,1]\n        ax.annotate('{:.1f}%'.format(100.*y\/ncount), (x.mean(), y), \n                ha='center', va='bottom') # set the alignment of the text\n    \n    # Final configuration\n    if not hue:\n        ax.set_title(df[feature].describe().name + ' Analysis', size=13, pad=15)\n    else:\n        ax.set_title(df[feature].describe().name + ' Analysis by ' + hue, size=13, pad=15)  \n    if title != '':\n        ax.set_title(title)       \n    plt.tight_layout()\n    \n    \ndef bar_plot(x, y, df, colors='Blues_d', hue=False, ax=None, value=False, title=''):\n    \n    # Preparing variables\n    try:\n        ncount = sum(df[y])\n    except:\n        ncount = sum(df[x])\n    #fig, ax = plt.subplots()\n    if hue != False:\n        ax = sns.barplot(x=x, y=y, data=df, palette=colors, hue=hue, ax=ax, ci=None)\n    else:\n        ax = sns.barplot(x=x, y=y, data=df, palette=colors, ax=ax, ci=None)\n\n    # Setting borders\n    format_spines(ax)\n\n    # Setting percentage\n    for p in ax.patches:\n        xp=p.get_bbox().get_points()[:,0]\n        yp=p.get_bbox().get_points()[1,1]\n        if value:\n            ax.annotate('{:.2f}k'.format(yp\/1000), (xp.mean(), yp), \n                    ha='center', va='bottom') # set the alignment of the text\n        else:\n            ax.annotate('{:.1f}%'.format(100.*yp\/ncount), (xp.mean(), yp), \n                    ha='center', va='bottom') # set the alignment of the text\n    if not hue:\n        ax.set_title(df[x].describe().name + ' Analysis', size=12, pad=15)\n    else:\n        ax.set_title(df[x].describe().name + ' Analysis by ' + hue, size=12, pad=15)\n    if title != '':\n        ax.set_title(title)  \n    plt.tight_layout()","0ac85891":"# loading data \ncustomers_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv\")\norder_items_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv\")\norder_payments_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv\")\norders_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv\")","7780c118":"# displaying data shape\n#dataset = [customers, geolocation, order_items, order_payments, order_reviews, orders, products, sellers, category_name_translation]\ndataset = {\n    'Customers': customers_,\n    'Order Items': order_items_,\n    'Payments': order_payments_,\n    'Orders': orders_\n}\n\nfor x, y in dataset.items():\n    print(f'{x}', (list(y.shape)))","ea427897":"# displaying dataset column names\nfor x, y in dataset.items():\n    print(f'{x}', f'{list(y.columns)}\\n')","d9272c77":"# checking for null values in datasets\nfor x, y in dataset.items():\n    print(f'{x}: {y.isnull().any().any()}')","dc5f685e":"# taking count for dataset with missing values\nfor x, y in dataset.items():\n    if y.isnull().any().any():\n        print(f'{x}', (list(y.shape)),'\\n')\n        print(f'{y.isnull().sum()}\\n')","2ec8adc1":"# creating master dataframe \norder_payments_.head()\ndf1 = order_payments_.merge(order_items_, on='order_id')\ndf2 = df1.merge(orders_, on='order_id')\ndf = df2.merge(customers_, on='customer_id')\nprint(df.shape)","f471803b":"# converting date columns to datetime\ndate_columns = ['shipping_limit_date', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\nfor col in date_columns:\n    df[col] = pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')","2ababe26":"# cleaning up name columns\ndf['customer_city'] = df['customer_city'].str.title()\ndf['payment_type'] = df['payment_type'].str.replace('_', ' ').str.title()\n# engineering new\/essential columns\ndf['delivery_against_estimated'] = (df['order_estimated_delivery_date'] - df['order_delivered_customer_date']).dt.days\ndf['order_purchase_year'] = df.order_purchase_timestamp.apply(lambda x: x.year)\ndf['order_purchase_month'] = df.order_purchase_timestamp.apply(lambda x: x.month)\ndf['order_purchase_dayofweek'] = df.order_purchase_timestamp.apply(lambda x: x.dayofweek)\ndf['order_purchase_hour'] = df.order_purchase_timestamp.apply(lambda x: x.hour)\ndf['order_purchase_day'] = df['order_purchase_dayofweek'].map({0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'})\ndf['order_purchase_mon'] = df.order_purchase_timestamp.apply(lambda x: x.month).map({1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'Jun',7:'Jul',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'})\n# Changing the month attribute for correct ordenation\ndf['month_year'] = df['order_purchase_month'].astype(str).apply(lambda x: '0' + x if len(x) == 1 else x)\ndf['month_year'] = df['order_purchase_year'].astype(str) + '-' + df['month_year'].astype(str)\n#creating year month column\ndf['month_y'] = df['order_purchase_timestamp'].map(lambda date: 100*date.year + date.month)","0cd634f2":"# displaying summary staticstics of columns\ndf.describe(include='all')","3ebe121f":"# displaying missing value counts and corresponding percentage against total observations\nmissing_values = df.isnull().sum().sort_values(ascending = False)\npercentage = (df.isnull().sum()\/df.isnull().count()*100).sort_values(ascending = False)\npd.concat([missing_values, percentage], axis=1, keys=['Values', 'Percentage']).transpose()","c9b6fef8":"# dropping missing values\ndf.dropna(inplace=True)\ndf.isnull().values.any()","77de0e2a":"# displaying dataframe info\ndf.info()","d6d01c7c":"# excluding incomplete 2012 data and displaying first 3 rows of master dataframe\ndf = df.query(\"month_year != '2016-12' and month_year != '2016-10'\")\ndf.head(3)","bf739584":"#calculate Revenue for each row and create a new dataframe with YearMonth - Revenue columns\ndf_revenue = df.groupby(['month_year'])['payment_value'].sum().reset_index()\ndf_revenue","87d48ddf":"#calculating for monthly revenie growth rate\n# using pct_change() function to see monthly percentage change\ndf_revenue['MonthlyGrowth'] = df_revenue['payment_value'].pct_change()\n\ndf_revenue","a8b23ac2":"#creating monthly active customers dataframe by counting unique Customer IDs\ndf_monthly_active = df.groupby('month_year')['customer_unique_id'].nunique().reset_index()\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.set(palette='muted', color_codes=True, style='whitegrid')\nbar_plot(x='month_year', y='customer_unique_id', df=df_monthly_active, value=True)\nax.tick_params(axis='x', labelrotation=90)\nplt.show()","a5135264":"#creating monthly active customers dataframe by counting unique Customer IDs\ndf_monthly_sales = df.groupby('month_year')['order_status'].count().reset_index()\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.set(palette='muted', color_codes=True, style='whitegrid')\nbar_plot(x='month_year', y='order_status', df=df_monthly_sales, value=True)\nax.tick_params(axis='x', labelrotation=90)\nplt.show()","e4809684":"# create a new dataframe for average revenue by taking the mean of it\ndf_monthly_order_avg = df.groupby('month_year')['payment_value'].mean().reset_index()\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.set(palette='muted', color_codes=True, style='whitegrid')\nbar_plot(x='month_year', y='payment_value', df=df_monthly_order_avg, value=True)\nax.tick_params(axis='x', labelrotation=90)\nplt.show()","9665c2d2":"#create a dataframe contaning CustomerID and first purchase date\ndf_min_purchase = df.groupby('customer_unique_id').order_purchase_timestamp.min().reset_index()\ndf_min_purchase.columns = ['customer_unique_id','minpurchasedate']\ndf_min_purchase['minpurchasedate'] = df_min_purchase['minpurchasedate'].map(lambda date: 100*date.year + date.month)\n\n#merge first purchase date column to our main dataframe (tx_uk)\ndf = pd.merge(df, df_min_purchase, on='customer_unique_id')","7bbf22f8":"#create a column called User Type and assign Existing \n#if User's First Purchase Year Month before the selected Invoice Year Month\ndf['usertype'] = 'New'\ndf.loc[df['month_y']>df['minpurchasedate'],'usertype'] = 'Existing'\n\n#calculate the Revenue per month for each user type\ndf_user_type_revenue = df.groupby(['month_y','usertype', 'month_year'])['payment_value'].sum().reset_index()\n\ndf_user_type_revenue","0ad4853e":"fig, ax = plt.subplots(figsize=(15, 6))\nsns.set(palette='muted', color_codes=True)\nax = sns.lineplot(x='month_year', y='payment_value', data=df_user_type_revenue.query(\"usertype == 'New'\"), label='New')\nax = sns.lineplot(x='month_year', y='payment_value', data=df_user_type_revenue.query(\"usertype == 'Existing'\"), label='Existing')\nformat_spines(ax, right_border=False)\nax.set_title('Existing vs New Customer Comparison')\nax.tick_params(axis='x', labelrotation=90)\nplt.show()","5beceb79":"#create a dataframe that shows new user ratio - we also need to drop NA values (first month new user ratio is 0)\ndf_user_ratio = df.query(\"usertype == 'New'\").groupby(['month_year'])['customer_unique_id'].nunique()\/df.query(\"usertype == 'Existing'\").groupby(['month_year'])['customer_unique_id'].nunique() \ndf_user_ratio = df_user_ratio.reset_index()\n\n#dropping nan values that resulted from first and last month\ndf_user_ratio = df_user_ratio.dropna()\ndf_user_ratio.columns = ['month_year','NewCusRatio']\n\n#print the dafaframe\ndf_user_ratio","3a057029":"fig, ax = plt.subplots(figsize=(12, 6))\nsns.set(palette='muted', color_codes=True, style='whitegrid')\nbar_plot(x='month_year', y='NewCusRatio', df=df_user_ratio, value=True)\nax.tick_params(axis='x', labelrotation=90)\nplt.show()","48522bb1":"#Monthly Retention Rate = Retained Customers From Prev. Month\/Active Customers Total (using crosstab)\n\n#identifying active users are active by looking at their revenue per month\ndf_user_purchase = df.groupby(['customer_unique_id','month_y'])['payment_value'].sum().reset_index()\ndf_user_purchase.head()","12914c93":"#identifying active users are active by looking at their order count per month\ndf_user_purchase = df.groupby(['customer_unique_id','month_y'])['payment_value'].count().reset_index()\ndf_user_purchase.head()","c8bb2ff9":"#create retention matrix with crosstab using purchase\ndf_retention = pd.crosstab(df_user_purchase['customer_unique_id'], df_user_purchase['month_y']).reset_index()\ndf_retention.head()","7a489862":"#creating an array of dictionary which keeps Retained & Total User count for each month\nmonths = df_retention.columns[2:]\nretention_array = []\nfor i in range(len(months)-1):\n    retention_data = {}\n    selected_month = months[i+1]\n    prev_month = months[i]\n    retention_data['month_y'] = int(selected_month)\n    retention_data['TotalUserCount'] = df_retention[selected_month].sum()\n    retention_data['RetainedUserCount'] = df_retention[(df_retention[selected_month]>0) & (df_retention[prev_month]>0)][selected_month].sum()\n    retention_array.append(retention_data)\n    \n#convert the array to dataframe and calculate Retention Rate\ndf_retention = pd.DataFrame(retention_array)\ndf_retention['RetentionRate'] = df_retention['RetainedUserCount']\/df_retention['TotalUserCount']\n\ndf_retention","0528d4ae":"fig, ax = plt.subplots(figsize=(12, 6))\nsns.set(palette='muted', color_codes=True, style='whitegrid')\nbar_plot(x='month_y', y='RetentionRate', df=df_retention, value=True)\nax.tick_params(axis='x', labelrotation=90)\nplt.show()","ab0d4b60":"#create our retention table again with crosstab() - we need to change the column names for using them in .query() function\ndf_retention = pd.crosstab(df_user_purchase['customer_unique_id'], df_user_purchase['month_y']).reset_index()\nnew_column_names = [ 'm_' + str(column) for column in df_retention.columns]\ndf_retention.columns = new_column_names","d228fffe":"#create the array of Retained users for each cohort monthly\nretention_array = []\nfor i in range(len(months)):\n    retention_data = {}\n    selected_month = months[i]\n    prev_months = months[:i]\n    next_months = months[i+1:]\n    for prev_month in prev_months:\n        retention_data[prev_month] = np.nan\n        \n    total_user_count =  retention_data['TotalUserCount'] = df_retention['m_' + str(selected_month)].sum()\n    retention_data[selected_month] = 1 \n    \n    query = \"{} > 0\".format('m_' + str(selected_month))\n    \n\n    for next_month in next_months:\n        query = query + \" and {} > 0\".format(str('m_' + str(next_month)))\n        retention_data[next_month] = np.round(df_retention.query(query)['m_' + str(next_month)].sum()\/total_user_count,2)\n    retention_array.append(retention_data)","8ce09aae":"#create the array of Retained users for each cohort monthly\nretention_array = []\nfor i in range(len(months)):\n    retention_data = {}\n    selected_month = months[i]\n    prev_months = months[:i]\n    next_months = months[i+1:]\n    for prev_month in prev_months:\n        retention_data[prev_month] = np.nan\n        \n    total_user_count =  retention_data['TotalUserCount'] = df_retention['m_' + str(selected_month)].sum()\n    retention_data[selected_month] = 1 \n    \n    query = \"{} > 0\".format('m_' + str(selected_month))\n    \n\n    for next_month in next_months:\n        query = query + \" and {} > 0\".format(str('m_' + str(next_month)))\n        retention_data[next_month] = np.round(df_retention.query(query)['m_' + str(next_month)].sum()\/total_user_count,2)\n    retention_array.append(retention_data)\n    \ndf_retention = pd.DataFrame(retention_array)\ndf_retention.index = months\n\n#showing new cohort based retention table\ndf_retention","825d3d15":"#creates a generic user dataframe to keep CustomerID and new segmentation scores\ndf_user = pd.DataFrame(df['customer_unique_id'])\ndf_user.columns = ['customer_unique_id']\n\n#gets the max purchase date for each customer and create a dataframe with it\ndf_max_purchase = df.groupby('customer_unique_id').order_purchase_timestamp.max().reset_index()\ndf_max_purchase.columns = ['customer_unique_id', 'MaxPurchaseDate']\n\n#we take our observation point as the max purchase date in our dataset\ndf_max_purchase['Recency'] = (df_max_purchase['MaxPurchaseDate'].max() - df_max_purchase['MaxPurchaseDate']).dt.days\n\n#merge this dataframe to our new user dataframe\ndf_user = pd.merge(df_user, df_max_purchase[['customer_unique_id','Recency']], on='customer_unique_id')\n\ndf_user.head()","428f9b57":"# getting summary statistics of the recency table\ndf_user.Recency.describe()","b0b42ba1":"# plotting the distribution of the continous feature set\nsns.set(palette='muted', color_codes=True, style='white')\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.despine(left=True)\nsns.distplot(df_user['Recency'], bins=30)\nplt.show()","0b38ebd1":" from sklearn.cluster import KMeans\n\nsse={}\ndf_recency = df_user[['Recency']]\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(df_recency)\n    df_recency[\"clusters\"] = kmeans.labels_\n    sse[k] = kmeans.inertia_\n    \nplt.figure(figsize=(10, 5))\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.show()","42554679":"#building 5 clusters for recency and adding it to dataframe\nkmeans = KMeans(n_clusters=5)\nkmeans.fit(df_user[['Recency']])\ndf_user['RecencyCluster'] = kmeans.predict(df_user[['Recency']])\n\n#function for ordering cluster numbers\ndef order_cluster(cluster_field_name, target_field_name,df,ascending):\n    new_cluster_field_name = 'new_' + cluster_field_name\n    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n    df_new = df_new.sort_values(by=target_field_name,ascending=ascending).reset_index(drop=True)\n    df_new['index'] = df_new.index\n    df_final = pd.merge(df,df_new[[cluster_field_name,'index']], on=cluster_field_name)\n    df_final = df_final.drop([cluster_field_name],axis=1)\n    df_final = df_final.rename(columns={\"index\":cluster_field_name})\n    return df_final\n\ndf_user = order_cluster('RecencyCluster', 'Recency',df_user,False)","166ee0b7":"#displaying the details of each cluster\ndf_user.groupby('RecencyCluster')['Recency'].describe()","e0f41ce0":"#get order counts for each user and create a dataframe with it\ndf_frequency = df.groupby('customer_unique_id').order_purchase_timestamp.count().reset_index()\ndf_frequency.columns = ['customer_unique_id','Frequency']\n\n#add this data to our main dataframe\ndf_user = pd.merge(df_user, df_frequency, on='customer_unique_id')","ff25721e":"# getting summary statistics of the recency table\ndf_user.Frequency.describe()","bd26a725":"# plotting the distribution of the continous feature set\nsns.set(palette='muted', color_codes=True, style='whitegrid')\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.despine(left=True)\nsns.distplot(df_user['Frequency'], hist=False)\nplt.show()","aaef8c62":"#k-means\nkmeans = KMeans(n_clusters=5)\nkmeans.fit(df_user[['Frequency']])\ndf_user['FrequencyCluster'] = kmeans.predict(df_user[['Frequency']])\n\n#order the frequency cluster\ndf_user = order_cluster('FrequencyCluster', 'Frequency',df_user,True)\n\n#see details of each cluster\ndf_user.groupby('FrequencyCluster')['Frequency'].describe()","340a0929":"#calculate revenue for each customer\ndf_revenue = df.groupby('customer_unique_id').payment_value.sum().reset_index()\n\n#merge it with our main dataframe\ndf_user = pd.merge(df_user, df_revenue, on='customer_unique_id')","d677ff2e":"# plotting the distribution of the continous feature set\nsns.set(palette='muted', color_codes=True, style='white')\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.despine(left=True)\nsns.distplot(df_user['payment_value'], hist=False)\nplt.show()","80160fda":"sse={}\ndf_revenue = df_user[['payment_value']]\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(df_revenue)\n    df_revenue[\"clusters\"] = kmeans.labels_\n    sse[k] = kmeans.inertia_\n    \nplt.figure(figsize=(10, 5))\nplt.plot(list(sse.keys()), list(sse.values()))\nplt.xlabel(\"Number of cluster\")\nplt.show()","29bc16d0":"#apply clustering\nkmeans = KMeans(n_clusters=6)\nkmeans.fit(df_user[['payment_value']])\ndf_user['RevenueCluster'] = kmeans.predict(df_user[['payment_value']])\n\n\n#order the cluster numbers\ndf_user = order_cluster('RevenueCluster', 'payment_value',df_user,True)\n\n#show details of the dataframe\ndf_user.groupby('RevenueCluster')['payment_value'].describe()","060c9abf":"#renaming columns\ndf_user.columns = ['customer_unique_id', 'Recency', 'RecencyCluster', 'Frequency', 'FrequencyCluster', 'Monetary', 'RevenueCluster']\n#calculate overall score and use mean() to see details\ndf_user['OverallScore'] = df_user['RecencyCluster'] + df_user['FrequencyCluster'] + df_user['RevenueCluster']\ndf_user.groupby('OverallScore')['Recency','Frequency','Monetary'].mean()","40cd0c89":"df_user['Segment'] = 'Low-Value'\ndf_user.loc[df_user['OverallScore']>3,'Segment'] = 'Mid-Value' \ndf_user.loc[df_user['OverallScore']>6,'Segment'] = 'High-Value' ","5e861900":"df_user.head()","c35918b7":"# plotting the distribution of the continous feature set\nsns.set(palette='muted', color_codes=True, style='whitegrid')\nfig, axs = plt.subplots(1, 3, figsize=(22, 5))\nsns.despine(left=True)\nsns.scatterplot(x='Recency', y='Frequency', ax=axs[0], hue='Segment', data=df_user, size='Segment', sizes=(50,150), size_order=['High-Value','Mid-Value','Low-Value'])\nsns.scatterplot(x='Frequency', y='Monetary', ax=axs[1], hue='Segment', data=df_user, size='Segment' , sizes=(50,150), size_order=['High-Value','Mid-Value','Low-Value'])\nsns.scatterplot(x='Recency', y='Monetary', ax=axs[2], hue='Segment', data=df_user, size='Segment' , sizes=(50,150), size_order=['High-Value','Mid-Value','Low-Value'])\naxs[0].set_title('Customer Segments by Recency & Frequency')\naxs[1].set_title('Customer Segments by Frequency & Monetary')\naxs[2].set_title('Customer Segments by Recency & Monetary')\nplt.show()","50249f04":"Although relating to the same transactions, the individual datasets holds different properties of an order, i would require methods like join and concat on unique keys to create a master dataset for analysis purpose.","dcf1f64a":"# Frequency\n\nTo create frequency clusters, i will need to find total number orders for each customer, after which i cango ahead and place them in various clusters","d98c6a5e":"As the same notation as recency clusters, high frequency number indicates better customers.","5dbab734":"# Overall Score\n\nAfter creating various metric scores (cluster numbers) for recency, frequency & revenue. now i will proceed to create an overall score out of them:","f6fdddd1":"# Monthly Retention Rate","4ba0b694":"The above master dataframe constitutes of the various independent dataset provided joined together via unique keys. Date columns have also been converted to datetime and new essential columns engineered for analysis purpose. ","48c9e3d5":"# New Customer Ratio","43bfb884":"# Monthly Active Customers","7097fb15":"# Recency\n\nTo calculate recency, we need to find out most recent purchase date of each customer and see for how many days they are inactive. After having no. of inactive days for each customer, we will apply K-means* clustering to assign customers a recency score.","5358fde3":"From the above table the recency clusters have different characteristics. The customers in Cluster 4 are very recent compared to Cluster 3 and 2.\nHence cluster 4 covers the most active customers wheras cluster 0 covers the most inactive","f85ae1b5":"# New Customer Ratio","46de2f0a":"# Monthly Revenue","d76e7d3f":"# Monthly Order Count","57c60575":"# Cohort Based Retention Rate\n\nCohorts are determined as first purchase year-month of the customers. I will be measuring what percentage of the customers retained after their first purchase in each month. This view will help unveil how recent and old cohorts differ regarding retention rate and if recent changes in customer experience affected new customer\u2019s retention or not.","6be84490":"I will be applying K-means clustering to assign a recency score to each customer. But there is need to tell how many clusters i need to K-means algorithm. To find this out, I will apply Elbow Method. Elbow Method simply tells the optimal cluster number for optimal inertia.","f10ac19b":"Here it looks like 4 is the optimal number of clusters. Based on business requirements, I can go ahead with less or more clusters. In tis case i will be selecting 5.","2ec193d5":"# Customer Segmentation\n\nCustomers who shop on Olist have different needs and they have their own different profile. We should adapt our actions depending on that.\n\nRFM stands for Recency - Frequency - Monetary Value, I will be using this metrics to segment customers. Theoretically we will have segments like below:\nLow Value: Customers who are less active than others, not very frequent buyer\/visitor and generates very low - zero - maybe negative revenue.\nMid Value: In the middle of everything. Often using our platform (but not as much as our High Values), fairly frequent and generates moderate revenue.\nHigh Value: The group we don\u2019t want to lose. High Revenue, Frequency and low Inactivity.","76afc92e":"# Revenue\nLet\u2019s see how our customer base looks like when I cluster them based on revenue. I will calculate revenue for each customer, plot a histogram and apply the same clustering method.","59dac588":"# Monthly Revenue Growth Rate","f06f5363":"# Average Revenue per Customer Purchase","4a6d36e6":"The scoring above clearly shows us that customers with score 12 is our best customers whereas 0 is the worst.\nTo keep things simple, better we name these scores:\n0 to 4: Low Value\n5 to 7: Mid Value\n8+: High Value"}}