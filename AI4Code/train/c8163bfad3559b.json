{"cell_type":{"8aab71e6":"code","76557661":"code","6c7af7b9":"code","e858e49a":"code","889b90f1":"code","9359a5e4":"code","482107f9":"code","40174b99":"code","3c838e1c":"code","d13f5ddb":"code","ba265af2":"code","b54f54bc":"code","7731c98b":"code","e8e9643e":"code","3bddec6f":"code","91cc4c5e":"code","d8ddbf92":"code","9e8ba334":"code","4a3666b1":"code","4c5b44be":"code","418b2a20":"code","7e7b20b3":"code","54bda930":"code","97b49c40":"code","277bbc16":"code","a503cc46":"code","178a286c":"code","0f7ea369":"code","b0947f51":"code","2f599683":"code","e7f50e7e":"code","08a35981":"code","0d863260":"code","27a32bd8":"code","a120142a":"code","1e13495a":"code","ba27536c":"code","07095fec":"code","016504e4":"markdown","cc8b184a":"markdown","ee0e211a":"markdown","fae3519d":"markdown","765c57ea":"markdown","261fa071":"markdown","d4fd9482":"markdown","95c4654c":"markdown","647d3900":"markdown","2c72574e":"markdown","5a80779f":"markdown","68e5ff6e":"markdown","c26f87d8":"markdown","0a6e2581":"markdown","4b2f60ec":"markdown","5140b71a":"markdown"},"source":{"8aab71e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76557661":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing","6c7af7b9":"df = pd.read_csv(\"..\/input\/zomato-restaurants-data\/zomato.csv\", encoding = \"ISO-8859-1\")\ndf.head()","e858e49a":"df_num = df.drop([\"Cuisines\", \"Restaurant Name\", \"Address\", \"Locality\", \"Locality Verbose\", \"Rating color\", \"City\", \"Currency\",  \"Restaurant ID\"], axis = 1)#\"Latitude\", \"Longitude\",\ndf_num[\"Has Table booking\"] = df_num[\"Has Table booking\"].map({\"Yes\":1,\"No\":0})\ndf_num[\"Has Online delivery\"] = df_num[\"Has Online delivery\"].map({\"Yes\":1,\"No\":0})\ndf_num[\"Is delivering now\"] = df_num[\"Is delivering now\"].map({\"Yes\":1,\"No\":0})\ndf_num[\"Switch to order menu\"] = df_num[\"Switch to order menu\"].map({\"Yes\":1,\"No\":0})\ndf_num[\"Rating text\"] = df_num[\"Rating text\"].map({\"Excellent\":5, \"Very Good\":4 ,\"Good\":3, \"Average\":2, \"Poor\":1, \"Not rated\":0})\ndf_num.head()","889b90f1":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.distplot(df_num['Aggregate rating'] )\nplt.show()","9359a5e4":"df_num.drop(df_num[(df_num['Aggregate rating']==0)].index, inplace=True)\nsns.distplot(df_num['Aggregate rating'] )\nplt.show()","482107f9":"# \u0418\u043c\u043f\u043e\u0440\u0442 \u043d\u0443\u0436\u043d\u043e\u0439 \u0444\u0443\u043d\u043a\u0446\u0438\u0438\nfrom sklearn.model_selection import train_test_split\n\n# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 X, y\n# X --- \u0432\u0441\u044f \u0442\u0430\u0431\u043b\u0438\u0446\u0430 \u0431\u0435\u0437 \u0442\u0430\u0440\u0433\u0435\u0442\u0430\n# y --- \u0442\u0430\u0440\u0433\u0435\u0442 (\u0446\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f)\ny = df_num['Aggregate rating'] \nX = df_num.drop('Aggregate rating', axis=1) \n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n# X = scaler.fit_transform(X)\n# \u0420\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435\n# test_size --- \u0434\u043e\u043b\u044f \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445, \u043a\u043e\u0442\u043e\u0440\u0443\u044e \u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c \u0434\u043b\u044f \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n# random_state --- \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u043b\u044c\u043d\u043e\u0435 \u0446\u0435\u043b\u043e\u0435 \u0447\u0438\u0441\u043b\u043e, \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\nscaler.fit(X_train)\n# X_train = scaler.transform(X_train)\n# X_valid = scaler.transform(X_valid)","40174b99":"from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)\ny_pred = lin_reg.predict(X_valid)","3c838e1c":"# \u0412\u044b\u0447\u0438\u0441\u043b\u0438\u043c \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error, r2_score\nprint('MSE:', mean_squared_error(y_valid, y_pred))\nprint('MAE:', mean_absolute_error(y_valid, y_pred))\nprint('MedAE:', median_absolute_error(y_valid, y_pred))\nprint('R2:', r2_score(y_valid, y_pred))","d13f5ddb":"# \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043e\u0442\u043a\u043b\u043e\u043d\u0435\u043d\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u043e\u0432 \u043d\u0430\u0448\u0435\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043e\u0442 \u0438\u0441\u0442\u0438\u043d\u043d\u044b\u0445\ng = sns.pointplot(x=y_valid.index[:20], y=y_valid[:20], color='blue', label='True')\ng = sns.pointplot(x=y_valid.index[:20], y=y_pred[:20], color='green', label='Prediction')\ng.set_xticklabels(np.arange(20))\nplt.legend()\nplt.show()","ba265af2":"# Ridge\nfrom sklearn.linear_model import Ridge\nridge = Ridge() # \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e alpha=1\nridge.fit(X_train, y_train)\ny_pred = ridge.predict(X_valid)\n\nprint('MSE:', mean_squared_error(y_valid, y_pred))\nprint('MAE:', mean_absolute_error(y_valid, y_pred))\nprint('MedAE:', median_absolute_error(y_valid, y_pred))\nprint('R2:', r2_score(y_valid, y_pred))","b54f54bc":"# \u043f\u043e\u0434\u0431\u043e\u0440 alpha\nfrom sklearn.model_selection import GridSearchCV\n\nalpha_grid = {'alpha': np.logspace(-1, 1, 20)} # 20 \u0442\u043e\u0447\u0435\u043a \u043e\u0442 10^(-4) \u0434\u043e 10^4\nridge_grid = GridSearchCV(ridge, alpha_grid, cv=5, scoring='r2', n_jobs=-1) \nridge_grid.fit(X_train, y_train)","7731c98b":"b_alpha = ridge_grid.best_params_['alpha']\nprint('Best alpha:', b_alpha)\nprint('\\nBest score:', ridge_grid.best_score_)","e8e9643e":"ridge_best = ridge_grid.best_estimator_\ny_pred = ridge_best.predict(X_valid)\nprint('R2:', r2_score(y_valid, y_pred))\nprint('MSE:', mean_squared_error(y_valid, y_pred))\nprint('MAE:', mean_absolute_error(y_valid, y_pred))\nprint('MedAE:', median_absolute_error(y_valid, y_pred))\nprint('R2:', r2_score(y_valid, y_pred))","3bddec6f":"# \u0412\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0430\u044f \u043a\u0440\u0438\u0432\u0430\u044f\n# \u041f\u043e \u043e\u0441\u0438 \u0445 --- \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 (param_alpha)\n# \u041f\u043e \u043e\u0441\u0438 y --- \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0438 (mean_test_score)\n\nimport matplotlib.pyplot as plt\nresults_df = pd.DataFrame(ridge_grid.cv_results_)\nplt.plot(results_df['param_alpha'], results_df['mean_test_score'])\n\n# \u041f\u043e\u0434\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u043e\u0441\u0438 \u0438 \u0433\u0440\u0430\u0444\u0438\u043a\nplt.xlabel('alpha')\nplt.ylabel('Test accuracy')\nplt.title('Validation curve')\nplt.show()","91cc4c5e":"# Lasso\nfrom sklearn.linear_model import Lasso\nlasso = Lasso() # \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e alpha=1\nlasso.fit(X_train, y_train)\ny_pred = lasso.predict(X_valid)\n\nprint('MSE:', mean_squared_error(y_valid, y_pred))\nprint('MAE:', mean_absolute_error(y_valid, y_pred))\nprint('MedAE:', median_absolute_error(y_valid, y_pred))\nprint('R2:', r2_score(y_valid, y_pred))","d8ddbf92":"eps = 1e-6\nlasso_coef = lasso.coef_\nprint('\u041d\u0443\u043b\u0435\u0432\u044b\u0445 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u043e\u0432:', sum(np.abs(lasso_coef) < eps))\nprint('\u0412\u0441\u0435\u0433\u043e \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u043e\u0432:', lasso_coef.shape[0])","9e8ba334":"# Lasso \u0441 \u043f\u043e\u0434\u0431\u043e\u0440\u043e\u043c alpha\nalpha_grid = {'alpha': np.logspace(-3, 3, 10)} # 10 \u0442\u043e\u0447\u0435\u043a \u043e\u0442 10^(-3) \u0434\u043e 10^3\nlasso_grid = GridSearchCV(lasso, alpha_grid, cv=5, scoring='r2', n_jobs=-1) \nlasso_grid.fit(X_train, y_train)","4a3666b1":"print('Best alpha:', lasso_grid.best_params_)\nprint('\\nBest score:', lasso_grid.best_score_)\n#\u041c\u0430\u043b\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 alpha \u0433\u043e\u0432\u043e\u0440\u0438\u0442 \u043e \u0442\u043e\u043c, \u0447\u0442\u043e \u043c\u044b \u0441\u043e\u0432\u0441\u0435\u043c \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0441\u043a\u043e\u0440\u0440\u0435\u043a\u0442\u0438\u0440\u043e\u0432\u0430\u043b\u0438 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c. \u041e\u0434\u043d\u0430\u043a\u043e \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 R2.","4c5b44be":"lasso_best = lasso_grid.best_estimator_\ny_pred = lasso_best.predict(X_valid)\nprint('MSE:', mean_squared_error(y_valid, y_pred))\nprint('MAE:', mean_absolute_error(y_valid, y_pred))\nprint('MedAE:', median_absolute_error(y_valid, y_pred))\nprint('R2:', r2_score(y_valid, y_pred))","418b2a20":"# \u0412\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u0430\u044f \u043a\u0440\u0438\u0432\u0430\u044f\n# \u041f\u043e \u043e\u0441\u0438 \u0445 --- \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 (param_alpha)\n# \u041f\u043e \u043e\u0441\u0438 y --- \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0438 (mean_test_score)\n\nresults_df = pd.DataFrame(lasso_grid.cv_results_)\nplt.plot(results_df['param_alpha'], results_df['mean_test_score'])\n\n# \u041f\u043e\u0434\u043f\u0438\u0441\u044b\u0432\u0430\u0435\u043c \u043e\u0441\u0438 \u0438 \u0433\u0440\u0430\u0444\u0438\u043a\nplt.xlabel('alpha')\nplt.ylabel('Test accuracy')\nplt.title('Validation curve')\nplt.show()","7e7b20b3":"eps = 1e-6\nlasso_coef = lasso_best.coef_\nprint('\u041d\u0443\u043b\u0435\u0432\u044b\u0445 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u043e\u0432:', sum(np.abs(lasso_coef) < eps))\nprint('\u0412\u0441\u0435\u0433\u043e \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u043e\u0432:', lasso_coef.shape[0])","54bda930":"# ElasticNet\nfrom sklearn.linear_model import ElasticNet\nelastic_net = ElasticNet() # alpha=1 l1_ratio=0.5\nelastic_net.fit(X_train, y_train)\ny_pred = elastic_net.predict(X_valid)\n\nprint('MSE:', mean_squared_error(y_valid, y_pred))\nprint('MAE:', mean_absolute_error(y_valid, y_pred))\nprint('MedAE:', median_absolute_error(y_valid, y_pred))\nprint('R2:', r2_score(y_valid, y_pred))","97b49c40":"grid = {'alpha': np.logspace(-2, 2, 20), \"l1_ratio\": np.linspace(0, 1, 100)} \nnet_grid = GridSearchCV(elastic_net, grid, cv=5, scoring='r2', n_jobs=-1) \nnet_grid.fit(X_train, y_train);","277bbc16":"elastic_net_best = net_grid.best_estimator_\ny_pred = elastic_net_best.predict(X_valid)\nprint('Best alpha:', net_grid.best_params_)\nprint('\\nBest score:', net_grid.best_score_)","a503cc46":"# \u041f\u043e \u043e\u0441\u0438 \u0445 --- \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \n# \u041f\u043e \u043e\u0441\u0438 y --- \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u043c\u0435\u0442\u0440\u0438\u043a\u0438 \n\nresults_df = pd.DataFrame(net_grid.cv_results_)\nfig, ax = plt.subplots(ncols=2, sharey=True)\nax[0].plot(grid['alpha'], results_df.groupby('param_alpha')['mean_test_score'].max())\nax[1].plot(grid['l1_ratio'], results_df.groupby('param_l1_ratio')['mean_test_score'].max())\nplt.show()","178a286c":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, precision_score, recall_score, f1_score\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.over_sampling import RandomOverSampler\nimport matplotlib.pyplot as plt\n\nnp.random.seed(1)","0f7ea369":"mlp = MLPRegressor()\nmlp.fit(X_train, y_train)\ny_pred = mlp.predict(X_valid)","b0947f51":"print('MSE:', mean_squared_error(y_valid, y_pred))\nprint('MAE:', mean_absolute_error(y_valid, y_pred))\nprint('MedAE:', median_absolute_error(y_valid, y_pred))\nprint('R2:', r2_score(y_valid, y_pred))","2f599683":"mlp2 = MLPRegressor(hidden_layer_sizes=(200,), solver=\"adam\", max_iter=400, alpha=0.1)\nmlp2.fit(X_train, y_train)\ny_pred = mlp2.predict(X_valid)\nprint('R2:', r2_score(y_valid, y_pred))","e7f50e7e":"mlp2.n_iter_","08a35981":"mlp4 = MLPRegressor(solver='adam', hidden_layer_sizes=(100,50), max_iter=400, alpha=0.0004)\nmlp4.fit(X_train, y_train)\ny_pred = mlp4.predict(X_valid)","0d863260":"print('MSE:', mean_squared_error(y_valid, y_pred))\nprint('MAE:', mean_absolute_error(y_valid, y_pred))\nprint('MedAE:', median_absolute_error(y_valid, y_pred))\nprint('R2:', r2_score(y_valid, y_pred))","27a32bd8":"mlp4.n_iter_","a120142a":"np.logspace(-2, 2, 10)","1e13495a":"mlp = MLPRegressor(max_iter=100, solver='adam')\nhidden = hidden = [(100,), (100, 50), (100, 50, 20), (50, 50), (50, 50, 50), (50, 30, 30, 20)]\nparam_grid  = {'hidden_layer_sizes': hidden, \"alpha\": np.logspace(-2, 2, 10)}\nmlp_grid = GridSearchCV(mlp, param_grid , cv=5, scoring='r2', n_jobs=-1) \nmlp_grid.fit(X_train, y_train)","ba27536c":"mlp_best = mlp_grid.best_estimator_\ny_pred = mlp_best.predict(X_valid)\n\nprint(\"Best params:\", mlp_best)\nprint('R2:', r2_score(y_valid, y_pred))\n","07095fec":"results_df = pd.DataFrame(mlp_grid.cv_results_)\nfig, ax = plt.subplots(ncols=2, sharey=True)\nax[0].plot(param_grid['alpha'], results_df.groupby('param_alpha')['mean_test_score'].max())\nhid = (str(hidden)).split(sep=\") (\")\nax[1].plot(str((np.array(hidden))).split(sep=\") (\"), results_df.groupby('param_hidden_layer_sizes')['mean_test_score'].max())\nplt.show()","016504e4":"\u0417\u043d\u0430\u0447\u0435\u043d\u0438\u044f R-\u043a\u0432\u0430\u0434\u0440\u0430\u0442 \u0432\u0430\u0440\u044c\u0438\u0440\u0443\u044e\u0442\u0441\u044f \u043e\u0442 0 \u0434\u043e 1 \u0438 \u043e\u0431\u044b\u0447\u043d\u043e \u0432\u044b\u0440\u0430\u0436\u0430\u044e\u0442\u0441\u044f \u0432 \u043f\u0440\u043e\u0446\u0435\u043d\u0442\u0430\u0445. \u042d\u0442\u043e \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u043c\u0435\u0440\u0430, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u0441\u043e\u0431\u043e\u0439 \u0434\u043e\u043b\u044e \u0434\u0438\u0441\u043f\u0435\u0440\u0441\u0438\u0438 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043e\u0431\u044a\u044f\u0441\u043d\u044f\u0435\u0442\u0441\u044f \u043d\u0435\u0437\u0430\u0432\u0438\u0441\u0438\u043c\u044b\u043c\u0438 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u043c\u0438. ","cc8b184a":"[www.datacamp.com\/community\/tutorials\/tutorial-ridge-lasso-elastic-net](http:\/\/)\n\n\n[scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.ElasticNet.html](http:\/\/)","ee0e211a":"# Neural nets","fae3519d":"# Linear regression","765c57ea":"**ElasticNet** \u0441\u043e\u0447\u0435\u0442\u0430\u0435\u0442 \u0432 \u0441\u0435\u0431\u0435 \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 Ridge \u0438 Lasso. \u041e\u043d \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442, \u043d\u0430\u043a\u0430\u0437\u044b\u0432\u0430\u044f \u043c\u043e\u0434\u0435\u043b\u044c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u043a\u0430\u043a l2-\u043d\u043e\u0440\u043c\u044b, \u0442\u0430\u043a \u0438 l1-\u043d\u043e\u0440\u043c\u044b.","261fa071":"**Lasso regression**\n\u0442\u0430\u043a\u0436\u0435 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043c\u043e\u0434\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0435\u0439 \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438. \u0412 \u041b\u0430\u0441\u0441\u043e \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c \u043c\u043e\u0434\u0438\u0444\u0438\u0446\u0438\u0440\u0443\u0435\u0442\u0441\u044f, \u0447\u0442\u043e\u0431\u044b \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438, \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0438\u0432\u0430\u044f \u0441\u0443\u043c\u043c\u0443 \u0430\u0431\u0441\u043e\u043b\u044e\u0442\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u043e\u0432 \u043c\u043e\u0434\u0435\u043b\u0438 (\u0442\u0430\u043a\u0436\u0435 \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u043c\u0443\u044e l1-\u043d\u043e\u0440\u043c\u043e\u0439).\n\n\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c \u0434\u043b\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u043b\u0430\u0441\u0441\u043e \u043c\u043e\u0436\u0435\u0442 \u0431\u044b\u0442\u044c \u0432\u044b\u0440\u0430\u0436\u0435\u043d\u0430 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c:\n\nLoss function = OLS + alpha * summation (absolute values of the magnitude of the coefficients)\n\n\u0412 \u043f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u043d\u043e\u0439 \u0432\u044b\u0448\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u043f\u043e\u0442\u0435\u0440\u044c \u0430\u043b\u044c\u0444\u0430 - \u044d\u0442\u043e \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u0448\u0442\u0440\u0430\u0444\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \u0432\u044b\u0431\u0440\u0430\u0442\u044c. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u043e\u0433\u0440\u0430\u043d\u0438\u0447\u0435\u043d\u0438\u044f \u043d\u043e\u0440\u043c\u044b l1 \u0437\u0430\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0432\u0435\u0441\u0430 \u043e\u0431\u043d\u0443\u043b\u044f\u0442\u044c\u0441\u044f, \u0447\u0442\u043e\u0431\u044b \u0434\u0440\u0443\u0433\u0438\u0435 \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u044b \u043c\u043e\u0433\u043b\u0438 \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0442\u044c \u043d\u0435\u043d\u0443\u043b\u0435\u0432\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f.","d4fd9482":"*\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043c\u043e\u0434\u0435\u043b\u0438 a \u0438 b \u0432\u044b\u0431\u0438\u0440\u0430\u044e\u0442\u0441\u044f \u043c\u0435\u0442\u043e\u0434\u043e\u043c \u043d\u0430\u0438\u043c\u0435\u043d\u044c\u0448\u0438\u0445 \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u043e\u0432 (OLS). \u041e\u043d \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043f\u0443\u0442\u0435\u043c \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438 \u0441\u0443\u043c\u043c\u044b \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u043e\u0432 \u043e\u0441\u0442\u0430\u0442\u043a\u043e\u0432 (\u0444\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 - \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u0443\u0435\u043c\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435).*","95c4654c":"Multi-layer Perceptron regressor.\n\u042d\u0442\u0430 \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u0443\u0435\u0442 \u043a\u0432\u0430\u0434\u0440\u0430\u0442 \u043e\u0448\u0438\u0431\u043a\u0438 \u0441 \u043f\u043e\u043c\u043e\u0449\u044c\u044e LBFGS \u0438\u043b\u0438 \u0441\u0442\u043e\u0445\u0430\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u0433\u043e \u0441\u043f\u0443\u0441\u043a\u0430.\n\nsolver {'lbfgs', 'sgd', 'adam'}, \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e = 'adam'\n\u0420\u0435\u0448\u0430\u0442\u0435\u043b\u044c \u0434\u043b\u044f \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0446\u0438\u0438 \u0432\u0435\u0441\u0430.\n* lbfgs - \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440 \u0438\u0437 \u0441\u0435\u043c\u0435\u0439\u0441\u0442\u0432\u0430 \u043a\u0432\u0430\u0437\u0438\u043d\u044c\u044e\u0442\u043e\u043d\u043e\u0432\u0441\u043a\u0438\u0445 \u043c\u0435\u0442\u043e\u0434\u043e\u0432.\n* \u00absgd\u00bb \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0441\u044f \u043a \u0441\u0442\u043e\u0445\u0430\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u043c\u0443 \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u043d\u043e\u043c\u0443 \u0441\u043f\u0443\u0441\u043a\u0443.\n* \u00abadam\u00bb \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0441\u044f \u043a \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u0443 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0441\u0442\u043e\u0445\u0430\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0433\u043e \u0433\u0440\u0430\u0434\u0438\u0435\u043d\u0442\u0430, \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u043d\u043e\u043c\u0443 \u041a\u0438\u043d\u0433\u043c\u043e\u0439, \u0414\u0438\u0434\u0435\u0440\u0438\u043a\u043e\u043c \u0438 \u0414\u0436\u0438\u043c\u043c\u0438 \u0411\u0430.\n\n\u041f\u0440\u0438\u043c\u0435\u0447\u0430\u043d\u0438\u0435. \u0420\u0435\u0448\u0430\u0442\u0435\u043b\u044c \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e adam \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u0445\u043e\u0440\u043e\u0448\u043e \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0441 \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0431\u043e\u043b\u044c\u0448\u0438\u043c\u0438 \u043d\u0430\u0431\u043e\u0440\u0430\u043c\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 (\u0441 \u0442\u044b\u0441\u044f\u0447\u0430\u043c\u0438 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0445 \u0432\u044b\u0431\u043e\u0440\u043e\u043a \u0438 \u0431\u043e\u043b\u0435\u0435) \u0441 \u0442\u043e\u0447\u043a\u0438 \u0437\u0440\u0435\u043d\u0438\u044f \u043a\u0430\u043a \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f, \u0442\u0430\u043a \u0438 \u043e\u0446\u0435\u043d\u043a\u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438. \u041e\u0434\u043d\u0430\u043a\u043e \u0434\u043b\u044f \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0438\u0445 \u043d\u0430\u0431\u043e\u0440\u043e\u0432 \u0434\u0430\u043d\u043d\u044b\u0445 lbfgs \u043c\u043e\u0436\u0435\u0442 \u0441\u0445\u043e\u0434\u0438\u0442\u044c\u0441\u044f \u0431\u044b\u0441\u0442\u0440\u0435\u0435 \u0438 \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u043b\u0443\u0447\u0448\u0435.","647d3900":"[scikit-learn.org\/stable\/modules\/generated\/sklearn.neural_network.MLPRegressor.html](http:\/\/)","2c72574e":"hidden_layer_sizes tuple, length = n_layers - 2, default=(100,)\nI-\u0439 \u044d\u043b\u0435\u043c\u0435\u043d\u0442 \u043f\u0440\u0435\u0434\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043d\u0435\u0439\u0440\u043e\u043d\u043e\u0432 \u0432 i-\u043c \u0441\u043a\u0440\u044b\u0442\u043e\u043c \u0441\u043b\u043e\u0435.","5a80779f":"*\u041f\u0440\u043e\u0441\u0442\u0435\u0439\u0448\u0435\u0439 \u0444\u043e\u0440\u043c\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u0440\u0435\u0434\u043f\u043e\u043b\u0430\u0433\u0430\u0435\u0442, \u0447\u0442\u043e \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u043e\u0440\u044b \u0438\u043c\u0435\u044e\u0442 \u043b\u0438\u043d\u0435\u0439\u043d\u0443\u044e \u0441\u0432\u044f\u0437\u044c \u0441 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439. \u041f\u0440\u0435\u0434\u043f\u043e\u043b\u0430\u0433\u0430\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u0432\u0445\u043e\u0434\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u0438\u043c\u0435\u044e\u0442 \u0433\u0430\u0443\u0441\u0441\u043e\u0432\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435. \u0414\u0440\u0443\u0433\u043e\u0435 \u043f\u0440\u0435\u0434\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u0438\u0435 \u0441\u043e\u0441\u0442\u043e\u0438\u0442 \u0432 \u0442\u043e\u043c, \u0447\u0442\u043e \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u043e\u0440\u044b \u043d\u0435 \u0441\u0438\u043b\u044c\u043d\u043e \u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u044b \u0434\u0440\u0443\u0433 \u0441 \u0434\u0440\u0443\u0433\u043e\u043c (\u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430, \u043d\u0430\u0437\u044b\u0432\u0430\u0435\u043c\u0430\u044f \u043c\u0443\u043b\u044c\u0442\u0438\u043a\u043e\u043b\u043b\u0438\u043d\u0435\u0430\u0440\u043d\u043e\u0441\u0442\u044c\u044e).*\n\n\u0423\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u0435 \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438 \u043c\u043e\u0436\u043d\u043e \u0432\u044b\u0440\u0430\u0437\u0438\u0442\u044c \u0432 \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0439 \u0444\u043e\u0440\u043c\u0435:\n\ny =  a1x1 + a2x2 + a3x3 + ..... + anxn + b\n\n\u0415\u0441\u043b\u0438 \u0432\u0435\u0440\u043d\u043e \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0435:\n\n*y - \u0446\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f.*\n\n*x1, x2, x3, ... xn - \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0438\u0441\u0442\u0438\u043a\u0438.*\n\n*a1, a2, a3, ..., an - \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u044b.*\n\n*b - \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440 \u043c\u043e\u0434\u0435\u043b\u0438.*","68e5ff6e":"\u041e\u0431\u0443\u0447\u0438\u043c \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438.","c26f87d8":"**Ridge regression** - \u044d\u0442\u043e \u0440\u0430\u0441\u0448\u0438\u0440\u0435\u043d\u0438\u0435 \u043b\u0438\u043d\u0435\u0439\u043d\u043e\u0439 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u0438, \u0433\u0434\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u043f\u043e\u0442\u0435\u0440\u044c \u043c\u043e\u0434\u0438\u0444\u0438\u0446\u0438\u0440\u0443\u0435\u0442\u0441\u044f, \u0447\u0442\u043e\u0431\u044b \u043c\u0438\u043d\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0441\u043b\u043e\u0436\u043d\u043e\u0441\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u0438. \u042d\u0442\u0430 \u043c\u043e\u0434\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u0442\u0441\u044f \u043f\u0443\u0442\u0435\u043c \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 \u0448\u0442\u0440\u0430\u0444\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u044d\u043a\u0432\u0438\u0432\u0430\u043b\u0435\u043d\u0442\u0435\u043d \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u0443 \u0432\u0435\u043b\u0438\u0447\u0438\u043d\u044b \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442\u043e\u0432.\n\nLoss function = OLS + alpha * summation (squared coefficient values)\n\n**alpha** , \u043f\u043e \u0443\u043c\u043e\u043b\u0447\u0430\u043d\u0438\u044e = 1.0\n\u0421\u0438\u043b\u0430 \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u0438; \u0434\u043e\u043b\u0436\u043d\u043e \u0431\u044b\u0442\u044c \u043f\u043e\u043b\u043e\u0436\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u043c \u0447\u0438\u0441\u043b\u043e\u043c \u0441 \u043f\u043b\u0430\u0432\u0430\u044e\u0449\u0435\u0439 \u0437\u0430\u043f\u044f\u0442\u043e\u0439. \u0420\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u0443\u043b\u0443\u0447\u0448\u0430\u0435\u0442 \u043e\u0431\u0443\u0441\u043b\u043e\u0432\u043b\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u044b \u0438 \u0441\u043d\u0438\u0436\u0430\u0435\u0442 \u0440\u0430\u0437\u0431\u0440\u043e\u0441 \u043e\u0446\u0435\u043d\u043e\u043a. \u0411\u043e\u043b\u044c\u0448\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0442 \u043d\u0430 \u0431\u043e\u043b\u0435\u0435 \u0441\u0438\u043b\u044c\u043d\u0443\u044e \u0440\u0435\u0433\u0443\u043b\u044f\u0440\u0438\u0437\u0430\u0446\u0438\u044e.","0a6e2581":"\u043f\u043e\u0434\u0431\u043e\u0440 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 ","4b2f60ec":"\u0426\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f - 'Aggregate rating'. \u0426\u0435\u043b\u044c: \u0441\u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0440\u0435\u0439\u0442\u0438\u043d\u0433 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0438\u043c\u0435\u044e\u0449\u0438\u0445\u0441\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432.","5140b71a":" 1. \u041f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u043b\u0438\u043d\u0435\u0439\u043d\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c (\u043b\u0438\u043d\u0435\u0439\u043d\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f, \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f, SVM), \u043d\u0430\u0441\u0442\u0440\u043e\u0438\u0442\u044c \u0435\u0451 \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b, \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u044b\u0432\u043e\u0434\u044b."}}