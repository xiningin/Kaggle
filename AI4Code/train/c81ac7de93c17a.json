{"cell_type":{"91d78659":"code","c863fe99":"code","ce739944":"code","78fc6912":"code","59baf902":"code","bb761536":"code","d432038f":"code","98c93608":"code","114e9b3b":"code","5fc68e79":"code","de61c651":"code","96671752":"code","20c6a87e":"code","fef23dfe":"code","49e6e147":"code","6d1d7ab8":"code","6fa3caf0":"code","d1f91357":"code","b5d2f660":"code","b2c11f69":"code","d8a13ddf":"code","81b6856d":"code","862f2253":"code","1178fe13":"code","097279b8":"code","6b2cd7b3":"code","7c55ac42":"code","e7fb6ba8":"code","9cb84888":"code","75149d90":"code","f873a9c5":"code","df480cdf":"code","86045725":"code","c5ca6afe":"code","81ae63a1":"code","9525736f":"code","0185513a":"code","13106fe2":"code","b187e9a9":"code","fef4677d":"code","44a6ba01":"code","605872d4":"code","8668ea10":"code","da80facf":"code","5eaf7c8e":"code","b5649da3":"code","d946a663":"code","7c5645f9":"code","a7473695":"code","a499a605":"code","8352ff2c":"code","ca2cf50f":"code","b70e4f74":"code","1dc50b5e":"code","f916ff13":"code","b1bfea00":"code","d9d882c9":"code","64287135":"code","d5cc7609":"code","f0691eb4":"code","c7672382":"code","01947d5b":"code","ad5964b6":"code","b673f43e":"code","9234c6cd":"code","9f9239ee":"code","8ad24962":"code","a63e4bbf":"code","7961c6c6":"code","dea5dace":"code","e35770d4":"code","e25a1716":"code","835f791b":"markdown","9a2c371d":"markdown","319516fd":"markdown","a9de0175":"markdown","b4cf5c9b":"markdown","857e3fdd":"markdown","b473db1c":"markdown","f938441c":"markdown","7f3bd519":"markdown","5d31a7bb":"markdown","7dabbf8b":"markdown","8e5577b0":"markdown","b9025368":"markdown","eac714d8":"markdown","a9e87160":"markdown","f7ef1f4b":"markdown","71a22672":"markdown","a291a797":"markdown","3a1b5edf":"markdown","623cec52":"markdown","f0cad3d1":"markdown","db5526e3":"markdown","8a03adc4":"markdown","f466d7e2":"markdown","4762c3b1":"markdown","237b8173":"markdown","d90a9a24":"markdown","7a825795":"markdown","479f9df0":"markdown","b6399353":"markdown","28b7b849":"markdown","f1fcc573":"markdown","54c62b02":"markdown","51fe814e":"markdown"},"source":{"91d78659":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport plotly.graph_objects as go\nfrom sklearn.preprocessing import MinMaxScaler\nimport gc\nimport joblib\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers \nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.cluster import KMeans\nimport json\nimport urllib\nfrom datetime import datetime, timedelta,timezone\nimport requests\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c863fe99":"btc = pd.read_csv('\/kaggle\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2020-12-31.csv')\nbtc.head()","ce739944":"btc['Timestamp'] = pd.to_datetime(btc.Timestamp, unit='s')\nbtc.head()","78fc6912":"print('Minutes in dataset: ',len(btc))\nprint('Hours in dataset: ',len(btc)\/60)\nprint('Days in dataset: ',len(btc)\/60\/24)","59baf902":"btc = btc[['Timestamp','Weighted_Price']]\nbtc.head()","bb761536":"btc.info()","d432038f":"# Data re-sampling based on 1 hour\n# If you want to sample by day, change H by D\nbtc = btc.resample('H', on='Timestamp')[['Weighted_Price']].mean()","98c93608":"    pano = btc.copy() #We're going to use this later\n    fig = go.Figure()\n    fig.add_trace(go.Scatter(x=pano.index, y=pano['Weighted_Price'],name='Full history BTC price'))\n    fig.update_layout(showlegend=True,title=\"BTC price history\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\n    fig.show()","114e9b3b":"print('Starting date selected: ',btc.index[51000])\nprint('NaN values: ',btc.iloc[51000:].isna().sum())","5fc68e79":"btc = btc.iloc[51000:]\nbtc.fillna(method ='bfill', inplace = True)\nprint('NaN values: ',btc.isna().sum())","de61c651":"print('New data points quantity: ',len(btc))","96671752":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=btc.index, y=btc['Weighted_Price'],name='BTC price'))\nfig.update_layout(showlegend=True,title=\"BTC price history\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","20c6a87e":"data_for_us = btc.copy() #To be used later on Unsupervised Learning\ntraining_start = int(len(btc) * 0.2)\n\ntrain = btc.iloc[training_start:]\ntest = btc.iloc[:training_start]\nprint(\"Total datasets' lenght: \",train.shape, test.shape)","fef23dfe":"scaler = MinMaxScaler().fit(train[['Weighted_Price']])","49e6e147":"def scale_samples(data,column_name,scaler):\n    data[column_name] = scaler.transform(data[[column_name]])\n    return data","6d1d7ab8":"joblib.dump(scaler, 'scaler.gz')\nscaler = joblib.load('scaler.gz')","6fa3caf0":"train = scale_samples(train.copy(),train.columns[0],scaler)\ntrain.head()","d1f91357":"test = scale_samples(test,test.columns[0],scaler)\ntest.head()","b5d2f660":"def shift_samples(data,column_name,lookback=24):\n    \"\"\"This function takes a *data* dataframe and returns two numpy arrays: \n    - X corresponds to the same values but packed into n frames of *lookback* values each\n    - Y corresponds to the sample shifted *lookback* steps to the future\n    \"\"\"\n    data_x = []\n    data_y = []\n    for i in range(len(data) - int(lookback)):\n        x_floats = np.array(data.iloc[i:i+lookback])\n        y_floats = np.array(data.iloc[i+lookback])\n        data_x.append(x_floats)\n        data_y.append(y_floats)\n    return np.array(data_x), np.array(data_y)","b2c11f69":"X_train, y_train = shift_samples(train[['Weighted_Price']],train.columns[0])\nX_test, y_test = shift_samples(test[['Weighted_Price']], test.columns[0])\ngc.collect()","d8a13ddf":"print(\"Final datasets' shapes:\")\nprint('X_train: '+str(X_train.shape)+', y_train: '+str(y_train.shape))\nprint('X_test: '+str(X_test.shape)+', y_train: '+str(y_test.shape))","81b6856d":"tsteps = X_train.shape[1]\nnfeatures = X_train.shape[2]","862f2253":"#First model - LSTM Autoencoder for anomaly detections\n\ndetector = Sequential()\ndetector.add(layers.LSTM(128, input_shape=(tsteps, nfeatures),dropout=0.2))\ndetector.add(layers.Dropout(rate=0.5))\ndetector.add(layers.RepeatVector(tsteps))\ndetector.add(layers.LSTM(128, return_sequences=True,dropout=0.2))\ndetector.add(layers.Dropout(rate=0.5))\ndetector.add(layers.TimeDistributed(layers.Dense(nfeatures))) \n\ndetector.compile(loss='mae', optimizer='adam')\ndetector.summary()","1178fe13":"checkpoint = ModelCheckpoint(\"\/kaggle\/working\/detector.hdf5\", monitor='val_loss', verbose=1,save_best_only=True, mode='auto', period=1)\nhistory1 = detector.fit(X_train,y_train,epochs=50,batch_size=128,verbose=1,validation_split=0.1,callbacks=[checkpoint],shuffle=False)","097279b8":"plt.plot(history1.history['loss'], label='Training Loss')\nplt.plot(history1.history['val_loss'], label='Validation Loss')\nplt.legend()","6b2cd7b3":"#Let's load the best model obtained during training\ndetector = load_model(\"detector.hdf5\")\ndetector.evaluate(X_test, y_test)","7c55ac42":"X_train_pred = detector.predict(X_train)\nloss_mae = np.mean(np.abs(X_train_pred - X_train), axis=1) #This is the formula to calculate MAE\nsns.distplot(loss_mae, bins=100, kde=True)","e7fb6ba8":"X_test_pred = detector.predict(X_test)\nloss_mae = np.mean(np.abs(X_test_pred - X_test), axis=1) \nsns.distplot(loss_mae, bins=100, kde=True)","9cb84888":"threshold = 0.15\n\ntest_df = pd.DataFrame(test[tsteps:])\ntest_df['loss'] = loss_mae\ntest_df['threshold'] = threshold\ntest_df['anomaly'] = test_df.loss > test_df.threshold\ntest_df['Weighted_Price'] = test[tsteps:].Weighted_Price","75149d90":"anomalies = test_df[test_df.anomaly == True]\nanomalies.head()","f873a9c5":"yvals1 = scaler.inverse_transform(test[tsteps:][['Weighted_Price']])\nyvals1 = yvals1.reshape(-1)","df480cdf":"yvals2 = scaler.inverse_transform(anomalies[['Weighted_Price']])\nyvals2 = yvals2.reshape(-1)","86045725":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=test[tsteps:].index, y=yvals1,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=anomalies.index, y=yvals2,mode='markers',name='Anomaly'))\nfig.update_layout(showlegend=True,title=\"BTC price anomalies\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","c5ca6afe":"scaled_pano = test.append(train, ignore_index=False)\nX_shifted, y_shifted = shift_samples(scaled_pano[['Weighted_Price']], scaled_pano.columns[0])\nprint(\"Scaled pano datasets' shapes:\")\nprint('X_shifted: '+str(X_shifted.shape)+', y_shifted: '+str(y_shifted.shape))","81ae63a1":"X_shifted_pred = detector.predict(X_shifted)\nloss_mae = np.mean(np.abs(X_shifted_pred - X_shifted), axis=1)","9525736f":"non_scaled_pano = pano.copy()[51000:]\nnon_scaled_pano.fillna(method ='bfill', inplace = True)\nnon_scaled_pano = non_scaled_pano[:-24]","0185513a":"non_scaled_pano['loss_mae'] = loss_mae\nnon_scaled_pano['threshold'] = threshold\nnon_scaled_pano['anomaly'] = non_scaled_pano.loss_mae > non_scaled_pano.threshold\nnon_scaled_pano.head()","13106fe2":"pano_outliers = non_scaled_pano[non_scaled_pano['anomaly'] == True]","b187e9a9":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=non_scaled_pano.index, y=non_scaled_pano['Weighted_Price'].values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=pano_outliers.index, y=pano_outliers['Weighted_Price'].values,mode='markers',name='Anomaly'))\nfig.update_layout(showlegend=True,title=\"BTC price anomalies - Autoencoder\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","fef4677d":"# Preparing data to be passed to the model\noutliers = pano.copy()[51000:]\noutliers.fillna(method ='bfill', inplace = True)\n\n# Training the model\nisolation_detector = IsolationForest(n_estimators=150,random_state=0,contamination='auto')\nisolation_detector.fit(outliers['Weighted_Price'].values.reshape(-1, 1))","44a6ba01":"data_ready = np.linspace(outliers['Weighted_Price'].min(), outliers['Weighted_Price'].max(), len(outliers)).reshape(-1,1)\noutlier = isolation_detector.predict(data_ready)","605872d4":"outliers['outlier'] = outlier\noutliers.head()","8668ea10":"a = outliers.loc[outliers['outlier'] == 1] #anomaly\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=outliers['Weighted_Price'].index, y=outliers['Weighted_Price'].values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=a.index, y=a['Weighted_Price'].values,mode='markers',name='Anomaly',marker_symbol='x',marker_size=2))\nfig.update_layout(showlegend=True,title=\"BTC price anomalies - IsolationForest\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","da80facf":"# Preparing data to be passed to the model\noutliers_k_means = pano.copy()[51000:]\noutliers_k_means.fillna(method ='bfill', inplace = True)\nkmeans = KMeans(n_clusters=2, random_state=0).fit(outliers_k_means['Weighted_Price'].values.reshape(-1, 1))\noutlier_k_means = kmeans.predict(outliers_k_means['Weighted_Price'].values.reshape(-1, 1))\noutliers_k_means['outlier'] = outlier_k_means\noutliers_k_means.head()","5eaf7c8e":"a = outliers_k_means.loc[outliers_k_means['outlier'] == 1] #anomaly\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=outliers_k_means['Weighted_Price'].index, y=outliers_k_means['Weighted_Price'].values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=a.index, y=a['Weighted_Price'].values,mode='markers',name='Anomaly',marker_symbol='x',marker_size=2))\nfig.update_layout(showlegend=True,title=\"BTC price anomalies - KMeans\",xaxis_title=\"Time\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\nfig.show()","b5649da3":"#Second model - LSTM regressor for price predictions\nregressor = Sequential()\nregressor.add(layers.LSTM(256, activation='relu', return_sequences=True, input_shape=(tsteps, nfeatures),dropout=0.2))\nregressor.add(layers.LSTM(256, activation='relu',dropout=0.2))\nregressor.add(layers.Dense(1))\n\nregressor.compile(loss='mse', optimizer='adam')\nregressor.summary()","d946a663":"checkpoint = ModelCheckpoint(\"\/kaggle\/working\/regressor.hdf5\", monitor='val_loss', verbose=1,save_best_only=True, mode='auto', period=1)\nhistory2 = regressor.fit(X_train,y_train,epochs=30,batch_size=128,verbose=1,validation_data=(X_test, y_test),callbacks=[checkpoint],shuffle=False)","7c5645f9":"#Third model - Conv1D regressor for price prediction\n\nregressor2 = Sequential()\nregressor2.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(tsteps, nfeatures)))\nregressor2.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\nregressor2.add(layers.Dropout(0.5))\nregressor2.add(layers.MaxPooling1D(pool_size=2))\nregressor2.add(layers.Flatten())\nregressor2.add(layers.Dense(50, activation='relu'))\nregressor2.add(layers.Dense(1))\n\nregressor2.compile(optimizer='adam', loss='mse')\nregressor2.summary()","a7473695":"checkpoint = ModelCheckpoint(\"\/kaggle\/working\/regressor2.hdf5\", monitor='val_loss', verbose=1,save_best_only=True, mode='auto', period=1)\nhistory3 = regressor.fit(X_train,y_train,epochs=30,batch_size=128,verbose=1,validation_data=(X_test, y_test),callbacks=[checkpoint],shuffle=False)","a499a605":"plt.plot(history2.history['loss'], label='Training Loss')\nplt.plot(history2.history['val_loss'], label='Validation Loss')\nplt.legend()","8352ff2c":"plt.plot(history3.history['loss'], label='Training Loss')\nplt.plot(history3.history['val_loss'], label='Validation Loss')\nplt.legend()","ca2cf50f":"regressor = load_model(\"regressor.hdf5\")\nregressor.evaluate(X_test, y_test)","b70e4f74":"regressor2 = load_model(\"regressor2.hdf5\")\nregressor2.evaluate(X_test, y_test)","1dc50b5e":"test = regressor.predict(X_test[0].reshape(1,24,1))","f916ff13":"test.shape","b1bfea00":"scaler.inverse_transform(test)","d9d882c9":"past = datetime.now(tz=timezone.utc) - timedelta(days=1) #yesterday's date\npast = datetime.strftime(past, '%s') #reshaping to unix format\ncurrent = datetime.now(tz=timezone.utc).strftime('%s') #today's date\n\nprint(past)\nprint(current)","64287135":"# connect to poloniex's API\nurl = 'https:\/\/poloniex.com\/public?command=returnChartData&currencyPair=USDT_BTC&start='+str(past)+'&end='+str(current)+'&period=300'\nresult = requests.get(url)\nresult = result.json()\nprint(result)","d5cc7609":"last_data = pd.DataFrame(result)","f0691eb4":"last_data","c7672382":"last_data['date'] = pd.to_datetime(last_data.date, unit='s') #To get date in readable format\nlast_data.head()","01947d5b":"last_data = last_data[['date','weightedAverage']]\nlast_data.head()","ad5964b6":"last_data = last_data.resample('H', on='date')[['weightedAverage']].mean()","b673f43e":"last_data = last_data[-24:]\nunscaled = last_data.copy()\nlen(last_data)","9234c6cd":"last_data_scaled = scale_samples(last_data,last_data.columns[0],scaler)\nlast_data_scaled.head()","9f9239ee":"predictions = regressor.predict(last_data_scaled.values.reshape(1,24,1))\nunscaled = unscaled.iloc[1:]\nunscaled = unscaled.append(pd.DataFrame(scaler.inverse_transform(predictions)[0], index= [unscaled.index[len(unscaled)-1] + timedelta(hours=1)],columns =['weightedAverage']))\nfuture_scaled = scale_samples(unscaled.copy(),unscaled.columns[0],scaler)\nfuture_scaled_pred = detector.predict(future_scaled.values.reshape(1,24,1))\nfuture_loss = np.mean(np.abs(future_scaled_pred - future_scaled.values.reshape(1,24,1)), axis=1)\nunscaled['threshold'] = threshold \nunscaled['loss'] = future_loss[0][0]\nunscaled['anomaly'] = unscaled.loss > threshold\nunscaled.head()","8ad24962":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=unscaled.index, y=unscaled.weightedAverage.values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=unscaled.index, y=unscaled[unscaled['anomaly']==True]['weightedAverage'].values,mode='markers',marker_symbol='x',marker_size=10,name='Anomaly'))\nfig.add_vrect(x0=unscaled.index[-2], x1=unscaled.index[-1],fillcolor=\"LightSalmon\", opacity=1,layer=\"below\", line_width=0)\nfig.update_layout(showlegend=True,title=\"BTC price predictions and anomalies\",xaxis_title=\"Time (UTC)\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\n\nfig.show()","a63e4bbf":"anomalies_24h = np.linspace(unscaled['weightedAverage'].min(), unscaled['weightedAverage'].max(), len(unscaled)).reshape(-1,1)\noutlier = isolation_detector.predict(anomalies_24h)\nunscaled['outlier'] = outlier\nunscaled.head()","7961c6c6":"print('Anomalies in prediction: ',len(unscaled[unscaled['outlier'] == 1]))","dea5dace":"outlier_k_means = kmeans.predict(unscaled['weightedAverage'].values.reshape(-1, 1))\nunscaled['outlier'] = outlier_k_means\nunscaled.head()","e35770d4":"print('Anomalies in prediction: ',len(unscaled[unscaled['outlier'] == 1]))","e25a1716":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=unscaled.index, y=unscaled.weightedAverage.values,mode='lines',name='BTC Price'))\nfig.add_trace(go.Scatter(x=unscaled.index, y=unscaled[unscaled['outlier']==True]['weightedAverage'].values,mode='markers',marker_symbol='x',marker_size=10,name='Anomaly'))\nfig.add_vrect(x0=unscaled.index[-2], x1=unscaled.index[-1],fillcolor=\"LightSalmon\", opacity=1,layer=\"below\", line_width=0)\nfig.update_layout(showlegend=True,title=\"BTC price predictions and anomalies\",xaxis_title=\"Time (UTC)\",yaxis_title=\"Prices\",font=dict(family=\"Courier New, monospace\"))\n\nfig.show()","835f791b":"# Imports","9a2c371d":"As you can see in the charts from above, observations after 0.150 become unusual. Let's set that number as the threshold.","319516fd":"# Neural networks' evaluation","a9de0175":"As you may see and compare, K-Means model achieved better results than IsolationForest and very similar results than the Autoencoder.","b4cf5c9b":"Let's plot the whole panorama to visually understand what portion of the set must me removed","857e3fdd":"# Time-series forecasting models\n\nLet's test a few models to determine which one fits better the dataset and delivers better results","b473db1c":"## LSTM Neural Network","f938441c":"## Preprocessing API data","7f3bd519":"## Conv1D Neural Network","5d31a7bb":"### Isolation Forest","7dabbf8b":"# Data scaling\n\nThis stage is extremely important as a requisite to train Neural Networks. If you skip this step maybe your model won't converge.","8e5577b0":"# Data preprocessing\nLet's resample the data, take only the variable we're going to use and determine what's the window of data that's more meaningful for our purpose. Let's also clean null values.","b9025368":"As you can see above, there's a portion of data at the beginning of the set that contains null values. In addition, those are values that are not common in the current BTC price. We need to get rid of them.","eac714d8":"Let's see how the new dataset looks like once the null and the close-to-cero values were removed.","a9e87160":"# Sequences generation and dataset creation","f7ef1f4b":"## Plotting prices' anomalies","71a22672":"## K-Means Clustering (Bonus)","a291a797":"### Plotting prices' anomalies","3a1b5edf":"# Data Splitting\nWe're going to take the test set as the first 20% window. The next 80s as the training set.","623cec52":"### KMeans","f0cad3d1":"Great! Let's move on.","db5526e3":"# Anomaly detectors' training\n## LSTM Autoencoder Neural Network\n\nThe one that we'll be using along this notebook.","8a03adc4":"Now that charts fits better with the current BTC price reality. Let's use those samples as our new dataset.","f466d7e2":"This notebook is part of an article about how to forecast and detect anomalies on time-series data. The main objective is to train a RNN regressor on the Bitcoin dataset to predict future values on then detect anomalies in the whole data window - that last step achieved by implementing a RNN Autoencoder.\n\nYou'll see some other models in the notebook that I've provided to you in case they are of your interest and this RNN regressor + RNN Autoencoder doesn't perform well for your purpose in any other scenario.\n\nThe dataset used is available at https:\/\/www.kaggle.com\/mczielinski\/bitcoin-historical-data and contains BITCOIN\/USD 1-minute candle data, from 2012-01-01 to 2020-12-31. I hope you can get advantage of this approach!","4762c3b1":"As you could see above, the LSTM model delivers better results. Let's keep that. Let's inspect now if the output has the shape that we were expecting. The model must return a single scalar by each sequence of 24 floating numbers:","237b8173":"## Getting current date and time","d90a9a24":"## Connecting to Poloniex public API","7a825795":"# Gathering crypto data from the API","479f9df0":"# Predicting on API data","b6399353":"I hope this notebook has been useful to you! Thanks a lot.","28b7b849":"### Determining threshold for Autoencoder detector","f1fcc573":"## Isolation forest model (Bonus)","54c62b02":"## Detecting outliers with classic Unsupervised Learning models","51fe814e":"## Implementing Neural Networks approach"}}