{"cell_type":{"2a8f0575":"code","14f3404c":"code","0de14d6d":"code","9d6899f5":"code","b5f997c4":"code","f4d02d00":"code","9ccc6110":"code","9990da03":"code","637a631e":"code","b4f65cba":"code","33cce45b":"code","40f02f2e":"code","a66255db":"code","a66dee95":"code","6dfa4a77":"code","914ccd39":"code","bcf4db25":"code","3b4added":"code","67cd3bb8":"code","14274287":"code","0f8c6586":"code","200d98ef":"code","5009a8cf":"code","7ec763df":"code","029f39eb":"code","f3547daf":"code","f9ff22a2":"code","be9757b4":"code","481fc893":"code","e4fcb0d0":"code","0541d4c1":"code","3c741726":"code","450c3360":"code","6c4e1d1e":"code","ed59ec95":"code","b765d033":"code","1baeab1e":"code","89aaface":"code","12c263d0":"code","d9796d64":"code","ef7d5257":"code","2a700869":"code","26666a0e":"code","9cedcad8":"code","ad393190":"code","6bdc960f":"code","b064c28c":"code","59742db5":"code","6708bd2f":"code","34478eb7":"code","c3d12995":"code","277c46e3":"code","e7f3438f":"markdown","f75c2c5b":"markdown","4b1538df":"markdown","a38d6c8a":"markdown"},"source":{"2a8f0575":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","14f3404c":"df = pd.read_csv(\"\/kaggle\/input\/shopee-sentiment-analysis\/train.csv\")\ndf.head()","0de14d6d":"df.shape","9d6899f5":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import confusion_matrix, balanced_accuracy_score, f1_score","b5f997c4":"X = df['review']\ny = df['rating']","f4d02d00":"from nltk.tokenize import word_tokenize\nimport string\nfrom nltk.corpus import stopwords","9ccc6110":"def text_processing(text):\n    # split into words\n    tokens = word_tokenize(text)\n    # convert to lower case\n    tokens = [w.lower() for w in tokens]\n    # remove punctuation from each word\n    table = str.maketrans('', '', string.punctuation)\n    stripped = [w.translate(table) for w in tokens]\n    # remove remaining tokens that are not alphabetic\n    words = [word for word in stripped if word.isalpha()]\n    # filter out stop words\n    stop_words = set(stopwords.words('english'))\n    words = [w for w in words if not w in stop_words]\n    return words","9990da03":"X = X.apply(lambda x: text_processing(x))","637a631e":"X = X.apply(lambda x: \" \".join(x))","b4f65cba":"X.to_csv(\"X_processed.csv\", index=False)","33cce45b":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\nprint(len(X_train), len(X_test), len(y_train), len(y_test))","40f02f2e":"X_train.head()","a66255db":"y_train.head()","a66dee95":"X.apply(lambda x:len(x.split(\" \"))).describe()","6dfa4a77":"import seaborn as sns\nsns.distplot(X.apply(lambda x:len(x.split(\" \"))))","914ccd39":"classifier_sgd = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,1), analyzer='word')),\n    ('clf-sgd', SGDClassifier()),\n])\n\nclassifier_sgd.fit(X_train, y_train)\ny_pred_sgd = classifier_sgd.predict(X_test)","bcf4db25":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_sgd))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_sgd, average='macro'))","3b4added":"classifier_svm = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,1), analyzer='word')),\n    ('clf-svm', LinearSVC()),\n])\n\nclassifier_svm.fit(X_train, y_train)\ny_pred_svm = classifier_svm.predict(X_test)","67cd3bb8":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_svm))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_svm, average='macro'))","14274287":"classifier_mnb = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,1), analyzer='word')),\n    ('clf-mnb', MultinomialNB()),\n])\n\nclassifier_mnb.fit(X_train, y_train)\ny_pred_mnb = classifier_mnb.predict(X_test)","0f8c6586":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_mnb))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_mnb, average='macro'))","200d98ef":"#### Unigram Bigram (SGD, SVM, MNB)","5009a8cf":"classifier_sgd = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,2), analyzer='word')),\n    ('clf-sgd', SGDClassifier()),\n])\n\nclassifier_sgd.fit(X_train, y_train)\ny_pred_sgd = classifier_sgd.predict(X_test)","7ec763df":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_sgd))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_sgd, average='macro'))","029f39eb":"classifier_svm = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,2), analyzer='word')),\n    ('clf-svm', LinearSVC()),\n])\n\nclassifier_svm.fit(X_train, y_train)\ny_pred_svm = classifier_svm.predict(X_test)","f3547daf":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_svm))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_svm, average='macro'))","f9ff22a2":"classifier_mnb = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,2), analyzer='word')),\n    ('clf-mnb', MultinomialNB()),\n])\n\nclassifier_mnb.fit(X_train, y_train)\ny_pred_mnb = classifier_mnb.predict(X_test)","be9757b4":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_mnb))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_mnb, average='macro'))","481fc893":"classifier_sgd = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(2,2), analyzer='word')),\n    ('clf-sgd', SGDClassifier()),\n])\n\nclassifier_sgd.fit(X_train, y_train)\ny_pred_sgd = classifier_sgd.predict(X_test)","e4fcb0d0":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_sgd))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_sgd, average='macro'))","0541d4c1":"classifier_svm = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(2,2), analyzer='word')),\n    ('clf-svm', LinearSVC()),\n])\n\nclassifier_svm.fit(X_train, y_train)\ny_pred_svm = classifier_svm.predict(X_test)","3c741726":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_svm))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_svm, average='macro'))","450c3360":"classifier_mnb = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(2,2), analyzer='word')),\n    ('clf-mnb', MultinomialNB()),\n])\n\nclassifier_mnb.fit(X_train, y_train)\ny_pred_mnb = classifier_mnb.predict(X_test)","6c4e1d1e":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_mnb))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_mnb, average='macro'))","ed59ec95":"classifier_sgd = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,4), analyzer='word')),\n    ('clf-sgd', SGDClassifier()),\n])\n\nclassifier_sgd.fit(X_train, y_train)\ny_pred_sgd = classifier_sgd.predict(X_test)","b765d033":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_sgd))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_sgd, average='macro'))","1baeab1e":"classifier_svm = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,4), analyzer='word')),\n    ('clf-svm', LinearSVC()),\n])\n\nclassifier_svm.fit(X_train, y_train)\ny_pred_svm = classifier_svm.predict(X_test)","89aaface":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_svm))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_svm, average='macro'))","12c263d0":"classifier_mnb = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,4), analyzer='word')),\n    ('clf-mnb', MultinomialNB()),\n])\n\nclassifier_mnb.fit(X_train, y_train)\ny_pred_mnb = classifier_mnb.predict(X_test)","d9796d64":"print(\"--- Accuracy Report ---\\n\")\nprint(\"-- Balanced Accuracy Score --\")\nprint(balanced_accuracy_score(y_test, y_pred_mnb))\nprint(\"\")\nprint(\"-- F1 Score --\")\nprint(f1_score(y_test, y_pred_mnb, average='macro'))","ef7d5257":"test = pd.read_csv(\"..\/input\/shopee-sentiment-analysis\/test.csv\")","2a700869":"test.head()","26666a0e":"X_test_final = test['review']\nX_test_final.head()","9cedcad8":"X_test_final = X_test_final.apply(lambda x: text_processing(x))","ad393190":"X_test_final = X_test_final.apply(lambda x: \" \".join(x))","6bdc960f":"X_test_final.head()","b064c28c":"X_train_combined = pd.concat([X_train, X_test])\ny_train_combined = pd.concat([y_train, y_test])","59742db5":"classifier_svm = Pipeline([\n    ('vect', TfidfVectorizer(ngram_range=(1,4), analyzer='word')),\n    ('clf-svm', LinearSVC()),\n])\n\nclassifier_svm.fit(X_train_combined, y_train_combined)\ny_pred_svm = classifier_svm.predict(X_test_final)","6708bd2f":"y_pred_svm","34478eb7":"sample_df = pd.read_csv(\"..\/input\/shopee-sentiment-analysis\/sampleSubmission.csv\")\nsample_df.head()","c3d12995":"submission_df = pd.DataFrame({\"review_id\": test['review_id'], \"rating\": y_pred_svm})\nsubmission_df.head()","277c46e3":"submission_df.to_csv(\"prediction_processed_ngram_1_4_mnb.csv\", index=False)","e7f3438f":"#### Unigram (SGD, SVM, MNB)","f75c2c5b":"#### NGram 1-4","4b1538df":"### Test Data","a38d6c8a":"#### Bigram-Only"}}