{"cell_type":{"73ebb660":"code","879fb963":"code","29c7ee63":"code","8980c525":"code","ad27ffbd":"markdown","b784903a":"markdown"},"source":{"73ebb660":"import numpy as np, pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import VarianceThreshold\n\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nfrom tqdm import tqdm_notebook\n\nimport warnings\nwarnings.filterwarnings('ignore')","879fb963":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]","29c7ee63":"oof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\nfor i in tqdm_notebook(range(512)):\n\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = VarianceThreshold(threshold=2).fit_transform(data[cols])\n\n    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n\n    skf = StratifiedKFold(n_splits=11, random_state=42)\n    for train_index, test_index in skf.split(train2, train2['target']):\n\n        clf = QuadraticDiscriminantAnalysis(0.1)\n        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n        oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n        preds[idx2] += clf.predict_proba(test3)[:,1] \/ skf.n_splits\n\nauc = roc_auc_score(train['target'], oof)\nprint(f'AUC: {auc:.5}')","8980c525":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['target'] = preds\nsub.to_csv('submission.csv', index=False)","ad27ffbd":"### Why it works so good?\nAs was found <a href=\"https:\/\/www.kaggle.com\/mhviraf\/synthetic-data-for-next-instant-gratification\">here<\/a>, dataset is created by `make_classification` method. This method generates gaussians with non-diagonal covariance matrix and assigns them classes. QDA works exactly with this structures of data, it learns normal distributions with n-dimentional covariance matrix.<br>\n### Why it works so fast?\nIt uses Bayes theorem to infer likelihood. Components of this formula fits fast, because they compute statiscs.\n\n\n#### People made challenge of minimizing lines of code. Let's make a challenge of minimizing exe time :)","b784903a":"# Quadratic Discriminant Analysis\n\n\nNotice that execution time of this kernel is 83 sec."}}