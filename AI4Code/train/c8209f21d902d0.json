{"cell_type":{"65149c34":"code","994a00dc":"code","39e5f3d2":"code","a40342f4":"code","3c711842":"code","d236ddae":"code","a2808497":"code","ef2bf27a":"code","07a93e91":"code","e5b685e0":"code","41673c31":"markdown","7f01b2b5":"markdown"},"source":{"65149c34":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","994a00dc":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","39e5f3d2":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","a40342f4":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","3c711842":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","d236ddae":"#Defining a function for submission file  to competition\ndef csv_write(pred):\n    output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': pred})\n    output.to_csv('submission.csv', index=False)\n    print(\"Your submission was successfully saved!\")","a2808497":"# I will do feature extraction and pattern finding here below:\n# For now, it is the simplest version of features\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\ny_train = train_data[\"Survived\"]\nX_train = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])","ef2bf27a":"# Our first try will be Random Forest Classifier as it is a powerful tool to split data into groups\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nclf1 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nclf1.fit(X_train, y_train)\ny_pred_rand_for = clf1.predict(X_test)\nacc_rand_for = round( clf1.score(X_train, y_train) * 100, 2)\nprint (\"Train Accuracy: \" + str(acc_rand_for) + '%')\n","07a93e91":"# Second one will be Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\n\nclf2 = LogisticRegression()\nclf2.fit(X_train, y_train)\ny_pred_log_reg = clf2.predict(X_test)\nacc_log_reg = round( clf2.score(X_train, y_train) * 100, 2)\nprint (\"Train Accuracy: \" + str(acc_log_reg) + '%')","e5b685e0":"# For now, finally third one is Decision Tree Classifier\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier()\nclf.fit(X_train, y_train)\ny_pred_dec_tree = clf.predict(X_test)\nacc_dec_tree = round(clf.score(X_train, y_train) * 100, 2)\nprint (\"Train Accuracy: \" + str(acc_dec_tree) + '%')\n\ncsv_write(y_pred_dec_tree)","41673c31":"## Titanic Competition Dataset\n\n![](https:\/\/i0.wp.com\/khosann.com\/wp-content\/uploads\/2017\/03\/titanic-titanik-ballard-leonardo_dicaprio-james_cameron.jpg)\n\n#### Here we try to figure out the patterns who survived the famous Titanic crash. As we apply feature extraction from train set, we will also apply machine learning concepts from very basic to harder to implement. #### \n\n#### This will be a live notebook which I try to implement new things as I learned.I will try to find out different patterns, and try to apply those day by day. #### \n","7f01b2b5":"All of the methods' accuracy will be calculated with train sets for now. Maybe it is a little bit wrong but for first try, I will just leave it like that.\n\nFor now, my codes' accuracy is just %77. That will go up as patterns can be found in the data."}}