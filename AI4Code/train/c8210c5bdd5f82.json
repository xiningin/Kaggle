{"cell_type":{"b6b30f8c":"code","cbaa4dd4":"code","fc12670c":"code","66ed1c34":"code","78d782fa":"code","c6c1efbc":"code","253b0eee":"code","7b5d29d0":"code","2a0f3e68":"code","132447c8":"code","caf53f29":"code","d31d6fbb":"code","37edc7f9":"code","3e7e47a1":"code","c04aa8af":"code","221202d2":"code","429b570d":"code","409d8f1c":"code","ec3d1ecf":"code","27b31d75":"code","678e899f":"code","05e1b379":"code","5576b105":"code","dd10ea9b":"code","39d5160f":"markdown","93ec34a8":"markdown","8a77d8a2":"markdown"},"source":{"b6b30f8c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n# Libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\nfrom colorama import Fore, Back, Style\nr_ = Fore.WHITE\nfrom plotly.offline import iplot\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nfrom skimage.io import imshow, imread, imsave\nfrom skimage.transform import rotate, AffineTransform, warp,rescale, resize, downscale_local_mean\nfrom skimage import color,data\nfrom skimage.exposure import adjust_gamma\nfrom skimage.util import random_noise","cbaa4dd4":"# Train \ntrain_labels=pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')","fc12670c":"cmap_plot = plt.get_cmap('jet_r')\nddt = train_labels.target.value_counts().to_frame()\nplt.style.use('fivethirtyeight')\nfig, ax = plt.subplots(1, 1, figsize = (12, 4))\nsns.countplot(data = train_labels, x = 'target', orient = \"v\", palette = 'pastel', ax = ax)\nplt.suptitle(\"Train target distribution\")\nplt.rcParams.update(plt.rcParamsDefault)","66ed1c34":"train_files = glob.glob(\"..\/input\/seti-breakthrough-listen\/train\" + \"\/*\/*.npy\")\nprint(\"\\t\\t\\t\\t{}{}Number of train files: {}\".format(r_, Back.BLACK, len(train_files)))","78d782fa":"def get_train_filename_by_id(_id: str) -> str:\n    return f\"..\/input\/seti-breakthrough-listen\/train\/{_id[0]}\/{_id}.npy\"\n\ndef show_cadence(filename: str, label: int) -> None:\n    fig, axes = plt.subplots(6, 1, figsize = (16, 10))\n    ax = axes.ravel()\n    arr = np.load(filename)\n    for i in range(6):\n        \n        ax[i].imshow(arr[i].astype(float), interpolation='nearest', aspect='auto')\n        ax[i].text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n        if i != 5:\n            ax[i].set_xticks([])\n            \n    fig.text(0.5, -0.02, 'Frequency Range', ha='center', fontsize=18)\n    fig.text(-0.02, 0.5, 'Seconds', va='center', rotation='vertical', fontsize=18)\n\n    plt.suptitle(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n    fig.tight_layout()\n    plt.show()","c6c1efbc":"positive_target=train_labels.query(\"target==1\").sample().id.item()\nnegative_target=train_labels.query(\"target==0\").sample().id.item()\nshow_cadence(get_train_filename_by_id(positive_target), 1)\nshow_cadence(get_train_filename_by_id(negative_target), 0)","253b0eee":"#Test\ntest_files = glob.glob('..\/input\/seti-breakthrough-listen\/test' + \"\/*\/*.npy\")\nprint(\"\\t\\t\\t\\t{}{}Number of test files: {}\".format(r_, Back.BLACK, len(test_files)))","7b5d29d0":"show_cadence(np.random.choice(test_files, 1).item(), None)\nshow_cadence(np.random.choice(test_files, 1).item(), None)","2a0f3e68":"!pip install efficientnet_pytorch","132447c8":"#Libraries\nimport os\nimport sys\nimport pandas as pd\nimport numpy as np\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nfrom efficientnet_pytorch import model as enet\nimport random\nfrom sklearn.model_selection import StratifiedKFold","caf53f29":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nrandom_state = set_seed(76)","d31d6fbb":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","37edc7f9":"class ClassificationDataset:\n    \n    def __init__(self, image_paths, targets): \n        self.image_paths = image_paths\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item]).astype(float)\n\n        targets = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }","3e7e47a1":"df_train=pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')","c04aa8af":"df_train['img_path']=df_train['id'].apply(lambda x:f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')","221202d2":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv1 = nn.Conv2d(6, 3, kernel_size=3, stride=1, padding=3, bias=False)\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","429b570d":"def train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data[\"image\"]\n        targets = data['targets']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","409d8f1c":"baseline_name = 'efficientnet-b1'\npretrained_model = {\n    baseline_name: '..\/input\/efficientnet-pytorch\/efficientnet-b1-dbc7070a.pth'\n}\nmodels = []\ndevice = \"cuda\"\nepochs = 3\nBatch_Size = 32\nX = df_train.img_path.values\nY = df_train.target.values\nskf = StratifiedKFold(n_splits=5)\nfold = 0\n\nfor train_index, test_index in skf.split(X, Y):\n    \n    model = enetv2(baseline_name, out_dim=1)\n    model.to(device)\n\n    train_images, valid_images = X[train_index], X[test_index]\n    train_targets, valid_targets = Y[train_index], Y[test_index]\n\n    train_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets)\n    valid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size,shuffle=True, num_workers=4)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size,shuffle=False, num_workers=4)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\n    for epoch in range(epochs):\n        train(train_loader, model, optimizer, device=device)\n        predictions, valid_targets = evaluate(valid_loader, model, device=device)\n        roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n        \n    torch.save(model.state_dict(),baseline_name + '-' + str(fold) + '.pt')\n    models.append(model)\n    fold += 1","ec3d1ecf":"submission=pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\nsubmission['img_path']=submission['id'].apply(lambda x:f'..\/input\/seti-breakthrough-listen\/test\/{x[0]}\/{x}.npy')","27b31d75":"test_dataset=ClassificationDataset(image_paths=submission.img_path.values, targets=submission.target.values)\ntest_loader=torch.utils.data.DataLoader(test_dataset, batch_size=16,shuffle=False,num_workers=4)","678e899f":"sig=torch.nn.Sigmoid()\nouts=[]\nfor model in models:\n    predictions,valid_targets=evaluate(test_loader, model, device=device)\n    predictions=np.array(predictions)[:,0]\n    out=sig(torch.from_numpy(predictions))\n    out=out.detach().numpy()\n    outs.append(out)","05e1b379":"pred=np.mean(np.array(outs),axis=0)","5576b105":"submission.target=pred\nsubmission.drop(['img_path'],axis=1,inplace=True)\nsubmission.to_csv('submission.csv', index=False)","dd10ea9b":"submission.head()","39d5160f":"Now let's visualize the Train and Test Dataset\n","93ec34a8":"## 3. Model: EffiecientNet","8a77d8a2":"Lets kickstart the modelling..\n"}}