{"cell_type":{"bf2c5d24":"code","b0ea5292":"code","e38f351f":"code","2b170b57":"code","c3fbfcf6":"code","78fb1bea":"code","e91fd0c6":"code","441ff319":"code","3e514f91":"code","9808ad5b":"code","96d517af":"code","b0961580":"code","85a5fcfb":"code","588452ab":"code","10a35898":"code","61f22525":"code","6b4c33a1":"code","b1923117":"code","efe75c5a":"code","5667dbc9":"code","db1e67b8":"code","1fb35a19":"code","a4c9605c":"code","62326f3c":"code","0fb848f8":"code","af11d81d":"code","8b5d7450":"code","fb18d702":"code","61a09c6c":"code","e81a22ef":"code","f299358c":"code","9951b4f1":"code","70e66b18":"code","2e9104ef":"code","5e0d2ea5":"code","d11c9526":"code","68b46bf7":"code","28f12963":"code","aaae51b2":"code","35acad56":"code","7fa9e1e0":"code","359dc2ba":"code","cb86295d":"code","7eb7ba2e":"code","67822ede":"code","37c901d0":"code","1f6218ed":"code","e08fdc34":"code","ee0c9cac":"code","4480684a":"markdown","745bdc29":"markdown","1bd03e41":"markdown","846139d7":"markdown","7e77103c":"markdown","98e342ff":"markdown","9bd5f8f8":"markdown","c4df8e66":"markdown","df8658c4":"markdown","05d6ce0d":"markdown","53f991cc":"markdown","92b17651":"markdown","62534b29":"markdown","63b6081a":"markdown","f23d510e":"markdown","32828140":"markdown","1a7cada4":"markdown","84a2e078":"markdown","059ab150":"markdown","54736b7b":"markdown","056b3297":"markdown","88fad72b":"markdown","86deed00":"markdown","d1e5e1ff":"markdown","a7ac5383":"markdown","8b95d09a":"markdown","537a4bf0":"markdown","ff3b4569":"markdown","530118cb":"markdown","914e43d8":"markdown","7b4a7ae0":"markdown","a21017cb":"markdown"},"source":{"bf2c5d24":"import numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport warnings\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings('ignore')","b0ea5292":"#import data\ndata = pd.read_csv('..\/input\/diamonds\/diamonds.csv')\ndata.head()","e38f351f":"data.drop('Unnamed: 0', axis=1, inplace=True)","2b170b57":"data.shape","c3fbfcf6":"data.info()","78fb1bea":"data.dtypes","e91fd0c6":"data.isnull().sum()\/data.shape[0]","441ff319":"data.describe()","3e514f91":"data.groupby('color')['price'].describe()","9808ad5b":"target = 'price'","96d517af":"data.price.hist(bins=10)","b0961580":"for col in data.select_dtypes(include=[np.number]):\n    plt.figure(figsize=(12,8))\n    sns.regplot(data=data, x = f'{col}', y=target)","85a5fcfb":"def detect_outliers(data):\n    data = data[data['x'] > 0]\n    data = data[data['y'] < 20]\n    data = data[data['z'] < 10]\n    data = data[data[\"z\"] > 1.8]\n    data = data[data['table'] > 50]\n    data = data[data['table'] < 70]\n    data = data[data['depth'] > 54]\n    data = data[data['depth'] < 70]\n    data = data[data['carat'] < 3.3]\n    return data","588452ab":"data = detect_outliers(data=data)","10a35898":"for col in data.select_dtypes(include=[np.number]):\n    plt.figure(figsize=(12,8))\n    sns.regplot(data=data, x = f'{col}', y=target)","61f22525":"carat_ranges = pd.qcut(data.carat, 5)\nplt.figure(figsize=(15, 5))\nsns.barplot(x=carat_ranges.values, y=target, data=data)","6b4c33a1":"x_ranges = pd.qcut(data.x, 6)\nplt.figure(figsize=(15, 5))\nsns.barplot(x=x_ranges.values, y=target, data=data)","b1923117":"depth_ranges = pd.qcut(data.depth, 4)\nplt.figure(figsize=(15, 5))\nsns.barplot(x=depth_ranges.values, y=target, data=data)","efe75c5a":"for col in data.select_dtypes(exclude=[np.number]):\n    plt.figure(figsize=(10, 6))\n    sns.countplot(data=data, x=f'{col}')","5667dbc9":"fig, axes = plt.subplots(1,2, figsize=(15,5), sharey=True, sharex=True)\nsns.barplot(ax=axes[0], x='cut', y=target, data=data)\naxes[0].set_title('cut')\nsns.boxplot(ax=axes[1], x='cut', y=target, data=data)\naxes[1].set_title('cut')","db1e67b8":"fig, axes = plt.subplots(1,2, figsize=(15,5), sharey=True, sharex=True)\nsns.barplot(ax=axes[0], x='clarity', y=target, data=data)\nsns.boxplot(ax=axes[1], x='clarity', y=target, data=data)","1fb35a19":"fig, axes = plt.subplots(1,2, figsize=(15,5), sharey=True, sharex=True)\nsns.barplot(ax=axes[0], x='color', y=target, data=data)\nsns.boxplot(ax=axes[1], x='color', y=target, data=data)","a4c9605c":"def dist_plot(data):\n    fig, axes = plt.subplots(1,3,figsize=(20,6), sharex=True)\n    i = 0\n    for col in data.select_dtypes(exclude=[np.number]):\n        for item in data[col].unique():\n            sns.distplot(data[data[col] == item]['price'], label=item, ax=axes[i])\n        i = i + 1\n        plt.legend()","62326f3c":"dist_plot(data)","0fb848f8":"df = data.copy()","af11d81d":"corr_matrix = df.corr()","8b5d7450":"plt.figure(figsize=(14,10))\nsns.heatmap(corr_matrix, cmap='RdBu_r', annot=True, linewidths=0.5, center=0)","fb18d702":"def features_eng(data):\n    data['volume'] = data['x'] * data['y'] * data['z']\n    data['carat_per_x'] = data['carat'] \/ data['x']\n    \n    #data['caratIsHigh'] = data['carat'] == 'C5'\n    data.drop(['x', 'y', 'z'], axis=1, inplace=True)\n    return data","61a09c6c":"#df = features_eng(data=df)","e81a22ef":"#df.head()","f299358c":"from sklearn.preprocessing import LabelEncoder\ndef preprocessing(data):\n    label_encode = LabelEncoder()\n    for col in data.select_dtypes('object'):\n        data[col] = label_encode.fit_transform(data[col])\n    return data\ndef encodage(dfp):\n    code = {\n        'Ideal': 5,\n        'Premium': 4,\n        'Very Good': 3,\n        'Good': 2,\n        'Fair': 1\n    }\n    dfp.loc[:,\"cut\"] = dfp.loc[:,\"cut\"].map(code)\n    dfp['color']=df['color'].map({'E':1,'D':2,'F':3,'G':4,'H':5,'I':6,'J':7})\n    dfp['clarity']=df['clarity'].map({'VVS1':1,'IF':2,'VVS2':3,'VS1':4,'I1':5,'VS2':6,'SI1':7,'SI2':8})\n    return dfp\ndef binarisation(data):\n    return pd.get_dummies(data)","9951b4f1":"df = encodage(df)\ndf.head()","70e66b18":"df.shape","2e9104ef":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, LabelBinarizer, MinMaxScaler\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV, learning_curve\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.decomposition import PCA\nfrom xgboost import XGBRegressor\nfrom sklearn.tree import DecisionTreeRegressor","5e0d2ea5":"#df.drop(['table', 'depth'], axis=1, inplace=True)\nX = df.drop([\"price\"], axis=1)\ny = df.price","d11c9526":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","68b46bf7":"def mse(y_true, y_pred):\n    mse = mean_squared_error(y_true, y_pred)\n    print(f'MSE = {mse}')\n    print(f'RMSE = {np.sqrt(mse)}')","28f12963":"from sklearn.linear_model import LogisticRegression, LinearRegression","aaae51b2":"model1 = make_pipeline(StandardScaler(), LinearRegression())\nmodel1.fit(X_train, y_train)\ny_pred = model1.predict(X_test)\nmse(y_true=y_test, y_pred=y_pred)","35acad56":"print(f' Xtrain shape : {X_train.shape}')\nprint(f' Xtest shape : {X_test.shape}')","7fa9e1e0":"numerical_features = X_train.select_dtypes(include=[np.number]).columns\ncategorical_features = X_train.select_dtypes(exclude=[np.number]).columns","359dc2ba":"numerical_pipeline = make_pipeline(StandardScaler())\n# categorical_pipeline = make_pipeline(OneHotEncoder(handle_unknown='ignore'))","cb86295d":"transformer = make_column_transformer((numerical_pipeline, numerical_features))","7eb7ba2e":"rf_reg = RandomForestRegressor(random_state=0, max_depth=8)\nxgb_reg = XGBRegressor(random_state=0)\nsvm = SVR()","67822ede":"models = {\n    \"Random Forest\": rf_reg,\n    \"XGBRegressor\": xgb_reg\n}","37c901d0":"for name,model in models.items():\n    m = make_pipeline(transformer, model)\n    N, train_score, val_score = learning_curve(m, X_train, y_train, cv=5, scoring='neg_mean_squared_error', error_score='raise')\n    print(f'{name} : {np.sqrt(-1 * val_score.mean(axis=1))}')\n    plt.figure(figsize=(10,8))\n    plt.plot(N, np.sqrt(-1 * train_score.mean(axis=1)), label=\"train_score\")\n    plt.plot(N, np.sqrt(-1 * val_score.mean(axis=1)), label= \"val_score\")\n    plt.legend()","1f6218ed":"param_grid = {\n        'xgbregressor__n_estimators': [100, 300, 500, 600, 800, 1000],\n        'xgbregressor__learning_rate': [0.01, 0.02, 0.05, 0.1],\n        'xgbregressor__colsample_bytree': [0.4, 0.45, 0.5],\n        'xgbregressor__reg_lambda': [0.6, 0.8, 0.85, 0.9]\n}\n\ngrid = GridSearchCV(model, param_grid, cv=4, return_train_score=True, scoring=\"neg_mean_squared_error\")","e08fdc34":"grid.fit(X_train, y_train)","ee0c9cac":"xgb_reg = XGBRegressor(random_state=0, colsample_bytree=0.4603,\n                             learning_rate=0.05, max_depth=5, \n                             min_child_weight=1.7817, n_estimators=600,\n                             reg_alpha=0.6640, reg_lambda=0.8571)\nmodel = make_pipeline(transformer, PolynomialFeatures(degree=2), xgb_reg)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nmse(y_test, y_pred)","4480684a":"# Diamonds price prediction\n\n*Task : Predict diamonds price*","745bdc29":"- on peut deja voir les intepretation faites pendant l'EDA","1bd03e41":"le XGBRegressor est beaucoup plus promoteur\n\n# optimisation de XGB Regressor avec GridSearchCV","846139d7":"* tout comme le carat, le prix du diamant est aussi proportinnel \u00e0 x, y, et z","7e77103c":"## fonction pour calculer le MSE et le RMSE","98e342ff":"*Remarque*\n- nos variables numeriques contiennent beaucoup de outliers ( carat, depth,x, y, z)\n- on peut voir que la target variables (price) est tr\u00e8s correl\u00e9 avec  carat, x, y,z variables","9bd5f8f8":"## 2- Clarity","c4df8e66":"## Variables Numeriques","df8658c4":"Le dataset ne contient pas de valeurs manquantes","05d6ce0d":"### 2- x (y, z)","53f991cc":"## premier model avec une regression lineaire","92b17651":"*on peut mieux observer les differentes correlation*\n- le prix du diament est proportionnel au nombre de carat, egalement \u00e0 x, y, z","62534b29":"## 3- Color","63b6081a":"### le prix du diamant est proportionnel a son nombre de carat\n- plus les nombre de carat est \u00e9l\u00e9v\u00e9s plus le prix du diamant augmente","f23d510e":"# suppression des outliers","32828140":"- on remarque la qualit\u00e9 de coupure n'a pas une tres grande influence sur le prix du diamant\n- on remarque aussi la presence de beaucoup de outliers","1a7cada4":"## Exploration supplementaire des variables numerique\n  ### Discretisation des variables","84a2e078":"# EDA (Exploratory Data Analysis)","059ab150":"*notre Dataset contient 53940 lines et 10 colonnes*","54736b7b":"## distribution de la target variables en fontion des variables catecorielles","056b3297":"# utilisation des methodes d'ensemble","88fad72b":"### 1- carat","86deed00":"# Model","d1e5e1ff":"# features engeenring","a7ac5383":"- 1. le prix du diamant est relativement bas lorsque clarity est \u00e0 IF, VVS1, VVS2\n- 2. la moyenne du prix du diamant augmente legerement pour les autres clarity\n- 3. ceci ne donne pas trop d'information sur le prix du diamant","8b95d09a":"### Apres Optimisation avec GridSearchCv","537a4bf0":"on constate que la profondeur du diamant n'a pas un impact sur son prix","ff3b4569":"- tout comme pour la variable clarity, cut, la variables color n'est pas assez informartif quant au prix du diamand\n- on note tout de meme que le prix du diamant est un peu plus \u00e9l\u00e9v\u00e9 lorsque la couleur les I,J ou H","530118cb":"### 3- Depth","914e43d8":"## Categorical Variables","7b4a7ae0":"## 1- Cut","a21017cb":"## Preprocessing"}}