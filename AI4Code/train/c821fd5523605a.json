{"cell_type":{"bc74b4dd":"code","53aa3936":"code","bb1ebd61":"code","db23ad90":"code","26da324d":"code","ac02665d":"code","09b47f2c":"code","a100d877":"code","c9403a28":"code","92d23fdd":"code","c567506d":"code","26a64012":"code","19e60815":"code","6b65eaeb":"code","54dc1b73":"code","2d0e76b2":"code","952a3e43":"code","be89ef09":"code","aaab79cd":"code","788c0771":"code","3a666116":"code","f666f0e9":"code","59f9f3f2":"code","afc369a0":"code","8f2af746":"code","e4bb9717":"code","d3972a4d":"code","81aee97a":"code","94f14f48":"code","6fa660b8":"code","d5b901db":"code","ee357fe9":"code","cde152f9":"code","9ad26ceb":"code","7aa80dd7":"code","eba4f795":"code","4d237292":"code","2961169e":"code","61fbd8c7":"code","10d23e2a":"code","5158b6cd":"code","426f054a":"code","47f4bcf6":"code","0dab6dde":"code","6a08d687":"code","40957963":"code","f96a95b5":"code","f4e280ab":"code","1c24d3e1":"code","a57829b5":"code","d51a0d71":"code","b7c7f2f4":"code","b5263e56":"code","57164ae4":"code","467895e5":"code","885ca9c6":"code","6b32b384":"code","c476bfee":"code","031d52b6":"code","0433dc12":"code","e60f1d53":"code","fdcbbbea":"code","05f0de1a":"code","9e6ea8f6":"code","2f5da9b4":"code","9239049a":"code","4ec12c8f":"code","30890951":"code","c55215d1":"code","69c26377":"code","97b1ee73":"code","72f231e8":"code","e92a1612":"code","f3e772a0":"code","510357fe":"code","8a0c8cca":"code","bd5a381e":"code","9e5fd5db":"code","2db2cd03":"code","ecc69844":"code","3f27735a":"code","d5042184":"code","5e25eff7":"code","30cb98c6":"code","7d6371e5":"code","359394fd":"code","b01b94e3":"code","d94b76e2":"code","d8252f2b":"code","55583f15":"code","9e00a4b2":"code","076d7e83":"code","4d280b4b":"code","19a24090":"code","3e81c37c":"code","074186d8":"code","86e8ca26":"code","a7a2642e":"code","f45357c8":"code","fab02072":"code","ee662396":"code","64337a5f":"code","c4c69d26":"code","6f569c5b":"code","b9c4813d":"code","a693cc08":"code","8b16d7c4":"code","1bea2c63":"code","bb849463":"code","808d4cb5":"code","3416e814":"code","0681eb74":"code","25b4646f":"code","03bd2530":"code","32809879":"markdown","f55a7645":"markdown","92d6de88":"markdown","1b63c836":"markdown","048c241d":"markdown","d0dbbf9a":"markdown","64bdd95f":"markdown","1dea5a6a":"markdown","638171a1":"markdown","1010c97e":"markdown","809c2ebd":"markdown","4b0794f1":"markdown","1767fd87":"markdown","0857ae76":"markdown","fa1c2c4f":"markdown","e6ead371":"markdown","8e7c83ab":"markdown","88da3e49":"markdown","9613b542":"markdown","6d9d77ac":"markdown","2df69c93":"markdown","32b32d76":"markdown","3234d36e":"markdown","63dc1950":"markdown","20009084":"markdown","06360b07":"markdown","45ca4ecb":"markdown","db342b23":"markdown","f99b35bb":"markdown","769efb95":"markdown","d92483cf":"markdown","685ebebc":"markdown","23c7bb2e":"markdown","aee1c1cb":"markdown","d30174b0":"markdown","087f15cc":"markdown","547c4ac6":"markdown","8c32a35e":"markdown","643397a5":"markdown","918a14f6":"markdown","1cf43265":"markdown","5bd177b3":"markdown","79655867":"markdown","846427ba":"markdown","26600385":"markdown","3f2d5b23":"markdown","ae810a1f":"markdown","7499dde4":"markdown","c5587c99":"markdown","c9fe910b":"markdown","195a5b71":"markdown","03c93c33":"markdown","8efd7af5":"markdown","ba80e520":"markdown","12377780":"markdown","1dbce3b1":"markdown","83172ec7":"markdown","a3f0fd18":"markdown","cb7e7d40":"markdown","dc017824":"markdown","64e35065":"markdown","83ee11dc":"markdown","c4020b36":"markdown","dc5c98e4":"markdown","3731f44c":"markdown","0e433181":"markdown","45e3e30b":"markdown","76456518":"markdown","de59c68a":"markdown","336cbe7e":"markdown","c864380d":"markdown"},"source":{"bc74b4dd":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport networkx as nx\nimport random\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score,roc_curve,precision_recall_curve,auc,average_precision_score,accuracy_score\n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))\n\npd.set_option(\"max_colwidth\",1000000)\npd.set_option('max_columns', 15000)","53aa3936":"# Read dataset\nsurvey_2019 = pd.read_csv(r'..\/input\/developer_survey_2019\/survey_results_public.csv')\nschema = pd.read_csv(r'..\/input\/developer_survey_2019\/survey_results_schema.csv')","bb1ebd61":"survey_2019.shape","db23ad90":"survey_2019.info()","26da324d":"survey_2019.describe()","ac02665d":"survey_2019.columns[survey_2019.isnull().mean()==0]","09b47f2c":"survey_2019.isnull().mean().sort_values(ascending=False)","a100d877":"# List all possible role\nsurvey_2019['DevType'].value_counts(dropna=False)","c9403a28":"# Check any missing DevType\nnp.sum(survey_2019['DevType'].isnull())","92d23fdd":"# The transpose data set should have 88883-7548=81335 observations.\ndf = pd.get_dummies(survey_2019['DevType'].str.split(';', expand=True)\n   .stack()\n   ).sum(level=0)\ndf.shape","c567506d":"df.head()","26a64012":"fig, ax = plt.subplots()\nfig.set_size_inches(10, 10)\nplt.title(\"Correlation of Developer\")\nax = sns.heatmap(df.corr(),vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","19e60815":"# Counter the number of developer who is a data scientist and a front-end or full-stack developer\nnum1 = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)\n           & (survey_2019['DevType'].str.contains(\"front-end\",na = False)\n           | survey_2019['DevType'].str.contains(\"full-stack\",na = False))].shape[0]\n# Counter the number of developer who is a data scientist\nnum2 = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)].shape[0]\nprint(num1)\nprint(num2)\nprint(num1\/num2)","6b65eaeb":"# Count the number of developer who is a front-end or full-stack developer\nnum3 = survey_2019[survey_2019['DevType'].str.contains(\"front-end\",na = False)\n           | survey_2019['DevType'].str.contains(\"full-stack\",na = False)].shape[0]\nprint(num3)\nprint(num2\/num3)","54dc1b73":"# Divide the data set into 3 subset and check the number of record for each group\nnon_data_scientist = survey_2019[~survey_2019['DevType'].str.contains(\"Data scientist\",na = False)]\nmixed_data_scientist = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)\n                                  & (survey_2019['DevType']!='Data scientist or machine learning specialist')]\npure_data_scientist = survey_2019[survey_2019['DevType']=='Data scientist or machine learning specialist']\nprint(non_data_scientist.shape[0])\nprint(mixed_data_scientist.shape[0])\nprint(pure_data_scientist.shape[0])","2d0e76b2":"# Define a function to show the top feature for each group.\ndef total_count(df, col1):\n    '''\n    INPUT:\n    df - the pandas dataframe you want to search\n    col1 - the column name you want to look through\n    \n    OUTPUT:\n    new_df - a dataframe shows the percentage account for the total observation. \n    '''\n    new_df = df[col1].str.split(';', expand=True).stack().value_counts(dropna=False).reset_index()\n    new_df.rename(columns={0: 'count'}, inplace=True)\n    new_df['percentage'] = new_df['count']\/np.sum(df[col1].notnull())\n    return new_df\n    ","952a3e43":"total_count(non_data_scientist,'LanguageWorkedWith')","be89ef09":"def barplot_group(col1,width=20,height=8):\n    '''\n    INPUT\n    col1 - column name you want to analyze\n    width - width of the graph\n    height -height of the graph\n    \n    OUTPUT\n    output the a barplot graph showing percentage of column accounting for the total by each group\n    '''\n    \n    df1 = total_count(non_data_scientist,col1)\n    df2 = total_count(mixed_data_scientist,col1)\n    df3 = total_count(pure_data_scientist,col1)\n    df1['role'] = 'non ds'\n    df2['role'] = 'mixed ds'\n    df3['role'] = 'pure ds'\n    df = pd.concat([df1,df2,df3])\n \n    fig, ax = plt.subplots()\n    fig.set_size_inches(width, height)\n    ax = sns.barplot(x=\"index\", y=\"percentage\", hue=\"role\", data=df)\n    plt.legend(loc=1, prop={'size': 20})","aaab79cd":"barplot_group('LanguageWorkedWith',30,8)\nplt.title(\"Language worked with\")","788c0771":"barplot_group('DatabaseWorkedWith')","3a666116":"barplot_group('PlatformWorkedWith')","f666f0e9":"barplot_group('WebFrameWorkedWith')","59f9f3f2":"barplot_group('MiscTechWorkedWith')","afc369a0":"barplot_group('DevEnviron',30,8)","8f2af746":"barplot_group('OpSys')","e4bb9717":"# Explore the pure data scientist group\n# data_scientist = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)]\n\n# Gather the technology variables\ntemp = pure_data_scientist[['LanguageWorkedWith'\n                                ,'DatabaseWorkedWith'\n                                ,'PlatformWorkedWith'\n                                ,'WebFrameWorkedWith'\n                                ,'MiscTechWorkedWith'\n                                ,'DevEnviron'\n                                ]]\n\n# Create a tech combining all technologies into one variable.\ntemp['tech'] = temp['LanguageWorkedWith'].map(str)+\";\"+temp['DatabaseWorkedWith'].map(str)+\";\"+temp['PlatformWorkedWith'].map(str)+\";\"+temp['WebFrameWorkedWith'].map(str)+\";\"+temp['MiscTechWorkedWith'].map(str)+\";\"+temp['DevEnviron'].map(str)\n\n# Transpose tech to build a one hot matrix \ndf = pd.get_dummies(temp['tech'].str.split(';', expand=True)\n   .stack()\n   ).sum(level=0)\n\n# drop the nan column\ndf = df.drop(columns=['nan'])\n\n# Convert the value to integer.\ndf_asint = df.astype(int)\n\n# Create co-occurrence matrix\ncoocc = df_asint.T.dot(df_asint)\ncoocc","d3972a4d":"# networkx time              \n# create edges with weight, and a note list\nedge_list = []\nnode_list = []\nfor index, row in coocc.iterrows():\n    i = 0\n    for col in row:\n        weight = float(col)\/df.shape[0]\n        \n        if weight >=0.2:    # ignore weak weight.\n            \n            if index != coocc.columns[i]:\n                edge_list.append((index, coocc.columns[i], weight))\n            \n            #create a note list\n            if index == coocc.columns[i]:\n                node_list.append((index, weight))\n        i += 1\n","81aee97a":"# networkx graph\nG = nx.Graph()\nfor i in sorted(node_list):\n    G.add_node(i[0], size = i[1])\nG.add_weighted_edges_from(edge_list)\n\n# create a list for edges width.\ntest = nx.get_edge_attributes(G, 'weight')\nedge_width = []\nfor i in nx.edges(G):\n    for x in iter(test.keys()):\n        if i[0] == x[0] and i[1] == x[1]:\n            edge_width.append(test[x])","94f14f48":"plt.subplots(figsize=(14,14))\nnode_scalar = 5000\nwidth_scalar = 10\nsizes = [x[1]*node_scalar for x in node_list]\nwidths = [x*width_scalar for x in edge_width]\n\n#draw the graph\npos = nx.spring_layout(G, k=0.4, iterations=15,seed=1234)\n\nnx.draw(G, pos, with_labels=True, font_size = 8, font_weight = 'bold', \n        node_size = sizes, width = widths,alpha=0.6,edge_color=\"green\")\nplt.title(\"Data Science Tool Relationship Map\")","6fa660b8":"barplot_group('EdLevel',50,8)","d5b901db":"barplot_group('UndergradMajor',50,10)","ee357fe9":"survey_2019['UndergradMajor'].value_counts(dropna=False)","cde152f9":"# Check the number of data scientist with social science background.\ndf = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)\n                                  & (survey_2019['UndergradMajor']=='A social science (ex. anthropology, psychology, political science)')]\ndf.shape[0]","9ad26ceb":"# What country do they reside in?\ndf['Country'].value_counts(dropna=False)","7aa80dd7":"# The percentage of data scientists who reside in US. \ndata_scientist = pd.concat([pure_data_scientist,mixed_data_scientist])\nprint(data_scientist[data_scientist['Country']=='United States'].shape[0]\/data_scientist.shape[0])","eba4f795":"# Distribution of undergraduate major of data scientist\ntotal_count(data_scientist,'UndergradMajor')","4d237292":"total_count(data_scientist,'EduOther')","2961169e":"total_count(data_scientist,'EdLevel')","61fbd8c7":"# The percentage of data scientists who reside in US grouped by undergraduate major.\ndf = data_scientist['UndergradMajor'].value_counts(dropna=False).sort_index().reset_index()\ndf1 = data_scientist[data_scientist['Country']=='United States']['UndergradMajor'].value_counts(dropna=False).sort_index().reset_index()\ndf2 = pd.merge(df,df1, on='index')\ndf2['PCT of US'] = df2['UndergradMajor_y']\/df2['UndergradMajor_x']\ndf2","10d23e2a":"survey_2019['EduOther'].value_counts(dropna=False)","5158b6cd":"total_count(non_data_scientist,'EduOther')","426f054a":"barplot_group('EduOther',50,10)","47f4bcf6":"df1 = non_data_scientist[non_data_scientist['Age'].notnull()]\ndf2 = mixed_data_scientist[mixed_data_scientist['Age'].notnull()]\ndf3 = pure_data_scientist[pure_data_scientist['Age'].notnull()]\n\n# density plot of age among 3 groups\nfig, ax = plt.subplots()\nfig.set_size_inches(8, 8)\nsns.distplot(df1[['Age']], hist=False,color='blue',norm_hist=True)\nsns.distplot(df2[['Age']], hist=False,color='red',norm_hist=True)\nsns.distplot(df3[['Age']], hist=False,color='green',norm_hist=True)\n\n","0dab6dde":"fig, ax = plt.subplots()\nfig.set_size_inches(8, 8)\n\n# density plot of age of pure data scientist between residing in US and non-US.\nsns.distplot(df3[df3['Country']=='United States'][['Age']], hist=False,color='green',norm_hist=True)\nsns.distplot(df3[df3['Country']!='United States'][['Age']], hist=False,color='red',norm_hist=True)","6a08d687":"survey_2019['CurrencySymbol'].value_counts(dropna=False)","40957963":"# Salaries among 3 groups \n\n\ndf1 = non_data_scientist[non_data_scientist['ConvertedComp'].notnull()]\ndf2 = mixed_data_scientist[mixed_data_scientist['ConvertedComp'].notnull()]\ndf3 = pure_data_scientist[pure_data_scientist['ConvertedComp'].notnull()]\nfig, ax = plt.subplots()\nfig.set_size_inches(8, 8)\nsns.distplot(df1[['ConvertedComp']], hist=False,color='blue',norm_hist=True)\nsns.distplot(df2[['ConvertedComp']], hist=False,color='red',norm_hist=True)\nsns.distplot(df3[['ConvertedComp']], hist=False,color='green',norm_hist=True)","f96a95b5":"# Salary vs Age\ndf = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)]\ndf['US'] = df['Country'].apply(lambda x: 1 if x=='United States' else 0)\n\n\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 10)\nax = sns.scatterplot(x=\"ConvertedComp\", y=\"Age\", data=df, hue='US',alpha=0.6)","f4e280ab":"# Zoom in the compensations less than 500000 USD.\n# Just ignore the big salaries, focus on common and reasonable salary.\ndf1 = df[df[\"ConvertedComp\"]<=500000]\n\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 10)\nax = sns.scatterplot(x=\"ConvertedComp\", y=\"Age\", data=df1, hue='US',alpha=0.8)","1c24d3e1":"# Filter the data scientist in the US.\n\ndf2 = pd.concat([pure_data_scientist,mixed_data_scientist])\ndf2 = df2[(df2[\"ConvertedComp\"]<=500000) & (df2[\"Country\"]=='United States')]\n\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 10)\nax = sns.scatterplot(x=\"ConvertedComp\", y=\"Age\", data=df2, color=\"#f28e2b\")\nax = sns.regplot(x=\"ConvertedComp\", y=\"Age\", data=df2,color=\"#f28e2b\")","a57829b5":"# Just curious whether US data scientist has any dependent.\ndf = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)]\ndf = df[df[\"Country\"]=='United States']\n\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 10)\nax = sns.boxplot(x=\"Dependents\",y=\"Age\" , data=df)","d51a0d71":"# Employment vs salary\n\nfig, ax = plt.subplots()\nfig.set_size_inches(20, 8)\nax = sns.boxplot(x=\"Employment\",y=\"CompTotal\" , data=df2)","b7c7f2f4":"# OrgSize vs salary\n\nfig, ax = plt.subplots()\nfig.set_size_inches(20, 8)\nax = sns.boxplot(x=\"OrgSize\",y=\"CompTotal\" , data=df2)","b5263e56":"# df = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)]\n# df = df[(df[\"Country\"]=='United States')]\n# df['CompTotal1'] = df.apply(lambda row : min(row['CompTotal'],row['ConvertedComp']),axis=1)\n\n# fig, ax = plt.subplots()\n# fig.set_size_inches(20, 20)\n# ax = sns.scatterplot(x='CompTotal1', y=\"Age\", data=df)","57164ae4":"# df = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)]\n# df = df[(df[\"Country\"]=='United States')]\n# df['CompTotal1'] = df.apply(lambda row : min(row['CompTotal'],row['ConvertedComp']),axis=1)\n# df = df[df['CompTotal1'] <600000] \n\n# fig, ax = plt.subplots()\n# fig.set_size_inches(20, 20)\n# ax = sns.scatterplot(x='CompTotal1', y=\"Age\", data=df)","467895e5":"# get the data first\ndf = survey_2019[survey_2019['DevType'].str.contains(\"Data scientist\",na = False)]\ndf = df[df[\"Country\"]=='United States']\ndf.shape","885ca9c6":"# Check the statistics of numeric variables, might remove some outliers.\ndf.describe()","6b32b384":"# Check CompTotal vs ConvertedComp, see which salary makes sense.\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 10)\nax = sns.scatterplot(x='CompTotal', y=\"ConvertedComp\", data=df)","c476bfee":"# if we set CompTotal<700000, will filter out most abnormal salaries.\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 10)\nax = sns.scatterplot(x='CompTotal', y=\"ConvertedComp\", data=df[df[\"CompTotal\"]<700000])","031d52b6":"df['Employment'].value_counts(dropna=False)","0433dc12":"# Remove records with missing CompTotal and outliers;\ndf = df[(df['CompTotal'].notnull()) & (df['CompTotal']<700000) & (df['CompTotal']>0)]\n\n# Exclude the unemployed.\ndf = df[df['Employment']!='Not employed, but looking for work']\n\n# Drop ConvertedComp, Respondent, Country, DevType, CurrencySymbol,CurrencyDesc\ndf = df.drop(['ConvertedComp', 'Respondent', 'Country', 'DevType', 'CurrencySymbol','CurrencyDesc'],axis=1)\ndf.shape","e60f1d53":"# Retrieve the categorical variables\ncat_vars_int = df.select_dtypes(include=['object']).copy().columns\nlen(cat_vars_int)","fdcbbbea":"# Split and transpose the categorical variable into one-hot columns.\nfor var in  cat_vars_int:\n    # for each cat add dummy var, drop original column\n    df = pd.concat([df.drop(var, axis=1), df[var].str.get_dummies(sep=';').rename(lambda x: var+'_' + x, axis='columns')], axis=1)\n\ndf.describe()","05f0de1a":"df.isnull().mean().sort_values(ascending=False)","9e6ea8f6":"# Impute missing values with column median\n# I choose median because the distributions are not normal\n# No needed to impute the missing value for the one-hot columns\ndf['CodeRevHrs'] = df['CodeRevHrs'].fillna(df['CodeRevHrs'].median())\ndf['Age'] = df['Age'].fillna(df['Age'].median())\ndf['WorkWeekHrs'] = df['WorkWeekHrs'].fillna(df['WorkWeekHrs'].median())","2f5da9b4":"# An option reducing features to prevent overfitting?\n# df = df.iloc[:, np.where((X.sum() > 10) == True)[0]]\n# df.shape","9239049a":"# Plot the distribution of numeric variables, see if any skewed distribution that needs to be normailized. \n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\nplt.tight_layout(w_pad=2.0, h_pad=5.0)\n\nplt.subplot(2,2,1)\nplt.xlabel('CompTotal')\np1 = sns.distplot(df[['CompTotal']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,2)\nplt.xlabel('WorkWeekHrs')\np2 = sns.distplot(df[['WorkWeekHrs']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,3)\nplt.xlabel('CodeRevHrs')\np3 = sns.distplot(df[['CodeRevHrs']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,4)\nplt.xlabel('Age')\np4 = sns.distplot(df[['Age']], hist=False,color='red',norm_hist=True)","4ec12c8f":"# Use logarithm function to transform the numeric columns\n# df['CompTotal_log'] = np.log(df['CompTotal']+100000)\ndf['WorkWeekHrs_log'] =np.log(df['WorkWeekHrs']+100)\ndf['CodeRevHrs_log'] = np.log(df['CodeRevHrs']-30)\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\nplt.tight_layout(w_pad=2.0, h_pad=5.0)\n\n# plt.subplot(2,2,1)\n# plt.xlabel('CompTotal_log')\n# p1 = sns.distplot(df[['CompTotal_log']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,2)\nplt.xlabel('WorkWeekHrs_log')\np2 = sns.distplot(df[['WorkWeekHrs_log']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,3)\nplt.xlabel('CodeRevHrs_log')\np3 = sns.distplot(df[['CodeRevHrs_log']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,4)\nplt.xlabel('Age')\np4 = sns.distplot(df[['Age']], hist=False,color='red',norm_hist=True)","30890951":"# Drop the original numeric columns\ndf = df.drop(['WorkWeekHrs','CodeRevHrs'],axis=1)","c55215d1":"# Split the data into train and test\ny = df['CompTotal'].values\nX = df.drop(['CompTotal'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0)","69c26377":"# Xgboost modelling\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndvalid = xgb.DMatrix(X_test, label=y_test)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]","97b1ee73":"# Set the parameters\n# Set the regularization lambda to 100000\n# Set the evalutaion metric as rmse (root mean square error)\n# Set the early stopping rounds to 5\n\nevals_result = {}\n\n\nxgb_pars = {'min_child_weight': 5, 'eta':0.5, 'colsample_bytree': 0.8, \n            'max_depth': 10,\n'subsample': 0.8, 'lambda': 100000, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n'eval_metric': 'rmse', 'objective': 'reg:linear','seed':1234}\n\n# xgb_pars = {'lambda': 100000, 'booster' : 'gbtree', \n# 'eval_metric': 'rmse', 'objective': 'reg:linear','seed':1234}\n\nmodel = xgb.train(xgb_pars, dtrain, 10000000, watchlist, early_stopping_rounds=5,\n      maximize=False, verbose_eval=1000, evals_result=evals_result)\nprint('Modeling RMSE %.5f' % model.best_score)","72f231e8":"# Model evaluation graph\nplt.plot(evals_result['train']['rmse'], linewidth=2, label='Train')\nplt.plot(evals_result['valid']['rmse'], linewidth=2, label='Test')\nplt.legend(loc='upper right')\nplt.title('Model RMSE')\nplt.ylabel('rmse')\nplt.xlabel('Epoch')\nplt.show()","e92a1612":"# confusion matrix\ndtest = xgb.DMatrix(X_test)\ny_pred = model.predict(dtest)\n\nfig, ax = plt.subplots()\nfig.set_size_inches(8, 8)\n\nax = sns.scatterplot(x=y_pred,y=y_test)\nplt.title('Residual plot');\nplt.xlabel('predicted');\nplt.ylabel('actual'); ","f3e772a0":"# histogram of residual\nsns.distplot(y_pred-y_test)","510357fe":"# Display the feature importance.\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 10)\nxgb.plot_importance(model, max_num_features=28, ax=ax)","8a0c8cca":"# Plot WorkWeekHrs vs CompTotal\n# Check the tendency\nfig, ax = plt.subplots()\nfig.set_size_inches(10, 10)\n\ndf['WorkWeekHrs'] = np.exp(df['WorkWeekHrs_log'])-100\n# ax = sns.boxplot(y='CompTotal', x=\"MgrMoney_Not sure\", data=df[df[\"CompTotal\"]<10000000])\n# ax = sns.boxplot(y='CompTotal', x=\"OrgSize_10,000 or more employees\", data=df[df[\"CompTotal\"]<10000000])\nax = sns.scatterplot( x=\"WorkWeekHrs\",y='CompTotal', data=df[df[\"CompTotal\"]<10000000])\nax = sns.regplot(x=\"WorkWeekHrs\", y=\"CompTotal\", data=df[df[\"CompTotal\"]<10000000])","bd5a381e":"# model = xgb.XGBRegressor(colsample_bytree=0.4,\n#                  gamma=0,                 \n#                  learning_rate=0.07,\n#                  max_depth=3,\n#                  min_child_weight=1.5,\n#                  n_estimators=10000,                                                                    \n#                  reg_alpha=0.75,\n#                  reg_lambda=0.45,\n#                  subsample=0.6,\n#                  seed=42,\n#                  verbose=10) ","9e5fd5db":"# model.fit(X_train,y_train)","2db2cd03":"# predictions = model.predict(X_test)\n# # print(explained_variance_score(predictions,y_test))\n# from sklearn.metrics import mean_absolute_error\n# print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, y_test)))","ecc69844":"# Retrieve the character variables.\n# df = survey_2019[survey_2019['Country']=='United States']\ndf = survey_2019\ncat_vars_int = survey_2019.select_dtypes(include=['object']).copy().columns\nlen(cat_vars_int)\ndf.shape","3f27735a":"# Again split and transpose the categorical variable into one-hot columns.\nfor var in  cat_vars_int:\n    # for each cat add dummy var, drop original column\n    df = pd.concat([df.drop(var, axis=1), df[var].str.get_dummies(sep=';').rename(lambda x: var+'_' + x, axis='columns')], axis=1)\n\ndf.describe()","d5042184":"df.shape","5e25eff7":"# Drop Respondent and CompTotal. Comptotal is the salary before curreny conversion \n# It does not provide valuable information unless we focus on one country.\ndf = df.drop(['Respondent','CompTotal'],axis=1)","30cb98c6":"# Check the ratio of data scientist and non data scientist\nsns.countplot(df['DevType_Data scientist or machine learning specialist'])","7d6371e5":"# Impute missing values with column median\n# The distribution of these variables are not normal\n# so I use column median rather than column mean.\n# No needed to impute the one-hot columns.\ndf['CodeRevHrs'] = df['CodeRevHrs'].fillna(df['CodeRevHrs'].median())\ndf['Age'] = df['Age'].fillna(df['Age'].median())\ndf['WorkWeekHrs'] = df['WorkWeekHrs'].fillna(df['WorkWeekHrs'].median())\ndf['ConvertedComp'] = df['ConvertedComp'].fillna(df['ConvertedComp'].median())","359394fd":"# See if the numeric variables need to be normalized.\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\nplt.tight_layout(w_pad=2.0, h_pad=5.0)\n\nplt.subplot(2,2,1)\nplt.xlabel('ConvertedComp')\np1 = sns.distplot(df[['ConvertedComp']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,2)\nplt.xlabel('WorkWeekHrs')\np2 = sns.distplot(df[['WorkWeekHrs']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,3)\nplt.xlabel('CodeRevHrs')\np3 = sns.distplot(df[['CodeRevHrs']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,4)\nplt.xlabel('Age')\np4 = sns.distplot(df[['Age']], hist=False,color='red',norm_hist=True)","b01b94e3":"# Use logarithm function to transform the numeric columns\ndf['ConvertedComp_log'] = np.log(df['ConvertedComp']-90000)\ndf['WorkWeekHrs_log'] = np.log(df['WorkWeekHrs']-70)\ndf['CodeRevHrs_log'] = np.log(df['CodeRevHrs']-30)\ndf['Age_log'] = np.log(df['Age']+30)\n\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\nplt.tight_layout(w_pad=2.0, h_pad=5.0)\n\nplt.subplot(2,2,1)\nplt.xlabel('ConvertedComp_log')\np1 = sns.distplot(df[['ConvertedComp_log']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,2)\nplt.xlabel('WorkWeekHrs_log')\np2 = sns.distplot(df[['WorkWeekHrs_log']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,3)\nplt.xlabel('CodeRevHrs_log')\np3 = sns.distplot(df[['CodeRevHrs_log']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,4)\nplt.xlabel('Age_log')\np4 = sns.distplot(df[['Age_log']], hist=False,color='red',norm_hist=True)","d94b76e2":"# Split data set into response vector and feature matrix.\ny = df['DevType_Data scientist or machine learning specialist'].values\nX = df.drop(['DevType_Data scientist or machine learning specialist'], axis=1)","d8252f2b":"# Drop original numeric columns. \n# We already know that researcher and data engineer might share the role of data scientist\n# Drop DevType as it does not provide the information why data scientist is distinct. \n\nX = X.drop([col for col in X.columns if 'DevType_' in col],axis=1)\nX = X.drop(['CodeRevHrs','ConvertedComp','WorkWeekHrs','Age'],axis=1)\nX.shape","55583f15":"# Split X y into training set and test set.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0,stratify=y)","9e00a4b2":"# Define an Xgboost classifer\n# Using AUPRC as the evaluation metric which is more sensitive to the minor class \n# As we know the population of data scientist is just 1\/8 of other developers\n\nmodel = xgb.XGBClassifier(\n    learning_rate =0.1, n_estimators=1000,\n    gamma=0,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective= 'binary:logistic', \n    nthread=4,\n    scale_pos_weight=7,\n    seed=27,\n    max_depth = 5,\n    min_child_weight = 5\n)\n\ndef evalauc(preds, dtrain):\n    labels = dtrain.get_label()\n    precision, recall, thresholds = precision_recall_curve(labels, preds)\n    area = auc(recall, precision)\n    return 'AUPRC', -area\n\n\nmodel.fit(X_train, y_train,\n          eval_metric=evalauc,\n          eval_set=[(X_train, y_train), (X_test, y_test)],\n          early_stopping_rounds=5,\n         verbose=True)","076d7e83":"# See the prediction result\npredict = model.predict(X_test)\nprint(classification_report(y_test, predict))\nprint(confusion_matrix(y_test,predict))\nprint(\"Accuracy: \")\nprint(accuracy_score(y_test,predict))","4d280b4b":"fpr, tpr, thresholds = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1])\nauprc = average_precision_score(y_test, predict)\n\nplt.plot(fpr, tpr, lw=1, label='AUPRC = %0.2f'%(auprc))\nplt.plot([0, 1], [0, 1], '--k', lw=1)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('XGBOOST AUPRC')\nplt.legend(loc=\"lower right\", frameon = True).get_frame().set_edgecolor('black')","19a24090":"fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\nroc_auc = roc_auc_score(y_test, predict)\n\nplt.plot(fpr, tpr, lw=1, label='AUC = %0.2f'%(roc_auc))\nplt.plot([0, 1], [0, 1], '--k', lw=1)\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('XGBOOST ROC')\nplt.legend(loc=\"lower right\", frameon = True).get_frame().set_edgecolor('black')","3e81c37c":"feature_name=X.columns.tolist()\n#feature_name.remove('DevType_Data scientist or machine learning specialist')\ndtrain = xgb.DMatrix(X, label=y,feature_names=feature_name)","074186d8":"# model.get_booster().get_score().items()","86e8ca26":"# mapper = {'f{0}'.format(i): v for i, v in enumerate(dtrain.feature_names)}\n# mapped = { mapper[k]: v for k, v in model.get_booster().get_score().items()}\n\nfig,ax  =  plt.subplots (figsize=(10, 5))\nxgb.plot_importance(model, max_num_features=20,ax=ax)\nplt.show()","a7a2642e":"\ndf.groupby(['Employment_Not employed, and not looking for work', 'DevType_Data scientist or machine learning specialist']).size()\n","f45357c8":"# Retrieve the character variables.\n# df = survey_2019[survey_2019['Country']=='United States']\ndf = pd.concat([pure_data_scientist,non_data_scientist])\ncat_vars_int = df.select_dtypes(include=['object']).copy().columns\nlen(cat_vars_int)\ndf.shape","fab02072":"# Again split and transpose the categorical variable into one-hot columns.\nfor var in  cat_vars_int:\n    # for each cat add dummy var, drop original column\n    df = pd.concat([df.drop(var, axis=1), df[var].str.get_dummies(sep=';').rename(lambda x: var+'_' + x, axis='columns')], axis=1)\n\ndf.describe()","ee662396":"df.shape","64337a5f":"sns.countplot(df['DevType_Data scientist or machine learning specialist'])","c4c69d26":"np.sum(df['DevType_Data scientist or machine learning specialist'])","6f569c5b":"# Impute missing values with column median\ndf['CodeRevHrs'] = df['CodeRevHrs'].fillna(df['CodeRevHrs'].median())\ndf['Age'] = df['Age'].fillna(df['Age'].median())\ndf['WorkWeekHrs'] = df['WorkWeekHrs'].fillna(df['WorkWeekHrs'].median())\ndf['ConvertedComp'] = df['ConvertedComp'].fillna(df['ConvertedComp'].median())","b9c4813d":"# See if the numeric variables need to be normalized.\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\nplt.tight_layout(w_pad=2.0, h_pad=5.0)\n\nplt.subplot(2,2,1)\nplt.xlabel('ConvertedComp')\np1 = sns.distplot(df[['ConvertedComp']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,2)\nplt.xlabel('WorkWeekHrs')\np2 = sns.distplot(df[['WorkWeekHrs']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,3)\nplt.xlabel('CodeRevHrs')\np3 = sns.distplot(df[['CodeRevHrs']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,4)\nplt.xlabel('Age')\np4 = sns.distplot(df[['Age']], hist=False,color='red',norm_hist=True)","a693cc08":"# Use logarithm function to transform the numeric columns\ndf['ConvertedComp_log'] = np.log(df['ConvertedComp']+1000)\ndf['WorkWeekHrs_log'] = np.log(df['WorkWeekHrs']-70)\ndf['CodeRevHrs_log'] = np.log(df['CodeRevHrs']-30)\ndf['Age_log'] = np.log(df['Age']+30)\n\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\nplt.tight_layout(w_pad=2.0, h_pad=5.0)\n\nplt.subplot(2,2,1)\nplt.xlabel('ConvertedComp_log')\np1 = sns.distplot(df[['ConvertedComp_log']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,2)\nplt.xlabel('WorkWeekHrs_log')\np2 = sns.distplot(df[['WorkWeekHrs_log']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,3)\nplt.xlabel('CodeRevHrs_log')\np3 = sns.distplot(df[['CodeRevHrs_log']], hist=False,color='red',norm_hist=True)\n\nplt.subplot(2,2,4)\nplt.xlabel('Age_log')\np4 = sns.distplot(df[['Age_log']], hist=False,color='red',norm_hist=True)","8b16d7c4":"# Split data set into response vector and feature matrix.\ny = df['DevType_Data scientist or machine learning specialist'].values\nX = df.drop(['DevType_Data scientist or machine learning specialist'], axis=1)","1bea2c63":"X = X.drop(['Respondent','CompTotal'],axis=1)\nX = X.drop([col for col in X.columns if 'DevType_' in col],axis=1)\nX = X.drop(['CodeRevHrs','ConvertedComp','WorkWeekHrs','Age'],axis=1)\nX.shape","bb849463":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=0,stratify=y)","808d4cb5":"model = xgb.XGBClassifier(\n    learning_rate =0.01, n_estimators=1000,\n    gamma=0,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective= 'binary:logistic', \n    nthread=4,\n    scale_pos_weight=100,\n    seed=27,\n    max_depth = 5,\n    min_child_weight = 3\n)\n\ndef evalauc(preds, dtrain):\n    labels = dtrain.get_label()\n    precision, recall, thresholds = precision_recall_curve(labels, preds)\n    area = auc(recall, precision)\n    return 'AUPRC', -area\n\n\nmodel.fit(X_train, y_train,\n          eval_metric=evalauc,\n          eval_set=[(X_train, y_train), (X_test, y_test)],\n          early_stopping_rounds=5,\n         verbose=True)","3416e814":"# See the prediction result\npredict = model.predict(X_test)\nprint(classification_report(y_test, predict))\nprint(confusion_matrix(y_test,predict))\nprint(\"Accuracy: \")\nprint(accuracy_score(y_test,predict))","0681eb74":"fpr, tpr, thresholds = precision_recall_curve(y_test, model.predict_proba(X_test)[:,1])\nauprc = average_precision_score(y_test, predict)\n\nplt.plot(fpr, tpr, lw=1, label='AUPRC = %0.2f'%(auprc))\nplt.plot([0, 1], [0, 1], '--k', lw=1)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('XGBOOST AUPRC')\nplt.legend(loc=\"lower right\", frameon = True).get_frame().set_edgecolor('black')","25b4646f":"fig,ax  =  plt.subplots (figsize=(10, 5))\nxgb.plot_importance(model, max_num_features=20,ax=ax)\nplt.show()","03bd2530":"df.groupby(['DevType_Data scientist or machine learning specialist','MiscTechWorkedWith_TensorFlow']).size()","32809879":"Just have 5 numeric variables, the other variables are all strings. The variable Respondent can be ignored since it's just an ID for each respondent. Take a look the statistic of these 5 numeric variables","f55a7645":"Let's see the the survey question of OpSys: What is the primary operating system in which you work? It indicates the system you are commonly working with including sending emails with Outlook and using MS Office production. Therefore, it's no doubt the result returns Windows as the top operation system. Data scientists prefer Linux then MacOS as we've known they work on Linux mostly. \n\n","92d6de88":"### 5.1 Data understanding and preparation","1b63c836":"<a class=\"anchor\" id=\"3\"><\/a>\n## 3. Q1: What skill and education background data scientists have?\n","048c241d":"#### 3.2.2 Descriptive charts and plots","d0dbbf9a":"<a class=\"anchor\" id=\"4\"><\/a>\n## 4. Q2: What salary does data scientist earn comparing to other developer?\n\n","64bdd95f":"There are two variables about the salary, ConvertedComp and CompTotal. ConvertedComp is USD converted from the CompTotal which is amount of local currency. There is a CurrencySymbol that indicates the type of currency.  ","1dea5a6a":"Theotically they should be aligned, but not all. In the original survey form, there is only a box for compensation. It's possible ConvertedComp is a calculated variable. So I just consider CompTotal and drop ConvertedComp.\n","638171a1":"<a class=\"anchor\" id=\"3.1\"><\/a>\n### 3.1 Data scientist comparing to other developer\n\n#### 3.1.1 Data preparation\n\nIn order to subset the data scientist people. Let's look at the DevType column which describes the role of each developer. The majority of people are \"full-stack developer\", they were allowed to select multiple roles so that I can anticipate data scientist can be a single role or a mixed data scientist who also know other skills.","1010c97e":"#### 3.2.1  Data preparation\n\nTo compare the different skills between data scientist and non data scientist, I would like to divide the developer into 3 groups:\n\n1. non data scientist - who does not identify himself as a data scientist\n2. mixed data scientist - who is a data scientist as well as other role\n3. pure data scientist - who has only one data scientist role\n\nI assume these 3 groups of people have diverse skill distribution, then we know what skill make data scientist different. ","809c2ebd":"We can see that the organization with 10000 or more employees tends to be generous, willing to pay more than others. ","4b0794f1":"That seems not much difference between data scientist and non data scientist. Taught yourself a new language and taking online course are the most suggested education method beyond earning a degree.","1767fd87":"Data scientists in the US have higher salaries than rest of the countries. We also see some abnormal number of population of salary at 1 million and 2 million.","0857ae76":"The graph shows data scientist or machine learning specialist is highly correlated with data or business analyst, data engineer and I missed one, the researcher and scientist also uses data science to do research. The interesting thing is data scientist has negative correlation with front-end and full-stack developer. That means, data scientist would rather work as back-end, but would not play a role as front-end? Let's see how many samples support this view.","fa1c2c4f":"Again, we show the LanguageWorkedWith across 3 group.","e6ead371":"First check the distribution of age among 3 groups. Can we distinguish data scientist with their age?","8e7c83ab":"### 5.2 Modeling","88da3e49":"It seems more than half of social data scientist are from United States. I am curious the portion of US data scientists grouping by different education field.","9613b542":"Non data scientists use MySQL a lot while pure data scientist use PostgreSQL, I think the reason is they have a different working platform. Let's check the platform.","6d9d77ac":"#### 4.3.2 Modeling","2df69c93":"We can check Employment status against salary, perhaps they are correlated.","32b32d76":"#### 3.3.1 Data preparation","3234d36e":"<a class=\"anchor\" id=\"2\"><\/a>\n## 2. Data understanding\n\nThe 2019 Stack Overflow Annual Developer Survey contains nearly 90000 responses fielded from over 170 countries and dependent territories. The survey examines all aspects of the developer experience from career satisfaction and job search to education and opinions on open source software. In this project, I will explore this survey dataset, specially focused on mining the people who identify themself as a data scientist.\n","63dc1950":"#### 4.3.3 Evaluation","20009084":"<a class=\"anchor\" id=\"4.2\"><\/a>\n### 4.2 Salary","06360b07":"Take a look the dimension of the dataset","45ca4ecb":"First, we check the LanguageWorkedWith, see what programming language the developer is using.","db342b23":"I will impute the missing values in the later steps.","f99b35bb":"The top 3 languages for mixed data scientist are Python, SQL and JavaScript. While more than 80% of pure data scientist use Python, SQL and R are also popular. This is so true that if you search \"Python SQL R\" in a job board website, it will return data scientist jobs. Beyond the programming language, we take a look DatabaseWorkedWith, PlatformWorkedWith, WebFrameWorkedWith, MiscTechWorkedWith, DevEnviron, OpSys. These developer tools might differ across 3 group. ","769efb95":"Comparing to other countries, the US accounts for a majority of data scientist who has an undergraduate degree of social science, art or humanities discipline. I wonder if data science recently grows on these fields in the US. Next, take a look the EduOther which shows other education like online course.","d92483cf":"# What you need to know to become a data scientist?\n#### - Data mining from Stack Overflow 2019 Annual Developer Survey.\n\n* [1. Business understanding](#1)\n* [2. Data understanding](#2)\n   + [2.1 Missing value](#2.1)  \n* [3. Q1: What skill and education background data scientists have?](#3)\n   + [3.1 Data scientist comparing to other developer](#3.1)\n   + [3.2 Skills](#3.2)\n   + [3.3 Relationship of skills](#3.3)\n   + [3.4 Education](#3.4)\n* [4. Q2: What salary does data scientist earn comparing to other developer?](#4)\n   + [4.1 Age](#4.1)   \n   + [4.2 Salary](#4.2)   \n   + [4.3 Predict US Salary](#4.3)   \n* [5. Q3: What features make data scientist distnct from other developer?](#5)\n\n","685ebebc":"Check columns without missing value. Just see 3 columns without missing values.","23c7bb2e":"Top 3 developing editors for pure data scientist are Jupyter, PyCharm and RStudio, which is corresponding to what we've found, they use Python and R.","aee1c1cb":" It looks like the data scientists tend to have a higher education degree than non data scientists. The majority of pure data scientists has a master degree, and it seems Ph.Ds are more common in data science. I am interested in what field the data scientist study. Let's look into UndergradMajor.","d30174b0":"<a class=\"anchor\" id=\"3.2\"><\/a>\n### 3.2 Skills","087f15cc":"The classifier does not return a clear bountary between data scientist and non data scientist. I am interested if we remove the mixed data scientist from the training and test data, will the model perform better? Let's do it.","547c4ac6":"Most developers are young between 20 and 40. A few developers is joking almost 100 years old. It looks like a larger portion of younger population for the data scientist.","8c32a35e":"Still, the model is not as good as I anticipate, there are many other developers being classified as data scientist. We can see somehow the top important feature is TensorFlow known by almost 50% of pure data scientist, while part of the non data scientist also know. The most distinct feature seems not to distinguish a data scientist very well. ","643397a5":"<a class=\"anchor\" id=\"2.1\"><\/a>\n### 2.1 Missing values","918a14f6":"It looks like data scientist has a higher salary than other developer.","1cf43265":"<a class=\"anchor\" id=\"4.3\"><\/a>\n### 4.3 Predict US Salary","5bd177b3":"Next we move to analyze the education background of data scientist. First, we look into EdLevel, which shows the highest education level of developers.","79655867":"The question is: What feature affect a data scientist salary? Skill, age, or company size? We already know that who resides in the US usually earns more than other countries. So we focus on analyzing salary within the US. ","846427ba":"It looks like there are multiple abnormal values for these numeric, e.g. Age is 99, WorkWeekHrs is 4850 that is impossible. We should clean these outliers if we need to analyze these variables. I will do it later.","26600385":"<a class=\"anchor\" id=\"3.3\"><\/a>\n### 3.3 Education","3f2d5b23":"### 5.3 Evaluation","ae810a1f":"Check the all column types","7499dde4":"Data scientists use Pandas, Tensorflow, a machine learning library, also Spark, Hadoop and PyTorch. All these tools are based on Python or with a Python access API. No wonder more than 80% of pure data scientists are using Python! I expect that DevEnviron is also correlated.","c5587c99":"<a class=\"anchor\" id=\"4.1\"><\/a>\n### 4.1 Age","c9fe910b":"#### 3.1.2 Descriptive plot","195a5b71":"<a class=\"anchor\" id=\"5\"><\/a>\n## 5. Q3: What features make data scientist distnct from other developer?","03c93c33":"<a class=\"anchor\" id=\"1\"><\/a>\n## 1. Business understanding\n\nData scientist is a very popular job since 2010s. A data scientist job openning will attract hundreds of applicants to submit their resume, I am interested what you should have to become a data scientist, also the key terms that you should add into your resume so you can increase the chance to get a data science job. The goal of this project is to find evidences to understand characteristics of a data scientist in industry. The project attempt to give answers to the following three questions:\n\n1. What skill and education background data scientist has?\n2. What salary does data scientist earn comparing to other developer?\n3. What features make data scientist distnct from other developer?\n\nThe plan is to perform data mining on the data set of 2019 Stack Overflow Developer Survey which can be downloaded from [here](https:\/\/insights.stackoverflow.com\/survey) ","8efd7af5":"The bigger note indicates the larger percentage of pure data scientists who use the tool. It's obvious Python is a core skill for data scientist, it connects to almost all data science tool. It can be concluded that data scientist must know Python as well as learn Python if you want to break into the field.","ba80e520":"We see there is an overfitting issue for the model. The residual is close to normal distribution, we can't say the model is bias. The next job maybe is tuning the model to find better parameters?","12377780":"#### 3.3.2 Descriptive plot","1dbce3b1":"No surprise that most data scientists earn a computer science or engineer degree. There is a large portion of pure data scientist earning a mathematics and statistics degree. I am curious about the people who has social science background. Let's see the data.","83172ec7":"The basic idea to answer this question is to build a classifier model that distinguishes data scientist and non data scentist, then we can dig out the distinct feature by exploring the feature importance of the model.","a3f0fd18":"The transformed data set looks good. Now we can generate a graph indicating the correlation among different roles. i use seaborn package to plot this correlation. ","cb7e7d40":"Now we see that only 42% of the data scientist is also working as front-end or full-stack developer, while only 12% of front-end or full-starck developers are working as data scientist. The negative correlation make senses. ","dc017824":"Linux is the top working platform for every developer, Windows also is a important working platform traditionally. There are recently new platforms such as AWS and Docker.","64e35065":"Non data scientists use JQuery while pure data scientist prefers Flask, which is a Python based web framework. It looks like WebFrameWorkedWith is somewhat correlated with LanguageWorkedWith, as well as they are correlated with MiscTechWorkedWith:","83ee11dc":"Check the columns that have highest percentage of missing values. The BlockchainOrg has most missing values, but still less than 50%.","c4020b36":"The classes are extremely bias.","dc5c98e4":"We can see Age and Working hour are important features, data scientist who has more years of working experience and working hours can earn more, which likely make senses. Other features seem less relevant. This perhaps is the fact of the data scientist market, working harder and gaining experience, you would earn more, so does it mean that the boss does not care about their skills?","3731f44c":"The top three languages are JavaScript, HTML and SQL among non data scientist, that makes sense due to most people taking part in this survey who are web developers. To understand the programming language for the data scientist group, I'd like to make graphs to compare the diversity. Let's make a barplot to display the result. Here I define the barplot function across 3 group:","0e433181":"<a class=\"anchor\" id=\"3.3\"><\/a>\n### 3.3 Relationship of skills\n\nI am interested if a network graph is able to explain the correlation among these technologies and tools. I want to gather all these tools and use networkx package to generate a technology network for data scientist. The first step, I need to create a co-occurence matrix for these technology variables.","45e3e30b":"Accuracy is high but it is not a good metric due to bias classes. F1-score is fair 0.53 for the data scientist prediction. We can see many non data scientist are being classified as data scientist.","76456518":"Now we use Xgboost to predict the salary of data scientist. Xgboost is one of the best tree learning algorithm by which most people have won a Kaggle competition.","de59c68a":"Also, look into OrgSize, the company size may affect their wage payment.","336cbe7e":"I am curious that some roles might be similar to each other, for instance, full-stack developer usually means a developer can do both front-end and back-end, data scientist usually works with data analyst and data engineer. Let's transform DevType into multiple columns of which each column represent an individual roles.","c864380d":"#### 4.3.1 Data understanding and preparation"}}