{"cell_type":{"6389cb0a":"code","3bf2f3f6":"code","d3f44a5f":"code","97347d04":"code","bef209a4":"code","41421330":"code","7bd71590":"code","d3ba6db5":"code","3402bc12":"code","4ca36936":"code","35211e82":"code","aab271c5":"code","51bc9f0f":"code","6aa73107":"code","b6ce0ff3":"code","af6d200d":"code","f6a05dec":"markdown","da1a884d":"markdown","9b512605":"markdown","95c2c915":"markdown","959c01c4":"markdown","841c57e3":"markdown","53451f2e":"markdown","770b2872":"markdown","dbed5a3f":"markdown","03258e52":"markdown","b7e6b8c8":"markdown","c0490a57":"markdown","4d670e86":"markdown","5e4761b6":"markdown","a7447849":"markdown"},"source":{"6389cb0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)\n   #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3bf2f3f6":"import os\nimport glob\nimport numpy as np\nfrom PIL import Image,ImageOps\nimport matplotlib.pyplot as plt\n%matplotlib inline","d3f44a5f":"base_dir = '..\/input\/intel-image-classification\/'\ndirectory = os.listdir(base_dir)\ndirectory","97347d04":"train_dir = base_dir + 'seg_train\/seg_train\/'\ntest_dir = base_dir + 'seg_test\/seg_test\/'","bef209a4":"CLASSES = os.listdir(train_dir)","41421330":"for imgType in CLASSES:\n    imgTypePath = train_dir + \"\/\" + imgType + \"\/\"\n    print(\"CLASS: \" + imgType + \"-->\"+\"Total image: \" + str(len(os.listdir(imgTypePath))))","7bd71590":"for imgType in CLASSES:\n    imgTypePath = test_dir + \"\/\" + imgType + \"\/\"\n    print(\"CLASS: \" + imgType + \"-->\"+\"Total image: \" + str(len(os.listdir(imgTypePath))))","d3ba6db5":"# function to convert the image into grayscale\n\ndef convert_to_grayscale(img):\n    #Convert to grayscale\n    return ImageOps.grayscale(img)\n\n# function to reshape the image\n\ndef reshape_img(img,target_size = (150,150)):\n    #Reshape any image to a fixed shape\n    return img.resize(target_size)\n\n# \n\ndef display_numpy_img(np_img, img_name=\"Transformed image\"):\n    plt.figure(figsize = (6,6))\n    plt.imshow(np_img, cmap='gray')\n    plt.title(img_name)\n    \n    \ndef transform_image(img_file_path):\n    img_obj = Image.open(img_file_path)\n    #print(img_obj.format)\n    #print(np.array(img_obj).shape)\n    #Perform transformations in series\n    img_obj = convert_to_grayscale(img_obj)\n    img_obj = reshape_img(img_obj, (150,150))\n    np_arr_img = np.array(img_obj)\n    return np_arr_img\n\ndef load_dir_to_numpy(dir_path, maxImgs=1500):\n    file_list = glob.glob(dir_path+'\/*')\n    imgs = []\n    #Load image by image\n    imgCount=0\n    for fname in file_list:\n        if imgCount>=maxImgs:\n            break\n        img_np = transform_image(fname)\n        imgs.append(img_np)\n        imgCount = imgCount + 1\n    np_imgs = np.array(imgs)\n    return np_imgs\n\ndef load_dir_to_numpy(dir_path, maxImgs=1500):\n    file_list = glob.glob(dir_path+'\/*')\n    imgs = []\n    #Load image by image\n    imgCount=0\n    for fname in file_list:\n        if imgCount>=maxImgs:\n            break\n        img_np = transform_image(fname)\n        imgs.append(img_np)\n        imgCount = imgCount + 1\n    np_imgs = np.array(imgs)\n    return np_imgs\n\ndef prepare_image_data(dir_path, MAX_IMGS):\n    imgs_arr_X = []\n    data_arr_y = []\n    classIdx = 0;\n    for imgType in CLASSES:\n        IMG_DIR = dir_path + \"\/\" + imgType + \"\/\"\n        #  print(\"IMG_DIR: \" + IMG_DIR)\n        imgs_arr = load_dir_to_numpy(IMG_DIR, MAX_IMGS)\n        #print(imgType + \": \" + str(imgs_arr.shape))\n        imgs_arr_X.extend(imgs_arr)\n        data_y = np.full((imgs_arr.shape[0],1), classIdx)\n        data_arr_y.extend(data_y)\n        classIdx += 1\n    np_img_arr_X = np.array(imgs_arr_X)\n    np_data_arr_y = np.array(data_arr_y)\n    return np_img_arr_X,np_data_arr_y","3402bc12":"train_np_x,train_np_y = prepare_image_data(train_dir, 500)\nprint('train_np_x.shape:', train_np_x.shape)\nprint('train_np_y.shape:', train_np_y.shape)","4ca36936":"train_size = train_np_x.shape[0]\ntrain_np_x = train_np_x.reshape((train_size, -1))\nprint('After reshaping, train_np_x.shape:', train_np_x.shape)","35211e82":"from sklearn import tree\nmodel =  tree.DecisionTreeClassifier()\nmodel.fit(train_np_x,train_np_y.reshape(-1))","aab271c5":"test_np_x,test_np_y = prepare_image_data(test_dir, 200)\n\ntest_size = test_np_x.shape[0]\ntest_np_x = test_np_x.reshape((test_size, -1))\nprint('Test shape:', test_np_x.shape)","51bc9f0f":"# Predict values\npredicted_y = model.predict(test_np_x)","6aa73107":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\nactual_y = test_np_y.reshape(-1)\nprint('Accuracy Score:', accuracy_score(test_np_y, predicted_y))","b6ce0ff3":"print(classification_report(test_np_y, predicted_y))","af6d200d":"print(confusion_matrix(test_np_y, predicted_y))","f6a05dec":"# Confusion matrix","da1a884d":"# flattening out the image","9b512605":"# preparing a model","95c2c915":"# Model training performance report","959c01c4":"# get a folder inside the seg_train","841c57e3":"# List of directories","53451f2e":"# Training and Test directory","770b2872":"# Total no of images per class in training dataset","dbed5a3f":"# Total no of images per class in testing dataset","03258e52":"# What's the trained model accuracy on test data","b7e6b8c8":"# List imports","c0490a57":"# Preparing testing data","4d670e86":"# Predict using testing data","5e4761b6":"# Pipeline helper functions","a7447849":"# Preparing taining dataset "}}