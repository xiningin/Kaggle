{"cell_type":{"74c10184":"code","7d58bb79":"code","10cf14a9":"code","c8276739":"code","10066e57":"code","0e40b881":"code","267257ff":"code","2c612bf4":"code","fc1f4cff":"code","9b0cbec3":"code","6067a539":"code","8f5a541d":"code","d16f68a7":"code","5a7a63af":"code","18a78a67":"code","a37d54d7":"code","3ff05444":"code","f7a03cee":"code","b3071599":"code","aac75e75":"code","573e678a":"code","e1eb5cc4":"code","6aa1d358":"code","db6f62d6":"code","a6a9af4d":"code","157a02b9":"code","0e419446":"markdown","aa7c6230":"markdown","7945d8bc":"markdown","70e9a9c6":"markdown","e64f46c9":"markdown","7b0a953f":"markdown","f54d51e2":"markdown","03df6645":"markdown","1c0ebf8a":"markdown","69137fcf":"markdown"},"source":{"74c10184":"import warnings\nwarnings.filterwarnings(\"ignore\")","7d58bb79":"# import libraries \nimport pickle\nimport seaborn as sns\nimport pandas as pd # Import Pandas for data manipulation using dataframes\nimport numpy as np # Import Numpy for data statistical analysis \nimport matplotlib.pyplot as plt # Import matplotlib for data visualisation\nimport random","10cf14a9":"# The pickle module implements binary protocols for serializing and de-serializing a Python object structure.\nwith open(\"\/kaggle\/input\/traffic-sign-classification\/train.p\", mode='rb') as training_data:\n    train = pickle.load(training_data)\nwith open(\"\/kaggle\/input\/traffic-sign-classification\/valid.p\", mode='rb') as validation_data:\n    valid = pickle.load(validation_data)\nwith open(\"\/kaggle\/input\/traffic-sign-classification\/test.p\", mode='rb') as testing_data:\n    test = pickle.load(testing_data)","c8276739":"X_train, y_train = train['features'], train['labels']\nX_validation, y_validation = valid['features'], valid['labels']\nX_test, y_test = test['features'], test['labels']\n","10066e57":"X_train.shape","0e40b881":"y_train.shape","267257ff":"i = 1001\nplt.imshow(X_train[i]) # Show images are not shuffled\ny_train[i]","2c612bf4":"from sklearn.utils import shuffle\nX_train, y_train = shuffle(X_train, y_train)\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')","fc1f4cff":"y_train","9b0cbec3":"import keras\ny_train = keras.utils.to_categorical(y_train, 43)","6067a539":"y_train","8f5a541d":"X_train = X_train\/255\nX_test = X_test\/255","d16f68a7":"X_train.shape","5a7a63af":"# Import train_test_split from scikit library\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import TensorBoard","18a78a67":"image_shape = X_train[i].shape","a37d54d7":"image_shape","3ff05444":"cnn_model = Sequential()\n\ncnn_model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (32, 32, 3)))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Conv2D(32, kernel_size = 3, activation='relu'))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Dropout(0.4))\n\ncnn_model.add(Conv2D(64, kernel_size = 3, activation='relu'))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Conv2D(64, kernel_size = 3, activation='relu'))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Dropout(0.4))\n\ncnn_model.add(Conv2D(128, kernel_size = 4, activation='relu'))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Flatten())\ncnn_model.add(Dropout(0.4))\ncnn_model.add(Dense(43, activation='softmax'))\n\n    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\ncnn_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","f7a03cee":"cnn_model.summary()","b3071599":"history = cnn_model.fit(X_train,\n                        y_train,\n                        batch_size=500,\n                        epochs=5,\n                        verbose=1,\n                        validation_split=0.2)","aac75e75":"y_test = keras.utils.to_categorical(y_test, 43)\nscore = cnn_model.evaluate(X_test, y_test,verbose=0)\nprint('Test Accuracy : {:.4f}'.format(score[1]))","573e678a":"history.history.keys()","e1eb5cc4":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\nplt.title('Training and Validation accuracy')\nplt.legend()\n","6aa1d358":"plt.plot(epochs, loss, 'ro', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","db6f62d6":"#get the predictions for the test data\npredicted_classes = cnn_model.predict(X_test)\n#get the indices to be plotted\ny_true = np.argmax(y_test,axis=1)\npredicted_classes = np.argmax(predicted_classes,axis=1)","a6a9af4d":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true, predicted_classes)\nplt.figure(figsize = (25,25))\nsns.heatmap(cm, annot=True)","157a02b9":"L = 7\nW = 7\nfig, axes = plt.subplots(L, W, figsize = (12,12))\naxes = axes.ravel() # \n\nfor i in np.arange(0, L * W):  \n    axes[i].imshow(X_test[i])\n    axes[i].set_title(\"Prediction={}\\n True={}\".format(predicted_classes[i], y_true[i]))\n    axes[i].axis('off')\n\nplt.subplots_adjust(wspace=1)","0e419446":"- In this case study, you have been provided with images of traffic signs and the goal is to train a Deep Network to classify them\n- The dataset contains 43 different classes of images. \n- Classes are as listed below: \n\n    - ( 0, b'Speed limit (20km\/h)') ( 1, b'Speed limit (30km\/h)')\n    - ( 2, b'Speed limit (50km\/h)') ( 3, b'Speed limit (60km\/h)')\n    - ( 4, b'Speed limit (70km\/h)') ( 5, b'Speed limit (80km\/h)')\n    - ( 6, b'End of speed limit (80km\/h)') ( 7, b'Speed limit (100km\/h)')\n    - ( 8, b'Speed limit (120km\/h)') ( 9, b'No passing')\n    - (10, b'No passing for vehicles over 3.5 metric tons')\n    - (11, b'Right-of-way at the next intersection') (12, b'Priority road')\n    - (13, b'Yield') (14, b'Stop') (15, b'No vehicles')\n    - (16, b'Vehicles over 3.5 metric tons prohibited') (17, b'No entry')\n    - (18, b'General caution') (19, b'Dangerous curve to the left')\n    - (20, b'Dangerous curve to the right') (21, b'Double curve')\n    - (22, b'Bumpy road') (23, b'Slippery road')\n    - (24, b'Road narrows on the right') (25, b'Road work')\n    - (26, b'Traffic signals') (27, b'Pedestrians') (28, b'Children crossing')\n    - (29, b'Bicycles crossing') (30, b'Beware of ice\/snow')\n    - (31, b'Wild animals crossing')\n    - (32, b'End of all speed and passing limits') (33, b'Turn right ahead')\n    - (34, b'Turn left ahead') (35, b'Ahead only') (36, b'Go straight or right')\n    - (37, b'Go straight or left') (38, b'Keep right') (39, b'Keep left')\n    - (40, b'Roundabout mandatory') (41, b'End of no passing')\n    - (42, b'End of no passing by vehicles over 3.5 metric tons')\n\n- The network used is called Le-Net that was presented by Yann LeCun\nhttp:\/\/yann.lecun.com\/exdb\/publis\/pdf\/lecun-01a.pdf\n","aa7c6230":"The model consists of the following layers: \n\n- STEP 1: THE FIRST CONVOLUTIONAL LAYER #1\n    - Input = 32x32x1\n    - Output = 28x28x6\n    - Output = (Input-filter+1)\/Stride* => (32-5+1)\/1=28\n    - Used a 5x5 Filter with input depth of 3 and output depth of 6\n    - Apply a RELU Activation function to the output\n    - pooling for input, Input = 28x28x6 and Output = 14x14x6\n\n\n    * Stride is the amount by which the kernel is shifted when the kernel is passed over the image.\n\n- STEP 2: THE SECOND CONVOLUTIONAL LAYER #2\n    - Input = 14x14x6\n    - Output = 10x10x16\n    - Layer 2: Convolutional layer with Output = 10x10x16\n    - Output = (Input-filter+1)\/strides => 10 = 14-5+1\/1\n    - Apply a RELU Activation function to the output\n    - Pooling with Input = 10x10x16 and Output = 5x5x16\n\n- STEP 3: FLATTENING THE NETWORK\n    - Flatten the network with Input = 5x5x16 and Output = 400\n\n- STEP 4: FULLY CONNECTED LAYER\n    - Layer 3: Fully Connected layer with Input = 400 and Output = 120\n    - Apply a RELU Activation function to the output\n\n- STEP 5: ANOTHER FULLY CONNECTED LAYER\n    - Layer 4: Fully Connected Layer with Input = 120 and Output = 84\n    - Apply a RELU Activation function to the output\n\n- STEP 6: FULLY CONNECTED LAYER\n    - Layer 5: Fully Connected layer with Input = 84 and Output = 43","7945d8bc":"# STEP 0: PROBLEM STATEMENT","70e9a9c6":"Citation\n\nJ. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German Traffic Sign Recognition Benchmark: A multi-class classification competition. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 1453\u20131460. 2011. \n\n@inproceedings{Stallkamp-IJCNN-2011,\n    author = {Johannes Stallkamp and Marc Schlipsing and Jan Salmen and Christian Igel},\n    booktitle = {IEEE International Joint Conference on Neural Networks},\n    title = {The {G}erman {T}raffic {S}ign {R}ecognition {B}enchmark: A multi-class classification competition},\n    year = {2011},\n    pages = {1453--1460}\n}\n\n","e64f46c9":"# STEP 5: MODEL EVALUATION","7b0a953f":"# STEP 4: MODEL TRAINING","f54d51e2":"## Shuffle the dataset ","03df6645":"# STEP 2: IMAGE EXPLORATION","1c0ebf8a":"# STEP 3: DATA PEPARATION","69137fcf":"# STEP 1: IMPORT LIBRARIES AND DATASET"}}