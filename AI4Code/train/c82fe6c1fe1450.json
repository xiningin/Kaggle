{"cell_type":{"2323d4f3":"code","f2064223":"code","49e92d0b":"code","9f043170":"code","1edee9d1":"code","66323478":"code","4d174388":"code","4d4157d1":"code","0da77162":"markdown"},"source":{"2323d4f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport time\nfrom datetime import datetime\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\/b3-stock-quotes\"]).decode(\"utf8\"))\nprint(check_output([\"ls\", \".\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","f2064223":"# Here we'll specify the columns width\nwidths = [2, 8, 2, 12, 3, 12, \n          10, 3, 4, 13, 13, 13, 13, 13, 13, 13, 5, 18, \n          18, 13, 1, 8, 7, 13, 12, 3]\n\n# and the columns names, based in the original specification\ncolumn_names = ['TIPREG', 'DATPRE', 'CODBDI', 'CODNEG', 'TPMERC', 'NOMRES', 'ESPECI', 'PRAZOT', \n                'MODREF', 'PREABE', 'PREMAX', 'PREMIN', 'PREMED', 'PREULT', 'PREOFC', 'PREOFV', \n                'TOTNEG', 'QUATOT', 'VOLTOT', 'PREEXE', 'INDOPC', 'DATVEN', 'FATCOT', 'PTOEXE', \n                'CODISI', 'DISMES']","49e92d0b":"# Most of the prices are defined with two decimals. \n# This function is used to adjust this while loading...\ndef convert_price(s):\n    return (float(s) \/ 100.0)\n\n# The date fields are in the format YYYYMMDD\ndef convert_date(d):\n    struct = time.strptime(d, '%Y%m%d')\n    dt = datetime.fromtimestamp(time.mktime(struct))\n    return(dt)","9f043170":"# Specify dtype while loading\ndtype_dict = {\n    'TOTNEG':np.int32\n}\n\n# Use the functions defined above to convert data while loading\nconvert_dict = {\n    'DATPRE':convert_date, \n    'PREABE':convert_price, 'PREMAX':convert_price, \n    'PREMIN':convert_price, \n    'PREMED':convert_price, 'PREULT':convert_price, 'PREOFC':convert_price, \n    'PREOFV':convert_price,\n    'DATVEN':convert_date, \n}","1edee9d1":"# Load the raw file\ndef load_and_preprocess(file_path):\n    df = pd.read_fwf(\n        file_path, \n        widths=widths, \n        names=column_names, \n        dtype=dtype_dict, \n        converters=convert_dict,\n        #compression='zip',\n        skiprows=1,              # Skip the header row\n        skipfooter=1             # Skip the footer row\n    )\n    return(df)","66323478":"import zipfile\n\n# Will unzip the files so that you can see them..\nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2009.ZIP\", \"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2010.ZIP\", \"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2011.ZIP\", \"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2012.ZIP\", \"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2013.ZIP\", \"r\") as z:\n    z.extractall(\".\")    \nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2014.ZIP\", \"r\") as z:\n    z.extractall(\".\")    \nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2015.ZIP\", \"r\") as z:\n    z.extractall(\".\")    \nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2016.ZIP\", \"r\") as z:\n    z.extractall(\".\")    \nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2017.ZIP\", \"r\") as z:\n    z.extractall(\".\")    \nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2018.ZIP\", \"r\") as z:\n    z.extractall(\".\")    \nwith zipfile.ZipFile(\"..\/input\/b3-stock-quotes\/COTAHIST_A2019.ZIP\", \"r\") as z:\n    z.extractall(\".\")    \n\n\n# Read all files and concatenate in one Dataframe\ndf1 = load_and_preprocess(\".\/COTAHIST_A2009.TXT\")\ndf2 = df1.append(load_and_preprocess(\".\/COTAHIST_A2010.TXT\"), ignore_index=True)\ndf3 = df2.append(load_and_preprocess(\".\/COTAHIST_A2011.TXT\"), ignore_index=True)\ndf4 = df3.append(load_and_preprocess(\".\/COTAHIST_A2012.TXT\"), ignore_index=True)\ndf5 = df4.append(load_and_preprocess(\".\/COTAHIST_A2013.TXT\"), ignore_index=True)\ndf6 = df5.append(load_and_preprocess(\".\/COTAHIST_A2014.TXT\"), ignore_index=True)\ndf7 = df6.append(load_and_preprocess(\".\/COTAHIST_A2015.TXT\"), ignore_index=True)\ndf8 = df7.append(load_and_preprocess(\".\/COTAHIST_A2016.TXT\"), ignore_index=True)\ndf9 = df8.append(load_and_preprocess(\".\/COTAHIST_A2017.TXT\"), ignore_index=True)\ndf10 = df9.append(load_and_preprocess(\".\/COTAHIST_A2018.TXT\"), ignore_index=True) # New file with full 2018 data (previous was partial)\ndf  = df10.append(load_and_preprocess(\".\/COTAHIST_A2019.TXT\"), ignore_index=True) # New file with full 2019 data\n\n","4d174388":"pd.set_option('display.max_columns', 26)\ndf.head()","4d4157d1":"df.to_csv('COTAHIST_A2009_to_A2019.csv')","0da77162":"The original files from the Brazillian Stock Exchange are not comma separated files. This Kernel will decode the files and generate a csv file to facilitate the use in others Kernels. The file format specification is available in this [link](http:\/\/www.bmfbovespa.com.br\/lumis\/portal\/file\/fileDownload.jsp?fileId=8A828D294E9C618F014EB7924B803F8B) (Portuguese only...)."}}