{"cell_type":{"427395bc":"code","5d9a4d3b":"code","02b4da25":"code","b7b24a38":"code","5b3593de":"code","3b24ede4":"code","28240574":"code","11b08040":"code","201329fe":"code","4d9b87de":"code","8230decb":"code","a94ef286":"code","408a07ba":"code","d1c6c28c":"code","cd27a0bd":"code","54beca0a":"code","47ae9bfe":"code","676045eb":"code","6329e881":"code","4655e550":"code","f5bab339":"code","e7f47096":"code","fd4b7c8c":"code","2f586b72":"code","bcf7953e":"code","f73a944d":"code","c22ef823":"code","38065e06":"code","7bf2ad38":"code","fa087eed":"code","36a9e16a":"code","06131efb":"code","735ca83e":"code","e5c2cee4":"code","1214963a":"code","f07d4721":"code","5d3c0958":"code","586690eb":"code","bdf97cfd":"code","c188448b":"code","a938ce74":"code","d901e6bf":"code","349dfeb7":"code","04fbe985":"code","09661ea3":"code","c8970b86":"code","9c440247":"code","e5c68df6":"code","0805b967":"code","26843d7d":"code","98a49d5b":"code","54920679":"code","81b1bf3d":"code","532c37e3":"code","39fdcf8c":"code","bdbbc0af":"code","ef41539b":"code","1fb3701d":"code","f483a861":"code","b5ceb7dc":"code","ff6bc1a1":"code","03d0f630":"code","3555b155":"code","f0998444":"code","a0d94118":"code","0768a093":"markdown","a6e16bb1":"markdown","601e40ee":"markdown"},"source":{"427395bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# Any results you write to the current directory are saved as output.","5d9a4d3b":"import tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport shutil","02b4da25":"train = pd.read_csv(\"..\/input\/aptos2019-blindness-detection\/train.csv\")","b7b24a38":"train.head()","5b3593de":"train.shape","3b24ede4":"train['diagnosis'].unique()","28240574":"train.diagnosis.hist()","11b08040":"def showbyserverity():\n    fig = plt.figure(figsize=(25, 16))\n    for class_id in sorted(train['diagnosis'].unique()): \n        for i, (idx, row) in enumerate(train.loc[train['diagnosis'] == class_id].sample(5, random_state=42).iterrows()):\n            ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n            path=f\"..\/input\/aptos2019-blindness-detection\/train_images\/{row['id_code']}.png\"\n            image = cv2.imread(path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image, (256, 256))\n            image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 50) ,-4 ,128)\n\n            plt.imshow(image, cmap = 'gist_gray')\n            ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","201329fe":"showbyserverity()","4d9b87de":"def label_img(name):\n    if name == 0 : \n        return np.array([1, 0, 0, 0, 0])\n    elif name == 1 : \n        return np.array([0, 1, 0, 0, 0])\n    elif name == 2 : \n        return np.array([0, 0, 1, 0, 0])\n    elif name == 3 : \n        return np.array([0, 0, 0, 1, 0])\n    else:\n        return np.array([0, 0, 0, 0, 1 ])","8230decb":"for class_id in sorted(train['diagnosis'].unique()):\n    opath = f\"\/output\/kaggle\/working\/class_{class_id}\"\n    os.makedirs(opath)\n    for i, (idx, row) in enumerate(train.loc[train['diagnosis'] == class_id].iterrows()):\n        path=f\"..\/input\/aptos2019-blindness-detection\/train_images\/{row['id_code']}.png\"\n        shutil.copy(path,opath)\n        \n    ","a94ef286":"print(os.listdir(\"\/output\/kaggle\/working\"))","408a07ba":"# shutil.rmtree(\"\/output\/kaggle\/working\")","d1c6c28c":"for i in range(5):\n    opath = f\"\/output\/kaggle\/working\/class_{i}\"\n    list = os.listdir(opath) # dir is your directory path\n    print(len(list))\n   ","cd27a0bd":"!pip install Augmentor","54beca0a":" import Augmentor","47ae9bfe":"def offline_augmentor(path, size, output_dir):\n    p = Augmentor.Pipeline(path,output_dir)\n    \n    p.rotate(probability=0.5, max_left_rotation=25, max_right_rotation=25)\n#     p.shear(probability=0.5, max_shear_left=16, max_shear_right=16)\n    p.flip_left_right(probability=0.5)\n    p.flip_top_bottom(probability=0.5)\n    p.zoom(probability=0.5, min_factor=0.75, max_factor=1.3)\n    p.crop_random(probability=0.5, percentage_area=0.9)\n#     p.random_brightness(probability=0.5, max_factor=1.2, min_factor=0.4)\n#     p.random_color(probability=0.5, max_factor=0.8, min_factor=0.3)\n#     p.random_contrast(probability=0.5, max_factor=0.8, min_factor=0.3)\n    p.resize(probability=1.0, width=512, height=512)\n    p.sample(size)","676045eb":"path = '\/output\/kaggle\/working\/class_1'\nsize = 1400\noutput_dir='\/output\/kaggle\/working\/class_1\/output'\n\noffline_augmentor(path, size, output_dir)","6329e881":"path = '\/output\/kaggle\/working\/class_2'\nsize = 800\noutput_dir='\/output\/kaggle\/working\/class_2\/output'\n\noffline_augmentor(path, size, output_dir)","4655e550":"path = '\/output\/kaggle\/working\/class_3'\nsize = 1600\noutput_dir='\/output\/kaggle\/working\/class_3\/output'\n\noffline_augmentor(path, size, output_dir)","f5bab339":"path = '\/output\/kaggle\/working\/class_4'\nsize = 1500\noutput_dir='\/output\/kaggle\/working\/class_4\/output'\n\noffline_augmentor(path, size, output_dir)","e7f47096":"print(os.listdir(\"\/output\/kaggle\/working\/class_4\/output\"))","fd4b7c8c":"path=f\"\/output\/kaggle\/working\/class_4\/output\/class_4_original_e019b3e0f33d.png_68e673f0-8f10-4e21-bbd4-7b88e4aa10ed.png\"\nimage = cv2.imread(path)\nplt.imshow(image)","2f586b72":"path=f\"..\/input\/aptos2019-blindness-detection\/train_images\/e019b3e0f33d.png\"\nimage = cv2.imread(path)\nplt.imshow(image)","bcf7953e":"train_image=[]\ntrain_label=[]","f73a944d":"for i in range(0,5):\n    path = f\"\/output\/kaggle\/working\/class_{i}\"\n    for filename in os.listdir(path):\n        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n            path_img = os.path.join(path,filename)\n            image = cv2.imread(path_img)\n            label = label_img(i)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n            image = cv2.resize(image, (256, 256))\n            image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 50) ,-4 ,128)\n            train_image.append(np.array(image))\n            train_label.append(label)\n    if i!=0:\n        path = f\"\/output\/kaggle\/working\/class_{i}\/output\"\n        for filename in os.listdir(path):\n            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n                path_img = os.path.join(path,filename)\n                image = cv2.imread(path_img)\n                label = label_img(i)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, (256, 256))\n                image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 50) ,-4 ,128)\n                train_image.append(np.array(image))\n                train_label.append(label)    \n    \n        ","c22ef823":"train_image[255].shape","38065e06":"from sklearn.model_selection import train_test_split\nxTrain, xTest, yTrain, yTest = train_test_split(train_image, train_label, test_size = 0.25, random_state = 42)\n\nxTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.15, random_state=42)","7bf2ad38":"type(xTrain)","fa087eed":"xTrain = np.array(xTrain)\nxTest = np.array(xTest)\n\n","36a9e16a":"yTrain = np.array(yTrain)\nyTest = np.array(yTest)","06131efb":"xVal = np.array(xVal)\nyVal = np.array(yVal)","735ca83e":"import matplotlib.pyplot as plt\nplt.imshow(train_image[123], cmap = 'gist_gray')","e5c2cee4":"sumy =[]","1214963a":"for i in range(len(yTrain)):\n    index = np.argmax(yTrain[i])\n    if index == 0:        \n        sumy.append(0)\n    elif index == 1: \n        sumy.append(1)\n    elif index == 2: \n        sumy.append(2)\n    elif index == 3:\n        sumy.append(3)\n    elif index == 4:\n        sumy.append(4)","f07d4721":"from collections import Counter","5d3c0958":"Counter(sumy)","586690eb":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(256, 256, 3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\n# model.add(Dropout(0.3))\nmodel.add(Dense(5, activation = 'softmax'))","bdf97cfd":"for layer in model.layers:\n    print(layer.output_shape)","c188448b":"from keras.optimizers import SGD\nfrom keras import metrics\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy', metrics = [metrics.categorical_accuracy],optimizer='adam')\n\n","a938ce74":"from keras.callbacks import ModelCheckpoint","d901e6bf":"checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", monitor = 'val_categorical_accuracy',verbose=1, save_best_only=True)","349dfeb7":"history = model.fit(xTrain, yTrain, batch_size=32, epochs=40,callbacks=[checkpointer],validation_data=(xVal,yVal))","04fbe985":"model.load_weights('best_weights.hdf5')","09661ea3":"model.save('model_1.h5')","c8970b86":"acc = history.history['categorical_accuracy']\nloss = history.history['loss']\n\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","9c440247":"yPred = model.predict(xTest)","e5c68df6":"result = []","0805b967":"for i in range(len(yPred)):\n    index = np.argmax(yPred[i])\n    if index == 0:        #According to one hot encoding above, 0 is Coronal, 1 is Horizontal and 2 is Sagittal.\n        result.append(0)\n    elif index == 1: \n        result.append(1)\n    elif index == 2: \n        result.append(2)\n    elif index == 3:\n        result.append(3)\n    elif index == 4:\n        result.append(4)","26843d7d":"result_test=[]","98a49d5b":"for i in range(len(yTest)):\n    index = np.argmax(yTest[i])\n    if index == 0:        #According to one hot encoding above, 0 is Coronal, 1 is Horizontal and 2 is Sagittal.\n        result_test.append(0)\n    elif index == 1: \n        result_test.append(1)\n    elif index == 2: \n        result_test.append(2)\n    elif index == 3:\n        result_test.append(3)\n    elif index == 4:\n        result_test.append(4)","54920679":"from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,recall_score,precision_score,precision_recall_fscore_support","81b1bf3d":"f1_score(result,result_test,average='macro')","532c37e3":"confusion_matrix(result,result_test)","39fdcf8c":"accuracy_score(result,result_test)","bdbbc0af":"loss, accuracy = model.evaluate(xTest,yTest, batch_size=32)\nprint(loss, accuracy)","ef41539b":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation='relu',kernel_initializer='uniform',input_shape=(256, 256, 3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu',kernel_initializer='uniform'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu',kernel_initializer='uniform'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(96, kernel_size=(3,3), activation='relu',kernel_initializer='uniform'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu',kernel_initializer='uniform'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu',kernel_initializer='uniform'))\n# model.add(Dropout(0.3))\nmodel.add(Dense(5, activation = 'softmax',kernel_initializer='uniform'))","1fb3701d":"from keras.callbacks import ModelCheckpoint","f483a861":"from keras import metrics\n\nmodel.compile(loss='categorical_crossentropy',metrics=[metrics.categorical_accuracy],optimizer='rmsprop')\ncheckpointer = ModelCheckpoint(filepath='best_weights.hdf5',monitor='val_categorical_accuracy',verbose=1,save_best_only=True)","b5ceb7dc":"history = model.fit(xTrain, yTrain, batch_size=32, epochs=40,callbacks=[checkpointer],validation_data=(xVal,yVal))","ff6bc1a1":"model.load_weights('best_weights.hdf5')\nmodel.save('model_2.h5')","03d0f630":"acc = history.history['categorical_accuracy']\nloss = history.history['loss']\n\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.title('Training accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.title('Training loss')\nplt.legend()\n\nplt.show()","3555b155":"yPred = model.predict(xTest)\nresult = []\nfor i in range(len(yPred)):\n    index = np.argmax(yPred[i])\n    if index == 0:        #According to one hot encoding above, 0 is Coronal, 1 is Horizontal and 2 is Sagittal.\n        result.append(0)\n    elif index == 1: \n        result.append(1)\n    elif index == 2: \n        result.append(2)\n    elif index == 3:\n        result.append(3)\n    elif index == 4:\n        result.append(4)\nresult_test=[]\nfor i in range(len(yTest)):\n    index = np.argmax(yTest[i])\n    if index == 0:        #According to one hot encoding above, 0 is Coronal, 1 is Horizontal and 2 is Sagittal.\n        result_test.append(0)\n    elif index == 1: \n        result_test.append(1)\n    elif index == 2: \n        result_test.append(2)\n    elif index == 3:\n        result_test.append(3)\n    elif index == 4:\n        result_test.append(4)","f0998444":"recall_score(result,result_test,average='macro')","a0d94118":"confusion_matrix(result,result_test)","0768a093":"Copied Individual ids into differnet folders ","a6e16bb1":"Model with the best hyperparameters from previous book","601e40ee":"Verifying the count of individual number of images in each id"}}