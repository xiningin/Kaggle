{"cell_type":{"3fa8bd86":"code","3825dfe3":"code","26ecbb1c":"code","f159ad96":"code","e47a89b1":"code","70f3a559":"code","069dc023":"code","5364ce0e":"code","82884e0b":"code","cfa313cd":"code","fc792ab1":"code","780d71be":"code","01f650c2":"code","a4d3250d":"code","24c3fa7d":"code","2c2f8d76":"code","07804075":"code","7cd3383b":"code","f854e7c0":"code","16d906e9":"code","c1f93079":"code","7799d3ca":"code","3a328404":"code","8fd1bd79":"code","8624d9ee":"code","52372bd3":"code","516ae7ae":"code","623a0b13":"code","680b5d76":"code","b72d22e0":"markdown","c4488ef7":"markdown","3a503102":"markdown","5d74dd62":"markdown","bf430106":"markdown"},"source":{"3fa8bd86":"import numpy as np\nimport pandas as pd\nimport re","3825dfe3":"test = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntrain.info()","26ecbb1c":"# define the target vector\ntarget = train[\"Survived\"].values\n\n# concatenate the datasets for feature engineering\nfull = pd.concat([train, test], axis=0, sort=False)","f159ad96":"# get the title from the name\nfull[\"Title\"] = full[\"Name\"].apply(lambda x: re.search(' ([A-Za-z]+)\\.',x).group(1))\ntitle_mapping = {\n    \"Mr\": 1,\n    \"Miss\": 2,\n    \"Mrs\": 3,\n    \"Master\": 4,\n    \"Dr\": 5,\n    \"Rev\": 6,\n    \"Major\": 7,\n    \"Col\": 7,\n    \"Mlle\": 2,\n    \"Mme\": 3,\n    \"Don\": 9,\n    \"Dona\": 9,\n    \"Lady\": 10,\n    \"Countess\": 10,\n    \"Jonkheer\": 10,\n    \"Sir\": 9,\n    \"Capt\": 7,\n    \"Ms\": 2,\n}\n# map the values into categories\nfull[\"TitleCat\"] = full.loc[:,'Title'].map(title_mapping)","e47a89b1":"# get family size by combining the number of siblings, parents and themself\nfull[\"FamilySize\"] = full[\"SibSp\"] + full[\"Parch\"] + 1\n# bin the values into different groups\nfull[\"FamilySize\"] = pd.cut(full[\"FamilySize\"], bins=[0,1,4,20], labels=[0,1,2])","70f3a559":"# get the full lenght of the name\nfull[\"NameLength\"] = full[\"Name\"].apply(lambda x: len(x))","069dc023":"# transform the embarked column into categorical\nfull[\"Embarked\"] = pd.Categorical(full.Embarked).codes","5364ce0e":"# fill the fare null values with the median fare\nmedian_fare = test.Fare.median()\nfull[\"Fare\"] = full[\"Fare\"].fillna(median_fare)","82884e0b":"# one-hot encode the sex column\nfull = pd.concat([full,pd.get_dummies(full['Sex'])],axis=1)","cfa313cd":"# fill the na values in the cabin column and save it to a new column\nfull['CabinCat'] = full.Cabin.fillna('0')\n# apply lambda function to retain only the cabin letter\nfull['CabinCat'] = full.CabinCat.apply(lambda x: x[0])\n# transform the column into categorical\nfull['CabinCat'] = pd.Categorical(full.CabinCat).codes","fc792ab1":"# function to check if the cabin is even\/odd\/null \ndef get_type_cabine(cabine):\n    # Use a regular expression to search for number\n    cabine_search = re.search('\\d+', cabine)\n    # If the number exists, extract and return it.\n    if cabine_search:\n        num = cabine_search.group(0)\n        if np.float64(num) % 2 == 0:\n            return '2'\n        else:\n            return '1'\n    return '0'\n\n# fill the na values in the cabin column and save it to a new column\nfull[\"CabinType\"] = full.Cabin.fillna(\" \")\n# apply the funciton\nfull[\"CabinType\"] = full.CabinType.apply(get_type_cabine)","780d71be":"# get the person type from age and sex\ndef get_person_type(passenger):\n    age, sex = passenger\n    if (age < 18):\n        return 'child'\n    elif (sex == 'female'):\n        return 'female_adult'\n    else:\n        return 'male_adult'\n    \nperson = pd.DataFrame(full[['Age', 'Sex']].apply(get_person_type, axis=1), columns=['person'])\n# concatenate the person series with the full dataset\nfull = pd.concat([full, person], axis=1)\n# one-hot enconde the person column\nfull = pd.concat([full,pd.get_dummies(full['person'])],axis=1)","01f650c2":"# count the number of members for each ticket\nticket_table = pd.DataFrame(full.Ticket.value_counts())\nticket_table.rename(columns={'Ticket':'Ticket_Members'}, inplace=True)\n\n# create boolean series\nisFemale = full.female_adult == 1\nisMale = full.male_adult == 1\nsurvived = full.Survived == 1\nperished = full.Survived == 0\nhasFamily = (full.Parch > 0) | (full.SibSp > 0)\n\n# get the number of women that perished for each ticket \nticket_table['Ticket_perishing_women'] = full.Ticket[\n    isFemale & perished & hasFamily\n].value_counts()\n# fill nan values with 0\nticket_table['Ticket_perishing_women'] = ticket_table.Ticket_perishing_women.fillna(0)\n# transform into a boolean series encoding any value greater than 0 as 1\nhasPerishedWomen = ticket_table.Ticket_perishing_women > 0\nticket_table.loc[hasPerishedWomen, 'Ticket_perishing_women'] = 1.0 \n\n# get the number of men that survived for each ticket\nticket_table['Ticket_surviving_men'] = full.Ticket[\n    isMale & survived & hasFamily\n].value_counts()\n# fill nan values with 0\nticket_table['Ticket_surviving_men'] = ticket_table.Ticket_surviving_men.fillna(0)\n# transform into a boolean series encoding any value greater than 0 as 1\nhasSurvivingMan = ticket_table.Ticket_surviving_men > 0\nticket_table.loc[hasSurvivingMan, 'Ticket_surviving_men'] = 1.0 \n\n# crate a Ticket_Id categorical column\nticket_table['Ticket_Id'] = pd.Categorical(ticket_table.index).codes\n# assign tickets with less than 3 members the code -1\nhasLessThan3Members = ticket_table.Ticket_Members < 3\nticket_table.loc[hasLessThan3Members, 'Ticket_Id'] = -1\n# bin the members values into different groups\nticket_table['Ticket_Members'] = pd.cut(ticket_table['Ticket_Members'], bins=[0,1,4,20], labels=[0,1,2])\n\n# merge the ticket_table dataframe with the full dataframe\nfull = pd.merge(\n    full,\n    ticket_table,\n    left_on=\"Ticket\",\n    right_index=True,\n    how='left', \n    sort=False\n)","a4d3250d":"# get the surname from the name\nfull['surname'] = full[\"Name\"].apply(lambda x: x.split(',')[0].lower())\n\n# count the number of members for each surname\nsurname_table = pd.DataFrame(full['surname'].value_counts())\nsurname_table.rename(columns={'surname':'Surname_Members'}, inplace=True)\n\n# create boolean series\nisFemale = full.female_adult == 1\nisMale = full.male_adult == 1\nsurvived = full.Survived == 1\nperished = full.Survived == 0\nhasFamily = (full.Parch > 0) | (full.SibSp > 0)\n\n# get the number of women that perished for each surname \nsurname_table['Surname_perishing_women'] = full.surname[\n    isFemale & perished & hasFamily\n].value_counts()\n# fill nan values with 0\nsurname_table['Surname_perishing_women'] = surname_table.Surname_perishing_women.fillna(0)\n# transform into a boolean series encoding any value greater than 0 as 1\nhasPerishedWomen = surname_table.Surname_perishing_women > 0\nsurname_table.loc[hasPerishedWomen, 'Surname_perishing_women'] = 1.0 \n\n# get the number of men that survived for each surname\nsurname_table['Surname_surviving_men'] = full.surname[\n    isMale & survived & hasFamily\n].value_counts()\n# fill nan values with 0\nsurname_table['Surname_surviving_men'] = surname_table.Surname_surviving_men.fillna(0)\n# transform into a boolean series encoding any value greater than 0 as 1\nhasSurvivingMan = surname_table.Surname_surviving_men > 0\nsurname_table.loc[hasSurvivingMan, 'Surname_surviving_men'] = 1.0 \n\n# crate a Surname_Id categorical column\nsurname_table['Surname_Id'] = pd.Categorical(surname_table.index).codes\n# assign surnames with less than 3 members the code -1\nhasLessThan3Members = surname_table.Surname_Members < 3\nsurname_table.loc[hasLessThan3Members, 'Surname_Id'] = -1\n# bin the members values into different groups\nsurname_table['Surname_Members'] = pd.cut(surname_table['Surname_Members'], bins=[0,1,4,20], labels=[0,1,2])\n\n# merge the surname_table dataframe with the full dataframe\nfull = pd.merge(\n    full,\n    surname_table,\n    left_on=\"surname\",\n    right_index=True,\n    how='left', \n    sort=False\n)","24c3fa7d":"print('Number of missing ages: ', full.Age.isnull().sum())\nprint('Median age: ', full.Age.median())\nprint('Mean age: ', full.Age.mean())\nprint('Std age: ', full.Age.std())\nprint('Min age: ', full.Age.min())\nprint('Max age: ', full.Age.max())","2c2f8d76":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n\nfeatures = ['Fare','Parch','Pclass','SibSp','TitleCat', \n'CabinCat','female','male', 'Embarked', 'FamilySize', 'NameLength','Ticket_Members','Ticket_Id']\n\n# build the train sets using the rows without the missing age\nX_train = full[features][full['Age'].notnull()]\ny_train = full['Age'][full['Age'].notnull()]\n\n# build the text set with the rows with missing ages\nX_test = full[features][full['Age'].isnull()]\n\n# create and fit the model\nmodel = ExtraTreesRegressor(n_estimators=500)\nmodel.fit(X_train, y_train)\n\n# make predictions on the train set\ny_preds_train = model.predict(X_train)\n\n# calculate the MSE of the predictions\nprint('MSE: ', mean_absolute_error(y_train, y_preds_train))","07804075":"# make predictions on the test set (missing ages)\ny_preds_test = model.predict(X_test)\n\n# fill the missing ages with the predictions\nfull.loc[full.Age.isnull(), 'Age'] = y_preds_test","7cd3383b":"print('Number of missing ages: ', full.Age.isnull().sum())\nprint('Median age: ', full.Age.median())\nprint('Mean age: ', full.Age.mean())\nprint('Std age: ', full.Age.std())\nprint('Min age: ', full.Age.min())\nprint('Max age: ', full.Age.max())","f854e7c0":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\n\nimport time","16d906e9":"# split back the full dataset into train and test sets\ntrain = full[0:891].copy()\ntest = full[891:].copy()","c1f93079":"# specify the features to be used in the model\nfeatures = ['female','male','Age','male_adult','female_adult', 'child','TitleCat', 'Pclass',\n'Pclass','Ticket_Id','NameLength','CabinType','CabinCat', 'SibSp', 'Parch',\n'Fare','Embarked','Surname_Members','Ticket_Members','FamilySize',\n'Ticket_perishing_women','Ticket_surviving_men',\n'Surname_perishing_women','Surname_surviving_men']","7799d3ca":"# build the train and test sets\nX_train = train[features]\ny_train = train['Survived']\n\nX_test = test[features]","3a328404":"seed = 42\n\n# create the default model\nrfc = RandomForestClassifier(\n#     min_samples_split=4,\n    class_weight={0:0.745,1:0.255}, \n    random_state=seed\n)\n\n# Create the grid search parameter grid and scoring funcitons\nparam_grid = {\n    \"max_depth\": np.linspace(1, 32, 2),\n    \"n_estimators\": np.arange(100, 1000, 100),\n    \"criterion\": [\"gini\",\"entropy\"],\n    \"max_leaf_nodes\": [16, 64, 128, 256],\n    \"oob_score\": [True],\n}\nscoring = {\n    'AUC': 'roc_auc', \n    'Accuracy': make_scorer(accuracy_score)\n}\n\n# create the Kfold object\nnum_folds = 10\nkfold = StratifiedKFold(n_splits=num_folds, random_state=seed)\n\n# create the grid search object with the full pipeline as estimator\nn_iter=50\ngrid = RandomizedSearchCV(\n    estimator=rfc, \n    param_distributions=param_grid,\n    cv=kfold,\n    scoring=scoring,\n    n_jobs=-1,\n    n_iter=n_iter,\n    refit=\"AUC\"\n)\n\n\n# fit grid search\n%time best_model = grid.fit(X_train,y_train)","8fd1bd79":"print(f'Best score: {best_model.best_score_}')\nprint(f'Best params: {best_model.best_params_}')","8624d9ee":"# metrics of the  best model\npred_train = best_model.predict(X_train)\n\nprint('Train Accuracy: ', accuracy_score(y_train, pred_train))\nprint(\"Out-of-Bag Accuracy: \", best_model.best_estimator_.oob_score_)\nprint('\\nClassification Report:')\nprint(classification_report(y_train,pred_train))","52372bd3":"# make the predictions on the test set\npredictions = best_model.predict(X_test)","516ae7ae":"# save the predictions to the outputfile\nPassengerId = np.array(test['PassengerId']).astype(int)\npredictions = predictions.astype(int)\n\nmy_predictions = pd.DataFrame({\n    'PassengerId': PassengerId,\n    'Survived': predictions\n})\nmy_predictions.to_csv(\"my_predictions.csv\", index=False)","623a0b13":"my_predictions.Survived.value_counts()","680b5d76":"my_predictions.info()","b72d22e0":"# 5. Making predictions and creating the output file","c4488ef7":"# 4. Training and evaluating the Model","3a503102":"# 2. Feature Engineering","5d74dd62":"# 1. Loading and exploring the datasets","bf430106":"# 3. Filling the missing Ages"}}