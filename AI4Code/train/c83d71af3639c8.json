{"cell_type":{"cd94e621":"code","fa850b70":"code","5bb597e8":"code","1b722e7f":"code","4d9fc815":"code","858b366a":"code","f8c72a13":"code","f6ab37a3":"code","3071968d":"code","73503fb9":"code","ca4e8fdb":"code","5c0847af":"code","2f3f0d90":"code","89373f6c":"code","56fbbff4":"code","7fd18762":"code","4d6fb4cc":"code","021766bf":"code","b3f18f6b":"code","43ac7dbc":"code","8c9f5440":"code","1f6526c2":"code","94b63a6d":"code","b1e38901":"code","030d344e":"code","8301ced6":"markdown","ec975b64":"markdown"},"source":{"cd94e621":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport warnings\nimport seaborn as sns\nimport matplotlib.pylab as plt\nimport PIL\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import f1_score\nfrom keras import backend as K\nfrom keras import layers, models, optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import *\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nwarnings.filterwarnings('ignore')\nK.image_data_format()","fa850b70":"pd.set_option(\"display.max_rows\", 20)","5bb597e8":"BATCH_SIZE = 32\nEPOCHS = 150\nk_folds = 2\nPATIENCE = 3\nSEED = 2019\nBASE_MODEL = Xception\nIMAGE_SIZE = 299","1b722e7f":"os.listdir('..\/input')","4d9fc815":"# \uae30\uc874 train crop \uc774\ubbf8\uc9c0 \ud30c\uc77c\uc758 \uac1c\uc218, \uae30\uc874 train \uc774\ubbf8\uc9c0 \ud30c\uc77c \uac1c\uc218\uc640 \ub3d9\uc77c. \ub098\ub294 train crop + train origin\uc744 \uc6d0\ud568.\nprint(len(next(os.walk('..\/input\/3rd-ml-month-car-image-cropping-dataset\/train_crop'))[2])) ","858b366a":"DATA_PATH = '..\/input\/2019-3rd-ml-month-with-kakr'\n\nTRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\nTEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n\ndf_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\ndf_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))\n\nmodel_path = '.\/'\nif not os.path.exists(model_path):\n    os.mkdir(model_path)","f8c72a13":"# df_train\uc5d0 crop\ud558\uace0 origin \ub370\uc774\ud130 \ud074\ub798\uc2a4 \ub2e4 \uc801\ud600 \uc788\ub294 df \ub9cc\ub4ec\ndf_train_crop = df_train.copy()\ndf_train_crop['img_file'] = [x[:-4] + '_crop.jpg' for x in df_train['img_file']] ","f6ab37a3":"# \uc8fc\uc758 \ud569\uc131\uc774\ub77c \ud55c\ubc88\ub9cc \uc2e4\ud589\ub418\uc5b4\uc57c \ud55c\ub2e4 *****\n# axis = 0 \uc740 \ud589\uc774 \ub354 \ub298\uc5b4\ub098\ub294 \ubc29\ud5a5\uc73c\ub85c \ubd99\uc5ec \uc8fc\ub294 \uac83\uc774\ub2e4. <-> axis = 1\n\ndf_train = pd.concat([df_train_crop, df_train], axis=0)","3071968d":"df_train","73503fb9":"def crop_boxing_img(img_name, margin=0, size=(IMAGE_SIZE,IMAGE_SIZE)):\n    if img_name.split('_')[0] == 'train':\n        PATH = TRAIN_IMG_PATH\n        data = df_train\n    else:\n        PATH = TEST_IMG_PATH\n        data = df_test\n\n    img = PIL.Image.open(os.path.join(PATH, img_name))\n    pos = data.loc[data[\"img_file\"] == img_name, ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1)\n\n    width, height = img.size\n    x1 = max(0, pos[0] - margin)\n    y1 = max(0, pos[1] - margin)\n    x2 = min(pos[2] + margin, width)\n    y2 = min(pos[3] + margin, height)\n\n    return img.crop((x1, y1, x2, y2)).resize(size)","ca4e8fdb":"%%time\n# \ud06c\ub86d\ub41c \uc774\ubbf8\uc9c0 \uacbd\ub85c\n#TRAIN_CROPPED_PATH = '..\/input\/3rd-ml-month-car-image-cropping-dataset\/train_crop'\n# \uae30\ubcf8\uacfc \ud06c\ub86d \uc11e\uc740\uac70!\nTRAIN_CROPPED_PATH = '..\/input\/train-origincrop\/train_all\/train_all'\n\n# \ud06c\ub86d\ub41c \uc774\ubbf8\uc9c0 \uacbd\ub85c\nTEST_CROPPED_PATH = '..\/input\/3rd-ml-month-car-image-cropping-dataset\/test_crop'\n# \uae30\ubcf8 \uc0ac\uc9c4\uc73c\ub85c \ud14c\uc2a4\ud2b8!\n#TEST_CROPPED_PATH = '..\/input\/2019-3rd-ml-month-with-kakr\/test'\n\n# if (os.path.isdir(TRAIN_CROPPED_PATH) == False):\n#     os.mkdir(TRAIN_CROPPED_PATH)\n\n# if (os.path.isdir(TEST_CROPPED_PATH) == False):\n#     os.mkdir(TEST_CROPPED_PATH)\n\n# for i, row in df_train.iterrows():\n#     cropped = crop_boxing_img(row['img_file'])\n#     cropped.save(os.path.join(TRAIN_CROPPED_PATH, row['img_file']))\n\n# for i, row in df_test.iterrows():\n#     cropped = crop_boxing_img(row['img_file'])\n#     cropped.save(os.path.join(TEST_CROPPED_PATH, row['img_file']))","5c0847af":"df_train['class'] = df_train['class'].astype('str')\ndf_train = df_train[['img_file', 'class']]\ndf_test = df_test[['img_file']]","2f3f0d90":"def recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\ndef precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","89373f6c":"def get_callback(model_name, patient):\n    ES = EarlyStopping(\n        monitor='val_loss', \n        patience=patient, \n        mode='min', \n        verbose=1)\n    RR = ReduceLROnPlateau(\n        monitor = 'val_loss', \n        factor = 0.5, \n        patience = patient \/ 2, \n        min_lr=0.000001, \n        verbose=1, \n        mode='min')\n    MC = ModelCheckpoint(\n        filepath=model_name, \n        monitor='val_loss', \n        verbose=1, \n        save_best_only=True, \n        mode='min')\n\n    return [ES, RR, MC]","56fbbff4":"#efficientnet download\n!pip install -U efficientnet==0.0.4\nfrom efficientnet import EfficientNetB3","7fd18762":"def get_model(model_name, iamge_size):\n    base_model = EfficientNetB3(weights='imagenet', input_shape=(iamge_size,iamge_size,3), include_top=False)\n    #base_model.trainable = False\n    model = models.Sequential()\n    model.add(base_model)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(2048, activation='relu', kernel_initializer='he_normal'))\n    model.add(layers.Dropout(0.25))\n \n    model.add(layers.Dense(196, activation='softmax', kernel_initializer='lecun_normal'))\n    model.summary()\n\n    #optimizer = optimizers.Nadam(lr=0.0002)\n    optimizer = optimizers.SGD(momentum=0.9)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc', f1_m, precision_m, recall_m])\n\n    return model","4d6fb4cc":"#ref: https:\/\/github.com\/yu4u\/cutout-random-erasing\/blob\/master\/cifar10_resnet.py\ndef get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1\/0.3, v_l=0, v_h=255, pixel_level=False):\n    def eraser(input_img):\n        img_h, img_w, img_c = input_img.shape\n        p_1 = np.random.rand()\n\n        if p_1 > p:\n            return input_img\n\n        while True:\n            s = np.random.uniform(s_l, s_h) * img_h * img_w\n            r = np.random.uniform(r_1, r_2)\n            w = int(np.sqrt(s \/ r))\n            h = int(np.sqrt(s * r))\n            left = np.random.randint(0, img_w)\n            top = np.random.randint(0, img_h)\n\n            if left + w <= img_w and top + h <= img_h:\n                break\n\n        if pixel_level:\n            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n        else:\n            c = np.random.uniform(v_l, v_h)\n\n        input_img[top:top + h, left:left + w, :] = c\n\n        return input_img\n\n    return eraser","021766bf":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    #featurewise_center= True,  # set input mean to 0 over the dataset\n    #samplewise_center=True,  # set each sample mean to 0\n    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    #samplewise_std_normalization=True,  # divide each input by its std\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=False,\n    zoom_range=0.2,\n    #shear_range=0.2,\n    #brightness_range=(1, 1.2),\n    fill_mode='nearest',\n    preprocessing_function = get_random_eraser(v_l=0, v_h=255),\n    )\n\nvalid_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    #featurewise_center= True,  # set input mean to 0 over the dataset\n    #samplewise_center=True,  # set each sample mean to 0\n    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    #samplewise_std_normalization=True  # divide each input by its std\n    )\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    #featurewise_center= True,  # set input mean to 0 over the dataset\n    #samplewise_center=True,  # set each sample mean to 0\n    #featurewise_std_normalization= True,  # divide inputs by std of the dataset\n    #samplewise_std_normalization=True,  # divide each input by its std\n    )","b3f18f6b":"skf = StratifiedKFold(n_splits=k_folds, random_state=SEED)\n#skf = KFold(n_splits=k_folds, random_state=SEED)","43ac7dbc":"j = 1\nmodel_names = []\nfor (train_index, valid_index) in skf.split(\n    df_train['img_file'], \n    df_train['class']):\n\n    traindf = df_train.iloc[train_index, :].reset_index()\n    validdf = df_train.iloc[valid_index, :].reset_index()\n\n    print(\"=========================================\")\n    print(\"====== K Fold Validation step => %d\/%d =======\" % (j,k_folds))\n    print(\"=========================================\")\n    \n    train_generator = train_datagen.flow_from_dataframe(\n        dataframe=traindf,\n        directory=TRAIN_CROPPED_PATH,\n        x_col='img_file',\n        y_col='class',\n        target_size= (IMAGE_SIZE, IMAGE_SIZE),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=BATCH_SIZE,\n        seed=SEED,\n        shuffle=True\n        )\n    \n    valid_generator = valid_datagen.flow_from_dataframe(\n        dataframe=validdf,\n        directory=TRAIN_CROPPED_PATH,\n        x_col='img_file',\n        y_col='class',\n        target_size= (IMAGE_SIZE, IMAGE_SIZE),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=BATCH_SIZE,\n        seed=SEED,\n        shuffle=True\n        )\n    \n    model_name = model_path + str(j) + '_' + 'Xception' + '.hdf5'\n    model_names.append(model_name)\n    \n    model = get_model(BASE_MODEL, IMAGE_SIZE)\n    \n    try:\n        model.load_weights(model_name)\n    except:\n        pass\n        \n    history = model.fit_generator(\n        train_generator,\n        steps_per_epoch=len(traindf.index) \/ BATCH_SIZE,\n        epochs=150, #########################################################\n        validation_data=valid_generator,\n        validation_steps=len(validdf.index) \/ BATCH_SIZE,\n        verbose=1,\n        shuffle=False,\n        callbacks = get_callback(model_name, PATIENCE)\n        )\n        \n    j+=1","8c9f5440":"test_generator = test_datagen.flow_from_dataframe(\n    dataframe=df_test,\n    directory=TEST_CROPPED_PATH,\n    x_col='img_file',\n    y_col=None,\n    target_size= (IMAGE_SIZE, IMAGE_SIZE),\n    color_mode='rgb',\n    class_mode=None,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","1f6526c2":"prediction = []\nfor i, name in enumerate(model_names):\n    model = get_model(BASE_MODEL, IMAGE_SIZE)\n    model.load_weights(name)\n    \n    test_generator.reset()\n    pred = model.predict_generator(\n        generator=test_generator,\n        steps = len(df_test)\/BATCH_SIZE,\n        verbose=1\n    )\n    prediction.append(pred)\n\ny_pred = np.mean(prediction, axis=0)","94b63a6d":"preds_class_indices=np.argmax(y_pred, axis=1)","b1e38901":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\nfinal_pred = [labels[k] for k in preds_class_indices]","030d344e":"submission = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n# if(JUST_FOR_TESTING):\n#     submission=submission[:10]\nsubmission[\"class\"] = final_pred\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","8301ced6":"based on [General base model stratifiedkfold ensemble w\/test](https:\/\/www.kaggle.com\/meditech101\/general-base-model-stratifiedkfold-ensemble-w-test) kernel.\n\nF1 score and Cutout Augmentation are applied.","ec975b64":"# \uae30\ubcf8 \uc774\ubbf8\uc9c0 + \ud06c\ub86d\ub41c \uc774\ubbf8\uc9c0\ub85c \ud559\uc2b5 \uc2dc\ucf30\uc2b5\ub2c8\ub2e4.<br>\n# Testing \ud560\ub550 \uae30\ubcf8 \uc774\ubbf8\uc9c0\uc5d0 \ub300\ud574 predict\ud588\uc2b5\ub2c8\ub2e4.<br>\n\uacb0\uacfc 0.94 \uc774\uc0c1 <br>\n\uae30\ubcf8 \ubca0\uc774\uc2a4\ucf54\ub4dc\ub294 \uacf5\uc720\ub41c \ucee4\ub110\uc911\uc5d0\uc11c \uac00\uc838\uc628 \uac83\uc784\uc744 \uc54c\ub9bd\ub2c8\ub2e4."}}