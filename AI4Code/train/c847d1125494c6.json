{"cell_type":{"a11cfdb6":"code","5163c63f":"code","070e7d99":"code","1f060de8":"code","2c7fdc89":"code","04488a3f":"code","ea2e4374":"code","380acca6":"code","1fd5bf26":"code","71bd5666":"code","b4956f9e":"code","c0d91c04":"code","2047b1a0":"code","f6e0ef14":"code","f8d26776":"code","697b6f3e":"code","878a686c":"code","d0506a43":"code","0ed2dccf":"code","9bf65eeb":"code","78d70dfa":"code","2bb5870f":"code","c4d1c5ea":"code","3a4ac66a":"code","d87e1c4e":"code","c18117bf":"code","2e6966ef":"code","1f792fc2":"code","061bf7c4":"code","2ae6cdd9":"code","e33828e1":"code","0ebb4ee9":"code","6bd0e376":"markdown","f98beb33":"markdown","b59c5a19":"markdown","ef14d6b3":"markdown","ee448bab":"markdown","a7f2d921":"markdown","13bca0fb":"markdown","2e6e081a":"markdown","a1314c78":"markdown","fb99919c":"markdown","4ad5a9c0":"markdown","f20e2b7e":"markdown","55a64399":"markdown","75c40083":"markdown","0dc4970c":"markdown","9fb9d513":"markdown","8748f702":"markdown","96a68fa0":"markdown","523a24bb":"markdown"},"source":{"a11cfdb6":"# Basic library\nimport numpy as np \nimport pandas as pd \nimport gc\n\n# Dir check\nimport os","5163c63f":"!conda install efficientnet.tfkeras","070e7d99":"!pip install efficientnet","1f060de8":"# OpenCV\nimport cv2 # Open cv\n\n# Data preprocessing\nfrom sklearn.model_selection import train_test_split # ML preprocessing\n\n# Visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Validation\nfrom sklearn.metrics import roc_auc_score\n\n# Karas\nimport keras\nfrom IPython.display import SVG\nfrom keras.utils import model_to_dot\nfrom keras.applications import InceptionV3, MobileNet\nimport efficientnet.tfkeras as efn\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model \nfrom keras.models import Sequential \nfrom keras.models import Input \nfrom keras.models import load_model\nfrom keras.layers import Dense \nfrom keras.layers import Conv2D \nfrom keras.layers import Flatten\nfrom keras.layers import MaxPool2D\nfrom keras.layers import Dropout \nfrom keras.layers import BatchNormalization\nfrom keras.layers import Activation \nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.optimizers import Adam \nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping","2c7fdc89":"sample_submission = pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/plant-pathology-2020-fgvc7\/train.csv\")","04488a3f":"# image loading\nimg_size=299\ntrain_image = []\n\nfor name in train[\"image_id\"]:\n    path = '..\/input\/plant-pathology-2020-fgvc7\/images\/'+name+'.jpg' \n    img=cv2.imread(path) \n    image = cv2.resize(img, (img_size,img_size), interpolation=cv2.INTER_AREA)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n    train_image.append(image)\n    \ntrain[\"img_data\"] = train_image","ea2e4374":"# Visualization some sample\ncol = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\nfig, ax = plt.subplots(4,4, figsize=(15,15))\nfor c in col:\n    for i in range(4):\n        if c == col[0]:\n            sample = train[train[c]==1]\n            ax[0,i].set_axis_off()\n            ax[0,i].imshow(sample[\"img_data\"].values[i])\n            ax[0,i].set_title(\"{}\".format(c))\n        elif c == col[1]:\n            sample = train[train[c]==1]\n            ax[1,i].set_axis_off()\n            ax[1,i].imshow(sample[\"img_data\"].values[i])\n            ax[1,i].set_title(\"{}\".format(c))\n        elif c == col[2]:\n            sample = train[train[c]==1]\n            ax[2,i].set_axis_off()\n            ax[2,i].imshow(sample[\"img_data\"].values[i])\n            ax[2,i].set_title(\"{}\".format(c))\n        else:\n            sample = train[train[c]==1]\n            ax[3,i].set_axis_off()\n            ax[3,i].imshow(sample[\"img_data\"].values[i])\n            ax[3,i].set_title(\"{}\".format(c))","380acca6":"# image loading\nimg_size=299\ntest_image = []\n\nfor name in test[\"image_id\"]:\n    path = '..\/input\/plant-pathology-2020-fgvc7\/images\/'+name+'.jpg'\n    img = cv2.imread(path)\n    image = cv2.resize(img, (img_size, img_size), interpolation=cv2.INTER_AREA)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    test_image.append(image)","1fd5bf26":"fig, ax = plt.subplots(1,4, figsize=(15,6))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(test_image[i])","71bd5666":"class preprocessing():\n    # image data:Series data, target:target data dateframe, size:image size\n    def __init__(self, image_data, target, size):\n        self.image = image_data\n        self.target = target\n        self.size = size\n        pass\n    \n    # Dimension change and create train and val data\n    # test_size:split size\n    def dataset(self, test_size, random_state):   \n        self.test_size = test_size\n        self.random_state = random_state\n        \n        # Data dimension\n        X_Train = np.ndarray(shape=(len(self.image), self.size, self.size, 3), dtype=np.float32)\n        # Change to np.ndarray\n        for i in range(len(self.image)):\n            X_Train[i]=self.image[i]\n            i=i+1\n    \n        # Scaling\n        X_Train = X_Train\/255\n\n        # change to np.array\n        self.target = np.array(self.target.values)\n        \n        # split train and val data\n        X_train, X_val, y_train, y_val = train_test_split(X_Train, self.target, test_size=self.test_size, random_state=self.random_state)\n        return X_train, X_val, y_train, y_val","b4956f9e":"# data\nimage_data = train[\"img_data\"]\ntarget = train[['healthy', 'multiple_diseases', 'rust', 'scab']]\nsize = img_size\n\n# preprocessing\ntest_size=0.2\nrandom_state=20\n\nprepro = preprocessing(image_data, target, size)\nX_train, X_val, y_train, y_val = prepro.dataset(test_size, random_state)","c0d91c04":"def define_model(model_name, size):\n    model = model_name(include_top=False, weights=\"imagenet\")\n    \n    inputs = Input(shape=(size, size, 3))\n    x = model(inputs)\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dense(256, activation='relu')(x)\n    output = Dense(4, activation=\"softmax\", name=\"root\")(x)\n        \n    model = Model(inputs, output)\n        \n    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n        \n    return model","2047b1a0":"def exe_model(model, X_train, y_train, X_val, y_val, save_file):\n    save_file = str(save_file)\n    batch_size=16\n    valid_samples=32\n    train_samples = len(X_train) - valid_samples\n    \n    # Data augmentation\n    datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.2,\n                                 height_shift_range=0.2, horizontal_flip=True)\n    datagen.fit(X_train)\n    \n    # early stopping and model checkpoint\n    es = EarlyStopping(monitor='val_loss', patience=15, verbose=1)\n    mc = ModelCheckpoint(save_file, monitor=\"val_loss\", verbose=1, save_best_only=True)\n    \n    hist = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),\n                               steps_per_epoch=train_samples\/batch_size, \n                               epochs=100, callbacks=[es, mc], \n                               validation_data=datagen.flow(X_val, y_val, batch_size=batch_size),\n                               validation_steps=valid_samples\/batch_size)\n    return hist","f6e0ef14":"def train_curve(hist_data):\n    train_loss = hist_data.history[\"loss\"]\n    val_loss = hist_data.history[\"val_loss\"]\n    train_acc = hist_data.history[\"accuracy\"]\n    val_acc = hist_data.history[\"val_accuracy\"]\n    \n    fig, ax = plt.subplots(1,2, figsize=(20,6))\n    # loss\n    ax[0].plot(range(len(train_loss)), train_loss, label=\"train_loss\")\n    ax[0].plot(range(len(val_loss)), val_loss, label=\"val_loss\")\n    ax[0].set_xlabel(\"epochs\")\n    ax[0].set_ylabel(\"loss\")\n    ax[0].set_yscale(\"log\")\n    ax[0].legend()\n    # accuracy\n    ax[1].plot(range(len(train_acc)), train_acc, label=\"train_acc\")\n    ax[1].plot(range(len(val_acc)), val_acc, label=\"val_acc\")\n    ax[1].set_xlabel(\"epochs\")\n    ax[1].set_ylabel(\"accuracy\")\n    ax[1].set_yscale(\"log\")\n    ax[1].legend()","f8d26776":"SVG(model_to_dot(InceptionV3(), dpi=70).create(prog='dot', format='svg'))","697b6f3e":"# model compile\nincept = define_model(InceptionV3, 299)\nincept.summary()","878a686c":"SVG(model_to_dot(Model(incept.layers[0].input, incept.layers[4].output), dpi=70).create(prog='dot', format='svg'))","d0506a43":"# save file\nsave_file = \"incept_v1\"\n# Execute model\nhist_incept = exe_model(incept, X_train, y_train, X_val, y_val, save_file)","0ed2dccf":"# ROC AUC score\ny_pred_incept = load_model(save_file).predict(X_val)\n\n# print ROC AUC score\nprint(\"ROC AUC score:{}\".format(roc_auc_score(y_true=y_val, y_score=y_pred_incept, average=\"weighted\").round(3)))","9bf65eeb":"# Training curve\ntrain_curve(hist_incept)","78d70dfa":"SVG(model_to_dot(MobileNet(), dpi=70).create(prog='dot', format='svg'))","2bb5870f":"# model compile\nmobilen = define_model(MobileNet, 299)\nmobilen.summary()","c4d1c5ea":"SVG(model_to_dot(Model(mobilen.layers[0].input, mobilen.layers[4].output), dpi=70).create(prog='dot', format='svg'))","3a4ac66a":"# save file\nsave_file = \"mobilen_v1\"\n# Execute model\nhist_mobilen = exe_model(mobilen, X_train, y_train, X_val, y_val, save_file)","d87e1c4e":"# ROC AUC score\ny_pred_mobilen = load_model(save_file).predict(X_val)\n\n# print ROC AUC score\nprint(\"ROC AUC score:{}\".format(roc_auc_score(y_true=y_val, y_score=y_pred_mobilen, average=\"weighted\").round(3)))","c18117bf":"# Training curve\ntrain_curve(hist_mobilen)","2e6966ef":"del X_train, X_val, y_train, y_val\ngc.collect()","1f792fc2":"# Data dimension\nX_Test = np.ndarray(shape=(len(test_image), 299, 299, 3), dtype=np.float32)\n# Change to np.ndarray\nfor i in range(len(test_image)):\n    X_Test[i]=test_image[i]\n    i=i+1\n# Scaling\nX_Test = X_Test\/255","061bf7c4":"# prediction Inception\nY_test_incept = load_model(\"incept_v1\").predict(X_Test)","2ae6cdd9":"# Create submit data\ncol = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\n\n# Inception V3\nY_test_incept = pd.DataFrame(Y_test_incept, columns=col)\nsubmit_incept = pd.DataFrame({})\nsubmit_incept[\"image_id\"] = test[\"image_id\"]\nsubmit_incept[col] = Y_test_incept\nsubmit_incept.to_csv('submit_incept.csv', index=False)","e33828e1":"# prediction Inception\nY_test_mobilen = load_model(\"mobilen_v1\").predict(X_Test)","0ebb4ee9":"# Create submit data\ncol = [\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]\n\n# Inception V3\nY_test_mobilen = pd.DataFrame(Y_test_mobilen, columns=col)\nsubmit_mobilen = pd.DataFrame({})\nsubmit_mobilen[\"image_id\"] = test[\"image_id\"]\nsubmit_mobilen[col] = Y_test_mobilen\nsubmit_mobilen.to_csv('submit_mobilen.csv', index=False)","6bd0e376":"# NasNet Mobile","f98beb33":"# Libraries","b59c5a19":"### 1) Inception V3\n### 2) NasNet Mobile","ef14d6b3":"# Dataloading","ee448bab":"### Execution calculate","a7f2d921":"*reference)\nhttps:\/\/www.kaggle.com\/urayukitaka\/comparing-resnet-model","13bca0fb":"# Test data prediction","2e6e081a":"### Create preprocessing class","a1314c78":"# Comparing, Inception and NasNetMobile","fb99919c":"### Train data image","4ad5a9c0":"# Datapreprocessing","f20e2b7e":"### Model difinition","55a64399":"# Define model and execution and validation curve function","75c40083":"# Inception V3 model","0dc4970c":"### Training curve","9fb9d513":"## The following Models were used to compare the performance of Plant Pathology 2020 image classification.The results were compared by ROC AUC score.","8748f702":"### NasNet Mobile prediction","96a68fa0":"### Test data image","523a24bb":"### InceptionV3 prediction"}}