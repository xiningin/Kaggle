{"cell_type":{"34b46845":"code","e4df5af5":"code","5a534a3a":"code","406a923c":"code","c544ad63":"code","6f0c4029":"code","21504848":"code","df185b77":"code","225e0f9a":"code","3158a6ad":"code","fa574345":"code","fed4c367":"code","892b828c":"code","9fb80557":"code","573d1b48":"code","700010d7":"code","3023d151":"code","7f984afc":"code","e5288582":"code","00ff2db5":"code","82249f03":"code","f871ba0e":"code","ce618915":"code","6c3d6f38":"code","820a64d0":"code","1a7e1cdc":"code","18441d3d":"code","53c7b96d":"code","e3c25f98":"code","36a5723e":"markdown","bd6f69a2":"markdown","563bb0f5":"markdown","015efc01":"markdown","98f11c2c":"markdown","d3303738":"markdown"},"source":{"34b46845":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cross_validation import ShuffleSplit,train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport statsmodels.api as sm\nfrom sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nimport folium\nfrom mpl_toolkits.basemap import Basemap","e4df5af5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\ndf=pd.read_csv('..\/input\/revised-notice-of-property-value-rnopv.csv')\ndf.head()","5a534a3a":"df_na= (df.isnull().sum() \/ len(df)) * 100\ndf_na = df_na.drop(df_na[df_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing %' :df_na})\nprint(df.columns.values)\nmissing_data.head(30)","406a923c":"df1=df.drop(['Country ','EASE','RC4','RC3','RC5'],axis=1)","c544ad63":"df_na= (df1.isnull().sum() \/ len(df)) * 100\ndf_na = df_na.drop(df_na[df_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing %' :df_na})\nmissing_data.head(20)","6f0c4029":"df2= df1[np.isfinite(df['BBL'])]","21504848":"df_na= (df2.isnull().sum() \/ len(df)) * 100\ndf_na = df_na.drop(df_na[df_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing %' :df_na})\nmissing_data.head(30)","df185b77":"\ndf2=df2.dropna(axis=1,how='any')","225e0f9a":"print(df2.isnull().values.any())\n","3158a6ad":"from plotly import __version__\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nx = df2['MAILED DATE']\ndata = [go.Histogram(x=x)]\n\niplot(data, filename='basic histogram')","fa574345":"df2=df2.drop(['MAILED DATE','Address 1','Address 2 ','Address 3 ','City, State, Zip ','NAME  ','NTA','RC2'],axis=1)\ndf2.head()\n#data like Adress, zip code are impossible to calculate into pcize","fed4c367":"x = df2['BLD Class']\ndata = [go.Histogram(x=x)]\n\niplot(data, filename='basic histogram')#lots of signs","892b828c":"x = df2['RC 1']\ndata = [go.Histogram(x=x)]\n\niplot(data, filename='basic histogram')","9fb80557":"x = df2['Borough']\ndata = [go.Histogram(x=x)]\n\niplot(data, filename='basic histogram')#few parameters","573d1b48":"df2.head()","700010d7":"df2 = pd.get_dummies(df2, prefix='BLD Class_', columns=['BLD Class'])\ndf2 = pd.get_dummies(df2, prefix='RC 1', columns=['RC 1'])\ndf2 = pd.get_dummies(df2, prefix='Borough_', columns=['Borough'])","3023d151":"df2.head()","7f984afc":"import matplotlib.pyplot as plt\n\nplt.matshow(df2.corr())\nplt.colorbar()\nplt.show()\nprint(df.columns.values)","e5288582":"#take transaction columns to other dataset\ntransactions=df2[['ORIGINAL MARKET VALUE','ORIGINAL ASSESSED VALUE','ORIGINAL EXEMPTION',\n                           'ORIGINAL TRANSITIONAL  ASSESSED VALUE ','ORIGINAL TRANSITIONAL EXEMPTION',\n                           'ORIGINAL TAXABLE VALUE','REVISED MARKET VALUE','REVISED ASSESSED VALUE',\n                           'REVISED  EXEMPTION','REVISED TRANSITIONAL ASSESSED VALUE','REVISED TRANSITIONAL EXEMPTION',\n                            'REVISED TAXABLE VALUE']].copy()\n\nplt.matshow(transactions.corr())\nplt.colorbar()\nplt.show()","00ff2db5":"df3=df2.drop(['ORIGINAL ASSESSED VALUE','ORIGINAL EXEMPTION',\n                'ORIGINAL TRANSITIONAL  ASSESSED VALUE ','ORIGINAL TRANSITIONAL EXEMPTION',\n                'ORIGINAL TAXABLE VALUE','REVISED MARKET VALUE','REVISED ASSESSED VALUE',\n                'REVISED  EXEMPTION','REVISED TRANSITIONAL ASSESSED VALUE',\n              'REVISED TRANSITIONAL EXEMPTION','REVISED TAXABLE VALUE'],axis=1)\ndf3.head()","82249f03":"labels1=df3.drop(['ORIGINAL MARKET VALUE'],axis=1)\nX1=labels1.loc[:,:].values\ny=df2.loc[:,'ORIGINAL MARKET VALUE'].values\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_classification\nprint(labels.columns.values)\nprint(labels.columns.values.shape)\nprint(X.shape)","f871ba0e":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\n\nX_train, X_test, y_train, y_test = train_test_split(X1, y, train_size=0.8 , random_state=100)\nscaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(scaler.transform(X_train))\nX_test_scaled = pd.DataFrame(scaler.transform(X_test))\n\n","ce618915":"from sklearn.metrics import r2_score\nreg = RandomForestRegressor(n_estimators=45,random_state=0, n_jobs=-1)\nmodel = reg.fit(X_train_scaled, y_train)\nmodel.score(X_train_scaled, y_train)\ny_pred= model.predict(X_test_scaled)\nprint(\"R2 for test\",r2_score(y_test,y_pred))","6c3d6f38":"df2.astype(bool).sum(axis=0)\ndf2 = df2.rename(columns={'ORIGINAL MARKET VALUE': 'VALUE'})\ndf2 = df2.rename(columns={'ORIGINAL TRANSITIONAL EXEMPTION': 'OTE'})\ndf2 = df2.rename(columns={'ORIGINAL TAXABLE VALUE': 'OTV'})\n\ndf2 = df2[df2.VALUE != 0]\ndf2 = df2[df2.OTE != 0]\ndf2 = df2[df2.OTV != 0]\ndf2.astype(bool).sum(axis=0)","820a64d0":"labels=df2.drop(['VALUE'],axis=1)\nX=labels.loc[:,:].values\ny=df2.loc[:,'VALUE'].values","1a7e1cdc":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8 , random_state=100)\nscaler = StandardScaler().fit(X_train)\nX_train_scaled = pd.DataFrame(scaler.transform(X_train))\nX_test_scaled = pd.DataFrame(scaler.transform(X_test))","18441d3d":"from sklearn.metrics import r2_score\nreg = RandomForestRegressor(n_estimators=45,random_state=0, n_jobs=-1)\nmodel = reg.fit(X_train_scaled, y_train)\nmodel.score(X_train_scaled, y_train)\ny_pred= model.predict(X_test_scaled)\nprint(\"R2 for test\",r2_score(y_test,y_pred))","53c7b96d":"feature_importances = pd.DataFrame(reg.feature_importances_,\n                                   index = labels.columns.values,\n                                    columns=['importance']).sort_values('importance',ascending=False)\nfeature_importances\n","e3c25f98":"imp=feature_importances[feature_importances['importance']>0.001]\nf, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation='90')\nsns.barplot(x=imp.index, y=imp.importance,palette=\"deep\")\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Feature importance', fontsize=15)\nplt.title('Feature importance using Random Forest model', fontsize=15)","36a5723e":"Very poor result. \nNow the same calculations with other costs.\nWe have to remamber there are lots of 0 values, which we have to remove","bd6f69a2":"Building corelation WITHOUT other cost parameters-based on X1","563bb0f5":"Looks like 'MAILED DATE\" is in two months-it should not have any influence on prices","015efc01":"Much better result. It means the real valu can not predict based only on presented building parameters, there are other important hiden parameters","98f11c2c":"The highest influence has original assessed value and next revised assessed value, revised market value. The other values are not so much important","d3303738":"Let find out if we can predict Original Market value only using \"building parameters\", what means without othect parameters corelated with taxt, cost etc\ndf5 and X1 are corelated withou other cost parameters\ndf4 and X are aditionaly corelated with cost parametes"}}