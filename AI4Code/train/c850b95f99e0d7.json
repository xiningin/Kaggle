{"cell_type":{"8da937f6":"code","b7db80cc":"code","b5ecad94":"code","3c622b5a":"code","5d8fff1f":"code","9ccaa8c4":"code","64d7d1d9":"code","655e3056":"code","f710d0e6":"code","570b245f":"code","6ba25b04":"code","1c3fd4cf":"code","85a7309b":"code","e329c419":"code","f5b17085":"code","88d9b333":"code","edf053bd":"code","4dbc9a31":"code","1f316ca4":"code","74bf8149":"code","773a7f82":"code","85a9e671":"code","4017e5bd":"code","6238aa32":"code","5c52d39b":"code","92e0ed23":"code","cf3cf7ac":"code","8372f43f":"code","d477e4a1":"code","6e77322a":"markdown","94a44e3b":"markdown","87bace11":"markdown","47fb981c":"markdown","4e65e478":"markdown","e72538d6":"markdown","a14d8232":"markdown","71b8983f":"markdown","c9151bce":"markdown","bdb6046d":"markdown"},"source":{"8da937f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b7db80cc":"df = pd.DataFrame({'Sentences':['Manthan is a good boy', 'Google watch people', 'People watch google', 'I am an Indian boy. I love my country'],\n                   'Review': [1, 0, 1, 1]})","b5ecad94":"df.head()","3c622b5a":"df['lower_sent'] = df['Sentences'].str.lower()","5d8fff1f":"df.head()","9ccaa8c4":"punc = '''!()-[]{};:'\"\\,<>.\/?@#$%^&*_~'''\nsent = \"Who, are <you?>\"\nfor w in sent:\n    if w in punc:\n        sent = sent.replace(w,\"\")\n        \nsent","64d7d1d9":"## Regex \nimport re\nsent = \"Who, are <you?>\"\nwithout_punc = re.sub(r'[^\\w\\s]', '', sent)\nwithout_punc","655e3056":"df1 = pd.DataFrame({'Sents':['Complete your homework ASAP', 'GM Students', 'I was abesent bcoz i was ill','Thnx bro']})\ndf1.head()","f710d0e6":"short_to_long = {'ASAP': 'As soon as possible', 'GM': 'Good Morning', 'bcoz': 'Because', 'Thnx': 'Thanks'}","570b245f":"short_to_long_sent = []\nfor sent in df1['Sents']:\n    for w in sent.split():\n        if w in short_to_long:\n            sent = sent.replace(w, short_to_long[w])\n    short_to_long_sent.append(sent)\ndf1['short_to_long_sent'] = short_to_long_sent","6ba25b04":"df1.head()","1c3fd4cf":"incorr_sent = \"Computr is grat Prouct\"\nfrom textblob import TextBlob\ntextblb = TextBlob(incorr_sent)\ncorr_sent = textblb.correct().string","85a7309b":"corr_sent","e329c419":"df.head()","f5b17085":"from nltk.corpus import stopwords\nprint(stopwords.words('english'))","88d9b333":"stop_words = stopwords.words('english')\nafter_removing_stopwords = []\nfor sent in df['lower_sent']:\n    new_sent = []\n    for word in sent.split():\n        if not word in stop_words:\n            new_sent.append(word)\n    after_removing_stopwords.append(new_sent)\ndf['after removing stopwords'] = after_removing_stopwords\ndf.head()","edf053bd":"sent = \"Rohit play \ud83c\udfcf\"\nsent1 = \"Mayank have 3 \ud83c\udfcd\ufe0f\"\nimport emoji\nprint(emoji.demojize(sent))\nprint(emoji.demojize(sent1))","4dbc9a31":"sent = 'NLP stands for Natural Language Processing'\nsent1 = 'We can tokenize words using nltk library. Also we can use str.split() method.'","1f316ca4":"from nltk.tokenize import word_tokenize, sent_tokenize","74bf8149":"word_tokenize(sent)","773a7f82":"word_tokenize(sent1)","85a9e671":"sent_tokenize(sent1)","4017e5bd":"import spacy\nnlp = spacy.load('en_core_web_sm')","6238aa32":"d1 = nlp(sent1)\ns = []\nfor tk in d1:\n    s.append(tk.text)\ns","5c52d39b":"from nltk.stem.porter import PorterStemmer","92e0ed23":"ps = PorterStemmer()","cf3cf7ac":"sent = 'talk talking talked talks story university'\n\ndef stemming(sent):\n    new_sent = []\n    for word in sent.split():\n        new_sent.append(ps.stem(word))\n    return new_sent\nprint(stemming(sent))","8372f43f":"from nltk.stem import WordNetLemmatizer\nlm = WordNetLemmatizer()","d477e4a1":"sent = \"meeting stories university dogs smiling feeling mice feet\"\ndef lemmatizing(sent):\n    new_sent = []\n    for word in sent.split():\n        new_sent.append(lm.lemmatize(word))\n    return new_sent\nprint(lemmatizing(sent))","6e77322a":"## Remove Stopwords","94a44e3b":"## Remove unneccessary keywords like 'HTML Tags', 'Punctuations', 'URLS'","87bace11":"#### Sometimes stemming is not giving the proper word. Like 'Story'-->>'Stori', 'university'-->>'univers'","47fb981c":"## Whatsapp chats have many short words like ASAP, GN, OMG, bcoz, Thnx,... \n## we have to change this keywords into the original meaningful word.","4e65e478":"## Lemmatization\n### Aim of lemmatization is to return the base or dictionary form of a word.\n### Lemmatization is more powerful than stemming.","e72538d6":"## Convert all sentences into lowercase letter ","a14d8232":"## Spelling Correction","71b8983f":"## Tokenization","c9151bce":"## Handling EMOJIS","bdb6046d":"## Stemming\n### Used for retrieving the information from the system.  We can form different words in given root words. Like, root word is 'talk' and different forms are: 'talks', 'talking', 'talked'\n### root word is also known as stem word"}}