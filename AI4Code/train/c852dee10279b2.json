{"cell_type":{"7f40ac34":"code","0e8b51d8":"code","67f32eb7":"code","3dc36231":"code","71cb03a2":"code","71d71253":"code","1981c350":"code","57fb3c00":"code","c2274736":"code","6b34f6c5":"code","a55cd7fe":"code","37135073":"code","a9d4eb67":"code","10c3d26c":"code","0233eb4f":"markdown","5d7715be":"markdown","3a730b94":"markdown","467eb839":"markdown","32d44a1c":"markdown","3aa79f80":"markdown","88fd97d1":"markdown","b3cbe485":"markdown","4f2296d7":"markdown","ab99cbda":"markdown"},"source":{"7f40ac34":"import os\nimport random \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\nimport cv2\nfrom tqdm import tqdm_notebook,tnrange\nfrom glob import glob\nfrom itertools import chain\nfrom skimage.io import imread,imshow,concatenate_images\nfrom skimage.morphology import label\nfrom skimage.transform import resize\nfrom skimage.color import rgb2gray\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","0e8b51d8":"train_files = []\nmask_files = glob('..\/input\/lgg-mri-segmentation\/kaggle_3m\/*\/*_mask*')\n\nfor i in mask_files:\n    train_files.append(i.replace('_mask',''))\n\nprint(train_files[:10])\nprint(mask_files[:10])","67f32eb7":"fig=plt.figure(figsize=(10,10))\nfor i in range(1,10):\n    fig.add_subplot(3,3,i)\n    img_path=train_files[i]\n    mask_path=mask_files[i]\n    img=cv2.imread(img_path)\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    mask=cv2.imread(mask_path)\n    plt.imshow(img)\n    plt.imshow(mask,alpha=0.4)\n    \nplt.show()","3dc36231":"df=pd.DataFrame(data={\"filename\":train_files,\"mask\":mask_files})\ndf_train,df_test=train_test_split(df,test_size=0.1)\ndf_train,df_val=train_test_split(df_train,test_size=0.2)\nprint(df_train.shape)\nprint(df_val.shape)\nprint(df_test.shape)","71cb03a2":"def train_generator(data_frame,batch_size,aug_dict,image_color_mode=\"rgb\",mask_color_mode=\"grayscale\",image_save_prefix=\"image\",mask_save_prefix=\"mask\",save_to_dir=None,target_size=(256,256),seed=1):\n    \n    image_datagen=ImageDataGenerator(**aug_dict)\n    mask_datagen=ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"filename\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n    \n    train_gen=zip(image_generator,mask_generator)\n    \n    for (img,mask) in train_gen:\n        img , mask =adjust_data(img,mask)\n        yield (img,mask)\n        \ndef adjust_data(img,mask):\n        img=img\/255\n        mask=mask\/255\n        mask[mask>0.5]=1\n        mask[mask<=0.5]=0\n        \n        return (img,mask)","71d71253":"def dice_coef(y_true,y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n    cal=K.sum(y_truef*y_predf)\n    \n    return ((2*cal+100)\/(K.sum(y_truef)+K.sum(y_predf)+100))\n\ndef dice_coef_loss(y_true,y_pred):\n    return -dice_coef(y_true,y_pred)\n\ndef iou(y_true,y_pred):\n    intersection=K.sum(y_true*y_pred)\n    sum_=K.sum(y_true+y_pred)\n    jac=(intersection+100)\/(sum_-intersection+100)\n    return jac\n\ndef jac_distance(y_true,y_pred):\n    y_truef=K.flatten(y_true)\n    y_predf=K.flatten(y_pred)\n    \n    return -iou(y_true,y_pred)","1981c350":"def unet(input_size=(256,256,3)):\n    inputs = layers.Input(input_size)\n    \n    conv1 = layers.Conv2D(64, (3, 3), padding='same')(inputs)\n    bn1 = layers.Activation('relu')(conv1)\n    conv1 = layers.Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = layers.BatchNormalization(axis=3)(conv1)\n    bn1 = layers.Activation('relu')(bn1)\n    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = layers.Conv2D(128, (3, 3), padding='same')(pool1)\n    bn2 = layers.Activation('relu')(conv2)\n    conv2 = layers.Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = layers.BatchNormalization(axis=3)(conv2)\n    bn2 = layers.Activation('relu')(bn2)\n    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = layers.Conv2D(256, (3, 3), padding='same')(pool2)\n    bn3 = layers.Activation('relu')(conv3)\n    conv3 = layers.Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = layers.BatchNormalization(axis=3)(conv3)\n    bn3 = layers.Activation('relu')(bn3)\n    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = layers.Conv2D(512, (3, 3), padding='same')(pool3)\n    bn4 = layers.Activation('relu')(conv4)\n    conv4 = layers.Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = layers.BatchNormalization(axis=3)(conv4)\n    bn4 = layers.Activation('relu')(bn4)\n    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = layers.Conv2D(1024, (3, 3), padding='same')(pool4)\n    bn5 = layers.Activation('relu')(conv5)\n    conv5 = layers.Conv2D(1024, (3, 3), padding='same')(bn5)\n    bn5 = layers.BatchNormalization(axis=3)(conv5)\n    bn5 = layers.Activation('relu')(bn5)\n\n    up6 = layers.concatenate([layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = layers.Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = layers.Activation('relu')(conv6)\n    conv6 = layers.Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = layers.BatchNormalization(axis=3)(conv6)\n    bn6 = layers.Activation('relu')(bn6)\n\n    up7 = layers.concatenate([layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = layers.Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = layers.Activation('relu')(conv7)\n    conv7 = layers.Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = layers.BatchNormalization(axis=3)(conv7)\n    bn7 = layers.Activation('relu')(bn7)\n\n    up8 = layers.concatenate([layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = layers.Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = layers.Activation('relu')(conv8)\n    conv8 = layers.Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = layers.BatchNormalization(axis=3)(conv8)\n    bn8 = layers.Activation('relu')(bn8)\n\n    up9 = layers.concatenate([layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = layers.Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = layers.Activation('relu')(conv9)\n    conv9 = layers.Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = layers.BatchNormalization(axis=3)(conv9)\n    bn9 = layers.Activation('relu')(bn9)\n\n    conv10 = layers.Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n    return models.Model(inputs=[inputs], outputs=[conv10])","57fb3c00":"model=unet()\nmodel.summary()","c2274736":"EPOCHS = 150\nBATCH_SIZE = 32\nlearning_rate = 1e-4\nBATCH_SIZE = 32\ndecay_rate = learning_rate \/ EPOCHS\nopt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=decay_rate, amsgrad=False)","6b34f6c5":"train_generator_args = dict(rotation_range=0.2,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=(256, 256))\n    \ntest_gener = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=(256, 256))\n    \nmodel = unet(input_size=(256, 256, 3))\n\n\n\n\nmodel.compile(optimizer=opt, loss=dice_coef_loss, metrics=[\"binary_accuracy\", iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('unet_brain_mri_seg.hdf5', verbose=1, save_best_only=True)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) \/ BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = test_gener,\n                    validation_steps=len(df_val) \/ BATCH_SIZE)","a55cd7fe":"a = history.history\n\nlist_traindice = a['dice_coef']\nlist_testdice = a['val_dice_coef']\n\nlist_trainjaccard = a['iou']\nlist_testjaccard = a['val_iou']\n\nlist_trainloss = a['loss']\nlist_testloss = a['val_loss']\nplt.figure(1)\nplt.plot(list_testloss, 'b-')\nplt.plot(list_trainloss,'r-')\nplt.xlabel('iteration')\nplt.ylabel('loss')\nplt.title('loss graph', fontsize = 15)\nplt.figure(2)\nplt.plot(list_traindice, 'r-')\nplt.plot(list_testdice, 'b-')\nplt.xlabel('iteration')\nplt.ylabel('accuracy')\nplt.title('accuracy graph', fontsize = 15)\nplt.show()","37135073":"model =models.load_model('unet_brain_mri_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","a9d4eb67":"test_gen = train_generator(df_test, BATCH_SIZE,\n                                dict(),\n                                target_size=(256, 256))\nresults = model.predict(test_gen, steps=len(df_test) \/ BATCH_SIZE)\nprint(\"Test lost: \",results[0])\nprint(\"Test IOU: \",results[1])\nprint(\"Test Dice Coefficent: \",results[2])","10c3d26c":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['filename'].iloc[index])\n    img = cv2.resize(img ,(256, 256))\n    img = img \/ 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","0233eb4f":"# 2-Load image's path and mask's path","5d7715be":"# 3-Visualize some examples","3a730b94":"# 9-plot model figures","467eb839":"# 1-Necessary Imports","32d44a1c":"# 6-Define Special loss function and metrics","3aa79f80":"# 8-Train the model","88fd97d1":"# 10-Load model to evaluate on test data","b3cbe485":"# 5-Data generator and augmentation","4f2296d7":"# 7-Define U-Net network","ab99cbda":"# 4-Create dataframe and split data into test and train"}}