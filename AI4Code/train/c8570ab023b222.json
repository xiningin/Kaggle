{"cell_type":{"9eeb8aef":"code","d653b92f":"code","578d7e0f":"code","414ec88c":"code","50cbd8cd":"code","cfc7b13e":"code","dacdc263":"code","27084c1d":"code","a7e596f6":"code","53327873":"code","ceceb2b8":"code","05e98da6":"code","e46900dd":"code","55380138":"code","d4a35d09":"code","a80c3b2e":"code","60ee0161":"code","11dbea2d":"markdown","0078dbd5":"markdown","18e1f7b6":"markdown","ea35d7ef":"markdown","835468c2":"markdown","a8dd87a5":"markdown","3139b564":"markdown","b9afb37d":"markdown","4adf592b":"markdown","42b30d7e":"markdown","4cfb02dc":"markdown","d343106f":"markdown","f1b73d34":"markdown","065cc5e1":"markdown","1dd31943":"markdown","112d5397":"markdown"},"source":{"9eeb8aef":"import json\nimport langdetect\nimport re\nimport time\nimport unidecode\nimport ipywidgets as widgets\nimport numpy as np\nimport pandas as pd\nfrom ipywidgets import interact\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold, cross_validate, train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import FunctionTransformer, LabelEncoder, MultiLabelBinarizer","d653b92f":"train = pd.read_json('..\/input\/train.json')\ntest = pd.read_json('..\/input\/test.json')\ntrain.head()","578d7e0f":"df = pd.concat([train, test], sort=False)\ndf['ingredients_text'] = df['ingredients'].apply(lambda x: ', '.join(x))\ndf['num_ingredients'] = df['ingredients'].apply(lambda x: len(x))\nraw_ingredients = [ingredient for ingredients in df.ingredients.values for ingredient in ingredients]\ndf.head()","414ec88c":"from matplotlib import pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(16,4))\nsns.countplot(x='num_ingredients', data=df)","50cbd8cd":"df[df['num_ingredients'] <= 1]","cfc7b13e":"[ingredient for ingredient in raw_ingredients if len(ingredient) <= 2]","dacdc263":"' '.join(sorted([char for char in set(' '.join(raw_ingredients)) if re.findall('[^A-Za-z]', char)]))","27084c1d":"list(set([ingredient for ingredient in raw_ingredients if re.findall('[A-Z]+', ingredient)]))[:5]","a7e596f6":"list(set([ingredient for ingredient in raw_ingredients if '\u2019' in ingredient]))","53327873":"list(set([ingredient for ingredient in raw_ingredients if re.findall('-', ingredient)]))[:5]","ceceb2b8":"list(set([ingredient for ingredient in raw_ingredients if re.findall('[0-9]', ingredient)]))[:5]","05e98da6":"units = ['inch', 'oz', 'lb', 'ounc', '%'] # ounc is a misspelling of ounce?\n\n@interact(unit=units)\ndef f(unit):\n    ingredients_df = pd.DataFrame([ingredient for ingredient in raw_ingredients if unit in ingredient], columns=['ingredient'])\n    return ingredients_df.groupby(['ingredient']).size().reset_index(name='count').sort_values(['count'], ascending=False)","e46900dd":"keywords = [\n    # It indicates the cusine directly\n    'american', 'greek', 'filipino', 'indian', 'jamaican', 'spanish', 'italian', 'mexican', 'chinese', 'thai',\n    'vietnamese', 'cajun', 'creole', 'french', 'japanese', 'irish', 'korean', 'moroccan', 'russian',\n    # Region names I found in the dataset\n    'tokyo', 'shaoxing', 'california'\n]\n\n@interact(keyword=keywords)\ndef f(keyword):\n    ingredients_df = pd.DataFrame([ingredient for ingredient in raw_ingredients if keyword in ingredient], columns=['ingredient'])\n    return ingredients_df.groupby(['ingredient']).size().reset_index(name='count').sort_values(['count'], ascending=False)","55380138":"accents = ['\u00e2', '\u00e7', '\u00e8', '\u00e9', '\u00ed', '\u00ee', '\u00fa']\n\n@interact(accent=accents)\ndef f(accent):\n    ingredients_df = pd.DataFrame([ingredient for ingredient in raw_ingredients if accent in ingredient], columns=['ingredient'])\n    return ingredients_df.groupby(['ingredient']).size().reset_index(name='count').sort_values(['count'], ascending=False)","d4a35d09":"lemmatizer = WordNetLemmatizer()\ndef preprocess(ingredients):\n    ingredients = ' '.join(ingredients).lower().replace('-', ' ')\n    ingredients = re.sub(\"\\d+\", \"\", ingredients)\n    return [lemmatizer.lemmatize(ingredient) for ingredient in ingredients.split()]\n\ningredients_df = df.groupby(['cuisine'])['ingredients'].sum().apply(lambda ingredients: preprocess(ingredients)).reset_index()\nunique_ingredients = []\nfor cuisine in ingredients_df['cuisine'].unique():\n    target = set(ingredients_df[ingredients_df['cuisine'] == cuisine]['ingredients'].values[0])\n    others = set(ingredients_df[ingredients_df['cuisine'] != cuisine]['ingredients'].sum())\n    unique_ingredients.append({\n        'cuisine': cuisine,\n        'ingredients': target - others\n    })\npd.DataFrame(unique_ingredients, columns=['cuisine', 'ingredients'])","a80c3b2e":"text_languages = []\nfor text in [\n    'ein, zwei, drei, vier',\n    'pur\u00e9e',\n    'taco',\n    'tofu',\n    'tangzhong',\n    'xuxu',\n]:\n    text_languages.append({\n        'text': text,\n        'detected language': langdetect.detect(text)\n    })\npd.DataFrame(text_languages, columns=['text', 'detected language'])","60ee0161":"from IPython.display import clear_output\n\ningredients = ['romaine lettuce', 'Eggs', 'Beef demi-glace', 'Sugar 10g', 'Pumpkin pur\u00e9e', 'Kahl\u00faa']\nlabels = [widgets.Label(ingredient) for ingredient in ingredients]\n\nlower_checkbox = widgets.Checkbox(value=False, description='lower', indent=False)\nlemmatize_checkbox = widgets.Checkbox(value=False, description='lemmatize', indent=False)\nremove_hyphens_checkbox = widgets.Checkbox(value=False, description='remove hyphens', indent=False)\nremove_numbers_checkbox = widgets.Checkbox(value=False, description='remove numbers', indent=False)\nstrip_accents_checkbox = widgets.Checkbox(value=False, description='strip accents', indent=False)\n\nlemmatizer = WordNetLemmatizer()\ndef lemmatize(sentence):\n    return ' '.join([lemmatizer.lemmatize(word) for word in sentence.split()])\nassert lemmatize('eggs') == 'egg'\n\ndef remove_numbers(sentence):\n    words = []\n    for word in sentence.split():\n        if re.findall('[0-9]', word): continue\n        if len(word) > 0: words.append(word)\n    return ' '.join(words)\n\ndef update_ingredients(widget):\n    for i, ingredient in enumerate(ingredients):\n        processed = ingredient\n        if lower_checkbox.value: processed = processed.lower()\n        if lemmatize_checkbox.value: processed = lemmatize(processed)\n        if remove_hyphens_checkbox.value: processed = processed.replace('-', ' ')\n        if remove_numbers_checkbox.value: processed = remove_numbers(processed)\n        if strip_accents_checkbox.value: processed = unidecode.unidecode(processed)\n        if processed == ingredient:\n            labels[i].value = ingredient\n        else:\n            labels[i].value = f'{ingredient} => {processed}'\n\nlower_checkbox.observe(update_ingredients)\nlemmatize_checkbox.observe(update_ingredients)\nremove_hyphens_checkbox.observe(update_ingredients)\nremove_numbers_checkbox.observe(update_ingredients)\nstrip_accents_checkbox.observe(update_ingredients)\n\ndisplay(widgets.VBox([\n    widgets.Box([lower_checkbox, lemmatize_checkbox, remove_hyphens_checkbox, remove_numbers_checkbox, strip_accents_checkbox]),\n    widgets.VBox(labels)\n]))","11dbea2d":"## 3. Apostrophes\n\n- \"Zatarain\u2019s Jambalaya Mix\"\n- \"Breakstone\u2019s Sour Cream\"\n- \"sheep\u2019s milk cheese\"\n\nIt'd be useful if there are many apostrophes for possession in the dataset but","0078dbd5":"## 4. Hyphens ( `-` )\n\nIt might be okay to replace \"-\" with \" \".\n\n- \"chicken-apple sausage\"\n- \"chocolate-hazelnut spread\"\n- \"bone-in chicken breasts\"","18e1f7b6":"## 8. Accents\n\nSome accents are used only in a specific region. Can we use this information?\n\n- \"pumpkin pur**\u00e9**e\"\n- \"cr\u00e8me fra**\u00ee**che\"\n- \"Ni**\u00e7**oise olives\"","ea35d7ef":"## 0. Outliers\n\nI found some recipes which consist of only 1 ingredient like below.\n\n- water => Japanese\n- butter => Indian\n- butter => French\n\nIt could get models confused. Unfortunately, such recipes exist in the test dataset though.","835468c2":"## 1. Special characters\n\nSee what special characters are contained.\n\n  - \"Bertolli**\u00ae** Alfredo Sauce\"\n  - \"Progresso**\u2122** Chicken Broth\"\n  - \"green bell pepper**,** slice\"\n  - \"half **&** half\"\n  - \"asafetida **\\(**powder**\\)**\"\n  - \"Spring**!** Water\"","a8dd87a5":"Let's see single-ingredient recipes.","3139b564":"Btw, are all ingredients valid? For example, do ingredients consisting of less than 2 characters make sense?","b9afb37d":"## 10. Language\n\nRelated to accents, we can guess which language the ingredient is by looking at the sequence of characters.\n\n- tofu => Japanese\n- pur\u00e9e => French\n\nCan we extract language information from ingredients? In this case, we need to think about how to detect the ingredient language.","4adf592b":"## 11. Misspellings\n\nI found that there are some misspellings in the dataset.\n\n- ounc (ounce)\n- wasabe (wasabi)\n- ...","42b30d7e":"## 7. Region names","4cfb02dc":"## 5. Numbers\n\nNumbers show quantity or density.\n\n- \"1% low-fat milk\"\n- \"40% less sodium taco seasoning\"\n- \"mexican style 4 cheese blend\"\n\nStrictly speaking, quantities can be a factor of identifying the cuisine but only a few ingredients come with quantity in this dataset.","d343106f":"## 6. Units\n\nUnits come with numbers.\n\n  - \"(15 **oz**.) refried beans\"\n  - \"2 1\/2 to 3 **lb**. chicken, cut into serving pieces\"\n  - \"pork chops, 1 **inch** thick\"\n  \nSome units are used only in a specific region. It might be useful for classifiers.","f1b73d34":"# Normalize\n\nI saw some ingredients which contain special characters, misspellings, ... I should probabily normalize ingredients.","065cc5e1":"## 2. Upper cases\n\nIt may be a proper noun.\n\n- Company name\n  - \"**Oscar Mayer** Deli Fresh Smoked Ham\"\n- Region name\n  - \"**Shaoxing** wine\"\n  - \"**California** bay leaves\"\n  - \"**Italian** parsley leaves\"","1dd31943":"# What are ingredients?\n\nIn the previous kernel (https:\/\/www.kaggle.com\/rejasupotaro\/representations-for-ingredients), I experimented which representation is better for this dataset without looking at what ingredients itself are.\n\nViewing ingredients, I found some interesting things which might help to understand cuisines.\n\n0. Outliers\n1. Special characters\n2. Upper cases\n3. Apostrophes\n4. Hyphens\n5. Numbers\n6. Units\n7. Region names\n8. Accents\n9. Unique ingredients\n10. Language\n11. Misspellings","112d5397":"## 9. Unique ingredients\n\nSome ingredients are used only in a specific region.\n\nI picked some ingredients used in `cuisine == 'japanese'`.\n\n### brown rice => genmai => \u7384\u7c73\n\n<img src=\"https:\/\/kinarino.k-img.com\/system\/press_eye_catches\/000\/025\/367\/aea26213187ab5c5f69ed43c3480e24038c3d06f.jpg?1477883419\" width=\"480\">\n\n### bonito => katsuo => \u9c39\n\n<img src=\"http:\/\/qoonell.me\/wordpress\/wp-content\/uploads\/2015\/10\/20070412155803000.jpg\" width=\"480\">\n\n### salmon roe => ikura => \u3044\u304f\u3089\n\n<img src=\"https:\/\/cdn.macaro-ni.jp\/image\/summary\/33\/33186\/40f8825cdd5438a6361373fae156a7b5.jpg\" width=\"480\">"}}