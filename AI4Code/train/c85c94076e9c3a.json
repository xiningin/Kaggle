{"cell_type":{"94c1c01d":"code","53905234":"code","b84e861e":"code","1a203460":"code","02067da4":"code","94533139":"code","23f21a07":"code","c8a08446":"code","8294a43a":"code","4c153829":"code","e16775e6":"code","a90119f9":"code","f8d1a972":"code","c6c5dc03":"code","83c36b8a":"code","cc33e998":"code","b9c793c8":"code","264c47c7":"code","e299cae0":"code","6725a910":"code","837f3c5c":"code","267f054a":"code","2679c908":"code","f20531c0":"code","89598c97":"code","8e1d7795":"code","a65ac26c":"code","674c25bc":"code","2b1023ae":"code","225387c4":"code","72e014c6":"code","ed11b608":"code","5daab81f":"code","0148f537":"code","aca0a253":"code","1468cbf3":"code","5aa9c7e7":"code","0b07df4b":"code","d884532f":"markdown","95e8ebf5":"markdown","8d20e450":"markdown","c357a5bd":"markdown","33d2a999":"markdown","9c0f7fb9":"markdown","d380b199":"markdown","ebac9e7a":"markdown","b0d756a2":"markdown","d77fd240":"markdown","5988e85e":"markdown","71b97ce0":"markdown","cce1f104":"markdown","2282ef57":"markdown","873452d0":"markdown","ac658755":"markdown","6a5961bb":"markdown","f711420a":"markdown","7a1fd65a":"markdown","bafda666":"markdown","50c30308":"markdown","428e43ec":"markdown","e30f50c3":"markdown","47edbf4f":"markdown","98aac5d4":"markdown","5a13d8e8":"markdown"},"source":{"94c1c01d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n#import library\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns ","53905234":"# load dataset\ndf=pd.read_csv('\/kaggle\/input\/marketing-data\/marketing_data.csv')","b84e861e":"# view the frist 5 rows \ndf.head()","1a203460":"# view the last 5 rows \ndf.tail()","02067da4":"# view the Random Sample  from dataset \ndf.sample(5)","94533139":"#Bcasic Infprmation on Data\ndf.info()","23f21a07":"# checking for duplicates\ndf.duplicated().all()","c8a08446":"# checking for duplicates\ndf.isnull().sum()","8294a43a":"#copy data \ndf1=df.copy()","4c153829":"# clean up column names that contain whitespace\n\ndf1.rename(columns={' Income ':'Income'}, inplace = True)\ndf1[\"Income\"]=df1[\"Income\"].str.replace(\"$\",\"\")\n\n\n# transform Income column to a numerical\n\ndf1[\"Income\"]=df1[\"Income\"].str.replace(\",\",\"\")\ndf1[\"Income\"]=df1[\"Income\"].astype(float)","e16775e6":"plt.grid();\nplt.title('Income',size=15);\nsns.boxplot(x='Income', data=df1);","a90119f9":"sns.histplot(df1['Income'],kde=20);","f8d1a972":"#Impute null values in Income, using median value (to avoid skewing of the mean due to outliers):\n\na=df1['Income'].median()\ndf1['Income'].fillna(a,inplace=True)","c6c5dc03":"#transform Dt_Customer column to a Date time\ndf1['Dt_Customer']=pd.to_datetime(df['Dt_Customer'])","83c36b8a":"df1['Customer_Age_When_Enrolled'] = df1['Dt_Customer'].dt.year - df1['Year_Birth']","cc33e998":"Total_Spent=['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']\nTotal_Purchases=['NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth']\n","b9c793c8":"df1['Total_Spent']=(df1['MntWines']+df1['MntFruits']+df1['MntMeatProducts']+df1['MntFishProducts']+df1['MntSweetProducts']+df1['MntGoldProds'])\ndf1['Total_Purchases']=(df1['NumDealsPurchases']+df1['NumWebPurchases']+df1['NumCatalogPurchases']+df1['NumStorePurchases']+df1['NumWebVisitsMonth'])\n\n# Merging columns Kids at home and Teenagers at home\ndf1['Kids_Teen_at_home'] = df1['Kidhome'] + df1['Teenhome']\n","264c47c7":"# Reducing columns\ndf1 = df1.drop(['ID','Kidhome','Teenhome'], axis = 1)","e299cae0":"df1.describe().T","6725a910":"df1.head()","837f3c5c":"sns.boxplot(x='Year_Birth', data=df1);","267f054a":"# Delete Outliers\ndf1=df1[df1['Year_Birth']>=1920]","2679c908":"plt.grid();\nplt.title('Education',size=15);\nsns.countplot(x = df1['Education'],palette = 'rocket_r');","f20531c0":"m = df1['Marital_Status'].value_counts().to_frame('Count')\nsns.set_palette('rocket_r')\nplt.figure(figsize = (6, 6))\nplt.pie(m['Count'], labels = m.index, explode = (0.1, 0, 0, 0, 0, 1, 2.5, 4), shadow = True, autopct = '%1.1f%%')\nplt.show()","89598c97":"cnt = 0\nmax_in_row = 1\nfor x in Total_Spent:\n    plt.figure(cnt\/\/max_in_row, figsize=(25,8))\n    plt.subplot(1, max_in_row, (cnt)%max_in_row + 1)\n    plt.title(x, fontsize=20)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.xlabel(x, fontsize=16)\n    plt.ylabel('Density', fontsize=16)\n    sns.kdeplot(data=df1, x=x, hue=\"Marital_Status\", fill=True, common_norm=False, alpha=.5, linewidth=0);\n    cnt += 1\n","8e1d7795":"plt.grid();\nplt.title('Income',size=15);\nsns.boxplot(x='Income', data=df1);","a65ac26c":"sns.histplot(df1['Income'],kde=20);","674c25bc":"df1=df1[df1['Income']<150000]","2b1023ae":"plt.grid();\nplt.title('Income',size=15);\nsns.histplot(df1['Income'],kde=20);","225387c4":"pd.value_counts(df1['Kids_Teen_at_home'])","72e014c6":"plt.grid();\nplt.title('Kids_Teen_at_home',size=15);\nsns.countplot(x = df1['Kids_Teen_at_home'],palette = 'rocket_r');","ed11b608":"cnt = 0\nmax_in_row = 1\nfor x in Total_Spent:\n    plt.figure(cnt\/\/max_in_row, figsize=(25,8))\n    plt.subplot(1, max_in_row, (cnt)%max_in_row + 1)\n    plt.title(x, fontsize=20)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.xlabel(x, fontsize=16)\n    plt.ylabel('Density', fontsize=16)\n    sns.kdeplot(data=df1, x=x, hue=\"Kids_Teen_at_home\", fill=True, common_norm=False, alpha=.5, linewidth=0);\n    cnt += 1\n","5daab81f":"cnt = 0\nmax_in_row = 1\nfor x in Total_Purchases:\n    plt.figure(cnt\/\/max_in_row, figsize=(25,8))\n    plt.subplot(1, max_in_row, (cnt)%max_in_row + 1)\n    plt.title(x, fontsize=20)\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.xlabel(x, fontsize=16)\n    plt.ylabel('Density', fontsize=16)\n    sns.kdeplot(data=df1, x=x, hue=\"Kids_Teen_at_home\", fill=True, common_norm=False, alpha=.5, linewidth=0);\n    cnt += 1\n","0148f537":"df2=df1.copy()","aca0a253":"sns.set()\ndf2.set_index('Dt_Customer',inplace=True)\ndf2.head()","1468cbf3":"df2[['Total_Purchases']].plot(figsize=(40,10));","5aa9c7e7":"df2[['Total_Spent']].plot(figsize=(40,10));","0b07df4b":"df2[['Customer_Age_When_Enrolled']].plot(figsize=(40,10));","d884532f":"### - Merging some columns","95e8ebf5":"### Let us now explore the dataset :\n","8d20e450":"# project : Marketing Data\n","c357a5bd":"### 1- Total_Purchases","33d2a999":"# Data Wrangling","9c0f7fb9":"## Dt_Customer","d380b199":"## Year_Birth","ebac9e7a":"## Kids_Teen_at_home","b0d756a2":"## Time Series :","d77fd240":"### 3-Customer_Age_When_Enrolled","5988e85e":"## Education","71b97ce0":"## Kids_Teen_at_home & Total_Spent","cce1f104":"### - Reducing columns","2282ef57":"### -Null Values ","873452d0":"## Marital_Status","ac658755":"## Kids_Teen_at_home & Total_Purchases","6a5961bb":"## Data Cleaning ","f711420a":"### - Create more variables","7a1fd65a":" Will impute null values with median value, to avoid effects of outliers on imputation value","bafda666":"### 2-Total_Spent","50c30308":"### checking for duplicates and null value :    ","428e43ec":"## Marital_Status & Total_Spent","e30f50c3":"## Income","47edbf4f":"* At what age customer enrolled in the company","98aac5d4":"The feature Income contains 24 null values ,  let us Plot this feature to identify best strategy for imputation","5a13d8e8":"# Exploratory Data Analysis"}}