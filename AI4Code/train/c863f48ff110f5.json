{"cell_type":{"ee450f8e":"code","3801e6f9":"code","006fb227":"code","fc8ac4cb":"code","d2bc07f1":"code","3c8b6dcd":"code","6779160a":"code","6f7fef37":"code","03c61e11":"code","6f1e81c5":"markdown"},"source":{"ee450f8e":"import torch\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","3801e6f9":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Resize(256),\n     transforms.CenterCrop(256),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = datasets.ImageFolder(root='..\/input\/flowers-recognition\/', transform=transform)\n\n# trainset = datasets.ImageFolder(root='.\/flowers', transform=transform)\n\ntrainloader = torch.utils.data.DataLoader(\n    trainset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=2,\n    collate_fn=None,\n    pin_memory=False,\n )\n\ntestset = datasets.ImageFolder(root='..\/input\/flowers-recognition', transform=transform)\n\n# trainset = datasets.ImageFolder(root='.\/flowers', transform=transform)\n\ntestloader = torch.utils.data.DataLoader(\n    testset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=2,\n    collate_fn=None,\n    pin_memory=False,\n )\n\n\nclasses = ('daisy', 'dandelion', 'rose', 'sunflower','tulip')\n\ntrainloader","006fb227":"def imshow(img):\n    img = img \/ 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()","fc8ac4cb":"dataiter = iter(trainloader)\n\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nimages.size()","d2bc07f1":"class NeuralNetwork(nn.Module):\n\n    def __init__(self):\n        super(NeuralNetwork,self).__init__()\n\n        # self.layer1 = nn.Sequential(nn.Conv2d(3,1,3),nn.BatchNorm2d(1),nn.ReLU())\n        # self.layer2 = nn.Sequential(nn.Conv2d(1,1,3),nn.BatchNorm2d(1),nn.ReLU())\n        # self.layer3 = nn.Sequential(nn.Conv2d(1,1,3),nn.BatchNorm2d(1),nn.ReLU())\n        # self.layer4 = nn.Sequential(nn.Conv2d(1,1,3),nn.BatchNorm2d(1),nn.ReLU())\n        # self.fc1 = nn.Linear(1*248*248,5)\n\n        self.layer1 = nn.Sequential(nn.Conv2d(3,16,3),nn.BatchNorm2d(16),nn.ReLU(),nn.MaxPool2d(2))\n        self.layer2 = nn.Sequential(nn.Conv2d(16,32,3),nn.BatchNorm2d(32),nn.ReLU(),nn.MaxPool2d(2))\n        self.layer3 = nn.Sequential(nn.Conv2d(32,16,3),nn.BatchNorm2d(16),nn.ReLU(),nn.MaxPool2d(2))\n        self.layer4 = nn.Sequential(nn.Conv2d(16,32,3),nn.BatchNorm2d(32),nn.ReLU(),nn.MaxPool2d(2))\n\n\n\n        self.fc1 = nn.Linear(32*14*14,5)\n\n    def forward(self,x):\n        #print(x.shape)\n        out = self.layer1(x)\n        #print(out.shape)\n        out = self.layer2(out)\n        #print(out.shape)\n        out = self.layer3(out)\n        #print(out.shape)\n        out = self.layer4(out)\n        #print(out.shape)\n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n\n        return out","3c8b6dcd":"NN = NeuralNetwork()","6779160a":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(NN.parameters(), lr=0.001, momentum=0.9)","6f7fef37":"for epoch in range(2):\n    print('Epoch Start')\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        \n        inputs, labels = data\n\n        optimizer.zero_grad()\n        outputs = NN(inputs)\n\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        if (i+1) % 2000 == 0:\n                print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}' \n                .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n    print('Epoch End')\n\n\n\nprint('Training Finished')\n\n    ","03c61e11":"NN.eval()  \nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in testloader:\n\n        outputs = NN(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print('Accuracy of the model on the 10000 test images: {}%'\\\n          .format(100 * correct \/ total))\n","6f1e81c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session"}}