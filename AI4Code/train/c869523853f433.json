{"cell_type":{"3edc3aa8":"code","ea2e5598":"code","cb1530c4":"code","63bf4465":"code","5f5d379e":"code","d93a4db4":"code","973042ce":"code","272eb390":"code","78c70c5e":"code","5ddbce1e":"code","76257d27":"code","8aab40e9":"code","27184e0a":"code","df4fda9b":"code","6c92e6db":"markdown","8de0bb0c":"markdown","d96647df":"markdown","052652dc":"markdown","aa770163":"markdown","13e7f67a":"markdown","b3279686":"markdown","6f597aac":"markdown","9508885b":"markdown","a5318238":"markdown","7086a30a":"markdown"},"source":{"3edc3aa8":"import pandas as pd \nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Lasso\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom matplotlib import pyplot as plt\n\nprint(\"Done importing.\")","ea2e5598":"df_train = pd.read_csv(\"..\/input\/insureme-historical-insurance-claims\/insureme_train.csv\")\nX_train = df_train.drop(columns=[\"claims\"]) \ny_train = df_train[\"claims\"]","cb1530c4":"df_val = pd.read_csv(\"..\/input\/insureme-historical-insurance-claims\/insureme_val.csv\")\nX_val = df_val.drop(columns=[\"claims\"]) \ny_val = df_val[\"claims\"]","63bf4465":"pipe = make_pipeline(StandardScaler(), Lasso(alpha=1)).fit(X_train, y_train)\n\ny_hat_val = pipe.predict(X_val)\nmse_val_alpha_1 = mean_squared_error(y_hat_val, y_val)\n\nprint(\"MSE on validation set\", mse_val_alpha_1)","5f5d379e":"pipe = make_pipeline(StandardScaler(), Lasso(alpha=5)).fit(X_train, y_train)\n\ny_hat_val = pipe.predict(X_val)\nmse_val_alpha_5 = mean_squared_error(y_hat_val, y_val)\n\nprint(\"MSE on validation set\", mse_val_alpha_5)","d93a4db4":"pipe = make_pipeline(StandardScaler(), Lasso(alpha=10)).fit(X_train, y_train)\n\ny_hat_val = pipe.predict(X_val)\nmse_val_alpha_10 = mean_squared_error(y_hat_val, y_val)\n\nprint(\"MSE on validation set\", mse_val_alpha_10)","973042ce":"pipe = make_pipeline(StandardScaler(), Lasso(alpha=15)).fit(X_train, y_train)\n\ny_hat_val = pipe.predict(X_val)\nmse_val_alpha_15 = mean_squared_error(y_hat_val, y_val)\n\nprint(\"MSE on validation set\", mse_val_alpha_15)","272eb390":"pipe = make_pipeline(StandardScaler(), Lasso(alpha=20)).fit(X_train, y_train)\n\ny_hat_val = pipe.predict(X_val)\nmse_val_alpha_20 = mean_squared_error(y_hat_val, y_val)\n\nprint(\"MSE on validation set\", mse_val_alpha_20)","78c70c5e":"plt.plot([1, 5, 10, 15, 20], [mse_val_alpha_1, mse_val_alpha_5, mse_val_alpha_10, mse_val_alpha_15, mse_val_alpha_20])","5ddbce1e":"\nalphas = [1, 5, 10, 15, 20] # This is the list of alphas we want to try\n\nmse_list = [] # This is an empty list of numbers that I'll use to store the MSEs for different alphas later on\n\n\nfor alpha in alphas: # This means that the indented code underneath will be repeated for each value of alpha declared above\n\n    pipe = make_pipeline(StandardScaler(), Lasso(alpha=alpha)).fit(X_train, y_train)\n\n    y_hat_val = pipe.predict(X_val)\n    mse_val = mean_squared_error(y_hat_val, y_val)\n    \n    mse_list.append(mse_val) # Here I add the calculated MSE to the list for later use\n\n    print(\"MSE on validation set\", mse_val, f\"(alpha {alpha})\")\n    \n    \nplt.plot(alphas, mse_list) # I plot the results from the list of alphas and the corresponding MSEs calculated","76257d27":"X_all = pd.concat([X_train, X_val])\ny_all = pd.concat([y_train, y_val])","8aab40e9":"pipe = make_pipeline(StandardScaler(), Lasso(alpha=10))","27184e0a":"cross_val_scores = cross_val_score(pipe, X_all, y_all, scoring=make_scorer(mean_squared_error))","df4fda9b":"print(\"All scores:\", cross_val_scores)\nprint(\"Mean score:\", cross_val_scores.mean())","6c92e6db":"## First we read training data","8de0bb0c":"### First let's join the training and validation sets in one single data frame (there's no need to keep them apart now, since Scikit Learn's cross validation functionality will split the data for us):","d96647df":"## Now we train several models with different values of alpha...\n\n## and we calculate the MSE on **validation data**\n\n### Remember that alpha determines how much we regularize the model's learned weights","052652dc":"# Cross-validation","aa770163":"### As you can see, there is a sweet spot. When alpha that is too low, the model fits the training data too well at the cost of not generalizing well to unseen data. When alpha is too high the model is too constrained so it can't model the target variable well, and thus the performance is also degraded.","13e7f67a":"## Let's plot the error curve on the validation set","b3279686":"## First we define our pipeline:\n### (No need to fit it)","6f597aac":"## Now we perform cross-validation by using Scikit Learn's \"cross_val_score\" function\n\n### We also used a gimmick to force it to use mean_squared_error as the validation metric\n\n### BTW, five folds are used by default but this can be configured","9508885b":"## And now we read validation data","a5318238":"## In case you were wondering...\n\n### I'll show a more elegant way to code the above, without having to repeat the same code to try out different values of alpha","7086a30a":"### Now we print out the scores computed on each of the five validation folds \n### and also the mean score (the average of the five), which is what we care about the most"}}