{"cell_type":{"1c10f2ad":"code","0735196b":"code","1fadcecb":"code","967f73e8":"code","83ffea0d":"code","278dc542":"code","14f88159":"code","0a9aead4":"code","22143a8c":"code","16a67c47":"code","2589e948":"code","ab11192a":"code","ce37a728":"code","f39008dd":"code","54af3a37":"code","683c4136":"code","a188a590":"code","828452d4":"code","da495daa":"code","00f74011":"code","df74fc2c":"code","7e7ad5e1":"code","7e523f2a":"code","3f82509d":"code","ea62fba7":"code","b05a6739":"code","8a9c97b5":"code","a107c64f":"code","c704dcb5":"code","3300cf18":"markdown","a1828091":"markdown","5afbf226":"markdown","638aeaa5":"markdown","70110d9e":"markdown","70a383a9":"markdown","2607425e":"markdown","af48b754":"markdown","0fa32448":"markdown","ad909ced":"markdown","40d10e89":"markdown","5e356b12":"markdown","539fcaff":"markdown","55d8252a":"markdown","9ae223d5":"markdown","bba26f80":"markdown","0f1642eb":"markdown","04246fd4":"markdown","a7f29182":"markdown","44c37dec":"markdown","fbb4486a":"markdown","61f97e65":"markdown"},"source":{"1c10f2ad":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pandas_profiling as pp\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","0735196b":"#train_df = pd.read_csv('..\/input\/titanic\/train.csv')\n#test_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntrain_df = pd.read_csv('train.csv')\ntest_df = pd.read_csv('test.csv')\nmerge = [train_df, test_df]\nmerge_df = pd.concat([train_df, test_df])","1fadcecb":"pp.ProfileReport(train_df, title = 'Pandas Profiling report of \"Train\" set', html = {'style':{'full_width': True}})","967f73e8":"pp.ProfileReport(test_df, title = 'Pandas Profiling report of \"Test\" set', html = {'style':{'full_width': True}})","83ffea0d":"train_df.info()","278dc542":"test_df.info()","14f88159":"train_df=train_df.drop(\"PassengerId\",axis=1)\ntrain_df=train_df.drop(\"Name\",axis=1)\ntrain_df=train_df.drop(\"Ticket\",axis=1)\ntrain_df=train_df.drop(\"Cabin\",axis=1)","0a9aead4":"train_df.head()","22143a8c":"test_df=test_df.drop(\"Name\",axis=1)\ntest_df=test_df.drop(\"Ticket\",axis=1)\ntest_df=test_df.drop(\"Cabin\",axis=1)","16a67c47":"test_df.head()","2589e948":"data = [train_df, test_df]\n\nfor dataset in data:\n    mean = train_df[\"Age\"].mean()\n    std = test_df[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    # compute random numbers between the mean, std and is_null\n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    # fill NaN values in Age column with random values generated\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = train_df[\"Age\"].astype(int)\ntrain_df[\"Age\"].isnull().sum()","ab11192a":"common_value = 'S'\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(common_value)","ce37a728":"test_df = test_df.fillna(test_df['Fare'].mean())","f39008dd":"train_df.info()","54af3a37":"test_df.info()","683c4136":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df[\"Sex\"]= le.fit_transform(train_df[\"Sex\"])\nprint(train_df[\"Sex\"])","a188a590":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntest_df[\"Sex\"]= le.fit_transform(test_df[\"Sex\"])\nprint(test_df[\"Sex\"])","828452d4":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df[\"Embarked\"]= le.fit_transform(train_df[\"Embarked\"])\nprint(train_df[\"Embarked\"])","da495daa":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntest_df[\"Embarked\"]= le.fit_transform(test_df[\"Embarked\"])\nprint(test_df[\"Embarked\"])","00f74011":"train_df.head()","df74fc2c":"test_df.head()","7e7ad5e1":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n''' OR\nX_train = train_df[:, 0:-1]\nY_train = train_df[:, -1]\nX_test  = test_df[:, 1:]\n'''","7e523f2a":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","3f82509d":"print(X_train)","ea62fba7":"print(Y_train)","b05a6739":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0)\nclassifier.fit(X_train, Y_train)\nY_pred = classifier.predict(X_test)\n\n''' Other Algorithms\n\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear', random_state = 0)\nclassifier.fit(X_train, Y_train)\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\nclassifier.fit(X_train, Y_train)\n\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, Y_train)\n\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\nfrom sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, Y_train)\n\nfrom xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train, Y_train)\n'''","8a9c97b5":"from sklearn.metrics import accuracy_score\nclassifier.score(X_train, Y_train)\nclassifier = round(classifier.score(X_train, Y_train) * 100, 2)\nclassifier","a107c64f":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })","c704dcb5":"submission.to_csv('submission.csv', index=False)","3300cf18":"## Accuracy score","a1828091":"### Updated head()","5afbf226":"### 'sex' in Train & Test set","638aeaa5":"### 'Test' set","70110d9e":"### 'Embarked' in Train & Test set","70a383a9":"# Part 2 - Training the Classification model","2607425e":"# Titanic: \n**I Got the best results by using Kernel SVM with 84% accuracy**\n---\n\n*  Part 1 - Data Preprocessing\n*  Part 2 - Training the Classification model\n*  Part 3 - Creating a submission.csv","af48b754":"### 'Age' in Train & Test set","0fa32448":"## Importing the dataset","ad909ced":"### Updated info()","40d10e89":"# Part 3 - Creating a submission.csv","5e356b12":"### 'Train' set","539fcaff":"# Part 1 - Data Preprocessing","55d8252a":"## Spliting the Train & Test datasets","9ae223d5":"## Taking care of misssing data","bba26f80":"## Encoding categorical data ","0f1642eb":"### 'Fare' in Test set","04246fd4":"## Dataset information","a7f29182":"## Feature Scaling","44c37dec":"### 'Embarked' in Train set","fbb4486a":"## Dropping unnecessary columns","61f97e65":"## Importing libraries"}}