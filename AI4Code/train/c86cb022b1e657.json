{"cell_type":{"066a4e7b":"code","caca91c7":"code","857fc101":"code","ad925b23":"code","5066c705":"code","f431b2e2":"code","7db5ddb3":"code","a51f00d7":"code","fe24672a":"code","6323d6d9":"code","a599219f":"code","66e76cc5":"code","56cce1bc":"code","d954c2e0":"code","8c3aa66d":"code","623648d5":"code","6d6983ac":"code","b42ccc99":"code","08f34f2b":"code","ebe4c879":"code","d9dd1800":"code","2702234e":"code","ea7ca595":"code","cc73b15e":"code","bd8ec202":"code","e669b2c0":"code","aefe63ce":"code","d02121cb":"code","c965ae54":"code","2f5ac75e":"code","dd11b9d2":"code","a988734a":"code","85fb6bc2":"code","08af0e14":"code","8bd345c6":"code","a41795e8":"markdown","9c74b206":"markdown","45e6267c":"markdown","e737fcd3":"markdown","8f01c01c":"markdown","619660c2":"markdown","495db7c1":"markdown","c40e3a91":"markdown","518badaa":"markdown","66bcca8b":"markdown","4917745c":"markdown","601ed388":"markdown","96ed6126":"markdown","f0fb77ee":"markdown","b8f4e73e":"markdown","af4c055d":"markdown","02fccfae":"markdown","4c055d8e":"markdown","ab4c809e":"markdown","b6d4151a":"markdown","2a230c42":"markdown","d6f5d468":"markdown","fd7934d8":"markdown","154fabc8":"markdown"},"source":{"066a4e7b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","caca91c7":"data_di = {'Feature' :['enrollee_id','city','city_ development _index','gender','relevent_experience','enrolled_university',\n                    'education_level','major_discipline','experience','company_size','company_type','last_new_job',\n                    'training_hours','target 0','target 1'],\n           'Explanation':['Unique ID for candidate','City code','Developement index of the city (scaled)',\n                          'Gender of candidate','Relevant experience of candidate',\n                          'Type of University course enrolled if any',\n                        'Education level of candidate','Education major discipline of candidate',\n                        'Candidate total experience in years','No of employees in current employers company',\n                        'Type of current employer','Difference in years between previous job and c.',\n                        'training hours completed','Not looking for job change','looking for job change']    \n}\ndata_dict = pd.DataFrame.from_dict(data_di)\ndata_dict.reset_index(drop=True, inplace=True)\ndata_dict","857fc101":"df_train = pd.read_csv('..\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ndf_train.head()","ad925b23":"df_train.info()","5066c705":"df_train.describe()","f431b2e2":"df_train.describe(include=[object])","7db5ddb3":"df_train.isnull().sum()","a51f00d7":"df_train = df_train.fillna(method='ffill')\ndf_train = df_train.fillna(method='bfill')\n#Using Forward fill Method we fill all Null Values.","fe24672a":"df_train.isnull().sum()","6323d6d9":"plt.figure(figsize=(16,6))\nsns.set_style('darkgrid')\nsns.countplot(x='gender',data=df_train)\nplt.show()","a599219f":"df_train.drop('enrollee_id',axis=1,inplace=True)\n# As enrollment_id  dosent contribute for model Prediction Hence We Drop the Feature.","66e76cc5":"plt.figure(figsize=(16,6))\ndf_train.boxplot()","56cce1bc":"features = ['city_development_index','training_hours']","d954c2e0":"#sns.set_style('dark')\nfor col in features:\n    plt.figure(figsize=(15,4))\n    plt.subplot(131)\n    sns.distplot(df_train[col], label=\"skew: \" + str(np.round(df_train[col].skew(),2)))\n    plt.legend()\n    plt.subplot(132)\n    sns.boxplot(df_train[col])\n    plt.subplot(133)\n    stats.probplot(df_train[col], plot=plt)\n    plt.tight_layout()\n    plt.show()","8c3aa66d":"df_cap = df_train.copy()","623648d5":"def iqr_capping(df, cols, factor):\n    \n    for col in cols:\n        \n        q1 = df[col].quantile(0.25)\n        q3 = df[col].quantile(0.75)\n        \n        iqr = q3 - q1\n        \n        upper_whisker = q3 + (factor*iqr)\n        lower_whisker = q1 - (factor*iqr)\n        \n        df[col] = np.where(df[col]>upper_whisker, upper_whisker,\n                 np.where(df[col]<lower_whisker, lower_whisker, df[col]))","6d6983ac":"iqr_capping(df_cap, features, 1.5)","b42ccc99":"for col in features:\n    plt.figure(figsize=(16,4))\n    \n    plt.subplot(141)\n    sns.distplot(df_train[col], label=\"skew: \" + str(np.round(df_train[col].skew(),2)))\n    plt.title('Before')\n    plt.legend()\n    \n    plt.subplot(142)\n    sns.distplot(df_cap[col], label=\"skew: \" + str(np.round(df_cap[col].skew(),2)))\n    plt.title('After')\n    plt.legend()\n    \n    plt.subplot(143)\n    sns.boxplot(df_train[col])\n    plt.title('Before')\n    \n    plt.subplot(144)\n    sns.boxplot(df_cap[col])\n    plt.title('After')\n    plt.tight_layout()\n    plt.show()","08f34f2b":"from sklearn.feature_selection import VarianceThreshold\ndf_num = df_train.select_dtypes(include=np.number)\nX = df_num\n\nv_threshold = VarianceThreshold(threshold=0)\nv_threshold.fit(X)\nprint(v_threshold.get_support())\nprint(v_threshold.get_params())","ebe4c879":"cor = df_train.corr()\ncor.style.applymap(lambda x: 'background-color : green' if x>0.1 else '')","d9dd1800":"plt.figure(figsize=(20,9))\nsns.pairplot(df_train,hue='target')\nplt.show()","2702234e":"df_train.head()","ea7ca595":"df_train.relevent_experience.value_counts()","cc73b15e":"df_train.city.value_counts()# Label Encoding...","bd8ec202":"X = df_train.drop('target',axis=1)\ny = df_train.target","e669b2c0":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nX['city'] = le.fit_transform(X['city'])","aefe63ce":"X['gender'] = le.fit_transform(X['gender'])\nX['relevent_experience'] = le.fit_transform(X['relevent_experience'])\nX['enrolled_university'] = le.fit_transform(X['enrolled_university'])\nX['education_level'] = le.fit_transform(X['education_level'])\nX['major_discipline'] = le.fit_transform(X['major_discipline'])\nX['experience'] = le.fit_transform(X['experience'])\nX['company_size'] = le.fit_transform(X['company_size'])\nX['company_type'] = le.fit_transform(X['company_type'])\nX['last_new_job'] = le.fit_transform(X['last_new_job'])","d02121cb":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)","c965ae54":"y_train.head()","2f5ac75e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n# instantiate the model (using the default parameters)\nlogreg = LogisticRegression(solver='liblinear')\n\n# fit the model with data\nlogreg.fit(X_train,y_train)\n\n#\ny_pred=logreg.predict(X_test)\nprint(classification_report(y_test,y_pred))\nprint(\"confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))\nprint(\"Accuracy Score = \",accuracy_score(y_test,y_pred))\n","dd11b9d2":"from sklearn import metrics\ny_pred_proba = logreg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.show()","a988734a":"from sklearn.tree import DecisionTreeClassifier","85fb6bc2":"dt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)\ny_pred = dt.predict(X_test)\nprint(classification_report(y_test,y_pred))\nprint(\"confusion Matrix:\\n\",confusion_matrix(y_test,y_pred))\nprint(\"Accuracy Score = \",accuracy_score(y_test,y_pred))","08af0e14":"import matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree,export_text","8bd345c6":"plt.figure(figsize = (16,10))\nplot_tree(dt,filled=True);","a41795e8":"###### AFTER OUTLIERS CAPPING ","9c74b206":"Inferance:\n            - no Numeric Features has 0 Variance.","45e6267c":"Inferance:\n            - Gender has 4508 null values and 3 Unique Values.\n            - enrolled_university has 386 Null values and 3 unique Values with no_enrollment as a top Value.\n            - education_level has 460 null Values and Graduate as a Top Value with 5 unique values.\n            - major_discipline has 2813 Null values and 6 Unique values . ","e737fcd3":"# Checking Null Value\n# Null value imputation","8f01c01c":"###### Auc\/Roc Curve:-","619660c2":"Data Info\/Cleaning\nChecking Null Value\nNull val imputation\nTreating Outliers\nHandling Skewness\nVariance Threshold\nChecking Correlation\nPairplot\nEncoding\nScaling\nPerforming Train Test split","495db7c1":"Ref = https:\/\/stackoverflow.com\/questions\/25039626\/how-do-i-find-numeric-columns-in-pandas\n\nVariance Threshold: https:\/\/www.analyticsvidhya.com\/blog\/2020\/10\/feature-selection-techniques-in-machine-learning\/","c40e3a91":"# Encoding\nScaling\nPerforming Train Test split","518badaa":"#   Decision Tree :","66bcca8b":"1. **Train Test Split:**","4917745c":"Inferance:\n            -There Dosent Seems to have Much Correlation Between Features.","601ed388":"Inferance:\n            - from the Above Features we Conclude that Training hours has Highest Numbers of Outliers.","96ed6126":"# Checking Correlation","f0fb77ee":"# logistic Regression:","b8f4e73e":"### Steps:","af4c055d":"# Treating Outliers","02fccfae":"https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2020\/01\/final_pipeline.png","4c055d8e":"###### Decision Tree Graph...","ab4c809e":"Inferance:\n            - City_development has all values with total count of 19158 with average count of 0.828848 and standard deviation of 0.12.\n            - Training_hrs has all values with total count of 19158 with average count of 65.366896 and standard deviation of 60.058462.","b6d4151a":"# Variance Threshold\n\n    The variance threshold is a simple baseline approach to feature selection. It removes all features which variance doesn\u2019t meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples. ","2a230c42":"###### Before Capping Outliers :","d6f5d468":"# Dropping Unnecessary Column","fd7934d8":"# Read csv:","154fabc8":"# Data Dictionary :"}}