{"cell_type":{"1c106227":"code","edd83e9e":"code","155adefd":"code","09c774d7":"code","2ab03a64":"code","c8fd0348":"code","f3b80a28":"code","bebce0b2":"code","f72adef1":"code","3643c879":"code","d1e29d0f":"code","06e343f3":"code","585f356c":"code","406329d3":"code","df301d05":"code","5857249e":"code","aaee17f3":"code","4653f726":"code","0cb8e2b9":"code","f28037ae":"code","5d88c2ed":"code","dee1480f":"code","f6a068a1":"code","fc91801a":"code","33bfe94e":"code","f1339d45":"code","70a0ac2a":"code","1306a6aa":"code","56acb713":"code","9f5888f9":"code","771cb30f":"code","9344c6fa":"code","b851a30b":"code","9a988d92":"code","25646be8":"code","4f3c935b":"code","af3cfb42":"code","c3b28a04":"code","0ef01532":"code","151df755":"code","92bfd6e8":"code","aca49814":"code","b80a0e66":"code","eedfa4e2":"code","29c38e77":"code","0663ba18":"code","62285308":"code","f5baf7a7":"code","2f30eee8":"code","8f1a53e1":"code","99d9192f":"code","5152f4d9":"code","5ebd5510":"code","0b5e36c3":"code","2a6b4fbd":"code","1a215433":"code","60bf8087":"code","565a906c":"code","e07629ad":"code","afd7eb22":"markdown","9962f4d6":"markdown","41d42b8b":"markdown","eeb27345":"markdown","e0fa38f9":"markdown","c9896c9e":"markdown","c4a6080b":"markdown","1f765833":"markdown","741af3ab":"markdown","74ac53af":"markdown","aae774bd":"markdown","0f4f2326":"markdown","74a85025":"markdown","cabe5ca5":"markdown","67e7ef76":"markdown","342b29f4":"markdown","d52d1d11":"markdown","f7c07604":"markdown","69112300":"markdown","5a9e9c79":"markdown","36dd9cb5":"markdown","07cd174f":"markdown","9899e941":"markdown","5d632668":"markdown","7095e7fb":"markdown","ccbf3e4c":"markdown","3f85f045":"markdown","26b5957c":"markdown","97bcc431":"markdown","00afb44d":"markdown","fdab5df2":"markdown","c6a8851c":"markdown","956f329a":"markdown","ddf89684":"markdown","c1c23aed":"markdown","ef72b956":"markdown","8641f238":"markdown","33dad09d":"markdown","f0bb648d":"markdown","8676dee7":"markdown","b44714cd":"markdown","5b39c56e":"markdown","c25e3e17":"markdown","4a080500":"markdown","39256d0b":"markdown","1c677b2a":"markdown","73956e81":"markdown","db3638d6":"markdown","d530897e":"markdown","3fa16edb":"markdown","03ca28b9":"markdown","fe2b3822":"markdown","3f650038":"markdown","b8a225c3":"markdown","137f9d78":"markdown","205f4c85":"markdown","785a8531":"markdown","ca25b617":"markdown","e31a4cf9":"markdown","a2f296aa":"markdown","3f4bd64d":"markdown","366a236c":"markdown"},"source":{"1c106227":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","edd83e9e":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Activation, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam,RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.metrics import confusion_matrix","155adefd":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","09c774d7":"train.shape","2ab03a64":"train.head()","c8fd0348":"X = train.drop('label', axis=1)\ny = train['label']","f3b80a28":"test.shape","bebce0b2":"train['label'].value_counts()","f72adef1":"sns.countplot(train['label'])","3643c879":"X.shape","d1e29d0f":"first_row = X.iloc[0].copy()","06e343f3":"first_mat = first_row.values.reshape(28,28)","585f356c":"plt.imshow(first_mat)","406329d3":"plt.figure(figsize=(15,10))\nfor i in range(10):\n    plt.subplot(2,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X.iloc[i].values.reshape(28,28))\n    plt.xlabel(y[i])","df301d05":"input_shape = (28, 28, 1)","5857249e":"unique_labels = y.unique()","aaee17f3":"unique_labels","4653f726":"num_labels = len(unique_labels)","0cb8e2b9":"num_labels","f28037ae":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","5d88c2ed":"y_train.shape","dee1480f":"X_train.shape","f6a068a1":"X_train = X_train.values.reshape(-1, 28, 28, 1)\nX_test = X_test.values.reshape(-1, 28, 28, 1)","fc91801a":"X_train.shape","33bfe94e":"X_train = X_train \/ 255.\nX_test = X_test \/ 255.","f1339d45":"###  Model Definition\nmodel = Sequential()\n\n# add 32 convolution filters used each of size 5x5 with relu activation\nmodel.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Valid', activation='relu', input_shape=(28, 28, 1)))\n\n\n# add another 32 convolution filters used each of size 3x3 with relu activation\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', activation='relu'))\n\n# adding pooling layer with a MaxPool2D filter of size 2x2 summarize the presence of features\n# in patches of the feature map.\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n\n# turn on and off neurons randomly for reducing interdependent learning amongst the neurons.\nmodel.add(Dropout(0.2))\n\n# add 64 convolution filters used each of size 5x5 with relu activation\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), padding='Valid', activation='relu'))\n\n# add 64 convolution filters used each of size 3x3 with relu activation\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n\n# adding pooling layer with a MaxPool2D filter of size 2x2 summarize the presence of features\n# in patches of the feature map.\nmodel.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n\n# turn on and off neurons randomly for reducing interdependent learning amongst the neurons.\nmodel.add(Dropout(0.2))\n\n# # Flattens the data.\nmodel.add(Flatten())\n\n# add densely-connected NN layer, to fully connected to drives the final classification decision.\nmodel.add(Dense(519, activation=\"relu\"))\n\n# turn on and off neurons randomly for reducing interdependent learning amongst the neurons.\nmodel.add(Dropout(0.5))\n\n# output a softmax to let the output to be interpreted as probabilities\nmodel.add(Dense(10, activation=\"softmax\"))\n","70a0ac2a":"model.summary()","1306a6aa":"# model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=[\"accuracy\"])","56acb713":"model.compile(loss='categorical_crossentropy',\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])","9f5888f9":"y_train = to_categorical(y_train, num_classes = num_labels)\ny_test = to_categorical(y_test, num_classes = num_labels)","771cb30f":"\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', patience=2, verbose=2, factor=0.5, min_lr=0.0000001)","9344c6fa":"img_data_gen = ImageDataGenerator(\n    featurewise_center=False,\n    samplewise_center=False,\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    zca_whitening=False,\n    rotation_range=10,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=False,\n    vertical_flip=False)\n\n","b851a30b":"# epochs     - One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE\nnum_epochs = 1 # replace it to 30\n# batch size -Total number of training examples present in a single batch.\nbatch_size = 64\n\ntrain_generator = img_data_gen.flow(X_train, y_train, batch_size=batch_size)\ntest_generator = img_data_gen.flow(X_test, y_test, batch_size=batch_size)","9a988d92":"# Save the model to disk\nmodel.save('MNIST-1.h5')\n","25646be8":"\n\nhistory = model.fit_generator(train_generator,\n                    epochs=num_epochs,\n                    validation_data=test_generator,\n                    callbacks=[reduce_lr])","4f3c935b":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1]) ","af3cfb42":"y_true =  [np.argmax(i) for i in y_test]\npredictions = model.predict(X_test)\ny_pred = [np.argmax(i) for i in predictions]\nplt.figure(figsize=(15,8))\nsns.heatmap(confusion_matrix(y_true, y_pred), cmap=\"coolwarm\", annot=True , fmt=\"d\")","c3b28a04":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')","0ef01532":"predictions[0]","151df755":"np.argmax(predictions[0])","92bfd6e8":"np.argmax(y_test[0])","aca49814":"def plot_image(i, predictions_array, true_label, img):\n    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.imshow(img, cmap=plt.cm.binary)\n\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        color = 'blue'\n    else:\n        color = 'red'\n\n    plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n                                100*np.max(predictions_array),\n                                true_label),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n    predictions_array, true_label = predictions_array, true_label[i]\n    plt.grid(False)\n    plt.xticks(range(10))\n    plt.yticks([])\n    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1])\n    predicted_label = np.argmax(predictions_array)\n\n    thisplot[predicted_label].set_color('red')\n    thisplot[true_label].set_color('blue')","b80a0e66":"num_rows = 5\nnum_cols = 3\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n    plot_image(i, predictions[i], np.argmax(np.array(y_test), axis=1), X_test.reshape(-1,28,28))\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions[i], np.argmax(np.array(y_test), axis=1))\nplt.tight_layout()\nplt.show()","eedfa4e2":"errors = pd.DataFrame(np.argmax(y_test, axis=1), columns=['label'])","29c38e77":"errors.reset_index(inplace=True)","0663ba18":"errors","62285308":"errors['predictions'] = y_pred","f5baf7a7":"errors.loc[errors['label'] - errors['predictions'] != 0, 'error'] = 1","2f30eee8":"errors[errors['error']==1]","8f1a53e1":"num_errors = len(errors[errors['error']==1].index)","99d9192f":"print(\"number of errors is: {}\".format(num_errors))","5152f4d9":"err_index = errors[errors['error']==1].index","5ebd5510":"plt.figure(figsize=(15,10))\nfor i in range(10):\n    err_index = errors[errors['error']==1].index[i]\n    plt.subplot(2,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_test[err_index].reshape(28,28))\n    plt.xlabel(\"ture is {}, predicted as {}\".format(np.argmax(y_test[err_index]), y_pred[err_index]))","0b5e36c3":"\ntest = test \/ 255\ntest = test.values.reshape(-1, 28, 28, 1)","2a6b4fbd":"final_predictions = model.predict(test)","1a215433":"final_predictions","60bf8087":"final_predictions = list(map(lambda x : np.argmax(np.round(x)), final_predictions))","565a906c":"final_predictions[:10]","e07629ad":"predicted_labels = pd.Series(final_predictions, name=\"Label\")\nimage_id = pd.Series(range(1, len(predicted_labels)+1),name=\"ImageId\")\n\nresults = pd.concat([image_id,predicted_labels],axis=1)\n\nresults.to_csv(\"MNIST.csv\",index=False)","afd7eb22":"### 8. Model Evaluation","9962f4d6":"let us plot the first 10 images","41d42b8b":"Let us see the first 10 prediction images","eeb27345":"Cool the model is right !","e0fa38f9":"accuracy vs. validation accuracy","c9896c9e":"#### 7.8 Image proccessing","c4a6080b":"#### 7.4 Reshaping and Scaling data","1f765833":"input dimension is (w,n,3) - (wxn) image with 3 channels (R,G,B)","741af3ab":"#### 7.2 Train\/Test Split","74ac53af":"Confusion matrix","aae774bd":"[Artificial neural networks](https:\/\/en.wikipedia.org\/wiki\/Artificial_neural_network) are computing systems that are inspired by, but not identical to, biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with task-specific rules.","0f4f2326":"<img src=\"https:\/\/datascience-enthusiast.com\/figures\/max_pool1.png\" width=\"500\">","74a85025":"#### 1.2.1 CNN Layers","cabe5ca5":"Let us count the labels.","67e7ef76":"[MNIST](https:\/\/www.kaggle.com\/c\/digit-recognizer) (\"Modified National Institute of Standards and Technology\") is the de facto \u201chello world\u201d dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.","342b29f4":"Let us take a loot to the first prediction","d52d1d11":"1.2.1.1 Convolutional Layers\n\nthe major block in CNN is Convolutional layers, which apply filtering to the input that results an activation, repeating applying the filter (kernel) on the input will create a feature map that summarizes the presence of detected features in the input.","f7c07604":"reshape it to 28x28","69112300":"Reduce learning rate when a metric has stopped improving.\nModels often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.","5a9e9c79":"as you can see we have label wich define the actual digit and 784pixels - pixels[0-783].\ni will seperate train data to (X, y) - y will be label only, and X will be the whole data without the label.","36dd9cb5":"#### 1.2 Convolutional neural network CNN)","07cd174f":"let display the model errors","9899e941":"#### 1.1 Artificial neural networks","5d632668":"1.2.1.3 Fully Connected Layer\n\nAfter the two previous steps in CNN process ends, breaking down the image into features, and analyzing them independently. The result of this process will be flatted and feeds into a fully connected neural network structure that drives the final classification decision.","7095e7fb":"<img src=\"https:\/\/www.researchgate.net\/profile\/Baptiste_Wicht\/publication\/322505397\/figure\/fig5\/AS:583063998308353@1516024698839\/A-valid-convolution-of-a-5x5-image-with-a-3x3-kernel-The-kernel-will-be-applied-to.png\" width=\"200\">","ccbf3e4c":"### 7. Neural network model","3f85f045":"### 6. Preprocessing that data","26b5957c":"<img src=\"https:\/\/summations.github.io\/assets\/img\/posts\/channelplot\/image-matrix.png\" width=\"600\">","97bcc431":"42,000 images to train and learn from.","00afb44d":"#### 1.3 MNIST","fdab5df2":"because we want to reduce over-fitting, i will use Data Augmentation technique \nData augmentation Applies a transformation to an image according to given parameters for example rotates, shears, zooms and other transformations to the image and make the model learns to generalize and not remember specific data. If the model overfits, it will perform very well on the images that it already knows but will fail if new images are given to it.","c6a8851c":"#### 7.5 Build Neural Network Model","956f329a":"We can see that the prediction is an array of 10 elements, each element representing the model \"confidence\" value for the corresponding class.\nand to get the correct prediction we need to get the Max \"confidence\" value for each input","ddf89684":"#### 7.7 Reduce Learning Rate (LR)","c1c23aed":"### 3. Import Libraries","ef72b956":"The goal is to correctly identify digits from a dataset of tens of thousands of handwritten images.","8641f238":"now we can plot that image","33dad09d":"for our case, we will feed the CNN model with graysacle images, graysacle image is one in which the value of each pixel is a single sample representing only an amount of light.\nwhich will be stored as (rows, columns, 1) in our case it will be (28, 28, 1)","f0bb648d":"### 4. Gathering data","8676dee7":"<img src=\"https:\/\/miro.medium.com\/max\/2510\/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" height=\"100\">","b44714cd":"Let's display the architecture of our model.","5b39c56e":"<img src=\"https:\/\/cdn-images-1.medium.com\/max\/600\/1*yjy3dwRL-vmSpmUG7UNJYg@2x.png\" width=200>","c25e3e17":"### 5. EDA - Exploratory data analysis","4a080500":"#### 7.1 Define Variables","39256d0b":"### 2. Problem","1c677b2a":"because we are using the ```categorical_crossentropy``` loss method, we need to convert ```y_train```, ```y_test``` using one hot encoder.","73956e81":"In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the results to identify cats in other images. They do this without any prior knowledge of cats, for example, that they have fur, tails, whiskers and cat-like faces. Instead, they automatically generate identifying characteristics from the examples that they process.","db3638d6":"### 1. Background","d530897e":"# Digit-Recognition by Convolutional Neural Networks (CNN)","3fa16edb":"start train","03ca28b9":"Let us take a look to the first row","fe2b3822":"#### 1.4 Images\nRGB images is stored as 3D numpy array (rows, columns, channels), rows is images height of the image and columns is the width of the image.\nChannels consists of Red, Green and Blue components of each individual pixel. for example a (0,0,0) pixel is displayed as black, and a pixel whose color components are (255,255,255) is displayed as white.","3f650038":"The model says that the first digit is ```3```, let see the acutal class","b8a225c3":"it looks like the digit ```1```","137f9d78":"let see how many unique labels we have","205f4c85":"#### 7.6 Model Compiling and Training","785a8531":"28,000 images to test","ca25b617":"<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/4\/46\/Colored_neural_network.svg\/800px-Colored_neural_network.svg.png\" width=\"250\">","e31a4cf9":"here is a simple example of a standard 2D CNN","a2f296aa":"<img src=\"https:\/\/corochann.com\/wp-content\/uploads\/2017\/02\/mnist_plot.png\" width=\"300\">","3f4bd64d":"1.2.1.2 Pooling Layer\n\nPooling is required to down sample the detection of features in feature maps by summarizing the presence of features in patches of the feature map. there is many pooling methods one of the common pooling methods is 'max pooling', which summarize the max activated presence of a feature.","366a236c":"Before training the model, we need to compile :\n* Loss function \u2014 This measures how accurate the model is during training. You want to minimize this function to \"steer\" the model in the right direction.\n* Optimizer \u2014This is how the model is updated based on the data it sees and its loss function.\n* Metrics \u2014Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified"}}