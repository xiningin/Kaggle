{"cell_type":{"db595ba2":"code","2851f3fd":"code","e8f15bf9":"code","cdf664d5":"code","330c6acb":"code","61608777":"code","85b11d7d":"code","46954698":"code","7ae3f54b":"code","21ad206f":"code","9f381208":"code","d3634be5":"code","f93f1cca":"code","9d7ea525":"code","49f98c51":"code","7fd68ed6":"code","6739d116":"code","88ca5c90":"code","ff420e26":"code","c4713b78":"code","02ccd153":"code","1173000d":"code","036a6898":"code","e8bd18ed":"markdown","0b1450c3":"markdown"},"source":{"db595ba2":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2851f3fd":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras import layers","e8f15bf9":"data = np.load('\/kaggle\/input\/face-mask-detection-dataset\/CleanedData\/data.npy')","cdf664d5":"target = np.load('\/kaggle\/input\/face-mask-detection-dataset\/CleanedData\/target.npy')\ntarget = tf.keras.utils.to_categorical(target) # converting [1,0,1,1,0...] to [[1,0],[0,1],[1,0]] i.e categorical\ntarget","330c6acb":"plt.imshow(data[890],cmap='gray')","61608777":"target[890]","85b11d7d":"# we need to create a 3D image since our image have only one channel as its a greyscale img.\n# so we will just replicate the image 3 times to create a 3d image.\n# for this process tf.image.grayscale_to_rgb comes handy.\n# https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/image\/grayscale_to_rgb\n# why RESHAPE - https:\/\/github.com\/tensorflow\/tensorflow\/issues\/26324 \n# preprocessing\nodata = data.copy()\nndata = []\nfor i in odata:\n  image = i.reshape((*i.shape,1)) # as tf.image.grayscale_to_rgb requires last dimension to be 1, see why reshape link\n  image = tf.convert_to_tensor(image)  # as tf.image.grayscale_to_rgb requires tensor for processing.\n  ndata.append(tf.image.grayscale_to_rgb(image).numpy()\/255.) # .numpy will convert dtype to numpy from tf\n\ndata = ndata.copy()","46954698":"from sklearn.model_selection import train_test_split","7ae3f54b":"np.shape(data)","21ad206f":"trainx, testx, trainy, testy = train_test_split(data,\n                                                target,\n                                                test_size=0.15,\n                                                random_state=345,\n                                                shuffle=True)\n# we need to convert list to np array for tensorflow\ntrainx = np.array(trainx)\ntestx = np.array(testx)","9f381208":"trainy.shape","d3634be5":"plt.figure(figsize=[30,30])\nfor i in np.arange(1,10):\n    plt.subplot(int(f\"19{i}\"))\n    plt.imshow(trainx[np.random.randint(0,1403)], cmap='gray')","f93f1cca":"plt.subplot(221)\nplt.imshow(trainx[np.random.randint(0,1440)], cmap='gray')\nplt.subplot(222)\nplt.imshow(trainx[np.random.randint(0,1440)], cmap='gray')\nplt.subplot(223)\nplt.imshow(trainx[np.random.randint(0,1440)], cmap='gray')\nplt.subplot(224)\nplt.imshow(trainx[np.random.randint(0,1440)], cmap='gray')","9d7ea525":"trainy[0]","49f98c51":"img_shape = trainx[0].shape\nimg_shape  ","7fd68ed6":"model=Sequential()\n\nmodel.add(layers.Conv2D(32,(3,3),input_shape=img_shape))\n# model.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(layers.Conv2D(64,(3,3)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(layers.Conv2D(128,(3,3)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(layers.Conv2D(256,(3,3)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2,2)))\n\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(64,activation='relu'))\nmodel.add(layers.Dropout(0.4))\n\nmodel.add(layers.Dense(2,activation='softmax'))\n#The Final layer with two outputs for two categories\n\n\nadam = tf.keras.optimizers.Adam(0.001)\nmodel.compile(loss='categorical_crossentropy',optimizer=adam,metrics=['accuracy'])","6739d116":"model.summary()","88ca5c90":"# monitor = on which basis we have to select best model\n# verbose = 0 i.e no message, 1 i.e update message.\nmodel_saving_path = r'\/tmp\/checkpoint\/cnn.model'\nsave_model = tf.keras.callbacks.ModelCheckpoint(model_saving_path,\n                                                monitor='val_acc',\n                                                save_best_only=True,\n                                                mode='max',\n                                                verbose=1)","ff420e26":"history = model.fit(x=trainx,\n                    y=trainy,\n                    batch_size=100,\n                    epochs=50,\n                    callbacks=[save_model],\n                    validation_split=0.2,\n                    verbose=2,\n                    shuffle=True)","c4713b78":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['loss','val_loss'])","02ccd153":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['accuracy', 'val_accuracy'])","1173000d":"model.evaluate(testx, testy)","036a6898":"model.save('cnn.h5')","e8bd18ed":"tf.image.grayscale_to_rgb(tf.convert_to_tensor(data[0].reshape((*data[0].shape,1)))).numpy().shape","0b1450c3":"# **Resources**\n**Go through the video on youtube for better understanding of the project: https:\/\/youtu.be\/Kd-rDV5N4wo**\n    \n**Fork at Github: https:\/\/bit.ly\/31ScS13**"}}