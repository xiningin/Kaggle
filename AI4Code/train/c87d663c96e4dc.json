{"cell_type":{"5f896b3c":"code","7c469437":"code","1586f190":"code","f426a257":"code","37c03131":"code","8beb145e":"code","adbe2d7d":"code","fe603200":"code","195699db":"code","fe2db122":"code","0ab7e832":"code","6561b541":"code","e0381b46":"code","21eaecc1":"code","86b3cdca":"code","daf26af8":"code","1dbe73b1":"code","4b702ec8":"code","bdcbce34":"code","161abe02":"code","a14cad0f":"code","a767211a":"code","89bc2640":"code","edbfa91d":"code","055e42ac":"code","f1a412dc":"code","9cd13b13":"code","dbe53d93":"code","73812c09":"code","91e950b3":"code","c8bcb7ff":"code","8c46693d":"code","485ceffb":"code","944964bc":"code","224ceba9":"code","559f8edc":"code","3834b048":"code","db0f45f8":"code","b19b9f48":"code","e0c672c2":"code","f3744b83":"code","770ff152":"code","6e8a089f":"code","113d7dbf":"code","afec16c5":"code","8acbcae5":"code","0efb83a0":"code","98e8f66e":"code","2e7eb397":"code","e46e2db2":"code","a78bfd4e":"code","2382ff5f":"code","69103ab8":"code","3bfe2ed8":"code","cbddc4e4":"code","986e2cfb":"markdown","d1f6f3cc":"markdown","c8fc8ab2":"markdown","a30bd826":"markdown","f3ec92e8":"markdown","906627cb":"markdown","c7773df5":"markdown","149f72b4":"markdown","1ace0b4c":"markdown","6eed8577":"markdown","d096ee6d":"markdown","a7098f75":"markdown","931d8133":"markdown","aa45fa42":"markdown","50dff5b2":"markdown","a395c83a":"markdown","9d06954f":"markdown","69539148":"markdown","7f391f52":"markdown","469f17b5":"markdown","a42c0d8a":"markdown","d7005b1d":"markdown","50a36d07":"markdown","a8d9786b":"markdown","40fe7baa":"markdown","7d70b64a":"markdown","af969419":"markdown","c9b91f90":"markdown","1c140d50":"markdown","a566a9df":"markdown","c60f90cd":"markdown","372e321a":"markdown","67385dca":"markdown","a0b7cf1a":"markdown","84aea8aa":"markdown","2a0181dd":"markdown","3c8a790f":"markdown","65e53eaf":"markdown","568c3456":"markdown","4bbb288f":"markdown","ace3df7d":"markdown","5c497288":"markdown","b2ed11db":"markdown"},"source":{"5f896b3c":"import os, random\n\nimport numpy as np\nfrom scipy.stats import chi2_contingency\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\n## Set fixed ranom seeds to get reproducible results\nseed_val = 0\nos.environ['PYTHONHASHSEED'] = str(seed_val)\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntf.random.set_seed(seed_val)","7c469437":"df = pd.read_csv('\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","1586f190":"df.info()","f426a257":"df.head()","37c03131":"df.isnull().sum()","8beb145e":"def summarize_categoricals(df, show_levels=False):\n    \"\"\"\n        Display uniqueness in each column\n    \"\"\"\n    data = [[df[c].unique(), len(df[c].unique()), df[c].isnull().sum()] for c in df.columns]\n    df_temp = pd.DataFrame(data, index=df.columns,\n                           columns=['Levels', 'No. of Levels',\n                                    'No. of Missing Values'])\n    return df_temp.iloc[:, 0 if show_levels else 1:]\n\n\ndef return_categoricals(df, threshold=5):\n    \"\"\"\n        Returns a list of columns that have less than or equal to\n        `threshold` number of unique categorical levels\n    \"\"\"\n    return list(filter(lambda c: c if len(df[c].unique()) <= threshold else None,\n                       df.columns))\n\n\ndef to_categorical(columns, df):\n    \"\"\"\n        Converts the columns passed in `columns` to categorical datatype\n    \"\"\"\n    for col in columns:\n        df[col] = df[col].astype('category')\n    return df","adbe2d7d":"summarize_categoricals(df, show_levels=True)","fe603200":"to_cast = return_categoricals(df, threshold=5)\ndf = to_categorical(to_cast, df)\n\ndf.info()","195699db":"df['smoking']","fe2db122":"df.describe().T","0ab7e832":"fig, ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(data=df.astype({'DEATH_EVENT': 'int64'}).corr(),\n            annot=True, cmap='coolwarm', cbar_kws={'aspect': 50},\n            square=True, ax=ax)\nplt.xticks(rotation=30, ha='right');\nplt.tight_layout()","6561b541":"def cramers_corrected_stat(contingency_table):\n    \"\"\"\n        Computes corrected Cramer's V statistic for categorial-categorial association\n    \"\"\"\n    \n    try:\n        chi2 = chi2_contingency(contingency_table)[0]\n    except ValueError:\n        return np.NaN\n    \n    n = contingency_table.sum().sum()\n    phi2 = chi2\/n\n    \n    r, k = contingency_table.shape\n    r_corrected = r - (((r-1)**2)\/(n-1))\n    k_corrected = k - (((k-1)**2)\/(n-1))\n    phi2_corrected = max(0, phi2 - ((k-1)*(r-1))\/(n-1))\n    \n    return (phi2_corrected \/ min( (k_corrected-1), (r_corrected-1)))**0.5","e0381b46":"def categorical_corr_matrix(df):\n    \"\"\"\n        Computes corrected Cramer's V statistic between all the\n        categorical variables in the dataframe\n    \"\"\"\n    df = df.select_dtypes(include='category')\n    cols = df.columns\n    n = len(cols)\n    corr_matrix = pd.DataFrame(np.zeros(shape=(n, n)), index=cols, columns=cols)\n    \n    excluded_cols = list()\n    \n    for col1 in cols:\n        for col2 in cols:\n            if col1 == col2:\n                corr_matrix.loc[col1, col2] = 1\n                break\n            df_crosstab = pd.crosstab(df[col1], df[col2], dropna=False)\n            corr_matrix.loc[col1, col2] = cramers_corrected_stat(df_crosstab)\n                \n    # Flip and add to get full correlation matrix\n    corr_matrix += np.tril(corr_matrix, k=-1).T\n    return corr_matrix","21eaecc1":"fig, ax = plt.subplots(figsize=(10, 5))\nsns.heatmap(categorical_corr_matrix(df), annot=True, cmap='coolwarm', \n            cbar_kws={'aspect': 50}, square=True, ax=ax)\nplt.xticks(rotation=30, ha='right');\nplt.tight_layout()","86b3cdca":"fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(10, 5))\ntitles = list(df.select_dtypes(include='category'))\n\nax_title_pairs = zip(axs.flat, titles)\n\nfor ax, title in ax_title_pairs:\n    sns.countplot(x=title, data=df, palette='Pastel2', ax=ax)\n    ax.set_title(title)\n    ax.set_xlabel('')\n\nplt.tight_layout()","daf26af8":"df_grouped = df.groupby(by='DEATH_EVENT')\nfig, axs = plt.subplots(nrows=3, ncols=3, figsize=(15, 8))\ntitles = list(df.select_dtypes(exclude='category'))\n\nax_title_pairs = zip(axs.flat, titles)\n\nfor ax, title in ax_title_pairs:\n    sns.distplot(df_grouped.get_group(0)[title], bins=10, ax=ax, label='No')\n    sns.distplot(df_grouped.get_group(1)[title], bins=10, ax=ax, label='Yes')\n    ax.legend(title='DEATH_EVENT')\n\naxs.flat[-1].remove()\naxs.flat[-2].remove()\nfig.tight_layout()","1dbe73b1":"fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(15, 5))\ntitles = list(df.select_dtypes(exclude='category'))\n\nax_title_pairs = zip(axs.flat, titles)\n\nfor ax, title in ax_title_pairs:\n    sns.boxplot(x='DEATH_EVENT', y=title, data=df, ax=ax)\nfig.tight_layout()","4b702ec8":"def modified_countplot(**kargs):\n    \"\"\"\n        Assumes that columns to be plotted are in of pandas dtype='CategoricalDtype'\n    \"\"\"\n    facet_gen = kargs['facet_generator']    ## Facet generator over facet data\n    curr_facet, facet_data = None, None\n    \n    while True:\n        ## Keep yielding until non-empty dataframe is found\n        curr_facet = next(facet_gen)            ## Yielding facet genenrator\n        df_rows = curr_facet[1].shape[0]\n        \n        ## Skip the current facet if its corresponding dataframe empty\n        if df_rows:\n            facet_data = curr_facet[1]\n            break\n    \n    x_hue = (kargs.get('x'), kargs.get('hue'))\n    cols = [col for col in x_hue if col]\n    col_categories = [facet_data[col].dtype.categories if col else None for col in x_hue]\n    \n    palette = kargs['palette'] if 'palette' in kargs.keys() else 'Pastel2'\n    sns.countplot(x=cols[0], hue=x_hue[1], \n                  order=col_categories[0], hue_order=col_categories[1],\n                  data=facet_data.loc[:, cols], palette=palette)","bdcbce34":"display(pd.crosstab(df['DEATH_EVENT'], [df['smoking'],\n                                        df['high_blood_pressure'],\n                                        df['sex']],\n                    dropna=False))\n\nfacet = sns.FacetGrid(df, row='smoking', col='sex', sharex=False,\n                      sharey=False, margin_titles=True)\nfacet.map(modified_countplot, x='high_blood_pressure', hue='DEATH_EVENT',\n          palette='Pastel2', facet_generator=facet.facet_data())\nfacet.set_xlabels('high_blood_pressure')\nfacet.set_ylabels('Count')\nfacet.add_legend(title='DEATH_EVENT');","161abe02":"list(df.select_dtypes(include='category'))","a14cad0f":"display(pd.crosstab(df['DEATH_EVENT'], [df['sex'], df['diabetes'], df['anaemia']], dropna=False))\n\nfacet = sns.FacetGrid(df, row='diabetes', col='sex', sharex=False,\n                      sharey=False, margin_titles=True)\nfacet.map(modified_countplot, x='anaemia', hue='DEATH_EVENT',\n          palette='Pastel2', facet_generator=facet.facet_data())\nfacet.set_xlabels('anaemia')\nfacet.set_ylabels('Count')\nfacet.add_legend(title='DEATH_EVENT');","a767211a":"x = df.iloc[:, :-1]\ny = df['DEATH_EVENT']\n\ncategorical_columns = list(x.select_dtypes(include='category').columns)\nnumeric_columns = list(x.select_dtypes(exclude='category').columns)","89bc2640":"from sklearn.model_selection import train_test_split\n\ndata_splits = train_test_split(x, y, test_size=0.25, random_state=seed_val,\n                               shuffle=True, stratify=y)\nx_train, x_test, y_train, y_test = data_splits\n\n\n# For CatBoost and Naive Bayes\ndata_splits = train_test_split(x, y, test_size=0.25, random_state=seed_val,\n                               shuffle=True, stratify=y)\nx_train_cat, x_test_cat, y_train_cat, y_test_cat = data_splits\n\n\nlist(map(lambda x: x.shape, [x, y, x_train, x_test, y_train, y_test]))","edbfa91d":"pd.Series(y_test).value_counts()","055e42ac":"sns.countplot(x=y_test);","f1a412dc":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline \n\n\nnumeric_transformer = Pipeline(steps=[\n    ('scaler', StandardScaler())])\n\ncategorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(drop='first', dtype=np.int))])\n\n## Column Transformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_columns),\n        ('cat', categorical_transformer, categorical_columns)],\n    remainder='passthrough')\n\n\n## Applying Column Transformer\nx_train = preprocessor.fit_transform(x_train)\nx_test = preprocessor.transform(x_test)\n\n\n## Label encoding\ny_trans = LabelEncoder()\ny_train = y_trans.fit_transform(y_train)\ny_test = y_trans.transform(y_test)\n\n\n## Save feature names after one-hot encoding for feature importances plots\nfeature_names = list(preprocessor.named_transformers_['cat'].named_steps['onehot'] \\\n                            .get_feature_names(input_features=categorical_columns))\nfeature_names = numeric_columns + feature_names","9cd13b13":"import timeit\nimport pickle\nimport sys\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n                            precision_recall_curve, roc_curve, accuracy_score\nfrom sklearn.exceptions import NotFittedError","dbe53d93":"def confusion_plot(matrix, labels=None):\n    \"\"\" Display binary confusion matrix as a Seaborn heatmap \"\"\"\n    \n    labels = labels if labels else ['Negative (0)', 'Positive (1)']\n    \n    fig, ax = plt.subplots(nrows=1, ncols=1)\n    sns.heatmap(data=matrix, cmap='Blues', annot=True, fmt='d',\n                xticklabels=labels, yticklabels=labels, ax=ax)\n    ax.set_xlabel('PREDICTED')\n    ax.set_ylabel('ACTUAL')\n    ax.set_title('Confusion Matrix')\n    plt.close()\n    \n    return fig","73812c09":"def roc_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Receiver Operating Characteristic (ROC) curve \n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    fpr, tpr, thresh = roc_curve(y_true, y_probs, drop_intermediate=False)\n    auc = round(roc_auc_score(y_true, y_probs), 2)\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    label = ' '.join([label, f'({auc})']) if compare else None\n    sns.lineplot(x=fpr, y=tpr, ax=axis,\n                 estimator=None, label=label)\n    \n    if compare:\n        axis.legend(title='Classifier (AUC)', loc='lower right')\n    else:\n        axis.text(0.72, 0.05, f'AUC = { auc }', fontsize=12,\n                  bbox=dict(facecolor='green', alpha=0.4, pad=5))\n            \n        # Plot No-Info classifier\n        axis.fill_between(fpr, fpr, tpr, alpha=0.3, edgecolor='g',\n                          linestyle='--', linewidth=2)\n        \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('ROC Curve')\n    axis.set_xlabel('False Positive Rate [FPR]\\n(1 - Specificity)')\n    axis.set_ylabel('True Positive Rate [TPR]\\n(Sensitivity or Recall)')\n    \n    plt.close()\n    \n    return axis if ax else fig","91e950b3":"def precision_recall_plot(y_true, y_probs, label, compare=False, ax=None):\n    \"\"\" Plot Precision-Recall curve.\n        Set `compare=True` to use this function to compare classifiers. \"\"\"\n    \n    p, r, thresh = precision_recall_curve(y_true, y_probs)\n    p, r, thresh = list(p), list(r), list(thresh)\n    p.pop()\n    r.pop()\n    \n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1)\n    \n    if compare:\n        sns.lineplot(r, p, estimator=None,\n                     ax=axis, label=label)\n        axis.set_xlabel('Recall')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n    else:\n        sns.lineplot(thresh, p, estimator=None,\n                     label='Precision', ax=axis)\n        axis.set_xlabel('Threshold')\n        axis.set_ylabel('Precision')\n        axis.legend(loc='lower left')\n\n        axis_twin = axis.twinx()\n        sns.lineplot(thresh, r, estimator=None,\n                     color='limegreen', label='Recall', ax=axis_twin)\n        axis_twin.set_ylabel('Recall')\n        axis_twin.set_ylim(0, 1)\n        axis_twin.legend(bbox_to_anchor=(0.24, 0.18))\n    \n    axis.set_xlim(0, 1)\n    axis.set_ylim(0, 1)\n    axis.set_title('Precision Vs Recall')\n    \n    plt.close()\n    \n    return axis if ax else fig","c8bcb7ff":"def feature_importance_plot(importances, feature_labels, ax=None):\n    fig, axis = (None, ax) if ax else plt.subplots(nrows=1, ncols=1, figsize=(5, 10))\n    sns.barplot(x=importances, y=feature_labels, ax=axis)\n    axis.set_title('Feature Importance Measures')\n    \n    plt.close()\n    \n    return axis if ax else fig","8c46693d":"def train_clf(clf, x_train, y_train, sample_weight=None, refit=False):\n    train_time = 0\n    \n    try:\n        if refit:\n            raise NotFittedError\n        y_pred_train = clf.predict(x_train)\n        \n        # For neural nets\n        y_pred_train = np.where(y_pred_train.flatten() > 0.5, 1, 0)\n        \n    except NotFittedError:\n        start = timeit.default_timer()\n        \n        if sample_weight is not None:\n            clf.fit(x_train, y_train, sample_weight=sample_weight)\n        else:\n            clf.fit(x_train, y_train)\n        \n        end = timeit.default_timer()\n        train_time = end - start\n        \n        y_pred_train = clf.predict(x_train)\n    \n    train_acc = accuracy_score(y_train, y_pred_train)\n    return clf, y_pred_train, train_acc, train_time","485ceffb":"def model_memory_size(clf):\n    return sys.getsizeof(pickle.dumps(clf))","944964bc":"def report(clf, x_train, y_train, x_test, y_test, display_scores=[],\n           sample_weight=None, refit=False, importance_plot=False,\n           confusion_labels=None, feature_labels=None, neural_net=False,\n           verbose=True):\n    \"\"\" Trains the passed classifier if not already trained and reports\n        various metrics of the trained classifier \"\"\"\n    \n    dump = dict()\n    \n    ## Train if not already trained\n    clf, train_predictions, \\\n    train_acc, train_time = train_clf(clf, x_train, y_train,\n                                      sample_weight=sample_weight,\n                                      refit=refit)\n    ## Testing\n    start = timeit.default_timer()\n    test_predictions = clf.predict(x_test)\n    end = timeit.default_timer()\n    test_time = end - start\n    \n    # For neural nets\n    if neural_net:\n        y_probs = np.copy(test_predictions)\n        test_predictions = np.where(test_predictions.flatten() > 0.5, 1, 0)\n    else:\n        y_probs = clf.predict_proba(x_test)[:, 1]\n    \n    test_acc = accuracy_score(y_test, test_predictions)\n    roc_auc = roc_auc_score(y_test, y_probs)\n        \n    ## Additional scores\n    scores_dict = dict()\n    for func in display_scores:\n        scores_dict[func.__name__] = [func(y_train, train_predictions),\n                                      func(y_test, test_predictions)]\n        \n    ## Model Memory\n    model_mem = None\n    if not neural_net:\n        model_mem = round(model_memory_size(clf) \/ 1024, 2)\n    \n    print(clf)\n    print(\"\\n=============================> TRAIN-TEST DETAILS <======================================\")\n    \n    ## Metrics\n    print(f\"Train Size: {x_train.shape[0]} samples\")\n    print(f\" Test Size: {x_test.shape[0]} samples\")\n    print(\"---------------------------------------------\")\n    print(f\"Training Time: {round(train_time, 3)} seconds\")\n    print(f\" Testing Time: {round(test_time, 3)} seconds\")\n    print(\"---------------------------------------------\")\n    print(\"Train Accuracy: \", train_acc)\n    print(\" Test Accuracy: \", test_acc)\n    print(\"---------------------------------------------\")\n    \n    if display_scores:\n        for k, v in scores_dict.items():\n            score_name = ' '.join(map(lambda x: x.title(), k.split('_')))\n            print(f'Train {score_name}: ', v[0])\n            print(f' Test {score_name}: ', v[1])\n            print()\n        print(\"---------------------------------------------\")\n    \n    print(\" Area Under ROC (test): \", roc_auc)\n    print(\"---------------------------------------------\")\n    print(f\"Model Memory Size: {model_mem} kB\")\n    print(\"\\n=============================> CLASSIFICATION REPORT <===================================\")\n    \n    ## Classification Report\n    clf_rep = classification_report(y_test, test_predictions, output_dict=True)\n    \n    print(classification_report(y_test, test_predictions,\n                                target_names=confusion_labels))\n    \n    \n    if verbose:\n        print(\"\\n================================> CONFUSION MATRIX <=====================================\")\n    \n        ## Confusion Matrix HeatMap\n        display(confusion_plot(confusion_matrix(y_test, test_predictions),\n                               labels=confusion_labels))\n        print(\"\\n=======================================> PLOTS <=========================================\")\n\n\n        ## Variable importance plot\n        fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n        roc_axes = axes[0, 0]\n        pr_axes = axes[0, 1]\n        importances = None\n\n        if importance_plot:\n            if not feature_labels:\n                raise RuntimeError(\"'feature_labels' argument not passed \"\n                                   \"when 'importance_plot' is True\")\n\n            try:\n                importances = pd.Series(clf.feature_importances_,\n                                        index=feature_labels) \\\n                                .sort_values(ascending=False)\n            except AttributeError:\n                try:\n                    importances = pd.Series(clf.coef_.ravel(),\n                                            index=feature_labels) \\\n                                    .sort_values(ascending=False)\n                except AttributeError:\n                    pass\n\n            if importances is not None:\n                # Modifying grid\n                grid_spec = axes[0, 0].get_gridspec()\n                for ax in axes[:, 0]:\n                    ax.remove()   # remove first column axes\n                large_axs = fig.add_subplot(grid_spec[0:, 0])\n\n                # Plot importance curve\n                feature_importance_plot(importances=importances.values,\n                                        feature_labels=importances.index,\n                                        ax=large_axs)\n                large_axs.axvline(x=0)\n\n                # Axis for ROC and PR curve\n                roc_axes = axes[0, 1]\n                pr_axes = axes[1, 1]\n            else:\n                # remove second row axes\n                for ax in axes[1, :]:\n                    ax.remove()\n        else:\n            # remove second row axes\n            for ax in axes[1, :]:\n                ax.remove()\n\n\n        ## ROC and Precision-Recall curves\n        clf_name = clf.__class__.__name__\n        roc_plot(y_test, y_probs, clf_name, ax=roc_axes)\n        precision_recall_plot(y_test, y_probs, clf_name, ax=pr_axes)\n\n        fig.subplots_adjust(wspace=5)\n        fig.tight_layout()\n        display(fig)\n    \n    ## Dump to report_dict\n    dump = dict(clf=clf, accuracy=[train_acc, test_acc], **scores_dict,\n                train_time=train_time, train_predictions=train_predictions,\n                test_time=test_time, test_predictions=test_predictions,\n                test_probs=y_probs, report=clf_rep, roc_auc=roc_auc,\n                model_memory=model_mem)\n    \n    return clf, dump","224ceba9":"def compare_models(y_test=None, clf_reports=[], labels=[], score='accuracy'):\n    \"\"\" Compare evaluation metrics for the True Positive class [1] of \n        binary classifiers passed in the argument and plot ROC and PR curves.\n        \n        Arguments:\n        ---------\n        y_test: to plot ROC and Precision-Recall curves\n         score: is the name corresponding to the sklearn metrics\n        \n        Returns:\n        -------\n        compare_table: pandas DataFrame containing evaluated metrics\n                  fig: `matplotlib` figure object with ROC and PR curves \"\"\"\n\n    \n    ## Classifier Labels\n    default_names = [rep['clf'].__class__.__name__ for rep in clf_reports]\n    clf_names =  labels if len(labels) == len(clf_reports) else default_names\n    \n    \n    ## Compare Table\n    table = dict()\n    index = ['Train ' + score, 'Test ' + score, 'Overfitting', 'Accuracy', 'ROC Area',\n             'Precision', 'Recall', 'F1-score', 'Support']\n    for i in range(len(clf_reports)):\n        scores = [round(i, 3) for i in clf_reports[i][score]]\n        \n        roc_auc = clf_reports[i]['roc_auc']\n        test_acc = clf_reports[i]['accuracy'][1]\n        \n        # Get metrics of True Positive class from sklearn classification_report\n        true_positive_metrics = list(clf_reports[i]['report'][\"1\"].values())\n        \n        table[clf_names[i]] = scores + [scores[1] < scores[0], test_acc, roc_auc] + \\\n                              true_positive_metrics\n    \n    table = pd.DataFrame(data=table, index=index)\n    \n    \n    ## Compare Plots\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n    \n    # ROC and Precision-Recall\n    for i in range(len(clf_reports)):\n        clf_probs = clf_reports[i]['test_probs']\n        roc_plot(y_test, clf_probs, label=clf_names[i],\n                 compare=True, ax=axes[0])\n        precision_recall_plot(y_test, clf_probs, label=clf_names[i],\n                              compare=True, ax=axes[1])\n    # Plot No-Info classifier\n    axes[0].plot([0,1], [0,1], linestyle='--', color='green')\n        \n    fig.tight_layout()\n    plt.close()\n    \n    return table.T, fig","559f8edc":"from sklearn import metrics\nprimary_eval_metric = metrics.f1_score\n\nconfusion_lbs = ['No Heart Failure', 'Heart Failure']","3834b048":"from sklearn.naive_bayes import CategoricalNB, GaussianNB \nfrom sklearn.preprocessing import KBinsDiscretizer, OrdinalEncoder\n\n\nnumeric_trans_nb = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler()),\n    ('kbn', KBinsDiscretizer(n_bins=5, encode='ordinal'))])\n\ncategorical_trans_nb = Pipeline(steps=[\n    ('ordinal', OrdinalEncoder(dtype=np.int64))])\n\n## Column Transformer\npreprocessor_nb = ColumnTransformer(\n    transformers=[\n        ('num', numeric_trans_nb, numeric_columns),\n        ('cat', categorical_trans_nb, categorical_columns)],\n    remainder='passthrough')\n\n\n## Applying Column Transformer\nx_train_nb = preprocessor_nb.fit_transform(x_train_cat)\nx_test_nb = preprocessor_nb.transform(x_test_cat)\n\nnb_clf = CategoricalNB()\n\nnb_clf, nb_report = report(nb_clf, x_train_nb, y_train,\n                           x_test_nb, y_test,\n                           display_scores=[primary_eval_metric],\n                           refit=True,\n                           confusion_labels=confusion_lbs)","db0f45f8":"from sklearn.linear_model import LogisticRegressionCV\n\nlogit_cv = LogisticRegressionCV(class_weight='balanced', cv=5,\n                                max_iter=500, penalty='l1',\n                                scoring='f1', solver='liblinear',\n                                n_jobs=-1, random_state=seed_val,\n                                refit=True, verbose=0)\n\nlogit_cv, logit_report = report(logit_cv, x_train, y_train,\n                                x_test, y_test,\n                                display_scores=[primary_eval_metric],\n                                importance_plot=True,\n                                feature_labels=feature_names,\n                                confusion_labels=confusion_lbs)","b19b9f48":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5, p=3,\n                           weights='distance', n_jobs=-1)\n\nknn, knn_report = report(knn, x_train, y_train,\n                         x_test, y_test,\n                         display_scores=[primary_eval_metric],\n                         importance_plot=True,\n                         feature_labels=feature_names,\n                         confusion_labels=confusion_lbs)","e0c672c2":"from sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier(class_weight='balanced',\n                                       criterion='entropy',\n                                       max_depth=6, max_leaf_nodes=10,\n                                       min_samples_split=0.2,\n                                       random_state=seed_val)\n\ndecision_tree, decision_tree_report = report(decision_tree, x_train, y_train,\n                                             x_test, y_test,\n                                             display_scores=[primary_eval_metric],\n                                             importance_plot=True,\n                                             feature_labels=feature_names,\n                                             confusion_labels=confusion_lbs)","f3744b83":"from sklearn.ensemble import BaggingClassifier\n\nbagging_dtree = DecisionTreeClassifier(max_depth=2, class_weight='balanced',\n                                       criterion='entropy', random_state=seed_val)\n\nbagging_clf = BaggingClassifier(base_estimator=bagging_dtree,\n                                max_samples=0.745, n_estimators=100,\n                                max_features=0.37,\n                                n_jobs=-1, random_state=seed_val)\n\nbagging_clf, bagging_clf_report = report(bagging_clf, x_train, y_train,\n                                         x_test, y_test,\n                                         display_scores=[primary_eval_metric],\n                                         feature_labels=feature_names,\n                                         confusion_labels=confusion_lbs)","770ff152":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(class_weight='balanced', criterion='entropy',\n                                       max_depth=2, max_samples=0.63, n_estimators=100,\n                                       n_jobs=-1, random_state=seed_val)\n\nrandom_forest, random_forest_report = report(random_forest, x_train, y_train,\n                                             x_test, y_test,\n                                             display_scores=[primary_eval_metric],\n                                             importance_plot=True,\n                                             feature_labels=feature_names,\n                                             confusion_labels=confusion_lbs)","6e8a089f":"from sklearn.ensemble import AdaBoostClassifier\n\nadaboot = AdaBoostClassifier(n_estimators=57, learning_rate=0.064,\n                             random_state=seed_val)\n\nadaboot, adaboot_report = report(adaboot, x_train, y_train,\n                                 x_test, y_test,\n                                 display_scores=[primary_eval_metric],\n                                 importance_plot=True,\n                                 feature_labels=feature_names,\n                                 confusion_labels=confusion_lbs)","113d7dbf":"from sklearn.svm import SVC\n\nlinear_svc = SVC(C=2.1, kernel='linear', probability=True,\n                 class_weight='balanced', random_state=seed_val)\n\nlinear_svc, linear_svc_report = report(linear_svc, x_train, y_train,\n                                       x_test, y_test,\n                                       display_scores=[primary_eval_metric],\n                                       importance_plot=True,\n                                       feature_labels=feature_names,\n                                       confusion_labels=confusion_lbs)","afec16c5":"rbf_svc = SVC(C=0.25, kernel='rbf', probability=True,\n              class_weight='balanced', random_state=seed_val)\n\nrbf_svc, rbf_svc_report = report(rbf_svc, x_train, y_train,\n                                 x_test, y_test,\n                                 display_scores=[primary_eval_metric],\n                                 importance_plot=True,\n                                 feature_labels=feature_names,\n                                 confusion_labels=confusion_lbs)","8acbcae5":"from xgboost import XGBClassifier\nfrom sklearn.utils import class_weight\n\ncls_weight = (y_train.shape[0] - np.sum(y_train)) \/ np.sum(y_train)\n\nparams = {'learning_rate': 0.014724527414939945,\n          'num_boost_round': 3451,\n          'gamma': 0.4074467665676125,\n          'reg_lambda': 31.082862686792716,\n          'reg_alpha': 0.008543705214252668,\n          'max_depth': 7,\n          'min_child_weight': 3.2435633342899867e-06,\n          'subsample': 0.15432895096353877,\n          'colsample_bytree': 0.7665394913603492}\n\nxgb_clf = XGBClassifier(**params, scale_pos_weight=cls_weight,\n                        random_state=seed_val, n_jobs=-1)\nxgb_clf.fit(x_train, y_train);\n\nxgb_clf, xgb_report = report(xgb_clf, x_train, y_train,\n                             x_test, y_test,\n                             display_scores=[primary_eval_metric],\n                             importance_plot=True,\n                             feature_labels=feature_names,\n                             confusion_labels=confusion_lbs)","0efb83a0":"from lightgbm import LGBMClassifier\n\nparams = {'objective': 'binary', 'verbose': -1, 'lambda_l1': 0.0,\n          'lambda_l2': 0.0, 'num_leaves': 31, 'feature_fraction': 0.8,\n          'bagging_fraction': 0.49916588402130324, 'bagging_freq': 3,\n          'min_child_samples': 20}\n\nlgbm_clf = LGBMClassifier(**params, random_state=seed_val, n_jobs=-1)\nlgbm_clf.fit(x_train, y_train);\n\nlgbm_clf, lgbm_report = report(lgbm_clf, x_train, y_train,\n                               x_test, y_test,\n                               display_scores=[primary_eval_metric],\n                               importance_plot=True,\n                               feature_labels=feature_names,\n                               confusion_labels=confusion_lbs)","98e8f66e":"from catboost import CatBoostClassifier\n\ncatboost_clf = CatBoostClassifier(cat_features=categorical_columns,\n                                  l2_leaf_reg=120, depth=6,\n                                  auto_class_weights='Balanced',\n                                  iterations=200, learning_rate=0.16,\n                                  use_best_model=True,\n                                  early_stopping_rounds=150,\n                                  eval_metric='F1', random_state=seed_val)\n\ncatboost_clf.fit(x_train_cat, y_train, \n                 eval_set=(x_train_cat, y_train),\n                 verbose=False)\n\n\nf_labels = categorical_columns+numeric_columns\ncatboost_clf, catboost_report = report(catboost_clf, x_train_cat, y_train,\n                                       x_test_cat, y_test,\n                                       display_scores=[primary_eval_metric],\n                                       importance_plot=True,\n                                       feature_labels=f_labels,\n                                       confusion_labels=confusion_lbs)","2e7eb397":"from sklearn.utils.class_weight import compute_class_weight\n\nCLASS_WEIGHT = compute_class_weight(class_weight='balanced',\n                                    classes=np.unique(y_train),\n                                    y=y_train)\nCLASS_WEIGHT = dict(zip([0, 1], CLASS_WEIGHT))\n\nBATCHSIZE = x_train.shape[0]\nFEATURES = x_train.shape[1]\nCLASSES = 1\nEPOCHS = 1000\nN_TRAIN_EXAMPLES = x_train.shape[0]\nSTEPS_PER_EPOCH = N_TRAIN_EXAMPLES \/\/ BATCHSIZE","e46e2db2":"def create_model(params, num_classes, metrics):    \n    layers_list = [keras.layers.InputLayer(input_shape=(FEATURES,))]\n    \n    for l in range(1, params['num_layers'] + 1):\n        new_layers = [keras.layers.BatchNormalization(),\n                      keras.layers.Dense(params[f'units_{l}'], activation='relu',\n                                         kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed_val),\n                                         kernel_regularizer=keras.regularizers.l2(0.001),\n                                         use_bias=True),\n                      keras.layers.Dropout(params[f'drop_rate_{l}'], seed=seed_val)]\n        layers_list.extend(new_layers)\n    \n    layers_list.append(keras.layers.Dense(num_classes, activation='sigmoid'))\n    model = keras.Sequential(layers=layers_list)\n    \n    model.compile(optimizer='adam',\n                  loss=\"binary_crossentropy\",\n                  metrics=metrics)\n\n    return model","a78bfd4e":"tf.keras.backend.clear_session()\n\nparams_dict = {'drop_rate_1': 0.7, 'num_layers': 1, 'units_1': 8}\n\n## tf.keras.metrics does not have F1-score so we will use Recall\nmodel = create_model(params=params_dict, num_classes=CLASSES,\n                     metrics=[keras.metrics.Recall()])\n\nmodel.summary()","2382ff5f":"callbacks = [tf.keras.callbacks.EarlyStopping(patience=5, verbose=0)]\n\nhistory = model.fit(x=x_train, y=y_train,\n                    batch_size=BATCHSIZE,\n                    epochs=EPOCHS,\n                    verbose=0,\n                    callbacks=callbacks,\n                    validation_data=(x_test, y_test),\n                    shuffle=True,\n                    class_weight=CLASS_WEIGHT,\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    use_multiprocessing=True)\n\n_, nn_report = report(model, x_train, y_train,\n                      x_test, y_test,\n                      display_scores=[primary_eval_metric],\n                      confusion_labels=confusion_lbs,\n                      neural_net=True)","69103ab8":"report_list = [nb_report, logit_report, knn_report, decision_tree_report,               \n               bagging_clf_report, random_forest_report, adaboot_report,\n               xgb_report, lgbm_report, catboost_report, nn_report,\n               linear_svc_report, rbf_svc_report]\nclf_labels = [rep['clf'].__class__.__name__ for rep in report_list]\nclf_labels[-3] = 'Neural Nets'\nclf_labels[-2] = 'Linear SVC'\nclf_labels[-1] = 'RBF SVC'","3bfe2ed8":"compare_table, compare_plot = compare_models(y_test, clf_reports=report_list,\n                                             labels=clf_labels,\n                                             score=primary_eval_metric.__name__)\n\ncompare_table.sort_values(by=['Overfitting', 'F1-score'], ascending=[True, False])","cbddc4e4":"compare_plot","986e2cfb":"<a id=\"correlations-in-the-data\"><\/a>\n# 2.   Correlations in the Data","d1f6f3cc":"<a id=\"correlation-between-qualitative\/-categorical-variables\"><\/a>\n## 2.2.   Correlation between Qualitative\/ Categorical variables","c8fc8ab2":"<a id=\"train-test-split\"><\/a>\n## 4.1.   Train-Test split\nCatBoost classifier does not require any knd of preprocessing while Naive bayes requires a different kind of preprocesing. Therefore, we will use raw\/ unmodified data (`x_train_cat, x_test_cat, y_train_cat, y_test_cat`) for CatBoost and preprocessed data (`x_train, x_test, y_train, y_test`) for all other classifiers. For Naive Bayes, we will use the raw data (`x_train_cat, x_test_cat, y_train_cat, y_test_cat`) and preprocess it as required in the Naive Bayes section.","a30bd826":"<a id=\"utility-functions\"><\/a>\n## 5.1.   Utility Functions","f3ec92e8":"<a id=\"heart-failure-among-gender-based-on-anaemia-and-diabetes\"><\/a>\n## 3.5.   Heart failure among gender based on anaemia and diabetes","906627cb":"<a id=\"xgboost\"><\/a>\n## 5.11.   XGBoost","c7773df5":"<a id=\"naive-bayes\"><\/a>\n## 5.2. Naive Bayes\nThe fundamental assumption made by Naive Bayes regarding the data is ***class conditional independence of features***. Sklearn provides different variants of Naive Bayes depending on whether the features follow a categorical distribution (CategoricalNB), normal distribution (GaussianNB), bernoulli distribution (BernoulliNB), multinomial distribution (MultinomialNB).\n\nSince majority of the features are categorical and follow a categorical distribution, we will use CategoricalNB. Continuous features will be discretized.","149f72b4":"`Cramer's V` is more appropriate than Pearson correlation to find correlation between two nominal variables. Here, the `Cramer's V` metric is implemented.","1ace0b4c":"<a id=\"lightgbm\"><\/a>\n## 5.12.   LightGBM\nLightGBM is similar to XGBoost but grows the trees in the ensemble based on Leaf-wise growth algorithm unlike Level-wise algorithm in XGBoost.","6eed8577":"<a id=\"frequency-distribution%3A-continuous-variables\"><\/a>\n## 3.2.   Frequency distribution: Continuous Variables","d096ee6d":"<a id=\"data-preprocessing\"><\/a>\n# 4.   Data Preprocessing","a7098f75":"<a id=\"frequency-distribution%3A-categorical-variables\"><\/a>\n## 3.1.   Frequency distribution: Categorical Variables","931d8133":"<a id=\"catboost\"><\/a>\n## 5.13.   CatBoost\nCat boost performs better without One-hot encoding because it performs an internal categorical encoding that is similar to Leave One Out Encoding (LOOE). So, we can give the dataframe as input to the catboost classifier.","aa45fa42":"***Inference:*** Only follow-up period is highly correlated to hearth failure relative to other features.","50dff5b2":"<a id=\"svm-with-rbf-kernel\"><\/a>\n## 5.10.   SVM with RBF kernel","a395c83a":"Data needs to be one-hot-encoded before applying machine learning models.","9d06954f":"<a id=\"data-modeling\"><\/a>\n# 5.   Data Modeling\nSince the dataset is imbalanced we will be using class-weighted\/ cost-sensitive learning. In cost-sensitive learning, a weighted cost function is used. Therefore, misclassifying a sample from the minority class will cost the classifiers more than misclassifying a sample from the majority class. In most of the Sklearn classifiers, cost-sensitive learning can be enabled by setting `class_weight='balanced'`.","69539148":"<a id=\"linear-svc\"><\/a>\n## 5.9.   Linear SVC","7f391f52":"**Highlights:**\n> 1. Correlation analysis using Pearson coefficient for continuous features and Cramer's V for categorical features\n>\n> 2. Data visualization using Seaborn FacetGrid plots\n>\n> 3. Classification of imbalanced dataset using `class weighted` or `cost sensitive` learning\n>\n> 4. Results for each ML algorithm are presented after performing 5-fold cross validation based on F1-score","469f17b5":"<a id=\"decision-tree\"><\/a>\n## 5.5.   Decision Tree","a42c0d8a":"<a id=\"box-plots-%3A-outlier-detection\"><\/a>\n## 3.3.   Box plots : Outlier detection","d7005b1d":"<a id=\"heart-failure-among-gender-based-on-smoking-and-bp\"><\/a>\n## 3.4.   Heart failure among gender based on smoking and BP","50a36d07":"<a id=\"correlation-between-quantitative-variables\"><\/a>\n## 2.1.   Correlation between Quantitative variables","a8d9786b":"<a id=\"import-and-clean-data\"><\/a>\n# 1.   Import and Clean Data","40fe7baa":"<a id=\"evaluation-metrics\"><\/a>\n## 6.1.   Evaluation Metrics","7d70b64a":"<a id=\"model-comparison\"><\/a>\n# 6.   Model Comparison","af969419":"Modifying seaborn countplot make it work with FacetGrid when all 3 arguments (`hue`, `row`, and `col`) are used.","c9b91f90":"<a id=\"random-forests\"><\/a>\n## 5.7.   Random Forests","1c140d50":"Thank you for reading!!","a566a9df":"# Comparing the performance of 13 Classifiers based on F1-score","c60f90cd":"<a id=\"missing-values\"><\/a>\n## 1.1.   Missing values","372e321a":"<a id=\"preprocessing-pipeline%3A-one-hot-encoding%2C-standardization\"><\/a>\n## 4.2.   Preprocessing Pipeline: One-hot Encoding, Standardization\nWe need to standardize the continuous or quantitative variables\/ features before applying Machine Learning models. This is important because if we don't standardize the features, features with high variance that are orders of magnitude larger that others might dominate the model fitting process and causing the model unable to learn from other features (with lower variance) correctly as expected. <br\/>\nThere is no need to standardize categorical variables.\n\nTo know which algorithms require standardization\/ feature scaling read this useful [stackoverflow post](https:\/\/stats.stackexchange.com\/questions\/244507\/what-algorithms-need-feature-scaling-beside-from-svm).\n\n***Also we need to standardize the data only after performing train-test split because if we standardize before splitting then there is a chance for some information leak from the test set into the train set. We always want the test set to be completely new to the ML models. [Read more](https:\/\/scikit-learn.org\/stable\/modules\/compose.html#columntransformer-for-heterogeneous-data)***","67385dca":"<a id=\"roc-and-pr-curves\"><\/a>\n## 6.2.   ROC and PR Curves","a0b7cf1a":"The dataset has no missing values.","84aea8aa":"<a id=\"type-casting-from-%60object%60-to-%60categorical%60-and-deleting-features\"><\/a>\n## 1.2.   Type casting from `object` to `Categorical` and deleting features\n\nFinding categorical features and converting their pandas *dtype* to `categorical` will ease visualization","2a0181dd":"<a id=\"k-nearest-neighbors\"><\/a>\n## 5.4.   K-Nearest Neighbors\nKNN estimator in Scikit-learn does not provide a way to pass class-weights to enable cost-sensitive\/ class-weighted learning.","3c8a790f":"<a id=\"decision-trees-with-adaboost\"><\/a>\n## 5.8.   Decision Trees with AdaBoost\nThe default base estimator for `AdaBoostClassifier` is `DecisionTreeClassifier(max_depth=1)`","65e53eaf":"* [1.   Import and Clean Data](#import-and-clean-data)\n    * [1.1.   Missing values](#missing-values)\n    * [1.2.   Type casting from `object` to `Categorical` and deleting features](#type-casting-from-%60object%60-to-%60categorical%60-and-deleting-features)\n* [2.   Correlations in the Data](#correlations-in-the-data)\n    * [2.1.   Correlation between Quantitative variables](#correlation-between-quantitative-variables)\n    * [2.2.   Correlation between Qualitative\/ Categorical variables](#correlation-between-qualitative\/-categorical-variables)\n* [3.   Data Visualization](#data-visualization)\n    * [3.1.   Frequency distribution: Categorical Variables](#frequency-distribution%3A-categorical-variables)\n    * [3.2.   Frequency distribution: Continuous Variables](#frequency-distribution%3A-continuous-variables)\n    * [3.3.   Box plots : Outlier detection](#box-plots-%3A-outlier-detection)\n    * [3.4.   Heart failure among gender based on smoking and BP](#heart-failure-among-gender-based-on-smoking-and-bp)\n    * [3.5.   Heart failure among gender based on anaemia and diabetes](#heart-failure-among-gender-based-on-anaemia-and-diabetes)\n* [4.   Data Preprocessing](#data-preprocessing)\n    * [4.1.   Train-Test split](#train-test-split)\n    * [4.2.   Preprocessing Pipeline: One-hot Encoding, Standardization](#preprocessing-pipeline%3A-one-hot-encoding%2C-standardization)\n* [5.   Data Modeling](#data-modeling)\n    * [5.1.   Utility Functions](#utility-functions)\n    * [5.2. Naive Bayes](#naive-bayes)\n    * [5.3.   Logistic Regression](#logistic-regression)\n    * [5.4.   K-Nearest Neighbors](#k-nearest-neighbors)\n    * [5.5.   Decision Tree](#decision-tree)\n    * [5.6.   Decision Trees with Bagging](#decision-trees-with-bagging)\n    * [5.7.   Random Forests](#random-forests)\n    * [5.8.   Decision Trees with AdaBoost](#decision-trees-with-adaboost)\n    * [5.9.   Linear SVC](#linear-svc)\n    * [5.10.   SVM with RBF kernel](#svm-with-rbf-kernel)\n    * [5.11.   XGBoost](#xgboost)\n    * [5.12.   LightGBM](#lightgbm)\n    * [5.13.   CatBoost](#catboost)\n    * [5.14.   Artificial Neural Networks](#artificial-neural-networks)\n* [6.   Model Comparison](#model-comparison)\n    * [6.1.   Evaluation Metrics](#evaluation-metrics)\n    * [6.2.   ROC and PR Curves](#roc-and-pr-curves)","568c3456":"<a id=\"artificial-neural-networks\"><\/a>\n## 5.14 Artificial Neural Networks","4bbb288f":"<a id=\"data-visualization\"><\/a>\n# 3.   Data Visualization","ace3df7d":"<a id=\"decision-trees-with-bagging\"><\/a>\n## 5.6.   Decision Trees with Bagging","5c497288":"***Inference:*** From the `DEATH_EVENT` plot we can see that the dataset is imbalanced.","b2ed11db":"<a id=\"logistic-regression\"><\/a>\n## 5.3.   Logistic Regression"}}