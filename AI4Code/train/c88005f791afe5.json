{"cell_type":{"37e557c4":"code","06c9bbb4":"code","79b8a880":"code","2af32a45":"code","5cfb7a84":"code","baf41e8e":"code","afa8721b":"code","2fa36cad":"code","2ae7cf96":"code","edcc5ba5":"code","f7a3f5e2":"code","d35c868c":"code","aec7e543":"code","4d734031":"code","70b55430":"code","23743c4b":"code","34866b18":"code","01e46ebd":"code","66f08670":"code","e238a42f":"code","260192ce":"code","db272084":"code","f5b93292":"code","f45eac6c":"code","aab47b67":"code","63c51fb4":"code","bab57f97":"markdown","707e6d5f":"markdown","1895da59":"markdown"},"source":{"37e557c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06c9bbb4":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers,layers, models\n\n\ntf.__version__","79b8a880":"train_data = pd.read_csv('..\/input\/nicht-mnist\/train.csv',header=None, index_col =0)\ntest_data = pd.read_csv('..\/input\/nicht-mnist\/test.csv',header=None , index_col = 0)","2af32a45":"test_data.shape","5cfb7a84":"test_data.shape","baf41e8e":"y = train_data[1]\nx = train_data.drop(columns=[1])","afa8721b":"len(y.unique())","2fa36cad":"y.value_counts()","2ae7cf96":"x = x \/ 255.0\ntest_data = test_data \/ 255.0\n","edcc5ba5":"x = x.values.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)","f7a3f5e2":"x.shape","d35c868c":"test_data.shape","aec7e543":"from tensorflow import keras\nfrom keras.layers import Dense, Dropout","4d734031":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder=LabelEncoder()\ny = pd.DataFrame(label_encoder.fit_transform(y))","70b55430":"from sklearn.model_selection import train_test_split\ntrain_x, val_x,train_y, val_y = train_test_split(x, y, test_size = 0.2, random_state=1)","23743c4b":"sequential = keras.Sequential([\n    keras.layers.Flatten(input_shape=(28, 28)),\n    keras.layers.Dense(128, activation='relu'),\n    keras.layers.Dense(128, activation='relu'),\n    keras.layers.Dense(10)\n])","34866b18":"sequential.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","01e46ebd":"sequential_history=sequential.fit(train_x, train_y, epochs=10, batch_size=32,validation_data=(val_x, val_y))\n","66f08670":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.plot(sequential_history.history['accuracy'], label='Training accuracy')\nplt.plot(sequential_history.history['val_accuracy'], label = 'Validation accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(sequential_history.history['loss'], label='Training Loss')\nplt.plot(sequential_history.history['val_loss'], label = 'Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n\ntest_loss, test_acc = sequential.evaluate(val_x,  val_y, verbose=2)\nprint('\\nTest accuracy:', test_acc)","e238a42f":"cnn = models.Sequential()\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28,1)))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu'))\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu'))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu'))\ncnn.add(Dropout(0.25))\ncnn.add(layers.Flatten())\ncnn.add(layers.Dense(64, activation='relu'))\ncnn.add(Dropout(0.5))\ncnn.add(layers.Dense(10))\ncnn.summary()","260192ce":"cnn.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\ncallbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\ncnn_history = cnn.fit(train_x, train_y, epochs=100, batch_size=32,validation_data=(val_x, val_y),callbacks=[callbacks])","db272084":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.plot(cnn_history.history['accuracy'], label='Training accuracy')\nplt.plot(cnn_history.history['val_accuracy'], label = 'Validation accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(cnn_history.history['loss'], label='Training Loss')\nplt.plot(cnn_history.history['val_loss'], label = 'Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n\ntest_loss, test_acc = cnn.evaluate(val_x,  val_y, verbose=2)\nprint('\\nTest accuracy:', test_acc)","f5b93292":"probability_model = tf.keras.Sequential([cnn,tf.keras.layers.Softmax()])\n\npredictions = probability_model.predict(test_data)\n\nresults = np.argmax(predictions,axis = 1)\n","f45eac6c":"results = pd.Series(results,name=\"target\")\nsubmission = pd.concat([pd.Series(range(0,9364),name = \"Id\"),results],axis = 1)\n\n","aab47b67":"submission['target'] = label_encoder.inverse_transform(submission['target'])\n","63c51fb4":"submission.to_csv('nicht-mnist_cnn.csv', index=False)","bab57f97":"# Training and Validation Accuracy","707e6d5f":"# import Libraries","1895da59":"# Sequential"}}