{"cell_type":{"1bc38bf5":"code","2af87aa1":"code","4440e87f":"code","f20fcfce":"code","221c8794":"code","c0bef4d5":"code","e918442d":"code","a4f1586d":"code","2a6ce75b":"code","2a04d300":"code","7f9ca852":"code","acbfc0eb":"code","94916b97":"code","9b6a175a":"code","99f622be":"code","63ccbe34":"code","cec44da3":"code","d54bd093":"code","90700ad6":"code","d15e2765":"markdown","d8be945c":"markdown","7585795a":"markdown","1e7aba2a":"markdown","b2899e9f":"markdown","2d4407d3":"markdown","0ae0349a":"markdown","a0750603":"markdown","490a9ccb":"markdown","6aab7fac":"markdown","17f2a57a":"markdown","cbf0ab2c":"markdown"},"source":{"1bc38bf5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2af87aa1":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import hstack","4440e87f":"train_df = pd.read_csv(f'..\/input\/jigsaw-toxic-severity-rating\/{filenames[1]}')","f20fcfce":"test_df = pd.read_csv(f'..\/input\/jigsaw-toxic-severity-rating\/{filenames[2]}')","221c8794":"less_df = pd.DataFrame([[v, 0] for v in train_df['less_toxic'].values], columns=['text', 'label'])\nmore_df = pd.DataFrame([[v, 1] for v in train_df['more_toxic'].values], columns=['text', 'label'])\ntrain_labeled_df = less_df.append(more_df).sample(frac=1)","c0bef4d5":"all_text = pd.concat([train_labeled_df['text'], test_df['text']])","e918442d":"word_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 1),\n    norm='l2',\n    min_df=0,\n    smooth_idf=False,\n    max_features=15000\n)","a4f1586d":"word_vectorizer.fit(all_text)\ntrain_word_X = word_vectorizer.transform(train_labeled_df['text'])\ntest_word_X = word_vectorizer.transform(test_df['text'])","2a6ce75b":"char_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    ngram_range=(2, 6),\n    norm='l2',\n    min_df=0,\n    smooth_idf=False,\n    max_features=50000\n)","2a04d300":"char_vectorizer.fit(all_text)\ntrain_char_X = char_vectorizer.transform(train_labeled_df['text'])\ntest_char_X = char_vectorizer.transform(test_df['text'])","7f9ca852":"vec3 = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(4, 6))","acbfc0eb":"vec3.fit(all_text)\ntrain_X3 = vec3.transform(train_labeled_df['text'])\ntest_X3 = vec3.transform(test_df['text'])","94916b97":"X_train_concat = hstack([train_char_X, train_word_X, train_X3])\nX_test_concat = hstack([test_char_X, test_word_X, test_X3])","9b6a175a":"params = {\n    'objective': 'binary:logistic',\n     'tree_method': 'gpu_hist',\n     'scale_pos_weight': 1,\n     'eval_metric': 'auc',\n     'subsample': 0.8,\n     'colsample_bytree': 0.8,\n     'verbosity': 2,\n     'max_depth': 9,\n     'min_child_weight': 7,\n     'eta': 0.2\n}","99f622be":"x, x_val, y, y_val = train_test_split(\n    X_train_concat, train_labeled_df['label'], test_size=0.2, stratify=train_labeled_df['label'])\nd_train = xgb.DMatrix(\n    x, label=y\n)\nd_valid = xgb.DMatrix(\n    x_val, label=y_val\n)\nwatchlist = [(d_train, \"train\"), (d_valid, \"valid\")]\nbst = xgb.train(params, d_train, evals=watchlist,\n                num_boost_round=1000, early_stopping_rounds=50)","63ccbe34":"d_test = xgb.DMatrix(X_test_concat)","cec44da3":"preds = bst.predict(d_test)","d54bd093":"sub_df = pd.DataFrame()\nsub_df['comment_id'] = test_df['comment_id']\nsub_df['score'] = preds\nsub_df['score'] = sub_df['score'].rank(method='first')","90700ad6":"sub_df.to_csv(\"submission.csv\", index=False)","d15e2765":"## 1. Load libraries","d8be945c":"### V. concat all training TFIDF data","7585795a":"## 3. Preprocessing","1e7aba2a":"# **Please, upvote if it was helpful!!!**","b2899e9f":"### II. TFIDF 1: word analyzer","2d4407d3":"### I. Labeling data: more toxic as 1 and less toxic as 0","0ae0349a":"## 2. Load Datasets","a0750603":"# Binary Classification (w\/ TFIDF + XGBOOST)\nDefine the problem as classification between less toxic and more toxic.","490a9ccb":"## 5. Submission","6aab7fac":"### IV. TFIDF 3: char_wb analyzer","17f2a57a":"## 4. Modeling","cbf0ab2c":"### III. TFIDF 2: char analyzer"}}