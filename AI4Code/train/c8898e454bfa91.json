{"cell_type":{"3a01c358":"code","9cf8e28d":"code","593b442c":"code","58547529":"code","3128c5f3":"code","671f790d":"code","eabbc166":"code","d32a0bba":"code","18754498":"code","26eeb66a":"code","d944b5d2":"code","dbadfb92":"code","74e443ae":"code","c48a06fd":"code","5d6f5840":"code","a49685e1":"code","bbc23149":"code","42bb006d":"code","4fd14fb2":"code","5f9acd18":"code","d5d76252":"code","fb4b4647":"code","c2240778":"code","7df466ef":"code","1e9b03c1":"code","cb86e1ee":"code","b18d7370":"code","416e6369":"code","588fd1c0":"code","cb1115bf":"code","b7df50ba":"code","bd77ebf6":"code","90f2535c":"code","64d9b569":"code","d335f3a5":"code","ca235eb8":"code","0fff32fb":"code","d27d7766":"code","800e3205":"code","09bf7a26":"code","53b9793f":"code","7724eeba":"code","7214b6ce":"code","1879d8e7":"markdown","80b85241":"markdown","d94af60b":"markdown","218ad25b":"markdown","167439cd":"markdown","8f7d7ef0":"markdown","14b34370":"markdown"},"source":{"3a01c358":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9cf8e28d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nsns.set_style('whitegrid')\n \n%config InlineBackend.figure_format = 'retina'\nfrom sklearn.metrics import classification_report\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')","593b442c":"df=pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.head()","58547529":"df.isna().sum()","3128c5f3":"df.columns","671f790d":"col = [   'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age' ]\nfor i in col:\n    df[i].replace(0, np.nan,inplace=True)","eabbc166":"df.isna().sum()","d32a0bba":"def det_median(col_name):\n    select_not_null=df[df[col_name].notnull()]\n    result=select_not_null[[col_name,'Outcome']].groupby(['Outcome'])[[col_name]].median().reset_index()\n    return result","18754498":"det_median('BMI')\n","26eeb66a":"det_median('Insulin')  ","d944b5d2":"det_median('Pregnancies')","dbadfb92":"det_median('BloodPressure')","74e443ae":"det_median('SkinThickness')","c48a06fd":"det_median('DiabetesPedigreeFunction')","5d6f5840":"det_median('Glucose')","a49685e1":"df.loc[(df['Outcome']==0) & (df['BMI'].isnull()),'BMI'] =30.1\ndf.loc[(df['Outcome']==1) & (df['BMI'].isnull()),'BMI'] =30.1\ndf.loc[(df['Outcome']==0) & (df['Glucose'].isnull()),'Glucose'] =107.0\ndf.loc[(df['Outcome']==1) & (df['Glucose'].isnull()),'Glucose'] =140.0\ndf.loc[(df['Outcome']==0) & (df['BloodPressure'].isnull()),'BloodPressure'] =70.0\ndf.loc[(df['Outcome']==1) & (df['BloodPressure'].isnull()),'BloodPressure'] =74.5\n# df.loc[(df['Outcome']==0) & (df['Pregnancies'].isnull()),'Pregnancies'] =3 \n# df.loc[(df['Outcome']==1) & (df['Pregnancies'].isnull()),'Pregnancies'] =5\ndf.loc[(df['Outcome']==0) & (df['Insulin'].isnull()),'Insulin'] =102.5\ndf.loc[(df['Outcome']==1) & (df['Insulin'].isnull()),'Insulin'] =169.5\ndf.loc[(df['Outcome']==0) & (df['SkinThickness'].isnull()),'SkinThickness'] =27.0\ndf.loc[(df['Outcome']==1) & (df['SkinThickness'].isnull()),'SkinThickness'] =32.0","bbc23149":"\ndf.isna().sum() ","42bb006d":"#sns.PairGrid(data = df.Age)\n\nsns.boxplot(df.Age)","4fd14fb2":"det_median('Age')","5f9acd18":"\ndf.loc[(df['Outcome']==0) & (df['Age']>63),'Age'] =27\ndf.loc[(df['Outcome']==1) & (df['Age']>63),'Age'] =36","d5d76252":"fig,axes=plt.subplots(4,2,figsize=(23,30))\nsns.boxplot(ax=axes[0,0],x='Age' ,data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[0,1],x='BMI',data=df,color='red',fliersize=8)\nsns.boxplot(ax=axes[1,0],x='Pregnancies',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[1,1],x='Glucose',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[2,0],x='Insulin',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[2,1],x='SkinThickness',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[3,0],x='BloodPressure',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[3,1],x='DiabetesPedigreeFunction',data=df,color='orange',fliersize=8)\n","fb4b4647":"df.loc[(df['Outcome']==0) & (df['BMI'] >52),'BMI'] =30.1\ndf.loc[(df['Outcome']==1) & (df['BMI']>52),'BMI'] =30.1\n \ndf.loc[(df['Outcome']==0) & (df['BloodPressure']>105),'BloodPressure'] =70.0\ndf.loc[(df['Outcome']==1) & (df['BloodPressure']>105),'BloodPressure'] =74.5\ndf.loc[(df['Outcome']==0) & (df['Pregnancies']>12),'Pregnancies'] =2 \ndf.loc[(df['Outcome']==1) & (df['Pregnancies']>12),'Pregnancies'] =4\ndf.loc[(df['Outcome']==0) & (df['Insulin']>250),'Insulin'] =102.5\ndf.loc[(df['Outcome']==1) & (df['Insulin']>250),'Insulin'] =169.5\ndf.loc[(df['Outcome']==0) & (df['SkinThickness']>40),'SkinThickness'] =27.0\ndf.loc[(df['Outcome']==1) & (df['SkinThickness']>40),'SkinThickness'] =32.0\ndf.loc[(df['Outcome']==0) & (df['DiabetesPedigreeFunction']>1),'DiabetesPedigreeFunction'] =0.336\ndf.loc[(df['Outcome']==1) & (df['DiabetesPedigreeFunction']>1),'DiabetesPedigreeFunction'] =0.449","c2240778":"df.loc[(df['Outcome']==0) & (df['SkinThickness']<20),'SkinThickness'] =27.0\ndf.loc[(df['Outcome']==1) & (df['SkinThickness']<20),'SkinThickness'] =32.0\ndf.loc[(df['Outcome']==0) & (df['BloodPressure']<40),'BloodPressure'] =70.0\ndf.loc[(df['Outcome']==1) & (df['BloodPressure']<40),'BloodPressure'] =74.5","7df466ef":"fig,axes=plt.subplots(4,2,figsize=(23,30))\nsns.boxplot(ax=axes[0,0],x='Age' ,data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[0,1],x='BMI',data=df,color='red',fliersize=8)\nsns.boxplot(ax=axes[1,0],x='Pregnancies',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[1,1],x='Glucose',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[2,0],x='Insulin',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[2,1],x='SkinThickness',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[3,0],x='BloodPressure',data=df,color='orange',fliersize=8)\nsns.boxplot(ax=axes[3,1],x='DiabetesPedigreeFunction',data=df,color='orange',fliersize=8)\n","1e9b03c1":"# Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n#        'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],","cb86e1ee":"X=df.drop(['Outcome'],axis=1)\ny=df['Outcome']","b18d7370":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)","416e6369":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\nlogreg.fit(X_train,y_train)\ny_predict_logreg = logreg.predict(X_test)\nprint(classification_report(y_test,y_predict_logreg))","588fd1c0":"from sklearn.ensemble import RandomForestRegressor\nrforest = RandomForestRegressor()\nrforest.fit(X_train,y_train)\nrforest.score(X_test,y_test)\n ","cb1115bf":"from sklearn.svm import SVC\nclassifier = SVC(kernel='rbf', random_state = 1)\nclassifier.fit(X_train,y_train)\nclassifier.score(X_test,y_test)\ny_pred_svm = classifier.predict(X_test)\nprint(classification_report(y_test,y_pred_svm))","b7df50ba":"import xgboost as xgb\nmodel=xgb.XGBClassifier(random_state=1,learning_rate=0.02)\nmodel.fit(X_train, y_train)\nmodel.score(X_test,y_test)\ny_predict_xg=model.predict(X_test)\nprint(classification_report(y_test,y_predict_xg))","bd77ebf6":"from sklearn import model_selection,metrics ","90f2535c":"cv = model_selection.StratifiedKFold(n_splits=10)\n\ndef acc_score(model):\n    score=model_selection.cross_val_score(model,X_train,y_train,cv=cv,scoring ='accuracy', n_jobs = -1)\n    return(score.mean())","64d9b569":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\nimport xgboost as xgb\n\nscores = []\nmodels = {\n    'logistic_regression': LogisticRegressionCV,\n    'decision_tree': DecisionTreeClassifier,\n    'random_forest': RandomForestClassifier,\n    'gbm_classifier': GradientBoostingClassifier,\n    'ext_classifier':ExtraTreesClassifier,\n    'xgb_classifier':xgb.XGBClassifier\n}\n\n\n\n\n\nfor model_names,model in models.items():\n    model_pipeline = make_pipeline(StandardScaler(),model())\n    print(f\"{model_names}  :{acc_score(model_pipeline)}\")","d335f3a5":"base_model=GradientBoostingClassifier()","ca235eb8":"base_model.fit(X_train,y_train)","0fff32fb":"y_pred=base_model.predict(X_test)","d27d7766":"print(f\"This is testing score : {metrics.accuracy_score(y_test,y_pred)}\")\nprint(f\"This is training score : {metrics.accuracy_score(y_train,base_model.predict(X_train))}\")","800e3205":"parameters = {\n   # \"loss\":[\"deviance\"],\n    \"learning_rate\": [0.01, 0.025,  0.075 ],\n    \"min_samples_split\": np.linspace(0.1, 0.5,6),\n    \"min_samples_leaf\": np.linspace(0.1, 0.5, 6),\n    \"max_depth\":[3,5,8],\n    \"max_features\":[\"log2\",\"sqrt\"],\n    \"criterion\": [\"friedman_mse\",  \"mae\"],\n  #  \"subsample\":[0.5, 0.618, 0.8 0.85, 0.9, 0.95, 1.0],\n    \"n_estimators\":[10]\n    }\n\nclf = model_selection.GridSearchCV(GradientBoostingClassifier(), parameters, cv=5, n_jobs=-1,verbose=1)\n\nclf.fit(X_train, y_train)\n#print(clf.score(trainX, trainY))\nprint(clf.best_params_)","09bf7a26":"clf.best_score_","53b9793f":"y_pre=clf.predict(X_test)","7724eeba":"metrics.accuracy_score(y_test,y_pre)","7214b6ce":"print(f\"This is testing score : {metrics.accuracy_score(y_test,y_pre)}\")\nprint(f\"This is training score : {metrics.accuracy_score(y_train,clf.predict(X_train))}\")","1879d8e7":"Here null values is replaced by median .\nhere we created seperate median i.e for outcome 0 and 1","80b85241":"splitting the dataset for testing and tranning","d94af60b":"**Checking the outliers and removing it with the median**","218ad25b":"Replacing the value 0 with Nan","167439cd":"## lets tune the model","8f7d7ef0":"fuction is created to calculate median","14b34370":"checking for the null values"}}