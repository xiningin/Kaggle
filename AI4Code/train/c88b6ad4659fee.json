{"cell_type":{"bb9b7761":"code","d8cbab3c":"code","7bbab7b1":"code","d6202cee":"code","213698a3":"code","e60d126a":"code","0668597a":"code","db7fefe1":"code","c5a31fe7":"code","9a026af7":"code","3c756294":"code","0e5976e9":"code","113be908":"code","3eae5e0e":"code","481ca7ba":"code","32107c98":"code","cb04a295":"markdown","5a9e3753":"markdown","77265647":"markdown","3bff488c":"markdown","f0aba161":"markdown","9ffd1e6e":"markdown","a58a3ad9":"markdown","3f51dc1d":"markdown","6736ce55":"markdown","d20a3e5a":"markdown","8536d17e":"markdown","8eb46a12":"markdown","4af57da4":"markdown","537fcb6e":"markdown","8eac4b94":"markdown","4d9089b2":"markdown","9c29afe9":"markdown","e229a687":"markdown","7977f554":"markdown","e489eea1":"markdown","d7f6b291":"markdown","6029bc19":"markdown"},"source":{"bb9b7761":"# Import libraries needed for working with SQLite3\nimport sqlite3\nimport pandas as pd","d8cbab3c":"# Specify pathway to .sqlite database\nconx = sqlite3.connect('..\/input\/divvytripsdata\/divvytripsdata.sqlite')\ncony = sqlite3.connect('..\/input\/divvytripsdataedit\/divvytripsdata-edit.sqlite')","7bbab7b1":"# Test the environment, viewing a table\npd.read_sql('''\n    SELECT *\n    FROM divvy202005\n    LIMIT 5;\n''', con=conx)","d6202cee":"#Test table structure\npd.read_sql('''\n--Test table structure\nPRAGMA table_info(divvy202005);\n''', con=conx)","213698a3":"#Double check table structure\npd.read_sql('''\nPRAGMA table_info(MAINdivvy);\n''', con=cony)","e60d126a":"#Counting empty spaces of started_at\npd.read_sql('''\nSELECT COUNT(*) AS started_at_empty_spaces\nFROM MAINdivvy\nWHERE started_at = '';\n''', con=cony)","0668597a":"#Counting empty spaces of ended_at\npd.read_sql('''\nSELECT COUNT(*) AS ended_at_empty_spaces\nFROM MAINdivvy\nWHERE ended_at = '';\n''', con=cony)","db7fefe1":"#Find instances where duration is less than or equal to zero\n#Found 411 records with duration is 0 and 10,506 records where it is  < 0\npd.read_sql('''\nSELECT\n    started_at,\n    ended_at,\n    STRFTIME('%s', ended_at) - STRFTIME('%s', started_at) AS ride_length\nFROM MAINdivvy\nWHERE STRFTIME('%s', ended_at) - STRFTIME('%s', started_at) <= 0\nORDER BY ride_length;\n''', con=cony)","c5a31fe7":"#Count rows in agreggated table\npd.read_sql('''\nSELECT\n    COUNT (ride_id) AS 'total_ride_id',\n    COUNT (DISTINCT ride_id) AS 'distinct_ride_id'\nFROM MAINdivvy2;\n''', con=cony)","9a026af7":"#Check top 5 shortest rides\npd.read_sql('''\nSELECT\n    ride_id,\n    started_at,\n    ended_at,\n    member_casual,\n    ride_length,\n    ride_length_timedate,\n    day_of_week\nFROM MAINdivvy2 ORDER BY ride_length LIMIT 5;\n''', con=cony)","3c756294":"#Check top 5 longest rides\npd.read_sql('''\nSELECT\n    ride_id,\n    started_at,\n    ended_at,\n    member_casual,\n    ride_length,\n    ride_length_timedate,\n    day_of_week\nFROM MAINdivvy2 ORDER BY ride_length DESC LIMIT 5;\n''', con=cony)","0e5976e9":"#Selecting all rides lasting under 60 sec.\npd.read_sql('''\nSELECT * FROM MAINdivvy2 WHERE ride_length <= 60;\n''', con=cony)","113be908":"#Number of rides by membership type\npd.read_sql('''\nSELECT\n    member_casual,\n    COUNT(ride_id) AS number_of_rides\nFROM MAINdivvy2\nGROUP BY member_casual;\n''', con=cony)","3eae5e0e":"#Average ride length by membership type\npd.read_sql('''\nSELECT\n    member_casual,\n    ROUND(AVG(ride_length)\/60,1) AS avr_ride_length_min\nFROM MAINdivvy2\nGROUP BY member_casual;\n''', con=cony)\n\n","481ca7ba":"#Number of rides by weekday, by membership type\npd.read_sql('''\nSELECT\n    day_of_week,\n    member_casual,\n    COUNT(ride_id) AS number_of_rides\nFROM MAINdivvy2\nGROUP BY day_of_week, member_casual\nORDER BY member_casual, day_of_week;\n''', con=cony)","32107c98":"#Average ride duration by month, by member type\npd.read_sql('''\nSELECT\n    STRFTIME('%m', started_at) AS month,\n    ROUND(AVG(ride_length\/60),1) AS avg_ride_length_min,\n    member_casual\nFROM MAINdivvy2\nGROUP BY month, member_casual\nORDER BY member_casual, month;\n''', con=cony)","cb04a295":"And let's check the table structure.","5a9e3753":"Let's check for top 5 shortest and longest rides.","77265647":"Since counting empty spaces results in 0 instances there are no empty spaces in those columns.\n\nNow I want to check if there are instances where trip duration is less than or equals 0 sec. For that, I am subtracting **started_at** from **ended_at** columns and converting them to Unix epoch time in seconds.","3bff488c":"Since **ride_id** records are tokenized there should not be repeating instances. Here I am checking for duplicate **ride_id** by comparing the number of **total_ride_id** and the number of **distinct_ride_id**.","f0aba161":"Doublechecking the table structure.","9ffd1e6e":"### 5.2 Importing into Adobe Illustrator\nAfter exporting these tables to .csv files with tabulated separators I am importing them into **Adobe Illustrator** with:\n* Column Graph Tool\n* Line Graph Tool\n* Pie Chart Tool\n\n### 5.3 Slideshow presentation\nThis is how final visualizations look in the **Adobe Illustrator** interface.\n\n![illust.png](attachment:3850bb3a-fa6f-4108-b471-4fea51266cae.png)\n\n## 6. Act\nThe final [__Cyclystic data analysis presentation__](https:\/\/docs.google.com\/presentation\/d\/1dJFRqilNzjHMs279K3sWfbKWjDg61FYBVdgC7RNCG_w\/edit?usp=sharing) can be viewed in **Google Slides.**\n\n### 6.1 Key findings\n* Members seem to be using bicycles for work and other repeating activities, while casual riders use them more recreationally.\n* Casual riders would buy a membership if they decide to change the way they use bicycles.\n\n### 6.2 Digital media campaign recommendations\n\n* Promote using bicycles for work commutes and other repeating trips.\n* Encourage using bicycles for short convenience trips.\n* Launch campaigns in Spring, Summer, and on weekends when casual riders are most active.\n\n### 6.3 Further actions\n\n* Launch digital media campaign based on given recommendations.\n* Collect digital media campaign data for measuring the effects on conversion to membership.","a58a3ad9":"Number of rides by weekday, by membership type","3f51dc1d":"Now that the new table **MAINdivvy** is created I am simply copying all the data from 12 tables into it.","6736ce55":"Copying **MAINdivvy** table while calculating three additional columns:\n* **ride_length:** Difference between *ended_at* and *started_at* in seconds\n* **ride_length_timedate:** *ride_length* converted to *Unix epoch time*.\n* **day_of_week:** Day of a week of *started_at*\n\n```\nINSERT INTO MAINdivvy2 SELECT\n    ride_id,\n    rideable_type,\n    started_at,\n    ended_at,\n    start_station_name,\n    start_station_id,\n    end_station_name,\n    end_station_id,\n    start_lat,\n    start_lng,\n    end_lat,\n    end_lng,\n    member_casual,\n    STRFTIME('%s', ended_at) - STRFTIME('%s', started_at) AS ride_length,\n    DATETIME((STRFTIME('%s', ended_at) - STRFTIME('%s', started_at)), 'unixepoch') AS ride_length_timedate,\n    STRFTIME('%w', started_at) AS day_of_week\n    FROM MAINdivvy;\n```","d20a3e5a":"## 4. Analyze\n### 4.1 PivotTable in Microsoft Excel\n* Selected the whole table and Inserted it as PivotTable to the new sheet\n* Inserted PivotChart to assist with visualization\n* Experimented with the parameters in Pivot table, created:\n\n * Number of rides by user type. Columns: **member_casual**, Values: **Count of ride_id**\n * Average ride length by user type. Columns: **member_casual**, Values: **Average of ride_length**\n * Average ride length by day of the week and by user type. Columns: **member_casual**, Rows: **day_of_week**, Values: **Average of ride_length**\n * Number of rides by day of the week and by user type. Columns: **member_casual**, Rows: **day_of_week**, Values: **Count of ride_id**\n \nOn this chart for example we can see that casual riders are most active on Fridays and weekends, while members ride regularly during the weekends.\n\n![pivot1.png](attachment:35053c09-986f-490f-9600-516e2e3cceb9.png)\n\n### 4.2 Analysis in SQLite\nFirst I want to make sure there are no empty spaces in the **started_at** and **ended_at** columns since I am going to use them for main calculations.","8536d17e":"I now have a single table **MAINdivvy** with 3.7M records. Let's move on to the analysis.","8eb46a12":"*#Combine all tables into one*\n```\nINSERT INTO MAINdivvy SELECT * FROM divvy202005;\nINSERT INTO MAINdivvy SELECT * FROM divvy202006;\nINSERT INTO MAINdivvy SELECT * FROM divvy202007;\nINSERT INTO MAINdivvy SELECT * FROM divvy202008;\nINSERT INTO MAINdivvy SELECT * FROM divvy202009;\nINSERT INTO MAINdivvy SELECT * FROM divvy202010;\nINSERT INTO MAINdivvy SELECT * FROM divvy202011;\nINSERT INTO MAINdivvy SELECT * FROM divvy202012;\nINSERT INTO MAINdivvy SELECT * FROM divvy202101;\nINSERT INTO MAINdivvy SELECT * FROM divvy202102;\nINSERT INTO MAINdivvy SELECT * FROM divvy202103;\nINSERT INTO MAINdivvy SELECT * FROM divvy202104;\n```","4af57da4":"# Cyclistic data analysis - Excel \/ SQL \/ Tableau \/ Illustrator\n\n## Introduction\nThis is a capstone project for **Google Data Analytics** course in which I design **marketing strategies** aimed at **converting** casual riders into annual members using **real-world data** provided by a bike-sharing company in Chicago.\n\n* The final [__Cyclistic data analysis presentation__](https:\/\/docs.google.com\/presentation\/d\/1dJFRqilNzjHMs279K3sWfbKWjDg61FYBVdgC7RNCG_w\/edit?usp=sharing) is available at **Google Slides.** \n* Detailed documentation is available in Kaggle kernel.\n* **Microsoft Excel** has been used for the initial assessment of a portion of data. \n* Processing, cleaning, validation, and analysis were done in **SQLite Studio.**\n* Further analysis was done in **Tableau Public** and can be viewed at [__Cyclistic Data Analysis Tableau__](https:\/\/public.tableau.com\/app\/profile\/dmnorth\/viz\/CyclisticDataAnalysisTableau\/select) project.\n* Visualization and slideshow presentation was designed in **Adobe Illustrator**.\n\n## Table of contents\nCyclistic data analysis - Excel \/ SQL \/ Tableau \/ Illustrator\nIntroduction\nTable of contents\n1. Ask  \n    1.1 Problem\n    1.2 Key findings  \n2. Prepare  \n    2.1 Data source  \n    2.2 Data description  \n    2.3 Data limitations  \n    2.4 Data handling  \n3. Process  \n    3.1 Tools used  \n    3.2 Initial assessment in Microsoft Excel  \n        3.2.1 Investigating errors  \n        3.2.2 Calculations analysis  \n    3.3 Processing with SQLite  \n        3.3.1 Setting up and testing  \n        3.3.2 Create a new table  \n4. Analyze  \n    4.1 PivotTable in Microsoft Excel  \n    4.2 Analysis in SQLite  \n    4.3 Analysis in Tableau  \n        4.3.1 Building charts in Tableau  \n        4.3.2 Making sense of Tableau charts  \n5. Share  \n    5.1 Recreating tables in SQLite  \n    5.2 Importing into Adobe Illustrator  \n    5.3 Slideshow presentation  \n6. Act  \n    6.1 Key findings  \n    6.2 Digital media campaign recommendations  \n    6.3 Further actions  \n\n## 1. Ask\n### 1.1 Problem\nHow to maximize the number of annual members to ensure future growth and increase profitability.\n\n#### Analytical questions\n\n* How do annual members and casual riders use Cyclistic bikes differently?\n* Why would casual riders buy Cyclistic annual memberships?\n* How can Cyclistic use digital media to influence casual riders to become members? \n\n### 1.2 Key findings\n* Members seem to be using bicycles for work and other repeating activities, while casual riders use them more recreationally.\n* Casual riders would buy a membership if they decide to change the way they use bicycles.\n\n#### Digital media campaign recommendations\n\n* Promote using bicycles for work commutes and other repeating trips.\n* Encourage using bicycles for short convenience trips.\n* Launch campaigns in Spring, Summer, and on weekends when casual riders are most active.\n\n#### Further actions\n\n* Launch digital media campaign based on given recommendations.\n* Collect digital media campaign data for measuring the effects on conversion to membership.\n\nPlease see\n[__Cyclystic data analysis presentation__](https:\/\/docs.google.com\/presentation\/d\/1dJFRqilNzjHMs279K3sWfbKWjDg61FYBVdgC7RNCG_w\/edit?usp=sharing).\n\n\n## 2. Prepare\n### 2.1 Data source\nData is provided by [Motivate International Inc.](https:\/\/divvy-tripdata.s3.amazonaws.com\/index.html)\nIt is organized in zipped .csv files each representing one month of bicycle rides for the period of May 2020 - Apr 2021.\nThe data is obtained under the [following license](https:\/\/www.divvybikes.com\/data-license-agreement). \n\n### 2.2 Data description\nIdentifiable user data is tokenized. The data provides starting and ending times, locations, as well as the type of ridership. This will be useful to analyze the occurring patterns of each rider type.\n\n### 2.3 Data limitations\nSince riders\u2019 personally identifiable information is unavailable due to data-privacy issues it will be impossible to connect pass purchases to credit card numbers to determine if casual riders live in the Cyclistic service area or if they have purchased multiple single passes.\n\n### 2.4 Data handling\nThe database is stored on a hard drive on a password-protected operating system and backed up to a cloud. To run SQLite3 in Kaggle kernel I converted original .csv files into a single .sqlite dataset. Since I couldn't clean, modify the original .sqlite dataset in this notebook, some of the code is presented as text and is not executable. I also uploaded a few extra files to make as much code executable as possible.\n\n## 3. Process\n### 3.1 Tools used\nI started with **Microsoft Excel** since it is a very versatile tool. It quickly let me familiarize myself with the dataset, check formatting, minimum and maximum values, typos, and duplicates through the \"Sort and filter\" option. Furthermore, I created a pivot table with accompanying visualizations. Since Cyclistic combined dataset is more than 3.5M records and Excel is limited to around 1M records I proceeded to **SQLite Studio** to combine monthly tables.\n\n### 3.2 Initial assessment in Microsoft Excel\n\n* Downloaded all the original data into \u2026\/data_cyclists\/orgn\n* Converted .csv files to .xslx and saved into \u2026\/data_cyclists\/edit\n* Checked each column and assigned datatypes such as custom `yyyy-mm-dd hh:mm:ss` for **started_at**, **eneded_at** parameters, and **ride_length**\n* Created and examined new columns: **ride_length** `(=D2-C2)`, **day_of_week** `(=WEEKDAY(C2,1))`\n* Filtered first row, viewed through listed options of every column, screened through errors, duplicates, blanks, maximum and minimum values\n* Calculated Average `(=AVERAGE(N2:N200275))`, `Maximum(=MAX(N2:N200275))`, and `Median(=MEDIAN(N2:N200275))` values for **ride_length**, Average, Median and Mode `(=MODE.SNGL(O2:O200275))` for **day_of_week**.\n\n#### 3.2.1 Investigating errors\nWhile checking filtered values of **ride_length** detected some errors. After filtering them it turned out that some **ended_at** dated are less than or equal to **started_at** which should not be possible. Made a note to further investigate in SQLite.\n\n![err copy.png](attachment:9749d9c1-b3c8-461e-8676-6acd584c2705.png)\n\n#### 3.2.2 Calculations analysis\nMaximum **ride_length** was more than 20 days. The average **ride_length** of 33 min is longer than the median **ride_length** of 19 min, which means that there is a smaller number of very long rides that skews the average.\n\nMedian **day_of_week** is on Thursday (5), and mode on Saturday (7), which means, that more rides happen on Fridays and Saturdays than on other days.\n\n### 3.3 Processing with SQLite\nI chose to work with **SQLite Studio** because it's free, easy to install and run, and executes queries quickly.\n\n#### 3.3.1 Setting up and testing\nImporting essential libraries to run SQLite3 in Python.","537fcb6e":"Average ride length by membership type","8eac4b94":"As we can see the shortest rides are about 1 sec and the longest rides are around 2 months. This would be a good time to speak with the staff to help determine how to set a cutoff for the shortest and longest rides. In the comments to the original dataset, it is stated that rides lasting 60 sec or less are probably not real rides so let's first select, then remove them.","4d9089b2":"The result is 10K+ instances. Since they represent roughly 0.3% of the dataset I decided to delete them. Next, I am deleting rows where duration is less than or equal to zero.\n\n*#Deleting all rows where duration is less than or equal to zero*\n```\nDELETE *\nFROM MAINdivvy\nWHERE STRFTIME('%s', ended_at) - STRFTIME('%s', started_at) <= 0;\n```","9c29afe9":"*#Deleting all rides lasting under 60 sec.*\n```\nDELETE * FROM MAINdivvy2 WHERE ride_length <= 60;\n```\n\n### 4.3 Analysis in Tableau\n\nNow that the table is aggregated and cleaned I want to bring it to Tableau to quickly plot multiple graphs and charts and pick a few for to include in a slideshow presentation.\n\n#### 4.3.1 Building charts in Tableau\nTo convert **ride_length** from seconds to minutes rounded to a single digit I am creating *New calculated column* with `ROUND([Ride Length]\/60,1)` formula.\n\nThe charts I have built, which can be viewed in [__Cyclistic Data Analysis Tableau__](https:\/\/public.tableau.com\/app\/profile\/dmnorth\/viz\/CyclisticDataAnalysisTableau\/select) project include:\n\n* Number of rides by membership type\n* Average ride length by membership type\n* Total minutes ridden by membership type\n* Number of rides by day of the week, by membership type\n* Average duration of rides by day of the week, by membership type\n* Number of rides by month, by membership type\n* Average duration of rides by month, by membership type\n\nHere are the ones I am choosing for the visualization in **Adobe Illustrator**.\n\n![select-viz.png](attachment:fc3e1ec2-5589-4221-bc52-2fbb16cad335.png)\n\n#### 4.3.2 Making sense of Tableau charts\nI first noticed that while causal riders are responsible for a smaller number of rides, they ride significantly longer on average. Once I broke down those parameters by day of the week and by month, the trend started to emerge. While members ride fairly regularly both in terms of the number of rides and in terms of duration, casual riders ride much more often on weekends relative to weekdays and in the Summer season relative to the Winter season. I made my conclusion and recommendations based on these findings.\n\n## 5. Share\nI am choosing to present my findings with a slideshow presentation since it can be quick and easy to comprehend. I am choosing **Adobe Illustrator** to prepare the slideshow because it supports importing via *Graph\/Chart Tools* and gives me complete freedom and control of the final result.\n\n### 5.1 Recreating tables in SQLite\n\nSince **Tableau Public** does not allow me to export .csv files for selected visualizations I am going to recreate the underlying data in **SQLite Studio**.\n\nNumber of rides by membership type","e229a687":"Since the numbers are equal there are no **ride_id** duplicates.\n\nNow I want to add a few computed columns to the table for further analysis. Here I am creating a new empty table MAINdivvy2 with the same structure and 3 additional columns for computing.\n\n```\nCREATE TABLE MAINdivvy2 (\nride_id,\nrideable_type,\nstarted_at\tDATETIME,\nended_at\tDATETIME,\nstart_station_name,\nstart_station_id,\nend_station_name,\nend_station_id,\nstart_lat,\nstart_lng,\nend_lat,\nend_lng,\nmember_casual,\nride_length DATETIME,\nride_length_timedate DATETIME,\nday_of_week \n);\n```","7977f554":"Now for testing purposes let us view the first 5 rows of a table.","e489eea1":"I uploaded .sqlite dataset with original tables as well as a dataset with newly created tables for demonstration purposes. Here I am specifying the paths. ","d7f6b291":"Everything is looking good, so let's proceed.\n\n#### 3.3.2 Create a new table\nInstead of working with each of the 12 tables separately, I decided to combine them all in one for convenience. Here I am creating a new table with the same structure as the original tables. I am assigning `DATETIME` datatype for **started_at** and **ended_at** columns.\n\n*#Create empty table MAINdivvy with the original table structure*\n```\nCREATE TABLE MAINdivvy (\nride_id,\nrideable_type,\nstarted_at\tDATETIME,\nended_at\tDATETIME,\nstart_station_name,\nstart_station_id,\nend_station_name,\nend_station_id,\nstart_lat,\nstart_lng,\nend_lat,\nend_lng,\nmember_casual\n);\n```","6029bc19":"Average ride duration by month, by member type"}}