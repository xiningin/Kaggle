{"cell_type":{"1696ca26":"code","d9ea8baa":"code","961e47b1":"code","fefc1375":"code","6c6f7445":"code","d0096652":"code","4421c85d":"code","493352e7":"code","66b81a8e":"code","89ad7eb6":"code","f7a0df76":"code","2475cd37":"code","7933c856":"code","0409ccac":"code","a64bc507":"code","73a6e8c6":"code","4ea9e2cc":"code","2d551841":"code","a65b7444":"code","db95a263":"code","5b09ee80":"code","6ccc572b":"markdown","d490593c":"markdown","d03007fd":"markdown","6b6518ec":"markdown","51fd9684":"markdown","07a6a112":"markdown","c4f5c47d":"markdown","59b21439":"markdown","68cd0331":"markdown","6b9cae86":"markdown"},"source":{"1696ca26":"import numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d9ea8baa":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)\ntrain.head()\n# here, the images are 28 by 28,\n# 28 * 28 = 784","961e47b1":"test= pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)\ntest.head()","fefc1375":"# put labels into y_train variable\n\nY_train = train[\"label\"]\n\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) ","6c6f7445":"# visualize number of digits classes\nplt.figure(figsize=(15,7))\ng = sns.countplot(Y_train, palette=\"icefire\")\nplt.title(\"Number of digit classes\")\nY_train.value_counts()","d0096652":"# plot some samples\nimg = X_train.iloc[312].values\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(train.iloc[0,0])\nplt.axis(\"off\")\nplt.show()","4421c85d":"# Normalize the data\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","493352e7":"# Reshape\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(\"x_train shape: \",X_train.shape)\nprint(\"test shape: \",test.shape)","66b81a8e":"from keras.utils.np_utils import to_categorical \n\n# convert to one-hot-encoding\n\nY_train = to_categorical(Y_train, num_classes = 10)","89ad7eb6":"# Split the train and the validation set for the fitting\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)\nprint(\"x_train shape\",X_train.shape)\nprint(\"x_test shape\",X_val.shape)\nprint(\"y_train shape\",Y_train.shape)\nprint(\"y_test shape\",Y_val.shape)","f7a0df76":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\n\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","2475cd37":"# Defining the optimizer\n\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","7933c856":"# Compiling the model\n\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","0409ccac":"epochs = 15  # for better result increase the epochs\nbatch_size = 250","a64bc507":"X_train.shape","73a6e8c6":"# data augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.1, # Randomly zoom image 10%\n        width_shift_range=0.1,  # randomly shift images horizontally 10%\n        height_shift_range=0.1,  # randomly shift images vertically 10%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","4ea9e2cc":"test_my_model = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val), steps_per_epoch=X_train.shape[0] \/\/ batch_size)","2d551841":"# Plot the loss and accuracy curves for training and validation \nplt.plot(test_my_model.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","a65b7444":"# confusion matrix\nimport seaborn as sns\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Reds\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","db95a263":"# Read test data for submission of results\ntest1 = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\n# Reshape and scale figures\ntest1 = test1.values.reshape(28000, 28, 28, 1)\ntest1 = test1 \/ 255.0","5b09ee80":"# Save results to csv file for submission\n\ndf_pred = pd.DataFrame(Y_pred)\ndf_pred.index = range(1, 28001)\ndf_pred = df_pred.reset_index()\ndf_pred.head()\ndf_pred.columns = [\"ImageId\", \"Label\"]\ndf_pred.to_csv(\"submission.csv\", index=False)","6ccc572b":"<a id = \"8\"><\/a> \n## 6) Evaluation \/ Confusion Matrix","d490593c":"<a id = \"7\"><\/a> \n## 5) Creating the CNN model using Keras","d03007fd":"<a id = \"5\"><\/a> \n## 3) Normalizing & Reshaping","6b6518ec":"# Digit Recognizer \/ Convolutional Neural Network\n## This is my first attempt at a CNN project. \n\n\n1.  [Importing](#1)\n    1. [Importing the Libraries](#2)\n    1. [Importing the Data](#3)\n1.  [Labeling & Inspecting](#4)\n1.  [Normalizing & Reshaping](#5)\n1.  [Label Encoding & Train-Test Split](#6)\n1.  [Creating the CNN model using Keras](#7)\n1.  [Evaluation & Confusion Matrix](#8)","51fd9684":"## This was my first attempt at a CNN project. \n\n### Tutorial from [@DATAI](https:\/\/www.kaggle.com\/kanncaa1) has been very helpful.\n","07a6a112":"<a id = \"4\"><\/a> \n## 2) Labeling & Inspecting","c4f5c47d":"<a id = \"2\"><\/a> \n## Importing the Libraries","59b21439":"<a id = \"3\"><\/a> \n## Importing the Data","68cd0331":"<a id = \"1\"><\/a> \n# 1) Importing ","6b9cae86":"<a id = \"6\"><\/a> \n## 4) Label Encoding & Train-Test Split"}}