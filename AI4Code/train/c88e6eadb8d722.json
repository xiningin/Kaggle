{"cell_type":{"6bc9706f":"code","1f481698":"code","8bbf8f73":"code","735ba82e":"code","9507c9fc":"code","acc8d7ef":"code","a9001a35":"code","6abd3a84":"code","c5777169":"code","f17b7c5e":"code","f1cae691":"code","213fc7d4":"code","c98dda50":"code","22a7a7ec":"code","84629dc4":"code","f4e28c8f":"code","35ce6289":"code","4ca23c38":"markdown","4f41cc9e":"markdown","e1cba3c9":"markdown","3d1a2f33":"markdown","9ca3332d":"markdown","01db7278":"markdown","1163290b":"markdown","1eee7221":"markdown","2c65c58a":"markdown","a241d084":"markdown","d2096e59":"markdown","a4365938":"markdown","c5c99386":"markdown","32cf55c4":"markdown"},"source":{"6bc9706f":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom pydicom import dcmread\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils import data","1f481698":"label_data = pd.read_csv('..\/input\/rsna-pneumonia-detection-challenge\/stage_2_train_labels.csv')\ncolumns = ['patientId', 'Target']\n\nlabel_data = label_data.filter(columns)\nlabel_data.head(5)","8bbf8f73":"train_labels, val_labels = train_test_split(label_data.values, test_size=0.1)\nprint(train_labels.shape)\nprint(val_labels.shape)","735ba82e":"print(f'patientId: {train_labels[0][0]}, Target: {train_labels[0][1]}')","9507c9fc":"train_f = '..\/input\/rsna-pneumonia-detection-challenge\/stage_2_train_images'\ntest_f = '..\/input\/rsna-pneumonia-detection-challenge\/stage_2_test_images'\n\ntrain_paths = [os.path.join(train_f, image[0]) for image in train_labels]\nval_paths = [os.path.join(train_f, image[0]) for image in val_labels]\n\nprint(len(train_paths))\nprint(len(val_paths))","acc8d7ef":"def imshow(num_to_show=9):\n    \n    plt.figure(figsize=(10,10))\n    \n    for i in range(num_to_show):\n        plt.subplot(3, 3, i+1)\n        plt.grid(False)\n        plt.xticks([])\n        plt.yticks([])\n        \n        img_dcm = dcmread(f'{train_paths[i+20]}.dcm')\n        img_np = img_dcm.pixel_array\n        plt.imshow(img_np, cmap=plt.cm.binary)\n        plt.xlabel(train_labels[i+20][1])\n\nimshow()","a9001a35":"transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.Resize(224),\n    transforms.ToTensor()])","6abd3a84":"class Dataset(data.Dataset):\n    \n    def __init__(self, paths, labels, transform=None):\n        self.paths = paths\n        self.labels = labels\n        self.transform = transform\n    \n    def __getitem__(self, index):\n        image = dcmread(f'{self.paths[index]}.dcm')\n        image = image.pixel_array\n        image = image \/ 255.0\n\n        image = (255*image).clip(0, 255).astype(np.uint8)\n        image = Image.fromarray(image).convert('RGB')\n\n        label = self.labels[index][1]\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        return image, label\n    \n    def __len__(self):\n        \n        return len(self.paths)","c5777169":"train_dataset = Dataset(train_paths, train_labels, transform=transform)\nimage = iter(train_dataset)\nimg, label = next(image)\nprint(f'Tensor:{img}, Label:{label}')\nimg = np.transpose(img, (1, 2, 0))\nplt.imshow(img)","f17b7c5e":"img.shape","f1cae691":"train_dataset = Dataset(train_paths, train_labels, transform=transform)\nval_dataset = Dataset(val_paths, val_labels, transform=transform)\ntrain_loader = data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\nval_loader = data.DataLoader(dataset=val_dataset, batch_size=128, shuffle=False)","213fc7d4":"batch = iter(train_loader)\nimages, labels = next(batch)\n\nimage_grid = torchvision.utils.make_grid(images[:4])\nimage_np = image_grid.numpy()\nimg = np.transpose(image_np, (1, 2, 0))\nplt.imshow(img)","c98dda50":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","22a7a7ec":"model = torchvision.models.resnet18(pretrained=True)\nnum_ftrs = model.fc.in_features\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\nmodel.fc = nn.Linear(num_ftrs, 2)\n\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","84629dc4":"print(model)","f4e28c8f":"num_epochs = 20\n# Train the model\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    # Training step\n    for i, (images, labels) in tqdm(enumerate(train_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (i+1) % 2000 == 0:\n            \n            print(\"Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}\"\n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n\n\n    # Validation step\n    correct = 0\n    total = 0  \n    for images, labels in tqdm(val_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        predictions = model(images)\n        _, predicted = torch.max(predictions, 1)\n        total += labels.size(0)\n        correct += (labels == predicted).sum()\n    print(f'Epoch: {epoch+1}\/{num_epochs}, Val_Acc: {100*correct\/total}')","35ce6289":"model.eval()\n\ncorrect = 0\ntotal = 0  \nfor images, labels in tqdm(val_loader):\n    images = images.to(device)\n    labels = labels.to(device)\n    predictions = model(images)\n    _, predicted = torch.max(predictions, 1)\n    total += labels.size(0)\n    correct += (labels == predicted).sum()\nprint(f'Val_Acc: {100*correct\/total}')","4ca23c38":"## Preparing train and validation image paths","4f41cc9e":"## Prepare training and validation dataloader","e1cba3c9":"## Composing transformations","3d1a2f33":"## Test model","9ca3332d":"## Load pre-trained ResNet18 and fine-tune","01db7278":"## Dividing labels for train and validation set","1163290b":"## Check dataloader","1eee7221":"## Check the custom dataset","2c65c58a":"## Write a train code and RUN","a241d084":"## Show some samples from data","d2096e59":"## Specify device object","a4365938":"## Write a custom dataset ","c5c99386":"## Train image shape","32cf55c4":"## Preparing labels"}}