{"cell_type":{"eb194a1d":"code","59b9a8e8":"code","e079f9b2":"code","452966ec":"code","f619cf3b":"code","a031946c":"code","0cbfa82f":"code","9212d27f":"code","6ebdc70d":"code","3e507caa":"code","ff9ba3a0":"code","7adc9d3b":"code","08befa09":"code","f3d70f04":"code","a2c13309":"code","a250da70":"code","04abd1d5":"code","9e065f22":"code","a46e5b5c":"code","2c54631c":"code","0f1d0773":"code","a3c55eb6":"code","c5071419":"code","2de2a22d":"code","2052891b":"code","d69c8560":"code","2854a8af":"code","02392851":"code","e8a58616":"markdown","2135a347":"markdown","0200aa2c":"markdown","180c68e9":"markdown","01c8ce26":"markdown","906f9255":"markdown","f086064a":"markdown","3431d2ba":"markdown","77def161":"markdown","94285f0e":"markdown","6d62c143":"markdown","8ed17513":"markdown","6093cffc":"markdown","1876325f":"markdown","8295b30e":"markdown","8f1a084b":"markdown","cbd62bde":"markdown","c405da3c":"markdown","c2798f42":"markdown","a3b7f1fc":"markdown","469d268a":"markdown"},"source":{"eb194a1d":"# Data handling\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Clustering\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn import preprocessing\nfrom sklearn.metrics import silhouette_score\n\n# Dimensionality reduction\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\n\n# Visualization\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport mpl_toolkits.mplot3d.axes3d as p3\nfrom matplotlib import animation\n\n%matplotlib inline \n\ndef load_preprocess_data():\n    \"\"\" Load and preprocess data\n    \"\"\"\n    \n    # Load data\n    df = pd.read_csv(\"..\/input\/telcom-churns-dataset\/TelcoChurn.csv\")\n    \n    # remove empty values\n    df = df.loc[df.TotalCharges!=\" \", :]\n    df.TotalCharges = df.TotalCharges.astype(float)\n    \n    # Label data correctly\n    replace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n                    'TechSupport','StreamingTV', 'StreamingMovies', 'Partner', 'Dependents',\n                   'PhoneService', 'MultipleLines', 'PaperlessBilling', 'Churn']\n    for i in replace_cols : \n        df.loc[:, i]  = df.loc[:, i].replace({'No internet service' : 'No', 'No phone service':'No'})\n        df.loc[:, i]  = df.loc[:, i].map({'No':0, 'Yes':1})\n    df.gender = df.gender.map({\"Female\":0, \"Male\":1})\n    \n    # One-hot encoding of variables\n    others_categorical = ['Contract', 'PaymentMethod', 'InternetService']\n    for i in others_categorical:\n        df = df.join(pd.get_dummies(df[i], prefix=i))\n    df.drop(others_categorical, axis=1, inplace=True)\n    \n    # Calculate number of services\n    services = ['PhoneService', 'MultipleLines', 'OnlineSecurity',\n            'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n            'StreamingMovies', 'InternetService_DSL', 'InternetService_Fiber optic',\n            'InternetService_No']\n    df['nr_services'] = df.apply(lambda row: sum([row[x] for x in services[:-1]]), 1)\n    \n    return df.drop('customerID', 1)\n\ndef plot_corr(df):\n    corr = df.corr()\n    mask = np.zeros_like(corr, dtype=np.bool)\n    mask[np.triu_indices_from(mask)] = True\n    f, ax = plt.subplots(figsize=(11, 9))\n    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n    \ndef plot_tsne(tnse_data, kmeans_labels):\n    df_tsne = pd.DataFrame(tsne_data).rename({0: 'x', 1: 'y'}, axis=1)\n    df_tsne['z'] = kmeans_labels\n    sns.scatterplot(x=df_tsne.x, y=df_tsne.y, hue=df_tsne.z, palette=\"Set2\")\n    plt.show()\n    \ndef prepare_pca(n_components, data, kmeans_labels):\n    names = ['x', 'y', 'z']\n    matrix = PCA(n_components=n_components).fit_transform(data)\n    df_matrix = pd.DataFrame(matrix)\n    df_matrix.rename({i:names[i] for i in range(n_components)}, axis=1, inplace=True)\n    df_matrix['labels'] = kmeans_labels\n    \n    return df_matrix\n\ndef prepare_tsne(n_components, data, kmeans_labels):\n    names = ['x', 'y', 'z']\n    matrix = TSNE(n_components=n_components).fit_transform(data)\n    df_matrix = pd.DataFrame(matrix)\n    df_matrix.rename({i:names[i] for i in range(n_components)}, axis=1, inplace=True)\n    df_matrix['labels'] = kmeans_labels\n    \n    return df_matrix\n\ndef plot_3d(df, name='labels'):\n    iris = px.data.iris()\n    fig = px.scatter_3d(df, x='x', y='y', z='z',\n                  color=name, opacity=0.5)\n    \n\n    fig.update_traces(marker=dict(size=3))\n    fig.show()\n    \ndef plot_animation(df, label_column, name):\n    def update(num):\n        ax.view_init(200, num)\n\n    N=360\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(tsne_3d_df['x'], tsne_3d_df['y'], tsne_3d_df['z'], c=tsne_3d_df[label_column],\n               s=6, depthshade=True, cmap='Paired')\n    ax.set_zlim(-15, 25)\n    ax.set_xlim(-20, 20)\n    plt.tight_layout()\n    ani = animation.FuncAnimation(fig, update, N, blit=False, interval=50)\n    ani.save('{}.gif'.format(name), writer='imagemagick')\n    plt.show()","59b9a8e8":"df = load_preprocess_data()","e079f9b2":"sns.scatterplot(df.TotalCharges, df.tenure, df.nr_services)","452966ec":"plot_corr(df)","f619cf3b":"df = df.drop([\"Churn\"], 1)","a031946c":"scores = [KMeans(n_clusters=i+2).fit(df).inertia_ for i in range(10)]\nsns.lineplot(np.arange(2, 12), scores)\nplt.xlabel('Number of clusters')\nplt.ylabel(\"Inertia\")\nplt.title(\"Inertia of k-Means versus number of clusters\")","0cbfa82f":"kmeans = KMeans(n_clusters=4)\nkmeans.fit(df)","9212d27f":"normalized_vectors = preprocessing.normalize(df)\nscores = [KMeans(n_clusters=i+2).fit(normalized_vectors).inertia_ for i in range(10)]\nsns.lineplot(np.arange(2, 12), scores)\nplt.xlabel('Number of clusters')\nplt.ylabel(\"Inertia\")\nplt.title(\"Inertia of Cosine k-Means versus number of clusters\")","6ebdc70d":"normalized_kmeans = KMeans(n_clusters=4)\nnormalized_kmeans.fit(normalized_vectors)","3e507caa":"min_samples = df.shape[1]+1 #  Rule of thumb; number of dimensions D in the data set, as minPts \u2265 D + 1\ndbscan = DBSCAN(eps=3.5, min_samples=min_samples).fit(df)","ff9ba3a0":"pca_df = prepare_pca(3, df, normalized_kmeans.labels_)\nsns.scatterplot(x=pca_df.x, y=pca_df.y, hue=pca_df.labels, palette=\"Set2\")","7adc9d3b":"pca_df = prepare_pca(3, df, normalized_kmeans.labels_)\nplot_3d(pca_df)","08befa09":"tsne_3d_df = prepare_tsne(3, df, kmeans.labels_)","f3d70f04":"plot_3d(tsne_3d_df)","a2c13309":"tsne_3d_df['normalized_kmeans'] = normalized_kmeans.labels_\nplot_3d(tsne_3d_df, name='normalized_kmeans')","a250da70":"tsne_3d_df['dbscan'] = dbscan.labels_\nplot_3d(tsne_3d_df, name='normalized_kmeans')","04abd1d5":"plot_animation(tsne_3d_df, 'normalized_kmeans', 'normalized_kmeans')\n","9e065f22":"plot_animation(tsne_3d_df, 'dbscan', 'dbscan')","a46e5b5c":"tsne_3d_df.dbscan = tsne_3d_df.dbscan.astype(int)\nplot_animation(tsne_3d_df, 'normalized_kmeans', 'normalized_kmeans_new')","2c54631c":"kmeans = KMeans(n_clusters=4).fit(df)\n\nnormalized_vectors = preprocessing.normalize(df)\nnormalized_kmeans = KMeans(n_clusters=4).fit(normalized_vectors)\n\nmin_samples = df.shape[1]+1 #  Rule of thumb; number of dimensions D in the data set, as minPts \u2265 D + 1\ndbscan = DBSCAN(eps=3.5, min_samples=min_samples).fit(df)","0f1d0773":"print('kmeans: {}'.format(silhouette_score(df, kmeans.labels_, metric='euclidean')))\nprint('Cosine kmeans: {}'.format(silhouette_score(normalized_vectors, normalized_kmeans.labels_, metric='cosine')))\nprint('DBSCAN: {}'.format(silhouette_score(df, dbscan.labels_, metric='cosine')))","a3c55eb6":"# Setting all variables between 0 and 1 in order to better visualize the results\nscaler = MinMaxScaler()\ndf_scaled = pd.DataFrame(scaler.fit_transform(df))\ndf_scaled.columns = df.columns\ndf_scaled['dbscan'] = dbscan.labels_","c5071419":"# df = load_preprocess_data()\ndf['dbscan'] = dbscan.labels_\ntidy = df_scaled.melt(id_vars='dbscan')\nfig, ax = plt.subplots(figsize=(15, 5))\nsns.barplot(x='dbscan', y='value', hue='variable', data=tidy, palette='Set3')\nplt.legend([''])\n# plt.savefig(\"mess.jpg\", dpi=300)\nplt.savefig(\"dbscan_mess.jpg\", dpi=300)","2de2a22d":"df_mean = df_scaled.loc[df_scaled.dbscan!=-1, :].groupby('dbscan').mean().reset_index()","2052891b":"df_mean","d69c8560":"# Setting all variables between 0 and 1 in order to better visualize the results\n# df = load_preprocess_data().drop(\"Churn\", 1)\nscaler = MinMaxScaler()\ndf_scaled = pd.DataFrame(scaler.fit_transform(df))\ndf_scaled.columns = df.columns\ndf_scaled['dbscan'] = dbscan.labels_\n\n# Calculate variables with largest differences (by standard deviation)\n# The higher the standard deviation in a variable based on average values for each cluster\n# The more likely that the variable is important when creating the cluster\ndf_mean = df_scaled.loc[df_scaled.dbscan!=-1, :].groupby('dbscan').mean().reset_index()\nresults = pd.DataFrame(columns=['Variable', 'Std'])\nfor column in df_mean.columns[1:]:\n    results.loc[len(results), :] = [column, np.std(df_mean[column])]\nselected_columns = list(results.sort_values('Std', ascending=False).head(7).Variable.values) + ['dbscan']\n\n# Plot data\ntidy = df_scaled[selected_columns].melt(id_vars='dbscan')\nfig, ax = plt.subplots(figsize=(15, 5))\nsns.barplot(x='dbscan', y='value', hue='variable', data=tidy, palette='Set3')\nplt.legend(loc='upper right')\nplt.savefig(\"dbscan_results.jpg\", dpi=300)","2854a8af":"from sklearn.ensemble import RandomForestClassifier\ny = df.iloc[:,-1]\nX = df.iloc[:,:-1]\nclf = RandomForestClassifier(n_estimators=100).fit(X, y)\nselected_columns = list(pd.DataFrame(np.array([clf.feature_importances_, X.columns]).T, columns=['Importance', 'Feature'])\n           .sort_values(\"Importance\", ascending=False)\n           .head(7)\n           .Feature\n           .values)","02392851":"# Plot data\ntidy = df_scaled[selected_columns+['dbscan']].melt(id_vars='dbscan')\nfig, ax = plt.subplots(figsize=(15, 5))\nsns.barplot(x='dbscan', y='value', hue='variable', data=tidy, palette='Set3')\nplt.legend(loc='upper right')\nplt.savefig('randomforest.jpg', dpi=300)","e8a58616":"No = 0\nYes = 1\n\nFemale = 0\nMale = 1","2135a347":"## <a name=\"table\">Table of Contents<\/a> \n\n1. [Functions](#functions)  \n2. [Preprocess Data](#preprocess)  \n\n    2.1 [Load Data](#load)\n    \n    2.2 [NaN Values](#nan)\n    \n    2.3 [Preprocessing Steps](#preprocessing)\n    \n    \n3. [EDA](#eda)  \n4. [Clustering](#clustering)  \n\n    4.1 [k-Means](#kmeans)\n    \n    4.2 [Normalized k-Means](#normalizedkmeans)\n    \n    4.3 [DBSCAN](#dbscan)\n    \n    \n5. [Visualization](#visualization)  \n\n    5.1 [PCA](#pca)\n    \n    5.2 [t-SNE](#tsne)\n    \n    5.3 [3D Animation](#animation)\n    \n    \n6. [Evaluation](#evaluation)  \n\n\n7. [What makes a cluster unique?](#unique)  \n\n    7.1 [Variance](#variance)\n    \n    7.2 [Feature Importance](#feature)\n    ","0200aa2c":"### <a name=\"tsne\">5.2. t-SNE<\/a> \n[Back to Table of Contents](#table)","180c68e9":"## <a name=\"preprocess\">2. Preprocess Data<\/a> \n[Back to Table of Contents](#table)\n\nDemographic\n* Gender\n* SeniorCitizen\n* Partner\n* Dependents\n* Tenure\n\nServices\n* PhoneService\n* MultipleLines\n* InternetService\n* OnlineSecurity\n* OnlineBackup\n* DeviceProtection\n* TechSupport\n* StreamingTV\n* StreamingMovies\n\nCustomer account information\n* Contract\n* PaperlessBilling\n* PaymentMethod\n* MonthlyCharges\n* TotalCharges\n\nTarget\n* Churn","01c8ce26":"### <a name=\"dbscan\">4.3. DBSCAN<\/a> \n[Back to Table of Contents](#table)","906f9255":"### <a name=\"animation\">5.3. 3D Animation<\/a> \n[Back to Table of Contents](#table)","f086064a":"### <a name=\"kmeans\">4.1. k-Means<\/a> \n[Back to Table of Contents](#table)","3431d2ba":"## <a name=\"clustering\">4. Clustering<\/a> \n[Back to Table of Contents](#table)","77def161":"## <a name=\"visualization\">5. Visualization<\/a> \n[Back to Table of Contents](#table)","94285f0e":"## <a name=\"eda\">3. EDA<\/a> \n[Back to Table of Contents](#table)","6d62c143":"The problem with this approach is that we simply have too many variables. Not all of them are likely to be important when creating the clusters. Instead, I will select the most important columns based on the following approach: ","8ed17513":"### <a name=\"variance\">7.1. Variance<\/a> \n[Back to Table of Contents](#table)","6093cffc":"## <a name=\"functions\">1. Functions<\/a> \n[Back to Table of Contents](#table)","1876325f":"## <a name=\"unique\">7. What makes a cluster unique?<\/a> \n[Back to Table of Contents](#table)","8295b30e":"### <a name=\"normalizedkmeans\">4.2. Normalized k-Means<\/a> \n[Back to Table of Contents](#table)","8f1a084b":"What I essentially do is group datapoints by cluster and take the average. Then, I calculate the standard deviation between\nthose values for each variable. Variables with a high standard deviation indicate that there are large differences between clusters and that the variable might be important. ","cbd62bde":"# Customer Segmentation\n![Customer segmentation](https:\/\/miro.medium.com\/max\/1400\/0*qxHSR7XeQAYrCn6n.gif)","c405da3c":"One way to see the differences between clusters is to take the average value of each cluster and visualize it. ","c2798f42":"### <a name=\"pca\">5.1. PCA<\/a> \n[Back to Table of Contents](#table)","a3b7f1fc":"### <a name=\"feature\">7.2. Feature Importance<\/a> \n[Back to Table of Contents](#table)","469d268a":"## <a name=\"evaluation\">6. Evaluation<\/a> \n[Back to Table of Contents](#table)"}}