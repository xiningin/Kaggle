{"cell_type":{"2502c26d":"code","596ba0cb":"code","37f3332b":"code","2f05dbf3":"code","588d824d":"code","b6e0cf09":"code","659e49d7":"code","a840bd9e":"code","e9cb3f88":"code","a44fb351":"code","d3b190bd":"code","fb072b9b":"code","62a5bbaa":"code","805d4206":"code","4247ae55":"code","f37a1718":"code","59107fc1":"code","6ddadba0":"code","a30f9730":"code","ec2dbc50":"code","73ecf44c":"code","1d822773":"code","03ff2c8d":"code","2661cc4c":"code","d130e12d":"code","e4e706cb":"code","96643be3":"code","74bbbd7a":"code","dd50b590":"code","e1690bc2":"code","b47ca2d5":"code","43ccffdd":"code","00504761":"code","e560fa59":"code","c4a1284a":"code","494536fe":"code","090ad7f3":"code","8ee68135":"code","0ebe5538":"code","58415dfc":"code","2bddd27c":"code","da36a51a":"code","211cdf04":"code","b4c64324":"code","b4366d91":"markdown","3d3854a4":"markdown","3453d233":"markdown","aa70cc34":"markdown","4e9fc1f9":"markdown","e637c171":"markdown","d497b709":"markdown","62acb9a7":"markdown","7d747460":"markdown","1c7b02ca":"markdown","4029e36d":"markdown","5f2a5e2d":"markdown","e37b0c30":"markdown","9eaa5704":"markdown","a413b9ed":"markdown"},"source":{"2502c26d":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport os","596ba0cb":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","37f3332b":"pd.set_option('display.max_columns', None)\ngeneral_data=pd.read_csv('\/kaggle\/input\/hr-analytics-case-study\/general_data.csv')\nemployee_survey_data=pd.read_csv('\/kaggle\/input\/hr-analytics-case-study\/employee_survey_data.csv')\nmanager_survey_data=pd.read_csv('\/kaggle\/input\/hr-analytics-case-study\/manager_survey_data.csv')","2f05dbf3":"print('\\n','-'*20,'General info','-'*20,'\\n')\ngeneral_data.info()\nprint('\\n','-'*20,'Employee Survey info','-'*20,'\\n')\nemployee_survey_data.info()\nprint('\\n','-'*20,'Manager Survey info','-'*20,'\\n')\nmanager_survey_data.info()","588d824d":"print(general_data.EmployeeID.nunique())\nprint(employee_survey_data.EmployeeID.nunique())\nprint(manager_survey_data.EmployeeID.nunique())","b6e0cf09":"general_data.set_index('EmployeeID')\nemployee_survey_data.set_index('EmployeeID')\nmanager_survey_data.set_index('EmployeeID')\ndata=pd.concat([general_data,employee_survey_data,manager_survey_data],axis=1)","659e49d7":"data.head()","a840bd9e":"print(f'There is {data.isna().any(axis=1).mean()*100:.2f}% Nans')","e9cb3f88":"data.describe(include='all')","a44fb351":"# last year arrtrition\ndata.Attrition.value_counts(normalize=True).to_frame()","d3b190bd":"cmap = plt.get_cmap(\"tab20c\")\nouter_colors = cmap(np.arange(2)*13)\n\nplt.subplots(figsize=(20,10))\nax=plt.subplot(1,2,1)\nsns.distplot(data.Age,bins=23)\nax.spines['left'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\nplt.subplot(1,2,2)\nplt.pie(data.Gender.value_counts(normalize=True),radius=1,autopct='%1.1f%%',wedgeprops=dict(width=0.5, edgecolor='w'),colors=outer_colors,labels=['Male','Female'])\nplt.show()","fb072b9b":"plt.figure(figsize=(10,6))\nsns.violinplot(data=data,x='Gender',y='Age',hue='Attrition')\nplt.show()","62a5bbaa":"from sklearn.preprocessing import LabelEncoder\nlabelEncoder_X = LabelEncoder()\ndata_labeled=data.copy()\ndata_labeled['Attrition'] = labelEncoder_X.fit_transform(data_labeled['Attrition'])\ndata_labeled['BusinessTravel'] = labelEncoder_X.fit_transform(data_labeled['BusinessTravel'])\ndata_labeled['Department'] = labelEncoder_X.fit_transform(data_labeled['Department'])\ndata_labeled['EducationField'] = labelEncoder_X.fit_transform(data_labeled['EducationField'])\ndata_labeled['Gender'] = labelEncoder_X.fit_transform(data_labeled['Gender'])\ndata_labeled['JobRole'] = labelEncoder_X.fit_transform(data_labeled['JobRole'])\ndata_labeled['MaritalStatus'] = labelEncoder_X.fit_transform(data_labeled['MaritalStatus'])\ndata_labeled.drop(['Over18','StandardHours','EmployeeCount'],axis=1,inplace=True)","805d4206":"# check relationship between attrition and other features.\ndata_labeled.corr()['Attrition'].sort_values().to_frame()","4247ae55":"data_labeled.dropna(inplace=True)\nax=plt.figure(figsize=(10,5))\nsns.distplot(data_labeled[data_labeled['Attrition']==1].TotalWorkingYears,label='yes')\nsns.distplot(data_labeled.TotalWorkingYears,label='all')\nplt.xticks(range(0,40,2))\nplt.legend()\nplt.show()","f37a1718":"plt.subplots(figsize=(10,5))\nsns.distplot(data[data['Attrition']=='Yes'].Age,label='yes')\nsns.distplot(data.Age,label='all')\nplt.legend()\nplt.show()","59107fc1":"plt.subplots(figsize=(10,5))\nsns.distplot(data[data['Attrition']=='Yes'].YearsWithCurrManager,label='yes')\nsns.distplot(data.YearsWithCurrManager,label='all')\nplt.legend()\nplt.show()","6ddadba0":"plt.subplots(figsize=(10,5))\nsns.distplot(data[data['Attrition']=='Yes'].YearsAtCompany,label='yes')\nsns.distplot(data.YearsAtCompany,label='all')\nplt.legend()\nplt.show()","a30f9730":"plt.subplots(figsize=(10,10))\nplt.subplot(2,1,1)\nsns.boxplot(data=data,x='Attrition',y='JobSatisfaction')\nplt.subplot(2,1,2)\nsns.boxplot(data=data,x='Attrition',y='EnvironmentSatisfaction')\nplt.show()","ec2dbc50":"pd.crosstab(data['Attrition'],data['MaritalStatus'],margins=True,normalize=True)","73ecf44c":"data_left=data[data.Attrition=='Yes']","1d822773":"plt.figure(figsize=(12,6))\nax=plt.subplot(131)\nsns.distplot(data_left.Age,ax=ax)\nax=plt.subplot(132)\nsns.distplot(data_left.YearsAtCompany,ax=ax)\nax=plt.subplot(133)\nsns.distplot(data_left.TotalWorkingYears,ax=ax)\nplt.grid()\nplt.show()","03ff2c8d":"data[data.Attrition=='Yes'].Gender.value_counts(normalize=True)","2661cc4c":"data_labeled[data_labeled.Age>40].corr()['Attrition']","d130e12d":"plt.figure(figsize=(12,6))\nax=plt.subplot(121)\nsns.boxplot(data=data_labeled[data_labeled.JobSatisfaction>3],x='Attrition',y='TotalWorkingYears',ax=ax)\nax=plt.subplot(122)\nsns.boxplot(data=data_labeled[data_labeled.JobSatisfaction>3],x='Attrition',y='Age',ax=ax)\nplt.show()","e4e706cb":"data_labeled.drop(columns=['EmployeeID'],inplace=True)","96643be3":"corr_cols = ['Age','Attrition','BusinessTravel','DistanceFromHome','Education', 'EducationField','Gender', 'JobLevel', 'JobRole',\n       'MaritalStatus', 'MonthlyIncome', 'NumCompaniesWorked',\n       'PercentSalaryHike', 'StockOptionLevel', 'TotalWorkingYears',\n       'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion',\n       'YearsWithCurrManager']\ncorr = data_labeled[corr_cols].corr()\nplt.figure(figsize=(16,14))\nsns.heatmap(corr, annot =True)\nplt.show()","74bbbd7a":"y = data_labeled['Attrition']\nx = data_labeled.drop('Attrition', axis = 1)","dd50b590":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train, y_test = train_test_split(x,y, test_size = 0.20, random_state=1)","e1690bc2":"from sklearn.preprocessing import StandardScaler\nScaler_X = StandardScaler()\nX_train = Scaler_X.fit_transform(X_train)\nX_test = Scaler_X.transform(X_test)","b47ca2d5":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score","43ccffdd":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\ny_pred = lr.predict(X_test)\n#confusion matrix\nprint(accuracy_score(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))","00504761":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","e560fa59":"cols_todrop = ['JobLevel','Department','JobRole','NumCompaniesWorked','PercentSalaryHike','StockOptionLevel',\n               'YearsWithCurrManager']\nx = data_labeled.drop(['Attrition'], axis=1).reset_index(drop=True)\ny = data_labeled['Attrition'].values\nx.drop(cols_todrop, axis=1, inplace=True)\nx.Age = pd.cut(x.Age, 4)","c4a1284a":"x = pd.get_dummies(x)\nx_copy=x.copy()","494536fe":"scaler = StandardScaler()\nx = scaler.fit_transform(x)","090ad7f3":"x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, random_state=42)","8ee68135":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, train_test_split, RandomizedSearchCV\nfrom sklearn import preprocessing\nfrom sklearn.metrics import r2_score, accuracy_score, roc_auc_score, mean_squared_error","0ebe5538":"def get_scores(score1, score2):\n    models = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('LDA', LinearDiscriminantAnalysis()))\n    models.append(('KNN', KNeighborsClassifier()))\n    models.append(('CART', DecisionTreeClassifier()))\n    models.append(('NB', GaussianNB()))\n    models.append(('SVM', SVC()))\n    models.append(('ADA', AdaBoostClassifier()))\n    models.append(('GradientBooster', GradientBoostingClassifier()))\n    models.append(('ExtraTrees', ExtraTreesClassifier()))\n    models.append(('RandomForest', RandomForestClassifier()))\n    cv_scores = []\n    test_scores = []\n    names = []\n    stds = []\n    differences = []\n    #res = pd.DataFrame(columns = {'Model',score+('(train)'), 'Std', score+('(test_score)'), 'difference'})\n    #res = res[['Model',score+('(train)'), 'Std', score+('(test_score)'), 'difference']]\n    res = pd.DataFrame()\n    for index, model in enumerate(models):\n        kfold = StratifiedKFold(n_splits=7)\n        cv_results = cross_val_score(model[1], x_train, y_train, cv=kfold, scoring=score1)\n        cv_scores.append(cv_results)\n        names.append(model[0])\n        model[1].fit(x_train,y_train)\n        predictions = model[1].predict(x_test)\n        test_score = score2(predictions, y_test)\n        test_scores.append(test_score)\n        stds.append(cv_results.std())\n        differences.append((cv_results.mean() - test_score))\n        res.loc[index,'Model'] = model[0]\n        res.loc[index,score1+('(train)')] = cv_results.mean()\n        res.loc[index,score1+('(test_score)')] = test_score\n        res.loc[index,'Std'] = cv_results.std()\n        res.loc[index,'difference'] = cv_results.mean() - test_score\n    return res","58415dfc":"get_scores('accuracy', accuracy_score)","2bddd27c":"params = {'bootstrap': [True, False],\n 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 400, 600, 800, 1000]}\nRandomForest = RandomForestClassifier()\nrandomgrid_forest = RandomizedSearchCV(estimator=RandomForest, param_distributions = params, \n                               cv=5, n_iter=25, scoring = 'accuracy',\n                               n_jobs = 4, verbose = 3, random_state = 42,\n                               return_train_score = True)\nrandomgrid_forest.fit(x_train,y_train)","da36a51a":"forest_preds = randomgrid_forest.predict(x_test)\nprint(classification_report(y_test,forest_preds))","211cdf04":"feature_importances_=randomgrid_forest.best_estimator_.feature_importances_.tolist()\nfeature_names = x_copy.columns\npd.DataFrame(pd.Series(feature_importances_,feature_names),columns=['importance']).sort_values('importance',ascending=False)","b4c64324":"from sklearn.metrics import roc_curve, auc\ny_score = randomgrid_forest.predict_proba(x_test)  # \u968f\u673a\u68ee\u6797\nfpr, tpr, thresholds = roc_curve(y_test, y_score[:, 1])\nroc_auc = auc(fpr, tpr)\ndef drawRoc(roc_auc,fpr,tpr):\n    plt.subplots(figsize=(7, 5.5))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([-0.1, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \ndrawRoc(roc_auc, fpr, tpr)","b4366d91":"We can see RandomForest can generate better results in this models","3d3854a4":"# What we will do in this notebook\n\n- Data cleaning\n- Basic EDA\n- Visualization\n- Try to understand why those people left\n- Typical employee that left profiling.\n- Untypical employee that left profiling.\n- Regression analysis.\n- Random Forest classificaion.\n\nPlus we got <font color=deepskyblue> highest <\/font> classification score so far  <font color=deepskyblue> : ) <\/font>","3453d233":"# 3.Typical employee left profiling","aa70cc34":"## This notebook is still under construction.\n## Feel free to <font color=deepskyblue> FORK  <\/font> this notebook, Please  <font color=deepskyblue> UPVOTE !! <\/font> if it's helpful to you  <font color=deepskyblue> : ) <\/font>","4e9fc1f9":"## 5.1 LogisticRegression\nLet's first use LogisticRegression to deal with this data.\nIt seems like LogisticRegression is not very ideal for this dataset","e637c171":"# 5 Modeling","d497b709":"# 4 Untypical employee left profiling\n\nBut,why those senior people \/ higher job satisfaction people leave?\n\n1. Senior People tend to leave because of bad Environment Satisfaction,and TotalWorkingYears is another negative factor.\n2. people with high JobSatisfaction tend to leave because of Age, and TotalWorkingYears","62acb9a7":"Let's draw a ROC curve","7d747460":"# 2. DESCRIPTIVE STATISTICS\n\n** what we know**\n\n1. we have 16% employees left last year.\n2. 60% employees are Male.\n3. Most employees are during 30~38 years old.\n4. employees that left are generally younger than employees stay.\n5. The top relative features to attrition is MaritalStatus,EnvironmentSatisfaction,JobSatisfaction,YearsAtCompany,YearsWithCurrManager,Age,TotalWorkingYears\n6. people who left have pretty low jobsatisfaction,whereas enviromentssatisfaction varies.\n7. Noticed that there is relatively low ralation between leaving and performanceRating or jobinvolvements.\n8. Single empolyees are more likely to leave.","1c7b02ca":"## 5.2 Model Selection\n\nLet's see if there is any other model can generate better reuslt.","4029e36d":"### Check Uniqueness of EmployeeID column, we gonna merge those three dataframe using this column","5f2a5e2d":"# 1. KNOW YOUR DATA\n1. we have 401 entries and 35 columns or features\n2. we have 3 datasets for this project,\n3. we have 23 numerical features\uff0c8 string features.\n","e37b0c30":"### Checking nans in Our data set.\n\n Normally,we should carefully check every nan data to find out why it is missing and deal with them. We gonna leave them there and ignore them when analyzing,since this is just a quick analysis,and nans are just a tiny portion of the whole dataset. \n \n **What we know**\n \n 1. we have 110 enteries that have at least one Nan data.About 2% of all dataset.\n \n **What we do**\n \n 1. we ignore them.","9eaa5704":"Let's use RandomizedSearchCV to try tuning parameters","a413b9ed":"1. You are a pretty young people in this company,under 32 yrs old,possiblely a male,slightly more chance you are single.\n2. You have been woking at this company for 1~6 years.Toltal working years is under 12.\n3. but you hate it, your jobsatisfaction is pretty low, which is 1.0\n4. Despite that,your emotion doesnt affect your jobinvolment and job performance."}}