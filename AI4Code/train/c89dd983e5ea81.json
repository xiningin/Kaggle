{"cell_type":{"3f8c9137":"code","8067e4e3":"code","b5952b85":"code","a016cd22":"code","0f71a29c":"code","299a34c9":"code","7589682a":"code","191f868a":"code","ee1c1b7d":"code","5f6bb85d":"code","24b9972d":"code","29404060":"code","6bf472f0":"code","fbb1bb9d":"code","3831be06":"code","aef89477":"code","960dab95":"code","b21086ad":"code","ca751051":"code","a6de767b":"code","afbf3418":"code","06fe4430":"code","7817fda4":"code","1ae01906":"code","e953855b":"code","df37e3b4":"code","bec26ef0":"code","76db7aeb":"code","1efccc65":"code","56dc8ea6":"code","565fa10a":"code","e09c402d":"code","4b899c51":"code","75129678":"code","34398df1":"code","f883d852":"code","e1b34ee2":"code","cc413c2d":"code","575de83e":"code","9ceabbc0":"code","0d963830":"code","5bc942bd":"code","296c6e18":"code","58e97430":"code","f69d04f8":"code","c62cea96":"code","d897b81b":"code","fcea198d":"code","9f6d7346":"code","5ad80ca0":"code","a6da6b56":"code","b414c16f":"code","cc4a0e0d":"code","42160d24":"code","c60d50cb":"code","d2f85722":"code","93cf2629":"code","0072244f":"code","9d2a90eb":"code","1ac44153":"code","40849b27":"code","75cb380a":"code","ab50e30c":"code","c06487cb":"code","4df2b428":"code","1228be66":"code","f4f9929d":"code","72318263":"code","96c07084":"code","54d891a4":"code","f74e63f5":"code","0d955913":"code","81a9bc97":"code","1c9836f5":"code","27a0caea":"code","4b18cb43":"code","daa97bc1":"code","7aaa2bc6":"code","584d73e1":"code","c60e4e5b":"code","db59ca73":"code","72a4cad8":"code","c23ae90c":"code","63f92314":"code","5aad5835":"code","826cca89":"markdown","a719b277":"markdown","8cc74bcb":"markdown","871a241a":"markdown","41b6e6f9":"markdown","4f88e01b":"markdown","9a04f579":"markdown","a2f044ae":"markdown","114b6335":"markdown","f2d1e2c0":"markdown","6b59ee05":"markdown","029c5e5c":"markdown","0c325d1d":"markdown","70e80556":"markdown","1ba31a16":"markdown","90211f2d":"markdown","e72fed86":"markdown","9ffc88f6":"markdown","706f5be6":"markdown","2e0ee4df":"markdown","fd5cc806":"markdown","ac732514":"markdown","01c3abfe":"markdown","ca36d378":"markdown","afb49857":"markdown","0039b1fe":"markdown","282644af":"markdown","eb778a4e":"markdown","02a51f21":"markdown","f32a96fa":"markdown","b00c718c":"markdown","7731a99b":"markdown","02ba4031":"markdown","1afd7f40":"markdown","99b16bea":"markdown","7bbb60c1":"markdown","6539e63d":"markdown","ba95bf8a":"markdown","d4a10124":"markdown","59405e6a":"markdown","e58c9048":"markdown","15bc1804":"markdown","bf674f2b":"markdown","3e2a70db":"markdown","930526c5":"markdown","1e4277c2":"markdown","39d95572":"markdown","2e4e45f7":"markdown","ff90c878":"markdown","a9adff35":"markdown","d49a83c3":"markdown","5ded3c3a":"markdown","3533039d":"markdown","20675bc8":"markdown","e06e2d7b":"markdown","68253660":"markdown","49440fa6":"markdown","8327f8df":"markdown"},"source":{"3f8c9137":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport gc\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import classification_report, roc_auc_score, f1_score, mean_squared_error\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nplt.rcParams[\"figure.figsize\"] = (12,8)\nplt.rcParams['axes.titlesize'] = 16\nplt.style.use('seaborn-whitegrid')\nsns.set_palette(\"Set3\")\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))","8067e4e3":"base_dir = '\/kaggle\/input\/marketing-data\/'","b5952b85":"df = pd.read_csv(base_dir + 'marketing_data.csv')\ndf.head()","a016cd22":"print(f'No. of rows in the dataset: {df.shape[0]}\\nNo. of columns in the dataset: {df.shape[1]}')","0f71a29c":"df.describe().T","299a34c9":"df.info()","7589682a":"missing = df.isna().sum().reset_index()\nmissing.columns = ['features', 'total_missing']\nmissing['percent'] = (missing['total_missing'] \/ len(df)) * 100\nmissing.index = missing['features']\ndel missing['features']\n\nmissing['total_missing'].plot(kind = 'bar')\nplt.title('Missing Values Count')\nmissing.T","191f868a":"df.rename(columns = {' Income ': 'Income'}, inplace = True)\ndf['Income'] = df['Income'].str.replace('$', '')\ndf['Income'] = df['Income'].str.replace(',', '').astype('float')","ee1c1b7d":"plt.figure(figsize = (10, 6))\nsns.histplot(data = df['Income'])\nplt.title('Income Distribution')\nplt.grid()","5f6bb85d":"income_outliers = df['Income'][df['Income'] > df['Income'].mean() + 3 * df['Income'].std()]\nincome_outliers","24b9972d":"df['Income'] = df['Income'].fillna(df['Income'].median())\n\nprint(f'Number of Null values in *Income* after Imputation: {df[\"Income\"].isna().sum()}')","29404060":"cols_to_check = [c for c in df.columns if (df[c].dtype != 'object') & (df[c].nunique() > 2) & (c != 'ID')]\n#cols_to_check.__len__()\n\nfig, ax = plt.subplots(4, 4, figsize = (16, 10))\nax = ax.flatten()\n\nfor i, c in enumerate(cols_to_check):\n    sns.boxplot(x = df[c], ax = ax[i])\nplt.suptitle('Outlier Analysis using BoxPlots', fontsize = 25)\nfig.tight_layout()\n\ndel cols_to_check\ngc.collect()","6bf472f0":"df[df['Year_Birth'] <= 1900]","fbb1bb9d":"#Remove\ndf = df[df['Year_Birth'] > 1900].reset_index(drop = True)\n#Impute\n#out = df['Year_Birth'][df['Year_Birth'] <= 1900].index\n#df['Year_Birth'][out] = np.nan\n#df['Year_Birth'].fillna(df['Year_Birth'].value_counts().index[0], inplace = True)\n#df.iloc[out]\ndf.head()","3831be06":"countplot = ['Education', 'Marital_Status', 'Kidhome', 'Teenhome', 'Complain', 'Response', 'Country', \n             'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5']\nfig, ax = plt.subplots(int(len(countplot) \/ 2), 2, figsize = (15, 20))\nax = ax.flatten()\nfor i, c in enumerate(countplot):\n    sns.countplot(x = c, data = df, ax = ax[i])\nplt.suptitle('Unique Value Count Plot', y = 1.0, fontsize = 25)\nfig.tight_layout()\n","aef89477":"print(f'Before Transformation:\\n{df[\"Dt_Customer\"].head()}')","960dab95":"df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'])\nprint(f'After Transformation:\\n{df[\"Dt_Customer\"].head()}')","b21086ad":"df['Customer_Age'] = df['Dt_Customer'].dt.year - df['Year_Birth']\n\nsns.histplot(data = df['Customer_Age'], kde = True)\nplt.title('Histogram Distribution of Customer Age');","ca751051":"plt.figure(figsize = (20, 15))\nsns.boxplot(data = df, x = 'Country', y = 'Customer_Age', hue = 'Education')\nplt.ylim(5, 80)\nplt.title('Country Vs Customer Age Per Education');","a6de767b":"sns.boxplot(data = df, x = 'Education', y = 'Income')\nplt.ylim(0, 300000)\nplt.title('Education Vs Income');","afbf3418":"df['Education'] = df['Education'].apply(lambda x: 'Undergraduate' if str(x) == '2n Cycle' else str(x))\nsns.countplot(data = df, x = 'Education')\nplt.title('Number of unique values plot after transformation - Education');","06fe4430":"df['Marital_Status'] = df['Marital_Status'].apply(lambda x: 'Single' if str(x) in ['YOLO', 'Alone', 'Absurd'] else str(x))\nsns.countplot(data = df, x = 'Marital_Status')\nplt.title('Number of unique values plot after transformation - Marital_Status');","7817fda4":"df['Dt_Customer_Month'] = df['Dt_Customer'].dt.month\ndf['Dt_Customer_Year'] = df['Dt_Customer'].dt.year\n\ndf['Num_Dependants'] = df['Kidhome'] + df['Teenhome']\n\npurchase_features = [c for c in df.columns if 'Purchase' in str(c)]\n#we should remove 'NumDealsPurchases' from the list above\npurchase_features.remove('NumDealsPurchases')\ndf['Num_TotalPurchases'] = df[purchase_features].sum(axis = 1)\n\namt_spent_features = [c for c in df.columns if 'Mnt' in str(c)]\ndf['TotalAmount_Spent'] = df[amt_spent_features].sum(axis = 1)\n\n#df.head()","1ae01906":"print(f'Avg. number of total purchases: {df[\"Num_TotalPurchases\"].mean()}')\nsns.histplot(data = df, x = 'Num_TotalPurchases', kde = True);","e953855b":"print(f'Min. Customer Age: {df[\"Customer_Age\"].min()}')\nprint(f'Max. Customer Age: {df[\"Customer_Age\"].max()}')","df37e3b4":"df['AgeGroup'] = pd.cut(df['Customer_Age'], bins = [6, 24, 29, 40, 56, 75], \n                        labels = ['Gen-Z', 'Gen-Y.1', 'Gen-Y.2', 'Gen-X', 'BBoomers'])\n\nsns.countplot(data = df, x = 'AgeGroup');\nplt.title('Unique Count Plot by AgeGroup')","bec26ef0":"df_orig = df.copy()","76db7aeb":"encode_features = ['Education', 'Marital_Status', 'Country', 'AgeGroup']\nprint(f'Features that needs to be Label Encoded: \\n{encode_features}')\n\nfor c in encode_features:\n    lbl = LabelEncoder()\n    lbl.fit(list(df[c].astype(str).values))\n    df[c] = lbl.transform(list(df[c].astype(str).values))\nprint('Label Encoding done..')\n\ncategorical_features = ['AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1', 'AcceptedCmp2', \n                        'Response', 'Complain']\ncategorical_features.extend(encode_features)\nprint(f'Number of Categorical features: {len(categorical_features)}')","1efccc65":"numerical_features = [c for c in df.columns if c not in categorical_features]\n\nprint(f'Number of Numerical features: {len(numerical_features)}')\nprint(f'Number of Categorical features: {len(categorical_features)}')","56dc8ea6":"df.corr()[['Num_TotalPurchases']].style.background_gradient(sns.light_palette('#2ecc71', as_cmap = True))","565fa10a":"sns.lineplot(data = df, y = 'Income', x = 'Num_TotalPurchases');","e09c402d":"sns.boxplot(data = df, y = 'Num_TotalPurchases', x = 'Num_Dependants');","4b899c51":"features = df.drop(['ID', 'Num_TotalPurchases', 'Dt_Customer', 'Year_Birth'], axis = 1)\ntarget = df['Num_TotalPurchases']\n\nXtrain, Xvalid, ytrain, yvalid = train_test_split(features, target, \n                                                  test_size = 0.2, random_state = 42)\nprint(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)","75129678":"print(f'Avg. Num_TotalPurchases: {df[\"Num_TotalPurchases\"].mean()}')\nprint(f'Median Num_TotalPurchases: {df[\"Num_TotalPurchases\"].median()}')","34398df1":"lin_reg = LinearRegression()\n\nlin_reg.fit(Xtrain, ytrain)\npredictions = lin_reg.predict(Xvalid)\nprint(f'RMSE using Linear reg: {np.sqrt(mean_squared_error(yvalid, predictions))}')\n\nsns.histplot(predictions, kde = True);","f883d852":"print(f'Avg. Predictions: {np.mean(predictions)}')\nprint(f'Median Predictions: {np.median(predictions)}')","e1b34ee2":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(lin_reg, random_state = 42).fit(Xvalid, yvalid)\neli5.show_weights(perm, feature_names = Xvalid.columns.tolist(), top = 10)","cc413c2d":"import shap\n\nexplainer = shap.Explainer(lin_reg, Xtrain)\nshap_values = explainer(Xvalid)\n\n#plotting\nshap.summary_plot(shap_values, Xvalid)","575de83e":"sns.histplot(data = df['NumStorePurchases'], kde = True, palette = 'Set3');","9ceabbc0":"print(f'Avg. NumStorePurchases: {df[\"NumStorePurchases\"].mean()}')\nprint(f'Median NumStorePurchases: {df[\"NumStorePurchases\"].median()}')","0d963830":"df.drop('ID', axis = 1).corr()[['NumStorePurchases']].style.background_gradient(sns.light_palette('#2ecc71', as_cmap = True))","5bc942bd":"features = df.drop(['ID', 'NumStorePurchases', 'Dt_Customer', 'Year_Birth'], axis = 1)\ntarget = df['NumStorePurchases']\n\nXtrain, Xvalid, ytrain, yvalid = train_test_split(features, target, \n                                                  test_size = 0.2, random_state = 42)\nprint(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)","296c6e18":"lin_reg = LinearRegression()\n\nlin_reg.fit(Xtrain, ytrain)\npredictions = lin_reg.predict(Xvalid)\nprint(f'RMSE using Linear reg: {np.sqrt(mean_squared_error(yvalid, predictions))}')\n\nsns.histplot(predictions, kde = True);","58e97430":"print(f'Avg. NumStorePurchases Prediction: {np.mean(predictions)}')\nprint(f'Median NumStorePurchases Prediction: {np.median(predictions)}')","f69d04f8":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(lin_reg, random_state = 42).fit(Xvalid, yvalid)\neli5.show_weights(perm, feature_names = Xvalid.columns.tolist(), top = 10)","c62cea96":"import shap\n\nexplainer = shap.Explainer(lin_reg, Xtrain)\nshap_values = explainer(Xvalid)\n\n#plotting\nshap.summary_plot(shap_values, Xvalid)","d897b81b":"df_cn = pd.pivot_table(data = df_orig, index = 'Country', values = ['Num_TotalPurchases'], \n                        aggfunc = ['sum', 'mean'])\ndf_cn.T","fcea198d":"df_cn['sum']['Num_TotalPurchases'].sort_values(ascending = False).plot(kind = 'bar', rot = 0)\nplt.ylabel('Total Num Purchases')\nplt.title('Total Number of Purchases by Country');","9f6d7346":"df_cn['mean']['Num_TotalPurchases'].plot(kind = 'bar', rot = 0)","5ad80ca0":"sns.lineplot(data = df, x = 'NumStorePurchases', y = 'MntGoldProds', palette = 'Set3')","a6da6b56":"df[['MntGoldProds', 'NumStorePurchases']].corr()","b414c16f":"print(f'Avg. MntFishProducts: {np.mean(df[\"MntFishProducts\"])}')\nprint(f'Median MntFishProducts: {np.median(df[\"MntFishProducts\"])}')","cc4a0e0d":"sns.histplot(data = df['MntFishProducts'], kde = True, palette = 'Set3')","42160d24":"df_fish = pd.pivot_table(data = df_orig, index = ['Marital_Status', 'Education'], values = ['MntFishProducts'], \n                        aggfunc = 'sum')\ndf_fish.T","c60d50cb":"df_fish.sort_values(by = 'MntFishProducts', ascending = False).plot(kind = 'bar', rot = 60)","d2f85722":"df_orig.corr()[['MntFishProducts']].style.background_gradient(sns.light_palette('#2ecc71', as_cmap = True))","93cf2629":"features = df.drop(['ID', 'MntFishProducts', 'Dt_Customer', 'Year_Birth'], axis = 1)\ntarget = df['MntFishProducts'].copy()\n\nXtrain, Xvalid, ytrain, yvalid = train_test_split(features, target, \n                                                  test_size = 0.2, random_state = 42)\nprint(Xtrain.shape, ytrain.shape, Xvalid.shape, yvalid.shape)\n\nlin_reg = LinearRegression()\n\nlin_reg.fit(Xtrain, ytrain)\npredictions = lin_reg.predict(Xvalid)\nprint(f'RMSE using Linear reg: {np.sqrt(mean_squared_error(yvalid, predictions))}')","0072244f":"print(f'Avg. MntFishProducts Predictions: {np.mean(predictions)}')\nprint(f'Median MntFishProducts Predictions: {np.median(predictions)}')\n\nsns.histplot(predictions, kde = True).set(ylabel = None)","9d2a90eb":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(lin_reg, random_state = 42).fit(Xvalid, yvalid)\neli5.show_weights(perm, feature_names = Xvalid.columns.tolist(), top = 10)","1ac44153":"import shap\n\nexplainer = shap.Explainer(lin_reg, Xtrain)\nshap_values = explainer(Xvalid)\n\n#plotting\nshap.summary_plot(shap_values, Xvalid)","40849b27":"df_cmp = df[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5']].copy()\ncmp_success = df_cmp.sum(axis = 0)\ncmp_srate = df_cmp.sum(axis = 0) \/ len(df_cmp) * 100\n\nsns.barplot(x = df_cmp.columns, y = cmp_success.values)","75cb380a":"plt.pie(x = cmp_srate, labels = df_cmp.columns, autopct = '%1.2f%%', shadow = False, explode = [0, 0.1, 0, 0, 0]);","ab50e30c":"df_cmp = df_orig[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', \n                    'Country']].copy()\ndf_cmp['Total_Accepted'] = df_orig[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', \n                                     'AcceptedCmp5']].sum(axis = 1)\ndf_cmp.head()","c06487cb":"df_cmp_country = pd.pivot_table(data = df_cmp, index = 'Country', values = 'Total_Accepted', \n                               aggfunc ={'Total_Accepted': ['sum', 'count']})\ndf_cmp_country['SuccessRate'] = df_cmp_country['sum'] \/ df_cmp_country['count'] * 100\ndf_cmp_country.rename(columns = {'count': 'NumCustomers', 'sum': 'NumSuccess'}, inplace = True)\ndf_cmp_country = df_cmp_country.sort_values(by = 'SuccessRate', ascending = False)\ndf_cmp_country","4df2b428":"cm = df_cmp.groupby('Country').agg('mean').sort_values(by = 'Total_Accepted', ascending = False)\ncm.style.background_gradient(sns.light_palette('#2ecc71', as_cmap = True))","1228be66":"cm = df_cmp[df_cmp['Country'] != 'ME'].groupby('Country').agg('mean').sort_values(by = 'Total_Accepted', ascending = False)\ncm.style.background_gradient(sns.light_palette('#2ecc71', as_cmap = True))","f4f9929d":"pd.DataFrame(cm.iloc[:, :5].sum(axis = 0)).style.background_gradient(sns.light_palette('#2ecc71', as_cmap = True))","72318263":"pd.DataFrame(cm.iloc[:, :5].sum(axis = 0)).plot(kind = 'bar', rot = 0)\nplt.ylabel('Overall Campaign Performance')","96c07084":"df_cn = pd.pivot_table(data = df_orig, index = 'Country', values = ['TotalAmount_Spent'], \n                       columns = ['AgeGroup'], aggfunc = ['mean'])\ndf_cn = df_cn[df_cn.index != 'ME']\ndf_cn.columns = ['Gen-Z', 'Gen-Y.1', 'Gen-Y.2', 'Gen-X', 'BBoomers']\ndf_cn.T","54d891a4":"fig, axes = plt.subplots(4, 2, figsize = (20, 20))\n\nfor i, (idx, row) in enumerate(df_cn.iterrows()):\n    pct = row.values \/ np.sum(row) * 100\n    ax = axes[i \/\/ 2, i % 2]\n    ax.pie(row, labels = row.index, autopct = '%1.2f%%', radius = 1.2, textprops = {'fontsize': 10}, \n           shadow = True, explode = (pct == max(pct)) * 0.1, startangle = 30)\n    ax.set_title(idx)\n\nfig.delaxes(axes[3, 1])\nplt.suptitle('Avg. Amount Spent in Countries by Age Demography', fontsize = 15)\nplt.show()","f74e63f5":"df_cn = pd.pivot_table(data = df_orig, index = 'Country', values = ['TotalAmount_Spent'], \n                       columns = ['Marital_Status'], aggfunc = ['mean'])\ndf_cn = df_cn[df_cn.index != 'ME']\ndf_cn.columns = ['Divorced', 'Married', 'Single', 'Together', 'Widow']\ndf_cn.T","0d955913":"fig, axes = plt.subplots(4, 2, figsize = (20, 20))\n\nfor i, (idx, row) in enumerate(df_cn.iterrows()):\n    pct = row.values \/ np.sum(row) * 100\n    ax = axes[i \/\/ 2, i % 2]\n    ax.pie(row, labels = row.index, autopct = '%1.2f%%', radius = 1.2, textprops = {'fontsize': 10}, \n           shadow = True, explode = (pct == max(pct)) * 0.1, startangle = 30)\n    ax.set_title(idx)\n\nfig.delaxes(axes[3, 1])\nplt.suptitle('Avg. Amount Spent in Countries by Marital Status', fontsize = 15)\nplt.show()","81a9bc97":"df_cn = pd.pivot_table(data = df_orig, index = 'Country', values = ['TotalAmount_Spent'], \n                       columns = ['Education'], aggfunc = ['mean'])\ndf_cn = df_cn[df_cn.index != 'ME']\ndf_cn.columns = ['Basic', 'Graduation', 'Master', 'PhD', 'Undergraduate']\ndf_cn.T","1c9836f5":"fig, axes = plt.subplots(4, 2, figsize = (20, 20))\n\nfor i, (idx, row) in enumerate(df_cn.iterrows()):\n    pct = row.values \/ np.sum(row) * 100\n    ax = axes[i \/\/ 2, i % 2]\n    ax.pie(row, labels = row.index, autopct = '%1.2f%%', radius = 1.2, textprops = {'fontsize': 10}, \n           shadow = True, explode = (pct == max(pct)) * 0.1, startangle = 30)\n    ax.set_title(idx)\n\nfig.delaxes(axes[3, 1])\nplt.suptitle('Avg. Amount Spent in Countries by Education', fontsize = 15)\nplt.show()","27a0caea":"df[['Income', 'Num_Dependants', 'Recency', 'Customer_Age', 'Num_TotalPurchases', \n    'TotalAmount_Spent']].mean().round(1).to_frame(name = 'Average').style.background_gradient(sns.light_palette('#2ecc71', \n                                                                                                                 as_cmap = True))","4b18cb43":"df_orig.groupby(['Marital_Status'])['TotalAmount_Spent'].agg('mean').plot.pie(autopct = '%1.2f%%', shadow = True)\nplt.title('Avg. Amount Spent by Marital Status');","daa97bc1":"df_orig.groupby(['Education'])['TotalAmount_Spent'].agg('mean').plot.pie(autopct = '%1.2f%%', shadow = True)\nplt.title('Avg. Amount Spent by Education');","7aaa2bc6":"df_orig.groupby(['AgeGroup'])['TotalAmount_Spent'].agg('mean').plot.pie(autopct = '%1.2f%%', shadow = True)\nplt.title('Avg. Amount Spent by Age Group');","584d73e1":"mnt_products = [c for c in df.columns if 'Mnt' in c]\n\ndef show_value(x):\n    a  = np.round(x \/ 100.0 * np.sum(temp.values), 1)\n    return a\n\ntemp = df[mnt_products].mean()\nplt.pie(temp.values, labels = temp.index, autopct = show_value, shadow = True);","c60e4e5b":"cmp_num = [c for c in df.columns if 'AcceptedCmp' in c] + [ c for c in df.columns if ('Num' in c) & \n                                                           (c not in ['Num_Dependants', 'Num_TotalPurchases'])]\nax = df[cmp_num].mean().round(2).to_frame(name = 'Average').sort_values(by = 'Average').plot(kind = 'bar', \n                                                                                            legend = None, rot = 45)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))","db59ca73":"temp = pd.pivot_table(data = df_orig, index = 'AgeGroup', values = ['NumWebVisitsMonth', 'NumWebPurchases'], \n                      aggfunc = 'mean')\ntemp","72a4cad8":"temp = pd.pivot_table(data = df_orig, index = 'AgeGroup', values = ['NumWebVisitsMonth', 'NumWebPurchases'], \n                      aggfunc = 'mean')\n\nfig = plt.figure(figsize = (16, 8))\n\nplt.subplot(2, 2, 1)\npct = temp['NumWebVisitsMonth'].values \/ np.sum(temp['NumWebVisitsMonth']) * 100\nplt.pie(temp['NumWebVisitsMonth'].values, labels = temp.index, autopct = '%1.2f%%', \n        explode = (pct == max(pct)) * 0.1, shadow = True, radius = 1.2)\nplt.title('Avg. number of Web visits by Age group', y = 1.1)\n\nplt.subplot(2, 2, 2)\npct = temp['NumWebPurchases'].values \/ np.sum(temp['NumWebPurchases']) * 100\nplt.pie(temp['NumWebPurchases'].values, labels = temp.index, autopct = '%1.2f%%', \n        explode = (pct == max(pct)) * 0.1, shadow = True, radius = 1.2)\nplt.title('Avg. number of Web Purchases by Age group', y = 1.1)\nplt.show()","c23ae90c":"cmp_num = [c for c in df.columns if 'AcceptedCmp' in c]\ntemp = pd.pivot_table(data = df_orig, index = 'AgeGroup', values = cmp_num, \n                      aggfunc = 'mean')\ntemp['Total'] = temp.sum(axis = 1)\ntemp","63f92314":"def show_value(x):\n    a  = np.round(x \/ 100.0 * np.sum(temp['Total'].values), 2)\n    return a\npct = temp['Total'] \/ np.sum(temp['Total']) * 100\n\nplt.title('Campaign success by Age Group')\ntemp['Total'].plot.pie(autopct = show_value, explode = (pct == max(pct)) * 0.1, shadow = True);","5aad5835":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","826cca89":"__1.3 Feature Engineering__","a719b277":"- Customers spent most on Wines\n- Next best selling product is the Meat products\n- Third best selling product is Gold","8cc74bcb":"__Unique Value Count Plots__","871a241a":"- Amount spent of Fish increases with increase in total amount spent\n- When customer spend more on Meat, Gold, Sweet and Wines, they tend to spend less on fish products","41b6e6f9":"# __Statistical Analysis__","4f88e01b":"__Education__\n\nLet's create a new feature 'Customer_Age' and make some plots to explore more","9a04f579":"- From the Boxplot Education Vs Income, we can assume that 'Basic' is someone who Primary\/Secondary school educated\n- From the Country Vs Customer Age Per Education plot we can assume 'Graduation' as someone who hasn't completed thier undergrad or who is in the process of completing it\n- Also '2n Cycle' could be construted as undergraduates from their income band and age. ","a2f044ae":"![](https:\/\/www.googleapis.com\/download\/storage\/v1\/b\/kaggle-forum-message-attachments\/o\/inbox%2F1327132%2F0c83aef015cef72a1c6ef0bdb18937f3%2Fcolumns%20meaning%20small.png?generation=1609671531255584&alt=media)","114b6335":"- Let's check correlation of Total Purchases with other features","f2d1e2c0":"- The 'Accepted*', 'Response' and 'Complain' features are already One-Hot encoded\n- We need to encode other categorical features","6b59ee05":"- On the outset we can create day, month and year feature from Dt_Customer\n- Create number of children\/dependents in home by adding 'Kidhome' and 'Teenhome' features\n- Create number of Total_Purchases by adding all the purchases features\n- Create TotalAmount_Spent by adding all the Mnt* features","029c5e5c":"- We ignore the data from ME\n- AcceptedCmp1 has worked well in SP, CA, US\n- AcceptedCmp2 doesn't seem to have worked in any of the countries\n- AcceptedCmp3 has worked well in almost all the countries\n- AcceptedCmp4 has worked well in GER, CA, SP\n- AcceptedCmp5 has got good success in AUS, SP, CA","0c325d1d":"__2.4 Fish has Omega 3 fatty acids which are good for the brain. Accordingly, do \"Married PhD candidates\" have a significant relation with amount spent on fish? What other factors are significantly related to amount spent on fish?__","70e80556":"__2.3 Find relationship between Amount spent in gold products and Store Purchases__","1ba31a16":"# __EDA__\n\n__1.1 Null Value and Outlier Analysis__","90211f2d":"__3.3 Which products are performing best?__","e72fed86":"__2.5 Is there a significant relationship between geographical regional and success of a campaign?__","9ffc88f6":"# __Section 03: Data Visualization__","706f5be6":"- Campaign 'AcceptedCmp3' has performed well in all the countries\n- 'Acceptedcmp4' is the next best performing campaign","2e0ee4df":"- On an average there are more than 5 Store purchases made\n- While average number of web visits by customer is 5\n- While number of web purchases made is 4 if is an impressive number considering the number of web visits(5)\n- There are 2 purchases done via the channels Catalog and Deals respectively\n- Campaigns 1-5 have done badly while Campaign 2 is worst of all","fd5cc806":"__3.1 Which marketing campaign is most successful?__","ac732514":"- We will look at the average spending of Customer groups by Country","01c3abfe":"- ME-Mexico has the highest overall campaign success rate, but with only 3 customers we can ignore it\n- CA-Canada has the next highest success rate","ca36d378":"- There is a positive correlation between the number of store purchases and the amount spent on gold\n- Usually people like to buy gold in store so that they can feel it and try it on them","afb49857":"__3.4 Which channels are underperforming?__","0039b1fe":"- With only 3 data we ignore ME\n- Get the mean of campaign success by country","282644af":"__2.1 What factors are significantly related to the number of store purchases?__","eb778a4e":"- Store\/Catlog\/Web Purchases have positive correlation with number of purchases","02a51f21":"__1.2 Data Transformation__\n\n__Dt_Customer__\n- Dt_Customer column has datatype as object which can be changed to pandas datatime datatype.\n- We can extract more features by changing to datatime type","f32a96fa":"- Using Linear Regression gives us closer to the trainset predictions (avg. and median scores)\n- Most Influencial features are Num_TotalPurchases, Num_WebPurchases, Num_CatalogPurchases","b00c718c":"- There are 3 rows with the outliers, we can remove these or impute them with most frequent occurances","7731a99b":"__An average customer for this company:__\n* is of age 44 \n* average amount spent by Gen-Z (under 24 years old) is higher compared to age group 57 - 75\n* has atleast 1 dependant (Kid or Teen)\n* $52200 is the income he\/she earns on an average\n\n* has bought an item in the last 49 days\n* spends an average of $605 in purchasing items\n* has made about 12 purchases with the company\n* Customers with PhD spend the most, while with Master and Graduation spend almost equally\n* Customers who are widow seem to be spending more with this company","02ba4031":"- When Catalog and Web purchases increase there is in reduction in number of store purchases","1afd7f40":"- TotalAmount_Spent is the most important feature according to the above chart, there is a big change in performance metric if we are to random shuffle this feature","99b16bea":"- There are 8 outlier values as shown above\n- If we impute the NaNs with mean value it'll get affected by these outliers, so its better we impute using median values","7bbb60c1":"- As can be seen from the pivot table chart, Married-Graduation category spends more on Fish products\n- Married-PhD category spending on fish products is at 4th place\n- Let's find what others factors influence spending on fish products","6539e63d":"__3.2 What does the average customer look like for this company?__","ba95bf8a":"- From the box plot of Year_Birth, there are 1900 and less than 1900 values which can be removed or imputed with other values\n- Other outliers could be considered as inherent to the data (real world data)","d4a10124":"- Now let's look at the features influencing the NumStorePurchases.","59405e6a":"- We can create a categorical feature using the customer's age by binnning them, this could be helpful to understand purchaing behaviour\n- Ref: https:\/\/www.kasasa.com\/articles\/generations\/gen-x-gen-y-gen-z","e58c9048":"- Columns 'ACCEPTE*' seems to be categorical feature with 2 values, let's plot their unique value counts","15bc1804":"# Insights and Recommendations","bf674f2b":"__2.2 Does US fare significantly better than the Rest of the World in terms of total purchases?__","3e2a70db":" - Null values in 'Income' need to be imputed\n - Before that we need to fix the spaces in its name and change the datatype from object to float","930526c5":"- As the number of Dependents increase in a household, the Total purchases is lesser than others","1e4277c2":"- As can be seen from above pivot table, Spain (SP) has the most number of purchases and US in at the 7th place\n- We can gain more insights into the purchase pattern among AgeGroup, Marital_Status and Education of the customers","39d95572":"__Initial Observations__\n- There are Null values in feature 'Income'\n- There are 5 categorical features (object) nad 23 numerical features\n- Income is under object datatype - need to change it into numerical feature","2e4e45f7":"__Marital Status__\n- In the Marital_Status feature we can assume 'YOLO', 'Alone' and 'Absurd' as 'Single'","ff90c878":"- AcceptedCmp2 has low success rate as evident from the plots above","a9adff35":" - Income and Total amount spent are the most important factor that decides the total purchases feature (positive correlation)\n - Also NumWebPurchases, NumCatalogPurchases, NumStorePurchases have positive effect on the Total purhcases\n - NumWebVisitsMonth, Year_Birth, Kidhome have negative effect on Total Purchases","d49a83c3":"__ELI5 Interpretation__\n\n- A feature is \u201cimportant\u201d if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction. A feature is \u201cunimportant\u201d if shuffling its values leaves the model error unchanged, because in this case the model ignored the feature for the prediction.\n- The first number in each row shows how much model performance decreased with a random shuffling.\n- The number after the \u00b1 measures how performance varied from one-reshuffling to the next","5ded3c3a":"__SHAP Interpretation__\n\nHere, all the values on the left represent the observations that shift the predicted value in the negative direction while the points on the right contribute to shifting the prediction in a positive direction.","3533039d":"- The Income is distributed between 0 and 100,000 with few outliers, let's check what those outliers are","20675bc8":"# __Task Overview__\n\nYou're a marketing analyst and you've been told by the Chief Marketing Officer that recent marketing campaigns have not been as effective as they were expected to be. You need to analyze the data set to understand this problem and propose data-driven solutions.\n\n# __Section 01: Exploratory Data Analysis__\n\nAre there any null values or outliers? How will you wrangle\/handle them?\nAre there any variables that warrant transformations?\nAre there any useful variables that you can engineer with the given data?\nDo you notice any patterns or anomalies in the data? Can you plot them?\n\n# __Section 02: Statistical Analysis__\n\nPlease run statistical tests in the form of regressions to answer these questions & propose data-driven action recommendations. Make sure to interpret your results with non-statistical jargons.\n\n- What factors are significantly related to the number of store purchases?\n- Does US fare significantly better than the Rest of the World in terms of total purchases?\n- Your supervisor insists that people who buy gold are more conservative. Therefore, people who spent an above average amount on gold in the last 2 years would have more in store purchases. Justify or refute this statement using an appropriate statistical test\n- Fish has Omega 3 fatty acids which are good for the brain. Accordingly, do \"Married PhD candidates\" have a significant relation with amount spent on fish? What other factors are significantly related to amount spent on fish? (Hint: use your knowledge of interaction variables\/effects)\n- Is there a significant relationship between geographical regional and success of a campaign?\n\n# __Section 03: Data Visualization__\n\nPlease plot and visualize the answers to the below questions.\n- Which marketing campaign is most successful?\n- What does the average customer look like for this company?\n- Which products are performing best?\n- Which channels are underperforming?\n\n# __Section 04: Recommendations__\n\nBring together everything from Sections 01 to 03 and provide data-driven recommendations\/suggestions.","e06e2d7b":"- Let's have a regression model predict the Total number of purchases and from that we can find out the important features that have positive\/negative effect on them","68253660":"__Columns Explanation__","49440fa6":"__Check outliers for other features__","8327f8df":"1. Number of total purchases is influenced by the income level of the customers, when there is increase in the number of web\/catalog purchases, there is a reduction in store purchases.\n2. Customers who spend more on Wines and Meat products tend to spend less on Fish products\n    - Also, Married-Graduation category spends more on Fish products than others\n3. Overall Campaigns have not done well for this company\n    - Although we have ignored the data for Mexico due to limited data, the campaigns have been successful in Mexico, the company can do similar campaigns in other countries to attract customers where it's not successful\n    - Campaign2 has not performed well in any of the countries, it's time to revisit how it's been done\n    - Campiagn3 is the best performing among all the campaigns\n    - Though Campaigns aren't doing well, on an average it's been successful with Gen-Z overall with GenY.1 and Baby Boomers coming 2nd and 3rd respectively - more campaigns should be targeted to drive up the sales among this groups\n4. Overall Gen-Z and Baby Boomers are the two groups which have spend more $ in the company\n    - This correlates with family with kid\/teen spending more\n    - Campaigns should be designed to target other age groups\n    - Out of 5 web visits on an average 4 purchases were made, more deals should be promoted in web to target customers' web purchases\n5. Wines and Meat products are the top 2 best perfoming products in terms of sales\n    - Deals and promotions should be carried out to increase the sales of other products"}}