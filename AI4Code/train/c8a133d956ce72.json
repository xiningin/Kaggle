{"cell_type":{"f2bf7eb0":"code","544d7f72":"code","53bf4f47":"code","68c452f5":"code","82ab748e":"code","89eba13e":"code","b7627b88":"code","21165ff8":"code","d8ce7ee7":"code","535e08ce":"code","0bcafc5d":"code","6ce7eede":"code","048dd137":"code","8ea9b079":"code","0cac7631":"markdown","a5fdb21f":"markdown","8916ed1b":"markdown","2016f6fb":"markdown","a934a891":"markdown","a7188f05":"markdown","cbef7ccf":"markdown","fb7c477e":"markdown","31f47ed2":"markdown","e9f4b221":"markdown","db924832":"markdown"},"source":{"f2bf7eb0":"! pip install -q easyocr","544d7f72":"import cv2\nimport numpy as np\nimport pandas as pd\nimport easyocr\nimport matplotlib.pyplot as plt\n\nfrom tqdm.notebook import tqdm\n\nfrom glob import glob\nfrom random import sample\nfrom PIL import Image, ImageFont, ImageDraw, ImageEnhance\n\nfrom pathlib import Path","53bf4f47":"FONT = ImageFont.truetype(\"..\/input\/arial-font\/arial.ttf\", 15)\nGREEN = (57,255,20)","68c452f5":"reader = easyocr.Reader(['en'], gpu=False)","82ab748e":"file = '..\/input\/nfl-helmet-safety-cropped-jerseys-dataset-png\/57583_000082_Sideline_342_H36.png'\nreader.readtext(file, allowlist ='0123456789')","89eba13e":"img = Image.open(file)\nimg","b7627b88":"img = Image.open(file).resize((128,128))\nimg","21165ff8":"reader.readtext(np.array(img), allowlist ='0123456789')","d8ce7ee7":"FILES = glob('..\/input\/nfl-helmet-safety-cropped-jerseys-dataset-png\/*.png')","535e08ce":"!mkdir annotated","0bcafc5d":"N = 1000\ncorrect_predictions = []\nconf_th = 0.01\nsave = False\nfor file in tqdm(FILES[:N]):\n    file = Path(file)\n    img = Image.open(file).resize((128,128))\n    draw = ImageDraw.Draw(img)\n    for bbox, label, conf in reader.readtext(np.array(img), allowlist ='0123456789'):\n        correct = file.stem.split('_')[-1][1:] == label\n        correct_predictions.append(correct)\n        if conf > conf_th:\n            save = True\n            draw.rectangle((tuple(bbox[0]), tuple(bbox[2])), outline = GREEN, width = 2)\n            draw.text(((bbox[0][0] + bbox[1][0])\/2, bbox[0][1] - 2), f'{label}({conf:.2f})', anchor=\"ms\", font=FONT, fill = GREEN)\n    if save:\n        img.save(Path('.\/annotated')\/file.name)\n        save = False","6ce7eede":"print(f'Average number of RELATIVE correct predictions {np.array(correct_predictions).mean()}')\nprint(f'Average number of TOTAL correct predictions {np.array(correct_predictions).sum()\/N}')","048dd137":"from zipfile import ZipFile\nimport shutil\nimport os\ndef zip_folder(folder, rm_original = True):\n    # iterate over all the files in directory\n    for folderName, subfolders, filenames in os.walk(folder):\n        # create a ZipFile object\n        with ZipFile(folderName.split('\/')[-1] + '.zip', 'w') as zipObj:\n            for filename in filenames:\n                # create complete filepath of file in directory\n                filePath = os.path.join(folderName, filename)\n                # add file to zip\n                zipObj.write(filePath, os.path.basename(filePath))\n                # delete the file to open space\n                if rm_original:\n                    os.remove(filePath)\n    if rm_original:\n        shutil.rmtree(folder)","8ea9b079":"zip_folder('annotated')","0cac7631":"The first thing is to install EasyOCR with `pip install`","a5fdb21f":"To apply the OCR model to an image, it is as easy as a single line","8916ed1b":"## Thanks for reading\n\nThat would be all for this kernel. As you can see this technique is not strong enough to be used alone. My hopes of sharing this publicly is that maybe someone could improve this approach so we can actualy use it.","2016f6fb":"The model now reads the number '36' (second argument). The values `readtext` returns are:\n1. Bounding box\n1. Label\n1. Confidence","a934a891":"As you can see, the accuracy is not very good. We get about 30% right when we try to predict anything at all. That number alone is not that bad. The problem is that the algoritm hardly predicts anything. Most of the time the numbers are too blury or just simply occluded for the model to do any prediction.","a7188f05":"## Runing against 1k images\n\nNow that we got the basics covered, we can run this trough a bunch of images. The folowing code do:\n1. Get all the files inside my custom cropped dataset\n1. Make a new directory named `annotated`\n1. Loop trough the first N pictures and:\n    1. Try to read any number on the image\n    1. If it finds anything it writes the bbox, label and confidence over the image and save it inside `annotated` folder\n1. Zip the folder and delete all files\n\nWith that, you can simply download the zipped folder and see the final results","cbef7ccf":"I also loaded some defaults like the font I will be using and the color for the overlay text","fb7c477e":"To use EasyOCR, first you need to initialize the model. This will load (or download it too if needed). You can pass the language an if it should be loaded into the GPU or not (and some other paramters too)","31f47ed2":"Folowed by importing some basic libraries","e9f4b221":"But this didn't work... The reason why is that our crop is too small. A quick-n-dirty hack is to re-scale the image","db924832":"# Using OCR to read players numbers\n\nIn this notebook:\n1. I use EasyOCR package in an attempt at reading the number on the players jerseys\n\nThis code was inspired on [this](http:\/\/https:\/\/www.kaggle.com\/jinssaa\/jersey-number-detection-using-ocr) great kernel"}}