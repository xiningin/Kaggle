{"cell_type":{"d75f4ad9":"code","7e1e2914":"code","4d6b9ca3":"code","be7e5cff":"code","8c77a9e3":"code","01fdf66d":"code","ca25638e":"code","0596a4df":"code","e04f99e6":"code","9a54dc7e":"code","97153858":"code","862b1b3b":"code","c45d9d28":"code","1aed2862":"code","f23f1c79":"code","b3d33e82":"code","a31512ff":"code","0f4e34ad":"code","f813078d":"code","16c6f322":"markdown"},"source":{"d75f4ad9":"import numpy as np\nimport pandas as pd\nfrom mlxtend.frequent_patterns import apriori, association_rules\n","7e1e2914":"# load data:\nfile_path = \"..\/input\/hotel-booking-demand\/hotel_bookings.csv\"\ndf = pd.read_csv(file_path)","4d6b9ca3":"df.head()","be7e5cff":"df.shape","8c77a9e3":"df.columns","01fdf66d":"df.info()","ca25638e":"# check for missing values\ndf.isnull().sum()","0596a4df":"# Replace missing values:\n# agent: If no agency is given, booking was most likely made without one.\n# company: If none given, it was most likely private.\n# rest schould be self-explanatory.\nnan_replacements = {\"children:\": 0.0,\"country\": \"Unknown\", \"agent\": 0, \"company\": 0}\ndf_clean = df.fillna(nan_replacements)\n\n# \"meal\" contains values \"Undefined\", which is equal to SC.\ndf_clean[\"meal\"].replace(\"Undefined\", \"SC\", inplace=True)\n\n# Some rows contain entreis with 0 adults, 0 children and 0 babies. \n# I'm dropping these entries with no guests.\nzero_guests = list(df_clean.loc[df_clean[\"adults\"]\n                   + df_clean[\"children\"]\n                   + df_clean[\"babies\"]==0].index)\ndf_clean.drop(df_clean.index[zero_guests], inplace=True)","e04f99e6":"df_clean.isnull().sum()","9a54dc7e":"india_df = df_clean[df_clean[\"country\"] == 'IND']\n\nindia_df.head(10)","97153858":"india_df.shape","862b1b3b":"clean_india_df = india_df[['stays_in_weekend_nights',\n       'stays_in_week_nights',  'children', 'babies', 'previous_cancellations',\n       'previous_bookings_not_canceled',  'booking_changes', \n       'required_car_parking_spaces', 'total_of_special_requests']]\n#india_df.dropna(axis=0, subset =)\nclean_india_df.head()","c45d9d28":"# Defining the hot encoding function to make the data suitable\n# for the concerned libraries\ndef hot_encode(x):\n    if(x<= 0):\n        return 0\n    if(x>= 1):\n        return 1\n\n# Encoding the datasets\nclean_india_df_encoded = clean_india_df.applymap(hot_encode)\nclean_india_df = clean_india_df_encoded\n\n","1aed2862":"# Building the model\nfrq_items = apriori(clean_india_df, min_support = 0.05, use_colnames = True)\n\n# Collecting the inferred rules in a dataframe\nrules = association_rules(frq_items, metric =\"lift\", min_threshold = 1)\nrules = rules.sort_values(['confidence', 'lift'], ascending =[False, False])\nprint(rules.head())\n","f23f1c79":"clean_india_df.shape","b3d33e82":"dataset = pd.read_csv('..\/input\/new-india-cleaned\/clean_india_df.csv',header=None)\ntransactions = []\n\nfor i in range(0,len(dataset)):\n    transactions.append({str(dataset.values[i,j]) for j in range(0,len(dataset.columns)) if str(dataset.values[i,j]) != 'nan'})\n\nprint('Transactions:\\n')\nfor transaction in transactions:\n    print(transaction)","a31512ff":"def init_candidates(transactions):\n    candidates = dict()\n    for transaction in transactions:\n        for item in transaction:\n            itemset = set()\n            itemset.add(item)\n            itemset = frozenset(itemset)\n            if itemset not in candidates:\n                candidates[itemset] = 1\n            else:\n                candidates[itemset] += 1\n                \n    return candidates\n\n\ndef prune_candidates(candidates,support):\n    fp = dict()\n    for key in candidates:\n        if candidates[key] >= support:\n            fp[key] = candidates[key]\n    \n    return fp\n\n\ndef get_count(transactions,itemset):\n    itemset = set(itemset)\n    count = 0\n    for transaction in transactions:\n        if itemset.issubset(transaction):\n            count += 1\n            \n    return count\n\n\ndef get_candidates(fp,transactions,fp_length):\n    candidates = dict()\n    for key1 in fp:\n        for key2 in fp:\n            if key2 != key1:\n                itemset1 = set(key1)\n                itemset2 = set(key2)\n                itemset = itemset1.union(itemset2)\n                itemset = frozenset(itemset)\n                if itemset not in candidates and len(itemset) == fp_length:\n                    candidates[itemset] = get_count(transactions,itemset)\n    \n    return candidates\n\n\ndef get_itemset_length(candidates):\n    itemset_len = 0\n    for key in candidates:\n        itemset_len = len(key)\n        break\n    \n    return itemset_len\n\n\nimport itertools\n\ndef get_rules(fp):\n    rules = []\n    for itemset in fp:\n        itemset = set(itemset)\n        for length in range(1,len(itemset)):\n            subsets = set(itertools.combinations(itemset, length))\n            for subset in subsets:\n                lhs = set(subset)\n                rhs = itemset.difference(lhs)\n                rules.append([lhs,rhs])\n    \n    return rules\n\n\ndef prune_rules(rules,confidence,transactions):\n    fp = []\n    for rule in rules:\n        lhs = rule[0]\n        rhs = rule[1]\n        lhs_rhs = lhs.union(rhs)\n        lhs_count = get_count(transactions,lhs)\n        lhs_rhs_count = get_count(transactions,lhs_rhs)\n        conf = lhs_rhs_count\/lhs_count\n        if conf >= confidence:\n            support = lhs_rhs_count\/len(transactions)\n            fp.append([lhs,rhs,support,conf])\n    \n    return fp\n\ndef display(candidates,fp,length):\n    print()\n    print(\"****** {}-Frequent Candidates ******\".format(length))\n    for key in candidates:\n        print(set(key),' : ',candidates[key])\n    print()\n    print(\"****** {}-Frequent Itemlist ******\".format(length))\n    for key in fp:\n        print(set(key),' : ',fp[key])","0f4e34ad":"def apriori(transactions,support,confidence):\n    support = support\/100 * len(transactions)\n    confidence = confidence\/100\n    candidates = init_candidates(transactions)\n    old_fp = prune_candidates(candidates,support)\n    final_fp = dict()\n    display(candidates,old_fp,1)\n    \n    while True:\n        new_fp_length = get_itemset_length(candidates) + 1\n        candidates = get_candidates(old_fp,transactions,new_fp_length)\n        new_fp = prune_candidates(candidates,support)\n        display(candidates,new_fp,new_fp_length)\n        if len(new_fp)<1:\n            final_fp = old_fp\n            break\n        else:\n            old_fp = new_fp\n    \n    rules = get_rules(final_fp)\n    fp = prune_rules(rules,confidence,transactions)\n    return fp","f813078d":"support = float(input('Enter support percentage : '))\nconfidence = float(input('Enter confidence percentage : '))\nfp = apriori(transactions,support,confidence)","16c6f322":"Thus, we can conclude that:\n* customers travel and stay with children have more special requests\n* customers who travel and stay during weekdays have more special requests"}}