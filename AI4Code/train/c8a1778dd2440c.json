{"cell_type":{"5a40d3a2":"code","9206dfd7":"code","be9a9951":"code","b6a5b372":"code","c4fb53e7":"code","9606c918":"code","da7eb7ac":"code","6d61d0e7":"code","41e72bbe":"code","568e8b05":"code","9185dffc":"code","b1111d5c":"code","c60c3491":"code","30e62fab":"code","485ab646":"code","54e22e52":"code","ae30e48e":"code","eeeb6271":"code","cd771388":"code","c580fc31":"code","fdbda6fd":"code","df457985":"code","0a199e5d":"code","ee840dc4":"markdown","52b01db6":"markdown","85385168":"markdown","95138625":"markdown","f54069d9":"markdown","93b1d928":"markdown","97ded01a":"markdown","4e401e5d":"markdown","57069bbb":"markdown","dab79ea3":"markdown","48a404c0":"markdown","7719f55f":"markdown","c542c14f":"markdown","b1973bc1":"markdown","336cb83f":"markdown","d1930ad6":"markdown","20a3ccba":"markdown","fe889ab4":"markdown","2243b510":"markdown","28cf9413":"markdown","458d3eb1":"markdown","8b8cfe63":"markdown","9c708054":"markdown","35f955dc":"markdown","48952d32":"markdown","3a067d24":"markdown","bcae0b69":"markdown","d94e174d":"markdown","d89ad78b":"markdown","958ffa85":"markdown","dcb06957":"markdown"},"source":{"5a40d3a2":"import warnings\n\nfrom statistics import stdev, mean\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, KFold\n\nfrom lightgbm import LGBMClassifier, plot_metric\n\nfrom sklearn.metrics import cohen_kappa_score\n\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)","9206dfd7":"datos = pd.read_csv('..\/input\/petfinder-adoption-prediction\/train\/train.csv')\ndatos.head()","be9a9951":"datos.info()","b6a5b372":"datos.isnull().sum()","c4fb53e7":"datos[\"Name\"].value_counts()","9606c918":"datos[datos.Name.isnull()].head()","da7eb7ac":"datos.Description.describe()","6d61d0e7":"datos.Description.head()","41e72bbe":"datos.nunique()","568e8b05":"# Se seleccionan columnas con menos de 40 valores distintos\ndatos_a_visualizar = datos.nunique()[datos.nunique() < 40].index\n\n# Se configuran los par\u00e1metros de figura a crear, se divide por 2.54 para pasar las dimensiones a cm\nplt.rcParams['figure.figsize'] = [30\/2.54, 300\/2.54]\nfix, axs = plt.subplots(nrows = len(datos_a_visualizar), ncols = 1)\n\n# Se crean los gr\u00e1ficos para cada variable\nfor i, column in enumerate(datos_a_visualizar):\n    datos[column].value_counts().plot.bar(title = column, rot = 45, ax = axs[i])","9185dffc":"datos.drop([\"Name\", \"Description\", \"PetID\"], axis = 1, inplace = True)\ndatos.head()","b1111d5c":"rescuer_id = dict(datos['RescuerID'].value_counts())\n\ndatos = datos.replace(rescuer_id)\n\ndatos.rename(columns= {'RescuerID': 'rescuer_score'}, inplace= True)\n\ndatos.head()","c60c3491":"def crear_train_test(datos: pd.DataFrame, var_respuesta: str, tamanio: float, semilla: int=1) -> tuple:\n    \n    x_train, x_test, y_train, y_test = train_test_split(\n        datos.drop(var_respuesta, axis=1),\n        datos[[var_respuesta]], \n        test_size=tamanio, \n        random_state=semilla\n    )\n    \n    return x_train, x_test, y_train, y_test\n\n# Se ejecuta la funci\u00f3n a modo de ejemplo, se vuelve a emplear mas abajo.\nx_train, x_test, y_train, y_test = crear_train_test(datos, \"AdoptionSpeed\", 0.1)","30e62fab":"def crear_folds(datos: pd.DataFrame, nro_folds: int) -> list:\n\n    kf = KFold(n_splits=nro_folds, shuffle = True,random_state=512)\n    folds = [(datos.iloc[train_idx].index, datos.iloc[valid_idx].index) for train_idx, valid_idx in kf.split(datos)]\n    \n    return folds\n\n\ndef calcular_kappa(y_true, y_pred) -> tuple:\n    \n    res = cohen_kappa_score(y_true, y_pred.reshape((y_true.shape[0], 5), order=\"F\").argmax(axis=1), weights= 'quadratic')\n    \n    return \"kappa\", res, True\n\n\ndef calcular_estadisticos(datos: list) -> dict:\n       \n    media = mean(datos)\n    desv_est = stdev(datos)\n    rstdev = desv_est\/media*100\n    \n    return {\"media\": media, \"stdev\": desv_est, \"rstdev\": rstdev}\n\n\ndef calcular_factor_everfitting(modelo, nombre_metrica=\"kappa\"):\n\n    factor_overfitting = modelo.evals_result_['training'][nombre_metrica][-1] \/ modelo.evals_result_['valid_1'][nombre_metrica][-1]\n\n    return factor_overfitting\n\n\ndef realizar_cv_LGBM_kappa(datos: tuple, nro_folds: int, parametros: dict) -> dict:\n  \n    x_train_val, y_train_val = datos\n    \n    kappa_folds = []\n    valores_pred = pd.Series()\n    valores_verd = pd.Series()\n    modelos_folds = []\n    \n    for i, (fold_train, fold_val) in enumerate(crear_folds(x_train_val.join(y_train_val), nro_folds)):\n        print(f\"--------- Fold {i+1} ---------\")\n        xt, xv = x_train_val.loc[fold_train], x_train_val.loc[fold_val]\n        yt, yv = y_train_val.loc[fold_train], y_train_val.loc[fold_val]\n        \n        modelo = LGBMClassifier(**parametros, n_estimators=1000, metric=\"custom\")\n        modelo.fit(\n            xt, yt, \n            eval_set=[(xt, yt), (xv, yv)],\n            early_stopping_rounds=50, \n            eval_metric=calcular_kappa,\n            verbose=100\n        )\n        prediccion = pd.Series(modelo.predict(xv), index=xv.index)\n        valores_pred = valores_pred.append(prediccion)\n        valores_verd = valores_verd.append(yv[yv.columns[0]])\n        \n        kappa_folds.append(cohen_kappa_score(yv, prediccion, weights= 'quadratic'))\n        \n        modelos_folds.append(modelo)\n    \n    kappa_final_cv = cohen_kappa_score(valores_verd, valores_pred, weights= 'quadratic')\n    \n    # Entrena el modelo por \u00faltima vez con todos los datos\n    modelo_final = LGBMClassifier(**parametros, n_estimators=1000, metric=\"custom\")\n    modelo_final.fit(x_train_val, y_train_val, eval_metric=calcular_kappa)\n    \n    return {\"parametros\": parametros, \n            \"modelo\": modelo_final,\n            \"kappa\": kappa_final_cv,\n            \"folds\": nro_folds, \n            \"estadisticos_kappa_cv\": calcular_estadisticos(kappa_folds),\n            \"modelos_folds\": modelos_folds,\n            \"factor_overfitting_mean\": mean([calcular_factor_everfitting(datos_modelo) for datos_modelo in modelos_folds]),\n            \"factor_overfitting_stev\": stdev([calcular_factor_everfitting(datos_modelo) for datos_modelo in modelos_folds])\n           }","485ab646":"# Divisi\u00f3n de datos en Train y test\nx_train, x_test, y_train, y_test = crear_train_test(datos, \"AdoptionSpeed\", 0.1)\n\n# Selecci\u00f3n de hiperpar\u00e1mtros de ejemplo\nparametros = {'max_depth': 6, 'num_leaves': 70, 'learning_rate': 0.05}\n\n# Sealizaci\u00f3n de la validaci\u00f3n cruzada con 2 folds para probar\nresultado = realizar_cv_LGBM_kappa(datos=(x_train, y_train) , nro_folds= 2, parametros = parametros)\n\n# Visualizaci\u00f3n de resultado\nresultado\n\n# Ejemplo de como se aplicar\u00eda el modelo final al conjunto de datos de prueba\n# cohen_kappa_score(y_test, resultados[\"modelo\"].predict(x_test), weights= 'quadratic')","54e22e52":"def ejecutar_busqueda_de_hiperparametros_con_cv(datos: tuple, folds: int, grilla_hiperparametros: dict) -> dict:\n    \n    resultado_grid_search = {}\n    resultados_prelim = []\n    \n    for parametros in grilla_hiperparametros:\n        print(f\"----- {parametros} -----\")\n        resultado = realizar_cv_LGBM_kappa(datos= datos , nro_folds= folds, parametros= parametros)\n        resultados_prelim.append(resultado)\n        \n    # Obtenci\u00f3n de mejor modelo criterio kappa\n    mejor_kappa = max([resultado[\"kappa\"] for resultado in resultados_prelim])\n\n    modelo_mejor_kappa = [resultado for resultado in resultados_prelim if resultado[\"kappa\"] == mejor_kappa][0]\n    \n    # Obtenci\u00f3n de mejor modelo criterio menor overfitting\n    menor_overfitting = min([resultado[\"factor_overfitting_mean\"] for resultado in resultados_prelim])\n\n    modelo_menor_overfitting = [resultado for resultado in resultados_prelim if resultado[\"factor_overfitting_mean\"] == menor_overfitting][0]\n\n    \n    # Mostrar resultados como dataframe\n    resultado_data_frame = pd.DataFrame(resultados_prelim)\n\n    resultado_data_frame = resultado_data_frame.join(\n        resultado_data_frame[\"parametros\"].apply(pd.Series) # Transforma a los diccionarios en columnas\n    ).drop(\"parametros\", axis = 1) # Quita la columna que estaba como diccionario\n\n    resultado_data_frame = resultado_data_frame.join( # Se repiten los pasos para la otra columna con diccionario\n        resultado_data_frame[\"estadisticos_kappa_cv\"].apply(pd.Series)\n    ).drop(\"estadisticos_kappa_cv\", axis = 1)\n\n    \n    # Armado de presentaci\u00f3n de resultado de grid search\n    resultado_grid_search[\"modelo_mejor_kappa\"] = modelo_mejor_kappa\n    resultado_grid_search[\"modelo_menor_overfitting\"] = modelo_menor_overfitting\n    resultado_grid_search[\"resultados\"] = resultados_prelim\n    resultado_grid_search[\"resultados_dataframe\"] = resultado_data_frame\n    \n    return resultado_grid_search","ae30e48e":"parametros = []\ndepths = range(2, 50, 5)\nnum_leaves = range(5, 100, 15)\nlearning_rate = 0.05\n\nfor leaf in num_leaves:\n    for depth in depths:\n        parametros.append({\"max_depth\": depth, \"num_leaves\": leaf, \"learning_rate\": learning_rate })\n\n# Selecci\u00f3n de par\u00e1metros aleatorios para random search\n        \nfrom random import randint\n\nnumeros_aleatorios = list(set([randint(0, len(parametros)-1) for _ in range(0, 10)]))\nnumeros_aleatorios\n\nparametros = [parametros[i] for i in numeros_aleatorios]\nparametros","eeeb6271":"x_train, x_test, y_train, y_test = crear_train_test(datos, \"AdoptionSpeed\", 0.1)\n\nresultados_random_search_cv = ejecutar_busqueda_de_hiperparametros_con_cv(datos = (x_train, y_train), \n                                                                          folds = 10, \n                                                                          grilla_hiperparametros = parametros)","cd771388":"resultados_random_search_cv[\"resultados_dataframe\"].sort_values(\"factor_overfitting_mean\")","c580fc31":"## Hiperpar\u00e1metros seleccionados\n\nparametros_seleccionados = resultados_random_search_cv[\"modelo_menor_overfitting\"][\"parametros\"]\n\n\nmodelo = LGBMClassifier(**parametros_seleccionados, n_estimators=1000, metric=\"custom\")\nmodelo.fit(\n    x_train, y_train, \n    eval_set=[(x_train, y_train), (x_test, y_test)],\n    early_stopping_rounds=50, \n    eval_metric=calcular_kappa,\n    verbose=100\n)\n\nplt.rcParams['figure.figsize'] = [20\/2.54, 20\/2.54]\nplot_metric(modelo)","fdbda6fd":"cohen_kappa_score(\n    y_test,\n    modelo.predict(x_test),\n    weights= 'quadratic'\n)","df457985":"parametros_seleccionados = resultados_random_search_cv[\"modelo_menor_overfitting\"][\"parametros\"]\n\nmodelo_final = LGBMClassifier(**parametros_seleccionados, n_estimators=1000, metric=\"custom\")\nmodelo_final.fit(datos.drop(\"AdoptionSpeed\", axis=1), datos[[\"AdoptionSpeed\"]], verbose=100)","0a199e5d":"#carga dataset de validacion y transformacion\ndatos_test_entrega_completo = pd.read_csv('..\/input\/petfinder-adoption-prediction\/test\/test.csv')\ndatos_test_entrega = datos_test_entrega_completo.drop([\"Name\", \"Description\", \"PetID\"], axis = 1)\ndatos_test_entrega_rescuer_id = dict(datos_test_entrega['RescuerID'].value_counts())\ndatos_test_entrega = datos_test_entrega.replace(datos_test_entrega_rescuer_id)\ndatos_test_entrega.rename(columns= {'RescuerID': 'rescuer_score'}, inplace= True)\n\n#prediccion con dataset de validacion\npredicciones = modelo_final.predict(datos_test_entrega)\npredicciones\n#submit de las predicciones\nsubmit = pd.DataFrame.from_dict({'PetID': datos_test_entrega_completo['PetID'],\n                                     'AdoptionSpeed': predicciones})\nsubmit.head()\nsubmit.to_csv('submission.csv', index=False)\n#chequeo del submit\n!head submission.csv\n","ee840dc4":"### 3.1. Verificaci\u00f3n de nulos\n\nDe la inspecci\u00f3n inicial se identificaron valores de tipo de dato \"NaN\" en dos variables, **\"Name\"** y **\"Description\"**.","52b01db6":"Elegimos el algoritmo LGBM que no demanda la normalizaci\u00f3n o estandarizaci\u00f3n de las variables.","85385168":"### Definici\u00f3n de hiperpar\u00e1metros a optimizar","95138625":"## Entrenamiento Final del modelo con el 100 % de los datos de entrenamiento y mejores hiperpar\u00e1metros","f54069d9":"### Esquema propuesto","93b1d928":"## 3. Pre-procesar Nulos\nVerificar la existencia de Nulos y decidir como Imputarlos en caso de que existan\n\nVerificar la existencia de Ceros u otros valores que puedan indicar que pueden ser perdidos","97ded01a":"#### 3.1.1. Variable \"Name\"\n\nLa columna **\"Name\"** tiene **1257** valores nulos y **9060** valores \u00fanicos. Los valores no son siempre nombres, hay casos que corresponden a descripciones, por ejemplo \"4 PUPPIES FOR ADOPTION\". Por el momento se decide dejarla fuera del an\u00e1lisis dado que requiere una limpieza detallada para obtener informaci\u00f3n \u00fatil.","4e401e5d":"### Ejecutar random search y CV","57069bbb":"## 6. Separa la base de Test (10%) y Train (90%)\nPueden ser otros porcentajes que les parezcan mejor","dab79ea3":"### Ejemplo de corrida de CV para un set de hiperpar\u00e1metros\n\nNo es necesario correr este bloque de c\u00f3digo, es solo a modo de ejemplo","48a404c0":"## 5. Normalizar o Estandarizar las variables Numericas (para los modelos que sean necesarios)\n\nRevisar si existen valores extremos y considerarlos para los modelos que afecte","7719f55f":"## 8. Entrenar al menos un Modelo que prefieran y optimizar al menos un Hiperpar\u00e1metro","c542c14f":"### 4.1. Se quitan las columnas Name, Description y PetID","b1973bc1":"## Entrenamiento y testeo del modelo final","336cb83f":"## 2. Leer los Datos\nAl menos los datos Tabulares de la base de \"train\"","d1930ad6":"#### 3.2.2. Inspecci\u00f3n visual de valores","20a3ccba":"#### 3.2.1. Valores \u00fanicos por columna","fe889ab4":"## Preparaci\u00f3n de submission","2243b510":"### 2.1. Carga de datos","28cf9413":"#### 3.1.2. Variable \"Description\"\n\nSe decide quitar la variable dado que en el modelo inicial no se a incluir procesamiento de lenguaje natural (ver punto 4).","458d3eb1":"* Crear un Dataframe con los resultados de los modelos y sus hiperpar\u00e1metros.\n* Seleccionar de ese dataframe el que di\u00f3 mejor resultado.","8b8cfe63":"### 4.2. Variable RescuerID\n\nReemplazamos el ID del\/la rescatador\/a por la cantidad de mascotas rescatadas por la persona creando la nueva variable **rescuer_score**.","9c708054":"## 1. Importar las Librer\u00edas Necesarias","35f955dc":"#### Variables categ\u00f3ricas y num\u00e9ricas con pocos valores distintos\n\nDe la inspecci\u00f3n visual se concluye que los valores de las variables con menos de 40 valores distintos coinciden con la [descripci\u00f3n presente en los metadatos](https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction\/data).","48952d32":"### 3.2. Verificaci\u00f3n de valores perdidos","3a067d24":"## 4. Convertir o eliminar las Columnas Categ\u00f3ricas\n\nPor ejemplo, la Descripci\u00f3n habr\u00eda que sacarla para un an\u00e1lisis independiente","bcae0b69":"### 7. Para la parte de Train, armar un esquema de Cross Validation\n\nUsar 10 Folds","d94e174d":"### Funciones de ayuda","d89ad78b":"### Funciones de ayuda\n\n\n","958ffa85":"![Esquema 10 fold CV](https:\/\/i.imgur.com\/3XSPeOU.png)","dcb06957":"### 2.2. Informaci\u00f3n sobre los datos"}}