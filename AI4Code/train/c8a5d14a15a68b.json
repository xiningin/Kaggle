{"cell_type":{"75ff1f7b":"code","1322f260":"code","9aeaa76f":"code","fb9c45ab":"code","850b2ac4":"code","61cf3b6c":"code","16246a2d":"code","99ce1df3":"code","fe529b05":"code","1c55303e":"code","7ad75f21":"code","a830fc86":"code","f303f0a5":"code","dbdb3ad6":"code","6cfec6be":"code","347235a3":"code","e041e4a7":"markdown","95da2f78":"markdown"},"source":{"75ff1f7b":"import os\nimport zipfile\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.optimizers import Adam","1322f260":"import tensorflow","9aeaa76f":"tensorflow.__version__","fb9c45ab":"# <SPECIFY YOUR PATH HERE>\npath = \"..\/input\/kaggledays-china\/\"\nos.listdir(path) # you should have test and train data here","850b2ac4":"# This initial size of the pictures - change it, if you're going to crop them manually\nimg_width, img_height = 100, 100\n\n# Specify here where your data are located - I use combined, 3-channel data\n\ntrain_data_dir = path + 'train3c\/train3c' # train data - it should have directories for each class inside\ntest_data_dir = path + 'test3c'  # test data - you have to keep 2-level directory structure here\n\n\nnb_train_samples = 5024\nnb_validation_samples = 1257\nepochs = 20\nbatch_size = 512","61cf3b6c":"if K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)","16246a2d":"# I use sklearn's implementation of ROC AUC, out of convenience\ndef auroc(y_true, y_pred):\n    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)","99ce1df3":"# Feel free to add more layers or neurons if you have enough computing power\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), input_shape=input_shape))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))\n\nmodel.add(Flatten())\nmodel.add(Dense(32))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.20))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","fe529b05":"# I star with quite small lr \noptimizer = Adam(lr=0.0003)\nmodel.compile(loss='binary_crossentropy',\n              optimizer=optimizer,\n              metrics=[auroc])","1c55303e":"# this is the augmentation configuration we will use for training\n# you can try using more transformations here, by uncommenting lines below\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n#     shear_range=0.2,\n#     zoom_range=[0.5,1.0],\n#     brightness_range=[0.2,1.0],\n#     rotation_range=90,\n#     horizontal_flip=True\n)","7ad75f21":"# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(\n    rescale=1. \/ 255\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    seed = 42\n)\n\n# avoid shuffling her - it'll make hard keeping your predictions and labels together\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode=None,\n    seed = 42,\n    shuffle = False\n)","a830fc86":"model.fit_generator(\n    train_generator,\n    steps_per_epoch=nb_train_samples \/\/ batch_size,\n    epochs=epochs,\n    #you can add a generator with validation data here, to monitor your training process in each epoch\n)","f303f0a5":"pred=model.predict_generator(test_generator,\nverbose=1)\npred[:10] # check if format is correct","dbdb3ad6":"pred = [x[0] for x in pred]","6cfec6be":"labels = (test_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())","347235a3":"# Save the data to required sumbission format\n\nfilenames=test_generator.filenames\nresults=pd.DataFrame({\"id\":[x.split(\"\/\")[-1].split(\".\")[0] for x in filenames],\n                      \"is_star\":pred})\nresults.to_csv(\"results.csv\",index=False)","e041e4a7":"# Aim for the stars! Baseline solution.\nWelcome! We're glad you decided to take part in the competition. The aim of this notebook is to help you to start and submit your first model as quick as possible, so you can focus on improving your results. I decided to buld my model in Keras, because it enables fast experimentation and is beginer friendly, but if you have some experience in other frameworks you can quickly translate it e.g to PyTorch. Let's begin!\n\nSidenote 1: I trained moded like this one on google colab, so, it shouldn't be computationally expensive, at least if you don't make major changes in NN. <br>\nSidenote 2: It will require some minor fixes (e.g. specyfing where your data are etc.) to run, so I recommend to download it on your lcoal machine or UCloud and starting from there.\n","95da2f78":"### Next steps\nThis should give around **0.68 AUC on public leaderboard**, but there are few more things to do:\n1. There is no local validation here, so if you want to know what's going on and don't waste submissions, build your own validation set\n2. Try adding star coordinates\n3. Try more sophisticated network architectures (this one is pretty basic)\n4. See if adding image transformations helps (rotaton, flips etc.)\n\n**Have fun!**"}}