{"cell_type":{"37496bfa":"code","e57917fe":"code","a5de8f02":"code","dc5d5256":"code","ef205294":"code","af564e04":"code","d78421b6":"code","decd1682":"code","36b5f056":"code","8cc6399a":"code","68612046":"code","f607355d":"code","6075d5a5":"code","40de4e7f":"code","5ed2da69":"code","57a6d30b":"code","2fd1554f":"code","2b8a3ff4":"markdown","ad6e743f":"markdown","0bbb7cd0":"markdown","165dd726":"markdown","d9b0d9b1":"markdown","c88b8c9a":"markdown","b57b5a88":"markdown","b2ebc6fb":"markdown","9f038de9":"markdown","4964713d":"markdown","507a2d55":"markdown","e30f89e5":"markdown","ad9176c0":"markdown","70a3548a":"markdown","a6bb2e6b":"markdown","ad4656a6":"markdown"},"source":{"37496bfa":"!pip install alibi","e57917fe":"import tensorflow as tf\ntf.get_logger().setLevel(40) # suppress deprecation messages\ntf.compat.v1.disable_v2_behavior() # disable TF2 behaviour as alibi code still relies on TF1 constructs\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom time import time\nfrom alibi.explainers import CounterFactual\nprint('TF version: ', tf.__version__)\nprint('Eager execution enabled: ', tf.executing_eagerly()) # False","a5de8f02":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nprint('x_train shape:', x_train.shape, 'y_train shape:', y_train.shape)\nplt.gray()\nplt.imshow(x_test[1]);","dc5d5256":"x_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255\nx_train = np.reshape(x_train, x_train.shape + (1,))\nx_test = np.reshape(x_test, x_test.shape + (1,))\nprint('x_train shape:', x_train.shape, 'x_test shape:', x_test.shape)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\nprint('y_train shape:', y_train.shape, 'y_test shape:', y_test.shape)","ef205294":"xmin, xmax = -.5, .5\nx_train = ((x_train - x_train.min()) \/ (x_train.max() - x_train.min())) * (xmax - xmin) + xmin\nx_test = ((x_test - x_test.min()) \/ (x_test.max() - x_test.min())) * (xmax - xmin) + xmin","af564e04":"def cnn_model():\n    x_in = Input(shape=(28, 28, 1))\n    x = Conv2D(filters=64, kernel_size=2, padding='same', activation='relu')(x_in)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(0.3)(x)\n\n    x = Conv2D(filters=32, kernel_size=2, padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(0.3)(x)\n\n    x = Flatten()(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x_out = Dense(10, activation='softmax')(x)\n\n    cnn = Model(inputs=x_in, outputs=x_out)\n    cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    return cnn","d78421b6":"cnn = cnn_model()\ncnn.summary()\ncnn.fit(x_train, y_train, batch_size=64, epochs=3, verbose=0)\ncnn.save('mnist_cnn.h5')","decd1682":"cnn = load_model('mnist_cnn.h5')\nscore = cnn.evaluate(x_test, y_test, verbose=0)\nprint('Test accuracy: ', score[1])","36b5f056":"X = x_test[0].reshape((1,) + x_test[0].shape)\nplt.imshow(X.reshape(28, 28));","8cc6399a":"shape = (1,) + x_train.shape[1:] #reshaping according to batch dimension, which is here 1, so 1 column is added.\ntarget_proba = 1.0\ntol = 0.01 # tolerance - want counterfactuals with p(class)>0.99\ntarget_class = 'other' # any class other than the class of the test instance (here 7).\nmax_iter = 1000\nlam_init = 1e-1\nmax_lam_steps = 10\nlearning_rate_init = 0.1\nfeature_range = (x_train.min(),x_train.max())","68612046":"# initialize explainer\ncf = CounterFactual(cnn, shape=shape, target_proba=target_proba, tol=tol,\n                    target_class=target_class, max_iter=max_iter, lam_init=lam_init,\n                    max_lam_steps=max_lam_steps, learning_rate_init=learning_rate_init,\n                    feature_range=feature_range)\n\nstart_time = time()\nexplanation = cf.explain(X)\nprint('Explanation took {:.3f} sec'.format(time() - start_time))","f607355d":"#explanation.cf","6075d5a5":"pred_class = explanation.cf['class']\nproba = explanation.cf['proba'][0][pred_class]\n\nprint(f'Counterfactual prediction: {pred_class} with probability {proba}')\nplt.imshow(explanation.cf['X'].reshape(28, 28));","40de4e7f":"n_cfs = np.array([len(explanation.all[iter_cf]) for iter_cf in range(max_lam_steps)])\nexamples = {}\nfor ix, n in enumerate(n_cfs):\n    if n>0:\n        examples[ix] = {'ix': ix, 'lambda': explanation.all[ix][0]['lambda'],\n                       'X': explanation.all[ix][0]['X']}\ncolumns = len(examples) + 1\nrows = 1\n\nfig = plt.figure(figsize=(16,6))\n\nfor i, key in enumerate(examples.keys()):\n    ax = plt.subplot(rows, columns, i+1)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    plt.imshow(examples[key]['X'].reshape(28,28))\n    plt.title(f'Iteration: {key}')","5ed2da69":"target_class = 1\n\ncf = CounterFactual(cnn, shape=shape, target_proba=target_proba, tol=tol,\n                    target_class=target_class, max_iter=max_iter, lam_init=lam_init,\n                    max_lam_steps=max_lam_steps, learning_rate_init=learning_rate_init,\n                    feature_range=feature_range)\n\nexplanation = start_time = time()\nexplanation = cf.explain(X)\nprint('Explanation took {:.3f} sec'.format(time() - start_time))","57a6d30b":"pred_class = explanation.cf['class']\nproba = explanation.cf['proba'][0][pred_class]\n\nprint(f'Counterfactual prediction: {pred_class} with probability {proba}')\nplt.imshow(explanation.cf['X'].reshape(28, 28));","2fd1554f":"plt.imshow((explanation.cf['X'] - X).reshape(28, 28));","2b8a3ff4":"Counterfactuals provide the solution or changes in prediction to \u201cWhat if\u201d cases by showing feature-perturbed versions of the same cases. If X is an independent variable and Y is a dependent variable, counterfactual shows the effect on Y due to small changes in X. Also, it helps to calculate,what changes need to be done in X if the outcome Y is changed to Y'.","ad6e743f":"Calculate the error for evaluation of model","0bbb7cd0":"Now, we have specified the target class as 1 which means that for the outcome of model prediction to be 1, what are the changes in features(pixels here) required.","165dd726":"Scale, reshape and categorize(one-hot encoding) ","d9b0d9b1":"Load MNIST data","c88b8c9a":"Run counterfactual","b57b5a88":"Since counterfactual is a local explanation method, we focus on one particular instance i.e. index 0 of test data which is an image of handwritten 7 as shown below.","b2ebc6fb":"After changing the feature values to change 7 to 1, 1 is predicted with a probability of 0.997 which is almost equal to 1.\n\nThe image is less interpretable compared to the one in which it was allowed to go to the closest class possible since we have explicitly specified the class.","9f038de9":"Since the accuracy is 98%, the model is good.","4964713d":"Define and train CNN model","507a2d55":"Counterfactual parameters -\n\ntarget_proba: This is the probability required for the returned target class after applying counterfactual. \n\ntol: the tolerance within the target_proba, this is used to specify a range of acceptable predicted probability values for flexibility in target_proba.\n\ntarget_class: desired target class for the returned counterfactual instance. \n\nfeature_range: feature-wise min and max values for the perturbed instance.\n\nmax_iter, lam_init, max_lam_steps, learning_rate_init are all mathematical parameters used for the method.\n\nlearning_rate_init: initial learning rate\n\nlam_init: initial value of the hyperparameter \u03bb. \n\nmax_lam_steps: the number of steps (outer loops) to search for with a different value of \u03bb.","e30f89e5":"## Counterfactual instances on MNIST","ad9176c0":"The above image shows the difference between the counterfactual and the original instance. This helps in concluding that the counterfactual is removing the top part of the 7 to make to result in a prediction of 1 which is correct as the horizontal line when cut from 7 gives a slanting 1.","70a3548a":"A counterfactual explanation of a prediction describes the smallest change to the feature values that changes the prediction to a predefined output.\nHere, the counterfactual starting from a 7, makes changes in the pixels and moves towards the closest class in the data, that is in this case a 2. As required, the probability of the returned counterfactual is 0.99 which is quite high.","a6bb2e6b":"Generate counterfactuals","ad4656a6":"The transformation of 7 to 2 over several iterations is shown in the above image."}}