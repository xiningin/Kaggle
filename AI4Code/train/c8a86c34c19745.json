{"cell_type":{"7ede5ca2":"code","a704eb06":"code","5710f299":"code","f61d30b9":"code","324df06a":"code","9365bab8":"code","c3c703e9":"code","8385903f":"code","b9499bda":"code","bd0c39d6":"code","7610b674":"code","9d6a0305":"code","fb1200e5":"code","58e2bc5e":"code","1e694f21":"code","24bccff4":"code","d31c7eb8":"code","5056be2e":"code","aab0c119":"code","8540b013":"code","8cbd52da":"code","45a592cd":"code","c7b00f22":"code","fcfa890d":"code","25823dc6":"code","cc011286":"code","30370f58":"code","f11a0eda":"code","3e6797b9":"code","b55324c7":"code","6e8dcfcb":"code","8a8a2a73":"code","29582a1b":"code","8a2d29cf":"code","a157b6d7":"code","d674871d":"code","af073e93":"code","fcba8ae0":"code","7be14cd8":"code","531c6370":"code","f1294834":"code","b009989d":"code","6dfd5e04":"code","263f4e42":"code","a754cba4":"code","a7e2c336":"code","17d41524":"code","dd76542a":"code","0860207d":"code","db831083":"code","8643aabf":"markdown","b73506c9":"markdown","02df41c4":"markdown","1da9ca20":"markdown","73ee3e6c":"markdown","dc774dd9":"markdown","ce334cfb":"markdown","2fc1a4f6":"markdown","2b3f2ba2":"markdown","1839df34":"markdown","e1b191d2":"markdown"},"source":{"7ede5ca2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","a704eb06":"# import standard libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","5710f299":"import os\nprint(os.listdir(\"..\/input\/pokemon\"))","f61d30b9":"pokemon_df = pd.read_csv(\"..\/input\/pokemon\/pokemon.csv\")\n## from the columns, pick out the ones of type float64, int64, and objects\ndf2 = pokemon_df.select_dtypes(include = ['float64', 'int64'])\ndf3 = pokemon_df.select_dtypes(include = ['object'])","324df06a":"pokemon_df.info()","9365bab8":"df2.info()","c3c703e9":"## .head() grabs the first 5 elements from the dataframe\ndf3.head()","8385903f":"## .tail() grabs the last 5 elements from the dataFrame\ndf3.tail()","b9499bda":"## https:\/\/scikit-learn.org\/stable\/modules\/preprocessing.html\n## https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.LabelEncoder.html\n\n## changes raw feature vectors into a representation \n## that is more suitable for the downstream estimators\nfrom sklearn import preprocessing \n\n## from preprocessing, use LabelEncoder, we want to encode \n## labels with value between 0 and n_classes - 1\nle = preprocessing.LabelEncoder() \nlabels = le.fit_transform(pokemon_df['type1'])\nprint(len(le.classes_)) ## len() -> length, classes is number of classes\nprint(le.classes_) ## prints what those classes are from the labels","bd0c39d6":"## from the dataframe, based on types, plot the occurences \npokemon_df.type1.value_counts().plot.bar()\n\n## What if we wanted to know a specific value?\npokemon_df.type1.value_counts() ","7610b674":"## As you noticed flying type Pokemon seem low, why?\n## Recall there are type1 and type2, let's look at type 2\npokemon_df.type2.value_counts()\npokemon_df.type2.value_counts().plot.bar()","9d6a0305":"## Now there's a lot more flying types, so let's combine them\npokemon_df.type1.value_counts() + pokemon_df.type2.value_counts()\n\n## and the accurate plot, keep in mind not every pokemon has 2 types\n(pokemon_df.type1.value_counts() + pokemon_df.type2.value_counts()).plot.bar()","fb1200e5":"## Note: you cannot simply add up all the frequencies since \n## not every Pokemon has 2 types, be careful with the data","58e2bc5e":"## Alternatively you can do this\nfig = plt.figure(figsize=(15,15)) ## figsize=(width, height)\nfig.add_subplot(211) # subplot(nrows, ncols, index)\n\n## autopct: used to label the wedges with their numeric value; \n## the label will be placed inside the wedge\n## pctdistance: the ratio between the center of each pie slice \n## and the start of the text generated by autopct\npokemon_df['type1'].value_counts().plot(kind = 'pie', \n                                       autopct = '%1.1f%%', \n                                       pctdistance = 0.9)\n\nplt.show()","1e694f21":"fig = plt.figure(figsize=(15,15))\nfig.add_subplot(212)\npokemon_df['type2'].value_counts().plot(kind = 'pie', \n                                       autopct = '%1.1f%%',\n                                       pctdistance = 0.9)","24bccff4":"## Other things we can look into, in no particular order\n## The frequency of Pokemon (y) vs HP stat total:\npokemon_df.hp.value_counts().sort_index().plot.line()","d31c7eb8":"## Frequency with weight\npokemon_df.weight_kg.plot.hist()","5056be2e":"## this is super important otherwise, later logistic regression \n## will throw an error could not convert string to float: 'None'\npokemon_df['type2'].fillna(value='None', inplace=True) ","aab0c119":"plt.subplots(figsize=(10, 10))\n\nsns.heatmap(\n    pokemon_df[pokemon_df['type2'] != 'None'].groupby(['type1', 'type2']).size().unstack(),\n    linewidths = 1,\n    annot = True,\n    cmap = \"Blues\" # color\n)\n\n# plt.xticks(rotation = 35)\nplt.show()","8540b013":"# Produce a list of unique abilities across all Pokemon    \nabilitiesList = []\nfor n in range(len(pokemon_df.abilities)):\n    for ability in pokemon_df.abilities.iloc[n]:\n        if ability not in abilitiesList:\n            abilitiesList.append(ability)\n            \nprint('Number of unique abilities: ', len(abilitiesList))","8cbd52da":"## Suppose you want to know how effective certain types are to one another\n\ndata = {\n    'attack': pokemon_df['attack'],\n    'defense': pokemon_df['defense'],\n    'sp_attack': pokemon_df['sp_attack'],\n    'sp_defense': pokemon_df['sp_defense'],\n    'type2': pokemon_df.type2,\n    'type1': pokemon_df['type1']\n}\ndata = pd.DataFrame(data)\n## look for columns with 'against' and join them\ndata = pokemon_df.filter(like='against').join(data) \n\nX = data.drop('type1', axis=1)\ny = data['type1']\nprint(list(X))\nX\n\n## Note you can can also generate a heatmap","45a592cd":"# Fix capture rate for Minior, then convert data to numeric\npokemon_df.capture_rate.iloc[773] = 255  \npokemon_df.capture_rate = pd.to_numeric(pokemon_df.capture_rate)","c7b00f22":"# print('Number of samples = number of Pokemon = ', pokemon_df.shape[0])\n\n# Processing Ability data\n# Ability data is in a single string format: \"['Ability1','Ability2']\"\n# Change it to a list of strings\ndef abilities_to_list(abil):\n    abil_ = abil.replace(' ','')\n    abil_ = abil_[2:-2].split(\"','\")\n    return abil_\n\n# Cycle through ability data and transform it to list of string format\n# Note: this step is slow\nfor n in range(len(pokemon_df.abilities)):\n    pokemon_df.abilities.iloc[n] = abilities_to_list(pokemon_df.abilities.iloc[n])\n            \n# Create a new dataframe containing the relevant information            \ndfAbilities = pokemon_df.loc[:,['pokedex_number','name','abilities','type1','type2']]\nfor n in range(len(dfAbilities.abilities)):\n    dfAbilities.abilities.iloc[n] = \" \".join(dfAbilities.abilities.iloc[n])","fcfa890d":"from pylab import ceil\n\n# Define a function that splits our dataframe randomly into \n# train and test sets        \ndef train_test_split_manual(pokemon_df, split=0.9):\n    n_samples = pokemon_df.shape[0]\n    n_test = int(ceil(split*n_samples))\n    indices = np.random.permutation(n_samples)\n    X_train = pokemon_df.iloc[indices[:n_test]]\n    X_test = pokemon_df.iloc[indices[n_test:]]\n    return X_train, X_test\n    \n# Set the random seed so the results are the same each time we run this kernel\nnp.random.seed(801)\n# Split the data\nX_train, X_test = train_test_split_manual(dfAbilities)","25823dc6":"# Feature Extration: Build dictionary of features from Abilities\n# CountVectorizer creates sparse matrices of \n# counts of each word in the dictionary\nfrom sklearn.feature_extraction.text import CountVectorizer\ncount_vect = CountVectorizer()\n\nX_train_counts = count_vect.fit_transform(X_train.abilities.values)          \n\n# Apply tf-idf downscaling since some Pokemon have more abilities than others\nfrom sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n# Check the shape of the feature array\nprint(X_train_tfidf.shape)","cc011286":"# Try to predict a pokemon's type1 and type2 from its abilities\n# Use a Naive Bayes classifier\nfrom sklearn.naive_bayes import MultinomialNB\n\n# Fit the classifier to Type 1 training data:\nclassifier = MultinomialNB().fit(X_train_tfidf, X_train.type1.values)\n\n# Transform the testing set to sparse feature matrices of counts\nX_test_counts = count_vect.transform(X_test.abilities.values)\nX_test_tfidf = tfidf_transformer.transform(X_test_counts)\n\npredicted = classifier.predict(X_test_tfidf)\n# Check the fraction of correct predictions\nprint(\"Fraction of correct predictions: Abilities predicting Type 1:\")\nprint(predicted[predicted == X_test.type1.values].shape[0], '\/', predicted.shape[0])\nprint((predicted[predicted == X_test.type1.values].shape[0])\/float(predicted.shape[0]))","30370f58":"# Try the prediction WITHOUT tf-idf downscaling\nclassifier = MultinomialNB().fit(X_train_counts, X_train.type1.values)\npredicted = classifier.predict(X_test_counts)\n# Check the fraction of correct predictions\nprint(\"Fraction of correct predictions: Abilities predicting Type 1 without tf-idf:\")\nprint(predicted[predicted == X_test.type1.values].shape[0], '\/', predicted.shape[0])\nprint((predicted[predicted == X_test.type1.values].shape[0])\/float(predicted.shape[0]))","f11a0eda":"# Fit the classifier to Type 2 training data:\n# Preprocess type 2 data, since it contains null values when Pokemon\n# have only one type and has mixed datatypes\ntype2 = np.array([str(value) for value in X_train.type2.values])\nindices = type2 != 'nan'\nclassifier = MultinomialNB().fit(X_train_counts[indices], type2[indices])\ntype2_test = np.array([str(value) for value in X_test.type2.values])\nindices_test = type2_test != 'nan'\npredicted = classifier.predict(X_test_counts[indices_test])\n\n# Check the fraction of correct predictions\nprint(\"Fraction of correct predictions: Abilities predicting Type 2 without tf-idf:\")\nprint((predicted[predicted == type2_test[indices_test]].shape[0])\/float(predicted.shape[0]))","3e6797b9":"## Let's first see how many there are\n\nfig = plt.figure(figsize=(7,7))\n\ncolors = [\"aqua\", \"orange\"]\npokeLeg = pokemon_df[pokemon_df['is_legendary'] == True]\npokeNon = pokemon_df[pokemon_df['is_legendary'] == False]\n\nlegDist = [pokeLeg['name'].count(), pokeNon['name'].count()]\nlegPie = plt.pie(legDist,\n                 labels= ['Legendary', 'Non Legendary'], \n                 autopct ='%1.1f%%', \n                 shadow = True,\n                 colors = colors,\n                 startangle = 45,\n                 explode=(0, 0.1))","b55324c7":"## correlation between legendary pokemon and non-legendary per generation\ncolors = [\"aqua\", \"orange\"]\ng = sns.factorplot(\n    x='generation', \n    data=pokemon_df,\n    kind='count', \n    hue='is_legendary',\n    palette=colors, \n    size=5, \n    aspect=1.5,\n    legend=False,\n    ).set_axis_labels('Generation', '# of Pokemon')\n\ng.ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),  shadow=True, ncol=2, labels=['NON LEGENDARY','LEGENDARY'])\nplt.show()","6e8dcfcb":"## Not usually a good sign since there is not enough data on what is a legendary\n## Maybe there's a very strong correlation we can exploit\n## Method 1: High attack and defense correlation\n## Method 2: hasGender - legendaries typically don't\n## Method 3: Catch rate - legendaries have very low catch rate","8a8a2a73":"## I will show Method 1 because it goes back to reviewing linear regression\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\n\nX = pokemon_df[['attack']]\nY = pokemon_df[['defense']]\nmodel.fit(X, Y)\n\nY_pred = model.predict(X)\n\nplt.scatter(X, Y)\nplt.plot(X, Y_pred, color = 'red')\nplt.xlabel('Attack')\nplt.ylabel('Defense')\nplt.show()","29582a1b":"## there is another graph we can look at, called a hex graph, \n## which shows you where most of the points congregate\n## The number of hexagons in the x-direction is gridsize\npokemon_df.plot.hexbin(x='defense', y='attack', gridsize=15) ","8a2d29cf":"## So, is there a relationship between attack and is_legendary?\nsns.boxplot(x=pokemon_df.is_legendary, y=pokemon_df.attack)","a157b6d7":"## What about defense and is_legendary?\nsns.boxplot(x=pokemon_df.is_legendary, y=pokemon_df.defense)","d674871d":"## KDE Plot described as Kernel Density Estimate is used for \n## visualizing the Probability Density of a continuous variable.\n## Here is a representation of is_legendary with generations\ngrid = sns.FacetGrid(pokemon_df, col='is_legendary', row='generation')\ngrid.map(sns.kdeplot, 'attack')","af073e93":"sns.boxplot(x='generation', y='base_total', hue='is_legendary', data=pokemon_df)","fcba8ae0":"sns.lmplot(x='attack', y='defense', hue='is_legendary', fit_reg=False, data=pokemon_df, markers = ['x', 'o'])","7be14cd8":"## So it's not as strong as we would like it to be but it \n## turns out this is still a viable approach, let's incorporate it with\n## gender and catch rate\nleg = pokemon_df[pokemon_df['is_legendary'] == True]\npokemon_df['capture_rate'].set_value(773, '30')\n\n## does not sort capture_rate properly not sure why, isn't \n## needed anyways, just for visualization\n# plt.figure(figsize=(15,6))\n# plt.title(\"Catch rate of Pokemon\")\n# pokemon_df['capture_rate'].sort_values()\n# sns.scatterplot(x='pokedex_number', y='capture_rate', data=pokemon_df, hue='is_legendary')","531c6370":"leg_total = leg['base_total'].mean()\nnon_leg_total = pokemon_df[pokemon_df['is_legendary'] != True]['base_total'].mean()","f1294834":"pd.DataFrame([leg_total, non_leg_total], index=['Legendary', 'non-Legendary'], columns=['Average Total'])","b009989d":"isLegendary = pd.get_dummies(pokemon_df['is_legendary'], drop_first=True)\nlr_df = pokemon_df[['base_total', 'capture_rate']]\nlr_df = pd.concat([lr_df, isLegendary], axis=1)","6dfd5e04":"lr_df.columns = ['Base Total', 'Catch Rate', 'Is Legendary']\nlr_df.head()","263f4e42":"X = lr_df.drop('Is Legendary', axis = 1)\ny = lr_df['Is Legendary']","a754cba4":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) ","a7e2c336":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression()\nLR.fit(X_train, y_train)","17d41524":"pred = LR.predict(X_test)","dd76542a":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","0860207d":"# from sklearn.metrics import confusion_matrix\n# print(confusion_matrix(y_test,pred))","db831083":"from sklearn import tree\nfrom sklearn.model_selection import cross_val_score, KFold\nkfold = KFold(n_splits=10, random_state=48)\n\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X,y)\n\nresult = cross_val_score(clf, X, y, cv=kfold, scoring='accuracy')\n\nprint(result.mean())","8643aabf":"### From Bulbapedia : Legendary Pok\u00e9mon are a group of incredibly rare and often very powerful Pok\u00e9mon, generally featured prominently in the legends and myths of the Pok\u00e9mon world. \n\n### Can we predict whether or not a Pokemon is legendary?","b73506c9":"# 4. Other Pokemon Related Problems \/ Resources\n\nTrying to figure out what Pokemon you are (given an image of yourself, find a Pokemon that is most similar to you):\nhttps:\/\/www.kaggle.com\/kohlisaab\/pokemon-comparison\n\nHeat maps with various other measured data:\nhttps:\/\/www.kaggle.com\/jeru666\/my-pokemon-collection\n\nBeautiful Visualizations:\nhttps:\/\/www.kaggle.com\/xvivancos\/analyzing-a-pok-mon-data-set-my-first-kernel\n\nGenerate new Pokemon images data set:\nhttps:\/\/www.kaggle.com\/russellgeum\/dcgan-with-pokemon-high-resolution\n\nOther approaches to is_legendary (neural network, xgboost, tpot approach?):\nhttps:\/\/www.kaggle.com\/yassinealouini\/pokemons-machine-learning-101\n\nLearn pandas with Pokemon:\nhttps:\/\/www.kaggle.com\/ash316\/learn-pandas-with-pokemons\n\nIn depth Pokemon stats analysis:\nhttps:\/\/www.kaggle.com\/ndrewgele\/visualizing-pok-mon-stats-with-seaborn\n\nEven more models for predicting whether a Pokemon is legendary:\nhttps:\/\/adityavichare.wordpress.com\/2017\/09\/21\/predicting-legendary-pokemon-using-dataset-of-stats\/","02df41c4":"### We'll use 90% of our data to train the classifier, and the remaining 10% to test it. We need to randomize the order since Pokemon in the same evolution line usually have the same set of abilities.","1da9ca20":"# 4. Decision Trees Approach (Extra)","73ee3e6c":"### Some Pokemon doesn't have secondary type so they have NaN (null values) in the Type 2 column. Let's fill in the null values in the Type 2 column by replacing it with None","dc774dd9":"## Pokemon type combinations\n### We've already seen what is the most and least common type of Pokemon, it will be also interesting to see all the type combination of the Pokemon, note that we will not include Pokemon that doesn't have secondary type","ce334cfb":"### Conclusion: A Pokemon's 1st typing can be correctly predicted from its abilities alone abot 60% of the time, and its 2nd type 40% of the time.","2fc1a4f6":"### I encourage you to play around with the data and come up with possible questions you might want to ask, here are a few","2b3f2ba2":"# 3. Intro to Logistic Regression","1839df34":"# 1. Basic Visualization; preprocessing the data - simple analysis such as counting, filtering, cleaning the data, and some basic plotting techniques","e1b191d2":"# 2. Predicting a Pokemon's type from its abilities"}}