{"cell_type":{"6086ec7b":"code","54caa6f3":"code","c7572bbd":"code","24e93517":"code","ccde277b":"code","2961ab30":"code","57ea0373":"code","0d3bdac2":"code","19b3452c":"code","5e92691b":"code","71c21e87":"code","c8fb9940":"code","beb66faf":"code","f8861467":"code","7c18fbe0":"code","05b6878e":"code","71414883":"code","a00e1500":"code","60abc552":"code","09c82e04":"code","33d9e00c":"code","92910026":"code","3cdf49ae":"code","1618a936":"code","ce080a5e":"code","2973efef":"code","00b625cf":"code","ff51859a":"code","2b6daeed":"code","cddc8715":"code","8f855612":"markdown","0d25e367":"markdown","62dce091":"markdown","6a822fe7":"markdown","d144f7bf":"markdown","1067ca77":"markdown","63a4593f":"markdown","160d61f4":"markdown"},"source":{"6086ec7b":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport os","54caa6f3":"pm_train = pd.read_csv('\/kaggle\/input\/mlubairtest\/pm_train.csv')\npm_test = pd.read_csv('\/kaggle\/input\/mlubairtest\/pm_test.csv')\nweather = pd.read_csv('\/kaggle\/input\/mlubairtest\/weather.csv')","c7572bbd":"pm_train.head()","24e93517":"len(pm_train['station'].unique())","ccde277b":"len(pm_test['station'].unique())","2961ab30":"dfs = [pm_train, pm_test, weather]\nfor df in dfs:\n    df['date'] = pd.to_datetime(df['date'])\n    df['year_month'] = df['date'].dt.strftime('%Y-%m')","57ea0373":"train_count = pm_train.groupby(['year_month']).size().reset_index(name='counts')\ntest_count = pm_test.groupby(['year_month']).size().reset_index(name='counts')\nweather_count = weather.groupby(['year_month']).size().reset_index(name='counts')\n\ntrain_count.set_index('year_month',inplace=True)\ntest_count.set_index('year_month',inplace=True)\nweather_count.set_index('year_month',inplace=True)","0d3bdac2":"def time_series_graph(df, key='counts'):\n    fig, ax = plt.subplots(figsize=(15, 6))\n    \n    # Add x-axis and y-axis\n    ax.bar(df.index.values,\n           df[key])\n\n    ax.set(xlabel=\"Date\",\n           ylabel=key)\n\n    plt.xticks(rotation=90)\n    plt.show()","19b3452c":"# \u0421\u0443\u0440\u0433\u0430\u043b\u0442\u044b\u043d \u0434\u0430\u0442\u0430\u043d\u044b \u0445\u0443\u0432\u044c\u0434 \u0434\u0430\u0442\u0430\u043d\u044b \u043c\u04e9\u0440\u0438\u0439\u043d \u0442\u043e\u043e (\u0441\u0430\u0440\u0430\u0430\u0440)\ntime_series_graph(train_count)","5e92691b":"# \u0422\u0435\u0441\u0442\u0438\u0439\u043d \u0434\u0430\u0442\u0430\u043d\u044b \u0445\u0443\u0432\u044c\u0434 \u0434\u0430\u0442\u0430\u043d\u044b \u043c\u04e9\u0440\u0438\u0439\u043d \u0442\u043e\u043e (\u0441\u0430\u0440\u0430\u0430\u0440)\ntime_series_graph(test_count)","71c21e87":"# \u0426\u0430\u0433 \u0430\u0433\u0430\u0430\u0440\u044b\u043d \u0434\u0430\u0442\u0430\u043d\u044b \u0445\u0443\u0432\u044c\u0434 \u0434\u0430\u0442\u0430\u043d\u044b \u043c\u04e9\u0440\u0438\u0439\u043d \u0442\u043e\u043e (\u0441\u0430\u0440\u0430\u0430\u0440)\ntime_series_graph(weather_count)","c8fb9940":"# \u0425\u043e\u0442\u043e\u0434 \u0431\u0430\u0439\u0433\u0430\u0430 \u0431\u04af\u0445 \u0441\u0442\u0430\u043d\u0446\u044b\u043d \u0434\u0443\u043d\u0434\u0436\u0430\u0430\u0440 \u0434\u0430\u0442\u0430 \u0431\u044d\u043b\u0434\u044d\u0445.\ndef get_records(df):\n    data = df[['date' , 'type', 'aqi']]\n    data = data.fillna(0)\n    pv = pd.pivot_table(data, values='aqi', index=['date'], columns=['type'], aggfunc=np.mean)\n    records = pd.DataFrame(pv.to_records())\n    return records","beb66faf":"train_records = get_records(pm_train)\ntest_records = get_records(pm_test)\ntest_records.info()","f8861467":"temp = weather[['date', 'temperature']]\ntemp = temp.set_index('date')\ntemp.plot(figsize=(15,8), rot=90)\n","7c18fbe0":"# \u0417\u0430\u0440\u0438\u043c \u0446\u0430\u0433\u0443\u0443\u0434\u044b\u043d \u0434\u0430\u0442\u0430 \u0434\u0443\u0442\u0443\u0443 \u0442\u0443\u043b \u0434\u0443\u0442\u0443\u0443 \u0446\u0430\u0433\u0438\u0439\u043d \u043c\u04e9\u0440\u0438\u0439\u0433 \u043e\u0440\u0443\u0443\u043b\u0436 \u0438\u0440\u044d\u0445\ndef fill_date(df):\n    ranges = pd.date_range(df['date'].min(),df['date'].max(), freq='H')\n    filled = pd.DataFrame(ranges, columns= ['date']).merge(df, on=['date'], how='left')\n    return filled","05b6878e":"train_records_filled = fill_date( train_records)\ntest_records_filled = fill_date( test_records)\n\ntrain = pd.merge(train_records_filled, temp, on=['date'], how='left')\ntest = pd.merge(test_records_filled, temp, on=['date'], how='left')","71414883":"train[train['PM10'].isna()]","a00e1500":"train_inter = train.interpolate()\ntest_inter = test.interpolate()\nprint(train_inter[train_inter['PM10'].isna()])\ntrain_inter.head()","60abc552":"test_inter = test_inter.fillna(200)","09c82e04":"#\u0425\u044d\u0434 \u0434\u044d\u0445 \u0441\u0430\u0440, \u04e9\u0434\u04e9\u0440 \u043c\u04e9\u043d \u0446\u0430\u0433 \u043c\u0430\u0430\u043d\u044c \u0442\u043e\u043e\u0441\u043e\u043d\u0446\u0440\u044b\u043d \u0445\u044d\u043c\u0436\u044d\u044d\u043d\u0434 \u043d\u04e9\u043b\u04e9\u04e9\u043b\u0434\u04e9\u0433 \u0431\u0430\u0439\u0445 \u0431\u043e\u043b\u043e\u043c\u0436\u0442\u043e\u0439 \u0433\u044d\u0436 \u04af\u0437\u044d\u044d\u0434 date features \u0431\u044d\u043b\u0434\u044d\u0445\ndef set_date_features(df):\n    df['month'] = pd.DatetimeIndex( df['date']).month\n    df['dayofweek'] = pd.DatetimeIndex( df['date']).dayofweek\n    df['hour'] = pd.DatetimeIndex( df['date']).hour\n    return df","33d9e00c":"train_data = set_date_features(train_inter)\ntest_data = set_date_features(test_inter)","92910026":"columns = ['date','PM10', 'PM2.5' , 'temperature','month','dayofweek','hour']\ntrain = train_data[columns]\ntest = test_data[columns]","3cdf49ae":"# onehot encoding\ndef encoding(df):\n    df = df.drop(['date'], axis = 1) \n    df = pd.get_dummies(df, columns=['month'], prefix='month')\n    df = pd.get_dummies(df, columns=['hour'], prefix='hour')\n    df = pd.get_dummies(df, columns=['dayofweek'], prefix='dayofweek')\n    return df","1618a936":"train_encoded = encoding(train)\ntest_encoded = encoding(test)\nn_train_hours = int( 365 * 24 * 2 )\n\ntrain_data = train_encoded.values[:n_train_hours, :]\nvalid_data = train_encoded.values[n_train_hours:, :]\ntest_data = test_encoded.values\n\ntrain_X, train_y = train_data[:, 2:], train_data[:, 0:2]\nvalid_X, valid_y = valid_data[:, 2:], valid_data[:, 0:2]\ntest_X, test_y = test_data[:, 2:], test_data[:, 0:2]\n\ndates = test['date'].values","ce080a5e":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error","2973efef":"model = RandomForestRegressor(n_estimators=100,\n                              max_depth=3,\n                              random_state=10)\nmodel.fit(train_X, train_y) \ny_hat= model.predict(valid_X)\n\nprint('MSE On validation Data: {}'.format( np.sqrt(mean_squared_error(valid_y,y_hat))))","00b625cf":"y_hat= model.predict(test_X)","ff51859a":"dates = dates.reshape(len(dates),1)\n\nsub = np.concatenate((dates.astype(str), y_hat.astype(str)),axis=1)\ntmp = pd.DataFrame(sub, columns=['date', 'PM10','PM2.5'])\n\ntmp['date']= pd.to_datetime(tmp['date'])\npm25 = pm_test[pm_test['type']=='PM2.5']\npm10 = pm_test[pm_test['type']=='PM10']\n\nsub_pm25 = pd.merge(pm25, tmp, on=['date'], how='left')\nsub_pm10 = pd.merge(pm10, tmp, on=['date'], how='left')\n\nsubmission = pd.DataFrame(columns=['ID', 'aqi'])\nsubmission = submission.append(sub_pm25[['ID', 'PM2.5']].rename(columns={'PM2.5': 'aqi'}))\nsubmission = submission.append(sub_pm10[['ID', 'PM10']].rename(columns={'PM10': 'aqi'}))","2b6daeed":"submission = submission.sort_values(by=['ID'])\nsubmission.head()","cddc8715":"submission.to_csv('submission.csv', index=None)\nsubmission.info()","8f855612":"### \u042d\u043d\u0433\u0438\u0439\u043d linear model \u0442\u0443\u0440\u0448\u0438\u0445\\\ntime-series \u0434\u0430\u0442\u0430 \u0431\u044d\u043b\u0434\u0441\u044d\u043d \u0431\u0430\u0439\u0433\u0430\u0430 \u0442\u0443\u043b ARIMA \u0433\u044d\u0445 \u043c\u044d\u0442 \u0441\u0442\u0430\u043d\u0434\u0430\u0440\u0442 \u0430\u0440\u0433\u0430\u0447\u043b\u0430\u043b \u0431\u043e\u043b\u043e\u043d LSTM \u0431\u043e\u043b\u043e\u043d ConvLSTM \u0433\u044d\u0445 deep learning \u0441\u0443\u0443\u0440\u044c\u0442\u0430\u0439 \u043c\u043e\u0434\u0435\u043b\u0443\u0443\u0434\u044b\u0433 \u0442\u0443\u0440\u0448\u0438\u0436 \u04af\u0437\u044d\u044d\u0441\u044d\u0439 \u0433\u044d\u0436 \u0445\u04af\u0441\u044d\u0436 \u0431\u0430\u0439\u043d\u0430.  \n","0d25e367":"## \u0426\u0430\u0433 \u0431\u043e\u043b\u0433\u043e\u043d \u0441\u0430\u0440 \u0431\u043e\u043b\u0433\u043e\u043d\u0434 \u0445\u044d\u0440 \u0438\u0445 \u0445\u044d\u043c\u0436\u044d\u044d\u043d\u0438\u0439 \u0434\u0430\u0442\u0430 \u04e9\u0433\u04e9\u0433\u0434\u0441\u04e9\u043d \u0431\u0430\u0439\u0433\u0430\u0430\u0433 \u0448\u0430\u043b\u0433\u0430\u0445","62dce091":"### \u0426\u0430\u0433 \u0430\u0433\u0430\u0430\u0440\u044b\u043d \u043c\u044d\u0434\u044d\u044d\u043b\u043b\u044d\u044d\u0441 \u0437\u04e9\u0432\u0445\u04e9\u043d \u0442\u0443\u0445\u0430\u0439\u043d \u0446\u0430\u0433\u0438\u0439\u043d \u0442\u0435\u043c\u043f\u0435\u0440\u0430\u0442\u0443\u0440\u044b\u0433 feature \u0431\u043e\u043b\u0433\u043e\u043d \u0430\u0432\u0430\u0445\n\u042d\u043d\u044d \u0443\u0434\u0430\u0430\u0434 \u0434\u0430\u0442\u0430 \u043c\u0430\u0430\u043d\u044c \u0431\u0430\u0433\u0430 \u0442\u0443\u043b \u043d\u044d\u043c\u044d\u043b\u0442\u044d\u044d\u0440 \u0434\u0430\u0442\u0430 \u043e\u0440\u0443\u0443\u043b\u0436 \u0438\u0440\u044d\u0445\u0438\u0439\u0433 \u0434\u044d\u043c\u0436\u0438\u0436 \u0431\u0430\u0439\u0433\u0430\u0430.","6a822fe7":" ### missing data-\u0433 \u043d\u04e9\u0445\u04e9\u043d \u0433\u04af\u0439\u0446\u044d\u044d\u043d time-series \u0434\u0430\u0442\u0430 \u0431\u043e\u043b\u0433\u043e\u0445\n(https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.interpolate.html)","d144f7bf":"\u042d\u043d\u044d \u0443\u0434\u0430\u0430\u0434 \u0442\u044d\u043c\u0446\u044d\u044d\u043d \u043c\u0430\u0430\u043d\u044c \u0431\u0443\u0441\u0430\u0434 \u0442\u044d\u043c\u0446\u044d\u044d\u043d\u04af\u04af\u0434\u0442\u044d\u0439 \u0445\u0430\u0440\u044c\u0446\u0443\u0443\u043b\u0432\u0430\u043b \u0431\u043e\u0433\u0438\u043d\u043e \u0445\u0443\u0433\u0430\u0446\u0430\u0430\u043d\u0434 \u0431\u043e\u043b\u0436 \u0431\u0443\u0439 \u0442\u0443\u043b \u0438\u043b\u04af\u04af \u0445\u0443\u0440\u0434\u0430\u043d \u0442\u044d\u043c\u0446\u044d\u044d\u043d\u0434 \u043e\u0440\u043e\u043b\u04e9\u043e\u0445 \u0431\u043e\u043b\u043e\u043c\u0436\u0438\u0439\u0433 \u0434\u044d\u043c\u0436\u0438\u0445 \u04af\u04af\u0434\u043d\u044d\u044d\u0441 \u043c\u0430\u0448 \u044d\u043d\u0433\u0438\u0439\u043d data exploration \u0431\u043e\u043b\u043e\u043d baseline model \u043e\u0440\u0443\u0443\u043b\u0430\u0445\u0430\u0430\u0440 \u0448\u0438\u0439\u0434\u0441\u044d\u043d \u0431\u0438\u043b\u044d\u044d. \n\n\u042d\u043d\u044d notebook-\u043d\u044b \u0437\u043e\u0440\u0438\u043b\u0433\u043e: \u0410\u0433\u0430\u0430\u0440 \u0434\u0430\u0445\u044c \u043d\u0430\u0440\u0438\u0439\u043d \u0442\u043e\u043e\u0441\u043e\u043d\u0446\u043e\u0440 PM(Particulate Matter)2.5 \u0431\u043e\u043b\u043e\u043d PM10-\u043d \u0445\u044d\u043c\u0436\u044d\u044d\u0433 \u0442\u0430\u0430\u043c\u0430\u0433\u043b\u0430\u0445\\\n\n\u0414\u0430\u0440\u0430\u0430\u043b\u0430\u043b:\n* \u041e\u0439\u043b\u0433\u043e\u043c\u0436\u0442\u043e\u0439 \u0431\u0430\u0439\u0445 \u04af\u04af\u0434\u043d\u044d\u044d\u0441 \u0445\u043e\u0442\u043e\u0434 \u0431\u0430\u0439\u0433\u0430\u0430 \u0431\u04af\u0445 \u0441\u0442\u0430\u043d\u0446\u044b\u043d \u0434\u0443\u043d\u0434\u0436\u0430\u0430\u0440 training \u0434\u0430\u0442\u0430 \u0431\u044d\u043b\u0434\u044d\u0445.\n* \u0417\u0430\u0440\u0438\u043c \u0446\u0430\u0433\u0443\u0443\u0434\u044b\u043d \u0434\u0430\u0442\u0430 \u0434\u0443\u0442\u0443\u0443 \u0442\u0443\u043b missing data-\u0433 \u043d\u04e9\u0445\u04e9\u043d \u0433\u04af\u0439\u0446\u044d\u044d\u043d time-series \u0434\u0430\u0442\u0430 \u0431\u043e\u043b\u0433\u043e\u0445\n* \u042d\u043d\u0433\u0438\u0439\u043d linear regression \u043c\u043e\u0434\u0435\u043b \u0442\u0443\u0440\u0448\u0438\u0445\n* \u0422\u0430\u0430\u043c\u0430\u0433\u043b\u0430\u0441\u0430\u043d \u04af\u0440 \u0434\u04af\u043d\u0433 submission \u0444\u0430\u0439\u043b\u044b\u043d \u0444\u043e\u0440\u043c\u0430\u0442 \u0440\u0443\u0443 \u0448\u0438\u043b\u0436\u04af\u04af\u043b\u044d\u043d \u0445\u0430\u0434\u0433\u0430\u043b\u0430\u0445","1067ca77":"### Data preprocess","63a4593f":"### \u0422\u0430\u0430\u043c\u0430\u0433\u043b\u0430\u0441\u0430\u043d \u04af\u0440 \u0434\u04af\u043d\u0433 submission \u0444\u0430\u0439\u043b\u044b\u043d \u0444\u043e\u0440\u043c\u0430\u0442 \u0440\u0443\u0443 \u0448\u0438\u043b\u0436\u04af\u04af\u043b\u044d\u043d \u0445\u0430\u0434\u0433\u0430\u043b\u0430\u0445","160d61f4":"#### \u042d\u043d\u0434\u044d\u044d\u0441 \u0442\u0435\u0441\u0442\u0438\u0439\u043d \u0434\u0430\u0442\u0430 \u043c\u04e9\u043d continuous \u0431\u0438\u0448 \u0445\u044d\u0434 \u0445\u044d\u0434\u044d\u043d \u0445\u044d\u0441\u044d\u0433\u0442 \u0442\u0430\u0441\u0430\u0440\u0441\u0430\u043d \u0431\u0430\u0439\u0433\u0430\u0430\u0433 \u0445\u0430\u0440\u0436 \u0431\u043e\u043b\u043d\u043e. : [(2019-01, 2019-03), (2019-10, 2020-03), (2019-10, 2020-11)]"}}