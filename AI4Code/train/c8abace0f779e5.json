{"cell_type":{"03292228":"code","ae00108d":"code","95037da8":"code","a94cb27e":"code","59a976e2":"code","741a3484":"code","64554a34":"code","1fa30d67":"code","3c2a5c8d":"code","3e4be9bb":"code","8079e23c":"code","16cb17bd":"code","4ab180cd":"code","0697f065":"code","d962af95":"code","1549fbd1":"code","eacc4a78":"markdown","1942253f":"markdown","d703d44b":"markdown","8de4b43f":"markdown","e6a3fd17":"markdown","9678e7b7":"markdown","7ab314aa":"markdown","5af890cd":"markdown","d0b0189c":"markdown","de052c74":"markdown","5921e77d":"markdown","0ed87b9c":"markdown","29a1fcd2":"markdown","df8f6775":"markdown","f7142756":"markdown","29bf6da3":"markdown","6a06a223":"markdown","58b2fe8e":"markdown","013ecee9":"markdown","cbe5ba8e":"markdown","01ec93cf":"markdown","406cddfd":"markdown","a9d1de32":"markdown"},"source":{"03292228":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#import torch packages\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as f\nfrom torch.optim import Adam\n\n#Sklearn packages\nfrom sklearn.model_selection import train_test_split as TTS\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\n\n\n#Seaborn packages\nimport seaborn as sns\n#We can go ahead and set the seed\ntorch.manual_seed(1000)\nprint(\"done\")\n\n","ae00108d":"# we will set up the transformer\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n#In this transformer, we are basically going to store the dataset in a tensor and then normalize it on a scale from 0-1\n\n#now we can actually download the datasets and transform them using the transforms we composed\n\ntrainSet = torchvision.datasets.CIFAR10(root='.\/data', train = True, download = True, transform=transform)\n#now do the same with the test dataset\ntestSet = torchvision.datasets.CIFAR10(root='.\/data', train = False, download = True, transform=transform)\n\nprint(\"done\")\n#This is a list of the classes in their respective numerical label positions\nclasses = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']","95037da8":"#It seems that since we have used torchvision to download the dataset, we need to interact with the class to get images we want.\n#However, it is not possible to iterate over the dataset in its current state, so we must first use the dataloader\n\ntrainLoader = torch.utils.data.DataLoader(trainSet,batch_size=20000,shuffle=True, num_workers=2)\n\ntestLoader = torch.utils.data.DataLoader(testSet,batch_size=20000,shuffle=False, num_workers=2)\n\n#Now we can iterate over the train and test data\n\ndataiter = iter(trainLoader)\nimages, labels = dataiter.next()\n\n# plt.imshow(np.transpose(images[10,:,:,:].numpy(),(1,2,0)))\n# print(classes[labels[10].numpy()])\n\n\n\n#Now we can define a function that will get us random 10 images and their respective labels\ndef getRandomImages(data):\n    #here the data is the dataset that we want to pass in\n    \n    #we want to create a dataset that will essentially hold the random indicies\n    randomImages = []\n    \n    for i in range(0,10):\n        #we want to iterate through each of the classes\n        #Define a counter and initiate it at a random position\n        counter = np.random.randint(0,high=data.size()[0])\n        \n        #now we want to iterate through the labels dataset and find the index of a label \n        while counter <= data.size()[0]:\n            #while we can still iterate, we want to continue to iterate\n            if counter >= data.size()[0]:\n                #we want the counter to restart at the beginning\n                counter = 0\n            elif data[counter].numpy() == i:\n                #append the index\n                randomImages.append(counter)\n                break\n            else:\n                #we dont find a match and we aren't at the end of the dataset\n                counter += 1\n    return randomImages\n\n\n#Run the algo on the train data set\ntrainLabels = getRandomImages(labels)\n\ntestImages,testLabels = iter(testLoader).next()\n\n#Run the algo on the test data set \ntestLabels = getRandomImages(testLabels)\n\n#Now we can plot the images\n#however, we need to define another function that will plot the histogram\ndef GetHistograms(img, intensity_range):\n    #this subroutine was taken from the tutorial \n    #Which can be found here https:\/\/www.kaggle.com\/soroush361\/deeplearninginbme-firsttutorial\n    histograms = list()\n    for i in range(3):\n        hist, edge = np.histogram(img[:,:,i], bins=100, range=intensity_range)\n        edge = (edge[:-1] + edge[1:])\/2\n        histograms.append((edge, hist))\n    return histograms\n\n#this subroutine will display the image\n#this subroutine was taken from the training notebook and was modified\n#the training can be found here https:\/\/www.kaggle.com\/soroush361\/deeplearninginbme-firsttutorial\ndef MyDisplayFunction(trainImages,testImages,trainIdx, testIdx):\n    plt.figure(figsize=(12,22))\n    colors = ('Red', 'Green', 'Blue')\n    for row in range(0,9):\n        #We want to iterate over all the different classes\n        #Print the Training Image and its histogram\n        img = np.transpose(trainImages[trainIdx[row],:,:,:].numpy(),(1,2,0))\n        #Plot the image\n        plt.subplot(10,4,row * 4 +1)\n        plt.title('{} from the Training Dataset'.format(classes[row]))\n        plt.imshow(img)\n        plt.axis('off')\n        #Plot the histogram\n        plt.subplot(10,4,row * 4 +2)\n        plt.title('Histogram')\n        histograms = GetHistograms(img, (0.0, 1.0))\n        for i in range(3):\n            plt.plot(histograms[i][0], histograms[i][1], c=colors[i], label='Channel {0}'.format(colors[i]))\n            \n        #Print and plot the image and histogram for the Testing datset\n        \n        img = np.transpose(testImages[testIdx[row],:,:,:].numpy(),(1,2,0))\n        #plot the image\n        plt.subplot(10,4,row * 4 + 3)\n        plt.title('{} from the Testing Dataset'.format(classes[row]))\n        plt.imshow(img)\n        plt.axis('off')\n        #Plot the histogram\n        plt.subplot(10,4,row * 4 + 4)\n        plt.title('Histogram')\n        histograms = GetHistograms(img, (0.0, 1.0))\n        for i in range(3):\n            plt.plot(histograms[i][0], histograms[i][1], c=colors[i], label='Channel {0}'.format(colors[i]))\n        plt.xlabel('Intensity')\n        plt.ylabel('Abundance')\n        plt.legend()\n    plt.show()\nMyDisplayFunction(images,testImages,trainLabels, testLabels)","a94cb27e":"# I have figured out how to iterate through the individual values in the dataset, but now I know how to.\n#If you are seeing this I probably did not have enough time to go back and change the code from the previous part\n# However, I think it is probably better given that there are two layers randomization. However, the time and space complexity have\n#definitely taken a massive hit\n\n\n#now we can take a look at how to split the training dataset into a validation and training set\n#we will leave the testing set alone\ntraining, validation = TTS(range(len(trainSet)), test_size=0.5, train_size=None, random_state=2, shuffle=True)\n\n#with these indices, we can now create our new dataset\n#We want to use the same variable names, to not confuse ourselves\n\n#we will define a function that inputs indices, finds the element, and appends it to a lest and outputs it.\n#I couldn't get it to work like what they did in the tutorial\n\ndef extractDataset(idxList,fullDataset):\n    shuffled = []\n    #we want to create an empty list to hold our data in\n    for idx in idxList:\n        shuffled.append(fullDataset[idx])\n    return shuffled\n#now we can run this on our indecies from our TTS method above\nnewTrainSet = extractDataset(training,trainSet)\nvalidSet = extractDataset(validation, trainSet)\n\n\n#just want to make sure we indeed have a list of tuples\nprint(type(newTrainSet[0]))\nprint(type(validSet[0]))\n\n#we want to ensure we have an even 50-50 split between training and validation sets\nprint(len(newTrainSet))\nprint(len(validSet))\n\n\n\n\nbatchSize = 512 #Went with this as the batch size since 32 was taking much too long\n\n#Now we can load our data into a dataloader\ntrainLoader = torch.utils.data.DataLoader(newTrainSet,batch_size=batchSize,shuffle=True, num_workers=2)\ntestLoader = torch.utils.data.DataLoader(testSet,batch_size=batchSize,shuffle=False, num_workers=2)\nvalidLoader = torch.utils.data.DataLoader(validSet,batch_size=batchSize,shuffle=False, num_workers=2)\nprint(\"Data has been Loaded\")\n\n\n\n","59a976e2":"#we will create a function that will go and count the number of images in each dataset\ndef countType(dataSet):\n    #we will exploit the fact that the labels are already \n    \n    #we will create a count \n    count = [0] * 10\n    for item in dataSet:\n        count[item[1]] += 1\n    return count\n\n        \ntrainCounts = countType(newTrainSet)\nvalidCounts = countType(validSet)\ntestCounts  = countType(testSet)\n\n\n#Create the graph now\nplt.figure(figsize=(12,8))\nplt.title('CIFAR 10 data distribution')\nplt.xticks(range(10), labels=range(10))\nplt.xlabel('Number')\nplt.ylabel('Number of samples')\nplt.bar(classes, trainCounts, label='Train')\nplt.bar(classes, testCounts, label='Test', bottom=trainCounts)\nplt.bar(classes, validCounts, label='Validation',bottom = np.add(trainCounts,testCounts))\nplt.legend()\nplt.show()\n\n\n","741a3484":"# Formula to calculate shape as we go through layer by layer = [(X - F + 2P)\/S] + 1\n# Here,\n# X = Width \/ Height\n# F = Kernel size\n# P = Padding\n# S = Strides (default = 1)\n#this was taken from the first tutorial\n\n\n\n# We can define our own LeNet\nclass LeNet(nn.Module):\n    '''\n    This is an implementation of the LeNet architecture\n    6 conv ---> ReLu & MaxPool ---> 6 conv --> ReLu & MaxPool --> 16 conv --> flattening --> FC --> FC --> 10 FC --> softmax\n    '''\n    #define the init\n    def __init__(self):\n        #we want to ensure that we have initiated the nn.Module class correctly \n        super(LeNet,self).__init__()\n        #now we can create the parts of our neural net\n        \n        #the conv2d takes the folowing parameters (in channels, out channels, kernel size, stride)\n        self.conv1 = nn.Conv2d(3,6,5,1)#this was how it was defined in the link given\n        self.conv2 = nn.Conv2d(6,16,5,1)\n        \n        #For this to work at every layer we want stride and kernel size = 2 and 2x2 respectively for both MaxPool layers\n        #the inputs take the form (kernel size, stride)\n        self.maxPool1 = nn.MaxPool2d(2,2)\n        \n        \n        #############################################\n        #try to remove this one and see what happens\n        self.maxPool2 = nn.MaxPool2d(2,2)\n        #############################################\n        \n        \n        self.fc1=nn.Linear(16 * 5 * 5, 120)\n        self.fc2=nn.Linear(120,84)\n        self.fc3=nn.Linear(84,10)#the output\n        \n        \n    def forward(self,x):\n        #Put the pieces together and create the neural net\n        x = f.relu(self.conv1(x))\n        x = self.maxPool1(x)\n        x = f.relu(self.conv2(x))\n        x = self.maxPool2(x)\n        #Now we need to flatten our data\n        x = x.view(-1,16 * 5 *5)#this will flatten the data\n        #Now we can feed this into our Fully conected Layers\n        x = f.relu(self.fc1(x))\n        x = f.relu(self.fc2(x))\n        x = self.fc3(x)\n        #now we can output to our output layer and run it through out log softmax function \n        return x\n        \n        \nCNN = LeNet()#Create an instance of our model\n\n\n\n#we want to check if Cuda is available and if so send our model over to the gpu\nif torch.cuda.is_available():\n    CNN.cuda()\nprint(CNN)#just want to print to check to see if everything looks good\n\n","64554a34":"#create an instance of ADAM\n\nadamOptimizer = Adam(CNN.parameters(),lr = 0.0001)\nloss = nn.MSELoss()\nprint(\"Done\")","1fa30d67":"!mkdir MSELossModelSaves\n!ls","3c2a5c8d":"#set the number of Epochs\n\nEpochs = 200\n#create lists to hold the training and validation errors\ntrainingLoss = []\nvalidLoss = []\n\n#now we can run our training\nfor epoch in range(Epochs):\n    #We also want to store loss data between batches so that we can present them later\n    trainBatchLoss = []\n    validBatchLoss = []\n    #we want to use our dataloader for the training data\n    for batchIds, (trainImage, trainLabel) in enumerate(trainLoader):\n        if torch.cuda.is_available():\n            #We will make sure to utilize Cuda for faster training\n            #################TRAINING PHASE#######################\n            #we want to move our model to training mode\n            CNN.train()\n            #We want to one hot encode our labels\n            oneHotLabels = f.one_hot(trainLabel.cuda(),num_classes = 10)\n            oneHotLabels = oneHotLabels.type(torch.float)\n            #With that out of the way, we want to have our model make some predictions\n            \n            modelPredictions = CNN(trainImage.cuda())#we want to move our images to the GPU as well\n            \n            #now we want to calculate the loss and append it to the list\n            modelLoss = loss(modelPredictions.type(torch.float),oneHotLabels)#Again, we want to move it to the GPU\n            #now append it\n            trainBatchLoss.append(modelLoss.cpu().data.item())\n            #.cpu() moves the tensor to the CPU\n            #.data gets the tensor data in the CPU\n            #.item() gets the actual plain number from the item\n            #This is then appended to the list\n       \n            #Now we can start the back propogation process\n            #reset the optimizer's gradient\n            adamOptimizer.zero_grad()\n            \n            #Now we can backpropogate the loss\n            modelLoss.backward()\n            #Now we can update the parameters\n            adamOptimizer.step()\n            ########################Validation######################\n            #first set our model to eval mode\n            CNN.eval()\n            #we want to iterate through each batch similar to how we have done for the training set\n            for validBatchIdx, (validImages,validLabels) in enumerate(validLoader):\n                #We can run through each batch and find the predicted labels\n                \n                validImagePredictions = CNN(validImages.cuda())#We want to move this to cuda\n                \n                #Convert our data to one-hot data\n                validOneHotLabels = f.one_hot(validLabels, num_classes = 10)\n                validOneHotLabels = validOneHotLabels.type(torch.float)\n                \n                #Now we can calculate the loss\n                validModelLoss = loss(validImagePredictions.type(torch.float),validOneHotLabels.cuda())\n                \n                validBatchLoss.append(validModelLoss.cpu().data.item())#we are doing this for the same reason we did it above\n        else:\n            #We dont have a gpu, we will do the same as we did above, but without the Cuda calls\n            #################TRAINING PHASE#######################\n            #we want to move our model to training mode\n            CNN.train()\n            #We want to one hot encode our labels\n            oneHotLabels = f.one_hot(trainLabel,num_classes = 10)\n           \n            #With that out of the way, we want to have our model make some predictions\n            \n            modelPredictions = CNN(trainImage)\n            #now we want to calculate the loss and append it to the list\n            modelLoss = loss(modelPredictions.type(torch.float),oneHotLabels.type(torch.float))\n            #now append it\n            trainBatchLoss.append(modelLoss.cpu().data.item())\n            #.cpu() moves the tensor to the CPU\n            #.data gets the tensor data in the CPU\n            #.item() gets the actual plain number from the item\n            #This is then appended to the list\n       \n            #Now we can start the back propogation process\n            #reset the optimizer's gradient\n            adamOptimizer.zero_grad()\n            \n            #Now we can backpropogate the loss\n            modelLoss.backward()\n            #Now we can update the parameters\n            adamOptimizer.step()\n            ########################Validation######################\n            #first set our model to eval mode\n            CNN.eval()\n            #we want to iterate through each batch similar to how we have done for the training set\n            for validBatchIdx, (validImages,validLabels) in enumerate(validLoader):\n                #We can run through each batch and find the predicted labels\n                validImagePredictions = CNN(validImages)\n                \n                #Convert our data to one-hot data\n                validOneHotLabels = f.one_hot(validLabels,num_classes = 10)\n               \n                \n                #Now we can calculate the loss\n                validModelLoss = loss(validImagePredictions.type(torch.float),validOneHotLabels.type(torch.float))\n                \n                validBatchLoss.append(validModelLoss.cpu().data.item())#we are doing this for the same reason we did it above\n    # Here we want to store our loss data and our model\n    \n    #Store average loss for the epoch\n    trainingLoss.append(np.mean(trainBatchLoss))\n    validLoss.append(np.mean(validBatchLoss))\n    \n    #Now we can save our model in the folder we created above\n    torch.save(CNN.state_dict(),'.\/MSELossModelSaves\/MSECheckpointSaveEpoch_{}.pth'.format(epoch))\n    #Now we can print out our loss\n    print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, trainingLoss[-1], validLoss[-1]))","3e4be9bb":"plt.figure(figsize = (12,6))\nplt.plot(range(len(validLoss)),validLoss,label = 'Validation loss')\nplt.plot(range(len(trainingLoss)),trainingLoss,label = 'Training Loss')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\n","8079e23c":"# [Your code here for loading the best model, testing on the test set, and displaying the confusion matrix as well as the classification report]\n\n#Get the best model\nbestEpoch = np.argmin(validLoss)\nprint(\"The best Epoch is: {}\".format(bestEpoch))\n#Load it into our CNN\nstateDict = torch.load('.\/MSELossModelSaves\/MSECheckpointSaveEpoch_{}.pth'.format(bestEpoch))\nprint(\"State Dict {}\".format(stateDict.keys()))\n#Now we can load it to our model\nCNN.load_state_dict(stateDict)\n\n\n#Now we can test it on our model\ndef classifyImages(model,inputData):\n    #Here we want to take an input model and input data and return the classificiations for use later\n    #we want to put our CNN into eval mode again\n    CNN.eval()\n    labelPredicted = []\n    predictedLabelOneHot = model(inputData)\n    labelProbability, LabelIndex = torch.max(predictedLabelOneHot,dim = 1)#we choose dim = 1 since we actually want to find the max for each sample\n    \n    #now we need to convert the data into its item by stepping through many layers\n    for currentPrediction in LabelIndex:\n        labelPredicted.append(currentPrediction.detach().cpu().numpy().item())\n    \n    return labelPredicted\n\ndef findAccuracy(model,testLoader):\n    #now we want to use the dataloader to run our accuracy calculation\n    #create a variable to hold the accuracy score averaged over the entire dataset\n    accuracy = []\n    for batchIdx, (testImages,testLabels) in enumerate(testLoader):\n        if torch.cuda.is_available():\n            testPredictions = classifyImages(model,testImages.cuda())\n        else:\n            #cuda isn't available, we want to use the CPU\n            testPredictions = classifyImages(model,testImages)\n        #now we want to actually get the accuracy using the sklearn subroutine\n        accuracy.append(accuracy_score(testLabels,testPredictions))\n\n    return np.mean(accuracy)\n    \n\nprint(\"Accuracy: {}%\".format(findAccuracy(CNN,testLoader) * 100))\n\n#now, we can create a confusion matrix\n\n#create a function, similar to the one above that returns a list of predictions and their labels\ndef getPredictionsAndLabels(model,testLoader):\n    #we want to create a list of labels and a list of predicted labels\n    predictedLabels = []\n    labels = []\n    #we also want to store the image matrices for the next step\n    images = []\n    for batchIdx, (testImages,testLabels) in enumerate(testLoader):\n        if torch.cuda.is_available():\n            testPredictions=classifyImages(model,testImages.cuda())\n        else:\n            #cuda isn't available, we want to use the CPU\n            testPredictions = classifyImages(model,testImages)\n        for item in testLabels.cpu().numpy().tolist():\n            labels.append(item)\n        for predictions in testPredictions:\n            predictedLabels.append(predictions)\n        for im in testImages:\n            images.append(im)\n    return labels,predictedLabels,images\n\n#now we can plot our CM \nlabels, predictions,images = getPredictionsAndLabels(CNN,testLoader)\n\n\n\nCM = confusion_matrix(labels, predictions)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\":10})\nplt.ylim([0,10])\nplt.ylabel(\"True Labels\")\nplt.xlabel(\"Predicted Labels\")\n\n","16cb17bd":"# we can define a subroutine to do just this\n\n#we can use the output from the previous functions here\ndef plotFivePredictions(labels,images,predictions):\n    plt.figure(figsize = (12,14))\n    for i in range(5):\n        #we can generate a random index\n        idx = np.random.randint(len(images))\n        #find the image\n        img = np.transpose(images[idx].numpy(),(1,2,0))\n        #we will plot the image\n        plt.subplot(5,1,i +1)\n        plt.title('Actual label is {}, Predicted to be {} '.format(classes[labels[idx]],classes[predictions[idx]]))\n        plt.imshow(img)\n        plt.axis('off')\nplotFivePredictions(labels,images,predictions)","4ab180cd":"#We want to change up our model a bit as well, to include a softmax opperator\n# Formula to calculate shape as we go through layer by layer = [(X - F + 2P)\/S] + 1\n# Here,\n# X = Width \/ Height\n# F = Kernel size\n# P = Padding\n# S = Strides (default = 1)\n#this was taken from the first tutorial\n\n\n\n# We can define our own LeNet\nclass LeNet(nn.Module):\n    '''\n    This is an implementation of the LeNet architecture\n    6 conv ---> ReLu & MaxPool ---> 6 conv --> ReLu & MaxPool --> 16 conv --> flattening --> FC --> FC --> 10 FC --> softmax\n    '''\n    #define the init\n    def __init__(self):\n        #we want to ensure that we have initiated the nn.Module class correctly \n        super(LeNet,self).__init__()\n        #now we can create the parts of our neural net\n        \n        #the conv2d takes the folowing parameters (in channels, out channels, kernel size, stride)\n        self.conv1 = nn.Conv2d(3,6,5,1)#this was how it was defined in the link given\n        self.conv2 = nn.Conv2d(6,16,5,1)\n        \n        #For this to work at every layer we want stride and kernel size = 2 and 2x2 respectively for both MaxPool layers\n        #the inputs take the form (kernel size, stride)\n        self.maxPool1 = nn.MaxPool2d(2,2)\n        \n        \n        #############################################\n        #try to remove this one and see what happens\n        self.maxPool2 = nn.MaxPool2d(2,2)\n        #############################################\n        \n        \n        self.fc1=nn.Linear(16 * 5 * 5, 120)\n        self.fc2=nn.Linear(120,84)\n        self.fc3=nn.Linear(84,10)#the output\n        \n        \n    def forward(self,x):\n        #Put the pieces together and create the neural net\n        x = f.relu(self.conv1(x))\n        x = self.maxPool1(x)\n        x = f.relu(self.conv2(x))\n        x = self.maxPool2(x)\n        #Now we need to flatten our data\n        x = x.view(-1,16 * 5 *5)#this will flatten the data\n        #Now we can feed this into our Fully conected Layers\n        x = f.relu(self.fc1(x))\n        x = f.relu(self.fc2(x))\n        x = self.fc3(x)\n        #now we can output to our output layer and run it through out log softmax function \n        return f.log_softmax(x,dim = 1)\n        \n        \nCNN = LeNet()#Create an instance of our model\n\n\n\n#we want to check if Cuda is available and if so send our model over to the gpu\nif torch.cuda.is_available():\n    CNN.cuda()\nprint(CNN)#just want to print to check to see if everything looks good\n\n","0697f065":"!mkdir CrossEntropySaves\n!ls","d962af95":"#Now we can create our new training regimen\n#set the number of Epochs\n\nEpochs = 200\n#create lists to hold the training and validation errors\ntrainingLoss = []\nvalidLoss = []\n\n\nadamOptimizer = Adam(CNN.parameters(),lr = 0.005)\n\n\n#now we can run our training\nfor epoch in range(Epochs):\n    #We also want to store loss data between batches so that we can present them later\n    trainBatchLoss = []\n    validBatchLoss = []\n    #we want to use our dataloader for the training data\n    for batchIds, (trainImage, trainLabel) in enumerate(trainLoader):\n        if torch.cuda.is_available():\n            #We will make sure to utilize Cuda for faster training\n            #################TRAINING PHASE#######################\n            #we want to move our model to training mode\n            CNN.train()\n            #We dont need to one hot encode our labels\n\n            #With that out of the way, we want to have our model make some predictions\n            \n            modelPredictions = CNN(trainImage.cuda())#we want to move our images to the GPU as well\n            \n            #now we want to calculate the loss and append it to the list\n            modelLoss = f.cross_entropy(modelPredictions,trainLabel.cuda())#Again, we want to move it to the GPU\n            #now append it\n            trainBatchLoss.append(modelLoss.cpu().data.item())\n            #.cpu() moves the tensor to the CPU\n            #.data gets the tensor data in the CPU\n            #.item() gets the actual plain number from the item\n            #This is then appended to the list\n       \n            #Now we can start the back propogation process\n            #reset the optimizer's gradient\n            adamOptimizer.zero_grad()\n            \n            #Now we can backpropogate the loss\n            modelLoss.backward()\n            #Now we can update the parameters\n            adamOptimizer.step()\n            ########################Validation######################\n            #first set our model to eval mode\n            CNN.eval()\n            #we want to iterate through each batch similar to how we have done for the training set\n            for validBatchIdx, (validImages,validLabels) in enumerate(validLoader):\n                #We can run through each batch and find the predicted labels\n                \n                validImagePredictions = CNN(validImages.cuda())#We want to move this to cuda\n                \n                #Now we can calculate the loss\n                validModelLoss = f.cross_entropy(validImagePredictions,validLabels.cuda())\n                \n                validBatchLoss.append(validModelLoss.cpu().data.item())#we are doing this for the same reason we did it above\n        else:\n            #We dont have a gpu, we will do the same as we did above, but without the Cuda calls\n            #################TRAINING PHASE#######################\n            #we want to move our model to training mode\n            CNN.train()\n           \n            #With that out of the way, we want to have our model make some predictions\n            \n            modelPredictions = CNN(trainImage)\n            #now we want to calculate the loss and append it to the list\n            modelLoss = f.cross_entropy(modelPredictions,trainLabels)\n            #now append it\n            trainBatchLoss.append(modelLoss.cpu().data.item())\n            #.cpu() moves the tensor to the CPU\n            #.data gets the tensor data in the CPU\n            #.item() gets the actual plain number from the item\n            #This is then appended to the list\n       \n            #Now we can start the back propogation process\n            #reset the optimizer's gradient\n            adamOptimizer.zero_grad()\n            \n            #Now we can backpropogate the loss\n            modelLoss.backward()\n            #Now we can update the parameters\n            adamOptimizer.step()\n            ########################Validation######################\n            #first set our model to eval mode\n            CNN.eval()\n            #we want to iterate through each batch similar to how we have done for the training set\n            for validBatchIdx, (validImages,validLabels) in enumerate(validLoader):\n                #We can run through each batch and find the predicted labels\n                validImagePredictions = CNN(validImages)\n\n               \n                \n                #Now we can calculate the loss\n                validModelLoss = f.cross_entropy(validImagePredictions,validLabels)\n                \n                validBatchLoss.append(validModelLoss.cpu().data.item())#we are doing this for the same reason we did it above\n    # Here we want to store our loss data and our model\n    \n    #Store average loss for the epoch\n    trainingLoss.append(np.mean(trainBatchLoss))\n    validLoss.append(np.mean(validBatchLoss))\n    \n    #Now we can save our model in the folder we created above\n    torch.save(CNN.state_dict(),'.\/CrossEntropySaves\/CrossEntropyCheckpointSaveEpoch_{}.pth'.format(epoch))\n    #Now we can print out our loss\n    print(\"Epoch: {} | train_loss: {} | validation_loss: {}\".format(epoch, trainingLoss[-1], validLoss[-1]))","1549fbd1":"# we can load the best epoch's model\n\n#Get the best model\nbestEpoch = np.argmin(validLoss)\nprint(\"The best Epoch is: {}\".format(bestEpoch))\n#Load it into our CNN\nstateDict = torch.load('.\/CrossEntropySaves\/CrossEntropyCheckpointSaveEpoch_{}.pth'.format(bestEpoch))\nprint(\"State Dict {}\".format(stateDict.keys()))\n#Now we can load it to our model\nCNN.load_state_dict(stateDict)\n\n#We can now find the accuracy of our data using the method created before\n\n\n##############################take this one out#############################\n#Now we can test it on our model\ndef classifyImages(model,inputData):\n    #Here we want to take an input model and input data and return the classificiations for use later\n    #we want to put our CNN into eval mode again\n    CNN.eval()\n    labelPredicted = []\n    predictedLabelOneHot = model(inputData)\n    labelProbability, LabelIndex = torch.max(predictedLabelOneHot,dim = 1)#we choose dim = 1 since we actually want to find the max for each sample\n    \n    #now we need to convert the data into its item by stepping through many layers\n    for currentPrediction in LabelIndex:\n        labelPredicted.append(currentPrediction.detach().cpu().numpy().item())\n    \n    return labelPredicted\n\ndef findAccuracy(model,testLoader):\n    #now we want to use the dataloader to run our accuracy calculation\n    #create a variable to hold the accuracy score averaged over the entire dataset\n    accuracy = []\n    for batchIdx, (testImages,testLabels) in enumerate(testLoader):\n        if torch.cuda.is_available():\n            testPredictions = classifyImages(model,testImages.cuda())\n        else:\n            #cuda isn't available, we want to use the CPU\n            testPredictions = classifyImages(model,testImages)\n        #now we want to actually get the accuracy using the sklearn subroutine\n        accuracy.append(accuracy_score(testLabels,testPredictions))\n\n    return np.mean(accuracy)\n\nprint(\"Accuracy: {}%\".format(findAccuracy(CNN,testLoader) * 100))\n\n\n\n\n\n\n\n# we can create a confusion matrix the same way we did before\n#we will use the subroutine that we had already created\n\nlabels, predictions,images = getPredictionsAndLabels(CNN,testLoader)\n\n\n\nCM = confusion_matrix(labels, predictions)\n\nplt.figure(figsize = (12,10))\nsns.heatmap(CM, annot = True, annot_kws = {\"size\":10})\nplt.ylim([0,10])\nplt.ylabel(\"True Labels\")\nplt.xlabel(\"Predicted Labels\")","eacc4a78":"### 6. (5 pts.) Display the number of samples for each class in the train, validation, and test sets as a stacked bar plot similar to the '[FirstTutorial](https:\/\/www.kaggle.com\/soroush361\/deeplearninginbme-firsttutorial)'.","1942253f":"### 11. (10 pts.) Load the model's weights at the best epoch and test your model performance on the test set. Display the confusion matrix and classification report.","d703d44b":"### 3. (5 pts.) Load train and test sets using Pytorch datasets functions.\nMake sure the intensity range is between $[0, 1]$ and images are stored as 'tensor' type. \nYou may use transformers while downloading the dataset to do the job. Look at this tutorial: [Pytorch CIFAR10](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html))","8de4b43f":"# Criteria for Best Epoch\n\nThe criteria for choosing the best epoch is to choose the one with the smallest validation loss (highest accuracy). The validation loss is specficially consulted becuase it will allow us to ensure that our model isn't overfitting the data (which might be the case if we instead chose to consult the training loss). We can write a quick script to automatically load the epoch with the lowest validation loss below.","e6a3fd17":"## Explain the Hyperparameters\n\nBased on the architecture, we can see that the following decisions hyperparemeters were set\n\nNumber of layers, not including input = 5\n\nStride in MaxPool Layers = 2\n\nKernel size in Convolutional Layers = 5\n\nKernel size in MaxPool layers = 2\n\nNumber of fully conected layers not including output layer = 2\n\nNumber of Kernals in each Convolutional Layer = 6 and 16\n\nUse of ReLu = once per layer (Except for the final output layer)\n\nUse of log Softmax function = on the output\n\nPadding in all the layers = No Padding in any layers\n\nBatch size in the training set = 1000\n\nNumber of images to train the model on = 25000\n\nChoice of optimizer and its learning rate = Adam and 0.001\n\nChoice of loss function = MSE\n\n## Activation Function\nAs mentioned in the previous section as well as the code above, the primary activation function that was used was the ReLu activiation function as it is generally accepted as the standard in terms of activation functions. The output of the final FC layer (the one with 10 nodes) was run through logSoftMax function in order to normalize the output in terms of percentages which can then be used to compute loss.\n\n## Tensor Shapes\n\nThe tensors will take the form of (Number of Samples in the Batch Size, Number of nodes(Kernals, FC neurons, etc.) in the layer, Image Width\/Height, Image Height\/Width). When the tensor is flattened, then it will take the form (Batch Size, 6 * 5 * 5), where the image has dimensions of 5x5 and there are 6 of them in the layer. We use a -1 in order to account of varying batch sizes, which in our case is 32 as we had defined in our dataloader.\n\n\n","9678e7b7":"### 5. (5 pts.) Split up the train set into new train and validation sets so that the number of samples in the validation set is equal to the number of samples in the test set. Then create a [```DataLoader```](https:\/\/pytorch.org\/docs\/stable\/data.html#torch.utils.data.DataLoader) for each set, including the test set, with a batch size of 32.\nThe [Pytorch CIFAR10](https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html) tutorial will also help you here.\nMake sure none of the samples in the validation set exists in the new train set.","7ab314aa":"### 9. (15 pts.) Train the model for 200 epochs using the train set and validate your model's performance at the end of each epoch using the validation sets.\nTo increase the training speed, use the GPU accelerator.\nLook at the '[FirstTutorial](https:\/\/www.kaggle.com\/soroush361\/deeplearninginbme-firsttutorial)' for more help.\nDo not forget to save the model at the end of each epoch.","5af890cd":"### 4. (10 pts.) Using the 'matplotlib' library, make a figure with $N\\times4$ grid cells where $N$ is the number of classes. Display one random sample of each class pulled from the train set in its corresponding row that depends on its class index and the first column and its histogram in the second column. Repeat this for the third and fourth columns but pull images from the test set.","d0b0189c":"## Cross-Entropy Model Performance\n\nWe can see that this model with the modifications such as the learning rate and error function, but under the same training regime does in fact do better than the previous model which used MSE as its loss calculation algorithm. It was theoretically clear why Cross-entropy is a much better fit for classification problems (compared to MSE), but given the results it is clear that the theoretical underpinnings does indeed translate to real world model performance. However, we can see that the improvement is only minimal which could be a result of the bigger learning rate used in the cross-entropy model\n\n\nOverall, this was a very fun project to spend my weekend on and I certainly learned a lot implementing the various ideas and concepts that have been discussed in class while figuring out where to look in the documentation (for all the libraries that were used in this project) to find answers on how to use certain subroutines, data structures, among other things. I hope this experience will equip me well for not only our upcoming final project but beyond. \n\n\nI look forward to hopefully implementing more complex CNNs, RNNs, and even GANs in the future.\n\nThank you\n\nAdi Shastry\n\n","de052c74":"### 1. (5 pts.) According to the [CIFAR10](http:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) dataset descriptions and other online resources, please identify the quantities below:\n\na) Total Number of samples \\\nb) Number of classes \\\nc) Image size \\\nd) Write class names and their corresponding label index (e.g., 0. cats, 1. dogs, ...) \\\ne) Intensity range","5921e77d":"\n## Adam Optimizer\n\nThe Adam optimizer is an optimizer that essentially calculates new learning rates based on a running exponential average of the previous gradients and the square of previous gradients. This allows the algorithm to choose different learning rates along the way to hopefully find a minimum in the error surface. The idea is similar to using a parameter like momentum, which basically takes a portion of the previous gradient and  includes it in the next step (This parameter would have to be coded and updated through trial and error to get better results). The idea behind Adam and other such algorithms that use this concept of a momentum is to give the optimizer (and subsequently the model) a chance to get out of a local minima (and finda. global minima instead). For example, the model might find itself on a saddle point in the error surface and because the gradient would effectively be zero, it would stop moving. In this case, if the optimizer were able to change the learning rate based on the previous movements, it could effectively \"get itself out\" of the local minima. If in fact the optimizer is at a global maxima, then over time the Adam algorithm (and others like it) would decrease the movement along the gradient and finally settle in the global maxima.\n\n## Mean Squared Error\n\nThis is a fairly simple algorithm in that it will find the average difference from the true value across all of the outputs of the model. It is important to notice that since no square root is taken, the algorithm punishes bigger mistakes a lot more than smaller mistakes (which is exactly what we want in general). However becuase of the way it is set up, it will punish the model for any value greater than zero in classes we don't actually care about. The cross-entropy solves this by only looking at the probability of the model in the label we are concerned with predicting. For example, the MSE will calculate a rather large error even if the model has a very high output (compared to other positions) in the true position such as in the example below (Assume the probabilities add up to 1)\n\n$$\n\\begin{bmatrix}\n.99\\\\\n.001\\\\\n\\vdots\n\\end{bmatrix}\n$$\n\nWhereas the cross-entropy loss function would not punish the model as much since it will only be concerned with the $0.99$ entry. This, from what I have understood from my own research, is why the cross-entropy loss function is the most widely used loss function for image classification tasks, whereas the MSE is used almost exclusively for regression problems.","0ed87b9c":"# Deep Learning in Biomedical Engineering","29a1fcd2":"### 10. (5 pts.) Display the learning curve and illustrate the best epoch. Explain your criteria for the best epoch.\nThe learning curve shows the model's loss and accuracy at the end of each epoch for all epochs (200 epochs). The criteria for the best epoch can be the minimum loss or maximum accuracy or other criteria.","df8f6775":"### 2. (0 pts.) Import the required packages in the following code block. \nYou can always come back here and import another package; please keep them all in the following block to make your code well-organized.","f7142756":"## Introduction\nIn this assignment, you will implement, train, and test [LeNet](https:\/\/en.wikipedia.org\/wiki\/LeNet) model to classify [CIFAR10](http:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) dataset.\n\n## Instructions\nDepending on each question, there are empty blocks you need to fill. The code blocks are only for Python codes and comments and currently have a comment like ```# [Your code here]```. The markdown blocks are only for plain or laTex text that you may use for answering descriptive questions. Currently, the markdown blocks have a comment like <font color='red'>[your answer here]<\/font>. Please remove the comments before filling the blocks. You can always add more blocks if you need to, or it just makes your answers well-organized.\n\nAlthough you may use other available online resources (such as GitHub, Kaggle Notebooks), it is highly recommended to try your best to do it yourself. If you are using an online code or paper, make sure you cite their work properly to avoid plagiarism. Using other students' works is absolutely forbidden and considered cheating.\n\nWrite comments for your codes in the big picture mode. One comment line at the top of each code block is necessary to explain what you did in that block. Don't comment on every detail.\n\nName your variables properly that represent the data they are holding, such as ``` test_set = ..., learning_rate = ...``` not ```a = ..., b = ...```.\n\nImplementing and reporting results using other architectures than LeNet will grant you an extra 20% on grade.\n\nIn this [Kaggle Notebook](https:\/\/www.kaggle.com\/roblexnana\/cifar10-with-cnn-for-beginer), you may find useful information about how your outputs must look. Just remember, they are using a different architecture, and they are using TensorFlow for implementations.\n\n\n## How to submit:\nAfter you have completed the assignment: \n1. Save a version (You can use 'Quick Save' to avoid re-running the whole notebook)\n2. Make the saved version public (Share -> Public)\n3. Copy the 'Public URL'\n4. Download your completed notebook as a '.ipynb' file (File -> Download)\n5. Upload the 'Public URL' and the '.ipynb' files on the [CourseWorks](https:\/\/courseworks2.columbia.edu\/).","29bf6da3":"### 7. (10 pts.) According to the LeNet architecture below, create a fully-connected model. Also, identify the architeture's hyper-parameters, activation functions, and tensor shapes.\nArchitecture hyper-parameter includes the number of layers, number of kernels in each layer, size of the kernels, stride, zero-padding size. Just by looking at the architecture itself, you should be able to identify the hyper-parameters. Keep in mind that you identified the $W, H$, and $N$ (Which refers to the number of classes) in the first question.\nFor more help, look at this [implementation](https:\/\/github.com\/icpm\/pytorch-cifar10\/blob\/master\/models\/LeNet.py).\n![LeNet Architecture](https:\/\/raw.githubusercontent.com\/soroush361\/DeepLearningInBME\/main\/Ass1_Arch1.png)","6a06a223":"## Assignment 2\n### Due date:<font color='red'> 11:59 pm, Febraury 25, 2021<\/font>","58b2fe8e":"### 8. (5 pts.) Create an instance of [ADAM optimizer](https:\/\/pytorch.org\/docs\/stable\/optim.html#torch.optim.Adam) with an initial learning rate of $0.0001$ and an instance of [Mean Squared Error (MSE)](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.MSELoss.html#torch.nn.MSELoss) loss function. Briefly explain the ADAM optimizer algorithm and the MSE loss function.\nFor ADAM optimizer, keep other arguments as default. \n\nFor your information, here is the mathematics behind the ADAM optimizer: \\\nFor each parameter $w^j$\n$$\nv_t = \\beta_1v_{t-1}-(1-\\beta_1)g_t \\\\\ns_t = \\beta_2s_{t-1}-(1-\\beta_2)g_t^2 \\\\\n\\Delta w^j = -\\eta\\frac{v_t}{\\sqrt{s_t+\\epsilon}}g_t \\\\\nw^j_{t+1} = w^j_t+\\Delta w^j\n$$\nWhere $\\eta$ is the initial learning rate, $g_t$ is the gradient at time $t$ along $w^j$, $v_t$ is the exponential average of gradients along $w^j$, $s_t$ is the exponential average of squares of gradients along $w^j$, $\\beta_1, \\beta_2$ are the hyper-parameters, and $\\epsilon$ is a small number to avoid dividing by zero.\n\nThe MSE loss function is:\n$$\nL(y,\\hat{y}) = \\frac{1}{N}\\sum_{i=1}^N{(y_i-\\hat{y}_i)^2}\n$$\nWhere $y$ is the true value, $\\hat{y}$ is the predicted value, $N$ is the number of classes. Keep in mind that $y$ is a one-hot vector like $y=\\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ \\vdots \\end{bmatrix}$ (This example of $y$ indicates that the sample belongs to class ID 2, remember it is zero-indexed) and $\\hat{y}=\\begin{bmatrix} 0.1 \\\\ 0.03 \\\\ 0.8 \\\\ \\vdots \\end{bmatrix}$ shows the probability of belonging to each class for the same sample and predicted by the model.\n\nFor other optimization algorithms and loss functions, check the links below:\n\n[Optimizers list](https:\/\/pytorch.org\/docs\/stable\/optim.html#algorithms) \n\n[Loss function list](https:\/\/pytorch.org\/docs\/stable\/nn.html#loss-functions)","013ecee9":"### 12. (5 pts.) Display five random samples of each class titled with the true label and the predicted label. Comment on your model's performance.\nSamples must be pulled from the test set.","cbe5ba8e":"### 13. (20 pts.) Repeat the training, validation, and testing with the [Cross-Entropy](https:\/\/pytorch.org\/docs\/stable\/generated\/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) loss function and initial learning rate of $0.005$. Explain how the model's performance changed.\nEssentially you need to copy all the codes above and just change the loss function and edit the learning rate. Obviously, you don't need to re-import the dataset and the libraries. However, you need to create a new instance of the architecture. Otherwise, the weights would be the same as the last epoch (or the best epoch) in the last part. To avoid overwriting your previously trained model, change the save directories in the training loop.","01ec93cf":"### Ansers to the above Questions\nA.According to this [link](http:\/\/www.cs.toronto.edu\/~kriz\/cifar.html), the number of samples is 60,000.\n\n\n\nB. According to the same webpage, we can see that there are 10 classes\n\n\n\nC.According to the same webpage, we can see that the images are 32x32\n\n\n\n\nD. According to this [blog post](https:\/\/towardsdatascience.com\/cifar-10-image-classification-in-tensorflow-5b501f7dc77c). The labels are the following.airplane : \n\n    0, automobile : 1, bird : 2, cat : 3, deer : 4, dog : 5, frog : 6, horse : 7, ship : 8, truck : 9\n\n\n\n\nE.From the site, it seems as though the intensity range is from 1-255 (Need to double check on this one)\n","406cddfd":"## Model Performance\nAs we can see the model after training for 200 epochs that the model is fairly accurate, but still gets confused between similar types of classes such as dogs, cats, horses, and even deers. While this is unfortunate, it is fairly expected since our model is fairly shallow and probably would not be able to pick out the high level features that it would need in order to differentiate between those classes. Overall, the accuracy of the model was pretty impressive given the the quality and resolution of the images provided in the dataset. When I was looking at the outputs of the images right above, there were many cases where it was difficult for me to turlly determine what classes each of the images belonged to. \n\n","a9d1de32":"Adithya Shastry Ams2590"}}