{"cell_type":{"ca52d841":"code","296d8e78":"code","3ab85e63":"code","445e00e8":"code","03971848":"code","6e316ad1":"code","83c50418":"code","f9ad911e":"code","e7e6199e":"code","2497e671":"code","1ac5ae2a":"code","3d439795":"code","0e64da96":"code","e7f19418":"code","a9b1af13":"code","2acf9ef2":"code","cedc94eb":"code","244cf76a":"code","db6d787f":"code","776ae1e6":"code","36289e90":"code","e9cb86bb":"code","0f4c5d2b":"code","d8975f94":"markdown","4af47ad6":"markdown","2b5bc238":"markdown","ada49c60":"markdown","53958b87":"markdown","74532cb8":"markdown","249f5625":"markdown","31658a8d":"markdown","1828016f":"markdown"},"source":{"ca52d841":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nstyle.use('ggplot')\n\nimport os\nfrom datetime import datetime\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.graph_objs as go\n\ninit_notebook_mode(connected=True)\n\nfrom gensim import corpora, models, similarities\n\nimport warnings\nwarnings.filterwarnings('ignore')","296d8e78":"df = pd.read_csv('..\/input\/OnceUponATimeInHollywood.csv')\ndf.head()","3ab85e63":"df['EST'] = df['comment_created_utc'].apply(lambda x: datetime.fromtimestamp(int(x)).strftime('%Y-%m-%d %H:%M:%S'))","445e00e8":"trace = go.Histogram(\n    x=df['EST'],\n    marker=dict(\n        color='blue'\n    ),\n    opacity=0.75\n)\n\nlayout = go.Layout(\n    title='Comment Activity',\n    height=450,\n    width=1200,\n    xaxis=dict(\n        title='Month'\n    ),\n    yaxis=dict(\n        title='Comment Quantity'\n    ),\n    bargap=0.2,\n)\n\ndata= [trace]\n\nfig = go.Figure(data=data, layout=layout)\npy.offline.iplot(fig)","03971848":"corpus = df.comment_body.values\ncorpus[0:5]","6e316ad1":"from sklearn.feature_extraction.text import CountVectorizer\n\ndef get_top_n_words(corpus, n=None):\n    vec = CountVectorizer().fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\ncommon_words = get_top_n_words(corpus, 75)\nfor word, freq in common_words:\n    pass\n    #print(word, freq)\ndf1 = pd.DataFrame(common_words, columns = ['word' , 'count'])","83c50418":"import plotly.express as px\ndata = px.data.gapminder()\n\nfig = px.bar(df1.iloc[:50], x='word', y='count', labels={'word':'Word'}, height=400)\nfig.show()","f9ad911e":"fig = px.bar(df1.iloc[50:], x='word', y='count', labels={'word':'Word'}, height=400)\nfig.show()","e7e6199e":"l1 = list(df1.word.values)\nkeep = ['tarantino','sharon','rick','movies','know','cliff','tate','scene','manson']\n[l1.remove(w) for w in keep] \nl1 = l1[:-8]","2497e671":"import gensim\nimport logging\nimport tempfile\n\nTEMP_FOLDER = tempfile.gettempdir()\nprint('We will save the temporary dictionary and corpus at this location: {}'.format(TEMP_FOLDER))\n\nfrom gensim import corpora\nlogging.basicConfig(format = '%(ascitime)s: %(levelname)s: %(message)s', level=logging.INFO)","1ac5ae2a":"from nltk.corpus import stopwords\nfrom string import punctuation\n\nstoplist = stopwords.words('english') + list(punctuation) + l1\n\ntexts = [[word for word in str(document).lower().split() if word not in stoplist] for document in corpus]","3d439795":"dictionary = corpora.Dictionary(texts)\ndictionary.save(os.path.join(TEMP_FOLDER, 'onceUponATime.dict'))\nprint(dictionary)","0e64da96":"corpus = [dictionary.doc2bow(text) for text in texts]\ncorpora.MmCorpus.serialize(os.path.join(TEMP_FOLDER,  'onceUponATime.dict'), corpus)","e7f19418":"tfidf = models.TfidfModel(corpus)","a9b1af13":"corpus_tfidf = tfidf[corpus]","2acf9ef2":"total_topics = 3","cedc94eb":"lda = models.LdaModel(corpus, id2word=dictionary, num_topics=total_topics)\ncorpus_lda = lda[corpus_tfidf]","244cf76a":"lda.show_topics(total_topics,4)","db6d787f":"from collections import OrderedDict\n\ndata_lda = {i: OrderedDict(lda.show_topic(i, 12)) for i in range(total_topics)}\n#data_lda","776ae1e6":"df_lda = pd.DataFrame(data_lda)\nprint(df_lda.shape)\ndf_lda = df_lda.fillna(0).T\nprint(df_lda.shape)","36289e90":"df_lda","e9cb86bb":"g = sns.clustermap(df_lda.corr(), center=0, cmap='RdBu', metric='cosine', linewidth=0.75, annot_kws={\"size\": 24}, figsize=(12, 12))\nplt.setp(g.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)\nfig = plt.gcf()\nsns.set(font_scale=2.0)\nfig.set_size_inches(18, 18)\nplt.savefig('lda_clustermap_tarantino.png')\nplt.show()","0f4c5d2b":"import pyLDAvis.gensim\n\npyLDAvis.enable_notebook()\npanel = pyLDAvis.gensim.prepare(lda, corpus_lda, dictionary, mds='tsne')\npyLDAvis.save_html(panel, 'lda.html')\npanel","d8975f94":"# Load data","4af47ad6":"# Comment activity vs. time","2b5bc238":"The movie premiered in July 2019 and the most number of comments were posted around that time. There is also a bump around ~Aug 18th (I wonder why?)","ada49c60":"## Create a corpus","53958b87":"Step 1: initialize the model (following erreanhas I'm using Tfidf).","74532cb8":"Step 2: we use the model to transform all the vectors in the corpus.","249f5625":"The date\/time when a comment was posted is in UTC format. I want to convert it to EST time for the purpose of plotting the distribution of comments by the date when they were posted.","31658a8d":"# Create a transformation","1828016f":"## LDA (Latent Dirichlet Allocation)"}}