{"cell_type":{"cf913398":"code","5fd484a1":"code","c76e6c0b":"code","dec042b2":"code","a898af1e":"code","f637ee98":"code","5d701744":"code","d3e83413":"code","eaa58985":"code","c086ecaf":"code","12ccc24d":"code","962c4374":"code","a581510d":"code","876ace99":"code","8dbf95b8":"code","0a27295e":"code","97e425a8":"code","8410c005":"code","3b73ab6e":"code","11aaa54c":"code","977bcf0a":"code","ec45a726":"code","488c0eaf":"code","a72807c9":"code","178b7980":"code","42268187":"code","2f30c3ed":"code","859224b1":"code","68ce91ee":"code","61a8787a":"code","ce4e2bb1":"code","ce8a7a38":"code","c4e53681":"code","f4b14a58":"code","bec5ab2c":"code","d4f0ce34":"code","908dd2e9":"code","b5e04299":"code","c07a3f19":"code","a8660cb8":"markdown","761312a1":"markdown","0fbbe877":"markdown","9bcae7fe":"markdown","70e4863d":"markdown"},"source":{"cf913398":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5fd484a1":"dataset_train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndataset_test = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","c76e6c0b":"dataset_train.head()","dec042b2":"#Checking for the Null Value\ndataset_train.isnull().sum()","a898af1e":"\ndataset_null = (dataset_train.isnull().sum() \/ len(dataset_train)) * 100\ndataset_null = dataset_null.drop(dataset_null[dataset_null == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' : dataset_null})\nmissing_data","f637ee98":"def missing_percentage(df):   \n    \n    missing_total = df.isnull().sum().sort_values(ascending = False)[df.isnull().sum().sort_values(ascending = False) != 0]\n    percent = round(df.isnull().sum().sort_values(ascending = False)\/len(df)*100,2)[round(df.isnull().sum().sort_values(ascending = False)\/len(df)*100,2) != 0]\n    return pd.concat([missing_total, percent], axis=1, keys=['Missing_Total','Percent'])\n\nmissing_percentage(dataset_train)","5d701744":"#dataset_train = dataset_train.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence'], axis= 1)\ndef show_missing_list():\n    list_missing = dataset_train.columns[dataset_train.isnull().any()].tolist()\n    return list_missing\n\ndef cat_exploration(column):\n    return dataset_train[column].value_counts()\n\ndef cat_imputation(colums, value):\n    dataset_train.loc[dataset_train[colums].isnull(), colums] = value","d3e83413":"dataset_train[show_missing_list()].isnull().mean()","eaa58985":"cat_exploration('Alley')","c086ecaf":"cat_imputation('Alley', 'None')","12ccc24d":"dataset_train[['MasVnrType' , 'MasVnrArea']][dataset_train['MasVnrType'].isnull() == True]","962c4374":"cat_exploration('MasVnrType')","a581510d":"cat_imputation('MasVnrType', 'None')\ncat_imputation('MasVnrArea', 0.0)","876ace99":"cat_exploration('Electrical')","8dbf95b8":"cat_imputation('Electrical', 'SBrkr')","0a27295e":"cat_exploration('FireplaceQu')","97e425a8":"dataset_train['Fireplaces'][dataset_train['FireplaceQu'].isnull() == True].describe()","8410c005":"cat_imputation('FireplaceQu', 'None')","3b73ab6e":"garage_cols=['GarageType','GarageQual','GarageCond','GarageYrBlt','GarageFinish','GarageCars','GarageArea']\ndataset_train[garage_cols][dataset_train['GarageType'].isnull()==True]","11aaa54c":"for cols in garage_cols:\n    if dataset_train[cols].dtype==np.object:\n        cat_imputation(cols,'None')\n    else:\n        cat_imputation(cols, 0)","977bcf0a":"cat_exploration('PoolQC')","ec45a726":"dataset_train['PoolArea'][dataset_train['PoolQC'].isnull() ==True].describe()","488c0eaf":"cat_imputation('PoolQC', 'None')\ncat_imputation('Fence', 'None')\ncat_imputation('MiscFeature', 'None')","a72807c9":"dataset_train[show_missing_list()].isnull().sum()","178b7980":"dataset_train['LotFrontage'].corr(dataset_train['LotArea'])","42268187":"dataset_train['SqrtLotArea'] = np.sqrt(dataset_train['LotArea'])\ndataset_train['LotFrontage'].corr(dataset_train['SqrtLotArea'])","2f30c3ed":"cond = dataset_train['LotFrontage'].isnull()\ndataset_train.LotFrontage[cond]=dataset_train.SqrtLotArea[cond]","859224b1":"del dataset_train['SqrtLotArea']","68ce91ee":"dataset_train[show_missing_list()].isnull().sum()","61a8787a":"dataset_train.head(10)","ce4e2bb1":"#Get all Categorical Variable\ndef getCategorical(dataset):\n    cat_var = [key for key in dict(dataset.dtypes)\n          if dict(dataset.dtypes)[key] in ['object']]\n    \n    return cat_var\n\n\ngetCategorical(dataset_train)","ce8a7a38":"#Get all numerical variable\ndef getNumericData(dataset):\n    numeric_var = [key for key in dict(dataset.dtypes)\n                   if dict(dataset.dtypes)[key]\n                       in ['float64','float32','int32','int64']]\n    return numeric_var\n     \n\ngetNumericData(dataset_train)","c4e53681":"\nx = dataset_train.drop(['SalePrice'], axis = 1)\n\nX = pd.get_dummies(x, drop_first=True)\nX_inscaled = pd.get_dummies(x, drop_first=True)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler1 = MinMaxScaler()\nX = scaler1.fit_transform(X)\ny_ = scaler1.fit_transform(dataset_train[['SalePrice']])\n","f4b14a58":"from sklearn.feature_selection import SelectKBest,  \\\n                                      f_regression\n\n\nselector_n = SelectKBest(score_func=f_regression, k = 50)\nX_k = selector_n.fit_transform(X, y_)\n\nf_score = selector_n.scores_\np_value = selector_n.pvalues_\n\n#columns = list(x.columns)\n#for i in range(0, len(columns)):\n#    print(\"f1 score %4.2f\"% f_score[i])\n#    print(\"p1 score %2.6f\"% p_value[i])\n#    print(\"_____________________________________\")\n    \n    \n\nselected_col = []\nfor i in range (0, len(x.columns)):\n    if p_value[i] < 0.5:\n        selected_col.append(p_value[i])\n\ncols = selector_n.get_support(indices=True)\nselected_col = X_inscaled.columns[cols].tolist()\nprint(\"Selected Cols \", selected_col)\n\n#This are the top 50 feature \ncoloumns_sel = ['LotFrontage', 'LotArea', 'OverallQual', 'YearBuilt', 'YearRemodAdd', \n                'MasVnrArea', 'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n                'FullBath', 'HalfBath', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars',\n                'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'MSZoning_RL', 'MSZoning_RM', \n                'LotShape_Reg', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', \n                'Exterior1st_VinylSd', 'Exterior2nd_VinylSd', 'MasVnrType_None', \n                'MasVnrType_Stone', 'ExterQual_Gd', 'ExterQual_TA', 'Foundation_CBlock', \n                'Foundation_PConc', 'BsmtQual_TA', 'BsmtExposure_Gd', 'BsmtExposure_No', \n                'BsmtFinType1_GLQ', 'HeatingQC_TA', 'CentralAir_Y', 'KitchenQual_Gd', \n                'KitchenQual_TA', 'FireplaceQu_Gd', 'FireplaceQu_None', 'GarageType_Attchd', \n                'GarageType_Detchd', 'GarageFinish_Unf', 'GarageQual_TA', 'GarageCond_TA',\n                'SaleType_New', 'SaleCondition_Partial']\n\ndata_select = X_inscaled[coloumns_sel]\n\n","bec5ab2c":"X = data_select\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_new = scaler.fit_transform(X)","d4f0ce34":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = \\\ntrain_test_split(X, y_, test_size = 0.3, random_state = 1234)","908dd2e9":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport math\n\nlr = LinearRegression()\n\nlr.fit(X_train, Y_train)\n\nY_predict = lr.predict(X_test)\n\nprint(\"R Score \", lr.score(X_train, Y_train))\nprint(\"R Score Test\", lr.score(X_test, Y_test))\nprint(\"RMSE \", np.sqrt(mean_squared_error(Y_test, Y_predict)))","b5e04299":"\nfrom sklearn import datasets\nfrom sklearn.model_selection import cross_val_predict\nimport matplotlib.pyplot as plt\n\n# cross_val_predict returns an array of the same size as `y` where each entry\n# is a prediction obtained by cross validation:\npredicted = cross_val_predict(lr, Y_test, Y_predict, cv=10)\n\nfig, ax = plt.subplots()\nax.scatter(Y_test, predicted)\nax.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()\n","c07a3f19":"y_result = scaler1.inverse_transform(Y_predict).tolist()\ny_resul_actual = scaler1.inverse_transform(Y_test).tolist()","a8660cb8":"As from the above selection we came to know that only 5 features are usefull\nSo again we well do feature selection get the feature name","761312a1":"SelectKBest for feature selection","0fbbe877":"Again we have to make Xtrain for new selected feature","9bcae7fe":"Selection Transform of feature selection","70e4863d":"Inverse Tranformation"}}