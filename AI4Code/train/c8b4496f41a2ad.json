{"cell_type":{"85c1166c":"code","fc445bed":"code","1d9c6935":"code","9aa1ebce":"code","d16e0a9e":"code","45b5a866":"code","9eb78c18":"code","fa51baa1":"code","121bd820":"code","7aa65143":"code","6a563e60":"code","5b3e87e4":"code","37ffdd74":"code","573ce188":"code","eb80bceb":"code","b69e6cf2":"code","ca880645":"code","903ece00":"code","43e5e4b2":"code","fa14f369":"code","07811444":"code","620be704":"code","ba06b3e2":"code","e393ba8d":"code","c92b145b":"code","8c3657d5":"code","12c28348":"markdown","f88fc694":"markdown","c3129cc7":"markdown","20811765":"markdown","caf2c63f":"markdown"},"source":{"85c1166c":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport albumentations as A\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\nimport PIL.Image as Image\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\nimport albumentations as A\nfrom albumentations.core.composition import Compose, OneOf\nfrom albumentations.augmentations.transforms import CLAHE, GaussNoise, ISONoise\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing","fc445bed":"DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","1d9c6935":"class CFG:\n    seed = 42\n    pretrained = False\n    img_size = 299\n    num_classes = 6\n    lr = .00001\n    min_lr = 1e-6\n    t_max = 20\n    num_epochs = 10\n    batch_size = 16\n    augmentation_probability = 0.25\n    accum = 1\n    precision = 16\n    n_fold = 5\n    weight_decay = .05\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","9aa1ebce":"PATH = \"..\/input\/plant-pathology-2021-fgvc8\/\"\n\nTEST_DIR = PATH + 'test_images\/'","d16e0a9e":"df_all = pd.read_csv(PATH + \"train.csv\")\ndf_all.shape","45b5a866":"from collections import defaultdict\n\n\ndct = defaultdict(list)\n\nfor i, label in enumerate(df_all.labels):\n    for category in label.split():\n        dct[category].append(i)\n \ndct = {key: np.array(val) for key, val in dct.items()}\ndct","9eb78c18":"new_df = pd.DataFrame(np.zeros((df_all.shape[0], len(dct.keys())), dtype=np.int8), columns=dct.keys())\n\nfor key, val in dct.items():\n    new_df.loc[val, key] = 1\n    \ndf_all = pd.concat([df_all, new_df], axis=1)\ndf_all.head()","fa51baa1":"multi_labels = new_df.columns\nmulti_labels","121bd820":"sub = pd.read_csv(PATH + \"sample_submission.csv\")\nsub.head()","7aa65143":"tmp = pd.DataFrame(np.zeros([len(sub), len(new_df.columns)]), columns=multi_labels)\nsub = pd.concat([sub, tmp], axis=1)\nsub.head()","6a563e60":"class PlantDataset(Dataset):\n    def __init__(self, df, directory, transform=None):\n        self.image_id = df['image'].values\n        self.labels = df.iloc[:, 2:].values\n        self.directory = directory\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        image_id = self.image_id[idx]\n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n        \n        image_path = self.directory + image_id\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        \n        augmented = self.transform(image=image)\n        image = augmented['image']\n        return {'image':image, 'target': label}","5b3e87e4":"def get_transform(phase: str):\n    if phase == 'train':\n        '''\n        return Compose([\n            A.RandomResizedCrop(height=CFG.img_size, width=CFG.img_size),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n        '''\n        return Compose([\n                      A.Resize(height=CFG.img_size, width=CFG.img_size),\n                      A.HorizontalFlip(p=CFG.augmentation_probability),\n                      A.VerticalFlip(p=CFG.augmentation_probability),\n                      A.ShiftScaleRotate(p=CFG.augmentation_probability),\n                      A.Rotate(p=CFG.augmentation_probability, limit=90),\n            \n                      A.RGBShift(p=CFG.augmentation_probability),\n            \n                      A.IAAAffine(rotate=90., p=CFG.augmentation_probability),\n                      A.IAAAffine(rotate=180., p=CFG.augmentation_probability),\n            \n                      A.RandomBrightnessContrast(p=CFG.augmentation_probability),\n                      A.RandomContrast(limit = 0.5,p = CFG.augmentation_probability),\n                      A.RandomSunFlare(p=CFG.augmentation_probability), \n                      A.RandomBrightness(p=CFG.augmentation_probability),\n            \n                      A.Normalize(),\n                      ToTensorV2(),\n        ])\n    else:\n        return Compose([\n            A.Resize(height=CFG.img_size, width=CFG.img_size),\n            A.Normalize(),\n            ToTensorV2(),\n        ])","37ffdd74":"train_dataset = PlantDataset(df_all, PATH + \"train_images\/\", get_transform('train'))\ndataset_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=5)\ntest_dataset = PlantDataset(sub, PATH + \"test_images\/\", get_transform('valid'))\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=5)","573ce188":"class SeparableConv2d(nn.Module):\n    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n        super(SeparableConv2d,self).__init__()\n\n        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n\n    def forward(self,x):\n        x = self.conv1(x)\n        x = self.pointwise(x)\n        return x","eb80bceb":"class Block(nn.Module):\n    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n        super(Block, self).__init__()\n\n        if out_filters != in_filters or strides!=1:\n            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n            self.skipbn = nn.BatchNorm2d(out_filters)\n        else:\n            self.skip=None\n\n        self.relu = nn.ReLU(inplace=True)\n        rep=[]\n\n        filters=in_filters\n        if grow_first:\n            rep.append(self.relu)\n            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n            rep.append(nn.BatchNorm2d(out_filters))\n            filters = out_filters\n\n        for i in range(reps-1):\n            rep.append(self.relu)\n            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n            rep.append(nn.BatchNorm2d(filters))\n\n        if not grow_first:\n            rep.append(self.relu)\n            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n            rep.append(nn.BatchNorm2d(out_filters))\n\n        if not start_with_relu:\n            rep = rep[1:]\n        else:\n            rep[0] = nn.ReLU(inplace=False)\n\n        if strides != 1:\n            rep.append(nn.MaxPool2d(3,strides,1))\n        self.rep = nn.Sequential(*rep)\n\n    def forward(self,inp):\n        x = self.rep(inp)\n\n        if self.skip is not None:\n            skip = self.skip(inp)\n            skip = self.skipbn(skip)\n        else:\n            skip = inp\n\n        x+=skip\n        return x","b69e6cf2":"class Xception(nn.Module):\n    def __init__(self, num_classes=1000):\n        super(Xception, self).__init__()\n        self.num_classes = num_classes\n\n        self.conv1 = nn.Conv2d(3, 32, 3,2, 0, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n        self.bn2 = nn.BatchNorm2d(64)\n\n        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n\n        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n\n        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n\n        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n\n        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n        self.bn3 = nn.BatchNorm2d(1536)\n\n        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n        self.bn4 = nn.BatchNorm2d(2048)\n\n        self.fc = nn.Linear(2048, num_classes)\n\n\n\n    def features(self, input):\n        x = self.conv1(input)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.block5(x)\n        x = self.block6(x)\n        x = self.block7(x)\n        x = self.block8(x)\n        x = self.block9(x)\n        x = self.block10(x)\n        x = self.block11(x)\n        x = self.block12(x)\n\n        x = self.conv3(x)\n        x = self.bn3(x)\n        x = self.relu(x)\n\n        x = self.conv4(x)\n        x = self.bn4(x)\n        return x\n\n    def logits(self, features):\n        x = self.relu(features)\n\n        x = F.adaptive_avg_pool2d(x, (1, 1))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n    def forward(self, input):\n        x = self.features(input)\n        x = self.logits(x)\n        return x","ca880645":"from collections import OrderedDict\n\ndef fix_model_state_dict(state_dict):\n    new_state_dict = OrderedDict()\n    for k, v in state_dict.items():\n        name = k\n        if name.startswith('model.'):\n            name = name[6:]  # remove 'model.' of dataparallel\n        new_state_dict[name] = v\n    return new_state_dict","903ece00":"model = Xception()\n\nxceptionModelPath = None\n\nfor dirpath, subdirs, files in os.walk('\/kaggle\/input\/xceptionimagenetcheckpoint'):\n    if xceptionModelPath:\n        break\n    for file in files:\n        if file.endswith('.pth'):\n            modelPath = os.path.join(dirpath,file)\n            break\n\nif xceptionModelPath:\n    model.load_state_dict(torch.load(xceptionModelPath), torch.device(DEVICE))\n\nmodel.fc = nn.Linear(2048, CFG.num_classes)\nmodel = model.to(DEVICE)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n\ncriterion = nn.BCELoss()\ncriterion = criterion.to(DEVICE)","43e5e4b2":"def saveModel(model):\n    torch.save(model.state_dict(), model.__class__.__name__+'.pth')","fa14f369":"def fitModel(model):\n    sigmoid = nn.Sigmoid()\n    sigmoid = sigmoid.to(DEVICE)\n    \n    for epoch in range(CFG.num_epochs):\n        model = model.train()\n\n        for i, batch in enumerate(dataset_loader, start=1):\n            image = batch['image'].cuda()\n            labels = batch['target'].cuda()\n\n            logits = model(image)\n            output = sigmoid(logits)\n            loss = criterion(output, labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss = loss.detach().item()\n            print(\"Epoch: {0}\/{1}, Current Epoch Progress: {2:.2f}%, Loss: {3:.4f}\".format(epoch+1, CFG.num_epochs, 100*i\/(len(dataset_loader)), train_loss))\n\n        saveModel(model)\n\n        model.eval()","07811444":"modelPath = None\n\nfor dirpath, subdirs, files in os.walk('\/kaggle'):\n    if modelPath:\n        break\n    for file in files:\n        if file.endswith('.pth') and \"xception-43020ad28.pth\" not in file:\n            modelPath = os.path.join(dirpath,file)\n            break\n\nif modelPath:\n    print(\"Using pretrained model: \" + modelPath)\n    model.load_state_dict(torch.load(modelPath), torch.device(DEVICE))\nelse:\n    fitModel(model)","620be704":"model.cuda()\nmodel.eval()\n\nsigmoid = nn.Sigmoid()\n\npredictions = []\nfor batch in test_loader:\n    image = batch['image'].cuda()\n    with torch.no_grad():\n        outputs = model(image)\n        preds = outputs.detach().cpu()\n        predictions.append(sigmoid(preds).numpy() > 0.5)","ba06b3e2":"predictions = pd.DataFrame(np.concatenate(predictions).astype(np.int), columns=new_df.columns)","e393ba8d":"sub.iloc[:, 2:] = predictions\nsub","c92b145b":"labels = []\nfor i, row in sub.iloc[:, 2:].iterrows():\n    if (row['healthy'] == 1):\n        tmp = 'healthy'\n    elif (row['healthy'] == 0 and\n             row['scab'] == 0 and\n             row['frog_eye_leaf_spot'] == 0 and\n             row['complex'] == 0 and\n             row['rust'] == 0 and\n             row['powdery_mildew'] == 0):\n        tmp = 'healthy'\n    else:\n        tmp = ' '.join(multi_labels[row==row.max()])\n    labels.append(tmp)","8c3657d5":"sub['labels'] = labels\nsub[['image', 'labels']].to_csv('submission.csv', index=False)\nsub.head()","12c28348":"# Import","f88fc694":"# Inference","c3129cc7":"# Define Dataset","20811765":"# Config","caf2c63f":"# Define Model"}}