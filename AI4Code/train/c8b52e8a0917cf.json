{"cell_type":{"6c316cf6":"code","28f5dbcc":"code","422b5d2a":"code","3a086120":"code","88a38531":"code","7d3bb781":"code","4c2f08e3":"code","4b9bd41a":"code","8eaa181b":"code","76bbc235":"code","59f4e7f1":"code","1517a38f":"code","2676a64d":"code","14065c23":"code","ac9982de":"code","f3ac2a6b":"code","4070acf7":"code","22c14de7":"code","a7e61ce1":"code","6607e40d":"code","5dce7c25":"code","b8a307b8":"code","6562c03f":"code","70fa7229":"code","e2857aa0":"code","48e32d16":"code","b2f721ce":"code","b9901060":"code","4e01b9ca":"code","41043eda":"code","c7908ebe":"code","0a20862b":"code","93765a8a":"code","6d0d2f4a":"code","3d985cca":"code","4f2910a1":"code","7265eb13":"code","4e0f8616":"markdown","1308796d":"markdown","5ad581a6":"markdown","b0e5b87f":"markdown","70836656":"markdown","e94f7da1":"markdown","8f4de775":"markdown","2b67c2cf":"markdown","1880aef3":"markdown","1cabbdea":"markdown","8f49a54f":"markdown","100726e5":"markdown","2322909c":"markdown","867432e0":"markdown"},"source":{"6c316cf6":"# Install necessary libraries\n!pip install pydotplus\n!pip install lazypredict\n!pip install pandas -U","28f5dbcc":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\nimport matplotlib.pyplot as plt\nimport altair as alt\n\nfrom sklearn.model_selection import train_test_split\nfrom lazypredict.Supervised import LazyClassifier\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom six import StringIO  \nimport pydotplus\nfrom sklearn.metrics import accuracy_score\n\n%matplotlib inline","422b5d2a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3a086120":"stars = pd.read_csv('\/kaggle\/input\/star-type-classification\/Stars.csv')","88a38531":"stars.sample(n = 10, random_state = 42)","7d3bb781":"print(stars.info(), '\\n', stars.isna().sum())","4c2f08e3":"stars.describe()","4b9bd41a":"stars.Type.value_counts()","8eaa181b":"# We'll get all the unique values and do a sort to see like values easier\ncolor_list = []\n\nfor n in stars['Color'].unique():\n    color_list.append(n)\n\ncolor_list.sort()\n\ncolor_list","76bbc235":"alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('Color:N', sort = '-x')\n    )","59f4e7f1":"color_map = {'Orange-Red' : 'Orange-Red', \n             'Pale yellow orange' : 'Yellow-Orange',\n             'Blue-white' : 'Blue-White', \n             'Blue White' : 'Blue-White',\n             'Blue white' : 'Blue-White',\n             'Blue-White' : 'Blue-White', \n             'yellow-white' : 'Yellow-White',\n             'Yellowish White' : 'Yellow-White',\n             'White-Yellow' : 'Yellow-White',\n             'yellowish' : 'Yellow',\n             'Yellowish' : 'Yellow',   \n             'White' : 'White',\n             'white' : 'White',\n             'Whitish' : 'White',\n             'Orange' : 'Orange', \n             'Red' : 'Red', \n             'Blue' : 'Blue'\n            }   \n\nstars.Color = stars.Color.map(color_map).astype('category')\nstars.Spectral_Class = stars.Spectral_Class.astype('category')","1517a38f":"alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('Color', sort = '-x')\n    )","2676a64d":"le = LabelEncoder()","14065c23":"# Map original labels for future reference\nle.fit(stars['Spectral_Class'])\nle_name_mapping_spectral_class = dict(zip(le.classes_, le.transform(le.classes_)))\nle.fit(stars['Color'])\nle_name_mapping_color = dict(zip(le.classes_, le.transform(le.classes_)))\nprint('Spectral Classes Mapping: ', le_name_mapping_spectral_class, \n      '\\n\\nColor Mapping: ', le_name_mapping_color)","ac9982de":"# Apply transformations\nstars['Color'] = le.fit_transform(stars['Color'])\nstars['Spectral_Class'] = le.fit_transform(stars['Spectral_Class'])","f3ac2a6b":"sc_chart = alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('Spectral_Class', sort = '-x')\n).properties(\n    height = 100,\n    width = 100\n)\n\nr_chart = alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('R:Q', bin = True)\n).properties(\n    height = 100,\n    width = 100\n)\n\nl_chart = alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('L:Q', bin = True)\n).properties(\n    height = 100,\n    width = 100\n)\n\ntemperature_chart = alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('Temperature:Q', bin = True)\n).properties(\n    height = 100,\n    width = 100\n)\n\nsc_chart | r_chart | l_chart | temperature_chart","4070acf7":"alt.Chart(stars).mark_point().encode(\n    alt.X(alt.repeat('column'), type = 'quantitative'),\n    alt.Y(alt.repeat('row'), type = 'quantitative'),\n    color = 'Type:N'\n).properties(\n    width = 200,\n    height = 200\n).repeat(\n    row = ['L', 'R'],\n    column = ['Temperature', 'A_M', 'Spectral_Class', 'Color']\n)","22c14de7":"stars['L'] = np.log(stars.L).astype(float)\nstars['R'] = np.log(stars.R).astype(float)","a7e61ce1":"sc_chart = alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('Spectral_Class', sort = '-x')\n).properties(\n    height = 100,\n    width = 100\n)\n\nr_chart = alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('R:Q', bin = True)\n).properties(\n    height = 100,\n    width = 100\n)\n\nl_chart = alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('L:Q', bin = True)\n).properties(\n    height = 100,\n    width = 100\n)\n\ntemperature_chart = alt.Chart(stars).mark_bar().encode(\n    x = 'count()',\n    y = alt.Y('Temperature:Q', bin = True)\n).properties(\n    height = 100,\n    width = 100\n)\n\nsc_chart | r_chart | l_chart | temperature_chart","6607e40d":"alt.Chart(stars).mark_point().encode(\n    alt.X(alt.repeat('column'), type = 'quantitative'),\n    alt.Y(alt.repeat('row'), type = 'quantitative'),\n    color = 'Type:N'\n).properties(\n    width = 200,\n    height = 200\n).repeat(\n    row = ['L', 'R'],\n    column = ['Temperature', 'A_M', 'Spectral_Class', 'Color']\n)","5dce7c25":"alt.Chart(stars).mark_point().encode(\n    alt.X(alt.repeat('column'), type = 'quantitative'),\n    alt.Y(alt.repeat('row'), type = 'quantitative'),\n    color = 'Type:N'\n).properties(\n    width = 200,\n    height = 200\n).repeat(\n    row = ['Temperature', 'L', 'R', 'A_M', 'Spectral_Class', 'Color'],\n    column = ['Temperature', 'L', 'R', 'A_M', 'Spectral_Class', 'Color']\n)","b8a307b8":"heatmap = alt.Chart(stars).mark_rect().encode(\n    alt.X('A_M:Q', bin = True),\n    alt.Y('Temperature:Q', bin = True),\n    alt.Color('count()', scale = alt.Scale(scheme = 'greenblue'))\n)\n\npoints = alt.Chart(stars).mark_circle(\n    color = 'black',\n    size = 5,\n).encode(\n    x = 'A_M:Q',\n    y = 'Temperature:Q',\n)\n\nheatmap + points","6562c03f":"chart = alt.Chart(stars).mark_circle().encode(\n    x = 'L:Q',\n    y = 'R:Q',\n).properties(\n    height = 300,\n    width = 300\n)\n\nchart + chart.transform_regression('L', 'R', method = 'poly').mark_line()","70fa7229":"X = stars.drop(['Type'], axis = 1)\ny = stars['Type']\n\nfeatures = X.columns\ntarget = 'Type'","e2857aa0":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 42)","48e32d16":"from lazypredict.Supervised import LazyClassifier","b2f721ce":"models = LazyClassifier(verbose = 0, ignore_warnings = True, custom_metric = None, predictions = True)\nmodel, predictions = models.fit(X_train, X_test, y_train, y_test)","b9901060":"model.head(10)","4e01b9ca":"dt = DecisionTreeClassifier(random_state = 42)","41043eda":"dt.fit(X_train, y_train)","c7908ebe":"importance = dt.feature_importances_","0a20862b":"importance = pd.DataFrame(importance).T\nimportance.columns = features\nimportance = importance.T.reset_index()\nimportance.columns = ['Features', 'Importance']","93765a8a":"alt.Chart(importance).mark_bar().encode(\n    x = 'Features',\n    y = 'Importance',\n    ).properties(width = 200, height = 200)","6d0d2f4a":"text_representation = tree.export_text(dt)\nprint(text_representation)","3d985cca":"with open(\"decistion_tree.log\", \"w\") as fout:\n    fout.write(text_representation)","4f2910a1":"plt.figure(figsize = (30, 30))\ntree.plot_tree(dt, feature_names = features,  \n                     class_names = ['0', '1', '2', '3', '4', '5'],  filled = True)\nplt.savefig('decision_tree_visualization.png')","7265eb13":"yhat_test = dt.predict(X_test)\nacc = accuracy_score(y_test, yhat_test)\nprint('Accuracy Score: ', acc)","4e0f8616":"## Overview\n\n*Star Type Classification \/ NASA*\n\nFor this dataset, we'll be classifying the type of star given our dataset.\nIn particular, if the star is appropriately labeled as a Red Drawf, Hyper Giant, etc.\n\nAs there are multiple possible outputs, we should be keen to note that this is a multiple classification problem.","1308796d":"Just at face-value, we can see that our target labels are normally distributed.","5ad581a6":"Here are a few observations from our plots\n\n    1. Radius, luminosity and absolute magnitude seem to have a role in the type of star\n    2. Radii and absolute magnitude seems to seperate the types better\n    3. It seems that radii plays an integral role in determining the type of star\n    4. Main sequence stars seem to have the widest spread\n\nTo further go off of points 2 and 3, it seems to make sense, especially if we refer to the Hertzsprung-Russell Diagram\n\n\nIn particular, the type of star may have some relationship to the equation:\n\n    L = Area x Flux = 4\u03c0R^2\u03c3SBT^4\n   \nLet's do a little bit more diving before creating a model","b0e5b87f":"Our top 10 models have a near 100% accuracy rating, but this could be due to the fact that the dataset is small, or some other factors. \n\nFor now, we'll go with Decision Tree Classification for the following reasons:\n\n    1. Short runtime\n    2. Trees are less susceptible to label encoded data","70836656":"We can see some values that are similar but have some character dissimilarities, such as 'Blue White'\n\nLet's see how the data is distributed and go from there.","e94f7da1":"We can infer that the color observations were probably made by direct observations.\n\nData of the Metalicity of the stars, would allow for use of something like a B-V Color Index. \n\nWe'll instead relabel the color labels to something a bit more appropriate for out test.","8f4de775":"When we look back at the graphs above, radii and absolute magnitude have seemed to play a role in classification.\n\nSurprisingly, luminosity did not have more weight in classification.","2b67c2cf":"The features for radii and luminosity seem to have a heavily skewed distribution.\n\nWe'll want to provide a log transformation to both of these.\nOur main reason is because for star categorization, radii and luminosity seem to be based on\nrelative changes rather than absolute, in regards to classification.\n\nBefore applying the transformation, let's see what the data looks like beforehand.","1880aef3":"## Analysis Part I\n\nWe'll take an overall peak of the data and take a deeper dive if we need to.","1cabbdea":"## Modeling","8f49a54f":"## Data Cleaning","100726e5":"We'll also label encode the spectral class and color columns as they are ordinal data","2322909c":"## Conclusion\n\nFor now, it seems we can draw a conclusion that absolute magnitude and radii are integral to classifying the type of star. With such a small dataset, it seems like the accuracy score is appropriate enough, especially at 100%. \n\nWhile we can certainly do feature selection and \"improve\" upon the decision tree, it does not seem necessary at this time.\n\n#### Other Thoughts\nI think it would have been nice to see the colors in a B-V Color Index. It would be interesting to see how metalicity would play a more integral role in the classification of stars.","867432e0":"Instead of testing each and every classifier, we'll use LazyPredict.\nIf a model seems promising, we might do a deeper dive into other related models that are not covered\nvia LazyPredict."}}