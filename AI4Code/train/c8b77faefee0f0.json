{"cell_type":{"f30ad469":"code","2b24a563":"code","c13d17b0":"code","902b92a7":"code","59ce2ce9":"code","05f11be2":"code","1010da9a":"code","22c46b6a":"code","e6c026d8":"code","f279f738":"code","7e03029b":"code","79c2b731":"code","d7f26be5":"code","8fafc04c":"code","575b59f1":"code","6d3b0796":"code","e941a08c":"code","af3e320c":"code","0cef5fc3":"code","aa49a7c9":"code","5f8b10b3":"markdown","e8051c59":"markdown","7dbfe06a":"markdown","d8701498":"markdown","817f1543":"markdown","d6f1895a":"markdown","841d08fb":"markdown","26e7dbd9":"markdown","403033ef":"markdown","a6564fbd":"markdown"},"source":{"f30ad469":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.cluster import KMeans\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2b24a563":"data = pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\ndata.head()","c13d17b0":"data.Species.unique()","902b92a7":"df = data.drop(['Id', 'Species'], axis = 1)","59ce2ce9":"df.head()","05f11be2":"from sklearn.preprocessing import StandardScaler","1010da9a":"SD = StandardScaler()\ndf_std = pd.DataFrame(SD.fit_transform(df), columns = df.columns)\ndf_std.head()\n","22c46b6a":"import matplotlib.pyplot as plt\n\nplt.scatter(df_std['SepalLengthCm'], df_std['PetalLengthCm'])","e6c026d8":"plt.scatter(df_std['SepalWidthCm'], df_std['PetalWidthCm'])","f279f738":"K = range(1,10)\nSSE = []\nfor i in K:\n    KM = KMeans(n_clusters = i)\n    KM.fit(df_std[['SepalLengthCm','PetalLengthCm']])\n    SSE.append(KM.inertia_)","7e03029b":"plt.plot(K, SSE)","79c2b731":"model = KMeans(n_clusters = 3)\npred = model.fit_predict(df_std[['SepalLengthCm','PetalLengthCm']])\npred","d7f26be5":"df_std['clusters'] = pred","8fafc04c":"df_std.head()","575b59f1":"Final_df = df_std.drop(['SepalWidthCm', 'PetalWidthCm'], axis = 1)\nFinal_df.head()","6d3b0796":"DF1 = Final_df[Final_df['clusters'] == 0]\nDF2 = Final_df[Final_df['clusters'] == 1]\nDF3 = Final_df[Final_df['clusters'] == 2]\nplt.scatter(DF1.SepalLengthCm, DF1.PetalLengthCm, color = 'red')\nplt.scatter(DF2.SepalLengthCm, DF2.PetalLengthCm, color = 'green')\nplt.scatter(DF3.SepalLengthCm, DF3.PetalLengthCm, color = 'blue')\nplt.show()","e941a08c":"K = range(1,10)\nSSE_2 = []\nfor i in K:\n    KM = KMeans(n_clusters = i)\n    KM.fit(df_std[['SepalLengthCm','PetalLengthCm','SepalWidthCm','PetalWidthCm']])\n    SSE_2.append(KM.inertia_)","af3e320c":"plt.plot(K,SSE_2)","0cef5fc3":"model_2 = KMeans(n_clusters = 3)\npred_2 = model_2.fit_predict(df_std[['SepalLengthCm','PetalLengthCm','SepalWidthCm','PetalWidthCm']])\npred_2","aa49a7c9":"np.unique(pred_2)","5f8b10b3":"## ***Elbow Method***\n\nHere we will apply KMeans only on 2 columns for demo purpose","e8051c59":"## ***Clustering Algorithm***\nFrom **Elbow Method** we can clearly take 3 clusters and apply it on data,","7dbfe06a":"## ***Load Dataset***","d8701498":"## ***Plot SepalLengthCm Vs PetalLengthCm***","817f1543":"## ***Visualization***\nAfter getting clusters we will plot it on scatter plot to visualize.","d6f1895a":"## ***Plot SepalWidthCm Vs PetalWidthCm***","841d08fb":"Here by cross-checking number of our Unique Labes and unique clusters we can say that out model is giving correct O\/P","26e7dbd9":"Apply **Elbow Method** on full dataset.","403033ef":"## ***Checking Unique Labes***\nHere we will check how many unique labers are there in dataset and cross-check it with our elbow method","a6564fbd":"## ***Scaling our data into one range***"}}