{"cell_type":{"e3704365":"code","5923d6f8":"code","f2e19fec":"code","efe6198b":"code","c75ed4a8":"code","25cca855":"code","25569730":"code","ca1dc8bb":"code","6727d68a":"code","3eab518e":"code","ab617105":"code","e2c9d580":"code","595ce282":"code","b5441242":"code","3bcdb660":"code","dd21f2c2":"code","9cbd3fca":"code","fcc47307":"code","7d4d2cd8":"code","216a1063":"code","608d462b":"code","44381a25":"code","217ddf26":"code","da0592d1":"code","13c921cf":"code","5caa7d0f":"code","ec8678b4":"code","5f90d7fe":"code","3e51f044":"code","281cc94d":"code","a36c336b":"code","5afd44c2":"code","8ee80f6b":"markdown","4a26b566":"markdown","79917967":"markdown","d64712c7":"markdown","cd78fee7":"markdown","b075e7bc":"markdown","3c3433dc":"markdown","38a5b51e":"markdown","d827ff66":"markdown","b5eb8dc7":"markdown","467e1127":"markdown","5223ca65":"markdown","f0de75db":"markdown","f13d5302":"markdown","a5ee7d7c":"markdown","59008250":"markdown","07edffac":"markdown"},"source":{"e3704365":"# pip install tensorflow-gpu","5923d6f8":"import os\nimport glob\nimport cv2\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.utils import shuffle\n\nfrom PIL import Image\n\nfrom skimage.io import imread, imsave\nfrom skimage.transform import resize \nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers as L\nfrom tensorflow.keras.applications import vgg16\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.optimizers import SGD, Adam, RMSprop\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\n\nimport imgaug as ia\nfrom imgaug import augmenters as iaa\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f2e19fec":"tf.__version__","efe6198b":"def plotImages(artist, directory):\n    \"\"\"Plot 25 images of an artist.\"\"\"\n    multipleImages = glob.glob(directory)\n    print(f\"{artist} has {len(multipleImages)} images\")\n    plt.rcParams['figure.figsize'] = (12, 12)\n    plt.subplots_adjust(wspace=0, hspace=0)\n    i_ = 0\n    for l in multipleImages[:25]:\n        im = cv2.imread(l)\n        \n        # Shrink image if too large\n        try:\n            im = cv2.resize(im, (128, 128))\n            plt.subplot(5, 5, i_+1) #.set_title(l)\n            plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n        except:\n            print(l)\n            pass\n        i_ += 1\n    plt.savefig(f\"{artist}.jpg\")","c75ed4a8":"%config InlineBackend.figure_format=\"svg\"\n%matplotlib inline\n\n\n# Reproducibility is importatnt. Always set the seed!\nseed=1234\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nia.seed(seed)","25cca855":"df = pd.read_csv('\/kaggle\/input\/best-artworks-of-all-time\/artists.csv', index_col=0)","25569730":"df.head()","ca1dc8bb":"genres = list(df['genre'].unique())\nprint(len(genres))\nsorted(genres)","6727d68a":"impressionists = df[(df['genre'] == 'Impressionism') | \n                    (df['genre'] == 'Realism,Impressionism') |\n                    (df['genre'] == 'Impressionism,Post-Impressionism')]\n\nimpressionists = impressionists.sort_values(by=[\"paintings\"], ascending=False)\nimpressionists","3eab518e":"impressionist_artists = impressionists['name'].values.tolist()\nimpressionist_artists = [artist.replace(\" \", \"_\") for artist in impressionist_artists] # match convention used in folder names\nimpressionist_artists","ab617105":"all_images_folders = glob.glob(\"\/kaggle\/input\/best-artworks-of-all-time\/images\/images\/*\")\nlen(all_images_folders)","e2c9d580":"impressionist_folders = [dir_ for dir_ in all_images_folders if dir_.split('\/')[-1] in  impressionist_artists]\nprint(len(impressionist_folders))\nimpressionist_folders","595ce282":"impressionist_images = []\nfor folder in impressionist_folders:\n  impressionist_images.extend(glob.glob(folder + \"\/*.jpg\", recursive=True))\n\nlen(impressionist_images)","b5441242":"impressioninst_df = pd.DataFrame(impressionist_images)\nimpressioninst_df.columns = ['filename']\nimpressioninst_df['genre'] = 'impressionist'\nimpressioninst_df.head()","3bcdb660":"artist_index = 0\nfolder = impressionist_folders[artist_index]\nartist = folder.split(\"\/\")[-1]\nplotImages(artist,  folder+'\/*.jpg')","dd21f2c2":"renaissance = df[(df['genre'] == 'Early Renaissance') | \n                    (df['genre'] == 'High Renaissance') |\n                    (df['genre'] == 'Northern Renaissance') |\n                    (df['genre'] == 'Proto Renaissance') |\n                    (df['genre'] == 'High Renaissance,Mannerism')]\n\nrenaissance = renaissance.sort_values(by=[\"paintings\"], ascending=False)\nrenaissance","9cbd3fca":"renaissance_artists = list(renaissance['name'].unique())\nprint(len(renaissance_artists))","fcc47307":"renaissance_artists = [artist.replace(\" \", \"_\") for artist in renaissance_artists] # match convention used in folder names\nrenaissance_artists","7d4d2cd8":"renaissance_folders = [dir_ for dir_ in all_images_folders if dir_.split('\/')[-1] in  renaissance_artists]\nprint(len(renaissance_folders))\nrenaissance_folders","216a1063":"renaissance_images = []\nfor folder in renaissance_folders:\n  renaissance_images.extend(glob.glob(folder + \"\/*.jpg\", recursive=True))\n\nlen(renaissance_images)","608d462b":"artist_index = 0\nfolder = renaissance_folders[artist_index]\nartist = folder.split(\"\/\")[-1]\nplotImages(artist,  folder+'\/*.jpg')","44381a25":"renaissance_df = pd.DataFrame(renaissance_images)\nrenaissance_df.columns = ['filename']\nrenaissance_df['genre'] = 'renaissance'\nrenaissance_df.head()","217ddf26":"train_df = pd.concat([renaissance_df, impressioninst_df.iloc[0:len(renaissance_df)]])\ntrain_df = shuffle(train_df)\ntrain_df.head()","da0592d1":"train_df['genre'].describe()","13c921cf":"# dimensions to consider for the images\nimg_rows, img_cols, img_channels = 224,224,3","5caa7d0f":"VALIDATION_SPLIT = 0.4\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=VALIDATION_SPLIT)","ec8678b4":"# batch size for training  \nbatch_size=16\n\n# total number of classes in the dataset\nnb_classes=2","5f90d7fe":"train_generator=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col=\"filename\",\n    y_col=\"genre\",\n    subset=\"training\",\n    batch_size=batch_size,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(224,224),\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n)","3e51f044":"valid_generator=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col=\"filename\",\n    y_col=\"genre\",\n    subset=\"validation\",\n    batch_size=batch_size,\n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(224,224),\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n)","281cc94d":"# Augmentation sequence \nseq = iaa.OneOf([\n    iaa.Fliplr(), # horizontal flips\n    iaa.Affine(rotate=20), # roatation\n    iaa.Multiply((1.2, 1.5))]) #random brightness","a36c336b":"def get_base_model():\n    base_model =  tf.keras.applications.vgg16.VGG16(input_shape=(img_rows, img_cols, img_channels), \n                       weights='imagenet', \n                       include_top=True)\n    return base_model\n\n# get the base model\nbase_model = get_base_model()","5afd44c2":"#  get the output of the second last dense layer \nbase_model_output = base_model.layers[-2].output\n\n# add new layers \nx = L.Dropout(0.5,name='drop2')(base_model_output)\noutput = L.Dense(nb_classes, activation='softmax', name='fc3')(x)","8ee80f6b":"We only have 1191 images in our dataset for each class, this is quite small","4a26b566":"## Data Augmentation\nWhen you have limited data, deep models don't do very well. Deep learning models are data hungry. The more data you provide to a deep learning model, the more it performance improves (until unless your algorithm has reached a limit). This is where data augmentation really comes handy. We will be using **[imgaug](https:\/\/github.com\/aleju\/imgaug)**, a very powerful library for augmenting our images. We will define a sequence of augmentations and for each image, one of these augmentations will be applied to the image during training","79917967":"Create a classifier to distinguish impressionist and renaissance images. Visualise the activation layers of the CNN","d64712c7":"Create a list of impressionists","cd78fee7":"Get the paths of all full images ","b075e7bc":"## EDA\nI am particularly interested identifying differences between impressionist and renaissance artists. The `artists.csv` provides into about each of the 50 artists","3c3433dc":"## Modelling\nWe will be doing transfer learning here and I am choosing vgg16 as the base network. You can choose whichever network you want. Also, as the dataset is very small and very very similar to Imagenet, we would make minimal changes in the network to keep the trainable parameters as few as possible","38a5b51e":"So we have more impressionist than renaissance images. Lets create a single dataframe with the file names and the renaissance\/impresisoninst labels and limit the number of impressionists to match the renaissance","d827ff66":"Appears its not possible to download the weights on Kaggle, what BS..","b5eb8dc7":"## Renaissance artists","467e1127":"## Combine impressionist and renaissance data\nTo train our classifier","5223ca65":"Get list of all impressionist images","f0de75db":"View some images","f13d5302":"Appears `Albrecht_D\u00fcrer` has no images","a5ee7d7c":"Create a dataframe to hold the image info","59008250":"Visualise an artist","07edffac":"## Setup DataGenerator\nWe will need to resize images as for VG16 The default input size for this model is 224x224."}}