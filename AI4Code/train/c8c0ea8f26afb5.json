{"cell_type":{"199d3faf":"code","408dbfe8":"code","d47ba8a5":"code","945a5aba":"code","c0d98394":"code","bf3c0368":"code","05436488":"code","ba757579":"code","a5027475":"code","5bfa5f85":"code","b96ea9e2":"code","0795ca6d":"code","234e36d6":"code","9ec1efb8":"code","d0b9c427":"code","6e8f777d":"code","f429a775":"code","4d24c208":"code","fc0e48a9":"code","f8e1cb53":"code","e3d66c1d":"code","8a6fea3c":"code","22311168":"code","94ba1fe3":"code","49b0d46b":"code","ee0b6357":"code","99f1c88e":"code","f0d0d633":"code","a2bd657d":"code","dcea2e87":"code","69c67515":"code","f7c4762a":"code","8caa2245":"code","0bead27b":"code","ff78b6de":"code","9b881188":"code","14c19d74":"code","22d84cc3":"code","9fd5edf6":"code","c987febd":"code","7ed31243":"code","efe58763":"code","363f5938":"code","563ae990":"code","0f28c605":"code","69d2b92c":"code","e333584e":"code","a31e567f":"code","25acebb6":"code","009f1fde":"code","4f477440":"code","8560b4c3":"code","2f7367b2":"code","dd18e59b":"code","e09ccc8f":"code","167ffe00":"code","63806fe6":"code","c873bc57":"code","70be16bc":"code","c055fb85":"code","9ce8f4ab":"code","08af5f44":"code","b99d209e":"code","d9bba33f":"code","c3729ac2":"code","0acc1e34":"code","c5c695b7":"code","1e075974":"code","4b5f3e41":"code","c638f7a3":"code","67857fd6":"code","a1f965c9":"code","eff82d82":"code","ef4e150a":"code","d1a0b599":"code","d77bdbd5":"code","2ad4286e":"code","88e327fe":"markdown","8af286b1":"markdown","3be49d2c":"markdown","152e516a":"markdown","92010943":"markdown","f6e22436":"markdown","ea6e9300":"markdown","2cbb2d76":"markdown","0b56f4b1":"markdown","f0b6afbf":"markdown","875717d5":"markdown","fd80f1fa":"markdown","8989cc6e":"markdown","65519081":"markdown","f5a583ad":"markdown","4f804a7a":"markdown","0c7df3af":"markdown","2a0d1c18":"markdown","1f21bdec":"markdown","4aee566e":"markdown","9397cda1":"markdown","9f00e18d":"markdown","3941df9f":"markdown","86a782e1":"markdown","b444de05":"markdown","aa2f09e2":"markdown","41c07b07":"markdown","ee708bb2":"markdown","69a134ab":"markdown","72ae15dd":"markdown","37b7dab1":"markdown","76f65a31":"markdown","c45e7ece":"markdown","9468e1f4":"markdown","1222e97e":"markdown","46139d37":"markdown","40f1fa9d":"markdown","eba6a40d":"markdown"},"source":{"199d3faf":"# Load Python libraries\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm.notebook import tqdm\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.graphics.gofplots import qqplot\nfrom scipy.stats import kstest\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom skimage.transform import resize\nimport colorsys\nfrom sklearn.cluster import KMeans\nfrom collections import Counter\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","408dbfe8":"PATH = \"..\/input\/petfinder-pawpularity-score\/\"\ntrain_df = pd.read_csv(\"\".join([PATH,\"train.csv\"]))\ntest_df = pd.read_csv(\"\".join([PATH,\"test.csv\"]))\nsubmission_df = pd.read_csv(\"\".join([PATH,\"sample_submission.csv\"]))","d47ba8a5":"train_df.head()","945a5aba":"print(f\"Number of images in Train set : {train_df.shape[0]}\")","c0d98394":"train_df.info()","bf3c0368":"test_df.head()","05436488":"print(f\"Number of images in Test set : {test_df.shape[0]}\")","ba757579":"submission_df.head()","a5027475":"sns.set(rc={'figure.figsize':(14,9)})","5bfa5f85":"fig = plt.figure()\nsns.histplot(data=train_df, x='Pawpularity', kde=True)\nplt.axvline(train_df['Pawpularity'].mean(), c='orange', ls='-', lw=3, label=\"Mean Pawpularity\")\nplt.title('Pawpularity score Histogram', fontsize=20, fontweight='bold')\nplt.legend()\nplt.show()","b96ea9e2":"fig = plt.figure()\nqqplot(train_df['Pawpularity'], line='s')\nplt.title('Quantile-Quantile plot of Pawpularity distribution', \n          fontsize=20, fontweight='bold')\nplt.show()","0795ca6d":"# Kolmogorov-Smirnov test with Scipy\nstat, p = kstest(train_df['Pawpularity'],'norm')\nprint('Statistics=%.3f, p=%.3f' % (stat, p))\n# interpret\nalpha = 0.05\nif p > alpha:\n    print(f'Sample looks Gaussian (fail to reject H0 at {int(alpha*100)}% test level)')\nelse:\n    print(f'Sample does not look Gaussian (reject H0 at {int(alpha*100)}% test level)')","234e36d6":"predictor = train_df.columns[1:-1]\n\nfig = plt.figure(figsize=(25,20))\nfor i, x in enumerate(predictor):\n    ax = plt.subplot(3,4,i+1)\n    sns.countplot(data=train_df, x=x, ax=ax)\n    ax.set_xlabel(None)\n    ax.set_title(x, fontweight='bold', color=\"#e7273e\")\n\nplt.suptitle(\"Predictor distribution\", y=0.93,\n             fontsize=20, fontweight='bold')\nplt.show()  ","9ec1efb8":"corr_matrix = train_df[predictor].corr()\nfig = plt.figure()\nsns.set_theme(style=\"white\")\nmask = np.triu(np.ones_like(corr_matrix, dtype=bool))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(corr_matrix, annot=True, fmt='.1g', cmap=cmap, \n            mask=mask, square=True)\nplt.title('Correlation Matrix', fontsize=20, fontweight='bold')\nplt.show()","d0b9c427":"# VIF dataframe\nvif_data = pd.DataFrame()\nX = train_df[predictor]\nvif_data[\"feature\"] = X.columns\n  \n# calculating VIF for each feature\nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n                          for i in range(len(X.columns))]  \nvif_data = vif_data.sort_values(\"VIF\", ascending=False)\nvif_data","6e8f777d":"X.drop(\"Face\", axis=1, inplace=True)\nX.columns","f429a775":"print(\"-\"*80)\nprint(\"Pearson correlation with Pawpularity (y)\")\nprint(\"-\"*80)\nfor x in X.columns:\n    corr_y = round(np.corrcoef(train_df[x], train_df[\"Pawpularity\"])[0,1],4)\n    print(f\"Pawpularity \/ {x}: {corr_y}\")\nprint(\"-\"*80)","4d24c208":"fig, ax = plt.subplots(2,3,figsize=(15,9))\nfig.patch.set_facecolor('#343434')\n\nfor i, a in zip(train_df[['Id', 'Pawpularity']].sample(6).iterrows(), ax.ravel()):\n    a.set(xticks=[], yticks=[])\n    img = plt.imread(PATH + \"train\/\" + i[1][0] + \".jpg\")\n    a.imshow(img)\n    a.set_title(f'Id: {i[0]}, Pawpularity Score: {i[1][1]}', color=\"white\")\n\nfig.suptitle('Pawpularity Images', fontsize=20, fontweight='bold', color=\"#e7273e\")\nfig.tight_layout()\nfig.show()","fc0e48a9":"fig, ax = plt.subplots(11, 2, figsize=(14,50))\nfig.patch.set_facecolor('#343434')\n\nfor a in ax.ravel():\n    a.set(xticks=[], yticks=[])\n\nfor r in range(11):\n    label = X.columns[r]\n    for i in [0, 1]:\n        img_id = train_df[train_df[label] == i].sample()['Id'].values[0]\n        img = plt.imread(PATH + f\"\/train\/{img_id}.jpg\")\n        ax[r, i].imshow(img)\n        ax[r, i].set_title(f'{label}={i}', color=\"white\")\n\nfig.tight_layout()\nfig.show()","f8e1cb53":"top = train_df[train_df['Pawpularity'] == 100]['Id']\n\nfig, ax = plt.subplots(1,3)\nfig.patch.set_facecolor('#343434')\n\nfor i, ax in zip(top.sample(3), ax.ravel()):\n    ax.set(xticks=[], yticks=[])\n    img = plt.imread(PATH + f\"\/train\/{i}.jpg\")\n    ax.imshow(img)\n    \nfig.suptitle('Most Pawpular Images', fontsize=20, fontweight='bold', color='#e7273e', y=0.95)\nfig.tight_layout()\nfig.show()","e3d66c1d":"bottom = train_df[train_df['Pawpularity'] == 1]['Id']\n\nfig, ax = plt.subplots(1,3)\nfig.patch.set_facecolor('#343434')\n\nfor i, ax in zip(bottom.sample(3), ax.ravel()):\n    ax.set(xticks=[], yticks=[])\n    img = plt.imread(PATH + f\"\/train\/{i}.jpg\")\n    ax.imshow(img)\n    \nfig.suptitle('Least Pawpular Images', fontsize=20, fontweight='bold', color='#e7273e', y=0.95)\nfig.tight_layout()\nfig.show()","8a6fea3c":"def get_dominant_color(image_path, k=4, image_processing_size = None):\n    \"\"\"\n    takes an image as input\n    returns the dominant color of the image as a list\n    \n    dominant color is found by running k means on the \n    pixels & returning the centroid of the largest cluster\n\n    processing time is speed up by working with a smaller image; \n    this resizing can be done with the image_processing_size param \n    which takes a tuple of image dims as input\n    \"\"\"\n    \n    image = plt.imread(image_path)\n    #resize image if new dims provided\n    if image_processing_size is not None:\n        image = cv2.resize(image, image_processing_size, \n                            interpolation = cv2.INTER_AREA)\n    \n    #reshape the image to be a list of pixels\n    image = image.reshape((image.shape[0] * image.shape[1], 3))\n\n    #cluster and assign labels to the pixels \n    clt = KMeans(n_clusters = k)\n    labels = clt.fit_predict(image)\n\n    #count labels to find most popular\n    label_counts = Counter(labels)\n\n    #subset out most popular centroid\n    dominant_color = clt.cluster_centers_[label_counts.most_common(1)[0][0]]\n    dominant_color = list(dominant_color)\n    r = int(dominant_color[0])\n    g = int(dominant_color[1])\n    b = int(dominant_color[2])\n    \n    #Convert to HLS color space\n    dominant_hls = colorsys.rgb_to_hls(r, g, b)\n\n    return list(dominant_hls)","22311168":"TRAIN_PATH = \"..\/input\/petfinder-pawpularity-score\/train\/\"\nTEST_PATH = \"..\/input\/petfinder-pawpularity-score\/test\/\"","94ba1fe3":"sample_img = TRAIN_PATH+\"0095f81bab3b68a4f70e99f0fcec7b06.jpg\"\nsample_hls = get_dominant_color(sample_img, k=3, image_processing_size = (50, 50))\nsample_dom_color = colorsys.hls_to_rgb(sample_hls[0],\n                                       sample_hls[1],\n                                       sample_hls[2])\nsample_dom_color = \"#{:02x}{:02x}{:02x}\".format(int(sample_dom_color[0]),\n                                                int(sample_dom_color[1]),\n                                                int(sample_dom_color[2]))\nprint(\"Dominant HLS : \", sample_hls)\nprint(\"Dominant Color Hex : \", sample_dom_color)\n\nfig = plt.figure(figsize=(12,5))\nax = fig.add_subplot(121)\nax = plt.imshow(plt.imread(sample_img))\nax2 = fig.add_subplot(122)\nrect1 = matplotlib.patches.Rectangle((0,0), 10, 5,color=sample_dom_color)\nax2.add_patch(rect1)\nplt.axis('off')\nplt.suptitle('Dominant color of sample image', fontsize=20, fontweight='bold', y=0.98)\nfig.tight_layout()\nplt.show()","49b0d46b":"tqdm.pandas()\ntrain_df[\"Dominant_color_hls\"] = train_df[\"Id\"].progress_apply(\n    lambda x : get_dominant_color(\n        TRAIN_PATH+x+\".jpg\", \n        k=3, \n        image_processing_size = (50, 50)))","ee0b6357":"HLS_train_df = train_df[\"Dominant_color_hls\"].apply(pd.Series)\nHLS_train_df = HLS_train_df.rename(columns={0:\"H\",1:\"L\",2:\"S\"})\ntrain_df = pd.concat([train_df, HLS_train_df], axis=1)\ntrain_df.drop(\"Dominant_color_hls\", axis=1, inplace=True)\ntrain_df.head()","99f1c88e":"fig = plt.figure(figsize=(20,6))\nax1 = fig.add_subplot(131)\nsns.histplot(train_df[\"H\"], ax=ax1)\nax1.set_title(\"Hue\", fontsize=17, color=\"#186fb4\")\nax2 = fig.add_subplot(132)\nsns.histplot(train_df[\"L\"], ax=ax2)\nax2.set_title(\"Luminance\", fontsize=17, color=\"#186fb4\")\nax3 = fig.add_subplot(133)\nsns.histplot(train_df[\"S\"], ax=ax3)\nax3.set_title(\"Saturation\", fontsize=17, color=\"#186fb4\")\nplt.suptitle('Dominant HLS color of train images', \n             fontsize=20, fontweight='bold', y=0.98)\nfig.tight_layout()\nplt.show()","f0d0d633":"test_df[\"Dominant_color_hls\"] = test_df[\"Id\"].progress_apply(\n    lambda x : get_dominant_color(\n        TEST_PATH+x+\".jpg\", \n        k=3, \n        image_processing_size = (50, 50)))","a2bd657d":"HLS_test_df = test_df[\"Dominant_color_hls\"].apply(pd.Series)\nHLS_test_df = HLS_test_df.rename(columns={0:\"H\",1:\"L\",2:\"S\"})\ntest_df = pd.concat([test_df, HLS_test_df], axis=1)\ntest_df.drop(\"Dominant_color_hls\", axis=1, inplace=True)\ntest_df.head()","dcea2e87":"def get_img_size(path):\n    width = []\n    height = []\n    landscape = []\n    for image_path in tqdm(os.listdir(path)):\n        image = plt.imread(path+image_path)\n        width.append(image.shape[1])\n        height.append(image.shape[0])\n        if(image.shape[1] > image.shape[0]):\n            landscape_img = 1\n        else:\n            landscape_img = 0\n        landscape.append(landscape_img)\n    return width, height, landscape","69c67515":"train_width, train_height, train_landscape = get_img_size(TRAIN_PATH)","f7c4762a":"train_df[\"width\"] = train_width\ntrain_df[\"height\"] = train_height\ntrain_df[\"landscape\"] = train_landscape\ntrain_df.head()","8caa2245":"test_width, test_height, test_landscape = get_img_size(TEST_PATH)","0bead27b":"test_df[\"width\"] = test_width\ntest_df[\"height\"] = test_height\ntest_df[\"landscape\"] = test_landscape\ntest_df.head()","ff78b6de":"ids = train_df[[\"Id\"]].values\ny = np.ravel(train_df[[\"Pawpularity\"]]\/100)\nX = train_df.drop([\"Id\", \"Pawpularity\"], axis=1)\nX_test = test_df.drop(\"Id\", axis=1)","9b881188":"# Normalization\nencoder = MinMaxScaler()\nencoder.fit(X)\nX_scaled = encoder.transform(X)\nX_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n\nX_test_scaled = encoder.transform(X_test)\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)","14c19d74":"X_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.3, random_state=42)\n\nprint(\"-\"*80)\nprint(\"Train and test split sizes\")\nprint(\"-\"*80)\nprint(f\"X_train : {X_train.shape}\")\nprint(f\"X_test : {X_valid.shape}\")\nprint(f\"y_train : {y_train.shape[0]}\")\nprint(f\"y_test : {y_valid.shape[0]}\")\nprint(\"-\"*80)","22d84cc3":"rfr = RandomForestRegressor(random_state=8)\nparam_grid = {\n            \"n_estimators\" : [10,50,100],\n            \"max_features\" : [\"log2\", \"sqrt\"],\n            \"max_depth\"    : [5,15,25],\n            \"bootstrap\"    : [True, False]\n        }\n\ngrid_rfr = GridSearchCV(\n    rfr,\n    param_grid,\n    cv = 5,\n    verbose=1,\n    n_jobs=-1)\n\nbest_rfr = grid_rfr.fit(X_train, y_train)","9fd5edf6":"print(\"-\"*80)\nprint(\"Best parameters for Random Forest model\")\nprint(\"-\"*80)\nprint(best_rfr.best_params_)\nprint(\"-\"*80)","c987febd":"importances = best_rfr.best_estimator_.feature_importances_\n\nfeature_names = X_train.columns\nforest_importances = pd.DataFrame(importances, columns=[\"FI\"], index=feature_names)\nforest_importances = forest_importances.sort_values(\"FI\", ascending=False)\n\nfig, ax = plt.subplots()\nsns.barplot(data=forest_importances, x = \"FI\", \n            y=forest_importances.index, ax=ax, \n            palette=\"Blues_d\")\nax.set_title(\"Feature importances of RandomForestRegressor\", \n             fontsize=20, fontweight='bold')\nax.set_xlabel(\"Mean decrease in impurity\")\nax.set_ylabel(\"Features\")\nfig.tight_layout()","7ed31243":"rfr_pred = best_rfr.predict(X_valid)","efe58763":"fig = plt.figure(figsize=(12,8))\nplt.scatter(x=rfr_pred, y=y_valid)\nplt.ylabel(\"Pawpularity real values (y_valid)\")\nplt.xlabel(\"Predicted values (rfr_pred)\")\nplt.title(\"Predicted Pawpularity VS True values with RandomForest\", \n          fontsize=20, fontweight='bold')\nplt.show()","363f5938":"# Laod Keras application Xception\nxcept_model = tf.keras.applications.Xception(\n    include_top=False,\n    weights=None,\n    input_shape=(299,299,3),\n    pooling=\"avg\"\n)\n\n# Load ImageNet weights pre-saved\nxcept_model.load_weights(\n    '..\/input\/resnet-imagenet-weights\/xception_imagenet_weights.h5')\n\n# Non trainable\nxcept_model.trainable = False","563ae990":"k_df = train_df[[\"Id\",\"Pawpularity\"]]\nk_df[\"Image\"] = k_df[\"Id\"].apply(lambda x: x+\".jpg\")\nk_df[\"Pawpularity\"] = k_df[\"Pawpularity\"]\/100\nk_df.head()","0f28c605":"k_X_train, k_X_valid, k_y_train, k_y_valid = train_test_split(\n    k_df[\"Image\"], k_df[\"Pawpularity\"], test_size=0.3, random_state=42)\n\nprint(\"-\"*80)\nprint(\"Train and test split sizes\")\nprint(\"-\"*80)\nprint(f\"X_train : {k_X_train.shape}\")\nprint(f\"X_test : {k_X_valid.shape}\")\nprint(f\"y_train : {k_y_train.shape[0]}\")\nprint(f\"y_test : {k_y_valid.shape[0]}\")\nprint(\"-\"*80)","69d2b92c":"k_train_df = pd.DataFrame(k_X_train, columns=[\"Image\"])\nk_train_df[\"Pawpularity\"] = k_y_train\nk_valid_df = pd.DataFrame(k_X_valid, columns=[\"Image\"])\nk_valid_df[\"Pawpularity\"] = k_y_valid","e333584e":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.xception.preprocess_input,\n    validation_split=0.2)\ntest_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.xception.preprocess_input)","a31e567f":"train_generator = datagen.flow_from_dataframe(\n    dataframe=k_train_df,\n    directory=PATH+\"train\/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    subset=\"training\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")\n\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe=k_train_df,\n    directory=PATH+\"train\/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    subset=\"validation\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")\n\ntest_generator = datagen.flow_from_dataframe(\n    dataframe=k_valid_df,\n    directory=PATH+\"train\/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")","25acebb6":"# Add new fully-connected layers\nbase_output = xcept_model.output\nbase_output = Dense(128, activation='relu')(base_output)\nbase_output = Dropout(0.2)(base_output)\n# Output : new classifier\npredictions = Dense(1, activation='linear')(base_output)\n\n# Define new model\nmy_xcept_model = Model(inputs=xcept_model.input,\n                       outputs=predictions)\nmy_xcept_model.compile(optimizer=\"adam\",\n                       loss=tf.keras.metrics.mean_squared_error)","009f1fde":"STEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\n\n# Early Stopping to prevent overfitting\nearly_stopper = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\", \n    patience=15, \n    verbose=2, \n    restore_best_weights=True)\n\nhistory_xcept = my_xcept_model.fit(\n    train_generator,\n    steps_per_epoch=STEP_SIZE_TRAIN,\n    validation_data=valid_generator,\n    validation_steps=STEP_SIZE_VALID,\n    epochs=50,\n    verbose=2,\n    callbacks=[early_stopper])","4f477440":"fig = plt.figure(figsize=(12, 7))\nplt.plot(history_xcept.history[\"loss\"],\n         color=\"#186fb4\", linestyle=\"-.\",\n         label=\"Train\")\nplt.plot(history_xcept.history[\"val_loss\"],\n         color=\"#186fb4\",\n         label=\"Validation\")\nplt.legend()\nplt.title(\"RMSE metric of Xception model for Pawpularity\", \n          fontsize=20, fontweight='bold')\nplt.show()","8560b4c3":"xcept_pred = my_xcept_model.predict(test_generator)\nxcept_pred.shape","2f7367b2":"fig = plt.figure(figsize=(12,8))\nplt.scatter(x=xcept_pred, y=k_y_valid)\nplt.ylabel(\"Pawpularity real values (k_y_valid)\")\nplt.xlabel(\"Predicted values (xcept_pred)\")\nplt.title(\"Predicted Pawpularity VS True values with Xception\", \n          fontsize=20, fontweight='bold')\nplt.show()","dd18e59b":"datagen_v2 = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=10, # rotation\n    width_shift_range=0.2, # horizontal shift\n    height_shift_range=0.2, # vertical shift\n    zoom_range=0.2, # zoom\n    horizontal_flip=True, # horizontal flip\n    preprocessing_function=tf.keras.applications.xception.preprocess_input,\n    validation_split=0.2)","e09ccc8f":"train_generator_v2 = datagen_v2.flow_from_dataframe(\n    dataframe=k_train_df,\n    directory=PATH+\"train\/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    subset=\"training\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")\n\nvalid_generator_v2 = datagen_v2.flow_from_dataframe(\n    dataframe=k_train_df,\n    directory=PATH+\"train\/\",\n    x_col=\"Image\",\n    y_col=\"Pawpularity\",\n    subset=\"validation\",\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"raw\")","167ffe00":"STEP_SIZE_TRAIN = train_generator_v2.n\/\/train_generator_v2.batch_size\nSTEP_SIZE_VALID = valid_generator_v2.n\/\/valid_generator_v2.batch_size","63806fe6":"tf.keras.backend.clear_session()\nhistory_xcept_v2 = my_xcept_model.fit(\n    train_generator_v2,\n    steps_per_epoch=STEP_SIZE_TRAIN,\n    validation_data=valid_generator_v2,\n    validation_steps=STEP_SIZE_VALID,\n    epochs=50,\n    verbose=2,\n    callbacks=[early_stopper])","c873bc57":"fig = plt.figure(figsize=(12, 7))\nplt.plot(history_xcept_v2.history[\"loss\"],\n         color=\"#186fb4\", linestyle=\"-.\",\n         label=\"Train\")\nplt.plot(history_xcept_v2.history[\"val_loss\"],\n         color=\"#186fb4\",\n         label=\"Validation\")\nplt.legend()\nplt.title(\"RMSE metric of Xception augmented model for Pawpularity\", \n          fontsize=20, fontweight='bold')\nplt.show()","70be16bc":"xcept_pred_v2 = history_xcept_v2.model.predict(test_generator)\nxcept_pred_v2.shape","c055fb85":"fig = plt.figure(figsize=(12,8))\nplt.scatter(x=xcept_pred_v2, y=k_y_valid)\nplt.ylabel(\"Pawpularity real values (k_y_valid)\")\nplt.xlabel(\"Predicted values (xcept_pred)\")\nplt.title(\"Predicted Pawpularity VS True values with Xception\", \n          fontsize=20, fontweight='bold')\nplt.show()","9ce8f4ab":"def feature_detect_img(folder, img_size=299):\n    listVectors = []\n    for img in tqdm(os.listdir(PATH+folder+\"\/\")):\n        image = plt.imread(PATH+folder+\"\/\"+img)\n        #resize image if new dims provided\n        image = cv2.resize(image, (img_size,img_size),\n                           interpolation = cv2.INTER_AREA)\n        image = np.expand_dims(image, axis=0)\n        image = tf.keras.applications.xception.preprocess_input(image)\n        \n        img_vector = xcept_model.predict(image)\n        listVectors.append(np.array(img_vector))\n    \n    return listVectors","08af5f44":"train_vectors_fd = feature_detect_img(\"train\", img_size=299)","b99d209e":"train_vectors_fd = np.array(train_vectors_fd)\ntrain_vectors_fd = np.squeeze(train_vectors_fd)\ntrain_vectors_fd.shape\ntrain_vectors_fd = pd.DataFrame(train_vectors_fd)","d9bba33f":"hy_train_df = pd.concat([train_df,train_vectors_fd], axis=1)\nhy_train_df.head(3)","c3729ac2":"h_labels = hy_train_df[\"Id\"]\nh_y = hy_train_df[\"Pawpularity\"]\nh_X = hy_train_df.drop([\"Id\",\"Pawpularity\"], axis=1)\n\n# Normalization\nencoder = MinMaxScaler()\nencoder.fit(h_X)\nh_X_scaled = encoder.transform(h_X)\nh_X_scaled = pd.DataFrame(h_X_scaled, columns=h_X.columns)\n\nh_X_train, h_X_valid, h_y_train, h_y_valid = train_test_split(\n    h_X_scaled, h_y, test_size=0.3, random_state=42)\n\nprint(\"-\"*80)\nprint(\"Train and test split sizes\")\nprint(\"-\"*80)\nprint(f\"X_train : {h_X_train.shape}\")\nprint(f\"X_test : {h_X_valid.shape}\")\nprint(f\"y_train : {h_y_train.shape[0]}\")\nprint(f\"y_test : {h_y_valid.shape[0]}\")\nprint(\"-\"*80)","0acc1e34":"h_rfr = RandomForestRegressor(random_state=8)\nparam_grid = {\n            \"n_estimators\" : [10,50,100],\n            \"max_features\" : [\"log2\", \"sqrt\"],\n            \"max_depth\"    : [5,15,25],\n            \"bootstrap\"    : [True, False]\n        }\n\nh_grid_rfr = GridSearchCV(\n    h_rfr,\n    param_grid,\n    cv = 5,\n    verbose=1,\n    n_jobs=-1)\n\nh_best_rfr = h_grid_rfr.fit(h_X_train, h_y_train)","c5c695b7":"print(\"-\"*80)\nprint(\"Best parameters for Random Forest model\")\nprint(\"-\"*80)\nprint(h_best_rfr.best_params_)\nprint(\"-\"*80)","1e075974":"h_rfr_pred = h_best_rfr.predict(h_X_valid)","4b5f3e41":"fig = plt.figure(figsize=(12,8))\nplt.scatter(x=h_rfr_pred, y=h_y_valid)\nplt.ylabel(\"Pawpularity real values (y_valid)\")\nplt.xlabel(\"Predicted values (rfr_pred)\")\nplt.title(\"Predicted Pawpularity VS True values with RandomForest\", \n          fontsize=20, fontweight='bold')\nplt.show()","c638f7a3":"test_vectors_fd = feature_detect_img(\"test\", img_size=299)","67857fd6":"test_vectors_fd = np.array(test_vectors_fd)\ntest_vectors_fd = np.squeeze(test_vectors_fd)\ntest_vectors_fd.shape\ntest_vectors_fd = pd.DataFrame(test_vectors_fd)","a1f965c9":"hy_test_df = pd.concat([test_df,test_vectors_fd], axis=1)\nhy_test_df.head(3)","eff82d82":"h_test_labels = hy_test_df[\"Id\"]\nh_X_test = hy_test_df.drop(\"Id\", axis=1)\nh_X_test_scaled = encoder.transform(h_X_test)\nh_X_test_scaled = pd.DataFrame(h_X_test_scaled, columns=h_X_test.columns)","ef4e150a":"submission_pred = h_best_rfr.predict(h_X_test_scaled)","d1a0b599":"fig = plt.figure(figsize=(10,7))\nplt.hist((submission_pred))\nplt.xlabel(\"Pawpularity Score\")\nplt.ylabel(\"number of individuals\")\nplt.title(\"Distribution of predicted submission results\", \n          fontsize=20, fontweight='bold')\nplt.show()","d77bdbd5":"submission_df[\"Pawpularity\"] = (submission_pred)\nsubmission_df = submission_df[[\"Id\",\"Pawpularity\"]]\nsubmission_df.head()","2ad4286e":"submission_df.to_csv(\"submission.csv\", sep=\",\", index=False)","88e327fe":"We will nevertheless **make a first submission to obtain a baseline**.\n\n# <span style=\"color: #186fb4\" id=\"section_5\">Competition submission on Test set<\/span>","8af286b1":"In this [competition](https:\/\/www.kaggle.com\/c\/petfinder-pawpularity-score), we\u2019ll analyze raw images and metadata to predict the **\u201cPawpularity\u201d of pet photos**. We'll train and test your model on PetFinder.my's thousands of pet profiles.\n\nIn this first Notebook, we will perform a quick exploratory analysis of the data and try to define new variables by feature engineering.\n\n<span style=\"color:red\">**Of course, if the Notebook helps you, don't hesitate to upvote!**<\/span>","3be49d2c":"This time again, **the predictions are very disparate and do not reflect the real values**. The processing of the images only part is therefore not a good solution for this competition *(Xception generally obtaining good results on image processing)*. ","152e516a":"# <span style=\"color: #186fb4; font-variant:small-caps;\" id=\"sommaire\">Summary<\/span>\n\n1. [Exploratory Data Analysis](#section_1)     \n2. [Feature Engineering](#section_2)\n2. [Are these features really important ?](#section_3)      \n3. [Modeling on Dataset images by Transfert Learning](#section_4)      \n4. [Competition submission on Test set](#section_5)","92010943":"In the train.csv file, there is an image identification variable: **Id**.\nThen, **12 binary variables** give us a quick description of the image *(Action, Blur, Human ...)*.\nFinally, the Pawpularity variable is our **target variable *(y)*** which gives the popularity of the image on a score between 0 and 100. We also note that **there is no missing data** in this dataset\n\n### Test file","f6e22436":"# <span style=\"color: #186fb4\" id=\"section_5\">Transfert Learning optimization<\/span>\n\nNow, we are going to do a preprocessing of our images to try to improve the algorithm.","ea6e9300":"We are now going to **apply this function to all the datasets** :","2cbb2d76":"We can see perfectly here that **the only modelization with the variables of the CSV file does not make it possible to obtain satisfactory performances**. RandomForest is very uncertain in its predictions which are concentrated on the 0.35 \/ 0.41 area. We will have to try another approach.\n\n# <span style=\"color: #186fb4\" id=\"section_4\">Modeling on Dataset images by Transfert Learning<\/span>\n\nHere we will use only the image data and perform transfer learning modeling with an **Xception model trained on ImageNet**.","0b56f4b1":"For better use in Tensorflow \/ Keras, we will **create generators by slightly modifying our DataFrame Pandas**. We will indeed add the name *(and extension)* of the image files to our y DataSets.","f0b6afbf":"The test file has the same fields, excluding the predictable variable `Pawpularity`. The **test set only has 8 images** against 9,912 images for training.\n\n### Submission file","875717d5":"We notice the deviation at this QQPlot which seems to indicate a non-Gaussian distribution. We will check with the **Kolmogorov-Smirnov test** *(Shapiro-Wilks is not suitable for a dataset greater than 5000 items)*.","fd80f1fa":"It can therefore be seen that **there is no linear correlation between the variable to be predicted and the predictive variables**.\n\n## <span style=\"color: #e7273e\" id=\"section_1_6\">Viewing sample training images<\/span>\n\nLet's start by viewing a few random images","8989cc6e":"The augmented model looks a bit better but still fails to predict popularity scores reliably enough.\n\n# <span style=\"color: #186fb4\" id=\"section_6\">Hybrid approach with feature detection and RandomForest<\/span>\n\nWe are therefore going to **test a last hybrid approach** consisting in carrying out the feature detection with Xception, then in coupling the results with the database of image characteristics to finally predict $y$ with a RandomForestRegressor.","65519081":"```Python\nsubmission_pred = my_xcept_model.predict(submission_generator)\nsubmission_pred.shape\n```","f5a583ad":"2 main correlations stand out *(> 0.5)*:\n- The first between **Occlusion and Human** *(Humans can hide part of the animal)*\n- The second between **Face and Eyes** which this time may seem logical.\n\nWe also need to check if there is too much **multicollinearity** that could degrade the performance of our models. For this we will use **VIF** : \n\n$$ \\large VIF = \\frac{1}{1- R^2}$$\n\nWhere, $R^2$ is the coefficient of determination in linear regression. Its value lies between 0 and 1.","4f804a7a":"For the submission file, we will need to provide the ID of the tested image as well as the popularity prediction between 0 and 100.\n\n## <span style=\"color: #e7273e\" id=\"section_1_2\">Pawpularity distribution<\/span>\n\nLet us now look at the distribution of the variable to be predicted in the train set","0c7df3af":"## <span style=\"color: #e7273e\" id=\"section_1_7\">Define final Dataset for training<\/span>\n\nFor the variable to be predicted *(y = Pawpularity)*, **we are going to reduce its value between 0 and 1** so that they are more understandable for the models.","2a0d1c18":"## <span style=\"color: #e7273e\" id=\"section_1_5\">Correlations between predictor variables and Pawpularity<\/span>\n\nWe will now check whether there are strong linear correlations *(Pearson)* between the predictor variables and the variable to be predicted *(Pawpularity)*.","1f21bdec":"As we can see, Face and Eyes have very high values of VIF, indicating that these two variables are highly correlated. Hence, considering these two features together leads to a model with high multicollinearity. **We will therefore use only one of these 2 variables for the modelizations**. \n\nWe remove the variable that has the highest VIF.","4aee566e":"We have now stored all the variables that we will need for our models. We will be able to create the final datasets. It will also be necessary to **standardize the data which are now on different scales**. We will use standardization thanks to StandardScaler from ScikitLearn.","9397cda1":"The test clearly indicates that the distribution does not follow a Gaussian law. **It will therefore be important to normalize the data according to the modeling chosen**.\n\n\n## <span style=\"color: #e7273e\" id=\"section_1_3\">Distribution of the predictor variables<\/span>\nWe will now take a quick look at the distribution of the predictor variables.","9f00e18d":"Let's look at the effect of this function on a test image :","3941df9f":"At the moment, it seems difficult to understand the difference between images that have a high popularity and those that do not win many votes. We also see that the orientations and sizes of images are different. \n\nWe will now look at the **differences between the predictor variables at 0 or 1**.","86a782e1":"The distribution of the predictor variables shows clear differences that are difficult to interpret for the moment.\n\n## <span style=\"color: #e7273e\" id=\"section_1_4\">Correlations between predictor variables<\/span>\n\nWe will see if there are marked correlations between our different predictor variables by calculating the **correlation matrix**.","b444de05":"## <span style=\"color: #e7273e\" id=\"section_2_2\">Original image resolution<\/span>\nFor our image processing algorithms, we will have to perform resize to obtain *input_shape* conforming to what the models expect. We are therefore going to **save the initial size of the image in a variable** *(which could have an impact on the popularity of the photo)*.","aa2f09e2":"Then, we will plot the **importance of features** in the modeling:","41c07b07":"We notice that the **Accessory, Near, Group and Info** variables have a greater importance in the decisions, without being in a very different order of magnitude.\n\nNow we will **perform the predictions with this model on the validation set** to check the performance and distribution of the predicted values compared to the actual values.","ee708bb2":"# <span style=\"color: #186fb4\" id=\"section_1\">Exploratory Data Analysis<\/span>\n\nThe data architecture is made up of 2 files: test and train each containing images of pets. 3 CSV files are also available. We will first look at the structure of these files.\n\n## <span style=\"color: #e7273e\" id=\"section_1_1\">CSV files<\/span>","69a134ab":"It's hard to explain when you see them what really differentiates the most popular images from the less popular ones ...\n\n# <span style=\"color: #186fb4\" id=\"section_2\">Feature Engineering<\/span>\n\nNow we are going to create new features.\n\n## <span style=\"color: #e7273e\" id=\"section_2_1\">Extract dominant color of each image with KMeans<\/span>\n\nSome photography experts agree that **the dominant color of an image can unconsciously affect its popularity** *(as well as overall exposure for that matter)*. We are therefore going to create a variable that will store the dominant color of each image. \n\nTo do this, we will use **clustering methods on the RGB layers** of our jpg files to extract the dominant color in HLS *(Hue Lightness Saturation)* format. This format will allow us to recover in a single formula the information on the **hue, saturation and luminance of the dominant color of each image**.","72ae15dd":"We see on the results plot that the RMSE metric follows a beautiful desendent curve in training but **struggles to drop in validation**. We will, as for RandomForest, carry out the predictions on the validation set.","37b7dab1":"Note that the distribution of the variable $y$ is centered on the scores between 20 and 30. We will **check the normality** of the distribution with a quantile - quantile diagram.","76f65a31":"Finally, we will project the **top 3 most popular and least popular images** to see if the difference is marked and humanly understandable.","c45e7ece":"After training the GrisSearchCV, we can extract the **best parameters** from the model:","9468e1f4":"![petfinder_baner](http:\/\/www.mf-data-science.fr\/images\/projects\/petfinder_baner.jpg)","1222e97e":"### Train file","46139d37":"**The submission RMSE score on this Baseline model *(based on images only)* is approximately 25.96**.\nWe will explore a multimodal approach in a second Notebook: https:\/\/www.kaggle.com\/michaelfumery\/pawpularity-multimodal-cnn","40f1fa9d":"# <span style=\"color: #186fb4\" id=\"section_3\">Are these features really important ?<\/span>\n\nTo check if the features at our disposal are really important, we will first model our data with **RandomForest and look at the importance of the features**.\n\n## <span style=\"color: #e7273e\" id=\"section_2_1\">RandomForest on binary features<\/span>\nWe will also apply a **GridSearchCV to find the best hyperparameters**.","eba6a40d":"```Python\nsubmission_df = pd.read_csv(\"\".join([PATH,\"test.csv\"]))\nsubmission_df = submission_df[[\"Id\"]]\nsubmission_df[\"Image\"] =  submission_df[\"Id\"].apply(lambda x: x+\".jpg\")\n\nsubmission_generator = test_datagen.flow_from_dataframe(\n    dataframe=submission_df,\n    directory=PATH+\"test\/\",\n    x_col=\"Image\",\n    y_col=None,\n    target_size=(299,299),\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=None)\n```"}}