{"cell_type":{"a98a6f39":"code","4c2da84e":"code","8862fa33":"code","63ca45d0":"code","d21cd8a7":"code","86f25c0e":"code","db9d826c":"code","7419eeb2":"code","4d797d80":"code","1ef4e154":"code","4eb74258":"code","77302cf4":"code","8f8bbc08":"code","61d672aa":"code","89613836":"code","21d1987d":"code","fcf0ad69":"code","c2337dd3":"code","f421f4d9":"code","c7399efa":"code","3217392d":"code","326c57c7":"code","346cfd6a":"code","d45cbc55":"code","973c7a69":"code","a37ad04a":"code","92e885f3":"code","0fd03717":"code","0b056aa2":"code","ae1b7724":"code","e1cafa8a":"code","6fd25a3a":"code","4312f645":"markdown","a8c2f9ca":"markdown","cb7b47a8":"markdown","d74325cf":"markdown","e77729c8":"markdown","dd8f3341":"markdown","bd8273de":"markdown","8a107449":"markdown","77ec0dee":"markdown","15a5fc9b":"markdown","ac4a1552":"markdown","58b6cd62":"markdown"},"source":{"a98a6f39":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\nplt.style.use(['seaborn-bright','dark_background'])","4c2da84e":"data = pd.read_csv('\/kaggle\/input\/california-housing-prices\/housing.csv')\ndata.head()","8862fa33":"data.isnull().sum()","63ca45d0":"for i in data.columns:\n    prct_missing = np.mean(data[i].isnull())\n    print(\"{} = {}%\".format(i,prct_missing*100))","d21cd8a7":"data = data.dropna(axis=0)","86f25c0e":"plt.figure(figsize=(10,5))\nsns.boxplot('longitude',data = data,palette=\"Blues\")\nplt.title('Longitude',fontsize=15)\nplt.show()","db9d826c":"plt.figure(figsize=(10,5))\nsns.boxplot('latitude',data = data,palette=\"plasma\")\nplt.title('Latitude',fontsize=15)\nplt.show()","7419eeb2":"plt.figure(figsize=(10,5))\nsns.boxplot('housing_median_age',data = data,palette=\"hsv\")\nplt.title('Housing Median Age',fontsize=15)\nplt.show()","4d797d80":"plt.figure(figsize=(10,5))\nsns.boxplot('total_rooms',data = data,palette=\"flag\")\nplt.title('Total Rooms',fontsize=15)\nplt.show()","1ef4e154":"plt.figure(figsize=(10,5))\nsns.boxplot('total_bedrooms',data = data,palette=\"YlGn\")\nplt.title('Total Bedrooms',fontsize=15)\nplt.show()","4eb74258":"plt.figure(figsize=(10,5))\nsns.boxplot('population',data = data,palette=\"PuOr\")\nplt.title('Population',fontsize=15)\nplt.show()","77302cf4":"plt.figure(figsize=(10,5))\nsns.boxplot('households',data = data,palette=\"Purples\")\nplt.title('Households',fontsize=15)\nplt.show()","8f8bbc08":"plt.figure(figsize=(10,5))\nsns.boxplot('median_income',data = data,palette=\"Reds\")\nplt.title('Median Income',fontsize=15)\nplt.show()","61d672aa":"plt.figure(figsize=(10,5))\nsns.boxplot('median_house_value',data = data,palette=\"bone\")\nplt.title('Median House Value',fontsize=15)\nplt.show()","89613836":"data.describe()","21d1987d":"def IQR(col):\n    q1 = data[col].quantile(0.25)\n    q3 = data[col].quantile(0.75)\n    iqr = q3 - q1\n    return iqr,q1,q3","fcf0ad69":"def whisker(col):\n    iqr,q1,q3 = IQR(col)\n    lower_whisker = q1 - 1.5*iqr\n    upper_whisker = q3 + 1.5*iqr\n    return lower_whisker,upper_whisker","c2337dd3":"for col in data.columns:\n    if data[col].dtype!=\"object\":\n        lw,uw = whisker(col)\n        print(\"Feature:-{} Lower:-{} Upper:-{}\".format(col,lw,uw))","f421f4d9":"def treat_outliers(value):\n    lower_limit,upper_limit = whisker(col)\n    data[col] = np.where(data[col]<lower_limit,lower_limit,data[col])\n    data[col] = np.where(data[col]>upper_limit,upper_limit,data[col])","c7399efa":"for col in data.columns:\n    if data[col].dtype!=\"object\":\n        treat_outliers(col)","3217392d":"data.describe()","326c57c7":"data.nunique()","346cfd6a":"data['ocean_proximity'].value_counts()","d45cbc55":"data.drop(data[data['ocean_proximity']==\"ISLAND\"].index, inplace = True) ","973c7a69":"data.shape","a37ad04a":"data.shape","92e885f3":"data_remove_duplicates = pd.DataFrame.drop_duplicates(data)","0fd03717":"data_remove_duplicates.shape","0b056aa2":"data['ocean_proximity'] = data['ocean_proximity'].str.lower()","ae1b7724":"data['ocean_proximity'].value_counts()","e1cafa8a":"data['ocean_proximity'] = data['ocean_proximity'].str.replace(\" \",\"_\")","6fd25a3a":"data['ocean_proximity'].value_counts()","4312f645":"## Treating Outliers.\n#### Like missing values we can drop the rows or columns , or replace the outliers with the  mean or median values.\n#### We can drop the rows with value lower than lower whisker or upper than upper whisker.\n#### Now here we replace the outliers with the lower whisker and upper whisker. These whiskers can be calculated by using inter quartile range(IQR). The formula for IQR is IQR = 3rd quantile - 1st quantile.","a8c2f9ca":"### Importing the required libraries and the dataset.","cb7b47a8":"## Duplicate values\n#### Our data set may contain some rows with exact same data values for all features , we can drop that rows to lower dataset size.","d74325cf":"## Identify outliers\n#### Using the describe method or plots like histogram , heatmap , scatter plot ot box-plot we can identify outliers.","e77729c8":"#### Here other than ocean proximity all features are numeric. So ocean_proximity consists of 5 unique value out of which ISLAND consists of only 5 value counts. So by droping the rows with ISLAND in feature dosen't impact our dataset so much.","dd8f3341":"### Computing the missing value percentage in data.","bd8273de":"#### Our data may contain spelling mistakes or white spaces in categorical values or measurement units in numeric values ,so can can replace white spaces or units and correct spells of categorical values.","8a107449":"## Non relatable data.\n#### Sometimes our data set consists of feature that does not impact our data set or is not inportant or informative we can drop the column.","77ec0dee":"#### Now converting the data in ocean proximity to lower case","15a5fc9b":"## Inconsistence categorical values\n#### Sometimes our data contain inconsistence data strings like iSlAnD or date and time 12-03-12 , we can treat these values by converting categorical values to lower case and extracting date, day , month ,time ,etc from date data.","ac4a1552":"## Column with repetative value.\n#### Whenever we see any case like a column consists of a maximum percent of same data or a data which is very less in percent as compare to other we can drop the entire column.","58b6cd62":"## Treating the missing values\n#### 1. Droping entire columns:- Whenever we see that column consists of maximum data missing we drop that column , otherwise we choose take another method to treat missing values.\n#### 2. Replace the values:- Sometimes we can replace the missing values as per our requirements like by numeric value for numeric feature and by any string for categorical value.\n#### 3. Imputing :- The missing values can be imputed by using the mean\/average value or median value  for numeric feature and by most frequent i.e. mode for categorical feature.\n#### 4. Drop the rows:- If the missing value percentage is very less as compare to total percentage of data we can drop the rows which consists of missing values as we done in this case. Here total_bedrooms feature contain only 1% data missing so we drop the rows with missing values."}}