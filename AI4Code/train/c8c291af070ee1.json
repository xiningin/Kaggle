{"cell_type":{"1cfc6d2d":"code","769087ef":"code","f328c5d7":"code","60326216":"code","ab44cb5b":"code","13144900":"code","dcea8acf":"code","2bf7fd8c":"code","c97981ad":"code","4cb6aab3":"code","abf3e027":"code","b26c987f":"code","d7ded4fe":"code","a166c3a9":"code","acbc3e70":"code","20fa05ae":"code","90f553e3":"code","6970056a":"code","e85f8e8d":"code","90a84353":"code","eec31bf3":"code","79f2f755":"code","25eeb4db":"code","dfa7655e":"code","9bbe69e7":"code","44c47306":"code","e2eefade":"code","d71812dd":"code","849ae780":"code","076c43c5":"code","24ffb8a5":"code","26bc4a24":"code","a68269dc":"code","f4e6319d":"code","d16a059c":"code","728e96d8":"code","c8adaa0c":"code","48d55c48":"code","d78c71c2":"code","faca2975":"markdown","4ecd36a4":"markdown","381a9de6":"markdown","28644a5f":"markdown","bbfabe30":"markdown","12a0ee25":"markdown","aea214ef":"markdown","f42ffbf9":"markdown","e2699a7d":"markdown","2be7c54b":"markdown","afecc7d1":"markdown","7fb0289b":"markdown","ccd48e8d":"markdown","b79dbea5":"markdown","68be0e2f":"markdown","5aa84fb9":"markdown","dacaa046":"markdown","d241f8fd":"markdown","5fdc6a2d":"markdown","7c82990d":"markdown","e2db8cfa":"markdown","137515a3":"markdown","8219d2f0":"markdown"},"source":{"1cfc6d2d":"# Basic library\nimport numpy as np \nimport pandas as pd \nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","769087ef":"# Visualization\nimport matplotlib.pyplot as plt\nplt.style.use(\"fivethirtyeight\")\nimport seaborn as sns","f328c5d7":"# Time series analysis library\nimport statsmodels.api as sm\nimport statsmodels.graphics.api as smg\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.ar_model import AR\nfrom statsmodels.tsa import stattools as st\nfrom statsmodels.tsa.arima_model import ARMA,ARIMA\n!pip install arch\nfrom arch import arch_model","60326216":"# data loading\ndf = pd.read_csv(\"\/kaggle\/input\/avocado-prices\/avocado.csv\", header=0)","ab44cb5b":"# data head\ndf.head()","13144900":"# null value\ndf.isnull().sum()","dcea8acf":"# Change date to datetime type and set index\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"])","2bf7fd8c":"# pivot by type and Date\npivot = pd.pivot_table(df, index=\"Date\", columns=\"type\", values=\"AveragePrice\", aggfunc=\"mean\")","c97981ad":"pivot.head() # Date is per week","4cb6aab3":"# data set, separate conventional and organic\nconv = pivot[\"conventional\"]\norga = pivot[\"organic\"]\n\n# Visualization\nplt.figure(figsize=(10,6))\nplt.plot(conv.index, conv, label=\"conventional\")\nplt.plot(orga.index, orga, label=\"organic\")\nplt.xlabel(\"date\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Average price\")\nplt.legend()","abf3e027":"data = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata[\"diff\"] = data[\"price\"].diff() # difference\ndata[\"ch_rate\"] = data[\"price\"].pct_change() # rate of change\ndata[\"log_ch_rate\"] = np.log(data[\"price\"]\/data[\"price\"].shift(1)) # Logarithmic change rate\n\ndata.set_index(\"date\", inplace=True)","b26c987f":"# difference Visualization\nplt.figure(figsize=(20,6))\nplt.plot(data.index, data[\"diff\"], label=\"difference\", color=\"blue\", linewidth=1)","d7ded4fe":"# rate of change Visualization\nplt.figure(figsize=(20,6))\nplt.plot(data.index, data[\"ch_rate\"], label=\"rate of change\", color=\"blue\", linewidth=1)","a166c3a9":"# Logarithmic change rate Visualization\nplt.figure(figsize=(20,6))\nplt.plot(data.index, data[\"log_ch_rate\"], label=\"Logarithmic change rate\", color=\"blue\", linewidth=1)","acbc3e70":"# calculation\nwindow=4\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata[\"min\"] = data[\"price\"].rolling(window=window).min()\ndata[\"max\"] = data[\"price\"].rolling(window=window).max()\ndata[\"mean_short\"] = data[\"price\"].rolling(window=window).mean()\ndata[\"mean_long\"] = data[\"price\"].rolling(window=12).mean()\n\ndata.set_index(\"date\", inplace=True)","20fa05ae":"# Visualization\nplt.figure(figsize=(20,6))\nplt.plot(data.index, data[\"price\"], label=\"price\", color=\"blue\", linewidth=1)\nplt.plot(data.index, data[\"min\"], label=\"min\", color=\"blue\", linestyle='--', linewidth=0.5)\nplt.plot(data.index, data[\"max\"], label=\"max\", color=\"blue\", linestyle='--', linewidth=0.5)\nplt.plot(data.index, data[\"mean_short\"], label=\"mean_4_short\", color=\"red\", linestyle='-', linewidth=1)\nplt.plot(data.index, data[\"mean_long\"], label=\"mean_12_long\", color=\"green\", linestyle='-', linewidth=1)\nplt.xlabel(\"date\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Price\")\nplt.legend()","90f553e3":"# Create dataframe\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata.set_index(\"date\", inplace=True)\n\n# Stats model\nres = sm.tsa.seasonal_decompose(data[\"price\"], freq=52)\n\n# Decomposition\ndata[\"trend\"] = res.trend\ndata[\"seaso\"] = res.seasonal\ndata[\"resid\"] = res.resid","6970056a":"# Visualization\nfig, ax = plt.subplots(4,1, figsize=(20,15))\nax[0].plot(data.index, data[\"price\"], label=\"price\", color=\"blue\", linewidth=1)\nax[0].set_xlabel(\"date\")\nax[0].set_ylabel(\"price\")\n\nax[1].plot(data.index, data[\"trend\"], label=\"trend\", color=\"blue\", linewidth=1)\nax[1].set_xlabel(\"date\")\nax[1].set_ylabel(\"trend\")\n\nax[2].plot(data.index, data[\"seaso\"], label=\"seasonaly\", color=\"blue\", linewidth=1)\nax[2].set_xlabel(\"date\")\nax[2].set_ylabel(\"seasonaly\")\n\nax[3].plot(data.index, data[\"resid\"], label=\"residual error\", color=\"blue\", linewidth=1)\nax[3].set_xlabel(\"date\")\nax[3].set_ylabel(\"residual error\")","e85f8e8d":"# Create dataframe\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata.set_index(\"date\", inplace=True)\n\n# plot with Stats model\nplt.figure(figsize=(10,6))\nplot_acf(data[\"price\"], lags=52)\nplt.show()","90a84353":"# plot with pandas\nplt.figure(figsize=(10,6))\nautocorrelation_plot(data[\"price\"])\nplt.show() # dash line is 99% confidence interval, solid line is 95% confidence interval","eec31bf3":"# plot with pandas 2\nplt.figure(figsize=(10,6))\nplt.acorr(data[\"price\"]-data[\"price\"].mean(), maxlags=52);","79f2f755":"# Create dataframe\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata.set_index(\"date\", inplace=True)\n\n# plot with Stats model\nplt.figure(figsize=(10,6))\nplot_pacf(data[\"price\"], lags=52)\nplt.show()","25eeb4db":"# ADF test\n# Create dataframe\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata.set_index(\"date\", inplace=True)\n\n# Null hypothesis : The process is a unit root AR (p)\nadf = sm.tsa.stattools.adfuller(data[\"price\"])\n\nprint(\"p-value:{}\".format(adf[1]))","dfa7655e":"# data set, separate conventional and organic\nconv = pivot[\"conventional\"][-102:]\n\n# Visualization\nplt.figure(figsize=(10,6))\nplt.plot(conv.index, conv, label=\"conventional\")\nplt.xlabel(\"date\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Average price\")\nplt.legend()","9bbe69e7":"# Create dataframe\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata.set_index(\"date\", inplace=True)\n\n# train data is 2year data forward date.\ntrain_data = data[\"price\"][:-13]\ndate = data.index[:-13]\n\n# with statsmodel \nar = AR(train_data, dates=date).fit(maxlag=52, ic='aic')\n\n# prediction is \npredict = ar.predict('2017-03-26','2018-03-25')","44c47306":"# Visualization\nplt.figure(figsize=(10,6))\nplt.plot(data.index, data[\"price\"], label=\"raw data\")\nplt.plot(predict.index, predict, label=\"AR model future prediction\", color=\"red\")\nplt.legend()","e2eefade":"# Create dataframe\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata.set_index(\"date\", inplace=True)\n\n# train data is 2year data forward date.\ntrain_data = data[\"price\"][:-13]\ndate = data.index[:-13]\n\n# with statsmodel, aic check of params\nst.arma_order_select_ic(train_data, ic='aic')","d71812dd":"# predict with statsmodel\narma = ARMA(train_data, order=[4,2]).fit(maxlag=4, ic='aic', dates=date)\n\npredict = arma.predict('2017-03-26','2018-03-25')","849ae780":"# Visualization\nplt.figure(figsize=(10,6))\nplt.plot(data.index, data[\"price\"], label=\"raw data\")\nplt.plot(predict.index, predict, label=\"AR model future prediction\", color=\"red\")\nplt.legend()","076c43c5":"# Create dataframe\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata.set_index(\"date\", inplace=True)\n\n# train data is 2year data forward date.\ntrain_data = data[\"price\"][:-13]\ndate = data.index[:-13]","24ffb8a5":"# predict with statsmodel, p,q are same as ARMA.\narima = ARIMA(train_data, order=[3,0,2],).fit(ic='aic', dates=date)\n\npredict = arima.predict('2017-03-26','2018-03-25')","26bc4a24":"# Visualization\nplt.figure(figsize=(10,6))\nplt.plot(data.index, data[\"price\"], label=\"raw data\")\nplt.plot(predict.index, predict, label=\"AR model future prediction\", color=\"red\")\nplt.legend()","a68269dc":"# Create dataframe\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata.set_index(\"date\", inplace=True)\n\n# train data is 2year data forward date.\ntrain_data = data[\"price\"][:-13]\ndate = data.index[:-13]","f4e6319d":"# SARIMA params optimization, round-robin algorithm\n# paramiter range\n# order(p, d, q)\nmin_p = 1; max_p = 2 # min_p must be >1\nmin_d = 0; max_d = 2\nmin_q = 0; max_q = 2 \n\n# seasonal_order(sp, sd, sq)\nmin_sp = 0; max_sp = 1\nmin_sd = 0; max_sd = 1\nmin_sq = 0; max_sq = 1\n\ntest_pattern = (max_p - min_p +1)*(max_q - min_q + 1)*(max_d - min_d + 1)*(max_sp - min_sp + 1)*(max_sq - min_sq + 1)*(max_sd - min_sd + 1)\nprint(\"pattern:\", test_pattern)\n\nsfq = 12 # seasonal_order\nts = train_data # training data\n\ntest_results = pd.DataFrame(index=range(test_pattern), columns=[\"model_parameters\", \"aic\"])\nnum = 0\nfor p in range(min_p, max_p + 1):\n    for d in range(min_d, max_d + 1):\n        for q in range(min_q, max_q + 1):\n            for sp in range(min_sp, max_sp + 1):\n                for sd in range(min_sd, max_sd + 1):\n                    for sq in range(min_sq, max_sq + 1):\n                        sarima = sm.tsa.SARIMAX(\n                            ts, order=(p, d, q), \n                            seasonal_order=(sp, sd, sq, sfq), \n                            enforce_stationarity = False, \n                            enforce_invertibility = False\n                        ).fit()\n                        test_results.iloc[num][\"model_parameters\"] = \"order=(\" + str(p) + \",\"+ str(d) + \",\"+ str(q) + \"), seasonal_order=(\"+ str(sp) + \",\"+ str(sd) + \",\" + str(sq) + \")\"\n                        test_results.iloc[num][\"aic\"] = sarima.aic\n                        print(num,'\/', test_pattern-1, test_results.iloc[num][\"model_parameters\"],  test_results.iloc[num][\"aic\"] )\n                        num = num + 1\n\n# result and AIC\nprint(\"best[aic] parameter ********\")\nprint(test_results[test_results.aic == min(test_results.aic)])","d16a059c":"test_results.sort_values(by='aic').head(10) ","728e96d8":"# statsmodel with dsarima\nsarimax = sm.tsa.SARIMAX(train_data, \n                        order=(1, 0, 0),\n                        seasonal_order=(0, 0, 0, 4),\n                        enforce_stationarity = False,\n                        enforce_invertibility = False\n                        ).fit(ic='aic', dates=date)\n\nsarimax_optimization_resid = sarimax.resid # resid check\n\nfig = plt.figure(figsize=(8, 8))\n\n# ACF of resid\nax1 = fig.add_subplot(211)\nsm.graphics.tsa.plot_acf(sarimax_optimization_resid, lags=40, ax=ax1) \n\n# PACF of resd\nax2 = fig.add_subplot(212)\nsm.graphics.tsa.plot_pacf(sarimax_optimization_resid, lags=40, ax=ax2) \nplt.show()","c8adaa0c":"# prediction\npredict = sarimax.predict('2017-03-26','2018-03-25')\n\n# Visualization\nplt.figure(figsize=(10,6))\nplt.plot(data.index, data[\"price\"], label=\"raw data\")\nplt.plot(predict.index, predict, label=\"AR model future prediction\", color=\"red\")\nplt.legend()","48d55c48":"# Create dataframe\ndata = pd.DataFrame({})\ndata[\"date\"] = conv.index\ndata[\"price\"] = conv.values\ndata.set_index(\"date\", inplace=True)\n\n# train data is 2year data forward date.\ntrain_data = data[\"price\"][:-13]\ndate = data.index[:-13]","d78c71c2":"garch = arch_model(train_data, mean='AR', lags=4, vol='GARCH',\n                  p=1, o=0, q=1, dist='studentst')\ngarch.fit()","faca2975":"## Time series prediction","4ecd36a4":"### optimizing sarima params, round-robin algorithm","381a9de6":"# AR model","28644a5f":"# Autocovariance and Autocorrelation","bbfabe30":"# Partial autocorrelation coefficient","12a0ee25":"### Preparing dataframe, average by date.","aea214ef":"# SARIMA model","f42ffbf9":"Create a summary of Time series analysis using Avocado price data as the subject.","e2699a7d":"Neither model can predict the time series correctly. For models with such periodicity but strong non-stationarity, it may be inappropriate to make predictions with these models.","2be7c54b":"Time series analysis\n- Time series change\n- Rolling\n- Trend and seasonaly\n- Autocovariance and Autocorrelation\n- AR model\n- ARMA model\n- ARIMA model\n- SARIMA model\n- GARCH model","afecc7d1":"# ARIMA model","7fb0289b":"# Rolling Statistics\n\n### object is average price of conventional","ccd48e8d":"# Reference) GARCH model","b79dbea5":"# Notebook, Time series analysis","68be0e2f":"# Trend and seasonaly","5aa84fb9":"# Unit root test","dacaa046":"# Time series change","d241f8fd":"# Average price time series","5fdc6a2d":"# ARMA model","7c82990d":"p-value > 0.05, this is not the process of unit roof AR(p)","e2db8cfa":"Confirm the time series prediction method such as ARIMA model. Therefore, we used the plan shown in the following figure, which can confirm a certain periodicity for the sample time series data.","137515a3":"Previous notebooks\n\nNotebooks<br>\nClassification method<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/notebook-classification-method<br>\nRegression method<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/notebook-regression-method<br>\nDimension reduction method<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/notebook-dimension-reduction<br>\nImage preprocessing OpenCV library<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/notebook-image-preprocessing-opencv-library<br>\nTime series analysis<br>\nhttps:\/\/www.kaggle.com\/urayukitaka\/notebook-statistical-test-with-avocado-price<br>","8219d2f0":"## Data loading and Data check"}}