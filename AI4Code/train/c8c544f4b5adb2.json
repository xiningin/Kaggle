{"cell_type":{"67cf82a1":"code","95d5b482":"code","d9e1d360":"code","e0e45375":"code","42c39c71":"code","a7b68fc7":"code","c0e5ffe4":"code","1b7a7a5f":"code","5c354e93":"code","d186b461":"code","477984a9":"code","813a32d0":"code","9f457fb1":"code","a1211cea":"code","8389356f":"code","7355cfa7":"code","c40a117c":"code","e6ce7edc":"code","348ee300":"code","2dc1563a":"code","ff1cfebc":"markdown","d73f82bb":"markdown","87de7a6f":"markdown","86aa846d":"markdown","0eac32ea":"markdown","18bd94f8":"markdown","590af039":"markdown","a13bd602":"markdown","43db1cb4":"markdown","34a152a9":"markdown","b42cbf1c":"markdown","3828e9d8":"markdown","fbb4e1fd":"markdown"},"source":{"67cf82a1":"import matplotlib.pyplot as plt \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import optimizers, losses, datasets\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D,Flatten\nimport numpy as np\ntf.__version__","95d5b482":"(train_images, train_labels),(test_images, test_labels) = datasets.mnist.load_data()","d9e1d360":"train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\ntest_images = test_images.reshape(test_images.shape[0], 28, 28, 1)","e0e45375":"train_images = train_images.astype('float32')\ntest_images = test_images.astype('float32')","42c39c71":"train_images = train_images \/ 255.0\ntest_images = test_images \/ 255.0","a7b68fc7":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3), input_shape = (28,28,1), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten()) \nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10,activation='softmax'))","c0e5ffe4":"model.summary()","1b7a7a5f":"model.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])","5c354e93":"model.fit(train_images,train_labels, epochs=10)","d186b461":"predictions = model.predict(test_images)","477984a9":"test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)","813a32d0":"predictions[0]","9f457fb1":"np.argmax(predictions[0])","a1211cea":"test_labels[0]","8389356f":"from sklearn.metrics import confusion_matrix","7355cfa7":"max_deger = []\nfor i in range(0,len(test_labels)):\n    max_deger.append(np.argmax(predictions[i]))","c40a117c":"cm = confusion_matrix(test_labels,max_deger)\nprint(cm)","e6ce7edc":"from tensorflow.keras.preprocessing.image import load_img,img_to_array,array_to_img ","348ee300":"def load_image(filename):\n    img = load_img(filename,color_mode = \"grayscale\",target_size=(28, 28))\n    plt.imshow(img,cmap='Greys')\n    img = img_to_array(img)\n    img = img.reshape(1, 28, 28, 1)\n    img = img.astype('float32')\n    img = img \/ 255.0\n    return img","2dc1563a":"quary_img=load_image(\"..\/input\/benim-rakamlarm\/5.JPG\")\npred = model.predict(quary_img)\nprint(\" Predict :\",pred.argmax())","ff1cfebc":"O zaman **covulotion neural network (evri\u015fimsel sinir a\u011flar\u0131)** ne yapar ondan k\u0131saca bahsedeyim bir g\u00f6rsel i\u015fleme yapay sinir a\u011f\u0131 i\u00e7in \u00f6zel filtreleme i\u015flemleri yapan bir katman olu\u015fturur bize. normal n\u00f6ral a\u011flardan fark\u0131 **3 farkl\u0131 katman\u0131n** bu modele dahil olmas\u0131d\u0131r asl\u0131nda bunlar **convolutin, pooling ve flattening** bu \u00fc\u00e7 a\u015fmadan da k\u0131saca bahsedeyim ve model \u00fczerinde nas\u0131l parametreler al\u0131yorlar onlar\u0131 inceleriz. ","d73f82bb":"**pooling** i\u015flemi ise g\u00f6r\u00fcnt\u00fcy\u00fc **k\u00fc\u00e7\u00fcltemeye** yar\u0131yor. Farkl\u0131 pooling i\u015flemleri var ama ben max pooling kulland\u0131m en anlaml\u0131 pixeli se\u00e7ip pooling i\u015flemini yap\u0131yor. Neden \u00f6nemli \u015fundan dolay\u0131 CNN g\u00f6rsellerin aras\u0131ndaki farklar\u0131 bularak bir \u00f6\u011frenme s\u00fcreci izliyor haliyle \u00f6nemsiz g\u00f6rd\u00fc\u011f\u00fc pixelleri atarak bu i\u015flemi daha h\u0131zl\u0131 yapacakt\u0131r.","87de7a6f":"Burada da n\u00f6ral a\u011f\u0131m\u0131z\u0131n bu verileri i\u015fleyebilmesi i\u00e7in verileri 0-1 aras\u0131na scale ettim.","86aa846d":"Karma\u015f\u0131kl\u0131k matrisi de bize modelimizin daha iyi bir sonu\u00e7 ald\u0131\u011f\u0131n\u0131 g\u00f6steriyor.","0eac32ea":"Train ve test image datalar\u0131n\u0131 tekrardan boyutland\u0131rd\u0131m burada 4 boyutlu bir matrix haline d\u00f6n\u00fc\u015ft\u00fcrd\u00fcm.","18bd94f8":"\u00f6ncelikle **convolution** katman\u0131ndan bahsedelim bu katmanda asl\u0131nda bir **filtreleme** yap\u0131l\u0131yor girdi katman\u0131na uygulanan filtre sonucunda \u00e7\u0131k\u0131\u015f de\u011feri \u00fcretiyor biraz daha ayrnt\u0131ya girecek olursam bir filtre boyutu belirliyoruz mesela 3x3 resmimiz \u00fczerinde 3x3 l\u00fck bir matrix dola\u015f\u0131p bir tak\u0131m i\u015flemler sonucu yeni bir matris ortaya \u00e7\u0131kar\u0131yor. ","590af039":"\u00d6nceki kernelde oldu\u011fu gibi bu kernelin sonuna da Carnegie Mellon \u00dcniversitesi'nin bir \u00f6\u011frencisi Adam Hartley'in haz\u0131rlam\u0131\u015f oldu\u011fu CNN a\u011f\u0131 ile rakam tan\u0131ma projesini linkini b\u0131rak\u0131yorum oradan da Covolution katam\u0131n\u0131n ne t\u00fcr flitreler uygulad\u0131\u011f\u0131n\u0131 g\u00f6rsel olarak g\u00f6rebilirsiniz. https:\/\/www.cs.cmu.edu\/~aharley\/vis\/conv\/flat.html","a13bd602":"Daha \u00f6ncesinde kurdu\u011fumuz fully connected a\u011f tahminlerine g\u00f6re daha iyi sonu\u00e7 verdi\u011fini g\u00f6rd\u00fck %1-2 lik bir art\u0131\u015f var zaten %99.62 ile baya y\u00fcksek de\u011fer alm\u0131\u015f ben burada \u015funa dikkat \u00e7ekmek istiyorum. loss de\u011feri 1.5 seviyelerinden 0.05 seviyesine kadar inmi\u015f bu \u00e7ok g\u00fczel bir \u015fey modelimizi compile ederken bir loss parametresi belirlemi\u015ftik bu oran\u0131n d\u00fc\u015fmesi modelimiz a\u00e7\u0131s\u0131ndan iyi bir geli\u015fimdir.  ","43db1cb4":"Sonras\u0131nda ise fully connected a\u011f\u0131m\u0131z\u0131 birebir koydum ki de\u011fi\u015fimi g\u00f6relim.","34a152a9":"Son olarak da **Flattening** matris \u015feklinde olan inputlar\u0131n **d\u00fcz bir input \u015fekline d\u00f6n\u00fc\u015ft\u00fcr\u00fclmesini** sa\u011fl\u0131yor mesela \u00f6nceli kernelde 28x28 olan matrisi 784 \u015feklinde tek boyuta indirgemi\u015ftik burada flattenig kullanarak bu i\u015flemleri yapabiliyoruz bize \u00e7ok g\u00fczel bir kolayl\u0131k sa\u011fl\u0131yor.","b42cbf1c":"Evet modelimiz burada farkl\u0131 olarak bu sefer \".add\" komutunu kulland\u0131m ilk kulland\u0131\u011f\u0131m katman Convolution katman\u0131 az \u00f6nce bahsetti\u011fim gibi flitreleme yapan katman\u0131m\u0131z peki 32 anlam\u0131 ne burada. \u0130lk parametre olan **flitre** ben 32 olarak se\u00e7tim. **kernel_size** ise g\u00f6r\u00fcnt\u00fcm\u00fcz\u00fcn \u00fcst\u00fcnde dola\u015fan filtrenin boyutudur. 3x3 tercih etmemin nedeni g\u00f6r\u00fcnt\u00fcm\u00fcz\u00fcn zaten boyut olarak 28x28 yani daha b\u00fcy\u00fck bir \u00e7\u00f6z\u00fcn\u00fcrl\u00fck se\u00e7mek do\u011fru olamayabilir. Neye g\u00f6re se\u00e7ece\u011fiz peki kernel_size'\u0131 g\u00f6r\u00fcnt\u00fc 128 pixelden b\u00fcy\u00fckse 5x5 ve 7x7 kullanabilir. daha k\u00fc\u00e7\u00fckse 3x3 kullanabilirsiniz. **input_shape** ise g\u00f6r\u00fcnt\u00fcm\u00fcz\u00fcn dikey,yatay \u00e7\u00f6z\u00fcn\u00fcrl\u00fck ve tek renk (grayscale) mi yoksa RGB mi oldu\u011funu girdi\u011fimiz 3 de\u011fer al\u0131yor bizim g\u00f6r\u00fcnt\u00fcm\u00fcz 28x28 ve grayscale oldu\u011fu i\u00e7in 1 de\u011ferini al\u0131yor RGB olsdayd\u0131 3 alacakt\u0131. **aktivasyon** zaten normal katmanlarda kulland\u0131\u011f\u0131m\u0131z gibi Convolution katman\u0131nda da kullan\u0131yoruz. \"input_shape\" sadece ilk katmana \u00f6zg\u00fcd\u00fcr he konusu a\u00e7\u0131lm\u0131\u015fken tek bir Covolution katman\u0131 olmak zorunda de\u011fil ayn\u0131 di\u011fer kaymanlar gibi o da iste\u011fe ba\u011fl\u0131 eklenebilir pooling de ayn\u0131 \u015fekilde.","3828e9d8":"Pooling de tek bir parametre yazd\u0131\u011f\u0131m\u0131z\u0131 fark etmi\u015fsinizdir bu parametre max pooling yap\u0131ld\u0131\u011f\u0131 i\u00e7in \u015funu ifade ediyor 2x2 lik olacak \u015fekilde t\u00fcm veriyi 4 pixellik matrislere ay\u0131r ve 4 pixelden sadece en de\u011ferli olan\u0131n\u0131 al ve yeni bir matris olu\u015ftur. Bunun nas\u0131l bir yarar\u0131 oldu\u011fudan bahsetmi\u015ftim. Sonu\u00e7 olarak hem dikeyde hem yatayda yar\u0131 yar\u0131ya boyut d\u00fc\u015f\u00fc\u015f\u00fc olur. Flatten de t\u00fcm bu i\u015flemlerden sonra full connected a\u011f\u0131m\u0131za ba\u011flamam\u0131z i\u00e7in verileri tek boyuta indirgenmesini sa\u011fl\u0131yor.","fbb4e1fd":"Ayn\u0131 \u015fekilde verilerimizi load ediyoruz buraya kadar her \u015fey ayn\u0131."}}