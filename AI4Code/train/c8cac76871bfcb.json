{"cell_type":{"c2089274":"code","6f6375c1":"code","c95ec625":"code","0022bb2d":"code","0a08e932":"code","99a7d2a8":"code","d516d7e7":"code","20077d5f":"code","035f8b26":"code","7df3a441":"code","73e21eb0":"code","29ac837b":"markdown","8533e172":"markdown","63a2bd12":"markdown","5f9a4ab0":"markdown","54311199":"markdown"},"source":{"c2089274":"!pip install openpyxl -q","6f6375c1":"import numpy as np\nimport pandas as pd\nimport openpyxl\n\nimport plotly.express as px\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport tensorflow as tf","c95ec625":"data = pd.read_excel('..\/input\/largest-2000-companies-in-the-world-by-revenue\/Largest Companies in the World.xlsx')","0022bb2d":"data","0a08e932":"data.info()","99a7d2a8":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop unused columns\n    df = df.drop(['Global Rank', 'Company'], axis=1)\n    \n    # One-hot encode nominal feature columns\n    for column in ['Country', 'Continent']:\n        dummies = pd.get_dummies(df[column], prefix=column)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    \n    # Split df into X and y\n    y = df['Market Value ($billion)']\n    X = df.drop('Market Value ($billion)', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","d516d7e7":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","20077d5f":"X_train","035f8b26":"y_train","7df3a441":"inputs = tf.keras.Input(shape=(71,))\nx = tf.keras.layers.Dense(128, activation='relu')(inputs)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\noutputs = tf.keras.layers.Dense(1, activation='linear')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='mse'\n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","73e21eb0":"y_pred = np.squeeze(model.predict(X_test))\n\nrmse = np.sqrt(np.mean((y_test - y_pred)**2))\nr2 = 1 - (np.sum((y_test - y_pred)**2) \/ np.sum((y_test - y_test.mean())**2))\n\nprint(\"RMSE: {:.2f}\".format(rmse))\nprint(\" R^2: {:.4f}\".format(r2))\n\nfig = px.scatter(\n    x=y_pred,\n    y=y_test,\n    labels={'x': \"Predicted\", 'y': \"Actual\"},\n    title=\"Actual vs. Predicted Values\",\n    width=700,\n    height=700\n)\n\nfig.show()","29ac837b":"# Preprocessing","8533e172":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/8owMOMOx-9Q","63a2bd12":"# Results","5f9a4ab0":"# Task for Today  \n\n***\n\n## Company Market Value Prediction  \n\nGiven *data about the world's largest companies*, let's try to predict the **market value** of a given company.\n\nWe will use a TensorFlow\/Keras neural network to make our predictions.","54311199":"# Training"}}