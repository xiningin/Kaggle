{"cell_type":{"f89268c1":"code","6312b68d":"code","dcc0f2d1":"code","fff3c138":"code","2578318b":"code","1d705359":"code","a42dd590":"code","cfc66ee7":"markdown","d6ae7f8d":"markdown","a1ce0700":"markdown","cf6bec33":"markdown","5c284c46":"markdown","b297cdad":"markdown"},"source":{"f89268c1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6312b68d":"df = pd.read_csv('\/kaggle\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv')\ndf.head()","dcc0f2d1":"X = df.loc[:,'GRE Score':'Research'].values\ny = df.iloc[:,-1].values","fff3c138":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nlr = LinearRegression()\nsgdr = SGDRegressor()\nmlpreg = MLPRegressor(random_state=1, max_iter=100)\nsvrl = SVR(kernel='linear',C=0.01)\nsvrp = SVR(kernel='poly',degree=3,C=1)\nmodels = {'LinReg':lr,'SGDReg':sgdr,'MLPreg':mlpreg,'SVRLinear':svrl,'SVRPoly':svrp}\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, shuffle=None)\nscaler = StandardScaler()  #MinMaxScaler(feature_range=(0,1))\n\nfor name in models:\n    regressor = models[name]\n    pipeline = Pipeline(steps=[('scaler',scaler),('name',regressor)])\n    model = pipeline.fit(X_train,y_train)\n    score = model.score(X_test,y_test)\n    predict = model.predict(X_test)\n    rmse = mean_squared_error(y_test,predict, squared=False)\n    \n    print(name+': score - %1.3f, rmse - %1.4f'%(score,rmse))\n","2578318b":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ndf1 = df.loc[:,'GRE Score':'Chance of Admit ']\ngrid = sns.PairGrid(df1)\ngrid.map(plt.scatter)","1d705359":"X = df[['TOEFL Score','SOP','CGPA','Research']].values\ny = df.iloc[:,-1].values","a42dd590":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, shuffle=None)\nfor name in models:\n    regressor = models[name]\n    pipeline = Pipeline(steps=[('scaler',scaler),('name',regressor)])\n    model = pipeline.fit(X_train,y_train)\n    score = model.score(X_test,y_test)\n    predict = model.predict(X_test)\n    rmse = mean_squared_error(y_test,predict, squared=False)\n    \n    print(name+': score - %1.3f, rmse - %1.4f'%(score,rmse))","cfc66ee7":"# Let's try to tune up the performance\nby 'eye-balling' correllations in input data","d6ae7f8d":"Try different models: using Linear Regression, SGDRegressor, NN-MLP Regressor, support vector machine regression (linear and nonlinear)","a1ce0700":"Run again with all the models previously instantiated","cf6bec33":"From this grid plot, we could infer a strong correlation between GRE and TOEFL scores as well as SOP, University rating and LOR. Hence, I choose drop to drop GRE score, University rating and LOR to improve training model perfomance.","5c284c46":"# Task details\nUsing the supplied predictive variables (GRE score, TOEFL score, University Rating, etc) to predict the likelihood of admission of a new candidate.\n\n# Evaluation Criteria\nThe best model should be the one that evaluates to have the lowest RMSE overall, and please indicate the error you get on validation set containing the last 100 observations.\n\n# Expected Submission\nPlease submit a Kernel where the final cell outputs the RMSE score on the final 100 observations.","b297cdad":"There's some improvements!\n# The best model in this case is LinearRegression() with rmse ~ 0.055 and ~ 84% prediction accuracy!"}}