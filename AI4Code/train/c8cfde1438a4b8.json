{"cell_type":{"3b0a91e3":"code","089f27e6":"code","b00d07a7":"code","6b6ba912":"code","4fea72a3":"code","5d2efa51":"code","24d8267f":"code","30602c41":"code","0ad43655":"code","decb0077":"code","b75972c9":"code","f5bea582":"code","d33f2c7a":"code","9fd9ce28":"code","d94acab5":"code","90811a3a":"code","0271e707":"code","7be1ad73":"markdown"},"source":{"3b0a91e3":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score, roc_auc_score, cohen_kappa_score, precision_score, recall_score, accuracy_score, confusion_matrix\nfrom keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom keras.models import Sequential\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.models import Model, Sequential\nfrom keras.applications.xception import Xception\nfrom keras.applications import *\nimport matplotlib.pyplot as plt\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom PIL import Image\nimport random\nimport os\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom xgboost import XGBClassifier \nfrom keras.callbacks import EarlyStopping\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA","089f27e6":"lung_aca = \"..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets\/lung_aca\/\"\n\nplt.figure(figsize = (10, 10))\nplt.subplot(131)\nimg = cv2.imread(lung_aca + os.listdir(lung_aca)[0])\nplt.title('Lung ACA')\nplt.imshow(img)\n\nplt.subplot(132)\nlung_n = \"..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets\/lung_n\/\"\nimg = cv2.imread(lung_n + os.listdir(lung_n)[0])\nplt.title('Lung N')\nplt.imshow(img)\n\nplt.subplot(133)\nlung_scc = \"..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets\/lung_scc\/\"\nimg = cv2.imread(lung_scc + os.listdir(lung_scc)[0])\nplt.title('Lung SCC')\nplt.imshow(img)\nplt.show()","b00d07a7":"data_dir = \"..\/input\/lung-and-colon-cancer-histopathological-images\/lung_colon_image_set\/lung_image_sets\/\"\nSIZE_X = SIZE_Y = 128\n\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.3)\n\ntrain_it = datagen.flow_from_directory(data_dir,\n                                       class_mode = \"categorical\",\n                                       target_size = (SIZE_X,SIZE_Y),\n                                       color_mode=\"rgb\",\n                                       batch_size = 12, \n                                       shuffle = False,\n                                       subset='training',\n                                       seed = 42)\n\nvalidate_it = datagen.flow_from_directory(data_dir,\n                                       class_mode = \"categorical\",\n                                       target_size = (SIZE_X, SIZE_Y),\n                                       color_mode=\"rgb\",\n                                       batch_size = 12, \n                                       shuffle = False,\n                                       subset='validation',\n                                       seed = 42)","6b6ba912":"def get_features(base_model, train, validate):\n    X_train = base_model.predict(train)\n    y_train = train.classes\n\n    X_val = base_model.predict(validate)\n    y_val = validate.classes\n\n    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.5, shuffle = True)\n    print('Shape of X_train----->', str(X_train.shape))\n    print('Shape of X_val----->', str(X_val.shape))\n    print('Shape of X_test----->', str(X_test.shape))\n    return (X_train, X_val, X_test, y_train, y_val, y_test)","4fea72a3":"def get_models():\n    ANN = Sequential()\n    ANN.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n    ANN.add(BatchNormalization())\n    ANN.add(Dropout(0.2))\n    ANN.add(Dense(64, activation='relu'))\n    ANN.add(Dense(32, activation='relu'))\n    ANN.add(Dense(16, activation='relu'))\n    ANN.add(Dense(8, activation='relu'))\n    ANN.add(Dense(len(train_it.class_indices), activation='softmax'))\n    ANN.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    KNN = KNeighborsClassifier()\n    \n    SVM = SVC(kernel = 'linear')\n    \n    RF = RandomForestClassifier(n_estimators = 50)\n    \n    ADB = AdaBoostClassifier()\n    \n    XGB = XGBClassifier(n_estimators = 50, use_label_encoder=False)\n    \n    print(\"Defined------->\")\n    print(\"ANN -------->\", \"(128x64x32x16x8)\")\n    print(\"KNeighborsClassifier()\")\n    print(\"SVC(kernel = 'linear')\")\n    print(\"RandomForestClassifier(n_estimators = 50)\")\n    print(\"AdaBoostClassifier()\")\n    print(\"XGBClassifier(n_estimators = 50)\")\n    \n    return (ANN, KNN, SVM, RF, ADB, XGB)","5d2efa51":"def reshape_data(X_train, X_val, X_test):\n    X_train = X_train.reshape(X_train.shape[0], -1)\n    X_val = X_val.reshape(X_val.shape[0], -1)\n    X_test = X_test.reshape(X_test.shape[0], -1)\n\n    print(\"Shape after reshaping------->\")\n    print(\"X train------->\", str(X_train.shape))\n    print(\"X val-------->\", str(X_val.shape))\n    print(\"X test-------->\", str(X_test.shape))\n    \n    return (X_train, X_val, X_test)","24d8267f":"def fit_ANN(model, X_train, y_train, X_val, y_test):\n    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n    history = model.fit(X_train, y_train, validation_data=(X_val, y_test), epochs=10, verbose=1, callbacks=[es])\n    return model\n\ndef fit_model(model, X_train, y_train):\n    model.fit(X_train, y_train)\n    return model\n\ndef get_accuracy_metrics_for_ANN(model, X_train, y_train, X_val, y_val, X_test, y_test):\n    print(\"Train accuracy Score------------>\")\n    print (\"{0:.3f}\".format(accuracy_score(y_train, np.argmax(model.predict(X_train), axis = 1))*100), \"%\")\n    \n    print(\"Val accuracy Score--------->\")\n    val_pred = np.argmax(model.predict(X_val), axis = 1)\n    print(\"{0:.3f}\".format(accuracy_score(y_val, val_pred)*100), \"%\")\n    \n    predicted =  np.argmax(model.predict(X_test), axis = 1)\n    print(\"Test accuracy Score--------->\")\n    print(\"{0:.3f}\".format(accuracy_score(y_test, predicted)*100), \"%\")\n    \n    print(\"F1 Score--------------->\")\n    print(\"{0:.3f}\".format(f1_score(y_test, predicted, average = 'weighted')*100), \"%\")\n    \n    print(\"Cohen Kappa Score------------->\")\n    print(\"{0:.3f}\".format(cohen_kappa_score(y_test, predicted)*100), \"%\")\n    \n    print(\"Recall-------------->\")\n    print(\"{0:.3f}\".format(recall_score(y_test, predicted, average = 'weighted')*100), \"%\")\n    \n    print(\"Precision-------------->\")\n    print(\"{0:.3f}\".format(precision_score(y_test, predicted, average = 'weighted')*100), \"%\")\n    \n    cf_matrix_test = confusion_matrix(y_test, predicted)\n    cf_matrix_val = confusion_matrix(y_val, val_pred)\n    \n    plt.figure(figsize = (12, 6))\n    plt.subplot(121)\n    sns.heatmap(cf_matrix_val, annot=True, cmap='Blues')\n    plt.title(\"Val Confusion matrix\")\n    \n    plt.subplot(122)\n    sns.heatmap(cf_matrix_test, annot=True, cmap='Blues')\n    plt.title(\"Test Confusion matrix\")\n    \n    plt.show()","30602c41":"def fit_KNN_metrics(model, X_train, y_train, X_val, y_val, X_test, y_test):\n    pca = PCA(n_components=7000)\n    randlist = random.sample(range(0, X_train.shape[0]), 1000)\n    if(X_train.shape[1] > 10000):\n        X_train = pca.fit_transform(X_train)\n        X_val = pca.transform(X_val)\n        X_test = pca.transform(X_test)\n\n    model.fit(X_train, y_train)\n    get_accuracy_metrics(model, X_train[randlist, :], y_train[randlist], X_val, y_val, X_test, y_test)\n    \ndef get_accuracy_metrics(model, X_train, y_train, X_val, y_val, X_test, y_test):\n    print(\"Train accuracy Score------------>\")\n    print (\"{0:.3f}\".format(accuracy_score(y_train, model.predict(X_train))*100), \"%\")\n    \n    print(\"Val accuracy Score--------->\")\n    val_pred = model.predict(X_val)\n    print(\"{0:.3f}\".format(accuracy_score(y_val, val_pred)*100), \"%\")\n    \n    predicted =  model.predict(X_test)\n    print(\"Test accuracy Score--------->\")\n    print(\"{0:.3f}\".format(accuracy_score(y_test, predicted)*100), \"%\")\n    \n    print(\"F1 Score--------------->\")\n    print(\"{0:.3f}\".format(f1_score(y_test, predicted, average = 'weighted')*100), \"%\")\n    \n    print(\"Cohen Kappa Score------------->\")\n    print(\"{0:.3f}\".format(cohen_kappa_score(y_test, predicted)*100), \"%\")\n    \n    print(\"Recall-------------->\")\n    print(\"{0:.3f}\".format(recall_score(y_test, predicted, average = 'weighted')*100), \"%\")\n    \n    print(\"Precision-------------->\")\n    print(\"{0:.3f}\".format(precision_score(y_test, predicted, average = 'weighted')*100), \"%\")\n    \n    cf_matrix_test = confusion_matrix(y_test, predicted)\n    cf_matrix_val = confusion_matrix(y_val, val_pred)\n    \n    plt.figure(figsize = (12, 6))\n    plt.subplot(121)\n    sns.heatmap(cf_matrix_val, annot=True, cmap='Blues')\n    plt.title(\"Val Confusion matrix\")\n    \n    plt.subplot(122)\n    sns.heatmap(cf_matrix_test, annot=True, cmap='Blues')\n    plt.title(\"Test Confusion matrix\")\n    \n    plt.show()","0ad43655":"base_model = MobileNet(include_top=False, input_shape=(SIZE_X, SIZE_Y, 3), weights='imagenet')\n\nfor layer in base_model.layers:\n    layer.trainable = False\n                   \nmodel = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\nmodel.summary()","decb0077":"X_train, X_val, X_test, y_train, y_val, y_test = get_features(model, train_it, validate_it)","b75972c9":"X_train, X_val, X_test = reshape_data(X_train, X_val, X_test)\nANN, KNN, SVM, RF, ADB, XGB = get_models()\n\nANN = fit_ANN(ANN, X_train, y_train, X_val, y_val)","f5bea582":"get_accuracy_metrics_for_ANN(ANN, X_train, y_train, X_val, y_val, X_test, y_test)","d33f2c7a":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)\n\nfit_KNN_metrics(KNN, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test)","9fd9ce28":"SVM = fit_model(SVM, X_train_scaled, y_train)\nget_accuracy_metrics(SVM, X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test)","d94acab5":"RF = fit_model(RF, X_train, y_train)\nget_accuracy_metrics(RF,  X_train, y_train, X_val, y_val, X_test, y_test)","90811a3a":"ADB = fit_model(ADB, X_train, y_train)\nget_accuracy_metrics(ADB,  X_train, y_train, X_val, y_val, X_test, y_test)","0271e707":"XGB = fit_model(XGB, X_train, y_train)\nget_accuracy_metrics(XGB,  X_train, y_train, X_val, y_val, X_test, y_test)","7be1ad73":"# MobileNet"}}