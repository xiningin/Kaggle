{"cell_type":{"8bcfc616":"code","a80fed1e":"code","6291d7a1":"code","f0700b64":"code","db37fdc9":"code","4b65c28a":"code","2c29dab8":"code","61cb00dc":"code","d42135d2":"code","4167d4de":"code","be05c277":"code","7e500cc6":"code","a8421f73":"code","10b4b1a6":"code","986e36ba":"code","ed146603":"code","5965446a":"code","bd80e72d":"code","cd03f5cf":"code","ebf02420":"code","25eff8f5":"code","d1660082":"code","d7e3eeb0":"code","e8f3d341":"code","12c39789":"code","b2f6dc4f":"code","1b497b79":"markdown","60c95809":"markdown","2e938262":"markdown","e3eedac7":"markdown","39159604":"markdown","64bde80d":"markdown","b06553f1":"markdown","aa18e54c":"markdown","98804503":"markdown","70edea46":"markdown","da369724":"markdown","8e8900b8":"markdown","8395eb6e":"markdown","4d3310a6":"markdown","0b865328":"markdown","ecea6ef6":"markdown","61be6c7f":"markdown","6fc3cf4e":"markdown","acd7a467":"markdown","504bec19":"markdown","e5ca171a":"markdown","2f62fddd":"markdown","3ea5e7ce":"markdown","d97b1326":"markdown","fdb90075":"markdown","e4460cfa":"markdown"},"source":{"8bcfc616":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nprint(\"pandas version\", pd.__version__)","a80fed1e":"X_train_full = pd.read_csv(\"\/kaggle\/input\/used-car-price-dataset-competition-format\/X_train.csv\")\nX_test_full = pd.read_csv(\"\/kaggle\/input\/used-car-price-dataset-competition-format\/X_test.csv\")\nprint(\"Train data (Full)\") \nprint(X_train_full)\n\nprint(\"Test data (Full)\") \nprint(X_test_full)","6291d7a1":"fuelTypes = X_train_full.fuelType.unique()\nprint(\"possible fuelTypes are\", str(fuelTypes))","f0700b64":"dtype_2d = { 'tax': float, 'engineSize': float, 'fuelType': 'category' }\ntrain_data_2d = X_train_full[['tax','engineSize','fuelType']].astype(dtype_2d)\n# train_data_2d.loc[:, 'fuelType'] = train_data_2d['fuelType'].astype('category')\ntest_data_2d = X_test_full[['tax','engineSize', 'fuelType']].astype(dtype_2d)\n# test_data_2d.loc[:, 'fuelType'] = test_data_2d.loc[:, 'fuelType'].astype('category')\nprint(\"Train data - 2d\")\nprint(train_data_2d)\n# print(train_data_2d.set_index('fuelType').filter(like='Electric', axis='index'))\nprint(\"Test data - 2d\")\nprint(test_data_2d)","db37fdc9":"# print(train_data_2d.dtypes)\ntrain_data_2d.plot.scatter(x='tax', y='engineSize', c='fuelType', colormap='tab10', s=3, figsize=(20,5), title=\"train data 2d\", sharex=False, sort_columns=True)\ntest_data_2d.plot.scatter(x='tax', y='engineSize', c='fuelType', colormap='tab10', s=3, figsize=(20,5), title=\"test data 2d\", sharex=False)","4b65c28a":"train_data_4d = X_train_full[['year','tax','mpg','engineSize','fuelType']]\ntest_data_4d = X_test_full[['year','tax','mpg','engineSize','fuelType']]\nprint(\"Train data - 4d\")\nprint(train_data_4d)\nprint(\"Test data - 4d\")\nprint(test_data_4d)","2c29dab8":"from scipy.spatial.distance import cdist\ntrain_points = train_data_2d[['tax', 'engineSize']].to_numpy()\ntest_points = test_data_2d[['tax', 'engineSize']].to_numpy()\n# print('train', train_points)\n# normalize points with iqr in each dimension (so that distance is comparable across different features)\nq75, q25 = np.percentile(train_points, [75 ,25], axis=0)\niqr = q75 - q25\npoint_normalize_ratio = iqr\ntrain_points \/= point_normalize_ratio\ntest_points \/= point_normalize_ratio\n# print('train', train_points)\ntrain_labels = train_data_2d[['fuelType']].to_numpy().flatten()\ntest_labels = test_data_2d[['fuelType']].to_numpy().flatten()\nfuelType_to_index = {k: v for v, k in enumerate(fuelTypes)}\nprint('point_normalize_ratio', point_normalize_ratio)\nprint('train_points', train_points.shape)\nprint('train_labels', train_labels.shape)","61cb00dc":"# https:\/\/gist.github.com\/pv\/8036995\n# Use below function from above gist for obtaining polygons regarding voronoi diagram\n# That's because the standard voronoi plot from scipy does not give bounds for infinite region, \n# so we cannot fill these cells with that. \n# The below function was a little buggy, so I fixed it.\ndef voronoi_finite_polygons_2d(vor, radius=None):\n    \"\"\"\n    Reconstruct infinite voronoi regions in a 2D diagram to finite\n    regions.\n    Parameters\n    ----------\n    vor : Voronoi\n        Input diagram\n    radius : float, optional\n        Distance to 'points at infinity'.\n    Returns\n    -------\n    regions : list of tuples\n        Indices of vertices in each revised Voronoi regions.\n    vertices : list of tuples\n        Coordinates for revised Voronoi vertices. Same as coordinates\n        of input vertices, with 'points at infinity' appended to the\n        end.\n    \"\"\"\n\n    if vor.points.shape[1] != 2:\n        raise ValueError(\"Requires 2D input\")\n\n    new_regions = []\n    new_vertices = vor.vertices.tolist()\n\n    center = vor.points.mean(axis=0)\n    if radius is None:\n        radius = vor.points.ptp().max()*2\n\n    # Construct a map containing all ridges for a given point\n    all_ridges = {}\n    for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n        all_ridges.setdefault(p1, []).append((p2, v1, v2))\n        all_ridges.setdefault(p2, []).append((p1, v1, v2))\n\n    # Reconstruct infinite regions\n    for p1, region in enumerate(vor.point_region):\n        vertices = vor.regions[region]\n\n        if all(v >= 0 for v in vertices):\n            # finite region\n            new_regions.append(vertices)\n            continue\n\n            \n        if not p1 in all_ridges:\n            new_regions.append(vertices)\n            continue\n        # reconstruct a non-finite region\n            \n        ridges = all_ridges[p1]\n        new_region = [v for v in vertices if v >= 0]\n\n        for p2, v1, v2 in ridges:\n            if v2 < 0:\n                v1, v2 = v2, v1\n            if v1 >= 0:\n                # finite ridge: already in the region\n                continue\n\n            # Compute the missing endpoint of an infinite ridge\n\n            t = vor.points[p2] - vor.points[p1] # tangent\n            t \/= np.linalg.norm(t)\n            n = np.array([-t[1], t[0]])  # normal\n\n            midpoint = vor.points[[p1, p2]].mean(axis=0)\n            direction = np.sign(np.dot(midpoint - center, n)) * n\n            far_point = vor.vertices[v2] + direction * radius\n\n            new_region.append(len(new_vertices))\n            new_vertices.append(far_point.tolist())\n\n        # sort region counterclockwise\n        vs = np.asarray([new_vertices[v] for v in new_region])\n        c = vs.mean(axis=0)\n        angles = np.arctan2(vs[:,1] - c[1], vs[:,0] - c[0])\n        new_region = np.array(new_region)[np.argsort(angles)]\n\n        # finish\n        new_regions.append(new_region.tolist())\n\n    return new_regions, np.asarray(new_vertices)","d42135d2":"from scipy.spatial import Voronoi, voronoi_plot_2d\nfrom matplotlib.colors import to_rgba\nimport matplotlib.patches as mpatches\n\nvor = Voronoi(train_points)\n\n# plot\nregions, vertices = voronoi_finite_polygons_2d(vor)\n\nprint('train_points', train_points.shape)\n# print('vor.regions', len(vor.regions), 'vor.vertices', len(vor.vertices))\nprint('regions', len(regions), 'vertices', len(vertices))\n\n\ncolor_mapper=np.array([0, 9, 2, 4, 6]) # remap just as pandas did at first\n# print('codes', np.max(train_data_2d.fuelType.cat.codes.to_numpy()))\n\nfig = plt.figure(figsize=(20,10))\nax = fig.gca()\nfig = voronoi_plot_2d(vor, ax, show_vertices=False, show_points=False)\n\nfor region_index, region in enumerate(regions):\n    if len(region) < 1: #skip the empty region\n        continue\n    label = train_labels[region_index]\n    color = fuelType_to_index[label]\n    color = color_mapper[color]\n    polygon = vertices[region]\n    plt.fill(*zip(*polygon), color=plt.cm.tab20(color*2+1))\n\npoint_to_color = []\nfor i, label in enumerate(train_labels):\n    color = fuelType_to_index[label]\n    color = color_mapper[color]\n    point_to_color.append(color)\n\nplt.scatter(vor.points[:,0], vor.points[:,1], s=7, marker='.', c=point_to_color, cmap=plt.cm.tab10, zorder=10)\n'''for c in range(len(fuelTypes)):\n    i, = np.where(train_labels == fuelTypes[c])\n    X = vor.points[i,0]\n    Y = vor.points[i,1]\n    color = color_mapper[c]\n    plt.scatter(X, Y, s=1, marker='.', label=fuelTypes[c], color=plt.cm.tab10(color), zorder=10)'''\nhandles = []\nfor label in fuelTypes:\n    color = fuelType_to_index[label]\n    color = color_mapper[color]\n    color = plt.cm.tab10(color)\n    handles.append(mpatches.Patch(color=color, label=label))\nplt.legend(bbox_to_anchor=(0.85, 0.9), loc=\"center right\", markerscale=5, handles=handles)\n\nplt.xlabel('normalized tax')\nplt.ylabel('normalized engineSize')\nplt.xlim(vor.min_bound[0] - 1, vor.max_bound[0] + 1)\nplt.ylim(vor.min_bound[1] - 1, vor.max_bound[1] + 1)\nplt.show()","4167d4de":"fig = plt.figure(figsize=(20,10))\nax = fig.gca()\nfig = voronoi_plot_2d(vor, ax, show_vertices=False, show_points=False)\n\nfor region_index, region in enumerate(regions):\n    if len(region) < 1: #skip the empty region\n        continue\n    label = train_labels[region_index]\n    color = fuelType_to_index[label]\n    color = color_mapper[color]\n    polygon = vertices[region]\n    plt.fill(*zip(*polygon), color=plt.cm.tab20(color*2+1))\n    \ntest_label_indices = [fuelType_to_index[label] for label in test_labels]\ntest_colors = color_mapper[test_label_indices]\n\nplt.scatter(test_points[:,0], test_points[:,1], s=7, marker='.', c=test_colors, cmap=plt.cm.tab10, zorder=10)\n\nplt.legend(bbox_to_anchor=(0.85, 0.9), loc=\"center right\", markerscale=5, handles=handles)\n\nplt.xlabel('normalized tax')\nplt.ylabel('normalized engineSize')\nplt.xlim(vor.min_bound[0] - 1, vor.max_bound[0] + 1)\nplt.ylim(vor.min_bound[1] - 1, vor.max_bound[1] + 1)\nplt.show()","be05c277":"distance_matrix = cdist(test_points, train_points, 'euclidean')\ntop_neighbours = np.argmin(distance_matrix, axis=1)\nprint('top_neighbours', top_neighbours.shape)\n\ntest_pred_label_indices = []\nfor neighbour in top_neighbours:\n    label = train_labels[neighbour]\n    label_index = fuelType_to_index[label]\n    test_pred_label_indices.append(label_index)\n\nfrom sklearn import metrics\n\naccuracy_score = metrics.accuracy_score(test_label_indices, test_pred_label_indices)\n\nprint(\"Our accuracy score is:\", accuracy_score)","7e500cc6":"K_VALUE=5\nmin_p = np.min(train_points, axis=0)\nmax_p = np.max(train_points, axis=0)\nprint('min p', min_p, 'max p', max_p)\ngrid_shape = [200, 100]\nticks_list = []\nfor i, tick_count in enumerate(grid_shape):\n    ticks = np.linspace(min_p[i], max_p[i], num=tick_count)\n    ticks_list.append(ticks)\ntarget_grid = np.array(np.meshgrid(*ticks_list)).T.reshape(-1, len(grid_shape))\n# print(target_grid)\ndistance_matrix = cdist(target_grid, train_points, 'euclidean')\nprint('distance_matrix', distance_matrix.shape)\nsorted_indices = np.argsort(distance_matrix, axis=1)\ntop_neighbours = sorted_indices[:,:K_VALUE]\nprint('top_neighbours', top_neighbours.shape)\n\ntarget_label_indices = []\nfor neighbours in top_neighbours:\n    labels = train_labels[neighbours]\n    label_indices = [fuelType_to_index[label] for label in labels]\n    votes = np.zeros(len(fuelTypes))\n    for label_index in label_indices:\n        votes[label_index]+=1\n    chosen_label_index = np.argmax(votes)\n    target_label_indices.append(chosen_label_index)\n    \ntarget_colors = color_mapper[target_label_indices].astype(int)\n# print('tc', target_colors)\n\nfig = plt.figure(figsize=(20,10))\nplt.scatter(target_grid[:,0], target_grid[:,1], s=20, marker='o', c=target_colors, cmap=plt.cm.tab10, zorder=10)\n\nhandles = []\nfor label in fuelTypes:\n    color = fuelType_to_index[label]\n    color = color_mapper[color]\n    color = plt.cm.tab10(color)\n    handles.append(mpatches.Patch(color=color, label=label))\nplt.legend(bbox_to_anchor=(1, .97), loc=\"center right\", markerscale=5, handles=handles)\n\nplt.xlabel('normalized tax')\nplt.ylabel('normalized engineSize')\nplt.xlim(min_p[0] - 1, max_p[0] + 1)\nplt.ylim(min_p[1] - 1, max_p[1] + 1)\nplt.show()\n    \n\n\n# grid_points = \n# train_distance_matrix = cdist(train_points, train_points, 'euclidean')\n# print('train_distance_matrix', train_distance_matrix.shape)","a8421f73":"from matplotlib import colors\ntest_label_indices = [fuelType_to_index[label] for label in test_labels]\ntest_colors = color_mapper[test_label_indices]\n\nfig = plt.figure(figsize=(20,10))\nplt.scatter(target_grid[:,0], target_grid[:,1], s=25, marker='s', c=target_colors*2+1, cmap='tab20', zorder=10, norm=colors.Normalize(0,20))\n\nplt.scatter(test_points[:,0], test_points[:,1], s=7, marker='o', c=test_colors, cmap=plt.cm.tab10, zorder=10)\n\nplt.legend(bbox_to_anchor=(1, .97), loc=\"center right\", markerscale=5, handles=handles)\n\nplt.xlabel('normalized tax')\nplt.ylabel('normalized engineSize')\nplt.xlim(min_p[0] - 1, max_p[0] + 1)\nplt.ylim(min_p[1] - 1, max_p[1] + 1)\nplt.show()","10b4b1a6":"distance_matrix = cdist(test_points, train_points, 'euclidean')\nprint('distance_matrix', distance_matrix.shape)\nsorted_indices = np.argsort(distance_matrix, axis=1)\ntop_neighbours = sorted_indices[:,:K_VALUE]\nprint('top_neighbours', top_neighbours.shape)\n\ntest_pred_label_indices = []\nfor neighbours in top_neighbours:\n    labels = train_labels[neighbours]\n    label_indices = [fuelType_to_index[label] for label in labels]\n    votes = np.zeros(len(fuelTypes))\n    for label_index in label_indices:\n        votes[label_index]+=1\n    chosen_label_index = np.argmax(votes)\n    test_pred_label_indices.append(chosen_label_index)\n    \ntest_pred_colors = color_mapper[test_pred_label_indices]\n\nfig = plt.figure(figsize=(20,10))\nplt.scatter(target_grid[:,0], target_grid[:,1], s=25, marker='s', c=target_colors*2+1, cmap='tab20', zorder=10, norm=colors.Normalize(0,20))\n\nplt.scatter(test_points[:,0], test_points[:,1], s=7, marker='o', c=test_pred_colors, cmap=plt.cm.tab10, zorder=10)\n\nplt.legend(bbox_to_anchor=(1, .97), loc=\"center right\", markerscale=5, handles=handles)\n\nplt.xlabel('normalized tax')\nplt.ylabel('normalized engineSize')\nplt.xlim(min_p[0] - 1, max_p[0] + 1)\nplt.ylim(min_p[1] - 1, max_p[1] + 1)\nplt.show()","986e36ba":"from sklearn import metrics\n\naccuracy_score = metrics.accuracy_score(test_label_indices, test_pred_label_indices)\n\nprint(\"Our accuracy score is:\", accuracy_score)","ed146603":"import multiprocessing\nfrom functools import partial\nfrom multiprocessing import Pool\n\nprint('cpu count', multiprocessing.cpu_count())\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\ndef knn_analysis_single(n_neighbours, train, test, weights, p):\n    X_train = train.drop('fuelType', axis=1)\n    X_test = test.drop('fuelType', axis=1)\n    y_train = train['fuelType']\n    y_test = test['fuelType']\n    knn_model = KNeighborsClassifier(n_neighbors=n_neighbours, weights=weights, p=p, metric='minkowski')\n    knn_model.fit(X_train, y_train)\n    y_train_pred = knn_model.predict(X_train)\n    y_test_pred = knn_model.predict(X_test)\n    accuracy_test = metrics.accuracy_score(y_test, y_test_pred)\n    accuracy_train = metrics.accuracy_score(y_train, y_train_pred)\n    return (accuracy_test, accuracy_train)\n\ndef knn_analysis(train, test, weights_list=['uniform'], p_list=[2], n_neighbours_list=[5]):\n    results_per_w = []\n    for weights in weights_list:\n        results_per_p = []            \n        for p in p_list:\n            results_per_n = []\n            with Pool(multiprocessing.cpu_count()) as pool: # simple multiprocessing across each n value\n                results_per_n = pool.map(\\\n                     partial(knn_analysis_single, train=train, test=test, weights=weights, p=p),\\\n                     n_neighbours_list\\\n                )\n            if len(results_per_n) == 1:\n                results_per_p.append(results_per_n[0])\n            else:\n                results_per_p.append(results_per_n)\n        if len(results_per_p) == 1:\n            results_per_w.append(results_per_p[0])\n        else:\n            results_per_w.append(results_per_p)\n    results = results_per_w[0] if len(results_per_w) == 1 else results_per_w\n    return np.array(results)","5965446a":"k_list=range(1,101)\nxticks=range(0,101,10)\nk_comparison_results = knn_analysis(train_data_2d, test_data_2d, n_neighbours_list=k_list)\ndf = pd.DataFrame(k_comparison_results, columns=['test_accuracy','train_accuracy'], index=k_list)\ndf.index.name = 'N_neighbours (k)'\ndf.plot.line(figsize=(20,5), title=\"Accuracies by varying k values (2d feature space)\", marker='o', xticks=xticks, grid=True, ylabel=\"accuracy\")","bd80e72d":"k_comparison_results = knn_analysis(train_data_4d, test_data_4d, n_neighbours_list=k_list)\ndf = pd.DataFrame(k_comparison_results, columns=['test_accuracy','train_accuracy'], index=k_list)\ndf.index.name = 'N_neighbours (k)'\ndf.plot.line(figsize=(20,5), title=\"Accuracies by varying k values (4d feature space)\", marker='o', xticks=xticks, grid=True, ylabel=\"accuracy\")","cd03f5cf":"# Define our custom weights function\n# refer to scikit implementation for dividing by 0 https:\/\/github.com\/scikit-learn\/scikit-learn\/blob\/071f98f0a753097c22c7d3c80f6113f972447187\/sklearn\/neighbors\/_base.py#L110\ndef inverse_squared_distance(distances):\n    with np.errstate(divide=\"ignore\"):\n        distances = 1.0 \/ np.square(distances)\n    inf_mask = np.isinf(distances)\n    inf_row = np.any(inf_mask, axis=1)\n    distances[inf_row] = inf_mask[inf_row]\n    return distances","ebf02420":"w_list = ['uniform', 'distance', inverse_squared_distance]\nk_comparison_results = knn_analysis(train_data_2d, test_data_2d, weights_list=w_list, n_neighbours_list=k_list)\nk_comparison_results = k_comparison_results[:,:,0] # select test accuracies only\nk_comparison_results = np.transpose(k_comparison_results) # reshape according to our needs\ndf = pd.DataFrame(k_comparison_results, columns=['uniform','inverse distance', 'inverse squared distance'], index=k_list)\ndf.index.name = 'N_neighbours (k)'\ndf.plot.line(figsize=(20,5), title=\"Test Accuracies per weighting option by varying k values (2d feature space)\", marker='o', xticks=xticks, grid=True, ylabel=\"accuracy\")","25eff8f5":"k_comparison_results = knn_analysis(train_data_4d, test_data_4d, weights_list=w_list, n_neighbours_list=k_list)\nk_comparison_results = k_comparison_results[:,:,0] # select test accuracies only\nk_comparison_results = np.transpose(k_comparison_results) # reshape according to our needs\ndf = pd.DataFrame(k_comparison_results, columns=['uniform','inverse distance', 'inverse squared distance'], index=k_list)\ndf.index.name = 'N_neighbours (k)'\ndf.plot.line(figsize=(20,5), title=\"Test Accuracies per weighting option by varying k values (4d feature space)\", marker='o', xticks=xticks, grid=True, ylabel=\"accuracy\")","d1660082":"p_list=range(1,5)\nk_comparison_results = knn_analysis(train_data_2d, test_data_2d, p_list=p_list, n_neighbours_list=range(1,101))\nk_comparison_results = k_comparison_results[:,:,0] # select test accuracies only\nk_comparison_results = np.transpose(k_comparison_results) # reshape according to our needs\ndf = pd.DataFrame(k_comparison_results, columns=range(1,5), index=range(1,101))\ndf.index.name = 'N_neighbours (k)'\ndf.plot.line(figsize=(20,5), title=\"Test Accuracies per weighting option by varying k values (2d feature space)\", marker='o', xticks=range(0,101,10), grid=True, ylabel=\"accuracy\")","d7e3eeb0":"print('df', df)\na = np.abs(k_comparison_results[:,0] - k_comparison_results[:, 1])\nb = np.abs(k_comparison_results[:,0] - k_comparison_results[:, 2])\nc = np.abs(k_comparison_results[:,0] - k_comparison_results[:, 3])\nprint('a', a)\nprint('b', b)\nprint('c', c)\nu = np.max(np.array([a,b,c]), axis=1)\nprint('max', u)\nprint('cpu count', multiprocessing.cpu_count())","e8f3d341":"k_comparison_results = knn_analysis(train_data_4d, test_data_4d, p_list=p_list, n_neighbours_list=range(1,101))\nk_comparison_results = k_comparison_results[:,:,0] # select test accuracies only\nk_comparison_results = np.transpose(k_comparison_results) # reshape according to our needs\ndf = pd.DataFrame(k_comparison_results, columns=range(1,5), index=range(1,101))\ndf.index.name = 'N_neighbours (k)'\ndf.plot.line(figsize=(20,5), title=\"Test Accuracies per weighting option by varying k values (4d feature space)\", marker='o', xticks=range(0,101,10), grid=True, ylabel=\"accuracy\")","12c39789":"k_comparison_results = knn_analysis(train_data_2d, test_data_2d, weights_list=w_list, p_list=p_list, n_neighbours_list=range(1,101))\nk_comparison_results = k_comparison_results[:,:,:,0] # select test accuracies only\nk_comparison_results = k_comparison_results.reshape(-1, k_comparison_results.shape[-1], order='A')\nfrom itertools import product\ncolumns=product(['uniform, p=','inverse distance, p=', 'inverse squared distance, p='], [str(p) for p in p_list])\nk_comparison_results = np.transpose(k_comparison_results) # reshape according to our needs\n\ncolor_list = [plt.cm.tab20c(i) for i in range(12)]\n\ndf = pd.DataFrame(k_comparison_results, columns=columns, index=range(1,101))\ndf.index.name = 'N_neighbours (k)'\nax = df.plot.line(figsize=(20,5), title=\"Test Accuracies per weighting option and p value combination by varying k values (2d feature space)\", marker='o', xticks=range(0,101,10), grid=True, ylabel=\"accuracy\", color=color_list)\nax.legend(bbox_to_anchor=(1.15, 0.5), loc=\"center right\")","b2f6dc4f":"k_comparison_results = knn_analysis(train_data_4d, test_data_4d, weights_list=w_list, p_list=p_list, n_neighbours_list=range(1,101))\nk_comparison_results = k_comparison_results[:,:,:,0] # select test accuracies only\nk_comparison_results = k_comparison_results.reshape(-1, k_comparison_results.shape[-1], order='A')\ncolumns=product(['uniform, p=','inverse distance, p=', 'inverse squared distance, p='], [str(p) for p in p_list])\nk_comparison_results = np.transpose(k_comparison_results) # reshape according to our needs\n\ncolor_list = [plt.cm.tab20c(i) for i in range(12)]\n\ndf = pd.DataFrame(k_comparison_results, columns=columns, index=range(1,101))\ndf.index.name = 'N_neighbours (k)'\nax = df.plot.line(figsize=(20,5), title=\"Test Accuracies per weighting option and p value combination by varying k values (4d feature space)\", marker='o', xticks=range(0,101,10), grid=True, ylabel=\"accuracy\", color=color_list)\nax.legend(bbox_to_anchor=(1.15, 0.5), loc=\"center right\")","1b497b79":"We can see that most points above match the background, ie: they will be correctly predicted.\nSo, we can expect a high accuracy here. Let's do the calculation.","60c95809":"# Start Here\n\n## What is Our task\n\nLet's say that we want to guess what a given car's fuel type is based on its year, tax, mpg (mile-per-gallon), and engine size.\n\n* So our features are `[year,tax,mpg,engineSize]` which will be our input,\n* our label is `fuelType` (one of `[Diesel, Petrol, Electric, Hybrid, Other]`) which will be our output.\n\n\nWe can apply KNN algorithm to solve this problem.\n\nIn order to be able to plot 2D scatter graphs, we'll first solve a smaller task by only using 2 features, `[tax,engineSize]`, then we'll solve it with 4 features.","2e938262":"Above graph indicates, test and train accuracies do not differ much (this most likely means train and test data resemble similar clusters so we cannot overfit, I was expecting some overfit results with very small k such as 1-2, but didn't observe it) The model seems unstable for very small k with the 2d feature space, and we see a general trend of decreasing accuracies first, and then staying almost fixed later as k value keeps increasing.\n\nWe can guess that indeed the default `k=5` is a sane choice as smaller k might give unstable output in with small amount of features.","e3eedac7":"We can see that choosing inverse distance and inverse squared distance almost doesn't affect the results. However, we can see that the trend of decreasing accuracy as k increases is drastically changed. Now, with smaller k values the result is unstable but as it is increased it the results get stable and fixed.\n\nThe case with more features seem resillient to unstable output even with small k values, but in the case with smaller number of features' the results only get stable with increasing k, without an accuracy decrease over increasing k.\n\nSo, a more sane choice that might apply to many cases would be choosing a high k value with inverse distance as the weighting method rather than uniform.","39159604":"It is already divided into train and test splits, so we will not split the data but use it as so.","64bde80d":"These are the actual predictions we made for test points. (Of course they match the background color, since the background color was our decision criteria anyways)\n\nLet's check out our accuracy scores and finalize. ","b06553f1":"## Implementing a KNN by ourselves\nLet's implement KNN manually, first.\n\nTo keep things simple we will implement it without any complicated search tree structure optimization. So it will run in $O(dn^2)$ complexity where n is the number of points, and d is the number of dimensions and the complexity comes from calculating distance of each two points.\n\nWe will run it only on 2d data with fixed k=5 and euclidean distance: $distance(x,y) = \\sqrt{\\sum_{i=1}^2 (x_{i} - y_{i})^2}$\n\nLet's initialize data first, according to our needs.","aa18e54c":"Let's plot test points on top of the voronoi diagram, so we can get an idea about how well does this diagram fits to the test data.","98804503":"#### **N_Neighbours (k)** comparison with other hyperparameters default\n\nRun it with k value in range from 1 to 100 and plot line graph","70edea46":"As depicted above graphs, we can see both small clusters and larger ones. What's important here is that both test and train data have a similar layout. So, KNN can probably estimate test data pretty well.","da369724":"As above depicted, we can see how our model decides in which category a given data fits. \nNow, let's visualize where test points fall on top of that map.","8e8900b8":"We can see that it fits fine for most but not all points. We verified our initial idea that train and test data are very much in agreement according to these clusters.\n\nLet's calculate all distances for test points and choose the closest neighbour for each test point. (Run the algorithm with k=1 which corresponds exactly to above voronoi diagram)","8395eb6e":"* I've found an open database consisting of a list of used cars' features. (And their prices but we don't use the prices)\n* We can see how the original data looks like:","4d3310a6":"Now let's try to show how our decision map would look like for k=5.\nTo do so, let's calculate estimated labels over a grid of points.","0b865328":"### 2D Case (Tax, Engine Size -> Fuel Type)\nWe initalize data and plot scatter graphs","ecea6ef6":"#### **Weights** and **N_Neighbours (k)** combined comparison with other hyperparameters default","61be6c7f":"### 4D Case (Year, Tax, MPG, Engine Size -> Fuel Type)\nWe initalize data for future use","6fc3cf4e":"Let's write a convenience function to help us with comparisons (which runs knn for all given parameters)\n(I have implemented it with simple multiprocessing across cpu cores to make it run faster, but that's not required of course, it just saves time)\n\nWhat it does is it runs knn with all combinations of given hyper-parameters, calculates test and train accuracy scores, and returns those accuracies as tuples within a numpy array (array shape is determined from input hyper-parameter space)","acd7a467":"As I guessed before, the reason that p value did not affect the output in the first case was probably that the feature space dimension was smaller than the p values. Interestingly, as the p value is increased the results get worse, but very ssimilar when `p > 1` This might be due to the fact that our data is orgaized somewhat similar to a grid as we can see in the initial scatter plots. An interesting effect here is that there seems to be an interaction effect between p value and k value that as k values increasse the results get even more worse when the p value is increased.","504bec19":"#### **Minkowski Power (p)** and **N_Neighbours (k)** combained comparison with other hyperparameters default","e5ca171a":"Let's plot a simple voronoi diagram corresponding to these points. (That would be exactly the same as a decision space if we chose k=1)\n\n(Note, there are cases when points are perfectly on top of each other, in such cases an arbitrary one's color is assigned to the surrounding region)","2f62fddd":"So, our current implementation can predict what fuelType a given test point has (according to tax and engineSize) with 84.5% accuracy! It did outperform the case with k=1","3ea5e7ce":"## Use a standard KNN and play around with hyper-parameters\nWe can use KNeighborsClassifier from sklearn, run it with different hyperparameters and plot results\n\nHyperparameters:\n* **n_neighbours**: our main `k` parameter (default is 5)\n    The k value in the knn algorithm. We can plot prediction error rates according to the k value we choose.\n\n* **weights**: `uniform` vs `distance` vs `[callable]` (default is uniform)\n    \n    Here, `distance` weights mean that each point contributes by their inverse distance to the queried point. \n    In addition we can create a `inverse_squared_distance` method which implements $$weight = 1\/ {distance^{2}}$$ We can compare those three options.\n\n* **metric**: `minkowski` vs others (default is `minkowski`)\n    sklearn supports a few different metrics for different types of data. since our data consists of real valued vectors, we can choose `minkowski` or its custom weighted versions. We'll choose minkowski in our case.\n\n* **p**: Power parameter for `minkowski` metric. (default is 2)\n    $$distance = (\\sum_{i=1}^{d} \\mid x_{i} - y_{i}\\mid^{p})^{1\/p} = \\sqrt[p]{\\sum_{i=1}^{d} \\mid x_{i} - y_{i}\\mid^{p}} \\quad\\text{where d is number of dimensions}$$\n    \n    When p is 2, distance equals to euclidean distance, when p is 1, distance equals to manhattan distance.\n    \n    We can choose p as 1,2,3,4 and compare the results","d97b1326":"#### All hypervalues combined","fdb90075":"The result was interesting that changing `p` had no effect on the result. It might be due to that our data is somewhat distrubuted in a grid format already so manhattan distance (p=0) and euclidian distance (p=1) is almost always identical and more `p` doesn't make sense as our data is already in 2d. I checked out differences across p values below, and verified. this. (~0.0004 accuracy differences between p=1 and p=2 in two special cases of n_neighbours `k=44` and `k=50`, and always 0 difference between p=1, p=3 and p=4 in all cases probably due to computational roundings)","e4460cfa":"Our accuracy score is 79.8% \nIt looks good, but let's see if we can improve it by implementing knn algorithm (k>1) rather than simple closest neighbour algorithm (k=1)"}}