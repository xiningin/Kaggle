{"cell_type":{"6b5eb2fe":"code","80f16f4b":"code","3210120b":"code","69d82a82":"code","29cea427":"code","d53a7ebd":"code","b6cafb39":"code","0f9e593f":"code","e6356ac3":"code","a164d957":"code","e68cba75":"code","b1b65901":"code","c3115b51":"code","23d730f5":"code","cbc9b6d9":"code","f0f1d4f9":"code","76d6a9b6":"code","69cba35c":"code","4da0c087":"code","e9d408ad":"code","f2a99763":"code","e36124a1":"code","c9a41716":"code","380913e7":"code","b6c77424":"code","ff2c2a12":"code","df7f4558":"code","86298407":"code","6113e0ec":"code","8c1660e9":"code","c3e3e54d":"code","8c1d39d3":"code","f14b2f70":"code","42c84924":"code","c043d426":"code","c10d8be3":"code","9dacc361":"code","a71af5bc":"code","3db474b1":"code","a094de5c":"code","6a310ee3":"code","96e73c43":"code","9f606834":"code","113f5c5e":"code","d3e2a673":"code","264b8854":"code","731aee06":"code","004b23bd":"code","fee003b0":"code","6137d19b":"code","b4c68e7b":"code","09895603":"code","e7457de1":"markdown","938aa550":"markdown","badbc1d5":"markdown","b0a777c8":"markdown","dcf6c8bc":"markdown","0f87c69f":"markdown","3b1b66cc":"markdown","a38a2ab7":"markdown","66ec8bda":"markdown"},"source":{"6b5eb2fe":"import math\n\nimport bcolz\nimport numpy as np\nfrom skimage.transform import resize\n\nimport tensorflow as tf\nfrom keras import backend as K\n\n\nOR_IM_WIDTH = 101\nOR_IM_HEIGHT = 101\nOR_IM_CHANNEL = 3\n\nIM_WIDTH = 128\nIM_HEIGHT = 128\nIM_CHAN = 1\n\n\ndef save_arr (fname, arr):\n    c = bcolz.carray(arr, rootdir=fname, mode='w')\n    c.flush()\n    \n\ndef load_array(fname):\n    return bcolz.open(fname)[:]\n\n\ndef upsample(img):\n    return resize(img, (IM_HEIGHT, IM_WIDTH, IM_CHAN), mode='constant', preserve_range=True)\n\n    \ndef downsample(img):\n    return resize(img, (OR_IM_HEIGHT, OR_IM_WIDTH), mode='constant', preserve_range=True)\n\n\ndef rle_decode(rle, shape):\n    \"\"\"\n    rle: run-length string or list of pairs of (start, length)\n    shape: (height, width) of array to return \n    Returns\n    -------\n        np.array: 1 - mask, 0 - background\n    \"\"\"\n    if isinstance(rle, float) and math.isnan(rle):\n        rle = []\n    if isinstance(rle, str):\n        rle = [int(num) for num in rle.split(' ')]\n    # [0::2] means skip 2 since 0 until the end - list[start:end:skip]\n    starts, lengths = [np.asarray(x, dtype=int) for x in (rle[0:][::2], rle[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 255\n    img = img.reshape(1, shape[0], shape[1])\n    img = img.T\n    return img\n\n\ndef rle_encode(img):\n    \"\"\"\n    img: np.array: 1 - mask, 0 - background\n    Returns\n    -------\n    run-length string of pairs of (start, length)\n    \"\"\"\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    rle = ' '.join(str(x) for x in runs)\n    return rle if rle else float('nan')\n\n\ndef iou(y_true, y_pred):\n    \"\"\" Intersection over Union Metric\n    \"\"\"\n    component1 = y_true.astype(dtype=bool)\n    component2 = y_pred.astype(dtype=bool)\n\n    overlap = component1 * component2 # Logical AND\n    union = component1 + component2 # Logical OR\n\n    iou = overlap.sum() \/ float(union.sum())\n    return iou\n\n\ndef iou_batch(y_true, y_pred):\n    batch_size = y_true.shape[0]\n    metric = []\n    for i in range(batch_size):\n        value = iou_metric(y_true[i], y_pred[i])\n        metric.append(value)\n    return np.mean(metric)\n\n\ndef mean_iou(y_true, y_pred):\n    \"\"\"Keras valid metric to use with a keras.Model\n    \"\"\"\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)\n","80f16f4b":"from utils import *\n\nimport os\nimport glob\nimport random\nimport tqdm\n\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom skimage.transform import resize\nfrom keras.preprocessing import image as image_utils","3210120b":"train_path = \"..\/input\/train\/images\/\"\ntrain_masks_path = \"..\/input\/train\/masks\/\"\ntest_path = \"..\/input\/test\/images\"","69d82a82":"train_files = sorted(glob.glob(os.path.join(train_path, \"*.png\")))\nmasks_files = sorted(glob.glob(os.path.join(train_masks_path, \"*.png\")))\ntest_files = sorted(glob.glob(os.path.join(test_path, \"*.png\")))","29cea427":"assert len(train_files) == len(masks_files)","d53a7ebd":"ids_train  = []\nX_train = np.zeros((len(train_files), OR_IM_HEIGHT, OR_IM_WIDTH, OR_IM_CHANNEL), dtype=np.uint8)\ny_train = np.zeros((len(masks_files), OR_IM_HEIGHT, OR_IM_WIDTH, OR_IM_CHANNEL), dtype=np.uint8)","b6cafb39":"X_train.shape, y_train.shape","0f9e593f":"for i, (train_path, mask_path) in tqdm.tqdm_notebook(enumerate(zip(train_files, masks_files)), total=len(train_files)):\n    train_id = os.path.basename(train_path)[:-4]\n    mask_id = os.path.basename(mask_path)[:-4]\n    assert train_id == mask_id\n    ids_train.append(train_id)\n    \n    x = image_utils.img_to_array(image_utils.load_img(train_path))\n    X_train[i] = x\n\n    y = image_utils.img_to_array(image_utils.load_img(mask_path))\n    y_train[i] = y","e6356ac3":"len(ids_train), X_train.shape, y_train.shape","a164d957":"n_images = 6\nfig, axarr = plt.subplots(2, n_images, figsize=(15, 5))\nfor image in range(n_images):\n    n = random.randint(1, X_train.shape[0])\n    axarr[0, image].imshow(X_train[n])\n    axarr[1, image].imshow(y_train[n])\nfig.tight_layout()","e68cba75":"ids_test = []\nX_test = np.zeros((len(test_files), OR_IM_HEIGHT, OR_IM_WIDTH, OR_IM_CHANNEL), dtype=np.uint8)\n\nfor i, test_path in tqdm.tqdm_notebook(enumerate(test_files), total=len(test_files)):\n    test_id = os.path.basename(test_path)[:-4]\n    ids_test.append(test_id)\n    \n    x = image_utils.img_to_array(image_utils.load_img(test_path))\n    X_test[i] = x","b1b65901":"len(ids_test), X_test.shape","c3115b51":"n_images = 6\nfig, axarr = plt.subplots(1, n_images, figsize=(15, 5))\nfor image in range(n_images):\n    n = random.randint(1, X_test.shape[0])\n    axarr[image].imshow(X_test[n])\nfig.tight_layout()","23d730f5":"coverage_train = np.zeros((X_train.shape[0], ), dtype=np.float64)","cbc9b6d9":"for i, (image, mask) in tqdm.tqdm_notebook(enumerate(zip(X_train, y_train)), total=X_train.shape[0]):\n    coverage_train[i] = np.mean(mask) \/ 255","f0f1d4f9":"coverage_train","76d6a9b6":"strata_train = np.zeros((X_train.shape[0], ), dtype=np.uint8)","69cba35c":"def cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\nv_cov_to_class = np.vectorize(cov_to_class)\nstrata_train = v_cov_to_class(coverage_train)","4da0c087":"strata_train","e9d408ad":"fig, axs = plt.subplots(1, 2, figsize=(15,5))\nsns.distplot(coverage_train, kde=False, ax=axs[0])\nsns.distplot(strata_train, bins=10, kde=False, ax=axs[1])\nplt.suptitle(\"Salt coverage\")\naxs[0].set_xlabel(\"Coverage\")\naxs[1].set_xlabel(\"Coverage class\")","f2a99763":"n_images = 11\nfig, axarr = plt.subplots(2, n_images, figsize=(18, 3))\nfor image in range(n_images):\n    statum_img = X_train[strata_train == image]\n    statum_mask = y_train[strata_train == image]\n    n = random.randint(1, statum_img.shape[0])\n    axarr[0, image].imshow(statum_img[n])\n    axarr[1, image].imshow(statum_mask[n])\nfig.tight_layout()","e36124a1":"X_train_up = np.array([upsample(img) for img in tqdm.tqdm_notebook(X_train, total=X_train.shape[0])])","c9a41716":"y_train_up = np.array([upsample(img) for img in tqdm.tqdm_notebook(y_train, total=y_train.shape[0])])","380913e7":"X_test_up = np.array([upsample(img) for img in tqdm.tqdm_notebook(X_test, total=X_test.shape[0])])","b6c77424":"X_train_up.shape, y_train_up.shape, X_test_up.shape","ff2c2a12":"# save_arr(\"ids_train\", ids_train)\n# save_arr(\"X_train\", X_train_up)\n# save_arr(\"y_train\", y_train_up)\n# save_arr(\"strata_train\", strata_train)\n# save_arr(\"ids_test\", ids_test)\n# save_arr(\"X_test\", X_test_up)\n\n# from tensorflow.python.client import device_lib\n# device_lib.list_local_devices()","df7f4558":"random_state = 42","86298407":"ids_train_ = ids_train\nX_train_ = X_train_up\ny_train_ = y_train_up.astype(np.bool)\nstrata_train = strata_train\nids_test = ids_test\nX_test = X_test_up","6113e0ec":"im_width  = X_train_.shape[1]\nim_height = X_train_.shape[2]\nim_chan = X_train_.shape[3]","8c1660e9":"X_train_.shape, y_train_.shape, im_width, im_height, im_chan","c3e3e54d":"X_train_  = np.append(X_train_, [np.fliplr(x) for x in X_train_], axis=0)\ny_train_ = np.append(y_train_, [np.fliplr(x) for x in y_train_], axis=0)","8c1d39d3":"strata_train = np.append(strata_train, strata_train)","f14b2f70":"X_train_.shape, y_train_.shape, strata_train.shape","42c84924":"from sklearn.model_selection import train_test_split\nrandom_state  = 42\nX_train, X_valid, y_train, y_valid = train_test_split(X_train_,y_train_,test_size=0.2, stratify=strata_train, random_state=random_state)","c043d426":"X_train.shape, X_valid.shape, y_train.shape, y_valid.shape","c10d8be3":"from keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Lambda\nfrom keras.layers import Conv2D, Conv2DTranspose\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import concatenate\nfrom keras.layers import Dropout\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau","9dacc361":"def build_model(input_layer, start_neurons):\n    # 128 -> 64\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(0.25)(pool1)\n\n    # 64 -> 32\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(0.5)(pool2)\n\n    # 32 -> 16\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(0.5)(pool3)\n\n    # 16 -> 8\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(0.5)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n\n    # 8 -> 16\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(0.5)(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n\n    # 16 -> 32\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])\n    uconv3 = Dropout(0.5)(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n\n    # 32 -> 64\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Dropout(0.5)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n\n    # 64 -> 128\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Dropout(0.5)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n\n    uncov1 = Dropout(0.5)(uconv1)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n    return output_layer","a71af5bc":"input_layer  = Input((im_height, im_width, im_chan))","3db474b1":"output_layer = build_model(input_layer, 16)","a094de5c":"model = Model(input_layer , output_layer)\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy', mean_iou])","6a310ee3":"model.summary()","96e73c43":"early_stopping = EarlyStopping(patience=10, verbose=1)\nmodel_checkpoint = ModelCheckpoint(\"unet-dropout.model\", save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n\nepochs = 100\nbatch_size = 16","9f606834":"history = model.fit(X_train, y_train,\n                    validation_data=[X_valid, y_valid], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[early_stopping, model_checkpoint, reduce_lr])","113f5c5e":"pred_test = model.predict(X_test, verbose=1)","d3e2a673":"threshold = 0.5\npred_test_tresh = np.int32(pred_test > threshold)","264b8854":"from utils import *\nimport tqdm\nimport numpy as np\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import load_model\nfrom skimage.transform import resize","731aee06":"import pandas as pd\nthreshold = 0.5\npred_test_tresh = np.int32(pred_test > threshold)","004b23bd":"preds_test_downsample  = []\nfor i in tqdm.tnrange(len(pred_test)):\n    # Resize it back to original size: 101x101\n    preds_test_downsample.append(np.int32(downsample(pred_test[i]) > threshold))","fee003b0":"pred_dict  = {img_id: rle_encode(preds_test_downsample[i]) for i, img_id in tqdm.tqdm_notebook(enumerate(ids_test), total=len(ids_test))}","6137d19b":"sub = pd.DataFrame.from_dict(pred_dict, orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']","b4c68e7b":"sub.head()","09895603":"sub.to_csv(\"submission.csv\")","e7457de1":"# Sanity Check for Strata","938aa550":"# Train\/valid slip","badbc1d5":"# Sanity Check","b0a777c8":"# Check the predictions","dcf6c8bc":"# Model","0f87c69f":"# Test Data","3b1b66cc":"# Save Arrays\n\nUpsample first","a38a2ab7":"# Stratify training data\n\nWe measure how much salt (mask) is on each photo and we divide this in n groups.\n\nSince the mask is just black and white we can just sum each pixel (black=1) of the mask and divide by the size of the img","66ec8bda":"# Data Augmentation\n\nWe flip the images along the y axis"}}