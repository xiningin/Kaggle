{"cell_type":{"a8550d57":"code","b684206b":"code","8864a328":"code","decc287b":"code","ebbb091c":"code","6c6d8beb":"code","de67144b":"code","5bab62e1":"code","4420a164":"code","ae50b549":"code","d9bf9103":"code","687e05fe":"code","afa8979b":"code","be2d03bc":"code","d4141b20":"code","668733dc":"code","3443109d":"code","84bfcb09":"code","eb319b10":"code","5e69a6f2":"code","72af85e1":"code","fb593701":"code","1ab4daa7":"code","e9881e4e":"code","dd5d1fce":"code","a2ccaa7b":"code","934eff8f":"code","46760ede":"code","3248ee53":"code","c2bec2ac":"code","8d6d2b23":"code","aabb13a3":"code","08e32c05":"code","470bc900":"code","18862f0e":"code","c6d533cf":"code","bdf6ae4b":"code","a7fdd10e":"code","6e818366":"code","d134f7d4":"code","b9f36c34":"code","fde88964":"code","789a3d00":"code","ae30a68f":"code","e145f5a3":"code","9ad0e5dd":"code","fdd2ec56":"code","d6965cc9":"code","a201d5da":"code","47cf3b1b":"code","b035ac95":"markdown","196239bb":"markdown","791acb94":"markdown","4ebc15c8":"markdown","032f45f4":"markdown","7ee13ae2":"markdown","d49501e0":"markdown","2253a87b":"markdown","fca7ae30":"markdown","be6aa1ef":"markdown","ba3afb9e":"markdown","d9107071":"markdown","bae16222":"markdown","c5660de2":"markdown","36a0658f":"markdown","bdc9dc1b":"markdown","5224abba":"markdown","42dc26c7":"markdown","5f808528":"markdown","37b04e88":"markdown"},"source":{"a8550d57":"DATA_labels1='..\/input\/bms-molecular-dataset-only-firts-1000-pngs\/bms-mol_v3\/bms-mol_v3\/train_labels.csv\/train_labels.csv'\n### only this number of rows for testing purposes\nnrows1=1000\n\n#### loading the data ---\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport requests, zipfile\ndata1 = pd.read_csv(DATA_labels1,nrows=nrows1)\ndata1.head()","b684206b":"!conda install -y -c rdkit rdkit","8864a328":"import numpy as np \n##import pandas as pd \nfrom tqdm.auto import tqdm\ntqdm.pandas()\n#### For plots #################\nimport skimage.io as io\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter, defaultdict\nimport cv2\nimport Levenshtein\n#################################\n\nfrom sklearn.model_selection import train_test_split\nimport rdkit\nfrom rdkit.Chem.Descriptors import MolWt\nfrom rdkit.Chem import Descriptors\nimport shutil\nfrom sklearn.metrics import jaccard_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import regularizers, optimizers\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","decc287b":"DATA_labels=DATA_labels1\n## only this number of rows for testing purposes\nnrows1=nrows1\n\n#### loading the data ---\ndata = data1\n\n#### for submission files etc,etc...\n##ss = pd.read_csv('..\/input\/dataset-bms-mol-v3\/sample_submission.csv', index_col = 0)\nss = pd.read_csv('..\/input\/bms-molecular-dataset-only-firts-1000-pngs\/bms-mol_v3\/bms-mol_v3\/sample_submission.csv\/sample_submission.csv', index_col = 0)\n\n# Let's add the path of the images to de DF...\ndata['path'] = data['image_id'].progress_apply(\n    lambda x: \"..\/input\/bms-molecular-dataset-only-firts-1000-pngs\/bms-mol_v3\/bms-mol_v3\/{}.png\".format(x))\n\n### Prepare to create only 2 Parts InChI --- Later adding more --\nlabel_splited2 = data['InChI'].progress_apply(lambda x: x.split('\/'))\n# Data Frame with label parts\nlabel_parts2 = pd.DataFrame.from_records(label_splited2.values)\nlabel_parts2.columns = np.array(label_parts2.columns + 1)\nlabel_parts2 = label_parts2.add_prefix('Part_')\n## important to add\nlabel_parts2['path'] = data['path']\nlabel_parts2.head()","ebbb091c":"train_sample = label_parts2 #.sample(nrows1)\n#train_sample['img_tensor'] = train_sample['path'].progress_apply(lambda x: io.imread(x))\ntrain_sample['InChI2p']= train_sample['Part_2']+\"\/\"+train_sample['Part_4'] ## Part_3 is complex, coming back later...\n\n#train_sample.drop(columns=['Part_1', 'Part_2', 'Part_3', 'Part_4', 'Part_5', 'Part_6', 'Part_7', 'Part_8'], inplace=True)\nParts2dropMax=max([len(i) for i in label_splited2])+1 # for the InChI=1S\/\nParts2drop=['Part_'+str(i) for i in range(1,Parts2dropMax)]\ntrain_sample.drop(columns=Parts2drop,inplace=True)\n\ntrain_sample = train_sample.reset_index()\ntrain_sample.head()","6c6d8beb":"train_sample.shape","de67144b":"class FeatureExtractorRDKIT():\n        \n    def __init__(self, df):\n        self.df = df\n        self.extract_features()\n             \n    def _get_mol_object(self):\n        self.df['MOL'] = self.df.SMILES.apply(lambda x: rdkit.Chem.MolFromSmiles(x))\n        \n    def _add_h_atoms(self):\n        self.df['MOL'] = self.df.MOL.apply(lambda x: rdkit.Chem.AddHs(x))\n    \n    def get_ring_info(self, x):\n        ri = x.GetRingInfo()\n        return ri.AtomRings()\n\n    def _num_of_rings(self):\n        self.df['num_of_rings'] = self.df.MOL.apply(lambda x: len(self.get_ring_info(x)))\n        \n    def _num_of_atoms_in_mol(self):\n        self.df['num_of_atoms_in_mol'] = self.df.MOL.apply(lambda x: x.GetNumAtoms())\n    \n    def _num_of_heavy_atoms_in_mol(self):\n        self.df['num_of_heavy_atoms_in_mol'] = self.df.MOL.apply(lambda x: x.GetNumHeavyAtoms())\n\n    def _lipophilicity(self):\n        self.df['logP'] = self.df.MOL.apply(lambda x: rdkit.Chem.Crippen.MolLogP(x))\n        \n    def _max_abs_estate(self):\n        self.df['max_abs_estate'] = self.df.MOL.apply(lambda x: rdkit.Chem.EState.EState.MaxAbsEStateIndex(x))\n        \n    def _min_abs_estate(self):\n        self.df['min_abs_estate'] = self.df.MOL.apply(lambda x: rdkit.Chem.EState.EState.MinAbsEStateIndex(x))\n        \n    def _min_estate(self):\n        self.df['min_estate'] = self.df.MOL.apply(lambda x: rdkit.Chem.EState.EState.MinEStateIndex(x))\n        \n    def _ether_oxygen(self):\n        self.df['ether_oxygen'] = self.df.MOL.apply(lambda x: rdkit.Chem.Fragments.fr_ether(x))\n        \n    def _aliphatic_carboxylic_acid(self):\n        self.df['aliphatic_carboxylic_acid'] = self.df.MOL.apply(lambda x: rdkit.Chem.Fragments.fr_Al_COO(x))\n        \n    def _carboxylic_acid_1(self):\n        self.df['carboxylic_acid_1'] = self.df.MOL.apply(lambda x: rdkit.Chem.Fragments.fr_COO(x))\n        \n    def _carboxylic_acid_2(self):\n        self.df['carboxylic_acid_2'] = self.df.MOL.apply(lambda x: rdkit.Chem.Fragments.fr_COO2(x))\n        \n    def _num_of_esters(self):\n        self.df['num_of_esters'] = self.df.MOL.apply(lambda x: rdkit.Chem.Fragments.fr_ester(x))\n        \n    def _num_of_aldehyde(self):\n        self.df['num_of_aldehyde'] = self.df.MOL.apply(lambda x: rdkit.Chem.Fragments.fr_aldehyde(x))\n        \n    def _num_of_ketone(self):\n        self.df['num_of_ketone'] = self.df.MOL.apply(lambda x: rdkit.Chem.Fragments.fr_ketone(x))\n            \n    def _molMR(self):\n        self.df['molMR'] = self.df.MOL.apply(lambda x: rdkit.Chem.Crippen.MolMR(x))\n        \n    def _len_smiles(self):\n        self.df['len_smiles'] = self.df.SMILES.apply(lambda x: len(list(x)))\n        \n    def _number_of_atoms(self):\n        atom_list = ['C', 'O', 'N', 'Cl', 'Br', 'F', 'S']\n        for atom in atom_list:\n            self.df['num_of_{}_atoms'.format(atom)] = self.df.MOL.apply(lambda x: len(x.GetSubstructMatches(rdkit.Chem.MolFromSmiles(atom))))\n\n    def _tpsa(self):\n        self.df['tpsa'] = self.df.MOL.apply(lambda x: Descriptors.TPSA(x))\n        \n    def _mol_w(self):\n        self.df['mol_w'] = self.df.MOL.apply(lambda x: Descriptors.ExactMolWt(x))\n        \n    def _num_valence_electrons(self):\n        self.df['num_valence_electrons'] = self.df.MOL.apply(lambda x: Descriptors.NumValenceElectrons(x))\n    \n    def _num_heteroatoms(self):\n        self.df['num_heteroatoms'] = self.df.MOL.apply(lambda x: Descriptors.NumHeteroatoms(x))\n        \n    def drop_for_train(self):\n        self.df = self.df.drop(['SMILES', 'MOL', 'SENTENCE'], axis=1)\n        \n    def drop_for_test(self):\n        self.df = self.df.drop(['SMILES', 'MOL'], axis=1)\n        \n    def return_data(self):\n        return self.df\n    \n    def extract_features(self):\n        self._get_mol_object()\n        self._add_h_atoms()\n        self._num_of_rings()\n        self._num_of_atoms_in_mol()\n        self._num_of_heavy_atoms_in_mol()\n        self._lipophilicity()\n#         self._max_abs_estate()\n#         self._min_abs_estate()\n#         self._min_estate()\n#         self._ether_oxygen()\n#         self._aliphatic_carboxylic_acid()\n#         self._carboxylic_acid_1()\n#         self._carboxylic_acid_2()\n#         self._num_of_esters()\n#         self._num_of_aldehyde()\n#         self._num_of_ketone()\n#         self._molMR()\n        self._len_smiles()\n        self._number_of_atoms()\n        self._tpsa()\n        self._mol_w()\n        self._num_valence_electrons()\n        self._num_heteroatoms()","5bab62e1":"'''Extraxt information from MOL graph.'''\n\nclass MOLGraphToMatrix:\n    \n    class ConnectivityMatrix():\n        \n        def __init__(self, df):\n            self.df = df\n            self.extract_features()\n            \n        def _get_mol_object(self):\n            if 'MOL' not in self.df:\n                self.df['MOL'] = self.df.SMILES.apply(lambda x: rdkit.Chem.MolFromSmiles(x))\n        \n        def _add_h_atoms(self):\n            if 'MOL' in self.df:\n                self.df['MOL'] = self.df.MOL.apply(lambda x: rdkit.Chem.AddHs(x))\n            \n        def connectivity_matrix(self, mol):\n            mol = rdkit.Chem.AddHs(mol)\n            matrix = rdkit.Chem.GetAdjacencyMatrix(mol)\n            if matrix.shape[0] <= 50:\n                padding_size = 50 - matrix.shape[0]\n                matrix = np.pad(matrix, (0, padding_size), 'constant', constant_values=(0))\n                return matrix\n            else:\n                return []\n            \n        def _make_connectivity_matrix(self):\n            self.df['connectivity_matrix'] = self.df.MOL.apply(lambda x: self.connectivity_matrix(x))\n            \n        def _len_connectivity_matrix(self):\n            self.df['len_con_matrix'] = self.df.connectivity_matrix.apply(lambda x: len(x))\n            \n        def extract_features(self):\n            self._get_mol_object()\n            self._add_h_atoms()\n            self._make_connectivity_matrix()\n            self._len_connectivity_matrix()\n        \n        def return_data(self):\n            return self.df\n        \n    class DistanceMatrix():\n        \n        def __init__(self, df):\n            self.df = df\n            self.extract_features()\n            \n        def _get_mol_object(self):\n            if 'MOL' not in self.df:\n                self.df['MOL'] = self.df.SMILES.apply(lambda x: rdkit.Chem.MolFromSmiles(x))\n        \n        def _add_h_atoms(self):\n            if 'MOL' in self.df:\n                self.df['MOL'] = self.df.MOL.apply(lambda x: rdkit.Chem.AddHs(x))\n            \n        def distance_matrix(self, mol):\n            mol = rdkit.Chem.AddHs(mol)\n            matrix = rdkit.Chem.GetDistanceMatrix(mol)\n            if matrix.shape[0] <= 50:\n                padding_size = 50 - matrix.shape[0]\n                matrix = np.pad(matrix, (0, padding_size), 'constant', constant_values=(0))\n                return matrix\n            else:\n                return []\n            \n        def _make_distance_matrix(self):\n            self.df['distance_matrix'] = self.df.MOL.apply(lambda x: self.distance_matrix(x))\n            \n        def extract_features(self):\n            self._get_mol_object()\n            self._add_h_atoms()\n            self._make_distance_matrix()\n        \n        def return_data(self):\n            return self.df\n        \n    class NodeFeaturesMatrix():\n        \n        def __init__(self, df):\n            self.df = df\n           \n        def _get_all_atom_types(self):\n            pass\n        \n        def _get_atom_type(self):\n            pass\n        \n        def _get_formal_charge(self):\n            pass\n        \n        def _get_implicit_Hs(self):\n            pass\n            \n        def _make_node_features_matrix(self):\n            pass\n        \n        def return_data(self):\n            return self.df\n        \n    class EdgeFeaturesMatrix():\n        \n        def __init__(self, df):\n            self.df = df\n            \n        def _get_all_bonds_in_df(self):\n            pass\n        \n        def _encode_smiles_bonds(self):\n            pass\n        \n        def _make_edge_featurs_matrix(self):\n            pass\n            \n        def return_data(self):\n            return self.df","4420a164":"train_sample=pd.read_csv('..\/input\/bms-molecular-dataset-only-firts-1000-pngs\/InChI2SMILES_1000th.csv')\ntrain_sample.path=train_sample.path.progress_apply(lambda x: \n                '..\/input\/bms-molecular-dataset-only-firts-1000-pngs\/bms-mol_v3\/bms-mol_v3\/'+x.split('\/')[2])\ntrain_sample.drop(columns=['Unnamed: 0','index'],inplace=True)\ntrain_sample.head()","ae50b549":"#!zip -r bms-mol_v3.zip .\/bms-mol_v3\n!ls ","d9bf9103":"cm_train = MOLGraphToMatrix().ConnectivityMatrix(train_sample)\ntrain = cm_train.return_data()\ntrain = train.query('len_con_matrix > 0')\ntrain = train.reset_index(drop=True)","687e05fe":"train.head()","afa8979b":"train_path = \"\/kaggle\/working\/train\"\ntest_path = \"\/kaggle\/working\/test\"\n\nif os.path.exists(train_path):\n    shutil.rmtree(train_path)\n    \nif os.path.exists(test_path):\n    shutil.rmtree(test_path)\n\nos.mkdir(train_path)\nos.mkdir(test_path)","be2d03bc":"def train_image_InchI_df(df):\n    df['image_id'] = np.nan\n    l = list()\n    for i, smiles in enumerate(df.SMILES):\n        _id = \".\/train\/image_{0}.png\".format(i)\n        l.append(_id)\n    df['image_id'] = l\n    images_df = pd.DataFrame(columns=[\"image_id\", \"SMILES\", \"InChI2p\"])\n    images_df.image_id = df.image_id\n    images_df.InChI2p = df.InChI2p\n    images_df.SMILES = df.SMILES\n    #images_df.InChI2p = images_df.InChI2p.apply(lambda x: x.split(\"\/\"))\n    return images_df\n\n### Check if the connectivity matrix is cero and remove it from the dataset -- Look later..\ntrain_sampleWOconnec=train_sample[train_sample[\"connectivity_matrix\"].str.len() != 0]\ntrain_images_df = train_image_InchI_df(train_sampleWOconnec)","d4141b20":"def make_image_from_smiles(idx, dataset_name, df):\n    arr = df.connectivity_matrix.iloc[idx]\n    arr = np.asarray(arr)\n    rescaled = (255.0 \/ arr.max() * (arr - arr.min())).astype(np.uint8)\n    path = \"\/kaggle\/working\/{0}\".format(dataset_name)\n    plt.imsave(\"\/kaggle\/working\/{0}\/image_{1}.png\".format(dataset_name, idx), rescaled)\n\nfor idx, smiles in tqdm(enumerate(train_sampleWOconnec.SMILES)): \n    make_image_from_smiles(idx, \"train\", train_sampleWOconnec)","668733dc":"train_sampleWOconnec.head()","3443109d":"!ls .\/train","84bfcb09":"def image_viz(image_id, title, figsize=(12,6)):\n    \"\"\"\n    Function for image visualization.\n    Takes image tensor, plot title (label) and figsize.\n    \"\"\"\n    image = cv2.imread(image_id)\n    plt.figure(figsize = figsize)\n    plt.imshow(image)\n    plt.title(title, size = 16)\n    plt.axis('off')\n    plt.show()\n    \n# ref: https:\/\/www.kaggle.com\/ihelon\/molecular-translation-exploratory-data-analysis \ndef convert_image_id_2_path(image_id: str) -> str:\n        return \"..\/input\/bms-molecular-dataset-only-firts-1000-pngs\/bms-mol_v3\/bms-mol_v3\/{}.png\".format(image_id\n    )\n\n#ref: https:\/\/www.kaggle.com\/ihelon\/molecular-translation-exploratory-data-analysis\ndef visualize_train_image(image_id, label):\n    plt.figure(figsize=(5, 5))\n    print(image_id)\n    image = cv2.imread(convert_image_id_2_path(image_id))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    plt.title(f\"{label}\", fontsize=14)\n    plt.axis(\"off\")\n    \n    plt.show()","eb319b10":"sample_row = data.iloc[0]\nvisualize_train_image(\n        sample_row[\"image_id\"], sample_row[\"InChI\"]\n    )","5e69a6f2":"sample_row =train_sampleWOconnec.iloc[0]\nimage_viz(sample_row['image_id'], sample_row['SMILES'])","72af85e1":" train_images_df.tail","fb593701":"from rdkit.Chem import Draw, AllChem\nidx=3\nsample_row = train_sampleWOconnec.iloc[idx]\n####\n####\n\n\ndef rotateImage(image, angle):\n    row,col = image.shape[:2]\n    center=tuple(np.array([row,col])\/2)\n    rot_mat = cv2.getRotationMatrix2D(center,angle,1.0)\n    new_image = cv2.warpAffine(image, rot_mat, (col,row))\n    return new_image\n\n\n## create a file ...\nDraw.MolToImageFile(rdkit.Chem.MolFromSmiles(sample_row.SMILES),'Mol_comparison.png')\nsrc1 = cv2.imread('Mol_comparison.png')\nsrc2 = rotateImage( cv2.flip( cv2.resize(cv2.imread(sample_row.path),np.array(src1).shape[:2]), 0), 35)\n\nalpha=0.2\nbeta = (1.0 - alpha)\ndst = cv2.addWeighted(src1, alpha, src2, beta, 0.0)\n\n\nplt.figure(figsize = (14, 14))\n\nax1 = plt.subplot2grid((1,3),(0,0))\nax1.imshow(dst)\nax2 = plt.subplot2grid((1,3),(0,1))\nax2.imshow(src1)\nax3 = plt.subplot2grid((1,3),(0,2))\nax3.imshow(src2)\n\nplt.show()","1ab4daa7":"print(np.array(src2).shape,np.array(src1).shape[:2])","e9881e4e":"from rdkit import Chem\nfrom rdkit.Chem import Draw, AllChem\nimport matplotlib.pyplot as plt\n\ndef draw_structure(mol_smiles_string, template_smiles_string, ax=None):\n    if not ax:\n        f, ax = plt.subplots()\n    m = Chem.MolFromSmiles(mol_smiles_string, sanitize=False)\n    m.UpdatePropertyCache()\n    Chem.SetHybridization(m)\n    t = Chem.MolFromSmiles(template_smiles_string, sanitize=False)\n    t.UpdatePropertyCache()\n    Chem.SetHybridization(t)\n    AllChem.Compute2DCoords(t)\n    AllChem.GenerateDepictionMatching2DStructure(m, t)\n    img = Draw.MolToImage(m)\n    return ax.imshow(img, interpolation='bessel')\n\nfig = plt.figure(figsize=(10,5))\nax1 = plt.subplot2grid((1, 3), (0, 0))\nax2 = plt.subplot2grid((1, 3), (0, 1))\ndraw_structure(mol_smiles_string=sample_row.SMILES,\ntemplate_smiles_string=sample_row.SMILES, ax=ax1)\ndraw_structure(mol_smiles_string=sample_row.SMILES,\ntemplate_smiles_string=sample_row.SMILES, ax=ax2)\nimage_viz(\n        sample_row.path, sample_row.InChI2p\n    )\nplt.tight_layout()\nplt.show()","dd5d1fce":"train_sample.head()#InChI2p.iloc[250]","a2ccaa7b":"plt.figure(figsize = (14, 14))\nfor i in range(3):\n    image = cv2.imread(train_sampleWOconnec.path.iloc[i])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image1 = cv2.imread(train_sampleWOconnec.image_id.iloc[i])\n    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n    \n    ax1 = plt.subplot(4, 3, 3*i+1)\n    ax1.imshow(image)\n    plt.title(train_sample.InChI2p.iloc[i][0:15]+'...', size = 10)\n    ax2 = plt.subplot(4, 3, 3*i+2)\n    ax2.imshow(image1)\n    ax3 = plt.subplot(4, 3, 3*i+3)\n    ax3.imshow(Draw.MolToImage(Chem.MolFromSmiles(train_sampleWOconnec['SMILES'].iloc[i])))\n    plt.title(train_sampleWOconnec['SMILES'].iloc[i][0:15]+'...', size = 10)\n    #plt.axis('off')\n\nplt.show()","934eff8f":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nw=10\nh=10\nfig=plt.figure(figsize=(10, 10))\ncolumns = 4\nrows = 5\nfor i in range(1, 15):\n    file = os.listdir('\/kaggle\/working\/train\/')[i]\n    img = mpimg.imread(os.path.join('\/kaggle\/working\/train\/', file))\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()","46760ede":"plt.figure(figsize=(15,5))\neda_train = train_sampleWOconnec.copy()\neda_train['len_smiles'] = train_sampleWOconnec.SMILES.apply(lambda x: len(x))\nax = sns.distplot(eda_train['len_smiles']).set_title(\"SMILES length in train dataset\")","3248ee53":"print(train_sample.shape,train_images_df.shape)","c2bec2ac":"import tensorflow as tf\nimport keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.experimental import CosineDecay\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, MaxPool2D, Dropout\nimport Levenshtein","8d6d2b23":"def train_trans_func(image):\n    return image \/ 255.\n\ndef val_trans_func(image):\n    return image \/ 255.\n\ndatagen_train = ImageDataGenerator(preprocessing_function = train_trans_func)\ndatagen_val = ImageDataGenerator(preprocessing_function = val_trans_func)","aabb13a3":"exploreSize = train_images_df.copy()\nexploreSize['img_tensor'] =train_images_df['image_id'].progress_apply(lambda x: io.imread(x))\n# Let's exlore the dimensions of images to take an \"average number...\"\nexploreSize['img_height'] = exploreSize['img_tensor'].progress_apply(lambda x: np.shape(x)[0])\nexploreSize['img_width'] = exploreSize['img_tensor'].progress_apply(lambda x: np.shape(x)[1])","08e32c05":"sns.jointplot(x = exploreSize['img_width'].astype('float32'), \n              y = exploreSize['img_height'].astype('float32'),\n              height = 4, color = '#930077')\nplt.show()","470bc900":"img_size=50\nclass_mode = \"raw\"\ninterpolation = \"nearest\"\nshuffle = False ## I want the map to be \"untouchable\"for now...\ncolor_mode = \"grayscale\"\nbatch_size_Run =64\nler_rat=0.005\n    \ndef create_train_set(train):\n    train_set = datagen_train.flow_from_dataframe(train,\n                                                  directory = None,\n                                                  seed = 12345,\n                                                  x_col = \"image_id\",\n                                                  y_col = 'SMILES',\n                                                  target_size = (img_size, img_size),\n                                                  class_mode = class_mode,\n                                                  interpolation = interpolation,\n                                                  shuffle = shuffle,\n                                                  color_mode = color_mode,\n                                                  batch_size = batch_size_Run,\n                                                  #######\n#                                                    rotation_range=40,\n#                                                    width_shift_range=0.2,\n#                                                    shear_range=0.2,\n#                                                    zoom_range=0.2,\n#                                                    horizontal_flip=True,\n                                                 )\n    return train_set\n    \ndef create_val_set(val):\n    val_set = datagen_val.flow_from_dataframe(val,\n                                              directory = None,\n                                              seed=12345,\n                                              x_col = \"image_id\",\n                                              y_col = 'SMILES',\n                                              target_size = (img_size, img_size),\n                                              class_mode = class_mode,\n                                              interpolation = interpolation,\n                                              shuffle = shuffle,\n                                              color_mode = color_mode,\n                                              batch_size = batch_size_Run)\n    return val_set","18862f0e":"from sklearn.model_selection import train_test_split\n\n## It does not matter if is not perftly organized. Yoy will receive dfs in return...\n\ntrain, val = train_test_split(train_images_df, test_size=0.2, random_state=12345)\n\n\n########\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n\n# prepare input data\ndef prepare_target(train_y_no):\n    le = LabelEncoder()\n    le.fit(train_y_no)\n    train_y = le.transform(train_y_no)\n    return train_y\n\ntrain['SMILES'] = prepare_target(train['SMILES'])\nval['SMILES'] = prepare_target(val['SMILES']) \nprint ('(Training, TEST)- TARGET shape:', train.shape, val.shape)\n########\n\n\n\nvalid_set = create_val_set(val)\ntrain_set = create_train_set(train)","c6d533cf":"train_images_df['SMILES'].head","bdf6ae4b":"import collections\nprint([item for item, count in collections.Counter(train_images_df['SMILES']).items() if count > 1])","a7fdd10e":"n_CLASS=len(train_images_df['SMILES'].unique())\nn_CLASS","6e818366":"def create_model():\n    model = Sequential()\n    model.add(Conv2D(16, 3, activation=\"relu\", padding=\"same\", input_shape=(img_size, img_size, 1)))\n    model.add(Conv2D(16, 3, activation=\"relu\", padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2), strides=None, padding=\"valid\"))\n    model.add(Conv2D(32, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(32, 3, activation=\"relu\", padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2), strides=None, padding=\"valid\"))\n    model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2), strides=None, padding=\"valid\"))\n    model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(64, 3, activation=\"relu\", padding=\"same\"))\n    model.add(BatchNormalization())\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(n_CLASS, activation=\"relu\"))\n    return model\n\nmodel = create_model()\nmodel.summary()","d134f7d4":"from keras.applications.resnet50 import ResNet50\n\nresnet_50 = tf.keras.applications.ResNet50V2(\n    include_top=True,\n    weights=None,\n    input_tensor=None,\n    input_shape=(img_size, img_size, 1),\n    pooling=max,\n    classes=n_CLASS,\n    classifier_activation='sigmoid')\n\nresnet_50.compile(loss='MAE', optimizer=optimizers.Adam(lr=0.003), metrics=[\"accuracy\"])\nresnet_50.summary()","b9f36c34":"step_size_train = train_set.n \/\/ train_set.batch_size\nstep_size_valid = valid_set.n \/\/ valid_set.batch_size\nprint(step_size_train,step_size_valid)","fde88964":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    patience=1,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\nepochs=20\nmodel = create_model()\n#model.load_weights(\"..\/input\/kaggle-api\/bms_formula_model.h5\")\n#model.load_weights(\".\/bms_formula_model.h5\")\n\nlr = CosineDecay(initial_learning_rate = ler_rat,\n                 decay_steps = step_size_train * epochs)\n\nmodel.compile(optimizer = Adam(learning_rate=  ler_rat),\n              loss='MAE',\n              metrics=['MAE'])\n#              loss=\"mean_squared_error\",\n#              metrics=[\"mean_squared_error\"])\n\n## checking --\ncheckpoint_cb = ModelCheckpoint(\"bms_CM_best_model.h5\",\n                                save_best_only=True,\n                                monitor=\"val_loss\",\n                                mode=\"min\")\n\n## Training --\nhistory = model.fit(train_set,\n                    validation_data = valid_set,\n                    epochs = epochs,\n                    batch_size = batch_size_Run,\n                    steps_per_epoch = step_size_train,\n                    validation_steps = step_size_valid,\n                    callbacks=[checkpoint_cb, early_stopping]) # checkpoint_cb,\n\n## saving --\nmodel.save(\"bms_CM_model.h5\")","789a3d00":"history_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss']].plot(title=\"MSE\") #,'val_loss'","ae30a68f":"from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stopping = EarlyStopping(\n    patience=1,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\ncheckpoint_cb = ModelCheckpoint(\"bms_CM_best_model.h5\",\n                                save_best_only=True,\n                                monitor=\"val_loss\",\n                                mode=\"min\")\n\nepochs=8\nresnet_history = resnet_50.fit(\n                    train_set,\n                    validation_data = valid_set,\n                    epochs = epochs,\n                    batch_size = batch_size_Run,\n                    steps_per_epoch = step_size_train,\n                    validation_steps = step_size_valid,\n                    callbacks=[checkpoint_cb, early_stopping]\n                    )","e145f5a3":"history_df = pd.DataFrame(resnet_history.history)\nhistory_df.loc[:, ['loss']].plot(title=\"MSE\") #,'val_loss'","9ad0e5dd":"for i, (imgArr, smilesArr) in enumerate(tqdm(train_set)):\n    if i >= 1:\n        break\n    Myimg=imgArr\n    Mysmiles=smilesArr\n    print(smilesArr)","fdd2ec56":"def image_viz2(image_id, title, figsize=(12,6)):\n    \"\"\"\n    Function for image visualization.\n    Takes image tensor, plot title (label) and figsize.\n    \"\"\"\n    image = image_id\n    plt.figure(figsize = figsize)\n    plt.imshow(image)\n    plt.title(title, size = 16)\n    plt.axis('off')\n    plt.show()","d6965cc9":"inchis = data['InChI'].iloc[0:nrows1]\ninchis","a201d5da":"idx=10\nsample_row = train_sample.iloc[idx]\n\nprint(train['InChI2p'][idx])\nprint('InChI=1S\/'+train['InChI2p'][idx] in inchis) ## Of course our label InChI2p is not in the list!\n\n\nimage_viz2(Myimg[idx], Mysmiles[idx])\n#####\n\nimage_viz(\n        sample_row[\"path\"], sample_row[\"SMILES\"]\n    )","47cf3b1b":"def triplet_loss(y_true, y_pred, alpha = 0.2):\n    \"\"\"\n    Implementation of the triplet loss\n    Arguments:\n    ...\n    \n    Returns:\n    loss -- real number, value of the loss\n    \"\"\"\n    \n    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n    \n    ###### \n    # Step 1: Compute the (encoding) distance between the anchor and the positive\n    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n    # Step 2: Compute the (encoding) distance between the anchor and the negative\n    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n    # Step 3: subtract the two previous distances and add alpha.\n    basic_loss =  tf.maximum(tf.subtract(pos_dist,neg_dist)+alpha,0)\n    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n    loss =  tf.reduce_sum(basic_loss)\n    #####\n    \n    return loss","b035ac95":"# Directing to Labels","196239bb":"v_2.0: Now, you don't need to download the example files and do the traduccion of the first SMILES. It is incorporated.\n\nv_3.0: Let's test ResNet50.","791acb94":"# BMS competition\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/e\/e7\/L-Ascorbic_acid.svg)\n\nCredit: Wikipedia\n\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#42c497;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:white;\">\n\nIn a technology-forward world, sometimes the best and easiest tools are still pen and paper. Organic chemists frequently draw out molecular work with the Skeletal formula, a structural notation used for centuries. Recent publications are also annotated with machine-readable chemical descriptions (InChI), but there are decades of scanned documents that can't be automatically searched for specific chemical depictions. Automated recognition of optical chemical structures, with the help of machine learning, could speed up research and development efforts.\n\nUnfortunately, most public data sets are too small to support modern machine learning models. Existing tools produce 90% accuracy but only under optimal conditions. Historical sources often have some level of image corruption, which reduces performance to near zero. In these cases, time-consuming, manual work is required to reliably convert scanned chemical structure images into a machine-readable format.\n\nBristol-Myers Squibb is a global biopharmaceutical company working to transform patients' lives through science. Their mission is to discover, develop, and deliver innovative medicines that help patients prevail over serious diseases.\n    \n<\/p>\n<\/div>","4ebc15c8":"<div class=\"alert alert-block alert-info\" style=\"font-size:24px; font-family:verdana; line-height: 1.7em;\">\n    \ud83d\udccc &nbsp; \n\n# Using CNN techniques\n    \n<\/div>","032f45f4":"***","7ee13ae2":"# Now let's add SMILEs to our dataset","d49501e0":"# We can work outside","2253a87b":"## The generator","fca7ae30":"1) https:\/\/www.kaggle.com\/ammarali32\/inchi-2-inchikey2-smiles\n\n2) https:\/\/www.kaggle.com\/vladislavkisin\/tutorial-ml-in-chemistry-research-rdkit-mol2vec","be6aa1ef":"# ResNet50","ba3afb9e":"<div class=\"alert alert-block alert-info\" style=\"font-size:24px; font-family:verdana; line-height: 1.7em;\">\n    \ud83d\udccc &nbsp; \n\n## The model\n    \n<\/div>","d9107071":"# Preparing data","bae16222":"# MOL extract","c5660de2":"<div class=\"alert alert-block alert-info\" style=\"font-size:24px; font-family:verdana; line-height: 1.7em;\">\n    \ud83d\udccc &nbsp; \n\n## Let's try to begin from something synthetic\n    \n<\/div>","36a0658f":"<div class=\"alert alert-block alert-info\" style=\"font-size:24px; font-family:verdana; line-height: 1.7em;\">\n    \ud83d\udccc &nbsp; \n\n## to be continue...\n    \n<\/div>","bdc9dc1b":"# Extracting features","5224abba":"# We are prepare to see both: \n\n# 1) Our draws, and \n# 2) SMILES pics. ","42dc26c7":"<div class=\"alert alert-block alert-info\" style=\"font-size:24px; font-family:verdana; line-height: 1.7em;\">\n    \ud83d\udccc &nbsp; \n\n## Rotating the images...\n    \n<\/div>","5f808528":"<h5 style=\"text-align: center; font-family: Verdana; font-size: 12px; font-style: normal; font-weight: bold; text-decoration: None; text-transform: none; letter-spacing: 1px; color: black; background-color: #ffffff;\">BY: Jos\u00e9 Manuel Ram\u00edrez <\/h5>","37b04e88":"## Well, well ... long strings with ~ 40 characters..."}}