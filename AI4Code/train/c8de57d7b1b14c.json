{"cell_type":{"433624d7":"code","8576284f":"code","927d844a":"code","d2b6b05a":"code","6ac2ec06":"code","de463c76":"code","87a3326e":"code","584d0b01":"code","42dfae1c":"code","c6678128":"code","1ad60c32":"code","e409b570":"code","b849bb09":"code","6a74daf6":"code","0b103a4f":"code","79af3c4f":"code","44237d30":"code","b3c971cf":"code","9a248d16":"code","d12174bb":"code","59d62fc6":"code","f841491e":"code","7d3f5ebe":"code","11ea2df2":"code","855d1151":"code","bd5ff890":"code","2254c1c4":"code","5c14ed5f":"code","0a78bf5b":"code","f6f0cc95":"code","b5d06ada":"code","1a8ecdce":"code","ab80ea66":"code","87edbcda":"code","677215b2":"code","16f3f330":"code","dd7ddd4b":"code","04c21643":"code","d5bbe29d":"code","fb695267":"code","44ec5720":"code","dffdf3b2":"code","98a6596d":"code","00ea7711":"code","f5898810":"code","edb49300":"code","37c64490":"code","68679d17":"code","6b985161":"code","c3c29f58":"code","d0b3890b":"code","2146f3f8":"code","33a36cc8":"code","0c98928f":"code","002e8a73":"code","63f5873b":"code","0d59f5db":"code","badfaaba":"code","cff2314a":"code","ca0a99c4":"code","e5b8bde5":"code","f62a674e":"code","f65742a2":"code","39e14117":"code","5c3ce097":"code","4b3d3fd0":"code","e3d4267a":"code","88592f82":"code","41602aa6":"markdown","03dfe168":"markdown","0a72b51d":"markdown","a993f5af":"markdown","c3cf619e":"markdown","5373eda0":"markdown","673a179f":"markdown","ff297f37":"markdown","cf5770ba":"markdown","3f51f621":"markdown","8b5c3b75":"markdown","d70996df":"markdown","48f56392":"markdown","984baf23":"markdown","a274f47e":"markdown","5522fe5a":"markdown","ef16ef56":"markdown","56bee79f":"markdown","4f73ac9c":"markdown","8e76a06a":"markdown","c3081ef5":"markdown","93f4a883":"markdown","50b6db8f":"markdown","5a6461c0":"markdown","2500d0c1":"markdown","927dd6db":"markdown","4496d7e8":"markdown","1b0400ec":"markdown","eecedcfd":"markdown","132d5025":"markdown","62ff1579":"markdown","d57a561b":"markdown","80b6e922":"markdown","f5f0122e":"markdown","d5fd8869":"markdown"},"source":{"433624d7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","8576284f":"df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf_new = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ndf = df.drop(columns='Id')\ndf_new = df_new.drop(columns='Id')","927d844a":"print(df.info())\nprint('\\n',df_new.info())","d2b6b05a":"print('MSSubClass Unique Values:')\nprint(df.MSSubClass.unique())\nprint(df_new.MSSubClass.unique())\nprint('\\nYrSold Unique Values')\nprint(df.YrSold.unique())\nprint(df_new.YrSold.unique())","6ac2ec06":"df.MSSubClass = df.MSSubClass.astype(object)\ndf_new.MSSubClass = df_new.MSSubClass.astype(object)\n\ndf.YrSold = df.YrSold.astype(object)\ndf_new.YrSold = df_new.YrSold.astype(object)","de463c76":"from sklearn.impute import SimpleImputer","87a3326e":"bsmt_df = df[df.columns[df.columns.str.contains('Bsmt')]]\nprint(bsmt_df.head())\nprint(bsmt_df.isnull().sum())","584d0b01":"no_bsmt_df = bsmt_df[bsmt_df.TotalBsmtSF == 0]\nwith_bsmt_df = bsmt_df[bsmt_df.TotalBsmtSF > 0]","42dfae1c":"# IMPUTE NO_BASEMENT!!\ncat_no_bsmt_df = no_bsmt_df.select_dtypes(object)\nnum_no_bsmt_df = no_bsmt_df.select_dtypes(exclude=object)\n\nimp_no_bsmt_df = SimpleImputer(strategy='constant', fill_value='no basement')\nimp_zero = SimpleImputer(strategy='constant', fill_value=0)\n\nimp_no_bsmt_df.fit(cat_no_bsmt_df)\nimp_zero.fit(num_no_bsmt_df)\n\ncat_no_bsmt_df = pd.DataFrame(imp_no_bsmt_df.transform(cat_no_bsmt_df), index = cat_no_bsmt_df.index, columns = cat_no_bsmt_df.columns)\nnum_no_bsmt_df = pd.DataFrame(imp_zero.transform(num_no_bsmt_df), index = num_no_bsmt_df.index, columns = num_no_bsmt_df.columns)\n\nno_bsmt_df = pd.concat([cat_no_bsmt_df, num_no_bsmt_df], axis=1)\nprint(no_bsmt_df.isnull().sum())","c6678128":"# IMPUTE WITH BASEMENTS!!\ncat_with_bsmt_df = with_bsmt_df.select_dtypes(object)\nnum_with_bsmt_df = with_bsmt_df.select_dtypes(exclude=object)\n\nimp_freq = SimpleImputer(strategy='most_frequent')\nimp_mean = SimpleImputer(strategy='mean')\n\nimp_freq.fit(cat_with_bsmt_df)\nimp_mean.fit(num_with_bsmt_df)\n\ncat_with_bsmt_df = pd.DataFrame(imp_freq.transform(cat_with_bsmt_df), index=cat_with_bsmt_df.index, columns=cat_with_bsmt_df.columns)\nnum_with_bsmt_df = pd.DataFrame(imp_mean.transform(num_with_bsmt_df), index=num_with_bsmt_df.index, columns=num_with_bsmt_df.columns)\n\nwith_bsmt_df = pd.concat([cat_with_bsmt_df, num_with_bsmt_df], axis=1)\nprint(with_bsmt_df.isnull().sum())","1ad60c32":"bsmt_df = pd.concat([with_bsmt_df, no_bsmt_df])\nbsmt_df.sort_index(inplace=True)\nbsmt_df.head()","e409b570":"bsmt_df_new = df_new[df_new.columns[df_new.columns.str.contains('Bsmt')]]\nprint(bsmt_df_new.head())\nprint(bsmt_df_new.isnull().sum())","b849bb09":"no_bsmt_df_new = bsmt_df_new[(bsmt_df_new.TotalBsmtSF == 0) | (bsmt_df_new.TotalBsmtSF.isnull() == True)]\nwith_bsmt_df_new = bsmt_df_new[bsmt_df_new.TotalBsmtSF > 0]","6a74daf6":"# IMPUTE NO_BASEMENT!!\ncat_no_bsmt_df_new = no_bsmt_df_new.select_dtypes(object)\nnum_no_bsmt_df_new = no_bsmt_df_new.select_dtypes(exclude=object)\n\nimp_no_bsmt_df_new = SimpleImputer(strategy='constant', fill_value='no basement')\nimp_zero = SimpleImputer(strategy='constant', fill_value=0)\n\nimp_no_bsmt_df_new.fit(cat_no_bsmt_df_new)\nimp_zero.fit(num_no_bsmt_df_new)\n\ncat_no_bsmt_df_new = pd.DataFrame(imp_no_bsmt_df_new.transform(cat_no_bsmt_df_new), index = cat_no_bsmt_df_new.index, columns = cat_no_bsmt_df_new.columns)\nnum_no_bsmt_df_new = pd.DataFrame(imp_zero.transform(num_no_bsmt_df_new), index = num_no_bsmt_df_new.index, columns = num_no_bsmt_df_new.columns)\n\nno_bsmt_df_new = pd.concat([cat_no_bsmt_df_new, num_no_bsmt_df_new], axis=1)\nprint(no_bsmt_df_new.isnull().sum())","0b103a4f":"# IMPUTE WITH BASEMENTS!!\ncat_with_bsmt_df_new = with_bsmt_df_new.select_dtypes(object)\nnum_with_bsmt_df_new = with_bsmt_df_new.select_dtypes(exclude=object)\n\nimp_freq = SimpleImputer(strategy='most_frequent')\nimp_mean = SimpleImputer(strategy='mean')\n\nimp_freq.fit(cat_with_bsmt_df_new)\nimp_mean.fit(num_with_bsmt_df_new)\n\ncat_with_bsmt_df_new = pd.DataFrame(imp_freq.transform(cat_with_bsmt_df_new), index=cat_with_bsmt_df_new.index, columns=cat_with_bsmt_df_new.columns)\nnum_with_bsmt_df_new = pd.DataFrame(imp_mean.transform(num_with_bsmt_df_new), index=num_with_bsmt_df_new.index, columns=num_with_bsmt_df_new.columns)\n\nwith_bsmt_df_new = pd.concat([cat_with_bsmt_df_new, num_with_bsmt_df_new], axis=1)\nprint(with_bsmt_df_new.isnull().sum())","79af3c4f":"bsmt_df_new = pd.concat([with_bsmt_df_new, no_bsmt_df_new])\nbsmt_df_new.sort_index(inplace=True)\nbsmt_df_new.head()","44237d30":"garage_df = df[df.columns[df.columns.str.contains('Garage')]]\nprint(garage_df.head())\nprint(garage_df.isnull().sum())","b3c971cf":"no_garage_df = garage_df[(garage_df.GarageArea == 0)]\nprint(no_garage_df.isnull().sum())\nwith_garage_df = garage_df[(garage_df.GarageArea > 0)]\nprint('\\n')\nprint(with_garage_df.isnull().sum())","9a248d16":"# IMPUTE NO_GARAGE!!\ncat_no_garage_df = no_garage_df.select_dtypes(object)\nnum_no_garage_df = no_garage_df.select_dtypes(exclude=object)\n\nimp_no_garage_df = SimpleImputer(strategy='constant', fill_value='no basement')\nimp_zero = SimpleImputer(strategy='constant', fill_value=0)\n\nimp_no_garage_df.fit(cat_no_garage_df)\nimp_zero.fit(num_no_garage_df)\n\ncat_no_garage_df = pd.DataFrame(imp_no_garage_df.transform(cat_no_garage_df), index = cat_no_garage_df.index, columns = cat_no_garage_df.columns)\nnum_no_garage_df = pd.DataFrame(imp_zero.transform(num_no_garage_df), index = num_no_garage_df.index, columns = num_no_garage_df.columns)\n\nno_garage_df = pd.concat([cat_no_garage_df, num_no_garage_df], axis=1)\nprint(no_garage_df.isnull().sum())","d12174bb":"garage_df = pd.concat([no_garage_df, with_garage_df])\ngarage_df.sort_index(inplace=True)\ngarage_df.head()","59d62fc6":"garage_df_new = df_new[df_new.columns[df_new.columns.str.contains('Garage')]]\nprint(garage_df_new.head())\nprint(garage_df_new.isnull().sum())","f841491e":"no_garage_df_new = garage_df_new[(garage_df_new.GarageArea == 0) | (garage_df_new.GarageArea.isnull())]\nprint(no_garage_df_new.isnull().sum())\nwith_garage_df_new = garage_df_new[(garage_df_new.GarageArea > 0)]\nprint('\\n')\nprint(with_garage_df_new.isnull().sum())","7d3f5ebe":"garage_df_new.loc[1116, 'GarageType'] = np.nan\ngarage_df_new.loc[1116]","11ea2df2":"# IMPUTE NO_GARAGE!!\ncat_no_garage_df_new = no_garage_df_new.select_dtypes(object)\nnum_no_garage_df_new = no_garage_df_new.select_dtypes(exclude=object)\n\nimp_no_garage_df_new = SimpleImputer(strategy='constant', fill_value='no basement')\nimp_zero = SimpleImputer(strategy='constant', fill_value=0)\n\nimp_no_garage_df_new.fit(cat_no_garage_df_new)\nimp_zero.fit(num_no_garage_df_new)\n\ncat_no_garage_df_new = pd.DataFrame(imp_no_garage_df_new.transform(cat_no_garage_df_new), index = cat_no_garage_df_new.index, columns = cat_no_garage_df_new.columns)\nnum_no_garage_df_new = pd.DataFrame(imp_zero.transform(num_no_garage_df_new), index = num_no_garage_df_new.index, columns = num_no_garage_df_new.columns)\n\nno_garage_df_new = pd.concat([cat_no_garage_df_new, num_no_garage_df_new], axis=1)\nprint(no_garage_df_new.isnull().sum())","855d1151":"# IMPUTE WITH GARAGE!!\ncat_with_garage_df_new = with_garage_df_new.select_dtypes(object)\nnum_with_garage_df_new = with_garage_df_new.select_dtypes(exclude=object)\n\nimp_freq = SimpleImputer(strategy='most_frequent')\nimp_mean = SimpleImputer(strategy='mean')\n\nimp_freq.fit(cat_with_garage_df_new)\nimp_mean.fit(num_with_garage_df_new)\n\ncat_with_garage_df_new = pd.DataFrame(imp_freq.transform(cat_with_garage_df_new), index=cat_with_garage_df_new.index, columns=cat_with_garage_df_new.columns)\nnum_with_garage_df_new = pd.DataFrame(imp_mean.transform(num_with_garage_df_new), index=num_with_garage_df_new.index, columns=num_with_garage_df_new.columns)\n\nwith_garage_df_new = pd.concat([cat_with_garage_df_new, num_with_garage_df_new], axis=1)\nprint(with_garage_df_new.isnull().sum())","bd5ff890":"garage_df_new = pd.concat([no_garage_df_new, with_garage_df_new])\ngarage_df_new.sort_index(inplace=True)\ngarage_df_new.head()","2254c1c4":"pool_df = df[df.columns[df.columns.str.contains('Pool')]]\npool_df.head()\npool_df.isnull().sum()","5c14ed5f":"pool_df[pool_df.PoolArea > 0]","0a78bf5b":"pool_df.PoolQC = pool_df.PoolQC.fillna('no pool')\npool_df.PoolQC.unique()","f6f0cc95":"pool_df_new = df_new[df_new.columns[df_new.columns.str.contains('Pool')]]\npool_df_new.head()\npool_df_new.isnull().sum()","b5d06ada":"pool_df_new[pool_df_new.PoolArea > 0]","1a8ecdce":"pool_df_new.PoolQC[pool_df_new.PoolArea > 0] = pool_df_new.PoolQC[pool_df_new.PoolArea > 0].fillna('Gd')\npool_df_new[pool_df_new.PoolArea > 0]","ab80ea66":"pool_df_new.PoolQC = pool_df_new.PoolQC.fillna('no pool')\npool_df_new.PoolQC.unique()","87edbcda":"masvnr_df = df[df.columns[df.columns.str.contains('Mas')]]\nprint(masvnr_df.head())\nprint(masvnr_df.isnull().sum())","677215b2":"masvnr_df[masvnr_df.MasVnrType.isnull()]","16f3f330":"masvnr_df.MasVnrType = masvnr_df.MasVnrType.fillna('None')\nmasvnr_df.MasVnrArea = masvnr_df.MasVnrArea.fillna(0)","dd7ddd4b":"masvnr_df.MasVnrType.unique()","04c21643":"masvnr_df_new = df_new[df_new.columns[df_new.columns.str.contains('Mas')]]\nprint(masvnr_df_new.head())\nprint(masvnr_df_new.isnull().sum())","d5bbe29d":"masvnr_df_new[masvnr_df_new.MasVnrType.isnull()]","fb695267":"masvnr_df_new.MasVnrArea = masvnr_df_new.MasVnrArea.fillna(0)\nmasvnr_df_new.MasVnrType[masvnr_df_new.MasVnrArea == 0] = masvnr_df_new.MasVnrType[masvnr_df_new.MasVnrArea == 0].fillna('None')","44ec5720":"masvnr_df_new.MasVnrType.value_counts()","dffdf3b2":"mask = (masvnr_df_new.MasVnrType.isnull() == True) & (masvnr_df_new.MasVnrArea > 0)\nmasvnr_df_new.MasVnrType[mask] = masvnr_df_new.MasVnrType[mask].fillna(masvnr_df_new.MasVnrType.value_counts().index[1])","98a6596d":"print(masvnr_df_new.isnull().sum())\nprint(masvnr_df_new.MasVnrType.unique())","00ea7711":"fireplace_df = df[df.columns[df.columns.str.contains('Fire')]]\nprint(fireplace_df.head())\nprint(fireplace_df.isnull().sum())","f5898810":"fireplace_df.FireplaceQu[fireplace_df.Fireplaces == 0] = fireplace_df.FireplaceQu[fireplace_df.Fireplaces == 0].fillna('no fireplace')","edb49300":"print(fireplace_df.isnull().sum())","37c64490":"fireplace_df_new = df_new[df_new.columns[df_new.columns.str.contains('Fire')]]\nprint(fireplace_df_new.head())\nprint(fireplace_df_new.isnull().sum())","68679d17":"fireplace_df_new.FireplaceQu[fireplace_df_new.Fireplaces == 0] = fireplace_df_new.FireplaceQu[fireplace_df_new.Fireplaces == 0].fillna('no fireplace')","6b985161":"print(fireplace_df_new.isnull().sum())","c3c29f58":"col_used = np.concatenate((garage_df.columns.values, bsmt_df.columns.values, pool_df.columns.values,\n                           masvnr_df.columns.values, fireplace_df.columns.values))\nremaining_df = df.drop(col_used, axis=1)\nremaining_df_new = df_new.drop(col_used, axis=1)","d0b3890b":"remaining_df.isnull().sum()[remaining_df.isnull().sum() > 0]","2146f3f8":"remaining_df.LotFrontage = remaining_df.LotFrontage.fillna(remaining_df.LotFrontage.mean())\nremaining_df.Alley = remaining_df.Alley.fillna('no alley')\nremaining_df.Electrical = remaining_df.Electrical.fillna(remaining_df.Electrical.value_counts().index[0])\nremaining_df.Fence = remaining_df.Fence.fillna('no fence')\nremaining_df.MiscFeature = remaining_df.MiscFeature.fillna('no misc feature')","33a36cc8":"df = pd.concat([remaining_df, fireplace_df, pool_df, masvnr_df, garage_df, bsmt_df], axis=1)\ndf['test_set'] = 0\nprint(df.info())","0c98928f":"remaining_df_new.isnull().sum()[remaining_df_new.isnull().sum() > 0]","002e8a73":"remaining_df_new.LotFrontage = remaining_df_new.LotFrontage.fillna(remaining_df_new.LotFrontage.mean())\nremaining_df_new.Alley = remaining_df_new.Alley.fillna('no alley')\nremaining_df_new.Fence = remaining_df_new.Fence.fillna('no fence')\nremaining_df_new.MiscFeature = remaining_df_new.MiscFeature.fillna('no misc feature')\nremaining_df_new.Utilities = remaining_df_new.Utilities.fillna(remaining_df_new.Utilities.value_counts().index[0])\nremaining_df_new.Exterior1st = remaining_df_new.Exterior1st.fillna(remaining_df_new.Exterior1st.value_counts().index[0])\nremaining_df_new.Exterior2nd = remaining_df_new.Exterior2nd.fillna(remaining_df_new.Exterior2nd.value_counts().index[0])\nremaining_df_new.KitchenQual = remaining_df_new.KitchenQual.fillna(remaining_df_new.KitchenQual.value_counts().index[0])\nremaining_df_new.Functional = remaining_df_new.Functional.fillna(remaining_df_new.Functional.value_counts().index[0])\nremaining_df_new.SaleType = remaining_df_new.SaleType.fillna(remaining_df_new.SaleType.value_counts().index[0])\nremaining_df_new.MSZoning = remaining_df_new.MSZoning.fillna(remaining_df_new.MSZoning.value_counts().index[0])","63f5873b":"df_new = pd.concat([remaining_df_new, fireplace_df_new, pool_df_new, masvnr_df_new, garage_df_new, bsmt_df_new], axis=1)\ndf_new['test_set'] = 1\nprint(df_new.info())","0d59f5db":"# Check if 'TotalBsmtSF' is the sum of BsmtFinSF1, BsmtFinSF2, and BsmtUnfSF\nif (df.BsmtFinSF1 + df.BsmtFinSF2 + df.BsmtUnfSF == df.TotalBsmtSF).sum() == len(df):\n    df = df.drop(columns='TotalBsmtSF')\nif (df_new.BsmtFinSF1 + df_new.BsmtFinSF2 + df_new.BsmtUnfSF == df_new.TotalBsmtSF).sum() == len(df_new):\n    df_new = df_new.drop(columns='TotalBsmtSF')\nprint(\"'TotalBsmtSF' dropped\")","badfaaba":"# Encode Categorical Features\ndata = pd.concat([df, df_new], ignore_index=True)\ndata = pd.get_dummies(data)\n\n# Set Training & Test Features\nX = data[data.test_set == 0].drop(columns=['test_set', 'SalePrice'])\nX_pred = data[data.test_set == 1].drop(columns=['test_set', 'SalePrice'])\nprint('Training features shape:')\nprint(X.shape)\nprint('\\nTest features shape:')\nprint(X_pred.shape)","cff2314a":"y = df.SalePrice\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\nax1.hist(y)\nax2.hist(np.log(y))","ca0a99c4":"# Set Target (Logarithmic Transformation)\ny = np.log(df.SalePrice)\nprint('Target shape:')\nprint(y.shape)","e5b8bde5":"# Validation Split (30%)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","f62a674e":"from sklearn.model_selection import GridSearchCV","f65742a2":"from sklearn.ensemble import GradientBoostingRegressor\nparam_gbr = {'n_estimators' : np.arange(500, 1100, 100)}\ngbr = GradientBoostingRegressor()\ngbr_cv = GridSearchCV(gbr, param_gbr, cv=3)\ngbr_cv.fit(X_train, y_train)\nprint('GBR Best Params & Score:')\nprint(gbr_cv.best_params_)\nprint(gbr_cv.best_score_)","39e14117":"from sklearn.metrics import mean_squared_log_error\ny_val = np.exp(gbr_cv.predict(X_test))\ny_true = np.exp(y_test)\nprint('Validation RMSLE: {:.4f}'.format(np.sqrt(mean_squared_log_error(y_true, y_val))))","5c3ce097":"# Re-train GB Regressor\ngbr_cv.fit(X, y)\nprint('GBR Best Params & Score:')\nprint(gbr_cv.best_params_)\nprint(gbr_cv.best_score_)","4b3d3fd0":"y_pred = np.exp(gbr_cv.predict(X_pred))\nprint('Predictions Shape:')\nprint(y.shape)","e3d4267a":"submission = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv', index_col=0)\nprint(submission.head())\nsubmission.SalePrice = y_pred\nprint('\\n')\nprint(submission.head())","88592f82":"submission.to_csv('submission.csv')\nprint('Result saved successfully!')","41602aa6":"### TEST DATA","03dfe168":"Target variable is normal when transformed into logarithmic therefore:","0a72b51d":"### TRAINING DATA","a993f5af":"**NOTES:**\n1. This notebook is **based on my limited knowledge**.\n2. I have tried several algorithm including random forest and xgb regressor. So far the gradient boosting regressor works best.\n\nThank you!","c3cf619e":"## CHECK FIREPLACE","5373eda0":"### TRAINING DATA","673a179f":"Check target distribution:","ff297f37":"## TEST DATA","cf5770ba":"Separate houses with garage & without:","3f51f621":"## CHECK BASEMENT\n### TRAINING DATA","8b5c3b75":"## CHECK GARAGE","d70996df":"There are no missing values for houses with garage therefore we only impute the houses with no garage:","48f56392":"Impute with different strategies for houses with basement and houses without:","984baf23":"# PREDICTIONS","a274f47e":"Separate houses with basements based on 'TotalBsmtSF' value:","5522fe5a":"Fill with most frequent value (not including 'None') for houses with MasonVnr","ef16ef56":"# ML PREPROCESSING\nThis chapter includes correlated feature removal, categorical data encoding, validation split, and target transformation.","56bee79f":"### TEST DATA","4f73ac9c":"### TEST DATA","8e76a06a":"Based on the table above, we can conclude that null values in PoolArea & PoolQC indicates no pool in the house.","c3081ef5":"## CHECK OTHER FEATURES","93f4a883":"# GRADIENT BOOSTING MODEL CHECK\nBefore predicting the test set, I looked at the model's performance in a validation dataset. Notes to be considered:\n1. **Validation size = 30%** of training data\n2. Hyperparametric tuning is done on **'n_estimators'**\n3. Validation score uses **RMSLE**","50b6db8f":"### TRAINING DATA","5a6461c0":"## CHECK POOL\n### TRAINING DATA","2500d0c1":"Fill with 0 & 'None' for houses without MasonryVnr:","927dd6db":"Fill MasVnrType with 'None' and MasVnrArea with 0:","4496d7e8":"## CHECK MASONRY VENEER\n### TRAINING DATA","1b0400ec":"As informed in data_description.txt, **'MSSubClass'** should be a categorical. I also experimented by categorizing **'YrSold'** since it has very few unique entries.","eecedcfd":"# FEATURE ENGINEERING\nFeature checks are done separately between training & test data. This chapter mainly consists of **inspecting the null values in the data**.\n1. Basement Check\n2. Garage Check\n3. Pool Check\n4. Masonry Veneer Check\n5. Fireplace Check\n6. Other Features Check","132d5025":"### TEST DATA","62ff1579":"# Project Summary\nThis is an update from my previous work. In this notebook, I cleaned the features separately between the training & test data. The feature engineering focused on house features such as basement, garage, masonry veneer, pool, fireplace, etc. Using **Gradient Boosting Regressor**, I got RMSLE = 0.13317 and ranked in top 36% (by the time I wrote this). I did not blend my results from other kernels in this notebook.\n\nReferences:\n1. https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python\n2. https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard\netc.\n\nContents:\n1. Feature Engineering\n2. ML Preprocessing\n3. Gradient Boosting Model Check\n4. Predictions & Submission\n","d57a561b":"Concatenate to bsmt_df:","80b6e922":"This chapter consists of model retraining (to the whole training set), test set prediction, and submission.","f5f0122e":"Impute 'Gd' PoolQC in houses with pool (assumes pool have Good quality!)","d5fd8869":"## TEST DATA"}}