{"cell_type":{"b40dd01b":"code","73fcbc7f":"code","1357a032":"code","41e16b30":"code","0f9895b2":"code","4ddaedeb":"code","c13dfd8f":"code","ae82d564":"code","aeaacb7e":"code","00344a3c":"code","cd82976e":"code","dc93e7fd":"code","0f6e8d11":"code","c776c5bd":"code","f415dfdd":"code","8687e036":"code","dc818300":"code","59905c2f":"code","c35f4825":"code","320f77dd":"code","8587ede7":"code","137facdf":"code","0f3f8991":"code","91d10b4a":"code","2d52e80e":"code","7e61c96e":"code","a1f83045":"code","ec95a8a5":"code","38425156":"code","f25bcb33":"code","d1f2883c":"code","7e1a3d9a":"code","06d19d57":"code","dc307035":"code","3c18eb35":"code","b267637f":"code","3ca2cfe8":"code","34c4ff4a":"code","2c528a5f":"code","8817c3b2":"code","f9b5013c":"code","c95d0897":"code","927e1a7a":"code","33baa84a":"code","bf93239e":"code","f018ee02":"code","06998b4a":"code","9a8211a0":"code","3e53fcaf":"code","7f05cb2f":"code","b7651ebb":"code","f56e8a24":"code","6f7a869e":"code","117df77f":"code","81b56ec3":"code","d5698016":"code","95799812":"code","029f1dec":"code","8095222b":"code","c006fc32":"code","5828f6f0":"code","67ba35c0":"code","4728b411":"code","f845038d":"code","19747650":"code","323d046a":"code","39fb0d30":"code","d96c9740":"code","7d2f0030":"code","042225e0":"code","6e3e38b3":"code","84151611":"code","19385ab9":"code","d05c088b":"code","e22c3ab0":"code","8ade9787":"code","984152fa":"code","0a9df858":"code","1146bfd8":"code","a43bcb1a":"code","b95fb8e6":"code","0bf01641":"code","54c851e1":"code","d171c347":"code","76851488":"code","9b8205f6":"code","e42a4386":"code","d39a28a4":"code","17120ed7":"code","99cc706a":"code","f3ec8a6d":"code","0dbd0617":"code","75d76b88":"code","4a006c12":"code","c26ccc4a":"code","3708c8a1":"code","68eb616a":"code","b38988cd":"code","05dd3c63":"code","ab5ed12d":"code","4e690530":"code","74565d74":"code","e4233cdc":"code","53444858":"code","4336a936":"code","97e64d11":"code","1ff9543f":"code","bf59268b":"code","a7c54e74":"code","dd7314d7":"code","170cff2c":"code","a87b2b8e":"code","0b794aa9":"code","e0d1ece9":"code","5ffac8b4":"code","521bfc10":"code","c5526cfc":"code","7123f62a":"code","a65cad20":"code","fd6fb203":"code","d1399050":"code","98eb4b1b":"code","7e67ec8e":"code","de4767ed":"code","7c0b1f41":"code","68a10d68":"code","f35d6ccd":"code","49ae5404":"code","25499b5a":"code","e8d32e0c":"code","6176b28c":"code","1474c7f7":"code","61c5f3e5":"code","9929e800":"code","9711d0dc":"code","32db96da":"code","41351312":"code","8b32d4ec":"code","7bf525e3":"code","32578aa2":"code","f9078d46":"code","896f3b88":"code","63a1cc06":"code","d644c96c":"code","a853b0a1":"code","66bf8e36":"code","2bcbd82e":"code","20ad1e6a":"code","382288d2":"code","89ad25f2":"code","3f715cb3":"code","390c1876":"code","776f9c7a":"code","601836d9":"code","e719880e":"code","ddc0280c":"code","17adf150":"code","bc0f5d4e":"code","5ee70876":"code","766216a8":"code","65af092d":"code","11508c77":"code","1410713f":"code","f71b9904":"code","797f03a1":"code","54f5b61e":"code","7f38d367":"code","ae4b1ecb":"code","2d1a894d":"code","9af1d99f":"code","136efe4e":"code","d64329eb":"code","fc38d673":"code","21b3819f":"code","c56c22f3":"code","455cd8a7":"code","556e9af3":"code","85abc498":"code","cc734345":"code","e4a1b11c":"code","6836068d":"code","b869c157":"code","7c84045b":"code","36ec84f1":"code","5d0062bb":"code","8e63c1f9":"code","764be84b":"code","d6ad54d1":"code","8e09bc4c":"code","82d0ed64":"code","3a199583":"code","f2a5891b":"code","50a5df2c":"code","f63e2536":"code","7aa8c826":"code","15bcabbd":"code","3b0d0101":"code","3eb0cbdf":"code","ee6ce3e8":"code","066a9948":"code","3dbb6303":"code","50fbcd5b":"code","fade2829":"code","90b0fb3c":"code","086f6b3a":"code","11827452":"code","e2e5c5ed":"code","c5a358e4":"code","6ced7a4e":"code","6da4d946":"code","93694660":"code","c690454d":"code","4613c561":"code","62da4a46":"code","f814c164":"code","3deed687":"code","9d3be448":"code","12ea307e":"code","d3c19124":"code","3896add8":"code","272084b7":"code","10abe973":"code","4b4a2f66":"code","8492cb62":"code","c04c3621":"code","cbc7da3f":"code","0a40a7c8":"code","10403d79":"code","fa64d1bf":"code","133dd00b":"code","a7fa815d":"code","7d999473":"code","d5fbd2ae":"code","7ca15639":"code","178f0e4d":"code","4d14067a":"code","db19f195":"code","da460b85":"code","2152b361":"code","15960568":"code","b3c634e0":"code","a95a916d":"code","4a431fc7":"code","2db6241f":"code","35e2f10e":"code","0ea85b98":"code","2f7296a4":"code","aa822e3c":"code","4c751c20":"code","f1e2aab5":"code","0c724ef5":"code","df6be6d9":"code","1a131e72":"code","adbe2e46":"code","5f3a7630":"code","f9c883cf":"code","c7f1f386":"code","7dbc8d58":"code","70276118":"code","39ecdc71":"code","979b926d":"code","868a032e":"code","478a98bc":"code","c4a4b216":"code","b8e6fdeb":"code","11cd02c9":"code","f2031c7a":"code","fb4f2016":"code","fbdaf26d":"code","dd63b9d8":"code","e6cae40d":"code","3c043405":"code","e8cb9bc2":"code","099de917":"code","fe8791ed":"code","35c9b270":"code","4cf880ea":"code","49788af7":"code","771d04c8":"code","79578d46":"code","63622b75":"code","2d2f5dc8":"code","2750cd55":"code","8ba8786e":"code","c37ed02b":"code","f9c2bc2b":"code","718661a7":"code","ce8bd49a":"code","1c2fbeb6":"code","e0450633":"code","163a269c":"code","aaadf7bb":"code","bf14456f":"code","920ea619":"code","800ba727":"code","6d46d1ab":"code","27774dac":"code","c5d2e15e":"code","c8fa975d":"code","6a4e84cf":"code","b2502a0d":"code","73819e98":"code","5f7142ef":"code","22123592":"code","d3b487e0":"code","ce11b93d":"code","813bd491":"code","cf95ae43":"code","4483a980":"code","2211e581":"code","612a1769":"code","586d1611":"code","c0430a24":"code","2b9c2da9":"code","95029586":"code","deaeeca0":"code","1c16531e":"code","7d3fcc24":"code","04bddecf":"code","3a56da44":"code","c2d3159c":"code","4268d0ce":"code","08494bd3":"code","b5d7b181":"code","75f13d1b":"code","93cf3faf":"code","798b0744":"code","a2c74bc4":"code","a0d2611b":"code","d681af28":"code","37939885":"code","67108fde":"code","7b4fdca5":"code","5c1b41d7":"code","c85e12d3":"code","660e975b":"code","a7e491b9":"code","fdedf11b":"code","f3d63dc1":"code","0da7626f":"code","49b75bb0":"code","6a4c36c6":"code","47451198":"code","9e64d240":"code","8d8d9d46":"code","be38e5ad":"code","4a0a52be":"code","b731a938":"code","ccb86878":"code","ef997687":"code","3d595b23":"code","32893470":"code","6c3eec92":"code","437749f8":"code","c634ca50":"code","28d4de03":"code","8c1fe486":"code","7d28a0b7":"code","bf06fdf1":"code","081e996a":"code","fee7cd49":"code","8c9cb9e3":"code","b8530ba2":"code","a2c28bd1":"code","3625e2ed":"code","73649550":"code","2215fec4":"code","3d1b9cb1":"code","6d9333e5":"code","22ee28e0":"code","f015b9a0":"code","5f1df23d":"code","67bb46c0":"code","3c92fa4b":"code","c2f07b7a":"code","1bc8d1d7":"code","f73f4ceb":"code","90d12c7e":"code","53935949":"code","ed0c5fca":"code","cb0b247f":"code","ede6ca9d":"code","63d91ccb":"code","d6af80f7":"code","8ffd5ccf":"code","9c620aac":"code","38a822f2":"code","38bbdf52":"code","469f9f25":"code","45a3dbe3":"code","8a8b3748":"code","11c9e438":"code","c6ea5f0b":"code","b079882d":"code","002bfd0c":"code","d981c18e":"code","4f427b6d":"code","6b71b402":"code","4fde3626":"code","31c063e2":"code","86a7f3c8":"code","0fc240cf":"code","74e46576":"code","db54b4c6":"code","544d985a":"code","86ae4660":"code","4cb9af49":"code","c0b23000":"code","10a2481f":"code","5aea0b2f":"code","a983e79f":"code","b7d7cbe8":"code","99332400":"code","9e0f925e":"code","f9129ad1":"code","46d897fb":"code","48209723":"code","6eeae669":"code","29a1290c":"code","35df04d5":"code","b680e766":"code","13422760":"code","ceac8720":"code","22a1e9c1":"code","23cc67bc":"code","12216c8d":"code","e9fc3533":"code","a5849e87":"code","e6ab9df7":"code","20c17cd3":"code","b9c97c68":"code","162c3bab":"code","f66f8bdc":"code","a1b62d7c":"code","575ee638":"code","b5c6c87d":"code","5610d855":"code","e530817c":"code","d1639e44":"code","01057882":"code","8f031f50":"code","2f97982a":"code","21854af2":"code","af3711a8":"code","26184624":"code","5f8082d3":"code","1c793fa2":"code","f1d54ba6":"code","7685d0e1":"code","17c68ed2":"code","ef657fdc":"code","a14b3ed4":"code","558c7bc7":"code","600870e7":"code","9012a5f6":"code","900345fb":"code","c41b6f65":"code","76af8467":"code","0bd31047":"code","782d2c46":"code","faae78de":"code","fe0c5c4a":"code","e1a469ee":"code","1272fd13":"code","b94c342e":"code","6cf098eb":"code","ed59530a":"code","7b0f6406":"code","761dced5":"code","31557cc7":"code","4946d1cf":"code","86463fbf":"code","1ec715c9":"code","3a332f74":"code","9550d93b":"code","2f748db3":"code","517849db":"code","fbaf0a8a":"code","fad8a709":"code","c9961591":"code","64db19fa":"code","c65b3ec2":"code","785d9678":"code","662dbdff":"code","474890b8":"code","3cdef5c4":"code","9d0b9cf9":"code","8f3470e8":"code","29c0c601":"code","30b1b085":"code","9806dede":"code","026e8bf6":"code","d24d4354":"code","267f91cb":"code","486459c1":"code","748f9d69":"code","4ea4d92f":"code","ef35f809":"code","ab4c2104":"code","b4dec460":"code","cdc12b3b":"code","31fcf260":"code","72da339c":"code","e8beb567":"code","29af4a46":"code","56350cb9":"code","0ce8fc81":"code","a2072c0b":"code","be1cbc90":"code","ff11e0f3":"code","b420e1dc":"code","98ad08c9":"code","63d2d178":"code","acc86fab":"code","bdc91a70":"code","e445309c":"code","908eeff9":"code","d3a1408f":"code","56006619":"code","ca041fd9":"code","ed861d98":"code","795e8db3":"code","4e0fd540":"code","eabde38a":"code","e8de1337":"code","9bb59dc0":"code","a3e9cd87":"code","eede1653":"code","0a6a4724":"code","62bbb6e5":"code","7e95b327":"code","00eb4c48":"code","d1ce520b":"code","b54cef13":"code","609177aa":"code","63f029ec":"code","81e1c33a":"code","c1357ee9":"code","25592c5f":"code","f77cb741":"code","b7d0d3ef":"code","9647ae1a":"code","661ea2b5":"code","bdc5566a":"code","8fea1c30":"code","4b4dcfc6":"code","3820efa9":"code","be7ef3f9":"code","1df6750c":"code","a76c5f60":"code","be4ba14b":"code","7f9c4185":"code","7be60752":"code","0f99ab6b":"code","9f28949c":"code","b7557ba8":"code","59401051":"code","b15d3a7f":"code","112d674e":"code","01c074c9":"code","e71c1660":"code","0158ec22":"code","94887319":"code","3fbb65f0":"code","89ae2daf":"code","ef9a6b51":"code","b1810c91":"code","bb61fb80":"code","76c3543b":"code","86e82378":"code","b671a57c":"code","e823322b":"code","2932ac49":"code","dbafdae9":"code","3490e481":"code","e1867466":"code","6ef1eea9":"code","2d032676":"code","9b7c9c43":"code","8cf2e9be":"code","899bc260":"code","6fb9c209":"code","03e20f44":"code","e95530c5":"code","23bc1713":"code","26c7acda":"code","35cc464d":"code","43e0a130":"code","d9c4f756":"code","cf1c4e10":"code","5b27a44d":"code","b1900ac3":"code","c136c414":"code","91510cb2":"code","c0682111":"code","ae445b86":"code","9390844b":"code","b3a883d8":"code","1cfecb36":"code","fc05b9ce":"code","af3c1725":"code","a4d1e121":"code","5c3ce694":"code","ad21b827":"code","135f639d":"code","3ab93779":"code","3db06e0a":"code","dbe4fa38":"code","367fcdc3":"code","4da4fdc6":"code","d60cd727":"code","0ddbefbe":"code","182aafa6":"code","fb3536b9":"code","b9060df9":"code","d3903e52":"code","7a40e1a6":"code","7dc5b93d":"code","95b44518":"code","cb912881":"code","efa554d8":"code","175501a0":"code","54ce0ea1":"code","ad8db1de":"code","c72bc609":"code","3864509e":"code","54a9aff3":"code","d61c4883":"code","146c9044":"code","861f34f3":"code","60caf8fd":"code","8911ee48":"markdown","beea531d":"markdown","7c26148e":"markdown","24dd1e37":"markdown","0f2c1583":"markdown","7fe501c1":"markdown","10aca244":"markdown","b58ec73d":"markdown","5464bba5":"markdown","1930db5e":"markdown","e613c8b7":"markdown","db832c65":"markdown","7620696d":"markdown","572f694c":"markdown","04749fa0":"markdown","76051a04":"markdown","243b158c":"markdown","b3c93a3a":"markdown","8fc1581a":"markdown","687388d0":"markdown","e4e23ff8":"markdown","6160fce9":"markdown","bc45b768":"markdown","da9c02b5":"markdown","a7904069":"markdown","a4c644ca":"markdown","59eedf09":"markdown","304b2287":"markdown","80cebb84":"markdown","7c0989dd":"markdown","7aa228ac":"markdown","ea401ee7":"markdown","c67f5ddd":"markdown","8c7884c2":"markdown","8494f1ab":"markdown","11e1214a":"markdown","67517e1d":"markdown","bcdbcb46":"markdown","6f653abc":"markdown","6dadf6d1":"markdown","4dc2d277":"markdown","64162c73":"markdown","4582feca":"markdown","2c9d07d0":"markdown","8a4d8260":"markdown","1b95dd93":"markdown","61e9474d":"markdown","dd99d9b7":"markdown","bfc66bf9":"markdown","f94b0e89":"markdown","8b41f00d":"markdown","88a4a95c":"markdown","05b159b1":"markdown","1133b85c":"markdown","fc18bd40":"markdown","2e1acee0":"markdown","9a54b8e9":"markdown","53ec0cd4":"markdown","d638f35c":"markdown","3c833428":"markdown","1bb7cc20":"markdown","42ebd4ee":"markdown","99fbfe6c":"markdown","3a93e385":"markdown","60fa8f80":"markdown","b9fccd2b":"markdown","3b71fe22":"markdown","0d17e7b8":"markdown","8b17b664":"markdown","e5d91e27":"markdown","7511f877":"markdown","47f8197c":"markdown","38945a10":"markdown","22da7bd4":"markdown","be4dd26b":"markdown","8cf22c9a":"markdown","e252cd9c":"markdown","06dcdc87":"markdown","d15cfa56":"markdown","1c7d0c29":"markdown","18843e74":"markdown","b95073b1":"markdown","adec7af4":"markdown","9c85f505":"markdown","23abc13d":"markdown","9c75e055":"markdown","aa1c05a6":"markdown","9042548c":"markdown","71eb4ce5":"markdown","0dd0d711":"markdown","971e5b83":"markdown","0ed240e6":"markdown","5d48ae52":"markdown","06e6f3eb":"markdown","4aa4f4a6":"markdown","ab88315a":"markdown","da4dac01":"markdown","1a5ebb49":"markdown","57eed5e4":"markdown","26e6c0a2":"markdown","80256b8b":"markdown","90ba5e6f":"markdown","0c4da543":"markdown","c32ab769":"markdown","610fdd7c":"markdown","907f3184":"markdown","fa48aa49":"markdown","cefd2919":"markdown","b4560604":"markdown","8c34e025":"markdown","4970f390":"markdown","14a39cfd":"markdown","54e83ad0":"markdown","fb78c384":"markdown","6ce5775e":"markdown","dcdaf577":"markdown","e9bbd069":"markdown","01b68823":"markdown","706037da":"markdown","56ce6bcb":"markdown","38260fbe":"markdown","efdc2cbb":"markdown","e5eb7838":"markdown","210c0109":"markdown","7685643c":"markdown","29cde90d":"markdown","e18e61bb":"markdown","2e90c592":"markdown","71913463":"markdown","347ebdb5":"markdown","aa69e02f":"markdown","12e38f88":"markdown","98626c46":"markdown","683c6224":"markdown","6ba210af":"markdown","04b1bb7c":"markdown","c85aeedf":"markdown","0fa8a5b8":"markdown","53e13900":"markdown","aa6aa3e3":"markdown","59f71f5a":"markdown","705704f2":"markdown","c0c6b5d4":"markdown","258cb64a":"markdown","3c8f1639":"markdown","8d8cc364":"markdown","f7dbbb0f":"markdown","2482dd19":"markdown","828520bc":"markdown","d172eca6":"markdown","01035001":"markdown","67f4204a":"markdown","0d45f0cc":"markdown","eda0d582":"markdown","a739084c":"markdown","43ffd028":"markdown","7dc4f587":"markdown","4a0c36ea":"markdown","1d0dcd86":"markdown","4a01f46e":"markdown","0eca6a54":"markdown","b6f4ede4":"markdown","fb098967":"markdown","0ba4e109":"markdown","81ea39e8":"markdown","28935987":"markdown","694e9c5b":"markdown","59ed06b0":"markdown","464672e6":"markdown","d6230b92":"markdown","2152efa3":"markdown","bd4ba92e":"markdown","f81e4740":"markdown","3609e324":"markdown","3d0bcdaa":"markdown","6adc4ddc":"markdown","55480b28":"markdown","d57e7b00":"markdown","fd7edd09":"markdown","9f6ec217":"markdown","0d0e1d6d":"markdown","bdc45c20":"markdown","794497d3":"markdown","3bf0514b":"markdown","44c71e7d":"markdown","d96bf9d3":"markdown","fb6b1814":"markdown","f75e9cf1":"markdown","ab0856f7":"markdown","add724b8":"markdown","f3a55841":"markdown","2954c97d":"markdown","0b708b68":"markdown","69f1e15b":"markdown","370cab79":"markdown","518cf23d":"markdown","361d54f3":"markdown","85e6507a":"markdown","016e43a5":"markdown","8a2bb5a1":"markdown","36b88c6a":"markdown","c8f5f25a":"markdown","97c235b0":"markdown","c0f0ecd8":"markdown","d3783350":"markdown","6207db90":"markdown","c75d08e7":"markdown","f47d230e":"markdown","bdbe88eb":"markdown","35dba057":"markdown","ab5135d6":"markdown","54c773c8":"markdown","35b35b6d":"markdown","40864542":"markdown","55d3f141":"markdown","c734f535":"markdown","906daef8":"markdown","58931187":"markdown","2599c9f7":"markdown","2e72b4ea":"markdown","26d4093e":"markdown","7ad3eeee":"markdown","d16c10e1":"markdown","f7f34ac4":"markdown","5911dbc6":"markdown","42ad1c6d":"markdown","47bcb4f3":"markdown","4d92e233":"markdown","f03fe3dc":"markdown","2179e708":"markdown","1d8fc9ec":"markdown","8332656a":"markdown","9f574ac7":"markdown","292fd801":"markdown","ee3d32b4":"markdown","8f75b878":"markdown","acfc0b1d":"markdown","ed0450cf":"markdown","383b734e":"markdown","7d533c12":"markdown","010cf1b6":"markdown"},"source":{"b40dd01b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","73fcbc7f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.utils import shuffle\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","1357a032":"#from sklearn.model_selection import train_test_split\n#from sklearn.naive_bayes import GaussianNB #from skmultilearn.adapt import MLkNN\nimport nltk\n#nltk.download('stopwords')\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\nimport re\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, ENGLISH_STOP_WORDS \nfrom sklearn.naive_bayes import MultinomialNB, GaussianNB\nfrom sklearn import metrics\nfrom scipy.stats import pearsonr\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression, Ridge, LinearRegression, \\\nLasso, RidgeClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport optuna\nimport xgboost as xgb\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils.np_utils import to_categorical \nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout, Masking, Embedding, SimpleRNN\nfrom sklearn.svm import LinearSVC, SVC, NuSVC\nfrom keras.layers.experimental.preprocessing import TextVectorization \nimport spacy\nfrom keras import regularizers\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom keras.losses import BinaryCrossentropy","41e16b30":"#from sklearn.impute import SimpleImputer, KNNImputer\n#from sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler,RobustScaler\n#from sklearn.ensemble import IsolationForest\n#from sklearn.covariance import EllipticEnvelope\n#from sklearn.neighbors import LocalOutlierFactor\n#from sklearn.svm import OneClassSVM\n#from sklearn.decomposition import PCA\n#from imblearn.over_sampling import SMOTE\n#from imblearn.over_sampling import ADASYN\n#from sklearn.feature_selection import SelectFromModel\n#from imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import BorderlineSMOTE, RandomOverSampler\n#from imblearn.over_sampling import SVMSMOTE\n#from eli5 import show_weights\n#from eli5 import show_prediction\n#from sklearn.ensemble import ExtraTreesClassifier\n#import shap\n#from sklearn.preprocessing import Normalizer\n#from sklearn.preprocessing import QuantileTransformer\n#from sklearn.preprocessing import PowerTransformer\n#from eli5.sklearn import PermutationImportance\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nimport xgboost as xgb\nimport lightgbm as lgb\nimport catboost as cb\nfrom sklearn.model_selection import StratifiedKFold\nimport optuna\nfrom optuna import Trial, visualization\nfrom optuna.samplers import TPESampler\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.svm import SVC\nfrom keras.layers import Flatten\nfrom nltk import word_tokenize, pos_tag, pos_tag_sents\nfrom scipy.stats import spearmanr","0f9895b2":"df = pd.read_csv('..\/input\/iba-ml1-final-project\/train.csv')\ndftest = pd.read_csv('..\/input\/iba-ml1-final-project\/test.csv')","4ddaedeb":"#I apply special lemmatization function - \n# Source: https:\/\/stackoverflow.com\/questions\/59787625\/lemmatizing-in-a-list-comprehension-if-word-is-less-than-x\ndef getWordNetPOS (POStag):\n    def is_noun(POStag):\n        return POStag in ['NN', 'NNS', 'NNP', 'NNPS']\n    def is_verb(POStag):\n        return POStag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n    def is_adverb(POStag):\n        return POStag in ['RB', 'RBR', 'RBS']\n    def is_adjective(POStag):\n        return POStag in ['JJ', 'JJR', 'JJS']\n\n    if is_noun(POStag):\n        return wordnet.NOUN\n    elif is_verb(POStag):\n        return wordnet.VERB\n    elif is_adverb(POStag):\n        return wordnet.ADV\n    elif is_adjective(POStag):\n        return wordnet.ADJ\n    else:\n        # if not noun, verb, adverb or adjective, return noun\n        return wordnet.NOUN","c13dfd8f":"def lemmas (wordtokens):\n    lemmatizer = WordNetLemmatizer()\n    POStag = pos_tag(wordtokens)\n    wordtokens = [lemmatizer.lemmatize(token[0], getWordNetPOS(token[1]))\n                  for token in POStag]\n\n    return wordtokens","ae82d564":"df.head()","aeaacb7e":"df.info()","00344a3c":"# I decide to replace Null values in \"Review\" column with \"Not Filled\" expression\ndf['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)","cd82976e":"#Using Stemming and Removing English stopwords from Review column\n# At first, I do not handle 'not' word - this stemming will be used in subm.1, 2 and 3\nstemmer = PorterStemmer()\nwords = stopwords.words(\"english\")\ndf['Review_st1'] = df['Review_filled'].apply(lambda x: \" \".\\\n                                                join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                                      split() if i not in words]).lower())","dc93e7fd":"# I also apply same techniques to 'Review_title' column - I will use it on later submissions\n#Replacing review_title null values and applying preprocessing to review_title\ndf['Review_Title'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nstemmer = PorterStemmer()\nstop_words = set(stopwords.words('english')) - set(['not'])\ndf['Rev_titl_pr'] = df['Review_Title'].apply(lambda x: \" \".\\\n                                       join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())","0f6e8d11":"# I start with predicting Recommendation\n#Creating training and test set for predicting Recommendation\ny2 = df['Recommended']\nX = df['Review_st1']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=100)\nprint(df.shape); print(X2_train.shape); print(X2_test.shape)","c776c5bd":"#I apply methodology described here: https:\/\/www.pluralsight.com\/guides\/nlp-machine-learning-text-data\/Converting Recommendation\n\nvectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n\ntrain_tfIdfrec = vectorizer_tfidf.fit_transform(X2_train.values.astype('U'))\n\ntest_tfIdfrec = vectorizer_tfidf.transform(X2_test.values.astype('U'))","f415dfdd":"print(train_tfIdfrec.shape); print(test_tfIdfrec.shape)","8687e036":"#I chose the model shown in Pluralsight text - link shown above\nnb_classifier = MultinomialNB()\n\nnb_classifier.fit(train_tfIdfrec, y2_train)\n\npred2 = nb_classifier.predict(test_tfIdfrec) \nprint(pred2[:10])","dc818300":"accuracy_tfidf = accuracy_score(y2_test, pred2)\nprint(accuracy_tfidf)\n\nConf_metrics_tfidf = confusion_matrix(y2_test, pred2)\nprint(Conf_metrics_tfidf)","59905c2f":"#Transforming test  set prior to creating recommendation column. \n#Applying technics similar to train set\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)","c35f4825":"# Will be used in submission 1\ndftest['Review_st1'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                              join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                                    split() if i not in words]).lower())","320f77dd":"main_test_tfIdf = vectorizer_tfidf.transform(dftest['Review_st1'].values.astype('U'))","8587ede7":"#Creating Recommended column for test set\ndftest['Recommended'] = nb_classifier.predict(main_test_tfIdf) ","137facdf":"y1 = df['Rating']\nX = df['Review_st1']\n\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, random_state=100)\n\nprint(df.shape); print(X1_train.shape); print(X1_test.shape)","0f3f8991":"train_tfIdfrat = vectorizer_tfidf.fit_transform(X1_train.values.astype('U'))\n\ntest_tfIdfrat = vectorizer_tfidf.transform(X1_test.values.astype('U'))","91d10b4a":"train_tfIdfrat2 = vectorizer_tfidf.fit_transform(X1_train.values)\n\ntest_tfIdfrat2 = vectorizer_tfidf.transform(X1_test.values)","2d52e80e":"# I compare several classifiers - start with GaussianNB\nmulticlass = GaussianNB()\n\nmulticlass.fit(train_tfIdfrat2.toarray(), y1_train)\n\npred1 = multiclass.predict(test_tfIdfrat2.toarray())","7e61c96e":"accuracy_tfidfrat = accuracy_score(y1_test, pred1)\nprint(accuracy_tfidfrat)","a1f83045":"ratingcl = MultinomialNB()\n\nratingcl.fit(train_tfIdfrat.toarray(), y1_train)\n\npred1 = multiclass.predict(test_tfIdfrat.toarray())\n\naccuracy_tfidfrat = metrics.accuracy_score(y1_test, pred1)\nprint(accuracy_tfidfrat)","ec95a8a5":"#I try SGD classifier - and tweak parameters\nsgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgd.fit(train_tfIdfrat.toarray(), y1_train)","38425156":"pred1 = sgd.predict(test_tfIdfrat.toarray())\n\naccuracy_tfidfrat = metrics.accuracy_score(y1_test, pred1)\nprint(accuracy_tfidfrat)","f25bcb33":"dftest['Rating'] = sgd.predict(main_test_tfIdf) ","d1f2883c":"coef_rat, p = spearmanr(y1_test, pred1)\ncoef_rec, p = spearmanr(y2_test, pred2)\n(coef_rat + coef_rec)\/2","7e1a3d9a":"submission1 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission1.to_csv('submissionanar1.csv',index=False)","06d19d57":"y2 = df['Recommended']\nX = df['Review_st1']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=100)\nsgd2rec = Pipeline([('vect', CountVectorizer()),\n                ('tfidf', TfidfTransformer()),\n                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n               ])\nsgd2rec.fit(X2_train, y2_train)","dc307035":"y_pred2 = sgd2rec.predict(X2_test)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","3c18eb35":"y1 = df['Rating']\nX = df['Review_st1']\n\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, random_state=100)","b267637f":"sgd2rat = Pipeline([('vect', CountVectorizer()),\n                ('tfidf', TfidfTransformer()),\n                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n               ])\nsgd2rat.fit(X1_train, y1_train)","3ca2cfe8":"y_pred1 = sgd2rat.predict(X1_test)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","34c4ff4a":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","2c528a5f":"dftest['Recommended'] = sgd2rec.predict(dftest['Review_st1']) \ndftest['Rating'] = sgd2rat.predict(dftest['Review_st1']) ","8817c3b2":"submission2 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission2.to_csv('submissionanar2.csv',index=False)","f9b5013c":"# I stat applying bag of words with CountVectorizer\ny2 = df['Recommended']\nX = df['Review_st1']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=100)\nvectorizer = CountVectorizer()\nX2_train_bow = vectorizer.fit_transform(X2_train)\nX2_test_bow = vectorizer.transform(X2_test)","c95d0897":"sgdbagrec = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdbagrec.fit(X2_train_bow, y2_train)","927e1a7a":"y_pred2 = sgdbagrec.predict(X2_test_bow)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","33baa84a":"y1 = df['Rating']\nX = df['Review_st1']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, random_state=100)","bf93239e":"X1_train_bow = vectorizer.fit_transform(X1_train)\nX1_test_bow = vectorizer.transform(X1_test)","f018ee02":"sgdbagrat = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdbagrat.fit(X1_train_bow, y1_train)","06998b4a":"y_pred1 = sgdbagrat.predict(X1_test_bow)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","9a8211a0":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","3e53fcaf":"dftest_bag= vectorizer.transform(dftest['Review_st1'])\ndftest['Recommended'] = sgdbagrec.predict(dftest_bag) \ndftest['Rating'] = sgdbagrat.predict(dftest_bag) ","7f05cb2f":"submission3 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission3.to_csv('submissionanar3.csv',index=False)","b7651ebb":"#I decide to apply n-grams to see how it affects the result\ny2 = df['Recommended']\nX = df['Review_st1']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=100)\nvectorizer_ng = CountVectorizer(ngram_range = (1,2))\nX2_train_ng = vectorizer_ng.fit_transform(X2_train)\nX2_test_ng = vectorizer_ng.transform(X2_test)","f56e8a24":"sgdngrec = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdngrec.fit(X2_train_ng, y2_train)","6f7a869e":"y_pred2 = sgdngrec.predict(X2_test_ng)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","117df77f":"X1_train_ng = vectorizer_ng.fit_transform(X1_train)\nX1_test_ng = vectorizer_ng.transform(X1_test)","81b56ec3":"sgdngrat = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdngrat.fit(X1_train_ng, y1_train)","d5698016":"y_pred1 = sgdngrat.predict(X1_test_ng)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","95799812":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","029f1dec":"#Here I omit not word from English stopwords - I use it later starting from submission 4\nstemmer = PorterStemmer()\nstop_words = set(stopwords.words('english')) - set(['not'])\ndf['Review_st2'] = df['Review_filled'].apply(lambda x: \" \".\\\n                                             join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x)\\\n                                                   .split() if i not in stop_words]).lower())","8095222b":"y2 = df['Recommended']\nX = df['Review_st2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=100)","c006fc32":"vectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)","5828f6f0":"sgdngrect = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdngrect.fit(X2_train_ngt, y2_train)","67ba35c0":"y_pred2 = sgdngrect.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","4728b411":"y1 = df['Rating']\nX = df['Review_st2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, random_state=100)","f845038d":"X1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)","19747650":"sgdngratnt = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdngratnt.fit(X1_train_ngt, y1_train)","323d046a":"y_pred1 = sgdngratnt.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","39fb0d30":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","d96c9740":"# I decide to try N-gram 3\nvectorizer_ng3t = CountVectorizer(ngram_range = (1,3))\nX2_train_ng3t = vectorizer_ng3t.fit_transform(X2_train)\nX2_test_ng3t = vectorizer_ng3t.transform(X2_test)","7d2f0030":"sgdngrec3t = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdngrec3t.fit(X2_train_ng3t, y2_train)","042225e0":"y_pred2 = sgdngrec3t.predict(X2_test_ng3t)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","6e3e38b3":"X1_train_ng3t = vectorizer_ng3t.fit_transform(X1_train)\nX1_test_ng3t = vectorizer_ng3t.transform(X1_test)","84151611":"sgdngrat3nt = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdngrat3nt.fit(X1_train_ng3t, y1_train)","19385ab9":"y_pred1 = sgdngrat3nt.predict(X1_test_ng3t)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","d05c088b":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","e22c3ab0":"dftest['Review_st2'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                              join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                                    split() if i not in stop_words]).lower())","8ade9787":"dftest_ng2= vectorizer_ngt.transform(dftest['Review_st2'])\ndftest['Recommended'] = sgdngrect.predict(dftest_ng2) \ndftest['Rating'] = sgdngratnt.predict(dftest_ng2) ","984152fa":"submission4 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission4.to_csv('submissionanar4.csv',index=False)","0a9df858":"# I apply Linear SVC to see the impact\ny1 = df['Rating']\nX = df['Review_st2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, random_state=100)","1146bfd8":"vectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)","a43bcb1a":"svm_ngtrat = LinearSVC(tol=1.0e-6,max_iter=5000,verbose=1)\nsvm_ngtrat.fit(X1_train_ngt, y1_train)","b95fb8e6":"y_pred1 = svm_ngtrat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","0bf01641":"y2 = df['Recommended']\nX = df['Review_st2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=100)","54c851e1":"X2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)","d171c347":"svm_ngtrec = LinearSVC(tol=1.0e-6,max_iter=5000,verbose=1)\nsvm_ngtrec.fit(X2_train_ngt, y2_train)","76851488":"y_pred2 = svm_ngtrec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","9b8205f6":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","e42a4386":"# I apply simple Keras ANN\ny1 = df['Rating']\nX = df['Review_st2']","d39a28a4":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(X)\nsequences = tokenizer.texts_to_sequences(X)","17120ed7":"max_seq_length = np.max(list(map(lambda x: len(x), sequences)))\n\nprint(\"Max sequence length:\", max_seq_length)","99cc706a":"X_pad = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\nX_pad = X_pad.astype(np.float32)","f3ec8a6d":"## Turning classes to one hot\n# First I deduct one from all column\n## To_categorical function creates one hot coding comprising of 6 columns, that is why I subtract 1\ny1_m1 = y1-1\ny1_onehot = to_categorical(y1_m1)","0dbd0617":"X1_train, X1_test, y1_train, y1_test = train_test_split(X_pad, y1_onehot, random_state=100)\n\nprint(df.shape); print(X1_train.shape); print(X1_test.shape)","75d76b88":"modelker = Sequential()\nmodelker.add(Dense(128, activation = 'relu', input_shape = (1,60)))\nmodelker.add(Dense(128, activation = 'relu'))\nmodelker.add(Dense(5, activation = 'softmax'))        \n","4a006c12":"modelker.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])","c26ccc4a":"modelker.fit(X1_train, y1_train, epochs = 1000, batch_size = 128)","3708c8a1":"modelker.evaluate(X1_test, y1_test, batch_size = 128)","68eb616a":"y_predcl = modelker.predict(X1_test)","b38988cd":"modelker.evaluate(y_predcl, y1_test, batch_size = 128)","05dd3c63":"y_pred1 = modelker.predict_classes(X1_test)\ny_pred1","ab5ed12d":"y2 = df['Recommended']\n#X = df['Review_st2']","4e690530":"#Converting back to int32 after converting to float\nX_pad = X_pad.astype(np.int32)","74565d74":"X2_train, X2_test, y2_train, y2_test = train_test_split(X_pad, y2, random_state=100)\n\nprint(df.shape); print(X2_train.shape); print(X2_test.shape)","e4233cdc":"modelker2 = Sequential()\nmodelker2.add(Dense(128, activation = 'relu', input_shape = (1,60)))\nmodelker2.add(Dense(128, activation = 'relu'))\nmodelker2.add(Dense(128, activation = 'relu'))\nmodelker2.add(Dense(1, activation = 'softmax'))   ","53444858":"modelker2.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])","4336a936":"modelker2.fit(X2_train, y2_train, epochs = 1000, batch_size = 128)","97e64d11":"pred = modelker2.predict(X2_test)\npred","1ff9543f":"(pred ==1).sum()","bf59268b":"X_df_test = dftest['Review_st2']\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_df_test)\n\nsequences = tokenizer.texts_to_sequences(X_df_test)\nX_pad_test = pad_sequences(sequences, maxlen=60, padding='post')\nX_pad_test = X_pad_test.astype(np.float32)\ndftest['Rating'] = modelker.predict_classes(X_pad_test)","a7c54e74":"dftest['Rating'] = dftest['Rating'] + 1","dd7314d7":"dftest['Rating']","170cff2c":"#Adding Recommendation from SGD\ny2 = df['Recommended']\nX = df['Review_st2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)\nsgdngrect = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdngrect.fit(X2_train_ngt, y2_train)","a87b2b8e":"y_pred2 = sgdngrect.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","0b794aa9":"dftest_ng2= vectorizer_ngt.transform(dftest['Review_st2'])\ndftest['Recommended'] = sgdngrect.predict(dftest_ng2) ","e0d1ece9":"submission5 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission5.to_csv('submissionanar5.csv',index=False)","5ffac8b4":"y2 = df['Recommended']\nX = df['Review_st2']","521bfc10":"X_val = X.values\ny2_val = y2.values\nX2_train, X2_test, y2_train, y2_test = train_test_split(X_val, y2_val)","c5526cfc":"# Encode text as list of indices (of vocabulary terms)\n# Still under \"experimental\" although already quite standard\nVOCAB_SIZE = 5000\nencoder = TextVectorization(max_tokens=VOCAB_SIZE)\nencoder.adapt(X2_train)","7123f62a":"#Starting with simple model\nmodel = Sequential([\n    encoder,\n    Embedding(\n        input_dim=len(encoder.get_vocabulary()),  # VOCAB_SIZE + 1 (1 for padding token)\n        output_dim=32,\n        mask_zero=True\n    ),\n    LSTM(16),\n    Dense(8, activation='relu'),\n    Dense(1, activation='sigmoid')\n])","a65cad20":"model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])","fd6fb203":"history = model.fit(X2_train, y2_train, epochs=20, validation_data=(X2_test, y2_test))","d1399050":"y1 = df['Rating']\nX = df['Review_st2']\ny1_m1 = y1-1\ny1_onehot = to_categorical(y1_m1)\nX_val = X.values\ny1_val = y1_onehot.astype(int)\nX1_train, X1_test, y1_train, y1_test = train_test_split(X_val, y1_val)","98eb4b1b":"VOCAB_SIZE = 5000\nencodercl = TextVectorization(max_tokens=VOCAB_SIZE)\nencodercl.adapt(X1_train)","7e67ec8e":"modelrat = Sequential([\n    encoder,\n    Embedding(\n        input_dim=len(encodercl.get_vocabulary()),  # VOCAB_SIZE + 1 (1 for padding token)\n        output_dim=32,\n        mask_zero=True\n    ),\n    LSTM(32),\n    Dense(64, activation='relu'),\n    Dense(64, activation='relu'),\n    Dense(5, activation='softmax')\n])","de4767ed":"modelrat.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])","7c0b1f41":"historyrat = modelrat.fit(X1_train, y1_train, epochs=50, validation_data=(X1_test, y1_test))","68a10d68":"VOCAB_SIZE = 5000\nencoderng = TextVectorization(max_tokens=VOCAB_SIZE, ngrams=(1,2))\nencoderng.adapt(X1_train)","f35d6ccd":"model_rat_ng = Sequential([\n    encoderng,\n    Embedding(\n        input_dim=len(encoderng.get_vocabulary()),  # VOCAB_SIZE + 1 (1 for padding token)\n        output_dim=32,\n        mask_zero=True\n    ),\n    LSTM(16),\n    Dense(32, activation='relu'),\n    Dense(5, activation='softmax')\n])","49ae5404":"model_rat_ng.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])","25499b5a":"history_rat_ng = model_rat_ng.fit(X1_train, y1_train, epochs=20, validation_data=(X1_test, y1_test))","e8d32e0c":"# Preparing prerdiction file and submission. Since RNN gives a result as an array of probabilities, \n#I use prerdict_class metod\ndftest['Recommended'] = model.predict_classes(dftest['Review_st2'])","6176b28c":"#Here I use plus1, to convert results from 0-4 to 1-5\ndftest['Rating'] = model_rat_ng.predict_classes(dftest['Review_st2']) +1","1474c7f7":"submission6 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission6.to_csv('submissionanar6.csv',index=False)","61c5f3e5":"#I decide to combine Review_Title and Review column into one column\n#Replacing review_title null values and applying preprocessing to review_title\ndf['Review_Title'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nstemmer = PorterStemmer()\nstop_words = set(stopwords.words('english')) - set(['not'])\ndf['Rev_titl_pr'] = df['Review_Title'].apply(lambda x: \" \".\\\n                                       join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())","9929e800":"#I combine columns into one column\ny1 = df['Rating']\nX = df['Rev_titl_pr'] + df['Review_st2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, random_state=100)\nvectorizer_ngdbl = CountVectorizer(ngram_range = (1,2))\nX1_train_ngdbl = vectorizer_ngdbl.fit_transform(X1_train)\nX1_test_ngdbl = vectorizer_ngdbl.transform(X1_test)\nsgd_ng_rat_dbl = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgd_ng_rat_dbl.fit(X1_train_ngdbl, y1_train)","9711d0dc":"y_pred1 = sgd_ng_rat_dbl.predict(X1_test_ngdbl)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","32db96da":"y2 = df['Recommended']\nX = df['Rev_titl_pr'] + df['Review_st2']\n#X = df['Review_st2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=100)\nvectorizer_ngdbl = CountVectorizer(ngram_range = (1,2))\nX2_train_ngdbl_rec = vectorizer_ngdbl.fit_transform(X2_train)\nX2_test_ngdbl_rec = vectorizer_ngdbl.transform(X2_test)\nsgdng_dbl_rec = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)\n               \nsgdng_dbl_rec.fit(X2_train_ngdbl_rec, y2_train)","41351312":"y_pred2 = sgdng_dbl_rec.predict(X2_test_ngdbl_rec)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","8b32d4ec":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","7bf525e3":"dftest['Review_Title'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Rev_titl_pr'] = dftest['Review_Title'].apply(lambda x: \" \".\\\n                                       join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())","32578aa2":"dftest['Combined'] = dftest['Review_st2'] + dftest['Rev_titl_pr']","f9078d46":"dftest_combined= vectorizer_ngdbl.transform(dftest['Combined'])\ndftest['Recommended'] = sgdng_dbl_rec.predict(dftest_combined) \ndftest['Rating'] = sgd_ng_rat_dbl.predict(dftest_combined) ","896f3b88":"submission7 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission7.to_csv('submissionanar7.csv',index=False)","63a1cc06":"# I apply Logistic Regression  - I find optimal parameters after several trials\ny1 = df['Rating']\nX = df['Review_st2'] # I return again to one column model\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)\nlr_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred1, y1_test))","d644c96c":"y2 = df['Recommended']\nX = df['Review_st2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)\nlr_rec = LogisticRegression(C=0.25, solver = 'sag')               \nlr_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","a853b0a1":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","66bf8e36":"dftest_nglg= vectorizer_ngt.transform(dftest['Review_st2'])\ndftest['Recommended'] = lr_rec.predict(dftest_nglg) \ndftest['Rating'] = lr_rat.predict(dftest_nglg) ","2bcbd82e":"submission8 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission8.to_csv('submissionanar8.csv',index=False)","20ad1e6a":"# After several trials, I continue with test size = 0.1\ny1 = df['Rating']\nX = df['Review_st2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)\nlr_rat_01 = LogisticRegression(C=0.25, solver = 'sag')               \nlr_rat_01.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_rat_01.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","382288d2":"y2 = df['Recommended']\nX = df['Review_st2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)\nlr_rec_01 = LogisticRegression(C=0.25, solver = 'sag')\n               \nlr_rec_01.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_rec_01.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","89ad25f2":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","3f715cb3":"dftest_ng_01= vectorizer_ngt.transform(dftest['Review_st2'])\ndftest['Recommended'] = lr_rec_01.predict(dftest_ng_01) \ndftest['Rating'] = lr_rat_01.predict(dftest_ng_01) ","390c1876":"submission9 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission9.to_csv('submissionanar9.csv',index=False)","776f9c7a":"# I decide to apply Bagging Classifier to see the impact on score\ny1 = df['Rating']\nX = df['Review_st2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)\nlr_rat_bag_01 = BaggingClassifier(LogisticRegression(C=0.25, solver = 'sag'))             \nlr_rat_bag_01.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_rat_bag_01.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred1, y1_test))","601836d9":"y2 = df['Recommended']\nX = df['Review_st2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)\nlr_rec_bag_01 = BaggingClassifier(LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_rec_bag_01.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_rec_bag_01.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","e719880e":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","ddc0280c":"dftest_ng_bag_01= vectorizer_ngt.transform(dftest['Review_st2'])\ndftest['Recommended'] = lr_rec_bag_01.predict(dftest_ng_bag_01) \ndftest['Rating'] = lr_rat_bag_01.predict(dftest_ng_bag_01) ","17adf150":"submission10 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission10.to_csv('submissionanar10.csv',index=False)","bc0f5d4e":"# I start applying lemmatization to see the difference\nlem = WordNetLemmatizer()\nstop_words = set(stopwords.words('english')) - set(['not'])\ndf['Review_lem'] = df['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())","5ee70876":"y1 = df['Rating']\nX = df['Review_lem']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)\nlr_rat_lem_01 = LogisticRegression(C=0.25, solver = 'sag')             \nlr_rat_lem_01.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_rat_lem_01.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","766216a8":"y2 = df['Recommended']\nX = df['Review_lem']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)\nlr_rec_lem_01 = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_rec_lem_01.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_rec_lem_01.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","65af092d":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","11508c77":"dftest['Review_lem'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())","1410713f":"dftest_ng_lem_01= vectorizer_ngt.transform(dftest['Review_lem'])\ndftest['Recommended'] = lr_rec_lem_01.predict(dftest_ng_lem_01) \ndftest['Rating'] = lr_rat_lem_01.predict(dftest_ng_lem_01) ","f71b9904":"submission11 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission11.to_csv('submissionanar11.csv',index=False)","797f03a1":"## I decide to find frequent words used in Review_lem column and remove some of them.\n## I perform the process manually, checking the result each time\nmost_freq = pd.Series(' '.join(df['Review_lem']).split()).value_counts()[0:200]\nmost_freq\n#list(most_freq.index)\n","54f5b61e":"#Removal of top words\n#freq = list(freq.index)\nfreq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndf['Review_cl'] = df['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","7f38d367":"y1 = df['Rating']\nX = df['Review_cl']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)\nlr_rat_lemcl_01 = LogisticRegression(C=0.25, solver = 'sag')             \nlr_rat_lemcl_01.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_rat_lemcl_01.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred1, y1_test))","ae4b1ecb":"y2 = df['Recommended']\nX = df['Review_cl']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)\nlr_rec_lemcl_01 = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_rec_lemcl_01.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_rec_lemcl_01.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","2d1a894d":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","9af1d99f":"freq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndftest['Review_cl'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ndftest_ng_lemcl_01= vectorizer_ngt.transform(dftest['Review_cl'])\ndftest['Recommended'] = lr_rec_lemcl_01.predict(dftest_ng_lemcl_01) \ndftest['Rating'] = lr_rat_lemcl_01.predict(dftest_ng_lemcl_01) ","136efe4e":"submission12 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission12.to_csv('submissionanar12.csv',index=False)","d64329eb":"rare = pd.Series(' '.join(df['Review_cl']).split()).value_counts()[-80:-1]\nrare","fc38d673":"#Removal of top words\n#freq = list(freq.index)\n#last cecked from (-60:-40) -rerrmaining later\nrare_list = ['ican', 'lithuanian','quintessential', 'glistening', 'wwear', 'seemd', 'chamois',\\\n            'succumb', 'traditionally', 'asflattering', 'earnings', 'inviting', 'sofla',\\\n            'teaser', 'rremiss', 'kneelength', 'commonly', 'autobots', 'fu', 'georgia',\\\n            'cheerleading', 'wireless', 'someway','fifty']\ndf['Review_cl2'] = df['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare_list))","21b3819f":"y1 = df['Rating']\nX = df['Review_cl2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)\nlr_rat_lemcl_02 = LogisticRegression(C=0.25, solver = 'sag')             \nlr_rat_lemcl_02.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_rat_lemcl_02.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred1, y1_test))","c56c22f3":"y2 = df['Recommended']\nX = df['Review_cl2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)\nlr_rec_lemcl_02 = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_rec_lemcl_02.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_rec_lemcl_02.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","455cd8a7":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","556e9af3":"rare_list = ['ican', 'lithuanian','quintessential', 'glistening', 'wwear', 'seemd', 'chamois',\\\n            'succumb', 'traditionally', 'asflattering', 'earnings', 'inviting', 'sofla',\\\n            'teaser', 'rremiss', 'kneelength', 'commonly', 'autobots', 'fu', 'georgia',\\\n            'cheerleading', 'wireless', 'someway','fifty']\ndftest['Review_cl2'] = dftest['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare_list))\ndftest_ng_lemcl_02= vectorizer_ngt.transform(dftest['Review_cl2'])\ndftest['Recommended'] = lr_rec_lemcl_02.predict(dftest_ng_lemcl_02) \ndftest['Rating'] = lr_rat_lemcl_02.predict(dftest_ng_lemcl_02) ","85abc498":"submission13 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission13.to_csv('submissionanar13.csv',index=False)","cc734345":"# I decide to try combining 'Review_title_filled' column without applying lemmatization\ndf['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)","e4a1b11c":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","6836068d":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","b869c157":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","7c84045b":"## Preparing ssubmission file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())\nfreq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndftest['Review_cl'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","36ec84f1":"dftest_combined = dftest['Review_title_filled']+dftest['Review_cl']\ndftest_combined_vec= vectorizer_ngt.transform(dftest_combined)\ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec) \ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec) ","5d0062bb":"submission14 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission14.to_csv('submissionanar14.csv',index=False)","8e63c1f9":"# I apply words one by one to see the impact on score\nmost_freq = pd.Series(' '.join(df['Review_lem']).split()).value_counts()[200:300]\nmost_freq","764be84b":"freq_list = ['purchase', 'almost', 'year', 'pocket', 'sizing', 'extra', 'line', 'leg', 'said',\\\n            'skinny', 'boot', 'full', 'part', 'p', 'neckline', 'take']\ndf['Review_cl_exp'] = df['Review_cl'].apply(lambda x: \" \".join(x for x in x.split()\\\n                                                               if x not in freq_list))","d6ad54d1":"y1 = df['Rating']\nX = df['Review_cl_exp'] + df['Review_title_filled']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat_exp = LogisticRegression(C=0.25, solver = 'sag')             \nlr_comb_rat_exp.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat_exp.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","8e09bc4c":"y2 = df['Recommended']\nX = df['Review_title_filled'] + df['Review_cl_exp'] \nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec_exp = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec_exp.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec_exp.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","82d0ed64":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","3a199583":"## Preparing submission file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())\nfreq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndftest['Review_cl'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['purchase', 'almost', 'year', 'pocket', 'sizing', 'extra', 'line', 'leg', 'said',\\\n            'skinny', 'boot', 'full', 'part', 'p', 'neckline', 'take']\ndftest['Review_cl_exp'] = dftest['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","f2a5891b":"dftest_combined1 = dftest['Review_cl_exp'] + dftest['Review_title_filled']\ndftest_combined2 = dftest['Review_title_filled']+dftest['Review_cl_exp']\ndftest_combined_vec1= vectorizer_ngt1.transform(dftest_combined1)\ndftest_combined_vec2= vectorizer_ngt2.transform(dftest_combined2)\ndftest['Rating'] = lr_comb_rat_exp.predict(dftest_combined_vec1) \ndftest['Recommended'] = lr_comb_rec_exp.predict(dftest_combined_vec2) ","50a5df2c":"submission15 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission15.to_csv('submissionanar15.csv',index=False)","f63e2536":"freq_list = ['purchase', 'almost', 'year', 'pocket', 'sizing', 'extra', 'line', 'leg', 'said',\\\n            'skinny', 'boot', 'full', 'part', 'p', 'neckline', 'take']\ndf['Review_cl_exp'] = df['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","7aa8c826":"y1 = df['Rating']\nX = df['Review_cl_exp'] + df['Review_title_filled']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat_exp = LogisticRegression(C=0.25, solver = 'sag')             \nlr_comb_rat_exp.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat_exp.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","15bcabbd":"# Here I use Review_cl column as combination\ny2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","3b0d0101":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","3eb0cbdf":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())\nfreq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndftest['Review_cl'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['purchase', 'almost', 'year', 'pocket', 'sizing', 'extra', 'line', 'leg', 'said',\\\n            'skinny', 'boot', 'full', 'part', 'p', 'neckline', 'take']\ndftest['Review_cl_exp'] = dftest['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","ee6ce3e8":"dftest_combined1 = dftest['Review_cl_exp'] + dftest['Review_title_filled']\ndftest_combined2 = dftest['Review_title_filled']+dftest['Review_cl']\ndftest_combined_vec1= vectorizer_ngt1.transform(dftest_combined1)\ndftest_combined_vec2= vectorizer_ngt2.transform(dftest_combined2)\ndftest['Rating'] = lr_comb_rat_exp.predict(dftest_combined_vec1) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec2) ","066a9948":"submission16 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission16.to_csv('submissionanar16.csv',index=False)","3dbb6303":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\nstop_words = set(stopwords.words('english')) - set(['not'])\ndf['Review_lem'] = df['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())\nfreq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndf['Review_cl'] = df['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","50fbcd5b":"df['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)","fade2829":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","90b0fb3c":"most_freq = pd.Series(' '.join(df['Review_lem']).split()).value_counts()[281:300]\nmost_freq","086f6b3a":"freq_list = ['purchase', 'show', 'year', 'sizing', 'actually', 'extra', 'sheer', 'something', 'leg',\\\n            'low', 'flowy','every', 'wash', 'put', 'skinny', 'boot', 'tt', 'p', 'simple', 'thick',\\\n            'heavy', 'fitting', 'snug', 'winter', 'room', 'flat']\ndf['Review_cl_exp'] = df['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","11827452":"y1 = df['Rating']\nX = df['Review_title_filled'] + df['Review_cl_exp']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat_exp = LogisticRegression(C=0.25, solver = 'sag')             \nlr_comb_rat_exp.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat_exp.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred1, y1_test))","e2e5c5ed":"#Separate list for Recommended part\nmost_freq2 = pd.Series(' '.join(df['Review_lem']).split()).value_counts()[281:300]\nmost_freq2","c5a358e4":"#This time I remove diffeent words for Recommendation column\nfreq_list2 = ['sizing', 'warm', 'actually', 'extra', 'leg', 'worth', 'every', 'full', 'navy', 'these',\\\n             'p', 'spring']\ndf['Review_cl_exp_rec'] = df['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","6ced7a4e":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_exp_rec']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","6da4d946":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","93694660":"#Preparing submission file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())\nfreq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndftest['Review_cl'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list_exp = ['purchase', 'show', 'year', 'sizing', 'actually', 'extra', 'sheer', 'something', 'leg',\\\n            'low', 'flowy','every', 'wash', 'put', 'skinny', 'boot', 'tt', 'p', 'simple', 'thick',\\\n            'heavy', 'fitting', 'snug', 'winter', 'room', 'flat']\ndftest['Review_cl_exp'] = dftest['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list_exp))\nfreq_list_exp_rec = ['sizing', 'warm', 'actually', 'extra', 'leg', 'worth', 'every', 'full', 'navy', 'these',\\\n             'p', 'spring']\ndftest['Review_cl_exp_rec'] = dftest['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list_exp_rec))","c690454d":"dftest_combined1 = dftest['Review_title_filled'] + dftest['Review_cl_exp'] \ndftest_combined2 = dftest['Review_title_filled']+ dftest['Review_cl_exp_rec']\ndftest_combined_vec1= vectorizer_ngt1.transform(dftest_combined1)\ndftest_combined_vec2= vectorizer_ngt2.transform(dftest_combined2)\ndftest['Rating'] = lr_comb_rat_exp.predict(dftest_combined_vec1) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec2) ","4613c561":"submission17 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission17.to_csv('submissionanar17.csv',index=False)","62da4a46":"freq_list = ['clothe', 'size', 'i', 'top', 'wear', 'ordered', 'soft', 'material','run', 'petite', 'x',\\\n            'waist', 'retailer', 'lb', 'summer', 'time', 'day', 'year', 'pocket', 'every', 'boot',\\\n            'skinny', 'reference', 'c', 'snug', 'layer', 'know', 'cami']\ndf['Review_cl_new'] = df['Review_lem'].apply(lambda x: \" \".join(x for x in x.split()\\\n                                                                if x not in freq_list))","f814c164":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","3deed687":"freq_list2 = ['size', 'i', 'wear', 'soft', 'material','x', 'lb', 'summer', 'time','day', 'year',\\\n             'pocket', 'every', 'boot', 'skinny', 'reference', 'c', 'snug']\ndf['Review_cl_new_rec'] = df['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","9d3be448":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","12ea307e":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","d3c19124":"## Preparing ssubmission file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())\nfreq_list = ['clothe', 'size', 'i', 'top', 'wear', 'ordered', 'soft', 'material','run', 'petite', 'x',\\\n            'waist', 'retailer', 'lb', 'summer', 'time', 'day', 'year', 'pocket', 'every', 'boot',\\\n            'skinny', 'reference', 'c', 'snug', 'layer', 'know', 'cami']\ndftest['Review_cl_new'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['size', 'i', 'wear', 'soft', 'material','x', 'lb', 'summer', 'time','day', 'year',\\\n             'pocket', 'every', 'boot', 'skinny', 'reference', 'c', 'snug']\ndftest['Review_cl_new_rec'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","3896add8":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","272084b7":"submission18 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission18.to_csv('submissionanar18.csv',index=False)","10abe973":"#I try another set of frequent words\nfreq_list = ['purchase', 'year', 'pocket', 'line', 'extra', 'every', 'put', 'boot', 'skinny',\\\n            'reference', 'take']\ndf['Review_cl_expn'] = df['Review_cl'].apply(lambda x: \" \".join(x for x in x.split()\\\n                                                                if x not in freq_list))","4b4a2f66":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_expn']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","8492cb62":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","c04c3621":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","cbc7da3f":"## Preparing ssubmission file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())\nfreq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndftest['Review_cl'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['purchase', 'year', 'pocket', 'line', 'extra', 'every', 'put', 'boot', 'skinny',\\\n            'reference', 'take']\ndftest['Review_cl_expn'] = dftest['Review_cl'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","0a40a7c8":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_expn']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl']\n\u200b\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","10403d79":"submission19 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission19.to_csv('submissionanar19.csv',index=False)","fa64d1bf":"# I start afresh checking words one by one\nfreq_list = ['clothe', 'size', 'i', 'top', 'wear', 'ordered', 'soft', 'material','run', 'petite', 'x',\\\n            'waist', 'retailer', 'lb', 'summer', 'time', 'day']\ndf['Review_cl_new'] = df['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() \\\n                                                                if x not in freq_list))","133dd00b":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","a7fa815d":"freq_list2 = ['size', 'i', 'wear', 'soft', 'material','x', 'lb', 'summer', 'time','day']\ndf['Review_cl_new_rec'] = df['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","7d999473":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","d5fbd2ae":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","7ca15639":"## Preparing submission file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())\nfreq_list = ['clothe', 'size', 'i', 'top', 'wear', 'ordered', 'soft', 'material','run', 'petite', 'x',\\\n            'waist', 'retailer', 'lb', 'summer', 'time', 'day']\ndftest['Review_cl_new'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['size', 'i', 'wear', 'soft', 'material','x', 'lb', 'summer', 'time','day']\n\u200b\ndftest['Review_cl_new_rec'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","178f0e4d":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","4d14067a":"submission20 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission20.to_csv('submissionanar20.csv',index=False)","db19f195":"#I apply special lemmatization function - \n# Source: https:\/\/stackoverflow.com\/questions\/59787625\/lemmatizing-in-a-list-comprehension-if-word-is-less-than-x\ndef getWordNetPOS (POStag):\n    def is_noun(POStag):\n        return POStag in ['NN', 'NNS', 'NNP', 'NNPS']\n    def is_verb(POStag):\n        return POStag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n    def is_adverb(POStag):\n        return POStag in ['RB', 'RBR', 'RBS']\n    def is_adjective(POStag):\n        return POStag in ['JJ', 'JJR', 'JJS']\n\n    if is_noun(POStag):\n        return wordnet.NOUN\n    elif is_verb(POStag):\n        return wordnet.VERB\n    elif is_adverb(POStag):\n        return wordnet.ADV\n    elif is_adjective(POStag):\n        return wordnet.ADJ\n    else:\n        # if not noun, verb, adverb or adjective, return noun\n        return wordnet.NOUN","da460b85":"def lemmas (wordtokens):\n    lemmatizer = WordNetLemmatizer()\n    POStag = pos_tag(wordtokens)\n    wordtokens = [lemmatizer.lemmatize(token[0], getWordNetPOS(token[1]))\n                  for token in POStag]\n\n    return wordtokens","2152b361":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())","15960568":"#I apply the same frequent list as in previous submission \nfreq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndf['Review_cl'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","b3c634e0":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","a95a916d":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","4a431fc7":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","2db6241f":"dftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())","35e2f10e":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\n\nfreq_list = ['cloth', 'i','thi', 'top', 'fit','shirt', 'jean', 'run', 'petite', 'x','skirt',\\\n            'retailer', 'sleeve', 'trouser', 'coat', 'summer','side', 'shoulder', 'shape',\\\n            'knee','stretch', 'clothees', 'different', 'bra', 'button', 'around']\ndftest['Review_cl'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","0ea85b98":"dftest_combined = dftest['Review_title_filled']+dftest['Review_cl']\ndftest_combined_vec= vectorizer_ngt.transform(dftest_combined)\ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec) \ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec) ","2f7296a4":"submission21 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission21.to_csv('submissionanar21.csv',index=False)","aa822e3c":"# I start removing frequent list again from scratch\nmost_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[0:20]\nmost_freq","4c751c20":"freq_list = ['the', 'i', 'a', 'it']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","f1e2aab5":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","0c724ef5":"freq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","df6be6d9":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","1a131e72":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","adbe2e46":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","5f3a7630":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","f9c883cf":"submission22 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission22.to_csv('submissionanar22.csv',index=False)","c7f1f386":"#Strategy is the same as in earlie submissions  - I expand frequent list\nmost_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[80:100]\nmost_freq","7dbc8d58":"freq_list = ['the', 'i', 'a', 'it', \"i'm\", 'would', 'one', '-', 'material', 'from', 'usually', 'me.']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","70276118":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","39ecdc71":"freq_list2 = ['the', 'a', 'in', \"i'm\", 'you', '-', 'from', 'usually']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","979b926d":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","868a032e":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","478a98bc":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it', \"i'm\", 'would', 'one', '-', 'material', 'from', 'usually', 'me.']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in', \"i'm\", 'you', '-', 'from', 'usually']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","c4a4b216":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","b8e6fdeb":"submission23 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission23.to_csv('submissionanar23.csv',index=False)","11cd02c9":"# Continuation of same tactic - expanding frequent list\nmost_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[140:160]\nmost_freq","f2031c7a":"freq_list = ['the', 'i', 'a', 'it', \"i'm\", 'would', 'one', '-', 'material', 'from', 'usually', 'me.', \"don't\",\\\n            \"short\", 'been', 'some']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","fb4f2016":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","fbdaf26d":"freq_list2 = ['the', 'a', 'in', \"i'm\", 'you', '-', 'from', 'usually', 'some']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","dd63b9d8":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","e6cae40d":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","3c043405":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it', \"i'm\", 'would', 'one', '-', 'material', 'from', 'usually', 'me.', \"don't\",\\\n            \"short\", 'been', 'some']\n\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in', \"i'm\", 'you', '-', 'from', 'usually', 'some']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","e8cb9bc2":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","099de917":"submission24 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission24.to_csv('submissionanar24.csv',index=False)","fe8791ed":"most_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[20:40]\nmost_freq","35c9b270":"freq_list = ['the', 'i', 'a', 'it', \"i'm\"]\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","4cf880ea":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","49788af7":"freq_list2 = ['the', 'a', 'in', \"i'm\"]\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","771d04c8":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","79578d46":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","63622b75":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it', \"i'm\"]\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in', \"i'm\"]\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","2d2f5dc8":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","2750cd55":"submission25 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission25.to_csv('submissionanar25.csv',index=False)","8ba8786e":"# I return again to simple lemmatization and applying same frequent list strategy\ndf['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\nstop_words = set(stopwords.words('english')) - set(['not'])\ndf['Review_lem3'] = df['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())","c37ed02b":"most_freq = pd.Series(' '.join(df['Review_lem3']).split()).value_counts()[0:20]\nmost_freq","f9c2bc2b":"freq_list = ['the','i','it', 'a', 'and', 'is']\ndf['Review_cl_3'] = df['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","718661a7":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_3']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","ce8bd49a":"freq_list2 = ['the','it']\ndf['Review_cl_rec3'] = df['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","1c2fbeb6":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_rec3']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","e0450633":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","163a269c":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem3'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\nfreq_list = ['the','i','it', 'a', 'and', 'is']\ndftest['Review_cl_3'] = dftest['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'it']\ndftest['Review_cl_rec3'] = dftest['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","aaadf7bb":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_3']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_rec3']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","bf14456f":"submission26 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission26.to_csv('submissionanar26.csv',index=False)","920ea619":"# Continuation of the same strategy - playing with words\nmost_freq = pd.Series(' '.join(df['Review_lem3']).split()).value_counts()[120:140]\nmost_freq","800ba727":"freq_list = ['the','i','it', 'a', 'and', 'is', 'in', 'of', 'that', 's', 't', 'be', 'me', 'm', 'you',\\\n            'just', 'these', 'them', 'ha','x', 'coat', 'design', 'summer']\ndf['Review_cl_3'] = df['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","6d46d1ab":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_3']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","27774dac":"freq_list2 = ['the','it','in', 'that', 's', 't', 'ha', 'x', 'design', 'summer']\ndf['Review_cl_rec3'] = df['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","c5d2e15e":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_rec3']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","c8fa975d":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","6a4e84cf":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem3'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\nfreq_list = ['the','i','it', 'a', 'and', 'is', 'in', 'of', 'that', 's', 't', 'be', 'me', 'm', 'you',\\\n            'just', 'these', 'them', 'ha','x', 'coat', 'design', 'summer']\ndftest['Review_cl_3'] = dftest['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the','it','in', 'that', 's', 't', 'ha', 'x', 'design', 'summer']\ndftest['Review_cl_rec3'] = dftest['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","b2502a0d":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_3']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_rec3']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","73819e98":"submission27 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission27.to_csv('submissionanar27.csv',index=False)","5f7142ef":"df['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\n#stop_words = set(stopwords.words('english')) - set(['not'])\ndf['Review_lem3'] = df['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())","22123592":"# Continuation of same strategy\nmost_freq = pd.Series(' '.join(df['Review_lem3']).split()).value_counts()[180:200]\nmost_freq","d3b487e0":"\nfreq_list = ['the','i','it', 'a', 'and', 'is', 'in', 'of', 'that', 's', 't', 'be', 'me', 'm', 'you',\\\n            'just', 'these', 'them', 'ha','x', 'coat', 'design', 'summer', 'arm','shoulder', 'time',\\\n            'some', 'what', 'side', 've', 'd', 'shape', 'need', 'regular', 'around', 'hip']\ndf['Review_cl_3'] = df['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","ce11b93d":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_3']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","813bd491":"\nfreq_list2 = ['the','it','in', 'that', 's', 't', 'ha', 'x', 'design', 'summer', 'what', 've', 'day', 'd', \\\n             'need', 'regular', 'hip']\ndf['Review_cl_rec3'] = df['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","cf95ae43":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_rec3']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))","4483a980":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","2211e581":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem3'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\nfreq_list = ['the','i','it', 'a', 'and', 'is', 'in', 'of', 'that', 's', 't', 'be', 'me', 'm', 'you',\\\n            'just', 'these', 'them', 'ha','x', 'coat', 'design', 'summer', 'arm','shoulder', 'time',\\\n            'some', 'what', 'side', 've', 'd', 'shape', 'need', 'regular', 'around', 'hip']\ndftest['Review_cl_3'] = dftest['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the','it','in', 'that', 's', 't', 'ha', 'x', 'design', 'summer', 'what', 've', 'day', 'd', \\\n             'need', 'regular', 'hip']\ndftest['Review_cl_rec3'] = dftest['Review_lem3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","612a1769":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_3']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_rec3']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","586d1611":"submission28 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission28.to_csv('submissionanar28.csv',index=False)","c0430a24":"# I decide again to apply lemma function with the same strategy\ndf['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())","2b9c2da9":"df['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)","95029586":"freq_list = ['the','i','a', 'it']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","deaeeca0":"y1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","1c16531e":"freq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","7d3fcc24":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","04bddecf":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","3a56da44":"# I decide to use TF-IDF vectorizer again\ny1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\ntf_ngt1 = TfidfVectorizer(ngram_range = (1,2))\nX1_train_ngt = tf_ngt1.fit_transform(X1_train)\nX1_test_ngt = tf_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","c2d3159c":"y2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\ntf_ngt2 = TfidfVectorizer(ngram_range = (1,2))\nX2_train_ngt = tf_ngt2.fit_transform(X2_train)\nX2_test_ngt = tf_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=25, solver = 'sag'))\n        \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","4268d0ce":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","08494bd3":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","b5d7b181":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= tf_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","75f13d1b":"submission29 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission29.to_csv('submissionanar29.csv',index=False)","93cf3faf":"# Contination of the same strategy with TF-IDF\nmost_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[80:100]\nmost_freq","798b0744":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)","a2c74bc4":"freq_list = ['the', 'i', 'a', 'it', 'is', 'this','my', 'as', \"wear\", 'am', \"i'm\", 'you', 'look',\\\n            '-', 'me.']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\ntf_ngt1 = TfidfVectorizer(ngram_range = (1,2))\nX1_train_ngt = tf_ngt1.fit_transform(X1_train)\nX1_test_ngt = tf_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=30, solver = 'sag') \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))","a0d2611b":"freq_list2 = ['the', 'a', 'is', 'as', 'wear', 'am', 'just', \"i'm\", 'you', 'these', '-']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\ntf_ngt2 = TfidfVectorizer(ngram_range = (1,2))\nX2_train_ngt = tf_ngt2.fit_transform(X2_train)\nX2_test_ngt = tf_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=30, solver = 'sag'))\n        \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","d681af28":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","37939885":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it', 'is', 'this','my', 'as', \"wear\", 'am', \"i'm\", 'you', 'look',\\\n            '-', 'me.']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'is', 'as', 'wear', 'am', 'just', \"i'm\", 'you', 'these', '-']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","67108fde":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= tf_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","7b4fdca5":"submission30 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission30.to_csv('submissionanar30.csv',index=False)","5c1b41d7":"# Again lemmas Count Vectorizer - playing with words\ndf['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())","c85e12d3":"df['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)","660e975b":"most_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[20:40]\nmost_freq","a7e491b9":"# I added multinomial to parameters of Logistic Regression \n# Also, until now I calculated combined corr score, now I calcualate separate scores for \n#rating and recommendation\nfreq_list = ['the', 'i', 'a', 'it']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag') \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","fdedf11b":"freq_list2 = ['the', 'a', 'in', 'you']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = LogisticRegression(multi_class = 'ovr', C=0.25, solver = 'sag')\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","f3d63dc1":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","0da7626f":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in', 'you']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","49b75bb0":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","6a4c36c6":"submission31 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission31.to_csv('submissionanar31.csv',index=False)","47451198":"most_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[60:80]\nmost_freq","9e64d240":"freq_list = ['the', 'i', 'a', 'it', 'and', 'is', 'in', 'on', 'of', 'so', 'my', \"fit\", \"i'm\", 'too',\\\n            'you', 'will', 'these', 'look', 'an', 'it.', 'fits', '-', 'material', 'even']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","8d8d9d46":"# I decide not to include Review_item_filled (only to Rating column) to see the result\ny1 = df['Rating']\nX = df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(C=0.25, solver = 'sag')               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","be38e5ad":"#USing same recommender prediction as in submission 31\nfreq_list2 = ['the', 'a', 'in', 'you']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = LogisticRegression(multi_class = 'ovr', C=0.25, solver = 'sag')\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))","4a0a52be":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\n(coef_rat + coef_rec)\/2","b731a938":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it', 'and', 'is', 'in', 'on', 'of', 'so', 'my', \"fit\", \"i'm\", 'too',\\\n            'you', 'will', 'these', 'look', 'an', 'it.', 'fits', '-', 'material', 'even']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in', 'you']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","ccb86878":"dftest_combined_rat = dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","ef997687":"submission32 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission32.to_csv('submissionanar32.csv',index=False)","3d595b23":"# Continuation of previous tactics\ndf['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())","32893470":"df['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)","6c3eec92":"most_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[40:60]\nmost_freq","437749f8":"freq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'an', 'will']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","c634ca50":"freq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = LogisticRegression(multi_class = 'ovr', C=0.25, solver = 'sag')\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","28d4de03":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","8c1fe486":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'an', 'will']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","7d28a0b7":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","bf06fdf1":"submission33 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission33.to_csv('submissionanar33.csv',index=False)","081e996a":"most_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[60:80]\nmost_freq","fee7cd49":"# I change only Rating part leaving Recommendation part as before\nfreq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'an', 'will', 'small',\\\n            'when', 'magnificent', '-', 'has', 'all']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_filled']+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.1, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\n#lr_comb_rat = AdaBoostClassifier(base_estimator=LogisticRegression(C=0.25, solver = 'sag')) \nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)\n","8c9cb9e3":"# Recommendation part is same\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_filled']+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = LogisticRegression(multi_class = 'ovr', C=0.25, solver = 'sag')\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","b8530ba2":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","a2c28bd1":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'an', 'will', 'small',\\\n            'when', 'magnificent', '-', 'has', 'all']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","3625e2ed":"dftest_combined_rat = dftest['Review_title_filled']+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","73649550":"submission34 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission34.to_csv('submissionanar34.csv',index=False)","2215fec4":"df['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)","3d1b9cb1":"# I also apply simple Lemmatization to Review_title_filled column\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nlem = WordNetLemmatizer()\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())","6d9333e5":"# I combine two columns with space and apply test size 0.2 to Rating part\nfreq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'an', 'will']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","22ee28e0":"freq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","f015b9a0":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","5f1df23d":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'an', 'will']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","67bb46c0":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","3c92fa4b":"submission35 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission35.to_csv('submissionanar35.csv',index=False)","c2f07b7a":"most_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[0:20]\nmost_freq","1bc8d1d7":"# I continue the same old tactics - playing with frequent word list\nfreq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'will', 'it.', 'one', 'these',\\\n            'and', 'this']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\n#lr_comb_rat = AdaBoostClassifier(base_estimator=LogisticRegression(C=0.25, solver = 'sag')) \nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","f73f4ceb":"freq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","90d12c7e":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","53935949":"#dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\n#lem = WordNetLemmatizer()\n#dftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                      # join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                       #      split()]).lower())\n#dftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\n#dftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'will', 'it.', 'one', 'these',\\\n            'and', 'this']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","ed0c5fca":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","cb0b247f":"submission36 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission36.to_csv('submissionanar36.csv',index=False)","ede6ca9d":"most_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[0:20]\nmost_freq","63d91ccb":"# I leave Rating part as before - change only RRecommendation part\nfreq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'will', 'it.', 'one', 'these',\\\n            'and', 'this']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","d6af80f7":"freq_list2 = ['the', 'a', 'in', 'i', 'it', 'but', 'for']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","8ffd5ccf":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","9c620aac":"freq_list = ['the', 'i', 'a', 'it', 'at', 'really', 'if', 'me', 'ordered', 'will', 'it.', 'one', 'these',\\\n            'and', 'this']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in', 'i', 'it', 'but', 'for']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","38a822f2":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","38bbdf52":"submission37 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission37.to_csv('submissionanar37.csv',index=False)","469f9f25":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())","45a3dbe3":"df['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())","8a8b3748":"most_freq = pd.Series(' '.join(df['Review_lem_new2']).split()).value_counts()[40:60]\nmost_freq","11c9e438":"## I play again with frequent word list for Rating column.\n## For Recommendation column I will use the same classification I used in submission 35 and 36\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they'] #0.7378\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","c6ea5f0b":"freq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","b079882d":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","002bfd0c":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","d981c18e":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","4f427b6d":"submission38 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission38.to_csv('submissionanar38.csv',index=False)","6b71b402":"## I try another set of list\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","4fde3626":"# The same model as in previous submission \nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","31c063e2":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","86a7f3c8":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                            split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","0fc240cf":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","74e46576":"submission39 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission39.to_csv('submissionanar39.csv',index=False)","db54b4c6":"# I decide to clean text after applying lemma function.\ndf['Review_lem_new3'] = df['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))","544d985a":"# I apply another list of frequent words\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was',\\\n             'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndf['Review_cl_new2'] = df['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","86ae4660":"# Same classification for recommendation\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = LogisticRegression(C=0.25, solver = 'sag')\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","4cb9af49":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","c0b23000":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was',\\\n             'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndftest['Review_cl_new2'] = dftest['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","10a2481f":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","5aea0b2f":"submission40 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission40.to_csv('submissionanar40.csv',index=False)","a983e79f":"# I apply short version of frequent list\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have']\ndf['Review_cl_new2'] = df['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","b7d7cbe8":"# Same classification for recommendation\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = LogisticRegression(C=0.25, solver = 'sag')\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","99332400":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","9e0f925e":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                           split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have']\ndftest['Review_cl_new2'] = dftest['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","f9129ad1":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","46d897fb":"submission41 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission41.to_csv('submissionanar41.csv',index=False)","48209723":"# After failures, I revert again to previous lemma function - without cleaning afterwards\nfreq_list = ['the','i', 'and', 'a', 'it']#, 'at', 'really', 'if', 'me', 'ordered', 'an', 'will']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\n#lr_comb_rat = AdaBoostClassifier(base_estimator=LogisticRegression(C=0.25, solver = 'sag')) \nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)\n","6eeae669":"freq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","29a1290c":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","35df04d5":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                            split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\nfreq_list = ['the','i', 'and', 'a', 'it']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","b680e766":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","13422760":"submission42 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission42.to_csv('submissionanar42.csv',index=False)","ceac8720":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndf['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndf['Review_lem_new3'] = df['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))","22a1e9c1":"# - I repeat the same model for rating which I used in subm 39\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2'] \nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","23cc67bc":"coef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)#I try Multinomial NB for Recommendaion since it gave a bit higher result\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = MultinomialNB(alpha = 0.26)\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","12216c8d":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","e9fc3533":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","a5849e87":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","e6ab9df7":"submission43 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission43.to_csv('submissionanar43.csv',index=False)","20c17cd3":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndf['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndf['Review_lem_new3'] = df['Review_lem_new2'].apply(lambda x: \" \".\\\n                                      join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))","b9c97c68":"# I use the same model used in submission 39\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2'] \nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","162c3bab":"# I use Linear SVC - since corr score is slightly higher\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = LinearSVC(C=0.01)\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","f66f8bdc":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","a1b62d7c":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                            split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                      join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","575ee638":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","b5c6c87d":"submission44 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission44.to_csv('submissionanar44.csv',index=False)","5610d855":"# I use expanded frequent list of words\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny1 = df['Rating']\nX = df['Review_title_new']+  ' ' +df['Review_cl_new2'] \nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\nvectorizer_ngt1 = CountVectorizer(ngram_range = (1,2))\nX1_train_ngt = vectorizer_ngt1.fit_transform(X1_train)\nX1_test_ngt = vectorizer_ngt1.transform(X1_test)\nlr_comb_rat = LogisticRegression(multi_class = 'multinomial', C=0.25, solver = 'sag')          \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\nprint('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","e530817c":"# The same model as in submission 39\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","d1639e44":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","01057882":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new3'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","8f031f50":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","2f97982a":"submission45 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission45.to_csv('submissionanar45.csv',index=False)","21854af2":"# I realized that I made a slight error in preparing submission file, so I make a new submission\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","af3711a8":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= vectorizer_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","26184624":"submission46 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission46.to_csv('submissionanar46.csv',index=False)","5f8082d3":"\ndf['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndf['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndf['Review_lem_new3'] = df['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))","1c793fa2":"# I decided to treat Rating prediction as Regression problem\ny1 = df['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\ntf_ngt = TfidfVectorizer(ngram_range = (1,2))\nX1_train_ngt = tf_ngt.fit_transform(X1_train)\nX1_test_ngt = tf_ngt.transform(X1_test)\n#lr_rat = LogisticRegression(C=0.25, solver = 'sag')  \nlr_comb_rat = Ridge(alpha = 0.6)               \n\nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\n#print('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","f1d54ba6":"np.unique(y_pred1)","7685d0e1":"# Above corr score is 0.7090, but I have to round numbers and replace 6 with 5\ny_pred1 = np.round(y_pred1)\ny_pred1 = np.where(y_pred1 == 6, 5, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","17c68ed2":"# The same model as in submission 39\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","ef657fdc":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","a14b3ed4":"# Prepaing test file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","558c7bc7":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= tf_ngt.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","600870e7":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","9012a5f6":"submission47 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission47.to_csv('submissionanar47.csv',index=False)","900345fb":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndf['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndf['Review_lem_new3'] = df['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))","c41b6f65":"# I keep the same model as in submission 47\ny1 = df['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\ntf_ngt1 = TfidfVectorizer(ngram_range = (1,2))\nX1_train_ngt = tf_ngt1.fit_transform(X1_train)\nX1_test_ngt = tf_ngt1.transform(X1_test)\nlr_comb_rat = Ridge(alpha = 0.6)               \nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\n#print('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","76af8467":"y_pred1 = np.round(y_pred1)\ny_pred1 = np.where(y_pred1 == 6, 5, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","0bd31047":"# I apply TfIdf Vectorizer, RidgeClassifier() and different frequent list for Recommendation\nfreq_list2 = ['the', 'i', 'a', 'in', 'at', 'this', 'to', 'on', 'that', 'have', \"or\", 'just',\\\n             \"i'm\", 'too', 'you', 'ordered', 'an', '-', 'from', 'usually', 'long', 'petite',\\\n             \"don't\", \"large\", 'true', 'retailer', 'xs', 'do', 'go', 'enough', 'store', \\\n             'top.', 'over', 'worn', 'try', 'make', 'design', 'first', 'style', 'around', \\\n             'makes', 'found', 'being', 'after', 'looking', \"blue\", 'summer', 'off']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\ntf_ngt2 = TfidfVectorizer(ngram_range = (1,2))\nX2_train_ngt = tf_ngt2.fit_transform(X2_train)\nX2_test_ngt = tf_ngt2.transform(X2_test)\nlr_comb_rec = RidgeClassifier(alpha = 0.15)               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","782d2c46":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","faae78de":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'i', 'a', 'in', 'at', 'this', 'to', 'on', 'that', 'have', \"or\", 'just',\\\n             \"i'm\", 'too', 'you', 'ordered', 'an', '-', 'from', 'usually', 'long', 'petite',\\\n             \"don't\", \"large\", 'true', 'retailer', 'xs', 'do', 'go', 'enough', 'store', \\\n             'top.', 'over', 'worn', 'try', 'make', 'design', 'first', 'style', 'around', \\\n             'makes', 'found', 'being', 'after', 'looking', \"blue\", 'summer', 'off']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","fe0c5c4a":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= tf_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","e1a469ee":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","1272fd13":"submission48 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission48.to_csv('submissionanar48.csv',index=False)","b94c342e":"# I apply simple Lemmatization with TF-IDF vectoizer.\nstop_words = set(stopwords.words('english')) - set(['not'])\ndf['Review_lem'] = df['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())","6cf098eb":"# I remove some frequently used words\ny1 = df['Rating']\nfreq_list = ['clothe', 'fit', 'size', 'i', 'top', 'color', 'wear', 'one', 'well', 'bought',\\\n            'material', 'x', 'trouser', 'retailer', 'get', 'style', 'design']#\n           \ndf['Review_cl'] = df['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = df['Review_title_new']+' '+df['Review_cl']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\ntf_ngt1 = TfidfVectorizer(ngram_range = (1,2))\nX1_train_ngt = tf_ngt1.fit_transform(X1_train)\nX1_test_ngt = tf_ngt1.transform(X1_test)\nlr_comb_rat =Ridge(alpha = 0.1)  \n\nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\n#print('accuracy %s' % accuracy_score(y\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)\ny_pred1 = np.round(y_pred1)\n# After ounding there was 6 and 0, I rreplace them to 5 and 1 respectively\ny_pred1 = np.where(y_pred1 == 6, 5, y_pred1)\ny_pred1 = np.where(y_pred1 == 0, 1, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","ed59530a":"# The same model as in submission 39\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","7b0f6406":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","761dced5":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\ndftest['Review_lem'] = dftest['Review_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split() if i not in stop_words]).lower())    \nfreq_list = ['clothe', 'fit', 'size', 'i', 'top', 'color', 'wear', 'one', 'well', 'bought',\\\n            'material', 'x', 'trouser', 'retailer', 'get', 'style', 'design']\ndftest['Review_cl'] = dftest['Review_lem'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","31557cc7":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","4946d1cf":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest['Rating'].unique()","86463fbf":"# Numbers 6 and 7 are replaced with 5, 0 with 1\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5},inplace=True)\ndftest[\"Rating\"].replace({7:5}, inplace=True)\ndftest[\"Rating\"].replace({0:1}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","1ec715c9":"submission49 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission49.to_csv('submissionanar49.csv',index=False)","3a332f74":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndf['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndf['Review_lem_new3'] = df['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))","9550d93b":"# I expand frequent list used in submission 47\ny1 = df['Rating']\nfreq_list = ['the','i', 'a', 'is', 'of', ' my', 'as', \"fit\", \"i'm\" , 'up' , 'look', 'it.', '-', \\\n             'material', 'from', 'tried', 'could', 'petite', \"cut\", 'waist', 'been', 'front', \\\n           \"without\", 'summer', \"light\", '&', 'by', 'body', 'while', 'pair', 'then', '4', 'bra', \\\n            'almost', 'weight', 'shoulders', 'print', 'should', 'green', \"i'd\", 'skinny', 'm']\n\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\ntf_ngt1 = TfidfVectorizer(ngram_range = (1,2))\nX1_train_ngt = tf_ngt1.fit_transform(X1_train)\nX1_test_ngt = tf_ngt1.transform(X1_test)\n\nlr_comb_rat =Ridge(alpha = 0.6)            \n\nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\ncorrrat2, _ = pearsonr(y_pred1, y1_test)\nprint('Corrat %s' %corrrat2)\ny_pred1 = np.round(y_pred1)\ny_pred1 = np.where(y_pred1 == 6, 5, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","2f748db3":"np.unique(y_pred1)","517849db":"# The same model as in submission 39\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' '+df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.1, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.25, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","fbaf0a8a":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","fad8a709":"# Prepaing test file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                    join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'a', 'is', 'of', ' my', 'as', \"fit\", \"i'm\" , 'up' , 'look', 'it.', '-', \\\n             'material', 'from', 'tried', 'could', 'petite', \"cut\", 'waist', 'been', 'front', \\\n           \"without\", 'summer', \"light\", '&', 'by', 'body', 'while', 'pair', 'then', '4', 'bra', \\\n            'almost', 'weight', 'shoulders', 'print', 'should', 'green', \"i'd\", 'skinny', 'm']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","c9961591":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","64db19fa":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest[\"Rating\"].replace({0: 1}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","c65b3ec2":"submission50 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission50.to_csv('submissionanar50.csv',index=False)","785d9678":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndf['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndf['Review_lem_new3'] = df['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))","662dbdff":"# Model used in submission 47\ny1 = df['Rating']\n#freq_list = ['the','i', 'and', 'a', 'it',  'this', 'of']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\ntf_ngt1 = TfidfVectorizer(ngram_range = (1,2))\nX1_train_ngt = tf_ngt1.fit_transform(X1_train)\nX1_test_ngt = tf_ngt1.transform(X1_test)\nlr_comb_rat = Ridge(alpha = 0.6)               \n\nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\n#print('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","474890b8":"y_pred1 = np.round(y_pred1)\ny_pred1 = np.where(y_pred1 == 6, 5, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","3cdef5c4":"freq_list = ['the','i', 'a']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))","9d0b9cf9":"# I apply LSTM to Recommended column\ny2 = df['Recommended']\nX = df['Review_title_new']+' ' +df['Review_cl_new_rec2']\nX_val = X.values\ny2_val = y2.values\nX2_train, X2_test, y2_train, y2_test = train_test_split(X_val, y2_val, test_size = 0.15, random_state=100)\nVOCAB_SIZE = 5000\nencoder_rec_cl = TextVectorization(max_tokens=VOCAB_SIZE, ngrams = (1,2), pad_to_max_tokens = False)\nencoder_rec_cl.adapt(X2_train)","8f3470e8":"model_rec_cl = Sequential([\n    encoder_rec_cl,\n    Embedding(\n        input_dim=len(encoder_rec_cl.get_vocabulary()),  # VOCAB_SIZE + 1 (1 for padding token)\n        output_dim=64,\n        mask_zero=True\n    ),\n    \n    LSTM(256),  \n    Dense(256, activation='relu'),\n    Dense(1, activation='sigmoid')\n])","29c0c601":"model_rec_cl.compile(loss=BinaryCrossentropy(from_logits = True) , optimizer='adam', metrics=['accuracy'])\nhistory_rec_cl = model_rec_cl.fit(X2_train, y2_train, epochs=20, batch_size = 10, validation_data=(X2_test, y2_test))","30b1b085":"# Preparing test file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","9806dede":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = model_rec_cl.predict_classes(dftest_combined_rec","026e8bf6":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","d24d4354":"submission51 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission51.to_csv('submissionanar51.csv',index=False)","267f91cb":"model_rec_cl.compile(loss=BinaryCrossentropy(from_logits = True) , optimizer='adam', metrics=['accuracy'])\nhistory_rec_cl = model_rec_cl.fit(X2_train, y2_train, epochs=20, batch_size = 10, validation_data=(X2_test, y2_test))","486459c1":"# In order not to change df, I work on duplicate file\ndfx = pd.read_csv('..\/input\/iba-ml1-final-project\/train.csv')","748f9d69":"# Replacing 'Review_title' valus with 'Not Filled' expression. For this column, nothing changes\ndfx['Review_title'] = dfx['Review_Title'].replace(np.nan, 'Not Filled', regex=True, inplace = True)\ndfc = dfx[['Review_Title', 'Review', 'Rating', 'Recommended']]","4ea4d92f":"# I separate dataframe into 2 parts - with and without null\ndfc_wna = dfc[dfc['Review'].isnull()==False]\ndfc_na = dfc[dfc['Review'].isnull()==True]","ef35f809":"# I select texts from Review column corresponding to Ratings\n\nFive = \"Love this top! the quality is magnificent and \\\nthe pattern is even cuter in person. 125 lbs and bought my normal size s which fits excellently.\\\nit's pretty flouncy and roomy, which is nice because it hides my post-baby tummy. especially \\\nlove how the back covers my bottom which means i can wear my skinny black leggings underneath.\\\ndefinitely recommend!\"\nFour = \"Amazing, beautiful clothe that is very slimming and \\\nelegant, while casual. but it is only for smaller busted women! i have a medium and am a 34c - \\\nit's tight and pulls strangely. i've seen that comment elsewhere. i tried on the large and \\\nit was too big everywhere but the bust.\"\nThree = \"Adorable suit, super cute print and magnificent quality,\\\nbut unfortunately not as flattering as other reviewers noted. i found that the white pattern\\\naccentuated the wrong areas and the ruffle feature was a bit over-the-top. the straps are \\\nalso very thin and didn't offer too much support.\"\nTwo = \"I was so smitten by this shirt when i saw it online. \\\ni love embroidery and purple is my preferred color. i am a size 10 and decided to order an l. \\\nthe shoulders fit well, but the rest of it was huge...like another reviewer said...\\\nlike a maternity top.\"\nOne = \"The cups on this suit are ridiculous. \\\nunless you are going to a nudist beach i do not recommend. the construction of the \\\nsuit itself was also vey poor. seams were messed up, a big pull right on the front-- \\\ni brought it back. sad because the design was adorable- just poor execution.\"\n","ab4c2104":"dfc_na.loc[dfc_na.Rating == 5, 'Review'] = Five\ndfc_na.loc[dfc_na.Rating == 4, 'Review'] = Four\ndfc_na.loc[dfc_na.Rating == 3, 'Review'] = Three\ndfc_na.loc[dfc_na.Rating == 2, 'Review'] = Two\ndfc_na.loc[dfc_na.Rating == 1, 'Review'] = One","b4dec460":"# Checking if filling is correct\ndfc_na['Review'].value_counts()","cdc12b3b":"# Then I concatenate separated dataframes back and sorrt by index\ndfc_stitched = pd.concat([dfc_na, dfc_wna])\ndfc_stitched_ind = dfc_stitched.sort_index()","31fcf260":"dfc_stitched_ind.head() ","72da339c":"# This is the same function I used fo lemmatization\ndef getWordNetPOS (POStag):\n    def is_noun(POStag):\n        return POStag in ['NN', 'NNS', 'NNP', 'NNPS']\n    def is_verb(POStag):\n        return POStag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n    def is_adverb(POStag):\n        return POStag in ['RB', 'RBR', 'RBS']\n    def is_adjective(POStag):\n        return POStag in ['JJ', 'JJR', 'JJS']\n\n    if is_noun(POStag):\n        return wordnet.NOUN\n    elif is_verb(POStag):\n        return wordnet.VERB\n    elif is_adverb(POStag):\n        return wordnet.ADV\n    elif is_adjective(POStag):\n        return wordnet.ADJ\n    else:\n        # if not noun, verb, adverb or adjective, return noun\n        return wordnet.NOUN","e8beb567":"def lemmas (wordtokens):\n    lemmatizer = WordNetLemmatizer()\n    POStag = pos_tag(wordtokens)\n    wordtokens = [lemmatizer.lemmatize(token[0], getWordNetPOS(token[1]))\n                  for token in POStag]\n\n    return wordtokens","29af4a46":"# Altough I sorted combined dataframe - I used unsorted one - Noticed mistake after submission\ndfc_stitched['Review_lem_new2'] = dfc_stitched['Review'].apply(lambda x: \"\".join(lemmas(x)).lower())\nlem = WordNetLemmatizer()\ndfc_stitched['Review_title_new'] = dfc_stitched['Review_Title'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())","56350cb9":"y1 = dfc_stitched['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndfc_stitched['Review_cl_new2'] = dfc_stitched['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = dfc_stitched['Review_title_new']+' '+dfc_stitched['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\ntf_ngt1 = TfidfVectorizer(ngram_range = (1,2))\nX1_train_ngt = tf_ngt1.fit_transform(X1_train)\nX1_test_ngt = tf_ngt1.transform(X1_test)\n#lr_rat = LogisticRegression(C=0.25, solver = 'sag')  \nlr_comb_rat = Ridge(alpha = 0.6)               \n\nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\n#print('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","0ce8fc81":"y_pred1 = np.round(y_pred1)\nnp.unique(y_pred1)","a2072c0b":"y_pred1 = np.round(y_pred1)\ny_pred1 = np.where(y_pred1 == 6, 5, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","be1cbc90":"# The same model as in previous submission for recommendation\nfreq_list2 = ['the', 'a', 'in']\ndfc_stitched['Review_cl_new_rec2'] = dfc_stitched['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = dfc_stitched['Recommended']\nX = dfc_stitched['Review_title_new']+' '+dfc_stitched['Review_cl_new_rec2']\n#X = dfc_stitched['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.2, random_state=100)\nvectorizer_ngt2 = CountVectorizer(ngram_range = (1,2))\nX2_train_ngt = vectorizer_ngt2.fit_transform(X2_train)\nX2_test_ngt = vectorizer_ngt2.transform(X2_test)\nlr_comb_rec = (LogisticRegression(C=0.6, solver = 'sag'))\n               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\nprint('accuracy %s' % accuracy_score(y_pred2, y2_test))\n#print('F1 %s' % f1_score(y_pred2, y2_test))\n#print('f1 %s' % f1_score(y_pred2, y2_test))\n#print('pecision %s' % precision_score(y_pred2, y2_test))\n#print('recall %s' % recall_score(y_pred2, y2_test))\n\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","ff11e0f3":"# I find number of null values respective to Rating column\nfive_null = df.Review[df['Rating'] == 5].isnull().sum()\nfour_null = df.Review[df['Rating'] == 4].isnull().sum()\nthree_null = df.Review[df['Rating'] == 3].isnull().sum()\ntwo_null = df.Review[df['Rating'] == 2].isnull().sum()\none_null = df.Review[df['Rating'] == 1].isnull().sum()\ntotal_null = (df['Review'].isnull()).sum()\ntest_null = (dftest['Review'].isnull()).sum()","b420e1dc":"# I find the proportion of null values in test file which I will fill with above_mentioned texts\n# I add 1 to fill_5 to make total value correct\nfill_5 = (round(five_null \/ total_null * test_null, 0) + 1).astype(int)\nfill_4 = (round(four_null \/ total_null * test_null, 0)).astype(int) \nfill_3 = (round(three_null \/ total_null * test_null, 0)).astype(int)\nfill_2 = (round(two_null \/ total_null * test_null, 0)).astype(int)\nfill_1 = (round(one_null \/ total_null * test_null, 0)).astype(int)\nprint(fill_5, fill_4, fill_3, fill_2, fill_1)","98ad08c9":"# I fill null values in testset according to proportion of null values\ndftest['Review'] = dftest['Review'].fillna(Five, limit = fill_5)\ndftest['Review'] = dftest['Review'].fillna(Four, limit = fill_4)\ndftest['Review'] = dftest['Review'].fillna(Three, limit = fill_3)\ndftest['Review'] = dftest['Review'].fillna(Two, limit = fill_2)\ndftest['Review'] = dftest['Review'].fillna(One, limit = fill_1)","63d2d178":"#Checking top five values\ndftest['Review'].value_counts()[0:5]","acc86fab":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\n\ndftest['Review_lem_new2'] = dftest['Review'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     # join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","bdc91a70":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec) ","e445309c":"dftest['Rating'] = dftest['Rating'].round()","908eeff9":"dftest['Rating'].unique()","d3a1408f":"dftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)","56006619":"submission52 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission52.to_csv('submissionanar52.csv',index=False)","ca041fd9":"df['Review_filled'] = df['Review'].replace(np.nan, 'Not Filled', regex=True)\ndf['Review_lem_new2'] = df['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndf['Review_title_filled'] = df['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndf['Review_title_new'] = df['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndf['Review_lem_new3'] = df['Review_lem_new2'].apply(lambda x: \" \".\\\n                                       join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))","ed861d98":"# Same model used in submission 47\ny1 = df['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\ntf_ngt1 = TfidfVectorizer(ngram_range = (1,2))\nX1_train_ngt = tf_ngt1.fit_transform(X1_train)\nX1_test_ngt = tf_ngt1.transform(X1_test)\nlr_comb_rat = Ridge(alpha = 0.6)               \n\nlr_comb_rat.fit(X1_train_ngt, y1_train)\ny_pred1 = lr_comb_rat.predict(X1_test_ngt)\n#print('accuracy %s' % accuracy_score(y1_test, y_pred1))\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","795e8db3":"y_pred1 = np.round(y_pred1)\ny_pred1 = np.where(y_pred1 == 6, 5, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","4e0fd540":"# I decided to apply Optuna to find best parameters for Recommended \nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_new']+' ' +df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)","eabde38a":"def objective(trial):\n    params = {\n\n        'alpha': trial.suggest_loguniform('alpha', 1e-8, 100.0)             \n           \n\n    }\n     #'scaler' RobustScaler\n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n   \n    ('vect', CountVectorizer(ngram_range = (1,2))),\n    ('classification', SGDClassifier(**params))  \n])\n\n    model.fit(X2_train, y2_train)\n    y_pred2 = model.predict(X2_test)\n    coef_rec, p = spearmanr(y2_test, y_pred2)\n    return (coef_rec)","e8de1337":"if __name__ == '__main__':\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","9bb59dc0":"modelsgd_rec = Pipeline(steps=[\n   \n    ('vect', CountVectorizer(ngram_range = (1,2))),\n    ('classification', SGDClassifier(alpha = 0.004972085933401556))  \n])\nmodelsgd_rec.fit(X2_train, y2_train)","a3e9cd87":"y_pred2 = modelsgd_rec.predict(X2_test)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","eede1653":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","0a6a4724":"# Prepaing test file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\ndftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', 'really', 'if', 'look', 'an', 'one']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","62bbb6e5":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\ndftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = lr_comb_rat.predict(dftest_combined_vec_rat) \ndftest['Recommended'] = modelsgd_rec.predict(dftest_combined_rec) ","7e95b327":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","00eb4c48":"submission53 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission53.to_csv('submissionanar53.csv',index=False)","d1ce520b":"# I will use the same model for Recommendation part. However, for some strange reason, model gave \n#differrent results in each run. Therefore I uploaded my last submission and will use that file\ndfrec = pd.read_csv('..\/input\/submission53\/submissionanar53.csv')","b54cef13":"# For rating, I expand freq_list\ny1 = df['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\n\nmodelrid_rat = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    ('regression', Ridge(alpha = 0.6))  \n])\nmodelrid_rat.fit(X1_train, y1_train)\ny_pred1 = modelrid_rat.predict(X1_test)\n#accuracy = accuracy_score(y1_test, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","609177aa":"y_pred1 = np.round(y_pred1)\nnp.unique(y_pred1)","63f029ec":"y_pred1 = np.where(y_pred1 == 6, 5, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","81e1c33a":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                    # join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n#freq_list2 = ['the', 'a', 'in']\n#dftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","c1357ee9":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\n#dftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\n#dftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = modelrid_rat.predict(dftest_combined_rat) \n#dftest['Recommended'] = modelsgd_rec.predict(dftest_combined_rec) ","25592c5f":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","f77cb741":"submission54 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dfrec['Recommended']})\nsubmission54.to_csv('submissionanar54.csv',index=False)","b7d0d3ef":"# In this submission, I repeat method applied in submission 52, but just for recommendation \n# In order not to change df, I work on duplicate file\ndfe = pd.read_csv('..\/input\/iba-ml1-final-project\/train.csv')","9647ae1a":"# Replacing 'Review_title' valus with 'Not Filled' expression. For this column, nothing changes\ndfe['Review_title'] = dfe['Review_Title'].replace(np.nan, 'Not Filled', regex=True, inplace = True)\ndft = dfe[['Review_Title', 'Review', 'Rating', 'Recommended']]","661ea2b5":"dft.head()","bdc5566a":"# I separate dataframe into 2 parts - with and without null\ndft_wna = dft[dft['Review'].isnull()==False]\ndft_na = dft[dft['Review'].isnull()==True]","8fea1c30":"one_rec = \"Love this top! the quality is magnificent and \\\nthe pattern is even cuter in person. 125 lbs and bought my normal size s which fits excellently.\\\nit's pretty flouncy and roomy, which is nice because it hides my post-baby tummy. especially \\\nlove how the back covers my bottom which means i can wear my skinny black leggings underneath.\\\ndefinitely recommend!\"\nzero = \"The cups on this suit are ridiculous. \\\nunless you are going to a nudist beach i do not recommend. the construction of the \\\nsuit itself was also vey poor. seams were messed up, a big pull right on the front-- \\\ni brought it back. sad because the design was adorable- just poor execution.\"","4b4dcfc6":"dft_na.loc[dft_na.Recommended == 1, 'Review'] = one_rec\ndft_na.loc[dft_na.Recommended == 0, 'Review'] = zero","3820efa9":"dft_na['Review'].head(10)","be7ef3f9":"# Then I concatenate separated dataafames back and sorrt by index\ndft_st = pd.concat([dft_na, dft_wna])\ndft_st_ind = dft_st.sort_index()","1df6750c":"dft_st_ind.info()","a76c5f60":"dft_st_ind['Review_lem_new2'] = dft_st_ind['Review'].apply(lambda x: \"\".join(lemmas(x)).lower())\nlem = WordNetLemmatizer()\ndft_st_ind['Review_title_new'] = dft_st_ind['Review_Title'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())","be4ba14b":"# Rating as in submission 54","7f9c4185":"freq_list2 = ['the', 'a', 'in']\ndft_st_ind['Review_cl_new_rec2'] = dft_st_ind['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = dft_st_ind['Recommended']\nX = dft_st_ind['Review_title_new']+' '+dft_st_ind['Review_cl_new_rec2']\n#X = dfc_stitched['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)","7be60752":"def objective(trial):\n    params = {\n        'solver': trial.suggest_categorical('solver', ['sag', 'newton-cg', 'lbfgs','liblinear']),\n        #'multi_class': trial.suggest_categorical('multiclass', ['multinomial', 'ovr']),\n        'C': trial.suggest_loguniform('C', 1e-8, 100.0)             \n           \n\n    }\n     #'scaler' RobustScaler\n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n   \n    ('vect', CountVectorizer(ngram_range = (1,2))),\n    ('classification', LogisticRegression(**params))  \n])\n\n    model.fit(X2_train, y2_train)\n    y_pred2 = model.predict(X2_test)\n    coef_rec, p = spearmanr(y2_test, y_pred2)\n    return (coef_rec)","0f99ab6b":"if __name__ == '__main__':\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","9f28949c":"model_rec = Pipeline(steps=[\n   \n    ('vect', CountVectorizer(ngram_range = (1,2))),\n    ('classification', LogisticRegression(C = 1.147417692029431, solver = 'sag'))  \n])\n\nmodel_rec.fit(X2_train, y2_train)\ny_pred2 = model_rec.predict(X2_test)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","b7557ba8":"one_null_rec = df.Review[df['Recommended'] == 1].isnull().sum()\nzero_null = df.Review[df['Recommended'] == 0].isnull().sum()\ntotal_null = (df['Review'].isnull()).sum()\ntest_null = (dftest['Review'].isnull()).sum()","59401051":"# I find the proportion of null values in test file which I will fill with above_mentioned texts\nfill_1 = round(one_null_rec \/ total_null * test_null, 0)\nfill_0 = round(zero_null \/ total_null * test_null, 0)\nprint(fill_1, fill_0)","b15d3a7f":"# I fill null values in testset according to proportion of null values\ndftest['Review'] = dftest['Review'].fillna(one_rec, limit = 317 )\ndftest['Review'] = dftest['Review'].fillna(zero, limit = 25)","112d674e":"# Correct tomorrrow for dftest - make so that Rating do not change\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\n\ndftest['Review_lem_new2'] = dftest['Review'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     # join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","01c074c9":"#dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\n#dftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\n#dftest['Rating'] = modelrid_rat.predict(dftest_combined_rat) \ndftest['Recommended'] = model_rec.predict(dftest_combined_rec) ","e71c1660":"dfco = pd.read_csv('..\/input\/submisssion\/submissionanar54.csv')","0158ec22":"submission55 = pd.DataFrame({'Id':dftest['Id'],'Rating':dfco['Rating'],'Recommended':dftest['Recommended']})\nsubmission55.to_csv('submissionanar55-3.csv',index=False)","94887319":"# LSTM for Recommendation column\nfreq_list = ['the','i', 'a']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\ny2 = df['Recommended']\nX = df['Review_title_new']+' ' +df['Review_cl_new_rec2']\nX_val = X.values\ny2_val = y2.values\nX2_train, X2_test, y2_train, y2_test = train_test_split(X_val, y2_val, test_size = 0.15, random_state=100)\nVOCAB_SIZE = 5000\nencoder_rec_cl = TextVectorization(max_tokens=VOCAB_SIZE, ngrams = (1,2), pad_to_max_tokens = False)\nencoder_rec_cl.adapt(X2_train)","3fbb65f0":"model_rec_cl = Sequential([\n    encoder_rec_cl,\n    Embedding(\n        input_dim=len(encoder_rec_cl.get_vocabulary()),  # VOCAB_SIZE + 1 (1 for padding token)\n        output_dim=64,\n        mask_zero=True\n    ),\n    \n    LSTM(256),  \n    Dense(256, activation='relu'),\n    Dense(1, activation='sigmoid')\n])","89ae2daf":"model_rec_cl.compile(loss=BinaryCrossentropy(from_logits = True) , optimizer='rmsprop', metrics=['accuracy'])\nhistory_rec_cl = model_rec_cl.fit(X2_train, y2_train, epochs=20, batch_size = 10, validation_data=(X2_test, y2_test))","ef9a6b51":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     #join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","b1810c91":"#dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\n#dftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\n#dftest['Rating'] = modelrid_rat.predict(dftest_combined_rat) \ndftest['Recommended'] = model_rec_cl.predict_classes(dftest_combined_rec)","bb61fb80":"# Rating part as in submission 54\ndfco = pd.read_csv('..\/input\/submisssion\/submissionanar54.csv')","76c3543b":"submission56 = pd.DataFrame({'Id':dftest['Id'],'Rating':dfco['Rating'],'Recommended':dftest['Recommended']})\nsubmission56.to_csv('submissionanar56.csv',index=False)","86e82378":"df12 = df[(df['Rating'] == 2) | (df['Rating'] == 1)]\ndfcon = df.append(df12)\ndfcon.info()","b671a57c":"y2 = dfcon['Recommended']\nfreq_list = ['the','i', 'a']\ndfcon['Review_cl_new_rec2'] = dfcon['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)","e823322b":"def objective(trial):\n    params = {\n\n        'C': trial.suggest_loguniform('C', 1e-8, 100.0),\n        'solver': trial.suggest_categorical('solver', ['sag', 'newton-cg', 'lbfgs','liblinear'])\n           \n\n    }\n     #'scaler' RobustScaler\n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    #('tfidf', TfidfTransformer()),    \n    ('classification', LogisticRegression(**params))  \n])\n\n    model.fit(X2_train, y2_train)\n    y_pred2 = model.predict(X2_test)\n    coef_rec, p = spearmanr(y2_test, y_pred2)\n    return (coef_rec)","2932ac49":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","dbafdae9":"## I use for Ratign column the model used in submission 54\ny1 = df['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\n\nmodelrid_rat = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    ('regression', Ridge(alpha = 0.6))  \n])\nmodelrid_rat.fit(X1_train, y1_train)\ny_pred1 = modelrid_rat.predict(X1_test)\n#accuracy = accuracy_score(y1_test, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","3490e481":"## Recommendation model\ny2 = dfcon['Recommended']\nfreq_list = ['the','i', 'a']\ndfcon['Review_cl_new_rec2'] = dfcon['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = dfcon['Review_title_new']+' '+dfcon['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)\nmodel_rec = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    #('tfidf', TfidfTransformer()),    \n    ('classification', LogisticRegression(solver = 'sag', C = 23.933639412213513)) \n])\nmodel_rec.fit(X2_train, y2_train)\ny_pred2 = model_rec.predict(X2_test)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","e1867466":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","6ef1eea9":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     #join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","2d032676":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\n#dftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = modelrid_rat.predict(dftest_combined_rat) \ndftest['Recommended'] = model_rec.predict(dftest_combined_rec)","9b7c9c43":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","8cf2e9be":"submission57 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission57.to_csv('submissionanar57.csv',index=False)","899bc260":"# In this submission I apply expanding based on Recommendation value 0\ndf0 = df[df['Recommended'] == 0]\ndfcon2 = df.append(df0)\ny2 = dfcon2['Recommended']\nfreq_list = ['the','i', 'a']\ndfcon2['Review_cl_new_rec2'] = dfcon2['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = dfcon2['Review_title_new']+' '+dfcon2['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)","6fb9c209":"def objective(trial):\n    params = {\n\n        'C': trial.suggest_loguniform('C', 1e-8, 100.0),\n        'solver': trial.suggest_categorical('solver', ['sag', 'newton-cg', 'lbfgs','liblinear'])\n           \n\n    }\n     #'scaler' RobustScaler\n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    #('tfidf', TfidfTransformer()),    \n    ('classification', LogisticRegression(**params))  \n])\n\n    model.fit(X2_train, y2_train)\n    y_pred2 = model.predict(X2_test)\n    coef_rec, p = spearmanr(y2_test, y_pred2)\n    return (coef_rec)","03e20f44":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","e95530c5":"## Recommendation model\ny2 = dfcon2['Recommended']\nfreq_list = ['the','i', 'a']\ndfcon2['Review_cl_new_rec2'] = dfcon2['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = dfcon2['Review_title_new']+' '+dfcon2['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)\nmodel_rec = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    #('tfidf', TfidfTransformer()),    \n    ('classification', LogisticRegression(solver = 'lbfgs', C = 53.79021478210791)) \n])\nmodel_rec.fit(X2_train, y2_train)\ny_pred2 = model_rec.predict(X2_test)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","23bc1713":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     #join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","26c7acda":"#dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\n#dftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\n#dftest['Rating'] = modelrid_rat.predict(dftest_combined_rat) \ndftest['Recommended'] = model_rec.predict(dftest_combined_rec)","35cc464d":"# For rating submission file 54\ndfco = pd.read_csv('..\/input\/submisssion\/submissionanar54.csv')","43e0a130":"submission58 = pd.DataFrame({'Id':dftest['Id'],'Rating':dfco['Rating'],'Recommended':dftest['Recommended']})\nsubmission58.to_csv('submissionanar58.csv',index=False)","d9c4f756":"#In this submission, I expand dataset atificially futher\ndf['Rating'].value_counts()","cf1c4e10":"df1 = df[df['Rating'] == 1]\ndfapp1 = df.append(df1)\ndf2 = df[df['Rating'] == 2]\ndfapp2 = dfapp1.append(df2)\ndf3 = df[df['Rating'] == 3]\ndfapp3 = dfapp2.append(df3)\ndf4 = df[df['Rating'] == 4]\ndfapp4 = dfapp3.append(df4)","5b27a44d":"dfapp4['Rating'].value_counts()","b1900ac3":"y1 = dfapp4['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndfapp4['Review_cl_new2'] = dfapp4['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = dfapp4['Review_title_new']+' '+dfapp4['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)","c136c414":"def objective(trial):\n    params = {\n\n        'alpha': trial.suggest_loguniform('alpha', 1e-8, 100.0)             \n           \n\n    }\n     #'scaler' RobustScaler\n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    #('vect', CountVectorizer(ngram_range = (1,2))),\n    #('tfidf', TfidfTransformer()),    \n    ('regression', Ridge(**params))  \n])\n\n    model.fit(X1_train, y1_train)\n    y_pred1 = model.predict(X1_test)\n    #accuracy = accuracy_score(y1_test, y_pred1)\n    coef_rat, p = spearmanr(y1_test, y_pred1)\n    return (coef_rat)","91510cb2":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","c0682111":"y1 = dfapp4['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndfapp4['Review_cl_new2'] = dfapp4['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = dfapp4['Review_title_new']+' '+dfapp4['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\n\nmodelrid_rat = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    ('regression', Ridge(alpha = 5.416832294284494e-07 ))  \n])\nmodelrid_rat.fit(X1_train, y1_train)\ny_pred1 = modelrid_rat.predict(X1_test)\n#accuracy = accuracy_score(y1_test, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","ae445b86":"## Recommendation model\ny2 = dfcon2['Recommended']\nfreq_list = ['the','i', 'a']\ndfcon2['Review_cl_new_rec2'] = dfcon2['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = dfcon2['Review_title_new']+' '+dfcon2['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)\nmodel_rec = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    #('tfidf', TfidfTransformer()),    \n    ('classification', LogisticRegression(solver = 'lbfgs', C = 53.79021478210791)) \n])\nmodel_rec.fit(X2_train, y2_train)\ny_pred2 = model_rec.predict(X2_test)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","9390844b":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","b3a883d8":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     #join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","1cfecb36":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\n#dftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = modelrid_rat.predict(dftest_combined_rat) \ndftest['Recommended'] = model_rec.predict(dftest_combined_rec)","fc05b9ce":"dftest['Rating'] = dftest['Rating'].round()\ndftest['Rating'].unique()","af3c1725":"dftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest[\"Rating\"].replace({7: 5}, inplace=True)\ndftest[\"Rating\"].replace({0: 1}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\ndftest['Rating'].unique()","a4d1e121":"submission59 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission59.to_csv('submissionanar59.csv',index=False)","5c3ce694":"## Application of MLP regressor - Note -this model took 4 hours - in case you want to run it\ny1 = df['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\n\nmodelrid_rat = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    ('regression', MLPRegressor(alpha = 0.5859535826020941))  \n])\nmodelrid_rat.fit(X1_train, y1_train)\ny_pred1 = modelrid_rat.predict(X1_test)\n#accuracy = accuracy_score(y1_test, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","ad21b827":"y_pred1 = np.round(y_pred1)\nnp.unique(y_pred1)","135f639d":"y_pred1 = np.where(y_pred1 == 6, 5, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","3ab93779":"# Prepaing test file\ndftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     #join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n#freq_list2 = ['the', 'a', 'in']\n#dftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","3db06e0a":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\n#dftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\n#dftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = modelrid_rat.predict(dftest_combined_rat) \n#dftest['Recommended'] = modelsgd_rec.predict(dftest_combined_rec)","dbe4fa38":"#dftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","367fcdc3":"# For recommendation I use the same model as in submission 58\ndf58rec = pd.read_csv('..\/input\/submission58\/submissionanar58.csv')","4da4fdc6":"submission60 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':df58rec['Recommended']})\nsubmission60.to_csv('submissionanar60.csv',index=False)","d60cd727":"# Application of SGD - parameters found by Optuna\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\n#X = df['Review_title_new']+' ' +df['Review_cl_new_rec2']\nX = df['Review_title_filled']+' ' +df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)","0ddbefbe":"def objective(trial):\n    params = {\n\n        'alpha': trial.suggest_loguniform('alpha', 1e-8, 100.0)             \n           \n\n    }\n     #'scaler' RobustScaler\n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    ('classification', SGDClassifier(**params))  \n])\n\n    model.fit(X2_train, y2_train)\n    y_pred2 = model.predict(X2_test)\n    coef_rec, p = spearmanr(y2_test, y_pred2)\n    return (coef_rec)","182aafa6":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=1500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","fb3536b9":"freq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\n#X = df['Review_title_new']+' ' +df['Review_cl_new_rec2']\nX = df['Review_title_filled']+' ' +df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)\n\nmodel_sgn = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    ('classification', SGDClassifier(alpha =3.0208816622384544e-05))  \n])\nmodel_sgn.fit(X2_train, y2_train)\ny_pred2 = model_sgn.predict(X2_test)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)\n","b9060df9":"## Rating  - part\ny1 = df['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\n\nmodelrid_rat = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    ('regression', Ridge(alpha = 0.6))  \n])\nmodelrid_rat.fit(X1_train, y1_train)\ny_pred1 = modelrid_rat.predict(X1_test)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","d3903e52":"# Since SGD produced differrent results each time, I decided to build model without pipeline. \n#However, it still gave different results. This version is used in final prediction\nfreq_list2 = ['the', 'a', 'in']\ndf['Review_cl_new_rec2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))\ny2 = df['Recommended']\nX = df['Review_title_filled']+' ' +df['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)\ntf_ngt1 = TfidfVectorizer(ngram_range = (1,2))\nX2_train_ngt = tf_ngt1.fit_transform(X2_train)\nX2_test_ngt = tf_ngt1.transform(X2_test)\nlr_comb_rec = SGDClassifier(alpha =3.0208816622384544e-05)               \nlr_comb_rec.fit(X2_train_ngt, y2_train)\ny_pred2 = lr_comb_rec.predict(X2_test_ngt)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)               \n                            ","7a40e1a6":"coef_rat, p = spearmanr(y1_test, y_pred1)\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rat %s' %coef_rat)\nprint('Coef_rec %s' %coef_rec)\n(coef_rat + coef_rec)\/2","7dc5b93d":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     #join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","95b44518":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_filled']+' '+dftest['Review_cl_new_rec2']\n\n#dftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\ndftest_combined_vec_rec= tf_ngt1.transform(dftest_combined_rec)\ndftest['Rating'] = modelrid_rat.predict(dftest_combined_rat) \ndftest['Recommended'] = lr_comb_rec.predict(dftest_combined_vec_rec)","cb912881":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","efa554d8":"submission61 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission61.to_csv('submissionanar61.csv',index=False)","175501a0":"# In this submission, I expand dataset atificially further\ndf0 = df[df['Recommended'] == 0]\ndfcon2 = df.append(df0)\ndfcon2_exp1 = dfcon2.append(df0)","54ce0ea1":"y2 = dfcon2_exp1['Recommended']\nfreq_list = ['the','i', 'a']\ndfcon2_exp1['Review_cl_new_rec2'] = dfcon2_exp1['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = dfcon2_exp1['Review_title_new']+' '+dfcon2_exp1['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)","ad8db1de":"def objective(trial):\n    params = {\n\n        'C': trial.suggest_loguniform('C', 1e-8, 100.0),\n        'solver': trial.suggest_categorical('solver', ['sag', 'newton-cg', 'lbfgs','liblinear'])\n           \n\n    }\n     #'scaler' RobustScaler\n    #model = xgb.XGBClassifier(**params)\n    model = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    #('tfidf', TfidfTransformer()),    \n    ('classification', LogisticRegression(**params))  \n])\n\n    model.fit(X2_train, y2_train)\n    y_pred2 = model.predict(X2_test)\n    coef_rec, p = spearmanr(y2_test, y_pred2)\n    return (coef_rec)","c72bc609":"if __name__ == '__main__':\n\n\n\n    study = optuna.create_study(direction='maximize')\n\n    study.optimize(objective, n_trials=1500)\n\n\n\n    print(study.best_params)\n\n    print(study.best_value)\n\n    print(study.best_trial)","3864509e":"# For rating, same model in submission 54\ny1 = df['Rating']\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndf['Review_cl_new2'] = df['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\n\nX = df['Review_title_new']+' '+df['Review_cl_new2']\nX1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.2, random_state=100)\n\nmodelrid_rat = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    ('regression', Ridge(alpha = 0.6))  \n])\nmodelrid_rat.fit(X1_train, y1_train)\ny_pred1 = modelrid_rat.predict(X1_test)\n#accuracy = accuracy_score(y1_test, y_pred1)\ncoef_rat, p = spearmanr(y1_test, y_pred1)\nprint('Coef_rat %s' %coef_rat)","54a9aff3":"## Recommendation model\ny2 = dfcon2_exp1['Recommended']\nfreq_list = ['the','i', 'a']\ndfcon2_exp1['Review_cl_new_rec2'] = dfcon2_exp1['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nX = dfcon2_exp1['Review_title_new']+' '+dfcon2_exp1['Review_cl_new_rec2']\nX2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.15, random_state=100)\nmodel_rec = Pipeline(steps=[\n   \n    ('vect', TfidfVectorizer(ngram_range = (1,2))),\n    #('tfidf', TfidfTransformer()),    \n    ('classification', LogisticRegression(solver = 'newton-cg', C = 97.42040151163032)) \n    \n])\nmodel_rec.fit(X2_train, y2_train)\ny_pred2 = model_rec.predict(X2_test)\nprint('accuracy %s' % accuracy_score(y2_test, y_pred2))\ncoef_rec, p = spearmanr(y2_test, y_pred2)\nprint('Coef_rec %s' %coef_rec)","d61c4883":"dftest['Review_title_filled'] = dftest['Review_Title'].replace(np.nan, 'Not Filled', regex=True)\nlem = WordNetLemmatizer()\ndftest['Review_title_new'] = dftest['Review_title_filled'].apply(lambda x: \" \".\\\n                                       join([lem.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).\\\n                                             split()]).lower())\ndftest['Review_filled'] = dftest['Review'].replace(np.nan, 'Not Filled', regex=True)\ndftest['Review_lem_new2'] = dftest['Review_filled'].apply(lambda x: \"\".join(lemmas(x)).lower())\n#dftest['Review_lem_new3'] = dftest['Review_lem_new2'].apply(lambda x: \" \".\\\n                                     #join([i for i in re.sub(\"[^a-zA-Z]\", \" \", x).split()]))\nfreq_list = ['the','i', 'and', 'a', 'it',  'this', 'of', 'was', 'my', 'have', 'they', \\\n             'really', 'if', 'look', 'an', 'one', 'in', 'on', 'that',  'size', 'will', 'an', \\\n            'had', 'it', 'than', 'fits', '-', 'which', 'material', 'think', 'them', 'back', 'from']\ndftest['Review_cl_new2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list))\nfreq_list2 = ['the', 'a', 'in']\ndftest['Review_cl_new_rec2'] = dftest['Review_lem_new2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq_list2))","146c9044":"dftest_combined_rat = dftest['Review_title_new']+' '+dftest['Review_cl_new2']\ndftest_combined_rec = dftest['Review_title_new']+' '+dftest['Review_cl_new_rec2']\n\n#dftest_combined_vec_rat= tf_ngt1.transform(dftest_combined_rat)\n#dftest_combined_vec_rec= vectorizer_ngt2.transform(dftest_combined_rec)\ndftest['Rating'] = modelrid_rat.predict(dftest_combined_rat) \ndftest['Recommended'] = model_rec.predict(dftest_combined_rec)","861f34f3":"# I should make several changes to Rating column\ndftest['Rating'] = dftest['Rating'].round()\ndftest[\"Rating\"].replace({6: 5}, inplace=True)\ndftest['Rating'] = dftest['Rating'].astype(int)\n# To see results\ndftest['Rating'].unique()","60caf8fd":"submission62 = pd.DataFrame({'Id':dftest['Id'],'Rating':dftest['Rating'],'Recommended':dftest['Recommended']})\nsubmission62.to_csv('submissionanar62.csv',index=False)","8911ee48":"## Preparing submission file","beea531d":"## Submission 14 - Combining Review title and Review_cl columns","7c26148e":"In this submission, I increase rows with Rating 1 or 2, to make dataset a bit balanced.","24dd1e37":"Public submission score is again disappointingly low.(0.6881)","0f2c1583":"## Basic EDA","7fe501c1":"Public score is very low  - 0.66853 - so I return to previous tactics","10aca244":"Corr score is 0.6920 - I try another submission ","b58ec73d":"Corr score above is 0.6754","5464bba5":"Corr above is 0.7065","1930db5e":"## Submission 11\n## Next strategy is to apply word lemmatization","e613c8b7":"## Submission 21","db832c65":"Public score is 0.65165 - I need to change my tactics","7620696d":"## Submission 46","572f694c":"Public score is 0.69170 - slight improvement","04749fa0":"Score is artifically high - 0.8722","76051a04":"## Submission 55","243b158c":"THe following two functions will be used afte submission 20. I placed it here so that it would be easy to find","b3c93a3a":"Corr score is artifically high - 0.8156 - I would like to see effect on actual score","8fc1581a":"Corr score is 0.6290, so I make another submission file","687388d0":"## Applying simple Keras","e4e23ff8":"Removed some words from most frequent 200 words (acc - 0.6723)","6160fce9":"Corr score is 0.57, so I make another submission","bc45b768":"## Submission 20","da9c02b5":"Combined corr score is 0.6985","a7904069":"Public score is 0.69114 - Again, no improvement","a4c644ca":"Public submission score is 0.67368","59eedf09":"## Submission 43 ","304b2287":"Combined Corr is 0.6924. I make another submission ","80cebb84":"Public submission score is 0.65137 - score dropped even lower.","7c0989dd":"## Transforming test set","7aa228ac":"## Submission 6","ea401ee7":"Combined score is 0.6815","c67f5ddd":"Accuracy is the 0.1986","8c7884c2":"Public score is 0.6085 - a bit higher than score prior to submission. ","8494f1ab":"Public score is 0.68315 - again lower score","11e1214a":"Unfortunately, score dropped futher to 0.6861 - no use in expanding frequent list","67517e1d":"## Submission 17 - I switch the places of Review_item_filled and 'Review_cl' ('Review_cl_exp) and expand the wordlist","bcdbcb46":"Corr score is 0.6978. I make another submission ","6f653abc":"Corr score is 0.6784 - so I make another submission ","6dadf6d1":" Corr is 0.7110","4dc2d277":"Corr score is 0.7069","64162c73":"## Submission 30","4582feca":"Public score dropped even lower to 0.67323","2c9d07d0":"Corr above is 0.7043","8a4d8260":"Public submission score is 0.63111","1b95dd93":"## Submission 47","61e9474d":"## Classification for Rating","dd99d9b7":"## RNN rating with ngrams","bfc66bf9":"## Submission 53","f94b0e89":"## Submission 12\n## Removing most frequent and less frequent words","8b41f00d":"Public submission score is 0.61006","88a4a95c":"## Submission 37 - try to improve 2nd prediction","05b159b1":"## Submission 42 ","1133b85c":"Public submission score is 0.6213","fc18bd40":"## Preparing submission 2 file for submission","2e1acee0":"## Submission 3\n## Bag of words for recommendation","9a54b8e9":"Public score is 0.69044, closer to 0.6917","53ec0cd4":"## Submission 9\n## Logistic Regression with Test size = 0.1","d638f35c":"Corr score is 0.6327 - so I make another submission file","3c833428":"Accuracy score was low, so I decide to apply n-grams.","1bb7cc20":"Combined corr score is 0.6993. I make another submission","42ebd4ee":"Corr score is 0.6848 - I make another submission ","99fbfe6c":"The score did not change substantially -0.68835","3a93e385":"## Submission 19","60fa8f80":"Public submission score is 0.60928","b9fccd2b":"## Submission 4\n## Using n-grams","3b71fe22":"Accuracy is the 0.1986","0d17e7b8":"Corr score is 0.7024, a bit higher than in previous submission 47","8b17b664":"Corr scorre is 0.7088","e5d91e27":"As expected correlation score is lower - 0.5388","7511f877":"## Submission 2\n## Creating Pipeline with CountVectorizer, TfidfTransformer and SGD classifier","47f8197c":"## Preparing Rating column","38945a10":"Corr score is 0.6869 - so I make another submission file","22da7bd4":"## Investigate why submission 55 fr dftest gave differrent euslt -corect it - look at subm 56 and make a copy out of it","be4dd26b":"Accuracy score is 0.879","8cf22c9a":"Corr score is 0.6311 - so I will make a submission file","e252cd9c":"## Submission 56","06dcdc87":"## Submission 50","d15cfa56":"## Submission 51","1c7d0c29":"After changes, I got the 0.6953, I make a new submission to see impact on results","18843e74":"Corr score is 0.6286 - so I make another submission file","b95073b1":"Rating accuracy is 0.595, recommendation is 0.84","adec7af4":"## TF IDF Vectorizer","9c85f505":"Corr is 0.7 - I make another submission ","23abc13d":"Corr score is 0.7066","9c75e055":"## Making first submission file","aa1c05a6":"## Submission 61","9042548c":"## Applying LINEAR SVC to n-2 gram model","71eb4ce5":"Public score dropped to 0.6533","0dd0d711":"## Submission 39","971e5b83":"## Converting Text to Word Frequency Vectors with TfidfVectorizer (Recommendation column)","0ed240e6":"## New function in lemmatization","5d48ae52":"Score is artifically high - 0.8931","06e6f3eb":"Combined corr is 0.6977 - I make another submission ","4aa4f4a6":"Public score is low - 0.69726","ab88315a":"## Submission 8\n## Logistic Regression","da4dac01":"In this submission, I apply new methodology in filling null values. Main idea is to copy one cell corresponding to 'Rating' for each values of 5,4,3,2,1 and fill them according to the weights of values in overall null values..","1a5ebb49":"## Submission 33","57eed5e4":"Test accuracy score is 0.86 on average","26e6c0a2":"Corr score is 0.6797","80256b8b":"## Submission 29\n## Back to lemmas","90ba5e6f":"Corr score is 0.6719 - I make another submission ","0c4da543":"Corr score is 0.6688, so I make another submission","c32ab769":"## Submission 54","610fdd7c":"Corr score is 0.6793- I make another submission ","907f3184":"## Combining Review_Title and Review columns","fa48aa49":"Combined corr score is 0.7048","cefd2919":"Corr score is 0.6701- so I make submission.","b4560604":"Accuracy is 0.68","8c34e025":"Public submission score is 0.6756 (much lower than previous scores)","4970f390":"## Preparing submission 3","14a39cfd":"## Predicting Recommendation","54e83ad0":"## Preprocessing text - stemming","fb78c384":"## Keras for recommendation","6ce5775e":"## Cleaning after lemma\n## Submission 40","dcdaf577":"## Submission 49","e9bbd069":"## Making rating prediction column for testset","01b68823":"Corr score - 0.6965. I make another submission ","706037da":"Corr score is 0.6711, so I make another submission","56ce6bcb":" I got disapointingly low score - 0.67740","38260fbe":"Corr score is 0.7544. I expect this would increase public score at least a bit.","efdc2cbb":"Corr score is 0.6988","e5eb7838":"Corr of recommend is 0.6832                                                                           \nCombined is 0.6761 - I make another submission ","210c0109":"Public score is 0.6813","7685643c":"## Submission 15\n## Expanding frequent list to see the impact on score","29cde90d":"Combined corrat score is 0.6978 - I make another submission. ","e18e61bb":"Public submission score improved a little bit - 0.68948 ","2e90c592":"## Submission 34","71913463":"Corr score is 0.6689","347ebdb5":"## Submission 36","aa69e02f":"## Submission 27","12e38f88":"I got the highest result with SGD classifier so I will make Rating column and will make submission","98626c46":"Corr score is 0.6951","683c6224":"## Preparing submission 4 files","6ba210af":"## Submission 44","04b1bb7c":"## Submission 62","c85aeedf":"Correlation score is 0.595","0fa8a5b8":"I got very poor submssion result (0.62769)","53e13900":"## Submission 7\n## RNN to Rating multiclass","aa6aa3e3":"Orig corr score 0.6693 - submission score is 0.66015","59f71f5a":"## Bag of words for rating","705704f2":"Corr score is 0.6731 - I make submission ","c0c6b5d4":"Unrounded combined corr is 0.7","258cb64a":"## Submission 28","3c8f1639":"Public score dropped to 0.67712","8d8cc364":"## Building Keras model","f7dbbb0f":"## Submission 18 - Trying different set of frequent words removal","2482dd19":"Since accuracy here is higher (0.6943 vs 0.6749, I apply this model)","828520bc":"Corr score is 0.7089","d172eca6":"Corr score is 0.6607","01035001":"Combined score is 0.7643","67f4204a":"Public score is low - 0.68853","0d45f0cc":"## Submission 16","eda0d582":"Accuracy score is 0.62","a739084c":"Corr is 0.6640, which is quite an improvement. So I make another submission ","43ffd028":"Combined corr score is 0.6743","7dc4f587":"Combined score is 0.6981","4a0c36ea":"Corr result is 0.3177, higher than prervious one, so I make a new submission","1d0dcd86":"Public score is 0.6843 ","4a01f46e":"Corr score is very low = 0.31","0eca6a54":"Corr score is 0.6802, I make another submission ","b6f4ede4":"## Submission 38","fb098967":"## Submission 22","0ba4e109":"Corr above is 0.6898","81ea39e8":"## Classification model for recommendation","28935987":"Public, score dropped to 0.68783","694e9c5b":"I did not like result from Keras recommend so I took rating from Keras and recommend from ngram SGD","59ed06b0":"Corr score is 0.60949 - Although it is low, I make another submission file to see public score","464672e6":"Public score rose to 0.7029","d6230b92":"Result is 0.6558 - which is lower than 0.66427","2152efa3":"Public submission score is 0.69545 - no improvement","bd4ba92e":"Unfortunately, score did not increase (0.6880)","f81e4740":"Public submission 0.6866 - at last slightly more increase","3609e324":"Corr score is 0.6726 - I make submission to see public score","3d0bcdaa":"Corr score is 0.68035 - I try my luck again.","6adc4ddc":"Public submission score decreased to 0.6841. Increase in corr score did not lead to an increase in public submission score","55480b28":"Score is 0.68685 - again lower","d57e7b00":"Actual public submission score is 0.606","fd7edd09":"Corr score is 0.6938","9f6ec217":"## RNN LSTM (recommendation column)","0d0e1d6d":"Score is 0.6040 - I make another submission just out of interest.","bdc45c20":"## Submission 26\n## Start lemmatizing again without stopwords","794497d3":"## Submission 35\n## I realized my mistake in combining columns - so I combine them with space","3bf0514b":"Combined corr score is 0.7248. Hope that this would be reflected in final score. I make submission","44c71e7d":"Corr score is 0.7111","d96bf9d3":"## Submission 31 - Count Vectorizer again","fb6b1814":"Corr score is 0.6736 - I want to see an impact on public score, so I make submission ","f75e9cf1":"Public score is 0.66393 - still no improvement","ab0856f7":"## Submission 5","add724b8":"## Submission 52","f3a55841":"Public score rose to 0.70521","2954c97d":"Corr scorre dropped to 0.5857, so I will not make a submission ","0b708b68":"Correlation score is 0.60 - omitting not words increased a result a bit","69f1e15b":"Combined corr is 0.6925.","370cab79":"## Submission 41","518cf23d":"## Submission 13\n## Removing rare words","361d54f3":"Combined corr score is 0.6983. I make submission ","85e6507a":"Corr score above is 0.6733","016e43a5":"Accurracy is 0.913","8a2bb5a1":"Combined score is 0.7054","36b88c6a":"## Submission 24","c8f5f25a":"## Submission 57","97c235b0":"## Submission 48","c0f0ecd8":"Max test accuracy score is 0.613. I do not expect an improvement of score, just make a submission","d3783350":"Public submission score is 0.62806","6207db90":"## Submission 59","c75d08e7":"Public score is 0.69626  - no improvement","f47d230e":"## Submission 45","bdbe88eb":"Public submission score is surprisingly 0.6976 - which is quite an improvement.","35dba057":"Corr score is 0.6781","ab5135d6":"## Submission 60","54c773c8":"## Submission 23","35b35b6d":"Max test accuracy was 0.9191, so I decide to make submission to see an impact on the result.","40864542":"Public submission scorer is 0.581, which is quite improvement","55d3f141":"## N-gram 2 with new stopwords without not","c734f535":"## N-gram 3 with new stop_words with not","906daef8":"Interestingly, corr score changes in each run for SGDClasssifier. Score at time of submission was 0.7","58931187":"Score is low - 0.69694","2599c9f7":"Combined corr score is 0.6897 - I make another submission ","2e72b4ea":"Public score is 0.67365 - again lower score","26d4093e":"## Trying without Review items filled\n## Submission 32 - experiment","7ad3eeee":"Corr score dropped to 0.5922. I make submission with n-grams = 2","d16c10e1":"## Submission 10\n## Bagging Classifier","f7f34ac4":"Public score is 0.6844  - slight improvement from previous score","5911dbc6":"Corr score is 0.7032","42ad1c6d":"Public score is 0.63133","47bcb4f3":"Combined corr score is 0.6998, I make another submission ","4d92e233":"I did not get desired result.Score is 0.6977","f03fe3dc":"Despite low score, I make another submission ","2179e708":"Average submission correl = 0.283                                                                                     \nPublic submission score 0.289","1d8fc9ec":"## Final models were chosen by Kaggle automatically - submission 58 and submission 62, of which submission 58 gave the highest private score.","8332656a":"Corr score is 0.6693 and accuracy for rating is 0.6943 - so I make another submission file","9f574ac7":"Until here, preprocessing is the same both for TF Vectorizer and both for pipeline Countvectorizer and bag of words","292fd801":"Public score is 0.6832 - got worse \n","ee3d32b4":"Corr is slightly higher - 0.7059","8f75b878":"Public score is 0.6846  - little improvement from 0.6844","acfc0b1d":"Public score is diappointingly low -0.6802, so I will revert to the prerrvious model for recommendation","ed0450cf":"Public score is 0.6891  - nice improvement","383b734e":"## Submission 25 - same strategy - playing with words","7d533c12":"## Submission 58","010cf1b6":"Public score is 0.6852 - gone down "}}