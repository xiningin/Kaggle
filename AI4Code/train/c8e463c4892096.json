{"cell_type":{"52f9c876":"code","c7be78b9":"code","f199f844":"code","3463dc09":"code","2c870df4":"code","987cea29":"code","058c7f79":"code","14534cac":"code","0930e211":"code","030fcb6b":"code","fd23a77d":"code","d2aebbfa":"code","8660b6ed":"code","fb46606d":"code","2f5a7b22":"code","170555d7":"code","cbb6e5ad":"code","d190aa91":"code","58951ca9":"code","70f6ead4":"markdown","9b2323b8":"markdown"},"source":{"52f9c876":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c7be78b9":"%matplotlib inline\n%reload_ext autoreload\n%autoreload 2\nimport warnings\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings(action='ignore')","f199f844":"# matplotlib configuration\nplt.rcParams['figure.figsize'] = (10, 8)\nplt.rcParams['figure.dpi'] = 100\nplt.rcParams['image.interpolation'] = 'spline16'\n\n# numpy setup\nnp.set_printoptions(precision=2)\nnp.random.seed(0)","3463dc09":"import pandas as pd\ntrain_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\n\nprint('Training data shape:    ', train_data.shape)\nprint('Testing data shape:  ', test_data.shape)\n","2c870df4":"Y_train = train_data[\"label\"]\n# # Drop 'label' column\nX_train = train_data.drop(labels = [\"label\"],axis = 1) ","987cea29":"# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = test_data.values.reshape(-1,28,28,1)\nprint('Training data shape:    ', X_train.shape)\nprint('Training labels shape:  ', X_test.shape)","058c7f79":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 10)\n ","14534cac":"from sklearn.model_selection import train_test_split\n# Split the train and the validation set for the fitting\nX_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)","0930e211":"print('X_train data shape:  ', X_train.shape)\nprint('Y_train data shape:    ', Y_train.shape)\n\nprint('X_test data shape:  ', X_test.shape)\nprint('Y_test data shape:  ', Y_test.shape)\n","030fcb6b":"import seaborn as sns\n\ndef plot_sample(X, y, idx=None, annot=False, shape=(28, 28)):\n    if idx is None:\n        idx = np.random.randint(0, X.shape[0] + 1)\n        \n    x = X[idx].reshape(shape)\n    \n    figsize = (shape[0] \/\/ 2, shape[1] \/\/ 2)\n    plt.figure(figsize=figsize)\n    sns.heatmap(x, annot=annot, cmap=plt.cm.Greys, cbar=False)\n    plt.title(y[idx])\n    plt.xticks([])\n    plt.yticks([])\n    plt.show()\n\nplot_sample(X_train, Y_train, annot=True, idx=None)","fd23a77d":"# compute mean vector from training data\nmu = np.mean(X_train, axis=0)\n\nX_train = X_train.astype(np.float32)\nX_test = X_test.astype(np.float32)\n\n# remove mean vector from all data\nX_train -= mu\nX_test  -= mu\n","d2aebbfa":"plt.figure(figsize=(4, 4))\nplt.imshow(mu.reshape(28, 28), interpolation='nearest', cmap=plt.cm.Greys)\nplt.xticks([])\nplt.yticks([])\nplt.title(\"Mean value of features\")\nplt.show()","8660b6ed":"from keras.layers import BatchNormalization\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',\n                 input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n#model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n#model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n#model.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","fb46606d":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(zoom_range = 0.1,\n                            height_shift_range = 0.1,\n                            width_shift_range = 0.1,\n                            rotation_range = 10)","2f5a7b22":"model.summary()","170555d7":"import tensorflow as tf\nfrom tensorflow import keras\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer =keras.optimizers.Adadelta(),\n              metrics= ['accuracy'])","cbb6e5ad":" \nmodel.fit(X_train, Y_train,\n          batch_size =128,\n          epochs = 5,\n          verbose =1,\n          validation_data =(X_test,Y_test)\n          )\n\n","d190aa91":"#Evaluation for Score Test Data\nscoreForTest = model.evaluate(X_test, Y_test, verbose=0)\n\n#Evaluation for Score Train Data\nscoreForTrain = model.evaluate(X_train, Y_train, verbose=0)\n\nprint('Test Score:', scoreForTest[0])\nprint('Test Accuracy:', scoreForTest[1] )\nprint('---------')\nprint('Train Score:', scoreForTrain[0])\nprint('Train Accuracy:', scoreForTrain[1] )","58951ca9":"# defining labels \nactivities = ('Test Score', 'Test Accuracy', 'Trian Score', 'Trian Accuracy')\n  \n# portion covered by each label \nslices = [scoreForTest[0], scoreForTest[1], scoreForTrain[0], scoreForTrain[1]] \n  \n# color for each label \ncolors = ['r', 'y', 'g', 'b'] \n  \n# plotting the pie chart \nplt.pie(slices, labels = activities, colors=colors,  \n        startangle=90, shadow = True, explode = (0, 0, 0.1, 0), \n        radius = 1.2, autopct = '%1.1f%%') \n  \n# plotting legend \nplt.legend() \n  \n# showing the plot \nplt.show() ","70f6ead4":"- In this dataset, every pixel has a value in `[0, 1]`, so there is no need for feature scaling.\n- But still we need to subtract the mean. \n\nNote that the mean vector is computed only from training data and subtracted from all data.","9b2323b8":"### Preprocessing: normalization"}}