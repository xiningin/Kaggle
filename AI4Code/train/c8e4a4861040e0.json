{"cell_type":{"ad9d85b2":"code","099945ba":"code","d0a937ae":"code","1a5c00d8":"code","10d1884c":"code","829e2599":"code","73bcf5f4":"code","84555d4b":"code","f4f94a29":"code","a71907e6":"code","6ab61b8b":"code","20f40fe7":"code","a198fcd2":"code","11466d27":"code","3c95defe":"code","f4ae05fe":"code","df2329e3":"code","a2628e7f":"code","9a70bad9":"code","7cf3998a":"code","e8c41ffe":"code","ecf78ec4":"code","4db41310":"code","6f4424c2":"code","45b5f53d":"code","a8aa583b":"code","bfa81ac6":"code","d702da0d":"code","c71b9b9f":"code","db98f49e":"code","afeea5d0":"code","37a34fc2":"code","eb458584":"code","ccfecc43":"code","77478f5d":"code","6d33538f":"code","ac9a9b99":"code","2e832f0a":"code","28c77699":"code","934f3a56":"code","2f1a0bf8":"code","e19a0745":"code","60c2f9fb":"code","2e122792":"code","3f69ae34":"code","fa303049":"code","19cc8014":"code","b8f11f57":"code","078b5332":"code","ed0af88d":"code","37b29d68":"code","282cbd2f":"code","bacaee7b":"code","5de842c9":"code","aed57a03":"code","80fe0af1":"code","7731458a":"code","13133330":"code","6400517e":"code","ce674b1b":"code","f4e8db14":"code","4412b47f":"code","b42226b3":"code","26295757":"code","10c103aa":"code","2c64f840":"code","e5fc84ea":"code","ca7019fd":"code","9cc40895":"code","0c226c1a":"code","5c35b729":"code","51b2ae51":"code","3ded677a":"code","6c2a8514":"code","cc60d5a3":"code","76856241":"code","06633e85":"code","6be475fb":"code","e7e01b99":"code","d4ea7745":"code","dee1f13f":"code","41a059f6":"code","7c2ba21b":"code","7869c2e4":"code","7bb075ba":"code","6939c842":"code","0bbe1911":"code","4f32e1c3":"code","eba2a91a":"code","fe953bca":"code","df762d29":"code","b00b685e":"code","567eb75b":"code","34241695":"code","1f9ab875":"code","dacee790":"code","4fe32782":"code","0845629c":"code","5489f1e2":"code","7348a1c7":"code","498075bd":"code","b3e9a254":"code","f389dce5":"code","d8f0e523":"code","e3028d86":"code","fba04f86":"code","7011a8b9":"code","6b2a2eef":"code","888c584f":"code","f740c9cd":"code","db0a1f79":"code","b1c96225":"code","fd5a23cf":"code","35cbbb2b":"code","46e45591":"code","1ad33757":"code","87d0a81a":"code","d866996d":"code","0371c4fa":"code","aff1f472":"markdown","e072669d":"markdown","103ee9b3":"markdown","d112824f":"markdown","51216064":"markdown","87adc895":"markdown","6f5eefcd":"markdown","7689b697":"markdown","01ccdd78":"markdown","a615e129":"markdown","bdb2d67b":"markdown","74a322d7":"markdown","7a686436":"markdown","418ee138":"markdown","4b438b57":"markdown","51aa9885":"markdown","b5fb94b2":"markdown","2577d9df":"markdown","30b2e408":"markdown","4815b7be":"markdown","40057324":"markdown","7db737cb":"markdown","d87821da":"markdown","1a0ddb3e":"markdown","d873ca6d":"markdown","dca1777d":"markdown","3dba36a0":"markdown","d734d825":"markdown","a3b8e5b2":"markdown","bb722634":"markdown","89435bd0":"markdown","8558f4ed":"markdown","fd275cdf":"markdown","d1451e05":"markdown","2a255047":"markdown","e0177914":"markdown","00424eda":"markdown","da992711":"markdown","ed8089b8":"markdown","814942db":"markdown","0ffb2bf0":"markdown","d3da0c7f":"markdown","b0de52b2":"markdown","ae189448":"markdown","25f5d24d":"markdown","3444d7a8":"markdown","ae9dcc7d":"markdown","d5c6fcbe":"markdown","babad2e7":"markdown","689bf1f4":"markdown","43249074":"markdown","1a4e057e":"markdown","0933334a":"markdown","53bb5fba":"markdown","1e24c667":"markdown","82db0381":"markdown","21008fe1":"markdown","df30dad0":"markdown","3621a76f":"markdown","808030be":"markdown","479d7738":"markdown","995f3518":"markdown","cb5d5e50":"markdown","fa7a4c96":"markdown","b777954f":"markdown","478cc8b3":"markdown","7b2259c2":"markdown","1adb5690":"markdown","3fd1663f":"markdown","28bbffaf":"markdown","4f08a80d":"markdown","8d99f1cc":"markdown"},"source":{"ad9d85b2":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","099945ba":"import numpy as np\nimport pandas as pd\nfrom pandas import Series, DataFrame\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","d0a937ae":"data = pd.read_csv('\/kaggle\/input\/airquality-uci\/AirQualityUCI.csv', sep=',', delimiter=\";\",decimal=\",\")","1a5c00d8":"data.head()","10d1884c":"data.tail()","829e2599":"data.shape","73bcf5f4":"data.info()","84555d4b":"#Deleting the Unnamed: 15 and Unnamed: 16 columns.\ndata = data.drop([\"Unnamed: 15\",\"Unnamed: 16\"], axis=1)","f4f94a29":"data.head()","a71907e6":"data.shape","6ab61b8b":"data.info()","20f40fe7":"data.isnull().any()","a198fcd2":"data.isnull().sum()","11466d27":"#Deleting all Null values in our dataset permanently.\ndata.dropna(inplace=True)\ndata.shape","3c95defe":"data.set_index(\"Date\", inplace=True) \n#setting Date column as new index of out dataframe.","f4ae05fe":"data.head(1)","df2329e3":"data.index = pd.to_datetime(data.index) #Converting the index in datetime datatype.\ntype(data.index)","a2628e7f":"data.head(1)","9a70bad9":"data['Time'] = pd.to_datetime(data['Time'],format= '%H.%M.%S').dt.hour #Selecting only Hour value from the 'Time' Column.\ntype(data['Time'][0])","7cf3998a":"data.head()","e8c41ffe":"data.info()","ecf78ec4":"data.describe()","4db41310":"data.plot.box()\nplt.xticks(rotation = 'vertical')\nplt.show()","6f4424c2":"data.replace(to_replace= -200, value= np.NaN, inplace= True)","45b5f53d":"data.isnull().any()","a8aa583b":"data.isnull().sum()","bfa81ac6":"plt.figure(figsize=(8,6))\nsns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')\nplt.show()","d702da0d":"data.drop('NMHC(GT)', axis=1, inplace=True)","c71b9b9f":"data.describe()","db98f49e":"data.shape","afeea5d0":"data.fillna(data.median(), inplace=True)","37a34fc2":"sns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')\nplt.show()","eb458584":"sns.set_style('whitegrid')\neda_data = data.drop(['Time','RH','AH','T'], axis=1)\nsns.pairplot(eda_data)","ccfecc43":"data.hist(figsize = (20,20))\nplt.show()","77478f5d":"data.drop(['Time','RH','AH','T'], axis=1).resample('M').mean().plot(figsize = (20,8))\nplt.legend(loc=1)\nplt.xlabel('Month')\nplt.ylabel('All Toxic Gases in the Air')\nplt.title(\"All Toxic Gases' Frequency by Month\")","6d33538f":"data['NOx(GT)'].resample('M').mean().plot(kind='bar', figsize=(18,6))\nplt.xlabel('Month')\nplt.ylabel('Total Nitrogen Oxides (NOx) in ppb')   # Parts per billion (ppb)\nplt.title(\"Mean Total Nitrogen Oxides (NOx) Level by Month\")","ac9a9b99":"plt.figure(figsize=(20,6))\nsns.barplot(x='Time',y='NOx(GT)',data=data, ci=False)\nplt.xlabel('Hours')\nplt.ylabel('Total Nitrogen Oxides (NOx) in ppb') # Parts per billion (ppb)\nplt.title(\"Mean Total Nitrogen Oxides (NOx) Frequency During Days\")","2e832f0a":"data.plot(x='NO2(GT)',y='NOx(GT)', kind='scatter', figsize = (10,6), alpha=0.3)\nplt.xlabel('Level of Nitrogen Dioxide')\nplt.ylabel('Level of Nitrogen Oxides (NOx) in ppb') # Parts per billion (ppb)\nplt.title(\"Mean Total Nitrogen Oxides (NOx) Frequency During Days\")\nplt.tight_layout();","28c77699":"plt.figure(figsize=(10,8))\nsns.heatmap(data.corr(), annot=True, linewidths=.20)","934f3a56":"sns.kdeplot(data['NOx(GT)'])\nplt.show()","2f1a0bf8":"plt.figure(figsize=(20,5))\nplt.plot(data['NOx(GT)'])\nplt.show()","e19a0745":"plt.figure(figsize=(21,8))\nplt.plot(data['NO2(GT)'])\nplt.show()","60c2f9fb":"data.shape","2e122792":"X = data.drop(['NOx(GT)','Time'], axis=1)\n\ny= data['NOx(GT)']","3f69ae34":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)","fa303049":"from sklearn.preprocessing import RobustScaler\n\nsc=RobustScaler()\nx_train=sc.fit_transform(x_train)\nx_test=sc.transform(x_test)","19cc8014":"from sklearn.linear_model import LinearRegression\n\nlm = LinearRegression()\nlm.fit(x_train, y_train)","b8f11f57":"print(lm.intercept_)","078b5332":"coeff_data = pd.DataFrame(lm.coef_, index=X.columns, columns=['Coefficient'])\ncoeff_data","ed0af88d":"prediction = lm.predict(x_test)\nplt.scatter(y_test, prediction, c=\"blue\", alpha=0.3)\nplt.xlabel('Measured')\nplt.ylabel('Predicted')\nplt.title('Linear Regression Predicted vs Actual')","37b29d68":"score_train = lm.score(x_train, y_train)\nscore_train","282cbd2f":"prediction = lm.predict(x_test)","bacaee7b":"score_test = lm.score(x_test, y_test)\nscore_test","5de842c9":"sns.distplot((y_test-prediction), bins=70, color=\"purple\")\n","aed57a03":"from sklearn import metrics\nprint('MAE:',metrics.mean_absolute_error(y_test, prediction))\nprint('MSE:',metrics.mean_squared_error(y_test, prediction))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, prediction)))","80fe0af1":"coeff_data","7731458a":"from sklearn.neighbors import KNeighborsRegressor\nknn=KNeighborsRegressor(n_neighbors=5)\nknn.fit(x_train,y_train)","13133330":"prediction = knn.predict(x_test)\nplt.scatter(y_test, prediction, c=\"black\", alpha=0.3)\nplt.xlabel('Measured')\nplt.ylabel('Predicted')\nplt.title('K-nearest Neighbors Predicted vs Actual')","6400517e":"knn_train = knn.score(x_train,y_train)\nknn_train","ce674b1b":"kreg_test = knn.score(x_test,y_test)\nkreg_test","f4e8db14":"from sklearn.neighbors import KNeighborsRegressor\nkreg=KNeighborsRegressor()","4412b47f":"para={'n_neighbors':np.arange(1,51),'weights':['uniform','distance'],\n      'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],'leaf_size':np.arange(10,51)}","b42226b3":"from sklearn.model_selection import RandomizedSearchCV","26295757":"knn_cv=RandomizedSearchCV(kreg,para,cv=5,random_state=0)\nknn_cv.fit(x_train,y_train)","10c103aa":"print(knn_cv.best_score_)\nprint(knn_cv.best_params_)","2c64f840":"kn=KNeighborsRegressor(weights='distance', n_neighbors= 12, leaf_size= 18, algorithm= 'brute')\nkn.fit(x_train,y_train)","e5fc84ea":"prediction = kn.predict(x_test)\nplt.scatter(y_test, prediction, c=\"black\", alpha=0.3)\nplt.xlabel('Measured')\nplt.ylabel('Predicted')\nplt.title('K-nearest Neighbors(Hyper) Predicted vs Actual')","ca7019fd":"#Accuracy on Training data\nknn_train=kn.score(x_train,y_train)\nknn","9cc40895":"#Accuracy on Training data\nknn_test=knn.score(x_test,y_test)\nknn_test","0c226c1a":"from sklearn.tree import DecisionTreeRegressor\ndreg=DecisionTreeRegressor()\ndreg.fit(x_train,y_train)","5c35b729":"prediction = dreg.predict(x_test)\nplt.scatter(y_test, prediction, c=\"green\", alpha=0.3)\nplt.xlabel('Measured')\nplt.ylabel('Predicted')\nplt.title('Decision Tree Predicted vs Actual')","51b2ae51":"dreg_train = dreg.score(x_train,y_train)\ndreg_train","3ded677a":"dreg_test = dreg.score(x_test,y_test)\ndreg_test","6c2a8514":"from sklearn.tree import DecisionTreeRegressor\nd=DecisionTreeRegressor()","cc60d5a3":"Param_grid={'splitter':['best','random'],'max_depth':[None,2,3,4,5],'min_samples_leaf':np.arange(1,9),\n            'criterion':['mse','friedman_mse','mae'],'max_features':['auto','sqrt','log2',None]}","76856241":"dt_cv=RandomizedSearchCV(d,Param_grid,cv=5,random_state=0)\ndt_cv.fit(x_train,y_train)","06633e85":"print(dt_cv.best_score_)\nprint(dt_cv.best_params_)","6be475fb":"dtr=DecisionTreeRegressor(splitter= 'best', min_samples_leaf= 8, max_features= 'auto', max_depth=None, criterion= 'mse')\ndtr.fit(x_train,y_train)","e7e01b99":"prediction = dtr.predict(x_test)\nplt.scatter(y_test, prediction, c=\"green\", alpha=0.3)\nplt.xlabel('Measured')\nplt.ylabel('Predicted')\nplt.title('Decision Tree(Hyper) Predicted vs Actual')","d4ea7745":"dtr_train=dtr.score(x_train,y_train)\ndtr_train","dee1f13f":"#Accuracy on Test Data\ndtr_test=dtr.score(x_test,y_test)\ndtr_test","41a059f6":"from sklearn.ensemble import RandomForestRegressor\nrfreg=RandomForestRegressor(n_estimators=10,random_state=0)\nrfreg.fit(x_train,y_train)","7c2ba21b":"prediction = rfreg.predict(x_test)\nplt.scatter(y_test, prediction, c=\"purple\", alpha=0.3)\nplt.xlabel('Measured')\nplt.ylabel('Predicted')\nplt.title('Random Forest Predicted vs Actual')","7869c2e4":"rfreg_train = rfreg.score(x_train,y_train)\nrfreg_train","7bb075ba":"rfreg_test = rfreg.score(x_test,y_test)\nrfreg_test","6939c842":"rh=RandomForestRegressor()","0bbe1911":"par={'n_estimators':np.arange(1,91),'criterion':['mse','mae'],'max_depth':[2,3,4,5,None],\n     'min_samples_leaf':np.arange(1,9),'max_features':['auto','sqrt','log2',None]}","4f32e1c3":"rh_cv=RandomizedSearchCV(rh,par,cv=5,random_state=0)\nrh_cv.fit(x_train,y_train)","eba2a91a":"print(rh_cv.best_score_)\nprint(rh_cv.best_params_)","fe953bca":"reg=RandomForestRegressor(n_estimators= 74, min_samples_leaf= 2, max_features= 'log2', max_depth=None, criterion= 'mse')\nreg.fit(x_train,y_train)","df762d29":"prediction = reg.predict(x_test)\nplt.scatter(y_test, prediction, c=\"purple\", alpha=0.3)\nplt.xlabel('Measured')\nplt.ylabel('Predicted')\nplt.title('Random Forest(Hyper) Predicted vs Actual')","b00b685e":"#Accuracy on Training data\nreg_train=reg.score(x_train,y_train)\nreg_train","567eb75b":"#Accuracy on Training data\nreg_test=reg.score(x_test,y_test)\nreg_test","34241695":"from sklearn.svm import SVR\nsreg = SVR(kernel='linear')\nsreg.fit(x_train, y_train)","1f9ab875":"prediction = sreg.predict(x_test)\nplt.scatter(y_test, prediction, c=\"brown\", alpha=0.3)\nplt.xlabel('Measured')\nplt.ylabel('Predicted')\nplt.title('SVM Predicted vs Actual')","dacee790":"sreg_train = sreg.score(x_train,y_train)\nsreg_train","4fe32782":"sreg_test = sreg.score(x_test,y_test)\nsreg_test","0845629c":"from xgboost import XGBRegressor\nxreg = XGBRegressor()\nxreg.fit(x_train, y_train)","5489f1e2":"plt.scatter(y_test, xreg.predict(x_test),c=\"red\", alpha=0.2)\nplt.xlabel('NOx(GT)(y_test)')\nplt.ylabel('XGBoost Predicted vs Actual')\nplt.show()","7348a1c7":"xreg_train = xreg.score(x_train,y_train)\nxreg_train","498075bd":"xreg_test = xreg.score(x_test,y_test)\nxreg_test","b3e9a254":"booster=['gbtree','gblinear']\nbase_score=[0.25,0.5,0.75,1]","f389dce5":"## Hyper Parameter Optimization\n\nn_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }","d8f0e523":"# Set up the random search with 4-fold cross validation\nfrom sklearn.model_selection import RandomizedSearchCV\nrandom_cv = RandomizedSearchCV(estimator=xreg,\n            param_distributions=hyperparameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_absolute_error',n_jobs = -1,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)","e3028d86":"random_cv.fit(x_train,y_train)","fba04f86":"random_cv.best_estimator_","7011a8b9":"from xgboost import XGBRegressor\nxreg = XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0,\n             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n             max_depth=10, min_child_weight=3, missing=None, n_estimators=100,\n             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n             silent=None, subsample=1, verbosity=1)\nxreg.fit(x_train, y_train)","6b2a2eef":"plt.scatter(y_test, xreg.predict(x_test),c=\"red\", alpha=0.2)\nplt.xlabel('NOx(GT)(y_test)')\nplt.ylabel('HXBoost(Hyper) Predicted vs Actual')\nplt.show()","888c584f":"#Accuracy on Training data\nxreg_train = xreg.score(x_train,y_train)\nxreg_train","f740c9cd":"#Accuracy on Test Data\nxreg_test = xreg.score(x_test,y_test)\nxreg_test","db0a1f79":"results = pd.DataFrame({'Algorithm':['Linear Regression','K-Nearest Neighbour Regressor','Decision Tree Regressor', 'Random Forest Regressor',\n                                     'Support Vector Machine Regressor', 'XGBoost'],\n                        'Train Accuracy':[score_train, knn_train, dtr_train,reg_train, sreg_train,xreg_train],\n                        'Test Accuracy':[score_test, knn_test, dtr_test,reg_test, sreg_test,xreg_test]})\nresults.sort_values('Test Accuracy', ascending=False)","b1c96225":"from sklearn.ensemble import BaggingRegressor","fd5a23cf":"m1=BaggingRegressor(LinearRegression()) #one method\nm1.fit(x_train,y_train)","35cbbb2b":"m2=BaggingRegressor(KNeighborsRegressor(weights='distance', n_neighbors= 12, leaf_size= 18, algorithm= 'brute'))\nm2.fit(x_train,y_train)\n  ","46e45591":"m3=BaggingRegressor(DecisionTreeRegressor(splitter= 'best', min_samples_leaf= 8, max_features= 'auto', max_depth=None, criterion= 'mse')) #one method\nm3.fit(x_train,y_train)\n","1ad33757":"m4=BaggingRegressor(RandomForestRegressor(n_estimators= 74, min_samples_leaf= 2, max_features= 'log2', max_depth=None, criterion= 'mse')) #one method\nm4.fit(x_train,y_train)\n#here low bias and low variance than decision tree algo","87d0a81a":"m5=BaggingRegressor(SVR(kernel='linear')) #one method\nm5.fit(x_train,y_train)\n","d866996d":"m6=BaggingRegressor(XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0,\n             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n             max_depth=10, min_child_weight=3, missing=None, n_estimators=100,\n             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n             silent=None, subsample=1, verbosity=1))\nm6.fit(x_train,y_train)","0371c4fa":"results = pd.DataFrame({'Algorithm':['Linear Regression','K-Nearest Neighbour Regressor','Decision Tree Regressor', 'Random Forest Regressor',\n                                     'Support Vector Machine Regressor', 'XGBoost'],\n                        'Train Accuracy':[m1.score(x_train,y_train), m2.score(x_train,y_train), m3.score(x_train,y_train),\n                                          m4.score(x_train,y_train), m5.score(x_train,y_train), m6.score(x_train,y_train)],\n                        'Test Accuracy':[m1.score(x_test,y_test) , m2.score(x_test,y_test), m3.score(x_test,y_test),\n                                         m4.score(x_test,y_test), m5.score(x_test,y_test), m6.score(x_test,y_test)]})\nresults.sort_values('Test Accuracy', ascending=False)","aff1f472":"Replacing -200 with NaN(null value) as it given in dataset information that Missing values are tagged with -200 value.","e072669d":"Accuracy on Training Data","103ee9b3":" Accuracy on Training Dataset","d112824f":"##**Ensemble Learning**","51216064":"## **Handling Missing Data**","87adc895":"# Nitrogen Oxides(NOx) Level Analysis in Air Quality","6f5eefcd":"###Applying Bagging on every algorithm one ny one.","7689b697":"### **SVM Algorithm**","01ccdd78":"### Model Evaluation","a615e129":"####Prediction Model","bdb2d67b":"Plotting of Nitric oxide:","74a322d7":"####Prediction Model","7a686436":"We can see that initially, the Nitric Oxide levels are low but as the year pass, the Nitric Oxide level is increased.","418ee138":"## **Accuracies(After HyperParameter Tuning)**","4b438b57":"Checking the Information about the dataset by using info()","51aa9885":"##**Conclusions:**","b5fb94b2":"**Histogram:**","2577d9df":"Accuracy on Test Data","30b2e408":"Here, the graph shows an average of Oxides of Nitrogen level with hours. It seems during the day, its level is high compared to night because of high use of transportations, phones, other electronics etc.\n\nThe Environmental Protection Agency (EPA) set a 1-hour NOx standard at the level of 100 parts per billion (ppb). (Ref: https:\/\/www.airnow.gov\/index.cfm?action=pubs.aqiguidenox)\n\nHere, this data shows, air has large amount of NOx compare to its standard measurement which is not good.","4815b7be":" Accuracy on Training Dataset","40057324":"###**Accuracies (After applying Bagging Regressor)**","7db737cb":"Accuracy on Test data\n","d87821da":"XGBoost is good but is little bit bias.","1a0ddb3e":"### **Decision Tree Regressor Algorithm**","d873ca6d":"Checking the Correlation between each attributes.","dca1777d":"From the info() we can see the following things:\n*   There are 17 columns\n*   There are 9471 records\n*   There are:\n> * Number of datetime column: 01\n> * Number of float datatype column(s): 15\n> * Number of object datatype column: 01\n\n\n\n\n\n\n\n","3dba36a0":"### Scaling and Transformation","d734d825":"####Prediction Model","a3b8e5b2":"## **Machine Learning**","bb722634":"####Prediction Model","89435bd0":"**Conclusion:** \n* Gases like CO, NOx, titania, and Benzene are increased in the air over time.\n* The frequency of Oxides in Nitrogen is increasing\n* During the day Nitrogen Oxides' level is high compared to night\n* By looking at above table, we conclude that Random Forest regressor performed best and is not bias as there is not much difference between predicting the training and testing data.","8558f4ed":"### **Random Forest Regressor Algorithm**","fd275cdf":"In the above graph, you can see the frequency of all toxics that is usually in polluted air. The Brown line shows Nitrogen Oxides (NOx) and Yellow line shows NO2 which is part of NOx. It is a mixture of gases are composed of nitrogen and oxygen. Two of the most toxicologically significant compounds are nitric oxide (NO) and nitrogen dioxide (NO2). I chose Nitrogen Oxides(NOx) because these are one of the most dangerous forms of air pollution and are most relevant for air pollution. However, There are many others ways to measure air pollution, including PM10 (particulate matter around between 2.5 and 10 microns in diameter), carbon monoxide, sulfur dioxide, nitrogen dioxide, ozone (O3), etc.\n\nNOx is produced from the reaction of nitrogen and oxygen gases in the air during combustion, especially at high temperatures. In areas of high motor vehicle traffic, such as in large cities, the amount of nitrogen oxides emitted into the atmosphere as air pollution can be significant.\n\nIt is mainly due to fossil fuel combustion from both stationary sources, i.e. power generation (21%), and mobile sources, i.e. transport (44%). Other atmospheric contributions come from non-combustion processes, for example nitric acid manufacture, welding processes and the use of explosives.\n\nIn addition, these create serious health issues. These mainly impact on respiratory conditions causing inflammation of the airways at high levels. Long term exposure can decrease lung function, increase the risk of respiratory conditions and increases the response to allergens. NOx also contributes to the formation of fine particles (PM) and ground level ozone, both of which are associated with adverse health effects.\n\nRef: https:\/\/www.epa.gov\/no2-pollution\/basic-information-about-no2#Effects","d1451e05":"####Prediction Model","2a255047":"Accuracy on Training data\n","e0177914":"## **Data Cleaning**","00424eda":"From above coefficient values, we can say: if 1 unit increases in Benzene (C6H6), NOx increases by 72.62. Same as, if 1 unit increases in Nitrogen Dioxide(NO2) and Relative Humidity(RH), Oxides of Nitrogen will increase by 71 points and 72.9 points, respectively.","da992711":"### **Data Visualization**","ed8089b8":"Accuracy on Test Dataset","814942db":"Checking the missing data in our dataset:","0ffb2bf0":"For this Air quality data analysis, we saw that NOx's ppb are increasing due to the air pollution causing factors as mentioned above and badly affects our health and enviroment. Before it becomes too dangeous for us, There are several intiatives has been tried successfully and some of them are as follow:\n\n* Switching fuel that has reduce low NOx emmision. For instance, No. 2 oil instead of No. 6, distillate oil and natual gas.\n* Recircuclating flue gas which a waste gas produced at the power station and other big installation, with the combustion air supplied to the burners. This process of diluting the combustion air with flue gas, reduces both the oxygen concentration at the burners and the temperature and has reduced NOx emissions by 30 to 60%.\n* Water Injection and Water Emulsion, in which water is added to reduce temperature of the combustion. Water is mixed with fuel at mounted of the cylinder to inject water. This method can reduce NOx by 20-45%\nReferences:\n\nhttps:\/\/www.pollutiononline.com\/doc\/nox-emission-reduction-strategies-0001\nhttps:\/\/www.marineinsight.com\/tech\/10-technologiesmethods-for-controlling-nox-sox-emissions-from-ships\/","d3da0c7f":"####Prediction Model","b0de52b2":"Accuracy on Test data","ae189448":"### Train Test Split","25f5d24d":"###Hyper-parameter Optimization","3444d7a8":"#### filling the null values with median","ae9dcc7d":"####Prediction Model","d5c6fcbe":"If we hold all other varibles constant and 1 point increases in CO(GT), NOx will increase by 49.81. Simillarly, If we hold all other varibles constant and 1 point increases in NO2(GT), NOx will increase by 1.48. and, If we hold all other varibles constant and 1 point increases in C6H6(GT), NOx will increase by 11.94.\n","babad2e7":"KDEPlot of Nitric Oxide:","689bf1f4":"Let's check the trend of Nitrogen gas:","43249074":"### HyperParameter Tuning","1a4e057e":"####Prediction Model","0933334a":" Accuracy on Test Dataset","53bb5fba":"####Prediction Model","1e24c667":"From the histogram, we can observe the variability of each attribute.\nAlso we can observe the skewness of data.","82db0381":"### **K-Nearest Neighbors Algorithm (KNN)**","21008fe1":"According to above graph, the maximum level of Nitric Oxide is spotted between September 2004 to April 2005","df30dad0":"Accuracy on Training data\n","3621a76f":"Residualt Histogram\n","808030be":"Accuracy on Test data\n","479d7738":"### HyperParameter Tuning","995f3518":"From the beginning of 2004 to April 2005, there is much more level of Nitrogen gas.","cb5d5e50":"### **XGBoost Algorithm**","fa7a4c96":"Accuracy on Training data\n","b777954f":" \n* Gases like CO, NOx, titania, and Benzene are increased in the air over time.\n* The frequency of Oxides in Nitrogen is increasing.\n* During the day Nitrogen Oxides' level is high compared to night","478cc8b3":"####Prediction Model","7b2259c2":"**Distplot:**","1adb5690":"### Creating and Training the Model","3fd1663f":"From above we can say that \n* XGBoost Regressor Algorithm is having the best Accuracy(i.e., Prediction) on Test Data which is 0.9240.","28bbffaf":"### Training a **Linear Regression** Model","4f08a80d":"Checking the shape(dimensions) of the dataset.","8d99f1cc":"### HyperParameter Tuning"}}