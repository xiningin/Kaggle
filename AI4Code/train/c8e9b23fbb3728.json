{"cell_type":{"c73ebbbd":"code","eca51d74":"code","d9434b6d":"code","4ccd87c6":"code","6e7db181":"code","670da7ca":"code","273840d4":"code","1b1eb29d":"code","5c917a7b":"code","00cb6902":"code","9878b904":"code","188d2f96":"code","3b1a2ee8":"code","1ae6b3bf":"code","050d0a59":"markdown","11df3276":"markdown","19ce038d":"markdown","3db06a03":"markdown","a9ebdbca":"markdown","d9b55177":"markdown","859c57c4":"markdown"},"source":{"c73ebbbd":"# IMPORT MODULES\nimport sys\nfrom os.path import join\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\n#from tensorflow.python.keras.applications import ResNet50\n\nfrom keras import models, regularizers, layers, optimizers, losses, metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils, to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.applications import ResNet50\n\nimport os\nprint(os.listdir(\"..\/input\"))","eca51d74":"PATH = \"..\/input\/dermmel\/DermMel\/\"\nprint(os.listdir(PATH))","d9434b6d":"# Check content of the dirs\n\nPATHtrain = PATH + 'train_sep\/'\nprint(len(os.listdir(PATHtrain)), \" TRAIN Directories of photos\")\nLabels = os.listdir(PATHtrain)\nsig = 0\nfor label in sorted(Labels):\n    print(label,len(os.listdir(PATHtrain + label +'\/')))\n    sig = sig + len(os.listdir(PATHtrain + label +'\/'))\n\nprint(\"Total TRAIN photos \", sig)\nprint(\"_\"*50)\n\nPATHvalid = PATH + 'valid\/'\nprint(len(os.listdir(PATHvalid)), \" VALID Directories of photos\")\nLabels = os.listdir(PATHvalid)\nsig = 0\nfor label in sorted(Labels):\n    print(label,len(os.listdir(PATHvalid + label +'\/')))\n    sig = sig + len(os.listdir(PATHvalid + label +'\/'))\n\nprint(\"Total Validation photos \", sig)\nprint(\"_\"*50)\n\nPATHtest = PATH + 'test\/'\nprint(len(os.listdir(PATHtest)), \" TEST Directories of photos\")\nLabels = os.listdir(PATHtest)\nsig = 0\nfor label in sorted(Labels):\n    print(label,len(os.listdir(PATHtest + label +'\/')))\n    sig = sig + len(os.listdir(PATHtest + label +'\/'))\n\nprint(\"Total Testing photos \", sig)\nprint(\"_\"*50)","4ccd87c6":"# Check the photos and their labels \n\nTestNum = 8\ndiag = 'Melanoma'\n\nimage_dir = PATHtrain +'\/'+diag+'\/'\nimg_name = os.listdir(image_dir)[TestNum]\nimg_path = image_dir+str(img_name)\nimg = image.load_img(img_path, target_size=(224, 224))\nimgplot = plt.imshow(img)\nprint(\"TRAIN \",diag,\" photo number \", TestNum)\nplt.show()\n\nimage_dir = PATHvalid +'\/'+diag+'\/'\nimg_name = os.listdir(image_dir)[TestNum]\nimg_path = image_dir+str(img_name)\nimg = image.load_img(img_path, target_size=(224, 224))\nimgplot = plt.imshow(img)\nprint(\"VALID \",diag,\" photo number \", TestNum)\nplt.show()\n\nimage_dir = PATHtest +'\/'+diag+'\/'\nimg_name = os.listdir(image_dir)[TestNum]\nimg_path = image_dir+str(img_name)\nimg = image.load_img(img_path, target_size=(224, 224))\nimgplot = plt.imshow(img)\nprint(\"TEST \",diag,\" photo number \", TestNum)\nplt.show()\n","6e7db181":"# Convoluted Base MODEL\n\nconv_base = ResNet50(weights='imagenet',\ninclude_top=False,\ninput_shape=(224, 224, 3))\n\nprint(conv_base.summary())","670da7ca":"# MODEL\n\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(1024, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(2, activation='sigmoid'))\n\nprint(model.summary())","273840d4":"# Make the conv_base NOT trainable:\n\nfor layer in conv_base.layers[:]:\n   layer.trainable = False\n\nprint('conv_base is now NOT trainable')","1b1eb29d":"# Compile frozen conv_base + my top layer\n\nmodel.compile(optimizer=optimizers.Adam(lr=1e-4),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nprint(\"model compiled\")\nprint(model.summary())","5c917a7b":"# Prep the Train Valid and Test directories for the generator\n\ntrain_dir = PATHtrain\nvalidation_dir = PATHvalid\ntest_dir = PATHtest\nbatch_size = 20\ntarget_size=(224, 224)\n\n#train_datagen = ImageDataGenerator(rescale=1.\/255)\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=40,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,target_size=target_size,batch_size=batch_size)\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,target_size=target_size,batch_size=batch_size)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,target_size=target_size,batch_size=batch_size)","00cb6902":"print(train_generator.class_indices)\nprint(validation_generator.class_indices)\nprint(test_generator.class_indices)","9878b904":"# Short training ONLY my top layers \n#... so the conv_base weights will not be destroyed by the random intialization of the new weights\n\nhistory = model.fit_generator(train_generator,\n                              epochs=50,\n                              steps_per_epoch = 10682 \/\/ batch_size,\n                              validation_data = validation_generator,\n                              validation_steps = 3562 \/\/ batch_size)","188d2f96":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","3b1a2ee8":"test_loss, test_acc = model.evaluate_generator(test_generator, steps= 3561 \/\/ batch_size, verbose=1)\nprint('test acc:', test_acc)","1ae6b3bf":"# SAVE or LOAD model (Keras - all batteries included: architecture, weights, optimizer, last status in training, etc.)\n# YOU supply this model.h5 file from previous training session(s) - expected as a data source by Kaggle\n\n# SAVE model\nmodel.save('MelanomaResNetFeatExtract.h5')\nprint(\"MelanomaResNetFeatExtract.h5 was saved\")\n\n# LOAD model\n#del model\n#model = load_model('..\/input\/weather-v9\/modelWeatherV10.h5')\n#print(\"modelWeatherV10.h5 was loaded\")","050d0a59":"# Compile frozen conv_base + UNfrozen top block + my top layer ... SLOW LR\n\nmodel.compile(optimizer=optimizers.Adam(lr=1e-5),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nprint(\"model compiled\")\nprint(model.summary())","11df3276":"# Make last block of the conv_base trainable:\n\nfor layer in conv_base.layers[:143]:\n   layer.trainable = False\nfor layer in conv_base.layers[143:]:\n   layer.trainable = True\n\nprint('Last block of the conv_base is now trainable')","19ce038d":"for i, layer in enumerate(conv_base.layers):\n   print(i, layer.name, layer.trainable)","3db06a03":"Classify pigmented skin lesions dermatoscopic images from HAM10k https:\/\/www.nature.com\/articles\/sdata2018161 into 7 diagnosis\n","a9ebdbca":"It\u2019s necessary to freeze the convolution base of the conv base in order to\nbe able to train a randomly initialized classifier on top. For the same reason, it\u2019s only\npossible to fine-tune the top layers of the convolutional base **once the classifier on top\nhas already been trained**. If the classifier isn\u2019t already trained, then the error signal\npropagating through the network during training will be too large, and the representations\npreviously learned by the layers being fine-tuned will be destroyed\n\n**Below, first train with no limit to lr - with conv_base frozen - only  my top layers**\n\n**Then, unfreeze last model conv block , recompile and train all with LOW lr=1e-5**","d9b55177":"# Long training with fine tuning\n\nhistory = model.fit_generator(train_generator,\n                              epochs=8,\n                              steps_per_epoch = 10682 \/\/ batch_size,\n                              validation_data = validation_generator,\n                              validation_steps = 3562 \/\/ batch_size)","859c57c4":"for i, layer in enumerate(conv_base.layers):\n   print(i, layer.name, layer.trainable)"}}