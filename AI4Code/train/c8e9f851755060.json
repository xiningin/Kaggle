{"cell_type":{"6c47bb79":"code","fbab24c1":"code","dce3b6d2":"code","9e08a97f":"code","3448c663":"code","9d2d5894":"code","508bdee5":"code","b0815f5b":"code","ad8933fe":"code","15d6038b":"code","29d04c42":"code","d24d79da":"code","39ae4144":"code","5d4f7968":"code","df1f3dba":"code","62b1a73c":"code","fbfbb8fb":"code","4a0b83ba":"code","eb8430c2":"code","893504a3":"code","b9baa81e":"code","d303ff0c":"code","bab8bd4c":"markdown","c40f2401":"markdown","0ad236a6":"markdown","82c44870":"markdown","1fdc13eb":"markdown"},"source":{"6c47bb79":"import os\nimport re\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\n\nfrom matplotlib import pyplot as plt\nplt.style.use('fivethirtyeight')\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\nimport spacy\nnlp = spacy.load('en')\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report","fbab24c1":"input_path = '..\/input\/nlp-getting-started\/'\noutput_path = '.\/'","dce3b6d2":"train = pd.read_csv(f'{input_path}\/train.csv')\ntrain.head()","9e08a97f":"test = pd.read_csv(f'{input_path}\/test.csv')\ntest.head()","3448c663":"train.info()","9d2d5894":"test.info()","508bdee5":"def text_preprocessing(text):\n    \n    text = re.sub('[^ A-Za-z]+', '', text)\n    text = text.split()\n    text = [word for word in text if word not in stopwords.words('english')]\n    text = ' '.join(text)\n    text = nlp(text)\n    text = [word.lemma_ for word in text]\n    text = ' '.join(text)\n    \n    return text","b0815f5b":"train['text'] = train['text'].progress_apply(text_preprocessing)","ad8933fe":"test['text'] = test['text'].progress_apply(text_preprocessing)","15d6038b":"train.to_pickle(f'{output_path}\/train.pkl')\ntest.to_pickle(f'{output_path}\/test.pkl')","29d04c42":"train['text'].apply(len).value_counts().plot.bar(rot=0)","d24d79da":"test['text'].apply(len).value_counts().plot.bar(rot=0)","39ae4144":"train = pd.read_pickle(f'{output_path}\/train.pkl')\ntest = pd.read_pickle(f'{output_path}\/test.pkl')","5d4f7968":"tokenizer = TfidfVectorizer()\ntokenizer.fit(train['text'])","df1f3dba":"X = tokenizer.transform(train['text'])\ny = train['target']\n\nX_test = tokenizer.transform(test['text'])\n\nprint('X shape:', X.shape, 'y shape:', y.shape)\nprint('X_test shape:', X_test.shape)","62b1a73c":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=100)\nX_train.shape, y_train.shape, X_val.shape, y_val.shape","fbfbb8fb":"model = RandomForestClassifier()\nmodel.fit(X_train, y_train)","4a0b83ba":"y_pred = model.predict(X_train)\nprint('Training accuracy:', accuracy_score(y_train, y_pred))","eb8430c2":"y_pred = model.predict(X_val)\nprint('Validation accuracy:', accuracy_score(y_val, y_pred))","893504a3":"print('Validation classification report:')\nprint(classification_report(y_val, y_pred))","b9baa81e":"y_pred = model.predict(X_test)\ntest['target'] = y_pred","d303ff0c":"sub = test[['id','target']].copy()\nsub.to_csv(f'{output_path}\/sub.csv', index=False)","bab8bd4c":"## Importing datasets","c40f2401":"## Vectorizing and fitting the model","0ad236a6":"## Making prediction","82c44870":"## Data cleaning","1fdc13eb":"## Importing modules"}}