{"cell_type":{"2039be9a":"code","e0d0fe4f":"code","ad4e1a36":"code","4b402dc5":"code","20a22d81":"code","fbc83690":"code","76c3e62f":"code","1d4af74d":"code","7de7dc0a":"code","2c2760ae":"code","9a759bcb":"code","16868e25":"code","fe86f2f3":"code","83e68f60":"code","a59459ab":"code","dfead045":"code","4e90ea0c":"code","d19760bb":"code","1a663262":"code","12a73508":"code","1c9bcebd":"code","2a812c26":"code","31e73754":"code","0cac1507":"code","67d6fd14":"code","07abdce0":"code","21b360c2":"code","11642896":"code","28bcd31c":"code","07a3dec9":"code","647eeced":"markdown"},"source":{"2039be9a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.neighbors import KNeighborsRegressor\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e0d0fe4f":"# Read both train and test datasets as a DataFrame\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","ad4e1a36":"train.head()","4b402dc5":"# Generate information and statistics about the data\n#train.info()\n#train.describe()\n#test.info()\n#test.describe()","20a22d81":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot(x='Survived', hue='Sex',data= train)","fbc83690":"sns.countplot(x='Survived', hue='Pclass',data= train)","76c3e62f":"# Change all missing Age values to the average Age\ntrain.loc[train['Age'].isnull(), 'Age'] = train['Age'].mean()\ntest.loc[test['Age'].isnull(), 'Age'] = test['Age'].mean()\n#print(train['Age'])","1d4af74d":"# Add a new column to define if an adult\ntrain[\"Adult\"] = 0\ntrain[\"Adult\"][train[\"Age\"] >= 18] = 1\ntest[\"Adult\"] = 0\ntest[\"Adult\"][test[\"Age\"] >= 18] = 1","7de7dc0a":"sns.countplot(x='Survived', hue='Adult',data= train)","2c2760ae":"# Drop the Cabin column because of the missing data\ntrain.drop('Cabin',axis=1,inplace=True)\ntest.drop('Cabin',axis=1,inplace=True)","9a759bcb":"# Drop the two rows with missing values in Embarked\ntrain.dropna(inplace=True)","16868e25":"# Change missing Fare value to the average Fare\ntest.loc[test['Fare'].isnull(), 'Fare'] = test['Fare'].mean()","fe86f2f3":"# Check both train and test datasets are clean\n#train.isnull().sum()\n#test.isnull().sum()","83e68f60":"# Combine  number of siblings \/ spouses aboard the Titanic and number of parents \/ children aboard the Titanic as family\ntrain['Family'] = train['SibSp'] + train['Parch']\ntest['Family'] = test['SibSp'] + test['Parch']","a59459ab":"# Create dummy values for categorical data Embarked and Sex\nembark_train = pd.get_dummies(train['Embarked'],drop_first=True)\nembark_test = pd.get_dummies(test['Embarked'],drop_first=True)\nsex_train = pd.get_dummies(train['Sex'],drop_first=True)\nsex_test = pd.get_dummies(test['Sex'],drop_first=True)","dfead045":"test_passengers = test.PassengerId","4e90ea0c":"# Prepare the train and test data by dropping unwanted column.\ny_train = train.Survived\ntrain.drop(['Sex','Embarked','Name','Ticket','PassengerId','Survived'],axis=1,inplace=True)\ntest.drop(['Sex','Embarked','Name','Ticket','PassengerId'],axis=1,inplace=True)\ntrain = pd.concat([train,sex_train,embark_train],axis=1)\ntest = pd.concat([test,sex_test,embark_test],axis=1)","d19760bb":"train.head()","1a663262":"# KNN classifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import mean_squared_error","12a73508":"# See mse function at the bottom. We pick the columns we want to train for.  \nfeature_remove = ['SibSp','Parch','Q','S','Age','Family','Adult']\nX_train = train.drop(feature_remove, axis=1)\nX_test = test.drop(feature_remove, axis=1)","1c9bcebd":"X_train.head()","2a812c26":"# Scale the data\nscaler = StandardScaler().fit(X_train)\nrescaled_X_train = scaler.transform(X_train)\nrescaled_X_test = scaler.transform(X_test)\n#print(scaler)\n#print(rescaled_X_test)","31e73754":"# Train all the train data\nmodel = KNeighborsClassifier(n_neighbors=5, algorithm='brute')\nmodel.fit(rescaled_X_train, y_train)","0cac1507":"# Make predictions using the KNN model\npredictions = model.predict(rescaled_X_test)","67d6fd14":"# Count how many predicted to survive\nnp.sum(predictions)","07abdce0":"# Output the predictions into a csv\npredictions = pd.DataFrame({'Survived': predictions})\ntest_passengers = pd.DataFrame(test_passengers)\noutput = pd.concat([test_passengers,predictions],axis=1)\n#output = pd.DataFrame({'PassengerId': test_passengers, 'Survived': predictions})\noutput.to_csv('gender_submission.csv', index=False)","21b360c2":"output","11642896":"# Calculate error when using one column. We test for 100 random halves of the train dataset and test on the other half. \n#\u00a0We output a dictionary that contains the average mean squared error for each column.\ndef calculate_mses(feature_list, n):\n    feature_dict = {}\n    for item in feature_list:\n        X_train = pd.DataFrame(train[item])\n        scaler = StandardScaler().fit(X_train)\n        rescaled_X_train = scaler.transform(X_train)\n        mses = list()\n        for i in range(0,n):\n            X_train_2, X_valid, y_train_2, y_valid = train_test_split(rescaled_X_train, y_train, test_size=0.5, random_state=i)\n            # Train the data for the validation\n            model_valid = KNeighborsClassifier(n_neighbors=5, algorithm='brute')\n            model_valid.fit(X_train_2, y_train_2)\n            # Make predictions for validation using the KNN model\n            predictions_valid = model_valid.predict(X_valid)\n            mse = mean_squared_error(y_valid, predictions_valid)\n            mses.append(mse)\n        feature_dict[item] = np.mean(mses)\n    return(feature_dict)","28bcd31c":"feature_list = ['Pclass','Age','SibSp','Parch','Fare','Adult','Family','male','Q','S']\ncalculate_mses(feature_list, n=100)","07a3dec9":"# When we set n=100; Male, Fare and Pclass return the lowest mean squared error so we use these column in the KNN model.","647eeced":"This scored 0.77990."}}