{"cell_type":{"3bd49ca7":"code","3cb1e50b":"code","4ba2d71f":"code","6984725b":"code","51c7d21f":"code","59e885b9":"code","220eedb5":"code","c22ebd68":"code","f0c5e760":"code","b082080b":"code","d1833bae":"code","15ebd5c9":"code","eadb9ca9":"code","65a83471":"code","15c7ce73":"code","119a696b":"code","2e4ff44f":"code","30d39247":"code","ef69996a":"code","07646726":"code","e8ec2692":"markdown","ba6f9a0d":"markdown","9388a1b6":"markdown"},"source":{"3bd49ca7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3cb1e50b":"%matplotlib inline\nimport torchvision\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader,Dataset\nimport matplotlib.pyplot as plt\nimport torchvision.utils\nimport numpy as np\nimport random\nfrom PIL import Image\nimport torch\nfrom torch.autograd import Variable\nimport PIL.ImageOps    \nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F","4ba2d71f":"def imshow(img,text=None,should_save=False):\n    npimg = img.numpy()\n    plt.axis(\"off\")\n    if text:\n        plt.text(75, 8, text, style='italic',fontweight='bold',\n            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()    \n\ndef show_plot(iteration,loss):\n    plt.plot(iteration,loss)\n    plt.show()","6984725b":"!git clone https:\/\/github.com\/harveyslash\/Facial-Similarity-with-Siamese-Networks-in-Pytorch","51c7d21f":"!find -name \"*pgm\" | xargs -I {} convert {} {}.png","59e885b9":"!ls \/kaggle\/working\/Facial-Similarity-with-Siamese-Networks-in-Pytorch\/data\/faces","220eedb5":"class Config():\n    training_dir = \"\/kaggle\/working\/Facial-Similarity-with-Siamese-Networks-in-Pytorch\/data\/faces\/training\/\"\n    testing_dir = \"\/kaggle\/working\/Facial-Similarity-with-Siamese-Networks-in-Pytorch\/data\/faces\/testing\/\"\n    train_batch_size = 64\n    train_number_epochs = 100","c22ebd68":"class SiameseNetworkDataset(Dataset):\n    \n    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n        self.imageFolderDataset = imageFolderDataset    \n        self.transform = transform\n        self.should_invert = should_invert\n        \n    def __getitem__(self,index):\n        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n        #we need to make sure approx 50% of images are in the same class\n        should_get_same_class = random.randint(0,1) \n        if should_get_same_class:\n            while True:\n                #keep looping till the same class image is found\n                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n                if img0_tuple[1]==img1_tuple[1]:\n                    break\n        else:\n            img1_tuple = random.choice(self.imageFolderDataset.imgs)\n\n        img0 = Image.open(img0_tuple[0])\n        img1 = Image.open(img1_tuple[0])\n        img0 = img0.convert(\"L\")\n        img1 = img1.convert(\"L\")\n        \n        if self.should_invert:\n            img0 = PIL.ImageOps.invert(img0)\n            img1 = PIL.ImageOps.invert(img1)\n\n        if self.transform is not None:\n            img0 = self.transform(img0)\n            img1 = self.transform(img1)\n        \n        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n    \n    def __len__(self):\n        return len(self.imageFolderDataset.imgs)","f0c5e760":"folder_dataset = dset.ImageFolder(root=Config.training_dir)","b082080b":"class SiameseNetworkDataset(Dataset):\n    \n    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n        self.imageFolderDataset = imageFolderDataset    \n        self.transform = transform\n        self.should_invert = should_invert\n        \n    def __getitem__(self,index):\n        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n        #we need to make sure approx 50% of images are in the same class\n        should_get_same_class = random.randint(0,1) \n        if should_get_same_class:\n            while True:\n                #keep looping till the same class image is found\n                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n                if img0_tuple[1]==img1_tuple[1]:\n                    break\n        else:\n            while True:\n                #keep looping till a different class image is found\n                \n                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n                if img0_tuple[1] !=img1_tuple[1]:\n                    break\n\n        img0 = Image.open(img0_tuple[0])\n        img1 = Image.open(img1_tuple[0])\n        img0 = img0.convert(\"L\")\n        img1 = img1.convert(\"L\")\n        \n        if self.should_invert:\n            img0 = PIL.ImageOps.invert(img0)\n            img1 = PIL.ImageOps.invert(img1)\n\n        if self.transform is not None:\n            img0 = self.transform(img0)\n            img1 = self.transform(img1)\n        \n        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n    \n    def __len__(self):\n        return len(self.imageFolderDataset.imgs)","d1833bae":"folder_dataset = dset.ImageFolder(root=Config.training_dir)","15ebd5c9":"siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n                                        transform=transforms.Compose([transforms.Resize((100,100)),\n                                                                      transforms.ToTensor()\n                                                                      ])\n                                       ,should_invert=False)","eadb9ca9":"vis_dataloader = DataLoader(siamese_dataset,\n                        shuffle=True,\n                        num_workers=8,\n                        batch_size=8)\ndataiter = iter(vis_dataloader)\n\n\nexample_batch = next(dataiter)\nconcatenated = torch.cat((example_batch[0],example_batch[1]),0)\nimshow(torchvision.utils.make_grid(concatenated))\nprint(example_batch[2].numpy())","65a83471":"class SiameseNetwork(nn.Module):\n    def __init__(self):\n        super(SiameseNetwork, self).__init__()\n        self.cnn1 = nn.Sequential(\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(1, 4, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(4),\n            \n            nn.ReflectionPad2d(1),\n            nn.Conv2d(4, 8, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(8),\n\n\n            nn.ReflectionPad2d(1),\n            nn.Conv2d(8, 8, kernel_size=3),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(8),\n\n\n        )\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(8*100*100, 500),\n            nn.ReLU(inplace=True),\n\n            nn.Linear(500, 500),\n            nn.ReLU(inplace=True),\n\n            nn.Linear(500, 5))\n\n    def forward_once(self, x):\n        output = self.cnn1(x)\n        output = output.view(output.size()[0], -1)\n        output = self.fc1(output)\n        return output\n\n    def forward(self, input1, input2):\n        output1 = self.forward_once(input1)\n        output2 = self.forward_once(input2)\n        return output1, output2","15c7ce73":"class ContrastiveLoss(torch.nn.Module):\n    \"\"\"\n    Contrastive loss function.\n    Based on: http:\/\/yann.lecun.com\/exdb\/publis\/pdf\/hadsell-chopra-lecun-06.pdf\n    \"\"\"\n\n    def __init__(self, margin=2.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, output1, output2, label):\n        euclidean_distance = F.pairwise_distance(output1, output2)\n        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n\n\n        return loss_contrastive","119a696b":"train_dataloader = DataLoader(siamese_dataset,\n                        shuffle=True,\n                        num_workers=0,\n                        batch_size=Config.train_batch_size)\n","2e4ff44f":"net = SiameseNetwork().cuda()\ncriterion = ContrastiveLoss()\noptimizer = optim.Adam(net.parameters(),lr = 0.0005 )","30d39247":"counter = []\nloss_history = [] \niteration_number= 0","ef69996a":"for epoch in range(0,Config.train_number_epochs):\n    for i, data in enumerate(train_dataloader,0):\n        img0, img1 , label = data\n        img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n        optimizer.zero_grad()\n        output1,output2 = net(img0,img1)\n        loss_contrastive = criterion(output1,output2,label)\n        loss_contrastive.backward()\n        optimizer.step()\n        if i %10 == 0 :\n            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n            iteration_number +=10\n            counter.append(iteration_number)\n            loss_history.append(loss_contrastive.item())\nshow_plot(counter,loss_history)","07646726":"!rm -rf \/kaggle\/working\/Facial-Similarity-with-Siamese-Networks-in-Pytorch\/","e8ec2692":"https:\/\/github.com\/harveyslash\/Facial-Similarity-with-Siamese-Networks-in-Pytorch","ba6f9a0d":"https:\/\/hackernoon.com\/facial-similarity-with-siamese-networks-in-pytorch-9642aa9db2f7","9388a1b6":"http:\/\/www.cl.cam.ac.uk\/Research\/DTG\/attarchive\/pub\/data\/att_faces.zip"}}