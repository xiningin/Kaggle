{"cell_type":{"aa412aa1":"code","69b65864":"code","aca25dd7":"code","4669e39c":"code","7d13a29f":"code","cb12bdb0":"code","f042b8e3":"code","9210dcf8":"code","f9832356":"code","81806eac":"code","ed573492":"code","a758ee9e":"code","d4162ed0":"code","4eaa5942":"code","a33d5b36":"code","3b8ab488":"code","622794ca":"code","967837ba":"code","06f568cb":"code","4176058a":"code","e04cc078":"code","6a2f4301":"code","fa192f7e":"code","7e451a75":"code","a2016280":"code","63a4d1e2":"code","7550f33b":"code","69942b36":"code","88d3e66a":"code","a9e3332e":"code","2320de39":"code","3bba6d86":"code","4f3f7e8c":"code","7ea2d9b5":"code","45b06c63":"markdown","2ce8f1c3":"markdown","8452c256":"markdown","29d4a5d9":"markdown","3cc55389":"markdown","c9b7eee5":"markdown","2d205238":"markdown","0e792da9":"markdown","d0164190":"markdown","aa253765":"markdown","efab1f41":"markdown","85cc9d97":"markdown","46f6450a":"markdown","a7603918":"markdown","55070f5f":"markdown","eff0093e":"markdown","9c2c5f19":"markdown","2ea7b726":"markdown","4fd86679":"markdown","c8908810":"markdown","e21e5b0c":"markdown","53ac29ec":"markdown","22d60008":"markdown"},"source":{"aa412aa1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","69b65864":"df = pd.read_csv('..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')\ndf.head()","aca25dd7":"print(df.shape)","4669e39c":"df.describe()","7d13a29f":"df.info()","cb12bdb0":"print(\"The missing values \", df.isnull().sum())","f042b8e3":"df['stroke'].value_counts().plot(kind='bar')","9210dcf8":"print(\"Percentage of patient had a stroke {} %\".format(df['stroke'].value_counts()[1]\/len(df) * 100))\nprint(\"Percentage of patient did not had a stroke {} %\".format(df['stroke'].value_counts()[0]\/len(df) * 100))","f9832356":"# histogram of all variables\ndf.hist(figsize=(15,15))\nplt.show()","81806eac":"# correlation to target variable\nsns.heatmap(df.corr())","ed573492":"sns.pairplot(df, hue='stroke')\n","a758ee9e":"# replace missing value with NAN value\n\ndf['bmi'].fillna(df['bmi'].mean(), inplace=True)","d4162ed0":"df.isnull().sum()","4eaa5942":"categorical = ['gender', 'hypertension', 'heart_disease', 'ever_married',\n'work_type', 'Residence_type', 'smoking_status']\n\nnumerical = ['age','avg_glucose_level', 'bmi']","a33d5b36":"df[numerical].describe()","3b8ab488":"df[numerical].skew()","622794ca":"sns.catplot(x=\"hypertension\", y=\"stroke\", hue='smoking_status', kind=\"bar\", data=df)","967837ba":"sns.catplot(x=\"heart_disease\", y=\"stroke\", hue='smoking_status', kind=\"bar\", data=df)","06f568cb":"sns.catplot(hue=\"smoking_status\", y=\"stroke\", x='gender', kind=\"bar\", data=df)","4176058a":"from sklearn.preprocessing import LabelEncoder\nenc=LabelEncoder()","e04cc078":"gender=enc.fit_transform(df['gender'])\nsmoking_status=enc.fit_transform(df['smoking_status'])\nwork_type=enc.fit_transform(df['work_type'])\nResidence_type=enc.fit_transform(df['Residence_type'])\never_married=enc.fit_transform(df['ever_married'])","6a2f4301":"df['ever_married']=ever_married\ndf['Residence_type']=Residence_type\ndf['smoking_status']=smoking_status\ndf['gender']=gender\ndf['work_type']=work_type","fa192f7e":"df[['ever_married', 'Residence_type', 'smoking_status', 'gender', 'work_type']].head()","7e451a75":"df.info()","a2016280":"y = df['stroke']\nX = df.drop(['id', 'stroke'], axis=1)","63a4d1e2":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","7550f33b":"from imblearn.over_sampling import SMOTE\n\nprint(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n\nsm = SMOTE(random_state=41)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n","69942b36":"from sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import accuracy_score, classification_report","88d3e66a":"import numpy as np\nrdf_model = RandomForestClassifier()\nrdf_model.fit(X_train_res, y_train_res)\nprint('Training Score: {}'.format(rdf_model.score(X_train_res, y_train_res)))\nprint('Test Score: {}'.format(rdf_model.score(X_test, y_test)))","a9e3332e":"xgb_model = XGBClassifier()\nxgb_model.fit(X_train_res, y_train_res)\nprint('Training Score: {}'.format(xgb_model.score(X_train_res, y_train_res)))\n\nprint('Test Score: {}'.format(xgb_model.score(X_test, y_test)))","2320de39":"from sklearn.linear_model import LogisticRegression\nlg = LogisticRegression(solver='liblinear')\nlg.fit(X_train_res, y_train_res)\nprint('Training Score: {}'.format(lg.score(X_train_res, y_train_res)))\n\nprint('Test Score: {}'.format(lg.score(X_test, y_test)))","3bba6d86":"from sklearn.svm import SVC\nmodel_svm = SVC()\nmodel_svm.fit(X_train_res, y_train_res)\nprint('Training Score: {}'.format(model_svm.score(X_train_res, y_train_res)))\n\nprint('Test Score: {}'.format(model_svm.score(X_test, y_test)))","4f3f7e8c":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'C' : [0.1 , 1 , 10 , 100 , 1000],\n    'gamma' : [1 , 0.1 , 0.01 , 0.001 , 0.0001],\n    'kernel' : ['rbf']\n}\n\ngrid = GridSearchCV(SVC() , param_grid , refit = True , verbose = 3)\n\ngrid.fit(X_train_res, y_train_res)\ngrid.best_params_","7ea2d9b5":"from sklearn.svm import SVC\nmodel_svm = SVC(C=10 , gamma = 0.1 , kernel = 'rbf')\nmodel_svm.fit(X_train_res, y_train_res)\nprint('Training Score: {}'.format(model_svm.score(X_train_res, y_train_res)))\n\nprint('Test Score: {}'.format(model_svm.score(X_test, y_test)))","45b06c63":"#### Logistic regression","2ce8f1c3":"### Label Encoder\n","8452c256":"The following are the columns :\nID, gender, age, hypertension, heart_disease, ever_married, work_type, Residence_type, avg_glucose_level, bmi, smoking_status, stroke('target variable')","29d4a5d9":"#### XG Boost","3cc55389":"### Numerical vs categorical","c9b7eee5":"categorical\n","2d205238":"### Importing Libraries","0e792da9":"### Modelling","d0164190":"From the above, we can infer that avg_glucose_level is rightly skewed. Age and bmi and slightly skewed to left and right respectively","aa253765":"Context\nAccording to the World Health Organization (WHO) stroke is the 2nd leading cause of death globally, responsible for approximately 11% of total deaths.\nThis dataset is used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient.\n\nAttribute Information\n1) id: unique identifier\n2) gender: \"Male\", \"Female\" or \"Other\"\n3) age: age of the patient\n4) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n5) heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n6) ever_married: \"No\" or \"Yes\"\n7) work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n8) Residence_type: \"Rural\" or \"Urban\"\n9) avg_glucose_level: average glucose level in blood\n10) bmi: body mass index\n11) smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n12) stroke: 1 if the patient had a stroke or 0 if not\n*Note: \"Unknown\" in smoking_status means that the information is unavailable for this patient","efab1f41":"Total of 5110 rows and 12 features including target variable.","85cc9d97":"From this dataset, we can infer that this dataset is an example of class imbalanced one. ","46f6450a":"### split the dataset","a7603918":"#### SVM","55070f5f":"### EDA","eff0093e":"Lets look at the distribution of target variable. out of 5112 instances, 249 have been striked with stroke.","9c2c5f19":"Some features are int\/float type. Some are categorical columns(gender, ever_married, work_type, Residence_type, smoking_status). We will convert to numerical types for modelling.\nThe column 'bmi' shows some missing data.","2ea7b726":"Best value we got from grid search is \nC : 10\ngamma : 0.1\nkernel : rbf","4fd86679":"#### RandomForest Classifier","c8908810":"The problem of missing values has been solved","e21e5b0c":"To conclude, we have seen the accuracies from various algroithms. Least performing algorithm for this dataset is logistic regression while XGBoost, random forest and SVC performs well.","53ac29ec":"### Handling Missing data\n\nBefore the data goes to modelling, we need to handle the missing value. Here the feature column 'bmi' has missing values.","22d60008":"### Approach to class-imbalance dataset"}}