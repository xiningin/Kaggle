{"cell_type":{"f3e1272c":"code","a0794459":"code","8d3c531f":"code","9dc19402":"code","718733bd":"code","f6e9cec0":"code","231e55af":"code","1fdec197":"code","ed8e9e9e":"code","37ff4cb0":"code","d9e398ec":"code","d3030378":"code","a38bb10f":"code","e3b73420":"code","60182731":"code","d08e9edf":"code","aaf58b0d":"code","ca196c40":"code","22197a6a":"code","45381dd8":"code","b6aad2e2":"code","6c76d7fb":"code","9f037c80":"code","7a1d885c":"code","21d9ea8e":"code","08e380d9":"code","9b3fe524":"code","9eae726b":"code","c9990ed9":"code","92aade75":"code","c97dfbf9":"code","5bbf6b36":"code","4db04273":"code","49f65bfb":"code","bc8f76ca":"code","cf9bc7e9":"code","897e933c":"code","280b241c":"code","efecc770":"code","05fb349a":"code","0822ecf4":"code","1c30f14a":"code","64721036":"code","ae27647d":"code","cc4d32bf":"code","545f4b7a":"code","8d4208a2":"code","0d5d6489":"code","bf79a9d3":"code","8235fc9b":"code","74cc3200":"code","297cfd9e":"code","0f8ac670":"code","eaea7402":"code","23037354":"code","296cf0c5":"code","7ef0f434":"code","b8b362f4":"markdown","f3ff0efa":"markdown","fc813629":"markdown","5efe34e5":"markdown","6e5c6ff8":"markdown","ae83f50e":"markdown","4ec6572c":"markdown","940a5ba5":"markdown","46cc0b63":"markdown","c334e2e7":"markdown","129ab3df":"markdown","c43ecff4":"markdown","25e9e10f":"markdown","cfaadad8":"markdown","51f9f59a":"markdown","8c74009d":"markdown","7bc0060f":"markdown","9fe202fe":"markdown","c9dc149c":"markdown","75067a44":"markdown","aa03c8cc":"markdown","d1ff5477":"markdown","dcd547b1":"markdown","cf128e1f":"markdown","15ffcaa3":"markdown","e21ccd77":"markdown","f34fe060":"markdown","4d0df794":"markdown","ffadd05c":"markdown","8600f3f1":"markdown","660650c6":"markdown","7f891720":"markdown","7f014ec1":"markdown","f5edb338":"markdown","ca0b199b":"markdown"},"source":{"f3e1272c":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns","a0794459":"# ImportError: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support \n# Use pip or conda to install xlrd.\n\n# !pip install xlrd\n\n# ValueError: Your version of xlrd is 2.0.1. In xlrd >= 2.0, only the xls format is supported. \n# Install openpyxl instead.\n\n!pip install openpyxl","8d3c531f":"# Loading the dataset\ndataset_path = '..\/input\/customer-survey-on-age-reversing-medicine\/data.xlsx'\ndf = pd.read_excel(dataset_path, index_col=0)\ndf.head()","9dc19402":"# Refactoring the column names\ndef refactor_column_names(df, inplace=False):\n    first_headers = df.columns.tolist()\n\n    # There are actually two headers, the 1st header is the actual header\n    # and the 2nd header is in the 1st row.\n    second_headers = df.iloc[0].tolist()\n\n    final_headers = []\n    for idx, header in enumerate(first_headers):\n        if ('Unnamed' in header):\n            final_headers.append(second_headers[idx])\n        else:\n            final_headers.append(header)\n\n    # changing the name of the header with the final headers\n    headers = {\n        header: final_headers[index]\n        for index, header in enumerate(first_headers)\n    }\n    return df.rename(columns=headers, inplace=inplace)\n\n\nrefactor_column_names(df, True)","718733bd":"# Chaning the index\ndf['Index'] = [i for i in range(len(df))]\ndf.set_index('Index', inplace=True)\n\n# Removing the 1st row\ndf.drop([0], inplace=True)","f6e9cec0":"# Dropping unnecessary columns\nunnecessary_columns = [\n    'Collector ID',\n    'Start Date',\n    'End Date',\n    'IP Address',\n    'Email Address',\n    'First Name',\n    'Last Name',\n    'Custom Data 1',\n    'collector_type_source',\n    'custom_value8',\n    'custom_value9',\n    'custom_value7'\n]\ndf.drop(unnecessary_columns, axis='columns', inplace=True)","231e55af":"df_columns = df.columns.tolist()\nprint(len(df_columns))","1fdec197":"def refactor_column_0(df, col_name):\n    column = df[col_name].tolist()\n    for idx, value in enumerate(column):\n        if type(value) != int:\n            df[col_name].iloc[idx] = int(value.split(' ')[0])\n        else:\n            df[col_name].iloc[idx] = value\n\n\nrefactor_column_0(df, df_columns[0])","ed8e9e9e":"def refactor_column_1(df, col_name):\n    return refactor_column_0(df, col_name)\n\n\nrefactor_column_1(df, df_columns[1])","37ff4cb0":"def refactor_column_2(df, col_name):\n    column = df[col_name].tolist()\n    for idx, value in enumerate(column):\n        amount = [string for string in value.split(' ') if '$' in string][0]\n        amount = ''.join(amount.split('$'))\n        if ('\/' in amount):\n            amount = ''.join(amount.split('\/')[0])\n        df[col_name].iloc[idx] = int(amount)\n\n\nrefactor_column_2(df, df_columns[2])","d9e398ec":"def refactor_column_3(df, col_name):\n    return refactor_column_0(df, col_name)\n\n\nrefactor_column_3(df, df_columns[3])","d3030378":"df.rename(columns={df_columns[4]: 'Beauty - General'}, inplace=True)\ndf_columns = df.columns.tolist()  # updating column list\n\n\ndef refactor_column_4(df, col_name):\n    column = df[col_name].tolist()\n    for idx, value in enumerate(column):\n        if type(value) == float:\n            df[col_name].iloc[idx] = 0\n        else:\n            df[col_name].iloc[idx] = 1\n\n\nrefactor_column_4(df, df_columns[4])","a38bb10f":"BINARY_COLUMNS = [\n    'Beauty',\n    'Books',\n    'Design',\n    'Family',\n    'Fitness',\n    'Games',\n    'Health',\n    'News',\n    'Nutrition',\n    'Politics',\n    'Science',\n    'Social',\n    'Sports',\n    'Technology',\n    'Travel'\n]\n\nfor header in df_columns:\n    if header.split(' ')[0] in BINARY_COLUMNS:\n        refactor_column_4(df, header)","e3b73420":"col_name = 'Other (please specify)'\nprint(df[col_name].unique())\nprint(df[col_name].value_counts())\n\n# Since the \"Other (please specify)\" column has very few values and those\n# values are unique therefore dropping the column\ndf.drop([col_name], axis='columns', inplace=True)\ndf_columns = df.columns.tolist()  # updating columns list","60182731":"col_name = 'Would you like to learn about ways to increase your lifespan and healthspan?'\nprint(list(df[col_name].unique()))\n\n\ndef _refactor(df, col_name):\n    column = df[col_name].tolist()\n    for idx, value in enumerate(column):\n        if 'Yes' in value:\n            df[col_name].iloc[idx] = 1\n        else:\n            df[col_name].iloc[idx] = 0\n\n\n_refactor(df, col_name)","d08e9edf":"def refactor_household_column(df):\n    col_name = 'Household Income'\n    # print(df[col_name].unique())\n\n    new_values = {\n        'Prefer not to answer': -1,\n        '$0-$9,999': 1,\n        '$10,000-$24,999': 2,\n        '$25,000-$49,999': 3,\n        '$50,000-$74,999': 4,\n        '$75,000-$99,999': 5,\n        '$100,000-$124,999': 6,\n        '$125,000-$149,999': 7,\n        '$150,000-$174,999': 8,\n        '$175,000-$199,999': 9,\n        '$200,000+': 10\n    }\n    df[col_name] = df[col_name].apply(lambda x: new_values[x])\n\n\nrefactor_household_column(df)","aaf58b0d":"def refactor_region_column(df):\n    col_name = 'Region'\n    # print(df[col_name].unique())\n\n    new_values = {\n        'Pacific': 1,\n        'Mountain': 2,\n        'Middle Atlantic': 3,\n        'West North Central': 4,\n        'South Atlantic': 5,\n        'East North Central': 6,\n        'West South Central': 7,\n        'New England': 8,\n        'East South Central': 9\n    }\n\n    for idx, value in enumerate(df[col_name]):\n        if type(value) == str:\n            df[col_name].iloc[idx] = new_values[value]\n        else:\n            df[col_name].iloc[idx] = -1\n\n\nrefactor_region_column(df)","ca196c40":"REGIONS = {\n    'Pacific': 1,\n    'Mountain': 2,\n    'Middle Atlantic': 3,\n    'West North Central': 4,\n    'South Atlantic': 5,\n    'East North Central': 6,\n    'West South Central': 7,\n    'New England': 8,\n    'East South Central': 9\n}","22197a6a":"def df_count_plot(df, col_name):\n    fig_dims = (16, 6)\n    _, ax = plt.subplots(figsize=fig_dims)\n    sns.countplot(x=col_name, data=df, ax=ax)","45381dd8":"# people who believe that in future science is capable\nfuture_believe = 'One day, advances in science and medicine will stop or reverse the human aging process.'\n\n# people who believe that today science is capable\ntoday_believe = 'I believe vitamins, supplements, or medications available today can slow, stop or reverse the aging process.'\n\n# people who are willing to buy the porduct if it's avilable today\nwillingness_to_buy_today = 'If it were available today, the most I would spend on a supplement that slows, stops, or reverses my aging:'\n\n# people who want to buy first\nwant_to_try_first = 'I tend to be among the first of my friends to try new products, services, technologies, etc.'\n\n# people who want to learn\nwant_to_learn = 'Would you like to learn about ways to increase your lifespan and healthspan?'","b6aad2e2":"def get_corr(df):\n    f_series = pd.Series(df[future_believe].values.tolist())\n    t_series = pd.Series(df[today_believe].values.tolist())\n    willingess_series = pd.Series(df[willingness_to_buy_today].values.tolist())\n    _try_first_series = pd.Series(df[want_to_try_first].values.tolist())\n    learn_series = pd.Series(df[want_to_learn].values.tolist())\n    gender_df = pd.get_dummies(df['Gender'])\n    region_df = pd.get_dummies(df['Region'])\n    age_df = pd.get_dummies(df['Age'])\n    household_income_series = pd.Series(df['Household Income'].values.tolist())\n    \n    series_df = pd.DataFrame({\n        'Future believe': f_series,\n        'Today\\'s believe': t_series,\n        'Willingness to buy': willingess_series,\n        'Try first': _try_first_series,\n        'Want to learn': learn_series\n    })\n    df_corr = pd.concat([gender_df, region_df, age_df, series_df], axis=1).corr()\n    plt.figure(figsize=(22, 16))\n    sns.heatmap(df_corr, annot=True, cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True))\n    \n    \nget_corr(df)","6c76d7fb":"def get_percent(of, total):\n    return round(of \/ total, 2) * 100","9f037c80":"num_of_people = len(df)\n\nnum_of_male = len(df[df['Gender'] == 'Male'])\nnum_of_female = len(df[df['Gender'] == 'Female'])","7a1d885c":"print(df[future_believe].mean()) # 1 - 10","21d9ea8e":"print(df[today_believe].mean()) # 1 - 10","08e380d9":"print(f'On average people are ready to spend ${round(df[willingness_to_buy_today].mean(), 2)} if the product is available today') # $","9b3fe524":"print(df[want_to_try_first].mean()) # 1 - 10","9eae726b":"# how many people want to learn of this product\/science\nwant_to = df[df[want_to_learn] == 1][want_to_learn].count()\n# print(want_to)\n\n# people who don't want to\ndont_want_to = df[df[want_to_learn] == 0][want_to_learn].count()\n# print(dont_want_to)\n\nprint(f'Percentage of who want to learn: {get_percent(want_to, num_of_people)}%')\nsns.countplot(x=want_to_learn, data=df)","c9990ed9":"print(df[df['Household Income'] > 0]['Household Income'].mean()) # $42499.3","92aade75":"sns.countplot(x='Household Income', data=df)","c97dfbf9":"print(df['Gender'].value_counts())\nsns.countplot(x='Gender', data=df)","5bbf6b36":"# male\nmale = len(df[(df[future_believe] > 5) & (df['Gender'] == 'Male')])\nprint(f'{round(get_percent(male, num_of_male), 2)}% of male believe in future of the product')\n\n# female\nfemale = len(df[(df[future_believe] > 5) & (df['Gender'] == 'Female')])\nprint(f'{get_percent(female, num_of_female)}% of female believe in future of the product')","4db04273":"# male\nmale = len(df[(df[today_believe] > 5) & (df['Gender'] == 'Male')])\nprint(f'{get_percent(male, num_of_male)}% of male believe that the technology\/product is available today')\n\n# female\nfemale = len(df[(df[today_believe] > 5) & (df['Gender'] == 'Female')])\nprint(f'{get_percent(female, num_of_female)}% of female believe that the technology\/product is available today')","49f65bfb":"# male\nmale_amount = df[df['Gender'] == 'Male'][willingness_to_buy_today].mean()\nprint(f'Male will spend ${male_amount} if the product is available today')\n\n# female\nfemale_amount = df[df['Gender'] == 'Female'][willingness_to_buy_today].mean()\nprint(f'Female will spend ${round(female_amount, 2)} if the product is available today')","bc8f76ca":"# male\nmale = len(df[(df[want_to_try_first] > 5) & (df['Gender'] == 'Male')])\nprint(f'{get_percent(male, num_of_male)}% of male want\\' to try the product first')\n\n# female\nfemale = len(df[(df[want_to_try_first] > 5) & (df['Gender'] == 'Female')])\nprint(f'{get_percent(female, num_of_female)}% of female want\\' to try the product first')","cf9bc7e9":"# male\nmale = len(df[(df[want_to_learn] == 1) & (df['Gender'] == 'Male')])\nprint(f'{get_percent(male, num_of_male)}% of males want to learn about the science\/product')\n\n# female\nfemale = len(df[(df[want_to_learn] == 1) & (df['Gender'] == 'Female')])\nprint(f'{get_percent(female, num_of_female)}% of females want to learn about the science\/product')","897e933c":"# male\nmale_amount = df[df['Gender'] == 'Male']['Household Income'].mean()\nprint(round(male_amount, 2))\n\n# female\nfemale_amount = df[df['Gender'] == 'Female']['Household Income'].mean()\nprint(round(female_amount, 2))\n\nprint()\n\nprint(f'$37,499.5 is the average household income of male')\nprint(f'$23,499.1 is the average household income of female')","280b241c":"# future\nincome_range = df[df[future_believe] > 5]['Household Income'].mean()\nprint(income_range) # $32,499.7","efecc770":"# today\nincome_range = df[df[today_believe] > 5]['Household Income'].mean()\nprint(income_range) # $23,499.1","05fb349a":"higger_income_grp = df['Household Income'] > 5\nspending = df[higger_income_grp][willingness_to_buy_today].mean()\nprint(f'Higher income group is ready to spend ${round(spending, 2)}')\n\nlower_income_grp = df['Household Income'] <= 5\nno_ans = df['Household Income'] != -1  # didn't disclosed their income\nspending = df[lower_income_grp & no_ans][willingness_to_buy_today].mean()\nprint(f'Lower income group is ready to spend ${round(spending, 2)}')","0822ecf4":"unique_regions = df.Region.unique().tolist()\nunique_regions.remove(-1)  # removing nan values\n\ndef value2key(dictonary, value):\n    for key, val in dictonary.items():\n        if value == val:\n            return key","1c30f14a":"regions = []\nf_believe_list = []\nt_believe_list = []\n_try_list = []\nspending_list = []\nlearn_list = []\n\nfor region in unique_regions:\n    spending = df[df.Region == region][willingness_to_buy_today].mean()\n    f_believe = df[df.Region == region][future_believe].mean()\n    t_believe = df[df.Region == region][today_believe].mean()\n    _try = df[df.Region == region][want_to_try_first].mean()\n\n    learn = df[df.Region == region][want_to_learn].value_counts()\n    learn_0, learn_1 = learn[0], learn[1]\n\n    f_str = f'future believe: {round(f_believe, 1)}'\n    t_str = f'today believe: {round(t_believe, 2)}'\n    tr_str = f'want to try: {round(_try, 2)}'\n    l_str = f'want to learn: {round(learn_1 \/ (learn_1 + learn_0) * 100, 2)}%'\n    spending_str = f'spending: ${round(spending, 2)}'\n    \n    regions.append(value2key(REGIONS, region))\n    f_believe_list.append(round(f_believe, 1))\n    t_believe_list.append(round(t_believe, 1))\n    _try_list.append(round(_try, 1))\n    learn_list.append(round(learn_1 \/ (learn_1 + learn_0) * 100, 2))\n    spending_list.append(round(spending, 2))\n\n    print(\n        f'''\n        *** {value2key(REGIONS, region)} ***\n        {f_str} \n        {t_str} \n        {tr_str} \n        {l_str} \n        {spending_str}\n\n        '''\n    )","64721036":"def plot_barh_sorted_range(_x, _y, x_label, y_label):\n    x = []\n    y = []\n\n    # remove nan\n    for idx, val in enumerate(_x):\n        if str(val) != 'nan':\n            x.append(_x[idx])\n            y.append(_y[idx])\n    \n    sorted_pairs = sorted(zip(x, y))\n    tuples = zip(*sorted_pairs)\n    x, y = [ list(tuple) for tuple in  tuples]\n    plt.barh(y, x, color='#65b87b', alpha=.7)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)","ae27647d":"plot_barh_sorted_range(f_believe_list, regions, 'Average rating of future believe', 'Regions')","cc4d32bf":"plot_barh_sorted_range(t_believe_list, regions, 'Average rating of today\\'s believe', 'Regions')","545f4b7a":"plot_barh_sorted_range(_try_list, regions, 'Average rating of people who want to try', 'Regions')","8d4208a2":"plot_barh_sorted_range(learn_list, regions, 'Percentage of people who want to learn', 'Regions')","0d5d6489":"plot_barh_sorted_range(spending_list, regions, 'Average amount($) people are ready to spend', 'Regions')","bf79a9d3":"df_columns = df.columns.tolist()\n\nBINARY_COLUMNS = [\n    'Beauty - General',\n    'Beauty - Fashion',\n    'Beauty - Makeup',\n    'Beauty - Skincare',\n    'Books - General',\n    'Books - Non-fiction',\n    'Books - Fiction',\n    'Design - General',\n    'Design - Architecture',\n    'Design - Graphic',\n    'Design - Interior',\n    'Family - General',\n    'Fitness - General',\n    'Fitness - Aerobics',\n    'Fitness - Biking',\n    'Fitness - Crossfit & Interval Training',\n    'Games - General',\n    'Games - Dungeons and Dragons',\n    'Games - Fortnite',\n    'Games - Minecraft',\n    'Games - MMORPGs',\n    'Health - General',\n    'Health - Meditation and Mindfulness',\n    'Health - Sauna & Steamrooms',\n    'Health - Sleep',\n    'News - General',\n    'News - Newspapers',\n    'News - Journals',\n    'News - Social media',\n    'News - Cable',\n    'Nutrition - General',\n    'Nutrition - Fasting',\n    'Nutrition - Mediterranean diets',\n    'Nutrition - Ketogenic & Gluten Free diets',\n    'Politics - General',\n    'Politics - Conservative',\n    'Politics - Liberal',\n    'Science - General',\n    'Science - Longevity research',\n    'Social media - General',\n    'Social media - Facebook',\n    'Social media - Instagram',\n    'Social media - Twitter',\n    'Social media - Tik Tok',\n    'Social media - WhatsApp',\n    'Sports - General',\n    'Sports - Backpacking',\n    'Sports - Hunting',\n    'Sports - Fly fishing',\n    'Sports - Marathons, triathlons, distance races, etc.',\n    'Sports - Motocross, snowmobiles, ATVs',\n    'Sports - NFL',\n    'Sports - Yoga',\n    'Technology - General',\n    'Technology - 3D printing',\n    'Technology - Artificial Intelligence',\n    'Technology - Programming',\n    'Technology - Quantified Self',\n    'Technology - Robotics',\n    'Technology - Smart Home, IoT, etc',\n    'Technology - Wearables',\n    'Travel - General',\n    'Travel - Road trips',\n]\n\nlen(BINARY_COLUMNS)","8235fc9b":"headers = []\nf_believe_list = []\nt_believe_list = []\n_try_list = []\nspending_list = []\nlearn_list = []\nreponse_percentage_list = []\n\nfor i in [1, 0]:\n    for h in BINARY_COLUMNS:  # h == header\n        spending = df[df[h] == i][willingness_to_buy_today].mean()\n        f_believe = df[df[h] == i][future_believe].mean()\n        t_believe = df[df[h] == i][today_believe].mean()\n        _try = df[df[h] == i][want_to_try_first].mean()\n\n        learn = df[df[h] == i][want_to_learn].value_counts()\n        try:\n            learn_0, learn_1 = learn[0], learn[1]\n        except:\n            try:\n                learn_0 = learn[0]\n            except:\n                learn_0 = 0\n                try:\n                    learn_1 = learn[1]\n                except:\n                    learn_1 = 0\n\n        # reponse percent\n        rp_per = round(len(df[df[h] == i]) \/ len(df[h]) * 100, 2)\n        rp_per_str = f'reponse percent: {rp_per}%'\n\n        f_str = f'future believe: {round(f_believe, 2)}'\n        t_str = f'today believe: {round(t_believe, 2)}'\n        tr_str = f'want to try: {round(_try, 2)}'\n\n        if (learn_0 != 0 and learn_1 != 0):\n            _learn = round(learn_1 \/ (learn_1 + learn_0) * 100, 2)\n            l_str = f'want to learn: {_learn}%'\n        else:\n            _learn = 0\n            l_str = f'want to learn: {_learn}%'\n\n        spending_str = f'spending: {round(spending, 2)}'\n        \n        headers.append(f'{i} - {h}')\n        reponse_percentage_list.append(rp_per)\n        f_believe_list.append(round(f_believe, 2))\n        t_believe_list.append(round(t_believe, 2))\n        _try_list.append(round(_try, 2))\n        spending_list.append(round(spending, 2))\n        learn_list.append(_learn)\n        \n#         print(\n#             f'''\n#             *** {i} - {h} ***\n#             {rp_per_str}\n#             {f_str} \n#             {t_str} \n#             {tr_str} \n#             {l_str} \n#             {spending_str}\n\n#             '''\n#         )","74cc3200":"def plot_barh_sorted_range_with_slice(_x, _y, _slice, x_label, y_label):\n    x = []\n    y = []\n    # remove nan\n    for idx, val in enumerate(_x):\n        if str(val) != 'nan':\n            x.append(_x[idx])\n            y.append(_y[idx])\n    \n    print(f'**** Top {_slice} ****')\n    sorted_pairs = sorted(zip(x, y))\n    tuples = zip(*sorted_pairs)\n    x, y = [ list(tuple) for tuple in  tuples]\n    \n    plt.barh(y[-_slice:], x[-_slice:], color='#706dbd', alpha=.7)\n    plt.xlabel(x_label)\n    plt.ylabel(y_label)","297cfd9e":"TOP = 10","0f8ac670":"plot_barh_sorted_range_with_slice(f_believe_list, headers, TOP, 'Average rating of future believe', 'Response type - Category')","eaea7402":"plot_barh_sorted_range_with_slice(t_believe_list, headers, TOP, 'Average rating of today\\'s believe', 'Response type - Category')","23037354":"plot_barh_sorted_range_with_slice(_try_list, headers, TOP, 'Average rating of people who want to try', 'Response type - Category')","296cf0c5":"plot_barh_sorted_range_with_slice(spending_list, headers, TOP, 'Average amount($) people are ready to spend', 'Response type - Category')","7ef0f434":"plot_barh_sorted_range_with_slice(learn_list, headers, TOP, 'Percentage of people who want to learn', 'Response type - Category')","b8b362f4":"# Customer survey on age reversing medicine EDA\n\nThe company `veva.co` sells a brand of supplements that support healthy ageing and longevity.\n\nThis kernel is an in depth analysis of `206 response SurveyMonkey` which are provided by the company to identify the attributes of consumers who are most likely to buy their products, so that we can design an efficient marketing strategy, targeting the right channels, interest groups and demographies with a compelling message that delivers high return on marketing investment.\n\nYou can read a `report` on the `findings` on my [GitHub](https:\/\/github.com\/AkashSDas\/customer-survey-on-age-reversing-medicine-eda) account and the `dataset` is available on [Kaggle](https:\/\/www.kaggle.com\/akashsdas\/customer-survey-on-age-reversing-medicine).\n\n![](https:\/\/media.giphy.com\/media\/GrUhLU9q3nyRG\/giphy.gif)","f3ff0efa":"`avg of how much people believe in product's future`","fc813629":"`Total number of people`","5efe34e5":"**Variable for long column headers**","6e5c6ff8":"`Gender wise who will spend more`","ae83f50e":"`avg of how much people want to try first`","4ec6572c":"`Gender wise avg Household Income`","940a5ba5":"`Gender wise today believe`","46cc0b63":"### Question related to the gender column","c334e2e7":"`Column: Household Income`","129ab3df":"`Column: I believe vitamins, supplements, or medications available today can slow, stop or reverse the ageing process`.","c43ecff4":"`Gender wise future believe`","25e9e10f":"`Column: 'Would you like to learn about ways to increase your lifespan and healthspan?'`","cfaadad8":"`Column: Region`","51f9f59a":"`Column: One day, advances in science and medicine will stop or reverse the human ageing process`.","8c74009d":"`Column: Other (please specify)`","7bc0060f":"`Gender wise who want to learn`","9fe202fe":"`Gender wise who want's to try first`","c9dc149c":"`avg of how much people believe that product is available today`","75067a44":"## \ud83c\udf99 Exploratory Data Analysis\n\nLet's explore the data.\n\n![](https:\/\/media.giphy.com\/media\/1SvsA7ypPi78fH2ZvG\/giphy.gif)","aa03c8cc":"`what is the avg household income`","d1ff5477":"`avg of how much people are ready to spend if the product is available today`","dcd547b1":"`Column: I am interested in the following`. This columns name should be `Beauty - General`.","cf128e1f":"`Column: If it were available today, the most I would spend on a supplement that slows, stops, or reverses my ageing`.","15ffcaa3":"## \ud83e\ude82 Data preparation","e21ccd77":"`number of male and female in the suvery`","f34fe060":"---\n\nI'll wrap things up there. If you want to find some other answers then go ahead `edit` this kernel. If you have any `questions` then do let me know.\n\nIf this kernel helped you then don't forget to \ud83d\udd3c `upvote` and share your \ud83c\udf99 `feedback` on improvements of the kernel.\n\n![](https:\/\/media.giphy.com\/media\/l1J3CbFgn5o7DGRuE\/giphy.gif)\n\n---","4d0df794":"`willingness to buy (how much an income grp is ready to spend)`","ffadd05c":"### Question related to remaining fields (columns)","8600f3f1":"### \u2753 Finding answers to questions\n\n![](https:\/\/media.giphy.com\/media\/Mfvjabj51UiQM\/giphy.gif)","660650c6":"### Cleaning column values","7f891720":"### Question related to household income column\n\n`Which income range is more interested in the product?`","7f014ec1":"### Question related to region column","f5edb338":"`Column: I tend to be among the first of my friends to try new products, services, technologies, etc`.","ca0b199b":"Since the remaining column from the below list also have same problem we can use the `refactor_column_4` function for all of them."}}