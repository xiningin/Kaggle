{"cell_type":{"8d39cc4a":"code","c025e9de":"code","a035d2af":"code","e6215762":"code","7620deed":"code","3dc28115":"code","dd32715a":"code","aa3a7546":"code","a26aaaa9":"code","28dfc453":"code","f3e0de49":"code","d4004ac0":"code","585e4391":"code","b2ca59bb":"code","0e50b29e":"code","dc31bd11":"code","99a4c693":"code","b1bae125":"code","5dcc8ec8":"code","f8889f20":"code","d3146ff9":"code","7b8df8f6":"code","6f48e304":"markdown","f6d0b339":"markdown","2b9c4b97":"markdown","2c4d729b":"markdown","92d66ce1":"markdown","5424c0f3":"markdown"},"source":{"8d39cc4a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow\nimport os\nimport tqdm\nimport skimage.io\nimport glob\n\nfrom tqdm import tqdm\n\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\n\nfrom sklearn.utils import shuffle\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import InputLayer, Conv2D, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n# Instantiating the model for loading the weights and biases and preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n\n%matplotlib inline","c025e9de":"# Reading Data\n\ntrain_dataset_0_all = glob.glob('..\/input\/leukemia-classification\/C-NMC_Leukemia\/training_data\/fold_0\/all\/*.bmp')\ntrain_dataset_0_hem = glob.glob('..\/input\/leukemia-classification\/C-NMC_Leukemia\/training_data\/fold_0\/hem\/*.bmp')\ntrain_dataset_1_all = glob.glob('..\/input\/leukemia-classification\/C-NMC_Leukemia\/training_data\/fold_1\/all\/*.bmp')\ntrain_dataset_1_hem = glob.glob('..\/input\/leukemia-classification\/C-NMC_Leukemia\/training_data\/fold_1\/hem\/*.bmp')\ntrain_dataset_2_all = glob.glob('..\/input\/leukemia-classification\/C-NMC_Leukemia\/training_data\/fold_2\/all\/*.bmp')\ntrain_dataset_2_hem = glob.glob('..\/input\/leukemia-classification\/C-NMC_Leukemia\/training_data\/fold_2\/hem\/*.bmp')\n\n#test_dataset  = glob.glob('..\/input\/leukemia-classification\/C-NMC_Leukemia\/testing_data\/C-NMC_test_final_phase_data\/*.bmp')\n#valid_dataset = glob.glob('..\/input\/leukemia-classification\/C-NMC_Leukemia\/validation_data\/C-NMC_test_prelim_phase_data\/*.bmp')\n\nvalid_data    = pd.read_csv('..\/input\/leukemia-classification\/C-NMC_Leukemia\/validation_data\/C-NMC_test_prelim_phase_data_labels.csv')","a035d2af":"A = []\nH = []\n\nA.extend(train_dataset_0_all)\nA.extend(train_dataset_1_all)\nA.extend(train_dataset_2_all)\n\nH.extend(train_dataset_0_hem)\nH.extend(train_dataset_1_hem)\nH.extend(train_dataset_2_hem)\n\nA = np.array(A)\nH = np.array(H)\n\nlen(A),len(H)","e6215762":"Image = []\nLabel = []\n\nfor i in tqdm(range(0, len(A))):\n    img = imread(A[i])\n    img = resize(img, (128,128))\n    Image.append(img)\n    Label.append(1)\n    \nfor i in tqdm(range(0, len(H))):\n    img = imread(H[i])\n    img = resize(img, (128,128))\n    Image.append(img)\n    Label.append(0)\n    \nImage = np.array(Image)\nLabel = np.array(Label)\n\nImage.shape, Label.shape","7620deed":"# Shuffle the data as results are appened.\n\nImage, Label = shuffle(Image, Label, random_state = 42)","3dc28115":"# Viewing Image - After Shuffle \n\nfig, ax = plt.subplots(nrows = 1, ncols = 5, figsize = (20,20))\n\nfor i in tqdm(range(0, 5)):\n    rand = np.random.randint(len(Image))\n    ax[i].imshow(Image[rand])\n    ax[i].axis('off')\n    a = Label[rand]\n    if a == 1:\n        ax[i].set_title('Diseased')\n    else:\n        ax[i].set_title('Non_Diseased')","dd32715a":"# Assigning Images and Label to new variable \n\nX = Image\ny = Label","aa3a7546":"del Image\ndel Label\ndel A\ndel H","a26aaaa9":"valid_data.head()","28dfc453":"# Loading image and storing it numpy array.\n\nX_val = []\n\nfor image_name in valid_data.new_names:\n    # Loading images\n    img = imread('..\/input\/leukemia-classification\/C-NMC_Leukemia\/validation_data\/C-NMC_test_prelim_phase_data\/' + image_name)\n    # Resizing \n    img = resize(img, (128,128))\n    # Appending them into list\n    X_val.append(img)\n \n# Converting into array\nX_val = np.array(X_val)\n\n# Storing target values as well \ny_val = valid_data.labels.values","f3e0de49":"# Augmentation & Applying preprocessing function of pre-trained model.\n\ntrain_datagen  = ImageDataGenerator(horizontal_flip=True,\n                                    vertical_flip=True,\n                                    zoom_range = 0.2,\n                                    preprocessing_function=preprocess_input)\ntrain_datagen.fit(X)","d4004ac0":"valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\nvalid_datagen.fit(X_val)","585e4391":"# Creating model with pre trained imagenet weights\n\nincep_v3 = InceptionV3(include_top=False, weights='imagenet', input_shape=(128,128,3))","b2ca59bb":"# Model Summary \n\nincep_v3.summary()","0e50b29e":"# We dont want to train all layers so, we do following step because we are using same weights given in VGG16\n\nfor layers in incep_v3.layers:\n    layers.trainable = False","dc31bd11":"# Introducing Flatten Layer\n\nx = Flatten()(incep_v3.output)","99a4c693":"# Introducing FCC & Output Layer\n\nfcc_layer_1 = Dense(units = 1024, activation = 'relu')(x)\ndropout_1   = Dropout(0.3)(fcc_layer_1)\n\nfcc_layer_2 = Dense(units = 512, activation = 'relu')(dropout_1)\ndropout_2   = Dropout(0.3)(fcc_layer_2)\n\nfinal_layer = Dense(units = 1, activation = 'sigmoid')(dropout_2)","b1bae125":"# Creating Final Model\n\nmodel = Model(inputs = incep_v3.input, outputs = final_layer)","5dcc8ec8":"# Model summary \n\nmodel.summary()","f8889f20":"# Model Compile \n\nmodel.compile(optimizer = 'adam', \n              loss = 'binary_crossentropy',\n              metrics = ['accuracy'])","d3146ff9":"# Defining Callbacks\n\nfilepath = '.\/best_weights.hdf5'\n\nearlystopping = EarlyStopping(monitor = 'val_accuracy', \n                              mode = 'max' , \n                              patience = 15,\n                              verbose = 1)\n\ncheckpoint    = ModelCheckpoint(filepath, \n                                monitor = 'val_accuracy', \n                                mode='max', \n                                save_best_only=True, \n                                verbose = 1)\n\nlearning_rate = ReduceLROnPlateau(monitor = 'val_accuracy',\n                                  mode = 'max',\n                                  patience = 5,\n                                  factor = 0.3,\n                                  min_delta = 0.00001)\n\n\ncallback_list = [earlystopping, checkpoint, learning_rate]","7b8df8f6":"# Fitting Model\n\nmodel_history = model.fit(train_datagen.flow(X, y, batch_size=512), \n                          validation_data = (X_val, y_val),\n                          epochs = 500,\n                          verbose = 1,\n                          callbacks = callback_list)","6f48e304":"### MODEL BUILDING","f6d0b339":"**`VALIDATION DATA PREPROCESSING`**","2b9c4b97":"**`TRAIN DATA PREPROCESSING`**","2c4d729b":"### IMPORT LIBRARIES","92d66ce1":"**`DATA AUGMENTATION`**","5424c0f3":"### IMPORT \/ VIEWING \/ PREPROCESSING DATASET"}}