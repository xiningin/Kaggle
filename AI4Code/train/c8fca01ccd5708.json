{"cell_type":{"26e216f9":"code","4b474846":"code","5afb55d3":"code","3dc5c2f4":"code","8f21ad4f":"code","ae17930e":"code","0d9d8053":"code","885ad64f":"code","e5562e70":"code","685acd4d":"code","735f45c0":"code","3af8c39d":"code","7a796637":"code","59700bd9":"code","aa8191ba":"code","b04dee57":"code","a2927981":"code","0807211b":"code","0763e361":"code","a2e386c9":"code","befba0e4":"code","814fc440":"code","19dbab46":"code","478e0f7c":"code","663efa96":"code","680f00dc":"code","8d4af2de":"code","849776f4":"code","3f87f152":"code","b0c166aa":"markdown","75584f98":"markdown","78166626":"markdown","2caa4737":"markdown","52c56324":"markdown","d3f01c8a":"markdown","aca3dc96":"markdown","b82b7d76":"markdown","fff2cb1a":"markdown","9746912d":"markdown","02127063":"markdown","ddcb6f59":"markdown","487eeef5":"markdown","ed671239":"markdown"},"source":{"26e216f9":"# !pip install pandas==1.1.3\n# !pip install numpy==1.18.5\n# !pip install holidays==0.10.3\n# !pip install fbprophet==0.7.1\n# !pip install matplotlib==3.2.1\n# !pip install ipython==7.13.0\n!pip -qq install pmdarima==1.7.1","4b474846":"import holidays\nimport numpy as np\nimport pandas as pd\nfrom fbprophet import Prophet\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nfrom pmdarima.arima import auto_arima\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_rows', 500)","5afb55d3":"df = pd.read_csv('..\/input\/bitgrit-3\/train_3.csv').drop(columns='Unnamed: 0')\n\ndf['send_timestamp'] = df.send_timestamp.apply(pd.to_datetime)\ndf['date'] = df.send_timestamp.apply(lambda x: x.date())\ndf_train = df.groupby(['shipping_company', 'date']).gross_weight.sum().reset_index().sort_values(by=['shipping_company', 'date']).copy()\ndf_train.to_csv('train_task_3.csv', index=False)\ndf = pd.read_csv('train_task_3.csv')\ndf['ds'] = df.date.apply(pd.to_datetime)\n\n## Give zero value to the missing dates\nmin_date = df.ds.min()\nmax_date = df.ds.max()\n\nidx = pd.date_range(min_date, max_date)\n\ndf1 = df[df.shipping_company=='SC1'].set_index('ds', drop=True).reindex(idx).fillna(0).reset_index().copy() ## time-series shiiping company 1\ndf2 = df[df.shipping_company=='SC2'].set_index('ds', drop=True).reindex(idx).fillna(0).reset_index().copy() ## time-series shiiping company 2\ndf3 = df[df.shipping_company=='SC3'].set_index('ds', drop=True).reindex(idx).fillna(0).reset_index().copy() ## time-series shiiping company 3","3dc5c2f4":"val1 = pd.DataFrame()\nval1['ds'] = pd.date_range('2020-06-14', '2020-08-13')\nval1['SC'] = 1\nval2 = pd.DataFrame()\nval2['ds'] = pd.date_range('2020-06-14', '2020-08-13')\nval2['SC'] = 2\nval3 = pd.DataFrame()\nval3['ds'] = pd.date_range('2020-06-14', '2020-08-13')\nval3['SC'] = 3","8f21ad4f":"uk_holidays = set(holidays.UnitedKingdom(years = [2019,2020]).keys())\n\ndef seasonalities(dd):\n    train = 'ds' not in dd.columns\n    if train:\n        dd['ds'] = dd['index']\n        dd['y'] = dd.gross_weight\n    dd['dow'] = dd.ds.apply(lambda x: x.dayofweek) ## day of week\n    dd['dom'] = dd.ds.apply(lambda x: x.day)       ## day of month\n    dd['weekend'] = dd.dow.isin([5,6])*1.0         ## is weekend\n    dd['wom'] = (dd.dom-1)\/\/7                      ## week of month\n    dd['holiday'] = dd.ds.isin(uk_holidays)        ## is a UK holiday\n    dd['year'] = dd.ds.apply(lambda x: x.year)     ## year\n    dd['month'] = dd.ds.apply(lambda x: x.month)   ## month\n    dd['week'] = dd.ds.apply(lambda x: x.week)     ## week of the year\n    dd['half'] = (dd.dom-1)\/\/15                    ## first half or second half of the month\n    \n    return dd","ae17930e":"df1 = seasonalities(df1).dropna()\ndf2 = seasonalities(df2).dropna()\ndf3 = seasonalities(df3).dropna()","0d9d8053":"val1 = seasonalities(val1).dropna()\nval2 = seasonalities(val2).dropna()\nval3 = seasonalities(val3).dropna()","885ad64f":"## mean of item count in first half and second half values\n\nh1 = df1.groupby(['year', 'half' , 'month']).y.mean().reset_index()\nh1['ds'] = h1.apply(lambda x: pd.to_datetime(str(int(x.year))+'-'+str(int(x.month))+'-'+str(int(x.half*15+1))), axis=1)\nh2 = df2.groupby(['year', 'half' , 'month']).y.mean().reset_index()\nh2['ds'] = h2.apply(lambda x: pd.to_datetime(str(int(x.year))+'-'+str(int(x.month))+'-'+str(int(x.half*15+1))), axis=1)\nh3 = df3.groupby(['year', 'half' , 'month']).y.mean().reset_index()\nh3['ds'] = h3.apply(lambda x: pd.to_datetime(str(int(x.year))+'-'+str(int(x.month))+'-'+str(int(x.half*15+1))), axis=1)","e5562e70":"vh1 = val1.groupby(['year', 'half' , 'month']).dow.count().reset_index().drop(columns='dow')\nvh1['ds'] = vh1.apply(lambda x: pd.to_datetime(str(int(x.year))+'-'+str(int(x.month))+'-'+str(int(x.half*15+1))), axis=1)\nvh2 = val2.groupby(['year', 'half' , 'month']).dow.count().reset_index().drop(columns='dow')\nvh2['ds'] = vh2.apply(lambda x: pd.to_datetime(str(int(x.year))+'-'+str(int(x.month))+'-'+str(int(x.half*15+1))), axis=1)\nvh3 = val3.groupby(['year', 'half' , 'month']).dow.count().reset_index().drop(columns='dow')\nvh3['ds'] = vh3.apply(lambda x: pd.to_datetime(str(int(x.year))+'-'+str(int(x.month))+'-'+str(int(x.half*15+1))), axis=1)","685acd4d":"def model0(features,m='prophet', ys=True, ws=True):\n    pred = []\n    date = []\n    sc = []\n\n    a = 0\n    for train0, val0 in zip([h1, h2, h3], [vh1, vh2, vh3]):\n        train = train0.copy()\n        val = val0.copy()\n        \n        if m=='prophet':\n            model = Prophet(yearly_seasonality=ys, weekly_seasonality=ws)\n            for feat in features:\n                model.add_regressor(feat)\n            model.fit(train)\n            pred += list(model.predict(val)['yhat'].apply(lambda x: int(max(x,0))).values)\n            \n        if m=='arima':\n            model = auto_arima(y=train.y, exogenous=train[features])\n            pred += list(pd.DataFrame({'yhat':model.predict(n_periods=len(val), exogenous=val[features])}).yhat.apply(lambda x: int(max(x,0))).values)\n    \n        date += list(val.ds.values)\n        a += 1\n        sc += [a]*len(val)\n\n    h_ = pd.DataFrame()\n    h_['pred'] = pred\n    h_['date'] = date\n    h_['SC'] = sc\n    h_ = h_.sort_values(by=['date', 'SC']).reset_index(drop=True)\n    return h_.pred.values, h_.date.values, h_.SC.values","735f45c0":"h = pd.DataFrame()\nh['pred_prophet1'], h['date'], h['SC'] = model0([\"month\"], 'prophet', False, False)\nh['pred_prophet2'], _, _ = model0([\"month\"], 'prophet', True, False)\nh['pred_prophet3'], _, _ = model0([], 'prophet', True, False)\nh['pred_arima1'], _, _ = model0([\"month\"], 'arima')","3af8c39d":"def d_15_pred(x):\n    if x.SC==1:\n        return x.pred_prophet1 * (12.13) + x.pred_prophet2 * (-4.25) + x.pred_prophet3 * (4.39) + x.pred_arima1 * (-2.02) - 23465.62\n    if x.SC==2:\n        return x.pred_prophet1 * (-30.67) + x.pred_prophet2 * (187.91) + x.pred_prophet3 * (-189.3) + x.pred_arima1 * (-81.7) + 224565.88\n    if x.SC==3:\n        return x.pred_prophet1 * (3.07) + x.pred_prophet2 * (-5.91) + x.pred_prophet3 * (5.53) + x.pred_arima1 * (0.94) - 5079.54","7a796637":"h['pred'] = h.apply(d_15_pred, axis=1)","59700bd9":"## Total in week\n\ndef seasonalities2(dd):\n    dd['dom'] = dd.ds.apply(lambda x: x.day)\n    dd['wom'] = (dd.dom-1)\/\/7\n    dd['year'] = dd.ds.apply(lambda x: x.year)\n    dd['month'] = dd.ds.apply(lambda x: x.month)\n    return dd\n\nw1 = df1.groupby(['year', 'week']).y.sum().reset_index()\nw1['ds'] = pd.to_datetime(w1.week.astype(str)+w1.year.astype(str).add('-1') ,format='%V%G-%u')\nw2 = df2.groupby(['year', 'week']).y.sum().reset_index()\nw2['ds'] = pd.to_datetime(w2.week.astype(str)+w2.year.astype(str).add('-1') ,format='%V%G-%u')\nw3 = df3.groupby(['year', 'week']).y.sum().reset_index()\nw3['ds'] = pd.to_datetime(w3.week.astype(str)+w3.year.astype(str).add('-1') ,format='%V%G-%u')","aa8191ba":"vw1 = val1.groupby(['year', 'week']).dow.count().reset_index().drop(columns='dow')\nvw1['ds'] = pd.to_datetime(vw1.week.astype(str)+vw1.year.astype(str).add('-1') ,format='%V%G-%u')\nvw2 = val2.groupby(['year', 'week']).dow.count().reset_index().drop(columns='dow')\nvw2['ds'] = pd.to_datetime(vw2.week.astype(str)+vw2.year.astype(str).add('-1') ,format='%V%G-%u')\nvw3 = val3.groupby(['year', 'week']).dow.count().reset_index().drop(columns='dow')\nvw3['ds'] = pd.to_datetime(vw3.week.astype(str)+vw3.year.astype(str).add('-1') ,format='%V%G-%u')","b04dee57":"w1, w2, w3, vw1, vw2, vw3 = seasonalities2(w1), seasonalities2(w2), seasonalities2(w3), seasonalities2(vw1), seasonalities2(vw2), seasonalities2(vw3)","a2927981":"def model1(features,m='prophet', ys=True, ws=True):\n    pred = []\n    date = []\n    sc = []\n    a = 0\n    for c,(train0, val0) in enumerate(zip([w1, w2, w3], [vw1, vw2, vw3])):\n        c = c+1\n        train = train0.copy()\n        val = val0.copy()\n        if m=='prophet':\n            model = Prophet(yearly_seasonality=ys, weekly_seasonality=ws)\n            for feat in features:\n                model.add_regressor(feat)\n            model.fit(train)\n            pred += list(model.predict(val)['yhat'].apply(lambda x: int(max(x,0))).values)\n        if m=='arima':\n            if len(features)!=0:\n                model = auto_arima(y=train.y, exogenous=train[features])\n                pred += list(pd.DataFrame({'yhat':model.predict(n_periods=len(val), exogenous=val[features])}).yhat.apply(lambda x: int(max(x,0))).values)\n            if len(features)==0:\n                model = auto_arima(y=train.y)\n                pred += list(pd.DataFrame({'yhat':model.predict(n_periods=len(val))}).yhat.apply(lambda x: int(max(x,0))).values)\n        date += list(val.ds.values)\n        a += 1\n        sc += [a]*len(val)\n    \n    w_ = pd.DataFrame()\n    w_['pred'] = pred\n    w_['date'] = date\n    w_['SC'] = sc\n    w_ = w_.sort_values(by=['date', 'SC']).reset_index(drop=True)\n    \n    return w_.pred.values, w_.date.values, w_.SC.values","0807211b":"def model2(features, ys=True, ws=True):\n    pred = []\n    date = []\n    sc = []\n    a = 0\n    for train0, val0 in zip([w1, w2, w3], [vw1, vw2, vw3]):\n        a += 1\n        for i in train0.wom.unique():\n            train = train0[train0.wom==i].copy()\n            val = val0[val0.wom==i].copy()\n            model = Prophet(yearly_seasonality=ys, weekly_seasonality=ws)\n            for feat in features:\n                model.add_regressor(feat)\n            model.fit(train)\n            pred += list(model.predict(val)['yhat'].apply(lambda x: int(max(x,0))).values)\n            date += list(val.ds.values)\n            sc += [a]*len(val)\n    w_ = pd.DataFrame()\n    w_['pred'] = pred\n    w_['date'] = date\n    w_['SC'] = sc\n    w_ = w_.sort_values(by=['date', 'SC']).reset_index(drop=True)\n    \n    return w_.pred.values, w_.date.values, w_.SC.values","0763e361":"w = pd.DataFrame()\nw['pred_prophet1'], w['date'], w['SC'] = model1([\"wom\"], 'prophet', False, False)\nw['pred_prophet2'], _, _ = model2([\"wom\"], False, False)\nw['pred_prophet3'], _, _ = model2([], False, False)\nw['pred_prophet4'], _, _ = model1([], 'prophet', False, False)\nw['pred_arima1'], _, _ = model1([\"wom\", \"month\"], 'arima')\nw['pred_arima2'], _, _ = model1([], 'arima')\nw['pred_arima3'], _, _ = model1([\"wom\"], 'arima')\nw['pred_arima4'], _, _ = model1([\"wom\", 'year'], 'arima')\nw['pred_arima5'], _, _ = model1([\"wom\", 'year', 'dom'], 'arima')","a2e386c9":"def fn(x):\n    if x.SC==1:\n        return x.pred_prophet1*273.63 + x.pred_prophet2*1311.94 - x.pred_prophet3*1309.30 + x.pred_prophet4*1137.62 + x.pred_arima1*5739.43 - x.pred_arima2*60.37 - x.pred_arima3*6724.46 + x.pred_arima4*3.24 - x.pred_arima5*92.90\n    if x.SC==2:\n        return x.pred_prophet1*(-5119.51) + x.pred_prophet2*601.77 - x.pred_prophet3*601.20 - x.pred_prophet4*2004.40 - x.pred_arima1*36372.53 + x.pred_arima2*7050.28 + x.pred_arima3*19196.13 + x.pred_arima4*16081.06 + x.pred_arima5*61.61\n    if x.SC==3:\n        return x.pred_prophet1*2906.93 + x.pred_prophet2*954.23 - x.pred_prophet3*947.57 - x.pred_prophet4*3708.00 - x.pred_arima1*1296.13 + x.pred_arima2*10149.87 - x.pred_arima3*7698.93 - x.pred_arima4*26.20 + x.pred_arima5*48.53\n\nw['pred'] = w.apply(fn, axis=1)","befba0e4":"h['year'] = h.date.apply(lambda x: pd.to_datetime(x).year)\nh['month'] = h.date.apply(lambda x: pd.to_datetime(x).month)\nh['half'] = h.date.apply(lambda x: (pd.to_datetime(x).day-1)\/\/15)\n\nh1['avg_15'] = h1.y\nh2['avg_15'] = h2.y\nh3['avg_15'] = h3.y\n\ndf1 = df1.merge(h1[['year', 'month', 'half', 'avg_15']], on=['year', 'month', 'half'], how='left').dropna()\ndf2 = df2.merge(h2[['year', 'month', 'half', 'avg_15']], on=['year', 'month', 'half'], how='left').dropna()\ndf3 = df3.merge(h3[['year', 'month', 'half', 'avg_15']], on=['year', 'month', 'half'], how='left').dropna()\n\nh['avg_15'] = h.pred\n\nval1 = val1.merge(h[['SC', 'year', 'month', 'half', 'avg_15']], on=['SC', 'year', 'month', 'half'])\nval2 = val2.merge(h[['SC', 'year', 'month', 'half', 'avg_15']], on=['SC', 'year', 'month', 'half'])\nval3 = val3.merge(h[['SC', 'year', 'month', 'half', 'avg_15']], on=['SC', 'year', 'month', 'half'])","814fc440":"w['year'] = w.date.apply(lambda x: pd.to_datetime(x).year)\nw['week'] = w.date.apply(lambda x: pd.to_datetime(x).week)\n\nw1['wk_sum'] = w1.y\nw2['wk_sum'] = w2.y\nw3['wk_sum'] = w3.y\n\ndf1 = df1.merge(w1[['year', 'week', 'wk_sum']], on=['year', 'week'], how='left').dropna()\ndf2 = df2.merge(w2[['year', 'week', 'wk_sum']], on=['year', 'week'], how='left').dropna()\ndf3 = df3.merge(w3[['year', 'week', 'wk_sum']], on=['year', 'week'], how='left').dropna()\n\nw['wk_sum'] = w.pred\n\nval1 = val1.merge(w[['SC', 'year', 'week', 'wk_sum']], on=['SC', 'year', 'week'])\nval2 = val2.merge(w[['SC', 'year', 'week', 'wk_sum']], on=['SC', 'year', 'week'])\nval3 = val3.merge(w[['SC', 'year', 'week', 'wk_sum']], on=['SC', 'year', 'week'])","19dbab46":"def model_p1(features, b1=True, b2=True):\n    pred=[]\n    date=[]\n    sc=[]\n    for c, (train0, val0) in enumerate(zip([df1, df2, df3], [val1, val2, val3])):\n        c = c+1\n        for i in train0.dow.unique():\n            train = train0[(train0.dow==i)].copy()\n            val = val0[val0.dow==i].copy()\n            model = Prophet(yearly_seasonality=b1, weekly_seasonality=b2)\n            for feat in features:\n                model.add_regressor(feat)\n            model.fit(train)\n            pred += list(model.predict(val)['yhat'].apply(lambda x: int(max(x,0))).values)\n            date += list(val.ds.values)\n            sc += list(val.SC.values)\n            \n    d1 = pd.DataFrame()\n    d1['pred'] = pred\n    d1['date'] = date\n    d1['SC'] = sc\n    d1 = d1.sort_values(by=['date', 'SC']).reset_index(drop=True)\n    \n    return list(d1.pred.values)\n    \ndef model_p2(features, b1=True, b2=True):\n    pred=[]\n    date=[]\n    sc=[]\n    for c, (train0, val0) in enumerate(zip([df1, df2, df3], [val1, val2, val3])):\n        c = c+1\n        train = train0.copy()\n        val = val0.copy()\n        model = Prophet(yearly_seasonality=b1, weekly_seasonality=b2)\n        for feat in features:\n            model.add_regressor(feat)\n        model.fit(train)\n        pred += list(model.predict(val)['yhat'].apply(lambda x: int(max(x,0))).values)\n        date += list(val.ds.values)\n        sc += list(val.SC.values)\n        \n    d1 = pd.DataFrame()\n    d1['pred'] = pred\n    d1['date'] = date\n    d1['SC'] = sc\n    d1 = d1.sort_values(by=['date', 'SC']).reset_index(drop=True)\n    \n    return list(d1.pred.values)\n\ndef model_a1(features):\n    pred=[]\n    date=[]\n    sc=[]\n    exo_vars = features[:]\n    for train0, val0 in zip([df1, df2, df3], [val1, val2, val3]):\n        for i in train0.dow.unique():\n            train = train0[(train0.dow==i)&(train0.ds>pd.to_datetime('2020-01-10'))].copy()\n            val = val0[val0.dow==i].copy()\n            model = auto_arima(y=train.y, exogenous=train[exo_vars])\n            pred += list(pd.DataFrame({'yhat':model.predict(n_periods=len(val), exogenous=val[exo_vars])}).yhat.apply(lambda x: int(max(x,0))).values)\n            date += list(val.ds.values)\n            sc += list(val.SC.values)\n            \n    d1 = pd.DataFrame()\n    d1['pred'] = pred\n    d1['date'] = date\n    d1['SC'] = sc\n    d1 = d1.sort_values(by=['date', 'SC']).reset_index(drop=True)\n    \n    return list(d1.pred.values)","478e0f7c":"d = pd.DataFrame()\nd['date'] = list(val1.ds.values)+list(val2.ds.values)+list(val3.ds.values)\nd['SC'] = list(val1.SC.values)+list(val2.SC.values)+list(val3.SC.values) \nd = d.sort_values(by=['date', 'SC']).reset_index(drop=True)","663efa96":"d['pred_p_0'] = model_p1(['avg_15', 'wk_sum'], True, True)\nd['pred_p_1'] = model_p1(['avg_15', 'wk_sum'], True, False)\nd['pred_p_2'] = model_p1(['avg_15', 'wk_sum'], False, True)\nd['pred_p_3'] = model_p1(['avg_15', 'wk_sum'], False, False)\nd['pred_p_4'] = model_p2(['avg_15', 'wk_sum'], True, True)\nd['pred_p_5'] = model_p2(['avg_15', 'wk_sum'], True, False)\nd['pred_p_6'] = model_p2(['avg_15', 'wk_sum'], False, True)\nd['pred_p_7'] = model_p2(['avg_15', 'wk_sum'], False, False)\nd['pred_p_8'] = model_a1(['avg_15', 'wk_sum'])\nd['pred_p_9'] = model_p1(['avg_15'], True, True)\nd['pred_p_10'] = model_p1(['avg_15'], True, False)\nd['pred_p_11'] = model_p1(['avg_15'], False, True)\nd['pred_p_12'] = model_p1(['avg_15'], False, False)\nd['pred_p_13'] = model_p2(['avg_15'], True, True)\nd['pred_p_14'] = model_p2(['avg_15'], True, False)\nd['pred_p_15'] = model_p2(['avg_15'], False, True)\nd['pred_p_16'] = model_p2(['avg_15'], False, False)\nd['pred_p_17'] = model_a1(['avg_15'])","680f00dc":"def fn(x):\n    if x.SC==1:\n        return x.pred_p_0 * (-19.57) + x.pred_p_1 * (19.26) + x.pred_p_2 * (-11.51) + x.pred_p_3 * (11.43) + x.pred_p_4 * (0.9) + x.pred_p_5 * (-1.17) + x.pred_p_6 * (0.62) + x.pred_p_7 * (1.14) + x.pred_p_8 * (-0.17) + x.pred_p_9 * (26.79) + x.pred_p_10 * (-26.24) + x.pred_p_11 * (26.81) + x.pred_p_12 * (-27.75) + x.pred_p_13 * (-0.88) + x.pred_p_14 * (0.63) + x.pred_p_15 * (-0.34) + x.pred_p_16 * (1.52) + x.pred_p_17 * (-0.34)\n    if x.SC==2:\n        return x.pred_p_0 * (-21.71) + x.pred_p_1 * (22.55) + x.pred_p_2 * (128.5) + x.pred_p_3 * (-132.59) + x.pred_p_4 * (-46.48) + x.pred_p_5 * (44.35) + x.pred_p_6 * (-16.88) + x.pred_p_7 * (21.5) + x.pred_p_8 * (1.38) + x.pred_p_9 * (-74.02) + x.pred_p_10 * (73.56) + x.pred_p_11 * (-9.19) + x.pred_p_12 * (11.41) + x.pred_p_13 * (75.68) + x.pred_p_14 * (-75.11) + x.pred_p_15 * (-12.03) + x.pred_p_16 * (12.15) + x.pred_p_17 * (-2.09)\n    if x.SC==3:\n        return x.pred_p_0 * (-16.55) + x.pred_p_1 * (17.76) + x.pred_p_2 * (-13.36) + x.pred_p_3 * (12.66) + x.pred_p_4 * (-0.65) + x.pred_p_5 * (0.42) + x.pred_p_6 * (-3.59) + x.pred_p_7 * (3.93) + x.pred_p_8 * (0.47) + x.pred_p_9 * (52.77) + x.pred_p_10 * (-53.5) + x.pred_p_11 * (85.71) + x.pred_p_12 * (-84.03) + x.pred_p_13 * (11.27) + x.pred_p_14 * (-10.35) + x.pred_p_15 * (-7.66) + x.pred_p_16 * (7.43) + x.pred_p_17 * (-1.23)","8d4af2de":"d['pred']=d.apply(fn, axis=1)\nd.pred.to_csv('submission_3.csv', header=False, index=False)","849776f4":"pd.read_csv('submission_3.csv', header=None)","3f87f152":"d['pred'].apply(lambda x: max(x,0))","b0c166aa":"### Combining Predictions","75584f98":"# Step 5: Predicting weekly statistics","78166626":"### Combining Predictions","2caa4737":"# Step 2: Dummy Test file to add date regressors","52c56324":"# Step 4: Predicting 15 day Statistics","d3f01c8a":"### Models for predicting 15 day mean","aca3dc96":"# Step 3: Add seasonalities and other features","b82b7d76":"# Even though I forgot to do this post processing in my best submission but this will further improve the scores","fff2cb1a":"### Models for day level predictions","9746912d":"## Adding new features to dataframe","02127063":"# Initialize Environment","ddcb6f59":"# Step 1: Generate the required time series","487eeef5":"### Models for predicting weekly total","ed671239":"# Day level Predictions"}}