{"cell_type":{"4bbbe168":"code","6d4bb686":"code","c821ec09":"code","f038d6bb":"code","474353a7":"code","e79a1b4d":"code","ca1fade1":"code","5f1a2606":"code","a76628f3":"code","fe4b6dc9":"code","1db6eb6c":"code","a4e60f68":"code","ab4e3c6f":"code","0c15b590":"code","1142b499":"code","4a76968a":"code","7b9ebec2":"code","ea0d5cb7":"code","72394fbc":"code","884b0c2a":"markdown","70d8fce7":"markdown","6ff8d574":"markdown","fa2e2c5b":"markdown","3ea19226":"markdown","edaab8d5":"markdown","446b6072":"markdown","7fcaae6c":"markdown","22ed8d68":"markdown","e3d6e1fb":"markdown"},"source":{"4bbbe168":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","6d4bb686":"filepath = '..\/input\/xAPI-Edu-Data\/xAPI-Edu-Data.csv'\ndata = pd.read_csv(filepath)","c821ec09":"data.head()","f038d6bb":"data.info()","474353a7":"dropped_data = data.drop(columns=['GradeID', 'SectionID', 'PlaceofBirth', 'Relation'])","e79a1b4d":"for col in dropped_data.columns:\n    print(col, '--')\n    print(dropped_data[col].value_counts())\n    print('---')","ca1fade1":"## Needed numerical Values : \nnum_attributes = ['VisITedResources','AnnouncementsView', 'Discussion', 'raisedhands']\n\n# If you want to visualize\/work with 3 attributes uncomment the lines below \n# num_attributes = ['VisITedResources', 'Discussion', 'raisedhands']\n\nnum_data = dropped_data[num_attributes]\nnum_data.head()\nprint(num_data.info())","5f1a2606":"from mpl_toolkits import mplot3d\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\nax = plt.axes(projection=\"3d\")\n\nax.scatter3D(num_data['VisITedResources'], num_data['Discussion'], num_data['raisedhands'])\n\nplt.show()","a76628f3":"from sklearn.preprocessing import StandardScaler\nscaled_num_data = StandardScaler().fit_transform(num_data)                                                                        ","fe4b6dc9":"mean_data = np.mean(scaled_num_data, axis=0)\n","1db6eb6c":"# Computing the covariance matrix\ncov_matrix = (scaled_num_data - mean_data).T.dot(scaled_num_data - mean_data) \/ (scaled_num_data.shape[0]-1)","a4e60f68":"# Computing eigen values and vectors \n\neig_values, eig_vectors = np.linalg.eig(cov_matrix)\n\nprint('Eigen values: --', eig_values)\nprint('Eigen vectors: --', eig_vectors)","ab4e3c6f":"eig_pairs = [(eig_values[i], eig_vectors[:, i]) for i in range(len(eig_values))]\neig_pairs.sort(key = lambda x:x[0], reverse=True)\neig_pairs","0c15b590":"total = sum(eig_values)\nvar_spread = [(i\/total)*100 for i in sorted(eig_values, reverse=True)]\ncum_var_spread = np.cumsum(var_spread)\nprint(cum_var_spread)\n\n# x_coordinates = ['PC1', 'PC2', 'PC3'] for working with 3 attributes\nx_coordinates = ['PC1', 'PC2', 'PC3', 'PC4']\n\ny_pos = np.arange(len(x_coordinates))\nplt.ylabel('Variance spread in %')\nplt.xticks(y_pos, x_coordinates)\nplt.bar(y_pos, var_spread)\nplt.plot(cum_var_spread, 'r')\nplt.show()\n","1142b499":"threshold = 90\n\n# If you're working with three attributes\n# threshold = 88 \n \nkeeping_vec = 0\nfor index, percentage in enumerate(cum_var_spread):\n    if percentage > threshold:\n        keeping_vec = index +1 \n        break\n\nprint(\"We keep \", keeping_vec, \" vectors\")","4a76968a":"num_features = scaled_num_data.shape[1]\n\nprojection_mat = eig_pairs[0][1].reshape(num_features, 1)\n","7b9ebec2":"for eig_vec_idx in range(1, keeping_vec):\n    projection_mat = np.hstack((projection_mat, eig_pairs[eig_vec_idx][1].reshape(num_features, 1)))\n    ","ea0d5cb7":"PCA_data = scaled_num_data.dot(projection_mat)\n\nPCA_data","72394fbc":"plt.scatter(PCA_data[:, 0], PCA_data[:, 1])","884b0c2a":"# Imlementing PCA without sckikit learn library function\n\nIplementing PCA on a student academic dataset [xAPI-Educational Mining Dataset](https:\/\/www.kaggle.com\/aljarah\/xAPI-Edu-Data)","70d8fce7":"Let's see what does our data comprise of by selecting the first 5 rows","6ff8d574":"# 4. Computing the co-variance matrix \nThe formula for computing the covariance matrix :\n![](https:\/\/education.howthemarketworks.com\/wp-content\/uploads\/2013\/09\/Covariance.jpg)","fa2e2c5b":"This plot shows that around 63% variance can be explained by first component, around 21% variance is explained by second component and 9% variance by the third component. Thus the three cover around 92% of the variance and fourth component can be dropped without losing too much information. It's a good tradeoff considering we are reducing 25% of our computations. ","3ea19226":"# 3. Scaling the numerical attributes\nThe values in the data need to be scaled around zero mean and unit variance","edaab8d5":"# 2. Visualising the attributes\nPlotting 3 of the attributes in a 3D scatter plot","446b6072":"# 5. Estimating the importance of each feature vector using explined variance.\n","7fcaae6c":"PCA reduces the 4 attribute data to 3 attributes","22ed8d68":"# 6. Projection Matrix","e3d6e1fb":"# 1. First importing the data"}}