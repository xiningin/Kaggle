{"cell_type":{"51fb2811":"code","32b9ff54":"code","0ae96532":"code","3d95711d":"code","4c15c557":"code","17570784":"code","329462f2":"code","4417ccb1":"code","a5d89b4f":"code","5804330c":"code","a508a075":"code","7448205b":"code","01b52612":"code","c6d10b3e":"code","76cfc44d":"code","ed7b326f":"code","a869940f":"code","0b509d2b":"code","78ad13d3":"code","c8be6aae":"code","a26db0e9":"code","c752dfdc":"code","ad8e1b8b":"code","65a8ad0d":"markdown","c38c80d5":"markdown","120cb63b":"markdown","bab0f4ba":"markdown"},"source":{"51fb2811":"import pandas_datareader as web\nimport datetime as dt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nplt.rcParams['figure.figsize'] = 20, 15\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout, GRU\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","32b9ff54":"start = dt.date(2014,1,1)\ndf = web.get_data_yahoo('bidi4.SA',start=start)\ndf = df['Close'].values\ndf.shape","0ae96532":"scaler = MinMaxScaler()\n\nscaled_data = scaler.fit_transform(df.reshape(-1,1))","3d95711d":"def rnn_process(all_data, window=60, test_size=.2):\n    # split\n    test_len = int(len(all_data) * test_size)\n    train = scaled_data[:-test_len]\n    test = scaled_data[-test_len-window:]\n    print(f'Train & Test lengths are : {len(train), len(test)}')\n\n    X_train = []\n    y_train = []\n    X_test = []\n    y_test = []\n    \n    # train build\n    for i in range(window,len(train)):\n        X_train.append(train[i-window:i,0])\n        y_train.append(train[i,0])\n    \n    #test build    \n    for i in range(window,len(test)):\n        X_test.append(test[i-window:i,0])\n        y_test.append(test[i,0])\n        \n    X_train, y_train, X_test, y_test = np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n    return X_train, y_train, X_test, y_test","4c15c557":"X_train, y_train, X_test, y_test = rnn_process(df)\nX_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\nX_test = X_test.reshape(X_test.shape[0],X_test.shape[1], 1)\nprint(f'X_train, y_train, X_test, y_test shapes are {X_train.shape, y_train.shape, X_test.shape, y_test.shape}')","17570784":"model = Sequential()\nmodel.add(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], 1)))\nmodel.add(LSTM(64, return_sequences=False))\nmodel.add(Dense(30))\nmodel.add(Dropout(.2))\nmodel.add(Dense(30))\nmodel.add(Dropout(.2))\nmodel.add(Dense(1, activation='linear'))\nmodel.compile(loss='mse', optimizer='adam')\nmodel.summary()\n","329462f2":"# Callbacks\ncheckpts = ModelCheckpoint('.\/lstm.h5', save_best_only=True, verbose=1)\nearly = EarlyStopping(patience=5)\ncallback_list = [checkpts, early]","4417ccb1":"EPOCHS = 15\nhistory = model.fit(X_train, y_train, validation_split=.2, epochs=EPOCHS, batch_size=32, \n                    verbose=1, callbacks=callback_list)","a5d89b4f":"preds = model.predict(X_test)\nmean_squared_error(preds, y_test)\n","5804330c":"preds = scaler.inverse_transform(preds)\nlosses = history.history","a508a075":"plt.plot(losses['loss'], label='Original')\nplt.plot(losses['val_loss'], label='Validation loss')\nplt.legend()","7448205b":"plt.plot(preds, label='Predictions')\nplt.plot(scaler.inverse_transform(y_test.reshape(-1,1)), label='Original')\nplt.legend()","01b52612":"def forecast(model, data, future=10, window=60): # function works for the window size 60 only\n    predictions = []\n    for i in range(future):\n        #data = data\n        predictions.append(model.predict(data.reshape(1,window,1)))\n        data = np.concatenate((data, predictions[-1]), axis=0)[-60:]\n    return np.array(predictions).reshape(-1,1)\n# Preds of next 10 days\nlstmpreds = forecast(model, X_test[-1])    \n    ","c6d10b3e":"lstmpreds = scaler.inverse_transform(lstmpreds)","76cfc44d":"model = Sequential()\nmodel.add(GRU(128, return_sequences=True, input_shape=(X_train.shape[1], 1)))\nmodel.add(GRU(64, return_sequences=False))\nmodel.add(Dense(30))\nmodel.add(Dropout(.2))\nmodel.add(Dense(30))\nmodel.add(Dropout(.2))\nmodel.add(Dense(1, activation='linear'))\nmodel.compile(loss='mse', optimizer='adam')\nmodel.summary()","ed7b326f":"# Callbacks\ncheckpts = ModelCheckpoint('.\/GRU.h5', save_best_only=True, verbose=1)\nearly = EarlyStopping(patience=5)\ncallback_list = [checkpts, early]","a869940f":"EPOCHS = 15\nhistory = model.fit(X_train, y_train, validation_split=.2, epochs=EPOCHS, batch_size=32,\n                    callbacks=callback_list, verbose=1)","0b509d2b":"preds = model.predict(X_test)\nmean_squared_error(preds, y_test)\n","78ad13d3":"preds = scaler.inverse_transform(preds)\nlosses = history.history","c8be6aae":"plt.plot(losses['loss'], label='Original')\nplt.plot(losses['val_loss'], label='Validation loss')\nplt.legend()","a26db0e9":"plt.plot(preds, label='Predictions')\nplt.plot(scaler.inverse_transform(y_test.reshape(-1,1)), label='Original')\nplt.legend()","c752dfdc":"# 10 days forecast\npreds = forecast(model, X_test[-1])\ngrupreds = scaler.inverse_transform(preds)\ngrupreds","ad8e1b8b":"tomorrow = dt.date.today() + dt.timedelta(days=1)\nresults = pd.DataFrame(np.concatenate((grupreds, lstmpreds), axis=1), columns=['GRU', \"LSTM\"], \n                       index=pd.date_range(tomorrow, periods=10, freq=\"B\"))\nresults","65a8ad0d":"# GRU","c38c80d5":"# Model","120cb63b":"today + datetime.timedelta(days=1)# Processing","bab0f4ba":"He we shall forecast 10 days of a given stock using LSTM and GRU. Please upvote if you like the work or fork it. Thanks."}}