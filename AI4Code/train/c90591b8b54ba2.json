{"cell_type":{"95433b6d":"code","137c55d7":"code","3d28d258":"code","e9e71332":"code","60a5ea97":"code","28f17c6b":"code","c0fcd018":"code","ba3dd420":"code","a25a136c":"code","19f598ea":"code","652469b9":"code","1ece4ff4":"code","926d3085":"code","5b038e41":"code","7b9b15b3":"code","cc99e97c":"code","655c29cc":"markdown","f385ea47":"markdown","aebac73f":"markdown","19159353":"markdown","36bf750d":"markdown","cbc72209":"markdown"},"source":{"95433b6d":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","137c55d7":"import os\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom tqdm import tqdm\nfrom glob import glob\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","3d28d258":"tf.__version__","e9e71332":"img_path = \"..\/input\/isic2018\/ISIC2018_Task1-2_Training_Input\/ISIC2018_Task1-2_Training_Input\/\"\nmask_path = '..\/input\/isic2018\/ISIC2018_Task1_Training_GroundTruth\/ISIC2018_Task1_Training_GroundTruth\/'","60a5ea97":"width = 128\nheight = 128\nchannels = 3","28f17c6b":"train_img = glob(img_path + '*.jpg')\ntrain_mask = [i.replace(img_path, mask_path).replace('.jpg', '_segmentation.png') for i in train_img]\n\n        \nprint(train_img[:2],\"\\n\" ,train_mask[:2])","c0fcd018":"# It contains 2594 training samples\nimg_files   = np.zeros([2594, height, width, channels])\nmask_files   = np.zeros([2594, height, width])\n\nprint('Reading ISIC 2018')\nfor idx, (img_path, mask_path) in tqdm(enumerate(zip(train_img, train_mask))):\n    img = cv2.imread(img_path)\n    img = np.double(cv2.resize(img,(width,height)))\n    img = img \/ 255\n    img_files[idx, :,:,:] = img\n\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask,(width,height))\n    mask = mask \/ 255\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    mask_files[idx, :,:] = mask    \n         \nprint('Reading ISIC 2018 finished')","ba3dd420":"# Display the first image and mask of the first subject.\nimage1 = np.array(Image.open(train_img[0]))\nimage1_mask = np.array(Image.open(train_mask[0]))\nimage1_mask = np.ma.masked_where(image1_mask == 0, image1_mask)\n\nfig, ax = plt.subplots(1,3,figsize = (16,12))\nax[0].imshow(image1, cmap = 'gray')\n\nax[1].imshow(image1_mask, cmap = 'gray')\n\nax[2].imshow(image1, cmap = 'gray', interpolation = 'none')\nax[2].imshow(image1_mask, cmap = 'jet', interpolation = 'none', alpha = 0.7)","a25a136c":"from tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate,add\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","19f598ea":"def dice_coef(y_true, y_pred):\n    smooth = 0.0\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum ( y_true_f * y_pred_f)\n    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n    return intersection\/union\n\n\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n","652469b9":"def unet(input_size=(256,256,1)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n\n    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n\n    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n\n    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n\n    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","1ece4ff4":"kf = KFold(n_splits = 5, shuffle=False)\n\nhistories = []\nlosses = []\naccuracies = []\ndicecoefs = []\nious = []\n\nEPOCHS = 120\nBATCH_SIZE = 16\n\nmask_files = mask_files[:, :, :, np.newaxis]\n\nfor k, (train_index, test_index) in enumerate(kf.split(img_files, mask_files)):\n    X_train = img_files[train_index]\n    y_train = mask_files[train_index]\n    X_test = img_files[test_index]\n    y_test = mask_files[test_index]\n    \n    model = unet(input_size=(height,width, channels))\n    model.compile(optimizer=Adam(lr=5e-6), loss=dice_coef_loss, \\\n                      metrics=[iou, dice_coef, 'binary_accuracy'])\n\n    model_checkpoint = ModelCheckpoint(str(k+1) + '_unet_skin_seg.hdf5', \n                                       verbose=1, \n                                       save_best_only=True)\n\n    history = model.fit(X_train,\n                        y_train,\n                        epochs=EPOCHS,\n                        callbacks=[model_checkpoint],\n                        validation_data = (X_test, y_test))\n    \n    model = load_model(str(k+1) + '_unet_skin_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})\n    \n    results = model.evaluate(X_test, y_test)\n    results = dict(zip(model.metrics_names,results))\n    \n    histories.append(history)\n    accuracies.append(results['binary_accuracy'])\n    losses.append(results['loss'])\n    dicecoefs.append(results['dice_coef'])\n    ious.append(results['iou'])","926d3085":"import pickle\n\nfor h, history in enumerate(histories):\n\n    keys = history.history.keys()\n    fig, axs = plt.subplots(1, len(keys)\/\/2, figsize = (25, 5))\n    fig.suptitle('No. ' + str(h+1) + ' Fold Results', fontsize=30)\n\n    for k, key in enumerate(list(keys)[:len(keys)\/\/2]):\n        training = history.history[key]\n        validation = history.history['val_' + key]\n\n        epoch_count = range(1, len(training) + 1)\n\n        axs[k].plot(epoch_count, training, 'r--')\n        axs[k].plot(epoch_count, validation, 'b-')\n        axs[k].legend(['Training ' + key, 'Validation ' + key])\n    \n    with open(str(h+1) + '_skin_trainHistoryDict', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)","5b038e41":"print('accuracies : ', accuracies)\nprint('losses : ', losses)\nprint('dicecoefs : ', dicecoefs)\nprint('ious : ', ious)\n\nprint('-----------------------------------------------------------------------------')\nprint('-----------------------------------------------------------------------------')\n\nprint('average accuracy : ', np.mean(np.array(accuracies)))\nprint('average loss : ', np.mean(np.array(losses)))\nprint('average dicecoefs : ', np.mean(np.array(dicecoefs)))\nprint('average ious : ', np.mean(np.array(ious)))\nprint()\n\nprint('standard deviation of accuracy : ', np.std(np.array(accuracies)))\nprint('standard deviation of loss : ', np.std(np.array(losses)))\nprint('standard deviation of dicecoefs : ', np.std(np.array(dicecoefs)))\nprint('standard deviation of ious : ', np.std(np.array(ious)))","7b9b15b3":"selector = np.argmin(abs(np.array(ious) - np.mean(ious)))\nmodel = load_model(str(selector+1) + '_unet_skin_seg.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})","cc99e97c":"for i in range(20):\n    index=np.random.randint(0,len(img_files))\n    print(i+1, index)\n    img = cv2.imread(img_files[index])\n    img = cv2.resize(img, (height, width))\n    img = img[np.newaxis, :, :, :]\n    img = img \/ 255\n    pred = model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.resize(cv2.imread(mask_files[index]), (height, width))))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","655c29cc":"Now, I try to load all image files and store them variables X and y. Afther doing this, I recognize that it takes very much memory.<br\/>\nPlease let me know if there are several efficient ways to store image file","f385ea47":"## Building the training dataset.\nLet's look at the train image list","aebac73f":"## How to deal with train_masks.csv ?","19159353":"**Sort the file list in ascending order and seperate it into images and masks**<br\/>\nEach file has the form of either \"subject_imageNum.tif\" or \"subject_imageNum_mask.tif\", so we can extract `subject` and `imageNum` from each file name by using regular expression. `\"[0-9]+\"` means to find the first consecutive number.<br\/>","36bf750d":"Let's modularize this work.","cbc72209":"Let's check that I did well"}}