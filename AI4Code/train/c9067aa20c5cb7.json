{"cell_type":{"1e176e60":"code","0ecbb80b":"code","8d6ce105":"code","6dc45bf4":"code","a0edc26b":"code","686230d9":"code","8dea56fb":"code","aff18cff":"code","5680150c":"code","04998d76":"code","ba7e3d13":"code","94b90846":"code","ef664c14":"code","0ac3fa93":"code","dd2c17f1":"code","3ea85ecb":"code","e291c8e3":"code","17f3664f":"code","5c6acda5":"code","9e155b1c":"code","8053bf90":"code","c4f43138":"code","ce297eb5":"code","641c95ff":"code","dc0260ff":"code","c9024a4f":"code","b3d79685":"code","cc3fe68b":"code","ed37c4ba":"code","3b325adf":"code","b7521fcb":"code","62d3a14a":"code","2510273a":"code","b821fb87":"code","19dd398d":"code","40de435b":"markdown","26fe8e6e":"markdown","5526d9f4":"markdown","2c7c0102":"markdown","cb186d61":"markdown","10e32ead":"markdown","3dd47327":"markdown","97d6a9aa":"markdown","09ba89fc":"markdown","cebedb5c":"markdown","8f56bdb6":"markdown","59be36a0":"markdown","d0997a77":"markdown","4fa8035d":"markdown","c2b158fd":"markdown","87654f4e":"markdown","0b207f53":"markdown","c2abf379":"markdown","970fab15":"markdown","5e0aabcb":"markdown","afd10df4":"markdown","32381506":"markdown","7932096f":"markdown","0fc14904":"markdown","0f3af48c":"markdown"},"source":{"1e176e60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ecbb80b":"import rasterio\nfrom rasterio.enums import Resampling\nfrom rasterio.plot import show\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport re","8d6ce105":"dataset = rasterio.open('..\/input\/global-gridded-model-of-carbon-footprints-ggmcf\/GGMCF_v1.0.tif')","6dc45bf4":"dataset.count","a0edc26b":"%%time\nupscale_factor = 0.01\n\n# resample data to target shape\ndata = dataset.read(\n    out_shape=(\n        dataset.count,\n        int(dataset.height * upscale_factor),\n        int(dataset.width * upscale_factor)\n    ),\n    resampling=Resampling.bilinear\n)\n\n# scale image transform\ntransform = dataset.transform * dataset.transform.scale(\n    (dataset.width \/ data.shape[-1]),\n    (dataset.height \/ data.shape[-2])\n)","686230d9":"data.shape","8dea56fb":"mpl.rcParams['figure.dpi'] = 200\nmpl.rcParams['font.size'] = 8\nimage_hidden = plt.imshow(np.log10(data[0,:,:]))\nplt.colorbar(image_hidden)","aff18cff":"dataset.crs","5680150c":"gdf = gpd.read_file('..\/input\/world-urban-areas-landscan-110-million-2012\/ne_10m_urban_areas_landscan.shp')","04998d76":"gdf.info()","ba7e3d13":"gdf.head()","94b90846":"%time gdf.plot(figsize=(12,8))","ef664c14":"LA_mask = gdf['name_conve'].str.contains('Angeles')\nsum(LA_mask)","0ac3fa93":"gdf[LA_mask]","dd2c17f1":"gdf[gdf['name_conve'] == 'Los Angeles1'].plot()","3ea85ecb":"gdf[gdf['name_conve'] == 'Los Angeles2'].plot()","e291c8e3":"gdf.crs","17f3664f":"from rasterio.warp import calculate_default_transform, reproject, Resampling","5c6acda5":"dst_crs = 'EPSG:4326'","9e155b1c":"%%time\nwith rasterio.open('..\/input\/global-gridded-model-of-carbon-footprints-ggmcf\/GGMCF_v1.0.tif') as src:\n    transform, width, height = calculate_default_transform(\n        src.crs, dst_crs, src.width, src.height, *src.bounds)\n    kwargs = src.meta.copy()\n    kwargs.update({\n        'crs': dst_crs,\n        'transform': transform,\n        'width': width,\n        'height': height\n    })\n\n    with rasterio.open('\/kaggle\/working\/reprojected.tif', 'w', **kwargs) as dst:\n        for i in range(1, src.count + 1):\n            reproject(\n                source=rasterio.band(src, i),\n                destination=rasterio.band(dst, i),\n                src_transform=src.transform,\n                src_crs=src.crs,\n                dst_transform=transform,\n                dst_crs=dst_crs,\n                resampling=Resampling.nearest)","8053bf90":"shapes = gdf[gdf['name_conve'] == 'Los Angeles1']['geometry']\nshapes","c4f43138":"from rasterio.mask import mask","ce297eb5":"with rasterio.open('reprojected.tif') as src:\n    out_image, out_transform = mask(src, shapes, crop=True)\n    out_meta = src.meta","641c95ff":"fig, axs = plt.subplots(1,2)\ngdf[gdf['name_conve'] == 'Los Angeles1'].plot(ax=axs[0])\nshow(out_image, ax=axs[1])","dc0260ff":"out_image.shape","c9024a4f":"out_image.sum()","b3d79685":"df = pd.read_csv('\/kaggle\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Disclosing\/2019_Cities_Disclosing_to_CDP.csv')","cc3fe68b":"df.info()","ed37c4ba":"df.head()","3b325adf":"df['City'].isnull().mean()","b7521fcb":"df['City_filled'] = df['City'].fillna(df['Organization'])","62d3a14a":"df[['City', 'Organization', 'City_filled']].head(10)","2510273a":"%%time\nmatched = []\nmatch_count = []\nfor city_1 in df['City_filled'].tolist():\n    for city_2 in gdf['name_conve'].tolist():\n        if re.match(city_1, city_2):\n            matched.append(city_2)\n            match_count.append(1)\n            break","b821fb87":"len(match_count)","19dd398d":"345\/861","40de435b":"So we've found polygons for...","26fe8e6e":"Now I show how to mask the carbon footprint data, which span the globe, to an individual city, LA.","5526d9f4":"Let's try to find Los Angeles in here to plot one city.","2c7c0102":"Now search for cities in the map data that match the city name in the CDP data, `break`ing the first time a match is found in order to take a city name ending in 1 in case of multiples.","cb186d61":"What's the coordinate reference system here?","10e32ead":"The city polygons across the world form a faint impression of global land masses. The largest concentrations of cities appear to be in India and China, which are the most populated countries.","3dd47327":"about 40% of the cities. Which isn't perfect but seems like a reasonable amount to do some analysis. A more detailed look here may yield more matches.","97d6a9aa":"It's apparent that more populated areas around the world have larger carbon footprints, which makes sense.\n\nWhat is the coordinate reference system of these data?","09ba89fc":"# Carbon Footprint Data\nThese data come in the form of a GeoTIFF, which is essentially a 2D array of numbers that can be mapped to spatial locations on the earth's surface.","cebedb5c":"This is different than the carbon footprint, requiring reprojection.","8f56bdb6":"We can also gather statistics on the carbon footprint data, such as adding up the carbon footprint for the LA metro area. I will just use the sum to add up the footprint over the whole city, but may come back later to add in other statistics.","59be36a0":"# Cities in the CDP data","d0997a77":"Reprojection code adapted from https:\/\/rasterio.readthedocs.io\/en\/latest\/topics\/reproject.html","4fa8035d":"Looks like `City` is the field I want, but sometimes it's null. I'll fill the missing data with `Organization`.","c2b158fd":"It looks like there are two cities in the data called \"Los Angeles\". What do they look like?","87654f4e":"This EPSG code comes from the metadata shown above.","0b207f53":"The coordinate reference system of these data need to match other systems, to be spatially joined.","c2abf379":"# Carbon footprints for cities in CDP data\nTBD","970fab15":"# Reproject carbon footprints data and save","5e0aabcb":"Image data often have multiple \"bands\", e.g. red\/green\/blue, but there is just one band here, which is the array of numbers representing carbon footprints. Let's visualize the data. For visibility, downsample the data by a factor of 100 plot it on a log scale.","afd10df4":"The first one appears to be the Southern California metropolis. I'll assume that for other cities in these data, the first one is the largest city and the one I'll take for matching with other data.","32381506":"# Plot carbon footprint for one city","7932096f":"# Dataset description and relation to competition\nThis dataset is available here: http:\/\/citycarbonfootprints.info\/ and derives from a recent publication on carbon footprints of world cities: https:\/\/iopscience.iop.org\/article\/10.1088\/1748-9326\/aac72a \"Carbon footprints of 13\u2009000 cities\", published in 2018. The carbon footprint data refer to the year 2013. To create the footprints for the 13,000 cities around the world, the authors created a 250m grid spanning the globe:\n\n>Units are Gg (1 Gg=1Kt) of CO2 emissions from fossil fuel combustion. The data year is 2013. The map is full-world extent (-90\u00b0 to +90\u00b0 and -180\u00b0 to 180\u00b0) in the equal-area World Mollewiede (EPSG:54009) projection, with 250m cells. The GeoTIFF files are 200mb uncompressed but require a minimum of 5gb RAM to view or analyse.\n\nThe study appears to be one of the most extensive efforts yet to characterize carbon footprints with as much spatial coverage as possible. This opens up numerous possibilities for analysis and incorporation into KPIs for the CDP: Unlocking Climate Solutions competition. The global extent should enable actual carbon footprint estimates to be spatially joined to the competition data, which include:\n- City-level information about commitments to improving carbon budgets, as well as\n- Fine-grained spatial analysis within cities at the zip code and census tract level\n\nThe data presented here could be used for both large, multi-city analysis, as well as within-city analysis due to the 250m spatial resolution.\n\nIn this notebook I load the data and visualize for Los Angeles, California, USA, then join with cities in the competition dataset (TBD).","0fc14904":"Now that we've done it for one city, the next step is to match up city names from the CDP competition data with the world urban areas data, in order to capture the carbon footprints. Here are the cities in the CDP data:","0f3af48c":"# World urban areas shapefile\nIn order to join the global gridded data, we need to identify which regions of the gridded data correspond to cities in the competition data set. This public data set has polygons describing major cities around the world (https:\/\/geo.nyu.edu\/catalog\/stanford-yk247bg4748)."}}