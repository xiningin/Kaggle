{"cell_type":{"5295a041":"code","ced74dc0":"code","2c664d94":"code","bc753b64":"code","cd19874f":"code","803e5b0e":"code","273c109a":"code","29e678e3":"code","1716e651":"code","994cd918":"code","0f2112bb":"code","29eb4ffd":"code","afcf762b":"code","6efd05ef":"code","5a489ded":"code","f41ac76a":"code","8f180815":"code","897c56e2":"code","c006cd97":"code","dc224f3f":"code","8a6a0bf1":"markdown","6bdd656b":"markdown","5b3a41cc":"markdown","57ae6345":"markdown","d7375791":"markdown","7c49a262":"markdown"},"source":{"5295a041":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ced74dc0":"import glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport collections\nimport math\nimport os\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import datasets, transforms\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)","2c664d94":"!pip install py7zr","bc753b64":"!python -m py7zr x \/kaggle\/input\/cifar-10\/train.7z","cd19874f":"!python -m py7zr x \/kaggle\/input\/cifar-10\/test.7z # Around 15 minutes to uncompress.","803e5b0e":"data_dir = '\/kaggle\/working\/'","273c109a":"def read_csv_labels(fname):\n    \"\"\"Read `fname` to return a filename to label dictionary.\"\"\"\n    with open(fname, 'r') as f:\n        # Skip the file header line (column name)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',') for l in lines]\n    return dict(((name, label) for name, label in tokens))\n\nlabels = read_csv_labels(os.path.join(data_dir, '\/kaggle\/input\/cifar-10\/trainLabels.csv'))\nprint(f'Number training examples: {len(labels)}')\nprint(f'Number classes: {len(set(labels.values()))}')","29e678e3":"def copyfile(filename, target_dir):\n    \"\"\"Copy a file into a target directory.\"\"\"\n    os.makedirs(target_dir, exist_ok=True)\n    shutil.copy(filename, target_dir)\n\ndef reorg_train_valid(data_dir, labels, valid_ratio):\n    \"\"\"Split the validation set out of the original training set.\"\"\"\n    # The number of examples of the class that has the fewest examples in the\n    # training dataset\n    n = collections.Counter(labels.values()).most_common()[-1][1]\n    # The number of examples per class for the validation set\n    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n    label_count = {}\n    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n        label = labels[train_file.split('.')[0]]\n        fname = os.path.join(data_dir, 'train', train_file)\n        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                     'train_valid', label))\n        if label not in label_count or label_count[label] < n_valid_per_label:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'valid', label))\n            label_count[label] = label_count.get(label, 0) + 1\n        else:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'train', label))\n    return n_valid_per_label","1716e651":"def reorg_test(data_dir):\n    \"\"\"Organize the testing set for data loading during prediction.\"\"\"\n    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n        copyfile(os.path.join(data_dir, 'test', test_file),\n                 os.path.join(data_dir, 'train_valid_test', 'test',\n                              'unknown'))","994cd918":"def reorg_cifar10_data(data_dir, valid_ratio):\n    labels = read_csv_labels('\/kaggle\/input\/cifar-10\/trainLabels.csv')\n    reorg_train_valid(data_dir, labels, valid_ratio)\n    reorg_test(data_dir)","0f2112bb":"batch_size = 64\nvalid_ratio = 0.1\nreorg_cifar10_data(data_dir, valid_ratio)","29eb4ffd":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandbkey\") # load wandbkey from Kaggle's secrets\n\nwandb.login(key=secret_value_0)\nwandb.init(project='Cifar 10', save_code=True)","afcf762b":"# Define the data augmentation technique \ntransform_train = torchvision.transforms.Compose([\n    torchvision.transforms.RandomResizedCrop(32), # RandomSizeCrop, randomly crops and resize to given value\n    torchvision.transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5,hue=0.5), # Color Jitter\n    torchvision.transforms.RandomHorizontalFlip(), # Horizontal Flip\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n                                     [0.2023, 0.1994, 0.2010])\n])\n\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n                                     [0.2023, 0.1994, 0.2010])])","6efd05ef":"train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(data_dir, 'train_valid_test', folder),\n    transform=transform_train) for folder in ['train', 'train_valid']]\n\nvalid_ds, test_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(data_dir, 'train_valid_test', folder),\n    transform=transform_test) for folder in ['valid', 'test']]\n\ntrain_iter, train_valid_iter = [torch.utils.data.DataLoader(\n    dataset, batch_size, shuffle=True, drop_last=True)\n    for dataset in (train_ds, train_valid_ds)]\n\nvalid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n                                         drop_last=True)\n\ntest_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n                                        drop_last=False)\n","5a489ded":"# Fine-tune a pre-trained ResNet-18 on CIFAR-10\n# We swap the head with a Linear layer of the correct output shape that we initialize\npretrained_net = torchvision.models.resnet18(pretrained=True)\npretrained_net.fc = nn.Linear(pretrained_net.fc.in_features, 10)\nnn.init.xavier_normal_(pretrained_net.fc.weight)\nnn.init.constant_(pretrained_net.fc.bias, 0)","f41ac76a":"# If we have a GPU, we use it. DataParallel allows to use multiple GPU in parallel if we have them\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\npretrained_net = pretrained_net.to(device)\nif device == 'cuda':\n    pretrained_net = torch.nn.DataParallel(pretrained_net) # if multiple GPUs use them\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(pretrained_net.parameters(), lr=1e-4, weight_decay=0.0001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True, min_lr=1e-5, factor=0.5)","8f180815":"from tqdm.notebook import trange, tqdm\n\nepochs = 10\nfor epoch in trange(epochs):\n    accurate = 0\n    total = 0\n    losses = 0\n    for X, y in tqdm(train_iter): # Training loop\n        # Send to GPU\n        X = X.to(device)\n        y = y.to(device)\n        \n        y_pred = pretrained_net(X)\n        loss = criterion(y_pred, y)\n        score, predicted = torch.max(y_pred, 1)\n        accurate += (y == predicted).sum().float()\n        losses += loss.item()\n        total += len(y)\n\n        # zero the gradients before running\n        # the backward pass.\n        optimizer.zero_grad()\n\n        # Backward pass to compute the gradient\n        # of loss w.r.t our learnable params. \n        loss.backward()\n\n        # Update params\n        optimizer.step()\n    \n    wandb.log({\n            'training-loss': losses \/ len(train_iter),\n            'training-accuracy': accurate \/ total\n    })\n    with torch.no_grad(): # Validation loop\n        pretrained_net.eval()\n        accurate = 0\n        total = 0 \n        losses = 0\n        for X, y in tqdm(valid_iter):\n            # Send to GPU\n            X = X.to(device)\n            y = y.to(device)\n                \n            y_pred = pretrained_net(X)\n            loss = criterion(y_pred, y)\n            score, predicted = torch.max(y_pred, 1)\n            accurate += (y == predicted).sum().float()\n            losses += loss.item()\n            total += len(y)\n        wandb.log({\n            'validation-loss': losses \/ len(valid_iter),\n            'validation-accuracy': accurate \/ total\n        })","897c56e2":"torch.save(pretrained_net.state_dict(), 'model.pt') # Save de model","c006cd97":"# Based on \"Generating Predictions\" from \n# https:\/\/www.kaggle.com\/francescolorenzo\/96-fine-tuning-resnet34-with-pytorch submitted 7 months ago.\npreds = []\n\npretrained_net.eval()\nwith torch.no_grad():\n    for X, _ in tqdm(test_iter):\n        X = X.to(device) # Send to GPU\n        preds.extend(pretrained_net(X).argmax(dim=1).type(torch.int32).cpu().numpy()) # Collect predictions\nids = list(range(1, len(test_ds)+1)) # Get IDs from the dataset\nids.sort(key=lambda x: str(x)) # Sort the IDs\ndf = pd.DataFrame({'id': ids, 'label': preds}) # Dataframe creation\ndf['label'] = df['label'].apply(lambda x: train_ds.classes[x]) # Set the class predicted in the prediction column,i.e.cat  \ndf.to_csv('submission.csv', index=False)","dc224f3f":"# Load saved model for future stuff\npretrained_net.load_state_dict(torch.load('model.pt'))","8a6a0bf1":"## WARNING: It can take a lot of time to uncompress!","6bdd656b":"# Unzip datasets","5b3a41cc":"# Import everything needed!","57ae6345":"# Fine-Tuning","d7375791":"# Prediction Submission","7c49a262":"# Wandb Setup"}}