{"cell_type":{"ec01b563":"code","539adca5":"code","481e131d":"code","d80dcd30":"code","c2f962ba":"code","6f866ad4":"code","f80b2b4d":"code","0c5d87ad":"code","53b30a33":"code","e7fc2f2f":"code","0d5abfc6":"code","d0dfc968":"code","2f1b73af":"code","a2dc7f56":"code","7c3f383f":"code","39e2632c":"code","6f74032e":"code","eef37b9e":"code","fa28fdb1":"code","a5729af6":"code","9b42817e":"code","2047e792":"code","2e1bd54a":"code","999782b1":"code","53980fc3":"code","af70a346":"code","4aba5315":"code","abbc3238":"markdown","c59c6286":"markdown","85c6bcd8":"markdown","b41e170a":"markdown","141f9448":"markdown","95243060":"markdown","dc47e360":"markdown"},"source":{"ec01b563":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","539adca5":"# For Oversampling\n!pip install imbalanced-learn","481e131d":"# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","d80dcd30":"card_df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ncard_df.head(3)","c2f962ba":"card_df['Class'].value_counts()","6f866ad4":"# Time -> Drop \n# Class 0 -> \uc815\uc0c1, 1 -> Fraud\nfrom sklearn.model_selection import train_test_split\n\ndef get_preprocessed_df(df=None) :\n    df_copy = df.copy()\n    df_copy.drop('Time', axis=1, inplace=True)\n    return df_copy","f80b2b4d":"def get_train_test_dataset(df=None) :\n    df_copy = get_preprocessed_df(df)\n    x_features = df_copy.iloc[:, :-1]\n    y_labels = df_copy.iloc[:, -1]\n    \n    x_train, x_test, y_train, y_test = train_test_split(x_features, y_labels, test_size=0.3, stratify=y_labels)\n    return x_train, x_test, y_train, y_test\n\nx_train, x_test, y_train, y_test = get_train_test_dataset(card_df)","0c5d87ad":"print(y_train.value_counts() \/ y_train.shape[0] * 100)\nprint(y_test.value_counts() \/ y_test.shape[0] * 100)","53b30a33":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n\ndef get_clf_eval(y_test, pred) :\n    confusion = confusion_matrix(y_test, pred)\n    accuracy = accuracy_score(y_test, pred)\n    precision = precision_score(y_test, pred)\n    recall = recall_score(y_test, pred)\n    f1 = f1_score(y_test, pred)\n    print('Confusion Matrix')\n    print(confusion)\n    print('Accuracy: {0:.4f}, Precision: {1:.4f}, Recall: {2:.4f}, f1-score: {3: .4f}'.format(accuracy, precision, recall, f1))\n\nlr_clf = LogisticRegression()\nlr_clf.fit(x_train, y_train)\nlr_pred = lr_clf.predict(x_test)\nget_clf_eval(y_test, lr_pred)","e7fc2f2f":"# \uc778\uc790\ub85c Estimator \uac1d\uccb4\uc640 \ud559\uc2b5\/\ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc14b\uc744 \uc785\ub825 \ubc1b\uc544 \ud559\uc2b5\/\ud3c9\uac00\ub97c \uc9c4\ud589\ud568.\ndef get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None) :\n    model.fit(ftr_train, tgt_train)\n    pred = model.predict(ftr_test)\n    get_clf_eval(tgt_test, pred)","0d5abfc6":"from lightgbm import LGBMClassifier\n\nlgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False, tree_method='gpu_exact')\nget_model_train_eval(lgbm_clf, x_train, x_test, y_train, y_test)","d0dfc968":"plt.figure(figsize=(8, 4))\nplt.xticks(range(0, 30000, 1000), rotation=60)\nsns.distplot(card_df['Amount'])","2f1b73af":"# Amount \uac12\uc744 \ud45c\uc900 \uc84d\uaddc \ubd84\ud3ec\ub85c \ubcc0\ud658\uc2dc\ucf1c\uc900\ub2e4.\nfrom sklearn.preprocessing import StandardScaler\n\ndef get_preprocessed_df(df=None) :\n    df_copy = df.copy()\n    scaler = StandardScaler()\n    amount_n = scaler.fit_transform(df_copy['Amount'].values.reshape(-1, 1))\n    df_copy.insert(0, 'Amount_Scaled', amount_n)\n    df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n    return df_copy","a2dc7f56":"x_train, x_test, y_train, y_test = get_train_test_dataset(card_df)","7c3f383f":"lr_clf = LogisticRegression()\nget_model_train_eval(lr_clf, x_train, x_test, y_train, y_test)\n\nlgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False, tree_method='gpu_exact')\nget_model_train_eval(lgbm_clf, x_train, x_test, y_train, y_test)","39e2632c":"def get_preprocessed_df(df=None) :\n    df_copy = df.copy()\n    amount_n = np.log1p(df_copy['Amount'])\n    df_copy.insert(0, 'Amount_Scaled', amount_n)\n    df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n    return df_copy","6f74032e":"x_train, x_test, y_train, y_test = get_train_test_dataset(card_df)\n\nlr_clf = LogisticRegression()\nget_model_train_eval(lr_clf, x_train, x_test, y_train, y_test)\n\nlgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False, tree_method='gpu_exact', verbose=1)\nget_model_train_eval(lgbm_clf, x_train, x_test, y_train, y_test)","eef37b9e":"plt.figure(figsize=(10, 12))\ncorr = card_df.corr()\nsns.heatmap(corr, cmap='RdBu')","fa28fdb1":"def get_outlier(df=None, column=None, weight=1.5) :\n    fraud = df[df.Class == 1][column]\n    q_25 = np.percentile(fraud.values, 25)\n    q_75 = np.percentile(fraud.values, 75)\n    \n    iqr = q_75 - q_25\n    iqr_weight = iqr * weight\n    lowest_val = q_25 - iqr_weight\n    highest_val = q_75 + iqr_weight\n    \n    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n    return outlier_index","a5729af6":"outlier_index = get_outlier(card_df, 'V14')\nprint(outlier_index)","9b42817e":"def get_preprocessed_df(df=None) :\n    df_copy = df.copy()\n    amount_n = np.log1p(df_copy['Amount'])\n    df_copy.insert(0, 'Amount_Scaled', amount_n)\n    df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n    \n    outlier_index = get_outlier(card_df, 'V14')\n    df_copy.drop(outlier_index, axis=0, inplace=True)\n    return df_copy","2047e792":"x_train, x_test, y_train, y_test = get_train_test_dataset(card_df)\n\nlr_clf = LogisticRegression()\nget_model_train_eval(lr_clf, x_train, x_test, y_train, y_test)\n\nlgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False, tree_method='gpu_exact', verbose=1)\nget_model_train_eval(lgbm_clf, x_train, x_test, y_train, y_test)","2e1bd54a":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nx_train_over, y_train_over = smote.fit_sample(x_train, y_train)\nprint(y_train.value_counts())\nprint(pd.Series(y_train_over).value_counts())","999782b1":"lr_clf = LogisticRegression()\nget_model_train_eval(lr_clf, x_train_over, x_test, y_train_over, y_test)","53980fc3":"from sklearn.metrics import precision_recall_curve\n\ndef precision_recall_curve_plot(y_test, pred_proba_c1) :\n    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n    \n    plt.figure(figsize=(8, 6))\n    threshold_boundary = thresholds.shape[0]\n    \n    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n    \n    start, end = plt.xlim()\n    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n    plt.legend()\n    plt.grid()\n    plt.show()","af70a346":"precision_recall_curve_plot(y_test, lr_clf.predict_proba(x_test)[:, 1])","4aba5315":"lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False, tree_method='gpu_exact', verbose=1)\nget_model_train_eval(lgbm_clf, x_train_over, x_test, y_train_over, y_test)","abbc3238":"# *Model Training\/Prediction\/Evaluation after data distribution transformation*","c59c6286":"### *log1p*","85c6bcd8":"### *StandardScaler*","b41e170a":"# *Data Loading & First Preprocessing & Learn\/Predict\/Evaluate*","141f9448":"# *Model Training\/Prediction\/Evaluation after removing outlier data*","95243060":"# *Model Training\/Prediction\/Evaluation after SMOTE Oversampling*","dc47e360":"# *Configuration*"}}