{"cell_type":{"04902e87":"code","8636058d":"code","43fd8185":"code","17a6c37f":"code","d423abf6":"code","9fe8b09b":"code","1ebed9e5":"code","cf0f4bca":"code","3a752044":"code","9f6bb7a7":"code","aa69f8c3":"code","5c834ec9":"code","074c90d5":"code","bf4b60cc":"code","621f9c2e":"code","c11ca40a":"code","a1064f76":"code","fdc3e9d1":"code","18b679b9":"code","2bcf78b5":"code","c8fc22c9":"code","2035e0bc":"code","7f6dae4d":"code","09917b77":"code","fdaa77e2":"code","34609da6":"code","e6d6318c":"code","347412f9":"code","860c1382":"code","819f75e6":"markdown","b7163a54":"markdown","a7665f20":"markdown","1d663ce8":"markdown","80993860":"markdown","45441bbf":"markdown","635a9bd1":"markdown","f6610d2a":"markdown","a8231e83":"markdown","c51579fc":"markdown","c175b186":"markdown"},"source":{"04902e87":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport os\nprint(os.listdir(\"..\/input\/titanic\"))\n","8636058d":"train=pd.read_csv(\"..\/input\/titanic\/train.csv\").drop(['PassengerId','Cabin','Ticket'],axis=1)\ntest=pd.read_csv(\"..\/input\/titanic\/test.csv\").drop(['Cabin','Ticket'],axis=1)\npassid=pd.DataFrame(test['PassengerId'])\ntest=test.drop(['PassengerId'],axis=1)","43fd8185":"#c_t= train['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n","17a6c37f":"train['Title']=train['Name'].str.extract('([A-Za-z]+)\\.')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')\ntrain['Title']=train['Title'].replace(['Capt','Col','Dr','Major','Rev'],'Special')\ntrain['Title']=train['Title'].replace(['Lady','Countess','Don','Sir','Jonkheer','Dona'],'Royalty')\n\ntrain['Title']=train['Title'].replace(['Royalty','Special','Miss','Mrs','Mr','Master'],[0,1,2,2,3,4])\n\nfrom sklearn.preprocessing import OneHotEncoder\nenc=OneHotEncoder()\ntitle=train['Title'].values\ntitle=pd.DataFrame(OneHotEncoder().fit_transform(title.reshape(-1,1)).toarray())\ntitle.columns=['Title1','Title2','Title3','Title4','Title5']\ntitle=title.iloc[:,:-1]\n\ntrain=train.drop(['Title','Name'],axis=1)\ntrain=pd.concat([train,title],axis=1)\n","d423abf6":"test['Title']=test['Name'].str.extract('([A-Za-z]+)\\.')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')\ntest['Title']=test['Title'].replace(['Capt','Col','Dr','Major','Rev'],'Special')\ntest['Title']=test['Title'].replace(['Lady','Countess','Don','Sir','Jonkheer','Dona'],'Royalty')\n\ntest['Title']=test['Title'].replace(['Royalty','Special','Miss','Mrs','Mr','Master'],[0,1,2,2,3,4])\n\nfrom sklearn.preprocessing import OneHotEncoder\nenc=OneHotEncoder()\ntitle=test['Title'].values\ntitle=pd.DataFrame(OneHotEncoder().fit_transform(title.reshape(-1,1)).toarray())\ntitle.columns=['Title1','Title2','Title3','Title4','Title5']\ntitle=title.iloc[:,:-1]\n\ntest=test.drop(['Title','Name'],axis=1)\ntest=pd.concat([test,title],axis=1)\n","9fe8b09b":"train.head()","1ebed9e5":"emb=pd.DataFrame(train['Embarked'])#Port from which they embarked\nsex=pd.DataFrame(train['Sex'])#The GENDER\ny=pd.DataFrame(train['Survived'])\ntrain_2=train.drop(['Embarked','Sex','Survived'],axis=1)\ntrain_2.columns=['Pclass','Age','SibSp','Parch','Fare','Title1','Title2','Title3','Title4']","cf0f4bca":"family_train= train_2[[\"Parch\", \"SibSp\"]].sum(axis=1)\n","3a752044":"#train_2.(4)","9f6bb7a7":"from sklearn.impute import SimpleImputer\nimp=SimpleImputer(strategy=\"most_frequent\")\ntrain_2=pd.DataFrame(imp.fit_transform(train_2))","aa69f8c3":"from sklearn.impute import SimpleImputer\nimp=SimpleImputer(strategy=\"most_frequent\")\nemb=pd.DataFrame(imp.fit_transform(emb))\nfrom sklearn.preprocessing import LabelEncoder ,OneHotEncoder\n#emb=pd.DataFrame(LabelEncoder().fit_transform(emb.values.ravel()))\nemb=pd.DataFrame(OneHotEncoder().fit_transform(emb).toarray())\nemb=emb.iloc[:,:-1]\nemb.columns=['Emb1','Emb2']","5c834ec9":"from sklearn.preprocessing import LabelEncoder\nsex=pd.DataFrame(LabelEncoder().fit_transform(sex))\nsex.columns=['Sex']","074c90d5":"#train_2.reset_index(drop=True, inplace=True)\n#sex.reset_index(drop=True, inplace=True)\n\ntrain_2=pd.concat([train_2,sex],axis=1)\ntrain_2=pd.concat([train_2,emb],axis=1)\n\"\"\"ADDING FAMILY SIZE IF IT WORKS\"\"\"\ntrain_2=pd.concat([train_2,family_train],axis=1)\ntrain_2.columns=['Pclass','Age','SibSp','Parch','Fare','Sex','Title1','Title2','Title3','Title4','Emb1','Emb2','FamilySize']\n#train_2.columns=['Pclass','Age','SibSp','Parch','Fare','Sex','Emb1','Emb2']\nfrom sklearn.preprocessing import MinMaxScaler\nsc1=MinMaxScaler()\nsc2=MinMaxScaler()\n#train_2['Age']=sc1.fit_transform(train_2['Age'].values.reshape(-1,1))\ntrain_2['Age']=pd.qcut(train_2['Age'].values,4,labels=False)\ntrain_2['Fare']=sc2.fit_transform(train_2['Fare'].values.reshape(-1,1))","bf4b60cc":"emb=pd.DataFrame(test['Embarked'])\nsex=pd.DataFrame(test['Sex'])\ny=pd.DataFrame(train['Survived'])\ntest_2=test.drop(['Embarked','Sex'],axis=1)\ntest_2.columns=['Pclass','Age','SibSp','Parch','Fare','Title1','Title2','Title3','Title4']\nfamily_test= test_2[[\"Parch\", \"SibSp\"]].sum(axis=1)\nfrom sklearn.impute import SimpleImputer\nimp=SimpleImputer(strategy=\"most_frequent\")\ntest_2=pd.DataFrame(imp.fit_transform(test_2))\nfrom sklearn.impute import SimpleImputer\nimp=SimpleImputer(strategy=\"most_frequent\")\nemb=pd.DataFrame(imp.fit_transform(emb))\nfrom sklearn.preprocessing import LabelEncoder ,OneHotEncoder\n#emb=pd.DataFrame(LabelEncoder().fit_transform(emb.values.ravel()))\nemb=pd.DataFrame(OneHotEncoder().fit_transform(emb).toarray())\nemb=emb.iloc[:,:-1]\nemb.columns=['Emb1','Emb2']\nfrom sklearn.preprocessing import LabelEncoder\nsex=pd.DataFrame(LabelEncoder().fit_transform(sex))\nsex.columns=['Sex']\n#train_2.reset_index(drop=True, inplace=True)\n#sex.reset_index(drop=True, inplace=True)\ntest_2=pd.concat([test_2,sex],axis=1)\ntest_2=pd.concat([test_2,emb],axis=1)\ntest_2=pd.concat([test_2,family_test],axis=1)\ntest_2.columns=['Pclass','Age','SibSp','Parch','Fare','Sex','Title1','Title2','Title3','Title4','Emb1','Emb2',\"FamilySize\"]\nfrom sklearn.preprocessing import MinMaxScaler\nsc1=MinMaxScaler()\nsc2=MinMaxScaler()\n#test_2['Age']=sc1.fit_transform(test_2['Age'].values.reshape(-1,1))\ntest_2['Age']=pd.qcut(test_2['Age'].values,4,labels=False)\ntest_2['Fare']=sc2.fit_transform(test_2['Fare'].values.reshape(-1,1))","621f9c2e":"\"\"\"from mlxtend.classifier import StackingClassifier\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nl=LogisticRegression(max_iter=500,solver='lbfgs')\nl.fit(X_train,y_train.values.ravel())\nfrom sklearn.svm import SVC\nclf2=SVC(kernel=\"linear\")\nclf2.fit(X_train,y_train.values.ravel())\nfrom xgboost import XGBClassifier\nxr=XGBClassifier(n_estimators=1000)\nxr.fit(X_train,y_train.values.ravel())\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression(max_iter=500,solver='lbfgs')\nsclf = StackingClassifier(classifiers=[lr, clf2,xr], \n                          meta_classifier=lm)\nsclf.fit(X_train,y_train)\"\"\"","c11ca40a":"from xgboost import XGBClassifier\nxr=XGBClassifier(n_estimators=1000)\nxr.fit(train_2,y.values.ravel())","a1064f76":"len(train_2.T)","fdc3e9d1":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\n\n# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 13, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units = 13, kernel_initializer = 'uniform', activation = 'relu'))\n\n#Adding a dropout layer\nclassifier.add(Dropout(rate=0.2))\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compiling the ANN\nclassifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Fitting the ANN to the Training set\nclassifier.fit(train_2, y, batch_size = 16, epochs = 300)\n\n# Part 3 - Making predictions and evaluating the model\n\n# Predicting the Test set results\ny_pred = classifier.predict(test_2)\ny_pred = (y_pred > 0.5)","18b679b9":"submission = pd.DataFrame(\n    { \n        'PassengerId': passid['PassengerId'].astype(int),\n        'Survived': y_pred.ravel().astype(int)\n    }\n)\nsubmission.to_csv(\"submission_final.csv\", index=False)","2bcf78b5":"#pd.Series(clf.feature_importances_,train_2.columns).sort_values().plot(kind=\"barh\")","c8fc22c9":"#pd.Series(clf2.feature_importances_,train_2.columns).sort_values().plot(kind=\"barh\")","2035e0bc":"#pd.Series(xr.feature_importances_,train_2.columns).sort_values().plot(kind=\"barh\")","7f6dae4d":"#import pandas_profiling as pp\n#pp.ProfileReport(train)","09917b77":"#from sklearn.model_selection import train_test_split\n#X_train, X_test, y_train, y_test = train_test_split(train_2, y, test_size=0.33, random_state=42)","fdaa77e2":"#from sklearn.metrics import confusion_matrix,classification_report\n#cm=confusion_matrix(y_test, xr.predict(X_test).astype(int))","34609da6":"\"\"\"\"from sklearn.model_selection import cross_val_score\naccuracies=cross_val_score(xr,X_train,np.array(y_train).ravel(),cv=10)\nACCURACIES=accuracies.mean()\nSTD=accuracies.std()\nprint(\"Accuracy Cross Val:\",ACCURACIES*100)\nprint(\"Std :\",STD*100)\"\"\"","e6d6318c":"\"\"\"acc=(cm[0][0]+cm[1][1])\/(cm[1][0]+cm[0][1]+cm[0][0]+cm[1][1])*100\nprint(\"Test acc:\",acc)\"\"\"","347412f9":"\"\"\"from sklearn import metrics\ny_pred_proba=l.predict_proba(X_test)[::,1]\nfpr,tpr,_=metrics.roc_curve(y_test,y_pred_proba)\nauc=metrics.roc_auc_score(y_test,y_pred_proba)\nplt.legend(loc=4)\nplt.plot(fpr,tpr,label=\"auc=\"+str(auc))\nplt.show()\"\"\"","860c1382":"#print(auc)\n","819f75e6":"**TRAIN**","b7163a54":"**TEST**","a7665f20":"#PERFORMING GRID SEARCH FOR PARAMETER SELECTION\n\"\"\"grid_param = {\n    'max_depth':[2,3,4,5],\n    'n_estimators': [100,500,1000],\n        'learning_rate': [0.05,0.1,0.15,0.20,0.30,0.35],\n    'reg_lambda':[1,2]\n    \n}\n\nfrom sklearn.model_selection import GridSearchCV\ngd_sr = GridSearchCV(estimator=clf,\n                     param_grid=grid_param,\n                     scoring='accuracy',\n                     cv=10\n                     )\ngd_sr.fit(train_2, y)\nbest_parameters = gd_sr.best_params_\nprint(best_parameters)\nbest_result = gd_sr.best_score_\nprint(best_result)\"\"\"","1d663ce8":"Cleaning procedure of **TEST COLUMNS**","80993860":"Family size could be another important feature over here.","45441bbf":"Encoding GENDER","635a9bd1":"For **GridSearchCV**","f6610d2a":"Joining the cleaned TRAINING PART back","a8231e83":"Cleaning and creation for titles","c51579fc":"* Embarked columns has missing values Ooof!\n* Then we LabelEncode it and create OneHotMatrix\n* Avoiding DummyVariaBle Trap","c175b186":"Fitting the various models"}}