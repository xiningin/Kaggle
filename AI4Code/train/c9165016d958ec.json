{"cell_type":{"c81b3c80":"code","6ee46dfd":"code","7029ed16":"code","287ed83f":"code","f5bbec24":"code","f60362a1":"markdown","a3a12d3e":"markdown","6cd6b653":"markdown","df3b6fca":"markdown","a4d5d688":"markdown"},"source":{"c81b3c80":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6ee46dfd":"# Import helpful libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBRegressor\n\n#Importing CSV files\nX_train_full=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/train.csv\")\nX_test_full=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/test.csv\")\n","7029ed16":"#Check if there are any rows with missing target values, and if so, delete them\n#missing_val_count_by_column = (X_train_full.isnull().sum())\n#print(missing_val_count_by_column[missing_val_count_by_column > 0])\n#X_train_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n\n#Create y_train,X_train_full\ny_train=X_train_full.SalePrice\nX_train_full.drop(['SalePrice'], axis=1, inplace=True)\n\n#Separate numeric data columns from categorical data columns\nX_train_full_num = X_train_full.select_dtypes(exclude=['object'])\nX_train_full_cat = X_train_full.select_dtypes(include=['object'])\nX_test_full_num = X_test_full.select_dtypes(exclude=['object'])\nX_test_full_cat = X_test_full.select_dtypes(include=['object'])\n\n#Remove columns with missing values in the category data\ncols_with_missing1 = [col for col in X_train_full_cat.columns if X_train_full_cat[col].isnull().any()] \ncols_with_missing2 = [col for col in X_test_full_cat.columns if X_test_full_cat[col].isnull().any()] \nbad_cat_list=list(set(cols_with_missing1)|set(cols_with_missing2))\nall_cat_list = [col for col in X_train_full_cat.columns]\nnomissing_cat_list=list(set(all_cat_list)-set(bad_cat_list))\nX_train_full_cat_nomissing=X_train_full_cat[nomissing_cat_list]\nX_test_full_cat_nomissing=X_test_full_cat[nomissing_cat_list]\n\n#Finally, we will create a data set that will be used in this analyses.\nX_train_full_final=pd.concat([X_train_full_num,X_train_full_cat_nomissing],axis=1)\nX_test_full_final=pd.concat([X_test_full_num,X_test_full_cat_nomissing],axis=1)\n\n","287ed83f":"# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='mean')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[('ordinal',OrdinalEncoder())])\n\n# Bundle preprocessing for numerical and categorical data\nnumerical_cols = [cname for cname in X_train_full_num.columns if X_train_full[cname].dtype in ['int64', 'float64']]\ncategorical_cols = [cname for cname in X_train_full_cat_nomissing.columns if X_train_full[cname].dtype == \"object\"]\npreprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),('cat', categorical_transformer, categorical_cols)])\n\n# Define model\n#This model has already been selected as the best one in the first intermediate course\n#So, using cross-validation may give better results (that's my future to-do)\nmodel = XGBRegressor(n_estimators=1000,learning_rate=0.05,n_jobs=4,random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),('model', model)])\n","f5bbec24":"clf.fit(X_train_full_final,y_train)\npreds=clf.predict(X_test_full_final)\noutput = pd.DataFrame({'Id': X_test_full.Id,'SalePrice': preds})\noutput.to_csv('submission.csv', index=False)","f60362a1":"# 3. Finally, fit and predict","a3a12d3e":"# 0.Import libraries and CSV files","6cd6b653":"# Explanation of this notebook\n- This code is a simple solution for those who have taken the Intermediate ML courses in Kaggle.\n- This code is not for the explanation of the lecture, but for creating a file for submission with the techniques learned in the course.\n- The following steps were used to analyze the data.\n1. Create a data set that will be used in this analyses\n2. Prepare to use pipeline for analysis\n3. Finally, fit and predict\n- This code is very simple, but it gave good results(Top5%!).\n- If you find any mistakes or problems with this code, please let me know in the comments!\n- Lastly, I'd love it if you'd give me a like!","df3b6fca":"# 2.Prepare to use pipeline for analysis","a4d5d688":"# 1.Create a data set that will be used in this analyses"}}