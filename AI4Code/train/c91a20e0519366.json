{"cell_type":{"9f5eaef2":"code","4e4698c1":"code","b3d341eb":"code","75e9e2e3":"code","d071e3e8":"code","9268b349":"code","3bd0c65d":"code","af266652":"code","d3f14481":"code","1631bdc7":"code","f3aa30a0":"code","aabd4936":"code","9b1eab0f":"code","aa494d6a":"code","92388c53":"code","e0a8208b":"code","4f4719bd":"code","7f77637a":"code","5021b3c0":"code","7b7bc598":"code","92da7fd4":"code","db6a5d52":"code","0b538087":"code","40b17e97":"code","af110186":"code","31242bec":"code","1e306323":"code","18271dc6":"code","078a6e14":"code","d0641f58":"code","c37abbd1":"code","55a36da6":"code","b92896c0":"code","cb866147":"code","d20f7bd8":"code","13939a35":"code","a4359bea":"code","6d133bfa":"code","84e911c3":"markdown","a2050f15":"markdown","0a02f348":"markdown","465ce2fc":"markdown","c47d84de":"markdown"},"source":{"9f5eaef2":"#Import all the required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom collections import Counter\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier","4e4698c1":"print(os.listdir(\"..\/input\"))","b3d341eb":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ngender_submission = pd.read_csv('..\/input\/gender_submission.csv')\ntrain.tail(5)","75e9e2e3":"print(train.shape)\nprint(test.shape)","d071e3e8":"import pandas_profiling\npandas_profiling.ProfileReport(train)","9268b349":"train_df_corr = train.corr()\nfig,ax = plt.subplots(figsize=(12,10))\nsns.heatmap(train_df_corr,annot=True);","3bd0c65d":"#let's remove the unwanted columns\ntrain_df = train.drop(['Name','Ticket','Cabin'],axis=1)\ntest_df = test.drop(['Name','Ticket','Cabin'],axis=1)\ntrain_df.head()","af266652":"#Check for missing values\ntrain_df.isnull().sum().sort_values(ascending=False)","d3f14481":"#Check for missing values\ntest_df.isnull().sum().sort_values(ascending=False)","1631bdc7":"# Replace Null Values (np.nan) with meadian & mode\ntrain_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())\ntest_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())\n\ntest_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median())\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n\n# Fit and transform to the parameters\ntrain_df['Embarked'] = imputer.fit_transform(train_df[['Embarked']])\n\n# train_df['Embarked'] = train_df['Embarked'].fillna(train_df['Embarked'].mode())","f3aa30a0":"print(\"Training Dataset :\\n\",train_df.isnull().sum().sort_values(ascending=False))\nprint()\nprint(\"Test Dataset :\\n\",test_df.isnull().sum().sort_values(ascending=False))\n\n# train_df = train_df.dropna()\n# test_df = test_df.dropna()","aabd4936":"train_df.describe()","9b1eab0f":"\nCounter(train_df['Survived'])","aa494d6a":"fx,ax = plt.subplots(figsize=(12,10))\nplt.scatter(train_df['Age'],train_df['Survived'])\nplt.xlabel('Age')\nplt.ylabel('Survived');","92388c53":"fig,ax = plt.subplots(figsize=(12,10))\nplt.scatter(train_df['Fare'],train_df['Survived'])\nplt.xlabel('Fare')\nplt.ylabel('Survived');","e0a8208b":"pd.crosstab(train_df['Sex'],train_df['Survived'])","4f4719bd":"pd.crosstab(train_df['Pclass'],train_df['Survived'])","7f77637a":"from sklearn.preprocessing import LabelEncoder\n\nlabel_encoding = LabelEncoder()\ntrain_df['Sex'] = label_encoding.fit_transform(train_df['Sex'].astype(str))\ntrain_df.sample(5)","5021b3c0":"test_df['Sex'] = label_encoding.fit_transform(test_df['Sex'].astype(str))\ntest_df.head()","7b7bc598":"train_df = pd.get_dummies(train_df,columns=['Embarked'])\ntrain_df.head()","92da7fd4":"test_df = pd.get_dummies(test_df,columns=['Embarked'])\ntest_df.head()","db6a5d52":"Pass_ID_test = test_df['PassengerId']\ntrain_df = train_df.drop(['PassengerId'],axis=1)\ntest_df = test_df.drop(['PassengerId'],axis=1)","0b538087":"len(Pass_ID_test)","40b17e97":"features = train_df.drop(['Survived'],axis=1)\ntarget = train_df['Survived']\nprint('Dimension of Fearures ;',features.shape)\nprint('Dimension of target column ;',target.shape)\nprint('Dimension of test dataset ;',test_df.shape)","af110186":"logistic_model = LogisticRegression(penalty='l2',C=1.0,solver='liblinear').fit(features,target)\ntest_pred = logistic_model.predict(test_df)\nlen(test_pred)","31242bec":"from sklearn.model_selection import GridSearchCV\nparameters = {'penalty': ['l1','l2'],\n             'C': [0.1,0.4,0.8,1,2,3,5]}\n\ngrid_search = GridSearchCV(LogisticRegression(solver='liblinear'),parameters,cv=3,return_train_score=True)\ngrid_search.fit(features,target)\n\ngrid_search.best_params_","1e306323":"for i in range(12):\n    print('Parameters: ',grid_search.cv_results_['params'][i])\n    print('Mean Test Score: ',grid_search.cv_results_['mean_test_score'][i])\n    print('Rank: ',grid_search.cv_results_['rank_test_score'][i])","18271dc6":"logistic_model = LogisticRegression(solver='liblinear',\\\n                                   penalty=grid_search.best_params_['penalty'],C=grid_search.best_params_['C']).\\\n                                   fit(features,target)","078a6e14":"test2_pred = logistic_model.predict(test_df)","d0641f58":"len(test2_pred)","c37abbd1":"## for the number of k neighbors\nk = list(range(1, 60, 2))\n\n## for the weights\nweights_options = ['uniform', 'distance']\n\n## for the algorithms applied \nalgos = ['ball_tree', 'kd_tree', 'brute']\n\n## leaf size (since i've initiated BallTree and KDTree algorithms)\nleaves = list(np.arange(10, 110, 10))\n\n## for the metrics\nmetric_options = ['euclidean', 'manhattan', 'chebyshev', 'minkowski']\n\n## for the parameters of the metrics\n#metric_params=metric_param_options\n\n# initializing the grid\n\nparams_grid = dict(n_neighbors=k, weights=weights_options, algorithm=algos, leaf_size=leaves, metric=metric_options)\n\n# initializing the grid search with 10 cross_validation splits\n\nmodel_KNN = KNeighborsClassifier() \n\ngrid = GridSearchCV(model_KNN, params_grid, cv=10, scoring='accuracy',n_jobs=-1)\n\n# training the model\ngrid.fit(features,target)","55a36da6":"print(f'best parameters: {grid.best_params_},\\nbest accuracy score: {grid.best_score_},\\nbest estimator: {grid.best_estimator_}')","b92896c0":"\nmodel_knn  = KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, metric='manhattan',\n                     metric_params=None, n_jobs=None, n_neighbors=15, p=2,weights='distance')\nmodel_knn.fit(features,target)\n\nkkn_test_pred = model_knn.predict(test_df)","cb866147":"logreg_test_submission = pd.DataFrame({'PassengerId':Pass_ID_test,'Survived':test2_pred})\nlogreg_test_submission.head()","d20f7bd8":"logreg_test_submission.shape","13939a35":"logreg_test_submission.to_csv(\"logreg_test_submission.csv\",index=False)","a4359bea":"knn_submission = gender_submission.copy()\n\nknn_submission['Survived'] = kkn_test_pred\n\nknn_submission.shape","6d133bfa":"knn_submission.head()","84e911c3":"## Logistics Regression Submission","a2050f15":"## KNN Submission","0a02f348":"## Classification Model 1: Logistic Regression","465ce2fc":"# Thank you ","c47d84de":"## Classification Model 2 : KNN"}}