{"cell_type":{"416491d6":"code","035c66e3":"code","dc33ab4e":"code","93250c52":"code","fb20a905":"code","68facba7":"code","80690dc2":"code","978f19ee":"code","529fc2f4":"code","86ccff00":"code","12a5f55e":"code","e5582a53":"code","a8f63462":"code","3d119cfc":"code","afe80b37":"code","f2ab3332":"code","0605807c":"code","72be0d02":"code","e25d5025":"code","57e38b3c":"code","f121c969":"code","9e25f65c":"code","3a3e5b33":"code","bbbea32e":"code","2b2b1967":"code","8ab71cc4":"code","0424d77d":"code","91adaebe":"code","2a96087e":"code","19bb79ae":"code","886ca8a9":"code","495781e1":"code","d91a7eee":"code","661fba7d":"code","0cae57d3":"code","8ae50330":"code","46ee6d57":"code","defea2e6":"code","547d24b9":"code","bf532163":"code","8371622b":"code","6c7b1963":"code","5b29f6e3":"code","1aec3651":"markdown","91a9f09d":"markdown","5a01e0f4":"markdown","4f3f91dd":"markdown","2e0a8e32":"markdown","c8a584ad":"markdown","b2e967b5":"markdown","1897b715":"markdown","4991d4fe":"markdown","d8398965":"markdown","7d162559":"markdown","2c1ca3e0":"markdown","69b7a6db":"markdown","fc07ab15":"markdown","c6cc45a4":"markdown","cdb6e9df":"markdown","8a6ad74f":"markdown","3837ef9d":"markdown","91eb1a1a":"markdown","be5011a6":"markdown","4a173b0b":"markdown","9e25cb54":"markdown","611af0ee":"markdown","e423f6ab":"markdown"},"source":{"416491d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","035c66e3":"from tensorflow import keras as ks\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport time\nimport datetime\nfrom keras.regularizers import l2\nimport random\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nimport tensorflow as tf","dc33ab4e":"inputs = ks.Input(shape=(32, 32, 3))","93250c52":"upscale = ks.layers.Lambda(lambda x: tf.image.resize_with_pad(x, 224,224, method=tf.image.ResizeMethod.BILINEAR))(inputs)","fb20a905":"ResNet152V2 = ks.applications.ResNet152V2(include_top=False, weights='imagenet', input_tensor=upscale, input_shape=(224,224,3), pooling='max')","68facba7":"ResNet152V2.summary()","80690dc2":"new_output_layer = ks.layers.Flatten()(ResNet152V2.layers[-1].output)\nResNet152V2= Model(ResNet152V2.input, new_output_layer)","978f19ee":"ResNet152V2.summary()","529fc2f4":"print(\"Is model trainable?\", ResNet152V2.trainable)","86ccff00":"pd.set_option('max_colwidth', None)\nlayers = [(layer, layer.name, layer.trainable) for layer in ResNet152V2.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])","12a5f55e":"entrenable = False\n\nfor layer in ResNet152V2.layers [:400]:\n  layer.trainable = entrenable","e5582a53":"pd.set_option('max_colwidth', None)\nlayers = [(layer, layer.name, layer.trainable) for layer in ResNet152V2.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])","a8f63462":"model= ks.Sequential()\n\nmodel.add(ResNet152V2)\n\nmodel.add(ks.layers.Dense(1024, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(ks.layers.BatchNormalization())\nmodel.add(ks.layers.Dropout(0.7))\nmodel.add(ks.layers.Dense(512, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(ks.layers.BatchNormalization())\nmodel.add(ks.layers.Dropout(0.7))\nmodel.add(ks.layers.Dense(256, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(ks.layers.BatchNormalization())\nmodel.add(ks.layers.Dropout(0.5))\nmodel.add(ks.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel.add(ks.layers.BatchNormalization())\nmodel.add(ks.layers.Dropout(0.3))\nmodel.add(ks.layers.Dense(10, activation='softmax'))\n","3d119cfc":"# model = ks.Sequential()\n\n# model.add(ks.layers.Conv2D(32, (3, 3), strides=1, activation='relu',\n#                            padding='same', kernel_initializer='he_uniform',input_shape=(32,32,3))) #convolution layer\n# model.add(ks.layers.LeakyReLU(0.1))\n# model.add(ks.layers.BatchNormalization())\n# model.add(ks.layers.Conv2D(32, (3, 3), strides=1, activation='relu',\n#                            padding='same',  kernel_initializer='he_uniform'))\n# model.add(ks.layers.LeakyReLU(0.1))\n# model.add(ks.layers.BatchNormalization())\n# model.add(ks.layers.MaxPooling2D((2, 2))) #Calculate the maximum value for each patch of the feature map.\n# model.add(ks.layers.Dropout(0.25)) #dropout to decrease overfitting\n\n# model.add(ks.layers.Conv2D(128, (3, 3), strides=1, activation='relu', \n#                            padding='same',  kernel_initializer='he_uniform'))\n# model.add(ks.layers.LeakyReLU(0.1))\n# model.add(ks.layers.BatchNormalization())\n# model.add(ks.layers.Conv2D(128, (3, 3), strides=1, activation='relu', \n#                            padding='same',  kernel_initializer='he_uniform'))\n# model.add(ks.layers.LeakyReLU(0.1))\n# model.add(ks.layers.BatchNormalization())\n# model.add(ks.layers.MaxPooling2D((2, 2)))\n# model.add(ks.layers.Dropout(0.5))\n\n# model.add(ks.layers.Conv2D(256, (3, 3), strides=1, activation='relu', \n#                            padding='same',kernel_initializer='he_uniform'))\n# model.add(ks.layers.LeakyReLU(0.1))\n# model.add(ks.layers.BatchNormalization())\n# model.add(ks.layers.Conv2D(256, (3, 3), strides=1, activation='relu', \n#                            padding='same',kernel_initializer='he_uniform'))\n# model.add(ks.layers.LeakyReLU(0.1))\n# model.add(ks.layers.BatchNormalization())\n# model.add(ks.layers.MaxPooling2D((2, 2)))\n# model.add(ks.layers.Dropout(0.25))\n\n# model.add(ks.layers.Flatten())\n# model.add(ks.layers.Dense(512, activation='relu',kernel_initializer='he_uniform'))\n# model.add(ks.layers.LeakyReLU(0.1))\n# model.add(ks.layers.BatchNormalization())\n# model.add(ks.layers.Dropout(0.6))\n# model.add(ks.layers.Dense(512, activation='relu',kernel_initializer='he_uniform'))\n# model.add(ks.layers.LeakyReLU(0.1))\n# model.add(ks.layers.BatchNormalization())\n# model.add(ks.layers.Dropout(0.6))\n# model.add(ks.layers.Dense(512, activation='relu',kernel_initializer='he_uniform'))\n# model.add(ks.layers.LeakyReLU(0.1))\n# model.add(ks.layers.BatchNormalization())\n# model.add(ks.layers.Dropout(0.6))\n# model.add(ks.layers.Dense(10, activation='softmax',kernel_initializer='he_uniform'))","afe80b37":"model.summary()","f2ab3332":"new_adam = Adam(lr=0.0003, decay=0, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nopt=SGD(lr=0.001, momentum=0.9)\nmodel.compile(optimizer=new_adam,\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","0605807c":"cifar10 = ks.datasets.cifar10\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nx_train_scaled, x_test_scaled = x_train \/ 255.0, x_test \/ 255.0","72be0d02":"y_train_label = y_train\n\ny_test\ny_train","e25d5025":"cifar10_labels = [\n'airplane', # id 0\n'automobile',\n'bird',\n'cat',\n'deer',\n'dog',\n'frog',\n'horse',\n'ship',\n'truck',\n]\n\nprint('Number of labels: %s' % len(cifar10_labels))","57e38b3c":"# Pintemos una muestra de las las imagenes del dataset MNIST\n\nprint('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\nprint('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n\nfor i in range(9):\n\n    plt.subplot(330 + 1 + i)\n    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(cifar10_labels[y_train_label[i,0]])\n\nplt.subplots_adjust(hspace = 1)\nplt.show()","f121c969":"x_val = x_train[-10000:]\ny_val = y_train[-10000:].ravel() #ravel() --> Return a contiguous flattened array.\n\nx_train = x_train[:-10000]\ny_train = y_train[:-10000].ravel()\n","9e25f65c":"#checking the results\nprint('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\nprint('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\nprint('Validation: X=%s, y=%s' % (x_val.shape, y_val.shape))","3a3e5b33":"callback_val_loss = EarlyStopping(monitor=\"val_loss\", patience=15)\ncallback_val_accuracy = EarlyStopping(monitor=\"val_accuracy\", patience=15)","bbbea32e":"# ruta_checkpoint = '\/tmp\/checkpoint'\n\n# callback_checkpoint = ModelCheckpoint(filepath=ruta_checkpoint,\n#                                       save_weights_only=True,\n#                                       monitor='val_accuracy', # Monitorizamos la accuracy de validacion\n#                                       mode='max', # Nos quedamos con el modelo con mayor accuracy\n#                                       save_best_only=True)","2b2b1967":"def apply_mask(image, size=12, n_squares=1):\n    h, w, channels = image.shape\n    new_image = image\n    for _ in range(n_squares):\n        y = np.random.randint(h)\n        x = np.random.randint(w)\n        y1 = np.clip(y - size \/\/ 2, 0, h)\n        y2 = np.clip(y + size \/\/ 2, 0, h)\n        x1 = np.clip(x - size \/\/ 2, 0, w)\n        x2 = np.clip(x + size \/\/ 2, 0, w)\n        new_image[y1:y2,x1:x2,:] = 0\n    return new_image","8ab71cc4":"import matplotlib.pyplot as plt\nprint(\"Original images:\")\nfor i in range(2):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(x_train[i])\nplt.show()\nprint(\"Images with cutout:\")\nfor i in range(2):\n    plt.subplot(330 + 1 + i)\n    plt.imshow(apply_mask(x_train[i]))\nplt.show()","0424d77d":"train_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    \n    #width_shift_range=[-4,4],\n    #height_shift_range=[-4,4],\n    #horizontal_flip=0.5, \n    #fill_mode=\"constant\",\n    #cval=0,\n    #preprocessing_function = apply_mask\n    \n    rotation_range=15,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.3\n    \n#     rotation_range=10,  \n#     zoom_range = 0.1, \n#     width_shift_range=0.1,  \n#     height_shift_range=0.1,\n#     shear_range = 0.1,\n#     horizontal_flip=True,  \n#     vertical_flip=False\n    \n    )\n\ntrain_generator = train_datagen.flow(\n    x_train,  \n    y_train, \n    batch_size=20\n) ","91adaebe":"validation_datagen = ImageDataGenerator(\n    rescale=1.\/255\n    )\nvalidation_generator = validation_datagen.flow(\n    x_val, \n    y_val, \n    batch_size=20\n)","2a96087e":"len(x_train)","19bb79ae":"sample = random.choice(range(0,4998))\n\nexample_generator = train_datagen.flow(\n    x_train[sample:sample+1],\n    y_train[sample:sample+1],\n    batch_size=64\n    )","886ca8a9":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X, Y in example_generator:\n        image = X[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","495781e1":"t = time.perf_counter()","d91a7eee":"len(x_train)","661fba7d":"x_train.shape[0]","0cae57d3":"epochs = 200\nbatch_size=20\nbatch_size_validation=20\nsteps = x_train.shape[0]\/batch_size\nval_steps = x_val.shape[0]\/batch_size_validation\n\nhistory = model.fit(train_generator, epochs=epochs, steps_per_epoch=steps, #number of unique samples of your dataset divided by the batch size\n                    validation_data=validation_generator, \n                    validation_steps = val_steps, # Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch.\n                    callbacks=[callback_val_loss, callback_val_accuracy])","8ae50330":"elapsed_time = datetime.timedelta(seconds=(time.perf_counter() - t))\n\nprint('Tiempo de entrenamiento:', elapsed_time)","46ee6d57":"_, acc = model.evaluate(x_test_scaled, y_test, verbose=0)\nprint('> %.3f' % (acc * 100.0))","defea2e6":"plt.title('Cross Entropy Loss')\nplt.plot(history.history['loss'], color='blue', label='train')\nplt.plot(history.history['val_loss'], color='orange', label='val')\nplt.legend()\nplt.show()\n\nplt.title('Classification Accuracy')\nplt.plot(history.history['accuracy'], color='blue', label='train')\nplt.plot(history.history['val_accuracy'], color='orange', label='val')\nplt.legend()\nplt.show()","547d24b9":"predictions = model.predict(x_test) #predictions in x_test","bf532163":"def plot_image(i, predictions_array, true_label, img):\n  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n  plt.grid(False)\n  plt.xticks([])\n  plt.yticks([])\n\n  plt.imshow(img, cmap=plt.cm.binary)\n\n  predicted_label = np.argmax(predictions_array)\n  if predicted_label == true_label:\n    color = 'blue'\n  else:\n    color = 'red'\n\n  plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n                                100*np.max(predictions_array),\n                                true_label[0]),\n                                color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n  predictions_array, true_label = predictions_array, true_label[i]\n  plt.grid(False)\n  plt.xticks(range(10))\n  plt.yticks([])\n  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n  plt.ylim([0, 1])\n  predicted_label = np.argmax(predictions_array)\n\n  thisplot[predicted_label].set_color('red')\n  thisplot[true_label[0]].set_color('blue')","8371622b":"i = 0\nfor l in cifar10_labels:\n    print(i, l)\n    i += 1\n\nnum_rows = 5\nnum_cols = 4\nstart = 650\nnum_images = num_rows*num_cols\nplt.figure(figsize=(2*2*num_cols, 2*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_image(i+start, predictions[i+start], y_test, x_test)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_value_array(i+start, predictions[i+start], y_test)\nplt.tight_layout()\nplt.show()","6c7b1963":"y_pred_model = model.predict_classes(x_test)\ny_true=np.argmax(y_test,axis=1)","5b29f6e3":"model.save('cifar10_base_model.h5')","1aec3651":"# Confusion Matrix","91a9f09d":"# 5. Callbacks\nThis callback allows you to specify the performance measure to monitor, the trigger, and once triggered, it will stop the training process. ","5a01e0f4":"# 10. Save model ","4f3f91dd":"# 4.Data Preparation ","2e0a8e32":"# 7. Results Data Generator\nIn this section, it is possible to see examples of the images that were created before","c8a584ad":"Graphic of how the error and the accuracy evolve in each epoch in the training data and in the validation","b2e967b5":"# 1. Libraries \n","1897b715":"# CutOut","4991d4fe":"# 3. Optimizer, error function","d8398965":"Fit - In this part I am going to generate images","7d162559":"Upload CIFAR-10 datasets. **Important:** neural network requires real numbers as inputs. So I will divide x_train and x_test by 255. ","2c1ca3e0":"# 2. Neural Network Architecture","69b7a6db":"The first images will be drawn, with the predictions and their real values (a total of 20 images, so as not to abuse your laptops)\n\nCorrect predictions will be painted blue and failures red. Even though you printed the labels first so we have a reference to the graphic.","fc07ab15":"It is necessary to prevent the over adjustment by stopping the fitting model when the validation error does not decrease after 15 epochs. ","c6cc45a4":"Let's paint a sample of the images from the CIFAR10 dataset, to see if it looks like we expect.\nFirst, we see what types of data I have, then we map those arrays in a grayscale using the **.Get_cmap ()** method of PlotLy with the first nine numbers of the dataset.","cdb6e9df":"When I added convolutions, it was necessary to \"pre-treat the data\", because **the convolution expects an array of 4 fields** (more like \"images\"), in the case of MNIST. CIFAR10 already has the right shape, but is better to check the size just in case.\n\nTherefore, when exiting the Convolution, you have to do a Flatten, because FullDense layers expect arrays, not matrix !!\n\nThen I print to see that everything is correct","8a6ad74f":"Checking the model with **.sumary()** function\n","3837ef9d":"# 9. Evaluating Results","91eb1a1a":"# 6. Data Augmentation\n","be5011a6":"CIFAR 10: Label array","4a173b0b":"Validation and Test - rescale validation and test","9e25cb54":"# 8. Fit","611af0ee":"It is time to start training the model. It is necessary to train against the data converted to the format expected by the Convolution.\nI will start with 20 epocs, that is, 20 complete passes of the dataset (which in turn will be with mini-batches internally), setting a batch of 512.\n\nThe **.fit ()** method also allows us to define if we have several CPUs, GPUs, and if we want to validate data at each end of epoch.","e423f6ab":"To start, I am going to upload some libraries that are necessary for this porject"}}