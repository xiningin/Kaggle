{"cell_type":{"c05b4e16":"code","c3487846":"code","625fc356":"code","3fe47dc5":"code","735e77ed":"code","bc8c31ee":"code","f6d74ec3":"code","d756ec62":"code","797c3e2f":"code","2fdfebae":"code","0f1132d8":"code","ac73fe8a":"code","e5de8d42":"code","c1bd17ab":"code","ad30e1df":"code","f7f27410":"code","c1f1cc84":"code","80f706d0":"code","4a82c8fe":"code","6ce1e7c7":"code","32ab3189":"code","2a8e8b96":"code","327ff381":"code","5c436f4f":"code","ebd04bcc":"code","d3da9e2f":"code","9a1db0bd":"code","7b1b6647":"code","c9766eb3":"code","d2c64bb6":"code","ae42b486":"code","4a3973d8":"code","3b487fe5":"code","bb8e7725":"code","1c350001":"code","8e48b2ba":"markdown","0fee3f5b":"markdown","f17fdd51":"markdown","2a7a6b33":"markdown","3ab51148":"markdown","a162fe5f":"markdown","9d8d581c":"markdown","e8b78828":"markdown","0ff351ac":"markdown","273f5965":"markdown","939a82d7":"markdown","93409daa":"markdown","d788eb59":"markdown","2bd7d930":"markdown","be83a94c":"markdown","d0b55b4e":"markdown"},"source":{"c05b4e16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker imAge: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packAges to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","c3487846":"train=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/train.csv\")\ntrain.head()","625fc356":"test=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/test.csv\")\ntest.head()","3fe47dc5":"sample=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/sample_submission.csv\")\nsample.head()","735e77ed":"train.info()","bc8c31ee":"train.describe()","f6d74ec3":"print(\"For train Data\")\nfor i in train.columns:\n    val=train[i].isnull().sum()\n    if val!=0:\n        print(\"The column {} contains {} Null values\".format(i,val))","d756ec62":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","797c3e2f":"print(\"For test Data\")\nfor i in test.columns:\n    val=test[i].isnull().sum()\n    if val!=0:\n        print(\"The column {} contains {} Null values\".format(i,val))","2fdfebae":"sns.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap='viridis')","0f1132d8":"plt.figure(figsize = (16, 7))\nsns.distplot(train['SalePrice'])\nplt.title('Distribution Plot of Sale Price\\n', fontsize =  20)\nplt.show()","ac73fe8a":"px.scatter(data_frame = train, x = 'SalePrice', y = 'RoofStyle', color = 'RoofStyle', template = 'plotly_dark')","e5de8d42":"px.histogram(data_frame = train, x = 'SalePrice', nbins = 8, color = 'CentralAir', marginal = 'box',\n             template = 'plotly_dark')","c1bd17ab":"px.bar(data_frame = train, x = 'HouseStyle', y = 'SalePrice', color = 'HouseStyle', template = 'plotly_dark',\n       title = 'Price to house style')","ad30e1df":"# total values in train data\ntrain.shape[0]","f7f27410":"dt_nan=[]\nfor i in train.columns:\n    val=train[i].isnull().sum()\n    if val>500:\n        dt_nan.append(i)\ndt_nan","c1f1cc84":"# total values in test data\ntest.shape[0]","80f706d0":"for i in test.columns:\n    val=test[i].isnull().sum()\n    if val>500:\n        dt_nan.append(i)\ndt_nan","4a82c8fe":"train=train.drop(list(set(dt_nan)),axis=1)\ntrain.head()","6ce1e7c7":"test=test.drop(list(set(dt_nan)),axis=1)\ntest.head()","32ab3189":"def impute_nan(df,variable):\n    df[variable]=df.fillna(value = {variable:df[variable].mode()})","2a8e8b96":"\nfor i in train.columns:\n    val=train[i].isnull().sum()\n    if val!=0:\n        impute_nan(train,i)","327ff381":"for i in test.columns:\n    val=test[i].isnull().sum()\n    if val!=0:\n        impute_nan(test,i)","5c436f4f":"from sklearn.preprocessing import  LabelEncoder\n# Encode each object type with a label using one hot encoding\ndef get_encoding(df):\n# loop over each column\n    for f in df.columns: \n        # check for object type\n        if df[f].dtype=='object':\n          #label encoder \n            lbl = LabelEncoder() \n            lbl.fit(list(df[f].values)) \n            df[f] = lbl.transform(list(df[f].values))\n\n# check the dataframe after label encoding\nget_encoding(train)\nget_encoding(test)","ebd04bcc":"train=train.drop(['Id'],axis=1)","d3da9e2f":"l=[]\nfor i in train.columns:\n    for j in train.columns:\n        if i!=j:\n            if train[i].corr(train[j])>0.9 or train[i].corr(train[j])<-0.9:\n                l.append(i)","9a1db0bd":"train=train.drop(l,axis=1)\ntest=test.drop(l,axis=1)","7b1b6647":"X=train.drop(['SalePrice'],axis=1)\nY=train[\"SalePrice\"]","c9766eb3":"from sklearn.model_selection import train_test_split\n# split the data to train and test set\nx_train,x_test,y_train,y_test = train_test_split(X,Y,train_size=0.85,random_state=42)\n\n\nprint(\"training data shape:-{} labels{} \".format(x_train.shape,y_train.shape))\nprint(\"testing data shape:-{} labels{} \".format(x_test.shape,y_test.shape))","d2c64bb6":"from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn.metrics import r2_score\n\n# train Random forest regressor\n\n# create the model\nmodel_rf = RandomForestRegressor(n_estimators=500, oob_score=True, random_state=100)\n\nprint(\"Training..........\")\n# fitting the model\nmodel_rf.fit(x_train, y_train) \n\n# get original predictions\npred_train_rf= model_rf.predict(x_train)\n\nprint(\"Training Evaluation\")\nprint(\"Mean Square Error\",np.sqrt(mean_squared_error(y_train,pred_train_rf)))\nprint(\"R2 Score\",r2_score(y_train, pred_train_rf))\n\nprint(\"Testing Evaluation\")\n# testing predictions\npred_test_rf = model_rf.predict(x_test)\nprint(\"Mean Square Error\",np.sqrt(mean_squared_error(y_test,pred_test_rf)))\nprint(\"R2 Score\",r2_score(y_test, pred_test_rf))","ae42b486":"test=test.drop(['Id'],axis=1)","4a3973d8":"predictions_rf = model_rf.predict(test)","3b487fe5":"test_df=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/test.csv\")\ntest_df.head()","bb8e7725":"output = pd.DataFrame({'Id': test_df.Id, 'SalePrice': list(predictions_rf)})\noutput.to_csv('submission.csv', index=False)","1c350001":"output.head()","8e48b2ba":"## Now let's fill null values for other data in the dataset using the mode","0fee3f5b":"## Get predictions","f17fdd51":"# Read in the data","2a7a6b33":"### We see we have same rows in both train and test data let's remove the rows from both train and test dataset","3ab51148":"# Data Prepration","a162fe5f":"## Traing Data ","9d8d581c":"## Removing correlated columns","e8b78828":"# Feature engineering","0ff351ac":"### Since there are a total 1459 values in training data so columns with more than 500 Null values can be removed.","273f5965":"### Since there are a total 1460 values in training data so columns with more than 500 Null values can be removed.","939a82d7":"Most of the price range varies from 1000 to 400000","93409daa":"## Testing data","d788eb59":"# Modeling Random Forest","2bd7d930":"## Labeling each object","be83a94c":"# Data Analysis","d0b55b4e":"## There are lots of feature with more than seventy percent Null values. Let's find all those features and remove it from dataset for better accuracy"}}