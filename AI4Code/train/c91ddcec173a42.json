{"cell_type":{"30b3681d":"code","94b599a7":"code","512b4fb1":"code","6808414a":"code","b040e405":"code","9fb4da48":"code","f12c4563":"code","06f8baff":"code","e608f71d":"code","cedf200c":"code","e36897d1":"code","1a6aea18":"code","1d3ed721":"code","d40d7e73":"code","86168ab2":"code","a0c4e26a":"code","65b7daf6":"markdown","f3ed8f16":"markdown","b4e6c715":"markdown","a72b3799":"markdown","0ff91d44":"markdown","c5d8d4c5":"markdown","50adbf3b":"markdown","9c6e8df5":"markdown","bda2696d":"markdown"},"source":{"30b3681d":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()","94b599a7":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras import initializers\nfrom keras.optimizers import Adam","512b4fb1":"generator = Sequential()\ngenerator.add(layers.Dense(256, input_shape=(100,), kernel_initializer=initializers.RandomNormal(stddev = 0.02)))\ngenerator.add(layers.LeakyReLU(alpha=0.2))\ngenerator.add(layers.Dense(512))\ngenerator.add(layers.LeakyReLU(alpha=0.2))\ngenerator.add(layers.Dense(1024))\ngenerator.add(layers.LeakyReLU(alpha=0.2))\ngenerator.add(layers.Dense(28*28, activation='tanh'))","6808414a":"optimizer = Adam(lr=0.0002, beta_1=0.5)\ngenerator.compile(optimizer= optimizer, loss='binary_crossentropy')\ngenerator.summary()","b040e405":"def generate_images(count=1):\n    input = np.random.normal(0, 1, size=[count, 100])\n    images = generator.predict(input)\n    images *= 255 # pixels should be in range 0-255\n    images = images.reshape((count, 28, 28))\n    return images\n    ","9fb4da48":"image = generate_images(3)\nplt.figure(figsize=(15,5))\nfor i in range(3):\n    plt.subplot('13{0}'.format(i+1))\n    plt.imshow(image[i], cmap='gray')\nplt.show()","f12c4563":"discriminator = Sequential()\ndiscriminator.add(layers.Dense(1024, input_dim=784))\ndiscriminator.add(layers.LeakyReLU(0.2))\ndiscriminator.add(layers.Dropout(0.3))\ndiscriminator.add(layers.Dense(512))\ndiscriminator.add(layers.LeakyReLU(0.2))\ndiscriminator.add(layers.Dropout(0.3))\ndiscriminator.add(layers.Dense(256))\ndiscriminator.add(layers.LeakyReLU(0.2))\ndiscriminator.add(layers.Dropout(0.3))\ndiscriminator.add(layers.Dense(1, activation='sigmoid'))\n","06f8baff":"discriminator.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\ndiscriminator.summary()","e608f71d":"gan = Sequential()\ngan.add(generator)\ndiscriminator.trainable = False\ngan.add(discriminator)\ngan.compile(optimizer=optimizer, loss='binary_crossentropy')\ngan.summary()","cedf200c":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nsamples = train_data.drop(columns='label').values\nsamples = samples\/255 - 1","e36897d1":"history = pd.DataFrame(columns=['d_loss', 'd_acc', 'gan_loss'])","1a6aea18":"\ndef train(batch_size=32, epochs=1):\n    half_batch_size = np.floor(batch_size\/2).astype(np.int32)\n    steps = int(len(samples)\/batch_size)\n    for epoch in range(epochs):\n        for step in range(steps):\n            y = np.zeros(batch_size) #fake_images\n            y[:half_batch_size] = 0.9  # real images\n            generated_images = generator.predict(np.random.normal(0, 1, size=[half_batch_size, 100]))\n            real_images = samples[np.random.randint(0, samples.shape[0], size=half_batch_size)]\n            x = np.concatenate((generated_images,real_images))\n            discriminator.trainable = True\n            d_metrics = discriminator.train_on_batch(x, y)\n            noise = np.random.normal(0, 1, size=[batch_size, 100])\n            discriminator.trainable = False\n            gan_loss = gan.train_on_batch(noise, np.zeros(batch_size))\n            history.loc[epoch*steps+steps] = [d_metrics[0], d_metrics[1], gan_loss]\n        # visualize training progress\n        str = f'Epoch {epoch}: [D loss: {d_metrics[0]} acc: {d_metrics[1]}] | [G loss: {gan_loss}'\n        print(str)\n        images = generate_images(9)\n        plt.figure(figsize=(15,5))\n        for i in range(9):\n            plt.subplot('19{0}'.format(i+1))\n            plt.imshow(images[i], cmap='gray_r' ,interpolation='nearest')\n        plt.show()\n\n\n    return history","1d3ed721":"history = train(batch_size=128, epochs=20)","d40d7e73":"plt.figure(figsize=(15, 5))\nplt.title('Discriminator loss')\nplt.plot(history['d_loss'])","86168ab2":"plt.figure(figsize=(15, 5))\nplt.title('GAN loss')\nplt.plot(history['gan_loss'])","a0c4e26a":"images = generate_images(9)\nplt.figure(figsize=(15,5))\nfor i in range(9):\n    plt.subplot('19{0}'.format(i+1))\n    plt.imshow(images[i], cmap='gray_r' ,interpolation='nearest')\nplt.savefig('generated_digits.png')","65b7daf6":"## GAN - Generative Adversarial Network","f3ed8f16":"### training","b4e6c715":"GAN loss","a72b3799":"Generator as an input will take vector of length 100 with random numbers in range (0, 1)","0ff91d44":"Untrained generator generates something like that","c5d8d4c5":"## Generator","50adbf3b":"Discriminator will try to detect if the input image is made by generator or it is real.","9c6e8df5":"Descriminator loss","bda2696d":"## Discriminator"}}