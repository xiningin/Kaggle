{"cell_type":{"49917836":"code","76dd49f3":"code","94a1a61d":"code","576a21a1":"code","d9837974":"code","8677f09a":"code","09785677":"code","c05300b8":"code","55cec333":"code","c8305c1b":"code","cc21c215":"code","efeade98":"code","5d1b4549":"code","e134da6e":"code","e18507f9":"code","cfbf15c6":"code","91045045":"code","28293a28":"code","8d5f4b27":"markdown","b3f8d020":"markdown","f4325b45":"markdown","b769dc60":"markdown","5d60295f":"markdown","b87fcad1":"markdown","5053a495":"markdown","a8ec8e67":"markdown","dad3f63f":"markdown","482bf6de":"markdown","58d32585":"markdown"},"source":{"49917836":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76dd49f3":"import matplotlib.pyplot as plt\nfrom PIL import Image\nfrom keras.models import Sequential\nimport keras, shutil\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, AveragePooling2D, Input, BatchNormalization, Activation, Add\nfrom keras.initializers import glorot_uniform\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator","94a1a61d":"path = '\/kaggle\/input\/face-mask-dataset\/data'\n# print directories\nprint(os.listdir(path))\n\n# print number of samples in each class\nprint(\"with_mask samples: \", len(os.listdir(os.path.join(path, 'with_mask'))))\nprint(\"without_mask samples: \", len(os.listdir(os.path.join(path, \"without_mask\"))))","576a21a1":"os.mkdir('\/kaggle\/temp')\nos.mkdir('\/kaggle\/temp\/with_mask')\nos.mkdir('\/kaggle\/temp\/without_mask')\n\nfor filename1, filename2 in zip(os.listdir(path + '\/with_mask'), os.listdir(path + '\/without_mask')):\n    shutil.copy(os.path.join(path, 'with_mask\/' + filename1), '\/kaggle\/temp\/with_mask')\n    shutil.copy(os.path.join(path, 'without_mask\/' + filename2), '\/kaggle\/temp\/without_mask')","d9837974":"# create necessary directories for training and validation set\ntemp_path = '\/kaggle\/temp\/'\n#os.mkdir(temp_path)\n\nos.mkdir(os.path.join(temp_path, 'train'))\nos.mkdir(os.path.join(temp_path, 'train\/with_mask'))\nos.mkdir(os.path.join(temp_path, 'train\/without_mask'))\n\nos.mkdir(os.path.join(temp_path, 'val'))\nos.mkdir(os.path.join(temp_path, 'val\/with_mask'))\nos.mkdir(os.path.join(temp_path, 'val\/without_mask'))\n\n# print directories\nprint(os.listdir(temp_path))","8677f09a":"# Move the data from '\/kaggle\/input\/face-mask-detection\/data' to 'train' and 'val' directories\n\npath = '\/kaggle\/temp\/'\n\n# move to 'train' directory\nfor filename in os.listdir(os.path.join(path, 'with_mask'))[0:2800]:\n    src_path = os.path.join(path, 'with_mask\/' + filename)\n    dst_path = os.path.join(temp_path, 'train\/with_mask\/')\n    shutil.move(src_path, dst_path)\n\nfor filename in os.listdir(os.path.join(path, 'without_mask'))[0:2800]:\n    src_path = os.path.join(path , 'without_mask\/' + filename)\n    dst_path = os.path.join(temp_path, 'train\/without_mask\/')\n    shutil.move(src_path, dst_path)\n    \n# move rest of the files to the 'val' directory\nfor filename in os.listdir(os.path.join(path, 'with_mask')):\n    src_path = os.path.join(path, 'with_mask\/' + filename)\n    dst_path = os.path.join(temp_path, 'val\/with_mask\/')\n    shutil.move(src_path, dst_path)\n    \nfor filename in os.listdir(os.path.join(path, 'without_mask')):\n    src_path = os.path.join(path, 'without_mask\/' + filename)\n    dst_path = os.path.join(temp_path, 'val\/without_mask\/')\n    shutil.move(src_path, dst_path)","09785677":"# remove 'with_mask' and 'without_mask' directory from '\/kaggle\/temp\/'\nos.rmdir(path + 'with_mask')\nos.rmdir(path + 'without_mask')\n\nprint(os.listdir(path))","c05300b8":"# print number of samples in training and validation set\nprint(\"\\n ---------------  Training samples  ------------------ \\n\")\nprint(\"with_mask samples: \", len(os.listdir(os.path.join(path, 'train\/with_mask'))))\nprint(\"without_mask samples: \", len(os.listdir(os.path.join(path, 'train\/without_mask'))))\n\nprint(\"\\n ---------------  Validation samples  --------------------\\n\")\nprint(\"with_mask samples: \", len(os.listdir(os.path.join(path, 'val\/with_mask'))))\nprint(\"without_mask samples: \", len(os.listdir(os.path.join(path, 'val\/without_mask'))))","55cec333":"# create Image Data Generator\ndatagen = ImageDataGenerator(rescale = 1.0\/255, horizontal_flip = True, \n                            rotation_range = 20, \n                            width_shift_range =  0.2,\n                            height_shift_range = 0.2)\n\ntrain_batch_size = 32\ntrain_dir = '\/kaggle\/temp\/train\/'\n\n# create train generator\ntrain_gen = datagen.flow_from_directory(train_dir,\n                                       target_size = (224, 224),\n                                       batch_size = train_batch_size,\n                                       class_mode = 'categorical')\n\nval_batch_size = 32\nval_dir = '\/kaggle\/temp\/val\/'\n\n# create val generator\nval_gen = datagen.flow_from_directory(val_dir,\n                                     target_size = (224, 224),\n                                     batch_size = val_batch_size,\n                                     class_mode = 'categorical')","c8305c1b":"# print label encoding\nprint(train_gen.class_indices)","cc21c215":"# get number of samples in training set and val set\ntrain_num_samples = 0\n\nfor _, _, filenames in os.walk('\/kaggle\/temp\/train\/'):\n    train_num_samples += len(filenames)\n    \nval_num_samples = 0\n\nfor _, _, filenames in os.walk('\/kaggle\/temp\/val\/'):\n    val_num_samples += len(filenames)\n    \nprint(\"train_num_samples: \",train_num_samples)\nprint(\"val_num_samples: \",val_num_samples)","efeade98":"x, y = train_gen.next()\nplt.figure(figsize = (15, 15))\n\nfor i, (img, label) in enumerate(zip(x, y)):\n    plt.subplot(8, 4, i+1)\n    \n    if label == 0:\n        plt.title(\"with mask\")\n    else:\n        plt.title(\"without mask\")\n        \n    plt.axis('off')\n    plt.imshow(img)","5d1b4549":"def identity_block(X, f, filters, stage, block):\n    \"\"\"\n    Implementation of the identity block\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string\/character, used to name the layers, depending on their position in the network\n    \n    Returns:\n    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n    \n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve filters\n    F1, F2, F3 = filters\n    \n    # Save the input value\n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1,1), strides = (1,1), padding = 'valid', \n               name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name = bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f,f), strides = (1,1), padding='same',\n              name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name = bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n    \n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1,1), strides = (1,1), padding='valid',\n              name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name = bn_name_base + '2c')(X)\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","e134da6e":"def convolution_block(X, f, filters, stage, block, s=2):\n    \"\"\"\n    Implementation of the convolution block\n    \n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle Conv's window for the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string\/character , used to name the layers, depending on their position in the network\n    s -- integer, specifying the stride to be used\n    \"\"\"\n    \n    # defining the name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n    \n    # Retrieve filters\n    F1, F2, F3 = filters\n    \n    # Save the input\n    X_shortcut = X\n    \n    # First component of main path\n    X = Conv2D(filters = F1, kernel_size = (1,1), strides = (s,s), padding='valid',\n              name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n    \n    # Second component of main path\n    X = Conv2D(filters = F2, kernel_size = (f,f), strides = (1,1), padding='same',\n              name=conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n    \n    # Third component of main path\n    X = Conv2D(filters = F3, kernel_size = (1,1), strides = (1,1), padding='valid',\n              name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base+'2c')(X)\n    \n    # Shortcut path\n    X_shortcut = Conv2D(filters = F3, kernel_size = (1,1), strides = (s,s), padding='valid',\n                      name=conv_name_base+'1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base+'1')(X_shortcut)\n    \n    # Final step, Add shortcut value to main path and pass it through a Relu activation\n    X = Add()([X, X_shortcut])\n    X = Activation('relu')(X)\n    \n    return X","e18507f9":"def ResNet50(input_shape=(64, 64, 3), classes=2):\n    \n    # define the input as a tensor with shape input_shape\n    X_input = Input(shape=input_shape)\n    \n    # Stage 1\n    X = Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding='valid',\n              name='conv1', kernel_initializer = glorot_uniform(seed=0))(X_input)\n    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D(pool_size=(3,3), strides=(2,2))(X)\n    \n    # Stage 2\n    X = convolution_block(X, f=3, filters=[64,64,256], stage=2, block='a', s=2)\n    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block='b')\n    X = identity_block(X, f=3, filters=[64,64,256], stage=2, block='c')\n    \n    # Stage 3\n    X = convolution_block(X, f=3, filters=[128,128,512], stage=3, block='a', s=2)\n    X = identity_block(X, f=3, filters=[128,128,512],stage=3, block='b')\n    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block='c')\n    X = identity_block(X, f=3, filters=[128,128,512], stage=3, block='d')\n    \n    # Stage 4\n    X = convolution_block(X, f=3, filters=[256,256,1024], stage=4, block='a', s=2)\n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='b')\n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='c')\n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='d')\n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='e')\n    X = identity_block(X, f=3, filters=[256,256,1024], stage=4, block='f')\n    \n    # Stage 5\n    X = convolution_block(X, f=3, filters=[512,512,2048], stage=5, block='a', s=2)\n    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block='b')\n    X = identity_block(X, f=3, filters=[512,512,2048], stage=5, block='c')\n    \n    # AVGPool\n    X = AveragePooling2D(pool_size=(2,2), padding='same')(X)\n    \n    # output layer\n    X = Flatten()(X)\n    X = Dense(units=classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n    \n    # create model\n    model = keras.Model(inputs = X_input, outputs=X, name='ResNet50')\n    \n    return model","cfbf15c6":"model = ResNet50(input_shape = (224,224,3), classes=2)\n\n# print model summary\nmodel.summary()","91045045":"# learning rate decay\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate = 0.001,\n                                                         decay_steps = 5,\n                                                         decay_rate = 0.2)\n# compile the model\nmodel.compile(loss='categorical_crossentropy', \n             optimizer = Adam(learning_rate=0.00002),\n             metrics=['accuracy'])\n\n# calculate train_steps and val_steps\ntrain_steps = np.ceil(train_num_samples \/ train_batch_size)\nval_steps = np.ceil(val_num_samples \/ val_batch_size)\n#print(val_steps.dtype)\n# train the model\nhistory = model.fit_generator(train_gen,\n                             steps_per_epoch = train_steps,\n                             epochs = 15,\n                             validation_data = val_gen,\n                             validation_steps = val_steps)","28293a28":"# plot the accuracy of the model\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n\n# plot the loss of the model\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.legend(['train','val'], loc='upper left')\nplt.show()\n\n# save the model\nmodel.save(\"\/kaggle\/working\/face_mask_detection.h5\")","8d5f4b27":"## Create 50 Layer ResNet Model acrhitecture","b3f8d020":"## Visualize images generated by the Image Generator","f4325b45":"Now  let's create training and validation set. To create training and validation set, first i will create the temp directory and inside this directory i will create the \"train\" and \"val\" directory. Both directories ('train' and 'val') will also have the sub directories 'with_mask' and 'without_mask'.\n\nAfter that I will move 2800 images from each class to train directory and rest of images will be used as the validation set which i will move to the val directory.\n\nIt means that out of 7553 samples (images), 5600 samples will be used for the training set and 1952 (about 26%) will be used as the validation set.","b769dc60":"### Building the model\n\nWe now have the necessary blocks to build a very deep ResNet. The details of the ResNet-50 model are as follows:\n\n- Stage 1:\n  - The 2D convolution has 64 filters of shape (7,7) and uses a stride of (2,2). Its name is \"conv1\".\n  - BatchNorm is applied to the channels axis of the input\n  - MaxPooling uses a 3x3 window and a (2,2) stride\n- Stage 2:\n  - The convolution block uses three set of filters of size [64,64,256], \"f\" is 3, \"s\" is 1 and the block is \"a\"\n  - The 2 identity blocks use three sets of filters of size [64,64,256], \"f\" is 3, and the blocks are \"b\" and \"c\"\n- Stage 3:\n  - The convolution block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\"\n  - Three identity blocks use three sets of filters of size [128,128,512], \"f\" is 3, and the blocks are \"b\", \"c\", and \"d\"\n- Stage 4:\n  - The convolution block uses three sets of filters of size [256,256,1024],\"f\" is 3, \"s\" is 2 and the block is \"a\"\n  - The 5 identity block use three sets of filters of size [256,256,1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\"\n- Stage 5:\n  - The convolution block uses three sets of filters of size [512,512,2048], \"f\" is 3, \"s\" is 2 and the block is \"a\"\n  - The 2 identity block use three sets of filters of size [512,512,2048], \"f\" is 3 and the blocks are \"b\" and \"c\"\n- The 2D AveragePooling uses a window of shape (2,2) and its name 'avg_pool'.\n- The 'Flatten' layer doesn't have any hyperparameters or name.\n- The Fully Connected (Dense) layers reduces its input to the number of classes using a softmax activation.","5d60295f":"## Compile, Train and Evaluate the model","b87fcad1":"Let's first define the identity_block used in ResNet.\n\n### Identity Block\nThe identity block is the standard block used in ResNets, and corresponds to the case where the input activation (say $a^{[l]}$)has the same dimension as the output activation (say $a^{[l+2]}$).\n\n- Use 0 as the seed for random initialization\n- BatchNorm is normalizing the 'channels' axis","5053a495":"### Convolution block\n\nThe ResNet \"convolution block\" is the second block type. You can use this block when the input and the output dimensions don't match up. The difference with the identity block is that there is a Conv2D layer in the shortcut path.\n\n- The Conv2D layer in the shortcut path is used to resize the input X to a different dimension, so that the dimensions match up in the final addition to add the shortcut value back to the main path.\n- For example, to reduce the activation dimensions height and width by a factor of 2, you can use a 1x1 convolution with a stride of 2.","a8ec8e67":"# Face Mask Detection","dad3f63f":"## 2. Load Data","482bf6de":"as you can see that **with_mask** class contains 3725 samples and **without_mask** contains 3828 samples.","58d32585":"## 1. Load necessary libraries"}}