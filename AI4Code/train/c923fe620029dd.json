{"cell_type":{"16d0f354":"code","084de419":"code","c943b006":"code","1827c197":"code","6c061cca":"code","80e594d1":"code","309d20b5":"code","1baf4156":"code","1f6d6e4b":"code","f12acd08":"code","00db4544":"code","52465587":"code","3ce00d65":"code","d21dead6":"code","2d242241":"code","44c4d8e9":"code","a0a46155":"code","c7ff68ba":"code","6d1db78c":"code","eecc1d7c":"code","bbf2655f":"code","75aa2236":"code","e025f26b":"code","f8ae5386":"code","ec02c020":"code","d63aa135":"code","1facd65f":"code","9ab0908d":"code","2383f247":"markdown","c89cef11":"markdown","9923ee8a":"markdown","2c34da80":"markdown","7bfcd957":"markdown","a70b38e3":"markdown","ab3c6668":"markdown","f4bf483f":"markdown","aebad7b1":"markdown"},"source":{"16d0f354":"import pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv('\/kaggle\/input\/tabular-playground-series-may-2021\/train.csv', index_col = 'id')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-may-2021\/test.csv', index_col = 'id')\ntrain","084de419":"test","c943b006":"train.shape","1827c197":"test.shape","6c061cca":"target = train.target.copy()\ntarget","80e594d1":"train.drop('target', axis = 1, inplace = True)\ntrain","309d20b5":"(train.columns).equals(test.columns)","1baf4156":"train_test = pd.concat([train, test], keys = ['train', 'test'], axis = 0)\ntrain_test","1f6d6e4b":"train_test = (train_test - train_test.mean()) \/ train_test.std()\ntrain = train_test.xs('train').copy()\ntest = train_test.xs('test').copy()\ntrain","f12acd08":"class_map = {\n    'Class_1': 0,\n    'Class_2': 1,\n    'Class_3': 2,\n    'Class_4': 3,\n}\n\ntarget = target.map(class_map).astype('int')\n\ntarget","00db4544":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\ntf.random.set_seed(1)","52465587":"train_test.head(5)","3ce00d65":"def df_inputSwapNoise(df, p):\n    \"\"\"\n    Custom function for implementing swap noise.\n    It takes: DataFrame of data, percentage of values to be replaced;\n    And it outputs: DataFrame with noise.\n    \"\"\"\n    n = df.shape[0]\n    idx = list(range(n))\n    swap_n = round(n * p)\n    for col in df.columns:\n        arr = df[col].values\n        col_vals = np.random.permutation(arr)\n        swap_idx = np.random.choice(idx, size = swap_n)\n        arr[swap_idx] = np.random.choice(col_vals, size = swap_n)\n        df[col] = arr\n    return df","d21dead6":"noisy_train_test = df_inputSwapNoise(train_test.copy(), 0.15)","2d242241":"noisy_train_test.equals(train_test)","44c4d8e9":"pd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nsns.set_style('whitegrid')\n\nplt.figure(figsize = (16, 12))\nsns.barplot(x = (-noisy_train_test.eq(train_test)).sum(), y = noisy_train_test.eq(train_test).sum().index, palette = 'winter_r')","a0a46155":"autoencoder = keras.Sequential([layers.Dense(input_shape = [noisy_train_test.shape[1]], \n                                             units = 1500, activation = 'relu'),\n                                layers.Dense(units = 1500, activation = 'relu'),\n                                layers.Dense(units = 1500, activation = 'relu'),\n                                layers.Dense(units = noisy_train_test.shape[1], activation = 'linear')])\n\nautoencoder.compile(optimizer = 'adam',\n                    loss = 'mse')","c7ff68ba":"autoencoder.summary()","6d1db78c":"autoencoder.fit(\n    noisy_train_test, \n    train_test, \n    epochs = 1000,\n    batch_size = 128,\n)","eecc1d7c":"layers_list = [layer.output for layer in autoencoder.layers[:-1]]","bbf2655f":"feat_extraction_model = keras.Model(inputs = autoencoder.input, outputs = layers_list)","75aa2236":"ext_features = feat_extraction_model.predict(train_test)","e025f26b":"ext_features","f8ae5386":"ext_features[0].shape","ec02c020":"train_test_dae = pd.DataFrame()\nfor n in range(len(layers_list)):\n    dae = pd.DataFrame(data = ext_features[n], \n                       columns = [f'feature_{ext_features[0].shape[1] * n + i}' for i in range(ext_features[n].shape[1])])\n    train_test_dae = pd.concat([train_test_dae, dae], axis = 1)","d63aa135":"train_test_dae.index.name = 'id'\ntrain_test_dae","1facd65f":"train_dae = train_test_dae.iloc[:train.shape[0]]\ntest_dae = train_test_dae.iloc[train.shape[0]:]","9ab0908d":"train_dae.to_csv('train_dae.csv')\ntest_dae.to_csv('test_dae.csv')","2383f247":"Plotting amount of noise per feature:","c89cef11":"# 1. Meeting our data","9923ee8a":"# 3.3 Extracting features","2c34da80":"# 3.2 Creating and fitting DAE","7bfcd957":"# 3.1 Implementing swap noise","a70b38e3":"# 3. Implementing Denoising Autoencoder","ab3c6668":"# Table of contents:\n\n1. Meeting our data\n\n2. Doing a bit of preprocessing\n\n3. Implementing Denoising Autoencoder\n\n    3.1 Implementing swap noise\n    \n    3.2 Creating and fitting DAE\n    \n    3.3 Extracting features","f4bf483f":"# 2. Doing a bit of preprocessing","aebad7b1":"# Introduction\nGreetings!\ud83d\udc4b\n\nIn this kernel you will find my data science approach to \"Tabular Playground Series - May 2021\" competition using **D**enoising **A**uto**e**ncoders with swap noise. As always, any feedback Is very much appreciated! :)\n\nCheck out my other notebooks about this competition:\n\n* [EDA+LGBM+Optuna using GPU](https:\/\/www.kaggle.com\/aipi12\/eda-lgbm-optuna-using-gpu)\n\n* [EDA+CatBoost+Optuna](https:\/\/www.kaggle.com\/aipi12\/eda-catboost-optuna)\n\nFor more information about DAE and swap noise technique:\n\n* https:\/\/www.kaggle.com\/c\/porto-seguro-safe-driver-prediction\/discussion\/44629\n\n* https:\/\/towardsdatascience.com\/how-to-apply-self-supervision-to-tabular-data-introducing-dfencoder-eec21c4afaef\n\n* https:\/\/www.kaggle.com\/springmanndaniel\/1st-place-turn-your-data-into-daeta"}}