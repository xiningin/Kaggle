{"cell_type":{"eeaf56a6":"code","a2f4859e":"code","35e38c09":"code","4c06eb0e":"code","d1b1d8b3":"code","79002ab9":"code","379385ec":"code","8c3016f7":"code","7d037186":"code","a5eec70c":"code","59af3b84":"code","b574ae7e":"code","46366623":"code","3c2e2c71":"code","d95dc383":"code","fcadc5e1":"code","3f82c894":"code","2907347d":"code","f691a731":"code","2589b519":"code","fc2dd1b2":"code","d8c89312":"code","410f2a37":"code","c7dab2fd":"code","dea0257d":"code","f79dd7ba":"code","6c29bd83":"code","dd592b4c":"code","07fcc316":"code","cb43a4da":"code","386483c5":"code","8a2d7218":"code","58db700b":"code","d239ae47":"code","50c89963":"code","c314cf3b":"code","06c4a38e":"code","32c1cc2a":"code","4aaeb932":"code","ec65d4b7":"code","bbcf48c4":"code","0be1ba92":"code","6724f68d":"code","0a7d2a7d":"code","2a5a687a":"code","0a4a752a":"code","d86e214e":"code","c12b0396":"code","b0dc6716":"code","20fe64e0":"code","865c416d":"code","b592a69e":"code","5edd37fb":"code","efe36649":"code","b72ddd67":"code","fb3414ea":"code","63318007":"code","51cf3d4a":"code","72b0c134":"code","0bf0b397":"code","9bd9664b":"code","781be75d":"code","17081375":"code","7047449c":"code","3cc73f9f":"code","0e06ea44":"code","391f2f6e":"code","905ee95d":"code","0892ee27":"code","4c9aba4b":"code","6a695c18":"code","369e495a":"code","f317171f":"code","0ae30987":"code","fd32916d":"code","4210c90a":"code","1cbb936a":"code","b8f24817":"code","e5a25ee4":"code","efeafa65":"code","5ea491b9":"code","1d45b45f":"code","1fb4ae32":"code","eaab14c6":"code","8fe07fea":"code","9767ac5d":"code","94dea5c7":"code","e7c34d24":"code","abf6f189":"code","0b21697b":"code","87213b19":"code","918a416e":"code","d2e82bf0":"code","464bc679":"code","dbfd741e":"code","adde07b5":"code","35ae7bb7":"code","936f8b23":"code","0493c838":"code","fa1cea68":"code","f50e6fc0":"markdown","c991a89c":"markdown","fc729700":"markdown","1b06afff":"markdown","e8073f4f":"markdown","48820e49":"markdown","768d1fda":"markdown","c51fb9d7":"markdown","545436f3":"markdown","b0c408d6":"markdown","32665e76":"markdown","a484687e":"markdown","546c43bd":"markdown","f62d3ce0":"markdown","c8b75052":"markdown","a0e80c5c":"markdown","de504d32":"markdown","6bd246aa":"markdown","6ac3273b":"markdown","1ba8d663":"markdown","d94f2cc5":"markdown","5a95c8d0":"markdown","5e33bf90":"markdown","bc7239cb":"markdown","8fce3553":"markdown","3fb20f25":"markdown","eafbbe7d":"markdown","73e27444":"markdown","1299dec3":"markdown","ea94bc87":"markdown","644cc26c":"markdown","2b26359d":"markdown","d531ec2c":"markdown","59f0104a":"markdown","0d32e60b":"markdown","854e62bd":"markdown","577894a4":"markdown","a100f3c8":"markdown","fa7436ec":"markdown","8d0fd197":"markdown","a0c73802":"markdown","ff09f717":"markdown","55a19bc7":"markdown","4994ba0e":"markdown","908290b3":"markdown","424a8c58":"markdown","36b538a8":"markdown","da2030c2":"markdown","058bd150":"markdown","5a04be47":"markdown","adf27e84":"markdown","56633c4d":"markdown"},"source":{"eeaf56a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a2f4859e":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_passengerId = test_data[\"PassengerId\"]","35e38c09":"train_data.columns","4c06eb0e":"train_data.head()","d1b1d8b3":"train_data.describe()","79002ab9":"train_data.head()","379385ec":"train_data.info()","8c3016f7":"def bar_plot(variable):\n    \"\"\"\n        input: variable for example: \"Sex\"\n        output: bar plot & value count\n    \"\"\"\n    \n    # get feature\n    var = train_data[variable]\n    # count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    #visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index, varValue)\n    \n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","7d037186":"category1 = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\",\"SibSp\",\"Parch\"]\nfor c in category1:\n    bar_plot(c)","a5eec70c":"category2 = [\"Cabin\",\"Name\",\"Ticket\"]\nfor c in category2:\n    print(\"{} \\n\".format(train_data[c].value_counts)) # \u00e7ok karmasik bir yap\u0131s\u0131 var","59af3b84":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_data[variable], bins = 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(variable))\n    plt.show()","b574ae7e":"train_data.columns","46366623":"numericVar = [\"Fare\",\"Age\"]\nfor n in numericVar:\n    plot_hist(n)","3c2e2c71":"train_data[[\"Pclass\",\"Survived\"]]","d95dc383":"#Pclass vs Survived\ntrain_data[[\"Pclass\",\"Survived\"]].groupby([\"Pclass\"], as_index =False).mean().sort_values(by = \"Survived\", ascending =  False)\n","fcadc5e1":"# Sex vs Survived\ntrain_data[[\"Sex\",\"Survived\"]].groupby([\"Sex\"], as_index = False).mean().sort_values(by = \"Survived\", ascending =  False)\n","3f82c894":"train_data.columns","2907347d":"#Sibsp vs Survived\ntrain_data[[\"SibSp\",\"Survived\"]].groupby([\"SibSp\"], as_index = False).mean().sort_values(by = \"Survived\", ascending =  False)\n","f691a731":"### Parch vs Survived\ntrain_data[[\"Parch\",\"Survived\"]].groupby([\"Parch\"], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","2589b519":"train_data[[\"Parch\",\"SibSp\",\"Survived\"]].groupby([\"Parch\",\"SibSp\"],as_index = False).mean().sort_values(by = \"Survived\",ascending = False)","fc2dd1b2":"#Age vs Fare ili\u015fkisine bakal\u0131m\ntrain_data[[\"Age\",\"Fare\"]].groupby([\"Fare\"],as_index = False).mean().sort_values(by = \"Age\",ascending = False)","d8c89312":"# Age vs Survived\ntrain_data[[\"Age\",\"Survived\"]].groupby([\"Survived\"],as_index = False).mean().sort_values(\"Survived\")","410f2a37":"def detect_outliers(df, features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        \n        #3rd quartile\n        Q3 = np.percentile(df[c],75)\n        \n        #IQR\n        IQR = Q3 - Q1\n        \n        #Outlier step\n        outlier_step = IQR * 1.5\n        \n        # detect outlier and their indices\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indices\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    # counter metodu ile elemanlar\u0131n ka\u00e7ar tane outlier i\u00e7erdi\u011fini saym\u0131\u015f oluruz.\n    # bu sayede tek bir featureda outlier bulursak o veriyi \u00e7\u0131karmayabilriz.\n    \n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","c7dab2fd":"train_data.loc[detect_outliers(train_data,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","dea0257d":"#drop outliers\ntrain_data = train_data.drop(detect_outliers(train_data,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]), axis = 0).reset_index(drop = True)","f79dd7ba":"#We will combine our train and test data before looking at missing values.\n#If we just fill in the missing values in the train_data and do not look at the tests,\n#our machine learning model will fail when it sees the gaps in the test data. It will not be able to recognize them.\n\n\ntrain_data_len = len(train_data)\ntrain_data = pd.concat([train_data,test_data],axis = 0).reset_index(drop = True) ","6c29bd83":"train_data.head()","dd592b4c":"train_data.columns[train_data.isnull().any()] # We determined which columns have missing value.\n","07fcc316":"train_data.isnull().sum() # How many null values are in which feature we found them\n#Survived have 418 null value because It is test data's survived column","cb43a4da":"#We can delete these missing values instead of filling them. But losing data is not something we want.\ntrain_data[train_data[\"Embarked\"].isnull()]","386483c5":"# We can fill the Embarked according to people with the same fare paid. \n#So we make a guess as if they might have gotten from the same place.\ntrain_data.boxplot(column = \"Fare\", by = \"Embarked\")\nplt.show()","8a2d7218":"train_data[\"Embarked\"]  = train_data[\"Embarked\"].fillna(\"C\")\n","58db700b":"train_data[train_data[\"Embarked\"].isnull()]","d239ae47":"train_data[train_data[\"Fare\"].isnull()]","50c89963":"#Pclass = 3 olanlar\u0131 al\u0131p bakal\u0131m\n\ntrain_data[\"Fare\"] = train_data[\"Fare\"].fillna(np.mean(train_data[train_data[\"Pclass\"]==3][\"Fare\"]))","c314cf3b":"list1 = [\"SibSp\",\"Parch\",\"Age\",\"Fare\",\"Survived\"]\nsns.heatmap(train_data[list1].corr(),annot = True,fmt =\".2f\")","06c4a38e":"g = sns.factorplot(x =\"SibSp\", y = \"Survived\", data = train_data, kind = \"bar\",size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","32c1cc2a":"g = sns.factorplot(x = \"Parch\",y = \"Survived\",data = train_data,kind = \"bar\",size = 6)\ng.set_ylabels(\"Surived Probability\")\nplt.show()","4aaeb932":"g = sns.factorplot(x = \"Pclass\",y = \"Survived\",data = train_data,kind=\"bar\",size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","ec65d4b7":"g = sns.FacetGrid(train_data, col = \"Survived\")\ng.map(sns.distplot, \"Age\",bins = 25)\nplt.show()","bbcf48c4":"g = sns.FacetGrid(train_data, col = \"Survived\", row = \"Pclass\",size = 2)\ng.map(plt.hist, \"Age\",bins = 25)\ng.add_legend()\nplt.show()","0be1ba92":"g = sns.FacetGrid(train_data,row = \"Embarked\",size = 2)\ng.map(sns.pointplot, \"Pclass\",\"Survived\", \"Sex\")\ng.add_legend()","6724f68d":"g = sns.FacetGrid(train_data, row= \"Embarked\",col = \"Survived\", size = 2.3)\ng.map(sns.barplot,\"Sex\",\"Fare\")\ng.add_legend()\nplt.show()","0a7d2a7d":"train_data[train_data[\"Age\"].isnull()]","2a5a687a":"sns.factorplot(x = \"Sex\",y = \"Age\", data = train_data,kind = \"box\")\nplt.show()","0a4a752a":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\",data = train_data, kind =\"box\")\nplt.show()","d86e214e":"sns.factorplot(x = \"Parch\", y = \"Age\",data = train_data, kind =\"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\",data = train_data, kind =\"box\")\nplt.show()","c12b0396":"train_data[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_data[\"Sex\"]]","b0dc6716":"sns.heatmap(train_data[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)","20fe64e0":"index_nan_age = list(train_data[\"Age\"][train_data[\"Age\"].isnull()].index)\nindex_nan_age\nfor i in index_nan_age:\n    age_pred = train_data[\"Age\"][((train_data[\"SibSp\"] == train_data.iloc[i][\"SibSp\"]) & (train_data[\"Parch\"] == train_data.iloc[i][\"Parch\"]) & (train_data[\"Pclass\"] == train_data.iloc[i][\"Pclass\"]))].median()\n    age_med = train_data[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_data[\"Age\"].iloc[i] = age_pred\n    else: \n        train_data[\"Age\"].iloc[i] = age_med","865c416d":"train_data[train_data[\"Age\"].isnull()]","b592a69e":"age_med","5edd37fb":"age_pred","efe36649":"train_data[\"Name\"].head(10)","b72ddd67":"s =\" McCarthy, Mr. Timothy J\"\ns.split(\".\")[0].split(\",\")[-1].strip()","fb3414ea":"train_data.columns","63318007":"name = train_data[\"Name\"]","51cf3d4a":"train_data[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","72b0c134":"train_data[\"Title\"].head(10)","0bf0b397":"sns.countplot(x=\"Title\", data = train_data)\nplt.xticks(rotation = 60)\nplt.show()","9bd9664b":"# convert to categorical \ntrain_data[\"Title\"] = train_data[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_data[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\"or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_data[\"Title\"]]\ntrain_data[\"Title\"].head(10)","781be75d":"sns.countplot(x=\"Title\", data = train_data)\nplt.xticks(rotation = 60)\nplt.show()","17081375":"sns.countplot(x=\"Title\", data = train_data)\nplt.xticks(rotation = 60)\nplt.show()","7047449c":"g = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_data, kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","3cc73f9f":"train_data.drop(labels = [\"Name\"], axis = 1, inplace = True)\n","0e06ea44":"train_data.head()","391f2f6e":"train_data = pd.get_dummies(train_data, columns = [\"Title\"])\ntrain_data.head() # bu sayede kategori say\u0131s\u0131 4'den 2'ye d\u00fc\u015ft\u00fc. feature say\u0131s\u0131 artt\u0131.","905ee95d":"train_data.head()","0892ee27":"train_data[\"Fsize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] +1 ","4c9aba4b":"train_data.head()","6a695c18":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_data, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","369e495a":"#ilk se\u00e7enek fsize \u0131 2 3 ve 4 olanlar\u0131 bir kategori, 1 ve 7 olanlar\u0131 bir kategori, 5 ve 6 olanlar\u0131 bir kategori yapmak olabilir.\n# ya da direkt bir threshold belirleyebiliriz. \ntrain_data[\"family_size\"] = [1 if i < 5 else 0 for i in train_data[\"Fsize\"]]\n","f317171f":"train_data.head(10)","0ae30987":"sns.countplot(x = \"family_size\", data = train_data)\nplt.show()","fd32916d":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_data, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","4210c90a":"train_data = pd.get_dummies(train_data, columns = [\"family_size\"])\ntrain_data.head()","1cbb936a":"train_data[\"Embarked\"].head()","b8f24817":"sns.countplot(x = \"Embarked\", data = train_data)\nplt.show()","e5a25ee4":"train_data = pd.get_dummies(train_data, columns = [\"Embarked\"])\ntrain_data.head()","efeafa65":"train_data[\"Ticket\"].head(10)","5ea491b9":"a = \"STON\/O2. 3101282\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]\n","1d45b45f":"tickets = []\nfor i in list(train_data.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_data[\"Ticket\"] = tickets\n\n    ","1fb4ae32":"train_data[\"Ticket\"].head(10)","eaab14c6":"train_data = pd.get_dummies(train_data, columns = [\"Ticket\"], prefix = \"T\")\ntrain_data.head()","8fe07fea":"sns.countplot(x = \"Pclass\", data = train_data)\nplt.show()","9767ac5d":"train_data[\"Pclass\"] = train_data[\"Pclass\"].astype(\"category\")\ntrain_data = pd.get_dummies(train_data, columns= [\"Pclass\"])\ntrain_data.head(10)","94dea5c7":"train_data[\"Sex\"] = train_data[\"Sex\"].astype(\"category\")\ntrain_data = pd.get_dummies(train_data, columns = [\"Sex\"])\ntrain_data.head()","e7c34d24":"train_data.drop(labels = [\"PassengerId\",\"Cabin\"], axis = 1, inplace = True)","abf6f189":"from sklearn.model_selection import (\n    train_test_split,\n    StratifiedKFold,\n    GridSearchCV)\nfrom sklearn.linear_model  import LogisticRegression  \nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import (\n    RandomForestClassifier,\n    VotingClassifier)\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","0b21697b":"train_data_len","87213b19":"test = train_data[train_data_len:]\ntest.drop(labels = [\"Survived\"], axis = 1, inplace = True)","918a416e":"test.head()","d2e82bf0":"train = train_data[:train_data_len]\nX_train = train.drop(labels = [\"Survived\"], axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))","464bc679":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2)\nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training accuracy: % {}\".format(acc_log_train))\nprint(\"Testing accuracy: % {}\".format(acc_log_test))","dbfd741e":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\" : range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\" : [0.001, 0.01, 0.1, 1],\n                 \"C\" : [1,10, 50, 100, 200, 300, 1000]}\n\nrf_param_grid = {\"max_features\" : [1,3,10],\n                \"min_samples_split\" : [2,3,10],\n                \"min_samples_leaf\" : [100,300],\n                \"criterion\" : [\"gini\"]}\nlogreg_param_grid = {\"C\" : np.logspace(-3,3,7),\n                    \"penalty\" : [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\" : np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\" : [\"uniform\",\"distance\"],\n                 \"metric\" : [\"euclidean\", \"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                    svc_param_grid,\n                    rf_param_grid,\n                    logreg_param_grid,\n                    knn_param_grid]","adde07b5":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1, verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","35ae7bb7":"cv_results = pd.DataFrame({\"Cross Validation Means\" : cv_result, \"ML Models\" :  [\"DecisionTreeClassifier\",\"SVM\",\"RandomForestClassifier\",\"LogisticRegression\",\"KNeighborsClassifier\"] })\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","936f8b23":"votingC = VotingClassifier(estimators = [(\"dt\", best_estimators[0]),\n                                        (\"rfc\", best_estimators[2]),\n                                        (\"lr\", best_estimators[3])],\n                                         voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train,y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","0493c838":"test_PassengerId = test_data[\"PassengerId\"]","fa1cea68":"test_survived = pd.Series(votingC.predict(test),name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived], axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","f50e6fc0":"Fare feature seems to have correlation with survived feature (0.26)","c991a89c":"<a id = \"28\"><\/a><br>\n\n## Drop Passenger ID and Cabin","fc729700":"* Sex is not informative for age prediction because female and male age median almost same.","1b06afff":"<a id = \"32\"><\/a><br>\n\n## Hyperparameter Tuning -- Grid Search -- Cross Validation\nWe will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\n* Decision Tree\n* SVM\n* Random Forest\n* KNN\n* Logistic Regression","e8073f4f":"* float64(2) : Fare and Age\n* int64(5) : Pclass, sibsp, parch, passengerId and survived\n* object(5) : Cabin, embarked, ticket, name, gender","48820e49":"<a id = \"11\"><\/a><br>\n# Visualization","768d1fda":"<a id = \"19\"><\/a><br>\n\n### Embarked -- Sex -- Fare -- Survived","c51fb9d7":"<a id = \"12\"><\/a><br>\n### Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived","545436f3":"<a id = \"10\"><\/a><\/br>\n## Fill Missing Value\n\n* Embarked has 2 missing values\n* Fare has 1 missing value","b0c408d6":"<a id = \"6\"><\/a><\/br>\n## Basic Data Analysis\n\n\n* Pclass - Survived Does it have to do with the survival of the class of passengers?\n* Sex - Survived Does the gender of passengers have anything to do with survival?\n* SibSp - Does the number of people in the families of Survived Passengers have anything to do with their survival?\n* Parch - Does the number of people in the families of Survived Passengers have anything to do with their survival?","32665e76":"<a id = \"33\"><\/a><br>\n## Ensemble Modelling","a484687e":"<a id = \"18\"><\/a><br>\n\n### Embarked -- Sex -- Pclass -- Survived","546c43bd":"<a id = \"2\"><\/a>\n# Variable Description\n\n\n1. PassengerId : unique id number for each passenger\n1. Survived : passenger survived (1) or died(0)\n1. Pclass : passenger class\n1. Name : name \n1. Sex : gender\n1. Age : age\n1. SibSp : number of siblings \/ spouses\n1. Parch : number of parents \/ children\n1. Ticket : ticket number\n1. Fare : amount of ticket money\n1. Cabin : cabin category\n1. Embarked : ports where passengers board the ship (C = Cherbourg, Q = Queenstown, S = Southhampton9","f62d3ce0":"* Pclass is important feature for model training","c8b75052":"<a id = \"4\"><\/a>\n## Categorical Variable \n\n\n","a0e80c5c":"* Having a lot of SibSp have less chance to survive.\n* if SibSp == 0 or 1 or 2, passenger has more chance to survive\n* we can consider a new feature describing these categories.","de504d32":"<a id = \"15\"><\/a><br>\n### Pclass -- Survived","6bd246aa":"<a id = \"23\"><\/a><br>\n## Family Size","6ac3273b":"Parch-SibSp together Survived ","1ba8d663":"Boxplota bakt\u0131\u011f\u0131m\u0131zda, fare = 80 olanlar i\u00e7in en uygun liman C liman\u0131d\u0131r. C olarak doldurabiliriz. ","d94f2cc5":"* 1st class passengers are older than 2nd, and 2nd class is older than 3rd class.","5a95c8d0":"<a id = \"26\"><\/a><br>\n## Pclass","5e33bf90":"* age<= 10 has a high survival rate\n* large number of 20 years old is not survive,\n* most passengers are in 15-35\n* use age feature in training\n* use age distribution for missing value of age","bc7239cb":"* Age is not corelated with sex but it is corelated with Parch, SibSp and Pclass.","8fce3553":"<a id = \"24\"><\/a><br>\n## Ticket","3fb20f25":"<a id = \"34\"><\/a><br>\n\n## Prediction and Submission","eafbbe7d":"<a id = \"17\"><\/a><br>\n\n### Pclass -- Survived -- Age","73e27444":"<a id = \"30\"><\/a><br>\n\n## Train - Test Split","1299dec3":"* SibSp and Parch can be used for new feature exraction with th = 3\n* small families have more chance to survive.\n* there is a std in survival of passenger with Parch = 3","ea94bc87":"<a id = \"5\"><\/a>\n## Numerical Variable ","644cc26c":"<a id = \"8\"><\/a><\/br>\n# Missing Value\n  * Find Missing Value\n  * Fill Missing Value","2b26359d":"# Introduction\n\nTitanic is a ship sunk in a major shipwreck. This accident happened in 1912. As a result of this accident, 1502 people died.\n\n<font color = pink >\n Content:\n    \n 1. [Load and Check Data](#1)<\/br>\n 2. [Variable Description](#2)\n* [Univariate Variable Analysis](#3)\n* * [Categorical Variable Analysis](#4)\n* * [Numerical Variable Analysis](#5)\n 1. [Basic Data Analysis](#6)\n 1. [Outlier Detection](#7)\n 1. [Missing Value](#8)\n    * [Find Missing Value](#9)    \n    * [Fill Missing Value](#10) \n 1. [Visualization](#11)\n    * [Correlation Between Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    * [SibSp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Survived -- Age](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill Missing: Age Feature](#20)\n 1. [Future Engineering](#21)\n    * [Name -- Title](#22)\n    * [Famiy Size](#23)\n    * [Embarked](#24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Drop Passenger ID and Cabin](#28)\n 1. [Modelling](#29)\n    * [Train - Test Split](#30)\n    * [Simple Logistic Regression](#31)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n    * [Ensemble Modelling](#33)\n    * [Prediction and  Submission](#34)\n\n\n    \n    \n     \n    ","d531ec2c":"<a id = \"1\"><\/a>\n## Load and Check Data","59f0104a":"<a id = \"7\"><\/a><\/br>\n# Outlier Detection\n\n* Let's think of data that is too big or too small than other data.","0d32e60b":"* parch ve sibsp aras\u0131nda bir benzerlik yakalayamad\u0131k corelation yok gibi g\u00f6r\u00fcn\u00fcyor.  \n* Bu bizim farkl\u0131 fikirler edinmemize yard\u0131mc\u0131 olabilir.\n* parch ve sibsp yi birle\u015ftirerek yeni bir feature ortaya \u00e7\u0131karabiliriz.\n","854e62bd":"<a id = \"24\"><\/a><br>\n## Embarked","577894a4":"<a id = \"9\"><\/a><\/br>\n## Find Missing Value","a100f3c8":"<a id = \"31\"><\/a><br>\n## Simple Logistic Regression","fa7436ec":"<a id = \"3\"><\/a>\n# Univariate Variable Analysis\n* Categorical Variable : Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, Sibsp, Parch \n* Numeric Variable : Fare, age and passengerId","8d0fd197":"<a id = \"29\"><\/a><br>\n# Modelling","a0c73802":"<a id = \"13\"><\/a><br>\n### SibSp -- Survived\n    ","ff09f717":"<a id = \"20\"><\/a><br>\n\n### Fill Missing: Age Feature","55a19bc7":"Small families have more chance to survive than large families.","4994ba0e":"* 1) Erkeklerin ortalama ya\u015f\u0131na g\u00f6re, kad\u0131nlar\u0131n ya\u015flar\u0131n\u0131 ortalama kad\u0131n ya\u015f\u0131na g\u00f6re doldurabiliriz.\n* 2) Pclasslara bak\u0131p o classdaki erkeklerin ya\u015f ortalmalar\u0131na g\u00f6re doldurabiliriz.\n* 3) Parch ve SibSp ye g\u00f6re yapabiliriz.(birinin \u00e7ocu\u011fuysa k\u00fc\u00e7\u00fck olabilir. Birinin annesi veya babas\u0131ysa ya\u015f\u0131 b\u00fcy\u00fckt\u00fcr)\n","908290b3":"<a id = \"14\"><\/a><br>\n### Parch -- Survived","424a8c58":"<a id = \"21\"><\/a><br>\n# Future Engineering","36b538a8":"*  Female passengers have much better survival rate than male.\n* males have better survival rate in pclass 3 in C.\n* embarked and sex will be used in training.","da2030c2":"<a id = \"22\"><\/a><br>\n##  Name -- Title","058bd150":"<a id = \"27\"><\/a><br>\n## Sex","5a04be47":"* passengers who pay higher fare have better survival. Fare can be used as categorical for training.","adf27e84":"  <a id = \"16\"><\/a><br>\n\n  ### Age -- Survived","56633c4d":"Firstly we looking for **Pclass vs Survived** relationship. When we looking up this, we use groupby method because we want to know which Pclass have how much survived."}}