{"cell_type":{"07499a75":"code","acfa7067":"code","2994ade0":"code","88f2b6db":"code","c70b9b4f":"code","a6b4f1ef":"code","046386ed":"code","33099303":"code","7bfd7178":"code","7f98168f":"code","59d2d3f2":"code","e43959be":"code","cfc6f4f1":"code","412a70d2":"code","374bdd48":"code","44adda5e":"code","bbb99f2f":"code","27669db9":"code","43dd8838":"code","3fb19b2e":"code","a25ddb86":"code","2e0ed18b":"markdown","4c590b29":"markdown"},"source":{"07499a75":"import os\nimport zipfile\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom shutil import copyfile\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport random\nprint(os.listdir(\"..\/input\/dogs-vs-cats\/\"))","acfa7067":"with zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/train.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"train\")\n\nwith zipfile.ZipFile(\"..\/input\/dogs-vs-cats\/test1.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"test1\")\n","2994ade0":"train_directory = \"train\/train\/\"\ntest_directory  = \"test1\/test1\/\"\n# See sample image\nfilenames = os.listdir(train_directory)\nsample = random.choice(filenames)\nprint(sample)\nimage = load_img(train_directory + sample)\nplt.imshow(image)","88f2b6db":"# 8000 train samples\n# 1600 validation samples\nimport shutil\nsource_dir = 'train\/'\ndef copy_files(prefix_str, range_start, range_end, target_dir):\n    image_paths = []\n    for i in range(range_start, range_end):\n        image_path = os.path.join(source_dir,'train', prefix_str + '.'+ str(i)+ '.jpg')\n        image_paths.append(image_path)\n    dest_dir = os.path.join( 'data', target_dir, prefix_str)\n    os.makedirs(dest_dir)\n\n    for image_path in image_paths:\n        shutil.copy(image_path,  dest_dir)\n\ncopy_files('dog', 0, 4000, 'train')\ncopy_files('cat', 0, 4000, 'train')\ncopy_files('dog', 4000, 4800,'validation')\ncopy_files('cat', 4000, 4800, 'validation')","c70b9b4f":"# All data, 12500 cat, 12500 dog\nsource_dir = 'train\/'\ndef copy_files(prefix_str, range_start, range_end, target_dir):\n    image_paths = []\n    for i in range(range_start, range_end):\n        image_path = os.path.join(source_dir,'train', prefix_str + '.'+ str(i)+ '.jpg')\n        image_paths.append(image_path)\n    dest_dir = os.path.join( 'Alldata', target_dir, prefix_str)\n    if not os.path.exists(dest_dir):\n        os.makedirs(dest_dir)\n\n    for image_path in image_paths:\n        shutil.copy(image_path,  dest_dir)\n\ncopy_files('dog', 0, 12500, 'train')\ncopy_files('cat', 0, 12500, 'train')","a6b4f1ef":"if  os.path.exists('train'):\n    #os.removedirs(\"train\")\n    shutil.rmtree(\"train\") \n","046386ed":"# dimensions of our images.\nimg_width, img_height = 150, 150\n\ntrain_dir = 'data\/train'\nvalidation_dir = 'data\/validation'","33099303":"print(len(os.listdir('data\/train\/cat')))\nprint(len(os.listdir('data\/train\/dog')))\nprint(len(os.listdir('data\/validation\/cat')))\nprint(len(os.listdir('data\/validation\/dog')))","7bfd7178":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(img_width, img_height, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n    tf.keras.layers.Dense(1, activation='sigmoid')  \n])\n\nfrom tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss='binary_crossentropy',\n              metrics = ['acc'])","7f98168f":"\"\"\"\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator( rescale = 1.0\/255. )\ntest_datagen  = ImageDataGenerator( rescale = 1.0\/255. )\n\ntrain_generator = train_datagen.flow_from_directory(train_dir,\n                                                    batch_size=20,\n                                                    class_mode='binary',\n                                                    target_size=(img_width, img_height))     \nvalidation_generator =  test_datagen.flow_from_directory(validation_dir,\n                                                         batch_size=20,\n                                                         class_mode  = 'binary',\n                                                         target_size = (img_width, img_height))\n                                                         \n                                                         \"\"\"","59d2d3f2":"\"\"\"\nhistory = model.fit_generator(train_generator,\n                              validation_data=validation_generator,\n                              steps_per_epoch=100,\n                              epochs=15,\n                              validation_steps=50,\n                              verbose=2)\n                              \"\"\"","e43959be":"\"\"\"\nacc      = history.history[     'acc' ]\nval_acc  = history.history[ 'val_acc' ]\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\nplt.plot  ( epochs,     acc )\nplt.plot  ( epochs, val_acc )\nplt.title ('Training and validation accuracy')\nplt.figure()\n\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )\n\"\"\"","cfc6f4f1":"# Updated to do image augmentation\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(150, 150),  # All images will be resized to 150x150\n        batch_size=20,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='binary')\n\nhistory = model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,  # 1000 images = batch_size * steps\n      epochs=15,\n      validation_data=validation_generator,\n      validation_steps=50,  # 500 images = batch_size * steps\n      verbose=2)","412a70d2":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","374bdd48":"test_filenames = os.listdir(\"test1\/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]\nprint(nb_samples)","44adda5e":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest1_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"test1\/test1\/\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=(img_width,img_height),\n    batch_size=20\n)","bbb99f2f":"predict = model.predict_generator(test1_generator)","27669db9":"test_df['label'] = np.round(predict)","43dd8838":"test_df['label'].value_counts().plot.bar()\n","3fb19b2e":"sample_test = test_df.head(18)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['label']\n    img = load_img(\"test1\/test1\/\"+filename, target_size=(img_width,img_height))\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\nplt.tight_layout()\nplt.show()","a25ddb86":"submission_df = test_df.copy()\nsubmission_df['id'] = submission_df['filename'].str.split('.').str[0]\nsubmission_df.drop(['filename'], axis=1, inplace=True)\nsubmission_df.to_csv('submission.csv', index=False)","2e0ed18b":"Importing Data from this notebook: https:\/\/www.kaggle.com\/abdallahhassan\/dogs-cats-resnet50-transfere-learning\/notebook","4c590b29":"# TensorFlow Keras\n* From Convolutional Neural Networks in TensorFlow\n* https:\/\/colab.research.google.com\/github\/lmoroney\/dlaicourse\/blob\/master\/Exercises\/Exercise%205%20-%20Real%20World%20Scenarios\/Exercise%205%20-%20Answer.ipynb#scrollTo=hwHXFhVG3786"}}