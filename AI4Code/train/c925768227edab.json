{"cell_type":{"bc5ca7cd":"code","55e51084":"code","eec4f77f":"code","ea580238":"code","f19dd619":"code","f36be77a":"code","21161924":"code","3a166e28":"code","fa9a91b1":"markdown","26d6cc0b":"markdown","39bd22f9":"markdown","e6df99ff":"markdown","99982c9b":"markdown","efa2d96a":"markdown","63e68cea":"markdown","e24539e7":"markdown","4f6dac89":"markdown"},"source":{"bc5ca7cd":"#-------Import Dependencies-------#\n%matplotlib inline\nimport pandas as pd\nimport os,shutil,math,scipy,cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random as rn\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix,roc_curve,auc\n\nfrom PIL import Image\nfrom PIL import Image as pil_image\nfrom PIL import ImageDraw\n\nfrom time import time\nfrom glob import glob\nfrom tqdm import tqdm\nfrom skimage.io import imread\nfrom IPython.display import SVG\n\nfrom scipy import misc,ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\n\nfrom keras import backend as K\nfrom keras.utils.np_utils import to_categorical\nfrom keras import layers\nfrom keras.preprocessing.image import save_img\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.applications.vgg16 import VGG16,preprocess_input\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\nfrom keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler","55e51084":"def show_final_history(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('acc')\n    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()","eec4f77f":"data_dir = '..\/input\/rps-cv-images\/'\naugs_gen = ImageDataGenerator(\n    rescale=1.\/255,        \n    horizontal_flip=True,\n    height_shift_range=.2,\n    vertical_flip = True,\n    validation_split = 0.2\n)  \n\ntrain_gen = augs_gen.flow_from_directory(\n    data_dir,\n    target_size = (224,224),\n    batch_size=32,\n    class_mode = 'categorical',\n    shuffle=True,\n)\n\nval_gen = augs_gen.flow_from_directory(\n    data_dir,\n    target_size=(224,224),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False,\n    subset = 'validation'\n)\n\n","ea580238":"model_base = MobileNet(weights='imagenet',include_top=False,input_shape=(224,224,3))\nmodel = Sequential()\nmodel.add(model_base)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dropout(0,5))\nmodel.add(Dense(3,activation='softmax'))\nmodel.summary()","f19dd619":"#-------Callbacks-------------#\nbest_model_weights = '.\/base.model'\ncheckpoint = ModelCheckpoint(\n    best_model_weights,\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n    save_weights_only=False,\n    period=1\n)\nearlystop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=10,\n    verbose=1,\n    mode='auto'\n)\ntensorboard = TensorBoard(\n    log_dir = '.\/logs',\n    histogram_freq=0,\n    batch_size=16,\n    write_graph=True,\n    write_grads=True,\n    write_images=False,\n)\n\ncsvlogger = CSVLogger(\n    filename= \"training_csv.log\",\n    separator = \",\",\n    append = False\n)\n\n#lrsched = LearningRateScheduler(step_decay,verbose=1)\n\nreduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=40,\n    verbose=1, \n    mode='auto',\n    cooldown=1 \n)\n\ncallbacks = [checkpoint,tensorboard,csvlogger,reduce]","f36be77a":"opt = SGD(lr=1e-4,momentum=0.99)\nopt1 = Adam(lr=2e-4)\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n    \nhistory = model.fit_generator(\n    train_gen, \n    steps_per_epoch  = 50, \n    validation_data  = val_gen,\n    validation_steps = 50,\n    epochs = 5, \n    verbose = 1,\n    callbacks=callbacks\n)","21161924":"show_final_history(history)\nmodel.load_weights(best_model_weights)\nmodel_score = model.evaluate_generator(val_gen,steps=20)\nprint(\"Model Test Loss:\",model_score[0])\nprint(\"Model Test Accuracy:\",model_score[1])\n\nmodel_json = model.to_json()\nwith open(\"model.json\",\"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save(\"model.h5\")\nprint(\"Weights Saved\")","3a166e28":"!wget https:\/\/bin.equinox.io\/c\/4VmDzA7iaHb\/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = '.\/logs' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('.\/ngrok http 8080 &')\n! curl -s http:\/\/localhost:4040\/api\/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","fa9a91b1":"# TensorBoard\n### Here is a script that you can use with the TensorBoard Keras Callback. It will give you a URL to view your models training results on TensorBoard","26d6cc0b":"# Project Page\n### Here is the link to the project page for this dataset\n### https:\/\/github.com\/DrGFreeman\/rps-cv","39bd22f9":"# Model Evaluation\n### Here I visualize the training results, load the best model weights, evalute the model, save the json file and h5 weights","e6df99ff":"# Happy Learning!","99982c9b":"# The Model\n### Here I use the pretrained mobile net.\n### I used this architecture because I plan to make this into a web app\n### https:\/\/keras.io\/applications\/#mobilenet","efa2d96a":"# Callbacks\n### Here I load my Keras Callbacks to monitor the training of the model\n### https:\/\/keras.io\/callbacks\/","63e68cea":"# Train The Model\n### Here I train our model using fit_generator","e24539e7":"# Image Preprocessing\n### Here I use the data augmentation and image preprocessing from the Keras ImageDataGenerator","4f6dac89":"# Function for training visualization\n### Here is a function I create to visualize the training of the model"}}