{"cell_type":{"9463e50a":"code","9ffabc8a":"code","3f0e5c53":"code","c93b05ec":"code","c45fd38f":"code","58fab069":"code","cee24375":"code","ccb833be":"code","2a0e7034":"code","db7ffa6b":"code","50ff73fb":"code","65340b0e":"code","2b862e09":"code","7b8e28cd":"code","7913dc41":"code","59b1cb55":"code","1924a95b":"code","5b100bb2":"code","7cf5ddfa":"code","5675da2e":"code","4380cb0d":"code","7a7df5fb":"code","8ccc6b34":"code","fb713f1c":"code","a3d3db89":"code","1f8180ca":"code","2e6aaa34":"code","0af34ca6":"code","9d4d86ba":"code","7dd6bf48":"code","60faa034":"code","f9f98e2e":"code","f5801464":"code","3a10120c":"code","c063aeec":"code","cdf7a6dc":"code","fb091a60":"code","3f6406f7":"code","5be417da":"code","6dfb98f4":"code","dc66e46e":"code","2aad8b45":"code","6300aa6f":"code","9837cfec":"code","fe5c7b16":"code","1a3c3976":"code","9feaa44d":"code","0adf32e3":"code","3420a435":"code","8e4ea528":"code","a546ac77":"code","06305729":"code","8c96791b":"code","fc6c9596":"code","0af7dd26":"code","6e2cfe27":"code","60ab25a2":"code","cd8ed7ce":"code","f065618b":"code","e2146e71":"markdown","7ebc1efa":"markdown","f72f6d3e":"markdown","f19fe29b":"markdown","a569c2bf":"markdown","fb4d9e5b":"markdown","664de61a":"markdown","2732b4fd":"markdown","9115ab32":"markdown","e9681647":"markdown","c82a8c13":"markdown","0860cfb1":"markdown","9a93e66f":"markdown","6adb47b8":"markdown","520bcc6f":"markdown","f37502d2":"markdown"},"source":{"9463e50a":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9ffabc8a":"train_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")","3f0e5c53":"train = train_df.copy()\ntest = test_df.copy()","c93b05ec":"cols_to_be_removed = [\"PassengerId\", \"Name\", \"Ticket\"]","c45fd38f":"train.drop(cols_to_be_removed, axis=1, inplace=True)\ntest.drop(cols_to_be_removed, axis=1, inplace=True)","58fab069":"train.shape","cee24375":"train.head()","ccb833be":"test.head()","2a0e7034":"print(train.isna().sum())","db7ffa6b":"print(train[\"Age\"].mean())\nprint(train[\"Embarked\"].mode())","50ff73fb":"train[\"Age\"].fillna(train[\"Age\"].mean(), inplace=True)","65340b0e":"train.drop([\"Cabin\"],axis=1, inplace=True)","2b862e09":"train.dropna(inplace=True) #Remaining 2 values in Embarked columns","7b8e28cd":"train.shape","7913dc41":"print(train.isna().sum())","59b1cb55":"test.shape","1924a95b":"print(test.isna().sum())","5b100bb2":"print(test[\"Age\"].mean())\nprint(test[\"Fare\"].mean())","7cf5ddfa":"test[\"Age\"].fillna(test[\"Age\"].mean(), inplace=True)","5675da2e":"test.drop([\"Cabin\"],axis=1,inplace=True)","4380cb0d":"test[\"Fare\"].fillna(test[\"Fare\"].mean(), inplace=True)","7a7df5fb":"print(test.isna().sum())","8ccc6b34":"train.head()","fb713f1c":"test.head()","a3d3db89":"plt.figure(figsize=(8,5))\nsns.countplot(x='Survived', hue='Pclass', data= train)","1f8180ca":"plt.figure(figsize=(8,5))\nsns.countplot(x='Survived', hue='Sex', data= train)","2e6aaa34":"import category_encoders as ce","0af34ca6":"encoder= ce.OrdinalEncoder(cols=['Sex'],return_df=True, mapping=[{'col':'Sex','mapping':{'male':0,'female':1}}])","9d4d86ba":"train = encoder.fit_transform(train)\ntest = encoder.fit_transform(test)","7dd6bf48":"from sklearn.preprocessing import OneHotEncoder","60faa034":"encoder = ce.OneHotEncoder(cols='Embarked',handle_unknown='return_nan',return_df=True,use_cat_names=True)","f9f98e2e":"train = encoder.fit_transform(train)\ntest = encoder.fit_transform(test)","f5801464":"train.head()","3a10120c":"train.shape","c063aeec":"test.shape","cdf7a6dc":"test.head()","fb091a60":"X = train.iloc[:,1:].values\ny = train.iloc[:,0].values","3f6406f7":"from sklearn.model_selection import train_test_split","5be417da":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)","6dfb98f4":"from sklearn.preprocessing import StandardScaler","dc66e46e":"sc = StandardScaler()","2aad8b45":"train.head()","6300aa6f":"print(train[\"Fare\"].var())\nprint(train[\"Age\"].var())","9837cfec":"X_train[:,5:6] = sc.fit_transform(X_train[:,5:6])\nX_test[:,5:6] = sc.transform(X_test[:,5:6])","fe5c7b16":"X_train[:,2:3] = sc.fit_transform(X_train[:,2:3])\nX_test[:,2:3] = sc.transform(X_test[:,2:3])","1a3c3976":"from sklearn.ensemble import GradientBoostingClassifier","9feaa44d":"gbc = GradientBoostingClassifier()","0adf32e3":"gbc.fit(X_train, y_train)","3420a435":"y_pred = gbc.predict(X_test)","8e4ea528":"from sklearn.metrics import accuracy_score, confusion_matrix","a546ac77":"accuracy_score(y_test,y_pred)","06305729":"confusion_matrix(y_test,y_pred)","8c96791b":"sns.heatmap(confusion_matrix(y_test,y_pred),annot=True)","fc6c9596":"test.head()","0af7dd26":"test_data = test.values","6e2cfe27":"test_data[:,5:6] = sc.fit_transform(test_data[:,5:6])\ntest_data[:,2:3] = sc.fit_transform(test_data[:,2:3])","60ab25a2":"prediction = gbc.predict(test_data)","cd8ed7ce":"submission= pd.DataFrame({'PassengerId' : test_df['PassengerId'], 'Survived': prediction })\nprint(submission.head())","f065618b":"filename= 'gender_submission.csv'\nsubmission.to_csv(filename, index=False)","e2146e71":"<div style = \"font-family:'Segoe UI'; border-left: 5px solid red; padding: 5px 0px 10px 10px; border-radius: 5px\">\n    <h2>Splitting the dependent and independent variables<\/h2>\n<\/div>","7ebc1efa":"<div style = \"font-family:'Segoe UI';\">All null values are handled in train and test data \u2705 <\/div>","f72f6d3e":"<div style = \"font-family:'Segoe UI';\"> \u27a1\ufe0f We can see that there are more female survivors compared to male <\/div>","f19fe29b":"<div style = \"font-family:'Segoe UI';\">All categorical values are encoded in the data \u2705 <\/div>","a569c2bf":"<div style = \"font-family:'Segoe UI'; border-left: 5px solid red; padding: 5px 0px 10px 10px; border-radius: 5px\">\n    <h2>Encoding the categorical values in the data<\/h2>\n<\/div>","fb4d9e5b":"<div style = \"font-family:'Segoe UI';\">\nGradient Boosting is an Ensemble Learning method. <br>\nIn Gradient Boosting, each predictor tries to improve on its predecessor by reducing the errors. But the fascinating idea behind Gradient Boosting is that instead of fitting a predictor on the data at each iteration, it actually fits a new predictor to the residual errors made by the previous predictor.\n<\/div>","664de61a":"<img src = \"https:\/\/image.freepik.com\/free-vector\/happy-family-cleaning-apartment_74855-6501.jpg\" >","2732b4fd":"<div style = \"font-family:'Segoe UI'; border-left: 5px solid red; padding: 5px 0px 10px 10px; border-radius: 5px\">\n    <h2>Validating the model<\/h2>\n<\/div>","9115ab32":"<div style = \"font-family:'Segoe UI';\">The model is 79.09 % accurate \ud83d\ude00\ud83d\ude00 <\/div>","e9681647":"<div style = \"font-family:'Segoe UI'; border-left: 5px solid red; padding: 5px 0px 10px 10px; border-radius: 5px\">\n    <h2>Scaling the values in data to reduce spread<\/h2>\n<\/div>","c82a8c13":"<div style = \"font-family:'Segoe UI';\"> \u27a1\ufe0f We can see that there are more people from third class who fail to survive, while the survival ratio is more or less similar in all classes <\/div>","0860cfb1":"<div style = \"font-family:'Segoe UI';\">Data cleaning in Test Data<\/div>","9a93e66f":"<div style = \"font-family:'Segoe UI'; border-left: 5px solid red; padding: 5px 0px 10px 10px; border-radius: 5px\">\n    <h2>Vizualizing the data<\/h2>\n<\/div>","6adb47b8":"<div style = \"font-family:'Segoe UI'; border-left: 5px solid red; padding: 5px 0px 10px 10px; border-radius: 5px\">\n    <h2>Predicting the survival status for the given test data<\/h2>\n<\/div>","520bcc6f":"<div style = \"font-family:'Segoe UI';\"> Saving the results into a csv file \u2705 <\/div>","f37502d2":"<div style = \"font-family:'Segoe UI'; border-left: 5px solid red; padding: 5px 0px 10px 10px; border-radius: 5px\">\n    <h2>Gradient Boosting Classifier<\/h2>\n<\/div>"}}