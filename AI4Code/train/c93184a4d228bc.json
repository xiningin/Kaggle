{"cell_type":{"e06f1e71":"code","3d0aa091":"code","32874f8d":"code","ecebaed3":"code","d0655221":"code","f76fdbb4":"code","ac43943c":"code","4b6c1407":"code","912d9fcd":"code","f217be73":"code","55b0037c":"code","f56fc124":"code","418ed257":"code","ab6074ac":"code","fa8790ef":"code","56d80af9":"code","113c2042":"markdown","582a0578":"markdown","1be36d43":"markdown"},"source":{"e06f1e71":"import numpy as np\nimport pandas as pd\nimport math\nimport multiprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nimport functools\nfrom concurrent.futures import ProcessPoolExecutor\nfrom sklearn.model_selection import KFold","3d0aa091":"train = pd.read_csv('..\/input\/X_train.csv')\ntest = pd.read_csv('..\/input\/X_test.csv')\ntarget = pd.read_csv('..\/input\/y_train.csv')\nsubmit = pd.read_csv('..\/input\/sample_submission.csv')","32874f8d":"# https:\/\/stackoverflow.com\/questions\/53033620\/how-to-convert-euler-angles-to-quaternions-and-get-the-same-euler-angles-back-fr?rq=1\ndef quaternion_to_euler(x, y, z, w):\n\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z\n    \ndef feature_engineering(df):\n    \n    df_new = pd.DataFrame()\n    \n    # calculate euclidean distance\n    df['total_angular_velocity'] = np.sqrt(df['angular_velocity_X'] ** 2 + df['angular_velocity_Y'] ** 2 + df['angular_velocity_Z'] ** 2)\n    df['total_linear_acceleration'] = np.sqrt(df['linear_acceleration_X'] ** 2 + df['linear_acceleration_Y'] ** 2 + df['linear_acceleration_Z'] ** 2)\n    df['total_orientation'] = np.sqrt(df['orientation_X'] ** 2 + df['orientation_Y'] ** 2 + df['orientation_Z'] ** 2 + df['orientation_W'] ** 2)\n\n    # calculate absolute value \n    df['linear_acceleration_X_abs'] = df['linear_acceleration_X'].where(df['linear_acceleration_X']>=0, - df['linear_acceleration_X'])\n    df['linear_acceleration_Y_abs'] = df['linear_acceleration_Y'].where(df['linear_acceleration_Y']>=0, - df['linear_acceleration_Y'])\n    df['linear_acceleration_Z_abs'] = df['linear_acceleration_Z'].where(df['linear_acceleration_Z']>=0, - df['linear_acceleration_Z'])\n    \n    # how much Robot have acceleration compared to velocity                                           \n    df['acc_vs_vel'] = df['total_linear_acceleration'] \/ df['total_angular_velocity']\n    \n    x, y, z, w = df['orientation_X'].tolist(), df['orientation_Y'].tolist(), df['orientation_Z'].tolist(), df['orientation_W'].tolist()\n    nx, ny, nz = [], [], []\n    \n    for i in range(len(x)):\n        \n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    df['euler_x'] = nx\n    df['euler_y'] = ny\n    df['euler_z'] = nz\n    \n    df['total_angle'] = np.sqrt(df['euler_x'] ** 2 + df['euler_y'] ** 2 + df['euler_z'] ** 2)\n    df['angle_vs_acc'] = df['total_angle'] \/ df['total_linear_acceleration']\n    df['angle_vs_vel'] = df['total_angle'] \/ df['total_angular_velocity']\n    \n    # add interaction feature\n    df['acc_times_vel'] = df['total_linear_acceleration'] * df['total_angular_velocity']\n    df['angle_times_acc'] = df['total_angle'] * df['total_linear_acceleration']\n    df['angle_times_vel'] = df['total_angle'] * df['total_angular_velocity']\n    df['angle_times_vel_times_acc'] = df['total_angle'] * df['total_angular_velocity'] * df['total_linear_acceleration']\n\n    def f1(x):\n        return np.mean(np.diff(np.abs(np.diff(x))))\n    \n    def f2(x):\n        return np.mean(np.abs(np.diff(x)))\n    \n    for col in df.columns:\n        \n        if col in ['row_id', 'series_id', 'measurement_number']:\n            continue\n        \n        df_new[col + '_mean'] = df.groupby(['series_id'])[col].mean()\n        df_new[col + '_min'] = df.groupby(['series_id'])[col].min()\n        df_new[col + '_max'] = df.groupby(['series_id'])[col].max()\n        df_new[col + '_std'] = df.groupby(['series_id'])[col].std()\n        df_new[col + '_max_to_min'] = df_new[col + '_max'] \/ df_new[col + '_min']\n\n        df_new[col + '_mean_abs_change'] = df.groupby('series_id')[col].apply(f2)\n        df_new[col + '_mean_change_of_abs_change'] = df.groupby('series_id')[col].apply(f1)\n        \n        df_new[col + '_abs_max'] = df.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n        df_new[col + '_abs_min'] = df.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n\n\n    return df_new","ecebaed3":"with multiprocessing.Pool() as pool: \n    train, test = pool.map(feature_engineering, [train, test])   ","d0655221":"train = train.reset_index()\ntest = test.reset_index()","f76fdbb4":"le = LabelEncoder()\ntarget['surface'] = le.fit_transform(target['surface'])","ac43943c":"def _distance(a, b):\n    distance = np.linalg.norm(a - b)\n    \n    return distance\n\ndef _knn_distance(xtr_c, target, k):\n    distances = np.array([_distance(target, x) for x in xtr_c])\n    sorted_distances = np.sort(distances)\n    nearest_distances = sorted_distances[:k]\n    sum_distances = np.sum(nearest_distances)\n\n    return sum_distances\n\ndef _knn_distance_fold(xtr_c, k, folds, target):\n    distances = np.empty([folds])\n\n    kf = KFold(shuffle=True, n_splits=folds)\n    for i, (train_index, _) in enumerate(kf.split(xtr_c)):\n        xtr_c_sampled = xtr_c[train_index]\n        distance = _knn_distance(xtr_c_sampled, target, k)\n        distances[i] = distance\n\n    average_distance = distances.mean()\n\n    return average_distance\n\n\ndef knn_extract(xtr, ytr, xte, k=1, folds=5, nprocesses=-1):\n    if nprocesses == -1:\n        nprocesses = multiprocessing.cpu_count()\n\n    classes = np.unique(ytr)\n    features = np.zeros([len(xte), len(classes) * k])\n\n    for i, class_ in enumerate(classes):\n        xtr_c = xtr[ytr == class_]\n\n        for j, k_n in enumerate(range(1, k + 1), 1):\n            f = functools.partial(_knn_distance_fold, xtr_c, k_n, folds)\n            with ProcessPoolExecutor(max_workers=nprocesses) as executor:\n                feature = executor.map(f, xte)\n                features[:, i * j] = list(feature)\n\n    return features","4b6c1407":"train_array = train.values\ntest_array = test.values\nknn_train = knn_extract(train_array, target['surface'].values, train_array)\nknn_test = knn_extract(train_array, target['surface'].values, test_array)","912d9fcd":"knn_train = pd.DataFrame(knn_train)\nknn_test = pd.DataFrame(knn_test)\nknn_train = pd.concat([train, knn_train], axis=1)\nknn_test = pd.concat([test, knn_test], axis=1)","f217be73":"# replace NAN to 0\ntrain.fillna(0, inplace=True)\ntest.fillna(0, inplace=True)\nknn_train.fillna(0, inplace=True)\nknn_test.fillna(0, inplace=True)\n\n# replace infinite value to zero\ntrain.replace(-np.inf, 0, inplace=True)\ntrain.replace(np.inf, 0, inplace=True)\ntest.replace(-np.inf, 0, inplace=True)\ntest.replace(np.inf, 0, inplace=True)\nknn_train.replace(-np.inf, 0, inplace=True)\nknn_train.replace(np.inf, 0, inplace=True)\nknn_test.replace(-np.inf, 0, inplace=True)\nknn_test.replace(np.inf, 0, inplace=True)","55b0037c":"folds = StratifiedKFold(n_splits=100, shuffle=True, random_state=546789)\nsub_preds_rf = np.zeros((knn_test.shape[0], 9))\nscore = 0\ncounter = 0\n\nfor train_index, test_index in folds.split(knn_train, target['surface']):\n    \n    clf_knn = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n    clf_knn.fit(knn_train.iloc[train_index], target['surface'][train_index])\n    sub_preds_rf += clf_knn.predict_proba(knn_test) \/ folds.n_splits\n    score += clf_knn.score(knn_train.iloc[test_index], target['surface'][test_index])\n    counter += 1\n\nprint('avg accuracy : {}'.format(score \/ folds.n_splits))","f56fc124":"fti_knn = clf_knn.feature_importances_\n\nfor i, feat in enumerate(knn_train.columns):\n    print('{0} : {1:>.6f}'.format(feat, fti_knn[i]))","418ed257":"submit['surface'] = le.inverse_transform(sub_preds_rf.argmax(axis=1))\nsubmit.to_csv('submit_with_knn.csv', index=False)","ab6074ac":"folds = StratifiedKFold(n_splits=100, shuffle=True, random_state=546789)\nsub_preds_rf = np.zeros((test.shape[0], 9))\nscore = 0\ncounter = 0\n\nfor train_index, test_index in folds.split(train, target['surface']):\n    \n    clf = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n    clf.fit(train.iloc[train_index], target['surface'][train_index])\n    sub_preds_rf += clf.predict_proba(test) \/ folds.n_splits\n    score += clf.score(train.iloc[test_index], target['surface'][test_index])\n    counter += 1\n\nprint('avg accuracy : {}'.format(score \/ folds.n_splits))","fa8790ef":"fti = clf.feature_importances_\n\nfor i, feat in enumerate(train.columns):\n    print('\\t{0} : {1:>.6f}'.format(feat, fti[i]))","56d80af9":"submit['surface'] = le.inverse_transform(sub_preds_rf.argmax(axis=1))\nsubmit.to_csv('submit_without_knn.csv', index=False)","113c2042":"## Notebook Summary\n\nI have tried to extract features with K-NN based on this Japanese [article](https:\/\/blog.amedama.jp\/entry\/knn-feature-extraction).  \nAs a result, these features seemed to cause overfitting into train data set.  \n- trained with features extracted with k-NN\n   - Local CV avarage accuracy : 0.9681818337327661\n   - LB accuracy : 0.67\n- trained with features extracted **without k-NN**\n   - Local CV avarage accuracy : 0.9226371135121014\n   - LB accuracy : 0.72\n\nI don't know whether my scripts is correct or not. Please feel free to comment and advice!\n","582a0578":"### train with features without KNN","1be36d43":"### train with features with KNN"}}