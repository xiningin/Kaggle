{"cell_type":{"77db21d5":"code","6644dc62":"code","8ddd185f":"code","12fa7129":"code","9297cd6e":"code","0f02d5ac":"code","d8e9c8f7":"code","6bc6d506":"code","f9c24113":"code","97616423":"code","08820742":"code","4a83f1ce":"code","607a5fca":"code","dc173921":"code","cebeebee":"code","72b86c96":"code","f7e75fb0":"markdown","9fb0eaf4":"markdown","cdb4e4b5":"markdown","2dc94eee":"markdown","120ad0c7":"markdown","8cf027b5":"markdown","072fcaaa":"markdown"},"source":{"77db21d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm_notebook as tqdm\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm","6644dc62":"\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n","8ddd185f":"df_test = pd.read_csv('..\/input\/test.csv')","12fa7129":"df_test.drop(['ID_code'], axis=1, inplace=True)","9297cd6e":"df_test.head()","0f02d5ac":"df_test = df_test.values #convert to numpy array","d8e9c8f7":"unique_samples = []\nunique_count = np.zeros_like(df_test) #create a same shape (200000,200) of zero np","6bc6d506":"unique_count","f9c24113":"for feature in tqdm(range(df_test.shape[1])):\n    # loop thru each column, find which rows has value that never repeat in the same column and +1 in unique_count\n    \n    # return the indexes and counts on each unique value found in the column \n    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n    \n    ## uncomment to see what np.unique return.\n    #print (index_[:20])\n    #print (count_[:20])\n    #break\n    \n    ## [ 14030 119481 194633 103891  23396 141831 111894  64543  32828 186765  188883 109095  17040 112895   2680 152511  14952  50619   7246  71156]\n    ## [2 2 1 1 2 1 1 1 2 1 1 2 4 1 3 1 1 2 2 2]\n    \n    # meaning at index 14030 , the value 0.1887 repeated twice. (another 1 is index 19561)\n    \n    \n    ### the following line  only +1 those row with 1 occurrence indexes\n    unique_count[index_[count_ == 1], feature] += 1","97616423":"unique_count.shape","08820742":"unique_count[0:100,0:10]","4a83f1ce":"# Samples which have unique values are real the others are fake\nreal_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\nsynthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]","607a5fca":"real_samples_indexes","dc173921":"synthetic_samples_indexes","cebeebee":"# df_test_real = df_test[real_samples_indexes].copy()\n\n# generator_for_each_synthetic_sample = []\n# # Using 20,000 samples should be enough. \n# # You can use all of the 100,000 and get the same results (but 5 times slower)\n# for cur_sample_index in tqdm(synthetic_samples_indexes[:20000]):\n#     cur_synthetic_sample = df_test[cur_sample_index]\n#     potential_generators = df_test_real == cur_synthetic_sample\n    \n#     #print (cur_synthetic_sample)\n#     #print (potential_generators)\n    \n#     # A verified generator for a synthetic sample is achieved\n#     # only if the value of a feature appears only once in the\n#     # entire real samples set\n#     features_mask = np.sum(potential_generators, axis=0) == 1\n#     verified_generators_mask = np.any(potential_generators[:, features_mask], axis=1)\n#     verified_generators_for_sample = real_samples_indexes[np.argwhere(verified_generators_mask)[:, 0]]\n#     generator_for_each_synthetic_sample.append(set(verified_generators_for_sample))","72b86c96":"# public_LB = generator_for_each_synthetic_sample[0]\n# for x in tqdm(generator_for_each_synthetic_sample):\n#     if public_LB.intersection(x):\n#         public_LB = public_LB.union(x)\n\n# private_LB = generator_for_each_synthetic_sample[1]\n# for x in tqdm(generator_for_each_synthetic_sample):\n#     if private_LB.intersection(x):\n#         private_LB = private_LB.union(x)\n        \n# print(len(public_LB))\n# print(len(private_LB))","f7e75fb0":"#### observe row 3, column 1 has a unique value that never occur in column one","9fb0eaf4":"from the fake row npy file we know that:...\n\nfake rows are:\narray([ 0,  1,  2,  4,  5,  6,  8,  9, 10, 12, 13, 14, 19, 23, 25, 26, 27,\n       28, 30, 31])\n","cdb4e4b5":"The rest is about detecting which sample is use to generate the public leader board and private leader board which i will **NOT** go thru","2dc94eee":"## let compare 1 fake row and 1 real row\n#### fake: row 0\n#### real: row 3","120ad0c7":"by observing 1 column.\n\nvalue 0.1887 occur twice in column var_01 (14030 & 19561)\n\nthe value which occur only once, we mark it in unique_count","8cf027b5":"### sum each row, \nif sum greater than 1 => real sample\n\nif sum == 0  => fake sample","072fcaaa":"## Understanding of \"fake\" sample in test set\ndig into deeper what #yag320 mean in the unique occurence in the test set.\nhttps:\/\/www.kaggle.com\/yag320\/list-of-fake-samples-and-public-private-lb-split\/comments"}}