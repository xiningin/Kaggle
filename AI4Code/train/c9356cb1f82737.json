{"cell_type":{"fa34f376":"code","50f348d7":"code","a051720f":"code","921fd824":"code","8fe772c5":"code","fbd6fafb":"code","ecad1d0e":"code","8a95d982":"code","154ed2dd":"code","b7fb48e6":"code","c26f82f0":"code","0ab691b4":"code","74946470":"code","2199c835":"code","ec4b1905":"code","2aeb1f72":"code","af7d1fbe":"code","fa054a5e":"code","b77bcc4b":"code","fc9df128":"code","339506fa":"code","deee95dc":"code","039ecdc9":"code","8556fcfe":"markdown","34725d0a":"markdown","1f112742":"markdown","18cc7cd8":"markdown","9d098aff":"markdown","da59dcb5":"markdown","ecc51599":"markdown","587dcb3b":"markdown","a7b2ba7f":"markdown","df4da217":"markdown","24941956":"markdown","514f2177":"markdown","4dfedaa0":"markdown","e5bf30e4":"markdown"},"source":{"fa34f376":"from glob import glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\nfrom PIL import Image\nimport cv2\nimport keras\nfrom keras.applications.vgg16 import preprocess_input,VGG16\nimport tensorflow as tf\nfrom keras.models import Sequential,Model\nfrom keras.layers import MaxPooling2D,Conv2D,Dense,BatchNormalization,Dropout,GlobalAveragePooling2D,Flatten,Input\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom sklearn.metrics import classification_report\nfrom keras.utils.vis_utils import plot_model\nimport warnings\nwarnings.filterwarnings('ignore')","50f348d7":"# Function to load images\n\ndef convert_image_to_dataset(file_location):\n    label=0\n    df=pd.DataFrame()\n    for category in glob(file_location+'\/*'):\n        for file in tqdm(glob(category+'\/*')):\n            img_array=cv2.imread(file)\n            img_array=cv2.resize(img_array,(224, 224))\n            data=pd.DataFrame({'image':[img_array],'label':[label]})\n            df=df.append(data)\n        label+=1\n    return df.sample(frac=1).reset_index(drop=True)","a051720f":"# Function to convert output labels to its class of tumor.\n\n\ndef inverse_classes(num):\n    if num==0:\n        return 'Glioma Tumor'\n    elif num==1:\n        return 'Meningioma Tumor'\n    elif num==2:\n        return 'No Tumor'\n    else:\n        return 'Pituitary Tumor'\n    ","921fd824":"train_data=convert_image_to_dataset('..\/input\/brain-tumor-classification-mri\/Training')\ntrain_x=np.array(train_data.image.to_list())","8fe772c5":"test_data=convert_image_to_dataset('..\/input\/brain-tumor-classification-mri\/Testing')\ntest_x=np.array(test_data.image.to_list())","fbd6fafb":"plt.pie(train_data.label.value_counts(),startangle=90,explode=[0.1,0.1,0.1,0.2],autopct='%0.2f%%',\n        labels=['Meningioma_tumor', 'Pituitary Tumor', 'No Tumor', 'Glioma Tumor'],radius=3)\nplt.show()","ecad1d0e":"plt.figure(figsize=(20,15))\nfor i in range(12):\n    plt.subplot(4,3,(i%12)+1)\n    index=np.random.randint(2000)\n    plt.title('This image is of {0}'.format(inverse_classes(train_data.label[index])),fontdict={'size':20,'weight':'bold'})\n    plt.imshow(train_data.image[index])\n    plt.tight_layout()","8a95d982":"early_stop=EarlyStopping(patience=3)\nreduceLR=ReduceLROnPlateau(patience=2)","154ed2dd":"\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","b7fb48e6":"# instantiating the model in the strategy scope creates the model on the TPU\n\nwith tpu_strategy.scope():\n    model_cnn=Sequential()\n    model_cnn.add(Input(shape=(224,224,3)))\n    model_cnn.add(Conv2D(128,(3,3)))\n    model_cnn.add(MaxPooling2D((2,2)))\n    model_cnn.add(BatchNormalization())\n    model_cnn.add(Conv2D(64,(3,3)))\n    model_cnn.add(MaxPooling2D((2,2)))\n    model_cnn.add(BatchNormalization())\n    model_cnn.add(Conv2D(32,(3,3)))\n    model_cnn.add(MaxPooling2D((2,2)))\n    model_cnn.add(BatchNormalization())\n    model_cnn.add(Flatten())\n    model_cnn.add(Dense(128,activation='relu'))\n    model_cnn.add(Dropout(0.2))\n    model_cnn.add(Dense(64,activation='relu'))\n    model_cnn.add(Dense(4,activation='softmax'))\n    model_cnn.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","c26f82f0":"plot_model(model_cnn)","0ab691b4":"r1=model_cnn.fit(train_x,train_data.label,validation_split=0.1,epochs=20,callbacks=[reduceLR])","74946470":"plt.figure(figsize=(10,8))\nplt.plot(r1.history['val_accuracy'])\nplt.plot(r1.history['accuracy'])\nplt.legend(['val_accuracy','accuracy'])\nplt.show()","2199c835":"plt.figure(figsize=(10,8))\nplt.plot(r1.history['val_loss'])\nplt.plot(r1.history['loss'])\nplt.legend(['val_loss','loss'])\nplt.show()","ec4b1905":"# Predictions on Test Datasets using CNN model\n\ntest_pred=np.argmax(model_cnn.predict(test_x),axis=1)\nprint(classification_report(test_data.label,test_pred))","2aeb1f72":"with tpu_strategy.scope():\n    vgg_model = VGG16(weights='imagenet',include_top=False)\n    for layers in vgg_model.layers:\n        layers.trainable=False\n    x=vgg_model.output\n    x=GlobalAveragePooling2D()(x)\n    x=Dense(128,activation='relu')(x)\n    x=Dropout(0.15)(x)\n    output=Dense(4,activation='softmax')(x)\n    model2=Model(inputs=vgg_model.input,outputs=output)\n    model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","af7d1fbe":"plot_model(model2)","fa054a5e":"r2=model2.fit(train_x,train_data.label,validation_split=0.1,epochs=20,callbacks=[early_stop,reduceLR])","b77bcc4b":"plt.figure(figsize=(10,8))\nplt.plot(r2.history['val_accuracy'])\nplt.plot(r2.history['accuracy'])\nplt.legend(['val_accuracy','accuracy'])\nplt.show()","fc9df128":"plt.figure(figsize=(10,8))\nplt.plot(r2.history['val_loss'])\nplt.plot(r2.history['loss'])\nplt.legend(['val_loss','loss'])\nplt.show()","339506fa":"# Predictions on Test Datasets using VGG16 model\n\ntest_pred_transfer=np.argmax(model2.predict(test_x),axis=1)\nprint(classification_report(test_data.label,test_pred_transfer))","deee95dc":"# Prediction using VGG16 model\n\nplt.figure(figsize=(15,12))\nfor i in range(4):\n    plt.subplot(3,2,(i%12)+1)\n    index=np.random.randint(200)\n    pred_class=inverse_classes(np.argmax(model2.predict(np.reshape(test_x[index],(-1,224,224,3))),axis=1))\n    plt.title('This image is of {0} and is predicted as {1}'.format(inverse_classes(test_data.label[index]),pred_class),\n              fontdict={'size':15})\n    plt.imshow(test_x[index])\n    plt.tight_layout()","039ecdc9":"# Prediction using CNN model\n\nplt.figure(figsize=(15,12))\nfor i in range(4):\n    plt.subplot(3,2,(i%12)+1)\n    index=np.random.randint(200)\n    pred_class=inverse_classes(np.argmax(model_cnn.predict(np.reshape(test_x[index],(-1,224,224,3))),axis=1))\n    plt.title('This image is of {0} and is predicted as {1}'.format(inverse_classes(test_data.label[index]),pred_class),\n              fontdict={'size':15})\n    plt.imshow(test_x[index])\n    plt.tight_layout()","8556fcfe":"<center><img src=\"https:\/\/media.istockphoto.com\/photos\/brain-cancer-picture-id174927353?k=6&m=174927353&s=612x612&w=0&h=P3EzH6J-haFHzmKQ8RzkfotD_lsygXzNUL72Dg3pfK0=\",height='300',width='600'><\/center>","34725d0a":"# Here we are going to explore two processes by which we could solve this problem,\n\n1. Traditional CNN Approach\n\n2. Transfer Learning Approach","1f112742":"<h1><center>INTRODUCTION TO PROBLEM OF BRAIN TUMOR<\/center><\/h1>\nA Brain tumor is considered as one of the aggressive diseases, among children and adults. Brain tumors account for 85 to 90 percent of all primary Central Nervous System(CNS) tumors. Every year, around 11,700 people are diagnosed with a brain tumor. The 5-year survival rate for people with a cancerous brain or CNS tumor is approximately 34 percent for men and36 percent for women. Brain Tumors are classified as: Benign Tumor, Malignant Tumor, Pituitary Tumor, etc. Proper treatment, planning, and accurate diagnostics should be implemented to improve the life expectancy of the patients. The best technique to detect brain tumors is Magnetic Resonance Imaging (MRI). A huge amount of image data is generated through the scans. These images are examined by the radiologist. A manual examination can be error-prone due to the level of complexities involved in brain tumors and their properties.","18cc7cd8":"<h5 style=\"background-color:#f4abcd;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\"><b>Importing Libraries<\/b><\/h5>\n","9d098aff":"<h1 style=\"background-color:#f4abcd;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\"><b>Visualizing Dataset<\/b><\/h1>\n","da59dcb5":"## Here We could clearly observe that both the approaches worked quite well, with not much difference in accuracy. Though VGG16 model worked quite more efficiently, Because of two reasons:-\n1. The validation accuracy and test accuracy is higher than the other method.\n2. Time of computation and computation power is required lesser than traditional method as pretrained weights are used.","ecc51599":"<h4 style=\"background-color:#f4a123;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\" ><b>Traditional CNN Approach<\/b><\/h4>\n","587dcb3b":"<h5 style=\"background-color:#a41234;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\" ><b>Conclusion<\/b><\/h5>\n","a7b2ba7f":"<h5 style=\"background-color:#a4adcb;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\" ><b>Visualizing Prediction on test dataset<\/b><\/h5>\n","df4da217":"<h1 style=\"background-color:#f4abcd;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\"><b>Callbacks Functions<\/b><\/h1>\n","24941956":"<h5 style=\"background-color:#f4a123;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\" ><b>Transfer Learning Approach (VGG 16)<\/b><\/h5>\n","514f2177":"## <i>If you liked the notebook do upvote it. If having any queries or suggestion ,write in the comment section below.<\/i>","4dfedaa0":"<h1 style=\"background-color:#8ffaaa;font-family:newtimeroman;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\"><b><u>Brain Tumor Classification<\/u><\/b><\/h1>\n","e5bf30e4":"## What is Transfer Learning?\n\nTransfer learning is a machine learning technique where a model trained on one task is re-purposed on a second related task.\n    In case of image processing we use some pretrained models like VGG-16,RasNet,VGG-19,etc. Which is trained on large ImageNet dataset.\n\n## What is imagenet?\n\nThe ImageNet project is a large visual database designed for use in visual object recognition software research. More than 14 million images have been hand-annotated by the project to indicate what objects are pictured and in at least one million of the images, bounding boxes are also provided. ImageNet contains more than 20,000 categories with a typical category, such as \"balloon\" or \"strawberry\", consisting of several hundred images. \n    Here we use VGG-16 to train our model.\n    \n## What is VGG-16?\n\nVGG16 (also called OxfordNet) is a convolutional neural network architecture named after the Visual Geometry Group from Oxford, who developed it. It was used to win the ILSVR (ImageNet) competition in 2014. VGG-16 is a convolutional neural network that is 16 layers deep. The network has learned rich feature representations for a wide range of images. The network has an image input size of 224-by-224. "}}