{"cell_type":{"4d05754e":"code","0b6e7109":"code","7917f228":"code","00d5288e":"code","ef506be4":"code","c3c58290":"code","272175a3":"code","9d955ffc":"code","207fb216":"code","9f1752b6":"code","a6072c2f":"code","452dec56":"code","26f1bbe3":"code","d36cc214":"code","a379cd3b":"markdown","418ef486":"markdown","92015fd5":"markdown"},"source":{"4d05754e":"# sources:\n# https:\/\/www.kaggle.com\/philculliton\/nlp-getting-started-tutorial","0b6e7109":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7917f228":"%time\nimport sys\nimport warnings\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n    \nimport seaborn as sns\nimport sklearn, matplotlib\n\nprint(\"Python version:\", sys.version)\nprint(\"Version info.:\", sys.version_info)\nprint(\"pandas version:\", pd.__version__)\nprint(\"numpy version:\", np.__version__)\nprint(\"skearn version:\", sklearn.__version__)\nprint(\"matplotlib version:\", matplotlib.__version__)\nprint(\"seaborn version:\", sns.__version__)","00d5288e":"from sklearn import feature_extraction, linear_model, model_selection, preprocessing","ef506be4":"train_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\n\ndisplay(train_df.shape, test_df.shape)\ndisplay(train_df.head(), test_df.head())","c3c58290":"train_df[~train_df['location'].isnull()].head()","272175a3":"display(train_df[train_df[\"target\"] == 0][\"text\"].values[1])\ndisplay(train_df[train_df[\"target\"] == 1][\"text\"].values[1])","9d955ffc":"# We'll use scikit-learn's CountVectorizer to count the words in each tweet and turn them into data our machine learning model can process.\ncount_vectorizer = feature_extraction.text.CountVectorizer()\n\n## let's get counts for the first 5 tweets in the data\nexample_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])\n\n## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\nprint(example_train_vectors[0].todense().shape)\nprint(example_train_vectors[0].todense())","207fb216":"# create vectors for all of our tweets.\ntrain_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n\n## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n# that the tokens in the train vectors are the only ones mapped to the test vectors - \n# i.e. that the train and test vectors use the same set of tokens.\ntest_vectors = count_vectorizer.transform(test_df[\"text\"])","9f1752b6":"## Linear model\n## Our vectors are really big, so we want to push our model's weights\n## toward 0 without completely discounting different words - ridge regression \n## is a good way to do this.\nclf = linear_model.RidgeClassifier()","a6072c2f":"scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\nscores","452dec56":"clf.fit(train_vectors, train_df[\"target\"])\nclf","26f1bbe3":"sample_submission = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\nsample_submission[\"target\"] = clf.predict(test_vectors)\nsample_submission.head()","d36cc214":"sample_submission.to_csv(\"submission.csv\", index=False)","a379cd3b":"# Read and explore data","418ef486":"# Models","92015fd5":"# Building vectors"}}