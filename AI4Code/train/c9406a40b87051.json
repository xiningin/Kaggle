{"cell_type":{"2cb6f176":"code","cb9589cd":"code","3ae93a7b":"code","2af7846b":"code","dfe64fa5":"code","67cbfd1a":"code","dc753bf1":"code","02dc89c2":"code","4aa4e72d":"code","c192dddd":"code","4ea471ef":"code","c5947aa0":"code","23bf0148":"code","a4a0cd5f":"code","cdc234e8":"code","6a5c141b":"code","e796ddb1":"code","851e6645":"code","cf27e590":"code","74d6259b":"code","1ecf5c5a":"markdown","c546e83b":"markdown","931bee29":"markdown","ee12b126":"markdown","64e59fe6":"markdown","ea967783":"markdown","7181bfa4":"markdown","b48fe5c7":"markdown","e8a3d5e2":"markdown","5311e140":"markdown","de8c2afc":"markdown","0e06af50":"markdown","609f79a0":"markdown","24da6929":"markdown","f0acbc7c":"markdown","7303fd65":"markdown","2c62ea91":"markdown","ae74e4f3":"markdown","87a117b3":"markdown"},"source":{"2cb6f176":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cb9589cd":"!pip install --upgrade plotly\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","3ae93a7b":"data = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\ndata = data.drop(columns = ['Time from Start to Finish (seconds)'])\ndata = data.drop([0])\ndata","2af7846b":"plt.figure(figsize=(15, 5))\nplt.xticks(size=20)\n\nq1 = sns.countplot(x=data['Q1'], data=data)\nq1\n\nfor p in q1.patches:\n  height = p.get_height()\n  q1.text(p.get_x()+p.get_width()\/2., height, height , ha=\"center\")\n  \nplt.title('Age Participant of Kaggle Survey 2020', fontsize=20)\nplt.show()","dfe64fa5":"q2 = data['Q2'].value_counts()\nfig = px.pie(names=q2.index, values=q2.values)\nfig.show()","67cbfd1a":"plt.figure(figsize=(15, 5))\nplt.yticks(size=20)\n\nq3 = sns.countplot(y=data['Q3'], data=data, order=data['Q3'].value_counts().iloc[:10].index)\nq3\n\nplt.title('Country Participant of Kaggle Survey 2020', fontsize=20)\nplt.show()\n\ndata['Q3'].value_counts()[:10]","dc753bf1":"notebooks = [data['Q10_Part_1'].any(), data['Q10_Part_2'].any(), data['Q10_Part_3'].any(), data['Q10_Part_4'].any(),\n             data['Q10_Part_5'].any(), data['Q10_Part_6'].any(), data['Q10_Part_7'].any(), data['Q10_Part_8'].any(),\n             data['Q10_Part_9'].any(), data['Q10_Part_10'].any(), data['Q10_Part_11'].any(), data['Q10_Part_12'].any(),\n             data['Q10_Part_13'].any(), data['Q10_OTHER'].any()]\n\ntotals = [data['Q10_Part_1'].value_counts().tolist()[0], data['Q10_Part_2'].value_counts().tolist()[0],\n          data['Q10_Part_3'].value_counts().tolist()[0], data['Q10_Part_4'].value_counts().tolist()[0],\n          data['Q10_Part_5'].value_counts().tolist()[0], data['Q10_Part_6'].value_counts().tolist()[0],\n          data['Q10_Part_7'].value_counts().tolist()[0], data['Q10_Part_8'].value_counts().tolist()[0],\n          data['Q10_Part_9'].value_counts().tolist()[0], data['Q10_Part_10'].value_counts().tolist()[0],\n          data['Q10_Part_11'].value_counts().tolist()[0], data['Q10_Part_12'].value_counts().tolist()[0],\n          data['Q10_Part_13'].value_counts().tolist()[0], data['Q10_OTHER'].value_counts().tolist()[0]]\n\ndf = pd.DataFrame(\n    dict(notebooks=notebooks, totals=totals)\n)\n\nfig = px.treemap(df, path=['notebooks'], values='totals', width=1000, height=1000)\nfig.show()","02dc89c2":"plt.figure(figsize=(15, 5))\nplt.yticks(size=20)\n\nq11 = sns.countplot(y=data['Q11'], data=data)\nq11\n\nplt.title('Computing Platform of Kaggle Survey 2020', fontsize=20)\nplt.show()\n\ndata['Q11'].value_counts()","4aa4e72d":"plt.figure(figsize=(15, 5))\nplt.yticks(size=20)\n\nq12 = {'1': [data['Q12_Part_1'].any(), data['Q12_Part_2'].any(), data['Q12_Part_3'].any(), data['Q12_OTHER'].any()],\n       '2': [data['Q12_Part_1'].value_counts().tolist()[0], data['Q12_Part_2'].value_counts().tolist()[0],\n             data['Q12_Part_3'].value_counts().tolist()[0], data['Q12_OTHER'].value_counts().tolist()[0]]}\n             \nsns.barplot(x=q12['1'], y=q12['2'])\n\nplt.title('Hardware of Kaggle Survey 2020', fontsize=16)\nplt.show()\n\nprint(data['Q12_Part_1'].any(), data['Q12_Part_1'].value_counts().tolist()[0])\nprint(data['Q12_Part_2'].any(), data['Q12_Part_2'].value_counts().tolist()[0])\nprint(data['Q12_Part_3'].any(), data['Q12_Part_3'].value_counts().tolist()[0])\nprint(data['Q12_OTHER'].any(), data['Q12_OTHER'].value_counts().tolist()[0])","c192dddd":"plt.figure(figsize=(15, 5))\nplt.yticks(size=20)\n\nq13 = sns.countplot(x=data['Q13'], data=data)\nq13\n\nplt.title('TPU used of hours | Kaggle Survey 2020', fontsize=20)\nplt.show()\n\n\nprint(data['Q12_Part_1'].any(), data['Q12_Part_1'].value_counts().tolist()[0])\nprint(data['Q12_Part_2'].any(), data['Q12_Part_2'].value_counts().tolist()[0])\nprint(data['Q12_Part_3'].any(), data['Q12_Part_3'].value_counts().tolist()[0])\nprint(data['Q12_OTHER'].any(), data['Q12_OTHER'].value_counts().tolist()[0])","4ea471ef":"visual = [data['Q14_Part_1'].any(), data['Q14_Part_2'].any(), data['Q14_Part_3'].any(), data['Q14_Part_4'].any(),\n             data['Q14_Part_5'].any(), data['Q14_Part_6'].any(), data['Q14_Part_7'].any(), data['Q14_Part_8'].any(),\n             data['Q14_Part_9'].any(), data['Q14_Part_10'].any(), data['Q14_Part_11'].any(), data['Q14_OTHER'].any()]\n\ntotals = [data['Q14_Part_1'].value_counts().tolist()[0], data['Q14_Part_2'].value_counts().tolist()[0],\n          data['Q14_Part_3'].value_counts().tolist()[0], data['Q14_Part_4'].value_counts().tolist()[0],\n          data['Q14_Part_5'].value_counts().tolist()[0], data['Q14_Part_6'].value_counts().tolist()[0],\n          data['Q14_Part_7'].value_counts().tolist()[0], data['Q14_Part_8'].value_counts().tolist()[0],\n          data['Q14_Part_9'].value_counts().tolist()[0], data['Q14_Part_10'].value_counts().tolist()[0],\n          data['Q14_Part_11'].value_counts().tolist()[0], data['Q14_OTHER'].value_counts().tolist()[0]]\n\ndf = pd.DataFrame(\n    dict(visual=visual, totals=totals)\n)\n\nfig = px.treemap(df, path=['visual'], values='totals', width=1000, height=1000)\nfig.show()","c5947aa0":"library = [data['Q16_Part_1'].any(), data['Q16_Part_2'].any(), data['Q16_Part_3'].any(), data['Q16_Part_4'].any(),\n             data['Q16_Part_5'].any(), data['Q16_Part_6'].any(), data['Q16_Part_7'].any(), data['Q16_Part_8'].any(),\n             data['Q16_Part_9'].any(), data['Q16_Part_10'].any(), data['Q16_Part_11'].any(), data['Q16_Part_12'].any(),\n             data['Q16_Part_13'].any(), data['Q16_Part_14'].any(), data['Q16_Part_15'].any(), data['Q16_OTHER'].any()]\n\ntotals = [data['Q16_Part_1'].value_counts().tolist()[0], data['Q16_Part_2'].value_counts().tolist()[0],\n          data['Q16_Part_3'].value_counts().tolist()[0], data['Q16_Part_4'].value_counts().tolist()[0],\n          data['Q16_Part_5'].value_counts().tolist()[0], data['Q16_Part_6'].value_counts().tolist()[0],\n          data['Q16_Part_7'].value_counts().tolist()[0], data['Q16_Part_8'].value_counts().tolist()[0],\n          data['Q16_Part_9'].value_counts().tolist()[0], data['Q16_Part_10'].value_counts().tolist()[0],\n          data['Q16_Part_11'].value_counts().tolist()[0], data['Q16_Part_12'].value_counts().tolist()[0],\n          data['Q16_Part_13'].value_counts().tolist()[0], data['Q16_Part_14'].value_counts().tolist()[0],\n          data['Q16_Part_15'].value_counts().tolist()[0], data['Q16_OTHER'].value_counts().tolist()[0]]\n\ndf = pd.DataFrame(\n    dict(library=library, totals=totals)\n)\n\nfig = px.treemap(df, path=['library'], values='totals', width=1000, height=1000)\nfig.show()","23bf0148":"plt.figure(figsize=(15, 5))\nplt.yticks(size=20)\n\nq17 = {'1': [data['Q17_Part_1'].any(), data['Q17_Part_2'].any(), data['Q17_Part_3'].any(), data['Q17_Part_4'].any(),\n             data['Q17_Part_5'].any(), data['Q17_Part_6'].any(), data['Q17_Part_7'].any(), data['Q17_Part_8'].any(),\n             data['Q17_Part_9'].any(), data['Q17_Part_10'].any(), data['Q17_Part_11'].any(), data['Q17_OTHER'].any()],\n       '2': [data['Q17_Part_1'].value_counts().tolist()[0], data['Q17_Part_2'].value_counts().tolist()[0],\n             data['Q17_Part_3'].value_counts().tolist()[0], data['Q17_Part_4'].value_counts().tolist()[0],\n             data['Q17_Part_5'].value_counts().tolist()[0], data['Q17_Part_6'].value_counts().tolist()[0],\n             data['Q17_Part_7'].value_counts().tolist()[0], data['Q17_Part_8'].value_counts().tolist()[0],\n             data['Q17_Part_9'].value_counts().tolist()[0], data['Q17_Part_10'].value_counts().tolist()[0],\n             data['Q17_Part_11'].value_counts().tolist()[0], data['Q17_OTHER'].value_counts().tolist()[0]]}\n  \nsns.barplot(y=q17['1'], x=q17['2'])\n\nplt.title('ML Algorithm of Kaggle Survey 2020', fontsize=20)\nplt.show()","a4a0cd5f":"labels = [data['Q18_Part_1'].any(), data['Q18_Part_2'].any(), data['Q18_Part_3'].any(), data['Q18_Part_4'].any(),\n             data['Q18_Part_5'].any(), data['Q18_Part_6'].any(), data['Q18_OTHER'].any()]\n\nvalues = [data['Q18_Part_1'].value_counts().tolist()[0], data['Q18_Part_2'].value_counts().tolist()[0],\n          data['Q18_Part_3'].value_counts().tolist()[0], data['Q18_Part_4'].value_counts().tolist()[0],\n          data['Q18_Part_5'].value_counts().tolist()[0], data['Q18_Part_6'].value_counts().tolist()[0],\n          data['Q18_OTHER'].value_counts().tolist()[0]]\n\ndf = pd.DataFrame(\n    dict(labels=labels, values=values)\n)\n\nfig = px.treemap(df, path=['labels'], values='values', width=1000, height=1000)\nfig.show()","cdc234e8":"labels = [data['Q19_Part_1'].any(), data['Q19_Part_2'].any(), data['Q19_Part_3'].any(), data['Q19_Part_4'].any(),\n             data['Q19_Part_5'].any(),  data['Q19_OTHER'].any()]\n\nvalues = [data['Q19_Part_1'].value_counts().tolist()[0], data['Q19_Part_2'].value_counts().tolist()[0],\n          data['Q19_Part_3'].value_counts().tolist()[0], data['Q19_Part_4'].value_counts().tolist()[0],\n          data['Q19_Part_5'].value_counts().tolist()[0], data['Q19_OTHER'].value_counts().tolist()[0]]\n\nfix = go.Figure(data=[go.Pie(labels=labels, values=values)])\nfix.show()","6a5c141b":"cloud = [data['Q26_A_Part_1'].any(), data['Q26_A_Part_2'].any(), data['Q26_A_Part_3'].any(), data['Q26_A_Part_4'].any(),\n             data['Q26_A_Part_5'].any(), data['Q26_A_Part_6'].any(), data['Q26_A_Part_7'].any(), data['Q26_A_Part_8'].any(),\n             data['Q26_A_Part_9'].any(), data['Q26_A_Part_10'].any(), data['Q26_A_Part_11'].any(), data['Q26_A_OTHER'].any()]\n\ntotals = [data['Q26_A_Part_1'].value_counts().tolist()[0], data['Q26_A_Part_2'].value_counts().tolist()[0],\n          data['Q26_A_Part_3'].value_counts().tolist()[0], data['Q26_A_Part_4'].value_counts().tolist()[0],\n          data['Q26_A_Part_5'].value_counts().tolist()[0], data['Q26_A_Part_6'].value_counts().tolist()[0],\n          data['Q26_A_Part_7'].value_counts().tolist()[0], data['Q26_A_Part_8'].value_counts().tolist()[0],\n          data['Q26_A_Part_9'].value_counts().tolist()[0], data['Q26_A_Part_10'].value_counts().tolist()[0],\n          data['Q26_A_Part_11'].value_counts().tolist()[0], data['Q26_A_OTHER'].value_counts().tolist()[0]]\n\ndf = pd.DataFrame(\n    dict(cloud=cloud, totals=totals)\n)\n\nfig = px.treemap(df, path=['cloud'], values='totals', width=1000, height=1000)\nfig.show()","e796ddb1":"plt.figure(figsize=(15, 5))\nplt.yticks(size=20)\n\nq27 = {'1': [data['Q27_A_Part_1'].any(), data['Q27_A_Part_2'].any(), data['Q27_A_Part_3'].any(), data['Q27_A_Part_4'].any(),\n             data['Q27_A_Part_5'].any(), data['Q27_A_Part_6'].any(), data['Q27_A_Part_7'].any(), data['Q27_A_Part_8'].any(),\n             data['Q27_A_Part_9'].any(), data['Q27_A_Part_10'].any(), data['Q27_A_Part_11'].any(), data['Q27_A_OTHER'].any()],\n       '2': [data['Q27_A_Part_1'].value_counts().tolist()[0], data['Q27_A_Part_2'].value_counts().tolist()[0],\n             data['Q27_A_Part_3'].value_counts().tolist()[0], data['Q27_A_Part_4'].value_counts().tolist()[0],\n             data['Q27_A_Part_5'].value_counts().tolist()[0], data['Q27_A_Part_6'].value_counts().tolist()[0],\n             data['Q27_A_Part_7'].value_counts().tolist()[0], data['Q27_A_Part_8'].value_counts().tolist()[0],\n             data['Q27_A_Part_9'].value_counts().tolist()[0], data['Q27_A_Part_10'].value_counts().tolist()[0],\n             data['Q27_A_Part_11'].value_counts().tolist()[0], data['Q27_A_OTHER'].value_counts().tolist()[0]]}\n             \ncloudProducts = sns.barplot(y=q27['1'], x=q27['2'])\ncloudProducts.tick_params(labelsize=12)\ncloudProducts.tick_params(length=2, axis='y')\nplt.tight_layout()\nplt.title('Cloud Products of Kaggle Survey 2020', fontsize=20)\nplt.show()","851e6645":"plt.figure(figsize=(15, 5))\nplt.yticks(size=20)\n\nq28 = {'1': [data['Q28_A_Part_1'].any(), data['Q28_A_Part_2'].any(), data['Q28_A_Part_3'].any(), data['Q28_A_Part_4'].any(),\n             data['Q28_A_Part_5'].any(), data['Q28_A_Part_6'].any(), data['Q28_A_Part_7'].any(), data['Q28_A_Part_8'].any(),\n             data['Q28_A_Part_9'].any(), data['Q28_A_Part_10'].any(), data['Q28_A_OTHER'].any()],\n       '2': [data['Q28_A_Part_1'].value_counts().tolist()[0], data['Q28_A_Part_2'].value_counts().tolist()[0],\n             data['Q28_A_Part_3'].value_counts().tolist()[0], data['Q28_A_Part_4'].value_counts().tolist()[0],\n             data['Q28_A_Part_5'].value_counts().tolist()[0], data['Q28_A_Part_6'].value_counts().tolist()[0],\n             data['Q28_A_Part_7'].value_counts().tolist()[0], data['Q28_A_Part_8'].value_counts().tolist()[0],\n             data['Q28_A_Part_9'].value_counts().tolist()[0], data['Q28_A_Part_10'].value_counts().tolist()[0],\n             data['Q28_A_OTHER'].value_counts().tolist()[0]]}\n             \nMLProducts = sns.barplot(y=q28['1'], x=q28['2']) \nMLProducts.tick_params(labelsize=12)\nMLProducts.tick_params(length=2, axis='y')\nplt.tight_layout()\nplt.title('ML Products of Kaggle Survey 2020', fontsize=20)\nplt.show()","cf27e590":"plt.figure(figsize=(15, 5))\nplt.yticks(size=20)\n\nq29 = {'1': [data['Q29_A_Part_10'].any(), data['Q29_A_Part_11'].any(), data['Q29_A_Part_12'].any(), data['Q29_A_Part_13'].any(),\n         data['Q29_A_Part_14'].any(), data['Q29_A_Part_15'].any(), data['Q29_A_Part_16'].any()],\n       '2': [data['Q29_A_Part_10'].value_counts().tolist()[0], data['Q29_A_Part_11'].value_counts().tolist()[0],\n          data['Q29_A_Part_12'].value_counts().tolist()[0], data['Q29_A_Part_13'].value_counts().tolist()[0],\n          data['Q29_A_Part_14'].value_counts().tolist()[0], data['Q29_A_Part_15'].value_counts().tolist()[0],\n          data['Q29_A_Part_16'].value_counts().tolist()[0]]}\n\nbigDataProducts = sns.barplot(y=q29['1'], x=q29['2']) \nbigDataProducts.tick_params(labelsize=12)\nbigDataProducts.tick_params(length=2, axis='y')\nplt.tight_layout()\nplt.title('Big Data Products of Kaggle Survey 2020', fontsize=20)\nplt.show()","74d6259b":"q32 = data['Q32'].value_counts()\nfig = px.pie(names=q32.index, values=q32.values)\nfig.show()","1ecf5c5a":"**Question sixteen (\"Q16\")** about machine learning framework used by participant. Top four are Scikit-learn, TensorFlow, Keras, and PyTorch. TensorFlow and Keras has integrated to be TensorFlow only (https:\/\/twitter.com\/fchollet\/status\/820746845068505088). \n\nI look at the growth in use of PyTorch and TensorFlow libraries. We can see that PyTorch is growing faster than TensorFlow, but TensorFlow are first machine learning framework most used.\nIn 2020, in Jetbrains Blog, TensorFlow used 420K people and PyTorch 253K people. You can see on https:\/\/blog.jetbrains.com\/datalore\/2020\/12\/17\/we-downloaded-10-000-000-jupyter-notebooks-from-github-this-is-what-we-learned\/ .\n","c546e83b":"Thank you for reading this notebooks. I done specify sources with drop link. Once again, thank you :)","931bee29":"**Question eighteen (\"Q18\")** about computer vision methods used by participant. Image classification are computer vision methods that most used. Image classification is a process that classifies object(s), pattern(s), or concept(s) in an image (https:\/\/developers.google.com\/machine-learning\/glossary#image-recognition). ","ee12b126":"**Question two (\"Q2\")** about gender participant. 78.8% of the total participants are man. While 21.2% are woman and other. \n\nNow, machine learning and data science world has community that focused for woman and other\/underrepresented groups (African Americans\/Black, Hispanic\/Latin, Asian, Disability, LGBTQ+ and many more)(https:\/\/blog.ongig.com\/diversity-and-inclusion\/minority-groups-in-america\/)","64e59fe6":"**Question evelen (\"Q11\")** about computing platform used by participant. Majority still many use personal computer or laptop. Followed, cloud provider like AWS, Azure, GCP, hosted notebooks (Kaggle Notebooks, Colab Notebooks and many more (you can see on question 10)). ","ea967783":"Hello all, I am Budi. I write notebook about 2020 Kaggle Survey. From many questions are available, I choose 17 questions that related with machine learning, data science and cloud computing.\n\nMachine learning is a sub-field of artificial intelligence. However, in recent years, some organizations have begun using the terms artificial intelligence and machine learning interchangeably (https:\/\/developers.google.com\/machine-learning\/glossary#artificial-intelligence). \n\nData science (data scientist) is the sexiest job of the 21st century (https:\/\/hbr.org\/2012\/10\/data-scientist-the-sexiest-job-of-the-21st-century). \n\nCloud computing is the on-demand skill with pay cloud services that you use (not need data center or server), connected with internet or need internet to use\/access cloud services (AWS, GCP and Azure website source). \n\nMachine learning, data science and cloud computing is each related. Amazon Sagemaker (AWS), AI Platform (GCP) and Azure ML Studio (Azure) is a machine learning product on the cloud services. \n\nAmazon Redshift (AWS), Amazon Athena (AWS), Google BigQuery (GCP), Cloud SQL (GCP), and Azure Data Lake (Azure) is a  data science (and data analytics) product on the cloud services. \n\n**If you interested with this notebook, read the results in this notebooks about 18 questions in Kaggle Survey 2020.**","7181bfa4":"**Question nineteen (\"Q19\")** about NLP methods used by participant. Word embedding are NLP methods that most used.","b48fe5c7":"**Question seventeen (\"Q17\")** about machine learning algorithm used by participant. Top three are linear regression, decision tree or random forest, and convolutional neural network (CNN). ","e8a3d5e2":"**Question twenty eight (\"Q28\")** about machine learning products. This question has three cloud computing platform (AWS, GCP and Azure) answer. Still many people not use machine learning products on cloud. No\/None are ranking 1 for this question. While machine learning products by GCP are Google Cloud AI Platform is ranking 2, followed by AWS are Amazon Sagemaker is ranking 3, by Azure are Azure ML Studio is ranking 4.","5311e140":"**Question thirteen (\"Q13\")** about TPU hours used by participant. Majority of people still not use TPUs. You can see question twelve (Q12) explained people that use TPUs rarely used.","de8c2afc":"**Question fourteen (\"Q14\")** about data visualization library used by participant. Top three are matplotlib, seaborn and Plotly. I use seaborn and Plotly in this notebooks. ","0e06af50":"**Question thirty (\"Q30\")** about business intelligence products. Tableau is business intelligence products that most used with 36% total participant of 2020 Kaggle Survey. Tableau has several products like Tableau Desktop, Tableau Server, Tableau Online and many more. Followed, Power BI by Microsoft are ranking two, Google Data Studio are ranking three. \n\nTableau and Power BI has integrations services with Google BigQuery, Amazon Redshift and many more. Google Data Studio running in the browser, can integrated with Google BigQuery and many more. Amazon Quicksight has 2.4% total participant, is are cloud business intelligence products by AWS. While, Looker are acquisition by Google and Looker available on Google Cloud Platform (GCP).","609f79a0":"**Question ten (\"Q10\")** about notebooks used by participant. In this question, I create treemap visualization because many notebooks product like Colab Notebooks, Kaggle Notebooks and many more. Btw, I use Colab and Kaggle Notebooks because it's free with GPU limited hours. \n\nKaggle Notebooks, a cloud computational environment that enables reproducible and collaborative analysis (https:\/\/www.kaggle.com\/docs\/notebooks). While Colaboratory execute code on Google's cloud servers, including GPUs and TPUs and need is a browser (https:\/\/colab.research.google.com\/notebooks\/intro.ipynb#scrollTo=OwuxHmxllTwN).\n\nNotebooks hosted on cloud services like Amazon Sagemaker, Google Cloud Datalab, Google Cloud AI Platform and Azure Notebooks has pricing model with other cloud services.\nIt is proven that there are still many people who do not use notebooks (None) as many as 25% of the more than 20,000 participants.","24da6929":"In this survey, 2020 Kaggle Survey have more than 20000 participant. I use Seaborn and Plotly library for analysis 18 questions in this notebook. \n\n**Question one (\"Q1\")** about age participant. 25-29 years old are the largest number of age participant. Followed, 22-24 years old, 18-21 years old. In means, total participant from top three age (18-21, 22-24 and 25-29 or 18-29) more than 50%. After 18-29 years of age or over 29 years of age, there are fewer participants.","f0acbc7c":"**Question three (\"Q3\")** about country participant. In this question, I choose top 9 country excluded \"Other\". India is the country that has participated the most in the 2020 Kaggle Survey. \n\nFollowed, United States, then Brazil, Japan, Russia, United Kingdom, Nigeria, China and Germany. Machine learning and data science resources are mostly written in English. \n\nIndia, United States and United Kingdom are country is communicate in English (https:\/\/www.lingoda.com\/en\/content\/english-speaking-countries\/). India total participant are two times United States total participant in this question.","7303fd65":"**Question twenty six (\"Q26\")** about cloud computing platform. In this question, AWS and GCP are top two cloud computing platform. While in Flexera blog, AWS are cloud computing platform that most used, followed Azure and GCP (https:\/\/www.flexera.com\/blog\/industry-trends\/trend-of-cloud-computing-2020\/). Various survey also explain top three cloud computing always are AWS, GCP and Azure. AWS, GCP and Azure have several services in common like compute, networking, storage, database and many more. ","2c62ea91":"**Question twenty seven (\"Q27\")** about cloud computing products. This question has three cloud computing platform (AWS, GCP and Azure) answer. If seen total participant use cloud computing products, AWS are first answer for this question followed GCP and Azure. \n\nAWS services that most use are Amazon EC2, then AWS Lambda and Amazon Elastic Container Service. Then, still many people not use cloud computing platform (No\/None). No\/None are ranking two after Amazon EC2.","ae74e4f3":"**Question twelve (\"Q12\")** about hardware used by participant. Majority of people still use GPUs and don't use hardware. TPU is still rarely used.","87a117b3":"**Question twenty nine (\"Q29\")** about big data products. In this question, I filtered several answers into cloud big data products only. As a result, BigQuery are first answer most used to big data products. Other cloud big data services have a nearly equal number of participants. "}}