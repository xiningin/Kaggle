{"cell_type":{"a10b1399":"code","231e14c2":"code","ac4e91d9":"code","283fad73":"code","639ebb14":"code","3aebf2c0":"code","c0c26de7":"code","f571dc3b":"code","2e520b14":"code","c905117d":"code","6954e5c1":"code","5bd6ca48":"code","7f243056":"code","7d46e76c":"code","74a0ad28":"code","cc0844e1":"code","17bfa96d":"code","7acacecd":"code","dc9927c7":"code","7ed4dd0e":"code","c3241040":"code","b9ebf483":"code","53dbda06":"code","3764d5c1":"code","411d82d2":"code","a9ba977b":"code","7fb46a8f":"code","d63e08a5":"code","d8a1dd70":"code","a8b475d8":"code","d7346eef":"code","e93f0bd6":"code","41e408bb":"code","da50d07e":"code","190f303f":"code","2806c9f4":"code","328961f4":"code","85ab7281":"code","e6ff93bd":"code","9905dd40":"code","66b4c118":"code","1837f2ef":"code","c6435014":"code","4c17a6e1":"code","ccea7560":"code","22fbdf53":"code","e650894b":"code","3d0f23ca":"markdown","7e9673d5":"markdown","640637f3":"markdown","8e81eeff":"markdown","37bd0dbf":"markdown","d6768d5e":"markdown","3fe0c98c":"markdown","566c4611":"markdown","e4e16192":"markdown","6a0a6d3b":"markdown","b0e17e26":"markdown","91ba7307":"markdown","b12c553a":"markdown","9ebb819b":"markdown","1ab8129e":"markdown","820c573b":"markdown","244bf10a":"markdown","34ad6063":"markdown","a9e4d629":"markdown","4f779431":"markdown","a8d12a46":"markdown","3e74889e":"markdown","bdd7788e":"markdown","e551be05":"markdown","4198c46b":"markdown","6f98b2af":"markdown","fda67f73":"markdown"},"source":{"a10b1399":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.utils import resample\nimport scipy\nfrom scipy.stats import chisquare\nfrom scipy import stats\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score,roc_auc_score\nimport warnings\nwarnings.filterwarnings(action='ignore')\npd.set_option('display.max_columns',300)","231e14c2":"train = pd.read_csv('..\/input\/train.csv',index_col='ID')","ac4e91d9":"test = pd.read_csv('..\/input\/test.csv',index_col='ID')","283fad73":"train.head()","639ebb14":"test.head()","3aebf2c0":"train.shape, test.shape","c0c26de7":"test['TARGET']=0","f571dc3b":"test.shape","2e520b14":"df = train.append(test)","c905117d":"df.shape","6954e5c1":"constant_cols=df.nunique()[df.nunique()==1].index","5bd6ca48":"df.drop(constant_cols,axis=1,inplace=True)","7f243056":"df.shape","7d46e76c":"def getDuplicateColumns(df):\n    '''\n    Get a list of duplicate columns.\n    It will iterate over all the columns in dataframe and find the columns whose contents are duplicate.\n    :param df: Dataframe object\n    :return: List of columns whose contents are duplicates.\n    '''\n    duplicateColumnNames = set()\n    # Iterate over all the columns in dataframe\n    for x in range(df.shape[1]):\n        # Select column at xth index.\n        col = df.iloc[:, x]\n        # Iterate over all the columns in DataFrame from (x+1)th index till end\n        for y in range(x + 1, df.shape[1]):\n            # Select column at yth index.\n            otherCol = df.iloc[:, y]\n            # Check if two columns at x and y index are equal\n            if col.equals(otherCol):\n                duplicateColumnNames.add(df.columns.values[y])\n \n    return list(duplicateColumnNames)","74a0ad28":"duplicated_cols = getDuplicateColumns(df)","cc0844e1":"df.drop(duplicated_cols,axis=1,inplace=True)","17bfa96d":"df.shape","7acacecd":"df_target = pd.DataFrame(train.TARGET.value_counts())\ndf_target['Percentage'] = 100*df_target['TARGET']\/train.shape[0]\ndf_target","dc9927c7":"fig, ax=plt.subplots(figsize=(8,6))\nsns.countplot('TARGET',data=train);","7ed4dd0e":"cor_mat = train.corr()\nfor i in range(5):\n    for j in range(5):\n        x = i*50\n        y = j*50\n        corr = cor_mat.iloc[range(x,x+50),range(y,y+50)]\n        # Set up the matplotlib figure\n        f, ax = plt.subplots(figsize=(15, 12))\n        # Draw the heatmap with the mask and correct aspect ratio\n        sns.heatmap(corr,linewidths=.5, ax=ax)","c3241040":"X = train.iloc[:,:-1]\ny = train.TARGET\n\nrf = RandomForestClassifier(n_estimators=100)\nrf.fit(X, y)\n\nfeat_imp = pd.Series(rf.feature_importances_, index=X.columns)\nfeat_imp.sort_values(inplace=True)\nax = feat_imp.tail(20).plot(kind='barh', figsize=(10,7), title='Feature importance')","b9ebf483":"fig, axs = plt.subplots(nrows= 3, ncols=3, figsize=(18, 25))\n\naxs[0, 0].boxplot(train['var38'])\naxs[0, 0].set_title('var38')\n\naxs[0, 1].boxplot(train['var15'])\naxs[0, 1].set_title('var15')\n\naxs[0, 2].boxplot(train['saldo_medio_var5_ult3'])\naxs[0, 2].set_title('saldo_medio_var5_ult3')\n\naxs[1, 0].boxplot(train['saldo_medio_var5_hace3'])\naxs[1, 0].set_title('saldo_medio_var5_hace3')\n\naxs[1, 1].boxplot(train['num_var45_ult3'])\naxs[1, 1].set_title('num_var45_ult3')\n\naxs[1, 2].boxplot(train['num_var45_hace3'])\naxs[1, 2].set_title('num_var45_hace3')\n\naxs[2, 0].boxplot(train['saldo_var30'])\naxs[2, 0].set_title('saldo_var30')\n\naxs[2, 1].boxplot(train['saldo_var42'])\naxs[2, 1].set_title('saldo_var42')\n\naxs[2, 2].boxplot(train['saldo_medio_var5_hace2'])\naxs[2, 2].set_title('saldo_medio_var5_hace2')","53dbda06":"fig, ax=plt.subplots(figsize=(8,6))\nsns.countplot('TARGET',data=df);","3764d5c1":"train_index_start= train.shape[0] # catching row until test data\nprint(train_index_start)\ntarget_index_start= train.shape[1] # catching column until target colum\nprint(target_index_start)","411d82d2":"train = df.iloc[:train_index_start,:]\ntest  = df.iloc[train_index_start:,:] ","a9ba977b":"#!pip install imblearn\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nrus = RandomUnderSampler(random_state=0)\nX_train = train.drop('TARGET',axis =1)\ny_train = train['TARGET']\nX_resampled, y_resampled = rus.fit_resample(X_train, y_train) ","7fb46a8f":"fig, ax=plt.subplots(figsize=(8,6))\nsns.countplot(y_resampled);","d63e08a5":"ros = RandomOverSampler(random_state = 0)\nX_rosampled, y_rosampled = ros.fit_resample(X_train,y_train) ","d8a1dd70":"fig, ax = plt.subplots(figsize=(8,6))\nsns.countplot(y_rosampled);","a8b475d8":"X_train, X_test, y_train, y_test = train_test_split(X_resampled,y_resampled , test_size=0.33, random_state=42)\nprint(X_test.shape, y_test.shape)\nprint(X_train.shape, y_train.shape)","d7346eef":"clf = ExtraTreesClassifier(random_state=42)","e93f0bd6":"selector = clf.fit(X_train, y_train)\ntest['TARGET'] = 0\ntest.shape","41e408bb":"feats_sel = SelectFromModel(selector, prefit=True)\nX_train = feats_sel.transform(X_train)\nX_test = feats_sel.transform(X_test)\ntest = feats_sel.transform(test.drop(\"TARGET\", axis = 1))","da50d07e":"X_train.shape, X_test.shape","190f303f":"clf_xgb = GridSearchCV(\n    estimator=xgb.XGBClassifier(seed=42),\n    param_grid={\n        \"learning_rate\": [0.1,0.01],\n        \"min_child_weight\": [1,2,4],\n        \"max_depth\": [4,6,8],\n        \"subsample\": [0.75],\n        \"colsample_bytree\":[0.75,0.8],\n        \"n_estimators\": [100,200,300],\n        \"max_features\": [3,4,6],\n    },\n    cv=3,\n    scoring=\"roc_auc\",\n    verbose=1,\n    n_jobs=-1,\n)\nclf_grid_result=clf_xgb.fit(X_train,y_train)","2806c9f4":"clf_grid_result.best_estimator_","328961f4":"clf_grid_result.best_score_","85ab7281":"y_pred = clf_grid_result.predict(X_test)","e6ff93bd":"fig, ax = plt.subplots(figsize=(8,6))\nsns.countplot(y_pred);","9905dd40":"clf_grid_result.scorer_","66b4c118":"random_seed = 42\n\nRF_parameters = {'n_estimators': [120, 240, 480],\n                 'bootstrap': [True],\n                 'max_depth': [16, 32, 80 ,120],\n                 'max_features': [, 'sqrt', 'log2'],\n                 'min_samples_leaf': [2, 6, 8, 16, 24, 36, 48],\n                 'min_samples_split': [8 ,10, 15, 24, 36, 48],\n                 'random_state':[random_seed],\n                 \"n_jobs\": [-1],\n                 'criterion':['gini', 'entropy']}\n\nclf_rf = GridSearchCV(\n    estimator=RandomForestClassifier(),\n    param_grid = RF_parameters,\n    cv=3,\n    scoring=\"roc_auc\",\n    verbose=1,\n    n_jobs=-1,\n)\nclf_grid_result_rf=clf_rf.fit(X_train,y_train)","1837f2ef":"clf_grid_result_rf.best_estimator_","c6435014":"clf_grid_result_rf.best_score_","4c17a6e1":"y_pred = clf_grid_result_rf.predict(X_test)","ccea7560":"fig, ax = plt.subplots(figsize=(8,6))\nsns.countplot(y_pred);","22fbdf53":"probabilities = clf_grid_result.predict_proba(test)\n\nsubmission = pd.DataFrame({\"ID\":df.iloc[train_index_start:,0].index, \"TARGET\": probabilities[:,1]})\nsubmission.to_csv(\"submission_xgb.csv\", index=False)","e650894b":"probabilities = clf_grid_result_rf.predict_proba(test)\n\nsubmission = pd.DataFrame({\"ID\":df.iloc[train_index_start:,0].index, \"TARGET\": probabilities[:,1]})\nsubmission.to_csv(\"submission_rf.csv\", index=False)","3d0f23ca":"#### Finding Duplicated columns ","7e9673d5":"# EDA\n## Imbalance Data","640637f3":"## Variable Correlation","8e81eeff":"pca = PCA()\nprincipalComponents = pca.fit_transform(\n    df.drop( \"TARGET\", axis=1)\n)\nvariance = pca.explained_variance_ratio_  \nvar_rat = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=2) * 100)","37bd0dbf":"## Outliers Detection for Top Important Variables","d6768d5e":"## Random Forest ","3fe0c98c":"### Inspection of Class Balance","566c4611":"pca_df['ID'] = df.index\npca_df.set_index('ID',inplace = True)\npca_df['TARGET'] = df['TARGET']","e4e16192":"# Task \nSantander aims to identify dissatisfied clients as soon as possible so that the bank can come up with proactive measures to make clients satisfied during the business relationship. Dissatisfied clients include clients who do not express their dissatisfaction with the bank\u2019s service.\n\nThe task of the challenge is to identify whether a client is satisfied or not with Santander\u2019s products and\/or services given hundreds of anonymized features. This will be done by predicting the probability that a customer is satisfied or not. \n\nThe dataset contains a huge number of numeric variable. The \u201cTARGET\u201d column is the variable to predict with 1 as unsatisfied customers while 0 is for satisfied customers. ","6a0a6d3b":"### Undersampling","b0e17e26":"### Automatic feature selection","91ba7307":"## Feature Importance","b12c553a":"plt.figure(figsize=(10, 6))\nplt.title(\"Cumulative explained variance with PCA\", fontsize=24)\nplt.xlabel(\"# Features\", fontsize=18)\nplt.ylabel(\"Cumulative explained variance\", fontsize=18)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.plot(var_rat);","9ebb819b":"## Dimensionality reduction with PCA\nChecked but got lower scores in Kaggle probably I guess because of lots of binary features","1ab8129e":"### Oversampling ","820c573b":"## Modeling","244bf10a":"### RF","34ad6063":"pca_df = pd.DataFrame(\n    data=principalComponents[:, :8], columns=[\"PC{}\".format(i) for i in range(1, 9)]\n)\n\npcas = pca_df.shape[1]-1 # selected","a9e4d629":"#### PCA ","4f779431":"#### Undersampled\nContinued with Undersampling as we achieved highest performance with it","a8d12a46":"### Combining train and test dataset","3e74889e":"var_rat[:8]","bdd7788e":"X_train=pca_df.iloc[:train_index_start, :pcas]\nX_test =pca_df.iloc[train_index_start:, :pcas]\ny_train=pca_df.iloc[:train_index_start, pcas]\ny_test =pca_df.iloc[train_index_start:, pcas]","e551be05":"# Prediction\nFinal score is with XGBoost 0.8368 and with RF 0.83610.\n### XGBoost","4198c46b":"# Santander Customer Satisfaction","6f98b2af":"#### Removing constant columns","fda67f73":"pca_df.head()"}}