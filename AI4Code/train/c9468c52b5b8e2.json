{"cell_type":{"79202722":"code","c636e98c":"code","90831d33":"code","dee982a2":"code","3ae680ca":"code","1fe1235c":"code","8a8150ad":"code","1407ad81":"code","4ad9cd9d":"code","d8686079":"code","05c9f122":"markdown","18d83e92":"markdown"},"source":{"79202722":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","c636e98c":"train_df = pd.read_csv(\"..\/input\/train.csv\").drop('id', axis=1)\ntrain_df.head()","90831d33":"test_df = pd.read_csv('..\/input\/test.csv').drop('id', axis = 1)\ntest_df.head()","dee982a2":"plt.bar(range(2), (train_df.shape[0], test_df.shape[0])) \nplt.xticks(range(2), ('Train', 'Test'))\nplt.ylabel('Count') \nplt.show()","3ae680ca":"y = train_df['target']\nX = train_df.drop('target', axis=1)","1fe1235c":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","8a8150ad":"best_score = 0\nfor penalty in ['l1', 'l2']:\n    for C in [0.001, 0.01, 0.1, 1, 10, 100]:       \n        logreg = LogisticRegression(class_weight='balanced',  penalty=penalty, C=C, solver='liblinear')\n        logreg.fit(X_train, y_train)\n        score = logreg.score(X_test, y_test)\n        if score > best_score:\n            best_score = score\n            best_parameters = {'C': C, 'penalty': penalty}            ","1407ad81":"logreg = LogisticRegression(**best_parameters)\nlogreg.fit(X_train, y_train)\ntest_score = logreg.score(X_test, y_test)","4ad9cd9d":"print(\"Best score: {:.2f}\".format(best_score))\nprint(\"Best parameters: {}\".format(best_parameters))\nprint(\"Best score on test data: {:.2f}\".format(test_score))","d8686079":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['target'] = logreg.predict_proba(test_df)[:,1]\nsub.to_csv('submission.csv', index=False)","05c9f122":"### Code for beginners to easily start participating in this competition","18d83e92":"Let's visualize difference between train and test data"}}