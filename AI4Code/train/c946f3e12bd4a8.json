{"cell_type":{"872a5476":"code","c771782b":"code","6fefa48e":"code","61d55ca7":"markdown","df6e8170":"markdown","affe6915":"markdown","a35064ba":"markdown","9a5a8e03":"markdown","ca848482":"markdown","ce298b26":"markdown","6e530724":"markdown","5e3df59d":"markdown","3365001f":"markdown","35a3d763":"markdown","f346b257":"markdown","84306cb7":"markdown","81ca42ce":"markdown","46ef30a4":"markdown","fd7e8e85":"markdown","24be2cef":"markdown"},"source":{"872a5476":"# Import the dependencies\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"white\")\nprint(\"Import completed\")","c771782b":"# Quick approximation of some probability densities by drawing 500.000 samples\nsns.distplot(np.random.normal(4,1.5,500000),hist=False, label='first throws, $\\mu$=4, $\\sigma$=1.5');\nsns.distplot(np.random.normal(7,1,500000),hist=False, label='getting better, $\\mu$=7, $\\sigma$=1');\nsns.distplot(np.random.normal(10,0.5,500000),hist=False, label='getting good, $\\mu$=10, $\\sigma$=0.5');\nplt.legend();","6fefa48e":"#Input parameters\nperc1dice=0.40\n\n#Calculate dice throws\nN=5000 # amount of dice throws\nN1=int(N*perc1dice) # amount of times six sided dice is thrown\nN2=int(N*(1-perc1dice))  # amount of times 2 six sided dice is thrown\nrandom_seed=1234567\nnp.random.seed(random_seed)\n\n#Build result table with some simple headers \nresults=np.zeros((3,14), dtype=int) # table where results are stored\nfor count in range(1, 13):\n    results[0,count]=count\nresults[1,0]=1\nresults[2,0]=2\nresults[1,13]=N1\nresults[2,13]=N2\n\n# Throw N times six sided dice\nfor count in range(0, N1):\n    throw=np.random.randint(1,7)\n    results[1,throw] += 1\n\n# Throw M times 2 six sided dice\nfor count in range(0, N2):\n    throw=np.random.randint(1,7)+np.random.randint(1,7)\n    results[2,throw] += 1\n\n# Print the results\nprint(results)\nprint()\n#Calculate P(x=2) given p(y=observation)\nfor observation in range(1,13):\n    nominator=(results[2,observation]\/N2)*(N2\/N)\n    denominator=(results[1,observation]\/N1)*(N1\/N)+(results[2,observation]\/N2)*(N2\/N)\n    print('Probability of 2 dice given observation ', observation, ' is ' , int(100*nominator\/denominator),'%')\n\n# Plot the probability distributions:\nfig, axes = plt.subplots(2,2)\nplt.subplots_adjust(wspace=0.35, hspace=0.35)\nfig.suptitle('Probability distributions')\nsns.barplot(results[0, 2:13], results[2,2:13]\/N2, color='blue' , ax=axes[0,0])\naxes[0,0].set_ylabel('Prob')\naxes[0,0].grid(1)\naxes[0,0].set_title('$p(Observation \\mid dice=2)$')\nsns.barplot(results[0, 1:7], results[1,1:7]\/N1, color='blue' , ax=axes[0,1])\naxes[0,1].set_ylabel('Prob')\naxes[0,1].grid(1)\naxes[0,1].set_title('$p(Observation \\mid dice=1)$')\nsns.barplot(results[0, 1:3], [N1\/N,N2\/N], color='blue' , ax=axes[1,0])\naxes[1,0].set_ylabel('Prob')\naxes[1,0].grid(1)\naxes[1,0].set_title('$p(dice)$')\nsns.barplot(results[0, 1:13], (results[1, 1:13]+results[2, 1:13])\/N, color='blue' , ax=axes[1,1])\naxes[1,1].set_ylabel('Prob')\naxes[1,1].grid(1)\naxes[1,1].set_title('$p(Observation)$');\n\n","61d55ca7":"<a id='secC'><\/a>\n# Conventions and Symbols\n\nUnfortunately have observed various types of symbols over various documents, not making it easier to read or understand. Below the symbols used in this notebook  \n\nSymbol | Description | Alternative |\n--- | --- | --- |\nx  | external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}\\in\\mathbb{R}^n$ with n number of states. | |\ny | sensory observations, the data from the available sensory set (effect of the environment on the \u00a8system\u00a8). Shorthand notation for the vector $\\vec{y}_{observation} \\in  \\mathbb{R}^{q}$ with q number of sensors.  | also sometimes noted \u00a8s\u00a8 as of sensory states |\nu | actions, control signal, The action that can be performed on the environment. (effect of the \u00a8system\u00a8 on the environment) Shorthand notation for the vector $\\vec{u} \\in  \\mathbb{R}^{l}$ with l number of controls.  | also noted as \u00a8a\u00a8 or \u00a8$\\alpha $\u00a8 |\n$\\mathcal{F}(y,\\zeta)$ or $\\mathcal{F}(y_{observation},\\zeta)$ | The Free Energy | simplifies under lapace transformation to $\\mathcal{F}(y,\\mu)$\n$q(x; \\zeta )$ or $q(x_{hypotheses}; \\zeta )$    | recognition probability density with sufficient statistics $\\zeta$, the brain to approximate posterior  $p(x_{hypotheses}\\mid  y_{observation})$ probability density. Expectation of the states x given observations y  | Ensemble density; simplifies under lapace transformation to $q(x; \\mu )$ |\n$p(x,y)$ or $p(x_{hypotheses},y_{observation})$ | Generative probability density: the brain encoding a probabilistic model of the environment\/world in which it is immersed. |  |\n$\\zeta$ | sufficient statistics (e.g. for a Gaussian distribution: mean \ud835\udf07, variance $\ud835\udf0e^2$) for the recognition probability density | $\\mu$ (because under laplace approximation sufficient statistics simplifies to mean $\\mu$, see next notebook), in few papers noted as $\\lambda$ (but in other papers $\\lambda$ sometimes also used for precision of random noise) |\n\n\n","df6e8170":"<a id='sec33'><\/a>\n## Why the brain is doing it - Minimize Surprise\n\nThe why question goes all the way back to the very primal basis of existence.  \n\nI started the notebook with a quote from Friston \u00a8The free-energy principle is an attempt to explain the structure and function of the brain, starting from the very fact that we exist\u00a8. What does it take to exist? If you would ask me you get an answer in terms of the [Maslows' pyramid](https:\/\/en.wikipedia.org\/wiki\/Maslow%27s_hierarchy_of_needs). If you could ask an animal like my cat, it could be something in terms of \u00a8Food and territory\u00a8. But what if you go to even more primitive lifeforms like Friston describes in [the history of the future of the Bayesian brain](https:\/\/www.researchgate.net\/publication\/51739007_The_history_of_the_future_of_the_Bayesian_brain)? \u00a8I overturned an old log and found myself absorbed in the antics of some woodlice (miniature armadillo-like bugs) that were fleeing for cover of darkness.\u00a8 Start looking and you see it for yourself. I observed diving in the great barrier reef a [Christmas tree worm](https:\/\/www.barrierreef.org\/the-reef\/the-facts\/creature-features\/christmas-tree-worms) retracting in the coral by waving over it. These lifeforms are not as \u00a8intelligent\u00a8 as more evolved mammal species but still have these behaviors entailed for something. I'll bet you the Christmas tree didn't want to be eaten by a big fish. Might the basic answer to the question \u00a8What does it take to exist?\u00a8 be: \u00a8to survive, don't die\u00a8? \n\nTo exist biological lifeforms must preserve their physical integrity (eg body temperature around 37 degrees) to survive. Their internal states x can only fluctuate within a certain \u00a8safe\u00a8 range that allows existence. It needs to avoid states that are \u00a8not safe\u00a8, and since these states are avoided these are surprising states in terms of information theory. Surprise in [information theory](https:\/\/en.wikipedia.org\/wiki\/Information_theory) is $ ln(\\frac{1}{p(x))}) = -ln(p(x))$ (negative log probability) That is: high probability is a low surprise and vise versa. \n*  Here\u2019s an [article](https:\/\/plus.maths.org\/content\/information-surprise) that explains surprise in terms of information theory nicely.\n* Note that it is the surprise in terms of information theory: atypical events, the unlikeliness of the occurrence of an event. E.g. If you got a surprise cake with your birthday but you get it every year it is still a nice surprise but not a surprise in information theory since you get it every year. \n\nWhy do the internal states fluctuate? Because of external influences (eg your body temperature will for sure be affected in the desert). So to make sure internal states are not in surprising ranges, better make sure the external environment stays within a certain \u00a8un-surprising\u00a8 range, avoiding surprise in external states (maintain equilibrium with their environment). So, better seek out an environment that does not surprise you, where you experienced you can survive and not fighting for your life. To go back to the example of Friston on the woodlice observation \u00a8they were not purposefully (mindfully) seeking darkness, they were simply moving faster (in any random direction) when warmed by the sun.\u00a8 If your environment to survive is in cooler places, better move if you are in warm daylight.\n\nIn short, the free-energy principle is inspired by a primary imperative of the living organisms to resist disorder in order to survive, by minimizing the surprise associated with the occurrence of atypical events in their sensory observations. The argumentation underpinned in math: \n* Free energy $\\geq $ surprise, by minimizing the free energy the surprise in the sensory states $-ln(p(y))$ is minimized (the latter a living organism cannot directly evaluate since this would require to average over all possible occurrences of the observations y in all possible situations, the same [problem](#sec3) as in Bayes' theorem to calculate the denominator $p(y_{observation})$). The term $-ln(p(y))$ you might recognize in the Free Energy equation as \u00a8surprise\u00a8. Placed for reference  a graph of the natural logarithm for inspection below. Since $0\\leq  p(y)\\leq  1$ because it is a probability density:  $-ln(p(y))$ is a positive number with a minimum of 0. Which in the Free Energy principle we try to minimize to avoid surprising states.  \n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/e\/ea\/Log.svg\/450px-Log.svg.png\" width=400>\n<center>Graph of the natural logarithm function from <a href=\"https:\/\/en.wikipedia.org\/wiki\/Natural_logarithm\">wikipedia<\/a> <\/center>\n* By minimizing surprise in observation states all times the long-term average of surprise (is the [entropy](https:\/\/en.wikipedia.org\/wiki\/Entropy_(information_theory), the degree of disorder or randomness) of the external states is minimized. \n$$H(p(y))= -\\int_{-\\infty}^{\\infty}p(y)ln(p(y))dx$$\n* By minimizing the entropy in sensory states the entropy in internal states $-ln(p(x))$is minimized, to preserve internal integrity and thus continued existence. \n$$H(p(y)) \\geq H(p(x)))$$\n\n","affe6915":"<a id='sec2'><\/a>\n# Bayesian Inference\n\nHow does the brain infer the hidden states and thus infer the real world through the veil of sensory input? Bayesian inference to the rescue: the brain is making Bayesian inferences about the world using [Bayes' theorem](https:\/\/en.wikipedia.org\/wiki\/Bayes%27_theorem) to update the probability for a hypothesis x as more evidence or sensory observations y become available. Updating beliefs about the world based on evidence that we observe. The free energy principle subsumes the Bayesian brain hypothesis. Probabilities play an important role.\n\nAlso, the brain needs to cope with uncertainties in the real world. You need to function with uncertainties and random fluctuations every day: e.g. the wind affecting the ball your child is throwing, Will my child throw the ball more to the left or the right? Can I cross the road before the upcoming car? Will I catch the train if I start running? Etc, etc. Probabilities play an important role.  \nIn the Free Energy Principle beliefs\/hypotheses about the world are typically represented as probability densities.\n\n<a id='sec21'><\/a>\n## Probability density\n\nFor the brain to cope with uncertainty, it is not enough to work with just a single point estimate for x. The brain has to encode all possible values of x and how likely they are. In probability theory this is recorded with a probability distribution: A probability distribution $p(x)$ is a list of outcomes and their associated probabilities of $x$. \n\nHere\u2019s an [article](https:\/\/towardsdatascience.com\/probability-concepts-explained-probability-distributions-introduction-part-3-4a5db81858dc) that explains probability distributions nicely if needed. \n\n[Probability distributions](https:\/\/en.wikipedia.org\/wiki\/Probability_distribution) are generally divided into two classes:\n* Probability Mass Function is used in the discrete domain (e.g. set of possible outcomes is discrete, such as a coin toss or a roll of dice). \n* Probability Density Function is used in the continuous domain (e.g. possible outcomes can take on values in a continuous range like real numbers). We will work with continuous variables as used in the Free Energy papers and use the terms \u00a8probability density\u00a8 or simply \u00a8density\u00a8.\n\nLet me explain it with an example. The distance $x$ your child throws is not the same every time. If you put all the distances thrown into a long list in ascending order you start to notice a pattern. Some distances are more probable\/common than others. If you make the list longer and longer and get the measurements more and more precise (continuous numbers) and convert this list into a graph with on the x-axis the distance thrown and the y-axis the probability then you get a probability density, noted as $p(x)$.   \nThese patterns you notice can have different shapes but the most common pattern is shaped like a bell curve (like in a clock tower) and it is called a Gaussian or [normal probability density](https:\/\/en.wikipedia.org\/wiki\/Normal_distribution). Why normal? Well, because it is the most common probability density observed in daily life, hence the name normal. For example: average height of a species of trees, the economic income of people in a population, average grades of students, etc, etc.    \nThe Free Energy Principle \/ active inference assumes Gaussian probability densities (assumption is called the Laplace approximation, and guess what, the Laplace\u2013Gauss is another name for the normal distribution). It makes the math much simpler.\n\n<img src=\"https:\/\/www.syncfusion.com\/books\/Statistics_Using_Excel_Succinctly\/Images\/normal-curve.png\" width=200>\n\nThe normal probability density (1-dimensional) can be mathematically efficiently described with just 2 parameters using the equation below:\n\n$$\\mathcal{N}( \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2} } e^{ -\\frac{(x-\\mu)^2}{2\\sigma^2} }$$\n\n* Mean $\\mu$ - the average value of all points, e.g. the average distance your child will throw the ball\n* Standard deviation $\\sigma$ - the spread of the points, how much the points deviate from the mean, e.g. if your child just started with learning to throw the ball you probable have a high standard deviation and with more practice, the throws will be more consistent and hence a lower standard deviation (and a longer distance hence a higher mean). The spread is also sometimes alternatively noted as:\n    * Variance - simply the squared standard deviation: $\\sigma^2$ \n    * Precision - inverse of the variance: $\\frac{1}{\\sigma^2}$. A higher precision equals lower variance (the higher the spike in the bell curve)  \n    \nSo instead of remembering all possible values for a variable, the brain only needs the $\\mu$ and $\\sigma$ to reason in probabilities about beliefs\/hypotheses about the world.  \nFor example, thanks to the distribution properties, 68% of the data lies within 1 $\\sigma$ from the mean, 95% within 2 $\\sigma$ from the mean and 99.7% within 3 $\\sigma$ from the mean. This allows to very quickly estimating chances, a feature which the brain might be doing to save time and effort: working out the perfect running path for a deer to get away from the lion would get it killed before it barely started the calculation.\n\nNote: mean $\\mu$ and control signal $u$ look alike but have vastly different meanings, don't mix them up.\n\nHope this short (over-simplified) recollection of probability theory was enough to remember your high school classes again. If you need some more knowledge about probability theory \/ statistics this [link](https:\/\/www.khanacademy.org\/math\/statistics-probability\/random-variables-stats-library) is a good place to start. \n","a35064ba":"<a id='sec34'><\/a>\n## Minimize free energy by improving perception\nHow can biological lifeforms minimize the free energy and thus minimize surprisal in the sensory observations in order to prolong existence?\nLet's go back to the free energy equation:\n\n![](https:\/\/i.imgur.com\/WdSWu79.jpg)\n\n\nKeeping y fixed, we see that the **perceptual inference part** (Variational Bayesian Inference) of free energy minimization is equal to $\\underset{\\zeta }{Argmin}\\:  D_{KL}(q(x_{hypotheses}; \\zeta )\\parallel p(x_{hypotheses}\\mid  y_{observation}))$ which is the brain minimizing the Free Energy by optimizing $\\zeta$ so that $q(x_{hypotheses}; \\zeta )$ better approximates $p(x_{hypotheses}\\mid  y_{observation})$, or in other words: the brain can model the environment better, improving perception.  \n\nThe equation to find $\\zeta$ with the lowest Free Energy (also sometimes noted as $\\zeta^*$) that has to be solved is:\n$$\\zeta = \\underset{\\zeta }{Argmin}\\:  \\mathcal{F}(y_{observation},\\zeta)$$\n\n","9a5a8e03":"<a id='sec31'><\/a>\n## What the brain is doing - Prediction error minimization\n  \n**In essence the brain is a prediction mechanism**, one that attempts to minimize the error of its hypothesis about the sensory input it receives from the world\n* The skull-bound brain needs to infer the world. \n* The brain builds an internal model of the world using Bayesian inference. \n* Discrepancies between the internal model (the prediction) and the sensory observations result in prediction error. \n* The brain aims to minimize the prediction error \n    * by either improving the internal model to better match the sensory input \n    * or to act upon the environment \n\n**The brain builds an internal model of the world, the world has structure and therefore the brain can predict.**  \n\nWhile you are reading this your brain is probably predicting that you will read some more (assuming you like what you are reading). If a sudden fire appears close by with a big bang the reading prediction is wrong and an alternative hypothesis is generated (most probably \u00a8bomb\u00a8 and the action to run). With the capability to generate new hypotheses your brain also has the possibility of imagining different options and scenarios, even fantasies, it might even be the birthplace of conscience?\n\nJakob Hohwy explores the prediction error minimization theory from the perspective of cognitive science and philosophy in his book \u00a8[the predictive mind](https:\/\/www.amazon.com\/Predictive-Mind-Jakob-Hohwy\/dp\/0199686734)\u00a8. The theory claims to explain all cognitive abilities including conscience, feelings, etc.  I found it a very interesting and eye-opening book which I would like to recommend in case you are interested.\n\nBelow some of my notes on the book:\n\n![](https:\/\/i.imgur.com\/ip8bWkC.jpg)\n\nWith this little detour, I wanted to show the potential of the prediction error minimization theory. Now let's go back to the Free Energy Principle and how to apply prediction error minimization to approximate posterior $p(x_{hypotheses}\\mid  y_{observation})$ probability density with $q(x_{hypotheses}; \\zeta )$","ca848482":"<a id='sec32'><\/a>\n## How the brain is doing it - Free Energy bounds surprise\n\nThe [Kullback-Leibler divergence](https:\/\/en.wikipedia.org\/wiki\/Kullback%E2%80%93Leibler_divergence) measures the difference between probability densities. This [video](https:\/\/www.youtube.com\/watch?v=ErfnhcEV1O8) gives an introduction to KL-Divergence.\n\nFor the brain making an internal model of the world $q(x; \\zeta )$ to approximate posterior  $p(x_{hypotheses}\\mid  y_{observation})$ probability density it needs to minimize KL with respect to the sufficient statistics $\\zeta$ (e.g. for a Gaussian density: mean $\\mu$, variance $\\sigma^2$)\n\n$$\\underset{\\zeta }{Argmin}\\:  D_{KL}(q(x_{hypotheses}; \\zeta )\\parallel p(x_{hypotheses}\\mid  y_{observation}))$$\n\nBut we still have a problem because what we want to approximate $p(x_{hypotheses}\\mid  y_{observation})$ is unknown, let's have a closer look at the Kullback-Leiber definition:\n\n$$D_{KL}(q(x_{hypotheses}; \\zeta )\\parallel p(x_{hypotheses}\\mid  y_{observation})) = \\int q(x_{hypotheses}; \\zeta )ln(\\frac{q(x_{hypotheses}; \\zeta )}{p(x_{hypotheses}\\mid  y_{observation})})dx_{hypotheses}$$\n\nsince $p(x,y)=p(x \\mid y)p(y)$  \n$$=\\int q(x_{hypotheses}; \\zeta )ln(\\frac{p(y_{observation})q(x_{hypotheses}; \\zeta )}{p(x_{hypotheses},  y_{observation})})dx_{hypotheses}$$  \nsince ln(ab)=ln(a)+ln(b)  \n$$= \\int q(x_{hypotheses}; \\zeta )ln(\\frac{q(x_{hypotheses}; \\zeta )}{p(x_{hypotheses},  y_{observation})})dx_{hypotheses} + \\int q(x_{hypotheses}; \\zeta )ln(p(y_{observation}))dx_{hypotheses} $$\nSince there is no $x_{hypotheses}$ in $p(y_{observation})$  \n$$= \\int q(x_{hypotheses}; \\zeta )ln(\\frac{q(x_{hypotheses}; \\zeta )}{p(x_{hypotheses},  y_{observation})})dx_{hypotheses} + ln(p(y_{observation}))\\int q(x_{hypotheses}; \\zeta )dx_{hypotheses} $$\nsince the integral over a probability density function equals one \n$$= \\int q(x_{hypotheses}; \\zeta )ln(\\frac{q(x; \\zeta )}{p(x_{hypotheses},  y_{observation})})dx_{hypotheses} + ln(p(y_{observation}))$$  \n\n\nThe Free energy is defined as:\n\n$$\\mathcal{F}(y_{observation},\\zeta)= \\int q(x_{hypotheses}; \\zeta )ln(\\frac{q(x_{hypotheses}; \\zeta )}{p(x_{hypotheses},  y_{observation})})dx_{hypotheses} $$\n\nHence we have that\n$$\\mathcal{F}(y_{observation},\\zeta)= D_{KL}(q(x_{hypotheses}; \\zeta )\\parallel p(x_{hypotheses}\\mid  y_{observation}))-ln(p(y_{observation}))$$\n\nAnd if we leave the subscripts \u00a8hypotheses\u00a8 and \u00a8observation\u00a8 it shows as the equation you will find back in many papers of Karl Friston:\n![](https:\/\/i.imgur.com\/SjUhQc7.jpg)\n\nThe free energy has some interesting properties:\n* First of all, free energy can be evaluated by the brain. $\\mathcal{F}(y_{observation},\\zeta)$ is a function of sensory data ($y_{observation}$) and brain states ($\\zeta$, the brain representing the sufficient statistics for the recognition density, e.g. for a Gaussian density: mean \ud835\udf07, variance $\ud835\udf0e^2$). It is a function of 2 probability densities (see definition):   \n    * Recognition density: $q(x_{hypotheses}; \\zeta )$ an internal probablistic density in the brain to approximate posterior  $p(x_{hypotheses}\\mid  y_{observation})$, or in other words estimations of hidden states x (given observations y)\n    * Generative density: $p(x_{hypotheses},  y_{observation})$ as an internal probabilistic density in the brain of the environment,\n        *  which applying the product rule it can be written as  $p(y_{observation}\\mid x_{hypotheses})* p(x_{hypotheses})$: probability of sensory mapping (belief how states cause sensory input) times probability of motion (belief about state dynamics). It is the means of a brain to encode a probabilistic model of the environment\/world in which it is immersed. Therefore this generative density is also called the generative *model* (while the generative *process* is the process in the external environment\/world generating the sensory states). Its implementation form in Active Inference is represented as 2 functions, which we will explore further in the next notebook:\n            * function of motion: belief about states dynamics expressed by $f(x)+w$  representing $p(x_{hypotheses})$. Where w is random noise making it a probabilistic model.  \n            * function of sensory mapping: belief how states cause sensory input expressed by $g(x)+z$  representing $p(y_{observation}\\mid x_{hypotheses})$. Where z is random noise making it a probabilistic model.  \n        * For example: \n            * $q(x_{hypotheses}; \\zeta )$ estimates the current position x of a car, eg 10 meters with a variance of 10 centimeters\n            * $p(x_{hypotheses})$ estimates the function of how a position x changes with the speed of the car, eg x = x + speed\/time + random fluctuations\n            * $p(y_{observation}\\mid x_{hypotheses})$ estimates the function how observation y is determined given position x, eg y = x + random fluctuations in case the car drives straight to you but if it would drive at an angle the measured observation y would be different.\n \n* It is an automatable optimization problem. If we adopt Gaussian probability densities (the Laplace assumption), minimizing the free-energy corresponds to minimizing prediction errors. \n* Free energy $\\geq $ surprise because $D_{KL} \\geq 0$, the free energy bounds the information surprise in the observation data. Or in other words, by minimizing the free energy the information surprise in the sensory observations is minimized, see next chapter why this is important.\n\nSo what is free energy? Free energy is an information theory quantity that bounds the \u2018surprise\u2019 in sensory data. Crucially, unlike surprise itself, free energy can be evaluated because it is a function of sensory data and brain states.  Note that it is the surprise in terms of information theory, also sometimes called surprisal. See next chapter.\n\nWhy is it called free-energy? Somehow in my mind free energy sounded like a good thing (it is free, right?), why is lowering it? In this [paper](https:\/\/www.fil.ion.ucl.ac.uk\/spm\/doc\/papers\/Action_and_behavior_A_free-energy_formulation.pdf) Friston explains: it is called free energy because of formal similarities with thermodynamic free energy where the meaning of energy equals surprise (negative log probabilities). So lowering free energy is lowering surprise (make things more predictable), which is a good thing to do, see next paragraph.\n\nTo summarize it again in a picture:\n* x are the external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}\\in\\mathbb{R}^n$ with n number of states.\n* y are the sensory observations, the data from the available sensory set. Shorthand notation for the vector $\\vec{y}_{observation} \\in  \\mathbb{R}^{q}$ with q number of sensors. \n* u are the actions that can be performed on the environment, control signal. Shorthand notation for the vector $\\vec{u} \\in  \\mathbb{R}^{l}$ with l number of controls.\n* The brain infers the world in which it is immersed:\n    * by a generative density $p(x_{hypotheses},y_{observation})$: the brain encoding a probabilistic model of the environment\/world in which it is immersed. \n    * by a recognition density $q(x_{hypotheses}; \\zeta )$: the brain estimating hidden states $x_{hypotheses}$ (given sensory data $y_{observation}$)\n    \n![](https:\/\/i.imgur.com\/yGtQNyj.jpg)\n\n\n","ce298b26":"<a id='sec5'><\/a>\n# Base camp\nYou made it and reached base camp!  \nTo summarize the notebook\/progress in a picture:\n\n* x are the external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}\\in\\mathbb{R}^n$ with n number of states.\n* y are the sensory observations, the data from the available sensory set. Shorthand notation for the vector $\\vec{y}_{observation} \\in  \\mathbb{R}^{q}$ with q number of sensors. \n* u are the actions that can be performed on the environment, control signal. Shorthand notation for the vector $\\vec{u} \\in  \\mathbb{R}^{l}$ with l number of controls.\n* The brain infers the world in which it is immersed:\n    * by a generative density $p(x,y)$: the brain encoding a probabilistic model of the environment\/world in which it is immersed. \n    * by a recognition density $q(x; \\zeta )$: the brain estimating hidden states $x$ (given sensory data $y$)\n    * by finding $\\zeta$ and $u$ with the lowest Free Energy and thus lowest surprise in sensory states:\n        * By improving perception:  $\\zeta= \\underset{\\zeta }{Argmin}\\:  \\mathcal{F}(y,\\zeta)$ \n        * By acting on the environment:  $u=\\underset{u }{Argmin}\\:  \\mathcal{F}(y,\\zeta)$ \n\n![](https:\/\/i.imgur.com\/eB6QaTB.jpg)\n\n","6e530724":"<a id='sec1'><\/a>\n# Inference\nThe term \"[inference](https:\/\/examples.yourdictionary.com\/examples-of-inference.html)\" according to the dictionary is \"the process of using observation and background knowledge as well as other known premises to determine a conclusion that makes sense\".  \ne.g. I see cookie crumbs around my daughter's mouth. I can infer that my daughter got into the cookie jar.\n\nWhy is this important?  \nThe brain is skull-bound and needs to infer the causes of its sensory input, it observes the world through a veil of sensory input and the real world can only be inferred.    \nTo stay in the ball catching example, the ball position needs to be inferred using the \u00a8pixels\u00a8 on the retina of your eye. Even states of your body need to be inferred, everything outside the brain needs to be inferred. For example, the position of your arms needs to be inferred using sensory data coming from your nervous system. Etc  \nAnd inference has to be a basic primal capability, even simpler life forms can inference, e.g. a shadow going over a [mouse](https:\/\/www.nature.com\/articles\/s41586-018-0244-6?WT.feed_name=subjects_synaptic-transmission) will make it run for cover because it learned to infer danger from the skies. Etc, etc.\n\nLet's do a thought experiment that I liked to get some understanding of the daunting task of the brain.  \nIt is an experiment called \u00a8trapped in the robot control room\u00a8 by [Daniel Denett](https:\/\/issuu.com\/vm2k14\/docs\/daniel_c._dennett_-_intuition_pumps), it goes like this:\nOne day, you are placed in the control room of a giant robot. One area is covered in thousands of numbered blinking lights, and one area is covered with thousands of numbered buttons. The lights are all outputs from the raw inputs streaming from the robot's video eyes, microphone ears, touch sensors, etc on the robot's body. Each button controls some actuator or output (like moving a muscle).  \n\nYou push button 8423 and you notice that the light 427 flickers out. You investigate button 1821 and notice that most of the time light 823 turns on, but not always. What has changed in the world? There is no window in the control room where you can peek out to understand what happened in the world. (In fact, your brain itself has no direct sensors at all, if I could somehow poke your brain right now, you would not even feel it.) You have to infer the world via the sensory input you get from the body. In other words, by interpretation of all the sensory observations the brain needs to hypothesize of what is happening in the external world.  \n\nTo put some structure around it:\n* x are the external hidden environment states the brain tries to infer. Called hidden because they are seldom observed directly, e.g. the ball position needs to be inferred using the sensory observation like \u00a8pixels\u00a8 on the retina of your eye. Shorthand notation for the vector $\\vec{x}_{hypotheses}\\in\\mathbb{R}^n$ with n number of states. The real world has many states but for now let's take some examples with a few states, e.g. the position of the ball, the position of your arm joints, etc\n* y are the sensory observations, the data from the available sensory set (the blinking lights). Shorthand notation for the vector $\\vec{y}_{observation} \\in  \\mathbb{R}^{q}$ with q number of sensors. or example: seeing, hearing, smelling, touching, etc\n* u are the actions that can be performed on the environment, control signal (the numbered buttons). Shorthand notation for the vector $\\vec{u} \\in  \\mathbb{R}^{l}$ with l number of controls. For example: the muscles of your eyes, arms, etc\n* The brain infers the world in which it is immersed\n\n![](https:\/\/i.imgur.com\/kpe7uR0.jpg)\n\n","5e3df59d":"Let me end the Bayesian paragraph with a nice exercise that is often quoted in a Bayesian learning context.  \n\nYou go to the doctor to have a test for a rare disease that normally strikes 1 in 1000 people. The test has a 99% accuracy. You test positive. What is the chance you actually have the disease?  \nHave a look at this [video](https:\/\/www.youtube.com\/watch?v=R13BD8qKeTg) for the answer and a great explanation of Bayesian logic.\n","3365001f":"## Imagine your child throws a ball to you and you want to catch it.\n<img src=\"https:\/\/images.unsplash.com\/photo-1534582953738-82b9f1d52eab?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1053&q=80\" width=500 >\n<center>Image by Anshu A from <a href=\"https:\/\/unsplash.com\/photos\/3VzJwKx6hGc\">Unsplash<\/a> <\/center>   \nYour arms seamlessly move to catch the ball in mid-air. How did you accomplish that? Did your brain take an engineering approach and calculate the trajectory formula of the ball to know the height?  \n$$y=xtan(\\Theta)-\\frac{gx^{2}}{2{v_{0}}^{2}cos^{2}\\Theta }$$  \nLet alone to compensate for the wind? I think not...   \nOnce your brain figured out where to position your hand to catch the ball, did it do the reversed kinematics calculations for your arm joint positions? Did you think about the angles of your arm and shoulder joints, how much strength on your biceps\/triceps? Did you consciously move certain muscles? I think not...  \n\nHope we can agree that an engineering approach is not what the brain does. But what did your brain do? I will keep using this example throughout the notebook series to explain how the brain might be doing this according to the free-energy principle.\n","35a3d763":"<a id='sec6'><\/a>\n# How the brain might function- part 2\nWhen you\u2019re sitting in base camp and you look up to the top and the long way to go, you might wonder if it is worth it. Yes it is! Below the teaser of a robot moving with active Inference by Corrado Pezzato at the Technical University Delft. See github repository [active inference for robot manipulators](https:\/\/github.com\/cpezzato\/panda_simulation).\n\n![](https:\/\/user-images.githubusercontent.com\/49310726\/56992707-f02b0e80-6b9a-11e9-99fd-58a31f114d0e.gif)\n\nHope you liked my notebook (upvote top right), my way to contribute back to this fantastic Kaggle platform and community. Let me know if these notes helped you to better understand active inference and the free energy principle. My intent is to help catalyze knowledge and research on Active Inference in an engineering\/robotics\/data sciences\/machine learning context.  \n\nSo if you are interested to learn more about it please keep on reading in the next notebook where we will explore how active inference translates into a straightforward prediction error minimization scheme: [How the brain might function - part 2](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-2).\n\nI would like to especially thank Sherin Grimbergen, I could build my understanding on his investigations and our dialogues helped me a lot in understanding active inference. Also special thanks to Corrado Pezzato and Ajith Anil Meera for proofreading and giving valuable feedback. And finally please remember, this notebook is just trying to make the brilliant work of Karl Friston more accessible, it might Hold the Key to True AI.","f346b257":"# How the brain might function - part 1 base camp \n### Free Energy Principle tutorial without a PhD\n  \n<img src=\"https:\/\/cdn.pixabay.com\/photo\/2018\/05\/08\/08\/44\/artificial-intelligence-3382507_960_720.jpg\" width=500>\n<center>Image by <a href=\"https:\/\/pixabay.com\/users\/geralt-9301\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Gerd Altmann<\/a> from <a href=\"https:\/\/pixabay.com\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Pixabay<\/a> <\/center>   \nWelcome to my notebook on Kaggle. I did record my notes with examples so it might help others in their journey to understand **Active Inference** minimizing the underlying **Free Energy** by examples.\n\nRecent years we made great steps in Artificial Intelligence. But let's face it, Artificial Intelligence is not yet really intelligent, it is a regression technique and with a lot of data and computing power able to deliver amazing results.   \nResearch into biological inspired true artificial intelligence continues and neuroscience has produced a candidate which suggests that several global brain theories might be unified within a free-energy framework: [Free Energy Principle](https:\/\/en.wikipedia.org\/wiki\/Free_energy_principle) (FEP) by [Karl Friston](https:\/\/www.fil.ion.ucl.ac.uk\/~karl\/): The free-energy principle is an attempt to explain the structure and function of the brain, starting from the very fact that we exist. The Free Energy Principle is mathematically rigorous and both neurologically and evolutionary plausible. It [might hold the key to true AI](https:\/\/www.wired.com\/story\/karl-friston-free-energy-principle-artificial-intelligence\/).   \n\nA lot of research papers have been published by Karl Friston and understanding them has a steep learning curve. Even to the point that people complain about it ([\u00a8God Help Us, Let\u2019s Try To Understand Friston On Free Energy\u00a8](https:\/\/www.lesswrong.com\/posts\/wpZJvgQ4HvJE2bysy\/god-help-us-let-s-try-to-understand-friston-on-free-energy)). I did record my notes with examples so it might help you to get a better understanding. This to help catalyze knowledge and research on Active Inference and the Free Energy Principle in an engineering\/robotics\/data sciences\/machine learning context. So if you are interested please keep on reading and upvote top right, leave a comment or contact me directly.","84306cb7":"# Table of Contents\nIn this notebook, I will explain the Free Energy Principle by explaining Active Inference minimizing the underlying Free Energy. This is a different approach to the research papers I read and it did help me to get a better understanding. Active inference is a shortcut for Active Variational Bayesian Inference, hence the structure I will follow in this notebook:\n1. [Inference](#sec1)    \n1. [Bayesian Inference](#sec2)\n    1. [Probability density](#sec21)\n    1. [Bayes' theorem](#sec22)\n    1. [Cookie example](#sec23)\n    1. [Bayesian Learning](#sec24)\n1. [Variational Bayesian Inference](#sec3)\n    1. [What the brain is doing - Prediction error minimization](#sec31)\n    1. [How the brain is doing it - Free Energy bounds surprise ](#sec32)\n    1. [Why the brain is doing it - Minimize surprise](#sec33)\n    1. [Minimize free energy by improving perception](#sec34)\n1. [Active Variational Bayesian Inference](#sec4)\n    1. [Minimize free energy by acting on the environment](#sec41)\n1. [Base camp](#sec5)\n1. [How the brain might function- part 2](#sec6)\n1. [Appendix](#secA)  \n    1. [Dice example](#secA1)\n1. [Conventions and Symbols](#secC)\n\n\nIt is a conscious choice to use as much as possible arguments and sentences from Friston's papers enriched with examples and insights for understanding. In the end, this notebook turned out to be longer than I anticipated and I needed to create a notebook series, there is a lot to explain. The Free energy principle has rich content that draws from many scientific disciplines. Enjoy.   \nThe articles of Karl Friston I mainly used for this notebook: [A free energy principle for the brain](https:\/\/www.fil.ion.ucl.ac.uk\/~karl\/A%20free%20energy%20principle%20for%20the%20brain.pdf), [The free-energy principle: a rough guide to the brain?](https:\/\/www.fil.ion.ucl.ac.uk\/~karl\/The%20free-energy%20principle%20-%20a%20rough%20guide%20to%20the%20brain.pdf), [Action and behavior: a free-energy formulation](https:\/\/www.fil.ion.ucl.ac.uk\/spm\/doc\/papers\/Action_and_behavior_A_free-energy_formulation.pdf).  \n","81ca42ce":"<a id='sec3'><\/a>\n# Variational Bayesian Inference\n\nUnfortunately, we do have a challenge calculating Bayes' theorem [1].  \n\nThe challenge is to calculate the denominator $p(y_{observation})$. It can be easily seen by writing out (applying the sum rule, the probability of x equals the probability of the sum of the probability of x given y for all possible y) the denominator leading to equation [2a] for discrete variables or equation [2b] for continues variables:  \n$$p(x_{hypotheses}\\mid  y_{observation})=\\frac{p(y_{observation}\\mid  x_{hypotheses}) * p(x_{hypotheses})}{\\sum_xp(y_{observation}\\mid  x_{hypotheses}) * p(x_{hypotheses})} \\:\\:\\:\\:\\:   [2a]$$ \n$$p(x_{hypotheses}\\mid  y_{observation})=\\frac{p(y_{observation}\\mid  x_{hypotheses}) * p(x_{hypotheses})}{\\int p(y_{observation}\\mid  x_{hypotheses}) * p(x_{hypotheses})dx} \\:\\:\\:\\:\\:   [2b]$$ \n\nThe denominator normalizes the probability, in other words, you need to average over all possible occurrences of the sensory observations (how to even know all possible observations?). The part in the nominator: $p(y_{observation}\\mid  x_{hypotheses}) * p(x_{hypotheses})$ is just one of the cases of the denominator as is easily seen in the discrete equation. Let alone calculating an integral $\\int p(y_{observation}\\mid  x_{hypotheses}) * p(x_{hypotheses})dx$ for continues variables. Which is unavailable in a complex high dimensional real world, or requires exponential time to compute! In short, the denominator $p(y_{observation})$ is generally intractable.  \n\nThe solution in active inference is to invoke Variational Bayesian inference methods: a set of techniques to *approximate* posterior  $p(x_{hypotheses}\\mid  y_{observation})$ probability density\n* Approximation model in the brain for a complex real-world, a sort of best guess for $p(x_{hypotheses}\\mid  y_{observation})$\n* Is suited for large complex data sets and scenarios \n\nFind a \u201crecognition\u201d probability density $q(x_{hypotheses}; \\zeta )$ that approximates the target density $p(x_{hypotheses}\\mid  y_{observation})$. \n* From a family of \u201cnice\u201d probability densities. The Free Energy Principle \/ active inference assumes Gaussian probability density.\n* Is specified by its sufficient statistics $\\zeta$ (e.g. for a Gaussian density: mean $\\mu$, variance $\\sigma^2$)\n* Find the right $\\zeta$ such that $q(x_{hypotheses}; \\zeta )$ is an approximation for $p(x_{hypotheses}\\mid  y_{observation})$\n* In the picture below, find the green probability density $q(x_{hypotheses}; \\zeta )$, in this example a basic normal\/Gaussian density, that approximates the blue complex target density $p(x_{hypotheses}\\mid  y_{observation})$.\n<img src=\"https:\/\/i.imgur.com\/NejhDaa.jpg\" width=200>\n\nTo summarize it again in a picture:\n* x are the external hidden environment states the brain tries to infer. Shorthand notation for the vector $\\vec{x}_{hypotheses}\\in\\mathbb{R}^n$ with n number of states.\n* y are the sensory observations, the data from the available sensory set. Shorthand notation for the vector $\\vec{y}_{observation} \\in  \\mathbb{R}^{q}$ with q number of sensors. \n* u are the actions that can be performed on the environment, control signal. Shorthand notation for the vector $\\vec{u} \\in  \\mathbb{R}^{l}$ with l number of controls.\n* The brain infers hidden states of the world in which it is immersed:\n    * Recognition density $q(x_{hypotheses}; \\zeta )$: the brain estimating hidden states $x_{hypotheses}$ (given sensory data $y_{observation}$)\n\n![](https:\/\/i.imgur.com\/7nNZ4YD.jpg)\n","46ef30a4":"<a id='sec4'><\/a>\n# Active Variational Bayesian Inference\n\nThe last paragraph we reviewed the brain to minimize the free energy by improving the internal model to better match the sensory input. In this paragraph we review the brain minimizing free energy by acting upon the environment.  \n\n<a id='sec41'><\/a>\n## Minimize free energy by acting on the environment\n\nPerceptual inference can lead to a tight bound on surprise but it cannot reduce surprise in the observations itself. By acting upon the environment, the brain can reduce surprising sensory input, e.g. avoid surprises. Action \ud835\udc62 can indirectly influence observation y. In the Free energy equation:\n\n![](https:\/\/i.imgur.com\/JlVNIKi.jpg)\n\nAssuming the brain made a good estimation $q(x; \\zeta )$ to equal posterior  $p(x_{hypotheses}\\mid  y_{observation})$ probability density, we can see that the **active inference part** of free energy minimization is equal to lowering $p(-ln(y_{observation}))$ (surprise in the sensory observations) by acting upon the environment. Actions cannot directly change observations y but can indirectly change them by acting on the environment states x. \n\nFor example:\n* if you think you see a tiger you can adapt your eye position to have a closer look to hopefully conclude it is your cat. Action to lower the surprise in observation states by a better sampling of the environment by eye movement.\n* If the woodlice live in cooler places, better move if you are in warm daylight. Action to lower the surprise in observation states by moving to an environment with expected observation states.\n* Going back to the example of catching the ball, how does that work? If you want your arm stretched out to catch the ball, your brain predicts your arm stretched. Action to Lower the surprise in observation states by moving your arm to the expected stretched arm state. Action can be thought of as classical [reflex arcs](https:\/\/en.wikipedia.org\/wiki\/Reflex_arc). In simple terms: your brain \"wills\" or predicts your arm stretched, and reflex arcs will move your arm to the desired position to lower the Free-energy (sensory surprise). **You predict (think) first and that causes you to act to make your own prediction (thought) come true.** And how does the brain know where to move the arm to? Here come the priors of the [Bayesian learning](#sec24) into play, the brain can use any memory of similar experiences for the prior distribution.\n\nInteresting idea!\n\nThe perceptual inference part and active inference part are to unfold continuously and simultaneously, underlining a deep continuity between perception and action. They are both sides of the same coin, performing the same Free Energy minimization algorithm. \n* There has to be a deep connection because to predict what we sense next is highly dependent on our own actions. E.g. To predict what we see is tightly connected to turning our head or an eye [saccade](https:\/\/en.wikipedia.org\/wiki\/Saccade) (human eyes make saccadic movements and stop several times, moving very quickly between each stop). Or to predict what we feel is depending what we touch which is highly dependent on our own movement.\n* The brain can learn\/predict patterns in how sensory input would change given a certain action.\n* Various neuroscience research points out a deep connection between action and sensing in our brain. In 1978 [Vernon Mountcastle](https:\/\/en.wikipedia.org\/wiki\/Vernon_Benjamin_Mountcastle#cite_note-13) proposed that all parts of the [cortex](https:\/\/en.wikipedia.org\/wiki\/Cerebral_cortex) operate through a common principle, based on his observation that the neocortex structure and appearance are highly similar for all regions, that is regions that handle auditory input, sensory input, somatosensory (body sense) input but also the motor output region. More recent studies even showed a direct link from all neocortex sensory regions to the muscular neural pathways suggesting a more widespread deeper connection between perception and action.\n* Some people might argue: Take the action to close your eyes and ears and sit in your cellar and your prediction is quite easy. That strategy will not work because eventually you will get thirsty and your somesthetic senses (touch\/feeling) will inform you, and good we have them else you would jeopardize your life without knowing it, not a good strategy for a species to survive. Simply switching them off is not a good strategy.\n\nHow this is exactly done in active inference we will investigate in next notebooks. For now, it is sufficient to conclude the equation to find $u$ with the lowest Free Energy (also sometimes noted as $u^*$) that has to be solved is:\n$$ u=\\underset{u }{Argmin}\\:  \\mathcal{F}(y_{observation},\\zeta)$$\n\n","fd7e8e85":"<a id='secA'><\/a>\n# Appendix\n\n<a id='secA1'><\/a>\n## Dice example\n\nlet's have a look at an example to calculate the probability. I deliberately chose a basic and simple dice example with discrete values so it is easier to understand connecting to our available\/intuitive knowledge about chances when throwing dice. Bayesian logic is not always very intuitive, so I do want to recommend playing around with some examples to familiarize yourself with Bayesian logic.  \n\nIn this dice example, a person will throw secretly either 1 or 2 six-sided dice, mostly 2 dice (60%) but also 1 dice (40%). You will just get the resulting number and you have to guess how many dice were thrown.  \n(a) If the person tells you the result is 1 you probably figured out it had to be with 1 six-sided dice, kind of hard to throw 1 with 2 dice.  \n(b) If the person tells you the result is 4 what would be more likely 1 or 2 six-sided dice? A naive approach would be to guess 2 dice because mostly 2 dice are thrown, or isn't it? Bayes' Theorem can help you to figure it out.  \n\nSo we are asking:\n\n(a) $$p(Dice=2 \\mid  Observation=1)=\\frac{p(Observation=1 \\mid Dice=2) * p(Dice=2)}{p(Observation=1)}$$ \nwhich is 0 because $p(Observation=1 \\mid Dice=2)$ is 0. So also Bayes's theorem confirms it is kind of hard to throw a 1 with 2 dice. Good start.\n\n(b) $$p(Dice=2 \\mid  Observation=4)=\\frac{p(Observation=4 \\mid Dice=2) * p(Dice=2)}{p(Observation=4)}$$ \n  \nwhich is equal to (apply sum rule, see equation [2a] next paragraph):\n$$=\\frac{p(Observation=4 \\mid Dice=2) * p(Dice=2)}{p(Observation=4 \\mid Dice=1) * p(Dice=1)+p(Observation=4 \\mid Dice=2) * p(Dice=2)}$$\n  \nSince this is a dice example and we remember the dice probabilities from high school the probability can be evaluated directly:\n$$=\\frac{\\frac{3}{36} * \\frac{6}{10}}{\\frac{1}{6} * \\frac{4}{10}+\\frac{3}{36} * \\frac{6}{10}}=\\frac{0,05}{0,1166}\\approx 43\\% $$\n  \nBoth (a) and (b) are point estimates for easy understanding. Bayesian logic also works with complete probability distributions (discrete and continuous). Did generate the discrete probability distributions below for reference. Please play around with the example below to better familiarize yourself with Bayes' Theorem.","24be2cef":"<a id='sec22'><\/a>\n## Bayes' theorem\nLet's define:  \n*  $p(x_{hypotheses})$ as the probability density of hypotheses x. \n*  $p(x_{hypotheses}\\mid  y_{observation})$ as the probability density of hypotheses x  given the observation y (conditional probability) \n*  $p(x_{hypotheses}, y_{observation})$ as the probability density of hypotheses x and observation y together (joint probability)  \n\nBayes' theorem is surprisingly easy to derive with basic probability rules:\n\nSymmetric property, the joint probability of x and y is the same as the probability of y and x:\n$$p(y_{observation} , x_{hypotheses})=p(x_{hypotheses},  y_{observation})$$  \nApply the product rule, the probability of x and y equals to probability of y multiplied with the probability of x given y.\n$$p(x_{hypotheses}\\mid  y_{observation})p(y_{observation})=p(y_{observation}\\mid x_{hypotheses})p(x_{hypotheses})$$ \n\nWhich leads to Bayes' theorem:  \n$$p(x_{hypotheses}\\mid  y_{observation})=\\frac{p(y_{observation}\\mid  x_{hypotheses}) * p(x_{hypotheses})}{p(y_{observation})} \\:\\:\\:\\:\\:   [1]$$  \n\nIf we replace $(x_{hypotheses}$ by A and $y_{observation}$ by B in [1], the famous Bayesian formula becomes visible. I read somewhere it is custom to put it into neon letters, so here we go:\n![](https:\/\/i.imgur.com\/O8ACGRH.jpg)\n\n<a id='sec23'><\/a>\n## Cookie example\nTo build some intuition around it, let's use the example: \u00a8I see cookie crumbs around my daughter's mouth, maybe she got into the cookie jar.\u00a8 So in probability terminology, we are asking ourselves: $p(StoleCookie\\mid  SeeCrumbs)$ and because of Bayes' theorem we can write it as:  \n$$p(StoleCookie\\mid  SeeCrumbs)=\\frac{p(SeeCrumbs \\mid StoleCookie) * p(StoleCookie)}{p(SeeCrumbs)}$$   \n\n* The likelihood term $p(SeeCrumbs \\mid StoleCookie)$ tells us that the more likely the effect is giving the cause, the more likely the cause is giving the effect. So if your daughter eats stolen cookies in such a way that she normally leaves crumbs around her mouth, the higher the chance she actually stole a cookie given the observation that her mouth displays cookie crumbs.  \n* The prior term $p(StoleCookie)$ tells us that the higher the prior expectation your daughter steals cookies (eg she has done it before) the higher the probability she actually stole a cookie given the observation her mouth displays cookie crumbs.\n* The numerator, also sometimes called the evidence term, $p(SeeCrumbs)$ tells us that the higher the probability you normally observe cookie crumbs around her mouth due to other effects (eg she always leaves crumbs around her mouth even when eating crackers, non-stolen cookies, she never washes her face, etc) the lesser the chance she actually stole a cookie given the observation her mouth displays cookie crumbles.  \n\nMakes sense!\n\n<a id='sec24'><\/a>\n## Bayesian Learning\n\nWith Bayes' Theorem, the brain can infer hypotheses x of the real world given the observation\/data y. But also the Bayes' Theorem enables the brain to learn. \n* The brain can use any memory of a similar experience about the problem for the prior distribution. E.g. To go back to the ball throwing example, the brain can learn by analogy (did throw some balls with my nephew last year), past similar experience (as a kid myself I was throwing balls), expert examples (watched some films where kids where throwing balls), hearsay (heard from the school teacher he is an excellent ball thrower), etc, etc. \n* Updating our beliefs\/hypotheses about the world based on new evidence that we observe (using a prediction error minimization approach, see later in the notebook). E.g. the more balls you are throwing with your child, the more evidence to estimate where the ball will probably come. \n* You even start to notice different specifics (e.g. the way the ball is thrown) so you can make the belief\/hypotheses x more specific  $p(Ball distance_{hypotheses}\\mid  lowerHand_{observation} , AttentionLevel_{observation} , RightFootLifted_{observation} )$"}}