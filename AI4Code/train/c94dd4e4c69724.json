{"cell_type":{"783a3be5":"code","b53953a4":"code","80615f29":"code","875e68cf":"code","5db22423":"code","bee521f1":"code","8f315acf":"code","50ea30d4":"code","27119cdb":"code","3ad4b7de":"code","b946fad8":"code","d4df8100":"code","3435847a":"code","9f03f59d":"code","f0a624ae":"code","42f68d59":"code","1cb49364":"code","9a34ffc0":"code","491eb12a":"code","c36bbcff":"code","d9b261b3":"code","65c5ed5e":"code","f866aa59":"code","3628f31e":"code","0da7724d":"markdown","0eb92e7c":"markdown","83bd3817":"markdown","ca3758e4":"markdown","9f4980e4":"markdown","bdffd9fe":"markdown","cd486a94":"markdown","48df559e":"markdown"},"source":{"783a3be5":"!\/opt\/conda\/bin\/python3.7 -m pip install --upgrade pip\n!pip install tf_slim\n!pip install pycocotools\n!pip install --user Cython -q\n!pip install --user contextlib2 -q\n!pip install --user pillow -q\n!pip install --user lxml -q","b53953a4":"import pdb\nimport pathlib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport pandas as pd\nimport tensorflow as tf\nimport sys\nimport tarfile\nimport tempfile\nimport zipfile\nimport glob\nimport cv2\nfrom pathlib import Path\n\nfrom PIL import Image, ImageOps\nfrom IPython.display import display\nimport hvplot.pandas\nimport os\n\n%matplotlib inline\n%xmode Verbose\n\nimage_path = Path('\/kaggle\/input\/open-images-object-detection-rvc-2020')\ndata_path = Path('\/kaggle\/input\/open-image-2019')\nimage_list = sorted(image_path.glob('test\/*.jpg'))\n\nprint(tf.__version__)\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    # Restrict TensorFlow to only use the first GPU\n    try:\n        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n    except RuntimeError as e:\n        # Visible devices must be set before GPUs have been initialized\n        print(e)","80615f29":"print('Getting image ids...')\ndf_image_ids = pd.read_csv(image_path\/'sample_submission.csv')\ndf_image_ids.drop('PredictionString', axis=1, inplace=True)","875e68cf":"# Install the protobufs compiler\n!wget -O protobuf.zip https:\/\/github.com\/google\/protobuf\/releases\/download\/v3.0.0\/protoc-3.0.0-linux-x86_64.zip -q\n!unzip -o protobuf.zip\n!rm protobuf.zip","5db22423":"%cd \/kaggle\n!rm -fr models\n!git clone https:\/\/github.com\/tensorflow\/models.git\n!rm -fr models\/.git","bee521f1":"# Compile protobufs\n%cd \/kaggle\/models\/research\n!..\/..\/working\/bin\/protoc object_detection\/protos\/*.proto --python_out=.","8f315acf":"# Install models\n!pip install .","50ea30d4":"# Environment Variables\nos.environ['AUTOGRAPH_VERBOSITY'] = '0'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONPATH']=os.environ['PYTHONPATH']+':\/kaggle\/models\/research\/slim:\/kaggle\/models\/research'\nos.environ['PYTHONPATH']","27119cdb":"# Import object detection model\nfrom object_detection.utils import ops as utils_ops\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as vis_util","3ad4b7de":"# patch tf1 into `utils.ops`\nutils_ops.tf = tf.compat.v1\n\n# Patch the location of gfile\ntf.gfile = tf.io.gfile","b946fad8":"!python object_detection\/builders\/model_builder_test.py","d4df8100":"# Get the file name from the image id\ndef filename_from_id(id):\n    return os.path.join(image_path, 'test\/', '{}.jpg'.format(id) )","3435847a":"# Resizes image to new_width x new_height and returns PIL file\ndef resize_image(path, new_width=900, new_height=900):\n    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n    pil_image = Image.open(path)\n    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n    pil_image_rgb = pil_image.convert(\"RGB\")\n    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n    # print('Resized image saved as: {}'.format(filename))\n    return filename","9f03f59d":"# Display a PIL image file\ndef display_image(image_path):\n    image_np = np.array(Image.open(image_path))\n    display(Image.fromarray(image_np))","f0a624ae":"%cd \/kaggle\nsample_submission_df = pd.read_csv(f'{image_path}\/sample_submission.csv')\nimage_ids = sample_submission_df['ImageId']\ndel sample_submission_df","42f68d59":"test_img = 50000\n# Build a list of images\n\nfilename = filename_from_id(image_ids[test_img])\n\n# Load, resize and display sample image\nfilename_r = resize_image(filename)\nprint(filename_r)\ndisplay_image(filename_r)\n","1cb49364":"# Model Loader\ndef load_model(model_name):\n    base_url = 'http:\/\/download.tensorflow.org\/models\/object_detection\/'\n    model_file = model_name + '.tar.gz'\n    model_dir = tf.keras.utils.get_file(fname=model_name, \n                                        origin=base_url + model_file,\n                                        untar=True)\n\n    model_dir = pathlib.Path(model_dir)\/\"saved_model\"\n\n    model = tf.saved_model.load(str(model_dir))\n    model = model.signatures['serving_default']\n\n    return model","9a34ffc0":"# Load Label Map\nPATH_TO_LABELS = 'models\/research\/object_detection\/data\/oid_v4_label_map.pbtxt'\ncategory_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)","491eb12a":"model_name = 'faster_rcnn_inception_resnet_v2_atrous_oid_v4_2018_12_12'\ndetection_model = load_model(model_name)","c36bbcff":"def run_inference_for_single_image(model, image):\n    image = np.asarray(image)\n    \n    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n    input_tensor = tf.convert_to_tensor(image)\n    \n    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n    input_tensor = input_tensor[tf.newaxis,...]\n\n    # Run inference\n    output_dict = model(input_tensor)\n\n    # All outputs are batches tensors.\n    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n    # We're only interested in the first num_detections.\n    num_detections = int(output_dict.pop('num_detections'))\n    output_dict = {key:value[0, :num_detections].numpy() for key,value in output_dict.items()}\n    output_dict['num_detections'] = num_detections\n\n    # detection_classes should be ints.\n    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n   \n    # Handle models with masks:\n    if 'detection_masks' in output_dict:\n        # Reframe the the bbox mask to the image size.\n        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n                  output_dict['detection_masks'], output_dict['detection_boxes'],\n                   image.shape[0], image.shape[1])      \n        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n                                           tf.uint8)\n        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n\n    return output_dict","d9b261b3":"def show_inference(model, image_path):\n    # the array based representation of the image will be used later in order to prepare the\n    # result image with boxes and labels on it.\n    image_np = np.array(Image.open(image_path))\n  \n    # Actual detection.\n    output_dict = run_inference_for_single_image(model, image_np)\n    \n    # Visualization of the results of a detection.\n    vis_util.visualize_boxes_and_labels_on_image_array(\n        image_np,\n        output_dict['detection_boxes'],\n        output_dict['detection_classes'],\n        output_dict['detection_scores'],\n        category_index,\n        instance_masks=output_dict.get('detection_masks_reframed', None),\n        use_normalized_coordinates=True,\n        line_thickness=8)\n    \n    display(Image.fromarray(image_np))\n    return output_dict","65c5ed5e":"# Check the input signature and output types\nprint('Input signature: {}\\n'.format(detection_model.inputs))\nprint('Output dtypes: {}\\n'.format(detection_model.output_dtypes))\nprint('Output shapes: {}'.format(detection_model.output_shapes))","f866aa59":"pred = show_inference(detection_model, filename_r)","3628f31e":"print(pred)","0da7724d":"## Resize and Display Sample Image","0eb92e7c":"## Model Preparation","83bd3817":"### Test on Single Image","ca3758e4":"### Get a Model","9f4980e4":"### Detection","bdffd9fe":"## Set up Environment","cd486a94":"## Get Classes, Labels, and Boxes","48df559e":"# Open Images Object Detection RVC 2020 edition\n### Detect objects in varied and complex images"}}