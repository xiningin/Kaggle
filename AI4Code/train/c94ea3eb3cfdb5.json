{"cell_type":{"e17997c5":"code","56c82c40":"code","1426948f":"code","9982ab54":"code","e8e862f2":"code","ef01227e":"code","6bb6c3e1":"code","3d170e38":"code","b0eeb900":"code","193e8365":"markdown","07cc6622":"markdown","a681d280":"markdown","51ddd3f5":"markdown"},"source":{"e17997c5":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow import keras\nfrom PIL import Image\nimport glob\nimport random\nimport pandas as pd\n","56c82c40":"files=glob.glob(\"\/kaggle\/input\/hotdognothotdog\/hotdog-nothotdog\/train\/hotdog\/*.jpg\")\nTrainData = []\nindex = 0\n\nfor file in files:\n    img = Image.open(file)\n    img = img.resize((128, 128))\n    imgarray = np.asarray(img)\n    TrainData.append((imgarray,1))\n\nfiles=glob.glob(\"\/kaggle\/input\/hotdognothotdog\/hotdog-nothotdog\/train\/nothotdog\/*.jpg\")\nindex = 0\nfor file in files:\n    img = Image.open(file)\n    img = img.resize((128, 128))\n    imgarray = np.asarray(img)\n    TrainData.append((imgarray,0))\n\nprint(\"Done.\")\n\nrandom.shuffle(TrainData)","1426948f":"files=glob.glob(\"\/kaggle\/input\/hotdognothotdog\/hotdog-nothotdog\/test\/hotdog\/*.jpg\")\nTestData = []\nindex = 0\n\nfor file in files:\n    img = Image.open(file)\n    img = img.resize((128, 128))\n    imgarray = np.asarray(img)\n    TestData.append((imgarray,1))\n\nfiles=glob.glob(\"\/kaggle\/input\/hotdognothotdog\/hotdog-nothotdog\/test\/nothotdog\/*.jpg\")\nindex = 0\nfor file in files:\n    img = Image.open(file)\n    img = img.resize((128, 128))\n    imgarray = np.asarray(img)\n    TestData.append((imgarray,0))\n\nprint(\"Done.\")\n\nrandom.shuffle(TestData)","9982ab54":"print(\"TrainData \",len(TrainData))\nprint(\"TrainData \",len(TestData))","e8e862f2":"Train_X = np.array([item[0] for item in TrainData])\nTrain_Y = np.array([item[1] for item in TrainData])\n\nTest_X = np.array([item[0] for item in TestData])\nTest_Y = np.array([item[1] for item in TestData])\n\nTrain_X = Train_X.astype('float32')\nTest_X = Test_X.astype('float32')\n\nTrain_X \/= 255\nTest_X \/= 255","ef01227e":"model = keras.Sequential([\n    keras.layers.AveragePooling2D((2,2),2,input_shape=(128,128,3)),\n    keras.layers.Conv2D(32,(3,3),activation='relu'),\n    keras.layers.MaxPool2D(),\n    keras.layers.Dropout(0.1),\n    keras.layers.Conv2D(32,(3,3),activation='relu'),\n    keras.layers.Conv2D(32,(3,3),activation='relu'),\n    keras.layers.MaxPool2D(),\n    keras.layers.Dropout(0.3),\n    keras.layers.Conv2D(64,(3,3),activation='relu'),\n    keras.layers.Conv2D(64,(3,3),activation='relu'),\n    keras.layers.MaxPool2D(),\n    keras.layers.Dropout(0.5),\n    keras.layers.Conv2D(128,(3,3),activation='relu'),\n    keras.layers.MaxPool2D(),\n    keras.layers.Dropout(0.5),\n    keras.layers.Flatten(),\n    keras.layers.Dense(128,activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(1,activation='sigmoid')\n])\n\nmodel.compile(optimizer ='adam',loss=keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n\nmodel.fit(Train_X, Train_Y, epochs = 50, batch_size = 100)","6bb6c3e1":"model.evaluate(Test_X,Test_Y)","3d170e38":"Predictions = model.predict(Test_X)\n\n","b0eeb900":"plt.figure(figsize=(10, 10))\na = 95\nfor i in range(0,9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(Test_X[i+a])\n    plt.title(\"Label: \"+str(Test_Y[i+a])+\" Pred: \"+str(Predictions[i+a][0]))\n    plt.axis(\"off\")","193e8365":"# **Context**\n\nOn HBO's show Silicon Valley season 4, Jian-Yang (a character from the show) creates an app that was pitched as a \"Shazam for food\", his app however ends up only being able to classify hotdogs and nothing else. Replicating his results will be the goal of this notebook.","07cc6622":"# **Preprocessing the Data**\n \nAll images in the dataset needs to be resized to the same size because sequential neural nets accept fixed sized inputs only, after that we need to convert the images to numpy arrays and normalise the arrays to have values from 0 to 1 (insted of 0 to 255 of the RGB format) since neural nets are designed to work with inputs at this range.","a681d280":"# **The Model**\n\nMany models architectures were tested, the best performing being the one shown below, my intuition to build this net was to follow a similar shape to the VGG16 net, but smaller to save resources. Dropout layers were added after each block to avoid overfitting. BinaryCrossentropy() was used as the loss function since choosing between hotdogs and not-hotdogs is a binary problem. due to the nature of the problem an deeper net should perform better than a wider one. AveragePooling2D() was used as the first layer to further reduce the image size since it provided better results during training.\n","51ddd3f5":"# **Results**\n\nThe model showed an accuracy of 75% which is an average performance, the model does well on pictures that are obviously hotdogs, but might mistake a salad for a hotdog. more data should improve the accuracy significantly especially more data portraying the edge cases such as images of people eating hotdogs and making hotdogs."}}