{"cell_type":{"c7919036":"code","2d2bdfc2":"code","536fe148":"code","6d1af24e":"code","1c00a08e":"code","3dbe265e":"code","7458e0e5":"code","de1414ca":"code","42aec29e":"code","91f0ab34":"code","ed4250bb":"code","e720edf7":"code","b2ca702e":"code","a816a0ce":"code","b6ee8bf9":"code","b41abbc7":"code","6e03f636":"code","6e2b1f50":"code","34659d19":"code","72957ea6":"code","280223ee":"code","8c053733":"code","af466a96":"code","f56f7ba2":"code","f278fc7b":"code","0550d5b8":"code","abde7d20":"code","e43c51c5":"code","91aa828a":"code","8cb61174":"code","0af09499":"code","dc07f89e":"code","dd5afaa1":"markdown","20f0d830":"markdown","d0349563":"markdown","3d99d48f":"markdown","58cc5978":"markdown","aea2a1bb":"markdown","67e90737":"markdown","f87af7fe":"markdown","a831e977":"markdown","d0b3c679":"markdown","3bf9e477":"markdown","7c7f640c":"markdown","82af52ce":"markdown","2f0a84f6":"markdown","95e0116e":"markdown","c7f12570":"markdown","7f2e9a7a":"markdown","70f1920d":"markdown","f38a2b0f":"markdown","24601448":"markdown","5a8a31b8":"markdown","c4b18fcd":"markdown","b41dbe81":"markdown","880ab2a8":"markdown","4aae6077":"markdown","5769580b":"markdown"},"source":{"c7919036":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2d2bdfc2":"import numpy as np\nimport pandas as pd\npd.options.mode.chained_assignment = None\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA \nfrom sklearn.cluster import KMeans\n\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom category_encoders.count import CountEncoder\n\nimport plotly as py\nimport plotly.graph_objs as go\nfrom plotly import tools\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\n%matplotlib inline ","536fe148":"df = pd.read_csv('..\/input\/chess\/games.csv')\ndf.head()","6d1af24e":"df = df[(df['turns'] > 19)]\ndf = df[['turns','victory_status','winner','increment_code','white_rating','black_rating','moves','opening_eco','opening_name','opening_ply']]","1c00a08e":"# Reducing opening name to two words for grouping ie.\"Sicilian Defense: Alapin Variation\" --> \"Sicilian Defense\"\n\ndf['opening_pref'] = df['opening_name'].apply(lambda x: ' '.join(x.split(' ')[:2]))\ndf['opening_pref'] = df['opening_pref'].apply(lambda x: x[:-1] if str(x).endswith(':') else x)\n\n\n# captures_per_ply measures how aggressively the players exchanged pieces\n\ndf['captures_per_ply']= df['moves'].apply(lambda x: str(x).count('x')) \/ df['turns']\n\n\n# get average rating of two players\n\ndf['rating_avg'] = (df['white_rating'] + df['black_rating']) \/ 2\n\n\n# get lower rating of two players\n\ndef rating_floor(df):\n    return min(df['white_rating'],df['black_rating'])\n    \ndf['rating_floor'] = df.apply(rating_floor, axis=1)\n\n\n# The winner rating difference is calculated by (winner rating - loser rating). If the result is draw, winner_diff is 1\/2 negative value.\n# Larger negative difference means larger upset. \n\ndef upset(df):\n    if df['winner'] == 'white':\n        return df['white_rating'] - df['black_rating']\n    elif df['winner'] == 'black':\n        return df['black_rating'] - df['white_rating']\n    else:\n        return abs(df['black_rating'] - df['white_rating']) * -.5\n    \n\ndf['winner_diff'] = df.apply(upset, axis=1)\n\n        ","3dbe265e":"avg_all = np.mean(df['turns'])\navg_expert= np.mean(df[(df['rating_floor'] >= 2000)]['turns'])\n\nprint('Average game length for all games is:', avg_all)\nprint('Average game length for higher-rated games is:', avg_expert)","7458e0e5":"# Calculate time_control\n\ndef time_control(df):\n    \n    time_control = [int(x) for x in df['increment_code'].split('+')]\n    \n    return time_control[0] + np.floor((time_control[1] * df['turns']\/2) \/ 60)\n   \n\ndf['time_control'] = df.apply(time_control, axis=1)\n","de1414ca":"from matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set_theme()\nsns.displot(df['time_control'])\nplt.xlim(0, 50)","42aec29e":"cluster = df[['turns','opening_eco','opening_pref','opening_ply','captures_per_ply','rating_avg','rating_floor','winner_diff','time_control']]","91f0ab34":"cluster[['opening_eco','opening_pref']].loc[cluster['opening_pref'] == 'Sicilian Defense'].head()","ed4250bb":"cluster[(cluster['opening_eco'] == 'C20')][['opening_eco','opening_pref']].drop_duplicates()","e720edf7":"cluster['opening_pref'].value_counts()[:10]","b2ca702e":"encoder = CountEncoder()\n\ncluster[['op_name','op_eco']] = encoder.fit_transform(cluster[['opening_pref','opening_eco']])","a816a0ce":"cluster.head()","b6ee8bf9":"f, ax = plt.subplots(figsize=(12, 10))\nplt.title('Pearson Correlation of Chess Game Features')\n\nsns.heatmap(cluster[['turns','op_name','op_eco','opening_ply','captures_per_ply','rating_avg','rating_floor','winner_diff','time_control']].corr(), cmap=\"magma\", annot=True)","b41abbc7":"scaler = StandardScaler()\n\nfeatures = ['turns','op_name','op_eco','opening_ply','captures_per_ply','rating_avg','rating_floor','winner_diff','time_control']\nX = scaler.fit_transform(cluster[features])\nX_processed = pd.DataFrame(X, columns = features)","6e03f636":"from yellowbrick.cluster import KElbowVisualizer\n   \nkmeans = KMeans(random_state=0)\n# Compute cluster centers and predict cluster indices\nvisualizer = KElbowVisualizer(kmeans, k=(2,12))\nvisualizer.fit(X_processed)        # Fit the data to the visualizer\nvisualizer.show()","6e2b1f50":"pca = PCA(n_components=3,random_state=0)\npca_df = pd.DataFrame(pca.fit_transform(X_processed), columns = ['p1','p2','p3'])\n   \nkmeans = KMeans(n_clusters=6,random_state=0)\n\n# Compute cluster centers and predict cluster indices\n\nX_clustered = kmeans.fit_predict(pca_df)\n","34659d19":"# Sanity check\n\nnp.unique(X_clustered)","72957ea6":"def plotly_scatter3d(data, feat1, feat2, feat3, color) :\n\n    df = data\n    x = df[feat1]\n    y = df[feat2]\n    z = df[feat3]\n\n    trace1 = go.Scatter3d( x = x, y = y, z = z,\n                           mode='markers',\n                           marker=dict( size=5, color = color,               \n                                        colorscale='Viridis',  \n                                        opacity=0.8 )\n                          )\n    data = [trace1]\n    camera = dict( up=dict(x=0, y=0, z=1),\n                   center=dict(x=0, y=0, z=0.0),\n                   eye=dict(x=2.5, y=0.1, z=0.8) )\n\n    layout = go.Layout( title= feat3 + \" as function of \" +  \n                               feat1 + \" and \" + feat2 ,\n                        autosize=False, width=700, height=600,               \n                        margin=dict( l=15, r=25, b=15, t=30 ) ,\n                        scene=dict(camera=camera,\n                                   xaxis = dict(title=feat1),\n                                   yaxis = dict(title=feat2),\n                                   zaxis = dict(title=feat3),                                   \n                                  ),\n                       )\n\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig)\n\nLABEL_COLOR_MAP = {0 : '#fab3a9', 1 : '#c6ad94', 2 : '#7fb285', 3:'#463239', 4:'#764248', 5:'#ed6b86'} \nlabel_color = [LABEL_COLOR_MAP[l] for l in X_clustered]\n\n\nplotly_scatter3d(pca_df, 'p1', 'p2', 'p3', label_color)\n","280223ee":"print(\"Components = \", pca.n_components_ , \"\\nTotal explained variance = \", round(pca.explained_variance_ratio_.sum(),5)  )","8c053733":"cluster.describe().transpose()","af466a96":"cluster['group'] = X_clustered\ncluster['group'].value_counts()","f56f7ba2":"cluster0 = cluster[cluster['group']==0]\ncluster1 = cluster[cluster['group']==1]\ncluster2 = cluster[cluster['group']==2]\ncluster3 = cluster[cluster['group']==3]\ncluster4 = cluster[cluster['group']==4]\ncluster5 = cluster[cluster['group']==5]","f278fc7b":"cluster0.describe().transpose()","0550d5b8":"cluster1.describe().transpose()","abde7d20":"cluster1['opening_eco'].value_counts()[:5]","e43c51c5":"cluster2.describe().transpose()","91aa828a":"cluster3.describe().transpose()","8cb61174":"cluster3['opening_eco'].value_counts()[:5]","0af09499":"cluster4.describe().transpose()","dc07f89e":"cluster5.describe().transpose()","dd5afaa1":"That being said we should look at each cluster closer. We will describe the game characteristics of each group. Before that, let's first review the statistics of the entire dataset so that we have a frame of reference.","20f0d830":"So far so good. Now we perform PCA and K-Means clustering to view and find groups within our games. We plot 3 principal components.","d0349563":"Looks like scoops of ice-cream. Mint chocolate chip, anyone?\n\nUnfortunately, it looks like our clusters are melted together. This may be due to the fact that 3 principal components do not sufficiently explain the variance in the original feature space.\n","3d99d48f":"Looks like the average game length is a little over 30 moves per side. We can calculate time_control as (increment * moves \/ 60(seconds\/min)).\n\nSo a 5+10 game in which each side makes 30 moves would have a time_control equivalent of a 5 + (10 * 30)\/60 = 10+0 minute game. In practice a 5+10 game plays a little differently than a 10+0 game, but this is a decent approximation.","58cc5978":"Correlations:\n\n* rating_floor\/avg vs opening_ply- as rating increases, so does the tendency to play more book moves\n* rating_floor\/avg vs opening_eco- as rating increases, players explore less popular ECO codes\n* captures_per_ply vs turns- as game length increases, captures become more spread out \n* opening eco is defined by a set series of opening ply","aea2a1bb":"Group 1 had lower ratings, with games moving quickly away from known openings. The op_eco value is very high. Exploring this further, we can see that this group is characterized by unconventional openings.","67e90737":"That's all, thanks for reading! I think it could be interesting to repeat this analysis for just the rated games, which is a feature I did not bring into account. Another cool experiment could be to cluster very high-rated games (2400+) to try and find opening patterns among players that are serious about opening theory.","f87af7fe":"# Chess Games Clustering\n\nThis notebook explores the lichess chess game dataset. There is some light EDA and feature engineering, and then we cluster the games to see if any patterns emerge.\n\nEn Passant will not be a feature this time around.","a831e977":"Group 2 is the underdog group. Winner_diff is negative, meaning lower-rated players are defeating higher-rated players. These games have the longest time_control by far, with games averaging more than 30 minutes each.","d0b3c679":"<img src=\"https:\/\/i.redd.it\/hgjiywrbxyh71.jpg\" width=\"400px\">","3bf9e477":"There are no clear elbows in the chart, but 6 groups seems like a good enough cutoff point. It is very clear that anything more than 7-8 groups is diminishing returns as distortion is not being meaningfully reduced.","7c7f640c":"Let's see if we can find a natural number of groups to which we can assign our games. We will the Yellowbrick elbow visualizer.\n\nhttps:\/\/www.scikit-yb.org\/en\/latest\/api\/cluster\/elbow.html","82af52ce":"And here are some opening names of ECO code C20.","2f0a84f6":"Group 5 has high-rated players similar to group 0. However, the amount of turns per game is larger, and winner-diff is lower. More games are drawn, as draws appear in higher frequency as rating increases.","95e0116e":"More information is here:\n\nhttps:\/\/en.wikipedia.org\/wiki\/Encyclopaedia_of_Chess_Openings","c7f12570":"That wraps up the initial phase. Before we go further, we will scale our features since we use some scale-sensitive tools.","7f2e9a7a":"Opening ECO and the name of an opening are related, since there are so many variations and transpositions, we can keep both fields. For example, here are some ECO codes of the Sicilian Defense:","70f1920d":"Group 3 games also have high ECO averages. Reviewing counts, it looks like many French Defense (C00) and unusual openings (A00).","f38a2b0f":"I keep only relevant features and serious games where the game lasts at least 10 moves. I leave out 'rated' for the purposes of this notebook.","24601448":"Group 4 is the most similar to the general population across the board.","5a8a31b8":"Viewing the time control distribution, we see peaks at 10, 15, 20, and 30 minutes. Most games are blitz or rapid chess.","c4b18fcd":"Group 0 has high rated players. Games remain in the the opening for longer with higher opening_ply, as players may have more knowledge of opening theory. Op_name is higher than the other groups, which shows preference for more popular openings.","b41dbe81":"Let's correlate all our features so far and see if any trends come up.","880ab2a8":"There are familiar faces in the top 10, with the Silician Defense leading the pack. We count encode openings so that more popular choices have larger values. ","4aae6077":"The most represented ECO code here is A00, which corresponds to unknown\/unanalyzed opening moves like 1. g4, a3, h3, etc.\n\nhttps:\/\/www.chessgames.com\/perl\/chessopening?eco=a00","5769580b":"Now let's create a feature for the time control of the game. The existing time control feature is formatted A+B (ie. 3+2) where each player gets A minutes for the entire game and B seconds added to their clock after each move.\n\nThere are different ways to factor in the increment. As the total time added across a game depends on the number of moves both players make, we should review game length."}}