{"cell_type":{"09d68562":"code","7d9feb23":"code","3d33db93":"code","8151be6f":"code","d4543902":"code","3e4bae7d":"code","aa7c12eb":"code","315a6b84":"code","c420a6fa":"code","afd66c69":"code","f9053480":"code","bd0c35ef":"code","6a55dcb3":"code","7f0101de":"code","4483a515":"code","4987d519":"code","12843ee5":"code","3503a972":"code","b58fbe5c":"code","ead8a4a8":"code","b2d0acb6":"code","c0445bbf":"code","53146b0d":"code","7f96f258":"code","16c11d86":"code","8d407b03":"code","cb380c6f":"code","aacffc75":"code","84b39570":"code","4c9108fb":"code","7be49900":"code","1aea5f47":"code","52408e4a":"code","0f1d6976":"code","c6a1cc6f":"code","4428657c":"code","b5bcd966":"code","72b912d6":"code","6651789e":"code","ad17164c":"code","099ce0cd":"code","b43da70d":"code","901674ed":"code","258ed6ca":"code","ff8ce789":"code","ce9a19e2":"code","42d67f33":"code","753285f4":"code","a0079d7f":"code","30555f7c":"code","8e455982":"code","10ab468d":"code","1ed493ec":"code","10d8188e":"code","1181e817":"code","e731f4a1":"code","b19d4a5e":"code","0f5513ee":"code","d63d114c":"code","b47e3825":"code","a6a4dfb0":"code","9f89f1b0":"code","bd3696de":"code","fcfb09af":"code","bcb95682":"code","7e147048":"code","c0cbb782":"code","1fc1f578":"code","8ddfcbf4":"code","26363bd6":"code","430196c4":"code","0e78a75b":"code","5ccb1c28":"code","79fc311b":"markdown","d0299e6c":"markdown","752f0c78":"markdown","c011389b":"markdown","349396b7":"markdown","ee5f7f3e":"markdown","602bd37b":"markdown","edbcc5f3":"markdown","b9af45b1":"markdown"},"source":{"09d68562":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7d9feb23":"test = pd.read_csv(\"..\/input\/zimnat-insurance-recommendation-challenge\/Test.csv\")\nsubmission = pd.read_csv(\"..\/input\/zimnat-insurance-recommendation-challenge\/SampleSubmission.csv\")\ntrain = pd.read_csv(\"..\/input\/zimnat-insurance-recommendation-challenge\/Train.csv\")","3d33db93":"train","8151be6f":"set(train.columns) - set(test.columns)","d4543902":"test","3e4bae7d":"dataset = pd.concat([train,test]).reset_index()\ndataset","aa7c12eb":"dataset['join_date'] = pd.to_datetime(dataset['join_date'], format='%d\/%m\/%Y').dt.year\ndataset['age'] = dataset['join_date'] - dataset['birth_year']\ndataset","315a6b84":"dataset_final = dataset[['age','sex','marital_status','branch_code','occupation_code','occupation_category_code']]\ndataset_final","c420a6fa":"dataset_final['sex'].value_counts()","afd66c69":"dataset_final['marital_status'].value_counts()","f9053480":"dataset_final['branch_code'].value_counts()","bd0c35ef":"dataset_final['occupation_category_code'].value_counts()","6a55dcb3":"train['occupation_code'].value_counts()","7f0101de":"len(train['occupation_code'].value_counts())","4483a515":"cutoff = 100\ndf_col = dataset_final['occupation_code'].value_counts()[dataset_final['occupation_code'].value_counts() > cutoff]\ndf_col","4987d519":"len(df_col.index),df_col.index","12843ee5":"dict_map = {value:key+1 for key,value in enumerate(df_col.index)}\ndict_map['etc'] = 37 \ndict_map","3503a972":"df_error = dataset_final['occupation_code'].value_counts()[dataset_final['occupation_code'].value_counts() <= cutoff]\ndf_error","b58fbe5c":"dataset_final","ead8a4a8":"# occupation_code : cutoff below 100, rename as etc","b2d0acb6":"df_error.index","c0445bbf":"for value in df_error.index:\n    dataset_final.loc[dataset_final['occupation_code'] == value,'occupation_code'] = 'etc'","53146b0d":"dataset_final['occupation_code'] = dataset_final['occupation_code'].map(dict_map)\ndataset_final","7f96f258":"from sklearn.preprocessing import LabelEncoder\ndataset_final['sex'] = LabelEncoder().fit_transform(dataset_final['sex'])\ndataset_final['marital_status'] = LabelEncoder().fit_transform(dataset_final['marital_status'])\ndataset_final['branch_code'] = LabelEncoder().fit_transform(dataset_final['branch_code'])\ndataset_final['occupation_category_code'] = LabelEncoder().fit_transform(dataset_final['occupation_category_code'])\ndataset_final","16c11d86":"dataset.columns","8d407b03":"dataset","cb380c6f":"dataset_final.iloc[:len(train)*8\/\/10]","aacffc75":"def prediction_column(columns):\n    x_train = dataset_final.iloc[:len(train)*8\/\/10]\n    x_val = dataset_final.iloc[len(train)*8\/\/10:len(train)]\n    x_test = dataset_final.iloc[len(train):]\n\n    y_train = dataset[columns].iloc[:len(train)*8\/\/10]\n    y_val = dataset[columns].iloc[len(train)*8\/\/10:len(train)]\n    \n    import time\n    import xgboost as xgb\n    ts = time.time()\n\n    model = xgb.XGBClassifier(\n        max_depth=10,\n        n_estimators=1000,\n        min_child_weight=0.5, \n        colsample_bytree=0.8, \n        subsample=0.8, \n        eta=0.1,\n    #     tree_method='gpu_hist',\n        seed=42)\n\n    model.fit(\n        x_train, \n        y_train, \n        eval_metric=\"rmse\", \n        eval_set=[(x_train, y_train), (x_val, y_val)], \n        verbose=True, \n        early_stopping_rounds = 20)\n\n    print(time.time() - ts)\n\n    Y_test_class = model.predict(x_test)\n    \n    df = pd.DataFrame(data=Y_test_class, columns=[\"column1\"])\n    df['column1'].value_counts().sort_values().plot(kind = 'barh')\n    \n    return Y_test_class","84b39570":"dataset.columns","4c9108fb":"Y1 = prediction_column('RIBP')","7be49900":"x_train = dataset_final.iloc[:len(train)*8\/\/10]\nx_val = dataset_final.iloc[len(train)*8\/\/10:len(train)]\nx_test = dataset_final.iloc[len(train):]\n\ny_train = dataset['P5DA'].iloc[:len(train)*8\/\/10]\ny_val = dataset['P5DA'].iloc[len(train)*8\/\/10:len(train)]\n\nimport time\nimport xgboost as xgb\nts = time.time()\n\nmodel = xgb.XGBClassifier(\n    max_depth=10,\n    n_estimators=1000,\n    min_child_weight=0.5, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,\n#     tree_method='gpu_hist',\n    seed=42)\n\nmodel.fit(\n    x_train, \n    y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(x_train, y_train), (x_val, y_val)], \n    verbose=True, \n    early_stopping_rounds = 20)\n\nprint(time.time() - ts)\n\nY_test_class = model.predict(x_test)\nY_test_class","1aea5f47":"df = pd.DataFrame(data=Y_test_class, columns=[\"column1\"])\ndf['column1'].value_counts().sort_values().plot(kind = 'barh')","52408e4a":"test","0f1d6976":"Y1 = prediction_column('RIBP')","c6a1cc6f":"submission_draft = pd.DataFrame()\nsubmission_draft['index'] = test['ID']\nsubmission_draft['P5DA'] = Y_test_class\nsubmission_draft['RIBP'] = Y1\nfor column in dataset.columns[-20:-1]:\n    submission_draft[column] = prediction_column(column)\nsubmission_draft","4428657c":"submission_draft","b5bcd966":"submission_draft.index = submission_draft['index']\nsubmission_draft = submission_draft.drop(['index'],axis=1)\nsubmission_draft","72b912d6":"submission_draft","6651789e":"output = []\nfor i in range(len(submission_draft)):\n    output += list(submission_draft.iloc[0].values)\noutput","ad17164c":"submission_sample = submission.copy()\nsubmission_sample['Label'] = output\nsubmission_sample","099ce0cd":"submission_sample.to_csv('submission_XGBClassifier.csv',index=False)","b43da70d":"submission_sample['Label'].value_counts().sort_values().plot(kind = 'barh')","901674ed":"submission","258ed6ca":"dict_map","ff8ce789":"for key in dict_map:\n    print(key, dict_map[key])","ce9a19e2":"dataset_final['occupation_code'].value_counts()","42d67f33":"len(dataset_final['occupation_code'].value_counts().index),dataset_final['occupation_code'].value_counts().index","753285f4":"dict_map","a0079d7f":"list(dict_map.values())","30555f7c":"dict_map.values()","8e455982":"dict_map","10ab468d":"df_error.index","1ed493ec":"len(df_error), sum(df_error.values)","10d8188e":"df_col.plot(kind = 'barh')","1181e817":"df_col","e731f4a1":"df_error","b19d4a5e":"df_error.sort_values().plot(kind = 'barh')","0f5513ee":"train['occupation_code'].value_counts()[train['occupation_code'].value_counts() == 5].value_counts().sort_values().plot(kind = 'barh')","d63d114c":"df_error.plot(kind = 'barh')","b47e3825":"df_error.value_counts().sort_values().plot(kind = 'barh')","a6a4dfb0":"df_error.value_counts().sort_values().plot(kind = 'barh')","9f89f1b0":"df_error.value_counts().values","bd3696de":"sum(np.array(df_error.value_counts().index)*np.array(df_error.value_counts().values))","fcfb09af":"df_error.value_counts()","bcb95682":"df_col.plot(kind = 'barh')","7e147048":"df_col.value_counts().plot(kind = 'barh')","c0cbb782":"df_col.value_counts().sort_values().plot(kind = 'barh')","1fc1f578":"df_col.value_counts()","8ddfcbf4":"test.columns","26363bd6":"test.columns[:8]","430196c4":"test.columns[8:]","0e78a75b":"len(test.columns[8:])","5ccb1c28":"submission","79fc311b":"def object_type_detection(data,detail=False):\n    data_object_columns = data.dtypes[data.dtypes == object].index.values\n    for columns in data_object_columns:\n        if detail:\n            print(columns)\n            print(data[columns].value_counts())\n            print()\n    return data_object_columns","d0299e6c":"dataset_final[dataset_final['occupation_code'] == 'Q57T']","752f0c78":"test.columns","c011389b":"spam","349396b7":"object_type_detection(train)","ee5f7f3e":"dataset_final['occupation_code'].replace(to_replace = list(df_error.index), value = 'etc')\ndataset_final['occupation_code']","602bd37b":"test['join_date'] = pd.to_datetime(test['join_date'])\ntest","edbcc5f3":"def non_object_type_detection(data):\n    data_non_object_columns = data.dtypes[data.dtypes != object].index.values\n    for columns in data_non_object_columns:\n        print(columns)\n        print(data[columns].value_counts())\n        print()","b9af45b1":"object_type_detection(train,detail=True)"}}