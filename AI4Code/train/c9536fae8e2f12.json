{"cell_type":{"78560d36":"code","80989d7d":"code","60109854":"code","cead0898":"code","04687acf":"code","8cb72728":"code","e681dd63":"code","02b40d9d":"code","a29d8e1d":"code","efdea08e":"code","0015dd37":"code","52ff9e50":"code","435126ae":"code","681a12c3":"code","bce97180":"code","758c17fd":"code","cb210a6d":"code","eab1dbbf":"code","186ca909":"code","31849830":"code","ad9acc17":"code","742e4176":"code","f35de606":"code","044c01d7":"code","02a500f1":"code","61fcf1af":"code","5e7cb12d":"code","c3ef6551":"code","bab988a5":"code","2dd14c0a":"code","0568f880":"code","6792de32":"code","51227e97":"code","ad05e00d":"code","7bfcf52b":"code","94d592ab":"code","c1285aef":"code","3be4409a":"code","512362cf":"code","aead8626":"code","18453efb":"code","4dc299f5":"code","bf82b79a":"code","c0f11ae4":"code","930fef5b":"code","82718102":"code","6d5a66d0":"code","eb156a53":"code","4fc28586":"code","7ff45970":"code","acf0d7b6":"code","8712c228":"code","63bc8f70":"code","1a094455":"code","96276a06":"code","d8c93511":"code","eb89af58":"code","68e6f426":"code","c35e232c":"code","5018b28e":"code","000416fb":"code","7693356b":"code","1cce9e8d":"code","3f99d6c3":"code","efa6cd12":"code","0fe8d9c4":"code","1cad03cd":"code","74970745":"code","fc803d6b":"code","cf99a079":"code","b9bc76d4":"code","077fd47e":"code","be43e01a":"code","22115de7":"code","f585531b":"code","ee592a70":"code","e71d9bb2":"code","25a871db":"code","297af651":"code","34fcc916":"code","8c2a8277":"code","f74cc081":"code","98572ed5":"code","b3086137":"code","50986412":"code","d4c7eddf":"code","4f278155":"code","0cee63fd":"code","0bb0184d":"code","dc14fc0c":"code","e05ca34a":"code","de363e23":"code","846ef455":"code","d9f8747f":"code","25d94a2b":"code","47140637":"code","31528a4a":"code","bb769ae9":"code","a654d17e":"code","49408a6e":"code","b83ad284":"code","d59d635c":"code","c5579551":"code","ba04e232":"code","b8967ae2":"code","209d82fb":"code","d68a654f":"code","92e18364":"code","194b0cfc":"code","41054ffd":"code","89031603":"code","ce10581a":"code","0c002b68":"code","5bf4a685":"code","1eca5094":"code","6c32935b":"markdown","070367c5":"markdown","003be51b":"markdown","233438d2":"markdown","9dbac99b":"markdown","355087d0":"markdown","580d86a5":"markdown","201b54b7":"markdown","7076c5fd":"markdown","03fa9040":"markdown","a3abd916":"markdown","f534560d":"markdown","88e17356":"markdown","11530b52":"markdown","5b02e810":"markdown","084b3d46":"markdown","6f86b5b5":"markdown","8cb36f1f":"markdown","d0838c7b":"markdown","c7d24228":"markdown","c16fcadb":"markdown","343ed3a1":"markdown","f9fe57f8":"markdown","a0c90565":"markdown","c6ff9dd7":"markdown","4f31d892":"markdown","0cfea10d":"markdown","05325cf6":"markdown"},"source":{"78560d36":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualization imports\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\n# Modeling imports\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV, StratifiedKFold, cross_val_score, cross_val_predict\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import f1_score, roc_auc_score,log_loss, confusion_matrix, precision_score, recall_score, accuracy_score \nfrom sklearn import linear_model, ensemble , tree \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier , VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport imblearn.over_sampling\nfrom sklearn.svm import SVC  \nfrom sklearn.utils import class_weight\nimport statsmodels.api as sm\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.pipeline import Pipeline as imbpipeline, make_pipeline \nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom mlxtend.classifier import StackingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegressionCV\nimport sklearn.metrics as metrics","80989d7d":"df = pd.read_csv('..\/input\/my-dataset\/credit_train.csv')\ndf","60109854":"df.shape","cead0898":"df.tail()","04687acf":"df.isna().sum()","8cb72728":"df.info() ","e681dd63":"duplicate = df.duplicated()\nprint(f'Duplicate in df :', duplicate.sum())","02b40d9d":"df.columns","a29d8e1d":"df.columns = df.columns.str.replace(' ','_')","efdea08e":"df.columns","0015dd37":"# cross val\ndf_train, df_test  = train_test_split(df, test_size=0.2, random_state=42)","52ff9e50":"print(f'Shape of train:', df_train.shape)\nprint(f'Shape of test:', df_test.shape)","435126ae":"# reset index for train\ndf_train = df_train.reset_index(drop=True)\n\n# reset index for val\ndf_test = df_test.reset_index(drop=True)","681a12c3":"# dope nulls in Loan_ID\n\n# for train\ndf_train = df_train.dropna(subset = ['Loan_ID'])\n\n# for test\ndf_test = df_test.dropna(subset = ['Loan_ID'])","bce97180":"print(f'Shape of train:', df_train.shape)\nprint(f'Shape of test:', df_test.shape)","758c17fd":"df_train.sample(20)","cb210a6d":"df_train.info()","eab1dbbf":"df_train.isna().sum()","186ca909":"# check for dublicate\n\n# for train\nduplicate = df_train.duplicated()\nprint(f'Duplicate in train :', duplicate.sum())\n\n# for test\nduplicate = df_test.duplicated()\nprint(f'Duplicate in test :', duplicate.sum())\nprint(f'Shape of train:', df_train.shape)\nprint(f'Shape of test:', df_test.shape)","31849830":"# drop duplicates rows\n# train\ndf_train.drop_duplicates(inplace=True)\n\n# test\ndf_test.drop_duplicates(inplace=True)","ad9acc17":"# check for dublicate\n\n# for train\nduplicate = df_train.duplicated()\nprint(f'Duplicate in train :', duplicate.sum())\n\n# for test\nduplicate = df_test.duplicated()\nprint(f'Duplicate in test :', duplicate.sum())\nprint(f'Shape of train:', df_train.shape)\nprint(f'Shape of test:', df_test.shape)","742e4176":"df_train['Loan_ID'].value_counts().sort_values(ascending=False)","f35de606":"df_train[df_train.Loan_ID.duplicated()]","044c01d7":"df_train[df_train['Loan_ID'] == '7830a00a-20c4-4480-9cf0-fe2f86b5266b']","02a500f1":"df_train[df_train['Loan_ID'] == '5a90cbe3-8fee-4582-8823-1f31546dec6e']","61fcf1af":"df_train[(df_train.Loan_ID.duplicated() & (df_train['Current_Loan_Amount'] == 99999999.0))]","5e7cb12d":"# drop duplicate in Loan_ID and Current_Loan_Amount = 99999999.0\n\n# for train\ndf_train = df_train[~(df_train.Loan_ID.duplicated() & (df_train['Current_Loan_Amount'] == 99999999.0))]\n\n# for test\ndf_test = df_test[~(df_test.Loan_ID.duplicated() & (df_test['Current_Loan_Amount'] == 99999999.0))]","c3ef6551":"df_train[(df_train.Loan_ID.duplicated())]","bab988a5":"df_train[df_train['Loan_ID'] == 'ff486b10-f97d-4dff-bb98-436ef48d8ab1']","2dd14c0a":"# dope nulls in Loan_Status\n\n# for train\ndf_train = df_train.dropna(subset = ['Annual_Income'])\n\n# for test\ndf_test = df_test.dropna(subset = ['Annual_Income'])","0568f880":"df_train[df_train['Loan_ID'] == 'ff486b10-f97d-4dff-bb98-436ef48d8ab1']","6792de32":"#df_train\ndf_train.Purpose.unique()\n\n#da_test\ndf_test.Purpose.unique()","51227e97":"df_train.Purpose.value_counts()","ad05e00d":"#df_train\ndf_train.Purpose = df_train.Purpose.str.replace('other','Other')\n\n#df_test\ndf_test.Purpose = df_test.Purpose.str.replace('other','Other')","7bfcf52b":"df_train.Purpose.value_counts()","94d592ab":"df_train.Purpose.unique()","c1285aef":"df_train.isnull().sum() # train","3be4409a":"# dope duplicated in Loan_ID\n\n# for train\ndf_train = df_train.drop_duplicates(subset = ['Loan_ID'])\n\n# for test\ndf_test = df_test.drop_duplicates(subset = ['Loan_ID'])","512362cf":"df_train.isnull().sum() # train","aead8626":"print(f'Shape of train:', df_train.shape)\nprint(f'Shape of test:', df_test.shape)","18453efb":"plt.figure(figsize=(10,5))\nsns.countplot(df_train['Years_in_current_job'], palette='pink_r');","4dc299f5":"# fill nulls in Years_in_current_job \n\n# for train\ndf_train['Years_in_current_job'] = df_train['Years_in_current_job'].fillna('10+ years')\n\n# for test\ndf_test['Years_in_current_job'] = df_test['Years_in_current_job'].fillna('10+ years')","bf82b79a":"# drop Months_since_last_delinquent bc the null > 50&\n\n# train\ndf_train = df_train.drop(columns='Months_since_last_delinquent')\n\n# test\ndf_test = df_test.drop(columns='Months_since_last_delinquent')","c0f11ae4":"df_train.isnull().sum()","930fef5b":"# drop nulls \n\n# for train\ndf_train = df_train.dropna()\n\n# for test\ndf_test = df_test.dropna()","82718102":"df_train.isnull().sum()","6d5a66d0":"df_train.duplicated().sum()","eb156a53":"df_train.isnull().sum()","4fc28586":"df_train.info()","7ff45970":"# train\nbank_lone_train = pd.get_dummies(df_train, columns =['Term','Home_Ownership','Purpose','Loan_Status', 'Years_in_current_job'], drop_first=True) ###\n\n# test\nbank_lone_test = pd.get_dummies(df_test, columns =['Term','Home_Ownership','Purpose','Loan_Status' , 'Years_in_current_job'], drop_first=True) ###","acf0d7b6":"bank_lone_train.columns","8712c228":"df_train.corr()","63bc8f70":"plt.figure(figsize=(10,8))\n\n# corr\ndata_corr = df_train.corr()\n\n# mask\nmask = np.triu(np.ones_like(data_corr, dtype=np.bool))\n\n# adjust mask and df\nmask = mask[1:, :-1]\ncorr = data_corr.iloc[1:,:-1].copy()\n\nsns.heatmap(corr, cmap = 'pink_r', annot = True, vmin= -1, vmax= 1, linewidths=1.5, fmt='.2f', mask=mask);\nplt.title('CORRELATION BETWEEN FEATURES\\n', loc='left', fontsize=18);\n# plt.savefig('plot13.png', dpi = 300, bbox_inches = 'tight');","1a094455":"c = ['#724949','#cfa691', '#120f0f', '#a06868']\nplt.figure(figsize=(7,7))\nplt.pie(x = bank_lone_train['Term_Short Term'].value_counts(),\n        labels=['Short term','Long term'],autopct='%.2f%%',\n        textprops={'fontsize': 12},explode=[0,0.09], colors = ['#724949','#DEDCBB'])\nplt.title('Time Period of Taking Loan',fontdict={'fontsize':15});","96276a06":"plt.figure(figsize=(8,6))\nsns.countplot(y='Purpose' , data=df_train, order = df_train['Purpose'].value_counts().index,\n              hue='Term', palette = 'pink_r')\nplt.title('Purpose of taking Loan' , fontdict={'fontsize':20})\nplt.legend(title=\"Loan type\", loc=\"lower right\");","d8c93511":"plt.figure(figsize=(8,6))\nsns.countplot(x='Home_Ownership',data=df_train ,order = df_train['Home_Ownership'].value_counts().index\n              ,hue='Term',  palette = 'pink_r')\nplt.title('Own Property vs Loan Status',fontdict={'fontsize':20})\nplt.legend(title=\"Loan type\", loc=\"upper right\", labels=[\"Short Term\",\"Long Term\"]);","eb89af58":"plt.figure(figsize = [10,15])\nplt.subplot(3,2,1)\nsns.boxplot(x='Term_Short Term',y='Current_Loan_Amount',\n            palette='pink_r', data=bank_lone_train.sort_values('Current_Loan_Amount',ascending=False));\nplt.title('Before dropping outliers',fontsize = 15 )\n\nbank_lone_train = bank_lone_train[bank_lone_train['Current_Loan_Amount'] != 99999999]\nbank_lone_train = bank_lone_train[((bank_lone_train['Current_Loan_Amount'] <= 600000 )\n                                   & (bank_lone_train['Term_Short Term']==1))\n                                  | (bank_lone_train['Term_Short Term']==0)]\n\nplt.subplot(3,2,2)\nsns.boxplot(x='Term_Short Term',y='Current_Loan_Amount',\n            palette='pink_r', data=bank_lone_train.sort_values('Current_Loan_Amount',ascending=False));\nplt.title('After dropping outliers',fontsize = 15 );","68e6f426":"bank_lone_test = bank_lone_test[bank_lone_test['Current_Loan_Amount'] != 99999999]\nbank_lone_test = bank_lone_test[((bank_lone_test['Current_Loan_Amount'] <= 600000 )\n                                   & (bank_lone_test['Term_Short Term']==1))\n                                  | (bank_lone_test['Term_Short Term']==0)]","c35e232c":"plt.figure(figsize = [10,15])\nplt.subplot(3,2,1)\nsns.boxplot(x='Term_Short Term',y='Credit_Score',\n            palette='pink_r', data = bank_lone_train.sort_values('Credit_Score',ascending=False));\nplt.title('Before dropping outliers',fontsize = 15 )\n\nbank_lone_train = bank_lone_train.loc[bank_lone_train['Credit_Score'] <= 1500,:]\nbank_lone_train = bank_lone_train.loc[bank_lone_train['Credit_Score'] >= 620 ,:]\nbank_lone_train = bank_lone_train[((bank_lone_train['Credit_Score'] >= 680 )\n                                   & (bank_lone_train['Term_Short Term']==1))| \n                                  (bank_lone_train['Term_Short Term']==0)]\n\nplt.subplot(3,2,2)\nsns.boxplot(x='Term_Short Term',y='Credit_Score',\n            palette='pink_r', data = bank_lone_train.sort_values('Credit_Score',ascending=False));\nplt.title('After dropping outliers',fontsize = 15 );","5018b28e":"bank_lone_test = bank_lone_test.loc[bank_lone_test['Credit_Score'] <= 1500,:]\nbank_lone_test = bank_lone_test.loc[bank_lone_test['Credit_Score'] >= 620 ,:]\nbank_lone_test = bank_lone_test[((bank_lone_test['Credit_Score'] >= 680 )\n                                   & (bank_lone_test['Term_Short Term']==1))| \n                                  (bank_lone_test['Term_Short Term']==0)]","000416fb":"plt.figure(figsize = [10,15])\nplt.subplot(3,2,1)\nsns.boxplot(x='Term_Short Term',y='Annual_Income',\n            palette='pink_r', data = bank_lone_train.sort_values('Annual_Income',ascending=False));\nplt.title('Before dropping outliers',fontsize = 15 )\n\nbank_lone_train = bank_lone_train.loc[bank_lone_train['Annual_Income'] <= 2750000,:]\nbank_lone_train = bank_lone_train[((bank_lone_train['Annual_Income'] <= 2395000 )\n                                   & (bank_lone_train['Term_Short Term']==1))\n                                  | (bank_lone_train['Term_Short Term']==0)]\n\nplt.subplot(3,2,2)\nsns.boxplot(x='Term_Short Term',y='Annual_Income',\n            palette='pink_r', data = bank_lone_train.sort_values('Annual_Income',ascending=False));\nplt.title('After dropping outliers',fontsize = 15 );","7693356b":"bank_lone_test = bank_lone_test.loc[bank_lone_test['Annual_Income'] <= 2750000,:]\nbank_lone_test = bank_lone_test[((bank_lone_test['Annual_Income'] <= 2395000 )\n                                   & (bank_lone_test['Term_Short Term']==1))\n                                  | (bank_lone_test['Term_Short Term']==0)]","1cce9e8d":"plt.figure(figsize = [10,15])\nplt.subplot(3,2,1)\nsns.boxplot(x='Term_Short Term',y='Monthly_Debt',\n            palette='pink_r', data=bank_lone_train.sort_values('Monthly_Debt',ascending=False));\nplt.title('Before dropping outliers',fontsize = 15)\n\nbank_lone_train = bank_lone_train.loc[bank_lone_train['Monthly_Debt'] <= 44500,:]\nbank_lone_train = bank_lone_train[((bank_lone_train['Monthly_Debt'] <= 36000 )& (bank_lone_train['Term_Short Term']==1))| \n                                  (bank_lone_train['Term_Short Term']==0)]\n\nplt.subplot(3,2,2)\nsns.boxplot(x='Term_Short Term',y='Monthly_Debt',\n            palette='pink_r', data=bank_lone_train.sort_values('Monthly_Debt',ascending=False));\nplt.title('After dropping outliers',fontsize = 15 );","3f99d6c3":"bank_lone_test = bank_lone_test.loc[bank_lone_test['Monthly_Debt'] <= 44500,:]\nbank_lone_test = bank_lone_test[((bank_lone_test['Monthly_Debt'] <= 36000 )& \n                                   (bank_lone_test['Term_Short Term']==1))| \n                                  (bank_lone_test['Term_Short Term']==0)]","efa6cd12":"plt.figure(figsize = [10,15])\nplt.subplot(3,2,1)\nsns.boxplot(x='Term_Short Term',y='Current_Credit_Balance',\n            palette='pink_r', data=bank_lone_train.sort_values('Current_Credit_Balance',ascending=False));\nplt.title('Before dropping outliers',fontsize = 15 )\n\nbank_lone_train = bank_lone_train.loc[bank_lone_train['Current_Credit_Balance'] <= 760000,:]\nbank_lone_train = bank_lone_train[((bank_lone_train['Current_Credit_Balance'] <= 504000 )& \n                                   (bank_lone_train['Term_Short Term']==1))| (bank_lone_train['Term_Short Term']==0)]\n\nplt.subplot(3,2,2)\nsns.boxplot(x='Term_Short Term',y='Current_Credit_Balance',\n            palette='pink_r', data=bank_lone_train.sort_values('Current_Credit_Balance',ascending=False));\nplt.title('After dropping outliers',fontsize = 15 );","0fe8d9c4":"bank_lone_test = bank_lone_test.loc[bank_lone_test['Current_Credit_Balance'] <= 760000,:]\nbank_lone_test = bank_lone_test[((bank_lone_test['Current_Credit_Balance'] <= 504000 )& \n                                   (bank_lone_test['Term_Short Term']==1))| \n                                  (bank_lone_test['Term_Short Term']==0)]","1cad03cd":"plt.figure(figsize = [10,15])\nplt.subplot(3,2,1)\nsns.boxplot(x='Term_Short Term',y='Maximum_Open_Credit',\n            palette='pink_r', data=bank_lone_train.sort_values('Maximum_Open_Credit',ascending=False));\nplt.title('Before dropping outliers',fontsize = 15)\n\nbank_lone_train = bank_lone_train.loc[bank_lone_train['Maximum_Open_Credit'] <= 1400000,:]\nbank_lone_train = bank_lone_train[((bank_lone_train['Maximum_Open_Credit'] <= 990000 )& \n                                   (bank_lone_train['Term_Short Term']==1))| (bank_lone_train['Term_Short Term']==0)]\nplt.subplot(3,2,2)\nsns.boxplot(x='Term_Short Term',y='Maximum_Open_Credit',\n            palette='pink_r', data=bank_lone_train.sort_values('Maximum_Open_Credit',ascending=False));\nplt.title('After dropping outliers',fontsize = 15 );","74970745":"bank_lone_test = bank_lone_test.loc[bank_lone_test['Maximum_Open_Credit'] <= 1400000,:]\nbank_lone_test = bank_lone_test[((bank_lone_test['Maximum_Open_Credit'] <= 990000 )& \n                                   (bank_lone_test['Term_Short Term']==1))| \n                                  (bank_lone_test['Term_Short Term']==0)]","fc803d6b":"plt.figure(figsize=(5, 8))\nheatmap = sns.heatmap(bank_lone_train.corr()[\n    ['Term_Short Term']].sort_values(by='Term_Short Term',ascending=False),\n                      vmin=-1, vmax=1, annot=True,\n                      cmap = 'pink_r')\nplt.title('CORRELATION BETWEEN FEATURES AND TARGET AFTER ONE HOT CODING\\n', loc='center', fontsize=18);","cf99a079":"X_train = bank_lone_train[['Current_Loan_Amount','Annual_Income','Monthly_Debt',\n                          'Current_Credit_Balance', 'Tax_Liens', \n                          'Home_Ownership_Home Mortgage', 'Loan_Status_Fully Paid',\n                          'Purpose_Buy House', 'Years_in_current_job_10+ years']]\ny_train = bank_lone_train['Term_Short Term']\nX_test = bank_lone_test[['Current_Loan_Amount','Annual_Income','Monthly_Debt',\n                          'Current_Credit_Balance', 'Tax_Liens',\n                          'Home_Ownership_Home Mortgage', 'Loan_Status_Fully Paid',\n                          'Purpose_Buy House', 'Years_in_current_job_10+ years']]\ny_test = bank_lone_test['Term_Short Term']","b9bc76d4":"model = sm.OLS(y_train,X_train)\nfit = model.fit()\nfit.summary()","077fd47e":"y_train.value_counts()","be43e01a":"# Separate class\nlong_term_0 = bank_lone_train[bank_lone_train['Term_Short Term'] == 0]\nshort_term_1 = bank_lone_train[bank_lone_train['Term_Short Term'] == 1]# print the shape of the class\nprint('Long term 0:', long_term_0.shape[0])\nprint('Short term 1:', short_term_1.shape[0])","22115de7":"# gridsearch\nparams = {'C': [0.001,0.01,0.1,1,10,100,1000], 'class_weight':[{0:0,0:0.01,0:0.1,0:0.5,0:1,0:10,0:2} ] }\nlr_grid = GridSearchCV(LogisticRegression(), param_grid = params, scoring='f1', cv = 5)\nlr_grid.fit(X_train, y_train)\nprint('\\n Best param after grid search: ', lr_grid.best_params_ )\nprint(' Best f1_score for cross validation: ',lr_grid.best_score_ )\n\n# normal\nLR = LogisticRegression(C= 0.001 ,solver='liblinear')\nkf = KFold(n_splits=10, random_state=42, shuffle=True)\ncr_f1 = cross_val_score(LR, X_train, y_train, scoring='f1', cv=kf)\nprint('\\n Normal Logistic Regression Valdition F1: \\n',cr_f1)\nprint('\\n Mean Normal Logistic Regression Valdition F1: \\n',cr_f1.mean())\nprint('--------------------------------')\n\n# balenced\nlr_balanced = LogisticRegression(class_weight='balanced', solver='liblinear')\ncr_balnced_f1 = cross_val_score(lr_balanced, X_train, y_train, scoring='f1', cv=kf)\nprint('\\n Balanced class weights Logistic Regression Valdition F1: \\n',cr_balnced_f1)\nprint('\\n Mean Balanced class weights Logistic Regression Valdition F1: \\n',cr_balnced_f1.mean())\nprint('--------------------------------')\n\n# weighted\nlr_4x = LogisticRegression(C= 0.001, class_weight={0 : 2, 1 : 1}, solver='liblinear')\ncr_weghts_f1 = cross_val_score(lr_4x, X_train, y_train, scoring='f1', cv=kf)\nprint('\\n Class weights Logistic Regression Valdition F1: \\n',cr_weghts_f1)\nprint('\\n Mean Class weights Logistic Regression Valdition F1: \\n',cr_weghts_f1.mean())\nprint('--------------------------------')\n\n# smote\nimba_pipeline = make_pipeline(SMOTE(random_state=42), \n                              LogisticRegression(C= 0.001, solver='liblinear'))\n\nimba_val = cross_val_score(imba_pipeline, X_train, y_train, scoring='f1', cv=kf)\nprint('\\n Smote Logistic Regression Valdition F1: \\n', imba_val)\nprint('\\n Mean Smote Logistic Regression Valdition F1: \\n', imba_val.mean())","f585531b":"LR.fit(X_train, y_train)\nprecision_curve, recall_curve, threshold_curve = precision_recall_curve(y_train, LR.predict_proba(X_train)[:,1] )\nplt.plot(threshold_curve, precision_curve[1:],label='precision', color = '#724949')\nplt.plot(threshold_curve, recall_curve[1:], label='recall', color = '#DEDCBB')\nplt.legend(loc='lower left')\nplt.xlabel('Threshold (above this probability)');\nplt.title('Precision and Recall Curves');","ee592a70":"y_predict = (LR.predict_proba(X_train)[:, 1] >= 0.65)\n\nprint(\"Default threshold:\")\nprint(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n                                                     recall_score(y_train, y_predict)))","e71d9bb2":"y_predict = (LR.predict_proba(X_train)[:, 1] >= 0.624)\n\nloan_confusion = confusion_matrix(y_train, y_predict)\n\nsns.heatmap(loan_confusion , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Train Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","25a871db":"# confusion matrix for crossval\ny_pred = cross_val_predict(LR, X = X_train, y = y_train, cv=5)\nconf_mat = confusion_matrix(y_train, y_pred)\nsns.heatmap(conf_mat , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Cross Validation Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","297af651":"knn = KNeighborsClassifier(n_neighbors= 9)\nk_range = list(range(3,11))\nparam_grd = dict(n_neighbors=k_range)\ngrid = GridSearchCV(KNeighborsClassifier(), param_grd, scoring='f1', cv = 5)\ngrid.fit(X_train, y_train)\nprint('Best estimator: ', grid.best_estimator_ )\nprint('Best f1_score for cross validation: ',grid.best_score_ )","34fcc916":"y_predict = (grid.predict_proba(X_train)[:, 1] >= 0.624)\n\nloan_confusion = confusion_matrix(y_train, y_predict)\n\nsns.heatmap(loan_confusion , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Train Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","8c2a8277":"# normal\nDecision_Tree = DecisionTreeClassifier(max_depth = 8)\nDecision_Tree.fit(X_train, y_train)\nscores = cross_val_score(Decision_Tree, X_train, y_train, cv=5, scoring='f1')\nprint('Normal Decision Tree Valdition F1:',scores.mean())\n\n\n# balenced\ndt_bal = DecisionTreeClassifier(max_depth = 8, class_weight='balanced')\ndt_bal.fit(X_train, y_train)\nscores = cross_val_score(dt_bal, X_train, y_train, cv=5, scoring='f1')\nprint('Balanced class weights Decision Tree Valdition F1:',scores.mean())\n\n\n# weighted\ndt_wtd = DecisionTreeClassifier(class_weight= {0 : 10, 1 : 1})\nscores = cross_val_score(dt_wtd, X_train, y_train, cv=5, scoring='f1')\ndt_wtd.fit(X_train, y_train)\nprint('10:1 class weights Decision Tree Valdition F1:',scores.mean())\n\n#gridsearch\n\ntree_param = {'criterion':['gini','entropy'],\n              'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n\ngd_sr = GridSearchCV(DecisionTreeClassifier(), param_grid=tree_param,scoring='f1',cv=5,n_jobs=-1)\ngd_sr.fit(X_train, y_train)\nbest_parameters = gd_sr.best_params_\nprint('\\n Best param after grid search', best_parameters)\nprint('\\n Best score after grid search', gd_sr.best_score_)","f74cc081":"precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_train, Decision_Tree.predict_proba(X_train)[:,1] )\nplt.plot(threshold_curve, precision_curve[1:],label='precision', color = '#724949')\nplt.plot(threshold_curve, recall_curve[1:], label='recall', color = '#DEDCBB')\nplt.legend(loc='lower left')\nplt.xlabel('Threshold (above this probability)');\nplt.title('Precision and Recall Curves');","98572ed5":"y_predict = (Decision_Tree.predict_proba(X_train)[:, 1] >= 0.5569)\n\nprint(\"Default threshold:\")\nprint(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n                                                     recall_score(y_train, y_predict)))","b3086137":"y_predict = (Decision_Tree.predict_proba(X_train)[:, 1] >= 0.61)\n\nloan_confusion = confusion_matrix(y_train, y_predict)\n\nsns.heatmap(loan_confusion , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Train Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","50986412":"# confusion matrix for crossval\ny_pred = cross_val_predict(Decision_Tree, X = X_train, y = y_train, cv=5)\nconf_mat = confusion_matrix(y_train, y_pred)\nsns.heatmap(conf_mat , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Cross Validation Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","d4c7eddf":"# normal\nRandom_Forest = RandomForestClassifier(n_estimators = 5, random_state=1)\nRandom_Forest.fit(X_train, y_train)\nscores = cross_val_score(Random_Forest, X_train, y_train, cv=10, scoring='f1')\nprint('\\n Normal Random Forest Valdition F1: \\n',scores)\nprint('\\n Mean Normal Random Forest Valdition F1:  \\n',scores.mean())\n\n# balenced\nrf_bal = RandomForestClassifier(n_estimators = 10, random_state=1, class_weight='balanced')\nrf_bal.fit(X_train, y_train)\nscores = cross_val_score(rf_bal, X_train, y_train, cv=10, scoring='f1')\nprint('\\n Balanced class weights Random Forest Valdition F1: \\n',scores)\nprint('\\n Mean Balanced class weights Random Forest Valdition F1: \\n',scores.mean())\n\n# weighted\nrf_wtd = RandomForestClassifier(n_estimators = 10, random_state=1, class_weight= {0 : 2, 1 : 1})\nrf_wtd.fit(X_train, y_train)\nscores = cross_val_score(rf_wtd, X_train, y_train, cv=10, scoring='f1')\nprint('\\n 2:1 class weights Random Forest Valdition F1:\\n',scores)\nprint('\\n 2:1 class weights Random Forest Valdition F1: \\n',scores.mean())\n\n# #gridsearch\n# grid_param = {\n#     'n_estimators': [100, 200, 50],\n#     'criterion': ['gini', 'entropy'],\n#     'bootstrap': [True, False]}\n# gd_sr1 = GridSearchCV(estimator=Random_Forest, param_grid=grid_param,scoring='f1',cv=5,n_jobs=-1)\n# gd_sr1.fit(X_train, y_train)\n# best_parameters = gd_sr1.best_params_\n# print('\\n Best param after grid search', best_parameters)\n# print('\\n Best score after grid search', gd_sr1.best_score_)","4f278155":"precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_train, Random_Forest.predict_proba(X_train)[:,1] )\nplt.plot(threshold_curve, precision_curve[1:],label='precision', color = '#724949')\nplt.plot(threshold_curve, recall_curve[1:], label='recall', color = '#DEDCBB')\nplt.legend(loc='lower left')\nplt.xlabel('Threshold (above this probability)');\nplt.title('Precision and Recall Curves');","0cee63fd":"y_predict = (Random_Forest.predict_proba(X_train)[:, 1] >= 0.66)\n\nprint(\"Default threshold:\")\nprint(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n                                                     recall_score(y_train, y_predict)))","0bb0184d":"y_predict = (Random_Forest.predict_proba(X_train)[:, 1] >= 0.61)\n\nloan_confusion = confusion_matrix(y_train, y_predict)\n\nsns.heatmap(loan_confusion , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Train Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","dc14fc0c":"# confusion matrix for crossval\ny_pred = cross_val_predict(Random_Forest, X = X_train, y = y_train, cv=5)\nconf_mat = confusion_matrix(y_train, y_pred)\nsns.heatmap(conf_mat , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Cross Validation Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","e05ca34a":"Extra_Tree = ExtraTreesClassifier()\nExtra_Tree.fit(X_train, y_train)\nscores = cross_val_score(Extra_Tree, X_train, y_train, cv =5, scoring = 'f1')\nprint('f1_scores for validation: ',scores)\nprint('Mean f1_score for validation: ',scores.mean())","de363e23":"y_predict = (Extra_Tree.predict_proba(X_train)[:, 1] >= 0.1)\n\nprint(\"Default threshold:\")\nprint(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n                                                     recall_score(y_train, y_predict)))","846ef455":"# confusion matrix for crossval\ny_pred = cross_val_predict(Extra_Tree, X = X_train, y = y_train, cv=5)\nconf_mat = confusion_matrix(y_train, y_pred)\nsns.heatmap(conf_mat , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Cross Validation Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","d9f8747f":"lr = LogisticRegression() \nstacked = StackingClassifier(classifiers =[knn,Decision_Tree, lr], meta_classifier = lr, use_probas = False)\nmodel_stack = stacked.fit(X_train, y_train)   # training of stacked model\naccuracies = cross_val_score(estimator = model_stack, X = X_train, y = y_train, cv = 5, scoring='f1')\nprint('f1_score stacking for cross validation : ',accuracies)\nprint('Mean f1_score stacking for cross validation : ',accuracies.mean())","25d94a2b":"precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_train, stacked.predict_proba(X_train)[:,1] )\nplt.plot(threshold_curve, precision_curve[1:],label='precision', color = '#724949')\nplt.plot(threshold_curve, recall_curve[1:], label='recall', color = '#DEDCBB')\nplt.legend(loc='lower left')\nplt.xlabel('Threshold (above this probability)');\nplt.title('Precision and Recall Curves');","47140637":"y_predict = (stacked.predict_proba(X_train)[:, 1] >= 0.1)\n\nprint(\"Default threshold:\")\nprint(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n                                                     recall_score(y_train, y_predict)))","31528a4a":"# confusion matrix for crossval\ny_pred = cross_val_predict(stacked, X = X_train, y = y_train, cv=5)\nconf_mat = confusion_matrix(y_train, y_pred)\nsns.heatmap(conf_mat , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Cross Validation Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","bb769ae9":"bag_clf = BaggingClassifier(\n    DecisionTreeClassifier(), n_estimators=50,\n    max_samples=100, bootstrap=True, n_jobs=-1)\nbag_clf.fit(X_train, y_train)\n\naccuracies = cross_val_score(estimator = bag_clf, X = X_train, y = y_train, cv = 5, scoring='f1')\nprint('f1_score Bagging for cross validation : ',accuracies)\nprint('Mean f1_score Bagging for cross validation : ',accuracies.mean())","a654d17e":"precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_train, bag_clf.predict_proba(X_train)[:,1] )\nplt.plot(threshold_curve, precision_curve[1:],label='precision', color = '#724949')\nplt.plot(threshold_curve, recall_curve[1:], label='recall', color = '#DEDCBB')\nplt.legend(loc='lower left')\nplt.xlabel('Threshold (above this probability)');\nplt.title('Precision and Recall Curves');","49408a6e":"y_predict = (bag_clf.predict_proba(X_train)[:, 1] >= 0.1)\n\nprint(\"Default threshold:\")\nprint(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n                                                     recall_score(y_train, y_predict)))","b83ad284":"# confusion matrix for crossval\ny_pred = cross_val_predict(bag_clf, X = X_train, y = y_train, cv=5)\nconf_mat = confusion_matrix(y_train, y_pred)\nconf_mat","d59d635c":"# confusion matrix for crossval\ny_pred = cross_val_predict(bag_clf, X = X_train, y = y_train, cv=5)\nconf_mat = confusion_matrix(y_train, y_pred)\nsns.heatmap(conf_mat , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Cross Validation Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","c5579551":"param_grid = {'base_estimator__criterion' : ['gini', 'entropy'],\n              'base_estimator__splitter' :   ['best', 'random'],\n              'n_estimators': [1, 5, 10, 20, 100, 500]\n             }\nDTC = DecisionTreeClassifier(random_state = 0)\nABC = AdaBoostClassifier(base_estimator = DTC)\n\n# run grid search\ngrid_search_ABC = GridSearchCV(ABC, param_grid=param_grid, scoring = 'f1')\ngrid_search_ABC.fit(X_train, y_train)\n\nprint('\\n Best param after grid search', grid_search_ABC.best_params_)\nprint('\\n Best score after grid search', grid_search_ABC.best_score_)","ba04e232":"y_predict = (grid_search_ABC.predict_proba(X_train)[:, 1] >= 0.1)\n\nprint(\"Default threshold:\")\nprint(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n                                                     recall_score(y_train, y_predict)))","b8967ae2":"# confusion matrix for crossval\ny_pred = cross_val_predict(grid_search_ABC, X = X_train, y = y_train, cv=5)\nconf_mat = confusion_matrix(y_train, y_pred)\nsns.heatmap(conf_mat , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Cross Validation Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","209d82fb":"X_train.columns = X_train.columns.str.replace('<','less').str.replace(' ','_')\n\nxgboost = XGBClassifier(n_estimators = 100, learning_rate = 0.05)\nxgboost.fit(X_train, y_train)\naccuracies = cross_val_score(estimator = xgboost, X = X_train, y = y_train, cv = 5, scoring='f1')\nprint('f1_score XGBoost for cross validation : ',accuracies)\nprint('Mean f1_score XGBoost for cross validation : ',accuracies.mean())","d68a654f":"precision_curve, recall_curve, threshold_curve = precision_recall_curve(y_train, xgboost.predict_proba(X_train)[:,1] )\nplt.plot(threshold_curve, precision_curve[1:],label='precision', color = '#724949')\nplt.plot(threshold_curve, recall_curve[1:], label='recall', color = '#DEDCBB')\nplt.legend(loc='lower left')\nplt.xlabel('Threshold (above this probability)');\nplt.title('Precision and Recall Curves');","92e18364":"y_predict = (xgboost.predict_proba(X_train)[:, 1] >= 0.1)\n\nprint(\"Default threshold:\")\nprint(\"Precision: {:6.4f},   Recall: {:6.4f}\".format(precision_score(y_train, y_predict), \n                                                     recall_score(y_train, y_predict)))","194b0cfc":"# confusion matrix for crossval\ny_pred = cross_val_predict(xgboost, X = X_train, y = y_train, cv=5)\nconf_mat = confusion_matrix(y_train, y_pred)\nsns.heatmap(conf_mat , cmap = 'pink_r', annot = True , square = True , fmt = 'd',\n           xticklabels = ['long term','short term'],\n           yticklabels = ['long term','short term'])\nplt.title('Cross Validation Confusion Matrix',fontsize = 15)\nplt.xlabel('prediction')\nplt.ylabel('actual');","41054ffd":"log=LogisticRegression() \nrnd=RandomForestClassifier()\ndct=DecisionTreeClassifier()\nvoting_classifer = VotingClassifier(estimators=[('lr',log),('rf',rnd),('dt',dct)],voting='hard',n_jobs=-1)\nvoting_classifer.fit(X_train, y_train)\nscores = cross_val_score(voting_classifer, X_train, y_train, cv=5, scoring='f1')\nprint('f1_score Voting Classifer for cross validation : ',scores)\nprint('Mean f1_score Voting Classifer for cross validation : ',scores.mean())","89031603":"# X_test.columns = X_test.columns.str.replace('<','less').str.replace(' ','_')\ny_pred_ =xgboost.predict(X_test)\ny_pred_1 =xgboost.predict(X_train)\nscores_1 = metrics.f1_score(y_train, y_pred_1)\nscores = metrics.f1_score(y_test, y_pred_)\nprint('Test score for XGBoost: ', scores)","ce10581a":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny_train_encoded = le.fit_transform(y_train)\ny_test_encoded = le.transform(y_test)","0c002b68":"xgboost.fit(X_train, y_train_encoded)","5bf4a685":"from sklearn.metrics import classification_report\n# predict the labels for the test set using the model\ny_hat_test = xgboost.predict(X_test)\nprint(classification_report(y_test_encoded, y_hat_test))","1eca5094":"import pickle\n\ndata = {\"model\": xgboost} \nwith open('saved_steps.pkl', 'wb') as file:\n    pickle.dump(data, file)","6c32935b":"## Data Pre-processing","070367c5":"## Deployment","003be51b":"## Random Forest Classifier\n---","233438d2":"## Feature Engneering\n---","9dbac99b":"# Bank Loan Term Prediction\n---","355087d0":"# Conclusion\nIn Conclusion, after examen multiple classification models, it is clear that the best model to predict whether a loan is a short term or a long term is XGBoost classification model, which gave the highest cross validation F1. The last step for this project is to train the best model using cross validation sets (80% of the data), and test it using the splatted data for testing (20% of the data set). Then F1 score for both the training and testing will be printed. F1 for the cross validition set is 0.8731 and for the testing set 0.8691 as shown above. However, For future work, more classification models will be examined.","580d86a5":"### Droping outliers","201b54b7":"### Get Dummies","7076c5fd":"## Boosting\n---","03fa9040":"## Split the data for train, validation and test","a3abd916":"We can see an error in data entry. There is a duplicate in loan ID but the difference in current loan amount or null values,\n\n**Now we fix it.**","f534560d":"## Bagging\n---","88e17356":"## Stacking\n---","11530b52":"* ### AdaBoost","5b02e810":"## Decision Tree Classifier\n---","084b3d46":"### Cleaning data","6f86b5b5":"### plot the correlation after one hot coding","8cb36f1f":"**Rename columns for easer code writing**","d0838c7b":"## Visualize data\n___","c7d24228":"## KNN Model\n---","c16fcadb":"## Voting Classifer (HARD)\n---","343ed3a1":"* ### XGBoost","f9fe57f8":"## Logistic Regression\n---","a0c90565":"---","c6ff9dd7":"___\n# Test\n___","4f31d892":"**Duplicate in Loan ID**","0cfea10d":"## Import packages & read data.","05325cf6":"## Extra Tree\n---"}}