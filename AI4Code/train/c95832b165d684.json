{"cell_type":{"314f53b4":"code","cb870a98":"code","1d9847a2":"code","2b150f50":"code","19197fdf":"code","27cda9af":"code","4041af74":"code","511125b7":"code","8009ae1e":"code","f8576d5f":"code","0505bce9":"code","546b08ae":"code","9149e6cd":"code","366bcfa5":"code","da19e41d":"code","8703ade3":"code","29107320":"code","32c4a618":"code","f5761f92":"code","68da7263":"code","7c7dde70":"code","9fd922ef":"code","65c15ff9":"code","8b0e056e":"code","c6d663bf":"code","88bb5bf8":"markdown","bc5fadfe":"markdown","08c942fb":"markdown","865aac21":"markdown","1d49dae8":"markdown","9ee96445":"markdown","5f1a9bfd":"markdown","4da708c0":"markdown","d9a63fc6":"markdown","8493c6c6":"markdown","5871a14b":"markdown","63f1891d":"markdown","7af411eb":"markdown","6b804fd3":"markdown","4b90ead2":"markdown"},"source":{"314f53b4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cb870a98":"import numpy as np \nimport pandas as pd \nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom sklearn.model_selection import train_test_split","1d9847a2":"train_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nprint(train_data.shape)\ntrain_data.head()","2b150f50":"test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)\ntest.head()","19197fdf":"test.describe()","27cda9af":"test.describe()","4041af74":"train_data.info()","511125b7":"test.info()","8009ae1e":"train_data.isnull().sum().sort_values(ascending = False) ","f8576d5f":"test.isnull().sum().sort_values(ascending = False) ","0505bce9":"data_labels = train_data['label']\nY = data_labels\ndata_new = train_data.drop(['label'], axis=1)\ndata_arr = np.array(data_new).reshape(-1,28,28)\ndata_clean = data_arr \/ 255.0\n\ndata = data_clean","546b08ae":"X = data\ntest_new = test\ntest_arr = np.array(test_new).reshape(-1,28,28)\ntest_clean = test_arr \/ 255.0\ntest_data = test_clean","9149e6cd":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(data[i], cmap=plt.cm.binary)\n    plt.xlabel(data_labels[i])\nplt.show()","366bcfa5":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y , random_state=1, test_size=0.2)","da19e41d":"X_train.shape","8703ade3":"X_test.shape","29107320":"Y_test.shape","32c4a618":"Y_train.shape","f5761f92":"model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10)\n])","68da7263":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","7c7dde70":"model.fit(X_train, Y_train, epochs=20)","9fd922ef":"test_loss, test_accuracy = model.evaluate(X_test,  Y_test, verbose=2)\n\nprint('\\nTest accuracy:', test_accuracy*100,\"%\")","65c15ff9":"train_loss, train_accuracy = model.evaluate(X_train,  Y_train, verbose=2)\n\nprint('\\nTrain accuracy:', train_accuracy*100,\"%\")","8b0e056e":"pred = model.predict(test_data)\n\noutput = pd.DataFrame()\n\noutput['ImageId'] = list(range(1,28001))\n\npredictions = []\nfor p in pred:\n    predictions.append(np.argmax(p))\n \noutput['Label'] = predictions\n\noutput.to_csv(\"my_submission.csv\", index=False)\n","c6d663bf":"pred","88bb5bf8":"## Data collection and preparation","bc5fadfe":"**Test Data has 28000 images of size 784(28*28)**","08c942fb":"###  Make predictions","865aac21":"**Training Data has 42000 examples of images of digits**","1d49dae8":"## Visualization","9ee96445":"**No Null Values here**","5f1a9bfd":"### Train the Model","4da708c0":"## Data split into tarining and test splits","d9a63fc6":"### Setting up layers","8493c6c6":"### Evaluate the model","5871a14b":"### Compile the Model","63f1891d":"## Exploring the dataset                                           \n### Data consists of two csv files i.e train and test","7af411eb":"## Building the Model","6b804fd3":"## Import all required libraries","4b90ead2":"#### Data is alredy clean and  ready to use"}}