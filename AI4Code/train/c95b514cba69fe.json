{"cell_type":{"2773971a":"code","e16e1b3c":"code","e00ff400":"code","bd7561ab":"code","e6699939":"code","bcf3c3af":"code","8f948bbc":"code","70f0adf9":"code","c693a672":"code","4db8823a":"code","1859a2e2":"code","3268be14":"code","7ed86b05":"code","703e1f80":"code","1e20b161":"markdown"},"source":{"2773971a":"!pip install -U kaggler==0.8.6","e16e1b3c":"import kaggler\nprint(kaggler.__version__)","e00ff400":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport gc\nimport joblib\nimport lightgbm as lgb\nimport numpy as np\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom kaggler.metrics import auc\nfrom kaggler.model import AutoLGB\nfrom kaggler.preprocessing import EmbeddingEncoder, LabelEncoder","bd7561ab":"train = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat\/test.csv\")\nsample = pd.read_csv(\"\/kaggle\/input\/cat-in-the-dat\/sample_submission.csv\")","e6699939":"for col in train.columns:\n    print('{:>8s}: {:6d}'.format(col, train[col].nunique()))","bcf3c3af":"features_to_emb = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_3', 'ord_4', 'ord_5']\nn_emb = [16, 16, 20, 20, 30, 4, 8, 16]\n\nfeatures_not_to_emb = [x for x in train.columns if x not in features_to_emb + ['id', 'target']]","8f948bbc":"n_fold = 5\nseed = 42\ncv = StratifiedKFold(n_splits=n_fold, random_state=seed)","70f0adf9":"ee = EmbeddingEncoder(cat_cols=features_to_emb, num_cols=[], n_emb=n_emb, random_state=seed)\nX_emb_trn = ee.fit_transform(train[features_to_emb], train['target'])\nX_emb_tst = ee.transform(test[features_to_emb])","c693a672":"features_emb = []\nfor n, col in zip(n_emb, features_to_emb):\n    features_emb += ['{}_{}'.format(col, i + 1) for i in range(n)]","4db8823a":"lbe = LabelEncoder(min_obs=10)\ntrain.loc[:, features_not_to_emb] = lbe.fit_transform(train[features_not_to_emb])\ntest.loc[:, features_not_to_emb] = lbe.transform(test[features_not_to_emb])","1859a2e2":"X_trn = pd.concat([train[features_not_to_emb], pd.DataFrame(X_emb_trn, columns=features_emb)], axis=1)\ny_trn = train['target']\nX_tst = pd.concat([test[features_not_to_emb], pd.DataFrame(X_emb_tst, columns=features_emb)], axis=1)\nfeatures = features_not_to_emb + features_emb","3268be14":"model = AutoLGB(objective='binary', metric='auc', sample_size=50000, random_state=seed)\nmodel.tune(X_trn, y_trn)\nprint('{} features selected out of {}'.format(len(model.features), len(features)))","7ed86b05":"p = np.zeros((X_trn.shape[0],))\np_tst = np.zeros((X_tst.shape[0],))\nfor i, (i_trn, i_val) in enumerate(cv.split(X_trn, y_trn), 1):\n    model.fit(X_trn.loc[i_trn, features], y_trn[i_trn])\n    p[i_val] = model.predict(X_trn.loc[i_val, features])\n    print('AUC (CV #{}): {:.4f}'.format(i, auc(y_trn[i_val], p[i_val])))\n    p_tst += model.predict(X_tst[features]) \/ n_fold\n    \nprint('AUC CV: {:.4f}'.format(auc(y_trn, p)))","703e1f80":"print(\"Saving submission file\")\nsubmission = pd.DataFrame.from_dict({\n    'id': test.id.values,\n    'target': p_tst\n})\nsubmission.to_csv(\"submission.csv\", index=False)","1e20b161":"Kaggler's EmbeddingEncoder (inspired by Abhishek's) + AutoLGB"}}