{"cell_type":{"9f1359a5":"code","7d43e3ca":"code","4e10599c":"code","49cab7f8":"code","c712e654":"code","77204ea7":"code","dafad1b2":"code","e595bab3":"code","f960280b":"code","ba22b969":"code","63a51356":"code","c2060474":"code","cc140fe0":"code","193218bd":"code","5f34b433":"code","4596f71c":"code","a1b7608a":"code","2f9d023d":"code","0ba7a3f1":"code","a36fcdd9":"code","1278ad93":"code","d0f669d8":"code","4e309a83":"code","beb9d881":"code","47d43a84":"code","4c78b8fc":"code","795dd085":"code","ca767897":"code","188ab7d2":"code","c2456e91":"code","8e611fcc":"code","dd8e71c6":"code","ca4a3edc":"code","bc379bf1":"code","67691347":"code","4b4fe132":"code","a363416e":"code","0d214017":"code","6d9ac5da":"code","d9bf26c9":"markdown","aeecdefa":"markdown"},"source":{"9f1359a5":"import os\nimport random\nimport numpy as np\nimport math\nimport itertools\n\nSEED = 7\nos.environ['PYTHONHASHSEED']=str(SEED)\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\nimport tensorflow as tf\ntf.random.set_seed(SEED)\nimport tensorflow.keras\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.models import Sequential, load_model, Model\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers.experimental import preprocessing\nimport tensorflow.keras.backend as K\n\nfrom tensorflow.keras.applications import DenseNet201\nNETWORK = DenseNet201\n\nfrom kaggle_datasets import KaggleDatasets\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix, mean_squared_error, classification_report\n\n\nimport re\nimport imageio\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\n%matplotlib inline\n\ntry:\n    tpu = None\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(\"Tensorflow version \", tf.__version__)","7d43e3ca":"# from tensorflow.keras.mixed_precision import experimental as mixed_precision\n# policy = mixed_precision.Policy('mixed_float16')\n# mixed_precision.set_policy(policy)","4e10599c":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\n\nuser_secrets.set_tensorflow_credential(user_credential)","49cab7f8":"# Cosine annealing scheduler\nfrom tensorflow.keras.callbacks import Callback\nclass CosineAnnealingScheduler(Callback):\n\n    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n        super(CosineAnnealingScheduler, self).__init__()\n        self.T_max = T_max\n        self.eta_max = eta_max\n        self.eta_min = eta_min\n        self.verbose = verbose\n\n    def on_epoch_begin(self, epoch, logs=None):\n        if not hasattr(self.model.optimizer, 'lr'):\n            raise ValueError('Optimizer must have a \"lr\" attribute.')\n        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch \/ self.T_max)) \/ 2\n        K.set_value(self.model.optimizer.lr, lr)\n        if self.verbose > 0:\n            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n                  'rate to %s.' % (epoch + 1, lr))\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        logs['lr'] = K.get_value(self.model.optimizer.lr)","c712e654":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ntf.config.optimizer.set_jit(True)\n\ndataset_id1 = 'covid19-lung-ct-scans'\nGCS_PATH1 = KaggleDatasets().get_gcs_path(dataset_id1)\nBATCH_SIZE = 128 * strategy.num_replicas_in_sync\n\nCLASSES = ['COVID-19', 'Non-COVID-19']\nNUM_CLASSES = len(CLASSES)\nIMAGE_SIZE = [224, 224]\ninput_shape = (224, 224, 3)\nLOSS = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2)\n\nMETRICS = ['accuracy']\n\nEpochs = 50\nEarly_Stop = 15\nOPTIMIZER = tensorflow.keras.optimizers.Adam(lr = 1e-2, decay = 1e-5)\n\nFine_Tune_Epochs = 100\nFine_Tune_Early_Stop = 20\nFine_Tune_OPTIMIZER = tensorflow.keras.optimizers.Adam(lr = 1e-3, decay = 1e-6)\nFine_Tune_filepath = \"Best-Model-FT.h5\"\n\nCallbacks = [\n    CosineAnnealingScheduler(Epochs, 1e-3, 1e-6),\n    EarlyStopping(monitor='val_accuracy', patience=Early_Stop, mode='auto', min_delta=0.00001, verbose=2, restore_best_weights=True)]\n\nFT_Callbacks = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, verbose=2, mode='min', min_delta=0.0001, cooldown=1, min_lr=1e-6),\n    ModelCheckpoint(Fine_Tune_filepath, monitor='val_accuracy', verbose=2, save_best_only=True, save_weights_only=False, mode='max'),\n    EarlyStopping(monitor='val_loss', patience=Fine_Tune_Early_Stop, mode='auto', min_delta=0.00001, verbose=2, restore_best_weights=True)]","77204ea7":"filenames = tf.io.gfile.glob(str(GCS_PATH1 + '\/COVID-19_Lung_CT_Scans\/COVID-19\/*'))\nfilenames.extend(tf.io.gfile.glob(str(GCS_PATH1 + '\/COVID-19_Lung_CT_Scans\/Non-COVID-19\/*')))\n\nfilenames.remove(str(GCS_PATH1 + '\/COVID-19_Lung_CT_Scans\/COVID-19\/desktop.ini'))\n    \nrandom.shuffle(filenames)","dafad1b2":"COUNT_COVID = len([filename for filename in filenames if \"\/COVID-19\/\" in filename])\nprint(\"COVID-19 images count : \" + str(COUNT_COVID))\n\nCOUNT_Non_COVID = len([filename for filename in filenames if \"\/Non-COVID-19\/\" in filename])\nprint(\"Non-COVID images count : \" + str(COUNT_Non_COVID))","e595bab3":"data = {'Cases':['COVID-19', 'non-COVID'],\n        'Cases_count':[COUNT_COVID, COUNT_Non_COVID]\n       }\n\ndf = pd.DataFrame(data)\n\nsns.set(style=\"darkgrid\")\nplt.figure(figsize=(10,8))\nsns.barplot(x=df.index, y= df['Cases_count'].values)\nplt.title('Number of All the Data', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(df.index)), ['COVID-19', 'non-COVID'])\nplt.show()\n\nprint(df)","f960280b":"train_filenames, test_filenames = train_test_split(filenames, test_size=0.2)\ntrain_filenames, val_filenames = train_test_split(train_filenames, test_size=0.2)","ba22b969":"train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\nval_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)\ntest_list_ds = tf.data.Dataset.from_tensor_slices(test_filenames)","63a51356":"TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\nprint(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n\nVAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\nprint(\"Validating images count: \" + str(VAL_IMG_COUNT))\n\nTest_IMG_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\nprint(\"Testing images count: \" + str(Test_IMG_COUNT))","c2060474":"def get_label(file_path):\n    parts = tf.strings.split(file_path, os.path.sep)\n    return int(parts[-2] == CLASSES)","cc140fe0":"def decode_img(img):\n    img = tf.image.decode_png(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    return tf.image.resize(img, IMAGE_SIZE)","193218bd":"def process_path(file_path):\n    label = get_label(file_path)\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","5f34b433":"train_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)","4596f71c":"def prepare_for_training(ds, cache=True):\n    ds = ds.shuffle(buffer_size=1000)\n    ds = ds.batch(BATCH_SIZE)\n\n    if cache:\n        ds = ds.prefetch(buffer_size=AUTOTUNE)\n\n    return ds","a1b7608a":"train_ds = prepare_for_training(train_ds)\nval_ds = prepare_for_training(val_ds)\ntest_ds = prepare_for_training(test_ds, False)","2f9d023d":"img_augmentation = Sequential([\n    preprocessing.RandomFlip(\"horizontal\"),\n    preprocessing.RandomContrast(factor=0.20)\n    ],name=\"Augmentation\")","0ba7a3f1":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10,10))\n    for n in range(15):\n        ax = plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        plt.title(CLASSES[np.argmax(label_batch[n])])\n        plt.axis(\"off\")","a36fcdd9":"image_batch, label_batch = next(iter(train_ds))\nshow_batch(image_batch.numpy(), label_batch.numpy())","1278ad93":"def dataset_to_numpy_util(dataset, N):\n    dataset = dataset.unbatch().batch(N)\n    for images, labels in dataset:\n        numpy_images = images.numpy()\n        numpy_labels = labels.numpy()\n        break\n    return numpy_images, numpy_labels\n\nx_test, y_test = dataset_to_numpy_util(test_ds, Test_IMG_COUNT)\n\nprint(\"Evaluation Dataset:\")\nprint('X shape: ', x_test.shape,' Y shape: ', y_test.shape)","d0f669d8":"def weight_classes(extra_weight=False, ew_value=1):\n    total_COUNT = COUNT_COVID + COUNT_Non_COVID\n\n    weight_for_0 = (1 \/ COUNT_COVID) * total_COUNT \/ 2.0 \n    weight_for_1 = (1 \/ COUNT_Non_COVID) * total_COUNT \/ 2.0\n    \n    if extra_weight:\n        weight_for_1 *= ew_value\n\n    class_weight = {0: weight_for_0, 1: weight_for_1}\n\n    print(f'Weight for class 0: {weight_for_0}')\n    print(f'Weight for class 1: {weight_for_1}')\n    \n    return class_weight","4e309a83":"class_weight = weight_classes(extra_weight=False, ew_value=1.5)","beb9d881":"def build_model(OPTIMIZER, LOSS, METRICS):\n    model = None\n    inputs = layers.Input(shape=input_shape)\n    x = img_augmentation(inputs)\n    baseModel = NETWORK(include_top=False, input_tensor=x, weights=\"imagenet\", pooling ='avg')\n\n    baseModel.trainable = False\n\n    x = BatchNormalization(axis = -1, name=\"Batch-Normalization-1\")(baseModel.output)\n    x = Dense(512, activation='relu', kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4))(x)\n    x = BatchNormalization(axis = -1, name=\"Batch-Normalization-2\")(x)\n    x = Dropout(.2, name=\"Dropout-1\")(x)\n\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization(axis = -1, name=\"Batch-Normalization-3\")(x)\n    \n    outputs = Dense(NUM_CLASSES, activation=\"softmax\", name=\"Classifier\")(x)\n    model = tf.keras.Model(inputs=baseModel.input, outputs=outputs, name=\"Deep-COVID\")\n    \n    model.compile(optimizer = OPTIMIZER, loss = LOSS, metrics = METRICS)\n        \n    return model","47d43a84":"with strategy.scope():\n    model = build_model(OPTIMIZER, LOSS, METRICS)","4c78b8fc":"def fit_model(Epochs, Callbacks, class_weight=None):\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=Epochs,\n        callbacks=Callbacks,\n        verbose=2,\n        class_weight=class_weight\n    )\n    return history\n    \nhistory = fit_model(Epochs, Callbacks, class_weight=class_weight)","795dd085":"def Plot_Learning_Curves():\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    \n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    sns.set(style=\"dark\")\n    plt.rcParams['figure.figsize'] = (14, 5)\n\n    plt.subplot(1,2,1)\n    plt.plot(loss, label='Training loss')\n    plt.plot(val_loss, linestyle=\"--\", label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.ylabel('Loss') \n    plt.xlabel('Epoch')\n    plt.legend()\n\n    plt.subplot(1,2,2)\n    plt.plot(acc, label='Training Accuracy')\n    plt.plot(val_acc, linestyle=\"--\", label='Validation Accuracy')\n    plt.title('Training and validation accuracy')\n    plt.ylabel('Accuracy') \n    plt.xlabel('Epoch')\n    plt.legend()\n\n    plt.show()\n    \nPlot_Learning_Curves()","ca767897":"def evaluate_model(model):\n    results = model.evaluate(test_ds, return_dict=True)\n    print ('\\nModel Evaluation:')\n    print(results['accuracy']*100)\n    return results\n    \nresults = evaluate_model(model)","188ab7d2":"def fine_tune(OPTIMIZER, LOSS, METRICS):\n    for layer in model.layers[-54:]:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = True\n            \n    model.compile(optimizer = Fine_Tune_OPTIMIZER, loss = LOSS, metrics = METRICS)\n    return model","c2456e91":"with strategy.scope():\n    model = fine_tune(Fine_Tune_OPTIMIZER, LOSS, METRICS)","8e611fcc":"history = fit_model(Fine_Tune_Epochs, FT_Callbacks, class_weight=class_weight)","dd8e71c6":"model = load_model(Fine_Tune_filepath)\n\nresults = model.evaluate(test_ds, return_dict=True)\nprint ('\\nModel Evaluation:')\nprint(results['accuracy']*100)","ca4a3edc":"# if not TPU_accelerator:\n#     tf.keras.mixed_precision.set_global_policy('float32')","bc379bf1":"preds = model.predict(x_test)\nprint('Shape of preds: ', preds.shape)\nplt.figure(figsize = (12, 12))\n\nR = np.random.choice(preds.shape[0])\n\nfor i in range(25):\n    plt.subplot(5, 5, i + 1)\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n    R = np.random.choice(preds.shape[0])\n    pred = np.argmax(preds[R])\n    actual = np.argmax(y_test[R])\n    col = 'g'\n    if pred != actual:\n        col = 'r'\n    plt.xlabel('I={} | P={} | L={}'.format(R, pred, actual), color = col)\n    plt.imshow(((x_test[R]* 255).astype(np.uint8)), cmap='binary')\nplt.show()","67691347":"index = 0\nplt.rcParams['figure.figsize'] = (6, 4)\nplt.plot(preds[index])\nsns.set(style=\"darkgrid\")\nplt.show()","4b4fe132":"categories = ['COVID-19', 'Non-COVID-19']\npreds = np.round(preds,0)\nclass_metrics = metrics.classification_report(y_test, preds, target_names = categories, zero_division = 0)\nprint (class_metrics)","a363416e":"matrix = metrics.confusion_matrix(y_test.argmax(axis=1), preds.argmax(axis=1))\n\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n    sns.set(style=\"dark\")\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\n Accuracy={:0.4f}; Misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()\n    \nplot_confusion_matrix(cm           = np.array(matrix), \n                      normalize    = False,\n                      target_names = categories,\n                      title        = \"Confusion Matrix\")\n\nplot_confusion_matrix(cm           = np.array(matrix), \n                      normalize    = True,\n                      target_names = categories,\n                      title        = \"Confusion Matrix, Normalized\")","0d214017":"test_image = x_test[0]\nx = np.expand_dims(test_image, axis=0)\nx = x\/255\n\nimages = np.vstack([x])\n\nclasses = model.predict(images, batch_size=BATCH_SIZE)\nclasses = np.argmax(classes,axis=1)\n\nprint ('Class:', categories[int(classes)] )","6d9ac5da":"FP = matrix.sum(axis=0) - np.diag(matrix)\nFN = matrix.sum(axis=1) - np.diag(matrix)\nTP = np.diag(matrix)\nTN = matrix[:].sum() - (FP + FN + TP)\n\nTPR = TP\/(TP+FN)\nTNR = TN\/(TN+FP) \nPPV = TP\/(TP+FP)\nNPV = TN\/(TN+FN)\nFPR = FP\/(FP+TN)\nFNR = FN\/(TP+FN)\nFDR = FP\/(TP+FP)\n\nACC = (TP+TN)\/(TP+FP+FN+TN)\n\nprint('Other Metrics:')\nMSE = mean_squared_error(y_test, preds)\n\nprint('MSE:', MSE)\nprint('Accuracy:', ACC)\nprint('Precision (positive predictive value):', PPV)\nprint('Recall (Sensitivity, hit rate, true positive rate):', TPR)\nprint('Specificity (true negative rate):', TNR)\nprint('Negative Predictive Value:', NPV)\nprint('Fall out (false positive rate):', FPR)\nprint('False Negative Rate:', FNR)\nprint('False discovery rate:', FDR)","d9bf26c9":"### Deep CNN-Based CAD System for COVID-19 Detection.\n#### _ Mehrad Aria","aeecdefa":"----\n\n**Deep-COVID** V.1.0.08 | Deep CNN-Based CAD System for COVID-19 Detection Using Multiple Lung CT Scans.\n<br>{Binary (COVID-19, Non-COVID) clasification.}\n\n\u00a9 Proposed Method Implementation by **Mehrad Aria** for Paper [Deep Convolutional Neural Network\u2013Based Computer-Aided Detection System for COVID-19 Using Multiple Lung Scans: Design and Implementation Study](https:\/\/doi.org\/10.2196\/27468).\n<br>Jan 2021 \/ Shiraz, Iran.\n\n----"}}