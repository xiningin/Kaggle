{"cell_type":{"dfd82362":"code","eac32ee3":"code","515527f7":"code","07b4ef56":"code","a229eacb":"code","07a88123":"code","4e9f2c80":"code","b67ad4b7":"code","f5363a71":"code","a7398969":"code","92550d3b":"code","0cca8b81":"code","aadc7ab4":"code","5a35f1d2":"code","3dfb887a":"code","2252bfc4":"code","a1cabbbf":"code","91984b69":"code","9bac0151":"code","71d2463d":"code","df085cb3":"code","fba188ad":"code","285175a8":"code","7d6f30fc":"code","7cbcb353":"code","be46000c":"code","37b52618":"code","51ed586c":"code","bb9e346c":"code","d47b69de":"code","47a303a7":"code","3fe7bec7":"code","2174152e":"code","a520de13":"code","fef9a11a":"code","5eec3fdc":"code","a154504c":"code","a950b947":"code","5a7fa24c":"code","fb7e39e0":"code","73aee102":"code","c9a87e8e":"code","277df270":"code","0da3f62b":"code","7d4824b3":"code","de116917":"code","303ce250":"code","a0da5d59":"code","7a370428":"code","ef379039":"code","1768f061":"code","201a61e4":"code","59632499":"code","5a800ad9":"code","886ad0a6":"code","ba3a1794":"code","039341db":"code","1b473182":"code","0fcb5d15":"code","da5e5c1d":"code","6ba17a55":"code","8d613b26":"code","03c2fc8e":"code","2f11f024":"code","a2e27e74":"code","b153c3c4":"code","79204202":"code","b5cc0a9a":"code","b9613e6b":"code","4c4506f1":"code","267d6f52":"code","4463ad7e":"code","c09c6266":"code","28a7d03f":"code","f4193ca0":"code","50a8108e":"code","fe23be8c":"code","7f795426":"code","23328002":"code","1c15ac8b":"code","f47c1944":"code","c9d8f994":"code","d91b2ef1":"code","435f999b":"code","b501c2eb":"code","63f4605a":"code","668da602":"code","eb0e1e4a":"markdown","45587545":"markdown","056dfd2a":"markdown","fdaf40b2":"markdown","64f821d1":"markdown","d83f09af":"markdown","ac0b92ce":"markdown","712de1a1":"markdown","420b5d4e":"markdown","c5070b5d":"markdown","9c05fe67":"markdown","26659d86":"markdown","3174d209":"markdown","3b3201bb":"markdown","814dcaab":"markdown"},"source":{"dfd82362":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eac32ee3":"df=pd.read_csv('\/kaggle\/input\/cardataset\/data.csv')\n\ndf","515527f7":"df.columns=df.columns.str.lower().str.replace(' ','_')\ndf.head()\n\ndf.dtypes","07b4ef56":"df.dtypes[df.dtypes==\"object\"].index\nstrings=list(df.dtypes[df.dtypes==\"object\"].index)\n# Loop over the strings list\nfor i in strings:\n    df[i]=df[i].str.lower().str.replace(' ','_')\n    \ndf.head()","a229eacb":"df.dtypes\nfor col in df.columns:\n    print(col)\n    print(df[col].unique()[:4],'\\n')\n    print(df[col].nunique())\n# lets try determining unique values\n# how many they are","07a88123":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nsns.histplot(df.msrp, bins=60)","4e9f2c80":"sns.histplot(df.msrp[df.msrp<=100000], bins=50)\n\nprice_logs=np.log1p(df.msrp)\nprice_logs\n","b67ad4b7":"sns.histplot(price_logs, bins=50)","f5363a71":"df.isnull().sum()","a7398969":"n=len(df)\n\nn_val=int(n*0.2)\nn_test=int(n*0.2)\n#  But this is not sustainable becase n reduces by 2 due to rounding off with fxn int()\n# we just subtract\nn_train=n-n_val-n_test\n\n# thus they are the same\nn, n_val+n_test+n_train\nn, n_val,n_test, n_train","92550d3b":"df.iloc[:10]","0cca8b81":"df_train=df.iloc[:n_train]\n\ndf_val=df.iloc[n_train:n_train+n_val]\n\ndf_test=df.iloc[n_train+n_val:]\n\n\nidx=np.arange(n)\nnp.random.seed(2)\nnp.random.shuffle(idx)","aadc7ab4":"df.iloc[idx[:10]]","5a35f1d2":"df_train= df.iloc[idx[:n_train]]\n\ndf_val= df.iloc[idx[n_train:n_train+n_val]]\n\ndf_test= df.iloc[idx[n_train+n_val:]]\n\n\ndf_train=df_train.reset_index(drop=True)\ndf_val=df_val.reset_index(drop=True)\ndf_test=df_test.reset_index(drop=True)\n","3dfb887a":"len(df_train), len(df_val), len(df_test)","2252bfc4":"y_train=np.log1p(df_train.msrp.values)\ny_val=np.log1p(df_val.msrp.values)\ny_test=np.log1p(df_test.msrp.values)","a1cabbbf":"df.head()","91984b69":"del df_train ['msrp']\ndel df_val ['msrp']\ndel df_test ['msrp']","9bac0151":"len(y_train)","71d2463d":"df_train.iloc[10]","df085cb3":"xi=[453, 11, 86]","fba188ad":"w0=7.17 #bias\nw=[0.01,0.04,0.002]# weights","285175a8":"#  is the linear regression model\ndef linear_regression(xi):\n    \n    n=len(xi)\n    \n    pred=w0\n    \n    for j in range(n):\n        \n        pred=pred+w[j] * xi[j]\n #do something\n    return pred","7d6f30fc":"np.expm1(linear_regression(xi))","7cbcb353":"def dot(xi, w):\n    n=len(xi)\n    \n    res=0.0\n    \n    for j in range(n):\n        \n        res=res + xi[j]* w[j]\n        \n    return res\n    ","be46000c":"dot(xi, w)","37b52618":"def linear_regression(xi):\n    return w0 + dot(xi, w)","51ed586c":"linear_regression(xi)","bb9e346c":"w_new=[w0]+ w\n\nw_new","d47b69de":"#  is the linear regression model\ndef linear_regression(xi):\n    \n    xi= [1] + xi\n    return dot(xi,w_new)","47a303a7":"round(linear_regression(xi), 3)","3fe7bec7":"xi=[453, 11, 86]\nw0=7.17 #bias\nw=[0.01,0.04,0.002]# weights\n\nw_new=[w0]+ w","2174152e":"x1=[1, 148, 24, 1385]\nx2=[1, 132, 25, 2031]\nx10=[1, 453, 11, 86]\n\n# We then make a list of lists\n\nX=[x1, x2, x10]\n\nX=np.array(X)\n\nX","a520de13":"def linear_regression(X):\n    return X.dot(w_new)","fef9a11a":"X=[[ 148, 24, 1385],\n[132, 25, 2031],\n[453, 11, 86],\n[158, 24, 185],\n[172, 25, 201],\n[413, 11, 86],\n[38, 54, 185],\n[142, 25, 431],\n[453, 31, 86]]\n\nX=np.array(X)\n# ones=np.ones(X.shape[0])\n# X= np.column_stack([ones,X])\nX\n","5eec3fdc":"y=[10000,20000,15000,20050,10000,20000,15000,25000,12000]","a154504c":"# gram matrix\n\nXTX=X.T.dot(X)\nXTX\nXTX_inv= np.linalg.inv(XTX)\nXTX_inv\n# w_full=XTX_inv.dot(X.T).dot(y)","a950b947":"np.linalg.inv(XTX)\nnp.linalg.det(XTX_inv)","5a7fa24c":"def train_linear_regression(X, y):\n# Iclude a bias term.. helps us identify value of car if we dont know anythig about the car.\n    ones=np.ones(X.shape[0])\n    X=np.column_stack([ones, X])\n    \n    XTX=X.T.dot(X)\n    XTX_inv= np.linalg.inv(XTX)\n    w_full= XTX_inv.dot(X.T).dot(y)\n    \n    return  w_full[0], w_full[1:]","fb7e39e0":"train_linear_regression(X,y)","73aee102":"df_train.dtypes","c9a87e8e":"base=['engine_hp','engine_cylinders','highway_mpg','city_mpg','popularity']\n\n\n","277df270":"X_train= df_train[base].fillna(0).values","0da3f62b":"# LEts now train a model\nw0, w= train_linear_regression(X_train, y_train)\n\nw0, w","7d4824b3":"y_pred=w0+ X_train.dot(w)","de116917":"sns.histplot(y_pred, color='red', alpha=0.4, bins=50)\nsns.histplot(y_train, color='blue',alpha=0.4, bins=50)","303ce250":"def rmse(y_pred, y):\n    \n    error=y_pred- y\n    se=error**2\n    mse=se.mean()\n    return np.sqrt(mse)\n    ","a0da5d59":"rmse(y_pred, y_train)","7a370428":"base=['engine_hp','engine_cylinders','highway_mpg','city_mpg','popularity']\nX_train= df_train[base].fillna(0).values\nw0, w= train_linear_regression(X_train, y_train)\ny_pred=w0+ X_train.dot(w)","ef379039":"def prepare_X(df):\n    df_num=df[base]\n    df_num=df_num.fillna(0)\n    X=df_num.values\n    return X\n\n    ","1768f061":"X_train=prepare_X(df_train)\nw0, w= train_linear_regression(X_train, y_train)\n\nX_val=prepare_X(df_val)\ny_pred=w0+ X_val.dot(w)\n\nrmse(y_val, y_pred)\n","201a61e4":"df_train[\"year\"].max()# to determine the ages of the cars.\n\n2017-df_train[\"year\"] # we can use this as one of our feeatures in this model","59632499":"def prepare_X(df):\n    df=df.copy()\n    \n    df['age']=2017-df[\"year\"] \n    \n    features= base+['age']\n    df_num=df[features]\n    df_num=df_num.fillna(0)\n    X=df_num.values\n    return X\n","5a800ad9":"X_train=prepare_X(df_train)\nw0, w= train_linear_regression(X_train, y_train)\n\nX_val=prepare_X(df_val)\ny_pred=w0+ X_val.dot(w)\n\nrmse(y_val, y_pred)\n\n","886ad0a6":"sns.histplot(y_pred, color='red', alpha=0.4, bins=50)\nsns.histplot(y_val, color='blue',alpha=0.4, bins=50)","ba3a1794":"df_train.dtypes #mostly strings(object)","039341db":"# df_train['num_doors_2']=(df_train.number_of_doors ==2).astype(int)\n# df_train['num_doors_3']=(df_train.number_of_doors ==3).astype(int)\n# df_train['num_doors_4']=(df_train.number_of_doors ==4).astype(int)","1b473182":"# for v in [2,3,4]:\n#     df_train['num_doors_%s' %v]=(df_train.number_of_doors ==v).astype(int)","0fcb5d15":"# df_train","da5e5c1d":"def prepare_X(df):\n    df=df.copy()\n    \n    df['age']=2017-df[\"year\"] \n    \n    features= base+['age']\n    \n    for v in[2,3,4]:\n        df['num_doors_%s' %v]=(df.number_of_doors ==v).astype(int)\n        features.append('num_doors_%s' %v)\n        \n    df_num=df[features]\n    df_num=df_num.fillna(0)\n    X=df_num.values\n    return X","6ba17a55":"prepare_X(df_train)","8d613b26":"X_train=prepare_X(df_train)\nw0, w= train_linear_regression(X_train, y_train)\n\nX_val=prepare_X(df_val)\ny_pred=w0+ X_val.dot(w)\n\nrmse(y_val, y_pred)\n","03c2fc8e":"df.make.nunique()\nmakes=list(df.make.value_counts().head().index)","2f11f024":"def prepare_X(df):\n    df=df.copy()\n    \n    df['age']=2017-df[\"year\"] \n    \n    features= base+['age']\n    \n    for v in[2,3,4]:\n        df['num_doors_%s' %v]=(df.number_of_doors ==v).astype(int)\n        features.append('num_doors_%s' %v)\n    for m in makes:\n        df['make_%s' %m]=(df.make ==m).astype(int)\n        features.append('make_%s' %m)\n        \n    df_num=df[features]\n    df_num=df_num.fillna(0)\n    X=df_num.values\n    return X","a2e27e74":"prepare_X(df_train)","b153c3c4":"X_train=prepare_X(df_train)\nw0, w= train_linear_regression(X_train, y_train)\n\nX_val=prepare_X(df_val)\ny_pred=w0+ X_val.dot(w)\n\nrmse(y_val, y_pred)\n","79204202":"df.dtypes","b5cc0a9a":"# We can now use all the categorical variables\n\ncategorical_var=['make',\n    \"engine_fuel_type\",'transmission_type','driven_wheels','market_category','market_category'  \n     ,'vehicle_style',]","b9613e6b":"# We use a dictionary\ncategories={}\n\nfor c in categorical_var:\n    categories[c]=list(df[c].value_counts().head().index)\n","4c4506f1":"categories","267d6f52":"def prepare_X(df):\n    df=df.copy()\n    \n    df['age']=2017-df[\"year\"] \n    \n    features= base+['age']\n    \n    for v in[2,3,4]:\n        df['num_doors_%s' %v]=(df.number_of_doors ==v).astype(int)\n        features.append('num_doors_%s' %v)\n    for c, values in categories.items():\n        for v in values:\n            df['%s_%s' %(c,v)]=(df[c] ==v).astype(int)\n            features.append('%s_%s' %(c,v))\n        \n    df_num=df[features]\n    df_num=df_num.fillna(0)\n    X=df_num.values\n    return X","4463ad7e":"X_train=prepare_X(df_train)\nw0, w= train_linear_regression(X_train, y_train)\n\nX_val=prepare_X(df_val)\ny_pred=w0+ X_val.dot(w)\n\nrmse(y_val, y_pred)\n","c09c6266":"w0, w","28a7d03f":"def train_linear_regression_reg(X, y, r=0.001):\n# Iclude a bias term.. helps us identify value of car if we dont know anythig about the car.\n    ones=np.ones(X.shape[0])\n    X=np.column_stack([ones, X])\n    \n    XTX=X.T.dot(X)\n    \n    XTX=XTX+ r* np.eye(XTX.shape[0])\n    XTX_inv= np.linalg.inv(XTX)\n    w_full= XTX_inv.dot(X.T).dot(y)\n    \n    return  w_full[0], w_full[1:]","f4193ca0":"X_train=prepare_X(df_train)\nw0, w= train_linear_regression_reg(X_train, y_train, r=0.001)\n\nX_val=prepare_X(df_val)\ny_pred=w0+ X_val.dot(w)\n\nrmse(y_val, y_pred)","50a8108e":"for r in [0.0, 0.00001,0.0001,0.001,0.1,1,10]:\n\n    X_train=prepare_X(df_train)\n    w0, w= train_linear_regression_reg(X_train, y_train, r=r)\n\n    X_val=prepare_X(df_val)\n    y_pred=w0+ X_val.dot(w)\n\n    score=rmse(y_val, y_pred)\n    \n    print(f\"for {r} the bias term is  {w0}  and score is  {score}\")","fe23be8c":"r=0.001\nX_train=prepare_X(df_train)\nw0, w= train_linear_regression_reg(X_train, y_train, r=r)\n\nX_val=prepare_X(df_val)\ny_pred=w0+ X_val.dot(w)\n\nscore=rmse(y_val, y_pred)\nscore","7f795426":"df_full_train=pd.concat([df_train, df_val])\ndf_full_train=df_full_train.reset_index(drop=True)\ndf_full_train","23328002":"X_full_train=prepare_X(df_full_train)","1c15ac8b":"X_full_train","f47c1944":"y_full_train= np.concatenate([y_train, y_val])\n\nw0, w= train_linear_regression_reg(X_full_train, y_full_train, r=0.001)\n\nw0, w","c9d8f994":"X_test=prepare_X(df_test)\ny_pred=w0+ X_test.dot(w)\n\nscore=rmse(y_test, y_pred)\nscore","d91b2ef1":"car=df_test.iloc[20].to_dict()\n\ncar","435f999b":"df_small=pd.DataFrame([car])\n","b501c2eb":"X_small=prepare_X(df_small)\n\ny_pred=w0+ X_small.dot(w)\n\ny_pred=y_pred[0]\ny_pred","63f4605a":"np.expm1(y_pred)","668da602":"(np.expm1(y_test[20])- np.expm1(y_pred))","eb0e1e4a":"## 2.15 Using the Model on Test Data","45587545":"## 2.14 Model Tuning","056dfd2a":"## 2.12 Categorical Variables","fdaf40b2":"## 2.13 Regularization","64f821d1":"#### Missing vaues","d83f09af":"# 2. LINEAR REGRESSION\n\nA model used to solve regression problems. Used to predict number","ac0b92ce":"Log transformation of our target variable y. Use .values to remain with a numpy array and not a Pandas series","712de1a1":"## 2.1 Linear Regression Vector Form","420b5d4e":"There is a slight change  .002 which shows that the doors feature is not useful.. Now let us look at the make feature","c5070b5d":"## 2.7 Training a linear regression model","9c05fe67":"## 2.10 Validating the  model","26659d86":"## 2.9 RMSE\n\nEVALUATION OF OUR REGRESSION MODELS","3174d209":"Our model shows that there is a slight difference between the predicted and actual price of the car model pick. A difference of $1692.","3b3201bb":"## 2.11 Simple Feature Engineering","814dcaab":"## 2.8 Car Price Baseline Model"}}