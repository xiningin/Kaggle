{"cell_type":{"2ad1cd23":"code","395e8d35":"code","1e699af5":"code","b611ea7c":"code","89a5e426":"code","34572b9c":"code","73304e00":"code","95b87066":"code","63e9e0a3":"code","d8b75cd3":"code","1a53daee":"code","df6e1419":"code","b2e127e2":"code","e3ba5a02":"code","95d04f10":"code","4bbb88d0":"code","2d88845e":"code","2aaeff0a":"code","2ed07c61":"code","bb5876bf":"markdown","82304199":"markdown","46e2c597":"markdown","3849db15":"markdown","f5b2b637":"markdown","6ae06348":"markdown","20e9d8fe":"markdown","6e1472fd":"markdown","10c6e8f9":"markdown","fe5d0c29":"markdown","d150219b":"markdown","356b0a0b":"markdown","307fb467":"markdown","8777a7cd":"markdown","5e2788c3":"markdown","4be5ff17":"markdown","18219f42":"markdown","de6e2f07":"markdown","88312f55":"markdown","1609845a":"markdown","731f48b9":"markdown","052f9aef":"markdown","422e8e18":"markdown","668109de":"markdown","a6df0f1a":"markdown","8b28f395":"markdown","f28986ec":"markdown","0f3707a2":"markdown","f81de9f8":"markdown"},"source":{"2ad1cd23":"!pip install --quiet scispacy","395e8d35":"!pip install --quiet https:\/\/s3-us-west-2.amazonaws.com\/ai2-s2-scispacy\/releases\/v0.2.4\/en_core_sci_md-0.2.4.tar.gz","1e699af5":"import pandas as pd\nfrom io import StringIO","b611ea7c":"riskfac = StringIO(\"\"\"Factor;Description\n    Pulmonary;Smoking, preexisting pulmonary disease\n    Infection;Coinfections determine whether coexisting respiratory or viral infections make the virus more transmissible or virulent and other comorbidities\n    Birth;Neonates and pregnant women\n    Socio-eco;Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences\n    Transmission;Transmission dynamics of the virus, including the basic reproductive number, incubation period, serial interval, modes of transmission and environmental factors\n    Severity;Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups\n    Susceptibility;Susceptibility of populations\n    Mitig-measures;Public health mitigation measures that could be effective for control\n    \"\"\")\n\nrf_base = pd.read_csv(riskfac, sep= \";\")\nrf_base","89a5e426":"# exporting factors and description to save it. rf_base.to_csv(r'\/2020-03-13\/rf_base.csv', index = False).\nrf_base.to_csv('rf_base.csv',index=False)","34572b9c":"data = pd.read_csv('..\/working\/rf_base.csv', delimiter=',', header=None, skiprows=1, names=['Factor','Description'])\n\ndescp = data[:8][['Description']];\ndescp['index'] = descp.index\ndescp","73304e00":"fact_name = data[:8][['Factor']];\nfact_name['index'] = fact_name.index\nfact_name","95b87066":"import scispacy\nimport spacy # needs to update spacy to load SciSpacy model.\nfrom spacy import displacy\n\n## need to install \"en_core_sci_md\" model https:\/\/allenai.github.io\/scispacy\/\n\nnlp = spacy.load('en_core_sci_md') # \"en_core_sci_md\" larger biodmedical vocab. word vector\n\ndef patternizing(dataF):\n    for i in range(8):\n        theme_sample = dataF[dataF['index'] == i].values[0][0]\n        \n        text = theme_sample\n        # print(theme_sample)\n\n        doc = nlp(text)\n       \n        # print(list(doc.sents))\n        # print(doc.ents)\n        \n        displacy.render(next(doc.sents), style='ent', jupyter=True)\npatternizing(descp)","63e9e0a3":"import spacy\nnlp = spacy.load(\"en_core_sci_md\")\n\ndef pRnize(dataF, indice):\n    \n    mastlist = []\n    \"\"\"\n    n_cov2 = ['covid19', 'covid-19',\n              'Covid19', 'Covid-19',\n              'COVID19', 'COVID-19',\n              'Sars-Cov-2', 'Sars-CoV-2', 'Sars-COV-2', 'Sars-cov-2',\n              'SARS-Cov-2', 'SARS-CoV-2', 'SARS-COV-2', 'SARS-cov-2',\n              'sars-Cov-2', 'sars-CoV-2', 'sars-COV-2', 'sars-cov-2',\n              'Sars Cov-2', 'Sars CoV-2', 'Sars COV-2', 'Sars cov-2',\n              'SARS Cov-2', 'SARS CoV-2', 'SARS COV-2', 'SARS cov-2',\n              'sars Cov-2', 'sars CoV-2', 'sars COV-2', 'sars cov-2',\n              'Sars-Cov 2', 'Sars-CoV 2', 'Sars-COV 2', 'Sars-cov 2',\n              'SARS-Cov 2', 'SARS-CoV 2', 'SARS-COV 2', 'SARS-cov 2',\n              'sars-Cov 2', 'sars-CoV 2', 'sars-COV 2', 'sars-cov 2',\n              'Sars Cov 2', 'Sars CoV 2', 'Sars COV 2', 'Sars cov 2',\n              'SARS Cov 2', 'SARS CoV 2', 'SARS COV 2', 'SARS cov 2',\n              'sars Cov 2', 'sars CoV 2', 'sars COV 2', 'sars cov 2',\n              'Sars Cov2', 'Sars CoV2', 'Sars COV2', 'Sars cov2',\n              'SARS Cov2', 'SARS CoV2', 'SARS COV2', 'SARS cov2',\n              'sars Cov2', 'sars CoV2', 'sars COV2', 'sars cov2',]\n    \"\"\"\n    for i in range(8):\n        factor = []\n        theme_sample = dataF[dataF['index'] == i].values[0][0]\n\n        text = theme_sample\n\n        doc = nlp(text) \n        \n        for item in doc.ents:\n            vocab = str(item).lower().strip('()')\n            factor.append(vocab)\n        \n        #for name in n_cov2:\n         #   factor.append(name)\n        mastlist.append(factor)\n    return mastlist[indice]\n\n# To test unquote\n#pRnize(descp, 0)","d8b75cd3":"def key_per_theme(dataF, word):\n    dic = {}\n    for i in range(8):\n        factor = dataF[dataF['index'] == i].values[0][0]\n        wordy = pRnize(word, i)\n    \n        dic[factor.strip()] = wordy\n    return dic","1a53daee":"key_per_theme(fact_name, descp)","df6e1419":"import os\nimport json\nimport glob","b2e127e2":"# json file access function\ndef data_access(path):\n    d_acc = {}\n    for i in glob.glob(path):\n        # link = os.path.normpath(i)\n        # print(link)\n        \n        # loading json file function\n        with open(os.path.normpath(i)) as json_file:\n            data = json.load(json_file)\n            paper_id = data['paper_id']\n            \n            # text = [item['text'] for item in data['body_text']]\n            for item in data['body_text']:\n                text = (item['text'])\n                \n                d_acc[paper_id] = text\n                \n    return d_acc","e3ba5a02":"# json files'path from each folder\n\n# path if needed to check just one article.\nbiomed_path = \"..\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\/\"  # bio and med archive\ncommu_path = \"..\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/\"\nnoncom_path = \"..\/input\/CORD-19-research-challenge\/noncomm_use_subset\/noncomm_use_subset\/\"\npmc_path = \"..\/input\/CORD-19-research-challenge\/pmc_custom_license\/pmc_custom_license\/\"\n\n# path if needed to check over all the folder.\nbiomed_fo = \"..\/input\/CORD-19-research-challenge\/biorxiv_medrxiv\/biorxiv_medrxiv\/*.json\"  # bio and med archive\ncommu_fo = \"..\/input\/CORD-19-research-challenge\/comm_use_subset\/comm_use_subset\/*.json\"\nnoncom_fo = \"..\/input\/CORD-19-research-challenge\/noncomm_use_subset\/noncomm_use_subset\/*.json\"\npmc_fo = \"..\/input\/CORD-19-research-challenge\/pmc_custom_license\/pmc_custom_license\/*.json\"","95d04f10":"metadata = pd.read_csv(\"..\/input\/CORD-19-research-challenge\/metadata.csv\")\nmetadata.head(5)","4bbb88d0":"def met_xiv(metadata, sha):\n    \n    sha = str(sha)\n        \n    for i, tracksha in enumerate(metadata['sha']):\n        if tracksha == sha:\n            print(\"Title\\n{} \\n\\nAuthors\\n{} \\n\\nSource: {} \\n\\nPaper ID: {}\\n\\ndoi: {} \\n\\npmcid: {} - pubmed_id: {} \\n\\nJournal: {}\\n\\n-linked to-\\n\\nMicrosoft Academic Paper ID: {} \\n\\nWHO #Covidence: {}\".format(\n                                                                                                                                                                                                 metadata['title'][i],\n                                                                                                                                                                                                 metadata['authors'][i],\n                                                                                                                                                                                                 metadata['source_x'][i],\n                                                                                                                                                                                                 metadata['sha'][i],\n                                                                                                                                                                                                 metadata['doi'][i],\n                                                                                                                                                                                                 metadata['pmcid'][i],\n                                                                                                                                                                                                 metadata['pubmed_id'][i],\n                                                                                                                                                                                                 \n                                                                                                                                                                                                 metadata['journal'][i],\n                                                                                                                                                                                                 \n                                                                                                                                                                                                 metadata['Microsoft Academic Paper ID'][i],\n                                                                                                                                                                                                 metadata['WHO #Covidence'][i]))\n# met_xiv(metadata, '0015023cc06b5362d332b3baf348d11567ca2fbb')","2d88845e":"# import spacy\nfrom spacy.matcher import Matcher\nfrom spacy.matcher import PhraseMatcher\n\nnlp = spacy.load(\"en_core_sci_md\")\n\ndef match_it(theme, xiv):\n    \n    phMatch = PhraseMatcher(nlp.vocab)\n    \n    article = data_access(xiv)\n    \n    \n    p = key_per_theme(fact_name, descp)[theme]\n    if len(p)==0:\n        print('no patterns')\n        \n    patterns = [nlp(i) for i in p]\n\n    phMatch.add(theme, None, *patterns)\n\n    for num_id in article:\n        paper_id = num_id\n        \n        doc = nlp(article[num_id])\n        \n        mat = phMatch(doc)\n        # print(mat)\n        \n        for match_id, start, end in mat:\n            string_id = nlp.vocab.strings[match_id]\n            if len(string_id) == 0:\n                print(\"No Result\")\n            else:\n                span = doc[start:end]\n                spant = doc[(start) : (end+20)]\n\n                print(\"\\nTHEME: \\033[34m{}\\033[00m - KEYWORDS: \\033[32m{}\\033[00m\\n\\nQUOTE: \\033[0;37;40m{}\\033[00m\\n\\nPAPER_ID:{}\".format(string_id,\n                                                                                                                     span.text, spant.text, paper_id))\n\n            \n                print()","2aaeff0a":"match_it('Susceptibility', biomed_fo)","2ed07c61":"met_xiv(metadata,'564f8823050b52b5f5c36638ac1ae07557963f36')","bb5876bf":"### Data extraction from Metadata doc\n\nThis additional infos on article that are included into the Metadata doc.<br>\nsha \/ source_x \/ title \/ doi \/ pmcid \/ pubmed_id \/ authors \/ journal \/ Microsot A.P ID \/ Who # covidence","82304199":"# The Appproach","46e2c597":"**Information** \n1. **Metadata** for papers from these sources are combined: CZI, PMC, BioRxiv\/MedRxiv.\n(total records 29500)\n    - **CZI** 1236 records\n    - **PMC** 27337\n    - **bioRxiv** 566\n    - **medRxiv** 361\n2. 17K of the paper records have PDFs and the hash of the PDFs are in 'sha'<br>\n3. For PMC sourced papers, one paper's metadata can be associated with one or more PDFs\/shas under that paper - a PDF\/sha correponding to the main article, and possibly additional PDF\/shas corresponding to supporting materials for the article.<br>\n4. 13K of the PDFs were processed with fulltext ('has_full_text'=True)<br>\n5. Various 'keys' are populated with the metadata:\n    - 'pmcid': populated for all PMC paper records (27337 non null)\n\t- 'doi': populated for all BioRxiv\/MedRxiv paper records and most of the other records (26357 non null)\n\t- 'WHO #Covidence': populated for all CZI records and none of the other records (1236 non null)\n\t- 'pubmed_id': populated for some of the records\n\t- 'Microsoft Academic Paper ID': populated for some of the records\n---\nGlossary:<br>\n**Chan Zuckerberg Initiative (CZI)**<br>\n**PubMed Central (PMC)** is a free digital repository that archives publicly accessible full-text scholarly articles that have been published within the biomedical and life sciences journal literature.<br>\n**BioRxiv** (pronounced \"bio-archive\") is an open access preprint repository for the biological sciences<br>\n**medRxiv. medRxiv** (pronounced med archive) is a preprint service for the medicine and health sciences and provides a free online platform for researchers to share, comment, and receive feedback on their work. Information among scientists spreads slowly, and often incompletely.\n\n---\n**The provided data are organized as followed**<br>\n- Commercial use subset (includes PMC content) -- 9118 full text (new: 128), 183Mb\n- Non-commercial use subset (includes PMC content) -- 2353 full text (new: 385), 41Mb\n- Custom license subset -- 16959 full text (new: 15533), 345Mb\n- bioRxiv\/medRxiv subset (pre-prints that are not peer reviewed) -- 885 full text (new: 110), 14Mb\n- Metadata file -- 60Mb\n\n  #### [More details on dataset](https:\/\/pages.semanticscholar.org\/coronavirus-research)","3849db15":"### Transform the required themes","f5b2b637":"### Loading the themes' descriptions","6ae06348":"---","20e9d8fe":"Installing SciSpacy and its specific 'en_core_sci_md' model for later utilization.<br>\n<br>\nMany thanks to [Marek Grzenkowicz](https:\/\/www.kaggle.com\/chopeen) for these two followed '!pip install --quiet' lines as even if my notebook was running perfectly within my Kaggle account environment, when committed it was not the case anymore. Now, everyone can read it smoothlessly.","6e1472fd":"### Dictionnary {Theme: patterns} ","10c6e8f9":"### These are the exact spelling of the themes that has to be used. Each of them contains the keywords we had within the initial briefing.\n\n- Pulmonary\n- Infection\n- Birth\n- Socio-eco\n- Transmission\n- Severity\n- Susceptibility\n- mitig-measures\n\n### These are the exact spelling of the Xiv folders path which contains the 29500 articles.\n\n- biomed_fo: bioRxiv\/medRxiv subset (pre-prints that are not peer reviewed)\n- commu_fo: Commercial use subset (includes PMC content)\n- noncom_fo: Non-commercial use subset (includes PMC content)\n- pmc_fo: Custom license subset","fe5d0c29":"---","d150219b":"### Loading the themes' designation","356b0a0b":"### Defining Patterns","307fb467":"# Retrieve the text from articles (xiv)\nrecall that the xiv are dispatched among different sources: Biomed, Commercial, ...","8777a7cd":"#### Preview of Themes","5e2788c3":"---","4be5ff17":"---","18219f42":"### Additional info about the paper found.\nWe can notice that the PAPER_ID: 564f8823050b52b5f5c36638ac1ae07557963f36 seems to match a lot with under this query.<br>\nThen, to obtain more info about the said article run the met_xiv function with the related PAPER_ID:","de6e2f07":"## Patternizing the themes\nThis is what we have to find among the 29 500 archives.","88312f55":"# Matching Part\n### Match the theme within a folder of xiv's.\ndisplay Theme \/ Keywords \/ Paper_id \/ Quote","1609845a":"### Initial form of the themes:\n> What do we know about COVID-19 risk factors? What have we learned from epidemiological studies?<br>\n<br>Specifically, we want to know what the literature reports about:\n1. Data on potential risks factors\n    - Smoking, pre-existing pulmonary disease\n    - Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other co-morbidities\n    - Neonates and pregnant women\n    - Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.\n2. Transmission dynamics of the virus, including the basic reproductive number, incubation period, serial interval, modes of transmission and environmental factors\n3. Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups\n4. Susceptibility of populations\n5. Public health mitigation measures that could be effective for control","731f48b9":"### Patterns into lists and then related to their name Theme.","052f9aef":"Patterns are ready!","422e8e18":"### Make the query of the desired theme over folder of xiv.","668109de":"### About the data","a6df0f1a":"### Keeping track of record of the themes by exporting them as .csv","8b28f395":"**Here none of the COVID-19 designation are not been include in the patterns.<br>\nIf needed, just unquote the list and the loop related to n_cov2.**","f28986ec":"# COVID-19 Open Research Dataset Challenge (CORD-19)\nAn AI challenge with AI2, CZI, MSR, Georgetown, NIH & The White House\n\n### Task: What do we know about COVID-19 risk factors?","0f3707a2":"## Tokenization of the themes with [ScispaCy package](https:\/\/allenai.github.io\/scispacy\/)\nPreview of themes after preprocessing\nSci-SpaCy are models for biomedical text processing made by Allen Institute AI2","f81de9f8":"This is a straight forward approach that used Allen Institute For AI SciSpacy model.<br>\n- Step 1: transform the quoted factors (see. initial brief) in patterns via SciSpaCy. They will be called \"Theme\".<br>\n- Step 2: then, match the Themes among the 29500 articles (XIV) due to SpaCy model. Here, we retrieve THEME, KEYWORD, PAPER_ID.<br>\n- Step 3: from there TITLE, AUTHORS, SOURCE, ... are available if the data are available in the Metadata document.\n<br><br>\n1. Pros:\n- provide quote, paper id, title, authors from article when the wanted 'Theme' is detected,\n- straight forward approach especially in the rush context,\n- use of models from Allen Institute of AI,\n- prune the volume of documents when searching a specific topic.\n<br><br>\n2. Cons:\n- basic approach: does not provide text summarization nor sentiment analysis,\n- when matching\/extraction actions are done, some manual actions are required."}}