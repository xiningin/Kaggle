{"cell_type":{"84413508":"code","3285eed3":"code","98f121ae":"code","791449b5":"code","bd94f83d":"code","01a42e73":"code","4d3a380e":"code","bfb5159d":"code","f32a0ab2":"code","70cf7175":"code","12243be3":"code","2f50156b":"code","2f74faa4":"code","21bc4625":"code","8066fa00":"code","7c8d4dc9":"code","e32b7c78":"code","0b2d1f57":"code","8a174527":"code","9f2ad8ea":"markdown","d4ff0025":"markdown","d37084c2":"markdown","91d6000f":"markdown","cfd0b13d":"markdown","dacaa11d":"markdown","1c7b8f25":"markdown","161de910":"markdown","170f5308":"markdown","e92b300b":"markdown","79e9e9b0":"markdown","1afe247d":"markdown","bd25a858":"markdown","f91d206e":"markdown"},"source":{"84413508":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","3285eed3":"import pandas as pd\npd.set_option('display.max_columns',200) \npd.set_option('display.max_rows',100)","98f121ae":"train_data = pd.read_csv(\"..\/input\/home-data-for-ml-course\/train.csv\")\ntest_data = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv')\ntrain = train_data.copy()\ntest = test_data.copy()","791449b5":"train.shape","bd94f83d":"test.shape","01a42e73":"train.head()","4d3a380e":"test.head()","bfb5159d":"train.info()","f32a0ab2":"test.info()","70cf7175":"train.isnull().sum()","12243be3":"test.isnull().sum()","2f50156b":"train_x = train.drop('SalePrice', axis=1)\ntrain_y = train['SalePrice']\ntest_x = test.copy()","2f74faa4":"train_x.drop(['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1, inplace=True)\ntest_x.drop(['Id','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], axis=1, inplace=True)","21bc4625":"categorical_columns = set(train_x.select_dtypes(include=[object]))\nfor column in train_x.columns:\n    if column in categorical_columns:\n        train_x[column].fillna('Undefined', inplace=True)\n        test_x[column].fillna('Undefined', inplace=True)\n    else:\n        train_mean = train[column].mean()\n        train_x[column].fillna(train_mean, inplace=True)\n        test_x[column].fillna(train_mean, inplace=True)","8066fa00":"from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nencoder.fit(train_x[categorical_columns]);\none_hot_columns = encoder.get_feature_names(list(categorical_columns))\ntrain_one_hot = pd.DataFrame(encoder.transform(train_x[categorical_columns]), columns=one_hot_columns)\ntest_one_hot = pd.DataFrame(encoder.transform(test_x[categorical_columns]), columns=one_hot_columns)\n\ntrain_x.drop(columns=categorical_columns, axis=1, inplace=True)\ntest_x.drop(columns=categorical_columns, axis=1, inplace=True)\n\ntrain_x[train_one_hot.columns] = train_one_hot\ntest_x[train_one_hot.columns] = test_one_hot","7c8d4dc9":"train_x.head()","e32b7c78":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nscaler = StandardScaler()\nscaler.fit(train_x)\ntrain_x = pd.DataFrame(scaler.transform(train_x), columns=train_x.columns)\ntest_x = pd.DataFrame(scaler.transform(test_x), columns=test_x.columns)","0b2d1f57":"from sklearn.ensemble import GradientBoostingRegressor\nmodel = GradientBoostingRegressor(random_state=1, n_estimators=200, min_samples_split=3)\n\nmodel.fit(train_x, train_y)","8a174527":"test_preds = model.predict(test_x)\noutput = pd.DataFrame({'Id': test.Id,\n                       'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)\noutput.head()","9f2ad8ea":"### count the numbers of missing values.We can see that some features miss many values,they have no help for model train.They should be dropped from datasset.","d4ff0025":"### import the train and test data.","d37084c2":"### import some data science and visualization library.","91d6000f":"## model train","cfd0b13d":"### build train set and test set.","dacaa11d":"### fill in the missing value.\n#### for object type,think of null value as a category `Undefined`.\n#### for non-object type, fill with mean value.","1c7b8f25":" ### set display maximum of columns and row.","161de910":"### encoder for categorical coumns.","170f5308":"### Normalization ","e92b300b":"### some basic informations about train and test data.","79e9e9b0":"### It's a simple model, but reach to the top 3% ranking.If need higher ranking, You can do further analysis on this basis.","1afe247d":"### size of train and test data","bd25a858":"### drop invalid features,`Id`,`Alley`,and so on.","f91d206e":"## data output"}}