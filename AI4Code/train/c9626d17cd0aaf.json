{"cell_type":{"8aeababf":"code","37888a42":"code","c66023e2":"code","3384b720":"code","2f1d210d":"code","471efc69":"code","5a78c304":"code","7d5faf72":"markdown","f7512eb6":"markdown","a3c7969a":"markdown","ceaa89f5":"markdown","ab8a6cbd":"markdown"},"source":{"8aeababf":"import numpy as np\nimport tensorflow as tf\nprint(\"tf.__version__: \", tf.__version__)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport pandas as pd # for load MNIST\nfrom sklearn.model_selection import train_test_split # for Validation","37888a42":"!pip install StealthFlow==0.0.9\nfrom stealthflow.resnest import ResNeStBlock\nfrom stealthflow.tf_layers import MyBlock","c66023e2":"class MNIST():\n    def __init__(self):\n\n        train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\n        test= pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\n\n        X_train = (train.iloc[:,1:].values).reshape(-1, 28, 28, 1).astype(np.float32) \/ 255.0 \n        y_train = train.iloc[:,0].values.astype('int32') #tf.keras.utils.to_categorical()\n        \n        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n        \n        self.X_test = test.values.reshape(-1, 28, 28, 1).astype(np.float32) \/ 255.0\n\nmnist = MNIST()\nprint(mnist.X_train.max(), mnist.X_train.min())\nprint(mnist.X_train.shape)\nprint(mnist.y_train.shape)\nprint(mnist.X_val.shape)\nprint(mnist.y_val.shape)\nprint(mnist.X_test.shape)\ndel mnist","3384b720":"class ResNeSt:\n    def __init__(self, params):\n        self.params = params\n        self.myblock = MyBlock()        \n        self.build_model()\n\n    def build_model(self):\n        self.model = self.define_resnest()\n        self.model.compile(loss = self.params.LOSS, optimizer = self.params.OPTIMIZER, metrics = self.params.METRICS)\n        tf.keras.utils.plot_model(self.model, to_file='architecture.png', show_shapes=True)\n\n    def define_resnest(self):\n        x_in = x = tf.keras.layers.Input(shape=self.params.INPUT_SHAPE)\n\n        x = self.myblock.conv_3x3_batch_relu(x, 16)\n        x = ResNeStBlock(radix=1, cardinality=1, bottleneck=16, ratio=4)(x)\n        \n        x = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(x)\n        \n        x = self.myblock.conv_3x3_batch_relu(x, 64)\n        x = ResNeStBlock(radix=2, cardinality=2, bottleneck=32, ratio=4)(x)\n\n        x = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(x)\n\n        x = self.myblock.conv_3x3_batch_relu(x, 128)\n        x = ResNeStBlock(radix=2, cardinality=4, bottleneck=64, ratio=4)(x)\n        \n        y = self.myblock.classification_MLP(x, num_classes=10, num_units=1024, dropout=0.5)\n        #y = self.myblock.classification_GAP(x, num_classes=10)\n        \n        model = tf.keras.Model(inputs=x_in, outputs=y)\n        return model","2f1d210d":"class Params():\n    def __init__(self):\n        self.EPOCHS = 50\n        self.BATCH_SIZE = 32\n        self.BATCH_SIZE_test = 32\n\n        self.LR_base = 0.05 * (self.BATCH_SIZE \/ 256)\n        self.scheduling_on = [int(self.EPOCHS*0.1), int(self.EPOCHS*0.6), int(self.EPOCHS*0.8)]\n        self.scheduling_decay = [0.2, 0.04]\n        self.LR_scheduler = tf.keras.callbacks.LearningRateScheduler(self.schedule, verbose=1)\n        \n        self.EarlyStopping = tf.keras.callbacks.EarlyStopping(\n                                    monitor='val_sparse_categorical_accuracy', min_delta=0.0001, patience=10, verbose=0, mode='auto',\n                                    baseline=None, restore_best_weights=True\n                                )\n\n        self.OPTIMIZER = tf.keras.optimizers.SGD(learning_rate=self.LR_base, momentum=0.9, nesterov=True, name=\"SGD_momentum\") # and momentum of 0.9,(5.1 Implementation Details)\n        self.LOSS = ['sparse_categorical_crossentropy']\n        self.METRICS = [tf.keras.metrics.SparseCategoricalAccuracy()]\n\n        self.INPUT_SHAPE = (28, 28, 1)\n\n    def schedule(self, epoch):\n        if(epoch < self.scheduling_on[0]):\n            return self.LR_base * (epoch+1)\/self.scheduling_on[0]\n        elif(epoch < self.scheduling_on[1]):\n            return self.LR_base\n        elif(epoch < self.scheduling_on[2]):\n            return self.LR_base * self.scheduling_decay[0]\n        else:\n            return self.LR_base * self.scheduling_decay[1]","471efc69":"class Trainer():\n    def __init__(self):\n        self.mnist = MNIST()\n        self.params = Params()\n        self.resnest = ResNeSt(self.params)\n    \n    def train(self):\n\n        self.resnest.model.fit(self.mnist.X_train, self.mnist.y_train\n                          , validation_data=(self.mnist.X_val, self.mnist.y_val)\n                          , epochs=self.params.EPOCHS\n                          , batch_size=self.params.BATCH_SIZE\n                          , callbacks=[self.params.LR_scheduler, self.params.EarlyStopping]\n                         )\n        \n        val_loss, val_acc = self.resnest.model.evaluate(self.mnist.X_val, self.mnist.y_val, batch_size=self.params.BATCH_SIZE_test)\n        print(val_loss, val_acc)\n\n    def predict(self, output_file):\n        \n        y_hat = self.resnest.model.predict(self.mnist.X_test, batch_size=self.params.BATCH_SIZE_test)\n        y_pred = np.argmax(y_hat,axis=1)\n        \n        submissions = pd.DataFrame({\n                                  \"ImageId\": list(range(1, len(y_pred)+1))\n                                , \"Label\": y_pred\n                                })\n        submissions.to_csv(\"submission.csv\", index=False, header=True)","5a78c304":"trainer = Trainer()\ntrainer.train()\ntrainer.predict(output_file=\"submission.csv\")","7d5faf72":"# Set Parameters","f7512eb6":"# import ResNeSt Module","a3c7969a":"# Run","ceaa89f5":"# Define ResNeSt class","ab8a6cbd":"# Set Dataset"}}