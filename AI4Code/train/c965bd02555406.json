{"cell_type":{"c247d827":"code","2abc3ede":"code","508fedd1":"code","943215ff":"code","ab18be02":"code","c95aa2d9":"code","dc2177f4":"code","8fec00e2":"code","f2f32f0d":"code","cc15ac03":"code","89ca9402":"code","f4baab25":"code","f217c214":"code","bd9aa26c":"code","b5bc4eda":"code","c09df535":"code","f9059eb0":"code","04412587":"code","e2e76b4d":"markdown","bbaa3ac5":"markdown","6a7e668c":"markdown","97bfc2d7":"markdown","0a28741a":"markdown","99207bb9":"markdown","acd161f6":"markdown","af0dead0":"markdown","3e1b91e9":"markdown","1b36c31f":"markdown"},"source":{"c247d827":"!pip install mtcnn   # \u5b89\u88c5\u4eba\u8138\u68c0\u6d4b\u4e0e\u5bf9\u9f50\u5e93MTCNN","2abc3ede":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom mtcnn import MTCNN\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.models import load_model\nfrom PIL import Image\nimport os\nfrom os.path import isdir","508fedd1":"%%time\n# \u7528MTCNN\u68c0\u6d4b\u56fe\u50cf\u6587\u4ef6\u4e2d\u7684\u4eba\u8138\uff0c\u8f6c\u6362\u4e3a\u6307\u5b9a\u5c3a\u5bf8\uff0c\u8fd4\u56de\u4eba\u8138\u56fe\u50cf\u7684numpy\u77e9\u9635\u683c\u5f0f\ndef extract_face(filename, required_size=(160, 160)):\n    image = Image.open(filename)  # \u6253\u5f00\u56fe\u50cf\u6587\u4ef6\n    image = image.convert('RGB')  # \u989c\u8272\u6a21\u5f0f\n    image = np.asarray(image) # \u56fe\u50cf\u8f6c\u6362\u4e3anumpy\u77e9\u9635\u683c\u5f0f\n    detector = MTCNN()  # \u4f7f\u7528\u9ed8\u8ba4\u6743\u91cd\u521b\u5efaMTCNN\u4eba\u8138\u68c0\u6d4b\u5668\n    results = detector.detect_faces(image)  #\u4eba\u8138\u68c0\u6d4b\n    x1, y1, width, height = results[0]['box'] #\u7b2c\u4e00\u5f20\u8138\u7684 bounding_box\n    x1, y1 = abs(x1), abs(y1)\n    x2, y2 = x1 + width, y1 + height \n    face = image[y1:y2, x1:x2] \n    image = Image.fromarray(face)\n    image = image.resize(required_size) # \u5927\u5c0f\u8f6c\u6362\n    face_array = np.asarray(image)\n    return face_array\n\n# \u63d0\u53d6\u6587\u4ef6\u5939\u5185\u6240\u6709\u56fe\u7247\u6587\u4ef6\u7684\u4eba\u8138\u6570\u636e\uff0c\u8fd4\u56de\u4eba\u8138\u6570\u636e\u5217\u8868\ndef load_face(dir):\n    faces = list()\n    for filename in os.listdir(dir):\n        path = dir + filename\n        face = extract_face(path)\n        faces.append(face)\n    return faces\n\n# \u83b7\u53d6\u6570\u636e\u96c6\u548c\u6807\u7b7e\uff08\u8bad\u7ec3\u96c6\u6216\u9a8c\u8bc1\u96c6\uff09\ndef load_dataset(directory):\n    X, y = list(), list()\n    for subdir in os.listdir(directory): #\u6587\u4ef6\u5939\u540d\u5c31\u662f\u6807\u7b7e\u540d\n        path = directory + subdir + '\/'\n        if not isdir(path):\n            continue\n        faces = load_face(path)  # \u5f53\u524d\u76ee\u5f55\u4e0b\u6240\u6709\u7684\u4eba\u8138\n        labels = [subdir for _ in range(len(faces))]\n        print(f'\u6807\u7b7e\uff1a{subdir} \u52a0\u8f7d\u4e86 {len(faces)} \u4e2a\u6837\u672c')\n        X.extend(faces)  # \u7279\u5f81\u96c6\n        y.extend(labels) # \u6807\u7b7e\u96c6\uff0c\u6807\u7b7e\u4e3a\u4eba\u540d\u5b57\u7b26\u4e32\u683c\u5f0f\n    return np.asarray(X), np.asarray(y)\n\n#\u8bfb\u53d6\u8bad\u7ec3\u96c6\ntrainX, trainy = load_dataset('..\/input\/5-celebrity-faces-dataset\/data\/train\/')\nprint(f'\u8bad\u7ec3\u96c6\u7279\u5f81\u77e9\u9635\u7684\u7ef4\u5ea6\uff1a{trainX.shape},\u6807\u7b7e\u7684\u7ef4\u5ea6\uff1a{trainy.shape}\\n')\n#\u8bfb\u53d6\u9a8c\u8bc1\u96c6\nvalX, valy = load_dataset('..\/input\/5-celebrity-faces-dataset\/data\/val\/')\nprint(f'\u9a8c\u8bc1\u96c6\u7279\u5f81\u77e9\u9635\u7684\u7ef4\u5ea6\uff1a{valX.shape},\u6807\u7b7e\u7684\u7ef4\u5ea6\uff1a{valy.shape}')","943215ff":"# \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\nfacenet_model = load_model('..\/input\/facenet-keras\/facenet_keras.h5')","ab18be02":"print(facenet_model.input)","c95aa2d9":"print(facenet_model.output)","dc2177f4":"# \u7528FaceNet\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u6307\u5b9a\u7684\u4eba\u8138\u6570\u636e\u505a\u7279\u5f81\u63d0\u53d6\uff0c\u8fd4\u56de\u4eba\u8138\u5d4c\u5165\u5411\u91cf\ndef get_embedding(model, face):\n    face = face.astype('float32')\n    mean, std = face.mean(), face.std()\n    face = (face-mean)\/std # \u6570\u636e\u6807\u51c6\u5316\u4e3a\u5747\u503c0\uff0c\u6807\u51c6\u5dee\u4e3a1\u7684\u5206\u5e03\n    sample = np.expand_dims(face, axis=0) #\u4e09\u7ef4\u53d8\u56db\u7ef4\n    yhat = model.predict(sample) #\u4eba\u8138\u6570\u636e\u7f16\u7801\u4e3a\u7279\u5f81\u5411\u91cf\n    return yhat[0]","8fec00e2":"%%time\n#\u8bad\u7ec3\u96c6\u4e2d\u6240\u6709\u7684\u4eba\u8138\u8f6c\u4e3a\u5d4c\u5165\u5411\u91cf\u77e9\u9635\nemdTrainX = list()\nfor face in trainX:\n    emd = get_embedding(facenet_model, face)\n    emdTrainX.append(emd)\nemdTrainX = np.asarray(emdTrainX) # \u8f6c\u4e3anumpy\u6570\u7ec4\nprint(f'\u8bad\u7ec3\u96c6\u7279\u5f81\u63d0\u53d6\u77e9\u9635\u7ef4\u5ea6\uff1a{emdTrainX.shape}')","f2f32f0d":"emdTrainX[0]","cc15ac03":"%%time\n#\u9a8c\u8bc1\u96c6\u4e2d\u6240\u6709\u7684\u4eba\u8138\u8f6c\u4e3a\u5d4c\u5165\u5411\u91cf\u77e9\u9635\nemdValX = list()\nfor face in valX:\n    emd = get_embedding(facenet_model, face)\n    emdValX.append(emd)\nemdValX = np.asarray(emdValX) #\u8f6c\u4e3a numpy \u6570\u7ec4\nprint(f'\u9a8c\u8bc1\u96c6\u7279\u5f81\u63d0\u53d6\u77e9\u9635\u7ef4\u5ea6\uff1a{emdValX.shape}')","89ca9402":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\n# \u6570\u636e\u96c6\u7279\u5f81\u6807\u51c6\u5316\nin_encoder = Normalizer(norm='l2')\nemdTrainX_norm = in_encoder.transform(emdTrainX)\nemdValX_norm = in_encoder.transform(emdValX)\n","f4baab25":"emdTrainX_norm[0]","f217c214":"# \u6570\u636e\u96c6\u6807\u7b7e\u7f16\u7801\nout_encoder = LabelEncoder()\nout_encoder.fit(trainy)\ntrainy_enc = out_encoder.transform(trainy) # \u8bad\u7ec3\u96c6\u6807\u7b7e\u7f16\u7801\nvaly_enc = out_encoder.transform(valy) # \u9a8c\u8bc1\u96c6\u6807\u7b7e\u7f16\u7801","bd9aa26c":"trainy","b5bc4eda":"trainy_enc","c09df535":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n# \u5b9a\u4e49SVC\u5206\u7c7b\u6a21\u578b\nmodel = SVC(kernel='linear', probability=True)\n# \u6a21\u578b\u8bad\u7ec3\nmodel.fit(emdTrainX_norm, trainy_enc)","f9059eb0":"# \u6a21\u578b\u8bc4\u4f30\nyhat_train = model.predict(emdTrainX_norm)\nyhat_val = model.predict(emdValX_norm)\nscore_train = accuracy_score(trainy_enc, yhat_train)\nscore_val = accuracy_score(valy_enc, yhat_val)\nprint(f'\u8bad\u7ec3\u96c6\u51c6\u786e\u7387\uff1a{score_train*100}\uff0c\u9a8c\u8bc1\u96c6\u51c6\u786e\u7387\uff1a{score_val*100}' )","04412587":"from random import choice\n# \u4ece\u9a8c\u8bc1\u96c6\u968f\u673a\u9009\u53d6\u4e00\u5f20\u4eba\u8138\u56fe\u50cf\nselection = choice([i for i in range(valX.shape[0])])\nrandom_face = valX[selection]  \nrandom_face_emd = emdValX_norm[selection] # \u83b7\u53d6\u8be5\u4eba\u8138\u7684\u7f16\u7801\u5411\u91cf\nrandom_face_class = valy_enc[selection] # \u83b7\u53d6\u8be5\u4eba\u8138\u7684\u6807\u7b7e\uff08\u6570\u503c\u578b\uff09\nrandom_face_name = out_encoder.inverse_transform([random_face_class]) #\u83b7\u53d6\u8be5\u4eba\u8138\u7684\u6807\u7b7e\n\nsamples = np.expand_dims(random_face_emd, axis=0) #\u4e09\u7ef4\u53d8\u56db\u7ef4\nyhat_class = model.predict(samples) #\u4f7f\u7528SVM\u5206\u7c7b\nyhat_prob = model.predict_proba(samples) #\u83b7\u53d6\u6bcf\u4e00\u7c7b\u7684\u6982\u7387\nclass_index = yhat_class[0] #\u83b7\u53d6\u5206\u7c7b\uff08\u6570\u503c\u578b\uff09\nclass_probability = yhat_prob[0,class_index] * 100  #\u5206\u7c7b\u7684\u6982\u7387\n\npredict_names = out_encoder.inverse_transform(yhat_class) #\u83b7\u53d6\u5206\u7c7b\u6807\u7b7e\nall_names = out_encoder.inverse_transform([0,1,2,3,4]) #\u6240\u6709\u79cd\u7c7b\u7684\u6807\u7b7e\nprint('\u9884\u6d4b\u7ed3\u679c\u6982\u7387\u5206\u5e03: \\n%s \\n%s' % (all_names, yhat_prob[0]*100))\nprint('\\n\u6700\u6709\u53ef\u80fd\u662f: %s\\n' % random_face_name[0])\nplt.imshow(random_face)\ntitle = '%s (%.3f)' % (predict_names[0], class_probability)\nplt.title(title)\nplt.show()\n","e2e76b4d":"\u6570\u636e\u96c6\u91c7\u75285-celebrity-faces-dataset\u3002\u5305\u542b\u4e94\u4e2a\u4eba\u7684\u8bad\u7ec3\u6837\u672c\u4e0e\u9a8c\u8bc1\u6837\u672c\u3002\u6587\u4ef6\u5939\u540d\u79f0\u4e3a\u4eba\u540d\uff0c\u53ef\u4f5c\u4e3a\u6570\u636e\u96c6\u7684\u6807\u7b7e\u3002","bbaa3ac5":"## 4 \u7528SVM\u6a21\u578b\u5206\u7c7b\uff0c\u8fdb\u884c\u4eba\u8138\u8bc6\u522b","6a7e668c":"## 5 \u968f\u673a\u6d4b\u8bd5","97bfc2d7":"\u672c\u6848\u4f8b\u91c7\u7528Hiroki Taniai\u57fa\u4e8e MS-Celeb-1M \u6570\u636e\u96c6\u63d0\u4f9b\u7684 FaceNet \u9884\u8bad\u7ec3\u6a21\u578b\u3002 \u8be5\u6a21\u578b\u8981\u6c42\u8f93\u5165160\u00d7160\u7684RGB\u5f69\u8272\u56fe\u50cf\u3002\n\u6a21\u578b\u53ef\u4ece\u4ee5\u4e0b\u5730\u5740\u4e0b\u8f7d\uff1ahttps:\/\/drive.google.com\/open?id=1pwQ3H4aJ8a6yyJHZkTwtjcL4wYWQb7bn","0a28741a":"# Face Recognition based on MTCNN+FaceNet+SVM","99207bb9":"## 1 \u5e93\u5bfc\u5165","acd161f6":"## 2 \u63d0\u53d6\u8bad\u7ec3\u96c6\u4e0e\u9a8c\u8bc1\u96c6","af0dead0":"## 3 \u7528FaceNet\u63d0\u53d6\u7279\u5f81","3e1b91e9":"\u89c2\u5bdf\u7b2c\u4e00\u4e2a\u6837\u672c\u7279\u5f81\u5411\u91cf\u6807\u51c6\u5316\u7684\u7ed3\u679c","1b36c31f":"\u89c2\u5bdf\u8bad\u7ec3\u96c6\u6837\u672c\u63d0\u53d6\u7684\u5d4c\u5165\u5411\u91cf\uff0c128\u7ef4"}}