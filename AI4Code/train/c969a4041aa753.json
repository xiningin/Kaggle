{"cell_type":{"78ecb2f5":"code","bea9e4e4":"code","2ee16f28":"code","466d1244":"code","e59e4add":"code","f3a8511d":"code","21dbd0c4":"code","b8d0cdc9":"code","0f326540":"code","b97a7216":"code","1e8f0733":"code","d8854fc6":"code","8b4ffd2c":"code","72871375":"code","e1229315":"code","472f4da1":"code","9fb9bf1a":"code","4d8afcdb":"code","158af9a1":"code","50c523c1":"code","98eed970":"code","d01444f0":"code","1fb63b00":"code","3498536a":"code","1af00f25":"code","31f084d9":"code","d8c47fbc":"code","cf0d6b39":"code","c3ba2c67":"code","3a07b3b0":"code","000d5bdf":"code","d21b8ef1":"code","30d36c73":"code","babc35d4":"code","96f3b8b4":"code","f3e6fe84":"code","f8d1fccc":"code","3bd381fc":"code","b66277a9":"code","3bdd60c2":"code","f5b29eae":"code","98643014":"code","ca0f555e":"code","45eb9c03":"code","7209f6d3":"code","4fa911e7":"code","997d9a1c":"code","f4d153b5":"code","7a107196":"code","53296f6f":"code","c26fa995":"code","6ab926da":"code","8fe3def5":"code","0b435e76":"markdown","d600cdf5":"markdown","7f3a8d19":"markdown","9b7f7033":"markdown","d7670419":"markdown","cc88cf79":"markdown","bd3e5f4f":"markdown","c8c3e703":"markdown","728a6488":"markdown","4dfd5f89":"markdown","b2343d6e":"markdown","39735949":"markdown","e19e65c1":"markdown","fe0743ef":"markdown","a5066217":"markdown","f099256a":"markdown","02538e24":"markdown","6b4424b5":"markdown","33d088e6":"markdown","ca823b5f":"markdown","95e4d7f2":"markdown","345a0329":"markdown","cec5cbe0":"markdown"},"source":{"78ecb2f5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n## Setting max displayed rows to 500, in order to display the full output of any command \npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","bea9e4e4":"# read the data \ndf = pd.read_csv(\"..\/input\/ames-housing-data\/Ames_Housing_Data.csv\")","2ee16f28":"df.head()","466d1244":"df.columns","e59e4add":"df.describe()","f3a8511d":"df.info()","21dbd0c4":"df.corr()[\"SalePrice\"].sort_values(ascending = False)","b8d0cdc9":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.scatterplot(data = df, x = \"Overall Qual\", y = \"SalePrice\");","0f326540":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.scatterplot(data = df, x = \"Gr Liv Area\", y = \"SalePrice\");","b97a7216":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.scatterplot(data = df, x = \"Total Bsmt SF\", y = \"SalePrice\");","1e8f0733":"df[(df[\"SalePrice\"] < 200000) & (df[\"Overall Qual\"] > 8)]","d8854fc6":"df[(df[\"SalePrice\"] < 200000) & (df[\"Overall Qual\"] > 8) & (df[\"Gr Liv Area\"] > 4000)]","8b4ffd2c":"drop_index = df[(df[\"SalePrice\"] < 200000) & (df[\"Overall Qual\"] > 8) & (df[\"Gr Liv Area\"] > 4000)].index","72871375":"df = df.drop(drop_index, axis = 0)","e1229315":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.scatterplot(data = df, x = \"Gr Liv Area\", y = \"SalePrice\");","472f4da1":"df.head()","9fb9bf1a":"df = df.drop(\"PID\", axis = 1)","4d8afcdb":"df.info()","158af9a1":"## lets create a functions that can be used for any future data\ndef percent_missing_data(df):\n    missing_count = df.isna().sum().sort_values(ascending = False)\n    missing_percent = 100 * df.isna().sum().sort_values(ascending = False) \/ len(df)\n    missing_count = pd.DataFrame(missing_count[missing_count > 0])\n    missing_percent = pd.DataFrame(missing_percent[missing_percent > 0])\n    missing_table = pd.concat([missing_count,missing_percent], axis = 1)\n    missing_table.columns = [\"missing_count\", \"missing_percent\"]\n    \n    return missing_table","50c523c1":"percent_nan = percent_missing_data(df)\npercent_nan","98eed970":"plt.figure(figsize = (8,4), dpi = 100)\nsns.barplot(x = percent_nan.index, y = percent_nan.values[:,1])\nplt.xticks(rotation = 90)\nplt.show()","d01444f0":"## lets see the features that has less than on percent missing\nplt.figure(figsize = (8,4), dpi = 100)\nsns.barplot(x = percent_nan.index, y = percent_nan.values[:,1])\nplt.xticks(rotation = 90)\nplt.ylim(0,1)\nplt.show()","1fb63b00":"percent_nan[percent_nan[\"missing_percent\"] < 1]","3498536a":"index = percent_nan[percent_nan[\"missing_percent\"] < 1].index\nfor name in index:\n    print(df[df[\"BsmtFin SF 2\"].isnull()][name])","1af00f25":"df[df[\"Garage Cars\"].isnull()][\"Garage Area\"]","31f084d9":"df = df.dropna(axis = 0, subset = [\"Garage Cars\"])","d8c47fbc":"percent_nan = percent_missing_data(df)\npercent_nan","cf0d6b39":"df[df[\"BsmtFin SF 1\"].isnull()]","c3ba2c67":"## basement numeric features ==> fillna 0\nbsmt_num_cols = ['BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF','Total Bsmt SF', 'Bsmt Full Bath', 'Bsmt Half Bath']\ndf[bsmt_num_cols] = df[bsmt_num_cols].fillna(0)\n\n## basement string features ==> fillna none\nbsmt_str_cols =  ['Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin Type 2']\ndf[bsmt_str_cols] = df[bsmt_str_cols].fillna('None')","3a07b3b0":"# now if you check again, you will find no nulls\ndf[df[\"BsmtFin SF 1\"].isnull()]","000d5bdf":"percent_nan = percent_missing_data(df)\npercent_nan","d21b8ef1":"df[df[\"Electrical\"].isnull()]","30d36c73":"# You have the choice of filling it with the mode or dropping it, I will drop it\ndf = df.dropna(axis = 0, subset = [\"Electrical\"])","babc35d4":"percent_nan = percent_missing_data(df)\npercent_nan","96f3b8b4":"df[[\"Mas Vnr Area\"]] = df[[\"Mas Vnr Area\"]].fillna(0)\ndf[[\"Mas Vnr Type\"]] = df[[\"Mas Vnr Type\"]].fillna(\"None\")","f3e6fe84":"percent_nan = percent_missing_data(df)\npercent_nan","f8d1fccc":"gar_str_cols = ['Garage Type', 'Garage Finish', 'Garage Qual', 'Garage Cond']\ndf[gar_str_cols] = df[gar_str_cols].fillna('None')","3bd381fc":"df['Garage Yr Blt'] = df['Garage Yr Blt'].fillna(0)","b66277a9":"percent_nan = percent_missing_data(df)\npercent_nan","3bdd60c2":"plt.figure(figsize = (8,4), dpi = 100)\nsns.barplot(x = percent_nan.index, y = percent_nan.values[:,1])\nplt.xticks(rotation = 90)\nplt.show()","f5b29eae":"df = df.drop([\"Pool QC\", \"Misc Feature\", \"Alley\", \"Fence\"], axis = 1)","98643014":"percent_nan = percent_missing_data(df)\npercent_nan","ca0f555e":"plt.figure(figsize = (8,4), dpi = 100)\nsns.barplot(x = percent_nan.index, y = percent_nan.values[:,1])\nplt.xticks(rotation = 90)\nplt.show()","45eb9c03":"df[\"Fireplace Qu\"].value_counts()","7209f6d3":"df[\"Fireplace Qu\"] = df[\"Fireplace Qu\"].fillna(\"None\")","4fa911e7":"percent_nan = percent_missing_data(df)\npercent_nan","997d9a1c":"df[\"Lot Frontage\"].value_counts()","f4d153b5":"plt.figure(figsize = (8, 4), dpi = 100)\nsns.boxplot(x = \"Neighborhood\", y = \"Lot Frontage\", data = df)\nplt.xticks(rotation = 90)\nplt.show()","7a107196":"df.groupby(\"Neighborhood\")[\"Lot Frontage\"].mean()","53296f6f":"df[\"Lot Frontage\"] = df.groupby(\"Neighborhood\")[\"Lot Frontage\"].transform(lambda value: value.fillna(value.mean()))","c26fa995":"percent_nan = percent_missing_data(df)\npercent_nan","6ab926da":"df[\"Lot Frontage\"] = df[\"Lot Frontage\"].fillna(0)","8fe3def5":"percent_nan = percent_missing_data(df)\npercent_nan","0b435e76":"#### Lets now repeat one of the scatter plots that we had before","d600cdf5":"Both \"Mas Vnr Area\" and \"Mas Vnr Type\" have less than 1 percent of null values. How to deal with them? \n\nGoing back to data description, we found that there is a category for none: It does not have \"Mas Vnr\". We can assume that those missing values are also none but they are mistakenly filled with Nan.","7f3a8d19":"PID is just an identifier, it has no numeric value for the model. Set it as index, or drop it. Dropping it will not make any problems, because we have the default identifier (0, 1, 2, 3, ... ) ","9b7f7033":"Since it is a categorical variable we can fill missing data with \"None\"","d7670419":"As we can see there are some points with very high quality (10\/10) but very low price. Lets explore other highly correlated features with Sale Price","cc88cf79":"lets now look at these rows, there might be houses with missing values across all features","bd3e5f4f":"It is tricky, it is numeric. I can not longer go back to the description and fill it with a convenient text. \nWe will use the Neighborhood feature calculate the missing feature.\n\nNeighborhood: Physical locations within Ames city limits\n\nLotFrontage: Linear feet of street connected to property\n\nWe will operate under the assumption that the Lot Frontage is related to what neighborhood a house is in.","c8c3e703":"Electrical still has 1 missing value, lets look at it closely and decide","728a6488":"As we can see each category is unique enough to make the assumption that we can impute the LotFrontage based on Neighborhood categories. ","4dfd5f89":"### 1. Checking for outliers\nThe following example shows why outliers are very dangerous. They significantly affect the mean and the standard deviation and thus affecting the estimators of the model.","b2343d6e":"In principle we should go through each feature and decide whether we will keep it, fill it or drop it. When we speak about dropping we can drop columns or rows.\n\nFor example Pool QC values are missing for 99.6 percent of houses. This might be due to:\n1. These houses have no pools, and instead of nan it should have been zero.\n2. These houses have pools, but the data is actually missing.\n\nWe should go back to the description file and try to understand it better. But now, lets deal with columns with very few missing values.","39735949":"It seems that all features related Basement have very high number of missing values. If we go back to data description you will find that Nan actually means that the house do not has a basement. It is not missing, it just has one. Therefore, it does make sense to replace nan values with a string saying that the house has no Basement. This will work for Basement string columns, as for Basement numeric columns we will replace them with zero.","e19e65c1":"**Yeah! Congratulations! we did it. Nothing is missing any more!**\n \n","fe0743ef":"The data set describes the sale of individual residential property in Ames, Iowa\nfrom 2006 to 2010. The data set contains 2930 observations and a large number of explanatory\nvariables (23 nominal, 23 ordinal, 14 discrete, and 20 continuous) involved in assessing home\nvalues.\n\nIn this note book we will explore the Ames housing data set. We will focus on:\n1. Removing outliers \n2. Dealing with missing data\n3. Building and assessing the model","a5066217":"|| | Data without outlier |  | Data with outlier | \n|--||--||--|\n|**Data**| |1,2,3,3,4,5,4 |  |1,2,3,3,4,5,**400** | \n|**Mean**| |3.142 | |**59.714** |  \n|**Median**| |3|  |3|\n|**Standard Deviation**| |1.345185| |**150.057**|","f099256a":"The points that indicate very high price and also very high living area (at the top right corner) are not outliers. They make sense as they are follwing a trend, therefore they will not hurt our model.\n\nOn the other hand The 3 points at the right-lower corner indicate very high living area but very low price. They are very likely to be outliers because they are not following the general trend.\n\n\n\n#### Lets now check those points closely","02538e24":"To achieve the intended result, we will use pandas transform method. I calls group by and fill in missing vsalues based on it. ","6b4424b5":"In order to visually see outliers, we need a box plot or a scatter plot. \nTherefore, lets see the most correlated features with sale price to plot them a gainst each others.","33d088e6":"As for all garage features, going back to data description we found that Nan means that there is no garage. Therefore, it is resonable to fill it with zero for numeric features and \"none\" for text features. ","ca823b5f":"### 2. Dealing with missing data","95e4d7f2":"#### What to do with the rest?\nThe rest of the features have more than 1% missing data. We need to carefully look at each one and decide how to deal with them. For sure, dropping rows is not a possible strategy any more. so we need to figure out something else. We have two options:\n1. Fill in missing values\n2. Drop thr feature column","345a0329":"Some of the above features have more than 99 percent missing data, dropping these features can be the best strategy to opt for.","cec5cbe0":"Now we are left with just to columns. You have to be carefull and do a lot of thinking because you can not just drop the rows nor the feature columns. Not enough to drop the feature but not too little to drop the rows."}}