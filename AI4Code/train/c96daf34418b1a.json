{"cell_type":{"24418d81":"code","89f47c6c":"code","2898a31e":"code","eb8febf6":"code","fc78353e":"code","4b689f98":"code","8a867413":"code","35dd6345":"code","2bebf06b":"code","5fd5e82a":"code","05c3b445":"code","dbe82641":"code","4463dbf7":"code","155b1fa1":"code","b589cf07":"code","d9591807":"code","af8da02c":"code","263218fd":"code","2a19b672":"code","75011a5a":"code","80e29815":"code","6c4186aa":"code","41e57d8c":"code","6a0311ac":"code","92c2b773":"code","9cbf9250":"code","c7e925c0":"code","ef88750e":"code","ea54b70c":"code","9dc29e9c":"code","6f82dbff":"code","57bd880e":"code","99799e9f":"code","834f2621":"code","ae2162ec":"code","d92e0728":"code","77a2f670":"code","aac13b79":"code","cb98efe9":"code","9d379cd0":"code","43720bc4":"code","ffc32ddd":"markdown","1f0b2844":"markdown","57d773a9":"markdown","bca02c84":"markdown","9b4e34ee":"markdown","27309c4e":"markdown","828b64cb":"markdown","a1e5d65b":"markdown","613ae283":"markdown","5525d7b0":"markdown","b4dfcd2d":"markdown","bb700b6f":"markdown","d6b7742a":"markdown","130f7e73":"markdown","4a546797":"markdown","6e8d3cb2":"markdown","7ccc6240":"markdown","0dc81a96":"markdown","48c16208":"markdown","c3998452":"markdown","16514830":"markdown"},"source":{"24418d81":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","89f47c6c":"df_train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\ndf_train.head()","2898a31e":"# getting information of null values\ndf_train.info()\n\n# summary ststistics\ndf_train.describe()\n","eb8febf6":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf_train.corr()","fc78353e":"#plt.hist(df_train.Age)\n\nsns.boxplot(x='Age',hue='Survived',data=df_train)\nplt.show()","4b689f98":"sns.boxplot('Pclass','Age',data=df_train)\nplt.show()","8a867413":"pclass1Age=(df_train.loc[df_train['Pclass']==1,'Age'].median())\npclass2Age=(df_train.loc[df_train['Pclass']==2,'Age'].median())\npclass3Age=(df_train.loc[df_train['Pclass']==3,'Age'].median())\n\ndf_train.loc[df_train['Pclass']==1,'Age']=df_train.loc[df_train['Pclass']==1,'Age'].fillna(pclass1Age)\ndf_train.loc[df_train['Pclass']==2,'Age']=df_train.loc[df_train['Pclass']==2,'Age'].fillna(pclass2Age)\ndf_train.loc[df_train['Pclass']==3,'Age']=df_train.loc[df_train['Pclass']==3,'Age'].fillna(pclass3Age)","35dd6345":"df_train.Embarked.fillna(df_train.Embarked.value_counts().index[0],inplace=True)","2bebf06b":"df_train.info()","5fd5e82a":"df_train['Title'] = df_train.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(df_train['Title'], df_train['Sex'])","05c3b445":"print(df_train.Title.unique())\ntoBeReplaced=[ 'Don' ,'Rev' ,'Dr', 'Mme', 'Ms', 'Major', 'Lady','Sir' ,'Mlle' ,'Col' ,'Capt', 'Countess' ,'Jonkheer']\ndf_train.Title=df_train.Title.replace(toBeReplaced,'other')\ndf_train.Title.unique()","dbe82641":"df_train.drop(['Name','PassengerId','Ticket','Cabin'],axis=1,inplace=True)\n","4463dbf7":"df_train['NumberOfFamily']=df_train.SibSp + df_train.Parch \ndf_train.drop(['SibSp','Parch'],axis=1,inplace=True)\ndf_train.head()","155b1fa1":"df_train=pd.get_dummies(df_train, prefix=['Title','Embarked','Sex'])\ndf_train.head()","b589cf07":"sns.boxplot('Fare',data=df_train)\nplt.show()","d9591807":"df_train['newage']=pd.cut(df_train['Age'],bins=4,labels=[0,1,2,3])\ndf_train['newfare']=pd.cut(df_train['Fare'],bins=4,labels=[0,1,2,3])\ndf_train.drop(['Age','Fare'],axis=1,inplace=True)\ndf_train.head()","af8da02c":"df_test.info()","263218fd":"pclass1Age=(df_test.loc[df_test['Pclass']==1,'Age'].median())\npclass2Age=(df_test.loc[df_test['Pclass']==2,'Age'].median())\npclass3Age=(df_test.loc[df_test['Pclass']==3,'Age'].median())\n\ndf_test.loc[df_test['Pclass']==1,'Age']=df_test.loc[df_test['Pclass']==1,'Age'].fillna(pclass1Age)\ndf_test.loc[df_test['Pclass']==2,'Age']=df_test.loc[df_test['Pclass']==2,'Age'].fillna(pclass2Age)\ndf_test.loc[df_test['Pclass']==3,'Age']=df_test.loc[df_test['Pclass']==3,'Age'].fillna(pclass3Age)\n\n\ndf_test.Fare.fillna(df_test.Fare.median(),inplace=True)\n\n\ndf_test['Title'] = df_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(df_test['Title'], df_test['Sex'])\n\nprint(df_test.Title.unique())\ntoBeReplaced=[ 'Dona','Don' ,'Rev' ,'Dr', 'Mme', 'Ms', 'Major', 'Lady','Sir' ,'Mlle' ,'Col' ,'Capt', 'Countess' ,'Jonkheer']\ndf_test.Title=df_test.Title.replace(toBeReplaced,'other')\ndf_test.Title.unique()\n\ndf_test.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)\n\n\ndf_test['NumberOfFamily']=df_test.SibSp + df_test.Parch \ndf_test.drop(['SibSp','Parch'],axis=1,inplace=True)\ndf_test.head()\n\n\ndf_test=pd.get_dummies(df_test, prefix=['Title','Embarked','Sex'])\ndf_test.head()\n\n\ndf_test['newage']=pd.cut(df_test['Age'],bins=4,labels=[0,1,2,3])\ndf_test['newfare']=pd.cut(df_test['Fare'],bins=4,labels=[0,1,2,3])\ndf_test.drop(['Age','Fare'],axis=1,inplace=True)\ndf_test.head()","2a19b672":"df_train.shape,df_test.shape","75011a5a":"Y_train=df_train.Survived\n\nX_train=df_train.drop('Survived',axis=1)\n\nX_test=df_test.drop('PassengerId',axis=1)\nX_train.shape, Y_train.shape, X_test.shape","80e29815":"print(X_train.columns)\nprint(X_test.columns)","6c4186aa":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","41e57d8c":"# Random Forest\n\nrandom_forest = RandomForestClassifier()\nrandom_forest.fit(X_train, Y_train)\nY_pred_forest = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","6a0311ac":"\nlogreg = LogisticRegression(max_iter=100,tol=0.01)\nlogreg.fit(X_train, Y_train)\nY_predLOG = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","92c2b773":"submission101 = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": Y_pred_forest\n    })\nsubmission101.to_csv('submission101.csv', index=False)","9cbf9250":"X_train = df_train.drop(\"Survived\", axis=1)\nY_train = df_train[\"Survived\"]\nX_test  = df_test.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","c7e925c0":"# Import MinMaxScaler\n\nfrom sklearn.preprocessing import MinMaxScaler\n \n# Instantiate MinMaxScaler and use it to rescale X_train and X_test\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX_train = scaler.fit_transform(X_train)\nrescaledX_test = scaler.fit_transform(X_test)","ef88750e":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","ea54b70c":"X_train.shape  , Y_train.shape ,X_test.shape\nX_train.columns , X_test.columns\nX_train.drop('Name',axis=1,inplace=True)","9dc29e9c":"# Logistic Regression\n\nlogreg = LogisticRegression(max_iter=100,tol=0.01)\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","6f82dbff":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc\n","57bd880e":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","99799e9f":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","834f2621":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron\n","ae2162ec":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","d92e0728":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","77a2f670":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","aac13b79":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred_forest = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","cb98efe9":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)\n\n","9d379cd0":"import matplotlib.pyplot as plt\nplt.barh(models['Model'],models['Score'])","43720bc4":"submission = pd.DataFrame({\n        \"PassengerId\": df_test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","ffc32ddd":"This means we should us the median for the missing values ","1f0b2844":"# Decision Tree","57d773a9":"## Finding the best performing model","bca02c84":"## splitting the data to train and test ","9b4e34ee":"# DATA EXPLORATION ","27309c4e":"Parch and sibsp combined ","828b64cb":"# machine learning ","a1e5d65b":"# Now i will do the same for the test data \ni'll copy the codes","613ae283":"# Support Vector Machines\n","5525d7b0":"# Stochastic Gradient Descent","b4dfcd2d":"# Linear SVC","bb700b6f":"## exploring the data sets and getting the summary","d6b7742a":"# get dummies","130f7e73":"# Gaussian Naive Bayes","4a546797":"## fixing the scale of the data with MinMaxScaler","6e8d3cb2":"# Random Forest","7ccc6240":"# Logistic Regression","0dc81a96":"## Datasets \n","48c16208":"# Perceptron","c3998452":"# for the name and title ","16514830":"# KNeighborsClassifier"}}