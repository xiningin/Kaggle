{"cell_type":{"956924b4":"code","4f437a53":"code","ef0d7b85":"code","c36f0755":"code","b9f4113c":"code","03f711be":"code","6158a203":"code","d8d18d50":"code","485baf43":"code","21ee2c13":"code","5faf5707":"code","e613034a":"code","1294417c":"code","31d13c05":"code","57855617":"code","d882cb9f":"code","2e22148b":"markdown"},"source":{"956924b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport datetime\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f437a53":"#import data\ndata=pd.read_csv('\/kaggle\/input\/jobs-on-naukricom\/home\/sdf\/marketing_sample_for_naukri_com-jobs__20190701_20190830__30k_data.csv')\ndata.head(5)","ef0d7b85":"#Detils about the dataframe\ndata.info()","c36f0755":"#Count of NA values for each columns\ndata.isna().sum()","b9f4113c":"#We shall drop all the NA records\ndata.dropna(inplace=True)\n#Count of NA values for each columns\ndata.isna().sum()","03f711be":"# Job Title\ndata['Job Title'].value_counts()","6158a203":"# Top 10 Job Titles\nsns.barplot(x=data['Job Title'].value_counts()[0:10],y=data['Job Title'].value_counts()[0:10].index);","d8d18d50":"# Lets analyse the top roles in a particular city\ndata['Location'].value_counts()","485baf43":"#Define a function to retun the top job tiles for a given location\ndef trending_roles_location(data,location,cnt):\n    location_data=data[data['Location'].str.contains(location)]\n    top_titles = data['Job Title'].value_counts()[0:cnt]\n    return top_titles","21ee2c13":"# Analyse the Bengaluru data\nprint(trending_roles_location(data,'Bengaluru',10))","5faf5707":"# Find the trending job titles in demand in Bangalore\nlabels=trending_roles_location(data,'Bengaluru',5).index\ncolors=['cyan','pink','orange','lightgreen','yellow']\nexplode=[0.1,0,0,0,0]\nvalues=trending_roles_location(data,'Bengaluru',5)\n#visualization\nplt.figure(figsize=(7,7))\nplt.pie(values,explode=explode,labels=labels,colors=colors,autopct='%1.1f%%')\nplt.title('Top trending roles in Bangalore',color='black',fontsize=10)\nplt.show()","e613034a":"#Lets extract the skills\nskills=data['Key Skills'].str.split(\"|\",expand=True,)\nskills_list=skills.stack(0, dropna=True)\nskills_list.value_counts()[0:20]\n#Skills with the count\ntop_skills= skills_list.value_counts().rename_axis('skills').reset_index(name='counts')\ntop_skills.head(10)","1294417c":"import squarify \n# Prepare Data\nlabels = top_skills[0:9].apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\",axis=1)\nsizes = top_skills['counts'].value_counts()[0:9]\ncolors = [plt.cm.Spectral(i\/float(len(labels))) for i in range(len(labels))]\n\n# Draw Plot\nplt.figure(figsize=(12,8), dpi= 80)\nsquarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8)\n\n# Decorate\nplt.title('Treemap of Top 10 Skills in Demand')\nplt.axis('off');","31d13c05":"#Lets do month wise analysis\n#Convert the Timestamp to Pandas Datetime\ndata['Crawl Timestamp'] = pd.to_datetime(data['Crawl Timestamp'])\n#Extract the Year and Month\n#data['year'] = pd.DatetimeIndex(data['Crawl Timestamp']).year\n#Data belongs to same year\ndata['month'] = pd.DatetimeIndex(data['Crawl Timestamp']).month\ndata['day']=pd.DatetimeIndex(data['Crawl Timestamp']).day","57855617":"print(\"Month \/n\",data['month'].value_counts())\nprint(\"day \/n\",data['day'].value_counts())","d882cb9f":"#Plot the stacked chart for each month crawl\ndata_month_day = data.groupby(['month', 'day']).size().reset_index().pivot(columns='day', index='month', values=0)\ndata_month_day.plot(kind='bar', stacked=True)\nplt.title(\"Stacked Histogram for each month crawl details\\n\", fontsize=12)\nplt.xlabel(\"Month\")\nplt.ylabel(\"Number of crawls\\n\");","2e22148b":"Data Analysis"}}