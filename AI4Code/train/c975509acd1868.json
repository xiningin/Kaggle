{"cell_type":{"bb4aaddc":"code","ae73d450":"code","682959a5":"code","9e1f18f8":"code","97ef80dc":"code","22e1364b":"code","24657c17":"code","c25951d1":"code","60bd8535":"code","7a5b099b":"code","91de326b":"code","8efc9046":"code","d846b32e":"code","f444f06a":"code","184263d1":"code","cf3aa3d3":"code","65f7f5c4":"code","547bfc69":"code","9224fd40":"code","34c60be9":"code","d21bb3c5":"code","af3a03bd":"code","f2b1f54d":"markdown"},"source":{"bb4aaddc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\n%load_ext tensorboard\n\n%tensorboard --logdir logs\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ae73d450":"#reading in csv files\ntrain_val_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n\n#show small part of training & validation dataframe\ntrain_val_data.head()","682959a5":"train_val_data['label'].value_counts()","9e1f18f8":"#number of each label in the dataset\nsns.countplot(train_val_data['label'])","97ef80dc":"#checking for null data in training\/validation set\ntrain_val_data.isnull().any().describe()","22e1364b":"#null data in test set?\ntest_data.isnull().any().describe()","24657c17":"#x and y for training\ny_train = train_val_data['label']\nx_train = train_val_data.drop(labels = ['label'], axis = 1).values","c25951d1":"import matplotlib.pyplot as plt\n#the first 4 images in the training set are\nfig, ax = plt.subplots(1,4, figsize = (15,6))\nfor i in range(4):\n    ax[i].imshow(x_train[i].reshape(28,28), cmap = 'gray')\n    ax[i].set_title('Label: ' +  str(train_val_data.iloc[i]['label']))\nplt.show()","60bd8535":"x_train.shape","7a5b099b":"#reshaping into images\nx_train = x_train.reshape(x_train.shape[0],28,28,1)\nx_train.shape","91de326b":"#test data shape\nx_test = test_data.values\nx_test.shape","8efc9046":"#reshaping test data\nx_test = x_test.reshape(x_test.shape[0],28,28,1)\nx_test.shape","d846b32e":"#normalize data\nx_train = x_train\/255\nx_test = x_test\/255","f444f06a":"#one hot encoding the train labels\nfrom keras.utils import to_categorical\ny_train = to_categorical(y_train, num_classes = 10)","184263d1":"#splitting into training and validation data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train,Y_val = train_test_split(x_train,y_train,test_size = 0.2, random_state = 2)","cf3aa3d3":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,Dense,Flatten,MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping\n#define model\nmodel = Sequential()\nmodel.add(Conv2D(32, (5,5), input_shape = (28,28,1), activation = 'relu' ))\nmodel.add(Conv2D(32, (5,5), activation = 'relu'))\nmodel.add(Conv2D(32, (5,5), activation = 'relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel.add(Conv2D(64, (3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(10, activation = 'softmax'))\n\nred_lr_plat = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\ntb = TensorBoard(\"logs\")\nearly_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0,patience=2,verbose=0, mode='auto')","65f7f5c4":"#compile model\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])","547bfc69":"#fit model\nhistory = model.fit(x = X_train, y = Y_train, epochs = 10, validation_data = (X_val,Y_val), callbacks = [red_lr_plat, tb, early_stopping])","9224fd40":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Accuracy vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Val'], loc = 'upper right')\nplt.show()","34c60be9":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Val'], loc = 'upper right')\nplt.show()","d21bb3c5":"results = model.predict(x = x_test)","af3a03bd":"results = np.argmax(results, axis = 1)\nsubmission = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nsubmission['Label'] = results\nsubmission.to_csv('my_submission.csv', index = False)","f2b1f54d":"distribution of all numbers is roughly equal!"}}