{"cell_type":{"ec0deda8":"code","df1b5bd7":"code","df00c57c":"code","7c7854d4":"code","cb2a8750":"code","3674da5c":"code","b632dcca":"code","886de574":"code","a977bf04":"code","4fbee8b5":"code","147f271b":"code","aa8a37a6":"markdown","a925ce68":"markdown"},"source":{"ec0deda8":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split","df1b5bd7":"# Read the data\nX_full = pd.read_csv('..\/input\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('..\/input\/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X_full.SalePrice\nX_full.drop(['SalePrice'], axis=1, inplace=True)\n\ncategorical_cols = [cname for cname in X_full.columns if X_full[cname].dtype == \"object\"]\nnumerical_cols = [cname for cname in X_full.columns if X_full[cname].dtype in ['int64', 'float64']]","df00c57c":"# Shape\nX_full.shape","7c7854d4":"# Missing values, categorical\nmis_cat = X_full[categorical_cols].isnull().sum()\nmis_cat[mis_cat > 0]","cb2a8750":"# Missing values, contineous\nmis_num = X_full[numerical_cols].isnull().sum()\nmis_num[mis_num > 0]","3674da5c":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# We create an explicit for feature for 'HasShed' from 'MiscFeature'\nX_full['Has_shed'] = np.where(X_full['MiscFeature']=='Shed',1,0)\nX_full_final = X_full.drop('MiscFeature',axis=1)\n\n# We need a bunch of transformers based on the above\n# Preprocessing for numerical data\nnumerical_transformer_median = SimpleImputer(strategy='median') \n\nnumerical_transformer_constant = SimpleImputer(strategy='constant',fill_value=0) \n\n# Preprocessing for categorical data\ncategorical_transformer_constant = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='NotPresentInTheHouse')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\ncategorical_transformer_mode = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\ncategorical_transformer_other = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n\n# Column categories\nnum_col_median = ['LotFrontage','GarageYrBlt']\n\nnum_col_constant = ['MasVnrArea']\n\ncat_col_constant = (['Alley',\n                         'MasVnrType',\n                         'BsmtQual',\n                         'BsmtCond',\n                         'BsmtExposure',\n                         'BsmtFinType1',\n                         'BsmtFinType2',\n                         'FireplaceQu',\n                         'GarageType',\n                         'GarageFinish',\n                         'GarageQual',\n                         'GarageCond',\n                         'PoolQC',\n                         'Fence'])\n\ncat_col_mode = ['Electrical']\n\ncat_col_other = (['MSZoning',\n             'Street',\n             'LotShape',\n             'LandContour',\n             'Utilities',\n             'LotConfig',\n             'LandSlope',\n             'Neighborhood',\n             'Condition1',\n             'Condition2',\n             'BldgType',\n             'HouseStyle',\n             'RoofStyle',\n             'RoofMatl',\n             'Exterior1st',\n             'Exterior2nd',\n             'ExterQual',\n             'ExterCond',\n             'Foundation',\n             'Heating',\n             'HeatingQC',\n             'CentralAir',\n             'KitchenQual',\n             'Functional',\n             'PavedDrive',\n             'SaleType',\n             'SaleCondition'])","b632dcca":"# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num_median', numerical_transformer_median, num_col_median),\n        ('num_constant', numerical_transformer_constant, num_col_constant),\n        ('cat_constant', categorical_transformer_constant, cat_col_constant),\n        ('cat_mode', categorical_transformer_mode, cat_col_mode),\n        ('cat_other', categorical_transformer_other, cat_col_other),\n    ], remainder = 'passthrough' )","886de574":"# Preprocessing\n# Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full_final, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\nX_train_processed = preprocessor.fit_transform(X_train_full)\nX_valid_processed = preprocessor.transform(X_valid_full)","a977bf04":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#n_estimators = [500,1000,2000]\n#learning_rate = [0.1,0.05,0.025,0.01]\n\n# A hacky grid search, best results for n_estimators=2000 and learning_rate=0.05 with MAE around 15,400\n#for n in n_estimators:\n#    for l in learning_rate:\n#\n#        model = XGBRegressor(n_estimators=n, learning_rate=l)\n#        model.fit(X_train_processed, y_train,verbose=False)\n#        \n#        predictions = model.predict(X_valid_processed)\n#\n#        print('n_estimators: ', n, 'lr: ', l, 'mae:', mean_absolute_error(predictions,y_valid))","4fbee8b5":"# Creating final model, based on grid search above\n\nmodel = XGBRegressor(n_estimators=2000, learning_rate=0.05)\n\n# Training preprocessing\nX_full_processed = preprocessor.fit_transform(X_full_final)\n\n# Test preprocessing\nX_test_full['Has_shed'] = np.where(X_test_full['MiscFeature']=='Shed',1,0)\nX_test_full_final = X_test_full.drop('MiscFeature',axis=1)\nX_test_processed = preprocessor.transform(X_test_full_final)\n\nmodel.fit(X_full_processed,y)\npredictions = model.predict(X_test_processed)\n","147f271b":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test_full.index,\n                       'SalePrice': predictions})\noutput.to_csv('submission.csv', index=False)","aa8a37a6":"# This relatively simple set-up achieves ~14k MAE score on the leaderboard\n\nIt's a continuation of the work done in the 'intermediate machine learning course' and does a bit of feature engineering without throwing any features away. It does a gridsearch and uses the best result for the final predictions.","a925ce68":"# Treatment of missing features\n\n- Missing categorical features (except MiscFeature, Electrical) seem to be caused by simply not having that part of the house, in this case the 'NaN' for feature X can be interpreted as 'does not have feature X in the house' and so deserves a separate category. So it makes sense to impute the NaNs with a new category.\n- MiscFeature: Is mostly empty, however 49 of the values are Shed, prompting me to create a new feature HasShed out of this.\n- Electrical: Impute by most common category (SBrkr)\n\n- Missing continuous features, we use median for LotFrontage, 0 for MasVnrArea and the median for GarageYrBlt"}}