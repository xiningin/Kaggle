{"cell_type":{"6be6467a":"code","d6a65dfd":"code","5dff87f7":"code","3e9cc0fd":"code","a7af770f":"code","cea1d8e5":"code","62464265":"code","1b11a8d5":"code","6e0a33fd":"code","1c2a1416":"code","a46e29c6":"code","1088fa0b":"code","ab0377bd":"code","680264ae":"code","81871667":"code","69e6137b":"code","67809899":"code","dbb67fac":"code","6a1c42ed":"code","5dc743f0":"code","b03f2a6e":"code","70d13a19":"code","d6909595":"code","164db21f":"code","de595939":"code","cc4567b0":"code","38cf0852":"code","b36ce134":"code","4dbdd0e9":"code","648fedf6":"code","57a98719":"code","d73dddb7":"code","de3836f5":"code","be7a85f9":"code","f3ce79fb":"code","68c86456":"markdown"},"source":{"6be6467a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport pydicom # A library that loads dicom(dcm) files \nimport os\nimport glob\nfrom IPython.display import Markdown # we will require this to print Markdown in the console\nfrom tensorflow.keras.applications.resnet50 import ResNet50 \n\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.layers import Input, GRU\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, MaxPooling2D,BatchNormalization, TimeDistributed, LSTM\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nimport datetime\n\nfrom pathlib import Path\nimport re\nfrom imageio import imread\nimport cv2\nfrom sklearn.model_selection import train_test_split\n","d6a65dfd":"input_df = \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv\"\nsample = \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv\"\n ","5dff87f7":"!pip install celluloid","3e9cc0fd":"from celluloid import Camera","a7af770f":"train_df = pd.read_csv(input_df)\ntrain_df","cea1d8e5":"sample_df = pd.read_csv(sample)\nsample_df","62464265":"def load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array   \n    #print(data.shape)\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data\/np.max(data)\n    data = (data*255).astype(np.uint8)   \n    return data    ","1b11a8d5":"def visualize_sample(ID,path, type_=\"flair\"):\n    plt.figure(figsize=(16,5))\n    data = load_dicom(path)\n    plt.imshow(data)\n    label = train_df[train_df['BraTS21ID'] == ID][\"MGMT_value\"].item()\n    plt.title(str(ID) + \" \" + type_ + \" MGMT_value: \" + str(label))\n    plt.axis(\"off\")   ","6e0a33fd":"visualize_sample(0, \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/FLAIR\/Image-104.dcm\", \"FLAIR\")","1c2a1416":"train_df","a46e29c6":"train_df = train_df[~train_df['BraTS21ID'].isin([109, 123, 709])]","1088fa0b":"train_df","ab0377bd":"X_train, X_valid, y_train, y_valid = train_test_split(train_df['BraTS21ID'], train_df['MGMT_value'], stratify = train_df['MGMT_value'], random_state = 42, test_size = 0.2)","680264ae":"type(X_train)","81871667":"y_train","69e6137b":"len(X_train)","67809899":"X_valid.shape","dbb67fac":"train_df","6a1c42ed":"from matplotlib import animation, rc\nrc('animation', html='jshtml')\n\n\ndef create_animation(ims):\n    fig = plt.figure(figsize=(6, 6))\n    plt.axis('off')\n    im = plt.imshow(ims[0], cmap=\"gray\")\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000\/\/24)","5dc743f0":"def load_dicom_line(path):\n    t_paths = sorted(\n        glob.glob(os.path.join(path, \"*\")), \n        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n    )\n    images = []\n    for filename in t_paths:\n        data = load_dicom(filename)\n        if data.max() == 0:\n            continue\n        images.append(data)\n        \n    return images","b03f2a6e":"# images = load_dicom_line(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/T2w\")\n# create_animation(images)","70d13a19":"size = 224","d6909595":"def crop_resize_image(img):\n    #if img.shape[0] == 512:\n        #img = crop(img, ((10, 10), (10, 10), (0,0)), copy=False)     \n    img = cv2.resize(img, (size, size)) \n    return img","164db21f":"def normalize(x):\n    dicom = pydicom.read_file(x)\n    data = dicom.pixel_array       \n    #print(data)\n    data = crop_resize_image(data)\n    normalised_data = (data.astype(float) - 128) \/ 128\n    #plt.imshow(normalised_data)\n    #plt.show()\n    return normalised_data     ","de595939":" \nSIZE = 256\nNUM_IMAGES = 64\ndata_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef load_dicom_image(path, img_size=SIZE, voi_lut=True, rotate=0):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    if rotate > 0:\n        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        data = cv2.rotate(data, rot_choices[rotate])\n        \n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\", rotate=0):\n\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)]) \n    #print(len(files))\n    middle = len(files)\/\/2\n    #print(middle)\n    #print(num_imgs)\n    num_imgs2 = num_imgs\/\/2\n    p1 = max(0, middle - num_imgs2)\n    #print(p1)\n    p2 = min(len(files), middle + num_imgs2)\n    #print(p2)\n    img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n\n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d \/ np.max(img3d)\n\n    return np.expand_dims(img3d,0)\n\n#a = load_dicom_images_3d(\"00000\")\n#print(a)\n#print(a.shape)\n#print(np.min(a), np.max(a), np.mean(a), np.median(a))","cc4567b0":"def generator(source_path, batch_size,y_data):\n    path = \"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/\"\n    types = [\"FLAIR\", \"T1w\" , \"T1wCE\" , \"T2w\"]\n    \n    run = True\n    i = 0 \n    while run:\n        j = 0\n        batch_data = np.zeros((batch_size*4, SIZE, SIZE, NUM_IMAGES))\n        batch_label = np.zeros(batch_size*4)\n        for folder_num in source_path:  \n            fullfilename = str(folder_num).zfill(5) \n            for t in types:\n                a =load_dicom_images_3d(fullfilename, mri_type=t)  \n                batch_data[j,:,:,:] = a  \n                j+=1 \n            batch_label[i] = y_data.iloc[i]   \n            i+=1\n            print(i)   \n            if (i+1) % batch_size == 0:\n                yield batch_data, batch_label\n                batch_data = np.zeros((batch_size*4, SIZE, SIZE, NUM_IMAGES))\n                batch_label = np.zeros(batch_size*4)\n                j = 0 \n                \n            \n                \n             \n","38cf0852":"train_generator = generator(X_train, 5, y_train)\nval_generator = generator(X_valid, 5, y_valid)","b36ce134":"for t, s in train_generator:\n    print(t.shape)","4dbdd0e9":"num_epochs = 1","648fedf6":"# resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(size,size,3))  \n# #cnn = Sequential([resnet])\n# cnn = Sequential()\n# cnn.add(Conv2D(16, 3, input_shape=(size,size, 64)))\n# cnn.add(Conv2D(16,(2,2), strides=(1,1)))\n# cnn.add(BatchNormalization())\n\n# cnn.add(Conv2D(32,(2,2), strides=(1,1)))\n# cnn.add(BatchNormalization()) \n\n# cnn.add(Conv2D(64,(2,2), strides=(1,1)))\n# cnn.add(BatchNormalization()) \n\n# cnn.add(Flatten())\n# cnn.add(Dropout(0.5))\n\n# model= Sequential()\n# model.add(TimeDistributed(cnn, input_shape=(20,size,size,64)))\n# model.add(GRU(16,input_shape=(None,30,256), return_sequences=True))\n# model.add(GRU(8))\n# model.add(Dense(2, activation='softmax')) \n# #model = Model(inputs=input_tensor,outputs=out)\n","57a98719":"from keras.models import Sequential\nfrom keras.layers import Dense, GRU, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers.convolutional import Conv3D, MaxPooling3D\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras import optimizers\n\nmodel = Sequential()\nmodel.add(Conv3D(64, (3,3,3), strides=(1,1,1), padding='same', input_shape=(20,size,size,64)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n\nmodel.add(Conv3D(128, (3,3,3), strides=(1,1,1), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n\n# model.add(Dropout(0.25))\n\nmodel.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n\n# model.add(Dropout(0.25))\n\nmodel.add(Conv3D(256, (3,3,3), strides=(1,1,1), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('elu'))\nmodel.add(MaxPooling3D(pool_size=(2,2,2), strides=(2,2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512, activation='elu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))","d73dddb7":"sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.7, nesterov=True)\nmodel.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\nprint (model.summary())","de3836f5":"curr_dt_time = datetime.datetime.now()","be7a85f9":"model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '\/'\n    \nif not os.path.exists(model_name):\n    os.mkdir(model_name)\n        \nfilepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n\nLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, mode='min', epsilon=0.0001, cooldown=0, min_lr=0.00001)\ncallbacks_list = [checkpoint, LR] ","f3ce79fb":"model.fit_generator(train_generator, epochs=num_epochs, verbose=1, \n                    callbacks=callbacks_list, validation_data=val_generator \n                    , class_weight=None, workers=1, initial_epoch=0)","68c86456":"### This code has been inspired from https:\/\/keeganfdes03.medium.com\/making-an-eda-on-medical-images-b823693a517a"}}