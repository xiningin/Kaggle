{"cell_type":{"7c8fb749":"code","8ddfe4b0":"code","a8dc70d8":"code","3494d6ac":"code","5db6b635":"code","add57cc2":"code","83f707d7":"code","69de6fb5":"code","60a516d0":"code","abb9046c":"code","c8eceed6":"code","35f0f321":"code","9dca4cd7":"markdown","1be58811":"markdown","d107e0be":"markdown","e555cc6e":"markdown","2d7fd2ff":"markdown","cb507b9a":"markdown","b86fca94":"markdown"},"source":{"7c8fb749":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\n\nimport os\nimport cv2\nimport random\n\nimport matplotlib.pyplot as plt","8ddfe4b0":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout,Activation, Flatten, Conv2D, MaxPool2D\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split","a8dc70d8":"def extract_label(img_path,train = True):\n    filename, _ = os.path.splitext(os.path.basename(img_path))\n\n    subject_id, etc = filename.split('__')\n    \n    if train:\n        gender, lr, finger, _, _ = etc.split('_')\n    else:\n        gender, lr, finger, _ = etc.split('_')\n    \n    gender = 0 if gender == 'M' else 1\n    lr = 0 if lr == 'Left' else 1\n\n    if finger == 'thumb':\n        finger = 0\n    elif finger == 'index':\n        finger = 1\n    elif finger == 'middle':\n        finger = 2\n    elif finger == 'ring':\n        finger = 3\n    elif finger == 'little':\n        finger = 4\n        \n    return np.array([subject_id, gender, lr, finger], dtype=np.uint16)","3494d6ac":"img_size = 96\n\ndef loading_data(path,train):\n    print(\"loading data from: \",path)\n    data = []\n    for img in os.listdir(path):\n        try:\n            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n            img_resize = cv2.resize(img_array, (img_size, img_size))\n            label = extract_label(os.path.join(path, img),train)\n            data.append([label[1], img_resize ])\n        except Exception as e:\n            pass\n    data\n    return data","5db6b635":"Real_path = \"..\/input\/socofing\/SOCOFing\/Real\"\nEasy_path = \"..\/input\/socofing\/SOCOFing\/Altered\/Altered-Easy\"\nMedium_path = \"..\/input\/socofing\/SOCOFing\/Altered\/Altered-Medium\"\nHard_path = \"..\/input\/socofing\/SOCOFing\/Altered\/Altered-Hard\"\n\n\nEasy_data = loading_data(Easy_path, train = True)\nMedium_data = loading_data(Medium_path, train = True)\nHard_data = loading_data(Hard_path, train = True)\ntest = loading_data(Real_path, train = False)\n\ndata = np.concatenate([Easy_data, Medium_data, Hard_data], axis=0)\n\ndel Easy_data, Medium_data, Hard_data\n","add57cc2":"X, y = [], []\n\nfor label, feature in data:\n    X.append(feature)\n    y.append(label)\n    \ndel data\n\nX = np.array(X).reshape(-1, img_size, img_size, 1)\nX = X \/ 255.0\n\ny = np.array(y)","83f707d7":"X_test, y_test = [], []\n\nfor label, feature in test:\n    X_test.append(feature)\n    y_test.append(label)\n    \ndel test    \nX_test = np.array(X_test).reshape(-1, img_size, img_size, 1)\nX_test = X_test \/ 255.0\n\ny_test = np.array(y_test)","69de6fb5":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)","60a516d0":"print(\"full data:  \",X.shape)\nprint(\"Train:      \",X_train.shape)\nprint(\"Validation: \",X_val.shape)\nprint(\"Test:       \",X_test.shape)","abb9046c":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (96,96,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(100, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation = \"sigmoid\"))\n\nmodel.summary()","c8eceed6":"epochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\nbatch_size = 86\nmodel_path = '.\/Model.h5'\n\n\nmodel.compile(optimizer = 'adam' , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n\ncallbacks = [\n    EarlyStopping(monitor='val_acc', patience=20, mode='max', verbose=1),\n    ModelCheckpoint(model_path, monitor='val_acc', save_best_only=True, mode='max', verbose=1),\n    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n]\n\n\nhistory = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, \n          validation_data = (X_val, y_val), verbose = 1, callbacks= callbacks)","35f0f321":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, label='Training acc')\nplt.plot(epochs, val_acc, label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss,  label='Training loss')\nplt.plot(epochs, val_loss, label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nscore = model.evaluate([X_test], [y_test], verbose=0)\nprint(\"Score: \",score[1]*100,\"%\")\n\nplt.show()","9dca4cd7":"# Imports","1be58811":"# Conclusion","d107e0be":"# labels\n\n- so the labes for the dataset is not the folder name, instead its the img name\n- therefore I searched and get this function from:\n    * https:\/\/github.com\/kairess\/fingerprint_recognition\n    * https:\/\/www.kaggle.com\/kairess\/fingerprint-recognition\n- it return an numpy array with the subject ID, the person gender, left of right hand, and the finger gender\n\n- Note:\n    - Training data labels are like this: 101__M_Right_ring_finger_Zcut\n    - Testing data labels are like this: 101__M_Right_ring_finger \n    - so the split is different \n    \n","e555cc6e":"# Model\n* its from Yassine Ghouzam kernel on the NMIST Compition:\n* https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6","2d7fd2ff":"# Loading Data ","cb507b9a":"# Intro \n##### welcome to my playground :)\n- In this kernel I am tring to make gender classifier by the use of fingerprints \n- And that what i got so far, just a beginner, so any help or suggestion will be nice .. thank you :) :* \n- i have problem with the Memory any suggestions ?? its almost full","b86fca94":"# Preparing Data\n\n* Create X as an array of pixels in img \n* Reshape X\n* normalize X\n\n\nrepeat for test\n\n* finally split the data into train, val"}}