{"cell_type":{"3913957b":"code","f8712ccb":"code","f50b169a":"code","31b1c5fc":"code","b71a7505":"code","8ff3f7b1":"code","15454d62":"code","e549394b":"code","2ed73ed3":"code","6aebc12e":"code","9bb1f79c":"code","cd3b17d7":"code","9fe2ab80":"code","76936b59":"code","3df12a2d":"code","96752b61":"code","2c960c45":"code","5f1ec349":"code","77443eff":"code","f232a451":"markdown","f408d036":"markdown","1c6bb577":"markdown","acd18334":"markdown","93548b46":"markdown","c1aa0a9c":"markdown","29d1d491":"markdown","977f14bf":"markdown"},"source":{"3913957b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8712ccb":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nimport sklearn.metrics as metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\nimport warnings\nwarnings.filterwarnings('ignore')","f50b169a":"train_data_path = \"..\/input\/covid19-image-dataset\/Covid19-dataset\/train\"\ntest_data_path = \"..\/input\/covid19-image-dataset\/Covid19-dataset\/test\"","31b1c5fc":"img = plt.imread(os.path.join(train_data_path, \"Covid\/01.jpeg\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nplt.title('Covid')\nprint(\"size of image (h x w)\",height,width)","b71a7505":"img = plt.imread(os.path.join(train_data_path, \"Viral Pneumonia\/01.jpeg\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nplt.title('Viral Pneumonia')\nprint(\"size of image (h x w)\",height,width)","8ff3f7b1":"img = plt.imread(os.path.join(train_data_path, \"Normal\/01.jpeg\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nplt.title('Normal')\nprint(\"size of image (h x w)\",height,width)","15454d62":"##image augmentaion\ntrain = ImageDataGenerator(rescale=1.\/255,\n                    rotation_range=20,\n                    horizontal_flip=True,\n                    shear_range = 0.2,\n                    fill_mode = 'nearest')\ntrain_dataset = train.flow_from_directory(train_data_path,\n                                          target_size=(150,150),\n                                          batch_size = 32,\n                                          class_mode = 'categorical',shuffle=True)","e549394b":"train_dataset.class_indices","2ed73ed3":"benchmark_model = Sequential()\n# Input here is 4D array (batchsize, height, width, channels) - we have already created the train_generator with batch size 32\n# 32 Images of size each 150x150 with 3 color channels will be input into this layer\nbenchmark_model.add(Conv2D(128, kernel_size=7, activation='relu', input_shape=(150,150,3)))\nbenchmark_model.add(MaxPool2D(pool_size=(4,4), strides=(2,2)))\nbenchmark_model.add(Conv2D(64, kernel_size=5, activation='relu'))\nbenchmark_model.add(MaxPool2D(pool_size=(4,4), strides=(2,2)))\nbenchmark_model.add(Flatten())\nbenchmark_model.add(Dense(128,activation='relu'))\nbenchmark_model.add(Dense(3,activation='softmax'))\nbenchmark_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\nbenchmark_model.summary()","6aebc12e":"from keras.utils.vis_utils import plot_model\nplot_model(benchmark_model)","9bb1f79c":"early_stopping = EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0,\n    patience=0,\n    verbose=0,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=False,\n)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.001)\nmodelcheck = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')","cd3b17d7":"history = benchmark_model.fit(train_dataset, \n                    epochs=30,\n                    callbacks=[modelcheck,reduce_lr,early_stopping],\n                    batch_size=32)","9fe2ab80":"akurasi = history.history['acc']\nloss = history.history['loss']","76936b59":"plt.title('Nilai Akurasi Training')\nsns.lineplot(data=akurasi)\nplt.xlabel('Epoch')\nplt.ylabel('Nilai Akurasi')","3df12a2d":"plt.title('Nilai Loss Training')\nsns.lineplot(data=loss)\nplt.xlabel('Epoch')\nplt.ylabel('Nilai Loss')","96752b61":"import numpy as np\ntest = ImageDataGenerator(rescale=1\/255)                                       \ntest_dataset = test.flow_from_directory(test_data_path,target_size=(150, 150),batch_size=32,shuffle=False)\ntest_steps_per_epoch = np.math.ceil(test_dataset.samples \/ test_dataset.batch_size)\n\npredictions = benchmark_model.predict(test_dataset, steps=test_steps_per_epoch)\npredicted_classes = np.argmax(predictions, axis=1)","2c960c45":"true_classes = test_dataset.classes\nclass_labels = list(test_dataset.class_indices.keys()) ","5f1ec349":"report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\nprint(report)","77443eff":"conf_matrix = confusion_matrix(true_classes, predicted_classes)\nplt.figure(figsize = (7,7))\nsns.heatmap(conf_matrix, annot=True)","f232a451":"### Build Model","f408d036":"### Train Model","1c6bb577":"### Data Path for Data Test and Data Train","acd18334":"### Doing Classification on Test Dataset using Model","93548b46":"### Using CallBack","c1aa0a9c":"### Show Images That Contain in Dataset","29d1d491":"### Import Library ","977f14bf":"### Image Preparation for Model"}}