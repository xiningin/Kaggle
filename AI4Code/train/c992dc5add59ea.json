{"cell_type":{"5bbdc45d":"code","bd4eb6c7":"code","ff19f0fc":"code","8a3312d4":"code","3de652a2":"code","d0e2f1a0":"code","3a8d291a":"code","5a1d6bc9":"code","1018ed47":"markdown","380d5714":"markdown","a9dd3e9a":"markdown","87b7ebbe":"markdown","09e9d94b":"markdown","52869306":"markdown","329b34b2":"markdown","fb0c5f49":"markdown","56ef0fae":"markdown"},"source":{"5bbdc45d":"# Basics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os # File\/directory scanning and editting\n\n# Image Processing\nfrom PIL import Image \nimport cv2 as cv\n\n# Image Displaying\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","bd4eb6c7":"# File Folders:\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    print(dirname)\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","ff19f0fc":"# Files\ndisplay_folders = \"n\" # y = display, anything else = no\nif (display_folders == 'y'):\n    for dirname, _, filenames in os.walk('\/kaggle\/input'):\n        print(\"-\"*30, \"\\n\"*10,\"-\"*30, sep = \"\\n\")\n        for filename in filenames:\n            print(os.path.join(dirname, filename))","8a3312d4":"## Step 1:\n\npicture_height = 3567 # Manually set\npicture_width = 3827 # Manually set\n\n## Note: I coded, as below, for a program to find the largest dimensions. \n##   It takes about 5-10 minutes to run, so to save the valuable kernel time,\n##   I manually set the values above, according to the result of the program below.\n\n## Code to identify the largest photo\n# for dirname, _, filenames in os.walk(train_path):\n#     for filename in filenames:\n#         temp_img = mpimg.imread(os.path.join(dirname, filename))\n#         (temp_height, temp_width) = temp_img.shape\n#         if temp_height > picture_height:\n#             picture_height = temp_height\n#         if temp_width > picture_width:\n#             picture_width = temp_width\n\n# for dirname, _, filenames in os.walk(test_path):\n#     for filename in filenames:\n#         temp_img = mpimg.imread(os.path.join(dirname, filename))\n#         (temp_height, temp_width) = temp_img.shape\n#         if temp_height > picture_height:\n#             picture_height = temp_height\n#         if temp_width > picture_width:\n#             picture_width = temp_width","3de652a2":"# Step 2:\n\n# We will use some example images. I'll label them, img_1 and img_2\n# We will read them, and then convert them to a numpy array.\n\n# img_1 = \"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/1.2.826.0.1.3680043.8.498.17952552645001544825751321016030941058.jpg\"\n# img_2 = '\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/1.2.826.0.1.3680043.8.498.10370758874574386468962321364924311754.jpg'\n\n\n# For this purpose, I will use the PIL (Pillow), library\n\nimg_1 = Image.open(\"\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/1.2.826.0.1.3680043.8.498.17952552645001544825751321016030941058.jpg\")\nimg_2 = Image.open('\/kaggle\/input\/ranzcr-clip-catheter-line-classification\/train\/1.2.826.0.1.3680043.8.498.10370758874574386468962321364924311754.jpg')\n\n# print(img_1.mode) # Prints the mode of the images (RGB, HSV, L, P, ...)\n# print(img_2.mode)\n# # The mode of the photos is \"L\", which are grayscale images with 8-bit pixels\n\nimg_1_np = np.array(img_1)\nimg_2_np = np.array(img_2)","d0e2f1a0":"# Step 3\n\nimg_1_np = np.pad(img_1_np, ((0, picture_height - img_1_np.shape[0]),(0, picture_width - img_1_np.shape[1])))\nimg_2_np = np.pad(img_2_np, ((0, picture_height - img_2_np.shape[0]),(0, picture_width - img_2_np.shape[1])))\nprint(img_1_np, \"\\n\\n\\n\")\nprint(img_2_np)","3a8d291a":"# Optional Step 4:\n# Now we can convert back to a PIL Image, and display it using matplot, along with the original image:\n\nnew_img_1 = Image.fromarray(img_1_np)\nnew_img_2 = Image.fromarray(img_2_np)\n\n# You can see the padding below, comparing the two images.\n# The white space, is space that is not part of the photo,\n# and the black is padding\n\nfig, ((ax1, ax2),(ax3, ax4)) = plt.subplots(nrows = 2, ncols = 2, sharex = True, sharey = True, figsize = (15, 15), dpi = 150, num = 1)\nax1.imshow(img_1, cmap = \"gray\") # Images are gray scale, ensuring that matplotlib displays them as such\nax2.imshow(new_img_1, cmap = \"gray\")\nax3.imshow(img_2, cmap = \"gray\")\nax4.imshow(new_img_2, cmap = \"gray\")","5a1d6bc9":"clahe = cv.createCLAHE(clipLimit=15.0, tileGridSize=(8,8))\n\nclahe_img_1 = clahe.apply(img_1_np)\nclahe_img_2 = clahe.apply(img_2_np)\n\nfig, ((new_ax1,  new_ax2),(new_ax3, new_ax4)) = plt.subplots(nrows = 2, ncols = 2, sharex = True, sharey = True, figsize = (20, 20), dpi = 150, num = 1)\nnew_ax1.imshow(clahe_img_1, cmap = \"gray\") # Images are gray scale, ensuring that matplotlib displays them as such\nnew_ax2.imshow(new_img_1, cmap = \"gray\")\nnew_ax3.imshow(clahe_img_2, cmap = \"gray\")\nnew_ax4.imshow(new_img_2, cmap = \"gray\")\n\n# Images on the left are the images with contrast applied, on the right are the non-contrasted images\n# I recommend values from 2 - 20\n# Notice, the difference in how well it works. In the top image, \n# you get black spots, for seemingly no reason, yet in the bottom \n# image, the spine becomes clearer.\n# Most importantly, the lines in both images become clearer for the catheters\/tubing.","1018ed47":"## Imports","380d5714":"## Medically Valid Models\n\nYou can apply some of the following models for further image preprocessing\n* https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC6113157\/\n* https:\/\/arxiv.org\/pdf\/2011.07394.pdf\n\nIn addition, one can apply further image filtration:\n* https:\/\/humanhealth.iaea.org\/HHW\/MedicalPhysics\/TheMedicalPhysicist\/Studentscorner\/HandbookforTeachersandStudents\/Chapter_17.pdf","a9dd3e9a":"### Image Padding:\n\n1. We have to figure out the maximum dimensions of the images\n2. We convert images to a numpy array\n3. We apply the numpy.pad function, and voil\u00e0, you have your padded image\n4. Optional: Convert numpy array to image type, or so that it is accessible by a library (such as PIL or OpenCV)","87b7ebbe":"## Goals\nThis notebook is about image preprocessing to optimize any model you use, whether it be a typical CNN, or a U-net, or anything else.\n1. Analyze and get a feel for the data\n2. Filtration and Image Normalization:\n    1. Application of image zero-padding using numpy.pad\n    2. Application of Contrast Limited Adaptive Histogram Equalization (referred to as CLAHE from now on)<sup>1<\/sup>\n3. Apply scientifically described and trained models to identify and separate medical devices from organs <sup>2<\/sup>\n4. Discuss image filtration techniques to provide before convolutions\n\n<sup>1<\/sup> http:\/\/www.cs.unc.edu\/techreports\/90-035.pdf\n\n<sup>2<\/sup> https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC6113157\/\n\nInterested in separate applications of CLAHE, in Python:\n\nThis one describes a model of CLAHE, and some of the limits of traditional models: https:\/\/towardsdatascience.com\/increase-your-face-recognition-models-accuracy-by-improving-face-contrast-a3e71bb6b9fb\n\nThis one describes the opencv application of adaptive Histogram equalization on grayscale images: https:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_histograms\/py_histogram_equalization\/py_histogram_equalization.html\n\nSame as above, but in \"layman's terms\" (is anything AI ever in layman's terms): https:\/\/www.geeksforgeeks.org\/clahe-histogram-eqalization-opencv\/\n\nScikit Image application of CLAHE (not used below): https:\/\/scikit-image.org\/docs\/dev\/api\/skimage.exposure.html#skimage.exposure.equalize_adapthist","09e9d94b":"### Applying Contrast Limited Adaptive Histogram Equalization (CLAHE)","52869306":"## Directory Structure","329b34b2":"### A \"quick\" discussion on image resizing\/padding:\n\n\n* Should I resize my images, pad my images, or both? There are pros and cons to both approaches:\n1. Resizing:\n    * Shrinking:\n        * Pros:\n            * Speeds up training process\n            * Reduces RAM requirement\n            * Allows for larger batch sizes\n            * Can focus images on larger portions of images\n        * Cons:\n            * Reduces image quality\n            * Removes finer details of the image\n    * Enlarging:\n        * Pros:\n            * Keeps all details of image\n            * Allows for more pooling layers\/convolutional layers, allowing for more sophisticated networks\n            * Allows network to train on finer details of image\n        * Cons:\n            * Increases training time\n            * Uses large amount or RAM\n            * Smaller batch sizes often required\n            * Images are often pixelated and\/or stretched\n                * **Note:** Images are not necessarily stretched, in either scenario, as one can shrink\/enlarge keeping the same aspect ratio, and then pad for the remaining pixels.\n                    * Example: Say I have a 100 by 200 pixel image, and I want it to be shrunk to a size of 50 by 50. I have two options: \n                        1. No Padding:\n                            * Reduce width by a factor of 2, and the height by a factor of 4.\n                        2. Padding:\n                            * Reduct width and height by a factor of 4\n                            * Pad an extra 25 by 50 region in the photo as desired\n2. Padding:\n    * Pros:\n        * Keeps image aspect ratios\n        * Retains all fine details\n    * Cons:\n        * Photos must be padded to the size of the largest photograph\n            * ***Common Mistake:*** This must be the largest photograph of both the training and test set\n            * This means that, depending on the sets, they can take up a lot of RAM, or not a lot, it varies\n3. Combination of Resizing and Padding:\n    * Pros and Cons:\n        * Depend on situation\/circumstances","fb0c5f49":"## Image Padding and Contrast Limited Adaptive Histogram Equalization (CLAHE)","56ef0fae":"# Filter Application and Data Visualization"}}