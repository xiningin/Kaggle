{"cell_type":{"345f1e19":"code","101db110":"code","80a32a77":"code","716dbdf1":"code","19f5d0fe":"code","deb115a0":"code","eaf79bd1":"code","fdb76acc":"code","d0cef7dc":"code","d2a6bfca":"code","cc0f9ccd":"code","862b4a7a":"code","8ee03210":"code","3f477a5a":"code","1d8c4510":"code","9830f012":"code","afe5d76e":"code","8dbbab46":"code","107e0206":"code","a591a01d":"code","e164c6e2":"code","ad0048a1":"code","8c999a5e":"code","36b436fc":"code","b2b5a846":"code","4bd5b4b6":"code","7eb4b9aa":"code","78b00c2c":"code","f9cf6693":"code","5978d3fd":"code","00a4eb6c":"code","ba66d787":"code","e00f1993":"code","d8c7266d":"code","6848db26":"code","d8d2251f":"code","bc27a2dc":"code","dab4b1f3":"code","75778232":"code","b97b215b":"code","765fbc5d":"markdown","1adc9eab":"markdown","8b2bc5e5":"markdown","1e1a5401":"markdown","da5e5d17":"markdown","24749d68":"markdown","fe46b7ef":"markdown","9cc1fc73":"markdown","f1d539be":"markdown","13f52983":"markdown","a22bb94d":"markdown","c90ae03b":"markdown","be3e683a":"markdown","c73f22cb":"markdown","3c0c9f64":"markdown","88c8cf32":"markdown","23e69982":"markdown","c58cc5a3":"markdown","2d1257af":"markdown","c920646e":"markdown"},"source":{"345f1e19":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport random\n\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline\nimport os\nos.listdir('..\/input')","101db110":"os.listdir('..\/input\/data\/data')","80a32a77":"train_data=pd.read_csv('..\/input\/data\/data\/train.csv',dtype=str)\ntrain_data.head()","716dbdf1":"train_data.dtypes","19f5d0fe":"train_data.count()","deb115a0":"test_data=pd.read_csv('..\/input\/data\/data\/test_ApKoW4T.csv')\ntest_data.head()","eaf79bd1":"test_data.count()","fdb76acc":"sample_sub=pd.read_csv('..\/input\/data\/data\/sample_submission_ns2btKE.csv')\nsample_sub.head()","d0cef7dc":"sample_sub.count()","d2a6bfca":"sample_sub.tail()","cc0f9ccd":"train_data.tail()","862b4a7a":"train_data['category'].value_counts()","8ee03210":"train_data['category'].value_counts().plot.bar()\nplt.show()","3f477a5a":"filenames = os.listdir(\"..\/input\/data\/data\/images\")\nsample = random.choice(filenames)\nimage = load_img(\"..\/input\/data\/data\/images\/\"+sample)\nplt.imshow(image)\nplt.show()","1d8c4510":"FAST_RUN = False\nIMAGE_WIDTH=128\nIMAGE_HEIGHT=128\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3 # RGB color","9830f012":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))","afe5d76e":"model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])","8dbbab46":"model.summary()","107e0206":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau","a591a01d":"earlystop = EarlyStopping(patience=10)","e164c6e2":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","ad0048a1":"callbacks = [earlystop, learning_rate_reduction]","8c999a5e":"train_df, validate_df = train_test_split(train_data, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\ntest_df = test_data.reset_index(drop=True)","36b436fc":"train_df['category'].value_counts()","b2b5a846":"train_df['category'].value_counts().plot.bar()\nplt.show()","4bd5b4b6":"validate_df['category'].value_counts()","7eb4b9aa":"validate_df['category'].value_counts().plot.bar()\nplt.show()","78b00c2c":"total_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\nbatch_size=15","f9cf6693":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df, \n    directory=\"..\/input\/data\/data\/images\/\", \n    x_col='image',\n    y_col=\"category\",\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","5978d3fd":"validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"..\/input\/data\/data\/images\/\", \n    x_col='image',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","00a4eb6c":"example_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"..\/input\/data\/data\/images\/\", \n    x_col='image',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)","ba66d787":"plt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","e00f1993":"epochs=3 if FAST_RUN else 50\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    callbacks=callbacks\n)","d8c7266d":"model.save_weights(\"model.h5\")","6848db26":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\nax1.plot(history.history['loss'], color='b', label=\"Training loss\")\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, epochs, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\n\nax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, epochs, 1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","d8d2251f":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"..\/input\/data\/data\/images\/\", \n    x_col='image',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","bc27a2dc":"nb_samples = test_df.shape[0]\nnb_samples","dab4b1f3":"test_generator.reset()\npredict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","75778232":"predicted_class_indices=np.argmax(predict,axis=1)\npredicted_class_indices","b97b215b":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\nfilenames=test_df.image\nresults=pd.DataFrame({\"image\":filenames,\n                      \"category\":predictions})\nresults.to_csv(\"results2.csv\",index=False)","765fbc5d":"## Create Testing Generator","1adc9eab":"## Problem Statement\n\nShip or vessel detection has a wide range of applications, in the areas of maritime safety,  fisheries management, marine pollution, defence and maritime security, protection from piracy, illegal migration, etc.\n\nKeeping this in mind, a Governmental Maritime and Coastguard Agency is planning to deploy a computer vision based automated system to identify ship type only from the images taken by the survey boats. You have been hired as a consultant to build an efficient model for this project.\n\nThere are 5 classes of ships to be detected which are as follows: \n- Cargo\n- Military \n- Carrier\n- Cruise\n- Tankers\n\nYou can download dataset from this [Link](https:\/\/datahack.analyticsvidhya.com\/contest\/game-of-deep-learning\/)","8b2bc5e5":"## Fit Model","1e1a5401":"### Early Stop\n\nTo prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased\n","da5e5d17":"## Traning Generator","24749d68":"## Virtualize Training","fe46b7ef":"## See sample image","9cc1fc73":"### Prepare Validate and Train Data","f1d539be":"## Validation Generator","13f52983":"## Build Model","a22bb94d":"## Callbacks","c90ae03b":"### Learning Rate Reduction\n\nWe will reduce the learning rate when then accuracy not increase for 2 steps","be3e683a":"## Import Packages","c73f22cb":"## Evaluation Metric\n\nThe Evaluation metric for this competition is weighted F1 Score.","3c0c9f64":"## Total In count for train and test data","88c8cf32":"## Dataset Description\nThere are 6252 images in train and 2680 images in test data. The categories of ships and their corresponding codes in the dataset are as follows -\n\n`{'Cargo': 1, \n'Military': 2, \n'Carrier': 3, \n'Cruise': 4, \n'Tankers': 5}`\n\nThere are three files provided to you, viz train.zip, test.csv and sample_submission.csv which have the following structure.\n\nVariable \t|Definition\n------------- |-----------\nimage \t   |  Name of the image in the dataset (ID column)\ncategory \t|Ship category code","23e69982":"## Save Model","c58cc5a3":"## See how our generator work","2d1257af":"# Game of Deep Learning","c920646e":"## Predict"}}