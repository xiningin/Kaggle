{"cell_type":{"f80cfb61":"code","9bb35ce4":"code","d2009cdd":"code","d9136030":"code","73aae205":"code","0390d666":"code","fa284a78":"code","8cac8e21":"code","076a2cfa":"code","2cc6acc2":"code","50befa6a":"code","6a1cdb81":"code","e763effd":"code","5d36e34e":"code","a9ab4fe0":"code","7cc69546":"code","c990638c":"code","c25dc852":"code","d7d21177":"code","b2606c91":"code","f8f5c986":"code","7344a255":"code","b1571e87":"code","fcc771a9":"code","131da6d9":"code","c5c9fc42":"code","b26fdf2c":"code","ac918dbb":"code","206bd244":"code","88e900f9":"code","39449114":"code","61f2e1da":"markdown","258ef70c":"markdown","bb2a428c":"markdown","033aec0f":"markdown","1ff7e788":"markdown","40a2c0a0":"markdown","dcab87c5":"markdown","2dc119ed":"markdown","24b5865f":"markdown","8772a191":"markdown","e85e600d":"markdown","16e21a60":"markdown","ccd911ce":"markdown","cbfd1149":"markdown","ed3318d8":"markdown","76f4afc5":"markdown","0a825caa":"markdown"},"source":{"f80cfb61":"!pip install tensorflow-gpu==2.0.0-beta1","9bb35ce4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d2009cdd":"import matplotlib.pyplot as plt #for plotting\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf","d9136030":"train = pd.read_csv(\"..\/input\/train.csv\")\nprint(train.shape)\ntrain.head()","73aae205":"z_train = Counter(train['label'])\nz_train","0390d666":"sns.countplot(train['label'])","fa284a78":"#loading the dataset.......(Test)\ntest= pd.read_csv(\"..\/input\/test.csv\")\nprint(test.shape)\ntest.head()","8cac8e21":"x_train = (train.ix[:,1:].values).astype('float32') # all pixel values\ny_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits\n\nx_test = test.values.astype('float32')","076a2cfa":"# preview the images first\nplt.figure(figsize=(12,10))\nx, y = 10, 4\nfor i in range(40):  \n    plt.subplot(y, x, i+1)\n    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')\nplt.show()","2cc6acc2":"x_train = x_train\/255.0\nx_test = x_test\/255.0","50befa6a":"print('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\n\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')","6a1cdb81":"X_train = x_train.reshape(x_train.shape[0], 28, 28,1)\nX_test = x_test.reshape(x_test.shape[0], 28, 28,1)\n\nprint('X_train shape:', X_train.shape)\nprint('X_test shape:', X_test.shape)","e763effd":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)","5d36e34e":"num_of_classes = 10\n\nepochs = 20\nbatch_size = 32\n\ninput_shape = (28, 28, 1)","a9ab4fe0":"class NaiveModel(tf.keras.Model):\n    def __init__(self):\n        super(NaiveModel, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(32, 3, activation='relu')\n        self.flatten = tf.keras.layers.Flatten()\n        self.d1 = tf.keras.layers.Dense(128, activation='relu')\n        self.d2 = tf.keras.layers.Dense(num_of_classes, activation='softmax')\n    \n    def call(self, x):\n        x = self.conv1(x)\n        x = self.flatten(x)\n        x = self.d1(x)\n        \n        return self.d2(x)","7cc69546":"class DeepModel(tf.keras.Model):\n    def __init__(self):\n        super(DeepModel, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(32, 3, activation='relu', kernel_initializer='he_normal')\n        self.conv2 = tf.keras.layers.Conv2D(32, 3, activation='relu', kernel_initializer='he_normal')\n        self.maxpool = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n        self.dropout1 = tf.keras.layers.Dropout(0.20)\n        self.conv3 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n        self.conv4 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n        self.dropout2 = tf.keras.layers.Dropout(0.25)\n        self.conv5 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n        self.flatten = tf.keras.layers.Flatten()\n        self.d1 = tf.keras.layers.Dense(128, activation='relu')\n        self.bn = tf.keras.layers.BatchNormalization()\n        self.d2 = tf.keras.layers.Dense(num_of_classes, activation='softmax')\n    \n    def call(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.maxpool(x)\n        x = self.dropout1(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.maxpool(x)\n        x = self.dropout2(x)\n        x = self.conv5(x)\n        x = self.dropout2(x)\n        x = self.flatten(x)\n        x = self.d1(x)\n        x = self.bn(x)\n        \n        return self.d2(x)","c990638c":"# model = NaiveModel()\nmodel = DeepModel()","c25dc852":"loss_object = tf.keras.losses.SparseCategoricalCrossentropy() ###\n\noptimizer = tf.keras.optimizers.RMSprop() ###","d7d21177":"train_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\nval_loss = tf.keras.metrics.Mean(name='val_loss')\nval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')","b2606c91":"@tf.function\ndef train_step(images, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(images)\n        loss = loss_object(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss(loss)\n    train_accuracy(labels, predictions)","f8f5c986":"@tf.function\ndef val_step(images, labels):\n    predictions = model(images)\n    v_loss = loss_object(labels, predictions)\n\n    val_loss(v_loss)\n    val_accuracy(labels, predictions)","7344a255":"datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.1, # Randomly zoom image \n    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=False,  # randomly flip images\n    vertical_flip=False)  # randomly flip images","b1571e87":"train_ds = tf.data.Dataset.from_tensor_slices(\n    (X_train, Y_train)).shuffle(10000).batch(batch_size)\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(batch_size)","fcc771a9":"# learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n#                                             patience=3, \n#                                             verbose=1, \n#                                             factor=0.5, \n#                                             min_lr=0.0001)","131da6d9":"# model.compile(loss=loss_object, optimizer=optimizer)","c5c9fc42":"# model.summary()","b26fdf2c":"# datagen.fit()\n\nfor epoch in range(epochs):\n    for images, labels in train_ds:\n        train_step(images, labels)\n\n    for val_images, val_labels in val_ds:\n        val_step(val_images, val_labels)\n\n    template = 'Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n    print (template.format(epoch+1,\n                           train_loss.result(),\n                           train_accuracy.result()*100,\n                           val_loss.result(),\n                           val_accuracy.result()*100))","ac918dbb":"# h = model.fit_generator(x=X_train, y=Y_train, \n#                         batch_size=batch_size, \n#                         epochs=epochs, \n#                         validation_data=(X_val, Y_val), \n#                         verbose=1, \n#                         steps_per_epoch=X_train.shape[0] \/\/ batch_size, \n#                         callbacks=learning_rate_reduction)","206bd244":"# model.compile(optimizer, loss_object)\n\n# final_loss, final_acc = model.evaluate(X_val, Y_val, verbose=0)\n# print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))","88e900f9":"#get the predictions for the test data\nY_test = tf.argmax(model.call(X_test), axis=1)","39449114":"ids = [x for x in range(1, Y_test.shape[0] + 1)]\npd_submit = pd.DataFrame({'ImageId':ids, 'Label':Y_test})\npd_submit.to_csv(\"submission.csv\", index=False)","61f2e1da":"# EDA","258ef70c":"## Model Architecture","bb2a428c":"### Check Training Dataset","033aec0f":"## Loading The Dataset","1ff7e788":"## Hyper-Param","40a2c0a0":"## Predict","dcab87c5":"### Reshaping Dataset","2dc119ed":"### Data Augmentation","24b5865f":"### Check Testing Dataset","8772a191":"- Refer: \n    - [MNIST with Keras for Beginners(.99457)](https:\/\/www.kaggle.com\/adityaecdrid\/mnist-with-keras-for-beginners-99457)\n    - [Introduction to CNN Keras - 0.997 (top 6%)](https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6)","e85e600d":"### Splitting Dataset into Training & Validation set","16e21a60":"## Data Preprocessing","ccd911ce":"### Set Data-Batch","cbfd1149":"## Train The Model","ed3318d8":"# Build Models","76f4afc5":"### Splitting Dataset into Feature(pixel value) & Label","0a825caa":"### Normalising The Data"}}