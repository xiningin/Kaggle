{"cell_type":{"a6f4d647":"code","8a8cab2f":"code","d4983fc4":"code","557f823e":"code","2184abde":"code","861b04e2":"code","0075f8c5":"code","7fa58294":"code","92f490c3":"code","b579a210":"code","b488e807":"code","5672cdc1":"code","5972658d":"code","73a0d092":"code","ccf9dd51":"code","9bccbfa5":"code","b514aca6":"code","c47fc575":"code","2ca5b3bd":"code","f796d562":"code","c28ca345":"code","89579a42":"code","8465ab78":"code","a1154b6b":"code","5201bd9d":"code","f894e0d4":"code","57fc4c87":"code","3d8b4212":"code","0185bb25":"code","cf829eb2":"code","05325431":"code","c1f1869f":"code","361c85a2":"code","0a35ec29":"code","bfd467dd":"code","c8c97c5b":"code","b379f317":"code","f2a9db5d":"code","a4a6284b":"code","d97653f9":"code","fff45c7f":"code","b21d3fec":"code","fe2cac6a":"code","bd6ea15a":"code","522ac578":"code","cabf1762":"code","cc7355e6":"code","4e87aff8":"code","02e97ec1":"code","44283df2":"code","f7b43de5":"code","bd618cc9":"code","5ba08bf8":"code","ea7a9dc0":"code","1c70fb16":"code","84adf48c":"code","d23ce5e2":"code","dd9295cf":"code","71d5a039":"code","694937b4":"code","7867a215":"code","c4adc2fd":"code","fdfeb423":"code","181ffc45":"code","4ce46984":"code","66e324de":"code","69a4ea25":"code","bb9ec267":"code","0d53493a":"code","dbfd7582":"code","e36cb3cb":"code","b96e1ec5":"code","ae8550dd":"code","29b8b768":"code","3a552b57":"code","6db27a33":"code","894d7eb6":"code","44f74c12":"code","0d6301db":"code","6630ff00":"code","76f7d1da":"code","1ba004c6":"code","01e08468":"code","ea9ce387":"code","b5bd4610":"code","8f38c7d3":"code","7f8f5971":"code","7de4859f":"markdown","02abecc7":"markdown","eac192c6":"markdown","c609a114":"markdown","d8f8e065":"markdown","d289d945":"markdown","aa9c69fe":"markdown","dfe18ec1":"markdown","401f80ef":"markdown","82da5230":"markdown","a4260dcb":"markdown","77587c55":"markdown","c6ebdc0b":"markdown"},"source":{"a6f4d647":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","8a8cab2f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4983fc4":"#lots of question marks in the data so used the argument na_values =['?']\n#object dtypes except the first 2 column gets converted to float type\ndata = pd.read_csv(\"..\/input\/electrity-prices\/electricity_prices.csv\", na_values=['?'])","557f823e":"data.head()","2184abde":"len(data)","861b04e2":"#create a function to view the data\n\ndef Missing_values(data):\n    # create list\n    variable_name =[]\n    total_value = []\n    total_missing_value = []\n    missing_value_rate =[]\n    unique_value_list = []\n    total_unique_value =[]\n    data_type = []\n    \n    for col in data.columns:\n        variable_name.append(col)\n        data_type.append(data[col].dtype)\n        total_value.append(data[col].shape[0])\n        total_missing_value.append(data[col].isnull().sum())\n        missing_value_rate.append(round(data[col].isnull().sum()\/data[col].shape[0], 3))\n        unique_value_list.append(data[col].unique())\n        total_unique_value.append(len(data[col].unique()))\n    missing_data = pd.DataFrame({'variable': variable_name,\n                                'total value': total_value,\n                                'total missing value': total_missing_value,\n                                'missing_value_rate': missing_value_rate,\n                                'unique_value_list': unique_value_list,\n                                'total_unique_value': total_unique_value,\n                                'data_type': data_type})\n    return missing_data.sort_values('missing_value_rate', ascending=False)","0075f8c5":"Missing_values(data)","7fa58294":"# see the unique value\ndata['Holiday'].unique()","92f490c3":"data['HolidayFlag'].unique()","b579a210":"data.value_counts(['Holiday']).plot(kind='bar')","b488e807":"data.value_counts(['HolidayFlag'])","5672cdc1":"data.value_counts(['HolidayFlag']).plot(kind='bar', color=['red', 'blue'])","5972658d":"data.value_counts(['PeriodOfDay']).plot(kind='bar', figsize=(12, 6))","73a0d092":"df_tmp = data.copy()","ccf9dd51":"# These columns contain strings\nfor label, content in df_tmp.items():\n    if pd.api.types.is_string_dtype(content):\n        print(label)","9bccbfa5":"# This will turn all of the string values into category values\nfor label, content in df_tmp.items():\n    if pd.api.types.is_string_dtype(content):\n        df_tmp[label] = content.astype(\"category\").cat.as_ordered()","b514aca6":"# This will turn all of the string values into category values\nfor label, content in df_tmp.items():\n    if pd.api.types.is_string_dtype(content):\n        df_tmp[label] = content.astype(\"category\").cat.as_ordered()","c47fc575":"Missing_values(df_tmp)","2ca5b3bd":"# Check columns which *aren't* numeric\nfor label, content in df_tmp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        print(label)","f796d562":"# Turn categorical variables into numbers\nfor label, content in df_tmp.items():\n    # Check columns which *aren't* numeric\n    if not pd.api.types.is_numeric_dtype(content):\n    # We add the +1 because pandas encodes missing categories as -1\n        df_tmp[label] = pd.Categorical(content).codes+1","c28ca345":"# Check columns which *aren't* numeric again\nfor label, content in df_tmp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        print(label)","89579a42":"Missing_values(df_tmp)","8465ab78":"#Fill the missing value\nfor label, content in df_tmp.items():\n    df_tmp[label] = content.fillna(content.median())","a1154b6b":"Missing_values(df_tmp)","5201bd9d":"import seaborn as sns\nplt.figure(figsize = (12, 5))\nsns.distplot(df_tmp['Holiday'])\nplt.show()","f894e0d4":"plt.figure(figsize = (12, 5))\nsns.distplot(df_tmp['ForecastWindProduction'])\nplt.show()","57fc4c87":"plt.figure(figsize = (12, 5))\nsns.distplot(df_tmp['ActualWindProduction'])\nplt.show()","3d8b4212":"fig, ax = plt.subplots()\nax.scatter(df_tmp['ActualWindProduction'], def_tmp['SMPEP2'])","0185bb25":"a = df_tmp.groupby(\"Year\").sum()[\"SMPEP2\"]\nb = df_tmp[\"Year\"].value_counts().index\nplt.figure(figsize = (10,6))\nsns.barplot(x = b, y = a, color = \"blue\", ci = None)\nplt.title(\"Prices by years\", fontsize = 15)\nplt.tick_params(axis = \"both\", which = \"major\", labelsize = 12, direction = \"out\")\nplt.xlabel(\"Years\",fontsize = 12)\nplt.ylabel(\"Prices\", fontsize = 12)\nplt.show()","cf829eb2":"a = df_tmp.groupby(\"Year\").mean()[\"ActualWindProduction\"]\nb = df_tmp[\"Year\"].value_counts().index\nplt.figure(figsize = (10,6))\nsns.barplot(x = b, y = a, color = \"blue\", ci = None)\nplt.title(\"productibility by years\", fontsize = 15)\nplt.tick_params(axis = \"both\", which = \"major\", labelsize = 12, direction = \"out\")\nplt.xlabel(\"Years\",fontsize = 12)\nplt.ylabel(\"ActualWindProduction\", fontsize = 12)\nplt.show()","05325431":"sns.jointplot('CO2Intensity','ActualWindProduction', data=df_tmp,\n              kind=\"kde\", fill=True, color='green', height=6);","c1f1869f":"g = sns.jointplot(data=df_tmp, x=\"CO2Intensity\", y=\"ORKTemperature\")\ng.plot_joint(sns.kdeplot, color=\"r\", zorder=0, levels=6)\ng.plot_marginals(sns.rugplot, color=\"r\", height=-.15, clip_on=False)","361c85a2":"sns.jointplot('CO2Intensity','ORKTemperature', data=df_tmp,\n              kind=\"kde\", fill=True,\n              color='green', height=6);","0a35ec29":"#built a function to visulize and compare the data\ndef plot_fourChart(df, feature1, feature2):\n    \"\"\"\n    plot a heatmap to compare the parameters with the actual productivity of energy\n    \"\"\"\n    sns.jointplot(df.loc[:,feature1], df.loc[:,feature2], data=df,\n              kind=\"kde\", fill=True,\n              color='blue', height=6)\n    pass","bfd467dd":"plot_fourChart(df_tmp, 'ORKWindspeed', 'ActualWindProduction')","c8c97c5b":"# split the data by date\ndf11 = df_tmp[df_tmp.Year == 2011] #test data\ndf12 = df_tmp[df_tmp.Year == 2012] #trainig data\ndf13 = df_tmp[df_tmp.Year == 2013] #valid data\nlen(df11), len(df12), len(df13)\ndf11_tmp = df11.copy()\ndf12_tmp = df12.copy()\ndf13_tmp = df13.copy()","b379f317":"len(df11), len(df12), len(df13)\n","f2a9db5d":"df13.head()","a4a6284b":"FirstPerdDay0 = df11[df11.PeriodOfDay == 0]","d97653f9":"FirstPerdDay0","fff45c7f":"plt.figure(figsize = (12, 5))\nsns.distplot(FirstPerdDay0['ActualWindProduction'])\nplt.show()","b21d3fec":"# let's try the midlle periode in the day\nFirstPerdDay24 = df11[df11.PeriodOfDay == 24]\nFirstPerdDay24","fe2cac6a":"#The production of the wind in the middle of day\nplt.figure(figsize = (12, 5))\nsns.distplot(FirstPerdDay24['ActualWindProduction'])\nplt.show()","bd6ea15a":"#Wind Production\ncol1= ['ForecastWindProduction', 'ActualWindProduction']\ndf11_tmp1 = df11[col1]\ndf11_tmp1","522ac578":"# the  national system load\ncol2  = ['SystemLoadEA', 'SystemLoadEP2']\ndf11_tmp2 = df11[col2]\ndf11_tmp2","cabf1762":"#The price\ncol3  = ['SMPEA', 'SMPEP2']\ndf11_tmp3 = df11[col3]\ndf11_tmp3","cc7355e6":"df11_tmp1[:50].plot.bar();","4e87aff8":"fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 8))\n\n# Index to plot data\nax[0, 0].plot(df11_tmp1); #wind production\nax[0, 1].plot(df11_tmp2); # the  national system load\nax[1, 0].plot(df11_tmp3); # the price","02e97ec1":"df_train = df12\ndf_val = df13\ndf_test = df11.drop('SMPEP2', axis=1)","44283df2":"# Split data into X & y\nX_train, y_train = df_train.drop(\"SMPEP2\", axis=1), df_train.SMPEP2\nX_valid, y_valid = df_val.drop(\"SMPEP2\", axis=1), df_val.SMPEP2","f7b43de5":"X_train.shape, y_train.shape, X_valid.shape, y_valid.shape","bd618cc9":"df_train.shape, df_val.shape, df_test.shape","5ba08bf8":"df_test.head()","ea7a9dc0":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_jobs=-1)","1c70fb16":"%%time\nmodel.fit(X_train ,y_train)","84adf48c":"#create evaluation function\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error\n\n\n\n#create function to evaluate our model\ndef show_scores(model):\n    train_preds = model.predict(X_train)\n    val_preds = model.predict(X_valid)\n    scores = {'Training MAE': mean_absolute_error(y_train, train_preds),\n             'Valid MAE': mean_absolute_error(y_valid, val_preds),\n             'Trainig R^2': model.score(X_train, y_train),\n             'valid R^2': model.score(X_valid, y_valid)}\n    return scores","d23ce5e2":"show_scores(model)","dd9295cf":"%%time\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Different RandomForestClassifier hyperparameters\nrf_grid = {\"n_estimators\": np.arange(10, 100, 10),\n           \"max_depth\": [None, 3, 5, 10],\n           \"min_samples_split\": np.arange(2, 20, 2),\n           \"min_samples_leaf\": np.arange(1, 20, 2),\n           \"max_features\": [0.5, 1, \"sqrt\", \"auto\"],\n           \"max_samples\": [10000]}\n\nrs_model = RandomizedSearchCV(RandomForestRegressor(),\n                              param_distributions=rf_grid,\n                              n_iter=20,\n                              cv=5,\n                              verbose=True)\n\nrs_model.fit(X_train, y_train)","71d5a039":"# Find the best parameters from the RandomizedSearch \nrs_model.best_params_","694937b4":"show_scores(rs_model)","7867a215":"%%time\n# Most ideal hyperparameters\nideal_model = RandomForestRegressor(n_estimators=70,\n                                    min_samples_leaf=13,\n                                    min_samples_split=10,\n                                    max_features='sqrt',\n                                    n_jobs=-1,\n                                    max_samples=None)\nideal_model.fit(X_train, y_train)","c4adc2fd":"show_scores(ideal_model)","fdfeb423":"df_test.shape","181ffc45":"test_preds = ideal_model.predict(df_test)\ntest_preds","4ce46984":"test_preds.shape","66e324de":"# create a dataFrame for the predicted data\ndf_preds = pd.DataFrame()\ndf_preds[\"predicted Price\"] = test_preds\ndf_preds","69a4ea25":"df_preds.shape","bb9ec267":"#compare the real price and the predicted one\nPriceCol  = ['SMPEP2']\nPrice = df11[PriceCol]\nframes = [Price, df_preds]\nresult = pd.concat(frames, axis=1)\nresult.shape, Price.shape","0d53493a":"result[:50].plot.bar();","dbfd7582":"result","e36cb3cb":"(54.32\/52.0901)","b96e1ec5":"rate = result['SMPEP2']\/result['predicted Price']","ae8550dd":"plt.figure(figsize = (12, 5))\nsns.distplot(rate)\nplt.show()","29b8b768":"len(Price)","3a552b57":"# define the important features\nideal_model.feature_importances_","6db27a33":"import seaborn as sns\n\n# Helper function for plotting feature importance\ndef plot_features(columns, importances, n=100):\n    df = (pd.DataFrame({\"features\": columns,\n                        \"feature_importance\": importances})\n          .sort_values(\"feature_importance\", ascending=False)\n          .reset_index(drop=True))\n    \n    sns.barplot(x=\"feature_importance\",\n                y=\"features\",\n                data=df[:n],\n                orient=\"h\")","894d7eb6":"plot_features(X_train.columns, ideal_model.feature_importances_)","44f74c12":"from sklearn.linear_model import Ridge","0d6301db":"model2 = Ridge(alpha=0.01)\nmodel2.fit(X_train, y_train)","6630ff00":"show_scores(model2)","76f7d1da":"preds2 = model2.predict(df_test)","1ba004c6":"preds2, preds2.shape","01e08468":"# create a dataFrame for the predicted data\ndf_preds2 = pd.DataFrame()\ndf_preds2[\"predicted Price2\"] = preds2\ndf_preds2","ea9ce387":"#compare the real price and the predicted one\nPriceCol  = ['SMPEP2']\nPrice = df11[PriceCol]\nframes2 = [df_preds2, Price]\nresult = pd.concat(frames2, axis=1)\nresult","b5bd4610":"rate2 = result['SMPEP2']\/result['predicted Price2']","8f38c7d3":"rate2","7f8f5971":"plt.figure(figsize = (12, 5))\nsns.distplot(rate2)\nplt.show()","7de4859f":"## Make prediction\nlet's make prediction on test dat wich is the data in 2011 and compare it with the true data","02abecc7":"Now let's try to compare the forcasted and the actual data in **2011**\nwer're gonna need four plot to visualizethe diffrent.","eac192c6":"* 1 means the perfect predict.\n* the most predicted rate here is 90%","c609a114":"## description of the rows\n\n* DateTime: String, defines date and time of sample\n* Holiday: String, gives name of holiday if day is a bank holiday\n* HolidayFlag: integer, 1 if day is a bank holiday, zero otherwise\n* DayOfWeek: integer (0-6), 0 monday, day of week\n* WeekOfYear: integer, running week within year of this date\n* Day integer: day of the date\n* Month integer: month of the date\n* Year: integer year of the date\n* PeriodOfDay: integer denotes half hour period of day (0-47)\n* ForecastWindProduction: the forecasted wind production for this period\n* SystemLoadEA: the national load forecast for this period\n* SMPEA: the price forecast for this period\n* ORKTemperature: the actual temperature measured at Cork airport\n* ORKWindspeed: the actual windspeed measured at Cork airport\n* CO2Intensity: the actual CO2 intensity in (g\/kWh) for the electricity produced\n* ActualWindProduction: the actual wind energy production for this period\n* SystemLoadEP2: the actual national system load for this period\n* SMPEP2: the actual price of this time period, the value to be forecasted.\n","d8f8e065":"## RidgeRegressor","d289d945":"## Hyperparameter tuning with RandomizedSearchCV","aa9c69fe":"1 mean the perfect predict\nthe most predicted percentage is 90% ","dfe18ec1":"Now all of our data is splited and numeric and there are no missing values, we should be able to build a machine learning model!","401f80ef":"## RandomForestRegressor","82da5230":"we'll choose RandomForestRegressor model to predict","a4260dcb":"the function work good.\nnow let's try it in a four chart and give it a good visualisation","77587c55":"## training model with best params","c6ebdc0b":"**split the data into train, validation and test sets**"}}