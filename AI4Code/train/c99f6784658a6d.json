{"cell_type":{"c473f36e":"code","699f0e51":"code","b9910d39":"code","8b653b2a":"code","b69b7c61":"code","b0f81ee7":"code","838aa2ab":"code","d3552c0d":"code","47068b10":"code","1fe9c415":"code","e32d4808":"code","4b2e9289":"code","2147f0ab":"code","d9181273":"code","4a9a2ee4":"code","5fb2b62c":"code","c13b2b9a":"code","3715d18b":"code","d854db27":"code","bd2ad21e":"code","444871ca":"code","d69b52e0":"code","8140cd15":"code","e8a41620":"markdown","45bb5f1a":"markdown","7c5c3843":"markdown","52a25ab5":"markdown","628e7948":"markdown","55cc9e94":"markdown","20ddfe05":"markdown","b3bf9ed9":"markdown","1d704a0c":"markdown","925baa45":"markdown","c34d448c":"markdown","8fb703ea":"markdown","9ef9c387":"markdown","5f41b9df":"markdown","73d331bc":"markdown","e7f1b4c6":"markdown"},"source":{"c473f36e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px #advanced visualization library\nimport missingno as msno\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n#ML\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold, train_test_split\nfrom sklearn.metrics import precision_score, confusion_matrix\nfrom sklearn import tree","699f0e51":"df = pd.read_csv(\"\/kaggle\/input\/water-potability\/water_potability.csv\")","b9910d39":"df.head()","8b653b2a":"#describe\ndf.describe()","b69b7c61":"df.info()","b0f81ee7":"d=pd.DataFrame(df[\"Potability\"].value_counts())\nfig = px.pie(d, values = \"Potability\", names = [\"Not Potable\", \"Potable\"], hole = 0.35, opacity = 0.8,\n            labels = {\"label\" :\"Potability\",\"Potability\":\"Number of Samples\"})\nfig.update_layout(title = dict(text = \"Pie Chart of Potability Feature\"))\nfig.update_traces(textposition = \"outside\", textinfo = \"percent+label\")\nfig.show()","838aa2ab":"df.corr()","d3552c0d":"sns.clustermap(df.corr(), cmap = \"vlag\", dendrogram_ratio = (0.1, 0.2), annot = True, linewidths = .8, figsize = (9,10))\nplt.show()","47068b10":"non_potable = df.query(\"Potability == 0\")\npotable = df.query(\"Potability == 1\")\n\nplt.figure(figsize = (15,15))\nfor ax, col in enumerate(df.columns[:9]):\n    plt.subplot(3,3, ax + 1)\n    plt.title(col)\n    sns.kdeplot(x = non_potable[col], label = \"Non Potable\")\n    sns.kdeplot(x = potable[col], label = \"Potable\")\n    plt.legend()\nplt.tight_layout()","1fe9c415":"msno.matrix(df)\nplt.show()","e32d4808":"df.isnull().sum()","4b2e9289":"# handle missing value with average of features\ndf[\"ph\"].fillna(value = df[\"ph\"].mean(), inplace = True)\ndf[\"Sulfate\"].fillna(value = df[\"Sulfate\"].mean(), inplace = True)\ndf[\"Trihalomethanes\"].fillna(value = df[\"Trihalomethanes\"].mean(), inplace = True)","2147f0ab":"df.isnull().sum()","d9181273":"X = df.drop(\"Potability\", axis = 1).values\ny = df[\"Potability\"].values","4a9a2ee4":"# train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 3)\nprint(\"X_train\",X_train.shape)\nprint(\"X_test\",X_test.shape)\nprint(\"y_train\",y_train.shape)\nprint(\"y_test\",y_test.shape)","5fb2b62c":"# min-max normalization\nx_train_max = np.max(X_train)\nx_train_min = np.min(X_train)\nX_train = (X_train - x_train_min)\/(x_train_max-x_train_min)\nX_test = (X_test - x_train_min)\/(x_train_max-x_train_min)","c13b2b9a":"models = [(\"DTC\", DecisionTreeClassifier(max_depth = 3)),\n          (\"RF\",RandomForestClassifier())]","3715d18b":"finalResults = []\ncmList = []\nfor name, model in models:\n    model.fit(X_train, y_train) # train\n    model_result = model.predict(X_test) # prediction\n    score = precision_score(y_test, model_result)\n    cm = confusion_matrix(y_test, model_result)\n    \n    finalResults.append((name, score))\n    cmList.append((name, cm))\nfinalResults","d854db27":"for name, i in cmList:\n    plt.figure()\n    sns.heatmap(i, annot = True, linewidths = 0.8, fmt = \".1f\")\n    plt.title(name)\n    plt.show()","bd2ad21e":"dt_clf = models[0][1]\ndt_clf","444871ca":"plt.figure(figsize = (25,20))\ntree.plot_tree(dt_clf,\n               feature_names =  df.columns.tolist()[:-1],\n               class_names = [\"0\", \"1\"],\n               filled = True,\n               precision = 5)\nplt.show()","d69b52e0":"model_params = {\n    \"Random Forest\":\n    {\n        \"model\":RandomForestClassifier(),\n        \"params\":\n        {\n            \"n_estimators\":[10, 50, 100],\n            \"max_features\":[\"auto\",\"sqrt\",\"log2\"],\n            \"max_depth\":list(range(1,21,3))\n        }\n    }\n    \n}\nmodel_params","8140cd15":"cv = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 2)\nscores = []\nfor model_name, params in model_params.items():\n    rs = RandomizedSearchCV(params[\"model\"], params[\"params\"], cv = cv, n_iter = 10)\n    rs.fit(X,y)\n    scores.append([model_name, dict(rs.best_params_),rs.best_score_])\nscores","e8a41620":"<a id=5><\/a>\n## Correlation Between Features","45bb5f1a":"## What will you learn from this project?\n* Bivariate and multivariate data analysis\n* Correlation analysis\n* Preprocessing: missing value, train-test split and normalization\n* Modelling: Decision Tree and Random Forest Classifiers\n* Visualize Decision Tree\n* Random Forest Hyperparameter Tuning","7c5c3843":"<a id=10><\/a>\n## Visualize Decision Tree\n![image.png](attachment:51e08f77-8026-4f38-b59d-b04c68295c18.png)","52a25ab5":"<a id=11><\/a>\n## Random Forest Hyperparameter Tuning","628e7948":"<a id=7><\/a>\n## Preprocessing: Missing Value Problem","55cc9e94":"<a id=6><\/a>\n## Distribution of Features","20ddfe05":"<a id=8><\/a>\n## Preprocessing: Train-Test Split and Normalization","b3bf9ed9":"<a id=1><\/a>\n## Python Libraries","1d704a0c":"# Water Quality Explanatory Data Analysis","925baa45":"<a id=3><\/a>\n## Read and Analyse Data","c34d448c":"<a id=9><\/a>\n## Modelling: Decision Tree and Random Forest Classifiers","8fb703ea":"<a id=2><\/a>\n## Data Content\n1. **pH value:** PH is an important parameter in evaluating the acid\u2013base balance of water. It is also the indicator of acidic or alkaline condition of water status. WHO has recommended maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52\u20136.83 which are in the range of WHO standards.\n2. **Hardness:** Hardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness producing material helps determine how much hardness there is in raw water. Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.\n3. **Solids (Total dissolved solids - TDS):** Water has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates etc. These minerals produced un-wanted taste and diluted color in appearance of water. This is the important parameter for the use of water. The water with high TDS value indicates that water is highly mineralized. Desirable limit for TDS is 500 mg\/l and maximum limit is 1000 mg\/l which prescribed for drinking purpose.\n4. **Chloramines:** Chlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg\/L or 4 parts per million (ppm)) are considered safe in drinking water.\n5. **Sulfate:** Sulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg\/L). It ranges from 3 to 30 mg\/L in most freshwater supplies, although much higher concentrations (1000 mg\/L) are found in some geographic locations.\n6. **Conductivity:** Pure water is not a good conductor of electric current rather\u2019s a good insulator. Increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines the electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceeded 400 \u03bcS\/cm.\n7. **Organic_carbon:** Total Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to US EPA < 2 mg\/L as TOC in treated \/ drinking water, and < 4 mg\/Lit in source water which is use for treatment.\n8. **Trihalomethanes:** THMs are chemicals which may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm is considered safe in drinking water.\n9. **Turbidity:** The turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of light emitting properties of water and the test is used to indicate the quality of waste discharge with respect to colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.\n10. **Potability:** Indicates if water is safe for human consumption where 1 means Potable and 0 means Not potable.","9ef9c387":"# Introduction\n* Access to safe drinking-water is essential to health, a basic human right and a component of effective policy for health protection. \n* This is important as a health and development issue at a national, regional and local level. \n* In some regions, it has been shown that investments in water supply and sanitation can yield a net economic benefit, since the reductions in adverse health effects and health care costs outweigh the costs of undertaking the interventions.\n* Drinking water and staying hydrated is associated with a reduced incidence of urinary tract infections (UTIs), lower blood pressure and heart disease.\n* Therefore, drinking water is essential for good heart health.\n* Water is the most important nutrient for the body. It has many benefits for your health and helps to protect you from illness and disease. \n* Water is also an essential part of a healthy lifestyle.\n![Using_sunlight_to_clean_water_Featured_Image-1.jpg](attachment:1aef93bd-3570-4df4-a5ca-c62c634c7bbd.jpg)","5f41b9df":"# Analysis Content\n1. [Python Libraries](#1)\n2. [Data Content](#2)\n3. [Read and Analyse Data](#3)\n4. [Dependent Variable Analysis](#4)\n5. [Correlation Between Features](#5)\n6. [Distribution of Features](#6)\n7. [Preprocessing: Missing Value Problem](#7)\n8. [Preprocessing: Train-Test Split and Normalization](#8)\n9. [Modelling: Decision Tree and Random Forest Classifiers](#9)\n10. [Visualize Decision Tree](#10)\n11. [Random Forest Hyperparameter Tuning](#11)\n12. [Conclusion](#12)","73d331bc":"<a id=4><\/a>\n## Dependent Variable Analysis","e7f1b4c6":"* **Precision Score:** The precision is the ratio tp \/ (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n\n![image.png](attachment:09c12ddb-28cd-4db1-b50e-1c4691d978b3.png)\n![image.png](attachment:540ada86-1e54-463e-b82a-01a2018722e4.png)"}}