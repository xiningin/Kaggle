{"cell_type":{"5ba8051e":"code","39997c7d":"code","487e634e":"code","9b41a3da":"code","9343c93c":"code","518ee5c5":"code","c7d725df":"code","b227b30d":"code","75be1828":"code","9f19595f":"code","f38969a6":"code","d19f58aa":"code","4d06b29f":"code","3ede79fa":"code","c21b6bb0":"code","d45b3f27":"code","2a3c64b5":"code","8b8a17a0":"code","6d9af279":"code","34b1baa5":"code","b0b04878":"code","81894f9c":"code","fbb6259b":"code","fbc8b4a7":"code","4df7535b":"code","01b575ee":"code","548714e8":"code","ca0c2ece":"code","4ab0ad92":"code","b962888a":"code","954fa3c5":"code","52697644":"code","497a5188":"code","c523ebcf":"code","e6c799af":"code","ebf8c3a1":"code","e74bafad":"code","96b279a9":"code","52d166bb":"code","c0695dd9":"code","2426dee6":"code","ee3dcb22":"code","05da0eec":"code","28c32a67":"code","df6931a9":"code","ac23adef":"code","5ab6cb3a":"code","977e967e":"code","e45c37b1":"code","15f8bd3a":"code","98ed47fa":"code","999b9740":"code","5a61c59b":"code","84ed007b":"code","2a2cb47d":"code","0eebcd5b":"code","8205e90b":"code","2fc9e24e":"code","b354dcda":"code","639c07bd":"code","6d77bc53":"code","6021a567":"code","59fc557c":"code","6ef8f1d5":"code","29fb9805":"code","b73a7bc9":"code","e93b0466":"code","d1aa7cb8":"code","07f85448":"code","27d629e1":"code","b06fcff2":"code","0e0d7608":"code","6b503ef5":"code","0f0e2882":"code","0a483076":"code","c35a6cbc":"code","52e89693":"code","47fa6f2b":"code","c45f0515":"code","15e960cd":"code","c8e1d5fc":"code","2f688fd6":"code","ff627437":"code","3a35ae9c":"code","d9f844fd":"code","aae7896f":"code","fdecc73d":"code","4281b384":"code","d95e44a0":"code","689f2fd2":"code","bbf77546":"code","4b7b082c":"code","0f7fb44d":"code","18b0d373":"code","ed5fb163":"code","c41d67c7":"code","80a1975c":"code","afd39edb":"code","4c022fb2":"code","201e4bee":"code","9d84d88d":"code","074bdf6a":"code","acb6c5d7":"code","00d1b680":"code","ee761259":"code","05571103":"code","cb8e9dd2":"code","d73b3d2b":"code","e358060a":"code","9badde5b":"code","c462d92f":"code","9f6850de":"code","b44cb4d4":"code","fb2e6b13":"code","b2a54700":"code","b54d8b59":"code","758815ba":"code","3dec7b3e":"code","8bf8ba0e":"code","026910de":"code","44046de8":"code","12af8bc6":"code","d4a47e42":"code","0cc3a30d":"code","911638b1":"code","2fbaf812":"code","06215515":"code","2c9833a2":"code","a987b566":"markdown","724e72c3":"markdown","35fafc69":"markdown","9d98fe7c":"markdown","e84af883":"markdown","0907fc9d":"markdown","9116d9fc":"markdown","2f50e489":"markdown","d9239ef1":"markdown","fba64688":"markdown","45325cd5":"markdown","45c6e578":"markdown","7a730952":"markdown","a652bc09":"markdown","630c5170":"markdown","0a864c0a":"markdown","3e47df05":"markdown","f481bdab":"markdown","5d1b8447":"markdown","47393bf0":"markdown","5811db0b":"markdown","b5182d5d":"markdown","ff3b549f":"markdown","7359aec0":"markdown","776fa5e4":"markdown","5f1f49cd":"markdown","ecc8972d":"markdown","b3ffa41a":"markdown","7b8f3012":"markdown","bf306572":"markdown","4cb105d4":"markdown","f2f3108f":"markdown","9dc18449":"markdown","23a78edb":"markdown","0c10fb42":"markdown","7453ce57":"markdown","1707da5a":"markdown","7af3e51d":"markdown","eb815269":"markdown","5cc9b2c0":"markdown","3058126f":"markdown","7f894c5a":"markdown","3984bf93":"markdown","e5db80b3":"markdown","927cf67a":"markdown","2a4216b9":"markdown","b66149ac":"markdown"},"source":{"5ba8051e":"#all the librarys used in this project\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport re\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import export_graphviz\n \nfrom IPython.display import Image \n!pip install pydotplus\nimport pydotplus\nimport graphviz\nfrom six import StringIO\n\nimport six\nimport sys\nsys.modules['sklearn.externals.six'] = six\nfrom sklearn.externals.six import StringIO \n\nfrom pydot import graph_from_dot_data\nfrom sklearn.utils import resample\n\n\n\nfrom sklearn.tree import export_graphviz\nimport pydot\nimport random\n\n%matplotlib inline","39997c7d":"df = pd.read_csv(\"..\/input\/startup-investments-crunchbase\/investments_VC.csv\") # uploading data set","487e634e":"df.head()#top 5 rows","9b41a3da":"df.head().T # transposing the dataset","9343c93c":"df.info()# date is not being read properly, some numerical values like funding_total_usd is being read as a object","518ee5c5":"df.shape # size of the data","c7d725df":"df.columns # column names","b227b30d":"# some of the columns have space in front. Removing spaces from the front.\ndf = df.rename(columns={' market ': \"market\", ' funding_total_usd ': \"funding_total_usd\"})\n\n# the funding total column is read as a object so clearning it up so that we can use it as a numerical column\ndf['funding_total_usd']=df['funding_total_usd'].str.replace(',','') # removing commas from funding_total_usd column\ndf['funding_total_usd']=df['funding_total_usd'].str.replace(' ','')#removing extra space from funding_total_usd column\ndf['funding_total_usd']=df['funding_total_usd'].str.replace('-','0') #removing - from funding_total_usd column and replacing with 0\n\n\ndf['funding_total_usd'] = pd.to_numeric(df['funding_total_usd'])# turning column to number\n\n\n#turning all date columns in to date\ndf['founded_at'] =  pd.to_datetime(df['founded_at'], format='%Y-%m-%d', errors = 'coerce') # conveting column into date and ignoring errors\ndf['first_funding_at'] =  pd.to_datetime(df['first_funding_at'], format='%Y-%m-%d', errors = 'coerce')  # conveting column into date and ignoring errors\ndf['last_funding_at'] =  pd.to_datetime(df['last_funding_at'], format='%Y-%m-%d', errors = 'coerce')  # conveting column into date and ignoring errors\ndf['founded_year'] =  pd.to_datetime(df['founded_year'], format='%Y', errors = 'coerce') # conveting column into date and ignoring errors\ndf['founded_month'] =  pd.to_datetime(df['founded_month'], format='%Y-%m', errors = 'coerce') # conveting column into date and ignoring errors\n\ndf.market = df.market.str.strip() #removing space from beginnning and end of market column","75be1828":"df.isin([0]).sum() # the number of zeros in the dataset. Some columns have a lot of zeros","9f19595f":"df.count() # number of values in each column","f38969a6":"df.nunique() # finding out unique values for each column\n# permalink has the highest number of unique values, this is agood indicator that it would good to use it as a unique ID","d19f58aa":"(df.isin([0]).sum()\/df.count()) *100 # some of the columns have a lot of zeros. Calculating zeros as apercentage of the total rows for each column","4d06b29f":"df['status'].unique() #unique values in status column\n#status column have three different values, this is what we are going to use to predict against","3ede79fa":"df.groupby('status')['name'].nunique() #number of companies with each status type\n#a lot of operating values in the dataset","c21b6bb0":"df['country_code'].nunique() # no. of unique country code\n#113 country code unique","d45b3f27":"df['country_code'].unique() #different unique values in country_code\n#lot fo different countries","2a3c64b5":"df.groupby('country_code')['name'].nunique().sort_values(ascending=False).head(50) #number of companies in each country_code\n# most of the values are from USA ","8b8a17a0":"df.isnull().sum() #sum of null values in each column\n# dataset also has some null values. Some of the columns have a lot of null values eg. state code and founded years","6d9af279":"df.isnull().sum()\/df.count() *100 #percentage of null values in each column\n#around 40% of the data does not have a founded date. \n#City, region, state also have high number of null values so it would be good to leave these columns.","34b1baa5":"df.groupby('status')['funding_total_usd'].describe() #grouping status and descriptive analysis of total funding\n#acquired companies have higher mean and median funding total comapred to closed and operating. Closed companies have the lowest funding total.","b0b04878":"df.groupby('status')['funding_rounds'].describe()#grouping status and descriptive analysis of funding rounds\n# acquired companies also has more funding rounds","81894f9c":"df.groupby('status')['funding_rounds', 'funding_total_usd', 'seed', 'venture', 'equity_crowdfunding',\n       'undisclosed', 'convertible_note', 'debt_financing', 'angel', 'grant',\n       'private_equity', 'post_ipo_equity', 'post_ipo_debt',\n       'secondary_market', 'product_crowdfunding', 'round_A', 'round_B',\n       'round_C', 'round_D', 'round_E', 'round_F', 'round_G', 'round_H'].mean().T #mean values of all columns and transposing it. Grouping by company status","fbb6259b":"df.groupby('status')['funding_rounds', 'funding_total_usd', 'seed', 'venture', 'equity_crowdfunding',\n       'undisclosed', 'convertible_note', 'debt_financing', 'angel', 'grant',\n       'private_equity', 'post_ipo_equity', 'post_ipo_debt',\n       'secondary_market', 'product_crowdfunding', 'round_A', 'round_B',\n       'round_C', 'round_D', 'round_E', 'round_F', 'round_G', 'round_H'].median().T #median value of all columns and transposing it. Grouping by company status\n       # median values are not being that useful as there is a lot of zeros in the dataset","fbc8b4a7":"df.groupby('status')['funding_rounds', 'funding_total_usd', 'seed', 'venture', 'equity_crowdfunding',\n       'undisclosed', 'convertible_note', 'debt_financing', 'angel', 'grant',\n       'private_equity', 'post_ipo_equity', 'post_ipo_debt',\n       'secondary_market', 'product_crowdfunding', 'round_A', 'round_B',\n       'round_C', 'round_D', 'round_E', 'round_F', 'round_G', 'round_H'].sum().T #sum of all columns and transposing it. Grouping by company status\n       #sum of operating companies  are high for all columns as there is more data for acquired comanies. \n       #There is no money for acquired and close comanies that went till round G and H","4df7535b":"df['founded_year'].hist()#histogram of year variable\n#most of the comapnies are around 2000","01b575ee":"df['founded_year'].max() #newest year\n #2014 is the newest year","548714e8":"df['founded_year'].min() # oldest year\n#1902 is the oldest year","ca0c2ece":"df['market'].nunique() # 736 unique number of market","4ab0ad92":"df.groupby('market')['funding_total_usd'].sum().sort_values(ascending = False).head(5)#top 5  markets with the most funding","b962888a":"df.groupby('market')['name'].count().sort_values(ascending = False).head(5) #Top five markets in terms of count","954fa3c5":"df.groupby(df['market'])['permalink'].count().sort_values(ascending = False).head(5) #top 5 markets","52697644":"df['region'].unique()","497a5188":"df.groupby('region')['name'].count().sort_values(ascending = False).head(10) # top 10 regions. There is a lot from main cities like SF, NYC, Boston, London","c523ebcf":"df['diff_funding'] = df['last_funding_at'] - df['first_funding_at'] # finding the difference in days between first and last funding dates","e6c799af":"df['diff_funding'].describe() # mean is 312 days which is about 1 year","ebf8c3a1":"df['diff_funding_months'] = (df['last_funding_at'] - df['first_funding_at'])\/np.timedelta64(1, 'M') # turning the difference into months","e74bafad":"df['diff_funding_months'].describe()","96b279a9":"df['total_investment'] = df['seed'] + df['venture'] + df['equity_crowdfunding'] + df['undisclosed'] + df['convertible_note'] + df['debt_financing'] + df['angel'] + df['grant'] + df['private_equity'] + df['post_ipo_equity'] + df['post_ipo_debt'] + df['secondary_market'] + df['product_crowdfunding']\n#creating new column for total investment\ndf['total_investment'].describe() # calculating the total investment for each company","52d166bb":"df['total_investment'].sum()# sum of total investment","c0695dd9":"df['funding_total_usd'].describe()","2426dee6":"df['funding_total_usd'].sum() # confirming that funding total and total investment is the same . We can drop one of the columns","ee3dcb22":"df['diff_first_funding_months'] = (df['first_funding_at'] - df['founded_at'])\/np.timedelta64(1, 'M') # calculating how long it took them to get their first funding after being founded","05da0eec":"df['diff_first_funding_months'].describe() #negative values shows that there is a founded date but there is no first funding date. Median is around 17 month and mean is around 46 months. ","28c32a67":"df1 = df.copy()# copying dataframe","df6931a9":"df1 = df1.drop(columns= ['homepage_url', 'category_list', 'state_code', 'founded_at', 'founded_month', 'founded_quarter', 'founded_year', \n                    'diff_first_funding_months', 'diff_funding', 'funding_total_usd', 'city', 'region', 'first_funding_at', 'last_funding_at'])\n#dropping unecessary columns that I dont plan on using","ac23adef":"df1 = df1.dropna(subset=['permalink', 'status', 'name', 'market', 'country_code', 'diff_funding_months']) \n# dropping null values from these columns","5ab6cb3a":"df1.isnull().sum()# checking if there are any null values left","977e967e":"df1.shape","e45c37b1":"df1['diff_funding_year'] = round(df1['diff_funding_months']\/12) # making new column that has difference in funding in year","15f8bd3a":"df1.groupby(df1['diff_funding_year'])['permalink'].count().sort_values(ascending = False).head(50) #number of companies with difference in funding years\n#There are not that many companies that has more than 13 year difference in funding","98ed47fa":"print(df1['market'].nunique()) # number of unique market values\nprint(df1['country_code'].nunique()) # number of unique country codes","999b9740":"# grouping markets in industries to decrease the number of segments. The list was being taken from here https:\/\/support.crunchbase.com\/hc\/en-us\/articles\/360043146954-What-Industries-are-included-in-Crunchbase-\nadmin_services = str('Employer Benefits Programs, Human Resource Automation, Corporate IT, Distribution, Service Providers, Archiving Service, Call Center, Collection Agency, College Recruiting, Courier Service, Debt Collections, Delivery, Document Preparation, Employee Benefits, Extermination Service, Facilities Support Services, Housekeeping Service, Human Resources, Knowledge Management, Office Administration, Packaging Services, Physical Security, Project Management, Staffing Agency, Trade Shows, Virtual Workforce').split(', ')\nadvertising = str('Creative Industries, Promotional, Advertising Ad Exchange, Ad Network, Ad Retargeting, Ad Server, Ad Targeting, Advertising, Advertising Platforms, Affiliate Marketing, Local Advertising, Mobile Advertising, Outdoor Advertising, SEM, Social Media Advertising, Video Advertising').split(', ')\nagriculture = str('Agriculture, AgTech, Animal Feed, Aquaculture, Equestrian, Farming, Forestry, Horticulture, Hydroponics, Livestock').split(', ')\napp = str('Application Performance Monitoring, App Stores, Application Platforms, Enterprise Application, App Discovery, Apps, Consumer Applications, Enterprise Applications, Mobile Apps, Reading Apps, Web Apps').split(', ')\nartificial_intelli = str('Artificial Intelligence, Intelligent Systems, Machine Learning, Natural Language Processing, Predictive Analytics').split(', ')\nbiotechnology = str('Synthetic Biology, Bio-Pharm, Bioinformatics, Biometrics, Biopharma, Biotechnology, Genetics, Life Science, Neuroscience, Quantified Self').split(', ')\nclothing = str('Fashion, Laundry and Dry-cleaning, Lingerie, Shoes').split(', ')\nshopping = str('Consumer Behavior, Customer Support Tools, Discounts, Reviews and Recommendations, Auctions, Classifieds, Collectibles, Consumer Reviews, Coupons, E-Commerce, E-Commerce Platforms, Flash Sale, Gift, Gift Card, Gift Exchange, Gift Registry, Group Buying, Local Shopping, Made to Order, Marketplace, Online Auctions, Personalization, Point of Sale, Price Comparison, Rental, Retail, Retail Technology, Shopping, Shopping Mall, Social Shopping, Sporting Goods, Vending and Concessions, Virtual Goods, Wholesale').split(', ')\ncommunity = str(\"Self Development, Sex, Forums, Match-Making, Babies, Identity, Women, Kids, Entrepreneur, Networking, Adult, Baby, Cannabis, Children, Communities, Dating, Elderly, Family, Funerals, Humanitarian, Leisure, LGBT, Lifestyle, Men's, Online Forums, Parenting, Pet, Private Social Networking, Professional Networking, Q&A, Religion, Retirement, Sex Industry, Sex Tech, Social, Social Entrepreneurship, Teenagers, Virtual World, Wedding, Women's, Young Adults\").split(', ')\nelectronics  = str('Mac, iPod Touch, Tablets, iPad, iPhone, Computer, Consumer Electronics, Drones, Electronics, Google Glass, Mobile Devices, Nintendo, Playstation, Roku, Smart Home, Wearables, Windows Phone, Xbox').split(', ')\nconsumer_goods= str('Commodities, Sunglasses, Groceries, Batteries, Cars, Beauty, Comics, Consumer Goods, Cosmetics, DIY, Drones, Eyewear, Fast-Moving Consumer Goods, Flowers, Furniture, Green Consumer Goods, Handmade, Jewelry, Lingerie, Shoes, Tobacco, Toys').split(', ')\ncontent = str('E-Books, MicroBlogging, Opinions, Blogging Platforms, Content Delivery Network, Content Discovery, Content Syndication, Creative Agency, DRM, EBooks, Journalism, News, Photo Editing, Photo Sharing, Photography, Printing, Publishing, Social Bookmarking, Video Editing, Video Streaming').split(', ')\ndata = str('Optimization, A\/B Testing, Analytics, Application Performance Management, Artificial Intelligence, Big Data, Bioinformatics, Biometrics, Business Intelligence, Consumer Research, Data Integration, Data Mining, Data Visualization, Database, Facial Recognition, Geospatial, Image Recognition, Intelligent Systems, Location Based Services, Machine Learning, Market Research, Natural Language Processing, Predictive Analytics, Product Research, Quantified Self, Speech Recognition, Test and Measurement, Text Analytics, Usability Testing').split(', ')\ndesign = str('Visualization, Graphics, Design, Designers, CAD, Consumer Research, Data Visualization, Fashion, Graphic Design, Human Computer Interaction, Industrial Design, Interior Design, Market Research, Mechanical Design, Product Design, Product Research, Usability Testing, UX Design, Web Design').split(', ')\neducation = str('Universities, College Campuses, University Students, High Schools, All Students, Colleges, Alumni, Charter Schools, College Recruiting, Continuing Education, Corporate Training, E-Learning, EdTech, Education, Edutainment, Higher Education, Language Learning, MOOC, Music Education, Personal Development, Primary Education, Secondary Education, Skill Assessment, STEM Education, Textbook, Training, Tutoring, Vocational Education').split(', ')\nenergy = str('Gas, Natural Gas Uses, Oil, Oil & Gas, Battery, Biofuel, Biomass Energy, Clean Energy, Electrical Distribution, Energy, Energy Efficiency, Energy Management, Energy Storage, Fossil Fuels, Fuel, Fuel Cell, Oil and Gas, Power Grid, Renewable Energy, Solar, Wind Energy').split(', ')\nevents = str('Concerts, Event Management, Event Promotion, Events, Nightclubs, Nightlife, Reservations, Ticketing, Wedding').split(', ')\nfinancial = str('Debt Collecting, P2P Money Transfer, Investment Management, Trading, Accounting, Angel Investment, Asset Management, Auto Insurance, Banking, Bitcoin, Commercial Insurance, Commercial Lending, Consumer Lending, Credit, Credit Bureau, Credit Cards, Crowdfunding, Cryptocurrency, Debit Cards, Debt Collections, Finance, Financial Exchanges, Financial Services, FinTech, Fraud Detection, Funding Platform, Gift Card, Health Insurance, Hedge Funds, Impact Investing, Incubators, Insurance, InsurTech, Leasing, Lending, Life Insurance, Micro Lending, Mobile Payments, Payments, Personal Finance, Prediction Markets, Property Insurance, Real Estate Investment, Stock Exchanges, Trading Platform, Transaction Processing, Venture Capital, Virtual Currency, Wealth Management').split(', ')\nfood = str('Specialty Foods, Bakery, Brewing, Cannabis, Catering, Coffee, Confectionery, Cooking, Craft Beer, Dietary Supplements, Distillery, Farmers Market, Food and Beverage, Food Delivery, Food Processing, Food Trucks, Fruit, Grocery, Nutrition, Organic Food, Recipes, Restaurants, Seafood, Snack Food, Tea, Tobacco, Wine And Spirits, Winery').split(', ')\ngaming = str('Game, Games, Casual Games, Console Games, Contests, Fantasy Sports, Gambling, Gamification, Gaming, MMO Games, Online Games, PC Games, Serious Games, Video Games').split(', ')\ngovernment = str('Polling, Governance, CivicTech, Government, GovTech, Law Enforcement, Military, National Security, Politics, Public Safety, Social Assistance').split(', ')\nhardware= str('Cable, 3D, 3D Technology, Application Specific Integrated Circuit (ASIC), Augmented Reality, Cloud Infrastructure, Communication Hardware, Communications Infrastructure, Computer, Computer Vision, Consumer Electronics, Data Center, Data Center Automation, Data Storage, Drone Management, Drones, DSP, Electronic Design Automation (EDA), Electronics, Embedded Systems, Field-Programmable Gate Array (FPGA), Flash Storage, Google Glass, GPS, GPU, Hardware, Industrial Design, Laser, Lighting, Mechanical Design, Mobile Devices, Network Hardware, NFC, Nintendo, Optical Communication, Playstation, Private Cloud, Retail Technology, RFID, RISC, Robotics, Roku, Satellite Communication, Semiconductor, Sensor, Sex Tech, Telecommunications, Video Conferencing, Virtual Reality, Virtualization, Wearables, Windows Phone, Wireless, Xbox').split(', ')\nhealth_care = str('Senior Health, Physicians, Electronic Health Records, Doctors, Healthcare Services, Diagnostics, Alternative Medicine, Assisted Living, Assistive Technology, Biopharma, Cannabis, Child Care, Clinical Trials, Cosmetic Surgery, Dental, Diabetes, Dietary Supplements, Elder Care, Electronic Health Record (EHR), Emergency Medicine, Employee Benefits, Fertility, First Aid, Funerals, Genetics, Health Care, Health Diagnostics, Home Health Care, Hospital, Medical, Medical Device, mHealth, Nursing and Residential Care, Nutraceutical, Nutrition, Outpatient Care, Personal Health, Pharmaceutical, Psychology, Rehabilitation, Therapeutics, Veterinary, Wellness').split(', ')\nit = str('Distributors, Algorithms, ICT, M2M, Technology, Business Information Systems, CivicTech, Cloud Data Services, Cloud Management, Cloud Security, CMS, Contact Management, CRM, Cyber Security, Data Center, Data Center Automation, Data Integration, Data Mining, Data Visualization, Document Management, E-Signature, Email, GovTech, Identity Management, Information and Communications Technology (ICT), Information Services, Information Technology, Intrusion Detection, IT Infrastructure, IT Management, Management Information Systems, Messaging, Military, Network Security, Penetration Testing, Private Cloud, Reputation, Sales Automation, Scheduling, Social CRM, Spam Filtering, Technical Support, Unified Communications, Video Chat, Video Conferencing, Virtualization, VoIP').split(', ')\ninternet = str('Online Identity, Cyber, Portals, Web Presence Management, Domains, Tracking, Web Tools, Curated Web, Search, Cloud Computing, Cloud Data Services, Cloud Infrastructure, Cloud Management, Cloud Storage, Darknet, Domain Registrar, E-Commerce Platforms, Ediscovery, Email, Internet, Internet of Things, ISP, Location Based Services, Messaging, Music Streaming, Online Forums, Online Portals, Private Cloud, Product Search, Search Engine, SEM, Semantic Search, Semantic Web, SEO, SMS, Social Media, Social Media Management, Social Network, Unified Communications, Vertical Search, Video Chat, Video Conferencing, Visual Search, VoIP, Web Browsers, Web Hosting').split(', ')\ninvest = str('Angel Investment, Banking, Commercial Lending, Consumer Lending, Credit, Credit Cards, Financial Exchanges, Funding Platform, Hedge Funds, Impact Investing, Incubators, Micro Lending, Stock Exchanges, Trading Platform, Venture Capital').split(', ')\nmanufacturing = str('Innovation Engineering, Civil Engineers, Heavy Industry, Engineering Firms, Systems, 3D Printing, Advanced Materials, Foundries, Industrial, Industrial Automation, Industrial Engineering, Industrial Manufacturing, Machinery Manufacturing, Manufacturing, Paper Manufacturing, Plastics and Rubber Manufacturing, Textiles, Wood Processing').split(', ')\nmedia = str('Writers, Creative, Television, Entertainment, Media, Advice, Animation, Art, Audio, Audiobooks, Blogging Platforms, Broadcasting, Celebrity, Concerts, Content, Content Creators, Content Discovery, Content Syndication, Creative Agency, Digital Entertainment, Digital Media, DRM, EBooks, Edutainment, Event Management, Event Promotion, Events, Film, Film Distribution, Film Production, Guides, In-Flight Entertainment, Independent Music, Internet Radio, Journalism, Media and Entertainment, Motion Capture, Music, Music Education, Music Label, Music Streaming, Music Venues, Musical Instruments, News, Nightclubs, Nightlife, Performing Arts, Photo Editing, Photo Sharing, Photography, Podcast, Printing, Publishing, Reservations, Social Media, Social News, Theatre, Ticketing, TV, TV Production, Video, Video Editing, Video on Demand, Video Streaming, Virtual World').split(', ')\nmessage = str('Unifed Communications, Chat, Email, Meeting Software, Messaging, SMS, Unified Communications, Video Chat, Video Conferencing, VoIP, Wired Telecommunications').split(', ')\nmobile = str('Android, Google Glass, iOS, mHealth, Mobile, Mobile Apps, Mobile Devices, Mobile Payments, Windows Phone, Wireless').split(', ')\nmusic = str('Audio, Audiobooks, Independent Music, Internet Radio, Music, Music Education, Music Label, Music Streaming, Musical Instruments, Podcast').split(', ')\nresource = str('Biofuel, Biomass Energy, Fossil Fuels, Mineral, Mining, Mining Technology, Natural Resources, Oil and Gas, Precious Metals, Solar, Timber, Water, Wind Energy').split(', ')\nnavigation = str('Maps, Geospatial, GPS, Indoor Positioning, Location Based Services, Mapping Services, Navigation').split(', ')\nother = str('Mass Customization, Monetization, Testing, Subscription Businesses, Mobility, Incentives, Peer-to-Peer, Nonprofits, Alumni, Association, B2B, B2C, Blockchain, Charity, Collaboration, Collaborative Consumption, Commercial, Consumer, Crowdsourcing, Customer Service, Desktop Apps, Emerging Markets, Enterprise, Ethereum, Franchise, Freemium, Generation Y, Generation Z, Homeless Shelter, Infrastructure, Knowledge Management, LGBT Millennials, Non Profit, Peer to Peer, Professional Services, Project Management, Real Time, Retirement, Service Industry, Sharing Economy, Small and Medium Businesses, Social Bookmarking, Social Impact, Subscription Service, Technical Support, Underserved Children, Universities').split(', ')\npayment = str('Billing, Bitcoin, Credit Cards, Cryptocurrency, Debit Cards, Fraud Detection, Mobile Payments, Payments, Transaction Processing, Virtual Currency').split(', ')\nplatforms = str('Development Platforms, Android, Facebook, Google, Google Glass, iOS, Linux, macOS, Nintendo, Operating Systems, Playstation, Roku, Tizen, Twitter, WebOS, Windows, Windows Phone, Xbox').split(', ')\nprivacy = str('Digital Rights Management, Personal Data, Cloud Security, Corrections Facilities, Cyber Security, DRM, E-Signature, Fraud Detection, Homeland Security, Identity Management, Intrusion Detection, Law Enforcement, Network Security, Penetration Testing, Physical Security, Privacy, Security').split(', ')\nservices = str('Funeral Industry, English-Speaking, Spas, Plumbers, Service Industries, Staffing Firms, Translation, Career Management, Business Services, Services, Accounting, Business Development, Career Planning, Compliance, Consulting, Customer Service, Employment, Environmental Consulting, Field Support, Freelance, Intellectual Property, Innovation Management, Legal, Legal Tech, Management Consulting, Outsourcing, Professional Networking, Quality Assurance, Recruiting, Risk Management, Social Recruiting, Translation Service').split(', ')\nrealestate= str('Office Space, Self Storage, Brokers, Storage, Home Owners, Self Storage , Realtors, Home & Garden, Utilities, Home Automation, Architecture, Building Maintenance, Building Material, Commercial Real Estate, Construction, Coworking, Facility Management, Fast-Moving Consumer Goods, Green Building, Home and Garden, Home Decor, Home Improvement, Home Renovation, Home Services, Interior Design, Janitorial Service, Landscaping, Property Development, Property Management, Real Estate, Real Estate Investment, Rental Property, Residential, Self-Storage, Smart Building, Smart Cities, Smart Home, Timeshare, Vacation Rental').split(', ')\nsales = str('Advertising, Affiliate Marketing, App Discovery, App Marketing, Brand Marketing, Cause Marketing, Content Marketing, CRM, Digital Marketing, Digital Signage, Direct Marketing, Direct Sales, Email Marketing, Lead Generation, Lead Management, Local, Local Advertising, Local Business, Loyalty Programs, Marketing, Marketing Automation, Mobile Advertising, Multi-level Marketing, Outdoor Advertising, Personal Branding, Public Relations, Sales, Sales Automation, SEM, SEO, Social CRM, Social Media Advertising, Social Media Management, Social Media Marketing, Sponsorship, Video Advertising').split(', ')\nscience = str('Face Recognition, New Technologies, Advanced Materials, Aerospace, Artificial Intelligence, Bioinformatics, Biometrics, Biopharma, Biotechnology, Chemical, Chemical Engineering, Civil Engineering, Embedded Systems, Environmental Engineering, Human Computer Interaction, Industrial Automation, Industrial Engineering, Intelligent Systems, Laser, Life Science, Marine Technology, Mechanical Engineering, Nanotechnology, Neuroscience, Nuclear, Quantum Computing, Robotics, Semiconductor, Software Engineering, STEM Education').split(', ')\nsoftware = str('Business Productivity, 3D Technology, Android, App Discovery, Application Performance Management, Apps, Artificial Intelligence, Augmented Reality, Billing, Bitcoin, Browser Extensions, CAD, Cloud Computing, Cloud Management, CMS, Computer Vision, Consumer Applications, Consumer Software, Contact Management, CRM, Cryptocurrency, Data Center Automation, Data Integration, Data Storage, Data Visualization, Database, Developer APIs, Developer Platform, Developer Tools, Document Management, Drone Management, E-Learning, EdTech, Electronic Design Automation (EDA), Embedded Software, Embedded Systems, Enterprise Applications, Enterprise Resource Planning (ERP), Enterprise Software, Facial Recognition, File Sharing, IaaS, Image Recognition, iOS, Linux, Machine Learning, macOS, Marketing Automation, Meeting Software, Mobile Apps, Mobile Payments, MOOC, Natural Language Processing, Open Source, Operating Systems, PaaS, Predictive Analytics, Presentation Software, Presentations, Private Cloud, Productivity Tools, QR Codes, Reading Apps, Retail Technology, Robotics, SaaS, Sales Automation, Scheduling, Sex Tech, Simulation, SNS, Social CRM, Software, Software Engineering, Speech Recognition, Task Management, Text Analytics, Transaction Processing, Video Conferencing, Virtual Assistant, Virtual Currency, Virtual Desktop, Virtual Goods, Virtual Reality, Virtual World, Virtualization, Web Apps, Web Browsers, Web Development').split(', ')\nsports = str('American Football, Baseball, Basketball, Boating, Cricket, Cycling, Diving, eSports, Fantasy Sports, Fitness, Golf, Hockey, Hunting, Outdoors, Racing, Recreation, Rugby, Sailing, Skiing, Soccer, Sporting Goods, Sports, Surfing, Swimming, Table Tennis, Tennis, Ultimate Frisbee, Volley Ball').split(', ')\nsustainability = str('Green, Wind, Biomass Power Generation, Renewable Tech, Environmental Innovation, Renewable Energies, Clean Technology, Biofuel, Biomass Energy, Clean Energy, CleanTech, Energy Efficiency, Environmental Engineering, Green Building, Green Consumer Goods, GreenTech, Natural Resources, Organic, Pollution Control, Recycling, Renewable Energy, Solar, Sustainability, Waste Management, Water Purification, Wind Energy').split(', ')\ntransportation = str('Taxis, Air Transportation, Automotive, Autonomous Vehicles, Car Sharing, Courier Service, Delivery Service, Electric Vehicle, Ferry Service, Fleet Management, Food Delivery, Freight Service, Last Mile Transportation, Limousine Service, Logistics, Marine Transportation, Parking, Ports and Harbors, Procurement, Public Transportation, Railroad, Recreational Vehicles, Ride Sharing, Same Day Delivery, Shipping, Shipping Broker, Space Travel, Supply Chain Management, Taxi Service, Transportation, Warehousing, Water Transportation').split(', ')\ntravel = str('Adventure Travel, Amusement Park and Arcade, Business Travel, Casino, Hospitality, Hotel, Museums and Historical Sites, Parks, Resorts, Timeshare, Tour Operator, Tourism, Travel, Travel Accommodations, Travel Agency, Vacation Rental').split(', ')\nvideo = str('Animation, Broadcasting, Film, Film Distribution, Film Production, Motion Capture, TV, TV Production, Video, Video Editing, Video on Demand, Video Streaming').split(', ')","5a61c59b":"#Making new column called  Industry group\ndf1['Industry_Group'] = pd.np.where(df1.market.str.contains('|'.join(admin_services), flags=re.IGNORECASE), \"Administrative Services\",\n                               pd.np.where(df1.market.str.contains('|'.join(software), flags=re.IGNORECASE), \"Software\", \n                               pd.np.where(df1.market.str.contains('|'.join(advertising), flags=re.IGNORECASE), \"Advertising\",\n                               pd.np.where(df1.market.str.contains('|'.join(agriculture), flags=re.IGNORECASE), \"Agriculture and Farming\",\n                               pd.np.where(df1.market.str.contains('|'.join(app), flags=re.IGNORECASE), \"Apps\", \n                               pd.np.where(df1.market.str.contains('|'.join(artificial_intelli), flags=re.IGNORECASE), \"Artificial Intelligence\", \n                               pd.np.where(df1.market.str.contains('|'.join(biotechnology), flags=re.IGNORECASE), \"Biotechnology\", \n                               pd.np.where(df1.market.str.contains('|'.join(clothing), flags=re.IGNORECASE), \"Clothing and Apparel\", \n                               pd.np.where(df1.market.str.contains('|'.join(shopping), flags=re.IGNORECASE), \"Commerce and Shopping\", \n                               pd.np.where(df1.market.str.contains('|'.join(community), flags=re.IGNORECASE), \"Community and Lifestyle\", \n                               pd.np.where(df1.market.str.contains('|'.join(electronics), flags=re.IGNORECASE), \"Consumer Electronics\", \n                               pd.np.where(df1.market.str.contains('|'.join(consumer_goods), flags=re.IGNORECASE), \"Consumer Goods\", \n                               pd.np.where(df1.market.str.contains('|'.join(content), flags=re.IGNORECASE), \"Content and Publishing\", \n                               pd.np.where(df1.market.str.contains('|'.join(data), flags=re.IGNORECASE), \"Data and Analytics\",\n                               pd.np.where(df1.market.str.contains('|'.join(design), flags=re.IGNORECASE), \"Design\", \n                               pd.np.where(df1.market.str.contains('|'.join(education), flags=re.IGNORECASE), \"Education\", \n                               pd.np.where(df1.market.str.contains('|'.join(energy), flags=re.IGNORECASE), \"Energy\", \n                               pd.np.where(df1.market.str.contains('|'.join(events), flags=re.IGNORECASE), \"Events\", \n                               pd.np.where(df1.market.str.contains('|'.join(financial), flags=re.IGNORECASE), \"Financial Services\",\n                               pd.np.where(df1.market.str.contains('|'.join(food), flags=re.IGNORECASE), \"Food and Beverage\", \n                               pd.np.where(df1.market.str.contains('|'.join(gaming), flags=re.IGNORECASE), \"Gaming\", \n                               pd.np.where(df1.market.str.contains('|'.join(government), flags=re.IGNORECASE), \"Government and Military\", \n                               pd.np.where(df1.market.str.contains('|'.join(hardware), flags=re.IGNORECASE), \"Hardware\",\n                               pd.np.where(df1.market.str.contains('|'.join(health_care), flags=re.IGNORECASE), \"Health Care\",\n                               pd.np.where(df1.market.str.contains('|'.join(it), flags=re.IGNORECASE), \"Information Technology\", \n                               pd.np.where(df1.market.str.contains('|'.join(internet), flags=re.IGNORECASE), \"Internet Services\", \n                               pd.np.where(df1.market.str.contains('|'.join(invest), flags=re.IGNORECASE), \"Lending and Investments\", \n                               pd.np.where(df1.market.str.contains('|'.join(manufacturing), flags=re.IGNORECASE), \"Manufacturing\",\n                               pd.np.where(df1.market.str.contains('|'.join(media), flags=re.IGNORECASE), \"Media and Entertainment\",\n                               pd.np.where(df1.market.str.contains('|'.join(message), flags=re.IGNORECASE), \"Messaging and Telecommunication\", \n                               pd.np.where(df1.market.str.contains('|'.join(mobile), flags=re.IGNORECASE), \"Mobile\", \n                               pd.np.where(df1.market.str.contains('|'.join(music), flags=re.IGNORECASE), \"Music and Audio\", \n                               pd.np.where(df1.market.str.contains('|'.join(resource), flags=re.IGNORECASE), \"Natural Resources\",\n                               pd.np.where(df1.market.str.contains('|'.join(navigation), flags=re.IGNORECASE), \"Navigation and Mapping\",\n                               pd.np.where(df1.market.str.contains('|'.join(payment), flags=re.IGNORECASE), \"Payments\", \n                               pd.np.where(df1.market.str.contains('|'.join(platforms), flags=re.IGNORECASE), \"Platforms\", \n                               pd.np.where(df1.market.str.contains('|'.join(privacy), flags=re.IGNORECASE), \"Privacy and Security\", \n                               pd.np.where(df1.market.str.contains('|'.join(services), flags=re.IGNORECASE), \"Professional Services\",\n                               pd.np.where(df1.market.str.contains('|'.join(realestate), flags=re.IGNORECASE), \"Real Estate\", \n                               pd.np.where(df1.market.str.contains('|'.join(sales), flags=re.IGNORECASE), \"Sales and Marketing\", \n                               pd.np.where(df1.market.str.contains('|'.join(science), flags=re.IGNORECASE), \"Science and Engineering\", \n                               pd.np.where(df1.market.str.contains('|'.join(sports), flags=re.IGNORECASE), \"Sports\",\n                               pd.np.where(df1.market.str.contains('|'.join(sustainability), flags=re.IGNORECASE), \"Sustainability\", \n                               pd.np.where(df1.market.str.contains('|'.join(transportation), flags=re.IGNORECASE), \"Transportation\", \n                               pd.np.where(df1.market.str.contains('|'.join(travel), flags=re.IGNORECASE), \"Travel and Tourism\", \n                               pd.np.where(df1.market.str.contains('|'.join(video), flags=re.IGNORECASE), \"Video\",\n                               pd.np.where(df1.market.str.contains('|'.join(other), flags=re.IGNORECASE), \"Other\",  \"Other\")))))))))))))))))))))))))))))))))))))))))))))))","84ed007b":"df1['Industry_Group'].unique() #Industry groups unique values","2a2cb47d":"df1['Industry_Group'].nunique() # number of industry groups","0eebcd5b":"df1.groupby(by = ['Industry_Group'])['permalink'].count().sort_values(ascending = False)#number of companies in each industry group\n#Software still is the most","8205e90b":"df1['total_investment'].hist(bins = 100) # histogram of total investment","2fc9e24e":"country = pd.read_csv('..\/input\/country\/country.csv') # uploading dataset to map countyr code to continent\ncountry = country[['Continent_Name', 'Three_Letter_Country_Code', 'Country_Name']]\ncountry = country.dropna(how='any',axis=0) \ncountry.isnull().sum() # checking if there is null values","b354dcda":"df1 = df1.merge(country, left_on='country_code', right_on='Three_Letter_Country_Code')\n# merging both datasets and creating new column called continent\ndf1.columns","639c07bd":"df1.groupby(by = ['Continent_Name'])['permalink'].count() #number of companies in each continent\n# North America is the highest","6d77bc53":"df1.shape # shape of datagrame","6021a567":"df1.hist(column=['funding_rounds', 'seed', 'venture', 'equity_crowdfunding',\n       'undisclosed', 'convertible_note', 'debt_financing', 'angel', 'grant',\n       'private_equity', 'post_ipo_equity', 'post_ipo_debt',\n       'secondary_market', 'product_crowdfunding', 'round_A', 'round_B',\n       'round_C', 'round_D', 'round_E', 'round_F', 'round_G', 'round_H',\n       'diff_funding_year', 'total_investment'], bins=100, grid=False, figsize=(20,15), color='#86bf91', zorder=2, rwidth=0.9) \n       # creating histogram of all numberical values, all values are very skewed","59fc557c":"df1.isin([0]).sum()# total number of zeros in each column\n# there is still a lot fo zeros","6ef8f1d5":"df2 = df1.copy() # copying the df1","29fb9805":"df2 = df2.drop(['Three_Letter_Country_Code', 'Country_Name', 'diff_funding_months', 'country_code', 'market'], axis=1) # dropping unnecessary columns","b73a7bc9":"df2[['funding_rounds', 'seed', 'venture', 'equity_crowdfunding',\n       'undisclosed', 'convertible_note', 'debt_financing', 'angel', 'grant',\n       'private_equity', 'post_ipo_equity', 'post_ipo_debt',\n       'secondary_market', 'product_crowdfunding', 'round_A', 'round_B',\n       'round_C', 'round_D', 'round_E', 'round_F', 'round_G', 'round_H',\n       'diff_funding_year', 'total_investment']].describe().T","e93b0466":"#creating categories of these numerical values based on the output from the describe data. Also creating new column for the categories\ncat_invest = pd.cut(df2.total_investment, bins = [-1, 112500, 1400300, 8205200, 40079503000], labels=['low','low_medium','high_medium','high'])\n#labeling total investment values as low, low medium, high medium and high based on their descriptive summary. \ndf2.insert(0,'cat_total_investment',cat_invest) # creating new column called cat_total_investment","d1aa7cb8":"cat_diff_funding_year = pd.cut(df2.diff_funding_year, bins = [-1, 2, 49], labels=['low','high'])\n#labeling diff_funding_year as low and high based on their descriptive summary. \ndf2.insert(0,'cat_diff_funding_year',cat_diff_funding_year)# creating new column called cat_diff_funding_year","07f85448":"cat_funding_rounds = pd.cut(df2.funding_rounds, bins = [-1, 2, 20], labels=['low','high'])\n#labeling funding_rounds as low and high based on their descriptive summary. \ndf2.insert(0,'cat_funding_rounds',cat_funding_rounds)# creating new column called cat_funding_rounds","27d629e1":"cat_seed = pd.cut(df2.seed, bins = [-1, 28000, 140000000], labels=['low','high'])\n#labeling seed as low and high  based on their descriptive summary. \ndf2.insert(0,'cat_seed',cat_seed)# creating new column called cat_seed","b06fcff2":"cat_venture = pd.cut(df2.venture, bins = [-1, 85038.5, 6000000, 2451000000], labels=['low','medium','high'])\n#labeling venture as low, medium and high based on their descriptive summary. \ndf2.insert(0,'cat_venture',cat_venture) # creating new column called cat_venture","0e0d7608":"# fixing the categorical columns  into numerical values so that we can use it on the model\ndf2['cat_status'] = df2['status'].replace(['closed', 'operating', 'acquired'], [0, 1, 2])\ndf2['cat_total_investment'] = df2['cat_total_investment'].replace(['low','low_medium','high_medium','high'], [0, 1, 2, 3])\ndf2['cat_diff_funding_year'] = df2['cat_diff_funding_year'].replace(['low', 'high'], [0, 1])\ndf2['cat_funding_rounds'] = df2['cat_funding_rounds'].replace(['low', 'high'], [0, 1])\ndf2['cat_seed'] = df2['cat_seed'].replace(['low', 'high'], [0, 1])\ndf2['cat_venture'] = df2['cat_venture'].replace(['low','medium','high'], [0, 1, 3])","6b503ef5":"#as a lot of the money columns have 0, we are turning them into new categories of 0 and 1\ndf2.loc[df2['equity_crowdfunding'] < 1, 'cat_equity_crowdfunding'] = 0\ndf2.loc[df2['equity_crowdfunding'] > 1, 'cat_equity_crowdfunding'] = 1\n\n\ndf2.loc[df2['undisclosed'] < 1, 'cat_undisclosed'] = 0\ndf2.loc[df2['undisclosed'] > 1, 'cat_undisclosed'] = 1\n\n\ndf2.loc[df2['convertible_note'] < 1, 'cat_convertible_note'] = 0\ndf2.loc[df2['convertible_note'] > 1, 'cat_convertible_note'] = 1\n\ndf2.loc[df2['debt_financing'] < 1, 'cat_debt_financing'] = 0\ndf2.loc[df2['debt_financing'] > 1, 'cat_debt_financing'] = 1\n\ndf2.loc[df2['angel'] < 1, 'cat_angel'] = 0\ndf2.loc[df2['angel'] > 1, 'cat_angel'] = 1\n\ndf2.loc[df2['grant'] < 1, 'cat_grant'] = 0\ndf2.loc[df2['grant'] > 1, 'cat_grant'] = 1\n\n\ndf2.loc[df2['private_equity'] < 1, 'cat_private_equity'] = 0\ndf2.loc[df2['private_equity'] > 1, 'cat_private_equity'] = 1\n\ndf2.loc[df2['post_ipo_equity'] < 1, 'cat_post_ipo_equity'] = 0\ndf2.loc[df2['post_ipo_equity'] > 1, 'cat_post_ipo_equity'] = 1\n\ndf2.loc[df2['post_ipo_debt'] < 1, 'cat_post_ipo_debt'] = 0\ndf2.loc[df2['post_ipo_debt'] > 1, 'cat_post_ipo_debt'] = 1\n\ndf2.loc[df2['secondary_market'] < 1, 'cat_secondary_market'] = 0\ndf2.loc[df2['secondary_market'] > 1, 'cat_secondary_market'] = 1\n\ndf2.loc[df2['product_crowdfunding'] < 1, 'cat_product_crowdfunding'] = 0\ndf2.loc[df2['product_crowdfunding'] > 1, 'cat_product_crowdfunding'] = 1\n\ndf2.loc[df2['round_A'] < 1, 'cat_round_A'] = 0\ndf2.loc[df2['round_A'] > 1, 'cat_round_A'] = 1\n\ndf2.loc[df2['round_B'] < 1, 'cat_round_B'] = 0\ndf2.loc[df2['round_B'] > 1, 'cat_round_B'] = 1\n\ndf2.loc[df2['round_C'] < 1, 'cat_round_C'] = 0\ndf2.loc[df2['round_C'] > 1, 'cat_round_C'] = 1\n\ndf2.loc[df2['round_D'] < 1, 'cat_round_D'] = 0\ndf2.loc[df2['round_D'] > 1, 'cat_round_D'] = 1\n\ndf2.loc[df2['round_E'] < 1, 'cat_round_E'] = 0\ndf2.loc[df2['round_E'] > 1, 'cat_round_E'] = 1\n\ndf2.loc[df2['round_F'] < 1, 'cat_round_F'] = 0\ndf2.loc[df2['round_F'] > 1, 'cat_round_F'] = 1\n\ndf2.loc[df2['round_G'] < 1, 'cat_round_G'] = 0\ndf2.loc[df2['round_G'] > 1, 'cat_round_G'] = 1\n\ndf2.loc[df2['round_H'] < 1, 'cat_round_H'] = 0\ndf2.loc[df2['round_H'] > 1, 'cat_round_H'] = 1","0f0e2882":"# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n#using label encoder for these two columns as there is a lot of variables\ndf2['cat_Continent_Name'] = labelencoder.fit_transform(df2['Continent_Name']) # using label encoder on continent\ndf2['cat_Industry_Group'] = labelencoder.fit_transform(df2['Industry_Group']) # using label encoder on industry group","0a483076":"df3 = df2[['cat_status', 'cat_Industry_Group',\n       'cat_Continent_Name','cat_funding_rounds',\n       'cat_diff_funding_year', 'cat_total_investment' , \n       'cat_equity_crowdfunding', 'cat_venture', 'cat_seed', 'cat_undisclosed',\n       'cat_convertible_note', 'cat_debt_financing', 'cat_angel', 'cat_grant',\n       'cat_private_equity', 'cat_post_ipo_equity', 'cat_post_ipo_debt',\n       'cat_secondary_market', 'cat_product_crowdfunding', 'cat_round_A',\n       'cat_round_B', 'cat_round_C', 'cat_round_D', 'cat_round_E',\n       'cat_round_F', 'cat_round_G', 'cat_round_H']] # Selecting the columns we need for the model\n\ndf3.head()","c35a6cbc":"df3.dtypes #data type of each column\n# making sure they are all numbers","52e89693":"df3.isna().sum() #number of null values in each column\n# making sure there is no null values","47fa6f2b":"#creating correlation matrix\ncolormap = plt.cm.viridis\nplt.figure(figsize = (35, 35))\nplt.title('Pearson Correlation of features', y = 1.05, size = 15)\nmatrix = np.triu(df3.corr())\nsns.heatmap(df3.astype(float).corr(), linewidth = 0.1, vmax = 1.0, square =True, cmap=colormap, linecolor = 'white', annot=True, mask = matrix)\n\n#we can remove cat_equity_crowdfunding, cat_undisclosed, cat_convertible_note, cat_grant , cat_post_ipo_equity, cat_post_ipo_debt, cat_secondary_market, cat_product_crowdfunding, cat_round_G, cat_round_H","c45f0515":"df3.shape","15e960cd":"df4 = df3[['cat_status', 'cat_Industry_Group', 'cat_Continent_Name',\n       'cat_funding_rounds', 'cat_diff_funding_year', 'cat_total_investment', 'cat_venture', 'cat_seed', 'cat_debt_financing', 'cat_angel',\n       'cat_private_equity', 'cat_round_A',\n       'cat_round_B', 'cat_round_C', 'cat_round_D', 'cat_round_E',\n       'cat_round_F']] # selecting the columns we need\n       #you can use this dataset for the model. Created after excluding columns with less correlation\n\ndf4.shape # shape of dataset","c8e1d5fc":"df4.head()","2f688fd6":"# Making new datafram that removes the operating value\ndf5 = df3.copy()\ndf5.drop(df5.index[df5['cat_status'] == 1], inplace = True)\ndf5 = df5.replace({'cat_status':2},1) # only 0 and 1, 0 means closed and 1 means acquired","ff627437":"colormap = plt.cm.viridis\nplt.figure(figsize = (35, 35))\nplt.title('Pearson Correlation of features', y = 1.05, size = 15)\nmatrix = np.triu(df5.corr())\nsns.heatmap(df5.astype(float).corr(), linewidth = 0.1, vmax = 1.0, square =True, cmap=colormap, linecolor = 'white', annot=True, mask = matrix)\n\n#we can remove cat_equity_crowdfunding, cat_undisclosed, cat_convertible_note, cat_grant , cat_post_ipo_equity, cat_post_ipo_debt, cat_secondary_market, cat_product_crowdfunding, cat_round_G, cat_round_H. This is the same as the other dataframe\n#venture and investment is highly correlated. Also high correlation between the round and the round after it. ","3a35ae9c":"df5 = df5[['cat_status', 'cat_Industry_Group', 'cat_Continent_Name',\n       'cat_funding_rounds', 'cat_diff_funding_year', 'cat_total_investment', 'cat_venture', 'cat_seed', 'cat_debt_financing', 'cat_angel',\n       'cat_private_equity', 'cat_round_A',\n       'cat_round_B', 'cat_round_C', 'cat_round_D', 'cat_round_E',\n       'cat_round_F']] # selecting the columns we need based on the correlation matrix","d9f844fd":"df5['cat_status'].count()# number of companies","aae7896f":"df5.shape # shape of dataframe","fdecc73d":"Y = df4.cat_status #setting Y variable\nX = df4.drop('cat_status', axis = 1) #dropping status and setting features\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)#test and train dataset","4281b384":"#checking size of each dataset\nprint('Shape of X_train=>',X_train.shape)\nprint('Shape of X_test=>',X_test.shape)\nprint('Shape of Y_train=>',Y_train.shape)\nprint('Shape of Y_test=>',Y_test.shape)","d95e44a0":"# testing with regular decision tree\nclf = DecisionTreeClassifier(random_state = 100) \nclf = clf.fit(X_train, Y_train)#train decison tree classifier","689f2fd2":"preds = clf.predict(X_test) # predict the response for test data\n\nprint(accuracy_score(Y_test,preds))\nprint(accuracy_score(Y_train,clf.predict(X_train)))\n\nprint('\\nClassification Report\\n')\nprint(classification_report(Y_test, preds, target_names=['Closed', 'Operating', 'Acquired']))\n#accuracy score is high for training dataset which shows that it might be overfitting","bbf77546":"#commenting the hyper parameter tuning part as it takes too long on kaggle to run it.\n\"\"\"\n#Hyper parameter tuning\nparam_dict = {\n    \"criterion\":['gini', 'entropy'],\n    \"max_depth\": range(1,20),\n    \"min_samples_split\": range(1,20),\n    \"min_samples_leaf\": range(1,10)\n}\n\ndecision_tree = DecisionTreeClassifier()\ngrid = GridSearchCV(decision_tree,\n                    param_grid = param_dict,\n                    cv = 10, # cross validation method\n                    verbose = 1,\n                    n_jobs = -1) # set to use all processors\n\ngrid.fit(X_train, Y_train)\n\"\"\"","4b7b082c":"# finding the best grid parameter\n#grid.best_params_ ","0f7fb44d":"#grid.best_estimator_","18b0d373":"#using paramerters from the grid search to create the model\nclf = DecisionTreeClassifier(criterion = 'entropy', max_depth = 5, min_samples_leaf = 1, min_samples_split=2, random_state=40)\nclf.fit(X_train,Y_train) #fitting into the model\ny_train_pred=clf.predict(X_train)\ny_test_pred=clf.predict(X_test)\n#test and train score are closer\n\nprint(accuracy_score(Y_train,y_train_pred),accuracy_score(Y_test,y_test_pred)) #accuracy score of test and train data. \nprint('\\nClassification Report\\n')\nprint(classification_report(Y_test, y_test_pred, target_names=['Closed', 'Operating', 'Acquired'])) # classification report","ed5fb163":"#visual representation of the model\nxvar = df4.drop('cat_status', axis=1)\nfeature_cols = xvar.columns\ndot_data = StringIO()\nexport_graphviz(clf, out_file=dot_data,  \n                filled=True, rounded=True,\n                special_characters=True,feature_names = feature_cols,class_names=['closed','operating','acquired'])\n\n(graph, ) = graph_from_dot_data(dot_data.getvalue())\nImage(graph.create_png())","c41d67c7":"feat_importance = clf.tree_.compute_feature_importances(normalize=False)\nfeat_imp_dict = dict(zip(feature_cols, clf.feature_importances_))\nfeat_imp = pd.DataFrame.from_dict(feat_imp_dict, orient='index')\nfeat_imp.rename(columns = {0:'FeatureImportance'}, inplace = True)\nfeat_imp.sort_values(by=['FeatureImportance'], ascending=False).head(6)#top 20 feature impacting decision tree split","80a1975c":"#creating sample data frame to test the model and predict\nsample_data = {'cat_Industry_Group': np.random.choice(range(0,42,1), size = (5)),\n        'cat_Continent_Name': np.random.choice(range(0,5,1), size = (5)),\n        'cat_funding_rounds': np.random.choice([0,1], size = (5)),\n        'cat_diff_funding_year': np.random.choice([0,1], size = (5)),\n        'cat_total_investment': np.random.choice([0,1,2,3], size = (5)),\n        'cat_venture': np.random.choice([0,1,2,3], size = (5)),\n        'cat_seed': np.random.choice([0,1], size = (5)),\n        'cat_debt_financing': np.random.choice([0,1], size = (5)),\n        'cat_angel': np.random.choice([0,1], size = (5)),\n        'cat_private_equity': np.random.choice([0,1], size = (5)),\n        'cat_round_A': np.random.choice([0,1], size = (5)),\n        'cat_round_B': np.random.choice([0,1], size = (5)),\n        'cat_round_C': np.random.choice([0,1], size = (5)),\n        'cat_round_D': np.random.choice([0,1], size = (5)),\n        'cat_round_E': np.random.choice([0,1], size = (5)),\n        'cat_round_F': np.random.choice([0,1], size = (5))\n       }\nsample = pd.DataFrame(sample_data, index=[0,1,2,3,4])\nsample # sample dataset","afd39edb":"ynew = clf.predict(sample)\nynew #predicted value from the sample dataset. 0 means close, 1 measn operating, 2 means acquired","4c022fb2":"Y5 = df5.cat_status # need to be classified as this\nX5 = df5.drop('cat_status', axis = 1) #dropping status and leaving only features\nX_train5, X_test5, Y_train5, Y_test5 = train_test_split(X5, Y5, test_size = 0.2, random_state = 42)","201e4bee":"#testing with small decision tree \nclf_pruned5 = DecisionTreeClassifier(criterion = \"gini\", random_state = 20,\n                               max_depth=3, min_samples_leaf=5) # using depth of 3 for simplicity\nclf_pruned5.fit(X_train5, Y_train5) # fitting the model","9d84d88d":"preds_pruned5 = clf_pruned5.predict(X_test5)\npreds_pruned_train5 = clf_pruned5.predict(X_train5)\n\nprint(accuracy_score(Y_test5, preds_pruned5)) # accuracy score of test dataset\n\nprint(accuracy_score(Y_train5, preds_pruned_train5))#accuracy score of train dataset\n#accuracy score for train dataset is more than test so model might be overfitting","074bdf6a":"print('\\nClassification Report\\n') # Classification report\nprint(classification_report(Y_test5, preds_pruned5, target_names=['Class 0', 'Class 1']))","acb6c5d7":"#commenting this part as kaggle take too long\n\"\"\"\n#using grid search to do hyper parameter tuning\nparam_dict = {\n    \"criterion\":['gini', 'entropy'],\n    \"max_depth\": range(1,20),\n    \"min_samples_split\": range(1,20),\n    \"min_samples_leaf\": range(1,10)\n}\n\ndecision_tree = DecisionTreeClassifier()\ngrid = GridSearchCV(decision_tree,\n                    param_grid = param_dict,\n                    cv = 10, # cross validation method\n                    verbose = 1,\n                    n_jobs = -1) # set to use all processors\n\n\ngrid.fit(X_train5, Y_train5)\n\"\"\"","00d1b680":"#grid.best_params_ # best grid parameters","ee761259":"#grid.best_estimator_","05571103":"#using parameter from grid to run model\nclf_pruned5 = DecisionTreeClassifier(criterion = \"gini\", random_state = 20,\n                               max_depth=3, min_samples_leaf=1, min_samples_split=2) \nclf_pruned5.fit(X_train5, Y_train5)\n\npreds_pruned5 = clf_pruned5.predict(X_test5)\npreds_pruned_train5 = clf_pruned5.predict(X_train5)\nprint(accuracy_score(Y_test5,preds_pruned5))#accuracy score\nprint(accuracy_score(Y_train5,preds_pruned_train5))# accuracy score\n\n#classification report\nprint('\\nClassification Report\\n')\nprint(classification_report(Y_test5, preds_pruned5, target_names=['Class 0', 'Class 1']))","cb8e9dd2":"#visualizing the tree\nxvar5 = df5.drop('cat_status', axis=1)\nfeature_cols5 = xvar5.columns\ndot_data5 = StringIO()\nexport_graphviz(clf_pruned5, out_file=dot_data5,  \n                filled=True, rounded=True,\n                special_characters=True,feature_names = feature_cols5,class_names=['0','1'])\n\n(graph, ) = graph_from_dot_data(dot_data5.getvalue())\nImage(graph.create_png())","d73b3d2b":"#Calculating feature importance\nfeat_importance5 = clf_pruned5.tree_.compute_feature_importances(normalize=False)\nfeat_imp_dict5 = dict(zip(feature_cols5, clf_pruned5.feature_importances_))\nfeat_imp5 = pd.DataFrame.from_dict(feat_imp_dict5, orient='index')\nfeat_imp5.rename(columns = {0:'FeatureImportance'}, inplace = True)\nfeat_imp5.sort_values(by=['FeatureImportance'], ascending=False).head()#top 5 feature impacting decision tree split","e358060a":"#creating sample data frame to test the model and predict\nsample_data = {'cat_Industry_Group': np.random.choice(range(0,42,1), size = (5)),\n        'cat_Continent_Name': np.random.choice(range(0,5,1), size = (5)),\n        'cat_funding_rounds': np.random.choice([0,1], size = (5)),\n        'cat_diff_funding_year': np.random.choice([0,1], size = (5)),\n        'cat_total_investment': np.random.choice([0,1,2,3], size = (5)),\n        'cat_venture': np.random.choice([0,1,2,3], size = (5)),\n        'cat_seed': np.random.choice([0,1], size = (5)),\n        'cat_debt_financing': np.random.choice([0,1], size = (5)),\n        'cat_angel': np.random.choice([0,1], size = (5)),\n        'cat_private_equity': np.random.choice([0,1], size = (5)),\n        'cat_round_A': np.random.choice([0,1], size = (5)),\n        'cat_round_B': np.random.choice([0,1], size = (5)),\n        'cat_round_C': np.random.choice([0,1], size = (5)),\n        'cat_round_D': np.random.choice([0,1], size = (5)),\n        'cat_round_E': np.random.choice([0,1], size = (5)),\n        'cat_round_F': np.random.choice([0,1], size = (5))\n       }\nsample = pd.DataFrame(sample_data, index=[0,1,2,3,4])\nynew = clf_pruned5.predict(sample)\nynew # predicting using decision tree binomial model","9badde5b":"Y = df4.cat_status\nX = df4.drop('cat_status', axis = 1) #setting features\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)# test and train dataset","c462d92f":"rfc = RandomForestClassifier(n_estimators = 1000, random_state = 42)\nrfc.fit(X_train, Y_train)#training the model","9f6850de":"rfc_pred_test = rfc.predict(X_test)\nprint(classification_report(Y_test, rfc_pred_test, target_names=['Class 1', 'Class 2', 'Class 3'])) # model is overfitting for class2 and bad at fitting 1 and 3","b44cb4d4":"# Get numerical feature importances\nimportances = list(rfc.feature_importances_)\nfeature_list = list(X.columns)\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","fb2e6b13":"#commenting this part as Kaggle take too long to run\n\"\"\"\n#Using Random Grid\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)\n\"\"\"","b2a54700":"\"\"\"\n# Use the random grid to search for best hyperparameters\n\n# First create the base model to tune\nrf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train, Y_train)\n\"\"\"","b54d8b59":"#rf_random.best_params_ # finding best parameter","758815ba":"rfc = RandomForestClassifier(n_estimators = 1600, min_samples_split= 2, min_samples_leaf= 4, max_features= \"sqrt\", max_depth =10, bootstrap = True, random_state = 42)\nrfc.fit(X_train, Y_train) \n\nrfc_pred_test = rfc.predict(X_test)\nprint(classification_report(Y_test, rfc_pred_test, target_names=['Class 1', 'Class 2', 'Class 3']))","3dec7b3e":"#creating sample data frame to test the model and predict\nsample_data = {'cat_Industry_Group': np.random.choice(range(0,42,1), size = (5)),\n        'cat_Continent_Name': np.random.choice(range(0,5,1), size = (5)),\n        'cat_funding_rounds': np.random.choice([0,1], size = (5)),\n        'cat_diff_funding_year': np.random.choice([0,1], size = (5)),\n        'cat_total_investment': np.random.choice([0,1,2,3], size = (5)),\n        'cat_venture': np.random.choice([0,1,2,3], size = (5)),\n        'cat_seed': np.random.choice([0,1], size = (5)),\n        'cat_debt_financing': np.random.choice([0,1], size = (5)),\n        'cat_angel': np.random.choice([0,1], size = (5)),\n        'cat_private_equity': np.random.choice([0,1], size = (5)),\n        'cat_round_A': np.random.choice([0,1], size = (5)),\n        'cat_round_B': np.random.choice([0,1], size = (5)),\n        'cat_round_C': np.random.choice([0,1], size = (5)),\n        'cat_round_D': np.random.choice([0,1], size = (5)),\n        'cat_round_E': np.random.choice([0,1], size = (5)),\n        'cat_round_F': np.random.choice([0,1], size = (5))\n       }\nsample = pd.DataFrame(sample_data, index=[0,1,2,3,4])\nynew = rfc.predict(sample)\nynew # 0 means close, 1 means operating and 2 means acquired","8bf8ba0e":"Y5 = df5.cat_status# setting y variable\nX5 = df5.drop('cat_status', axis = 1) # setting features\nX_train5, X_test5, Y_train5, Y_test5 = train_test_split(X5, Y5, test_size = 0.2, random_state = 42) # test and train data","026910de":"rfc5 = RandomForestClassifier(n_estimators = 1000, random_state = 42)\nrfc5.fit(X_train5, Y_train5) # using df5 and fitting the data","44046de8":"rfc_pred_test5 = rfc5.predict(X_test5) # predicting for test\nprint(classification_report(Y_test5, rfc_pred_test5, target_names=['Class 0', 'Class 1']))# classification report","12af8bc6":"# Get numerical feature importances\nimportances = list(rfc5.feature_importances_)\nfeature_list = list(X5.columns)\n# List of tuples with variable and importance\nfeature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n# Sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n\n#Industry group, Total investment and continent name is most important features. We can only include these moving forward","d4a47e42":"#commenting this part and it takes too long\n\"\"\"\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)\n\"\"\"","0cc3a30d":"\"\"\"\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestClassifier()\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# Fit the random search model\nrf_random.fit(X_train5, Y_train5)\n\"\"\"","911638b1":"#rf_random.best_params_ # best parameters","2fbaf812":"#using the parameters from grid search to make the model\nrfc5 = RandomForestClassifier(n_estimators = 200, min_samples_split= 5, min_samples_leaf= 4, max_features= \"auto\", max_depth =10, bootstrap = True, random_state = 42)\nrfc5.fit(X_train5, Y_train5) \n\nrfc_pred_test5 = rfc5.predict(X_test5)\nprint(classification_report(Y_test5, rfc_pred_test5, target_names=['Class 0', 'Class 1']))\n#scuracy rate remians the same, slight variation in other values","06215515":"#creating sample data frame to test the model and predict\nsample_data = {'cat_Industry_Group': np.random.choice(range(0,42,1), size = (5)),\n        'cat_Continent_Name': np.random.choice(range(0,5,1), size = (5)),\n        'cat_funding_rounds': np.random.choice([0,1], size = (5)),\n        'cat_diff_funding_year': np.random.choice([0,1], size = (5)),\n        'cat_total_investment': np.random.choice([0,1,2,3], size = (5)),\n        'cat_venture': np.random.choice([0,1,2,3], size = (5)),\n        'cat_seed': np.random.choice([0,1], size = (5)),\n        'cat_debt_financing': np.random.choice([0,1], size = (5)),\n        'cat_angel': np.random.choice([0,1], size = (5)),\n        'cat_private_equity': np.random.choice([0,1], size = (5)),\n        'cat_round_A': np.random.choice([0,1], size = (5)),\n        'cat_round_B': np.random.choice([0,1], size = (5)),\n        'cat_round_C': np.random.choice([0,1], size = (5)),\n        'cat_round_D': np.random.choice([0,1], size = (5)),\n        'cat_round_E': np.random.choice([0,1], size = (5)),\n        'cat_round_F': np.random.choice([0,1], size = (5))\n       }\nsample = pd.DataFrame(sample_data, index=[0,1,2,3,4])","2c9833a2":"ynew = clf_pruned5.predict(sample)\nynew # predicting using decision tree binomial model. 0 means closed and 1 means acquired","a987b566":"# Models","724e72c3":"To train the machine learning model, we used investment data about startup companies available on [Kaggle.](https:\/\/www.kaggle.com\/arindam235\/startup-investments-crunchbase) The data has been collected from Crun[](https:\/\/www.crunchbase.com\/)chbase which is a leading website for company insights from early stage startups to Fortune 1000. \n\nThe data had around 54k rows and 39 columns. The dataset had company information such as name of the company, url, market, country, state, region, city, founded date, first funding date, last funding date. It also had data on different investment types such as seed, venture equity crowdfunding, undisclosed funding, convertible note, debt financing, angel, grant, private equity, post ipo equity, post ipo debt, secondary market, product crowdfunding, round A-H series funding. Detailed descriptions of the different funding types is available [here](https:\/\/support.crunchbase.com\/hc\/en-us\/articles\/115010458467-Glossary-of-Funding-Types). Status of the companies were also available and segmented by acquired, operating and closed.\n","35fafc69":"To predict for acquired and closed companies only, we use a random forest model too. We used the same steps as the previous models.","9d98fe7c":"Startup investment can be very risky due to the high failure rate of startups. People like angel investors and venture capitalists have a very high risk while they are investing in startups.\nTo assist startup investors with their decisions, in this project we aim to find the important features that lead to startup success and forecast a company\u2019s success with supervised machine learning methods. \n","e84af883":"The analysis of the dataset was important to understand what is important to use in the final model. It also helped us understand the data more before using them in the models. The analysis below contains some of the important EDA we did on the data. \n\nMost of the companies were in the Software and Biotechnology industry. Biotechnology had the highest number in total funding. Mobile companies had the second lowest number in total funding. \n\nA lot of the companies raised venture and seed funding. The number of companies decreased as the companies proceeded to more series funding. Round G and H have a very low number of companies compared to round A and round B.\n\nMost of the acquired and operating companies are from the U.S. Acquired companies had higher mean and median funding compared to closed and operating companies. Acquired companies also had more number of funding rounds compared to companies with closed and operating statuses.\n\nIn terms of year, 2014 was the newest year and the oldest year was 1902. Most of the companies were founded quite recently around the 2000. The total investment data was very skewed, similar to the other type of funding.","0907fc9d":"#### Decision Tree: Binomial Classification","9116d9fc":"To clean the data, we removed extra spaces from different columns and also removed things like \u201c , \u201d, \u201c - \u201d where ever necessary. We made sure that columns that had numbers were being read as numbers and also converted all of the date columns into date data types.\n\nRows with null values were removed. Columns with a high percentage of null values like state, city, region, and found date were removed. \n","2f50e489":"# Statistics and Variable Selection","d9239ef1":"## Model: Random Forest","fba64688":"Multiclass classification model  was used to try to predict for closed, operating and acquired companies. It showed that Industry Group is the most important feature. ","45325cd5":"It showed that Industry Group is the most important feature. The important features are as follows:","45c6e578":"Startup refers to a company that is in their first stages of operations. Startups can be founded by one or more entrepreneurs who are working on developing a product or service.  Startups normally have very high cost and limited revenue. As they require a lot of capital to take it off the ground, they look for capital from a lot of sources like venture capitalists. \n\nStartups go through multiple rounds of funding to raise capital. The different funding rounds that let outside investors the opportunity to invest cash in exchange of equity or partial ownership of the company. Other types of investments are debt, convertible note, stock or dividends.  Startups can start off with \u201cseed\u201d funding or angel investor funding at the beginning. The next funding rounds  can be followed by  Series A, B, C and so on. Goal of most startups is to get acquired by a different company or become a publicly traded company.\n\n90% of startups fail due to bad product market fit, marketing problems, team problems or other issues. They also fail within the first few years. This makes startup investment very risky. Historically only venture capitalists could invest in startups but due to the recent trend in crowdfunding sites, an average investor can easily grab a piece of an exciting startup. ","7a730952":"Using the same classification model, we now tried predicting with a sample dataset.","a652bc09":"# Analysis","630c5170":"To make a decision about which columns to pick on the final model, we did a correlation matrix.  \n\nBecause of low correlation, we decided to leave out crowdfunding, undisclosed, convertible note, grant , post ipo equity, post ipo debt, secondary market, product crowdfunding, round G, round H from the final model. ","0a864c0a":"Using this mode, we now tried predicting with a sample dataset.","3e47df05":"The accurate rate came up to be 0.69 and it was good at predicting for both closed and acquired companies.","f481bdab":"Industry, continent and total investment are important features. We received the best result when we used SVM and Random Forest for Multi Class Classification. Received the best result when we used Random Forest for Binomial Classification.\nFor future scope, we would like more data for closed and acquired companies, test model with one-hot encoding, test with other models like Naive Bayes and XG Boost, test with KNN and SVM on Binary Classification Model. Using Crunchbase API, we can also make a real time dashboard and deploy a model so that it can assist investors and founders.","5d1b8447":"Random forest consists of a large number of individual decision trees that operate on ensemble. Ensemble method means that multiple models are generated and combined to solve the problem. For Random Forest, each individual tree in a random forest spits out a class prediction and the class with the most votes is the model\u2019s prediction","47393bf0":"# Methodology","5811db0b":"#### Decision Tree: Multi Class Classification","b5182d5d":"### Cleaning Data","ff3b549f":"![pic](https:\/\/qph.fs.quoracdn.net\/main-qimg-2f5a3c2b414be2553b8c85e340fdc604)","7359aec0":"When we decided to use only default values on the decision tree model, the model was overfitting. We used cost_complex_pruning_path from sklearn to find the most efficient alpha value that would help us prune the tree. The alpha value that would give the highest accuracy rate was used in the model. To tune the model, we also tested with grid search.  Tuning with  cost_complex_pruning_path and grid search gave the same accuracy results but their decision tree looked very different from each other. ","776fa5e4":"For the Binomial Classification, we tried to predict for closed and acquired companies. Using grid search, we tried to find the model parameters which give the best accuracy rate. We received the best accuracy rate when we used gini criterion, max depth of 3, min samples leaf of 1 and min samples split of 2.","5f1f49cd":"Decision Tree is a flow-chart like tree structure where the internal mode is considered as a feature and the branches are considered as a decision rule. It learns to partition on the basis of the attribute value. We used decision tree on both multiclass and binomial model","ecc8972d":"### Exploratory Data Analysis","b3ffa41a":"We will be using df4 for multiclass classification and df5 for binomial classification.","7b8f3012":"We used random grid search for hyper parameter tuning where--\n'n_estimators': 1600, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True. \nUsing these parameter the accuracy rate came up to be 0.86\n","bf306572":"We used random grid search for hyper parameter tuning where--\n'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': True. \nUsing these parameters the accuracy rate come up to be 0.69\n","4cb105d4":"We created a new column that included differences in time between the last and first funding date. \n\nA total investment column was also created that included the sum of all the investments (seed, venture, equity crowdfunding, undisclosed, convertible note, debt financing, angel, grant, private equity, post ipo equity, post ipo debt, secondary market, product crowdfunding).\n\nThe data contained 753 different market values. As there were a lot of different types of markets, we wanted to reduce this number. To reduce the number of markets, we grouped markets into different industry groups segment on the industry grouping list produced by crunchbase. The list can be found [here](https:\/\/support.crunchbase.com\/hc\/en-us\/articles\/360043146954-What-Industries-are-included-in-Crunchbase-). The new column Industry Group  had 43 industry groups .\n\nThe data contained 115 countries. The dataset was joined with a different dataset that contained the country name and continent. We made a new column for the continent name. \n\nNumerical values like total investment, difference in funding year, funding rounds, seed, venture were turned into categories like low and high based on their spread in number. The categorical values were again turned into numbers for the models to understand.\n\nOther columns like equity crowdfunding, undisclosed, convertible note, debt financing, angel, private equity, post ipo equity, secondary market, product crowdfunding, round A -H were turned into 0 and 1 based on if the company was able to raise that type of funding. This was done as the columns had too many zero values. \n","f2f3108f":"#### Random Forest: Multi Class Cassification","9dc18449":"# Conclusion","23a78edb":"According to this model, total investment, funding rounds, industry group, continent name were important features in understanding if a company will be successful or not. The model shows that total investment is very important and if it is less then the company is likely to be closed.","0c10fb42":"## Model: Decision Tree","7453ce57":"Before we could use the data to train the different models, we had to clean the data and select the most important columns to be included into the model. One of the biggest problems we had with the dataset was that it had a lot of zeros and a lot of columns to choose from. \n\nWe also realized later that the status column had around 80% of the companies as operating status and the rest as closed and acquired companies. \n","1707da5a":"Using grid search, we tried to find features that would get the best accuracy rate.  Our grid search gave us the best result when the criterion was entropy, max depth of 5, min sample leaf of 1 and min sample leaf of 2. According to the model total investment, continent name, and venture were the most important features. ","7af3e51d":"# Introduction","eb815269":"#### Random Forest: Binomial Classification","5cc9b2c0":"According to the model the important features are:\n","3058126f":"We used different types of models on the data to understand which model would be the best. We have tested with both multi class and binomial classification models. For multi class models, we were trying to predict for closed, acquired and operating companies. For binomial classification models, we tried to predict for closed and acquired companies only. \nAs the dataset contained 80% of the data that had operating companies, the multiclass model was good at predicting for operating companies.\nFor most of the models, 20% of the data was accounted for as a test dataset and results were drawn at random.\nWe also tested all models with undersampled data. However as biases get included into the result, we decided to leave it aside from the final analysis.","7f894c5a":"Used the model to predict for a sample dataset","3984bf93":"### Uploading the dataset","e5db80b3":"# Featured Engineering","927cf67a":"We used this model to predict for a sample dataframe.","2a4216b9":"## Data","b66149ac":"## Problem Statement"}}