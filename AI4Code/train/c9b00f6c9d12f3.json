{"cell_type":{"cf77d929":"code","11838e6f":"code","503d86d5":"code","0f0a9970":"code","457fdb03":"code","921e6a54":"code","f209c4fb":"code","3a072b43":"code","0b288f0a":"code","e9321a6c":"code","85faa270":"code","810ce636":"code","fe239816":"code","c38c8c04":"code","3dbaf41c":"code","d493eaed":"code","3e6722b3":"code","2193ea78":"code","52419686":"code","ade637ee":"code","05ff3ff0":"code","feee52e5":"code","c56a30b0":"code","7e02d7c9":"code","66a53f79":"code","5f2267d8":"code","9b3a432f":"code","61cd98f4":"code","473fd7b6":"code","9f368f95":"code","1f705098":"code","27612ef6":"code","a278f772":"code","d71f5ba9":"code","a36ff38b":"code","d2e5d726":"code","e51cad58":"code","5e5c5974":"code","6cea97b9":"code","4aacd0a1":"code","1b621bd8":"code","9fbea7f2":"code","fd6d5c03":"code","3fbf5407":"code","e0b92b6b":"markdown","de769759":"markdown","c5cf87af":"markdown","f88a800f":"markdown","c11d74b1":"markdown","24fdd82f":"markdown","40884af6":"markdown","ef7d1012":"markdown","7ed54cce":"markdown","16d0201a":"markdown","fe51f11a":"markdown","d52cdf61":"markdown","48263f33":"markdown","88151909":"markdown","5796b34a":"markdown","0d1f7356":"markdown"},"source":{"cf77d929":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","11838e6f":"housing = pd.read_csv('..\/input\/housing.csv')\nhousing.head()\n# housing.info()","503d86d5":"# Plot the histogram\nhousing.hist(bins=50, figsize=(20,15))\nplt.show()","0f0a9970":"# Write function to create test data\ndef split_train_test(data, test_ratio):\n    shuffled_indices = np.random.permutation(len(data))\n    test_set_size = int(len(data) * test_ratio)\n    test_indices = shuffled_indices[:test_set_size]\n    train_indices = shuffled_indices[test_set_size:]\n    return data.iloc[train_indices], data.iloc[test_indices]\n\n# Derive Train set and Test set\ntrain_set, test_set = split_train_test(housing, 0.2)","457fdb03":"import hashlib\n\ndef test_set_check(identifier, test_ratio, hash):\n    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n\ndef split_train_test_by_id(data, test_ratio, id_column, hash=hashlib.md5):\n    ids = data[id_column]\n    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))\n    return data.loc[-in_test_set], data.loc[in_test_set]","921e6a54":"from sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)","f209c4fb":"housing[\"income_cat\"] = np.ceil(housing[\"median_income\"]\/1.5)\nhousing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n\n","3a072b43":"from sklearn.model_selection import StratifiedShuffleSplit\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=.2, random_state=42)\nfor train_index, test_index in split.split(housing, housing.income_cat):\n    strat_train_set = housing.loc[train_index]\n    strat_test_set = housing.loc[test_index]","0b288f0a":"housing.income_cat.value_counts() \/ len(housing)","e9321a6c":"for set_ in (strat_train_set, strat_test_set):\n    set_.drop(\"income_cat\", axis=1, inplace=True)\n    \nhousing = strat_train_set.copy()","85faa270":"housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4, \n             s=housing[\"population\"]\/100, label=\"population\",figsize=(10,7),\n             c=\"median_house_value\",cmap=plt.get_cmap(\"jet\"),colorbar=True)\nplt.legend()","810ce636":"corr_matrix = housing.corr()\ncorr_matrix[\"median_house_value\"].sort_values(ascending=False)","fe239816":"from pandas.tools.plotting import scatter_matrix\n\nattributes = ['median_house_value', 'median_income', 'total_rooms', 'housing_median_age']\nscatter_matrix(housing[attributes], figsize=(12,8))","c38c8c04":"housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)","3dbaf41c":"housing[\"rooms_per_household\"] = housing[\"total_rooms\"]\/housing['households']\nhousing['bedrooms_per_room'] = housing['total_bedrooms']\/housing['total_rooms']\nhousing['population_per_household'] = housing['population']\/housing['households']","d493eaed":"corr_matrix = housing.corr()\ncorr_matrix['median_house_value'].sort_values(ascending=False)","3e6722b3":"housing = strat_train_set.drop('median_house_value', axis=1)\nhousing_labels = strat_train_set['median_house_value'].copy()","2193ea78":"housing_num = housing.drop(\"ocean_proximity\", axis=1)\n","52419686":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\nhousing_cat = housing['ocean_proximity']\nhousin_cat_encoded = encoder.fit_transform(housing_cat)\nprint(encoder.classes_)\nhousin_cat_encoded","ade637ee":"# Using 1 hot encoding\nfrom sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder()\nhousing_cat_1hot = encoder.fit_transform(housin_cat_encoded.reshape(-1,1))\nhousing_cat_1hot.toarray()","05ff3ff0":"from sklearn.preprocessing import LabelBinarizer\nencoder = LabelBinarizer()\nhousing_cat_1hot = encoder.fit_transform(housing_cat)\nhousing_cat_1hot","feee52e5":"from sklearn.base import BaseEstimator, TransformerMixin\n\nrooms_ix, bedrooms_ix, population_ix, household_ix = 3,4,5,6\n\nclass CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n    def __init__(self, add_bedrooms_per_room = True): # no *args or **kwargs\n        self.add_bedrooms_per_room = add_bedrooms_per_room\n    \n    def fit(self, X, y=None):\n        return self # nothing else to do\n    \n    def transform(self, X, y=None):\n        rooms_per_household = X[:, rooms_ix]\/X[:, household_ix]\n        population_per_household = X[:, population_ix]\/X[:, household_ix]\n        if self.add_bedrooms_per_room:\n            bedrooms_per_room = X[:, bedrooms_ix]\/X[:, rooms_ix]\n            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n        else:\n            return np.c_[X, rooms_per_household, population_per_household]\n        \nattr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\nhousing_extra_attribs = attr_adder.transform(housing.values)","c56a30b0":"# Transformation Pipelines\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, Imputer\n\nnum_pipeline = Pipeline([\n    ('imputer', Imputer(strategy='median')),\n    ('attribs_adder', CombinedAttributesAdder()),\n    ('std_scaler', StandardScaler())\n])\n\nhousing_num_tr = num_pipeline.fit_transform(housing_num)","7e02d7c9":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        return X[self.attribute_names].values","66a53f79":"num_attribs = list(housing_num)\ncat_attribs = [\"ocean_proximity\"]\n\nfrom sklearn.base import TransformerMixin #gives fit_transform method for free\nclass MyLabelBinarizer(TransformerMixin):\n    def __init__(self, *args, **kwargs):\n        self.encoder = LabelBinarizer(*args, **kwargs)\n    def fit(self, x, y=0):\n        self.encoder.fit(x)\n        return self\n    def transform(self, x, y=0):\n        return self.encoder.transform(x)\n\nnum_pipeline = Pipeline([\n    ('selector', DataFrameSelector(num_attribs)),\n    ('imputer', Imputer(strategy=\"median\")),\n    ('attribs_adder', CombinedAttributesAdder()),\n    ('std_scaler', StandardScaler())\n])\n\ncat_pipeline = Pipeline([\n    ('selector', DataFrameSelector(cat_attribs)),\n    ('label_binarizer', MyLabelBinarizer())\n])\n\nfrom sklearn.pipeline import FeatureUnion\n\nfull_pipeline = FeatureUnion(transformer_list=[\n    (\"num_pipeline\", num_pipeline),\n    (\"cat_pipeline\", cat_pipeline)\n])\n\n","5f2267d8":"housing_prepared = full_pipeline.fit_transform(housing)","9b3a432f":"housing_prepared","61cd98f4":"# Linear Regression\nfrom sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(housing_prepared, housing_labels)","473fd7b6":"some_data = housing.iloc[:5]\nsome_labels = housing_labels.iloc[:5]\nsome_data_prepared = full_pipeline.transform(some_data)\nprint(\"Predictions:\", lin_reg.predict(some_data_prepared))\nprint(\"Labels: \", some_labels)\n\nfrom sklearn.metrics import mean_squared_error\nhousing_predictions = lin_reg.predict(housing_prepared)\nlin_mse = mean_squared_error(housing_labels, housing_predictions)\nlin_rmse = np.sqrt(lin_mse)\nlin_rmse","9f368f95":"from sklearn.tree import DecisionTreeRegressor\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(housing_prepared, housing_labels)\n\nhousing_predictions = tree_reg.predict(housing_prepared)\ntree_mse = mean_squared_error(housing_labels, housing_predictions)\ntree_rmse = np.sqrt(tree_mse)\ntree_rmse","1f705098":"# Get scores\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\ntree_rmse_scores = np.sqrt(-scores)\n\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Mean:\",scores.mean())\n    print(\"Standard deviation:\", scores.std())\n    \ndisplay_scores(tree_rmse_scores)","27612ef6":"lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","a278f772":"from sklearn.ensemble import RandomForestRegressor\nforest_reg = RandomForestRegressor()\nforest_reg.fit(housing_prepared, housing_labels)\nforest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\nforest_scores_rmse = np.sqrt(-forest_scores)\ndisplay_scores(forest_scores_rmse)","d71f5ba9":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'n_estimators': [3, 10, 30], 'max_features':[2,4,6,8]},\n    {'bootstrap': [False], 'n_estimators':[3,10], 'max_features': [2, 3, 4]}\n]\n\nforest_reg = RandomForestRegressor()\n\ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring=\"neg_mean_squared_error\",refit=True)\n\ngrid_search.fit(housing_prepared, housing_labels)","a36ff38b":"print(grid_search.best_params_)\nprint(\"Best Estimator is\")\nprint(grid_search.best_estimator_)","d2e5d726":"cvres = grid_search.cv_results_\nfor mean_scre, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_scre), params)","e51cad58":"feature_importances = grid_search.best_estimator_.feature_importances_\nfeature_importances","5e5c5974":"extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\ncat_one_hot_attribs = list(encoder.classes_)\nattributes = num_attribs + extra_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)","6cea97b9":"final_model = grid_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\nY_test = strat_test_set[\"median_house_value\"].copy()\n\nx_test_prepared = full_pipeline.transform(X_test)\n\nfinal_predictions = final_model.predict(x_test_prepared)\n\nfinal_mse = mean_squared_error(Y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\nfinal_rmse","4aacd0a1":"from sklearn.svm import SVR\n\nsvm_reg = SVR(kernel=\"linear\",gamma=3.4,C=10)\nsvm_reg.fit(housing_prepared, housing_labels)","1b621bd8":"svm_pred = svm_reg.predict(housing_prepared)\nsvm_mse = mean_squared_error(housing_labels, svm_pred)\nsvm_rmse = np.sqrt(svm_mse)\nsvm_rmse","9fbea7f2":"from sklearn.model_selection import RandomizedSearchCV\n\nparam_grid = [\n    {'kernel': [\"rbf\",\"linear\"], \"gamma\": [0.5, 3.0, 20.0, 30.0, 80.0], \"C\": [10, 100, 1000]}\n]\n\nsvm_reg = SVR()\n\nrandom_search = GridSearchCV(svm_reg, param_grid, cv=5, scoring=\"neg_mean_squared_error\",refit=True)\n\nrandom_search.fit(housing_prepared, housing_labels)\n\nprint(random_search.best_params_)\nprint(\"Best Estimator is\")\nprint(random_search.best_estimator_)\n\ncvres = random_search.cv_results_\nfor mean_scre, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_scre), params)","fd6d5c03":"feature_importances = grid_search.best_estimator_.feature_importances_\nextra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\ncat_one_hot_attribs = list(encoder.classes_)\nattributes = num_attribs + extra_attribs + cat_one_hot_attribs\nsorted(zip(feature_importances, attributes), reverse=True)\n\nfinal_model = random_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\nY_test = strat_test_set[\"median_house_value\"].copy()\n\nx_test_prepared = full_pipeline.transform(X_test)\n\nfinal_predictions = final_model.predict(x_test_prepared)\n\nfinal_mse = mean_squared_error(Y_test, final_predictions)\nfinal_rmse = np.sqrt(final_mse)\nfinal_rmse","3fbf5407":"## ","e0b92b6b":"# Write hash regular function for test and train data\n* np.random.permutation(n):\n  Returns a random array of size 'n' having elements from 0 to n-1\n  ","de769759":"# Using GridSearchCV to tune Hyperparameters","c5cf87af":"# Write hashing function to generate test and train data","f88a800f":"## Automatically explore Some preparation options using GridSearchCV","c11d74b1":"# To be Continued\n## try adding a transformer in the pipeline to pick only important attributes","24fdd82f":"# Custom Transformer","40884af6":"Now try with Decision tree Regressor","ef7d1012":"## Split the data into train and test sets","7ed54cce":"# Prepare the data for Algorithms\n* Data cleaning","16d0201a":"## Try this using the RandomizedSearchCV\n\nUsing GridSearchCV because RandomizedSearchCV doesn't work in this scenario.\n\n[Refer here](https:\/\/stackoverflow.com\/questions\/36488564\/randomizedsearchcv-results-in-attribute-error)","fe51f11a":"# Use 1 Hot Binarizer\nUse Laber Binarizer to convert text values into 1 hot values directly","d52cdf61":"# Using Random Forest Regressor","48263f33":"## Handling text","88151909":"## Try full pipeline that does the data preparation plus prediction","5796b34a":"# Ex.1 Trying SVM\nUse different hyperparameters such as kernel=\"linear|rbf\" and various values for c, gammahyperparameter\n\n","0d1f7356":"# Evaluating the system on Test set"}}