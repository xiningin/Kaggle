{"cell_type":{"79cbc0e0":"code","0db0c686":"code","753a0280":"code","2978cb74":"code","c16a6c07":"code","cf268efd":"code","0d05cf41":"code","54651ece":"code","63c6439f":"code","7357b1d0":"code","4e22d2e2":"code","91246449":"code","f5890a45":"code","f5dccace":"code","1caf5a17":"code","0b864a16":"code","dd7a474a":"code","1b1d23f6":"code","88404aa5":"markdown","0fa00428":"markdown","327864be":"markdown","0581d219":"markdown","5a909b76":"markdown"},"source":{"79cbc0e0":"import numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport glob\n# Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nimport cv2\nfrom wordcloud import WordCloud, STOPWORDS\n#Text Processing\nimport re\nimport nltk\nnltk.download('popular')","0db0c686":"submittion_csv = pd.read_csv(\"..\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv\")\ntrain_csv = pd.read_csv(\"..\/input\/coleridgeinitiative-show-us-the-data\/train.csv\")\ntrain_dir = glob.glob(\"..\/input\/coleridgeinitiative-show-us-the-data\/train\/*\")\ntest_dir = glob.glob(\"..\/input\/coleridgeinitiative-show-us-the-data\/test\/*\")","753a0280":"train_csv.head()","2978cb74":"train_csv.describe()","c16a6c07":"#Total data: 19661\n#unique Id count: 14316\n#Ids are reused: 5345\nid_counts = pd.value_counts(train_csv[\"Id\"])\nfig = px.bar(x=id_counts.values[:20], y=id_counts.index[:20])\nx_axis = dict(tickmode = 'linear',\n    tick0 = 0,\n    dtick = 2)\ny_axis = dict(autorange=\"reversed\")\nfig.update_layout(\n    title=\"Id count\",\n    xaxis_title=\"Count\",\n    yaxis_title=\"Id\",\n    xaxis = x_axis,\n    yaxis = y_axis\n)\nfig.show()","cf268efd":"#Total data: 19661\n#unique Publication Titles: 14316\n#Publication Titles are reused: 5390\npub_counts = pd.value_counts(train_csv[\"pub_title\"])\nfig = px.bar(x=pub_counts.values[:20], y=pub_counts.index[:20])\nx_axis = dict(tickmode = 'linear',\n    tick0 = 0,\n    dtick = 2)\ny_axis = dict(autorange=\"reversed\",\n              tickmode=\"array\",\n              tickvals=list(range(len(pub_counts))),\n              ticktext = pub_counts.index[:20].map(lambda x: x[:40])\n    )\nfig.update_layout(\n    title=\"Pub Title Count\",\n    xaxis_title=\"Count\",\n    yaxis_title=\"Publication title\",\n    xaxis = x_axis,\n    yaxis = y_axis\n)\nfig.show()","0d05cf41":"#Total data: 19661\n#unique Dataset Titles: 45\ndataset_title_counts = pd.value_counts(train_csv[\"dataset_title\"])\nfig = px.bar(x=dataset_title_counts.values[:20], y=dataset_title_counts.index[:20])\n\ny_axis = dict(autorange=\"reversed\",\n              tickmode=\"array\",\n              tickvals=list(range(len(pub_counts))),\n              ticktext = dataset_title_counts.index[:20].map(lambda x: x[:40])\n    )\nfig.update_layout(\n    title=\"Pub Title Count\",\n    xaxis_title=\"Count\",\n    yaxis_title=\"Publication title\",\n    yaxis = y_axis\n)\nfig.show()","54651ece":"#Total data: 19661\n#unique Dataset Titles: 45\nclean_counts = pd.value_counts(train_csv[\"cleaned_label\"])\nfig = px.bar(x=clean_counts.values[:20], y=clean_counts.index[:20])\ny_axis = dict(autorange=\"reversed\",\n              tickmode=\"array\",\n              tickvals=list(range(len(clean_counts))),\n              ticktext = clean_counts.index[:20].map(lambda x: x[:40])\n    )\nfig.update_layout(\n    title=\"Pub Title Count\",\n    xaxis_title=\"Count\",\n    yaxis_title=\"Publication title\",\n    yaxis = y_axis\n)\nfig.show()","63c6439f":"def plot_wordcloud(column, title):\n    stopwords = set(STOPWORDS) \n    wordcloud = WordCloud(width = 800, \n                          height = 800,\n                          background_color ='white',\n                          min_font_size = 10,\n                          stopwords = stopwords).generate(' '.join(column)) \n    plt.figure(figsize = (8, 8), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n    plt.title('Wordcloud: ' + title, fontsize = 20)\n    plt.show()  ","7357b1d0":"plot_wordcloud(column = train_csv['pub_title'], title = 'Publication Title')","4e22d2e2":"def preprocess_text(text):\n    lst_stopwords = nltk.corpus.stopwords.words(\"english\")\n    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n    lst_text = text.split()\n    if lst_stopwords is not None:\n        lst_text = [word for word in lst_text if word not in \n                    lst_stopwords]\n\n    lem = nltk.stem.wordnet.WordNetLemmatizer()    \n    lst_text = [lem.lemmatize(word) for word in lst_text]\n\n    text = \" \".join(lst_text)\n    return text","91246449":"train_csv[\"clean_pub_title\"] = train_csv[\"pub_title\"].apply(lambda x: preprocess_text(x))\ntrain_csv[\"clean_pub_title_len\"] = train_csv[\"clean_pub_title\"].apply(lambda x: len(x))\ntrain_csv[\"clean_pub_title_word_count\"] =train_csv[\"clean_pub_title\"].apply(lambda x: len(str(x).split(\" \")))\ntrain_csv[\"clean_pub_title_char_count\"] = train_csv[\"clean_pub_title\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\ntrain_csv[\"clean_pub_title_avg_word_length\"] = train_csv[\"clean_pub_title_char_count\"] \/ train_csv[\"clean_pub_title_word_count\"]","f5890a45":"train_csv.head()","f5dccace":"plot_wordcloud(column = train_csv['clean_pub_title'], title = 'Publication Title')","1caf5a17":"plot_wordcloud(column = train_csv['dataset_title'], title = 'Dataset Title')","0b864a16":"plot_wordcloud(column = train_csv['cleaned_label'], title = 'Cleaned Label')","dd7a474a":"def plot_distribution(x, title):\n    fig = px.histogram(x)\n    fig.show()","1b1d23f6":"pub_title_list = [(\"clean_pub_title_len\", \"Publication Title: Length Distribution\"),\n                 (\"clean_pub_title_word_count\", \"Publication Title: Word Count Distribution\"),\n                 (\"clean_pub_title_char_count\", \"Publication Title: Character Count Distribution\"),\n                 (\"clean_pub_title_avg_word_length\", \"Publication Title: Average Word Length Distribution\")]\nfor i, j in pub_title_list:\n    plot_distribution(train_csv[i], j)","88404aa5":"<h2>Files<\/h2>\n<ul>\n<li><strong>train<\/strong> - the full text of the training set's publications in JSON format, broken into sections with section titles<\/li>\n<li><strong>test<\/strong> - the full text of the test set's publications in JSON format, broken into sections with section titles<\/li>\n<li><strong>train.csv<\/strong> - labels and metadata for the training set<\/li>\n<li><strong>sample_submission.csv<\/strong> - a sample submission file in the correct format<\/li>\n<\/ul>","0fa00428":"# Coleridge Initiative - Show US the Data","327864be":"* The objective of the competition is to identify the mention of datasets within scientific publications.\n* Predictions that more accurately match the precise words used to identify the dataset within the publication will score higher.\n* Predictions should be cleaned using the clean_text function from the Evaluation page to ensure proper matching.\n* The goal in this competition is not just to match known dataset strings but to generalize to datasets that have never been seen before using NLP and statistical techniques.\n* The hidden test set has roughly ~8000 publications, many times the size of the public test set.","0581d219":"<h2>Columns<\/h2>\n<ul>\n<li><code>id<\/code> - publication <code>id<\/code> - note that there are multiple rows for some training documents, indicating multiple mentioned datasets<\/li>\n<li><code>pub_title<\/code>&nbsp;- title of the publication (a small number of publications have the same title)<\/li>\n<li><code>dataset_title<\/code> - the title of the dataset that is mentioned within the publication<\/li>\n<li><code>dataset_label<\/code> - a portion of the text that indicates the dataset<\/li>\n<li><code>cleaned_label<\/code> - the <code>dataset_label<\/code>, as passed through the <code>clean_text<\/code> function from the <a rel=\"nofollow\" href=\"https:\/\/www.kaggle.com\/c\/coleridgeinitiative-show-us-the-data\/overview\/evaluation\">Evaluation page<\/a><\/li>\n<\/ul>","5a909b76":"Refrences:https:\/\/www.kaggle.com\/ishandutta\/coleridge-complete-eda-in-one-notebook"}}