{"cell_type":{"c4fa44f3":"code","0d20705e":"code","dedd3df7":"code","91c7f365":"code","101e7291":"code","bd47a8d3":"code","1501ab80":"code","9ea790fc":"code","c9014f16":"code","e25ded3b":"code","da794c95":"code","c17829cf":"code","9cf07846":"code","e44a19e0":"code","16e13354":"code","40289b1e":"code","be1d3805":"code","67b423e7":"code","b01172fa":"code","b9dbdd10":"code","6ad3cf92":"code","180b1d47":"code","52f53d4a":"code","ce4e2a22":"code","1af919a1":"code","a6ec60ed":"code","638b68ff":"code","67077910":"code","9a484d9c":"code","1f7fc533":"code","372a44ea":"code","25c8088a":"code","3d3d77b9":"code","ada35d05":"code","89d31029":"code","d3af9f48":"code","4977d8d2":"code","448b78fc":"code","ce4ab265":"code","046a74fa":"code","ebc504ba":"code","01026a5f":"code","cc44081e":"code","1c5468e8":"code","0fc2a265":"code","614ce0c6":"code","3cde1e2e":"code","6cde9b7c":"code","4deaa598":"code","036af385":"code","4be51753":"code","d2520a62":"code","08ccbb60":"code","1f13f19c":"code","b5cb24a5":"code","4f8026a7":"code","450c3a79":"code","3037a3de":"code","21bf398d":"code","58341a6e":"code","205d995f":"code","02aa2098":"code","30f959af":"code","0b2523bf":"code","0f886ce0":"code","f0c12566":"code","98e60ac8":"code","371a8f49":"code","8c22a9a5":"code","e764e0e5":"code","20cf887a":"code","33afaa32":"code","84e3ccc3":"code","845882ab":"code","16ff6ce2":"code","fa00e3ed":"code","4747bb2c":"code","98cd316f":"code","11943f12":"code","04ab0f9d":"code","117efabb":"code","0142fa17":"code","26e82bd9":"code","2e590aea":"code","44151869":"code","26c78f16":"code","45671158":"code","cc933073":"code","3e8c9834":"code","2dbb053d":"code","16f46165":"code","91e789c1":"code","b843932e":"markdown","e511f838":"markdown","f0b55982":"markdown","7000fa45":"markdown","95290ff6":"markdown","2225470a":"markdown","478837ee":"markdown","d7c93db1":"markdown","cc31c2f7":"markdown","7c7df13e":"markdown","1df068f9":"markdown","0c3a335c":"markdown","c6356e7f":"markdown","4ee4d3d6":"markdown","9373cb77":"markdown","a8321dfc":"markdown","d6c0b77d":"markdown","d53c1ba3":"markdown","c3955283":"markdown","07458242":"markdown","69d40bcf":"markdown","18fbaa57":"markdown","494ad8a4":"markdown","2eaf03c6":"markdown","350a6b46":"markdown","d37e9fc1":"markdown","99041ad0":"markdown","e64ee6dd":"markdown","88eaf9a5":"markdown","5468f03c":"markdown"},"source":{"c4fa44f3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings('ignore')\n# Any results you write to the current directory are saved as output.\n\n!pip install fastai==0.7.0 --quiet\n\nimport datetime as dt\nfrom fastai.structured import add_datepart","0d20705e":"from scipy import stats","dedd3df7":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","91c7f365":"train.head()","101e7291":"train.shape, test.shape","bd47a8d3":"train.describe()","1501ab80":"train.isna().sum()","9ea790fc":"train.columns","c9014f16":"## Converting columns into usable form\n\nimport ast\n\nfor column in ['belongs_to_collection','genres', 'production_companies','production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']:\n    train[column] = train[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))","e25ded3b":"train['collection_name'] = train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x!={} else 0)\ntrain['has_collection'] = train['belongs_to_collection'].apply(lambda x: 1 if x!={} else 0)\n\ntrain = train.drop(['belongs_to_collection'], axis=1)","da794c95":"train","c17829cf":"train['has_homepage'] = train['homepage'].apply(lambda x: 0 if pd.isna(x) else 1)\n\ntrain = train.drop(['homepage'], axis=1)","9cf07846":"train['num_genre'] = train['genres'].apply(lambda x: len(x) if x!= {} else 0)","e44a19e0":"train['all_genre'] = train['genres'].apply(lambda x: ' '.join([e['name'] for e in x]) if x!= {} else '')\n\ntrain['all_genre'] = list(train['all_genre'].apply(lambda x: x.split(\" \") if x!='' else [] ))\n\nlist_all_genre = list(train['all_genre'])\n\nlist_of_genres = list(set([genre for list_gen in list_all_genre for genre in list_gen]))\n\nlist_of_genres = ['gen_'+ s for s in list_of_genres]\n\ntrain = train.reindex( columns = train.columns.tolist() + list_of_genres)\n\nfor i, e in train.iterrows():\n    for genre in (e['all_genre']):\n        #print(genre)\n        #print(train.loc[i,('gen_'+genre)])\n        train.loc[i,('gen_'+genre)] =1\n\ntrain[list_of_genres] = train[list_of_genres].fillna(0)\ntrain = train.drop(['all_genre','genres'], axis=1)","16e13354":"train","40289b1e":"train['production_companies_name'] = train['production_companies'].apply(lambda x: ','.join([e['name'] for e in x]) if x!={} else '')\n\ntrain['production_companies_name'] = train['production_companies_name'].apply(lambda x: x.split(\",\") if x!='' else [] )\n\n#train['production_companies_name']\n\ncompanies_count = train['production_companies_name'].apply(pd.Series).stack().value_counts()\ncommon_prod_companies = companies_count[companies_count> 30].keys()\n\ncommon_prod_companies = ['comp_'+ s for s in list(common_prod_companies)]\ntrain = train.reindex( columns = train.columns.tolist() + common_prod_companies)\n\n","be1d3805":"train.head()","67b423e7":"for i, e in train.iterrows():\n    for comp in (e['production_companies_name']):\n        if 'comp_'+ comp in list(common_prod_companies):\n            train.loc[i,('comp_'+comp)] =1\n\ntrain[list(common_prod_companies)] = train[list(common_prod_companies)].fillna(0)","b01172fa":"train = train.drop(['production_companies_name','production_companies'], axis=1)","b9dbdd10":"train['production_countries_name'] = train['production_countries'].apply(lambda x: ','.join([e['name'] for e in x]) if x!={} else '')\n\ntrain['production_countries_name'] = train['production_countries_name'].apply(lambda x: x.split(\",\") if x!='' else [] )\n\n#train['production_countries_name']\n\ncountries_count = train['production_countries_name'].apply(pd.Series).stack().value_counts()\ncommon_countries = countries_count[countries_count> 30].keys()\n\ncommon_countries = ['country_'+ s for s in list(common_countries)]\n\ntrain = train.reindex( columns = train.columns.tolist() + list(common_countries))\n\nfor i, e in train.iterrows():\n    for count in (e['production_countries_name']):\n        if 'country_'+count in list(common_countries):\n            train.loc[i,'country_'+count] =1\n\n\ntrain[list(common_countries)] = train[list(common_countries)].fillna(0)","6ad3cf92":"train = train.drop(['production_countries', 'production_countries_name'], axis=1)","180b1d47":"train.head()","52f53d4a":"train['all_spoken_languages'] = train['spoken_languages'].apply(lambda x: ','.join([e['name'] for e in x]) if x!={} else '')\n\ntrain['no_of_languages_spoken'] = train['all_spoken_languages'].apply(lambda x: len(x.split(\",\")))","ce4e2a22":"train = train.drop(['all_spoken_languages'], axis=1)","1af919a1":"list_of_cast_names = list(train['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n\nCounter([i for j in list_of_cast_names for i in j]).most_common(15)\n\ntop_cast_names = [e[0] for e in (Counter([i for j in list_of_cast_names for i in j]).most_common(15))]\n \ntop_cast_names = ['cast_name_' + s for s in top_cast_names]\n\ntrain = train.reindex( columns = train.columns.tolist() + top_cast_names)\n\nfor i, e in train.iterrows():\n    for cast in (e['cast']):\n        if 'cast_name_'+cast['name'] in top_cast_names:\n            train.loc[i,('cast_name_'+ cast['name'])] = 1\n\n\ntrain[top_cast_names] = train[top_cast_names].fillna(0)\n","a6ec60ed":"list_of_crew_names = list(train['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n\nCounter([i for j in list_of_crew_names for i in j]).most_common(15)\n\ntop_crew_names = [e[0] for e in (Counter([i for j in list_of_crew_names for i in j]).most_common(15))]\n\ntop_crew_names = ['crew_name_'+s for s in top_crew_names]\n\ntrain = train.reindex( columns = train.columns.tolist() + top_crew_names)\n\nfor i, e in train.iterrows():\n    for crew in (e['crew']):\n        if ('crew_name_'+crew['name']) in top_crew_names:\n            train.loc[i, ('crew_name_'+crew['name'])] = 1\n\n\ntrain[top_crew_names] = train[top_crew_names].fillna(0)","638b68ff":"list_of_crew_jobs = list(train['crew'].apply(lambda x: [i['job'] for i in x] if x != {} else []).values)\n\nCounter([i for j in list_of_crew_jobs for i in j]).most_common(15)\n\ntop_crew_jobs = [e[0] for e in (Counter([i for j in list_of_crew_jobs for i in j]).most_common(15))]\n\ntop_crew_jobs = ['crew_jobs_'+ s for s in top_crew_jobs]\n\ntrain = train.reindex( columns = train.columns.tolist() + top_crew_jobs)\n\nfor i, e in train.iterrows():\n    for crew in (e['crew']):\n        if ('crew_jobs_'+crew['job']) in top_crew_jobs:\n            train.loc[i,('crew_jobs_'+crew['job'])] = 1\n\n\ntrain[top_crew_jobs] = train[top_crew_jobs].fillna(0)","67077910":"list_of_crew_depts = list(train['crew'].apply(lambda x: [i['department'] for i in x] if x != {} else []).values)\n\nCounter([i for j in list_of_crew_depts for i in j]).most_common(15)\n\ntop_crew_depts = [e[0] for e in (Counter([i for j in list_of_crew_depts for i in j]).most_common(15))]\n\ntop_crew_depts = ['crew_dept_'+s for s in top_crew_depts]\n\ntrain = train.reindex( columns = train.columns.tolist() + top_crew_depts)\n\nfor i, e in train.iterrows():\n    for crew in (e['crew']):\n        if ('crew_dept_'+crew['department']) in top_crew_depts:\n            train.loc[i,('crew_dept_'+crew['department'])] = 1\n\ntrain[top_crew_depts] = train[top_crew_depts].fillna(0)","9a484d9c":"train['release_date'] = pd.to_datetime(train['release_date'])\n\ntrain['release_date']\n\nadd_datepart(train, 'release_date')\ntrain.dtypes","1f7fc533":"train","372a44ea":"train['Keywords'][0]","25c8088a":"train['all_keywords'] = train['Keywords'].apply(lambda x: ','.join([e['name'] for e in x]) if x!={} else '')","3d3d77b9":"train","ada35d05":"list_of_keywords = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n\n\nCounter([i for j in list_of_keywords for i in j]).most_common(15)\n\ntop_keywords = [e[0] for e in (Counter([i for j in list_of_keywords for i in j]).most_common(15))]\n\ntop_keywords = ['keywords_'+s for s in top_keywords]\n\ntrain = train.reindex( columns = train.columns.tolist() + top_keywords)\n\nfor i, e in train.iterrows():\n    for key in (e['Keywords']):\n        if ('keywords_'+key['name']) in top_keywords:\n            train.loc[i,('keywords_'+key['name'])] = 1\n\n\ntrain[top_keywords] = train[top_keywords].fillna(0)","89d31029":"train['collection_name'].value_counts()","d3af9f48":"plt.figure(figsize=(100,10))\ntrain['collection_name'].value_counts().plot(kind='bar')","4977d8d2":"train['has_collection'].value_counts()","448b78fc":"train['has_collection'].value_counts().plot(kind='bar')","ce4ab265":"sns.regplot(x=train['has_collection'], y=train['revenue'], fit_reg=False)","046a74fa":"sns.distplot(train['revenue'])","ebc504ba":"train['box_cox_revenue'],fitted_lambda = stats.boxcox(train['revenue'])","01026a5f":"sns.distplot(train['box_cox_revenue'])","cc44081e":"from numpy import log\ntrain['log_revenue'] = log(train['revenue'])","1c5468e8":"sns.distplot(train['log_revenue'])","0fc2a265":"sns.distplot(train['budget'])","614ce0c6":"train['log_budget'] = np.log1p(train['budget'])","3cde1e2e":"sns.distplot(train['log_budget'])","6cde9b7c":"sns.regplot(x= train['budget'], y=train['revenue'], fit_reg = False)","4deaa598":"sns.regplot(x= train['log_budget'], y=train['log_revenue'], fit_reg = False)","036af385":"list_all_genre","4be51753":"all_genres = Counter([genre for list_gen in list_all_genre for genre in list_gen])","d2520a62":"keys  = Counter([genre for list_gen in list_all_genre for genre in list_gen]).keys()","08ccbb60":"count = [all_genres[k] for k in keys] ","1f13f19c":"plt.figure(figsize=(10,10))\nplt.xlabel(\"Count of each genre\")\nplt.ylabel(\"Genre type\")\nplt.barh(list(keys), list(count))","b5cb24a5":"f, axes = plt.subplots(5, 5, figsize= (24,32))\nfor i, e in enumerate([col for col in train.columns if 'gen_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i \/\/ 5][i % 5]);","4f8026a7":"from wordcloud import WordCloud, STOPWORDS","450c3a79":"text_for_genre = ' '.join([genre for list_gen in list_all_genre for genre in list_gen])","3037a3de":"genre_cloud = WordCloud(width= 1000, height=1000, background_color='white', min_font_size=10, collocations=False).generate(text_for_genre)","21bf398d":"plt.figure(figsize=(8, 8))\nplt.imshow(genre_cloud)\n","58341a6e":"train['has_homepage'].value_counts()","205d995f":"train['has_homepage'].value_counts().plot(kind='bar')\nplt.xlabel(\"Has Homepage or not\")\nplt.ylabel(\"Count for each category\")\nplt.show()","02aa2098":"sns.regplot(x=train['has_homepage'], y=train['revenue'], fit_reg=False)","30f959af":"train['original_language'].value_counts()","0b2523bf":"train[['original_language','revenue','log_revenue']].groupby('original_language').agg(['min','max','mean'])","0f886ce0":"plt.figure(figsize=(16,8))\nsns.boxplot(x='original_language', y='revenue', data=train);\nplt.show()","f0c12566":"plt.figure(figsize=(16,8))\nsns.boxplot(x='original_language', y='log_revenue', data=train);\nplt.show()","98e60ac8":"train['overview'].fillna('None', inplace=True)","371a8f49":"overview_text  = ' '.join(e for e in train['overview'])","8c22a9a5":"stopwords = set(STOPWORDS)","e764e0e5":"overview_cloud  = WordCloud(width= 1000, height = 1000, background_color ='white', max_font_size=None).generate(overview_text)","20cf887a":"plt.figure(figsize=(12,12))\nplt.imshow(overview_cloud)","33afaa32":"print(\"Popularity min is {}, mean is {}, max is {}\".format(train['popularity'].min(), train['popularity'].mean(),train['popularity'].max() ))","84e3ccc3":"plt.figure(figsize=(12,12))\nsns.boxplot(x='popularity', data = train, orient='v')","845882ab":"sns.regplot(x=train['popularity'], y=train['revenue'], fit_reg=False)","16ff6ce2":"f, axes = plt.subplots(4, 5, figsize= (24,32))\nfor i, e in enumerate([col for col in train.columns if 'comp_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i \/\/ 5][i % 5]);","fa00e3ed":"f, axes = plt.subplots(3, 5, figsize= (24,32))\nfor i, e in enumerate([col for col in train.columns if 'country_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i \/\/ 5][i % 5]);","4747bb2c":"f, axes = plt.subplots(3, 5, figsize= (24,32))\nfor i, e in enumerate([col for col in train.columns if 'keywords_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i \/\/ 5][i % 5]);","98cd316f":"f, axes = plt.subplots(3, 5, figsize= (24,32))\nfor i, e in enumerate([col for col in train.columns if 'cast_name_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i \/\/ 5][i % 5]);","11943f12":"f, axes = plt.subplots(3, 5, figsize= (24,32))\nfor i, e in enumerate([col for col in train.columns if 'crew_name_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i \/\/ 5][i % 5]);","04ab0f9d":"f, axes = plt.subplots(3, 5, figsize= (24,32))\nfor i, e in enumerate([col for col in train.columns if 'crew_dept_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i \/\/ 5][i % 5]);","117efabb":"f, axes = plt.subplots(3, 5, figsize= (24,32))\nfor i, e in enumerate([col for col in train.columns if 'crew_jobs_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i \/\/ 5][i % 5]);","0142fa17":"sns.regplot(x='runtime', y='revenue', data=train, fit_reg=False)","26e82bd9":"train['status']","2e590aea":"train['status'] = train.status.astype(\"category\").cat.codes","44151869":"sns.regplot(x='status', y='revenue', data=train, fit_reg=False)","26c78f16":"train.columns","45671158":"mostly_release_year = train['release_Year'].value_counts()\nmostly_release_year_movies = mostly_release_year[mostly_release_year>30].keys()","cc933073":"# plt.figure(figsize=(24,24))\n# ax = sns.boxplot(x='release_Year', y='revenue', data=train[train['revenue'] in list(mostly_release_year_movies)])\n# for label in ax.xaxis.get_ticklabels():\n#     label.set_rotation(60)","3e8c9834":"train['release_Year'].unique()","2dbb053d":"print(train.columns)","16f46165":"for col in train.columns:\n    print(col)","91e789c1":"#print(train['release_Dayofweek'])\ntrain[['revenue','release_Dayofweek']].groupby('release_Dayofweek').agg('mean')","b843932e":"#### 4.overview","e511f838":"We can see from above graph that 1k has homepage associated with them and rest don't have. Let's see if having homepage does effect on revenue or not.","f0b55982":">> Keywords Processing","7000fa45":"#### 4.Genre ","95290ff6":"#### 6. original_language","2225470a":">> Spoken languages","478837ee":"#### 5. Popularity","d7c93db1":"> Collection name processing","cc31c2f7":">> Production Companies processing","7c7df13e":"#### 5. has_homepage","1df068f9":"#### 3. Budget","0c3a335c":"Let's apply box-cox transformation, though we can from above graph that it is higly positive skewed hence log transformation(special case of box-cox transformation) should be applied but will try both.","c6356e7f":"#### 2. Revenue","4ee4d3d6":">> Genre Processing","9373cb77":"Let's check the distrubtion of revenue","a8321dfc":"From the above plot we can conclude that runtime between 70 to 200 minutes are generating more revenue. So, neither too short nor too long will be good in generating more revenues.","d6c0b77d":"#### From abobe graph we can see that drama, comedy, action, thriller has highest occurence","d53c1ba3":"#### Production Countries ","c3955283":"In this kernel, I tried showing up necessary processing and some EDA.\n\nTook help from these kernels -:\n\nhttps:\/\/www.kaggle.com\/artgor\/eda-feature-engineering-and-model-interpretation\n\nhttps:\/\/www.kaggle.com\/dway88\/feature-eng-feature-importance-random-forest\n\nThis kernel is in progress.\n\nAfter EDA, will try to build some model.","07458242":"#### 1. belongs_to_collection","69d40bcf":"Let's see how much popularity and revenue is correlated","18fbaa57":"From the  above graph not able to conclude anything as there are few movies which are in not released state.","494ad8a4":">> Production Countries name","2eaf03c6":"WE can see out of 3k most of them belong to english itself.\nWhat else we can explore is how each lanugauge is asscociated with movie revenue.","350a6b46":"## **Exploratory Data Analysis**","d37e9fc1":"We can see from above graph that movies which have collection name are generating more revenue.\nLet's focus on target variable for now.","99041ad0":">> Homepage Processing","e64ee6dd":"english movies has high revenue but apart from that we have other languages like hindi, zh(diagraph- mixture of two). It can be an important factor for prediction will see.","88eaf9a5":"So, we come up with a really nice observation that movie having home page may generate more revenue.","5468f03c":"It seems some them have very high popularity, can be outliers but not sure. \nBut we can observe that higher the popularity higher is the revenue generated by the movie."}}