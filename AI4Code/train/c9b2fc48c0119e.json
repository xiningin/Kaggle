{"cell_type":{"bf805206":"code","316f8fc6":"code","f0b46f81":"code","5ba4ce67":"code","46fdd98a":"code","938ebbf7":"code","45a62398":"code","c0ae8266":"code","295c72e6":"code","51d2d0ee":"code","e75047ac":"code","6fafd823":"code","5d6b9c34":"code","c56fe7f9":"code","03097b5e":"code","091ad314":"code","6d398828":"code","fc0167c5":"code","ce7bdddb":"code","935b6e56":"code","c470fae7":"code","d84f1dad":"code","c08a172d":"code","56bbe842":"code","1c600fa7":"code","db01802b":"code","8b29959d":"code","196c7a4b":"code","2c15cd19":"code","4c3c8aa6":"code","8f9fee97":"code","32518e25":"code","84673a03":"code","6fc22c78":"code","2193b8f9":"code","d2a736bc":"code","28a4fbc8":"code","905918e3":"code","71b681b2":"code","5b8fb679":"code","3abbfa15":"code","12b08b37":"code","4fae7fdf":"code","ba13a01f":"code","eb20e853":"code","ebd2014f":"code","934b0454":"code","22e3125e":"code","b1464811":"code","33c73553":"code","af5b7531":"code","14e3e747":"code","b80e73cb":"code","c993c5e4":"code","4e634711":"code","b469ae51":"code","3cd84ab2":"code","41a574ec":"code","1e9c36e1":"code","b7d39c92":"code","1bd895bb":"code","48ec3ca9":"code","a9e5a547":"code","6fbf81fb":"code","1373150a":"code","e95b1a54":"code","3f27337b":"code","1af824ff":"code","359a88c7":"code","b3feb0e7":"code","d71e1614":"code","083a06b7":"code","2add96e4":"code","b95da63e":"code","53b4bd29":"code","504d5fa6":"code","0b609c36":"code","dc8f7d55":"code","1aeb04f6":"code","a3b8926b":"code","a41e8b76":"code","cc051823":"code","0a817966":"code","63b6cdc4":"code","20def2ae":"markdown","7077e33a":"markdown","7d5bf0e0":"markdown","5bac2b3d":"markdown","492a68c6":"markdown","438a0bf7":"markdown","765b39b0":"markdown","b602f198":"markdown","7b88ebc9":"markdown","e3a54f3c":"markdown","d26c214f":"markdown","bb6f775a":"markdown","9a710e22":"markdown","921b9ead":"markdown","a2e753f5":"markdown"},"source":{"bf805206":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","316f8fc6":"#Display all columns\npd.pandas.set_option('display.max_columns',None)\npd.pandas.set_option('display.max_rows',None)","f0b46f81":"df=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf.head()","5ba4ce67":"df.shape","46fdd98a":"null_values=[features for features in df.columns if df[features].isnull().sum()>1]\nprint(null_values)","938ebbf7":"for feature in null_values:\n    print(feature,np.round(df[feature].isnull().mean(),4),'% missing values')","45a62398":"sns.heatmap(df.isnull())","c0ae8266":"for feature in null_values:\n    data=df.copy()\n    data[feature]=np.where(data[feature].isnull(),1,0)\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n#     sns.countplot(data[feature].isnull())\n    plt.title(feature)\n    plt.show()","295c72e6":"#Drop","51d2d0ee":"numerical_features=[feature for feature in df.columns if df[feature].dtypes!='O']\nprint(\"No of numerical values: \",len(numerical_features))\ndf[numerical_features].head()","e75047ac":"year_f=[feature for feature in numerical_features if 'Yr' in feature or 'Year' in feature]\nprint(year_f)","6fafd823":"for i in year_f:\n    print(i,df[i].unique())","5d6b9c34":"df.groupby('YrSold')['SalePrice'].median().plot()\nplt.xlabel('Year Sold')\nplt.ylabel('Medan House Price')\nplt.title('House Price vs YearSold')","c56fe7f9":"year_f","03097b5e":"for feature in year_f:\n    if feature!='YrSold':\n        data=df.copy()\n        data[feature]=data['YrSold']-data[feature]\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('SalePrice')\n        plt.show()\n        ","091ad314":"## Numerical variables are usually of 2 type\n## 1. Continous variable and Discrete Variables\n\ndiscrete_feature=[feature for feature in numerical_features if len(df[feature].unique())<25 and feature not in year_f+['Id']]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","6d398828":"discrete_feature","fc0167c5":"df[discrete_feature].head()","ce7bdddb":"## Lets Find the realtionship between them and Sale PRice\n\nfor feature in discrete_feature:\n    data=df.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","935b6e56":"continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature+year_f+['Id']]\nprint(\"Continuous feature Count {}\".format(len(continuous_feature)))","c470fae7":"## Lets analyse the continuous values by creating histograms to understand the distribution\n\nfor feature in continuous_feature:\n    data=df.copy()\n    data[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"Count\")\n    plt.title(feature)\n    plt.show()","d84f1dad":"data=df.copy()\nfor feature in continuous_feature:\n    data=df.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        data['Saleprice']=np.log(data['SalePrice'])\n        plt.scatter(data[feature],data['SalePrice'])\n        plt.xlabel(feature)\n        plt.ylabel('Saleprice')\n        plt.title(feature)\n        plt.show()","c08a172d":"for feature in continuous_feature:\n    data=df.copy()\n    if 0 in data[feature].unique():\n        pass\n    else:\n        data[feature]=np.log(data[feature])\n        sns.boxplot(data[feature])\n        plt.ylabel(feature)\n        plt.title(feature)\n        plt.show()","56bbe842":"categorical_feature=[feature for feature in df.columns if data[feature].dtypes=='O']\ncategorical_feature\n\n","1c600fa7":"df[categorical_feature].head()","db01802b":"for feature in categorical_feature:\n    print(\"The feature of {} and number of categories are {}\".format(feature,len(df[feature].unique())))","8b29959d":"for feature in categorical_feature:\n    data=df.copy()\n    data.groupby(feature)['SalePrice'].median().plot.bar()\n    plt.xlabel(feature)\n    plt.ylabel('SalePrice')\n    plt.title(feature)\n    plt.show()","196c7a4b":"dft=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ndft.head()\ndft.shape","2c15cd19":"feature_null=[feature for feature in df.columns if df[feature].isnull().sum()>0 and df[feature].dtypes=='O']\nfor feature in feature_null:\n    print(\"{}: {}% missing values\".format(feature,np.round(df[feature].isnull().mean(),4)))","4c3c8aa6":"feature_nul=[feature for feature in dft.columns if df[feature].isnull().sum()>0 and dft[feature].dtypes=='O']\nfor feature in feature_null:\n    print(\"{}: {}% missing values\".format(feature,np.round(dft[feature].isnull().mean(),4)))","8f9fee97":"def replace_cat_feature(df,feature_null):\n    data=df.copy()\n    data[feature_null]=data[feature_null].fillna('Missing')\n    return data\ndf=replace_cat_feature(df,feature_null)\ndf[feature_null].isnull().sum()","32518e25":"def replace_cat_feature(dft,feature_null):\n    data=dft.copy()\n    data[feature_null]=data[feature_null].fillna('Missing')\n    return data\ndft=replace_cat_feature(dft,feature_nul)\ndft[feature_nul].isnull().sum()","84673a03":"df.head()","6fc22c78":"dft.head()","2193b8f9":"numerical_null=[feature for feature in df.columns if df[feature].isnull().sum()>0 and df[feature].dtypes=='int' or df[feature].dtypes=='float']\nfor feature in numerical_null:\n    print(\"{}: {}% missing values\".format(feature,np.round(df[feature].isnull().mean(),4)))","d2a736bc":"numerical_nul=[feature for feature in dft.columns if dft[feature].isnull().sum()>0 and dft[feature].dtypes=='int' or dft[feature].dtypes=='float']\nfor feature in numerical_nul:\n    print(\"{}: {}% missing values\".format(feature,np.round(dft[feature].isnull().mean(),4)))","28a4fbc8":"for feature in numerical_null:\n    median_value=df[feature].median()\n    #we are median since there are outliers\n    df[feature+'nan']=np.where(df[feature].isnull(),1,0)\n    #Where there is null value replace it with 1 else 0\n    df[feature].fillna(median_value,inplace=True)\ndf[numerical_null].isnull().sum()","905918e3":"for feature in numerical_nul:\n    median_value=dft[feature].median()\n    #we are median since there are outliers\n    dft[feature+'nan']=np.where(dft[feature].isnull(),1,0)\n    #Where there is null value replace it with 1 else 0\n    dft[feature].fillna(median_value,inplace=True)\ndft[numerical_null].isnull().sum()","71b681b2":"df.head(10)","5b8fb679":"dft.head()","3abbfa15":"for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n    df[feature]=df['YrSold']-df[feature]","12b08b37":"for feature in ['YearBuilt','YearRemodAdd','GarageYrBlt']:\n    dft[feature]=dft['YrSold']-dft[feature]","4fae7fdf":"df.head()","ba13a01f":"dft.head()","eb20e853":"df[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()","ebd2014f":"dft[['YearBuilt','YearRemodAdd','GarageYrBlt']].head()","934b0454":"import numpy as np\nnum_features=['LotFrontage','LotArea','1stFlrSF','GrLivArea']\nfor feature in num_features:\n    df[feature]=np.log(df[feature])","22e3125e":"import numpy as np\nnum_features=['LotFrontage','LotArea','1stFlrSF','GrLivArea']\nfor feature in num_features:\n    dft[feature]=np.log(dft[feature])","b1464811":"df.head()","33c73553":"categorical_features=[feature for feature in df.columns if df[feature].dtypes=='O']\ncategorical_features","af5b7531":"for feature in categorical_features:\n    temp=df.groupby(feature)['SalePrice'].count()\/len(df)\n    temp_df=temp[temp>0.01].index\n    df[feature]=np.where(df[feature],df[feature],'Rare_var')","14e3e747":"df.head(50)","b80e73cb":"feature_scale=[feature for feature in df.columns if feature not in ['Id','SalePrice'] and df[feature].dtypes!='O']\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()#Scale down the data between 0 to 1\nscaler.fit(df[feature_scale])","c993c5e4":"feature_scale=[feature for feature in df.columns if feature not in ['Id','SalePrice'] and df[feature].dtypes!='O']\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()#Scale down the data between 0 to 1\nscaler.fit(dft[feature_scale])","4e634711":"df.head()","b469ae51":"dft.head()\n","3cd84ab2":"data=pd.concat([df[['Id','SalePrice']].reset_index(drop=True),\n                 pd.DataFrame(scaler.transform(df[feature_scale]),columns=feature_scale)],\n                             axis=1)","41a574ec":"data.to_csv('X_train.csv',index=False)","1e9c36e1":"dtrain=pd.read_csv('X_train.csv')\ndtrain.head()","b7d39c92":"data=pd.concat([dft[['Id']].reset_index(drop=True),\n                 pd.DataFrame(scaler.transform(dft[feature_scale]),columns=feature_scale)],\n                             axis=1)","1bd895bb":"data.to_csv('X_test.csv',index=False)","48ec3ca9":"dtest=pd.read_csv('X_test.csv')\ndtest.head()","a9e5a547":"from sklearn.linear_model import Lasso\nfrom sklearn .feature_selection import SelectFromModel\n","6fbf81fb":"y_train=dtrain['SalePrice']\nx_train=dtrain.drop(['Id','SalePrice'],axis=1)","1373150a":"x_test=dtest.drop('Id',axis=1)","e95b1a54":"feature_sel_model=SelectFromModel(Lasso(alpha=0.005,random_state=0))\nfeature_sel_model.fit(x_train,y_train)","3f27337b":"feature_sel_model.get_support()","1af824ff":"selected_feat=x_train.columns[(feature_sel_model.get_support())]\nprint(\"Total features: \",x_train.shape[1])\nprint(\"Selected features: \",len(selected_feat))","359a88c7":"selected_feat","b3feb0e7":"x_train=x_train[selected_feat]\nx_test=x_test[selected_feat]","d71e1614":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import train_test_split,KFold,cross_val_score\nfrom xgboost import XGBRegressor","083a06b7":"models=[]\nmodels.append(('LR',LinearRegression()))\nmodels.append(('RR',Ridge(alpha=0.9)))\nmodels.append(('LasR',Lasso(alpha=0.9)))\nmodels.append(('RF',RandomForestRegressor(min_samples_leaf=5)))\nmodels.append(('DT',DecisionTreeRegressor()))\nmodels.append(('KNN',KNeighborsRegressor(n_neighbors=6)))\nmodels.append(('XG',XGBRegressor()))\nmodels.append(('SVR',SVR()))","2add96e4":"results=[]\nnames=[]\nscoring='accuracy'\nfor name,model in models:\n    l=model\n    l.fit(x_train,y_train)\n    print(name,\" \",l.score(x_train,y_train))","b95da63e":"p=PolynomialFeatures(degree=3)\np.fit(x_train)\nxt=p.transform(x_train)\nl=LinearRegression()\nl.fit(xt,y_train)\nprint(\"Poly \",l.score(xt,y_train))","53b4bd29":"X_train,X_test,Y_train,y_test=train_test_split(x_train,y_train,test_size=0.2,random_state=1)\nX_train.shape\nX_train.head()","504d5fa6":"params={\n    'learning_rate':[0.05,0.1,0.15,0.2,0.25,0.3],\n    'max_depth':[3,4,5,6,8,10,12,15,20,25,30,35,40,45],\n    'min_child_weight':[1,3,5,7],\n    'gamma':[0.0,0.1,0.2,0.3,0.4],\n    'colsample_bytree':[0.1,0.4,0.5,0.7]\n}","0b609c36":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV","dc8f7d55":"clf=XGBRegressor()\nrandom_search=RandomizedSearchCV(clf,param_distributions=params,n_iter=5,n_jobs=-1,cv=5,verbose=1)","1aeb04f6":"random_search.fit(X_train,Y_train)","a3b8926b":"random_search.best_estimator_","a41e8b76":"random_search.best_params_","cc051823":"my_model=XGBRegressor(min_child_weight=5,\n                      max_depth=12,\n                      learning_rate=0.15,\n                      gamma=0.1,\n                      colsample_bytree=0.5)\nmy_model.fit(X_train,Y_train)\nprint(my_model.score(X_train,Y_train))\nprint(my_model.score(X_test,y_test))\n# l=my_model.predict(x_test)\n","0a817966":"# my_model=DecisionTreeRegressor(criterion='mse',min_samples_leaf=15,)\n# my_model.fit(x_train,y_train)\n# print(my_model.score(X_train,Y_train))\n# print(my_model.score(X_test,y_test))","63b6cdc4":"predictions = my_model.predict(x_test)\noutput = pd.DataFrame({'Id': dtest['Id'],'SalePrice': predictions})\noutput.to_csv('Saleprice1.csv', index=False)\noutput","20def2ae":"## Feature Selection","7077e33a":"## Missing Values","7d5bf0e0":"## Temporal Variables(Eg: DataTime )","5bac2b3d":"## Handling Rare Categorical Feature","492a68c6":"## Prediction","438a0bf7":"## Feature Engineering","765b39b0":"## Feature Scaling","b602f198":"### Outliers","7b88ebc9":"#### Missing Values","e3a54f3c":"There is a relationship between variable number and SalePrice","d26c214f":"The feature which has null value is 1 else 0","bb6f775a":"## Numerical Variables","9a710e22":"## Exploratory Data Analysis 2","921b9ead":"## Continuous Variables","a2e753f5":"### Categorical Variables"}}