{"cell_type":{"53ae29ce":"code","0fc56fdc":"code","7c5bb3e3":"code","4843523f":"code","ccded307":"code","610e98bf":"code","e278bc95":"code","52d338e5":"code","9ce973c7":"code","e7df68f6":"code","fe38153e":"code","5d0c1f1d":"code","63c40703":"code","58bb5e92":"code","c5b53bce":"code","2c94a9fe":"code","01d1527f":"code","c7a90a57":"markdown","97a582c6":"markdown","10ee30d2":"markdown"},"source":{"53ae29ce":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\n# Any results you write to the current directory are saved as output.\n\ntrain = pd.read_csv('..\/input\/X_train.csv')\ny = pd.read_csv('..\/input\/y_train.csv')\ntest = pd.read_csv('..\/input\/X_test.csv')\nsub = pd.read_csv('..\/input\/sample_submission.csv')","0fc56fdc":"import gc\nimport os\nimport logging\nimport datetime\nimport warnings\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nimport xgboost as xgb","7c5bb3e3":"#checking the Target distribution\nplt.figure(figsize=(15,5))\nsns.countplot(y=y['surface'],order=y.surface.value_counts().index)","4843523f":"## Take on of each surface\n\nlist_materials = y.surface.unique()\n\n## Array of Dataframe, a dataframe for each material\nsample = {}\n\n## Take one serie for each material\nfor mat in list_materials:\n    serie_id = y[y.surface==mat]['series_id'].values[0]\n    print(\"material is %s serie taken %d\"%(mat,serie_id))\n    sample[mat]=train[train.series_id == serie_id]","ccded307":"from plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nscatter = []\nfor s in sample:\n    scatter.append(go.Scatter(x=np.arange(128), y=sample[s]['linear_acceleration_Z'], mode='lines',name=s))\niplot(scatter)","610e98bf":"from scipy.signal import butter, lfilter, medfilt,lfilter_zi\nfrom scipy.signal import freqs\nimport matplotlib as mpl\n\nmpl.rcParams['figure.figsize'] = (10,10)\n\ndef low_pass_filter(data,order=1,alpha=0.05):\n    b, a = butter(order,alpha)\n    zi =  lfilter_zi(b, a)\n    z,_ = lfilter(b, a,data,zi=zi*data.mean())\n    return z\n\nfor s in sample:\n    ##\u00a0Take accZ\n    y=sample[s]['linear_acceleration_Z']\n    \n    ##\u00a0LowPass Filter it\n    #low_pass_filter(y)\n    \n    sp = np.fft.fft(y)\n    freq = np.fft.fftfreq(y.shape[-1])\n    plt.plot(freq[10:],sp[10:],label=s)\n    \n\nplt.legend()\nplt.show()","e278bc95":"scatter = []\nfor s in sample:\n    scatter.append(go.Scatter(x=np.arange(128), y=sample[s].angular_velocity_Z, mode='lines',name=s))\niplot(scatter)","52d338e5":"train.columns","9ce973c7":"\n\ndef serie_to_item(serie,serie_id):\n    '''For 1 series_id (ie dataset), return a line with a '''\n    '''value per feature '''\n    ## Thoses are the columns from wich we will extract measurable\n    cols = ['angular_velocity_X',\n       'angular_velocity_Y', 'angular_velocity_Z', 'linear_acceleration_X',\n        'linear_acceleration_Y', 'linear_acceleration_Z']\n    \n    '''Get a dataset an return a line of measurable'''\n    \n    feat = [\"count\",\"mean\",\"std\",\"min\",\"25%\",\"50%\",\"75%\",\"max\"]\n    \n    new_items_names=[]\n    new_data=[]\n    for c in cols:\n        #start_time = time.time()\n        new_items_names.extend([c+'_'+i for i in feat])\n        ## Extract measurable\n        new_data.extend(serie[c].describe())\n        #print(\"--- %s seconds ---\" % (time.time() - start_time))\n        \n                \n        ## Will contain name of new fields\n    return pd.Series(new_data,index=new_items_names)\n\ndef prepare_data(data):\n    '''Will transform each dataset series in 1-liner item in a new array'''\n    '''For instance : [series_id,count,mean,std,min,...]'''\n    '''Thus to extract measurable from each dataset and perform machine learning'''\n    result = []\n    list_series = data.series_id.unique()\n    #for i in list_series[:10]:\n    result = [serie_to_item(data[data.series_id==i],i) for i in list_series]\n    return pd.DataFrame(result)\n\n","e7df68f6":"prepared_data = prepare_data(train)","fe38153e":"encoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y['surface'])\ny_encoded_df = pd.DataFrame(y_encoded,y.series_id)\ntrain_X, test_X, train_y, test_y = train_test_split(prepared_data, y_encoded, test_size=0.30)","5d0c1f1d":"from xgboost import XGBRegressor\n\nmy_model = xgb.XGBClassifier(n_estimators=1000, learning_rate=0.05,n_jobs=8)\n\n# Add silent=True to avoid printing out updates with each cycle\nmy_model.fit(train_X, train_y, early_stopping_rounds=5, eval_set=[(test_X, test_y)], verbose=False)","63c40703":"\n\npreds = my_model.predict(test_X)\naccuracy_score(test_y,preds)\n","58bb5e92":"for i in [40]:\n    my_model = xgb.XGBClassifier(n_estimators=1000, learning_rate=0.05,n_jobs=8)\n    # Add silent=True to avoid printing out updates with each cycle\n    my_model.fit(train_X, train_y, early_stopping_rounds=i, eval_set=[(test_X, test_y)], verbose=False)\n    preds = my_model.predict(test_X)\n    print(\"n_estimators :%d -- Acc : %f\"%(i,accuracy_score(test_y,preds)))\n","c5b53bce":"prepared_data_sub = prepare_data(test)","2c94a9fe":"prepared_data_sub.head()","01d1527f":"sub_preds = my_model.predict(prepared_data_sub)\n\n\nresult = pd.DataFrame()\nresult['series_id']=prepared_data_sub.index\nresult['surface']= encoder.inverse_transform(sub_preds)\n\nresult.to_csv('submission.csv', index=False)","c7a90a57":"# Take some sample and analyse","97a582c6":"## Hypothesis : Measurement of vibration profile is better in a straight line","10ee30d2":"# Feature Engineering"}}