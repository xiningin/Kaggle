{"cell_type":{"087abea9":"code","54c552fe":"code","3ca20e48":"code","48510317":"code","13eb6075":"code","0dfba8a6":"code","2a065011":"code","c9d816a4":"code","ec3c9be0":"code","79dde385":"code","2cbbbbf1":"code","653c45a8":"code","45c949fb":"code","6d847fa8":"code","e93e7753":"code","f7269cd0":"code","8a548470":"code","47f6f59b":"code","5fd2ee88":"code","4773fc7a":"code","5b13e250":"code","7f58adba":"code","7c3f3024":"code","2c74e213":"code","c7329895":"code","58895c07":"markdown","5339c248":"markdown","6bd6b994":"markdown","126411c3":"markdown","d6553849":"markdown"},"source":{"087abea9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","54c552fe":"# read train\ntrain = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\nprint(train.shape)\ntrain.head()","3ca20e48":"# read test\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nprint(test.shape)\ntest.head()","48510317":"# labels into y_train\nY_train = train[\"label\"]\n# drop label column and load x_train\nX_train = train.drop(labels = [\"label\"], axis = 1)","13eb6075":"Y_train.value_counts()","0dfba8a6":"# visualize number of digits \nplt.figure(figsize=(10,5))\ng = sns.countplot(Y_train)\nplt.title(\"Number of digit classes\")\nplt.show()","2a065011":"# an example from digit data\nimg = X_train.loc[0]\nimg = np.asarray(img).reshape(28,28)\nplt.axis(\"off\")\nplt.imshow(img, cmap=\"gray\")\nplt.show()\n# 1","c9d816a4":"# an example from digit data\nimg = X_train.loc[34]\nimg = np.asarray(img).reshape(28,28)\nplt.axis(\"off\")\nplt.imshow(img, cmap=\"gray\")\nplt.show()\n# 2","ec3c9be0":"# Normalization\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\nprint(\"X_train shape: \", X_train.shape)\nprint(\"test shape: \", test.shape)","79dde385":"# Reshape\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\nprint(\"X_train shape: \", X_train.shape)\nprint(\"test shape: \", test.shape)","2cbbbbf1":"# Label Encoding\nfrom keras.utils.np_utils import to_categorical # convert to one hot encoding\nY_train = to_categorical(Y_train, num_classes=10)","653c45a8":"# Split the train and the validation set for the fitting\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\nprint(\"X train shape: \", x_train.shape)\nprint(\"Y train shape: \", y_train.shape)\nprint(\"X test shape: \", x_val.shape)\nprint(\"Y test shape: \", y_val.shape)","45c949fb":"# Create Model\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\n#from keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nmodel = Sequential()\n#\nmodel.add(Conv2D(filters=8, kernel_size=(5,5), padding=\"Same\", activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n#\nmodel.add(Conv2D(filters=16, kernel_size=(3,3), padding=\"Same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))          \n# fully connected\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation=\"softmax\"))\n","6d847fa8":"# Define the Optimizer # Adam optimizer: Change the learning rate\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)","e93e7753":"# Compile the Model\nmodel.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","f7269cd0":"# Epoch and Batch Size\nepochs = 50 # for better result increase the epochs\nbatch_size = 250","8a548470":"# Data Augmentation\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.1, # Randomly zoom image 10%\n        width_shift_range=0.1,  # randomly shift images horizontally 10%\n        height_shift_range=0.1,  # randomly shift images vertically 10%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(x_train)","47f6f59b":"# Fit the Model\nhistory = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, \n                              validation_data = (x_val,y_val), \n                              steps_per_epoch=x_train.shape[0] \/\/ batch_size)","5fd2ee88":"# Plot the loss and accuracy curves for training and validation \nplt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\nplt.title(\"Test Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","4773fc7a":"# confusion matrix\nimport seaborn as sns\n# Predict the values from the validation dataset\ny_pred = model.predict(x_val)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \n# plot the confusion matrix\nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","5b13e250":"result = model.predict(test)","7f58adba":"result[0]","7c3f3024":"new_result = np.zeros(shape=(len(result)))\nfor i in range(len(result)):\n    maks = np.max(result[i])\n    for x,value in enumerate(result[i], start=1):\n        if value == maks:\n            new_result[i] = x\nnew_result.astype(int)","2c74e213":"# ImageId,Label\nimage_id = np.asarray([x for x in range(1,len(new_result)+1)])\nimage_id = pd.Series(image_id, name = \"ImageId\").astype(int)\nlabel = pd.Series(new_result, name = \"Label\").astype(int)\nres = pd.concat([image_id,label], axis=1)\nres.to_csv(\"digit_recognizer_test_output.csv\", index=False)","c7329895":"res","58895c07":"<a id = \"4\"><\/a>\n# Convolutional Neural Network (CNN)","5339c248":"# Digit Recognizer with CNN\n<font color = \"blue\">\n    \n1. [Loading Data](#1)\n1. [Normalization Reshape and Label Encoding](#2)\n1. [Train Test Split](#3)\n1. [Convolutional Neural Network (CNN)](#4)\n    \n    ","6bd6b994":"<a id = \"1\"><\/a>\n# Loading Data","126411c3":"<a id = \"2\"><\/a>\n# Normalization Reshape and Label Encoding\n\n* Normalization\n    * If we perform normalization, CNN works faster\n* Reshape\n    * Train and test images (28x28), we reshape all to 28x28x1 3D matrices, because keras needs for understand how much channel with the end which.\n* Label Encoding\n    * Encode labels to one hot vectors\n        * 1 --> [0,1,0,0,0,0,0,0,0,0]\n        * 8 --> [0,0,0,0,0,0,0,0,1,0]\n","d6553849":"<a id = \"3\"><\/a>\n# Train Test Split\n\n* We split data into train and test sets.\n* Train size is %90\n* Test size is %10"}}