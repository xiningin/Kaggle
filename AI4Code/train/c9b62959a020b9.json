{"cell_type":{"c002215f":"code","a468152a":"code","98ad7c99":"code","673e44c3":"code","3d336359":"code","b17fd130":"code","4d29529b":"code","cf940d5b":"code","4922e109":"code","5d805568":"code","4d3e5759":"code","d1ce7dee":"code","04b6629d":"code","6a11de6a":"code","af211907":"markdown","41167ca3":"markdown","abf09ca2":"markdown","de2d8eb2":"markdown","c1f7fdf9":"markdown","d4537a13":"markdown","a8296ae2":"markdown","9ee673c0":"markdown","f21bcf2f":"markdown","8e70ceb6":"markdown","683c71ae":"markdown"},"source":{"c002215f":"import torch\n\nROOT = '\/kaggle\/input'\n\nTRAIN_DIR = f'{ROOT}\/cartoon\/data\/train'\nTEST_DIR = f'{ROOT}\/cartoon\/data\/test'\nVALIDATION_DIR = f'{ROOT}\/cartoon\/data\/validation'\n","a468152a":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms as T\n\ntarget_size = 256\nbatch_size = 50\n\nstats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n\n\ndef load_data(filepath):\n    data_s = ImageFolder(filepath, T.Compose(\n    [\n        T.Resize(target_size),\n        T.CenterCrop(target_size),\n        T.ToTensor(),\n        T.Normalize(*stats)\n    ]))\n    \n    data_l = DataLoader(data_s, batch_size, shuffle=True)\n    return data_l\n\ntrain_dl = load_data(TRAIN_DIR)\ntest_dl = load_data(TEST_DIR)\nvalidation_dl = load_data(VALIDATION_DIR)\n\n","98ad7c99":"from torchvision.utils import make_grid\nfrom matplotlib import pyplot as plt\n\ndef show_images(data_l):\n    for img, labels in data_l:\n        b_images = img\n        b_labels = labels\n        break\n        \n    fig, ax = plt.subplots(figsize=(10,10))\n    ax.axis('off')\n    ax.imshow(make_grid(stats[0][0] + stats[1][0] * b_images, nrow=5).permute(1,2,0))\n    plt.show()","673e44c3":"show_images(train_dl)","3d336359":"show_images(test_dl)","b17fd130":"from torch import nn\n\nclassifier = nn.Sequential(\n    \n    nn.Conv2d(3, 32, kernel_size=4, padding=1, stride=2, bias=False),\n    nn.BatchNorm2d(32),\n    nn.LeakyReLU(0.2, inplace=True),\n    \n    nn.Conv2d(32, 64, kernel_size=64, padding=16, stride=32, bias=False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2, inplace=True),\n    \n    nn.Conv2d(64, 128, kernel_size=4, padding=0, stride=1, bias=False),\n    nn.Flatten(),\n    nn.Linear(128, 256),\n    nn.Linear(256, 5),\n)\n","4d29529b":"for img, labels in train_dl:\n        b_images = img\n        b_labels = labels\n        break\nprint(b_images.shape) \nprint(labels.shape)\noutputs = classifier(b_images)\nprint(outputs.shape)\n_, preds = torch.max(outputs, 1)\nprint(preds.shape)","cf940d5b":"loss_fn = nn.CrossEntropyLoss()\n\ndef train_classifier(b_data, b_labels, opt_c, validation=False):\n    \n    opt_c.zero_grad()\n    \n    preds = classifier(b_data)\n    loss = loss_fn(preds, b_labels)\n    \n    _, pred_labels = torch.max(preds, 1)\n    score = torch.sum(pred_labels == b_labels.data)\n    \n    if not validation:\n        loss.backward()\n        opt_c.step()\n    \n    return loss.item(), score.item()\/batch_size","4922e109":"from tqdm.notebook import tqdm\nfrom torch.optim import Adam\n\ndef fit(epochs, lr):\n    \n    t_losses = []\n    t_scores = []\n    v_losses = []\n    v_scores = []\n    \n    for epoch in range(epochs):\n        opt_c = Adam(classifier.parameters(), lr=lr, betas=(0.5, 0.999))\n        \n        for b_images, b_labels in tqdm(train_dl):\n            t_loss, t_score = train_classifier(b_images, b_labels, opt_c)\n            \n        for b_images, b_labels in tqdm(validation_dl):\n            v_loss, v_score = train_classifier(b_images, b_labels, opt_c, validation=True)\n            \n        print(f'Epoch [{epoch+1}\/{epochs}], loss: {t_loss}, accuracy: {t_score}, validation_loss: {v_loss}, validation_accuracy: {v_score}')\n        t_losses.append(t_loss)\n        t_scores.append(t_score)\n        v_losses.append(v_loss)\n        v_scores.append(v_score)\n        \n    return t_losses, t_scores, v_losses, v_scores\n            ","5d805568":"history = fit(6, 0.00005)","4d3e5759":"total_score  = 0\ntotal = 0\nfor b_images, b_labels in test_dl:\n    preds = classifier(b_images)\n    _, pred_labels = torch.max(preds, 1)\n    score = torch.sum(pred_labels == b_labels.data)\n\n    total_score += score.item()\n    total += b_images.size(0)\n    \nprint(f'Accuracy: {total_score*100\/total}%')","d1ce7dee":"torch.save(classifier.state_dict(), '\/kaggle\/working\/model_classifier.pth')","04b6629d":"import pickle\npickle.dump(history,open('\/kaggle\/working\/history.pickle','wb'))","6a11de6a":"import pickle\n\nhistory = pickle.load(open('\/kaggle\/working\/history.pickle','rb'))\nt_losses = history[0]\nt_scores = history[1]\nv_losses = history[2]\nv_scores = history[3]\n\nfrom matplotlib import pyplot as plt\n\nfig = plt.figure(figsize=(5, 10))\n\nax = fig.add_subplot(2,1,1)\nax.plot(t_losses, c='g')\nax.plot(v_losses, c='b')\nplt.title('Loss vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nax = fig.add_subplot(2, 1, 2)\nax.plot(t_scores, c='g')\nax.plot(v_scores, c='b')\nplt.title('Score vs Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Score')","af211907":"**2. Preprocessing the data**\n\nThe images need to be converted to a format that can be fed to our model. In pytorch, we convert them into tensors. Each image is resized, cropped, normalized and converted to a tensor. ImageFolder and DataLoader helps us extract images from folders, apply transforms, assign labels to them based on what subfolder they are in and also lets us retrieve batches of images that can be fed to the model.","41167ca3":"**3. Analyzing the data**\n\nWe analyze the data to identify patterns that can be exploited for easily building th model and training our data. Here, the data is a bunch of images which can be visually inspected before preprocessing.\nHowever, once they are loaded as tensors we can build some helpers that can represent these normalized tensors as denormalized images. This not only helps us assert if the whole \"transform to tensor\" thing worked fine but also lets us display these images when we predict their labels using the model.","abf09ca2":"**9. Analyzing the results**\n\nWe can analyze the results to see the trends in learning that the model has displayed. ","de2d8eb2":"**1. Recognizing the directories that contain the input data.**\n\nHere, the input folder contains three subfolders - train, test and validate which can be used for their respective purposes while building and testing the model.","c1f7fdf9":"**5. Defining the training process**\n\nIn pytorch, we can define how each batch of data optimizes the model and can define the required metrics.\nEach training involves feeding the input, getting a prediction, finding the loss, asking optimizer to \"optimize\" the model by changing the variables based on how much each variable is causing the model to lose.","d4537a13":"**8. Saving**\n\nOnce the process is complete, we can save usefull things like the model, metrics etc. This saves the trouble of recalculation and retraining.","a8296ae2":"**6. Fitting  the model**\n\nWe train the model with all the batches and repeat it over multiple 'epochs'. The training data is used to optimize the model while we use the validation data to just calculate the metrics. The metrics on the validation data gives us a rough idea about how the model is going to respond on data it has not been trained on (like the test data).","9ee673c0":"**4. Building a model**\n\nA model is a kind of signal processor that learns how to process an input to give the desired output by just going through a bunch of inputs and corresponding outputs. Here, we create a model (basically just a bunch of fancy variables stacked together hoping they would learn something from the data we are going to pass through them) by stacking some convolutional layers and dense layers, and making sure that the input and output layers are modelled after our dataset.\n\n*Note: Refer reliable sources for actual definitions*","f21bcf2f":"**7. Predicting using the model**\n\nOnce the model has reached a desired level of accuracy\/loss (depending on how critical classifying cartoon images are), we can use the model to predict and then compare the predictions with actual labels.","8e70ceb6":"# Classifying a bunch of cartoon images using PyTorch.\n\n -A notebook for beginners from a beginner.","683c71ae":"*When working on different components of multidimensional data, it's always better to do some testing and shape analysis before starting to put these components together*"}}