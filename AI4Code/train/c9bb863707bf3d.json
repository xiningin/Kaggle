{"cell_type":{"60869408":"code","c029a9b0":"code","878b8fba":"code","97149906":"code","93368d1f":"code","974423e4":"code","bdfd7162":"code","3839a416":"code","ba8a8a04":"code","236ff7dd":"code","744f8916":"code","fa839f26":"code","6c75814d":"code","7bf0dbde":"markdown","475f9de1":"markdown","4454b372":"markdown","31568875":"markdown","d5dd6944":"markdown","c6eea650":"markdown","7552e3d9":"markdown"},"source":{"60869408":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c029a9b0":"!ls \/kaggle\/input\/face-mask-dataset\/data\/","878b8fba":"#!pip install split-folders tqdm\nbase_dir = '\/kaggle\/input\/face-mask-dataset\/data'","97149906":"\ntrain_dir = os.path.join(base_dir)\n# validation_dir = os.path.join(base_dir, 'validation')\n\n# Directory with our training cat\/dog pictures\ntrain_with_mask_dir = os.path.join(train_dir, 'with_mask')\ntrain_without_mask_dir = os.path.join(train_dir, 'without_mask')\ntrain_withmask_fnames = os.listdir( train_with_mask_dir)\ntrain_without_fnames = os.listdir( train_without_mask_dir)","93368d1f":"%matplotlib inline\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n# Parameters for our graph; we'll output images in a 4x4 configuration\nnrows = 4\nncols = 4\n\npic_index = 0 # Index for iterating over images","974423e4":"# Set up matplotlib fig, and size it to fit 4x4 pics\nfig = plt.gcf()\nfig.set_size_inches(ncols*4, nrows*4)\n\npic_index+=8\n\nnext_cat_pix = [os.path.join(train_with_mask_dir, fname) \n                for fname in train_withmask_fnames[ pic_index-8:pic_index] \n               ]\n\nnext_dog_pix = [os.path.join(train_without_mask_dir, fname) \n                for fname in train_without_fnames[ pic_index-8:pic_index]\n               ]\n\nfor i, img_path in enumerate(next_cat_pix+next_dog_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows, ncols, i + 1)\n  sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()\n","bdfd7162":"import tensorflow as tf","3839a416":"model = tf.keras.models.Sequential([\n    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n    tf.keras.layers.Conv2D(512, (3,3), activation='relu', input_shape=(200, 200, 3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2), \n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n    tf.keras.layers.MaxPooling2D(2,2),\n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(), \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'), \n    tf.keras.layers.Dense(256, activation='relu'), \n    tf.keras.layers.Dense(1, activation='sigmoid')  \n])","ba8a8a04":"model.summary()","236ff7dd":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(optimizer=RMSprop(lr=0.001),\n              loss='binary_crossentropy',\n              metrics = ['accuracy'])","744f8916":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndef image_data_generator(data_dir,\n                       data_augment=True,\n                       batch_size=32,\n                       target_size=(200, 200),\n                       color_mode='rgb',\n                       class_mode='binary',\n                       shuffle=True):\n  if data_augment:\n      datagen = ImageDataGenerator(rescale=1.\/255,\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   validation_split=0.2,#this is the trick\n                                   horizontal_flip=True)\n  else:\n      datagen = ImageDataGenerator(rescale=1.\/255)\n\n  generator = datagen.flow_from_directory(data_dir,\n                                          target_size=target_size,\n                                          color_mode=color_mode,\n                                          batch_size=batch_size,\n                                          shuffle=shuffle,\n                                          class_mode=class_mode)\n  return generator\n\ntrain_generator = image_data_generator(base_dir,data_augment=True)\n","fa839f26":"history = model.fit(train_generator,\n                              #validation_data=validation_generator,\n                              steps_per_epoch=100,\n                              epochs=31,\n                              #validation_steps=50,\n                              verbose=2)","6c75814d":"#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc      = history.history[     'accuracy' ]\n#val_acc  = history.history[ 'val_accuracy' ]\nloss     = history.history[    'loss' ]\n\nepochs   = range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     acc )\nplt.title ('Training and  accuracy')\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.plot  ( epochs,     loss )\nplt.title ('Training and  loss'   )","7bf0dbde":"### checking layers parameters ","475f9de1":"### Prinitng Accuracy","4454b372":"### Creating image Generator to feed the conv neural network","31568875":"### Plotting some of the sample images from Data","d5dd6944":"### Defining the CNN model using Tensorflow\n","c6eea650":"Making Dir paths","7552e3d9":"### Training"}}