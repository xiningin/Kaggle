{"cell_type":{"fcd3652b":"code","c3924eec":"code","ba89923b":"code","ddfe8fb1":"code","147a763c":"code","b06b5189":"code","ba4f34ef":"code","b88c05d4":"code","8f78f804":"code","f0d8f782":"code","d8fcafcb":"code","07b74215":"markdown","62abcdb4":"markdown","e1c668b6":"markdown","3b4c6e5f":"markdown"},"source":{"fcd3652b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import KFold\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c3924eec":"# read train.csv file\ndf = pd.read_csv(\"..\/input\/train.csv\")\ndf.head()","ba89923b":"# check if there is any empty cell or not\ndf.isnull().any().any()","ddfe8fb1":"#check classification distribution\ndf['target'].value_counts().plot.bar()","147a763c":"#check classification distribution in percentage. So, target are not balanced\ndf['target'].value_counts(normalize=True)","b06b5189":"# separate target column and feature columns\nlabels = df.pop('target')\ndata = df.drop('ID_code', axis=1)","ba4f34ef":"# load test data\ntest_data = pd.read_csv(\"..\/input\/test.csv\")\ntest_data.head()","b88c05d4":"# keep only features columns\ntest_data = test_data.drop('ID_code', axis=1)\ntest_data.head()","8f78f804":"# K-fold corss validation with 10 fold\nn_splits = 10\nkf = KFold(n_splits=n_splits)","f0d8f782":"# model with LGB\nimport warnings\nwarnings.filterwarnings('ignore')\n\nparam = {'objective': 'binary', 'metric': 'auc', 'learning_rate': 0.01, 'num_rounds': 6000, 'verbose': 1}\ntest_pred = np.zeros(len(test_data))\nfor fold, (train_indx, val_indx) in enumerate(kf.split(labels)):\n    print(\"Fold {}\".format(fold+1))\n    train_set = lgb.Dataset(data.iloc[train_indx], label=labels.iloc[train_indx])\n    val_set = lgb.Dataset(data.iloc[val_indx], label=labels.iloc[val_indx])\n    model = lgb.train(param, train_set, valid_sets=val_set, verbose_eval=500)\n    test_pred += model.predict(test_data)\/n_splits","d8fcafcb":"# save data\nsave = pd.read_csv('..\/input\/sample_submission.csv')\nsave['target'] = test_pred\nsave.to_csv('LGB_kfold.csv', index=False)\nsave.head()","07b74215":"# Santander Customet Transaction prediction by applying LGB with K-Fold\n\nThis kernel show some visualization of the data and applied Light Gradient Boosting (LGB) algorithm over K-Fold cross validation. After applying different algorithms (Decision Tree, Logistic regression, PCA to diemention reduction; which will discuss later) this approaches gives better accuracy.","62abcdb4":"# Load data","e1c668b6":"# Data check, visualization and preprocessing","3b4c6e5f":"A simple model but great works. upvote if you like :):)"}}