{"cell_type":{"30a289ff":"code","d5837bb9":"code","4a94ee91":"code","778fe697":"code","e9c5f49a":"code","77eb7638":"code","73f3d3b1":"code","c9287520":"code","b5868dda":"markdown","9386f20c":"markdown","087a9626":"markdown","52f5a3ed":"markdown","c1dea806":"markdown","d59ceb3b":"markdown","10654ff8":"markdown"},"source":{"30a289ff":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport albumentations as A","d5837bb9":"DATA_DIR = '..\/input\/made-cv-2021-contest-02-license-plate-recognition\/data\/'\nDATA_IMG_TRAIN  = DATA_DIR + 'train\/'\nDATA_JSON_TRAIN = DATA_DIR + 'train.json'\nW_PLATE = 235\nH_PLATE = 50\n\nwith open(DATA_JSON_TRAIN) as f:\n    JSON_TRAIN = json.load(f)\n    TARGETS = {p['file'].split('\/')[1]: p['nums'] for p in JSON_TRAIN}","4a94ee91":"def sort_corners(p1, p2, p3, p4):\n    p1, p2, p3, p4 = list(sorted([p1, p2, p3, p4]))\n    if p1[1] > p2[1]:\n        p1, p2 = p2, p1\n    if p4[1] > p3[1]:\n        p3, p4 = p4, p3\n    return [p1, p2, p3, p4]\n\n\ndef sort_plates(plates):\n    n_plates = plates.shape[0] \/\/ 4\n    plates = np.split(plates, np.arange(4, 4*n_plates, 4))\n    plates = sorted(plates, key=lambda p: min(p[:, 0]))\n    for i in range(n_plates):\n        plates[i] = sort_corners(*map(list, plates[i]))\n        \n    return np.vstack(plates)\n\n\ndef get_target(path):\n    file = path.split('\/')[-1]\n    target = [[list(p) for p in t['box']] for t in TARGETS[file]]\n    return np.vstack(target)\n\n\ndef show_image(img, plates, axis=None):\n    axis = axis or plt.gca()\n    img = img.copy()\n    \n    if plates is not None:\n        thickness = max(img.shape[0] \/\/ 400, 1)\n        color = (0, 255, 0)\n        n_plates = plates.shape[0] \/\/ 4\n\n        for i in range(n_plates):\n            plate = plates[4*i:4*(i + 1), :]\n            p1, p2, p3, p4 = plate\n            p1 = (round(p1[0]), round(p1[1]))\n            p2 = (round(p2[0]), round(p2[1]))\n            p3 = (round(p3[0]), round(p3[1]))\n            p4 = (round(p4[0]), round(p4[1]))\n            cv2.line(img, p1, p2, color=color, thickness=thickness)\n            cv2.line(img, p2, p3, color=color, thickness=thickness)\n            cv2.line(img, p3, p4, color=color, thickness=thickness)\n            cv2.line(img, p4, p1, color=color, thickness=thickness)\n\n    axis.axis('off')\n    axis.imshow(img)","778fe697":"class PlateHorizontalFlip(A.HorizontalFlip):\n    def __call__(self, *args, force_apply=False, **kwargs):\n        result = super(A.HorizontalFlip, self).__call__(*args, force_apply=False, **kwargs)\n        self.flip_plates(result)\n\n        return result\n\n\n    def flip_plates(self, result):\n        image = result['image']\n        plates = np.asarray(result['keypoints'])\n        n_plates = plates.shape[0] \/\/ 4\n        plates = np.split(plates, np.arange(4, 4*n_plates, 4))\n\n        for i in range(n_plates):\n            plate = plates[i]\n            self.flip_plate(image, plate[:, :2])\n\n\n    def flip_plate(self, image, plate):\n        p1, p2, p3, p4 = list(map(list, plate))\n\n        pts_from = np.float32([p1, p4, p2, p3])\n        pts_to = np.float32([[0, 0], [W_PLATE, 0], [0, H_PLATE], [W_PLATE, H_PLATE]])\n\n        M = cv2.getPerspectiveTransform(pts_from, pts_to)\n        plate = cv2.warpPerspective(image, M, (W_PLATE, H_PLATE))\n        plate = cv2.flip(plate, 1)\n        plate = cv2.warpPerspective(plate, np.linalg.inv(M), (image.shape[1], image.shape[0]))\n        image[plate>0] = plate[plate>0]\n\n\n    def apply_to_keypoints(self, keypoints, **params):\n        keypoints = np.array(keypoints)\n        keypoints[:, 0] = (params['cols'] - 1) - keypoints[:, 0]\n\n        return sort_plates(keypoints)","e9c5f49a":"augmentation = A.Compose([\n    PlateHorizontalFlip(p=1.0),\n    A.RandomBrightness(limit=0.2, p=0.5),\n    A.RandomContrast(limit=0.2, p=0.5),\n    A.Blur(blur_limit=3, p=0.5),\n    A.Rotate(border_mode=cv2.BORDER_CONSTANT, limit=10, p=0.8),\n], keypoint_params=A.KeypointParams(format='xy'))","77eb7638":"for file in ['0.jpg', '59.jpg']:\n    file = DATA_IMG_TRAIN + file\n\n    src = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB)\n    plates = get_target(file)\n\n    res_flipx = augmentation(image=src, keypoints=plates)\n    src_flipx, plates_flipx = res_flipx['image'], np.asarray(res_flipx['keypoints'])\n\n    fig, axes = plt.subplots(1, 2, figsize=(21, 15))\n    show_image(src, plates, axis=axes[0])\n    show_image(src_flipx, plates_flipx, axis=axes[1])","73f3d3b1":"file = DATA_IMG_TRAIN + '22.jpg'\n\nsrc = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB)\nplates = get_target(file)\n\nres_flipx = augmentation(image=src, keypoints=plates)\nsrc_flipx, plates_flipx = res_flipx['image'], np.asarray(res_flipx['keypoints'])\n\nfig, axes = plt.subplots(1, 2, figsize=(21, 15))\nshow_image(src, plates, axis=axes[0])\nshow_image(src_flipx, plates_flipx, axis=axes[1])","c9287520":"file = DATA_IMG_TRAIN + '463.jpg'\n\nsrc = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB)\nplates = get_target(file)\n\nres_flipx = augmentation(image=src, keypoints=plates)\nsrc_flipx, plates_flipx = res_flipx['image'], res_flipx['keypoints']\n\nfig, axes = plt.subplots(1, 2, figsize=(21, 15))\nshow_image(src, None, axis=axes[0])\nshow_image(src_flipx, None, axis=axes[1])","b5868dda":"# Flip-X Transform\n\n\u0412 \u044d\u0444\u0438\u0440\u0435 \u043f\u043e\u0441\u0442\u043e\u044f\u043d\u043d\u0430\u044f \u0440\u0443\u0431\u0440\u0438\u043a\u0430 \"Flip-X Transform\"","9386f20c":"\u041d\u0430 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445 \u0441 \u043f\u043b\u043e\u0445\u043e\u0439 \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u043e\u0439 \u0431\u0443\u0434\u0435\u0442 \u0447\u0442\u043e-\u0442\u043e \u043f\u043e\u0434\u043e\u0431\u043d\u043e\u0435:","087a9626":"\u041a\u043e\u043d\u0435\u0447\u043d\u043e, \u0442\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430 \u043f\u0435\u0440\u0435\u0432\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u0435\u0442 \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0435 \u043d\u043e\u043c\u0435\u0440\u0430, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0435\u0441\u0442\u044c \u0432 \u0442\u0430\u0440\u0433\u0435\u0442\u0435. \u041e\u0431 \u044d\u0442\u043e\u043c \u0441\u0442\u043e\u0438\u0442 \u043f\u043e\u043c\u043d\u0438\u0442\u044c. \u0415\u0441\u043b\u0438 \u043d\u043e\u043c\u0435\u0440 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e \u0441\u043a\u0440\u044b\u0442 \u0438\u043b\u0438 \u043f\u0440\u043e\u0441\u0442\u043e \u043e\u0448\u0438\u0431\u043a\u0430 \u0432 \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0435, \u0442\u043e \u043e\u043d \u0444\u043b\u0438\u043f\u043d\u0443\u0442 \u043d\u0435 \u0431\u0443\u0434\u0435\u0442.","52f5a3ed":"## Utils","c1dea806":"\u0421 \u0442\u0430\u043a\u0438\u043c \u043c\u043e\u0436\u043d\u043e \u0431\u043e\u0440\u043e\u0442\u044c\u0441\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u043e\u043c \u043e\u0448\u0438\u0431\u043e\u043a \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435 \u0438 \u0437\u0430\u043c\u0435\u043d\u043e\u0439 \u043f\u043b\u043e\u0445\u043e\u0439 \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u0438 \u043d\u0430 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 (\u0435\u0441\u043b\u0438 \u043e\u043d\u0438 \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u044b\u0435).  ","d59ceb3b":"\u041d\u0430 \u0445\u043e\u0440\u043e\u0448\u0438\u0445 \u043f\u0440\u0438\u043c\u0435\u0440\u0430\u0445 \u0441 \u0445\u043e\u0440\u043e\u0448\u0435\u0439 \u0440\u0430\u0437\u043c\u0435\u0442\u043a\u043e\u0439 \u0432\u0441\u0435 \u0431\u0443\u0434\u0435\u0442 \u0445\u043e\u0440\u043e\u0448\u043e. \u041f\u0435\u0440\u0435\u0432\u043e\u0440\u0430\u0447\u0438\u0432\u0430\u0442\u044c\u0441\u044f \u0431\u0443\u0434\u0443\u0442 \u0432\u0441\u0435 \u043d\u043e\u043c\u0435\u0440\u0430, \u0447\u0442\u043e \u0435\u0441\u0442\u044c \u0432 \u0442\u0430\u0440\u0433\u0435\u0442\u0435:","10654ff8":"## Transform"}}