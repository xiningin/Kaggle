{"cell_type":{"3b029a37":"code","063f58fd":"code","e57059af":"code","4765b0fc":"code","2770f584":"code","4f5deedd":"code","55a06beb":"code","a4336ac7":"code","c4e167cc":"code","5edae2a6":"code","c7b41164":"code","c685905b":"code","5642cb0b":"code","ed6dabee":"code","1c5e4521":"code","f9218585":"code","4c447f6c":"code","f2263b8e":"code","548e4863":"code","f36d6716":"code","fde72941":"code","0a0f2620":"code","7a648c79":"code","55d72e6b":"code","498d421f":"code","28b549da":"code","b8747ba7":"code","392cffff":"code","58dd4020":"code","553de747":"code","d931cda1":"code","0b9d70a5":"code","4e3ef280":"code","2ca9b7ad":"code","dc0dabde":"code","c3a9d980":"code","3d00d667":"code","35448257":"code","c66a43c4":"code","33746e2a":"markdown","c5b94d2e":"markdown","5489b1c9":"markdown","004fccb9":"markdown","e615b4d1":"markdown","7bc8dc1e":"markdown","5c760309":"markdown","fa7fd894":"markdown","cce30836":"markdown","35ab2251":"markdown","0e5330f9":"markdown"},"source":{"3b029a37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# since I can't do much about warnings from libraries, just ignore them!!\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os, random\nimport numpy as np \n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nprint('Using Tensorflow version: ', tf.__version__)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport cv2\nprint('Using OpenCV version: ', cv2.__version__)\n%matplotlib inline\n\nplt.style.use('seaborn')\nsns.set_style('darkgrid')\n\nseed = 123\nrandom.seed(seed)\nnp.random.seed(seed)\ntf.set_random_seed(seed)\n\nfloat_formatter = lambda x: '%.4f' % x\nnp.set_printoptions(formatter={'float_kind':float_formatter})\nnp.set_printoptions(threshold=np.inf, suppress=True, precision=4, linewidth=110)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n# all images are available in \/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/ folder\n# this has 2 sub-folders holding \"Parasitized\" and \"Uninfected\"\nimages_root = \"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\"","063f58fd":"# some globals used throught this workbook (hyper-parameters)\nIMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS = 128, 128, 3\nNUM_EPOCHS, BATCH_SIZE = 100, 32\nADAM_LR = 0.001","e57059af":"def load_image(image_path):\n    img = cv2.resize(cv2.imread(image_path),(IMAGE_HEIGHT, IMAGE_WIDTH))\n    img = img.clip(0, 255).astype('uint8')\n    # convert from BGR colorspace to RGB, so other libraries can process easily\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\ninfected_images, infected_labels = [], []\n\nprint('Processing Infected images...', end='', flush=True)\ninfected_images_glob = glob.glob(\"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Parasitized\/*.png\")\nfor i in infected_images_glob:\n    img = load_image(i)\n    infected_images.append(img)\n    infected_labels.append(1)\n    \ninfected_images = np.array(infected_images)\ninfected_labels = np.array(infected_labels)\nprint('\\rInfected images: found %d images & %d labels' % (len(infected_images), len(infected_labels)))\n\nuninfected_images, uninfected_labels = [], []\n\nprint('Processing Un-infected images...', end='', flush=True)\nuninfected_images_glob = glob.glob(\"\/kaggle\/input\/cell-images-for-detecting-malaria\/cell_images\/cell_images\/Uninfected\/*.png\")\nfor i in uninfected_images_glob:\n    img = load_image(i)\n    uninfected_images.append(img)\n    uninfected_labels.append(0)\n    \nuninfected_images = np.array(uninfected_images)\nuninfected_labels = np.array(uninfected_labels)\nprint('\\rUn-infected images: found %d images & %d labels' % (len(uninfected_images), len(uninfected_labels)))\n\nall_images = np.vstack([infected_images, uninfected_images])\nall_labels = np.hstack([infected_labels, uninfected_labels])\nprint('Combining into all: we have %d images & %d labels' % (len(all_images), len(all_labels)))\n\n# delete unwanted arrays to conserve memory, especially since we'll be using pre-trained (huge) models\ndel infected_images, infected_labels\ndel uninfected_images, uninfected_labels","4765b0fc":"# shuffle the data\nindexes = np.random.permutation(np.arange(all_images.shape[0]))\n#for _ in range(5): np.random.shuffle(indexes)\n\nall_images = all_images[indexes]\nall_labels = all_labels[indexes]\nall_labels[:25]","2770f584":"# split into train\/test sets (80:20)\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = \\\n    train_test_split(all_images, all_labels, test_size=0.20, random_state=seed)\ntest_images, test_labels = X_test.copy(), y_test.copy()\n# NOTE: we set aside a copy of the test set for visualization purposes\n# we WILL NOT apply any further pre-processing steps to test_images\/test_labels\nX_train.shape, y_train.shape, X_test.shape, y_test.shape, test_images.shape, test_labels.shape","4f5deedd":"def display_sample(sample_images, sample_labels, sample_predictions=None, num_rows=5, num_cols=10,\n                   plot_title=None, fig_size=None):\n    \"\"\" display a random selection of images & corresponding labels, optionally with predictions\n        The display is laid out in a grid of num_rows x num_col cells\n        If sample_predictions are provided, then each cell's title displays the prediction \n        (if it matches actual) or actual\/prediction if there is a mismatch\n    \"\"\"\n    from PIL import Image\n    import seaborn as sns\n    assert sample_images.shape[0] == num_rows * num_cols\n\n    # a dict to help encode\/decode the labels\n    LABELS = {\n        0: 'Uninfected',\n        1: 'Infected',\n    }\n    \n    with sns.axes_style(\"whitegrid\"):\n        sns.set_context(\"notebook\", font_scale=1.1)\n        sns.set_style({\"font.sans-serif\": [\"Verdana\", \"Arial\", \"Calibri\", \"DejaVu Sans\"]})\n\n        f, ax = plt.subplots(num_rows, num_cols, figsize=((14, 9) if fig_size is None else fig_size),\n            gridspec_kw={\"wspace\": 0.02, \"hspace\": 0.25}, squeeze=True)\n        #fig = ax[0].get_figure()\n        f.tight_layout()\n        f.subplots_adjust(top=0.93)\n\n        for r in range(num_rows):\n            for c in range(num_cols):\n                image_index = r * num_cols + c\n                ax[r, c].axis(\"off\")\n                # show selected image\n                pil_image = Image.fromarray(sample_images[image_index])\n                ax[r, c].imshow(pil_image, cmap=\"Greys\")\n\n                if sample_predictions is None:\n                    # show the actual labels in the cell title\n                    title = ax[r, c].set_title(\"%s\" % LABELS[sample_labels[image_index]])\n                else:\n                    # else check if prediction matches actual value\n                    true_label = sample_labels[image_index]\n                    pred_label = sample_predictions[image_index]\n                    prediction_matches_true = (sample_labels[image_index] == sample_predictions[image_index])\n                    if prediction_matches_true:\n                        # if actual == prediction, cell title is prediction shown in green font\n                        title = LABELS[true_label]\n                        title_color = 'g'\n                    else:\n                        # if actual != prediction, cell title is actua\/prediction in red font\n                        title = '%s\/%s' % (LABELS[true_label], LABELS[pred_label])\n                        title_color = 'r'\n                    # display cell title\n                    title = ax[r, c].set_title(title)\n                    plt.setp(title, color=title_color)\n        # set plot title, if one specified\n        if plot_title is not None:\n            f.suptitle(plot_title)\n\n        plt.show()\n        plt.close()","55a06beb":"# display a random sample of 64 images from test_images\/test_labels set\nsample_size = 64\nrand_indexes = np.random.choice(np.arange(len(test_images)), sample_size)\nsample_images = test_images[rand_indexes]\nsample_labels = test_labels[rand_indexes]\n#sample_images.shape, sample_labels.shape, len(sample_images), len(sample_labels)\ndisplay_sample(sample_images, sample_labels, plot_title=\"Random sample of %d images\" % sample_size, \n               num_rows=8, num_cols=8, fig_size=(13,13))","a4336ac7":"# normalize images\nX_train = X_train.astype('float32') \/ 255.0\nX_test = X_test.astype('float32') \/ 255.0","c4e167cc":"def show_plots(history, plot_title=None, fig_size=None):\n    \n    import seaborn as sns\n    \n    \"\"\" Useful function to view plot of loss values & accuracies across the various epochs\n        Works with the history object returned by the train_model(...) call \"\"\"\n    assert type(history) is dict\n\n    # NOTE: the history object should always have loss & acc (for training data), but MAY have\n    # val_loss & val_acc for validation data\n    loss_vals = history['loss']\n    val_loss_vals = history['val_loss'] if 'val_loss' in history.keys() else None\n    \n    # accuracy is an optional metric chosen by user\n    # NOTE: in Tensorflow 2.0, the keys are 'accuracy' and 'val_accuracy'!! Why Google why??\n    acc_vals = history['acc'] if 'acc' in history.keys() else None\n    if acc_vals is None:\n        # try 'accuracy' key, could be using Tensorflow 2.0 backend!\n        acc_vals = history['accuracy'] if 'acc' in history.keys() else None\n        \n    val_acc_vals = history['val_acc'] if 'val_acc' in history.keys() else None\n    if val_acc_vals is None:\n        # try 'val_accuracy' key, could be using Tensorflow 2.0 backend!\n        val_acc_vals = history['val_accuracy'] if 'val_accuracy' in history.keys() else None       \n        \n    epochs = range(1, len(history['loss']) + 1)\n    \n    col_count = 1 if ((acc_vals is None) and (val_acc_vals is None)) else 2\n    \n    with sns.axes_style(\"darkgrid\"):\n        sns.set_context(\"notebook\", font_scale=1.1)\n        sns.set_style({\"font.sans-serif\": [\"Verdana\", \"Arial\", \"Calibri\", \"DejaVu Sans\"]})\n\n        f, ax = plt.subplots(nrows=1, ncols=col_count, figsize=((16, 5.5) if fig_size is None else fig_size))\n    \n        # plot losses on ax[0]\n        #ax[0].plot(epochs, loss_vals, color='navy', marker='o', linestyle=' ', label='Training Loss')\n        ax[0].plot(epochs, loss_vals, label='Training Loss')\n        if val_loss_vals is not None:\n            #ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n            ax[0].plot(epochs, val_loss_vals, label='Validation Loss')\n            ax[0].set_title('Training & Validation Loss')\n            ax[0].legend(loc='best')\n        else:\n            ax[0].set_title('Training Loss')\n    \n        ax[0].set_xlabel('Epochs')\n        ax[0].set_ylabel('Loss')\n        ax[0].grid(True)\n    \n        # plot accuracies, if exist\n        if col_count == 2:\n            #acc_vals = history['acc']\n            #val_acc_vals = history['val_acc'] if 'val_acc' in history.keys() else None\n\n            #ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n            ax[1].plot(epochs, acc_vals, label='Training Accuracy')\n            if val_acc_vals is not None:\n                #ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n                ax[1].plot(epochs, val_acc_vals, label='Validation Accuracy')\n                ax[1].set_title('Training & Validation Accuracy')\n                ax[1].legend(loc='best')\n            else:\n                ax[1].set_title('Training Accuracy')\n\n            ax[1].set_xlabel('Epochs')\n            ax[1].set_ylabel('Accuracy')\n            ax[1].grid(True)\n    \n        if plot_title is not None:\n            plt.suptitle(plot_title)\n    \n        plt.show()\n        plt.close()\n\n    # delete locals from heap before exiting (to save some memory!)\n    del loss_vals, epochs, acc_vals\n    if val_loss_vals is not None:\n        del val_loss_vals\n    if val_acc_vals is not None:\n        del val_acc_vals","5edae2a6":"def save_keras_model(model, base_file_name, save_dir=os.path.join('.', 'model_states')):\n    \"\"\" save keras model graph + weights to one HDF5 file \"\"\"\n    # check if save_dir exists, else create it\n    if not os.path.exists(save_dir):\n        try:\n            os.mkdir(save_dir)\n        except OSError as err:\n            print(\"Unable to create folder {} to save Keras model. Can't continue!\".format(save_dir))\n            raise err\n    \n    # save the model\n    if not base_file_name.lower().endswith('.h5'):\n        base_file_name = base_file_name + '.h5'\n        \n    model_save_path = os.path.join(save_dir, base_file_name)\n    model.save(model_save_path)\n    print('Saved model to file %s' % model_save_path)","c7b41164":"def load_keras_model(base_file_name, save_dir=os.path.join('.', 'model_states'), \n                     use_tf_keras_impl=True):            \n    \"\"\"load keras model graph + weights from HDF5 file\"\"\"\n    if not base_file_name.lower().endswith('.h5'):\n        base_file_name = base_file_name + '.h5'\n        \n    model_save_path = os.path.join(save_dir, base_file_name)\n    if not os.path.exists(model_save_path):\n        raise IOError('Cannot find model state file at %s!' % model_save_path)\n        \n    # load the state\/weights etc.\n    if use_tf_keras_impl:\n        from tensorflow.keras.models import load_model \n    else:\n        from keras.models import load_model\n\n    # load the state\/weights etc. from .h5 file        \n    model = load_model(model_save_path)\n    print('Loaded Keras model from %s' % model_save_path)\n    return model","c685905b":"def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    import itertools\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","5642cb0b":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import backend as K\n\nK.clear_session()\n\n# NOTE: will download the weights for imagenet\nvgg16_base = VGG16(\n    weights='imagenet',    # use weights for ImageNet\n    include_top=False,     # don't use upper Dense layers\n    input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\nprint(vgg16_base.summary())","ed6dabee":"# build our model above the VGG16 pre-trained model\ndef build_model_xfer(use_l2_loss=True):\n    from tensorflow.keras.optimizers import Adam\n    from tensorflow.keras.regularizers import l2\n    \n    l2_loss_lambda = 0.00002  # just a wee-bit :)\n    l2_loss = l2(l2_loss_lambda) if use_l2_loss else None\n    if l2_loss is not None: print('Using l2_loss_lambda = %f' % l2_loss_lambda)\n        \n    model = tf.keras.models.Sequential([\n        # our vgg16_base model added as a layer\n        vgg16_base,\n        # here is our custom prediction layer (same as before)\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dropout(0.50),\n        tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=l2_loss),\n        tf.keras.layers.Dropout(0.20),        \n        tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=l2_loss),\n        tf.keras.layers.Dropout(0.10),         \n        tf.keras.layers.Dense(1, activation='sigmoid')    \n    ])\n    \n    # mark mobilenet layer as non-trainable, so training updates\n    # weights and biases of just our newly added layers\n    vgg16_base.trainable = False\n    \n    model.compile(optimizer=Adam(lr=0.001), \n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model","1c5e4521":"model = build_model_xfer()\nprint(model.summary())","f9218585":"# train the model\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\ndef lr_step(epoch):\n    power = (epoch % 20) # [0-19] = 0, [20-39] = 1, [40-59] = 2...\n    new_lr = ADAM_LR_START * 1.0 \/ (1 + ADAM_LR_DECAY * power)\n    return new_lr\n\nlr_callback = LearningRateScheduler(lr_step)\n\nhist = model.fit(X_train, y_train, epochs=50, batch_size=BATCH_SIZE, validation_split=0.20)\n                 #callbacks=[lr_callback])","4c447f6c":"show_plots(hist.history, plot_title='Malaria Detection - VGG16 Base Model')","f2263b8e":"# evaluate performance on train & test data\nloss, acc = model.evaluate(X_train, y_train, batch_size=64, verbose=1)\nprint('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\nloss, acc = model.evaluate(X_test, y_test, batch_size=64, verbose=1)\nprint('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))","548e4863":"save_keras_model(model, \"kr_malaria_vgg16\")\ndel model","f36d6716":"model = load_keras_model(\"kr_malaria_vgg16\")\nprint(model.summary())","fde72941":"# run predictions\ny_pred = (model.predict(X_test, batch_size=BATCH_SIZE) >= 0.5).ravel().astype('int32')\nprint('Actuals    : ', y_test[:30])\nprint('Predictions: ', y_pred[:30])\nprint('We got %d of %d wrong!' % ((y_pred != y_test).sum(), len(y_test)))","0a0f2620":"# let's see the confusion matrix & classification report\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nplot_confusion_matrix(confusion_matrix(y_test, y_pred), classes=[\"Uninfected\",\"Parasitized\"])","7a648c79":"# display a random sample of 64 images from test_images\/test_labels set with predictions\nsample_size = 64\nrand_indexes = np.random.choice(np.arange(len(test_images)), sample_size)\nrand_images = test_images[rand_indexes]\nrand_labels = test_labels[rand_indexes]\nrand_predictions = y_pred[rand_indexes]\n#sample_images.shape, sample_labels.shape, len(sample_images), len(sample_labels)\ndisplay_sample(rand_images, rand_labels, sample_predictions=rand_predictions,\n               plot_title='Malaria Detection - VGG16 Base Model - Sample Predictions for %d images' % sample_size, \n               num_rows=8, num_cols=8, fig_size=(16,16))","55d72e6b":"# cleanup to save space\ndel vgg16_base\ndel model","498d421f":"try:\n    del vgg16_base_ft\nexcept NameError:\n    pass # model is not defined!    \n\ntry:\n    del model\nexcept NameError:\n    pass # model is not defined!","28b549da":"# here is the pre-trained model again\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras import backend as K\n\nK.clear_session()\n\n# NOTE: will download the weights for imagenet\nvgg16_base_ft = VGG16(\n    weights='imagenet',    # use weights for ImageNet\n    include_top=False,     # don't use upper Dense layers\n    input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))\nprint(vgg16_base_ft.summary())","b8747ba7":"trainable = False\n\n# this will iterate over the layers in sequence from bottom to top\n# i.e. from input_1 to block5_pool\nfor layer in vgg16_base_ft.layers:\n    if layer.name == 'block5_conv3':\n        trainable = True\n    layer.trainable = trainable\n    \n# let's see what that just did\nfor layer in vgg16_base_ft.layers:\n    print('%s -> trainable? %s' % (layer.name, \"Yes\" if layer.trainable else \"No\"))","392cffff":"print(vgg16_base_ft.summary())","58dd4020":"# now let's build our model\ndef build_model_xfer_ft(use_l2_loss=True):\n    from tensorflow.keras.optimizers import Adam\n    from tensorflow.keras.regularizers import l2\n    \n    l2_loss_lambda = 0.00010  # just a \"pinch\" of L2 regularization :)\n    l2_loss = l2(l2_loss_lambda) if use_l2_loss else None\n    if l2_loss is not None: print('Using l2_loss_lambda = %f' % l2_loss_lambda)\n        \n    model = tf.keras.models.Sequential([\n        # our vgg16_base model added as a layer\n        vgg16_base_ft,\n        # here is our custom prediction layer (same as before)\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dropout(0.50),\n        tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=l2_loss),\n        tf.keras.layers.Dropout(0.30),        \n        tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=l2_loss),\n        tf.keras.layers.Dropout(0.20),     \n        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2_loss),\n        tf.keras.layers.Dropout(0.10),           \n        tf.keras.layers.Dense(1, activation='sigmoid')    \n    ])\n    \n    # NOTE: we do not freeze vgg_base entirely as done previously!!\n    \n    model.compile(optimizer=Adam(lr=0.001), \n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model","553de747":"model = build_model_xfer_ft()\nprint(model.summary())","d931cda1":"# train model with pre-trained VGG16 layer\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n\ndef lr_step(epoch):\n    epoch_step = epoch \/\/ 20  # [0-19] == 0, [20-39] == 1, [40-59] == 2...\n    divisor = 10 ** (epoch_step)\n    new_lr = ADAM_LR \/ divisor\n    return new_lr\n\nlr_scheduler = LearningRateScheduler(lr_step)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.1, mode='auto', patience=5, verbose=1)\n\n# NOTE: since there are many more parameters to update, I am training for 75 epochs\nhist = model.fit(X_train, y_train, epochs=50, batch_size=BATCH_SIZE, validation_split=0.20)\n                 #callbacks=[lr_scheduler])","0b9d70a5":"show_plots(hist.history, plot_title='Malaria Detection - VGG16 Fine-tuned Model')","4e3ef280":"# evaluate performance on train & test data\nloss, acc = model.evaluate(X_train, y_train, batch_size=64, verbose=1)\nprint('Training data  -> loss: %.3f, acc: %.3f' % (loss, acc))\nloss, acc = model.evaluate(X_test, y_test, batch_size=64, verbose=1)\nprint('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))","2ca9b7ad":"save_keras_model(model, \"kr_malaria_vgg16_ft-1\")\ndel model","dc0dabde":"model = load_keras_model(\"kr_malaria_vgg16_ft-1\")\nprint(model.summary())","c3a9d980":"# run predictions\ny_pred = (model.predict(X_test, batch_size=BATCH_SIZE) >= 0.5).ravel().astype('int32')\nprint('Actuals    : ', y_test[:30])\nprint('Predictions: ', y_pred[:30])\nprint('We got %d of %d wrong!' % ((y_pred != y_test).sum(), len(y_test)))","3d00d667":"# let's see the confusion matrix & classification report\nfrom sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nplot_confusion_matrix(confusion_matrix(y_test, y_pred), classes=[\"Uninfected\",\"Parasitized\"])","35448257":"# display a random sample of 64 images from test_images\/test_labels set with predictions\nsample_size = 64\nrand_indexes = np.random.choice(np.arange(len(test_images)), sample_size)\nrand_images = test_images[rand_indexes]\nrand_labels = test_labels[rand_indexes]\nrand_predictions = y_pred[rand_indexes]\n#sample_images.shape, sample_labels.shape, len(sample_images), len(sample_labels)\ndisplay_sample(rand_images, rand_labels, sample_predictions=rand_predictions,\n               plot_title='Malaria Detection - VGG16 Fine-tuned Model - Sample Predictions for %d images' % sample_size, \n               num_rows=8, num_cols=8, fig_size=(16,16))","c66a43c4":"# cleanup\ndel vgg16_base_ft\ndel model","33746e2a":"**Cool!** So just  the last 2 layers of `vgg16_base` are now trainable. The `block5_pool` (MaxPooling2D) layer carries no weights, but the 2 Conv2D layers do!","c5b94d2e":"* The cells with red titles ('red cells') are the once displaying incorrect predictions\n* For such 'red cells' the title is displayed as 'correct_value'\/'prediction'\n* For all other cells, with green titles - these are cells displaying correct predictions","5489b1c9":"### Helper Function(s)","004fccb9":"## Fune-tuning the VGG16 Model\nIn ths section, we will try and further improve performance of the model by finetuning some Conv2D layers of the pre-trained VGG16 model.","e615b4d1":"Notice that some of the weights (parameters) are now marked as trainable - out of `14,714,688` parameters, `4,719,616` are now trainable (these are the # parameters in the `block5_conv2` + `block5_conv3` layer)\n\nNow let's build our model again, using `vgg16_base` layer with 2 of it's `Conv2D` layers _unlocked_. The code below is exactly the same as before, with one exception - we have commented out the `vgg16_base_ft.trainable = False` line.","7bc8dc1e":"**Observations:**\n\n>Configuration | Training Acc | Test Acc | Incorrect Predictions | Precision | Recall | F1-Score\n>:---|:---:|:---:|:---:|:---:|:---:|:---:|\n>**VGG16 Base Model**|96-97%|94-95%|315|0.95|0.93|0.94\n\n* From the loss and accuracy curves, we see that the cross-validation loss & accuracy follows the training loss & accuracy curves\n* From the accuracy metrics, we can conclude that the model is overfitting the data slightly (2% difference between training & test accuracies).\n* Though the precision & recall metrics are good, we'd like to reduce False Positives (i.e. predicting as Parasitized when actually not).","5c760309":"**Observations:**\n\n>Configuration | Training Acc | Test Acc | Incorrect Predictions | Precision | Recall | F1-Score\n>:---|:---:|:---:|:---:|:---:|:---:|:---:|\n>**VGG16 Base Model**|96-97%|94-95%|322|0.95|0.93|0.94\n>**VGG16 Fine Tuned**|98-99%|95-96%|276|0.96|0.94|0.95\n\n* Though the metrics look good, this is still an overfitting model. We should look at increasing the regularization.\n* Notice that the incidence of False Positives (predicting +ve, when actual uninfected) has come down to 106 from 132 and false negatives (predicting not infected, when infected) have also come down to 170 from 183. This is a better model than before.","fa7fd894":"![](http:\/\/)Let's **unfreeze** layers `block_conv3` and `block5_pool` and keep all others frozen. Consequently, these layers will also have their weights updated as the model trains across epochs.","cce30836":"## Training the model\nWe will use the **pre-trained VGG16** model. As a first step, we use the Conv2d layers of this model and freeze it, so that weights are not updated.","35ab2251":"Notice that the entire `14,714,688` parameters of the `vgg16_base` layer are marked as _Non-trainable_ parameters!","0e5330f9":"## Loading the images"}}