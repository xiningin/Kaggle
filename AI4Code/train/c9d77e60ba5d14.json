{"cell_type":{"a656f35a":"code","9ee9c36d":"code","805b8822":"code","23bc1fde":"code","fa347e67":"code","f48edff5":"code","1bfc6cb9":"code","7514db4f":"code","bfa06415":"code","9a592134":"code","255d2f53":"code","e4bddd90":"code","4cd16374":"code","b2201b38":"code","a8954c0b":"code","f2b76f60":"code","f2f02e39":"code","7eb96523":"code","9b5429a4":"code","3ccc156d":"code","4d7e789a":"code","585d29f0":"code","e7fc08cc":"code","ac8dc942":"code","53fd6240":"code","1f22f177":"code","f41b9056":"code","7b2390a5":"code","334a2fb7":"code","c8f951d8":"code","c30df9fd":"code","a95e8acb":"code","a4ef683a":"code","a985f2c6":"code","dd784548":"code","ac3bf2b8":"code","509a382f":"code","51c6792b":"code","d23e8095":"code","26fccca2":"code","0c6ea89a":"code","7d6381f0":"code","5fd2139e":"code","8ba8cdba":"code","74c74de6":"code","83dcf492":"code","ec23f528":"code","13753bb0":"code","3362f19d":"code","af3b19fb":"code","e4d5c825":"markdown","e333ef48":"markdown","03f74c0d":"markdown","6ef8ccf8":"markdown","2fb269d5":"markdown","59a34704":"markdown","83a3af69":"markdown","7d15c380":"markdown","c7d68beb":"markdown","5d3a7edd":"markdown","39113e04":"markdown","88282fb1":"markdown","a93e5208":"markdown","2850761e":"markdown","4250b566":"markdown","1e82ff27":"markdown","d0ba7f86":"markdown","be3182b5":"markdown","837671be":"markdown","802e6067":"markdown","6bf6fa54":"markdown","483ab897":"markdown","73937167":"markdown","9607b59a":"markdown","3c815bfd":"markdown","3d811717":"markdown","a8de9b80":"markdown","94fefa21":"markdown","2daf8ed1":"markdown","0714fec8":"markdown"},"source":{"a656f35a":"# numpy and pandas for data manipulation\nimport numpy as np\nimport pandas as pd \n\npd.set_option('display.max_rows', 500)\nimport gc\n\n# sklearn preprocessing \nfrom sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\n\nimport lightgbm as lgb\n\n# File system manangement\nimport os\n\n#eda\n!pip install klib\nimport klib\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nseed = 2357\nnp.random.seed(seed)","9ee9c36d":"# List files available\nprint(os.listdir(\"..\/input\/widsdatathon2021\/\"))\n","805b8822":"# Training data\ndf_train = pd.read_csv('..\/input\/widsdatathon2021\/TrainingWiDS2021.csv')\nprint('Training data shape: ', df_train.shape)\ndf_train.head()","23bc1fde":"df_train.drop('Unnamed: 0',axis=1,inplace=True)\nprint('Training data shape: ', df_train.shape)\ndf_train.head()","fa347e67":"# Testing data features\ndf_test = pd.read_csv('..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv')\ndf_test.drop('Unnamed: 0',axis=1,inplace=True)\nprint('Testing data shape: ', df_test.shape)\ndf_test.head()","f48edff5":"df_train.info(verbose=True, null_counts=True)","1bfc6cb9":"# Number of each type of column\ndf_train.dtypes.value_counts()","7514db4f":"# Number of unique classes in each object column\ndf_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","bfa06415":"# Function to calculate missing values by column# Funct \n\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","9a592134":"# Missing values for training data\nmissing_values_train = missing_values_table(df_train)\nmissing_values_train[:20].style.background_gradient(cmap='Greens')","255d2f53":"# Missing values for testing data\nmissing_values_test = missing_values_table(df_test)\nmissing_values_test[:20].style.background_gradient(cmap='Greens')","e4bddd90":"df_cleaned_train = klib.data_cleaning(df_train)\nklib.missingval_plot(df_cleaned_train)","4cd16374":"df_train['diabetes_mellitus'].value_counts(normalize=True)","b2201b38":"df_train['diabetes_mellitus'].astype(int).plot.hist();","a8954c0b":"plt.figure(figsize=(10,6))\nplt.title(\"Age vs people suffering from Diabetes\")\nsns.lineplot(df_train[\"age\"],df_train[\"diabetes_mellitus\"])\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number of people Suffering\")","f2b76f60":"plt.figure(figsize=(10,6))\nplt.title(\"Age vs people suffering from Diabetes\")\nsns.lineplot(data=df_train, x=\"age\", y=\"diabetes_mellitus\", hue=\"gender\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number of people Suffering\")","f2f02e39":"# Ethnicity vs Diabetes \ng = sns.catplot(x=\"ethnicity\", hue=\"gender\", col=\"diabetes_mellitus\",\n                data=df_train, kind=\"count\",\n                height=5, aspect=1.5);","7eb96523":"#Display correlation with a target variable of interest\nklib.corr_plot(df_train, target='diabetes_mellitus')","9b5429a4":"# combine train and test together to do common feature engineering\n\ntrain_copy = df_train.copy()\ntest_copy = df_test.copy()\n\n# set up a flag field to distinguish records from training and testing sets in the combined dataset\ntrain_copy['source'] = 0\ntest_copy['source'] = 1\n\n\nall_data = pd.concat([train_copy, test_copy], axis=0, copy=True)\ndel train_copy\ndel test_copy\ngc.collect()\n","3ccc156d":"all_data.drop('encounter_id',axis=1,inplace=True)\n","4d7e789a":"df_train['hospital_id'].isin(df_test['hospital_id']).value_counts()","585d29f0":"# Dropping hospital id also\nall_data.drop('hospital_id',axis=1,inplace=True)","e7fc08cc":"klib.cat_plot(df_train, figsize=(50,20))","ac8dc942":"categorical_columns = all_data.select_dtypes('object').columns\ncategorical_columns","53fd6240":"objList = all_data.select_dtypes(include = \"object\").columns\nprint (objList)\n\n\n# Create a label encoder object\nle = LabelEncoder()\nfor feat in objList:\n    all_data[feat] = le.fit_transform(all_data[feat].astype(str))\n\nprint (all_data.info())\n\n","1f22f177":"all_data[categorical_columns].head()","f41b9056":"all_data.fillna(-9999, inplace=True)\nall_data.isnull().sum()","7b2390a5":"# split the all-data DF into training and testing again\ntraining = all_data[all_data['source']==0]\ntesting = all_data[all_data['source']==1]\n\ndel all_data\ngc.collect()","334a2fb7":"print(training.shape)\nprint(testing.shape)","c8f951d8":"testing.drop('diabetes_mellitus',axis=1,inplace=True)\nprint(testing.shape)","c30df9fd":"TARGET = 'diabetes_mellitus'\ntrain_labels = training[TARGET]\ntrain = training.drop(columns = [TARGET,'source'])\nfeatures = list(train.columns)\ntest = testing.drop(columns = ['source'])\nprint('Training data shape: ', train.shape)\nprint('Testing data shape: ', test.shape)","a95e8acb":"\n# Make the model with the specified regularization parameter\nlog_reg = LogisticRegression(C = 0.0001)\n\n# Train on the training data\nlog_reg.fit(train, train_labels)\n","a4ef683a":"# Make predictions\n# Make sure to select the second column only\nlog_reg_pred = log_reg.predict_proba(test)[:, 1]","a985f2c6":"log_reg_pred ","dd784548":"# Submission dataframe\nsubmit = df_test[['encounter_id']]\nsubmit['diabetes_mellitus'] = log_reg_pred\nsubmit.to_csv('logreg_baseline.csv',index=False)\nsubmit.head()","ac3bf2b8":"# Make the random forest classifier\nrf = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)","509a382f":"# Train on the training data\nrf.fit(train, train_labels)\n\n# Extract feature importances\nfeature_importance_values = rf.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\n\n# Make predictions on the test data\npredictions = rf.predict_proba(test)[:, 1]","51c6792b":"# Make a submission dataframe\n# Submission dataframe\nsubmit = df_test[['encounter_id']]\nsubmit['diabetes_mellitus'] = predictions\n\n# Save the submission dataframe\nsubmit.to_csv('random_forest_baseline_domain.csv', index = False)","d23e8095":"def plot_feature_importances(df):\n    \"\"\"\n    Plot importances returned by a model. This can work with any measure of\n    feature importance provided that higher importance is better. \n    \n    Args:\n        df (dataframe): feature importances. Must have the features in a column\n        called `features` and the importances in a column called `importance\n        \n    Returns:\n        shows a plot of the 15 most importance features\n        \n        df (dataframe): feature importances sorted by importance (highest to lowest) \n        with a column for normalized importance\n        \"\"\"\n    \n    # Sort features according to importance\n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    # Normalize the feature importances to add up to one\n    df['importance_normalized'] = df['importance'] \/ df['importance'].sum()\n\n    # Make a horizontal bar chart of feature importances\n    plt.figure(figsize = (10, 6))\n    ax = plt.subplot()\n    \n    # Need to reverse the index to plot most important on top\n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance_normalized'].head(15), \n            align = 'center', edgecolor = 'k')\n    \n    # Set the yticks and labels\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    # Plot labeling\n    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n    plt.show()\n    \n    return df","26fccca2":"# Show the feature importances for the default features\nfeature_importances_sorted = plot_feature_importances(feature_importances)","0c6ea89a":"numerical_columns = train.columns[~train.columns.isin(categorical_columns)]","7d6381f0":"X = train\ny = train_labels\n\ntrain_X, val_X, train_y, val_y = train_test_split( X, y, test_size=0.20,random_state=0)","5fd2139e":"# Logistic Regression\n\nlr = LogisticRegression()\nlr.fit(train_X, train_y)\npredictions2 = lr.predict_proba(val_X)[:,1]\nroc_auc_score(val_y, predictions2)\n\n\n","8ba8cdba":"# RF\n\nrf.fit(train_X, train_y)\npredictions3 = rf.predict_proba(val_X)[:,1]\nroc_auc_score(val_y, predictions3)\n","74c74de6":"# Light GBM\n\nd_train=lgb.Dataset(train_X, label=train_y)\n\n#Specifying the parameter\nparams={}\nparams['learning_rate']=0.03\nparams['boosting_type']='gbdt' #GradientBoostingDecisionTree\nparams['objective']='binary' #Binary target feature\nparams['metric']='binary_logloss' #metric for binary classification\nparams['max_depth']=10\n\n#train the model \nclf=lgb.train(params,d_train,100) #train the model on 100 epocs\n\npredictions_lgb = clf.predict(val_X)\nroc_auc_score(val_y, predictions_lgb)","83dcf492":"# Log Reg baseline with CV\nscores_log = cross_val_score(lr, X, y, cv=10, scoring='roc_auc')\nscores_log.sort()\nprint('Mean Absolute Score %2f' %(scores_log.mean()))\n","ec23f528":"# RF baseline with CV\n\nscores_rf = cross_val_score(rf, X, y, cv=10, scoring='roc_auc')\nscores_rf.sort()\nprint('Mean Absolute Score %2f' %(scores_rf.mean()))","13753bb0":"kf = StratifiedKFold(n_splits=3,shuffle=False,random_state=seed)\npred_test_full = 0\ncv_score =[]\ni=1\nfor train_index,test_index in kf.split(X,y):\n    print('{} of KFold {}'.format(i,kf.n_splits))\n    xtr,xvl = X.loc[train_index],X.loc[test_index]\n    ytr,yvl = y[train_index],y[test_index]\n    \n    #model\n    lr = RandomForestClassifier(n_estimators = 100, random_state = 50, verbose = 1, n_jobs = -1)\n    #lr = LogisticRegression(C = 0.0001)\n    lr.fit(xtr,ytr)\n    score = roc_auc_score(yvl,lr.predict_proba(xvl)[:,1])\n    print('ROC AUC score:',score)\n    cv_score.append(score)    \n    pred_test = lr.predict_proba(test)[:,1]\n    pred_test_full +=pred_test\n    i+=1","3362f19d":"print('Confusion matrix\\n',confusion_matrix(yvl,lr.predict(xvl)))\nprint('Cv',cv_score,'\\nMean cv Score',np.mean(cv_score))","af3b19fb":"proba = lr.predict_proba(xvl)[:,1]\nfrp,trp, threshold = roc_curve(yvl,proba)\nroc_auc_ = auc(frp,trp)\n\nplt.figure(figsize=(10,6))\nplt.title('Reciever Operating Characteristics')\nplt.plot(frp,trp,'r',label = 'AUC = %0.2f' % roc_auc_)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'b--')\nplt.ylabel('True positive rate')\nplt.xlabel('False positive rate')","e4d5c825":"### Dropping unnecessary columns\nThere were no recurring patient visits, so the encounter_id would not be relevant to our models","e333ef48":"## Read in Data","03f74c0d":"# Evaluating the model\n\nWe have created our model but how will we know how accurate it is? We do have a Test dataset but since it doesn't have the Target column, everytime we optimize our model, we will have to submit our predictions to public Leaderboard to assess it accuracy.\n\n### Creating a Validation set\nAnother option would be to create a validation set from the training set. We will hold out a part of the training set during the start of the experiment and use it for evaluating our predictions. We shall use the scikit-learn library's model_selection.train_test_split() function that we can use to split our data","6ef8ccf8":"## Importing the necessary libraries","2fb269d5":"\n![1610090459081.jpg](attachment:1610090459081.jpg)\n\n##  Objective\nThe objective of this competition is to determine whether a patient admitted to an ICU has been diagnosed with a particular type of diabetes - Diabetes Mellitus. \n\n\n## Dataset\n* The dataset consists of 130,157 patient records along in the TrainingWiDS2021.csv file. This is the data that we will sue to train our model. \n* The UnlabeledWiDS2021.csv  file consists of the unlabelled data and will be sued for testing purposes\n* SampleSubmissionWiDS2021.csv and the SolutionTemplateWiDS2021.csv provide a template and the submissions should be in this form\n* DataDictionaryWiDS2021.csv contains additional information about the dataset.\n\n## Evaluation Metric\n\nSubmissions for the leaderboard will be evaluated on the Area under the Receiver Operating Characteristic (ROC) curve between the predicted and the observed target (diabetes_mellitus_diagnosis).\n\nAn ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n\n![](https:\/\/imgur.com\/yNeAG4M.png)\n\nAn ROC curve plots TPR vs. FPR at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. The following figure shows a typical ROC curve.\n\n![roccomp.jpg](attachment:roccomp.jpg)\n\nsource: http:\/\/gim.unmc.edu\/dxtests\/ROC3.htm\n\nThe closer the AUC is to 1, the better. An AUC of 0.9 is much better than an AUC of 0.01.\nFor additional reading: http:\/\/www.davidsbatista.net\/blog\/2018\/08\/19\/NLP_Metrics\/","59a34704":"# Baseline\n\n### 1. Logistic Regression","83a3af69":"This is an example of imbalanced class problem i.e we where the total number of a class of data (0) is far less than the total number of another class of data (1). Examples include:\n* Fraud detection.\n* Outlier detection.\n","7d15c380":"let's check if there is overlap between the hospitals in the labelled dataset and the hospitals in the unlabelled dataset","c7d68beb":"## This notebook was presented during the WiDS Datathon 2021 Workshop held on 13th Jan,2021. Sharing the notebook here incase others find it useful too.","5d3a7edd":"# Feature Engineering\n\nDepending on your model, your dataset may contain too many features for it to handle.Hence you can eliminate the ones which donot appear very high on the feature importance leaderboard.","39113e04":"Depending upon the percentage of missing values, you can decide to drop the columns which have a very high percentage of missing values and see if that improves the results.Let's drop the empty and single valued columns as well as empty and duplicate rows and visualise the clean dataframe. I'll do it for train but the same needs to be done for the test dataframe as well.","88282fb1":"### split the all-data DF into training and testing again","a93e5208":"The test set is considerably smaller and lacks a TARGET column.","2850761e":"# Exploratory Data Analysis\n\n##  Column Types","4250b566":"## The Target Column","1e82ff27":"### 2. Random Forest","d0ba7f86":"The graph above gives a high-level overview of the missing values in a dataset. It pinpoints which columns and rows to examine in more detail.\n\nTop portion of the plot shows the aggregate for each column. Summary statistics is displayed on the right most side.\n\nBottom portion of the plot shows the missing values (black colors) in the DataFrame.","be3182b5":"We can also visualise the missign values instead of looking at the numbers. ","837671be":"The predictions must be in the format shown in the sample_submission.csv file, where there are only two columns: encounter_id and diabetes_mellitus are present. We will create a dataframe in this format from the test set and the predictions called submit.\n\n","802e6067":"## Preprocessing Data\n\n","6bf6fa54":"Let's first visualise the categorical columns","483ab897":"The training data has 130157 observations and 180 variables including the TARGET (the label we want to predict).","73937167":"### Handling missing values","9607b59a":"# Using cross validation for more robust error measurement\nUsing a Validation dataset has a drawback. Firstly, it decreases the training data and secondly since it is tested against a small amount of data, it has high chances of overfitting. To overcome this, there is a technique called cross validation. The most common form of cross validation, and the one we will be using, is called k-fold cross validation. \u2018Fold\u2019 refers to each different iteration that we train our model on, and \u2018k\u2019 just refers to the number of folds. In the diagram above, we have illustrated k-fold validation where k is 5.\n\n![](https:\/\/scikit-learn.org\/stable\/_images\/grid_search_cross_validation.png)\n\n\nsource: https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html","3c815bfd":"## Some things that you could try to improve performance:\n\n* Check for outliers\n* Efficient Missing value handling\n* Hyperparameter tuning\n\nWhen we do hyperparameter tuning, it's crucial to not tune the hyperparameters on the testing data. We can only use the testing data a single time when we evaluate the final model that has been tuned on the validation data.\n\n* Ensembling\n","3d811717":"## Reciever Operating Characteristics","a8de9b80":"## Missing Values\n\nReal world data is messy and often contains a lot of missing values. There could be multiple reasons for the missing values:\n\n![](https:\/\/imgur.com\/68u0dD2.png)\n\nResource: [A Guide to Handling Missing values in Python](https:\/\/www.kaggle.com\/parulpandey\/a-guide-to-handling-missing-values-in-python)","94fefa21":"## Correlation Plot\n\n","2daf8ed1":"### Encoding Categorical Variables\n\nResource: https:\/\/www.analyticsvidhya.com\/blog\/2020\/08\/types-of-categorical-data-encoding\/","0714fec8":"## Cross-Validation for Imbalanced Classification\nA better way of splitting data would be to split it in such a way that maintains the same class distribution in each subset.we can use a version of k-fold cross-validation that preserves the imbalanced class distribution in each fold. It is called stratified k-fold cross-validation and will enforce the class distribution in each split of the data to match the distribution in the complete training dataset.\n\nLogistic regression is used for modelling. The data set is split using Stratified Kfold. In each split model is created and predicted using that model. The final predicted value is average of all model."}}