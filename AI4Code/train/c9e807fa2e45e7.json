{"cell_type":{"0a626b8f":"code","a5bc7066":"code","a57466ba":"code","e1305eb2":"code","021a837e":"code","aa402074":"code","6d3a0e5a":"code","aa381692":"code","878a43e0":"code","b92c245c":"code","8a7e6f72":"code","1dd1a272":"code","9d5ecb23":"code","f6cfdcb5":"code","5eeffc61":"code","26b28d37":"code","e2f25f3e":"code","cca633db":"code","cc469b9d":"code","416319a1":"code","287d8acc":"code","97e05e3b":"code","b5267eda":"code","6fa67a3d":"code","ed1fc801":"code","fe78f694":"code","4ec74629":"code","72b34eaf":"code","e9ed2ad1":"code","5a732ea6":"code","6e42230b":"code","27f63d5c":"code","d883d1fc":"code","2a051c29":"markdown","624b621b":"markdown","ca07c10f":"markdown","d66b6a8d":"markdown","44a991c5":"markdown","0d6631be":"markdown","342eba9d":"markdown","964416ed":"markdown","c69ad2d5":"markdown","c52c8f24":"markdown","7ac14950":"markdown","16460e13":"markdown","cf3ad7da":"markdown","5062f621":"markdown","42391ce5":"markdown","f253a439":"markdown","01105664":"markdown","9c57d7ce":"markdown","9b29fd3c":"markdown","e2625311":"markdown","9aefe344":"markdown","ad14cee8":"markdown"},"source":{"0a626b8f":"import os\nfrom os import listdir\nfrom os.path import isfile, join\nimport gc\nimport random\nfrom collections import defaultdict\n\nimport pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nimport sklearn.preprocessing as sk_p\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.mixture import GaussianMixture\n#!pip install wikipedia\n#import wikipedia as wp\n\n#sort out the month number-> month name association\nmonth = {'1':'January',\n        '2':'February',\n        '3':'March',\n        '4':'April',\n        '5':'May',\n        '6':'June',\n        '7':'July',\n        '8':'August',\n        '9':'September',\n        '10':'October',\n        '11':'November',\n        '12':'December'\n        }\n\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n\n\n# \n# Parent categories\n# LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations\n# Extract categories\ndef encapsulate_split_primary_essential_function(products):\n    \"\"\"Transform Primary Essential Function\n    input: dataframe products\n    output: function to apply on dataframe, set of tokens\n    \"\"\"\n    cat=[q.split(\"\/\")  for c in products[\"Primary Essential Function\"].unique() for q in c.split(\" - \")]\n\n    token_primary_essential_function=set()\n    [token_primary_essential_function.update(c) for c in cat]\n    #print(token_primary_essential_function)\n    def test_a(x,s):\n        #lambda x: True if s in q.split(\"\/\") else False   for q in c\n        \n        for first_split in x[\"Primary Essential Function\"].split(\" - \"):\n            if type(first_split)==str:\n                if first_split==s:\n                    return True\n            else:\n                for q in first_split:\n                    second_split=q.split(\"\/\")\n                    if type(second_split)==str:\n                        if second_split==s:\n                            return True\n                    else:\n                        if s in second_split:\n                            return True\n                        \n            \n        return False\n\n    return test_a,token_primary_essential_function\n\n\ndef load_df_month(index):\n    \"\"\"Load Dataframe per month\n    \"\"\"\n    df=pd.read_parquet('\/kaggle\/working\/base_month_{}.parquet'.format(index))\\\n        .fillna(-1)\\\n        .set_index(\"time\").astype({\n            \"URL\":int,\n            \"locale\":int,\n            \"state\":int,\n            \"Product Name\":int,  \n            \"Provider\/Company Name\":int,  \n            \"Sector(s)\":int, \n            \"Primary Essential Function\":int,\n        })\n    df[\"month\"]=index\n    \n    return df\n\n\ndef create_synthetic_product(row):\n    \"\"\"\n    define a function who substitute collapse URL product name and so on into a syntetic feature product.\n    \"\"\"\n    product=-1 #unknown\n    if row[\"URL\"]!=-1:\n        return row[\"URL\"]\n    if row[\"Product Name\"]!=-1:\n        return row[\"Product Name\"]\n    if row[\"Provider\/Company Name\"]!=-1:\n        return row[\"Provider\/Company Name\"]\n    if row[\"Primary Essential Function\"]!=-1:\n        return row[\"Primary Essential Function\"]\n    \n    return product\n","a5bc7066":"districts=pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\").dropna(subset=[\"district_id\"])\n#the ranaming is useful to have them sorted in right way.\ndistricts=districts.replace({\n    \"[4000, 6000[\":\"[04000, 6000[\",\n    \"[6000, 8000[\":\"[06000, 8000[\",\n    \"[8000, 10000[\":\"[08000, 10000[\",\n})\n\ndistricts_columns_to_categorize=[\n                      \"pct_black\/hispanic\",\"pct_free\/reduced\",\"county_connections_ratio\",\n                      \"pp_total_raw\",\"state\",\"locale\"\n]\n\n\ndistricts=districts.fillna(\"nan\")\ndistricts_cat=sk_p.OrdinalEncoder()\ndistricts_cat.fit(districts[districts_columns_to_categorize])\ndistricts[districts_columns_to_categorize]=districts_cat.transform(\n                                                            districts[districts_columns_to_categorize]\n                                                        ).astype(np.int8)\n\n\nind=0\nprint(\"districts categories\")\nfor c in districts_cat.categories_:\n    print(\"{}:{}\".format(ind,c))\n    ind=ind+1","a57466ba":"products=pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\").dropna(subset=[\"LP ID\"])\nproducts=products.fillna(\"nan\")\n#transform sectors in booleans\nproducts[\"PreK-12\"]=products.apply(lambda x: True if \"PreK-12\" in x[\"Sector(s)\"].split(\"; \") else False,axis=1)\nproducts[\"Higher Ed\"]=products.apply(lambda x: True if \"Higher Ed\" in x[\"Sector(s)\"].split(\"; \") else False,axis=1)\nproducts[\"Corporate\"]=products.apply(lambda x: True if \"Corporate\" in x[\"Sector(s)\"].split(\"; \") else False,axis=1)\nproducts[\"Unknown-Sector\"]=products.apply(lambda x: True if x[\"Sector(s)\"]==\"nan\" else False,axis=1)\nproducts[\"Provider\/Company Name\"]=products.apply(lambda x: x[\"Provider\/Company Name\"] if \"|\" not in x[\"Provider\/Company Name\"] else x[\"Provider\/Company Name\"].replace(\"|\",\"<br>\"),axis=1)\n\n\n\nlambded_split_primary_essential_function,token_primary_essential_function=encapsulate_split_primary_essential_function(products)\n\nfor s in token_primary_essential_function:\n    products[s]=products.apply(lambded_split_primary_essential_function,args=(s,),axis=1)\n\nproducts=products.rename({\n                    \"nan\":\"unknown-Primary-function\"\n                    },axis=1).replace({\n                            True:1,\n                            False:0\n                        })\n    \nproducts_columns_to_categorize=[  \"URL\",\"Primary Essential Function\",\n                                  \"Sector(s)\",\"Provider\/Company Name\",\n                                  \"Product Name\"]\n\n\nprint(\"matrix sparsity coefficient:{}\\n\".format(((products!=0).count().sum()-(products==0).values.sum())\/(products!=0).count().sum()))\nprint(\"count nan values in the matrix {}\\n\\n\".format(products[products==\"nan\"].count().sum()))\nproducts_cat=sk_p.OrdinalEncoder()\nproducts_cat.fit(products[products_columns_to_categorize])\nproducts[products_columns_to_categorize]=products_cat.transform(\n                                                            products[products_columns_to_categorize]\n                                                        ).astype(np.int16)\n\n\nbic_results=[]\nfor n_components in range(1,45):\n    \n    products_clusters=GaussianMixture(n_components).fit(products[products_columns_to_categorize])\n    bic=products_clusters.bic(products[products_columns_to_categorize])\n    aic=products_clusters.aic(products[products_columns_to_categorize])\n    print(\"mixture {} --- BIC:{} --- AIC:{}\\n\".format(n_components,bic,aic),\n         #   products_clusters.means_\n         )\n    bic_results.append({\n        \"bic\":bic,\n        \"aic\":aic,\n        \"model\":n_components\n    })\n    components=products_clusters.predict(products[products_columns_to_categorize])\n    #print(components)\n\n\nprint( sorted(bic_results, key=lambda x: float(x[\"bic\"])))","e1305eb2":"#product.info()\nproducts.sum()","021a837e":"# load all the engagement files, the district id is the filename, so, trim the extension and add as column\n\n\nkaggle_directory=\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\"\nonlyfiles = [f for f in listdir(kaggle_directory) if isfile(join(kaggle_directory, f))]\n\nlist_of_districts=[]\nfor i in onlyfiles:\n    d1=pd.read_csv(join(kaggle_directory,i))\n    d1[\"district_id\"]=int(i.split(\".\")[0])\n    list_of_districts.append(d1)\n\nengagement=pd.concat(list_of_districts,axis=0).dropna(subset=[\"lp_id\"])\nengagement[\"time\"]=pd.to_datetime(engagement[\"time\"])\nengagement=engagement.set_index(\"time\")\nengagement[\"month\"]=engagement.index.month\nengagement=engagement.astype({\n    \"lp_id\":int\n}).reset_index()\n\n#engagement.info()","aa402074":"for index, block in engagement.groupby(\"month\"):\n    if os.path.exists('\/kaggle\/working\/base_month_{}.parquet'.format(index))==False:\n        gc.collect()\n        temp=block.copy()\n        base=pd.merge(temp,products,how=\"left\",left_on=\"lp_id\",right_on=\"LP ID\").drop(\"LP ID\",axis=1)\n        base=pd.merge(base,districts,how=\"left\",left_on=\"district_id\",right_on=\"district_id\")\n        base[\"month\"]=index\n        base.to_parquet('\/kaggle\/working\/base_month_{}.parquet'.format(index))\n    ","6d3a0e5a":"for i in range(len(products_cat.categories_)):\n    print(i)\n    print(products_cat.categories_[i][:5],products_cat.categories_[i][-5:])\n","aa381692":"res=[]\nfor index in range(1,13):\n    df=load_df_month(index)\n    df=df[[\"pct_black\/hispanic\",\"pct_free\/reduced\",\"county_connections_ratio\",\"pp_total_raw\"]]\n    res.append(df)\n\nresult=pd.concat(res,axis=0)\nresult[(result[\"pct_black\/hispanic\"]!=5)&(\n        result[\"pct_free\/reduced\"]!=5)&(\n        result[\"county_connections_ratio\"]!=2)&(\n        result[\"pp_total_raw\"]!=11)][[\"pct_black\/hispanic\",\n                                         \"pct_free\/reduced\",\n                                         \"county_connections_ratio\",\n                                          \"pp_total_raw\"]].corr()","878a43e0":"\n\n\nres=[]\nfor index in range(1,13):\n    df=load_df_month(index)\n    df=df[[\"engagement_index\",\"month\",\"Product Name\",\"locale\"]]\n    res.append(df)\n\nresult=pd.concat(res,axis=0)\n\nfig=go.Figure()\nfor index,g in result[result[\"engagement_index\"]>np.mean(result[\"engagement_index\"].dropna().values)].groupby(\"locale\"):\n    target_district=districts[districts[\"locale\"]==index]\n    #print(target_district[\"state\"].values[0])\n    t=g[[\"month\",\"Product Name\"]].drop_duplicates().groupby(\"month\").agg(\"count\").reset_index()\n    fig.add_trace(go.Bar(x=[ month[str(i)] for i in t[\"month\"].values],\n                         y=t[\"Product Name\"].values,\n                         marker={\n                                 \"color\":index\n                             },\n                         name=districts_cat.categories_[-1][target_district[\"locale\"].values[0]]\n                         ),\n                  \n                 )\nfig.update_layout(#showlegend=False,\n                  title=\"FIG.1: diversity of tools with high engagement per month\",\n                  yaxis_title=\"number of tools\",)\nfig.show()","b92c245c":"fig=go.Figure()\ntars2={\"locale\":[],\"tools abandoned\":[],\"tools stable\":[]}\nfor index,g in result[result[\"engagement_index\"]>np.mean(result[\"engagement_index\"].dropna().values)].groupby(\"locale\"):\n    target_district=districts[districts[\"locale\"]==index]\n    \n    #remove the common products on each month\n    t=g[[\"month\",\"Product Name\"]].drop_duplicates().reset_index().drop(\"time\",axis=1)#.groupby(\"month\").agg(\"count\").reset_index()\n    # check products that have been abandoned during the year\n    abandoned=0\n    stable=0\n    for i,r in t.groupby(\"Product Name\"):\n        if len(r[r[\"month\"]<7])>0 and len(r[r[\"month\"]>7])==0:\n            abandoned=abandoned+1\n        if len(r[r[\"month\"]<7])>0 and len(r[r[\"month\"]>7])>0:\n            stable=stable+1\n            \n    tars2[\"locale\"].append(districts_cat.categories_[-1][target_district[\"locale\"].values[0]])\n    tars2[\"tools abandoned\"].append(abandoned)\n    tars2[\"tools stable\"].append(stable)\n    \n\nfig.add_trace(go.Bar(x=tars2[\"locale\"], y=tars2[\"tools abandoned\"], name=\"tools abandoned\"))\nfig.add_trace(go.Bar(x=tars2[\"locale\"], y=tars2[\"tools stable\"], name=\"tools stable\"))\nfig.update_layout(#showlegend=False,\n                  title=\"FIG.1.1: Tools stable and abandoned per locale\",\n                  yaxis_title=\"number of tools\",)\nfig.show()","8a7e6f72":"#black array(['[0, 0.2[', '[0.2, 0.4[', '[0.4, 0.6[', '[0.6, 0.8[', '[0.8, 1[','nan'], dtype=object)\n#free array(['[0, 0.2[', '[0.2, 0.4[', '[0.4, 0.6[', '[0.6, 0.8[', '[0.8, 1[','nan'], dtype=object)\n#connection array(['[0.18, 1[', '[1, 2[', 'nan']\n#total array(['[04000, 6000[', '[06000, 8000[', '[08000, 10000[',\n#       '[10000, 12000[', '[12000, 14000[', '[14000, 16000[',\n#       '[16000, 18000[', '[18000, 20000[', '[20000, 22000[',\n#       '[22000, 24000[', '[32000, 34000[', 'nan'], dtype=object)\n#locale array(['City', 'Rural', 'Suburb', 'Town', 'nan'], dtype=object)\n#state array(['Arizona', 'California', 'Connecticut', 'District Of Columbia',\n#       'Florida', 'Illinois', 'Indiana', 'Massachusetts', 'Michigan',\n#       'Minnesota', 'Missouri', 'New Hampshire', 'New Jersey', 'New York',\n#       'North Carolina', 'North Dakota', 'Ohio', 'Tennessee', 'Texas',\n#       'Utah', 'Virginia', 'Washington', 'Wisconsin', 'nan'], dtype=object)\n\nres_df_1=[]\nres_df_2=[]\nres_df_3=[]\nres_df_4=[]\n\nfor index in range(1,13):\n    df=load_df_month(index)\n    val1=df[[\"pct_black\/hispanic\",\"URL\"]].groupby([\"pct_black\/hispanic\"]).agg(\"count\").reset_index()\n    val2=df[[\"pct_free\/reduced\",\"URL\"]].groupby([\"pct_free\/reduced\"]).agg(\"count\").reset_index()\n    val3=df[[\"county_connections_ratio\",\"URL\"]].groupby([\"county_connections_ratio\"]).agg(\"count\").reset_index()\n    val4=df[[\"pp_total_raw\",\"URL\"]].groupby([\"pp_total_raw\"]).agg(\"count\").reset_index()\n    \n    \n    val1[\"month\"]=month[str(index)]\n    val2[\"month\"]=month[str(index)]\n    val3[\"month\"]=month[str(index)]\n    val4[\"month\"]=month[str(index)]\n    #pct_free\/reduced\n    #county_connections_ratio\n    #pp_total_raw\n    # x axis is the black\n    # y is minority\n    res_df_1.append(val1)\n    res_df_2.append(val2)\n    res_df_3.append(val3)\n    res_df_4.append(val4)\n\nres1=pd.concat(res_df_1,axis=0).set_index(\"pct_black\/hispanic\")\nres2=pd.concat(res_df_2,axis=0).set_index(\"pct_free\/reduced\")\nres3=pd.concat(res_df_3,axis=0).set_index(\"county_connections_ratio\")\nres4=pd.concat(res_df_4,axis=0).set_index(\"pp_total_raw\")\n#i would like to see how the differential between months changed per category\n#print(res1)\n#print(res2)\n#print(res3)\n#print(res4)\nresa=res1.reset_index()#.set_index([\"month\",\"pct_black\/hispanic\"])\nresb=res2.reset_index()#.set_index([\"month\",\"pct_free\/reduced\"])\nresc=res3.reset_index()#.set_index([\"month\",\"county_connections_ratio\"])\nresd=res4.reset_index()#.set_index([\"month\",\"pp_total_raw\"])\nc_res=[\"pct_black\/hispanic\",\"pct_free\/reduced\",\"county_connections_ratio\",\"pp_total_raw\"]\nc_names={\"pct_black\/hispanic\": \"Percentage of black\/hispanic\",\n         \"pct_free\/reduced\": \"Percentage of free\/reduced meals\",\n         \"county_connections_ratio\": \"County connections ratio\",\n         \"pp_total_raw\": \"Per pupil total expenditure\"}\nres=[resa,resb,resc,resd]","1dd1a272":"\n\nfor r in range(len(res)):\n    fig=go.Figure()\n    for i in res[r][c_res[r]].unique():\n        fig.add_trace(go.Scatter(x=res[r][res[r][c_res[r]]==i][\"month\"].values,\n                                 y=res[r][res[r][c_res[r]]==i][\"URL\"].values,name=\"{}\".format(\n                                     districts_cat.categories_[r][i]\n                                     )))\n\n    fig.update_layout(title=\"FIG.{}: {}\".format(4+r, c_names[c_res[r]]),\n                      yaxis_title=\"number of samples\",)\n    \n    fig.show()","9d5ecb23":"fig=go.Figure()\nfig.add_trace(\n    go.Bar(\n        x=res1[\"month\"].values,\n        y=res1[\"URL\"].values,\n        hovertext=[\"{}\".format(districts_cat.categories_[0][i%len(districts_cat.categories_[0])]) for i in range(len(res1[\"URL\"].values))],\n        name = \"black\/hispanic\"\n    )\n)\nfig.add_trace(\n    go.Bar(\n        x=res2[\"month\"].values,\n        y=res2[\"URL\"].values,\n        hovertext=[\"{}\".format(districts_cat.categories_[1][i%len(districts_cat.categories_[1])]) for i in range(len(res2[\"URL\"].values))],\n        name = \"free\/reduced\"\n    )\n)\nfig.add_trace(\n    go.Bar(\n        x=res3[\"month\"].values,\n        y=res3[\"URL\"].values,\n        hovertext=[\"{}\".format(districts_cat.categories_[2][i%len(districts_cat.categories_[2])]) for i in range(len(res3[\"URL\"].values))],\n        name = \"county_connections_ratio\"\n    )\n)\nfig.add_trace(\n    go.Bar(\n        x=res4[\"month\"].values,\n        y=res4[\"URL\"].values,\n        hovertext=[\"{}\".format(districts_cat.categories_[3][i%len(districts_cat.categories_[3])]) for i in range(len(res4[\"URL\"].values))],\n        name = \"pp_total_raw\"\n    )\n)\nfig.update_layout(title=\"FIG.8: Number of samples per feature category\",\n                      yaxis_title=\"number of samples per feature category\",)\nfig.show()","f6cfdcb5":"res=[]\nfor index in range(1,13):\n    df=load_df_month(index)\n    df[\"black+free\"]=df[\"pct_black\/hispanic\"]*10+df[\"pct_free\/reduced\"]\n    df[\"month\"]=month[str(index)]\n    df=df.drop([\"pct_free\/reduced\",\"county_connections_ratio\"],axis=1)\n    \n    df=df[[\"black+free\",\"month\",\"URL\"]].groupby([\"month\",\"black+free\"]).agg(\"count\").reset_index()\n    df[\"base\"]=np.floor(df[\"black+free\"]\/10)\n    df[\"color\"]=(df[\"black+free\"]-df[\"base\"]*10)\n    res.append(df)\n\nresult=pd.concat(res,axis=0).astype({\n    \"color\":int,\n    \"base\":int\n})\n\ncolor=[\"black\",\"red\",\"green\",\"blue\",\"brown\",\"grey\"]\n\n\n\n\nresult[\"values\"]=1\nfor b in result[\"base\"].unique():\n    for c in result[\"month\"].unique():\n        condition=(result[\"base\"]==b)&(result[\"month\"]==c)\n        s=result[condition][\"URL\"].sum()\n        result.loc[condition,\"values\"]=s\n        \nresult[\"color\"]=result[\"color\"].apply(lambda x: color[int(x)])\n\n#print(result)\nfig=go.Figure()\nfig.add_trace(go.Scatter(\n  x=result[\"month\"].values,\n  y=result[\"black+free\"].values,\n  text=[ \"number:{}<br>black\/hispanic {}<br>free\/reduced {}\".format(result[\"URL\"].values[v],\n                                                                   districts_cat.categories_[0][int(str(result[\"black+free\"].values[v])[0])],\n                                                                   districts_cat.categories_[1][int(str(result[\"black+free\"].values[v])[1])]\n        ) if len(str(result[\"black+free\"].values[v]))==2 else \"number:{}<br>black\/hispanic [0, 0.2[<br>free\/reduced {}\".format(\n                          result[\"URL\"].values[v],\n                          districts_cat.categories_[0][int(result[\"black+free\"].values[v])]) for v in range(len(result[\"URL\"].values))  ],\n  mode=\"markers\",\n  marker={\n         \"size\":result[\"URL\"].values\/result[\"values\"].values*10+5,\n         \"line\":dict(\n                width=0\n                ),\n         \"color\":result[\"color\"].values,\n         \"opacity\":0.5\n     },\n))\nfig.update_layout(title=\"FIG.9: Point distribution per category of the features black\/hispanic and free\/reduced\",\n                      yaxis_title=\"number of samples per feature category\",)\nfig.show()\n","5eeffc61":"\n\n\nres=[]\nfor index in range(1,13):\n    df=load_df_month(index).astype({\n            \"pct_black\/hispanic\":str,\n            \"pct_free\/reduced\":str\n        })\n    df[\"product\"]=df.apply(lambda row: create_synthetic_product(row),axis=1)\n    df[\"black+free\"]=df[\"pct_black\/hispanic\"]+df[\"pct_free\/reduced\"]\n    df[\"month\"]=month[str(index)]\n    #count the number of different products used, no distinction about the engagement \n    target=df[[\"month\",\"black+free\",\"product\"]].drop_duplicates().groupby([\"month\",\"black+free\"]).agg({\n        \"product\":\"count\"\n    }).reset_index()\n    \n    res.append(target)\n    \n    \nresult=pd.concat(res,axis=0)\n\n#print(result)\n\n\n\nfig=go.Figure()\nfor i in result[\"black+free\"].unique():\n    temp=result[result[\"black+free\"]==i]\n    fig.add_trace(go.Scatter(\n      x=temp[\"month\"].values,\n      y=temp[\"product\"].values,\n      mode=\"markers+lines\",\n      name=\"BH{}<br>FR{}\".format(districts_cat.categories_[0][int(i[0])],districts_cat.categories_[1][int(i[1])]\n        ) if len(str(i))==2 else \"BH[0, 0.2[<br>FR{}\".format(districts_cat.categories_[0][int(i)]),\n      text=[ \"number:{}<br>black\/hispanic {}<br>free\/reduced {}\".format(temp[\"product\"].values[v],\n                                                                   districts_cat.categories_[0][int(i[0])],\n                                                                   districts_cat.categories_[1][int(i[1])]\n        ) if len(str(i))==2 else \"number:{}<br>black\/hispanic [0, 0.2[<br>free\/reduced {}\".format(\n                          temp[\"product\"].values[v],\n                          districts_cat.categories_[0][int(i)]) for v in range(len(temp[\"product\"].values))  ],\n    ))\nfig.update_layout(title=\"FIG.10: Diversity of products per category of the features black\/hispanic (BH) and free\/reduced (FR)\",\n                      yaxis_title=\"number of products\",)\nfig.show()","26b28d37":"res=[]\nfor index in range(1,13):\n    df=load_df_month(index).astype({\n            \"pct_black\/hispanic\":str,\n            \"pct_free\/reduced\":str\n        })\n    df[\"product\"]=df.apply(lambda row: create_synthetic_product(row),axis=1)\n    df[\"black+free\"]=df[\"pct_black\/hispanic\"]+df[\"pct_free\/reduced\"]\n    df[\"month\"]=month[str(index)]\n    #filter the products that have engagement greater than the overall average on the month\n    df=df[df[\"engagement_index\"]>np.mean(df[\"engagement_index\"].values)]\n    #count the number of different products used, no distinction about the engagement \n    target=df[[\"month\",\"black+free\",\"product\"]].drop_duplicates().groupby([\"month\",\"black+free\"]).agg({\n        \"product\":\"count\"\n    }).reset_index()\n    \n    res.append(target)\n    \n    \nresult=pd.concat(res,axis=0)\n\n#print(result)\n\n\n\nfig=go.Figure()\nfor i in result[\"black+free\"].unique():\n    temp=result[result[\"black+free\"]==i]\n    fig.add_trace(go.Scatter(\n      x=temp[\"month\"].values,\n      y=temp[\"product\"].values,\n      mode=\"markers+lines\",\n      name=\"BH{}<br>FR{}\".format(districts_cat.categories_[0][int(i[0])],districts_cat.categories_[1][int(i[1])]\n        ) if len(str(i))==2 else \"BH[0, 0.2[<br>FR{}\".format(districts_cat.categories_[0][int(i)]),\n      text=[ \"number:{}<br>black\/hispanic {}<br>free\/reduced {}\".format(temp[\"product\"].values[v],\n                                                                   districts_cat.categories_[0][int(i[0])],\n                                                                   districts_cat.categories_[1][int(i[1])]\n        ) if len(str(i))==2 else \"number:{}<br>black\/hispanic [0, 0.2[<br>free\/reduced {}\".format(\n                          temp[\"product\"].values[v],\n                          districts_cat.categories_[0][int(i)]) for v in range(len(temp[\"product\"].values))  ],\n    ))\nfig.update_layout(title=\"FIG.11: Diversity of products with high engagement per category of the features <br>       black\/hispanic(BH) and free\/reduced(FR)\",\n                      yaxis_title=\"number of products\",)\nfig.show()","e2f25f3e":"res=[]\nfor index in range(1,13):\n    df=load_df_month(index).astype({\n            \"pct_black\/hispanic\":str,\n            \"pct_free\/reduced\":str\n        })\n    #df.apply(lambda x: print(x),axis=1)\n    \n    df[\"black+free\"]=df[\"pct_black\/hispanic\"]+df[\"pct_free\/reduced\"]\n    df[\"month\"]=index #month[str(index)]\n    #filter the products that have engagement greater than the overall average on the month\n    target=df[[\"month\",\"black+free\",\n               \"Provider\/Company Name\",\n               \"Product Name\"]].drop_duplicates().groupby([\"month\",\n                                                          \"black+free\",\n                                                          \"Provider\/Company Name\"]).agg({\n                                                                        \"Product Name\":\"count\"\n                                                                        }).reset_index()\n    #count the number of different products used, no distinction about the engagement \n    res.append(target)\n    \n    \nresult=pd.concat(res,axis=0)","cca633db":"\n\nsliders_dict = {\n    \"active\": 0,\n    \"yanchor\": \"top\",\n    \"xanchor\": \"left\",\n    \"currentvalue\": {\n        \"font\": {\"size\": 20},\n        #\"prefix\": \"Month:\",\n        \"visible\": True,\n        \"xanchor\": \"right\"\n    },\n    \"transition\": {\"duration\": 300, \"easing\": \"cubic-in-out\"},\n    \"pad\": {\"b\": 10, \"t\": 50},\n    \"len\": 0.9,\n    \"x\": 0.1,\n    \"y\": 0,\n    \"steps\": []\n}\n\nframes=[]\n\n\nfor m in result[\"month\"].unique():\n    df_m=result[result[\"month\"]==m].groupby(\"black+free\").agg({\n        \"Product Name\":sum\n    }).reset_index()\n    \n    \n    frames.append({\"data\":go.Heatmap(\n                            x=[districts_cat.categories_[0][int(i[0])] for i in df_m[\"black+free\"].values],\n                            y=[districts_cat.categories_[1][int(i[1])] for i in df_m[\"black+free\"].values],\n                            z=df_m[\"Product Name\"].values, \n                            #text=products_cat.categories_[3][c],\n                            zmin=30,\n                            zmax=380,\n                            opacity=0.3,),\n                   \"name\":month[str(m)]\n                  })\n    sliders_dict[\"steps\"].append({\"args\": [\n                                                [ month[str(m)]],\n                                                {\"frame\": {\"duration\": 300, \"redraw\": True},\n                                                 \"mode\": \"immediate\",\n                                                 \"transition\": {\"duration\": 300}}\n                                            ],\n                                \"label\": month[str(m)],\n                                \"method\": \"animate\"})\n\nfig = go.Figure(\n    data=[frames[0][\"data\"]],\n    layout=go.Layout(#width=1000, height=700,\n                     hovermode=\"closest\",\n                     updatemenus=[dict(type=\"buttons\",\n                                       buttons=[dict(label=\"Play\",\n                                                     method=\"animate\",\n                                                     args=[None])])],\n                     sliders=[sliders_dict]\n                    ),\n    frames=[go.Frame(data=[f[\"data\"]],name=f[\"name\"]) for f in frames]\n)\n\n\n    \nfig.update_layout(title=\"FIG.11.1: Number of products across black\/hispanic and free\/reduced \",\n                  xaxis_title=\"pct_black_hispanic\",\n                  yaxis_title=\"pct_free\/reduced\",\n                  #zaxis_title=\"Product\",\n                  showlegend=True)\nfig.show()","cc469b9d":"res=[]\nfor index in range(1,13):\n    df=load_df_month(index).astype({\n            \"pct_black\/hispanic\":str,\n            \"pct_free\/reduced\":str\n        })\n    \n    df[\"black+free\"]=df[\"pct_black\/hispanic\"]+df[\"pct_free\/reduced\"]\n    df[\"month\"]=month[str(index)]\n    #filter the products that have engagement greater than the overall average on the month\n    target=df[[\"month\",\"black+free\",\n               \"Provider\/Company Name\",\n               \"Product Name\"]].drop_duplicates().groupby([\"month\",\n                                                          \"black+free\",\n                                                          \"Provider\/Company Name\"]).agg({\n                                                                        \"Product Name\":\"count\"\n                                                                        }).reset_index()\n    #count the number of different products used, no distinction about the engagement \n    res.append(target)\n    \n    \nresult=pd.concat(res,axis=0)\n\n\n\ncounter=12\n\nfor i in result[\"black+free\"].unique():\n    temp=result[result[\"black+free\"]==i].set_index(\"month\")\n    #print(temp)\n    #    print(temp[temp[\"Provider\/Company Name\"]==c].index.values)\n    #    print(temp[temp[\"Provider\/Company Name\"]==c][\"Product Name\"].values)\n    fig=go.Figure()\n    for c in temp[\"Provider\/Company Name\"].unique():\n        if np.mean(temp[temp[\"Provider\/Company Name\"]==c][\"Product Name\"].values)>1:\n            fig.add_trace(go.Scatter(\n              x=temp[temp[\"Provider\/Company Name\"]==c].index.values,\n              y=temp[temp[\"Provider\/Company Name\"]==c][\"Product Name\"].values,\n              mode=\"markers+lines\",\n              name=\"{}\".format(products_cat.categories_[3][c]),\n            ))\n    if len(str(i))>1:\n        fig.update_layout(title=\"FIG.{}:  Number of products used of each company<br>       considering only black\/hispanic {} AND free\/reduced {}\".format(counter,\n            districts_cat.categories_[0][int(str(i)[0])],districts_cat.categories_[1][int(str(i)[1])],))\n    else:\n        fig.update_layout(title=\"FIG.{}:  Number of products used of each company<br>       considering only black\/hispanic AND free\/reduced {}\".format(counter,\n            districts_cat.categories_[0][int(i)]))\n    counter=counter+1\n    fig.show()","416319a1":"res=[]\nfor index in range(1,13):\n    df=load_df_month(index)\n    \n    #df[\"black+free\"]=df[\"pct_black\/hispanic\"]*10+df[\"pct_free\/reduced\"]\n    df[\"month\"]=str(index)\n    #filter the products that have engagement greater than the overall average on the month\n    target=df[[\"month\",\"pp_total_raw\",\n               \"Provider\/Company Name\",\n               \"Product Name\"]].drop_duplicates().groupby([\"month\",\n                                                          \"pp_total_raw\",\n                                                          \"Provider\/Company Name\"]).agg({\n                                                                        \"Product Name\":\"count\"\n                                                                        }).reset_index()\n    #count the number of different products used, no distinction about the engagement \n    res.append(target)\n    \n    \nresult=pd.concat(res,axis=0)\ncounter=33\n\nfor i in result[\"pp_total_raw\"].unique():\n    temp=result[result[\"pp_total_raw\"]==i].set_index(\"month\")\n    #print(temp)\n    #    print(temp[temp[\"Provider\/Company Name\"]==c].index.values)\n    #    print(temp[temp[\"Provider\/Company Name\"]==c][\"Product Name\"].values)\n    fig=go.Figure()\n    for c in temp[\"Provider\/Company Name\"].unique():\n        if np.mean(temp[temp[\"Provider\/Company Name\"]==c][\"Product Name\"].values)>1:\n            \n            x=temp[temp[\"Provider\/Company Name\"]==c].index.values.tolist()\n            y=temp[temp[\"Provider\/Company Name\"]==c][\"Product Name\"].values.tolist()\n            if len(x)<12:\n                #figure whos' missing\n                tester=defaultdict(lambda: 0)\n                [tester[k] for k in month]\n                for k in range(len(x)):\n                    tester[x[k]]=y[k]\n                x=[str(k) for k in range(1,13)]\n                y=[tester[str(k)] for k in range(1,13)]\n            x=[month[str(k)] for k in range(1,13)]\n            \n            \n            fig.add_trace(go.Scatter(\n              x=x,\n              y=y,\n              mode=\"markers+lines\",\n              name=\"{}\".format(products_cat.categories_[3][c]),\n            ))\n    fig.update_layout(title=\"FIG.{}: Number of products used for each company<br>       considering only Per Pupil total expenditure class {}\".format(counter,districts_cat.categories_[3][i]))\n    counter=counter+1\n    fig.show()","287d8acc":"res=[]\nfor index in range(1,13):\n    df=load_df_month(index)\n    \n    #df[\"black+free\"]=df[\"pct_black\/hispanic\"]*10+df[\"pct_free\/reduced\"]\n    df[\"month\"]=str(index)\n    #filter the products that have engagement greater than the overall average on the month\n    target=df[[\"month\",\"pp_total_raw\",\n               \"Provider\/Company Name\",\n               \"engagement_index\",\n               \"pct_access\",\n               \"Product Name\"]].drop_duplicates().groupby([\"month\",\n                                                          \"pp_total_raw\",\n                                                          \"Provider\/Company Name\"]).agg({\n                                                                        \"Product Name\":\"count\",\n                                                                        \"pct_access\":\"mean\",\n                                                                        \"engagement_index\":\"mean\",\n                                                                        }).reset_index()\n    #count the number of different products used, no distinction about the engagement \n    res.append(target)\n    \n    \nresult=pd.concat(res,axis=0)\ncounter=45\n\nfor i in result[\"pp_total_raw\"].unique():\n    temp=result[result[\"pp_total_raw\"]==i].set_index(\"month\")\n    #print(temp)\n    #    print(temp[temp[\"Provider\/Company Name\"]==c].index.values)\n    #    print(temp[temp[\"Provider\/Company Name\"]==c][\"Product Name\"].values)\n    fig=go.Figure()\n    for c in temp[\"Provider\/Company Name\"].unique():\n        #filter the companies who provide a percentage of access greater than 2%\n        if np.mean(temp[temp[\"Provider\/Company Name\"]==c][\"pct_access\"].values)>2:\n            fig.add_trace(go.Scatter(\n              x=[month[x] for x in temp[temp[\"Provider\/Company Name\"]==c].index.values],\n              y=temp[temp[\"Provider\/Company Name\"]==c][\"pct_access\"].values,\n              mode=\"markers+lines\",\n              name=\"{}\".format(products_cat.categories_[3][c]),\n            ))\n    fig.update_layout(title=\"FIG.{}: Percentage of access per company<br>       considering only Per Pupil total expenditure class {}\".format(counter,districts_cat.categories_[3][i]))\n    counter=counter+1\n    fig.show()","97e05e3b":"counter=57\nfor i in result[\"pp_total_raw\"].unique():\n    temp=result[result[\"pp_total_raw\"]==i].set_index(\"month\")\n    #print(temp)\n    #    print(temp[temp[\"Provider\/Company Name\"]==c].index.values)\n    #    print(temp[temp[\"Provider\/Company Name\"]==c][\"Product Name\"].values)\n    fig=go.Figure()\n    for c in temp[\"Provider\/Company Name\"].unique():\n        #filter the companies who provide a percentage of engagement greater than 100 \n        if np.mean(temp[temp[\"Provider\/Company Name\"]==c][\"engagement_index\"].values)>100:\n            fig.add_trace(go.Scatter(\n              x=[month[x] for x in temp[temp[\"Provider\/Company Name\"]==c].index.values],\n              y=temp[temp[\"Provider\/Company Name\"]==c][\"engagement_index\"].values,\n              mode=\"markers+lines\",\n              name=\"{}\".format(products_cat.categories_[3][c]),\n            ))\n    fig.update_layout(title=\"FIG.{}:Engagement index per company<br>       considering only Per Pupil total expenditure class {}\".format(counter,districts_cat.categories_[3][i]))\n    counter=counter+1\n    fig.show()","b5267eda":"#print(token_primary_essential_function)\n# LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations\n\n\n\n#for each category list the companies.\nfor col in list(token_primary_essential_function):\n    if col in result.columns:\n        print(\"\\n\\n\",col)\n        print(\"\\n\",[\n            products_cat.categories_[3][int(i)] for i in result[result[col]==1][\"Provider\/Company Name\"].unique()\n        ])","6fa67a3d":"#reduced_base=reduced_base.astype({col:int for col in list(token_primary_essential_function) if col in reduced_base.columns })\n\ndictionary_of_results={}\n\nfor index in range(1,13):\n    df=load_df_month(index).astype({\n            col:int for col in list(token_primary_essential_function) if col in df.columns \n        })\n    df[\"month\"]=str(index)\n    #df[\"black+free\"]=df[\"pct_black\/hispanic\"]*10+df[\"pct_free\/reduced\"]\n    \n    for col in list(token_primary_essential_function):\n        if col in df.columns:\n            if col not in dictionary_of_results:\n                dictionary_of_results[col]=[]\n            \n            result=df[df[col]==1].groupby(\"month\").agg({\n                                                \"pct_access\":\"mean\",\n                                                \"engagement_index\":\"mean\"\n                                            })\n            \n                #print(col)\n            dictionary_of_results[col].append(result)\n\n    \n    \n    \nfor col in dictionary_of_results:\n    dictionary_of_results[col]=pd.concat(dictionary_of_results[col],axis=0)\n","ed1fc801":"def replace_ampersand_with_newline(string):\n    if len(string)>25:\n        return string.replace(\"&\",\"&<br>    \")\n    return string","fe78f694":"fig=go.Figure()\nfor col in dictionary_of_results:\n        \n    fig.add_trace(go.Scatter(x=[month[str(i)] for i in dictionary_of_results[col].index.values],\n                             y=dictionary_of_results[col][\"engagement_index\"].values,\n                             #z=poject[:,2],\n                             mode=\"markers+lines\",\n                             name=replace_ampersand_with_newline(col)\n                            ),\n                 )\nfig.update_layout(title=\"FIG.69: engagement index per Primary Essential Function\")\nfig.show()","4ec74629":"fig=go.Figure()\nfor col in dictionary_of_results:\n        \n    fig.add_trace(go.Scatter(x=[month[str(i)] for i in dictionary_of_results[col].index.values],\n                             y=dictionary_of_results[col][\"pct_access\"].values,\n                             #z=poject[:,2],\n                             mode=\"markers+lines\",\n                             name=replace_ampersand_with_newline(col)\n                            ),\n                 )\nfig.update_layout(title=\"FIG.70: Percentage access per Primary Essential Function\")\nfig.show()","72b34eaf":"\nfig=go.Figure()\nfor col in dictionary_of_results:\n    tmp=dictionary_of_results[col][~dictionary_of_results[col].index.isin([\"6\",\"7\",\"8\"])]\n        \n    fig.add_trace(go.Scatter(x=[month[str(i)] for i in tmp.index.values],\n                             y=tmp[\"pct_access\"].values,\n                             #z=poject[:,2],\n                             mode=\"markers+lines\",\n                             name=replace_ampersand_with_newline(col)\n                            ),\n                 )\nfig.update_layout(title=\"FIG.71: Percentage access per Primary Essential Function\")\nfig.show()\n#get the categories who decreased\nfig=go.Figure()\nfor col in dictionary_of_results:\n    \n    tmp=dictionary_of_results[col][~dictionary_of_results[col].index.isin([\"6\",\"7\",\"8\"])]\n    \n    fig.add_trace(go.Scatter(x=[month[str(i)] for i in tmp.index.values],\n                             y=tmp[\"engagement_index\"].values,\n                             #z=poject[:,2],\n                             mode=\"markers+lines\",\n                             name=replace_ampersand_with_newline(col)\n                            ),\n                 )\nfig.update_layout(title=\"FIG.72: Engagement index per Primary Essential Function\")\nfig.show()","e9ed2ad1":"res=[]\nfor index in range(1,13):\n    df=load_df_month(index)\n    df[\"product\"]=df.apply(lambda row: create_synthetic_product(row),axis=1)\n    df[\"black+free\"]=df[\"pct_black\/hispanic\"]*10+df[\"pct_free\/reduced\"]\n    df[\"month\"]=month[str(index)]\n    #filter the products that have engagement greater than the overall average on the month\n    #df=df[df[\"engagement_index\"]>np.mean(df[\"engagement_index\"].values)]\n    #count the number of different products used, no distinction about the engagement \n    target=df[[\"month\",\"black+free\",\"product\",\"locale\"]].drop_duplicates().groupby([\"month\",\"black+free\",\"locale\"]).agg({\n        \"product\":\"count\"\n    }).reset_index()\n    \n    res.append(target)\n    \n    \nresult=pd.concat(res,axis=0)\n\n#print(result)\n\ncounter=73\nfor j in result[\"locale\"].unique():\n    \n    fig=go.Figure()\n    for i in result[\"black+free\"].unique():\n        temp=result[(result[\"black+free\"]==i)&(result[\"locale\"]==j)]\n        fig.add_trace(go.Scatter(\n          x=temp[\"month\"].values,\n          y=temp[\"product\"].values,\n          mode=\"markers+lines\",\n          name=\"BH{}<br>FR{}\".format(districts_cat.categories_[0][int(str(i)[0])],districts_cat.categories_[1][int(str(i)[1])]\n        ) if len(str(i))==2 else \"BH[0, 0.2[<br>FR{}\".format(districts_cat.categories_[0][int(i)]),\n          text=[ \"number:{}<br>black\/hispanic {}<br>free\/reduced {}\".format(temp[\"product\"].values[v],\n                                                                       districts_cat.categories_[0][int(str(i)[0])],\n                                                                       districts_cat.categories_[1][int(str(i)[1])]\n            ) if len(str(i))==2 else \"number:{}<br>black\/hispanic [0, 0.2[<br>free\/reduced {}\".format(\n                              temp[\"product\"].values[v],\n                              districts_cat.categories_[0][int(i)]) for v in range(len(temp[\"product\"].values))  ],\n        ))\n    fig.update_layout(title=\"FIG.{}: product diversity considering only data from {}\".format(counter,districts_cat.categories_[5][int(j)]))\n    counter=counter+1\n    fig.show()","5a732ea6":"#https:\/\/en.wikipedia.org\/wiki\/List_of_U.S._states_and_territories_by_African-American_population\n\n\ntry:\n    table1=pd.read_html(\"https:\/\/en.wikipedia.org\/wiki\/List_of_U.S._states_and_territories_by_African-American_population\",\n                  attrs={\n                      'class':'sortable wikitable'\n                  })[0].set_index(\"Rank\")\n    print(\"Table.1 - Percentage of African-American per state, census 2019, source wikipedia\\n\\n\")\n    #pd.set_option('display.max_columns', None)\n    #pd.set_option('display.max_rows', None)\n    #print(table)\nexcept:\n    print(\"no table, got at the link directly\")\n\n","6e42230b":"table1","27f63d5c":"res=[]\nfor index in range(1,13):\n    df=load_df_month(index)\n    df[\"product\"]=df.apply(lambda row: create_synthetic_product(row),axis=1)\n    df[\"black+free\"]=df[\"pct_black\/hispanic\"]*10+df[\"pct_free\/reduced\"]\n    df[\"month\"]=month[str(index)]\n    #filter the products that have engagement greater than the overall average on the month\n    #df=df[df[\"engagement_index\"]>np.mean(df[\"engagement_index\"].values)]\n    #count the number of different products used, no distinction about the engagement \n    target=df[[\"month\",\"black+free\",\"product\",\"state\"]].drop_duplicates().groupby([\"month\",\"black+free\",\"state\"]).agg({\n        \"product\":\"count\"\n    }).reset_index()\n    \n    res.append(target)\n    \n    \nresult=pd.concat(res,axis=0)\n\n#print(result)\n\ncounter=78\nfor j in result[\"state\"].unique():\n    \n    fig=go.Figure()\n    for i in result[\"black+free\"].unique():\n        temp=result[(result[\"black+free\"]==i)&(result[\"state\"]==j)]\n        fig.add_trace(go.Scatter(\n          x=temp[\"month\"].values,\n          y=temp[\"product\"].values,\n          mode=\"markers+lines\",\n          name=\"BH{}<br>FR{}\".format(districts_cat.categories_[0][int(str(i)[0])],districts_cat.categories_[1][int(str(i)[1])]\n        ) if len(str(i))==2 else \"BH[0, 0.2[<br>FR{}\".format(districts_cat.categories_[0][int(i)]),\n          text=[ \"number:{}<br>black\/hispanic {}<br>free\/reduced {}\".format(temp[\"product\"].values[v],\n                                                                       districts_cat.categories_[0][int(str(i)[0])],\n                                                                       districts_cat.categories_[1][int(str(i)[1])]\n            ) if len(str(i))==2 else \"number:{}<br>black\/hispanic [0, 0.2[<br>free\/reduced {}\".format(\n                              temp[\"product\"].values[v],\n                              districts_cat.categories_[0][int(i)]) for v in range(len(temp[\"product\"].values))  ],\n        ))\n    fig.update_layout(title=\"FIG.{}: product diversity considering only data from {}\".format(counter,districts_cat.categories_[4][int(j)]))\n    counter=counter+1\n    fig.show()","d883d1fc":"if \"nan\" in token_primary_essential_function:\n    token_primary_essential_function.remove(\"nan\")\n\n\n\nres=[]\n\nfor index in range(1,13):\n    df=load_df_month(index)\n    \n    \n    df[\"month\"]=str(index)\n    #filter the products that have engagement greater than the overall average on the month\n    #df=df[df[\"engagement_index\"]>np.mean(df[\"engagement_index\"].values)]\n    #count the number of different products used, no distinction about the engagement \n    target=df[[\"month\",\"URL\",\"state\"]+list(token_primary_essential_function)].drop_duplicates().groupby([\"month\",\"state\"]+list(token_primary_essential_function)).agg({\n        \"URL\":\"count\"\n    }).reset_index()\n    \n    res.append(target)\n    \n    \nresult=pd.concat(res,axis=0)\n\n#reduced_base=reduced_base.astype({col:int for col in list(token_primary_essential_function) if col in reduced_base.columns })\ncounter=102\n#reduced_base[\"syntetic\"]=reduced_base[\"pct_access\"]\/100*reduced_base[\"engagement_index\"]\nfor state in result[\"state\"].unique():\n    fig=go.Figure()\n    for col in list(token_primary_essential_function):\n\n        if col in result.columns:\n            temp=result[(result[col]==1)&(result[\"state\"]==state)].groupby(\"month\").agg({\n                \"URL\":\"mean\",\n            })\n            x=temp.index.values.tolist()\n            y=temp[\"URL\"].values.tolist()\n            if len(x)<12:\n                #figure whos' missing\n                tester=defaultdict(lambda: 0)\n                [tester[k] for k in month]\n                for k in range(len(x)):\n                    tester[x[k]]=y[k]\n                x=[str(k) for k in range(1,13)]\n                y=[tester[str(k)] for k in range(1,13)]\n            x=[month[str(k)] for k in range(1,13)]\n            fig.add_trace(go.Scatter(x=x,\n                                     y=y,\n                                     mode=\"markers+lines\",\n                                     name=col,\n                                    ),\n                         )\n           \n    fig.update_layout(title=\"FIG.{}: products number per Primary Essential Function on {}\".format(counter,districts_cat.categories_[4][int(state)]))\n    counter=counter+1\n    fig.show()","2a051c29":"FIG.69 and FIG.70 show the mean engagement index and mean percentage per month for each primary essential function. ","624b621b":"Table.1 lists the percentage of black\/hispanic per state, the source is wikipedia (https:\/\/en.wikipedia.org\/wiki\/List_of_U.S._states_and_territories_by_African-American_population). ","ca07c10f":"FIG.11 restricts the sample to the most engaging platforms. \nConsidered the average engagement, the products are filtered having engagement greater than the average.\nThe vertical axis is counting the montly number of different products with an engagement greater than the average,\neach line represents a syntetic combined class, pct_black\/hispanic concatenated pct_free\/reduced.\n\nThe class code is the same, BH is pct of black\/hispanic, FR is pct of free\/reduced,  nan is not categorized.\n\nThe figure shows three groups: \n* a diversity greater than 150: \n  + BH\\[0.0,0.2\\[ FR\\[0.0,0.2\\[ \n  + BH\\[0.2,0.4\\[ FR\\[0.0,0.2\\[ \n  + BH\\[0.2,0.4\\[ FR\\[0.2,0.4\\[ \n  + BH\\[0.4,0.6\\[ FR\\[0.0,0.2\\[ \n  + BH\\[ nan \\[ FR\\[0.0,0.2\\[ \n  + BH\\[ nan \\[ FR\\[ nan \\[ \n- diversity between 60 and 150: \n  + BH\\[0.2,0.4\\[ FR\\[0.4,0.6\\[\n  + BH\\[0.2,0.4\\[ FR\\[ nan \\[ \n  + BH\\[0.4,0.6\\[ FR\\[0.4,0.6\\[\n  + BH\\[0.4,0.6\\[ FR\\[0.6,0.8\\[\n  + BH\\[0.4,0.6\\[ FR\\[ nan \\[  \n  + BH\\[0.6,0.8\\[ FR\\[0.2,0.4\\[\n  + BH\\[0.6,0.8\\[ FR\\[0.4,0.6\\[\n  + BH\\[0.6,0.8\\[ FR\\[0.6,0.8\\[\n  + BH\\[0.8,1.0\\[ FR\\[0.8,1.0\\[\n  + BH\\[0.8,1.0\\[ FR\\[ nan \\[ \n- diversity under 60: \n  + BH\\[0.2,0.4\\[ FR\\[0,0.2\\[\n  + BH\\[0.2,0.4\\[ FR\\[0.6,0.8\\[\n  + BH\\[0.2,0.4\\[ FR\\[0.8,1.0\\[\n  + BH\\[0.4,0.6\\[ FR\\[0.2,0.4\\[\n  + BH\\[0.8,1.0\\[ FR\\[0.6,0.8\\[\n\nIf we consider the diversity of products used a proxy to measure the learning\/teaching potential, the classes most disadvantaged who also lost diversity are:\n- BH[0,0.2[ FR[0.8,1[\n- BH[0.8,1[ FR[0.6,8[\n\nIn March, almost all classes recorded a peak, which is compatible with experimenting solutions, some classes report a decline in diversity during the year. A possible explanation for the reduction in the diversity during the year is the product substitution. More interconnected functionalities are needed to manage a virtual class, make sense that institutions adopted solutions that were solving more problems and abandoned products specialized in one single functionality. \n\n","d66b6a8d":"One question to answer is how the usage of tools evolved during the pandemic. \n\nFIG.12 to FIG.32 show for each company who offer more than one product, how many products have been used each month. \n\nGoogle LCC shows an increased product adoptation in each class examined. Microsoft and Houghton Mifflin Harcourt are the second, with an average of 6 products.\n","44a991c5":"# Summary\n\n\n- The COVID-19 pandemic generated a product substitution, all the locales abandoned more than 30 tools in the second part of the year. One possible cause could be operational efficiency. \n\n- The classes that lost product diversity are:\n-- Black\/Hispanic(BH)[0,0.2[ Free\/Reduced(FR)[0.8,1[\n-- BH[0.8,1[ FR[0.6,8[\n\n- The market is segmented by class of expenditure, some tools are predominant only in some classes.\n\n- BH [0.8,1]  deteriorated its condition centering its distribution on FR[0.8,1].\n\n- Almost all classes peaked the number of tools used in March. A possible hypothesis is that these increases represent the effort spent to prepare for the pandemic, testing new tools, preparing for the possibility of a remote teaching scholastic year\n\n- The classroom virtualization reduced the gap between classes in general, BH[0,0.2[ FR[0.8,1[ did not catch up with the others,  some classes worsened i.e. BH[0.4,0.6[ with FR[nan].\n\n- A disaggregated picture of the product diversity per state, black\/hispanic and free\/reduced classes is produced. The figures highlight a substatial difference of the effects of the pandemy within the minority communities across states. A common and intuitive phenomena between the figures is that deterioration is recorded on FR classes greater than [0,0.2] regardless BH, showing that higher FR has been penalyzed more than other classes during the pandemy. However, in Indiana, Arizona, New York, and California the associated BH was greater than 0.4.\n\n","0d6631be":"Load the engagement files, the district id is the filename, trim the extension and add the id as column\n\nJoin the dataframe products, districs and engagement. \n\nSave the aligned matrix in parquet, having a month in each file. \n\nHelpful to handle the data without having to recompute the join.","342eba9d":"Companies in each primary essential function category ","964416ed":"FIG.1: shows the number of unique product names having engagement greater than the average and grouped by locale. The term 'tools' in this context represents product names, and it is used interchangeably.\n\nOn the horizontal axis are listed the months, whilst the vertical axis represents the number of different tools. The figure highlights the difference in the number of products used in cities, suburban areas, rural areas and towns. The monthly seasonality reflects the scholastic year. The July low is due to the summer break. \n\nThe number of tools used in rural, suburban areas, and non categorized (nan) is higher than the number of tools used in cities or towns.\n\nAlmost all classes peaked the number of tools used in March. A possible hypothesis is that these increases represent the effort spent to prepare for the pandemic, testing new tools, preparing for the possibility of a remote teaching scholastic year. This hypothesis is supported by FIG.1.1, which represents the number of tools used in the first part of the year and abandoned in the second part, and the tools used in both parts. July is the cut-off month between first and second part. \n\nFIG.1.1 shows that effort was made in all locales. All the locales abandoned a number of tools between 30 and 40, whilst towns abandoned 57 products. One possible cause could be efficiency and product substitution. \n\n\n\n","c69ad2d5":"FIG.71 and FIG.72 reproduce respectively FIG.69 and FIG.70 removing the seasonal drop of June, July and August. The scope is to better capture the Primary Essential Functions that increased\/decreased during the pandemy.\n\n\nThe year shows an increased adoption of technology. Learning management systems, SSO and School management software record an high usage. Categories on increasing adoption are Video Conferencing & Screen sharing, Assessment and Classroom response, Virtual Classroom, online courses, SDO, streaming services, and Content Creation & curation. \n\nDeclining categories are Mobile Device Management.\n\nThe picture is compatible with the virtualization of the learning process happened during the year and by all the agent of the system: from the side of the schools, teachers (virtual classroom, videoconferencing, and so on) and from the side of the students (the sharp increase of the online courses).  ","c52c8f24":"FIG.9 investigates the distribution of points in the classes black\/hispanic(BH), free\/reduced (FR), and counts the number of points - samples (NS). A syntetic feature is created, BH * 10 + FR, to easily sort along the vertical axis all the available combinations, in other words, the point at (January,11) shows the number of samples with BH\\[0.2, 0.4[ and FR[0.2, 0.4[ recorded in January. \n\n\nThe minimum size of the markers is 3, it increases to represent the distribution of samples across the available FR, the baseline is the sum across FR on the considered BH.\n\nTo be noted that nan means not categorized.\n\nIf the sampling is reppresentative of the population, then approximatively the relative distribution between categories did not change considerably during the year (however, the absolute values changed). \n\nSome points that can be draft from this image are:\n- BH=0 (\\[0, 0.2[) has FR below or equal to [0.4, 0.6[. The numbers in each subsequent FR halves on a very coarse approximation.\n- the percentage of black\/hispanic is correlated with the percentage of free\/reduced. If the dataset is representative of the underlying population, the data shows that communities with higher concetration of BH will also have higher concentration of FR, having the median into the same category of percentage (BH[0.2,0.4[ FR[0.2,0.4[, BH[0.4,0.6[ FR[0.4,0.6[, BH[0.6,0.8[ FR[0.6,0.8[, BH[0.8,1[ FR[0.8,1[).\n- From April, the class BH[0.8,1[ registered a worsening in the distribution of FR (centering the distribution on BH[0.8,1[ FR[0.8,1[ from the previous BH[0.8,1[ FR[0.6,0.8[).","7ac14950":"The focus now shifts toward the engagement. \n\nFIG.10 shows the evolution over time of the diversity of products for each of the combined classes.","16460e13":"FIG.73 to FIG.77 show the the product diversity for the combined classes pct_black\/hispanic and pct_free\/reduced filtering only the data within a locale. The objective is to highlight the differences between living in an urban or rural district as example.\n\n","cf3ad7da":"The challenge is based on three datasets: products, engagement and districts. \nThe products dataset contains one combined feature, \"Primary Essential Function\", that can be further decomposed in multiple binary features with the following process: tokenize \"Primary Essential Function\", each token becomes a binary feature which mark if the product has the feature. Decomposing enables the aggregation of products by common features.\n\nThe district \n\n\nfirst step is to load the data, remove the nan district_id since I can't match them with the other tables.\n\nThe second step is to categorize the data to reduce RAM usage.\n\nLoad products, split sector and primary essential function. Check the number of row for each feature.","5062f621":"FIG.78 to FIG.101 show a disaggregated picture of the product diversity per state, black\/hispanic and free\/reduced classes. The figures highlight a substatial difference of the effects of the pandemy within the minority communities across states.  In Table.1 we list the states by percentage of black\/hispanic people resident, the data is downloaded from wikipedia which refers the 2019 census. We will refer the percentage of african\/american in the population of a state with the achronim PAA.\n\nIn the following description we will use BH for pct of black\/hispanic, FR for pct of free\/reduced, and NOP for number of products. We use the NOP as proxy to measure the relative offering of a learning system, and we compare the change of NOP across the year between BH and FR combinations in each state. \n\n\nFIG.78 (California, PAA 7\\%) shows a sharp drop in the NOP used between October and November, the fall affected only BH\\[0.6,0.8] FR\\[0.4,0.6] and BH[0.2,0.4] FR[0.2,0.4], while the other classes remained stable. \n\nFIG.79 (Connecticut, PAA 13.2\\%) shows the least NOP along the year is on BH[0,0.2] and FR[0.4,0.6], while all other classes follow a close pattern. \n\nFIG.80 (Illinois, PAA 15.4\\%) has a similar behaviour of FIG.79 having the lowest NOP on BH[0,0.2] and FR[0.8,0.1].  \n\nFIG.84 (Ohio, PAA 14.4\\%) has only data from June to August. During the summer break, only BH[0.4,0.6] FR[nan] and BH[0.2,0.4] FR[0.2,0.4] shows a sharp drop in NOP. \n\nFIG.85 (Utah, PAA 1.9\\%), shows that the least NOP is on BH[0.2,0.4] FR[0.4,0.6], moreover it is also the only category that recorded a drop in NOP during summer break. \n\nFIG.86 (Washington, PAA 5.6\\%) shows probably a issue in the sampling method BH[0,0.2] FR[0.2,0.4] with BH[0,0.2] FR[0,0.2] display a suspicius pattern. The first dropped from over 300 to less then 60 in April and continued in this range unil end of year, while the second started the year with a NOP around 23 to raise to over 300 by October. The other classes are stable around 300. \nFIG.87 (Wisconsin, PAA 7.5\\%) shows a similar pattern of FIG.86 with BH[0,0.2] FR[0.2,0.4]. Similar problems can be found in FIG.98 (Minnesota, PAA 8.1\\%) and FIG.97 (Texas, PAA 13.5\\%). In Texas there are only two classes, BH[0.6,0.8] FR[0.4,0.6] improved and BH[0.4,0.6] FR[0.4,0.6] worsened their NOP.\n\nFIG.88 (New Hampshire, PAA 2.2\\%) has only data for BH[0,0.2] FR[0.8,1] and shows a drop during summer break. The summer break drop is recorded also in FIG.94 (North Carolina, PAA 23.1\\%) only for the class BH[0.4,0.6] FR[0.6,0.8], while in FIG.96 (Michigan, PAA 15.3\\%) is common in all the classes.\n\nFIG.89 (New York, PAA 17.6\\%) has the lowest NOP on BH[0.8,1] FR[0.8,1], the pattern along the year is similar to the other classes. A similar figure is FIG.90 (Virginia, PAA 23.3\\%) which shows the minimum NOP on BH[0,0.2] FR[0.2,0.4].\n\nFIG.91 (Indiana, PAA 11\\%) shows BH[0.8,1] FR[0.6,0.8] the only class to have substantially deteriorated NOP during the year. A similar comment can be applied for FIG.100 (Arizona, PAA 6\\%) and the class BH[0.8,1] FR[nan].\n\nFIG.93 (Tennessee, PAA 18\\%) shows a deterioration of NOP for the class BH[0.2,0.4] FR[nan], the timeseries has data until August.\n\nFIG.99 (District of Columbia, PAA 47.2\\%) shows the least NOP in BH[0.4,0.6] which improved in the second part of the year without catching BH[0.8,1].\n\n\nA common and intuitive phenomena between the figures is that deterioration is recorded on FR classes greater than [0,0.2] regardless BH, showing that higher FR has been penalyzed more than other classes during the pandemy. However, in Indiana, Arizona, New York, and California the associated BH was greater than 0.4.\n\nFIG.99 is counterintuitive because in a state with PAA of about 50\\% the class with BH [0.4, 0.6] has a lower NOP than BH [0.8,1]. A possible hypothesis could be that homogeneous districts have more political weight than mixed districts. \n\n\n\n\n\n\n\n\n\n","42391ce5":"Fig.11.1 shows an heatmap of how the number of products used in each combination of classes changed through the year. Since the color scale is fixed, similar color is similar number: the figure highlights the gap between the least and the most. It is particularly interesting the initial gap between  BH\\[0,0.2\\[ FR[0.8,1\\[ and the rest of the classes (please have a look at February), despite having improved it did not catch up with the others. \n\nAnother insteresting point is that some classes worsened during the year, i.e. BH\\[0.4,0.6\\[ with FR\\[nan\\]. ","f253a439":"FIG.8 summarizes the pandemy evolution by number of samples. The lines in each bar represents the ending of the class (or category). The sum for each class in each bar is the sum of the samples for the month. The number of samples is compatible with the pandemy evolution and the schoolastic year. \n\nTo be noted how the online usage increased significantly in the second part of the year (starting the new schoolastic year). This result is compatible with the pandemy adaptation.","01105664":"Calculate the correlation matrix including percentage of black\/hispanic, pct free\/reduced, county_connections_ratio and per pupil total expenditure for the sampled dataset. The mapping for the categories preserves the underlying meaning after removing the 'nan' category: lower category number implies lower percentage and conversely high number implies high percentage.\n\nThe dataset shows positive correlation between pct_black\/hispanic and pct_free\/reduced.\n\n","9c57d7ce":"FIG.33 to FIG.44 show how many products have been used in each month, Each figure represents a class of expenditure per pupil.  Since March, Google registered an increase of products persistent through the year in almost all the classes of expenditure.","9b29fd3c":"FIG.57 to FIG.68 compare companies toward the engagement index, the companies with engagement value lower than 100 are filtered out. Each figure shows only one per pupil total expenditure class. It is interesting a comparison of the engagement index registered in the first half of the year with the values in second half: Schoology, Instructure, Google show a substantial increase in second half, while kahoot! shows a loss in almost all classes.\n\n","e2625311":"FIG.102 to FIG.125 show the product number per state. The figures show the similarity in the number of products used per state across the year. \n\nAn outlier with an unique pattern is Arizona (FIG.102), where the peak of usage of digital learning platform happened during the summer break. \n\nMinnesota (FIG.111) and North Dakota (FIG.117) probably have an issue in the data sampling, because after few months there is no data available. \n\nThe District of Columbia (FIG.105), New Hampshire (FIG.113), New Jersey (FIG.114), Michigan (FIG.110) and New York(FIG.115) show a common drop in the number of the digital learning platform close to October, which may be the effect of the covid-19 policy response. As example, Michigan allowed the schools to open in-person in September, and later moved again on virtual learning in November (https:\/\/en.wikipedia.org\/wiki\/COVID-19_pandemic_in_Michigan). \n\nTexas (FIG.120) has a low in July compatible with the summer break. ","9aefe344":"FIG.4, FIG.5, FIG.6, FIG.7 show the montly samples available in each category of percentage of black\/hispanic (BH), percentage of free\/reduced (FR), county connections ratio (CC), and per pupil total expendidure (PP). \n\n\n\n","ad14cee8":"FIG.45 to FIG.56 show the percentage of access per company for each month having a value greater than 2%. Each figure isolates a class of expenditure per pupil. \n\nThe sequence shows the variability of the offer across capacity of expenditure. We recall an hypothesis formulated from Fig.11, which will be useful for the investigation \n> A possible explanation for the reduction in the diversity during the year is the product substitution. More interconnected functionalities are needed to manage a virtual class, make sense that institutions adopted solutions that were solving more problems and abandoned products specialized in one single functionality. A possible explanation for the reduction in the diversity during the year is the product substitution. More interconnected functionalities are needed to manage a virtual class, make sense that institutions adopted solutions that were solving more problems and abandoned products specialized in one single functionality.\n\nIn almost all classes Cleaver shows a loss of percentage of access against other companies, as example:\nFig.45 focus on \\[4000,6000[ and shows a substitution of Cleaver and Imagine Learning by Instructure and Curriculum Associates.\nFig.46 focus on \\[6000,8000[ shows a substitution of Cleaver and Curriculum Associates toward Instructure and School loop.\nFig 47 focus on \\[8000,1000[ shows a gain oof Schoology and Instructure against Cleaver and Curriculum Associates.\n\nThese figures show how the instruction market adapted during the year. Some companies that gained market share are Schoology, Instructure, Curriculum Associates, Classlink, Zoom, while others appear to have lost market, i.e. Cleaver, CoolMath.com, Mind research, and so on. The hypothesis of product substitution appears to have some credit. \n\nIt is also interesting how some companies are present with a significant share only in some classes, i.e. Seesaw Learning, Google, Ed Puzzle, Blindside Networks (Fig.53 to Fig.55), whilst in some classes there are clear winners on the second part of the year:  Fig.50, Fig.51 Schoology; Fig.53 Classlink and Schoology.\n\n\n "}}