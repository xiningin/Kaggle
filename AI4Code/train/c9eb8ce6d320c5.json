{"cell_type":{"e7e5cf83":"code","b0583cc4":"code","6330685f":"code","218d9e64":"code","fc7b5339":"code","1d70a486":"code","9f3d9d28":"code","ad41a669":"code","5aa2e3f4":"code","ed30ef56":"code","5f2b6aa8":"code","a407dfa6":"code","e7cf3610":"code","e9e549e2":"markdown","22dde0b5":"markdown","d9eb0454":"markdown","98cd50b7":"markdown","454e1668":"markdown","244ca4a8":"markdown","84dbe0b5":"markdown","90329ada":"markdown","49153543":"markdown"},"source":{"e7e5cf83":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report, mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n","b0583cc4":"def load_csv(dataset, datadir):\n    \"\"\"Load covid19-week1 kaggle data sets\"\"\"\n    df = pd.read_csv(\n        f\"{datadir}\/{dataset}.csv\",\n        dtype={\"Country\/Region\": \"category\"},\n        parse_dates=[\"Date\"],\n    )\n    df[\"DayOfYear\"] = df[\"Date\"].dt.dayofyear\n    df[\"Province\/State\"].fillna(df[\"Country\/Region\"], inplace=True)\n    return df\n\n\ndef sigmoid(x, x0, L, k):\n    return L \/ (1 + np.exp(-k * (x - x0)))\n\n\ndef fit(df: pd.DataFrame, index: str, channel: str):\n    x = df[index].values\n    y = df[channel].values\n    try:\n        p, pc = curve_fit(\n            sigmoid,\n            x,\n            y,\n            p0=(np.median(x), y[-1], 0.1),\n            maxfev=100000,\n            bounds=([0, y[-1], 0], [np.inf, np.inf, 2]),\n            ftol=1e-5,\n        )\n    except RuntimeError:\n        return [-1] * 9\n    return list(p) + pc[np.triu_indices_from(pc)].tolist()\n\n\ndef apply_fit(df: pd.DataFrame, index: str, channel: str) -> pd.DataFrame:\n    \"\"\"Apply fit to channel\"\"\"\n    fits = df.groupby([\"Country\/Region\", \"Province\/State\"])[\n        [index, channel]\n    ].apply(lambda x: fit(x, index=index, channel=channel))\n    return pd.DataFrame(\n        fits.tolist(),\n        columns=[\"x0\", \"L\", \"k\", \"sx0\", \"sx0L\", \"sx0k\", \"sL\", \"sLk\", \"sk\"],\n        index=fits.index,\n    ).add_suffix(f\"_{channel}\")\n\n\ndef prep_pop(filename: str) -> pd.DataFrame:\n    \"\"\"Prepare population summary data.\n\n    Dataset: SYB62_1_201907_Population, Surface Area and Density.csv\n\n    Index: country\n    Columns:\n        - young%: percent young 0-14 years old\n        - old%: percent 60+ years old\n        - density: people\/area\n        - population: people\n        - fem%: percent females of total\n    \"\"\"\n    df = pd.read_csv(\n        filename,\n        engine=\"python\",\n        skiprows=901,\n        index_col=0,\n        names=(\n            \"idx\",\n            \"country\",\n            \"Year\",\n            \"Series\",\n            \"Value\",\n            \"Footnotes\",\n            \"Source\",\n        ),\n        usecols=[\"country\", \"Year\", \"Series\", \"Value\"],\n    )\n    pivot = (\n        df[df[\"Year\"] == 2019]\n        .pivot(columns=\"Series\", values=\"Value\")\n        .dropna()\n        .rename(\n            columns={\n                \"Population aged 0 to 14 years old (percentage)\": \"young%\",\n                \"Population aged 60+ years old (percentage)\": \"old%\",\n                \"Population density\": \"density\",\n                \"Population mid-year estimates (millions)\": \"population\",\n                \"Population mid-year estimates for females (millions)\": \"fem\",\n                \"Population mid-year estimates for males (millions)\": \"male\",\n                \"Sex ratio (males per 100 females)\": \"ratio\",\n            }\n        )\n    )\n    pivot[\"fem%\"] = pivot[\"fem\"] * 100.0 \/ pivot[\"population\"]\n    return pivot.drop(columns=[\"fem\", \"male\", \"ratio\"])\n\n\ndef prep_hh(filename: str) -> pd.DataFrame:\n    \"\"\"Household statistics.\n\n    Dataset:\n        population_division_UN_Houseshold_Size_and_Composition_2019.csv\n\n    Index: country\n    Columns:\n        - avg_hh: average household size\n        - hh%1: percentage single housholds\n        - hh%2-3: percentage 2-3 person housholds\n        - hh%4-5: percentage 4-5 person housholds\n        - hh%6+: percentage 6+ person housholds\n        - hh65+: percentage housholds with 65+ yearolds\n    \"\"\"\n    return (\n        pd.read_csv(\n            filename,\n            usecols=[0, 3, 4, 5, 6, 7, 8, 18],\n            names=[\n                \"country\",\n                \"date\",\n                \"avg_hh\",\n                \"hh%1\",\n                \"hh%2-3\",\n                \"hh%4-5\",\n                \"hh%6+\",\n                \"hh65+\",\n            ],\n            na_values=\"..\",\n            header=0,\n            parse_dates=[\"date\"],\n        )\n        .sort_values(by=[\"country\", \"date\"])\n        .groupby(\"country\")\n        .tail(1)\n        .drop(columns=[\"date\"])\n        .set_index(\"country\")\n    )\n\n\ndef predict(df):\n    df[\"y_ConfirmedCases\"] = (\n        (\n            df[\"L_ConfirmedCases\"]\n            \/ (\n                1\n                + np.exp(\n                    -df[\"k_ConfirmedCases\"]\n                    * (df[\"DayOfYear\"] - df[\"x0_ConfirmedCases\"])\n                )\n            )\n        )\n        .round()\n        .astype(int)\n    )\n    df[\"y_Fatalities\"] = (\n        (\n            df[\"L_Fatalities\"]\n            \/ (\n                1\n                + np.exp(\n                    -df[\"k_Fatalities\"]\n                    * (df[\"DayOfYear\"] - df[\"x0_Fatalities\"])\n                )\n            )\n        )\n        .round()\n        .astype(int)\n    )\n    return df\n\n\ndef merge_support_main(main_df, supp_df):\n    return pd.merge(\n        main_df,\n        supp_df,\n        left_on=\"Country\/Region\",\n        right_on=\"country\",\n        how=\"left\",\n    )\n\n\ndef augment_dataset(DATADIR=\"data\/\"):\n    # Load kaggle data\n    train = load_csv(\"train\", DATADIR)\n    test = load_csv(\"test\", DATADIR)\n\n    # Make fits\n    fits_cc = apply_fit(train, index=\"DayOfYear\", channel=\"ConfirmedCases\")\n    fits_f = apply_fit(train, index=\"DayOfYear\", channel=\"Fatalities\")\n    fits = fits_cc.join(fits_f)\n\n    # Insert fits\n    train = pd.merge(\n        train, fits.reset_index(), on=[\"Country\/Region\", \"Province\/State\"]\n    )\n    test = pd.merge(\n        test, fits.reset_index(), on=[\"Country\/Region\", \"Province\/State\"]\n    )\n\n    # Augment dataset\n    ## Supports\n    sf = pd.read_csv(f\"{DATADIR}\/supporting_features.csv\", index_col=0).drop(\n        columns=[\"avg_HH\"]\n    )\n    sf.index.name = \"country\"\n    train = merge_support_main(train, sf)\n    test = merge_support_main(test, sf)\n\n    ## Housholds\n    hh = prep_hh(\n        f\"{DATADIR}\/population_division_UN_Houseshold_Size_and_Composition_2019.csv\"\n    )\n    train = pd.merge(\n        train, hh, left_on=\"Country\/Region\", right_on=\"country\", how=\"left\"\n    )\n    test = pd.merge(\n        test, hh, left_on=\"Country\/Region\", right_on=\"country\", how=\"left\"\n    )\n    ## Population size\n    pop = prep_pop(\n        f\"{DATADIR}\/SYB62_1_201907_Population, Surface Area and Density.csv\"\n    )\n    train = pd.merge(\n        train, pop, left_on=\"Country\/Region\", right_on=\"country\", how=\"left\"\n    )\n    test = pd.merge(\n        test, pop, left_on=\"Country\/Region\", right_on=\"country\", how=\"left\"\n    )\n\n    # Include fit predictions\n    train = predict(train)\n    test = predict(test)\n    return train, test","6330685f":"## See appendix on details on augmented data\ntrain = pd.read_csv(\"\/kaggle\/input\/covid19aug\/augmented\/train_aug.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/covid19aug\/augmented\/test_aug.csv\")","218d9e64":"def plotfit(df, country, channel, ax, c=\"b\"):\n    df_sel = df[\n        (df[\"Country\/Region\"] == country) & (df[\"Province\/State\"] == country)\n    ]\n    x = df_sel[\"DayOfYear\"].values\n    y = df_sel[channel].values\n    s = df_sel[f'y_{channel}']\n    (x0, L, k) = df_sel[\n        [f\"x0_{channel}\", f\"L_{channel}\", f\"k_{channel}\"]\n    ].values[0]\n    s = sigmoid(x, x0, L, k)\n    ax.plot(x, y, f\"{c}o\", mfc=\"none\", alpha=0.5)\n    ax.plot(x, s, f\"{c}-\")\n    ax.text(\n        0.2,\n        0.8,\n        f\"$x_0$={x0:.2f}\\nL={L:.2f}\\nk={k:.2f}\",\n        transform=ax.transAxes,\n        verticalalignment=\"top\",\n    )\n    ax.set_title(country)\n    ax.set_ylabel(channel)\n\nsel = (\"Italy\", \"Austria\", \"Germany\", \"Netherlands\")\nfig, ax = plt.subplots(4, 2, sharex=True, figsize=(10,8))\nfor i, country in enumerate(sel):\n    plotfit(train, country, \"ConfirmedCases\", ax[i, 0], c=\"g\")\n    plotfit(train, country, \"Fatalities\", ax[i, 1], c=\"r\")\n    ","fc7b5339":"def prepare_data(df: pd.DataFrame):\n    df = df[df['ConfirmedCases'] > 100].reset_index()\n    df['days_since_first100cases'] = df.groupby(['Province\/State', 'Country\/Region']\n                                                )['ConfirmedCases'].transform(lambda x: range(len(x)))\n    return df.drop(['x0_ConfirmedCases', 'L_ConfirmedCases', 'k_ConfirmedCases', 'sx0_ConfirmedCases',\n                    'sx0L_ConfirmedCases', 'sx0k_ConfirmedCases', 'sL_ConfirmedCases',\n                    'sLk_ConfirmedCases', 'sk_ConfirmedCases', 'x0_Fatalities',\n                    'L_Fatalities', 'k_Fatalities', 'sx0_Fatalities', 'sx0L_Fatalities',\n                    'sx0k_Fatalities', 'sL_Fatalities', 'sLk_Fatalities', 'sk_Fatalities',\n                    'DayOfYear', 'index', 'Id', 'Date'], axis=1)\n\n\ndef impute_values(df: pd.DataFrame):\n    features = ['life_expectancy_years', 'literacy_rates', 'veg_supply_person_kg_year',\n                'respiratory_infections_death', 'deaths_from_smoking%', 'young%',\n                'old%', 'density', 'population', 'fem%', 'number_doc_per1000',\n                'surgeons_act_working', 'obstetricians_act_working',\n                'anaesthesiologists_act_working', 'avg_hh', 'hh%1', 'hh%2-3', 'hh%4-5',\n                'hh%6+', 'hh65+']\n    df_per_country = df.groupby(\n        ['Province\/State', 'Country\/Region'], as_index=False).min()\n    df_per_country = df_per_country[[\n        'Province\/State', 'Country\/Region']+features].replace(0, np.nan)\n    # drop colunms with many nulls\n    column_null = df_per_country.isnull().mean()\n    column_null_drop = list(column_null[column_null > 0.5].index)\n    df_per_country_clean = df_per_country.drop(\n        column_null_drop, axis=1).fillna(df_per_country.median())\n    return df.drop(features, axis=1).merge(df_per_country_clean,\n                                           on=['Province\/State', 'Country\/Region'], how='left')","1d70a486":"def model(df, ylab):\n    features = df.drop(['Country\/Region','Province\/State',\n                    'ConfirmedCases', 'Fatalities', 'Long', 'y_Fatalities', 'y_ConfirmedCases'\n                    ], axis=1)\n    label = df[ylab]\n    train_df, test_df, train_label, test_label = train_test_split(\n        features, label, test_size=0.2)\n    model = XGBClassifier(objective='reg:linear')\n    model.fit(train_df, train_label)\n    test_pred = model.predict(test_df)\n    return model, np.sqrt(mean_squared_error(test_label, test_pred))","9f3d9d28":"df = impute_values(prepare_data(train))\ndf.head(3)","ad41a669":"corr = df.drop(['Country\/Region', 'Province\/State'], axis=1).corr()\nfig, ax = plt.subplots(figsize=(12,8))\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=45,\n    horizontalalignment='right'\n);","5aa2e3f4":"xgb_cases, rmse_cases= model(df,'y_ConfirmedCases')","ed30ef56":"print(\"ConfirmedCases: Importance by Weight\")\nplot_importance(xgb_cases,max_num_features=20, importance_type='gain', show_values=False)\nplt.show()","5f2b6aa8":"xgb_fatalities, rmse_fatalities = model(df,'y_Fatalities')","a407dfa6":"print(\"Fatalities:  Importance by Weight\")\nplot_importance(xgb_fatalities, max_num_features=20, importance_type='gain', show_values=False)\nplt.show()","e7cf3610":"prediction = predict(test)[[\"ForecastId\", \"y_ConfirmedCases\", \"y_Fatalities\"]]\nprediction.columns = [\"ForecastId\",\"ConfirmedCases\",\"Fatalities\"]\nprediction.head()\nprediction.to_csv('submission.csv', index=False)","e9e549e2":"# Make submission","22dde0b5":"## Plot correlation","d9eb0454":"## Confirmed cases","98cd50b7":"# Explain logistic function parameters with XGBoost\n","454e1668":"## Growth fit\n\nThe main idea of this notebook is to try to explain what contributes to the growth.\nWe model the growth as a Logistic funtions as follows (see predict and apply_fit in augmentation part):\n\n$$f(x) = \\frac{L}{1 + e^{-k(x-x_0)}}+y_0$$\n- $e$: the natural logarithm base (also known as Euler's number),\n- $x_0$:  the $x$-value of the sigmoid's midpoint,\n- $y_0$: base line level\n- $L$ the curve's maximum value,\n- $k$ = the logistic growth rate or steepness of the curve.[1]\n\n### Fit sanity check\nDraw fit as line, and datapoints as points, see that things look non-crazy.","244ca4a8":"## Fatalities","84dbe0b5":"## Data augmentation\nThis inserts data on household size, and population from UN public data, and inserts a sigmoid fit to fatalities and confirmed cases. It also inserts some other supporting features documented above.\n\nNOTE: This step has already been executed ahead of time, code is here for sake of completeness.","90329ada":"# Load augmented data","49153543":"In addition to train data following external data is used per country\n\n* `days_since_first100cases`     Days since first 100 ConfirmedCases\n* `y_Fatalities`      Sigmoid function estimation for Fatalities\n* `y_ConfirmedCases`      Sigmoid function estimation for ConfirmedCases\n* `life_expectancy_years`      life expectancy in years\n* `veg_supply_person_kg_year`       vegetable supply per person per year in kg\n* `respiratory_infections_death%`      % of respiratory infections death people in population\n* `deaths_from_smoking%`        % of deaths from smoking in population\n* `young%`      % of young people in population\n* `old%`        % of old people in population\n* `population`  total population\n* `fem%`        % of female in population\n* `number_doc_per1000`    number of medical doctors per 1000 \n* `hh%1`        % of 1 person household in population\n* `hh%2-3`      % of 2_3 person household in population\n* `hh%4-5`      % of 4-5 person household in population\n* `hh%6+`       % of 6+ person household in population"}}