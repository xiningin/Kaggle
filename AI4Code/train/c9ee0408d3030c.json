{"cell_type":{"50d787c3":"code","79317dc1":"code","09c6dfcc":"code","9c5b6cb7":"code","35a78884":"code","e5c14e73":"code","0c3a74fd":"code","2e58b7f0":"code","d4d12976":"code","107aa817":"code","b9f6e619":"code","308c45ad":"code","b533b6fa":"code","2b77bfc2":"code","0520b08b":"code","26f9041f":"code","48d2838c":"code","3f51a151":"code","f4242207":"code","584bb2ab":"code","86371a7d":"code","7e53cc16":"code","e98be708":"code","dddc4a19":"code","746252de":"code","e120d48c":"code","7b61e5f9":"code","2b13145f":"code","73e7f4fa":"code","ba144487":"code","0f1717c3":"code","d6065aa8":"code","477c758a":"code","22565f26":"markdown","67f2822b":"markdown","fc9dc3c7":"markdown","cf84132d":"markdown"},"source":{"50d787c3":"!pip install klib","79317dc1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#klib is a Python library for importing, cleaning, analyzing and preprocessing data. \nimport klib","09c6dfcc":"df = pd.read_csv('..\/input\/beyond-analysis\/train.csv')","9c5b6cb7":"test = pd.read_csv('..\/input\/beyond-analysis\/test.csv')","35a78884":"df.head()","e5c14e73":"test.head()","0c3a74fd":"df.info()","2e58b7f0":"df=klib.convert_datatypes(df)","d4d12976":"df.info()","107aa817":"klib.corr_plot(df,figsize=(20,18))","b9f6e619":"df_try = df.copy()","308c45ad":"df_try = df_try[['UNIQUE_IDENTIFIER', 'SEQUENCE_NO', 'STATUS_CHECK',\n         'REVENUE','ACTIVE_YN',\n       'WINNINGS_2', 'DEPOSIT',\n       'WITHDRAW', 'DEPOSIT_TRAILS', 'ENTRY_NUMBER','Y1', 'Y2']]","b533b6fa":"df_try = df_try.groupby(by='UNIQUE_IDENTIFIER').median()","2b77bfc2":"df_try.describe()","0520b08b":"X = df_try.iloc[:,0:-2]\ny = df_try.iloc[:,-2:]","26f9041f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test=train_test_split(X, y.values, test_size=0.2,random_state=42,shuffle=True)","48d2838c":"X_train.shape","3f51a151":"y_train.shape","f4242207":"# importing the libraries\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.regularizers import l1_l2,l1","584bb2ab":"model = Sequential()\nmodel.add(Dense(units=64, input_dim=9, activation='relu',activity_regularizer=l1(0.001)))\nmodel.add(Dense(units=32, activation='relu',activity_regularizer=l1(0.001)))\n#model.add(Dense(units=16, activation='relu',kernel_initializer='normal'))\nmodel.add(Dense(2,kernel_initializer='normal'))\nmodel.compile(loss='mean_squared_error', optimizer='adam')","86371a7d":"history = model.fit(X_train, y_train ,batch_size = 132, epochs = 150, validation_data=(X_test,y_test),verbose=1)","7e53cc16":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom math import sqrt\npred = model.predict(X_test)\nprint(sqrt(mean_squared_error(y_test,pred)) )\nprint(r2_score(y_test,pred))","e98be708":"import matplotlib.pyplot as plt\nloss     = history.history[    'loss' ]\nval_loss = history.history['val_loss' ]\nepochs   = range(len(loss))\nplt.figure()\nplt.plot  ( epochs,     loss )\nplt.plot  ( epochs, val_loss )\nplt.title ('Training and validation loss'   )","dddc4a19":"import seaborn as sns\nsns.regplot(y_test[:,0],pred[:,0],ci=None)\nplt.xlabel(\"Test\")\nplt.ylabel(\"Prediction\")","746252de":"test=klib.convert_datatypes(test)\ntest['cat_1'] = test['CATEGORY_1'].cat.codes\ntest['cat_2'] = test['CATEGORY_2'].cat.codes","e120d48c":"test_X = test[['UNIQUE_IDENTIFIER', 'SEQUENCE_NO', 'STATUS_CHECK',\n         'REVENUE','ACTIVE_YN',\n       'WINNINGS_2', 'DEPOSIT',\n       'WITHDRAW', 'DEPOSIT_TRAILS', 'ENTRY_NUMBER']]","7b61e5f9":"test_X = test_X.groupby(by='UNIQUE_IDENTIFIER').median()","2b13145f":"pred = model.predict(test_X.values)","73e7f4fa":"test_final = pd.DataFrame(pred,columns=['Y1','Y2'])","ba144487":"test_final['UNIQUE_IDENTIFIER'] = test_X.index","0f1717c3":"test_final = test_final[['UNIQUE_IDENTIFIER','Y1','Y2']]","d6065aa8":"test_final","477c758a":"test_final.to_csv('submit.csv',index=False)","22565f26":"# Test data","67f2822b":"# **Build Model**","fc9dc3c7":"**Problem Statement**\n* Estimating customer value and extrapolating the existing value into future are the sought-after problems of any business.\n* The current problem hails from the domain of online skill-based gaming.\n* The problem is to estimate the customer values based on the features collected from different timestamps of sequences and also to predict the duration that for how much time the customer was generating revenue.\n\n**Dataset Description**\n* Provided feature space contains 22 variables spanning across multiple aspects of customer behavior.\n* Temporal variation is captured by a numbered sequence of entries for each customer.\n* The goal is to predict Y1 & Y2 which represent customer value and temporal extrapolation respectively.\n* Each customer can have N sequenced entries as input and only one set of (Y1, Y2) is expected as output.","cf84132d":"# **Split Data**"}}