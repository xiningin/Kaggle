{"cell_type":{"2e776d82":"code","51031982":"code","31fdf00f":"code","898b3c0d":"code","8f39b616":"code","5ffc4dcd":"code","205d097d":"code","f4d09717":"code","894b6547":"code","9e184374":"code","bc6877f6":"code","798a0c51":"code","22fb601f":"code","cc05d8b5":"code","3766e9e8":"code","6c924729":"code","ce8b889f":"code","fe764c22":"code","d3edfabb":"code","dd8f55ec":"code","9c7f2cb3":"code","144a6de7":"code","494029e4":"code","082ef2eb":"code","902cc5d7":"code","4972ef01":"code","ec8af8ff":"code","5d73da7d":"code","7602e943":"code","4d0d132a":"code","ccd6c095":"markdown","28776f08":"markdown"},"source":{"2e776d82":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom  tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\npath='\/kaggle\/input\/face-mask-dataset\/data'\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\nBATCH_SIZE = 32\ninit_epochs=10\nfine_tuning_epochs=8\nIMG_SIZE = (224, 224)\nbase_learning_rate=0.0001\noutput_path='\/kaggle\/working\/'\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51031982":"train_dataset = image_dataset_from_directory(path,\n                                             shuffle=True,\n                                             subset='training',\n                                             seed=1,\n                                             validation_split=0.2,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE)","31fdf00f":"validation_dataset = image_dataset_from_directory(path,\n                                             shuffle=True,\n                                             subset='validation',\n                                             seed=1,\n                                             validation_split=0.2,\n                                             batch_size=BATCH_SIZE,\n                                             image_size=IMG_SIZE)","898b3c0d":"class_names = train_dataset.class_names\n\nplt.figure(figsize=(10, 10))\n# \u4ecetrain_dataset\u91cc\u9762\u62ff\u4e00\u4e2abatch size\u6570\u91cf\u7684\u56fe\u7247\u548c\u6b63\u89e3\u6807\u7b7e\nfor images, labels in train_dataset.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","8f39b616":"val_batches = tf.data.experimental.cardinality(validation_dataset)\n# \u9a8c\u8bc1\u96c6\u4e2d\u4e00\u5171\u670932\u4e2a\u6279\u6b21\u7684batch\u6570\u636e\uff08\u4e00\u4e2abatch\u91cc\u9762\u670932\u5f20\u56fe\u7247\uff09\uff0c32\u4e2a\u6279\u6b21\u5206\u621026\u548c6\uff0c2\u4e2a\u90e8\u5206\uff08\u9a8c\u8bc1\u548c\u6d4b\u8bd5\uff09\ntest_dataset = validation_dataset.take(val_batches\/\/5)\nvalidation_dataset = validation_dataset.skip(val_batches\/\/5)","5ffc4dcd":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\nvalidation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\ntest_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)","205d097d":"len(train_dataset),len(validation_dataset),len(test_dataset)","f4d09717":"data_augmentation=tf.keras.Sequential([\n#     \u6c34\u5e73 \u5782\u76f4 \u7ffb\u8f6c\n    tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n#     \u65cb\u8f6c\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n#     \u7f29\u653e\n    tf.keras.layers.experimental.preprocessing.RandomZoom(.5, .2),\n    #     \u56fe\u7247\u4e0a\u4e0bshift20%\uff0c\u5de6\u53f3shift20%\n    tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n#     \u72ec\u7acb\u7684\u8c03\u6574\u6bcf\u4e2a\u56fe\u7247\u6bcf\u4e2a\u901a\u9053\u7684\u5bf9\u6bd4\u5ea6\n    tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1),\n])","894b6547":"image, label = next(iter(validation_dataset))\nlen(image)","9e184374":"plt.figure(figsize=(3,3))\nplt.imshow(image[0].numpy().astype('uint8'))\nplt.title(\"original image\")\nplt.axis(\"off\")\nplt.show()\nplt.figure(figsize=(10,10))\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    data_aug_image=data_augmentation(tf.expand_dims(image[0],0))\n    plt.imshow(data_aug_image[0]\/255.0)\n    plt.title(\"augumentation image\")\n    plt.axis(\"off\")\nplt.show()","bc6877f6":"image_shape=IMG_SIZE+(3,)\nbase_model=tf.keras.applications.EfficientNetB0(input_shape=image_shape,\n                                    include_top=False,\n                                    weights='imagenet',\n                                    drop_connect_rate=0.4)","798a0c51":"base_model.trainable=False","22fb601f":"model=tf.keras.Sequential()\nmodel.add(base_model)\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())\nmodel.add(tf.keras.layers.Dense(1))","cc05d8b5":"model.summary()","3766e9e8":"input=tf.keras.Input(image_shape)\nx=data_augmentation(input)\nx=base_model(x,training=False)\nx=tf.keras.layers.GlobalAveragePooling2D()(x)\nx=tf.keras.layers.Dropout(0.2)(x)\nx=tf.keras.layers.BatchNormalization()(x)\noutput=tf.keras.layers.Dense(1)(x)\nmodel=tf.keras.Model(input,output)","6c924729":"model.summary()","ce8b889f":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","fe764c22":"len(train_dataset),len(validation_dataset),len(test_dataset)","d3edfabb":"history=model.fit(train_dataset,\n          epochs=init_epochs,\n          validation_data=validation_dataset\n         )","dd8f55ec":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,0.2])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","9c7f2cb3":"base_model.trainable = True","144a6de7":"print(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 100\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable=False\n    ","494029e4":"model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate\/10),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","082ef2eb":"fine_tuning_history=model.fit(train_dataset,\n          epochs=fine_tuning_epochs,\n          validation_data=validation_dataset\n         )","902cc5d7":"acc = fine_tuning_history.history['accuracy']\nval_acc = fine_tuning_history.history['val_accuracy']\n\nloss = fine_tuning_history.history['loss']\nval_loss = fine_tuning_history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,0.2])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","4972ef01":"pred=model.evaluate(test_dataset)","ec8af8ff":"image,label=next(iter(test_dataset))\nlen(image)","5d73da7d":"plt.figure(figsize=(15,15))\n# \u8bbe\u5b9a\u7a7a\u767d\u5904 \u95f4\u9694\u5927\u5c0f\nplt.subplots_adjust(wspace=0.1, hspace=0.1)\nfor i in range(32):\n    plt.subplot(4,8,i+1)\n    pred=model.predict(tf.expand_dims(image[i],0))\n    predictions = tf.nn.sigmoid(pred)\n    predictions = tf.where(predictions < 0.5, 0, 1)\n    plt.imshow(image[i].numpy().astype('uint8'))\n    plt.title(class_names[predictions[0][0]])\n    plt.axis(\"off\")\n    plt.suptitle(\"Face Mask Detection\")\nplt.show()","7602e943":"import pickle\ndef pickle_dump(obj, path):\n    with open(path, mode='wb') as f:\n        pickle.dump(obj, f)\n\n\npickle_dump(fine_tuning_history.history,\n            os.path.join('fine_tuning_history.pickle'))\n\nmodel.save(\"face_mask_detection.h5\")\n","4d0d132a":"del model\nmodel=load_model(os.path.join(output_path,\"face_mask_detection.h5\"))","ccd6c095":"### Fine Tuning for model","28776f08":"### Load Model"}}