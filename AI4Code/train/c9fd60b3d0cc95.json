{"cell_type":{"97b53456":"code","5a4e38a5":"code","40fda7f5":"code","ebe3390b":"code","2f2116ef":"code","1b684f1c":"code","ba013a50":"code","9d0fc34c":"code","bffe521d":"code","4c708158":"code","d0bfee83":"code","58b630dc":"code","47107502":"code","7dc66d1e":"code","dedd4904":"markdown","a3e7c633":"markdown","25065bba":"markdown","594c8c4d":"markdown","c13b8130":"markdown","71fbcc82":"markdown","c8232cdb":"markdown"},"source":{"97b53456":"import pandas as pd\nimport numpy as np\nimport random\nimport time\nimport sys\nimport os\nimport gc\n\nimport cudf\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport xgboost as xgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tqdm.notebook import tqdm\n\nimport warnings\nwarnings.simplefilter('ignore')","5a4e38a5":"DEBUG = True\nEXTRA_DATA = False\n\nN_SPLITS = 5\nN_ESTIMATORS = 20000\nEARLY_STOPPING_ROUNDS = 200\nVERBOSE = 1000\nSEED = 42","40fda7f5":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \nseed_everything(SEED)","ebe3390b":"train = cudf.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\ntest = cudf.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\ntrain = train.iloc[:, 1:]\ntest = test.iloc[:, 1:]\n\nif DEBUG:\n    train = train.sample(frac=0.4, random_state=SEED)\n    \nTARGET = 'target'","2f2116ef":"features = [col for col in train.columns if 'f' in col]\n\ncont_features =[]\ndisc_features =[]\n\nfor col in features:\n    if train[col].dtype=='float64':\n        cont_features.append(col)\n    else:\n        disc_features.append(col)","1b684f1c":"train['bin_count'] = train[disc_features].sum(axis=1)\ntest['bin_count'] = test[disc_features].sum(axis=1)\n\ndisc_features += ['bin_count']","ba013a50":"train[cont_features] = train[cont_features].astype('float32')\ntrain[disc_features] = train[disc_features].astype('uint8')\ntest[cont_features] = test[cont_features].astype('float32')\ntest[disc_features] = test[disc_features].astype('uint8')","9d0fc34c":"train = train.to_pandas()\ntest = test.to_pandas()\n\nfeatures = disc_features + cont_features","bffe521d":"display(train.info())\ndisplay(train[features].head())","4c708158":"display(test.info())\ndisplay(test[features].head())","d0bfee83":"xgb_params = {\n    'objective': 'binary:logistic',\n    'learning_rate': 8e-3,\n    'seed': SEED,\n    'subsample': 0.6,\n    'colsample_bytree': 0.4,\n    'n_estimators': N_ESTIMATORS,\n    'max_depth': 8,\n    'alpha': 10,\n    'lambda': 1e-1,\n    'min_child_weight': 256,\n    'importance_type': 'gain',\n    'tree_method': 'gpu_hist',\n    'predictor': 'gpu_predictor',\n}","58b630dc":"N_EXTRADATA = 5\n\nif not EXTRA_DATA:\n    xgb_oof = np.zeros(train.shape[0])\nxgb_pred = np.zeros(test.shape[0])\nxgb_importances = pd.DataFrame()\n\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(X=train, y=train[TARGET])):\n    print(f\"===== fold {fold} =====\")\n    X_train, y_train = train[features].iloc[trn_idx], train[TARGET].iloc[trn_idx]\n    X_valid, y_valid = train[features].iloc[val_idx], train[TARGET].iloc[val_idx]\n    X_test = test[features]\n    \n    if EXTRA_DATA:\n        oof_idx = fold*len(val_idx)*N_EXTRADATA\n\n        X_train_row_length = X_train.shape[0]\n        X_valid_row_length = X_valid.shape[0]\n        ex_X_train = []\n        ex_y_train = []\n        ex_X_valid = []\n        ex_y_valid = []\n        for _ in range(N_EXTRADATA):\n            ex_X_train.append(X_train)\n            ex_y_train.append(y_train)\n            ex_X_valid.append(X_valid)\n            ex_y_valid.append(y_valid)\n        X_train = pd.concat(ex_X_train).reset_index(drop=True)\n        y_train = pd.concat(ex_y_train).reset_index(drop=True)\n        X_valid = pd.concat(ex_X_valid).reset_index(drop=True)\n        y_valid = pd.concat(ex_y_valid).reset_index(drop=True)\n\n        for i in tqdm(range(N_EXTRADATA-1)):\n            X_train_multiplier = np.random.normal(loc=1.0, scale=0.01, size=(X_train_row_length, len(cont_features)))\n            X_valid_multiplier = np.random.normal(loc=1.0, scale=0.01, size=(X_valid_row_length, len(cont_features)))\n            X_train.loc[X_train_row_length*(i+1):X_train_row_length*(i+2)-1, cont_features] *= X_train_multiplier\n            X_valid.loc[X_valid_row_length*(i+1):X_valid_row_length*(i+2)-1, cont_features] *= X_valid_multiplier\n\n        del X_train_multiplier, X_train_row_length\n        del X_valid_multiplier, X_valid_row_length\n        gc.collect()\n    \n    start = time.time()\n    model = xgb.XGBClassifier(**xgb_params)\n    model.fit(\n        X_train, \n        y_train,\n        eval_set=[(X_valid, y_valid)],\n        eval_metric='auc',\n        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n        verbose=VERBOSE\n    )\n\n    fi_tmp = pd.DataFrame()\n    fi_tmp['feature'] = X_train.columns\n    fi_tmp['importance'] = model.feature_importances_\n    fi_tmp['fold'] = fold\n    fi_tmp['seed'] = SEED\n    xgb_importances = xgb_importances.append(fi_tmp)\n\n    del fi_tmp\n    gc.collect()\n    \n    if EXTRA_DATA:\n        y_hat = model.predict_proba(X_valid)[:, -1]\n        if fold == 0:\n            xgb_oof = y_hat\n            target = y_valid\n        else:\n            xgb_oof = np.concatenate([xgb_oof, y_hat])\n            target = np.concatenate([target, y_valid])\n    else:\n        xgb_oof[val_idx] = model.predict_proba(X_valid)[:, -1]\n        \n    xgb_pred += model.predict_proba(X_test)[:, -1] \/ N_SPLITS\n\n    elapsed = time.time() - start\n    if EXTRA_DATA:\n        auc = roc_auc_score(y_valid, y_hat)\n    else:\n        auc = roc_auc_score(y_valid, xgb_oof[val_idx])\n    print(f\"fold {fold} - xgb auc: {auc:.6f}, elapsed time: {elapsed:.2f}sec\\n\")\n\n    del X_train, y_train, X_valid, y_valid\n    if EXTRA_DATA:\n        del y_hat\n    gc.collect()\n    \nif EXTRA_DATA:\n    print(f\"oof xgb auc = {roc_auc_score(target, xgb_oof)}\")\nelse:\n    print(f\"oof xgb auc = {roc_auc_score(train[TARGET], xgb_oof)}\")\n    \nnp.save(\"xgb_oof.npy\", xgb_oof)\nnp.save(\"xgb_pred.npy\", xgb_pred)","47107502":"order = list(xgb_importances.groupby('feature').mean().sort_values('importance', ascending=False).index)\n\nfig = plt.figure(figsize=(16, 32), tight_layout=True)\nsns.barplot(x=\"importance\", y=\"feature\", data=xgb_importances.groupby('feature').mean().reset_index(), order=order)\nplt.title(\"XGBoost feature importances\")","7dc66d1e":"submission = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv')\n\nsubmission[TARGET] = xgb_pred\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission","dedd4904":"## Feature importance","a3e7c633":"# Submission\n---","25065bba":"# XGBoost\n---","594c8c4d":"# Libraries\n---","c13b8130":"# Parameters\n---","71fbcc82":"## Cross validation","c8232cdb":"# Datasets\n---"}}