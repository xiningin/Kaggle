{"cell_type":{"6acfa886":"code","66feee71":"code","404af081":"code","800f31f9":"code","5cd10893":"code","b46ab2b8":"code","8ffcaebf":"code","22cc50c0":"code","419c11ba":"code","f52f04b3":"code","446324d9":"code","16123aa4":"code","5e7b29e3":"code","ab366f06":"code","8a4ccff7":"code","43a97d18":"code","8d3675ce":"code","61b0fff6":"code","5101d2b3":"code","331175c0":"code","4971b547":"code","ce8f8032":"code","5fcc8d10":"code","dbf51f2c":"code","009a9738":"code","81060805":"code","ff21972e":"code","3acb330d":"code","19af804c":"code","a607cc44":"code","e070c5fd":"code","f5181f4b":"code","6820c197":"code","ce3f694d":"code","48e9b487":"code","b61d33c2":"code","6c7dae4a":"code","08640fb1":"code","9a3a573c":"code","55bd9ec5":"code","9af872eb":"code","ec3d3ea8":"code","d1d7ab93":"code","8b28859a":"code","430f368a":"code","55c64fea":"code","ca1f24ac":"code","7a731ae1":"code","16fadba5":"code","0cefe3a8":"code","738875f8":"code","05a9d894":"code","501930f6":"code","fe26d4ae":"markdown","d2b3e91f":"markdown","c3ad54b3":"markdown","40f19a0d":"markdown","b3e80ee2":"markdown","659f9cec":"markdown","d7d46153":"markdown","3fdb72d3":"markdown","70efdca2":"markdown","61b9a8bc":"markdown","bfdb9dd4":"markdown","f57f5292":"markdown","753e2605":"markdown","2f1b5c39":"markdown","0b35a81f":"markdown"},"source":{"6acfa886":"# importing libraries\nimport os, time, random, sys\nos.environ['PYTHONHASHSEED']=str(1)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use('seaborn-deep')\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.serif'] = 'Ubuntu'\nplt.rcParams['font.monospace'] = 'Ubuntu Mono'\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['xtick.labelsize'] = 8\nplt.rcParams['ytick.labelsize'] = 8\nplt.rcParams['legend.fontsize'] = 12\nplt.rcParams['figure.titlesize'] = 14\nplt.rcParams['figure.figsize'] = (12, 8)\n\npd.options.mode.chained_assignment = None\npd.options.display.float_format = '{:.2f}'.format\npd.set_option('display.max_columns', 200)\npd.set_option('display.width', 400)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport sklearn.utils as sku\nfrom skimage.io import imread\nfrom skimage.transform import resize\nseed = 12","66feee71":"import tensorflow as tf\nimport tensorflow_addons as tfa\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\nfrom keras import backend as K","404af081":"def runSeed():\n    global seed\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\nrunSeed()\n\n## Checking the GPU configuration\n!nvidia-smi","800f31f9":"basePath = '\/kaggle\/input\/deepweeds\/'\nimgPath = basePath + 'images\/'\nlabelsBase = basePath + 'labels\/'\nlabelsPath = labelsBase + 'labels.csv'\nlabels_df = pd.read_csv(labelsPath)\nlabels_df.head()","5cd10893":"trainSubsets = []\nvalSubsets = []\ntestSubsets = []\nfor x in range(5):\n    trainSubsets.append(pd.read_csv(labelsBase + 'train_subset'+str(x)+'.csv'))\n    valSubsets.append(pd.read_csv(labelsBase + 'val_subset'+str(x)+'.csv'))\n    testSubsets.append(pd.read_csv(labelsBase + 'test_subset'+str(x)+'.csv'))\n    \ntrainDf = pd.concat(trainSubsets, axis=0, ignore_index=True)\nvalDf = pd.concat(valSubsets, axis=0, ignore_index=True)\ntestDf = pd.concat(testSubsets, axis=0, ignore_index=True)","b46ab2b8":"def showImage(img):\n    plt.figure(figsize=(2,2))\n    plt.imshow(img)\n    plt.show()","8ffcaebf":"# constants\nbatch_size = 512\nimg_dim = 299\ndef getImgTensor(img_d):\n    return (img_d, img_d, 3)\ngetImgTensor(img_dim)","22cc50c0":"df_train = trainDf.sample(frac=1, random_state=seed+568)\ndf_train.reset_index(drop=True, inplace=True)\ndf_train['Label'] = df_train['Label'].astype('str')\n\ndf_val = valDf.sample(frac=1, random_state=seed+568)\ndf_val.reset_index(drop=True, inplace=True)\ndf_val['Label'] = df_train['Label'].astype('str')\n\ndf_test = testDf.sample(frac=1, random_state=seed+568)\ndf_test.reset_index(drop=True, inplace=True)\ndf_test['Label'] = df_train['Label'].astype('str')","419c11ba":"# reading training and validation separately to prevent overlapping \n\ntrain_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255, \n#                                                          validation_split=0.2,\n                                                         shear_range=0.2, \n#                                                          zoom_range=0.2, \n                                                         horizontal_flip=True, \n#                                                          width_shift_range=0.1, \n#                                                          height_shift_range=0.1\n                                                        )\n\ntrain_generator=train_datagen.flow_from_dataframe(directory=imgPath,\n                                                  dataframe=df_train,\n                                                  x_col='Filename',\n                                                  y_col='Label',\n#                                                   subset=\"training\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","f52f04b3":"# generate class weights as classes are imbalanced\nclass_weights = sku.class_weight.compute_class_weight('balanced',\n                                                      np.unique(train_generator.classes), \n                                                      train_generator.classes)\ntrain_class_weights = {i:x for i, x in enumerate(class_weights)}\ntrain_class_weights","446324d9":"batch = train_generator.next()[0]\nshowImage(batch[0])\nshowImage(batch[1])","16123aa4":"val_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\nvalid_generator=val_datagen.flow_from_dataframe(directory=imgPath,\n                                                  dataframe=df_val,\n                                                  x_col='Filename',\n                                                  y_col='Label',\n#                                                   subset=\"validation\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=getImgTensor(img_dim)[:2])","5e7b29e3":"batch = valid_generator.next()[0]\nshowImage(batch[0])\nshowImage(batch[1])","ab366f06":"test_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntest_generator=test_datagen.flow_from_dataframe(directory=imgPath, \n                                                dataframe=df_test,\n                                                x_col='Filename',\n                                                y_col='Label',\n                                                batch_size=1,\n                                                color_mode=\"rgb\",\n                                                seed=seed,\n                                                shuffle=False,\n                                                class_mode=\"categorical\",\n#                                                 classes=['TEST'],\n                                                target_size=getImgTensor(img_dim)[:2])","8a4ccff7":"batch = test_generator.next()[0]\nshowImage(batch[0])","43a97d18":"def plotModelHistory(h):\n    fig, ax = plt.subplots(1, 2, figsize=(15,4))\n    ax[0].plot(h.history['loss'])   \n    ax[0].plot(h.history['val_loss'])\n    ax[0].legend(['loss','val_loss'])\n    ax[0].title.set_text(\"Train loss vs Validation loss\")\n\n    ax[1].plot(h.history['categorical_accuracy'])\n    ax[1].plot(h.history['val_categorical_accuracy'])\n    ax[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n    ax[1].title.set_text(\"Train accuracy vs Validation accuracy\")\n\n    print(\"Max. Training Accuracy\", max(h.history['categorical_accuracy']))\n    print(\"Max. Validaiton Accuracy\", max(h.history['val_categorical_accuracy']))","8d3675ce":"class myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        ACCURACY_THRESHOLD = 0.99\n        if(logs.get('categorical_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True","61b0fff6":"# training model using train and val data\ndef trainModel(model, epochs, optimizer, vb=1, modelName='model'):\n    bestModelPath = '.\/'+modelName+'_model.hdf5'\n    callback = myCallback()\n    callbacks_list = [\n        callback,\n        k.callbacks.ReduceLROnPlateau(monitor = 'val_loss', patience = 5, verbose = 1, min_lr=0.00001), \n        k.callbacks.EarlyStopping(monitor = 'val_loss', patience = 15, verbose = 1, restore_best_weights = True), \n        k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)\n    ]\n    model.compile(optimizer=optimizer,\n                  loss=k.losses.CategoricalCrossentropy(label_smoothing=.05),\n                  metrics=[k.metrics.CategoricalAccuracy(), k.metrics.Precision(), k.metrics.Recall()]\n    )\n    train_generator.reset()\n    \n    steps_per_epoch = np.ceil(train_generator.n\/train_generator.batch_size)\n    validation_steps = np.ceil(valid_generator.n\/valid_generator.batch_size)\n\n    return model.fit_generator(generator=train_generator, steps_per_epoch=steps_per_epoch, \n                               validation_data=valid_generator, validation_steps=validation_steps, \n                               epochs=epochs, verbose=vb,\n#                                class_weight=train_class_weights,\n                               callbacks=callbacks_list)","5101d2b3":"# evaluate model with time on test data\ndef evaluateModel(model, path=True):\n    batch_size = test_generator.batch_size\n    num_train_sequences = test_generator.n\n    test_generator.reset()\n    steps_per_epoch = 0\n    if (test_generator.n%test_generator.batch_size) == 0:\n        steps_per_epoch = int(test_generator.n\/test_generator.batch_size)\n    else:\n        steps_per_epoch = int(test_generator.n\/\/test_generator.batch_size) + 1\n\n    t1 = time.time()\n    if path:\n        model = k.models.load_model(model)\n    eval_results = model.evaluate_generator(test_generator, steps=steps_per_epoch)\n    t2 = time.time()\n    print(f'\\nLoss: {eval_results[0]}, Accuracy: {eval_results[1]}, Precision: {eval_results[2]}, Recall: {eval_results[3]}')\n    print(f'Prediction Time per Image: {(t2-t1)\/valid_generator.n}')","331175c0":"# # predict images using model\n# def predictModel(modelPath):\n#     batch_size = test_generator.batch_size\n#     num_train_sequences = test_generator.n\n#     steps_per_epoch = 0\n#     if (test_generator.n%test_generator.batch_size) == 0:\n#         steps_per_epoch = int(test_generator.n\/test_generator.batch_size)\n#     else:\n#         steps_per_epoch = int(test_generator.n\/\/test_generator.batch_size) + 1\n\n#     test_generator.reset()\n\n#     t1 = time.time()\n#     model = k.models.load_model(modelPath)\n#     predictions = model.predict_generator(test_generator, steps=steps_per_epoch, verbose=1)\n#     t2 = time.time()\n#     print(f'Prediction Time per Image: {(t2-t1)\/test_generator.n}')\n    \n#     print(\"Generating Predictions file..\")\n#     labels = (train_generator.class_indices)\n#     labels = dict((v,k) for k,v in labels.items())\n#     predicted_class_indices=np.argmax(predictions, axis=1)\n#     predictions_label = [labels[k] for k in predicted_class_indices]\n#     filenames = list(map(lambda x: x.split('\/')[-1], test_generator.filenames))\n#     submission=pd.DataFrame({\n#         \"Filename\":filenames, \n#         \"Class\":predictions_label\n#     })\n#     submission_file = \"submission_\"+modelPath.split('\/')[-1].split('_')[0]+\".csv\"\n#     submission.to_csv(submission_file,index=False)\n#     print(f\"Submission file with {len(submission.values)} rows generated:\", submission_file)\n#     submission.head()","4971b547":"img_dim=299\nmobilenet = k.applications.mobilenet_v2.MobileNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\nmobilenet.trainable = False\n\nmodel = k.models.Sequential([\n                             mobilenet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.25),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(9, activation='softmax')\n])\nprint(model.summary())","ce8f8032":"history_1 = trainModel(model, 10, 'adam', modelName='mobilenet')","5fcc8d10":"plotModelHistory(history_1)","dbf51f2c":"# img_dim=299\n# resnet152 = k.applications.ResNet152V2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\n# resnet152.trainable = False\n\n# model_2 = k.models.Sequential([\n#                              resnet152,\n#                              tf.keras.layers.GlobalAveragePooling2D(),\n#                              k.layers.Dropout(0.4),\n#                             #  k.layers.Dense(1024, activation='relu'),\n#                             #  k.layers.BatchNormalization(),\n#                             #  k.layers.Dropout(0.3),\n\n#                             #  k.layers.Dense(512, activation='relu'),\n#                             #  k.layers.BatchNormalization(),\n#                             #  k.layers.Dropout(0.3),\n\n#                              k.layers.Dense(256, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.3),\n#                              k.layers.Dense(9, activation='softmax')\n# ])\n# print(model_2.summary())","009a9738":"# history_2 = trainModel(model_2, 30, 'adam', modelName='resnet152')","81060805":"# plotModelHistory(history_2)","ff21972e":"# img_dim=224\n# inceptionv3 = k.applications.InceptionV3(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\n# inceptionv3.trainable = False\n\n# model_3 = k.models.Sequential([\n#                              inceptionv3,\n#                              tf.keras.layers.GlobalAveragePooling2D(),\n#                              k.layers.Dropout(0.4),\n#                              k.layers.Dense(256, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.3),\n#                             #  k.layers.Dense(128, activation='relu'),\n#                             #  k.layers.BatchNormalization(),\n#                             #  k.layers.Dropout(0.2),\n#                              k.layers.Dense(5, activation='softmax')\n# ])\n# print(model_3.summary())","3acb330d":"# history_3 = trainModel(model_3, 50, 'adam', modelName='inceptionv3')","19af804c":"# plotModelHistory(history_3)","a607cc44":"# img_dim=331\n# nasnet = k.applications.nasnet.NASNetLarge(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\n# nasnet.trainable = False\n\n# model_4 = k.models.Sequential([\n#                              nasnet,\n#                              tf.keras.layers.GlobalAveragePooling2D(),\n#                              k.layers.Dropout(0.3),\n#                              k.layers.Dense(256, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.25),\n#                             #  k.layers.Dense(128, activation='relu'),\n#                             #  k.layers.BatchNormalization(),\n#                             #  k.layers.Dropout(0.2),\n#                              k.layers.Dense(9, activation='softmax')\n# ])\n# print(model_4.summary())","e070c5fd":"# history_4 = trainModel(model_4, 50, 'adam', modelName='nasnet_large')","f5181f4b":"# plotModelHistory(history_4)","6820c197":"img_dim=299\ninceptionresnet = k.applications.InceptionResNetV2(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\ninceptionresnet.trainable = False\n\nmodel_5 = k.models.Sequential([\n                             inceptionresnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n                            #  k.layers.Dense(128, activation='relu'),\n                            #  k.layers.BatchNormalization(),\n                            #  k.layers.Dropout(0.2),\n                             k.layers.Dense(9, activation='softmax')\n])\nprint(model_5.summary())","ce3f694d":"history_5 = trainModel(model_5, 10, 'adam', modelName='inceptionresnet')","48e9b487":"plotModelHistory(history_5)","b61d33c2":"# img_dim=299\n# densenet152 = k.applications.DenseNet169(weights='imagenet', input_shape=getImgTensor(img_dim), include_top=False)\n# densenet152.trainable = False\n\n# model_6 = k.models.Sequential([\n#                              densenet152,\n#                              tf.keras.layers.GlobalAveragePooling2D(),\n#                              k.layers.Dropout(0.3),\n#                              k.layers.Dense(256, activation='relu'),\n#                              k.layers.BatchNormalization(),\n#                              k.layers.Dropout(0.25),\n#                             #  k.layers.Dense(128, activation='relu'),\n#                             #  k.layers.BatchNormalization(),\n#                             #  k.layers.Dropout(0.2),\n#                              k.layers.Dense(9, activation='softmax')\n# ])\n# print(model_6.summary())","6c7dae4a":"# history_6 = trainModel(model_6, 50, 'adam', modelName='densenet169')","08640fb1":"# plotModelHistory(history_6)","9a3a573c":"# model_7 = k.Model(model_5.input, model_5.layers[-3].output)\n# train_generator.reset()\n# # scan model feature representations\n# X_train_embed = []\n# y_train_embed = []\n# for x in range(int(np.ceil(train_generator.n\/train_generator.batch_size))):\n#     x_batch, y_batch = next(train_generator)\n#     x_last = model_7.predict(x_batch)\n#     X_train_embed.extend(x_last)\n#     y_train_embed.extend(y_batch)\n\n# # generate predictions for embeddings\n# y_train_embed = np.array(np.argmax(y_train_embed, axis=1))\n# X_train_embed = np.array(X_train_embed)\n# print(y_train_embed.shape)","55bd9ec5":"# # create xgb classifier for classification\n# from xgboost import XGBClassifier\n# xgb = XGBClassifier(max_depth=10, objective='multi:softmax', n_estimators=1000, num_classes=9,\n#                     tree_meth ='gpu_hist', gpu_id=0, n_jobs=-1)\n# xgb.fit(X_train_embed,y_train_embed)","9af872eb":"# # generate predictions for test data\n# img_dim=299\n# X_test_embed = np.array(model_7.predict(test_generator))\n# predictions_xgb = xgb.predict(X_test_embed)\n\n# # generate submission file for predictions\n# labels = (train_generator.class_indices)\n# labels = dict((v,k) for k,v in labels.items())\n# predictions_label = [labels[k] for k in predictions_xgb]\n# filenames = list(map(lambda x: x.split('\/')[-1], test_generator.filenames))\n# submission=pd.DataFrame({\n#     \"Filename\":filenames, \n#     \"Class\":predictions_label\n# })\n# submission_file = \"submission_DENSENET169_XGB.csv\"\n# submission.to_csv(submission_file,index=False)\n# print(f\"Submission file with {len(submission.values)} rows generated:\", submission_file)\n# submission.head()","ec3d3ea8":"# mobile net\nimg_dim=299\nevaluateModel('.\/mobilenet_model.hdf5')","d1d7ab93":"# # resnet152\n# img_dim=224\n# evaluateModel('.\/resnet152_model.hdf5')","8b28859a":"# # inceptionv3\n# img_dim=224\n# evaluateModel('.\/inceptionv3_model.hdf5')","430f368a":"# # nasnet\n# img_dim=331\n# evaluateModel('.\/nasnet_large_model.hdf5')\n# # evaluateModel(model_4, False)","55c64fea":"# inceptionresnet\nimg_dim=299\nevaluateModel('.\/inceptionresnet_model.hdf5')","ca1f24ac":"# # densenet169\n# img_dim=299\n# evaluateModel('.\/densenet169_model.hdf5')","7a731ae1":"# # mobile net\n# img_dim=224\n# predictModel('.\/mobilenet_model.hdf5')","16fadba5":"# # resnet152\n# img_dim=224\n# predictModel('.\/resnet152_model.hdf5')","0cefe3a8":"# # inceptionv3\n# img_dim=224\n# predictModel('.\/inceptionv3_model.hdf5')","738875f8":"# # nasnet\n# img_dim=331\n# predictModel('.\/nasnet_large_model.hdf5')","05a9d894":"# # inceptionresnet\n# img_dim=299\n# predictModel('.\/inceptionresnet_model.hdf5')","501930f6":"# # densenet169\n# img_dim=299\n# predictModel('.\/densenet169_model.hdf5')","fe26d4ae":"## Train MobileNetV2 - Light Model","d2b3e91f":"# Model Building","c3ad54b3":"## Train InceptionV3 - Medium Model","40f19a0d":"# Data Preparation\n","b3e80ee2":"## CNN + XGB Model","659f9cec":"### Loading Dataset","d7d46153":"# Model Evaluation","3fdb72d3":"## Train ResNet152 - Heavy Model","70efdca2":"## Train NASNetLarge - Heavy Model","61b9a8bc":"You can try out with other models. I've deployed using only two models due to script execution time constraints.","bfdb9dd4":"## Setup Image Generator","f57f5292":"# Model Prediction\n\nNot required for competition submission.","753e2605":"## Train InceptionResNetV2 - Heavy Model","2f1b5c39":"## Train DenseNet169 - Light Model","0b35a81f":"# DeepWeeds Classification\n\nThe DeepWeeds dataset consists of 17,509 unique 256x256 colour images in 9 classes. There are 15,007 training images and 2,501 test images. These images were collected in situ from eight rangeland environments across northern Australia.\n\nClasses:-\n- Chinee Apple\n- Lantana\n- Parkinsonia\n- Parthenium\n- Prickly Acacia\n- Rubber Vine\n- Siam Weed\n- Snake Weed\n- Other.\n\n# Reading & Understanding Data\n## Importing Libraries"}}