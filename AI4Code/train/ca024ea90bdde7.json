{"cell_type":{"5537f003":"code","0cb6c1fa":"code","71ef1b25":"code","866ee92b":"code","a64a5d19":"code","e7ddb12f":"code","2a515303":"code","3c4990fd":"code","97f24209":"code","5ff49b4b":"code","f9a7a932":"code","a7568534":"code","b8460a9c":"code","ac8eb97e":"code","71ce141a":"code","91477614":"code","469bbdb6":"code","e3d9c839":"code","0ceda8bd":"code","30d07af5":"code","638c26df":"code","d5e3c98e":"code","07e6a8ee":"code","fd208108":"code","d94f99d0":"code","4295b546":"code","557be55c":"code","d7655ec4":"code","51cd1292":"code","7ef5cb73":"code","2e47def8":"code","bb23dd34":"code","e7f2d213":"code","d335558b":"code","fbc92b36":"code","44282bb7":"code","6865e096":"code","d6b2d852":"code","81551b10":"code","ac871728":"code","63966a22":"code","63d76c40":"markdown","12625123":"markdown"},"source":{"5537f003":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0cb6c1fa":"data=pd.read_csv('\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\ndata","71ef1b25":"data.drop(columns=['CustomerID'],inplace=True)\ndata","866ee92b":"nom_cols=[0]\nord_cols=[]","a64a5d19":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.compose import make_column_transformer\nfrom sklearn import set_config\n\ntrans = make_column_transformer((OneHotEncoder(sparse=False),nom_cols),\n                                (OrdinalEncoder(), ord_cols)\n                                ,remainder= 'passthrough')\nset_config(display= 'diagram')","e7ddb12f":"from sklearn.cluster import KMeans\nkm=KMeans(n_clusters=2)","2a515303":"from sklearn.pipeline import make_pipeline\npipe = make_pipeline(trans,km)\npipe","3c4990fd":"data","97f24209":"pipe.fit(data)","5ff49b4b":"data['Gender']=pd.get_dummies(data.Gender,drop_first=True)\nkm.fit(data)                #TO CONVERT STRINGS TO INTEGERS ","f9a7a932":"data.head()","a7568534":"#for k in K:\n   # km=KMeans(n_clusters=k).fit(data)\n    #km.fit(data)","b8460a9c":"km.labels_","ac8eb97e":"km.cluster_centers_","71ce141a":"km.n_iter_","91477614":"X=data","469bbdb6":"\nfrom sklearn.cluster import KMeans\nfrom sklearn import metrics\nfrom scipy.spatial.distance import cdist\nimport numpy as np\nimport matplotlib.pyplot as plt","e3d9c839":"distortions = []\ninertias = []\nmapping1 = {}\nmapping2 = {}\nK = range(1, 10)\n \nfor k in K:\n    # Building and fitting the model\n    kmeanModel = KMeans(n_clusters=k).fit(X)\n    kmeanModel.fit(X)\n \n    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_,\n                                        'euclidean'), axis=1)) \/ X.shape[0])\n    inertias.append(kmeanModel.inertia_)\n \n    mapping1[k] = sum(np.min(cdist(X, kmeanModel.cluster_centers_,\n                                   'euclidean'), axis=1)) \/ X.shape[0]\n    mapping2[k] = kmeanModel.inertia_","0ceda8bd":"for key, val in mapping1.items():\n    print(f'{key} : {val}')","30d07af5":"plt.plot(K, distortions, 'bx-')\nplt.xlabel('Values of K')\nplt.ylabel('Distortion')\nplt.title('The Elbow Method using Distortion')             #1to 6 have optimal number of clusters \nplt.show()","638c26df":"for key, val in mapping2.items():\n    print(f'{key} : {val}')","d5e3c98e":"plt.plot(K, inertias, 'bx-')\nplt.xlabel('Values of K')\nplt.ylabel('Inertia')\nplt.title('The Elbow Method using Inertia')\nplt.show()","07e6a8ee":"#selhoitte clustering","fd208108":"from sklearn.metrics import silhouette_score\nimport matplotlib.pyplot as plt ","d94f99d0":"range_n_clusters = [2, 3, 4, 5, 6, 7, 8]              #k means how many clusters we can make  \nsilhouette_avg = []\nfor num_clusters in range_n_clusters:\n \n # initialise kmeans\n kmeans = KMeans(n_clusters=num_clusters)\n kmeans.fit(data)\n cluster_labels = kmeans.labels_\n \n # silhouette score\n silhouette_avg.append(silhouette_score(data, cluster_labels))\n#plt.plot(range_n_clusters,silhouette_avg,'bx-')\nplt.barh(range_n_clusters,silhouette_avg)\nplt.xlabel('Values of K') \nplt.ylabel('Silhouette score') \nplt.title('Silhouette analysis For Optimal k')\nplt.show()","4295b546":"silhouette_avg","557be55c":"silhouette_avg.index(max(silhouette_avg))            #4th cluster fits the data very well","d7655ec4":"silhouette_avg[silhouette_avg.index(max(silhouette_avg))] ","51cd1292":"from sklearn.cluster import AgglomerativeClustering \nimport scipy.cluster.hierarchy as sch\ndend = sch.dendrogram(sch.linkage(data,method='ward'))","7ef5cb73":"ac=AgglomerativeClustering(n_clusters=5)\npipe_ac=make_pipeline(trans,ac)\npipe_ac","2e47def8":"from sklearn.cluster import DBSCAN\ndb=DBSCAN(10,min_samples=3)\npipe_db=make_pipeline(trans,db)\npipe_db","bb23dd34":"pipe_db.fit(data)","e7f2d213":"db.labels_.max()                  # 9 types of pple ","d335558b":"db.labels_","fbc92b36":"from sklearn.decomposition import PCA\npca=PCA(n_components=2)\ndata_1=pca.fit_transform(data)\ndata_1     ","44282bb7":"import seaborn as sns\n","6865e096":"sns.pairplot(data)","d6b2d852":"sns.jointplot(data_1[0],data_1[1])","81551b10":"pca.components_                                #row wise scaling wrt to pca ","ac871728":"pca.explained_variance_ratio_                #add both values then 10 percent gets deducted due to pca ","63966a22":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('Visualizing', fontsize = 20)\ntargets = [0,1]\ncolors = ['r', 'g']\nfor target, color in zip(targets,colors):\n    indicesToKeep = data['target'] = target\n    ax.scatter(data.loc[indicesToKeep, 'principal component 1']\n               , data.loc[indicesToKeep, 'principal component 2']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()","63d76c40":"# Distortion","12625123":"# Inertia"}}