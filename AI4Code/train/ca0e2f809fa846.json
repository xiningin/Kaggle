{"cell_type":{"d1d47ce1":"code","ad3b7841":"code","a526e950":"code","5650eb5c":"code","d41cec9f":"code","725a39c2":"code","b6a9aede":"code","b5441685":"code","13087e6a":"code","eeef1938":"code","7ef4ce32":"code","265c8cf6":"code","81a59afa":"code","3a1af5c6":"code","f9b54a19":"code","12b204e6":"code","baccda35":"code","86de001d":"code","758e3984":"code","d133660c":"code","ed2c6ec3":"code","07470b79":"code","a9d340fa":"code","343603c4":"code","350fca44":"code","bedb22f0":"code","70dee340":"code","5790951a":"code","cfb8c4d6":"code","632ccbcb":"code","0f49eb18":"code","c51cac0e":"code","6703b889":"code","6cdd761a":"code","87cf73be":"code","1b5167d5":"code","4d3b4b47":"code","99008d43":"code","1a45492d":"code","463e18a8":"code","dcd1e18e":"code","9be7ce9b":"code","f736060d":"code","b6910ae3":"code","ceaf46a2":"code","549ad539":"code","4792bd26":"code","1cd5c361":"code","faf6fcd2":"code","eb8ccd76":"code","ce808e74":"code","3390345c":"code","64bcd6f0":"code","623bde09":"code","aa5ab70d":"code","49f0f2f6":"code","d239f3b2":"code","46f13100":"code","4320f6d6":"code","606d2821":"code","a888d31e":"code","cc31bdca":"code","c6b52615":"code","cd9a0f85":"code","d6ed6daa":"code","53c5c7e1":"code","7f656f46":"code","112b75a9":"code","5e3078e5":"code","9032b498":"code","c27b0e02":"code","191795c8":"code","335f77c7":"code","8efdfb2a":"code","b94beae6":"code","c2a8ca99":"code","98d78891":"code","71596741":"code","b89f42e5":"markdown","0e833b55":"markdown","d3d193cc":"markdown","2749f6eb":"markdown","db614636":"markdown","6f8e73e9":"markdown","93b84549":"markdown","a15f1f53":"markdown","10296a1e":"markdown","a1931262":"markdown","ab40adb0":"markdown","58a18ab8":"markdown"},"source":{"d1d47ce1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad3b7841":"df = pd.read_csv('..\/input\/water-potability\/water_potability.csv')","a526e950":"df.head()","5650eb5c":"df.info()","d41cec9f":"df.describe()","725a39c2":"df.isnull().sum()","b6a9aede":"df.Potability.value_counts()","b5441685":" df = df.dropna(subset=['ph','Sulfate','Trihalomethanes'], how='all')","13087e6a":"df['ph'].fillna(df.ph.mean(),inplace= True)","eeef1938":"df['Sulfate'].fillna(df.Sulfate.mean(),inplace= True)\ndf['Trihalomethanes'].fillna(df.Trihalomethanes.mean(),inplace= True)","7ef4ce32":"df.isnull().sum()","265c8cf6":"df.head()","81a59afa":"df.columns","3a1af5c6":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.express as px","f9b54a19":"plt.figure(figsize=(10,10))\nsns.heatmap(df.corr(),annot=True, cmap='YlGnBu')","12b204e6":"\nsns.pairplot(df, hue='Potability',palette='mako')","baccda35":"sns.countplot(x='Potability',data =df)","86de001d":"fig = px.scatter_matrix(df,\n    dimensions=['ph', 'Hardness', 'Solids','Turbidity'],\n    color=\"Potability\")\nfig.show()","758e3984":"fig = px.scatter(df, x=\"ph\", y=\"Sulfate\", color=\"Potability\")\nfig.show()","d133660c":"fig = px.histogram(df, x=\"Chloramines\", color=\"Potability\", marginal=\"violin\", # can be `box`, `violin`\n                         hover_data=df.columns)\nfig.show()\n","ed2c6ec3":"fig = px.density_contour(df, x=\"Conductivity\", y=\"Solids\",color=\"Potability\", marginal_x=\"rug\", marginal_y=\"histogram\")\nfig.show()","07470b79":"fig = px.scatter_ternary(df, a=\"Chloramines\", b=\"Turbidity\", c=\"Conductivity\",color='Potability')\nfig.show()","a9d340fa":"from sklearn.model_selection import train_test_split","343603c4":"X = df.drop('Potability',axis=1)\ny = df.Potability","350fca44":" X_train, X_test, y_train, y_test = train_test_split(\n     X, y, \n     test_size=0.3,\n     random_state=0)","bedb22f0":"X_train.shape, y_train.shape","70dee340":"plt.figure(figsize=(10,10))\nsns.heatmap(X_train.corr(),annot=True, cmap='YlGnBu')","5790951a":"def correlation(dataset,threshold):\n    col_corr = set() # set of names of all the columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if (corr_matrix.iloc[i,j]) > threshold:# we r intrested in coeff value\n                col_name = corr_matrix.columns[i] # getting the name of column\n                col_corr.add(col_name)\n    return col_corr","cfb8c4d6":"corr_features = correlation(X,0.85)\nlen(set(corr_features))","632ccbcb":"corr_features","0f49eb18":"## Feature Importance\nfrom sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier()","c51cac0e":"model.fit(X,y)","6703b889":"print(model.feature_importances_)","6cdd761a":"## plot graph of feature importance for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(5).plot(kind='barh')\nplt.show()","87cf73be":"from sklearn.feature_selection import mutual_info_classif\n\nfrom sklearn.feature_selection import SelectKBest","1b5167d5":"mutual_info = mutual_info_classif(X_train,y_train)\nmutual_info","4d3b4b47":"mutual_info = pd.Series(mutual_info)\nmutual_info.index = X_train.columns\nmutual_info.sort_values(ascending=False)","99008d43":"mutual_info.sort_values(ascending=False).plot.bar(figsize=(20,13))","1a45492d":"select_5_best = SelectKBest(mutual_info_classif,k=5)\nselect_5_best.fit(X_train,y_train)\ncols = X_train.columns[select_5_best.get_support()]","463e18a8":"cols","dcd1e18e":"from sklearn.preprocessing import StandardScaler \nscaler=StandardScaler()\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.fit_transform(X_test)","9be7ce9b":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()","f736060d":"# RANDOMIZED SEARCH CV\n# HYPERPARAMETERS\n\n## no.of trees in the radnom forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n\n## criterion\ncriterion = [\"gini\", \"entropy\"]\n\n## no.of features to consider at every split\nmax_features = ['auto','sqrt']\n\n## max no of levels of trees\nmax_depth = [int(x) for x in np.linspace(5,30,num=6)]\n\n## min no of samples required to split a node\nmin_samples_split = [2,5,10,15,100]\n\n## min no. of samples required at each leaf node\nmin_samples_leaf = [1,2,3,10]","b6910ae3":"from sklearn.model_selection import RandomizedSearchCV , GridSearchCV","ceaf46a2":"# create the random grid\nrandom_grid = { 'n_estimators' : n_estimators,\n               'criterion' : criterion,\n               'max_features' : max_features,\n               'max_depth' : max_depth,\n               'min_samples_split' : min_samples_split,\n               'min_samples_leaf' : min_samples_leaf\n               }\nprint(random_grid)","549ad539":"rfc_random = RandomizedSearchCV(estimator = rfc,\n                               param_distributions=random_grid,\n                               scoring='neg_mean_squared_error',\n                               n_iter = 10,\n                               cv = 5,\n                               verbose = 2,\n                               random_state = 42,\n                               n_jobs = 1)","4792bd26":"rfc_random.fit(X_train,y_train)","1cd5c361":"prediction = rfc_random.predict(X_test)","faf6fcd2":"prediction","eb8ccd76":"from sklearn.metrics import classification_report,confusion_matrix","ce808e74":"print(classification_report(y_test,prediction))","3390345c":"print(confusion_matrix(y_test,prediction))","64bcd6f0":"from sklearn.linear_model import SGDClassifier\nsgd_cal = SGDClassifier()","623bde09":"from sklearn.model_selection import cross_val_score\nscore = cross_val_score(sgd_cal,X_train,y_train,cv=10)","aa5ab70d":"from sklearn.metrics import accuracy_score","49f0f2f6":"score","d239f3b2":"score.mean()","46f13100":"from sklearn.model_selection import StratifiedKFold","4320f6d6":"accuracy = []\nskfl = StratifiedKFold(n_splits=10,random_state=None)\nskfl.get_n_splits(X_train,y_train)\nfor train_index,test_index in skfl.split(X_train,y_train):\n    print('train:',train_index,'validation:',test_index)\n    X1_train , X1_test = X_train[train_index] , X_train[test_index]\n    y1_train , y1_test = y_train.iloc[train_index] , y_train.iloc[test_index]\n    \n    sgd_cal.fit(X1_train,y1_train)\n    prediction = sgd_cal.predict(X1_test)\n    score = accuracy_score(prediction,y1_test)\n    accuracy.append(score)","606d2821":"np.array(accuracy).mean()","a888d31e":"from sklearn.linear_model import LogisticRegression","cc31bdca":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","c6b52615":"prediction = lr.predict(X_test)","cd9a0f85":"print(classification_report(y_test,prediction))","d6ed6daa":"sns.heatmap(confusion_matrix(y_test,prediction),annot=True)","53c5c7e1":"print(accuracy_score(y_test,prediction))","7f656f46":"from sklearn.ensemble import AdaBoostClassifier\n","112b75a9":"ada = AdaBoostClassifier()\n","5e3078e5":"\nparams_ada = {'n_estimators': [50,100,250,400,500,600], 'learning_rate': [0.2,0.5,0.8,1]}\ngrid_ada =  RandomizedSearchCV(ada, param_distributions = params_ada, cv=5)","9032b498":"grid_ada.fit(X_train,y_train)","c27b0e02":"y_pred = grid_ada.predict(X_test)\naccuracy = accuracy_score(y_test,y_pred)\nprint(accuracy)","191795c8":"from sklearn.linear_model import SGDClassifier","335f77c7":"sgd_cal = SGDClassifier()","8efdfb2a":"sgd_cal.fit(X_train,y_train)","b94beae6":"predictions = sgd_cal.predict(X_test)","c2a8ca99":"print(classification_report(y_test,predictions))","98d78891":"sns.heatmap(confusion_matrix(y_test,predictions),annot=True,cmap='YlGnBu')","71596741":"print(accuracy_score(y_test,predictions))","b89f42e5":"# **Feature Scaling**","0e833b55":"# **Feature Selection**","d3d193cc":"## 1. **Using SGDClassifier**","2749f6eb":"## 2. **Using STRATIFIED K_FOLD**","db614636":"## 3. **Using Mutual Information Gain** ","6f8e73e9":"## 1. Using RandomForestClassifier","93b84549":"## 2. **Using ExtraTressClassifier** ","a15f1f53":"# **Data Visualization**","10296a1e":"##  1. **Using Pearson Corelation**","a1931262":"## 1.**Using ADABOOST Classifier** ","ab40adb0":"# **Prediction and Evaluation**","58a18ab8":"## 3. **Using Logistic Regression**"}}