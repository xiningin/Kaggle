{"cell_type":{"93639975":"code","a770707f":"code","bd69d5c6":"code","0e9dfbfd":"code","8f8063df":"code","2938d8cb":"code","cdbbf546":"code","62c8348d":"code","7714b858":"code","93b7692a":"code","eaee1b21":"code","065d2293":"code","fc59aa6b":"code","2b5839f6":"code","387516d0":"code","16920c5b":"code","f2d3fd9c":"code","931f0fb9":"code","ed094b8a":"code","a0a59f79":"code","604b6b35":"code","bb443bd6":"code","cb809f08":"code","64c6f25f":"code","282b5483":"code","6bd6e895":"code","0e12246d":"code","5bb5a0d9":"code","7653da3c":"code","9b75a827":"markdown"},"source":{"93639975":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.utils.np_utils import to_categorical\nfrom keras.optimizers import SGD\nfrom matplotlib import pyplot as plt\nfrom PIL import Image, ImageDraw \n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a770707f":"import json\nf = open(r'..\/input\/shipsnet.json')\ndataset = json.load(f)\nf.close()","bd69d5c6":"input_data = np.array(dataset['data']).astype('uint8')\noutput_data = np.array(dataset['labels']).astype('uint8')","0e9dfbfd":"input_data.shape,output_data.shape","8f8063df":"X = input_data.reshape([-1,3, 80, 80])\nX[0].shape","2938d8cb":"pic = X[0]\n\nrad_spectrum = pic[0]\ngreen_spectrum = pic[1]\nblue_spectum = pic[2]\n\nplt.figure(2, figsize = (5*3, 5*1))\nplt.set_cmap('jet')\n\n# show each channel\nplt.subplot(1, 3, 1)\nplt.imshow(rad_spectrum)\n\nplt.subplot(1, 3, 2)\nplt.imshow(green_spectrum)\n\nplt.subplot(1, 3, 3)\nplt.imshow(blue_spectum)\n    \nplt.show()","cdbbf546":"output_data.shape","62c8348d":"out_y = to_categorical(output_data, num_classes = 2)","7714b858":"indexes = np.arange(2800)\nnp.random.shuffle(indexes)\nX_train = X[indexes].transpose([0,2,3,1])\ny_train = out_y[indexes]","93b7692a":"X_train = X_train \/ 255\nnp.random.seed(2)","eaee1b21":"model = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5, 5), activation='relu',\n                 input_shape = (80, 80, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (4, 4), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(3,3)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))","065d2293":"model.summary()","fc59aa6b":"from keras.optimizers import Adamax\noptimizer = Adamax(lr=0.001)\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","2b5839f6":"\n# training\nmodel.fit(\n    X_train, \n    y_train,\n    batch_size=32,\n    epochs=2,\n    validation_split=0.2,\n    shuffle=True,\n    verbose=2\n    )","387516d0":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n                            rotation_range = 90,\n                             zoom_range = 0.3,\n                            )\n\ndatagen.fit(X_train)","16920c5b":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state= 3)","f2d3fd9c":"from keras.callbacks import ReduceLROnPlateau\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","931f0fb9":"model.fit_generator(datagen.flow(X_train,y_train, batch_size= 86),shuffle = True,\n                                  epochs = 10, validation_data = (X_val,y_val),\n                                  verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ 86,\n                                  callbacks=[learning_rate_reduction])","ed094b8a":"image = Image.open('..\/input\/scenes\/scenes\/sfbay_2.png')\npix = image.load()\nn_spectrum = 3\nwidth = image.size[0]\nheight = image.size[1]\npicture_vector = []\nfor chanel in range(n_spectrum):\n    for y in range(height):\n        for x in range(width):\n            picture_vector.append(pix[x, y][chanel])\n","a0a59f79":"\npicture_vector = np.array(picture_vector).astype('uint8')\npicture_tensor = picture_vector.reshape([n_spectrum, height, width]).transpose(1, 2, 0)","604b6b35":"plt.figure(1, figsize = (15, 30))\n\nplt.subplot(3, 1, 1)\nplt.imshow(picture_tensor)\n\nplt.show()","bb443bd6":"picture_tensor = picture_tensor.transpose(2,0,1)","cb809f08":"def cutting(x, y):\n    area_study = np.arange(3*80*80).reshape(3, 80, 80)\n    for i in range(80):\n        for j in range(80):\n            area_study[0][i][j] = picture_tensor[0][y+i][x+j]\n            area_study[1][i][j] = picture_tensor[1][y+i][x+j]\n            area_study[2][i][j] = picture_tensor[2][y+i][x+j]\n    area_study = area_study.reshape([-1, 3, 80, 80])\n    area_study = area_study.transpose([0,2,3,1])\n    area_study = area_study \/ 255\n    sys.stdout.write('\\rX:{0} Y:{1}  '.format(x, y))\n    return area_study","64c6f25f":"def not_near(x, y, s, coordinates):\n    result = True\n    for e in coordinates:\n        if x+s > e[0][0] and x-s < e[0][0] and y+s > e[0][1] and y-s < e[0][1]:\n            result = False\n    return result","282b5483":"def show_ship(x, y, acc, thickness=5):   \n    for i in range(80):\n        for ch in range(3):\n            for th in range(thickness):\n                picture_tensor[ch][y+i][x-th] = -1\n\n    for i in range(80):\n        for ch in range(3):\n            for th in range(thickness):\n                picture_tensor[ch][y+i][x+th+80] = -1\n        \n    for i in range(80):\n        for ch in range(3):\n            for th in range(thickness):\n                picture_tensor[ch][y-th][x+i] = -1\n        \n    for i in range(80):\n        for ch in range(3):\n            for th in range(thickness):\n                picture_tensor[ch][y+th+80][x+i] = -1","6bd6e895":"import sys\nstep = 10; coordinates = []\nfor y in range(int((height-(80-step))\/step)):\n    for x in range(int((width-(80-step))\/step) ):\n        area = cutting(x*step, y*step)\n        result = model.predict(area)\n        if result[0][1] > 0.90 and not_near(x*step,y*step, 88, coordinates):\n            coordinates.append([[x*step, y*step], result])\n            print(result)\n            plt.imshow(area[0])\n            plt.show()","0e12246d":"for e in coordinates:\n    show_ship(e[0][0], e[0][1], e[1][0][1])","5bb5a0d9":"picture_tensor = picture_tensor.transpose(1,2,0)\npicture_tensor.shape","7653da3c":"plt.figure(1, figsize = (15, 30))\n\nplt.subplot(3,1,1)\nplt.imshow(picture_tensor)\n\nplt.show()\n","9b75a827":"**Code used from https:\/\/www.kaggle.com\/byrachonok\/keras-for-search-ships-in-satellite-image\/#data to display correct and incorrect predictions.**"}}