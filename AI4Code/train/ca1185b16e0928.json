{"cell_type":{"79337200":"code","c140a4d2":"code","2305e32f":"code","de28cf3e":"code","745c3d28":"code","9bd631fc":"code","f31c021a":"code","135b9b6d":"code","44fa8471":"code","58e46deb":"code","4c3c906d":"code","8a4abcd3":"code","92a830d7":"code","a319f294":"code","17ec9dfe":"code","605e4724":"code","7047cfda":"code","904d3ba8":"code","eca6779b":"code","bc3941d9":"code","197f6589":"code","b42c28b8":"code","2532c1e2":"code","1ef85f9a":"code","a438d0f3":"code","0cfb64f1":"code","f164a9d6":"code","a9889323":"code","d6e6e6ab":"code","701f02f7":"code","ec8581da":"code","266ca12d":"code","9b07e645":"code","ecf77b50":"code","786c0340":"code","1f18f238":"code","ae502d02":"code","f68847cf":"code","6d304c04":"code","c937742f":"code","803251a8":"code","4c5c2a65":"code","a9ac9825":"code","cdd24bed":"code","6948581c":"code","df1303f0":"code","976bd395":"code","f64e44d9":"code","4cf68e44":"code","1d9ebfb5":"code","dbadac89":"code","7cbea4e5":"code","03b1d4ab":"code","bcb9aee4":"code","097a7369":"code","ffce89fc":"code","76133811":"code","67624e54":"code","07d7da76":"code","ec65dae5":"code","9efaddee":"code","071c7683":"code","87a24be7":"code","4db3cc66":"markdown","a6214822":"markdown","198c888a":"markdown","9c60422e":"markdown","b9706a2d":"markdown","3f17f707":"markdown","945c4585":"markdown","7689f8bc":"markdown","860e1021":"markdown","4c538ac9":"markdown","956030a5":"markdown","1ee6d19d":"markdown","dd93cc45":"markdown","1a461587":"markdown","7227837a":"markdown","ee95f480":"markdown","e5b5fa1a":"markdown","89a54d4f":"markdown","36395525":"markdown","be5d5b6f":"markdown","c7dd49bb":"markdown","271219c9":"markdown","567ff994":"markdown","040b4d69":"markdown","c359acb4":"markdown","21fc211f":"markdown","6516375a":"markdown","126caaeb":"markdown","ef92b133":"markdown","b64a835f":"markdown"},"source":{"79337200":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom PIL import Image\nimport PIL","c140a4d2":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset","2305e32f":"!pip install timm","de28cf3e":"import timm\nfrom timm.data import resolve_data_config\nfrom timm.data.transforms_factory import create_transform","745c3d28":"import timm\nfrom pprint import pprint\nmodel_names = timm.list_models(pretrained=True)\npprint(model_names)","9bd631fc":"train = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\")\ntrain","f31c021a":"path = \"..\/input\/petfinder-pawpularity-score\/train\"\n\ntrain[\"path\"] = [os.path.join(path,s) + \".jpg\" for s in train[\"Id\"]]","135b9b6d":"train.head(3)","44fa8471":"img = cv2.imread(train[\"path\"].iloc[0])\nplt.imshow(img[:,:,::-1])","58e46deb":"class timmDataset:\n    def __init__(self, path, modelcfg=None):\n        \n        self.path = path\n        self.transform = create_transform(**modelcfg)\n        \n        \n    def __len__(self):\n        return len(self.path)\n    \n    def __getitem__(self, item):\n        \n        impath = self.path[item]\n        img = Image.open(impath).convert('RGB')\n        img = self.transform(img) # PIL image\n        return img\n","4c3c906d":"modelname = 'efficientnet_b0'","8a4abcd3":"model = timm.create_model(modelname, pretrained=True)","92a830d7":"model.to(\"cuda\")\nmodel.eval()","a319f294":"model.default_cfg","17ec9dfe":"train_dataset = timmDataset(\n    train[\"path\"],\n    modelcfg = resolve_data_config({},model=modelname)\n)","605e4724":"train_dataset[0]","7047cfda":"train_dataset[0].shape","904d3ba8":"train_dataloader = DataLoader(train_dataset, batch_size=256, num_workers= 2, shuffle=False)","eca6779b":"for a in train_dataloader:\n    print(a)\n    break","bc3941d9":"from tqdm import tqdm","197f6589":"allpreds = []\n\nwith torch.no_grad():\n    for a in tqdm(train_dataloader):\n        preds = model(a.to(\"cuda\"))\n        preds = preds.detach().cpu().numpy()\n        allpreds.append(preds)\n    ","b42c28b8":"len(allpreds)","2532c1e2":"allpreds = np.concatenate(allpreds)\nlen(allpreds)","1ef85f9a":"preddf = pd.DataFrame(allpreds)","a438d0f3":"preddf","0cfb64f1":"import cudf, cuml, cupy\nfrom cuml import UMAP\n","f164a9d6":"umap = UMAP()\nembed_2d = umap.fit_transform(preddf.values)\nembed_2d = cupy.asnumpy( embed_2d )","a9889323":"plt.scatter(embed_2d[:,0],embed_2d[:,1])","d6e6e6ab":"from cuml import KMeans\nkmeans = cuml.KMeans(n_clusters=2)\nkmeans.fit(embed_2d)\ntrain['cluster'] = kmeans.labels_","701f02f7":"plt.scatter(embed_2d[:,0],embed_2d[:,1],c = kmeans.labels_)","ec8581da":"train.head(3)","266ca12d":"tmpdf = train[train[\"cluster\"]==0]\nplt.figure(figsize=(25,25))\n\nfor a in range(25):\n    img = cv2.imread(tmpdf[\"path\"].iloc[a])\n    img = img[:,:,::-1]\n    plt.subplot(5,5,a+1)\n    plt.axis(\"off\")\n    plt.imshow(img)\n","9b07e645":"tmpdf = train[train[\"cluster\"]==1]\nplt.figure(figsize=(25,25))\n\nfor a in range(25):\n    img = cv2.imread(tmpdf[\"path\"].iloc[a])\n    img = img[:,:,::-1]\n    plt.subplot(5,5,a+1)\n    plt.axis(\"off\")\n    plt.imshow(img)\n","ecf77b50":"preddf","786c0340":"from cuml.manifold import TSNE\ntsne = TSNE(n_components=2)\nX_embedded = tsne.fit_transform(preddf.values)","1f18f238":"plt.scatter(X_embedded[:,0],X_embedded[:,1])","ae502d02":"from cuml.neighbors import NearestNeighbors","f68847cf":"KNN = 50\nmodel = NearestNeighbors(n_neighbors=KNN)\nmodel.fit(preddf.values)\ndistances, indices = model.kneighbors(preddf.values)","6d304c04":"distances","c937742f":"indices","803251a8":"indices[0][:6]","4c5c2a65":"plt.figure(figsize=(20,5))\nfor num,a in enumerate(indices[0][:6]):\n    img = cv2.imread(train[\"path\"].iloc[a])\n    img = img[:,:,::-1]\n    \n    title =train[\"Pawpularity\"].iloc[a]\n    plt.subplot(1,6,num+1)\n    plt.imshow(img)\n    plt.axis(\"off\")\n    plt.title(f\"Pawpularity : {title}\")\n","a9ac9825":"preddf","cdd24bed":"predcudf = cudf.from_pandas(preddf)","6948581c":"im_embed_norm = [s \/ cupy.linalg.norm(s) for s in predcudf.values]","df1303f0":"im_embed_norm = cupy.array(im_embed_norm)","976bd395":"cos_sim = cupy.matmul( im_embed_norm, im_embed_norm.T).T","f64e44d9":"cos_sim","4cf68e44":"simdf = cudf.DataFrame(cos_sim)\nsimdf","1d9ebfb5":"simdf = simdf.to_pandas()","dbadac89":"plt.hist(np.concatenate(simdf.values))","7cbea4e5":"similarity_thres = 0.87","03b1d4ab":"similar_index = [cupy.where(s > similarity_thres)[0] for s in cos_sim]","bcb9aee4":"similar_index[:3]","097a7369":"sim_combination = [train.iloc[cupy.asnumpy(s)].index.values for s in similar_index]","ffce89fc":"sim_combination[:3]","76133811":"duplicatejudge = [len(s) > 1 for s in sim_combination]","67624e54":"train[\"combi\"] = sim_combination\ntrain[\"judge\"] = duplicatejudge","07d7da76":"train[\"combi\"] = train[\"combi\"].astype(\"str\")","ec65dae5":"dupdf = train[train[\"judge\"]]\ndupdf = dupdf.sort_values(\"combi\")","9efaddee":"dupdf.head()","071c7683":"for a in range(int(len(dupdf)\/2)):\n    \n    img = cv2.imread(dupdf[\"path\"].iloc[2*a])\n    img2 = cv2.imread(dupdf[\"path\"].iloc[2*a+1])\n    \n    fig = plt.figure(figsize = (10,5))\n    \n    plt.subplot(1,2,1)\n    plt.imshow(img[:,:,::-1])\n    plt.axis(\"off\")\n    \n    score = dupdf[\"Pawpularity\"].iloc[2*a]\n    plt.title(f\"id{dupdf.index[2*a]}. Pawpularity {score}\")\n    \n    \n    plt.subplot(1,2,2)\n    plt.imshow(img2[:,:,::-1])\n    plt.axis(\"off\")\n    \n    score = dupdf[\"Pawpularity\"].iloc[2*a+1]\n    plt.title(f\"id{dupdf.index[2*a+1]}. Pawpularity {score}\")\n    \n    del fig\n    ","87a24be7":"dupdf.to_csv(\"dupdf.csv\",index=False)","4db3cc66":"## this is not good compared to UMAP (poor condition ?)","a6214822":"## maybe dog and cats. check now","198c888a":"## 2.1 Dataset\/Dataloader\n\nFor the basic writing code, I referred to the following notebook.\n\n\nref ) https:\/\/www.kaggle.com\/titericz\/imagenet-embeddings-plus-rapids-svr @GIBA. Thank you very much!","9c60422e":"## cosine similality","b9706a2d":"## Try to put out 5 similar images of no 0","3f17f707":"### pandas \u2192 cudf","945c4585":"# 2. Making Image embedding","7689f8bc":"## np.where(condition) put out the index satisfied with the condition\n\n### you can change the threshold","860e1021":"# 6.Cosign Similarity : extract duplicate image","4c538ac9":"## check histgram","956030a5":"### All dogs !!","1ee6d19d":"## make judge whether duplicate or not","dd93cc45":"## Cluster 0","1a461587":"## cudf \u2192 cupy","7227837a":"## normalization each image embedding","ee95f480":"## All cats !!","e5b5fa1a":"## visualize duplicate image","89a54d4f":"## show 1 image","36395525":"## make combination id","be5d5b6f":"## 2.2 making image embedding with prediction","c7dd49bb":"## it looks good.","271219c9":"## Cluster 1","567ff994":"# 1.Loading train data","040b4d69":"# 4. (Ref) t-SNE : no good case","c359acb4":"# About this notebook\n\nWhen I saw [Chris Deotte's][1] wonderful notebook in Feedback Prize competition,\n\n https:\/\/www.kaggle.com\/cdeotte\/rapids-umap-tfidf-kmeans-discovers-15-topics \n\nI wondered if it could be classified using UMAP for image embedding.\n\nThank you for Chris Deotte! I respect you.\n\nIn this notebook, I showed a result, dogs and cats could be easily classified by using UMAP for image embedding. \n\n[1]:https:\/\/www.kaggle.com\/cdeotte","21fc211f":"# 5.Find similar image knn\n\nThis is also referred from @chris deotte's notebook in Shoppee competition. Thank you so much !\nhttps:\/\/www.kaggle.com\/cdeotte\/rapids-cuml-tfidfvectorizer-and-knn","6516375a":"## cudf \u2192 pandas","126caaeb":"# 0. Import timm","ef92b133":"# 3. UMAP\n(ref : https:\/\/www.kaggle.com\/cdeotte\/rapids-umap-tfidf-kmeans-discovers-15-topics \nthank you for @chris deotte)\n","b64a835f":"## 6.1 normalization"}}