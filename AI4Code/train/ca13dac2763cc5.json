{"cell_type":{"46107471":"code","37983b1d":"code","ababc205":"code","18d7dcf4":"code","224c1abd":"code","07ef2a13":"code","deca6b5f":"code","9f952e20":"code","ef3b1522":"code","aec13c6c":"code","10274e2e":"code","c9fcaaf1":"code","1236b260":"code","cca69787":"code","53875311":"code","d54b9f73":"code","28bf769f":"code","99ae9cef":"code","1a4474d5":"code","d8bea30c":"code","67146e8a":"code","e19f1698":"code","050fd838":"code","0c51e799":"code","eaac1328":"code","7db44477":"code","48ba0ade":"code","640eb69f":"code","44916b90":"code","5e9e1715":"code","325ba56c":"code","2cc9af72":"code","a53f42d1":"code","aaa6010a":"code","c02a8715":"code","4b49fa75":"code","4aeb6393":"code","bded2d60":"code","81a14e99":"code","36a18081":"code","be010dc4":"code","b83311b7":"code","c70708c2":"code","27b8d111":"code","9d7a2532":"code","45b04664":"code","39b4d196":"code","2a3efa82":"markdown","00d2aa9a":"markdown","55b3adcb":"markdown","494f196a":"markdown","434f03b2":"markdown","eb2f8ae7":"markdown","25548ffe":"markdown","344f5f61":"markdown","fb1de1a0":"markdown","bb29ae7f":"markdown","38db13d7":"markdown","388dad69":"markdown","f81a8ff8":"markdown","282a9084":"markdown","b556ef87":"markdown","4ac4dae2":"markdown","63c77fc6":"markdown","6edf4ec4":"markdown","4fb7be08":"markdown","5d220368":"markdown","265dbbad":"markdown","f63daf61":"markdown","f3d648e9":"markdown","0766b34f":"markdown","a29d05a5":"markdown","d7e482a5":"markdown","e4d5056e":"markdown","fe1bad32":"markdown","8f70d1c0":"markdown","f59e6949":"markdown","38c92799":"markdown","8fd00074":"markdown","b7902978":"markdown","ea2a4295":"markdown","3e3de3ed":"markdown","fd999dd8":"markdown","a7593c6f":"markdown","977ae7fb":"markdown","d9e807c4":"markdown","3355c825":"markdown","1c0a5b0d":"markdown","b4864ddf":"markdown","b81c1686":"markdown","1a1c4a44":"markdown","14959adf":"markdown","63e139d8":"markdown","b4379c99":"markdown","27561b7d":"markdown","375778fe":"markdown","070bd7ab":"markdown","4902c9fe":"markdown","cb1bd850":"markdown","8711d93b":"markdown","1c57abd0":"markdown","5c43e2ba":"markdown"},"source":{"46107471":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport os\nimport tempfile\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler","37983b1d":"mpl.rcParams['figure.figsize'] = (12, 10)\ncolors = plt.rcParams['axes.prop_cycle'].by_key()['color']","ababc205":"file = tf.keras.utils\nraw_df = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\nraw_df.head()","18d7dcf4":"raw_df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V26', 'V27', 'V28', 'Amount', 'Class']].describe()","224c1abd":"neg, pos = np.bincount(raw_df['Class'])\ntotal = neg + pos\nprint('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n    total, pos, 100 * pos \/ total))","07ef2a13":"cleaned_df = raw_df.copy()\n\n# You don't want the `Time` column.\ncleaned_df.pop('Time')\n\n# The `Amount` column covers a huge range. Convert to log-space.\neps=0.001 # 0 => 0.1\u00a2\ncleaned_df['Log Ammount'] = np.log(cleaned_df.pop('Amount')+eps)","deca6b5f":"# Use a utility from sklearn to split and shuffle our dataset.\ntrain_df, test_df = train_test_split(cleaned_df, test_size=0.2)\ntrain_df, val_df = train_test_split(train_df, test_size=0.2)\n\n# Form np arrays of labels and features.\ntrain_labels = np.array(train_df.pop('Class'))\nbool_train_labels = train_labels != 0\nval_labels = np.array(val_df.pop('Class'))\ntest_labels = np.array(test_df.pop('Class'))\n\ntrain_features = np.array(train_df)\nval_features = np.array(val_df)\ntest_features = np.array(test_df)","9f952e20":"scaler = StandardScaler()\ntrain_features = scaler.fit_transform(train_features)\n\nval_features = scaler.transform(val_features)\ntest_features = scaler.transform(test_features)\n\ntrain_features = np.clip(train_features, -5, 5)\nval_features = np.clip(val_features, -5, 5)\ntest_features = np.clip(test_features, -5, 5)\n\n\nprint('Training labels shape:', train_labels.shape)\nprint('Validation labels shape:', val_labels.shape)\nprint('Test labels shape:', test_labels.shape)\n\nprint('Training features shape:', train_features.shape)\nprint('Validation features shape:', val_features.shape)\nprint('Test features shape:', test_features.shape)","ef3b1522":"pos_df = pd.DataFrame(train_features[ bool_train_labels], columns = train_df.columns)\nneg_df = pd.DataFrame(train_features[~bool_train_labels], columns = train_df.columns)\n\nsns.jointplot(pos_df['V5'], pos_df['V6'],\n              kind='hex', xlim = (-5,5), ylim = (-5,5))\nplt.suptitle(\"Positive distribution\")\n\nsns.jointplot(neg_df['V5'], neg_df['V6'],\n              kind='hex', xlim = (-5,5), ylim = (-5,5))\n_ = plt.suptitle(\"Negative distribution\")","aec13c6c":"METRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n]\n\ndef make_model(metrics = METRICS, output_bias=None):\n  if output_bias is not None:\n    output_bias = tf.keras.initializers.Constant(output_bias)\n  model = keras.Sequential([\n      keras.layers.Dense(\n          16, activation='relu',\n          input_shape=(train_features.shape[-1],)),\n      keras.layers.Dropout(0.5),\n      keras.layers.Dense(1, activation='sigmoid',\n                         bias_initializer=output_bias),\n  ])\n\n  model.compile(\n      optimizer=keras.optimizers.Adam(lr=1e-3),\n      loss=keras.losses.BinaryCrossentropy(),\n      metrics=metrics)\n\n  return model","10274e2e":"EPOCHS = 100\nBATCH_SIZE = 2048\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_auc', \n    verbose=1,\n    patience=10,\n    mode='max',\n    restore_best_weights=True)","c9fcaaf1":"model = make_model()\nmodel.summary()","1236b260":"#Test run the model\nmodel.predict(train_features[:10])","cca69787":"initial_weights = os.path.join(tempfile.mkdtemp(),'initial_weights')\nmodel.save_weights(initial_weights)","53875311":"model = make_model()\nmodel.load_weights(initial_weights)\nmodel.layers[-1].bias.assign([0.0])\nzero_bias_history = model.fit(\n    train_features,\n    train_labels,\n    batch_size=BATCH_SIZE,\n    epochs=20,\n    validation_data=(val_features, val_labels), \n    verbose=0)","d54b9f73":"model = make_model()\nmodel.load_weights(initial_weights)\ncareful_bias_history = model.fit(\n    train_features,\n    train_labels,\n    batch_size=BATCH_SIZE,\n    epochs=20,\n    validation_data=(val_features, val_labels), \n    verbose=0)","28bf769f":"def plot_loss(history, label, n):\n  # Use a log scale to show the wide range of values.\n  plt.semilogy(history.epoch,  history.history['loss'],\n               color=colors[n], label='Train '+label)\n  plt.semilogy(history.epoch,  history.history['val_loss'],\n          color=colors[n], label='Val '+label,\n          linestyle=\"--\")\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss')\n  \n  plt.legend()","99ae9cef":"plot_loss(zero_bias_history, \"Zero Bias\", 0)\nplot_loss(careful_bias_history, \"Careful Bias\", 1)","1a4474d5":"model = make_model()\nmodel.load_weights(initial_weights)\nbaseline_history = model.fit(\n    train_features,\n    train_labels,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks = [early_stopping],\n    validation_data=(val_features, val_labels))","d8bea30c":"def plot_metrics(history):\n  metrics =  ['loss', 'auc', 'precision', 'recall']\n  for n, metric in enumerate(metrics):\n    name = metric.replace(\"_\",\" \").capitalize()\n    plt.subplot(2,2,n+1)\n    plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n    plt.plot(history.epoch, history.history['val_'+metric],\n             color=colors[0], linestyle=\"--\", label='Val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    if metric == 'loss':\n      plt.ylim([0, plt.ylim()[1]])\n    elif metric == 'auc':\n      plt.ylim([0.8,1])\n    else:\n      plt.ylim([0,1])\n\n    plt.legend()\n","67146e8a":"plot_metrics(baseline_history)","e19f1698":"train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\ntest_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)","050fd838":"def plot_cm(labels, predictions, p=0.5):\n  cm = confusion_matrix(labels, predictions > p)\n  plt.figure(figsize=(5,5))\n  sns.heatmap(cm, annot=True, fmt=\"d\")\n  plt.title('Confusion matrix @{:.2f}'.format(p))\n  plt.ylabel('Actual label')\n  plt.xlabel('Predicted label')\n\n  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n  print('Total Fraudulent Transactions: ', np.sum(cm[1]))","0c51e799":"baseline_results = model.evaluate(test_features, test_labels,\n                                  batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(model.metrics_names, baseline_results):\n  print(name, ': ', value)\nprint()\n\nplot_cm(test_labels, test_predictions_baseline)","eaac1328":"def plot_roc(name, labels, predictions, **kwargs):\n  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n\n  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n  plt.xlabel('False positives [%]')\n  plt.ylabel('True positives [%]')\n  plt.xlim([-0.5,20])\n  plt.ylim([80,100.5])\n  plt.grid(True)\n  ax = plt.gca()\n  ax.set_aspect('equal')","7db44477":"plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\nplot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\nplt.legend(loc='lower right')","48ba0ade":"# Scaling by total\/2 helps keep the loss to a similar magnitude.\n# The sum of the weights of all examples stays the same.\nweight_for_0 = (1 \/ neg)*(total)\/2.0 \nweight_for_1 = (1 \/ pos)*(total)\/2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint('Weight for class 0: {:.2f}'.format(weight_for_0))\nprint('Weight for class 1: {:.2f}'.format(weight_for_1))","640eb69f":"weighted_model = make_model()\nweighted_model.load_weights(initial_weights)\n\nweighted_history = weighted_model.fit(\n    train_features,\n    train_labels,\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks = [early_stopping],\n    validation_data=(val_features, val_labels),\n    # The class weights go here\n    class_weight=class_weight) ","44916b90":"plot_metrics(weighted_history)","5e9e1715":"train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\ntest_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)","325ba56c":"weighted_results = weighted_model.evaluate(test_features, test_labels,\n                                           batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(weighted_model.metrics_names, weighted_results):\n  print(name, ': ', value)\nprint()\n\nplot_cm(test_labels, test_predictions_weighted)","2cc9af72":"plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\nplot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n\nplot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\nplot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n\n\nplt.legend(loc='lower right')","a53f42d1":"# Oversample the minority class\npos_features = train_features[bool_train_labels]\nneg_features = train_features[~bool_train_labels]\n\npos_labels = train_labels[bool_train_labels]\nneg_labels = train_labels[~bool_train_labels]","aaa6010a":"ids = np.arange(len(pos_features))\nchoices = np.random.choice(ids, len(neg_features))\n\nres_pos_features = pos_features[choices]\nres_pos_labels = pos_labels[choices]\n\nres_pos_features.shape","c02a8715":"resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\nresampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n\norder = np.arange(len(resampled_labels))\nnp.random.shuffle(order)\nresampled_features = resampled_features[order]\nresampled_labels = resampled_labels[order]\n\nresampled_features.shape","4b49fa75":"BUFFER_SIZE = 100000\n\ndef make_ds(features, labels):\n  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n  ds = ds.shuffle(BUFFER_SIZE).repeat()\n  return ds\n\npos_ds = make_ds(pos_features, pos_labels)\nneg_ds = make_ds(neg_features, neg_labels)","4aeb6393":"for features, label in pos_ds.take(1):\n  print(\"Features:\\n\", features.numpy())\n  print()\n  print(\"Label: \", label.numpy())","bded2d60":"resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\nresampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)","81a14e99":"for features, label in resampled_ds.take(1):\n  print(label.numpy().mean())","36a18081":"resampled_steps_per_epoch = np.ceil(2.0*neg\/BATCH_SIZE)\nresampled_steps_per_epoch","be010dc4":"resampled_model = make_model()\nresampled_model.load_weights(initial_weights)\n\n# Reset the bias to zero, since this dataset is balanced.\noutput_layer = resampled_model.layers[-1] \noutput_layer.bias.assign([0])\n\nval_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\nval_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n\nresampled_history = resampled_model.fit(\n    resampled_ds,\n    epochs=EPOCHS,\n    steps_per_epoch=resampled_steps_per_epoch,\n    callbacks = [early_stopping],\n    validation_data=val_ds)","b83311b7":"plot_metrics(resampled_history )","c70708c2":"resampled_model = make_model()\nresampled_model.load_weights(initial_weights)\n\n# Reset the bias to zero, since this dataset is balanced.\noutput_layer = resampled_model.layers[-1] \noutput_layer.bias.assign([0])\n\nresampled_history = resampled_model.fit(\n    resampled_ds,\n    # These are not real epochs\n    steps_per_epoch = 20,\n    epochs=10*EPOCHS,\n    callbacks = [early_stopping],\n    validation_data=(val_ds))","27b8d111":"plot_metrics(resampled_history)","9d7a2532":"train_predictions_resampled = resampled_model.predict(train_features, batch_size=BATCH_SIZE)\ntest_predictions_resampled = resampled_model.predict(test_features, batch_size=BATCH_SIZE)","45b04664":"resampled_results = resampled_model.evaluate(test_features, test_labels,\n                                             batch_size=BATCH_SIZE, verbose=0)\nfor name, value in zip(resampled_model.metrics_names, resampled_results):\n  print(name, ': ', value)\nprint()\n\nplot_cm(test_labels, test_predictions_resampled)","39b4d196":"plot_roc(\"Train Baseline\", train_labels, train_predictions_baseline, color=colors[0])\nplot_roc(\"Test Baseline\", test_labels, test_predictions_baseline, color=colors[0], linestyle='--')\n\nplot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\nplot_roc(\"Test Weighted\", test_labels, test_predictions_weighted, color=colors[1], linestyle='--')\n\nplot_roc(\"Train Resampled\", train_labels, train_predictions_resampled,  color=colors[2])\nplot_roc(\"Test Resampled\", test_labels, test_predictions_resampled,  color=colors[2], linestyle='--')\nplt.legend(loc='lower right')","2a3efa82":"### Plot the ROC","00d2aa9a":"### Plot the ROC","55b3adcb":"The goal is to identify fraudulent transactions, but you don't have very many of those positive samples to work with, so you would want to have the classifier heavily weight the few examples that are available. You can do this by passing Keras weights for each class through a parameter. These will cause the model to \"pay more attention\" to examples from an under-represented class","494f196a":"The raw data has a few issues. First the Time and Amount columns are too variable to use directly. Drop the Time column (since it's not clear what it means) and take the log of the Amount column to reduce its range","434f03b2":"To make the various training runs more comparable, keep this initial model's weights in a checkpoint file, and load them into each model before training","eb2f8ae7":"Normalize the input features using the sklearn StandardScaler. This will set the mean to 0 and standard deviation to 1","25548ffe":"![](https:\/\/thumbs.gfycat.com\/PoliteOddHuemul-max-1mb.gif)","344f5f61":"![](https:\/\/thumbs.gfycat.com\/PoliteOddHuemul-max-1mb.gif)","fb1de1a0":"### Look at the data distribution","bb29ae7f":"### Re-train","38db13d7":"### Check training history","388dad69":"# Define the model and metrics","f81a8ff8":"### Train on the oversampled data","282a9084":"### Examine the class label imbalance","b556ef87":"Because training is easier on the balanced data, the above training procedure may overfit quickly.\n\nSo break up the epochs to give the callbacks.EarlyStopping finer control over when to stop training","4ac4dae2":"### Check training history","63c77fc6":"### Evaluate metrics","6edf4ec4":"### Train the model","4fb7be08":"Before moving on, confirm quick that the careful bias initialization actually helped.\n\nTrain the model for 20 epochs, with and without this careful initialization, and compare the losses","5d220368":"There are a few metrics defined above that can be computed by the model that will be helpful when evaluating the performance\n\n- False negatives and false positives are samples that were incorrectly classified\n- True negatives and true positives are samples that were correctly classified\n- Accuracy is the percentage of examples correctly classified \n- Precision is the percentage of predicted positives that were correctly classified\n- Recall is the percentage of actual positives that were correctly classified \n- AUC refers to the Area Under the Curve of a Receiver Operating Characteristic curve (ROC-AUC). This metric is equal to the probability that a classifier will rank a random positive sample higher than a random negative sample","265dbbad":"**The validation curve generally performs better than the training curve. This is mainly caused by the fact that the dropout layer is not active when evaluating the model**","f63daf61":"### Re-check training history","f3d648e9":"Split the dataset into train, validation, and test sets. The validation set is used during the model fitting to evaluate the loss and any metrics, however the model is not fit with this data. The test set is completely unused during the training phase and is only used at the end to evaluate how well the model generalizes to new data. This is especially important with imbalanced datasets where overfitting is a significant concern from the lack of training data","0766b34f":"# Data processing and exploration","a29d05a5":"# Class weights","d7e482a5":"### Checkpoint the initial weights","e4d5056e":"### Clean, split and normalize the data","fe1bad32":"![](https:\/\/lh3.googleusercontent.com\/proxy\/KP0n77r2Qt-u7Cdm8hbyiQsqxtjVt21YoA2ftP0RNDlyS7eix2FYDRgnPlvHaDB04oJQm5pOvl64bMy5Uez2Mmqf8w)","8f70d1c0":"We will Define a function that creates a simple neural network with a densly connected hidden layer, a dropout layer to reduce overfitting, and an output sigmoid layer that returns the probability of a transaction being fraudulent","f59e6949":"We will produce plots of your model's accuracy and loss on the training and validation set. These are useful to check for overfitting.Additionally, we can produce these plots for any of the metrics we created above.","38c92799":"### Confirm that the bias fix helps","8fd00074":"# Oversampling","b7902978":"### Evaluate metrics","ea2a4295":"Merge the two together using experimental.sample_from_datasets","3e3de3ed":"Evaluate our model on the test dataset and display the results for the metrics that we created above","fd999dd8":"**If we had predicted everything perfectly, this would be a diagonal matrix where values off the main diagonal, indicating incorrect predictions, would be zero. In this case the matrix shows that we have relatively few false positives, meaning that there were relatively few legitimate transactions that were incorrectly flagged. However,we would likely want to have even fewer false negatives despite the cost of increasing the number of false positives. This trade off may be preferable because false negatives would allow fraudulent transactions to go through, whereas false positives may cause an email to be sent to a customer to ask them to verify their card activity**","a7593c6f":"Now plot the ROC. This plot is useful because it shows, at a glance, the range of performance the model can reach just by tuning the output threshold","977ae7fb":"# Baseline model","d9e807c4":"### Evaluate metrics","3355c825":"![](https:\/\/i.pinimg.com\/originals\/f4\/44\/93\/f444933e5c9ff754fd4c5bc7a45442cc.gif)","1c0a5b0d":"### Check training history","b4864ddf":"We will see how to classify a highly imbalanced dataset in which the number of examples in one class greatly outnumbers the examples in another.The aim is to detect a mere 492 fraudulent transactions from 284,807 transactions in total. We will use Keras adn Tensorflow to define the model and class weights to help the model learn from the imbalanced data. .\n\nWe will see complete code to:\n\n- Load a CSV file using Pandas.\n- Create train, validation, and test sets.\n- Define and train a model using Keras (including setting class weights).\n- Evaluate the model using various metrics (including precision and recall).\n-  Try common techniques for dealing with imbalanced data like\n- Class weighting\n- Oversampling","b81c1686":"### Using NumPy","1a1c4a44":"### Train a model with class weights","14959adf":"## --------------------If you found this helpful, do upvote please------------------","63e139d8":"![](https:\/\/thumbs.gfycat.com\/PoliteOddHuemul-max-1mb.gif)","b4379c99":"**If the training process were considering the whole dataset on each gradient update, this oversampling would be basically identical to the class weighting**\n\n**But when training the model batch-wise, as you did here, the oversampled data provides a smoother gradient signal: Instead of each positive example being shown in one batch with a large weight, they're shown in many different batches each time with a small weight**\n\n**This smoother gradient signal makes it easier to train the model**","27561b7d":"The above figure makes it clear: In terms of validation loss, on this problem, this careful initialization gives a clear advantage","375778fe":"![](https:\/\/thumbs.gfycat.com\/PoliteOddHuemul-max-1mb.gif)","070bd7ab":"We will compare the distributions of the positive and negative examples over a few features","4902c9fe":"### Using tf.data","cb1bd850":"If we're using tf.data the easiest way to produce balanced examples is to start with a positive and a negative dataset, and merge them","8711d93b":"### Plot the ROC","1c57abd0":"**It looks like the precision is relatively high, but the recall and the area under the ROC curve (AUC) aren't as high as you might like. Classifiers often face challenges when trying to maximize both precision and recall, which is especially true when working with imbalanced datasets. It is important to consider the costs of different types of errors in the context of the problem we care about. In this example, a false negative (a fraudulent transaction is missed) may have a financial cost, while a false positive (a transaction is incorrectly flagged as fraudulent) may decrease user happiness**","5c43e2ba":"###  Understanding useful metrics"}}