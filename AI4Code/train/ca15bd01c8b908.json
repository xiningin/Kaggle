{"cell_type":{"06dd1b14":"code","e0bd4249":"code","e2e1b96e":"code","0071648f":"code","1dde3dcb":"code","aa9fc07b":"code","efcc4ebb":"code","d443ddd5":"code","726b78c4":"code","7102ef1c":"code","cf60ef88":"code","e1ff82bf":"code","fcdb3a96":"code","bc79760f":"code","0c0e57ef":"code","8f1b29a3":"markdown","870aa9b6":"markdown"},"source":{"06dd1b14":"import librosa\nimport librosa.display\nimport IPython.display\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport matplotlib.font_manager as fm\nimport pandas as pd\nimport scipy as sklearn\n\nimport os","e0bd4249":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nimport torchvision\nimport torchvision.transforms as transforms\nimport random","e2e1b96e":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nrandom.seed(777)\ntorch.manual_seed(777)\nif device =='cuda':\n    torch.cuda.manual_seed_all(777)","0071648f":"trans = transforms.Compose([\n    transforms.ToTensor(), #\ud559\uc2b5\uc744 \uc704\ud574 dataset\ub4e4\uc744 \ud150\uc11c\ub85c \uc804\ud658\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_data = torchvision.datasets.ImageFolder(root='..\/input\/music-genres-classification\/train_mfcc', transform=trans)\ntest_data = torchvision.datasets.ImageFolder(root='..\/input\/music-genres-classification\/test_mfcc', transform=trans)","1dde3dcb":"batch_size = 200\ndata_loader = DataLoader(dataset = train_data, \n                         batch_size = batch_size, \n                         shuffle = True, \n                         num_workers=2, # \ub370\uc774\ud130\ub97c \ube68\ub9ac \uc77d\uc5b4\uc624\uae30 \uc704\ud55c\uac83\n                         drop_last=True)","aa9fc07b":"import matplotlib.pyplot as plt\n# plt.imshow(data_loader.dataset[0][0].numpy().reshape((28,28,3)))\nplt.imshow(data_loader.dataset[0][0].numpy().transpose(2,1,0)) ## 3,28,28 -> 28,28,3\nplt.show() #normal\uc744\ud574\uc11c \uc6d0\ubcf8\uc0ac\uc9c4\uacfc \uc0c9\uc758 \ucc28\uc774\uac00 \uc788\uc2b4\nplt.imshow(torch.transpose(data_loader.dataset[0][0], 2, 0)) \nplt.show()\n# print(data_loader.dataset[0][0].numpy())","efcc4ebb":"test_set = DataLoader(dataset = test_data, \n                      batch_size = len(test_data),\n                      shuffle=False)","d443ddd5":"class MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        \n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1), \n            nn.MaxPool2d(kernel_size=2, stride=2), \n            nn.ReLU()\n        )\n\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), \n            nn.MaxPool2d(kernel_size=2, stride=2), \n            nn.ReLU()\n        )\n\n        self.fc = nn.Sequential(\n            nn.Linear(64*7*7, 128, bias=True),\n            nn.ReLU(),\n#             nn.Dropout(p=0.3),\n            nn.Linear(128, 10, bias=True)\n        )\n        \n        torch.nn.init.xavier_uniform_(self.fc[0].weight)\n        torch.nn.init.xavier_uniform_(self.fc[2].weight)\n        \n    def forward(self, x):\n        return self.fc(self.layer2(self.layer1(x)).view(-1, 64*7*7))","726b78c4":"model = MyModel().to(device)","7102ef1c":"loss = torch.nn.CrossEntropyLoss().to(device) \noptimizer = torch.optim.Adam(model.parameters(), lr=0.01) ","cf60ef88":"total_batch = len(data_loader)\nmodel.train()\nfor epoch in range(50+1):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n        X = X.to(device)\n        # one-hot encoding\ub418\uc5b4 \uc788\uc9c0 \uc54a\uc74c\n        Y = Y.to(device)\n      \n        optimizer.zero_grad()\n        hypothesis = model(X) #forward \uacc4\uc0b0\n        cost = loss(hypothesis, Y) #cost\n        cost.backward() #backpropagation\n        optimizer.step() #\uac31\uc2e0\n\n        avg_cost += cost \/ total_batch #\ud3c9\uade0 error\n    if epoch % 5==0:\n        print('Epoch:', '%04d' % (epoch), 'cost =', '{:.9f}'.format(avg_cost,))\n            \n\nprint('Learning finished')","e1ff82bf":"with torch.no_grad():\n    model.eval()\n    for _, data in enumerate(test_set):\n        imgs, label = data\n#                 print(len(imgs), len(label))\n        imgs = imgs.to(device)\n        label = label.to(device)\n\n        prediction = model(imgs)\n\n        correct_prediction = torch.argmax(prediction, 1) == label\n\n        accuracy = correct_prediction.float().mean()\n        print(accuracy.item())","fcdb3a96":"submit=pd.read_csv('..\/input\/music-genres-classification\/submition_form.csv')","bc79760f":"submit['label'] = torch.argmax(prediction, 1).cpu().numpy()\nsubmit.to_csv('submission.csv',index=False, header=True)","0c0e57ef":"submit","8f1b29a3":"## \ud559\uc2b5 \uc2dc\uc791","870aa9b6":"## \uc131\ub2a5 \uacc4\uc0b0"}}