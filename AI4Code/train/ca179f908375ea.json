{"cell_type":{"0d95c57f":"code","72166b86":"code","9f295deb":"code","52c02c40":"code","15f53106":"code","abf11ff2":"code","1fd5406d":"code","87513f3b":"code","0ce29b8b":"code","31ce3218":"code","6bcfc82b":"code","eb874815":"code","cafc774d":"code","cc23bf0c":"code","f87f6742":"code","2bbbff07":"code","a08ce3aa":"code","e51eb9fc":"code","91813c1e":"markdown","74871527":"markdown","2f21d596":"markdown","cb178512":"markdown","7338e37a":"markdown"},"source":{"0d95c57f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# importing matplotlib\nimport matplotlib.pyplot as plt\n# display plots in the notebook itself\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_absolute_error as MAE\nfrom tqdm import tqdm\n\n","72166b86":"#read the data\ntrain = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/train.csv')\ntest  = pd.read_csv('\/kaggle\/input\/30-days-of-ml\/test.csv')\ntrain = train.drop(['id'],axis=1)\nid = test.id\ntest = test.drop(['id'],axis=1)\ntest.head()","9f295deb":"s = (train.dtypes == 'object')\nobject_cols = list(s[s].index)\ncols= list(train.columns)[:-1]","52c02c40":"#Converting categorical to numerical data\nfrom sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\ntrain[object_cols]=ordinal_encoder.fit_transform(train[object_cols])\n\n\ntest[object_cols]=ordinal_encoder.fit_transform(test[object_cols])\ntest","15f53106":"# segregate the the dependent and independent variable\ny = train.target\nX = train.drop(['target'], axis=1)\ntrain.shape, test.shape","abf11ff2":"# # Divide data into training and validation subsets\n# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.9, test_size=0.1,\n#                                                                 random_state=0)\n","1fd5406d":"# Scaling the features\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\n# X_train_Scaled = scaler.fit_transform(X_train)\n# X_train_Scaled = pd.DataFrame(X_train_Scaled, columns = cols)\n\n# X_valid_Scaled = scaler.fit_transform(X_valid)\n# X_valid_Scaled = pd.DataFrame(X_valid_Scaled,columns = cols)\n\ntest_scaled = scaler.fit_transform(test)\ntest_scaled = pd.DataFrame(test_scaled,columns = cols)\n\nX_train_Scaled = scaler.fit_transform(X)\nX_train_Scaled = pd.DataFrame(X_train_Scaled, columns = cols)","87513f3b":"import torch","0ce29b8b":"x_train = torch.FloatTensor(X_train_Scaled.values)\ny_train = torch.FloatTensor(y.values)\nx_test = torch.FloatTensor(test_scaled.values)\n# x_valid = torch.FloatTensor(X_valid_Scaled.values)\n\n# y_valid = torch.FloatTensor(y_valid.values)","31ce3218":"import torch.nn as nn\nfrom torch.nn import Linear,Sigmoid,Sequential,ReLU\nfrom torch.nn import BatchNorm1d, Dropout","6bcfc82b":"class Net(nn.Module):\n    \n    def __init__(self):\n        super(Net,self). __init__()\n        \n        self.linear_layers = Sequential(\n            Linear(x_train.shape[1],10),\n            ReLU(),\n            BatchNorm1d(10),\n            Linear(10, 5),\n            ReLU(),\n            Linear(5,1),\n            ReLU()\n        )\n    def forward(self,x):\n        x = self.linear_layers(x)\n        return x\n        ","eb874815":"from torch.nn import MSELoss\nfrom torch.optim import Adam","cafc774d":"torch.manual_seed(42)\nmodel = Net()\noptimizer = Adam(model.parameters(),lr=0.02)\ncriterion = MSELoss()\n\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\nprint(model)","cc23bf0c":"batch_size = 256\nfor epoch in tqdm(range(81)):\n    train_loss = 0.0\n    permutation = torch.randperm(x_train.size()[0])\n    training_loss = []\n    for i in range(0,x_train.size()[0],batch_size):\n        model.train()\n        indices = permutation[i:i+batch_size]\n        batch_x, batch_y = x_train[indices],y_train[indices]\n        if torch.cuda.is_available():\n            batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n        optimizer.zero_grad()\n        \n        outputs = model(batch_x)\n        loss = criterion(outputs,batch_y)\n        training_loss.append(loss.item())\n        loss.backward()\n        optimizer.step()\n    training_loss = np.average(training_loss)\n    if epoch%10 ==0:\n        print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)","f87f6742":"test_prediction =[]\nfor i in tqdm(range(0,x_test.size()[0],batch_size)):\n    model.eval()\n    batch_x = x_test[i:i+batch_size]\n   \n    if torch.cuda.is_available():\n        batch_x = batch_x.cuda()\n    with torch.no_grad():\n        output = model(batch_x).data.cpu()\n        \n    test_prediction.extend(output)\n    \n    ","2bbbff07":"list1 = []\nfor i in test_prediction:\n    list1.extend(i.numpy())\npredictions=np.array(list1)","a08ce3aa":"predictions","e51eb9fc":"# Save test predictions to file\noutput = pd.DataFrame({'Id': id,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","91813c1e":"> # Evalution","74871527":"# Compile the model","2f21d596":"# DeepLearning Pythorch","cb178512":"# Training The Model","7338e37a":"# Defining the architecture"}}