{"cell_type":{"d450ebbe":"code","f6c461f1":"code","e1c2d406":"code","a7dcb744":"code","3e4eeb60":"code","2a46944a":"code","9d7b7ea2":"code","f656b9c3":"code","50a96209":"code","d50df3f8":"code","9e4be903":"code","727cb3c5":"code","a4f953a1":"code","e01c54e8":"code","706ff0b2":"code","71d01809":"code","346e77cc":"code","0a7a63f0":"code","4971b231":"code","4fc5f5f5":"code","feae44e3":"code","b3a7528d":"code","8280b900":"code","7538cae8":"code","3191d8f1":"code","2f1d327c":"code","30b3a97c":"code","f9d64d6a":"code","efadb177":"code","05b774d4":"code","f865bbe0":"markdown","187aeef1":"markdown","ba4b71e1":"markdown","b49d017a":"markdown","dab24fc2":"markdown","073cd321":"markdown","4b669c07":"markdown","87a75ff8":"markdown","8177ebdd":"markdown","775a8de7":"markdown","1c1350eb":"markdown","b1d73ca7":"markdown","619ea5c6":"markdown","484cfb97":"markdown","b888a5f1":"markdown","622fdedd":"markdown","65b7ccfe":"markdown","80cf5ae3":"markdown","3313e30e":"markdown","da08e12c":"markdown","09935ba6":"markdown","be7884e6":"markdown","0e802dcf":"markdown","bc544074":"markdown","fef0e167":"markdown","be4cb768":"markdown","0c7e7cad":"markdown","01295f71":"markdown","c8623c69":"markdown","bcfed877":"markdown","87b2c250":"markdown"},"source":{"d450ebbe":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","f6c461f1":"cpt=0\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        cpt+=1\n        print(os.path.join(dirname, filename))\n        if cpt >5:\n            break\n","e1c2d406":"# Distribution graphs (histogram\/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) \/ nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()\n","a7dcb744":"# Correlation matrix\ndef plotCorrelationMatrix(df, graphWidth):\n    filename = df.dataframeName\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()\n","3e4eeb60":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()\n","2a46944a":"nRowsRead = 50 # specify 'None' if want to read whole file\n# dev_sent_emo.csv may have more rows in reality, but we are only loading\/previewing the first 1000 rows\ndf1 = pd.read_csv('..\/input\/meld-dataset\/MELD-RAW\/MELD.Raw\/dev_sent_emo.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'dev_sent_emo.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","9d7b7ea2":"df1.head(5)","f656b9c3":"plotPerColumnDistribution(df1, 10, 5)","50a96209":"plotCorrelationMatrix(df1, 8)","d50df3f8":"plotScatterMatrix(df1, 15, 10)","9e4be903":"nRowsRead = 50 # specify 'None' if want to read whole file\n# test_sent_emo.csv may have more rows in reality, but we are only loading\/previewing the first 1000 rows\ndf2 = pd.read_csv('..\/input\/meld-dataset\/MELD-RAW\/MELD.Raw\/test_sent_emo.csv', delimiter=',', nrows = nRowsRead)\ndf2.dataframeName = 'test_sent_emo.csv'\nnRow, nCol = df2.shape\nprint(f'There are {nRow} rows and {nCol} columns')","727cb3c5":"df2.head(5)","a4f953a1":"plotPerColumnDistribution(df2, 10, 5)","e01c54e8":"plotCorrelationMatrix(df2, 8)","706ff0b2":"plotScatterMatrix(df2, 15, 10)","71d01809":"nRowsRead = 50 # specify 'None' if want to read whole file\n# train_sent_emo.csv may have more rows in reality, but we are only loading\/previewing the first 1000 rows\ndf3 = pd.read_csv('..\/input\/meld-dataset\/MELD-RAW\/MELD.Raw\/train\/train_sent_emo.csv', delimiter=',', nrows = nRowsRead)\ndf3.dataframeName = 'train_sent_emo.csv'\nnRow, nCol = df3.shape\nprint(f'There are {nRow} rows and {nCol} columns')","346e77cc":"df3.head(5)","0a7a63f0":"plotPerColumnDistribution(df3, 10, 5)","4971b231":"plotCorrelationMatrix(df3, 8)","4fc5f5f5":"plotScatterMatrix(df3, 15, 10)","feae44e3":"!git clone https:\/\/github.com\/declare-lab\/MELD.git","b3a7528d":"!python \/kaggle\/input\/meld-files\/baseline.py -classify Emotion -modality audio -train -epochs 2 -output_file \".\/\" -direc \"\/kaggle\/input\/meld-dataset\/MELD-Features-Models\/MELD.Features.Models\" ","8280b900":"!python ..\/input\/meld-files\/baseline.py  -classify Emotion -modality text -train -epochs 2  -output_file \".\/\" -direc \"\/kaggle\/input\/meld-dataset\/MELD-Features-Models\/MELD.Features.Models\/\" ","7538cae8":"!python ..\/input\/meld-files\/baseline.py  -classify Emotion -modality bimodal -train  -epochs 2 -output_file \".\/\" -direc \"\/kaggle\/input\/meld-dataset\/MELD-Features-Models\/MELD.Features.Models\" ","3191d8f1":"%cp -arfv ..\/input\/meld-files\/baseline_1.py  ..\/input\/meld-files\/data_helpers_1.py .\/","2f1d327c":"from baseline_1 import *\n\n\ndef train_model(self):\n\n    checkpoint = ModelCheckpoint(os.path.join(self.output_file,\"models\"), monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n\n    if self.modality == \"audio\":\n        model = self.get_audio_model()\n        model.compile(optimizer='adadelta', loss='categorical_crossentropy', sample_weight_mode='temporal', metrics=['accuracy'])\n    elif self.modality == \"text\":\n        model = self.get_text_model()\n        model.compile(optimizer='adadelta', loss='categorical_crossentropy', sample_weight_mode='temporal', metrics=['accuracy'])\n    elif self.modality == \"bimodal\":\n        model = self.get_bimodal_model()\n        model.compile(optimizer='adam', loss='categorical_crossentropy', sample_weight_mode='temporal', metrics=['accuracy'])\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n    model.fit(self.train_x, self.train_y,\n                    epochs=2,\n                    batch_size=self.batch_size,\n                    sample_weight=self.train_mask,\n                    shuffle=True, \n                    callbacks=[early_stopping, checkpoint],\n                    validation_data=(self.val_x, self.val_y, self.val_mask))\n\n    test_model(self)\n\n\n\ndef test_model(self):\n\n    model = load_model(self.PATH)\n    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(\"utter\").output)\n\n    intermediate_output_train = intermediate_layer_model.predict(self.train_x)\n    intermediate_output_val = intermediate_layer_model.predict(self.val_x)\n    intermediate_output_test = intermediate_layer_model.predict(self.test_x)\n    pickle.dump([self.train_x, self.train_y,self.val_x, self.val_y, self.test_x, self.test_y], open(os.path.join(self.output_file,\"X_{}.pkl\".format(self.modality)), \"wb\"))\n    train_emb, val_emb, test_emb = {}, {}, {}\n    for idx, ID in enumerate(self.train_id):\n        train_emb[ID] = intermediate_output_train[idx]\n    for idx, ID in enumerate(self.val_id):\n        val_emb[ID] = intermediate_output_val[idx]\n    for idx, ID in enumerate(self.test_id):\n        test_emb[ID] = intermediate_output_test[idx]\n    pickle.dump([train_emb, val_emb, test_emb], open(os.path.join(self.output_file,\"emb_{}.pkl\".format(self.modality)), \"wb\"))\n\n    self.calc_test_result(model.predict(self.test_x), self.test_y, self.test_mask)\n\n\n# -classify\", help=\"Set the classifiction to be 'Emotion' or 'Sentiment'\", required=True)\n# -modality\", help=\"Set the modality to be 'text' or 'audio' or 'bimodal'\", required=True)\n# -direc\", help=\"Set directory of models and features\", required=True)\n# -output_file\", help=\"Set output_file\", required=True)\n# -train\", default=False, action=\"store_true\" , help=\"Flag to intiate training\")\n# -test\", default=False, action=\"store_true\" , help=\"Flag to initiate testing\")\nclassify= \"Emotion\" # or \"Sentiment\" \nmodality = 'text' # or 'audio' or 'bimodal'\"\noutput_file = \".\/\"\ndirec = \"\/kaggle\/input\/meld-dataset\/MELD-Features-Models\/MELD.Features.Models\/\"\ntrain=True # or False if you want to test existed model  and show result and save the features of this model\n\nif train == True:\n    test = False\nelse :\n    test = True\n    \n\n    \n\nif classify.lower() not in [\"emotion\", \"sentiment\"]:\n    print(\"Classification mode hasn't been set properly. Please set the classifiction flag to be: -classify Emotion\/Sentiment\")\n    exit()\nif modality.lower() not in [\"text\", \"audio\", \"bimodal\"]:\n    print(\"Modality hasn't been set properly. Please set the modality flag to be: -modality text\/audio\/bimodal\")\n    exit()\n\nclassify = classify.title()\nmodality = modality.lower()\n\n# Check directory existence\nfor directory in [os.path.join(output_file, \"features\"), os.path.join(output_file, \"models\")]:\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\nargs={\n        \"classify\": classify, # or \"Sentiment\" \n        \"modality\" : modality, # or 'audio' or 'bimodal'\"\n        \"output_file\" : output_file,\n        \"direc\" : direc\n    }\n\nmodel = bc_LSTM(args)\nmodel.load_data()\n\n\nif test:\n    test_model(model)\nelse:\n    train_model(model)\n","30b3a97c":"from baseline_1 import *\n\n\ndef train_model(self):\n\n    checkpoint = ModelCheckpoint(os.path.join(self.output_file,\"models\"), monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n\n    if self.modality == \"audio\":\n        model = self.get_audio_model()\n        model.compile(optimizer='adadelta', loss='categorical_crossentropy', sample_weight_mode='temporal', metrics=['accuracy'])\n    elif self.modality == \"text\":\n        model = self.get_text_model()\n        model.compile(optimizer='adadelta', loss='categorical_crossentropy', sample_weight_mode='temporal', metrics=['accuracy'])\n    elif self.modality == \"bimodal\":\n        model = self.get_bimodal_model()\n        model.compile(optimizer='adam', loss='categorical_crossentropy', sample_weight_mode='temporal', metrics=['accuracy'])\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n    model.fit(self.train_x, self.train_y,\n                    epochs=2,\n                    batch_size=self.batch_size,\n                    sample_weight=self.train_mask,\n                    shuffle=True, \n                    callbacks=[early_stopping, checkpoint],\n                    validation_data=(self.val_x, self.val_y, self.val_mask))\n\n    test_model(self)\n\n\n\ndef test_model(self):\n\n    model = load_model(self.PATH)\n    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(\"utter\").output)\n\n    intermediate_output_train = intermediate_layer_model.predict(self.train_x)\n    intermediate_output_val = intermediate_layer_model.predict(self.val_x)\n    intermediate_output_test = intermediate_layer_model.predict(self.test_x)\n    pickle.dump([self.train_x, self.train_y,self.val_x, self.val_y, self.test_x, self.test_y], open(os.path.join(self.output_file,\"X_{}.pkl\".format(self.modality)), \"wb\"))\n    train_emb, val_emb, test_emb = {}, {}, {}\n    for idx, ID in enumerate(self.train_id):\n        train_emb[ID] = intermediate_output_train[idx]\n    for idx, ID in enumerate(self.val_id):\n        val_emb[ID] = intermediate_output_val[idx]\n    for idx, ID in enumerate(self.test_id):\n        test_emb[ID] = intermediate_output_test[idx]\n    pickle.dump([train_emb, val_emb, test_emb], open(os.path.join(self.output_file,\"emb_{}.pkl\".format(self.modality)), \"wb\"))\n\n    self.calc_test_result(model.predict(self.test_x), self.test_y, self.test_mask)\n\n\n# -classify\", help=\"Set the classifiction to be 'Emotion' or 'Sentiment'\", required=True)\n# -modality\", help=\"Set the modality to be 'text' or 'audio' or 'bimodal'\", required=True)\n# -direc\", help=\"Set directory of models and features\", required=True)\n# -output_file\", help=\"Set output_file\", required=True)\n# -train\", default=False, action=\"store_true\" , help=\"Flag to intiate training\")\n# -test\", default=False, action=\"store_true\" , help=\"Flag to initiate testing\")\nclassify= \"Emotion\" # or \"Sentiment\" \nmodality = 'audio' # or 'audio' or 'bimodal'\"\noutput_file = \".\/\"\ndirec = \"\/kaggle\/input\/meld-dataset\/MELD-Features-Models\/MELD.Features.Models\/\"\ntrain=True # or False if you want to test existed model  and show result and save the features of this model\n\nif train == True:\n    test = False\nelse :\n    test = True\n    \n\n    \n\nif classify.lower() not in [\"emotion\", \"sentiment\"]:\n    print(\"Classification mode hasn't been set properly. Please set the classifiction flag to be: -classify Emotion\/Sentiment\")\n    exit()\nif modality.lower() not in [\"text\", \"audio\", \"bimodal\"]:\n    print(\"Modality hasn't been set properly. Please set the modality flag to be: -modality text\/audio\/bimodal\")\n    exit()\n\nclassify = classify.title()\nmodality = modality.lower()\n\n# Check directory existence\nfor directory in [os.path.join(output_file, \"features\"), os.path.join(output_file, \"models\")]:\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\nargs={\n        \"classify\": classify, # or \"Sentiment\" \n        \"modality\" : modality, # or 'audio' or 'bimodal'\"\n        \"output_file\" : output_file,\n        \"direc\" : direc\n    }\n\nmodel = bc_LSTM(args)\nmodel.load_data()\n\n\nif test:\n    test_model(model)\nelse:\n    train_model(model)\n","f9d64d6a":"from baseline_1 import *\n\n\ndef train_model(self):\n\n    checkpoint = ModelCheckpoint(os.path.join(self.output_file,\"models\"), monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n\n    if self.modality == \"audio\":\n        model = self.get_audio_model()\n        model.compile(optimizer='adadelta', loss='categorical_crossentropy', sample_weight_mode='temporal', metrics=['accuracy'])\n    elif self.modality == \"text\":\n        model = self.get_text_model()\n        model.compile(optimizer='adadelta', loss='categorical_crossentropy', sample_weight_mode='temporal', metrics=['accuracy'])\n    elif self.modality == \"bimodal\":\n        model = self.get_bimodal_model()\n        model.compile(optimizer='adam', loss='categorical_crossentropy', sample_weight_mode='temporal', metrics=['accuracy'])\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n    model.fit(self.train_x, self.train_y,\n                    epochs=2,\n                    batch_size=self.batch_size,\n                    sample_weight=self.train_mask,\n                    shuffle=True, \n                    callbacks=[early_stopping, checkpoint],\n                    validation_data=(self.val_x, self.val_y, self.val_mask))\n\n    test_model(self)\n\n\n\ndef test_model(self):\n\n    model = load_model(self.PATH)\n    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(\"utter\").output)\n\n    intermediate_output_train = intermediate_layer_model.predict(self.train_x)\n    intermediate_output_val = intermediate_layer_model.predict(self.val_x)\n    intermediate_output_test = intermediate_layer_model.predict(self.test_x)\n    pickle.dump([self.train_x, self.train_y,self.val_x, self.val_y, self.test_x, self.test_y], open(os.path.join(self.output_file,\"X_{}.pkl\".format(self.modality)), \"wb\"))\n    train_emb, val_emb, test_emb = {}, {}, {}\n    for idx, ID in enumerate(self.train_id):\n        train_emb[ID] = intermediate_output_train[idx]\n    for idx, ID in enumerate(self.val_id):\n        val_emb[ID] = intermediate_output_val[idx]\n    for idx, ID in enumerate(self.test_id):\n        test_emb[ID] = intermediate_output_test[idx]\n    pickle.dump([train_emb, val_emb, test_emb], open(os.path.join(self.output_file,\"emb_{}.pkl\".format(self.modality)), \"wb\"))\n\n    self.calc_test_result(model.predict(self.test_x), self.test_y, self.test_mask)\n\n\n# -classify\", help=\"Set the classifiction to be 'Emotion' or 'Sentiment'\", required=True)\n# -modality\", help=\"Set the modality to be 'text' or 'audio' or 'bimodal'\", required=True)\n# -direc\", help=\"Set directory of models and features\", required=True)\n# -output_file\", help=\"Set output_file\", required=True)\n# -train\", default=False, action=\"store_true\" , help=\"Flag to intiate training\")\n# -test\", default=False, action=\"store_true\" , help=\"Flag to initiate testing\")\nclassify= \"Emotion\" # or \"Sentiment\" \nmodality = 'bimodal' # or 'audio' or 'bimodal'\"\noutput_file = \".\/\"\ndirec = \"\/kaggle\/input\/meld-dataset\/MELD-Features-Models\/MELD.Features.Models\/\"\ntrain=True # or False if you want to test existed model  and show result and save the features of this model\n\nif train == True:\n    test = False\nelse :\n    test = True\n    \n\n    \n\nif classify.lower() not in [\"emotion\", \"sentiment\"]:\n    print(\"Classification mode hasn't been set properly. Please set the classifiction flag to be: -classify Emotion\/Sentiment\")\n    exit()\nif modality.lower() not in [\"text\", \"audio\", \"bimodal\"]:\n    print(\"Modality hasn't been set properly. Please set the modality flag to be: -modality text\/audio\/bimodal\")\n    exit()\n\nclassify = classify.title()\nmodality = modality.lower()\n\n# Check directory existence\nfor directory in [os.path.join(output_file, \"features\"), os.path.join(output_file, \"models\")]:\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\nargs={\n        \"classify\": classify, # or \"Sentiment\" \n        \"modality\" : modality, # or 'audio' or 'bimodal'\"\n        \"output_file\" : output_file,\n        \"direc\" : direc\n    }\n\nmodel = bc_LSTM(args)\nmodel.load_data()\n\n\nif test:\n    test_model(model)\nelse:\n    train_model(model)\n","efadb177":"import pickle\nfilepath = \".\/X_audio.pkl\"\ntrain_x_a, train_y_a, val_x_a, val_y_a , test_x_a, test_y_a  = pickle.load(open(filepath, 'rb'))\n\nfilepath = \".\/X_text.pkl\"\ntrain_x_t, train_y_t, val_x_t, val_y_t , test_x_t, test_y_t  = pickle.load(open(filepath, 'rb'))\n\nfilepath = \".\/X_bimodal.pkl\"\ntrain_x_b, train_y_b, val_x_b, val_y_b , test_x_b, test_y_b   = pickle.load(open(filepath, 'rb'))","05b774d4":"import pickle\nfilepath = \".\/emb_audio.pkl\"\ntrain_emb_a, val_emb_a, test_emb_a  = pickle.load(open(filepath, 'rb'))\n\nfilepath = \".\/emb_text.pkl\"\ntrain_emb_t, val_emb_t, test_emb_t  = pickle.load(open(filepath, 'rb'))\n\nfilepath = \".\/emb_bimodal.pkl\"\ntrain_emb_b, val_emb_b, test_emb_b  = pickle.load(open(filepath, 'rb'))\n","f865bbe0":"## **Bimodal modality**\n-classify Emotion","187aeef1":"### Let's check 2nd file: \/kaggle\/input\/MELD-RAW\/MELD.Raw\/test_sent_emo.csv","ba4b71e1":"Let's take a quick look at what the data looks like:","b49d017a":"## **for read thies files  X_audio.pkl, X_text.pkl and X_bimodal.pkl**","dab24fc2":"Let's take a quick look at what the data looks like:","073cd321":"Distribution graphs (histogram\/bar graph) of sampled columns:","4b669c07":"**To simplify the importation files we will copy these files in the current directory**","87a75ff8":"Correlation matrix:","8177ebdd":"Let's take a quick look at what the data looks like:","775a8de7":"### Let's check 1st file: \/kaggle\/input\/MELD-RAW\/MELD.Raw\/dev_sent_emo.csv","1c1350eb":"# **The first way to run your program with the default parameters**\nlike epoch=100,\nbatch_size=50,\nand so on ","b1d73ca7":"## **Text modality**\n-classify Emotion","619ea5c6":"# Introduction\n## **This tutorial lets you how to read MELD and start exploring and training it.**\n\nMELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversation has been accepted as a full paper at ACL 2019.\nThe updated paper can be found here - https:\/\/arxiv.org\/pdf\/1810.02508.pdf\n\nGithub:\n\nMELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversation\nhttps:\/\/github.com\/declare-lab\/MELD\/\n \nIf you're inspired to dig deeper, click the blue \"Fork Notebook\" button at the top of this kernel to begin editing.","484cfb97":"The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code.","b888a5f1":"# **The second way to run your program with more control**","622fdedd":"Distribution graphs (histogram\/bar graph) of sampled columns:","65b7ccfe":"## **Text Modality**\n-classify Emotion","80cf5ae3":"## **Bimodal Modality**\n-classify Emotion","3313e30e":"Scatter and density plots:","da08e12c":"## Exploratory Analysis\nTo begin this exploratory analysis, first import libraries and define functions for plotting the data using `matplotlib`. Depending on the data, not all plots will be made. (Hey, I'm just a simple kerneling bot, not a Kaggle Competitions Grandmaster!)","09935ba6":"There are 3 csv files in the current version of the dataset:\n","be7884e6":"## **Audio modality**\n-classify Emotion","0e802dcf":"## **Audio Modality**\n-classify Emotion","bc544074":"### Let's check 3rd file: \/kaggle\/input\/MELD-RAW\/MELD.Raw\/train\/train_sent_emo.csv","fef0e167":"## The Implementation of Multimodal EmotionLines Dataset (MELD)\n","be4cb768":"Correlation matrix:","0c7e7cad":"Now you're ready to read in the data and use the plotting functions to visualize the data.","01295f71":"Correlation matrix:","c8623c69":"Scatter and density plots:","bcfed877":"Distribution graphs (histogram\/bar graph) of sampled columns:","87b2c250":"Scatter and density plots:"}}