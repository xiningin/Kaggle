{"cell_type":{"282c37d4":"code","6be65ab5":"code","b179b71d":"code","399fb740":"code","39119f5b":"code","4643a769":"code","ad6a390b":"code","6feb279c":"code","f89397b0":"markdown","3489cd6d":"markdown","9c0163d8":"markdown","78b33b3c":"markdown","e24987d5":"markdown","1e980e09":"markdown","21a5b2a2":"markdown","4a3f99b3":"markdown"},"source":{"282c37d4":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np","6be65ab5":"training_set_path = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\ntest_set_path = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\nwith open(training_set_path) as training_file:\n    file = np.loadtxt(training_file, dtype=list, delimiter=',')\n    #the first column of each row contains training label.\n    training_labels = file[1:29401,0].astype('int32')\n    #the columns from 1:785 contains value of 28x28 pixel image.\n    training_images = file[1:29401,1:785].astype('int32')\n    training_images = training_images.reshape(len(training_images),28,28)\n    val_labels = file[29401:42001,0].astype('int32')\n    val_images = file[29401:42001,1:785].astype('int32')\n    val_images = val_images.reshape(len(val_images),28,28)\n\nwith open(test_set_path) as test_file:\n    file = np.loadtxt(test_file,dtype=list,delimiter=',')\n    testing_images = file[1:,:784].astype('int32')\n    testing_images = testing_images.reshape(len(testing_images),28,28)\n\n#normalising the training and validation data by dividing each pixel value with maximum pixel value.\n#Here, each pixel value is gray scale, so value lies from 0 to 255.0\ntraining_images = training_images\/255.0\nval_images = val_images\/255.0\n\nprint(training_images.shape)\nprint(training_labels.shape)\nprint(val_images.shape)\nprint(val_labels.shape)\nprint(testing_images.shape)\n","b179b71d":"training_images = np.expand_dims(training_images,axis=3)\nval_images = np.expand_dims(val_images,axis=3)\ntesting_images = np.expand_dims(testing_images,axis=3)\nprint(training_images.shape)\nprint(val_images.shape)\nprint(testing_images.shape)","399fb740":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(28,(5,5),activation='relu',input_shape=(28,28,1)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10,activation='softmax')\n])\nmodel.compile(optimizer='adam',\n             loss = 'sparse_categorical_crossentropy',\n             metrics=['acc'])\nmodel.summary()\n\nhistory = model.fit(training_images,training_labels,epochs=7,\n                   validation_data=(val_images,val_labels))\n\nloss, acc= model.evaluate(val_images,val_labels)\nprint('loss = ' + str(loss))\nprint('acc = ' + str(acc))","39119f5b":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","4643a769":"val_pred = model.predict_classes(val_images)\nval_pred = val_pred.reshape(12600,1)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(val_labels,val_pred,labels=[0,1,2,3,4,5,6,7,8,9])","ad6a390b":"test_predictions = model.predict_classes(testing_images)\ntest_predictions = test_predictions.reshape(28000,1)\nidx = 237\nimg = testing_images[idx].reshape(28,28)\nplt.imshow(img)\nprint(test_predictions[idx])","6feb279c":"image_id = np.arange(1,28001).reshape(28000,1)\ntest_results = np.concatenate((image_id,test_predictions),axis=1)\nnp.savetxt('test_predictions.csv',test_results,fmt=\"%d\",header=\"ImageId,Label\",delimiter=\",\")","f89397b0":"Ploting training and validation loss and accuracy in order to check whether data overfit or not.","3489cd6d":"Load mnist digits data using np.loadtxt(). We can use csv_reader() also, but it quite takes a lot more time in loading the data.\nI have divide the data from train.csv into 29400 training data and 12600 as validation data.","9c0163d8":"Now, predicting the classes for the testing data in test.csv file. we can change the value of 'idx' below (from 0 to 27999) to check some of the results.","78b33b3c":"Confusion matrix for the validation data predictation and true labels.","e24987d5":"Well, we got both the graphs intersecting each other and going in the same direction with a slight change. So I have considered it as 'Just good' situation with no underfit and no overfit. But there is always a scope for improvement!!","1e980e09":"As we will use Conv2D layer from tensorflow.keras, so we need to add one more dimension to our data.\nThe format of input to Conv2D layer is (Number_of_data, height_image, width_image, Number_channel)\nSo, here Number_channel = 1 (pixel values: 0 to 255 takes 1 byte for representation)","21a5b2a2":"Designing, compiling, training and testing the model.","4a3f99b3":"Let's begin with importing some libraries for the model."}}