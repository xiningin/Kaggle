{"cell_type":{"b2d96dd2":"code","1880a447":"code","43dcecd2":"code","6a015440":"code","277fe0ec":"code","3ad7aef7":"code","4fbd7a93":"code","4c691678":"code","24d1f504":"code","98a1eced":"code","5c5f12d3":"code","8a60733f":"code","19efaee5":"code","338f6de4":"code","c867c18a":"markdown","e842bc59":"markdown","0ba17370":"markdown","8677658b":"markdown","f5357bac":"markdown","0c768b6f":"markdown","e4b84084":"markdown","ed7e07f2":"markdown","a2ce5e38":"markdown"},"source":{"b2d96dd2":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport copy\nimport warnings\nimport joblib\nfrom sklearn.model_selection import train_test_split, KFold\nimport lightgbm as lgb\nimport datatable as dt\nimport gc\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error\nwarnings.filterwarnings(action='ignore', category=UserWarning)\nimport os\nimport time\nimport random","1880a447":"from sklearn.metrics import mean_squared_error\ndef my_metrics(y_true, y_pred):\n    return mean_squared_error(y_true, y_pred, squared=False)","43dcecd2":"folds = 7\nseed_list = [i for i in range(20,21)]\nearly_stopping = 200","6a015440":"td = dt.fread(\"..\/input\/tabular-playground-series-aug-2021\/train.csv\")\ntrain = td.to_pandas()\ndel td\nto_test = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\").drop(\"id\", axis = 1)","277fe0ec":"fake = pd.read_csv(\"..\/input\/tps08-nn-file\/7.85017.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/test.csv\")\ntest[\"loss\"] = fake.loss\ntrain = pd.concat([train, test]).reset_index(drop = True)","3ad7aef7":"y = train.loss\nX = train.drop([\"id\", \"loss\"], axis = 1)","4fbd7a93":"def objective(trial , X = X , y = y):\n    params = {\n        'reg_alpha' : trial.suggest_loguniform('reg_alpha' , 0.47 , 0.5),\n        'reg_lambda' : trial.suggest_loguniform('reg_lambda' , 0.32 , 0.33),\n        'num_leaves' : trial.suggest_int('num_leaves' , 50 , 70),\n        'learning_rate' : trial.suggest_uniform('learning_rate' , 0.03 , 0.04),\n        'max_depth' : trial.suggest_int('max_depth', 30 , 40),\n        'n_estimators' : trial.suggest_int('n_estimators', 100 , 6100),  #  4000 , 5600\n        'min_child_weight' : trial.suggest_loguniform('min_child_weight', 0.015 , 0.02),\n        'subsample' : trial.suggest_uniform('subsample' , 0.7 , 1.0), # 0.7 , 1.0\n        'colsample_bytree' : trial.suggest_loguniform('colsample_bytree', 0.52 , 1), # 0.5 , 1\n        'min_child_samples' : trial.suggest_int('min_child_samples', 76, 80),\n        'metric' : 'rmse', #'rmse'\n        'device_type' : 'gpu',\n    }\n    #pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'rmse', valid_name = 'valid_0')  \n    score = 0\n    for seed in seed_list: \n        kf = KFold(n_splits = folds ,random_state= seed, shuffle=True)\n        for idx_train,idx_test in kf.split(X, y):\n            X_train,X_test=X.iloc[idx_train],X.iloc[idx_test]\n            y_train,y_test=y.iloc[idx_train],y.iloc[idx_test]\n            model = lgb.LGBMRegressor(**params, random_state = seed, n_jobs = -1)\n            model.fit(X_train, y_train.values.ravel(), eval_set = [(X_test , y_test.values.ravel())] ,eval_metric = 'rmse', early_stopping_rounds = early_stopping, \\\n             verbose = 0, \n                      # callbacks = [pruning_callback]\n                     ) \n            y_pred = model.predict(X_test)  \n            score += (my_metrics(y_test.values.ravel(), y_pred) \/ folds) \/ len(seed_list)                 \n    del model\n    return score\nimport optuna\nstudy = optuna.create_study(direction = 'minimize' , study_name = 'lgbm'\n                        #   , pruner = optuna.pruners.HyperbandPruner()\n                           )\nstudy.optimize(objective , n_trials = 14)\nprint('numbers of the finished trials:' , len(study.trials))\nprint('the best params:' , study.best_trial.params)\nprint('the best value:' , study.best_value)\nprint(\"done\")\n#time.sleep(60)","4c691678":"params = {'reg_alpha': 0.4844428103930398, 'reg_lambda': 0.3212929260836738,\n          'num_leaves': 52, 'learning_rate': 0.033482626431611054, 'max_depth': 37,\n          'n_estimators': 4040, 'min_child_weight': 0.017690546165775478, 'subsample': 0.836321023865464,\n          'colsample_bytree': 0.8998887705274462,\n          'min_child_samples': 80} # Best is trial 0 with value: 6.203933623898198.","24d1f504":"show_feature_importance = 1\nshow_time = 1\nscore = 0\nif show_feature_importance:\n    features_importance= pd.DataFrame({'Feature':[], 'Importance':[]})\n    features = X.columns\nfor seed in seed_list: \n    kf = KFold(n_splits = folds ,random_state= seed, shuffle=True)\n    count = 1\n    for idx_train,idx_test in kf.split(X, y):\n        print(\"=\" * 40)\n        print(\"seed\", seed)\n        print(\"fold\", count)\n        print(\"=\" * 30)\n        if show_time:\n            start_time = time.time()\n        X_train, X_test = X.iloc[idx_train], X.iloc[idx_test]\n        y_train, y_test = y.iloc[idx_train], y.iloc[idx_test]\n        model = lgb.LGBMRegressor(**params, random_state = seed, n_jobs = -1, metric = 'rmse', device_type = 'gpu')\n        model.fit(X_train, y_train, eval_set = [(X_test , y_test.values.ravel())], eval_metric = 'rmse',\\\n                  early_stopping_rounds = early_stopping, verbose = False)\n        cv_score = my_metrics(y_test.values.ravel(), model.predict(X_test))\n        score += (cv_score \/ folds) \/ len(seed_list)\n        joblib.dump(model, f'LGBM seed_{seed}_fold_{count}_cv_score_{round(cv_score, 5)}.pkl') # save model\n        if show_feature_importance:\n            fold_importance_df= pd.DataFrame({'Feature':[], 'Importance':[]})\n            fold_importance_df['Feature']= features\n            fold_importance_df['Importance']= model.feature_importances_\n            fold_importance_df[\"fold\"] = count\n            features_importance = pd.concat([features_importance, fold_importance_df], axis=0)\n        if show_time:\n            end_time = time.time()\n            run_time = round(end_time - start_time)\n            print (\"fold\", count, \"took\", run_time , \"seconds to run\")\n            print (\"The estimated remaining training time in the current seed\", seed, \"are\",\\\n                   round(((folds - count) * run_time) \/ 60, 3), \"minuets\")        \n        count += 1\n        print(\"Validation score\", cv_score)\nprint(\"Mean RMSPE validation score of\", folds, \"folds\", score)\n","98a1eced":"if show_feature_importance:\n    import seaborn as sns\n    from matplotlib import pyplot as plt\n    feature_importance_df_ = features_importance\n    cols = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=True)[:10].index\n    best_features = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=True)[:10]\n    best_features.reset_index(inplace=True)\n    print(best_features.dtypes)\n    plt.figure(figsize=(10, 4))\n    sns.barplot(x=\"Importance\", y=\"Feature\", data=best_features)\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()","5c5f12d3":"if show_feature_importance:\n    feature_importance_df_ = features_importance\n    cols = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending= False)[:10].index\n    best_features = feature_importance_df_[[\"Feature\", \"Importance\"]].groupby(\"Feature\").mean().sort_values(by=\"Importance\", ascending=False)[:10]\n    best_features.reset_index(inplace=True)\n    print(best_features.dtypes)\n    plt.figure(figsize=(10, 4))\n    sns.barplot(x=\"Importance\", y=\"Feature\", data=best_features)\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()","8a60733f":"output = []\n# Mean RMSPE validation score of 7 folds 6.203931071616227\nfor filepath in glob.iglob('.\/*.pkl'):   \n    model = joblib.load(filepath)\n    pred = model.predict(to_test, num_iteration = model.best_iteration_)\n    output.append(pred)\n    del model\n    del pred\ny_pred = sum(output) \/ len(output)","19efaee5":"final_pred = pd.read_csv(\"..\/input\/tabular-playground-series-aug-2021\/sample_submission.csv\")\nfinal_pred.loss = y_pred\nfinal_pred","338f6de4":"final_pred.to_csv('submission.csv',index=False)","c867c18a":"# Hyperparameter Optimization","e842bc59":"files are from \n* https:\/\/www.kaggle.com\/aayush26\/tps-aug-2021-simple-weighted-ensemble by Aayush Kumar Singha\n* https:\/\/www.kaggle.com\/alexryzhkov\/lightautoml-classifier-regressor-mix by Alexander Ryzhkov\n* https:\/\/www.kaggle.com\/somayyehgholami\/3-tps-aug-21-results-rmse-evaluation by Somayyeh Gholami and Mehran Kazeminia","0ba17370":"# Fit","8677658b":"# Data","f5357bac":"# Config","0c768b6f":"# Infer","e4b84084":"# Custom Metrics","ed7e07f2":"# Pseudo Labeling","a2ce5e38":"# Feature Importance"}}