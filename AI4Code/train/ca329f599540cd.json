{"cell_type":{"e26f1441":"code","163ae44c":"code","08bf6751":"code","c22521d1":"code","ad119164":"code","f2b7e138":"code","dfef2acd":"code","e7da7c94":"code","7c7c15a9":"code","02a4851e":"code","086c98f5":"code","d6a6d48e":"code","1633f3cc":"code","055912b3":"code","d531930e":"code","95ebf8a6":"code","afa0c1f9":"code","2276183f":"code","34880b29":"code","8cb04e75":"code","2284560d":"code","4051bc43":"code","b923d6d7":"code","6cc7b677":"code","daa37a87":"code","6982bb07":"markdown","8411d976":"markdown","d303022d":"markdown","bfa2341f":"markdown","52e14a5c":"markdown","f0cbd0b8":"markdown","0e4060ce":"markdown","3c53c20b":"markdown","e47655ea":"markdown","5f2e96d3":"markdown","b0945060":"markdown","ef641de7":"markdown","89f7c3ab":"markdown","d3f7267b":"markdown","70f8a72c":"markdown","f3b0bc86":"markdown","020e3271":"markdown","ed764589":"markdown","301f68d4":"markdown","db65f943":"markdown","54ecffb2":"markdown","e23b8f99":"markdown","b2d1d669":"markdown","0df4a498":"markdown","f46d6221":"markdown","4f175b86":"markdown","0ed563e0":"markdown","c74f719c":"markdown","5d6ad460":"markdown","387e268d":"markdown","19894796":"markdown","da13426e":"markdown","0a53e8fd":"markdown","f6657f0f":"markdown","e566eb5f":"markdown","bd9944f6":"markdown","bbc2128d":"markdown","84d89ea6":"markdown","db0e11b9":"markdown","40c41ab1":"markdown","d05eb08a":"markdown","3b34cd67":"markdown","73db03db":"markdown","f63b306f":"markdown"},"source":{"e26f1441":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","163ae44c":"# Charger la BD\niris = pd.read_csv(\"..\/input\/iris\/Iris.csv\", index_col=0)\niris.head()","08bf6751":"iris[np.random.rand(150,5)<0.05]=np.nan\niris.head()","c22521d1":"display(iris.head())\ndisplay(iris.shape)\ndisplay(iris.describe())","ad119164":"# On s'int\u00e9resse aux donn\u00e9s manquantes... \n#Nbre donn\u00e9es manquantes\ndisplay(iris.isnull().sum())\ndisplay(iris.shape)\niris.dropna(inplace=True)\ndisplay(iris.shape)\n\n    ","f2b7e138":"# On aurait pu faire: \n     #Pour rem\u00e9dier aux donn\u00e9es manquantes, on pourrait \u00e9xecuter un algorithme qui pour chaque donn\u00e9e manquante, cherchera dans les \u00e9chantillons\n     #de la m\u00eame classe une donn\u00e9e qui pour les autres param\u00e8tres aura un petit \u00e9cart 'x' ou moins et ainsi on pourrait lui affecter la valeur \n     #de la donn\u00e9e manquante comme si les deux donn\u00e9es se ressemblaient.","dfef2acd":"fig,ax = plt.subplots(nrows=4, ncols=4, figsize=(21, 15))\n\nspecies = iris.Species.unique()\n\nfor i in range(4):\n    for sp in species:\n        sns.distplot(a=iris[iris.Species == sp].iloc[:, i], ax=ax[0, i])\n        sns.boxplot(iris[iris.Species == sp].iloc[:, i], ax=ax[1, i])\n        sns.violinplot(iris[iris.Species == sp].iloc[:, i], ax=ax[2, i])\n        sns.kdeplot(iris[iris.Species == sp].iloc[:, i], ax=ax[3, i])\n    \n    \n    \n\n","e7da7c94":"# import puis utilisation pour fabriquer les trois ensembles\nfrom sklearn.model_selection import train_test_split\n\n#S\u00e9paration d'iris en observation (X) et en classe (Y)\nX = iris.iloc[:,:4]\nY = iris.iloc[:, 4:]\n\ntrain_X,rest_X,train_Y, rest_Y= train_test_split(X, Y, train_size= 0.7, test_size= 0.3, stratify=Y)\ntest_X, validation_X,test_Y, validation_Y= train_test_split(rest_X, rest_Y, train_size=2\/3, test_size=1\/3, stratify=rest_Y)\n\n","7c7c15a9":"# Retour sur des graphiques, mais cette fois pour r\u00e9aliser l'apprentissage\niris_Train = pd.concat([train_X, train_Y], axis=1)\ng = sns.PairGrid(iris_Train, hue='Species')\ng.map(plt.scatter)\ng.add_legend()","02a4851e":"# Fonction niveau0\ndef classe0(row):\n    if row.PetalLengthCm < 2.2:\n        return 'Iris-setosa'\n    return '???'\n\ndef niveau0(set):\n    return set.apply(lambda x:pd.Series(classe0(x), index=['Species']), axis=1);","086c98f5":"def nonClassed(set_X, set_Y):\n    set_X_classe0 = niveau0(set_X)\n    # Array des Id des enregistrements qui ont donn\u00e9e iris-setosa comme r\u00e9ponse par niveau0:\n    toDelete = set_X_classe0[set_X_classe0.Species != '???'].index.values\n    return set_X.drop(toDelete, axis=0), set_Y.drop(toDelete, axis=0)\n\ntrain_X_2, train_Y_2 = nonClassed(train_X, train_Y)\ntrain_2 = pd.concat([train_X_2, train_Y_2], axis=1)\n\n# Je n'ai pas eu besoin de faire un reset_index()","d6a6d48e":"# Retour sur des graphiques, mais cette fois pour r\u00e9aliser l'apprentissage\ng = sns.PairGrid(train_2, hue='Species')\ng.map(plt.scatter)\ng.add_legend()","1633f3cc":"def separe(attribut, seuil, etiquette1, etiquette2):\n    def choixEtiquette(situation):\n        if (situation[attribut] < seuil):\n            return etiquette1\n        return etiquette2\n    return choixEtiquette","055912b3":"def niveau1_d(a_set, realClasses):\n    total_elements = a_set.shape[0]\n    #attributs\n    attributs = list(a_set)\n    maxAccuracy = 0\n    answer = [0, 0, 0, 0]\n    for att in attributs:\n        minSeuil = int(a_set[att].min())\n        maxSeuil = int(a_set[att].max())\n        for seuil in range(minSeuil, maxSeuil):\n            prediction = a_set.apply(lambda x:pd.Series(separe(att, seuil, 'Iris-versicolor', 'Iris-virginica')(x),index=['Classe0']), axis=1)\n            truePositif = (prediction.iloc[:, 0]==realClasses.iloc[:, 0]).sum()\n            accuracy = truePositif\/total_elements\n            if accuracy > maxAccuracy:\n                maxAccuracy = accuracy\n                answer = [att, seuil, 'Iris-versicolor', 'Iris-virginica', maxAccuracy]\n            prediction = a_set.apply(lambda x:pd.Series(separe(att, seuil, 'Iris-virginica', 'Iris-versicolor')(x), index=['Classe0']), axis=1)\n            truePositif = (prediction.iloc[:, 0]==realClasses.iloc[:, 0]).sum()\n            accuracy = truePositif\/total_elements\n            if accuracy > maxAccuracy:\n                maxAccuracy = accuracy\n                answer = [att, seuil, 'Iris-virginica', 'Iris-versicolor', maxAccuracy]\n    return answer            ","d531930e":"def classe1(row, parameters):\n    if row[parameters[0]] < parameters[1]:\n        return parameters[2]\n    return parameters[3]\n\ndef niveau1(set, parameters):\n    return set.apply(lambda x:pd.Series(classe1(x, parameters), index=['Species']), axis=1);\n\n\ndef arbre(aSet, realclasses, parameters):\n    n0 = niveau0(aSet)\n    classe0 = n0[n0.Species != '???']\n    aSet_x_2, aSet_y_2 = nonClassed(aSet, realclasses)\n    \n    classe1 = niveau1(aSet_x_2, parameters)\n    \n    classification = pd.concat([classe0, classe1], axis=0)\n    \n    return classification\n\n#Calcul manuel de l'accuracy pour l'ensemble d'entrainement et celui de test\nparameters = niveau1_d(train_X_2, train_Y_2) #param\u00e8tres du niveau1 de l'arbre \u00e0 partir de l'ensemble d'entrainement\n#Pour l'entrainement : \nclassification_train = arbre(train_X, train_Y, parameters)\nall_train = pd.merge(classification_train, train_Y, on='Id')\ndisplay('accuracy sur l\\'ensemble d\\'apprentissage = ' + str((all_train.Species_x==all_train.Species_y).sum()\/train_X.shape[0]))\n#Pour le test :\nclassification_test = arbre(test_X, test_Y, parameters)\nall_test = pd.merge(classification_test, test_Y, on='Id')\ndisplay('accuracy sur l\\'ensemble de test = ' + str((all_test.Species_x==all_test.Species_y).sum()\/test_X.shape[0]))","95ebf8a6":"import sklearn\ny_test = all_test.Species_y\ny_pred = all_test.Species_x\ndisplay(sklearn.metrics.confusion_matrix(y_test, y_pred, labels=iris.Species.unique()))\ndisplay(sklearn.metrics.accuracy_score(y_test, y_pred))\n\n#Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\ndisplay(sklearn.metrics.f1_score(y_test, y_pred, average = 'macro'))\ndisplay(sklearn.metrics.precision_score(y_test, y_pred, average = 'macro'))\ndisplay(sklearn.metrics.recall_score(y_test, y_pred, average = 'macro'))\n\n#Les mesures sont toutes >= 0.85 ( pour diff\u00e9rents ex\u00e9cutions) ce qui est bon signe surtout qu'on les mesure pour l'ensemble de test que le mod\u00e8le \n#n'a pas us\u00e9 pour s'entrainer.","afa0c1f9":"from sklearn import tree\nclf = tree.DecisionTreeClassifier()\nclf.fit(train_X, train_Y)","2276183f":"from sklearn import dummy\nfrom sklearn.utils import check_X_y\n#Score du classificateur vu en dessus\nscore_clf = clf.score(test_X, test_Y)\n#Classificateur bidon :\nclf_bidon = dummy.DummyClassifier(strategy=\"most_frequent\")\ntrain_X_f, train_Y_f = check_X_y(X=train_X, y = train_Y)\nclf_bidon.fit(train_X_f, train_Y_f)\ntest_X_f, test_Y_f = check_X_y(X=test_X, y = test_Y)\nscore_clf_bidon = clf_bidon.score(test_X_f, test_Y_f)\n\ndisplay('Score du DecisionTreeClassifier : ' + str(score_clf) +' Score du classificateur bidon : ' + str(score_clf_bidon) )\n# Le score du DecisionTreeClassifier est (>0.9) alors que le classificateur bidon a un score en dessous de la moyenne.","34880b29":"# jouer avec les param\u00e8tres, et \u00e0 chaque fois juger de la qualit\u00e9, jusqu'\u00e0 obtenir votre 'meilleur arbre'\n# Je vais jouer ici sur le max_depth de l'abre de d\u00e9cision qu'on souhaite g\u00e9n\u00e9rer en allant de 1 \u00e0 10 et choisissant \n# celle ayant la plus grande accuracy.\nmaxScore = 0\nbest_depth = 0\nbest_clf = tree.DecisionTreeClassifier() #will replace it with best classifier\nfor i in range(1, 10):\n    clf = tree.DecisionTreeClassifier(max_depth = i)\n    clf.fit(train_X, train_Y)\n    score = clf.score(test_X, test_Y)\n    if score > maxScore:\n        maxScore = score\n        best_depth = i\n        best_clf = clf\n\ndisplay(maxScore)\ndisplay(best_depth)\ndisplay(best_clf)\n\n#On remarque dans ce cas que dans la plupart du temps, une profondeur de 2 est suffisante \n#pour avoir un score parfait.\n","8cb04e75":"vald_score = best_clf.score(validation_X, validation_Y)\ndisplay(vald_score)\n#L'\u00e9valuation donne un score parfait.","2284560d":"with open(\"iris.dot\", 'w') as f:\n    f = tree.export_graphviz(clf, out_file=f, filled=True)","4051bc43":"#L'algorithme des for\u00eats d'arbres d\u00e9cisionnels est un apprentissage sur diff\u00e9rents arbre de d\u00e9cision construits\n#\u00e0 partir de sous-ensembles l\u00e9g\u00e8rement diff\u00e9rent.\n\nfrom sklearn import ensemble\nclf_forest = ensemble.RandomForestClassifier()\nclf_forest.fit(train_X, train_Y)","b923d6d7":"from sklearn import model_selection\nn_estimators = [20, 40, 70] #Nombre d'arbre \u00e0 construire pour d\u00e9duire la for\u00eat\nmax_depth = [3, 7, 13]#Profondeur de chaque arbre\nmin_samples_split = [2, 4, 6] #minumum d'enregistrement pour split un node \nmin_samples_leaf = [1, 3, 5] #minimum d'enregistrement qu'un noeud caragt\u00e9rise\n\nhyperParam = dict(n_estimators = n_estimators, max_depth = max_depth,  \n              min_samples_split = min_samples_split, \n             min_samples_leaf = min_samples_leaf)\n\n#gridSearh will enable us to optimise the random forest by picking the best \n#hyperparameters automatically\ngrid = model_selection.GridSearchCV(clf_forest, hyperParam)\nbestF = grid.fit(train_X, train_Y)\n\n","6cc7b677":"import pandas as pd\nIris = pd.read_csv(\"..\/input\/iris\/Iris.csv\")","daa37a87":"import pandas as pd\nIris = pd.read_csv(\"..\/input\/iris\/Iris.csv\")","6982bb07":"## Recherche de la meilleure coupe\nOn va rechercher parmi tous les attributs celui qui semble permettre la meilleure s\u00e9paration entre les deux vari\u00e9t\u00e9s d'iris restantes. Pour cela, on va envisager une coupe selon n'importe quel attribut, et pour n'importe quelle valeur de seuil, puis on r\u00e9alisera un balayage des coupes verticales possibles, et on conservera la moins mauvaise.\n\n** Il existe des m\u00e9thodes plus efficaces (heureusement) que celle pr\u00e9sent\u00e9e ici, cf. S\u00e9parateurs \u00e0 Vastes Marges **\n\nEcrire une fonctionnelle *separe* prenant comme entr\u00e9es :\n- un attribut 'att'\n- un seuil\n- une \u00e9tiquette 'A'\n- une \u00e9tiquette 'B'\n\nqui renvoie une fonction qui prend en entr\u00e9e une situation et qui renvoie 'A' si cette situation a sont attribut *att < seuil* et 'B' sinon\n\n** Normalement vous devriez pouvoir prendre *niveau0* comme base de travail**","8411d976":"## Sur quel ensemble doit-on juger de la qualit\u00e9 ?\nExpliquer l'int\u00e9ret de  mesurer la qualit\u00e9 sur chacun des ensembles\n- Ensemble d'apprentissage : Evaluer le niveau d'entrainement du mod\u00e8le\n- Ensemble de validation :  r\u00e9gler les param\u00e8tres de l'arbre de d\u00e9cision\n- Ensemble de test : Evaluer la classification du mod\u00e8le sur des enregistrements qu'il n'a jamais utilis\u00e9","d303022d":"---\n# Arbre de d\u00e9cision r\u00e9alis\u00e9s par sklearn\n---\n- importer le module ```tree``` de ```sklearn```\n- Etudier la documentation de ```DecisionTreeClassifier```, en particulier la partie **Tips on practical use**\n- Construire un classifieur utilisant l'indice de Gini","bfa2341f":"- Le param\u00e8tre stratify nous permet, lorsqu'on lui affecte la liste des classes 'Y', de pr\u00e9server dans les sous ensembles la m\u00eame proportion de chaque classe que dans l'ensemble initial. Cette technique nous permettra de travailler dans des ensembles homog\u00e8nes.\n\n- L'utilisation du param\u00e8tre randome_state nous permettra de fixer une graine qui rendera le 'split' statique d'une ex\u00e9cution \u00e0 une autre. J'ai pr\u00e9f\u00e9r\u00e9 ne pas l'utiliser afin d'obtenir diff\u00e9rents sous ensembles de travail apr\u00e8s chaque ex\u00e9cution. \n ","52e14a5c":"# Optimisation des param\u00e8tres\n- Utiliser une 'gridSearch' de sklearn afin de rechercher les meilleurs param\u00e8tres de la for\u00eat","f0cbd0b8":"R\u00e9ponses  :\n - Iris-setosa est ais\u00e9ment s\u00e9parable.\n - Les attributs qui permettent de la s\u00e9parer sont: PetalLength et PetalWidth\n \n - Les graphiques (PetalLength, *) permet de tracer un trait horizontal s\u00e9parant cet esp\u00e8ce des autres.\n - Les graphiques (*, PetalLength) permet de tracer un trait vertical s\u00e9parant cet esp\u00e8ce des autres.\n \n - Les graphiques (PetalWidth, *) permet de tracer un trait horizontal s\u00e9parant cet esp\u00e8ce des autres.\n - Les graphiques (*, PetalWidth) permet de tracer un trait vertical s\u00e9parant cet esp\u00e8ce des autres.\n \n - **Remarque:** \n     PetalLength permet une s\u00e9paration plus precise de l'esp\u00e8ce Iris-setosa que l'attribut PetalWidth. ","0e4060ce":"# Niveau suivant de l'arbre\nOn devrait maintenant construire pour chacune des valeurs de sortie de *niveau0* une fonction permettant d'affiner la classification. Ici, le travail est simplifi\u00e9, car une des deux classes obtenues par *niveau0* est parfaitement homog\u00e8ne, on ne va donc affiner que la partie corrrespondant \u00e0 la r\u00e9ponse *???* de la sortie de *niveau0*. Dans le cas g\u00e9n\u00e9ral, il faudrait suivre la m\u00eame proc\u00e9dure sur l'autre sous-arbre.","3c53c20b":" # TP L3 ISIMA : arbres de d\u00e9cision\n---\nLes principaux points abord\u00e9s dans ce TP sont :\n- La construction des ensembles \u00e0 manipuler (apprentissage, test, validation)\n- La visualisation des donn\u00e9es\n- Le choix des crit\u00e8res de s\u00e9paration pour la cr\u00e9ation d'un arbre de d\u00e9cision\n  + cas o\u00f9 la s\u00e9paration peut s'effectuer sur un unique attribut\n  + cas o\u00f9 la s\u00e9pararation est lin\u00e9aire, mais doit faire intervenir plusieurs attributs\n- La construction de l'arbre\n- Le jugement de la qualit\u00e9 de l'apprentissage\n- D\u00e9couverte de sklearn","e47655ea":"## A l'aide de sklearn.metric, \u00e9valuer les diff\u00e9rentes mesures, commenter","5f2e96d3":"## Dur Dur\nIl semble ici nettement plus difficile de d\u00e9terminer la meilleure fa\u00e7on de classer :\n- aucune coupe verticale ne semble nettement meilleure que les autres\n- aucune coupe diagonale ne semble r\u00e9soudre le probl\u00e8me\n- peut-\u00eatre existe-il une coupe en dimension sup\u00e9rieure qui serait satisfaisante, mais \u00e0 partir de la dimension 3, les choses deviennent difficiles \u00e0 voir...\n\n1) Donner une situation (non pr\u00e9sente ici) o\u00f9 il n'y aurait aucune coupe verticale satisfaisante mais o\u00f9 il y aurait une coupe oblique convenable, si possible g\u00e9n\u00e9raliser \u00e0 trois variables.\n\n2) Montrer dans un exemple simple en dimension 2 (sur un domaine compact) que par une infinit\u00e9 de coupes verticales il est possible d'obtenir une coupe oblique.","b0945060":"**R\u00e9ponse:**\n- attribut sur lequel effectuer la s\u00e9paration: PetalLength\n- valeur du seuil \u00e0 utiliser: 2.2 cm de tel sorte si PetalLength<2.2cm alors il s'agit de l'esp\u00e8ce Iris-setosa\n- J'ai pr\u00e9f\u00e9r\u00e9 l'utilisation de PetalLenght comme racine de l'arbre car elle donne plus de pr\u00e9cision que PetalWidth","ef641de7":" ## Charger la base de donn\u00e9es 'Iris Species' dans l'environnement\n - Commencer par incorporer la BD dans le kernel : *add data* dans la 'frame' de droite\n - Utiliser la commande pandas permettant de charger le fichier CSV des donn\u00e9es\n - N'oubliez pas de v\u00e9rifier l'apparence du r\u00e9sultat en affichant les premi\u00e8res lignes\n \nRappel : les donn\u00e9es se trouvent dans \"..\/input\/\", dont on peut lister le contenu par :\n ```\nimport os\nprint(os.listdir(\"..\/input\/\"))\n```\n ","89f7c3ab":"## Filtrer dans la base de test les \u00e9l\u00e9ments dont la r\u00e9ponse par *niveau0* est '???'\n- Appeller cette base train_2\n- la s\u00e9parer en train_X_2, train_Y_2\n\n** Si n\u00e9cessaire, faire un reset d'index : df.reset_index(drop=True, inplace = True) **","d3f7267b":"R\u00e9ponse \u00e0 l'utilit\u00e9 de l'ensemble de validation :\n- L'ensemble de validation nous a permis de confirmer la validit\u00e9 des param\u00e8tres de notre mod\u00e8le.","70f8a72c":"## Choisir la racine de l'arbre de d\u00e9cision :\n- attribut sur lequel effectuer la s\u00e9paration:\n- valeur du seuil \u00e0 utiliser: ","f3b0bc86":"R\u00e9ponse : \n- Pareil pour la question avant , on utilisera gridSearchCV en lui affectant un ensemble de valeurs pour les diff\u00e9rents hyperparam\u00e8tres mais cette fois-ci on l'appliquera \u00e0 l'ensemble de test.\n- La validation crois\u00e9e consiste \u00e0 \u00e9valuer notre mod\u00e8le sur un ensemble de vlaidation hypoth\u00e9tique (issue en g\u00e9n\u00e9ral de l'ensemble d'entrainement m\u00eame) et ceci lorsqu'on n'a pas un ensemble de validation ind\u00e9pendant.","020e3271":"---\n---\n# Mise en place manuelle d'un arbre de d\u00e9cision\n---\n---","ed764589":"## Au fait, \u00e0 quoi sert l'ensemble de validation ??\n- Utiliser l'ensemble de validation pour donner la qualification finale de votre arbre\n- Pourquoi cette qualification ne peut-elle pas \u00eatre obtenue \u00e0 partir de l'ensemble de test ?\n","301f68d4":"### Rappeler la fonction de chacun de ces ensembles\n*Ces ensembles sont des sous-ensembles de l'ensemble de donn\u00e9es.*\n\n**L'ensemble d'apprentissage:** Utilis\u00e9 pour entra\u00eener un mod\u00e8le (c\u00e0d) d\u00e9terminer les param\u00e8tres cl\u00e9s du classificateur.\n\n**L'ensemble de validation:** Utilis\u00e9 pour le r\u00e9glage des param\u00e8tres du mod\u00e8le et permet aussi une \u00e9valuation continue du mod\u00e8le.\n\n**L'ensemble de test:** Utilis\u00e9 pour \u00e9valuer le mod\u00e8le finale d'une mani\u00e8re non biais\u00e9 et ceci en interdisant tout utilisation de cet ensemble lors de l'entrainement ou lors du r\u00e8glage des param\u00e8tres du classificateur.\n\n\n","db65f943":"## Choix de la 'meilleure' coupe verticale\nLes mesures que vous devez conna\u00eetre sont  :\n- la matrice de confusion  \n- Le taux de bonne pr\u00e9diction (accuracy) $\\frac{VP + VN}{VP+VN+FP+FN}$\n- Le taux de vrais positifs \/ rappel (recall, sensitivity) $\\frac{VP }{VP+FN}$\n- Le taux de vrais n\u00e9gatifs (specificity) $\\frac{VN}{VN+FP}$\n- La pr\u00e9cision $\\frac{VP }{VP + FP}$\n- La F_1 mesure $2 \\times \\frac{rappel \\times pr\u00e9cision}{rappel + pr\u00e9cision}$\n- La courbe ROC\n- Le score ROC  \nSi un besoin d'aide sur ces mesures se fait sentir : [Evaluating classifiers](https:\/\/www.youtube.com\/watch?v=FAr2GmWNbT0)\n\nOn choisit de d\u00e9finir la meilleure coupe comme celle ayant le meilleur taux de pr\u00e9diction.\nEcrire une fonction de balayage renvoyant le tuple *(attribut, seuil, A, B)* (ou la fonction permettant le taux de pr\u00e9diction) maximisant le taux de pr\u00e9diction. On nomme mc niveau1_d la fonction de classification obtenue.\n\nNB1 : il n'est pas demand\u00e9 un algo malin, mais un simple balayage... qui peut prendre un temps important :)\n\nNB2 : penser \u00e0 incorporermetrics de sklearn...\n\nNB3 : faire attention \u00e0 bien choisir l'ensemble sur lequel on travaille (apprentissage ?, test ?, validation ?)\n","54ecffb2":"---\n---\n# Pr\u00e9paration \/ consignes\n- Votre travail consiste \u00e0 compl\u00e9ter ce cadre de TP. \n- Vous pouvez (hmmm devez ?) ajouter des blocs de code comme des blocs d'explication.\n- Les blocs d'explication sont au format Markdown : \t[markdown](https:\/\/www.markdownguide.org\/cheat-sheet\/).\n- Le rendu est une version imprim\u00e9e de cette ```frame```.\n- Pensez \u00e0 faire des ```commit``` r\u00e9guli\u00e8rement\n- Il est posible de cr\u00e9er une copie locale de votre travail ```file \/ Download Notebook```\n---\n---","e23b8f99":"## Ecrire une fonction niveau0\n- Prenant en entr\u00e9e une description\n- Renvoyant une estimation de la vari\u00e9t\u00e9 d'iris (pour l'instant, il n'y a que deux 'vari\u00e9t\u00e9s', celle qu'on a s\u00e9par\u00e9 et 'le reste'  que l'on note ici ```???```)  \n\nNB : une utilisation de votre fonction peut \u00eatre par exemple : ```niveau0(iris_Train_X)``` doit renvoyer ```iris_Train_Y``` si l'apprentissage est parfait (ce qui n'est en g\u00e9n\u00e9ral pas bon signe...)\n\nNB2 : vous devez renvoyer un DataFrame poss\u00e9dant un unique attribut que vous nommerez\n\nNB3 : mettre en oeuvre apply de pandas\n","b2d1d669":"## Recommencer le graphique des paires, afin de d\u00e9terminer la meilleure s\u00e9paration","0df4a498":"## Cr\u00e9er ces ensembles\n- Charger ```train_test_split``` du module ```sklearn.model_selection```\n- S\u00e9parer iris en observations (les attributs observables) et classe (la vari\u00e9t\u00e9)\n- Lire le manuel de ```train_test_split```\n  - Examiner en particulier l'option stratify, la mettre en oeuvre\n  - Se poser la question de l'int\u00e9r\u00eat de random_state\n- Par deux applications de cette fonction, cr\u00e9er les 6 ensembles train_X, train_Y, test_X, test_Y, validation_X, validation_Y (conseil, v\u00e9rifier les tailles des ensembles obtenus)","f46d6221":"# Merci d'\u00eatre all\u00e9 jusqu'\u00e0 la fin du TP, j'esp\u00e8re que ce travail vous a aid\u00e9 \u00e0 approfondir votre compr\u00e9hension du cours d'apprentissage artificiel. A bient\u00f4t pour la suite :)","4f175b86":"# Repr\u00e9sentation de la distribution des attributs\n## Pour chaque attribut, repr\u00e9senter sa distribution (une courbe par vari\u00e9t\u00e9)\n- Histogramme\n- Bo\u00eete \u00e0 moustache\n- Diagramme en violon\n- Estimation par fonction noyau de la densit\u00e9\n\nNB : pour obtenir une pr\u00e9sentation correcte, il peut \u00eatre utile d'utiliser ```fig,ax = plt.subplots(param\u00e8tres)``` pour d\u00e9finir la pr\u00e9sentation des graphiques, puis ```plt.sca(ax[i])``` afin de choisir dans quel sous graphique \u00e9crire.","0ed563e0":"## Commenter les graphismes obtenus\n- Y a-t-il une vari\u00e9t\u00e9 ais\u00e9ment s\u00e9parable ?\n- Quels attributs permettent de la s\u00e9parer des deux autres ?\n- Quels graphiques ont permis de choisir cet attribut ?","c74f719c":"Cette base de donn\u00e9e est trop bien nettoy\u00e9e... A des fins p\u00e9dagogiques, nous allons la d\u00e9terriorer.\nEx\u00e9cuter la ligne suivante : ```iris[np.random.rand(150,5)<0.05]=np.nan```","5d6ad460":"## Examiner le contenu de cette base de donn\u00e9es\n- Lister les 5 premi\u00e8res lignes (pr\u00e9f\u00e9rer```display```  \u00e0 ```print```)\n- Afficher le nombre de lignes ainsi que le nombre de colonnes\n- Afficher un r\u00e9sum\u00e9 statistique simple de cette base","387e268d":"## Il est possible de repr\u00e9senter un arbre de d\u00e9cision\n- Importer le module graphviz\n- utiliser la fonction de ```tree.export_graphviz``` puis ```graphviz.Source``` afin de r\u00e9aliser une belle repr\u00e9sentation graphique","19894796":"## Expliquer l'int\u00e9ret de chacune des mesures pr\u00e9c\u00e9dentes, et proposer un exemple pertinent pour chacune d'elles justifiant son existence\n- la matrice de confusion  : Nous donne une vision globale de nos pr\u00e9diction qui nous permettra de calculer diff\u00e9rents param\u00e8tres plus pr\u00e9cises par la suite.\n- Le taux de bonne pr\u00e9diction (accuracy) : Evaluer la pr\u00e9diction globale du mod\u00e8le(ex: la proportion des personnes ayant une maladie dans tout le lot)\n- Le taux de vrais positifs \/ rappel (recall, sensitivity) : mesure la proportion des r\u00e9sultats positifs lorsque l'hypoth\u00e8se est v\u00e9rifi\u00e9e.(ex: le pourcentage des personnes malades qui ont correctement \u00e9t\u00e9 identifi\u00e9 ainsi)\n- Le taux de vrais n\u00e9gatifs (specificity) : mesure la proportion des r\u00e9sultats n\u00e9gatifs lorsque l'hypoth\u00e8se n'est pas v\u00e9rifi\u00e9e. (ex: le pourcentage des personnes non malades qui on \u00e9t\u00e9 identifi\u00e9 n'ayant pas la maladie.)\n- La pr\u00e9cision : la proportion des r\u00e9sultats positifs parmis toutes les pr\u00e9dictions vraies de cette classe.\n- La F_1 mesure : mesure le taux de bonne pr\u00e9diction d'un test.","da13426e":"## Construction du classifieur cha\u00eenant les deux premier classifieurs\nCr\u00e9er une fonction de classification qui encha\u00eene les deux fonctions **niveau0** et **niveau1_d**, nommer la fonction obtenue **arbre**","0a53e8fd":"## V\u00e9rifier qu'il n'y a pas de donn\u00e9es absentes\n- Pour chaque attribut, compter le nombre de donn\u00e9es manquantes.\n- Supprimer les lignes poss\u00e9dant au moins une donn\u00e9e manquante (c'est la fa\u00e7on la plus simple de se d\u00e9barrasser du probl\u00e8me)\n- Combien d'exemples ont-ils \u00e9t\u00e9 ainsi perdus ?\n- R\u00e9fl\u00e9chir \u00e0 d'autres fa\u00e7ons de traiter les donn\u00e9es absentes (conseil : revenir \u00e0 ce point \u00e0 la fin du TP)","f6657f0f":"# Premi\u00e8re d\u00e9coupe : (travail sur **iris_Train**)","e566eb5f":"---\n# Random Forest\n---\n- Rappeler le principe des forets d'arbres d\u00e9cisionnelles\n\n- Remplacer le classifieur par arbre de d\u00e9cision par un classifieur par une for\u00eat d'arbres d\u00e9cisionnels","bd9944f6":"# Choisir les meileurs param\u00e8tres en utilisant l'ensemble de  test, expliquer ce qu'est la validation crois\u00e9e","bbc2128d":"## Charger les librairies \n- numpy\n- pandas\n- seaborn\n- matplotlib.pyplot\n\nDans la suite ajouter les imports dans cette cellule.","84d89ea6":"---\n# Juger de la qualit\u00e9 du travail !!\n---\nJuger de la qualit\u00e9 du r\u00e9sultat est tr\u00e8s important, cela permet\n- De choisir entre plusieurs mod\u00e8les le plus adapt\u00e9\n- De d\u00e9terminer des pistes d'am\u00e9lioration d'un mod\u00e8le\n- D'\u00e9valuer les capacit\u00e9s du mod\u00e8le  lorsqu'il sera mis en production  ","db0e11b9":"## Les ensembles de travail\n- l'ensemble d'apprentisage : iris_Train, 70% des donn\u00e9es\n- l'ensemble de validation : iris_Test, 20% des donn\u00e9es\n- l'ensemble de test : iris_Validation, 10% des donn\u00e9es  ","40c41ab1":"## Repr\u00e9senter tous les couples d'attributs possibles\n- Diagrammes points ou points\n- Densit\u00e9 ou histogramme ou bo\u00eete \u00e0 moustaches\n\n*** (utiliser *pair*grid du module seaborn)***","d05eb08a":"## Coupes en 'diagonale'\nOn a choisi d'effectuer des coupes sur un attribut (un c\u00f4t\u00e9 gauche, et un c\u00f4t\u00e9 droit). Il est possible \u00e9galement de d\u00e9couper l'espace en deux demi-espaces. Dans l'absolu, outes les d\u00e9coupes sont possibles. On s'int\u00e9resse ici des d\u00e9coupes observables par le graphique des paires.  \nR\u00e9observer le graphique, et d\u00e9terminer s'il existe une d\u00e9coupe plus efficace que celle trouv\u00e9e pr\u00e9c\u00e9dement.\n- Il n'est pas demand\u00e9 de la r\u00e9aliser (mais vous le pouvez :))\n- Exposer une situation \u00e0 3 attributs o\u00f9 il n'existe pas de coupe par plan sur 2 param\u00e8tres alors qu'il existe un plan s\u00e9parateur parfait. (ils ne sont lin\u00e9airement s\u00e9parables dans aucun des graphiques 'paires' mais sont pourtant lin\u00e9airement s\u00e9parables)\n","3b34cd67":"## Qualification\n- Calculer les scores utilis\u00e9s dans ce TP\n- Comparer les scores \u00e0 ceux obtenus par un classifieur 'bidon' (sklearn.dummy) (\u00e0 quoi cela sert-il ?)\n\nRq : il reste un bug dans dummy, si vous obtenez une erreur de type 'no argmax on list', un contournement de ce probl\u00e8me peut \u00eatre obtenu en reformattant les entr\u00e9es du classifieur par 'check_X_y'\n","73db03db":"# Construction du 'meilleur' arbre de d\u00e9cision\n- Faire varier les param\u00e8tres de construction de l'arbre de d\u00e9cision (bien mettre en pratique les 'Tips')\n- Pour chaque s\u00e9rie de param\u00e8tres, qualifier le r\u00e9sultat sur l'ensemble de test\n- Choisir l'arbre le 'meilleur' sur l'ensemble de test  \n\nN'oubliez pas le principe du ** rasoir d'Ockham ** pour effectuer votre choix !!!!!","f63b306f":"### R\u00e9ponses :"}}