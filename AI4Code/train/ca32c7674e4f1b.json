{"cell_type":{"27cb8560":"code","fee4e5ea":"code","aac9fe98":"code","7b971cc0":"code","a1c19125":"code","88c1f429":"code","3389556e":"code","b9c5bb4c":"code","33aae66a":"code","e8b3862e":"code","04d8c44c":"code","f14f3890":"code","82753e8a":"code","9fcba5a5":"code","9f3a1796":"markdown","297fe461":"markdown","67dc15ba":"markdown","8ae67159":"markdown","e1814f60":"markdown","e0c39a89":"markdown","3cbfeb80":"markdown","17c2ba0e":"markdown"},"source":{"27cb8560":"# Loading libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom statistics import mean\nfrom torch.autograd import Variable\nimport time\nfrom PIL import Image\nimport random\nfrom skimage import io, transform\nfrom collections import OrderedDict\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms, utils\nfrom torch import nn\n\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\nfrom matplotlib import pyplot as plt\nfrom skimage import io, transform\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Any results you write to the current directory are saved as output.","fee4e5ea":"csv_path =  '\/kaggle\/input\/lgg-mri-segmentation\/lgg-mri-segmentation\/kaggle_3m\/data.csv'\ndata_folder = '\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m'\neg_path = '\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/TCGA_HT_8113_19930809'\neg_img = '\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/TCGA_CS_4944_20010208\/TCGA_CS_4944_20010208_10.tif'\neg_mask = '\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/TCGA_CS_4944_20010208\/TCGA_CS_4944_20010208_10_mask.tif'","aac9fe98":"class Brain_data(Dataset):\n    def __init__(self,path):\n        self.path = path\n        self.patients = [file for file in os.listdir(path) if file not in ['data.csv','README.md']]\n        self.masks,self.images = [],[]\n\n        for patient in self.patients:\n            for file in os.listdir(os.path.join(self.path,patient)):\n                if 'mask' in file.split('.')[0].split('_'):\n                    self.masks.append(os.path.join(self.path,patient,file))\n                else: \n                    self.images.append(os.path.join(self.path,patient,file)) \n          \n        self.images = sorted(self.images)\n        self.masks = sorted(self.masks)\n        \n        \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self,idx):\n        image = self.images[idx]\n        mask = self.masks[idx]\n        image = io.imread(image)\n        image = transform.resize(image,(256,256))\n        image = image \/ 255\n        image = image.transpose((2, 0, 1))\n        \n        \n        mask = io.imread(mask)\n        mask = transform.resize(mask,(256,256))\n        mask = mask \/ 255\n        mask = np.expand_dims(mask,axis=-1).transpose((2, 0, 1))\n\n        image = torch.from_numpy(image)\n        mask = torch.from_numpy(mask)\n        \n        return (image,mask)\n            ","7b971cc0":"data = Brain_data(data_folder)\nprint('Length of dataset is {}'. format(data.__len__()))\nprint('sample data: ')\ndata.__getitem__(0)","a1c19125":"# checking shape of data\nfor img,msk in data:\n      print(img.shape)\n      print(msk.shape)\n      break","88c1f429":"# splitting to trainset and validation set\n\ntrainset, valset = random_split(data, [3600, 329])\n\ntrain_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=10,shuffle=True)\n\nval_loader = torch.utils.data.DataLoader(dataset=valset, batch_size=10)","3389556e":"# converting tensor to image\ndef image_convert(image):\n    image = image.clone().cpu().numpy()\n    image = image.transpose((1,2,0))\n    image = (image * 255)\n    return image\n\ndef mask_convert(mask):\n    mask = mask.clone().cpu().detach().numpy()\n    return np.squeeze(mask)\n\ndef plot_img(no_):\n    iter_ = iter(train_loader)\n    images,masks = next(iter_)\n    images = images.to(device)\n    masks = masks.to(device)\n    plt.figure(figsize=(20,10))\n    for idx in range(0,no_):\n         image = image_convert(images[idx])\n         plt.subplot(2,no_,idx+1)\n         plt.imshow(image)\n    for idx in range(0,no_):\n         mask = mask_convert(masks[idx])\n         plt.subplot(2,no_,idx+no_+1)\n         plt.imshow(mask,cmap='gray')\n    plt.show()","b9c5bb4c":"plot_img(5)","33aae66a":"class ConvBlock(nn.Module):\n    def __init__(self,in_channels,out_channels,kernel_size=(3,3),padding=1):\n        super(ConvBlock,self).__init__()\n        self.conv = nn.Conv2d(in_channels,out_channels,kernel_size,padding=padding,bias=False)\n        self.batchnorm = nn.BatchNorm2d(out_channels,eps=1e-4)\n        self.relu = nn.ReLU(inplace=True)\n        \n    def forward(self,x):\n        x = self.conv(x)\n        x = self.batchnorm(x)\n        x = self.relu(x)\n        return x\n        \n        \nclass StackEncoder(nn.Module):\n    def __init__(self,channel1,channel2,kernel_size=(3,3),padding=1):\n        super(StackEncoder,self).__init__()\n        self.maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n        self.block = nn.Sequential(\n            ConvBlock(channel1,channel2,kernel_size,padding),\n            ConvBlock(channel2,channel2,kernel_size,padding),     \n        )\n        \n    def forward(self,x):\n        big_out = self.block(x)\n        poolout = self.maxpool(big_out)\n        return big_out,poolout\n     \n        \nclass StackDecoder(nn.Module):\n    def __init__(self,big_channel,channel1,channel2,kernel_size=(3,3),padding=1):\n        super(StackDecoder,self).__init__()\n        self.block = nn.Sequential(\n            ConvBlock(channel1+big_channel,channel2,kernel_size,padding),\n            ConvBlock(channel2,channel2,kernel_size,padding),\n            ConvBlock(channel2,channel2,kernel_size,padding),\n        )\n        \n    def forward(self,x,down_tensor):\n            _, channels, height, width = down_tensor.size()  \n            x = F.upsample(x, size=(height, width), mode='bilinear')\n            x = torch.cat([x, down_tensor], 1)  #combining channels of  input from encoder and upsampling input\n            x = self.block(x)\n            return x\n        \n        \nclass Unet256(nn.Module):\n    def __init__(self,input_shape):\n        super(Unet256,self).__init__()\n        \n        channel,height,width = input_shape\n        \n        self.down1 = StackEncoder(channel,12,kernel_size=(3,3))  #256\n        self.down2 = StackEncoder(12,24,kernel_size=(3,3))  # 128\n        self.down3 = StackEncoder(24,46,kernel_size=(3,3))  # 64\n        self.down4 = StackEncoder(46,64,kernel_size=(3,3))  # 32\n        self.down5 = StackEncoder(64,128,kernel_size=(3,3))  #16\n        \n        self.center = ConvBlock(128,128,kernel_size=(3,3),padding=1) #16\n        \n        self.up5 = StackDecoder(128,128,64,kernel_size=(3,3))  #32\n        self.up4 = StackDecoder(64,64,46,kernel_size=(3,3)) #64\n        self.up3 = StackDecoder(46,46,24,kernel_size=(3,3))\n        self.up2 = StackDecoder(24,24,12,kernel_size=(3,3))\n        self.up1 = StackDecoder(12,12,12,kernel_size=(3,3))\n        self.conv = Conv2d(12,1,kernel_size=(1,1),bias=True)\n        \n    def forward(self,x):\n        down1,out = self.down1(x)  \n        down2,out = self.down2(out)  \n        down3,out = self.down3(out)\n        down4,out = self.down4(out)\n        down5,out = self.down5(out)\n        \n        \n        out = self.center(out)\n        \n        up5 = self.up5(out,down5)\n        up4 = self.up4(up5,down4)\n        up3 = self.up3(up4,down3)\n        up2 = self.up2(up3,down2)\n        up1 = self.up1(up2,down1)\n        \n        out = self.conv(up1)\n\n\n        return out\n        \n","e8b3862e":"# from torchsummary import summary\nmodel = Unet256((3,256,256)).to(device)\nmodel","04d8c44c":"\nclass DiceBCELoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceBCELoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        bce_weight = 0.5\n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice_loss = 1 - (2.*intersection + smooth)\/(inputs.sum() + targets.sum() + smooth)  \n        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n        loss_final = BCE * bce_weight + dice_loss * (1 - bce_weight)\n        return loss_final\n    \n    \n\nclass IoU(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(IoU, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        #intersection is equivalent to True Positive count\n        #union is the mutually inclusive area of all labels & predictions \n        intersection = (inputs * targets).sum()\n        total = (inputs + targets).sum()\n        union = total - intersection \n        \n        IoU = (intersection + smooth)\/(union + smooth)\n                \n        return IoU * 100\n\n    \n    \nclass DiceScore(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceScore, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = F.sigmoid(inputs)       \n        \n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice_score = (2.*intersection + smooth)\/(inputs.sum() + targets.sum() + smooth) \n        return dice_score","f14f3890":"criterion = DiceBCELoss()\n\n\nlearning_rate = 1e-3\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","82753e8a":"epochs = 25\n\n\ntrain_loss = []\nval_loss = []\n\nfor epoch in range(epochs):\n    print('Epoch {}\/{}'.format(epoch + 1, epochs))\n    start_time = time.time()\n     \n\n    \n    running_train_loss = []\n    \n    for image,mask in train_loader: \n            image = image.to(device,dtype=torch.float)\n            mask = mask.to(device,dtype=torch.float)\n            \n            pred_mask = model.forward(image) # forward propogation\n            loss = criterion(pred_mask,mask)\n            optimizer.zero_grad() # setting gradient to zero\n            loss.backward()\n            optimizer.step()\n            running_train_loss.append(loss.item())\n                              \n\n    else:           \n        running_val_loss = []\n        \n        with torch.no_grad():\n            for image,mask in val_loader:\n                    image = image.to(device,dtype=torch.float)\n                    mask = mask.to(device,dtype=torch.float)                            \n                    pred_mask = model.forward(image)\n                    loss = criterion(pred_mask,mask)\n                    running_val_loss.append(loss.item())\n                    \n\n                                    \n    \n    epoch_train_loss = np.mean(running_train_loss) \n    print('Train loss: {}'.format(epoch_train_loss))                       \n    train_loss.append(epoch_train_loss)\n    \n    epoch_val_loss = np.mean(running_val_loss)\n    print('Validation loss: {}'.format(epoch_val_loss))                                \n    val_loss.append(epoch_val_loss)\n                      \n    time_elapsed = time.time() - start_time\n    print('{:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n                        \n","9fcba5a5":"plt.plot(train_loss,label='train_loss')\nplt.plot(val_loss,label='val_loss')\nplt.legend()\nplt.title('Loss Plot')\nplt.show()","9f3a1796":"No we will check the shape of the tensors","297fe461":"This dataset contains brain MR images together with manual FLAIR abnormality segmentation masks.\nThe images were obtained from The Cancer Imaging Archive (TCIA).\nThey correspond to 110 patients included in The Cancer Genome Atlas (TCGA) lower-grade glioma collection with at least fluid-attenuated inversion recovery (FLAIR) sequence and genomic cluster data available. Baiscally we have a segmentation problem.\n\nIn this kernal we will segment using a basic Unet architecture.","67dc15ba":"First we will load the dataset by writing a custom Dataset loader","8ae67159":"Now we will split the data to train and validation such a way that 3600 image in train and 329 images in validation. After that we load the data the batches for training using DataLoader.","e1814f60":"### Loss function ","e0c39a89":"Next we will visualize the images ","3cbfeb80":"### **Unet Architecture**","17c2ba0e":"Now we will write out loss function.Here in this segmentation problem we will use combination of  dice loss and binary cross entropy as our loss function.\n\nDice coeff = 2\u2217|X\u2229Y| \/ |X|+|Y|\n\nWith X being our prediction matrix and Y our target matrix."}}