{"cell_type":{"0d82d740":"code","c2079e88":"code","e28507ea":"code","b5c4b9ca":"code","ff0a6d95":"code","e176dbb3":"code","f868b8ba":"code","6574b1dd":"code","c207e4d4":"code","04ef491f":"code","6ec25bb5":"code","5a1ada51":"code","d16069ca":"code","4c23db6a":"code","7c8c6802":"code","416f24c2":"code","1f7d1704":"code","a06c30e8":"code","88602b24":"code","39c07736":"code","0e8cc5ed":"code","b137378b":"code","7ccf902c":"markdown"},"source":{"0d82d740":"import keras\n\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense,Convolution2D, Flatten, MaxPooling2D, Dropout\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sbn\nimport cv2 as cv\nimport random\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')","c2079e88":"#loading the dataset\ntraining_set = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\ntesting_set = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_test.csv')","e28507ea":"training_set.head()","b5c4b9ca":"testing_set.tail()","ff0a6d95":"training = np.array(training_set, dtype = 'float32')\ntesting = np.array(testing_set, dtype = 'float32')","e176dbb3":"i = random.randint(0,6001)","f868b8ba":"plt.imshow(training[i,1:].reshape(28,28))","6574b1dd":"fig , axe = plt.subplots(15,15, figsize=(17,17)) #create a plot of 15 row and 15 column each with a size of 17x17\naxe = axe.ravel() #reareange the array of axe as 1D\nlen_train = len(training_set) #getting the length of the training set\n\nfor i in np.arange(0, 15*15): #creating a loop the runs for 225 time, which is the amonth of subplot we created\n    \n    index = np.random.randint(0,len_train) #creating a random numbers from 0 to lenght og training set, we will use to index the image\n    \n    axe[i].imshow(training[index, 1:].reshape(28,28))\n    axe[i].set_title(training[index,0], fontsize = 8)\n    axe[i].axis('off')\nplt.subplots_adjust(hspace=0.4)","c207e4d4":"x_train = training[:,1 :]\/255  # picking all row from the second column to the last and normalizing the values by dividing by 255\ny_train = training[:,0] # picking just the label column from the training set","04ef491f":"x_test = testing[:,1 :]\/255\ny_test = testing[:, 0]","6ec25bb5":"x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size= 0.2, random_state = 12345)\n","5a1ada51":"#resize the image \nx_train = x_train.reshape(x_train.shape[0], 28,28,1)   \nx_validate = x_validate.reshape(x_validate.shape[0], 28,28,1) \nx_test = x_test.reshape(x_test.shape[0], *(28,28,1)) # since the reshape expects just normal int but we are passing tuple so we use asterick ","d16069ca":"a = x_train.shape\na","4c23db6a":"#creating the CNN layers \nclassifier = Sequential()\nclassifier.add(Convolution2D(32, (3,3), input_shape=(28,28,1), activation='relu')) # add a 32 feature detector to the CNN, with a 3x3 shape\nclassifier.add(MaxPooling2D(pool_size=(2,2))) #appling maxpooling od size 2x2 to the CNN\n\nclassifier.add(Flatten()) # we flatten the CNN into one single vector","7c8c6802":"#connect the CNN to the ANN\nclassifier.add(Dense(output_dim=32, activation='relu')) # adding the hidden layer of 32 neurons\nclassifier.add(Dense(output_dim=32, activation='relu')) # adding the hidden layer of 32 neurons\nclassifier.add(Dense(output_dim=32, activation='relu')) # adding the hidden layer of 32 neurons\nclassifier.add(Dense(output_dim=32, activation='relu')) # adding the hidden layer of 32 neurons\nclassifier.add(Dense(output_dim=32, activation='relu')) # adding the hidden layer of 32 neurons\nclassifier.add(Dense(output_dim=32, activation='relu')) # adding the hidden layer of 32 neurons\nclassifier.add(Dense(output_dim=32, activation='relu')) # adding the hidden layer of 32 neurons\nclassifier.add(Dense(output_dim=32, activation='relu')) # adding the hidden layer of 32 neurons\nclassifier.add(Dense(output_dim=10, activation='sigmoid')) #adding output layer of 10 neurons ","416f24c2":"classifier.compile(loss = 'sparse_categorical_crossentropy', optimizer= Adam(lr=0.001), metrics= ['sparse_categorical_accuracy'])","1f7d1704":"classifier.fit(x_train,\n               y_train,\n               batch_size=512,\n               epochs=50,\n               verbose=1,\n               validation_data=(x_validate,y_validate)\n              )\nclassifier.save('fashion_class.h5')","a06c30e8":"evalu = classifier.evaluate(x_test,y_test) \nprint('Test accuracu is {:0.3f}'.format(evalu[1]))","88602b24":"predicted_class = classifier.predict_classes(x_test) #getting all the predicted class of the x_test","39c07736":"fig,axe = plt.subplots(5,5, figsize=(12,12))# creating a 5x5 graph of size 12x12 each\naxe = axe.ravel()#flatten the value of axe into a vector format\n\nfor i in np.arange(0,5*5):# we will loop through 25 times\n    axe[i].imshow(x_test[i].reshape(28,28)) #for each index of graph we add a image from x_test and reshape the image\n    axe[i].set_title('prediction class = {:0.1f}\\n True class = {:0.1f}'.format(predicted_class[i], y_test[i]))\n    #showing the predicted class and the true value of the predicted class\n    axe[i].axis('off')\nplt.subplots_adjust(wspace =0.55)","0e8cc5ed":"confmetrix = confusion_matrix(y_test, predicted_class)\nplt.figure(figsize=(14,10))\nsbn.heatmap(confmetrix, annot=True)","b137378b":"class_names = ['class {}'.format(i)for i in range(0,10)]\nprint(classification_report(y_test,predicted_class, target_names= class_names))","7ccf902c":"                                                        CLASSIFICATION REPORT"}}