{"cell_type":{"133ca3a6":"code","85a62842":"code","82a80791":"code","66ec6943":"code","bdefa619":"code","730813b1":"code","b4dc2877":"code","c25df58c":"code","9408c496":"code","56b23cf8":"code","cc49ec38":"code","67da6d67":"code","48b1022c":"code","38aeebb9":"code","d489e5bd":"code","12756964":"code","b216be76":"code","4fcde3bf":"code","3dc1f99f":"code","1e1551a2":"code","6748dc52":"code","897e2f50":"code","6e71ab9d":"code","868e76de":"markdown","d96bb0e3":"markdown","79fb1320":"markdown","27c36a4c":"markdown","123811df":"markdown","34e52d79":"markdown","46d7e0ce":"markdown","355531d0":"markdown","32be2f92":"markdown","b855394d":"markdown","bdb15222":"markdown","2d1c0c50":"markdown","4428204f":"markdown","cedd30a0":"markdown","5847c18a":"markdown","2b935cd9":"markdown","4257056d":"markdown","8cb56682":"markdown"},"source":{"133ca3a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","85a62842":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer","82a80791":"# setting display options\npd.set_option('display.max_colwidth', 900, \"display.max_columns\", 30, \"display.max_rows\", 100)\ntweets_data = pd.read_csv('\/kaggle\/input\/all-covid19-vaccines-tweets\/vaccination_all_tweets.csv')\ntweets_data.head(2)","66ec6943":"tweets_data = tweets_data.drop(['user_name', 'user_location', \n                                'user_description', 'user_created', \n                                'user_followers', 'user_friends', \n                                'user_favourites', 'user_verified', \n                                'source', 'retweets', 'favorites', 'is_retweet'], axis=1)\n\ntweets_data['date'] = pd.to_datetime(tweets_data['date']).dt.date\ntweets_data.info()","bdefa619":"# fill null with 'Notags'\ntweets_data['hashtags'] = tweets_data['hashtags'].fillna('Notags')\n# cleaning and adaptive for analysis\ntweets_data['hashtags'] = [re.sub(\"[(\\[\\')|(\\]\\')|\\s]\", '', tags) for tags in tweets_data['hashtags']]\ntweets_data.info()","730813b1":"tweets_data.head()","b4dc2877":"# prepare stopwords\nstopwords = set(stopwords.words('english'))\n\n# this 'deEmojify': via https:\/\/www.kaggle.com\/sharibkhan\/my-first-semantic-analysis-problem-in-nlp\ndef deEmojify(inputString):\n    return inputString.encode('ascii', 'ignore').decode('ascii')\n\ndef nlp(text):\n    corpus = []\n    text = deEmojify(text)\n    text = re.sub('http\\S+', '', text) # remove url\n    text = re.sub('#\\w+', '', text) # remove hashtags\n    text = re.sub('@[^\\s]+', '', text) # remove @twitter_id\n    text = text.split()\n    corpus = [txt for txt in text if not txt in stopwords]\n    return ' '.join(corpus)\n\ntweets_data['text_nlp'] = tweets_data['text'].apply(lambda x: nlp(x))\ntweets_data['text_nlp'].head()","c25df58c":"# if you want to study more, below link is so useful for me\n# https:\/\/www.analyticsvidhya.com\/blog\/2018\/02\/natural-language-processing-for-beginners-using-textblob\/\n\nsample = tweets_data['text_nlp'][22]\nprint(sample)\n\ntestimonial = TextBlob(sample)\npola = testimonial.sentiment.polarity\nsubj = testimonial.sentiment.subjectivity\nprint('pola', pola, 'subj', subj)","9408c496":"sample = 'Thank you, but I finally use other items another gave me'\nprint(sample)\n\ntestimonial = TextBlob(sample)\npola = testimonial.sentiment.polarity\nsubj = testimonial.sentiment.subjectivity\nprint('pola', pola, 'subj', subj)","56b23cf8":"def polarity(text):\n    testimonial = TextBlob(text)\n    polarity = testimonial.sentiment.polarity\n    return polarity\n\n\ndef subjectivity(text):\n    testimonial = TextBlob(text)\n    subjectivity = testimonial.subjectivity\n    return subjectivity\n\n\ndef senti(text, polarity_threshold=0.2):\n    testimonial = TextBlob(text)\n    senti = testimonial.sentiment.polarity\n    \n    if senti >= polarity_threshold:\n        return 'Positive'\n    elif np.abs(senti) < polarity_threshold:\n        return 'Neutral'\n    else:\n        return 'Negative'\n    \n\ntweets_data['polarity'] = tweets_data['text_nlp'].apply(lambda x: polarity(x))\ntweets_data['subjectivity'] = tweets_data['text_nlp'].apply(lambda x: subjectivity(x))\ntweets_data['sentiment'] = tweets_data['text_nlp'].apply(lambda x: senti(x))\ntweets_data.head()","cc49ec38":"fig, ax = plt.subplots(3, 1, figsize=(15, 15))\nsentiments = tweets_data['sentiment'].unique()\nfor i, senti in enumerate(sentiments):\n    senti_df = tweets_data.query('sentiment==@senti')\n    cloud = ' '.join([tweet for tweet in senti_df['text_nlp']])\n    wc = WordCloud(max_words=2000, width=1600, \\\n                   height=800, stopwords=stopwords).generate(cloud)\n\n    ax[i].set_title(senti, fontsize=25)\n    ax[i].axis('off')\n    ax[i].imshow(wc , interpolation = 'bilinear')\n    \nplt.tight_layout()\nplt.show()","67da6d67":"fig, ax = plt.subplots(3, 1, figsize=(10, 8), sharey=True, sharex=True)\n\nsentiments = tweets_data['sentiment'].unique()\ncolors = ['green', 'blue', 'red']\nplt.suptitle('words in texts', fontsize=30)\nfor i, senti in enumerate(sentiments):\n    senti_df = tweets_data.query('sentiment==@senti')\n    # number of words in text\n    # ex. 'Explain need vaccine' -> 3\n    words_len = senti_df['text_nlp'].str.split().map(lambda x: len(x))\n    ax[i].set_title(senti, fontsize=25)\n    ax[i].hist(words_len, color=colors[i], bins=20)\n    \nplt.tight_layout()\nplt.show()","48b1022c":"fig, ax = plt.subplots(3, 1, figsize=(10, 8), sharey=True, sharex=True)\n\nsentiments = tweets_data['sentiment'].unique()\nplt.suptitle('characters len in texts', fontsize=30)\ncolors = ['green', 'blue', 'red']\nfor i, senti in enumerate(sentiments):\n    posi_df = tweets_data.query('sentiment==@senti')\n    # chars of words in text\n    words_len = posi_df['text_nlp'].str.len()\n    ax[i].set_title(senti, fontsize=25)\n    ax[i].hist(words_len, color=colors[i], bins=20)\n    \nplt.tight_layout()\nplt.show()","38aeebb9":"fig, ax = plt.subplots(1, 3, figsize=(12,8), sharey=True, sharex=True)\nsentiments = tweets_data['sentiment'].unique()\ncolors = ['green', 'blue', 'red']\nfig.suptitle('Average word len in each text', fontsize=25)\n\nfor i, senti in enumerate(sentiments):\n    senti_df = tweets_data.query('sentiment==@senti')\n    word = senti_df['text_nlp'].str.split().apply(lambda x: [len(i) for i in x])\n    sns.histplot(word.apply(lambda x: np.mean(x)), ax=ax[i], color=colors[i])\n    ax[i].set_title(senti, fontsize=20)\n\nplt.tight_layout()\nplt.xlim([0, 20])\nplt.show()","d489e5bd":"# via https:\/\/www.kaggle.com\/madz2000\/nlp-using-glove-embeddings-99-87-accuracy\ndef get_top_text_ngrams(corpus, n, g):\n    vec = CountVectorizer(ngram_range=(g, g)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]\n\nfig, ax = plt.subplots(1, 3, figsize=(13,8))\nsentiments = tweets_data['sentiment'].unique()\ncolors = ['green', 'blue', 'red']\nfor i, senti in enumerate(sentiments):\n    senti_df = senti_df = tweets_data.query('sentiment==@senti')['text_nlp']\n    most_common_bi = get_top_text_ngrams(senti_df,10,1)\n    most_common_bi = dict(most_common_bi)\n    sns.barplot(x=list(most_common_bi.values()),y=list(most_common_bi.keys()), ax=ax[i])\n    ax[i].set_title(senti, fontsize=20, color=colors[i])\n\nplt.suptitle('Unigram of each sentiment', fontsize=25)\nplt.tight_layout()\nplt.show()","12756964":"fig, ax = plt.subplots(1, 3, figsize=(13,8))\nsentiments = tweets_data['sentiment'].unique()\ncolors = ['green', 'blue', 'red']\nfor i, senti in enumerate(sentiments):\n    senti_df = senti_df = tweets_data.query('sentiment==@senti')['text_nlp']\n    most_common_bi = get_top_text_ngrams(senti_df, 10, 2)\n    most_common_bi = dict(most_common_bi)\n    sns.barplot(x=list(most_common_bi.values()),y=list(most_common_bi.keys()), ax=ax[i])\n    ax[i].set_title(senti, fontsize=20, color=colors[i])\n\nplt.suptitle('Bigram of each sentiment', fontsize=25)\nplt.tight_layout()\nplt.show()","b216be76":"fig, ax = plt.subplots(1, 3, figsize=(13,8))\nsentiments = tweets_data['sentiment'].unique()\ncolors = ['green', 'blue', 'red']\nfor i, senti in enumerate(sentiments):\n    senti_df = senti_df = tweets_data.query('sentiment==@senti')['text_nlp']\n    most_common_bi = get_top_text_ngrams(senti_df, 10, 3)\n    most_common_bi = dict(most_common_bi)\n    sns.barplot(x=list(most_common_bi.values()),y=list(most_common_bi.keys()), ax=ax[i])\n    ax[i].set_title(senti, fontsize=20, color=colors[i])\n\nplt.suptitle('Trigram of each sentiment', fontsize=25)\nplt.tight_layout()\nplt.show()","4fcde3bf":"hashtags = tweets_data['hashtags']\nhead_refs = ['pfize', 'biont', 'sinop', 'sinov', 'moder', 'oxfor', 'astra', 'covax', 'sputn']\nreference_dict = {'pfize': 'Pfizer\/BioNTech', \n                  'biont': 'Pfizer\/BioNTech', \n                  'sinop': 'Sinopharm', \n                  'sinov': 'Sinovac', \n                  'moder': 'Moderna', \n                  'oxfor': 'Oxford\/AstraZeneca', \n                  'astra': 'Oxford\/AstraZeneca', \n                  'covax': 'Covaxin', \n                  'sputn': 'Sputnik V'}\n\nkinds_of_refs = []\nfor hashtag in hashtags:\n    tag_list = []\n    tags = hashtag.split(',')\n    for tag in tags:\n        if tag.lower()[:5] in reference_dict.keys():\n            refer = reference_dict[tag.lower()[:5]]\n            tag_list.append(refer)\n    \n    if len(tag_list) > 0:\n        kinds_of_refs.append(tag_list)\n    else:\n        kinds_of_refs.append(['NoTags'])\n            \ntweets_data['vaccine_hashtags'] = kinds_of_refs","3dc1f99f":"def reference(tags, refs):\n    flag = 0\n    if refs in tags:\n        return 1\n    else:\n        return 0\n    \ntweets_data['pfizer'] = tweets_data['vaccine_hashtags'].apply(lambda x: reference(x, 'Pfizer\/BioNTech'))\ntweets_data['sinopharm'] = tweets_data['vaccine_hashtags'].apply(lambda x: reference(x, 'Sinopharm'))\ntweets_data['sinovac'] = tweets_data['vaccine_hashtags'].apply(lambda x: reference(x, 'Sinovac'))\ntweets_data['moderna'] = tweets_data['vaccine_hashtags'].apply(lambda x: reference(x, 'Moderna'))\ntweets_data['oxford'] = tweets_data['vaccine_hashtags'].apply(lambda x: reference(x, 'Oxford\/AstraZeneca'))\ntweets_data['covaxin'] = tweets_data['vaccine_hashtags'].apply(lambda x: reference(x, 'Covaxin'))\ntweets_data['sputnik'] = tweets_data['vaccine_hashtags'].apply(lambda x: reference(x, 'Sputnik V'))","1e1551a2":"tweets_data = tweets_data.drop(['hashtags', 'vaccine_hashtags'], axis=1)\ntweets_data.head(3)","6748dc52":"results = {}\nvaccines = ['pfizer', 'sinopharm', 'sinovac', 'moderna', 'oxford', 'covaxin', 'sputnik']\nfor vaccine in vaccines:\n    prefix = vaccine + '_'\n    df = pd.DataFrame(tweets_data.query(f'{vaccine}==1')[['polarity', 'subjectivity']].describe())\n    results[prefix] = df\n    \nstats_dict = pd.concat(results.values(), axis=1, keys=results.keys())\nstats_dict","897e2f50":"_, axes = plt.subplots(1, 2, figsize=(15, 8))\nstats_dict.loc['mean', ::2].plot(kind='barh', ax=axes[0])\nstats_dict.iloc[1, 1::2].plot(kind='barh', ax=axes[1])\naxes[0].set_title('Each Mean of Polarity ', fontsize=20, color='red')\naxes[1].set_title('Each Mean of subjectivity', fontsize=20, color='blue')\n\nplt.tight_layout()\nplt.show()","6e71ab9d":"vaccines_df = {}\n\nfor vaccine in vaccines:\n    df = tweets_data.query(f'{vaccine}==1')[['date', 'polarity', 'sentiment']]\n    df = df.sort_values(by='date')\n    df['Avg_'+vaccine] = df.polarity.rolling(20, min_periods=3).mean()\n    vaccines_df[vaccine] = df\n\nfor i, (name, df) in enumerate(vaccines_df.items()):\n    plt.figure(figsize=(10, 7))\n    plt.plot(df.date, df.iloc[:, -1])\n    plt.xticks(rotation=45)\n    plt.title('\\n'+name+'\\n', fontsize=25)\n    plt.ylim([-0.2, 0.8])\n    plt.tight_layout()\n    plt.show()","868e76de":"<div style=\"background-color: lightgreen;padding:20px\">\n    <h1 style=\"color:gray\">NLP Sentiment Analysis<\/h1>\n    <h2>We explore the tweet data this time. We check how the data is later.<\/h2>\n    <h2>This data has text data and we care about what approaches are better ways in this data. <\/h2>\n    <h2>I tried EDA-> Visualize -> NLP -> seek data in chronological order per kinds of vaccine<\/h2>\n<\/div>","d96bb0e3":"#### sample image","79fb1320":"<div style=\"background-color: lightgreen;padding:20px\">\n    <h1 style=\"color:red\">Get the sentiment from tweet<\/h1>\n    <h3>\n        I use TextBlob to data.\n        <br>\n        <br>\n        TextBlob is good for NLP and beginner (like me, haha)!<br>\n        We can get the sentiment from polarity (+1~-1, getting to +1 means positive sentiment, -1 is oppsit.)\n    <\/h3>\n<\/div>","27c36a4c":"<div style=\"background-color: lightgreen;padding:15px\">\n    <h1 style=\"color:red\">Last, how sentiment move, time goes by??<\/h1>\n<\/div>","123811df":"## Next, we check wordcloud per sentiment then we get to know what words each sentiment groups have","34e52d79":"## Sinop, covax, sput have the mountain in above graph, this means those vaccine have good sentiment in Twitter at that time!","46d7e0ce":"<div style=\"background-color: lightyellow;padding:20px\">\n    <h3>\n        OK, I suppose Negas worried about 'be forced to take shot' 'eating alone to avoid that others infect because of me'\n        <br>\n        <br>\n        Posi care about 'when taking vaccine starts? is it free??'\n    <\/h3>\n<\/div>","355531d0":"## 'text' col has noises. Let's remove it","32be2f92":"<div style=\"background-color: lightgreen;padding:20px;text-align:center;\">\n    <h1 style=\"color:red\">Conclusion<\/h1>\n    <h2>We sought data and try various ways<\/h2>\n    <h2>We got to know each senti have their own opinion about vaccine, sometimes positively, sometimes negatively<\/h2>\n<\/div>\n\n<h2>I stop trying for the moment here.<\/h2>\n<h2>Thank you for visiting my notebook and feel free to comment or upvote!!<\/h2>","b855394d":"<div style=\"background-color: lightyellow;padding:20px\">\n    <h3>\n        Actually, polarity > 0 (or < 0)  means pos or neg senti but I doubt 'is it really positive??'\n        <br>\n        <br>\n        Let's imagine when you tweet 'Thank you, but I finally use other items another gave me'\n        <br>\n        <br>\n        Of couse, it depends on your feeling but I think this is not 'negative'. This seems to be Neutral??\n        <br>\n        <br>\n        So, I set the threshold in my_function. Please change the threshold however you like when you have some opinion!\n    <\/h3>\n<\/div>","bdb15222":"### negatives have doubts vaccines work well??\n### positives want (wanted?) to take vaccine??","2d1c0c50":"### Number of Neutral is more than others so its hist tends to be high.\n### but Neutral chars length is longer than others. ","4428204f":"### check stats per kinds of vaccines and try to figure out main sentiment per vaccine","cedd30a0":"## It shows Sinopharm is liked better than others?","5847c18a":"### check hashtags and add vaccine cols","2b935cd9":"<div style=\"background-color: lightgreen;padding:20px\">\n    <h1 style=\"color:red\">Next, We seek data per type of vaccines<\/h1>\n    <h3>\n        We can't seach all hashtag cols, hence we search initial 5 letters and don't seach related words\n        <br>\n        <br>\n        TextBlob is good for NLP and beginner (like me, haha)!<br>\n        We can get the sentiment from polarity (+1~-1, getting to +1 means positive sentiment, -1 is oppsit.)\n    <\/h3>\n<\/div>\n\nif you would like to get deeply, below link is very useful! <br>\nhttps:\/\/www.kaggle.com\/amartyanambiar\/covid-19-vaccine-sentitmental-analysis\/notebook","4257056d":"## Import and check data","8cb56682":"# EDA\n\n<div style=\"background-color:lightyellow;padding:18px\">\n    <h3>\n        We drop useless cols, (for instance user_name, location, is_retweet, etc.) because we consider text data.\n        <br><br>\n        If you have interests of analysis you'd like to try with various ways, keep lefting those cols!\n    <\/h3>\n<\/div>"}}