{"cell_type":{"5bf9d79c":"code","19200c3c":"code","4bbe43fe":"code","5bb731e0":"code","6d078d8b":"markdown","bafb8322":"markdown","960637c1":"markdown","08652325":"markdown","4706fc12":"markdown","eb298b51":"markdown","fd49a77e":"markdown"},"source":{"5bf9d79c":"import numpy as np\nimport scipy\nimport matplotlib.pyplot as plt\n#seed(1)\nanomalies = []\n\n# multiply and add by random numbers to get some real values\ndata = np.random.randn(50000)  * 20 + 20\n\n# Function to Detection Outlier on one-dimentional datasets.\ndef find_anomalies(data):\n    # Set upper and lower limit to 3 standard deviation\n    random_data_std = scipy.std(data)\n    random_data_mean = scipy.mean(data)\n    anomaly_cut_off = random_data_std * 3\n    \n    lower_limit  = random_data_mean - anomaly_cut_off \n    upper_limit = random_data_mean + anomaly_cut_off\n    print(lower_limit)\n    print (upper_limit)\n    # Generate outliers\n    for outlier in data:\n        if outlier > upper_limit or outlier < lower_limit:\n            anomalies.append(outlier)\n    return anomalies\n\nfind_anomalies(data)","19200c3c":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.boxplot(data=data)","4bbe43fe":"from sklearn.cluster import DBSCAN\nimport random \nrandom.seed(1)\nrandom_data = np.random.randn(50000,2)  * 20 + 20\n\noutlier_detection = DBSCAN(min_samples = 2, eps = 3)\nclusters = outlier_detection.fit_predict(random_data)\nlist(clusters).count(-1) \n\n#Sklearn labels noisy points as -1\n","5bb731e0":"from sklearn.ensemble import IsolationForest\nimport numpy as np\nnp.random.seed(1)\nrandom_data = np.random.randn(50000,2)  * 20 + 20\n\nclf = IsolationForest( behaviour = 'new', max_samples=100, random_state = 1, contamination= 'auto')\npreds = clf.fit_predict(random_data)\npreds","6d078d8b":"**MEthod 3 DBSCAN **","bafb8322":"The above code displays the plot below. As you can see, it considers everything above 75 or below ~ -35 to be an outlier. The results are very close to method 1 above.","960637c1":"**METHOD 4 ISOLATION FOREST - BUILDS iTREE ! **","08652325":"**The output of this code is a list of values above 80 and below -40. Notice that the dataset I am passing is a one-dimensional dataset. Now, let\u2019s explore more advanced methods for multi-dimensional datasets.\nIn statistics, If a data distribution is approximately normal then about 68% of the data values lie within one standard deviation of the mean and about 95% are within two standard deviations, and about 99.7% lie within three standard deviationsTherefore, if you have any data point that is more than 3 times the standard deviation, then those points are very likely to be anomalous or outliers.**","4706fc12":"**METHOD 1 - STD. DeVIAtion**","eb298b51":"**METHOD 2 - BOXPLOTS **","fd49a77e":"**Detecting outliers or anomalies is one of the core problems in data mining. The emerging expansion and continued growth of data and the spread of IoT devices, make us rethink the way we approach anomalies and the use cases that can be built by looking at those anomalies.\n\nWe now have smart watches and wristbands that can detect our heartbeats every few minutes. Detecting anomalies in the heartbeat data can help in predicting heart diseases. Anomalies in traffic patterns can help in predicting accidents. It can also be used to identify bottlenecks in network infrastructure and traffic between servers. Hence, the use cases and solution built on top of detecting anomalies are limitless.\n\nAnother reason why we need to detect anomalies is that when preparing datasets for machine learning models, it is really important to detect all the outliers and either get rid of them or analyze them to know why you had them there in the first place.\n\nNow, let\u2019s explore 5 common ways to detect anomalies starting with the most simple way.**"}}