{"cell_type":{"97f9b58e":"code","8728d9cc":"code","6fd2d496":"code","9de85300":"code","afa9eb36":"code","fcc9889d":"code","4f6df937":"code","7df956a0":"code","7997fcd0":"code","2face236":"code","cdc63dc1":"markdown","dfffc4ba":"markdown","612e20e1":"markdown","76040a20":"markdown","fda8ba05":"markdown","5ed0afa3":"markdown","a32bab7a":"markdown"},"source":{"97f9b58e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.tree import DecisionTreeRegressor\nfrom statistics import mean \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pylab as plt\n\n## Add these lines to turn off the warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8728d9cc":"#Set up the input path \ninput_file_path = '..\/input\/titanic\/train.csv'\ntest_file_path = '..\/input\/titanic\/test.csv'\n\n\n#Create the data frames for the input & test  data\ninput_data = pd.read_csv(input_file_path)\ntest_data = pd.read_csv(test_file_path)","6fd2d496":"#Plots grapgh shows the comparision between dead and survived\nfig = plt.figure(figsize=(20,30))  #Dimensions of the whole grid\n\n##Plots Survived vs Dead\nplt.subplot2grid((5,3),(0,0))  #Tells where the graph starts in the grid\ninput_data.Survived.value_counts(normalize=True).plot(kind='bar', alpha=1) #Plots the graph\nplt.title(\"Survived vs Dead\") #Title of the graph \nind=np.arange(2) \nplt.xticks(ind, ('Dead','Survived'))\nplt.text(0.5,0.5, 'Only 40% survived', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n##Plots Survived with respect to Age \nplt.subplot2grid((5,3),(0,1)) \nplt.scatter(input_data.Survived, input_data.Age, alpha=0.05)\nplt.title(\"Survived wrt Age\")\nplt.text(.2,30, 'High density in age range 20-40', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n##Plots the class distribution of the passengers\nplt.subplot2grid((5,3),(0,2))  #Tells where the graph starts in the grid\ninput_data.Pclass.value_counts(normalize=True).plot(kind='bar', alpha=1) #Plots the graph\nplt.title(\"Class distribution\") #Title of the graph \nplt.text(0.5,0.5, 'Uneven distribution of passengers', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n#Plots the class distribution with respect to age\nplt.subplot2grid((5,3),(1,0)) #Tells where the graph starts in the grid\nfor x in [1,2,3]:\n    input_data.Age[input_data.Pclass == x].plot(kind=\"kde\")\nplt.title(\"Class wrt Age\")\nplt.legend((\"1st\",\"2nd\",\"3rd\"))\nplt.text(0.01,0.005, '1st class passengers are relatively old', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n##Plots the distribution of the passengers on where they on-boraded\nplt.subplot2grid((5,3),(1,1))  #Tells where the graph starts in the grid\ninput_data.Embarked.value_counts(normalize=True).plot(kind='bar', alpha=1) #Plots the graph\nplt.title(\"Embarked distribution\") #Title of the graph \nplt.text(0.5,0.5, '70% of passengers boarded Titanic \\nin South Hampton, England', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n##Plots Men Survived \nplt.subplot2grid((5,3),(1,2))  #Tells where the graph starts in the grid\ninput_data.Survived[input_data.Sex==\"male\"].value_counts(normalize=True).plot(kind='bar', alpha=1) #Plots the graph\nplt.title(\"Men Survived\") #Title of the graph \nind=np.arange(2) \nplt.xticks(ind, ('Dead','Survived'))\nplt.text(0.5,0.5, '80% Men dead', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n##Plots Women Survived \nplt.subplot2grid((5,3),(2,0))  #Tells where the graph starts in the grid\ninput_data.Survived[input_data.Sex==\"female\"].value_counts(normalize=True).plot(kind='bar', alpha=0.25, color = ['#FA0000']) #Plots the graph\nplt.title(\"Women Survived\") #Title of the graph \nind=np.arange(2) \nplt.xticks(ind, ('Survived','Dead'))\nplt.text(0.5,0.5, 'Only 25% women dead', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n##Plots Men vs Women among Survived \nplt.subplot2grid((5,3),(2,1))  #Tells where the graph starts in the grid\ninput_data.Sex[input_data.Survived == 1].value_counts(normalize=True).plot(kind='bar', alpha=0.25, color = ['#FA0000','b']) #Plots the graph\nplt.title(\"Survived Men vs Women\") #Title of the graph \nind=np.arange(2) \n# plt.xticks(ind, ('Women','Men'))\nplt.text(0.4,0.5, '75% of who survived are women', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n#Plots the class distribution with respect to Survival\nplt.subplot2grid((5,3),(2,2)) #Tells where the graph starts in the grid\nfor x in [1,2,3]:\n    input_data.Survived[input_data.Pclass == x].plot(kind=\"kde\")\nplt.title(\"Class wrt Survived\")\nplt.legend((\"1st\",\"2nd\",\"3rd\"))\nplt.text(0.2,1.75, 'Most survived passengers are 1st class passengers \\nMost dead are 3rd class passengers', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n#Plots percentage of rich men survived\nplt.subplot2grid((5,3),(3,0)) #Tells where the graph starts in the grid\ninput_data.Survived[(input_data.Pclass == 1) & (input_data.Sex == 'male')].value_counts(normalize=True).plot(kind=\"bar\")\nplt.title(\"Rich Men Survived\")\nind=np.arange(2) \nplt.xticks(ind, ('Dead','Survived'))\nplt.text(0.5,0.5, '35% of rich men survived', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n#Plots percentage of poor men survived\nplt.subplot2grid((5,3),(3,1)) #Tells where the graph starts in the grid\ninput_data.Survived[(input_data.Pclass == 3) & (input_data.Sex == 'male')].value_counts(normalize=True).plot(kind=\"bar\")\nplt.title(\"Poor Men Survived\")\nind=np.arange(2) \nplt.xticks(ind, ('Dead','Survived'))\nplt.text(0.5,0.5, '85% of poor men dead', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n#Plots percentage of rich women survived\nplt.subplot2grid((5,3),(3,2)) #Tells where the graph starts in the grid\ninput_data.Survived[(input_data.Pclass == 1) & (input_data.Sex == 'female')].value_counts(normalize=True).plot(kind=\"bar\", alpha =0.25, color = ['#FA0000'])\nplt.title(\"Rich women Survived\")\nind=np.arange(2) \nplt.xticks(ind, ('Dead','Survived'))\nplt.text(0.5,0.5, '95% of rich women survived', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\n\n#Plots percentage of poor women survived\nplt.subplot2grid((5,3),(4,0)) #Tells where the graph starts in the grid\ninput_data.Survived[(input_data.Pclass == 3) & (input_data.Sex == 'female')].value_counts(normalize=True).plot(kind=\"bar\", alpha =0.25, color = ['#FA0000'])\nplt.title(\"Poor women Survived\")\nind=np.arange(2) \nplt.xticks(ind, ('Dead','Survived'))\nplt.text(0.3,0.3, '50% of poor women survived', style='italic',bbox={'facecolor':'red', 'alpha':0.5, 'pad':10})\n\nplt.show()\n","9de85300":"\n#Clean up the input & test data and delete NULL values \n# input_data = input_data.dropna(axis=0)\n# test_data = test_data.dropna(axis=0)\n\n# input_data.columns\n\n# def deal_with_null_values(dataset):\n#     dataset.isnull().sum()\n# #   dataset.Survived.mean()\n#     #Impute Age with mean value \n#     dataset['Age'].fillna(dataset['Age'].mean(), inplace=True)\n\n#     #Impute Fare with back fill value \n#     dataset['Fare'].fillna(method='bfill', inplace=True)\n\n#     #Impute Cabin with Unique value \n#     dataset['Cabin'].fillna('Missing', inplace=True)\n\n#     #Impute Embarked with most embarked value using Histogram \n#     dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace=True)\n    \n#     #Impute every thing else with front fill value \n#     dataset.fillna(method='ffill', inplace=True)\n    \n#     return datset\n\n# input_data = deal_with_null_values(input_data)\n# # test_data = deal_with_null_values(test_data)\n\n# input_data.Survived.mean()\n\n\n####Bad way of writing code, wanted to create function call but weirdly 'Survived' coulumns is being dropped after function call\n###So repeating this piece of code once for input_data and once for test_data \n\n    #Impute Age with mean value \n    input_data['Age'].fillna(input_data['Age'].mean(), inplace=True)\n\n    #Impute Fare with back fill value \n    input_data['Fare'].fillna(method='bfill', inplace=True)\n\n    #Impute Cabin with Unique value \n    input_data['Cabin'].fillna('Missing', inplace=True)\n\n    #Impute Embarked with most embarked value using Histogram \n    input_data['Embarked'].fillna(input_data['Embarked'].mode()[0], inplace=True)\n    \n    #Impute every thing else with front fill value \n    input_data.fillna(method='ffill', inplace=True)\n    \n    ###################\n    \n    #Impute Age with mean value \n    test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)\n\n    #Impute Fare with back fill value \n    test_data['Fare'].fillna(method='bfill', inplace=True)\n\n    #Impute Cabin with Unique value \n    test_data['Cabin'].fillna('Missing', inplace=True)\n\n    #Impute Embarked with most embarked value using Histogram \n    test_data['Embarked'].fillna(test_data['Embarked'].mode()[0], inplace=True)\n    \n    #Impute every thing else with front fill value \n    test_data.fillna(method='ffill', inplace=True)","afa9eb36":"#Create feautures and build the subset out of the input data \nfeatures = ['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\ntrain_X = input_data[features]\ntrain_y = input_data.Survived\n# input_data_X = input_data[features]\n# input_data_y = input_data.Survived\n\n\n#Split input data \ntrain_X, val_X, train_y, val_y = train_test_split(train_X, train_y, random_state = 1)\n\n\n#Building test data \ntest_X = test_data[features]","fcc9889d":"\n### label encode the categorical values and convert them to numbers \nle = LabelEncoder()\nle.fit(train_X['Sex'].astype(str))\ntrain_X['Sex'] = le.transform(train_X['Sex'].astype(str))\ntest_X['Sex'] = le.transform(test_X['Sex'].astype(str))\n# input_data_X['Sex'] = le.transform(input_data_X['Sex'].astype(str))\n\n### label encode the categorical values and convert them to numbers \nle = LabelEncoder()\nle.fit(val_X['Sex'].astype(str))\nval_X['Sex'] = le.transform(val_X['Sex'].astype(str))\n\n\n# le.fit(train_X['Pclass'].astype(str))\n# train_X['Pclass'] = le.transform(train_X['Pclass'].astype(str))\n# test_X['Pclass'] = le.transform(test_X['Pclass'].astype(str))\n\n# le.fit(train_X['Name'].astype(str))\n# train_X['Name'] = le.transform(train_X['Name'].astype(str))\n# test_X['Name'] = le.transform(test_X['Name'].astype(str))\n\n# le.fit(train_X['Ticket'].astype(str))\n# train_X['Ticket'] = le.transform(train_X['Ticket'].astype(str))\n# test_X['Ticket'] = le.transform(test_X['Ticket'].astype(str))\n\n# le.fit(train_X['Cabin'].astype(str))\n# train_X['Cabin'] = le.transform(train_X['Cabin'].astype(str))\n# test_X['Cabin'] = le.transform(test_X['Cabin'].astype(str))","4f6df937":"#Prepares a list of different leave nodes for which decision tree will be evaluated against\nmax_leaf_nodes = [ interval + 1 for interval in range(2,150) if interval%1 == 0]\n\n#Makes a dictionary {leaf_node : Mean Absolute Error} for each leaf node from the list above\ndef calculate_mae_leaf_nodes (max_leaf_nodes,train_X, train_y, val_X, val_y):\n        #Create Model\n        titanic_model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes,random_state=1)\n        #Train Model\n        titanic_model.fit(train_X,train_y)\n        #Predict for the split test data\n        titanic_test_prediction = titanic_model.predict(val_X)\n        #Predict Model\n        titanic_prediction = titanic_model.predict(test_X) \n        #Calculates Mean Absolute Error\n        val_mae = mean_absolute_error(val_y, titanic_test_prediction)\n        return(val_mae)\n    \nscores = {leaf_count:calculate_mae_leaf_nodes(leaf_count, train_X, train_y, val_X, val_y) for leaf_count in max_leaf_nodes}\n","7df956a0":"#Sorts the dictionary based on the key \nlists = sorted(scores.items())\n\n#Unpacks the list and assign the values to plot_x & plot_y\nplot_x, plot_y = zip(*lists)\n\n#Plot the graph \nplt.plot(plot_x, plot_y)\n\n#Label the plot\nplt.xlabel('Mean Absolute Error')\nplt.ylabel('Max Leaf Count')\nplt.title('MAE vs Max Leaf Count')\n\n#Print the graph\nplt.show()\n","7997fcd0":"#Computes the best tree depth based on the least Mean Absolute Error\nbest_tree_depth = min(scores, key=scores.get)\n\n#Build the final model using the best tree depth\nfinal_titanic_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_depth,random_state=1)\n\n#Fit the model using all the input data \nfinal_titanic_model.fit(train_X, train_y)\n\n#Predict the model usint the test data \nfinal_titanic_predictions = final_titanic_model.predict(test_X)","2face236":"#Create the data for submission\nsubmission = pd.DataFrame({\"PassengerId\": test_X[\"PassengerId\"], \"Survived\": final_titanic_predictions}) \n\n#Save the data file in to local disk\nfilename = 'submission.csv'\nsubmission.to_csv(filename,index=False)\n\n#Print the file\nprint('Saved file: ' + filename)\nprint(submission)","cdc63dc1":"This code is to print CSV file and make it ready for the submission","dfffc4ba":"This code is to build the final model using the best tree depth","612e20e1":"This code plots the graph against the various tree depth size and mean absolute error","76040a20":"This code deals with the missing cell values in the input data & test data  - Data cleansing","fda8ba05":"This sets up the file path and create data frames","5ed0afa3":"This code calaculates the best depth of the decision tress based on the minimum Mean Absolute Error","a32bab7a":"This section analyse the input data by building various graphs"}}