{"cell_type":{"c91cd43e":"code","63399d66":"code","7555c494":"code","42615387":"code","ec6c1231":"code","973d853f":"code","7dd27cdd":"code","873dae68":"code","af96ae71":"code","1ad79af0":"code","87d4aca7":"code","70366be0":"code","95c9d083":"code","f1d48d00":"code","4ff9bf62":"code","c8956258":"code","62141917":"code","dbb42038":"code","485a8e34":"markdown","58800904":"markdown","d1b7106b":"markdown","1c45135d":"markdown","71f62c97":"markdown","8e90767a":"markdown","f336ed72":"markdown"},"source":{"c91cd43e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","63399d66":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt ","7555c494":"df_train = pd.read_csv('\/kaggle\/input\/task-03\/train_full.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/task-03\/test_without_label.csv')","42615387":"df_train.columns = pd.Index(['Game', 'Data', 'H_Team', 'H_Wins', 'H_Loss', 'H_W\/D%', 'H_SRS', 'H_Games', 'H_TotalPoints', 'H_AvgPointsPerGame', 'H_FG', 'H_FGA',\n            'H_FG%', 'H_3P', 'H_3PA', 'H_3P%', 'H_2P', 'H_2PA', 'H_2P%', 'H_FT', 'H_FTA', 'H_FT%', 'H_ORB', 'H_DRB', 'H_TRB', 'H_AST', 'H_BLK',\n            'H_TOV', 'H_PF', 'H_PointsOpp', 'H_AvgPointsPerGameOpp', 'H_OFG', 'H_OFGA', 'H_OFG%', 'H_O3P', 'H_O3PA', 'H_O3P%', 'H_O2P', 'H_O2PA',\n            'H_O2P%', 'H_OFT', 'H_OFTA', 'H_OFT%', 'H_OORB', 'H_ODRB', 'H_OTRB', 'H_OAST', 'H_OBLK', 'H_OTOV', 'H_OPF', 'H_PW', 'H_PL', 'H_MOV',\n            'H_SOS', 'H_Ortg', 'H_Drtg', 'H_Pace', 'H_Ftr', 'H_3PAr', 'H_TS%', 'H_eFG%', 'H_TOV%', 'H_ORB%', 'H_FT\/FGA', 'H_OeFG%', 'H_OTOV%',\n            'H_DRB%', 'H_OFT\/FGA', 'A_Team', 'A_Wins', 'A_Loss', 'A_W\/D%', 'A_SRS', 'A_Games', 'A_TotalPoints', 'A_AvgPointsPerGame', 'A_FG',\n            'A_FGA', 'A_FG%', 'A_3P', 'A_3PA', 'A_3P%', 'A_2P', 'A_2PA', 'A_2P%', 'A_FT', 'A_FTA', 'A_FT%', 'A_ORB', 'A_DRB', 'A_TRB', 'A_AST',\n            'A_BLK', 'A_TOV', 'A_PF', 'A_PointsOpp', 'A_AvgPointsPerGameOpp', 'A_OFG', 'A_OFGA', 'A_OFG%', 'A_O3P', 'A_O3PA', 'A_O3P%', 'A_O2P',\n            'A_O2PA', 'A_O2P%', 'A_OFT', 'A_OFTA', 'A_OFT%', 'A_OORB', 'A_ODRB', 'A_OTRB', 'A_OAST', 'A_OBLK', 'A_OTOV', 'A_OPF', 'A_PW', 'A_PL',\n            'A_MOV', 'A_SOS', 'A_Ortg', 'A_Drtg', 'A_Pace', 'A_Ftr', 'A_3PAr', 'A_TS%', 'A_eFG%', 'A_TOV%', 'A_ORB%', 'A_FT\/FGA', 'A_OeFG%', 'A_OTOV%',\n            'A_DRB%', 'A_OFT\/FGA', 'WinOrLose'])","ec6c1231":"df_test.columns = pd.Index(['Game','Data', 'H_Team',\n            'H_Wins', 'H_Loss', 'H_W\/D%', 'H_SRS', 'H_Games', 'H_TotalPoints', 'H_AvgPointsPerGame', 'H_FG', 'H_FGA',\n            'H_FG%', 'H_3P', 'H_3PA', 'H_3P%', 'H_2P', 'H_2PA', 'H_2P%', 'H_FT', 'H_FTA', 'H_FT%', 'H_ORB', 'H_DRB', 'H_TRB', 'H_AST', 'H_BLK',\n            'H_TOV', 'H_PF', 'H_PointsOpp', 'H_AvgPointsPerGameOpp', 'H_OFG', 'H_OFGA', 'H_OFG%', 'H_O3P', 'H_O3PA', 'H_O3P%', 'H_O2P', 'H_O2PA',\n            'H_O2P%', 'H_OFT', 'H_OFTA', 'H_OFT%', 'H_OORB', 'H_ODRB', 'H_OTRB', 'H_OAST', 'H_OBLK', 'H_OTOV', 'H_OPF', 'H_PW', 'H_PL', 'H_MOV',\n            'H_SOS', 'H_Ortg', 'H_Drtg', 'H_Pace', 'H_Ftr', 'H_3PAr', 'H_TS%', 'H_eFG%', 'H_TOV%', 'H_ORB%', 'H_FT\/FGA', 'H_OeFG%', 'H_OTOV%',\n            'H_DRB%', 'H_OFT\/FGA', 'A_Team', 'A_Wins', 'A_Loss', 'A_W\/D%', 'A_SRS', 'A_Games', 'A_TotalPoints', 'A_AvgPointsPerGame', 'A_FG',\n            'A_FGA', 'A_FG%', 'A_3P', 'A_3PA', 'A_3P%', 'A_2P', 'A_2PA', 'A_2P%', 'A_FT', 'A_FTA', 'A_FT%', 'A_ORB', 'A_DRB', 'A_TRB', 'A_AST',\n            'A_BLK', 'A_TOV', 'A_PF', 'A_PointsOpp', 'A_AvgPointsPerGameOpp', 'A_OFG', 'A_OFGA', 'A_OFG%', 'A_O3P', 'A_O3PA', 'A_O3P%', 'A_O2P',\n            'A_O2PA', 'A_O2P%', 'A_OFT', 'A_OFTA', 'A_OFT%', 'A_OORB', 'A_ODRB', 'A_OTRB', 'A_OAST', 'A_OBLK', 'A_OTOV', 'A_OPF', 'A_PW', 'A_PL',\n            'A_MOV', 'A_SOS', 'A_Ortg', 'A_Drtg', 'A_Pace', 'A_Ftr', 'A_3PAr', 'A_TS%', 'A_eFG%', 'A_TOV%', 'A_ORB%', 'A_FT\/FGA', 'A_OeFG%', 'A_OTOV%',\n            'A_DRB%', 'A_OFT\/FGA' ])","973d853f":"df_train['WinOrLose'] = df_train.WinOrLose.apply(lambda x: 1 if x=='W' else -1)","7dd27cdd":"df_train.shape","873dae68":"vars = ['H_Wins', 'H_Loss', 'H_W\/D%', 'H_SRS', 'H_Games', 'H_TotalPoints', 'H_AvgPointsPerGame', 'H_FG', 'H_FGA',\n            'H_FG%', 'H_3P', 'H_3PA', 'H_3P%', 'H_2P', 'H_2PA', 'H_2P%', 'H_FT', 'H_FTA', 'H_FT%', 'H_ORB', 'H_DRB', 'H_TRB', 'H_AST', 'H_BLK',\n            'H_TOV', 'H_PF', 'H_PointsOpp', 'H_AvgPointsPerGameOpp', 'H_OFG', 'H_OFGA', 'H_OFG%', 'H_O3P', 'H_O3PA', 'H_O3P%', 'H_O2P', 'H_O2PA',\n            'H_O2P%', 'H_OFT', 'H_OFTA', 'H_OFT%', 'H_OORB', 'H_ODRB', 'H_OTRB', 'H_OAST', 'H_OBLK', 'H_OTOV', 'H_OPF', 'H_PW', 'H_PL', 'H_MOV',\n            'H_SOS', 'H_Ortg', 'H_Drtg', 'H_Pace', 'H_Ftr', 'H_3PAr', 'H_TS%', 'H_eFG%', 'H_TOV%', 'H_ORB%', 'H_FT\/FGA', 'H_OeFG%', 'H_OTOV%',\n            'H_DRB%', 'H_OFT\/FGA','A_Wins', 'A_Loss', 'A_W\/D%', 'A_SRS', 'A_Games', 'A_TotalPoints', 'A_AvgPointsPerGame', 'A_FG',\n            'A_FGA', 'A_FG%', 'A_3P', 'A_3PA', 'A_3P%', 'A_2P', 'A_2PA', 'A_2P%', 'A_FT', 'A_FTA', 'A_FT%', 'A_ORB', 'A_DRB', 'A_TRB', 'A_AST',\n            'A_BLK', 'A_TOV', 'A_PF', 'A_PointsOpp', 'A_AvgPointsPerGameOpp', 'A_OFG', 'A_OFGA', 'A_OFG%', 'A_O3P', 'A_O3PA', 'A_O3P%', 'A_O2P',\n            'A_O2PA', 'A_O2P%', 'A_OFT', 'A_OFTA', 'A_OFT%', 'A_OORB', 'A_ODRB', 'A_OTRB', 'A_OAST', 'A_OBLK', 'A_OTOV', 'A_OPF', 'A_PW', 'A_PL',\n            'A_MOV', 'A_SOS', 'A_Ortg', 'A_Drtg', 'A_Pace', 'A_Ftr', 'A_3PAr', 'A_TS%', 'A_eFG%', 'A_TOV%', 'A_ORB%', 'A_FT\/FGA', 'A_OeFG%', 'A_OTOV%',\n            'A_DRB%', 'A_OFT\/FGA']\n\ntarget = ['WinOrLose']","af96ae71":"len(vars)","1ad79af0":"X_vars_train = df_train[vars]\nX_vars_test = df_test[vars]","87d4aca7":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_vars_train_trf = sc.fit_transform(X_vars_train)\nX_vars_test_trf = sc.transform(X_vars_test)","70366be0":"from sklearn.feature_selection import SelectPercentile, f_classif\nlistlist = df_train[target].to_numpy().T.tolist()\ny = np.array(listlist[0])\nsp = SelectPercentile(f_classif, percentile = 20)\nX_vars_train_trf = sp.fit_transform(X_vars_train_trf, y)\nX_vars_test_trf = sp.transform(X_vars_test_trf)","95c9d083":"selected_features = sp.get_support('True')\n\nfor i in selected_features:\n  print(vars[i])","f1d48d00":"from sklearn.decomposition import PCA\npca = PCA(n_components=len(selected_features))\nX_vars_train_trf = pca.fit_transform(X_vars_train_trf)\nX_vars_test_trf = pca.transform(X_vars_test_trf)\nX_vars_train_trf = pd.DataFrame(X_vars_train_trf, index = X_vars_train.index, columns = ['PC'+str(i+1) for i in range(pca.n_components_)])\nX_vars_test_trf = pd.DataFrame(X_vars_test_trf, index = X_vars_test.index, columns = ['PC'+str(i+1) for i in range(pca.n_components_)])","4ff9bf62":"df_train_final = pd.concat([df_train.loc[:,'WinOrLose'], X_vars_train_trf], axis=1)\ndf_test_final = X_vars_test_trf","c8956258":"df_train_final.head(2)","62141917":"df_test_final.head(2)","dbb42038":"df_test_final.to_csv('test.csv')\ndf_train_final.to_csv('train.csv')","485a8e34":"## Sele\u00e7\u00e3o e padroniza\u00e7\u00e3o de vari\u00e1veis","58800904":"## PCA","d1b7106b":"# Introdu\u00e7\u00e3o\n\nNesse notebook \u00e9 feito o pr\u00e9-processamento de dados e experimentos com diferentes modelos.\n\n# Pr\u00e9-processamento\n\nO pr\u00e9-processamento \u00e9 feito removendo as colunas Data, H_Team, A_Team, mudando os targets do WinOrLOse para -1 ou 1 al\u00e9m de ser aplicado um filtro de features usando os m\u00e9todos StandardScaler, SelectPercentile (f_classif) e PCA do pacote scikit-learn.\n\nO Data foi retirado porque, seprando os dias da semana, h\u00e1 uma varia\u00e7\u00e3o baixa. Tamb\u00e9m foi retirado por simplifica\u00e7\u00e3o.\n\nOs H_Team e A_Team foram retirados para evitar um vies de treino com rela\u00e7\u00e3o ao nome dos times. A ideia \u00e9 que o modelo foque no desempenho dos times.\n\nAs outras features removidas s\u00e3o comparadas usando medidas como informa\u00e7\u00e3o mutual e chi2 (ainda testando).","1c45135d":"## SelectPercentile","71f62c97":"## Standard Scaling","8e90767a":"## Transforma\u00e7\u00e3o de vari\u00e1veis","f336ed72":"## Separando Resultado "}}