{"cell_type":{"a4e1a64c":"code","72a6e486":"code","5991d525":"code","ab4cfc31":"code","58a2878a":"code","5c4daacf":"code","c8a1344a":"code","1e793ad2":"code","1af40193":"code","1210bdff":"code","415c60df":"code","aa7ba3ad":"code","981ac675":"code","6edeea9b":"code","0bed038e":"code","0ef41190":"markdown","c56661ab":"markdown","b661f56a":"markdown","060f42d3":"markdown","0bd1d820":"markdown","96bd815a":"markdown","aab009cc":"markdown","6b2c4852":"markdown","0baee0a5":"markdown","17f3ce4b":"markdown"},"source":{"a4e1a64c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('seaborn-whitegrid')\nsns.set_style(\"white\")\nfrom mpl_toolkits import mplot3d\nfrom mpl_toolkits.mplot3d import axes3d\nimport matplotlib as mpl\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","72a6e486":"# load a single file as a numpy array\ndef load_file(filepath):\n    df = pd.read_csv(filepath, header=None, delim_whitespace=True)\n    return df.values\n\n# load a list of files into a 3D array of [observations, timesteps, features(x,y,z)]\ndef load_group(files, prefix=''):\n    loaded = list()\n    for f in files:\n        data = load_file(prefix + f)\n        loaded.append(data)\n    # stack group so that features are the 3rd dimension\n    loaded = np.dstack(loaded)\n    return loaded\n\ndef load_dataset_group(group, prefix=''):\n    filepath = prefix + group + '\/Inertial Signals\/'\n    # load all 9 files as a single array\n    files = list()\n    # body acceleration\n    files += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n    # body gyroscope\n    files += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n    # total acceleration\n    files += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n    # load input data\n    X = load_group(files, filepath)\n    # load class output\n    y = load_file(prefix + group + '\/y_'+group+'.txt')\n    return X, y\n\ndef load_dataset(prefix=''):\n    # load all train\n    X_train, y_train = load_dataset_group('train', prefix)\n    # load all test\n    X_test, y_test = load_dataset_group('test', prefix)\n    \n    \"\"\"\n    # zero-offset class values\n    y_train = y_train - 1\n    y_test = y_test - 1\n    # one hot encode y\n    y_train = to_categorical(y_train)\n    y_test = to_categorical(y_test)\n    \"\"\"\n    \n    print(f\"\"\"Dataset loaded.\nTraining Set:\nX_train {X_train.shape} y_train {y_train.shape}\nTest Set:\nX_test {X_test.shape} y_test {y_test.shape}\"\"\")\n    return X_train, y_train, X_test, y_test","5991d525":"X_train, y_train, X_test, y_test = load_dataset(prefix=\"..\/input\/human-activity-recognition\/UCI_HAR_Dataset\/\")","ab4cfc31":"activity = {\n        1: 'Walking',\n        2: 'Walking Upstairs',\n        3: 'Walking Downstairs',\n        4: 'Sitting',\n        5: 'Standing',\n        6: 'Laying'}\ndef activities(obs):\n    return activity[int(y_train[obs])]","58a2878a":"def features(feature):\n    f={\"Body acceleration\": 0, \"Gyro\": 1, \"Total acceleration\": 2}\n    return f[feature]","5c4daacf":"# Example for each activity\nsample=[777, 666, 818, 0,6666,66]\n[activity[int(y_train[i])] for i in sample]","c8a1344a":"# Grab values for graphs\ndef get_values(y_values, T, N, f_s, sample_rate):\n    y_values = y_values\n    x_values = [sample_rate * kk for kk in range(0,len(y_values))]\n    return x_values, y_values","1e793ad2":"# Display x,y,z as separate lines for each feature\ndef signal_viz(obs):\n    N = 128 # number of timesteps\n    f_s = 50 # overlapped percentage\n    t_n = 2.56 # time\n    T = t_n \/ N\n    sample_rate = 1 \/ f_s\n    \n    labels = ['x-component', 'y-component', 'z-component']\n    colors = ['r', 'g', 'b']\n    suptitle = \"Different signals for the activity: {}\"\n    graph_name=\"graph\/Signals {}.png\" \n    xlabel = 'Time [sec]'\n    ylabel = 'Amplitude'\n    axtitles = ['Body acceleration', 'Gyro', 'Total acceleration']\n    activity_name = activities(obs)\n    \n    sns.set(style=\"white\", font_scale = 1.7)\n    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24,8))\n\n\n    for comp_no in range(0,9):\n            col_no = comp_no \/\/ 3\n            plot_no = comp_no % 3\n            color = colors[plot_no]\n            label = labels[plot_no]\n\n            axtitle  = axtitles[col_no]\n\n            ax = axes[col_no]\n            ax.set_title(axtitle)\n            ax.set_xlabel(xlabel)\n            if col_no == 0:\n                ax.set_ylabel(ylabel, fontsize=16)\n\n            signal_component = X_train[obs][:, comp_no]\n            x_values, y_values = get_values(signal_component, T, N, f_s, sample_rate)\n            ax.plot(x_values, y_values, linestyle='-', color=color, label=label)  \n            if col_no == 2:\n                ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n\n    fig.suptitle(suptitle.format(activity_name))    \n    plt.tight_layout()\n    plt.subplots_adjust(top=0.90, hspace=0.6)\n    plt.show()    ","1af40193":"for i in sample:\n    signal_viz(i)","1210bdff":"# Plot the selected feature signal in 3D\ndef signal_3dviz(obs,feature):\n    graph_name=\"graph\/3D {} {}.png\"\n    activity_name = activities(obs)\n    \n    i=features(feature)\n    \n    sns.set(style=\"white\", font_scale = 2)\n    fig = plt.figure(figsize=(12,12))\n    ax = fig.gca(projection=\"3d\")    \n    x = X_train[obs][:, i*3+0]\n    y = X_train[obs][:, i*3+1]\n    z = X_train[obs][:, i*3+2]\n    ax.plot(x, y, z, label=feature)\n    ax.legend()\n    plt.title(activity_name)\n    plt.xlabel(\"x\")\n    plt.ylabel(\"y\")\n    ax.set_zlabel(\"z\")\n    # Get rid of colored axes planes\n    # First remove fill\n    ax.xaxis.pane.fill = False\n    ax.yaxis.pane.fill = False\n    ax.zaxis.pane.fill = False\n\n    # Bonus: To get rid of the grid as well:\n    ax.grid(False)\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    for t in ax.zaxis.get_major_ticks(): t.label.set_fontsize(12)\n    plt.show()","415c60df":"for i in sample:\n    signal_3dviz(i, \"Body acceleration\")","aa7ba3ad":"# Calculate the distance of each timesteps to origin (0,0,0)\ndef distance_viz(obs, feature):\n    graph_name=\"graph\/distance {} {}.png\"\n    activity_name = activities(obs)\n    \n    i=features(feature)\n    \n    sns.set(style=\"white\", font_scale = 2)\n    fig = plt.figure(figsize=(8,6))\n    x = X_train[obs][:, i*3+0]\n    y = X_train[obs][:, i*3+1]\n    z = X_train[obs][:, i*3+2]\n    plt.plot((x**2+y**2+z**2)**0.5, label=feature)\n    plt.legend()\n    plt.title(activity_name)\n    plt.xlabel(\"Timesteps\")\n    plt.ylabel(\"Distance\")\n    plt.show()","981ac675":"for i in sample:\n    distance_viz(i, \"Body acceleration\")","6edeea9b":"def y_graph():\n    y=pd.DataFrame(np.concatenate((y_train, y_test)), columns=[\"Activity\"])\n    y[\"Activity\"]=y.Activity.map(activity)\n    sns.set(style=\"white\", font_scale=3)\n    f, ax = plt.subplots(figsize=(40,15))\n    sns.countplot(data=y, y=\"Activity\")\n    plt.title(\"Observations by Activity\")\n    plt.show()","0bed038e":"y_graph()","0ef41190":"Still very hard to make sense out of and to do any visual comparisons between the activities.\nWill try to compute the distance of each timesteps to the origin (xyz = (0,0,0))","c56661ab":"Distribution of the observations by the actiivities","b661f56a":"# EDA & Data Visualisation","060f42d3":"It is now easier for us human eyes to compare the feature signals between different activities.","0bd1d820":"### Distance to Origin the Body Acceleration Feature","96bd815a":"### EDA - Observations by Activity","aab009cc":"## Data Pipeline\nFunctions to load the dataset","6b2c4852":"### 3D Plots for the Body Acceleration Feature","0baee0a5":"## Data Visualisation\n### Feature Signals (xyz)","17f3ce4b":"Interesting visualisation, but difficult to interpret. In reality these xyz signals for each features works together to provide the insight, therefore we should visualise the data of xyz together."}}