{"cell_type":{"273dd7f8":"code","787004e5":"code","bb8467f1":"code","d90ea5af":"code","44374c2d":"code","6b95e4f2":"code","d3ea3053":"code","01ecca58":"code","17fb166f":"code","0e61a30b":"code","b1c4971e":"code","01b9d12c":"code","1f59a5c5":"code","503cadc7":"code","37fffa58":"code","3b86ea03":"code","8d1ccec3":"code","44f0f228":"code","757f34c9":"code","9a115e7c":"code","776561b6":"code","adced167":"code","69aa4374":"code","f0899453":"code","8c94df1d":"code","41e4fb91":"code","ca4de6b3":"code","234b2fad":"code","998f9b48":"code","aec7fa26":"code","f8173cb9":"code","58310730":"code","5273f62e":"markdown","6a1566c9":"markdown","172c0875":"markdown","6d77793b":"markdown","2ab38dd8":"markdown","53366852":"markdown","8ff3c5c0":"markdown","9ec3e20e":"markdown","5cafb9f1":"markdown","6e613905":"markdown","27ab1877":"markdown","bbd132aa":"markdown","3ac497c8":"markdown","db0a978b":"markdown","ec2e46fe":"markdown","5de8717b":"markdown","5f1d3789":"markdown","8df50dff":"markdown","1824e1c8":"markdown"},"source":{"273dd7f8":"from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","787004e5":"print(os.listdir('..\/input'))","bb8467f1":"# Distribution graphs (histogram\/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) \/ nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()\n","d90ea5af":"# Correlation matrix\ndef plotCorrelationMatrix(df, graphWidth):\n    filename = df.dataframeName\n    df = df.dropna('columns') # drop columns with NaN\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    if df.shape[1] < 2:\n        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n        return\n    corr = df.corr()\n    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n    corrMat = plt.matshow(corr, fignum = 1)\n    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n    plt.yticks(range(len(corr.columns)), corr.columns)\n    plt.gca().xaxis.tick_bottom()\n    plt.colorbar(corrMat)\n    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n    plt.show()\n","44374c2d":"# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    color_wheel = {1: \"#aa0000\", \n               2: \"#0000aa\", \n               3: \"#0000ff\"}\n    colors = df[\"sick\"].map(lambda x: color_wheel.get(x + 1))\n\n    \n    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n    # Remove rows and columns that would lead to df being singular\n    df = df.dropna('columns')\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    columnNames = list(df)\n    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    \n    ax = pd.plotting.scatter_matrix(df,color=colors, alpha=0.15, figsize=[plotSize, plotSize], diagonal='kde',)\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()\n","6b95e4f2":"nRowsRead = None # specify 'None' if want to read whole file\n# commentInteractions.csv has 93816 rows in reality, but we are only loading\/previewing the first 1000 rows\ndf1 = pd.read_csv('..\/input\/commentInteractions.csv', delimiter=',', nrows = nRowsRead)\ndf1.dataframeName = 'commentInteractions.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')","d3ea3053":"df1.head(5)","01ecca58":"plotPerColumnDistribution(df1, 10, 5)","17fb166f":"nRowsRead = None # specify 'None' if want to read whole file\n# comments_by_employees_in_anonymous_forum.csv has 5072 rows in reality, but we are only loading\/previewing the first 1000 rows\ndf2 = pd.read_csv('..\/input\/comments_by_employees_in_anonymous_forum.csv', delimiter=',', nrows = nRowsRead)\ndf2.dataframeName = 'comments_by_employees_in_anonymous_forum.csv'\nnRow, nCol = df2.shape\nprint(f'There are {nRow} rows and {nCol} columns')","0e61a30b":"df2.head(5)","b1c4971e":"plotPerColumnDistribution(df2, 10, 5)","01b9d12c":"plotCorrelationMatrix(df2, 8)","1f59a5c5":"df4 = pd.read_csv('..\/input\/employeeAbsenteeism.csv', delimiter=',')\ndf4.dataframeName = 'employeeAbsenteeism'\nnRow, nCol = df4.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf4.head(5)","503cadc7":"sickSet = set(df4['employee'])\na = len(df4['employee'])\nb =  (len(sickSet))\nprint(f'In {df4.dataframeName}, there are {a} employee ids entries and  {b} of those are unique')\n\ndef is_sick(id_str):\n    return id_str in sickSet\n\ndf2['sick'] =  df2['employee'].apply(is_sick)\n\na = len(df2['employee'])\nb =  (len(set(df2['employee'])))\nprint(f'In {df2.dataframeName}, there are {a} employee ids entries and  {b} of those are unique')\n\nb =  (len(set(df2['employee'])))\nd = df2.loc[df2['employee'].isin(sickSet)]\nc = (len(set(d['employee'])))\n    \n\nprint(f'In {df2.dataframeName}, of the  {b}  unique employees {c} were sick at some point')\n\nb =  (len(sickSet))\nprint(f'So of the sick, only {c} out of {b} wrote a comment in {df2.dataframeName} ; ( {c\/b}%)')\n\n\nprint(f'the ratio in non sick is...')\n\n# check if any duplciated rows... none so far...\n#df2[df2.duplicated(keep=False)]\n\n","37fffa58":"df5 = pd.read_csv('..\/input\/lastParticipationExists.csv', delimiter=',')\ndf5.dataframeName = 'lastParticipationExists.csv'\nnRow, nCol = df5.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf5.head(5)\nall =(set(df5['employee']))\nlen(all)","3b86ea03":"wrotesomething = set (df2['employee'])\nprint(f'the ratio for all emplyees is { len(wrotesomething) } wrote a comment out of {len(all)}... {(len(wrotesomething)\/len(all))} %')\nprint(f'inconclusive')\nprint(f'inconclusive')\n\n","8d1ccec3":"df4.drop_duplicates(inplace=True)\ndf4['employee'].value_counts().plot.hist(bins=12, alpha=0.5)\n\ndf4['employee'].value_counts()\ndf4.loc[df4['employee']=='yKX']\n#mask = (df['date'] > start_date) & (df['date'] <= end_date)\n","44f0f228":"plotScatterMatrix(df2, 9, 10)","757f34c9":"df4['from'] = pd.to_datetime(df4['from'])\ndf4['to']   = pd.to_datetime(df4['to'])\ndf2['commentDate'] =pd.to_datetime(df2['commentDate'])\n\n\ndef calculatePostsPerWeekAllTimeAndWB4(id_str,sick_date, n):\n    #select posts from df2\n    # test with df4.loc[df4['employee']=='yKX']\n    xx = df2.loc[df2['employee']==id_str]\n    if (xx.empty):\n        return (0)\n    else:\n        #print(print(xx.dtypes))   \n        ndays = -(xx['commentDate'].min() - pd.to_datetime(sick_date) )\n        nposts = len(xx.index)\n        #print(ndays.days)\n        WB4mask = (xx['commentDate'] > (sick_date- pd.DateOffset(days=7)) ) & (xx['commentDate'] <= sick_date)\n        WB4 = xx.loc[WB4mask]\n        if not (WB4.empty):\n            WB4_c =  len(WB4.index)\n            if not (WB4_c > -1):\n                WB4_c = -1\n        else:\n            WB4_c = 0\n\n        MB4mask = (xx['commentDate'] > (sick_date- pd.DateOffset(days=7*4)) ) & (xx['commentDate'] <= sick_date)\n        MB4 = xx.loc[MB4mask]\n        if not (MB4.empty):\n            MB4_c =  len(MB4.index)\n            if not (MB4_c > -1 ):\n                MB4_c = -1\n        else:\n            MB4_c = 0\n        Ndays_since_first_comment_to_sick = ndays.days   \n        res = [(nposts\/(ndays.days\/7)),WB4_c,MB4_c, nposts,Ndays_since_first_comment_to_sick]\n        return res[n]\n        #return pd.Series([(nposts\/(ndays.days\/7)),WB4_c,MB4_c, nposts,ndays.days])\n\n\n# test the function\n# print(df4.dtypes)\nid_str = \"qKO\"\nsick_date = df4.iloc[3][\"from\"]\n#print(sick_date)\nprint(calculatePostsPerWeekAllTimeAndWB4(id_str,sick_date,1))\n\n#calculatePostsPerWeekAllTimeAndWB4(df4['employee'], df4['from'])\ndf4['npostsperweek'] = df4.apply(lambda x: calculatePostsPerWeekAllTimeAndWB4(x['employee'], x['from'],0) , axis=1)\ndf4['npostsWB4Sick'] = df4.apply(lambda x: calculatePostsPerWeekAllTimeAndWB4(x['employee'], x['from'],1) , axis=1)\ndf4['npostsMB4Sick'] = df4.apply(lambda x: calculatePostsPerWeekAllTimeAndWB4(x['employee'], x['from'],2) , axis=1)\ndf4['nposts'] = df4.apply(lambda x: calculatePostsPerWeekAllTimeAndWB4(x['employee'], x['from'],3) , axis=1)\ndf4['Ndays_since_first_comment_to_sick'] = df4.apply(lambda x: calculatePostsPerWeekAllTimeAndWB4(x['employee'], x['from'],4) , axis=1)\ndf4.head(5)\n#df4['postsWB4Sick'] = df4.apply(lambda x: calculatePostsPerWeekAllTimeAndWB4(df4['employee'], df4['from'])[2], axis=1)\n#df4['ratio'] = df4['postsWB4Sick'] \/ df4['Alltimepostperweek']\n","9a115e7c":"dd = df4.groupby(['npostsWB4Sick','npostsMB4Sick']).size()\nprint(dd)\n","776561b6":"\ndf4.head(100)\nplotPerColumnDistribution(df4[1:144], 10, 5)","adced167":"import matplotlib.pyplot as plt\nplt.scatter(df4.npostsWB4Sick, df4.npostsMB4Sick\/4\n, s=df4.nposts)\nplt.title('Employee posts less the week before getting sick')\nplt.xlabel('Number of posts the week before sick leave day')\nplt.ylabel('Number of posts per week the month before sick leave day')\n\n","69aa4374":"# sample points \nX = df4.npostsWB4Sick\nY = df4.npostsMB4Sick\/4\n#YSum = df4.groupby(['npostsWB4Sick'],['npostsMB4Sick']).count()\n#print(YSum)\n# solve for a and b\ndef best_fit(X, Y):\n\n    xbar = sum(X)\/len(X)\n    ybar = sum(Y)\/len(Y)\n    n = len(X) # or len(Y)\n\n    numer = sum([xi*yi for xi,yi in zip(X, Y)]) - n * xbar * ybar\n    denum = sum([xi**2 for xi in X]) - n * xbar**2\n\n    b = numer \/ denum\n    a = ybar - b * xbar\n\n    print('best fit line:\\ny = {:.2f} + {:.2f}x'.format(a, b))\n\n    return a, b\n\n# solution\na, b = best_fit(X, Y)\n#best fit line:\n#y = 0.80 + 0.92x\n\n# plot points and fit line\nimport matplotlib.pyplot as plt\nplt.scatter(X, Y)\nyfit = [a + b * xi for xi in X]\nplt.plot(X, yfit)\n\nplt.title('Employee posts less the week before getting sick')\nplt.xlabel('Number of posts the week before sick leave day')\nplt.ylabel('Number of posts per week the month before sick leave day')\n\n","f0899453":"nRowsRead = None # specify 'None' if want to read whole file\n# comments_by_employees_in_anonymous_forum.csv has 5072 rows in reality, but we are only loading\/previewing the first 1000 rows\ndf6 = pd.read_csv('..\/input\/commentInteractions.csv', delimiter=',', nrows = nRowsRead)\ndf6.dataframeName = 'commentInteractions.csv'\nnRow, nCol = df2.shape\nprint(f'There are {nRow} rows and {nCol} columns')\n#df6.head(55)\ndf6.dtypes\ndd = df6.groupby(['interaction']).size()\nprint(dd)","8c94df1d":"df6['actionDate'] = pd.to_datetime(df6['actionDate'])\n\n\ndef calculateLikesPerWeekAllTimeAndWB4(id_str,sick_date, n):\n    #select posts from df2\n    # test with df4.loc[df4['employee']=='yKX']\n    xx = df6.loc[df6['employee']==id_str]\n    if (xx.empty):\n        return (0)\n    else:\n        #print(print(xx.dtypes))   \n        ndays = -(xx['actionDate'].min() - pd.to_datetime(sick_date) )\n        nposts = len(xx.index)\n        #print(ndays.days)\n        WB4mask = (xx['actionDate'] > (sick_date- pd.DateOffset(days=7)) ) & (xx['actionDate'] <= sick_date)\n        WB4 = xx.loc[WB4mask]\n        if not (WB4.empty):\n            WB4_c =  len(WB4.index)\n            if not (WB4_c > -1):\n                WB4_c = -1\n        else:\n            WB4_c = 0\n\n        MB4mask = (xx['actionDate'] > (sick_date- pd.DateOffset(days=7*4)) ) & (xx['actionDate'] <= sick_date)\n        MB4 = xx.loc[MB4mask]\n        if not (MB4.empty):\n            MB4_c =  len(MB4.index)\n            if not (MB4_c > -1 ):\n                MB4_c = -1\n        else:\n            MB4_c = 0\n        Ndays_since_first_comment_to_sick = ndays.days   \n        res = [(nposts\/((0.001 + ndays.days)\/7)),WB4_c,MB4_c, nposts,Ndays_since_first_comment_to_sick]\n        return res[n]\n        #return pd.Series([(nposts\/(ndays.days\/7)),WB4_c,MB4_c, nposts,ndays.days])\n\n\n# test the function\n# print(df4.dtypes)\nid_str = \"qKO\"\nsick_date = df4.iloc[3][\"from\"]\n#print(sick_date)\nprint(calculatePostsPerWeekAllTimeAndWB4(id_str,sick_date,1))\n\n#calculatePostsPerWeekAllTimeAndWB4(df4['employee'], df4['from'])\ndf4['nlikesperweek'] = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],0) , axis=1)\ndf4['nlikesWB4Sick'] = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],1) , axis=1)\ndf4['nlikesMB4Sick'] = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],2) , axis=1)\ndf4['nposts']        = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],3) , axis=1)\ndf4['Ndays_since_first_like_to_sick'] = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],4) , axis=1)\n\n#df4['postsWB4Sick'] = df4.apply(lambda x: calculatePostsPerWeekAllTimeAndWB4(df4['employee'], df4['from'])[2], axis=1)\n#df4['ratio'] = df4['postsWB4Sick'] \/ df4['Alltimepostperweek']","41e4fb91":"df4.head(5)","ca4de6b3":"dd = df4.groupby(['nlikesWB4Sick','nlikesMB4Sick']).size()\nprint(dd)\n","234b2fad":"# sample points \nX = df4.nlikesWB4Sick\nY = df4.nlikesMB4Sick\/4\n#YSum = df4.groupby(['npostsWB4Sick'],['npostsMB4Sick']).count()\n#print(YSum)\n# solve for a and b\ndef best_fit(X, Y):\n\n    xbar = sum(X)\/len(X)\n    ybar = sum(Y)\/len(Y)\n    n = len(X) # or len(Y)\n\n    numer = sum([xi*yi for xi,yi in zip(X, Y)]) - n * xbar * ybar\n    denum = sum([xi**2 for xi in X]) - n * xbar**2\n\n    b = numer \/ denum\n    a = ybar - b * xbar\n\n    print('best fit line:\\ny = {:.2f} + {:.2f}x'.format(a, b))\n\n    return a, b\n\n# solution\na, b = best_fit(X, Y)\n#best fit line:\n#y = 0.80 + 0.92x\n\n# plot points and fit line\nimport matplotlib.pyplot as plt\nplt.scatter(X, Y)\nyfit = [a + b * xi for xi in X]\nplt.plot(X, yfit)\n\nplt.title('Employee likes less the week before getting sick?')\nplt.xlabel('Number of (likes+dislikes) the week before sick leave day')\nplt.ylabel('Number of (likes+dislikes) per week the month before sick leave day')\n","998f9b48":"# unlikes\ndf6 = df6.loc[df6['interaction']<0 ]\ndf4['nUNlikesperweek'] = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],0) , axis=1)\ndf4['nUNlikesWB4Sick'] = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],1) , axis=1)\ndf4['nUNlikesMB4Sick'] = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],2) , axis=1)\ndf4['nposts']        = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],3) , axis=1)\ndf4['Ndays_since_first_UNlike_to_sick'] = df4.apply(lambda x: calculateLikesPerWeekAllTimeAndWB4(x['employee'], x['from'],4) , axis=1)\n\nX = df4.nUNlikesWB4Sick\nY = df4.nUNlikesMB4Sick\/4\nplt.scatter(X, Y)\nyfit = [a + b * xi for xi in X]\nplt.plot(X, yfit)\nplt.title('Employee UNlike less the week before getting sick?')\nplt.xlabel('Number of (dislikes) the week before sick leave day')\nplt.ylabel('Number of (dislikes) per week the month before sick leave day')\n","aec7fa26":"df2['sick'].describe()","f8173cb9":"df2.head()","58310730":"df22 = df2[['likes','sick']]\ndf22.describe()\ndf2.groupby(['sick']).mean()\n","5273f62e":"Correlation matrix:","6a1566c9":"fig above, dots are sick leaves. ","172c0875":"Lets analyze likes as michael suggests...\n","6d77793b":"compare employees that get sick vs those who never get sick.\n\n1. make list of sick employees\n2. mark was_ever_sick in df4\n3. groupby wasever sick the stats for nposts.\n","2ab38dd8":"1. 1. - lets find stats for sick ppl, for cases 1 month before sick, sick and after sick.\nsome employees get sick alot\n","53366852":"### Let's check 2nd file: ..\/input\/comments_by_employees_in_anonymous_forum.csv","8ff3c5c0":"* There are 6 csv files in the current version of the dataset:\n","9ec3e20e":"Let's take a quick look at what the data looks like:","5cafb9f1":"- Load data of employees that got sick. How many unique users? how many of them got sick?","6e613905":"### Let's check 1st file: ..\/input\/commentInteractions.csv","27ab1877":"Distribution graphs (histogram\/bar graph) of sampled columns:","bbd132aa":"## Introduction\n- Can we predict who will get sick from comments they write or likes they give?","3ac497c8":"Let's take a quick look at what the data looks like:","db0a978b":"- mark absenteeism employees in other datasets\n\n","ec2e46fe":"The next hidden code cells define functions for plotting data. Click on the \"Code\" button in the published kernel to reveal the hidden code.","5de8717b":"- above: colors mean red: no sixk, blue sick\n- lets find out if the behavior of the week before geting sick is detectable as in changes comapred to the average behaviour... in terms of posting frequency and likes.\n","5f1d3789":"Scatter and density plots:","8df50dff":"## Exploratory Analysis\nTo begin this exploratory analysis, first import libraries and define functions for plotting the data using `matplotlib`. Depending on the data, not all plots will be made. (Hey, I'm just a simple kerneling bot, not a Kaggle Competitions Grandmaster!)","1824e1c8":"Distribution graphs (histogram\/bar graph) of sampled columns:"}}