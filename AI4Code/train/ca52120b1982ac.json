{"cell_type":{"84e982ae":"code","748baf03":"code","b86a61c1":"code","43ca4ea5":"code","9b53330d":"code","51cc29f2":"code","adc9c351":"code","b38e6c24":"code","a744e305":"code","ee8542d9":"code","eb8c020f":"code","6d1e8590":"code","50b48500":"code","eb81de02":"code","ca052203":"code","efef099b":"code","b406ae5f":"code","a6e0e7e9":"code","25c4aedc":"code","c44ba88d":"markdown","b7d9ab80":"markdown"},"source":{"84e982ae":"# Import\n\nimport numpy as np\nimport pandas as pd\nimport re\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom IPython.display import Image as PImage\nfrom subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\n\n# Wczytanie danych\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\n#Utworzenie dost\u0119pu do Identyfikator\u00f3w pasa\u017cer\u00f3w\nPassengerId = test['PassengerId']\n\n#Wy\u015bwietlenie podgl\u0105du danych treningowych\ntrain.head(3)","748baf03":"# Utworzenie kopii danych treningowych\noriginal_train = train.copy() \n\n# \u0141\u0105czenie danych\nfull_data = [train, test]\n\n# Czy mia\u0142 kabin\u0119\ntrain['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\ntest['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n\n# Warto\u015b\u0107 czy mia\u0142\u00a0rodzin\u0119\nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    \n# Warto\u015b\u0107 czy by\u0142 sam\nfor dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n    \n# Usuwanie brak\u00f3w\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n    \nfor dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n\nfor dataset in full_data:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    # Ulepszenie, aby unikn\u0105\u0107 ostrze\u017cenia\n    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n\n# Wyodr\u0119bnienie tytu\u0142u z nazwiska\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n   \n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n    \n# Po\u0142\u0105czenie niepasuj\u0105cych tytu\u0142\u00f3w do grupy 'Rare'\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\nfor dataset in full_data:\n    \n    # Mapowanie P\u0142ci\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapowanie Tytu\u0142\u00f3w\n    title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\n    # Mapowanie Miejsca wsiadania\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapowanie Ceny biletu\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapowanie Wieku\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] ;","b86a61c1":"# Usuwanie zmiennych, kt\u00f3re nie b\u0119d\u0105 potrzebne\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntest  = test.drop(drop_elements, axis = 1)","43ca4ea5":"# Ponowny podgl\u0105d danych treningowych\ntrain.head(3)","9b53330d":"# Pokazanie zwi\u0105zku pomi\u0119dzy zmiennymi za pomoc\u0105 korelacji Pearsona\ncolormap = plt.cm.viridis\nplt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","51cc29f2":"# Wsp\u00f3\u0142czynnik prze\u017cycia w\u015br\u00f3d poszczeg\u00f3lnych tytu\u0142\u00f3w\ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).agg(['mean', 'count', 'sum'])\n# Mean oznacza wsp\u00f3\u0142czynnik prze\u017cycia \n# Count oznacza ilo\u015b\u0107 obserwacji\n# Sum oznacza ilo\u015b\u0107 os\u00f3b kt\u00f3re prze\u017cy\u0142y\n# Mr = 1, Miss = 2, Mrs = 3, Master = 4, Rare = 5","adc9c351":"# Wsp\u00f3\u0142czynnik prze\u017cycia w\u015br\u00f3d poszczeg\u00f3lnych p\u0142ci\ntrain[['Sex', 'Survived']].groupby(['Sex'], as_index=False).agg(['mean', 'count', 'sum'])\n# Mean oznacza wsp\u00f3\u0142czynnik prze\u017cycia \n# Count oznacza ilo\u015b\u0107 obserwacji\n# Sum oznacza ilo\u015b\u0107 os\u00f3b kt\u00f3re prze\u017cy\u0142y   \n# Kobiety = 0, M\u0119\u017cczy\u017ani = 1","b38e6c24":"# Wsp\u00f3\u0142czynnik prze\u017cy\u0107 w\u015br\u00f3d poszczeg\u00f3lnych tytu\u0142\u00f3w z uwzgl\u0119dnieniem p\u0142ci.\n# U\u017cycie funkcji copy (), aby zapobiec modyfikacjom w zbiorze danych original_train\ntitle_and_sex = original_train.copy()[['Name', 'Sex']]\n\n# Utworzenie warto\u015bci 'Title' \ntitle_and_sex['Title'] = title_and_sex['Name'].apply(get_title)\n\n# Mapowanie 'Sex' jako warto\u015bci binarnej\ntitle_and_sex['Sex'] = title_and_sex['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n\n# Rozk\u0142ad warto\u015bci 'Sex' pogrupowanej przez 'Title'\ntitle_and_sex[['Title', 'Sex']].groupby(['Title'], as_index=False).agg(['mean', 'count', 'sum'])\n\n# Mean oznacza wsp\u00f3\u0142czynnik m\u0119\u017cczyzn\n# Count oznacza ilo\u015b\u0107 obserwacji\n# Sum oznacza ilo\u015b\u0107 m\u0119\u017cczyzn","a744e305":"# Zdefiniowanie funkcji do obliczania prawdopodobie\u0144stwa b\u0142\u0119dnego oznakowania\ndef get_gini_impurity(survived_count, total_count):\n    survival_prob = survived_count\/total_count\n    not_survival_prob = (1 - survival_prob)\n    random_observation_survived_prob = survival_prob\n    random_observation_not_survived_prob = (1 - random_observation_survived_prob)\n    mislabelling_survided_prob = not_survival_prob * random_observation_survived_prob\n    mislabelling_not_survided_prob = survival_prob * random_observation_not_survived_prob\n    gini_impurity = mislabelling_survided_prob + mislabelling_not_survided_prob\n    return gini_impurity","ee8542d9":"# Obliczenie prawdopodobie\u0144stwa b\u0142\u0119dnego oznakowania elementu przy za\u0142o\u017ceniu,\n# \u017ce element jest oznaczony losowo zgodnie z rozk\u0142adem wszystkich klas w zbiorze przy pomocy Gini Impurity\n# u\u017cyte get_gini_impurity(x,y) gdzie X = ilo\u015b\u0107 os\u00f3b kt\u00f3re prze\u017cy\u0142y, Y = ilo\u015b\u0107 obserwacji\ngini_impurity_starting_node = get_gini_impurity(342, 891)\ngini_impurity_starting_node","eb8c020f":"# Oczyszczenie w\u0119z\u0142\u0105 dla obserwacji m\u0119skich\ngini_impurity_men = get_gini_impurity(109, 577)\ngini_impurity_men","6d1e8590":"# Oczyszczenie w\u0119z\u0142\u0105 dla obserwacji damskich\ngini_impurity_women = get_gini_impurity(233, 314)\ngini_impurity_women","50b48500":"# Oczyszczenie przy podziale przez p\u0142e\u0107\nmen_weight = 577\/891\nwomen_weight = 314\/891\nweighted_gini_impurity_sex_split = (gini_impurity_men * men_weight) + (gini_impurity_women * women_weight)\n\nsex_gini_decrease = weighted_gini_impurity_sex_split - gini_impurity_starting_node\nsex_gini_decrease","eb81de02":"# Oczyszczenie dla obserwacji z tytu\u0142em \"Mr\"\ngini_impurity_title_1 = get_gini_impurity(81, 517)\ngini_impurity_title_1","ca052203":"# Oczyszczenie dla obserwacji z tytu\u0142em innym ni\u017c Mr.\ngini_impurity_title_others = get_gini_impurity(261, 374)\ngini_impurity_title_others","efef099b":"# Prawdopodobie\u0144stwa b\u0142\u0119dnego oznakowania elementu zmniejsza si\u0119, \n# je\u015bli dane podzielone s\u0105 na obserwacje wzgl\u0119dem tytu\u0142u \"Mr\"\ntitle_1_weight = 517\/891\ntitle_others_weight = 374\/891\nweighted_gini_impurity_title_split = (gini_impurity_title_1 * title_1_weight) + (gini_impurity_title_others * title_others_weight)\n\ntitle_gini_decrease = weighted_gini_impurity_title_split - gini_impurity_starting_node\ntitle_gini_decrease","b406ae5f":"# Walidacja krzy\u017cowa 10-krotna\ncv = KFold(n_splits=10)            \naccuracies = list()\nmax_attributes = len(list(test))\ndepth_range = range(1, max_attributes + 1)\n\n# Testowanie max_depth od 1 do 10 atrybut\u00f3w\n# Odkomentowanie drukuje szczeg\u00f3\u0142owe informacje o ka\u017cdym przej\u015bciu walidacji krzy\u017cowej\nfor depth in depth_range:\n    fold_accuracy = []\n    tree_model = tree.DecisionTreeClassifier(max_depth = depth)\n    for train_fold, valid_fold in cv.split(train):\n        f_train = train.loc[train_fold] \n        f_valid = train.loc[valid_fold] \n\n        model = tree_model.fit(X = f_train.drop(['Survived'], axis=1), \n                               y = f_train[\"Survived\"]) \n        valid_acc = model.score(X = f_valid.drop(['Survived'], axis=1), \n                                y = f_valid[\"Survived\"])\n        fold_accuracy.append(valid_acc)\n\n    avg = sum(fold_accuracy)\/len(fold_accuracy)\n    accuracies.append(avg)\n    \n# Wy\u015bwietlenie wyniku\ndf = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\ndf = df[[\"Max Depth\", \"Average Accuracy\"]]\nprint(df.to_string(index=False))","a6e0e7e9":"# Tworzenie Numpy\nimport matplotlib.font_manager\nmatplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\ny_train = train['Survived']\nx_train = train.drop(['Survived'], axis=1).values \nx_test = test.values\n\n# Tworzenie drzewa decyzyjnego z max_depth = 3 kt\u00f3re mia\u0142o najwi\u0119ksz\u0105 precyzje\ndecision_tree = tree.DecisionTreeClassifier(max_depth = 3)\ndecision_tree.fit(x_train, y_train)\n\n# Przewidywanie wynik\u00f3w dla testowego zestawu danych\ny_pred = decision_tree.predict(x_test)\nsubmission = pd.DataFrame({\n        \"PassengerId\": PassengerId,\n        \"Survived\": y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)\n\n# Eksportowanie modelu trenowanego\nwith open(\"tree1.dot\", 'w') as f:\n     f = tree.export_graphviz(decision_tree,\n                              out_file=f,\n                              max_depth = 3,\n                              impurity = True,\n                              feature_names = list(train.drop(['Survived'], axis=1)),\n                              class_names = ['Died', 'Survived'],\n                              rounded = True,\n                              filled= True )\n        \n# Przekonwertowanie pliku do .jpg\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n\n# Wykres z adnotacjami z PIL\nimg = Image.open(\"tree1.png\")\ndraw = ImageDraw.Draw(img)\nfont = ImageFont.truetype('..\/input\/fonted\/LiberationSerif-Bold.ttf', 26)\ndraw.text((10, 0), \n          '\"Title <= 1.5\" corresponds to \"Mr.\" title', \n          (0,0,255), \n          font=font) \nimg.save('sample-out.png')\nPImage(\"sample-out.png\")","25c4aedc":"acc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\nacc_decision_tree","c44ba88d":"Z powy\u017cszego wida\u0107\u00a0i\u017c warto\u015bci Title bardzo dobrze rozpoznaje r\u00f3wnie\u017c p\u0142e\u0107","b7d9ab80":"Prze\u017cy\u0142e tylko :\n\n\"osoby kt\u00f3re mia\u0142y tytu\u0142 inny ni\u017c\u00a0\"Mr\" oraz wielko\u015b\u0107 rodziny mniejsz\u0105 ni\u017c\u00a05\" jak i r\u00f3wnie\u017c\n\n\"osoby kt\u00f3re mia\u0142y tytu\u0142 inny ni\u017c \"Mr\" oraz wielko\u015b\u0107 rodziny wi\u0119ksz\u0105 ni\u017c\u00a04 oraz mieli klas\u0119 nie najni\u017csz\u0105\"\n"}}