{"cell_type":{"777f4c60":"code","6319b0eb":"code","1fca9971":"code","bba13acc":"code","8141ec9f":"code","d49b2b9e":"code","8dd59b86":"code","2d43eb5e":"code","b0d7da79":"code","1343235f":"code","6f5461a3":"code","78e699f4":"code","518e7be0":"code","0884a8ed":"code","4e259039":"code","f235a140":"code","e51e9509":"code","626ff342":"code","189d8551":"code","8bad653b":"code","b0be484b":"code","2b701f19":"code","9efbca9d":"code","fc972ea7":"code","00b1a9bc":"code","3a2246e9":"code","06b5cacf":"code","d0b43f26":"code","ce0d617b":"code","fb270692":"code","4e7bf3b8":"code","9482a540":"code","53f0e878":"code","346d230b":"code","1686421e":"markdown","f7504e5e":"markdown","46f7d3f2":"markdown","018e0704":"markdown","eb771351":"markdown","4a619561":"markdown","c744915d":"markdown","f4fbee1a":"markdown","055e0548":"markdown","64a4e1ef":"markdown","e583009c":"markdown","39719f84":"markdown","22ea77bf":"markdown","792f938f":"markdown","94d7022d":"markdown","59555179":"markdown","297074e7":"markdown","4c02d1ef":"markdown"},"source":{"777f4c60":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport pickle\nfrom tqdm import tqdm\nfrom wordcloud import WordCloud\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score,roc_curve,auc,confusion_matrix,classification_report\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\nfrom IPython.display import Image,YouTubeVideo,HTML\n\n#KERAS Import\nfrom keras.models import Sequential, Model\nfrom keras.utils import to_categorical,plot_model\nfrom keras.layers import Dense, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.initializers import he_normal,glorot_normal\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.layers import Dropout\nfrom keras.layers import Embedding,CuDNNLSTM,CuDNNGRU, Flatten, Input, concatenate, Conv1D, GlobalMaxPooling1D, SpatialDropout1D, GlobalAveragePooling1D, Bidirectional\nfrom keras.regularizers import l2\nfrom keras.optimizers import Adam\nfrom keras.initializers import Orthogonal\nfrom keras.preprocessing.text import one_hot\nfrom keras.constraints import max_norm\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers","6319b0eb":"df = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/train.csv')\ndf.head()","1fca9971":"test_df = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/test.csv')","bba13acc":"print(df.iloc[28]['comment_text'])\nprint(\"Toxicity Level: \",df.iloc[28]['target'])","8141ec9f":"print(df.iloc[4]['comment_text'])\nprint(\"Toxicity Level: \",df.iloc[4]['target'])","d49b2b9e":"# https:\/\/stackoverflow.com\/a\/47091490\/4084039\nimport re\n\ndef decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase","8dd59b86":"# https:\/\/gist.github.com\/sebleier\/554280\n# we are removing the words from the stop words list: 'no', 'nor', 'not'\nstopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"]","2d43eb5e":"# Combining all the above statemennts \npreprocessed_comments = []\n# tqdm is for printing the status bar\nfor sentence in tqdm(df['comment_text'].values):\n    sent = decontracted(sentence)\n    sent = sent.replace('\\\\r', ' ')\n    sent = sent.replace('\\\\\"', ' ')\n    sent = sent.replace('\\\\n', ' ')\n    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n    # https:\/\/gist.github.com\/sebleier\/554280\n    sent = ' '.join(e for e in sent.split())\n    preprocessed_comments.append(sent.lower().strip())","b0d7da79":"df['comment_text'] = preprocessed_comments","1343235f":"df['comment_text'][1]","6f5461a3":"# Combining all the above statemennts \npreprocessed_comments_test = []\n# tqdm is for printing the status bar\nfor sentence in tqdm(test_df['comment_text'].values):\n    sent = decontracted(sentence)\n    sent = sent.replace('\\\\r', ' ')\n    sent = sent.replace('\\\\\"', ' ')\n    sent = sent.replace('\\\\n', ' ')\n    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n    # https:\/\/gist.github.com\/sebleier\/554280\n    sent = ' '.join(e for e in sent.split())\n    preprocessed_comments_test.append(sent.lower().strip())","78e699f4":"test_df['comment_text'] = preprocessed_comments_test","518e7be0":"train_len = len(df.index)","0884a8ed":"miss_val_train_df = df.isnull().sum(axis=0) \/ train_len\nmiss_val_train_df = miss_val_train_df[miss_val_train_df > 0] * 100\nmiss_val_train_df","4e259039":"identity_columns = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']","f235a140":"for column in identity_columns + ['target']:\n    df[column] = np.where(df[column] >= 0.5, True, False)","e51e9509":"# Target variable as well\ny = df['target'].values","626ff342":"train_df = df","189d8551":"class Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a \/= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","8bad653b":"MAX_VOCAB_SIZE = 100000\nTOXICITY_COLUMN = 'target'\nTEXT_COLUMN = 'comment_text'\nMAX_SEQUENCE_LENGTH = 300\n\n# Create a text tokenizer.\ntokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\ntokenizer.fit_on_texts(train_df[TEXT_COLUMN])\n\n# All comments must be truncated or padded to be the same length.\ndef padding_text(texts, tokenizer):\n    return sequence.pad_sequences(tokenizer.texts_to_sequences(texts), maxlen=MAX_SEQUENCE_LENGTH)","b0be484b":"train_text = padding_text(train_df[TEXT_COLUMN], tokenizer)\ntrain_y = to_categorical(train_df[TOXICITY_COLUMN])","2b701f19":"# for submission purpose\ntest_text = padding_text(test_df[TEXT_COLUMN], tokenizer)","9efbca9d":"NUM_EPOCHS = 6\nBATCH_SIZE = 1024","fc972ea7":"embeddings_index = {}\nwith open('..\/input\/fasttext-crawl-300d-2m\/crawl-300d-2M.vec' ,encoding='utf8') as f:\n  for line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs","00b1a9bc":"len(tokenizer.word_index)","3a2246e9":"embedding_matrix = np.zeros((len(tokenizer.word_index) + 1,300))\nnum_words_in_embedding = 0\nfor word, i in tokenizer.word_index.items():\n  embedding_vector = embeddings_index.get(word)\n  if embedding_vector is not None:\n    num_words_in_embedding += 1\n    # words not found in embedding index will be all-zeros.\n    embedding_matrix[i] = embedding_vector","06b5cacf":"embedding_matrix.shape","d0b43f26":"input_text_bgru = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='float32')\nembedding_layer_bgru = Embedding(len(tokenizer.word_index) + 1,\n                                    300,\n                                    weights=[embedding_matrix],\n                                    input_length=MAX_SEQUENCE_LENGTH,\n                                    trainable=False)\ng = embedding_layer_bgru(input_text_bgru)\ng = SpatialDropout1D(0.4)(g)\ng = Bidirectional(CuDNNGRU(64, return_sequences=True))(g)\natt = Attention(MAX_SEQUENCE_LENGTH)(g)\ng = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"he_uniform\")(g)\navg_pool = GlobalAveragePooling1D()(g)\nmax_pool = GlobalMaxPooling1D()(g)\ng = concatenate([att, avg_pool, max_pool])\ng = Dense(128, activation='relu')(g)\nbgru_output = Dense(2, activation='softmax')(g)","ce0d617b":"model = Model(inputs=[input_text_bgru], outputs=[bgru_output])","fb270692":"plot_model(model, show_shapes=True, to_file='singlegru.png')\nImage(filename=\"singlegru.png\")","4e7bf3b8":"model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])","9482a540":"SGRU_Model = model.fit(train_text,train_y,\n              batch_size=BATCH_SIZE,\n              epochs=NUM_EPOCHS)","53f0e878":"predictions = model.predict(test_text)[:, 1]","346d230b":"df_submit = pd.read_csv('..\/input\/jigsaw-unintended-bias-in-toxicity-classification\/sample_submission.csv')\ndf_submit.prediction = predictions\ndf_submit.to_csv('submission.csv', index=False)","1686421e":"#### Model building","f7504e5e":"# 1. Introduction","46f7d3f2":"## Previous competition and it's problem\nHere\u2019s the background: When the Conversation AI team first built toxicity models, they found that the models incorrectly learned to associate the names of frequently attacked identities with toxicity. Models predicted a high likelihood of toxicity for comments containing those identities (e.g. \"gay\"), even when those comments were not actually toxic (such as \"I am a gay woman\"). This happens because training data was pulled from available sources where unfortunately, certain identities are overwhelmingly referred to in offensive ways. Training a model from data with these imbalances risks simply mirroring those biases back to users.\n\nIn this competition, you're challenged to build a model that recognizes toxicity and minimizes this type of unintended bias with respect to mentions of identities. You'll be using a dataset labeled for identity mentions and optimizing a metric designed to measure unintended bias. Develop strategies to reduce unintended bias in machine learning models, and you'll help the Conversation AI team, and the entire industry, build models that work well for a wide range of conversations.","018e0704":"## About the problem\nThe Conversation AI team, a research initiative founded by Jigsaw and Google (both part of Alphabet), builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion.\n\nLast year, in the Toxic Comment Classification Challenge, you built multi-headed models to recognize toxicity and several subtypes of toxicity. This year's competition is a related challenge: building toxicity models that operate fairly across a diverse range of conversations.\n\n\n\n\n\n","eb771351":"#### Attention layer implementation","4a619561":"#### Submissions","c744915d":"## Percentage of NaN values","f4fbee1a":"# 5. Recurrent Neural Network","055e0548":"#### Creating the embedding matrix for the embedding layer","64a4e1ef":"# 4. Data Preprocessing","e583009c":"# 2. Imports","39719f84":"#### Model training","22ea77bf":"#### Model visualization","792f938f":"# 3. Data cleaning","94d7022d":"### Using GRU - Single GRU layer architecture","59555179":"## Understanding the evalution metrics\nhttps:\/\/medium.com\/jash-data-sciences\/measuring-unintended-bias-in-text-classification-a1d2e6630742\n\n**a. Subgroup AUC** \u2014 This calculates AUC on only the examples from the subgroup. It represents model understanding and performance within the group itself.\nA low value in this metric means the model does a poor job of distinguishing between toxic and non-toxic comments that mention the identity.\n\n**b. BNSP AUC** \u2014 This calculates AUC on the positive examples from the background and the negative examples from the subgroup.\nA low value here means that the model confuses toxic examples that mention the identity with non-toxic examples that do not.\n\n\n**c. BPSN AUC** \u2014 This calculates AUC on the negative examples from the background and the positive examples from the subgroup.\nA low value in this metric means that the model confuses non-toxic examples that mention the identity with toxic examples that do not.\n\n**d. Final Metrics** \u2014 We combine the overall AUC with the generalized mean of the Bias AUCs to calculate the final model score:\n\nscore=w0AUCoverall+\u2211a=1AwaMp(ms,a)\nwhere:\n\nA = number of submetrics (3)\n\nms,a = bias metric for identity subgroup s using submetric a\n\nwa = a weighting for the relative importance of each submetric; all four w values set to 0.25\n","297074e7":"## To understand more on bias\nhttps:\/\/www.youtube.com\/watch?v=59bMh59JQDo","4c02d1ef":"#### Preparing the text data for model"}}