{"cell_type":{"459ec273":"code","b3753d28":"code","d234adf4":"code","a103e17e":"code","1e77c0bf":"code","b1557370":"code","850507a0":"code","7014940d":"code","edaf1ec3":"code","0181c813":"code","2c416b71":"code","65bd916f":"code","54afad33":"code","9a32e70e":"code","bb4c153b":"markdown","17b4e629":"markdown","5debd36e":"markdown"},"source":{"459ec273":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b3753d28":"#Code by  https:\/\/www.kaggle.com\/kartushovdanil\/ubiquant-market-prediction-eda\n\nfrom pathlib import Path\nimport random\nimport tqdm\n\nfrom argparse import Namespace\nimport random\nimport os\nimport gc\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\n# setting up options\nimport warnings\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\nwarnings.filterwarnings('ignore')\nfrom cycler import cycler","d234adf4":"#Code by  https:\/\/www.kaggle.com\/kartushovdanil\/ubiquant-market-prediction-eda\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","a103e17e":"train = pd.read_csv(\"..\/input\/netflix-appetency\/train.csv\",nrows=10000)\ntest =  pd.read_csv(\"..\/input\/netflix-appetency\/test.csv\",nrows=10000)\nsub = pd.read_csv('\/kaggle\/input\/netflix-appetency\/sample_submission.csv')","1e77c0bf":"inv_ids = random.choices(train['target'].unique(), k=3)","b1557370":"#Code by  https:\/\/www.kaggle.com\/kartushovdanil\/ubiquant-market-prediction-eda\n\nplt.rcParams['figure.dpi'] = 600\nfig = plt.figure(figsize=(10, 10), facecolor='#f6f5f5')\ngs = fig.add_gridspec(5, 5)\ngs.update(wspace=0.3, hspace=0.3)\nbackground_color = '#f6f5f5'\nrun_no = 0\n\ncolormap = ['#1DBA94','#1C5ED2', '#FFC300', '#C70039']\nplt.rc('axes', prop_cycle=(cycler('color', colormap)))\n\nfor row in range(0, 5):\n    for col in range(0, 5):\n        locals()[\"ax\"+str(run_no)] = fig.add_subplot(gs[row, col])\n        locals()[\"ax\"+str(run_no)].set_facecolor(background_color)\n        for s in [\"top\",\"right\"]:\n            locals()[\"ax\"+str(run_no)].spines[s].set_visible(False)\n        run_no += 1  \n\n\nfeatures = list(train.columns[7:16]) #column 7 till 16 are uint\n\nrun_no = 0\nfor col in features:\n    sns.kdeplot(ax=locals()[\"ax\"+str(run_no)], x=train[col], zorder=2, alpha=1, linewidth=1, color='#ffd514')\n    sns.kdeplot(ax=locals()[\"ax\"+str(run_no)], x=train[train['target'].isin(inv_ids)][col], hue=train[train['target'].isin(inv_ids)]['target'],zorder=2, alpha=1, fill=True, color=colormap, linewidth=0.5, legend=False, hue_order=inv_ids.sort(reverse=True))\n    \n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='x', zorder=0, color='#EEEEEE', linewidth=0.4)\n    locals()[\"ax\"+str(run_no)].grid(which='major', axis='y', zorder=0, color='#EEEEEE', linewidth=0.4)\n    locals()[\"ax\"+str(run_no)].set_ylabel('')\n    locals()[\"ax\"+str(run_no)].set_xlabel(col, fontsize=4, fontweight='bold')\n    locals()[\"ax\"+str(run_no)].tick_params(labelsize=4, width=0.5)\n    locals()[\"ax\"+str(run_no)].xaxis.offsetText.set_fontsize(4)\n    locals()[\"ax\"+str(run_no)].yaxis.offsetText.set_fontsize(4)\n    #locals()[\"ax\"+str(run_no)].get_legend().remove()\n    \n    run_no += 1\n\nplt.show()","850507a0":"#Code by MAYUR DALVI  https:\/\/www.kaggle.com\/mayurdalvi\/tabular-playground-series-simple-and-easy\n\ncols = ['feature_'+str(i) for i in range(100)]","7014940d":"#Code by MAYUR DALVI  https:\/\/www.kaggle.com\/mayurdalvi\/tabular-playground-series-simple-and-easy\n\n#plot 32 features (59 - 91) When all are numerical (int\/float)\ni = 1\nplt.figure()\nfig, ax = plt.subplots(8, 4,figsize=(20, 22))\nfor feature in cols[59:91]:\n    plt.subplot(8, 4,i)\n    sns.histplot(train[feature],color=\"blue\", kde=True,bins=100, label='train_'+feature)\n    sns.histplot(test[feature],color=\"olive\", kde=True,bins=100, label='test_'+feature)\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show();","edaf1ec3":"sns.catplot(x=\"target\", kind=\"count\",  data=train, )\nplt.figure(figsize=(6,4)); #Why the size didn't changed?","0181c813":"plt.figure(figsize = (12,5))\nax = sns.distplot(train['target'], bins=5000)\nplt.xlim(-3,3)\nplt.xlabel(\"Histogram of Target\", size=18)\nplt.show();\ngc.collect()","2c416b71":"#Code by Vopani https:\/\/www.kaggle.com\/rohanrao\/automl-tutorial-tps-november-2021\n\n## define configuration\nPATH_TRAIN = '..\/input\/netflix-appetency\/train.csv'\nPATH_TEST = '..\/input\/netflix-appetency\/test.csv'\n\nPATH_AUTOGLUON_SUBMISSION = 'submission_autogluon.csv'\nPATH_EVALML_SUBMISSION = 'submission_evalml.csv'\nPATH_FLAML_SUBMISSION = 'submission_flaml.csv'\nPATH_H2OAML_SUBMISSION = 'submission_h2oaml.csv'\nPATH_LAML_SUBMISSION = 'submission_laml.csv'\nPATH_TPOT_SUBMISSION = 'submission_tpot.csv'\n\nMAX_MODEL_RUNTIME_MINS = 10\nMAX_MODEL_RUNTIME_SECS = MAX_MODEL_RUNTIME_MINS * 60","65bd916f":"#Code by Vopani https:\/\/www.kaggle.com\/rohanrao\/automl-tutorial-tps-november-2021\n\n## prepare data\nimport gc\nimport os\nimport shutil\nimport datatable as dt\nfrom pathlib import Path\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ntrain = dt.fread(PATH_TRAIN)[:100000, :]\ntest = dt.fread(PATH_TEST)\n\ntarget = train['target'].to_numpy().ravel()\ntest_ids = test['id']\n\ndel train[:, ['id', 'target']]\ntest = test[:, train.names]","54afad33":"#Code by Vopani https:\/\/www.kaggle.com\/rohanrao\/automl-tutorial-tps-november-2021\n\n## install packages\n!python3 -m pip install -q \"mxnet<2.0.0\"\n!python3 -m pip install -q autogluon\n!python3 -m pip install -q -U graphviz\n!python3 -m pip install -q -U scikit-learn","9a32e70e":"## import packages\nfrom autogluon.tabular import TabularPredictor","bb4c153b":"Above : ImportError: cannot import name '_check_feature_names_in' from 'sklearn.utils.validation' (\/opt\/conda\/lib\/python3.7\/site-packages\/sklearn\/utils\/validation.py)\n\nSince I couldn't even import\nfrom autogluon.tabular import TabularPredictor\n\nMy attempt to adapt Tab Playground Nov 2022 and Ubiquant to Netflix Appentency stop here.","17b4e629":"#Acknowledgements \n \nTorch me https:\/\/www.kaggle.com\/kartushovdanil\/ubiquant-market-prediction-eda\n\nMayur Dalvi https:\/\/www.kaggle.com\/mayurdalvi\/tabular-playground-series-simple-and-easy\n\nVopani https:\/\/www.kaggle.com\/rohanrao\/automl-tutorial-tps-november-2021","5debd36e":"#What's that above? Flattened distplot?"}}