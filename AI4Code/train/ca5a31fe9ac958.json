{"cell_type":{"dcf89bd1":"code","decad0d3":"code","ba3f3a23":"code","51e51ea6":"code","4cf49825":"code","7a0c35c7":"code","f12ec16b":"code","cc266a23":"code","ea374649":"code","8054d563":"code","cc69af5c":"code","33f3d200":"code","3c22bb85":"code","66f9b8f2":"code","ca24928a":"code","c9b61e7c":"code","6ad18a80":"code","42a2ac10":"code","0be2dad5":"code","7adc684f":"code","d1ca2105":"code","738d3c86":"code","b71db21c":"code","ac832a24":"code","ea028977":"code","79aea9dc":"markdown","d9eae9cc":"markdown","7059a489":"markdown","659c49a8":"markdown"},"source":{"dcf89bd1":"!wget -O \"caltech_image_classification_challenge-dataset.zip\" \"https:\/\/dockship-job-models.s3.ap-south-1.amazonaws.com\/026ce99895fb54347719338db96b045e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIDOPTEUZ2LEOQEGQ%2F20220125%2Fap-south-1%2Fs3%2Faws4_request&X-Amz-Date=20220125T070539Z&X-Amz-Expires=1800&X-Amz-Signature=d18ed035b02e8cb71551fa44e64ad9d0e6df41fbd57697d4dacf8f8fe2c28af8&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3D%22caltech_image_classification_challenge-dataset.zip%22\"","decad0d3":"!unzip .\/caltech_image_classification_challenge-dataset.zip","ba3f3a23":"!pip install tensorflow-gpu","51e51ea6":"import cv2\nimport tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\nimport PIL\nimport os\n\nROOT = '.\/256_train_imgs\/'","4cf49825":"import pathlib\n\ndata_dir = pathlib.Path('.\/256_train_imgs\/')","7a0c35c7":"images = list(data_dir.glob('*.jpg'))\nprint(len(images))","f12ec16b":"PIL.Image.open(str(images[3]))","cc266a23":"batch_size = 32\nimg_height = 150\nimg_width = 150","ea374649":"df = pd.read_csv('.\/256_train.csv')\ndf.head()","8054d563":"!mkdir .\/train","cc69af5c":"for dirname in df['Labels'].unique():\n  fn = os.path.join('.\/train', dirname)\n  os.mkdir(fn)\n","33f3d200":"import os\n\nk=0\nfor _, (fileName, label) in df.iterrows():\n  # if k > 4:\n  #   break\n  # k += 1\n  \n  destinationfile = os.path.join('.\/train',label, fileName)\n  currentfile = os.path.join('.\/256_train_imgs', fileName)\n\n  os.rename(currentfile, destinationfile)\n","3c22bb85":"data_dir = pathlib.Path('.\/train')","66f9b8f2":"train_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=49,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","ca24928a":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=49,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","c9b61e7c":"print(train_ds.class_names)","6ad18a80":"base_model = keras.applications.Xception(\n    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n    input_shape=(150, 150, 3),\n    include_top=False,\n)  # Do not include the ImageNet classifier at the top.","42a2ac10":"# Freeze the base_model\nbase_model.trainable = False","0be2dad5":"inputs = keras.Input(shape=(150, 150, 3))\n\n# Pre-trained Xception weights requires that input be scaled\n# from (0, 255) to a range of (-1., +1.), the rescaling layer\n# outputs: `(inputs * scale) + offset`\nscale_layer = keras.layers.Rescaling(scale=1 \/ 127.5, offset=-1)\nx = scale_layer(inputs)","7adc684f":"# The base model contains batchnorm layers. We want to keep them in inference mode\n# when we unfreeze the base model for fine-tuning, so we make sure that the\n# base_model is running in inference mode here.\nx = base_model(x, training=False)\nx = keras.layers.GlobalAveragePooling2D()(x)\nx = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\nx = keras.layers.Dense(257*4, activation=\"relu\")(x)\nx = keras.layers.Dense(257*2, activation=\"relu\")(x)\noutputs = keras.layers.Dense(257, activation=\"sigmoid\")(x)\nmodel = keras.Model(inputs, outputs)\n\nmodel.summary()","d1ca2105":"def plot(history):\n  # list all data in history\n  print(history.history.keys())\n  # summarize history for accuracy\n  plt.plot(history.history['accuracy'])\n  plt.plot(history.history['val_accuracy'])\n  plt.title('model accuracy')\n  plt.ylabel('accuracy')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()\n  # summarize history for loss\n  plt.plot(history.history['loss'])\n  plt.plot(history.history['val_loss'])\n  plt.title('model loss')\n  plt.ylabel('loss')\n  plt.xlabel('epoch')\n  plt.legend(['train', 'test'], loc='upper left')\n  plt.show()","738d3c86":"!pip install tensorflow-gpu","b71db21c":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","ac832a24":"ID = 44\n\nfor i in range(2):\n    ID += 1\n    train_ds = tf.keras.utils.image_dataset_from_directory(\n      data_dir,\n      validation_split=0.2,\n      subset=\"training\",\n      seed=ID,\n      image_size=(img_height, img_width),\n      batch_size=batch_size)\n    \n    val_ds = tf.keras.utils.image_dataset_from_directory(\n      data_dir,\n      validation_split=0.2,\n      subset=\"validation\",\n      seed=ID,\n      image_size=(img_height, img_width),\n      batch_size=batch_size)\n    \n    base_model.trainable = False\n\n    model.compile(\n      optimizer='adam',\n      loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n      metrics=['accuracy'])\n\n    model.fit(\n      train_ds,\n      validation_data=val_ds,\n      epochs=2\n    )\n    model.save('.\/my_model2e.h5')\n\n\n    base_model.trainable = True\n\n    model.compile(\n      optimizer=keras.optimizers.Adam(1e-5),\n      loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n      metrics=['accuracy'])\n\n    # Train end-to-end. Be careful to stop before you overfit!\n    model.fit(\n      train_ds,\n      validation_data=val_ds,\n      epochs=1\n    )\n    model.save('.\/my_model2e1s.h5')\n","ea028977":"!nvidia-smi","79aea9dc":"## Creating model","d9eae9cc":"## split test train","7059a489":"## Train the top layer","659c49a8":"## create folder with sub classified folders"}}