{"cell_type":{"2ba816a7":"code","8c0cdc8c":"code","4852cfc6":"code","b3a53d57":"code","e5bab42b":"code","c8ad5cd3":"code","1418eccf":"code","d1feb775":"code","68a3cd7d":"code","b19169d0":"code","40594afb":"code","c573c261":"code","819f4646":"code","a93f2bf0":"code","486e06c8":"code","45808396":"code","92ae0c1c":"code","4fb15bab":"code","c4b25873":"code","883ba2fe":"code","e1ac5340":"code","86b3524e":"code","77c667b8":"code","3091fc73":"markdown","35cf6066":"markdown","3f43e7f9":"markdown","03ace34d":"markdown","cd58fc41":"markdown","f8d25359":"markdown","a8fa4f04":"markdown","3c8ecc34":"markdown","2accea19":"markdown"},"source":{"2ba816a7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport eli5\nfrom nltk.tokenize import TweetTokenizer\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.multiclass import OneVsRestClassifier\npd.set_option('max_colwidth',400)\nimport msgpack\nfrom sklearn.metrics import roc_auc_score","8c0cdc8c":"info = pd.read_csv('..\/input\/train_info.csv')\ninfo.head()","4852cfc6":"info.injection.value_counts()","b3a53d57":"with open('..\/input\/train.msgpack', 'rb') as data_file:\n    train = msgpack.unpack(data_file)","e5bab42b":"with open('..\/input\/test.msgpack', 'rb') as data_file:\n    test = msgpack.unpack(data_file)","c8ad5cd3":"train = pd.DataFrame(train)\ntest = pd.DataFrame(test)\ntrain.columns = ['id', 'text']\ntest.columns = ['id', 'text']","1418eccf":"train.head(10).values","d1feb775":"train['text'] = train['text'].astype(str)\ntest['text'] = test['text'].astype(str)","68a3cd7d":"vectorizer = TfidfVectorizer(ngram_range=(1, 4), analyzer='char')\nfull_text = list(train['text'].values) + list(test['text'].values)\nvectorizer.fit(full_text)\ntrain_vectorized = vectorizer.transform(train['text'])\ntest_vectorized = vectorizer.transform(test['text'])","b19169d0":"info.injection.value_counts()","40594afb":"info = pd.merge(train, info, on='id')","c573c261":"y = np.array([1 if i == True else 0 for i in info.injection.values])","819f4646":"logreg = LogisticRegression(C=10.0)","a93f2bf0":"scores = cross_val_score(logreg, train_vectorized, y, scoring='roc_auc', n_jobs=-1, cv=5)\nprint('Cross-validation mean auc {0:.2f}%, std {1:.2f}.'.format(np.mean(scores) * 100, np.std(scores) * 100))","486e06c8":"logreg.fit(train_vectorized, y)","45808396":"eli5.show_weights(logreg, vec=vectorizer,  targets=[0, 1])","92ae0c1c":"eli5.show_prediction(logreg, doc=train['text'].values[100], vec=vectorizer)","4fb15bab":"# logreg1 = LogisticRegression(C=1.0)\n# logreg1.fit(train_vectorized, y)\n# logreg2 = LogisticRegression(C=0.1)\n# logreg2.fit(train_vectorized, y)","c4b25873":"# sub = pd.read_csv('..\/input\/sample_submission.csv')\n# pred = (logreg.predict_proba(test_vectorized) + logreg1.predict_proba(test_vectorized) + logreg2.predict_proba(test_vectorized)) \/ 3\n# sub['injection'] = pred\n# sub.head()\n# sub.to_csv('sub.csv', index=False)","883ba2fe":"from sklearn.model_selection import StratifiedKFold, KFold\nn_fold = 5\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=11)","e1ac5340":"def train_model(X=train_vectorized, X_test=test_vectorized, y=y, params=None, folds=folds, model_type='lgb', plot_feature_importance=False):\n\n    oof = np.zeros(X.shape[0])\n    prediction = np.zeros(X_test.shape[0])\n    scores = []\n    feature_importance = pd.DataFrame()\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n        print('Fold', fold_n, 'started at', time.ctime())\n        X_train, X_valid = X[train_index], X[valid_index]\n        y_train, y_valid = y[train_index], y[valid_index]\n        \n        if model_type == 'lgb':\n            model = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\n            model.fit(X_train, y_train, \n                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n                    verbose=1000, early_stopping_rounds=200)\n            \n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n        \n        oof[valid_index] = y_pred_valid.reshape(-1,)\n        scores.append(roc_auc_score(y_valid, y_pred_valid))\n        \n        prediction += y_pred    \n\n    prediction \/= n_fold\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n\n    return oof, prediction","86b3524e":"import time\nparams = {'num_leaves': 54,\n         'min_data_in_leaf': 79,\n         'objective': 'regression',\n         'max_depth': 7,\n         'learning_rate': 0.018545526395058548,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.8354507676881442,\n         \"bagging_freq\": 3,\n         \"bagging_fraction\": 0.8126672064208567,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.1,\n         \"verbosity\": -1,\n         'min_child_weight': 5.343384366323818,\n         'reg_alpha': 1.1302650970728192,\n         'reg_lambda': 0.3603427518866501,\n         'subsample': 0.8767547959893627,}\n\noof_lgb, prediction_lgb = train_model(X=train_vectorized, X_test=test_vectorized, y=y, folds=folds,\n                                                          params=params, model_type='lgb')","77c667b8":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['injection'] = prediction_lgb\nsub.head()\nsub.to_csv('sub.csv', index=False)","3091fc73":"### General information\n\nIn this kernel I'll analyse data from Malicious Intent Detection Challenge.\n\nWe need to identify injections among neutral input vectors using machine learning.","35cf6066":"### Loading data","3f43e7f9":"### ELI5\nBut at fist let's see what features are important.","03ace34d":"Wow, this baseline is pretty good! let's try submitting it.","cd58fc41":"Not sure whether this is an overfitting...","f8d25359":"## Exploring the data","a8fa4f04":"msgpack is a special format of data, similar to json. It requires msgpack library and data is read as bytes, not as strings.","3c8ecc34":"Data is a complete mess! There are symbols, words is strange encodings, links and so on... For now I'm not sure whether any preprocessing is useful. It could be a bad idea in fact!\nLet's try something basic for now - tokenizing on char level and logistic regression.","2accea19":"So we have a balanced dataset."}}