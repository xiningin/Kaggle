{"cell_type":{"62aaa336":"code","7c631ee9":"code","7075ac4e":"code","414ba8b5":"code","f46c8b2e":"code","a1d93809":"code","de480927":"code","b7ed143e":"code","5e296cae":"code","86b29b6d":"code","0fa0839d":"code","c7f1c717":"code","d1af8f66":"code","4efd8653":"code","ce81e5b9":"code","171d4eef":"code","1114d1af":"code","fe3ed25e":"code","9e0068a4":"code","2fe9849f":"code","02c78b2a":"code","e889c71c":"code","0ae305a3":"code","f137fc3b":"code","b0113d40":"markdown","81e7d290":"markdown","054dbf40":"markdown","0daf91cb":"markdown","f276effe":"markdown","001b783e":"markdown","762801f5":"markdown","64534682":"markdown","3317030e":"markdown","3f3ef8f6":"markdown","3b7b21c5":"markdown","756c8c28":"markdown","c1b7264d":"markdown","cae80193":"markdown","7c3d1b6d":"markdown","aa8a3df0":"markdown","8454cad2":"markdown","6e4f1cee":"markdown","7b61d225":"markdown","3b4db225":"markdown","89df8c09":"markdown"},"source":{"62aaa336":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7c631ee9":"df = pd.read_csv(\"\/kaggle\/input\/us-accidents\/US_Accidents_June20.csv\")","7075ac4e":"print(df.columns.tolist())","414ba8b5":"df.isnull().sum(axis = 0).sort_values(ascending = False).head(25)","f46c8b2e":"len(df)","a1d93809":"df = df.drop(['Number','Wind_Chill(F)', \"End_Lat\", \"End_Lng\", \"Timezone\", \"Airport_Code\", \"Weather_Timestamp\", \"Zipcode\", \n              \"Pressure(in)\", \"Wind_Direction(mph)\", \"Humidity(%\"], axis=1)","de480927":"df.isnull().sum(axis = 0).sort_values(ascending = False).head(10)","b7ed143e":"df = df.dropna(subset=[\"Astronomical_Twilight\", \"Nautical_Twilight\", \"Civil_Twilight\", \"Description\"])","5e296cae":"df['Precipitation(in)'] = df['Precipitation(in)'].fillna(df['Precipitation(in)'].median())\ndf['Visibility(mi)'] = df['Visibility(mi)'].fillna(df['Visibility(mi)'].median())\ndf['Temperature(F)'] = df['Temperature(F)'].fillna(df['Temperature(F)'].median())\ndf['Humidity(%)'] = df['Humidity(%)'].fillna(df['Humidity(%)'].median())","86b29b6d":"plt.figure(figsize=(17,8))\nax = df['State'].value_counts().plot(kind='bar')\nax.set_title(\"Accident count by state\")\nax.set_xlabel(\"State\")","0fa0839d":"plt.figure(figsize=(17,8))\nax = df['Severity'].value_counts().plot(kind='bar')\nax.set_title(\"Accident count by severity\")\nax.set_xlabel(\"Severity Rating\")","c7f1c717":"print(df[\"Severity\"].value_counts())","d1af8f66":"df['time'] = pd.to_datetime(df[\"Start_Time\"], format='%Y-%m-%d %H:%M:%S')\npd.DatetimeIndex(df['time']).month.value_counts().sort_index().plot.bar(width=0.5,align='center')\nplt.title(\"Accident Count by Month with Severity \")\nplt.xlabel(\"Month\")\nplt.ylabel(\"Accident Count\")\n","4efd8653":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\n\ndf['weekday'] = df['time'].dt.dayofweek\ndf['weekday'].value_counts().sort_index().plot.bar(width=0.5,align='center')\nplt.title(\"Accident Count by Month with Severity \")\nplt.xlabel(\"Day\")\nplt.ylabel(\"Accident Count\")\n","ce81e5b9":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\n\ndf['weekday'] = df['time'].dt.hour\ndf['weekday'].value_counts().sort_index().plot.bar(width=0.5,align='center')\nplt.title(\"Accident Count by Time with Severity \")\nplt.xlabel(\"Hour\")\nplt.ylabel(\"Accident Count\")","171d4eef":"fig = plt.figure()\nax = fig.add_axes([0,0,1,1])\n\ndf['weekday'] = df['time'].dt.hour\ndf[df[\"Severity\"] == 4]['weekday'].value_counts().sort_index().plot.bar(width=0.5,align='center')\nplt.title(\"Severe Accident Count by Time with Severity \")\nplt.xlabel(\"Hour\")\nplt.ylabel(\"Accident Count\")","1114d1af":"plt.subplots(figsize=(12,5))\ndf['Weather_Condition'].value_counts().head(20).plot.bar(width=0.5,align='center')\nplt.xlabel('Weather Condition',fontsize=16)\nplt.ylabel('Accident Count',fontsize=16)\nplt.title('20 of The Main Weather Conditions for Accidents of Severity ',fontsize=16)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)","fe3ed25e":"plt.title(\"Severity with Fog\")\ndf.loc[df[\"Weather_Condition\"] == \"Fog\"]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","9e0068a4":"plt.title(\"Severity with Fog\")\ndf.loc[df[\"Weather_Condition\"] == \"Fog\"]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","2fe9849f":"plt.title(\"Severity with Light Rain\")\ndf.loc[df[\"Weather_Condition\"] == \"Light Rain\"]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","02c78b2a":"plt.title(\"Severity with Rain\")\ndf.loc[df[\"Weather_Condition\"] == \"Rain\"]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","e889c71c":"plt.title(\"Severity with Heavy Rain\")\ndf.loc[df[\"Weather_Condition\"] == \"Heavy Rain\"]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","0ae305a3":"plt.title(\"Severity with Snow\")\ndf.loc[df[\"Weather_Condition\"] == \"Snow\"]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","f137fc3b":"for s in ['Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop']:\n    if (df[s] == True).sum() > 0:\n        plt.subplots(1,1,figsize=(12,5))\n        plt.xticks()\n        plt.suptitle('Accident Severity Near ' + s,fontsize=16)\n        plt.subplot(1,2,2)\n        df.loc[df[s] == True]['Severity'].value_counts().plot.pie(autopct='%1.0f%%',fontsize=16)","b0113d40":"Most accidents recieved a 2 rating for severity. There is a smaller amount of 4 ratings for severity which means that the 3 rating for severity will also be an important part of understanding ","81e7d290":"# Part 2: Data Analysis and Severity Analysis","054dbf40":"From this information we are able to find that junctions, give ways, railways, and no exits cause higher rates of crashes. ","0daf91cb":"# Part 1: Dealing with Missing Data\/Preprocessing","f276effe":"Next, we can do some EDA to understand when accidents happen, why they happen, and where they happen the most.","001b783e":"# Time of Accident","762801f5":"However, extremely severe accidents pretty much occurred at any time of day, there were no major differences between what time of day severe accidents occurred on the streets.","64534682":"Since most accidents here are during clear weather, we are unsure whether inclement weather causes greater accidents. It is interesting however, that light rain and light snow cause more accidents than snow and regular slow. Is this because drivers tend to go slower in heavy rain and heavy snow whereas they might not notice heavy snow and rain?\n","3317030e":"To fill in the precipitation values, we fill in the missing precipitation data with the median of the precipitation values (we don't use mean because it is more likely to be subject to skewed data). Another step that I could have took was to create a seperate column which contains whether the precipiration data was null or not. I do the same with visibility here. It is important to note that this might not have ben the best course of action if our visiblity distribution has a large distribution. However, NaN values only account for 2% of the data so we're hoping that doing this doesn't have a huge impact on our overall results. ","3f3ef8f6":"Some important features here to analyze are:\n* Severity\n* Start Time\n* State of Accident (Does one state have more accidents than others?)\n* Presence of Crossings, Junctions, Railways, Roundabouts, Stations, Stop\n* Precipitation and Visibility\n\nWe can use this data to predict what causes accidents, as well as how some of these features contribute to higher severity accidents. The features listed above are what I;m going to focus on based on an itial review of what I believe would most likely be indicators of car accidents.","3b7b21c5":"# State","756c8c28":"For some reason, there is a smaller amount of accidents in July. But, as a general rule, there does not seem to be much dependence on months in terms of accidents.","c1b7264d":"Now, we should drop datapoints with missing values in the following categories: astronomical twilight, nautical twilight, civil twilight, description since these wont affect the database since there is so few missing values.","cae80193":"Here we can see that Saturdays and Sundays have far less accidents than the other days of the week. ","7c3d1b6d":"Accidents occurred most frequently at 7 and 8 in the morning and at 4 and 5 in the afternoon and are the lowest after midnight as expected. ","aa8a3df0":"First, we should deal with missing data and work on preprocessing our data to be in a form where it is usable.","8454cad2":"We have null values for some important features such as Visibility and Precipitation as well as weather condition. For that reason, I'm going to remove some unimportant indicators below. For the sake of this exercise, I am removing the following indicators. In real pratice, I would do some research to understand what features actually affect car accidents so I dont remove important features prematurely. ","6e4f1cee":"**CA, TX, FL, SC, NC** are the leaders here in car accidents. We see a huge skew towards California drivers for accidents. Why? Is this dataset representative or did the sampling technique cause more california accidents to be scraped?","7b61d225":"Now we'll try to see how some of these factors actually affect the severity of the accident rather than just looking at whether an accident occurs or not.","3b4db225":"Level 3 and Level 4 Accidents increase as we go frrom light rain to heavy rain and snow. THis means that accidents are more likely to be severe under the influence of heavy rain and snow when compared to light rain and snow. ","89df8c09":"From this notebook, we were able to find that certain states had higher rates of accidents (CA specifically). We see that certain road features such as the presence of crossings, junctions and railways cause more severe accidents and the presence of inlcement weather also causes more severe accidents as a whole. \n\nAfter this initial review, if I were to expand on this study, I would attempt to find a correlation between visibility and severity of accidents. In addition,I would try to fit a logistic regression model to the dataset in order to find out whether we could predict the severity of an accident by inputting a variety of factors. This data analysis confirmed my hypothesis that inclement weather causes more severe accidents and that certain junctions and road features also cause more high profile accidents. This shows us that there are a lot of important factors to consider when looking at the severity of accidents and the presence of accidents around the country. "}}