{"cell_type":{"9f17520a":"code","8557c1e3":"code","d52696b1":"code","d63e0ca7":"code","09b47944":"code","aa1407b7":"code","73c52eee":"code","60fbfb3a":"code","38a99a0a":"code","047ce834":"code","3c122201":"code","9d8ef410":"code","8b8004bc":"code","a10bfdda":"code","260daf89":"code","d74ce447":"code","50deed5a":"code","979d3d5e":"code","ba35f672":"markdown","bd8ff6c1":"markdown","e71e71bc":"markdown","24478ed0":"markdown","6df1d9da":"markdown"},"source":{"9f17520a":"import pandas as pd\nimport numpy as np\nimport time\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import cross_val_score\n\nfrom catboost import CatBoostClassifier\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances","8557c1e3":"train=pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest=pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\nsub=pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')","d52696b1":"for col in train.columns: train[col] = train[col].astype('category')\nfor col in test.columns: test[col] = test[col].astype('category')","d63e0ca7":"X_test = test.drop(['id'], axis=1)\nX = train.drop(['id', 'target'], axis=1)\ny = train.target.str.extract(\"(\\d)\").astype(int)","09b47944":"oof_lightautoml=pd.read_csv('..\/input\/tps-jun2021-lightautoml\/oof_lightautoml.csv')\nsub_lightautoml=pd.read_csv('..\/input\/tps-jun2021-lightautoml\/sub_lightautoml.csv')\n\noof_lightautoml = oof_lightautoml.drop('id', axis=1)\noof_lightautoml.columns = ['pred_lightautoml' + str(i) for i in range(1, 10)]\n\nsub_lightautoml = sub_lightautoml.drop('id', axis=1)\nsub_lightautoml.columns = ['pred_lightautoml' + str(i) for i in range(1, 10)]\n\nX = pd.concat([X, oof_lightautoml], axis=1)\nX_test = pd.concat([X_test, sub_lightautoml], axis=1)","aa1407b7":"K=5\nSEED=314\nESR=100\n\nfixed_params = {\n    'random_state': SEED,\n    'task_type':\"GPU\",\n    'iterations': 100000, \n    'od_wait' : 50,\n    'loss_function':'MultiClass',\n    'use_best_model': True,\n    'eval_metric':'MultiClass', \n    'leaf_estimation_method':'Newton',\n    'bootstrap_type': 'Bernoulli',\n    'boosting_type': \"Plain\"\n}\n\nkf = StratifiedKFold(n_splits=K, shuffle=True, random_state=SEED)","73c52eee":"cat_oof = np.zeros((X.shape[0], 9))\ncat_pred = 0\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X=X, y=y)):\n    print(f\"\u279c FOLD :{fold}\")\n    X_train = X.iloc[train_idx]\n    y_train = y.iloc[train_idx]\n    X_val = X.iloc[val_idx]\n    y_val = y.iloc[val_idx]\n\n    start = time.time()\n    \n    model = CatBoostClassifier(**fixed_params, \n                               cat_features=[\"feature_\"+str(i) for i in range(75)])\n    \n    model.fit(X_train, y_train,\n              eval_set=(X_val, y_val),\n              early_stopping_rounds=ESR,\n              verbose=False\n             )\n    \n    cat_oof[val_idx,:] = model.predict_proba(X_val)\n    cat_pred += model.predict_proba(X_test) \/ K\n    \n    cat_logloss = log_loss(y_val, cat_oof[val_idx])\n    print(f\"score: {cat_logloss:.6f} \")\n    print(f\"elapsed: {time.time()-start:.2f} sec\\n\")\n    \n    del model\n\ncat_logloss = log_loss(y, cat_oof)\nprint(f\"Final logloss score: {cat_logloss} \u2714\ufe0f \")","60fbfb3a":"sub.iloc[:, 1:] = cat_pred\nsub.to_csv(\"sub_cat_default.csv\", index=False)\n\noof_cat = pd.concat([train.id,\n                     pd.DataFrame(cat_oof,\n                                  columns=[\"Class_1\", \"Class_2\", \"Class_3\",\n                                           \"Class_4\", \"Class_5\", \"Class_6\",\n                                           \"Class_7\", \"Class_8\", \"Class_9\"])],\n                    axis=1)\noof_cat.to_csv(\"oof_cat_default.csv\", index=False)","38a99a0a":"def objective(trial):\n    \n    max_depth = trial.suggest_int('depth', 2, 6)\n    max_num_leaves = (2 ** max_depth) - 1\n\n    hyperparams = {\n        'learning_rate':trial.suggest_uniform(\"learning_rate\", 0.01, 0.3),\n        'random_strength':trial.suggest_int(\"random_strength\", 1,50),\n        'max_bin':trial.suggest_categorical('max_bin', [2,3,4,5,6,8,10,20,30]),\n        'grow_policy':trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),        \n        \"depth\": max_depth,\n        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-5, 100),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1)\n        }\n    \n    if hyperparams['grow_policy'] == \"Lossguide\": \n        max_leaves = trial.suggest_int('num_leaves', 3, max_num_leaves)\n        if max_leaves<64:\n            hyperparams[\"max_leaves\"] = max_leaves\n        else:\n            hyperparams[\"max_leaves\"] = 31\n\n    params = dict(**fixed_params, **hyperparams)\n    cat_oof = np.zeros((X.shape[0], 9))\n\n    for i, (train_idx, val_idx) in enumerate(kf.split(X, y) ):\n\n        X_train = X.iloc[train_idx]\n        y_train = y.iloc[train_idx]\n        X_val = X.iloc[val_idx]\n        y_val = y.iloc[val_idx]\n\n        model = CatBoostClassifier(**params, \n                               cat_features=[\"feature_\"+str(i) for i in range(75)])\n\n        model.fit(X_train, y_train,\n                  eval_set=(X_val, y_val),\n                  early_stopping_rounds=ESR,\n                  verbose=False\n                 )\n\n        cat_oof[val_idx,:] = model.predict_proba(X_val)\n\n    return log_loss(y, cat_oof)","047ce834":"study = optuna.create_study(direction='minimize',\n                            pruner=optuna.pruners.HyperbandPruner(),\n                            #pruner=optuna.pruners.HyperbandPruner(min_resource=100,  reduction_factor=4),\n                            #sampler=optuna.samplers.TPESampler(n_startup_trials=50, multivariate=True, seed=123)\n                           )\n\nstudy.optimize(objective, \n               timeout=60*60*7.5, \n               n_trials=None, \n               gc_after_trial=False)","3c122201":"study.best_value","9d8ef410":"plot_optimization_history(study)","8b8004bc":"optuna.visualization.plot_parallel_coordinate(study)","a10bfdda":"plot_param_importances(study)","260daf89":"final_params = dict(**fixed_params, **study.best_params)\nfinal_params","d74ce447":"cat_oof = np.zeros((X.shape[0], 9))\ncat_pred = 0\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X=X, y=y)):\n    print(f\"\u279c FOLD :{fold}\")\n    X_train = X.iloc[train_idx]\n    y_train = y.iloc[train_idx]\n    X_val = X.iloc[val_idx]\n    y_val = y.iloc[val_idx]\n\n    start = time.time()\n    \n    model = CatBoostClassifier(**final_params, \n                               cat_features=[\"feature_\"+str(i) for i in range(75)])\n    \n    model.fit(X_train, y_train,\n              eval_set=(X_val, y_val),\n              early_stopping_rounds=ESR,\n              verbose=False\n             )\n    \n    cat_oof[val_idx,:] = model.predict_proba(X_val)\n    cat_pred += model.predict_proba(X_test) \/ K\n    \n    cat_logloss = log_loss(y_val, cat_oof[val_idx])\n    print(f\"score: {cat_logloss:.6f} \")\n    print(f\"elapsed: {time.time()-start:.2f} sec\\n\")\n    \n    del model\n\ncat_logloss = log_loss(y, cat_oof)\nprint(f\"Final logloss score: {cat_logloss} \u2714\ufe0f \")","50deed5a":"sub.iloc[:, 1:] = cat_pred\nsub.to_csv(\"sub_cat_optuned.csv\", index=False)","979d3d5e":"oof_cat = pd.concat([train.id,\n                     pd.DataFrame(cat_oof, columns=[\"Class_1\", \"Class_2\", \"Class_3\",\n                                                    \"Class_4\", \"Class_5\", \"Class_6\",\n                                                    \"Class_7\", \"Class_8\", \"Class_9\"])],\n                    axis=1)\noof_cat.to_csv(\"oof_cat_optuned.csv\", index=False)","ba35f672":"# Sub","bd8ff6c1":"# Optuna","e71e71bc":"# Final Model","24478ed0":"# Baseline","6df1d9da":"# Load Dependencies"}}