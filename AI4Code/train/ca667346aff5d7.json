{"cell_type":{"bac256b9":"code","2a0dd47c":"code","87db24b2":"code","094d2629":"code","6cd0b161":"code","8340ae48":"code","e6980491":"code","fa8c0bc2":"code","ae48fc36":"code","2feada0d":"code","27ab3b3d":"code","3e199c9f":"code","30443c38":"code","07315c29":"code","3a054772":"code","73db1509":"code","1986de1b":"code","de562150":"code","3d08ef1f":"code","151e79e9":"code","4a800cd5":"code","9a0d67ba":"code","ab9df805":"code","5502255b":"code","f4d4a440":"code","9653567a":"code","9f9b5c55":"code","dd5434ea":"code","d59b8e3c":"code","75789882":"code","2a6b148c":"code","dcdd3218":"code","5621bb4b":"code","c7d2c31b":"code","674a3d5e":"code","6a7aafb7":"code","9cb6a77c":"code","641f16b6":"code","e7a90d17":"code","eaad3a90":"code","c1b2171c":"code","49dbac96":"code","ee8358e8":"markdown","4172d43e":"markdown","c49e3357":"markdown","20f7dfa2":"markdown","3baabc93":"markdown","84053cac":"markdown","6c34e707":"markdown","312979e2":"markdown","17830389":"markdown","2c085fc8":"markdown","5ec2cad5":"markdown","1288bbe9":"markdown","fe582d09":"markdown","43d6465c":"markdown","abb9285e":"markdown","a2913d78":"markdown","2c5c32e6":"markdown","8277245c":"markdown","2c43d89d":"markdown","de921490":"markdown","14b62c18":"markdown"},"source":{"bac256b9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier","2a0dd47c":"data_folder = '..\/input\/titanic'\nprint(\"Available data files :\")\n!ls $data_folder","87db24b2":"train_df = pd.read_csv(os.path.join(data_folder,'train.csv'))","094d2629":"train_df.head()","6cd0b161":"train_df.describe()","8340ae48":"test_df = pd.read_csv(os.path.join(data_folder,'test.csv'))\ntest_df.head()","e6980491":"features = ['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Cabin']\ntrain_featured_data = train_df[features].copy()\ntrain_featured_data.head()","fa8c0bc2":"men = train_featured_data.loc[train_featured_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\nprint(f\"Total males who survived {sum(men)}\")\nprint(f\"Total males who didn't survived {len(men)-sum(men)}\")\nprint(\"% of males survived:\", rate_men)","ae48fc36":"female = train_featured_data.loc[train_featured_data.Sex == 'female'][\"Survived\"]\nrate_female = sum(female)\/len(female)\nprint(f\"Total females who survived {sum(female)}\")\nprint(f\"Total females who didn't survived {len(female)-sum(female)}\")\nprint(\"% of  females survived:\", rate_female)","2feada0d":"ax = sns.countplot(x='Sex', hue='Survived', data=train_featured_data,palette= ['#FF0000','#00FF00'])\nax.set_title('Survival Rate for range of Sex');","27ab3b3d":"plt.hist(train_featured_data['Age'])\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.title('Range of Ages in dataset');","3e199c9f":"survived_age = train_featured_data[train_featured_data['Survived']==1]['Age']\ndeath_age = train_featured_data[train_featured_data['Survived']==0]['Age']","30443c38":"ax = sns.histplot(survived_age, bins=10, label ='survived', kde =False, color=\"green\");\nax = sns.histplot(death_age, bins=10, label = 'not survived', kde =False, color=\"red\");\nax.legend();\nax.set_title('Survival Rate for range of ages');","07315c29":"survived_pclass = train_featured_data[train_featured_data['Survived']==1]['Pclass']\ndeath_pclass = train_featured_data[train_featured_data['Survived']==0]['Pclass']","3a054772":"ax = sns.countplot(x='Pclass', hue='Survived', data=train_featured_data,palette= ['#FF0000','#00FF00'])\nax.legend();\nax.set_title('Survival Rate for range of pclass');","73db1509":"survived_SibSp = train_featured_data[train_featured_data['Survived']==1]['SibSp']\ndeath_SibSp = train_featured_data[train_featured_data['Survived']==0]['SibSp']","1986de1b":"ax = sns.histplot(survived_SibSp, label ='survived', kde =False, color=\"green\");\nax = sns.histplot(death_SibSp, label = 'not survived', kde =False, color=\"red\");\nax.legend();\nax.set_title('Survival Rate for range of SibSp');","de562150":"survived_Parch = train_featured_data[train_featured_data['Survived']==1]['Parch']\ndeath_Parch = train_featured_data[train_featured_data['Survived']==0]['Parch']\n\nax = sns.histplot(survived_Parch, label ='survived', kde =False, color=\"green\");\nax = sns.histplot(death_Parch, label = 'not survived', kde =False, color=\"red\");\nax.legend();\nax.set_title('Survival Rate for range of Parch');","3d08ef1f":"def calculate_familysize(df):\n    cur_sib,cur_parch = df\n    family_size = cur_sib+cur_parch+1\n    \n    if family_size == 1:\n        return \"alone\"\n    elif family_size >1 and family_size<=4:\n        return \"small\"\n    else:\n        return \"large\"\n\ntrain_featured_data['family_size'] = train_featured_data[['SibSp','Parch']].apply(calculate_familysize,axis=1)\ntrain_featured_data.drop(['SibSp', 'Parch'], axis='columns', inplace=True)","151e79e9":"test_df['family_size'] = test_df[['SibSp','Parch']].apply(calculate_familysize,axis=1)\ntest_df.drop(['SibSp', 'Parch'], axis='columns', inplace=True)","4a800cd5":"ax = sns.countplot(x='family_size', hue='Survived', data=train_featured_data,palette= ['#FF0000','#00FF00'])\nax.legend();\nax.set_title('Survival Rate for range of family size');","9a0d67ba":"survived_Fare = train_featured_data[train_featured_data['Survived']==1]['Fare']\ndeath_Fare = train_featured_data[train_featured_data['Survived']==0]['Fare']\n\nax = sns.histplot(survived_Fare, label ='survived', kde =False, color=\"green\");\nax = sns.histplot(death_Fare, label = 'not survived', kde =False, color=\"red\");\nax.legend();\nax.set_title('Survival Rate for range of Fare');","ab9df805":"ax = sns.countplot(x='Embarked', hue='Survived', data=train_featured_data,palette= ['#FF0000','#00FF00'])\nax.legend();\nax.set_title('Survival Rate for range of Embarked');","5502255b":"cabin_temp_data = train_featured_data[['Cabin','Survived']].copy()\ncabin_temp_data = cabin_temp_data.dropna()\ncabin_temp_data['Cabin'] = cabin_temp_data['Cabin'].apply(lambda x : x[0])\nprint(f\"List of all cabins : {set(cabin_temp_data['Cabin'])}\")","f4d4a440":"survived_Cabin = cabin_temp_data[cabin_temp_data['Survived']==1]['Cabin']\ndeath_Cabin = cabin_temp_data[cabin_temp_data['Survived']==0]['Cabin']\n\nax = sns.histplot(survived_Cabin, label ='survived', kde =False, color=\"green\");\nax = sns.histplot(death_Cabin, label = 'not survived', kde =False, color=\"red\");\nax.legend();\nax.set_title('Survival Rate for range of Cabin');","9653567a":"#temporaly encoding the data\ntemp_data = train_featured_data.copy()\ntemp_data = temp_data.dropna()\nfeatures_to_encode = ['Sex','Embarked','Cabin','family_size']\nfor feature in features_to_encode:\n    le = LabelEncoder()\n    le.fit(temp_data[feature])\n    temp_data[feature] = le.transform(temp_data[feature])\n\nfeatures = list(temp_data.columns)\nplt.figure(figsize=(6,6))\nplt.imshow(np.abs(temp_data.corr()))\nplt.xticks(ticks=list(range(len(features))),labels=features,rotation='vertical');\nplt.yticks(ticks=list(range(len(features))),labels=features);\nplt.colorbar();\nplt.tight_layout()\n\ndel temp_data","9f9b5c55":"cabin_temp_data = train_featured_data[['Cabin','Survived','Pclass']].copy()\ncabin_temp_data = cabin_temp_data.dropna()\ncabin_temp_data['Cabin'] = cabin_temp_data['Cabin'].apply(lambda x : x[0])\nsns.countplot(x='Cabin', hue='Pclass', data=cabin_temp_data)","dd5434ea":"#assigning cabin on the basis of pclass using above information(graph)\npclass_1_cabin = ['A','B','C','D','E','T']\npclass_1_cabin_prob = [15,50,60,30,25,0]\npclass_1_cabin_prob = list(map(lambda x : x\/sum(pclass_1_cabin_prob) , pclass_1_cabin_prob))\npclass_2_cabin = ['F']\npclass_3_cabin = ['G']","d59b8e3c":"def get_cabin(df):\n    cur_pclass,x = df\n    if x is np.nan:\n        if cur_pclass==1:\n            return np.random.choice(pclass_1_cabin,p=pclass_1_cabin_prob)\n        elif cur_pclass==2:\n            return pclass_2_cabin[0]\n        else:\n            return pclass_3_cabin[0]\n    return x[0]","75789882":"train_featured_data['Cabin']=train_featured_data[['Pclass','Cabin']].apply(get_cabin,axis=1)\ntrain_featured_data['Cabin'].describe()","2a6b148c":"test_df['Cabin']=test_df[['Pclass','Cabin']].apply(get_cabin,axis=1)","dcdd3218":"# we will find median age of male and female in each pclass \nmale_median = list()\nfemale_median = list()\n\nfeatures = list(train_featured_data.columns)\nfeatures.remove('Survived')\ndf_all = pd.concat([train_featured_data[features],test_df[features]])\n\nfor i in range(3):      #since there is three values of pclass\n    male_cur_median = (df_all.loc[(df_all['Pclass'] ==(i+1)) & (df_all['Sex']=='male')])['Age'].median()\n    female_cur_median = (df_all.loc[(df_all['Pclass'] ==(i+1)) & (df_all['Sex']=='female')])['Age'].median()\n    male_median.append(male_cur_median)\n    female_median.append(female_cur_median)\n\ndef get_age(df):\n    age,sex,pclass = df\n    if age == -1:\n        return male_median[pclass-1] if sex=='male' else female_median[pclass-1]\n    else:\n        return age\ntrain_featured_data['Age'] = train_featured_data['Age'].fillna(-1)\ntrain_featured_data['Age'] = train_featured_data[['Age','Sex','Pclass']].apply(get_age,axis=1)","5621bb4b":"test_df['Age'] = test_df['Age'].fillna(-1)\ntest_df['Age'] = test_df[['Age','Sex','Pclass']].apply(get_age,axis=1);","c7d2c31b":"for feature in train_featured_data.columns:\n    train_featured_data[feature] = train_featured_data[feature].fillna(method=\"ffill\")\n    try:\n        test_df[feature] = test_df[feature].fillna(method=\"ffill\")\n    except:\n        continue","674a3d5e":"features_to_encode = ['Sex','Embarked','Cabin','family_size']\nfor feature in features_to_encode:\n    le = LabelEncoder()\n    le.fit(train_featured_data[feature])\n    train_featured_data[feature] = le.transform(train_featured_data[feature])\n    test_df[feature] = le.transform(test_df[feature])","6a7aafb7":"train_featured_data.isna().sum()","9cb6a77c":"test_df.isna().sum()","641f16b6":"X = train_featured_data.drop(columns=['Survived']).to_numpy()\ny = np.expand_dims(train_featured_data['Survived'].to_numpy(),axis=-1)\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.025, random_state=10)","e7a90d17":"print(f\"Number of features : {X.shape[1]}\")\nprint(f\"Number of training examples are {X_train.shape[0]}\")\nprint(f\"Number of testing examples are {X_test.shape[0]}\")","eaad3a90":"#training with random forest\nmodel = RandomForestClassifier(criterion='gini',\n                                           n_estimators=1750,\n                                           max_depth=7,\n                                           min_samples_split=6,\n                                           min_samples_leaf=6,\n                                           max_features='auto',\n                                           oob_score=True,\n                                           n_jobs=-1,\n                                           verbose=1)\nmodel.fit(X,y);\ny_pred = model.predict(X)\ny_pred = (y_pred>0.5).astype(np.int32)\nprint(classification_report(y,y_pred))","c1b2171c":"features = list(train_featured_data.columns)\nfeatures.remove('Survived')\nX_test = test_df[features]\npredictions = model.predict(X_test)","49dbac96":"submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = predictions\nsubmission.to_csv('submission.csv', index=False)","ee8358e8":"##### SibSp and parch feature can be combined in to one feature","4172d43e":"### Examine 'Parch' feature","c49e3357":"### Examine 'SibSp' feature","20f7dfa2":"### Examine 'Pclass' feature","3baabc93":"### Splitting traing and test data","84053cac":"### For training, manually picking relevant features","6c34e707":"### Looking through data file available","312979e2":"### Examine 'Fare' feature","17830389":"### Examine 'Sex' feature","2c085fc8":"#### We will fit the model with the complete data and test on a random selection from the data because the data is limited.","5ec2cad5":"### Extracting train data","1288bbe9":"# Data Extraction and Pre-processing","fe582d09":"### Why is a Neural Network not a viable option for this dataset?\nThe main disadvantage of Neural Network is that it requires a large quantity of data, which is not accessible in this dataset. As a result, Neural Network is not practicable.\n\n### Why would decision tree-based models outperform neural network models?\nBecause the majority of the selected characteristics are highly correlated to the target variable, a decision tree-based model will perform better because it will provide a more meaningful corelated tree.","43d6465c":"##### Now filling up the values of reamining feature with nearest method","abb9285e":"# Importing Required Libraries","a2913d78":"### Extracting test data","2c5c32e6":"# Build and Train Model","8277245c":"##### cabin is highly correlated with Pclass##### ","2c43d89d":"# Making submission to Kaggle","de921490":"### Examine 'Embarked' feature","14b62c18":"### Examine 'Age' feature"}}