{"cell_type":{"868af0c7":"code","9cda1367":"code","825e58b9":"code","309d1f30":"code","72bdddd2":"code","c885884d":"code","0eb476e0":"code","e5b96807":"code","bc6604f1":"code","465fc2df":"code","f375766a":"code","4be19637":"code","8f2ef6e1":"code","1a021ad9":"code","39b807ad":"code","c94a3400":"code","b2cf9e19":"code","df26dbe0":"code","b0ddd387":"code","beaaf25b":"code","bf47f856":"code","0a436619":"code","a6fc71e7":"code","815dc880":"code","0c3e2205":"code","c5847371":"code","3d4cbbed":"code","c945489e":"code","67cc69fc":"code","deab4e82":"code","580dd130":"code","d080da14":"code","b637466f":"code","40c0c2f2":"code","da9d1960":"code","8a41a8ca":"code","ee168ccb":"code","84ef3e80":"code","97643597":"code","68e18fb0":"code","d52f291a":"code","6fb739a0":"code","495ff9bb":"code","69c48f62":"code","47d8076d":"code","c342cd64":"code","1dd3413f":"code","e4c98869":"code","68186293":"code","c3552dc2":"code","28f910ff":"code","0f85a73c":"code","bd6f0e34":"code","f92d67c2":"code","f0f66a3f":"code","e8a9f5d1":"code","b9565ced":"code","d2c00333":"code","480198ca":"code","83ada404":"code","4c24b218":"code","674f32c4":"code","73947e2a":"code","b181665f":"code","9b48a525":"code","25b7708e":"code","afba0062":"code","3c559e28":"code","2501e458":"code","4cc91e7b":"code","aada3c72":"code","7b79955b":"code","d0dd08d0":"code","b0934bff":"code","9e5707d5":"code","77ab15e4":"code","b4633e0f":"code","23603ac7":"code","6ffea891":"code","1d4d9986":"code","2b332be8":"code","c442d1c0":"code","ff1389c7":"code","0cfef51f":"code","9ff320a8":"markdown","d3ccc4e9":"markdown","6efa5628":"markdown","39a63618":"markdown","152f6329":"markdown","f1ce22a4":"markdown","bce0d1a4":"markdown","06baeb67":"markdown","610a2f46":"markdown","88d6dc47":"markdown","e4e924ec":"markdown","d12abbc2":"markdown","af728f0f":"markdown","4693f6d4":"markdown","c0413e2a":"markdown","e31c97e7":"markdown","35536373":"markdown","3297b6b9":"markdown","dbd26bbd":"markdown","930c7328":"markdown","023a02c8":"markdown","737f45fb":"markdown","52962bc3":"markdown","d18b2e9c":"markdown","46a78082":"markdown","20532cfa":"markdown"},"source":{"868af0c7":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder, OneHotEncoder\nfrom sklearn.preprocessing import PolynomialFeatures, PowerTransformer, FunctionTransformer\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold, RandomizedSearchCV, StratifiedShuffleSplit\nfrom sklearn.feature_selection import SelectFromModel, SelectKBest, VarianceThreshold\nfrom sklearn.metrics import roc_auc_score, roc_curve, f1_score, accuracy_score, classification_report\nfrom sklearn.decomposition import PCA, FactorAnalysis, TruncatedSVD\nfrom sklearn.manifold import TSNE\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\npd.set_option('display.max_columns', None)","9cda1367":"train = pd.read_csv(\"\/kaggle\/input\/janatahack-crosssell-prediction\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/janatahack-crosssell-prediction\/test.csv\")\ntrain.drop('id', axis=1, inplace=True)\ntest.drop('id', axis=1, inplace=True)\nsample = pd.read_csv(\"\/kaggle\/input\/janatahack-crosssell-prediction\/sample_submission.csv\")","825e58b9":"train.info()","309d1f30":"train.head()","72bdddd2":"train.isna().sum()","c885884d":"test.isna().sum()","0eb476e0":"for col in train.columns:\n    print(f\"{col} : {train[col].nunique()}\")\n    print(train[col].unique())","e5b96807":"#separating continuous and categorical variables\ncat_var = [\"Gender\",\"Driving_License\",\"Previously_Insured\",\"Vehicle_Age\",\"Vehicle_Damage\"]\ncon_var = list(set(train.columns).difference(cat_var+[\"Response\"]))","bc6604f1":"train.Response.value_counts(normalize=True)","465fc2df":"sns.countplot(train.Response)\nplt.title(\"Class count\")\nplt.show()","f375766a":"train.head(3)","4be19637":"# axis is as follows\n\nsns.pairplot(train, hue='Response', diag_kind='hist')\nplt.show()","8f2ef6e1":"def map_val(data):\n    data[\"Gender\"] = data[\"Gender\"].replace({\"Male\":1, \"Female\":0})\n    data[\"Vehicle_Age\"] = data[\"Vehicle_Age\"].replace({'> 2 Years':2, '1-2 Year':1, '< 1 Year':0 })\n    data[\"Vehicle_Damage\"] = data[\"Vehicle_Damage\"].replace({\"Yes\":1, \"No\":0})\n    return data\n\ntrain = map_val(train)\ntest = map_val(test)","1a021ad9":"comb = pd.concat([train,test])\ncomb.shape , train.shape , test.shape","39b807ad":"\nprint('The distribution of gender:',comb['Gender'].value_counts())","c94a3400":"comb.head()","b2cf9e19":"comb.info()","df26dbe0":"list1 = ['Gender', 'Age', 'Region_Code', 'Previously_Insured',\n       'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium',\n       'Policy_Sales_Channel', 'Vintage']","b0ddd387":"# list1 = set(comb.columns) - set('Driving_License')\nlist1","beaaf25b":"\nfig, axes = plt.subplots(nrows=3, ncols=3,figsize=(20,20))\n\nfor i, column in enumerate(list1):\n    print(column)\n    sns.distplot(comb[column],ax=axes[i\/\/3,i%3])","bf47f856":"train.head(3)","0a436619":"cat_var","a6fc71e7":"fig, ax = plt.subplots(2,3 , figsize=(15,15))\nax = ax.flatten()\nfor i,col in enumerate(cat_var):\n    sns.pointplot(x = col, y = 'Response',hue = 'Vehicle_Age',data=train, ax = ax[i])\nplt.tight_layout()\nplt.show()","815dc880":"fig, ax = plt.subplots(2,3 , figsize=(10,10))\nax = ax.flatten()\nfor i,col in enumerate(cat_var):\n    sns.pointplot(col, 'Response', data=train, ax = ax[i])\nplt.tight_layout()\nplt.show()","0c3e2205":"sns.catplot('Gender', 'Response',hue='Vehicle_Age', row = 'Previously_Insured',col='Vehicle_Damage',data=train, kind='point', height=3, aspect=2)\nplt.show()","c5847371":"fig, ax = plt.subplots(2,3 , figsize=(16,6))\nax = ax.flatten()\ni = 0\nfor col in con_var:\n    sns.boxplot( 'Response', col, data=train, ax = ax[i])\n    i+=1\nplt.tight_layout()\nplt.show()","3d4cbbed":"sns.catplot('Gender', 'Vintage',hue='Response', row = 'Previously_Insured',col='Vehicle_Damage',data=train, kind='box', height=3, aspect=2)\nplt.show()","c945489e":"sns.catplot('Gender', 'Age',hue='Response', row = 'Previously_Insured',col='Vehicle_Damage',data=train, kind='box', height=3, aspect=2)\nplt.show()","67cc69fc":"sns.catplot('Gender', 'Annual_Premium',hue='Response', row = 'Previously_Insured',col='Vehicle_Damage',data=train, kind='box', height=3, aspect=2)\nplt.show()","deab4e82":"plt.figure(figsize=(30,5))\nsns.heatmap(pd.crosstab([train['Previously_Insured'], train['Vehicle_Damage']], train['Region_Code'],\n                        values=train['Response'], aggfunc='mean', normalize='columns'), annot=True, cmap='inferno')\nplt.show()","580dd130":"crosstab_df=pd.crosstab([train['Previously_Insured'], train['Vehicle_Damage']], train['Region_Code'],values=train['Response'], aggfunc='mean', normalize='columns')\ncrosstab_df","d080da14":"cat_var","b637466f":"train.head(1)","40c0c2f2":"sns.relplot(x=\"Age\", y=\"Annual_Premium\", hue=\"Response\", data=train)","da9d1960":"sns.relplot(x=\"Vintage\", y=\"Annual_Premium\", hue=\"Response\", data=train)","8a41a8ca":"sns.relplot(x=\"Policy_Sales_Channel\", y=\"Annual_Premium\", hue=\"Response\", data=train)","ee168ccb":"corr = train.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)]=True\nplt.figure(figsize=(10,6))\nsns.heatmap(corr, annot=True, fmt='.2f', cmap='YlGnBu', mask=mask)\nplt.title(\"Correlation Heatmap\")\nplt.show()","84ef3e80":"train.skew()","97643597":"train['log_premium'] = np.log(train.Annual_Premium)\ntrain['log_age'] = np.log(train.Age)\ntest['log_premium'] = np.log(test.Annual_Premium)\ntest['log_age'] = np.log(test.Age)","68e18fb0":"train.groupby(['Previously_Insured','Gender'])['log_premium'].plot(kind='kde')\nplt.show()","d52f291a":"train.groupby(['Previously_Insured','Gender'])['log_age'].plot(kind='kde')\nplt.show()","6fb739a0":"import eli5\nfrom eli5.sklearn import PermutationImportance","495ff9bb":"def feature_engineering(data, col):\n    mean_age_insured = data.groupby(['Previously_Insured','Vehicle_Damage'])[col].mean().reset_index()\n    mean_age_insured.columns = ['Previously_Insured','Vehicle_Damage','mean_'+col+'_insured']\n    mean_age_gender = data.groupby(['Previously_Insured','Gender'])[col].mean().reset_index()\n    mean_age_gender.columns = ['Previously_Insured','Gender','mean_'+col+'_gender']\n    mean_age_vehicle = data.groupby(['Previously_Insured','Vehicle_Age'])[col].mean().reset_index()\n    mean_age_vehicle.columns = ['Previously_Insured','Vehicle_Age','mean_'+col+'_vehicle']\n    data = data.merge(mean_age_insured, on=['Previously_Insured','Vehicle_Damage'], how='left')\n    data = data.merge(mean_age_gender, on=['Previously_Insured','Gender'], how='left')\n    data = data.merge(mean_age_vehicle, on=['Previously_Insured','Vehicle_Age'], how='left')\n    data[col+'_mean_insured'] = data['log_age']\/data['mean_'+col+'_insured']\n    data[col+'_mean_gender'] = data['log_age']\/data['mean_'+col+'_gender']\n    data[col+'_mean_vehicle'] = data['log_age']\/data['mean_'+col+'_vehicle']\n    data.drop(['mean_'+col+'_insured','mean_'+col+'_gender','mean_'+col+'_vehicle'], axis=1, inplace=True)\n    return data\n\ntrain = feature_engineering(train, 'log_age')\ntest = feature_engineering(test, 'log_age')\n\ntrain = feature_engineering(train, 'log_premium')\ntest = feature_engineering(test, 'log_premium')\n\ntrain = feature_engineering(train, 'Vintage')\ntest = feature_engineering(test, 'Vintage')","69c48f62":"train","47d8076d":"test","c342cd64":"X = train.drop([\"Response\"], axis=1)\nY = train[\"Response\"]","1dd3413f":"from sklearn.model_selection import train_test_split\nX_train,X_val,y_train,y_val=train_test_split(X,Y,test_size=0.2,random_state=294,stratify = Y)","e4c98869":"lg=LGBMClassifier(boosting_type='gbdt',n_estimators=500,depth=5,learning_rate=0.04,objective='binary',metric='auc',is_unbalance=True,\n                 colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=294,n_jobs=-1)\n\nlg.fit(X_train,y_train)\nprint(roc_auc_score(y_val,lg.predict_proba(X_val)[:,1]))","68186293":"#Check for Permutation Importance of Features\nperm = PermutationImportance(lg,random_state=294).fit(X_val, y_val)\neli5.show_weights(perm,feature_names=X_val.columns.tolist())","c3552dc2":"\ndef drop_permute_feat(data,permuter):\n    mask = permuter.feature_importances_ > 0 \n    features = data.columns[mask]\n    return features","28f910ff":"features = drop_permute_feat(X_train,perm)\nfeatures","0f85a73c":"X_train_permute = X_train[features]\nX_val_permute = X_val[features]","bd6f0e34":"lg=LGBMClassifier(boosting_type='gbdt',n_estimators=500,depth=5,learning_rate=0.04,objective='binary',metric='auc',is_unbalance=True,\n                 colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=294,n_jobs=-1)\n\nlg.fit(X_train_permute,y_train)\nprint(roc_auc_score(y_val,lg.predict_proba(X_val_permute)[:,1]))","f92d67c2":"## Full fit\nlg=LGBMClassifier(boosting_type='gbdt',n_estimators=500,depth=10,learning_rate=0.04,objective='binary',metric='auc',is_unbalance=True,\n                 colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=294,n_jobs=-1)\nlg.fit(X,Y)","f0f66a3f":"submission_df=pd.read_csv('\/kaggle\/input\/janatahack-crosssell-prediction\/sample_submission.csv')\nsubmission_df['Response']=np.array(lg.predict_proba(test)[:,1])\nsubmission_df.to_csv('baseline_test.csv',index=False)\nsubmission_df.head(5)","e8a9f5d1":"def drop(data,list2):\n    data_new = data.drop(list2, axis=1,inplace = False)\n    return data_new\n\n\n\n\n","b9565ced":"X.info()","d2c00333":"test.info()","480198ca":"X_select = X.copy()\ntest_select = test.copy()","83ada404":"from sklearn.model_selection import StratifiedKFold","4c24b218":"model_xgb = XGBClassifier(n_jobs=4, random_state=1, scale_pos_weight=7, objective='binary:logistic')\nmodel_lgbm = LGBMClassifier(n_jobs=4, random_state=1, is_unbalance=True, objective='binary')\nmodel_cat = CatBoostClassifier(random_state=1, verbose=0, scale_pos_weight=7, custom_metric=['AUC'])","674f32c4":"def submission(preds, model):\n    sample[\"Response\"] = preds\n    sample.to_csv(\"model_\"+model+\".csv\", index=False)","73947e2a":"model_lgbm = LGBMClassifier(boosting_type='gbdt',n_estimators=500,depth=10,learning_rate=0.04,objective='binary',metric='auc',is_unbalance=True,\n                 colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=294,n_jobs=-1)","b181665f":"def cv_generator(model,n_splits_user,X_select,Y):\n    cv = StratifiedKFold(n_splits=n_splits_user, random_state=1, shuffle=True)\n    predictions= []\n    train_roc_score = 0\n    test_roc_score = 0\n\n    for train_index, test_index in cv.split(X_select, Y):\n        xtrain, xtest = X_select.iloc[train_index], X_select.iloc[test_index]\n        ytrain, ytest = Y[train_index], Y[test_index]\n\n        model.fit(xtrain, ytrain)\n        trainpred = model.predict_proba(xtrain)[:,1]\n        testpred = model.predict_proba(xtest)[:,1]\n        train_roc_score += roc_auc_score(ytrain, trainpred)\n        test_roc_score += roc_auc_score(ytest, testpred)\n        print(\"Train ROC AUC : %.4f Test ROC AUC : %.4f\"%(roc_auc_score(ytrain, trainpred),roc_auc_score(ytest, testpred)))\n\n        prediction = model.predict_proba(test_select)[:,1]\n        predictions.append(prediction)\n    \n    print(\"The mean train score is :\",train_roc_score\/5)\n    print(\"The mean test score is :\",test_roc_score\/5)\n    \n    return prediction\n","9b48a525":"predictions_lgbm = cv_generator(model = model_lgbm,n_splits_user = 5,X_select = X,Y = Y)\nsubmission(np.mean(predictions_lgbm, axis=0), 'lgbm_stack')","25b7708e":"predictions_xgb = cv_generator(model = model_xgb,n_splits_user = 5,X_select = X,Y = Y)\nsubmission(np.mean(predictions_xgb, axis=0), 'xgb_stack')","afba0062":"predictions_cat = cv_generator(model = model_cat,n_splits_user = 5,X_select = X,Y = Y)\nsubmission(np.mean(predictions_cat, axis=0), 'cat_stack')","3c559e28":"from sklearn.model_selection import train_test_split\nX_train,X_val,y_train,y_val=train_test_split(X,Y,test_size=0.2,random_state=294,stratify = Y)","2501e458":"# categorical column \ncat_col=['Gender','Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage','Policy_Sales_Channel']","4cc91e7b":"X.info()","aada3c72":"X.columns","7b79955b":"X.Region_Code.dtype == 'float64'\n","d0dd08d0":"X_copy = X.copy()","b0934bff":"test_copy = test.copy()\nfor col in test.columns:\n    if test[col].dtype == 'float64' :\n        test_copy[col] = test[col].astype('int')\ntest_copy.info()          \n        \n        ","9e5707d5":"for col in X.columns:\n    if X[col].dtype == 'float64' :\n        X_copy[col] = X[col].astype('int')\n        \nX_copy.info()        \n        ","77ab15e4":"col_1=['Gender', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']","b4633e0f":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nX_t, X_tt, y_t, y_tt = train_test_split(X_copy[col_1], Y, test_size=.25, random_state=150303,stratify=Y,shuffle=True)","23603ac7":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score\ncatb = CatBoostClassifier()\ncatb= catb.fit(X_t, y_t,cat_features=cat_col,eval_set=(X_tt, y_tt),plot=True,early_stopping_rounds=40,verbose=100)\n#catb= catb.fit(X_t, y_t,cat_features=cat_col,eval_set=(X_tt, y_tt),plot=True,verbose=100)\ny_cat = catb.predict(X_tt)\nprobs_cat_train = catb.predict_proba(X_t)[:, 1]\nprobs_cat_test = catb.predict_proba(X_tt)[:, 1]\nroc_auc_score(y_t, probs_cat_train)\nroc_auc_score(y_tt, probs_cat_test)","6ffea891":"cat_pred_new= catb.predict_proba(test_copy[col_1])[:, 1]\n","1d4d9986":"submission(cat_pred_new,'cat_boost_predictions_reduced_cols')\n","2b332be8":"feat_importances = pd.Series(catb.feature_importances_, index=X_t.columns)\nfeat_importances.nlargest(15).plot(kind='barh')\n#feat_importances.nsmallest(20).plot(kind='barh')\nplt.show()","c442d1c0":"X_final = X_copy[col_1].copy()\ntest_final = test_copy[col_1].copy()","ff1389c7":"X_final.info()","0cfef51f":"test_final.info()","9ff320a8":"#  Cross validation strategy \n\n* best scores are obtained from catboost ","d3ccc4e9":"# Some key findings :\n* Males in general have better response rates\n* As the vehicle age increases response rate also increases\n* People having prior vehicle damage are more prone to respond as normally expected\n* People having prior insurance do not have a high response rate as expected \n* Driving License has a considerable error margin\n","6efa5628":"Dropping function due to eli5 Permutation Importance of Features","39a63618":"# Feature importance \/ Feature selection ","152f6329":"* Public leaderboard rank:\n* Private leaderboard rank:","f1ce22a4":"Keeping baseline score of all the stack : \n* Model          | CV  test score   | Leaderboard score\n* xgb_stacked : 0.8553    0.8563\n* lgb_stacked : 0.858    0.8573\n* cat_stacked : 0.85541   0.8559\n\n","bce0d1a4":"## Train data head","06baeb67":"# Preparing the data for training","610a2f46":"## Current Age\/ Vintage\/ Annual Premium distributions are not helping very much so we will try mean transformation","88d6dc47":"## Correlation Heatmap","e4e924ec":"Generate interactive features from the most important features","d12abbc2":"## Importing the libraries","af728f0f":"Cat boost gave the best CV score for train : 0.883 although the roc auc score is less for test 0.8554\n* The cat boost model is probably overfitting","4693f6d4":"### Around 12.26 % of customer have given a positive response","c0413e2a":"This function will drop the permutation features which have the weight < 0","e31c97e7":"- No missing values in the data. Will confirm the same using unique values","35536373":"* **As the vehicle age increases the response rate also increases** . ","3297b6b9":"Just a baseline submission check ","dbd26bbd":"# Interactive features","930c7328":"## Missing values check","023a02c8":"Annual_Premium showed interesting characteristics in the starting scatter plots","737f45fb":"# lets see the distribution of each category in the entire dataset","52962bc3":"Your client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n\nAn insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.\n\nFor example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000\/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000\/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n\nJust like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called \u2018sum assured\u2019) to the customer.\n\nBuilding a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue. \n\nNow, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.","d18b2e9c":"### we can see that the data is imbalanced classification, hence we will not use accuracy as scoring metric. Instead we will use f1-score or more preferrably roc-auc","46a78082":"* When the vehicle was not previously insured and sustained damage the response shows tremendous gain . Even more so when the vehicle range is at higher limits\n","20532cfa":"A point plot represents an estimate of central tendency for a numeric variable by the position of scatter plot points and provides some indication of the uncertainty around that estimate using error bars.\n\nPoint plots can be more useful than bar plots for focusing comparisons between different levels of one or more categorical variables. They are particularly adept at showing interactions: how the relationship between levels of one categorical variable changes across levels of a second categorical variable. The lines that join each point from the same hue level allow interactions to be judged by differences in slope, which is easier for the eyes than comparing the heights of several groups of points or bars.\n\n\n[Click here for info](https:\/\/seaborn.pydata.org\/generated\/seaborn.pointplot.html)"}}