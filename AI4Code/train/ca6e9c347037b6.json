{"cell_type":{"8a48deec":"code","fbeb520e":"code","b4b666ec":"code","1a614871":"code","85bb9962":"code","51cea925":"code","029f8934":"code","7c0c600f":"code","dbcd9dcb":"code","8dc7207b":"code","0bf64909":"code","5cd3c7fa":"code","d00a76e1":"code","4a238f5e":"code","80a970a0":"code","d20fc091":"code","5210a7d2":"code","191945f8":"code","f23700a0":"code","714fcd6b":"code","7653450b":"code","6f4a1793":"code","200d256f":"code","3ba0335c":"code","c6ab5e94":"code","ac9efc4d":"code","f4d96a8d":"code","37735567":"code","734a3f6e":"code","6cfe8fdf":"code","5d193bec":"code","54a84473":"code","55bb47a7":"code","476d7cb6":"code","bbedf218":"code","d690a601":"code","6350d82d":"code","fa7d510b":"code","928571ad":"code","4420bfb2":"code","52761906":"code","a58eedfd":"markdown","998d4e4b":"markdown","0cfd2083":"markdown","ad77381f":"markdown","572c29ec":"markdown","3015e35a":"markdown","2eb4a83f":"markdown","01cd0f80":"markdown","2bb5f028":"markdown","a6ccd082":"markdown","e8cad67a":"markdown","bb4a1c1c":"markdown","9ae15287":"markdown","96dd3094":"markdown","dafe3e6c":"markdown","29b6d540":"markdown","6c2cc52d":"markdown","0e4cc044":"markdown","16816cb8":"markdown","88467778":"markdown","91750c4a":"markdown","1c58be94":"markdown","d4f0ac6a":"markdown","9d0643f7":"markdown","58d99437":"markdown","7178a825":"markdown","d1febe77":"markdown","77cdadec":"markdown","0fe7427f":"markdown","b0e299c2":"markdown","ede43ef0":"markdown","c575e7bc":"markdown","b9294ce8":"markdown","f7f05443":"markdown","0b41ec04":"markdown","90485b38":"markdown","aeddddac":"markdown","239c738e":"markdown","e86fbad9":"markdown","cc72086a":"markdown","4ebe2d70":"markdown","36fc7e8b":"markdown","f943b5ea":"markdown","14b3103d":"markdown","f55f43a3":"markdown","900a4ae7":"markdown"},"source":{"8a48deec":"import os","fbeb520e":"import numpy as np\nimport pandas as pd\nimport scipy\nfrom scipy.stats import skew\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\nimport plotly\nimport plotly.graph_objects as go\n%matplotlib inline\nimport cv2\nimport pydicom\nimport glob\n# formatting libraries\nfrom colorama import Fore\nfrom tqdm import tqdm_notebook as tqdm\n\nimport gc","b4b666ec":"train = pd.DataFrame(pd.read_csv(\"..\/input\/osic-pulmonary-fibrosis-progression\/train.csv\"))\nprint(Fore.YELLOW+\"Shape Of Train Dataframe = \", train.shape)","1a614871":"train.head()","85bb9962":"train.info()","51cea925":"test = pd.DataFrame(pd.read_csv(\"..\/input\/osic-pulmonary-fibrosis-progression\/test.csv\"))\nprint(Fore.BLUE+\"Shape Of Testing Dataframe = \", test.shape)","029f8934":"test","7c0c600f":"unique_count = len(train[\"Patient\"].unique())\nprint(Fore.YELLOW+\"Number of unique entries out of 1549 overall record = \", unique_count)","dbcd9dcb":"train.head()","8dc7207b":"patient_ids = os.listdir(\"..\/input\/osic-pulmonary-fibrosis-progression\/train\")\nlen(os.listdir(\"..\/input\/osic-pulmonary-fibrosis-progression\/train\"))","0bf64909":"patient_ids[:5]","5cd3c7fa":"def create_custom_dataframe(df, directory) : \n    \n    unique_count = len(df[\"Patient\"].unique())\n    dataframe = pd.DataFrame(index = np.arange(unique_count), columns = [\"patient_id\", \"age\", \"sex\",\n                                                                             \"smoking_status\", \"num_of_scans_available\"])\n    patient_ids = os.listdir(directory)\n    \n    i = 0 \n    for patient_id in tqdm(patient_ids) : \n        subset_frame = df[df[\"Patient\"] == patient_id]\n        age = subset_frame[\"Age\"].values[0]\n        sex = subset_frame[\"Sex\"].values[0]\n        smoking_status = subset_frame[\"SmokingStatus\"].values[0]\n        num_of_scans_available = len(os.listdir(directory + patient_id))\n        \n        dataframe.iloc[i][\"patient_id\"] = patient_id\n        dataframe.iloc[i][\"age\"] = age\n        dataframe.iloc[i][\"sex\"] = sex\n        dataframe.iloc[i][\"smoking_status\"] = smoking_status\n        dataframe.iloc[i][\"num_of_scans_available\"] = num_of_scans_available\n        \n        i += 1\n    return dataframe","d00a76e1":"train_dataframe = create_custom_dataframe(train, directory = \"..\/input\/osic-pulmonary-fibrosis-progression\/train\/\")\ntest_dataframe = create_custom_dataframe(test, directory = \"..\/input\/osic-pulmonary-fibrosis-progression\/test\/\")\n\nprint(Fore.YELLOW +\"Shape of the TRAIN custom dataframe = \", train_dataframe.shape)\nprint(Fore.BLUE +\"Shape of the TEST custom dataframe = \", test_dataframe.shape)","4a238f5e":"train_dataframe.head()","80a970a0":"test_dataframe","d20fc091":"train_male_count = len(train_dataframe[train_dataframe[\"sex\"] == \"Male\"])\ntrain_female_count = len(train_dataframe[train_dataframe[\"sex\"] == \"Female\"])\n\ntest_male_count = len(test_dataframe[test_dataframe[\"sex\"] == \"Male\"])\ntest_female_count = len(test_dataframe[test_dataframe[\"sex\"] == \"Female\"])\n\nlabels = [\"Male\", \"Female\"]\nsize = [train_male_count, train_female_count]\nexplode = [0.1, 0.0]\n\nplt.figure(figsize = (16, 16))\nplt.subplot(1,2,1)\nplt.pie(size, labels = labels, explode = explode, shadow = True, startangle = 90, colors = [\"brown\", \"cyan\"])\nplt.title(\"Male VS Female Count - TRAIN\", fontsize = 18)\nplt.legend()\nprint(Fore.YELLOW+\"Number of males in training set = \", train_male_count)\nprint(Fore.BLUE+\"Numver of females in training set = \", train_female_count)\nprint(\"\\n\")\n\nsize = [test_male_count, test_female_count]\nplt.subplot(1,2,2)\nplt.pie(size, labels = labels, explode = explode, shadow = True, startangle = 90, colors = [\"brown\", \"cyan\"])\nplt.title(\"Male VS Female Count - TEST\", fontsize = 18)\nplt.legend()\nprint(Fore.YELLOW+\"Number of males in test set = \", test_male_count)\nprint(Fore.BLUE+\"Numbet of females in test set = \", test_female_count)","5210a7d2":"gc.collect()","191945f8":"train_dataframe[\"smoking_status\"].unique()","f23700a0":"train_ex_smoker = len(train_dataframe[train_dataframe[\"smoking_status\"] == \"Ex-smoker\"])\ntrain_never_smoked = len(train_dataframe[train_dataframe[\"smoking_status\"] == \"Never smoked\"])\ntrain_currently_smokes = len(train_dataframe[train_dataframe[\"smoking_status\"] == \"Currently smokes\"])\n\ntest_ex_smoker = len(test_dataframe[test_dataframe[\"smoking_status\"] == \"Ex-smoker\"])\ntest_never_smoked = len(test_dataframe[test_dataframe[\"smoking_status\"] == \"Never smoked\"])\ntest_currently_smokes = len(test_dataframe[test_dataframe[\"smoking_status\"] == \"Currently smokes\"])\n\nsize = [train_ex_smoker, train_never_smoked, train_currently_smokes]\nlabels = [\"Ex-smoker\", \"Never smoked\", \"Currently smokes\"]\nexplode = [0.1, 0.1, 0.0]\n\nplt.figure(figsize = (16, 16))\nplt.subplot(1,2,1)\nplt.pie(size, labels = labels, explode = explode, shadow = True, startangle = 90, colors = [\"lightblue\", \"darkgreen\", \"darkred\"],\n        autopct='%.2f')\nplt.title(\"Smoking Status - TRAIN\", fontsize = 18)\nplt.legend()\nprint(Fore.YELLOW+\"Ex-smoker count = \", train_ex_smoker)\nprint(Fore.YELLOW+\"Never smoked = \", train_never_smoked)\nprint(Fore.YELLOW+\"Currently smokes = \", train_currently_smokes)\nprint(\"\\n\")\n\nsize = [test_ex_smoker, test_never_smoked, test_currently_smokes]\nplt.subplot(1,2,2)\nplt.pie(size, labels = labels, explode = explode, shadow = True, startangle = 90, colors = [\"lightblue\", \"darkgreen\", \"darkred\"],\n       autopct='%.2f')\nplt.title(\"Smoking Status - TEST\", fontsize = 18)\nplt.legend()\nprint(Fore.BLUE+\"Ex-smoker count = \", test_ex_smoker)\nprint(Fore.BLUE+\"Never smoked = \", test_never_smoked)\nprint(Fore.BLUE+\"Currently smokes = \", test_currently_smokes)","714fcd6b":"scans_available_train = train_dataframe[\"num_of_scans_available\"].values","7653450b":"plt.figure(figsize = (12, 8))\nplt.subplot(1,1,1)\nsns.distplot(scans_available_train, kde = False, rug = False, color = \"darkgreen\")\nplt.ylabel(\"Scan Count\", fontsize = 12)\nplt.grid(True)\nplt.title(\"Scans Available - TRAIN\", fontsize = 16)","6f4a1793":"plt.figure(figsize = (10, 5))\nplt.subplot(1,1,1)\nsns.swarmplot(scans_available_train, size = 18, alpha = 0.4, color = \"gold\")\nplt.grid(True)\nplt.title(\"Bee Swarm Plot For Scans - TRAIN\", fontsize = 16) ","200d256f":"plt.figure(figsize = (10, 5))\nplt.subplot(1,1,1)\nsns.boxplot(scans_available_train, color = \"brown\")\nsns.swarmplot(scans_available_train, size = 14, alpha = 0.3, color = \"gold\")\nplt.grid(True)\nplt.title(\"Box Plot For Scans - TRAIN\", fontsize = 16) ","3ba0335c":"sex_versus_smoking_status = train_dataframe.groupby([\"sex\", \"smoking_status\"]).size()\nprint(sex_versus_smoking_status)\nprint(type(sex_versus_smoking_status))","c6ab5e94":"sex_versus_smoking_status = np.log(sex_versus_smoking_status.unstack(level = 1))\nprint(sex_versus_smoking_status)\nprint(type(sex_versus_smoking_status))","ac9efc4d":"sns.set(style = \"whitegrid\")\nsns.set_context(\"paper\", rc = {\"font.size\" : 12, \"axes.titlesize\" : 20, \"axes.labelsize\" : 18})\n\nplt.figure(figsize = (10, 6))\nsns.heatmap(sex_versus_smoking_status, annot = True, cmap = \"icefire\", cbar = True)\nplt.title(\"Sex VS Smoking Status - Log Analysis\", fontsize = 18)\nplt.tight_layout()","f4d96a8d":"train_male_scans = train_dataframe[train_dataframe[\"sex\"] == \"Male\"][\"num_of_scans_available\"].sum()\ntrain_female_scans = train_dataframe[train_dataframe[\"sex\"] == \"Female\"][\"num_of_scans_available\"].sum()\n\nx = [\"Male Scans\", \"Female Scans\"]\ny = [train_male_scans, train_female_scans]\n\nplt.figure(figsize = (12, 8))\nplt.subplot(1,1,1)\nplt.bar(x, y, color = \"r\")\nplt.grid(True)\nplt.title(\"Total Scans Available - TRAIN\", fontsize = 16)","37735567":"def load_scan(path) :\n    files = os.listdir(path)\n    file_numbers = []\n    for file in files :\n        file_numbers.append(np.int(file.split(\".\")[0]))\n    file_numbers.sort(reverse = True)\n    file_numbers = np.array(file_numbers)\n    \n    slices = []\n    for number in file_numbers :\n        read_dicom_file = pydicom.dcmread(path + \"\/\" + str(number) + \".dcm\")\n        slices.append(read_dicom_file)\n    \n    return slices","734a3f6e":"train.head(2)","6cfe8fdf":"sample_path = \"..\/input\/osic-pulmonary-fibrosis-progression\/train\/\"+ train.Patient.values[0]\nslices = load_scan(sample_path)\n\nprint(slices[0])","5d193bec":"print(Fore.YELLOW+\"Number of slices available = {}\".format(len(slices)))","54a84473":"plt.figure(figsize = (15, 8))\nfor i in range(30) : \n    image = slices[i].pixel_array.flatten()\n    image = image * slices[i].RescaleSlope + slices[i].RescaleIntercept\n    sns.distplot(image.flatten(), kde = True, hist = True)\nplt.title(\"Distribution in Hounsfield Units\", fontsize = 18); # ; to suppress the text output","55bb47a7":"def transform_to_hu(slices) : \n    scan_collection = []\n    for scan in slices : \n        scan_collection.append(scan.pixel_array)\n    scan_collection = np.stack(scan_collection)\n    scan_collection = scan_collection.astype(np.int16)\n    # setting everything outside to air.\n    scan_collection[scan_collection <= -1000] = 0 \n    \n    for i in range(len(slices)) : \n        scan_collection[i] = slices[i].RescaleSlope * scan_collection[i].astype(np.float64)\n        scan_collection[i] = scan_collection[i].astype(np.int16)\n        scan_collection[i] = scan_collection[i] + np.int16(slices[i].RescaleIntercept)\n    return np.array(scan_collection, dtype = np.int16)   ","476d7cb6":"scan_collection = transform_to_hu(slices)","bbedf218":"print(Fore.CYAN+\"Shape Of the scan_collection tensor = \",scan_collection.shape)","d690a601":"plt.figure(figsize = (30, 20))\n\nplt.subplot(3, 2, 1)\nplt.imshow(slices[0].pixel_array, cmap = plt.cm.bone)\nplt.title(\"Original CT-Scan\", fontsize = 18)\nplt.grid(False)\n\nplt.subplot(3, 2, 2)\nsns.distplot(slices[0].pixel_array.flatten(), kde = True, hist = True)\nplt.title(\"Pixel Array Distribution\", fontsize = 18)\nplt.grid(True)\n\nplt.subplot(3, 2, 3)\nplt.imshow(scan_collection[0], cmap = plt.cm.bone)\nplt.title(\"CT-Scan in HU\", fontsize = 18)\nplt.grid(False)\n\nplt.subplot(3, 2, 4)\nsns.distplot(scan_collection[0].flatten(), kde = True, hist = True)\nplt.title(\"Housfield Value Distribution\", fontsize = 18)\nplt.grid(True)","6350d82d":"turbo_colormap_data = [[0.18995,0.07176,0.23217],[0.19483,0.08339,0.26149],[0.19956,0.09498,0.29024],[0.20415,0.10652,0.31844],[0.20860,0.11802,0.34607],[0.21291,0.12947,0.37314],[0.21708,0.14087,0.39964],[0.22111,0.15223,0.42558],[0.22500,0.16354,0.45096],[0.22875,0.17481,0.47578],[0.23236,0.18603,0.50004],[0.23582,0.19720,0.52373],[0.23915,0.20833,0.54686],[0.24234,0.21941,0.56942],[0.24539,0.23044,0.59142],[0.24830,0.24143,0.61286],[0.25107,0.25237,0.63374],[0.25369,0.26327,0.65406],[0.25618,0.27412,0.67381],[0.25853,0.28492,0.69300],[0.26074,0.29568,0.71162],[0.26280,0.30639,0.72968],[0.26473,0.31706,0.74718],[0.26652,0.32768,0.76412],[0.26816,0.33825,0.78050],[0.26967,0.34878,0.79631],[0.27103,0.35926,0.81156],[0.27226,0.36970,0.82624],[0.27334,0.38008,0.84037],[0.27429,0.39043,0.85393],[0.27509,0.40072,0.86692],[0.27576,0.41097,0.87936],[0.27628,0.42118,0.89123],[0.27667,0.43134,0.90254],[0.27691,0.44145,0.91328],[0.27701,0.45152,0.92347],[0.27698,0.46153,0.93309],[0.27680,0.47151,0.94214],[0.27648,0.48144,0.95064],[0.27603,0.49132,0.95857],[0.27543,0.50115,0.96594],[0.27469,0.51094,0.97275],[0.27381,0.52069,0.97899],[0.27273,0.53040,0.98461],[0.27106,0.54015,0.98930],[0.26878,0.54995,0.99303],[0.26592,0.55979,0.99583],[0.26252,0.56967,0.99773],[0.25862,0.57958,0.99876],[0.25425,0.58950,0.99896],[0.24946,0.59943,0.99835],[0.24427,0.60937,0.99697],[0.23874,0.61931,0.99485],[0.23288,0.62923,0.99202],[0.22676,0.63913,0.98851],[0.22039,0.64901,0.98436],[0.21382,0.65886,0.97959],[0.20708,0.66866,0.97423],[0.20021,0.67842,0.96833],[0.19326,0.68812,0.96190],[0.18625,0.69775,0.95498],[0.17923,0.70732,0.94761],[0.17223,0.71680,0.93981],[0.16529,0.72620,0.93161],[0.15844,0.73551,0.92305],[0.15173,0.74472,0.91416],[0.14519,0.75381,0.90496],[0.13886,0.76279,0.89550],[0.13278,0.77165,0.88580],[0.12698,0.78037,0.87590],[0.12151,0.78896,0.86581],[0.11639,0.79740,0.85559],[0.11167,0.80569,0.84525],[0.10738,0.81381,0.83484],[0.10357,0.82177,0.82437],[0.10026,0.82955,0.81389],[0.09750,0.83714,0.80342],[0.09532,0.84455,0.79299],[0.09377,0.85175,0.78264],[0.09287,0.85875,0.77240],[0.09267,0.86554,0.76230],[0.09320,0.87211,0.75237],[0.09451,0.87844,0.74265],[0.09662,0.88454,0.73316],[0.09958,0.89040,0.72393],[0.10342,0.89600,0.71500],[0.10815,0.90142,0.70599],[0.11374,0.90673,0.69651],[0.12014,0.91193,0.68660],[0.12733,0.91701,0.67627],[0.13526,0.92197,0.66556],[0.14391,0.92680,0.65448],[0.15323,0.93151,0.64308],[0.16319,0.93609,0.63137],[0.17377,0.94053,0.61938],[0.18491,0.94484,0.60713],[0.19659,0.94901,0.59466],[0.20877,0.95304,0.58199],[0.22142,0.95692,0.56914],[0.23449,0.96065,0.55614],[0.24797,0.96423,0.54303],[0.26180,0.96765,0.52981],[0.27597,0.97092,0.51653],[0.29042,0.97403,0.50321],[0.30513,0.97697,0.48987],[0.32006,0.97974,0.47654],[0.33517,0.98234,0.46325],[0.35043,0.98477,0.45002],[0.36581,0.98702,0.43688],[0.38127,0.98909,0.42386],[0.39678,0.99098,0.41098],[0.41229,0.99268,0.39826],[0.42778,0.99419,0.38575],[0.44321,0.99551,0.37345],[0.45854,0.99663,0.36140],[0.47375,0.99755,0.34963],[0.48879,0.99828,0.33816],[0.50362,0.99879,0.32701],[0.51822,0.99910,0.31622],[0.53255,0.99919,0.30581],[0.54658,0.99907,0.29581],[0.56026,0.99873,0.28623],[0.57357,0.99817,0.27712],[0.58646,0.99739,0.26849],[0.59891,0.99638,0.26038],[0.61088,0.99514,0.25280],[0.62233,0.99366,0.24579],[0.63323,0.99195,0.23937],[0.64362,0.98999,0.23356],[0.65394,0.98775,0.22835],[0.66428,0.98524,0.22370],[0.67462,0.98246,0.21960],[0.68494,0.97941,0.21602],[0.69525,0.97610,0.21294],[0.70553,0.97255,0.21032],[0.71577,0.96875,0.20815],[0.72596,0.96470,0.20640],[0.73610,0.96043,0.20504],[0.74617,0.95593,0.20406],[0.75617,0.95121,0.20343],[0.76608,0.94627,0.20311],[0.77591,0.94113,0.20310],[0.78563,0.93579,0.20336],[0.79524,0.93025,0.20386],[0.80473,0.92452,0.20459],[0.81410,0.91861,0.20552],[0.82333,0.91253,0.20663],[0.83241,0.90627,0.20788],[0.84133,0.89986,0.20926],[0.85010,0.89328,0.21074],[0.85868,0.88655,0.21230],[0.86709,0.87968,0.21391],[0.87530,0.87267,0.21555],[0.88331,0.86553,0.21719],[0.89112,0.85826,0.21880],[0.89870,0.85087,0.22038],[0.90605,0.84337,0.22188],[0.91317,0.83576,0.22328],[0.92004,0.82806,0.22456],[0.92666,0.82025,0.22570],[0.93301,0.81236,0.22667],[0.93909,0.80439,0.22744],[0.94489,0.79634,0.22800],[0.95039,0.78823,0.22831],[0.95560,0.78005,0.22836],[0.96049,0.77181,0.22811],[0.96507,0.76352,0.22754],[0.96931,0.75519,0.22663],[0.97323,0.74682,0.22536],[0.97679,0.73842,0.22369],[0.98000,0.73000,0.22161],[0.98289,0.72140,0.21918],[0.98549,0.71250,0.21650],[0.98781,0.70330,0.21358],[0.98986,0.69382,0.21043],[0.99163,0.68408,0.20706],[0.99314,0.67408,0.20348],[0.99438,0.66386,0.19971],[0.99535,0.65341,0.19577],[0.99607,0.64277,0.19165],[0.99654,0.63193,0.18738],[0.99675,0.62093,0.18297],[0.99672,0.60977,0.17842],[0.99644,0.59846,0.17376],[0.99593,0.58703,0.16899],[0.99517,0.57549,0.16412],[0.99419,0.56386,0.15918],[0.99297,0.55214,0.15417],[0.99153,0.54036,0.14910],[0.98987,0.52854,0.14398],[0.98799,0.51667,0.13883],[0.98590,0.50479,0.13367],[0.98360,0.49291,0.12849],[0.98108,0.48104,0.12332],[0.97837,0.46920,0.11817],[0.97545,0.45740,0.11305],[0.97234,0.44565,0.10797],[0.96904,0.43399,0.10294],[0.96555,0.42241,0.09798],[0.96187,0.41093,0.09310],[0.95801,0.39958,0.08831],[0.95398,0.38836,0.08362],[0.94977,0.37729,0.07905],[0.94538,0.36638,0.07461],[0.94084,0.35566,0.07031],[0.93612,0.34513,0.06616],[0.93125,0.33482,0.06218],[0.92623,0.32473,0.05837],[0.92105,0.31489,0.05475],[0.91572,0.30530,0.05134],[0.91024,0.29599,0.04814],[0.90463,0.28696,0.04516],[0.89888,0.27824,0.04243],[0.89298,0.26981,0.03993],[0.88691,0.26152,0.03753],[0.88066,0.25334,0.03521],[0.87422,0.24526,0.03297],[0.86760,0.23730,0.03082],[0.86079,0.22945,0.02875],[0.85380,0.22170,0.02677],[0.84662,0.21407,0.02487],[0.83926,0.20654,0.02305],[0.83172,0.19912,0.02131],[0.82399,0.19182,0.01966],[0.81608,0.18462,0.01809],[0.80799,0.17753,0.01660],[0.79971,0.17055,0.01520],[0.79125,0.16368,0.01387],[0.78260,0.15693,0.01264],[0.77377,0.15028,0.01148],[0.76476,0.14374,0.01041],[0.75556,0.13731,0.00942],[0.74617,0.13098,0.00851],[0.73661,0.12477,0.00769],[0.72686,0.11867,0.00695],[0.71692,0.11268,0.00629],[0.70680,0.10680,0.00571],[0.69650,0.10102,0.00522],[0.68602,0.09536,0.00481],[0.67535,0.08980,0.00449],[0.66449,0.08436,0.00424],[0.65345,0.07902,0.00408],[0.64223,0.07380,0.00401],[0.63082,0.06868,0.00401],[0.61923,0.06367,0.00410],[0.60746,0.05878,0.00427],[0.59550,0.05399,0.00453],[0.58336,0.04931,0.00486],[0.57103,0.04474,0.00529],[0.55852,0.04028,0.00579],[0.54583,0.03593,0.00638],[0.53295,0.03169,0.00705],[0.51989,0.02756,0.00780],[0.50664,0.02354,0.00863],[0.49321,0.01963,0.00955],[0.47960,0.01583,0.01055]]","fa7d510b":"plt.figure(figsize = (20, 12))\nplt.imshow(scan_collection[0], cmap=ListedColormap(turbo_colormap_data))\nplt.grid(False)\nplt.title(\"CT-Scanned HU Image in TURBO\", fontsize = 18) ; ","928571ad":"sample_image = scan_collection[0]\n\nplt.figure(figsize = (16, 10))\nplt.subplot(2,2,1)\nplt.imshow(sample_image, cmap = \"jet\")\nplt.grid(False)\nplt.title(\"JET Colormap\", fontsize = 16)\n\nplt.subplot(2,2,2)\nplt.imshow(sample_image, cmap = \"viridis\")\nplt.grid(False)\nplt.title(\"VIRIDIS Colormap\", fontsize = 16)\n\nplt.subplot(2,2,3)\nplt.imshow(sample_image, cmap = \"inferno\")\nplt.grid(False)\nplt.title(\"INFERNO Colormap\", fontsize = 16)\n\nplt.subplot(2,2,4)\nplt.imshow(sample_image, cmap = ListedColormap(turbo_colormap_data))\nplt.grid(False)\nplt.title(\"TURBO Colormap\", fontsize = 16)\n\nplt.tight_layout()","4420bfb2":"print(slices[0])","52761906":"\"\"\"\ndef extract_information(location_of_images) : \n    image_statistics = pd.DataFrame(index = np.arange(len(location_of_images)), \n                                   columns = [\"image path\", \"rows\", \"columns\", \"image_mean\", \n                                              \"image_standard_deviation\", \"image_skewness\",\n                                             \"mean_red_value\", \"mean_green_value\", \"mean_blue_value\"])\n    i = 0 \n    for path in tqdm(location_of_images) : \n        image = pydicom.dcmread(path)\n        image_statistics.iloc[i][\"image_path\"] = path\n        image_statistics,iloc[i][\"rows\"] = image.shape[0]\n        image_statistics.iloc[i][\"columns\"] = image.shape[1]\n        image_statistics.iloc[i][\"image_mean\"] = np.mean(image)\n        image_statistics.iloc[i][\"image_standard_deviation\"] = np,std(image)\n        image_statistics.iloc[i][\"image_skewness\"] = skew(image)\n\"\"\"","a58eedfd":"# Analyzing Distribution","998d4e4b":"We can observe that the circular boundary has been correctly scaled. Note that it's not vanished magically!! It's still there. Just color corrected...one might presume.","0cfd2083":"Hence, the custom dataframe creation is complete. Now, we have a subset of attributes corresponding to each patient ID without duplicate IDs repeating incessantly. Number of scans per ID are also made available in this dataframe.","ad77381f":"Let's observe the number of unique patients we have out of 1549 overall entries.","572c29ec":"# OSIC Pulmonary Fibrosis Progression\n\n![image.png](attachment:image.png)\n\n## Book One - Exploratory Data Analysis (EDA)","3015e35a":"The values indicate the overall percentage of that fraction. So, we can see that our data is dominated a lot by Ex-smoker entries, followed by never smoked ones! ","2eb4a83f":"# Loading Mandatory Files","01cd0f80":"## Scans Available : ","2bb5f028":"## Observing the difference with colormap choice\n\n**JET V VIRIDIS V INFERNO V TURBO**","a6ccd082":"We can see that the initial attributes such as UID, X-ray tube current, image position, orientation and so on..largely depends upon the working condition and the eqipment setup. The more powerful attributes having a stronger imapact are in the second half.","e8cad67a":"So, we have the IDs corresponding to each patient now. Let's display the first five entries.","bb4a1c1c":"Let's observe hown many categories are there in this column.","9ae15287":"So, the data is biased when analyzed from gender point of view. It's evident that not even 25% of total IDs corresponds to females, in the training set.","96dd3094":"We can see both JET and Turbo aids us in properly visualizing the scan by, illuminating even the darkest corners. Of course,, we have the bone map too from before. We will keep this insight as a potential reminder for the upcoming visualziation.","dafe3e6c":"*This cannot go before thanking the Kaggle community for clearing many doubts! Thank you all so much. I complied my learning into this EDA, and hope that this will be helpful to all range of audience here*.\n\nThe ideas on processing dicoms are inspired by this **titan level** tutorial :\n\n* **https:\/\/www.kaggle.com\/gzuidhof\/full-preprocessing-tutorial** || Do give it a shot post reading this notebook!\n","29b6d540":"Again, a disbalance we observe. Female scans are way too less when compared to males.","6c2cc52d":"picking a random image","0e4cc044":"**Hounsfield Units** : \n\nIs a quantitative scale for describing radiodensity. It is frequently used in CT scans, where its value is also termed CT number. Various Hounsfield Units are listed in the table below : \n\n![image.png](attachment:image.png) \n\nNext function will convert the voxel values to Hounsfield Units. *Before that, let's have a look at the metadata again*.","16816cb8":"Visualize few images from the scan_collection.","88467778":"An interesting point over here is to realize that though we have an OVERALL majority of *ex-smokers* in the training data, and this is reflected as *ex-smokers males* are dominant, however in females *never smoked* category is the dominant one.","91750c4a":"## Sex VS Smoking Status : ","1c58be94":"Inference : \n* The distribution of the histogram of scans available is negatively skewed. We see that people having scans of about 0-100 are quite high. More than 80.\n* As number of scans increases, the number of patients decreases. ","d4f0ac6a":"Colorama provides a simple cross-platform API to print colored terminal text from Python applications. It's useful for projecting results in a visually appealing manner. ","9d0643f7":"This is great, as we don't have any missing values! Let's analyze for the test set also.","58d99437":"let's once again load the dicom attributes and analyze a few of them.","7178a825":"Two extremely important things over here are the **third last and second last tag**, that is \n* Rescale slope\n* Rescale Intercept\n\n*********************************************\n**Extracted from StackOverFlow : https:\/\/stackoverflow.com\/questions\/10193971\/rescale-slope-and-rescale-intercept** : \n\n*The rescale slope and rescale intercept allow to transform the pixel values to HU or other units, as specified in the tag 0028,1054*.\n\n*For CT images, the unit should be HU (Hounsfield) **and the default value is indeed HU** when the tag 0028,1054 is not present. However, the tag may be present and may specify a different unit (OD=optical density, US=unspecified)*.\n\n*The rescale slope and intercept are determined by the manufacturer of the hardware*.\n********************************************\n**Extracted from A Coyote's Guide To IDL Programming : http:\/\/www.idlcoyote.com\/fileio_tips\/hounsfield.html**\n\nTo convert from the normal units found in CT data (a typical data set ranges from 0 to 4000 or so) you have to apply a linear transformation of the data. The equation is:\n\n`hu = pixel_value * slope + intercept`\n\n********************************************","d1febe77":"## Histogram Plots : \n\nMost common way to gain insights into 1-D data is through Histogram plots. When dealing with a set of data, often the first thing you\u2019ll want to do is get a sense for how the variables are distributed. The most convenient way to take a quick look at a univariate distribution in seaborn is the **distplot() function**. ","77cdadec":"Loading attribute for the first slice.","0fe7427f":"# Image EDA and Analysis","b0e299c2":"Now, this is much more informative. Let's see first a boxplot is all about. \n\nThere appears only one prominent peak, and this agrees with the histogram plot before. Maximum patient fall into category of those having 0-200 scans per person. \n\n****************************\n\n## BoxPlot : \n\n![image.png](attachment:image.png) \n\nA boxplot is all about **quartiles, which are a way of recording how our data is distributed**. A boxplot will have **25% line as the base line of the box, 50% line somewhere inside the box and the top edge of the box refers to the 75% line**. \n\nIn other words, **25% data is below the base line of the boxplot, and 75% is above the top edge**. This helps us in analyzing the spread and skewness of the data distribution.\n\n* So, the mid line is the 50% line denoting the mean.\n* Size of the box conveys how spread out the data is!\n\n**Combining it with bee-swarm plot dynamically increases visual appeal for ease of analysis**.\n\n## The Top Line Of The BoxPlot - Not The Box\n\nWe can see outside the box there appears to be a prominent line, some distance below and above the box(*here right and left as the box is plot is horizontal*). This normally upper (*here right*) gap is actually **1.5 X Interquartile range**, where interqaurtile range is the distance between the 75% mark and 25% mark. \n\n* The points crossing the upper and lower lines are **outliers**.\n\nThis gap can be controlled via a keyword called **whis** in seaborn. By default it is 1.5\n\n## So, what's the downside of a boxplot?\n\nWell, if we carefully see, a boxplots condenses our distribution into **5 values**. The lower and upper ends (between the outliers) and the three inside the box(25%, mean and 75% marks). So, in a way we are losing information.\n\n`Boxplot are primarily useful when we want to compare several distributions`. \n\n## A much better plot to use is a VIOLIN PLOT. \n\nHowever, here our purpose is served.","ede43ef0":"## Effect of colormaps - Taken from Google AI Blog\n\nColorizing images helps the human visual system pick out detail, estimate quantitative values, and notice patterns in data in a more intuitive fashion. However, the choice of color map can have a significant impact on a given task. For example, interpretation of \u201crainbow maps\u201d have been linked to lower accuracy in mission critical applications, such as medical imaging. Still, **in many applications, \u201crainbow maps\u201d are preferred since they show more detail (at the expense of accuracy) and allow for quicker visual assessment**. \n\n![image.png](attachment:image.png) \n\n**You can read the article below or get more info at : https:\/\/ai.googleblog.com\/2019\/08\/turbo-improved-rainbow-colormap-for.html**\n\n***************************\n\nOne of the most commonly used color mapping algorithms in computer vision applications is Jet, which is high contrast, making it useful for accentuating even weakly distinguished image features. However, if you look at the color map gradient, one can see distinct \u201cbands\u201d of color, most notably in the cyan and yellow regions. This causes sharp transitions when the map is applied to images, which are misleading when the underlying data is actually smoothly varying. \n\nToday there are many modern alternatives that are uniform and color blind accessible, such as Viridis or Inferno from matplotlib. While these linear lightness maps solve many important issues with Jet, their constraints may make them suboptimal for day to day tasks where the requirements are not as stringent.\n\n****************************","c575e7bc":"## Sex Distribution : ","b9294ce8":"Each of these IDs encapsulates the CT scans of that patient, over a span of time commencing from week 0.","f7f05443":"## Analyze the pixel_array values, for the images in slices[0] (for sample).","0b41ec04":"## Smoking Status :","90485b38":"Let's prepare a dataframe encapsulating all the important information about the images. We will save this as .csv and use it as an external data set source. ","aeddddac":"Though a beeswarm plot lack the **scientific rigor** of other plots, however they are good for visualization purposes, especially those in **categorical feature sections**. We did that with pie chart as all the necessary was conveyed through it. BeeSwarm was another alternative to that.\n\nThis can be made more informative using a 1-D BoxPlot.","239c738e":"# Custom DataFrame Creation\n\nIn order to perform EDA relatively more easily, let's create a custom dataframe having attributes corresponding to each patient. \n\n**How is it different from the original one?**\n\n*This dataframe will only have the Age, sex and smoking status attribute corresponding to each person. Using this way we will analyze the distribution of patients centered around these attributes. Analysis of CT Scans will be done later in the notebook.*","e86fbad9":"No missing values either!","cc72086a":"## Image - 3-D analysis","4ebe2d70":"## Sex VS Scans Available : ","36fc7e8b":"## Turbo Colormap : \n\nThe usage can be found here after that amazing Google AI blog.\n\n**https:\/\/gist.github.com\/mikhailov-work\/ee72ba4191942acecc03fe6da94fc73f**","f943b5ea":"The negative 3000 value is most probably air, or whatever is outside of the circular zone in which the image is captured in a CT-scan.\n\nIn the chart of HU pasted above, it's pretty evident that air starts from -1000. ","14b3103d":"Now, we can more clearly see the spaces too! It's good for visual inspection.","f55f43a3":"## Understanding DICOM images for CT Scans : \n\n* Standard way of representing medical images.\n* The unit of measurement in CT medical scans is the Hounsfield Unit (HU), which is a measure of radiodensity\n* Apart from the images, just like tfRecords, a lot of metadata can be encapsulated in a .dcm file format.\n* pydicom Python3 module was made for inspecting and modifying DICOM data in an easy \"pythonic\" way.\n* DICOM groups information into data sets. For example, a file of a chest x-ray image may contain the patient ID within the file, so that the image can never be separated from this information by mistake.\n* A DICOM data object consists of a number of attributes, including items such as name, ID, etc., and also one special attribute containing the image pixel data. \n\n`There are so many gray level values in a CT Scan(in thousands) that it is nearly impossible for us to capture them through naked eyes! Hence, in order to extract meaningful information, we display the image in HU range that suits our current interest. For example we may set a range to view bones, and another to view tissues`.","900a4ae7":"We have several scans for each patient. For a particular ID, we will analyze all the `.dcm` images available. For this, the load_scan( ) function is written.\n\nEach scan is referred to as a `slice` in popularly used CT terminology. \n\nRemember the scanner scans the patient from different positions. Hence, in order to load the full scan of a person, we ought to rearrange everything by ImagePosition attribute, embedded in the dicoms.\n\n__________________________\n\nSo, now in the `load function` we will : \n* Input a directory as the argument 'path'.\n* Inside a directory, we will have many .dcm files corresponding to a patient. For e.g. 1.dcm, 2.dcm and so on... depending on the directory ID of the person we supplied.\n* Let's store all these files under the tag file_numbers. This will be arranged from the most recent number to the oldest one.\n* Now, we will read these files as stored, that is the latest scan first, followed by the previous ones. All these dicom files will be read using pydicom Python3 module, and will be appended to a list named `slices`. \n* Ultimately, the list `slices` will be returned."}}