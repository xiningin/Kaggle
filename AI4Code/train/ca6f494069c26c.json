{"cell_type":{"0c02d32b":"code","1c8710dc":"code","e89542a2":"code","4eecf64b":"code","34fcd2a2":"code","1a4e9c62":"code","83940900":"code","777d6172":"code","cbc45196":"code","74b12df7":"code","76fd2e4e":"code","4f061609":"code","95635b83":"code","075165d1":"markdown","5651f34d":"markdown","0a5b2626":"markdown","6c1d3964":"markdown","0a4bd2bc":"markdown","f21470d3":"markdown","ed0bbea7":"markdown","ca4636db":"markdown","e00630a2":"markdown","55b7a533":"markdown","61c204fa":"markdown","3c8a9715":"markdown"},"source":{"0c02d32b":"# Imports\nimport os\nimport numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport matplotlib.pyplot as plt\nimport pandas as pd\n!pip install opencv-python\nimport cv2","1c8710dc":"# Get a list with all the image paths. The dataset parameter defines if you want to load training or test images.\ndef data_importer(directory, dataset):\n    list_directories = []\n    for dirname, _, filenames in os.walk(directory):\n        if dirname.split(\"\/\")[-1] == dataset: \n            for filename in filenames:\n                list_directories.append(os.path.join(dirname, filename))\n        \n    return list_directories\n","e89542a2":"dataset_directory = '\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection'\n\ntrain_paths = data_importer(dataset_directory,\"train\")\n\nprint(\"Total files found: \", len(train_paths))","4eecf64b":"# Read dicom data into np.array\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data\n","34fcd2a2":"# Read one image to check the loading is OK\nimg = read_xray(train_paths[0])\nplt.figure(figsize = (10,10))\nplt.imshow(img, 'gray')\nplt.axis(\"Off\")","1a4e9c62":"# Create a dataframe containing the training data\ncsv_path = '\/kaggle\/input\/vinbigdata-chest-xray-abnormalities-detection\/train.csv'\ndf = pd.read_csv(csv_path)","83940900":"# Getting the first 5 elements of the dataframe\ndf.head()","777d6172":"# method to plot images with its annotations\ndef plot_annotations(df_item, path, hide_axis = False, predicted_df_item = None):\n    \n    # Convert the x-ray image into RGB\n    img = cv2.cvtColor(read_xray(os.path.join(path, \"{}.dicom\".format(df_item[\"image_id\"]))),cv2.COLOR_GRAY2RGB)\n    \n    if (np.isnan(df_item[\"x_min\"]) and np.isnan(df_item[\"y_min\"])):\n        return print(\"No detection found!\")\n    \n    # Declare coordinates and convert them to integers\n    x_min = int(df_item[\"x_min\"])\n    y_min = int(df_item[\"y_min\"])\n    x_max = int(df_item[\"x_max\"])\n    y_max = int(df_item[\"y_max\"])\n\n    # Create figure\n    plt.figure(figsize = (10,10))\n    \n    # Create rectangle where the annotation is located\n    image = cv2.rectangle(img=img,rec=(x_min,y_min,x_max-x_min,y_max-y_min), color = (0,255,0),thickness = 10)\n    \n    # Add label to the annotation\n    image = cv2.putText(image, df_item[\"class_name\"], (int(df_item[\"x_min\"]),int(df_item[\"y_min\"])), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,0), 3)\n    \n    if predicted_df_item is not None:\n        \n        if not ((np.isnan(predicted_df_item[\"x_min\"])) and (np.isnan(predicted_df_item[\"y_min\"]))):\n\n            # Declare coordinates and convert them to integers\n            pred_x_min = int(predicted_df_item[\"x_min\"])\n            pred_y_min = int(predicted_df_item[\"y_min\"])\n            pred_x_max = int(predicted_df_item[\"x_max\"])\n            pred_y_max = int(predicted_df_item[\"y_max\"])\n\n            # Create rectangle where the annotation is located\n            image = cv2.rectangle(img=img,rec=(pred_x_min,pred_y_min,pred_x_max-pred_x_min,pred_y_max-pred_y_min), color = (0,0,255),thickness = 10)\n\n            # Add label to the annotation\n            image = cv2.putText(image, \"pred: {}\".format(predicted_df_item[\"class_name\"]), (int(predicted_df_item[\"x_min\"]),int(predicted_df_item[\"y_min\"])), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,0), 3)\n        else:\n            print(\"No detection found for prediction!\")\n                \n    # Plot image\n    plt.imshow(image)\n    \n    # Select if axis should be hidden\n    if hide_axis:\n        plt.axis(\"Off\")\n    plt.show()\n    ","cbc45196":"# Plot the 3rd dataset item\n\ntrain_directory = os.path.join(dataset_directory, \"train\")\nplot_annotations(df.iloc[3],train_directory, True)","74b12df7":"# Compare the 3rd dataset item with the 2nd\n\ntrain_directory = os.path.join(dataset_directory, \"train\")\nplot_annotations(df.iloc[3],train_directory, True,df.iloc[2])","76fd2e4e":"# Get the image ids without repetitions\nimage_ids = df.image_id.unique()\n\n# Select all annotations corresponding to the first image\nimage_annotations = df.loc[df['image_id'].isin([image_ids[52]])]\n\nimage_annotations","4f061609":"# method to plot images with its annotations\ndef plot_all_labels(df_item, path, hide_axis = False):\n    # Convert the x-ray image into RGB\n    image = cv2.cvtColor(read_xray(os.path.join(path, \"{}.dicom\".format(df_item.iloc[1][\"image_id\"]))),cv2.COLOR_GRAY2RGB)\n    \n    # Create figure\n    plt.figure(figsize = (10,10))\n    plt.title(\"Image ID - {}\".format(df_item.iloc[1][\"image_id\"]))\n    \n    for index,item in df_item.iterrows():\n        \n        if (np.isnan(item[\"x_min\"]) and np.isnan(item[\"y_min\"])):\n            continue\n\n        # Declare coordinates and convert them to integers\n        x_min = int(item[\"x_min\"])\n        y_min = int(item[\"y_min\"])\n        x_max = int(item[\"x_max\"])\n        y_max = int(item[\"y_max\"])\n\n        # Create rectangle where the annotation is located\n        image = cv2.rectangle(img=image,rec=(x_min,y_min,x_max-x_min,y_max-y_min), color = (0,255,0),thickness = 10)\n\n        # Add label to the annotation\n        image = cv2.putText(image, item[\"class_name\"], (int(item[\"x_min\"]),int(item[\"y_min\"])), cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(0,0,0), thickness=3)\n\n                \n    # Plot image\n    plt.imshow(image)\n    \n    # Select if axis should be hidden\n    if hide_axis:\n        plt.axis(\"Off\")\n    plt.show()","95635b83":"plot_all_labels(image_annotations, train_directory, hide_axis = True)","075165d1":"## Importing the data\n\nThe *data_importer* method is used to get a list with the directories of all the images within a directory.\n\n**Parameters**: \n* directory: path where the test and training directories are located\n* dataset: \"train\" for trainin data, \"test\" for test data\n\n* it returns a list of strings containing the paths where the images are located","5651f34d":"## Plot one annotation\n","0a5b2626":"From the loaded dataframe we are going to use the information stored in the **class_name** column to label the detection bounding box.\n\nThen, we are going to use the **x_min** and **y_min** values to determine the upper left corner of the annotation bounding box, and the **x_max** and **y_max** to place the lower right corner of the bounding box.","6c1d3964":"## Importing dicom data\n\nThe *read_xray* function will help us to load dicom image data as np.arrays, this will allow us to work in a more confortable way with images and compute operations more efficiently. This function is taken from the notebook https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n","0a4bd2bc":"# Plot Label Bounding Boxes\n\nThis is a helper script containing simple methods for ploting the label bounding boxes on the X-Ray chest images.\n\nIn the first place we are going to load the x-ray images, then load the csv file containing the labels, and finally put it all together in the same plot.\nIf you are new to python I recommend you follow the steps, but if you have quite some experience just jump straight to the last method!\n\nSee the final result:\n\n\n### Plot all the anotations corresponding to the same image\n\n![image.png](attachment:image.png)","f21470d3":"This is how the method is called:","ed0bbea7":"Now we can see how a sample image looks like","ca4636db":"## Plot all the anotations corresponding to the same image\n\nThis is the method we have all waited for!!\n\nThe *plot_all_labels* method will allow us to plot several annotations corresponding to the same x-ray in the same image. \n\nFor that, we need to extract the all the the labels corresponding to each image.\n\nWith the *.unique()* call we are obtaining the unique image ids from the dataframe. Next, using the *.isin()* method we are getting all the annotations corresponding to one exact image.","e00630a2":"## Plot the annotations\n\n**This are the important methods!!**\n\nFirst let's plot the annotations just one by one, one dataframe item at a time\n\nThe method *plot_annotations* has as input:\n* df_item: a dataframe item\n* path: the image dataset path\n* hide_axis: a boolean to state whether to plot the image axis\n* predicted_df_item: second dataframe item in case the user wants to compare two annotations on the first item's image.\n\nThis method will come handy at any point of the process as it will allow us to visilize the annotations on top of the image, and compare the predictions with the ground truths.","55b7a533":"The method *plot_all_labels* has as input:\n* df_item: is the dataframe containing al the annotations corresponding to one image, in this case image_annotations\n* path: as before, the path where we can find the images as a string\n* hide_axis: a boolean determining if we want to hide or show the image axis\n\nand outputs the plot containing all the annotations","61c204fa":"## Load the annotation data\n\nIn this challenge, the annotation data is provided in the train.csv file. To be able to work with it first we need to load it as a dataframe (df). For that I will use pandas dataframe.","3c8a9715":"**And here you have the call to the function, *voil\u00e0*!**\n\nThis is an easy method to plot the images with it's corresponding segmentations. If you would like to beautify it just plaz with the font, thickness and color of the functions [cv2.putText()](https:\/\/www.geeksforgeeks.org\/python-opencv-cv2-puttext-method\/) and [cv2.rectangle()](https:\/\/www.geeksforgeeks.org\/python-opencv-cv2-rectangle-method\/). Have linked the documentation."}}