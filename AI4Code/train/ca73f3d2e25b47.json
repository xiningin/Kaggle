{"cell_type":{"53b63e24":"code","f11f3f61":"code","b5a423eb":"code","ae69ccfb":"code","245d873e":"code","f6602a31":"code","cc078989":"code","63c7518d":"code","8dc2f8c0":"code","071e36e1":"code","08fb4a10":"code","ca08ea3e":"code","a61758e7":"code","24ce050d":"code","1586d969":"code","5f55ba98":"code","16e97b31":"code","8c28ccb4":"code","96df01b5":"code","00cb6537":"code","2b0cf416":"code","59317990":"code","f13b2b14":"code","b8380599":"code","7270c336":"code","61a8bee8":"code","dda42d14":"code","017f3f09":"markdown","461ba502":"markdown","ea9557dd":"markdown","aa6a5eb4":"markdown","b548b0e9":"markdown","fc98ffb2":"markdown","325e470c":"markdown","a9663a0d":"markdown"},"source":{"53b63e24":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f11f3f61":"import pandas as pd\nimport numpy as np","b5a423eb":"path = \"\/kaggle\/input\/house-prices-advanced-regression-techniques\/\"\n\ntrainData = pd.read_csv(path +\"train.csv\")\ntestData = pd.read_csv(path +\"test.csv\")\n\n\nprint(trainData.info())\nprint(testData.info())","ae69ccfb":"dataset = pd.concat([trainData, testData], axis=0)\ndataset.info()","245d873e":"trainData.head(3)\ntrainData.describe()","f6602a31":"testData.head(3)","cc078989":"###Check missing data\n# Check if any data is missing\ndef checkMissing(dataset):\n    if(pd.isna(dataset).any().any() == True):\n        # Check which column has missing data\n        print(pd.isna(dataset).any())\n        print(\"\\n---Total number of missing value---\")\n        global numMiss \n        numMiss = dict(dataset.isna().sum()[dataset.isna().sum() > 0])\n        print(numMiss)\n        print(\"\\n---Columns with missing value---\")\n        print(list(pd.isna(dataset).any()[pd.isna(dataset).any()==True].index))\n    else:\n        print(\"No missing data\")\n    \n    return None\n\ncheckMissing(dataset)","63c7518d":"price = dataset.iloc[:,-1:]\nprice","8dc2f8c0":"features = dataset.iloc[:,:-1]\nfeatures","071e36e1":"# Drop columns with data less than 50%\ndropCol = [x for x in numMiss if (numMiss[x]*100 \/ len(dataset) < 50)]\ndataset = dataset.drop(dropCol, axis=1)\n\ncheckMissing(dataset)\n","08fb4a10":"dataset.MSSubClass = dataset.MSSubClass.astype(object)\ndataset.OverallQual = dataset.OverallQual.astype(object)\ndataset.OverallCond = dataset.OverallCond.astype(object)\ndataset.OverallCond = dataset.OverallCond.astype(object)\n\n\npd.options.display.max_rows = 100\nlisttype = dataset.dtypes\nlisttype","ca08ea3e":"#Select integer and float based columns\ncolInt = dataset.select_dtypes(exclude=[object])\ncolYr = dataset[['Id', 'YearBuilt', 'YearRemodAdd', 'MoSold', 'YrSold']]\ncolInt = colInt.drop(colYr, axis = 1)\ncolInt.head(3)","a61758e7":"# colInt.loc[:,colInt.columns != ['Id', 'YearBuilt', 'YearRemodAdd', 'MoSold', 'YrSold']]\ncolInt = np.log1p(colInt)\ncolInt.tail()\n\n# Reverse\n# np.expm1(colInt).head(3)","24ce050d":"colObj = dataset.select_dtypes(include=[object])\ncolObj.info()","1586d969":"colObj = pd.get_dummies(colObj)\ncolObj.head(3)","5f55ba98":"print(colObj.shape)\nprint(colInt.shape)\nnewDf = pd.concat([colObj, colInt, colYr, price], axis=1)","16e97b31":"newDf.head()","8c28ccb4":"X = newDf[newDf.Id <= trainData.shape[0]]\nY = newDf[newDf.Id > trainData.shape[0]]\nassert X.shape[0] + Y.shape[0] == newDf.shape[0], \"wrong data\"","96df01b5":"x_train = X.iloc[:, :-1]\ny_train = X[\"SalePrice\"]\n\nx_test = Y.iloc[:, :-1]\ny_test = Y[\"SalePrice\"]","00cb6537":"from sklearn.model_selection import train_test_split\ntrain_X, test_X, train_y, test_y = train_test_split(x_train, y_train, test_size = 0.3, random_state = 123)\nprint(train_X)","2b0cf416":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error as MSE","59317990":"xgbMod = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators = 10, seed = 123) \nxgbMod.fit(train_X, train_y)\nxgbPred = xgbMod.predict(test_X)\nxgbRmse = np.sqrt(MSE(test_y, xgbPred)) \nprint(\"RMSE : % f\" %(rmse)) ","f13b2b14":"train_dmatrix = xgb.DMatrix(data = train_X, label = train_y) \ntest_dmatrix = xgb.DMatrix(data = test_X, label = test_y) \n\nparam = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"} \n  \nxgbR = xgb.train(params = param, dtrain = train_dmatrix, num_boost_round = 10) \nxgbRPred = xgbR.predict(test_dmatrix) \n\nrmse = np.sqrt(MSE(test_y, xgbRPred)) \nprint(\"RMSE : % f\" %(rmse)) ","b8380599":"params = {\n        'objective':'reg:linear',\n        'booster':'gbtree',\n        'max_depth':2,\n        'eval_metric':'rmse',\n        'learning_rate':0.1, \n        'min_child_weight':1,\n        'subsample':0.80,\n        'colsample_bytree':0.81,\n        'seed':45,\n        'reg_alpha':1,#1e-03,\n        'reg_lambda':0,\n        'gamma':0,\n        'nthread':-1\n}\n\nwatchList = [(train_dmatrix, 'train'), (test_dmatrix, 'test')]\n\nxgbParams = xgb.train(params, train_dmatrix, 2000, watchList, early_stopping_rounds=300, maximize=False, verbose_eval=10)\np_test = xgbParams.predict(test_dmatrix)\nrmse = np.sqrt(MSE(test_y, p_test)) \nprint(\"RMSE : % f\" %(rmse)) ","7270c336":"from sklearn.metrics import mean_absolute_error, r2_score\nx_testDmatrix = xgb.DMatrix(data = x_test) \nd_test = xgbParams.predict(x_testDmatrix)\nresult = pd.DataFrame(d_test)","61a8bee8":"Y[\"SalePrice\"] = pd.DataFrame(d_test)\nresult = Y[[\"Id\", \"SalePrice\"]]","dda42d14":"result.to_csv(\"xgboost.csv\", index = False)","017f3f09":"Data PreProcessing: change datatype\n","461ba502":"Display the features columns","ea9557dd":"Check missing data in dataset","aa6a5eb4":"# XGBoost","b548b0e9":"Normalizing numeric based data using log(1+p).","fc98ffb2":"Combine trainData and testData","325e470c":"Display the last column (label)","a9663a0d":"Split the lablled dataset into training set and test set.\n\n* x_train = features of training data\n* y_train = label of training data\n\n* x_test - features of testing data\n* y_test = label of testing data"}}