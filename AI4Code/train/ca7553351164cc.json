{"cell_type":{"55aeac4a":"code","3fe7e78d":"code","15f0fe9b":"code","970e0f8f":"code","595a5fee":"code","39b21b8b":"code","2e6ff184":"code","2a68ef95":"code","4141ce39":"code","012258e6":"code","816d108e":"code","71b93a91":"code","66526541":"code","8e7c5389":"code","86a2d602":"code","931c4338":"code","785e22e5":"code","b902d046":"code","67bcdc58":"code","3a55e738":"code","c4940b2b":"markdown","ee48d386":"markdown","8306b289":"markdown","7bc7c9cd":"markdown","a693eab6":"markdown","5e6909b4":"markdown"},"source":{"55aeac4a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3fe7e78d":"import pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import f1_score ,roc_auc_score ,roc_curve,auc\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import StandardScaler,OrdinalEncoder,LabelEncoder,RobustScaler,OneHotEncoder,PowerTransformer\nfrom sklearn.model_selection import KFold,StratifiedKFold, train_test_split,GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nimport lightgbm as lgb","15f0fe9b":"train = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")\nsubmission = pd.read_csv(\"..\/input\/song-popularity-prediction\/sample_submission.csv\")","970e0f8f":"train.drop('id', axis=1,inplace=True)\ntest.drop('id', axis=1,inplace=True)","595a5fee":"train.shape,test.shape","39b21b8b":"cat_cols = ['key', 'audio_mode', 'time_signature']\nnum_cols =  ['song_duration_ms', 'acousticness', 'danceability', \n             'energy','instrumentalness', 'liveness', 'loudness',\n             'speechiness', 'tempo', 'audio_valence']","2e6ff184":"num_pipeline = Pipeline([\n    ('impute', KNNImputer()),\n    ('scale', StandardScaler()),\n    ('transform',PowerTransformer(method='yeo-johnson'))\n])","2a68ef95":"cat_pipeline = Pipeline([\n    ('impute', KNNImputer()),\n    ('encode', OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n])","4141ce39":"data_pipeline = ColumnTransformer([\n    ('numerical', num_pipeline, num_cols),\n    ('categorical', cat_pipeline, cat_cols),\n])","012258e6":"feature = [col for col in train.columns if col not in (\"id\", \"song_popularity\")]","816d108e":"X = train[feature]\ny = train['song_popularity']","71b93a91":"X.shape,test.shape","66526541":"# #Now apply the pipeline on the data\n\n# X = pd.DataFrame(data=data_pipeline.fit_transform(X))\n# test = pd.DataFrame(data=data_pipeline.transform(test))","8e7c5389":"#param_lgb are taken from https:\/\/www.kaggle.com\/venkatkumar001\/spp2-lgbm , with some modification\n\nparams_lgb = {\n    \"task\": \"train\",\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    'subsample': 0.95312,\n    'learning_rate': 0.001635,\n    \"max_depth\": 5,\n    \"feature_fraction\": 0.2256038826485174,\n    \"bagging_fraction\": 0.7705303688019942,\n    \"min_child_samples\": 290,\n    \"reg_alpha\": 14.68267919457715,\n    \"reg_lambda\": 66.156,\n    \"max_bin\": 772,\n    \"min_data_per_group\": 177,\n    \"bagging_freq\": 1,\n    \"cat_smooth\": 96,\n    \"cat_l2\": 17,\n    \"verbosity\": -1,\n    'random_state':42,\n    'n_estimators':8000,\n    'colsample_bytree':0.1107\n    }","86a2d602":"prediction = []\nscore = []\n\nfolds=5\nidx = list(range(len(train)))\n\nfor fold in range(folds):\n    random.shuffle(idx)\n    \n    train_idx=idx[:int(len(train)*0.8)]\n    valid_idx=idx[int(len(train)*0.8):]\n    \n    x_train=X.iloc[train_idx]\n    y_train=y.iloc[train_idx]\n    \n    x_valid=X.iloc[valid_idx]\n    y_valid=y.iloc[valid_idx]\n    \n    print('x_train.shape: ',x_train.shape)\n    \n    x_train = pd.DataFrame(data=data_pipeline.fit_transform(x_train))\n    x_valid = pd.DataFrame(data=data_pipeline.transform(x_valid))\n\n    print('x_train.shape: ',x_train.shape)\n\n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_val = lgb.Dataset(x_valid, y_valid)\n\n    model = lgb.train(\n                      train_set=lgb_train,\n                      valid_sets=lgb_val,\n                      early_stopping_rounds=300,\n                      verbose_eval=False)\n                     \n    \n    preds_valid = model.predict(x_valid,num_iteration=model.best_iteration)\n    roc1= roc_auc_score(y_valid,preds_valid)\n    score.append(roc1)\n    print(f\"fold|split:{fold},roc:{roc1}\")\n    \n    print('test.shape: ',test.shape)\n    test_x = pd.DataFrame(data=data_pipeline.transform(test))\n    print('test.shape: ',test_x.shape)\n\n    test_predict = model.predict(test_x,num_iteration=model.best_iteration)\n    prediction.append(test_predict)\n    \nprint(np.mean(score),np.std(score))    ","931c4338":"prediction = np.array(prediction)\nfinal_preds = np.mean(prediction, axis=0)","785e22e5":"xgb_submission = submission.copy()","b902d046":"xgb_submission['song_popularity'] = final_preds","67bcdc58":"xgb_submission.head()","3a55e738":"xgb_submission.to_csv(\"submission.csv\",index=False)\nxgb_submission.head()","c4940b2b":"# Lets Build a Pipeline","ee48d386":"In pipeline we have:\n*     KNNImputer\n*     StandardScaler\n*     PowerTransformer\n\nHere we can do different experiment with all the pipeline component.","8306b289":"# Submission","7bc7c9cd":"# Happy Learning !!!","a693eab6":"# Build Model","5e6909b4":"Pip"}}