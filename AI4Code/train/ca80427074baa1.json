{"cell_type":{"cca8cf2d":"code","6bac028c":"code","1b90b2aa":"code","6df37e9b":"code","bc4d9ccf":"code","773af23a":"code","f48a1730":"code","9955a6f9":"code","682b7a17":"code","78487364":"code","4dc110a1":"code","15cd2ad3":"code","cee8c12d":"code","c4e542fd":"code","0a5be342":"code","5599bff1":"code","ee84138f":"code","660d33e3":"code","e522400b":"code","5b9d6841":"code","d27f26d7":"code","3c52ca38":"code","a69456be":"code","ec6490f2":"code","941a692d":"code","e22dd5cd":"code","196d56ef":"code","93ebcddb":"code","b08f1226":"code","bb296db2":"code","5273b635":"code","ca631832":"code","5a5ce9fc":"code","87c17a8f":"code","03521426":"code","4fad5ff8":"code","099f5fce":"code","de60cd72":"code","c8185065":"code","5aed3211":"code","d6465f37":"code","12fe302f":"code","24cfe656":"code","525b3e85":"code","e567f4a3":"code","dda9c43c":"code","ec3f722e":"code","d6833167":"code","b9c3d607":"code","21e41e11":"code","4da73325":"code","f4ec279f":"code","0632329a":"code","015daab7":"code","43554b70":"code","d4bb338d":"code","1e959728":"code","704df95a":"code","346d0f72":"code","be090ae5":"code","58031d62":"code","2f8adfff":"code","e0af1f84":"code","8bcfeabd":"code","2cca737a":"code","89b1aa56":"code","4f3a9290":"code","9b3431e4":"code","bc22f06f":"code","e5dba507":"code","79c05100":"code","7b36625d":"code","972ebd3a":"code","539f2809":"code","fced0282":"code","767e4a3c":"code","6c02c125":"markdown","5b920085":"markdown","daa29e5b":"markdown","7527fe09":"markdown","986ef65b":"markdown","b42629fb":"markdown","a899db10":"markdown","87051258":"markdown","9ecf44b7":"markdown","3714b666":"markdown","e86c14e8":"markdown","a456558a":"markdown","dd80d0e3":"markdown","b1d4619a":"markdown","be4413f4":"markdown","384fd75f":"markdown","780301c3":"markdown","2779cf87":"markdown","10301231":"markdown","55880289":"markdown","ebad2e58":"markdown","f10f6e82":"markdown","4a58137e":"markdown","4427d46f":"markdown","16c24fa3":"markdown","02e955b2":"markdown","c8c6838f":"markdown","0941e697":"markdown","4beec223":"markdown","4309ddd0":"markdown","d7b29c14":"markdown","08305e45":"markdown","e798e7f4":"markdown","29d90005":"markdown","04e17880":"markdown","cb8b5618":"markdown","e656f8b7":"markdown","a77069b9":"markdown","a4c3e27a":"markdown","66d7fd28":"markdown","9456ce11":"markdown","bd13445a":"markdown"},"source":{"cca8cf2d":"import numpy as np\nimport pandas as pd\nimport os\nfrom pathlib import Path\nfrom learntools.time_series.style import *  # plot style settings\n#from learntools.time_series.utils import plot_lags, make_lags, make_leads\nfrom learntools.time_series.utils import (create_multistep_example,\n                                          load_multistep_data,\n                                          make_lags,\n                                          make_leads,\n                                          plot_lags,\n                                          make_multistep_target,\n                                          plot_multistep,\n                                          plot_periodogram, \n                                          seasonal_plot)\nfrom statsmodels.graphics.tsaplots import plot_pacf\nimport matplotlib.pyplot as plt\nimport plotly as py\nimport cufflinks as cf\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom sklearn.multioutput import RegressorChain\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom xgboost import XGBRegressor\n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\ncf.go_offline()\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","6bac028c":"stores = pd.read_csv('\/kaggle\/input\/store-sales-time-series-forecasting\/stores.csv')\ntrans = pd.read_csv('\/kaggle\/input\/store-sales-time-series-forecasting\/transactions.csv')\noil = pd.read_csv('\/kaggle\/input\/store-sales-time-series-forecasting\/oil.csv')\n#load the data\ncomp_dir = Path('..\/input\/store-sales-time-series-forecasting')\nstore_sales = pd.read_csv(\n    comp_dir \/ 'train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\n#rearranging values according to the store, product family, and date that they occur\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n#unstacking the time series data to wide form and averaging over product families over stores\nfamily_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean() \n    .unstack('family')\n    .loc[:, ['sales', 'onpromotion']]\n)\n\n\nholidays_events = pd.read_csv(\n    comp_dir \/ \"holidays_events.csv\",\n    dtype={\n        'type': 'category',\n        'locale': 'category',\n        'locale_name': 'category',\n        'description': 'category',\n        'transferred': 'bool',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nholidays_events = holidays_events.set_index('date').to_period('D')\n\ndf_test = pd.read_csv(\n    comp_dir \/ 'test.csv',\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'onpromotion': 'uint32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\ndf_test['date'] = df_test.date.dt.to_period('D')\ndf_test = df_test.set_index(['store_nbr', 'family', 'date']).sort_index()","1b90b2aa":"store_sales","6df37e9b":"store_sales.unstack(['store_nbr', 'family'])","bc4d9ccf":"y = store_sales.unstack(['store_nbr', 'family']).loc['2017']\nSTORE_NBR = '3'  # 1 - 54\nSTORE_NBR_2 = '5'  # 1 - 54\nSTORE_NBR_3 = '15'  # 1 - 54\nFAMILY = 'AUTOMOTIVE'\nFAMILY_2 = 'MAGAZINES'\nFAMILY_3 = 'BEAUTY'\n\n# Uncomment to see a list of product families\ndisplay(store_sales.index.get_level_values('family').unique())\n\nfig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, sharey=True)\nax1 = y.loc(axis=1)['sales', STORE_NBR, FAMILY].plot(**plot_params, ax=ax1)\nax1.set_title(f'{FAMILY} Sales at Store {STORE_NBR}');\nax2 = y.loc(axis=1)['sales', STORE_NBR_2, FAMILY_2].plot(**plot_params, ax=ax2)\nax2.set_title(f'{FAMILY_2} Sales at Store {STORE_NBR_2}');\nax3 = y.loc(axis=1)['sales', STORE_NBR_3, FAMILY_3].plot(**plot_params, ax=ax3)\nax3.set_title(f'{FAMILY_3} Sales at Store {STORE_NBR_3}');","773af23a":"y = store_sales.unstack(['store_nbr', 'family'])\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    drop=True,\n)\nX = dp.in_sample()\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X, y)\ny_pred = pd.DataFrame(model.predict(X), index=X.index, columns=y.columns)","f48a1730":"y = store_sales.unstack(['store_nbr', 'family']).loc['2017']\nshort_y_pred = y_pred.loc['2017']\nSTORE_NBR = '3'  # 1 - 54\nSTORE_NBR_2 = '5'  # 1 - 54\nSTORE_NBR_3 = '15'  # 1 - 54\nFAMILY = 'AUTOMOTIVE'\nFAMILY_2 = 'MAGAZINES'\nFAMILY_3 = 'BEAUTY'\n\ndisplay(store_sales.index.get_level_values('family').unique())\n\nfig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, sharey=True)\nax1 = y.loc(axis=1)['sales', STORE_NBR, FAMILY].plot(**plot_params, ax=ax1)\nax1 = short_y_pred.loc(axis=1)['sales', STORE_NBR, FAMILY].plot(ax=ax1)\nax1.set_title(f'{FAMILY} Sales at Store {STORE_NBR}');\nax2 = y.loc(axis=1)['sales', STORE_NBR_2, FAMILY_2].plot(**plot_params, ax=ax2)\nax2 = short_y_pred.loc(axis=1)['sales', STORE_NBR_2, FAMILY_2].plot(ax=ax2)\nax2.set_title(f'{FAMILY_2} Sales at Store {STORE_NBR_2}');\nax3 = y.loc(axis=1)['sales', STORE_NBR_3, FAMILY_3].plot(**plot_params, ax=ax3)\nax1 = short_y_pred.loc(axis=1)['sales', STORE_NBR_3, FAMILY_3].plot(ax=ax3)\nax3.set_title(f'{FAMILY_3} Sales at Store {STORE_NBR_3}');","9955a6f9":"average_sales = (\n    store_sales.loc[:, ['sales']]\n    .groupby('date').mean()\n    .squeeze()\n    .loc['2017']\n)\naverage_sales\nplot_periodogram(average_sales);","682b7a17":"y = store_sales.unstack(['store_nbr', 'family'])\nfourier = CalendarFourier(order = 4, freq = 'M')\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    additional_terms=[fourier],\n    seasonal = True,\n    drop=True,\n)\nX = dp.in_sample()\nX","78487364":"fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=True, sharey=True)\nax1 =  X[X.columns[8:10]].loc['2017'].plot(ax=ax1)\nax1.set_title('Fourier Features 1');\nax2 =  X[X.columns[10:12]].loc['2017'].plot(ax=ax2)\nax2.set_title('Fourier Features 2');\nax3 =  X[X.columns[12:14]].loc['2017'].plot(ax=ax3)\nax3.set_title('Fourier Features 3');\nax4 =  X[X.columns[14:16]].loc['2017'].plot(ax=ax4)\nax4.set_title('Fourier Features 4');","4dc110a1":"y.loc['2017']","15cd2ad3":"y = y.loc['2017']\nX = X.loc['2017']\nmodel = LinearRegression().fit(X, y)\ny_pred = pd.DataFrame(model.predict(X), index=X.index, columns=y.columns)\n\nSTORE_NBR = '3'  # 1 - 54\nFAMILY = 'AUTOMOTIVE'\nax = y.loc['2017'].loc(axis=1)['sales', STORE_NBR, FAMILY].plot(**plot_params)\nax = y_pred.loc['2017'].loc(axis=1)['sales', STORE_NBR, FAMILY].plot(ax=ax)\nax.set_title(f'{FAMILY} Sales at Store {STORE_NBR}');","cee8c12d":"y_deseason = y - y_pred\n\naverage_sales_deseason = (\n    y_deseason.stack(['store_nbr', 'family']).loc[:, ['sales']]\n    .groupby('date').mean()\n    .squeeze()\n    .loc['2017']\n)\n\nax = average_sales_deseason.plot(**plot_params)\nax.set_title('Average of Deseasoned Data')","c4e542fd":"fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\nax1 = plot_periodogram(average_sales, ax=ax1)\nax1.set_title(\"Product Sales Frequency Components\")\nax2 = plot_periodogram(average_sales_deseason, ax=ax2);\nax2.set_title(\"Deseasonalized\");","0a5be342":"# National and regional holidays in the training set\nholidays = (\n    holidays_events\n    .query(\"locale in ['National', 'Regional']\")\n    .loc['2017':'2017-08-15', ['description']]\n    .assign(description=lambda x: x.description.cat.remove_unused_categories())\n)\n\ndisplay(holidays)","5599bff1":"ax = average_sales_deseason.plot(**plot_params)\nplt.plot_date(holidays.index, average_sales_deseason[holidays.index], color='C3')\nax.set_title('National and Regional Holidays');","ee84138f":"X_holidays = pd.get_dummies(holidays)\n\nX2 = X.join(X_holidays, on='date').fillna(0.0)","660d33e3":"X2","e522400b":" model = LinearRegression().fit(X2, y)\n\ny_pred = pd.DataFrame(model.predict(X2), index=X2.index, columns=y.columns)\n\navg = (\n    y_pred.stack(['store_nbr', 'family']).loc[:, ['sales']]\n    .groupby('date').mean()\n    .squeeze()\n    .loc['2017']\n)\n\ndeseasoned_average = average_sales - avg","5b9d6841":"fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\nax1 = average_sales.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\", ax=ax1)\nax1 = avg.plot(ax=ax1, label=\"Seasonal\")\nax2 = deseasoned_average.plot(title=\"Deseasoned Sales\", ylabel=\"items sold\", ax=ax2)","d27f26d7":"deseasoned = y - y_pred\ndeseasoned.columns[y.std().argmax()]","3c52ca38":"cycle_col = deseasoned.loc(axis=1)['sales', '46', 'GROCERY I']","a69456be":"STORE_NBR = '46'  # 1 - 54\nFAMILY = 'GROCERY I'\nax = cycle_col.plot(**plot_params)\nax.set_title('Deseasoned Grocery Sales at Store 46');","ec6490f2":"y_ma = y.loc(axis=1)['sales', '46', 'GROCERY I'].rolling(window=7, center=True).mean()\n\nax = y_ma.plot()\nax.set_title(\"Seven-Day Moving Average\");","941a692d":"plot_pacf(cycle_col, lags=8);\nplot_lags(cycle_col, lags=8, nrows=2);","e22dd5cd":"promo = store_sales.unstack(['store_nbr', 'family']).loc(axis=1)['onpromotion', '46', 'GROCERY I'].loc['2017']","196d56ef":"plot_lags(x=promo, y=cycle_col, lags=3, leads=3, nrows=1);","93ebcddb":"y = store_sales.unstack(['store_nbr', 'family']).loc['2017', 'sales']\nall_promotion = store_sales.unstack(['store_nbr', 'family']).loc(axis=1)['onpromotion'].loc['2017']\nX_lags = make_lags(y, lags=4)\nX_promo = pd.concat([\n    make_lags(all_promotion, lags=3),\n    all_promotion,\n    make_leads(all_promotion, leads=2),\n], axis=1)\n\n#putting together on promotion lag and lead data, seasonality, trends, holidays, and sales lags\nX = pd.concat([X2, X_lags, X_promo], axis=1).dropna()\ny, X = y.align(X, join='inner', axis = 0)\nX","b08f1226":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=30, shuffle=False)\n\nmodel = LinearRegression(fit_intercept=False).fit(X_train, y_train)\ny_fit = pd.DataFrame(model.predict(X_train), index=X_train.index, columns = y_train.columns).clip(0.0)\ny_pred = pd.DataFrame(model.predict(X_valid), index=X_valid.index, columns = y_valid.columns).clip(0.0)\nrmsle_train = mean_squared_log_error(y_train, y_fit) ** 0.5\nrmsle_valid = mean_squared_log_error(y_valid, y_pred) ** 0.5\nprint(f'Training RMSLE: {rmsle_train:.5f}')\nprint(f'Validation RMSLE: {rmsle_valid:.5f}')\ny_avg = (y.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\ny_fit_avg = (y_fit.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\ny_pred_avg = (y_pred.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())","bb296db2":"ax = y_avg.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_fit_avg.plot(ax=ax, label=\"Fitted\", color='C0')\nax = y_pred_avg.plot(ax=ax, label=\"Forecast\", color='C3')\nax.legend();","5273b635":"class BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None  # store column names from fit method\n","ca631832":"def fit(self, X_1, X_2, y):\n    self.model_1.fit(X_1, y)\n\n    y_fit = pd.DataFrame(\n        self.model_1.predict(X_1),\n        index=X_1.index, columns=y.columns,\n    )\n\n    y_resid = y - y_fit\n    y_resid = y_resid.stack(['family', 'store_nbr']).squeeze() # wide to long\n\n    self.model_2.fit(X_2, y_resid)\n\n    # Save column names for predict method\n    self.y_columns = y.columns\n    # Save data for question checking\n    self.y_fit = y_fit\n    self.y_resid = y_resid\n\n\n# Add method to class\nBoostedHybrid.fit = fit\n","5a5ce9fc":"def predict(self, X_1, X_2):\n    y_pred = pd.DataFrame(\n        self.model_1.predict(X_1),\n        index=X_1.index, columns=self.y_columns,\n    )\n    y_pred = y_pred.stack(['family', 'store_nbr']).squeeze()  # wide to long\n\n    y_pred += self.model_2.predict(X_2)\n    \n    return y_pred.unstack(['family', 'store_nbr'])  # long to wide\n\n\n# Add method to class\nBoostedHybrid.predict = predict","87c17a8f":"\nX_2 = store_sales.unstack(['store_nbr', 'family']).loc['2017', 'onpromotion']  # onpromotion feature\nX_2.stack(['family', 'store_nbr'])\nX_2, y = X_2.align(y, join='inner', axis = 0)\nX_2 = X_2.stack(['family', 'store_nbr']).squeeze()\n# Label encoding for 'family'\nle = LabelEncoder()  # from sklearn.preprocessing\nX_2 = X_2.reset_index('family')\nX_2['family'] = le.fit_transform(X_2['family'])\nX_2","03521426":"model = BoostedHybrid(LinearRegression(), XGBRegressor())\n\nmodel.fit(X, X_2, y)\ny_pred = model.predict(X, X_2)\n\ny_pred = y_pred.clip(0.0)\n#converting back to the right order\ny_pred = y_pred.stack(['store_nbr', 'family']).unstack(['store_nbr', 'family'])","4fad5ff8":"y_pred","099f5fce":"rmsle_train = mean_squared_log_error(y, y_pred) ** 0.5\nrmsle_train","de60cd72":"y_fit = pd.DataFrame(model.predict(X, X_2), index=X.index, columns = y.columns)\ny_avg = (y.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\ny_fit_avg = (y_pred.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())","c8185065":"ax = y_avg.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_fit_avg.plot(ax=ax, label=\"Fitted\", color='C0')\nax.legend();","5aed3211":"X = dp.in_sample()\nholidays = (\n    holidays_events\n    .query(\"locale in ['National', 'Regional']\")\n    .loc['2017':'2017-08-15', ['description']]\n    .assign(description=lambda x: x.description.cat.remove_unused_categories())\n)\n\nX_holidays = pd.get_dummies(holidays)\nX = X.join(X_holidays, on='date').fillna(0.0)\n\ny = store_sales.unstack(['store_nbr', 'family']).loc['2017', 'sales']\nall_promotion = store_sales.unstack(['store_nbr', 'family']).loc(axis=1)['onpromotion'].loc['2017']\nX_lags = make_lags(y, lags=4)\n\nX_promo = pd.concat([\n    make_lags(all_promotion, lags=3),\n    all_promotion,\n    make_leads(all_promotion, leads=1),\n], axis=1)\n\n#putting together on promotion lag and lead data, seasonality, trends, holidays, and sales lags\nX_whole = pd.concat([X, X_lags, X_promo], axis=1).dropna()\n#X\ny_whole = store_sales.unstack(['store_nbr', 'family']).loc['2017', 'sales']\ny = make_multistep_target(y, steps=16).dropna()\ny, X = y.align(X_whole, join='inner', axis = 0)\nX_fore = X_whole.loc['2017-08']\ny","d6465f37":"X_fore","12fe302f":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=16, shuffle=False)\nlinear_model = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n\nlinear_y_fit = pd.DataFrame(linear_model.predict(X_train), index=X_train.index, columns = y_train.columns).clip(0.0)\nlinear_y_pred = pd.DataFrame(linear_model.predict(X_valid), index=X_valid.index, columns = y_valid.columns).clip(0.0)","24cfe656":"y","525b3e85":"y_avg = (y_whole.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\nlinear_y_fit_avg = (linear_y_fit.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\nlinear_y_pred_avg = (linear_y_pred.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\n\n#reorder the columns based on the proper order of steps\nlinear_y_fit_avg = linear_y_fit_avg.reindex(columns=['y_step_1', 'y_step_2', 'y_step_3',\n       'y_step_4', 'y_step_5', 'y_step_6', 'y_step_7', 'y_step_8', 'y_step_9', 'y_step_10', 'y_step_11', 'y_step_12', 'y_step_13',\n       'y_step_14', 'y_step_15', 'y_step_16'])\n\nlinear_y_pred_avg = linear_y_pred_avg.reindex(columns=['y_step_1', 'y_step_2', 'y_step_3',\n       'y_step_4', 'y_step_5', 'y_step_6', 'y_step_7', 'y_step_8', 'y_step_9', 'y_step_10', 'y_step_11', 'y_step_12', 'y_step_13',\n       'y_step_14', 'y_step_15', 'y_step_16'])\n\n#create the forecasted values:\ncheck = linear_y_pred.loc['2017-07-31']\ncheck.index.names=['date', 'store_nbr', 'family']\ncheck = check.groupby('date').mean()\ncheck.index = y_whole.loc['2017-07-31':'2017-08-15'].index","e567f4a3":"rmsle_train = mean_squared_log_error(y_train, linear_y_fit) ** 0.5\nrmsle_valid = mean_squared_log_error(y_valid, linear_y_pred) ** 0.5\nrmsle_forecast= mean_squared_log_error(y_valid.loc['2017-07-31'], linear_y_pred.loc['2017-07-31']) ** 0.5\nprint(f'Training RMSLE: {rmsle_train:.5f}')\nprint(f'Validation RMSLE: {rmsle_valid:.5f}')\nprint(f'Forecast RMSLE: {rmsle_forecast:.5f}')","dda9c43c":"ax = y_avg.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = plot_multistep(linear_y_fit_avg, ax=ax, every=16)\nax = plot_multistep(linear_y_pred_avg, ax=ax, every=16)\nax = check.plot(ax=ax, label=\"Forecasted\", color='C0')","ec3f722e":"linear_model = LinearRegression(fit_intercept=False).fit(X, y)\n\nlinear_y_fit_full = pd.DataFrame(linear_model.predict(X), index=X.index, columns = y.columns).clip(0.0)\nlinear_y_forecast = pd.DataFrame(linear_model.predict(X_fore), index=X_fore.index, columns = y.columns).clip(0.0)","d6833167":"y_avg = (y_whole.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\nlinear_y_fit_full_avg = (linear_y_fit.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\nlinear_y_forecast_avg = (linear_y_pred.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\n\n#reorder the columns based on the proper order of steps\nlinear_y_fit_full_avg = linear_y_fit_full_avg.reindex(columns=['y_step_1', 'y_step_2', 'y_step_3',\n       'y_step_4', 'y_step_5', 'y_step_6', 'y_step_7', 'y_step_8', 'y_step_9', 'y_step_10', 'y_step_11', 'y_step_12', 'y_step_13',\n       'y_step_14', 'y_step_15', 'y_step_16'])\n\nlinear_y_forecast_avg = linear_y_forecast_avg.reindex(columns=['y_step_1', 'y_step_2', 'y_step_3',\n       'y_step_4', 'y_step_5', 'y_step_6', 'y_step_7', 'y_step_8', 'y_step_9', 'y_step_10', 'y_step_11', 'y_step_12', 'y_step_13',\n       'y_step_14', 'y_step_15', 'y_step_16'])\n\n#create the forecasted values:\nlinear_forecast = linear_y_forecast.loc['2017-08-15']\nlinear_forecast.index.names=['date', 'store_nbr', 'family']\nlinear_forecast_avg = linear_forecast.groupby('date').mean()\nlinear_forecast_avg.index = df_test.unstack(['store_nbr', 'family']).index","b9c3d607":"rmsle_fit_full = mean_squared_log_error(y, linear_y_fit_full) ** 0.5\nprint(f'Full Training RMSLE: {rmsle_fit_full:.5f}')","21e41e11":"ax = y_avg.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = plot_multistep(linear_y_fit_full_avg, ax=ax, every=16)\nax = plot_multistep(linear_y_forecast_avg, ax=ax, every=16)\nax = linear_forecast_avg.plot(ax=ax, label=\"Forecasted\", color='C0')","4da73325":"all_promotion = store_sales.unstack(['store_nbr', 'family']).loc(axis=1)['onpromotion'].loc['2017']\n#using lags\nX_2_lags = make_lags(y_whole, lags=4)\nX_2_lags = X_2_lags.stack(['store_nbr', 'family'])\n\n#using promotional data\nX_2_promo = pd.concat([\n    make_lags(all_promotion, lags=3).stack(['store_nbr', 'family']),\n    all_promotion.stack(['store_nbr', 'family']),\n    make_leads(all_promotion, leads=1).stack(['store_nbr', 'family']),\n], axis=1)\n\n#putting them both together\nX_2_whole = pd.concat([X_2_lags, X_2_promo], axis=1).dropna()\n\n#label encoding the family column\nle = LabelEncoder()\nX_2_whole = (X_2_whole\n    .reset_index('family')  # convert index to column\n    .assign(family=lambda x: le.fit_transform(x.family)))\n\n#stacking the y value for the benefit of a not linear model like XGBoost\ny_2 = y.stack(['store_nbr', 'family'])\n#fixing the order\ny_2 = y_2.reindex(columns=['y_step_1', 'y_step_2', 'y_step_3',\n       'y_step_4', 'y_step_5', 'y_step_6', 'y_step_7', 'y_step_8', 'y_step_9', 'y_step_10', 'y_step_11', 'y_step_12', 'y_step_13',\n       'y_step_14', 'y_step_15', 'y_step_16'])\nX_2 = X_2_whole.loc['2017':'2017-07-31']\nX_2_fore = X_2_whole.loc['2017-08':'2017-08-15']","f4ec279f":"y_2","0632329a":"X_2","015daab7":"DirRec_xgboost = RegressorChain(base_estimator=XGBRegressor())\nDirRec_xgboost.fit(X_2, y_2)\ny_2_fit = pd.DataFrame(\n   DirRec_xgboost.predict(X_2),\n   index=y_2.index,\n   columns=y_2.columns,\n).clip(0.0)\ny_2_pred = pd.DataFrame(\n   DirRec_xgboost.predict(X_2_fore),\n    index=y_whole.stack(['store_nbr', 'family']).loc['2017-08'].index,\n   columns=y_2.loc['2017-07-15':'2017-07-31'].columns,\n).clip(0.0)","43554b70":"y_2_fit","d4bb338d":"y_2_pred","1e959728":"y_avg = (y_whole.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\ny_2_fit_avg = (y_2_fit.groupby('date').mean().squeeze())\ny_2_pred_avg = (y_2_pred.groupby('date').mean().squeeze())\n\n#create the forecasted values:\ny_2_forecast = y_2_pred.loc['2017-08-15']\ny_2_forecast_avg = y_2_pred.groupby('date').mean()\ny_2_forecast_avg = y_2_forecast_avg.loc['2017-08-15']\ny_2_forecast_avg.index = df_test.unstack(['store_nbr', 'family']).index\ny_2_forecast_avg","704df95a":"rmsle_fit_full = mean_squared_log_error(y, linear_y_fit_full) ** 0.5\nprint(f'Full Training RMSLE: {rmsle_fit_full:.5f}')","346d0f72":"y_whole = store_sales.unstack(['store_nbr', 'family']).loc['2017':'2017-07-31', 'sales']\ny_avg = (y_whole.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\n\nax = y_avg.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = plot_multistep(y_2_fit_avg, ax=ax, every=16)\nax = plot_multistep(y_2_pred_avg, ax=ax, every=16)\nax = y_2_forecast_avg.plot(ax=ax, label=\"Forecast\", color='C3')","be090ae5":"#splitting data for linear model\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=16, shuffle=False)\n#splitting data for XGBRegressor\nX_2_train = X_2.loc['2017':'2017-07-15']\nX_2_valid = X_2.loc['2017-07-16':'2017-07-31']","58031d62":"X_2_train","2f8adfff":"hybrid_forecast_model = BoostedHybrid(LinearRegression(), RegressorChain(base_estimator=XGBRegressor()))\n\n\nhybrid_forecast_model.fit(X_train, X_2_train, y_train)\nhybrid_forecast_fit = hybrid_forecast_model.predict(X_train, X_2_train)\nhybrid_forecast_pred = hybrid_forecast_model.predict(X_valid, X_2_valid)\n\nhybrid_forecast_fit = hybrid_forecast_fit.clip(0.0)\nhybrid_forecast_pred = hybrid_forecast_pred.clip(0.0)","e0af1f84":"hybrid_forecast_pred","8bcfeabd":"#reorder the columns based on the proper order of steps\nhybrid_forecast_fit = hybrid_forecast_fit.stack(['store_nbr', 'family']).reindex(columns=['y_step_1', 'y_step_2', 'y_step_3',\n       'y_step_4', 'y_step_5', 'y_step_6', 'y_step_7', 'y_step_8', 'y_step_9', 'y_step_10', 'y_step_11', 'y_step_12', 'y_step_13',\n       'y_step_14', 'y_step_15', 'y_step_16'])\nhybrid_forecast_fit = hybrid_forecast_fit.unstack(['store_nbr', 'family'])\n\nhybrid_forecast_pred = hybrid_forecast_pred.stack(['store_nbr', 'family']).reindex(columns=['y_step_1', 'y_step_2', 'y_step_3',\n       'y_step_4', 'y_step_5', 'y_step_6', 'y_step_7', 'y_step_8', 'y_step_9', 'y_step_10', 'y_step_11', 'y_step_12', 'y_step_13',\n       'y_step_14', 'y_step_15', 'y_step_16'])\nhybrid_forecast_pred = hybrid_forecast_pred.unstack(['store_nbr', 'family'])\n\ny_avg = (y_whole.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\nhybrid_forecast_fit_avg = (hybrid_forecast_fit.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\nhybrid_forecast_pred_avg = (hybrid_forecast_pred.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\n\n\n#create the forecasted values:\ncheck = hybrid_forecast_pred.loc['2017-07-31']\ncheck = check.groupby('date').mean()\ncheck.index = store_sales.unstack(['store_nbr', 'family']).loc['2017', 'sales'].loc['2017-07-31':'2017-08-15'].index","2cca737a":"rmsle_train = mean_squared_log_error(y_train, hybrid_forecast_fit) ** 0.5\nrmsle_valid = mean_squared_log_error(y_valid, hybrid_forecast_pred) ** 0.5\nrmsle_forecast= mean_squared_log_error(y_valid.loc['2017-07-31'], hybrid_forecast_pred.loc['2017-07-31']) ** 0.5\nprint(f'Training RMSLE: {rmsle_train:.5f}')\nprint(f'Validation RMSLE: {rmsle_valid:.5f}')\n#print(f'Forecast RMSLE: {rmsle_forecast:.5f}')","89b1aa56":"ax = y_avg.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = plot_multistep(hybrid_forecast_fit_avg, ax=ax, every=16)\nax = plot_multistep(hybrid_forecast_pred_avg, ax=ax, every=16)\nax = check.plot(ax=ax, label=\"Forecasted\", color='C0')","4f3a9290":"hybrid_forecast_model = BoostedHybrid(LinearRegression(), RegressorChain(base_estimator=XGBRegressor()))\n\n#fit the model on the full data\nhybrid_forecast_model.fit(X, X_2, y)\nhybrid_forecast = hybrid_forecast_model.predict(X_fore, X_2_fore)\nhybrid_forecast_full_fit = hybrid_forecast_model.predict(X, X_2)\n\n\nhybrid_forecast = hybrid_forecast.clip(0.0)\nhybrid_forecast_full_fit = hybrid_forecast_full_fit.clip(0.0)","9b3431e4":"#reorder the columns based on the proper order of steps\nhybrid_forecast_full_fit = hybrid_forecast_full_fit.stack(['store_nbr', 'family']).reindex(columns=['y_step_1', 'y_step_2', 'y_step_3',\n       'y_step_4', 'y_step_5', 'y_step_6', 'y_step_7', 'y_step_8', 'y_step_9', 'y_step_10', 'y_step_11', 'y_step_12', 'y_step_13',\n       'y_step_14', 'y_step_15', 'y_step_16'])\nhybrid_forecast_full_fit = hybrid_forecast_full_fit.unstack(['store_nbr', 'family'])\n\nhybrid_forecast = hybrid_forecast.stack(['store_nbr', 'family']).reindex(columns=['y_step_1', 'y_step_2', 'y_step_3',\n       'y_step_4', 'y_step_5', 'y_step_6', 'y_step_7', 'y_step_8', 'y_step_9', 'y_step_10', 'y_step_11', 'y_step_12', 'y_step_13',\n       'y_step_14', 'y_step_15', 'y_step_16'])\nhybrid_forecast = hybrid_forecast.unstack(['store_nbr', 'family'])\n\ny_avg = (y_whole.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\nhybrid_forecast_full_fit_avg = (hybrid_forecast_full_fit.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\nhybrid_forecast_avg = (hybrid_forecast.stack(['store_nbr', 'family']).groupby('date').mean().squeeze())\n\n\n#create the forecasted values:\nforecast = hybrid_forecast.loc['2017-08-15']\nforecast.index.names=['date', 'store_nbr', 'family']\nforecast_avg = check.groupby('date').mean()\nforecast_avg.index = df_test.unstack(['store_nbr', 'family']).index","bc22f06f":"rmsle_train = mean_squared_log_error(y, hybrid_forecast_full_fit) ** 0.5\nprint(f'Full Training RMSLE: {rmsle_train:.5f}')","e5dba507":"ax = y_avg.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = plot_multistep(hybrid_forecast_full_fit_avg, ax=ax, every=16)\nax = plot_multistep(hybrid_forecast_avg, ax=ax, every=16)\nax = forecast_avg.plot(ax=ax, label=\"Forecasted\", color='C0')","79c05100":"forecast","7b36625d":"forecast_formatted = forecast.unstack('date', 'family').stack('date')\nforecast_formatted","972ebd3a":"df_test","539f2809":"forecast_formatted.index = df_test.index\npd.DataFrame(forecast_formatted, columns = ['sales'])\n#forecast_formatted = pd.DataFrame(forecast_formatted, index = df_test.index)\nforecast_formatted = pd.DataFrame(forecast_formatted, columns = ['sales'])\nforecast_formatted","fced0282":"y_submit = forecast_formatted.join(df_test.id).reindex(columns=['id', 'sales'])\ny_submit","767e4a3c":"y_submit.to_csv('submission.csv', index=False)\n","6c02c125":"To see how well we model seasonality we will subtract the model's prediction from the ground truth values, giving the deseasoned values.","5b920085":"Submission to the competition requires a 16 step forecast with a one step lead time (16 days into the future starting 1 day after the last date we have available). So, instead of training on all of the data that we have as we have been doing, we will will restructure our data to be multistep to account for this forecast.","daa29e5b":"Now that we have our model ready we can submit to the store sales forecasting competition! Below is code getting our forecast in the right format so that it can be graded for the competition.","7527fe09":"# Submission to Competition","986ef65b":"In this notebook I will be looking at the store sales time series forecasting Kaggle competition data and attempting to accurately model store sales in a variety of product families from 9 stores.","b42629fb":"# Introduction","a899db10":"And here is the wide form of our time series data.","87051258":"**Holidays**","9ecf44b7":"Not that great at predicting. Let's use our hybridized model!","3714b666":"Below we set up a moving average over the non-deseasoned data that smooths over weekly seasons, but preserves cycles in the data.","e86c14e8":"# Cycles","a456558a":"# Hybrid Modeling","dd80d0e3":"Lets look at how holidays impact sales.","b1d4619a":"# Trend","be4413f4":"Let's look at the output when we try to use a linear model to model this data's seasonality with the features we created.","384fd75f":"# Seasonality","780301c3":"Below we see the stacked version of our data.","2779cf87":"Using a linear model we have fit a simple straight line to our data to show how sales are trending over time.\n\nLet's look at the trend our model predicts below.","10301231":"# Load Data","55880289":"# Preparing to Forecast","ebad2e58":"We can see from this plot that some of these holidays may help our predictions by removing variance.\n\nLets add one-hot encoding features to account for these holidays.","f10f6e82":"Based on this periodogram we can see strong seasonality monthly, biweekly, weekly, and semiweekly. Below we will use fourier features to model longer seasons (multiple weeks) and one-hot features to model shorter seasons (weekly). I think by modeling weekly seasons that will take care of biweekly and semiweekly features as well.","4a58137e":"Looks like the new model performs pretty well!","4427d46f":"Let's see how this impacts our predictions.","16c24fa3":"We're going to make a dataset that is cleaned up so as not to use series information for a model like an xgb regressor.","02e955b2":"Let's get a look at a few of the time series that we will be working with.","c8c6838f":"Now lets see if we can capture the rest of the noise present in our data by modeling market cycles.\n\nTo model if we are doing this well we will be looking at the column with the largest standard deviation (or variance) which would be the GROCERY I column of sales for store 46.","0941e697":"And we can see from the line plotted in each of the graphs that the trend line is fairly flat over different product families. The flat trend line is indicative of a ranging market that is neither growing nor shrinking.","4beec223":"It looks like many of the stores' product families follow a fairly flat or ranging trend (close to a slope of 0). Let's see if we can fit a trend to these sales using a time dummy.","4309ddd0":"0.74409 (root mean squared log error) is pretty good! Visually it looks like a simple linear regression model does a pretty good job of capturing sales trends.","d7b29c14":"That looks great! From the chart of deseasoned sales, we can see that adding holiday data reduced a lot of the noise in the sales data.","08305e45":"# Error","e798e7f4":"Based on a periodogram of the deseasoned values it looks like we did well to remove seasonality and the little variance left is likely noise or cycles.","29d90005":"Based on the partial autocorrelation, it looks like lags 1 and 4 may be useful. Also, We see some potentially useful non-linear results from our lag plots, especially 1 and 4.\n\nOn promotion data refers to the number of items that the stores put on promotion in each product family. This may supply useful lead features as the store decides when to put items on promotion.","04e17880":"Now lets consider seasonality. Presumably sales at a supermarket would follow normal social patterns like weekly grocery runs, monthly expenditures, heavier traffic during the holidays, and the like.\n\nLet's use a periodogram to see what seasons are present in our store sales data. To get an idea for all product families and stores, we will work with their average.","cb8b5618":"Here's what our forecast will look like.","e656f8b7":"It looks like there is still a lot of movement, so we can look at periodogram to see if this is just a result of cycles in the market or seasonality that wasn't fully accounted for.","a77069b9":"A list of holidays in Ecuador was supplied.","a4c3e27a":"# Imports","66d7fd28":"Seeing how the moving average looks a lot like the deseasoned data plot makes a case for cyclical movement.","9456ce11":"Lead 2 and Lag 3 both look like they could lend useful insights into our data.","bd13445a":"Below you can see a glimpse at the fourier features that we created. We created these features based on monthly seasonality with a variety of 4 subdivisions of this season. Also we created one-hot encodings of the days of the week."}}