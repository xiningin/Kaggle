{"cell_type":{"4dc1ec90":"code","37ef765b":"code","0c578dee":"code","c1ef8e1f":"code","1f787ead":"code","b5b1490b":"code","98257572":"code","a413ff02":"code","28ccecd9":"code","3b0e86c6":"code","e8b0da8d":"code","6750c232":"code","591be361":"code","3de9131a":"code","0afbe7ab":"code","a87344c5":"markdown","bb659ad2":"markdown"},"source":{"4dc1ec90":"#importing basic libraries\nimport numpy as np\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\n","37ef765b":"%%time\ndf=pd.read_csv(\"..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv\")\ndf.info()\n#no missing values","0c578dee":"#equal division of positive and negative sentiment\ndf['sentiment'].value_counts().plot(kind='pie',autopct='%.1f')","c1ef8e1f":"%%time\n#1. Removing all html tags\n\nfrom bs4 import BeautifulSoup\ndef html_remover(text):\n    soup=BeautifulSoup(text,'html.parser')\n    a=soup.get_text()\n    return a\ndf['review']=df['review'].apply(html_remover)\ndf['review'][0]","1f787ead":"%%time\n#2. Removal of punctuations and special characters\nimport re\ndef sp_char_remover(review):\n    review = re.sub('\\[[^]]*\\]', ' ', review)\n    review = re.sub('[^a-zA-Z]', ' ', review)\n    return review\ndf['review']=df['review'].apply(sp_char_remover)\ndf['review'][1]","b5b1490b":"%%time\n#Converting To lower\ndef lower(text):\n    return text.lower()\ndf['review']=df['review'].apply(lower)\ndf['review'][2]","98257572":"%%time\n#3. Removal of stopwords\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\ndef stopword_remover(text):\n    x=[]\n    text=text.split()    #splitting into individual words\n    for i in text:\n        if i not in stopwords.words('english'):\n            x.append(i)\n    return x\n\ndf['review']=df['review'].apply(stopword_remover)\ndf['review'][0]","a413ff02":"%%time\n#4. Lemmatizing the stopwords and then joining it back\nfrom nltk.stem import WordNetLemmatizer\nlem=WordNetLemmatizer()\n\ndef temp(text):\n    text=\" \".join(text)\n    return text\n\ndef lemma_join(text):\n    text=[lem.lemmatize(word) for word  in text]\n    text=temp(text)\n    return text\n\ndf['review']=df['review'].apply(lemma_join)        \ndf['review'][0]","28ccecd9":"#Separation into training and testing\nfrom sklearn.model_selection import train_test_split\ndf_train, df_test, train_data_label, test_data_label = train_test_split(df['review'], df['sentiment'], test_size=0.20, random_state=42)","3b0e86c6":"#Changing Labels to 1 and 0 for the ease of understanding where 1 is positive review and 0 is negative review.\ntrain_data_label=(train_data_label.replace({'positive':1,'negative':0}))\ntest_data_label=(test_data_label.replace({'positive':1,'negative':0}))","e8b0da8d":"#Creating cleaned corpus from the cleaned df['review'] dataset for the purpose of training\ncorpus_train = []\ncorpus_test  = []\n\nfor i in df_train.index:\n    temp=df_train[i]\n    corpus_train.append(temp)\n\nfor j in df_test.index:\n    temp1=df_test[j]\n    corpus_test.append(temp1)\n    \n    ","6750c232":"#Dummy corpus to perform Vectorization\ncorpus_train2=corpus_train\ncorpus_test2=corpus_test","591be361":"%%time\n#5. Count Vectorization (Bag of words model)\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer()\ncv_train=cv.fit_transform(corpus_train2)\ncv_test=cv.transform(corpus_test2)","3de9131a":"%%time\n#6. Using a Support vector classifier for training our model\nfrom sklearn.svm import LinearSVC\nlin_svc=LinearSVC(C=0.5,random_state=42,max_iter=10000)\nlin_svc.fit(cv_train,train_data_label)\n\ny_pred=lin_svc.predict(cv_test)","0afbe7ab":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\n\nprint(classification_report(test_data_label,y_pred))\nprint(\"ACCURACY SCORE IS: \",accuracy_score(test_data_label,y_pred))","a87344c5":"**Conclusion**\n\nAfter Following the steps to pre-process the reviews and train our Classifier we find a 86% accuracy score for our model. I.e, given a new review with a 86% accuracy it can distingusih between Positive reviews and Negative reviews.","bb659ad2":"# TEXT CLEANING AND TRAINING STEP BY STEP:\n\n1)Removal of HTML contents like \"< br>\".\n\n2)Removal of punctutions, special characters like '\\'.\n\n3)Removal of stopwords like is, the which do not offer much insight.\n\n4)Stemming\/Lemmatization to bring back multiple forms of same word to their common root like 'coming', 'comes' into 'come'.\n\n5)Vectorization - Encode the numeric values once you have cleaned it.\n\n6)Fit the data to the ML model.\n"}}