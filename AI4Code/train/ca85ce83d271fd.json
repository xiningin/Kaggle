{"cell_type":{"f3d8389f":"code","9b9ef9d7":"code","7e9dd099":"code","d6e83823":"code","c6c48345":"code","7cb59e04":"code","921bdb14":"code","cc9a18fd":"code","58ccddb7":"code","a86a0c01":"code","e55a59ce":"code","e25ae6e1":"code","c1b0df3c":"code","6a66c1ae":"code","2cc08a19":"code","b8e9767b":"code","17d01f81":"markdown","35a7e97a":"markdown","94e27de3":"markdown","dd683924":"markdown","764eae37":"markdown","b91b9824":"markdown","f127374d":"markdown","b60aca3e":"markdown","e0f9ee90":"markdown","e9b83c31":"markdown"},"source":{"f3d8389f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9b9ef9d7":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nimport sklearn.metrics as metrics\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns","7e9dd099":"data = pd.read_csv('\/kaggle\/input\/pizza-price-prediction\/pizza_v2.csv')","d6e83823":"data.head() #Displaying head of the data","c6c48345":"df = pd.read_csv('\/kaggle\/input\/pizza-price-prediction\/pizza_v2.csv')","7cb59e04":"plt.figure(figsize=(20,10)) #Companies Vs. Prices\nplt.bar(df.company,df.price_rupiah,color='red')","921bdb14":"plt.figure(figsize=(20,10)) #Toppings Vs. Prices\nplt.bar(df.topping,df.price_rupiah,color='blue')","cc9a18fd":"data.isnull().sum() #No Null values are there","58ccddb7":"data.describe() #Basic Info about the data","a86a0c01":"data['price_rupiah'] = data['price_rupiah'].apply(lambda x : x.replace(\"Rp\",\"\").replace(\",\",\"\"))\n# remove rp and comma and store it in new price column\ndata['diameter'] = data['diameter'].apply(lambda x : x.replace(\" inch\",\"\"))\n#remove inch and store it in new column\ndata[\"diameter\"] = data[\"diameter\"].astype(float)\ndata[\"price_rupiah\"] = data[\"price_rupiah\"].astype(float)","e55a59ce":"en = LabelEncoder()\ncatCols = ['company','topping','variant','size','extra_sauce','extra_cheese','extra_mushrooms']\nfor cols in catCols:\n    data[cols] = en.fit_transform(data[cols])","e25ae6e1":"data.head() #Displaying head of the data","c1b0df3c":"Y = data[\"price_rupiah\"]\nX = data.drop(\"price_rupiah\",axis = 1)","6a66c1ae":"y=pd.DataFrame(Y)","2cc08a19":"# Splitting the dataset into train and test datasets\n# 80% Train Data + 20% Test Data\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)","b8e9767b":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\n# Define the model\nmodel = XGBRegressor(n_estimators=1000, learning_rate=0.09) \n\n# Fit the model\nmodel.fit(X_train, y_train) \n\n# Get predictions\npredictions = model.predict(X_test) \n\n# Calculate MAE\nmae = mean_absolute_error(predictions, y_test)\nprint(\"Mean Absolute Error:\" , mae)\n\n#Calculating R2\nr2 =  metrics.r2_score(y_test, predictions)\nprint(\"R2 score :\", r2)","17d01f81":"# Visualizations","35a7e97a":"# Importing Required Libraries","94e27de3":"# Now, Let's Encode the Data","dd683924":"**We can see that our model has performed really well on the Test Dataset with a R2 Score >95%.**","764eae37":"# In this notebook, we will try to predcit Pizza Prices based on the features such as Company, Diameter, Toppings, Cheese Amount, Sauce Amount, etc.","b91b9824":"# Reading the CSV File","f127374d":"# Let's us check for NULL Values","b60aca3e":"![](https:\/\/www.incimages.com\/uploaded_files\/image\/1920x1080\/getty_835271096_410065.jpg)","e0f9ee90":"# Using XGBoost","e9b83c31":"# SPLITTING THE DATASET INTO TRAIN AND TEST DATA"}}