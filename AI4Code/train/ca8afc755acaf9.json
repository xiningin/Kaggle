{"cell_type":{"8eac9772":"code","515dad7c":"code","51aabe2f":"code","a201d2ef":"code","16969410":"markdown","66ceb222":"markdown","d19cd11f":"markdown","7e96d7a1":"markdown","da754a3a":"markdown","44423c0a":"markdown","56bf7fbb":"markdown","bd276195":"markdown","09d2fe64":"markdown"},"source":{"8eac9772":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Read Data\ndata = pd.read_csv('..\/input\/melb_data.csv')\ncols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\nX = data[cols_to_use]\ny = data.Price\ntrain_X, test_X, train_y, test_y = train_test_split(X, y)\n\n","515dad7c":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer # Fill missing values, default mean\n\nmy_pipeline = make_pipeline(Imputer(), RandomForestRegressor())","51aabe2f":"my_pipeline.fit(train_X, train_y)\npredictions = my_pipeline.predict(test_X)","a201d2ef":"my_imputer = Imputer()\nmy_model = RandomForestRegressor()\n\nimputed_train_X = my_imputer.fit_transform(train_X)\nimputed_test_X = my_imputer.transform(test_X)\nmy_model.fit(imputed_train_X, train_y)\npredictions = my_model.predict(imputed_test_X)","16969410":"\nYou have a modeling process that uses an Imputer to fill in missing values, followed by a Random Forest Regressor to make predictions.  These can be bundled together with the **make_pipeline** function as shown below.","66ceb222":"# Conclusion\n- This is all I had about <b>Pipelines<\/b>.\nTHANK YOU","d19cd11f":"# Understanding Pipelines\nMost scikit-learn objects are either **transformers** or **models.** \n\n**Transformers** are for pre-processing before modeling.  The Imputer class (for filling in missing values) is an example of a transformer.  \n\n**Models** are used to make predictions. You will usually preprocess your data (with transformers) before putting it in a model.  \n\nYou can tell if an object is a transformer or a model by how you apply it.  After fitting a transformer, you apply it with the *transform* command.  After fitting a model, you apply it with the *predict* command. Your pipeline must start with transformer steps and end with a model.  This is what you'd want anyway.\n\nEventually you need  to apply more transformers and combine them more flexibly. ","7e96d7a1":"You can now fit and predict using this pipeline as a fused whole.","da754a3a":"# Example\n\nWe won't focus on the data loading. For now, you can imagine you are at a point where you already have train_X, test_X, train_y and test_y. ","44423c0a":"This particular pipeline was only a small improvement in code elegance. But pipelines become increasingly valuable as your data processing becomes increasingly sophisticated.","56bf7fbb":"# Introduction\n- In this kernel you will learn what are <b>Pipelines<\/b>, why are they used and implementation of <b>Pipelines<\/b> using <b>SkLearn<\/b>\n- We'll be using the <a href='https:\/\/www.kaggle.com\/dansbecker\/melbourne-housing-snapshot'>Melbourne Housing Data<\/a> which is a snapshot of the dataset created by <a href='https:\/\/www.kaggle.com\/anthonypino\/melbourne-housing-market'>Tony Pino<\/a>\n- Here's the link to the official document of <a href='https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.pipeline.Pipeline.html'>SkLearn's Pipeline<\/a>","bd276195":"\n# What Are Pipelines\n\nPipelines are a simple way to keep your data processing and modeling code organized.  Specifically, a pipeline bundles preprocessing and modeling steps, so you can use the whole bundle as if it is a single step.\n\nMany data scientists hack together models without pipelines, but Pipelines have some important benefits. Those include:\n1. **Cleaner Code:** You won't need to keep track of your training (and validation) data at each step of processing.  Accounting for data at each step of processing can get messy.  With a pipeline, you don't need to manually keep track of each step.\n2. **Fewer Bugs:** There are fewer opportunities to mis-apply a step or forget a pre-processing step.\n3. **Easier to Productionize:** It can be surprisingly hard to transition a model from a prototype to something deployable at scale.  We won't go into the many related concerns here, but pipelines can help.\n4. **More Options For Model Testing:** You will see an example in the next tutorial, which covers cross-validation.\n\n---","09d2fe64":"For comparison, here is the code to do the same thing without pipelines"}}