{"cell_type":{"25505a11":"code","21b116b9":"code","638b6f7c":"code","1c8bfa11":"code","51c92aa0":"code","0a9ac031":"code","1740dc27":"code","53776808":"code","7b47fc2a":"code","3bf2bb16":"code","ca11d166":"code","9381f8da":"code","518f51a2":"code","c44a0ff6":"code","40a8816f":"code","e81b4aad":"code","77766d72":"code","a600a92a":"code","e20d3716":"markdown","3005cbc8":"markdown","441a6404":"markdown"},"source":{"25505a11":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport math","21b116b9":"df = pd.read_csv(\"..\/input\/liverpool-ion-switching\/test.csv\")\ndf","638b6f7c":"n_groups = 40\ndf[\"group\"] = 0\nfor i in range(n_groups):\n    ids = np.arange(i*50000, (i+1)*50000)\n    df.loc[ids,\"group\"] = i","1c8bfa11":"for i in range(n_groups):\n    sub = df[df.group == i]\n    signals = sub.signal.values\n    imax, imin = math.floor(np.max(signals)), math.ceil(np.min(signals))\n    signals = (signals - np.min(signals))\/(np.max(signals) - np.min(signals))\n    signals = signals*(imax-imin) \n    df.loc[sub.index,\"open_channels\"] = [0,] + list(np.array(signals[:-1],np.int))","51c92aa0":"import matplotlib.pyplot as plt\n#distr=df.groupby('open_channels').count() \n\nplt.scatter(df['signal'],df['open_channels'] ,c=df.group)\nplt.show()\nfrom scipy.stats import boxcox\n","0a9ac031":"trdf = pd.read_csv(\"..\/input\/liverpool-ion-switching\/train.csv\")\n","1740dc27":"n_groups = 100\ntrdf[\"group\"] = 0\nfor i in range(n_groups):\n    ids = np.arange(i*50000, (i+1)*50000)\n    trdf.loc[ids,\"group\"] = i","53776808":"for i in range(n_groups):\n    sub = trdf[trdf.group == i]\n    signals = sub.signal.values\n    imax, imin = math.floor(np.max(signals)), math.ceil(np.min(signals))\n    signals = (signals - np.min(signals))\/(np.max(signals) - np.min(signals))\n    signals = signals*(imax-imin) \n    trdf.loc[sub.index,\"open_channel2\"] = [0,] + list(np.array(signals[:-1],np.int))","7b47fc2a":"plt.scatter(trdf[-500000:]['open_channel2'],trdf[-500000:]['open_channels'] ,c=trdf[-500000:]['group'])\nplt.show()\n","3bf2bb16":"plt.scatter(trdf[-500000:]['signal'],trdf[-500000:]['open_channels'] ,c=trdf[-500000:]['group'])\nplt.show()\n","ca11d166":"trdf","9381f8da":"lengte=50000\ntr=trdf[:lengte]\ntr['date']=pd.to_datetime((tr.time*1000000-1.469100e+06)*100, unit='ms')\n\nts = pd.Series(tr.signal.values, index=pd.DatetimeIndex(tr.date).to_period('ms'))\nts","518f51a2":"from statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n#Checking trend and autocorrelation\ndef initial_plots(time_series, num_lag):\n\n    #Original timeseries plot\n    plt.figure(1)\n    plt.plot(time_series)\n    plt.title('Original data across time')\n    plt.figure(2)\n    plot_acf(time_series, lags = num_lag)\n    plt.title('Autocorrelation plot')\n    plot_pacf(time_series, lags = num_lag)\n    plt.title('Partial autocorrelation plot')\n    \n    plt.show()\n\n    \n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\n#print('p-value: {}'.format(adfuller('date')[1]))\n\n#plotting\ninitial_plots(ts, 45)","c44a0ff6":"#Defining RMSE\ndef rmse(x,y):\n    return sqrt(mean_squared_error(x,y))\n\n#fitting ARIMA model on dataset\ndef SARIMAX_call(time_series,p_list,d_list,q_list,P_list,D_list,Q_list,s_list,test_period):    \n    \n    #Splitting into training and testing\n    training_ts = time_series[:-test_period]\n    \n    testing_ts = time_series[len(time_series)-test_period:]\n    \n    error_table = pd.DataFrame(columns = ['p','d','q','P','D','Q','s','AIC','BIC','RMSE'],\\\n                                                           index = range(len(ns_ar)*len(ns_diff)*len(ns_ma)*len(s_ar)\\\n                                                                         *len(s_diff)*len(s_ma)*len(s_list)))\n    count = 0\n    \n    for p in p_list:\n        for d in d_list:\n            for q in q_list:\n                for P in P_list:\n                    for D in D_list:\n                        for Q in Q_list:\n                            for s in s_list:\n                                #fitting the model\n                                SARIMAX_model = SARIMAX(training_ts.astype(float),\\\n                                                        order=(p,d,q),\\\n                                                        seasonal_order=(P,D,Q,s),\\\n                                                        enforce_invertibility=False)\n                                SARIMAX_model_fit = SARIMAX_model.fit(disp=0)\n                                AIC = np.round(SARIMAX_model_fit.aic,2)\n                                BIC = np.round(SARIMAX_model_fit.bic,2)\n                                predictions = SARIMAX_model_fit.forecast(steps=test_period,typ='levels')\n                                RMSE = rmse(testing_ts.values,predictions.values)                                \n                                print(p,d,q,P,D,Q,AIC,BIC,RMSE)\n                                #populating error table\n                                error_table['p'][count] = p\n                                error_table['d'][count] = d\n                                error_table['q'][count] = q\n                                error_table['P'][count] = P\n                                error_table['D'][count] = D\n                                error_table['Q'][count] = Q\n                                error_table['s'][count] = s\n                                error_table['AIC'][count] = AIC\n                                error_table['BIC'][count] = BIC\n                                error_table['RMSE'][count] = RMSE\n                                \n                                count+=1 #incrementing count        \n    \n    #returning the fitted model and values\n    return error_table\n\nns_ar = [0,1,2]\nns_diff = [1]\nns_ma = [0,1]#,2]\ns_ar = [0,1]\ns_diff = [0,1] \ns_ma = [1,2]\ns_list = [4]\n\nerror_table = SARIMAX_call(ts,ns_ar,ns_diff,ns_ma,s_ar,s_diff,s_ma,s_list,30)\nerror_table.sort_values(by='RMSE').head(15)","40a8816f":"import statsmodels.api as sm\n\nmod = sm.tsa.SARIMAX(ts,order = (0,1,1), seasonal_order=(0,0,1,4)).fit()\nmod.summary()","e81b4aad":"mod.plot_diagnostics()","77766d72":"sample_df = pd.read_csv(\"..\/input\/liverpool-ion-switching\/sample_submission.csv\", dtype={'time':str})","a600a92a":"sample_df.open_channels = np.array(df.open_channels, np.int)\nsample_df.to_csv(\"submission.csv\",index=False)","e20d3716":"# at first sight an impressive LB\n\nwhat does this mean ?","3005cbc8":"# Want to see the relationship ?\n\nindeed: at first sight we simply need to find the bottom\/min, find the max and disperse the solution\nand then there seems to me that the true problem is how do you forecast that variability ?","441a6404":"# not the most convincing solution h\u00e9\n\nthere is simply a remarkable low 'error' mesurement"}}