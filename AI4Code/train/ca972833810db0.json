{"cell_type":{"754f8ba0":"code","6d9ff658":"code","01171430":"code","51f69633":"code","2e4b22db":"code","5e5e56dd":"code","2f85b5e5":"code","3bee1e29":"code","cc36ee6a":"code","820f123d":"markdown","f8269161":"markdown","f1945649":"markdown","aa5b4082":"markdown","084f26a7":"markdown","9fc46e33":"markdown","1f831df9":"markdown"},"source":{"754f8ba0":"import cupy, cudf, matplotlib.pyplot as plt\ntrain_gf = cudf.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\n\nplt.title('Histogram of Train Pressures',size=14)\nplt.hist(train_gf.sample(100_000).pressure.to_array(),bins=100)\nplt.show()\nprint('Max pressure =',train_gf.pressure.max(), 'Min pressure =',train_gf.pressure.min())","6d9ff658":"all_pressure = cupy.sort( train_gf.pressure.unique().values )\nprint('The first 25 unique pressures...')\nPRESSURE_MIN = all_pressure[0].item()\nPRESSURE_MAX = all_pressure[-1].item()\nall_pressure[:25]","01171430":"print('The differences between first 25 pressures...')\nPRESSURE_STEP = ( all_pressure[1] - all_pressure[0] ).item()\nall_pressure[1:26] - all_pressure[:25]","51f69633":"import numpy as np\nimport pandas as pd\n\nimport optuna\n\nimport os \nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n# https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/274717\n\nimport tensorflow as tf, gc\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nfrom sklearn.metrics import mean_absolute_error as mae\nfrom sklearn.preprocessing import RobustScaler, normalize\nfrom sklearn.model_selection import train_test_split, GroupKFold, KFold\n\nfrom IPython.display import display\n\nDEBUG = False\nTRAIN_MODEL = False\n\ntrain = pd.read_csv('..\/input\/ventilator-pressure-prediction\/train.csv')\ntest = pd.read_csv('..\/input\/ventilator-pressure-prediction\/test.csv')\nsubmission = pd.read_csv('..\/input\/ventilator-pressure-prediction\/sample_submission.csv')\n\nif DEBUG:\n    train = train[:80*1000]","2e4b22db":"def add_features(df):\n    df['area'] = df['time_step'] * df['u_in']\n    df['area'] = df.groupby('breath_id')['area'].cumsum()\n    \n    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n    df = df.fillna(0)\n    \n    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n    \n    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n    df['cross']= df['u_in']*df['u_out']\n    df['cross2']= df['time_step']*df['u_out']\n    \n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n    df = pd.get_dummies(df)\n    return df\n\ntrain = add_features(train)\ntest = add_features(test)\n\ntargets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure', 'id', 'breath_id'], axis=1, inplace=True)\ntest = test.drop(['id', 'breath_id'], axis=1)\n\nRS = RobustScaler()\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","5e5e56dd":"EPOCH = 300\nBATCH_SIZE = 1024\nNUM_FOLDS = 10\n\ngpu_strategy = tf.distribute.get_strategy()\n\nwith gpu_strategy.scope():\n    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n    test_preds = []\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        K.clear_session()\n        \n        print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        \n        checkpoint_filepath = f\"folds{fold}.hdf5\"\n        if TRAIN_MODEL:\n            model = keras.models.Sequential([\n                keras.layers.Input(shape=train.shape[-2:]),\n                keras.layers.Bidirectional(keras.layers.LSTM(1024, return_sequences=True)),\n                keras.layers.Bidirectional(keras.layers.LSTM(512, return_sequences=True)),\n                keras.layers.Bidirectional(keras.layers.LSTM(256, return_sequences=True)),\n                keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n                keras.layers.Dense(128, activation='selu'),\n                keras.layers.Dense(1),\n            ])\n            model.compile(optimizer=\"adam\", loss=\"mae\")\n\n            lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n            es = EarlyStopping(monitor=\"val_loss\", patience=60, verbose=1, mode=\"min\", restore_best_weights=True)\n            sv = keras.callbacks.ModelCheckpoint(\n                checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n                save_weights_only=False, mode='auto', save_freq='epoch',\n                options=None\n            )\n            model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n        else:\n            model = keras.models.load_model('..\/input\/finetune-of-tensorflow-bidirectional-lstm\/'+checkpoint_filepath)\n            \n        test_preds.append(model.predict(test, batch_size=BATCH_SIZE, verbose=2).squeeze().reshape(-1, 1).squeeze())\n        \n        del model, X_train, X_valid; gc.collect()","2f85b5e5":"# ENSEMBLE FOLDS WITH MEAN\nsubmission[\"pressure\"] = sum(test_preds)\/NUM_FOLDS\nsubmission.to_csv('submission_mean_LB157.csv', index=False)\n\n# ENSEMBLE FOLDS WITH MEDIAN\nsubmission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\nsubmission.to_csv('submission_median_LB155.csv', index=False)\n\n# ENSEMBLE FOLDS WITH MEDIAN AND ROUND PREDICTIONS\nsubmission[\"pressure\"] =\\\n    np.round( (submission.pressure - PRESSURE_MIN)\/PRESSURE_STEP ) * PRESSURE_STEP + PRESSURE_MIN\nsubmission.pressure = np.clip(submission.pressure, PRESSURE_MIN, PRESSURE_MAX)\nsubmission.to_csv('submission_median_round_LB153.csv', index=False)","3bee1e29":"plt.title('Histogram of Test Pressures',size=14)\nplt.hist(submission.sample(10_000).pressure.values, bins=100)\nplt.show()\nprint('Max pressure =',submission.pressure.max(), 'Min pressure =',submission.pressure.min())","cc36ee6a":"all_pressure = np.sort( submission.pressure.unique() )\nprint('The differences between first 25 test pressures...')\nall_pressure[1:26] - all_pressure[:25]","820f123d":"# Load Data","f8269161":"# Train Targets are Discrete - EDA\nThe discovery that train targets are discrete was first published in discussion [here][1], then [here][2]\n\n[1]: https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/275897\n[2]: https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/discussion\/276083","f1945649":"# Infer Test Data","aa5b4082":"# Ensemble Folds with MEDIAN - [0.153]\nThis notebook is a fork of [Zhangxin's][1] notebook [here][2]. The purpose of this notebook is to demonstrate using **median** (instead of mean) to ensemble fold model predictions. Additionally it demonstrates \"rounding\" predictions to match the discrete target distribution observed in train data.\n\nSince the [competition metric][3] is MAE, using **median** is best. If the competition metric were RSME, then **mean** would be best.\n\nThe original notebook ensembles its 10 fold models with **mean** (instead of median) and achieves **LB 0.157**. By using **median** we boost the LB by **+0.002** and by using \"rounding\", we boost LB by **+0.002** too. Both of these tricks together boost LB a total **+0.004**!\n\n[1]: https:\/\/www.kaggle.com\/tenffe\n[2]: https:\/\/www.kaggle.com\/tenffe\/finetune-of-tensorflow-bidirectional-lstm\n[3]: https:\/\/www.kaggle.com\/c\/ventilator-pressure-prediction\/overview\/evaluation","084f26a7":"# Post Process with Median and Round","9fc46e33":"# Engineer Features","1f831df9":"# After PostProcess, Test Targets are Discrete - EDA"}}