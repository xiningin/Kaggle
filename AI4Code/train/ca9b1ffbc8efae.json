{"cell_type":{"b215f419":"code","10a647be":"code","861b139c":"code","e310b424":"code","590d3e1f":"code","8f6b6353":"code","564cc9ff":"code","c27e6653":"code","97d1d3d5":"code","5c211d16":"code","49303488":"code","b907f33b":"code","f4cf5474":"code","c44171d1":"code","0bf34189":"code","3d6dfc3f":"code","ea27e0ad":"code","e75cc012":"code","85edf24e":"code","7320044e":"code","d798d4a3":"code","0f944a73":"code","a44706e6":"markdown","ae6f03ed":"markdown","3769ec9c":"markdown"},"source":{"b215f419":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# clustering\nfrom sklearn.cluster import KMeans\n\n# time\nfrom pandas.tseries.holiday import USFederalHolidayCalendar\n# from sklearn.preprocessing import LabelEncoder\nimport datetime\n\n# training\nfrom sklearn.model_selection import train_test_split\n# import lightgbm as lgb\n\n# import environment for data\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n# Any results you write to the current directory are saved as output.","10a647be":"(market_train_df, news_train_df) = env.get_training_data()","861b139c":"market_train_df.head()","e310b424":"news_train_df.head()","590d3e1f":"market_train_df.shape","8f6b6353":"news_train_df.shape","564cc9ff":"news_train_df[\"time\"] = pd.to_datetime(news_train_df[\"time\"],infer_datetime_format=True)\nprint(\"time\")\nnews_train_df[\"sourceTimestamp\"] = pd.to_datetime(news_train_df[\"sourceTimestamp\"],infer_datetime_format=True)\nprint(\"sourceTimestamp\")\nnews_train_df[\"firstCreated\"] = pd.to_datetime(news_train_df[\"firstCreated\"],infer_datetime_format=True)\nprint(\"firstCreated\")","c27e6653":"news_train_df.dtypes","97d1d3d5":"## For now remove universe 0 rows. We could use the mfor context later though\n# returnsOpenNextMktres10\nprint(market_train_df.shape[0])\nmarket_train_df = market_train_df.loc[market_train_df.universe>0]\nprint(market_train_df.shape[0])","5c211d16":"market_assetName = set(market_train_df.assetName)\nprint(len(market_assetName))","49303488":"news_train_df.head()","b907f33b":"print(\"orig news shape:\",news_train_df.shape[0])\nnews_train_df = news_train_df.loc[news_train_df.assetName.isin(market_assetName)]\nnews_train_df.shape[0]","f4cf5474":"market_train_df.tail()","c44171d1":"market_train_df.drop(['universe'],axis=1,inplace=True)","0bf34189":"market_train_df.columns","3d6dfc3f":"market_train_df.tail()","ea27e0ad":"market_train_df[\"close_open_diff\"] = market_train_df[\"close\"]\/market_train_df[\"open\"]\nmarket_train_df[\"volume_money_mean\"] = (market_train_df[\"close\"]*market_train_df[\"volume\"] + market_train_df[\"open\"]*market_train_df[\"volume\"])\/2\n","e75cc012":"## Add extra target col - binary\nmarket_train_df[\"binary_returnsNextMktres10\"] = market_train_df[\"returnsOpenNextMktres10\"]>0","85edf24e":"## from : https:\/\/www.kaggle.com\/magichanics\/amateur-hour-using-headlines-to-predict-stocks\ndef clustering(df):\n\n    def cluster_modelling(features):\n        df_set = df[features]\n        cluster_model = KMeans(n_clusters = 9)\n        cluster_model.fit(df_set)\n        return cluster_model.predict(df_set)\n    \n    # get columns:\n    vol_cols = [f for f in df.columns if f != 'volume' and 'volume' in f]\n    novelty_cols = [f for f in df.columns if 'novelty' in f]\n    \n#     prev_returns_cols = [\"returnsClosePrevMktres1\",\"returnsOpenPrevRaw1\",\"returnsClosePrevMktres10\"] # mktRes have NaNs! \n    prev_returns_cols =[\"returnsOpenPrevRaw1\",\"returnsClosePrevRaw10\",\"returnsOpenPrevRaw10\"]\n    \n    # fill nulls\n    cluster_cols = novelty_cols + vol_cols + ['open', 'close']\n    df[cluster_cols] = df[cluster_cols].fillna(0)\n    \n    df['cluster_open_close'] = cluster_modelling(['open', 'close'])\n    df['cluster_volume'] = cluster_modelling(vol_cols)\n#     df['cluster_novelty'] = cluster_modelling(novelty_cols)\n    df['cluster_prev_returns'] = cluster_modelling(prev_returns_cols)\n    \n    return df","7320044e":"market_train_df = clustering(market_train_df)","d798d4a3":"market_train_df.tail(3)","0f944a73":"market_train_df.to_csv(\"market_train_uni1_v1.csv.gz\",index=False,compression=\"gzip\")\nnews_train_df.to_csv(\"news_market_train_uni1_v1.csv.gz\",index=False,compression=\"gzip\")","a44706e6":"## Clean data? \n* e.g. remove outliers of price change..","ae6f03ed":"## Export data","3769ec9c":"## Remove leak columns (could be added as context with an appropiate shift)\n* ( also add open\/close diff\n* Add clusters\n* add sum total feature"}}