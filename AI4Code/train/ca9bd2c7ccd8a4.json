{"cell_type":{"1f19edab":"code","e0f95e48":"code","df6512f6":"code","3a210b06":"code","71147cdd":"code","390f5070":"code","05780363":"code","6b796c91":"code","45afdd30":"code","9d2f594b":"code","8fb657d9":"code","882fbd9b":"markdown"},"source":{"1f19edab":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport tensorflow as tf\nfrom PIL import ImageFile\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \ntf.get_logger().setLevel('INFO')\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","e0f95e48":"train_datagen = ImageDataGenerator(\n                                    rescale=1.\/255,\n                                    horizontal_flip = True,\n                                    brightness_range=(0.8,1.2)\n                                    )\n\ntest_datagen = ImageDataGenerator(\n                                    rescale=1.\/255,\n                                    brightness_range=(0.8,1.2),\n                                    horizontal_flip = True,\n                                    )\n\n\ntraining_set = train_datagen.flow_from_directory(\n                                                 '..\/input\/faceshape-processed\/dataset\/train',\n                                                 target_size = (250,190),\n                                                 batch_size = 64,\n                                                 color_mode = 'grayscale',\n                                                 shuffle = True,\n                                                 class_mode = 'categorical'\n                                                 )\n\ntest_set = test_datagen.flow_from_directory(\n                                            '..\/input\/faceshape-processed\/dataset\/test',\n                                            target_size = (250,190),\n                                            batch_size = 64,\n                                            color_mode = 'grayscale',\n                                            shuffle=True,\n                                            class_mode = 'categorical'\n                                            )","df6512f6":"# Build model\n\nmodel = Sequential()\nmodel.add(Conv2D(8, (7, 7), activation='selu', padding=\"valid\", input_shape=(250,190,1)))\nmodel.add(Conv2D(8, (5, 5), activation='selu', padding=\"valid\"))\nmodel.add(MaxPooling2D(pool_size=(5,5),padding=\"valid\", strides=(2, 2)))\nmodel.add(MaxPooling2D(pool_size=(3,3),padding=\"valid\", strides=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='selu'))\nmodel.add(Dense(5, activation=\"softmax\"))\n\nmodel.summary()\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","3a210b06":"X_train, y_train = next(training_set)\nX_test, y_test = next(test_set)","71147cdd":"# Visualize convolution processing\nfrom tensorflow.keras.models import Model\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\nactivations = activation_model.predict(X_train[0].reshape(1,250,190,1))\n \ndef display_activation(activations, col_size, row_size, act_index): \n    activation = activations[act_index]\n    activation_index=0\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*4.5,col_size*2.5))\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n            activation_index += 1\ncol_size = 4\nrow_size = 2\nn_layers = 4\nfor layer_index in range(n_layers):#(len(model.layers)-10):\n    display_activation(activations, col_size, row_size, layer_index)","390f5070":"# Custom early stop\nclass ValAccEarlyStop(tf.keras.callbacks.Callback):\n    def __init__(self, threshold):\n        super(ValAccEarlyStop, self).__init__()\n        self.threshold = threshold\n\n    def on_epoch_end(self, epoch, logs=None): \n        val_acc = logs[\"val_accuracy\"]\n        if val_acc >= self.threshold:\n            self.model.stop_training = True","05780363":"# Training phase\nhistory = model.fit(\n                             training_set,\n                             epochs = 50,\n                             validation_data = test_set,\n                             shuffle = True,\n                            callbacks=[\n                                 ValAccEarlyStop(0.73)\n                             ]\n                            )","6b796c91":"# Evaluate Model\nscoreSeg = model.evaluate_generator(test_set)\nprint(\"Accuracy = \",scoreSeg[1])","45afdd30":"model.save(\"face-shape-recognizer.h5\")","9d2f594b":"# Visualize Loss & Accuracy\n\n%matplotlib inline\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","8fb657d9":"# Make some predictions on training data\n\nfrom tensorflow.keras.preprocessing import image\n\nlabels = list(training_set.class_indices)\n\nfor i in np.random.randint(X_train.shape[0], size=10):\n    img = image.img_to_array(X_train[i])\n    img = np.expand_dims(img, axis=0)\n    images = np.vstack([img])\n    y_pred = np.argmax(model.predict(img,verbose=0), axis=1)[0]\n    y_true = np.argmax(y_train[i])\n    plt.imshow(X_train[i])\n    plt.title(f\"Y true({labels[y_true]}) | Y pred ({labels[y_pred]})\")\n    plt.show()","882fbd9b":"# **NOTE**\n# Val_accuracy has a maximum of 75% \n(changing network architecture won't work);<br>\nBecause (after data investigation) I found that many samples are misclassifed & some samples are corrupted (face recognition & preprocessing issues)"}}