{"cell_type":{"c332e721":"code","938bcb84":"code","68830969":"code","bc90bbcc":"code","ffd20153":"code","5f74cd7c":"code","77442924":"code","01f5f22b":"code","efa3da6e":"code","9227d290":"code","f2bb0a1f":"code","49649a6d":"code","f127616d":"code","021358ca":"code","b33b32ae":"code","5cff67ff":"code","83b0a056":"code","3509e644":"code","b5e377a1":"code","e4350f87":"code","73d4cef9":"code","bfcb3f7f":"code","639f0ccb":"code","bdd0ea07":"code","75b091be":"code","20891eb4":"code","4710756a":"markdown","fa69bd07":"markdown","7254032d":"markdown","28464479":"markdown","a878b025":"markdown","09dfb517":"markdown","08e6939f":"markdown","b6cf8314":"markdown","f477fbb0":"markdown","ed2b6841":"markdown","ec7da745":"markdown","cf61de84":"markdown"},"source":{"c332e721":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","938bcb84":"df = pd.read_csv('\/kaggle\/input\/ccdata\/CC GENERAL.csv')\ndf.head()","68830969":"df.shape","bc90bbcc":"df.info()","ffd20153":"df.describe(include = 'all').T","5f74cd7c":"df.duplicated().sum()","77442924":"df_clus = df.drop('CUST_ID', axis = 1)\ndf_clus.info()","01f5f22b":"plt.figure(figsize = (20,16))\nFeatures = df_clus.columns\nfor i in range(len(Features)):\n    plt.subplot(6,3, i + 1)\n    sns.boxplot(y = df_clus[Features[i]], data = df_clus)\n    plt.title(f\"Boxplot of {Features[i]}\")\n    plt.tight_layout()","efa3da6e":"def detect_outliers(col):\n    Q1, Q3 = col.quantile([0.25,0.75])\n    IQR = Q3 - Q1\n    lower_range = Q1 - (1.5 * IQR)\n    upper_range = Q3 + (1.5 * IQR)\n    return lower_range, upper_range","9227d290":"Feature_list = df_clus.columns\nfor i in Feature_list:\n    lr, ur = detect_outliers(df_clus[i])\n    df_clus[i] = np.where(df_clus[i] > ur, ur,df_clus[i])\n    df_clus[i] = np.where(df_clus[i] < lr, lr,df_clus[i])","f2bb0a1f":"plt.figure(figsize = (20,16))\nFeatures = df_clus.columns\nfor i in range(len(Features)):\n    plt.subplot(6,3, i + 1)\n    sns.boxplot(y = df_clus[Features[i]], data = df_clus)\n    plt.title(f\"Boxplot of {Features[i]}\")\n    plt.tight_layout()","49649a6d":"df_clus.isnull().sum()","f127616d":"df_clus.CREDIT_LIMIT = df_clus.CREDIT_LIMIT.fillna(df_clus.CREDIT_LIMIT.median())\ndf_clus.MINIMUM_PAYMENTS = df_clus.MINIMUM_PAYMENTS.fillna(df_clus.MINIMUM_PAYMENTS.median())\ndf_clus.isnull().sum()","021358ca":"#Importing the necessary libraries \n\nfrom sklearn.preprocessing import StandardScaler","b33b32ae":"#Intilizing object of StandardScaler\n \nzscore = StandardScaler() \nzscore.fit(df_clus)\ndf_clus_scaled= pd.DataFrame(zscore.transform(df_clus),columns = df_clus.columns)\ndf_clus_scaled.describe().T","5cff67ff":"from sklearn.cluster import KMeans","83b0a056":"wss = []\nfor i in range(1,11):\n    k_means = KMeans(n_clusters = i)\n    k_means.fit(df_clus_scaled)\n    wss.append(k_means.inertia_)\n    print(f\"The inertia of {i} clusters : {k_means.inertia_}\")","3509e644":"plt.plot(range(1,11),wss, marker='o', linestyle='dashed',\n...      linewidth=2, markersize=8);","b5e377a1":"from sklearn.metrics import silhouette_samples, silhouette_score","e4350f87":"sil_score = []\nsil_width_min = []\nfor i in range(2,11):\n    k_means = KMeans(n_clusters = i,random_state = 123)\n    k_means.fit(df_clus_scaled)\n    labels = k_means.labels_\n    score = silhouette_score(df_clus_scaled,labels, random_state = 123)\n    sil_score.append(score)\n    print(f\"The Silhouette Score of {i} clusters : {score}\")\n    min_width = silhouette_samples(df_clus_scaled,labels).min()\n    sil_width_min.append(min_width)\n    print(f\"The Silhouette Width of {i} clusters : {min_width}\")","73d4cef9":"plt.figure(figsize = (18,4))\nplt.subplot(1,2,1)\nplt.plot(range(2,11),sil_score, marker='o', linestyle='dashed',linewidth=2, markersize=8);\nplt.subplot(1,2,2)\nplt.plot(range(2,11),sil_width_min, marker='o', linestyle='dashed',linewidth=2, markersize=8);","bfcb3f7f":"k_Means4 = KMeans(n_clusters = 3,random_state = 123)\nk_Means4.fit(df_clus_scaled)\nlabels = k_Means4.labels_\ndf['Cluster_Labels_3'] = labels\ndf.head(3)","639f0ccb":"silhouette_score(df_clus_scaled,labels,random_state = 123)","bdd0ea07":"sil_width = silhouette_samples(df_clus_scaled,labels)\ndf['Sil_Width_3'] = sil_width\nsil_width.min()","75b091be":"df_out = df.groupby(by = 'Cluster_Labels_3').sum()[['PURCHASES','PAYMENTS','TENURE']].reset_index()\ndf_out.head(3)","20891eb4":"sns.set_style(\"darkgrid\")\nplt.figure(figsize = (18,4))\nplt.subplot(1,3,1)\nsns.barplot(x= 'Cluster_Labels_3',y = 'PURCHASES', data = df_out, palette = 'crest', seed = 123);\nplt.subplot(1,3,2)\nsns.barplot(x= 'Cluster_Labels_3',y = 'PAYMENTS', data = df_out, palette = 'crest', seed = 123);\nplt.subplot(1,3,3)\nsns.barplot(x= 'Cluster_Labels_3',y = 'TENURE', data = df_out, palette = 'crest', seed = 123);","4710756a":"## Checking for Outliers","fa69bd07":"## Treat Missing Values","7254032d":"**** End ****","28464479":"### Observations\n1. The missing values are present in the fields : CREDIT_LIMIT and MINIMUM_PAYMENTS.\n2. I will use median() to fill the null fields.","a878b025":"### Observations\n1. The value ranges vary among fields, hence scaling is required.\n2. No Bad values observed\n3. CUST_ID is all unique\n\n## Checking for Duplicates","09dfb517":"## Scaling of Data using z-score method","08e6939f":"## Observations\n1. The silhouette_score is highest with 3 numbers of clusters and lowest for 9 & 10 number of clusters.\n2. The Minimum silhouette Width, all the values for all the clusters in analysis are negatives, with minimum value at n = 9 and maximum at n = 2.\n\n**Hence lets form an analysis with n_clusters = 3.**\n## KMeans with clusters = 3","b6cf8314":"No Duplicates present in the dataframe.\n## Drop unique columns for Analysis","f477fbb0":"## Observations\n1. Cluster 0 : It is highest amounts for Tenure, medium for Purchases, whereas lowest for Payments.\n2. Cluster 1 : It is lowest for Purchases,whereas medium for Tenure & Payments.\n3. Cluster 2 : It is highest for Purchases & Payments, whereas lowest for Tenure.","ed2b6841":"### Observations\n1. The Outliers are present in all the fields except : PURCHASES_FREQUENCY, PURCHASES_INSTALLMENTS_FREQUENCY.\n\n## Removing Outliers","ec7da745":"### Observations\n1. We have 8950 rows and 18 columns\n2. We have float64(14), int64(3), object(1)\n3. MINIMUM_PAYMENTS field has null values\n\n## Descriptive Stats","cf61de84":"### Observations:\nFrom the above plot, we can see, there is a sharp decrease in the inertia from cluster = 1 till cluster= 4, Hence we can either choose 3 or 4 clusters. But we will verify the silhouette_score for clusters upto 10.\n\n## Predicting KMean and silhouette_score with n clusters"}}