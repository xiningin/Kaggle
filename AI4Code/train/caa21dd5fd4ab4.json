{"cell_type":{"6468f8b4":"code","5fb0f8ec":"code","d2eb05c1":"code","24934322":"code","b9d67c90":"code","e99e438d":"code","793ca3a1":"code","71b4aec9":"code","475bdafd":"code","ee6878bf":"code","3f11529e":"code","3a78cb8a":"code","5abdbd59":"code","d74247ff":"code","2bda1fcc":"code","fc314665":"code","b821e47a":"code","097f14a5":"code","77f6ba19":"code","97c10b6e":"code","a4ca617c":"code","f417683c":"markdown","1159ba3c":"markdown","62b181a6":"markdown","64ccdd78":"markdown","d5144671":"markdown","289bdf03":"markdown"},"source":{"6468f8b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5fb0f8ec":"import numpy as np\nimport pandas as pd\nfrom pandas import Series,DataFrame \nimport os\nimport matplotlib.pylab as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nimport sklearn.metrics\nimport seaborn as sns","d2eb05c1":"data=pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-prognostic-data-set\/data 2.csv')","24934322":"#Get some information regarding the data\ndata.info","b9d67c90":"data=pd.DataFrame(data)\ndata_train =data.drop(columns = ['id','diagnosis','Unnamed: 32'])","e99e438d":"data_train","793ca3a1":"#Creating  a new variable {disease_type} \ndisease_type = data['diagnosis'].astype('category')\ndisease_type\n","71b4aec9":"#Visualize the data in order to see the count of both the categories\nsns.countplot(x='diagnosis',data=data,palette='Set2')\n","475bdafd":"#Replacing the targets with 0 and 1\ntargets=disease_type.replace(('M','B'),(1,0))\ntargets","ee6878bf":"x_train,x_test,y_train,y_test = train_test_split(data_train,targets,test_size =0.4)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","3f11529e":"from sklearn.linear_model import LogisticRegression\nclassifier=LogisticRegression()\nclassifier=classifier.fit(x_train,y_train)","3a78cb8a":"prediction= classifier.predict(x_test)\nprediction\nprint(classification_report(y_test,prediction))","5abdbd59":"x_train,x_test,y_train,y_test = train_test_split(data_train,targets,test_size =0.4)\n\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","d74247ff":"print (y_train.value_counts(sort=False, normalize=False))\nprint(y_test.value_counts(sort=False, normalize=False))\n","2bda1fcc":"#Decision Tree\n\n\nclassifier = DecisionTreeClassifier()\n\nclassifier = classifier.fit(x_train,y_train)\n\nprediction = classifier.predict(x_test)\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nprint(classification_report(y_test,prediction))\nprint (confusion_matrix(y_test,prediction))\nprint (accuracy_score(y_test,prediction))","fc314665":"from sklearn import tree\nfig = plt.figure(figsize=(30,15))\n_ = tree.plot_tree(classifier, \n                   feature_names=x_train.columns.values, \n                     class_names = ['metastatic','benign'],\n                   filled=True)","b821e47a":"from sklearn.ensemble import RandomForestClassifier\nclassifier=RandomForestClassifier(n_estimators=25)\nclassifier=classifier.fit(x_train,y_train)\n\npredictions=classifier.predict(x_test)\n\n# 3.2.3 Random Forest Accuracy\nsklearn.metrics.accuracy_score(y_test, predictions) #0.57\n","097f14a5":"from sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier()\nmodel.fit(x_train,y_train)","77f6ba19":"var_name = (x_train.columns.tolist())\nvar_sig = (list(model.feature_importances_))\n","97c10b6e":"print(var_name)\nvar_sig","a4ca617c":"import matplotlib.pylab as plt\ntrees=range(25)\naccuracy=np.zeros(25)\n\nfor idx in range(len(trees)):\n    classifier=RandomForestClassifier(n_estimators=idx + 1)\n    classifier=classifier.fit(x_train,y_train)\n    predictions=classifier.predict(x_test)\n    accuracy[idx]=sklearn.metrics.accuracy_score(y_test, predictions)\nplt.cla()  \nplt.plot(trees, accuracy)\nplt.ylabel('Accuracy')\nplt.xlabel('Number of Trees')\n","f417683c":"Predicting the given data using logistic regression","1159ba3c":"Import all the essential libraries.....","62b181a6":"Predicting the data using decision tree classifier and visualizing the tree\n\\\nNOTE : the accuracy may or may not improve . This is primarily not because of the data and the sample features which have been used it's based on the model being used","64ccdd78":"Based on the above classifications on the data decision tree model has more accuracy than logistic regression model .Decisiontree is mostly used to help identify a strategy most likely to reach a goal","d5144671":"As you can see the data ,it is clear that there are some reduntant features,(For example radius and radius mean of the cell nucleous )they may or may not effect the performance of the model.For instance let us consider six features which might play a key role in predicting the labels accurately.We may also consider only few features based on our system computational efficiency .  ","289bdf03":"According to the above figure ,approximately 25 is the optimum value for the number of trees to be considered.\nNote : results may vary differently as the samples are taken randomly "}}