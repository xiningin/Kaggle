{"cell_type":{"6b82beb0":"code","42d3fa5e":"code","9d900660":"code","b3aac384":"code","4b8b1e3f":"code","818de506":"code","fa356689":"code","0ce17124":"markdown"},"source":{"6b82beb0":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import KNNImputer, SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import KFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_recall_curve, auc, roc_curve\nfrom catboost import Pool, CatBoostClassifier, cv, CatBoostRegressor\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","42d3fa5e":"train_data = pd.read_csv('..\/input\/iba-ml1-mid-project\/train.csv')\ntest_data=pd.read_csv('..\/input\/iba-ml1-mid-project\/test.csv')","9d900660":"train_data['credit_line_utilization'].replace(',','.',regex=True, inplace=True)\ntrain_data[\"credit_line_utilization\"] = pd.to_numeric(train_data[\"credit_line_utilization\"])\n\ntest_data['credit_line_utilization'].replace(',','.',regex=True, inplace=True)\ntest_data[\"credit_line_utilization\"] = pd.to_numeric(test_data[\"credit_line_utilization\"])","b3aac384":"train_data.drop(labels='Id', axis=1, inplace=True)","4b8b1e3f":"variables = ['credit_line_utilization', 'number_of_previous_late_payments_up_to_59_days','number_of_previous_late_payments_up_to_89_days',\n             'number_of_previous_late_payments_90_days_or_more','age','number_dependent_family_members', 'monthly_income', 'number_of_credit_lines', 'real_estate_loans',\n             'ratio_debt_payment_to_income']\ntarget = 'defaulted_on_loan'\ntrain_data[variables] = SimpleImputer(strategy='median').fit_transform(train_data[variables])\ntrain_data.isnull().sum()\n\nX = train_data[variables]\ny = train_data[target]\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1999, train_size=0.6)","818de506":"catb = CatBoostClassifier(silent=True, iterations=2000, learning_rate=0.01, l2_leaf_reg=3.5, depth=8, rsm=0.98, loss_function='Logloss', eval_metric='AUC',use_best_model=True,random_seed=42)\ncate_features_index = np.where(X.dtypes != float)[0]\ncatb.fit(X_train, y_train,cat_features=cate_features_index,eval_set=(X_test,y_test))\n\ny_pred = catb.predict(X_test)\ny_pred_proba = catb.predict_proba(X_test)\n\nfpr, tpr, threshold = roc_curve(y_test, y_pred_proba[:,1])\nroc_auc = auc(fpr, tpr)\n\n#plotting ROC and getting AUC value\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","fa356689":"\nX = test_data[variables]\n\nX[variables]=SimpleImputer(strategy='median').fit_transform(X[variables])\n\ntrial = catb.predict_proba(X)[:,1:]\ntrial_df=pd.DataFrame(trial)\ntrial_df.index = trial_df.index+1 \ntrial_df.columns=['Predicted']\ntrial_df.to_csv('trial17.csv', index_label='Id')","0ce17124":"now comparing all these results, CatBoostClassifier gave the best result. Using grid search we can find the best result for it to fit. But also from my observations, removing outliers also have negative effect on the model results. So I will not remove the outliers."}}