{"cell_type":{"9ca38927":"code","e24633c9":"code","26f5ea97":"code","f10969d7":"code","3be98fab":"code","4f11aedc":"code","90b0a04f":"code","b50981a9":"code","e7bfff75":"code","6210533a":"code","efde7226":"code","75deec3f":"code","2cee7513":"code","54da4119":"code","7b980d52":"code","04ea7c44":"code","34f1f4e1":"code","ac94aac8":"code","74c0cc56":"code","5c8247fe":"code","144955aa":"code","ca63d8d1":"code","3b6a5107":"code","e32aad5f":"code","704e5027":"code","65a4e51f":"code","1ef7cbe8":"code","60a84f12":"code","62c439ca":"code","447c9da1":"code","e79cd870":"code","88373cad":"code","de59c860":"code","99ee1cd2":"code","4e61f44f":"code","d9d1d6b6":"code","0e23b53d":"code","4432b73f":"code","bbc0351b":"code","f97ec3f2":"code","00eb73da":"code","273b9eed":"code","46556bdd":"code","56bc2e13":"code","b110de69":"code","c448652e":"code","a2f28ac2":"code","118bb5f4":"code","47a3d244":"code","ce57c6a6":"code","d06005dc":"code","94fb380f":"code","266af372":"code","75cf49ab":"code","41b85e24":"code","e8284193":"code","c9bcb3b9":"code","88b0296b":"code","079b620f":"code","51c75e79":"code","7246e7d6":"code","4a3aa96a":"code","6e2147b0":"code","33c4d215":"code","d4246e89":"code","052ef544":"code","7a1e088e":"code","eb6e72ad":"code","74491846":"code","18d34a6a":"code","eecc7ed9":"code","871294f3":"code","83012d99":"code","31a50d62":"code","3ae276d8":"code","0d49dda6":"code","c9aa72cf":"code","eedaa112":"code","2d6883c5":"code","35e84409":"code","02ea4fb9":"code","2f55ce0b":"code","c2f9ac4a":"code","a11bea54":"code","7fd11b0f":"code","12499156":"code","8f938e22":"code","de3f42ee":"markdown","f64328db":"markdown","7560be8e":"markdown","04c00f63":"markdown","f5ab403b":"markdown","f3a112ef":"markdown","f12b2112":"markdown","bc9aba46":"markdown","61e095a2":"markdown","99cbefc5":"markdown","a23ff54f":"markdown","b2aeafd5":"markdown","7db58d29":"markdown","7af388b5":"markdown","7467698b":"markdown","a3206c4b":"markdown","88f85854":"markdown","421ad0cd":"markdown","f386fdd1":"markdown","968979a3":"markdown","09484ab2":"markdown","ef6eacdd":"markdown","e826b3bf":"markdown","fe8d3d82":"markdown","316376e2":"markdown","fcf0275c":"markdown","29bc53db":"markdown","c41f11e8":"markdown","30dd3bf8":"markdown","a3a0fb48":"markdown","d84a9ae4":"markdown","b0c3f63a":"markdown","8f334f2c":"markdown","3fa97c34":"markdown","7489cfd1":"markdown","e761fe8d":"markdown","50dba15e":"markdown","69177c58":"markdown","21730879":"markdown","d48ea970":"markdown","cf737961":"markdown","52d8b7e3":"markdown","b33481f3":"markdown","b59c9f00":"markdown","64b77cb6":"markdown","a5fbe6d4":"markdown","619274e8":"markdown","3c953acd":"markdown","d0a2ef62":"markdown","36c9fdf5":"markdown","fbfea49d":"markdown","67ffd9e6":"markdown","669091b0":"markdown","c0f76e85":"markdown","cecc3df0":"markdown","c0664900":"markdown","f84ff5f8":"markdown","4b23a387":"markdown","f29f38c8":"markdown","2e0ce7d5":"markdown","e944d7b7":"markdown","b57453d5":"markdown","cba45bab":"markdown","ce0655f3":"markdown","ca5e88e7":"markdown","51a1f67d":"markdown","4823e93c":"markdown","ed3b0b39":"markdown","e89d90d9":"markdown","b80fb1a5":"markdown","fc4ba0cf":"markdown","771b5f5f":"markdown","b7f6a8f9":"markdown","c5178f9c":"markdown","6f8792b9":"markdown","99503cd4":"markdown","72bf7347":"markdown","4785c7c4":"markdown","83122a01":"markdown","080027e0":"markdown","3e3d87bd":"markdown","9de32c8e":"markdown","bdb2388e":"markdown","79e29724":"markdown"},"source":{"9ca38927":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score","e24633c9":"# Definiamo il percorso dove andare a leggere il dataset\nurl = '..\/input\/classificazione-dei-vini\/wine.data'\n\n# Assegniamo i nomi di colonna al dataset\nnames = ['class', 'alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280\/OD315 of diluted wines', 'Proline']\n\n# Leggiamo il dataset dal pandas dataframe\ndataset = pd.read_csv(url, names = names)","26f5ea97":"dataset.head()","f10969d7":"dataset.describe()","3be98fab":"# true se sono presenti valori vuoti, falso altrimenti\ndataset.isnull().values.any()","4f11aedc":"dataset.isnull().sum()","90b0a04f":"# Numero di voci dataset (righe,colonne)\nprint(dataset.shape)","b50981a9":"# Numero di valori univoci in ogni colonna\nprint(dataset.nunique())","e7bfff75":"Q1 = dataset.quantile(0.25)\nQ3 = dataset.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","6210533a":"(dataset < (Q1 - 1.5 * IQR)) |(dataset > (Q3 + 1.5 * IQR))","efde7226":"plt.boxplot(dataset[\"alcohol\"])\nplt.show()\n\nplt.boxplot(dataset[\"Malic acid\"])\nplt.show()\n\nplt.boxplot(dataset[\"Ash\"])\nplt.show()\n\nplt.boxplot(dataset[\"Alcalinity of ash\"])\nplt.show()\n\nplt.boxplot(dataset[\"Magnesium\"])\nplt.show()\n\nplt.boxplot(dataset[\"Total phenols\"])\nplt.show()\n\nplt.boxplot(dataset[\"Flavanoids\"])\nplt.show()\n\nplt.boxplot(dataset[\"Nonflavanoid phenols\"])\nplt.show()\n\nplt.boxplot(dataset[\"Proanthocyanins\"])\nplt.show()\n\nplt.boxplot(dataset[\"Color intensity\"])\nplt.show()\n\nplt.boxplot(dataset[\"Hue\"])\nplt.show()\n\nplt.boxplot(dataset[\"OD280\/OD315 of diluted wines\"])\nplt.show()\n\nplt.boxplot(dataset[\"Proline\"])\nplt.show()","75deec3f":"print(dataset['Malic acid'].quantile(0.10))\nprint(dataset['Malic acid'].quantile(0.90))\n","2cee7513":"dataset[\"Malic acid\"] = np.where(dataset[\"Malic acid\"] <1.2469999999999999, 1.2469999999999999,dataset['Malic acid'])\ndataset[\"Malic acid\"] = np.where(dataset[\"Malic acid\"] >3.983, 3.983,dataset['Malic acid'])\nprint(dataset['Malic acid'].skew())","54da4119":"print(dataset['Ash'].quantile(0.10))\nprint(dataset['Ash'].quantile(0.90))","7b980d52":"dataset[\"Ash\"] = np.where(dataset[\"Ash\"] <2.0, 2.0,dataset['Ash'])\ndataset[\"Ash\"] = np.where(dataset[\"Ash\"] >2.7, 2.7,dataset['Ash'])\nprint(dataset['Ash'].skew())","04ea7c44":"print(dataset['Alcalinity of ash'].quantile(0.10))\nprint(dataset['Alcalinity of ash'].quantile(0.90))","34f1f4e1":"dataset[\"Alcalinity of ash\"] = np.where(dataset[\"Alcalinity of ash\"] <16.0, 16.0,dataset['Alcalinity of ash'])\ndataset[\"Alcalinity of ash\"] = np.where(dataset[\"Alcalinity of ash\"] >24.0, 24.0,dataset['Alcalinity of ash'])\nprint(dataset['Alcalinity of ash'].skew())","ac94aac8":"print(dataset['Magnesium'].quantile(0.10))\nprint(dataset['Magnesium'].quantile(0.90))","74c0cc56":"dataset[\"Magnesium\"] = np.where(dataset[\"Magnesium\"] <85.0, 85.0,dataset['Magnesium'])\ndataset[\"Magnesium\"] = np.where(dataset[\"Magnesium\"] >118.0, 118.0,dataset['Magnesium'])\nprint(dataset['Magnesium'].skew())","5c8247fe":"\nprint(dataset['Proanthocyanins'].quantile(0.10))\nprint(dataset['Proanthocyanins'].quantile(0.90))","144955aa":"dataset[\"Proanthocyanins\"] = np.where(dataset[\"Proanthocyanins\"] <0.8540000000000001, 0.8540000000000001,dataset['Proanthocyanins'])\ndataset[\"Proanthocyanins\"] = np.where(dataset[\"Proanthocyanins\"] >2.3050000000000006, 2.3050000000000006,dataset['Proanthocyanins'])\nprint(dataset['Proanthocyanins'].skew())","ca63d8d1":"print(dataset['Color intensity'].quantile(0.10))\nprint(dataset['Color intensity'].quantile(0.90))","3b6a5107":"dataset[\"Color intensity\"] = np.where(dataset[\"Color intensity\"] <2.549, 2.549,dataset['Color intensity'])\ndataset[\"Color intensity\"] = np.where(dataset[\"Color intensity\"] >8.530000000000001, 8.530000000000001,dataset['Color intensity'])\nprint(dataset['Color intensity'].skew())","e32aad5f":"print(dataset['Hue'].quantile(0.10))\nprint(dataset['Hue'].quantile(0.90))","704e5027":"dataset[\"Hue\"] = np.where(dataset[\"Hue\"] <0.61, 0.61,dataset['Hue'])\ndataset[\"Hue\"] = np.where(dataset[\"Hue\"] >1.233, 1.233,dataset['Hue'])\nprint(dataset['Hue'].skew())","65a4e51f":"import seaborn as sns\ncorr = dataset.corr()\nplt.subplots(figsize = (10, 8))\nsns.heatmap(corr,\n            xticklabels=corr.columns.drop('class').values,\n            yticklabels=corr.columns.drop('class').values,\n            annot = True, annot_kws={'size': 12})\n","1ef7cbe8":"corr = dataset.corr()\nplt.subplots(figsize = (10, 8))\nsns.heatmap(corr[((corr >= 0.3) | (corr <= -0.3)) & (corr != 1)], xticklabels=corr.columns.drop('class').values,\n            yticklabels=corr.columns.drop('class').values,annot=True, linewidths=.5, fmt= '.2f')\nplt.title('Configured Corelation Matrix');","60a84f12":"x = dataset.iloc[:, 1:14].values\ny = dataset.iloc[:, 0].values\nprint(x.shape)\nprint(y.shape)","62c439ca":"from sklearn.model_selection import train_test_split\n\n# Suddivisione del set di dati in 80% in dati di allenamento e 20% in dati di test\n# x = feature\n# y = target\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.20, random_state = 0)\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)","447c9da1":"print(\"Class 1 numbers: \" , len(y_train[y_train==1]))\nprint(\"Class 2 numbers: \" , len(y_train[y_train==2]))\nprint(\"Class 3 numbers: \" , len(y_train[y_train==3]))","e79cd870":"from imblearn.over_sampling import SMOTE\n\n# esegue sovracampionamento usando SMOTE\nsm = SMOTE(random_state = 0)\n\n#sovracampionamento casuale\nx_train_res, y_train_res = sm.fit_resample(x_train, y_train)\n\nprint(\"Class 1 numbers: \" , len(y_train_res[y_train_res==1]))\nprint(\"Class 2 numbers: \" , len(y_train_res[y_train_res==2]))\nprint(\"Class 3 numbers: \" , len(y_train_res[y_train_res==3]))\n","88373cad":"from sklearn.preprocessing import StandardScaler\n\n# Classe StandarScaler che permette di standardizzare i dati di allenamento e i test per renderli uniformi e confrontabili tra di loro\nscaler = StandardScaler()\n\n#Calcola la media e lo std da utilizzare per il successivo ridimensionamento.\nscaler.fit(x_train) \n\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","de59c860":"from sklearn.tree import DecisionTreeClassifier\n\n# List of values to try for max_depth:\nmax_depth_range = list(range(1, 6))\n# List to store the average RMSE for each value of max_depth:\naccuracy = []\nfor depth in max_depth_range:\n    \n    clf = DecisionTreeClassifier(max_depth = depth, \n                             random_state = 0)\n    clf.fit(x_train, y_train)\n    score = clf.score(x_test, y_test)\n    accuracy.append(score)\n    print(score)","99ee1cd2":"classifierDT = DecisionTreeClassifier(max_depth=3)\n\n# adatto il modello\nclassifierDT.fit(x_train, y_train)","4e61f44f":"y_predDT = classifierDT.predict(x_test)","d9d1d6b6":"summation = 0\nn = len(y_test)\nfor i in range(0,n):\n    difference = y_test[i] - y_predDT[i]\n    summation = summation + difference\nprint(summation)","0e23b53d":"from sklearn.metrics import mean_absolute_error\n\nmean_absolute_error(y_test, y_predDT)","4432b73f":"summation = 0\nn = len(y_test)\nfor i in range(0,n):\n    difference = y_test[i] - y_predDT[i]\n    squared_difference = difference**2\n    summation = summation + squared_difference\nprint(summation)","bbc0351b":"from sklearn.metrics import plot_confusion_matrix\n\nclass_names = [1,2,3]\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifierDT, x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","f97ec3f2":"def perf_measure(y_actual, y_hat):\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n    \n    for i in range(len(y_hat)): \n        if y_actual[i]==y_hat[i]==1:\n           TP += 1\n        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n           FP += 1\n        if y_actual[i]==y_hat[i]==0:\n           TN += 1\n        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n           FN += 1\n\n    return(TP, FP, TN, FN)","00eb73da":"perf_measure(y_test, y_predDT)","273b9eed":"print(classification_report(y_test, y_predDT))","46556bdd":"print(accuracy_score(y_test, y_predDT))","56bc2e13":"def plot_roc_curve(fpr, tpr):\n    plt.plot(fpr, tpr, color='orange', label='ROC')\n    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC) Curve')\n    plt.legend()\n    plt.show()","b110de69":"probs = classifierDT.predict_proba(x_train)","c448652e":"probs = probs[:, 1]","a2f28ac2":"auc = roc_auc_score(y_test, probs)\nprint('AUC: %.2f' % auc)","118bb5f4":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, probs)","47a3d244":"plot_roc_curve(fpr, tpr)","ce57c6a6":"from sklearn import tree\ntree.plot_tree(classifierDT) ","d06005dc":"from sklearn.neighbors import KNeighborsClassifier","94fb380f":"error = []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(x_train, y_train)\n    pred_i = knn.predict(x_test)\n    error.append(np.mean(pred_i != y_test))","266af372":"plt.figure(figsize = (12, 6))\nplt.plot(range(1, 40), error, color='red', linestyle = 'dashed', marker = 'o',\n        markerfacecolor = 'blue', markersize = 10)\nplt.title('Error rate K Value')\n\nplt.xlabel('K Value')\n\nplt.ylabel('Mean Error')","75cf49ab":"classifier = KNeighborsClassifier(n_neighbors = 9)\nclassifier.fit(x_train, y_train)","41b85e24":"y_pred = classifier.predict(x_test)","e8284193":"from sklearn.metrics import plot_confusion_matrix\n\nclass_names = [1,2,3]\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifier, x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","c9bcb3b9":"print(classification_report(y_test, y_pred))\n","88b0296b":"print(accuracy_score(y_test, y_pred))","079b620f":"from sklearn.ensemble import RandomForestClassifier\nclassifierRF = RandomForestClassifier(max_depth=2, random_state=0)\nclassifierRF.fit(x_train, y_train)","51c75e79":"y_predRF = classifierRF.predict(x_test)","7246e7d6":"from sklearn.metrics import plot_confusion_matrix\n\nclass_names = [1,2,3]\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifierRF, x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","4a3aa96a":"print(classification_report(y_test, y_predRF))","6e2147b0":"#indica la frazione dei campioni predetti correttamente\nprint(accuracy_score(y_test, y_predRF))","33c4d215":"column = [ 'alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280\/OD315 of diluted wines', 'Proline ']\n\nimportances = classifierRF.feature_importances_\nfeature_imp = pd.Series(classifierRF.feature_importances_, index = column).sort_values(ascending = False)\nprint(feature_imp)","d4246e89":"import seaborn as sns\n\nsns.barplot(x = feature_imp, y=feature_imp.index)\nplt.xlabel('Punteggion di importanza delle caratteristiche')\nplt.ylabel('Caratteristiche')\nplt.title('Visualizzazione caratteristiche per importanza')\nplt.show()","052ef544":"from sklearn import svm\nclassifierSV = svm.SVC(kernel = 'linear')\nclassifierSV.fit(x_train, y_train)","7a1e088e":"y_predSV = classifierSV.predict(x_test)","eb6e72ad":"from sklearn.metrics import plot_confusion_matrix\n\nclass_names = [1,2,3]\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifierSV, x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","74491846":"print(classification_report(y_test, y_predSV))","18d34a6a":"print(accuracy_score(y_test, y_predSV))","eecc7ed9":"from sklearn.naive_bayes import GaussianNB\n\nclassifierNB = GaussianNB()\nclassifierNB.fit(x_train, y_train)","871294f3":"y_predNB = classifierNB.predict(x_test)","83012d99":"from sklearn.metrics import plot_confusion_matrix\n\nclass_names = [1,2,3]\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifierNB, x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","31a50d62":"print(classification_report(y_test, y_predNB))","3ae276d8":"print(accuracy_score(y_test, y_predNB))","0d49dda6":"print(accuracy_score(y_test, y_predDT))","c9aa72cf":"from sklearn.neural_network import MLPClassifier\nclassifierNN = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\nclassifierNN.fit(x_train, y_train)","eedaa112":"y_predNN = classifierNN.predict(x_test)","2d6883c5":"class_names = [1,2,3]\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifierNN, x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","35e84409":"print(classification_report(y_test, y_predNN))","02ea4fb9":"print(accuracy_score(y_test, y_predNN))","2f55ce0b":"from sklearn.ensemble import GradientBoostingClassifier\nclassifierGB = GradientBoostingClassifier(random_state=0)\nclassifierGB.fit(x_train, y_train)","c2f9ac4a":"y_predGB = classifierGB.predict(x_test)","a11bea54":"class_names = [1,2,3]\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(classifierGB, x_test, y_test,\n                                 display_labels=class_names,\n                                 cmap=plt.cm.Blues,\n                                 normalize=normalize)\n    disp.ax_.set_title(title)\n\n    print(title)\n    print(disp.confusion_matrix)\n\nplt.show()","7fd11b0f":"print(classification_report(y_test, y_predGB))","12499156":"print(accuracy_score(y_test, y_predGB))","8f938e22":"print('Neural Netwok Model', accuracy_score(y_test, y_predNN))\nprint('Support Vector Machine', accuracy_score(y_test, y_predSV))\nprint('Random forest', accuracy_score(y_test, y_predRF))\nprint('Naive Bayesian', accuracy_score(y_test, y_predNB))\nprint('K Neighbors Classifier', accuracy_score(y_test, y_pred))\nprint('Decision Tree', accuracy_score(y_test, y_predDT))\nprint('Gradient Boosting Classifie', accuracy_score(y_test, y_predGB))\n\n\n","de3f42ee":"> Importare librerie","f64328db":"> Previsione","7560be8e":"> Errore assoluto","04c00f63":"> Matrice di confusione","f5ab403b":"> Matrice di confusione","f3a112ef":"> Matrice di confusione","f12b2112":"> Classification report","bc9aba46":"# Valutazione algoritmo","61e095a2":"> Predizione","99cbefc5":"> Classification report","a23ff54f":"<h1 style='color:red'> Neural Network Model","b2aeafd5":"> Grado di accuratezza","7db58d29":"<h1 style='color:red'> K Neighbors Classifier\n\n","7af388b5":"<h1 style='color:red'> Learn Decision Tree","7467698b":"> Suggerimenti","a3206c4b":"Nelle seguenti misure di errore di previsioni ho:\n- E = insieme di esempi\n- T = insieme di target feature\n\nPer le target feature Y appartiene T e l'esempi e apprtiene E, il valore attuale \u00e8 Y(e) e il valore predetto \u00e8 Y(cappelletto)e\n\nTipologie di errori:\n- errore 0\/1 = somma del numero di predizioni sbagliate\n- media errore assoluto = somma della differenza assoluta tra il valore attuale e il valore predetto\n- somma degli errori quadrati = considera gli errori pi\u00f9 gravi\n\n\n","88f85854":"> Learn Decision Tree (Basic Model for Supervised Learning)","421ad0cd":"> Previsione\n","f386fdd1":"> Classification report","968979a3":"<h1 style='color:red'> Analisi dataset","09484ab2":"> Previsione","ef6eacdd":"> Grado di accuratezza ","e826b3bf":"> Classification report","fe8d3d82":"Addestramento","316376e2":"Somma degli errori quadrati","fcf0275c":"# Suddivisione del dataset in fase di allenamento e fase di test \n> # Convalida incrociata","29bc53db":"> Configurazione matrice di confusione","c41f11e8":"> Errore 0\/1 ","30dd3bf8":"<h1 style='color:red'>  Preprocessamento","a3a0fb48":"Feature Selection","d84a9ae4":"> Addestramento","b0c3f63a":"- TP = True positive\n- TN = True negative\n- FP = False positive (\u00e8 una predizione positiva sbagliata)\n- FN = False negative (\u00e8 una predizione negativa sbagliata)","8f334f2c":"DecisionTreeClassifier prende come input du array:\n- array di campioni di addestramento\n- array di target per campione di addestramento","3fa97c34":"> Grado di accuratezza","7489cfd1":"> max depth","e761fe8d":"> Grado di accuratezza","50dba15e":"# Obiettivo\n\nL'obiettivo che si vuole ottenere \u00e8 stabilire la precisione che l'algoritmo ci da nel determinare la classe di vino a cui apparterranno nuove istanze, ossia nuovi vini. Pi\u00f9 preciso sar\u00e0 l'algoritmo e maggiormente sar\u00e0 probabile determinare a che classi futuri vini apparterranno.\n","69177c58":"> Valutazione delle previsioni","21730879":"> Coefficiente di correlazione\n\nI coefficienti di correlazione vengono utilizzati nelle statistiche per misurare quanto \u00e8 forte una relazione tra due variabili\n\nQuesta analisi consente di vedere quali coppie hanno la correlazione pi\u00f9 alta, le coppie che sono altamente correlate rappresentano la stessa varianza del set di dati, quindi possiamo analizzarle ulteriormente per capire quale attributo tra le coppie \u00e8 pi\u00f9 significativo per la costruzione del modello.\n\nLe variabili altamente correlate avranno un valore di correlazione vicino a +1 e le variabili meno correlate avranno un valore di correlazione prossimo a -1.","d48ea970":"Queto \u00e8 un modello di base da cui sono costruiti altri modelli compositi.\n\nUn albero decisionale o albero di classificazione \u00e8 una semplice rappresentazione per classificare gli esempi. L'apprendimento dell'albero decisionale \u00e8 una delle tecniche utili pi\u00f9 semplici per all'apprendimento con classificazione supervisionato.\n\n\u00c8 composto in questo modo:\n- ogni nodo interno (non foglia) \u00e8 etichettato con una condizione\n- ogni nodo interno ha due figli\n- ogni foglia dell'albero \u00e8 etichettata con una stima puntuale sulla classe (classe = elemento del dominio di classificazione)\n\nIn molte situazioni \u00e8 utile definire un criterio di arresto (halting), o anche criterio di potatura (pruning) al fine di determinarne la profondit\u00e0 massima. Questo perch\u00e9 il crescere della profondit\u00e0 di un albero (ovvero della sua dimensione) non influisce direttamente sulla bont\u00e0 del modello. Infatti, una crescita eccessiva della dimensione dell'albero potrebbe portare solo ad aumento sproporzionato della complessit\u00e0 computazionale rispetto ai benefici riguardanti l'accuratezza delle previsioni\/classificazioni.\n\nUna sua evoluzione \u00e8 la tecnica della \"foresta casuale\"\n","cf737961":"> > Metodo Holdout","52d8b7e3":"> Classification report","b33481f3":"Gli alberi decisionali si adattano eccessivamente adi dati con un numero di funzionalit\u00e0 molto elevato.\nPer evitare ci\u00f2 possiamo ridurre la dimensione o con la tecnica PCA o ICA.\n\nInoltre utilizziamo un \"max_depth\" per controllare la dimensione dell'albero e per evitare un adattamente eccessivo. Quindi bisogna fare vari test per capire il miglior numero per max_depth.\n\n\u00c8 consigliato anche bilanciare il set di dati prima dell'addestramento per evitare che l'albero venga influenzato dalle classi dominanti.","b59c9f00":"> Box Plot","64b77cb6":"> Addestramento","a5fbe6d4":"> Vantaggi Learn Decision Tree\n\n- Semplice da capire e da interpretare.\n- Richiede poca preparazione dei dati\n- Il costo dell'utilizzo dell'albero (ovvero la previsione dei dati) \u00e8 logaritmico.\n- In grado di gestire dati sia numerici che catogorici.\n- Possibilit\u00e0 di validare un modello utilizzando test statistici. Ci\u00f2 consente di tenere conto dell'affidabilit\u00e0 del modello.\n\n> Svantaggi Learn Decision Tree\n\n- Possibilit\u00e0 overfitting ( soluzione: potatura, profondit\u00e0 massima albero)\n- Instabilit\u00e0 per piccole variazioni nei dati, causa albero diverso (soluzione: uso di alberi decisionali all'interno di un insieme)\n- Apprendimento albero decisionale ottimale \u00e8 NP-completo anche per concetti semplici.\n- Si consiglia di bilanciare il set di dati prima di adattarlo all'albero decisionale","619274e8":"> Overfitting\n\nL'overfitting si verifica quando le previsioni compaiono nel set di addestramento ma non compaiono nel set di test. Bisogna capire come rilevare ed evitare l'overfitting.\n\nL'erore del set di test \u00e8 causato da:\n- bias: errore dovuto all'algoritmo di trovare un modello imperfetto (errore medio per diversi seti di addestramento)\n- varianza: errore dovuto alla mancanza di dati (indica quanto sia sensibile alla variazione dei set di addestramento)\n- rumore: errore intrinseco dovuto ai dati dipendenti da caratteristiche non modellate","3c953acd":"> Classification report","d0a2ef62":"> Matrice di confusione","36c9fdf5":"<h1 style='color:red'> Random Forest Classifier","fbfea49d":"<h1 style='color:red'> Naive Bayes","67ffd9e6":"> Classification report","669091b0":"![Istantanea_2020-08-27_12-51-08.png](attachment:Istantanea_2020-08-27_12-51-08.png)\n\n\n1. **Class**: indica la classe del vino, in particolare nel dataset ne abbiamo 3 (classe 1, classe 2 e classe 3). Rappresenta anche l\u2019output che si vuole ottenere, cio\u00e8 stabilire a quale di queste classi i nuovi vini appartengono;\n\n2. **Alcohol**: indica il grado alcolico del vino (% in volume);\n\n3. **Malic acid**: ossia acido malico, uno dei principali acidi organici presenti nelle uve da vino (g \/ l);\n\n4. **Ash**: sono le ceneri, che rappresentano il contenuto delle sostanze minerali presenti in un vino. \u00c8 un indicatore importante per determinare la qualit\u00e0 del vino (misurato in millisiemens per centimetro, mS\/cm);\n\n5. **Alcalinity of ash**: ossia l\u2019alcalinit\u00e0 delle ceneri, un parametro che esprime approssimativamente la quantit\u00e0 di acidi organici presenti nel vino sottoforma di sali (pH).\n\n6. **Magnesium**: indica la quantit\u00e0 di magnesio presente nel vino (g su kg).\n\n7. **Total phenols**: indica il numero di fenoli inclusi nel vino, che sono sostanze naturali che danno il colore al vino stesso oltre che a sensazioni gustative (mg\/L).\n\n8. **Flavanoids**: I flavonoidi sono i polifenoli pi\u00f9 abbondanti nel vino. (mg\/L);\n\n9. **Nonflavanoid phenols**: I composti fenolici conferiscono caratteristiche specifiche al vino e creano anche aromi e sapori specifici quando le interazioni complesse si svolgono durante la fermentazione e la vinificazione (mg \/ L);\n\n10. **Proanthocyanins**: indicano le proantocianidine, un tipo di fenolo antiossidante del vinorosso (mg\/L).\n\n11. **Color intensity**: ossia una semplice misura di quanto sia scuro il vino;\n\n12. **Hue**: \u00e8 una delle principali propriet\u00e0 del colore;\n\n13. **OD280\/OD315 of diluted wines**;\n\n14. **Proline**: ossia la prolina, un amminoacido (Mg \/ L).\n\nLe colonne sono 14 perch\u00e8 \u00e8 stata indicata anche la classe dei vini(1 colonna)\n\nMaggiori informazioni sul dataset si veda [l'analisi eseguita da Github](https:\/\/github.com\/moibra\/Wine-Analysis) \n\nFonte del dataset https:\/\/archive.ics.uci.edu\/ml\/datasets\/Wine\n\n","c0f76e85":"> Addestramento","cecc3df0":"<h1 style='color:red'> Tabella riassuntiva","c0664900":"> Analisi di rilevamento dei valori anomali\n\nIQR = Q3 - Q1\n\nL'IQR pu\u00f2 essere utilizzato per rilevare i valori anomali. I valori anomali sono osservazioni che scendono al di sotto di Q1 - 1.5 (IQR) o al di sopra di Q3 + 1.5 (IQR).\n\nIQR = colore blu","f84ff5f8":"# Classificatore dei vini\n\n![](https:\/\/lemillebolleblog.it\/wp-content\/uploads\/2020\/02\/Adeletappobicchiere.jpg)\n\n\n","4b23a387":"> Tracciamento albero","f29f38c8":"> Predizione","2e0ce7d5":"> Grado di accuratezza","e944d7b7":"Lo spazio ROC traccia il tasso dei falsi positivi contro il tasso dei veri positivi","b57453d5":"> Addestramento","cba45bab":"<h1 style='color:red'> Feature Scaling (ridimensionamento dei dati)","ce0655f3":"> ROC space","ca5e88e7":"> Matrice di confusione","51a1f67d":"> Bilanciamento usando SMOTE\n\nSMOTE (tecnica di sovracampionamento minoritario sintetico) \u00e8 uno dei metodi di sovracampionamento pi\u00f9 comunemente utilizzati per risolvere il problema dello squilibrio.\n\nMira a bilanciare la distribuzione di classi aumentando casualmente gli esempi di classi di minoranza replicandoli.\n\n","4823e93c":"> Grado di accuratezza","ed3b0b39":"<h1 style='color:red'> Support Vector Machine(SVM)","e89d90d9":"# Tabella dei contenuti\n\n- Analisi dataset\n- Preprocessamento\n- Feature Scaling \n- Apprendimento automatico supervisionato\n    - > Learn Decision Tree\n    - > K Neighbors Classifier\n    - > Random Forest Classifier\n    - > Naive Bayes\n    - > Support Vector Machine(SVM)\n    - > Neural Network Model\n- Apprendimento non supervisionato\n- Tabella riassuntiva","b80fb1a5":"> Addestramento","fc4ba0cf":"Individuo il max_depth migliore","771b5f5f":"- precision = tp\/(tp + fp) la proporzione di previsioni positive che sono effettivamente positive.\n\n- recall (true-positive rate) = tp\/(tp + fn) la percentuale di positivi efettivi che si prevede siano positivi\n\n- f1_score = 2*(precision * recall)\/(precision + recall) media ponderata della precisione e del richiamo.\n","b7f6a8f9":"<h1 style='color:red'> Gradient Boosting Classifie","c5178f9c":"<h1 style='color:red'> Apprendimento automatico supervisionato","6f8792b9":"> Matrice di confusione","99503cd4":"> Grado di accuratezza ","72bf7347":"> Predizione","4785c7c4":"> Matrice di confusione\n\n","83122a01":"> Pavimentazione e tappatura a base quantile","080027e0":"> Individuare gli attributi per importanza","3e3d87bd":"> Tipi di errori","9de32c8e":"> Who so neglects learning in his youth, loses the past and is dead for the future.\nEuripides (484 BC - 406 BC)\n\nL'apprendimento \u00e8 la capacit\u00e0 di un agente di migliorare il proprio comportamento in base all'esperienza. La capacit\u00e0 di apprendere \u00e8 essenziale per qualsiasi agente intelligente. Come ha sottolineato Euripide, l'apprendimento coinvolge un agente che ricorda il suo passato in un modo che \u00e8 utile per il suo futuro.\n\nCi\u00f2 che faremo con questi algoritmi \u00e8 di fare una previsione come apprendimento supervisionato: data una serie di esempi di addestramento costituiti da coppie input-output, prevedere l'output di un nuovo esempio in cui vengono forniti solo gli input.","bdb2388e":"> Rilevazione valori anomali","79e29724":"> Predizione"}}