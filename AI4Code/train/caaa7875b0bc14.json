{"cell_type":{"82275ab7":"code","4aa60877":"code","1fe95805":"code","e9eebe6d":"code","f3e30e5c":"code","91daec0e":"code","4e9639bb":"code","f90cc2ed":"code","589610c0":"code","360099fe":"code","2870a49c":"code","37081443":"code","0200fa14":"code","4c08aed1":"code","112a0f43":"code","0f74e91d":"code","00cd39ff":"code","78b3c2ab":"code","51bac3f3":"code","1abef0f2":"code","201e3b28":"code","f0012033":"code","2efa763c":"code","bf2cd32c":"code","4a3ad3dc":"code","eb70e5ac":"code","3756dd47":"code","57453148":"code","bbbdf167":"code","a5f8c46f":"code","57b92e6a":"code","416b85b4":"code","665e8807":"code","6942b348":"code","edac68fd":"code","2789cac9":"code","a32eb10c":"code","7b4e45e0":"code","23985b60":"code","cfe1c951":"code","3c8814ee":"code","1f7b76f1":"code","2fd1dff5":"code","c746f780":"code","17380103":"code","5f171da7":"code","e8633849":"code","5c52252c":"code","9ac73ffd":"code","dcadbcf8":"code","9aafafaf":"code","43047095":"code","ebc705d4":"code","8bf27083":"code","af0c01e3":"code","06d9482d":"code","a723f92a":"code","3602ba51":"markdown","47b3bc66":"markdown","65da6af6":"markdown","44d6556f":"markdown","ae3996cd":"markdown","4a6bd05d":"markdown","d2a18f24":"markdown","cbfe6f9f":"markdown","a1d04f04":"markdown","4c5477e4":"markdown","12e107da":"markdown","1e921442":"markdown","c9a0b661":"markdown","601b949e":"markdown","f8069693":"markdown","6e0ed192":"markdown","899a29ca":"markdown","7c89c310":"markdown","e326a852":"markdown","f5bb7d22":"markdown","1444dc3d":"markdown","820336b4":"markdown","230e5a4e":"markdown","446b5f47":"markdown","f3c085b1":"markdown","cdf659cc":"markdown","8c855bb7":"markdown","1bedbbb1":"markdown","139100c1":"markdown","75e2ca2a":"markdown","b042a202":"markdown","a9621ba9":"markdown","9044e1f1":"markdown","3105c23d":"markdown","70d6d74b":"markdown","69c9ad5f":"markdown","0573be74":"markdown","b37e96a6":"markdown","597803db":"markdown","e20a58de":"markdown","5f34b8b3":"markdown","9040a9a2":"markdown","8c00f1f3":"markdown"},"source":{"82275ab7":"!pip install ..\/input\/python-datatable\/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl > \/dev\/null","4aa60877":"# import packages\nimport os, gc\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport datatable as dt\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# riiideducation module\nimport riiideducation\n\n%matplotlib inline\nwarnings.filterwarnings('ignore')\n\n# directory\nprint('Competition Data\/Files')\nos.listdir('..\/input\/riiid-test-answer-prediction')","1fe95805":"def countplot(column, plot_type='multiple', gridstyle='whitegrid', gs=None,\n              palette='Accent', xlab=None, ylab=None, title=None, fontsize=12):\n    \n    '''\n    Make countplots\n    -----------------\n    \n    Arguments:\n    column -- column with categorical values\n    plot_type -- multiple grid ('multiple\/single')\n    gridstyle -- seaborn gridstyle\n    gs -- gridspec (if using subplots)\n    palette -- color palette\n    xlab -- x-axis label\n    ylab -- y-axis label\n    title -- plot title\n    fontsize -- fontsize\n    \n    Returns:\n    sns.countplot()\n    '''\n    if plot_type=='multiple':\n        with sns.axes_style(gridstyle):\n            ax = f.add_subplot(gs)\n            aa = sns.countplot(column, palette=palette)\n            for p in ax.patches:\n                height = p.get_height()\n                aa.text(p.get_x()+p.get_width()\/2.,\n                        height,\n                        '{:1.2f}%'.format(height\/len(column)*100),\n                        ha=\"center\", fontsize=fontsize)\n            plt.xlabel(xlab,fontsize=fontsize)\n            plt.ylabel(ylab,fontsize=fontsize)\n            plt.title(title)\n            \n    elif plot_type=='single':\n        with sns.axes_style(\"whitegrid\"):\n            aa = sns.countplot(column, palette=palette)\n            for p in aa.patches:\n                height = p.get_height()\n                aa.text(p.get_x()+p.get_width()\/2.,\n                        height + 3,\n                        '{:1.2f}%'.format(height\/len(column)*100),\n                        ha=\"center\", fontsize=fontsize)\n            plt.xlabel(xlab,fontsize=fontsize)\n            plt.ylabel(ylab,fontsize=fontsize)\n            plt.title(title)","e9eebe6d":"# root directory\nROOT = '..\/input\/riiid-test-answer-prediction\/'\n\n# files\ntrain = dt.fread(\"..\/input\/riiid-test-answer-prediction\/train.csv\").to_pandas()\n\ntrain = train.astype({\n    'row_id': 'int32',\n    'timestamp': 'int64',\n    'user_id': 'int64',\n    'content_id': 'int16',\n    'content_type_id': 'int8',\n    'task_container_id': 'int16',\n    'user_answer': 'int8',\n    'answered_correctly': 'int8',\n    'prior_question_elapsed_time': 'float32',\n    'prior_question_had_explanation': 'boolean'\n})\n\nquestions = pd.read_csv(f'{ROOT}questions.csv')\nlectures = pd.read_csv(f'{ROOT}lectures.csv')\nexample_test = pd.read_csv(f'{ROOT}example_test.csv')\nexample_sample_submission = pd.read_csv(f'{ROOT}example_sample_submission.csv')","f3e30e5c":"train.head()","91daec0e":"print(f'We have {train.shape[0]} rows and {train.shape[1]} features in train.csv.')","4e9639bb":"train.info()","f90cc2ed":"print(f'Missing values in train.csv in each columns:\\n{train.isnull().sum()}')","589610c0":"print(f'We have total of {train.isnull().values.sum()} missing values in train data.')","360099fe":"print('Unique Values in each column of train.csv')\nprint('##########################################')\nfor col in train:\n    print(f'{col}: {train[col].nunique()}')","2870a49c":"questions.head()","37081443":"print(f'We have {questions.shape[0]} rows and {questions.shape[1]} features in questions.csv.')","0200fa14":"print(f'Missing values in questions.csv in each columns:\\n{questions.isnull().sum()}')","4c08aed1":"print(f'We have total of {questions.isnull().values.sum()} missing values in train data.')","112a0f43":"print('Unique Values in each column of questions.csv')\nprint('##########################################')\nfor col in questions:\n    print(f'{col}: {questions[col].nunique()}')","0f74e91d":"lectures.head()","00cd39ff":"print(f'We have {lectures.shape[0]} rows and {lectures.shape[1]} features in lectures.csv.')","78b3c2ab":"print(f'Missing values in lectures.csv in each columns:\\n{lectures.isnull().sum()}')","51bac3f3":"print(f'We have total of {lectures.isnull().values.sum()} missing values in lectures data.')","1abef0f2":"print('Unique Values in each column of lectures.csv')\nprint('##########################################')\nfor col in lectures:\n    print(f'{col}: {lectures[col].nunique()}')","201e3b28":"# You can only call make_env() once, so don't lose it!\nenv = riiideducation.make_env()\n\n# You can only iterate through a result from `env.iter_test()` once\n# so be careful not to lose it once you start iterating.\niter_test = env.iter_test()","f0012033":"count = 0\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df['answered_correctly'] = 0.5\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n    count += len(test_df)","2efa763c":"print(f'We have {count} observations in total and {test_df.shape[1]} features in test.csv.')","bf2cd32c":"test_df.head()","4a3ad3dc":"test_df.info()","eb70e5ac":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    train['timestamp'].hist(bins = 50,color='orange')\n    plt.title(\"Timestamp Distribution\")\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    train['user_id'].hist(bins = 50,color='red')\n    plt.title(\"User Id Distribution\")","3756dd47":"mean = train['content_id'].mean()\nmedian = train['content_id'].median()\nmode = train['content_id'].mode()[0]\n\nmean_2 = train['task_container_id'].mean()\nmedian_2 = train['task_container_id'].median()\nmode_2 = train['task_container_id'].mode()[0]\n\nprint(f'Content Id (Mean): {mean}')\nprint(f'Content Id (Median): {median}')\nprint(f'Content Id (Mode): {mode}\\n')\nprint('######################################\\n')\nprint(f'Task Container Id (Mean): {mean_2}')\nprint(f'Task Container Id (Median): {median_2}')\nprint(f'Task Container Id (Mode): {mode_2}')","57453148":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    sns.distplot(train['content_id'], color='green')\n    ax.axvline(int(mean), color='r', linestyle='--')\n    ax.axvline(int(median), color='y', linestyle='-')\n    ax.axvline(mode, color='b', linestyle='-')\n    plt.legend({'Mean':mean,'Median':median,'Mode':mode})\n    plt.title(\"Content Id Distribution\")\n    \nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    sns.distplot(train['task_container_id'], color='yellow')\n    ax.axvline(int(mean_2), color='r', linestyle='--')\n    ax.axvline(int(median_2), color='g', linestyle='-')\n    ax.axvline(mode_2, color='b', linestyle='-')\n    plt.legend({'Mean':mean_2,'Median':median_2,'Mode':mode_2})\n    plt.title(\"Task Container Id Distribution\")","bbbdf167":"mean_3= train['prior_question_elapsed_time'].mean()\nmedian_3 = train['prior_question_elapsed_time'].median()\nmode_3 = train['prior_question_elapsed_time'].mode()[0]","a5f8c46f":"f = plt.figure(figsize=(16, 8))\n\nwith sns.axes_style(\"whitegrid\"):\n    sns.distplot(train['prior_question_elapsed_time'], color='olive')\n    plt.axvline(int(mean_3), color='c', linestyle='--')\n    plt.axvline(int(median_3), color='m', linestyle='-')\n    plt.axvline(mode_3, color='k', linestyle='-')\n    plt.legend({'Mean':mean_3,'Median':median_3,'Mode':mode_3})\n    plt.title(\"Prior Question Elapsed Time Distribution\")\n    \nprint(f'Prior Question Elapsed Time (Mean): {mean_3}')\nprint(f'Prior Question Elapsed Time (Median): {median_3}')\nprint(f'Prior Question Elapsed Time (Mode): {mode_3}')","57b92e6a":"mean_4 = lectures['tag'].mean()\nmedian_4 = lectures['tag'].median()\nmode_4 = lectures['tag'].mode()[0]","416b85b4":"f = plt.figure(figsize=(16, 8))\n\nwith sns.axes_style(\"whitegrid\"):\n    sns.distplot(lectures['tag'], color='coral', bins=20)\n    plt.axvline(int(mean_4), color='r', linestyle='--')\n    plt.axvline(int(median_4), color='g', linestyle='-')\n    plt.axvline(mode_4, color='b', linestyle='-')\n    plt.legend({'Mean':mean_4,'Median':median_4,'Mode':mode_4})\n    plt.title(\"Lecture Tag Distribution\")\n    \nprint(f'Tag (Mean): {mean_4}')\nprint(f'Tag (Median): {median_4}')\nprint(f'Tag (Mode): {mode_4}')","665e8807":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    test_df['timestamp'].hist(bins = 50,color='maroon')\n    plt.title(\"Timestamp Distribution in Test Data\")\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    test_df['user_id'].hist(bins = 50,color='gold')\n    plt.title(\"User Id Distribution in Test Data\")","6942b348":"mean_5 = test_df['content_id'].mean()\nmedian_5 = test_df['content_id'].median()\nmode_5 = test_df['content_id'].mode()[0]\n\nmean_6 = test_df['task_container_id'].mean()\nmedian_6 = test_df['task_container_id'].median()\nmode_6 = test_df['task_container_id'].mode()[0]\n\nprint(f'Content Id Test(Mean): {mean_5}')\nprint(f'Content Id Test(Median): {median_5}')\nprint(f'Content Id Test(Mode): {mode_5}\\n')\nprint('######################################\\n')\nprint(f'Task Container Id Test(Mean): {mean_6}')\nprint(f'Task Container Id Test(Median): {median_6}')\nprint(f'Task Container Id Test(Mode): {mode_6}')","edac68fd":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    sns.distplot(test_df['content_id'], color='cyan')\n    ax.axvline(int(mean_5), color='r', linestyle='--')\n    ax.axvline(int(median_5), color='y', linestyle='-')\n    ax.axvline(mode_5, color='b', linestyle='-')\n    plt.legend({'Mean':mean_5,'Median':median_5,'Mode':mode_5})\n    plt.title(\"Content Id Distribution in Test Data\")\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    sns.distplot(test_df['task_container_id'], color='purple')\n    ax.axvline(int(mean_6), color='r', linestyle='--')\n    ax.axvline(int(median_6), color='y', linestyle='-')\n    ax.axvline(mode_6, color='b', linestyle='-')\n    plt.legend({'Mean':mean,'Median':median,'Mode':mode})\n    plt.title(\"Task Container Id Distribution in Test Data\")","2789cac9":"mean_7 = test_df['prior_question_elapsed_time'].mean()\nmedian_7 = test_df['prior_question_elapsed_time'].median()\nmode_7 = test_df['prior_question_elapsed_time'].mode()[0]","a32eb10c":"f = plt.figure(figsize=(16, 8))\n\nwith sns.axes_style(\"whitegrid\"):\n    sns.distplot(test_df['prior_question_elapsed_time'], color='darkgoldenrod')\n    plt.axvline(int(mean_7), color='r', linestyle='--')\n    plt.axvline(int(median_7), color='g', linestyle='-')\n    plt.axvline(mode_7, color='b', linestyle='-')\n    plt.legend({'Mean':mean_7,'Median':median_7,'Mode':mode_7})\n    plt.title(\"Prior Question Elapsed Time Distribution\")\n    \nprint(f'Content Id Test(Mean): {mean_7}')\nprint(f'Content Id Test(Median): {median_7}')\nprint(f'Content Id Test(Mode): {mode_7}\\n')","7b4e45e0":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 3)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    ay = sns.countplot(y = train['user_id'], order=train.user_id.value_counts().index[:10], palette=\"ocean_r\")\n    plt.title(\"Top 10 Active Users\")\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    aa = sns.countplot(y = train['content_id'], order=train.content_id.value_counts().index[:10], palette=\"terrain\")\n    plt.title(\"Top 10 Popular Contents Ids\")\n    \nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 2])\n    aa = sns.countplot(y = train['task_container_id'], order=train.task_container_id.value_counts().index[:10], palette=\"OrRd_r\")\n    plt.title(\"Top 10 Tasks\")","23985b60":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    ay = sns.countplot(train['user_answer'], palette=\"Set3\")\n    for p in ax.patches:\n        height = p.get_height()\n        ay.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/101230332*100),\n                ha=\"center\", fontsize=12)\n    plt.xlabel('user answer',fontsize=12)\n    plt.ylabel('count',fontsize=12)\n    plt.title(\"User's Answer To Questions\")\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    aa = sns.countplot(train['answered_correctly'], palette=\"pastel\")\n    for p in ax.patches:\n        height = p.get_height()\n        aa.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/101230332*100),\n                ha=\"center\", fontsize=14)\n    plt.xlabel('answered correctly',fontsize=12)\n    plt.ylabel('count',fontsize=12)\n    plt.title(\"Correct Answers\")","cfe1c951":"f = plt.figure(figsize=(16, 10))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    ay = sns.countplot(train['prior_question_had_explanation'].dropna(), palette=\"Pastel1\")\n    for p in ax.patches:\n        height = p.get_height()\n        ay.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/101230332*100),\n                ha=\"center\", fontsize=12)\n    plt.xlabel('Prior question had explanation',fontsize=12)\n    plt.ylabel('count',fontsize=12)\n    plt.title(\"Users Saw Explanation\", fontsize=14)\n    \nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    aa = sns.countplot(train['content_type_id'], palette=\"twilight_r\")\n    for p in ax.patches:\n        height = p.get_height()\n        aa.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/101230332*100),\n                ha=\"center\", fontsize=12)\n    plt.xlabel('Content Type Id',fontsize=12)\n    plt.ylabel('count',fontsize=12)\n    plt.title(\"Posed Question\/Watching Lecture\", fontsize=14)","3c8814ee":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    ay = sns.countplot(questions['correct_answer'], palette=\"hls\")\n    for p in ax.patches:\n        height = p.get_height()\n        ay.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/13523*100),\n                ha=\"center\", fontsize=14)\n    plt.title(\"User's Answer To Questions\")\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    aa = sns.countplot(questions['part'], palette=\"deep\")\n    for p in ax.patches:\n        height = p.get_height()\n        aa.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/13523*100),\n                ha=\"center\", fontsize=12)\n    plt.title(\"TOIEC English-language Assessment Section Number\")","1f7b76f1":"questions['tag'] = questions['tags'].str.split(' ')\nquestions['tag_length'] = questions['tag'].str.len()\ntag_len = questions['tag_length'].dropna()\ntag_len = tag_len.astype({'tag_length': 'int8'})\n\ntop_tags = questions.tag.explode('tags').reset_index()","2fd1dff5":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    aa = sns.countplot(tag_len, palette=\"coolwarm\")\n    for p in aa.patches:\n        height = p.get_height()\n        aa.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/13522*100),\n                ha=\"center\", fontsize=12)\n    plt.xlabel('number of tags',fontsize=14)\n    plt.ylabel('count',fontsize=14)\n    plt.title(\"Number Of Tags Per Questions\", fontsize=14)\n    \nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    sns.countplot(y = top_tags['tag'], order = top_tags.tag.value_counts().index[:10], palette=\"ocean_r\")\n    plt.xlabel('count',fontsize=14)\n    plt.ylabel('tag',fontsize=14)\n    plt.title(\"Top 10 Tags\",fontsize=14)","c746f780":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    ay = sns.countplot(lectures['part'], palette='BuPu_r')\n    for p in ax.patches:\n        height = p.get_height()\n        ay.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/418*100),\n                ha=\"center\", fontsize=14)\n    plt.title(\"Category code for lecture\")\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    aa = sns.countplot(lectures['type_of'], palette=\"gist_stern_r\")\n    for p in ax.patches:\n        height = p.get_height()\n        aa.text(p.get_x()+p.get_width()\/2.,\n                height + 3,\n                '{:1.2f}%'.format(height\/418*100),\n                ha=\"center\", fontsize=12)\n    plt.title(\"Lecture Description\")","17380103":"f = plt.figure(figsize=(16, 8))\ngs = f.add_gridspec(1, 2)\n\nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 0])\n    ay = sns.countplot(train['user_answer'], hue = train['prior_question_had_explanation'], palette=\"vlag\")\n    for p in ax.patches:\n        height = p.get_height()\n        ay.text(p.get_x()+p.get_width()\/2.,\n                height + 2,\n                '{:1.2f}%'.format(height\/101230332*100),\n                ha=\"center\", fontsize=12)\n    plt.xlabel('User Answer',fontsize=14)\n    plt.ylabel('count',fontsize=14)\n    plt.title(\"User's Answer With And Without Explanation\", fontsize=16)\n        \nwith sns.axes_style(\"whitegrid\"):\n    ax = f.add_subplot(gs[0, 1])\n    aa = sns.countplot(train['answered_correctly'], hue= train['prior_question_had_explanation'], palette=\"deep\")\n    for p in ax.patches:\n        height = p.get_height()\n        aa.text(p.get_x()+p.get_width()\/2.,\n                height + 2,\n                '{:1.2f}%'.format(height\/101230332*100),\n                ha=\"center\", fontsize=12)\n    plt.legend(loc='center upper')\n    plt.xlabel('Answered Correctly',fontsize=14)\n    plt.ylabel('count',fontsize=14)\n    plt.title(\"User's Saw explanation and Correct Answers\", fontsize=15)","5f171da7":"f = plt.figure(figsize=(16, 8))\n\nwith sns.axes_style(\"whitegrid\"):\n    sns.countplot(train['user_answer'], hue = train['answered_correctly'], palette=\"husl\")\n    plt.title(\"User's Answer vs Answered Correctly\")","e8633849":"f = plt.figure(figsize=(16, 8))\n\nwith sns.axes_style(\"whitegrid\"):\n    sns.countplot(questions['correct_answer'], hue = questions['part'], palette=\"Spectral\")\n    plt.title(\"User's Answer vs Answered Correctly\")","5c52252c":"f = plt.figure(figsize=(16, 8))\n\nwith sns.axes_style(\"white\"):\n    sns.catplot(x=\"part\", y=\"tag_length\", kind=\"box\",\n                col=\"correct_answer\", aspect=.7, data=questions)","9ac73ffd":"with sns.axes_style(\"white\"):\n    sns.pairplot(questions, hue=\"correct_answer\", palette=\"gnuplot_r\", diag_kind=\"kde\",\n                 height=3, corner=True, plot_kws=dict(linewidth=1, alpha=1))","dcadbcf8":"f = plt.figure(figsize=(16, 8))\n\nwith sns.axes_style(\"whitegrid\"):\n    sns.countplot(lectures['part'], hue = lectures['type_of'], palette=\"Spectral\")\n    plt.title(\"Categories in Parts\")","9aafafaf":"f = plt.figure(figsize=(16, 8))\n\nwith sns.axes_style(\"white\"):\n    sns.catplot(x=\"part\", y=\"tag\", kind=\"box\",\n                col=\"type_of\", aspect=.7, data=lectures)","43047095":"with sns.axes_style(\"white\"):\n    sns.pairplot(lectures, hue=\"type_of\", palette=\"copper\", height=3,\n                 corner=True, plot_kws=dict(linewidth=1, alpha=0.6))","ebc705d4":"gc.collect()","8bf27083":"f = plt.figure(figsize=(16, 10))\n\nmask = np.triu(np.ones_like(train.corr(), dtype=bool))\n\nwith sns.axes_style(\"white\"):\n    sns.heatmap(train.corr(), mask=mask, square=True, cmap = 'YlGnBu', annot=True);\n    plt.title(\"Train Data Feature Correlation\", fontsize=14)","af0c01e3":"f = plt.figure(figsize=(16, 10))\n\nmask = np.triu(np.ones_like(questions.corr(), dtype=bool))\n\nwith sns.axes_style(\"white\"):\n    sns.heatmap(questions.corr(), mask=mask, square=True, cmap = 'YlOrBr', annot=True);\n    plt.title(\"Questions Data Feature Correlation\", fontsize=14)","06d9482d":"f = plt.figure(figsize=(16, 10))\n\nmask = np.triu(np.ones_like(lectures.corr(), dtype=bool))\n\nwith sns.axes_style(\"white\"):\n    sns.heatmap(lectures.corr(), mask=mask, square=True, cmap = 'icefire', annot=True);\n    plt.title(\"Lectures Data Feature Correlation\", fontsize=14)","a723f92a":"gc.collect()","3602ba51":"### Missing Values","47b3bc66":"# 1. <a id='1'>Introduction\ud83d\udcd4<\/a>\n[Table of contents](#0.1)\n\nWelcome to this new competition hosted by [Riiid! Labs](https:\/\/www.riiid.co\/en\/main), leader in AI based education. Here are some of the [products](https:\/\/www.riiid.co\/en\/product) provided by [Riiid! Labs](https:\/\/www.riiid.co\/en\/main).\n\nIn this competition, your challenge is to create algorithms for \"Knowledge Tracing,\" the modeling of student knowledge over time. The goal is to accurately predict how students will perform on future interactions. You will pair your machine learning skills using Riiid\u2019s EdNet data.\n\n## About Competition Data\n\nThe data is in tabular format. We have data regarding student's historic performance, the performance of other students on the same question, metadata about the question itself. \n\n**This is a time-series code competition, you will receive test set data and make predictions with Kaggle's time-series API. Please be sure to review the Time-series API Details section closely**.\n\nWe are provided with following **csv** files - \n\n* train.csv - Training features.\n* questions.csv - Metadata for the questions posed to users.\n* lectures.csv - Metadata for the lectures watched by users as they progress in their education.\n\nPlease check this starter kernels here to get more information.\n* [Competition API Detailed Introduction](https:\/\/www.kaggle.com\/sohier\/competition-api-detailed-introduction)\n* [Quick Sample Submission](https:\/\/www.kaggle.com\/sohier\/quick-sample-submission\/)\n\n## What we are prediciting?\n\n You will predict whether students are able to answer their next questions correctly.\n \n## Evaluation Metric: Area Under ROC Curve\n\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n\n<img src=\"https:\/\/i.ytimg.com\/vi\/J9l8J1MeCbY\/hqdefault.jpg\" width=\"400\" height=\"400\" align='left'>","65da6af6":"**\ud83d\udccc Points to note :**\n\n* question_id - foreign key for the train\/test content_id column, when the content type is question (0).\n\n* bundle_id - code for which questions are served together.\n\n* correct_answer - the answer to the question. Can be compared with the train user_answer column to check if the user was right.\n\n* part - top level category code for the question.\n\n* tags - one or more detailed tag codes for the question. The meaning of the tags will not be provided, but these codes are sufficient for clustering the questions together.\n\n### Missing Values in questions.csv","44d6556f":"**\ud83d\udccc Points to note :**\n\n* **Concepts and Solving questions** categories are present in evey part. \n* **Intention and Starter** categories are almost missing in each part. There is only **one occurence of Intention category** in **part 2** and **starter category is present only in part 5 and 6**.","ae3996cd":"**\ud83d\udccc Points to note :**\n\n* row_id - ID code for the row.\n\n* timestamp - the time between this user interaction and the first event from that user.\n\n* user_id - ID code for the user.\n\n* content_id - ID code for the user interaction\n\n* content_type_id - 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.\n\n* task_container_id - Id code for the batch of questions or lectures. For example, a user might see three questions in a row before seeing the explanations for any of them. Those three would all share a task_container_id. Monotonically increasing for each user.\n\n* user_answer - the user's answer to the question, if any. Read -1 as null, for lectures.\n\n* answered_correctly - if the user responded correctly. Read -1 as null, for lectures.\n\n* prior_question_elapsed_time - How long it took a user to answer their previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Note that the time is the total time a user took to solve all the questions in the previous bundle.\n\n* prior_question_had_explanation - Whether or not the user saw an explanation and the correct response(s) after answering the previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback.\n\nLet's get somemore info about the training data.","4a6bd05d":"### Unique Values","d2a18f24":"# 4. <a id='4'>Data Overview\ud83d\udd0d<\/a>\n[Table of contents](#0.1)\n\nIn this section we will develop some intuition about the [competition data](https:\/\/www.kaggle.com\/c\/riiid-test-answer-prediction\/data). The train.csv is huge around 5.45 GB we will use python **datatable** package to load this huge tabular data in our notebook. The **datatable** is adopted from the [R data.table](https:\/\/cran.r-project.org\/web\/packages\/data.table\/vignettes\/datatable-intro.html) package for faster readability of tabular data. Thanks to [Rohan Rao](https:\/\/www.kaggle.com\/rohanrao) for this [notebook](https:\/\/www.kaggle.com\/rohanrao\/riiid-with-blazing-fast-rid\/notebook).","cbfe6f9f":"**\ud83d\udccc Points to note :**\n* We see **Top 10 most active users in first plot**. User with Id **801103753** has most number of interactions around **17,917**.\n* **Content** with Id **6116** is most popular.  \n* **Task Id** is unique Id for batched of questions\/lectures. **Task Id 14** is at the top followed by **15 and 4**. ","a1d04f04":"### 5.1.3 <a id='5.1.3'>Test Data Feature Distribution<\/a>\n[Table of contents](#0.1)","4c5477e4":"## 4.1 <a id='4.1'>Train Data<\/a>\n[Table of contents](#0.1)","12e107da":"# 6. <a id='6'>Multiple Features\ud83d\udcc8<\/a>\n[Table of contents](#0.1)\n\n## 6.1 <a id='6.1'>Train Data Features<\/a>","1e921442":"### Unique Values","c9a0b661":"**\ud83d\udccc Points to note :**\n\nWe can see test dataframe is same as train.csv except we have two new columns. \n\n* prior_group_responses - provides all of the user_answer entries for previous group in a string representation of a list in the first row of the group. All other rows in each group are null. If you are using Python, you will likely want to call eval on the non-null rows. Some rows may be null, or empty lists.\n\n* prior_group_answers_correct - provides all the answered_correctly field for previous group, with the same format and caveats as prior_group_responses. Some rows may be null, or empty lists.","601b949e":"**\ud83d\udccc Points to note :**\n\n* We can see **7 category codes** for lectures. **34%** lectures having **code 5**. Only **5%** lectures have **code 3**.\n* Most of the lectures seems to be describing **theoritical concepts(53%)** followed by **44%** lectures on **solving questions**. We can see significantly less percentage of lectures for **Intention and Starter** categories **2% and 1% respectively**. ","f8069693":"<img src=\"https:\/\/mma.prnewswire.com\/media\/1200045\/Riiid_Labs.jpg?p=publish&w=950\" width=\"800\" height=\"400\">\n\n## <center>Riiid! Answer Correctness Prediction<\/center>\n### <center>\ud83e\udde0Track knowledge states of 1M+ students in the wild\ud83e\udde0<\/center>","6e0ed192":"**\ud83d\udccc Points to note :**\n\n* We observe for most of the users response **there are 3-4 tags associated per question**.\n* **Part 7** has more number of tags for all available correct answers. \n* For all correct answers **3 tag** are present in **Part 1, 3,and 4**.\n* For **correct answers (choices 0 and 4)** we see there are **questions with 4, 5 and 6 tags associated**.  ","899a29ca":"## 5.1 <a id='5.1'>Continous Feature Distribution<\/a>\n### 5.1.1 <a id='5.1.1'>Train Data Feature Distribution<\/a>","7c89c310":"# 2. <a id='2'>Import Packages\ud83d\udcda<\/a>\n[Table of contents](#0.1)","e326a852":"**\ud83d\udccc Points to note :**\n\n* It seems that users saw explanation and correct response after answering the previous question bundle. We have boolean value **True** and **False** if the users saw explanation or not respectively. \n\n* Most of the events in second graph represents **questions posed to the users around 98%**. Very small percentage **(~2%) of the events are associated with users watching a lecture**.\n\n## 5.2.2 <a id='5.2.2'>Questions Data<\/a>\n[Table of contents](#0.1)","f5bb7d22":"**\ud83d\udccc Points to note :**\n\n* We have **3,93,656 unique users**.\n* We have 10,000 unique batches of questions. \n* We have 4 categorical features **content_type_id, user_answer, answered_correctly, prior_question_had_explanation**.","1444dc3d":"\n## 4.3 <a id='4.3'>Lectures Data (metadata)<\/a>\n[Table of contents](#0.1)","820336b4":"## 6.2 <a id='6.2'>Question MetaData Features<\/a>\n[Table of contents](#0.1)","230e5a4e":"**\ud83d\udccc Points to note :**\n\n* In the above plot we have **added some more information to visualize more relationships i.e tag variable**. **Concepts and Solving questions** categories are present in evey part as we can see in the bar plots above this graph. \n\n* There are **151 unique tags for lectures**. Most of which are in two categories i.e **Concepts and Solving questions**.\n\n* **Parts 5 and 6** seems to have more tags mostly in three categories **Concepts, Solving questions and Starter**. \n\n* There is one **outlier in Part 7 for *Solving Question* category**. ","446b5f47":"## 4.2 <a id='4.2'>Questions Data (metadata)<\/a>\n[Table of contents](#0.1)","f3c085b1":"### 5.1.2 <a id='5.1.2'>Lectures Data Feature Distribution<\/a>\n[Table of contents](#0.1)","cdf659cc":"## 6.3 <a id='6.3'>Lectures MetaData Features<\/a>\n[Table of contents](#0.1)","8c855bb7":"### Unique Values","1bedbbb1":"**\ud83d\udccc Points to note :**\n* We have **2744044** in total. **2351538** in column **prior_question_elapsed_time** and **392506** in **prior_question_had_explanation**.","139100c1":"# 5. <a id='5'>Individual Features\ud83d\udcca<\/a>\n[Table of contents](#0.1)\n\nNow we will visualize our data using information available to us in each of the csv file. ","75e2ca2a":"For more information visit [here](https:\/\/www.iibc-global.org\/english\/toeic\/test\/lr\/about\/format.html) regarding the part column in questions.csv.\n\n**\ud83d\udccc Points to note :**\n* We see user's answer to MCQ questions. The first graph is same as the graph just above it from the **train.csv's user_answer column** almost same distribution except we **don't have -1 label for lectures**.  \n* The secound bar graph has information related to the sections in TOIEC English-language Assessment. It has 7 parts as given [here](https:\/\/www.iibc-global.org\/english\/toeic\/test\/lr\/about\/format.html). Most of the questions appear from **part 5 (Incomplete Sentences)**. In TOIEC English-language Assessment we have 2 sections **Listening and Reading Section** where former section has **4 part** and later section has **3 parts**.","b042a202":"**\ud83d\udccc Points to note :**\n\n* Tags assign to each question. We can see most the questions have only **one tag (48%) followed by questions with three tags (29%)**. \n* **92 is the most used tags for questions**.\n\n\n## 5.2.3 <a id='5.2.3'>Lectures Data<\/a>\n[Table of contents](#0.1)\n\nThis tabular data contain metadata for the lectures watched by students. ","a9621ba9":"**\ud83d\udccc Points to note :**\n\n* User's response to given questions (MCQ) and if the answer is correct or not. ","9044e1f1":"**\ud83d\udccc Points to note :**\n\n* We can see correct responses by users for each of the 7 parts. There seems to be only three reponses for part 2.","3105c23d":"# 7. <a id='7'>Reference<\/a>\n[Table of contents](#0.1)\n* https:\/\/www.kaggle.com\/sohier\/competition-api-detailed-introduction\n* [Unique Values](https:\/\/stackoverflow.com\/questions\/27241253\/print-the-unique-values-in-every-column-in-a-pandas-dataframe)\n* [Fast Tabular Data Read](https:\/\/www.kaggle.com\/rohanrao\/riiid-with-blazing-fast-rid\/notebook)","70d6d74b":"**\ud83d\udccc Points to note :**\n* We can see that user most of the time user's saw explanation after giving answers. Also, **answers** ranges from **-1 to 3** where -1 indicate a lecture video. \n* User's tend to answer correctly often and see explanation after answering the previous question bundle. We can also see **class imbalance**.","69c9ad5f":"## 6.4 <a id='6.4'>Feature Correlation<\/a>\n[Table of contents](#0.1)\n\nLet's see some correlation using heatmap.","0573be74":"**\ud83d\udccc Points to note :**\n\n* **timestamp** represents user interaction upto first event completion. We see the graph is rightly skew. \n* **User Id** is unique id assigned to each user.","b37e96a6":"# 3. <a id='3'>Utility<\/a>\n[Table of contents](#0.1)\n","597803db":"## 5.2 <a id='5.2'>Categorical Feature Distribution<\/a>\n[Table of contents](#0.1)\n\n## 5.2.1 <a id='5.2.1'>Train Data<\/a>","e20a58de":"**\ud83d\udccc Points to note :**\n\n* lecture_id - foreign key for the train\/test content_id column, when the content type is lecture (1).\n\n* part - top level category code for the lecture.\n\n* tag - one tag codes for the lecture. The meaning of the tags will not be provided, but these codes are sufficient for clustering the lectures together.\n\n* type_of - brief description of the core purpose of the lecture\n\n### Missing Values in lectures.csv","5f34b8b3":"**\ud83d\udccc Points to note :**\n* User's answers to MCQ type questions. We can see users **have 4 options to choose from**. **-1** means lecture videos.  \n* **answered_correctly** is our traget label. It is binary target variable **0 means False and 1 means True** ignoring -1 since it is label for lecture videos. It sepecify if the answer chose by users in graph one are correct or not. We can see **most the users tend to answer correctly**. ","9040a9a2":"\n## 4.4 <a id='4.4'>Test Data<\/a>\n[Table of contents](#0.1)\n\nIn this competition we have to predict which questions each student can answer correctly. You will loop through a series of batches of questions. Once you make that prediction, you can move on to the next batch.\n\nWe need to use **riiideducation** python module to work with our test data. For more detailed explanation please visit [here](https:\/\/www.kaggle.com\/sohier\/competition-api-detailed-introduction).","8c00f1f3":"# Table of contents <a id='0.1'><\/a>\n\n* [Introduction](#1)\n* [Import Packages](#2)\n* [Utility](#3)\n* [Data Overview](#4)\n    * [Train Data](#4.1)\n    * [Questions Data](#4.2)\n    * [Lectures Data](#4.3)\n    * [Test Data](#4.4)\n* [Individual Features](#5)\n    * [Continous Feature Distribution](#5.1)\n        * [Train Data Feature Distribution](#5.1.1)\n        * [Lectures Data Feature Distribution](#5.1.2)\n        * [Test Data Feature Distribution](#5.1.3)\n    * [Categorical Feature Distribution](#5.2)\n        * [Train Data](#5.2.1)\n        * [Questions Data](#5.2.2)\n        * [Lectures Data](#5.2.3)\n* [Multiple Features](#6)\n    * [Train Data Features](#6.1)\n    * [Questions MetaData Features](#6.2)\n    * [Lectures MetaData Features](#6.3)\n    * [Feature Correlation](#6.4)\n* [Reference](#7)"}}