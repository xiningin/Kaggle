{"cell_type":{"4e5d38a3":"code","360789b3":"code","fbc2b697":"code","ec07185a":"code","9a4fffdd":"code","2eb17eea":"code","c27b9f8e":"code","71b964ce":"code","280a6e1c":"code","7d809917":"code","ff7a7814":"code","79a8732a":"code","b9b59263":"code","76c289c2":"code","dc8823c2":"markdown","c0ebc3b9":"markdown","74d86c58":"markdown","c7ffc8da":"markdown","b1210f87":"markdown","d20982dd":"markdown","2c2d7747":"markdown","e1fecc33":"markdown"},"source":{"4e5d38a3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","360789b3":"soccer_data = pd.read_csv('..\/input\/fifa-20-complete-player-dataset\/players_20.csv') ","fbc2b697":"soccer_data.head()","ec07185a":"EPL_list = ['Arsenal', 'Aston Villa', 'Bournemouth', 'Brighton & Hove Albion', \n            'Burnley', 'Chelsea', 'Crystal Palace','Everton', 'Leicester City', \n            'Liverpool', 'Manchester City', 'Manchester United', 'Newcastle United', \n            'Norwich City', 'Sheffield United', 'Southampton', 'Tottenham Hotspur', \n            'Watford', 'West Ham United', 'Wolverhampton Wanderers']","9a4fffdd":"soccer_data['new'] = soccer_data['club'].apply(lambda x: 1 if x in EPL_list else 0)\nEPL_data = soccer_data[soccer_data['new'] == 1]","2eb17eea":"EPL_data = EPL_data.dropna(axis='columns') # remove NA's\nEPL_data = EPL_data[EPL_data['player_positions'] != 'GK'] # remove Goalkeepers\nEPL_data = EPL_data.loc[:,~EPL_data.columns.str.contains('^goalkeeping', case=False)] # remove Goalkeepers skills \nEPL_data = EPL_data._get_numeric_data() # remove non-numerical data\nEPL_data= EPL_data.drop(columns=['sofifa_id', 'new', 'value_eur', 'team_jersey_number','contract_valid_until', 'overall', 'potential'])","c27b9f8e":"EPL_data.columns","71b964ce":"from matplotlib.pyplot import figure\n\nfig, axes = plt.subplots(2, 3, figsize=(20, 10))\n# fig, ax = plt.subplots()\n\nEPL_data.loc[:, ['attacking_crossing', 'attacking_finishing', \n                 'attacking_heading_accuracy', 'attacking_short_passing',\n                 'attacking_volleys']].plot.hist(bins=12, alpha=0.3, ax=axes[0,0])\n\nEPL_data.loc[:, ['skill_fk_accuracy', 'skill_long_passing', \n                 'skill_ball_control']].plot.hist(bins=12, alpha=0.3, ax=axes[0,1])\n\nEPL_data.loc[:, ['movement_acceleration', 'movement_sprint_speed', \n                 'movement_agility', 'movement_reactions', \n                 'movement_balance']].plot.hist(bins=12, alpha=0.3, ax=axes[0,2])\n\nEPL_data.loc[:, ['power_jumping', 'power_stamina', 'power_strength',\n                 'power_long_shots']].plot.hist(bins=12, alpha=0.3, ax=axes[1,0])\n\nEPL_data.loc[:, ['mentality_aggression', 'mentality_interceptions',\n                 'mentality_positioning', 'mentality_vision', 'mentality_penalties',\n                 'mentality_composure']].plot.hist(bins=12, alpha=0.3, ax=axes[1,1])\n\nEPL_data.loc[:, ['defending_marking', 'defending_standing_tackle',\n                 'defending_sliding_tackle']].plot.hist(bins=12, alpha=0.3, ax=axes[1,2])","280a6e1c":"EPL_data","7d809917":"# Use numpy to convert to arrays\nimport numpy as np\n# Labels are the values we want to predict\nlabels = np.log(EPL_data['wage_eur'])\n# Remove the labels from the features\n# axis 1 refers to the columns\nfeatures= EPL_data.drop('wage_eur', axis = 1)\n# Saving feature names for later use\nfeature_list = list(features.columns)\n# Convert to numpy array\nfeatures = np.array(features)","ff7a7814":"# Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n# Split the data into training and testing sets\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)","79a8732a":"# Import the model we are using\nfrom sklearn.ensemble import RandomForestRegressor\n# Instantiate model with 1000 decision trees\nrf = RandomForestRegressor(n_estimators = 1000, random_state = 0)\n# Train the model on training data\nrf.fit(train_features, train_labels);","b9b59263":"# Use the forest's predict method on the test data\npredictions = rf.predict(test_features)\n# Calculate the absolute errors\nerrors = abs(predictions - test_labels)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')","76c289c2":"import matplotlib.pyplot as plt\nplt.plot(predictions, test_labels, 'o', color='black');","dc8823c2":"## Filter Data","c0ebc3b9":"# Salary Prediction Soccer","74d86c58":"## Data Exploration","c7ffc8da":"## Machine Learning - Random Forest Model","b1210f87":"## Filter English Teams","d20982dd":"## Import Libraries","2c2d7747":"## Plot Result","e1fecc33":"## Import Data"}}