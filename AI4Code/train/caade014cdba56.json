{"cell_type":{"62803fae":"code","e114c820":"code","e0a40a2b":"code","fdc51950":"code","59f2c55e":"code","db9d25a3":"code","36800655":"code","e1fc6bce":"code","c3f37b51":"code","97594de2":"code","725bc528":"code","6e2f2ee6":"markdown","f0241b7f":"markdown","deaf1d76":"markdown","59564c4c":"markdown","993491c6":"markdown","a5238769":"markdown","c4383c35":"markdown","335ea052":"markdown"},"source":{"62803fae":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nimport collections\n\nextensions = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        extension = filename.split('.')[-1]\n        extensions.append(extension)\n","e114c820":"collections.Counter(extensions)","e0a40a2b":"from PIL import Image \nimport matplotlib.pyplot as plt\n\ndef read_annot(path):\n    with open(path) as f:\n        annot = f.read()\n    return annot\n\nplt.figure(figsize=(8,8))\nimage = Image.open('\/kaggle\/input\/gomrade-dataset-go-baduk-images-with-labels\/dataset\/7\/Zrzut ekranu 2020-04-11 o 15.39.39.png')\nplt.imshow(image)\nplt.show()\n\nannot = read_annot('\/kaggle\/input\/gomrade-dataset-go-baduk-images-with-labels\/dataset\/7\/Zrzut ekranu 2020-04-11 o 15.39.39.txt')\nprint(annot)","fdc51950":"import yaml\ndef load_board_extractor_state(path):\n    with open(path) as f:\n        board_annotation = yaml.load(f, Loader=yaml.FullLoader)\n\n    return board_annotation","59f2c55e":"board_annotation = load_board_extractor_state('\/kaggle\/input\/gomrade-dataset-go-baduk-images-with-labels\/dataset\/7\/board_extractor_state.yml')","db9d25a3":"board_annotation","36800655":"plt.figure(figsize=(8,8))\nplt.imshow(image)\nplt.scatter([pt[0] for pt in board_annotation['pts_clicks']], [pt[1] for pt in board_annotation['pts_clicks']], c='red', s=100)\nplt.show()","e1fc6bce":"import tqdm\n\nROOT = '\/kaggle\/input'\n\ndef get_dataset(path):\n    dataset = []\n    for dirname, _, filenames in tqdm.tqdm(os.walk(path)):\n        for filename in filenames:\n            if filename.endswith('.jpg') or filename.endswith('.JPG') or filename.endswith('.png'):\n                row = {}\n                image = Image.open(os.path.join(dirname, filename))\n                row['image'] = image\n                row['path'] = os.path.join(dirname, filename)\n\n                if os.path.exists(os.path.join(dirname, filename[:-4] + '.txt')):\n                    row['annot'] = read_annot(os.path.join(dirname, filename[:-4] + '.txt'))\n                    \n                if os.path.exists(os.path.join(dirname, filename[:-4] + '.TXT')):\n                    row['annot'] = read_annot(os.path.join(dirname, filename[:-4] + '.TXT'))\n                    \n                if os.path.exists(os.path.join(dirname, 'board_extractor_state.yml')):\n                    row['pts_clicks'] = load_board_extractor_state(os.path.join(dirname, 'board_extractor_state.yml'))['pts_clicks']\n                    \n                dataset.append(row)\n    return dataset\n\ndef visualize_datapoint(datapoint):\n    print(datapoint['path'])\n    plt.figure(figsize=(8,8))\n    plt.imshow(datapoint['image'])\n    plt.scatter([pt[0] for pt in datapoint['pts_clicks']], [pt[1] for pt in datapoint['pts_clicks']], c='red', s=100)\n    plt.show()\n\n    annot = datapoint['annot']\n    print(annot)\n    \n    annot = datapoint['pts_clicks']\n    print(annot)\n                \n        \ndata = get_dataset(ROOT)","c3f37b51":"visualize_datapoint(data[1])","97594de2":"len(data)","725bc528":"len(data) * 19 * 19","6e2f2ee6":"## Dataset size\n\nWe have that many images from 66 games:","f0241b7f":"### Initial\n\nThis is some initial view at the data","deaf1d76":"There is a lot of info in board_annotation f.e. board intersections, transformation matrix, but the most important is 'pts_clicks'","59564c4c":"## About modeling\n\nHaving such a a dataset you can start your own research in this area! I encourage you to do so. How accurate can stones classifiers be? And maybe you are able to detect also the board, no basing on the annotation from the annot files?\n\n\n### Train\/test data split\n\nRemember, however, that the split based on rows only may not be sufficient. It would be much better to split data on the folders so that you don't have images from the same game in training and testing split. Only then your classifier will generalize to new, unseen boards, cameras, and angles.\n\n","993491c6":"## Example of Board Annotation","a5238769":"Which results in `786980` board points to predict!","c4383c35":"## Example of Image and Annotation","335ea052":"# Creating dataset for modeling\n\nNow we should create pairs of images-annotations for each image. For that, we will first create a triple: \n- path to image\n- path to annotation\n- path to board annots"}}