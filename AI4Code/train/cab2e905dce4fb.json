{"cell_type":{"bd90f244":"code","cb31f8b3":"markdown","023c9779":"markdown"},"source":{"bd90f244":"from pyspark.sql.functions import *\nfrom fbprophet import Prophet\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nimport pandas as pd\nfrom pyspark.sql.types import *\nimport pickle\nimport numpy as np\n\n#read data \nprod_demand_df = read(\"TimeSeries_ElectricProduction.ElectricProduction\")\n#explore data\nprod_demand_df.printSchema()\nprod_demand_df.show(10)\nprod_demand_df.count()\n\n#I found the date is recognized as string \n#I tried to covert Date in string to a date for pandas\nprod_demand_df = prod_demand_df.withColumn('Date_date',to_date(prod_demand_df.DATE, 'MM-dd-yyyy')).drop(prod_demand_df.DATE)\nprod_demand_df.printSchema()\nprod_demand_df.show(10)\n\n#convert spark dataframe to pandas dataframe\npdf = prod_demand_df.toPandas()\n# Check the format of 'Date' column\npdf.info()\n\n#spark dataframe with the datatype still recognized as object \n# convert the 'Date' column to datetime format\npdf['Date_date'] = pdf['Date_date'].astype('datetime64[ns]')\n# Check the format of 'Date' column\npdf.info()\n#set index \npdf.set_index(pd.DatetimeIndex(pdf['Date_date']))\ncutoff_date = \"01-01-2017\"\nbefore_cutoff = pdf[\"Date_date\"] < cutoff_date\nafter_cutoff = pdf[\"Date_date\"] >= cutoff_date\n#filter data before date\ntrain = pdf.loc[before_cutoff]\ntrain.tail(10)\ntrain.info()\nprint(type(train))\n\n#Rename the columns for Prophet\n#ds:date y:indicating the amount we want to predict\ntrain.columns = ['y','ds']\n\n#Create model\nprophet = Prophet(changepoint_prior_scale=0.15, daily_seasonality=False)\nprophet.fit(train)\n#Prediction\nfuture = list()\n\nfor i in range(1, 13):\n    date = '2017-%02d' % i\n    print(i, date)\n    future.append([date])\nfuture = pd.DataFrame(future)\nfuture.columns = ['ds']\nfuture['ds']= pd.to_datetime(future['ds'])\nfuture\n#Use the model(prophet) to make a forecast\nforecast=prophet.predict(future)\nforecast\n\n#filter data before date\ntrain = pdf.loc[before_cutoff]\ntrain\n#filter data after date\ntest = pdf.loc[after_cutoff]\ntest\n#concat dataframe\npdf_with_forecast = pd.concat([train, test])\npdf_with_forecast\n#yhat:predicted value\ntest2 = forecast.loc[:,['ds', 'yhat']]\ntest2\n\n\n#rename columns For the same column name, merge column\ntest2.rename(columns = {'ds':'Date_date'}, inplace = True)\ntest2\n\n#merge colume become 3 columes\ndtest = test.merge(test2, on=\"Date_date\", how = 'inner')\n#Change the order of the columns\ndtest = dtest[['Date_date','Value','yhat']]\ndtest\n#import numpy as np\ntrain['yhat']=np.nan\n#Change the order of the columns\ndtrain = train[['Date_date','Value','yhat']]\ndtrain\n#concat two dataframes\npdf_result = pd.concat([dtrain, dtest])\npdf_result\n#covert pandas dataframe to spark dataframe \nresult_df = spark.createDataFrame(pdf_result)\nsave(result_df)","cb31f8b3":"## I'm using time series analysis electric production by FB Prophet","023c9779":"### Here is the result in Incorta. The blue line showing original data, and the green line showing predict electric production. \n\n![this is a pic](https:\/\/1.bp.blogspot.com\/--WFnbjOfH54\/YIj6yUCteNI\/AAAAAAAAAs8\/o07GNQMMB6MJ6ojiNe69zkk0hfSzHz7UgCLcBGAsYHQ\/s16000\/Screen%2BShot%2B2021-04-27%2Bat%2B10.32.33%2BPM.png)"}}