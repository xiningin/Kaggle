{"cell_type":{"84bb1e26":"code","90b8f102":"code","28dd4f33":"code","e84dda1b":"code","966846f9":"code","d52df2b1":"code","13cbd5f8":"code","c1efe508":"code","3a0f6cd5":"code","e01f8856":"code","c4b35693":"code","5bc5d923":"code","b0c42a9b":"markdown","5eba7f23":"markdown","da04fbe6":"markdown","13285fa2":"markdown","b598df2f":"markdown","ee47f71b":"markdown","4623573b":"markdown","b93b909e":"markdown"},"source":{"84bb1e26":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","90b8f102":"FILE_PATH = '\/kaggle\/input\/clickbait-dataset\/clickbait_data.csv'\ndata = pd.read_csv(FILE_PATH)\ndata","28dd4f33":"text = data['headline'].values\nlabels = data['clickbait'].values\ntext_train, text_test, y_train, y_test = train_test_split(text, labels)\nprint(text_train.shape, text_test.shape, y_train.shape, y_test.shape)","e84dda1b":"vocab_size = 5000\nmaxlen = 500\nembedding_size = 32\n\ntokenizer = Tokenizer(num_words=vocab_size)\ntokenizer.fit_on_texts(text)\n\nX_train = tokenizer.texts_to_sequences(text_train)\nx_test = tokenizer.texts_to_sequences(text_test)\n\nX_train = pad_sequences(X_train, maxlen=maxlen)\nx_test = pad_sequences(x_test, maxlen=maxlen)","966846f9":"model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_size, input_length=maxlen))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","d52df2b1":"callbacks = [\n    EarlyStopping(\n        monitor='val_accuracy',\n        min_delta=1e-4,\n        patience=3,\n        verbose=1\n    ),\n    ModelCheckpoint(\n        filepath='weights.h5',\n        monitor='val_accuracy', \n        mode='max', \n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n]","13cbd5f8":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, batch_size=512, validation_data=(x_test, y_test), epochs=20, callbacks=callbacks)","c1efe508":"model.load_weights('weights.h5')\nmodel.save('model')","3a0f6cd5":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nx = range(1, len(acc) + 1)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(x, acc, 'b', label='Training acc')\nplt.plot(x, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(x, loss, 'b', label='Training loss')\nplt.plot(x, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","e01f8856":"preds = [round(i[0]) for i in model.predict(x_test)]\ncm = confusion_matrix(y_test, preds)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Not clickbait', 'Clickbait'], fontsize=16)\nplt.yticks(range(2), ['Not clickbait', 'Clickbait'], fontsize=16)\nplt.show()","c4b35693":"tn, fp, fn, tp = cm.ravel()\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))","5bc5d923":"test = ['My biggest laugh reveal ever!', 'Learning game development with Unity', 'A tour of Japan\\'s Kansai region', '12 things NOT to do in Europe']\ntoken_text = pad_sequences(tokenizer.texts_to_sequences(test), maxlen=maxlen)\npreds = [round(i[0]) for i in model.predict(token_text)]\nfor (text, pred) in zip(test, preds):\n    label = 'Clickbait' if pred == 1.0 else 'Not Clickbait'\n    print(\"{} - {}\".format(text, label))","b0c42a9b":"# Plot training metrics","5eba7f23":"# Run predictions on arbitrary user input","da04fbe6":"# Importing libraries","13285fa2":"# Tokenize text","b598df2f":"# Plot confusion matrix and metrics","ee47f71b":"# Loading data","4623573b":"# Train-test split","b93b909e":"# Define and train model"}}