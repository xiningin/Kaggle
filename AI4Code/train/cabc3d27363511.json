{"cell_type":{"d6ea17d8":"code","74a09d28":"code","b8823ecf":"code","283887c8":"code","baf6efdb":"code","af77a74b":"code","4a8defd9":"markdown","469c3fdd":"markdown","5b791d9f":"markdown"},"source":{"d6ea17d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","74a09d28":"insurance_file_path = \"..\/input\/insurance-premium-prediction\/insurance.csv\"\nX_full = pd.read_csv(insurance_file_path)\nprint(X_full.shape)\n\nmissing_val_count_by_column = (X_full.isnull().sum())\nprint(missing_val_count_by_column)\n\n\nprint(\"There is no NaN value in the dataset\")","b8823ecf":"# First, let's take a peek at the training data\nX_full.head(20)","283887c8":"# Get list of categorical variables\ns = (X_full.dtypes == 'object')\nobject_cols = list(s[s].index)\n\nprint(\"Categorical variables:\")\nprint(object_cols)","baf6efdb":"# Loop all categorical columns and get values\nfor col in object_cols:\n    col_options = X_full[col].nunique()\n    col_options_value = X_full[col].unique()\n    print ('Number of {} are: {}, there are {}'.format(col, col_options, col_options_value))","af77a74b":"# Pipelines step\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', categorical_transformer, object_cols)\n    ])\n\n# Define model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\n\n# Bundle preprocessing and modeling code in a pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)\n                     ])","4a8defd9":"# Insurance purchase prediction\n\nHi! This notebook is belong to **CTy TNHH Bamboo**. Our team members are: An, Anh, Tung.","469c3fdd":"# Next, let's handling categorical data\n\nThis part belongs to **Tung**","5b791d9f":"# First, let's handle empty rows\n\nThis part belongs to **An**\n"}}