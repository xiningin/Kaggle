{"cell_type":{"2bc5c221":"code","2cbd302c":"code","ed67e325":"code","06901875":"code","e1956d34":"code","44f3238b":"code","12a1abe6":"code","b9ea3161":"code","a2962a8f":"code","2ae0cfbe":"code","d4643993":"code","65bbd0aa":"code","a861d46b":"code","3812a2b5":"code","fd02b920":"code","66f06077":"code","a41bd0bc":"code","a9af6077":"code","9925c7f7":"code","ee0de33f":"code","383c7517":"code","c0c51688":"code","4e01b571":"code","b4d0678b":"code","74f1839f":"code","9ca7ee74":"code","0c6214f5":"code","847692a3":"code","21bf0db1":"code","c61c6e87":"code","5e27c497":"code","ee1e53bd":"code","dea45731":"code","82865fef":"code","c4242e9a":"code","d54d50ff":"code","096b10c1":"code","cd58ac11":"markdown","56067b76":"markdown","c9928dc9":"markdown","cf92a972":"markdown","1a719269":"markdown","51a04ccb":"markdown","d338d876":"markdown","a7866b46":"markdown","1d5e5063":"markdown","5aff61a6":"markdown"},"source":{"2bc5c221":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nfrom PIL import Image\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport cv2\ntorch.manual_seed(1)\nnp.random.seed(1)\nimport re\nimport pydicom\nimport math\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut","2cbd302c":"IMAGE_SIZE = 256\nNUM_IMAGES = 64\nBATCH_SIZE= 4","ed67e325":"def loading_image(path, img_size=IMAGE_SIZE):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    data = cv2.resize(data, (img_size, img_size))\n    return data","06901875":"def load_3d_image(idx, mri_type, num_imgs=NUM_IMAGES, split='train'):\n    files = sorted(glob.glob(f\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/{split}\/{idx}\/{mri_type}\/*.dcm\"), \n                   key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n    middle = int(len(files) \/ 2)\n    half_num_imgs = int(num_imgs \/ 2)\n    start = max(0, middle - half_num_imgs)\n    end = min(len(files) + 1, middle + half_num_imgs)\n#     for i, f in enumerate(files[start:end]):\n#         if i == 0:\n#             img3d = loading_image(f)\n#         else:\n#             img3d = np.stack([loading_image(f)])\n    arrays = [loading_image(f) for f in files[start:end]]\n#     print(arrays)\n    img3d = np.stack(arrays, axis=2)\n    \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((IMAGE_SIZE, IMAGE_SIZE, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis=-1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d \/ np.max(img3d)\n\n    return img3d\n","e1956d34":"def load_png(path, img_size=IMAGE_SIZE):\n    img = Image.open(path)\n    img = np.array(img)\n    img = cv2.resize(img, (img_size, img_size))\n    \n    return img","44f3238b":"def load_3d_png(idx, mri_type, num_imgs=NUM_IMAGES, split='train'):\n    files = sorted(glob.glob(f\"..\/input\/rsna-miccai-png\/{split}\/{idx}\/{mri_type}\/*.png\"), \n                   key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n    middle = int(len(files) \/ 2)\n    half_num_imgs = int(num_imgs \/ 2)\n    start = max(0, middle - half_num_imgs)\n    end = min(len(files) + 1, middle + half_num_imgs)\n    arrays = [load_png(f) for f in files[start:end]]\n#     raise ValueError(idx)\n#     print(idx)\n#     print(len(arrays))\n    img3d = np.stack(arrays, axis=2)\n    \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((IMAGE_SIZE, IMAGE_SIZE, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis=-1)\n\n    return img3d\n","12a1abe6":"train_labels = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv')","b9ea3161":"train_labels","a2962a8f":"train_files = sorted(os.listdir('..\/input\/rsna-miccai-png\/train'))","2ae0cfbe":"len(train_files)","d4643993":"train_files = pd.Series(train_files, name='train_files')","65bbd0aa":"train_labels = pd.concat([train_labels, train_files], axis=1)","a861d46b":"train_labels","3812a2b5":"train_labels = train_labels[train_labels['BraTS21ID'] != 109]","fd02b920":"train_labels = train_labels[train_labels['BraTS21ID'] != 709]","66f06077":"train_labels['MGMT_value'].value_counts()","a41bd0bc":"test_data = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv')\ntest_ids = []\nfor f in test_data.itertuples():\n    test_ids.append(f[1])","a9af6077":"a = load_3d_png(\"00000\", \"FLAIR\")\nprint(a.shape)","9925c7f7":"plt.imshow(load_3d_png(\"00122\", \"FLAIR\")[:, :, 2], cmap='gray')","ee0de33f":"class TumorDataset(torch.utils.data.Dataset):\n    def __init__(self, df=train_labels, transform=transforms.Compose([transforms.ToTensor()]), mri_type=\"FLAIR\", train=True):\n        self.df = df\n        self.transform = transform\n        self.type = mri_type\n        self.train = train\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n            if self.train == True:\n                patient_id = self.df.iloc[idx, 2]\n                \n                image = load_3d_png(str(patient_id), self.type)\n                image = self.transform(image)\n                image = image[None, :, :, :]\n                label = self.df.iloc[idx, 1]\n                label = torch.tensor(label)\n                \n                return image, label\n            \n            else:\n                patient_id = self.df[idx]\n                patient_id = str(patient_id)\n                for i in range(5 - len(patient_id)):\n                    patient_id = '0' + patient_id\n                \n                \n                image = load_3d_image(patient_id, self.type, split='test')\n                image = self.transform(image)\n                image = image[None, :, :, :]\n                \n                return image, idx","383c7517":"train_dataset = TumorDataset()\ntest_dataset = TumorDataset(df=test_ids, train=False)","c0c51688":"train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=4)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=4)","4e01b571":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","b4d0678b":"class ThreeDNetwork(nn.Module):\n    \n    def conv_layer(self, in_channels, out_channels, kernel_size, stride=2):\n        conv_layer = nn.Sequential(\n            nn.Conv3d(in_channels, out_channels, kernel_size, stride=stride),\n            nn.LeakyReLU(),\n            nn.MaxPool3d((2, 2, 2)),\n            nn.BatchNorm3d(out_channels))\n        return conv_layer\n    \n    def __init__(self, batch_size=BATCH_SIZE):\n        super(ThreeDNetwork, self).__init__()\n        self.batch_size = batch_size\n        self.block1 = nn.Sequential(\n            self.conv_layer(1, 64, 3, 2),\n            self.conv_layer(64, 128, 3, 2))\n        \n        self.fc = nn.Sequential(\n            nn.Linear(86400, 1024),\n            nn.LeakyReLU(),\n            nn.BatchNorm1d(1024),\n            nn.Dropout(0.2),\n            nn.Linear(1024, 1))\n        \n    def forward(self, x):\n        x = self.block1(x)\n        x = x.view(-1, 86400)\n        x = self.fc(x)\n        return x","74f1839f":"model = ThreeDNetwork()","9ca7ee74":"print(model)","0c6214f5":"optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain_criterion = nn.BCELoss()\nlr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=4, cooldown=2, verbose=True)\n\nmodel = model.to(device)\ntrain_criterion = train_criterion.to(device)","847692a3":"epochs = 30\n\ntotal_train_loss = []\nbest_train_loss = np.Inf\n\nfor epoch in range(epochs): \n    print('Epoch: ', epoch + 1)\n    train_loss = []\n    train_correct = 0\n    train_total = 0\n    for image, target in train_loader:\n        optimizer.zero_grad()\n        new_target = []\n        for element in target:\n            new_target.append([element])\n        new_target = torch.tensor(new_target, dtype=torch.float)\n        image = image.float()\n        image, new_target = image.to(device), new_target.to(device)\n        output = model(image)\n        output = nn.Sigmoid()(output)\n        loss = train_criterion(output, new_target)\n        loss.backward()\n        optimizer.step()\n        train_loss.append(loss.item())\n            \n    epoch_train_loss = np.mean(train_loss)\n    print(f'Epoch {epoch + 1}, train loss: {epoch_train_loss:.4f}')\n    \n    if epoch_train_loss < best_train_loss:\n        torch.save(model.state_dict(), 'tumor.pth')\n        print('Model improved. Saving model.')\n        best_train_loss = epoch_train_loss\n        \n    lr_scheduler.step(epoch_train_loss)\n    total_train_loss.append(epoch_train_loss)","21bf0db1":"def rounding(num):\n    return math.floor(num + 0.5)","c61c6e87":"model.load_state_dict(torch.load('tumor.pth'))","5e27c497":"correct = 0\ntotal = 0\n\nwith torch.no_grad():\n    model.eval()\n    for image, target in train_loader:\n        new_target = []\n        for element in target:\n            new_target.append([element])\n        new_target = torch.tensor(new_target, dtype=torch.int)\n        image = image.float()\n        image, new_target = image.to(device), new_target.to(device)\n        output = model(image)\n        output = nn.Sigmoid()(output)\n        predicted = []\n        for element in output:\n            predicted.append([rounding(element)])\n        predicted = torch.tensor(predicted, dtype=torch.int)\n        predicted = predicted.to(device)\n        total += BATCH_SIZE\n\n        num_correct = 0\n        for i, element in enumerate(predicted):\n            if element == new_target[i]:\n                num_correct += 1\n                \n        correct += num_correct\n\nprint('Train Accuracy: %d %%' % (100 * correct \/ total))","ee1e53bd":"id_series = []\nmgmt_series = []\n\nwith torch.no_grad():\n    for image, idx in test_loader:\n        image = image.float()\n        image = image.to(device)\n        output = model(image)\n        output = nn.Sigmoid()(output)\n        for element in output:\n            for el in element.cpu().numpy():\n                mgmt_series.append(float(math.trunc(el * 10000) \/ 10000.0))\n        idx = idx.tolist()\n        for element in idx:\n            id_series.append(element)","dea45731":"brats_id_series = []\nfor idx in id_series:\n    brats_id_series.append(int(test_ids[idx]))","82865fef":"brats_id_series = pd.Series(brats_id_series, name='BraTS21ID')\nmgmt_series = pd.Series(mgmt_series, name='MGMT_value')\ntest_preds = pd.concat([brats_id_series, mgmt_series], axis=1)","c4242e9a":"# prediction = pd.concat([x.set_index('BraTS21ID') for x in brats_id_series], axis=1).mean(axis=1)\n# prediction = pd.DataFrame(prediction, columns=['MGMT_value']).reset_index()\n# prediction.to_csv('submission.csv',index=False)","d54d50ff":"test_preds.to_csv('submission.csv', index=False)","096b10c1":"test_preds","cd58ac11":"# **Simple Model Architecture**","56067b76":"# **Inference**","c9928dc9":"Fairly balanced train set.","cf92a972":"**Dicom Imgs took too much memory so switched to png dataset**","1a719269":"# **Training**","51a04ccb":"# **Dataset and DataLoader**","d338d876":"109 and 709 don't have flair images so for this dataset. ","a7866b46":"# **Data Loading and Visualizations**","1d5e5063":"References:\nhttps:\/\/www.kaggle.com\/ammarnassanalhajali\/brain-tumor-3d-training","5aff61a6":"# **Import Libraries**"}}