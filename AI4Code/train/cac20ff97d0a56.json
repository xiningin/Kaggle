{"cell_type":{"42018cdc":"code","5780fa36":"code","03efae6c":"code","de8b5c23":"code","f45309a9":"code","f6028869":"code","1e9b142e":"code","547e5140":"code","baec8744":"code","19cecc76":"code","edbf9fa8":"code","14eeee3c":"code","a54f11e8":"code","d7a9dba4":"code","f0d1ca16":"code","01a8cd9c":"code","98037f0a":"code","bd0c2e3e":"code","ae545be6":"code","eaea8d97":"code","da614858":"code","4643e60a":"code","740ec89c":"code","085fa026":"code","54e271ed":"code","ce7621e8":"code","e0d5fd0e":"code","b815c303":"code","3a6a2b22":"code","36d3b5b5":"code","69cc55ca":"code","bfb9648e":"markdown","95019f40":"markdown","8e5017cd":"markdown","f549f49a":"markdown","8cf221dc":"markdown","793f095a":"markdown","7a45730c":"markdown","52aca16d":"markdown","44afc984":"markdown","a6240e3b":"markdown","faa3989a":"markdown","e19e67c5":"markdown","d1542314":"markdown","00edc9a6":"markdown","3546ebda":"markdown","ca7d5932":"markdown","52f4fafd":"markdown"},"source":{"42018cdc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5780fa36":"# for Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# To ignore Unnessary warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n# set the style to use for plotting\nplt.style.use('ggplot')","03efae6c":"# import diffrent algorithms. This will be use to establish a baseline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, RandomForestRegressor","de8b5c23":"df = pd.read_csv('\/kaggle\/input\/aiosogbo-certification-competition\/Train.csv')","f45309a9":"# check the first 5 rows\ndf.head()","f6028869":"# checking the features (columns) names of the data\ndf.columns","1e9b142e":"df.shape","547e5140":"df.info()","baec8744":"df.isnull().sum()","19cecc76":"numeric_features = df.select_dtypes(include=['int64', 'float64'])\ncategorical_features = df.select_dtypes(include='object')\nprint('Numeric Columns are {}'.format(numeric_features.columns))\nprint('-----------'*10)\nprint('Categorical Columns are {}'.format(categorical_features.columns))","edbf9fa8":"# Our target is continous, so we can get the distribution using a histogram\n\nplt.figure\nplt.hist(df['Item_Outlet_Sales'], bins=50)\nplt.xlabel('Item_Outlet_Sales')\nplt.ylabel('count')\nplt.title('Histogram of Item_Outlet_Sales')\nplt.show()","14eeee3c":"# independent Variables (Numeric variables)\n# histogram helps us to visualize the distribution of the variable\nItem_Weight = df['Item_Weight']\nfig, ax = plt.subplots()\nax.hist(Item_Weight.dropna(), color='blue', bins=50, alpha=0.9)\nplt.xlabel('Item_Weight')\nplt.ylabel('count')\nplt.title('Histogram of Item_Weight')","a54f11e8":"Item_Visibility = df['Item_Visibility']\nfig, ax = plt.subplots()\nax.hist(Item_Visibility.dropna(), color='green', bins=80, alpha=0.9)\nplt.xlabel('Item_Visibility')\nplt.ylabel('count')\nplt.title('Histogram of Item_Visibility')","d7a9dba4":"Item_MRP = df['Item_MRP']\nfig, ax = plt.subplots()\nax.hist(Item_MRP.dropna(), color='red', bins=90, alpha=0.9)\nplt.xlabel('Item_MRP')\nplt.ylabel('count')\nplt.title('Histogram of Item_MRP')","f0d1ca16":"df['Item_Fat_Content'].value_counts().plot(kind='bar')\n\nplt.xlabel('Item_Fat_Content')\nplt.ylabel('count')\nplt.title('Histogram of Item_Fat_Content')","01a8cd9c":"df.Item_Fat_Content[df['Item_Fat_Content'] == 'LF'] = 'Low Fat'\ndf.Item_Fat_Content[df['Item_Fat_Content'] == 'low fat'] = 'Low Fat'\n\n# for regular\ndf.Item_Fat_Content[df['Item_Fat_Content'] == 'reg'] = 'Regular'\n\n# plot again\n\ndf['Item_Fat_Content'].value_counts().plot(kind='bar')\n\nplt.xlabel('Item_Fat_Content')\nplt.ylabel('count')\nplt.title('Bar Chart of Item_Fat_Content')\n","98037f0a":"# plot for Item_Type\n\ndf['Item_Type'].value_counts().plot(kind='bar')\n\nplt.xlabel('Item_Fat_Content')\nplt.ylabel('count')\nplt.title('Bar Chart of Item_Fat_Content')\n","bd0c2e3e":"# plot for Outlet_Identifier\n\ndf['Outlet_Identifier'].value_counts().plot(kind='bar')","ae545be6":"# plot for Outlet_Size\n\ndf['Outlet_Size'].value_counts().plot(kind='bar')\n","eaea8d97":"# plot for Establishment_Year\ndf.Outlet_Establishment_Year.value_counts().plot(kind = 'bar')","da614858":"# plot for Outlet_Type\ndf['Outlet_Type'].value_counts().plot(kind='bar')","4643e60a":"# Item_Weight vs Item_Outlet_Sales\nplt.scatter(df['Item_Weight'], df['Item_Outlet_Sales'], c='violet', alpha=0.3, marker='.')\nplt.xlabel('Item_Weight'), plt.ylabel('Item_Outlet_Sales'), plt.title('Item_Weight vs Item_Outlet_Sales')\n\n######################## Item_Outlet_Sales is spread well across the entirerang","740ec89c":"# Item_Visibility vs Item_Outlet_Sales\nplt.scatter(df['Item_Visibility'], df['Item_Outlet_Sales'], c='violet', alpha=0.3, marker='.')\nplt.xlabel('Item_Visibility'), plt.ylabel('Item_Outlet_Sales'), plt.title('Item_Visibility vs Item_Outlet_Sales')\n","085fa026":" # Item_MRP vs Item_Outlet_Sales\nplt.scatter(df['Item_MRP'], df['Item_Outlet_Sales'], c='violet', alpha=0.3, marker='.')\n\nplt.xlabel('Item_MRP'), plt.ylabel('Item_Outlet_Sales'), plt.title('Item_MRP vs Item_Outlet_Sales')","54e271ed":"sns.violinplot(df['Item_Type'], df['Item_Outlet_Sales'])\nplt.xticks(rotation=90)\n","ce7621e8":"sns.violinplot(df['Item_Fat_Content'], df['Item_Outlet_Sales'])\nplt.xticks(rotation=90)","e0d5fd0e":"sns.violinplot(df['Outlet_Size'], df['Item_Outlet_Sales'])\nplt.xticks(rotation=40)","b815c303":"df.isnull().sum()","3a6a2b22":"# fill int or float data type with median and fill categorical data type with mode.\n# Note this is optional you can use what you see best\ndf['Item_Weight'] = df['Item_Weight'].fillna(df['Item_Weight'].median())\n","36d3b5b5":"# remember Item_Visibility as lots of 0 values which is not possible\nplt.hist(df['Item_Visibility'], bins=70, color='grey')\nplt.show()","69cc55ca":"# let replace the zeroes and plot again to see the changes\nzero_index = df['Item_Visibility'] == 0\n\ndf['Item_Visibility'] = df['Item_Visibility'].replace(0, np.median(df.Item_Visibility))\nplt.hist(df['Item_Visibility'], bins=70, color='grey')\nplt.show()","bfb9648e":"Explore data Visually to understand the nature of data in terms of distribution of the individual features, finding missing values, relationship with other variables and many others.\n*UNIVARIATE* Exploratory Data Analysis (EDA) involves exploring features individually. continuous variables should be done using histogram and or scatter plots. Box plots too can help to visualize and understand outliers in the data. Outliers are data points that are either too low or too high as compared to the other values in the dataset. It is also adviced to use bar plots to explore the categorical featurs present in the data\n","95019f40":"**Gaining** insights from categorical variable which can only have a finite set of values\n# lets plot the Item_Fat_Content","8e5017cd":"We can clearly see 4 different distributions for Item_Mrp. it is an intresting insight","f549f49a":"before we start analysis we could split our data into integer type and floats and categorical so we can better analyze each one thoroughly ","8cf221dc":"in the figure LF, Low Fat and low fat are same category and Regular and reg are also the same we can combine this and plot again","793f095a":"### in Bivariate Analysis we will explore the independent variables with respect to the target variable.\n### this hepls to discover hidden patterns between independent and target variable.\n### we can then use those findings to deal with missing data imputation and feature engineering\n\n### scatter plots is advisable for the continuous or numeric features while violin plots for categorical\n\n","7a45730c":"End of Simple EDA hope you have learnt something if yes please do upvote this kernal. Thank you ALL","52aca16d":"Item_Visibility is right skewed and should be transformed to fix its skewness","44afc984":"the plot shows the feature is right skewd and would need some data transformation to treat its skewness\n\n**Keep in mind that item_Outlet_Sales** is the target. so take notes of all you do","a6240e3b":"There seems to be no clear-cut pattern in Item_Weight\nWe can see that it is normally distributed across the dataset","faa3989a":"# Bivariate Analysis","e19e67c5":"from the chart above, Fruits and Vegetables, as the highest count\n","d1542314":"SO there are 1463 missing values in Item_Weight and 2410 missing values in Outlet_size","00edc9a6":"# Visualize Categorical Variables\n\ncheck the distribution of the target across all categorical. violin and boxplot would fit in perfectly, i used violin as it shows full distributionthe width of a violin at a particular level indicates the concentration or density of data target the height tells us about the range of the largest variable values","3546ebda":"There is a string of point at 0.0 for Item_visibility which is not possible more into this soon.","ca7d5932":"dealing with Missing Values","52f4fafd":"we can observe that from the result of the info(), there are missing values in 'Item_Weight' and 'Outlet_Size'\nto get a count of what missing we will use isnull()"}}