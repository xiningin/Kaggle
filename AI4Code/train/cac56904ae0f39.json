{"cell_type":{"3ff8639f":"code","cfbf91e9":"code","54a45716":"code","80642df8":"code","4ff0b432":"code","230ffa74":"code","5ad2cd63":"code","17652145":"code","5e780892":"code","240c76b4":"code","6011fb99":"code","951e77c3":"code","e72c8b75":"code","f32aaf89":"code","47bf7273":"code","a0ba3c88":"code","0b4bc769":"code","fff5efe6":"code","412a58ca":"code","7a78ec27":"code","57569856":"code","03e297b9":"code","a2047a0c":"code","9a625176":"code","5f1b31a9":"code","e895f26d":"code","45c8bb15":"code","a58fdbe7":"code","b19a6714":"code","349c5abb":"code","ae958748":"code","1fabe4a6":"code","520a9870":"code","ea2b775d":"code","b7d634c5":"code","2aa9e6c9":"markdown","a1adca01":"markdown","837f0c78":"markdown","be6be48f":"markdown","b3b2d45a":"markdown","ef576a3d":"markdown"},"source":{"3ff8639f":"#import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n%matplotlib inline\n#import data\ndata = pd.read_csv(\"..\/input\/logistics-delivery-data\/logistics_train_data.csv\")\n#preview top five rows in the dataset\ndata.head()","cfbf91e9":"#Extract Hour, Minute and Second from Pickup Time\ndata[\"Pickup_Hour\"] = pd.to_datetime(data['Pickup_Time'],format= '%H:%M:%S %p' ).dt.hour\ndata[\"Pickup_Minute\"] = pd.to_datetime(data['Pickup_Time'],format= '%H:%M:%S %p' ).dt.minute\ndata[\"Pickup_Second\"] = pd.to_datetime(data['Pickup_Time'],format= '%H:%M:%S %p' ).dt.second","54a45716":"#Check for null values\ndata.isnull().sum()","80642df8":"#Plot temperature values to see distribution. If normal distribution, use mean to handle nulls, if not normal with outliers, use median\nplt.hist(data[\"Temperation\"], bins = 10, color= \"green\")\n#Distribution is normal so we'll use mean to handle nulls","4ff0b432":"#Plot Precipitation_in_millimeters values to see distribution. If normal distribution, use mean to handle nulls, if not normal with outliers, use median\nplt.hist(data[\"Precipitation_in_millimeters\"], bins = 10, color= \"green\")\n#Distribution is not normal and there are outliers so we'll use median to handle nulls","230ffa74":"#Handle Nulls\ndata[\"Temperation\"] = data[\"Temperation\"].fillna(data[\"Temperation\"].mean())\ndata[\"Precipitation_in_millimeters\"] = data[\"Precipitation_in_millimeters\"].fillna(data[\"Precipitation_in_millimeters\"].median())\n","5ad2cd63":"data.isnull().sum()","17652145":"'''\nAs we are predicting the time it will take to deliver a parcel, I am assuming for the modelling that we only know the pick-up date, pick-up time, \npick-up location, delivery location, temperature and Precipitation, hence we are only using these columns as the independent variables while\nTime_Elapsed_from_Pickup_to_Delivery_in_Min is the dependent variable we need to predict.\n'''\ndata.info() #To check for nulls and get indexes of columns we are not using for the model that needs to be dropped: [0,1,2,3,4,5,6,7,8,9,10,11,12,15,16,17,18,19] ","5e780892":"#split data into dependent(y) and independent variables(x) and convert x and y to numpy arrays \ny = data.iloc[:,26].values \nx = data.drop(\"Time_Elapsed_from_Pickup_to_Delivery_in_Min\", axis = 1).values","240c76b4":"#Delete independent variables from x that won't be used in the model \nx = np.delete(x,[0,1,2,3,4,5,6,7,8,9,10,11,12,15,16,17,18,19],1) ","6011fb99":"#Split data into training and test set for modelling\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.20, random_state=88)\n              ","951e77c3":"#Feature Scaling\nfrom sklearn.preprocessing import MinMaxScaler \n\nSc = MinMaxScaler(feature_range = (0,1))\nx_train = Sc.fit_transform(x_train )\nx_test = Sc.transform(x_test)\n\n\ny_train = y_train.reshape(-1,1) #reshape y_train first before normalizing to eliminate error\nSc2 = MinMaxScaler(feature_range = (0,1))\ny_train = Sc2.fit_transform(y_train )","e72c8b75":"from sklearn.linear_model import LinearRegression \n\nLR = LinearRegression()\nLR.fit(x_train,y_train)\n\n\ny_pred = LR.predict(x_test)\n\ny_pred = Sc2.inverse_transform(y_pred)","f32aaf89":"#Linear Regression Model Evaluation \n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\n\nimport math \n\n\n\nMAE = mean_absolute_error(y_test,y_pred) #12.468495177524579\n\nMSE = mean_squared_error(y_test,y_pred) #278.5774526377687\n\nRMSE = math.sqrt(MSE) #16.690639671317836\n\nR2 = r2_score(y_test, y_pred) #0.010062773414825421\n\nYtest_Mean = y_test.mean()  #26.394349730458224\n\nprint(\"Mean Absolute Error:\", MAE)\nprint(\"Mean Squared Error:\", MSE)\nprint(\"Root Mean Squared Error:\", RMSE)\nprint(\"R-Squared:\", R2)\nprint(\"Test data mean:\", Ytest_Mean)\nprint(\"RMSE\/Mean:\", RMSE\/Ytest_Mean) #0.6323565400081586\n","47bf7273":"from sklearn.svm import SVR\n\nRegressor_SVR = SVR(kernel=\"rbf\")\nRegressor_SVR.fit(x_train,y_train.ravel())\n\ny_pred_s = Regressor_SVR.predict(x_test)\n\ny_pred_s = y_pred_s.reshape(-1,1)\ny_pred_s = Sc2.inverse_transform(y_pred_s)","a0ba3c88":"#SVR Model Evaluation \nMAE_S = mean_absolute_error(y_test,y_pred_s) #LR: 12.468495177524579 SVR: 10.70163941936098\n\nMSE_S = mean_squared_error(y_test,y_pred_s) #LR: 278.5774526377687 SVR: 219.9313845248983\n\nRMSE_S = math.sqrt(MSE_S) #LR: 16.690639671317836 SVR: 14.830083766617715\n\nR2_S = r2_score(y_test, y_pred_s) #LR: 0.010062773414825421  SVR: 0.21846415503442718\n\nYtest_Mean = y_test.mean()  #26.394349730458224\n\nprint(\"Mean Absolute Error:\", MAE_S)\nprint(\"Mean Squared Error:\", MSE_S)\nprint(\"Root Mean Squared Error:\", RMSE_S)\nprint(\"R-Squared:\", R2_S)\nprint(\"Test data mean:\", Ytest_Mean)\nprint(\"RMSE\/Mean\", RMSE_S\/Ytest_Mean) #LR: 0.6323565400081586 SVR: 0.561865850762153\n","0b4bc769":"from sklearn.tree import DecisionTreeRegressor\nregressor_dt = DecisionTreeRegressor()\nregressor_dt.fit(x_train,y_train)\n\n\ny_pred_dt = regressor_dt.predict(x_test)\n\ny_pred_dt = y_pred_dt.reshape(-1,1)\ny_pred_dt = Sc2.inverse_transform(y_pred_dt)","fff5efe6":"#Decision Tree Regression Model Evaluation\nMAE_DT = mean_absolute_error(y_test,y_pred_dt) #LR: 12.468495177524579 SVR: 10.70163941936098 DT: 13.727018194070082\n\nMSE_DT = mean_squared_error(y_test,y_pred_dt) #LR: 278.5774526377687 SVR: 219.9313845248983 DT: 384.88007051886797\n\nRMSE_DT = math.sqrt(MSE_DT) #LR: 16.690639671317836 SVR: 14.830083766617715 DT: 19.61836054615339\n\nR2_DT = r2_score(y_test, y_pred_dt) #LR: 0.010062773414825421  SVR: 0.21846415503442718 DT: -0.36768825319389387\n\nYtest_Mean = y_test.mean()  #26.394349730458224\n\nprint(\"Mean Absolute Error:\", MAE_DT)\nprint(\"Mean Squared Error:\", MSE_DT)\nprint(\"Root Mean Squared Error:\", RMSE_DT)\nprint(\"R-Squared:\", R2_DT)\nprint(\"RMSE\/Mean\", RMSE_DT\/Ytest_Mean) #LR: 0.6323565400081586 SVR: 0.561865850762153 DT: 0.7432787981707478\n","412a58ca":"#HyperParameter Tuning - Check for best n_estimators\n#1000 had the least RMSE\n\n'''\nThe execution of this cell was taking too long to run on kaggle so i had to cancel it but i was able to run it successfully on my local machine \nand n_estimators = 1000 had the lowest RMSE.\n'''\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nRF_RMSE = []\nestimators = [100,200,300,400,500,600,700,800,900,1000,1200,1500]\nfor i in estimators:\n    RFR = RandomForestRegressor(n_estimators = i)\n    RFR.fit(x_train,y_train.ravel())\n    y_pred_rf = RFR.predict(x_test)\n    y_pred_rf = y_pred_rf.reshape(-1,1)\n    y_pred_rf = Sc2.inverse_transform(y_pred_rf)\n    MSE_RF = mean_squared_error(y_test,y_pred_rf)\n    RMSE_RF = math.sqrt(MSE_RF) \n    RF_RMSE.append(RMSE_RF)\n    \n\nprint(RF_RMSE)    ","7a78ec27":"#Build model with n_estimators = 1000\n \nfrom sklearn.ensemble import RandomForestRegressor \nregressor_rf = RandomForestRegressor(n_estimators = 1000)\n \nregressor_rf.fit(x_train,y_train.ravel());\n\n\ny_pred_rf = regressor_rf.predict(x_test)\n\ny_pred_rf = y_pred_rf.reshape(-1,1)\ny_pred_rf = Sc2.inverse_transform(y_pred_rf)\n","57569856":"#Random Forest Regression Evaluation\n\n#LR: 12.468495177524579 SVR: 10.70163941936098 DT: 13.727018194070082 RFR_1000: 9.672237136118602\nMAE_RF = mean_absolute_error(y_test,y_pred_rf) \n\n#LR: 278.5774526377687 SVR: 219.9313845248983 DT: 384.88007051886797 RFR_1000: 198.17660585137224\nMSE_RF = mean_squared_error(y_test,y_pred_rf) \n\n#LR: 16.690639671317836 SVR: 14.830083766617715 DT: 19.61836054615339 RFR_1000: 14.077521296427587\nRMSE_RF = math.sqrt(MSE_RF) \n\n#LR: 0.010062773414825421  SVR: 0.21846415503442718 DT: -0.36768825319389387 RFR_1000: 0.2957707175761112\nR2_RF = r2_score(y_test, y_pred_rf) \n\nYtest_Mean = y_test.mean()  #26.394349730458224\n\nprint(\"Mean Absolute Error:\", MAE_RF)\nprint(\"Mean Squared Error:\", MSE_RF)\nprint(\"Root Mean Squared Error:\", RMSE_RF)\nprint(\"R-Squared:\", R2_RF)\n\n#LR: 0.6323565400081586 SVR: 0.561865850762153 DT: 0.7432787981707478 RFR_1000: 0.5333535942422777\nprint(\"RMSE\/Mean\", RMSE_RF\/Ytest_Mean) \n","03e297b9":"#HyperParameter Tuning - Check for best n_neighbors\n#30 had the least RMSE\n\n'''\nThe execution of this cell takes a long time to run on kaggle but i was able to run it successfully on my local machine \nand n_neighbors = 30 had the lowest RMSE.\n'''\n\nfrom sklearn.neighbors import KNeighborsRegressor\n\nKNN_RMSE = []\nfor i in range(1,50):\n    KNNR = KNeighborsRegressor(n_neighbors = i)\n    KNNR.fit(x_train,y_train)\n    y_pred_knn = KNNR.predict(x_test)\n    y_pred_knn = y_pred_knn.reshape(-1,1)\n    y_pred_knn = Sc2.inverse_transform(y_pred_knn)\n    MSE_KNN = mean_squared_error(y_test,y_pred_knn)\n    RMSE_KNN = math.sqrt(MSE_KNN) \n    KNN_RMSE.append(RMSE_KNN)\n    \n\nprint(KNN_RMSE)  ","a2047a0c":"#Build model with n_neighbors = 30\nfrom sklearn.neighbors import KNeighborsRegressor\nregressor_knn = KNeighborsRegressor(n_neighbors = 30)\n \nregressor_knn.fit(x_train,y_train)\n\n\ny_pred_knn = regressor_knn.predict(x_test)\n\ny_pred_knn = y_pred_knn.reshape(-1,1)\ny_pred_knn = Sc2.inverse_transform(y_pred_knn)","9a625176":"#KNN Regression Model Evaluation\n\n#LR: 12.468495177524579 SVR: 10.70163941936098 DT: 13.727018194070082 RFR_1000: 9.672237136118602 KNN_30: 11.707566823899372\nMAE_KNN = mean_absolute_error(y_test,y_pred_knn) \n\n#LR: 278.5774526377687 SVR: 219.9313845248983 DT: 384.88007051886797 RFR_1000: 198.17660585137224 KNN_30: 269.81948219493114\nMSE_KNN = mean_squared_error(y_test,y_pred_knn) \n\n#LR: 16.690639671317836 SVR: 14.830083766617715 DT: 19.61836054615339 RFR_1000: 14.077521296427587  KNN_30: 16.426182824835816\nRMSE_KNN = math.sqrt(MSE_KNN) \n\n#LR: 0.010062773414825421  SVR: 0.21846415503442718 DT: -0.36768825319389387 RFR_1000: 0.2957707175761112 KNN_30: 0.04118460645840227\nR2_KNN = r2_score(y_test, y_pred_knn) \n\nYtest_Mean = y_test.mean()  #26.394349730458224\n\n\nprint(\"Mean Absolute Error:\", MAE_KNN)\nprint(\"Mean Squared Error:\", MSE_KNN)\nprint(\"Root Mean Squared Error:\", RMSE_KNN)\nprint(\"R-Squared:\", R2_KNN)\n\n#LR: 0.6323565400081586 SVR: 0.561865850762153 DT: 0.7432787981707478 RFR_1000: 0.5333535942422777 KNN_30: 0.6223370908009351\nprint(\"RMSE\/Mean\", RMSE_KNN\/Ytest_Mean) ","5f1b31a9":"#import test data\ndata_test = pd.read_csv(\"..\/input\/logistics-delivery-data\/logistics_test_data.csv\")\n#preview top five rows in the dataset\ndata_test.head()","e895f26d":"#Extract Hour, Minute and Time from pickup time\ndata_test[\"Pickup_Hour\"] = pd.to_datetime(data_test['Pickup_Time'],format= '%H:%M:%S %p' ).dt.hour\ndata_test[\"Pickup_Minute\"] = pd.to_datetime(data_test['Pickup_Time'],format= '%H:%M:%S %p' ).dt.minute\ndata_test[\"Pickup_Second\"] = pd.to_datetime(data_test['Pickup_Time'],format= '%H:%M:%S %p' ).dt.second","45c8bb15":"#Check for nulls\ndata_test.isnull().sum()","a58fdbe7":"#Handle Nulls\ndata_test[\"Temperation\"] = data_test[\"Temperation\"].fillna(data_test[\"Temperation\"].mean())\ndata_test[\"Precipitation_in_millimeters\"] = data_test[\"Precipitation_in_millimeters\"].fillna(data_test[\"Precipitation_in_millimeters\"].median())","b19a6714":"data_test.info()","349c5abb":"#Convert data frame to a numpy array\nx_data_test = data_test.values","ae958748":"#delete columns not needed for prediction just as done earlier\nx_data_test = np.delete(x_data_test,[0,1,2,3,4,5,6,7,8,9,10,11,12,15,16,17,18,19],1) ","1fabe4a6":"#Scale data \nx_data_test = Sc.transform(x_data_test)","520a9870":"#Predict y using the random forest regression model\n\ny_pred_rf = regressor_rf.predict(x_data_test)\n\ny_pred_rf = y_pred_rf.reshape(-1,1)\ny_pred_rf = Sc2.inverse_transform(y_pred_rf)","ea2b775d":"#Convert predictions to a data frame\ny_pred_rf = pd.DataFrame(y_pred_rf, columns = [\"Predicted_Time\"])\n\n#preview predictions\ny_pred_rf.head()","b7d634c5":"#Extract predictions\n\ny_pred_rf.to_csv(\"delivery_time_predictions.csv\")","2aa9e6c9":"**Linear Regression Modelling**","a1adca01":"**Support Vector Regression**","837f0c78":"**K-Nearest Neighbour (KNN) Regression**","be6be48f":"**Random Forest Regression**","b3b2d45a":"**Random Forest Regression performed the best with the lowest RMSE, so we will predict delivery time for the test data using the random forest regression model.**","ef576a3d":"**Decision Tree Regression**"}}