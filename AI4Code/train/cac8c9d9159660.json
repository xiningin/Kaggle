{"cell_type":{"53e15f09":"code","d96792a3":"code","4ba335fb":"code","5a01a33d":"code","97a5e383":"code","3715317e":"code","77a81f7b":"code","f8a16990":"code","a758a989":"code","9987a3dc":"code","421bad11":"code","10088310":"markdown","2f9222ee":"markdown","e6ba2b56":"markdown","4fd7520c":"markdown","3f2c2130":"markdown","90ea780e":"markdown","c7019d11":"markdown"},"source":{"53e15f09":"#import necessary librabry\nimport numpy as np\nimport pandas as pd\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","d96792a3":"#defining the base, train and validation directory path\nbase_dir = '..\/input\/car-damage-detection\/data1a'\ntrain_dir = os.path.join(base_dir, 'training')\nvalidation_dir = os.path.join(base_dir, 'validation')","4ba335fb":"#defining the damage and whole , train nand validation directory\ntrain_damage_dir = os.path.join(train_dir, '00-damage')\ntrain_whole_dir = os.path.join(train_dir, '01-whole')\nvalidation_damage_dir = os.path.join(validation_dir, '00-damage')\nvalidation_whole_dir = os.path.join(validation_dir, '01-whole')","5a01a33d":"#data augmentation\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_datagen = ImageDataGenerator(rescale=1.\/255)","97a5e383":"train_generator = train_datagen.flow_from_directory(\n        train_dir,  \n        target_size=(150, 150), \n        batch_size=20,\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(150, 150),\n        batch_size=20,\n        class_mode='binary')","3715317e":"#defining model\nfrom tensorflow.keras import Model \nfrom tensorflow.keras.applications import DenseNet121   \n\nbase_model = DenseNet121(input_shape = (150, 150, 3),  include_top = False, weights = 'imagenet') \n\nx=   tf.keras.layers.Flatten()(base_model.output)\nx=   tf.keras.layers.Dense(512, activation='relu')(x) \nx=   tf.keras.layers.Dense(1, activation='sigmoid')(x) \n\nmodel= Model( base_model.input, x)\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer=RMSprop(lr=1e-4),\n              metrics=['Accuracy','Precision','Recall'])\n\n#training the model\nhistory = model.fit(\n      train_generator,\n      epochs=15,\n      validation_data=validation_generator,\n      verbose=2)","77a81f7b":"#weights saving\nmodel.save(\"classifier.h5\")","f8a16990":"import matplotlib.pyplot as plt\nacc = history.history['Accuracy']\nval_acc = history.history['val_Accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","a758a989":"import matplotlib.pyplot as plt\nacc = history.history['precision']\nval_acc = history.history['val_precision']\nloss = history.history['recall']\nval_loss = history.history['val_recall']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","9987a3dc":"import cv2\nim = cv2.imread(\"..\/input\/car-damage-detection\/data1a\/validation\/00-damage\/0001.JPEG\")\nim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\nim = cv2.resize(im, (150, 150)) \nimS=im.reshape([1,150,150,3])\npred=model.predict(np.array(imS))\nif pred[0][0]>0.5:\n    print(\"The car is damaged\")\nelse:\n    print(\"The car is not damaged\")\nplt.axis(\"off\")\nplt.imshow(im)","421bad11":"im = cv2.imread(\"..\/input\/car-damage-detection\/data1a\/validation\/01-whole\/0006.jpg\")\nim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\nim = cv2.resize(im, (150, 150)) \nimS=im.reshape([1,150,150,3])\npred=model.predict(np.array(imS))\nprint(pred)\nif pred[0][0]>0.5:\n    print(\"The car is damaged\")\nelse:\n    print(\"The car is not damaged\")\nplt.axis(\"off\")\nplt.imshow(im)\n","10088310":"Training and evaluating the model with binary crossentropy loss, accuracy, precision , recall","2f9222ee":"plotting the history of train and validation loss, accurcy, precision, recall","e6ba2b56":"For training 1840 images are used.\nFor Validation 460 image are used.","4fd7520c":"Data Augmentation is used to:\n1. Rescale the data \n2. to bring all the image to same dimension  i.e. 150x150\n","3f2c2130":"Testing","90ea780e":"Conclusion: Successfully build a classifier to classify the images containing into damage and undamage cars. ","c7019d11":"Goal of this notebook: <br> To classify whether the image contains damaged or un-dmages cars.<br>\nApproach: Deep learning <br>\nFramework used: Tensorflow<br>\n\nIn this notebook, Densenet121 pre trained model is used to classify where the image contain the damaged car or not."}}