{"cell_type":{"2cea97dd":"code","5e5a948c":"code","d35280a2":"code","f2c4fa26":"code","7bc4aa43":"code","29be1d0a":"code","d35f778c":"code","eb2fe7f3":"code","3e8fe1f1":"code","dab1f4ce":"code","d62199ac":"code","45303fd1":"code","2df9f205":"code","1c4826ef":"code","0ff8d996":"code","06477940":"code","6b2a0ef8":"code","594ce4b4":"code","0a1ab555":"code","4ef4db43":"code","db292935":"code","de100aca":"markdown","be60463e":"markdown","9d2fd5ff":"markdown"},"source":{"2cea97dd":"# DATA_PATH = '..\/input\/'\nDATA_PATH = '..\/input\/shopee-product-matching\/'","5e5a948c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2, matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import normalize\nimport math\nimport torch\n\n# import cudf, cuml, cupy\n# from cuml.feature_extraction.text import TfidfVectorizer\n# from cuml.neighbors import NearestNeighbors\n\n\n# \u5b9a\u4e49\u8bc4\u4ef7\u51fd\u6570\uff1a\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\uff0cF1\ndef getMetric(col):\n    def f1score(row):\n        n = len( np.intersect1d(row.target,row[col]))\n        if len(row[col])==0:\n            p = 0\n        else:\n            p = n\/len(row[col])\n        if len(row.target) == 0:\n            r = 0\n        else:\n            r = n\/len(row.target)\n        return p, r, 2*n\/(len(row.target)+len(row[col]))\n    return f1score","d35280a2":"from contextlib import contextmanager\nimport os, sys, time, psutil\n\n# \u8ba1\u7b97\u5f53\u524d\u4ee3\u7801\u6240\u4f7f\u7528\u7684\u5185\u5b58\u548c\u65f6\u95f4\n@contextmanager\ndef timer_memory(name):\n    t0 = time.time()\n    yield\n    print(f'Memory: {(psutil.Process(os.getpid()).memory_info().rss\/2**30):.02f}GB')\n    print(f'{name} done in {time.time()-t0:.0f}s')","f2c4fa26":"COMPUTE_CV = True\ndevice = 'cuda'\n\ntest = pd.read_csv(DATA_PATH + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\nelse: print('this submission notebook will compute CV score, but commit notebook will not')\n\n# COMPUTE_CV = False\nwith timer_memory('Reading CSV'):\n    if COMPUTE_CV:\n        train = pd.read_csv(DATA_PATH + 'train.csv')\n        train['image'] = DATA_PATH + 'train_images\/' + train['image']\n        tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n        train['target'] = train.label_group.map(tmp)\n    else:\n        train = pd.read_csv(DATA_PATH + 'test.csv')\n        train['image'] = DATA_PATH + 'test_images\/' + train['image']\n    \nprint('train shape is', train.shape )\ntrain.head()","7bc4aa43":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof_hash'] = train.image_phash.map(tmp)","29be1d0a":"if COMPUTE_CV:\n    train['cv_score'] = train.apply(getMetric('oof_hash'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())","d35f778c":"from PIL import Image\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nclass SHOPEEDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        \n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        row = self.df.loc[index]\n        img = cv2.imread(row.image)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            res = self.transform(image=img)\n            img = res['image']\n                \n        img = img.astype(np.float32)\n        img = img.transpose(2,0,1)\n        \n        if self.mode == 'test':\n            return torch.tensor(img).float()\n        else:\n            return torch.tensor(img).float(), torch.tensor(row.label_group).float()\n\nclass ArcModule(nn.Module):\n    def __init__(self, in_features, out_features, s = 10, m = 0.5):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_normal_(self.weight)\n\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = torch.tensor(math.cos(math.pi - m))\n        self.mm = torch.tensor(math.sin(math.pi - m) * m)\n\n    def forward(self, inputs, labels):\n        cos_th = F.linear(inputs, F.normalize(self.weight))\n        cos_th = cos_th.clamp(-1, 1)\n        sin_th = torch.sqrt(1.0 - torch.pow(cos_th, 2))\n        cos_th_m = cos_th * self.cos_m - sin_th * self.sin_m\n        # print(type(cos_th), type(self.th), type(cos_th_m), type(self.mm))\n        cos_th_m = torch.where(cos_th > self.th, cos_th_m, cos_th - self.mm)\n\n        cond_v = cos_th - self.th\n        cond = cond_v <= 0\n        cos_th_m[cond] = (cos_th - self.mm)[cond]\n\n        if labels.dim() == 1:\n            labels = labels.unsqueeze(-1)\n        onehot = torch.zeros(cos_th.size()).cuda()\n        labels = labels.type(torch.LongTensor).cuda()\n        onehot.scatter_(1, labels, 1.0)\n        outputs = onehot * cos_th_m + (1.0 - onehot) * cos_th\n        outputs = outputs * self.s\n        return outputs\n    \n    \nclass SHOPEEDenseNet(nn.Module):\n\n    def __init__(self, channel_size, out_feature, dropout=0.5, backbone='densenet121', pretrained=True):\n        super(SHOPEEDenseNet, self).__init__()\n        self.channel_size = channel_size\n        self.out_feature = out_feature\n        \n        if backbone == 'resnet101':\n            self.backbone = models.resnet101(False)\n            self.in_features = self.backbone.fc.in_features\n            self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n            self.fc1 = nn.Linear(self.in_features * 7 * 7 , self.channel_size)\n        print(self.backbone)\n        \n        self.margin = ArcModule(in_features=self.channel_size, out_features = self.out_feature)\n        self.bn1 = nn.BatchNorm2d(self.in_features)\n        self.dropout = nn.Dropout2d(dropout)\n        self.bn2 = nn.BatchNorm1d(self.channel_size)\n        \n    def forward(self, x, labels=None):\n        features = self.backbone(x)\n        features = self.dropout(features)\n        features = features.view(features.size(0), -1)\n        # print(features.shape)\n        features = self.fc1(features)\n        features = F.normalize(features)\n        if labels is not None:\n            return self.margin(features, labels)\n        return features\n    \n    def test(self):\n        x = torch.rand(1, 3, 224, 224).cuda()\n        print(self.forward(x))","eb2fe7f3":"model = SHOPEEDenseNet(512, 11014, backbone='resnet101')\nmodel.load_state_dict(torch.load('..\/input\/shopee-models\/baseline_fold0_densenet_224_epoch50.pth'))\nmodel.to('cuda')","3e8fe1f1":"def generate_test_features(test_loader):\n    model.eval()\n    bar = tqdm_notebook(test_loader)\n    \n    FEAS = []\n    TARGETS = []\n\n    with torch.no_grad():\n        for batch_idx, (images) in enumerate(bar):\n            images = images.to('cuda')\n            features = model(images)\n            FEAS += [features.detach().cpu()]\n    FEAS = torch.cat(FEAS).cpu().numpy()\n    return FEAS","dab1f4ce":"# !mkdir -p \/root\/.cache\/torch\/hub\/checkpoints\/\n# !cp ..\/input\/pretrained-pytorch-models\/resnet18-5c106cde.pth \/root\/.cache\/torch\/hub\/checkpoints\/","d62199ac":"import albumentations\ntransforms_valid = albumentations.Compose([\n    albumentations.Resize(224, 224),\n    albumentations.Normalize()\n])\n\ndataset_test = SHOPEEDataset(train, 'test', transform=transforms_valid)\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=16, \n                                          shuffle=False, num_workers=2, pin_memory=True)\nimagefeat = generate_test_features(test_loader)\nimagefeat = torch.tensor(imagefeat)","45303fd1":"imagefeat = imagefeat.cuda()","2df9f205":"print('Finding similar images...')\n\npreds = []\npreds_index = []\nCHUNK = 1024*4\n\nCTS = len(imagefeat)\/\/CHUNK\nif len(imagefeat)%CHUNK!=0: CTS += 1\n\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b, len(imagefeat))\n    print('chunk',a,'to',b)\n    \n    distances = torch.matmul(imagefeat, imagefeat[a:b].T).T\n    distances = distances.data.cpu().numpy()\n    # distances = np.dot(imagefeat[a:b,], imagefeat.T)\n    \n    for k in range(b-a):\n        # IDX = cupy.where(distances[k,]>0.95)[0]\n        IDX = np.where(distances[k,]>0.9)[0][:]\n        o = train.iloc[IDX].posting_id.values\n#         o = train.iloc[cupy.asnumpy(IDX)].posting_id.values\n        preds.append(o)\n        preds_index.append(IDX)\n        \n# del imagefeat, imgmodel","1c4826ef":"train['oof_cnn'] = preds\nprint(train['oof_cnn'].apply(len).mean())\n\nif COMPUTE_CV:\n    train['cv_score'] = train.apply(getMetric('oof_cnn'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())","0ff8d996":"from sklearn.feature_extraction.text import TfidfVectorizer\nmodel = TfidfVectorizer(stop_words=None, binary=True, max_features=None)\ntext_embeddings = model.fit_transform(train.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","06477940":"text_embeddings = torch.from_numpy(text_embeddings)\ntext_embeddings = text_embeddings.cuda()","6b2a0ef8":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(train)\/\/CHUNK\nif len(train)%CHUNK!=0: CTS += 1\nCTS_index = 0\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(train))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n    cts = torch.matmul(text_embeddings, text_embeddings[a:b].T).T\n    cts = cts.data.cpu().numpy()\n    print(cts.shape)\n    for k in range(b-a):\n        IDX = np.where(cts[k,]>0.7)[0]\n        # IDX = np.where(cts[k,list(preds_index[CTS_index])]>0.7)[0]\n        # IDX = [preds_index[CTS_index][x] for x in IDX]\n        o = train.iloc[IDX].posting_id.values\n        preds.append(o)\n        CTS_index += 1\n# del model, text_embeddings","594ce4b4":"train['oof_text'] = preds\n\nif COMPUTE_CV:\n    train['cv_score'] = train.apply(getMetric('oof_text'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())","0a1ab555":"def combine_for_sub(row):\n    x = np.concatenate([row.oof_cnn, row.oof_hash, row.oof_text])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.oof_cnn, row.oof_hash, row.oof_text])\n    return np.unique(x)","4ef4db43":"if COMPUTE_CV:\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train['oof'] = train.apply(combine_for_cv,axis=1)\n    \n    train['cv_score'] = train.apply(getMetric('oof'),axis=1)\n    print('P score for baseline =',train['cv_score'].apply(lambda x:x[0]).mean())\n    print('R score for baseline =',train['cv_score'].apply(lambda x:x[1]).mean())\n    print('F1 score for baseline =',train['cv_score'].apply(lambda x:x[2]).mean())\n    \ntrain['matches'] = train.apply(combine_for_sub,axis=1)","db292935":"train[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","de100aca":"# image hash","be60463e":"# title TFIDF","9d2fd5ff":"# image CNN"}}