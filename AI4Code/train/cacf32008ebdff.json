{"cell_type":{"974f5c6b":"code","e711481d":"code","7ab42605":"code","4f3d5ad4":"code","132b7b9f":"code","5018e0ac":"code","76e51fa8":"code","fc35cf3f":"code","f0a749cb":"code","aa6ca852":"code","424d357a":"code","f445835f":"code","25cb0633":"code","0d6236aa":"markdown","7ee3283d":"markdown","839eace3":"markdown","9813bef5":"markdown","46a8693b":"markdown"},"source":{"974f5c6b":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e711481d":"# Import dataset\ntrain = pd.read_csv('..\/input\/train_V2.csv')\ntest = pd.read_csv('..\/input\/test_V2.csv')","7ab42605":"# Memory saving function credit to https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.\n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                #    df[col] = df[col].astype(np.float16)\n                #el\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        #else:\n            #df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n        start_mem, end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\ntrain=reduce_mem_usage(train)\ntest=reduce_mem_usage(test)","4f3d5ad4":"train['totalDistance']=train['rideDistance']+train['walkDistance']+train['swimDistance']\ntrain['killsWithoutMoving']=((train['kills']>0)&(train['totalDistance']==0))\ntrain['headshot_rate']=train['headshotKills']\/train['kills']\n# Add a feature containing the number of players that joined each match.\ntrain['playersJoined'] = train.groupby('matchId')['matchId'].transform('count')\n\nprint(train.shape)\ntrain.drop(train[train['winPlacePerc'].isnull()].index,inplace=True)\ntrain.drop(train[train['killsWithoutMoving']==True].index,inplace=True)\ntrain.drop(train[train['roadKills']>10].index,inplace=True)\ntrain.drop(train[train['kills']>35].index,inplace=True)\ntrain.drop(train[((train['headshot_rate']==1) & (train['kills']>9))].index,inplace=True)\ntrain.drop(train[train['longestKill']>=1000].index,inplace=True)\ntrain.drop(train[train['walkDistance']>=10000].index,inplace=True)\ntrain.drop(train[train['rideDistance']>=20000].index,inplace=True)\ntrain.drop(train[train['swimDistance']>=2000].index,inplace=True)\ntrain.drop(train[train['weaponsAcquired']>=80].index,inplace=True)\ntrain.drop(train[train['heals']>=40].index,inplace=True)\ntrain.drop(train[( (train['totalDistance']==0) & (train['weaponsAcquired']>3) )].index,inplace=True)\nprint(train.shape)","132b7b9f":"train['killsNorm'] = train['kills']*((100-train['playersJoined'])\/100 + 1)\ntrain['headshotKillsNorm'] = train['headshotKills']*((100-train['playersJoined'])\/100 + 1)\ntrain['killPlaceNorm'] = train['killPlace']*((100-train['playersJoined'])\/100 + 1)\ntrain['killPointsNorm'] = train['killPoints']*((100-train['playersJoined'])\/100 + 1)\ntrain['killStreaksNorm'] = train['killStreaks']*((100-train['playersJoined'])\/100 + 1)\ntrain['longestKillNorm'] = train['longestKill']*((100-train['playersJoined'])\/100 + 1)\ntrain['roadKillsNorm'] = train['roadKills']*((100-train['playersJoined'])\/100 + 1)\ntrain['teamKillsNorm'] = train['teamKills']*((100-train['playersJoined'])\/100 + 1)\ntrain['damageDealtNorm'] = train['damageDealt']*((100-train['playersJoined'])\/100 + 1)\ntrain['DBNOsNorm'] = train['DBNOs']*((100-train['playersJoined'])\/100 + 1)\ntrain['revivesNorm'] = train['revives']*((100-train['playersJoined'])\/100 + 1)\n# Features to remove\ntrain = train.drop([ 'kills', 'headshotKills', 'killPlace', 'killPoints', 'killStreaks', \n 'longestKill', 'roadKills', 'teamKills', 'damageDealt', 'DBNOs', 'revives'],axis=1)","5018e0ac":"train.head()","76e51fa8":"target='winPlacePerc'\nfeatures=list(train.columns)\nfeatures.remove(\"Id\")\nfeatures.remove(\"matchId\")\nfeatures.remove(\"groupId\")\nfeatures.remove(\"matchType\")\nfeatures.remove(\"killsWithoutMoving\")\nfeatures.remove(\"headshot_rate\")\nfeatures.remove(target)\nsample = 500000\ndf_sample = train.sample(sample)\nx_train=df_sample[features]\ny_train=df_sample[target]","fc35cf3f":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nrandom_seed=1\nsample = 500000\n\nx_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.1,random_state=random_seed)\nmodel=RandomForestRegressor(n_estimators=70,min_samples_leaf=3,max_features=0.5,n_jobs=-1)","f0a749cb":"%%time\nmodel.fit(x_train,y_train)","aa6ca852":"print('mae train:',mean_absolute_error(model.predict(x_train),y_train))\nprint('mae train:',mean_absolute_error(model.predict(x_val),y_val))","424d357a":"test['totalDistance']=test['rideDistance']+test['walkDistance']+test['swimDistance']\n#train['killsWithoutMoving']=((train['kills']>0)&(train['totalDistance']==0))\ntest['headshot_rate']=test['headshotKills']\/test['kills']\n\ntest['playersJoined'] = test.groupby('matchId')['matchId'].transform('count')\ntest['killsNorm'] = test['kills']*((100-test['playersJoined'])\/100 + 1)\ntest['headshotKillsNorm'] = test['headshotKills']*((100-test['playersJoined'])\/100 + 1)\ntest['killPlaceNorm'] = test['killPlace']*((100-test['playersJoined'])\/100 + 1)\ntest['killPointsNorm'] = test['killPoints']*((100-test['playersJoined'])\/100 + 1)\ntest['killStreaksNorm'] = test['killStreaks']*((100-test['playersJoined'])\/100 + 1)\ntest['longestKillNorm'] = test['longestKill']*((100-test['playersJoined'])\/100 + 1)\ntest['roadKillsNorm'] = test['roadKills']*((100-test['playersJoined'])\/100 + 1)\ntest['teamKillsNorm'] = test['teamKills']*((100-test['playersJoined'])\/100 + 1)\ntest['damageDealtNorm'] = test['damageDealt']*((100-test['playersJoined'])\/100 + 1)\ntest['DBNOsNorm'] = test['DBNOs']*((100-test['playersJoined'])\/100 + 1)\ntest['revivesNorm'] = test['revives']*((100-test['playersJoined'])\/100 + 1)\n# Features to remove\ntest = test.drop([ 'kills', 'headshotKills', 'killPlace', 'killPoints', 'killStreaks', \n 'longestKill', 'roadKills', 'teamKills', 'damageDealt', 'DBNOs', 'revives'],axis=1)","f445835f":"x_test=test[features]\npred=model.predict(x_test)\ntest['winPlacePerc']=pred\nsubmission=test[['Id','winPlacePerc']]\nsubmission.head()","25cb0633":"submission.to_csv('submission.csv',index=False)","0d6236aa":"### Normalized features","7ee3283d":"Fellow Kaggler '[averagemn](https:\/\/www.kaggle.com\/donkeys)' brought to our attention that there is one particular player with a 'winPlacePerc' of NaN. The case was that this match had only one player. We will delete this row from our dataset.","839eace3":"Earlier in this kernel we created the new features ''totalDistance'' and  ''headshot_rate\". In this section we add more interesting features to improve the predictive quality of our machine learning models.\n\nInitial ideas for this section come from [this amazing kernel](https:\/\/www.kaggle.com\/deffro\/eda-is-fun).\n\nNote: It is important with feature engineering that you also add the engineered features to your test set!","9813bef5":"# Feature Engineering <a id=\"5\"><\/a>","46a8693b":"# Illegal Match <a id=\"4\"><\/a>"}}