{"cell_type":{"fd909b8a":"code","6c19f8ea":"code","29227e73":"code","77d8d168":"code","015b35e7":"code","01f1904b":"code","93d3a090":"code","884ea0a3":"code","d0e32adf":"code","6ccec27f":"code","56e8ee15":"code","a6bc8a37":"code","880ea33b":"code","dbb0c1fd":"code","fd239a71":"code","eae78467":"code","d7096a53":"code","b7f50257":"code","36d81538":"code","6bab5a2f":"code","863e2963":"code","d5f73fd8":"code","119c99c8":"code","c2193572":"code","eaada224":"code","bef3306f":"code","a98cb028":"code","77f76972":"code","825e1166":"code","12f091cd":"code","705d8a6b":"code","59254b37":"code","1fc210e7":"code","34e2d579":"code","628093ec":"code","cf3b1055":"code","d781519a":"code","9e7248e2":"code","25178ced":"code","cb4f0ec6":"code","1e094f38":"code","b4a26ed3":"code","7ebfa972":"code","6bc4c570":"code","0a7f21fd":"code","32453231":"code","62ac4fa3":"code","edfbe7c0":"code","2576d3be":"code","0b20f90d":"code","3aa9e2ac":"code","408ba3c0":"code","a87da2ab":"code","99a64b63":"markdown"},"source":{"fd909b8a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6c19f8ea":"train_data=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntrain_data.head()","29227e73":"test_data=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_data.head()","77d8d168":"train_data.info()","015b35e7":"test_data.info()","01f1904b":"train_data.describe()","93d3a090":"test_data.describe()","884ea0a3":"train_data.isnull().sum()","d0e32adf":"import seaborn as sns","6ccec27f":"sns.heatmap(train_data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","56e8ee15":"test_data.isnull().sum()","a6bc8a37":"sns.heatmap(test_data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","880ea33b":"#let's replace the nan value of age with median\ntrain_data['Age']=train_data['Age'].fillna(train_data['Age'].median())\ntrain_data.isnull().sum()","dbb0c1fd":"#let's replace the nan value of age with median\ntest_data['Age']=test_data['Age'].fillna(test_data['Age'].median())\ntest_data.isnull().sum()","fd239a71":"test_data['Fare']=test_data['Fare'].fillna(test_data['Fare'].median())\ntest_data.isnull().sum()","eae78467":"#let's do some Exploratory data analysis\nsns.countplot(train_data['Survived'])","d7096a53":"sns.countplot(train_data['Sex'])","b7f50257":"sns.barplot(x=train_data['Sex'],y=train_data['Survived'])","36d81538":"sns.jointplot(x=train_data['Age'],y=train_data['Survived'],hue=train_data['Sex'],palette='plasma')","6bab5a2f":"sns.pairplot(train_data,hue='Survived')","863e2963":"train_data['Pclass'].value_counts()","d5f73fd8":"\nsns.barplot(x=train_data['Pclass'],y=train_data['Survived'],hue=train_data['Sex'])","119c99c8":"sns.barplot(x=train_data['Parch'],y=train_data['Survived'],hue=train_data['Sex'])","c2193572":"sns.barplot(x=train_data['SibSp'],y=train_data['Survived'],hue=train_data['Sex'])","eaada224":"train_data.corr()","bef3306f":"sns.heatmap(train_data.corr(),annot=True)","a98cb028":"test_data.corr()","77f76972":"sns.heatmap(test_data.corr(),annot=True)","825e1166":"#let's handle the categorical data\ncat_feat=[feature for feature in train_data.columns if train_data[feature].dtype=='O']\ncat_feat\n\n    ","12f091cd":"train_data[\"Sex\"]=pd.get_dummies(train_data['Sex'])\ntrain_data[\"Embarked\"]=pd.get_dummies(train_data['Embarked'])","705d8a6b":"train_data.head()","59254b37":"cat_feat=[feature for feature in test_data.columns if test_data[feature].dtype=='O']\ncat_feat","1fc210e7":"test_data[\"Sex\"]=pd.get_dummies(test_data['Sex'])\ntest_data[\"Embarked\"]=pd.get_dummies(test_data['Embarked'])","34e2d579":"test_data.head()","628093ec":"test_data.columns","cf3b1055":"X = train_data.drop(columns = ['PassengerId','Name','Ticket','Survived','Cabin'],axis=1)\ny=train_data['Survived']","d781519a":"X.head()","9e7248e2":"from sklearn.model_selection  import train_test_split","25178ced":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)","cb4f0ec6":"X_train.shape","1e094f38":"X_test.shape","b4a26ed3":"y_train.shape","7ebfa972":"y_test.shape","6bc4c570":"#let's solve this using Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV","0a7f21fd":"n_estimators=[int(x) for x in np.linspace(start=100,stop=1500,num=10)]\nmax_features=['auto', 'sqrt', 'log2']\nmax_depth=[int(x) for x in np.linspace(10,100,10)]\nmin_samples_split=[2,4,6,10,14]\nmin_samples_leaf=[3,5,7,13,19]","32453231":"random_grid={'n_estimators':n_estimators,\n             'max_features':max_features,\n             'max_depth':max_depth,\n             'min_samples_split' :min_samples_split,\n             'min_samples_leaf':min_samples_leaf,\n             'criterion':['entropy','gini']}\nprint(random_grid)","62ac4fa3":"rf=RandomForestClassifier()","edfbe7c0":"rf_randomcv=RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, n_jobs=-1,random_state=101)","2576d3be":"model = rf_randomcv.fit(X_train,y_train)","0b20f90d":"rf_randomcv.best_params_","3aa9e2ac":"best_random_grid=rf_randomcv.best_estimator_","408ba3c0":"from sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import accuracy_score\ny_pred=best_random_grid.predict(X_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\nprint(\"Classification report: {}\".format(classification_report(y_test,y_pred)))","a87da2ab":"from sklearn.ensemble import RandomForestClassifier\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","99a64b63":"**ALTERNATE AND EASY METHOD**"}}