{"cell_type":{"7ce94770":"code","f1308735":"code","5207acb4":"code","f80c4c0a":"code","d65d530c":"code","c7772cd1":"code","858e6fc1":"code","882b3353":"code","27aeabcc":"code","9227c34f":"code","aaf1de9b":"code","7e5aa810":"code","1b353288":"code","cd167d18":"code","744cdbc6":"code","a49876ce":"code","de5c36fd":"code","a3937b27":"code","01cc2714":"markdown","1977442f":"markdown","a5a2e52c":"markdown","d1cab26f":"markdown","8e6b79db":"markdown","ddda4e5c":"markdown","56dfa2f2":"markdown","522b3f12":"markdown","db9f7367":"markdown","6af5e3c2":"markdown","8bcf82f5":"markdown","559f3819":"markdown","f57645d2":"markdown","84e02e01":"markdown","c6e60ee2":"markdown","e2be15bc":"markdown","272aedb6":"markdown"},"source":{"7ce94770":"import numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport category_encoders as ce\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n%matplotlib inline","f1308735":"australia = pd.read_csv('..\/input\/weatherauscsv\/weatherAUS.csv')\naustralia.head()","5207acb4":"australia  = australia.drop(['Location','Date','Evaporation','Sunshine', 'Cloud9am','Cloud3pm',\n                           'WindGustDir','WindGustSpeed','WindDir9am','WindDir3pm','WindSpeed9am',\n                           'WindSpeed3pm'], axis=1)","f80c4c0a":"Y =  australia.RainTomorrow\nX = australia.drop(['RainTomorrow'], axis=1)","d65d530c":"plot_sb = sb.countplot(Y, label='Total')\nRain, NotRain = Y.value_counts()\nprint('Rain: ',Rain)\nprint('Not Rain : ',NotRain)","c7772cd1":"X = X.replace({'No':0, 'Yes':1})\nX = X.fillna(0)\nY = Y.replace({'No':0, 'Yes':1})\nY = Y.fillna(0)","858e6fc1":"X_scaled = (X - X.mean()) \/ (X.std())\nX_scaled.head()","882b3353":"# Concatenate the target frame with just 20 columns from corpus_scaled\n#X_plot = pd.concat([Y, X_scaled], axis=1) \nX_plot = pd.concat([Y, X_scaled.iloc[:,0:20]], axis=1) \n\n# Reshaping the frame\nX_plot = pd.melt(X_plot, id_vars=\"RainTomorrow\", var_name=\"Features\", value_name='Values')\nX_plot.head()","27aeabcc":"# Setting the plt object\nplt.figure(figsize=(10,10))\n# Setting the violinplot objetc with respecitve atributes\nsb.violinplot(x=\"Features\", y=\"Values\", hue=\"RainTomorrow\", data=X_plot, split=True, inner=\"quart\")\n# Rotation of x ticks\nplt.xticks(rotation=90)","9227c34f":"# Correlation is taken from Pearsonr value, 1 is totally correlated.\nsb.jointplot(X_scaled.loc[:,'MinTemp'], \n              X_scaled.loc[:,'MaxTemp'], kind=\"regg\", color=\"#ce1414\")","aaf1de9b":"f, ax = plt.subplots(figsize=(18, 18))\nsb.heatmap(X_scaled.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.xticks(rotation=90)","7e5aa810":"x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.25, random_state=28)","1b353288":"clf_rf = RandomForestClassifier(random_state=23)      \nclr_rf = clf_rf.fit(x_train,y_train)","cd167d18":"y_predict = clf_rf.predict(x_test)\naccuracy = accuracy_score(y_test, y_predict )\nprint('Accuracy: ', accuracy)","744cdbc6":"conf_matrix = confusion_matrix(y_test, y_predict)\nsb.heatmap(conf_matrix, annot=True, fmt=\"d\")","a49876ce":"clf_svm = SVC(kernel='linear', random_state=12)\nclf_svm = clf_svm.fit(x_train, y_train)","de5c36fd":"y_predict = clf_svm.predict(x_test)\naccuracy = accuracy_score(y_test, y_predict)\nprint('Accuracy: ', accuracy)","a3937b27":"conf_matrix = confusion_matrix(y_test, y_predict)\nsb.heatmap(conf_matrix, annot=True, fmt=\"d\")","01cc2714":"## 2. Data Visualization","1977442f":"# Classification and Data Visualization\n\nThe notebook break down a problem of classification based on a weather in australia's data set. The idea of this work is to show different aproaches in how to visualize a data set, besides the idea is to develop different kind of Machine Learning Algorithms as Random Forest, SVM and Neural Networks.","a5a2e52c":"### 2.1 Preparing data to plot","d1cab26f":"> ### 2.4 Correlation Matrix","8e6b79db":"### 1.4 Plotting balance between positive and negative classes","ddda4e5c":"### 3.1 Splitting train and test set","56dfa2f2":"### 1.5 Changing boolen values and handling NaN values","522b3f12":"### 3.2 Random Forest","db9f7367":"## 1. Getting Started","6af5e3c2":"### 2.2 Violin Plot","8bcf82f5":"### 1.2 Dropping some columns","559f3819":"### 1.6 Scaling Data","f57645d2":"### 1.3 Splitting 'Y' vector and 'X' matrix","84e02e01":"### 2.3 Joint plot","c6e60ee2":"## 3. Classification Algorithms","e2be15bc":"### 3.3 Suppor Vector Machine (SVM)","272aedb6":"### 1.1 Loading file"}}