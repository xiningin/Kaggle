{"cell_type":{"434f5455":"code","f23f0f1d":"code","472923b4":"code","ae8dde63":"code","1e29c735":"code","335ae6ed":"code","cb2c6991":"code","83daff8a":"code","2db42b9d":"code","6a52eb5f":"code","2de54377":"code","08c04da7":"code","57e1e5b3":"code","45380c34":"code","3539c2c3":"code","e0ae6b91":"code","9bbc26e5":"code","6ab522e0":"code","21b20e5d":"code","51ff5948":"code","e6cabb2a":"code","45292fa2":"code","05e1a614":"code","fcf23ffe":"code","d1ffa426":"code","4a2c1566":"code","7e058d84":"code","83418d5f":"code","c06ff63f":"code","ebf1a96b":"code","e9b54ec1":"code","e89f4fa2":"markdown","29be802a":"markdown","4a2a714f":"markdown","7dee4e05":"markdown","4d4fac32":"markdown","f6482ea4":"markdown","e587401d":"markdown","7269f9c2":"markdown","c48a04fe":"markdown","f7689d85":"markdown","c7defc17":"markdown","f3878383":"markdown","9fb1a540":"markdown","ed03023c":"markdown","89e638e9":"markdown"},"source":{"434f5455":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import  GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,accuracy_score","f23f0f1d":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","472923b4":"train.sample(5)","ae8dde63":"train.shape","1e29c735":"train.info()","335ae6ed":"# Drop useless columns\ntrain = train.drop(['Cabin','Ticket','Name','PassengerId'],axis=1)","cb2c6991":"#   number of \"NAN\" values \ntrain.isnull().sum()","83daff8a":"## Dealing with mising values ##\nfreq = train.Embarked.dropna().mode()\nprint(freq,'\\n')\ntrain['Embarked'] = train['Embarked'].fillna(freq[0]) # fill \"NAN\" values with the most frequent value\n\nmean = train['Age'].dropna().mean()\ntrain['Age'] = train['Age'].fillna(round(mean))\nprint(round(mean))","2db42b9d":"train['Sex'].replace('female', 0,inplace=True)\ntrain['Sex'].replace('male', 1,inplace=True)\n\n\ntrain['Embarked'].replace('S', 0,inplace=True)\ntrain['Embarked'].replace('C', 1,inplace=True)\ntrain['Embarked'].replace('Q', 2,inplace=True)","6a52eb5f":"print(train.isnull().sum() , train.shape ,train.head(), train.describe().T ,sep = ' \\n ***********   *************  *********** \\n ' )","2de54377":"sns.set(rc={'figure.figsize':(13,13)})\nax = sns.heatmap(train.corr(), annot=True)","08c04da7":"cols = ['Pclass','Sex','SibSp' ,'Parch','Embarked']\nfor col in cols :\n    print(train[[col, 'Survived']].groupby([col],as_index=False).mean().sort_values(by='Survived', ascending=False),end=' \\n ******** ******* ********* \\n ')","57e1e5b3":"fig, axes =plt.subplots(5,1, figsize=(6,12))\naxes = axes.flatten()\n\nfor ax, catplot in zip(axes,train[cols]):\n      \n    _=sns.countplot(x=catplot, data=train, ax=ax, hue=train['Survived'], palette=\"OrRd\")\n    _.legend(loc='upper right')\n    \nplt.tight_layout()  \nplt.show()        ","45380c34":"_ = sns.FacetGrid(train, col='Survived')\n_.map(plt.hist, 'Age', bins=15)","3539c2c3":"_ = sns.FacetGrid(train, col='Pclass')\n_.map(plt.hist, 'Age', bins=15)","e0ae6b91":"_ = sns.FacetGrid(train, col='Sex')\n_.map(plt.hist, 'Age', bins=15)","9bbc26e5":"fig,ax=plt.subplots(1,3,figsize=(20,8))\nsns.histplot(train[train['Pclass']==1].Fare,ax=ax[0],kde=True, stat=\"density\", linewidth=0)\nax[0].set_title('Fares in Pclass 1')\nsns.histplot(train[train['Pclass']==2].Fare,ax=ax[1],kde=True, stat=\"density\", linewidth=0)\nax[1].set_title('Fares in Pclass 2')\nsns.histplot(train[train['Pclass']==3].Fare,ax=ax[2],kde=True, stat=\"density\", linewidth=0)\nax[2].set_title('Fares in Pclass 3')\nplt.show()","6ab522e0":"test.sample(5)","21b20e5d":"print(test.shape,test.info(),test.isnull().sum(),sep=' \\n ***********  *************  ************ \\n')","51ff5948":"# Drop useless columns\ntest = test.drop(['Cabin','Ticket','Name','PassengerId'],axis=1)\n\n\n## Dealing with mising values ##\nfreq = test.Fare.dropna().mode()\nprint(freq,'\\n')\ntest['Fare'] = test['Fare'].fillna(freq[0]) # fill \"NAN\" values with the most frequent value\n\nmean = test['Age'].dropna().mean()\ntest['Age'] = test['Age'].fillna(round(mean))\nprint(round(mean))","e6cabb2a":"\ntest['Sex'].replace('female', 0,inplace=True)\ntest['Sex'].replace('male', 1,inplace=True)\n\n\ntest['Embarked'].replace('S', 0,inplace=True)\ntest['Embarked'].replace('C', 1,inplace=True)\ntest['Embarked'].replace('Q', 2,inplace=True)","45292fa2":"test.sample(5)","05e1a614":"x_test =test\nx_train = train.drop(\"Survived\", axis=1)\ny_train = train[\"Survived\"]","fcf23ffe":"model1= LogisticRegression(solver='liblinear')\nmodel1.fit(x_train,y_train)\nprediction = model1.predict(x_test)\nprediction[:10]","d1ffa426":"model2= KNeighborsClassifier(n_neighbors=3)\nmodel2.fit(x_train, y_train)\nprediction = model2.predict(x_test)\nprediction[:10]","4a2c1566":"model3 = GaussianNB()\nmodel3.fit(x_train,y_train)\nprediction = model3.predict(x_test)\nprediction[:10]","7e058d84":"model4 = SVC(kernel='linear')\nmodel4.fit(x_train, y_train)\nprediction= model4.predict(x_test)\nprediction[:10]","83418d5f":"score1 = round(model1.score(x_train, y_train) * 100, 2)\nscore2 = round(model2.score(x_train, y_train) * 100, 2)\nscore3 = round(model3.score(x_train, y_train) * 100, 2)\nscore4 = round(model4.score(x_train, y_train) * 100, 2)","c06ff63f":"dict = {'Model' : ['Logistic Regression','K nearest neighbor','Naive Bayes','Support Vector Machine'],\n'Score' :[score1,score2,score3,score4] }\nmodels_score = pd.DataFrame(dict)","ebf1a96b":"models_score","e9b54ec1":"submission = pd.DataFrame({ 'Survived': prediction})\nsubmission .to_csv('my_submission.csv', index=False)","e89f4fa2":"## Dataset","29be802a":"### 4. Support Vector Machine (SVM)","4a2a714f":"### Required Libraries","7dee4e05":"**\"NAN\" values  in the taining dataset**","4d4fac32":"### Data Analysis & Visualization","f6482ea4":"\n\n\n**Synopsis :** \n\nTitanic, in full Royal Mail Ship (RMS) Titanic, British luxury passenger liner that sank on April 14\u201315, 1912, during its maiden voyage, en route to New York City from Southampton, England, killing about 1,500 passengers and ship personnel. One of the most famous tragedies in modern history, it inspired numerous stories, several films, and a musical and has been the subject of much scholarship and scientific speculation.\n\n**Data :**\n\nThere are tow datasets one dataset is titled `train.csv` and the other is titled `test.csv`.\nTrain.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the \u201cground truth\u201d.\nThe `test.csv` dataset contains similar information but does not disclose the \u201cground truth\u201d for each passenger. It\u2019s your job to predict these outcomes.\n\n**Goal :**\n\nKnowing from a training set of samples listing passengers who survived or did not survive the Titanic disaster, can our model determine based on a given test dataset not containing the survival information, if these passengers in the test dataset survived or not.\n","e587401d":"### Training and Predictions","7269f9c2":"## Machine learning model","c48a04fe":"### 2. K nearest neighbor (KNN)","f7689d85":"### let\u2018s talk about test dataset!","c7defc17":"### let\u2018s talk about train dataset!","f3878383":"### Evaluating","9fb1a540":"### 3. Naive Bayes","ed03023c":"**Converting categorical feature to numeric**","89e638e9":"### 1. Logistic Regression"}}