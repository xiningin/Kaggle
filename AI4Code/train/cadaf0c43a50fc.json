{"cell_type":{"bc673345":"code","b46e268d":"code","6f156d9e":"code","7ace25d0":"code","1eb50759":"code","a543eadf":"code","6189789f":"code","418bbe3b":"code","9f12a719":"code","76d9caca":"code","1d8fdf2e":"code","64dd8cf1":"code","1694f0a3":"code","b0abf346":"code","02226114":"code","fd9c287b":"code","7e6cae87":"code","2722d983":"code","1628dbdc":"code","eab1bea2":"code","7bae095b":"code","f04f5c36":"code","917c5cba":"markdown","8c78870a":"markdown","a32ddd0d":"markdown","3f1de73b":"markdown","5385328a":"markdown","6c531504":"markdown","ddcd0c04":"markdown","647885d4":"markdown","c73817e5":"markdown","16d958ef":"markdown"},"source":{"bc673345":"#!kaggle competitions download --force titanic\nimport pandas as pd\nimport numpy as np\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n%matplotlib inline  ","b46e268d":"\n\"\"\"\ndependent var = survived: 0\/1 for no\/yes\nindependent vars = \n    pcalss: ticket class \n    sex: \n    age: age in years\n    sibsp: num of sibling aboard the titanic\n    parch: num of parents aboard the titanic\n    ticket: ticket number\n    fare: passenger fare\n    cabin: cabin number\n    embarked: port of embarkation\n\"\"\"","6f156d9e":"_data_path = '..\/input\/titanic\/'\n\n_train_data = os.path.join(_data_path, 'train.csv') \n_test_data =  os.path.join(_data_path, 'test.csv') \n\ntrain_df = pd.read_csv(_train_data)\ntest_df = pd.read_csv(_test_data)\ntrain_df.columns = train_df.columns.str.lower()\ntest_df.columns = test_df.columns.str.lower()\n\ndisplay(train_df.head(10))","7ace25d0":"print('data shape: {}'.format(train_df.shape))\n# train_df\nprint('\\ndata columns: {}'.format(list(train_df.columns)))\nprint(train_df.survived.value_counts() \/ len(train_df))\n\n# # check no duplicates\ntrain_df.groupby('survived').size().describe()\n\n# # check for null values\nprint('whether having a null value: {}\\n'.format(train_df.isnull().values.any()))\nprint(train_df.isnull().sum())\nprint('\\n')\nprint(train_df.info())","1eb50759":"sns.countplot(x= 'survived', data= train_df)\nsns.catplot(x= \"pclass\", y= \"fare\", hue= 'survived', kind= 'box', data= train_df)\ntrain_df[['pclass', 'survived']].groupby(['pclass', 'survived']).size().unstack().plot(kind = 'bar', stacked = True, title = 'Pclass distribution')","a543eadf":"import re\n\ncombined_dfs = [train_df, test_df]\nfor df in combined_dfs:\n    df['title'] = df['name'].apply(lambda x: re.search('[A-Za-z]+\\.', x).group())\n# train_df['title'].value_counts()\n","6189789f":"def encode_title(data):\n    if data == 'Mr.':\n        data = 0\n    elif data == 'Miss.':\n        data = 1\n    elif data == 'Mrs.':\n        data = 2\n    else:\n        data = 3\n    return data\n\nfor df in combined_dfs:\n    df['title'] = df['title'].apply(encode_title)\n\ndf['title'].value_counts()","418bbe3b":"train_df.groupby(['title', 'survived']).size().unstack().plot(kind = 'bar')\n\n# delete unneeded variable\nfor df in combined_dfs:\n    df.drop('name', axis= 1, inplace = True)\n","9f12a719":"\nfor df in combined_dfs:\n    df['age'].fillna(df.groupby('title')['age'].transform('median'), inplace= True)\n\ndisplay(train_df.head())\ndisplay(test_df.head())\n\nsns.FacetGrid(train_df, hue= 'survived', height=8).map(sns.kdeplot, 'age', shade = True).set_axis_labels('age','survived').add_legend()\nsns.FacetGrid(train_df, hue= 'survived', height=8).map(sns.distplot, 'age').set_axis_labels('age','survived').add_legend()\nplt.show()\n\n\n","76d9caca":"for df in combined_dfs:\n    df.loc[df['age'] <= 18, 'age'] = 0\n    df.loc[(df['age'] > 18) & (df['age'] <= 30), 'age'] = 1\n    df.loc[(df['age'] > 30) & (df['age'] <= 45), 'age'] = 2\n    df.loc[(df['age'] > 45) & (df['age'] <= 60), 'age'] = 3\n    df.loc[df['age'] > 60, 'age'] = 4\ntrain_df.head()\n\n","1d8fdf2e":"for df in combined_dfs:\n    df['sex'] = df['sex'].apply(lambda x:1 if x =='male' else 0)\ntrain_df","64dd8cf1":"train_df[['sex', 'survived']].groupby(['sex', 'survived']).size().unstack().plot(kind = 'bar', stacked = True, title = 'Sex distribution')\n","1694f0a3":"train_df[['embarked', 'survived']].groupby(['embarked', 'survived']).size().unstack().plot(kind = 'bar', stacked = True, title = 'embarked distribution')\nprint('{} missing value for embark\\n'.format(train_df['embarked'].isnull().sum()))\n\n# to see the distribution of embarked within different pclass\nfor i in range(1, 4):\n    print(train_df[train_df['pclass'] == i]['embarked'].value_counts())","b0abf346":"# fill out the Nan value with S cat \nfor df in combined_dfs:\n    df['embarked'] = df['embarked'].fillna('S')\nprint('{} Nan value of Embarked'.format(df['embarked'].isnull().sum()))","02226114":"def embarked_encode(data):\n    if data == 'C':\n        data = 0\n    elif data == 'Q':\n        data = 1\n    else:\n        data = 2\n    return data \n\nfor df in combined_dfs:\n    df['embarked'] = df['embarked'].astype(str).apply(embarked_encode)\n    df.drop(['ticket', 'cabin'], axis = 1, inplace = True)\n# train_df['embarked'] = train_df['embarked'].astype(str).apply(embarked_encode)\n# train_df.drop(['ticket', 'cabin'], axis = 1, inplace = True)\n# train_df\n\n","fd9c287b":"display(train_df)\ndisplay(test_df)\n","7e6cae87":"test_df.isnull().sum()\n# fill out fare null by mean\n\ntest_df['fare'] = test_df['fare'].fillna(test_df['fare'].mean())\nprint('{} fare null value'.format(test_df['fare'].isnull().sum()))","2722d983":"train_df.isnull().sum()","1628dbdc":"X_train = train_df.loc[:, train_df.columns != 'survived']\ny_train= train_df.survived.values\nX_test = test_df\n\n# display(X_train)\n# display(y_train)\n","eab1bea2":"from xgboost.sklearn import XGBClassifier\n\nxfb_clf = XGBClassifier(\n        # \u6a39\u7684\u500b\u6578\n        n_estimators=100,\n        # \u5b78\u7fd2\u7387\n        learning_rate= 0.3, \n        # \u69cb\u5efa\u6a39\u7684\u6df1\u5ea6\uff0c\u8d8a\u5927\u8d8a\u5bb9\u6613\u904e\u64ec\u5408    \n        max_depth=6, \n        # \u96a8\u6a5f\u53d6\u6a23\u8a13\u7df4\u6a23\u672c \u8a13\u7df4\u4f8b\u9805\u7684\u5b50\u53d6\u6a23\u6bd4\n        subsample=1, \n        # \u7528\u65bc\u63a7\u5236\u662f\u5426\u5f8c\u526a\u679d\u7684\u5f15\u6578,\u8d8a\u5927\u8d8a\u4fdd\u5b88\uff0c\u4e00\u822c0.1\u30010.2\u9019\u6a23\u5b50\n        gamma=0, \n        # \u63a7\u5236\u6a21\u578b\u8907\u96dc\u5ea6\u7684\u6b0a\u91cd\u503c\u7684L2\u6b63\u5247\u5316\u9805\u5f15\u6578\uff0c\u5f15\u6578\u8d8a\u5927\uff0c\u6a21\u578b\u8d8a\u4e0d\u5bb9\u6613\u904e\u64ec\u5408\u3002\n        reg_lambda=1,  \n        #\u6700\u5927\u589e\u91cf\u6b65\u9577\uff0c\u6211\u5011\u5141\u8a31\u6bcf\u500b\u6a39\u7684\u6b0a\u91cd\u4f30\u8a08\u3002\n        max_delta_step=0,\n        # \u751f\u6210\u6a39\u6642\u9032\u884c\u7684\u5217\u53d6\u6a23 \n        colsample_bytree=1, \n\n        # \u9019\u500b\u5f15\u6578\u9810\u8a2d\u662f 1\uff0c\u662f\u6bcf\u500b\u8449\u5b50\u88e1\u9762 h \u7684\u548c\u81f3\u5c11\u662f\u591a\u5c11\uff0c\u5c0d\u6b63\u8ca0\u6a23\u672c\u4e0d\u5747\u8861\u6642\u7684 0-1 \u5206\u985e\u800c\u8a00\n        # \u5047\u8a2d h \u5728 0.01 \u9644\u8fd1\uff0cmin_child_weight \u70ba 1 \u610f\u5473\u8457\u8449\u5b50\u7bc0\u9ede\u4e2d\u6700\u5c11\u9700\u8981\u5305\u542b 100 \u500b\u6a23\u672c\u3002\n        #\u9019\u500b\u5f15\u6578\u975e\u5e38\u5f71\u97ff\u7d50\u679c\uff0c\u63a7\u5236\u8449\u5b50\u7bc0\u9ede\u4e2d\u4e8c\u968e\u5c0e\u7684\u548c\u7684\u6700\u5c0f\u503c\uff0c\u8a72\u5f15\u6578\u503c\u8d8a\u5c0f\uff0c\u8d8a\u5bb9\u6613 overfitting\u3002\n        min_child_weight=1, \n\n        #\u96a8\u6a5f\u7a2e\u5b50\n        seed=1000)\n\n# \u6a21\u578b \u8a13\u7df4\nxfb_clf.fit(X_train, y_train, eval_metric='auc')\n# \u9810\u6e2c\u503c\ny_pred = xfb_clf.predict(X_test)","7bae095b":"X_test['Survived'] = y_pred\nX_test = X_test[['passengerid', 'Survived']]\nX_test.rename(columns = {'passengerid': 'PassengerId'}, inplace = True)\nX_test","f04f5c36":"X_test.to_csv('Titanic_output.csv', index = False)","917c5cba":"## Reference","8c78870a":"## data exploration","a32ddd0d":"### focuing on age","3f1de73b":"This experiment is inspired by the following resources\n- https:\/\/www.youtube.com\/watch?v=COUWKVf6zKY\n- https:\/\/medium.com\/@yulongtsai\/https-medium-com-yulongtsai-titanic-top3-8e64741cc11f\n- https:\/\/www.kaggle.com\/aman56\/titanic-beginners-ml\n\nif i miss out the refernece not listed above, please let me know. Thanks","5385328a":"## data modeling","6c531504":"## data visulization and data engineering","ddcd0c04":"### focus on embark","647885d4":"## data loading\n","c73817e5":"### focus on sex","16d958ef":"### focus on name"}}