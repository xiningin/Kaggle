{"cell_type":{"385eb28a":"code","bff69d17":"code","732fb934":"code","bc5eb3c1":"code","8d48a8b6":"code","a8c9f926":"code","9671a923":"code","1e65286a":"markdown"},"source":{"385eb28a":"# Import Libraries\nimport os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt","bff69d17":"# Load base image\nimg = cv2.imread(\"..\/input\/neural-style-transfer\/images\/images\/Yuki.jpg\")\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()","732fb934":"# Total of 9 style images\nstyle_images = os.listdir(\"..\/input\/neural-style-transfer\/art\/art\")\nlen(style_images)","bc5eb3c1":"# Load style images\nstyle_images = np.array(style_images)\nstyle_images = style_images.reshape(3, 3)\n\nstyle_dic = {}\nfig, axs = plt.subplots(3, 3, figsize = (15, 15))\nfor i in range(3):\n    for j in range(3):\n        path = os.path.join(\"..\/input\/neural-style-transfer\/art\/art\", style_images[i, j])\n        img_st = cv2.imread(path)\n        img_st = cv2.cvtColor(img_st, cv2.COLOR_BGR2RGB)\n        \n        axs[i, j].imshow(img_st)\n        axs[i, j].set(xticks = [], yticks = [])\n        \n        text = style_images[i, j][:-4]\n        axs[i, j].set_title(text)\n        \n        style_dic[text] = img_st","8d48a8b6":"# List of models for each image\nmodels = [\n    \"candy.t7\",\n    \"composition_vii.t7\",\n    \"feathers.t7\",\n    \"la_muse.t7\",\n    \"mosaic.t7\",\n    \"starry_night.t7\",\n    \"the_scream.t7\",\n    \"the_wave.t7\",\n    \"udnie.t7\"\n]","a8c9f926":"# Apply Neural Style Transfer\noutput_dic = {}\nfor i, mod in enumerate(models):\n    text = str(mod)[:-3]\n    style = cv2.imread(os.path.join(\"..\/input\/neural-style-transfer\/art\/art\", text + \".jpg\"))\n\n    # Load Neural Transfer Style Model\n    model_neural = cv2.dnn.readNetFromTorch(os.path.join(\"..\/input\/neural-style-transfer\", mod))\n\n    # Resize and make smaller (takes forever to perform on large images)\n    height, width = img.shape[0], img.shape[1]\n    new_height = 640\n    new_width = int((new_height\/height) * width)\n    new_img = cv2.resize(\n        img, \n        (new_width, new_height),\n        interpolation = cv2.INTER_AREA\n    )\n\n    # Create a blob from the image and perform a forward pass considering the mean (R, G, B) values from ImageNet \n    R, G, B = 103.93, 116.77, 123.68\n    input_blob = cv2.dnn.blobFromImage(\n        new_img,\n        1,\n        (new_width, new_height),\n        (R, G, B),\n        swapRB = False,\n        crop = False\n    )\n    model_neural.setInput(input_blob)\n    output = model_neural.forward()\n    \n    # Reshape the output Tensor\n    output = output.reshape(output.shape[1], output.shape[2], output.shape[3])\n    # Adding the mean (R, G, B) values from ImageNet\n    output[0] += R\n    output[1] += G\n    output[2] += B\n   \n    # Normalize output\n    output \/= 255\n    # Ensure range of values in between (0, 1)\n    output = output.clip(0, 1)\n    output = output.transpose(1, 2, 0)\n    \n    output_dic[text] = output","9671a923":"fig, axs = plt.subplots(9, 3, figsize = (20, 20))\nfor i, text in enumerate(output_dic):\n    axs[i, 0].imshow(img)\n    axs[i, 0].set(xticks = [], yticks = [])\n    axs[i, 0].set_title(\"Base Image\")\n    \n    axs[i, 1].imshow(style_dic[text])\n    axs[i, 1].set(xticks = [], yticks = [])\n    axs[i, 1].set_title(text + \" (Style)\")    \n        \n    axs[i, 2].imshow(output_dic[text])\n    axs[i, 2].set(xticks = [], yticks = [])\n    axs[i, 2].set_title(\"Output Image\")\n    \nfig.tight_layout()","1e65286a":"# Neural Style Transfer with OpenCV"}}