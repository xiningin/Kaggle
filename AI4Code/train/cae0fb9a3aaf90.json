{"cell_type":{"1fa1589c":"code","47d80709":"code","c2a7cf62":"code","1feff830":"code","c9b7fb29":"code","9e59dc68":"code","3ca49d19":"code","822828d1":"code","1e750537":"code","903ce59e":"code","41eed999":"markdown","2fdea94d":"markdown","c454645e":"markdown","61535149":"markdown","4d4c221c":"markdown","ebe98003":"markdown","2a548c53":"markdown","5318bb68":"markdown","74cbf282":"markdown","1a853f34":"markdown"},"source":{"1fa1589c":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score","47d80709":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")","c2a7cf62":"# 1. delete insignificant feature\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n# 2. check null and fill new data\ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n# 3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)","1feff830":"y = train['Survived']\nX = train.drop(['Survived'], axis=1)\nX_test = test\nRANDOM_SEED = 2021\n\nX_Train, X_Val, Y_Train, Y_Val = train_test_split(X, y, test_size = 0.25,random_state = RANDOM_SEED )","c9b7fb29":"model1 = RandomForestClassifier(random_state= RANDOM_SEED).fit(X_Train,Y_Train)\nmodel1","9e59dc68":"import joblib \nfile_name = 'randomclassifier_titanic.pkl' \njoblib.dump(model1, file_name) ","3ca49d19":"model2 = joblib.load(file_name) \nmodel2","822828d1":"print(\"model.get_params()\")\nprint(model2.get_params())\nprint(\" \")\nprint(\"model.classes_\")\nprint(model2.classes_)\nprint(\" \")\nprint(\"model.estimators_\")\nmodel2.estimators_","1e750537":"print(\"<predictionforest>\")\npredictionforest = model2.predict(X_Val)\nprint(predictionforest)\nprint(\" \")\nprint(\"<confusion_matrix>\")\nprint(confusion_matrix(Y_Val,predictionforest))\nprint(\" \")\nprint(\"<classification_report>\")\nprint(classification_report(Y_Val,predictionforest,target_names=['Died', 'Survived']))\nprint(\" \")\nprint(\"<accuracy_score>\")\nacc1 = accuracy_score(Y_Val,predictionforest)\nprint(acc1)","903ce59e":"submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\nsubmission.Survived = model2.predict(X_test)\nsubmission.to_csv(\"submission.csv\",index=False)","41eed999":"# split train and valid set ","2fdea94d":"# load data","c454645e":"# make model","61535149":"# save model with joblib","4d4c221c":"# preprocessing","ebe98003":"# predict validation set ","2a548c53":"# load model ","5318bb68":"# import basic libraray ","74cbf282":"# model info","1a853f34":"# submit result"}}