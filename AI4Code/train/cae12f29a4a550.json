{"cell_type":{"0fc30889":"code","e587d6b0":"code","65265142":"code","29074006":"code","f5b7c869":"code","7b980581":"code","895899a3":"code","72713c4c":"code","f7eade98":"code","8a5342de":"code","1ae1a5fe":"code","1906eef3":"code","b9eded60":"code","8d69a5da":"code","26f96f8c":"code","da72d201":"code","fca1522d":"code","2c78c742":"code","3d1889ad":"code","7a75ce22":"code","cc6ba8be":"code","85af7805":"code","8be0add8":"code","5ae5b434":"markdown","43a3b218":"markdown","81e0c36f":"markdown"},"source":{"0fc30889":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","e587d6b0":"# import and instantiate CountVectorizer (with the default parameters)\nfrom sklearn.feature_extraction.text import CountVectorizer\nvect = CountVectorizer(ngram_range=(1, 2), stop_words='english')","65265142":"# read file into pandas using a relative path\nsms = pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\", encoding='latin-1')\nsms.dropna(how=\"any\", inplace=True, axis=1)\nsms.columns = ['label', 'message']\nsms.head()","29074006":"sms.groupby('label').describe()\n# convert label to a numerical variable\nsms['label_num'] = sms.label.map({'ham':0, 'spam':1})\nsms.head()","f5b7c869":"sms['message_len'] = sms.message.apply(len)\nplt.figure(figsize=(12, 8))\n\nsms[sms.label=='ham'].message_len.plot(bins=35, kind='hist', color='blue', \n                                       label='Ham messages', alpha=0.6)\nsms[sms.label=='spam'].message_len.plot(kind='hist', color='red', \n                                       label='Spam messages', alpha=0.6)\nplt.legend()\nplt.xlabel(\"Message Length\")","7b980581":"df = pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\", encoding='latin-1')\ndf = df[['v1', 'v2']]\ndf","895899a3":"import string\nfrom nltk.corpus import stopwords\n\nSTOPWORDS = stopwords.words('english') + ['u', '\u00fc', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']","72713c4c":"!pip install pycaret","f7eade98":"from pycaret.nlp import *\n\n%time nlp = setup(data = df, target ='v2', custom_stopwords = STOPWORDS, session_id = 21)\n# label_num is the target","8a5342de":"%time m1 = create_model(model = 'lda', multi_core = True)","1ae1a5fe":"%time lda_data = assign_model(m1)","1906eef3":"lda_data.head()","b9eded60":"evaluate_model(m1)","8d69a5da":"lda_data.drop(['v2', 'Dominant_Topic', 'Perc_Dominant_Topic'], axis = 1, inplace = True)\nlda_data.head()","26f96f8c":"from sklearn.model_selection import train_test_split\nTrain, Test = train_test_split(lda_data, test_size=0.1, random_state=1)","da72d201":"from pycaret.classification import *\n%time setup2 = setup(data = Train, target = 'v1', session_id = 5, train_size = 0.9)","fca1522d":"%time best_3 = compare_models(sort = 'Accuracy', n_select = 3)","2c78c742":"blended = blend_models(estimator_list = best_3, fold = 5, method = 'soft')","3d1889ad":"pred_holdout = predict_model(blended)","7a75ce22":"final_model = finalize_model(blended)","cc6ba8be":"Predictions = predict_model(final_model, data = Test)\nPredictions","85af7805":"Result = Predictions[['v1', 'Label']]\nResult","8be0add8":"model_score = sum(Result['v1'] == Result['Label'])\/len(Result)\nmodel_score","5ae5b434":"# 2. Building and evaluating an AutoML model","43a3b218":"# Spam Classification with AutoML","81e0c36f":"# 1. Exploratory Data Analysis (EDA)"}}