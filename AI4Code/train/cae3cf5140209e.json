{"cell_type":{"8024011e":"code","6f69ac89":"code","5e44e047":"code","eb6f3799":"code","e3aef6cd":"code","81dcd30a":"code","5b1532d2":"code","51d7f3c3":"code","dc6cbf39":"code","e58002ed":"code","66180c54":"code","ea2987a6":"code","9254f7c4":"code","104084d6":"code","5eaf08ed":"code","0dac1efd":"code","7076822a":"code","7776cebe":"code","02e13dc0":"code","b8dae55c":"code","65fd0396":"code","e1b45684":"code","42d862a9":"code","f489f743":"code","4b090276":"code","26a7642a":"markdown","a87f86c9":"markdown","6a20e055":"markdown","1c15f6c8":"markdown","974df1a7":"markdown","d795626d":"markdown","4c8a5105":"markdown","5f62c042":"markdown","619f3e59":"markdown","0dde4914":"markdown","7d8321c8":"markdown","bb08218e":"markdown","0808fe44":"markdown","bae437c8":"markdown","2dd6b9b9":"markdown"},"source":{"8024011e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport tensorflow as tf\nfrom tensorflow.keras.regularizers import l1\nfrom tensorflow.keras.regularizers import l2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# Any results you write to the current directory are saved as output.\n\nprint(tf.__version__)","6f69ac89":"train = pd.read_csv('..\/input\/learn-together\/train.csv')\ntrain.head()","5e44e047":"test = pd.read_csv('..\/input\/learn-together\/test.csv')\ntest_Id = test['Id'] ","eb6f3799":"train_stats = train.describe()\ntrain_stats = train_stats.transpose()\ntrain_stats","e3aef6cd":"train = train.drop(['Soil_Type7','Soil_Type15','Id'], axis =1)\ntest = test.drop(['Soil_Type7','Soil_Type15','Id'], axis =1)","81dcd30a":"train_labels = train.pop('Cover_Type') -1\ntrain.head()","5b1532d2":"train_labels.head()","51d7f3c3":"def maxNorm (df, themin,themax):\n    normalized_df=(df-themin)\/( themax - themin)\n    return normalized_df","dc6cbf39":"train_min = train.min()\ntrain_max = train.max()\nnormed_train_data = maxNorm(train, train_min, train_max)\nnormed_test_data = maxNorm(test,train_min, train_max)\nnormed_train_data.head()","e58002ed":"print (len(train_labels))\nuniqueValues = np.unique(train_labels)\nprint('Unique Values : ',uniqueValues)\ncnt_labels = len(uniqueValues)\nprint (cnt_labels)","66180c54":"def build_model(length):\n    model = keras.Sequential([\n    layers.Dense(512, activation=tf.nn.relu, input_shape=[length]), \n    layers.Dropout(0.5),\n    layers.Dense(256, activation=tf.nn.relu, activity_regularizer=l2(0.001)),   \n    layers.Dropout(0.5),\n    layers.Dense(256, activation=tf.nn.relu, activity_regularizer=l2(0.001)), \n    layers.Dropout(0.5),\n    layers.Dense(7, activation=tf.nn.softmax)\n    ])\n    #optimizer = tf.keras.optimizers.RMSprop(lr=0.0001)\n    optimizer = tf.keras.optimizers.Adam()\n    \n    model.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',\n              metrics=['sparse_categorical_accuracy' ])\n    return model\n\n","ea2987a6":"model = build_model(len(normed_train_data.keys()))\nmodel.summary()","9254f7c4":"good = 0\nbad=0\npredictions = model.predict(normed_train_data)\nfor i in range(len(normed_train_data)):\n    if (np.argmax(predictions[i]) == train_labels[i]):\n        good +=1\n    else:\n        bad +=1\nprint (\"good:\", good)\nprint (\"bad:\", bad)","104084d6":"es = keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1, patience=40,restore_best_weights=False )\nhistory = model.fit(normed_train_data, train_labels,batch_size=1024,callbacks=[es],\n                    epochs=350, validation_split = 0.2, verbose=1)","5eaf08ed":"_, train_acc = model.evaluate(normed_train_data, train_labels, verbose=0)\nprint('Train: %.3f' % (train_acc))\n","0dac1efd":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nbestEpochs = hist.tail(1).epoch.item()","7076822a":"def plot_history(history, val=True):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Accuracy ')\n  plt.plot(hist['epoch'], hist['sparse_categorical_accuracy'],\n           label='Train Accuracy')\n  if val:\n     plt.plot(hist['epoch'], hist['val_sparse_categorical_accuracy'],label = 'Val Accuracy')\n  plt.ylim([0,1])\n  plt.legend()\n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Loss ')\n  plt.plot(hist['epoch'], hist['loss'],\n           label='Train Loss')\n  if val:\n      plt.plot(hist['epoch'], hist['val_loss'],label = 'Val Loss')\n  plt.ylim([0,1])\n  plt.legend()\n\n\n  plt.show()\n\n\nplot_history(history)","7776cebe":"finalmodel = build_model(len(normed_train_data.keys()))\nhistory = finalmodel.fit(normed_train_data, train_labels,batch_size=1024,\n                    epochs=bestEpochs + 1, verbose=1)","02e13dc0":"hist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\n","b8dae55c":"example_batch = normed_train_data[:10]\nexample_result = finalmodel.predict(example_batch)\nexample_result","65fd0396":"good = 0\nbad=0\npredictions = finalmodel.predict(normed_train_data)\nfor i in range(len(normed_train_data)):\n    if (np.argmax(predictions[i]) == train_labels[i]):\n        good +=1\n    else:\n        bad +=1\nprint (\"good:\", good)\nprint (\"bad:\", bad)","e1b45684":"plot_history(history,False)","42d862a9":"test_predictions = finalmodel.predict(normed_test_data)","f489f743":"print (test_predictions[0])\ntest_label = np.argmax(test_predictions,axis=1) + 1\nprint (test_label[0])","4b090276":"submission = pd.DataFrame(columns=['Id', 'Cover_Type'])\nsubmission['Id'] = test_Id\nsubmission['Cover_Type'] = test_label\nsubmission.to_csv('submission.csv', index=False)","26a7642a":"Predict with trained Model on training data:","a87f86c9":"Create Model:","6a20e055":"Predict with untrained model on training data:","1c15f6c8":"Nomalize:","974df1a7":"Find last epoch to retrain the network with the full dataset without train\/val split","d795626d":"Train the Model:","4c8a5105":"Get features:","5f62c042":"Train new Model with all train data:","619f3e59":"As is seen Soil_Type 7 and 15 have mean zero, what leads to the conclusion that there are no entries with soil_type 7 or 15. ","0dde4914":"Create Submission:","7d8321c8":"This kernel got a score of 0.76.. on the \"learn-together\" competion out of the box. To increase performance one could try : More nodes, more layers, more epochs. \n","bb08218e":"Have a look at the labels:","0808fe44":"Examine Dataset:","bae437c8":"Get the Dataset:","2dd6b9b9":"Analyze:"}}