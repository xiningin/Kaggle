{"cell_type":{"1d40246d":"code","39b08e73":"code","ca1a027c":"code","66b93e38":"code","2189ea32":"code","754cf85a":"code","941b6105":"code","a78309d1":"code","cc5540a6":"code","e01f7d2f":"code","71f5d655":"code","66fabbbc":"code","a7a24d56":"code","f5c7bd9f":"code","f36be23f":"code","01c1737a":"code","fe873f5f":"code","84b9d359":"code","a1733809":"markdown","47734210":"markdown","5f2de966":"markdown","1944622b":"markdown","d1d31153":"markdown","04dbb32b":"markdown","b42b5f0b":"markdown","117ec5c9":"markdown","46aea417":"markdown","ec9e0609":"markdown","8287caea":"markdown","04931190":"markdown","32adeb72":"markdown","c630f03f":"markdown","af57de32":"markdown","fcf61b76":"markdown","da3a9f34":"markdown","a2dbc8b0":"markdown","c3effde2":"markdown","96bb2837":"markdown","ad626a34":"markdown"},"source":{"1d40246d":"# Install\n!pip install -q s2cell","39b08e73":"# Biasalah\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Date\nfrom datetime import datetime\nimport calendar\n\n# S2\nfrom s2cell import *\n\n# Preprocess & Metric\nfrom sklearn.model_selection import *\nfrom sklearn.preprocessing import *\nfrom sklearn.metrics import f1_score\n\n# LGBM\nfrom lightgbm import LGBMClassifier","ca1a027c":"SEED = 2021","66b93e38":"train = pd.read_csv(\"..\/input\/danthon2021\/data_train.csv\")\ntest = pd.read_csv(\"..\/input\/danthon2021\/data_test.csv\")\n\ntrain.head()","2189ea32":"# Train\ntrain['token'] = train.Ids.apply(lambda x : x.split('_')[0])\ntrain['hour'] = train.Ids.apply(lambda x : x.split('_')[-1])\n\n# Test\ntest['token'] = test.Ids.apply(lambda x : x.split('_')[0])\ntest['hour'] = test.Ids.apply(lambda x : x.split('_')[-1])\n\ntrain.head()","754cf85a":"def extract_day(x):\n    date = datetime.strptime(x, '%Y-%m-%d')\n    return calendar.day_name[date.weekday()]","941b6105":"train['day'] = train.Ids.apply(lambda x : extract_day(x.split('_')[1]))\ntest['day'] = test.Ids.apply(lambda x : extract_day(x.split('_')[1]))\n    \ntest.head()","a78309d1":"def extract_l2(tokens):\n    lat, lon = [], []\n    for token in tokens:\n        temp = token_to_lat_lon(token)\n        lat.append(temp[0])\n        lon.append(temp[1])\n    return lat, lon","cc5540a6":"# train\ntrain['lat'], train['lon'] = extract_l2(train.token.values)\n\n# test\ntest['lat'], test['lon'] = extract_l2(test.token.values)\n\ntrain.head()","e01f7d2f":"# Train\nX = train.drop(['Ids', 'Labels', 'token'], axis = 1)\ny = train.Labels\n\n# Test\nX_test = test.drop(['Ids', 'token'], axis = 1)\n\nX.head()","71f5d655":"# Train\nX = pd.get_dummies(X, columns=['day'])\nX['hour'] = X['hour'].astype(float)\ny = y.astype(int).values\n\n# Test\nX_test = pd.get_dummies(X_test, columns=['day'])\nX_test['hour'] = X_test['hour'].astype(float)\n\nX.head()","66fabbbc":"# Kfold 5 splits\nfold = KFold(n_splits = 5, shuffle=True, random_state=SEED)\n\nscores = []\nfor train_idx, test_idx in fold.split(X,y):\n    # LGBM Model\n    lgbm = LGBMClassifier(random_state=SEED)\n    # Fit Model\n    lgbm.fit(X.iloc[train_idx, :],  y[train_idx], \n            eval_set=(X.iloc[test_idx, :],y[test_idx]),\n            eval_metric = 'logloss',\n            early_stopping_rounds = 300, verbose=0)\n    # Evaluate\n    y_pred = lgbm.predict(X.iloc[test_idx, :])\n    score = f1_score(y[test_idx], y_pred) # Hitung F1 - Scorenya\n    scores.append(score)\nscores = np.array(scores)\n\nfor i, score in enumerate(scores):\n    print(f'Fold 1 score {i + 1} : {score}')\nprint()\nprint('Mean CV :', scores.mean())\nprint('STD CV :', scores.std())","a7a24d56":"X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size=0.2, \n                                                  random_state=SEED, stratify = y)","f5c7bd9f":"model = LGBMClassifier(random_state=SEED)\n\n# Fit Model\nmodel.fit(X_train,  Y_train, eval_set=(X_val, Y_val), \n         eval_metric = 'logloss', early_stopping_rounds = 500)","f36be23f":"f1_score(Y_val, model.predict(X_val))","01c1737a":"pred = model.predict_proba(X_test)\ntest['Labels'] = model.predict(X_test).astype(bool)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (14, 7))\nsns.histplot(x = pred[:, 1], ax = ax1)\nax1.set_title(\"Distribusi peluang hasil prediksi True \\ndata test\")\n\nsns.countplot(data = test, x = 'Labels', ax = ax2)\nax2.set_title(\"Count Plot hasil Prediksi model \\nterhadap data test\")\nplt.show()","fe873f5f":"test.head()","84b9d359":"sub = test.drop(['token', 'hour', 'lat', 'lon', 'day'], axis = 1)\nsub.to_csv('LGBM.csv', index = False)","a1733809":"**Insight**\n\nDilihat dari skor `mean-cv`-nya dan `std`-nya dapat di simpulkan. Setidaknya model yang telah di bangun memiliki kemampuan untuk mendapatkan nilai pada rentang `0.81` - `0.82` namun hasil dari cv ini tidak dapat di jadikan acuan untuk score data test mengingat **terdapat banyak wilayah yang hanya ada di data test saja** yang kemungkinan besar model ini akan gagal dalam memprediksi hal tersebut","47734210":"cek `f1-score`-nya pada data validasi","5f2de966":"## Train Model\n\nTrain model `LGBMClassifier`","1944622b":"# Peramalan (Prediction)\n\nMembuat prediksi dari data test","d1d31153":"# LGBMClassifier\n\nPemodelan dengan menggunakan `LGBMClassifier`","04dbb32b":"# Load Library\n\n![Biasalah](https:\/\/media.tenor.com\/images\/4d8307e40eeadc8e5e4282bbc445cd3b\/tenor.gif)","b42b5f0b":"cek cross validation scorenya","117ec5c9":"### 2. Day\n\nDapatkan `hari` dari kolom `Ids`","46aea417":"## S2Cell\n\nAkan digunakan library `s2cell` untuk menganalisa token s2 yang ada di dataset","ec9e0609":"# Summary\n\nDi notebook ini akan di lakukan pemodelan untuk data `train` dan data `test` dengan menggunakan model `LGBM` tanpa adanya join atau merge dari data `alerts` dan `irregularities`.","8287caea":"## Feature Extraction\n\n### 1. Token & Hour\n\nAmbil token dan jam dari kolom `Ids` lalu taruh di variable baru","04931190":"## 3. Latitude & Longitude\n\nUbah `token` menjadi `Latitude` dan `Longitude` menggunakan fungsi `token_to_lat_lon` dari library `s2cell`\n\nreferensi bacaan : [S2 Geometry Concepts](https:\/\/docs.s2cell.aliddell.com\/s2_concepts.html)","32adeb72":"# Submission","c630f03f":"# Penutup\n\nPada notebook ini telah dilakukan pemodelan menggunakan `LGBM` dengan hanya memanfaatkan data `train` saja. Masih banyak hal yang kurang dan dapat dikembangkan untuk meningkatkan performa model seperti:\n\n1. Tuning Model\n2. Menggunakan dan memanfaatkan data `allerts` dan `irregularities`\n3. dll :v\n\nJika ada kekurangan dan kesalahan terhadap kode dan interpretasi tolong diingatkan. Terimakasih.\n\n![Thank You](https:\/\/i.pinimg.com\/originals\/a2\/77\/e7\/a277e75de57be3e23f9d4f266e361d22.gif)","af57de32":"# Data Preprocessing\n\nPreprocess datanya dulu yak\n\n![Bad Data](https:\/\/miro.medium.com\/max\/826\/0*Cir0TzUEkHMbb8QB)","fcf61b76":"### Config\n\nGlobal configuration","da3a9f34":"### X & Y","a2dbc8b0":"Definisikan dan `fit` model","c3effde2":"# Load Data\n\nLoad dataset ke memory","96bb2837":"## Feature Encoding\n\nEncode variable - variable yang bertipe non-numerik\n\nMetode\n\n1. Ubah variable `day` dengan menjadi `dummy`\n2. Ubah `hour` menjadi `float`\n2. Ubah `y` menjadi `int`","ad626a34":"Split datasetnya terlebih dahulu"}}