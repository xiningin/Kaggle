{"cell_type":{"c4a8c855":"code","f103b083":"code","f045f78e":"code","1754475c":"code","28d893d7":"code","2684d349":"code","a16f5b66":"code","93cda9eb":"code","31357009":"code","a9a0591f":"code","f8e69845":"markdown","3fe9a588":"markdown","cbd97987":"markdown","0fdaceae":"markdown","014904f4":"markdown","bcaf9d40":"markdown","8248ca33":"markdown","530b9d68":"markdown"},"source":{"c4a8c855":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score, auc, roc_curve, roc_auc_score\n\n    \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n","f103b083":"data = pd.read_csv('\/kaggle\/input\/jobposts\/data job posts.csv')\nprint(data.columns)\n# selecting only IT Jobs\ndf = data[data['IT']]\n# selecting \ncols = ['RequiredQual', 'Eligibility', 'Title', 'JobDescription', 'JobRequirment']\ndf=df[cols]\ndf.head(5)","f045f78e":"classes = df['Title'].value_counts()[:21]\nkeys = classes.keys().to_list()\n\ndf = df[df['Title'].isin(keys)]\ndf['Title'].value_counts()","1754475c":"def chane_titles(x):\n    x = x.strip()\n    if x == 'Senior Java Developer':\n        return 'Java Developer'\n    elif x == 'Senior Software Engineer':\n        return 'Software Engineer'\n    elif x == 'Senior QA Engineer':\n        return 'Software QA Engineer'\n    elif x == 'Senior Software Developer':\n        return 'Senior Web Developer'\n    elif x =='Senior PHP Developer':\n        return 'PHP Developer'\n    elif x == 'Senior .NET Developer':\n        return '.NET Developer'\n    elif x == 'Senior Web Developer':\n        return 'Web Developer'\n    elif x == 'Database Administrator':\n        return 'Database Admin\/Dev'\n    elif x == 'Database Developer':\n        return 'Database Admin\/Dev'\n\n    else:\n        return x\n        \n    \ndf['Title'] = df['Title'].apply(chane_titles)\ndf['Title'].value_counts()","28d893d7":"from nltk import word_tokenize          \nfrom nltk.stem import WordNetLemmatizer \nclass LemmaTokenizer(object):\n    def __init__(self):\n        # lemmatize text - convert to base form \n        self.wnl = WordNetLemmatizer()\n        # creating stopwords list, to ignore lemmatizing stopwords \n        self.stopwords = stopwords.words('english')\n    def __call__(self, doc):\n        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.stopwords]\n\n# removing new line characters, and certain hypen patterns                  \ndf['RequiredQual']=df['RequiredQual'].apply(lambda x: x.replace('\\n', ' ').replace('\\r', '').replace('- ', ''). replace(' - ', ' to '))","2684d349":"from sklearn.feature_extraction.text import TfidfVectorizer\n# train features and labels \ny = df['Title']\nX = df['RequiredQual']\n# tdif feature rep \nvectorizer = TfidfVectorizer(tokenizer=LemmaTokenizer(), stop_words='english')\nvectorizer.fit(X)\n# transoforming text to tdif features\ntfidf_matrix = vectorizer.transform(X)\n# sparse matrix to dense matrix for training\nX_tdif = tfidf_matrix.toarray()\n# encoding text labels in categories \nenc = LabelEncoder() \nenc.fit(y.values)\ny_enc=enc.transform(y.values)\n\nX_train_words, X_test_words, y_train, y_test = train_test_split(X, y_enc, test_size=0.15, random_state=10)\n\nX_train = vectorizer.transform(X_train_words)\nX_train = X_train.toarray()\n\nX_test = vectorizer.transform(X_test_words)\nX_test = X_test.toarray()\n","a16f5b66":"from sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\ngnb = GaussianNB()\ntrain_preds = gnb.fit(X_train, y_train).predict(X_train)\ntest_preds = gnb.predict(X_test)\n\nprint('Train acc: {0}'.format(accuracy_score(y_train, train_preds)))\nprint('Test acc: {0}'.format(accuracy_score(y_test, test_preds)))\n","93cda9eb":"from sklearn.linear_model import LogisticRegression\n\nlogistic = LogisticRegression(max_iter=15,verbose=1, C=0.75)\n\ntrain_preds = logistic.fit(X_train, y_train).predict(X_train)\ntest_preds = logistic.predict(X_test)\n\nprint('Train acc: {0}'.format(accuracy_score(y_train, train_preds)))\nprint('Test acc: {0}'.format(accuracy_score(y_test, test_preds)))\n","31357009":"preds_data = {'Current Position Requirments': [], 'Current Position': [], 'Alternative 1': [], 'Alternative 2': []}\ny_preds_proba = logistic.predict_proba(X_test)\n\ncounter = 0 \nfor idx, (pred_row, true_job_position) in enumerate(zip(y_preds_proba, y_test)):\n    class_preds = np.argsort(pred_row)\n    # delete true class\n    for i in [-1, -2]:\n        if class_preds[i] == true_job_position:\n            class_preds=np.delete(class_preds,i)\n    # getting other 2 highest job predictions         \n    top_classes = class_preds[-2:]\n    # obtaining class name string from int label \n    class_names = enc.inverse_transform(top_classes)\n    true_job_position_name = enc.inverse_transform([true_job_position])\n    # saving to dict\n    preds_data['Current Position Requirments'].append(X_test_words.iloc[idx])\n    preds_data['Current Position'].append(true_job_position_name[0])\n    preds_data['Alternative 1'].append(class_names[1])\n    preds_data['Alternative 2'].append(class_names[0])\n\n    \n    counter +=1","a9a0591f":"preds_df = pd.DataFrame.from_dict(preds_data)\npreds_df.to_csv('Recommendations.csv', index=False)\npreds_df\n","f8e69845":"# Training Logistic Regression\nBy modifiying the maximum number of iterations, and regularization, C, the above experienced overfitting was reduced significantly \n","3fe9a588":"# Job Recommendations \n\nThis notebook creates a model, to recommend job positions given a position requirements description . This is done only for IT jobs. ","cbd97987":"# Creating Job Recommendations \nRecommends 2 job position alternatives given a job requirement. By obtaining probability of class predictions, and picking the top N predictions, other than true label, N closest recommendations can be got","0fdaceae":"# Building custom tokenizer to process text","014904f4":"# Training Naive Bayes\nLooks pretty overfit","bcaf9d40":"Change job titles to base title. For exmaple, chaning Senior Java Developer to Java Developer.   ","8248ca33":"# Featurizing Text","530b9d68":"# Modifying Job Titles\nSelecting only top 21 job titles, to manage class imbalance"}}