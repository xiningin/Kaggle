{"cell_type":{"ff65693e":"code","28c77af4":"code","8398a49b":"code","089ad5b2":"code","da61eb6d":"code","634980df":"code","2f98a3fa":"code","20822efb":"code","47a9164e":"code","952de445":"code","6954faea":"markdown","7c32a94a":"markdown","861bb929":"markdown","a3ae9042":"markdown","15732587":"markdown"},"source":{"ff65693e":"import gym","28c77af4":"env = gym.make(\"Taxi-v2\").env\nenv.render()","8398a49b":"env.reset()","089ad5b2":"print(env.observation_space)\nprint(env.action_space)","da61eb6d":"state = env.encode(3,1,2,3)\nprint(state)","634980df":"env.s = state\nenv.render()","2f98a3fa":"env.P[331]","20822efb":"env.reset()","47a9164e":"total_reward_list = []\n# episode\nfor j in range(5):\n    env.reset()\n    time_step = 0\n    total_reward = 0\n    list_visualize = []\n    while True:\n        time_step += 1\n        #choose action\n        action = env.action_space.sample()\n        #perform action and get reward\n        state, reward, done, _ =  env.step(action) # state = next state\n        #total reward\n        total_reward += reward\n        # visualize\n        list_visualize.append({\"frame\": env.render(mode = \"ansi\"),\n                                \"state\": state, \"action\": action, \"reward\":reward,\n                                \"Total Reward\": total_reward})\n        if done:\n            total_reward_list.append(total_reward)\n            break","952de445":"import time       \nfor i, frame in enumerate(list_visualize):\n    print(frame[\"frame\"])\n    print(\"Timestep: \", i + 1)\n    print(\"State: \", frame[\"state\"])\n    print(\"action: \", frame[\"action\"])\n    print(\"reward: \", frame[\"reward\"])\n    print(\"Total Reward: \", frame[\"Total Reward\"])\n    # time.sleep(2)","6954faea":"* blue = passenger\n* purple = destination\n* yellow = empty taxi\n* green = full taxi\n* RGBY = location for destination and passanger","7c32a94a":"* taxi row, taxi column, passenger index, destination","861bb929":"Again, we must reset our environment.","a3ae9042":"* reset env and return  random initial state","15732587":"There are 6 discrete deterministic actions:\n    - 0: move south\n    - 1: move north\n    - 2: move east \n    - 3: move west \n    - 4: pickup passenger\n    - 5: dropoff passenger\n    \nFirst column:probability, \nSecond column:next_state, \nThird column:reward, \nFourt column:done"}}