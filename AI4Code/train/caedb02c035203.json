{"cell_type":{"2c816aa5":"code","64df2f1c":"code","c5fc5bac":"code","c0ff821c":"code","c0c994f3":"code","80f023b3":"code","28580378":"code","0b2029a0":"code","43b52a4e":"code","0a32285d":"code","6fa59be8":"code","7ab25896":"code","3538ffad":"code","0dba76b4":"code","1948e716":"code","5f0255af":"code","73a6f880":"code","c02d4e58":"code","3a771100":"code","31fe84b1":"code","0096ad24":"code","8d815123":"code","eed337e7":"code","32fc0587":"code","6b413f2a":"code","b783d7ec":"code","43f99cc3":"code","db4da732":"code","cf5e117f":"code","15088c40":"code","ab1e2ec3":"code","4b976afe":"code","f383a0bb":"markdown","34953112":"markdown","c60b2fa2":"markdown","c10eea68":"markdown"},"source":{"2c816aa5":"import numpy as np # linear algebra\nimport pandas as pd # data processing\/manipulation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LinearRegression\n\nfrom collections import Counter\nimport nltk\nimport seaborn as sns\nimport string\nfrom nltk.corpus import stopwords\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","64df2f1c":"#Importing Data\ndata = pd.read_csv('..\/input\/consumer-reviews-of-amazon-products\/1429_1.csv')\ndata.head()","c5fc5bac":"#34660 columns and 21 columns.\ndata.shape","c0ff821c":"#Checking missing values.\ndata.isnull().sum()","c0c994f3":"review=pd.DataFrame(data.groupby('reviews.rating').size().sort_values(ascending=False).rename('No of Users').reset_index())\nreview.head()","80f023b3":"#Though the four columns below contains very less missing values, it would do no harm in removing NA values.\ndata1 = data[['reviews.rating' , 'reviews.text' , 'reviews.title' , 'reviews.username']]\nfinal = data1.dropna()\nfinal.head()","28580378":"#No NA values\nfact =  final[final[\"reviews.text\"].isnull()]\nfact.head()","0b2029a0":"rating = final[(final['reviews.rating'] == 1) | (final['reviews.rating'] == 5)]\nrating.shape","43b52a4e":"y = rating['reviews.rating']\nx = rating['reviews.text'].reset_index()","0a32285d":"len(y)","6fa59be8":"X = x['reviews.text']\nprint(X)","7ab25896":"print(len(X))","3538ffad":"import nltk\nfrom nltk.corpus import stopwords\nset(stopwords.words('english'))","0dba76b4":"import nltk\nnltk.download('punkt')","1948e716":"import nltk\nnltk.download('wordnet')","5f0255af":"#Lemmatization\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.tokenize import word_tokenize \nlemmatizer = WordNetLemmatizer() \n# lemmatize string \ndef lemmatize_word(text): \n    word_tokens = word_tokenize(text) \n    # provide context i.e. part-of-speech \n    lemmas = [lemmatizer.lemmatize(word, pos ='v') for word in word_tokens] \n    return lemmas \n  \ntext = 'Inexpensive tablet for him to use and learn on, step up from the NABI. He was thrilled with it, learn how to Skype on it already....'\nlemmatize_word(text) ","73a6f880":"import string\nfrom nltk.corpus import stopwords\n# stop=set(stopwords.words('english'))\ndef text_process(text):\n  \n    nopunc = [char for char in text if char not in string.punctuation]\n    nopunc = ''.join(nopunc)\n    \n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","c02d4e58":"import nltk\nnltk.download('stopwords') #To downlaod 'stopwords' in your notebook\nsample_text = (\"Inexpensive tablet for him to use and learn on, step up from the NABI. He was thrilled with it, learn how to Skype on it already....\")\nprint(text_process(sample_text))","3a771100":"from sklearn.feature_extraction.text import CountVectorizer\n\ntransformer = CountVectorizer(analyzer=text_process).fit(X)","31fe84b1":"#The numbers are not count, they are position in sparse vector.\ntransformer.vocabulary_","0096ad24":"print(transformer)","8d815123":"len(transformer.vocabulary_)","eed337e7":"review = X[24]\nbow = transformer.transform([review])\nbow","32fc0587":"print(bow)","6b413f2a":"X = transformer.transform(X)","b783d7ec":"#Lets start training the model\nfrom sklearn.model_selection import train_test_split\n#using 30% of the data for testing, this will be revised once we do not get the desired accuracy\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","43f99cc3":"from sklearn.naive_bayes import MultinomialNB\nnaive = MultinomialNB()\nnaive.fit(X_train, y_train)","db4da732":"pred = naive.predict(X_test)","cf5e117f":"from sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, pred))\nprint('\\n')\n\nprint(classification_report(y_test, pred))\nnaive.score(X_train, y_train)","15088c40":"from sklearn.svm import SVC\nclf = SVC()\nclf.fit(X_train, y_train) \nsvm = clf.predict(X_test)","ab1e2ec3":"from sklearn.metrics import confusion_matrix, classification_report\nprint(confusion_matrix(y_test, pred))\nprint('\\n')\nprint(classification_report(y_test, svm))\nsvm = clf.predict(X_test)\nclf.score(X_train,y_train)","4b976afe":"#Both the models relatively provides better accuracy.\nmethods = [\"Multinomial Naive Bayes\",\"SVM\"]\naccuracy = [0.9839,0.9908]\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(6,8))\nplt.yticks(np.arange(0,100,10))\nplt.ylabel(\"Accuracy %\",fontsize=14)\nplt.xlabel(\"ML Models\",fontsize=14)\nsns.barplot(x=methods, y=accuracy)\nplt.show()","f383a0bb":"# The only significant features needed to train the model.","34953112":"![](https:\/\/cms.qz.com\/wp-content\/uploads\/2019\/03\/amazon-storefront-e1552931998325.jpg?quality=75&strip=all&w=1600&h=900)","c60b2fa2":"Using CountVectorizer and vectorizer to return a vector array.","c10eea68":"# Text Pre-processing\nHere, with the help of NLTK Library, we will be importing stopwords.Then, perform the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Return the cleaned text as a list of words\n    4. Lemmatization \n"}}