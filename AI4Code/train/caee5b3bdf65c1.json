{"cell_type":{"edd5365b":"code","e10ff265":"code","2d53dcb9":"code","4ba4380e":"code","d890429d":"code","2d1580e3":"code","286ed001":"code","e0c902d5":"code","d92ee1d1":"code","d1aedf14":"code","9c7fecd4":"code","06122933":"code","0a669a98":"code","8adbc46e":"markdown","9fc6b1da":"markdown","d26fa0c1":"markdown","732d2eea":"markdown","eb669508":"markdown"},"source":{"edd5365b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\nimport sklearn\nimport sklearn.tree\nimport sklearn.model_selection\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e10ff265":"df = pd.read_csv(\"\/kaggle\/input\/heart-disease-uci\/heart.csv\")\ndf","2d53dcb9":"df.corr()","4ba4380e":"fig = plt.gcf()\nsn.heatmap(df.corr(), annot=True)\nfig.set_size_inches(15,15)","d890429d":"dt = sklearn.tree.DecisionTreeClassifier(criterion=\"entropy\")\nX = df.drop(\"target\", axis=1)\ny = df[\"target\"]\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)","2d1580e3":"dt.fit(X_train, y_train)","286ed001":"y_predict = dt.predict(X_test)","e0c902d5":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\naccuracy_score(y_test,y_predict)","d92ee1d1":"for size in [0.3,0.25,0.2,0.15,0.1,0.05]:\n    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=size)\n    dt.fit(X_train, y_train)\n    y_predict = dt.predict(X_test)\n    print(size, accuracy_score(y_test,y_predict))","d1aedf14":"import sklearn.cluster","9c7fecd4":"km = sklearn.cluster.KMeans(n_clusters=2)","06122933":"X_train = df[:int(0.8*len(X))].drop(\"target\", axis=1)\nX_test = df[int(0.8*len(X)):]\nmodel = km.fit(X_train)","0a669a98":"correct = df[\"target\"][0] == km.labels_[0]\ncount = 0\nfor x, y in X_test.iterrows():\n    result = km.predict([[y[c] for c in cols[:-1]]])\n    if correct:\n        if result == y[cols[-1]]:\n            correct += 1\n    else:\n        if result != y[cols[-1]]:\n            correct += 1\n            \ncorrect\/len(X_test)","8adbc46e":"# K-Means Clustering","9fc6b1da":"## Test multiple splits to avoid overfitting","d26fa0c1":"# Data Analysis","732d2eea":"# Decision Tree Method","eb669508":"In order with target: exang, cp, oldpeak, thalach, ca, slope, thal, sex, age"}}