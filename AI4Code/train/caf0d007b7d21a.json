{"cell_type":{"9f618fb0":"code","f5c372d8":"code","5a448f0d":"code","9a94970a":"code","2ca90e89":"code","538a0914":"code","dd04a432":"code","aab9d540":"code","0a46b891":"code","a5a6d090":"code","1eb4129d":"code","c37a33b5":"code","2be27cf3":"code","0ffa7d16":"code","1e1106dd":"code","2cc554e6":"code","9507e253":"code","f278d894":"code","30b2fe93":"code","f1e07494":"code","20de7a37":"code","2bf62129":"code","7ea050bf":"code","9601f528":"code","ad6fb572":"code","dfcd1534":"code","5dd76bc1":"code","dd6b546c":"code","d9b569b5":"code","3c422285":"code","1c292d4e":"code","8300d234":"code","03e86a2b":"code","c67e27d7":"markdown","23f665df":"markdown","c4e444af":"markdown","28557007":"markdown","3b41f76a":"markdown","dd7c4325":"markdown","e3ba0d57":"markdown","cd4e174c":"markdown","0271d45b":"markdown","16d09b79":"markdown","f090d233":"markdown","48132a2a":"markdown","e696c1e0":"markdown","ca96f971":"markdown","8dc1ec9c":"markdown","6dc40133":"markdown","af8a414c":"markdown","ceea7aa5":"markdown","314c9533":"markdown","34423cc3":"markdown","55c43451":"markdown","a12d2dca":"markdown","74d9142f":"markdown","209ed1d0":"markdown","6b183565":"markdown","cee6d775":"markdown","307ee868":"markdown","8a66ef01":"markdown"},"source":{"9f618fb0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5c372d8":"import pandas as pd\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\ndf = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\")\ndf.tail(5)","5a448f0d":"sn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q1',\n              data = df,\n              order = df['Q1'].value_counts().index)\nplt.show()\n\nprint(df.Q1.value_counts())","9a94970a":"plt.figure(figsize=(15,5))\n\nax = sn.countplot(x=\"Q2\", data=df)\n\nprint(df.Q2.value_counts())\n#Overall female respondent percentage\nprint(4890\/25974*100)","2ca90e89":"# Finding and plotting respondents from each country\nsn.set(style='darkgrid')\nplt.figure(figsize=(10,15))\nsn.countplot(y = 'Q3',\n              data = df,\n              order = df['Q3'].value_counts().index)\nplt.show()\n\nprint(df.Q3.value_counts())","538a0914":"#Visualising distribution of respondents across world map, Geo clustering using folium\nimport folium\nfrom folium.plugins import MarkerCluster\n# loading location data which contains each country\u2019s latitude and longitude, courtsey: @melanieshi0210\nlocation=pd.read_csv('https:\/\/raw.githubusercontent.com\/melanieshi0120\/COVID-19_global_time_series_panel_data\/master\/data\/countries_latitude_longitude.csv')\nlocation.rename(columns = {'name':'Q3'}, inplace = True)\n\n# merge dataframes and convert column to numeric\nmerge=pd.merge(location,df,on='Q3')\nmerge['Time from Start to Finish (seconds)'] = pd.to_numeric(merge['Time from Start to Finish (seconds)'])\n\nworld_map= folium.Map(tiles=\"cartodbpositron\")\nmarker_cluster = MarkerCluster().add_to(world_map)\n#for each coordinate, create circlemarker of user percent\nfor i in range(len(merge)):\n        lat = merge.iloc[i]['latitude']\n        long = merge.iloc[i]['longitude']\n        radius=i\n        popup_text = \"\"\"Q3 : {}<br>\n                    'Time from Start to Finish (seconds)' : {}<br>\"\"\"\n        popup_text = popup_text.format(merge.iloc[i]['Q3'],\n                                   merge.iloc[i]['Time from Start to Finish (seconds)']\n                                   )\n        folium.CircleMarker(location = [lat, long], radius=radius, popup= popup_text, fill =True).add_to(marker_cluster)\n    \n    \nworld_map","dd04a432":"df_In = df[df.Q3 == 'India']\n\ndf_US = df[df.Q3 == 'United States of America']\n\ndf_Jp = df[df.Q3 == 'Japan']\n\ndf_Cn = df[df.Q3 == 'China']\n\n#Gender distribution for specific countries(Top 4)\n\nprint(\"Gender distribution India: \\n\",df_In.Q2.value_counts())\n\nprint(\"\\nGender distribution Japan: \\n\",df_Jp.Q2.value_counts())\n\nprint(\"\\nGender distribution US: \\n\",df_US.Q2.value_counts())\n\nprint(\"\\nGender distribution China: \\n\",df_Cn.Q2.value_counts())","aab9d540":"#Female percentage in data science for top 4 countries\n\nprint(\"female_percentage_In :\", round(1656\/7434*100,2),\"\\n\")\n\nprint(\"female_percentage_Jp :\", round(68\/921*100,2),\"\\n\")\n\nprint(\"female_percentage_US :\", round(606\/2650*100,2),\"\\n\")\n\nprint(\"female_percentage_Cn :\", round(106\/818*100,2),\"\\n\")\n","0a46b891":"#We visualise responses of Q4\n\nprint(df.Q4.value_counts())\nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q4',\n              data = df,\n              order = df['Q4'].value_counts().index)\nplt.show()","a5a6d090":"#Current profession of respondents\n\nprint(df.Q5.value_counts())\nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q5',\n              data = df,\n              order = df['Q5'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\n","1eb4129d":"#Visualising Q6 now \nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q6',\n              data = df,\n              order = df['Q6'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\nprint(df.Q6.value_counts())","c37a33b5":"# We make lists containing all columns containing these questions with multiple parts\n\ndf2 = pd.read_csv(\"\/kaggle\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\",header=None)\n\nQ7 = list(df2.loc[0][7:20])\n\nQ9 = list(df2.loc[0][21:34])\n\nQ10 = list(df2.loc[0][34:51])\n\nQ12 = list(df2.loc[0][52:58])\n\nQ14 = list(df2.loc[0][59:71])\n\n\n\nQ16 = list(df2.loc[0][72:90])\n\nQ17 = list(df2.loc[0][90:102])\n\nQ18 = list(df2.loc[0][102:109])\n\nQ19 = list(df2.loc[0][109:115])\n\nQ10","2be27cf3":"df7 = df[Q7]\n\ndf7.columns = ['Python', 'R', 'SQL', 'C', 'C++', 'Java', 'Javascript', 'Julia', 'Swift', 'Bash', 'MATLAB', 'None', 'Other']\n\nplt.figure(figsize=(10,10))\ndf7.count().sort_values(ascending=True).plot(kind = 'pie');\nplt.show();\nprint(df7.count())","0ffa7d16":"#Visualising Q8 now \nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q8',\n              data = df,\n              order = df['Q8'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\nprint(df.Q8.value_counts())","1e1106dd":"df9 = df[Q9]\n\ndf9.columns = ['Jupyter (JupyterLab, Jupyter Notebooks, etc)',' RStudio','Visual Studio','Visual Studio Code (VSCode)',\n              'PyCharm','Spyder','Notepad++','Sublime Text','Vim \/ Emacs','MATLAB','Jupyter Notebook','None','Other']\n\nplt.figure(figsize=(10,10))\ndf9.count().sort_values(ascending=True).plot(kind = 'pie');\nplt.show();\nprint(df9.count())","2cc554e6":"df10 = df[Q10]\n\ndf10.columns = ['Kaggle Notebooks','Colab Notebooks','Azure Notebooks','Paperspace \/ Gradient','Binder \/ JupyterHub','Code Ocean','IBM Watson Studio',\n              'Amazon Sagemaker Studio Notebooks','Amazon EMR Notebooks','Google Cloud Notebooks (AI Platform \/ Vertex AI)','Google Cloud Datalab',\n              'Databricks Collaborative Notebooks','Zeppelin \/ Zepl Notebooks','Deepnote Notebooks','Observable Notebooks','None','Other']\n\nplt.figure(figsize=(20,10))\ndf10.count().sort_values(ascending=True).plot(kind = 'barh');\nplt.show();\nprint(df10.count())","9507e253":"#Visualising Q11 now \nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q11',\n              data = df,\n              order = df['Q11'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\nprint(df.Q11.value_counts())","f278d894":"\ndf12 = df[Q12]\n\ndf12.columns = ['NVIDIA GPUs ','Google Cloud TPUs ','AWS Trainium Chips ','AWS Inferentia Chips ','None','Other']\n\nplt.figure(figsize=(20,10))\ndf12.count().sort_values(ascending=True).plot(kind = 'line');\nplt.show();\nprint(df12.count())","30b2fe93":"#Visualising Q13 now \nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q13',\n              data = df,\n              order = df['Q13'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\nprint(df.Q13.value_counts())","f1e07494":"# Visualisisng Q14 now\n\ndf14 = df[Q14]\n\ndf14.columns = ['Matplotlib ','Seaborn ','Plotly \/ Plotly Express ','Ggplot \/ ggplot2 ','Shiny ','D3 js ','Altair ',\n               'Bokeh ','Geoplotlib ','Leaflet \/ Folium ','None','Other']\n\nplt.figure(figsize=(20,10))\ndf14.count().sort_values(ascending=True).plot(kind = 'pie');\nplt.show();\nprint(df14.count())","20de7a37":"#Visualising Q15 now \nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q15',\n              data = df,\n              order = df['Q15'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\nprint(df.Q15.value_counts())","2bf62129":"# Visualisisng Q16 now\n\ndf16 = df[Q16]\n\ndf16.columns = ['Scikit-learn ','TensorFlow ','Keras ','PyTorch ','Fast.ai ','MXNet ','Xgboost ','LightGBM ','CatBoost ',\n               'Prophet','H2O 3 ','Caret ','Tidymodels ','JAX ','PyTorch Lightning ','Huggingface ','None','Other']\n\nplt.figure(figsize=(20,10))\ndf16.count().sort_values(ascending=True).plot(kind = 'pie');\nplt.show();\nprint(df16.count())\n","7ea050bf":"# Visualisisng Q17 now\n\ndf17 = df[Q17]\n\ndf17.columns = ['Linear or Logistic Regression','Decision Trees or Random Forests',\n               'Gradient Boosting Machines (xgboost, lightgbm, etc)','Bayesian Approaches','Evolutionary Approaches',\n               'Dense Neural Networks (MLPs, etc)','Convolutional Neural Networks','Generative Adversarial Networks',\n               'Recurrent Neural Networks','Transformer Networks (BERT, gpt-3, etc)','Selected Choice - None',\n               'Selected Choice - Other']\n\nplt.figure(figsize=(20,10))\ndf17.count().sort_values(ascending=True).plot(kind = 'pie');\nplt.show();\nprint(df17.count())\n","9601f528":"# Visualisisng Q18 now\n\ndf18 = df[Q18]\n\ndf18.columns =  ['General purpose image\/video tools (PIL, cv2, skimage, etc)','Image segmentation methods (U-Net, Mask R-CNN, etc)',\n               'Object detection methods (YOLOv3, RetinaNet, etc)',\n               'Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)',\n               'Generative Networks (GAN, VAE, etc)','None','Other']\n\nplt.figure(figsize=(10,10))\ndf18.count().sort_values(ascending=True).plot(kind = 'barh');\nplt.show();\nprint(df18.count())","ad6fb572":"# Visualisisng Q19 now\n\ndf19 = df[Q19]\n\ndf19.columns = [' Word embeddings\/vectors (GLoVe, fastText, word2vec)','Encoder-decorder models (seq2seq, vanilla transformers)',\n               'Contextualized embeddings (ELMo, CoVe)','Transformer language models (GPT-3, BERT, XLnet, etc)',\n               'None','Other']\n\nplt.figure(figsize=(20,10))\ndf19.count().sort_values(ascending=True).plot(kind = 'barh');\nplt.show();\nprint(df19.count())\n\n","dfcd1534":"#Visualising Q20 now \nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q20',\n              data = df,\n              order = df['Q20'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\nprint(df.Q20.value_counts())","5dd76bc1":"#Visualising Q21 now \nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q21',\n              data = df,\n              order = df['Q21'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\nprint(df.Q21.value_counts())","dd6b546c":"#Visualising Q22 now \nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q22',\n              data = df,\n              order = df['Q22'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\nprint(df.Q22.value_counts())","d9b569b5":"# Now we get down to consolidating data for rest of the questions with multiple parts to it\n\nQ24 = list(df2.loc[0][119:127])\n\nQ27A = list(df2.loc[0][129:141])\n\nQ29 = list(df2.loc[0][142:147])\n\nQ30 = list(df2.loc[0][147:155])\n\nQ31 = list(df2.loc[0][155:165])\n\nQ32 = list(df2.loc[0][165:186])\n\nQ34 = list(df2.loc[0][187:204])\n\nQ36 = list(df2.loc[0][205:213])\n\nQ37 = list(df2.loc[0][213:221])\n\nQ38 = list(df2.loc[0][221:233])\n\nQ39 = list(df2.loc[0][233:243])\n\nQ40 = list(df2.loc[0][243:255])\n\nQ42 = list(df2.loc[0][256:268])\n\nQ27B = list(df2.loc[0][268:280])\n\nQ29B = list(df2.loc[0][280:285])\n\nQ30B = list(df2.loc[0][285:293])\n\nQ31B = list(df2.loc[0][293:303])\n\nQ32B = list(df2.loc[0][303:324])\n\nQ34B = list(df2.loc[0][324:341])\n\nQ36B = list(df2.loc[0][341:349])\n\nQ37B = list(df2.loc[0][349:357])\n\nQ38B = list(df2.loc[0][357:369])\n#for example lets see list of all parts for Q38\nQ38B ","3c422285":"df24 = df[Q24]\ndf24.columns = ['Analyze and understand data to influence product or business decisions',\n               'Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data',\n               'Build prototypes to explore applying machine learning to new areas',\n               'Build and\/or run a machine learning service that operationally improves my product or workflows',\n               'Experimentation and iteration to improve existing ML models',\n               'Do research that advances the state of the art of machine learning',\n               'None of these activities are an important part of my role at work','Other']\n\nplt.figure(figsize=(20,10))\ndf24.count().sort_values(ascending=True).plot(kind = 'barh');\nplt.show();\nprint(df24.count())","1c292d4e":"#Visualising Q25 now \nsn.set(style='darkgrid')\nplt.figure(figsize=(10,10))\nsn.countplot(y = 'Q25',\n              data = df,\n              order = df['Q25'].value_counts().index)\nplt.xticks(size = 12)\nplt.show()\n\nprint(df.Q25.value_counts())","8300d234":"print(df_In.Q25.value_counts(),\"\\n\")\n\nprint(df_US.Q25.value_counts(),\"\\n\")\n\nprint(df_Cn.Q25.value_counts(),\"\\n\")\n\nprint(df_Jp.Q25.value_counts(),\"\\n\")","03e86a2b":"#Side by side plotting of India,US and Japan Salary distribution\nsn.set(style='darkgrid')\n\nfig, axs = plt.subplots(ncols=3,figsize=(35,30))\n\nsn.countplot(y = 'Q25',\n              data = df_In,ax=axs[0],\n              order = df_In['Q25'].value_counts().index)\nsn.countplot(y = 'Q25',\n              data = df_US,ax=axs[1],\n              order = df_US['Q25'].value_counts().index)\nsn.countplot(y = 'Q25',\n              data = df_Jp,ax=axs[2],\n              order = df_Jp['Q25'].value_counts().index)","c67e27d7":"**When it comes to Algorithm choice Regression(Linear and Logistic) take first spot with 13853 responses( about 53 %) , followed by a close 11864 for Decision Trees or Random Forests ( about 45 %) followed by Gradient boosting ( about 29 %) and a close 27 % for Convolutional Neural Networks** ","23f665df":"### One look at the dataset and we note each column barring column 1 which is 'Time from Start to Finish (seconds)' contains Questions coded with index 1 to i, Questions with multiple selectable option are further coded with suffix Part_j(1 - j), we will need to do a little data engineering for sure to consolidate Quesitons with multiple parts.\n\n**We will start by plotting individual columns and try to see if we can derive meaningful insights from it**","c4e444af":"**With 6804 entries, about 25 % respondents are students, followed by**\n\n- 3616 Data scientists\n- 2449 Software engineers\n- 2301 Data Analysts","28557007":"#### As we may notice there are total 25974 entries and \n\n- The respondents from India are almost 3 times that of the far second USA and 6 times that of Japan it seems from this dataset.\n\n- India tops with a total 7434, followed by USA with 2650, Japan 921 and China 814. ","3b41f76a":"**Visualising Q7 which has multiple parts to it is slightly tricky, we need to consolidate each of these questions with multiple parts to visualise**","dd7c4325":"**Most of the respondents , about 63 % have never used a TPU, another insightful piece since its a unpenetrated audience for TPUs**","e3ba0d57":"**Kaggle notebooks, Colab Notebooks followed by None( No notebooks) take top 3 spot with 9508, 9793 and 7175 responses, what's insightful is about 27 % of respondents dont use any notebook , hence a potential target audience for Notebook companies.**","cd4e174c":"## This is work in progress, will have more updates continuing from here...","0271d45b":"#### Very clearly visible that about bachelor's and Masters degree level combined have over 20 k entries.","16d09b79":"#### As we may notice, we are able to plot the age group column Q1, with the Question \"What is your Age\" also being plotted on the grid with a count 1, we don't mind that, we get to read the question and visualise the values via the barplot of value counts.\n\n**We also display a table of Age group.**\n\n- We note that age group 25-29 is at top with 4931 entries followed by 18-21 with 4901 and 22-24 with 4694 entries, \n- now that was expected meaning age group 18 - 29 consolidated contain about 50 % of all entries. \n- That means the age group 30 - 70 is also adopting usage of these technologies and thats a great insight, \n- furthermore the age group of 30 - 55 contains about 45 % all all entreis.\n\n**Now we will plot Q2 and visualise for insights**","f090d233":"**","48132a2a":"**Python followed by SQL and C++ with 21861, 10757 and 5335 caounts are the top 3 programming languages freuently used**","e696c1e0":"**Again Python R, SQL with 20213,1445 and 1338 take the top 3 spot as recommended programming languages to learn for beginners**","ca96f971":"**The gender skew is very clearly visible, out of 25974 entreis 20598 are men and 4890 are women, that's about 79 % male respondents**\n\n**We get down to Q3 , which is about the country of respondents**","8dc1ec9c":"**Evidently ML methods has a huge number of new adopters, with 9163 responses ( about 35 %) have been using it for less than 1 year, furthermore 4675 responses ( about 18 % ) use it for 1 - 2 years. ML methods adotion is on the rise in the last 2 years clearly.**","6dc40133":"**This is interesting to note that 1 - 2 employees share Data sceince workload in 3642 cases from our respondents, ironically second spot goes to organisations with 20 + employees in the organisation, this shows disparity in Data science strategy adopted by various organisation, while the ones with small number of emplyees could be experimenting to get hands on experience , teams with 20 + people in all probablity are more mature in terms of adoption of Data Science.**","af8a414c":"**India and US fairs among the top of the list for presence of women in Data Science, they seem to have better than average number of women in Data Science than rest of the world**\n\nNow we get down to Q4 , which is about educational qualification of respondents","ceea7aa5":"**When it comes to Choice of NLP methods, word embeddings with 2644 takes top spot follwed by Transformer language models with 2352 and Encoder-decoder models with 2024 responses**","314c9533":"**When it comes to computer vision Image classification and general purpose networks with 4374 take the top spot, foloowed by Image segmentation methods and object detetction methods with 4374 and 2741** ","34423cc3":"**Matplotlib, Seaborn and Plotly \/ PLotly Express take the top 3 spot with 17596, 12587 and 5779 responses**","55c43451":"**Laptops followed by PC\/Desktop, Cloud computing platform take top 3 spots with 16231,4916 and 2328 responses, what's insightful is that Deeplearning workstations with 814 have a rising adoption.**","a12d2dca":"### We start by setting up coding environment and importing neccessary libraries","74d9142f":"**Computer\/Tech with 4079 followed by Academics\/Education - 3214 and Accounting\/Finance with 1459 take the top 3 spots interms of Current\/last industry respondents belong to**","209ed1d0":"**Now we will try to plot geoclusters of respondents on the worldmap using folium, we will need to assign lat lon data for each country, for that we will use open source information from github with thanks to @@melanieshi0210**","6b183565":"**Scikit-learn tops the chart with 13988(about 53 %) respondents picking it as a regularly used ML framework, Tesnorflow and Keras with 9372 and 7976 responses tale 2 and 3 spot.**","cee6d775":"**Jupyter studio , Visual Studio and Pycharm with 16234, 10041 and 7469 are the top 3 IDEs used by the respondents**","307ee868":"**Nvidia GPUs followed by Google Cloud TPUs AWS Trianim Chips  tale the top the 3 spots, although None is suppsoed to be at top spot with 13235 responses,Meaning about 50 % respondents dont use any specialised hardware.**","8a66ef01":"**Now we will try to find specific data from these geoclusters, uniquely identified by countrynames as given in the dataset**"}}