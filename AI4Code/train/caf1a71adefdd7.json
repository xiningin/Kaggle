{"cell_type":{"5efdab81":"code","5ebc22b7":"code","7a34ccf0":"code","4b6ba8ac":"code","6e2c76e3":"code","23a92350":"code","45b91308":"code","8e57b49e":"code","5f9cc644":"code","f0cf35cd":"code","27670724":"code","1e46126e":"markdown","3811f2cf":"markdown","0ac2ba44":"markdown","ec674833":"markdown","a872997f":"markdown","a78533ff":"markdown","163ae566":"markdown","cba22181":"markdown","8b7eebcd":"markdown","bfcbb86a":"markdown","48f13142":"markdown","14067c24":"markdown","f72fa60f":"markdown"},"source":{"5efdab81":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom tensorflow.keras import layers, models\n\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing import sequence, text\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport seaborn as sns","5ebc22b7":"df = pd.read_csv('..\/input\/spam-and-ham\/spam.csv', delimiter = ',', encoding = 'latin-1')\ndf.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\ndf.head()","7a34ccf0":"sns.countplot(df.v1)\nplt.xlabel('Label')\nplt.title('Number of ham and spam messages')","4b6ba8ac":"X = df.v2\ny = df.v1\nle = LabelEncoder()\ny = le.fit_transform(y)\ny = y.reshape(-1, 1)","6e2c76e3":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15)","23a92350":"max_words = 1000\nmax_len = 150\ntokens = text.Tokenizer(num_words = max_words)\ntokens.fit_on_texts(X_train)\ntrain_sequences = tokens.texts_to_sequences(X_train)\ntrain_sequences_matrix = sequence.pad_sequences(train_sequences, maxlen = max_len)\ntest_sequences = tokens.texts_to_sequences(X_test)\ntest_sequences_matrix = sequence.pad_sequences(test_sequences, maxlen = max_len)","45b91308":"lstm_model = models.Sequential()\nlstm_model.add(layers.Input(shape = [max_len]))\nlstm_model.add(layers.Embedding(max_words,50,input_length=max_len))\nlstm_model.add(layers.LSTM(64))\nlstm_model.add(layers.Dense(256, activation = 'relu'))               \nlstm_model.add(layers.Dropout(0.5))               \nlstm_model.add(layers.Dense(1, activation = 'sigmoid'))\nlstm_model.summary()            ","8e57b49e":"lstm_model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(), metrics=['accuracy'])\nhistory = lstm_model.fit(train_sequences_matrix, y_train, batch_size = 128, epochs=10,\n          validation_split = 0.2, callbacks = [EarlyStopping(monitor = 'val_loss', min_delta = 0.0001)])","5f9cc644":"# In[10]: Step 4: Evaluate the model\n\nplt.plot(history.history['accuracy'], label = 'Training_accuracy')\nplt.plot(history.history['val_accuracy'], label = 'Validation_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc = 'lower right')\naccuracy = lstm_model.evaluate(test_sequences_matrix, y_test, verbose = 2)","f0cf35cd":"pred = lstm_model.predict(test_sequences_matrix)\nX_test = np.array(X_test)\n\nprint(\"Predicted Label\", \"\\tTest Data\")\nfor i in range(len(y_test)):\n    p = \"ham\" if (pred[i] < 0.5) else \"spam\"\n    print(p, \"\\t\", X_test[i])\n    # print(p, \"\\t\", y_test[i][0], \"\\t\", X_test[i])","27670724":"# Save the model\nlstm_model.save('.\/saved_model\/')","1e46126e":"### Process the data\n* Tokenize the data and convert the text to sequences.\n* Add padding to ensure that all the sequences have the same shape.\n* There are many ways of taking the *max_len* and here an arbitrary length of 150 is chosen.","3811f2cf":"Evaluate the model on the test set.","0ac2ba44":"The objective of this program is to classify the text sms into the two classes: ham & sam using LSTM.","ec674833":"Understand the distribution better.","a872997f":"### Load the data into Pandas dataframe\nDrop the columns that are not required for the neural network.","a78533ff":"# Classify Text Sms using LSTM","163ae566":"* Create input and output vectors.\n* Process the labels.","cba22181":"# Import the necessary libraries","8b7eebcd":"This program takes the span.csv file as input dataset. The file contains one message per line. Each line is composed by two columns: v1 contains the label (ham or spam) and v2 contains the raw text. The dataset can be downloaded from the link: https:\/\/www.kaggle.com\/uciml\/sms-spam-collection-dataset","bfcbb86a":"Split into training and test data.","48f13142":"### RNN\nDefine the RNN structure.","14067c24":"Compile and Fit on the training data.","f72fa60f":"The model performs well on the validation set and this configuration is chosen as the final model."}}