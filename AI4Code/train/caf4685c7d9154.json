{"cell_type":{"1af0b141":"code","9a7c5ab4":"code","3c8bfdb5":"code","5c18b7bc":"code","eeb7d670":"code","cafcc62c":"code","f2327131":"code","f805f636":"code","2841cbc5":"code","8aa7a9f5":"code","90e6a019":"code","269fa0e8":"code","08a316e1":"code","1f1d006a":"code","dd5fb070":"code","4595d936":"markdown","474f843e":"markdown","7ae24517":"markdown","37e07cc9":"markdown","61c8d4a0":"markdown","934757a9":"markdown","14f55aaf":"markdown"},"source":{"1af0b141":"from tqdm.auto import tqdm\nimport regex\nimport numpy as np \nimport pandas as pd \n\nimport os\n\ntqdm.pandas()\n\nclass_map_csv=\"\/kaggle\/input\/taklagraphemes\/classes.csv\"\ndf=pd.read_csv(\"\/kaggle\/input\/taklagraphemes\/wiki_graphemes.csv\")\ndf=df[[\"unique_words\",\"graphemes\"]]\ndf","9a7c5ab4":"def get_data_frames(class_map_csv):\n    '''\n        reads and creates dataframe for roots,consonant_diacritic,vowel_diacritic and graphemes\n        args:\n            class_map_csv        : path of classes.csv\n        returns:\n            tuple(df_root,df_vd,df_cd)\n            df_root          :     dataframe for grapheme roots\n            df_vd            :     dataframe for vowel_diacritic \n            df_cd            :     dataframe for consonant_diacritic\n            \n    '''\n    # read class map\n    df_map=pd.read_csv(class_map_csv)\n    # get grapheme roots\n    df_root = df_map.groupby('component_type').get_group('grapheme_root')\n    df_root.index = df_root['label']\n    df_root = df_root.drop(columns = ['label','component_type'])\n    # get vowel_diacritic\n    df_vd = df_map.groupby('component_type').get_group('vowel_diacritic')\n    df_vd.index = df_vd['label']\n    df_vd = df_vd.drop(columns = ['label','component_type'])\n    # get consonant_diacritic\n    df_cd = df_map.groupby('component_type').get_group('consonant_diacritic')\n    df_cd.index = df_cd['label']\n    df_cd = df_cd.drop(columns = ['label','component_type'])\n    return df_root,df_vd,df_cd\n\n#------------\n# global ops\n#-----------\ndf_root,df_vd,df_cd=get_data_frames(class_map_csv)\nvds=df_vd.component.tolist()[1:]\ncds=df_cd.component.tolist()[1:]\ncds.remove(\"\u09b0\u09cd\u09af\") # special case\n\nmds=['\u09bc']\nrts=df_root.component.tolist()\n\nchs=[]\nfor root in rts:\n    decomp=[ch for ch in root]\n    if len(decomp)==1:\n        chs.append(decomp[0])\nnms=['\u09e7','\u09e8','\u09e9','\u09ea','\u09eb','\u09ec','\u09ed','\u09ee','\u09ef','\u09e6']\n#------------\n# helpers\n#-----------\ndef clean_word(word):\n    '''\n        cleans a word from any non benglai chars and numbers\n        args:\n            word   :   the word to clean\n        return:\n            a list of decomposed chars\n    '''\n    for num in nms:\n        if num in word:\n            word=word.replace(num,\"\")\n    \n    # this is to filter non-bengali chars\n    decomp=regex.findall(r\"[\\p{Bengali}]\",word)\n    # take care of doubles(consecutive doubles): proposed for vd and cd only \n    for idx,d in enumerate(decomp):\n        # if its not the last one and it is in cd or vd and the next symbol is as same as the current one \n        # remove current symbol    \n        if d in vds+cds and idx<len(decomp)-1 and decomp[idx+1]==d:\n            decomp.remove(d)\n    return decomp\n     ","3c8bfdb5":"def get_root_from_decomp(decomp):\n    '''\n        creates grapheme root based list \n    '''\n    # mod correction\n    for idx,d in enumerate(decomp):\n        if d==mds[0]:\n            if decomp[idx-1] not in vds+cds+mds: \n                decomp[idx-1]=decomp[idx-1]+mds[0]\n    for idx,d in enumerate(decomp):\n        if d==mds[0]:\n            del decomp[idx]\n            \n    # map roots\n    connector= '\u09cd'\n    add=0\n    '''\n    # insert nan for absurd begining\n    if decomp[0] in vds+cds+mds:\n        decomp.insert(0,np.nan)\n    \n    '''\n    if connector in decomp:\n        # remove ending connector as it has no value\n        while decomp[-1]==connector:\n            decomp=decomp[:-1]\n            add=1\n        # remove middle connectors \n        for idx,d in enumerate(decomp):\n            if d==connector:\n                if decomp[idx-1] in vds+cds or decomp[idx+1] in vds+cds:\n                    del decomp[idx]\n                elif decomp[idx-1]+connector in rts:\n                    decomp[idx-1]=decomp[idx-1]+connector\n                    del decomp[idx]   \n        c_idxs = [i for i, x in enumerate(decomp) if x == connector]\n        # component wise index map    \n        comps=[[cid-1,cid,cid+1] for cid in c_idxs ]\n        # merge multi root\n        r_decomp = []\n        while len(comps)>0:\n            first, *rest = comps\n            first = set(first)\n\n            lf = -1\n            while len(first)>lf:\n                lf = len(first)\n\n                rest2 = []\n                for r in rest:\n                    if len(first.intersection(set(r)))>0:\n                        first |= set(r)\n                    else:\n                        rest2.append(r)     \n                rest = rest2\n\n            r_decomp.append(sorted(list(first)))\n            comps = rest\n        # add    \n        combs=[]\n        for ridx in r_decomp:\n            comb=''\n            for i in ridx:\n                comb+=decomp[i]\n            combs.append(comb)\n            for i in ridx:\n                decomp[i]=comb\n                \n        # new root based decomp\n        new_decomp=[]\n        for i in range(len(decomp)-1):\n            if decomp[i] not in combs:\n                new_decomp.append(decomp[i])\n            else:\n                if decomp[i]!=decomp[i+1]:\n                    new_decomp.append(decomp[i])\n\n        new_decomp.append(decomp[-1])#+add*connector\n        \n        return new_decomp\n    else:\n        return decomp\n\ndef get_graphemes_from_decomp(decomp):\n    '''\n        create graphemes from decomp\n    '''\n    graphemes=[]\n    idxs=[]\n    for idx,d in enumerate(decomp):\n        if d not in vds+cds+mds:\n            idxs.append(idx)\n    idxs.append(len(decomp))\n    for i in range(len(idxs)-1):\n        sub=decomp[idxs[i]:idxs[i+1]]\n        grapheme=''\n        for s in sub:\n            grapheme+=s\n        graphemes.append(grapheme)\n    return graphemes\n\n#-----------\n# ops\n#-----------\ndef word2grapheme(word,verbose=False,return_root=False):\n    '''\n        creates grapheme list for a given word\n    '''\n    decomp=clean_word(word)\n    if verbose:\n        print(\"decomp(list):\",decomp)\n    decomp=get_root_from_decomp(decomp)\n    if verbose:\n        print(\"root construction:\",decomp)\n    if return_root:\n        for d in decomp:\n            if d in cds+vds+mds:\n                decomp.remove(d)\n        return decomp\n    else:\n        graphemes=get_graphemes_from_decomp(decomp)\n        return graphemes\n","5c18b7bc":"print(\"graphemes:\",word2grapheme(\"\u0995\u09b0\u09c7\u09a8\u09a8\u09ac\u09c0\u09a8\u099a\u09a8\u09cd\u09a6\u09cd\u09b0\",verbose=True))","eeb7d670":"def filter_df_word(word):\n    dec=[ch for ch in word]\n    if dec[-1]=='\u09cd':\n        return np.nan\n    else:\n        return word\ndf.unique_words=df.unique_words.progress_apply(lambda x: filter_df_word(x))\ndf.dropna(inplace=True)\n\n\ndef filter_df_word(word):\n    if word[0] in vds+cds+mds+['\u09cd']:\n        return np.nan\n    else:\n        return word\n    \n    \ndf[\"unique_words\"]=df.unique_words.progress_apply(lambda x: filter_df_word(x))\ndf.dropna(inplace=True)\n\ndef filter_df_word(word):\n    decomp=[ch for ch in word]\n    \n    if '\u09cd' in decomp:\n        # remove middle connectors \n        for idx,d in enumerate(decomp):\n            if d=='\u09cd':\n                if decomp[idx-1] in vds+cds or decomp[idx+1] in vds+cds:\n                    return np.nan\n                \n        return word\n    else:\n        return word\n    \n    \ndf[\"unique_words\"]=df.unique_words.progress_apply(lambda x: filter_df_word(x))\ndf.dropna(inplace=True)\n\n\ndf","cafcc62c":"df[\"mod_graphemes\"]=df.unique_words.progress_apply(lambda x: word2grapheme(x))\ndf","f2327131":"from ast import literal_eval\ndf.graphemes=df.graphemes.progress_apply(lambda x: literal_eval(x))\ndf","f805f636":"df[\"mod_roots\"]=df.unique_words.progress_apply(lambda x: word2grapheme(x,return_root=True))\ndf","2841cbc5":"all_roots=[]\nfor rt_list in tqdm(df.mod_roots):\n    all_roots+=rt_list\nall_roots=list(set(all_roots))\nprint(len(all_roots))","8aa7a9f5":"new_roots=list(set(all_roots)^set(rts))\nprint(len(new_roots))","90e6a019":"df_nrts=pd.DataFrame({\"new_roots\":new_roots})\ndf_nrts","269fa0e8":"df[\"mismatch\"]=df.progress_apply(lambda x: np.nan if x[\"graphemes\"]==x[\"mod_graphemes\"] else 0,axis=1)\ndfm=df.dropna()\ndfm","08a316e1":"dfm.to_csv(\"mismatch.csv\",index=False)","1f1d006a":"decCheck=[ch for ch in \"\u09b9\u09a4\u09be\u09c7\"]\ndecCheck=decCheck[2:]\ndecCheck","dd5fb070":"for word in df.unique_words.tolist():\n    dec=[ch for ch in word]\n    for idx,d in enumerate(dec):\n        if idx<len(dec)-1 and d ==decCheck[0] and dec[idx+1]==decCheck[1]:\n            print(word)\n            ","4595d936":"# Graphemes Generated based on addition approach\n* [source](https:\/\/www.kaggle.com\/nazmuddhohaansary\/dataanalysis)\n* [original](https:\/\/www.kaggle.com\/reasat\/word2grapheme?scriptVersionId=56816880)","474f843e":"# Convert String list to list","7ae24517":"# Modified word2Grapheme\n* **root construction approach**: construct roots and add them with mods","37e07cc9":"Example","61c8d4a0":"# Determine Mismatches","934757a9":"# Roots","14f55aaf":"# MOD graphemes (wrong constructions\/ mismatching)"}}