{"cell_type":{"ee86780a":"code","2ec2df58":"code","f56b2a85":"code","801c89bb":"code","4282f9b2":"code","cdfc4b6d":"code","2e6649f0":"code","4e3c9895":"markdown","25a2fe70":"markdown"},"source":{"ee86780a":"# \u4fdd\u5b58\u56fe\u7247\uff0c\u6bcf\u4e2aepoch\u90fd\u4f1a\u68c0\u6d4b\u5f53\u524d\u751f\u6210\u5668\u6548\u679c\nimport os\nos.mkdir(\".\/temp1\")\n\n","2ec2df58":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutil\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline","f56b2a85":"image_size = 28\ninput_dim = 100\nnum_channels = 1\nnum_features = 64\nbatch_size = 64\n\nuse_cuda = torch.cuda.is_available()\n\ndtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\nitype = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n\ntrain_dataset = dsets.MNIST(root = \".\/data\",\n                            train = True,\n                            transform = transforms.ToTensor(),\n                            download = True)\n\ntest_dataset = dsets.MNIST(root = \".\/data\",\n                           train = False,\n                           transform = transforms.ToTensor())\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                           batch_size = batch_size,\n                                           shuffle = True)\n\nindices = range(len(test_dataset))\nindices_val = indices[:5000]\nindices_test = indices[5000:]\n\nsampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\nsampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n\nvalidation_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                                batch_size = batch_size,\n                                                sampler = sampler_val)\n\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                          batch_size = batch_size,\n                                          sampler = sampler_test)","801c89bb":"class ModelG(nn.Module):\n    def __init__(self):\n        super(ModelG, self).__init__()\n        self.model = nn.Sequential() #model\u4e3a\u4e00\u4e2a\u5185\u5d4c\u7684\u5e8f\u5217\u5316\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\n        \n        # \u5229\u7528add_module\u589e\u52a0\u4e00\u4e2a\u53cd\u5377\u79ef\u5c42\uff0c\u8f93\u5165\u4e3ainput_dim\u7ef4\uff0c\u8f93\u51fa\u4e3a2*num_features\u7ef4\uff0c\u7a97\u53e3\u5927\u5c0f\u4e3a5\uff0cpadding\u662f0\n        # \u8f93\u5165\u56fe\u50cf\u5927\u5c0f\u4e3a1\uff0c\u8f93\u51fa\u56fe\u50cf\u5927\u5c0f\u4e3aW'=(W-1)S-2P+K+P'=(1-1)*2-2*0+5+0=3, 5*5\n        self.model.add_module('deconv1',nn.ConvTranspose2d(input_dim, num_features*2, 5, 2, 0, bias=False))\n        self.model.add_module('bnorm1',nn.BatchNorm2d(num_features*2))\n        self.model.add_module('relu1',nn.ReLU(True))\n        # \u589e\u52a0\u7b2c\u4e8c\u5c42\u53cd\u5377\u79ef\u5c42\uff0c\u8f93\u51652*num_features\u7ef4\uff0c\u8f93\u51fanum_features\u7ef4\uff0c\u7a97\u53e35\uff0cpadding=0\n        # \u8f93\u5165\u56fe\u50cf\u5927\u5c0f\u4e3a5\uff0c\u8f93\u51fa\u56fe\u50cf\u5927\u5c0f\u4e3aW'=(W-1)S-2P+K+P'=(5-1)*2-2*0+5+0=13, 13*13\n        self.model.add_module('deconv2',nn.ConvTranspose2d(num_features*2, num_features, 5, 2, 0, bias=False))\n        self.model.add_module('bnorm2', nn.BatchNorm2d(num_features))\n        self.model.add_module('relu2',nn.ReLU(True))\n        # \u589e\u52a0\u7b2c\u4e8c\u5c42\u53cd\u5377\u79ef\u5c42\uff0c\u8f93\u51652*num_features\u7ef4\uff0c\u8f93\u51fanum_features\u7ef4\uff0c\u7a97\u53e34\uff0cpadding=0\n        # \u8f93\u5165\u56fe\u50cf\u5927\u5c0f\u4e3a13\uff0c\u8f93\u51fa\u56fe\u50cf\u5927\u5c0f\u4e3aW'=(W-1)S-2P+K+P'=(13-1)*2-2*0+4+0=28, 28*28\n        self.model.add_module('deconv3',nn.ConvTranspose2d(num_features, num_channels, 4, 2, 0,bias=False))\n        self.model.add_module('sigmoid',nn.Sigmoid())\n        \n    \n    def forward(self, input):\n        output = input\n        for name, module in self.model.named_children():\n            output = module(output)\n        return(output) # 28*28\n    \n    \ndef weight_init(m):\n    #\u6a21\u578b\u53c2\u6570\u521d\u59cb\u5316\uff0e\n    #\u9ed8\u8ba4\u7684\u521d\u59cb\u5316\u53c2\u6570\u5377\u79ef\u6838\u7684\u6743\u91cd\u662f\u5747\u503c\u5927\u6982\u4e3a0\uff0c\u65b9\u5dee\u572810^{-2}. BatchNorm\u5c42\u7684\u6743\u91cd\u5747\u503c\u662f\u5927\u7ea60.5\uff0c\u65b9\u5dee\u57280.2\u5de6\u53f3\n    #\u4f7f\u7528\u5982\u4e0b\u521d\u59cb\u5316\u65b9\u5f0f\u53ef\u4ee5\uff0c\u53ef\u4ee5\u8ba9\u65b9\u5dee\u66f4\u5c0f\uff0c\u4f7f\u5f97\u6536\u655b\u66f4\u5feb\n    class_name=m.__class__.__name__\n    if class_name.find('conv')!=-1:\n        m.weight.data.normal_(0, 0.02)\n    if class_name.find('norm')!=-1:\n        m.weight.data.normal_(1.0,0.02)\ndef make_show(img):\n    # \u5c06\u5f20\u91cf\u53d8\u6210\u53ef\u4ee5\u663e\u793a\u7684\u56fe\u50cf\n    img = img.data.expand(batch_size, 3, image_size, image_size)\n    return img\ndef imshow(inp, title=None, ax=None):\n    # \u5728\u5c4f\u5e55\u4e0a\u7ed8\u5236\u56fe\u50cf\n    if inp.size()[0] > 1:\n        inp = inp.numpy().transpose((1, 2, 0))\n    else:\n        inp = inp[0].numpy()\n    mvalue = np.amin(inp)\n    maxvalue = np.amax(inp)\n    if maxvalue > mvalue:\n        inp = (inp - mvalue)\/(maxvalue - mvalue)\n    ax.imshow(inp)\n    if title is not None:\n        ax.set_title(title)","4282f9b2":"print('Initialized!')\n\nnet = ModelG()\nnet = net.cuda() if use_cuda else net\n\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n\n# \u968f\u673a\u9009\u62e9\u751f\u62100-9\u7684\u6570\u5b57\uff0c\u7528\u4e8e\u6bcf\u4e2a\u5468\u671f\u6253\u5370\u67e5\u770b\u7ed3\u679c\u7528\nsamples = np.random.choice(10, batch_size)\nsamples = torch.from_numpy(samples).type(dtype)\n\n#\u5f00\u59cb\u8bad\u7ec3\nstep = 0\nnum_epochs = 10\nrecord = []\nfor epoch in range(num_epochs):\n    train_loss = []\n    \n    for batch_idx, (data, target) in enumerate(train_loader):\n        # \u6ce8\u610f\u6570\u636e\u4e2d\u7684data\u8f6c\u5316\u4e3a\u4e86\u8981\u9884\u6d4b\u7684target\uff0c\u6570\u636e\u4e2d\u7684target\u5219\u8f6c\u5316\u6210\u4e86\u8f93\u5165\u7ed9\u7f51\u7edc\u7684\u6807\u7b7e\n        target, data = data.clone().detach(), target.clone().detach()\n        if use_cuda:\n            target, data = target.cuda(), data.cuda()\n        #\u5c06\u8f93\u5165\u7684\u6570\u5b57\u6807\u7b7e\u8f6c\u5316\u4e3a\u751f\u6210\u5668net\u80fd\u591f\u63a5\u53d7\u7684(batch_size, input_dim, 1, 1)\u7ef4\u5f20\u91cf\n        data = data.type(dtype)\n        data = data.resize(data.size()[0], 1, 1, 1)\n        data = data.expand(data.size()[0], input_dim, 1, 1)\n        \n        net.train()\n        output = net(data)\n        loss = criterion(output, target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        step += 1\n        \n        if use_cuda:\n            loss = loss.cpu()\n        train_loss.append(loss.data.numpy())\n        \n        if step % 100 == 0:\n            net.eval()\n            val_loss = []\n            \n            idx = 0\n            for (data, target) in validation_loader:\n                target, data = data.clone().detach(), target.clone().detach()\n                idx += 1\n                if use_cuda:\n                    target, data = target.cuda(), data.cuda()\n                data = data.type(dtype)\n                data = data.resize(data.size()[0], 1, 1, 1)\n                data = data.expand(data.size()[0], input_dim, 1, 1)\n                output = net(data)\n                loss = criterion(output, target)\n                if use_cuda:\n                    loss = loss.cpu()\n                val_loss.append(loss.data.numpy())\n            print('\u8bad\u7ec3\u5468\u671f\uff1a{} [{}\/{} ({:.0f}%)]\\t\u8bad\u7ec3\u6570\u636eLoss: {:.6f}\\t\u6821\u9a8c\u6570\u636eLoss: {:.6f}'.format(\n                epoch, batch_idx * batch_size, len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), np.mean(train_loss), np.mean(val_loss)))\n            record.append([np.mean(train_loss), np.mean(val_loss)])\n            \n            \n    # \u4ea7\u751f\u4e00\u7ec4\u56fe\u50cf\u4fdd\u5b58\u5230temp1\u6587\u4ef6\u5939\u4e0b\uff08\u9700\u8981\u4e8b\u5148\u5efa\u7acb\u597d\u8be5\u6587\u4ef6\u5939\uff09\uff0c\u68c0\u6d4b\u751f\u6210\u5668\u5f53\u524d\u7684\u6548\u679c\n    # \u6539\u53d8\u8f93\u5165\u6570\u5b57\u7684\u5c3a\u5bf8\uff0c\u9002\u5e94\u4e8e\u751f\u6210\u5668\u7f51\u7edc\n    samples.resize_(batch_size, 1, 1, 1)\n    samples = samples.data.expand(batch_size, input_dim, 1, 1)\n    samples = samples.cuda() if use_cuda else samples\n    fake_u = net(samples)\n    fake_u = fake_u.cpu() if use_cuda else fake_u\n    img = make_show(fake_u) #\u5c06\u5f20\u91cf\u8f6c\u5316\u6210\u53ef\u7ed8\u5236\u7684\u56fe\u50cf\n    vutil.save_image(img,'temp1\/fake%s.png' % (epoch))","cdfc4b6d":"plt.figure(figsize = (10, 7))\nplt.plot([i[0] for i in record], label='Training')\nplt.plot([i[1] for i in record], label='Validation')\nplt.xlabel('Batchs')\nplt.ylabel('Loss')\nplt.legend()","2e6649f0":"# \u7ed8\u5236\u4e00\u6279\u56fe\u50cf\u6837\u672c\nfake_u = fake_u.cpu() if use_cuda else fake_u\nsamples = samples.cpu() if use_cuda else samples\nimg = fake_u.data\nfig = plt.figure(figsize = (15, 15))\n\nf, axarr = plt.subplots(8, 8, sharex=True, figsize=(15, 15))\nfor i in range(batch_size):\n    \n    axarr[i \/\/ 8, i % 8].axis('off')\n    imshow(img[i],\n           samples.data.numpy()[i][0, 0, 0].astype(int),\n           axarr[i \/\/ 8, i % 8])","4e3c9895":"# \u955c\u50cf\u4e0e\u732b\u9f20\u6e38\u620f\u2014\u2014\u53cd\u5377\u79ef\u751f\u6210\u7f51\u7edc\u4e0eDCGAN\n\n\u672c\u6587\u4ef6\u662f\u96c6\u667aAI\u5b66\u56ed\u5f00\u53d1\u7684\u201c\u706b\u70ac\u4e0a\u7684\u6df1\u5ea6\u5b66\u4e60\u201d\u7cfb\u5217\u8bfe\u7a0b\u7b2c\u4e94\u8282\u8bfe\uff1a\u300a\u955c\u50cf\u7f51\u7edc\u4e0e\u732b\u9f20\u6e38\u620f\u300b\u7684\u914d\u5957\u6587\u6863\u3002\u5728\u672c\u6587\u6863\u4e2d\uff0c\u6211\u4eec\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53cd\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u751f\u6210\u5668\uff0c\u5b83\u53ef\u4ee5\u901a\u8fc7\u8f93\u5165\u7684\u4fe1\u53f7\uff0c\u751f\u6210\u4e00\u5f20\u903c\u771f\u7684\u624b\u5199\u6570\u5b57\u56fe\u50cf\u3002\u4e3a\u4e86\u8ba9\u6211\u4eec\u7684\u751f\u6210\u56fe\u50cf\u80fd\u591f\u8db3\u591f\u903c\u771f\uff0c\u6211\u4eec\u5c1d\u8bd5\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u65b9\u6cd5\uff1a\n\n1\u3001\u5728MINST\u6570\u636e\u96c6\u4e2d\uff0c\u9009\u51fa\u4e00\u4e2a\u6837\u672c\uff0c\u8f93\u5165\u6570\u5b57\u6807\u7b7e\uff0c\u8f93\u51fa\u56fe\u50cf\uff0c\u5e76\u8ba9\u8f93\u51fa\u7684\u56fe\u50cf\u4e0e\u6837\u672c\u56fe\u50cf\u5c3d\u53ef\u80fd\u76f8\u4f3c\uff0c\u603b\u8bef\u5dee\u6700\u5c0f\u5316\uff1b\n2\u3001\u540c\u4e0a\uff0c\u53ea\u4e0d\u8fc7\u5e76\u4e0d\u76f4\u63a5\u6bd4\u8f83\u8f93\u51fa\u548c\u6837\u672c\u76f8\u4f3c\u6027\uff0c\u800c\u662f\u8ba9\u4e00\u4e2a\u5df2\u8bad\u7ec3\u597d\u7684\u624b\u5199\u6570\u5b57\u8bc6\u522b\u7f51\u7edc\u6765\u5224\u65ad\u8fd9\u4e2a\u4f2a\u9020\u7684\u56fe\u50cf\u662f\u51e0\uff1b\n3\u3001DCGAN\uff0c\u540c\u65f6\u8bad\u7ec3\u4e00\u4e2a\u751f\u6210\u5668\u4e00\u4e2a\u5224\u522b\u5668\u3002\u6bcf\u4e2a\u65f6\u523b\u968f\u673a\u91c7\u6837\u4e00\u4e2a\u5411\u91cf\u8f93\u5165\u7ed9\u751f\u6210\u5668\uff0c\u5b83\u8f93\u51fa\u4e00\u5f20\u56fe\u50cf\uff0c\u540c\u65f6\u8bfb\u53d6\u4e00\u4e2a\u6570\u636e\u6837\u672c\uff0c\u5224\u522b\u5668\u5224\u65ad\u6837\u672c\u56fe\u50cf\n\u548c\u751f\u6210\u56fe\u50cf\u7684\u771f\u5047\u3002","25a2fe70":"## \u4e00\u3001\u751f\u6210\u5668\u9884\u6d4b\u56fe\u50cf\u6a21\u578b\n\n\u5728\u8fd9\u4e2a\u6a21\u578b\u4e2d\uff0c\u6211\u4eec\u6839\u636e\u8f93\u5165\u7684\u624b\u5199\u6570\u5b57\u751f\u6210\u4e00\u5f20\u56fe\u50cf\uff0c\u5e76\u8ba9\u8fd9\u4e2a\u56fe\u50cf\u4e0e\u6570\u636e\u4e2d\u7684\u6837\u672c\u56fe\u50cf\u5c3d\u53ef\u80fd\u4e00\u81f4"}}