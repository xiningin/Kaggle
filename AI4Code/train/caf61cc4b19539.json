{"cell_type":{"0e380eff":"code","4fb4b298":"code","8591f04f":"code","815fc6b4":"code","24d41661":"code","b458466f":"code","94e04bcd":"code","ba649a53":"code","cf4ecce5":"code","0b7bc2c6":"code","04c2f3c9":"code","1623b749":"code","524a7f34":"code","fbfad353":"code","5e92c424":"code","0e19eda3":"code","f0d64df1":"code","8b5d0b5a":"code","650b506a":"code","99107b02":"code","647b0140":"code","4baaf8b8":"code","1cb4d65e":"code","a0377fcc":"code","700c28b6":"code","cf9f15e4":"code","568ff709":"code","5dd9ddce":"code","654698a0":"code","ad262da7":"code","7965e5cd":"code","c6a02945":"code","c6887120":"code","423f1884":"code","a71ceafd":"code","11bf215b":"code","a9bb6da0":"code","2d61463e":"code","519134da":"code","e1709e75":"code","439bff57":"code","628b59c5":"markdown","5e1be87d":"markdown","517372e6":"markdown","bb877d95":"markdown","904d5051":"markdown","4ea89513":"markdown","67dc073e":"markdown","e2522041":"markdown","dbf17510":"markdown","5d2d18e3":"markdown","93e43372":"markdown","514dcea6":"markdown","03994a58":"markdown","ec62d7fb":"markdown","99c4d07d":"markdown","81f0ece0":"markdown","67058d00":"markdown","593e05dd":"markdown","cf051f73":"markdown","0732a4ba":"markdown","59a82f8e":"markdown","39056316":"markdown","c6210e75":"markdown","5a81d2eb":"markdown"},"source":{"0e380eff":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import GridSearchCV\n\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.ensemble import StackingRegressor","4fb4b298":"## Load 100k rows only\ndata = pd.read_csv(\"\/kaggle\/input\/new-york-city-taxi-fare-prediction\/train.csv\", nrows=100_000, parse_dates=['pickup_datetime'])\n","8591f04f":"print(data.shape)\nprint(data.info())","815fc6b4":"data.head()","24d41661":"data.describe()","b458466f":"data[data.fare_amount<100].fare_amount.hist(bins=100, figsize=(14,3))\nplt.xlabel('fare $USD')\nplt.title('Histogram');","94e04bcd":"from math import sin, cos, sqrt, atan2, radians\n\ndef calculateDistance(lt1, ln1, lt2, ln2):\n\n    # approximate radius of earth in km\n    R = 6373.0\n\n    lat1 = radians(lt1)\n    lon1 = radians(ln1)\n    lat2 = radians(lt2)\n    lon2 = radians(ln2)\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = sin(dlat \/ 2)**2 + cos(lat1) * cos(lat2) * sin(dlon \/ 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n\n    distance = R * c * 1000\n    \n    return distance","ba649a53":"def featureCleanup(dfOrig, train = True):\n    if(train):\n        df = dfOrig[dfOrig['fare_amount'] >= 0]\n    else:\n        df = dfOrig.copy()\n        \n    df['weekday'] = df['pickup_datetime'].dt.day_name()\n    df['pickup_hour'] = df['pickup_datetime'].dt.hour\n    df['pickup_time'] = df['pickup_datetime'].dt.hour + df['pickup_datetime'].dt.minute\/60\n    \n    df['distance'] = df.apply(lambda x: \n                              calculateDistance(x['pickup_latitude'], \n                                                x['pickup_longitude'],\n                                                x['dropoff_latitude'],\n                                                x['dropoff_longitude']), \n                              axis=1)\n    \n    df.drop(columns = ['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude','pickup_datetime','key'], \n          inplace = True)\n    \n    if(train):\n        df.dropna(\n            axis=0,\n            how='any',\n            thresh=None,\n            subset=None,\n            inplace=True\n        )\n\n        df = df[df['distance'] > 0]\n    \n    return df","cf4ecce5":"trainData = featureCleanup(data)","0b7bc2c6":"trainData.head()","04c2f3c9":"def plotChart(df, x, y, title, num):\n    plt.subplot(5, 2, num)\n    sns.lineplot(data = df, x= x, y = y)\n    plt.title(title)\n    #plt.xticks(rotation = 90)\n    plt.legend(loc='upper right')","1623b749":"plt.figure(figsize  = (15,30))\nplotChart(trainData.groupby(by=\"weekday\").mean().reset_index(), 'weekday', 'fare_amount', 'weekday vs fare', 1)\nplotChart(trainData.groupby(by=\"weekday\").mean().reset_index(), 'weekday', 'distance', 'weekday vs distance', 2)\nplotChart(trainData.groupby(by=\"pickup_hour\").mean().reset_index(), 'pickup_hour', 'fare_amount', 'hour vs fare', 3)\nplotChart(trainData.groupby(by=\"distance\").mean().reset_index(), 'distance', 'fare_amount', 'distance vs fare', 4)","524a7f34":"plt.figure(figsize  = (20,40))\nfor i in enumerate(trainData.columns.drop(['fare_amount', 'distance', 'pickup_time'])):\n    plt.subplot(10, 2, i[0]+1)\n    sns.countplot(trainData[i[1]])\n","fbfad353":"trainData.drop(columns=['pickup_hour'], inplace=True)\ntrainData['weekday'] = trainData['weekday'].map({\"Monday\": 1, \"Tuesday\": 2, \"Wednesday\": 3, \"Thursday\": 4, \"Friday\": 5, \"Saturday\": 6, \"Sunday\": 7})","5e92c424":"y_train = trainData.pop('fare_amount')\nX_train = trainData","0e19eda3":"X_train.head()","f0d64df1":"params = {\n    'max_depth': [4,5,6,7,8,9,10]\n}","8b5d0b5a":"# Instantiate the grid search model\n\ndt = DecisionTreeRegressor(random_state=100)\n\ngrid_search = GridSearchCV(estimator=dt, param_grid = params, \n                          cv=4, n_jobs=-1, verbose=1)","650b506a":"grid_search.fit(X_train, y_train)\ngrid_search.best_estimator_","99107b02":"y_train_predict = grid_search.predict(X_train)\nprint(\"Decision Tree Accuracy:\", round(r2_score(y_train, y_train_predict)*100, 2), \"%\")","647b0140":"rfEstimator = RandomForestRegressor(random_state=42)\npara_grids = {\n            \"n_estimators\" : [50],\n            \"max_depth\": [6,7,8],\n            'max_features': [2,3,4]\n        }","4baaf8b8":"grid_rf = GridSearchCV(rfEstimator, para_grids, verbose=1, n_jobs=-1, cv=5)\ngrid_rf.fit(X_train, y_train)\ngrid_rf.best_estimator_","1cb4d65e":"y_train_pred_rf = grid_rf.predict(X_train)\nprint(\"Random Forest Accuracy:\", round(r2_score(y_train, y_train_pred_rf)*100, 2), \"%\")","a0377fcc":"xg_reg = xgb.XGBRegressor(n_jobs=-1)","700c28b6":"xg_reg.fit(X_train,y_train)","cf9f15e4":"from sklearn import metrics\n\ny_train_pred_xg = xg_reg.predict(X_train)\ny_train_pred_xg","568ff709":"print(\"XGBoost Accuracy:\", round(r2_score(y_train, y_train_pred_xg)*100, 2), \"%\")","5dd9ddce":"para_grids = {\n            \"n_estimators\": [100,200],\n            \"learning_rate\": [0.3,0.4,0.5],\n            \"max_depth\": [6,7,8]\n        }\n\ngrid_xg = GridSearchCV(xg_reg, para_grids, verbose=1, n_jobs=-1, cv=4)\ngrid_xg.fit(X_train, y_train)\ngrid_xg.best_estimator_","654698a0":"y_train_pred_xg_cv = grid_xg.predict(X_train)\ny_train_pred_xg_cv","ad262da7":"print(\"XGBoost Accuracy after Hyperparameter tuning:\", round(r2_score(y_train, y_train_pred_xg_cv)*100, 2), \"%\")","7965e5cd":"xgb.plot_tree(grid_xg.best_estimator_,num_trees=0)\nplt.show()","c6a02945":"base_learners = [\n                 ('es1', xg_reg),\n                 ('es2', grid_rf.best_estimator_)     \n                ]","c6887120":"stregr = StackingRegressor(estimators=base_learners, cv=4,n_jobs=1,verbose=1)","423f1884":"stregr.fit(X_train, y_train)","a71ceafd":"y_predict_stack_reg = stregr.predict(X_train)","11bf215b":"print(\"Accuracy:\", round(r2_score(y_train, y_predict_stack_reg)*100, 2), \"%\")","a9bb6da0":"test = pd.read_csv(\"\/kaggle\/input\/new-york-city-taxi-fare-prediction\/test.csv\", parse_dates=['pickup_datetime'])\n\ntestData = featureCleanup(test, False)\n","2d61463e":"testData.head()","519134da":"testData.drop(columns=['pickup_hour'], inplace=True)\ntestData['weekday'] = testData['weekday'].map({\"Monday\": 1, \"Tuesday\": 2, \"Wednesday\": 3, \"Thursday\": 4, \"Friday\": 5, \"Saturday\": 6, \"Sunday\": 7})","e1709e75":"y_test_pred_xg_cv = grid_xg.predict(testData)\ny_test_pred_xg_cv","439bff57":"test['fare_amount_predicted'] = y_test_pred_xg_cv\ntest.head()","628b59c5":"## Outliers Detection\n- There are outliers in the dataset but it will not impact on ML models based on decision tree.\n- Outlier detection and treatment are not required here.","5e1be87d":"## XGBoost accuracy 85.46% is much higher than Random Forest which proves that XGBoost is the best in predicting the New York Taxi fares","517372e6":"## Accuracy didn't change even after Hyperparameter tuning, that means XGBoost is really predicting well with high level of accuracy on its own.","bb877d95":"# Exploratory Data Analysis","904d5051":"## Hyperparameter Tuning for Decision Trees\n- Max depth need to be set in order to avoid over fitting\n- select multiple max_depth from 4 to 10 to identity the best max_depth\n- Other parameters like max_sample_split etc can also be set, but its taking a lot of time to fit the data","4ea89513":"## New York Taxi fare Prediction\n\n- Decision Tree, Random Forest and XGBoost Regression technique to predict the taxi fare\n- Train data is huge so we will be taking only sample of data (100k records) for building the model\n- Result will improve if increase the train size and do some Hyperparameter tuning with cross validation. Due to memory issue in Kaggle environment, chose to go with only 100k records.\n\n## Steps Taken to build the model\n- Load the data \/ Cleanup the data\n- Feature Engineering\n- Exploratory Data Anaysis\n- Univariate and Bivariate Anaysis\n- Distribution of data\n- Decision Tree for Predict the taxi fare\n- Random Forest for Predicting the taxi fare\n- XGBoost for Predicting the taxi fare\n\n## Result\n- Descision Tree: 77.9 % accuracy\n- Random Forest: 78.4 % accuracy\n- XGBoost: 85.46% accuracy\n\n## Final Result: XGBoost accuracy is 85.46% is much higher than Random Forest and Decision Tree which proves that XGBoost is the best in predicting the New York Taxi fares\n","67dc073e":"## Using Stacking Regressor to check if it improves the accracy\n- use Random Forest and XGBoost together to predict","e2522041":"# Random Forest","dbf17510":"## Hyperparameter Tuning for Random Forest\n- Number of estimator used 50\n- max_depth used 6 to 8 to identify the best depth of the trees\n- max_feature used from 2 to 4 to identify best number of features\n- We can iterate this based on the results and tune the hyperparameter futher to get the optimal values","5d2d18e3":"### Grid Search Cross validation Technique\n- We don't have to split the data (train, test) into two parts because test data is provided seperately\n- So I am using Cross validation technique to validate the model with random validation set\n- cv=4 means 3 part will be used for traning and 1 part will be used for cross validation","93e43372":"# Hyperparameter tuning for XGBoost\n- Note: XGBoost already has inbuilt hyperparameter tuning but we can test it further with cross validation\n- we will try to see if we tune different parameter, do we get the better results or not\n- This Hyperparameter tuning might take around 6-7 mins because it is training with around 72 XGBoost Trees to find the best estimator","514dcea6":"## Decision Tree Result\n- Decision tree has predicted the data with 77.9% accuracy","03994a58":"### Convert Weekday names with numeric numbers\n- ML models always look for numbers not String values so converting weeknames to weeknumber.","ec62d7fb":"### Random forest will create 45 different trees for training the model and will use best tree for prediction","99c4d07d":"### Calculate the distance between two GPS location\n- actual lat long are not useful for modeling\n- we will calculate the distance between two points","81f0ece0":"# Predict the taxi fare for Test Data","67058d00":"## Bivariate Analysis\n- Generally taxi fares are expensive on Sundays \n- Generally people are travelling on Sundays or Wednesday (wednesday has max distance because of an outlier)\n- Taxi fare is maximum during 2AM - 4AM. Midnight Charges ?\n- Outlier causing issue with distance vs fare distribution","593e05dd":"# XGBoost (Extreme Gradient Boosting)\n- This is the best Machine learning Algorithm in today's world\n- The concept of using 100s of weak learner to create a strong learner which makes it special\n- Also it is much much faster than Random Forest and Decision Tree because it is leveraging parallel computations","cf051f73":"## Feature Engineering\n- pickup_datetime will not help much in feature selection\n- We can extract weekday and pickup_time from the pickup_datetime which will be very good feature for prediction\n- Weekday will tell which day has peak day in the month\n- Pickup Time will tell which is a peak hour in a day\n\n## Data Cleanup\n- Remove the rows which have fare amount as negative which doesn't make sense\n- Remove the rows which have distance as <=0\n- Also we will remove all the rows which have nan values","0732a4ba":"# Decision Tree","59a82f8e":"## Random forest accuracy is 78.41 slighly better than Decision Tree Regressor 77.9%\n","39056316":"## Univariate Analysis\n- Single passenger Taxi hire has maximum trend, hiring taxi from office to home ?\n- Thurday, Friday and Saturday has maximum taxi hiring count\n- Moderate hour is from 9:00 AM to 5:00 PM\n- Peak hour is from 6:00PM to 9:00PM, leaving from office to home ?","c6210e75":"## Accuracy goes little down if Random Forest and XGBoost stacked together.","5a81d2eb":"## Fare Amount Distribution"}}