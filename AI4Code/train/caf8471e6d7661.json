{"cell_type":{"0bce5957":"code","2a4549cd":"code","266cccf3":"code","e1e0b252":"code","3a4524ac":"code","0ff3684b":"code","d3f08058":"code","dadeab8c":"code","dfe39dc6":"code","4b47da0c":"code","9813ed57":"code","fffee885":"code","06961311":"code","5285c97f":"code","dbff9ac0":"code","c9a3d613":"code","fb3b7c90":"code","60d12292":"code","0b13d00f":"code","1e3c43d6":"code","d1b26473":"code","c1a5d9b1":"code","7ebb8153":"markdown"},"source":{"0bce5957":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","2a4549cd":"# Import raw data\nraw_data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\nraw_data","266cccf3":"# Show the data details\nraw_data.describe()","e1e0b252":"# See the null value\nraw_data.isna().sum().max()","3a4524ac":"# See the number of each class\nraw_data[\"Class\"].value_counts()*100\/len(raw_data) # Imbalance dataset 0: Not fraud, 1: Fraud","0ff3684b":"# Show the imbalance between the number of class via histogram\nsns.countplot(x='Class', data=raw_data)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14);","d3f08058":"# Scale the amount and time column\nfrom sklearn.preprocessing import StandardScaler,RobustScaler\n\nscaler = RobustScaler()\nraw_data[\"Scaled_amount\"] = scaler.fit_transform(raw_data[\"Amount\"].values.reshape(-1,1))\nraw_data[\"Scaled_time\"] = scaler.fit_transform(raw_data[\"Time\"].values.reshape(-1,1))\nraw_data.drop([\"Amount\",\"Time\"],axis=1,inplace=True)\n\nraw_data.head()","dadeab8c":"# Over sampling\nraw_data_0 = raw_data[raw_data[\"Class\"]==0] # Only label 0\nraw_data_1 = raw_data[raw_data[\"Class\"]==1] # Only label 1\ndata_0_count = len(raw_data_0) # Count 0\ndata_1_count = len(raw_data_1) # Count 1\ndata_1 = raw_data_1.sample(data_0_count,replace=True) # Under sampling the data\ndata = pd.concat([raw_data_0, data_1], axis=0,ignore_index=True) # Join the data\ndata","dfe39dc6":"# Show the balance between the number of class via histogram\nsns.countplot(x='Class', data=data)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14);","4b47da0c":"# Correlation matrix\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n\n# Correlation matrix of raw_data\ncorr = raw_data.corr()\nsns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\nax1.set_title(\"Imbalanced Correlation Matrix \\n (don't use for reference)\", fontsize=14)\n\n# Correlation matrix of over sampling data\nsub_sample_corr = data.corr()\nsns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\nax2.set_title('SubSample Correlation Matrix \\n (use for reference)', fontsize=14)\nplt.show()","9813ed57":"f, axes = plt.subplots(ncols=4, figsize=(20,4))\n\nneg_corr = [\"V17\",\"V14\",\"V12\",\"V10\"]\nfor i,v in enumerate(neg_corr,0):\n# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\n    sns.boxplot(x=\"Class\", y=v, data=data, ax=axes[i])\n    axes[i].set_title(f'{v} vs Class Negative Correlation')\n\nplt.show()","fffee885":"f, axes = plt.subplots(ncols=4, figsize=(20,4))\n\npos_corr = [\"V11\",\"V4\",\"V2\",\"V19\"]\nfor i,v in enumerate(pos_corr,0):\n# Positive correlations (The higher the feature the probability increases that it will be a fraud transaction)\n    sns.boxplot(x=\"Class\", y=v, data=data, ax=axes[i])\n    axes[i].set_title(f'{v} vs Class Negative Correlation')\n\nplt.show()","06961311":"from scipy.stats import norm\n\nf, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20, 6))\n\nv14_fraud_dist = data['V14'].loc[data['Class'] == 1].values\nsns.distplot(v14_fraud_dist,ax=ax1, fit=norm, color='#FB8861')\nax1.set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nv12_fraud_dist = data['V12'].loc[data['Class'] == 1].values\nsns.distplot(v12_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\nax2.set_title('V12 Distribution \\n (Fraud Transactions)', fontsize=14)\n\n\nv10_fraud_dist = data['V10'].loc[data['Class'] == 1].values\nsns.distplot(v10_fraud_dist,ax=ax3, fit=norm, color='#C5B3F9')\nax3.set_title('V10 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nplt.show()","5285c97f":"# Over sampling\nX = data.drop(\"Class\",axis=1)\ny = data[\"Class\"]","dbff9ac0":"# Dimensionality Reduction with PCA\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2,random_state=0)\nX_reduced = pca.fit_transform(X)\nX_reduced","c9a3d613":"import matplotlib.patches as mpatches\nf, ax = plt.subplots(1, 1, figsize=(8,6))\n# labels = ['No Fraud', 'Fraud']\nf.suptitle('Clusters using Dimensionality Reduction', fontsize=14)\n\n\nblue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\nred_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n\n# PCA scatter plot\nax.scatter(X_reduced[:,0], X_reduced[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\nax.scatter(X_reduced[:,0], X_reduced[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\nax.set_title('PCA', fontsize=14)\nax.grid(True)\nax.legend(handles=[blue_patch, red_patch]);","fb3b7c90":"# Split the dataset to training and testing\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)","60d12292":"# Classifiers\nfrom sklearn.linear_model import LogisticRegression\n\nclassifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n}\n\nclassifiers_predicted = {\n    \"LogisiticRegression\": None,\n}","0b13d00f":"# Train the model and check the score with test set\nfrom sklearn.model_selection import cross_val_score\n\nfor key, classifier in classifiers.items():\n    classifier.fit(X_train,y_train)\n    classifiers_predicted[key] = classifier.predict(X_test)\n    score = classifier.score(X_test,y_test)\n    print(f\"The accuracy score of {key}: {np.mean(score)*100:.2f}%\")","1e3c43d6":"# Confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\nfor key, predicted in classifiers_predicted.items():\n    print(key+\":\")\n    print(confusion_matrix(y_test,predicted,))\n    print()","d1b26473":"# Classification report\nfrom sklearn.metrics import classification_report\n\nfor key, predicted in classifiers_predicted.items():\n    print(key+\":\")\n    print(classification_report(y_test,predicted,))\n    print()","c1a5d9b1":"# Train the model with cross validation\nfrom sklearn.model_selection import cross_val_score\n\nfor key, classifier in classifiers.items():\n    score = cross_val_score(classifier, X_train, y_train, cv=5)\n    print(f\"The accuracy score of {key}: {np.mean(score)*100:.2f}%\")","7ebb8153":"#### Summary and Explanation:\n\nNegative Correlations: V17, V14, V12 and V10 are negatively correlated. Notice how the lower these values are, the more likely the end result will be a fraud transaction.\n\nPositive Correlations: V2, V4, V11, and V19 are positively correlated. Notice how the higher these values are, the more likely the end result will be a fraud transaction.\n\nBoxPlots: We will use boxplots to have a better understanding of the distribution of these features in fradulent and non fradulent transactions."}}