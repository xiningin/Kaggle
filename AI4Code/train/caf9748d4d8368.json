{"cell_type":{"dad66bf3":"code","fc8799a2":"code","5871ce6c":"code","988a831f":"code","59a77bfb":"code","1bf854d8":"code","dab4bb71":"code","45f76e90":"code","5db841f8":"code","ebee351d":"code","db1e83cc":"code","de05fe0d":"code","e39be453":"code","b9f47df4":"code","55c3b5e7":"code","703ff463":"code","3768fc57":"code","7a598c89":"code","fed4dce6":"code","2939329e":"code","c2679767":"code","4e6a27ca":"code","f033496f":"code","b244572d":"code","d4f26530":"code","f466a9f9":"code","a593218a":"code","87ef4c25":"code","0eca9655":"code","d3f3a870":"code","d6b1e682":"code","4660771e":"code","3e82067f":"code","b76d9477":"code","eee435ff":"code","330bc274":"code","8b40a161":"code","479ffaed":"code","57c54d8a":"code","962fec6f":"code","c4a8c296":"code","26978145":"code","ce9544ce":"code","fc083007":"code","0fb4f358":"code","27f88f10":"code","db0f189f":"code","3102d76a":"code","6ec0385f":"code","2726e757":"code","780441e1":"code","1aca5a1e":"code","582d9113":"code","34a1d682":"code","baf5ed17":"code","915e2b82":"code","2fab5bcf":"code","114d1a24":"code","a549ac95":"code","a3cc978c":"code","930d4bfe":"code","543cde03":"code","d0e95ae7":"code","8e1cb97d":"code","b689cf68":"code","584c2e43":"code","a202e8d9":"code","67160852":"code","9f805118":"code","026ac49c":"code","4088eabc":"code","a270b86d":"code","fb0d5523":"code","509556f1":"code","91d16676":"code","3b87c57b":"code","a3a9f2f5":"code","6d97dd29":"code","9448d617":"code","05bc740b":"code","f10e3445":"code","507655e5":"code","e2adbf75":"code","38681d54":"code","1cf61690":"code","0f80b6ee":"code","6f416a31":"code","e369e588":"code","f55152c2":"code","06cbc536":"code","c5b3baca":"code","19b42999":"code","791bfd95":"code","2885b6ad":"code","e5ac6730":"code","dbdcb436":"code","1cdf37f8":"code","760e3028":"code","cfb31c9b":"code","d586b0d4":"code","cab8caab":"code","ba87aff6":"code","25282e85":"code","1fdc241c":"code","5e7f5060":"code","7af1bce0":"code","97e5753c":"code","25895269":"code","db9eb11d":"code","9f4a63ac":"code","44ba34e0":"code","d9484009":"code","f24fac77":"code","8d2cd11c":"code","664eb5d9":"code","d4a7dea7":"code","709dcf1e":"code","b2b240fe":"code","93c6b279":"code","adee4e55":"code","ccce992d":"code","a7932089":"code","29cada35":"code","d707bc3f":"code","78870ee4":"code","565df422":"code","fac395b5":"code","f9ba3a14":"code","0d7d7c19":"code","d9a29047":"code","b94d8fa2":"code","30921697":"code","ea17a3a5":"code","87558a43":"code","c310b625":"code","49cbe587":"code","db1ff2c4":"code","cbbe86f3":"code","6b5b8930":"code","626ebaf9":"code","d2a0a405":"code","ccdc0142":"code","6b2b4f36":"code","d6a6411b":"code","325b565d":"code","db161e4f":"code","0a835af8":"code","1fa8bbcb":"code","fb41180a":"code","17f88f00":"code","9852b711":"code","2fcc6a89":"code","80a7814d":"code","2e36b97c":"code","2486f735":"code","686bd174":"code","b42cabc5":"code","afc78219":"code","6e209fa5":"code","84073cbc":"code","9e1fef84":"code","20505915":"code","fb57f6c0":"code","d7b14057":"code","2d10eabd":"markdown","1e815872":"markdown","faf43a46":"markdown","191a9e3d":"markdown","b26b4e6c":"markdown","ffc88677":"markdown","25b259c8":"markdown","4e6be943":"markdown","645c320d":"markdown","5e7a2cfe":"markdown","472e2c73":"markdown","5f124d58":"markdown","be9725f5":"markdown","654a865c":"markdown","6eacc4f4":"markdown","a847942f":"markdown","2af95576":"markdown","5379f28c":"markdown","10891ffe":"markdown","34b83381":"markdown","51500fb1":"markdown","51d2d80d":"markdown","636045df":"markdown","45fe91ad":"markdown","601ab791":"markdown","513e118a":"markdown","63fe5d06":"markdown","476648a3":"markdown","de5352e4":"markdown","6efa4fad":"markdown","b5de02cb":"markdown","ef37d737":"markdown","4f05542b":"markdown","73fe854f":"markdown","f12a3f2e":"markdown","362efd42":"markdown","2420b940":"markdown","bd0f8a9b":"markdown","1225fc13":"markdown","66bf67d4":"markdown","075fd484":"markdown","b0c981eb":"markdown","babe6833":"markdown","8119f205":"markdown","8039b149":"markdown","e30152e9":"markdown","2b5fbad3":"markdown","aa0c1286":"markdown","d7aeb5e1":"markdown","eb4ffabe":"markdown","92faef78":"markdown","d8921016":"markdown","661fd707":"markdown","5dbbefe0":"markdown","53ee0435":"markdown","f432df23":"markdown","3071820a":"markdown","1804c8ea":"markdown","803f32db":"markdown","c52b5713":"markdown","2c693a22":"markdown","f3b769a4":"markdown","96c38df3":"markdown","7b6af9ae":"markdown","6d47a79e":"markdown","124d3842":"markdown","d58249ae":"markdown","c0888d96":"markdown","26d1e7b9":"markdown","853d6cc7":"markdown","434f5dc2":"markdown","e14da27b":"markdown","c8e0f9d5":"markdown","31467f05":"markdown","ebf3120a":"markdown","dc43a430":"markdown","b7b8f7db":"markdown","60276662":"markdown","4c3e353e":"markdown","707880b1":"markdown","dd8dd2be":"markdown","100e15dd":"markdown","afbe55f4":"markdown","3d648d10":"markdown","fe80238a":"markdown","fbda7f41":"markdown","7f393f07":"markdown","1c87cede":"markdown","268100cb":"markdown","58428183":"markdown","1dc3de7f":"markdown","706ca19c":"markdown","a6fc056b":"markdown"},"source":{"dad66bf3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn import preprocessing \nfrom category_encoders import *\nfrom sklearn.preprocessing import LabelEncoder\n%matplotlib inline\nfrom sklearn import datasets, linear_model, metrics\nfrom sklearn.metrics import  confusion_matrix\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')","fc8799a2":"df = pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")\ndf","5871ce6c":"# Exploratory Data Analysis\ndef libraries():\n    global pd,np\n    import pandas as pd\n    import numpy as np\ndef load():\n    global df\n    df = pd.read_csv(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")\n    \ndef top_rows(value):\n    print('\\033[1m'+ 'displaying the', value, 'rows from top'+'\\033[0m')\n    a=df.head(value)\n    print(a,'\\n')\n    \ndef bottom_rows(value):\n    print('\\033[1m'+'displaying the', value, 'rows from bottom'+'\\033[0m')\n    b=df.tail(value)\n    print(b,'\\n')\n    \ndef rows_columns():\n    print('\\033[1m'+'Shape of the Data set'+'\\033[0m')\n    c=df.shape\n    print(c,'\\n')\n    \ndef col_names():\n    print('\\033[1m'+'Column Names in the Data set'+'\\033[0m')\n    d=df.columns\n    print(d,'\\n')\n    \ndef information():\n    print('\\033[1m'+'Quick Overview of DataSet(info)'+'\\033[0m')\n    e = df.info()\n    print(e,'\\n')\n\ndef sizee():\n    print('\\033[1m'+'No.of Elements in the DataSet'+'\\033[0m')\n    f = df.size\n    print(f,'\\n')\n\ndef ndimension():\n    print('\\033[1m'+'Dimensions in your dataframe'+'\\033[0m')\n    g = df.ndim\n    print(g,'\\n')\n    \ndef stats_summary():\n    print('\\033[1m'+'Staistical Summary of DataSet'+'\\033[0m')\n    h = df.describe()\n    print(h,'\\n')\n    \ndef null_values():\n    print('\\033[1m'+'Number of Missing values in each column'+'\\033[0m')\n    i = df.isnull().sum()\n    print(i,'\\n')\n    \ndef n_unique():\n    print('\\033[1m'+'Number of unique elements'+'\\033[0m')\n    j = df.nunique()\n    print(j,'\\n')\n    \ndef memory_use():\n    print('\\033[1m'+'Memory used by all colomns in bytes'+'\\033[0m')\n    k = df.memory_usage()\n    print(k,'\\n')\n    \ndef is_na(value):\n    print('\\033[1m'+'Dataframe filled with boolean values with true indicating missing values'+'\\033[0m')\n    l = df.isna().head(value)\n    print(l,'\\n')\n    \ndef duplicate():\n    print('\\033[1m'+'Boolean Series denoting duplicate rows'+'\\033[0m')\n    m = df.duplicated().sum()\n    print(m,'\\n')\n    \ndef valuecounts():\n    print('\\033[1m'+'Series containing count of unique values'+'\\033[0m')\n    n = df.value_counts()\n    print(n,'\\n')\n\ndef datatypes():\n    print('\\033[1m'+'Datatype of each column'+'\\033[0m')\n    o = df.dtypes\n    print(o,'\\n')\n    \ndef correlation():\n    print('\\033[1m'+'Correalation between all columns in DataFrame'+'\\033[0m')\n    p = df.corr()\n    print(p,'\\n')\n    \ndef nonnull_count():\n    print('\\033[1m'+'Count of non-null values'+'\\033[0m')\n    q = df.count()\n    print(q,'\\n')\n    \ndef eda():\n    load()\n    value= 5 \n    datatypes()\n    top_rows(value)\n    bottom_rows(value)\n    rows_columns()\n    col_names()\n    information()\n    sizee()\n    ndimension()\n    stats_summary()\n    null_values()\n    n_unique()\n    memory_use()\n    is_na(value)\n    nonnull_count()\n    duplicate()\n    valuecounts()\n    correlation()\n    \n    \n    \n        \ndef stats_u(data,col):\n    if data[col].dtype == \"float64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        max_value = data[col].max()\n        print('Maximum value of',col,'column',max_value)\n        min_value = data[col].min()\n        print('Minimum value of',col,'column',min_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n            \n    elif data[col].dtype == \"int64\":\n        print(col,\"has Quantitative data\")\n        mean_value=data[col].mean()\n        print('mean of',col,'column',mean_value)\n        median_value = data[col].median(skipna = True)\n        print('median of',col,'column',median_value)\n        std_value = data[col].std()\n        print('standard deviation of',col,'column',std_value)\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        print('quartile 1 of',col,'column is',q1)\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        print('quartile 2 of',col,'column is',q2)\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        print('quartile 3 of',col,'column is',q3)\n        q4 = data[col].quantile(1,interpolation='nearest')\n        print('quartile 4 of',col,'column is',q4)\n        IQR = q3 -q1\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        print('Lower Limit Point:',LLP)\n        print('Upper Limit Point:',ULP)\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers\")\n        else:\n            print(\"There are outliers\")\n            print(\"Outliers are:\")\n            print(data[data[col]<LLP][col])\n            print(data[data[col]>ULP][col])\n    else:\n        print(col,'has Qualitative Data')\n        z = df[col].mode()\n        print('mode of',col,'column:\\n',z)\n        print('Count of mode is:\\n',df[col].value_counts())\n        print('Unique strings in',col,'are',data[col].nunique())\n        if(data[col].nunique() == 1):\n            print(col,'has same string')\n        elif(data[col].nunique() == 2):\n            print(col,'has binary strings')\n        else:\n            print(col,'has multi stings')\n\n\nlibraries()\neda()\n\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of DataSet'+'\\033[0m')\nprint('\\033[1m'+'DataTypes in the DataSet:\\n'+'\\033[0m',df.dtypes)\nprint('\\033[1m'+'Columns in DataSet:'+'\\033[0m',df.columns)\nprint('\\033[1m'+'Shape of DataSet:'+'\\033[0m',df.shape)\nprint('\\033[1m'+'Size of DataSet:'+'\\033[0m',df.size)\nprint('\\033[1m'+'Dimension of DataSet:'+'\\033[0m',df.ndim)\nprint('\\033[1m'+'Total Memory used in DataSet:'+'\\033[0m',df.memory_usage().sum())\nprint('\\033[1m'+'Total Number of missing values in DataSet:'+'\\033[0m',df.isnull().sum().sum())\nprint('\\033[1m'+'Total Number of Unique values in DataSet:'+'\\033[0m',df.nunique().sum())\nprint('\\033[1m'+'Total Number of non null values in DataSet:'+'\\033[0m',df.count().sum())\nprint('\\033[1m'+'Total Number of duplicate rows in DataSet:'+'\\033[0m',df.duplicated().sum())\nprint(\"----------------------------------------------------------------------------------------------------------------------\")\nprint('\\033[1m'+'Summary Of Each Colomn'+'\\033[0m')\nprint(\"\\n\")\ncols=df.columns\ncols\nfor i in cols:\n    print('\\033[1m'+i+'\\033[0m')\n    stats_u(df,i)\n    print(\"\\n\")\n            ","988a831f":"df.head()","59a77bfb":"df.tail()","1bf854d8":"df.dtypes","dab4bb71":"df.columns","45f76e90":"df.shape","5db841f8":"df.size","ebee351d":"df.info()","db1e83cc":"df.describe()","de05fe0d":"df.isnull().sum()","e39be453":"df.duplicated().sum()","b9f47df4":"df.skew()","55c3b5e7":"df.corr()","703ff463":"! pip install Autoviz","3768fc57":"! pip install xlrd","7a598c89":"from autoviz.AutoViz_Class import AutoViz_Class\nAV = AutoViz_Class()\ndf_av = AV.AutoViz(\"..\/input\/students-performance-in-exams\/StudentsPerformance.csv\")","fed4dce6":"df['race\/ethnicity'].value_counts()","2939329e":"sns.countplot(x = 'race\/ethnicity',data = df)\nplt.show()","c2679767":"df['parental level of education'].value_counts()","4e6a27ca":"sns.set(rc={'figure.figsize':(10,10)})\nsns.countplot(x = 'parental level of education',data = df)\nplt.show()","f033496f":"df['lunch'].value_counts()","b244572d":"sns.set(rc={'figure.figsize':(10,10)})\nsns.countplot(x = 'lunch',data = df)\nplt.show()","d4f26530":"df['test preparation course'].value_counts()","f466a9f9":"sns.countplot(x = 'test preparation course',data = df)\nplt.show()","a593218a":"df['gender'].value_counts()","87ef4c25":"sns.countplot(x = 'gender',data = df)\nplt.show()","0eca9655":"from IPython.core.display import HTML\n\ndef multi_table(table_list):\n    ''' Acceps a list of IpyTable objects and returns a table which contains each IpyTable in a cell\n    '''\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","d3f3a870":"df_nunique = {var: pd.DataFrame(df[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'}}\nmulti_table([df_nunique['race\/ethnicity'], df_nunique['parental level of education'],df_nunique['lunch']\n            ,df_nunique['test preparation course'],df_nunique['gender']])","d6b1e682":"df_groupby = {var: pd.DataFrame(df.groupby([var, 'math score']).size()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'}}\nmulti_table([df_groupby['race\/ethnicity'], df_groupby['parental level of education'],df_groupby['lunch']\n            ,df_groupby['test preparation course'],df_groupby['gender']])","4660771e":"plt.figure(figsize=(16,9))\nax = sns.heatmap(df.corr(),annot = True,cmap = 'viridis')\nplt.show()","3e82067f":"''' Plot a Shifted Correlation Matrix '''\n# Diagonal correlation is always unity & less relevant, shifted variant shows only relevant cases\ndef corrMat(df,id=False):\n    \n    corr_mat = df.corr().round(2)\n    f, ax = plt.subplots(figsize=(12,7))\n    mask = np.triu(np.ones_like(corr_mat, dtype=bool))\n    mask = mask[1:,:-1]\n    corr = corr_mat.iloc[1:,:-1].copy()\n    sns.heatmap(corr,mask=mask,vmin=-0.3,vmax=0.3,center=0, \n                cmap='RdPu_r',square=False,lw=2,annot=True,cbar=False)\n#     bottom, top = ax.get_ylim() \n#     ax.set_ylim(bottom + 0.5, top - 0.5) \n    ax.set_title('Shifted Linear Correlation Matrix')\n    \ncorrMat(df.drop(['race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'],axis = 1))","b76d9477":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='test preparation course',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['test preparation course', 'math score',\n       'reading score', 'writing score']\nsnsPairGrid(df[numvars_targ])","eee435ff":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='race\/ethnicity',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['race\/ethnicity', 'math score',\n       'reading score', 'writing score']\nsnsPairGrid(df[numvars_targ])","330bc274":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='parental level of education',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['parental level of education', 'math score',\n       'reading score', 'writing score']\nsnsPairGrid(df[numvars_targ])","8b40a161":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='lunch',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['lunch',  'math score',\n       'reading score', 'writing score']\nsnsPairGrid(df[numvars_targ])","479ffaed":"''' Draw a Bivariate Seaborn Pairgrid \/w KDE density w\/ '''\ndef snsPairGrid(df):\n\n    ''' Plots a Seaborn Pairgrid w\/ KDE & scatter plot of df features'''\n    g = sns.PairGrid(df,diag_sharey=False,hue='gender',palette='Purples')\n    g.fig.set_size_inches(13,13)\n    g.map_upper(sns.kdeplot,n_levels=5)\n    g.map_diag(sns.kdeplot, lw=2)\n    g.map_lower(sns.scatterplot,s=20,edgecolor=\"k\",linewidth=1,alpha=0.6)\n    g.add_legend()\n    plt.tight_layout()\nnumvars_targ = ['gender', 'math score',\n       'reading score', 'writing score']\nsnsPairGrid(df[numvars_targ])","57c54d8a":"df_B = df[df['race\/ethnicity'] == 'group B']\ndf_B # contains all group B students details","962fec6f":"df_B.corr()","c4a8c296":"df_B.describe()","26978145":"df_B_nunique = {var: pd.DataFrame(df_B[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'}}\nmulti_table([df_B_nunique['race\/ethnicity'], df_B_nunique['parental level of education'],df_B_nunique['lunch']\n            ,df_B_nunique['test preparation course'],df_B_nunique['gender']])","ce9544ce":"fig = px.histogram(data_frame = df_B,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","fc083007":"fig = px.histogram(data_frame = df_B,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","0fb4f358":"fig = px.histogram(data_frame = df_B,\n             x = \"parental level of education\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with gender<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","27f88f10":"fig = px.histogram(data_frame = df_B,\n             x = \"test preparation course\",\n             color=\"gender\", title=\"<b>Analysis of test preparation course with sex<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","db0f189f":"df_A = df[df['race\/ethnicity'] == 'group A']\ndf_A # contains all group A students details","3102d76a":"df_A.corr()","6ec0385f":"df_A.describe()","2726e757":"df_A_nunique = {var: pd.DataFrame(df_A[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'}}\nmulti_table([df_A_nunique['race\/ethnicity'], df_A_nunique['parental level of education'],df_A_nunique['lunch']\n            ,df_A_nunique['test preparation course'],df_A_nunique['gender']])","780441e1":"fig = px.histogram(data_frame = df_A,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","1aca5a1e":"fig = px.histogram(data_frame = df_A,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","582d9113":"fig = px.histogram(data_frame = df_A,\n             x = \"parental level of education\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with gender<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","34a1d682":"fig = px.histogram(data_frame = df_A,\n             x = \"test preparation course\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","baf5ed17":"df_C = df[df['race\/ethnicity'] == 'group C']\ndf_C # contains all group C students details","915e2b82":"df_C.corr()","2fab5bcf":"df_C.describe()","114d1a24":"df_C_nunique = {var: pd.DataFrame(df_C[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'}}\nmulti_table([df_C_nunique['race\/ethnicity'], df_C_nunique['parental level of education'],df_C_nunique['lunch']\n            ,df_C_nunique['test preparation course'],df_C_nunique['gender']])","a549ac95":"fig = px.histogram(data_frame = df_C,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","a3cc978c":"fig = px.histogram(data_frame = df_C,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","930d4bfe":"fig = px.histogram(data_frame = df_C,\n             x = \"parental level of education\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with gender<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","543cde03":"fig = px.histogram(data_frame = df_C,\n             x = \"test preparation course\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","d0e95ae7":"df_D = df[df['race\/ethnicity'] == 'group D']\ndf_D # contains all group D students details","8e1cb97d":"df_D.corr()","b689cf68":"df_D.describe()","584c2e43":"df_D_nunique = {var: pd.DataFrame(df_D[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'}}\nmulti_table([df_D_nunique['race\/ethnicity'], df_D_nunique['parental level of education'],df_D_nunique['lunch']\n            ,df_D_nunique['test preparation course'],df_D_nunique['gender']])","a202e8d9":"fig = px.histogram(data_frame = df_D,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","67160852":"fig = px.histogram(data_frame = df_D,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","9f805118":"fig = px.histogram(data_frame = df_D,\n             x = \"parental level of education\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with gender<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","026ac49c":"fig = px.histogram(data_frame = df_D,\n             x = \"test preparation course\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","4088eabc":"df_E = df[df['race\/ethnicity'] == 'group E']\ndf_E # contains all group E students details","a270b86d":"df_E.corr()","fb0d5523":"df_E.describe()","509556f1":"df_E_nunique = {var: pd.DataFrame(df_E[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'}}\nmulti_table([df_E_nunique['race\/ethnicity'], df_E_nunique['parental level of education'],df_E_nunique['lunch']\n            ,df_E_nunique['test preparation course'],df_E_nunique['gender']])","91d16676":"fig = px.histogram(data_frame = df_E,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","3b87c57b":"fig = px.histogram(data_frame = df_E,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","a3a9f2f5":"fig = px.histogram(data_frame = df_E,\n             x = \"parental level of education\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with gender<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","6d97dd29":"fig = px.histogram(data_frame = df_E,\n             x = \"test preparation course\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","9448d617":"fig = px.histogram(data_frame = df,\n             x = \"parental level of education\",\n             color=\"lunch\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","05bc740b":"fig = px.histogram(data_frame = df,\n             x = \"parental level of education\",\n             color=\"test preparation course\", title=\"<b>Analysis of parent level education with test preparation course<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","f10e3445":"fig = px.histogram(data_frame = df,\n             x = \"parental level of education\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with sex<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","507655e5":"fig = px.histogram(data_frame = df,\n             x = \"test preparation course\",\n             color=\"gender\", title=\"<b>Analysis of parent level education with lunch<\/b>\",\n             pattern_shape_sequence=['x'],\n             template='plotly_dark')\n\nfig.show()","e2adbf75":"max_math_percent = df['math score'].max()\nmax_math_percent","38681d54":"df[df['math score'] == max_math_percent]","1cf61690":"min_math_percent = df['math score'].min()\nmin_math_percent","0f80b6ee":"df[df['math score'] == min_math_percent]","6f416a31":"max_reading_percent = df['reading score'].max()\nmax_reading_percent","e369e588":"df_read = df[df['reading score'] == max_reading_percent]\ndf_read","f55152c2":"df_nunique = {var: pd.DataFrame(df_read[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'}}\nmulti_table([df_nunique['race\/ethnicity'], df_nunique['parental level of education'],df_nunique['lunch']\n            ,df_nunique['test preparation course'],df_nunique['gender']])","06cbc536":"df1 = df_read.groupby('race\/ethnicity').agg({'math score' : 'mean','reading score' : 'mean','writing score' : 'mean'})\ndf1","c5b3baca":"px.bar(data_frame=df1, barmode='group',\n       title = \"<b>race\/ethnicity wise Analyzing<\/b>\",template=\"plotly_dark\")","19b42999":"min_reading_percent = df['reading score'].min()\nmin_reading_percent","791bfd95":"df_minread = df[df['reading score'] == min_reading_percent]\ndf_minread","2885b6ad":"max_writing_percent = df['writing score'].max()\nmax_writing_percent","e5ac6730":"df_write = df[df['writing score'] == max_writing_percent]\ndf_write","dbdcb436":"df_nunique = {var: pd.DataFrame(df_write[var].value_counts()) \n              for var in {'race\/ethnicity', 'parental level of education', 'lunch',\n       'test preparation course','gender'}}\nmulti_table([df_nunique['race\/ethnicity'], df_nunique['parental level of education'],df_nunique['lunch']\n            ,df_nunique['test preparation course'],df_nunique['gender']])","1cdf37f8":"min_writing_percent = df['writing score'].min()\nmin_writing_percent","760e3028":"df_minwrite = df[df['writing score'] == min_writing_percent]\ndf_minwrite","cfb31c9b":"df[(df['math score'].values == df['reading score']) & (df['math score'].values == df['writing score'])]","d586b0d4":"dfb = df[df['race\/ethnicity'] == 'group B']\ndfb","cab8caab":"max_percent_b = dfb['math score'].max()\nmax_percent_b","ba87aff6":"dfb[dfb['math score'] == max_percent_b]","25282e85":"obj = ['race\/ethnicity','parental level of education','lunch','test preparation course','gender']\nnum = ['math score','reading score','writing score']","1fdc241c":"for i in range(len(obj)):\n    plt.figure(figsize=(11,7))\n    sns.barplot(x=obj[i],y=\"math score\", data=df)\n    plt.show()","5e7f5060":"for i in range(len(obj)):\n    plt.figure(figsize=(11,7))\n    sns.barplot(x=obj[i],y=\"reading score\", data=df)\n    plt.show()","7af1bce0":"for i in range(len(obj)):\n    plt.figure(figsize=(11,7))\n    sns.barplot(x=obj[i],y=\"writing score\", data=df)\n    plt.show()","97e5753c":"df2 = df.groupby('race\/ethnicity').agg({'math score' : 'mean','reading score' : 'mean','writing score' : 'mean'})\ndf2","25895269":"px.bar(data_frame=df2, barmode='group',\n       title = \"<b>race\/ethnicity wise Analyzing<\/b>\",template=\"plotly_dark\")","db9eb11d":"df3 = df.groupby('parental level of education').agg({'math score' : 'mean','reading score' : 'mean','writing score' : 'mean'})\ndf3","9f4a63ac":"px.bar(data_frame=df3, barmode='group',\n       title = \"<b>race\/parental level of education wise Analyzing<\/b>\",template=\"plotly_dark\")","44ba34e0":"df4 = df.groupby('lunch').agg({'math score' : 'mean','reading score' : 'mean','writing score' : 'mean'})\ndf4","d9484009":"px.bar(data_frame=df4, barmode='group',\n       title = \"<b>lunch wise Analyzing<\/b>\",template=\"plotly_dark\")","f24fac77":"df5 = df.groupby('test preparation course').agg({'math score' : 'mean','reading score' : 'mean','writing score' : 'mean'})\ndf5","8d2cd11c":"px.bar(data_frame=df5, barmode='group',\n       title = \"<b>test preparation course wise analysing<\/b>\",template=\"plotly_dark\")","664eb5d9":"df6 = df.groupby('gender').agg({'math score' : 'mean','reading score' : 'mean','writing score' : 'mean'})\ndf6","d4a7dea7":"px.bar(data_frame=df6, barmode='group',\n       title = \"<b>sex wise analyzing<\/b>\",template=\"plotly_dark\")","709dcf1e":"# Here my target variable is math percentage\ndef categorial_feature_overview(feature, rotation=0):\n    print(feature, 'has', df[feature].isnull().sum() \/ len(df) * 100, '% of null values')\n    f,ax = plt.subplots(1, 2, figsize=(20, 6))\n    ax[0].tick_params(labelrotation=rotation)\n    ax[1].tick_params(labelrotation=rotation)\n    sns.countplot(data=df, x=feature, ax=ax[0]);\n    sns.boxplot(data=df, x=feature, y='math score', ax=ax[1])\n    plt.show()\n    \ndef numerical_feature_overview(feature, rotation=0):\n    print(feature, 'has', df[feature].isnull().sum() \/ len(df) * 100, '% of null values')\n    f,ax = plt.subplots(1, 2, figsize=(20, 6))\n    ax[0].tick_params(labelrotation=rotation)\n    ax[1].tick_params(labelrotation=rotation)\n    sns.scatterplot(data=df, x=feature, y='math score', ax=ax[0]);\n    sns.boxplot(data=df, x=feature, ax=ax[1])\n    plt.show()","b2b240fe":"categorial_feature_overview('race\/ethnicity')","93c6b279":"categorial_feature_overview('parental level of education')","adee4e55":"categorial_feature_overview('lunch')","ccce992d":"categorial_feature_overview('gender')","a7932089":"categorial_feature_overview('test preparation course')","29cada35":"numerical_feature_overview('math score')","d707bc3f":"numerical_feature_overview('reading score')","78870ee4":"numerical_feature_overview('writing score')","565df422":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nx = df.drop(obj,axis = 1)\nfor i in x.columns:\n    count_outliers(x,i)","fac395b5":"Num_vars = ['math score','reading score','writing score']","f9ba3a14":"Cat_vars = df.drop(Num_vars, axis = 1).columns.tolist()\nCat_vars","0d7d7c19":"Cat_vars_low = list(df[Cat_vars].loc[:, (df[Cat_vars].nunique() < 10)].nunique().index)\nCat_vars_high = list(df[Cat_vars].loc[:, (df[Cat_vars].nunique() >= 10)].nunique().index)","d9a29047":"sns.set_theme(rc = {'grid.linewidth': 0.5,\n                    'axes.linewidth': 0.75, 'axes.facecolor': '#fff3e9', 'axes.labelcolor': '#6b1000',\n                    'figure.facecolor': '#f7e7da'})\n                    #'xtick.labelcolor': '#6b1000', 'ytick.labelcolor': '#6b1000'","b94d8fa2":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(2, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['math score']), \n                        hue =  np.log(df['math score']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","30921697":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(2, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['reading score']), \n                        hue =  np.log(df['reading score']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","ea17a3a5":"with plt.rc_context(rc = {'figure.dpi': 300, 'axes.labelsize': 8, \n                          'xtick.labelsize': 6, 'ytick.labelsize': 6}): \n    \n    fig_0, ax_0 = plt.subplots(2, 3, figsize = (8, 7))\n\n    for idx, (column, axes) in list(enumerate(zip(Num_vars, ax_0.flatten()))):\n        \n        sns.scatterplot(ax = axes, x = df[column], \n                        y = np.log(df['writing score']), \n                        hue =  np.log(df['writing score']),\n                        palette = 'viridis', alpha = 0.7, s = 8)\n    \n    # Get rid of legend\n    \n        axes.legend([], [], frameon = False)\n    \n    # Remove empty figures\n    \n    else:\n        [axes.set_visible(False) for axes in ax_0.flatten()[idx + 1:]]\n\nplt.tight_layout()\nplt.show()","87558a43":"train_num_visual_0 = df.select_dtypes(include = ['int64']).columns.tolist()","c310b625":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(3, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['gender'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","49cbe587":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(3, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['race\/ethnicity'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","db1ff2c4":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(2, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['parental level of education'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","cbbe86f3":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(2, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['lunch'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","6b5b8930":"sns.set_theme(rc = {'figure.dpi': 120, 'axes.labelsize': 8, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'}, font_scale = 0.65)\n\nfig, ax = plt.subplots(2, 1, figsize = (7, 6))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_num_visual_0, ax.flatten())))):\n    \n    sns.scatterplot(ax = axes, y = df[column].index, x = df[column], \n                    hue = df['test preparation course'], palette = 'crest', alpha = 0.8)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","626ebaf9":"list(zip(Num_vars, ax_0.flatten()))","d2a0a405":"list(enumerate(zip(Num_vars, ax_0.flatten())))","ccdc0142":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['gender']].columns.tolist()","6b2b4f36":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math score'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math score'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math score'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","d6a6411b":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['race\/ethnicity']].columns.tolist()","325b565d":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math score'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math score'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math score'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","db161e4f":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['parental level of education']].columns.tolist()","0a835af8":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math score'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math score'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math score'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","1fa8bbcb":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['lunch']].columns.tolist()","fb41180a":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math score'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math score'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math score'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","17f88f00":"train_no_NA = df.dropna()\n\ntrain_cat_visual_0 = train_no_NA[['test preparation course']].columns.tolist()","9852b711":"sns.set_theme(rc = {'figure.dpi': 250, 'axes.labelsize': 7, \n                    'axes.facecolor': '#f0eee9', 'grid.color': '#fffdfa', \n                    'figure.facecolor': '#e8e6e1'},font_scale = 0.25)\n\nfig, ax = plt.subplots(3, 2, figsize = (6.5, 7.5))\n\nfor indx, (column, axes) in list(enumerate(list(zip(train_cat_visual_0, ax.flatten())))):\n    \n    sns.violinplot(ax = axes, x = train_no_NA[column], \n                   y = train_no_NA['math score'],\n                   scale = 'width', linewidth = 0.5, \n                   palette = 'crest', inner = None)\n    \n    plt.setp(axes.collections, alpha = 0.3)\n    \n    sns.stripplot(ax = axes, x = train_no_NA[column], \n                  y = train_no_NA['math score'],\n                  palette = 'crest', alpha = 0.9, \n                  s = 1.5, jitter = 0.07)\n    sns.pointplot(ax = axes, x = train_no_NA[column],\n                  y = train_no_NA['math score'],\n                  color = '#ff5736', scale = 0.25,\n                  estimator = np.mean, ci = 'sd',\n                  errwidth = 0.5, capsize = 0.15, join = True)\n    \n    plt.setp(axes.lines, zorder = 100)\n    plt.setp(axes.collections, zorder = 100)\n    \nelse:\n    [axes.set_visible(False) for axes in ax.flatten()[indx + 1:]]\n    \nplt.tight_layout()\nplt.show()","2fcc6a89":"df.isnull().sum()\n## no null value treatment","80a7814d":"df=pd.get_dummies(data=df,columns=obj,drop_first=True)\ndf","2e36b97c":"X = df.drop(['math score'],axis = 1)\nY = df['math score']\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3,random_state=44)","2486f735":"from sklearn.ensemble import RandomForestRegressor\nforest= RandomForestRegressor(n_estimators =40, random_state = 0)\nforest.fit(X_train,Y_train)  \ny_pred = forest.predict(X_test)\nforest.score(X_test,Y_test)","686bd174":"plt.scatter(Y_test,y_pred)\nplt.xlabel('Y Test (True Values)')\nplt.ylabel('Predicted values')\nplt.show()","b42cabc5":"metrics.explained_variance_score(Y_test,y_pred)","afc78219":"print('MAE',metrics.mean_absolute_error(Y_test,y_pred))\nprint('MSE',metrics.mean_squared_error(Y_test,y_pred))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(Y_test,y_pred)))","6e209fa5":"sns.displot(Y_test-y_pred,bins = 50,kde = True)","84073cbc":"reg = linear_model.LinearRegression()\nreg.fit(X_train, Y_train)\npred = reg.predict(X_test)\nreg.score(X_test,Y_test)","9e1fef84":"plt.scatter(Y_test,pred)\nplt.xlabel('Y Test (True Values)')\nplt.ylabel('Predicted values')\nplt.show()","20505915":"metrics.explained_variance_score(Y_test,pred)","fb57f6c0":"print('MAE',metrics.mean_absolute_error(Y_test,pred))\nprint('MSE',metrics.mean_squared_error(Y_test,pred))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(Y_test,pred)))","d7b14057":"sns.displot(Y_test-pred,bins = 50,kde = True)","2d10eabd":"# Analysis and visualisation using group by","1e815872":"# Query 9: Find the student with lowest reading score percentage","faf43a46":"# Visualization related to Query 1","191a9e3d":"#### People who taken course for test preparation done very great in math exam","b26b4e6c":"#### Outliers are present in wrting score percentage and it has a positive corelation with math percentage","ffc88677":"# Importing Libraries","25b259c8":"# Query 4: Find all students belongs to group D","4e6be943":"# Query 12: Find the students who gots equal percentage in all scores","645c320d":"# Query 10: Find the student with highest writing score percentage","5e7a2cfe":"#### In group A only parents master's degree have more number of female children(only 1 diffeence)","472e2c73":"#### In groub D, in all categories many number of students not taken any course","5f124d58":"## grouped tables for categorical variables","be9725f5":"# Query 3: Find all students belongs to group C","654a865c":"#### In group D,In students who has completed course females are more\n#### In group D, In students who has not completed course males are more","6eacc4f4":"#### In group E parents with associate's college level education level are more\n#### In group E parents with maters's degree level of education are very less\n#### In group E most of the students eating standard lunch\n#### In group E there are more number of students who has not taken any test preparation course\n#### In group E males are more in number(only 2 difference)","a847942f":"#### Females are doing good in reading, writing but in math exam males are good over them","2af95576":"# Advanced Visualisation","5379f28c":"#### Most of the students didn't took any course for test preparation","10891ffe":"#### In group D parents with some college level education level are more\n#### In group D parents with maters's degree level of education are very less\n#### In group D most of the students eating standard lunch\n#### In group D there are more number of students who has not taken any test preparation course\n#### In group D males are more in number(only 4 difference)","34b83381":"# Data Preprocessing","51500fb1":"#### In groub C in all  categories more number of  of students not taken any course","51d2d80d":"# Feature Selection","636045df":"#### All numerical columns are highly positively corelated","45fe91ad":"#### In group A irrespective of gender students who have not taken course are more in number","601ab791":"#### pairlot of all numerical columns with race\/ethnicity as hue","513e118a":"# Query 8: Find the student with highest reading score percentage","63fe5d06":"#### No outliers in group A","476648a3":"#### In df more number of students irrespective of parent level of education are taking standard food ","de5352e4":"# Query 11: Find the student with lowest writing score percentage","6efa4fad":"# Analysis related to Query 4","b5de02cb":"#### pairlot of all numerical columns with gender as hue","ef37d737":"#### In df,In students who has completed course females are more\n#### In df, In students who has not completed course females are more","4f05542b":"# Analysis and visualisation using Query","73fe854f":"#### More number of parents studied in college\n#### Less number of parents done Masters","f12a3f2e":"# Data visualisation using Autoviz","362efd42":"# Exploratory Data Analysis","2420b940":"# Query 7: Find the student with lowest math percentage","bd0f8a9b":"#### In group B,In students who has completed course females are more(but only 2 students difference)\n#### In group B, In students who has not completed course females are more","1225fc13":"## UPVOTE IF U LIKE","66bf67d4":"# Exploratory Data Analysis Using User Defined function","075fd484":"#### In groub B Except children of some high school level educated parents(In this case both are equal), in all other categories more number of students not taken any course","b0c981eb":"#### Ouliers in reading score percentage and it has a good corelation with math percentage","babe6833":"#### In df  in all other categories moret number of students not taken any course","8119f205":"#### No outliers in master's degree and associate's degree","8039b149":"#### The main reason of plotting strip plots is sometimes values jump in the column, to checknthe continuity strip plot is needed.","e30152e9":"## Scatter plots","2b5fbad3":"#### In group C more number of students irrespective of parent level of education are taking standard food except master's degree parents students take free\/reduced lunch","aa0c1286":"#### In group E,In students who has completed course males are more.\n#### In group E, In students who has not completed course females are more","d7aeb5e1":"#### This looks like balanced data","eb4ffabe":"# Query 13: Find the students who got highest math percentage in group B","92faef78":"## visualisation of whole df","d8921016":"## Getting unique values of each category","661fd707":"# Loading Data Set","5dbbefe0":"#### In group A, In master's degree there are no students with test preparation course taken\n#### In all other cases students who have not taken course are more in number","53ee0435":"#### In group C parents with associate's degree education level are more\n#### In group C parents with maters's degree level of education are very less\n#### In group C most of the students eating standard lunch\n#### In group C there are more number of students who has not taken any test preparation course\n#### In group C most of the students are females","f432df23":"# Prediction using Linear Regression","3071820a":"#### In group C,In students who has completed course females are more\n#### In group C, In students who has not completed course females are more","1804c8ea":"#### In group E more number of students irrespective of parent level of education are taking standard food","803f32db":"#### Female students are more in number than male","c52b5713":"#### In group B more number of students irrespective of parent level of education are taking standard food except master's degree parents students take free\/reduced lunch","2c693a22":"## Encoding","f3b769a4":"#### pairlot of all numerical columns with parental level of education as hue","96c38df3":"#### In group A more number of students irrespective of parent level of education are taking standard food except associate's degree parents students are equal in number in both cases.","7b6af9ae":"#### Most of the students are eating standard lunch(to their fullest)","6d47a79e":"# Visualization related to Query 2","124d3842":"# Data Visualisation","d58249ae":"#### Outliers in math percentage","c0888d96":"# Query 5: Find all students belongs to group E","26d1e7b9":"#### More females,more test preparation completed students, standard lunch students, parents of bachelor's degree, group E who got 100 percentage in reading ","853d6cc7":"#### Group E is more balanced because math percentage, reading score percentage and writing score percentage are alomost same","434f5dc2":"#### In group B parents with Education level bachelor's degrre,Master's degree,associates's degree,some college,some high school have female children more\n#### In group B only parents with high college have male children more","e14da27b":"#### In group B parents with Education level bachelor's degrre,Master's degree,associates's degree,,high school,some high school have female children more\n#### In group B only parents with some college have male children more","c8e0f9d5":"#### out of 7 students who got 100% 5 of them are from group E \n#### parental level of education of students who got 100% math percentage are 3 from some college, 2 from associates's degree, 2 from bachelor's degree\n#### 6 students eating standard lunch out of 7\n#### 4 are males and 3 are females\n#### 3 students got 100 in all percentages(2 of them are females)","31467f05":"# Query 6: Find the student with highest math percentage","ebf3120a":"# Query 2: Find all students belongs to group A","dc43a430":"#### In group C parents with Education level bachelor's degrre,associates's degree,some high school have female children more\n#### In group C parents with high school, master's degree have male children more","b7b8f7db":"#### In group E parents with Education level bachelor's degrre,Master's degree,high school have female children more\n#### In group E only parents with some college,associates's degree,some high school have male children more","60276662":"#### In group D parents with Education level bachelor's degrre,associates's degree,high schoolhave male children more\n#### In group D parents with Master's degree have female children more\n#### In group D parents with some high school have male and female childrens equal","4c3e353e":"#### More females,more test preparation completed students, standard lunch students, parents of bachelor's degree, group D who got 100 percentage in writing","707880b1":"#### In group E , children of high school  level educated parents both completed and none are equal\n#### In group E, children of bachelor's degree level educated parents have more number of completed course than none","dd8dd2be":"#### pairlot of all numerical columns with lunch as hue","100e15dd":"#### People with standard lunch are doing great","afbe55f4":"# Prediction Using Random forest Regressor","3d648d10":"## Violin plot with strip plots","fe80238a":"#### In group D more number of students irrespective of parent level of education are taking standard food except bachelor's degree parents students take free\/reduced lunch and standard lunch equally","fbda7f41":"#### In group B parents with  high school education level are more\n#### In group B parents with maters's degree level of education are very less\n#### In group B most of the students eating standard lunch\n#### In group B most of the students are females","7f393f07":"## Count of Outliers","1c87cede":"# Query 1: Find all students  belongs to group B","268100cb":"#### In group A parents with  some high school education level are more\n#### In group A parents with maters's degree level of education are very less\n#### In group A most of the students eating standard lunch\n#### In group A most of the students are not involved in test preparation course\n#### In group A most of the students are males","58428183":"# Analysis related to Query 3","1dc3de7f":"## Bar plot analysis","706ca19c":"# Analysis related to Query 5","a6fc056b":"#### pairlot of all numerical columns with test preparation score as hue\n\n### We can clearly see that all numerical columns are highly corelated and their values are slightly right skewed"}}