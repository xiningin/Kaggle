{"cell_type":{"7d533f6a":"code","136ac956":"code","9460684b":"code","62f88bc7":"code","b2293309":"code","e7a8860e":"code","e1ffbabe":"code","a094ee21":"code","5acf5537":"code","eb6beb3a":"code","e7572b5f":"code","9b5d3dd4":"code","22f1f480":"code","7d240ede":"code","bd9ba40d":"code","287e871c":"code","bc18054d":"code","a6013b37":"code","e5db0c37":"code","556b22bf":"code","4d0e8cae":"code","61e70c18":"code","10ef8582":"markdown","22414326":"markdown","be5779aa":"markdown","ad5a78ed":"markdown","af70dd24":"markdown","ddcf4b67":"markdown","88c6f12d":"markdown","9be27cf0":"markdown","a16c47ed":"markdown","eefb49fa":"markdown","4022c7ce":"markdown"},"source":{"7d533f6a":"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\npd.options.mode.chained_assignment = None\nimport seaborn as sns\nfrom matplotlib.pylab import rcParams\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n%matplotlib inline\n\nsns.set(style='whitegrid', palette='muted')\nrcParams['figure.figsize'] = 14, 8\nnp.random.seed(1)\ntf.random.set_seed(1)\n\nprint('Tensorflow version:', tf.__version__)","136ac956":"df = pd.read_csv(\"..\/input\/sp500-daily-19862018\/spx.csv\", parse_dates=['date'])\ndf.head()","9460684b":"df.shape","62f88bc7":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=df.date, y=df.close,\n                    mode='lines',\n                    name='close'))\nfig.update_layout(showlegend=True)\nfig.show()","b2293309":"train_size = int(len(df) * 0.8)\ntest_size = len(df) - train_size\ntrain, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]\nprint(train.shape, test.shape)","e7a8860e":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler = scaler.fit(train[['close']])\n\ntrain['close'] = scaler.transform(train[['close']])\ntest['close'] = scaler.transform(test[['close']])","e1ffbabe":"def create_dataset(X, y, time_steps=1):\n    Xs, ys = [], []\n    for i in range(len(X) - time_steps):\n        v = X.iloc[i:(i + time_steps)].values\n        Xs.append(v)        \n        ys.append(y.iloc[i + time_steps])\n    return np.array(Xs), np.array(ys)","a094ee21":"time_steps = 30\n\nX_train, y_train = create_dataset(train[['close']], train.close, time_steps)\nX_test, y_test = create_dataset(test[['close']], test.close, time_steps)\n\nprint(X_train.shape)","5acf5537":"timesteps = X_train.shape[1]\nnum_features = X_train.shape[2]","eb6beb3a":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n\nmodel = Sequential([\n    LSTM(128, input_shape=(timesteps, num_features)),\n    Dropout(0.2),\n    RepeatVector(timesteps),\n    LSTM(128, return_sequences=True),\n    Dropout(0.2),\n    TimeDistributed(Dense(num_features))                 \n])\n\nmodel.compile(loss='mae', optimizer='adam')\nmodel.summary()","e7572b5f":"es = tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=5)\nhistory = model.fit(\n    X_train, y_train,\n    epochs=100,\n    batch_size=32,\n    validation_split=0.1,\n    callbacks = [es],\n    shuffle=False\n)","9b5d3dd4":"plt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend();","22f1f480":"model.evaluate(X_test, y_test)","7d240ede":"X_train_pred = model.predict(X_train)\n\ntrain_mae_loss = pd.DataFrame(np.mean(np.abs(X_train_pred - X_train), axis=1), columns=['Error'])","bd9ba40d":"train_mae_loss","287e871c":"sns.distplot(train_mae_loss, bins=50, kde=True);","bc18054d":"X_test_pred = model.predict(X_test)\n\ntest_mae_loss = np.mean(np.abs(X_test_pred - X_test), axis=1)","a6013b37":"sns.distplot(test_mae_loss, bins=50, kde=True);","e5db0c37":"THRESHOLD = 0.55\n\ntest_score_df = pd.DataFrame(test[time_steps:])\ntest_score_df['loss'] = test_mae_loss\ntest_score_df['threshold'] = THRESHOLD\ntest_score_df['anomaly'] = test_score_df.loss > test_score_df.threshold\ntest_score_df['close'] = test[time_steps:].close","556b22bf":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=test[time_steps:].date, y=test_score_df.loss,\n                    mode='lines',\n                    name='Test Loss'))\nfig.add_trace(go.Scatter(x=test[time_steps:].date, y=test_score_df.threshold,\n                    mode='lines',\n                    name='Threshold'))\nfig.update_layout(showlegend=True)\nfig.show()","4d0e8cae":"anomalies = test_score_df[test_score_df.anomaly == True]\nanomalies.head()","61e70c18":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=test[time_steps:].date, y=scaler.inverse_transform(test[time_steps:].close),\n                    mode='lines',\n                    name='Close Price'))\nfig.add_trace(go.Scatter(x=anomalies.date, y=scaler.inverse_transform(anomalies.close),\n                    mode='markers',\n                    name='Anomaly'))\nfig.update_layout(showlegend=True)\nfig.show()","10ef8582":" ## Create Training and Test Time Splits","22414326":"## Train the LSTM","be5779aa":"# Anomaly Detection in Time Series data\n ","ad5a78ed":"## Plot Metrics and Evaluate the Model","af70dd24":"## Load and Inspect the S&P 500 Index Data","ddcf4b67":"## Build an LSTM Autoencoder","88c6f12d":"## Import Libraries","9be27cf0":"## Data Preprocessing","a16c47ed":"[Data Source](https:\/\/www.kaggle.com\/pdquant\/sp500-daily-19862018): S&P500 Daily Prices 1986 - 2018\n","eefb49fa":"## Detect Anomalies in the S&P 500 Index Data","4022c7ce":"![image.png](attachment:image.png)"}}