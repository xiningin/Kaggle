{"cell_type":{"54554f87":"code","36093fa0":"code","14b39686":"code","8771525c":"code","29c85601":"code","14e2be82":"code","5803dbc9":"code","efaaa9f2":"code","8dbb1719":"code","206d2e82":"code","49593b5a":"code","8cb4e202":"code","fb480f12":"code","eb9b7e0d":"code","799982e1":"code","e8f2b47f":"code","b1a1b0ba":"markdown","d2a2c517":"markdown","dafe40b0":"markdown","1836df0e":"markdown","3a1d77e0":"markdown","d020ffd0":"markdown","34642248":"markdown","b921e564":"markdown","6bd21105":"markdown","be7e7a92":"markdown","ed84db06":"markdown","52d7998e":"markdown","fa4fbbad":"markdown","5a42b4e6":"markdown","03791ea3":"markdown","acf019e8":"markdown","69fbf0a3":"markdown","1523f54a":"markdown","b66419b8":"markdown"},"source":{"54554f87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","36093fa0":"import seaborn as sns\nimport io\nimport requests\nimport re\nimport warnings\nimport os\nprint(os.listdir(\"..\/input\"))\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.templates\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('seaborn-notebook')\nfrom matplotlib.ticker import StrMethodFormatter\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer","14b39686":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","8771525c":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","29c85601":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","14e2be82":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","5803dbc9":"data = [train_data, test_data]\nfor dataset in data:\n    mean = train_data[\"Age\"].mean()\n    std = test_data[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    # compute random numbers between the mean, std and is_null\n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    # fill NaN values in Age column with random values generated\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = train_data[\"Age\"].astype(int)","efaaa9f2":"survived = 'survived'\nnot_survived = 'not survived'\nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(16, 8))\nwomen = train_data[train_data['Sex']=='female']\nmen = train_data[train_data['Sex']=='male']\nax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False, color=\"green\")\nax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False, color=\"red\")\nax.legend()\nax.set_title('Female')\nax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False, color=\"green\")\nax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False, color=\"red\")\nax.legend()\n_ = ax.set_title('Male');","8dbb1719":"df = pd.read_csv('..\/input\/titanic\/train.csv')\nfig = px.scatter_3d(df, x='Name', y='Sex', z='Age',\n                    color='Age')\nfig.show()","206d2e82":"for template in [\"plotly\"]:\n    fig = px.scatter(train_data,\n                     x=\"PassengerId\", y=\"Age\", color=\"Survived\",\n                     log_x=True, size_max=20,\n                     template=template, title=\"Which Age Survived?\")\n    fig.show()","49593b5a":"embarked = train_data['Embarked'].mode()\ndata = [train_data, test_data]\nfor dataset in data:\n    dataset['Embarked'] = dataset['Embarked'].fillna(embarked)","8cb4e202":"FacetGrid = sns.FacetGrid(train_data, row='Embarked', size=4.5, aspect=1.6)\nFacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', order=None, hue_order=None )\nFacetGrid.add_legend();","fb480f12":"data = [train_data, test_data]\nfor dataset in data:\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'travelled_alone'] = 'No'\n    dataset.loc[dataset['relatives'] == 0, 'travelled_alone'] = 'Yes'\naxes = sns.factorplot('relatives','Survived', \n                      data=train_data, aspect = 2.5, );","eb9b7e0d":"pd.read_csv('..\/input\/titanic\/gender_submission.csv')","799982e1":"from sklearn.ensemble import RandomForestClassifier\n\n#data[\"Age\"] = data[\"Age\"].astype(int)\n#if [\"Age\"]\n\ny = train_data[\"Survived\"]\n\nfeatures = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\nX = pd.get_dummies(train_data[features])\nX_test = pd.get_dummies(test_data[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = survived\nsubmission.to_csv('submission_titanic.csv', index=False)","e8f2b47f":"pd.read_csv('submission_titanic.csv')","b1a1b0ba":"\uc131\ubcc4 \uc0dd\uc874\ube44\uc728\uc744 \uad6c\ud588\uc73c\ubbc0\ub85c \uc5ec\uae30\uc5d0 \uc5f0\ub839\ub300\ub77c\ub294 \ub2e4\ub978 \ubcc0\uc218\ub97c \ub123\uc5b4 \ubd84\uc11d\ud558\uace0, \uc774\ub97c \uc2dc\uac01\ud654\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.","d2a2c517":"\uc774\ubc88\uc5d0\ub294 SibSp \ubcc0\uc218\uc640 Parch \ubcc0\uc218\ub97c \ud569\ud558\uc5ec relatives\ub77c\ub294 \uc0c8\ub85c\uc6b4 \ubcc0\uc218\uc5d0 \uc9c0\uc815\ud55c \ub2e4\uc74c, \uc774 relatives\ub97c X\ucd95, survived\ub97c Y\ucd95\uc73c\ub85c \ub450\uace0 \uc2dc\uac01\ud654\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \nSibsp \ubcc0\uc218\ub294 \ud615\uc81c\uc790\ub9e4 \ubc0f \ubc30\uc6b0\uc790(siblings \/ spouses aboard)\ub97c, parch \ubcc0\uc218\ub294 \ubd80\ubaa8\ub2d8 \ubc0f \uc790\ub140(parents \/ children aboard)\ub97c \uc758\ubbf8\ud569\ub2c8\ub2e4.\uadf8\ub807\uae30\uc5d0 '\ub3d9\uc2b9\ud55c \uac00\uc871'\uc774\ub77c\ub294 \ud070 \ud2c0\ub85c \ubb36\uc5b4\ubcf4\uace0\uc790 \ud55c \uac83\uc785\ub2c8\ub2e4.  \n","dafe40b0":"\uba3c\uc800 data\ub97c \ubd88\ub7ec\uc624\uaca0\uc2b5\ub2c8\ub2e4. ","1836df0e":"\uc774\ubc88\uc5d0\ub294 \uc6d0\ub798 \ub370\uc774\ud130\uc5d0 \uc774\ub984(Name) \ubcc0\uc218\uac00 \uc788\ub294 \ub9cc\ud07c, name\uc744 \ub123\uc5b4 \uc2dc\uac01\ud654\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.","3a1d77e0":"\uc800\ub294 titanic \ud504\ub85c\uc81d\ud2b8\ub97c \uba3c\uc800 \uc131\ubcc4\/\uc774\ub984\/\uc5f0\ub839\ub300\ubcc4\/\ub3d9\uc2b9\uc790 \uc5ec\ubd80(\ubcc0\uc218 \uc0dd\uc131)\uc758 4\uac1c \ubcc0\uc218\ub97c \uc911\uc2ec\uc73c\ub85c, \ucc28\ub840\ub300\ub85c \uc2dc\uac01\ud654\ub97c \uc9c4\ud589, \uac01 \uacb0\uacfc\ub97c \uae30\ubc18\uc73c\ub85c \ub9c8\uc9c0\ub9c9\uc5d0 submission_titanic \ud30c\uc77c\ub85c \uc0dd\uc874 \uc5ec\ubd80\ub97c \uc608\uce21\ud55c \ub370\uc774\ud130\ub97c \ub0b4\ubcf4\ub0b4\uace0\uc790 \ud569\ub2c8\ub2e4. \ub610\ud55c, \uc2dc\uac01\ud654\uc758 \uacbd\uc6b0 \uc5ec\ub7ec \uac00\uc9c0 \uadf8\ub798\ud504\ub85c \uc2dc\uac01\ud654\ud558\ub294 \uac83\uc774 \uac00\ub2a5\ud558\uae30\uc5d0, \uac00\uae09\uc801 \ub9ce\uc740 \uc885\ub958\uc758 \uadf8\ub798\ud504\ub97c \uc0ac\uc6a9\ud574 \ubcf4\uace0\uc790 \ud569\ub2c8\ub2e4.","d020ffd0":"\ub098\uc774\ub97c \uc911\uc2ec\uc73c\ub85c\ub3c4 \ud30c\uc545\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \ub2e4\ub9cc, \uc704\uc5d0\uc11c\ucc98\ub7fc 3\ucc28\uc6d0 \uadf8\ub798\ud504\uac00 \uc544\ub2c8\ub77c, \uc810\uc73c\ub85c \uc2dc\uac01\ud654\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n\uc704\uc5d0\uc11c \uc0ac\uc6a9\ud588\ub358 \uc774\ub984 \ub610\ud55c \ub108\ubb34 \uae38\uae30 \ub54c\ubb38\uc5d0, passenger ID\ub85c \ub300\uccb4\ud558\uaca0\uc2b5\ub2c8\ub2e4.","34642248":"\ud544\uc694\ud55c \uae30\ub2a5\ub4e4\uc744 \ubd88\ub7ec\uc624\uba74\uc11c \uc2dc\uc791\ud558\uaca0\uc2b5\ub2c8\ub2e4.","b921e564":"\uc774\uc81c sklearn \ud328\ud0a4\uc9c0\uc5d0\uc11c RandomForestClassifier \uae30\ub2a5\uc744 \ud65c\uc6a9\ud574 \uc704\uc5d0\uc11c \uc9c4\ud589\ud588\ub358 \ub300\ub85c, Pclass(ticket class), \uc131\ubcc4(sex), relatives\ub97c \uad6c\uc131\ud588\ub358 SibSp,Parch \uc774\ub807\uac8c 4\uac00\uc9c0 \ubcc0\uc218\ub97c \uac00\uc9c0\uace0 \uc9c4\ud589\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.","6bd21105":"embarked \ubd80\ubd84 \ub370\uc774\ud130\ub97c \uba3c\uc800 \uc190\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.","be7e7a92":"\uba3c\uc800 data\ub97c \uc190\ubcf4\uaca0\uc2b5\ub2c8\ub2e4.","ed84db06":"\ub450 \uac00\uc9c0 \ub370\uc774\ud130\ub97c \ubaa8\ub450 \ubcc0\uc218\uc5d0 \uc9c0\uc815\ud574 \uc8fc\uc5c8\uc73c\ubbc0\ub85c, \uc774\uc81c \uc0dd\uc874\uc790 \ubd84\uc11d\uc744 \uc9c4\ud589\ud558\uaca0\uc2b5\ub2c8\ub2e4. \uba3c\uc800 \uc131\ubcc4\ub85c \uc9c4\ud589\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.","52d7998e":"\uc6d0 \ub370\uc774\ud130\ub97c \ubcf4\uba74, embarked \uac12\uc5d0\ub294 \ud06c\uac8c S,Q,C\uac00 \uc788\uc74c\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. Embarked \uac12\uc744 \uc911\uc2ec\uc73c\ub85c \ud558\uace0\uc790 \ud588\uc73c\ubbc0\ub85c '\uc0dd\uc874\uc790'\ub77c\ub294 \uc804\uc81c \ud558\uc5d0, \uc131\ubcc4 \ubcc0\uc218\ub97c \ucd94\uac00\ud558\uc5ec \uac01 embarked \uac12\ubcc4 \uadf8\ub798\ud504\ub97c \uc2dc\uac01\ud654\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.","fa4fbbad":"relatives \uc218\ub294 0\ubd80\ud130 10\uae4c\uc9c0 \ub2e4\uc591\ud558\uc9c0\ub9cc, \uc0dd\uc874 \ube44\uc728\uc740 \uc81c\uac01\uae30 \ub2e4\ub985\ub2c8\ub2e4.\uc704\uc758 \uc2dc\uac01\ud654 \uc790\ub8cc\uc5d0\uc11c relatives \uac12\ubcc4 \uc9c1\uc120\uc740 \ubaa8\ub4e0 survived \ube44\uc728\uc744 \ud45c\uc2dc\ud55c \uac83\uc774\uba70, \uc810\uc740 \uc9c1\uc120\uc758 \uac00\uc6b4\ub370\ub97c \ucc0d\uc740 \uac83\uc774\uace0, \uadf8\ub798\ud504\ub294 \uc774 \uc810\ub4e4\uc744 \uc774\uc740 \uac83\uc785\ub2c8\ub2e4. ","5a42b4e6":"\ub9c8\ucc2c\uac00\uc9c0 \uc791\uc5c5\uc774\uc9c0\ub9cc, \uc704\uc5d0\ub294 train dataset\uc744 \ubd88\ub7ec\uc628 \uac83\uc774\uace0 \uc544\ub798\ub294 test dataset\uc785\ub2c8\ub2e4.","03791ea3":"\uc9c0\uae08\uae4c\uc9c0 \uc6d0 \ub370\uc774\ud130\uc5d0\uc11c passenger ID, age, name \ub4f1 \ub300\ubd80\ubd84\uc758 \ubcc0\uc218\ub97c \uc0ac\uc6a9\ud574 \uc2dc\uac01\ud654\uae4c\uc9c0 \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc, \uc544\uc9c1 embark \ubcc0\uc218\ub294 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc558\uae30\uc5d0 \uc774\uc81c \uc0ac\uc6a9\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.","acf019e8":"\uc774\uc81c \uc704\uc5d0\uc11c \uc2dc\uac01\ud654\ud574 \ubcf8 \uac12\uc744 \uae30\ubc18\uc73c\ub85c, \uc81c\uacf5\ub418\uc5c8\ub358 3\uac1c\uc758 datasets \uc911 \uc544\uc9c1 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc740 gender_submission \ub370\uc774\ud130\ub97c \ud65c\uc6a9\ud574 \ud504\ub85c\uc81d\ud2b8\ub97c \ub9c8\uc800 \uc9c4\ud589\ud558\uaca0\uc2b5\ub2c8\ub2e4.","69fbf0a3":"\ud655\uc778\ucc28 submission_titanic.csv \ud30c\uc77c\uc744 \ub2e4\uc6b4\ubc1b\uc740 \ub2e4\uc74c(\uc6b0\uce21 \ub354\ubcf4\uae30\ub780(?)\uc5d0\uc11c Data\uc5d0 \ub4e4\uc5b4\uac00\uba74, input \uc544\ub798\uc5d0 output \ud30c\uc77c\uc774 \uc0dd\uc131\ub418\uc5b4 \uc788\uc73c\ubbc0\ub85c \uc774\ub97c \ub2e4\uc6b4\ubc1b\uc2b5\ub2c8\ub2e4) \uc77d\uc5b4\uc624\uaca0\uc2b5\ub2c8\ub2e4.\n","1523f54a":"\uadf8 \ub2e4\uc74c, \ub2e4\uc6b4\ubc1b\uc740 \ub370\uc774\ud130(\ucd1d 3\uac1c set)\ub97c \ucc28\ub840\ub300\ub85c \ubd88\ub7ec\uc624\ub418 head \ud568\uc218\ub97c \uc0ac\uc6a9\ud574 \uc77c\ubd80\ub9cc \ubd88\ub7ec\uc624\uaca0\uc2b5\ub2c8\ub2e4.","b66419b8":"\ubcc0\uc218\uc640 \uc2dc\uac01\ud654 \uacfc\uc815\uc5d0\uc11c \ud544\uc694\ud55c \uac12\uacfc \uc0c9\uc0c1\uc744 \uc9c0\uc815\ud558\uaca0\uc2b5\ub2c8\ub2e4."}}