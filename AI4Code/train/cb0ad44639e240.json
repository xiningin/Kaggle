{"cell_type":{"e9dc2bc0":"code","631f8a3c":"code","ff3cbc56":"code","8a0ebdf7":"code","7d6d3105":"code","bdbd39ea":"code","c88e6fa5":"code","73995a56":"code","ca02109b":"code","cecba5d3":"code","555697da":"code","838416de":"code","28b0f485":"code","0f054afd":"code","f6f0bf0e":"code","1e0c57f8":"code","948b5627":"code","e4cfbc54":"code","303fb0ad":"code","282cb18b":"code","3b5f3894":"code","64148202":"markdown","bfd7de4f":"markdown","0daac49d":"markdown","8352b85f":"markdown","93101892":"markdown","0ee19627":"markdown","15816e29":"markdown","3b1247ad":"markdown"},"source":{"e9dc2bc0":"# linear algebra\nimport numpy as np\n# library\nimport pandas as pd\n#load input\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n#visualisation\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n#data preprocessing tool\nfrom sklearn.model_selection import train_test_split\n#nerual network tools\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D","631f8a3c":"#split into train and test set\ntrain = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","ff3cbc56":"#for further informaton check out the [data description of the competitioin](https:\/\/www.kaggle.com\/c\/digit-recognizer\/data)\ntrain.columns","8a0ebdf7":"# connect TPU and set up distribution strategy\nimport tensorflow as tf\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\nstrategy = tf.distribute.experimental.TPUStrategy(tpu)","7d6d3105":"#seperate target\ny_train = train.pop(\"label\")","bdbd39ea":"#As each pixel has a assigned color value from 0-255 we normalize the values from 0-1\nX_train = train \/ 255\ntest = test \/ 255","c88e6fa5":"#reshape pixel values into a 28x28x1 array\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","73995a56":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\ny_train = to_categorical(y_train, num_classes = 10)","ca02109b":"#split into train and validation set\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=2021)","cecba5d3":"#example\nplt.imshow(X_train[0], cmap= \"gray\")","555697da":"#optimizer\nfrom keras.optimizers import RMSprop\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","838416de":"# Set a learning rate annealer\nfrom keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","28b0f485":"#assign epochs and batch_size\nepochs = 30\nbatch_size = 16 * strategy.num_replicas_in_sync","0f054afd":"#create neural network\nwith strategy.scope():\n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n\n\n    model.add(Flatten())\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = \"softmax\"))\n\n    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"], steps_per_execution=32)\n    ","f6f0bf0e":"#fit the model\nhistory = model.fit(X_train,Y_train, batch_size=batch_size,\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction])","1e0c57f8":"#accuracy and loss curve for train and validation set - looks good\nfig, ax = plt.subplots(2,1)\n\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\")\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","948b5627":"#load real life picture\nfrom PIL import Image\nreal_life_example = np.array(Image.open('\/kaggle\/input\/png001\/3_example.png').resize((28,28)))\nplt.imshow(real_life_example)\nprint(\"Shape of uploaded example: {}\".format(real_life_example.shape))","e4cfbc54":"#normailze \nreal_life_example = real_life_example \/ 255\n# transform 3-dimensional channel (color dimension) into one dimension\nreal_life_example = real_life_example.mean(axis=2).astype(np.float64)\nplt.imshow(real_life_example)\nprint(\"Shape of transformed example: {}\".format(real_life_example.shape))","303fb0ad":"#reshape to fit the model\nreal_life_example = real_life_example.reshape(1,28,28,1)\nprint(\"Final shape of example: {}\".format(real_life_example.shape))","282cb18b":"#real life example prediction\nexample_pred = model.predict(real_life_example)\n#reverse one-hot encoded target\nexample_pred = np.argmax(example_pred,axis = 1)\nprint(\"Predicted digit: {}\".format(example_pred))","3b5f3894":"#predictions\nresults = model.predict(test)\n#reverse one-hot encoded target\nresults = np.argmax(results,axis = 1)\n# create submission\nsubmission = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\")\nsubmission[\"Label\"] = results.tolist()\nsubmission.to_csv(\"submission.csv\", index=False)","64148202":"# 1. First Look","bfd7de4f":"I am aware that for further TPU efficiency you must split the data into TFRecords. Just for the sake of time I skipped that step. Fitting the model take about 1-2 minutes.","0daac49d":"# 3. Neural Network building","8352b85f":"# 2. Data Preprocessing","93101892":"# 5. Submission","0ee19627":"# Digit Recognizer\n\n![image.png](attachment:ba2b352a-9204-4510-bc05-de8d94ece60d.png)\n\nIn this notebook we are going to predict digits from the famous MNIST dataset of handwritten images. We also upload one digit written by myself and check whether our model predicts the hand written digit aswell!\n\nBest score: 99.36% accuracy\n\n# Agenda:\n1. First Look\n2. Model Preprocessing\n3. Neural Network building\n4. Real life example\n5. Submission","15816e29":"# Disclaimer:\n\nMost of the parameters and the neural network structure were inspired by https:\/\/www.kaggle.com\/yassineghouzam. Check his notebook out - it's really well explained. \nFor this notebook I keep the explanation of each step at a minimum. So reading this kernel requires basic computer vision knowledge.\nThis is just a quick runthrough!","3b1247ad":"# 4. Real life example"}}