{"cell_type":{"240995d2":"code","149b2691":"code","634f9b6c":"code","db8b8943":"code","6c73fc8a":"code","eac523a7":"code","8fa15eab":"code","b3bcc28d":"code","f0fbbecb":"code","035feab9":"code","8903f8bc":"code","41e66394":"code","a33f6ad1":"code","a6f7a139":"code","082362ea":"code","57552709":"code","dedcb7fb":"code","e10d70f9":"code","b434e67a":"code","02a42049":"markdown","f1bc8a67":"markdown","4b8b0b00":"markdown","83044fcf":"markdown","b927a0f0":"markdown"},"source":{"240995d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","149b2691":"# load datasets\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","634f9b6c":"train.head()","db8b8943":"train_len = len(train)\ntest_copy = test.copy()","6c73fc8a":"# combine train and test set\ntotal = train.append(test)\ntotal.isnull().sum()","eac523a7":"total[total.Fare.isnull()]","8fa15eab":"# fill the missing value for Fare column with median\ntotal['Fare'].fillna(value = total[total.Pclass==3]['Fare'].median(), inplace = True)","b3bcc28d":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# extract title from name, fill the missing value for Age column according to title's median\ntotal['Title'] = total['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n# check distribution of title\nplt.figure(figsize=(8,6))\nsns.countplot(x= \"Title\",data = total)\nplt.xticks(rotation='45')\nplt.show()","f0fbbecb":"# Replacing rare titles with more common ones\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ntotal.replace({'Title': mapping}, inplace=True)","035feab9":"# fill the missing value for Age column with median of its title\ntitles = list(total.Title.unique())\nfor title in titles:\n    age = total.groupby('Title')['Age'].median().loc[title]\n    total.loc[(total.Age.isnull()) & (total.Title == title),'Age'] = age","8903f8bc":"# add family size as a feature\ntotal['Family_Size'] = total['Parch'] + total['SibSp']","41e66394":"# This feature is from S.Xu, https:\/\/www.kaggle.com\/shunjiangxu\/blood-is-thicker-than-water-friendship-forever\ntotal['Last_Name'] = total['Name'].apply(lambda x: str.split(x, \",\")[0])\ntotal['Fare'].fillna(total['Fare'].mean(), inplace=True)\n\ndefault_survival_rate = 0.5\ntotal['Family_Survival'] = default_survival_rate\n\nfor grp, grp_df in total[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n    \n    if (len(grp_df) != 1):\n        # A Family group is found.\n        for ind, row in grp_df.iterrows():\n            smax = grp_df.drop(ind)['Survived'].max()\n            smin = grp_df.drop(ind)['Survived'].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                total.loc[total['PassengerId'] == passID, 'Family_Survival'] = 1\n            elif (smin==0.0):\n                total.loc[total['PassengerId'] == passID, 'Family_Survival'] = 0\n\nprint(\"Number of passengers with family survival information:\", \n      total.loc[total['Family_Survival']!=0.5].shape[0])","a33f6ad1":"for _, grp_df in total.groupby('Ticket'):\n    if (len(grp_df) != 1):\n        for ind, row in grp_df.iterrows():\n            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    total.loc[total['PassengerId'] == passID, 'Family_Survival'] = 1\n                elif (smin==0.0):\n                    total.loc[total['PassengerId'] == passID, 'Family_Survival'] = 0\n                        \nprint(\"Number of passenger with family\/group survival information: \" \n      +str(total[total['Family_Survival']!=0.5].shape[0]))\n","a6f7a139":"# add fare bins\ntotal['Fare_Bin'] = pd.qcut(total['Fare'], 5,labels=False)\n# add age bins\ntotal['Age_Bin'] = pd.qcut(total['Age'], 4,labels=False)","082362ea":"# convert Sex to catergorical value\ntotal.Sex.replace({'male':0, 'female':1}, inplace = True)\n\n# only select the features we want\nfeatures = ['Survived','Pclass','Sex','Family_Size','Family_Survival','Fare_Bin','Age_Bin']\ntotal = total[features]","57552709":"# split total to train and test set\ntrain = total[:train_len]\n# set Survied column as int\nx_train = train.drop(columns = ['Survived'])\ny_train = train['Survived'].astype(int)\n\nx_test = total[train_len:].drop(columns = ['Survived'])","dedcb7fb":"# Scaling features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)","e10d70f9":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclf = KNeighborsClassifier()\nparams = {'n_neighbors':[6,8,10,12,14,16,18,20],\n         'leaf_size':list(range(1,50,5))}\n\n# Using ROC_AUC as metric has a better result than using accuracy. \ngs = GridSearchCV(clf, param_grid= params, cv = 5,scoring = \"roc_auc\",verbose=1)\ngs.fit(x_train, y_train)\nprint(gs.best_score_)\nprint(gs.best_estimator_)","b434e67a":"preds = gs.predict(x_test)\nresult = pd.DataFrame({'PassengerId': test_copy['PassengerId'], 'Survived': preds})\nresult.to_csv('result.csv', index = False)","02a42049":"## Model Building","f1bc8a67":"## Load datasets","4b8b0b00":"Reference:\n1. [Blood is thicker than water & friendship forever](https:\/\/www.kaggle.com\/shunjiangxu\/blood-is-thicker-than-water-friendship-forever)\n2. [Titanic [0.82] - [0.83]](https:\/\/www.kaggle.com\/konstantinmasich\/titanic-0-82-0-83)","83044fcf":"## Data Preprocess\nAs Cabin and Embarked has no correlations to survival, we just drop those columns later. \nSee reference:\n[Titanic [0.82] - [0.83]](https:\/\/www.kaggle.com\/konstantinmasich\/titanic-0-82-0-83)  \nFor Age and Fare, we fill the missing values with corresponding medians.\n","b927a0f0":"## Feature Scailing"}}