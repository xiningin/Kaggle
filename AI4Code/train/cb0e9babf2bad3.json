{"cell_type":{"cbe32616":"code","f06837f5":"code","8139ca5c":"code","48ebaa66":"code","38d12b50":"code","21064e34":"code","05e01be4":"code","13837a8a":"code","920410ff":"code","ab47fa10":"code","ea3d7cbd":"code","e9669eb7":"code","c2a09074":"code","7c40bb06":"code","f785a196":"code","f0648e91":"code","0cae4494":"code","d41775a7":"code","8900cb89":"code","53b6d55b":"code","5ccc32b0":"code","ac77b64b":"code","eeb29bd2":"code","44c34a67":"code","6d2d3b2b":"code","d4a6e127":"code","1b1a96f5":"code","1fbc9b46":"code","a86efb44":"code","2cdc625c":"code","dd62a43d":"code","4e4d5e4c":"code","a662285b":"code","d58ac875":"code","ecdddb29":"code","618e5de4":"code","1160be41":"code","5862e6d3":"code","23589e1c":"code","0ec63f70":"code","cd62d356":"code","d7501c99":"code","0b3dddd8":"code","677d37a9":"code","c3d23e74":"code","c5a6490d":"code","07a45ba6":"code","71770185":"code","144aad54":"code","380112f3":"code","c085f7fa":"code","ac1df9c1":"code","07426239":"code","c3103781":"code","8ba295de":"code","eb855093":"code","2a9250d0":"code","f5ae6f92":"code","1c5dce46":"code","1dbd5bd3":"code","5e322699":"code","2f258530":"markdown","ab839370":"markdown"},"source":{"cbe32616":"#we will import the TED.COM dataset\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndf=pd.read_csv('\/kaggle\/input\/ted-talks-main-csv\/ted_main.csv')\ndf.head()","f06837f5":"#now we will take a look at the data\ndf.shape\n#the output is total number of rows and columns","8139ca5c":"#this shows the datatypes\ndf.dtypes\n#the output object includes strings, list,dicts","48ebaa66":"#now we will check the missing values in the entire dataset\ndf.isna().sum()\n#the output tells that the speaker occupation has 6 null values, we shall handle it later","38d12b50":"#now we will find out which talks provoke most online discussion\n#one method is that the the talks with more online comments\/subcomments is provocative\n#next method is that we shall form a separate dataframe which calculates comments\/total number of views\ndf.sort_values('comments').tail()\n","21064e34":"df['comments_per_view']=df.comments\/df.views","05e01be4":"df['comments_per_view']","13837a8a":"#here you can see comments_per_view attached on to the dataframe\ndf.sort_values('comments_per_view').tail()","920410ff":"# we can also interpret that 'The case for same-sex marriage' talk by Diane J Savino has more provocative\n#for every view there is 0.002 comments per views\n#now we will see views per comment\ndf['views_per_comment']=df.views\/df.comments","ab47fa10":"df.sort_values('views_per_comment').head()","ea3d7cbd":"#Now we will visulaize the distribution of comments\ndf.comments.plot()\n\n#this is not the right way normally time series data are plotted with line plots","e9669eb7":"df.comments.plot(kind='hist')","c2a09074":"#we will make the chart most informative\ndf[df.comments<1000].comments.plot(kind='hist')","7c40bb06":"#one more method to do the same above plot\ndf.loc[df.comments<1000,'comments'].plot(kind='hist',bins=20)\n#place cursor inside parenthesis and clik shift+tab and tryout different plot types","f785a196":"#now we will plot number of talks that took each year\ndf.film_date.head()\n#the output is unis time stamps","f0648e91":"pd.to_datetime(df.film_date,unit='s')","0cae4494":"#now we will create a new datframe out of above output\ndf['film_datetime']=pd.to_datetime(df.film_date,unit='s')","d41775a7":"df.head()","8900cb89":"#now we will compare the dates output with event column\ndf[['event','film_datetime']].sample(5)\n#seems like the output is comparable","53b6d55b":"df.dtypes","5ccc32b0":"# the following attributes are available with datetime (dayofyear,year,dayofweek)\ndf.film_datetime.dt.dayofyear","ac77b64b":"#now we will count the number of talks every year\ndf.film_datetime.dt.year.value_counts()","eeb29bd2":"#try plotting by removing sort_index()\ndf.film_datetime.dt.year.value_counts().sort_index().plot()","44c34a67":"#now we will try to find the best event in the TED history\n#one method is that number od events in an year\ndf.event.value_counts()","6d2d3b2b":"#mean number of views for each event\ndf.groupby('event').views.mean().sort_values().tail()","d4a6e127":"#now we will pass on the aggregate function\n\ndf.groupby('event').views.agg(['count','mean','sum']).sort_values('sum').tail()","1b1a96f5":"#now we will unpack the ratings data\ndf['ratings']","1fbc9b46":"#what is the datatypes\ntype(df.ratings[0])\n#the dtypeis a stringified dictionary","a86efb44":"df.ratings[0]","2cdc625c":"import ast\n#abstract syntax tree","dd62a43d":"ast.literal_eval(df.ratings[0])\n#its a magic function which outputs string as a list","4e4d5e4c":"#now we will pass the custom function which converts the string to list\ndef str_to_list(ratings_str):\n    return ast.literal_eval(ratings_str)\n","a662285b":"str_to_list(df.ratings[0])","d58ac875":"#now the string output is converted to list\ntype(str_to_list(df.ratings[0]))","ecdddb29":"df.ratings.apply(str_to_list).head()","618e5de4":"#the above function can also be done by using a Lamda function\n#try changing ast.literal_eval to str_to_list\ndf['ratings_list']=df.ratings.apply(lambda x:ast.literal_eval(x))","1160be41":"#the goal is to convert the series of strings to series of lists\ndf['ratings_list']","5862e6d3":"#rating converted into ratings_list(series)\ndf.head(1)","23589e1c":"#now we will try to count the total number of ratings received by each talk\ndf.ratings_list[0]","0ec63f70":"#now we will buind the function to count the ratings\ndef get_num_ratings(list_of_dicts):\n    return list_of_dicts[0]['count']","cd62d356":"get_num_ratings(df.ratings_list[0])","d7501c99":"#now we will and the number of counts for the above function\ndef get_num_ratings(list_of_dicts):\n    num=0\n    for d in list_of_dicts:\n        num=num+d['count']\n        return num\n        \n    ","0b3dddd8":"#so the output is the total count of ratings of each talk\nget_num_ratings(df.ratings_list[0])","677d37a9":"#we will create a separate column in the dataframe\ndf['num_ratings']=df.ratings_list.apply(get_num_ratings)","c3d23e74":"df['num_ratings']","c5a6490d":"df.head(1)\n","07a45ba6":"#one more method to calculate the sum of counts of review\npd.DataFrame(df.ratings_list[0])['count'].sum()","71770185":"#now we will find which occupations deliver the funniest ted talks\n#now we will count the funny ratings\ndf.ratings.str.contains('funny').value_counts()","144aad54":"#now we will get the funny ratings from the dicts\ndef get_funny_ratings(list_of_dicts):\n    for d in list_of_dicts:\n        if d['name']== 'Funny':\n            return d['count']","380112f3":"df['funny_ratings']=df.ratings_list.apply(get_funny_ratings)","c085f7fa":"df['funny_ratings'].head()","ac1df9c1":"#now we will calculate the percentage of ratings which are funny\ndf['funny_rate']=df.funny_ratings\/df.num_ratings","07426239":"df.head(3)","c3103781":"df.sort_values('funny_rate').speaker_occupation\n#this output gives the funny rate with respect to the occupations","8ba295de":"#now we will analyse the funny rate by occupation\ndf.groupby('speaker_occupation').funny_rate.mean().sort_values()","eb855093":"df.speaker_occupation.describe()","2a9250d0":"#the speaker occupations which are well reperesented\noccupation_counts=df.speaker_occupation.value_counts()","f5ae6f92":"#now we will filter above series by their values\ntop_occupations=occupation_counts[occupation_counts>=5].index\n#now we will filter out top occupations which are represented more than 5 times in the dataframe\nted_top_occupations=df[df.speaker_occupation.isin(top_occupations)]\n","1c5dce46":"top_occupations","1dbd5bd3":"ted_top_occupations","5e322699":"ted_top_occupations.shape","2f258530":"Its a guided exercise.Please upvote if you like","ab839370":"# Introduction to the dataset"}}