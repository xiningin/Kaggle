{"cell_type":{"995f883e":"code","50014257":"code","d4b4c8de":"code","fe8d176c":"code","9f3b9017":"code","e0d2111a":"code","dfe5d435":"code","0a0ca7e9":"code","1003282b":"code","e26ffd52":"code","202fc1bb":"code","db88cc3c":"code","b37188f0":"code","f3c89566":"code","27152176":"code","0b523780":"code","773d29a1":"code","acf88caf":"code","fc1435b6":"code","df14bc0a":"code","f8f98fe1":"code","0032ce1c":"code","aad519a0":"code","4bd9210a":"code","314aa5ff":"code","78cf0cbd":"code","7e50dd5d":"code","3f0e7adf":"code","a88b5d78":"code","cb346f1c":"code","c2c6c0ea":"code","0f5f7039":"code","97c30bbf":"code","24d89900":"code","5027d3ca":"code","1ad0cf93":"code","7a2bb90a":"code","7e31653a":"code","c4387b39":"code","4436d730":"markdown","95491a10":"markdown","c3e75645":"markdown","b64fbee6":"markdown","7067344b":"markdown","4aab0b6d":"markdown"},"source":{"995f883e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","50014257":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","d4b4c8de":"train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')","fe8d176c":"train.head(10)","9f3b9017":"train.describe()","e0d2111a":"train.columns","dfe5d435":"cols = ['country', 'store', 'product']\nfor i in cols:\n    print('Value Count in {} is :\\n {} \\n \\n'.format(i, train[i].value_counts()))","0a0ca7e9":"train.isnull().sum()","1003282b":"train.describe()","e26ffd52":"train_df = train.drop(['row_id'], axis = 1)\ntest_df = test.drop(['row_id'], axis = 1)","202fc1bb":"train_df['date'] = pd.to_datetime(train_df['date'])\ntrain_df['year'] = train_df['date'].dt.year\ntrain_df['month'] = train_df['date'].dt.month\ntrain_df['day'] = train_df['date'].dt.day\ntrain_df['weekday'] = train_df['date'].dt.weekday\ntrain_df['week_of_year'] = train_df['date'].dt.isocalendar().week\ntrain_df['day_of_year'] = train_df['date'].dt.dayofyear\ntrain_df['quarter'] = train_df['date'].dt.quarter\ntrain_df['is_weekend'] = train_df.date.dt.weekday>4\ntrain_df.head()","db88cc3c":"train_df.head()","b37188f0":"test_df['date'] = pd.to_datetime(test_df['date'])\ntest_df['year'] = test_df['date'].dt.year\ntest_df['month'] = test_df['date'].dt.month\ntest_df['day'] = test_df['date'].dt.day\ntest_df['weekday'] = test_df['date'].dt.weekday\ntest_df['week_of_year'] = test_df['date'].dt.isocalendar().week\ntest_df['day_of_year'] = test_df['date'].dt.dayofyear\ntest_df['quarter'] = test_df['date'].dt.quarter\ntest_df['is_weekend'] = test_df.date.dt.weekday>4\ntest_df.head()","f3c89566":"country = pd.DataFrame()\ncountry = train_df.groupby('country').sum()\ncountry.head()","27152176":"train_df = train_df.drop('date', axis = 1)\ntest_df = test_df.drop('date', axis = 1)","0b523780":"def labelling(data, feature, plt):\n    total_height = 0\n    bar_plots = plt.patches\n    for bars in bar_plots:\n        total_height+=bars.get_height()\n    for bars in bar_plots:\n        percentage = '{:.1f}%'.format(100 * bars.get_height()\/total_height)\n        x = (bars.get_x() + bars.get_width()) \/ 2.0\n        y = bars.get_height()\n        plt.text(x,y+2, str(int(y))+','+percentage, ha='center', fontweight='bold', fontsize=1)\n    ","773d29a1":"import seaborn as sns\nfig = plt.figure(figsize = (13,7))\nsns.set_theme(style = 'whitegrid')\nplot = sns.barplot(x = country.index, y= country['num_sold'], palette = 'rocket')\nplt.xlabel('Country', fontweight = 'bold')\nplt.ylabel('Number of sold items', fontweight = 'bold')\nlabelling(country,'country',plot)\nplt.show()","acf88caf":"finland = train_df[train_df['country'] == 'Finland']\nfinland","fc1435b6":"finland_store = finland.groupby('store').sum()\nfinland_store.head()","df14bc0a":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\n","f8f98fe1":"le = LabelEncoder()\ncol_encoder = ['country','store','product', 'is_weekend']\nfor i in col_encoder:\n    train_df[i] = le.fit_transform(train_df[i])","0032ce1c":"y = train_df['num_sold']\nx = train_df.drop('num_sold', axis = 1)","aad519a0":"x['week_of_year'] = x['week_of_year'].astype(int)\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)","4bd9210a":"print(\"Shape of x_train is :\",x_train.shape)\nprint(\"Shape of x_test is :\",x_test.shape)\nprint(\"Shape of y_train is :\",y_train.shape)\nprint(\"Shape of y_test is :\",y_test.shape)","314aa5ff":"def SMAPE(y_true,y_pred):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    smape=0\n    if(len(y_true)==len(y_pred)):\n        smape = (100\/len(y_true)) * np.sum(2* np.abs(y_pred-y_true)\/(np.abs(y_true)+np.abs(y_pred)))\n        smape_2 = (1\/len(y_true))*np.sum(2*(np.abs(y_pred - y_true))\/np.abs(y_true) + np.abs(y_pred))\n    else:\n        return\n    return(smape)","78cf0cbd":"x_train.columns","7e50dd5d":"dic_model = {\n    \"RandomForestRegerssor\":RandomForestRegressor(n_estimators = 100),\n    'GradientBoosting':GradientBoostingRegressor(n_estimators=100),\n    'XGradientBoosting':xgb.XGBRegressor(n_estimators=100),\n    #'CatBoostRegressor':cb.CatBoostRegressor(n_estimators=100),\n    'LightGBM': lgb.LGBMRegressor(n_estimators=100)\n}\nfor i in dic_model:\n    #Training\n    print('Training with '+ i + ' Algorithm: \\n')\n    model = dic_model[i].fit(x_train,y_train)\n    \n    #Predicting\n    print('Predicting with '+ i +' Algorithm: \\n')\n    prediction = model.predict(x_test)\n    \n    #Using SMAPE for prediction\n    print('SMAPE of ' + i + ' Model is: ' + str(SMAPE(y_test, prediction)))\n    print('---------------------------------------------------------------------')","3f0e7adf":"import optuna\n\ndef objective(trial, data = x, target =y):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n    params = {\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02,0.2,1.0]),\n        #'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        #'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n    }\n    model = xgb.XGBRegressor(**params)\n    model.fit(x_train,y_train)\n    preds = model.predict(x_test)\n    Smape = SMAPE(y_test, preds)\n    return Smape","a88b5d78":"study_xgb = optuna.create_study(direction = 'minimize')\nstudy_xgb.optimize(objective, n_trials = 50)","cb346f1c":"best_trial = study_xgb.best_trial\nprint(best_trial.value)\nprint(best_trial.params)","c2c6c0ea":"model_xgb = xgb.XGBRegressor(**best_trial.params)\nmodel_xgb.fit(x,y)","0f5f7039":"test_df.columns","97c30bbf":"#Preprocessing test dataset\nle = LabelEncoder()\ncol_encode = ['country','store','product','is_weekend']\nfor i in col_encode:\n    test_df[i] = le.fit_transform(test_df[i])","24d89900":"test_df['week_of_year'] = test_df['week_of_year'].astype('int')","5027d3ca":"test_df.head()","1ad0cf93":"test.head()","7a2bb90a":"pred_xgb = model_xgb.predict(test_df)","7e31653a":"dataframe = pd.DataFrame({\"row_id\":test['row_id'], 'num_sold':pred_xgb})\ndataframe.head()","c4387b39":"dataframe.to_csv(\"Output_xgb_addedfeatures.csv\",index=False)","4436d730":"# Exploratory Data analysis","95491a10":"Optimizing the XGBoost","c3e75645":"Preprocessing the test dataset","b64fbee6":"## Country wise analysis","7067344b":"modelling and processing","4aab0b6d":"can't understand what's wrong with the text in this. ill deal with later"}}