{"cell_type":{"62f97fef":"code","74b32c04":"code","390f0be5":"code","fad96f99":"code","8a646e84":"code","937ec0aa":"code","ada97f4b":"code","128c27aa":"code","9a2bc384":"code","6f711f38":"code","9ab49929":"code","5ccbd597":"code","fa0b503f":"code","12d5e142":"code","5199ffb8":"code","c5460f2b":"code","5ea49149":"code","422b9dad":"code","3f61076b":"code","6671dca1":"code","d472b924":"code","b5a3e23c":"code","b6b0f603":"code","19622bc2":"code","351775ba":"code","5f1c9370":"code","45954718":"markdown","6e6c7d81":"markdown"},"source":{"62f97fef":"import numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import classification_report, log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split","74b32c04":"base_dir = '..\/input\/animals10\/raw-img'","390f0be5":"LABELS = os.listdir(base_dir)\nLABELS.sort()\nLABELS","fad96f99":"base_dir + '\/' + LABELS[0]","8a646e84":"dataset=[]\ntestset=[]\ncount=0\n\nfor label in LABELS:\n    i=0\n#     path = base_dir + '\/' + label\n    path = os.path.join(base_dir, label)\n#     print(path)\n    for img in os.listdir(path):\n#         print(img)\n        image=load_img(os.path.join(path, img), grayscale=False, color_mode='rgb', target_size=(100,100))\n        image=img_to_array(image)\n        image=image\/255.0\n        if i<1000:\n            dataset.append([image,count])\n            i+=1\n        else:\n            testset.append([image,count])\n    count=count+1","937ec0aa":"# dataset[:2]\nlen(dataset)","ada97f4b":"X,y =zip(*dataset)\ntest, test_labels=zip(*testset)","128c27aa":"len(X), len(y), len(test), len(test_labels)","9a2bc384":"y = to_categorical(y)\ny=np.array(y)\nX=np.array(X)\nprint(\"Train Shape:{}\\nTrain Labels shape: {}\".format(X.shape,y.shape))","6f711f38":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=99)","9ab49929":"X_train.shape, X_valid.shape, y_train.shape, y_valid.shape","5ccbd597":"datagen = ImageDataGenerator(\n    horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=20,\n    zoom_range=0.2,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.1,\n    fill_mode=\"nearest\"\n)","fa0b503f":"pretrained_model = tf.keras.applications.MobileNetV2(\n    input_shape=(100,100,3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)\n\npretrained_model.trainable = False","12d5e142":"inputs = pretrained_model.input\n\nm = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n\noutputs = tf.keras.layers.Dense(10, activation='softmax')(m)\n\nmn_model = tf.keras.Model(inputs=inputs, outputs=outputs)","5199ffb8":"mn_model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","c5460f2b":"hist = mn_model.fit(\n    datagen.flow(X_train, y_train, batch_size=32), \n    validation_data = (X_valid, y_valid),\n    epochs=30\n)","5ea49149":"y_pred = mn_model.predict(X_valid)\npred = np.argmax(y_pred,axis=1)\nactual = np.argmax(y_valid,axis=1)\nprint(classification_report(actual,pred))","422b9dad":"test = np.array(test)\ntest_pred = mn_model.predict(test)\n\npredictions = []\nfor p in test_pred:\n    result = np.argmax(p)      \n    predictions += [result]\n    \nprint(len(predictions))","3f61076b":"test_actuals = list(test_labels)\nlen(test_actuals)","6671dca1":"accuracy = accuracy_score(test_actuals, predictions)\nprint(accuracy)","d472b924":"image=load_img(\"..\/input\/animals10\/raw-img\/gallina\/1001.jpeg\",target_size=(100,100))\n\nimage=img_to_array(image) \nimage=image\/255.0\nprediction_image=np.array(image)\nprediction_image= np.expand_dims(image, axis=0)","b5a3e23c":"pred = mn_model.predict(prediction_image)\nvalue = np.argmax(pred)\nLABELS[value]","b6b0f603":"def predict_image(image):\n    image=img_to_array(image) \n    image=image\/255.0\n    prediction_image=np.array(image)\n    prediction_image= np.expand_dims(image, axis=0)\n    \n    pred = mn_model.predict(prediction_image)\n    value = np.argmax(pred)\n    print(\"Prediction : \", LABELS[value])","19622bc2":"image=load_img(\"..\/input\/animals10\/raw-img\/gatto\/1006.jpeg\",target_size=(100,100))\npredict_image(image)\nplt.imshow(image)\nplt.show()","351775ba":"image=load_img(\"..\/input\/animals10\/raw-img\/farfalla\/OIP--7K5JzW1ZEmrY2YRyVjFCQHaE7.jpeg\",target_size=(100,100))\npredict_image(image)\nplt.imshow(image)\nplt.show()","5f1c9370":"mn_model.save(\"animal_classify_mobilenetv2.h5\")","45954718":"# Evaluate on Test data","6e6c7d81":"# Test using single image"}}