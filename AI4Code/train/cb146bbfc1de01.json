{"cell_type":{"4139b416":"code","93f1ecf2":"code","a13362d9":"code","95d494c3":"markdown","050ace4b":"markdown","c6740ec8":"markdown","fc4bc62a":"markdown"},"source":{"4139b416":"import numpy as np\nimport matplotlib.pyplot as plt\n\nlines = np.loadtxt('..\/input\/data.csv', delimiter=',', dtype='str')\nx_total = lines[:, 1:3].astype('float')\ny_total = lines[:, 3].astype('float')\n\npos_index = np.where(y_total == 1)\nneg_index = np.where(y_total == 0)\nplt.scatter(x_total[pos_index, 0], x_total[pos_index, 1], marker='o', c='r')\nplt.scatter(x_total[neg_index, 0], x_total[neg_index, 1], marker='x', c='b')\nplt.show()\nprint('Data set size:', x_total.shape[0])","93f1ecf2":"from sklearn import linear_model\n\nlr_clf = linear_model.LogisticRegression()\nlr_clf.fit(x_total, y_total)\nprint(lr_clf.coef_[0])\nprint(lr_clf.intercept_)\n\ny_pred = lr_clf.predict(x_total)\nprint('accuracy:',(y_pred == y_total).mean())\n\nplot_x = np.linspace(-1.0, 1.0, 100)\nplot_y = - (lr_clf.coef_[0][0] * plot_x + lr_clf.intercept_[0]) \/ lr_clf.coef_[0][1]\nplt.scatter(x_total[pos_index, 0], x_total[pos_index, 1], marker='o', c='r')\nplt.scatter(x_total[neg_index, 0], x_total[neg_index, 1], marker='x', c='b')\nplt.plot(plot_x, plot_y, c='g')\nplt.show()","a13362d9":"# 1. finish function my_logistic_regression;\n# 2. draw a training curve (the x-axis represents the number of training iterations, and the y-axis represents the training loss for each round);\n# 3. draw a pic to show the result of logistic regression (just like the pic in section 2);\n\nn_iterations = 2000\nlearning_rate = 0.1\nloss_list = []\ndef my_logistic_regression(x_total, y_total):\n    # TODO\n    return y_total\n\ny_pred = my_logistic_regression(x_total, y_total)\nprint('accuracy:',(y_pred == y_total).mean())","95d494c3":"## Step 3: Gradient Descent(TO DO)\n$$\\frac{\\partial}{\\partial w_1}L(w,b)=\\frac{1}{N}\\sum\\limits_{i=1}^{N}(f(x^{(i)})-y^{(i)})x_1^{(i)}$$\n$$\\frac{\\partial}{\\partial b}L(w,b)=\\frac{1}{N}\\sum\\limits_{i=1}^{N}f(x^{(i)})-y^{(i)}$$","050ace4b":"## Step 1: Data Preparation","c6740ec8":"# Logistic Regression\nThis is the second homework of EE448. In this homework, you need to be familiar with and independently write the calculation process of logistic regression.\n+ Task: Binary classification problem\n+ Input: Two-dimensional feature\n+ Label: 1 and 0","fc4bc62a":"## Step 2: Sklearn"}}