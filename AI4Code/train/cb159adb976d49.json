{"cell_type":{"32aede3a":"code","56a84e5d":"code","74ec35e7":"code","9f953ce0":"code","a09f9dc3":"code","d75b1e2b":"code","9976475b":"code","691bc63a":"code","9501ec6b":"code","379dc661":"code","5236e8f5":"code","c97907b5":"code","36ddef6f":"code","19e422b1":"code","c6fdbc8e":"code","8491c40f":"markdown","91e91495":"markdown","5068c1d0":"markdown","1a1db530":"markdown","4bebe863":"markdown","90764cbb":"markdown","82501583":"markdown","e2089e23":"markdown","344c99d0":"markdown","216c1159":"markdown","84dce152":"markdown","587fdec3":"markdown"},"source":{"32aede3a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport cv2\nimport os\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","56a84e5d":"np.random.seed(1234)\ndirectory=\"..\/input\/fruits-360\/Training\/\"\nclasses=[\"Apple Golden 1\",\"Avocado\",\"Banana\",\"Cherry 1\",\"Cocos\",\"Kiwi\",\n         \"Lemon\",\"Mango\",\"Orange\"]\n\nall_arrays=[]\nimg_size=100\nfor i in classes:\n    path=os.path.join(directory,i)\n    class_num=classes.index(i)\n    for img in os.listdir(path):\n        #img_array=cv2.imread(os.path.join(path,img),\n        #                     cv2.IMREAD_GRAYSCALE)\n        img_array=cv2.imread(os.path.join(path,img))\n        img_array=cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n        #img_array=cv2.resize(img_array,(img_size,img_size))\n        all_arrays.append([img_array,class_num])","74ec35e7":"directory2=\"..\/input\/fruits-360\/Test\/\"\nclasses2=[\"Apple Golden 1\",\"Avocado\",\"Banana\",\"Cherry 1\",\"Cocos\",\"Kiwi\",\n         \"Lemon\",\"Mango\",\"Orange\"]\n\nall_arrays2=[]\nimg_size=100\nfor i in classes2:\n    path=os.path.join(directory2,i)\n    class_num2=classes2.index(i)\n    for img in os.listdir(path):\n        #img_array2=cv2.imread(os.path.join(path,img),\n        #                     cv2.IMREAD_GRAYSCALE)\n        img_array2=cv2.imread(os.path.join(path,img))\n        img_array2=cv2.cvtColor(img_array2, cv2.COLOR_BGR2RGB)\n        #img_array2=cv2.resize(img_array2,(img_size,img_size))\n        all_arrays2.append([img_array2,class_num2])","9f953ce0":"fruits_array_train=[]\nfor features,label in all_arrays:\n    fruits_array_train.append(features)\n\nlocation=[[1,500,1150],[1500,2000,2500],[3000,3500,4000]]\nfruit_names=[\"Apple\",\"Avocado\",\"Banana\",\"Cherry\",\"Cocos\",\"Kiwi\",\"Lemon\",\"Mango\",\"Orange\"]\na=0\nb=1\nc=2\nfor i,j,k in location:\n    plt.subplots(figsize=(8,8))\n    plt.subplot(1,3,1)\n    plt.imshow(fruits_array_train[i])\n    plt.title(fruit_names[a])\n    plt.axis(\"off\")\n    plt.subplot(1,3,2)\n    plt.imshow(fruits_array_train[j])\n    plt.title(fruit_names[b])\n    plt.axis(\"off\")\n    plt.subplot(1,3,3)\n    plt.imshow(fruits_array_train[k])\n    plt.title(fruit_names[c])\n    plt.axis(\"off\")\n    a+=3\n    b+=3\n    c+=3","a09f9dc3":"import random\nrandom.shuffle(all_arrays)\n\nX_train=[]\nY_train=[]\nfor features,label in all_arrays:\n    X_train.append(features)\n    Y_train.append(label)\nX_train=np.array(X_train) #arraying\n\nimport random\nrandom.shuffle(all_arrays2)\n\nX_test=[]\nY_test=[]\nfor features,label in all_arrays2:\n    X_test.append(features)\n    Y_test.append(label)\nX_test=np.array(X_test) #arraying\n","d75b1e2b":"#normalization and reshaping\nX_train=X_train.reshape(-1,img_size,img_size,3)\nX_train=X_train\/255\nX_test=X_test.reshape(-1,img_size,img_size,3)\nX_test=X_test\/255\nprint(\"shape of X_train= \",X_train.shape)\nprint(\"shape of X_test=  \",X_test.shape)","9976475b":"from keras.utils import to_categorical\nY_train=to_categorical(Y_train,num_classes=9)\nY_test=to_categorical(Y_test,num_classes=9)","691bc63a":"Y_train.shape","9501ec6b":"X_train.shape","379dc661":"from sklearn.model_selection import  train_test_split\nx_train,x_val,y_train,y_val=train_test_split(X_train,Y_train,test_size=0.2,random_state=42)","5236e8f5":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nmodel=Sequential()\nmodel.add(Conv2D(filters=8,kernel_size=(3,3),padding=\"Same\",activation=\"relu\",input_shape=(100,100,3)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.35))\n\nmodel.add(Conv2D(filters=16,kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Dropout(0.35))\n\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Dropout(0.35))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(9,activation=\"softmax\"))\n#defining optimizer\noptimizer=Adam(lr=0.001,beta_1=0.9,beta_2=0.999)\n#compile the model\nmodel.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\nepochs=10\nbatch_size=18","c97907b5":"datagen=ImageDataGenerator(featurewise_center=False, #set input mean to 0\n                           samplewise_center=False,  #set each sample mean to 0\n                           featurewise_std_normalization=False, #divide input datas to std\n                           samplewise_std_normalization=False,  #divide each datas to own std\n                           zca_whitening=False,  #dimension reduction\n                           rotation_range=0.5,    #rotate 5 degree\n                           zoom_range=0.5,        #zoom in-out 5%\n                           width_shift_range=0.5, #shift 5%\n                           height_shift_range=0.5,\n                           horizontal_flip=False,  #randomly flip images\n                           vertical_flip=False,\n                           )\ndatagen.fit(x_train)\n\n#model fitting\nhistory=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),epochs=epochs,\n                            validation_data=(x_val,y_val),steps_per_epoch=x_train.shape[0]\/\/batch_size\n                           )\n","36ddef6f":"plt.plot(history.history[\"val_acc\"],color=\"r\",label=\"val_acc\")\nplt.title(\"Accuracy Graph\")\nplt.xlabel(\"number of epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend()\nplt.grid()\nplt.show()","19e422b1":"#confusion matrix\ny_pred=model.predict(x_val)\ny_pred_classes=np.argmax(y_pred,axis=1)\ny_true=np.argmax(y_val,axis=1)\n#compute conf mat\nconf_mat=confusion_matrix(y_true,y_pred_classes)\n#plot the con mat\nfruit_names=[\"Apple\",\"Avocado\",\"Banana\",\"Cherry\",\"Cocos\",\"Kiwi\",\"Lemon\",\"Mango\",\"Orange\"]\nf,ax=plt.subplots(figsize=(10,9))\nsns.heatmap(conf_mat,annot=True,fmt='.0f')\nax.set_xticklabels(fruit_names)\nax.set_yticklabels(fruit_names)\nplt.show()\n","c6fdbc8e":"#confusion matrix\ny_pred2=model.predict(X_test)\ny_pred_classes2=np.argmax(y_pred2,axis=1)\ny_true2=np.argmax(Y_test,axis=1)\n#compute conf mat\nconf_mat2=confusion_matrix(y_true2,y_pred_classes2)\n#plot the con mat\nf,ax=plt.subplots(figsize=(10,9))\nsns.heatmap(conf_mat2,annot=True,fmt=\".0f\")\nax.set_xticklabels(fruit_names)\nax.set_yticklabels(fruit_names)\nplt.show()\n","8491c40f":"While reshaping we added RGB scale.","91e91495":"We created our X features and Y labels. Also we used shuffle function to mix our dataset.","5068c1d0":"We can see error values on validation data","1a1db530":"**Image examples of our data:**","4bebe863":"With train_test_split we separated our datas to train and validation datas.","90764cbb":"At the beginning we had only images, not any dataframe or any array from. We used os and cv2 libraries to created our array form. ","82501583":"We connected our labels-layers with keras library. With Dense we added hidden layers. We avoided overfitting thanks to Dropout. With relu function we don't have variance around zero.","e2089e23":"Here we checked error on test data. We almost no have false detection in test set except false results of Banana and Lemon classes","344c99d0":"In conclusion we used CNN method to check nine types of fruit. We have training accuracy around 95% and it is really acceptable.\nIf you have any question feel free to contact with me.","216c1159":"We converted our labels to one-hot-encoding values. 3 ----->(0,0,0,1,0,0,0,0,0,0) etc","84dce152":"Let's go with data augmentation. In this section we add different shapes of our images. We will use **zooming,shifting,rotating,fliping** methods in order to avoid **overfitting**.                                                             \nFor example we will add a image of banana with 5 degrees rotated.","587fdec3":"After 15 iteration we have a high accuracy around 96%"}}