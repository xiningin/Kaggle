{"cell_type":{"70d7d360":"code","f21abc6c":"code","7c0167fc":"code","03838932":"code","741f700d":"code","55c107f5":"code","d093b36e":"code","e2ff6456":"code","7a751f8d":"code","c9bbc8c4":"code","7ce8475b":"code","8a36b0a6":"code","fe8b0e92":"markdown","f1eb0bcf":"markdown","50527b01":"markdown","4f7f05aa":"markdown","056b08e7":"markdown","e41b6b6f":"markdown","1592f646":"markdown","534396ac":"markdown","7907f9a1":"markdown","e7d6f3ac":"markdown"},"source":{"70d7d360":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom mpl_toolkits.mplot3d import proj3d\nfrom imageio import imread\nfrom skimage.transform import resize\nfrom scipy.spatial import distance\nfrom keras.models import load_model\nimport pandas as pd\nfrom tqdm import tqdm","f21abc6c":"model_path = '..\/input\/facenetmodel\/keras-facenet\/facenet_keras.h5'\nmodel = load_model(model_path)","7c0167fc":"def prewhiten(x):\n    if x.ndim == 4:\n        axis = (1, 2, 3)\n        size = x[0].size\n    elif x.ndim == 3:\n        axis = (0, 1, 2)\n        size = x.size\n    else:\n        raise ValueError('Dimension should be 3 or 4')\n\n    mean = np.mean(x, axis=axis, keepdims=True)\n    std = np.std(x, axis=axis, keepdims=True)\n    std_adj = np.maximum(std, 1.0\/np.sqrt(size))\n    y = (x - mean) \/ std_adj\n    return y\n\ndef l2_normalize(x, axis=-1, epsilon=1e-10):\n    output = x \/ np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n    return output\n\ndef load_and_align_images(filepaths, margin,image_size = 160):\n    \n    aligned_images = []\n    for filepath in filepaths:\n        img = imread(filepath)\n        aligned = resize(img, (image_size, image_size), mode='reflect')\n        aligned_images.append(aligned)\n            \n    return np.array(aligned_images)\n\n","03838932":"def calc_embs(filepaths, margin=10, batch_size=512):\n    pd = []\n    for start in tqdm(range(0, len(filepaths), batch_size)):\n        aligned_images = prewhiten(load_and_align_images(filepaths[start:start+batch_size], margin))\n        pd.append(model.predict_on_batch(aligned_images))\n    embs = l2_normalize(np.concatenate(pd))\n\n    return embs","741f700d":"test_path = '..\/input\/vn-celeb-face-recognition\/vn_celeb_face_recognition\/test\/'\ntrain_path = '..\/input\/vn-celeb-face-recognition\/vn_celeb_face_recognition\/train\/'\n\ntrain_df = pd.read_csv('..\/input\/vn-celeb-face-recognition\/vn_celeb_face_recognition\/train.csv')\ntest_df = pd.read_csv('..\/input\/vn-celeb-face-recognition\/vn_celeb_face_recognition\/sample_submission.csv')","55c107f5":"train_embs = calc_embs([os.path.join(train_path, f) for f in train_df.image.values])\nnp.save(\"train_embs.npy\", train_embs)","d093b36e":"test_embs = calc_embs([os.path.join(test_path, f) for f in test_df.image.values])\nnp.save(\"test_embs.npy\", test_embs)","e2ff6456":"# indices which belong to each label\nlabel2idx = []\n\nfor i in tqdm(range(1000)):\n    label2idx.append(np.asarray(train_df[train_df.label == i].index))","7a751f8d":"import matplotlib.pyplot as plt\n\nmatch_distances = []\nfor i in range(1000):\n    ids = label2idx[i]\n    distances = []\n    for j in range(len(ids) - 1):\n        for k in range(j + 1, len(ids)):\n            distances.append(distance.euclidean(train_embs[ids[j]], train_embs[ids[k]]))\n    match_distances.extend(distances)\n    \nunmatch_distances = []\nfor i in range(1000):\n    ids = label2idx[i]\n    distances = []\n    for j in range(5):\n        idx = np.random.randint(train_embs.shape[0])\n        while idx in label2idx[i]:\n            idx = np.random.randint(train_embs.shape[0])\n        distances.append(distance.euclidean(train_embs[ids[np.random.randint(len(ids))]], train_embs[idx]))\n    unmatch_distances.extend(distances)\n    \n_,_,_=plt.hist(match_distances,bins=100)\n_,_,_=plt.hist(unmatch_distances,bins=100,fc=(1, 0, 0, 0.5))","c9bbc8c4":"threshold = 1.1","7ce8475b":"for i in tqdm(range(len(test_df.image))):\n    distances = []\n    for j in range(1000):\n        distances.append(np.min([distance.euclidean(test_embs[i], train_embs[k]) for k in label2idx[j]]))\n    distances.append(threshold)\n    test_df.loc[i].label = ' '.join([str(p) for p in np.argsort(distances)[:5]])","8a36b0a6":"test_df.to_csv(\"sub.csv\", index=False)","fe8b0e92":"Load c\u00e1c file metadata","f1eb0bcf":"# AIviVN Celebs Re-identification Baseline\n\n## Ph\u01b0\u01a1ng ph\u00e1p chung\n\nR\u1ea5t \u0111\u01a1n gi\u1ea3n th\u00f4i, m\u00ecnh s\u1eed d\u1ee5ng pretrained facenet t\u1eeb repo n\u00e0y https:\/\/github.com\/nyoki-mtl\/keras-facenet . T\u00ednh embedding cho m\u1ed7i \u1ea3nh, so s\u00e1nh m\u1ed7i embedding m\u1ed7i \u1ea3nh trong t\u1eadp test v\u1edbi t\u1eebng nh\u00f3m c\u00e1c embeddings thu\u1ed9c c\u00f9ng m\u1ed9t ng\u01b0\u1eddi trong t\u1eadp train, t\u00ecm ra kho\u1ea3ng c\u00e1ch ng\u1eafn nh\u1ea5t c\u1ee7a m\u1ed7i \u1ea3nh \u0111\u1ebfn m\u1ed7i ng\u01b0\u1eddi","50527b01":"M\u00ecnh s\u1ebd ch\u1ecdn ch\u1ed7 giao nhau gi\u1eefa 2 th\u1eb1ng t\u1ee9c l\u00e0 t\u1ea7m 1.1","4f7f05aa":"T\u00ednh to\u00e1n kho\u1ea3ng c\u00e1ch gi\u1eefa 2 t\u1eadp v\u00e0 \u0111\u01b0a ra d\u1ef1 \u0111o\u00e1n.","056b08e7":"L\u1ecdc ra t\u1eadp c\u00e1c index trong file train.csv ch\u1ee9a c\u00f9ng 1 label (t\u1eeb 0 - 999), ti\u1ec7n cho t\u00ednh to\u00e1n b\u00ean d\u01b0\u1edbi","e41b6b6f":"\u0110\u1ec3 ch\u00e8n class 1000 v\u00e0o d\u1ef1 \u0111o\u00e1n, m\u00ecnh d\u00f9ng 1 ph\u01b0\u01a1ng ph\u00e1p \u0111\u01a1n gi\u1ea3n l\u00e0 d\u00f9ng ng\u01b0\u1ee1ng.\n\n\u0110\u1ea7u ti\u00ean m\u00ecnh s\u1ebd v\u1ebd ph\u00e2n ph\u1ed1i x\u00e1c su\u1ea5t c\u1ee7a 2 bi\u1ebfn:\n\n- Kho\u1ea3ng c\u00e1ch euclide gi\u1eefa 2 \u1ea3nh n\u1ebfu ch\u00fang thu\u1ed9c c\u00f9ng m\u1ed9t m\u1eb7t.\n\n- Kho\u1ea3ng c\u00e1ch euclide gi\u1eefa 2 \u1ea3nh n\u1ebfu ch\u00fang thu\u1ed9c 2 m\u1eb7t kh\u00e1c nhau.\n\nM\u1ee5c \u0111\u00edch l\u00e0 t\u00ecm 1 kho\u1ea3ng c\u00e1ch th\u00edch h\u1ee3p \u0111\u1ec3 n\u1ebfu kho\u1ea3ng c\u00e1ch t\u1eeb 1 \u1ea3nh \u0111\u1ebfn t\u1ea5t c\u1ea3 c\u00e1c \u1ea3nh \u0111\u1ec1u cao h\u01a1n n\u00f3 th\u00ec s\u1ebd kh\u1eb3ng \u0111\u1ecbnh n\u00f3 l\u00e0 unkown v\u1eady th\u00f4i.","1592f646":"Load model train s\u1eb5n l\u00ean","534396ac":"C\u00e1c b\u01b0\u1edbc load \u1ea3nh v\u00e0 chu\u1ea9n h\u00f3a tr\u01b0\u1edbc khi cho v\u00e0o m\u1ea1ng.","7907f9a1":"H\u00e0m t\u00ednh embedding, trong code g\u1ed1c \u0111\u1ec3 `l2_normalize` n\u00ean m\u00ecnh c\u0169ng \u0111\u1ec3 nguy\u00ean v\u1eady","e7d6f3ac":"B\u00e2y gi\u1edd ta t\u00ednh embeddings cho t\u1ea5t c\u1ea3 c\u00e1c \u1ea3nh trong t\u1eadp train c\u0169ng nh\u01b0 t\u1eadp test"}}