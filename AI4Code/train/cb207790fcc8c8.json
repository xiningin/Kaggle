{"cell_type":{"e494debb":"code","f797cffe":"code","198eef1d":"code","9605e964":"code","a57ab4fd":"code","ec9959f5":"code","e487e6a9":"code","e499d969":"code","3c65bf16":"code","e11d72dc":"code","442beb0b":"code","f644fc7f":"code","5fe1fb00":"code","6521aea3":"code","9f03ef00":"markdown","38c7d5aa":"markdown","3d9090d8":"markdown"},"source":{"e494debb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport json\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f797cffe":"# import tensorflow.compat.v1.keras.backend as K\n# import tensorflow as tf\n# tf.compat.v1.disable_eager_execution()","198eef1d":"# num = int(df[df['image_id'] == '1000015157.jpg']['label'])\n# num\n\n\n# df = df.set_index(\"image_id\")\n# int(df.loc[[\"999329392.jpg\"]]['label'])","9605e964":"\n# # ---- This works!!!! Converts jpg into array easily\n# def parse_image(file):\n    \n\n\n#     img = tf.io.read_file(file)\n#     img = tf.image.decode_jpeg(img, channels=3)\n    \n#     img = tf.image.convert_image_dtype(img, tf.float32)\n#     img = tf.image.resize(img, size=(600, 800))\n\n#     return img, image_id\n\n# dataset = tf.data.Dataset.list_files(\"\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/*.jpg\")\n\n# dataset = dataset.map(parse_image)\n\n# dataset = dataset.shuffle(20)\n# dataset = dataset.batch(16)\n\n# dataset","a57ab4fd":"# ---- Need to add label\ndef parse_image(dataset_slice):\n    file = dataset_slice['image_id']\n    label = dataset_slice['label']\n    \n#     image_id = str(file).split(\".jpg\")[0][12:]\n#     #image_id = str(file).split(\"', shape\")[0][12:]\n    \n#     #int(df.loc[[image_id]]['label'])\n    \n    # now slicing tensor as a string isn't working, but using the file directly seems to be fine\n    img = tf.io.read_file(\"\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/\" + file)#+ image_id + \".jpg\")\n    img = tf.image.decode_jpeg(img, channels=3)\n    \n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, size=(300, 400))\n    \n\n    return img, label\n\n\n\ndf = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\")\ndataset = tf.data.Dataset.from_tensor_slices(dict(df))\n\ndataset = dataset.map(parse_image)\n\n\n# Old way that also worked (except it didn't know the shape)\n\n# from PIL import Image\n# def parse_image(file):\n#     file = bytes.decode(file.numpy())\n    \n#     image = tf.constant(np.asarray(Image.open(file)))\n#     return image\n\n#dataset = dataset.map(lambda x: tf.py_function(parse_image, [x], [tf.uint8]))\n\n\ndataset = dataset.shuffle(20)\ndataset = dataset.batch(20)\n# for item in dataset.take(1):\n#     print(str(item['image_id']))\ndataset","ec9959f5":"next(iter(dataset))","e487e6a9":"tensor = next(iter(dataset))[0][0]\ntensor","e499d969":"model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation=tf.nn.relu),\n                                    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n                                    tf.keras.layers.Dropout(.1),\n                                    \n                                    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=tf.nn.relu),\n                                    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n                                    tf.keras.layers.Dropout(.1),\n                                    \n#                                     tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=tf.nn.relu),\n#                                     tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n#                                     tf.keras.layers.Dropout(.1),\n                                    tf.keras.layers.Flatten(),\n                                    \n#                                    tf.keras.layers.Dense(8192, activation=tf.nn.relu),\n                                    tf.keras.layers.Dropout(.1),\n                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n                                    tf.keras.layers.Dropout(.1),\n                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n                                    tf.keras.layers.Dropout(.1),\n                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax),\n                                    \n])\nmodel.build((None, 300, 400, 3))\nmodel.summary()","3c65bf16":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(dataset, epochs=10, verbose=1)","e11d72dc":"!pip install -q pyyaml h5py","442beb0b":"model.save('simple_conv2d_cassava')\nnew_model = tf.keras.models.load_model('simple_conv2d_cassava')\n","f644fc7f":"# old attempts to use dataset\n\n\n# df = pd.read_csv(\"\/kaggle\/input\/cassava-leaf-disease-classification\/train.csv\")\n# df['image_id']\n\n# dataset = tf.data.Dataset.from_tensor_slices(dict(df))\n\n# test = dataset.map(parse_image)\n\n#training_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2, preprocessing_function=parse_image(dataset.take(1)))\n\n# print(dataset.take(1))\n\n# model.fit_generator(generator=training_generator, epochs=5, verbose =1)\n\n\n# fits the model on batches with real-time data augmentation:\n# model.fit(datagen.flow(x_train, y_train, batch_size=32),\n#           steps_per_epoch=len(x_train) \/ 32, epochs=epochs)\n\n# tf.keras.preprocessing.image.ImageDataGenerator(\n#     featurewise_center=False,\n#     samplewise_center=False,\n#     featurewise_std_normalization=False,\n#     samplewise_std_normalization=False,\n#     zca_whitening=False,\n#     zca_epsilon=1e-06,\n#     rotation_range=0,\n#     width_shift_range=0.0,\n#     height_shift_range=0.0,\n#     brightness_range=None,\n#     shear_range=0.0,\n#     zoom_range=0.0,\n#     channel_shift_range=0.0,\n#     fill_mode=\"nearest\",\n#     cval=0.0,\n#     horizontal_flip=False,\n#     vertical_flip=False,\n#     rescale=None,\n#     preprocessing_function=None,\n#     data_format=None,\n#     validation_split=0.0,\n#     dtype=None,\n# )\n\n\n\n#dataset_pixels = dataset.map(parse_image)\n\n# for image in dataset_pixels.take(2):\n#     print(image.numpy().decode('utf-8'))\n\n\n\n# ------------------------------------------------------------- #\n\n# Way to decode tensor\n# for feature_batch in dataset.take(1):\n#     print(feature_batch['image_id'].numpy())\n#     var = feature_batch['image_id'].numpy().decode('utf-8')\n#     print(var)\n    \n    \n# ------------------------------------------------------------- #\n\n    \n    \n    \n    \n    \n    \n    \n    \n    \n#     for key, value in feature_batch.items():\n\n#         print(\"  {!r:20s}: {}\".format(key, value))\n        \n        \n# dataset_process = dataset.map(parse_image)\n\n    \n# for pixels in dataset_process.take(2):\n#     print(pixels)\n        \n\n\n#df['image_id'] = df['image_id'].str.replace(r'.jpg', '')\n#print(type(df['label'][0]))\n#dataset = tf.convert_to_tensor(df, dtype=tf.int64)\n#tf.convert_to_tensor(my_np_array, dtype=tf.float32)\n\n#type(dataset)","5fe1fb00":"# from PIL import Image\n\n# # converts to pixeks\n# img = np.asarray(Image.open(\"\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/1578977008.jpg\"))\n# img.shape\n\n# #image_pixels = pd.Series()\n\n\n\n# def parse_image(file_name):\n#     print(file_name.numpy())\n#     print(tf.strings.as_string(file_name['image_id']))\n# #    print(file_name['image_id'].as_string())\n# #     #print(tf.io.decode_raw(file_name['image_id'], tf.uint8))\n    \n# # #     unicode_char_bytes = tf.strings.unicode_split(file_name['image_id'], \"UTF-8\")\n# # #     print(unicode_char_bytes)\n# #     unicode_values = tf.strings.unicode_decode(file_name['image_id'], \"UTF-8\")\n# #     print(unicode_values)\n\n    \n# #     #print(file_name['image_id'].decode('utf-8'))\n# #     print(bytes.decode(file_name['image_id']))\n#     # get string of filename\n#     file = file_name['image_id'].numpy().decode('utf-8')\n#     return np.asarray(Image.open(\"\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/\" + str(file)))\n    \n\n# #image_data_list = parse_image(df['image_id'][0])","6521aea3":"# plt.figure(figsize=(15,10))\n\n# for i in range(1,10):\n#     plt.subplot(3,3,i)\n#     plt.tight_layout()\n\n#     plt.imshow(df1.iloc[i-1, 1])\n#     plt.title(label_dict[str(df1.iloc[i-1, 0])])\n\n#     #plt.colorbar()\n#     plt.grid(False)\n\n# plt.show()","9f03ef00":"convert np array to tensor: ```tf.convert_to_tensor(my_np_array, dtype=tf.float32)```\n","38c7d5aa":"## Model Creation and Training","3d9090d8":"-- the below was just using cpu, using GPU takes 1\/10th the time\n\n### First Run\n*ETA 67 min for one epoch*\n- Batch-size = 16\n- image size was (600, 800)\n- Simple model, one conv2d, pool, flatten, and 2 dense layers\n\nMax accuracy after 2nd-3rd epoch: ~60%, loss @ 1.222 (see downloaded ss)\n\n### Second Run\nBatch-size = 32 --> OOM error\n\n### Third Run\n*ETA 47 min for one epoch*\n- Batch-size = 20\n- image size = (300, 400)\n- more complex model, 2 conv2D and pool, flatten and 3 dense layers (1024, 128, 5)\nalmost done with 5th epoch: accuracy - 94.5%, loss 0.1679\n"}}