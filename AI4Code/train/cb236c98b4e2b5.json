{"cell_type":{"8e372c74":"code","6dd37ea7":"code","a5eb357a":"code","0bbfe84b":"code","173e8df1":"code","68aaaa3f":"code","1c577dc3":"code","8e412deb":"code","ea1fde68":"code","f50a91c1":"code","bafc8a16":"code","3a222345":"code","59e4c8cf":"code","d5486eb8":"code","5a0f8a9f":"code","93f8d8e7":"code","87bc7d14":"code","a544a0ab":"code","25f30f58":"code","a294c6b6":"code","a917761d":"code","a767b90a":"code","8e264fd9":"code","75b0929f":"code","2c6d5425":"code","69332b5e":"code","c04a268a":"code","6b924507":"code","33d288d2":"code","c4ae05ea":"code","f4a4dd6c":"code","74249c3e":"code","c58de01b":"code","61a96da7":"code","412ae4f5":"code","d0caf3b3":"code","2354a0cc":"code","78484563":"code","5bb81759":"code","d6d61079":"code","b3253fbe":"code","d96b0b40":"code","34323fd6":"code","8058520b":"code","5677b4f5":"code","e3cf07e8":"code","8fc37e64":"code","53b7eb05":"code","f56ef7cc":"code","59a05c60":"code","be525dba":"code","46ae05a3":"code","5f3b2050":"markdown","12bb6fa3":"markdown","93d93796":"markdown","80f8b742":"markdown","3bd97083":"markdown","ccac8021":"markdown","a356bcf6":"markdown","16a13144":"markdown","301ac00c":"markdown","c9507eea":"markdown","bf68b6b5":"markdown","271c5273":"markdown","2bd7b4e0":"markdown","5dac4444":"markdown","a1bbe77c":"markdown","cc4eaf6c":"markdown","b506f09e":"markdown","75bfa2cb":"markdown","051d4cee":"markdown","487c4a13":"markdown","f24043f9":"markdown","0ab3c54b":"markdown","2976d914":"markdown","0cf88cbd":"markdown","a8d96a9f":"markdown","e34d2b4a":"markdown","42ed734c":"markdown","bff3f986":"markdown"},"source":{"8e372c74":"#import libraries \n\n#structures\nimport pandas as pd\nimport numpy as np\n\n#visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport math\nimport seaborn as sns\nsns.set()\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#get model duration\nimport time\nfrom datetime import date\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6dd37ea7":"#load dataset\ndata = '..\/input\/titanicdataset-traincsv\/train.csv'\ndataset = pd.read_csv(data)\ndataset.shape","a5eb357a":"dataset.dtypes","0bbfe84b":"dataset.describe()","173e8df1":"dataset.head(10)","68aaaa3f":"print(\"Total number of passengers in the dataset: \" + str(len(dataset.index)))","1c577dc3":"sns.countplot(x=\"Survived\", data=dataset)","8e412deb":"sns.countplot(x=\"Survived\", hue=\"Sex\", data=dataset)","ea1fde68":"sns.countplot(x=\"Survived\", hue=\"Pclass\", data=dataset)","f50a91c1":"dataset[\"Age\"].plot.hist()","bafc8a16":"sns.boxplot(x=\"Survived\", y=\"Age\", data=dataset)","3a222345":"dataset[\"Pclass\"].plot.hist()","59e4c8cf":"sns.boxplot(x=\"Pclass\", y=\"Age\", data=dataset)","d5486eb8":"dataset[\"Fare\"].plot.hist(figsize=(10,10))","5a0f8a9f":"dataset.info()","93f8d8e7":"sns.countplot(x=\"SibSp\", data=dataset)","87bc7d14":"sns.countplot(x=\"Parch\", data=dataset)","a544a0ab":"dataset.isnull()","25f30f58":"dataset.isnull().sum()","a294c6b6":"sns.heatmap(dataset.isnull(), yticklabels=False, cmap=\"viridis\")","a917761d":"dataset.head()","a767b90a":"#dropping 'Cabin' feature\ndataset.drop(\"Cabin\", axis=1, inplace=True)","8e264fd9":"#check if the 'Cabin' feature is dropped\ndataset.head()","75b0929f":"sns.heatmap(dataset.isnull(), yticklabels=False, cmap=\"viridis\")","2c6d5425":"#dropping rows of data with 'Age' null\ndataset.dropna(inplace=True)","69332b5e":"sns.heatmap(dataset.isnull(), yticklabels=False, cmap=\"viridis\")","c04a268a":"#checking if any more null value in the dataset\ndataset.isnull().sum()","6b924507":"dataset.shape","33d288d2":"dataset.head()","c4ae05ea":"dataset.Pclass.unique()","f4a4dd6c":"dataset.Sex.unique()","74249c3e":"dataset.Embarked.unique()","c58de01b":"Pcl=pd.get_dummies(dataset[\"Pclass\"],drop_first=True)\nPcl.head()","61a96da7":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nX = dataset\na = dataset['Sex']\n\nX['Sex'] = le.fit_transform(X['Sex'])\n\na = le.transform(a)\ndataset = X","412ae4f5":"embark=pd.get_dummies(dataset[\"Embarked\"])\nembark.head()","d0caf3b3":"dataset=pd.concat([dataset,embark,Pcl],axis=1)\ndataset.head()","2354a0cc":"dataset.drop(['PassengerId','Pclass', 'Name','Ticket','Embarked'],axis=1, inplace=True)\ndataset.head()","78484563":"#get correlation map\ncorr_mat=dataset.corr()","5bb81759":"#visualise data\nplt.figure(figsize=(13,5))\nsns_plot=sns.heatmap(data=corr_mat, annot=True, cmap='GnBu')\nplt.show()","d6d61079":"# Train\nX = dataset.drop(\"Survived\", axis=1)\ny = dataset[\"Survived\"]","b3253fbe":"from sklearn.model_selection import train_test_split","d96b0b40":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)","34323fd6":"from sklearn.linear_model import LogisticRegression","8058520b":"logmodel=LogisticRegression()","5677b4f5":"logmodel.fit(X_train,y_train)","e3cf07e8":"predictions = logmodel.predict(X_test)\nprint(predictions)","8fc37e64":"from sklearn.metrics import classification_report","53b7eb05":"print(classification_report(y_test,predictions))","f56ef7cc":"from sklearn.metrics import confusion_matrix","59a05c60":"confusion_matrix(y_test, predictions)","be525dba":"from sklearn.metrics import accuracy_score ","46ae05a3":"accuracy_score(y_test,predictions) #(0+1)\/(0+1+1+3) = 0.2","5f3b2050":"We have 3 unique values. <br>\nSo we can convert 'Pclass' feature into 2 columns '2' for 2nd Class & '3' for 3rd Class with 0 for No & 1 for Yes values. <br>\n0 in both of these columns will be automatically 1st class.","12bb6fa3":"# Description of data","93d93796":"My understanding on a logistics regression is that it is a classification model and it produces results in a binary format (discrete\/categorical). <br> <br>\nMeans the prediction will be in 0 or 1, Yes or No etc. which is very fitting in this Titanic scenario where the result we want to find out is alive or not.","80f8b742":"# Logistics Regression","3bd97083":"The titanic train data consists of 891 rows and 12 columns.","ccac8021":"Lets drop the redundant columns which includes 'PassengerId', 'Pclass', 'Name', 'Ticket' & 'Embarked'.","a356bcf6":"We can convert 'Embarked' feature into 3 columns 'S', 'C', 'Q' with 0 for No & 1 for Yes values.","16a13144":"So we have following confusion matrix values: <br> <br>\n\nPredicted No:Actual No: 140 <br>\nPredicted No:Actual Yes: 32 <br> <br>\n\nPredicted Yes:Actual No: 30 <br>\nPredicted Yes:Actual Yes: 83 <br> <br>\n\nLets look at Sensitivity & Specificity values. <br> <br>\n\nSensitivity = (Predicted No:Actual No value)\/(Total No) = 140\/172 = 0.814 <br> <br>\n\nSpecificity = (Predicted Yes:Actual Yes value)\/(Total Yes) = 83\/113 = 0.735 <br> <br>\n\nWe have higher Sensitivity score over Specificity score. So we can conclude our model is better at predicting the number of people who do no survive the incident.","301ac00c":"We can see average population of passengers on the titanic are young to middle age group.","c9507eea":"# Pearson's Correlation","bf68b6b5":"We can see that older population of passengers are more likely to be in Passenger Class 1 & Class 2 than Class 3.","271c5273":"We have 2 unique values only. So we can convert 'Sex' feature values into '0' for female & '1' for male.","2bd7b4e0":"So we can see most of the passengers on Titanic are 3rd class passengers.","5dac4444":"We can see that younger people tend to have a slightly higher survival rate than the older counterpart.","a1bbe77c":"First, lets check how many unique values in each of these features.","cc4eaf6c":"## Train & Test Data","b506f09e":"We can see only one third of the total passengers survived the incident.","75bfa2cb":"# Analyzing Data","051d4cee":"The death rate of 3rd class passengers are much higher than the other 2 passenger classes. <br>\nAgain, with a reference to the Titanic movie, 3rd class passengers are staying at the lowest level of the ship and they have longer route to get to the top when the ship was sinking.","487c4a13":"# Cleaning Data","f24043f9":"We are left with 712 data points which is plenty.","0ab3c54b":"# Importing Libraries","2976d914":"**Data Definitions** <br> <br>\n\n* PassengerId - Unique Id of each passenger on the ship\n* Survived - '0' for not survived & '1' for survived\n* Pclass - Passenger class: '1' for 1st class, '2' for 2nd class & '3' for 3rd class\n* Name - Passenger name\n* Sex - Passenger gender: 'male' or 'female'\n* Age - Passenger age\n* SibSp - No. of siblings or spouses aborded Titanic together with the passenger\n* Parch - No. of parents or children aborded Titanic together with the passenger\n* Ticket - Passenger ticket number\n* Fare - Passenger ticket fare\n* Cabin - Passenger cabin number\n* Embarked - Encoded name of city passenger embarked","0cf88cbd":"We can see females have a higher survival rate than males in this scenario. <br>\nBased on the Titanic movie, they arranged females and children to board the lifeboats so it makes sense, I guess.","a8d96a9f":"As we can see, there are many null values under 'Cabin' column. <br>\n\n687 out of 891 data points is a really high amount. Also there are quite a number of null values under age. <br>\n\nThis will surely affect the prediction results if left unhandled. <br>\n\nHandling null values in dataset has two approaches. We can determine the null value at a given point by averaging out the surrounding values under the feature. However, this only works given that the data is an ordinal data and we know that it is in either ascending or descending order or have some sort of pattern. In our case,  it is not. And same for the 'Cabin' feature as well which actually looks like a nominal data. <br>\n\nTherefore, I decided to remove 177 lines of data from Age along with the whole column of 'Cabin' from the dataset.","e34d2b4a":"So now it is confirmed that the dataset is clean without any null value.","42ed734c":"Based on the 2 graphs above, we can conclude most of the passengers on titanic are single passengers and the 2nd most are most likely couples. <br> <br>\n\nThis sounds plausible because as we already saw above that most of the passengers on Titanic are 3rd class passengers and normally, when you are travelling with a family or a spouse, you definitely don't want to choose a 3rd class unless you have no choice.","bff3f986":"Now we need to convert features: \"Pclass\", \"Sex\" & \"Embarked\" into categorical binary data which is 0 & 1 or True or False or something along. We have 2 options: we can use a label encoder or we can use a pandas method as well."}}