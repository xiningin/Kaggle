{"cell_type":{"0776feb2":"code","d50f48de":"code","b3675fa2":"code","b0b1a83f":"code","34c0f1b7":"code","ccb9ffb5":"code","fcebf535":"code","89d4227f":"code","0b5150e0":"code","52f0efa5":"code","9682fe0e":"code","fe16535b":"code","768f57f7":"code","eda624e7":"code","d9ed0186":"code","57b6ec0d":"code","f771c294":"code","5f72bfa4":"code","fc6a0369":"code","ea92d312":"code","5883ef28":"code","2b7319f0":"code","0f79ba49":"code","5d111229":"code","d47e6f88":"code","b332ad1c":"code","56f09208":"code","d46ebddf":"code","7c074f33":"code","90f18fe2":"code","0873bbfe":"code","a528ee60":"code","da27d132":"code","bbb04401":"code","f13b8427":"code","5d6d586b":"code","9deeae1a":"code","590b5fa3":"code","471df6b9":"code","fc648838":"code","606212bb":"code","eaec8734":"code","e1ef4c46":"code","cb58f29a":"code","e52c0bdb":"code","57e1f86f":"code","7ea170a6":"code","ced5c0b4":"code","216dcdcd":"code","5418a49d":"code","5834bfe6":"code","0f4179b3":"code","d7950e0f":"code","cc454a01":"markdown","06f699eb":"markdown","5ddd653e":"markdown","68b41aa9":"markdown","810fb262":"markdown","d1b54f36":"markdown","a64c902c":"markdown","d74f0b41":"markdown","ce779605":"markdown","f7a540b7":"markdown","5968fb24":"markdown","8c843d8c":"markdown","cdf83610":"markdown","3072a5a6":"markdown","2ee6a2c9":"markdown","93c28218":"markdown"},"source":{"0776feb2":"import numpy as np # linear algebra\nimport pandas as pd # dataframes\nimport matplotlib # helping the plotting\nimport matplotlib.pyplot as plt  \nimport missingno as mno # plot missing numbers\nimport seaborn as sns \nsns.set_style('darkgrid')\nimport plotly.express as px\nimport matplotlib.colors as cl\n\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier as Knn\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\n# imbalanced learn\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import ADASYN\nfrom imblearn.metrics import classification_report_imbalanced\n\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report , confusion_matrix\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\n# to ignore those pesky warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","d50f48de":"raw_data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\nraw_data.head()","b3675fa2":"raw_data.describe()","b0b1a83f":"raw_data.info()","34c0f1b7":"# color palette for visualizations\ncolors = ['#FFE459','#F43B86','#3D087B','#11052C','black']\npalette = sns.color_palette( palette = colors)\n\nsns.palplot(palette,size=3)\nplt.text(-0.75,-0.75,'Color Palette for this Visualization', {'fontname':'serif', 'size':25, 'weight':'bold'})\nplt.text(-0.75,-0.64,'Mostly same colors will be used for throughout this notebook.', {'fontname':'serif', 'size':18, 'weight':'normal'}, alpha = 0.8)\nplt.show()","ccb9ffb5":"mno.bar(raw_data,color=colors[0])","fcebf535":"x = pd.DataFrame( raw_data.groupby(['Class'])['Class'].count())\n\n# plot\nfig, ax = plt.subplots(figsize = (14,6), dpi=70 )\nax.barh([0], x.Class[0], height = 0.7, color = colors[0])\n# plt.text(-1,0.88, 'Not Fraud',{'fontname': 'Serif','weight':'bold','Size': '16','style':'normal', 'color':colors[0]})\nplt.text(290000,0.08, '99.8%',{'fontname':'Serif','weight':'bold' ,'size':'16','color': colors[0]})\nax.barh([1], x.Class[1], height = 0.7, color = colors[3])\n# plt.text(-10,1, 'Fraud', {'fontname': 'Serif','weight':'bold','Size': '16','style':'normal', 'color': colors[3]})\nplt.text(3900,1, '0.17%',{'fontname':'Serif', 'weight':'bold','size':'16','color':colors[3]})\n\nfig.patch.set_facecolor('white')\nax.set_facecolor('white')\n\nplt.text(-150,1.77, 'Percentage of People surviving' ,{'fontname': 'Serif', 'Size': '25','weight':'bold', 'color':'black'})\nplt.text(150000,1.55, 'Not Fraud ', {'fontname': 'Serif','weight':'bold','Size': '14','weight':'bold','style':'normal', 'color':colors[0]})\nplt.text(185000,1.55, '|', {'color':'black' , 'size':'16', 'weight': 'bold'})\nplt.text(190000,1.55, 'Fraud', {'fontname': 'Serif','weight':'bold', 'Size': '14','style':'normal', 'weight':'bold','color':colors[3]})\n\nax.axes.get_xaxis().set_visible(False)\nax.axes.get_yaxis().set_visible(False)\nax.spines['bottom'].set_visible(False)\nax.spines['left'].set_visible(True)\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)","89d4227f":"fig,ax = plt.subplots(1,2,figsize=(19,8))\nax[0].set_title(\"Distribution of time\")\nsns.kdeplot(raw_data.Time,ax=ax[0],color=colors[0],shade=True)\n\nax[1].set_title(\"Distribution of time according to classes\")\nsns.kdeplot(raw_data[raw_data['Class']==0]['Time'],ax=ax[1],color = colors[1],legend=True,shade=True,alpha=1)\nsns.kdeplot(raw_data[raw_data['Class']==1]['Time'],ax=ax[1],color = colors[3],shade=True,legend=True,alpha=0.8)","0b5150e0":"fig,ax = plt.subplots(1,2,figsize=(19,8))\nax[0].set_title(\"Distribution of Amount\")\nsns.kdeplot(raw_data.Amount,ax=ax[0],color=colors[0],shade=True)\n\nax[1].set_title(\"Distribution of Amount according to classes\")\nsns.kdeplot(raw_data[raw_data['Class']==0]['Amount'],ax=ax[1],color = colors[3],legend=True,shade=True,alpha=1)\nsns.kdeplot(raw_data[raw_data['Class']==1]['Amount'],ax=ax[1],color = colors[2],shade=True,legend=True,alpha=0.8)","52f0efa5":"CORR = raw_data.corr()","9682fe0e":"fig = plt.figure(figsize=(24,24))\nsns.heatmap(CORR,cmap=cl.LinearSegmentedColormap.from_list(\"\",colors),square=True , annot_kws={'size': 14})","fe16535b":"fig,axes = plt.subplots(1,2,figsize=(24,24))\nsns.boxplot(x = raw_data['Class'],y = raw_data[\"Time\"],ax=axes[0],palette=palette)\naxes[0].set_title(\"BoxPlot for Time\")\nsns.boxplot(x = raw_data['Class'],y = raw_data.Amount,ax=axes[1],palette=palette)\naxes[1].set_title(\"BoxPlot for Amount\")","768f57f7":"from sklearn.preprocessing import RobustScaler,StandardScaler\nstd = StandardScaler()\nrbst = RobustScaler()\n# Using RobustScaler \nraw_data['Amount'] = rbst.fit_transform(raw_data['Amount'].values.reshape(-1,1))\nraw_data['Time'] = rbst.fit_transform(raw_data['Time'].values.reshape(-1,1))","eda624e7":"target = 'Class'\npredictors = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\\\n       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\\\n       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\\\n       'Amount']","d9ed0186":"X = raw_data.drop('Class',axis=1)\nY = raw_data.Class.values","57b6ec0d":"trainX,testX,trainY,testY = train_test_split(X,Y,test_size=0.2,random_state=42,shuffle=True)","f771c294":"clf = RandomForestClassifier(n_estimators=100,n_jobs=4,verbose=False)\nclf.fit(trainX,trainY)","5f72bfa4":"y_pred = clf.predict(testX)\nsns.heatmap(confusion_matrix(testY,y_pred),annot=True,fmt='0.0f')","fc6a0369":"roc_auc_score(testY, y_pred)","ea92d312":"print(classification_report(testY,y_pred))","5883ef28":"smt = SMOTE(random_state=42)\n# adasyn = ADASYN(random_state=42)\nX_smote,Y_smote = smt.fit_resample(trainX,trainY)","2b7319f0":"clf = RandomForestClassifier(n_estimators=100,n_jobs=4,verbose=False)\nclf.fit(X_smote,Y_smote)","0f79ba49":"fig, axes = plt.subplots(1,2,figsize=(27,12))\ny_pred = clf.predict(testX)\naxes[0].set_title(\"Confusion Matrix\")\nsns.heatmap(confusion_matrix(testY,y_pred),annot=True,fmt='0.0f',ax=axes[0])\n\ntmp = pd.DataFrame({'Feature': predictors, 'Feature importance': clf.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance',ascending=False)\ns = sns.barplot(x='Feature',y='Feature importance',data=tmp,color=colors[1],ax=axes[1])\naxes[1].set_title(\"Feature Importance\")\n# s.set_xticklabels(s.get_xticklabels(),rotation=90)\n","5d111229":"roc_auc_score(testY, y_pred)","d47e6f88":"print(classification_report(testY,y_pred))","b332ad1c":"model = Knn()\nmodel.fit(X_smote,Y_smote)","56f09208":"y_pred = model.predict(testX)\naxes[0].set_title(\"Confusion Matrix\")\nsns.heatmap(confusion_matrix(testY,y_pred),annot=True,fmt='0.0f')\n","d46ebddf":"print(classification_report(testY,y_pred))","7c074f33":"print(roc_auc_score(testY, y_pred))","90f18fe2":"model = AdaBoostClassifier(random_state=42,\n                        algorithm='SAMME.R',\n                         learning_rate=0.8,)","0873bbfe":"model.fit(X_smote,Y_smote)","a528ee60":"fig, axes = plt.subplots(1,2,figsize=(27,12))\ny_pred = model.predict(testX)\naxes[0].set_title(\"Confusion Matrix\")\nsns.heatmap(confusion_matrix(testY,y_pred),annot=True,fmt='0.0f',ax=axes[0])\n\ntmp = pd.DataFrame({'Feature': predictors, 'Feature importance': model.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance',ascending=False)\ns = sns.barplot(x='Feature',y='Feature importance',data=tmp,color=colors[1],ax=axes[1])\naxes[1].set_title(\"Feature Importance\")\n# s.set_xticklabels(s.get_xticklabels(),rotation=90)\n","da27d132":"print(classification_report(testY,y_pred))","bbb04401":"roc_auc_score(testY,y_pred)","f13b8427":"model = lgb.LGBMClassifier(\n    objective='binary',\n        metric = 'auc',\n          learning_rate= 0.05,\n          num_leaves =  7,max_depth=4,min_child_samples= 100,  \n          max_bin=100)","5d6d586b":"model.fit(X_smote,Y_smote)","9deeae1a":"fig, axes = plt.subplots(1,2,figsize=(27,12))\ny_pred = model.predict(testX)\naxes[0].set_title(\"Confusion Matrix\")\nsns.heatmap(confusion_matrix(testY,y_pred),annot=True,fmt='0.0f',ax=axes[0])\n\ntmp = pd.DataFrame({'Feature': predictors, 'Feature importance': model.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance',ascending=False)\ns = sns.barplot(x='Feature',y='Feature importance',data=tmp,color=colors[1],ax=axes[1])\naxes[1].set_title(\"Feature Importance\")\n# s.set_xticklabels(s.get_xticklabels(),rotation=90)\n","590b5fa3":"print(classification_report(testY,y_pred))","471df6b9":"print(roc_auc_score(testY,y_pred))","fc648838":"model_xgb = xgb.XGBClassifier(silent=True,max_depth=2,eval_metric='auc')","606212bb":"model_xgb.fit(X_smote,Y_smote)","eaec8734":"fig, axes = plt.subplots(1,2,figsize=(27,12))\ny_pred = model_xgb.predict(testX)\naxes[0].set_title(\"Confusion Matrix\")\nsns.heatmap(confusion_matrix(testY,y_pred),annot=True,fmt='0.0f',ax=axes[0])\n\ntmp = pd.DataFrame({'Feature': predictors, 'Feature importance': model_xgb.feature_importances_})\ntmp = tmp.sort_values(by='Feature importance',ascending=False)\ns = sns.barplot(x='Feature',y='Feature importance',data=tmp,color=colors[1],ax=axes[1])\naxes[1].set_title(\"Feature Importance\")\n# s.set_xticklabels(s.get_xticklabels(),rotation=90)\n","e1ef4c46":"print(classification_report(testY,y_pred))","cb58f29a":"print(roc_auc_score(testY, y_pred))","e52c0bdb":"slm = SelectFromModel(model_xgb,threshold=0.02)\nX_train_xgb = slm.fit_transform(X_smote,Y_smote)","57e1f86f":"# Because we need to select the same features as train dataset\ntest_xgb = np.array(testX[testX.columns[slm.get_support()]])","7ea170a6":"# Prepare the train and test datasets\ndtrain = xgb.DMatrix(pd.DataFrame(X_train_xgb),Y_smote )\ndtest = xgb.DMatrix(pd.DataFrame(test_xgb), testY)\n\n#What to monitor (in this case, **train** and **test**)\nwatchlist = [(dtrain, 'train'), (dtest, 'test')]\n","ced5c0b4":"params = {}\nparams['objective'] = 'binary:logistic'\nparams['silent'] = True\nparams['max_depth'] = 2\nparams['eval_metric'] = 'auc'\nparams['random_state'] = 42","216dcdcd":"model = xgb.train(params,dtrain,200,watchlist)","5418a49d":"y_pred = model.predict(dtest)","5834bfe6":"xgb.plot_importance(model, height=0.8, title=\"Feature importance \",color=colors[1],show_values=False)","0f4179b3":"roc_auc_score(testY,y_pred)","d7950e0f":"# visualising the tree\nxgb.plot_tree(model_xgb)\nfig = matplotlib.pyplot.gcf()\nfig.set_size_inches(210, 100)\nfig.savefig('tree.png')","cc454a01":"# Data Visualisation","06f699eb":"#### Highly imbalanced data as seen in the visualisation only 0.17% of the data is belonging to the class 1 i.e., Fraud","5ddd653e":"#### No missing value in any of the features","68b41aa9":"#### As there are many outliers in the features we will use RobustScaler in place of Standard Scaler for only Time and Amount as other feature are already PCA transformed so there is no need for scaling.","810fb262":"# Why recall or auc-roc and accuracy??? \ud83e\udd14\ud83e\udd14\n#### 1. Accuracy can be a little a biased for imbalanced data as a model which classifies all the data points as the prominent class and can achievce near perfect accuracy.\n#### 2. The aim of the comapnies is to reduce the **False negatives** as they are the most important for the companies.\n\n\n![](https:\/\/miro.medium.com\/max\/1044\/1*I0Yd-o2yQsHBRKFbf0rjpQ.png)\n\n### 3. So we will use Recall or Auc Roc score.\n#### 4. As can be seen from the formula as FN(False Negatives) decreases Recall increases.","d1b54f36":"# Feature Selection ","a64c902c":"# Upvote\nIf liked my notebook than please upvote it keep me motivated to work harder and also check out my other notebooks.\n- [Surviving The Titanic](https:\/\/www.kaggle.com\/govindsrathore\/survivingthetitanic)\n- [Heart Attack Analysis](https:\/\/www.kaggle.com\/govindsrathore\/heart-attack-analysis-prediction-91-acc)\n- [Linear Regression from Scratch](https:\/\/www.kaggle.com\/govindsrathore\/linear-regression-from-scratch)\n- [Chest Xray Pneumonia Classification using Transfer leanrning](https:\/\/www.kaggle.com\/govindsrathore\/vgg-transfer-learning-data-augmentation-94-acc)","d74f0b41":"#### True Positive :- Transactions which are **actually fraudulent** and the model also able correctly identify them as **fraudulent transactions**\n#### False Positive :- Transactions which are actually **non fraudulent** transactions but the model is predicting them as **fraudulent** transactions\n#### True Negative :- Transactions which are actually **non fraudulent** transactions and model is also predicting them as **non fraudulent** transactions\n#### False Negative :- Transactions which are **actually fraudulent** but the model is predicting them as **non fraudulent** transactions","ce779605":"# Importing Libraries","f7a540b7":"## Credit card fraud:- \n- It  is an inclusive term for fraud committed using a payment card, such as a credit card or debit card.\n- [Credit card fraud resulted in more lost dollars than debit cards in 2020, with \\\\$149 million in total losses. Debit cards resulted in a total of $117 million lost in 2020](https:\/\/mint.intuit.com\/blog\/planning\/credit-card-fraud-statistics\/#:~:text=Credit%20card%20fraud%20resulted%20in,%24117%20million%20lost%20in%202020.)","5968fb24":"## About Dataset:\n### - This dataset is highly imabalanced as in case of real world scenarios.\n### - All the features are PCA transformations of original features so as to secure the privacy of the user.\n### - Time and Amount are the only features which are given without PCA transformations\n    - Note : We will have to perform standardisation on these features.\n### - It is sufficiently large dataset for this task.","8c843d8c":"# Conclusion\n- Since the dataset is quite large we will perform feature selection so to improve the speed of training.\n- Apparently the most important features did not include Time or Amount. \n- The Auc-roc score and recall after oversampling has increased drastically for all the classifiers.","cdf83610":"# Dealing with imbalanced data","3072a5a6":"# Scaling and normalisation","2ee6a2c9":"# Split train and test","93c28218":"## Credt Card Fraud\n\n![](https:\/\/cdn.dnaindia.com\/sites\/default\/files\/styles\/full\/public\/2017\/04\/04\/562375-cyberfraud-040417.jpg)"}}