{"cell_type":{"a9fe65ba":"code","89cf16b3":"code","fdb619de":"code","78f3f58f":"code","78a4a5b7":"code","5d7def67":"code","497de01a":"code","333c480c":"code","b4271084":"code","40981a30":"code","5774f13c":"code","033683fe":"code","213a66e9":"code","5af7b46e":"code","1ab01124":"code","3510e291":"code","6e9854f8":"code","9393473a":"code","e68af63b":"code","cb0d4107":"code","ae752c49":"code","269dea1e":"code","7e03e94b":"code","8da94c84":"code","3901223c":"code","d6dbade8":"code","60f0493c":"code","9fb13399":"code","077bc8ec":"code","396378e9":"code","18863a4c":"code","acf2de45":"code","67221bb7":"code","07537f8c":"code","2ece899d":"code","61d28b95":"code","5df5c6df":"code","d9c9c039":"code","e737e253":"code","aab225aa":"code","fd7f045a":"code","69342354":"code","14e76cad":"code","ea998dc3":"code","ffffe5fd":"code","96831640":"code","a8b9bea8":"code","9bd67a9f":"code","3959e7ac":"code","32d0a9c7":"code","fc2adf2d":"code","e18a807c":"code","219bfdfa":"code","9ce92371":"code","e8c4b477":"code","39202392":"code","36870866":"code","5193ada8":"code","dea489f6":"code","1ecaf88c":"code","6617a89a":"code","4640d9b7":"code","fa286986":"code","d6b83ff5":"code","b80b92c3":"code","aa471c76":"code","3e156ebd":"code","a113df1e":"markdown","dddc41ac":"markdown","6565da2f":"markdown"},"source":{"a9fe65ba":"!pip install --no-deps ..\/input\/pretrined-models\/timm-0.3.3-py3-none-any.whl","89cf16b3":"import os\nimport pandas as pd\nimport timm\nfrom PIL import Image, ImageDraw, ImageChops\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid\nfrom tqdm import tqdm\nimport numpy as np","fdb619de":"path = \"..\/input\/cassava-leaf-disease-classification\"\nos.listdir(path)","78f3f58f":"df = pd.read_csv(path + \"\/train.csv\")","78a4a5b7":"import json\n\npath_json = '..\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json'\n\nwith open(path_json, mode = 'r') as f:\n    label_to_name = json.load(f)","5d7def67":"label_to_name","497de01a":"df.head()","333c480c":"# dataframe\u306e\u5199\u771f\u306eID\u3092path\u306b\u5909\u66f4\u3059\u308b\ndf[\"path\"] = df[\"image_id\"].map(lambda x: path + \"\/train_images\/\" + x)\ndf = df.drop(columns=[\"image_id\"])\ndf = df.sample(frac=1).reset_index(drop=True)","b4271084":"df.head()","40981a30":"from sklearn import model_selection\n\ntrain_df, valid_df = model_selection.train_test_split(\n    df, test_size=0.2, random_state=42, stratify=df.label.values\n)","5774f13c":"def get_label_id(name):\n    id = 0\n    if name == 'cbb':\n        id = 0\n    elif name == 'cbsd':\n        id = 1\n    elif name == 'cgm':\n        id = 2\n    elif name == 'healthy':\n        id = 4\n    return id","033683fe":"paths, labels = [], []\nimg_labels = os.listdir('..\/input\/cassava-2019-compe-data\/kaggle_upload\/train\/')\nprint(img_labels)\nfor label in img_labels:\n    if label != \"cmd\":\n        img_ids = os.listdir(\"..\/input\/cassava-2019-compe-data\/kaggle_upload\/train\/\"+label+\"\/\")\n        for img_id in img_ids:\n            paths.append(\"..\/input\/cassava-2019-compe-data\/kaggle_upload\/train\/\"+label+\"\/\"+img_id)\n            labels.append(get_label_id(label))","213a66e9":"extra_df = pd.DataFrame({'label':labels, 'path':paths})","5af7b46e":"extra_df","1ab01124":"train_df = pd.concat([train_df, extra_df])","3510e291":"train_df.label.value_counts().plot(kind=\"bar\")","6e9854f8":"valid_df.label.value_counts().plot(kind=\"bar\")","9393473a":"train_df = train_df.reset_index().drop(columns=[\"index\"])\ntrain_df.head()","e68af63b":"valid_df = valid_df.reset_index().drop(columns=[\"index\"])\nvalid_df.head()","cb0d4107":"p_df = pd.read_csv('..\/input\/pretrined-models\/extra_label.csv', index_col = 0).reset_index().drop(columns = ['index'])","ae752c49":"p_df","269dea1e":"def convert(p):\n    tmp = p.replace('[',\"\").replace(']','').split(',')\n    tmp = [float(i) for i in tmp]\n    return tmp","7e03e94b":"p_df['p_label'] = p_df['p_label'].map(convert)","8da94c84":"p_df","3901223c":"def add_p(df):\n    paths = df['path']\n    list_df = pd.DataFrame(columns = ['label', 'path', 'p_label'])\n    for path in tqdm(paths):\n        tmp = p_df[p_df['path'] == path]\n        # print(tmp['p_label'])\n        list_df = list_df.append(tmp, ignore_index = True)\n    return list_df","d6dbade8":"#train_df = add_p(train_df)\n#valid_df = add_p(valid_df)","60f0493c":"train_df","9fb13399":"im = Image.open(train_df[\"path\"][0])","077bc8ec":"im","396378e9":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.dataset import Subset\n\nfrom sklearn.model_selection import KFold\n\nimport matplotlib.image as img","18863a4c":"class CassavaDataset(Dataset):\n    def __init__(self, dataframe, transform=None, p_label = False):\n        super().__init__()\n        self.df = dataframe\n        self.transform = transform\n        self.p = p_label\n\n    def __len__(self):\n        return len(self.df[\"path\"])\n\n    def __getitem__(self, index):\n        # path\u3068\u6b63\u89e3\u30e9\u30d9\u30eb\u306e\u5165\u624b\n        path = self.df[\"path\"][index]\n        if self.p:\n            label = self.df['p_label'][index]\n            label = np.array(label)\n        else:\n            label = self.df[\"label\"][index]\n        # \u753b\u50cf\u306e\u8aad\u307f\u8fbc\u307f\n        with open(path, \"rb\") as f:\n            image = Image.open(f)\n            image = image.convert(\"RGB\")\n        # transform\u304c\u3042\u308b\u3068\u304d\u306b\u306f\u3001\u753b\u50cf\u306b\u9069\u7528\u3059\u308b\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return image, label","acf2de45":"import random","67221bb7":"class make_mask_image:\n    def __init__(self, p, mask_size=50):\n        self.p = p\n        self.mask_size = mask_size\n\n    def __call__(self, image):\n        start_width, start_height = [], []\n        if random.random() < self.p:\n            draw = ImageDraw.Draw(image)\n            width, height = image.size\n            for i in range(10):\n                start_width.append(random.randrange(0, width - self.mask_size))\n                start_height.append(random.randrange(0, height - self.mask_size))\n            for x, y in zip(start_width, start_height):\n                draw.rectangle(\n                    (x, y, x + self.mask_size, y + self.mask_size),\n                    fill=(0, 0, 0),\n                    outline=(0, 0, 0),\n                )\n        return image","07537f8c":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u8a55\u4fa1\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u753b\u50cf\u306e\u524d\u51e6\u7406\u306e\u5b9a\u7fa9\nimage_size = 384\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\ntrain_transform = transforms.Compose(\n    [  # \u5927\u304d\u3055\u306e\u5909\u66f4\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomResizedCrop(image_size),\n        make_mask_image(p=0.5, mask_size=40),\n        # tensor\u578b\u306b\u5909\u66f4\n        transforms.ToTensor(),\n        # \u6b63\u898f\u5316\u3059\u308b\n        transforms.Normalize(mean=mean, std=std),\n    ]\n)\n\nvalid_transform = transforms.Compose(\n    [\n        transforms.Resize((image_size, image_size)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=mean, std=std),\n    ]\n)","2ece899d":"dataset = CassavaDataset(train_df, train_transform, False)","61d28b95":"dataset.__getitem__(3)[1]","5df5c6df":"class Unnormalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n        \n    def __call__(self, tensor):\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.mul_(s).add_(m)\n        return tensor","d9c9c039":"unnorm = Unnormalize(mean, std)","e737e253":"def display_img(img, unnorm = None, label = None):\n    if unnorm != None:\n        img = unnorm(img)\n        \n    plt.imshow(img.permute(1, 2, 0))\n    \n    if label != None:\n        plt.title(label_to_name[str(label)])","aab225aa":"def display_batch(batch, unnorm = None):\n    imgs, labels = batch\n    \n    if unnorm:\n        unnorm_imgs = []\n        for img in imgs:\n            unnorm_imgs.append(unnorm(img))\n        imgs = unnorm_imgs\n        \n    ig, ax = plt.subplots(figsize=(16, 8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(imgs, nrow=8).permute(1, 2, 0))","fd7f045a":"class TaylorSoftmax(nn.Module):\n\n    def __init__(self, dim=1, n=2):\n        super(TaylorSoftmax, self).__init__()\n        assert n % 2 == 0\n        self.dim = dim\n        self.n = n\n\n    def forward(self, x):\n        \n        fn = torch.ones_like(x)\n        denor = 1.\n        for i in range(1, self.n+1):\n            denor *= i\n            fn = fn + x.pow(i) \/ denor\n        out = fn \/ fn.sum(dim=self.dim, keepdims=True)\n        return out\n\nclass LabelSmoothingLoss(nn.Module):\n\n    def __init__(self, classes, smoothing=0.0, dim=-1): \n        super(LabelSmoothingLoss, self).__init__() \n        self.confidence = 1.0 - smoothing \n        self.smoothing = smoothing \n        self.cls = classes \n        self.dim = dim \n    def forward(self, pred, target): \n        \"\"\"Taylor Softmax and log are already applied on the logits\"\"\"\n        #pred = pred.log_softmax(dim=self.dim) \n        with torch.no_grad(): \n            true_dist = torch.zeros_like(pred) \n            true_dist.fill_(self.smoothing \/ (self.cls - 1)) \n            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n    \n\nclass TaylorCrossEntropyLoss(nn.Module):\n\n    def __init__(self, n=2, ignore_index=-1, reduction='mean', smoothing=0.2):\n        super(TaylorCrossEntropyLoss, self).__init__()\n        assert n % 2 == 0\n        self.taylor_softmax = TaylorSoftmax(dim=1, n=n)\n        self.reduction = reduction\n        self.ignore_index = ignore_index\n        self.lab_smooth = LabelSmoothingLoss(num_classes, smoothing=smoothing)\n\n    def forward(self, logits, labels):\n\n        log_probs = self.taylor_softmax(logits).log()\n        #loss = F.nll_loss(log_probs, labels, reduction=self.reduction,\n        #        ignore_index=self.ignore_index)\n        loss = self.lab_smooth(log_probs, labels)\n        return loss","69342354":"tensor, label = dataset[3]\ndisplay_img(tensor, unnorm, label)","14e76cad":"loader = DataLoader(dataset, 16, shuffle = True)\ndisplay_batch(next(iter(loader)))","ea998dc3":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F","ffffe5fd":"epoch = 5\nbatch_size = 16\nnum_classes = 5\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","96831640":"resNet = timm.create_model(\"resnet50\", pretrained=False)\nresNet.fc = nn.Linear(resNet.fc.in_features, num_classes)\nresNet = resNet.to(device)","a8b9bea8":"ef_model = timm.create_model(\"tf_efficientnet_b4_ns\", pretrained=False)\nef_model.classifier = nn.Linear(ef_model.classifier.in_features, num_classes)\nef_model = ef_model.to(device)","9bd67a9f":"ef_optimizer = torch.optim.AdamW(ef_model.parameters(), lr=1e-4, weight_decay=0.0001)\nef_scheduler = torch.optim.lr_scheduler.StepLR(ef_optimizer, step_size=2, gamma=0.1)\n\nresNet_optimizer = torch.optim.AdamW(resNet.parameters(), lr=1e-4, weight_decay=0.0001)\nresNet_scheduler = torch.optim.lr_scheduler.StepLR(resNet_optimizer, step_size=2, gamma=0.1)\ncriterion=TaylorCrossEntropyLoss()\n# criterion = nn.MSELoss()","3959e7ac":"ef_model.load_state_dict(torch.load(\"..\/input\/models\/ef_model.pth\", map_location = device))\nresNet.load_state_dict(torch.load(\"..\/input\/models\/res_model.pth\", map_location = device))","32d0a9c7":"def collate_fn(batch):\n    images, targets = list(zip(*batch))\n    images = torch.stack(images)\n    targets = torch.Tensor(targets)\n    return images, targets","fc2adf2d":"def calc_correction(model, df):\n    model.eval()\n    path = df[\"path\"]\n    label = df[\"label\"]\n    count = 0\n    pred_list = [0, 0, 0, 0, 0]\n    model = model.to(device)\n    with torch.no_grad():\n        for i in tqdm(range(len(path))):\n            image_path = path[i]\n            image_label = label[i]\n            image = Image.open(image_path)\n            image = valid_transform(image)\n            image = image.unsqueeze(0).to(device)\n            pred = model(image)\n            pred = pred.argmax(1).item()\n            pred_list[pred] += 1\n            if pred == image_label:\n                count += 1\n    percent = count \/ len(path)\n    return percent, pred_list","e18a807c":"# loss\u306e\u8868\u793a\u3092\u3059\u308b\nfrom matplotlib import pyplot as plt\ndef plot_losses(epoch, title, train_losses, valid_losses):\n    y = list(range(len(train_losses)))\n    train_loss = plt.plot(y, train_losses)\n    valid_loss = plt.plot(y, valid_losses)\n    plt.title(title)\n    plt.ylabel(\"loss\")\n    plt.legend(\n        (train_loss[0], valid_loss[0]), (\"train loss\", \"valid loss\"),\n    )\n    plt.show()\n","219bfdfa":"import time\ndef train_model(model, dataset, batch_size, optimizer, criterion, scheduler,  epoch, model_title):\n    best_model = None\n    best_loss = float(\"inf\")\n    train_losses, valid_losses = [], []\n    kf = KFold(n_splits = 5)\n    \n    for fold, (train_index, valid_index) in enumerate(kf.split(dataset)):\n        print(\"fold: \", fold)\n        train_dataset = Subset(dataset, train_index)\n        train_loader = DataLoader(train_dataset, batch_size, shuffle = True, num_workers = 4)#, collate_fn = collate_fn)\n        valid_dataset = Subset(dataset, valid_index)\n        valid_loader= DataLoader(valid_dataset, batch_size, shuffle = False)#, collate_fn = collate_fn)\n        \n        for epoch in range(1, epoch + 1):\n            epoch_start_time = time.time()\n            acc = []\n            train_loss = 0\n            valid_loss = 0\n\n            model.train()\n            for data, target in train_loader:\n                data = data.to(device)\n                target = target.to(device)\n                optimizer.zero_grad()\n                output = model(data)\n                loss = criterion(output, target)\n                loss.backward()\n                optimizer.step()\n                train_loss += loss.item()*len(data)\n            train_loss = train_loss\/len(train_loader.sampler)\n            train_losses.append(train_loss)\n\n            model.eval()\n            for data, target in valid_loader:\n                data = data.to(device)\n                target = target.to(device)\n\n                with torch.no_grad():\n                    output = model(data)\n                    # pred = (output.argmax(1) == target)\n                    # acc.append(sum(pred)\/len(pred))\n\n                    loss = criterion(output, target)\n\n                    valid_loss += loss.item()*len(data)\n                    \n            if valid_loss < best_loss:\n                best_loss = valid_loss\n                best_model = model\n                    \n            scheduler.step()\n\n            # collection = sum(acc)\/len(acc)\n            valid_loss = valid_loss\/len(valid_loader.sampler)\n            valid_losses.append(valid_loss)\n            print('Time: {:.3f}\\t Epoch: {} \\tTraining Loss: {:.3f} \\tValidation Loss: {:.3f}'# \\t Acc: {:.2f}'\n                  .format(time.time() - epoch_start_time, epoch, train_loss, valid_loss))#, collection))\n            num_collection = []\n    torch.save(model.state_dict(), model_title)\n    \n    return model, train_losses, valid_losses","9ce92371":"def train_models(resNet, ef_model):\n    model_title = \".\/ef_model.pth\"\n    ef_model, train_losses, valid_losses = train_model(ef_model, dataset, batch_size, ef_optimizer, criterion, ef_scheduler, epoch, model_title)\n    print(calc_correction(ef_model, valid_df))\n    title = \"ef losses\"\n    plot_losses(epoch, title, train_losses, valid_losses)\n    \n    model_title = \".\/res_model.pth\"\n    resNet, train_losses, valid_losses = train_model(resNet, dataset, batch_size, resNet_optimizer, criterion,resNet_scheduler, epoch, model_title)\n    print(calc_correction(resNet, valid_df))\n    title = \"resNet losses\"\n    plot_losses(epoch, title, train_losses, valid_losses)","e8c4b477":"# train_models(resNet, ef_model)","39202392":"class CassaveClassifier(nn.Module):\n    def __init__(self, model, ef_model):\n        super().__init__()\n        self.model = model\n        self.ef_model = ef_model\n    \n    def forward(self, x):\n        x1 = self.model(x)\n        x2 = self.ef_model(x)\n        return (0.5 * x1 + 0.5 * x2)\n\n    def test(self, x, rate):\n        x1 = self.model(x)\n        x2 = self.ef_model(x)\n        p = rate * x1 + (1 - rate) * x2\n        return p","36870866":"classifier = CassaveClassifier(resNet, ef_model)\nclassifier = classifier.to(device)","5193ada8":"def test_rate():\n    for rate in range(1, 10):\n        classifier.eval()\n        path = valid_df[\"path\"]\n        label = valid_df[\"label\"]\n        count = 0\n        pred_list = [0, 0, 0, 0, 0]\n        for i in tqdm(range(len(path))):\n            image_path = path[i]\n            image_label = label[i]\n            image = Image.open(image_path)\n            image = valid_transform(image)\n            image = image.unsqueeze(0).to(device)\n            pred = classifier.test(image, rate\/10).argmax(1).item()\n            pred_list[pred] += 1\n            if pred == image_label:\n                count += 1\n        percent = count \/ len(path)\n        print(\"rate: \", rate\/10)\n        print(\"percent: \", percent)","dea489f6":"# test_rate()","1ecaf88c":"calc_correction(classifier, valid_df)","6617a89a":"path = \"..\/input\/cassava-leaf-disease-classification\/test_images\/\"","4640d9b7":"image_path = []\nimage_id = []\nfor i in os.listdir(path):\n    image_id.append(str(i))\n    image_path.append(path + str(i))","fa286986":"pred = []\nfor path in image_path:\n    image = Image.open(path)\n    image = valid_transform(image)\n    image = image.unsqueeze(0).to(device)\n    predict = classifier(image).argmax(1).item()\n    pred.append(predict)","d6b83ff5":"pred","b80b92c3":"sub = pd.DataFrame({\"image_id\": image_id, \"label\": pred})","aa471c76":"sub","3e156ebd":"sub.to_csv(\"submission.csv\", index=False)","a113df1e":"# show labels","dddc41ac":"# \u30c7\u30fc\u30bf\u7528\u306e\u95a2\u6570\u306e\u5b9a\u7fa9","6565da2f":"[reference of preprocess](https:\/\/www.pluralsight.com\/guides\/image-classification-with-pytorch)"}}