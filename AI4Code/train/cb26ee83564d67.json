{"cell_type":{"5f1daa2d":"code","fba206ec":"code","56a3b6c3":"code","589da7da":"code","9e2d1ec8":"code","28dedce7":"code","92a68d76":"code","cfa4974e":"code","3a01e7d3":"code","e984121b":"code","6990b5b4":"code","5b7d6aa6":"code","0d9f1c5a":"code","287e9890":"markdown","f5be02f9":"markdown","17d44094":"markdown","9dbf7df1":"markdown","8ed50935":"markdown","177dcd7f":"markdown","d5e181d3":"markdown","0ef3e8b9":"markdown","cfc2a0c0":"markdown","6707842d":"markdown","71a6032e":"markdown","040188ad":"markdown","c4f01947":"markdown","b5c16616":"markdown","fde332aa":"markdown","1c080372":"markdown","df485e5f":"markdown"},"source":{"5f1daa2d":"import math\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot\nfrom scipy import stats\n\nmatches    = pd.read_csv('..\/input\/matches.csv')\ndeliveries = pd.read_csv('..\/input\/deliveries.csv')","fba206ec":"win_by_wickets_data = matches[matches.win_by_wickets > 0].win_by_wickets\nwin_by_wickets_freq = win_by_wickets_data.value_counts(sort=False)\nprint(win_by_wickets_freq)\nplt = win_by_wickets_freq.plot.bar()\nplt.set_title(\"Frequency distribution graph - Win by wickets\")\nplt.set_xlabel(\"Win by wickets\")\nplt.set_ylabel(\"Frequency\")","56a3b6c3":"win_by_wickets_rel_freq = win_by_wickets_data.value_counts(sort = False, normalize = True)\nprint(win_by_wickets_rel_freq)\nplt = win_by_wickets_rel_freq.plot.bar()\nplt.set_title(\"Relative Frequency distribution graph - Win by wickets\")\nplt.set_xlabel(\"Win by wickets\")\nplt.set_ylabel(\"Relative frequency (%)\")","589da7da":"win_by_wickets_cumulative_freq = win_by_wickets_data.value_counts(sort = False, normalize = True).cumsum()\nprint(win_by_wickets_cumulative_freq)\nplt = win_by_wickets_cumulative_freq.plot.bar()\nplt.set_title(\"Cumulative relative frequency distribution graph - Win by wickets\")\nplt.set_xlabel(\"Win by wickets\")\nplt.set_ylabel(\"Cumulative relative frequency (%)\")","9e2d1ec8":"plt = win_by_wickets_cumulative_freq.plot.line()\nplt.axhline(y = win_by_wickets_cumulative_freq[6], xmax = 5.5\/10, linestyle='dashed')\nplt.axvline(x = 6, ymax = win_by_wickets_cumulative_freq[6], linestyle='dashed')","28dedce7":"# Get mean (mu) and std (sigma)\nwin_by_wickets_mean, win_by_wickets_std = win_by_wickets_data.mean(), win_by_wickets_data.std()\n\n# Plot histogram (normalized) - LIGHT-BLUE\nwin_by_wickets_data.hist(color='lightblue', weights = np.zeros_like(win_by_wickets_data) + 1.0 \/ win_by_wickets_data.count())\n\n# Plot line graph - RED\nwin_by_wickets_data.value_counts(sort=False, normalize=True).plot.line(color='red')\n\n# Normal distribution for random points between 1 to 10 with mean, std.\nrandom_data = np.arange(1, 10, 0.001)\npyplot.plot(random_data, stats.norm.pdf(random_data, win_by_wickets_mean, win_by_wickets_std), color='green')","92a68d76":"mu, sigma = 128, 25 # From the above example\nhighest_scores = np.random.normal(mu, sigma, 1000) # Random 1000 values\n\ncount, bins, _ = pyplot.hist(highest_scores, 100, normed = True, color='lightblue') # plot 100 points\npyplot.plot(bins, 1\/(sigma * np.sqrt(2 * np.pi)) *\n    np.exp( - (bins - mu)**2 \/ (2 * sigma**2) ),\n    linewidth = 2, color = 'r') # Plot the PDF","cfa4974e":"win_by_runs_data = matches[matches.win_by_runs > 0].win_by_runs\nwin_by_runs_mean, win_by_runs_std = win_by_runs_data.mean(), win_by_runs_data.std()\nz_score_35 = (35 - win_by_runs_mean) \/ win_by_runs_std\nprint(f'Z-score of 35 is {z_score_35:.2f}')","3a01e7d3":"z_score = stats.norm.cdf(0.19)\nprint(f'z-score of 0.19 = {z_score * 100:.2f} percentile')","e984121b":"def compute_binomial_probability(x, n, p):\n    \"\"\"Returns the probability of getting `x` success outcomes in `n` trials,\n    probability of getting success being `p`\n\n    Arguments:\n\n    x - number of trials of the event\n    n - number of trials\n    p - probability of the event\n\n    \"\"\"\n    outcomes = math.factorial(n) \/ (math.factorial(x) * math.factorial(n - x))\n    probability_of_each_outcome = p ** x * (1 - p) ** (n - x)\n    return outcomes * probability_of_each_outcome\n\ndef plot_binomial_distribution_graph(n, p):\n    \"\"\"Plots Binomial distribution graph of an event with `n` trials,\n    probability of getting success of the event being `p` for values `0` to `n`\n\n    Arguments:\n\n    n - number of trials\n    p - probability of the event\n\n    \"\"\"\n    probabilities = list(map(lambda x: compute_binomial_probability(x, n, p), range(0, n+1)))\n    pyplot.bar(list(range(0, n+1)), probabilities)\n\nplot_binomial_distribution_graph(5, 0.5)","6990b5b4":"plot_binomial_distribution_graph(10, 0.5)","5b7d6aa6":"plot_binomial_distribution_graph(10, 0.7)","0d9f1c5a":"pyplot.bar(['0', '1'], [0.35, 0.65])","287e9890":"Now, let's plot **Relative frequency distribution graph** for the same data. Here in **Y-axis**, instead of showing the frequency, we show the **percentage** of the value. We can use `normalize = True` argument for `pandas.Series.value_counts` method","f5be02f9":"# Empirical rule (68\u201395\u201399.7 rule)\n\n**Empirical rule** also called **68-95-99.7** or **three sigma rule** gives an approximate of values within 1,2 or 3 standard deviations from the mean. The following diagrams represents the value distribution from the mean in a normal distribution.\n\n![Empirical rule](https:\/\/raw.githubusercontent.com\/nowke\/nowke.github.io\/gh-pages\/src\/pages\/stats\/images\/normal-distribution-empirical.png)\n![Normal distribution](https:\/\/raw.githubusercontent.com\/nowke\/nowke.github.io\/gh-pages\/src\/pages\/stats\/images\/normal-distribution.png)","17d44094":"# Binomial distribution\n\n## Binomial experiment\n\nA Binomial experiment has the following properties.\n\n* Consists of fixed number of trials (n)\n* Trials are independent of each other\n* Each trial can be either success or failure\n* Probability of success (P) on each trial remains the same\n\n***Example:*** Number of heads in after flipping a coin 10 times\n\n* The experiment is conducted for fixed number of trials - 10\n* Probability of getting head in one trial does not affect the other\n* Probability of getting head in any trial remains same - 0.5 (in a non-biased coin)\n\n## Binomial variable\n\nA **binomial variable** is the number of successes (x) out of all the trials (n).\n\nWhat is the probability of getting 5 heads after flipping a coin 10 times? Here $x = 5$ is a binomial variable.\n\n## Binomial distribution\n\nThe probability distribution of a binomial variable is called **Binomial distribution**.\n\nLet's take the problem statement of flipping a coin - Probability of getting 5 heads after 10 flips? P(X = 5) can be calculated as\n\n$$\n\\begin{align}\nP(X = 5) = No.\\,of\\,outcomes\\,we\\,want\\,\\times Probability\\,of\\,each\\,outcome\n\\end{align}\n$$\n\nFor 10 flips, we have a total of $2^{10} =1024$ outcomes. Hence,\n\n$$\n\\begin{align}\nProbability\\,of\\,each\\,outcome={1 \\over 1024}\n\\end{align}\n$$\n\nNo. of outcomes where exactly 5 heads occur out of 10 flips = $^{10}C_5 = 252$\n\n$$\n\\begin{align}\nP(X = 5) = 252 \\times {1 \\over 1024} \\approx 24.6 \\%\n\\end{align}\n$$\n\n### Deriving General Binomial Probability equation\n\nLet's take the example of a biased coin instead of a fair coin with **60%** chance of heads and **40%** chance of tails.\n\nWhat is the probability of getting 2 heads out of 3 tosses?\n\n$p = 0.6$ (Probability of getting heads)\n\n$x = 2$ (no. of success i.e. heads)\n\n$n = 3$ (no. of trials)\n\nNo. of outcomes we want = $^{n}C_x = ^{3}C_2 = 3$ (HHT, HTH, THH) \n\nTo calculate probability of each outcome, let's take one outcome- HHT\n\n* Probability of getting **H** in trial 1 = 0.6\n* Probability of getting **H** in trial 2 = 0.6\n* Probability of getting **T** in trial 3 = 0.4\n\nHence, probability of getting HHT = $0.6\\times0.6\\times0.4 = 0.144$\n\ni.e. $(0.6)^2 \\times (0.4)^1 = (0.6)^2 \\times (1-0.6)^(2-1) = p^x \\times (1-p)^{n-x}$\n\nFinally,\n\nProbability of getting 2 heads out of 3 = $3 \\times 0.144 = 0.432$\n\nPutting it together,\n\n$$\n\\begin{align}\nNo.\\,of\\,outcomes\\,= ^{n}C_x\n\\end{align}\n$$\n\n$$\n\\begin{align}\nProbability\\,of\\,each\\,outcome\\,= p^x \\times (1-p)^{(n-x)}\n\\end{align}\n$$\n\n$$\n\\begin{align}\nP(x\\,\\,of\\,\\,n) = ^{n}C_x\\,\\,p^x\\,(1-p)^{(n-x)}\n\\end{align}\n$$\n\nHence, the **general binomial probability equation** is,\n\n$$\n\\begin{align}\nP(x\\,\\,of\\,\\,n) = {n! \\over x!(n-x)!}\\,p^x\\,(1-p)^{(n-x)}\n\\end{align}\n$$\n\nAlso,\n\n$$\n\\begin{align}\nExpected\\,Value: E[X] = n \\cdot p\n\\end{align}\n$$\n\n$$\n\\begin{align}\nVariance: \\sigma^2 = n \\cdot p \\cdot (1 - p)\n\\end{align}\n$$\n\n$$\n\\begin{align}\nStandard\\,deviation: \\sigma = \\sqrt{n \\cdot p \\cdot (1 - p)}\n\\end{align}\n$$\n\n## Plotting Binomial Distribution\n\nLet $X$ be a random variable = No. of heads from flipping a coin 5 times\n\n$$\n\\begin{align}\nP(X = 0) = {5! \\over 0!(5-0)!}\\,0.5^0\\,(1-{1 \\over 2})^{(5-0)} = {1 \\over 32}\n\\end{align}\n$$\n\n$$\n\\begin{align}\nP(X = 1) = {5 \\over 32},\nP(X = 2) = {10 \\over 32},\nP(X = 3) = {10 \\over 32},\nP(X = 4) = {5 \\over 32},\nP(X = 5) = {1 \\over 32}\n\\end{align}\n$$","9dbf7df1":"Probability distribution function in terms of z-score (z) given by,\n\n$$\n\\begin{align}\nf(x, \\sigma, z) = {1 \\over \\sqrt{2\\pi\\sigma^2e^{z^2}}}\n\\end{align}\n$$","8ed50935":"From here, we can plot the **cumulative relative frequency graph** using `pandas.Series.cumsum` .","177dcd7f":"## Plotting the probability density function (PDF)\n\nA Probability distribution function (PDF) is a function associated with continuous random variable which desribes the relative probability of the random variable at a given value.\n\nThe probability density function of the normal distribution for a given point (x), mean ($\\mu$) and standard deviation ($\\sigma$)  is given by,\n\n$$\n\\begin{align}\nf(x, \\mu, \\sigma) = {1 \\over \\sqrt{2\\pi\\sigma^2}} \\cdot e^{-{(x - \\mu)^2} \\over 2\\sigma^2}\n\\end{align}\n$$\n\nLet's plot a PDF for some random values (Source: [numpy.random.normal](https:\/\/docs.scipy.org\/doc\/numpy-1.14.0\/reference\/generated\/numpy.random.normal.html))","d5e181d3":"# Normal distribution\n\n**Normal distribution** is a continuous probability distribution that describes many natural datasets. It is also known as **bell curve** or **Gaussian distribution**. We see many natural examples that are closer to a normal distribution.\n\n* Heights of people\n* Shoe sizes\n* Lap duration in a car race\n\nIn a perfect normal distribution, we can see 50% symmetry about the center. Also, the center is - **mean** = **mode** = **median**.\n\n![Normal distribution - symmetry](https:\/\/raw.githubusercontent.com\/nowke\/nowke.github.io\/gh-pages\/src\/pages\/stats\/images\/normal-distribution-symmetry.png)\n\n## Normal distribution and variance\n\nIf the variance of the dataset is high, the curve tends to look flat. If variance is low, curve is more steeper.\n\n![Nomral distribution - variance](https:\/\/raw.githubusercontent.com\/nowke\/nowke.github.io\/gh-pages\/src\/pages\/stats\/images\/normal-distribution-variance.png)\n\nLet's plot `win_by_wickets` data and watch the curve.","0ef3e8b9":"Originally published in [Kaggle](https:\/\/www.kaggle.com\/nowke9\/statistics-2-distributions)\n\n# Introduction\n\nA distribution of data is a representation (or function) showing all possible values (or intervals) and how often those values occur.\n\nFor **categorical data**, we'll often see percentage or exact number for each of the category.<br>\nFor **numerical data**, we'll see the data split into appropriate sized buckets ordered from smallest to largest\n\nWhen a distribution is plotted into a graph, we can observe different shapes of the curve. Based on the shape and other attributes, there exists many types of distributions. A few statistical distributions are,\n* Bernoulli Distribution\n* Binomial Distribution\n* Cumulative frequency distribution\n* Bimodal distribution\n* Gaussian distribution (Normal distribution)\n* Uniform distribution\n\nLet's setup our dataset,","cfc2a0c0":"# Bernoulli distribution\n\nBernoulli distribution is a **discrete probability distribution** of a random variable which has only two outcomes (\"success\" or a \"failure\"). It is named after Swiss mathematician [**Jacon Bernoulli**](https:\/\/en.wikipedia.org\/wiki\/Jacob_Bernoulli). It is a special case of Binomial distribution for n = 1.\n\nFor example, probability (**p**) of scoring a goal in last 10 minutes is **0.35** (success), probability of not scoring a goal in last 10 minutes (failure) is **1 - p = 0.65**.\n\nPlotting Bernoulli distribution with probability for **p = 0.65**,","6707842d":"$$\n\\begin{align}\nExpected\\,Value: E[X] = p\n\\end{align}\n$$\n\n$$\n\\begin{align}\nVariance: \\sigma^2 = p(1 - p)\n\\end{align}\n$$\n\n$$\n\\begin{align}\nStandard\\,deviation: \\sigma = \\sqrt{p(1 - p)}\n\\end{align}\n$$","71a6032e":"What's the relevance of this representation?\n\nLet's try to answer this &rarr; **What is the probability of winning a match by 6 wickets or less?**. \n\nOf course we can calculate that using the data. But let's try to figure out from the graph. Draw a line from the top of **\"6\"** to the Y-axis. We'll draw **Line graph** instead of Bar graph.","040188ad":"We can convert from z-score to percentile using a [Z-table](http:\/\/www.z-table.com\/) or `scipy.stats.norm.cdf` function.\n\n![Z-score-curve](https:\/\/raw.githubusercontent.com\/nowke\/nowke.github.io\/gh-pages\/src\/pages\/stats\/images\/z-score-curve.png)","c4f01947":"# Z-Score\n\nA Z-score measures how many standard deviations above or below the mean a data point is. It is calculated as,\n\n$$\n\\begin{align}\nz = {x - \\mu \\over \\sigma}\n\\end{align}\n$$\n\n* Positive Z-score &rarr; Data point is above the mean\n* Negative Z-score &rarr; Data point is below the mean\n* Close to zero &rarr; Data point is close to the mean\n\n**Example**: If a team wins by a margin of 35 runs, what's the z-score? Let's calculate","b5c16616":"Let's plot the distribution for flipping a coin 10 times.","fde332aa":"As we can observe, with more trials, the plot tends to look like **Normal distribution**\n\nPlotting the graph for a biased coin - $P(head) = 0.7, P(tail) = 0.3$","1c080372":"We can roughly approximate this value to be around 0.54. \n\nThus, using cumulative relative frequency graph, the **probability of winning a match by 6 wickets or less is approximately 54%.**\n\nWe can also calculate the **percentile** of a value using the above graph. For example, if a team wins by a margin of **4** wickets, the **percentile** of this match is around **16%**","df485e5f":"# Cumulative relative frequency graph\n\nLet's take `win_by_wickets` dataset and plot a frequency distribution graph.\n\nX-axis - Win by wickets (value from 1 to 10), Y-axis - Number of instances (or frequency) of win-by-wicket margin"}}