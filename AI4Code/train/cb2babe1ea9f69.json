{"cell_type":{"5803dc0b":"code","f22037c9":"code","1e42bfce":"code","a2e46eb3":"code","cb475d22":"code","ad625f56":"code","d8f18df0":"code","62fc1fcf":"code","ab4f109a":"code","bd219787":"code","fad6e8c7":"code","c4848e85":"code","9234c22e":"code","c83cb827":"code","6ee74171":"code","1feca388":"code","6eb9a494":"code","a7cd04d6":"code","924b3b6d":"code","e77c64a2":"code","833ee6b0":"code","7004381a":"code","0499fc51":"code","e7c4a8c0":"code","f53e8b20":"code","f5d61caa":"code","20cafdfa":"code","d391e1d8":"code","56f95c13":"code","501172e1":"code","4e148a49":"code","ef27950a":"code","5248f6d6":"code","204bfbf2":"code","303901ab":"code","4f288706":"code","ecd35369":"code","3079dfb8":"code","dc465d0e":"code","b8d26387":"code","40de987d":"code","5d2a78ef":"code","92f9249c":"code","be4bd7b4":"code","1dbec836":"code","e0825494":"code","32042854":"code","5a01d2fd":"code","219eed83":"code","1df93b84":"code","59caab7a":"code","d2ee4854":"code","d8245a95":"code","c9b3b80c":"code","6c2e42c2":"code","3480f1b1":"code","03a6afaf":"code","43747af7":"code","8048bb6e":"code","df1b333b":"code","e170b2b3":"code","85cde72a":"code","683c0bb4":"code","a5956cee":"code","7316a2ef":"code","73d1f706":"code","392fe299":"code","d4661b98":"code","a62e29bd":"code","9ad4c2a3":"code","208fee2f":"code","83641c00":"code","b16e5653":"code","ec2cde5b":"code","6314928c":"code","f549fbbb":"code","a3ead98d":"code","e9c67fcb":"code","baeff915":"code","3a1adb2d":"code","e428ab25":"code","0d4feb77":"code","29da4788":"code","3bea7fc0":"code","a3f8aecb":"code","317bf148":"code","546bb1e6":"code","5d87ae41":"code","6b264d9d":"code","e5e95b44":"code","6ee8e324":"code","881df2e7":"code","e5dda0a4":"code","28b0d83f":"code","01422c56":"code","6038a56d":"code","2d728691":"code","0c2559ec":"code","be9ef4d6":"code","654470b9":"code","65145b72":"code","5ed9c6da":"code","631f7bcb":"code","bba0498c":"code","f7e5a99a":"code","63911793":"code","eb248753":"code","99a97471":"code","cc12e1e7":"code","5e795cfd":"code","7edff232":"code","fe3d8768":"code","c55e4f4f":"code","0d16c159":"code","52aeec1d":"code","94ec7ee9":"code","d10f7ef1":"code","5d2a835b":"code","4248f504":"code","cf30b5c1":"code","8b38b98c":"code","178d2719":"code","5ca452ff":"code","1bb76eab":"code","205b292a":"code","b3670840":"code","02910916":"code","e224bb84":"code","88d90d9e":"code","c41f97d2":"code","29637a89":"code","d274eb40":"code","0733fad2":"code","e97c2c6a":"code","cf52f40f":"code","cbe6ae52":"code","792c6b8c":"code","a3205a8a":"code","ea0b75f3":"code","455f78ff":"code","72b1a73c":"code","8fcab17b":"code","c50e4d22":"code","f6928be1":"code","3cc89b6f":"code","a2f0e6d9":"code","bce0927d":"code","b389fb75":"code","9435168b":"code","eddcac51":"code","63a4371f":"code","b556fbe9":"code","1750e025":"code","5c008f4d":"code","5f54f7d8":"markdown","e5af1ceb":"markdown","72c979d6":"markdown","e1a63ce8":"markdown","a5afe3e9":"markdown","5bc45b7d":"markdown","9de9e0b8":"markdown","bde43c93":"markdown","0a3e06b0":"markdown","eb98a278":"markdown","76f52292":"markdown","933e7e07":"markdown","36795b30":"markdown","02ae50f3":"markdown","6387abe0":"markdown","33cc1256":"markdown","fdb6abab":"markdown","b8e76e77":"markdown","4e5eaed9":"markdown","ffeb33dc":"markdown","9e479fb6":"markdown","8b5dd203":"markdown","3258bb26":"markdown","174564b9":"markdown","e54e4b94":"markdown","5bfe9e06":"markdown","aefe7b3d":"markdown","66b30fec":"markdown","88642ac6":"markdown","8910d4f0":"markdown","a41f32b6":"markdown","8df7c962":"markdown","3ed6309f":"markdown","4745c106":"markdown","f93a9535":"markdown","e57476a0":"markdown","a8356d04":"markdown","da03bb64":"markdown","4d0c5488":"markdown","a1f1c7c7":"markdown","76fba68c":"markdown","fbf74c2d":"markdown","5f1b9b64":"markdown","6cfeb450":"markdown","267d5983":"markdown","cd9784d2":"markdown","ab79cc2c":"markdown","21d95749":"markdown","30903478":"markdown"},"source":{"5803dc0b":"import os\nfor dirname, _, filenames in os.walk('\/kaggle'):\n    for filename, j in zip(filenames, range(3)):\n        print(os.path.join(dirname, filename))","f22037c9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport keras\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_absolute_error\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nplt.style.use(\"ggplot\")\n","1e42bfce":"final = pd.read_csv(\"\/kaggle\/input\/dfdata\/dfdata.csv\").drop_duplicates(keep='first')\nprint(final.shape)\nfinal.head()","a2e46eb3":"final.rename(columns = {\"AvgEnergyPerDay\":\"avg_energy\"}, inplace=True)","cb475d22":"fig, ax1 = plt.subplots(figsize=(25, 6))\nax1.plot( final[\"avg_energy\"], color=\"yellow\")\nax1.plot( final[\"temperatureMax\"],  color=\"green\")\nax1.plot(final[\"uvIndex\"], color=\"blue\")\nax1.plot(final[\"dewPoint\"], \"black\")\nplt.show()","ad625f56":"final.corr()","d8f18df0":"final.reset_index(inplace=True)\nfinal = final[final[\"day\"]!=\"2014-02-28\"]\nfinal.tail()","62fc1fcf":"final['day'] = pd.to_datetime(final[\"day\"])\nfinal[\"month\"] = final[\"day\"].dt.month\nfinal[\"date\"] = final[\"day\"].dt.day","ab4f109a":"from sklearn import preprocessing","bd219787":"pre = preprocessing.LabelEncoder()","fad6e8c7":"pre.fit(final[\"day\"])","c4848e85":"final.head()","9234c22e":"#pre.classes_","c83cb827":"final[\"datetime\"] = pre.transform(final[\"day\"])","6ee74171":"#final[\"datetime\"] = [i.replace(\"-\", \"\") for i in final[\"day\"]]\n#final.head()","1feca388":"print(\"maximum date :\", max(final[\"day\"]))\nprint(\"minimum date :\", min(final[\"day\"]))","6eb9a494":"final.columns","a7cd04d6":"final_corr = final.corr()","924b3b6d":"fig, ax = plt.subplots(figsize=(25,15))\nsns.heatmap(final_corr, cmap=\"YlGnBu\", linewidths=0.3, annot=True, fmt='.1g', vmin=-1, vmax=1, center= 0, ax=ax)","e77c64a2":"final_corr.reset_index(inplace=True)","833ee6b0":"final_corr","7004381a":"feature_list = [j for i, j in zip(final_corr[\"avg_energy\"], final_corr[\"level_0\"]) if abs(i) > 0.3]\nfeature_list","0499fc51":"final.to_csv(\"final.csv\", index=False)","e7c4a8c0":"final_columns = ['day','temperatureMax', 'dewPoint',\n       'apparentTemperatureHigh', 'temperatureMin', 'temperatureLow', \n        'temperatureHigh', #'apparentTemperatureMin',\n       'uvIndex', 'month', 'datetime' , \n       'avg_energy']","f53e8b20":"train = final[final[\"day\"]<\"2014-02-01\"][final_columns]\ntest = final[final[\"day\"]>=\"2014-02-01\"][final_columns]\n#train = final[final[\"day\"]<\"2014-02-01\"][[\"day\", \"temperatureMax\",\"uvIndex\", \"dewPoint\", \"windSpeed\", \"pressure\",\"humidity\",\"housecount\",\"month\",\"datetime\",\"avg_energy\"]]\n#test = final[final[\"day\"]>=\"2014-02-01\"][[\"day\", \"apparentTempetatureMax\", \"temperatureM\",\"uvIndex\", \"dewPoint\", \"windSpeed\", \"pressure\",\"holiday\",\"housecount\",\"month\",\"datetime\",\"avg_energy\"]]\ntrain.to_csv(\"train.csv\", index=False)\ntest.to_csv(\"test.csv\", index=False)","f5d61caa":"def accuracy_function(y, y_pred):\n    yhat_lower = []\n    yhat_upper = []\n    y_bin = [1]*len(y)\n    y_pred_bin = []\n    for i in y:\n        yhat_lower.append(i-0.5)\n        yhat_upper.append(i+0.5)\n    for i, j, k in zip(yhat_lower, yhat_upper, y_pred):\n        if k< j and k>i:\n            y_pred_bin.append(1)\n        else:\n            y_pred_bin.append(0)\n    acc_score = accuracy_score(y_bin, y_pred_bin)\n    return acc_score","20cafdfa":"out_df = pd.DataFrame()","d391e1d8":"from fbprophet import Prophet\nfrom fbprophet.diagnostics import cross_validation\nfrom fbprophet.diagnostics import performance_metrics\nfrom fbprophet.plot import plot\nfrom fbprophet.plot import plot_components\nfrom sklearn.model_selection import train_test_split","56f95c13":"train = pd.read_csv(\"\/kaggle\/working\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/working\/test.csv\")\ntest[\"day\"] = pd.to_datetime(test[\"day\"])\ntrain[\"day\"] = pd.to_datetime(train[\"day\"])\ntrain_df = train[[\"day\", \"avg_energy\"]]\ntrain_df.columns = [\"ds\", \"y\"]\ntest_df = test[[\"day\", \"avg_energy\"]]\ntest_df.columns = [\"ds\", \"y\"]\ntest_df_ans = test_df.copy()\ntest_df[\"y\"] = 0","501172e1":"train_df.shape, test_df.shape, test_df_ans.shape","4e148a49":"fb_model = Prophet()\nfb_model.add_seasonality(name=\"monthly\", period=180, fourier_order=5)\nfb_model.add_country_holidays(country_name='UK')\nfb_model.fit(train_df)","ef27950a":"fb_model.train_holiday_names","5248f6d6":"forecast = fb_model.predict(test_df)\nforecast.head()","204bfbf2":"out_df[\"fbprophet\"] = forecast[\"yhat\"]","303901ab":"'''def accuracy_function(y_test ,y_pred):\n    y_pred_bin=[]\n    for i, j, k in zip(forecast[\"yhat_lower\"], forecast[\"yhat_upper\"], y_pred):\n        if k < j and k > i:\n            y_pred_bin.append(1)\n        else:\n            y_pred_bin.append(0)\n    \n    y_test_bin=[]\n    for i, j, k in zip(forecast[\"yhat_lower\"], forecast[\"yhat_upper\"], y_test):\n        if k < j and k > i:\n            y_test_bin.append(1)\n        else:\n            y_test_bin.append(0)\n    acc_score = accuracy_score(y_test_bin, y_pred_bin)\n    return acc_score'''","4f288706":"fig = plot(fb_model, forecast, figsize=(20, 7))\nax = fig.gca()\nax.set_title(\"Date vs energy_sum\", size=25)\nax.set_xlabel(\"Date-->\", size=15)\nax.set_ylabel(\"energy_sum\", size=15)\nax.tick_params(axis=\"x\", labelsize=15, rotation=45)\nax.tick_params(axis=\"y\", labelsize=15)","ecd35369":"fig = plot_components(fb_model, forecast, figsize=(20, 10))\nax = fig.gca()\nax.tick_params(axis=\"x\", labelsize=15, rotation=45)\nax.tick_params(axis=\"y\", labelsize=15)","3079dfb8":"df_cv = cross_validation(fb_model, horizon=\"60 days\")\ndf_cv.head()","dc465d0e":"df_cv.shape","b8d26387":"df_p = performance_metrics(df_cv)\ndf_p.head()","40de987d":"forecast[\"ds\"].shape, forecast[\"yhat\"].shape","5d2a78ef":"fig, ax1 = plt.subplots(figsize=(25, 6)) \nax1.plot(test_df_ans[\"ds\"], test_df_ans[\"y\"], color=\"orange\")\n#ax1.plot(forecast[\"ds\"], forecast[\"yhat\"], color=\"blue\")\nax1.plot(forecast[\"ds\"], forecast[\"yhat_lower\"], color=\"black\")\nax1.plot(forecast[\"ds\"], forecast[\"yhat_upper\"], color=\"red\")\nax1.legend((\"y\", \"yhat_lower\", \"yhat_upper\"))\n# ax1.set_xlabel(\"days-->\", fontsize=20)\n# ax1.set_ylabel(\"energy_sum\", fontsize=20)\n# plt.xticks(rotation=45, fontsize=15)","92f9249c":"future_1yr = fb_model.make_future_dataframe(periods=365)\nfuture_1yr.tail()","be4bd7b4":"forecast_1yr = fb_model.predict(future_1yr)\nforecast_1yr.head()","1dbec836":"fig, ax1 = plt.subplots(figsize=(25, 10))\nax1.plot(forecast_1yr[\"ds\"], forecast_1yr[\"yhat\"], color=\"blue\")\nax1.plot(forecast_1yr[\"ds\"], forecast_1yr[\"yhat_lower\"], color=\"black\")\nax1.plot(forecast_1yr[\"ds\"], forecast_1yr[\"yhat_upper\"], color=\"red\")\n\nax1.legend((\"y\", \"yhat_lower\", \"yhat_upper\"))","e0825494":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import r2_score","32042854":"train = pd.read_csv(\"\/kaggle\/working\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/working\/test.csv\")\ntest.head()","5a01d2fd":"train.set_index(\"day\", inplace=True)\ntest.set_index(\"day\", inplace=True)","219eed83":"X_train = train.drop([\"avg_energy\"], axis=1).iloc[:len(train)-27,:]\nX_val = train.drop(\"avg_energy\", axis=1).iloc[len(train)-27:,:]\ny_train = train[\"avg_energy\"][:len(train)-27,]\ny_val = train[\"avg_energy\"][len(train)-27:,]\nX_test = test.drop(\"avg_energy\", axis=1)\ny_test = test[\"avg_energy\"]","1df93b84":"'''scaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)'''","59caab7a":"X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape","d2ee4854":"X_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n#--------------------------------------------\nX_val = np.array(X_val)\ny_val = np.array(y_val)","d8245a95":"X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\nX_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n#---------------------------------------------------------------------------------\nX_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))","c9b3b80c":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","6c2e42c2":"'''X_test = tf.keras.utils.normalize(X_test, axis=1)\nX_train = tf.keras.utils.normalize(X_train, axis=1)'''","3480f1b1":"model = Sequential()","03a6afaf":"# design network\n\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(tf.keras.layers.Dropout(0.1))\nmodel.add(tf.keras.layers.Dense(10, activation=\"linear\"))\n\nmodel.add(tf.keras.layers.Dense(1))\nmodel.compile(loss='mae', optimizer='adam')\nes = EarlyStopping(monitor='log_loss', mode=100, verbose=4)\nfit = model.fit(X_train, y_train, epochs=1000, validation_data=(X_val, y_val))#, callbacks=[es])\n","43747af7":"y_train_pred = model.predict(X_train)\ny_train_pred_rnn = np.reshape(y_train_pred, (y_train.shape[0]))","8048bb6e":"fig, ax1 = plt.subplots(figsize = (20,5))\nax1.plot(y_train_pred_rnn, color=\"blue\")\nax1.plot(y_train, color=\"red\")\nax1.legend((\"y_train_pred_rnn\", \"y_train\"))\nplt.show()","df1b333b":"y_test_pred = model.predict(X_test)\ny_test_pred_rnn = np.reshape(y_test_pred, (y_test_pred.shape[0]))","e170b2b3":"out_df[\"rnn\"] = y_test_pred_rnn","85cde72a":"accuracy_function(y_test, y_test_pred_rnn)","683c0bb4":"fig, ax2 = plt.subplots(figsize = (20,5))\nax2.plot(y_test, color=\"red\")\nax2.plot(y_test_pred_rnn, color=\"blue\")\nax2.legend((\"y_test\", \"y_test_pred_rnn\"))\nplt.show()","a5956cee":"trainScore = mean_squared_error(y_train, y_train_pred_rnn)\nprint('Train Score: %.2f MSE' % (trainScore))\ntestScore = mean_squared_error(y_test, y_test_pred_rnn)\nprint('Test Score: %.2f MSE' % (testScore))","7316a2ef":"trainScore = mean_absolute_error(y_train, y_train_pred_rnn)\nprint(\"trainScore : %.2f MAE\" % (trainScore))\ntestScore = mean_absolute_error(y_test, y_test_pred_rnn)\nprint(\"testScore : %.2f MAE\" % (testScore))","73d1f706":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","392fe299":"train = pd.read_csv(\"\/kaggle\/working\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/working\/test.csv\")\ntrain.head()","d4661b98":"train.set_index(\"day\", inplace=True)\ntest.set_index(\"day\", inplace=True)\nX_train = train.drop(\"avg_energy\", axis=1)\ny_train = train[\"avg_energy\"]\nX_test = test.drop(\"avg_energy\", axis=1)\ny_test = test[\"avg_energy\"]","a62e29bd":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","9ad4c2a3":"xg_model = xgb.XGBRegressor(n_estimators=1000, learning_rate = 0.02, max_depth=3)","208fee2f":"\nxg_model.fit(X_train, y_train,\n        eval_set=[(X_train, y_train), (X_test, y_test)], #learning_rate = 0.01, max_depth=4,\n        #early_stopping_rounds=50, #stop if 50 consequent rounds without decrease of error\n        verbose=False)","83641c00":"xgb.plot_importance(xg_model, height=0.9)","b16e5653":"y_train_pred_xg = xg_model.predict(X_train)","ec2cde5b":"y_test_pred_xg = xg_model.predict(X_test)","6314928c":"out_df[\"xg\"] = y_test_pred_xg","f549fbbb":"accuracy_function(y_test, y_test_pred_xg)","a3ead98d":"trainScore = mean_squared_error(y_train, y_train_pred_xg)\nprint('Train Score: %.2f MSE' % (trainScore))\ntestScore = mean_squared_error(y_test, y_test_pred_xg)\nprint('Test Score: %.2f MSE' % (testScore))","e9c67fcb":"trainScore = mean_absolute_error(y_train, y_train_pred_xg)\nprint('Train Score: %.2f MAE' % (trainScore))\ntestScore = mean_absolute_error(y_test, y_test_pred_xg)\nprint('Test Score: %.2f MAE' % (testScore))","baeff915":"def mean_absolute_percentage_error(y_true, y_pred): \n    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","3a1adb2d":"mean_absolute_percentage_error(y_test,y_test_pred_xg)","e428ab25":"fig, ax1 = plt.subplots(figsize=(15,3))\nax1.plot(y_test_pred_xg, label='data')\nax1.plot(y_test, label='prediction')\nax1.set_xlabel('Days-->')\nax1.set_ylabel('Energy Consumed')\nax1.legend((\"y_test_pred_xg\", \"y_test\"))\nax1.tick_params(rotation=45)\n# plt.legend()\n","0d4feb77":"from sklearn.ensemble import GradientBoostingRegressor","29da4788":"\nclf = GradientBoostingRegressor(random_state=10,learning_rate= 0.6, \n                                max_depth= 5, min_samples_leaf= 10, min_samples_split= 9, \n                                n_estimators= 50)\nclf.fit(X_train,y_train)\ny_train_pred_grad = clf.predict(X_train)\ny_test_pred_grad = clf.predict(X_test)","3bea7fc0":"out_df[\"grad\"] = y_test_pred_grad","a3f8aecb":"accuracy_function(y_test, y_test_pred_grad)","317bf148":"trainScore = mean_squared_error(y_train, y_train_pred_grad)\nprint('Train Score: %.2f MSE' % (trainScore))\ntestScore = mean_squared_error(y_test, y_test_pred_grad)\nprint('Test Score: %.2f MSE' % (testScore))","546bb1e6":"trainScore = mean_absolute_error(y_train, y_train_pred_grad)\nprint('Train Score: %.2f MAE' % (trainScore))\ntestScore = mean_absolute_error(y_test, y_test_pred_grad)\nprint('Test Score: %.2f MAE' % (testScore))","5d87ae41":"fig, ax2 = plt.subplots(figsize = (20,5))\nax2.plot(y_test, color=\"red\")\nax2.plot(y_test_pred_grad, color=\"blue\")\nax2.legend((\"y_test\", \"y_test_pred_grad\"))\nplt.show()","6b264d9d":"'''\nlr_range = np.linspace(0.1,1, 5)\nn_est_range = np.arange(10,50,10)\n\ndepth_range = [3,4,5,6,7,8,9]\nminsplit_range = [5,10,20,25,30]\nminleaf_range = [5,10,15]\n\nparameters = dict(learning_rate=lr_range,\n                  n_estimators=n_est_range,\n                  max_depth=depth_range,\n                  min_samples_split=minsplit_range, \n                  min_samples_leaf=minleaf_range)\n\nfrom sklearn.model_selection import KFold\nkfold = KFold(n_splits=5, random_state=2020)\n\nfrom sklearn.model_selection import GridSearchCV\ngrad_reg = GradientBoostingRegressor(random_state=2020)\ncv = GridSearchCV(grad_reg, param_grid=parameters,\n                  cv=kfold,scoring='r2')\n\ncv.fit(X_train,y_train)\n\nprint(cv.best_params_)\n\nprint(cv.best_score_)'''\n","e5e95b44":"from sklearn.ensemble import RandomForestRegressor","6ee8e324":"ran_reg = RandomForestRegressor(random_state=2020)\nran_reg.fit(X_train, y_train)\ny_test_pred_ran = ran_reg.predict(X_test)\ny_train_pred_ran = ran_reg.predict(X_train)","881df2e7":"y_test.shape","e5dda0a4":"accuracy_function(y_test, y_test_pred_ran)","28b0d83f":"trainScore = mean_squared_error(y_train, y_train_pred_ran)\nprint('Train Score: %.2f MSE' % (trainScore))\ntestScore = mean_squared_error(y_test, y_test_pred_ran)\nprint('Test Score: %.2f MSE' % (testScore))","01422c56":"trainScore = mean_absolute_error(y_train, y_train_pred_ran)\nprint('Train Score: %.2f MAE' % (trainScore))\ntestScore = mean_absolute_error(y_test, y_test_pred_ran)\nprint('Test Score: %.2f MAE' % (testScore))","6038a56d":"out_df[\"random\"] = y_test_pred_ran","2d728691":"fig, ax2 = plt.subplots(figsize = (20,5))\nax2.plot(y_test, color=\"red\")\nax2.plot(y_test_pred_ran, color=\"blue\")\nax2.legend((\"y_test\", \"y_test_pred_rnn\"))\nplt.show()","0c2559ec":"from sklearn.linear_model import LinearRegression","be9ef4d6":"train = pd.read_csv(\"\/kaggle\/working\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/working\/test.csv\")\ntrain.head()","654470b9":"X_train = train.drop([\"avg_energy\", \"day\"], axis=1)\ny_train = train[\"avg_energy\"]\nX_test = test.drop([\"avg_energy\", \"day\"], axis=1)\ny_test = test[\"avg_energy\"]\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","65145b72":"lin_reg = LinearRegression(normalize=0.2)\nlin_reg.fit(X_train, y_train)\ny_train_pred_reg = lin_reg.predict(X_train)\ny_test_pred_reg = lin_reg.predict(X_test)","5ed9c6da":"out_df[\"linear\"] = y_test_pred_reg","631f7bcb":"accuracy_function(y_test, y_test_pred_reg)","bba0498c":"trainScore = mean_squared_error(y_train, y_train_pred_reg)\nprint('Train Score: %.2f MSE' % (trainScore))\ntestScore = mean_squared_error(y_test, y_test_pred_reg)\nprint('Test Score: %.2f MSE' % (testScore))","f7e5a99a":"trainScore = mean_absolute_error(y_train, y_train_pred_reg)\nprint('Train Score: %.2f MSE' % (trainScore))\ntestScore = mean_absolute_error(y_test, y_test_pred_reg)\nprint('Test Score: %.2f MSE' % (testScore))","63911793":"fig, ax2 = plt.subplots(figsize = (20,5))\nax2.plot(y_test, color=\"red\")\nax2.plot(y_test_pred_reg, color=\"blue\")\nax2.legend((\"y_test\", \"y_test_pred_reg\"))\nplt.show()","eb248753":"from sklearn.svm import SVR","99a97471":"svm_reg = SVR()\nsvm_reg.fit(X_train, y_train)\ny_train_pred_svm = svm_reg.predict(X_train)\ny_test_pred_svm = svm_reg.predict(X_test)","cc12e1e7":"out_df[\"svm\"] = y_test_pred_svm","5e795cfd":"accuracy_function(y_test, y_test_pred_svm)","7edff232":"trainScore = mean_squared_error(y_train, y_train_pred_svm)\nprint('Train Score: %.2f MSE' % (trainScore))\ntestScore = mean_squared_error(y_test, y_test_pred_svm)\nprint('Test Score: %.2f MSE' % (testScore))","fe3d8768":"trainScore = mean_absolute_error(y_train, y_train_pred_svm)\nprint('Train Score: %.2f MAE' % (trainScore))\ntestScore = mean_absolute_error(y_test, y_test_pred_svm)\nprint('Test Score: %.2f MAE' % (testScore))","c55e4f4f":"fig, ax2 = plt.subplots(figsize = (20,5))\nax2.plot(y_test, color=\"red\")\nax2.plot(y_test_pred_svm, color=\"blue\")\nax2.legend((\"y_test\", \"y_test_pred_svm\"))\nplt.show()","0d16c159":"pip install pmdarima","52aeec1d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n%matplotlib inline\nfrom sklearn.metrics import r2_score\nimport statsmodels.api as sm\nfrom pmdarima.arima import auto_arima","94ec7ee9":"#train = pd.read_csv(\"\/kaggle\/working\/train.csv\")\n#test = pd.read_csv(\"\/kaggle\/working\/test.csv\")\nfinal = pd.read_csv(\"\/kaggle\/working\/final.csv\")","d10f7ef1":"#train.head()\nsari_columns = ['temperatureMax', 'dewPoint',#'weather_cluster',\n       \n       'temperatureMin',\n       'uvIndex', 'temperatureLow', \n       'temperatureHigh', \n       'avg_energy']#, 'month', 'datetime']","5d2a835b":"final.head()","4248f504":"final.columns","cf30b5c1":"# scaler = MinMaxScaler()\n# train_scaled = scaler.fit_transform(train)\n# train_scaled_df = pd.DataFrame(train_scaled)\n# train_scaled_df.head()","8b38b98c":"t = sm.tsa.adfuller(final[\"avg_energy\"], autolag='AIC',regression='ct')\npd.Series(t[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])","178d2719":"final[\"day\"] = pd.to_datetime(final[\"day\"])\nfinal.set_index(\"day\", inplace=True)\nfinal_sample = final.resample(\"W\").mean()\nfinal_sample.head()","5ca452ff":"t = sm.tsa.adfuller(final_sample[\"avg_energy\"], autolag='AIC',regression='ct')\npd.Series(t[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])","1bb76eab":"final_sample.shape","205b292a":"train = final_sample[sari_columns][:(len(final_sample)-7)]\ntest = final_sample[sari_columns][len(final_sample)-7:]","b3670840":"len(train), len(test)","02910916":"seas_d=sm.tsa.seasonal_decompose(train['avg_energy'],model=\"additive\",freq=52)\nfig=seas_d.plot()\nfig.set_figheight(15)\nfig.set_figwidth(15)\nplt.show()","e224bb84":"X_train=train.drop(\"avg_energy\", axis=1)\ny_train=train[\"avg_energy\"]\nX_test=test.drop(\"avg_energy\", axis=1)\ny_test=test[\"avg_energy\"]\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","88d90d9e":"model = auto_arima(y_train, exogenous=X_train, start_p=1, start_q=1, max_p=3, max_q=3, m=52,\n                    seasonal=True,trace=True, error_action='ignore', suppress_warnings=True,\n                    stepwise=True)","c41f97d2":"model.aic()","29637a89":"model_order = model.order\nmodel_seasonal_order = model.seasonal_order\n#model_order = (0, 1, 1)\n#model_seasonal_order = (0, 0, 0, 52)","d274eb40":"model_sarimax = sm.tsa.statespace.SARIMAX(endog = y_train,order=model_order,\n                                          seasonal_order=model_seasonal_order, \n                                          exog = X_train,enforce_stationarity=False, \n                                          enforce_invertibility=False)","0733fad2":"model_fit = model_sarimax.fit()","e97c2c6a":"model_fit.summary()","cf52f40f":"print(max(X_test.index))\nprint(min(X_test.index))","cbe6ae52":"print(max(X_train.index.date))\nprint(min(X_train.index.date))","792c6b8c":"y_train_pred_sarimax = model_fit.predict(start=min(X_train.index.date), end=max(X_train.index.date),exog = X_train)\ny_train_pred_sarimax.head()","a3205a8a":"y_test_pred_sarimax = model_fit.predict(start=min(X_test.index.date), end=max(X_test.index.date),exog = X_test)\ny_test_pred_sarimax.head()","ea0b75f3":"forecast=model_fit.forecast(steps='2014-03-02', exog=X_test)","455f78ff":"r2_score(y_train, y_train_pred_sarimax)","72b1a73c":"r2_score(y_test, y_test_pred_sarimax)","8fcab17b":"trainScore = mean_squared_error(y_train, y_train_pred_sarimax)\nprint('Train Score: %.2f MSE' % (trainScore))\ntestScore = mean_squared_error(y_test, y_test_pred_sarimax)\nprint('Test Score: %.2f MSE' % (testScore))","c50e4d22":"trainScore = mean_absolute_error(y_train, y_train_pred_sarimax)\nprint('Train Score: %.2f MAE' % (trainScore))\ntestScore = mean_absolute_error(y_test, y_test_pred_sarimax)\nprint('Test Score: %.2f MAE' % (testScore))","f6928be1":"y_test.plot(figsize=(20,8), legend=True, color='blue')\ny_test_pred_sarimax.plot(legend=True, color='red', figsize=(20,8))","3cc89b6f":"out_df.head()","a2f0e6d9":"#out_df.drop(\"svm\", axis=1, inplace=True)\n#out_df.head()","bce0927d":"def final_output(df):\n    \n    y_out_pred = df.mean(axis=1)\n    \n    return y_out_pred\n\ny_out_pred = final_output(out_df)\ny_out_pred.head()","b389fb75":"test = pd.read_csv(\"\/kaggle\/working\/test.csv\")\ny_test = test[\"avg_energy\"]","9435168b":"y_test.shape, y_out_pred.shape","eddcac51":"r2_score(y_test, y_out_pred)","63a4371f":"accuracy_function(y_test, y_out_pred)","b556fbe9":"testScore = mean_squared_error(y_test, y_out_pred)\nprint('Test Score: %.2f MSE' % (testScore))","1750e025":"testScore = mean_absolute_error(y_test, y_out_pred)\nprint('Test Score: %.2f MSE' % (testScore))","5c008f4d":"fig, ax2 = plt.subplots(figsize = (20,5))\nax2.plot(y_test, color=\"red\")\nax2.plot(y_out_pred, color=\"blue\")\nax2.legend((\"y_test\", \"y_out_pred\"))\nplt.show()","5f54f7d8":"## Mean Squared Error","e5af1ceb":"# MEAN OF ALL OUTPUT","72c979d6":"### Mean Absolute Error","e1a63ce8":"##  Instantiation of an XGBoost Regressor","a5afe3e9":"## Normalization of X_train and X_test","5bc45b7d":"# SARIMAX","9de9e0b8":"### Mean Absolute Error","bde43c93":"## Initiating out_df","0a3e06b0":"### accuracy score","eb98a278":"# Random Forest Tree","76f52292":"We can use an additive model when it seems that the trend is more linear and the seasonality and trend components seem to be constant over time (e.g. every year we add 100 units of energy production). A multiplicative model is more appropriate when we are increasing (or decreasing) at a non-linear rate (e.g. each year we double the amount of energy production everyyear).","933e7e07":"### Instantiation of Random Forest Regressor","36795b30":"## r2 score for train and test dataset","02ae50f3":"# Using XGBOOST","6387abe0":"# **Using fbprophet**","33cc1256":"### Instantiation of Support Vector Regressor","fdb6abab":"### Mean Absolute Error","b8e76e77":"## Mean absolute error","4e5eaed9":"### Mean Absolute Error","ffeb33dc":"### Mean Squared Error","9e479fb6":"# Feature Selection ","8b5dd203":"# Apply RNN ","3258bb26":"# SUPPORT VECTOR MACHINE","174564b9":"# Dickey Fuller's Test\n\nADF-test(Original-time-series)\n\nFor Average Energy Per Day\n\nWhen Original-data is not stationary and Differenced-data is stationary,the time series is called unit root process.\n\nFor unit root process, we use ARIMA or SARIMA model. From results, we decided that Original time series is not stationary\n\nH0 : Data is not stationary H1 : Data is stationary\n\nIf p is greater than 0.05 then data is not stationary\n\nWhat is adfuller method parameter 'regression'?\n\n\u2019c\u2019 : constant only (default) \u2019ct\u2019 : constant and trend \u2019ctt\u2019 : constant, and linear and quadratic trend \u2019nc\u2019 : no constant, no trend\n\nADF-test(differenced-time-series)\n","e54e4b94":"test dataset is stationary","5bfe9e06":"### accuracy score","aefe7b3d":"## Future Prediction for next 1 year","66b30fec":"# Linear Regression","88642ac6":"# Seasonal Decompose\nWe use statsmodel for seasonal decompose as an additive model and the frequency of the time series which is the periodicity of the data which is 365 days for an yearly data.\nAdditive model = Trend + Seasonality + Random Noise","8910d4f0":"### Mean Absolute Error","a41f32b6":"### Instantiation of LinearRegression","8df7c962":"### accuracy score","3ed6309f":"Data is not stationary so apply resampling of train dataset","4745c106":"### Anlysis with cross_validation","f93a9535":"## Mean squared error","e57476a0":"# Accuracy Function","a8356d04":"# Heatmap","da03bb64":"## make model with Prophet by Facebook","4d0c5488":"# Gradient Boosting Regressor","a1f1c7c7":"split data into X_train, y_train, X_test and y_test form","76fba68c":"## Save File to csv","fbf74c2d":"### Mean Squared Error","5f1b9b64":"### Mean Squared Error","6cfeb450":"### Instantiation of GradientBoostingRegressor","267d5983":"# Forecast on Test Set","cd9784d2":"### With performance_metrics, we can visualize the score","ab79cc2c":"### accuracy score","21d95749":"### accuracy score","30903478":"### calculate root mean squared error"}}