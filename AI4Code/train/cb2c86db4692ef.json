{"cell_type":{"dc5d4ff7":"code","0a6575bb":"code","08d9d778":"code","77679fa0":"code","a0a72ba0":"code","e841acc1":"code","11a2b8cb":"code","36aaac7e":"code","18bc2bd2":"code","4aedbc87":"code","d1d66b3d":"code","c8cbd8c6":"code","0f3e3c1b":"code","da165827":"code","61ae9a44":"code","efcf3b3e":"code","44f7ee4a":"code","5f125645":"code","c8d253da":"code","7d320348":"code","b4fe81d1":"code","c40308cd":"code","6aeb22a1":"code","ca191073":"code","bccf8ccd":"markdown","bc8ae94e":"markdown","82e696ac":"markdown","fe39ade9":"markdown","d5bc88a7":"markdown","4e8c921b":"markdown","1eec3342":"markdown","492cceca":"markdown","eb556ae4":"markdown","68634e68":"markdown","44653725":"markdown","a4149fa8":"markdown","faac6dfa":"markdown"},"source":{"dc5d4ff7":"import tensorflow as tf\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nfrom tensorflow.keras import layers\nimport time\nfrom IPython import display","0a6575bb":"(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()","08d9d778":"train_images.shape","77679fa0":"train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\ntrain_images = (train_images - 127.5) \/ 127.5 # Normalize the images to [-1, 1]","a0a72ba0":"BUFFER_SIZE = 60000\nBATCH_SIZE = 256","e841acc1":"train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","11a2b8cb":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((7, 7, 256)))\n    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 7, 7, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14, 14, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 28, 28, 1)\n\n    return model","36aaac7e":"generator = make_generator_model()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 0])","18bc2bd2":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","4aedbc87":"discriminator = make_discriminator_model()\ndecision = discriminator(generated_image)\nprint (decision)","d1d66b3d":"# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","c8cbd8c6":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","0f3e3c1b":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","da165827":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","61ae9a44":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","efcf3b3e":"EPOCHS = 100\nnoise_dim = 100\nnum_examples_to_generate = 16\n\n# We will reuse this seed overtime (so it's easier)\n# to visualize progress in the animated GIF)\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","44f7ee4a":"# Notice the use of `tf.function`\n# This annotation causes the function to be \"compiled\".\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = discriminator(images, training=True)\n      fake_output = discriminator(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","5f125645":"def train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    # Produce images for the GIF as we go\n    display.clear_output(wait=True)\n    generate_and_save_images(generator, epoch + 1,seed)\n\n    # Save the model every 15 epochs\n    if (epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n  # Generate after the final epoch\n  display.clear_output(wait=True)\n  generate_and_save_images(generator, epochs, seed)","c8d253da":"def generate_and_save_images(model, epoch, test_input):\n  # Notice `training` is set to False.\n  # This is so all layers run in inference mode (batchnorm).\n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(10,10))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5)\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()","7d320348":"train(train_dataset, EPOCHS)","b4fe81d1":"# Display a single image using the epoch number\ndef display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","c40308cd":"display_image(EPOCHS)","6aeb22a1":"anim_file = 'dcgan.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  last = -1\n  for i,filename in enumerate(filenames):\n    frame = 2*(i**0.5)\n    if round(frame) > round(last):\n      last = frame\n    else:\n      continue\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\nimport IPython\nif IPython.version_info > (6,2,0,''):\n  display.Image(filename=anim_file)","ca191073":"try:\n  from google.colab import files\nexcept ImportError:\n   pass\nelse:\n  files.download(anim_file)","bccf8ccd":"Checking discriminator to discriminate the above generated image","bc8ae94e":"The below code snippet is used to download the GIF of all the training images","82e696ac":"# Loading Fashion MNIST Images","fe39ade9":"# Defining training paprameters","d5bc88a7":"# Importing Library","4e8c921b":"# Creating Generator Module of GAN","1eec3342":"# Defining training process","492cceca":"# Generative Adversarial Network (GAN) for Fake Image Generation","eb556ae4":"This function will save the images that are generated during training process","68634e68":"# Checking Generator by generating a random image","44653725":"Now, the training will start","a4149fa8":"In this implementation, we will train the Deep Convolutional Generative Adversarial Network on Fashion MNIST training images in order to generate a new set of fashion apparel images.","faac6dfa":"# Defining Discriminator Module of GAN"}}