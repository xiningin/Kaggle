{"cell_type":{"d5117a1a":"code","e0d15172":"code","a810ef57":"code","b76aa45a":"code","262acbc1":"code","9bcfe6bd":"code","aef94095":"code","0df11fb7":"code","faab9aec":"code","db88b42b":"code","9af20de6":"code","da166fed":"code","8d63e18f":"code","5dfd18ad":"code","58e6e1f8":"code","5a393bbd":"code","5e37047b":"code","345fbeda":"code","4599f0f2":"code","e24bf2d0":"code","ac2e7dd1":"code","0e6b5df3":"code","d25d2c20":"code","d0526a50":"markdown","909de5eb":"markdown","ab05c4fd":"markdown","7e9f8629":"markdown","bc64a7c1":"markdown","4195ffc8":"markdown","82a2d0ae":"markdown","463dd70a":"markdown","ac2f1c71":"markdown","f2ac75fb":"markdown","fd77c80b":"markdown","7916e7ff":"markdown","fb03faee":"markdown","ed91d793":"markdown","308238b1":"markdown","fabb7424":"markdown","308285d8":"markdown","93ca3252":"markdown","af86682d":"markdown","fa8b2b32":"markdown","be5a1b32":"markdown"},"source":{"d5117a1a":"import pandas as pd\nimport numpy as np  \nimport matplotlib.pyplot as plt  \n#import seaborn as seabornInstance \n#from sklearn.model_selection import train_test_split \nfrom sklearn.ensemble import AdaBoostClassifier\nimport sklearn.metrics as metrics\n%matplotlib inline","e0d15172":"#flightdata = pd.read_csv(\"https:\/\/introtomlsampledata.blob.core.windows.net\/data\/flightdelays\/flightdelays.csv\")\nflightdata = pd.read_csv(r\"..\/input\/flightdelays\/flightdelays.csv\")","a810ef57":"print(flightdata.shape)\nflightdata.columns","b76aa45a":"flightdata.dtypes","262acbc1":"flightdata.head(10)","9bcfe6bd":"#flightdata.describe()\ncarrierlist = list(flightdata.Carrier.unique())\ncarrierlist.sort()","aef94095":"carrierdict = {carrierlist[i]: list(range(len(carrierlist)))[i] for i in range(len(carrierlist))} \nflightdata[\"Carrier\"] = flightdata[\"Carrier\"].replace(carrierdict) \nflightdata.Carrier.unique()","0df11fb7":"train = flightdata[flightdata[\"Month\"] < 10]\ntest = flightdata[flightdata[\"Month\"] >= 10]\nprint(train.shape, test.shape)","faab9aec":"train = train.drop(\n    [\"Month\", \"Year\", \"Year_R\", \"Timezone\", \"Timezone_R\"], axis=1)\ntest = test.drop([\"Month\", \"Year\", \"Year_R\", \"Timezone\", \"Timezone_R\"], axis=1)\nprint(train.shape, test.shape)","db88b42b":"trainX = train.drop([\"ArrDel15\"],axis = 1)\ntrainy = train[\"ArrDel15\"]\nprint(trainX.shape,trainy.shape)","9af20de6":"testX = test.drop([\"ArrDel15\"],axis = 1)\ntesty = test[\"ArrDel15\"]\nprint(testX.shape,testy.shape)","da166fed":"model = AdaBoostClassifier()\nmodel.fit(trainX, trainy)","8d63e18f":"predicted_classes = model.predict(testX)\naccuracy = metrics.accuracy_score(testy,predicted_classes)","5dfd18ad":"accuracy","58e6e1f8":"confusion = metrics.confusion_matrix(testy, model.predict(testX))\nprint(confusion)\n#[row, column]\nTP = confusion[1, 1]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]","5a393bbd":"# use float to perform true division, not integer division\nprint((TP + TN) \/ float(TP + TN + FP + FN))\nprint(metrics.accuracy_score(testy, model.predict(testX)))","5e37047b":"classification_error = (FP + FN) \/ float(TP + TN + FP + FN)\n\nprint(classification_error)\nprint(1 - metrics.accuracy_score(testy, model.predict(testX)))","345fbeda":"sensitivity = TP \/ float(FN + TP)\n\nprint(sensitivity)\nprint(metrics.recall_score(testy, model.predict(testX)))","4599f0f2":"specificity = TN \/ (TN + FP)\n\nprint(specificity)","e24bf2d0":"false_positive_rate = FP \/ float(TN + FP)\n\nprint(false_positive_rate)\nprint(1 - specificity)","ac2e7dd1":"precision = TP \/ float(TP + FP)\n\nprint(precision)\nprint(metrics.precision_score(testy, model.predict(testX)))","0e6b5df3":"# calculate the fpr and tpr for all thresholds of the classification\nprobs = model.predict_proba(testX)\npreds = probs[:,1]\nfpr, tpr, threshold = metrics.roc_curve(testy, preds)\nroc_auc = metrics.auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","d25d2c20":"# IMPORTANT: first argument is true values, second argument is predicted probabilities\nprint(metrics.roc_auc_score(testy, preds))","d0526a50":"Plotting the ROC curve","909de5eb":"Calculating the specificity using the confusion matrix.","ab05c4fd":"Calculating the classification error using the confusion matrix.","7e9f8629":"Creating a dictionary using dictionary comprehension.\n\nParsing the dictionary to replace() method to find and replace \"keys\" with \"values\".\n\nMore on Dictionary Comprehensions: https:\/\/www.programiz.com\/python-programming\/dictionary-comprehension","bc64a7c1":"Creating trainX, trainy, textX and testy.","4195ffc8":"Calculating the precision using the confusion matrix.","82a2d0ae":"Initialising our classifier and fitting.\n\nMore ensemble methods: https:\/\/scikit-learn.org\/stable\/modules\/ensemble.html","463dd70a":"Calculating the sensitivity using the confusion matrix.","ac2f1c71":"Looking at the top 10 records in the dataset.","f2ac75fb":"Importing the required libraries:\n\n\n* pandas: For reading and manipulating our dataset\n* numpy: Used for working on arrays\n* matplotlib: For plotting\n* sklearn.ensemble: For importing our AdaBoost Classifier\n* sklearn.metrics: Importing this will enable us to use different metrics for evaluating our model","fd77c80b":"Splitting into test and train dataset.","7916e7ff":"Calculating the confusion matrix.","fb03faee":"Here, we are encoding the \"Carrier\" categorical column.\n\nunique() is used to find out the unique values in a DataFrame column.\n\nsort() is used to sort the list.","ed91d793":"Having a first glance at the data. shape, columns and dtypes attributes are used.","308238b1":"Calculating the accuracy using the confusion matrix.","fabb7424":"Calculating the roc_auc_score\n","308285d8":"Calculating the false positive rate using the confusion matrix.","93ca3252":"Dropping the \"Month\", \"Year\", \"Year_R\", \"Timezone\", \"Timezone_R\" columns from the test and train datasets.\n","af86682d":"Using a predownloaded dataset instead of the link as the dataset is huge and there has been some download issues","fa8b2b32":"<h1>Lab6: Train a two class decision forest<\/h1>\n\nIn this lab, we will be using the Flight Delays data set that is enhanced with the weather data. Based on the enriched dataset, we will learn to use the Python and Jupyter Notebook to process data, build, train, score, and evaluate a classification model to predict if a particular flight will be delayed by 15 minutes or more.\n","be5a1b32":"Predicting and calculating the Accuracy."}}