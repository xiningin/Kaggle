{"cell_type":{"cb7eee4a":"code","cbc53ab0":"code","530ce879":"code","deead74d":"code","7d79a09e":"code","ec58428a":"code","e57c99cb":"code","d087b428":"code","86ce6b00":"code","0fab58df":"code","cf8bb6ed":"code","a9c55a7d":"code","d072ba39":"code","6fe1b112":"code","8a8e9d05":"code","2eb88d6e":"code","f4dc1f86":"code","e17ce75a":"code","501b284d":"code","3baa02cc":"code","b9f2be95":"code","679be726":"code","7c3a3916":"markdown","0bede606":"markdown","6acae624":"markdown","1cfebebf":"markdown","1f1cfffc":"markdown","da432e69":"markdown","7a16c7f6":"markdown","291e12f9":"markdown","9a65bacf":"markdown","eb52a2d6":"markdown","f2868280":"markdown","ac684bbe":"markdown","c55ba455":"markdown","927f61e4":"markdown","2fd057e9":"markdown"},"source":{"cb7eee4a":"# \u8981\u6dfb\u52a0\u4e00\u4e2a\u65b0\u5355\u5143\uff0c\u8f93\u5165 '# %%'\n# \u8981\u6dfb\u52a0\u4e00\u4e2a\u65b0\u7684\u6807\u8bb0\u5355\u5143\uff0c\u8f93\u5165 '# %% [markdown]'","cbc53ab0":"\nEXT_PATH=r''\n# EXT_PATH=r'\/home\/aistudio\/external-libraries'\n\nDATA_PATH=r'..\/input\/shopee-product-matching\/'\n\nCNN_MODEL='resnet34'\nCNN_MODEL_PATH='..\/input\/shopee-models\/shopee34_119.pth'\n\nIMG_DIST_THRESHOLD = 0.7\nIMG_CHUNK = 1024*4\n\nNUM_WORKERS=2\n\nimport os\nif EXT_PATH:\n    os.sys.path.insert(0, EXT_PATH)","530ce879":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm.notebook import tqdm\n# from tqdm import tqdm\nimport torch\nfrom sklearn.feature_extraction.text import TfidfVectorizer","deead74d":"# \u8ba1\u7b97\u4ea4\u53c9\u9a8c\u8bc1\nCOMPUTE_CV = True\nHAS_CUDA = torch.cuda.is_available()\nDEVICE = 'cuda' if HAS_CUDA else 'cpu'\nif COMPUTE_CV:\n    print('this submission notebook will compute CV score, but commit notebook will not')\nelse:\n    print('this submission notebook will not compute CV score')\n\ntest = pd.read_csv(DATA_PATH + 'test.csv')\nif len(test)>3: COMPUTE_CV = False\n\nprint('COMPUTE_CV:', COMPUTE_CV)","7d79a09e":"def getMetric(col_name):\n    \"\"\"\u8ba1\u7b97f1_score\n\n    Args:\n        col_name: \u9884\u6d4b\u5217\n    \"\"\"\n    def f1score(row):\n        # f1 = 2tp\/(tp+fn+tp+fp) = 2tp\/(len(target)+len(predict))\n        n = len( np.intersect1d(row.target,row[col_name]) )\n        return 2*n \/ (len(row.target)+len(row[col_name]))\n    return f1score","ec58428a":"if COMPUTE_CV:\n    train = pd.read_csv(DATA_PATH + 'train.csv')\n    train['image'] = DATA_PATH + 'train_images\/' + train['image']\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    # target: [pid1, pid2, ...]\n    train['target'] = train.label_group.map(tmp)\nelse:\n    train = pd.read_csv(DATA_PATH + 'test.csv')\n    train['image'] = DATA_PATH + 'test_images\/' + train['image']\n    \nprint('train shape is', train.shape )\ntrain.head()","e57c99cb":"tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\ntrain['oof_hash'] = train.image_phash.map(tmp)","d087b428":"if COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_hash'),axis=1)\n    print('CV score for baseline =',train.f1.mean())","86ce6b00":"# \u62f7\u8d1d\u9884\u8bad\u7ec3\u6a21\u578b\nimport os\nimport shutil\npretrained_pytorch_models = r'..\/input\/pretrained-pytorch-models\/'\nif os.path.isdir(pretrained_pytorch_models):    \n    pretrained_dir = f'{torch.hub.get_dir()}\/checkpoints\/'\n    os.makedirs(pretrained_dir, exist_ok=True)\n    shutil.copy(os.path.join(pretrained_pytorch_models, 'resnet18-5c106cde.pth'), pretrained_dir)","0fab58df":"\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\nfrom torch.nn import functional as F\nfrom torch.nn import DataParallel\n\nimport torch\nimport torch.nn as nn\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.fc1   = nn.Conv2d(in_planes, in_planes \/\/ 16, 1, bias=False)\n        self.relu1 = nn.ReLU()\n        self.fc2   = nn.Conv2d(in_planes \/\/ 16, in_planes, 1, bias=False)\n\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n        out = avg_out + max_out\n        return self.sigmoid(out)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n        padding = 3 if kernel_size == 7 else 1\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass BasicBlockShopee(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None, use_se=True):\n        super(BasicBlockShopee, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.use_se = use_se\n        self.ca = ChannelAttention(planes)\n        self.sa = SpatialAttention()\n\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.use_se:            \n            out = self.ca(out) * out\n            out = self.sa(out) * out\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\nclass ResNetShopee(nn.Module):\n    def __init__(self, block, layers, use_se=True):\n        self.inplanes = 64\n        self.use_se = use_se\n        super(ResNetShopee, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.prelu = nn.PReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.bn4 = nn.BatchNorm2d(512)\n        self.dropout = nn.Dropout()\n        self.fc5 = nn.Linear(512 * 8 * 8, 512)\n        self.bn5 = nn.BatchNorm1d(512)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.xavier_normal_(m.weight)\n            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, use_se=self.use_se))\n        self.inplanes = planes\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, use_se=self.use_se))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.prelu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.bn4(x)\n        x = self.dropout(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc5(x)\n        x = self.bn5(x)\n\n        return x\n\ndef resnet_shopee18(use_se=True, **kwargs):\n    model = ResNetShopee(BasicBlockShopee, [2, 2, 2, 2], use_se=use_se, **kwargs)\n    return model\n\ndef resnet_shopee34(use_se=True, **kwargs):\n    model = ResNetShopee(BasicBlockShopee, [3, 4, 6, 3], use_se=use_se, **kwargs)\n    return model\n\ndef get_model(model, model_path=None, device='cuda', use_se=True) -> nn.Module:\n    if model == 'resnet18':\n        model = resnet_shopee18(use_se=use_se)\n    elif model == 'resnet34':\n        model = resnet_shopee34(use_se=use_se)\n    else:\n        raise NotImplemented\n    model = DataParallel(model)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model = model.to(device)\n    return model","cf8bb6ed":"from torch.utils.data.dataset import Dataset\nfrom PIL import Image\nimport torch\nimport numpy as np\nfrom torchvision import transforms as T\nimport pandas as pd\n\nclass ShopeeImageDataset(Dataset):\n\n    def __init__(self, imgs, input_shape=(1, 128, 128)):\n        self.input_shape = input_shape\n        # columns: 'posting_id', 'image', 'image_phash', 'title', 'label_group'\n\n        self.imgs = imgs\n        self.transforms = T.Compose([\n            # T.CenterCrop(self.input_shape[1:]),\n            T.Resize(self.input_shape[1:]),\n            T.ToTensor(),\n            T.Normalize(mean=[0.5], std=[0.5])\n        ])\n\n    def __getitem__(self, index):\n        img_path = self.imgs[index]\n        data = Image.open(img_path)\n        data = data.convert('L')\n        data = self.transforms(data)\n        return data.float()\n\n    def __len__(self):\n        return len(self.imgs)","a9c55a7d":"imagedataset = ShopeeImageDataset(train['image'].values)\n\nimageloader = torch.utils.data.DataLoader(\n    imagedataset,\n    batch_size=10, shuffle=False,  num_workers=NUM_WORKERS,drop_last=False,\n)","d072ba39":"# backbone, model_path=None, device='cuda', use_se=False\n\nprint('CNN_MODEL:', CNN_MODEL)\nprint('CNN_MODEL_PATH:', CNN_MODEL_PATH)\n\nimgmodel = get_model(CNN_MODEL, os.path.join(CNN_MODEL_PATH), device=DEVICE)\nimgmodel = imgmodel.to(DEVICE)","6fe1b112":"imgmodel.eval()\nimagefeat = []\nwith torch.no_grad():\n    for data in tqdm(imageloader):\n        data = data.to(DEVICE)\n        feat = imgmodel(data)\n        feat = feat.reshape(feat.shape[0], feat.shape[1])\n        # feat = feat.data.cpu().numpy()\n        \n        imagefeat.append(feat)\n\nimagefeat = torch.cat(imagefeat)\nimagefeat = F.normalize(imagefeat)\n\nprint('img embeddings shape',imagefeat.shape)\nprint('img embeddings device',imagefeat.device)","8a8e9d05":"preds = []\nCHUNK = IMG_CHUNK\n\nprint('Finding similar images...')\nCTS = len(imagefeat)\/\/CHUNK\nif len(imagefeat)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b, len(imagefeat))\n    print('chunk',a,'to',b)\n    \n    distances = torch.matmul(imagefeat[a:b], imagefeat.T)\n    \n    for k in range(b-a):\n        # dists, IDX = torch.topk(distances[k,], limit_count)\n        # IDX = IDX[dists > IMG_DIST_THRESHOLD]\n\n        IDX = torch.where(distances[k,]>IMG_DIST_THRESHOLD)[0]\n        top_idx = torch.topk(distances[k,][IDX], min(len(IDX), 51))[1]\n        IDX = IDX[top_idx]\n\n        # IDX = torch.where(distances[k,]>IMG_DIST_THRESHOLD)[0]\n        o = train.iloc[IDX.data.cpu().numpy()].posting_id.values\n        preds.append(o)\n\n    del distances","2eb88d6e":"del imgmodel, imagefeat\ntrain['oof_cnn'] = preds\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_cnn'),axis=1)\n    print('CV score for baseline =',train.f1.mean())","f4dc1f86":"model = TfidfVectorizer(stop_words=None, binary=True, max_features=25000)\ntext_embeddings = model.fit_transform(train.title).toarray()\n\ntext_embeddings = torch.from_numpy(text_embeddings).to(DEVICE)\nprint('text embeddings shape',text_embeddings.shape)\nprint('text embeddings device',text_embeddings.device)","e17ce75a":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(text_embeddings)\/\/CHUNK\nif len(text_embeddings)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(text_embeddings))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    # cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n    cts = torch.matmul(text_embeddings[a:b], text_embeddings.T)\n\n    for k in range(b-a):\n        # dists, IDX = torch.topk(cts[k,], limit_count)\n        # IDX = IDX[dists > 0.7]\n        IDX = torch.where(cts[k,]>0.7)[0]\n        top_idx = torch.topk(cts[k,][IDX], min(len(IDX), 51))[1]\n        IDX = IDX[top_idx]\n\n        # IDX = np.where(cts[k,]>0.7)[0]\n        # IDX = cupy.where(cts[k,]>0.7)[0]\n        o = train.iloc[IDX.data.cpu().numpy()].posting_id.values\n        preds.append(o)\n    del cts","501b284d":"del model, text_embeddings\ntrain['oof_text'] = preds\n\nif COMPUTE_CV:\n    train['f1'] = train.apply(getMetric('oof_text'),axis=1)\n    print('CV score for baseline =',train.f1.mean())","3baa02cc":"def combine_for_sub(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return ' '.join( np.unique(x) )\n\ndef combine_for_cv(row):\n    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n    return np.unique(x)","b9f2be95":"if COMPUTE_CV:\n    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n    train['target'] = train.label_group.map(tmp)\n    train['oof'] = train.apply(combine_for_cv,axis=1)\n    train['f1'] = train.apply(getMetric('oof'),axis=1)\n    print('CV Score =', train.f1.mean() )\n\ntrain['matches'] = train.apply(combine_for_sub,axis=1)","679be726":"train[['posting_id','matches']].to_csv('submission.csv',index=False)\nsub = pd.read_csv('submission.csv')\nsub.head()","7c3a3916":"### \u52a0\u8f7d\u6a21\u578b","0bede606":"### \u8ba1\u7b97 image CNN \u9884\u6d4b\u7ed3\u679c","6acae624":"## \u73af\u5883\u914d\u7f6e","1cfebebf":"---\n## utils","1f1cfffc":"---\n## image hash \u7279\u5f81","da432e69":"---\n## \u914d\u7f6e","7a16c7f6":"### \u52a0\u8f7d\u6570\u636e\u96c6","291e12f9":"---\n### Datasets","9a65bacf":"---\n### Models","eb52a2d6":"---\n## \u7ec4\u5408\u6240\u6709\u7279\u5f81","f2868280":"---\n## title TFIDF","ac684bbe":"---\n## image CNN \u7279\u5f81","c55ba455":"### \u8ba1\u7b97 image CNN \u7279\u5f81","927f61e4":"---\n## import","2fd057e9":"---\n## \u52a0\u8f7d\u6570\u636e"}}