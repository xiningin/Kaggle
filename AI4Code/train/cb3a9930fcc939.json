{"cell_type":{"321704cc":"code","ddd46e7b":"code","cd7ae931":"code","4c3a6e78":"code","40b77773":"code","63c60eea":"code","b445e383":"code","c494055d":"code","56ddbf5e":"code","4e1c4b6d":"code","da749ff7":"code","73c22b7d":"code","a0fb5670":"code","db23ed3d":"code","b493d763":"code","071fde84":"code","e1105060":"code","afe03b78":"code","e57fbfc1":"code","6554aa14":"code","589ca0cb":"markdown","03a69375":"markdown","745ceaca":"markdown","053deafd":"markdown"},"source":{"321704cc":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ddd46e7b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier","cd7ae931":"from sklearn.model_selection import GridSearchCV","4c3a6e78":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)\ntrain_df.head()","40b77773":"#check the survival with respect to Pclass\ntrain_df[['Pclass','Survived']].groupby('Pclass').mean().sort_values(by = 'Survived', ascending = False)","63c60eea":"train_df[['Sex','Survived']].groupby('Sex').mean().sort_values(by = 'Survived', ascending = False)","b445e383":"train_df[['SibSp','Survived']].groupby('SibSp').mean().sort_values(by = 'Survived', ascending = False)","c494055d":"train_df[['Parch','Survived']].groupby('Parch').mean().sort_values(by = 'Survived', ascending = False)","56ddbf5e":"#converting categorial variable sex into encoding\nlabelencoder = LabelEncoder()\ntrain_df['Sex'] = labelencoder.fit_transform(train_df['Sex'])\ntest_df['Sex'] = labelencoder.fit_transform(test_df['Sex'])\ntest_df.head()","4e1c4b6d":"bins = [0,16,32,48,64,200]\nlabels = [0,1,2,3,4]\ntrain_df['Age Bin'] = pd.cut(train_df['Age'], bins=bins, labels=labels)\ntest_df['Age Bin'] = pd.cut(test_df['Age'], bins=bins, labels=labels)\ntrain_df.head()","da749ff7":"train_df['Family size'] = train_df['SibSp'] + train_df['Parch'] + 1\ntest_df['Family size'] = test_df['SibSp'] + test_df['Parch'] + 1\ntrain_df[['Family size','Survived']].groupby('Family size').mean().sort_values(by = 'Survived', ascending = False)","73c22b7d":"train_df['Fam_type'] = pd.cut(train_df['Family size'], [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\ntest_df['Fam_type'] = pd.cut(test_df['Family size'], [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])","a0fb5670":"combine = [train_df, test_df]\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","db23ed3d":"for dataset in combine:\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Don', 'Sir', 'Jonkheer', 'Dona'],'Royalty')\n    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col','Dr','Major','Rev'],'Special')\n\ntrain_df[['Title','Survived']].groupby(['Title'], as_index=False).mean()","b493d763":"train_df.head()","071fde84":"#first features extraction\ny = train_df['Survived']\nfeatures = ['Pclass','Sex','Fam_type','Fare','Age Bin','Embarked']\nX = train_df[features]\nX.head()","e1105060":"numerical_col = ['Fare']\ncategorical_col = ['Pclass','Sex','Fam_type','Age Bin','Embarked']\nnum_trans = SimpleImputer(strategy = 'median')\ncat_trans = Pipeline(steps = [\n    ('imputer',SimpleImputer(strategy = 'most_frequent')),\n    ('onehot',OneHotEncoder())\n])\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('num',num_trans,numerical_col),\n        ('cat',cat_trans,categorical_col)\n])\ntitanic_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', RandomForestClassifier(random_state=0\n                                                               ))\n                                  ])\n#titanic_pipeline.fit(X,y)\nparam_grid = {\n    'model__max_depth': [2, 3, 4, 5],\n    'model__min_samples_leaf': [3, 4, 5],\n    'model__min_samples_split': [6, 8, 10, 12],\n    'model__n_estimators': [100, 200, 300, 500]\n}\nsearch = GridSearchCV(titanic_pipeline, param_grid, n_jobs=-1)\nsearch.fit(X, y)\nprint(search.best_params_)\n#print('Cross validation score: {:.3f}'.format(cross_val_score(titanic_pipeline, X, y, cv=10).mean()))","afe03b78":"numerical_col = ['Fare']\ncategorical_col = ['Pclass','Sex','Fam_type','Age Bin','Embarked']\nnum_trans = SimpleImputer(strategy = 'median')\ncat_trans = Pipeline(steps = [\n    ('imputer',SimpleImputer(strategy = 'most_frequent')),\n    ('onehot',OneHotEncoder())\n])\npreprocessor = ColumnTransformer(\n    transformers = [\n        ('num',num_trans,numerical_col),\n        ('cat',cat_trans,categorical_col)\n])\ntitanic_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', RandomForestClassifier(random_state=0,\n                                                               max_depth = 5,\n                                                               #min_samples_leaf = 5,\n                                                               #min_samples_split = 12,\n                                                               n_estimators = 500\n                                                               ))\n                                  ])\ntitanic_pipeline.fit(X,y)\nprint('Cross validation score: {:.3f}'.format(cross_val_score(titanic_pipeline, X, y, cv=10).mean()))","e57fbfc1":"X_test = test_df[features]\nX_test.head()","6554aa14":"predictions = titanic_pipeline.predict(X_test)\noutput = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission2.csv', index=False)\nprint(\"Your submission was successfully saved!\")","589ca0cb":"Data exploration No manipulation must be done here","03a69375":"Above this declare all the libraries","745ceaca":"Data manipulation","053deafd":"Any features if generated must be done above this point in the notebook"}}