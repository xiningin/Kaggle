{"cell_type":{"b47c6487":"code","54e0f4ad":"code","108b49ae":"code","cf0d74d0":"code","95c9f07c":"code","87c76e9a":"code","cefa3dfe":"code","c40b502f":"code","95c17c05":"code","df68a7bb":"code","f35bf058":"code","21b4c089":"code","872324e8":"code","24031ee4":"code","0e01c648":"code","023e9132":"code","34af3947":"markdown","b909f1f9":"markdown","ed5a7ee2":"markdown"},"source":{"b47c6487":"import os\n\n\nimport copy\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, Flatten, Input\nfrom keras.layers import Conv2D, Activation, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.applications.resnet50 import preprocess_input, ResNet50\nimport matplotlib\nimport matplotlib.pylab as plt\nimport numpy as np\nimport seaborn as sns\nimport shap\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split","54e0f4ad":"W = 224 # The default size for ResNet is 224 but resize to .5 to save memory size\nH = 224 # The default size for ResNet is 224 but resize to .5 to save memory size\nlabel_to_class = {\n    'covid': 0,\n    'normal':    1,\n    'pneumonia':   2\n}\nclass_to_label = {v: k for k, v in label_to_class.items()}\nn_classes = len(label_to_class)\n\ndef get_images(dir_name='..\/input\/preprocessed-ekdom-latest\/preprocessed', label_to_class=label_to_class):\n    \"\"\"read images \/ labels from directory\"\"\"\n    \n    Images = []\n    Classes = []\n    \n    for label_name in os.listdir(dir_name):\n        cls = label_to_class[label_name]\n        \n        for img_name in os.listdir('\/'.join([dir_name, label_name])):\n            img = load_img('\/'.join([dir_name, label_name, img_name]), target_size=(W, H))\n            img = img_to_array(img)\n            \n            Images.append(img)\n            Classes.append(cls)\n            \n    Images = np.array(Images, dtype=np.float32)\n    Classes = np.array(Classes, dtype=np.float32)\n    Images, Classes = shuffle(Images, Classes, random_state=0)\n    \n    return Images, Classes","108b49ae":"## get images \/ labels\n\nImages, Classes = get_images()\n\nImages.shape, Classes.shape","cf0d74d0":"## visualize some images \/ labels\n\nn_total_images = Images.shape[0]\n\nfor target_cls in [0, 1, 2]:\n    \n    indices = np.where(Classes == target_cls)[0] # get target class indices on Images \/ Classes\n    n_target_cls = indices.shape[0]\n    label = class_to_label[target_cls]\n    print(label, n_target_cls, n_target_cls\/n_total_images)\n\n    n_cols = 10 # # of sample plot\n    fig, axs = plt.subplots(ncols=n_cols, figsize=(25, 3))\n\n    for i in range(n_cols):\n\n        axs[i].imshow(np.uint8(Images[indices[i]]))\n        axs[i].axis('off')\n        axs[i].set_title(label)\n\n    plt.show()","95c9f07c":"## split train \/ test\n\nindices_train, indices_test = train_test_split(list(range(Images.shape[0])), train_size=0.8, test_size=0.2, shuffle=False)\n\nx_train = Images[indices_train]\ny_train = Classes[indices_train]\nx_test = Images[indices_test]\ny_test = Classes[indices_test]\n\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","87c76e9a":"## to one-hot\n\ny_train = keras.utils.to_categorical(y_train, n_classes)\ny_test = keras.utils.to_categorical(y_test, n_classes)\n\ny_train.shape, y_test.shape","cefa3dfe":"## to image data generator\n\ndatagen_train = ImageDataGenerator(\n    preprocessing_function=preprocess_input, # image preprocessing function\n    rotation_range=30,                       # randomly rotate images in the range\n    zoom_range=0.1,                          # Randomly zoom image\n    width_shift_range=0.1,                   # randomly shift images horizontally\n    height_shift_range=0.1,                  # randomly shift images vertically\n    horizontal_flip=True,                    # randomly flip images horizontally\n    vertical_flip=False,                     # randomly flip images vertically\n)\ndatagen_test = ImageDataGenerator(\n    preprocessing_function=preprocess_input, # image preprocessing function\n)","c40b502f":"import keras\nimport tensorflow as tf\nfrom keras.applications.mobilenet_v2 import MobileNetV2\n\ndef build_model():\n    \"\"\"build model function\"\"\"\n    \n    # Resnet\n    input_tensor = Input(shape=(W, H, 3)) # To change input shape\n    densenet_121 = MobileNetV2(\n        include_top=False,                # To change output shape\n        weights='imagenet',               # Use pre-trained model\n        input_tensor=input_tensor,        # Change input shape for this task\n    )\n    \n    # fc layer\n    top_model = Sequential()\n    top_model.add(GlobalAveragePooling2D())               # Add GAP for cam\n    top_model.add(Dense(n_classes, activation='softmax')) # Change output shape for this task\n    \n    # model\n    model = Model(input=densenet_121.input, output=top_model(densenet_121.output))\n    \n    # frozen weights\n    for layer in model.layers[:-11]:\n        layer.trainable = False or isinstance(layer, BatchNormalization) # If Batch Normalization layer, it should be trainable\n        \n    # compile\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","95c17c05":"model = build_model()","df68a7bb":"model.summary()","f35bf058":"## finetuning\n\nbatch_size = 32\n\nhistory = model.fit_generator(\n    datagen_train.flow(x_train, y_train, batch_size=32),\n    epochs= 50,\n    validation_data=datagen_test.flow(x_test, y_test, batch_size=32),\n    verbose = 1,\n    #callbacks=callbacks,\n    steps_per_epoch=  int(len(x_train)\/\/batch_size),\n    validation_steps= int(len(x_test)\/\/ batch_size)\n)","21b4c089":"## plot confusion matrix\n\nx = preprocess_input(copy.deepcopy(x_test))\ny_preds = model.predict(x)\ny_preds = np.argmax(y_preds, axis=1)\ny_trues = np.argmax(y_test, axis=1)\ncm = confusion_matrix(y_trues, y_preds)\n\nfig, ax = plt.subplots(figsize=(7, 6))\n\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'shrink': .3}, linewidths=.1, ax=ax)\n\nax.set(\n    xticklabels=list(label_to_class.keys()),\n    yticklabels=list(label_to_class.keys()),\n    title='confusion matrix',\n    ylabel='True label',\n    xlabel='Predicted label'\n)\nparams = dict(rotation=45, ha='center', rotation_mode='anchor')\nplt.setp(ax.get_yticklabels(), **params)\nplt.setp(ax.get_xticklabels(), **params)\nplt.show()","872324e8":"def superimpose(img, cam):\n    \"\"\"superimpose original image and cam heatmap\"\"\"\n    \n    heatmap = cv2.resize(cam, (img.shape[1], img.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n    superimposed_img = heatmap * .45 + img * 1.2\n    superimposed_img = np.minimum(superimposed_img, 255.0).astype(np.uint8)  # scale 0 to 255  \n    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n    \n    return img, heatmap, superimposed_img","24031ee4":"def _plot(model, cam_func, img, cls_true):\n    \"\"\"plot original image, heatmap from cam and superimpose image\"\"\"\n    \n    # for cam\n    x = np.expand_dims(img, axis=0)\n    x = preprocess_input(copy.deepcopy(x))\n\n    # for superimpose\n    img = np.uint8(img)\n\n    # cam \/ superimpose\n    cls_pred, cam = cam_func(model=model, x=x, layer_name=model.layers[-2].name)\n    img, heatmap, superimposed_img = superimpose(img, cam)\n\n    fig, axs = plt.subplots(ncols=2, figsize=(8, 6))\n\n    axs[0].imshow(img)\n    #axs[0].set_title('True label: ' + class_to_label[cls_true] + ' \/ Predicted label : ' + class_to_label[cls_pred])\n    axs[0].axis('off')\n\n    #axs[1].imshow(heatmap)\n    #axs[1].set_title('heatmap')\n    #axs[1].axis('off')\n\n    axs[1].imshow(superimposed_img)\n    #axs[1].set_title(class_to_label[cls_true])\n    axs[1].axis('off')\n\n    plt.suptitle('True label: ' + class_to_label[cls_true] + ' \/ Predicted label : ' + class_to_label[cls_pred])\n    plt.tight_layout()\n    plt.show()\n    #fig.savefig(\"colon_aca_prewitt.jpeg\",bbox_inches='tight', pad_inches=0)\n    \n    ","0e01c648":"## Grad-CAM function\n\ndef grad_cam(model, x, layer_name):\n    \"\"\"Grad-CAM function\"\"\"\n    \n    cls = np.argmax(model.predict(x))\n    \n    y_c = model.output[0, cls]\n    conv_output = model.get_layer(layer_name).output\n    grads = K.gradients(y_c, conv_output)[0]\n\n    # Get outputs and grads\n    gradient_function = K.function([model.input], [conv_output, grads])\n    output, grads_val = gradient_function([x])\n    output, grads_val = output[0, :], grads_val[0, :, :, :]\n    \n    weights = np.mean(grads_val, axis=(0, 1)) # Passing through GlobalAveragePooling\n\n    cam = np.dot(output, weights) # multiply\n    cam = np.maximum(cam, 0)      # Passing through ReLU\n    cam \/= np.max(cam)            # scale 0 to 1.0\n\n    return cls, cam","023e9132":"for i in range(200):\n\n    _plot(model=model, cam_func=grad_cam, img=Images[i], cls_true=Classes[i])\n","34af3947":"def build_model():\n    \"\"\"build model function\"\"\"\n    \n    # Resnet\n    input_tensor = Input(shape=(W, H, 3)) # To change input shape\n    resnet50 = ResNet50(\n        include_top=False,                # To change output shape\n        weights='imagenet',               # Use pre-trained model\n        input_tensor=input_tensor,        # Change input shape for this task\n    )\n    \n    # fc layer\n    top_model = Sequential()\n    top_model.add(GlobalAveragePooling2D())               # Add GAP for cam\n    top_model.add(Dense(n_classes, activation='softmax')) # Change output shape for this task\n    \n    # model\n    model = Model(input=resnet50.input, output=top_model(resnet50.output))\n    \n    # frozen weights\n    for layer in model.layers[:-10]:\n        layer.trainable = False or isinstance(layer, BatchNormalization) # If Batch Normalization layer, it should be trainable\n        \n    # compile\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","b909f1f9":"import keras\nimport tensorflow as tf\nfrom keras.applications.mobilenet_v2 import MobileNetV2\n\ndef build_model():\n    \"\"\"build model function\"\"\"\n    \n    # Resnet\n    input_tensor = Input(shape=(W, H, 3)) # To change input shape\n    mobilenet_v2 = MobileNetV2(\n        include_top=False,                # To change output shape\n        weights='imagenet',               # Use pre-trained model\n        input_tensor=input_tensor,        # Change input shape for this task\n    )\n    \n    # fc layer\n    top_model = Sequential()\n    top_model.add(GlobalAveragePooling2D())               # Add GAP for cam\n    top_model.add(Dense(n_classes, activation='softmax')) # Change output shape for this task\n    \n    # model\n    model = Model(input=mobilenet_v2.input, output=top_model(mobilenet_v2.output))\n    \n    # frozen weights\n    for layer in model.layers[:-11]:\n        layer.trainable = False or isinstance(layer, BatchNormalization) # If Batch Normalization layer, it should be trainable\n        \n    # compile\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","ed5a7ee2":"{\nW = 224 # The default size for ResNet is 224 but resize to .5 to save memory size\nH = 224 # The default size for ResNet is 224 but resize to .5 to save memory size\nlabel_to_class = {\n    'colon_aca': 0,\n    'colon_n':    1,\n    'lung_aca':   2,\n    'lung_n':  3,\n    'lung_scc': 4\n}\nclass_to_label = {v: k for k, v in label_to_class.items()}\nn_classes = len(label_to_class)\n\ndef get_images(dir_name='..\/input\/lung-colon-sobel\/trainable_sobel', label_to_class=label_to_class):\n    \"\"\"read images \/ labels from directory\"\"\"\n    \n    Images = []\n    Classes = []\n    \n    for label_name in os.listdir(dir_name):\n        cls = label_to_class[label_name]\n        \n        for img_name in os.listdir('\/'.join([dir_name, label_name])):\n            img = load_img('\/'.join([dir_name, label_name, img_name]), target_size=(W, H))\n            img = img_to_array(img)\n            \n            Images.append(img)\n            Classes.append(cls)\n            \n    Images = np.array(Images, dtype=np.float32)\n    Classes = np.array(Classes, dtype=np.float32)\n    Images, Classes = shuffle(Images, Classes, random_state=0)\n    \n    return Images, Classes }"}}