{"cell_type":{"c2728032":"code","ea233aa6":"code","783ee87c":"code","232871a0":"code","0d10e851":"code","791c529b":"code","25166502":"code","5e340a21":"code","84fb8f77":"markdown","b1f6e6c2":"markdown","22647219":"markdown","e53349b4":"markdown","6e4846dd":"markdown","0692bfdf":"markdown","dd0b24ce":"markdown"},"source":{"c2728032":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt \nimport h5py","ea233aa6":"training_data_dir = '..\/input\/skin-cancer-malignant-vs-benign\/train'\ntesting_data_dir = '..\/input\/skin-cancer-malignant-vs-benign\/test'\ntraining_data_generator = IDG(\n                              rescale = 1.\/255,   #normalize the image pixels values to be between 0 & 1\n                              rotation_range = 40,\n                              width_shift_range = 0.2,\n                              height_shift_range = 0.2,\n                              shear_range = 0.2,\n                              zoom_range = 0.2,\n                              horizontal_flip = True,\n                              fill_mode = 'nearest'\n                             )\ntesting_data_generator = IDG(rescale = 1.\/255)\ntraining_data = training_data_generator.flow_from_directory(\n                                                            training_data_dir,\n                                                            target_size = (150, 150),\n                                                            batch_size = 32,\n                                                            class_mode = 'binary'\n                                                            )\ntesting_data = testing_data_generator.flow_from_directory(\n                                                            testing_data_dir,\n                                                            target_size = (150, 150),\n                                                            batch_size = 32,\n                                                            class_mode = 'binary'\n                                                            )\ntraining_data.class_indices","783ee87c":"model = tf.keras.Sequential([\n                            Conv2D(64, (3, 3), input_shape = (150, 150, 3)),\n                            BatchNormalization(),\n                            MaxPool2D(2),\n                            Conv2D(64, (3, 3)),\n                            BatchNormalization(),\n                            MaxPool2D(2),\n                            Conv2D(128, (3, 3)),\n                            BatchNormalization(),\n                            MaxPool2D(2),\n                            Conv2D(128, (3, 3), input_shape = (150, 150, 3)),\n                            BatchNormalization(),\n                            MaxPool2D(2),\n                            Flatten(),\n                            Dense(256, activation = 'relu'),\n                            Dropout(rate = 0.2),\n                            Dense(128, activation = 'relu'),\n                            Dense(1, activation = 'sigmoid')\n])\n\n\nmodel.compile(optimizer = Adam(learning_rate=0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n\nmodel.summary()     # To summarize the model","232871a0":"saved_weights = 'best_weights.hdf5'\n\ncheckpoint = ModelCheckpoint(filepath = saved_weights, monitor = 'val_accuracy', save_best_only = True, save_weights_only = True)\n\ncallback = [checkpoint]","0d10e851":"history = model.fit(training_data, epochs = 300 , validation_data = testing_data, callbacks = callback)","791c529b":"#model.load_weights(saved_weights)","25166502":"#history = model.fit(training_data, epochs = 10, validation_data = testing_data, callbacks = callback)","5e340a21":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","84fb8f77":"First of all we will import all the packages we will need.","b1f6e6c2":"Now we are done. Before testing the model in a new image, Let's see how both the Accuracy (training, testing) and the loss (training, test) changed during training.","22647219":"**In this notebook, we are trying to classify the skin cancer into Malignant and Benign. We will use teo approaches. First we will use a simple Convolutional Neural Netowk and secondly we will use transfer learning in another notebook. This is mainly to compare the performance between the two models and see how transfer learning can increase the accuray specially when we do not have the needed amount of data.**","e53349b4":"Now, we are ready to train our model.","6e4846dd":"Now, before we go through training our model, we will define a class called \"myCallback\". The purpose of creating that class will be to save the weights of the best model. The best model is the model with the highest Validation accuracy.","0692bfdf":"Next, we will define our model. As mentioned in the introduction, this notebook is one of two notebooks solving this problem with two approaches. In this notebook we will use a simple model that is as follows:\n- Conv2D >> BatchNormalization >> MaxPooling >> Conv2D >> BatchNormalization >> MaxPooling >> Conv2D >> BatchNormalization >> MaxPooling >> Flatten >> Dense >> Dropout >> Dense (output layer).","dd0b24ce":"- Secondly, we will prepare the data. For this we will use the keras API named \"ImageDataGenerator\" that we imorted as \"IDG\".\n- The data we will used is saved in the directory \"..\/input\/skin-cancer-malignant-vs-benign\". It is splitted into two directories, training and test.\n- The ImageDataGenerator API will use the directories names to get the labels of the data.\n- We will use data augmentation as a technique to increase the size of the data set and to avoid the model with cases that may not be covered in the available short dataset.\n- The ImageDataGenerator will care for the data augmentation augmentation along with the data loading."}}