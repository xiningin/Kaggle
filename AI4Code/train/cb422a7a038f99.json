{"cell_type":{"471c602d":"code","2d498ca4":"code","ee51bd8e":"code","fe6482f9":"code","bd46f254":"code","b0f42ccf":"code","900b7e12":"code","93d28e95":"code","cc8edec4":"code","438e4071":"code","5a7f341a":"markdown","1f27c54e":"markdown","cb372f05":"markdown","0475d521":"markdown","79f128c8":"markdown","21b860d5":"markdown","e74a9de6":"markdown"},"source":{"471c602d":"%%time\nimport sys\n!cp ..\/input\/rapids\/rapids.0.12.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzf rapids.tar.gz\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\"] + [\"\/opt\/conda\/envs\/rapids\/lib\/python3.6\/site-packages\"] + sys.path\n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","2d498ca4":"import cuml\nfrom cuml.manifold import TSNE, UMAP\nimport plotly.express as px\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub","ee51bd8e":"train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")","fe6482f9":"%%time\nmodule_url = '\/kaggle\/input\/universalsentenceencoderlarge4\/'\nembed = hub.KerasLayer(module_url, trainable=True, name='USE_embedding')","bd46f254":"%%time\nencodings = embed(train.text)['outputs'].numpy()","b0f42ccf":"%%time\ntsne2d = TSNE(n_components=2)\nprojections_2d = tsne2d.fit_transform(encodings)","900b7e12":"%%time\numap3d = UMAP(n_components=3)\nprojections_3d = umap3d.fit_transform(encodings)","93d28e95":"labels = train.target.apply(lambda x: 'Real Disaster' if x else 'Not Disaster')","cc8edec4":"fig = px.scatter(\n    x=projections_2d[:, 0], y=projections_2d[:, 1], \n    color=labels, hover_name=train.text, height=700\n)\nfig.show()","438e4071":"fig = px.scatter_3d(\n    x=projections_3d[:, 0], y=projections_3d[:, 1], z=projections_3d[:, 2], \n    color=labels, hover_name=train.text, size_max=2, height=700\n)\nfig.update_traces(marker=dict(size=3))\n\nfig.show()","5a7f341a":"# Step 4 - Visualize with Plotly","1f27c54e":"## 3D Visualization with UMAP","cb372f05":"# About this kernel\n\nIn this kernel, I show you:\n\n* How to embed each tweet into a high-dimensional vector (512d) using *Universal Sentence Encoder (USE)*. This is done in **Tensorflow Hub**.\n* How to project each of those tweets from high-dimension to low-dimension (2d and 3d), using techniques like *t-SNE* and *UMAP*. This will be done using **RAPIDS.ai**, a framework that let you run all kinds of ML algorithms (not DL specific) directly on GPU.\n* Visualize t-SNE and UMAP interactively using 2D and 3D *scatter plots* with **Plotly**. You can hover over each dot to see the content!","0475d521":"# Step 2 - Embed sentences into vector with USE in TFHub\n\nUniversal Sentence Encoder (USE) is a practical.","79f128c8":"## 2D visualization with t-SNE","21b860d5":"# Step 3 - Run t-SNE with RAPIDS.ai","e74a9de6":"# Step 1: Install RAPIDS.ai\nFirst install RAPIDS offline (directly taken from [this kernel](https:\/\/www.kaggle.com\/tunguz\/cats-ii-t-sne-and-umap-embeddings-with-rapids\/data)):"}}