{"cell_type":{"91a5d96b":"code","a76e6490":"code","fcdd79ab":"code","491d5741":"code","1bb1e0c9":"code","d36a8566":"code","037c8d21":"code","6deeaeac":"code","8ca20be0":"code","a9df51b6":"code","0ed63b89":"code","1ff7153f":"code","4717fb5c":"code","3640636c":"code","22b86992":"code","80b64ed7":"code","1ad3d013":"code","37a25290":"code","2e80a1cc":"code","594fb983":"code","de2fac9d":"code","f5c9555e":"code","a4784bd5":"code","7477756b":"code","4cf64ad4":"code","fe2ef547":"code","62ea973e":"code","c83ede2b":"code","eb8f3647":"code","6d11ddbc":"code","5b91aaed":"code","948221ee":"code","3d9f1729":"code","2c21f925":"code","e0a50504":"code","4595da6a":"code","1ce6af46":"code","82496083":"code","500b7e41":"code","1bc98103":"code","566e1313":"markdown","4f7eeeb3":"markdown","78e59a8f":"markdown","eff05afe":"markdown","df6b4904":"markdown","0741c41a":"markdown","9f162873":"markdown","10993fc0":"markdown","22a1979a":"markdown","40a90e50":"markdown","5f295e6c":"markdown","416bc1b6":"markdown","3bbf9cde":"markdown","9e42405c":"markdown","39bbaef1":"markdown","98880d68":"markdown","c50264c9":"markdown","e718aca6":"markdown","c0e9a134":"markdown","e209d5b7":"markdown","7f7547c2":"markdown","826348ac":"markdown","dfca6b06":"markdown","9fb56c5b":"markdown","60ae4971":"markdown","deab8c2d":"markdown","c88051d9":"markdown","9689f85a":"markdown","6b296a8e":"markdown","0accbcf4":"markdown","cf85f450":"markdown","2f6e9915":"markdown","e11765f1":"markdown","fcb0a42f":"markdown","0b6b3e84":"markdown","09399c3e":"markdown","f1103c03":"markdown","21139165":"markdown","ec6707c2":"markdown","6ab053b8":"markdown","3cb4b73b":"markdown","8b5ea075":"markdown","2beaaa1a":"markdown","0fa7379b":"markdown","e711d9af":"markdown"},"source":{"91a5d96b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns # plotting graphs for visualizations\nimport matplotlib.pyplot as plt # plotting graphs for visualizations\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, auc, roc_curve\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport graphviz\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a76e6490":"df = pd.read_csv(\"\/kaggle\/input\/mushroom-classification\/mushrooms.csv\")","fcdd79ab":"df.head()","491d5741":"df.info()","1bb1e0c9":"df.describe()","d36a8566":"print(\"Dataset shape:\",df.shape)","037c8d21":"df[\"class\"].unique()","6deeaeac":"count = df.iloc[:,0].value_counts()\nplt.figure(figsize=(8,7))\nsns.barplot(count.index, count.values, alpha=0.8, palette=\"prism\")\nplt.ylabel('Count', fontsize=12)\nplt.xlabel('Class', fontsize=12)\nplt.title('Number of poisonous\/edible mushrooms')\nplt.show()","8ca20be0":"labelencoder=LabelEncoder()\nfor column in df.columns:\n    df[column] = labelencoder.fit_transform(df[column])","a9df51b6":"df.head()","0ed63b89":"df=df.drop([\"veil-type\"],axis=1)","1ff7153f":"df_div = pd.melt(df, \"class\", var_name=\"Characteristics\")\nfig, ax = plt.subplots(figsize=(16,6))\np = sns.violinplot(ax = ax, x=\"Characteristics\", y=\"value\", hue=\"class\", split = True, data=df_div, inner = 'quartile', palette = 'Set1')\ndf_no_class = df.drop([\"class\"],axis = 1)\np.set_xticklabels(rotation = 90, labels = list(df_no_class.columns));","4717fb5c":"plt.figure(figsize=(14,12))\nsns.heatmap(df.corr(),linewidths=.1,cmap=\"Purples\", annot=True)\nplt.yticks(rotation=0);","3640636c":"df[['class', 'gill-color']].groupby(['gill-color'], as_index=False).mean().sort_values(by='class', ascending=False)","22b86992":"new_var = df[['class', 'gill-color']]\nnew_var = new_var[new_var['gill-color']<=3.5]\nsns.factorplot('class', col='gill-color', data=new_var, kind='count', size=4.5, aspect=.8, col_wrap=4);","80b64ed7":"new_var=df[['class', 'gill-color']]\nnew_var=new_var[new_var['gill-color']>3.5]\n\nsns.factorplot('class', col='gill-color', data=new_var, kind='count', size=4.5, aspect=.8, col_wrap=4);","1ad3d013":"X = df.drop(['class'], axis=1)  \ny = df[\"class\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)   ","37a25290":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)","2e80a1cc":"os.environ[\"PATH\"] += os.pathsep + 'C:\/Program Files (x86)\/Graphviz2.38\/bin\/'\n\ndot_data = export_graphviz(dt, out_file=None, \n                         feature_names=X.columns,  \n                         filled=True, rounded=True,  \n                         special_characters=True)  \ngraph = graphviz.Source(dot_data)  \ngraph ","594fb983":"features_list = X.columns.values\nfeature_importance = dt.feature_importances_\nsorted_idx = np.argsort(feature_importance)\n\nplt.figure(figsize=(8,7))\nplt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center', color =\"red\")\nplt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\nplt.xlabel('Importance')\nplt.title('Feature importances')\nplt.draw()\nplt.show()","de2fac9d":"y_pred_dt = dt.predict(X_test)","f5c9555e":"print(\"Decision Tree Classifier report: \\n\\n\", classification_report(y_test, y_pred_dt))","a4784bd5":"print(\"Test Accuracy: {}%\".format(round(dt.score(X_test, y_test)*100, 2)))","7477756b":"cm = confusion_matrix(y_test, y_pred_dt)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for Decision Tree Classifier')\nplt.show()","4cf64ad4":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(solver=\"lbfgs\", max_iter=500)\nlr.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {}%\".format(round(lr.score(X_test, y_test)*100,2)))","fe2ef547":"y_pred_lr = lr.predict(X_test)\nprint(\"Logistic Regression Classifier report: \\n\\n\", classification_report(y_test, y_pred_lr))","62ea973e":"cm = confusion_matrix(y_test, y_pred_lr)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for Logistic Regression Classifier')\nplt.show()","c83ede2b":"from sklearn.neighbors import KNeighborsClassifier\n\nbest_Kvalue = 0\nbest_score = 0\n\nfor i in range(1,10):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    if knn.score(X_test, y_test) > best_score:\n        best_score = knn.score(X_train, y_train)\n        best_Kvalue = i\n        \nprint(\"Best KNN Value: {}\".format(best_Kvalue))\nprint(\"Test Accuracy: {}%\".format(round(best_score*100,2)))","eb8f3647":"y_pred_knn = knn.predict(X_test)\nprint(\"KNN Classifier report: \\n\\n\", classification_report(y_test, y_pred_knn))","6d11ddbc":"cm = confusion_matrix(y_test, y_pred_knn)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for KNN Classifier')\nplt.show()","5b91aaed":"from sklearn.svm import SVC\n\nsvm = SVC(random_state=42, gamma=\"auto\")\nsvm.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {}%\".format(round(svm.score(X_test, y_test)*100, 2)))","948221ee":"y_pred_svm = svm.predict(X_test)\nprint(\"SVM Classifier report: \\n\\n\", classification_report(y_test, y_pred_svm))","3d9f1729":"cm = confusion_matrix(y_test, y_pred_svm)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for SVM Classifier')\nplt.show()","2c21f925":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {}%\".format(round(nb.score(X_test, y_test)*100, 2)))","e0a50504":"y_pred_nb = nb.predict(X_test)\nprint(\"Naive Bayes Classifier report: \\n\\n\", classification_report(y_test, y_pred_nb))","4595da6a":"cm = confusion_matrix(y_test, y_pred_nb)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for Naive Bayes Classifier')\nplt.show()","1ce6af46":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\n\nprint(\"Test Accuracy: {}%\".format(round(rf.score(X_test, y_test)*100, 2)))","82496083":"y_pred_rf = rf.predict(X_test)\nprint(\"Random Forest Classifier report: \\n\\n\", classification_report(y_test, y_pred_rf))","500b7e41":"cm = confusion_matrix(y_test, y_pred_rf)\n\nx_axis_labels = [\"Edible\", \"Poisonous\"]\ny_axis_labels = [\"Edible\", \"Poisonous\"]\n\nf, ax = plt.subplots(figsize =(7,7))\nsns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Purples\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\nplt.xlabel(\"PREDICTED LABEL\")\nplt.ylabel(\"TRUE LABEL\")\nplt.title('Confusion Matrix for Random Forest Classifier');\nplt.show()","1bc98103":"preds = dt.predict(X_test)\n\nprint(preds[:36])\nprint(y_test[:36].values)\n\n# 0 - Edible\n# 1 - Poisonous","566e1313":"# Examining the Data","4f7eeeb3":"### From the confusion matrix, we saw that our train and test data is balanced.\n### Most of classfication methods hit 100% accuracy with this dataset.","78e59a8f":"## 2. Logistic Regression Classification","eff05afe":"#### Classification report of SVM Classifier","df6b4904":"## 2. KNN Classification","0741c41a":"#### Usually, the least correlating variable is the most important one for classification. In this case, \"gill-color\" has -0.53 so let's look at it closely.","9f162873":"### Reading the csv file of the dataset","10993fc0":"#### Classification report of Random Forest Classifier","22a1979a":"#### The column \"veil-type\" is 0 and not contributing to the data so we remove it.","40a90e50":"### Visualizing the count of edible and poisonous mushrooms","5f295e6c":"### Confusion Matrix for Naive Bayes Classifier","416bc1b6":"#### Classification report of Naive Bayes Classifier","3bbf9cde":"### Confusion Matrix for KNN Classifier","9e42405c":"#### Classification report of Logistic Regression Classifier","39bbaef1":"#### Setting X and y axis and splitting the data into train and test respectively.","98880d68":"# Predictions","c50264c9":"## Feature importances","e718aca6":"#### The data is categorial so we'll convert it with LabelEncoder to transfer to ordinal.","c0e9a134":"#### The dataset is balanced.","e209d5b7":"#### Lets look closely at the feature \"gill-color\".","7f7547c2":"#### By all methods examined before the feature that is most important is \"gill-color\".","826348ac":"### Confusion Matrix for Logistic Regression Classifier","dfca6b06":"### Quick look at the characteristics of the data","9fb56c5b":"# Preparing the Data","60ae4971":"### Predicting some of the X_test results and matching it with true i.e. y_test values using Decision Tree Classifier.","deab8c2d":"### Importing the packages","c88051d9":"#### Classification report of KNN Classifier","9689f85a":"### Confusion Matrix for SVM Classifier","6b296a8e":"## 3. SVM Classification","0accbcf4":"#### In this project, we will examine the data and create a machine learning algorithm that will detect if the mushroom is edible or poisonous by its specifications like cap shape, cap color, gill color, etc. using different classifiers.\n#### The dataset used in this project is \"mushrooms.csv\" which contains 8124 instances of mushrooms with 22 features like cap-shape, cap-surface, cap-color, bruises, odor, etc.","cf85f450":"## 1. Decision Tree Classification","2f6e9915":"## 4. Naive Bayes Classification","e11765f1":"# Data Manipulation","fcb0a42f":"# Conclusion","0b6b3e84":"### Confusion Matrix for Decision Tree Classifier","09399c3e":"### Let's look at the correlation between the variables","f1103c03":"### Confusion Matrix for Random Forest Classifier","21139165":"#### The violin plot below represents the distribution of the classification characteristics. It is possible to see that \"gill-color\" property of the mushroom breaks to two parts, one below 3 and one above 3, that may contribute to the classification.","ec6707c2":"### Predicting and estimating the result","6ab053b8":"### As we can see the predicted and the true values match 100%.","3cb4b73b":"### Shape of the dataset","8b5ea075":"## 6. Random Forest Classification","2beaaa1a":"# Classification Methods","0fa7379b":"#### After importing the data, to learn more about the dataset, we'll use .head() .info() and .describe() methods.","e711d9af":"# Mushroom Classification Using Different Classifiers"}}