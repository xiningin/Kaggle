{"cell_type":{"88e6135c":"code","c7d3c575":"code","420d57f5":"code","784d1287":"code","19bf4dba":"code","6d248843":"code","831a371c":"code","f98132b7":"code","3d1b0a80":"code","085dbb06":"code","4c5d1ec7":"code","5f429bc2":"code","86fddf7f":"code","7b7df6ab":"code","02329e79":"code","bdb27f83":"code","cd751260":"code","56c10c92":"code","cd7daef9":"code","95b00901":"code","a87950bf":"code","55c8dc8a":"code","3f009e35":"code","24ec6386":"code","89d73734":"code","c1f5ce54":"code","1a66b2af":"code","7810a16f":"code","86242884":"code","e19c7df9":"code","0c3688ff":"code","fb63bc36":"code","03eb7ea0":"code","e4845992":"code","e2501011":"code","988e63e2":"code","79d29bbb":"code","d4462c87":"code","902f9f44":"code","466c1431":"code","eb4a4806":"code","f28b603f":"code","78946ba3":"markdown"},"source":{"88e6135c":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nfrom sklearn import metrics\nfrom scipy import stats","c7d3c575":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","420d57f5":"#importing the dataset without outliers to fit multiple linear Regression\ndataset = pd.read_csv('..\/input\/house-prices\/House_price.csv')","784d1287":"dataset.head()","19bf4dba":"dataset = dataset.drop(labels = 'Address', axis = 1)","6d248843":"z = np.abs(stats.zscore(dataset))\ndataset = dataset[(z < 3).all(axis=1)]\ndataset.head()","831a371c":"X = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","f98132b7":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","3d1b0a80":"# trying to fit multiple linear regression onto the given dataset\nfrom sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)","085dbb06":"y_pred = regressor.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), axis = 1))","4c5d1ec7":"print(regressor.coef_)\nprint(regressor.intercept_)","5f429bc2":"print(\"R-Square Value\",r2_score(y_test,y_pred))\nprint (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\nprint (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\nprint (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","86fddf7f":"print(\"Train Accuracy:\",regressor.score(X_train, y_train))","7b7df6ab":"y_pred = y_pred.reshape(len(y_pred),1)\ny_test = y_test.reshape(len(y_test),1)\nresidual = y_test - y_pred\n# to check distribution of residual values\nplt.hist(residual, bins = 50)\nplt.title('Frequency distribution of Residual Values')\nplt.xlabel('Residual Value')\nplt.ylabel('Frequency')\nplt.show()","02329e79":"# to check Homoscedasticity assumption of linear regression\nplt.scatter(y_pred, residual)\nplt.title('Predicted value vs Residual Value')\nplt.ylabel('Predicted Value')\nplt.xlabel('Residual Value')\nplt.show()","bdb27f83":"#from EDA we observed the the No of Bedrooms and the No of Rooms were has a correlation coefficient of 0.46\n#so we trying fitting multiple linear regression by dropping No of Bedrooms\ndataset1 = dataset.drop(labels = 'Number of Bedrooms', axis = 1)","cd751260":"dataset1.head()","56c10c92":"X = dataset1.iloc[:, :-1].values\ny = dataset1.iloc[:, -1].values","cd7daef9":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","95b00901":"regressor1 = LinearRegression()\nregressor1.fit(X_train, y_train)","a87950bf":"y_pred = regressor1.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), axis = 1))","55c8dc8a":"print(regressor1.coef_)\nprint(regressor1.intercept_)","3f009e35":"print(\"R-Square Value\",r2_score(y_test,y_pred))\nprint (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\nprint (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\nprint (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","24ec6386":"print(\"Train Accuracy:\",regressor1.score(X_train, y_train))","89d73734":"y_pred = y_pred.reshape(len(y_pred),1)\ny_test = y_test.reshape(len(y_test),1)\nresidual = y_test - y_pred\n# to check distribution of residual values\nplt.hist(residual, bins = 50)\nplt.title('Frequency distribution of Residual Values')\nplt.xlabel('Residual Value')\nplt.ylabel('Frequency')\nplt.show()","c1f5ce54":"# to check Homoscedasticity assumption of linear regression\nplt.scatter(y_pred, residual)\nplt.title('Predicted value vs Residual Value')\nplt.ylabel('Predicted Value')\nplt.xlabel('Residual Value')\nplt.show()","1a66b2af":"# Fitting the data with Regularisation Techniques\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, -1].values","7810a16f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","86242884":"from sklearn.linear_model import Ridge\nridgereg = Ridge(alpha=0.01, normalize=True)\nridgereg.fit(X_train, y_train)","e19c7df9":"y_pred = ridgereg.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), axis = 1))","0c3688ff":"print(\"Coeffients:\", ridgereg.coef_)\nprint(\"Intercept:\", ridgereg.intercept_)","fb63bc36":"print(\"R-Square Value : \",r2_score(y_test,y_pred))\nprint (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\nprint (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\nprint (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","03eb7ea0":"print(\"Train Accuracy:\",ridgereg.score(X_train, y_train))","e4845992":"y_pred = y_pred.reshape(len(y_pred),1)\ny_test = y_test.reshape(len(y_test),1)\nresidual = y_test - y_pred\n# to check distribution of residual values\nplt.hist(residual, bins = 50)\nplt.title('Frequency distribution of Residual Values')\nplt.xlabel('Residual Value')\nplt.ylabel('Frequency')\nplt.show()","e2501011":"# to check Homoscedasticity assumption of linear regression\nplt.scatter(y_pred, residual)\nplt.title('Predicted value vs Residual Value')\nplt.ylabel('Predicted Value')\nplt.xlabel('Residual Value')\nplt.show()","988e63e2":"from sklearn.linear_model import Lasso\nlassoreg = Lasso(alpha=0.1, normalize=True)\nlassoreg.fit(X_train, y_train)","79d29bbb":"y_pred = lassoreg.predict(X_test)\nnp.set_printoptions(precision = 2)\nprint(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), axis = 1))","d4462c87":"print(\"Coeffients:\", lassoreg.coef_)\nprint(\"Intercept:\", lassoreg.intercept_)","902f9f44":"print(\"R-Square Value : \",r2_score(y_test,y_pred))\nprint (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\nprint (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\nprint (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))","466c1431":"print(\"Train Accuracy:\",lassoreg.score(X_train, y_train))","eb4a4806":"y_pred = y_pred.reshape(len(y_pred),1)\ny_test = y_test.reshape(len(y_test),1)\nresidual = y_test - y_pred\n# to check distribution of residual values\nplt.hist(residual, bins = 50)\nplt.title('Frequency distribution of Residual Values')\nplt.xlabel('Residual Value')\nplt.ylabel('Frequency')\nplt.show()","f28b603f":"# to check Homoscedasticity assumption of linear regression\nplt.scatter(y_pred, residual)\nplt.title('Predicted value vs Residual Value')\nplt.ylabel('Predicted Value')\nplt.xlabel('Residual Value')\nplt.show()","78946ba3":"### House Prices Model Fitting\n I performed EDA on the same data set, for which the link is as follows:   \n https:\/\/www.kaggle.com\/tanyachawla412\/eda-of-house-prices   \n I then tried to fit regression models by tweaking the parameters and appling diffrent regularisation techniques."}}