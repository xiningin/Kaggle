{"cell_type":{"4aa3b6b0":"code","c6891d43":"code","5101a19a":"code","696d3b5e":"code","2b6baec7":"code","217b2059":"code","6b0eaa0e":"code","db73ce02":"code","f2cdff7f":"code","320cfc2e":"code","fad4ee94":"code","f7c8517d":"code","50d3b845":"code","8588e54f":"code","3fa31638":"code","7e668110":"code","7d1a4e38":"code","f5a56260":"code","43b23a7a":"code","aa1a8ddb":"code","af1095dc":"code","89e906c5":"code","2e8db03a":"code","49ed67d3":"code","d2d3b93f":"code","f2c69902":"code","33a2d8c6":"code","1730d72c":"markdown","45f259f1":"markdown","0a64b935":"markdown","3fda3fac":"markdown","d7f7f9ec":"markdown","dc40f601":"markdown","fcc8a5ec":"markdown","f5ec0f9f":"markdown","8dacb18f":"markdown","2a9e526b":"markdown","3892f9f4":"markdown","7e622c71":"markdown","61fa8532":"markdown","0fea9f7b":"markdown"},"source":{"4aa3b6b0":"!pip install --upgrade seaborn","c6891d43":"import numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns","5101a19a":"dim = 1024 #512, 256, 'original'\nfold = 1","696d3b5e":"train_df = pd.read_csv(f'..\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train.csv')\ntrain_df.head()","2b6baec7":"train_df['image_path'] = f'\/kaggle\/input\/vinbigdata-{dim}-image-dataset\/vinbigdata\/train\/'+train_df.image_id+('.png' if dim!='original' else '.jpg')\ntrain_df.head()","217b2059":"train_df = train_df[train_df.class_id!=14].reset_index(drop = True)","6b0eaa0e":"mapper = {0:'Aortic enlargement',\n         1:'Atelectasis',\n         2:'Calcification',\n         3:'Cardiomegaly',\n         4:'Consolidation',\n         5:'ILD',\n         6:'Infiltration',\n         7:'Lung Opacity',\n         8:'Nodule\/Mass',\n         9:'Other lesion',\n         10:'Pleural effusion',\n         11:'Pleural thickening',\n         12:'Pneumothorax',\n         13:'Pulmonary fibrosis'}","db73ce02":"train_df['x_min'] = train_df.apply(lambda row: (row.x_min)\/row.width, axis =1)\ntrain_df['y_min'] = train_df.apply(lambda row: (row.y_min)\/row.height, axis =1)\n\ntrain_df['x_max'] = train_df.apply(lambda row: (row.x_max)\/row.width, axis =1)\ntrain_df['y_max'] = train_df.apply(lambda row: (row.y_max)\/row.height, axis =1)\n\ntrain_df['x_mid'] = train_df.apply(lambda row: (row.x_max+row.x_min)\/2, axis =1)\ntrain_df['y_mid'] = train_df.apply(lambda row: (row.y_max+row.y_min)\/2, axis =1)\n\ntrain_df['w'] = train_df.apply(lambda row: (row.x_max-row.x_min), axis =1)\ntrain_df['h'] = train_df.apply(lambda row: (row.y_max-row.y_min), axis =1)\ntrain_df['class_name'] = train_df.apply(lambda row: mapper.get(row.class_id), axis =1)\n\ntrain_df['area'] = train_df['w']*train_df['h']\ntrain_df.head()","f2cdff7f":"features = ['x_min', 'y_min', 'x_max', 'y_max', 'x_mid', 'y_mid', 'w', 'h', 'area']\nX = train_df[features]\ny = train_df['class_id']\nX.shape, y.shape","320cfc2e":"class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","fad4ee94":"train_df['fold'] = 0\nIMG_IDS = np.load('..\/input\/modified-effnet-classification\/validation_image_list.npy',allow_pickle = True).tolist()\nfor i in IMG_IDS:\n    train_df.loc[train_df['image_id']==i, 'fold'] = 1\ntrain_df.head()","f7c8517d":"train_files = []\nval_files   = []\nval_files += list(train_df[train_df.fold==fold].image_path.unique())\ntrain_files += list(train_df[train_df.fold!=fold].image_path.unique())\nlen(train_files), len(val_files)","50d3b845":"os.makedirs('\/kaggle\/working\/vinbigdata\/labels\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/labels\/val', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/images\/train', exist_ok = True)\nos.makedirs('\/kaggle\/working\/vinbigdata\/images\/val', exist_ok = True)\nlabel_dir = '\/kaggle\/input\/vinbigdata-yolo-labels-dataset\/labels'\nfor file in tqdm(train_files):\n    shutil.copy(file, '\/kaggle\/working\/vinbigdata\/images\/train')\n    filename = file.split('\/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/vinbigdata\/labels\/train')\n    \nfor file in tqdm(val_files):\n    shutil.copy(file, '\/kaggle\/working\/vinbigdata\/images\/val')\n    filename = file.split('\/')[-1].split('.')[0]\n    shutil.copy(os.path.join(label_dir, filename+'.txt'), '\/kaggle\/working\/vinbigdata\/labels\/val')","8588e54f":"class_ids, class_names = list(zip(*set(zip(train_df.class_id, train_df.class_name))))\nclasses = list(np.array(class_names)[np.argsort(class_ids)])\nclasses = list(map(lambda x: str(x), classes))\nclasses","3fa31638":"from os import listdir\nfrom os.path import isfile, join\nimport yaml\n\ncwd = '\/kaggle\/working\/'\n\nwith open(join( cwd , 'train.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata\/images\/train\/*'):\n        f.write(path+'\\n')\n            \nwith open(join( cwd , 'val.txt'), 'w') as f:\n    for path in glob('\/kaggle\/working\/vinbigdata\/images\/val\/*'):\n        f.write(path+'\\n')\n\ndata = dict(\n    train =  join( cwd , 'train.txt') ,\n    val   =  join( cwd , 'val.txt' ),\n    nc    = 14,\n    names = classes\n    )\n\nwith open(join( cwd , 'vinbigdata.yaml'), 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\nf = open(join( cwd , 'vinbigdata.yaml'), 'r')\nprint('\\nyaml:')\nprint(f.read())","7e668110":"# https:\/\/www.kaggle.com\/ultralytics\/yolov5\n# !git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo\n# %cd yolov5\nshutil.copytree('..\/input\/yolov5-official-v31-dataset\/yolov5', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5')\n# %pip install -qr requirements.txt # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))","7d1a4e38":"!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data\/images\/\nImage(filename='runs\/detect\/exp\/zidane.jpg', width=600)","f5a56260":"# !WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --nosave --cache \n!WANDB_MODE=\"dryrun\" python train.py --img 640 --batch 16 --epochs 50 --data \/kaggle\/working\/vinbigdata.yaml --hyp \/kaggle\/input\/modified-effnet-classification\/hyperparameters.yaml --weights yolov5x.pt --cache","43b23a7a":"plt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/labels_correlogram.jpg'));","aa1a8ddb":"plt.figure(figsize = (20,20))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/labels.jpg'));","af1095dc":"import matplotlib.pyplot as plt\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch0.jpg'))\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch1.jpg'))\n\nplt.figure(figsize = (15, 15))\nplt.imshow(plt.imread('runs\/train\/exp\/train_batch2.jpg'))","89e906c5":"fig, ax = plt.subplots(3, 2, figsize = (2*5,3*5), constrained_layout = True)\nfor row in range(3):\n    ax[row][0].imshow(plt.imread(f'runs\/train\/exp\/test_batch{row}_labels.jpg'))\n    ax[row][0].set_xticks([])\n    ax[row][0].set_yticks([])\n    ax[row][0].set_title(f'runs\/train\/exp\/test_batch{row}_labels.jpg', fontsize = 12)\n    \n    ax[row][1].imshow(plt.imread(f'runs\/train\/exp\/test_batch{row}_pred.jpg'))\n    ax[row][1].set_xticks([])\n    ax[row][1].set_yticks([])\n    ax[row][1].set_title(f'runs\/train\/exp\/test_batch{row}_pred.jpg', fontsize = 12)","2e8db03a":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/results.png'));","49ed67d3":"plt.figure(figsize=(30,15))\nplt.axis('off')\nplt.imshow(plt.imread('runs\/train\/exp\/confusion_matrix.png'));","d2d3b93f":"!python detect.py --weights 'runs\/train\/exp\/weights\/best.pt'\\\n--img 640\\\n--conf 0.15\\\n--iou 0.5\\\n--source \/kaggle\/working\/vinbigdata\/images\/val\\\n--exist-ok","f2c69902":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs\/detect\/exp\/*')\nfor _ in range(3):\n    row = 4\n    col = 4\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img          = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","33a2d8c6":"shutil.rmtree('\/kaggle\/working\/vinbigdata')\nshutil.rmtree('runs\/detect')\nfor file in (glob('runs\/train\/exp\/**\/*.png', recursive = True)+glob('runs\/train\/exp\/**\/*.jpg', recursive = True)):\n    os.remove(file)","1730d72c":"# Train","45f259f1":"# Confusion Matrix","0a64b935":"# Inference","3fda3fac":"# Pre-Processing","d7f7f9ec":"# Remove Only 14 Class","dc40f601":"# BBox Location","fcc8a5ec":"# Get Class Name","f5ec0f9f":"# Class Distribution","8dacb18f":"# Copying Files","2a9e526b":"# YOLOv5 Stuff","3892f9f4":"# GT Vs Pred","7e622c71":"# (Loss, Map) Vs Epoch","61fa8532":"# Inference Plot","0fea9f7b":"# Batch Image"}}