{"cell_type":{"71493188":"code","404bb2b3":"code","e54648ea":"code","23c30ccf":"code","e1da99db":"code","af2ebe53":"code","849c7cab":"code","d2b56da4":"code","a330de46":"code","17b8eadd":"code","a60427c6":"code","e80cc020":"code","56421cf7":"code","0002a85e":"code","67aed67f":"code","421e0291":"code","130b2550":"code","9228e249":"code","d4166172":"code","771fb335":"code","be1b88ed":"code","cf751db3":"code","144d4494":"code","00a5510c":"code","079628ff":"code","8ac1ff2a":"code","c28990be":"code","e1b8c267":"code","36595d6f":"code","af833c2d":"code","aa0a817f":"code","bf85ef77":"code","7c93b9c0":"code","f63c8094":"code","7e2c8c55":"code","a33933bb":"code","a334822a":"code","2d990717":"code","95ca43be":"code","a2ff713b":"code","0d3594dd":"code","fa16b2a1":"code","7b9f657c":"code","f8ceb604":"code","d09e5684":"code","52c42a98":"code","7af4fbaa":"code","f8b210ff":"code","10181827":"code","77272e95":"code","0ce99824":"code","d64ee289":"code","b466c034":"code","44f8c31c":"code","d933a79c":"code","4fe64031":"code","bad25b63":"code","b150a809":"code","bc4f8c31":"code","7089b99c":"code","c529bb5b":"code","8472cadb":"code","c00c63e1":"code","7028cf1d":"code","5a46063c":"code","c30ef638":"code","697c04e3":"code","7d800eef":"code","a97c63ef":"code","7e4ad68c":"code","b7a31e91":"code","b98a0f88":"code","11f11554":"code","95529845":"code","54b3dd35":"code","ad8f4ae9":"code","7e36157d":"code","bd70ab9c":"code","11d6a8e7":"code","603e8e16":"code","c3f50a2b":"code","998da46a":"code","22726ef5":"code","2c3e9137":"code","a806f442":"code","11579adc":"code","f73f6f0f":"code","55442ecd":"markdown","1ce83b81":"markdown","c0d64d17":"markdown","d9268f80":"markdown","58e87e03":"markdown","3c4b02fe":"markdown","3467671c":"markdown","0213d616":"markdown","a2ef3ee0":"markdown","4d545ead":"markdown","e843a1f4":"markdown","bdadd854":"markdown","e7a9826b":"markdown","16aff116":"markdown","95a2b9e7":"markdown","782f6039":"markdown","22af14fa":"markdown","97dab28c":"markdown","0a75c654":"markdown","6e2be837":"markdown","d373c3d4":"markdown","d6c39368":"markdown","b633488b":"markdown","157134ae":"markdown","38b27acf":"markdown","4f0c1181":"markdown","3c5d45b2":"markdown","7d9b2335":"markdown","a861b25f":"markdown","72f21e9c":"markdown","015977f7":"markdown","c3a2afdb":"markdown","d23bdfa1":"markdown","92bf38d7":"markdown","de84cd31":"markdown","6e960b7c":"markdown","06469e12":"markdown","afaf51b7":"markdown","3fce283a":"markdown","09b052f7":"markdown","f8a8caa3":"markdown","10ab8e9d":"markdown","cda06bac":"markdown","8f660cec":"markdown","b6849dad":"markdown","7620ea94":"markdown","e9ad0851":"markdown","8e32b7bc":"markdown","0d3dbe16":"markdown","7bfefc3d":"markdown","4cb473ad":"markdown","ed90467f":"markdown","9dcd7867":"markdown","ca8aee6f":"markdown","ab0abdd5":"markdown","e191c05e":"markdown","a409f8bb":"markdown","e211a955":"markdown","994065c7":"markdown","d197d472":"markdown","3d96fbeb":"markdown","e2983d25":"markdown","7434933b":"markdown","0aaa9e91":"markdown","ad9fe6ce":"markdown","96942260":"markdown","cb59ffba":"markdown","cd61522f":"markdown","ffc7dbde":"markdown","038b5a1d":"markdown","04eacd14":"markdown","ff2f93a8":"markdown","672736b6":"markdown","1071e4f2":"markdown","a8d681c5":"markdown","708cefaa":"markdown","00c242fc":"markdown","7b4310a1":"markdown","90400b6c":"markdown","dcdd32d9":"markdown","feb79b4a":"markdown","43817a8e":"markdown","07bec191":"markdown","ce7b7f8d":"markdown","589be83c":"markdown","b4a2f511":"markdown","960b7818":"markdown","7d85e581":"markdown","ae9e1522":"markdown","41d4992b":"markdown","492b4593":"markdown","2747a794":"markdown","de4bb332":"markdown","6ef00f86":"markdown","02164935":"markdown","a1170a41":"markdown","3d5e6ea3":"markdown","f040c425":"markdown","630043ea":"markdown","10f4fb54":"markdown","34671d08":"markdown","28a63640":"markdown"},"source":{"71493188":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nfrom sklearn.model_selection import cross_val_score,cross_val_predict, train_test_split\nfrom sklearn.preprocessing import OneHotEncoder,StandardScaler,PowerTransformer,LabelEncoder\n\nfrom sklearn.metrics import accuracy_score,classification_report, recall_score,confusion_matrix, roc_auc_score, precision_score, f1_score, roc_curve, auc, plot_confusion_matrix,plot_roc_curve\n\n\nimport optuna\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n\n\n\n#importing plotly and cufflinks in offline mode\nimport cufflinks as cf\nimport plotly.offline\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\n\n\nimport plotly \nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.offline as py\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\n\nimport shap \n\nimport missingno as msno\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","404bb2b3":"pd.set_option('max_columns',100)\npd.set_option('max_rows',900)\n\npd.set_option('max_colwidth',200)","e54648ea":"data = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndata.head()","23c30ccf":"df = data.copy()","e1da99db":"df.head()","af2ebe53":"print(\"We have \", df.shape[0], \" rows and \", df.shape[1], \"columns in our dataset.\")","849c7cab":"df.duplicated().sum()","d2b56da4":"df.duplicated().any()","a330de46":"\ndef missing (df):\n    missing_number = df.isnull().sum().sort_values(ascending=False)\n    missing_percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n    return missing_values\n\nmissing(df)","17b8eadd":"df.info()","a60427c6":"df1 = df.drop(\"customerID\", axis=1).copy()\ndf1.head()","e80cc020":"df1.columns","56421cf7":"# Following two codes were given for displaying that even though we do not have any missing value above we need to check deeper just to be 100% sure.\ndf2 = df1.copy()","0002a85e":"# It seems that we have some missing values in our dataset.\n# df2[\"TotalCharges\"] = df2[\"TotalCharges\"].astype(float)\n# df2.info()","67aed67f":"print(\"Before dealing with blank values, let's see what we have that causes the error above.\")\nprint(df1[df1['TotalCharges'] == ' '].index)","421e0291":"df1[\"TotalCharges\"] = df1[\"TotalCharges\"].map(lambda x: x if x!=\" \" else np.nan).astype(float)","130b2550":"df1.info()","9228e249":"def missing (df):\n    missing_number = df.isnull().sum().sort_values(ascending=False)\n    missing_percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n    return missing_values\n\nmissing(df1)","d4166172":"y = df1['Churn']\nprint(f'Percentage of Churn:  {round(y.value_counts(normalize=True)[1]*100,2)} %  --> ({y.value_counts()[1]} customers)')\nprint(f'Percentage Non_Churn: {round(y.value_counts(normalize=True)[0]*100,2)}  %  --> ({y.value_counts()[0]} customers)')","771fb335":"y.iplot(kind=\"hist\", title=\"Churns vs. NonChurns\");","be1b88ed":"le = LabelEncoder()\ndf1.Churn = le.fit_transform(df1.Churn)","cf751db3":"df1.info()","144d4494":"numerical= df1.select_dtypes(include = 'number').columns\n\ncategorical = df1.select_dtypes(include = 'object').columns\n\nprint(f'Numerical Columns:  {df1[numerical].columns}')\nprint('\\n')\nprint(f'Categorical Columns: {df1[categorical].columns}')","00a5510c":"df1.tenure = df1.tenure.astype(float)","079628ff":"df1.tenure.dtype","8ac1ff2a":"df1[numerical].describe()\n# df1.describe()","c28990be":"df1[[\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]].iplot(kind=\"histogram\", subplots=True, bins=50);","e1b8c267":"plt.figure(figsize=(16, 8))\nsns.heatmap (df1[numerical].corr(), annot=True, fmt= '.2f', vmin=-1, vmax=1, center=0, cmap='coolwarm');","36595d6f":"df1[categorical].nunique()","af833c2d":"for column in df1[categorical]:\n    print(f\"{column}: {df1[column].unique()}\")","aa0a817f":"df1.groupby(\"gender\")[\"Churn\"].value_counts(normalize=True)","bf85ef77":"print(f'A female customer has a probability of {round(df1[df1[\"gender\"]==\"Female\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A female customer has a probability of {round(df1[df1[\"gender\"]==\"Male\"][\"Churn\"].mean()*100,2)} % churn.')","7c93b9c0":"# print(f'A female customer has a probability of {round(df1[df1[\"gender\"]==\"Female\"][\"Churn\"].value_counts(normalize=True)[1]*100,2)} % churn.')\n# print()\n# print(f'A female customer has a probability of {round(df1[df1[\"gender\"]==\"Male\"][\"Churn\"].value_counts(normalize=True)[1]*100,2)} % churn.')","f63c8094":"fig = px.histogram(data_frame=df1, x=\"gender\", color=\"Churn\", width=420, height=420)\nfig.show()","7e2c8c55":"print(f'A customer who has a partner has a probability of {round(df1[df1[\"Partner\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have a partner has a probability of {round(df1[df1[\"Partner\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","a33933bb":"fig = px.histogram(data_frame=df1, x=\"Partner\", color=\"Churn\", width=420, height=420)\nfig.show()","a334822a":"print(f'A customer who has dependents has a probability of {round(df1[df1[\"Dependents\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have dependents has a probability of {round(df1[df1[\"Dependents\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","2d990717":"fig = px.histogram(data_frame=df1, x=\"Dependents\", color=\"Churn\", width=420, height=420)\nfig.show()","95ca43be":"print(f'A customer who has a phone service has a probability of {round(df1[df1[\"PhoneService\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have a phone service has a probability of {round(df1[df1[\"PhoneService\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","a2ff713b":"fig = px.histogram(data_frame=df1, x=\"PhoneService\", color=\"Churn\", width=420, height=420)\nfig.show()","0d3594dd":"df1.MultipleLines.unique()","fa16b2a1":"df1.MultipleLines = df1.MultipleLines.replace(\"No phone service\", \"No\")\ndf1.MultipleLines.unique()","7b9f657c":"print(f'A customer who has multiple lines has a probability of {round(df1[df1[\"MultipleLines\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have multiple lines has a probability of {round(df1[df1[\"MultipleLines\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","f8ceb604":"fig = px.histogram(data_frame=df1, x=\"MultipleLines\", color=\"Churn\", width=420, height=420)\nfig.show()","d09e5684":"print(f'A customer with a Fiber optic internet service has a probability of {round(df1[df1[\"InternetService\"]==\"Fiber optic\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer with a DSL internet service has a probability of {round(df1[df1[\"InternetService\"]==\"DSL\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer with no internet service has a probability of {round(df1[df1[\"InternetService\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","52c42a98":"fig = px.histogram(data_frame=df1, x=\"InternetService\", color=\"Churn\", width=420, height=420)\nfig.show()","7af4fbaa":"col_list = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\nfor col in col_list:\n    print(col,\" :\" , df1[col].unique())","f8b210ff":"df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')","10181827":"print(f'A customer who has online security has a probability of {round(df1[df1[\"OnlineSecurity\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have online security has a probability of {round(df1[df1[\"OnlineSecurity\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","77272e95":"fig = px.histogram(data_frame=df1, x=\"OnlineSecurity\", color=\"Churn\", width=420, height=420)\nfig.show()","0ce99824":"print(f'A customer who has online backup has a probability of {round(df1[df1[\"OnlineBackup\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have online backup has a probability of {round(df1[df1[\"OnlineBackup\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","d64ee289":"fig = px.histogram(data_frame=df1, x=\"OnlineBackup\", color=\"Churn\", width=420, height=420)\nfig.show()","b466c034":"print(f'A customer who has device protection has a probability of {round(df1[df1[\"DeviceProtection\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have device protection has a probability of {round(df1[df1[\"DeviceProtection\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","44f8c31c":"fig = px.histogram(data_frame=df1, x=\"DeviceProtection\", color=\"Churn\", width=420, height=420)\nfig.show()","d933a79c":"print(f'A customer who has tech support has a probability of {round(df1[df1[\"TechSupport\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have tech support has a probability of {round(df1[df1[\"TechSupport\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","4fe64031":"fig = px.histogram(data_frame=df1, x=\"TechSupport\", color=\"Churn\", width=420, height=420)\nfig.show()","bad25b63":"print(f'A customer who has streaming tv has a probability of {round(df1[df1[\"StreamingTV\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have streaming tv has a probability of {round(df1[df1[\"StreamingTV\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","b150a809":"fig = px.histogram(data_frame=df1, x=\"StreamingTV\", color=\"Churn\", width=420, height=420)\nfig.show()","bc4f8c31":"print(f'A customer who has streaming movies has a probability of {round(df1[df1[\"StreamingMovies\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn.')\nprint()\nprint(f'A customer who does not have streaming movies has a probability of {round(df1[df1[\"StreamingMovies\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn.')","7089b99c":"fig = px.histogram(data_frame=df1, x=\"StreamingMovies\", color=\"Churn\", width=420, height=420)\nfig.show()","c529bb5b":"df1.Contract.unique()","8472cadb":"print (f'A customer with a month-to-month contract has a probability of {round(df1[df1[\"Contract\"]==\"Month-to-month\"][\"Churn\"].mean()*100,2)} % churn')\nprint()\nprint (f'A customer with a two-year contract has a probability of {round(df1[df1[\"Contract\"]==\"Two year\"][\"Churn\"].mean()*100,2)} % churn')\nprint()\nprint (f'A customer with a one-year contract has a probability of {round(df1[df1[\"Contract\"]==\"One year\"][\"Churn\"].mean()*100,2)} % churn')","c00c63e1":"fig = px.histogram(data_frame=df1, x=\"Contract\", color=\"Churn\", width=420, height=420)\nfig.show()","7028cf1d":"print (f'A customer with a Paperless billing  has a probability of {round(df1[df1[\"PaperlessBilling\"]==\"Yes\"][\"Churn\"].mean()*100,2)} % churn')\nprint()\nprint (f'A customer without a Paperless billing has a probability of {round(df1[df1[\"PaperlessBilling\"]==\"No\"][\"Churn\"].mean()*100,2)} % churn')","5a46063c":"fig = px.histogram(data_frame=df1, x=\"PaperlessBilling\", color=\"Churn\", width=420, height=420)\nfig.show()","c30ef638":"print (f'A customer with a Payment method as a Electornic Check has a probability of {round(df1[df1[\"PaymentMethod\"]==\"Electronic check\"][\"Churn\"].mean()*100,2)} % churn')\nprint()\nprint (f'A customer with a Payment method as a Mailed Check has a probability of {round(df1[df1[\"PaymentMethod\"]==\"Mailed check\"][\"Churn\"].mean()*100,2)} % churn')\nprint()\nprint (f'A customer with a Payment method as a Bank transfer (automatic) has a probability of {round(df1[df1[\"PaymentMethod\"]==\"Bank transfer (automatic)\"][\"Churn\"].mean()*100,2)} % churn')\nprint()\nprint (f'A customer with a Payment method as a Credit card (automatic) has a probability of {round(df1[df1[\"PaymentMethod\"]==\"Credit card (automatic)\"][\"Churn\"].mean()*100,2)} % churn')","697c04e3":"fig = px.histogram(data_frame=df1, x=\"PaymentMethod\", color=\"Churn\", width=420, height=420)\nfig.show()","7d800eef":"# All codes in one cell!\naccuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\nmodel_names =[]\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n# Since we saw almost no difference in churn rates for the following features, we decided to drop them. \ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\n# convert categorical into numerical (for target feature)\nle = LabelEncoder()  \ndf1['Churn']=le.fit_transform(df1['Churn'])\n\n\ndf1['tenure']= df1['tenure'].astype(float)\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\ncategorical_features_indices = np.where(X.dtypes != np.float)[0]\n\n# Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\ncatboost_base = CatBoostClassifier(verbose=False,random_state=0)\n\ncatboost_base.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_test, y_test))\ny_pred = catboost_base.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['Catboost_default']\nresult_df1 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df1","a97c63ef":"fig, ax = plt.subplots(figsize=(10, 6))\nplot_confusion_matrix(catboost_base, X_test, y_test, cmap=plt.cm.plasma, ax=ax);","7e4ad68c":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['tenure']= df1['tenure'].astype(float)\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\ncategorical_features_indices = np.where(X.dtypes != np.float)[0]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# With scale_pos_weight=3, minority class gets 3 times more impact and 3times more correction than errors made on the majority class.\ncatboost = CatBoostClassifier(verbose=False,random_state=0,scale_pos_weight=3)\n\ncatboost.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_test, y_test))\ny_pred = catboost.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['Catboost_adjusted_weight_3']\nresult_df2 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df2","b7a31e91":"fig, ax = plt.subplots(figsize=(10, 6))\nplot_confusion_matrix(catboost, X_test, y_test, cmap=\"plasma\", ax=ax);","b98a0f88":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['tenure']= df1['tenure'].astype(float)\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\ncategorical_features_indices = np.where(X.dtypes != np.float)[0]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# With scale_pos_weight=5, minority class gets 5 times more impact and 5 times more correction than errors made on the majority class.\ncatboost_5 = CatBoostClassifier(verbose=False,random_state=0,scale_pos_weight=5)\n\ncatboost_5.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_test, y_test))\ny_pred = catboost_5.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['Catboost_adjusted_weight_5']\nresult_df3 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df3","11f11554":"fig, ax = plt.subplots(figsize=(10, 6))\nplot_confusion_matrix(catboost_5, X_test, y_test, cmap=\"plasma\", ax=ax);","95529845":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n# Since XGBoost cannot handle catgorical features internally, we convert them into numeric features with get_dummies.\ndf1= pd.get_dummies(df1)\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nxgbc_base = XGBClassifier(random_state=0)\n\nxgbc_base.fit(X_train, y_train)\ny_pred = xgbc_base.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['XGBoost_Default']\nresult_df4 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df4","54b3dd35":"fig, ax = plt.subplots(figsize=(10, 6))\nplot_confusion_matrix(xgbc_base, X_test, y_test, cmap=\"plasma\", ax=ax);","ad8f4ae9":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n# Since XGBoost cannot handle catgorical features internally, we convert them into numeric features with get_dummies.\ndf1= pd.get_dummies(df1)\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# With scale_pos_weight=3, minority class gets 3 times more impact and 3 times more correction than errors made on the majority class.\nxgbc_3 = XGBClassifier(random_state=0,scale_pos_weight=3)\n\nxgbc_3.fit(X_train, y_train)\ny_pred = xgbc_3.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['XGBoost_adjusted_weight_3']\nresult_df5 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df5","7e36157d":"fig, ax = plt.subplots(figsize=(10, 6))\nplot_confusion_matrix(xgbc_3, X_test, y_test, cmap=\"plasma\", ax=ax);","bd70ab9c":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n# Since XGBoost cannot handle catgorical features internally, we convert them into numeric features with get_dummies.\ndf1= pd.get_dummies(df1)\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# With scale_pos_weight=5, minority class gets 5 times more impact and 5 times more correction than errors made on the majority class.\nxgbc_5 = XGBClassifier(random_state=0,scale_pos_weight=5)\n\nxgbc_5.fit(X_train, y_train)\ny_pred = xgbc_5.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['XGBoost_adjusted_weight_5']\nresult_df6 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df6","11d6a8e7":"fig, ax = plt.subplots(figsize=(10, 6))\nplot_confusion_matrix(xgbc_5, X_test, y_test, cmap=\"plasma\", ax=ax);","603e8e16":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n# We can comment out get_dummies in the following code. The scores will be silightly different. However, plot_confusion_metrics will not work.\ndf1= pd.get_dummies(df1)\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\nfor col in X.columns:\n    col_type = X[col].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        X[col] = X[col].astype('category')\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nlgbmc_base=LGBMClassifier(random_state=0)\n\nlgbmc_base.fit(X_train, y_train,categorical_feature = 'auto',eval_set=(X_test, y_test),feature_name='auto', verbose=0)\n\ny_pred = lgbmc_base.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['LightGBM_default']\nresult_df7 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df7","c3f50a2b":"fig, ax = plt.subplots(figsize=(10, 6))\nplot_confusion_matrix(lgbmc_base, X_test, y_test, cmap=\"plasma\", ax=ax);","998da46a":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n# We can comment out get_dummies in the following code. The scores will be silightly different. However, plot_confusion_metrics will not work.\ndf1= pd.get_dummies(df1)\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\nfor col in X.columns:\n    col_type = X[col].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        X[col] = X[col].astype('category')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# With scale_pos_weight=3, minority class gets 3 times more impact and 3 times more correction than errors made on the majority class.\nlgbmc_3=LGBMClassifier(random_state=0,scale_pos_weight=3)\n\nlgbmc_3.fit(X_train, y_train,categorical_feature = 'auto',eval_set=(X_test, y_test),feature_name='auto', verbose=0)\n\ny_pred = lgbmc_3.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['LightGBM_adjusted_weight_3']\nresult_df8 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df8","22726ef5":"fig, ax = plt.subplots(figsize=(10, 6))\nplot_confusion_matrix(lgbmc_3, X_test, y_test, cmap=\"plasma\", ax=ax);","2c3e9137":"accuracy= []\nrecall =[]\nroc_auc= []\nprecision = []\n\n\ndf = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf1 = df.drop(['customerID','gender','PhoneService'],axis=1).copy()\nle = LabelEncoder()\ndf1['Churn']=le.fit_transform(df1['Churn'])\n\ndf1['TotalCharges']= df1['TotalCharges'].apply(lambda x: x if x!= ' ' else np.nan).astype(float)\n\ndf1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']]= df1[['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']].replace('No internet service','No')\n\n# We can comment out get_dummies in the following code. The scores will be silightly different. However, plot_confusion_metrics will not work.\ndf1= pd.get_dummies(df1)\nX= df1.drop('Churn', axis=1)\ny= df1['Churn']\n\nfor col in X.columns:\n    col_type = X[col].dtype\n    if col_type == 'object' or col_type.name == 'category':\n        X[col] = X[col].astype('category')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# With scale_pos_weight=5, minority class gets 5 times more impact and 5 times more correction than errors made on the majority class.\nlgbmc_5=LGBMClassifier(random_state=0,scale_pos_weight=5)\n\nlgbmc_5.fit(X_train, y_train,categorical_feature = 'auto',eval_set=(X_test, y_test),feature_name='auto', verbose=0)\n\ny_pred = lgbmc_5.predict(X_test)\n\naccuracy.append(round(accuracy_score(y_test, y_pred),4))\nrecall.append(round(recall_score(y_test, y_pred),4))\nroc_auc.append(round(roc_auc_score(y_test, y_pred),4))\nprecision.append(round(precision_score(y_test, y_pred),4))\n\nmodel_names = ['LightGBM_adjusted_weight_5']\nresult_df9 = pd.DataFrame({'Accuracy':accuracy,'Recall':recall, 'Roc_Auc':roc_auc, 'Precision':precision}, index=model_names)\nresult_df9","a806f442":"fig, ax = plt.subplots(figsize=(10, 6))\nplot_confusion_matrix(lgbmc_5, X_test, y_test, cmap=\"plasma\", ax=ax);","11579adc":"result_final= pd.concat([result_df1,result_df2,result_df3,result_df4,result_df5,result_df6, result_df7,result_df8,result_df9],axis=0)\nresult_final","f73f6f0f":"result_final.sort_values(by=['Recall'], ascending=True,inplace=True)\nfig = px.bar(result_final, x='Recall', y=result_final.index,title='Model Comparison',height=600,labels={'index':'MODELS'})\nfig.show()","55442ecd":"Today, we will create models with famous trio (**XGBoost** & **LightGBM** & **Catboost**) that predict behavior to retain customers. We will analyze all relevant customer data and develop focused customer retention programs.","1ce83b81":"#### Contract vs. Churn","c0d64d17":"# Famous Trio and Imbalanced Data","d9268f80":"#### TechSupport vs. Churn","58e87e03":"- By using recommended value for **scale_pos_weight**, **LightGBM** correctly predicted almost 77% of the churned customer.","3c4b02fe":"# Model Comparision","3467671c":"- With the default parameters, Catboost get almost 0.52 **Recall** and 0.72 **Roc_Auc**.","0213d616":"### CatBoost - scale_pos_weight = 5","a2ef3ee0":"### XGBoost - with default parameters","4d545ead":"#### StremingTV vs. Churn","e843a1f4":"- Great! We managed to convert type of **TotalCharges** into **float** and change spaces into missing values.\n- Since each member of famous trio (**XGBoost** & **LightGBM** & **Catboost**) deals with missing values itself, we do not bother to fill or drop them.","bdadd854":"- By only changing the value of **scale_pos_weight** to recommended value (three in our case) we increased our **Recall** score by 32%.\n- In other words, **CatBoost** correctly predicted 84% of churned customers.\n- However, for such an increase in **Recall** scoe, we compromised our **Pricision** score (it reduced from 0.69 to 0.53).","e7a9826b":"- It is an **boosting** algorithm.\n- It only habdles missing values internally.","16aff116":"- CatBoost, XGBoost, and LightGBM use **scale_pos_weight** hyperparameter to tune the training algorithm for the imbalanced data.\n\n- By defualt, **scale_pos_weight** is 1.\n\n- Both major class and minority class get the same weight in balanced data. However, when dealing with imbalanced data, story changes a bit.\n\n- Formula for calculating value of **scale_pos_weight**: \n    - Number of Non-churned (**majority**) customer: 5174\n    - Number of Churned customer(**minority**): 1869\n    - **scale_pos_weight** = 5174 \/ 1869 or almost 3\n- By adjusting the weight, minority class gets 3 times more impact and 3 times more correction than errors made on the majority class.\n\n**Note1**: If we use extreme values for the **scale_pos_weight**, we can overfit the minority class and model could make worse predictions.\n\n**Note2**: While **CatBoost** and **LightGBM** can handle categorical features, **XGBoost** cannot. You have to convert categorical features before creating your model.","95a2b9e7":"- With **scale_pos_weight =5**, **LightGBM** correctly predicted 83% of the churned customer.","782f6039":"We will also deal with imbalanced data by using the famous trio modles.","22af14fa":"# Exploratory Data Analysis","97dab28c":"- After analyzing data and data dictionary we see that we have a classification problem.\n- We wil make classification on the target variable **Churn**.\n- For this purpose we will look at the balance of the target variable.\n- Since our target variable has imblanced data we are not going to use **Accuracy** score.\n- Based on the problem on the hand, we will use **Recall** score.","0a75c654":"- It is an algorithm that was developed by **Microsoft**.\n- It can handle both missing values and categorical values internally.","6e2be837":"- By using weight a little bit higher than recommended formula for **scale_pos_weight = 5**, **CatBoost** correctly predict almost 92% of the churned customers.\n- On the other hand we have lost 7% for the **Precision** and 3 points for the **Roc_Auc** score.","d373c3d4":"## XGBOOST","d6c39368":"- Now, let's look at the **CatBoost**, **XGBoost**, and **LightGBM** and see how they handle imbalanced data internally.\n- By giving an opportunity to focus more on the minority class and accordingly tunning the training, they do good job even on imbalanced data.","b633488b":"- Churn rate of customers with phone service is quite close to churn rate of customers without phone service.","157134ae":"- We have an extra **No internet service** value in each of these columns. Let's correct it.","38b27acf":"- Customers without dependents are almost 2.1 times more likely to churn than those with dependents.","4f0c1181":"#### DeviceProtection vs. Churn","3c5d45b2":"- We converted **Churn** column into numeric type.","7d9b2335":"- We converted **tenure** column type into **float**.","a861b25f":"- While almost half of the customers with electronic check churn, rest of the churn rates are close to each other.","72f21e9c":"> - Great news! We do  not have a high cardinality or zero variance issues.","015977f7":"- It seems that there is not much difference between genders on **churn** rate.","c3a2afdb":"- We have neither duplicated nor missing value (some deeper checks might always be needed to be 100% sure).","d23bdfa1":"- We dropped **cutomerID** column.","92bf38d7":"- A customer with a streaming tv with the company is almost 1.2 more likely to leave the company than a customer without any online backup service with the company.","de84cd31":"#### OnlineSecurity vs. Churn","6e960b7c":"#### StreamingMovies vs. Churn","06469e12":"- Withdefault value of **scale_pos_weight**, **XGBoost** correctly predicted less than half of the churned customers.","afaf51b7":"1. **`CustomerID`**: A unique ID that identifies each customer.\n\n2. **`Gender`**: The customer\u2019s gender: Male, Female\n\n3. **`Age`**: The customer\u2019s current age, in years, at the time the fiscal quarter ended.\n\n4. **`Senior Citizen`**: Indicates if the customer is 65 or older: Yes, No\n\n5. **`Married (Partner)`**: Indicates if the customer is married: Yes, No\n\n6. **`Dependents`**: Indicates if the customer lives with any dependents: Yes, No. Dependents could be children, parents, grandparents, etc.\n\n7. **`Number of Dependents`**: Indicates the number of dependents that live with the customer.\n\n8. **`Phone Service`**: Indicates if the customer subscribes to home phone service with the company: Yes, No\n\n9. **`Multiple Lines`**: Indicates if the customer subscribes to multiple telephone lines with the company: Yes, No\n\n10. **`Internet Service`**: Indicates if the customer subscribes to Internet service with the company: No, DSL, Fiber Optic, Cable.\n\n11. **`Online Security`**: Indicates if the customer subscribes to an additional online security service provided by the company: Yes, No\n\n12. **`Online Backup`**: Indicates if the customer subscribes to an additional online backup service provided by the company: Yes, No\n\n13. **`Device Protection Plan`**: Indicates if the customer subscribes to an additional device protection plan for their Internet equipment provided by the company: Yes, No\n\n14. **`Premium Tech Support`**: Indicates if the customer subscribes to an additional technical support plan from the company with reduced wait times: Yes, No\n\n15. **`Streaming TV`**: Indicates if the customer uses their Internet service to stream television programing from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n\n16. **`Streaming Movies`**: Indicates if the customer uses their Internet service to stream movies from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n\n17. **`Contract`**: Indicates the customer\u2019s current contract type: Month-to-Month, One Year, Two Year.\n\n18. **`Paperless Billing`**: Indicates if the customer has chosen paperless billing: Yes, No\n\n19. **`Payment Method`**: Indicates how the customer pays their bill: Bank Withdrawal, Credit Card, Mailed Check\n\n20. **`Monthly Charge`**: Indicates the customer\u2019s current total monthly charge for all their services from the company.\n\n21. **`Total Charges`**: Indicates the customer\u2019s total charges, calculated to the end of the quarter specified above.\n\n22. **`Tenure`**: Indicates the total amount of months that the customer has been with the company.\n\n23. **`Churn`**: Yes = the customer left the company this quarter. No = the customer remained with the company. Directly related to Churn Value.\n\nNew version from IBM:\nhttps:\/\/community.ibm.com\/community\/user\/businessanalytics\/blogs\/steven-macko\/2019\/07\/11\/telco-customer-churn-1113","3fce283a":"- Now we found what causes us a problem. We have some spaces in **TotalCharges** column.","09b052f7":"**In this notebook**: \n\n- We have looked in detail at how famous trio (**XGBoost** & **LightGBM** & **CatBoost**) handle the imbalanced data internally.\n- In general, boosting algorithms do good job even on imbalanced data.\n- They produce good results on the imbalanced data by giving an opportunity to focus more on the minority class and accordingly tune the training algorithm.\n- CatBoost, XGBoost and LightGBM use **scale_pos_weight** hyperparameter to tune the training algrotih for the imbalanced data.","f8a8caa3":"- A customer with an online security service with the company is almost 2.2 times less likely to leave the company than a customer without any online security service with the company.","10ab8e9d":"- Since **No phone service** is same as **No** let's correct this naming issue.","cda06bac":"#### Dependents vs. Churn","8f660cec":"- With the adjusted **scale_pos_weight = 5**, **LightGBM** got .*083 **Recall** and almost 0.76 **Roc_Auc**.","b6849dad":"- A customer with a streaming movies service with the company is almost 1.2 more likely to leave the company than a customer without any online backup service with the company.","7620ea94":"- A customer with a paperless billing with the company is almost 2.1 times more likely to leave the company than a customer without a paperless billing with the company.","e9ad0851":"- With the adjusted **scale_pos_weight = 3**, **LightGBM** got 0.77 **Recall** and 0.76 **Roc_Auc**.","8e32b7bc":"**Based on our preliminary analysis, we conclude that**:\n\n- since we won't use **customerID, we will drop it,\n- type of **TotalCharges** should be converted into **float** type from **object** type,\n- for **CatBoost** model, type of **tenure** column will be converted into **float** type from **integer** type,\n- we will look at the cardinality of the categorical variables,\n- and finally, we will convert **churn** column to **numeric** type by using **label encoding**.","0d3dbe16":"### LigthGBM - with default parameters","7bfefc3d":"- As always, let's import libraries that we we use.","4cb473ad":"![image.png](attachment:aeca28ed-4221-4b94-bc5b-3d5fd766a224.png)","ed90467f":"### CatBoost - with default parameters","9dcd7867":"#### PaperlessBilling vs. Churn","ca8aee6f":"![](https:\/\/miro.medium.com\/max\/1400\/1*1kjLMDQMufaQoS-nNJfg1Q.png)","ab0abdd5":"- With the adjusted **scale_pos_weight = 5**, **XGBoost** got 0.74 **Recall** and 0.75 **Roc_Auc**.","e191c05e":"- **No internet service** is repeating several times in the features. It gives same meaning as **No**. So, we will change them to **No**.\n- We have the same issue for **MultipleLines** as well. We will follow the same steps. ","a409f8bb":"- Single customers are almost 1.7 times more likely to churn than those with partners.","e211a955":"### XGBoost - scale_pos_weight = 3","994065c7":"- It is obvious that we have imbalanced data.\n- Almost 27% of the customers (1869 customers) didn't continue with the company and churned.\n- Almost 73% of the customers (5174 customers) continue with the company and didn't churn.","d197d472":"- With recommended adjusted value of **scale_pos_weight**, **XGBoost** correctly predicted almost 67% of the churned customers.","3d96fbeb":"## Categorical Features","e2983d25":"- A customer with a tech support with the company is almost 2.1 times less likely to leave the company than a customer without any online backup service with the company.","7434933b":"- With default **scale_pos_weight** value (which equals to **one**), **CatBoost** correctly predicted slighly more than half of the chruned customers.\n- In other words, it could not correctly predict the other half of the churned customers.","0aaa9e91":"### LightGBM - scale_pos_weight = 5","ad9fe6ce":"- Churn rate of customers with multiple lines is quite close to churn rate of customers without multiple lines.","96942260":"## Numerical Features","cb59ffba":"- It is an **Boosting** algorithm that was created by **Yandex**.\n- It can handle both missing values and categorical values internally.","cd61522f":"# Table of Contents\n\n- Data\n\n- Problem at Hand and Metric to Use?\n\n- Exploratory Data Analysis\n    \n    - Target Variable\n    \n    - Numerical Features\n    \n    - Categorical Features\n    - Overall Insights\n\n- Famous Trio and Imbalanced Data\n\n    - CATBOOST\n\n    - XGBOOST\n\n    - LIGHTGBM\n\n- Model Comparision\n\n- Conclusion","ffc7dbde":"#### InternetService vs. Churn","038b5a1d":"- With the default parameters, **XGBoost** got 0.47 **Recall** and 0.68 **Roc_Auc**.","04eacd14":"# Conclusion","ff2f93a8":"# Data","672736b6":"# Hi all. \ud83d\ude4b","1071e4f2":"- A customer with a device protection with the company is almost 1.3 times less likely to leave the company than a customer without any online backup service with the company.","a8d681c5":"- With the adjusted **scale_pos_weight=3**, **CatBoost** got 0.84 **Recall** and 0.78 **Roc_Auc**.","708cefaa":"- Customers with a month-to-month contract with the company have the heighest churn rate.\n- Customers with a two-year contract with the company have the lowest churn rate.\n- One customer out of every hundred customers with one-year contract with the company is likely to churn.","00c242fc":"### XGBoost - scale_pos_weight = 5","7b4310a1":"#### PhoneService vs. Churn","90400b6c":"- **gender**: There is not much difference between genders on churn rate.\n- **Partner**: Single customers are almost 1.7 times more likely to churn than those with partners.\n- **Dependents**: Customers without dependents are almost 2.1 times more likely to churn than those with dependents.\n- **PhoneService**: Churn rate of customers with phone service is quite close to churn rate of customers without phone service.\n- **MultipleLines**: Churn rate of customers with multiple lines is quite close to churn rate of customers without multiple lines.\n- **InternetService**: \n    - Customers with a Fiber optic internet service have the heighest churn rate.\n    - Customers without internet service have the lowest churn rate.\n    - Almost five customers out of every hundred customers with DSL internet service are likely to churn.\n- **OnlineSecurity**: A customer with an online security service with the company is almost 2.2 times less likely to leave the company than a customer without any online security service with the company.\n- **OnlineBackup**: A customer with an online backup service with the company is almost 1.3 times less likely to leave the company than a customer without any online backup service with the company.\n- **DeviceProtection**: A customer with a device protection with the company is almost 1.3 times less likely to leave the company than a customer without any online backup service with the company.\n- **TechSupport**:A customer with a tech support with the company is almost 2.1 times less likely to leave the company than a customer without any online backup service with the company.\n- **StreamingTV**: A customer with a streaming tv with the company is almost 1.2 more likely to leave the company than a customer without any online backup service with the company.\n- **StreamingMovies**:A customer with a streaming movies service with the company is almost 1.2 more likely to leave the company than a customer without any online backup service with the company.\n- **Contract**: \n    - Customers with a month-to-month contract with the company have the heighest churn rate.\n    - Customers with a two-year contract with the company have the lowest churn rate.\n    - One customer out of every hundred customers with one-year contract with the company is likely to churn.\n- **PaperlessBilling**: A customer with a paperless billing with the company is almost 2.1 times more likely to leave the company than a customer without a paperless billing with the company.\n- **PaymentMethod**: While almost half of the customers with electronic check churn, rest of the churn rates are close to each other.","dcdd32d9":"- A customer with an online backup service with the company is almost 1.3 times less likely to leave the company than a customer without any online backup service with the company.","feb79b4a":"### Telco Customer Churn - Data Dictionary","43817a8e":"- With deafult value of **scale_pos_weight**, **LightGBM** correctly predicted slightly more than half of the churned customers.","07bec191":"![image.png](attachment:91c90f0c-c099-476c-86c4-2b810d5df8da.png)","ce7b7f8d":"## Target Variable ","589be83c":"- For ease of usage, we got the list of the **numerical** and **categorical** features.","b4a2f511":"## Overall Insights","960b7818":"# Problem at Hand and Metric to Use?","7d85e581":"## CATBOOST","ae9e1522":"- With the adjusted **scale_pos_weight=5**, **CatBoost** got almost 0.92 **Recall** and 0.75 **Roc_Auc**.","41d4992b":"#### PaymentMethod vs. Churn","492b4593":"## LIGHTGBM","2747a794":"**Have Fun Reading**","de4bb332":"#### OnlineBackup vs. Churn","6ef00f86":"- We can observe weak level correlation between the numerical features and the target variable.\n- We observe a strong correlation between **tenure** and **TotalCharges**.\n- Being senior citizen and increasing monthly charges have a positive correlation with the churn.\n- Customer with higher monthly charges also more likely churn than lesser monthly charges customers.\n- Being long term with the company, customer less likely churn than customer with lesser time with the company.\n- Total charges has negative correlation with the churn.","02164935":"### CatBoost - scale_pos_weight = 3","a1170a41":"- With default **scale_pos_weight**, **LightGBM** got almost 0.54 **Recall** and 0.71 **Roc_Auc**","3d5e6ea3":"#### Partner vs. Churn","f040c425":"### LightGBM - scale_pos_weight = 3","630043ea":"- With the adjusted **scale_pos_weigh = 3**, **XGBoost** got almost 0.67 **Recall** and 0.73 **Roc_Auc**.","10f4fb54":"#### gender vs. Churn ","34671d08":"- Customers with a Fiber optic internet service have the heighest churn rate.\n- Customers without internet service have the lowest churn rate.\n- Almost five customers out of every hundred customers with DSL internet service are likely to churn.","28a63640":"- With **scale_pos_weight = 5**, **XGBoost** correctly predicted almost 74% of the churned customers."}}