{"cell_type":{"b14fc6ad":"code","742fff5a":"code","349af1bc":"code","9362d266":"code","212f1f11":"code","add50cc6":"code","5c94497c":"code","ecf8e2fd":"code","91bacbcf":"code","304f555b":"code","8da51638":"code","5e318104":"code","892c874f":"code","4636bac4":"code","c4d23575":"code","3bc3de2d":"code","7334a5fa":"code","c5f6e5da":"code","24a0fa2c":"code","a433122b":"code","686e44c7":"code","24b8116b":"markdown","3af93b46":"markdown"},"source":{"b14fc6ad":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd\nimport lightgbm as lgb\nimport xgboost as xgb\nimport eli5\n\nfrom eli5.sklearn import PermutationImportance\nfrom collections import Counter, defaultdict\nfrom sklearn.decomposition import  PCA\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold, KFold, cross_val_score, train_test_split, GridSearchCV\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.metrics import auc, roc_auc_score \nfrom sklearn.ensemble import  GradientBoostingRegressor\nfrom catboost import CatBoostRegressor, CatBoostClassifier","742fff5a":"train = pd.read_csv(\"\/kaggle\/input\/mind-type-pred\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/mind-type-pred\/test_x.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/mind-type-pred\/sample_submission.csv\")","349af1bc":"is_test = False\nif is_test:\n    train=train.loc[:10000]\n    test=test.loc[:1000]","9362d266":"col_del = ['index', 'voted']","212f1f11":"data = pd.concat([train,test], axis=0)\ndata.reset_index(inplace=True, drop=True)\n\n# factorizing\n# for col in ['gender', 'race', 'age_group', 'religion']:\n#     data[col]=pd.factorize(data[col])[0]\n    \n# # dummy\nfor col in ['gender', 'age_group', 'education', 'race', 'religion' ]:   \n    data = pd.concat([data,pd.get_dummies(data[col])], axis=1)\ncol_del += ['gender', 'age_group', 'education', 'race', 'religion'] \n\n# \ubc94\uc8fc\ud615 \ube48\ub3c4\uc218\nfor col in ['age_group', 'religion', 'education']:\n    dic = dict(Counter(data[col]))\n    data['Freq_{}'.format(col)] = data[col].apply(lambda x:dic[x])\n\n# E\ubcc0\uc218 \ud1b5\uacc4\ub7c9\ngood = ['f', 'k', 'q', 'r']\nbad = ['b', 'c', 'e', 'h', 'j', 'm', 'o', 's']\nsecret = ['a', 'd', 'g', 'i', 'l', 'n', 'p', 't']\nvar_x = list(map(lambda x: 'Q'+x+'E', good+bad+secret))\nfor i, func in enumerate([np.min, np.max, np.mean, np.std]):\n    data['E_{}'.format(['min','max','mean','std'][i])] = data[var_x].agg(func, axis=1)\n\n# A\ubcc0\uc218 \ud1b5\uacc4\ub7c9\nvar_x = list(map(lambda x: 'Q'+x+'A', good+bad+secret))\nfor i, func in enumerate([np.min, np.max, np.mean, np.std]):\n    data['A_{}'.format(['min','max','mean','std'][i])] = data[var_x].agg(func, axis=1)\n\n# E \ud2b9\ubcc4 \ubcc0\uc218 \ud1b5\uacc4\ub7c9\nfor i, func in enumerate([np.mean, np.max, np.std]):\n    data['E_spe_{}'.format(['mean', 'max','std'][i])] = data[list(map(lambda x: 'Q'+x+'E', ['f','r','h','l']))].agg(func, axis=1)\n\n# E \ud2b9\ubcc4 if_big flag\nfor i, col in enumerate(list(map(lambda x: 'Q'+x+'E', ['f','r','h','l']))):\n    data['{}>1e+07'.format(col)] = data[col].apply(lambda x: 1 if x>1e+03 else 0)\n\n\n# E\ubcc0\uc218 \ud1b5\uacc4\ub7c9 (good, bad, secret \ub098\ub220\uc11c)\nfor i, vars in enumerate([good, bad,secret]):\n    for j, func in enumerate([np.min, np.max, np.mean, np.std]):\n        data['E_{}_{}'.format(['good','bad','secret'][i], ['min','max','mean','std'][j])] = data[list(map(lambda x: 'Q'+x+'E', vars))].agg(func, axis=1)\n\n# E\ubcc0\uc218 \ud1b5\uacc4\ub7c9 (group by Vars)\nfor i, var in enumerate(['race', 'religion', 'age_group', 'education']):\n    for j, func in enumerate([ np.max, np.mean, np.std]):\n        for e_var in list(map(lambda x: 'Q'+x+'E', good+bad+secret)):\n            dic = dict(data.groupby(var)[e_var].agg(func))\n            data['{}_{}_{}'.format(var, e_var, ['max','mean','std'][j])] = data[var].apply(lambda x:dic[x])\n            \n\n# E\ubcc0\uc218 \ud1b5\uacc4\ub7c9 (group by A \uc810\uc218)\nfor j, func in enumerate([np.min, np.max, np.mean, np.std]):\n    for e_var in list(map(lambda x: 'Q'+x+'E', good+bad+secret)):\n        dic = dict(data.groupby(e_var[:-1]+'A')[e_var].agg(func))\n        data['{}_{}'.format(e_var, ['min','max','mean','std'][j])] = data[e_var[:-1]+'A'].apply(lambda x:dic[x])\n\n# PCA\npca = PCA(n_components=3)\ndata[['PC1_E', 'PC2_E', 'PC3_E']] = pca.fit_transform(data[list(map(lambda x: 'Q'+x+'E', good+bad+secret))])\n\n# tp\ubcc0\uc218 \ud1b5\uacc4\ub7c9\nvar_x = list(map(lambda x: 'tp0'+str(x) if x<10 else 'tp'+str(x),[2,4,8,10]))\nfor i, func in enumerate([np.min, np.max, np.mean, np.std]):\n    data['tp_neg_{}'.format(['min','max','mean','std'][i])] = data[var_x].agg(func, axis=1)\n    \n# tp\ubcc0\uc218 \ud1b5\uacc4\ub7c9\nvar_x = list(map(lambda x: 'tp0'+str(x) if x<10 else 'tp'+str(x),[1,3,5,6,7,9]))\nfor i, func in enumerate([np.min, np.max, np.mean, np.std]):\n    data['tp_pos_{}'.format(['min','max','mean','std'][i])] = data[var_x].agg(func, axis=1)\n\n# # tp\ubcc0\uc218 \ud1b5\uacc4\ub7c9 (group by Vars)\n# for i, var in enumerate(['race', 'religion', 'age_group', 'education']):\n#     for j, func in enumerate([ np.max, np.mean, np.std]):\n#         for e_var in list(map(lambda x: 'tp0'+str(x) if x<10 else 'tp'+str(x), range(1, 11))):\n#             dic = dict(data.groupby(var)[e_var].agg(func))\n#             data['{}_{}_{}'.format(var, e_var, ['max','mean','std'][j])] = data[var].apply(lambda x:dic[x])\n\n# data['edu_age'] = pd.factorize(data['education'].astype(str) + data['age_group'].astype(str))[0]\n\ntrain = data.iloc[:45532]\ntest = data.iloc[45532:]","add50cc6":"X=train.columns[~pd.Series(train.columns).isin(col_del)]\ny='voted'\n\nprint(len(X))","5c94497c":"model = lgb.LGBMRegressor(n_estimators=100,    \n                            colsample_bytree = 0.7,\n#                           subsamples = 0.9,\n                          random_state = 42)\n# model = make_pipeline(MinMaxScaler(), ElasticNet(alpha=1e-3, l1_ratio=0.7)) \n\n\nclass Ensemble(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models, weights):\n        self.models = models\n        self.weights = weights\n        \n    def fit(self, X, y):\n        self.models_ = [clone(model) for model in self.models]\n        for model in self.models_:\n            model.fit(X, y)\n            \n    def predict(self, x):\n        results = np.zeros(len(x))\n        scores = [model.predict(x) for model in self.models_]\n        for i, model in enumerate(scores):\n            results += scores[i] * self.weights[i]\n        return results\n\n# model = Ensemble(models= [make_pipeline(MinMaxScaler(), ElasticNet(alpha=1e-3, l1_ratio=0.7)),\n#                          lgb.LGBMRegressor(n_estimators=100, random_state = 42)],\n#                  weights = [0.3,0.7])","ecf8e2fd":"train_copy = train.copy()\nfolds = KFold(n_splits=5, shuffle=True, random_state=123)\npreds = []\nactuals = []\nscores = []\ncol_noimp = []\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(train)):\n#     model.fit(train.loc[trn_idx, X], train.loc[trn_idx, y])\n#     perm = PermutationImportance(model, random_state=42).fit(train.loc[trn_idx, X], train.loc[trn_idx, y])\n#     col_noimp.append(X[perm.feature_importances_==0])\n    model.fit(train.loc[trn_idx, X], train.loc[trn_idx, y])\n    pred = model.predict(train.loc[val_idx, X])\n    scores.append(roc_auc_score(train.loc[val_idx, y], pred))\n    preds.append(pred)\n    actuals.append(train.loc[val_idx, y])  \n    train_copy.loc[val_idx, 'pred_scr'] = pred \n\nsns.lineplot(x= ['#1','#2','#3','#4','#5'], y= scores)\nprint(\"Validation Avg. Score: \", np.mean(scores))\nprint(scores)","91bacbcf":"sns.distplot(train_copy['pred_scr'])","304f555b":"pal = ['#50d890', '#007944','#888888','#f3c623','#EFEFEF', '#96bb7c', '#d9bf77','#3f3f44']\nplt.figure(figsize=(15,10))\nt = sorted(zip(X, perm.feature_importances_), key=lambda x:-x[1])[:40]\nsns.barplot(x=list(map(lambda x:x[0], t)), y= list(map(lambda x:x[1], t)), palette=pal)\nt = plt.xticks(rotation=45)","8da51638":"pal = ['#50d890', '#007944','#888888','#f3c623','#EFEFEF', '#96bb7c', '#d9bf77','#3f3f44']\nplt.figure(figsize=(15,10))\nt = sorted(zip(X, model.feature_importances_), key=lambda x:-x[1])[:40]\nsns.barplot(x=list(map(lambda x:x[0], t)), y= list(map(lambda x:x[1], t)), palette=pal)\nt = plt.xticks(rotation=45)","5e318104":"train_copy['pred'] = train_copy['pred_scr'].apply(lambda x: 2 if x>=1.45 else 1)\nf, ax = plt.subplots(1, 2, figsize=(16,7))\nfor i, col in enumerate(['voted', 'pred']):\n    sns.countplot(train_copy[col], ax=ax[i])","892c874f":"# Validation plotting of all rows\npal = ['#50d890', '#007944','#888888','#f3c623','#EFEFEF', '#96bb7c', '#d9bf77','#3f3f44']\ntrain_copy['pred'] = train_copy['pred'].apply(lambda x: 2 if x>=1.5 else 1)\nf, ax = plt.subplots(1, 3, figsize=(24,5))\nfor j, x in enumerate([good, bad, secret]):\n    var_x = list(map(lambda x: 'Q'+x+'A', x))\n    var_line = 'pred'\n    vars = sorted(train_copy[var_line].unique())\n    for i, var in enumerate(vars):\n        dat = train_copy[train_copy[var_line]==var]\n        dat = pd.DataFrame(dat[var_x].mean())\n        sns.pointplot(x=dat.index, y=0, data=dat, color=pal[i],alpha=0.8, ax=ax[j])\n    ax[j].set_ylim(0,5)\n    ax[j].legend(handles= ax[j].lines[::len(dat)+1], labels=vars)\n    ax[j].grid()\nplt.show()","4636bac4":"f, ax = plt.subplots(1, 3, figsize=(24,5))\n\nfor j, x in enumerate([good, bad, secret]):\n    var_x = list(map(lambda x: 'Q'+x+'E', x))\n    var_line = 'pred'\n    vars = sorted(train_copy[var_line].unique())\n    for i, var in enumerate(vars):\n        dat = train_copy[train_copy[var_line]==var]\n        dat = pd.DataFrame(dat[var_x].mean())\n        sns.pointplot(x=dat.index, y=0, data=dat, color=pal[i],alpha=0.8, ax=ax[j])\n    ax[j].set_ylim(0,8000)\n    ax[j].legend(handles= ax[j].lines[::len(dat)+1], labels=vars)\n    ax[j].grid()\nplt.show()","c4d23575":"f, ax = plt.subplots(2, 3, figsize=(24,10))\nfor i, col in enumerate(list(map(lambda x: 'Q'+x+'E', ['f','r','h','l']))):\n    sns.boxplot(x='pred', y=col, data=train_copy, ax=ax[i\/\/3][i%3], palette = pal, showmeans=True)\n    ax[i\/\/3][i%3].set_ylim(0,100000)","3bc3de2d":"var_x = ['age_group', 'education', 'engnat', 'familysize', 'gender', 'hand', 'married', 'race', 'religion', 'urban']\nf, ax = plt.subplots(4, 3, figsize=(24,20))\n\nfor i, x in enumerate(var_x):\n    sns.barplot(x=x, y='index', hue=\"pred\", data=train_copy,  estimator=len, ax=ax[i\/\/3][i%3], palette =pal)\n    if x=='religion':\n        t = ax[i\/\/3][i%3].set_xticklabels(train_copy[x].unique(), Rotation= 45) ","7334a5fa":"var_x = ['age_group', 'education', 'engnat', 'familysize', 'gender', 'hand', 'married', 'race', 'religion', 'urban']\nf, ax = plt.subplots(4, 3, figsize=(24,20))\n\nfor i, x in enumerate(var_x):\n    dat = pd.DataFrame(train_copy.groupby([x, 'pred'])['index'].count() \/ train_copy.groupby('pred')['index'].count()).reset_index()\n    sns.barplot(x=x, y= 'index', hue='pred', data=dat.reset_index(), palette=pal, ax=ax[i\/\/3][i%3])\n    if x=='religion':\n        t = ax[i\/\/3][i%3].set_xticklabels(train[x].unique(), Rotation= 45) ","c5f6e5da":"f, ax = plt.subplots(4, 3, figsize=(24,20))\nfor i, col in enumerate(list(map(lambda x: 'tp0'+str(x) if x <10 else 'tp'+str(x), list(range(1,11))))):\n    sns.boxplot(x='pred', y=col, data=train_copy, ax=ax[i\/\/3][i%3], palette = pal)","24a0fa2c":"var_x = list(map(lambda x: 'wr_0'+str(x) if x <10 else 'wr_'+str(x), list(range(1,14)))) + ['wf_01', 'wf_02', 'wf_03']\nf, ax = plt.subplots(4, 4, figsize=(24,20))\n\nfor i, x in enumerate(var_x):\n    dat = pd.DataFrame(train_copy.groupby([x, 'pred'])['index'].count() \/ train_copy.groupby('pred')['index'].count()).reset_index()\n    sns.barplot(x=x, y= 'index', hue='pred', data=dat.reset_index(), palette=pal, ax=ax[i\/\/4][i%4])","a433122b":"# Final submission\nX=train.columns[~pd.Series(train.columns).isin(col_del)]\n\n# for i in range(4):\n#     if i ==0:\n#         inter = set(col_noimp[0])\n#         continue\n#     inter = inter.intersection(col_noimp[i+1])\n# print(len(inter), inter)\n# X=X[~pd.Series(X).isin(inter)]\n\nmodel.fit(train[X], train[y])\npred = model.predict(test[X])\nsubmission['voted'] = pred\nsubmission.to_csv(\"submission.csv\", index=False)","686e44c7":"sns.distplot(pred)","24b8116b":"# \ubaa8\ub378\ub9c1","3af93b46":"# \uc804\ucc98\ub9ac"}}