{"cell_type":{"77eea455":"code","6b145107":"code","759dd4fe":"code","a3784f78":"code","b5d94fc1":"code","6ae690b3":"code","f1460d39":"code","16ddd9b2":"code","fa1f5218":"code","58b49fc5":"code","7dfd27f6":"code","e606bbc1":"code","28b9b81a":"code","02879938":"code","3ad7167c":"code","36ad4795":"code","a8e62265":"code","d5e98c6c":"code","5a3db580":"code","f4ca6a32":"code","fc2264fa":"code","275f2758":"code","a2fbb167":"code","bb8ef3c5":"code","852f313a":"code","09cd6e7b":"code","a630a361":"code","e1e92133":"code","3db4358e":"code","6077f82b":"code","a1e527ee":"code","67a2d10b":"code","916e7643":"code","1b71780c":"code","40fe2923":"code","42b190fa":"code","fa1f7ab0":"code","a35dd100":"code","551bde0a":"code","81a59980":"code","4bc03ac0":"code","e9367bf9":"code","a40f0439":"code","6803bfdf":"code","7a114bcd":"code","6e55a1b0":"code","d0032b22":"code","04948686":"code","69df9200":"code","e3be8d27":"code","a21c1df1":"code","308cdd89":"code","2048ac91":"code","3edb4aff":"code","ebc232d4":"code","ebbab729":"code","812a14b6":"code","85e64eba":"code","5006eabe":"code","b8f0bba2":"code","7bb93895":"code","ddd2dcc0":"code","d565cf28":"code","7f953ade":"code","8128269a":"code","8feb2bee":"code","d9fce29b":"code","677d9182":"code","f9e8cb71":"code","e2724ba2":"code","f0eeee74":"code","eaa8d239":"code","321981bd":"code","92c11250":"code","44735e4d":"code","a85e3cb9":"code","2a9a68e5":"code","169552ba":"code","18904738":"code","fc13ed83":"code","43c8971e":"code","b75fb902":"code","14dc61ff":"code","903f95b0":"code","0ed85d28":"code","27939363":"code","fb60b6e7":"code","778770f8":"code","eed98f62":"code","505019b8":"code","d4858268":"code","3788562f":"markdown","47394cb1":"markdown","b3f6671f":"markdown","20cc590b":"markdown","0421560e":"markdown","a1c49426":"markdown","d70794a5":"markdown","828321fc":"markdown","705abf33":"markdown","e6bcd61e":"markdown","485f1197":"markdown","c03c0c7d":"markdown","c7cd774c":"markdown","194f0e3b":"markdown","c25545cb":"markdown","16fe47d0":"markdown","25062ac9":"markdown","fe407fb7":"markdown","717f6e08":"markdown","8a166d67":"markdown","029b5b24":"markdown","8642e077":"markdown","fd2f2c05":"markdown","dc3c5724":"markdown","bf55801b":"markdown","9ecb0b78":"markdown","327b5977":"markdown","c2c4d009":"markdown","bd3ca34e":"markdown","31c7fbe2":"markdown","ddd14e48":"markdown","9052b503":"markdown","6e7a184e":"markdown","ded92610":"markdown","1e6f99eb":"markdown","f323942f":"markdown","f38d70f5":"markdown","e2c4871a":"markdown","49d69424":"markdown","1e90d6a3":"markdown","72209959":"markdown","4eae622d":"markdown","db9c4ce5":"markdown","761b3fad":"markdown","e8a2d3b9":"markdown","4416fe68":"markdown","277ac5a2":"markdown","14e87a93":"markdown"},"source":{"77eea455":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6b145107":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom scipy.stats import normaltest\nimport holoviews as hv\nfrom holoviews import opts\nfrom mpl_toolkits.mplot3d import Axes3D\nimport plotly.offline as py\nimport plotly.express as px\nimport cufflinks as cf\nhv.extension('bokeh')","759dd4fe":"from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_val_predict\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\nfrom sklearn.neighbors import KNeighborsRegressor \nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error","a3784f78":"#create class\nclass AirBnB_price_model:\n    \"\"\"  **AirBnB_price_model** is the class for exploratory data \n        analysis and machine learning. \n        This class have 10 attributes that are given important:\n\n    - multi_categorical_plot\n\n    - distplot_multi\n\n    - boxplot_multi\n\n    - correlation_plot\n\n    - VIF\n\n    - learner_selection\n\n    - training_evaluate\n    \"\"\"\n    \n    def __init__(self, data=None, cols=None, name='price'):\n        \n        self.name = name # target\n        self.data = data # feature\n        self.cols = cols # feature columns name\n        self.listof_model = {'LinearRegression': LinearRegression(), \n                'KNeighborsRegression':KNeighborsRegressor(),\n                'RandomForestRegression': RandomForestRegressor(),\n               'GradientBoostingRegression': GradientBoostingRegressor(),\n                'XGBoostRegression': XGBRegressor(),\n                'adaboost':AdaBoostRegressor()} # list of different learner\n    \n    #Read csv file\n    def read(self, file):\n        return pd.read_csv(file)\n    \n    def multi_categorical_plot(self, data):\n    \n        \"\"\" plot a categorical feature\n        \n            data: float64 array  n_observation x n_feature\n        \n        \"\"\"\n        # Find a feature that type is object\n        string = []\n        for i in data.columns:\n            if data[i].dtypes == \"object\":\n                string.append(i)\n    \n        fig = plt.figure(figsize=(20,20))\n        fig.subplots_adjust(wspace=0.2, hspace = 0.3)\n        for i in range(1,len(string)+1):\n            ax = fig.add_subplot(1,2,i)\n            sns.countplot(x=string[i-1], orient='v', data=data, ax=ax)\n            ax.set_title(f\" {string[i-1]} countplot\")\n            \n    def distplot_multi(self, data):\n        \"\"\" plot multi distplot\"\"\"\n    \n        \n        from scipy.stats import norm\n        cols = []\n        \n        #Feature that is int64 or float64 type \n        for i in data.columns:\n            if data[i].dtypes == \"float64\" or data[i].dtypes == 'int64':\n                cols.append(i)\n        \n        gp = plt.figure(figsize=(15,10))\n        gp.subplots_adjust(wspace=0.2, hspace=0.4)\n        for i in range(1, len(cols)+1):\n            ax = gp.add_subplot(3,4,i)\n            sns.distplot(data[cols[i-1]], fit=norm, kde=False)\n            ax.set_title('{} m.l. gaussian'.format(cols[i-1]))\n        \n    def boxplot_multi(self, data):\n        \n        \"\"\" plot multi box plot\n            hue for plotting categorical data\n        \"\"\"\n    \n        cols = []\n        for i in data.columns:\n            if data[i].dtypes == \"float64\" or data[i].dtypes == 'int64':\n                cols.append(i)\n    \n        gp = plt.figure(figsize=(20,15))\n        gp.subplots_adjust(wspace=0.2, hspace=0.4)\n        for i in range(1, len(cols)+1):\n            ax = gp.add_subplot(3,4,i)\n            sns.boxplot(x = cols[i-1], data=data)\n            ax.set_title('Boxplot for {}'.format(cols[i-1]))\n            \n    def correlation_plot(self, data, vrs= 'price'):\n    \n        \"\"\"\n        This function plot only a variable that are correlated with a target  \n        \n            data: array m_observation x n_feature\n            vrs:  target feature (n_observation, )\n            cols: interested features\n        \"\"\"\n        \n        cols = []\n        for i in data.columns:\n            if data[i].dtypes == \"float64\" or data[i].dtypes == 'int64':\n                cols.append(i)\n                \n        feat = list(set(cols) - set([vrs]))\n    \n        fig = plt.figure(figsize=(15,10))\n        fig.subplots_adjust(wspace = 0.3, hspace = 0.25)\n        for i in range(1,len(feat)+1):\n        \n            gp = data.groupby(feat[i-1]).agg('mean').reset_index()\n        \n            if len(feat) < 3:\n                ax = fig.add_subplot(1,3,i)\n            else:\n                #n = len(feat)\/\/2 + 1\n                ax = fig.add_subplot(3,4,i)\n            \n            ax.scatter(data[feat[i-1]], data[vrs], alpha=.25)\n            ax.plot(gp[feat[i-1]], gp[vrs], 'r-', label='mean',  linewidth=1.5)\n            ax.set_xlabel(feat[i-1])\n            ax.set_ylabel(vrs)\n            ax.set_title('Plotting data {0} vs {1}'.format(vrs, feat[i-1]))\n            ax.legend(loc='best')\n            \n    # Standardize data\n    def standardize(self, data):\n        data = (data - data.mean())\/data.std()\n        return data\n            \n            \n    def VIF(self, data):\n        \"\"\" \n        This function compute variance inflation factor for data that all feature are multicolinear\n        \n        if the outcome is 1, it is okay\n        if it is between 1 and 5, it shows low to average colinearity, and above 5 generally means highly \n        redundant and variable should be dropped\n        \"\"\" \n        # Apply the standardize method to each feature and save it to a new data\n        std_data = data.apply(self.standardize, axis=0)\n    \n        from statsmodels.stats.outliers_influence import variance_inflation_factor\n    \n        vif = pd.DataFrame()\n        vif['VIF_FACTOR'] = [variance_inflation_factor(std_data.values, i) for i in range(std_data.shape[1])]\n    \n        vif['feature'] = std_data.columns\n    \n        return vif\n    \n    \n    def split_data(self):\n        \"\"\"\n        This function splits data to train set and target set\n        \n        data: matrix feature n_observation x n_feature dimension\n        name: target  (n_observation, )\n        cols: interested feature\n        \n        return xtrain, xtest, ytrain, ytest\n        \"\"\"\n    \n        train = self.data[self.cols]\n        target = self.data[self.name]\n    \n        return train_test_split(train, target, random_state=42, test_size=0.2, shuffle=True)\n    \n    def spearman_pearson_correlation(self, data):\n        \n        \n        gp = plt.figure(dpi = 300, figsize=(20,10))\n        cols = ['pearson', 'spearman']\n        palette = sns.diverging_palette(20, 220, n=256)\n        gp.subplots_adjust(wspace=0.4, hspace=0.4)\n        for i in range(1, len(cols)+1):\n            ax = gp.add_subplot(1,2,i)\n            sns.heatmap(data.corr(method=cols[i-1]), annot=True, fmt=\".2f\", cmap=palette, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}).set(ylim=(11, 0))\n            ax.set_title('{} correlation'.format(cols[i-1]))\n        \n        \n        plt.show()\n    \n    \n    def learner_selection(self):\n\n        \"\"\"\n            This function compute differents score measure like cross validation,\n            r2, root mean squared error and mean absolute error.\n            listof_model: dictionary type containing different model algorithm.     \n        \"\"\" \n    \n        result = {}\n        \n        x, _, y, _ = self.split_data() # take only xtrain and ytrain\n    \n        for cm in list(self.listof_model.items()):\n        \n            name = cm[0]\n            model = cm[1]\n        \n            cvs = cross_val_score(model, x, y, cv=10).mean()\n            ypred = cross_val_predict(model, x, y, cv=10)\n            r2 = r2_score(y, ypred)\n            mse = mean_squared_error(y, ypred)\n            mae = mean_absolute_error(y, ypred)\n            rmse = np.sqrt(mse)\n        \n            result[name] = {'cross_val_score': cvs, 'rmse': rmse, 'mae': mae, 'r2': r2}\n        \n            print('{} model done !!!'.format(name))\n        \n        \n        return pd.DataFrame(result)\n    \n    \n    def training_evaluate(self, algorithm):\n        \n        \"\"\"This function train and evaluate our model to find r2, rmse and mae\"\"\"\n        \n        result = {}\n        xtrain, xtest, ytrain, ytest = self.split_data()\n        \n        learner = self.listof_model[algorithm] # learner selected in model_selection function\n        \n        model = learner.fit(xtrain, ytrain)\n        ypred = model.predict(xtest)\n        \n        r2 = learner.score(xtest, ytest)\n        rmse =  np.sqrt(mean_squared_error(ytest, ypred))\n        mae = mean_absolute_error(ytest, ypred)\n        \n        result['car price measure'] = {'r2':round(r2, 3),  'rmse':round(rmse, 3), 'mae':round(mae, 3)}\n        \n        return  pd.DataFrame(result)","b5d94fc1":"file = '\/kaggle\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv'","6ae690b3":"from IPython.display import Image\nImage('\/kaggle\/input\/new-york-city-airbnb-open-data\/New_York_City_.png', \n     width=600, height=1200)","f1460d39":"model = AirBnB_price_model()","16ddd9b2":"airbnb = model.read(file)","fa1f5218":"airbnb.head()","58b49fc5":"airbnb.info()","7dfd27f6":"airbnb.isnull().sum()[airbnb.isnull().sum()>0] # see missing value.","e606bbc1":"airbnb['name'] = airbnb['name'].fillna(value=' ')\nairbnb['host_name'] = airbnb['host_name'].fillna(value=' ')\nairbnb['last_review'] = airbnb['last_review'].fillna(method='ffill')\nairbnb['reviews_per_month'] = airbnb['reviews_per_month'].fillna(method='ffill')","28b9b81a":"airbnb.info()","02879938":"data = airbnb.drop(columns=['id', 'host_id'])","3ad7167c":"data['last_review'] = pd.to_datetime(data['last_review'])","36ad4795":"data.describe()","a8e62265":"model.distplot_multi(data)","d5e98c6c":"model.boxplot_multi(data)","5a3db580":"neigh = data['neighbourhood'].value_counts() #we take only neighbourhood for dis\nname = airbnb.name.value_counts()\nhost = airbnb.host_name.value_counts()","f4ca6a32":"neigh[neigh>100].plot(figsize=(15,5), kind='bar')\nplt.title('Most common neighbourhood Airbnb')\nplt.show()","fc2264fa":"host[host>100].plot(figsize=(15,5), kind='bar')\nplt.title('Most common host name Airbnb')\nplt.show()","275f2758":"name[name>5].plot(figsize=(15,5), kind='bar')\nplt.title('Most common name Airbnb')\nplt.show()","a2fbb167":"sns.countplot(data['neighbourhood_group'])\nplt.title('Ranking neighbourhood group Airbnb')\nplt.show()","bb8ef3c5":"sns.countplot(data['room_type'])\nplt.title('Ranking room type Airbnb')\nplt.show()","852f313a":"plt.figure(figsize=(10,5), dpi=100)\nplt.hist2d(x='longitude', y='latitude', data=data, bins=150, density=True)\nplt.title('2d histogramme for Airbnb in New York City')\nplt.xlabel('longitude')\nplt.ylabel('latitude')\nplt.show()","09cd6e7b":"data = data.set_index('last_review') ","a630a361":"data.price.resample('M').sum().plot(figsize=(15,5))\nplt.title('Total airbnb price in each year')\nplt.ylabel('TOTAL PRICE')","e1e92133":"plt.figure(figsize=(15,5))\nsns.violinplot(x='room_type', y='availability_365', data=data)\nplt.title('room type availability')\nplt.show()","3db4358e":"plt.figure(figsize=(15,5))\nsns.distplot(data[data.room_type == 'Private room']['availability_365'], color='blue', bins=10,\n             label='Private room')\nsns.distplot(data[data.room_type == 'Entire home\/apt']['availability_365'], color='red', bins=10,\n             label='Entire home\/apt')\nsns.distplot(data[data.room_type == 'Shared room']['availability_365'], color='green', bins=10,\n             label='Shared room')\nplt.ylabel('Frequence')\nplt.title('Room availability by type')\nplt.legend(loc='best')\nplt.show()","6077f82b":"plt.figure(figsize=(15,5))\nsns.violinplot(x='neighbourhood_group', y='availability_365', data=data)\nplt.title('neighbourhood_group availability')\nplt.show()","a1e527ee":"plt.figure(figsize=(20,5))\nsns.violinplot(x='neighbourhood', y='availability_365', data=data[data.neighbourhood.isin(list(neigh[neigh >=1200].index))])\nplt.title('most common neighbourhood availability')\nplt.show()","67a2d10b":"plt.figure(figsize=(20,5))\nsns.violinplot(x='host_name', y='availability_365', data=airbnb[airbnb.host_name.isin(list(host[host >=200].index))])\nplt.title('most common host name availability')\nplt.show()","916e7643":"plt.figure(figsize=(20,5))\nsns.violinplot(x='host_name', y='availability_365', data=airbnb[airbnb.host_name.isin(list(host[(host <200) & (host > 150)].index))])\nplt.title('most common host name availability')\nplt.show()","1b71780c":"plt.figure(figsize=(20,5))\nsns.violinplot(x='host_name', y='availability_365', data=airbnb[airbnb.host_name.isin(list(host[(host <150) & (host > 125)].index))])\nplt.title('most common host name availability')\nplt.show()","40fe2923":"plt.figure(figsize=(20,5))\nsns.violinplot(x='host_name', y='availability_365', data=airbnb[airbnb.host_name.isin(list(host[(host <125) & (host > 100)].index))])\nplt.title('most common host name availability')\nplt.show()","42b190fa":"plt.figure(figsize=(20,5))\nsns.violinplot(x='name', y='availability_365', data=airbnb[airbnb.name.isin(list(name[name>10].index))])\nplt.title('most common name availability')\nplt.show()","fa1f7ab0":"plt.figure(figsize=(20,5))\nsns.violinplot(x='name', y='availability_365', data=airbnb[airbnb.name.isin(list(name[(name<10) & (name >7)].index))])\nplt.title('most common name availability')\nplt.show()","a35dd100":"model.spearman_pearson_correlation(data)","551bde0a":"import geopandas as gpd\nimport mapclassify as mpc\nimport contextily as ctx","81a59980":"gpd.plotting.plot_linestring_collection","4bc03ac0":"geo_airbnb = gpd.GeoDataFrame(airbnb,  geometry=gpd.points_from_xy(airbnb.longitude, airbnb.latitude))","e9367bf9":"#Set the coordinate reference system (crs)to EPSG 4326\ngeo_airbnb.crs = 'epsg:4326'","a40f0439":"geo_airbnb = geo_airbnb.sort_values(by='last_review')","6803bfdf":"geo_airbnb.head()","7a114bcd":"#convert categorical data to integer\nfact1 = pd.factorize(geo_airbnb['neighbourhood_group'])\nfact2 = pd.factorize(geo_airbnb['room_type'])\ngeo_airbnb['neighbourhood_group'] = fact1[0]\ngeo_airbnb['room_type'] = fact2[0]\ndefinitions1 = fact1[1]\ndefinitions2 = fact2[1]","6e55a1b0":"nyc = gpd.read_file(gpd.datasets.get_path('nybb'))","d0032b22":"nyc = nyc.to_crs(epsg=4326)","04948686":"ax = nyc.plot(figsize=(20,15), color='whitesmoke', edgecolor='k', alpha=0.75)\ncolor=['Reds', 'Blues', 'Yellow', 'Green', 'Gray']\nregion = list(definitions1)\nfor a in [0, 1, 2, 3, 4]:\n    \n    lon = geo_airbnb[geo_airbnb.neighbourhood_group == a].longitude\n    lat = geo_airbnb[geo_airbnb.neighbourhood_group == a].latitude\n    \n    ax.scatter(lon, lat, cmap=color[a] , alpha=0.5, label = region[a])\n    ax.set_title('New York City Region\/Province Presentation')\n    ax.set_xlabel('lon')\n    ax.set_ylabel('lat')\n    ax.legend(loc='best')","69df9200":"date = geo_airbnb.last_review.unique()","e3be8d27":"\ndt = date[-1]\ndate_geoAirbnb = data.reset_index()[data.reset_index().last_review == dt]\nax1 = nyc.plot(figsize=(20,20), color='whitesmoke', edgecolor='k', alpha=0.2)\nax1.scatter(date_geoAirbnb.longitude, date_geoAirbnb.latitude, s= date_geoAirbnb.price, \n            c=date_geoAirbnb.availability_365, alpha=0.5, cmap='Reds', label='Last review:'+dt)\nax1.set_title('Price (color) and Availability(cercle) map', fontdict={'fontsize':18})\nax1.legend(loc='best')\nplt.show()","a21c1df1":"group_portfolio = data.pivot_table(values='price', columns='neighbourhood_group', index='last_review',\n                                     aggfunc='sum')\n#aggfunc = 'sum' aggregate price in same date","308cdd89":"group_portfolio.tail()","2048ac91":"group_portfolio.info()","3edb4aff":"group_portfolio.describe()","ebc232d4":"group_portfolio.resample('M').mean().plot(figsize=(15,5), logy=True) # resample data in month\nplt.ylabel('price')\nplt.title('Monthly price per year')\nplt.show()","ebbab729":"fig=plt.figure(figsize=(15,5))\nfig.subplots_adjust(wspace=0.2, hspace=0.2)\na1 = fig.add_subplot(1,2,1)\na2 = fig.add_subplot(1,2,2)\n\nsns.scatterplot(x='longitude', y='price', hue='neighbourhood_group', data=data, ax=a1)\nsns.scatterplot(x='latitude', y='price', hue='neighbourhood_group', data=data, ax=a2)\n\na1.set_title('price along a longitude')\na2.set_title('price along a latitude')\nplt.show()","812a14b6":"fd = plt.figure(figsize=(15,10))\nad = f3d = Axes3D(fd)\n\ndt = date[-1]\nAirbnb = data.reset_index()[data.reset_index().last_review == dt]\nad.scatter3D(Airbnb.longitude, Airbnb.latitude, Airbnb.price, cmap='viridis', label='Last review:'+dt)\nad.set_xlabel('longitude')\nad.set_ylabel('latitude')\nad.set_zlabel('price')\nad.set_title('See price in 3D')\nad.legend(loc='best')\nplt.show()","85e64eba":"plt.figure(figsize=(15,5))\nsns.scatterplot(x='availability_365', y='price', hue='neighbourhood_group', data=data)\nplt.title('price distributed along an availability_365')\nplt.text(300, 9000, '1. Some price have 0 availability \\n but others price have 365 avai-\\nlability.')\nplt.show()","5006eabe":"_price = data[data.price > 2000]","b8f0bba2":"ax3 =  nyc.plot(figsize=(20,15), color='whitesmoke', edgecolor='k', alpha=0.75)\nax3.scatter(_price.longitude, _price.latitude, c=_price.price\/15, s=_price.availability_365,\n            cmap='Reds', alpha=0.5)\nfor name in _price.host_name.unique():\n    annot = _price[_price.host_name == name]\n    \n    x = annot.longitude\n    y = annot.latitude\n    \n    if len(x) == 1 and len(y) == 1:\n        a = x\n        b = y\n    \n    plt.annotate(name, xy=(a, b), xycoords='data', xytext=(a, b), fontsize=16)\n    \nplt.text(-74.2, 40.8, 'Price > $2000')\nplt.title('host name containing high price > $2000.', fontsize=15)\nplt.show()","7bb93895":"busy = data[data.availability_365.isin([0,1])]\navai = data[data.availability_365 != 0]","ddd2dcc0":"ax4 =  nyc.plot(figsize=(20,15), color='whitesmoke', edgecolor='k', alpha=0.75)\nax4.scatter(avai.longitude, avai.latitude, s=avai.price\/35, color='green',  alpha=0.5, label = 'Available')\nax4.scatter(busy.longitude, busy.latitude, s=busy.price\/35, color='red',  alpha=0.5, label='Busy')\nax4.set_title('host name busy and availability airbnb', fontsize=15)\nax4.legend(loc='best')\nplt.show()","d565cf28":"room_portfolio_median = data.pivot_table(values='price', index='neighbourhood_group', columns='room_type', \n                                  aggfunc='median')\nroom_portfolio_mean = data.pivot_table(values='price', index='neighbourhood_group', columns='room_type', \n                                  aggfunc='mean')\nroom_portfolio_max = data.pivot_table(values='price', index='neighbourhood_group', columns='room_type', \n                                  aggfunc='max')\nroom_portfolio_min = data.pivot_table(values='price', index='neighbourhood_group', columns='room_type', \n                                  aggfunc='min')","7f953ade":"room_portfolio_mean.plot(figsize=(15,5), kind='bar', title='mean price', rot=0)\nplt.ylabel('price')\nplt.show()","8128269a":"room_portfolio_median.plot(figsize=(15,5), kind='bar', title='median price', rot=0)\nplt.ylabel('price')\nplt.show()","8feb2bee":"room_portfolio_max.plot(figsize=(15,5), kind='bar', title='max price', rot=0)\nplt.ylabel('price')\nplt.show()","d9fce29b":"room_portfolio_min.plot(figsize=(15,5), kind='bar', title='min price', rot=0)\nplt.ylabel('price')\nplt.show()","677d9182":"time_series = airbnb.drop(columns=['neighbourhood', 'name', 'host_name', 'id', 'host_id', 'geometry',\n                                  'neighbourhood_group', 'room_type'])","f9e8cb71":"time_series['last_review'] = pd.to_datetime(time_series['last_review'])","e2724ba2":"#we sort \ntime_series = time_series.sort_values(by='last_review')","f0eeee74":"time_series.head()","eaa8d239":"from statsmodels.graphics.tsaplots import plot_acf, plot_pacf","321981bd":"fg = plt.figure(figsize=(15, 5))\nfg.subplots_adjust(hspace=0.4, wspace=0.4)\naxis1 = fg.add_subplot(1, 2, 1)\naxis2 = fg.add_subplot(1, 2, 2)\n_ = plot_acf(time_series.availability_365, ax=axis1)\n_ = plot_pacf(time_series.availability_365, ax=axis2)","92c11250":"from statsmodels.tsa.stattools import grangercausalitytests\n\ndef grangers_causation_matrix(data, variables, verbose=False, test='ssr_chi2test',maxlag=5): \n    \n    \"\"\"\n    Check Granger Causality of all possible combinations of the Time series.\n    The rows are the response variable, columns are predictors. The values in the table \n    are the P-Values. P-Values lesser than the significance level (0.05), implies \n    the Null Hypothesis that the coefficients of the corresponding past values is \n    zero, that is, the X does not cause Y can be rejected.\n\n    data      : pandas dataframe containing the time series variables\n    \n    variables : list containing names of the time series variables.\n    \n    \"\"\"\n    \n    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n    for c in df.columns:\n        for r in df.index:\n            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n            min_p_value = np.min(p_values)\n            df.loc[r, c] = min_p_value\n    df.columns = [var + '_x' for var in variables]\n    df.index = [var + '_y' for var in variables]\n    return df","44735e4d":"time_series = time_series.set_index('last_review')","a85e3cb9":"grangers_causation_matrix(time_series, variables = list(time_series.columns))","2a9a68e5":"#checking stationarity\nfrom statsmodels.tsa.vector_ar.vecm import coint_johansen","169552ba":"coint_johansen(time_series, 1, 1).eig # if all absolute eigen values are less than 1 data are stationary","18904738":"time_series.index = pd.DatetimeIndex(time_series.index).to_period('M')","fc13ed83":"n_size = int(0.8*time_series.shape[0])\ntrain = time_series.iloc[:n_size, :]\nvalid = time_series.iloc[n_size:, :]\n\nprint('train shape: {}\\nvalid shape: {}'.format(train.shape, valid.shape))","43c8971e":"from statsmodels.tsa.vector_ar.var_model import VAR","b75fb902":"var_model = VAR(endog=train)","14dc61ff":"var_result = var_model.fit(maxlags=30, ic='aic', verbose=True)","903f95b0":"var_result.summary()","0ed85d28":"pred = var_result.forecast(train.values, len(valid))","27939363":"for i, col in enumerate(valid.columns):\n    print('{} mae score: {}'.format(col, (mean_absolute_error(pred[i-1], valid.values[i-1]))))","fb60b6e7":"_= var_result.plot_forecast(1000)","778770f8":"irf = var_result.irf()","eed98f62":"_=irf.plot(impulse='price', )","505019b8":"gate = VAR(endog=valid.iloc[:1000,:], freq='M')\nres = gate.fit(maxlags=30, ic='aic')","d4858268":"_=res.plot_forecast(30)","3788562f":"As we can see here,  different room type by name are busy.","47394cb1":"### Correlation","b3f6671f":"In the New York City, we see two area (Manhanttan and Brooklyn) have huge Airbnb activity. ","20cc590b":"private room and entire home\/apt are the room most taken by a people. But for Shared room, people does not like to take it. We see it well with histogram.","0421560e":"**Result interpretation**\n\nThe row are the Response (Y) and the columns are the predictor series (X). For example, if you take the value 0.0003 in (row 1, column 2), it refers to the p-value of **latitude_x** causing **neighbourhood_group_y**. Whereas, the 0.0714 in (row 2, column 1) refers to the p-value of **latitude_y** not causing **neighbourhood_group_x**.\n\nIf a given p-value is < significance level (0.05), then, the corresponding X series (column) causes the Y (row). See table above.","a1c49426":"Williansburg and Bedford-Stuyvesant are the neighbouurhood containning  more airbnb than others.","d70794a5":"### Availability for most common neighbourdhood","828321fc":"## Distribution","705abf33":"# Import python package","e6bcd61e":"**time running**","485f1197":"### Availability by room type","c03c0c7d":"**Stationarities using Cointegration Johanssen test**","c7cd774c":"### Forecasting","194f0e3b":"only availability_365 feature does not contain outlier.","c25545cb":"Manhattan and Brooklyn are the two neighbourhood_group containing high price for airbnb.","16fe47d0":"Any correlation between feature. Any feature are correlated with price. ","25062ac9":"### Availability for most common host_name","fe407fb7":"Michael and David are the host name who have more airbnb than others.","717f6e08":"Now, we see this well.","8a166d67":"# Predict NYC Airbnb Rental Prices.","029b5b24":"# 2D distribution","8642e077":"Interpretation soon...","fd2f2c05":"### compare price by host name","dc3c5724":"### Availability by neighbourhood_group","bf55801b":"private room and Entire home\/apt are the room type more represented in the data.","9ecb0b78":"### Impulse-Response function","327b5977":"## Compare prices by region by looking at Airbnb on a New York City map.","c2c4d009":"# Geospatial analysis\n\nIn this part, we are comparing price and availability for each last review.","bd3ca34e":"**Splitting data**","31c7fbe2":"# conclusion\n\nSoon ...","ddd14e48":"### Availability for most common name","9052b503":"Only Sonder (NYC) and Blueground  are available.   ","6e7a184e":"# Airbnb Machine learning \n\nIn this notebook, we are talking about:\n\n1. Import python package and load data.\n2. EDA and visualization.\n3. Geospatial analysis.\n\n    3.1. Compare prices by region by looking at Airbnb on a New York City map.\n    \n    3.2. Analyse whether there is a Difference price by room type.\n    \n4. Predict NYC Airbnb Rental Prices.\n5. Conclusion\n\nLet's go.","ded92610":"Brooklyn and Manhattan are neighbourhood where most people likes  to take an Airbnb.","1e6f99eb":"### Testing Causation using Granger\u2019s Causality Test\n\nThe basis behind Vector AutoRegression is that each of the time series in the system influences each other. That is, you can predict the series with past values of itself along with other series in the system.\n\nUsing Granger\u2019s Causality Test, it\u2019s possible to test this relationship before even building the model.\n","f323942f":"We take only price > 2000 to seing it in the map.","f38d70f5":"# Var Model\n\nWe use this model because any features are correlated. So, we have time series  ","e2c4871a":"Williamsburg, Crown Heights, East Village are very busy.","49d69424":"## Visualizing relation between feature and categorical data","1e90d6a3":"Brooklyn and Manhatttan are a neighbourhood_group where people likes to take airbnb. That's why, certain room availability are busy.","72209959":"**Evaluation**","4eae622d":"# EDA and visualization","db9c4ce5":"The trend of total price of airbnb in New York City.","761b3fad":"### See price in other way","e8a2d3b9":"\n## Analyzing difference price by room type.","4416fe68":"We see  Manhatan ","277ac5a2":"# load data","14e87a93":"### Create class"}}