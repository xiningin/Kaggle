{"cell_type":{"f1923dcb":"code","f0e499bc":"code","e00ad666":"code","e741038b":"code","008e4042":"code","b011d39a":"code","255889b2":"code","05e3a1f4":"code","45fb2dd6":"code","a37dc286":"code","e7b2ffbb":"code","8bbc4510":"code","e6963665":"code","b1895f4f":"code","5757324e":"code","cd447310":"code","0f9a9323":"code","a6c27a67":"code","4a152719":"code","a1d11f2f":"code","c3359357":"code","8c405742":"code","fd035431":"code","3afdd065":"code","76fdb835":"code","7f9831e1":"code","3e1b18b3":"code","135eb97a":"code","f33adc5d":"code","b8eb6385":"code","27b5a3be":"code","53982075":"code","597b7b36":"code","7115ce0e":"code","d9136cfd":"code","6e1099cc":"code","1784320a":"code","76de7f75":"code","4f557c9f":"code","eef9fec3":"code","27a8fe95":"code","e16c3102":"code","bd77d551":"code","f2ab4d78":"code","c735044c":"code","c9e78ed1":"code","48156286":"markdown","d6a4b068":"markdown","5e2ea17e":"markdown","17563a03":"markdown","318c3e3b":"markdown","1217d503":"markdown","7d5b471c":"markdown","9ebb8e65":"markdown","5de07ccc":"markdown","833760ea":"markdown","c6404c48":"markdown","c1c45999":"markdown","c7ef20d4":"markdown","7265bc15":"markdown","f9546fd6":"markdown"},"source":{"f1923dcb":"import numpy as np # linear algebra\nimport pandas as pd # data processing CSV file \nimport os","f0e499bc":"categories=['dandelion', 'daisy', 'sunflower', 'tulip', 'rose'] ","e00ad666":"dire='\/kaggle\/input\/flowers-recognition\/flowers'","e741038b":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfeatures=[]\nfor i in categories:\n    path=os.path.join(dire,i)\n    num_classes=categories.index(i)\n    for img in os.listdir(path):\n        if img.endswith('.jpg'):\n            \n            img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_COLOR)\n            img_array=cv2.resize(img_array,(150,150))\n            features.append([img_array,num_classes])","008e4042":"X=[]\ny=[]\nfor i,j in features:\n    X.append(i)\n    y.append(j)","b011d39a":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        l=np.random.randint(0,len(y))\n        ax[i,j].imshow(X[l])\n        ax[i,j].set_title('Flower: '+categories[y[l]])\nplt.axis('off')        \nplt.tight_layout()","255889b2":"X=np.array(X).reshape(-1,150,150,3)\/255.0\n","05e3a1f4":"sns.set_style('whitegrid')\nplt.figure(figsize=(14,7))\nfig=sns.countplot(y)\nfig.set(xticks=range(len(categories)), xticklabels=[i for i in categories])\nplt.xlabel('FLOWER SPECIES')\nplt.show()\n","45fb2dd6":"list_dandelion=len([i for i in y if i==0])\nlist_daisy=len([i for i in y if i==1])\nlist_sunflower=len([i for i in y if i==2])\nlist_tulip=len([ i for i in y if i==3])\nlist_rose=len([i for i in y if i==4])","a37dc286":"list_species=[list_dandelion,list_daisy,list_sunflower,list_tulip,list_rose]\n","e7b2ffbb":"sns.set_style('whitegrid')\nplt.figure(figsize=(18,10))\nplt.pie(list_species,labels=categories,startangle=90,colors=['r','g','b','y','m'],autopct='%1.1f%%',explode = (0, 0.1, 0, 0,0),shadow=True)\nplt.legend()\nplt.show()","8bbc4510":"from tensorflow.keras.utils import to_categorical\ny=to_categorical(y)\n","e6963665":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=12)","b1895f4f":"from keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.utils import to_categorical\n\n# specifically for cnn\nfrom keras.layers import Dropout, Flatten,Activation\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n \nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\n","5757324e":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), input_shape=(150,150,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2, padding=\"same\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2, padding=\"same\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(2, 2, padding=\"same\"))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5, activation=\"softmax\"))\n","cd447310":"epochs=10\n\nfrom keras.callbacks import ReduceLROnPlateau\nred_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)\n","0f9a9323":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","a6c27a67":"model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])","4a152719":"model.summary()","a1d11f2f":"History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=128),\n                              epochs = epochs, validation_data = (x_test,y_test),\n                              verbose = 1, steps_per_epoch=x_train.shape[0] \/\/ 128)\n# model training","c3359357":"sns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()\n","8c405742":"sns.set_style('whitegrid')\nplt.figure(figsize=(12,5))\nplt.plot(History.history['accuracy'])\nplt.plot(History.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","fd035431":"preds=model.predict(x_test)","3afdd065":"predictions=np.argmax(preds,axis=1)","76fdb835":"correct_class=[]\nincorrect_class=[]\ni=0\nfor i in range(len(y_test)):\n    if(np.argmax(y_test[i])==predictions[i]):\n        correct_class.append(i)\n    if(len(correct_class)==8):\n        break\n    \n","7f9831e1":"i=0\nfor i in range(len(y_test)):\n    \n    if (np.argmax(y_test[i])!=predictions[i]):\n        \n        incorrect_class.append(i)\n    if (len(incorrect_class)==8):\n        break\n        \n        ","3e1b18b3":"count=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range (4):\n    for j in range (2):\n        ax[i,j].imshow(x_test[correct_class[count]])\n        ax[i,j].set_title(\"Predicted Flower : \"+ categories[predictions[correct_class[count]]] +\"\\n\"+\"Actual Flower : \"+ categories[np.argmax(y_test[correct_class[count]])])\n        plt.tight_layout()\n        count+=1","135eb97a":"count=0\nfig,ax=plt.subplots(4,2)\nfig.set_size_inches(15,15)\nfor i in range(4):\n    for j in range(2):\n        ax[i,j].imshow(x_test[incorrect_class[count]])\n        ax[i,j].set_title(\"Predicted flower : \" + categories[predictions[incorrect_class[count]]] + \"\\n\"+\"Actual Flower : \" +categories[np.argmax(y_test[incorrect_class[count]])])\n        plt.tight_layout()\n        count+=1","f33adc5d":"#The image we want to predict is also needed to be preprocessed according to the requirements of the model.\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\n\ndef process_image(url):\n    response=requests.get(url)\n    img=Image.open(BytesIO(response.content))\n    fix,ax=plt.subplots(1,3,figsize=(15,20))\n    ax[0].imshow(img)\n    ax[0].set_title('image')\n    \n    #grayscale and normalization\n    img=np.array(img)\n    img=cv2.cvtColor(img,cv2.IMREAD_COLOR)\n    print(img.shape)\n    img=img\/255.0\n    ax[1].imshow(img)\n    ax[1].set_title('color image')\n    \n    #resizing\n    img=cv2.resize(img,(150,150))\n    print(img.shape)\n    ax[2].imshow(img)\n    ax[2].set_title('predicted image')\n    plt.tight_layout()\n    img=np.expand_dims(img,axis=0)\n    \n    \n    print(img.shape)\n    return img\n\n\n    ","b8eb6385":"def predict(url):\n    img=process_image(url)\n    label=model.predict(img)\n    final_1=np.argmax(label,axis=1)[0]\n    plt.xlabel(categories[final_1])\n    return categories[final_1]","27b5a3be":"predict(\"https:\/\/media4.picsearch.com\/is?LwsQDsAhRnF2IV-PP61f1fCUcQWD2jYoz6X55V_6-dg&height=266\") ","53982075":"predict(\"https:\/\/media5.picsearch.com\/is?8agnR1fAz2qzGkGmQsnFEb0nXkmuh-7hb-Il2rLLd7U&height=341\")","597b7b36":"predict(\"https:\/\/www.gardendesign.com\/pictures\/images\/675x529Max\/site_3\/helianthus-yellow-flower-pixabay_11863.jpg\")","7115ce0e":"predict(\"https:\/\/i.etsystatic.com\/22658127\/r\/il\/898a9f\/2529892017\/il_794xN.2529892017_25c5.jpg\")","d9136cfd":"predict(\"https:\/\/www.gardeningknowhow.com\/wp-content\/uploads\/2019\/11\/red-rose-400x265.jpg\")","6e1099cc":"predict(\"https:\/\/www.gardeningknowhow.com\/wp-content\/uploads\/2021\/05\/shasta-daisy.jpg\")","1784320a":"predict(\"https:\/\/cf.shopee.com.my\/file\/b20609824dba9d9fd5059ac7c739c8e5\")","76de7f75":"predict(\"https:\/\/external-content.duckduckgo.com\/iu\/?u=https%3A%2F%2Fwww.aspirus.org%2Fuploads%2Fpublic%2Fimages%2Fdesign%2Fsunflower-award.png&f=1&nofb=1\")","4f557c9f":"predict(\"https:\/\/i.guim.co.uk\/img\/media\/aa36897836981a77792b1a628219ccd8ac9bdabb\/0_552_3367_2020\/master\/3367.jpg?width=1200&height=1200&quality=85&auto=format&fit=crop&s=5436f660db1b6bee3fec5b7c5fedf53a\")","eef9fec3":"predict(\"https:\/\/d3mvlb3hz2g78.cloudfront.net\/wp-content\/uploads\/2015\/08\/thumb_720_450_f_12.jpg\")","27a8fe95":"predict(\"https:\/\/idsb.tmgrup.com.tr\/ly\/uploads\/images\/2021\/02\/12\/92946.jpg\")","e16c3102":"predict(\"https:\/\/imagesvc.meredithcorp.io\/v3\/mm\/image?url=https%3A%2F%2Fstatic.onecms.io%2Fwp-content%2Fuploads%2Fsites%2F37%2F2020%2F04%2F15%2Fblooming-light-pink-roses.jpg\")","bd77d551":"predict(\"https:\/\/ct.counseling.org\/wp-content\/uploads\/2016\/06\/Dandelion-e1560266284412.jpg\")","f2ab4d78":"predict(\"https:\/\/www.gardeningknowhow.com\/wp-content\/uploads\/2008\/07\/tulips.jpg\")","c735044c":"predict(\"https:\/\/s3.amazonaws.com\/finegardening.s3.tauntoncloud.com\/app\/uploads\/2018\/01\/23223745\/bellisperennis_mb_2_lg_0-main-500x500.jpg\")","c9e78ed1":"predict(\"https:\/\/thumbs.dreamstime.com\/b\/single-white-daisy-out-focus-background-54393375.jpg\")","48156286":"# Classify flowers by category","d6a4b068":"# Split the data in Random","5e2ea17e":"> # preprocess categorical values","17563a03":"#  Distribute class lables","318c3e3b":"> # Data Augmentation:It is the technique used to overome the problem of overfitting and make our model to generalize well on the unseen data.","1217d503":"# Load and Predict Image from Internet","7d5b471c":"# Model building","9ebb8e65":"# Reshape and normalize: resizing the feature vector x to meet the keras requirement and normalize to scale all the values in a similar range","5de07ccc":"# Analysing the predicitons","833760ea":"# Model Prediction Test ","c6404c48":"# visualizations","c1c45999":"# Preprocessing: separate the features and lables from the data","c7ef20d4":"# Load Data and Preprocessing","7265bc15":"# Initialize working directory","f9546fd6":"# Visualize model function"}}