{"cell_type":{"4204e794":"code","91c4b1e0":"code","0ce0aea9":"code","4da6fd88":"code","ecc02e0d":"code","147c6b8a":"code","70ab4770":"code","56c26f05":"code","af232ab7":"code","6427c69a":"code","3fe6589b":"code","fd3df9a5":"code","8c3ac7bc":"code","21978ba6":"code","721258a0":"code","8f07828a":"code","7ae6db09":"code","a42d8503":"code","39a079cf":"code","24136528":"code","475c9a42":"code","8265ddec":"code","370e2f66":"code","ae8dce0a":"code","09212fe2":"code","4eebb58d":"code","ecdba930":"code","8430e518":"code","1503ed89":"code","e5c53cd5":"code","d2cb6e84":"code","18f304f2":"code","b6177610":"code","5eb552bc":"code","844601be":"code","0e2c23cb":"code","8c423b62":"code","a4eed326":"code","0615474f":"code","04a18da2":"code","9507f909":"code","fe866226":"code","1eef9e69":"code","f35f54cc":"code","dd91aff4":"code","e133954d":"code","676cbb99":"code","9b97095a":"code","6acc8a87":"code","8a692bed":"code","81c10714":"code","8d1d8cec":"code","d561495c":"markdown","3f97895b":"markdown","c2a64328":"markdown","27cc3a30":"markdown","74a9cc83":"markdown","62b82f12":"markdown","85511e26":"markdown","b3246b76":"markdown","398901e6":"markdown","0b54fcb8":"markdown","4bbf6426":"markdown","0e481188":"markdown","fa16b4c9":"markdown","92695721":"markdown","0035cb8d":"markdown","0fe8d69b":"markdown"},"source":{"4204e794":"#import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","91c4b1e0":"%%capture\n!pip install trelawney","0ce0aea9":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain.head()","4da6fd88":"train = train.drop([\"Name\", \"Ticket\", \"Fare\"],axis=1)\ntest = test.drop([\"Name\", \"Ticket\", \"Fare\"],axis=1)","ecc02e0d":"train.head()","147c6b8a":"train.isna().sum()","70ab4770":"#fill the missing cabin values with mode\ntrain[\"Cabin\"] = train[\"Cabin\"].fillna(str(train[\"Cabin\"].mode().values[0]))\ntest[\"Cabin\"] = test[\"Cabin\"].fillna(str(test[\"Cabin\"].mode().values[0]))","56c26f05":"train[\"Cabin\"] = train[\"Cabin\"].apply(lambda x:str(x).replace(' ','')if ' ' in str(x) else str(x))\ntest[\"Cabin\"] = test[\"Cabin\"].apply(lambda x:str(x).replace(' ','')if ' ' in str(x) else str(x))","af232ab7":"train[\"Deck\"] = train[\"Cabin\"].str.slice(0,1)\ntest[\"Deck\"] = test[\"Cabin\"].str.slice(0,1)","6427c69a":"train = train.drop([\"Cabin\"],axis=1)\ntest = test.drop([\"Cabin\"],axis=1)","3fe6589b":"def impute_median(series):\n    return series.fillna(series.median())","fd3df9a5":"train.Age = train.Age.transform(impute_median)\ntest.Age = test.Age.transform(impute_median)","8c3ac7bc":"train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\ntest[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","21978ba6":"train.isnull().sum()","721258a0":"test.isnull().sum()","8f07828a":"train['Is_Married'] = np.where(train['SibSp']==1, 1, 0)\ntest['Is_Married'] = np.where(test['SibSp']==1, 1, 0)\n\ntrain.head()","7ae6db09":"train[\"Family_Size\"] = train.SibSp + train.Parch\ntest[\"Family_Size\"] = test.SibSp + test.Parch\n\ntrain.head()","a42d8503":"train['Elderly'] = np.where(train['Age']>=50, 1, 0)\ntrain.head()","39a079cf":"#Split the data set into independent(x) and dependent (y) data sets\n\ny = train[\"Survived\"].values.reshape(-1, 1)\nx = train.iloc[:, 2:12]\nx_test  = test.drop(\"PassengerId\",axis=1).copy()","24136528":"x.dtypes","475c9a42":"x_test.dtypes","8265ddec":"from collections import Counter","370e2f66":"##### encode the categorical data values\nfrom sklearn.preprocessing import LabelEncoder\n\n\nlabelEncoder_Y = LabelEncoder()\nx.iloc[:,1] = labelEncoder_Y.fit_transform(x.iloc[:, 1].values)\nx_test.iloc[:,1] = labelEncoder_Y.transform(x_test.iloc[:, 1].values)\n\nx.iloc[:,5] = labelEncoder_Y.fit_transform(x.iloc[:, 5].values)\nx_test.iloc[:,5] = labelEncoder_Y.transform(x_test.iloc[:, 5].values)\n\nx.iloc[:,6] = labelEncoder_Y.fit_transform(x.iloc[:, 6].values)\nx_test.iloc[:,6] = labelEncoder_Y.transform(x_test.iloc[:, 6].values)","ae8dce0a":"x.dtypes","09212fe2":"x_test.dtypes","4eebb58d":"#split the data set\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x, y , test_size=0.25, random_state=42)","ecdba930":"#scale the data(feature scaling)\nfrom sklearn.preprocessing import StandardScaler\n\nsc = StandardScaler()\nx_train = pd.DataFrame(sc.fit_transform(x_train), columns=x_train.columns, index=x_train.index)\nx_val = pd.DataFrame(sc.fit_transform(x_val), columns=x_val.columns, index=x_val.index)\ny_train = pd.DataFrame(y_train, index=x_train.index)\ny_val = pd.DataFrame(y_val, index=x_val.index)","8430e518":"x_train.shape, x_val.shape, y_train.shape, y_val.shape","1503ed89":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics","e5c53cd5":"model = RandomForestClassifier(min_samples_leaf=3, max_depth=5, n_estimators=100)","d2cb6e84":"model.fit(x_train, y_train)\nprint(metrics.classification_report(y_val, model.predict(x_val)))","18f304f2":"from trelawney.shap_explainer import ShapExplainer\n\nexplainer = ShapExplainer()\nexplainer.fit(model, x_train, y_train)","b6177610":"feature_importance_graph = explainer.graph_feature_importance(x_val)\nfeature_importance_graph.update_layout(title='Shap Feature Importance')\nfeature_importance_graph.show()","5eb552bc":"from trelawney.surrogate_explainer import SurrogateExplainer\nfrom sklearn.tree import DecisionTreeClassifier\n\nexplainer = SurrogateExplainer(DecisionTreeClassifier(max_depth=4))\nexplainer.fit(model, x_train, y_train)","844601be":"from IPython.display import Image\nexplainer.plot_tree(out_path='.\/tree_viz')\nImage('.\/tree_viz.png', width=1000, height=500)","0e2c23cb":"explainer.adequation_score()","8c423b62":"from sklearn import metrics","a4eed326":"explainer.adequation_score(metric=metrics.roc_auc_score)","0615474f":"y_pred = pd.DataFrame(model.predict_proba(x_val)[:, 1], index=x_val.index)","04a18da2":"most_probable = y_pred.idxmax()\nbiggest_false_positive = (y_pred - y_val).idxmax()\nbiggest_false_negative = (y_pred - y_val).idxmin()","9507f909":"from trelawney.lime_explainer import LimeExplainer","fe866226":"explainer = LimeExplainer()\nexplainer.fit(model, x_train, y_train)","1eef9e69":"x_val.loc[most_probable, :]","f35f54cc":"lime_explanation_graph = explainer.graph_local_explanation(x_val.loc[most_probable, :])\nlime_explanation_graph.update_layout(title='Lime individual prediction interpretation')\nlime_explanation_graph.show()","dd91aff4":"x.loc[biggest_false_positive, :]","e133954d":"lime_explanation_graph = explainer.graph_local_explanation(x_val.loc[biggest_false_positive, :])\nlime_explanation_graph.update_layout(title='Lime individual prediction interpretation')\nlime_explanation_graph.show()","676cbb99":"x.loc[biggest_false_negative, :]","9b97095a":"lime_explanation_graph = explainer.graph_local_explanation(x_val.loc[biggest_false_negative, :])\nlime_explanation_graph.update_layout(title='Lime individual prediction interpretation')\nlime_explanation_graph.show()","6acc8a87":"from trelawney.shap_explainer import ShapExplainer\n\nexplainer = ShapExplainer()\nexplainer.fit(model, x_train, y_train)","8a692bed":"shap_explanation_graph = explainer.graph_local_explanation(x_val.loc[most_probable, :])\nshap_explanation_graph.update_layout(title='SHAP individual prediction interpretation')\nshap_explanation_graph.show()","81c10714":"shap_explanation_graph = explainer.graph_local_explanation(x_val.loc[biggest_false_positive, :])\nshap_explanation_graph.update_layout(title='SHAP individual prediction interpretation')\nshap_explanation_graph.show()","8d1d8cec":"shap_explanation_graph = explainer.graph_local_explanation(x_val.loc[biggest_false_negative, :])\nshap_explanation_graph.update_layout(title='SHAP individual prediction interpretation')\nshap_explanation_graph.show()","d561495c":"Feature importance of the model, according to SHAP","3f97895b":"## 1.3 Modeling with Random Forest","c2a64328":"## 2.2 Local explanations\n\nThe second type of explanations you can do are local explanations. Here we will try to understand specific predictions for a given observation of our model (rather than understanding the model as a whole)\n\nFor this we have two explainers available to us again:\n\n- LIME, this uses the LIME package that creates local explainable models that approximate a model around a specifc prediction to understand how the model came to that prediction\n- SHAP, we can use the SHAP method again but instead of aggregating the SHAP values on a dataset, we use the values for the prediction that interest us","27cc3a30":"# Introduction and imports\nWelcome to the notebook introducing Trelawney, a unified Python API for interpretation of Machine Learning Model. For more information about this package, you can find a Medium article about it here (https:\/\/medium.com\/@antoine.redier2\/introducing-trelawney-a-unified-python-api-for-interpretation-of-machine-learning-models-6fbc0a1fd6e7)\n\n\nThe point of this kernel is not to achieve the best performance but to demonstate how to explain your model's prediction with the Trelawney package, with both overall importance of feature and local explanation of a single prediction.\n\nIn the first section of this notebook, we built the model to predict the survival of a given passenger on the Titanic. In the second section, we show you how to use the Trelawney package, both for global and local interpretation","74a9cc83":"## 1.1 Feature engineering ","62b82f12":"## 1.2 Data Preprocessing","85511e26":"### 2.1.2 Surogate explainer","b3246b76":"## 2.2.1 lime","398901e6":"# 2. Model interpretation (Trelawney explanations start here)\n\n## 2.1 Global explanation\n\nThe first kind of analysis we can do to interpret our model is to provide a global explanation of it, namely which features are more influential for the model overall. Trelawney provides two types of global explainers:\n\n- Shap which will use the Shap package to check which features influence each prediction and aggregate them\n- Surrogate explainer : This technique uses an interpretable model (Single Tree for us) to mimic the outputs of our black box model\n\n### 2.1.1 SHAP","0b54fcb8":"the next three graph are the contribution of each feature to the same three predictions using the SHAP explainer:","4bbf6426":"This first section creates a model to predict whether a certain passenger will survive or not.","0e481188":"here we can see that the surogate tree (that you can see in the graph) erxplains ~95% of predictions.\nBy default the `adequation_score` metric uses accuracy but you can choose which ever suits you best:","fa16b4c9":"the next three graph are the contribution of each feature to specific predictions using the LIME explainer:","92695721":"**surogate decision tree**","0035cb8d":"## 2.2.2 SHAP","0fe8d69b":"# 1. Modelling "}}