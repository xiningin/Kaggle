{"cell_type":{"3f3830f0":"code","2d0eaa69":"code","432681c2":"code","c460362b":"code","1e0a992e":"code","63932f0e":"code","de6738a4":"code","efbcf21d":"code","068fc20d":"code","d2371a1b":"code","27473268":"code","5225bed1":"code","9404e8dc":"code","7ce0b58b":"code","e8abc4a5":"code","c96413b6":"code","06abaa2c":"code","992f9671":"code","353edb13":"code","6563b21f":"code","8af38c0c":"code","ecb8b326":"code","dc41b0c7":"code","a8f3feea":"code","93907e92":"code","77596295":"code","6cee09fd":"code","fd8bdf93":"code","b7c48e5a":"markdown","c11fcb77":"markdown","8e4ab309":"markdown","dc315812":"markdown","0fefbb56":"markdown","ec864c92":"markdown","15f31408":"markdown"},"source":{"3f3830f0":"import pandas as pd\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv').set_index('PassengerId')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv').set_index('PassengerId')\nsubmission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')\n\ntitanic = pd.concat([train,test], axis=0, sort=False) #Concat on the row axis\ndisplay(titanic.describe(include='all'))\ntitanic.isnull().sum()","2d0eaa69":"titanic['Cabin_Missing'] = titanic.Cabin.isnull()*1.0\ntitanic.drop(['Cabin'], axis=1, inplace=True)","432681c2":"titanic['Title'] = titanic.Name.str.split(',').str[1].str.split('.').str[0].str.strip()\ntitanic['LastName'] = titanic.Name.str.split(',').str[0]\ntitanic.drop(['Name'], axis=1 ,inplace=True)\ntitanic.LastName, _ = pd.factorize(titanic['LastName'])","c460362b":"alone_child = titanic.query('Age < 12 & Parch == 0').index\nfor i in alone_child:\n    titanic.at[i,'Parch'] += 1 #add nanny","1e0a992e":"def get_ticket_type(ticket):\n  ticket_list = ticket.split(' ')\n  if len(ticket_list) == 2:\n    return ticket_list[0]\n  else:\n    ticket_list = ticket.split('.')\n    return 'Normal'\n\ndef get_ticket_number(ticket):\n  ticket_list = ticket.split(' ')\n  if len(ticket_list) == 2:\n    return ticket_list[1]\n  else:\n    return ticket\n\ntitanic['Ticket_Type'] = titanic['Ticket'].apply(lambda x: get_ticket_type(x))\ntitanic['Ticket_Number'] = titanic['Ticket'].apply(lambda x: get_ticket_number(x))\nmissing_index = titanic[pd.to_numeric(titanic['Ticket_Number'], errors='coerce').isnull()].index\nmissing_index = missing_index.to_list()\ndf_ticket_type_correction = ['STON\/O2.','STON\/O2.','LINE','STON\/O2.','LINE','LINE','STON\/O2.','STON\/O2.','STON\/O2.','STON\/O2.','SC\/AH Basle','STON\/O2.','STON\/O2.','LINE','STON\/O2.',\n                             'STON\/O2.', 'STON\/O2.', 'STON\/O2.', 'STON\/O2.', 'A.\/2.']\ndf_ticket_number_correction = [3101294,2101280,0,3101275,0,0,3101293,3101289,3101269,3101274,541,3101286,3101273,0,3101292,3101285,3101288,3101291,3101268,39186]\nfor i in range(20):\n  titanic.at[missing_index[i], 'Ticket_Type'] = df_ticket_type_correction[i]\n  titanic.at[missing_index[i], 'Ticket_Number'] = df_ticket_number_correction[i]\ntitanic['Ticket_Number'] = pd.to_numeric(titanic['Ticket_Number'])\ntitanic['Ticket_Type'] = titanic['Ticket_Type'].apply(lambda x: x.replace('.','').upper())\ntitanic.drop(['Ticket'], axis=1, inplace=True)\ntitanic.drop(['Ticket_Type'], axis=1, inplace=True)\ntitanic.Ticket_Number, _ = pd.factorize(titanic['Ticket_Number'])","63932f0e":"titanic.isnull().sum()","de6738a4":"print(titanic.Embarked.value_counts())\ntitanic.Embarked = titanic.Embarked.fillna('S')","efbcf21d":"age_mean_dict = titanic.groupby(['Pclass','Title','Embarked'])['Age'].mean().to_dict()\nage_mean_dict[(3,'Ms','Q')] = titanic.groupby(['Title'])['Age'].mean().to_dict()['Ms']\nprint(age_mean_dict)\nmissing_age_index = titanic[titanic.Age.isnull()].index\nfor i in missing_age_index:\n    titanic.at[i,'Age'] = age_mean_dict[(titanic.at[i,'Pclass'], titanic.at[i,'Title'], titanic.at[i,'Embarked'])]","068fc20d":"missing_fare_index = titanic[titanic.Fare.isnull()].index\ntitanic.at[missing_fare_index, 'Fare'] = titanic.groupby(['Pclass','Embarked','Title'])['Age'].mean()[(3,'S','Mr')]","d2371a1b":"titanic['WomanOrChild'] = ((titanic.Title == 'Master') | (titanic.Sex == 'female'))","27473268":"titanic.Pclass = titanic.Pclass.apply(lambda x: ['Dummy','Rich','Middle','Poor'][x])\ntitanic['Family_Size'] = titanic['SibSp']+titanic['Parch']","5225bed1":"titanic.loc[titanic.Survived.isnull(),'Survived'] = titanic.loc[titanic.Survived.isnull(),'WomanOrChild'] * 1.0\nfamily = titanic.groupby(['LastName']).Survived\nfriends = titanic.groupby(['Ticket_Number']).Survived","9404e8dc":"titanic['WomanOrBoyCount'] = family.transform(lambda s: s[titanic.WomanOrChild].fillna(0).count())\ntitanic['WomanOrBoyCount'] = titanic.mask(titanic.WomanOrChild, titanic.WomanOrBoyCount - 1, axis=0)","7ce0b58b":"titanic['WomanOrBoyCount2'] = friends.transform(lambda s: s[titanic.WomanOrChild].fillna(0).count())\ntitanic['WomanOrBoyCount2'] = titanic.mask(titanic.WomanOrChild, titanic.WomanOrBoyCount2 - 1, axis=0)\ntitanic.WomanOrChild = titanic.WomanOrChild * 1.0","e8abc4a5":"titanic['Alone'] = (titanic.Family_Size == 0) * 1.0","c96413b6":"titanic.head()","06abaa2c":"titanic_onehot = pd.get_dummies(titanic, columns=['Pclass','Sex','Title','Embarked'])","992f9671":"train_cols = [col.replace('(','_').replace(']','_').replace('<','_') for col in titanic_onehot.columns]\ntitanic_onehot.columns = train_cols","353edb13":"train_onehot = titanic_onehot.loc[train.index]\ntest_onehot = titanic_onehot.loc[test.index]\nassert train_onehot['Survived'].isnull().sum() == 0\ntest_onehot.drop(['Survived'], axis=1, inplace=True)","6563b21f":"!pip install rfpimp","8af38c0c":"from rfpimp import *\ntrain_X = train_onehot.drop(['Survived'], axis=1)\ntrain_y = train_onehot['Survived']\nrf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\nrf.fit(train_X, train_y)\nimp = importances(rf, train_X, train_y) # permutation\nprint(imp)","ecb8b326":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.tree.export import export_text\n\ndtree_cols=['WomanOrBoyCount2','WomanOrChild','Pclass_Poor','Pclass_Rich']\ndtree = DecisionTreeClassifier(max_depth=3).fit(train_X[dtree_cols], train_y)\nprint(cohen_kappa_score(train_y, dtree.predict(train_X[dtree_cols])))\nprint(confusion_matrix(train_y, dtree.predict(train_X[dtree_cols])))\ntree_rules = export_text(dtree, feature_names=dtree_cols, show_weights=True)\nprint(tree_rules)","dc41b0c7":"dtree2_cols=['Ticket_Number','WomanOrBoyCount2','WomanOrChild']\ndtree2 = DecisionTreeClassifier(max_depth=10).fit(train_X[dtree2_cols], train_y)\nprint(cohen_kappa_score(train_y, dtree2.predict(train_X[dtree2_cols])))\nprint(confusion_matrix(train_y, dtree2.predict(train_X[dtree2_cols])))\ntree_rules = export_text(dtree2, feature_names=dtree2_cols, show_weights=True)\nprint(tree_rules)","a8f3feea":"dtree3_cols=['LastName','WomanOrBoyCount2','WomanOrChild']\ndtree3 = DecisionTreeClassifier(max_depth=10).fit(train_X[dtree3_cols], train_y)\nprint(cohen_kappa_score(train_y, dtree3.predict(train_X[dtree3_cols])))\nprint(confusion_matrix(train_y, dtree3.predict(train_X[dtree3_cols])))\ntree_rules = export_text(dtree3, feature_names=dtree3_cols, show_weights=True)\nprint(tree_rules)","93907e92":"submission['Survived_dtree'] = dtree.predict(test_onehot[dtree_cols]).astype(int)\nsubmission['Survived_dtree2'] = dtree2.predict(test_onehot[dtree2_cols]).astype(int)\nsubmission['Survived_dtree3'] = dtree3.predict(test_onehot[dtree3_cols]).astype(int)\nsubmission['Survived_gender'] = submission['Survived']\nsubmission['Average_Survived'] = (submission['Survived_dtree'] + submission['Survived_dtree2'] + submission['Survived_dtree3'] + submission['Survived_gender'])\/4.0\nsubmission['Survived'] = (submission['Average_Survived'] >= 0.75) * 1","77596295":"submission = submission[['PassengerId','Survived']]","6cee09fd":"submission.head()","fd8bdf93":"submission.to_csv('submission.csv', index=False)","b7c48e5a":"This notebook aims to use the ticket number in some way to do the predictions.\n\n\n### 1. Data Cleaning and Preprocessing","c11fcb77":"Let's extract the ticket number and the ticket type.","8e4ab309":"Children with 0 Parch is said to travel with nanny, so increase the Parch by 1 in such cases","dc315812":"Model building time!\nWe will be building three models and taking the majority voting at the end.","0fefbb56":"On the first look, PassengerId has very high variance compared to the rest of the columns, so it is not included in our analysis.\nSecondly, cabin has 1000+ missing values so it will also be discarded from out analysis and instead we will use a derived variable cabin_missing.","ec864c92":"The name column can be extracted to make two or more columns, let's make that.","15f31408":"#### Missing Values Imputation!"}}