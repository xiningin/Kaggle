{"cell_type":{"1c6653fb":"code","764bfea2":"code","d6037399":"code","e08658c9":"code","6b8b12ff":"code","bbc62939":"code","feaef0d9":"code","b3fccea8":"code","74a12e37":"code","df7978bb":"code","e62dd4f3":"code","bc4bef98":"markdown","53023928":"markdown","ccc15607":"markdown","7d7f9bb9":"markdown","31595c31":"markdown","20235324":"markdown","df4283d8":"markdown","057fff81":"markdown","a6a07591":"markdown"},"source":{"1c6653fb":"import numpy as np \nimport pandas as pd \n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image\nfrom scipy.misc import imread\n\nimport os\n\n# ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# Channel visualization\nchannel_names = ['Green','Red','Blue','Yellow']\nchannel_colors = ['mediumseagreen', 'salmon', 'steelblue', 'burlywood']\nchannel_cmaps = ['Greens','Reds','Blues','Oranges']\n\n# Load training labels\ntrain_labels = pd.read_csv(\"..\/input\/train.csv\")\nprint('Number of training images = {0}'.format(train_labels.shape[0]))","764bfea2":"# set the path to our training image folder\ntrain_path = \"..\/input\/train\/\"","d6037399":"# Helper function for loading images\n# Copied from: https:\/\/www.kaggle.com\/allunia\/protein-atlas-exploration-and-baseline\ndef load_image(basepath, image_id):\n    images = np.zeros(shape=(4,512,512))\n    images[0,:,:] = imread(basepath + image_id + \"_green\" + \".png\")\n    images[1,:,:] = imread(basepath + image_id + \"_red\" + \".png\")\n    images[2,:,:] = imread(basepath + image_id + \"_blue\" + \".png\")\n    images[3,:,:] = imread(basepath + image_id + \"_yellow\" + \".png\")\n    return images","e08658c9":"for id in train_labels.Id:\n    images = load_image(train_path, id)\n    fig, ax = plt.subplots(1,4,figsize=(20,5))\n    for n in range(4):\n        ax[n].imshow(images[n], cmap=channel_cmaps[n])\n        ax[n].set_title(channel_names[n])\n    break","6b8b12ff":"def mean_from_histogram(arr):\n    hist_sum = 0\n    count = np.sum(arr)\n    for n in range(len(arr)):\n        hist_sum += n * arr[n]\n    return hist_sum \/ count\n\ndef stdev_from_histogram(arr, mean):\n    count = np.sum(arr)\n    variance = 0\n    for n in range(len(arr)):\n        variance += arr[n] * (n - mean) * (n - mean)\n    return np.sqrt(variance\/count)","bbc62939":"channel_hist = np.zeros(shape=(4,256))\nchannel_means = np.zeros(shape=(4))\nchannel_stdevs = np.zeros(shape=(4))\n\n# These iterations are divided into two cells because the Jupyter Notebook cell timeout is 20 minutes\n# and going through all images takes about 25 minutes\nfrom tqdm import tqdm\ncounter = 0\nfor id in train_labels.Id:\n    images = load_image(train_path, id)\n    for n in range(4):\n        hist, _ = np.histogram(images[n], 256, density=False)\n        channel_hist[n,:,] = np.sum([hist,channel_hist[n]], axis=0)\n    counter += 1\n    if(counter == 15000):\n        break","feaef0d9":"for id in train_labels.Id:\n    if(counter > 0):\n        counter -= 1\n        continue\n    images = load_image(train_path, id)\n    for n in range(4):\n        hist, _ = np.histogram(images[n], 256, density=False)\n        channel_hist[n,:,] = np.sum([hist,channel_hist[n]], axis=0)","b3fccea8":"fig, ax = plt.subplots(1,4,figsize=(20,5))\nx = range(256)\nfig.suptitle('Histograms (log)', fontsize=16)\n\n# Calculate means and standard deviations for each channel\nfor n in range(4):\n    ax[n].bar(x, channel_hist[n], color=channel_colors[n], width=1.0)\n    ax[n].set_yscale('log')\n    ax[n].set_title(channel_names[n])\n    channel_means[n] = mean_from_histogram(channel_hist[n])\n    channel_stdevs[n] = stdev_from_histogram(channel_hist[n], channel_means[n])\n    print(channel_names[n] + ': Mean = {0} ,StDev = {1}'.format(channel_means[n], channel_stdevs[n]))\n    \nplt.show()","74a12e37":"import skimage.io\nfrom skimage.transform import resize\ndef load_normalized_image(basepath, image_id):\n        image_green = skimage.io.imread(basepath + image_id + \"_green\" + \".png\")\n        image_red = skimage.io.imread(basepath + image_id + \"_red\" + \".png\")\n        image_blue = skimage.io.imread(basepath + image_id + \"_blue\" + \".png\")\n        image_yellow = skimage.io.imread(basepath + image_id + \"_yellow\" + \".png\")\n\n        # normalize with calculated channel means and standard deviations\n        image = np.stack((\n            (image_red - 20.535) \/ 38.161,\n            (image_green - 13.528) \/ 28.700,\n            (image_blue - 14.249) \/ 40.195, \n            (image_yellow - 21.106) \/ 38.172), -1)\n        \n        image = resize(image, (512, 512, 4), mode='reflect')\n        return image.astype(np.float)","df7978bb":"def load_normalized_0_1_image(basepath, image_id):\n        image_green = skimage.io.imread(basepath + image_id + \"_green\" + \".png\")\n        image_red = skimage.io.imread(basepath + image_id + \"_red\" + \".png\")\n        image_blue = skimage.io.imread(basepath + image_id + \"_blue\" + \".png\")\n        image_yellow = skimage.io.imread(basepath + image_id + \"_yellow\" + \".png\")\n        \n        image = np.stack((\n            image_red \/ 255.,\n            image_green \/ 255.,\n            image_blue \/ 255., \n            image_yellow \/ 255.), -1)\n        \n        image = resize(image, (512, 512, 4), mode='reflect')\n        return image.astype(np.float)","e62dd4f3":"counter = 0\n# 256 bins\nhist_100 = np.zeros(shape=(256))\nhist_100_reg = np.zeros(shape=(256))\nhist_100_0_1 = np.zeros(shape=(256))\nbin_edges = []\nbin_edges_reg = []\nbin_edges_0_1 = []\nfor id in train_labels.Id:\n    # load normalized (mean SD)\n    image = load_normalized_image(train_path, id)\n    hist, bin_edges = np.histogram(image, 256, (-1,10), density=False)\n    hist_100 = np.sum([hist, hist_100], axis=0)\n    # load normalized to 0-1 range\n    image = load_normalized_0_1_image(train_path, id)\n    hist, bin_edges_0_1 = np.histogram(image, 256, (0,1), density=False)\n    hist_100_0_1 = np.sum([hist, hist_100_0_1], axis=0)\n    # load regular\n    images = load_image(train_path, id)\n    for n in range(4):\n        hist, bin_edges_reg = np.histogram(images[n], 256, density=False)\n        hist_100_reg = np.sum([hist,hist_100_reg], axis=0)\n    \n    counter += 1\n    if(counter == 100):\n        break\n\nfig, ax = plt.subplots(1,3,figsize=(18,5))\nax[0].bar(bin_edges_reg[1:], hist_100_reg, 1, color='steelblue')\n#ax[0].set_yscale('log')\nax[0].set_ylim(0,1000000)\nax[0].set_title('Without normalization')\n\nax[1].bar(bin_edges[1:], hist_100, 0.043, color='mediumaquamarine')\n#ax[1].set_yscale('log')\nax[1].set_ylim(0,1000000)\nax[1].set_title('Normalized ((channel - mean)\/SD)')\n\nax[2].bar(bin_edges_0_1[1:], hist_100_0_1, 0.004, color='sandybrown')\n#ax[2].set_yscale('log')\nax[2].set_ylim(0,1000000)\nax[2].set_title('Normalized (channel\/255)')\n\nfig.suptitle('Histogram (sum of all channels)', fontsize=16)\nplt.show()","bc4bef98":"### Functions for calculating mean and standard deviation","53023928":"### Get histograms from the training images","ccc15607":"For comparison. The below function normalizes each channel to 0-1 range with ```channel = channel \/ 255```","7d7f9bb9":"Test that we can read the images and plot the channels of the first image.","31595c31":"# Channel means and standard deviations\nThese are calculated from the whole training dataset.\n\n| **Channel** | **Mean**| **Standard deviation** |\n| -------------- | :----------: | :---------------------------: |\n| **Green** | `13.528` | `28.700` |\n| **Red** | `20.535` | `38.161` |\n| **Blue** | `14.249` | `40.195` |\n| **Yellow** | `21.106` | `38.172` |\n","20235324":"### Value distribution comparison\n- **Without normalization**\n- **Normalized (*(channel - channel_mean) \/ channel_SD*)**\n- **Normalized (*channel\/255*)**\n\nLets look at histograms from batches of 100 first images to see how the pixel values are distributed.","df4283d8":"## Calculate means and standard deviations for each channel\nPrint results and plot histograms ","057fff81":"## How to normalize when loading images\nHere is an image loading function that returns a normalized 4-channel 512x512 image where each channel is normalized as: ```channel = (channel - channel_mean) \/ channel_stdev``` ","a6a07591":"# Channel normalization\nMany of the kernels here are normalizing their input data dividing by 255 so you end up with values ranging from 0 to 1.\n\nAnother common normalization practice with images is to have a **mean of 0 and a standard deviation of 1 per channel.** This notebook calculates the necessary values for each channel so we can normalize them with:\n\n```channel = (channel - channel_mean) \/ channel_stdev```\n\nI got slightly better predictions by changin from 0-1 normalization to the latter (from **0.348** to **0.354**) with a *512x512x4 CNN with batch norm* (from scratch). This is not much of an improvement but at least this did not make it worse.\n\nIn conclusion, **if you are using batch normalization in your neural network, the method of input normalization is probably not gonna have a large effect**.\n"}}