{"cell_type":{"1a367b92":"code","614c4aec":"code","656596fe":"code","8e3eab22":"code","7c9d2b1a":"code","1610cbcd":"code","7ae8be21":"code","b3bf37a2":"code","e97caa65":"code","cb8cf042":"code","e7b13254":"code","6e1afebb":"code","46c66662":"code","f475c46a":"code","7a0df5c5":"code","a988e28b":"code","cf3769e1":"code","5e1b2ec0":"code","8ffd374c":"code","ab8d63fd":"code","92724476":"code","75a94675":"code","99a57f52":"code","28b3fc1e":"code","39132f41":"code","e69df084":"code","ce918ff3":"code","eba1ff5f":"code","6c615d63":"code","9f21dbba":"code","2438cc64":"code","57c28543":"code","c49ba145":"code","043db5da":"code","370f0563":"code","e0de692f":"code","78e4cf76":"code","60c7a8d3":"code","447c07a3":"code","886dd7b5":"code","d176c264":"code","7a567b05":"code","c36d3886":"code","a49088fc":"code","e866f3d1":"code","66a13d89":"code","3941f33a":"code","2f10c7a3":"code","a93957fc":"code","96e3355e":"code","021cf46f":"code","f1d95379":"code","f4e04ad8":"code","9173ec39":"code","59426a66":"code","0ceea832":"code","d800488c":"code","9ab5ade3":"code","b50f276b":"code","02d48c97":"code","158ac90a":"code","6b349bc2":"code","f7d8fc29":"code","0670b567":"code","010bcda3":"code","7d91490d":"code","bc4427cf":"code","3b8768eb":"code","444e21c8":"code","c46ada78":"code","de601e7f":"code","56c58f59":"code","88816a40":"code","503d3589":"code","362b5f5b":"code","74b66bbe":"code","bf1f19f2":"code","1abd2096":"code","5c6efd20":"code","b8f9a753":"code","10b22753":"code","43848bf3":"code","353c6b24":"code","3502f9da":"code","15168428":"code","d6017405":"code","f7bf3b72":"code","47c0cf0e":"code","34860344":"code","ca2ecf91":"code","97ca1845":"code","fff6f25c":"code","aa4c9da9":"code","e8c075c4":"code","17057fbc":"code","9ea58e24":"code","4001aad7":"code","e03fd316":"code","d1f43eb6":"code","13b732a6":"code","84884543":"code","3208c946":"code","4c5d9fae":"code","d524b7e2":"code","a643b8bf":"code","bcfccff6":"code","1e7aea9b":"markdown","d977dabe":"markdown","b254386c":"markdown","bb5df6ef":"markdown","f25f2011":"markdown","0c47e9d0":"markdown","a703dde2":"markdown","d97c416a":"markdown","32247549":"markdown","a2b51533":"markdown","c89a7ce2":"markdown","8588ef49":"markdown","f8615bcb":"markdown","08203d3e":"markdown","856382e2":"markdown","90ff21b1":"markdown","4e218ea2":"markdown","61d5a99b":"markdown","112b9fcc":"markdown","1c23784a":"markdown","395ecdf9":"markdown","79cf43d8":"markdown","918488aa":"markdown","152cb24a":"markdown","d1e03275":"markdown","70d248d3":"markdown","61cc34df":"markdown","f48767ed":"markdown","4a87b32c":"markdown","bc7a4fb9":"markdown","9b57bff2":"markdown","47a7b19a":"markdown","a090dec7":"markdown","7ae42197":"markdown","84db3600":"markdown","357c56ff":"markdown","c9445d9e":"markdown","1d3a6460":"markdown","ed35faef":"markdown","38b50997":"markdown","0671fddb":"markdown","452196b0":"markdown","5edb3cd1":"markdown","5e8a0a14":"markdown","242da0c9":"markdown","9ee4edeb":"markdown","40bcf696":"markdown","8b86d565":"markdown","f98dab3d":"markdown","7405eb66":"markdown","d9dea3a6":"markdown","66468fa5":"markdown","91130ae8":"markdown","9e358861":"markdown","c7b8ae78":"markdown","629a7e6c":"markdown","7f1d1e3a":"markdown","d32dc2c9":"markdown"},"source":{"1a367b92":"import os\nimport pandas as pd\nimport pandas_profiling\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport datetime\n\n%matplotlib inline","614c4aec":"doc_reports_data = pd.read_csv(\"..\/input\/doc_reports.csv\", index_col=0)\n\nfacial_similarity_reports_data = pd.read_csv(\"..\/input\/facial_similarity_reports.csv\", index_col=0)","656596fe":"doc_reports_data.columns","8e3eab22":"doc_reports_data.user_id.size","7c9d2b1a":"doc_reports_data.head()","1610cbcd":"import collections\ncounter=collections.Counter(doc_reports_data.user_id)\ncollections.Counter(counter.values())","7ae8be21":"facial_similarity_reports_data.columns","b3bf37a2":"facial_similarity_reports_data.head()","e97caa65":"#outputfile1 = \"doc_reports_profile.html\"\n#doc_reports_profile = pandas_profiling.ProfileReport(doc_reports_data, bins=50)\n#doc_reports_profile.to_file(outputfile=outputfile1)","cb8cf042":"#outputfile2 = \"facial_similarity_reports_profile.html\"\n#facial_similarity_reports_profile = pandas_profiling.ProfileReport(facial_similarity_reports_data, bins=50)\n#facial_similarity_reports_profile.to_file(outputfile=outputfile2)","e7b13254":"joined_results = doc_reports_data.merge(facial_similarity_reports_data,on='user_id', \n                                        how='outer', suffixes=['_doc', '_facial'])","6e1afebb":"joined_results.head()","46c66662":"joined_results_curated = joined_results[['user_id','result_doc','result_facial',\n                                         'created_at_doc']]","f475c46a":"joined_results_curated.head()","7a0df5c5":"joined_results_curated['pass_value_doc'] = np.where(joined_results_curated.loc[:,'result_doc'].eq('clear') ,1,0)\njoined_results_curated['pass_value_facial'] = np.where( joined_results_curated.loc[:,'result_facial'].eq('clear') ,1,0)\njoined_results_curated['pass_value'] = np.where(joined_results_curated.loc[:,'result_doc'].eq('clear') & \n                                                joined_results_curated.loc[:,'result_facial'].eq('clear')\n                                               ,1,0)","a988e28b":"joined_results_curated.head()","cf3769e1":"joined_results_curated[\"created_at_doc\"] = pd.to_datetime(joined_results_curated[\"created_at_doc\"])","5e1b2ec0":"joined_results_curated['date_created_at'] = joined_results_curated[\"created_at_doc\"].apply( lambda df : \ndatetime.datetime(year=df.year, month=df.month, day=df.day))","8ffd374c":"joined_results_curated.set_index(joined_results_curated[\"date_created_at\"],inplace=True)","ab8d63fd":"joined_results_curated.head()","92724476":"weekly_pass_value = joined_results_curated['pass_value'].resample('W').sum()\n\nweekly_pass_value_doc = joined_results_curated['pass_value_doc'].resample('W').sum()\n\nweekly_pass_value_facial = joined_results_curated['pass_value_facial'].resample('W').sum()","75a94675":"weekly_pass_value.head()","99a57f52":"weekly_attempts = joined_results_curated['pass_value'].resample('W').size()","28b3fc1e":"weekly_attempts.head()","39132f41":"pass_rate_data = weekly_pass_value\/weekly_attempts * 100\npass_KYC = pass_rate_data\npass_rate_data_doc = weekly_pass_value_doc\/weekly_attempts * 100\npass_rate_data_facial = weekly_pass_value_facial\/weekly_attempts * 100","e69df084":"pass_rate_data = pass_rate_data.rename(\"KYC process\")\npass_rate_data_doc = pass_rate_data_doc.rename(\"Document check\")\npass_rate_data_facial = pass_rate_data_facial.rename(\"Facial check\")","ce918ff3":"fig = plt.figure()\nax1 = pass_rate_data.plot()\nax2 = pass_rate_data_doc.plot()\nax3 = pass_rate_data_facial.plot()\nplt.xlabel('Week date')\nplt.ylabel('Pass rate (%)')\nplt.legend()\nplt.show()","eba1ff5f":"doc_reports_currated = doc_reports_data[['user_id','result','created_at' ,'visual_authenticity_result','image_integrity_result',\n                                         'data_validation_result', 'data_consistency_result', 'data_comparison_result',\n                                         'police_record_result', 'compromised_document_result']]","6c615d63":"doc_reports_currated[\"created_at\"] = pd.to_datetime(doc_reports_currated[\"created_at\"])","9f21dbba":"doc_reports_currated['created_at'] = doc_reports_currated[\"created_at\"].apply( lambda df : \ndatetime.datetime(year=df.year, month=df.month, day=df.day))","2438cc64":"doc_reports_currated['result'] = np.where(doc_reports_currated.loc[:,'result'].eq('consider') ,0,1)\n\ndoc_reports_currated['visual_authenticity_result'] = np.where(doc_reports_currated.loc[:,'visual_authenticity_result'].eq('consider') ,0,1)\ndoc_reports_currated['image_integrity_result'] = np.where(doc_reports_currated.loc[:,'image_integrity_result'].eq('consider') ,0,1)\ndoc_reports_currated['data_validation_result'] = np.where(doc_reports_currated.loc[:,'data_validation_result'].eq('consider') ,0,1)\ndoc_reports_currated['data_consistency_result'] = np.where(doc_reports_currated.loc[:,'data_consistency_result'].eq('consider') ,0,1)\ndoc_reports_currated['data_comparison_result'] = np.where(doc_reports_currated.loc[:,'data_comparison_result'].eq('consider') ,0,1)\ndoc_reports_currated['police_record_result'] = np.where(doc_reports_currated.loc[:,'police_record_result'].eq('consider') ,0,1)\ndoc_reports_currated['compromised_document_result'] = np.where(doc_reports_currated.loc[:,'compromised_document_result'].eq('consider') ,0,1)","57c28543":"doc_reports_currated.head()","c49ba145":"corr = doc_reports_currated.corr()\ncorr.style.background_gradient()","043db5da":"doc_reports_currated.set_index(doc_reports_currated[\"created_at\"],inplace=True)","370f0563":"weekly_pass_value = doc_reports_currated['result'].resample('W').sum()\n\nweekly_pass_visual_authenticity = doc_reports_currated['visual_authenticity_result'].resample('W').sum()\nweekly_pass_integrity = doc_reports_currated['image_integrity_result'].resample('W').sum()\nweekly_pass_data_validation = doc_reports_currated['data_validation_result'].resample('W').sum()\nweekly_pass_consistency = doc_reports_currated['data_consistency_result'].resample('W').sum()\nweekly_pass_data_comparison = doc_reports_currated['data_comparison_result'].resample('W').sum()\nweekly_pass_police_record = doc_reports_currated['police_record_result'].resample('W').sum()\nweekly_pass_compromised_document = doc_reports_currated['compromised_document_result'].resample('W').sum()","e0de692f":"weekly_attempts = doc_reports_currated['result'].resample('W').size()","78e4cf76":"rate_pass = weekly_pass_value\/weekly_attempts * 100\n\nrate_pass_visual_authenticity = weekly_pass_visual_authenticity\/weekly_attempts * 100\nrate_pass_integrity = weekly_pass_integrity\/weekly_attempts * 100\nrate_pass_data_validation = weekly_pass_data_validation\/weekly_attempts * 100\nrate_pass_consistency = weekly_pass_consistency\/weekly_attempts * 100\nrate_pass_data_comparison = weekly_pass_data_comparison\/weekly_attempts * 100\nrate_pass_police_record = weekly_pass_police_record\/weekly_attempts * 100\nrate_pass_compromised_document = weekly_pass_compromised_document\/weekly_attempts * 100\n","60c7a8d3":"df = pd.DataFrame(rate_pass)\ndf2 = pd.DataFrame(rate_pass_visual_authenticity)\ndf3 = pd.DataFrame(rate_pass_integrity)\ndf4 = pd.DataFrame(rate_pass_data_validation)\ndf5 = pd.DataFrame(rate_pass_consistency)\ndf6 = pd.DataFrame(rate_pass_data_comparison)\ndf7 = pd.DataFrame(rate_pass_police_record)\ndf8 = pd.DataFrame(rate_pass_compromised_document)\n\nweekly_pass_rate = df.merge(df2, left_on='created_at', right_on='created_at')\nweekly_pass_rate = weekly_pass_rate.merge(df3, left_on='created_at', right_on='created_at')\nweekly_pass_rate = weekly_pass_rate.merge(df4, left_on='created_at', right_on='created_at')\nweekly_pass_rate = weekly_pass_rate.merge(df5, left_on='created_at', right_on='created_at')\nweekly_pass_rate = weekly_pass_rate.merge(df6, left_on='created_at', right_on='created_at')\nweekly_pass_rate = weekly_pass_rate.merge(df7, left_on='created_at', right_on='created_at')\nweekly_pass_rate = weekly_pass_rate.merge(df8, left_on='created_at', right_on='created_at')\n\nweekly_pass_rate.columns = ['pass_value', 'visual_authenticity', 'image_integrity','data_validation' , \n                           'document_consistency', 'data_comparison','police_record','compromised_document']\n\nweekly_pass_rate.head()","447c07a3":"corrx2 = weekly_pass_rate.corr()\ncorrx2.style.background_gradient()","886dd7b5":"plt.figure()\nrate_pass.plot()\nrate_pass_visual_authenticity.plot()\nrate_pass_integrity.plot()\nrate_pass_data_validation.plot()\nrate_pass_consistency.plot()\nrate_pass_data_comparison.plot()\nrate_pass_police_record.plot()\nrate_pass_compromised_document.plot()\nplt.xlabel('Date')\nplt.ylabel('Pass Rate')\n\nplt.legend(['y = pass rate', 'y = visual authenticity', 'y = image integrity', 'y=data validation',\n            'y=document consistency', 'y= data comparison', 'y=police record', 'y=compromised document'\n           ], loc='lower left')\nplt.show()","d176c264":"integrity_currated = doc_reports_data[['user_id','result','created_at' ,'image_integrity_result',\n                                        'supported_document_result', 'image_quality_result', 'colour_picture_result', 'conclusive_document_quality_result'\n                                        ]]","7a567b05":"integrity_currated[\"created_at\"] = pd.to_datetime(integrity_currated[\"created_at\"])","c36d3886":"integrity_currated['created_at'] = integrity_currated[\"created_at\"].apply( lambda df : \ndatetime.datetime(year=df.year, month=df.month, day=df.day))","a49088fc":"integrity_currated['image_integrity_result'] = np.where(integrity_currated.loc[:,'image_integrity_result'].eq('consider') ,0,1)\n\nintegrity_currated['supported_document_result'] = np.where(integrity_currated.loc[:,'supported_document_result'].eq('unidentified') ,0,1)\nintegrity_currated['image_quality_result'] = np.where(integrity_currated.loc[:,'image_quality_result'].eq('unidentified') ,0,1)\nintegrity_currated['colour_picture_result'] = np.where(integrity_currated.loc[:,'colour_picture_result'].eq('consider') ,0,1)\nintegrity_currated['conclusive_document_quality_result'] = np.where(integrity_currated.loc[:,'conclusive_document_quality_result'].eq('consider') ,0,1)","e866f3d1":"corr2 = integrity_currated.corr()\ncorr2.style.background_gradient()","66a13d89":"integrity_currated.set_index(integrity_currated[\"created_at\"],inplace=True)\n\nweekly_pass_image_integrity = integrity_currated['image_integrity_result'].resample('W').sum()\nweekly_pass_supported_document_result = integrity_currated['supported_document_result'].resample('W').sum()\nweekly_pass_image_quality_result = integrity_currated['image_quality_result'].resample('W').sum()\nweekly_pass_colour_picture_result = integrity_currated['colour_picture_result'].resample('W').sum()\nweekly_pass_conclusive_document_quality_result = integrity_currated['conclusive_document_quality_result'].resample('W').sum()\n\nweekly_attempts = integrity_currated['image_integrity_result'].resample('W').size()\n\nrate_image_integrity = weekly_pass_image_integrity\/weekly_attempts * 100\nrate_image_supported_document_result = weekly_pass_supported_document_result\/weekly_attempts * 100\nrate_image_quality = weekly_pass_image_quality_result\/weekly_attempts * 100\nrate_colour_picture = weekly_pass_colour_picture_result\/weekly_attempts * 100\nrate_conclusive_document_quality = weekly_pass_conclusive_document_quality_result\/weekly_attempts * 100\n\nplt.figure()\nrate_image_integrity.plot()\nrate_image_supported_document_result.plot()\nrate_image_quality.plot()\nrate_colour_picture.plot()\nrate_conclusive_document_quality.plot()\nplt.xlabel('Date')\nplt.ylabel('Pass Rate')\n\nplt.legend(['y = image integrity', 'y = supported document', 'y = image quality', 'y=colour picture',\n            'y=conclusive document quality'\n           ], loc='lower left')\nplt.show()","3941f33a":"from flatten_json import flatten\nimport ast\n\njson_data = doc_reports_data['properties'].values.copy()\n\nfor index,entry in enumerate(json_data):\n    json_data[index] = ast.literal_eval('{'+str(entry).strip('{}')+'}')\n\nflattened = (flatten(entry) for entry in json_data)\ndf = pd.DataFrame(flattened)\n\ndoc_reports_data.drop('properties',axis=1,inplace=False)\ndoc_reports_data = pd.concat([doc_reports_data,df],axis=1)\n\nnan_index = np.where(doc_reports_data['created_at'].isnull())[0]\ndoc_reports_data_new = doc_reports_data.drop(nan_index,inplace=False)","2f10c7a3":"df.head()","a93957fc":"doc_reports_data.head()","96e3355e":"# to be activate to get a profiling study on new properties\n#outputfile3 = \"doc_reports_reports_not_clear_profile.html\"\n#facial_similarity_reports_profile = pandas_profiling.ProfileReport(doc_reports_data, bins=50)\n#facial_similarity_reports_profile.to_file(outputfile=outputfile3)","021cf46f":"id_currated = doc_reports_data_new[['user_id','result','created_at' ,'image_integrity_result',\n                                         'image_quality_result', 'conclusive_document_quality_result', 'gender', 'nationality',\n                                'document_type', 'date_of_expiry', 'issuing_country'\n                                        ]]","f1d95379":"id_currated[\"created_at\"] = pd.to_datetime(id_currated[\"created_at\"])","f4e04ad8":"id_currated['created_at'] = id_currated[\"created_at\"].apply( lambda df : \ndatetime.datetime(year=df.year, month=df.month, day=df.day))\n\nid_currated.set_index(id_currated[\"created_at\"],inplace=True)","9173ec39":"id_currated['nation'] = np.where( id_currated['issuing_country'].eq(np.nan) , id_currated['nationality'] ,\n                                 id_currated['issuing_country']\n                                )\n","59426a66":"nation_different = collections.Counter(id_currated.nation)","0ceea832":"myset = set(nation_different)\n\n#print (myset)\n#myset.sort()\n\nmy_new_list = list(myset)\n\n\n#a faire\n#my_new_list[] = 'no_nation'\n\ni=0\nwhile i< len(my_new_list):\n    if pd.isnull(my_new_list[i]):\n        my_new_list[i] = 'no_nation'\n    i=i+1\n\nprint(my_new_list)\n\nlen(my_new_list)","d800488c":"id_currated['no_nation'] = np.where( pd.isnull( id_currated['nation']) , 1 , 0 )","9ab5ade3":"sum( id_currated.no_nation)","b50f276b":"id_currated['no_nation'] = np.where( pd.isnull( id_currated['nation']) , 1 , 0 )\ni = 1\nwhile i < len(my_new_list):\n\n    id_currated[ my_new_list[i] ] = np.where( id_currated['nation'].eq(my_new_list[i]) , 1 , 0 )\n    i = i+1\n    ","02d48c97":"id_currated.head()","158ac90a":"#id_currated.to_csv('id.csv')","6b349bc2":"id_currated['image_integrity_result'] = np.where(id_currated.loc[:,'image_integrity_result'].eq('consider') ,0,1)\nid_currated['image_quality_result'] = np.where(id_currated.loc[:,'image_quality_result'].eq('consider') ,0,1)\nid_currated['conclusive_document_quality_result'] = np.where(id_currated.loc[:,'conclusive_document_quality_result'].eq('consider') ,0,1)\n","f7d8fc29":"id_currated_nation = id_currated[['result','created_at' ,'image_integrity_result',\n                                         'conclusive_document_quality_result', 'no_nation',\n                               'GBR', 'JOR', 'NAM', 'ITA', 'VEN', 'BGD', 'COM', 'MWI', 'DOM', 'IMN', 'SEN', 'CMR', 'BRA', 'MUS', 'LKA', 'SWE', 'MNE', 'CHN', 'EGY', 'BLZ', 'NIC', 'CYP', 'SI<', 'JPN', 'MDG', 'LTU', 'CIV', 'IND', 'KAZ', 'MEX', 'ISL', 'SYC', 'JEY', 'LIE', 'GRD', 'POL', 'ZIM', 'DEU', 'QAT', 'PHL', 'BEN', 'NGA', 'NPL', 'LBN', 'MLI', 'LBY', 'SVN', 'ISR', 'UGA', 'HUN', 'ARM', 'BFA', 'SGP', 'TZA', 'MAR', 'ROU', 'DZA', 'GAB', 'CPV', 'Svn', 'BLR', 'TUN', 'UZB', 'TKM', 'MKD', 'NOR', 'COD', 'MCO', 'ARE', 'KGZ', 'GIB', 'MRT', 'MDA', 'DMA', 'OMN', 'TCD', 'GTM', 'USA', 'AFG', 'RUS', 'ZAF', 'FRN', 'MDV', 'CHL', 'ESP', 'CZE', 'PAN', 'BGR', 'TTO', 'HTI', 'CRI', 'ZWE', 'FIN', 'HRV', 'ARG', 'BRB', 'SWZ', 'AUT', 'KYA', 'GIN', 'COL', 'HKG', 'ECU', 'GMB', 'TUR', 'SAU', 'ZMB', 'ETH', 'SVK', 'VNM', 'URY', 'GGY', 'RKS', 'SDN', 'PAK', 'SLV', 'KNA', 'DNK', 'TJK', 'NLD', 'BWA', 'PRY', 'TGO', 'IRL', 'SLE', 'NZL', 'CAN', 'BRN', 'CAF', 'IRQ', 'PER', 'LCA', 'CUB', 'FRA', 'UKR', 'ALB', 'PRT', 'AUS', 'KEN', 'KWT', 'KHM', 'MLT', 'TWN', 'JAM', 'BIH', 'IRN', 'GEO', 'THA', 'BOL', 'MYS', 'SYR', 'BMU', 'KOR', 'AZE', 'IDN', 'CHE', 'BEL', 'SUR', 'COG', 'GHA', 'EST', 'HND', 'LUX', 'BHR', 'LVA', 'GRC', 'SRB'\n                                 ]]","0670b567":"#corr3 = id_currated_nation.corr()","010bcda3":"#is very long process\n#corr3.style.background_gradient()","7d91490d":"id_currated_gender = id_currated[[ 'image_integrity_result','gender']]","bc4427cf":"id_currated_gender.head()","3b8768eb":"id_currated_gender['gender'] = np.where(id_currated.loc[:,'gender'].eq('Male') ,1,0)","444e21c8":"corr4 = id_currated_gender.corr()\ncorr4.style.background_gradient()","c46ada78":"id_different = collections.Counter(id_currated.document_type)","de601e7f":"myset2 = set(id_different)\n\nmy_new_list2 = list(myset2)\n\nprint(my_new_list2)\n\ni=0\nwhile i< len(my_new_list2):\n    if pd.isnull(my_new_list2[i]):\n        my_new_list2[i] = 'no_document'\n    i=i+1\n\nprint(my_new_list2)","56c58f59":"id_currated['no_document'] = np.where( pd.isnull( id_currated['document_type']) , 1 , 0 )\ni = 1\nwhile i < len(my_new_list2):\n    id_currated[ my_new_list2[i] ] = np.where( id_currated['document_type'].eq(my_new_list2[i]) , 1 , 0 )\n    i = i+1","88816a40":"id_currated_doc_id = id_currated[[ 'image_integrity_result','work_permit','no_document', 'tax_id', 'birth_certificate', 'national_identity_card', 'residence_permit', 'passport', 'driving_licence', 'voter_id']]","503d3589":"corr5 = id_currated_doc_id.corr()\ncorr5.style.background_gradient()","362b5f5b":"id_currated_nation.head()","74b66bbe":"i=0\nwhile i < len(my_new_list) : \n    #all that pass the test\n    id_currated_nation[ my_new_list[i]+'_good'] = np.where(id_currated_nation.loc[:,'image_integrity_result'].eq(1) & id_currated_nation.loc[:,my_new_list[i]].eq(1) ,1,0) \n    \n    i = i+1","bf1f19f2":"id_currated_nation.FRA_good.sum()","1abd2096":" print ( sum(id_currated_nation.no_nation_good) \/ sum(id_currated_nation.no_nation ) )","5c6efd20":"id_currated_nation.set_index(integrity_currated[\"created_at\"],inplace=True)","b8f9a753":"len(id_currated_nation.result)","10b22753":"pass_rates = dict.fromkeys(my_new_list[0:])\nweekly_attempts_ = dict.fromkeys(my_new_list[0:])\nweekly_attempts_['total'] = id_currated_nation.result.resample('W').size() \/ len(id_currated_nation.result) *100 * 24 -100\n#line above explain in 7.2\n\nfor country in pass_rates.keys():\n    id_currated_nation[country +'_good'] = np.where( id_currated_nation.loc[:,'image_integrity_result'].eq(1) & id_currated_nation.loc[:,country].eq(1) ,1,0)\n    country_weekly_pass_value = id_currated_nation[country +'_good'].resample('W').sum()\n    country_weekly_attempts = id_currated_nation[country].resample('W').sum()\n#    if (country_weekly_attempts.sum() > 2000):\n#        weekly_attempts_[country] = country_weekly_attempts\n    pass_rate_data_country = country_weekly_pass_value\/country_weekly_attempts * 100\n    pass_rates[country] = pass_rate_data_country","43848bf3":"df = pd.DataFrame.from_dict(pass_rates)\ndf.FRA.head(3)","353c6b24":"df.ESP.plot()\ndf.ITA.plot()\ndf.FRA.plot()\ndf.no_nation.plot()\ndf.GBR.plot()","3502f9da":"df5 = pd.DataFrame.from_dict(weekly_attempts_)\ndf5.total.head()","15168428":"df5.total.sum()","d6017405":"weekly_pass_value = id_currated_nation[country +'_good'].resample('W').sum()\n","f7bf3b72":"fig, ax1 = plt.subplots()\nax1.plot(df5.total, 'b-')\nax1.set_xlabel('time')\n# Make the y-axis label and tick labels match the line color.\nax1.set_ylabel('difference in % of attempt to equidistribution ', color='b')\nfor tl in ax1.get_yticklabels():\n    tl.set_color('b')\n\n\nax2 = ax1.twinx()\nax2.plot(pass_KYC, 'r-')\nax2.set_ylabel('Pass rate', color='r')\nfor tl in ax2.get_yticklabels():\n    tl.set_color('r')\nplt.savefig('ShareAxes.png')    \nplt.show()","47c0cf0e":"counter=collections.Counter(doc_reports_data.user_id)\ncollections.Counter(counter.values())","34860344":"joined_results.head(2)","ca2ecf91":"len(joined_results.user_id)","97ca1845":"joined_results_currated2 = joined_results [[ 'user_id','result_doc', 'result_facial', 'created_at_doc' ,  'image_integrity_result' , 'conclusive_document_quality_result' ]]\n","fff6f25c":"joined_results_currated2['pass_value_doc'] = np.where(joined_results_currated2.loc[:,'result_doc'].eq('clear') ,1,0)\njoined_results_currated2['pass_value_facial'] = np.where( joined_results_currated2.loc[:,'result_facial'].eq('clear') ,1,0)\njoined_results_currated2['KYCpass_value'] = np.where(joined_results_currated2.loc[:,'result_doc'].eq('clear') & \n                                                joined_results_currated2.loc[:,'result_facial'].eq('clear')\n                                               ,1,0)","aa4c9da9":"joined_results_currated2.drop_duplicates(subset='user_id', keep='last', inplace=True)","e8c075c4":"joined_results_currated2[\"created_at\"] = pd.to_datetime(joined_results_currated2[\"created_at_doc\"])\njoined_results_currated2['created_at'] = joined_results_currated2[\"created_at\"].apply( lambda df : \ndatetime.datetime(year=df.year, month=df.month, day=df.day))","17057fbc":"joined_results_currated2.set_index(joined_results_currated2[\"created_at\"],inplace=True)","9ea58e24":"joined_results_currated2.head()","4001aad7":"unique_user_week = joined_results_currated2['user_id'].resample('W').size()\n","e03fd316":"unique_user_week.head()","d1f43eb6":"uuw_equidistrib = unique_user_week \/ unique_user_week.sum() *100 * 24 -100","13b732a6":"KYC_final = joined_results_currated2.KYCpass_value.resample('W').sum() \/ joined_results_currated2.KYCpass_value.resample('W').size()","84884543":"fig, ax1 = plt.subplots()\nax1.plot(uuw_equidistrib, 'g-')\nax1.set_xlabel('time')\n# Make the y-axis label and tick labels match the line color.\nax1.set_ylabel('difference in % of unique user to equidistribution ', color='g')\nfor tl in ax1.get_yticklabels():\n    tl.set_color('g')\n\n\nax2 = ax1.twinx()\nax2.plot(pass_KYC, 'r-')\nax2.set_ylabel('Pass rate', color='r')\nfor tl in ax2.get_yticklabels():\n    tl.set_color('r')\nplt.savefig('ShareAxes.png')    \nplt.show()","3208c946":"checkfinal = pd.DataFrame()\ncf = checkfinal\ncf ['rate'] = pass_KYC\ncf ['diff_equidistrib'] = uuw_equidistrib\ncf ['image_integrity'] = rate_image_integrity\ncf ['conclusive_document_quality_result'] = rate_conclusive_document_quality","4c5d9fae":"cf.head(3)","d524b7e2":"cf = cf.iloc[1:,]\ncorr6 = cf.corr()\ncorr6.style.background_gradient()","a643b8bf":"#joined_results_curated.drop_duplicates(subset='user_id', keep='first', inplace=True)","bcfccff6":"fig, ax1 = plt.subplots()\nax1.plot(KYC_final, 'b-')\nax1.set_ylabel('KYC Pass rate %', color='b')\nfor tl in ax1.get_yticklabels():\n    tl.set_color('b') \nplt.show()","1e7aea9b":"## 6. Any correlation on the user characteristic (gender, nationality, document type used...) and the fact that its picture is poor quality ?","d977dabe":"### 7.2 Equidistribution as a reference for the user inscription plot","b254386c":"We use again the same procedure.","bb5df6ef":"We create after the binary variables which defines if the results of the Profile and Facial Similarity reports checks are \u2018clear\u2019, we name them respectively \"pass_value_doc\" and \"pass_value_facial\".\n\nWe add the KYC validation variable which is here the heart of the data study to investigate its \"decreased substantially for the last few weeks\". The \"pass_value\" is defined as a binary value, equal to 1 if the results of both Document and Facial Similarity checks are \u2018clear\u2019, 0 otherwise.","f25f2011":"As a financial institution regulated by the FCA, the startup XYZ has the obligation to verify the identity of all customers who want to open a XYZ account. Each prospective customer has to go through a Know Your Customer (KYC) process by submitting a government-issued photo ID and a facial picture of themself to our partner, Veritas. Veritas then would perform 2 checks:\n\n\u2022 Document check: To verify that the photo ID is valid and authentic;\n\n\u2022 Facial Similarity check: To verify that the face in the picture is the same with that on the submitted ID.\n\nThe customer will \u2018pass\u2019 the KYC process and get aboard if the results of both Document and Facial Similarity checks are \u2018clear\u2019. If the result of any check is not \u2018clear\u2019, the customer has to submit all the photos again.\n\nThe pass rate is defined as the number of customers who pass both the KYC process divided by the number of customers who attempt the process. Each customer has up to 2 attempts.\nThe pass rate has decreased substantially for the last few weeks. Please write a report that outlines the root causes and solutions.\n\nRelevant files:\n\n\u2022 facial_similarity_reports.csv - Reports of all Facial Similarity checks\n\n\u2022 doc_reports.csv - Reports of all Document checks\n\n\u2022 veritas.html - The API documentation of Veritas explaining some terms used in the reports.\n\nThe candidate is free to use Excel or any scripting language to parse and analyse the data.\nPlease show all your work (including your code if applicable) and assumptions.\n","0c47e9d0":"We have a lot of people that are trying 2 times, we will take only the first attempt when we will join the two documents together by linking on the User_ID to plot what the statement name the pass rate.","a703dde2":"### 6.3 Is the type of document (detected or not) used relevant ?","d97c416a":"There aren't any correlation with the type of document used too.","32247549":"#### 7.2.3 The statement KYC pass rate","a2b51533":"Until now we try to correlate considering attempts because UX is directly impacted by many attempts and secondly, I've assume that an user who is attempting a second time is more likely to have again the same issue which will give more data on it.","c89a7ce2":"And plot the correlation","8588ef49":"## KYC recruitment Challenge","f8615bcb":"### 6.2 is gender influencing ?","08203d3e":"Now let's compare the graph of the rate of result of the facial similarity check to the rates of its different parameters. To do so we create a curated dataframe with only the concerned parameters.","856382e2":"We change the date again to a day.","90ff21b1":"First, we export the parameters in column in the new data frame \" doc_reports_data_new \"","4e218ea2":"### 6.1 Is the nation (detected or not) a factor influencing ?","61d5a99b":"## 5. Image integrity in-depth investigation","112b9fcc":"We can see that the creation of the profile reports occure few seconds after so we can perform the study on a day or larger time base on any of those parameter. We choose to use the \"created_at_doc\" variable.\n\n\nThen we create the table with only the information for this raising in faillure check between the document reports and the facial similarity.","1c23784a":"##\u00a04. What is failing in the Facial similarity check? ","395ecdf9":"#### We can conclude that the KYC problem is due to a problem of image quality of the pictures taken and the main problem is that we often don't have an enough quality of the document to be able to perform a fraud inspection.","79cf43d8":"We see that we don't have any correlations higher than 0.02 between any nation and the pass rate or the image_integrity, therefore nations if detected are not significative. ","918488aa":"We see that all the main countries which represent over 80% on the total suscription on this period are facing the same issue, therefore we confirm the no-correlation concluded in 6.2","152cb24a":"## 1. Load data in pandas and have a quick look at it","d1e03275":"## 7.  Unique user \/ week and KYC pass rate ","70d248d3":"we convert the time to a date and set it as index","61cc34df":"And finally.... here is the unique user ! Which will also gives us the KYC pass rate as defined in the statement. ","f48767ed":"# Solution","4a87b32c":"### Conclusion: We can see that the Facial similarity is responsible of making fail the KYC process over the past weeks","bc7a4fb9":"We create a specific file for the correlation of the pass rate and image integrity with nations","9b57bff2":"example of parameters {'gender': 'Male', 'nationality': 'IRL', 'document_type': 'passport', 'date_of_expiry': '2019-08-12', 'issuing_country': 'IRL'}","47a7b19a":"We now need to converte those pass_value into a pass rate and taking an even larger window of a week. \n\nTo convert the pass value into rates, we need to calculate the number of pass_value for doc, facial and the total KYC and then divide by the total numbers of attempts.\n","a090dec7":"## 3. KYC = 2 processes: Is one more guilty ?","7ae42197":"### 7.1 Graph of main countries pass rates","84db3600":"We then convert the date to get a usable format and only get the date as we are investigating a problem over few weeks, for now we keep a large window of one-day minimum.","357c56ff":"We are using pandas_profiling to get an overview of the results. Time-consuming procedure that generate an html file, remove the # to execute it.","c9445d9e":"We can observe on which variables the pass_value is the most correlated and it is definitly correlated with \"the image integrity result\". We now can observe those values as rates of their test pass along time on a graph.\n","1d3a6460":"Then we create a dataframe with only the usefull values for the next studies","ed35faef":"    \"image_integrity\": {\n      \"result\": \"clear\",\n      \"breakdown\": {\n        \"supported_document\": {\n          \"result\": \"clear\",\n          \"properties\": {}\n        },\n        \"image_quality\": {\n          \"result\": \"clear\",\n          \"properties\": {}\n        },\n        \"colour_picture\": {\n          \"result\": \"clear\",\n          \"properties\": {}\n        },\n        \"conclusive_document_quality\": {\n          \"result\": \"clear\",\n          \"properties\": {}\n        }\n      }\n    },","38b50997":"By activated the next cell:\nWe can drop the second try of the doc to not account a little portion of users that fails a lot the same process compared to a larger population failing the other and we would get the same tendance.","0671fddb":"First, I would like to graph for the main overall countries their pass rate, which will reinforce the point made on nation and KYC (6.2)","452196b0":"From those reports, we can see that, on the doc validation side, 75.1% of the test are clear; whereas on the facial similarity test 93.8% of the tests are clear.\n\nWe can see that the tests are failing way more often on the doc validation than the facial similarity, however those are results over the total period and one can't therefore conclude on trends yet.\n\nSo first, we need to investigate if the raised of faillure in the KYC process is due to a raise in faillure in the doc validation or a raise in the facial similarity faillure and if those two tests results are correlated.","5edb3cd1":"Per definition, the image integrity: \"Asserts whether the document was of sufficient quality to verify\". ","5e8a0a14":"Here we consider all attempts and not unique user which can be quite different. However there is quite a correlation yet.","242da0c9":"#### 7.2.2 Unique Users","9ee4edeb":"We then convert every values to binary nb, a question remained for the blanks or NaN filled. We quickly checked how many User_ID have been an overall result \"clear\" while having no \"consider\" columns and we find less then 0.00013%. Therefore our test will be negative if it's blank and positive otherwise.","40bcf696":"Again here we could assume that it's not relevant, but don't make assumptions, prove it :)","8b86d565":"First, import the Libraries that will help us to arrange and treat the data:","f98dab3d":"#### 7.2.1 Total attempts","7405eb66":"## 2. Descriptive statistics","d9dea3a6":"Because there are the same nb of attempts for all (as every KYC generate both) we don't need to differentiate the weely_attempts for documents reports and facial check.","66468fa5":"Let's conclude with the KYC pass rate as defined per the statement :)","91130ae8":"The statement mentions that users can attenpts twice the KYC procedure, let's have a quick look at that repartition:","9e358861":"### We have find our problem, the image integrity. Let's find our on what this test depend on and investigate.","c7b8ae78":"We joined the two reports by matching with User_id, to identify the variables presents under the same name in both reports we add them a suffixes \"_doc\" or \"_facial\" depending if the variable is coming from respectively the profile check or the facial similarity.","629a7e6c":"Gender is not influing the image quality as being logic but we have better check than make assumptions that could occure part of the result as for example woman \/man could tends to be more meticulous to get an unblurred image.","7f1d1e3a":"To use a value representing the variations in % of the user inscription, we chose to use as reference the value of an equidistribution of our user inscription over the total period. The % will be equal to 0 when the user inscription of the week period is corresponding to its number of user inscription if total user were evenly distributed on all weeks.","d32dc2c9":"\"conclusive_document_quality will assert if the document was of enough quality to be able to perform a fraud inspection \""}}