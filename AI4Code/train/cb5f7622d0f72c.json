{"cell_type":{"6e5835d2":"code","7ec62d0d":"code","c0b7985c":"code","227663d0":"code","98681dab":"code","1e46450e":"code","edbd20e4":"code","e815ca34":"code","0af33ba2":"code","75d2facc":"code","a982ffc7":"code","a02874b2":"code","b81b9196":"code","58736075":"code","35f28658":"code","13b495fb":"code","2949a76b":"code","0f2ce0b6":"code","2fad706d":"code","4e751f74":"code","b7cf4369":"code","c5ae8f2a":"code","c3ab0975":"code","8752a5da":"code","dd5e7386":"code","802191d9":"code","2c229e5c":"code","0d1bb5fc":"code","fb7aa235":"code","18e3ce28":"code","3a2b2021":"code","ae736e27":"markdown","4c68bbc2":"markdown","e65e7d66":"markdown","56d0da6f":"markdown","316a6913":"markdown","cec8f91f":"markdown","02319286":"markdown","0c23c8bb":"markdown","feb14e38":"markdown","1c661dee":"markdown","3aebd9c7":"markdown","9484a36c":"markdown","b8f800dc":"markdown","6babf2a4":"markdown","6533f5e2":"markdown","a63070da":"markdown","5754b403":"markdown","cee32199":"markdown"},"source":{"6e5835d2":"import os\n\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\nfrom fastai import *\nfrom fastai.vision import *\n\nimport json\n\n%matplotlib inline","7ec62d0d":"test_images = os.listdir(\"..\/input\/iwildcam2020-256\/256_images\/test\/images\/\")\ntrain_images = os.listdir(\"..\/input\/iwildcam2020-256\/256_images\/train\/images\/\")","c0b7985c":"with open(r'\/kaggle\/input\/iwildcam-2020-fgvc7\/iwildcam2020_train_annotations.json') as json_file:\n    train_data = json.load(json_file)","227663d0":"df_train = pd.DataFrame({'id': [item['id'] for item in train_data['annotations']],\n                         'category_id': [item['category_id'] for item in train_data['annotations']],\n                         'image_id': [item['image_id'] for item in train_data['annotations']],\n                         'location': [item['location'] for item in train_data['images']],\n                         'file_name': [item['file_name'] for item in train_data['images']]})\n\ndf_train.head()","98681dab":"df_train.shape","1e46450e":"df_train = df_train[df_train['file_name'].isin(train_images)]","edbd20e4":"df_train.shape","e815ca34":"cat_images = dict()\ncat_count = dict()\n\nannotations = train_data['annotations']\n_images = train_data['images']\nfor i, annotation in enumerate(annotations):\n    _img = annotation['image_id']\n    cat = annotation['category_id']\n    \n    imgs = cat_images.get(cat, None)\n    if imgs is None:\n        cat_images[cat] = [{'image_id': _img, 'category': cat}]\n    else:\n        cat_images[cat].append({'image_id': _img, 'category': cat})\n        \n    count = cat_count.get(cat, 0)\n    if count == 0:\n        cat_count[cat] = 1\n    else:\n        cat_count[cat] += 1\n        \nn_train = dict()\nn_val = dict()\n\nfor cat, count in cat_count.items():\n    _train = math.floor(count * 0.70)\n    if _train < 1:\n        _train = 1\n    _val = count - _train\n    n_train[cat] = _train\n    n_val[cat] = _val\n\ntrain_images = []\nval_images = []\nfor cat in cat_images.keys():\n    random.shuffle(cat_images[cat])\n    train_images += cat_images[cat][:n_train[cat]]\n    val_images += cat_images[cat][n_train[cat]:]\n\nval_img_dt = pd.DataFrame(val_images)\n\n","0af33ba2":"df_train['is_valid'] = np.where(df_train.image_id.isin(val_img_dt['image_id']), True, False)","75d2facc":"loc_valid = df_train.loc[(df_train['is_valid'] == True)].location.unique()\nloc_train = df_train.loc[(df_train['is_valid'] == False)].location.unique()\n\nloc_valid.shape\ndf_train.category_id.unique().shape","a982ffc7":"df_train.groupby('is_valid').size()","a02874b2":"df_train.drop(df_train.loc[df_train['file_name']=='87022118-21bc-11ea-a13a-137349068a90.jpg'].index, inplace=True)\ndf_train.drop(df_train.loc[df_train['file_name']=='8792549a-21bc-11ea-a13a-137349068a90.jpg'].index, inplace=True)","b81b9196":"df_train.category_id.unique().shape","58736075":"with open(r'\/kaggle\/input\/iwildcam-2020-fgvc7\/iwildcam2020_test_information.json') as f:\n    test_data = json.load(f)","35f28658":"df_test = pd.DataFrame.from_records(test_data['images'])\ndf_test.head()","13b495fb":"train, test = [ImageList.from_df(df, path='..\/input\/iwildcam2020-256\/256_images\/', cols='file_name', folder=folder, suffix='') \n               for df, folder in zip([df_train, df_test], ['train\/images', 'test\/images'])]\ntrfm = get_transforms(max_rotate=20, max_zoom=1.3, max_lighting=0.4, max_warp=0.4,\n                      p_affine=1., p_lighting=1.)\nsrc = (train.use_partial_data(1)\n        .split_from_df(col='is_valid')\n        .label_from_df(cols='category_id')\n        .add_test(test))\ndata = (src.transform(trfm, size = 128, padding_mode = 'reflection')\n        .databunch(path=Path('.'), bs = 256).normalize(imagenet_stats))","2949a76b":"print(data.classes)","0f2ce0b6":"org_classes = pd.DataFrame({\"org_category\": data.classes})\norg_classes['Category'] = org_classes.index","2fad706d":"def _plot(i,j,ax):\n    x,y = data.train_ds[1]\n    x.show(ax, y=y)\n\nplot_multi(_plot, 3, 3, figsize=(8,8))","4e751f74":"data.show_batch()","b7cf4369":"data.c","c5ae8f2a":"learn = cnn_learner(data, base_arch=models.resnet50, metrics=accuracy).mixup()","c3ab0975":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","8752a5da":"learn.recorder.min_grad_lr","dd5e7386":"learn.fit_one_cycle(10, slice(0.01))","802191d9":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","2c229e5c":"learn.fit_one_cycle(10, slice(1e-5, 1e-4))","0d1bb5fc":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(12,12), dpi=60)","fb7aa235":"preds,y = learn.TTA(ds_type=DatasetType.Test)","18e3ce28":"pred_csv = pd.DataFrame(preds.numpy())\npred_csv['Id'] = learn.data.test_ds.items\npred_csv.to_csv(\"outout_preds.csv\", index = False)","3a2b2021":"submission = pd.read_csv('..\/input\/iwildcam-2020-fgvc7\/sample_submission.csv')\nid_list = list(submission.Id)\npred_list = list(np.argmax(preds.numpy(), axis=1))\npred_dict = dict((key, value.item()) for (key, value) in zip(learn.data.test_ds.items,pred_list))\npred_ordered = [pred_dict['..\/input\/iwildcam2020-256\/256_images\/test\/images\/' + id + '.jpg'] for id in id_list]\nsubmission_with_idx = pd.DataFrame({'Id':id_list,'Category':pred_ordered})\nsubmission_fixed_labels = pd.merge(submission_with_idx, org_classes, on = 'Category', how='left')\nsubmission_fixed_labels = submission_fixed_labels.drop(['Category'], axis = 1)\nsubmission_fixed_labels.rename(columns={'org_category': 'Category'}, inplace=True)\n\nsubmission_fixed_labels.to_csv(\"submission.csv\".format(Category),index = False)\nprint(\"Done\")","ae736e27":"## Modelling part","4c68bbc2":"Show batch.","e65e7d66":"Read in training dataset.","56d0da6f":"Tag validation set.","316a6913":"Split training validation using categories. 70% of category entries in training set.","cec8f91f":"## Data pre-processing","02319286":"I'm creating a ImageDataBunch in a few steps. DataBunch is an object that the model needs.\nFirst I create an `ImageList` with training and test data.\nSecondly I define the transformations that will be applied to the pictures.\nI say that labels for the training come from the dataframe and are stored in `category_id` column. I add the test set.\nFinally I can create the databunch. Apply transofrmations to the data, resize all pictures to 128x128, add reflection padding. I want to use a batch size `bs` of 256 images, and normalize the data with `imagenet_stats`.","0c23c8bb":"I use transfer learning. This means I will use a pre-trained model in this case Resnet50 and adapt it to my dataset. In transfer learning we keep the convolutionals layers: body or the backbone with their weigths pre-trained on ImageNet and only define a new head. I use the head defined by the fastai library.\n\nI use accuracy as the metric to print. I add mixup. Model won't be trained on actual photos, but on random combinations of them.","feb14e38":"Recommended methods choosing the LR:\n * at the steepest decline of loss\n * 10x prior to the minimum loss. ","1c661dee":"Remove corrupted images.","3aebd9c7":"Make predictions on the test set using test time augmentation. TTA makes 4 predictions using the transforms of the training set and averages them. ","9484a36c":"The most important parameter to set is learning rate which is the step size in the optimization to reach the loss minimum. To find the learning rate I use `lr_find`. What it does is it starts with a very small lr, increases it with every batch and records the loss. Then the lr values are ploted against the losses.","b8f800dc":"Check what is location split.","6babf2a4":"Fastai.vision module divides the architecture in 3 groups and trains them with variable learning rates depending on what you input. (Starting layers usually don't require large variations in parameters)\n\nAdditionally, if you use 'fit_one_cycle', all the groups will have learning rate annealing with their respective variable learning.\nFirst I freeze the body weights and only train the head.","6533f5e2":"Read test data.","a63070da":"Show number of categories in the data.","5754b403":"After the random weights in the head are trained a bit, we can unfreeze the weights in the whole network and train everything.","cee32199":"Fastai vision on iWildCam 2020 data resized to 256x256.\nResnet50 + mixup + TTA"}}