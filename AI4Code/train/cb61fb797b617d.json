{"cell_type":{"2ed86e20":"code","b8b122a4":"code","08ccddcb":"code","6ace7271":"code","7f37c355":"code","335ad207":"code","7bc303fd":"code","316b1c75":"code","d03769da":"code","0417c8e9":"code","797aeefc":"code","4c84ac21":"code","8579b563":"code","f3014ecf":"code","7f503183":"code","ba345647":"code","585d2359":"code","bc0fe908":"code","be14abbb":"code","5e97a936":"code","42a8e959":"code","ec15cdfa":"code","081f4dc2":"code","5b5530c1":"code","266b0764":"code","173e06fc":"code","e5892bc5":"code","3434f6b7":"code","3b8e82a4":"code","14679e10":"code","30fb8329":"code","ab505290":"code","5ed01dcf":"code","72dca42e":"code","d6341977":"code","bc50c2e2":"code","0bad3634":"code","c3966df7":"code","6392d6c2":"code","433bb922":"code","c01589b7":"code","f4807f1a":"code","519168c4":"code","9a7bbab5":"code","0a8db4e2":"code","6d7829ca":"markdown","ca1ef5e9":"markdown","2cf56eb0":"markdown","14a4bebe":"markdown","1b3049b6":"markdown","24dcb103":"markdown","93a5af52":"markdown","e1c59399":"markdown","975d7573":"markdown","11b4a5d9":"markdown","6aa37574":"markdown","3187e870":"markdown","3579e3e8":"markdown","a0532307":"markdown","1eea103e":"markdown","ed207ae6":"markdown","ecc81bac":"markdown","5e47261f":"markdown","2501d061":"markdown","d3a8a6d4":"markdown","e1769960":"markdown","d4d72a6e":"markdown","617b37ab":"markdown","1903c436":"markdown","0c852216":"markdown","ee9abeb9":"markdown","1e5a6020":"markdown","ea86d491":"markdown","d12c8152":"markdown","50545be7":"markdown","75575d46":"markdown","9acf6dc6":"markdown","ed0c48b6":"markdown","51321a7b":"markdown","77edc7d8":"markdown","8ec2c128":"markdown","a34fe5fd":"markdown","d84108e0":"markdown","89b7860c":"markdown","38bad465":"markdown","638a73c6":"markdown","7cefd2bf":"markdown","7e479aa4":"markdown","ca53313f":"markdown","b87c7db2":"markdown","de57d282":"markdown","65c0c51e":"markdown","052d3739":"markdown"},"source":{"2ed86e20":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, cross_validate\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import precision_score, recall_score,roc_auc_score, accuracy_score, f1_score, make_scorer, roc_curve\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import BaggingClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n","b8b122a4":"df = pd.read_csv('..\/input\/covid19-deaths-data\/data.csv',index_col=0)\ndf.describe()","08ccddcb":"fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(14, 30))\nfor i in range(13):\n    sns.histplot(x=df.columns[i],hue='result',data=df, ax=ax[i\/\/2][i%2])\n\nplt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)","6ace7271":"corr = df.corr()\nfig, ax = plt.subplots(figsize=(20,15))\nax = sns.heatmap(corr, annot=True)","7f37c355":"#Negative hours changed to positive\nfor i in range(len(df)):\n    df.iloc[i, 12] = df.iloc[i,12]*-1 if df.iloc[i, 12] < 0 else df.iloc[i, 12]\n\n#Gender value 2 changed to the most common gender\ndf['gender'] = df['gender'].mask(df['gender'] == 2, 1)","335ad207":"# drop columns form the given data frame\ndef drop(dropped_columns, df):\n    df_dropped = df.copy()\n    for col in dropped_columns:\n        df_dropped.drop(col, axis=1, inplace=True)\n    return df_dropped","7bc303fd":"# one hot encoding\ndef encode(columns, df):\n    df_encoded = df.copy()\n    for col in columns:\n        encoding = pd.get_dummies(df[col], prefix=col)\n        df_encoded = df_encoded.join(encoding)\n        df_encoded.drop(col, axis=1, inplace=True)\n    return df_encoded","316b1c75":"# scaling\ndef scale(scaled_columns, df):\n    df_scaled = df.copy()\n    scaler = MinMaxScaler()\n    for col in scaled_columns:\n        df_scaled[col] = scaler.fit_transform(df_scaled[col].to_numpy()[:,np.newaxis])[:,0]\n    return df_scaled","d03769da":"# Splits the given dataframe into 70% training set, 15% validation set, 15% testing set\ndef split(df):\n    x = df.drop('result', axis=1)\n    y = df['result']\n    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,shuffle=True, random_state=42)\n    X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, test_size=0.5,shuffle=True, random_state=42)\n    return X_train, X_validate, X_test, y_train, y_validate, y_test","0417c8e9":"def predict_and_score(clf,X, y, average=None):\n    y_predict = clf.predict(X)\n    precision= precision_score(y, y_predict,average=average)\n    recall = recall_score(y,y_predict,average=average)\n    roc_auc = roc_auc_score(y, y_predict)\n    F1 = f1_score(y, y_predict)\n    return precision, recall, F1, roc_auc","797aeefc":"def knn_validate(X_train, X_validate, y_train, y_validate, score='recall'):\n    dic = {'clf':[], 'recall':[], 'precision':[], 'f1':[], 'roc_auc':[]}\n    \n    # Whether the algorithm should take into account the distance of a neighbour when it performs voting\n    weights = ['distance', 'uniform']\n    \n    # K should be an odd number to avoid voting ties, and should be >= 1 and < sqrt(number of samples)\n    for k in range(1, int(len(X_train) ** 0.5), 2):\n        for weight in weights: \n            \n            knn = KNeighborsClassifier(n_neighbors=k, weights=weight)\n            knn.fit(X_train, y_train)\n            precision, recall, roc_auc, F1 = predict_and_score(knn, X_validate, y_validate, 'binary')\n            dic['clf'].append(knn)\n            dic['recall'].append(recall)\n            dic['precision'].append(precision)\n            dic['f1'].append(F1)\n            dic['roc_auc'].append(roc_auc)\n            \n    df_scores = pd.DataFrame(dic)\n    max_index = df_scores[score].idxmax()\n    return df_scores.iloc[max_index, 0]","4c84ac21":"def logistic_validate(X_trian, X_validate, y_train, y_validate, score='recall'):\n    dic = {'clf':[], 'recall':[], 'precision':[], 'f1':[], 'roc_auc':[]}\n    \n    weights = []\n    for i in np.arange(0.01,1,0.05):\n        weights.append({0:1 - i, 1:i})\n\n    weights.append('balanced')\n    \n    # the weights are the weight of each class in the classification\n    \n    for weight in weights: \n        \n        logistic = LogisticRegression(class_weight=weight,random_state=42, max_iter=1000)\n        logistic.fit(X_train, y_train)\n        precision, recall, roc_auc, F1 = predict_and_score(logistic, X_validate, y_validate, 'binary')\n        dic['clf'].append(logistic)\n        dic['recall'].append(recall)\n        dic['precision'].append(precision)\n        dic['f1'].append(F1)\n        dic['roc_auc'].append(roc_auc)\n    df_scores = pd.DataFrame(dic)\n    max_index = df_scores[score].idxmax()\n    return df_scores.iloc[max_index, 0]","8579b563":"def gnb_validate(X_train, X_validate, y_train, y_validate, score='recall'):\n    dic = {'clf':[], 'recall':[], 'precision':[], 'f1':[], 'roc_auc':[]}\n    \n    #var_smoothing adds a value to the distribution's variance to smooth out the curve \n    for var in np.logspace(0,-9, num=100): \n        gnb = GaussianNB(var_smoothing=var)\n        gnb.fit(X_train, y_train)\n        precision, recall, roc_auc, F1 = predict_and_score(gnb, X_validate, y_validate, 'binary')\n        dic['clf'].append(gnb)\n        dic['recall'].append(recall)\n        dic['precision'].append(precision)\n        dic['f1'].append(F1)\n        dic['roc_auc'].append(roc_auc)\n    df_scores = pd.DataFrame(dic)\n    max_index = df_scores[score].idxmax()\n    return df_scores.iloc[max_index, 0]","f3014ecf":"def draw_roc_curve(clf,X_test,y_test):\n    y_predict =  clf.predict_proba(X_test)\n    y_pred_proba = y_predict[::,1]\n    fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n    auc = roc_auc_score(y_test, y_pred_proba)\n    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()","7f503183":"def train_test(clf, X_train, X_test, y_train, y_test):\n    clf.fit(X_train, y_train)\n    return predict_and_score(clf, X_test, y_test)","ba345647":"X_train, X_validate, X_test, y_train, y_validate, y_test = split(df)\nbest_knn = knn_validate(X_train, X_validate, y_train, y_validate)\nprint(best_knn)\nprecision,recall,f1,roc_auc = train_test(best_knn, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_knn,X_test,y_test)","585d2359":"encoded_columns =['symptom1', 'symptom2', 'symptom3', 'symptom4', 'symptom5', 'symptom6', 'location', 'country']\ndf_encoded = encode(encoded_columns, df)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\nbest_knn = knn_validate(X_train, X_validate, y_train, y_validate)\nprint(best_knn)\nprecision,recall,f1,roc_auc = train_test(best_knn, X_train, X_test, y_train, y_test)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_knn,X_test,y_test)","bc0fe908":"scaled_columns=['diff_sym_hos']\ndf_scaled = scale(scaled_columns,df_encoded )\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_knn = knn_validate(X_train, X_validate, y_train, y_validate)\nprint(best_knn)\nprecision,recall,f1,roc_auc = train_test(best_knn, X_train, X_test, y_train, y_test)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_knn,X_test,y_test)","be14abbb":"scaled_columns =['age', 'diff_sym_hos']\ndf_scaled = scale(scaled_columns,df_encoded )\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_knn = knn_validate(X_train, X_validate, y_train, y_validate)\nprint(best_knn)\nprecision,recall,f1,roc_auc = train_test(best_knn, X_train, X_test, y_train, y_test)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_knn,X_test,y_test)","5e97a936":"dropped_columns = ['symptom2', 'symptom3', 'symptom6']\nencoded_columns =['location', 'symptom1','country','symptom4','symptom5']\nscaled_columns=['diff_sym_hos']\ndf_dropped = drop(dropped_columns, df)\ndf_encoded = encode(encoded_columns,df_dropped)\ndf_scaled = scale(scaled_columns,df_encoded )\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_knn = knn_validate(X_train, X_validate, y_train, y_validate)\nprint(best_knn)\nprecision,recall,f1,roc_auc = train_test(best_knn, X_train, X_test, y_train, y_test)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_knn,X_test,y_test)","42a8e959":"dropped_columns = ['symptom2', 'symptom3','symptom5', 'symptom6','country','symptom4']\nencoded_columns =['location', 'symptom1']\nscaled_columns=['diff_sym_hos']\ndf_dropped = drop(dropped_columns, df)\ndf_encoded = encode(encoded_columns,df_dropped)\ndf_scaled = scale(scaled_columns,df_encoded )\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_knn = knn_validate(X_train, X_validate, y_train, y_validate)\nprint(best_knn)\nprecision,recall,f1,roc_auc = train_test(best_knn, X_train, X_test, y_train, y_test)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_knn,X_test,y_test)","ec15cdfa":"dropped_columns = ['symptom2', 'symptom3','symptom6']\nencoded_columns =['location', 'symptom1','symptom5','country','symptom4']\nscaled_columns=['diff_sym_hos']\ndf_dropped = drop(dropped_columns, df)\ndf_encoded = encode(encoded_columns,df_dropped)\ndf_scaled = scale(scaled_columns,df_encoded)\nx = df_scaled.drop('result', axis=1)\ny = df_scaled['result']\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,shuffle=True, random_state=42)\nparameters = {'n_neighbors': np.arange(1, int(len(X_train) ** 0.5), 2),\n     'weights':['distance','uniform']}\nknn = KNeighborsClassifier()\ngrid_search = GridSearchCV(knn, parameters, scoring='recall', cv=5)\ngrid_search.fit(X_train, y_train)\nbest_knn = grid_search.best_estimator_\nbest_knn.fit(X_train, y_train)\ny_predict = best_knn.predict(X_test)\nprecision= precision_score(y_test, y_predict,average=None)\nrecall = recall_score(y_test,y_predict,average=None)\nroc_auc = roc_auc_score(y_test, y_predict)\nf1 = f1_score(y_test.values, y_predict)\nprint(best_knn)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_knn,X_test,y_test)","081f4dc2":"dropped_columns = ['symptom2', 'symptom3','symptom5', 'symptom6','country','symptom4']\nencoded_columns =['location', 'symptom1']\nscaled_columns=['diff_sym_hos']\ndf_kfold = drop(dropped_columns,df)\ndf_kfold = encode(encoded_columns, df_kfold)\ndf_kfold = scale(scaled_columns,df_kfold)\n\nparameters = {'n_neighbors': np.arange(1, int(len(X_train) ** 0.5), 2),\n     'weights':['distance','uniform']}\nknn = KNeighborsClassifier()\ngrid_search = GridSearchCV(knn, parameters, scoring='recall', cv=5)\n\ntraining_set, testing_set = train_test_split(df_kfold, test_size=0.3,shuffle=True, random_state=42)\nX_training = training_set.drop('result', axis=1)\ny_training = training_set['result']\nKFolds = RepeatedStratifiedKFold(n_splits = 5,n_repeats=5, random_state=42)\n\ncustom_scorer = {'accuracy': make_scorer(accuracy_score),\n                 'precision': make_scorer(precision_score, average='binary'),\n                 'recall': make_scorer(recall_score, average='binary'),\n                 'f1': make_scorer(f1_score,average='binary'),\n                 'aoc_roc': make_scorer(roc_auc_score)\n                 }\n\nmetrics = cross_validate(grid_search,X_training.values,y_training.values,scoring = custom_scorer, cv = KFolds,return_estimator= True)","5b5530c1":"X_test = testing_set.drop('result', axis=1)\ny_test = testing_set['result']\nmetrics2 = pd.DataFrame(metrics)\nmax_index = metrics2['test_recall'].idxmax()\nbest_knn = metrics2.iloc[max_index, 2].best_estimator_\nprint(best_knn)\nprecision,recall,f1,roc_auc = predict_and_score(best_knn, X_test, y_test)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_knn,X_test,y_test)","266b0764":"# X_train, X_validate, X_test, y_train, y_validate, y_test = split(df)\n# best_logistic = logistic_validate(X_train, X_validate, y_train, y_validate)\n# print(best_logistic)\n# precision,recall,f1,roc_auc = train_test(best_logistic, X_train, X_test, y_train, y_test)\n# print(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\n# draw_roc_curve(best_logistic,X_test,y_test)","173e06fc":"encoded_columns =['symptom1', 'symptom2', 'symptom3', 'symptom4', 'symptom5', 'symptom6', 'location', 'country']\ndf_encoded = encode(encoded_columns, df)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\nbest_logistic = logistic_validate(X_train, X_validate, y_train, y_validate)\nprint(best_logistic)\nprecision,recall,f1,roc_auc = train_test(best_logistic, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_logistic,X_test,y_test)","e5892bc5":"scaled_columns=['diff_sym_hos']\ndf_scaled = scale(scaled_columns, df_encoded)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_logistic = logistic_validate(X_train, X_validate, y_train, y_validate)\nprint(best_logistic)\nprecision,recall,f1,roc_auc = train_test(best_logistic, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_logistic,X_test,y_test)","3434f6b7":"scaled_columns=['age','diff_sym_hos']\ndf_scaled = scale(scaled_columns, df_encoded)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_logistic = logistic_validate(X_train, X_validate, y_train, y_validate)\nprint(best_logistic)\nprecision,recall,f1,roc_auc = train_test(best_logistic, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_logistic,X_test,y_test)","3b8e82a4":"dropped_columns = ['symptom2', 'symptom3', 'symptom6']\nencoded_columns =['location', 'symptom1','country','symptom4','symptom5']\nscaled_columns=['diff_sym_hos']\ndf_dropped = drop(dropped_columns, df)\ndf_encoded = encode(encoded_columns,df_dropped)\ndf_scaled = scale(scaled_columns, df_encoded)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_logistic = logistic_validate(X_train, X_validate, y_train, y_validate)\nprint(best_logistic)\nprecision,recall,f1,roc_auc = train_test(best_logistic, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_logistic,X_test,y_test)","14679e10":"dropped_columns = ['symptom2','symptom3' ,'symptom4', 'symptom5', 'symptom6']\nencoded_columns =['symptom1', 'location','country']\nscaled_columns=['diff_sym_hos']\ndf_dropped = drop(dropped_columns, df)\ndf_encoded = encode(encoded_columns,df_dropped)\ndf_scaled = scale(scaled_columns, df_encoded)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_logistic = logistic_validate(X_train, X_validate, y_train, y_validate)\nprint(best_logistic)\ntrain_test(best_logistic, X_train, X_test, y_train, y_test)\nprecision,recall,f1,roc_auc = train_test(best_logistic, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_logistic,X_test,y_test)","30fb8329":"dropped_columns = ['symptom2', 'symptom3','symptom6']\nencoded_columns =['location', 'symptom1','symptom5','country','symptom4']\nscaled_columns=['diff_sym_hos']\n\ndf_dropped = drop(dropped_columns, df)\ndf_encoded = encode(encoded_columns,df_dropped)\n\ndf_scaled = scale(scaled_columns,df_encoded)\nx = df_scaled.drop('result', axis=1)\ny = df_scaled['result']\n\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,shuffle=True, random_state=42)\n\nweights = []\nfor i in np.arange(0.01,1,0.05):\n    weights.append({0:1 - i, 1:i})\n\nweights.append('balanced')\n\nparameters = {'class_weight':weights}\n\nlogistic = LogisticRegression(random_state=42)\ngrid_search = GridSearchCV(logistic, parameters, scoring='recall', cv=5)\ngrid_search.fit(X_train, y_train)\nbest_logistic = grid_search.best_estimator_\nbest_logistic.fit(X_train, y_train)\n\ny_predict = best_logistic.predict(X_test)\nprecision= precision_score(y_test, y_predict,average=None)\nrecall = recall_score(y_test,y_predict,average=None)\nroc_auc = roc_auc_score(y_test, y_predict)\nf1 = f1_score(y_test.values, y_predict)\n\nprint(best_logistic)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_logistic,X_test,y_test)","ab505290":"df = pd.read_csv('..\/input\/covid19-deaths-data\/data.csv',index_col=0)\n#Negative hours changed to positive\nfor i in range(len(df)):\n    df.iloc[i, 12] = df.iloc[i,12]*-1 if df.iloc[i, 12] < 0 else df.iloc[i, 12]\n\n#Gender value 2 changed to the most common gender\ndf['gender'] = df['gender'].mask(df['gender'] == 2, 1)","5ed01dcf":"#This cell takes some time to run \ndropped_columns = ['symptom2', 'symptom3','symptom5', 'symptom6','country','symptom4']\nencoded_columns =['location', 'symptom1']\nscaled_columns=['diff_sym_hos']\n\ndf_kfold_logist = drop(dropped_columns,df)\ndf_kfold_logist = encode(encoded_columns, df_kfold_logist)\ndf_kfold_logist = scale(scaled_columns,df_kfold_logist)\n\n\n\nweights = []\n\nfor i in np.arange(0.01,1,0.05):\n    weights.append({0:1 - i, 1:i})\n\nweights.append('balanced')\n\nparameters = {'class_weight':weights}\n\nlogistic = LogisticRegression(random_state=42)\ngrid_search = GridSearchCV(logistic, parameters, scoring='recall', cv=5)\n\ntraining_set, testing_set = train_test_split(df_kfold_logist, test_size=0.3,shuffle=True, random_state=42)\nX_training = training_set.drop('result', axis=1)\ny_training = training_set['result']\nKFolds = RepeatedStratifiedKFold(n_splits = 5,n_repeats=5, random_state=42)\n\ncustom_scorer = {'accuracy': make_scorer(accuracy_score),\n                 'precision': make_scorer(precision_score, average='binary'),\n                 'recall': make_scorer(recall_score, average='binary'),\n                 'f1': make_scorer(f1_score,average='binary'),\n                 'aoc_roc': make_scorer(roc_auc_score)\n                 }\n\nmetrics = cross_validate(grid_search,X_training.values,y_training.values,scoring = custom_scorer, cv = KFolds,return_estimator= True)","72dca42e":"X_test = testing_set.drop('result', axis=1)\ny_test = testing_set['result']\n\nmetrics2 = pd.DataFrame(metrics)\nmax_index = metrics2['test_recall'].idxmax()\nbest_logistic = metrics2.iloc[max_index, 2].best_estimator_\n\nprint(best_logistic)\nprecision,recall,f1,roc_auc = predict_and_score(best_logistic, X_test, y_test)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_logistic,X_test,y_test)","d6341977":"X_train, X_validate, X_test, y_train, y_validate, y_test = split(df)\ndf_nn = pd.DataFrame()\nbest_gnb = gnb_validate(X_train, X_validate, y_train, y_validate)\nprint(best_gnb)\nprecision,recall,f1,roc_auc = train_test(best_gnb, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_gnb,X_test,y_test)","bc50c2e2":"encoded_columns =['symptom1', 'symptom2', 'symptom3', 'symptom4', 'symptom5', 'symptom6', 'location', 'country']\ndf_encoded = encode(encoded_columns, df)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_encoded)\nbest_gnb = gnb_validate(X_train, X_validate, y_train, y_validate)\nprint(best_gnb)\nprecision,recall,f1,roc_auc = train_test(best_gnb, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_gnb,X_test,y_test)","0bad3634":"# scaled_columns =['age', 'diff_sym_hos']\nscaled_columns=['diff_sym_hos']\ndf_scaled = scale(scaled_columns, df)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_gnb = gnb_validate(X_train, X_validate, y_train, y_validate)\nprint(best_gnb)\nprecision,recall,f1,roc_auc = train_test(best_gnb, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_gnb,X_test,y_test)","c3966df7":"scaled_columns =['age', 'diff_sym_hos']\ndf_scaled = scale(scaled_columns, df)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_gnb = gnb_validate(X_train, X_validate, y_train, y_validate)\nprint(best_gnb)\nprecision,recall,f1,roc_auc = train_test(best_gnb, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_gnb,X_test,y_test)","6392d6c2":"df_bayes = df[['age','diff_sym_hos','result','location','vis_wuhan']]\ndf_scaled = scale(['location','diff_sym_hos'], df_bayes)\nX_train, X_validate, X_test, y_train, y_validate, y_test = split(df_scaled)\nbest_gnb = gnb_validate(X_train, X_validate, y_train, y_validate)\nprint(best_gnb)\nprint(df_bayes.columns)\nprecision,recall,f1,roc_auc = train_test(best_gnb, X_train, X_test, y_train, y_test)\nprint(f\"\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_gnb,X_test,y_test)","433bb922":"df_bayes = df[['age','diff_sym_hos','result','location','vis_wuhan']]\ndf_scaled = scale(['location', 'diff_sym_hos'], df_bayes)\nx = df_scaled.drop('result', axis=1)\ny = df_scaled['result']\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,shuffle=True, random_state=42)\n\nparameters = {'var_smoothing': np.logspace(0,-9, num=100)}\n\ngnb = GaussianNB()\ngrid_search = GridSearchCV(gnb, parameters, scoring='recall', cv=5)\ngrid_search.fit(X_train, y_train)\nbest_gnb = grid_search.best_estimator_\nbest_gnb.fit(X_train, y_train)\n\ny_predict = best_gnb.predict(X_test)\nprecision= precision_score(y_test, y_predict,average=None)\nrecall = recall_score(y_test,y_predict,average=None)\nroc_auc = roc_auc_score(y_test, y_predict)\nf1 = f1_score(y_test.values, y_predict)\n\nprint(best_gnb)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_gnb,X_test,y_test)","c01589b7":"df_bayes = df[['age','diff_sym_hos','result','location','vis_wuhan']]\ndf_scaled = scale(['location', 'diff_sym_hos'], df_bayes)\n\n\nparameters = {'var_smoothing': np.logspace(0,-9, num=100)}\n\ngnb = GaussianNB()\ngrid_search = GridSearchCV(gnb, parameters, scoring='recall', cv=5)\n\ntraining_set, testing_set = train_test_split(df_scaled, test_size=0.3,shuffle=True, random_state=42)\nX_training = training_set.drop('result', axis=1)\ny_training = training_set['result']\nKFolds = RepeatedStratifiedKFold(n_splits = 5,n_repeats=5, random_state=42)\n\ncustom_scorer = {'accuracy': make_scorer(accuracy_score),\n                 'precision': make_scorer(precision_score, average='binary'),\n                 'recall': make_scorer(recall_score, average='binary'),\n                 'f1': make_scorer(f1_score,average='binary'),\n                 'aoc_roc': make_scorer(roc_auc_score)\n                 }\n\nmetrics = cross_validate(grid_search,X_training.values,y_training.values,scoring = custom_scorer, cv = KFolds,return_estimator= True)","f4807f1a":"X_test = testing_set.drop('result', axis=1)\ny_test = testing_set['result']\nmetrics2 = pd.DataFrame(metrics)\nmax_index = metrics2['test_recall'].idxmax()\nbest_gnb = metrics2.iloc[max_index, 2].best_estimator_\nprint(best_gnb)\nprecision,recall,f1,roc_auc = predict_and_score(best_gnb,X_test, y_test)\nprint(f\"Precision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_gnb,X_test,y_test)","519168c4":"models_comparision_dic = {\n    'model':['KNN', 'Logistic Regression', 'Naive Bayes'],\n    'optimal_hyperparameters': ['k = 1, weights = distance', 'class weights: {0: 0.14, 1: 0.86}', 'var_smoothing: 5.3366992312063123e-05'],\n    'precision': ['zero class = 0.96, one class = 0.88',  'zero: 0.98, one class = 0.68 ', ' zero class = 0.96, one class = 0.89'],\n    'recall': ['zero class = 0.98, one class = 0.79' ,'zero class = 0.93, one class = 0.89','zero class = 0.99, one class = 0.75 ' ],\n    'F1': [0.83, 0.77 ,  0.81],\n    'ROC_AUC': [0.89, 0.91 , 0.87]\n}\n\nmodels_comaprision_df = pd.DataFrame(models_comparision_dic)\nmodels_comaprision_df","9a7bbab5":"df_bayes = df[['age','diff_sym_hos','result','location','vis_wuhan']]\ndf_scaled = scale(['location', 'diff_sym_hos'], df_bayes)\n\nx = df_scaled.drop('result', axis=1)\ny = df_scaled['result']\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,shuffle=True, random_state=42)\n\ngnb_bagging = GaussianNB()\nbagging_classifier = BaggingClassifier(gnb_bagging, random_state=42, max_samples=1.0)\n\nparameters = {\n    'base_estimator__var_smoothing':np.logspace(0,-9, num=100),\n    'max_features': np.arange(2, 13, 1),\n}\n\ngrid_search = GridSearchCV(bagging_classifier, parameters, scoring='recall', cv=5)\nbest_gnb = grid_search.fit(X_train, y_train)\nbest_gnb.fit(X_train, y_train)\ny_predict = best_gnb.predict(X_test)","0a8db4e2":"accuracy = accuracy_score(y_test,y_predict)\nprecision= precision_score(y_test, y_predict,average=None)\nrecall = recall_score(y_test,y_predict,average=None)\nroc_auc = roc_auc_score(y_test, y_predict)\nF1 = f1_score(y_test, y_predict)\nprint(best_gnb.best_estimator_)\n\nprint(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1: {f1}\\nROC_AUC: {roc_auc}\")\ndraw_roc_curve(best_gnb,X_test,y_test)","6d7829ca":"## Scaling \nWe then scale the values of the larger dimensions such as 'diff_sym_hos'. In theory we should also scale the age feature, however, experimentally not scaling age results in better metrics. This is explainable by the fact that the result is highly correleated with age, which we know about COVID from a medical perpective. So as such the model should highly favour age in its classification of the result.","ca1ef5e9":"## Hyperparamter Tuning Using Training, Validation, and Test Sets\nFirst we attempt to get the best hyperparameters by splitting the data in training, validation, and Test sets and then fitting different models with different hyperparameters and evaluating the performance on the validation set. We then test the best model using the testing data to obtain our metrics.","2cf56eb0":"## Using RepeatedStratifiedKFold and cross_validate","14a4bebe":"## No encoding\nFirst we attempt to fit the model without any changes to act as a baseline.","1b3049b6":"This function takes a classifier and the training and testing set. To fit the model then perform testing and return the evaluation metrics.","24dcb103":"## Feature Selection\nPreviously, we discussed how symptoms 1, 2, and 3 were highly correleated with one another. Additionally, symptom6 had very little correlation with the result. So we drop symptoms 2 and 3 and leave symptom1, then drop symptom6.","93a5af52":"## No encoding\nFirst we attempt to fit the model without any changes to act as a baseline.","e1c59399":"Next, we create a correlation graph between all the features within the dataset.","975d7573":"## Using RepeatedStratifiedKFold and cross_validate","11b4a5d9":"> By inspecting the correlation matrix we can observe that the result is highly correlated with \"age\" and \"diff_sym_hos\".\n>\n> Furthermore, there is a large correlation between symptom2 and symptom1, symptom3 and symptom2.\n>\n> Additionally, we can see there is very little correlation between the result and symptom6 and symptom5.","6aa37574":"The following three methods perform hyperparameter tuning on the different required algorithms by providing them with the training set and the validation set and the metric on which the performance of the models is evaluated, then they return the best hyperparamteres found.\n\nHere we use recall as the default metric for evaluation as we need to increase the rate \n\n$ True Positive \/ (True Positive + False Negative) $\n\nWhich means of all the people who are going to die we classify as many as possible correctly.","3187e870":"# Gaussian Naive Bayes","3579e3e8":"> This shows experimentally that 'age' should not be scaled.","a0532307":"## One-Hot Encoding\nWe then encode some of the categorical data in the dataset to improve the metrics. In logistic regression we need to make sure none of the features are dependant on each other and as such we remove one of each of the hot-encoded columns.","1eea103e":"## Using GridSearch to Find Optimal Hyperparameters and Perform Cross-Validation","ed207ae6":"## One-Hot Encoding\nWe then encode some of the categorical data in the dataset to improve the metrics.","ecc81bac":"### No Encoding\nFirst we attempt to fit the model without any changes to act as a baseline.","5e47261f":"## Further Experimentation\nHere we experimentally select features. After some experiments this is the best result.","2501d061":"> This shows experimentally that 'age' should not be scaled.","d3a8a6d4":"## Final Model\nWe recommend using the model found in the \"Feature Selection\" section. As it leads to the highest values of recall.\n\n\nLogisticRegression(class_weight={0: 0.1399999999999999, 1: 0.8600000000000001},\n                   max_iter=1000, random_state=42)\n\nPrecision: [0.98095238 0.68      ]\n\nRecall: [0.92792793 0.89473684]\n\nF1: 0.7727272727272727\n\nROC_AUC: 0.9113323850165955\n\n ","e1769960":"While scaling the 'age' feature increased the recall of the positive class, the precision sharply fell to a point where the model is no longer useful. So we do not scale the age.","d4d72a6e":"## Further Experimentation\nHere we experimentally select features. After some experiments this is the best result.","617b37ab":"While this yields a decent recall in the positive class, however, the precision of the positive class is too low to be useful.","1903c436":"## One-Hot Encoding\nWe then encode some of the categorical data in the dataset to improve the metrics.","0c852216":"While this yields a decent recall in the positive class, however, the precision of the positive class is too low to be useful.","ee9abeb9":"## Scaling\nWe then scale the values of the larger dimensions such as 'diff_sym_hos'. In theory we should also scale the age feature, however, experimentally not scaling age results in better metrics. This is explainable by the fact that the result is highly correleated with age, which we know about COVID from a medical perpective. So as such the model should highly favour age in its classification of the result.","1e5a6020":"# Classifying COVID-19 Deaths Using KNN, Logistic Regression, and Naive Bayes\n## by Mostafa Lotfy and Youssef Maher","ea86d491":"While the recall increased the precision of the model sharply fell, this prompts us to not encode our data later on.","d12c8152":"## Final Model\nWe recommend using the model found in the \"Using GridSearch to Find Optimal Hyperparameters and Perform Cross-Validation\" section. As it leads to the highest values of recall.\n\nGaussianNB(var_smoothing=5.3366992312063123e-05)\n\nPrecision: [0.96551724 0.88888889]\n\nRecall: [0.98678414 0.75      ]\n\nF1: 0.8135593220338982\n\nROC_AUC: 0.8683920704845816\n","50545be7":"# Logistic Regression","75575d46":"# Bonus Section: Utilising Bagging Classifier to Improve Naive Bayes","9acf6dc6":"## Using GridSearch to Find Optimal Hyperparameters and Perform Cross-Validation","ed0c48b6":"## Scaling\nWe then scale the values of the larger dimensions such as 'diff_sym_hos'. In theory we should also scale the age feature, however, experimentally not scaling age results in better metrics. This is explainable by the fact that the result is highly correleated with age, which we know about COVID from a medical perpective. So as such the model should highly favour age in its classification of the result.","51321a7b":"# KNN","77edc7d8":"## Using GridSearch to Find Optimal Hyperparameters and Perform Cross-Validation","8ec2c128":"## Hyperparamter Tuning Using Training, Validation, and Test Sets\nFirst we attempt to get the best hyperparameters by splitting the data in training, validation, and Test sets and then fitting different models with different hyperparameters and evaluating the performance on the validation set. We then test the best model using the testing data to obtain our metrics.","a34fe5fd":"## Hyperparamter Tuning Using Training, Validation, and Test Sets\nFirst we attempt to get the best hyperparameters by splitting the data in training, validation, and Test sets and then fitting different models with different hyperparameters and evaluating the performance on the validation set. We then test the best model using the testing data to obtain our metrics.","d84108e0":"## Final Model\nWe recommend using the model found in the \"Further experimentation\" section. As it leads to the highest values of recall.\n\nKNeighborsClassifier(n_neighbors=1, weights='distance')\n\nPrecision: [0.96460177 0.88235294]\n\nRecall: [0.98198198 0.78947368]\n\nF1: 0.8333333333333333\n\nROC_AUC: 0.8857278330962541","89b7860c":"We then analyze our data visually by plotting histograms of each feature.","38bad465":"We read the data from the 'data.csv' file and then look at the numerical summary of the different columns.","638a73c6":"## Feature Selection\nFor Gaussian Naive Bayes we chose to add only the features that are from a gaussian distribution to our features these included: age,diff_sym_hos.\n\nAdditionally, through experimentation it was found that the 'location' and 'vis_wuhan' features added to the model's metrics.","7cefd2bf":"## Using RepeatedStratifiedKFold and cross_validate","7e479aa4":"# Comparison Between the Different Algorithms","ca53313f":"# Cleaning\nBy inspecting the values in the different columns we noticed some irregular values especially in the gender and diff_sym_hos columns.","b87c7db2":"This method is given a classifier and the testing data and then returns the different evaluation metrics needed. For precision and recall metrics the value of the metric of the zero-class is shown first then the positive class.","de57d282":"## Feature Selection\nPreviously, we discussed how symptoms 1, 2, and 3 were highly correleated with one another. Additionally, symptom6 had very little correlation with the result. So we drop symptoms 2 and 3 and leave symptom1, then drop symptom6.","65c0c51e":"# Functions\nThese methods will be used to perform different operations such as dropping, encoding, and scaling features in the data. As well as splitting the dataframe to train, test, and validation sets.","052d3739":"First we import some libraries and methods that will prove useful later on."}}