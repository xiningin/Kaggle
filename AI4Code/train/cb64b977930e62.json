{"cell_type":{"e702e30a":"code","2e193ee6":"code","ec963b9b":"code","342f94f5":"code","1692c642":"code","b21e355e":"code","db4924ae":"code","346a912f":"code","491bdda4":"code","9813da0c":"code","ec7beb12":"code","85f86450":"code","ef4a0a6e":"code","bb9fb370":"code","d9c3ebc0":"code","f2c17fad":"code","06c35a7f":"code","26f4a679":"code","eb6789e8":"code","56af74e7":"code","bd68b1c6":"code","812ed169":"code","19803257":"code","19641513":"code","9be28398":"code","6ddbc741":"code","06d99aa5":"code","dc513d39":"code","e5a3303c":"code","a5e19594":"code","d1dd4320":"code","ef5776dd":"code","9fb13ce4":"code","40ae8a47":"code","26b2a02b":"code","2762349b":"code","2ab5abcc":"code","7920bc85":"code","3417a7bb":"code","7d5a82f3":"markdown","ead11de5":"markdown","a359a561":"markdown","45c02173":"markdown","c9d24438":"markdown","e928d097":"markdown","eedc847b":"markdown","d7ac1e48":"markdown","6a60b811":"markdown","04d45557":"markdown"},"source":{"e702e30a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2e193ee6":"# Import the necessary library\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom collections import Counter\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nimport pickle\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom itertools import chain","ec963b9b":"df_review = pd.read_csv('\/kaggle\/input\/amazon-music-reviews\/Musical_instruments_reviews.csv')\ndf_review.head()","342f94f5":"# review the head of dataset\ndf_review.head()","1692c642":"# checking the scale of overall rating\nprint('Maximum rating scale of overall rating {}'.format(df_review.overall.max()))\nprint('Minimum rating scale of overall rating {}'.format(df_review.overall.min()))","b21e355e":"# defing the function for adding the category for the feedback\ndef add_category(df):\n\n  if df['overall']==1.0:\n    return \"I hate it\"\n  elif df['overall']==2.0:\n    return \"I don't like it\"\n  elif df['overall'] == 3.0:\n    return \"It's okey\"\n  elif df['overall'] == 4.0:\n    return \"I like it\"\n  elif df['overall'] == 5.0:\n    return \"I love it\"\n  else:\n    return -1\n","db4924ae":"# adding the category in dataframe\ndf_review['category'] = df_review.apply(add_category, axis=1)\nplt.figure(figsize=(6,6))\nplt.title('Percentage of category')\nax = sns.countplot(y = 'category', data = df_review)\ntotal = len(df_review)\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))\n","346a912f":"df_review.head()","491bdda4":"# checking the total number of nan values of each features\ndf_review.isnull().sum()","9813da0c":"# imputing the reviewText features with missing \ndf_review['reviewText'] = df_review.reviewText.fillna('missing')\n\n# concating the reviewText and summary features\ndf_review['review']= df_review['reviewText'] +\" \"+ df_review['summary']\n\n# deleting the summary column\ndf_review.drop(['summary','reviewText'], inplace=True, axis=1)\n","ec7beb12":"df_review.head()","85f86450":"# create a dataframe that has only reviewText and overall rating\ndf = df_review[['review', 'overall']].copy()\ndf.head()","ef4a0a6e":"# defing the funtion for remoing the punctuation\ndef clean(text):\n\n  # converting the all the text into lowercase\n  text = str(text).lower()\n  text = re.sub('\\[.*?\\]', '', text)\n  text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n  text = re.sub('<.*?>+', '', text)\n  text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n  text = re.sub('\\n', '', text)\n  text = re.sub('\\w*\\d\\w*', '', text)\n  return text","bb9fb370":"# apply the clean function on dataframe\ndf['review'] = df.review.apply(lambda x: clean(x))\ndf.head()","d9c3ebc0":"nltk.download('stopwords')","f2c17fad":"# remove the stop_words from the reivew\ndf['review']= df.review.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\ndf.head()","06c35a7f":"nltk.download('wordnet')","26f4a679":"# conveting the words into the root words using the WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\ndf['review'] = df.review.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\ndf.head()","eb6789e8":"# converting the words into base words using stemming method\nps = PorterStemmer()\ndf['review']= df.review.apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\ndf.head()","56af74e7":"# featuers extraction most 5000 best features from the all featues with 1 to 3 gram using TF-IDF\ntfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,3))\nx = tfidf.fit_transform(df['review'])","bd68b1c6":"# label of featuere\ny = df['overall']\nprint('Origonal no samples of each ratting {}'.format(Counter(y)))\nprint('original shape of the input features {}'.format(x.shape))\nprint('origonal shape of the output features {}'.format(y.shape))","812ed169":"# create the SMOTE over_sampling technique object and fit_resample the features\nsm = SMOTE()\nx_res, y_res = sm.fit_resample(x, y)\nprint('Before sampling the  shape of dataset {}'.format(Counter(y)))\nprint('After sampling the shape of dataset {}'.format(Counter(y_res)))","19803257":"# create the test and train set\nx_train, x_test, y_train, y_test = train_test_split(x_res, y_res, random_state=0, test_size=0.25)","19641513":"# model selection\n# cross validation score\ndef cross_validation(model,x,y):\n\n  cross_value_scored = []\n  for model in models:\n      model_name = model.__class__.__name__\n      accuracies= cross_val_score(model, x, y, scoring = 'accuracy', cv = 5)\n      for accuracy in accuracies:\n          cross_value_scored.append((model_name, accuracy))\n  df_cv = pd.DataFrame(cross_value_scored, columns =['model_name', 'accuracy'])\n  acc = pd.concat([df_cv.groupby('model_name').accuracy.mean(),df_cv.groupby('model_name').accuracy.std()], axis= 1,ignore_index=True)\n  acc.columns = ['Mean Accuracy', 'Standard deviation']\n  return acc","9be28398":"# define all the models\nmodels = [\n    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n    XGBClassifier(),\n    LinearSVC(),\n    BernoulliNB(),\n    KNeighborsClassifier()\n    \n]\n# calling the cross_validation function\ncross_validation(models, x_res, y_res)","6ddbc741":"# Training the model and predict \ndef train_predict_final_model(x_train, y_train, x_test):\n  svc = LinearSVC(C=100.0, random_state=0)\n  svc.fit(x_train, y_train)\n  return svc, svc.predict(x_test)","06d99aa5":"# call the train_predict_final_model\nmodel, y_pred = train_predict_final_model(x_train, y_train, x_test)\nprint('Accuracy of the model {}'.format(accuracy_score(y_test, y_pred)))","dc513d39":"# plot the confusion matrix\ndef confusion_matrix_plot(y_test, y_pred):\n  cm = confusion_matrix(y_test, y_pred)\n  fig, ax = plt.subplots(figsize=(8,8))\n  sns.heatmap(cm, annot=True, cmap = 'Reds',square = True,xticklabels = [1,2,3,4,5],yticklabels=[1,2,3,4,5])\n  plt.ylabel('Actual')\n  plt.xlabel('Predicted')\n  plt.title('Confusion Matrix.')\n\n# calling the confusion_matrix_plot function\nconfusion_matrix_plot(y_test, y_pred)","e5a3303c":"print('Accuracy of the model {}'.format(accuracy_score(y_test, y_pred)))","a5e19594":"# report of the model\nprint('Report of the model {}'.format(classification_report(y_test, y_pred)))","d1dd4320":"# ploting the learning curver\ndef plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n   \n       \n    if axes is None:\n        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n    axes[0].set_title(title)\n    if ylim is not None:\n        axes[0].set_ylim(*ylim)\n    axes[0].set_xlabel(\"Training examples\")\n    axes[0].set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,train_sizes=train_sizes,return_times=True)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    fit_times_mean = np.mean(fit_times, axis=1)\n    fit_times_std = np.std(fit_times, axis=1)\n\n    # Plot learning curve\n    axes[0].grid()\n    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,train_scores_mean + train_scores_std, alpha=0.1,color=\"r\")\n    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1,color=\"g\")\n    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n    axes[0].legend(loc=\"best\")\n\n    # Plot n_samples vs fit_times\n    axes[1].grid()\n    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,fit_times_mean + fit_times_std, alpha=0.1)\n    axes[1].set_xlabel(\"Training examples\")\n    axes[1].set_ylabel(\"fit_times\")\n    axes[1].set_title(\"Scalability of the model\")\n\n    # Plot fit_time vs score\n    axes[2].grid()\n    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,test_scores_mean + test_scores_std, alpha=0.1)\n    axes[2].set_xlabel(\"fit_times\")\n    axes[2].set_ylabel(\"Score\")\n    axes[2].set_title(\"Performance of the model\")\n\n    return plt","ef5776dd":"title = 'Learning curve of LinearSVC'\ncv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\nestimator = LinearSVC(C=100.0)\nplot_learning_curve(estimator, title, x_res, y_res,  ylim=(0.7, 1.01),cv=cv, n_jobs=4)","9fb13ce4":"# rating of the insturiments\nplt.figure(figsize=(6,6))\nplt.title('Rating of the Musical Instruments')\nax = sns.countplot(y = 'overall', data = df_review)\ntotal = len(df_review)\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()\/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()\/2\n        ax.annotate(percentage, (x, y))","40ae8a47":"all_words = df.review.values\nnegtive_words= df[df.overall <= 2.0]['review'].values\npositive_words = df[df.overall >= 4.0]['review'].values","26b2a02b":"# conert string of list to word of list\ndef string_to_word(words):\n  word = []\n  for w in words:\n    word.append(w.split())\n  return word","2762349b":"# 10 most frequnt words\ndef most_frequent(word, title):\n  word = string_to_word(word)\n  word = list(chain.from_iterable(word))\n  word = Counter(word)\n  freq_words = word.most_common(10)\n\n  y = [x[0] for x in freq_words]\n  x = [x[1] for x in freq_words]\n  plt.title(title)\n  plt.bar(y, x)\n  plt.show()","2ab5abcc":"most_frequent(all_words, '10 Most frequent words')","7920bc85":"most_frequent(negtive_words, '10 Most Negative words')","3417a7bb":"most_frequent(positive_words, '10 most positive words')","7d5a82f3":"* **NOTE:We should the categorize the opnion of the feedback based on the overall rating because overall rating indicate that how much customers are satisfied from that product. <br>**\n\n* Rating and there General Meaning are follows <br>\n<pre>\n    Rating            General Meaning\n    1.0               I hate it.\n    2.0               I don't like it.\n    3.0               It's okey.\n    4.0               I like it.\n    5.0               I love it.\n<\/pre>\n\n","ead11de5":"+ we can easly see that five classess has different number of samples so we need to handle this\n+ we are using the over_sampling technique to handle the imbalance dataset","a359a561":"* Our goal is predict the overall rating based on the comment\/ review\n* so review\/comment is input feature and overall rating is the label\n* This problem is mutliclass classification problem","45c02173":"+ You have to classify individual comments\/reviews and you have to determine overall rating based on individual comments\/reviews.","c9d24438":"* You have to categorise opinions expressed in feedback forums","e928d097":"+ We can see the above only to two features has nan values reviewerName and reviewText respectively.\n+ we can reviewText row whose values is nan because this is an important features. Curruently imput with missing string.","eedc847b":"+ **We can see the above graph**<br>\n<pre>\n  67.6% customers love the product.\n  7.5% customers it's okey.\n  20.3% customers like the product.\n  2.4% customres don't like the product.\n  2.1% customers hate the product.\n<\/pre>","d7ac1e48":"#### Text Preprocessing","6a60b811":"+ Validate your build model, use any of your choice of validation matrices","04d45557":"Perform an Exploratory Data Analysis for the Text Data (Reviews) and help the organisation to understand better about their customer feedbacks."}}