{"cell_type":{"f07742c3":"code","ae39e1aa":"code","13bfc517":"code","eec2902e":"code","5f82d413":"code","d012c9a0":"code","894e357b":"code","17928aa8":"code","9caa4b02":"code","87426bb7":"code","2b72bdf6":"code","cbd7b118":"code","7af626b1":"code","d80b8a08":"code","c29a3bd3":"code","ba3be7ec":"code","2696f698":"markdown","00d03681":"markdown","ebd16cdf":"markdown","30308792":"markdown","99703efd":"markdown","2bcda68e":"markdown","7d96d581":"markdown"},"source":{"f07742c3":"%config Completer.use_jedi = False\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle\n\nfrom sklearn.model_selection import train_test_split \n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *","ae39e1aa":"train = pd.read_csv('..\/input\/challenges-in-representation-learning-facial-expression-recognition-challenge\/train.csv')\n\nprint('Training Set Size:', train.shape)","13bfc517":"train.head()","eec2902e":"# Convert the string of pixels to an array\ntrain['pixels'] = [np.fromstring(x, dtype=int, sep=' ').reshape(-1,48,48,1) for x in train['pixels']]","5f82d413":"pixels = np.concatenate(train['pixels'])\nlabels = train.emotion.values\n\nprint(pixels.shape)\nprint(labels.shape)","d012c9a0":"X_train, X_valid, y_train, y_valid = train_test_split(\n    pixels, labels, test_size=0.2, stratify=labels, random_state=1\n)\n\n\nprint('X_train Shape:', X_train.shape)\nprint('y_train Shape:', y_train.shape)\nprint()\nprint('X_valid Shape:', X_valid.shape)\nprint('y_valid Shape:', y_valid.shape)","894e357b":"Xs_train = X_train \/ 255\nXs_valid = X_valid \/ 255","17928aa8":"np.random.seed(1)\ntf.random.set_seed(1)\n\ncnn = Sequential([\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same', input_shape=(48,48,1)),\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.50),\n    BatchNormalization(),\n\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.50),\n    BatchNormalization(),\n    \n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.50),\n    BatchNormalization(),\n\n    Flatten(),\n    \n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    Dropout(0.5),\n    BatchNormalization(),\n    Dense(7, activation='softmax')\n])\n\ncnn.summary()","9caa4b02":"opt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","87426bb7":"%%time\n# Complete one or more training runs. \n# Display training curves after each run.  \n\nh1 = cnn.fit(Xs_train, \n             y_train, \n             batch_size=2048, \n             epochs=50, \n             validation_data=(Xs_valid, y_valid), verbose=1)","2b72bdf6":"history = h1.history\nn_epochs = len(history['loss'])\n\nplt.figure(figsize=[10,4])\nplt.subplot(1,2,1)\nplt.plot(range(1, n_epochs+1), history['loss'], label='Training')\nplt.plot(range(1, n_epochs+1), history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(range(1, n_epochs+1), history['accuracy'], label='Training')\nplt.plot(range(1, n_epochs+1), history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.show()","cbd7b118":"tf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","7af626b1":"%%time \n\nh2 = cnn.fit(Xs_train, \n             y_train, \n             batch_size=2048, \n             epochs=50, \n             validation_data=(Xs_valid, y_valid), verbose=1)","d80b8a08":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","c29a3bd3":"%%time \n\nh3 = cnn.fit(Xs_train, \n             y_train, \n             batch_size=2048, \n             epochs=50, \n             validation_data=(Xs_valid, y_valid), verbose=1)","ba3be7ec":"for k in history.keys():\n    history[k] += h3.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,2,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.show()","2696f698":"# Build CNN Model","00d03681":"# Training Run 2","ebd16cdf":"# Load Data","30308792":"# Training Run 1","99703efd":"# Import Statements","2bcda68e":"# Training Run 3","7d96d581":"# Split, Reshape, and Scale Datasets"}}