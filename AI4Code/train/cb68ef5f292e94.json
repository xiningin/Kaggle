{"cell_type":{"f8641f12":"code","e9352d9f":"code","f3d76418":"code","bc9ec621":"code","03777b25":"code","32fa8a4c":"code","c95f84e6":"code","afb88895":"code","6febae57":"code","1c5cc0b1":"code","16a68423":"code","2b35691d":"markdown","6ff3f99c":"markdown","1982aa5b":"markdown","d8653171":"markdown","281011f8":"markdown","b17b1293":"markdown","023c1dbb":"markdown","b756a88f":"markdown","ac89b71b":"markdown","2cc72bba":"markdown","7c979615":"markdown"},"source":{"f8641f12":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datatable as dt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, InputLayer, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import StratifiedKFold","e9352d9f":"TRAIN_PATH = \"..\/input\/titanic\/train.csv\"\nTEST_PATH = \"..\/input\/titanic\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/titanic\/gender_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"id\"\nTARGET = \"Survived\"\nSEED = 42\nTHRESHOLD = 0.5\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\nBATCH_SIZE = 1024\nEPOCHs = 500\nVERBOSE = 0\n\nDROPOUT_RATE = 0.3\nMODEL_DENSE = 1024\nLAST_MODEL_DENSE = 1\nMID_ACTIVATION = 'swish'\nLAST_ACTIVATION = \"sigmoid\"\nN_SPLILTS = 5\nN_ROUND = 5\n\n\nMONITOR_OBJECT = 'val_loss'\nMODE = \"min\"\nES_PATIENCE = 40\nES_MIN_DELTA = 0\nES_VERBOSE = 0\nRR_PATIENCE = 10\nRR_FACTOR = 0.2\n\nMODEL_NAME = \"MyNN\"\nMODEL_OPTIMIZER = 'adam'\nMODEL_LOSS = \"binary_crossentropy\"\nMODEL_METRICS = ['AUC']\n","f3d76418":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","bc9ec621":"#1. delete unnecessary columns\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntest = test.drop(drop_elements, axis = 1)\n\n#2.find null data and fill new data \ndef checkNull_fillData(df):\n    for col in df.columns:\n        if len(df.loc[df[col].isnull() == True]) != 0:\n            if df[col].dtype == \"float64\" or df[col].dtype == \"int64\":\n                df.loc[df[col].isnull() == True,col] = df[col].mean()\n            else:\n                df.loc[df[col].isnull() == True,col] = df[col].mode()[0]\n                \ncheckNull_fillData(train)\ncheckNull_fillData(test)\n\n#3.one hot encoding \nstr_list = [] \nnum_list = []\nfor colname, colvalue in train.iteritems():\n    if type(colvalue[1]) == str:\n        str_list.append(colname)\n    else:\n        num_list.append(colname)\n        \ntrain = pd.get_dummies(train, columns=str_list)\ntest = pd.get_dummies(test, columns=str_list)","03777b25":"X = train.drop(columns=[TARGET]).copy()\ny = train[TARGET].copy()\n\nX_test = test","32fa8a4c":"# early stopping\nearly_stopping = EarlyStopping(\n    monitor=MONITOR_OBJECT, \n    min_delta=ES_MIN_DELTA, \n    patience=ES_PATIENCE, \n    verbose=ES_VERBOSE,\n    mode=MODE, \n    baseline=None, \n    restore_best_weights=True\n)\n\n#Learning Rate tuning\nreduce_lr = ReduceLROnPlateau(\n    monitor=MONITOR_OBJECT, \n    factor=RR_FACTOR,\n    patience=RR_PATIENCE,\n    mode=MODE\n)","c95f84e6":"def define_model(name:str):\n    model = Sequential(name=name)\n\n    model.add(InputLayer(input_shape=(X.shape[1])))\n    model.add(Flatten())\n\n    model.add(Dense(MODEL_DENSE, activation=MID_ACTIVATION))\n    model.add(Dropout(rate=DROPOUT_RATE))\n    \n    model.add(Dense(MODEL_DENSE, activation=MID_ACTIVATION))\n#     model.add(Dropout(rate=DROPOUT_RATE))\n    \n    model.add(Dense(MODEL_DENSE, activation=MID_ACTIVATION))\n    model.add(Dropout(rate=DROPOUT_RATE))\n    \n    model.add(Dense(MODEL_DENSE, activation=MID_ACTIVATION))\n#     model.add(Dropout(rate=DROPOUT_RATE))\n    \n    model.add(Dense(MODEL_DENSE, activation=MID_ACTIVATION))\n    model.add(Dropout(rate=DROPOUT_RATE))\n    \n    model.add(Dense(MODEL_DENSE, activation=MID_ACTIVATION))\n#     model.add(Dropout(rate=DROPOUT_RATE))\n\n    model.add(Dense(MODEL_DENSE, activation=MID_ACTIVATION))\n    model.add(Dropout(rate=DROPOUT_RATE))\n\n    model.add(Dense(LAST_MODEL_DENSE, activation=LAST_ACTIVATION))\n    \n    return model","afb88895":"### cross-validation \ncv = StratifiedKFold(n_splits=N_SPLILTS, shuffle=True, random_state=SEED)\n\nscores = {fold:None for fold in range(cv.n_splits)}\npredictions = []\n\nfor fold, (idx_train, idx_valid) in enumerate(cv.split(X, y)):\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n\n    model = define_model(name=MODEL_NAME)\n    \n    model.compile(\n        optimizer=MODEL_OPTIMIZER,\n        loss=MODEL_LOSS,\n        metrics=MODEL_METRICS\n    )\n\n    print('**'*20)\n    print(f\"Fold {fold+1} || Training\")\n    print('**'*20)\n    \n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_valid, y_valid),\n        batch_size=BATCH_SIZE,\n        epochs=EPOCHs,\n        verbose=VERBOSE,\n        callbacks=[\n            early_stopping,\n            reduce_lr\n        ]\n    )\n    \n    scores[fold] = (history.history)\n    \n    print(f\"Fold {fold+1} || Mean Validation AUC: {np.mean(scores[fold]['val_auc'])}\")\n    \n    prediction = model.predict(X_test).reshape(1,-1)[0]\n    predictions.append(prediction)","6febae57":"fig, ax = plt.subplots(1, cv.n_splits, tight_layout=True, figsize=(20,2.5))\nax = ax.flatten()\n\nfor fold in range(cv.n_splits):\n    df_eval = pd.DataFrame({'train_loss': scores[fold]['loss'], 'valid_loss': scores[fold]['val_loss']})\n\n    mean_train = np.round(np.mean(df_eval['train_loss']),N_ROUND)\n    mean_valid = np.round(np.mean(df_eval['valid_loss']),N_ROUND)\n    delta = np.round(mean_valid - mean_train,N_ROUND)\n    \n    sns.lineplot(\n        x=df_eval.index,\n        y=df_eval['train_loss'],\n        label='train_loss',\n        ax = ax[fold]\n    )\n\n    sns.lineplot(\n        x=df_eval.index,\n        y=df_eval['valid_loss'],\n        label='valid_loss',\n        ax = ax[fold]\n    )\n    \n    ax[fold].set_ylabel('')\n    ax[fold].set_xlabel(f\"Fold {fold+1}\\nmean_train: {mean_train}\\nmean_valid: {mean_valid}\\ndelta: {delta}\", fontstyle='italic')\n\nsns.despine()","1c5cc0b1":"pred_test = np.mean(np.column_stack(predictions), axis=1)","16a68423":"submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsubmission[TARGET] = (pred_test > THRESHOLD).astype(int)\nsubmission.to_csv(SUBMISSION_PATH, index=False)\nsubmission.head()","2b35691d":"# import libraries","6ff3f99c":"# plot train and valid loss over number of epochs","1982aa5b":"# define callback ","d8653171":"# load data","281011f8":"# global variables","b17b1293":"# split data","023c1dbb":"# build model and predict test data ","b756a88f":"# predicted mean probability","ac89b71b":"# submission","2cc72bba":"# preprocessing","7c979615":"# define model"}}