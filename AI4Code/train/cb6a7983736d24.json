{"cell_type":{"888577d2":"code","c17b6d43":"code","f8b76884":"code","ffc5c29e":"code","d0bc6e98":"code","95fc61c8":"code","34e7e610":"code","d542fe44":"code","4f028b36":"code","61b75017":"code","ee138e02":"code","8fd9113d":"code","717a267c":"code","7eef90fe":"code","d534aa07":"code","b1038280":"code","76b96a30":"code","67779673":"code","25d7e103":"code","2c97c15e":"code","19dea916":"code","36087021":"code","2b12948f":"code","860800be":"code","8abc71fe":"code","48c74c9c":"code","336d6b11":"code","b6ec1099":"code","e9e3b642":"code","994da591":"code","b3d51053":"code","eeaa618a":"markdown","f7cc0ad3":"markdown","c24f059f":"markdown","eca2caa9":"markdown","6af9ed9a":"markdown","0838ea45":"markdown","5f39a299":"markdown","98d0664a":"markdown","cc1500d5":"markdown","ce417ad6":"markdown","31de99f2":"markdown","24acbb90":"markdown"},"source":{"888577d2":"PART_1_SKIP = False\nPART_2_SKIP = False\nPART_3_SKIP = False","c17b6d43":"import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport skimage\nfrom PIL import Image\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.util import crop, pad\nfrom skimage.morphology import label\nfrom skimage.color import rgb2gray, gray2rgb\n\nimport os\n\nimport zipfile\nz = zipfile.ZipFile(\"Dancer_Images.zip\", \"w\")","f8b76884":"cap = cv2.VideoCapture('..\/input\/video-obama\/video_obama.mp4')\nprint(cap.get(cv2.CAP_PROP_FPS))","ffc5c29e":"%%time\n\nif PART_1_SKIP == False:\n    try:\n        \n        if not os.path.exists('data'):\n            os.makedirs('data')\n    except OSError:\n        print ('Error: Creating directory of data')\n\n    currentFrame = 0\n    count = 0\n    TRAIN_SIZE = 27000\n    FRAME_SKIP = 2\n    IMG_WIDTH = 96\n    IMG_HEIGHT = 64\n    IMG_CHANNELS = 1\n    X_train = np.zeros((TRAIN_SIZE, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype='float32')\n    \n    video = cv2.VideoWriter('Simple_Shadow_Dancer_Video.avi',cv2.VideoWriter_fourcc(*\"MJPG\"), 30, (IMG_WIDTH, IMG_HEIGHT), False)\n\n    while(count < TRAIN_SIZE):\n        try:\n            ret, frame = cap.read()\n\n            if currentFrame % FRAME_SKIP == 0:\n                count += 1\n                if count % int(TRAIN_SIZE\/10) == 0:\n                    print(str((count\/TRAIN_SIZE)*100)+\"% done\")\n                # preprocess frames\n                img = frame\n                img = rgb2gray(img)\n                img = resize(img, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), mode='constant', preserve_range=True)\n                img[img > 0.2] = 255\n                img[img <= 0.2] = 0\n                # save frame to zip and new video sample\n                name = '.\/data\/frame' + str(count) + '.jpg'\n                cv2.imwrite(name, img)\n                video.write(gray2rgb(img.astype('uint8')))\n                z.write(name)\n                os.remove(name)\n                # save image to training set if training directly to part 2\n                img = img.astype('float32') \/ 255.\n                X_train[count] = img\n        except:\n            print('Frame error')\n            break\n        currentFrame += 1\n\n    print(str(count)+\" Frames collected\")\n    cap.release()\n    z.close()\n    video.release()","d0bc6e98":"import os\nimport sys\nimport random\nimport warnings\nfrom pylab import imshow, show, get_cmap\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom itertools import chain\nimport skimage\nfrom PIL import Image\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.util import crop, pad\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model, Sequential\nfrom keras.layers import Input, Dense, UpSampling2D, Flatten, Reshape\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\nfrom keras import backend as K\nimport tensorflow as tf\n\nwarnings.filterwarnings('ignore', category=UserWarning, module='skimage')\nseed = 42\nrandom.seed = seed\nnp.random.seed = seed","95fc61c8":"%%time\nif PART_1_SKIP:\n    IMG_WIDTH = 96\n    IMG_HEIGHT = 64\n    IMG_CHANNELS = 1\n    INPUT_SHAPE=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n    TRAIN_PATH = '..\/input\/dancer_images\/data\/'\n    train_ids = next(os.walk(TRAIN_PATH))[2]\n    X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype='float32')\n    missing_count = 0\n    print('Getting training images ... ')\n#     sys.stdout.flush()\n    for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n        path = TRAIN_PATH +'frame'+ str(n+1) + '.jpg'\n        try:\n            img = imread(path)\n            img = img.astype('float32') \/ 255.\n            img = resize(img, (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), mode='constant', preserve_range=True)\n            X_train[n-missing_count] = img\n        except:\n            print(\" Problem with: \"+path)\n            missing_count += 1\n\n    print(\"Done! total missing: \"+ str(missing_count))\nelse:\n    INPUT_SHAPE=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)","34e7e610":"for n in range(10,15):\n    imshow(X_train[n].reshape(IMG_HEIGHT,IMG_WIDTH))\n    plt.show()","d542fe44":"def Encoder():\n    inp = Input(shape=INPUT_SHAPE)\n    x = Conv2D(128, (4, 4), activation='elu', padding='same',name='encode1')(inp)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same',name='encode2')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same',name='encode3')(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same',name='encode4')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same',name='encode5')(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same',name='encode6')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same',name='encode7')(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same',name='encode8')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(32, (3, 3), activation='elu', padding='same',name='encode9')(x)\n    x = Flatten()(x)\n    x = Dense(256, activation='elu',name='encode10')(x)\n    encoded = Dense(128, activation='sigmoid',name='encode11')(x)\n    return Model(inp, encoded)\n\nencoder = Encoder()\nencoder.summary()","4f028b36":"D_INPUT_SHAPE=[128]\ndef Decoder():\n    inp = Input(shape=D_INPUT_SHAPE, name='decoder')\n    x = Dense(256, activation='elu', name='decode1')(inp)\n    x = Dense(768, activation='elu', name='decode2')(x)\n    x = Reshape((4, 6, 32))(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same', name='decode3')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same', name='decode4')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same', name='decode5')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same', name='decode6')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(64, (2, 2), activation='elu', padding='same', name='decode7')(x)\n    x = Conv2D(128, (3, 3), activation='elu', padding='same', name='decode8')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(64, (2, 2), activation='elu', padding='same', name='decode9')(x)\n    x = Conv2D(64, (4, 4), activation='elu', padding='same', name='decode10')(x)\n    x = Conv2D(128, (3, 3), activation='elu', padding='same', name='decode11')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(64, (4, 4), activation='elu', padding='same', name='decode12')(x)\n    x = Conv2D(32, (3, 3), activation='elu', padding='same', name='decode13')(x)\n    x = Conv2D(16, (2, 2), activation='elu', padding='same', name='decode14')(x)\n    decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same', name='decode15')(x)\n    return Model(inp, decoded)\n\ndecoder = Decoder()\ndecoder.summary()","61b75017":"def Autoencoder():\n    inp = Input(shape=INPUT_SHAPE)\n    x = Conv2D(128, (4, 4), activation='elu', padding='same',name='encode1')(inp)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same',name='encode2')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same',name='encode3')(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same',name='encode4')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same',name='encode5')(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same',name='encode6')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same',name='encode7')(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same',name='encode8')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(32, (3, 3), activation='elu', padding='same',name='encode9')(x)\n    x = Flatten()(x)\n    x = Dense(256, activation='elu',name='encode10')(x)\n    encoded = Dense(128, activation='sigmoid',name='encode11')(x)\n    x = Dense(256, activation='elu', name='decode1')(encoded)\n    x = Dense(768, activation='elu', name='decode2')(x)\n    x = Reshape((4, 6, 32))(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same', name='decode3')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same', name='decode4')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(32, (2, 2), activation='elu', padding='same', name='decode5')(x)\n    x = Conv2D(64, (3, 3), activation='elu', padding='same', name='decode6')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(64, (2, 2), activation='elu', padding='same', name='decode7')(x)\n    x = Conv2D(128, (3, 3), activation='elu', padding='same', name='decode8')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(64, (2, 2), activation='elu', padding='same', name='decode9')(x)\n    x = Conv2D(64, (4, 4), activation='elu', padding='same', name='decode10')(x)\n    x = Conv2D(128, (3, 3), activation='elu', padding='same', name='decode11')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(64, (4, 4), activation='elu', padding='same', name='decode12')(x)\n    x = Conv2D(32, (3, 3), activation='elu', padding='same', name='decode13')(x)\n    x = Conv2D(16, (2, 2), activation='elu', padding='same', name='decode14')(x)\n    decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same', name='decode15')(x)\n    return Model(inp, decoded)\n\nmodel = Autoencoder()\nmodel.compile(optimizer='adam', loss='mean_squared_error')\nmodel.summary()","ee138e02":"learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                            patience=4, \n                                            verbose=1, \n                                            factor=0.5,\n                                            min_lr=0.00001)\n\ncheckpoint = ModelCheckpoint(\"Dancer_Auto_Model.hdf5\",\n                             save_best_only=True,\n                             monitor='val_loss',\n                             mode='min')\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                              patience=8,\n                              verbose=1,\n                              mode='min',\n                              restore_best_weights=True)","8fd9113d":"class ImgSample(Callback):\n\n    def __init__(self):\n       super(Callback, self).__init__() \n\n    def on_epoch_end(self, epoch, logs={}):\n        sample_img = X_train[50]\n        sample_img = sample_img.reshape(1, IMG_HEIGHT, IMG_WIDTH, 1)\n        sample_img = self.model.predict(sample_img)[0]\n        imshow(sample_img.reshape(IMG_HEIGHT,IMG_WIDTH))\n        plt.show()\n\n\nimgsample = ImgSample()\nmodel_callbacks = [learning_rate_reduction, checkpoint, early_stopping, imgsample]\nimshow(X_train[50].reshape(IMG_HEIGHT,IMG_WIDTH))","717a267c":"%%time\nif PART_2_SKIP == False:\n    model.fit(X_train, X_train,\n              epochs=30, \n              batch_size=32,\n              verbose=2,\n              validation_split=0.05,\n            callbacks=model_callbacks)\nelse:\n    model = load_model('..\/input\/Dancer_Auto_Model.hdf5')\n    model.load_weights(\"..\/input\/Dancer_Auto_Weights.hdf5\")","7eef90fe":"decoded_imgs = model.predict(X_train)","d534aa07":"plt.figure(figsize=(20, 4))\nfor i in range(5,10):\n    # original\n    plt.subplot(2, 10, i + 1)\n    plt.imshow(X_train[i].reshape(IMG_HEIGHT, IMG_WIDTH))\n    plt.axis('off')\n \n    # reconstruction\n    plt.subplot(2, 10, i + 1 + 10)\n    plt.imshow(decoded_imgs[i].reshape(IMG_HEIGHT, IMG_WIDTH))\n    plt.axis('off')\n \nplt.tight_layout()\nplt.show()","b1038280":"model.save('Dancer_Auto_Model.hdf5')\nmodel.save_weights(\"Dancer_Auto_Weights.hdf5\")","76b96a30":"encoder = Encoder()\ndecoder = Decoder()\n\nencoder.load_weights(\"Dancer_Auto_Weights.hdf5\", by_name=True)\ndecoder.load_weights(\"Dancer_Auto_Weights.hdf5\", by_name=True)\n\n\ndecoder.save('Dancer_Decoder_Model.hdf5') \nencoder.save('Dancer_Encoder_Model.hdf5')\n\ndecoder.save_weights(\"Dancer_Decoder_Weights.hdf5\")\nencoder.save_weights(\"Dancer_Encoder_Weights.hdf5\")","67779673":"encoder_imgs = encoder.predict(X_train)\nprint(encoder_imgs.shape)\nnp.save('Encoded_Dancer.npy',encoder_imgs)","25d7e103":"decoded_imgs = decoder.predict(encoder_imgs[0:11])\n\nplt.figure(figsize=(20, 4))\nfor i in range(5,10):\n    # reconstruction\n    plt.subplot(1, 10, i + 1)\n    plt.imshow(decoded_imgs[i].reshape(IMG_HEIGHT, IMG_WIDTH))\n    plt.axis('off')\n \nplt.tight_layout()\nplt.show()","2c97c15e":"import numpy as np\nimport pandas as pd\nimport keras as K\nimport random\nimport sqlite3\nimport cv2\nimport os\n\nfrom skimage.color import rgb2gray, gray2rgb\nfrom skimage.transform import resize\nfrom skimage.io import imread, imshow\nimport matplotlib.pyplot as plt\n\nfrom keras.layers import Input, Dropout, Dense, concatenate, Embedding\nfrom keras.layers import Flatten, Activation\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.utils import np_utils\n\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.models import load_model\nfrom keras.layers import LSTM, CuDNNGRU, CuDNNLSTM\nfrom keras.layers import MaxPooling1D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n\nimport warnings\nwarnings.filterwarnings('ignore')","19dea916":"if PART_2_SKIP:\n    Dance_Data = np.load('..\/input\/Encoded_Dancer.npy')\nelse:\n    Dance_Data = encoder_imgs\n\nDance_Data.shape","36087021":"TRAIN_SIZE = Dance_Data.shape[0]\nINPUT_SIZE = Dance_Data.shape[1]\nSEQUENCE_LENGTH = 70\n\nX_train = np.zeros((TRAIN_SIZE-SEQUENCE_LENGTH, SEQUENCE_LENGTH, INPUT_SIZE), dtype='float32')\nY_train = np.zeros((TRAIN_SIZE-SEQUENCE_LENGTH, INPUT_SIZE), dtype='float32')\nfor i in range(0, TRAIN_SIZE-SEQUENCE_LENGTH, 1 ): \n    X_train[i] = Dance_Data[i:i + SEQUENCE_LENGTH]\n    Y_train[i] = Dance_Data[i + SEQUENCE_LENGTH]\n\nprint(X_train.shape)\nprint(Y_train.shape)","2b12948f":"def get_model():\n    inp = Input(shape=(SEQUENCE_LENGTH, INPUT_SIZE))\n    x = CuDNNLSTM(512, return_sequences=True,)(inp)\n    x = CuDNNLSTM(256, return_sequences=True,)(x)\n    x = CuDNNLSTM(512, return_sequences=True,)(x)\n    x = CuDNNLSTM(256, return_sequences=True,)(x)\n    x = CuDNNLSTM(512, return_sequences=True,)(x)\n    x = CuDNNLSTM(1024,)(x)\n    x = Dense(512, activation=\"elu\")(x)\n    x = Dense(256, activation=\"elu\")(x)\n    outp = Dense(INPUT_SIZE, activation='sigmoid')(x)\n    \n    model = Model(inputs=inp, outputs=outp)\n    model.compile(loss='mse',\n                  optimizer=Adam(lr=0.0002),\n                  metrics=['accuracy'],\n                 )\n\n    return model\n\nmodel = get_model()\n\nmodel.summary()","860800be":"checkpoint = ModelCheckpoint(\"Ai_Dance_RNN_Model.hdf5\",\n                             monitor='loss',\n                             verbose=1,\n                             save_best_only=True,\n                             mode='min')\n\nearly = EarlyStopping(monitor=\"loss\",\n                      mode=\"min\",\n                      patience=3,\n                     restore_best_weights=True)\n\nmodel_callbacks = [checkpoint, early]","8abc71fe":"%%time\nif PART_3_SKIP == False:\n    model.fit(X_train, Y_train,\n              batch_size=64,\n              epochs=60,\n              verbose=2,\n              callbacks = model_callbacks)\nelse:\n    model = load_model('..\/input\/Ai_Dance_RNN_Model.hdf5')\n    model.load_weights('..\/input\/Ai_Dance_RNN_Weights.hdf5')","48c74c9c":"model.save(\"Ai_Dance_RNN_Model.hdf5\")\nmodel.save_weights('Ai_Dance_RNN_Weights.hdf5')","336d6b11":"%%time\nDANCE_LENGTH  = 6000\nLOOPBREAKER = 10\n\nx = np.random.randint(0, X_train.shape[0]-1)\npattern = X_train[x]\noutp = np.zeros((DANCE_LENGTH, INPUT_SIZE), dtype='float32')\nfor t in range(DANCE_LENGTH):\n    x = np.reshape(pattern, (1, pattern.shape[0], pattern.shape[1]))\n    pred = model.predict(x)\n    result = pred[0]\n    outp[t] = result\n    new_pattern = np.zeros((SEQUENCE_LENGTH, INPUT_SIZE), dtype='float32') \n    new_pattern[0:SEQUENCE_LENGTH-1] = pattern[1:SEQUENCE_LENGTH]\n    new_pattern[-1] = result\n    pattern = np.copy(new_pattern)\n    ####loopbreaker####\n    if t % LOOPBREAKER == 0:\n        pattern[np.random.randint(0, SEQUENCE_LENGTH-10)] = Y_train[np.random.randint(0, Y_train.shape[0]-1)]","b6ec1099":"if PART_2_SKIP:\n    Decoder = load_model('..\/input\/Dancer_Decoder_Model.hdf5')\n    Decoder.load_weights('..\/input\/Dancer_Decoder_Weights.hdf5')\nelse:\n    Decoder = load_model('Dancer_Decoder_Model.hdf5')\n    Decoder.load_weights('Dancer_Decoder_Weights.hdf5')\n\nDance_Output = Decoder.predict(outp)\nDance_Output.shape","e9e3b642":"IMG_HEIGHT = Dance_Output[0].shape[0]\nIMG_WIDTH = Dance_Output[0].shape[1]\n\nfor row in Dance_Output[0:10]:\n    imshow(row.reshape(IMG_HEIGHT,IMG_WIDTH))\n    plt.show()","994da591":"video = cv2.VideoWriter('AI_Dance_Video.avi', cv2.VideoWriter_fourcc(*\"XVID\"), 20.0, (IMG_WIDTH, IMG_HEIGHT),False)\n\nfor img in Dance_Output:\n    img = resize(img, (IMG_HEIGHT,IMG_WIDTH), mode='constant', preserve_range=True)\n    img = img * 255\n    img = img.astype('uint8')\n    video.write(img)\n    cv2.waitKey(50)\n    \nvideo.release()","b3d51053":"from IPython.display import Image\nImage(\"..\/input\/Dance_Robots_Comic2.png\")","eeaa618a":"## Callbacks","f7cc0ad3":"### Custom Image Sample Callback\n\nHere is a custom callback I made named ImgSample. It tests the result of the autoencoder after every epoch by desplaying an sample image. The goal is to have the dancer come into focus as clearly as possible.","c24f059f":"## Create Compressed Dance Sequences\n\nOur model will look at the last 70 frames and attemp to predict the 71st. As such, sur X variable will be an array of 70 (compressed) frames in sequence and our Y variable will be the 71st frame. This block chops our Dance_Data into such sequences of frames.","eca2caa9":"## Save Video","6af9ed9a":"## Save Models and Create Encoded Dataset","0838ea45":"## Callbacks","5f39a299":"## Sample the Autoencoder Results\n\nThe reconstructions look pretty close to the originals, then the autoencoder works.","98d0664a":"## Output the Dance\n\nBefore we can save the video, we need to decode the frames back into images using the decoder we made in part 2.","cc1500d5":"## Create the Models\n\nIn addition to the Autoencoder model, we will also prepare an encoder and decoder for later. It is important to give the layers the same unique names and shapes in all 3 as we will be using the keras load_weights by_name option to copy our trained Autoencoder weights to each respective layer later.","ce417ad6":"## Train the Autoencoder","31de99f2":"## Read in Images","24acbb90":"## Decode a Sample to Double Check Results\n\nIf the encoder and decoder models are working correctly, the dancer should appear like in the reconstruction of the autoencoder above."}}