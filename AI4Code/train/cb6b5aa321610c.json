{"cell_type":{"230afe16":"code","916ceeed":"code","543208e8":"code","a9dcf5db":"code","90610e45":"code","b87f4fe1":"code","976d69f0":"code","a8e47c51":"code","d403b124":"code","60ddb84b":"code","13758f1e":"code","1b30e440":"code","54b8f733":"code","9e03577a":"code","7f835224":"markdown","ab6068f3":"markdown","73956b18":"markdown","a584f8d1":"markdown","ae5792e1":"markdown","05046260":"markdown","d32d6ca6":"markdown","94a8e8ea":"markdown","de094d81":"markdown","5ab3fdf2":"markdown","9bc24951":"markdown","42488991":"markdown","8ea6ee98":"markdown","888c03cf":"markdown","54f90854":"markdown","19732c8c":"markdown","ff600434":"markdown"},"source":{"230afe16":"import pandas as pd\nimport numpy as np\nimport os\nfrom IPython.display import Image, display_png\nimport matplotlib.pyplot as plt\nimport PIL as pil\nimport random\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D,MaxPooling2D","916ceeed":"print(os.listdir('..\/input'))","543208e8":"d= os.listdir('..\/input\/kkanji')\nprint('Directories: ' + str(d[:10]))","a9dcf5db":"dr = '..\/input\/kkanji\/kkanji2\/'\nd= os.listdir(dr)\nprint('Directories: ' + str(d[:10]))","90610e45":"print(os.listdir(dr + 'U+8AA4')[:10])","b87f4fe1":"dict = {'U+4E00': '1',\n        'U+4E8C': '2',\n        'U+4E09': '3', \n        'U+56DB': '4', \n        'U+4E94': '5', \n        'U+516D': '6', \n        'U+4E03': '7' ,\n        'U+516B': '8', \n        'U+4E5D': '9', \n        'U+5341': '10', \n        'U+767E': '100', \n        'U+5343': '1000',\n        'U+4E07': '10000' }\n\npngs ={}\n\nfor kanji_dir in dict.keys():\n    d2 =dr + kanji_dir\n    \n    if (os.path.isdir(d2)):\n        png_list = os.listdir(d2)\n        pngs[kanji_dir] = png_list\n        \n        print(\"Number: \" + dict.get(kanji_dir)+ \" , \" + str(len(png_list))+ \" samples\")\n        \n        fig, ax = plt.subplots(nrows=1, ncols=5)\n        \n        for i in range(5):\n            img = np.array(pil.Image.open(d2+'\/'+ png_list[i]))\n            ax[i].imshow(img, cmap = 'gray')\n        ax[0].set_xticks([])\n        ax[0].set_yticks([])\n        plt.tight_layout()\n        plt.show()","976d69f0":"samples = 115\nrandom.seed(1)\n\npngs2={}\n\nfor d in dict.keys():\n    pngs2[d] = random.sample(pngs[d], samples)","a8e47c51":"img_shape = 64 * 64\n\nX_samples =np.empty((0,img_shape), int)\ny_samples =np.array([],int)\ni=0\n\nfor d in dict.keys():\n    d2 =dr+d\n    for f in pngs2[d]:\n        img = np.array(pil.Image.open(d2 +'\/'+ f))\n        X_samples = np.append(X_samples, img.reshape(1,img_shape), axis=0)\n        y_samples = np.append(y_samples, i)\n    i=i+1","d403b124":"(X_train, X_test, y_train, y_test) = train_test_split(X_samples, y_samples, test_size=0.1, random_state=0)\n\ny_train_onehot = np.eye(13)[y_train]\n\nmean_vals = np.mean(X_train, axis=0)\nstd_val = np.std(X_train)\n\nX_train_centered = (X_train - mean_vals) \/ std_val\nX_test_centered = (X_test - mean_vals) \/ std_val","60ddb84b":"img_rows , img_cols = 64,64\nbatch_size = 64\nnum_classes = 13\nepochs = 50\n\nmodel = tf.keras.models.Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss = tf.keras.losses.categorical_crossentropy, \n                             optimizer = tf.keras.optimizers.Adam(),\n                                 metrics = ['accuracy'])","13758f1e":"X_train_centered_reshape = X_train_centered.reshape(X_train_centered.shape[0], 64, 64, 1)\nhistory = model.fit(X_train_centered_reshape,y_train_onehot, batch_size = batch_size, epochs =epochs, verbose = 1, validation_split = 0.3)","1b30e440":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.legend(['Training', 'Validation'])\nplt.title('Accuracy')\nplt.xlabel('Epochs')","54b8f733":"X_test_centered_reshape = X_test_centered.reshape(X_test_centered.shape[0], 64, 64, 1)\ny_test_onehot = np.eye(13)[y_test]\n\ntest_accuracy = model.evaluate(X_test_centered_reshape, y_test_onehot)\nprint(\"Test set accuracy: \"+ str(test_accuracy[1]) + \" , loss: \" + str(test_accuracy[0]))","9e03577a":"dict2 ={0:\"1\",\n        1:\"2\",\n        2:\"3\",\n        3:\"4\",\n        4:\"5\",\n        5:\"6\",\n        6:\"7\",\n        7:\"8\",\n        8:\"9\",\n        9:\"10\",\n        10:\"100\",\n        11:\"1000\",\n        12:\"10000\"}\n\ny_test_pred = model.predict_classes(X_test_centered_reshape)\n\nprint (\"----- Wrong prediction in test set ------\")\n\nfor label, pred,i in zip(y_test, y_test_pred, range(0,len(y_test))):\n    if (label != pred):\n        print(\"Label: \"+ dict2.get(label)+ \", Prediction: \" + dict2.get(pred)) \n        plt.imshow(X_test[i].reshape(64,64),cmap = 'gray')\n        plt.show()\n        \n    \n    ","7f835224":"### Check data directory","ab6068f3":"### Check the samples in test data having wrong prediction","73956b18":"## 5. Conclusion\n\nWe performed text recognition for Kanji number characters in historical documents. While the data size is quite small (about 100 samples for each category), we achieved over 90% accuracy for the classification of 13 Kanji numbers.","a584f8d1":"### Read Kanji number data\n\nSince we only have 117 samples for the character representing 100, we decided to use 115 random sample data from each character. ","ae5792e1":"Then we input data and labels into array X_samples and y_samples respectively.","05046260":"# Japanese Kanji Number MNIST by CNN\n\n## 1. Introduction\n\nJapanees language has \"Kanji\" characters having their meanings. Of course, there are some Kanji characters representing numbers. This is an experiment of image recognition of Kanji numbers recorded in historical documents.\u3000The followings are basic Kanji numbers.\n\n|Number | Kanji | pronounciation | Code|\n|----------|--------|---------------------|------|\n|1| \u4e00 | ichi |U+4E00|\n|2|\u4e8c| ni |U+4E8C|\n|3|\u4e09| san |U+4E09|\n|4|\u56db|yon|U+56DB|\n|5|\u4e94|go|U+4E94|\n|6|\u516d|roku|U+516D|\n|7|\u4e03|nana|U+4E03|\n|8|\u516b|hachi|U+516B|\n|9|\u4e5d|kyuu|U+4E5D|\n|10|\u5341| juu|U+5341|\n|100| \u767e|hyaku|U+767E|\n|1000|\u5343|sen|U+5343|\n|10000|\u4e07\/\u842c|man|U+4E07|\n\n(Reference: Wiktionary https:\/\/en.wiktionary.org\/wiki\/ )\n\nThere are still other characters representing larger digit numbers (\u5104(oku)\uff1a100M, \u5146(chou): 1T, etc.) but I suppose they appear less frequently than the above numbers. I am not sure if there is any character corresponding to 0 (zero) in historical documents. But any natural numbers larger than 0 can be represented by Kanji characters. For example, in English, we can say 10400 as \"ten thonsand and four hundred\". In the same way, we can write 10400 in Kanji as \"\u4e00\u4e07\u56db\u767e\" (ichi(1)-man(10000)-yon(4)-hyaku(100)).\n\n### Task\n\n- Extract Kanji number characters from data\n- Construct CNN model using Keras\n- Conduct learning and evalation","d32d6ca6":"We can see that we have directories corresponding to Kanji codes.","94a8e8ea":"### Check Kanji number characters","de094d81":"Let's see what are in the Kanji directories","5ab3fdf2":"## 4. Result evaluation\n\nSee the history of accuracy for training set and validation set during learning.","9bc24951":"### Construct CNN model\n\nBy referring [this](https:\/\/www.kaggle.com\/michaelyadidya\/k-mnist-exploration-classification-with-keras), we construct CNN model using convolution layer, maxpooling layer and dropout layer.","42488991":"### Perform evaluation for test set","8ea6ee98":"## 3. Conduct learning","888c03cf":"We can see png files.","54f90854":"## 2. Construct CNN model\n\n### Prepare training set and test set\n\n- Split 115 samples into training set(0.9) and test set(0.1).\n- Normalize and standardize the samples.","19732c8c":"See what is in the Kanji directory","ff600434":"## 1. Preparation\n\n### Load libraries"}}