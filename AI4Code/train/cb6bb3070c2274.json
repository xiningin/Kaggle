{"cell_type":{"61a36485":"code","29ac83f3":"code","159b8481":"code","8d70a496":"code","2d77abbe":"code","f60c5849":"code","e75ded32":"code","f688f11e":"code","f581967e":"code","713eae53":"code","00d7149e":"code","e146d80f":"code","b71fa4ba":"code","607efb4e":"code","ea34f24e":"code","07504150":"code","052e84fa":"code","fa12971d":"code","abdf6775":"code","0f32405b":"code","884995c4":"markdown","4b94ff09":"markdown","e069e378":"markdown"},"source":{"61a36485":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","29ac83f3":"# install the feyn module\n!pip install feyn","159b8481":"import feyn\nimport sklearn.model_selection\nimport seaborn as sbn","8d70a496":"# loading the dataset\ndf_polution = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/train.csv\")\ndf_polution[\"date_time\"] = pd.to_datetime(df_polution[\"date_time\"], format=\"%Y-%m-%d %H:%M:%S\")","2d77abbe":"def calculate_new_features(df):\n    \n    df[\"month\"] = df[\"date_time\"].dt.month_name()\n    df[\"day_of_week\"] = df['date_time'].dt.day_name()\n        \n    \n    df.loc[df[\"date_time\"].dt.month.isin([12,1,2]), \"season\"] = \"winter\"\n    df.loc[df[\"date_time\"].dt.month.isin([3,4,5]), \"season\"] = \"spring\"\n    df.loc[df[\"date_time\"].dt.month.isin([6,7,8]), \"season\"] = \"summer\"\n    df.loc[df[\"date_time\"].dt.month.isin([9,10,11]), \"season\"] = \"autum\"\n            \n    df[\"is_weekend\"] = (df[\"date_time\"].dt.dayofweek >= 5).astype(\"int\")\n    \n    \n    df.loc[df[\"date_time\"].dt.hour.isin(np.arange(8, 17, 1)), \"time_of_day\"] = \"day\"\n    df.loc[df[\"date_time\"].dt.hour.isin(np.arange(17, 24, 1)), \"time_of_day\"] = \"evening\"\n    df.loc[df[\"date_time\"].dt.hour.isin(np.arange(0, 8, 1)), \"time_of_day\"] = \"night\" \n    \n    df['SMC'] = (df['absolute_humidity'] * 100) \/ df['relative_humidity']\n        \n    return df","f60c5849":"df_polution = calculate_new_features(df_polution)\ndf_polution = df_polution = df_polution.drop([\"date_time\"], axis=1)\nstypes = {\"season\": \"cat\",\n          \"time_of_day\": \"cat\",\n          \"month\": \"cat\",\n          \"day_of_week\": \"cat\"\n         }","e75ded32":"# preparing a dataset for predicting each variable\ndf_target_carbon_monoxide = df_polution\ndf_target_carbon_monoxide = df_target_carbon_monoxide.drop([\"target_benzene\", \n                                                            \"target_nitrogen_oxides\"], \n                                                           axis=1)\n\ndf_target_benzene = df_polution\ndf_target_benzene = df_target_benzene.drop([\"target_carbon_monoxide\", \n                                            \"target_nitrogen_oxides\"], \n                                           axis=1)\n\ndf_target_nitrogen_oxides = df_polution\ndf_target_nitrogen_oxides = df_target_nitrogen_oxides.drop([\"target_carbon_monoxide\", \n                                                            \"target_benzene\"], \n                                                           axis=1)","f688f11e":"# splitting the datasets\ndf_train_target_carbon_monoxide, df_test_target_carbon_monoxide = sklearn.model_selection.train_test_split(df_target_carbon_monoxide, \n                                                                                                           train_size=.80, \n                                                                                                           random_state=1)\ndf_train_target_benzene, df_test_target_benzene = sklearn.model_selection.train_test_split(df_target_benzene, \n                                                                                           train_size=.80, \n                                                                                           random_state=1)\ndf_train_target_nitrogen_oxides, df_test_target_nitrogen_oxides = sklearn.model_selection.train_test_split(df_target_nitrogen_oxides, \n                                                                                                           train_size=.80, \n                                                                                                           random_state=1)","f581967e":"# connect to a qlattice\nql = feyn.connect_qlattice()","713eae53":"# training model for predicting carbon_monoxide\nmodels = ql.auto_run(df_train_target_carbon_monoxide,\n                     output_name=\"target_carbon_monoxide\",\n                     stypes = stypes)","00d7149e":"# plotting the best model the qlattice found\nbest_model = models[0]\nbest_model.plot(df_train_target_carbon_monoxide, df_test_target_carbon_monoxide)","e146d80f":"# loading test data\ndf_polution_test = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/test.csv\")\ndf_polution_test[\"date_time\"] = pd.to_datetime(df_polution_test[\"date_time\"], format=\"%Y-%m-%d %H:%M:%S\")\ncalculate_new_features(df_polution_test) ","b71fa4ba":"# preparring for building submission df\npred_target_carbon_monoxide = best_model.predict(df_polution_test)","607efb4e":"# training model for predicting benzene\nql.reset()\nmodels = ql.auto_run(df_train_target_benzene, \n                     output_name=\"target_benzene\",\n                     stypes = stypes)","ea34f24e":"# plotting the best model the qlattice found\nbest_model = models[0]\nbest_model.plot(df_train_target_benzene, df_test_target_benzene)","07504150":"# preparring for building submission df\npred_target_benzene = best_model.predict(df_polution_test)","052e84fa":"# training model for predicting nitrogen_oxides\nql.reset()\nmodels = ql.auto_run(df_train_target_nitrogen_oxides, \n                     output_name=\"target_nitrogen_oxides\",\n                     stypes = stypes)","fa12971d":"# plotting the best model the qlattice found\nbest_model = models[0]\nbest_model.plot(df_train_target_nitrogen_oxides, df_test_target_nitrogen_oxides)","abdf6775":"# preparring for building submission df\npred_target_nitrogen_oxides = best_model.predict(df_polution_test)","0f32405b":"# building submission csv\ndf_my_submission = pd.DataFrame(columns=[\"date_time\", \"target_carbon_monoxide\", \"target_benzene\", \"target_nitrogen_oxides\"])\ndf_my_submission = df_my_submission.astype({\"date_time\": object, \"target_carbon_monoxide\": float, \"target_benzene\": float, \"target_nitrogen_oxides\": float})\n\nfor i in range(len(df_polution_test)):\n    new_row = {\"date_time\":df_polution_test[\"date_time\"].values[i], \n               \"target_carbon_monoxide\": pred_target_carbon_monoxide[i],\n               \"target_benzene\": pred_target_benzene[i],\n               \"target_nitrogen_oxides\": pred_target_nitrogen_oxides[i]}    \n    df_my_submission = df_my_submission.append(new_row, ignore_index=True)  \n\ndf_my_submission.to_csv('submission.csv', index=False)","884995c4":"# The QLattice\n\nI previous did a notebook on this dataset with a very simple approach, letting the QLattice do all the work with no EDA or data prep at all. You can see it here: https:\/\/www.kaggle.com\/karinbondgaard\/ml-your-grandmother-can-do. \nIn this notebook I'll still use a very simple approach letting the QLattice do the feature selection for me, but this time I will create some new features from the datetime column to see if the QLattice picks up usable signal from those.\nThe QLattice can also be used for much more advanced analysis, but you have to find examples of that in other notebooks.\n\nThe QLattice is a supervised machine learning tool for symbolic regression developed by Abzu. It is inspired by Richard Feynman's path integral formulation. That's why the python module to use it is called Feyn, and the Q in QLattice is for Quantum.\n\nAbzu provides free QLattices for non-commercial use to anyone. These free community QLattices gets allocated for you automatically if you use Feyn without an active subscription, as we will do in this notebook. Read more about how it works here: https:\/\/docs.abzu.ai\/docs\/guides\/getting_started\/community.html","4b94ff09":"# Conclusion\n\nThe new features did indeed improve my predictions compared to my first notebook on this dataset!","e069e378":"# Calculating new features \n\nI will calculate new features based on the date_time:\n* name of month\n* name of day\n* season\n* is weekend\n* time of day\n\nThe idea of also calculating a SMC feature was taken from this [notebook](https:\/\/www.kaggle.com\/maximkazantsev\/tps-07-21-eda-lightautoml)."}}