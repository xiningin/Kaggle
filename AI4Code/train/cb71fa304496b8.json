{"cell_type":{"bf061004":"code","98314dcf":"code","a808916c":"code","4cf40ddd":"code","1b00e5af":"code","df8261f4":"code","c15a4d6e":"code","20f66168":"code","df05779d":"code","1b68e8aa":"code","4265acad":"code","9005ba9b":"code","d1b7b089":"code","6b802bd2":"code","7a802e03":"code","06e93b66":"code","a8a79321":"code","b78d5a7b":"code","67f8112f":"code","b56421f8":"code","60eb71d1":"code","836c5d7b":"code","0d221337":"code","e3c5d8b1":"code","947fc1ee":"code","b44e90d6":"code","dc4d672e":"code","2daef195":"markdown","bf20efba":"markdown","d5fb421d":"markdown","3c27919d":"markdown","2bde221a":"markdown","24292186":"markdown","37633076":"markdown","e07c1515":"markdown","b1ca3941":"markdown","c3d936ee":"markdown","d05b2c4b":"markdown","10231316":"markdown","a8f1c7f4":"markdown","5dff9598":"markdown","b640e636":"markdown","4eef45c7":"markdown","603f7d72":"markdown","4ae70010":"markdown","0f0d442d":"markdown","985321f1":"markdown","43a6807c":"markdown","ce0bd6a5":"markdown","e078ac91":"markdown","ce36bf20":"markdown","8098c503":"markdown","4e05d728":"markdown","384953ad":"markdown"},"source":{"bf061004":"!pip install fastai2 --quiet","98314dcf":"#Load the dependancies\nfrom fastai2.vision.all import *\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport h5py\nimport nilearn as nl\nfrom nilearn import image, datasets, plotting\nfrom nilearn.image import get_data\nfrom random import randint\n\nmatplotlib.rcParams['image.cmap'] = 'gray'","a808916c":"source = Path(\"..\/input\/trends-assessment-prediction\")\nfiles = os.listdir(source)\nprint(files)","4cf40ddd":"fnc = pd.read_csv(f'{source}\/train_scores.csv')\nfnc.head()","1b00e5af":"train_files = get_files(source\/'fMRI_train')\ntrain_files","df8261f4":"test_files = get_files(source\/'fMRI_test')\ntest_files","c15a4d6e":"test_img = train_files[0]\ntest_img = h5py.File(test_img, 'r')\ntest_img","20f66168":"test_img.keys()","df05779d":"test_img['SM_feature']","1b68e8aa":"test_image = train_files[0]\nt = h5py.File(test_image, 'r')['SM_feature'][()]","4265acad":"x_axis = t[:,:,19].transpose(1,2,0)\nplt.imshow(x_axis[:, :,28])","9005ba9b":"@delegates(subplots)\ndef show_images(ims, nrows=1, ncols=None, titles=None, cmap=None, **kwargs):\n    \"Show all images `ims` as subplots with `rows` using `titles`\"\n    if ncols is None: ncols = int(math.ceil(len(ims)\/nrows))\n    if titles is None: titles = [None]*len(ims)\n    axs = subplots(nrows, ncols, **kwargs)[1].flat\n    for im,t,ax in zip(ims, titles, axs): show_image(im, ax=ax, title=t, cmap=cmap)","d1b7b089":"x_list = []\nfor i in range(52):\n    x_axis = t[:,:,i].transpose(1,2,0)\n    x_ = x_axis[:, :,0]\n    x_list.append(x_)","6b802bd2":"show_images(x_list, nrows=4, cmap=plt.cm.Set1)","7a802e03":"y_list = []\nfor i in range(63):\n    y_axis = t[:, :, i, :].transpose(1, 2, 0)\n    y_ = y_axis[:, :,0]\n    y_list.append(y_)","06e93b66":"show_images(y_list, nrows=4, cmap=plt.cm.Set1)","a8a79321":"z_list = []\nfor i in range(52):\n    z_axis = t[:, i, :, :].transpose(1, 2, 0)\n    z_ = z_axis[:, :,0]\n    z_list.append(z_)","b78d5a7b":"show_images(z_list, nrows=4, cmap=plt.cm.Set1)","67f8112f":"train_path = source\/'fMRI_train'\ntrain_path","b56421f8":"def mat_x(fn):\n    file = int(fn.Id)\n    im = f'{train_path}\/{file}.mat'\n    t = h5py.File(im, 'r')['SM_feature'][()]\n    idx_3 = randint(0, 52)\n    x_axis = t[:, :, :, idx_3].transpose(1, 2, 0)\n    return x_axis[:, :, 0]","60eb71d1":"def mat_y(fn):\n    file = int(fn.Id)\n    im = f'{train_path}\/{file}.mat'\n    t = h5py.File(im, 'r')['SM_feature'][()]\n    idx_2 = randint(0, 62)\n    y_axis = t[:, :, idx_2, :].transpose(1, 2, 0)\n    return y_axis[:, :, 0]","836c5d7b":"def mat_z(fn):\n    file = int(fn.Id)\n    im = f'{train_path}\/{file}.mat'\n    t = h5py.File(im, 'r')['SM_feature'][()]\n    idx_1 = randint(0, 51)\n    z_axis = t[:, idx_1, :, :].transpose(1, 2, 0)\n    return z_axis[:, :, 0]","0d221337":"age_ = fnc['age'].unique()\ndom1_ = fnc['domain1_var1'].unique()\ndom2_ = fnc['domain1_var2'].unique()\ndom3_ = fnc['domain2_var1'].unique()\ndom4_ = fnc['domain2_var2'].unique()","e3c5d8b1":"blocks = (\n          ImageBlock(cls=PILImage),\n          ImageBlock(cls=PILImage),\n          ImageBlock(cls=PILImage),\n          CategoryBlock(vocab=age_),\n          CategoryBlock(vocab=dom1_),\n          CategoryBlock(vocab=dom2_),\n          CategoryBlock(vocab=dom3_),\n          CategoryBlock(vocab=dom4_)\n          )\n         \ngetters = [\n           mat_x,\n           mat_y,\n           mat_z,\n           ColReader('age'),\n           ColReader('domain1_var1'),\n           ColReader('domain1_var2'),\n           ColReader('domain2_var1'),\n           ColReader('domain2_var2')\n          ]\n\ntrends = DataBlock(blocks=blocks,\n              getters=getters,\n              item_tfms=Resize(128),\n              n_inp=3\n              )","947fc1ee":"trends.summary(fnc)","b44e90d6":"dls = trends.dataloaders(fnc, bs=4)","dc4d672e":"dls.show_batch(max_n=4)","2daef195":"Lets take a look at image `19` from the `x-axis` and the `28th` slice","bf20efba":"Now we need to specify the outputs, in this case we have to predict 5 features `[age, domain1_var1, domain1_var2, domain2_var1, domain2_var2]`.","d5fb421d":"The data inside the file can be accessed by accessing the `keys()` within the file.","3c27919d":"Now the `y_axis`","2bde221a":"# Exploring the images","24292186":"The images are stored in `.mat` (MATLAB) format in 2 folders `fMRI_train` and `fMRI_test`","37633076":"what about the `z_axis`?","e07c1515":"In this case the data is stored within the `SM_feature` key","b1ca3941":"`show_images` does not allow you to specify colormaps and the default in `fastai2` is set at `viridis`.  We can update the `show_images` function by using `@delegates` to include a `cmap` option","c3d936ee":"Both the `train` and `test` folders contain 5877 files each.  We cannot access the files using standard `fastai2` methods and need to be accessed using `h5py.File`.  You have to specify a mode when using `h5py.File` in this case we use `r` for reading the file.  In this dataset the `.mat` files are pretty similar to working with `dicom` files where there is a `head` and the `array of pixels`","d05b2c4b":"Specify the `blocks` thats the beauty about `fastai2` we can easily specify what the `blocks` will be.  In this case we have 3 `ImageBlock`'s because we have images from the `x`, `y` and `z` axis and we will need 5 `CategoryBlock`'s because we have to predict 5 features.","10231316":"Each `.mat` file is a 4D tensor with the shape of (53, 52, 63, 53)\n\n![](http:\/\/www.talairach.org\/images\/brain.gif)","a8f1c7f4":"- Clean the data\n- Create a `Learner` for training\n- Experiment","5dff9598":"# Building the DataBlock","b640e636":"Specify a function to get images from the `x` orientation","4eef45c7":"As there are images in the `x`, `y` and `z` axis we need to specify how we get those images into the `DataBlock`","603f7d72":"This is a first draft experimental `fastai2` starter notebook.  This dataset is really interesting because it has images that are in 3 different orientations and the output has to be a prediction of 5 features `[age, domain1_var1, domain1_var2, domain2_var1, domain2_var2]` where each feature has the following weights `[.3, .175, .175, .175, .175]` ","4ae70010":"`fastai2` provides a handy function `summary` that you can use to check to see if there are any issues when building the `pipeline`","0f0d442d":"#### Test Files","985321f1":"Each file contains 52 images orientated in the `x-axis`, 63 images in the `y-axis` and 53 images in the `z-axis`.","43a6807c":"Still with the `test_image` lets view all the images within this 1 `.mat` file.\n\nStarting with images within the `x-axis` (there are 53), note the choosen `cmap` color is just for adding color to the notebook :)","ce0bd6a5":"#### Train Files","e078ac91":"`y` orientation","ce36bf20":"## Next Steps","8098c503":"`z` orientation","4e05d728":"We can access the files using the `get_files` function from `fastai2`.","384953ad":"# Experimental Starter\n\n![db.PNG](attachment:db.PNG)"}}