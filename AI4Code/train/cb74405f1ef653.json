{"cell_type":{"4cc85a15":"code","96271f31":"code","2971403a":"code","ed5990e9":"code","001c078a":"code","5c44f01f":"code","485d1480":"code","c26e6a62":"code","4ca0cd26":"code","b3110afe":"code","54f2616d":"code","e5274be0":"code","31ac86bc":"code","21334684":"code","c5e704e4":"code","8236c17d":"code","3af9730f":"code","5dc0d148":"code","609681f9":"code","4ff21723":"code","93fecd15":"code","30c98d51":"code","9e3fa4f4":"code","38f5c250":"code","68faa4e5":"code","6a1cc22c":"code","2f657703":"code","8d593fe2":"code","e7375ed1":"code","f606c58b":"markdown","8a5fca0e":"markdown","078bd494":"markdown"},"source":{"4cc85a15":"import pandas as pd\nimport numpy as np\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import defaultdict\nfrom nltk.corpus import wordnet as wn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import model_selection, naive_bayes, svm\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics","96271f31":"# Add the Data using pandas\nCorpus = pd.read_csv(\"..\/input\/category\/cat.csv\",encoding='latin-1')\nCorpus.head","2971403a":"# Step - 1: Data Pre-processing - This will help in getting better results through the classification algorithms\n\n# Step - 1a : Remove blank rows if any.\nCorpus['text'].dropna(inplace=True)","ed5990e9":"# Step - 1b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\nCorpus['text'] = [entry.lower() for entry in Corpus['text']]","001c078a":"# Step - 2: Split the model into Train and Test Data set\nTrain_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text'],Corpus['label'],test_size=0.3)","5c44f01f":"# Step - 3: Label encode the target variable  - This is done to transform Categorical data of string type in the data set into numerical values\nEncoder = LabelEncoder()\nTrain_Y = Encoder.fit_transform(Train_Y)\nTest_Y = Encoder.fit_transform(Test_Y)","485d1480":"Train_Y.shape","c26e6a62":"Test_Y.shape","4ca0cd26":"# Step - 4: Vectorize the words by using TF-IDF Vectorizer - This is done to find how important a word in document is in comaprison to the corpus\nTfidf_vect = TfidfVectorizer(max_features=5000)\nTfidf_vect.fit(Corpus['text'])","b3110afe":"Train_X_Tfidf = Tfidf_vect.transform(Train_X)\nTest_X_Tfidf = Tfidf_vect.transform(Test_X)","54f2616d":"# Step - 5: Now we can run different algorithms to classify out data check for accuracy\n\n# Classifier - Algorithm - Naive Bayes\n# fit the training dataset on the classifier\nNaive = naive_bayes.MultinomialNB()\nNaive.fit(Train_X_Tfidf,Train_Y)","e5274be0":"# predict the labels on validation dataset\npredictions_NB = Naive.predict(Test_X_Tfidf)\nnbaccuracy=accuracy_score(predictions_NB, Test_Y)*100\nconf_mat = metrics.confusion_matrix(\n        Test_Y, predictions_NB)\n\nprint(metrics.classification_report( Test_Y, predictions_NB))","31ac86bc":"# Use accuracy_score function to get the accuracy\nprint(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)","21334684":"# Classifier - Algorithm - SVM\n# fit the training dataset on the classifier\nSVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\nSVM.fit(Train_X_Tfidf,Train_Y)","c5e704e4":"# predict the labels on validation dataset\npredictions_SVM = SVM.predict(Test_X_Tfidf)\nsvmaccuracy=accuracy_score(predictions_SVM, Test_Y)*100\nconf_mat = metrics.confusion_matrix(\n        Test_Y, predictions_SVM)\nprint(metrics.classification_report( Test_Y, predictions_SVM))","8236c17d":"# Use accuracy_score function to get the accuracy\nprint(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)","3af9730f":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(Train_X_Tfidf.toarray(),Train_Y)","5dc0d148":"predictions_GNB = gnb.predict(Test_X_Tfidf.toarray())\ngnbaccuracy=accuracy_score(predictions_GNB, Test_Y)*100\nconf_mat = metrics.confusion_matrix(\n        Test_Y, predictions_GNB)\n\nprint(metrics.classification_report( Test_Y, predictions_GNB))","609681f9":"# Use accuracy_score function to get the accuracy\nprint(\"Gaussian NB Accuracy Score -> \",accuracy_score(predictions_GNB, Test_Y)*100)","4ff21723":"import xgboost as xg\nxgb=xg.XGBClassifier(n_extimators=150,max_depth=5,reg_alpha=.25)\nxgb.fit(Train_X_Tfidf,Train_Y)","93fecd15":"xgb.score(Train_X_Tfidf,Train_Y)\n\naccuracy_score(predictions_GNB, Test_Y)*100","30c98d51":"import sklearn.feature_extraction.text as text\ntfidf=text.TfidfVectorizer(input=Corpus['text'].tolist(),stop_words='english')","9e3fa4f4":"X=Corpus['text']\ntdm=tfidf.fit_transform(X.tolist())","38f5c250":"X=pd.DataFrame(tdm.toarray())\nX.columns=tfidf.get_feature_names()","68faa4e5":"from sklearn.preprocessing import LabelEncoder\nenc=LabelEncoder()\ny_train=enc.fit_transform(Corpus['label'])","6a1cc22c":"xgb=xg.XGBClassifier(n_estimators=150,max_depth=5,reg_alpha=.25)\nxgb.fit(X,y_train)","2f657703":"xgbaccuracy=xgb.score(X,y_train)*100","8d593fe2":"accuracy=pd.DataFrame({'algo':['Naive Bayes','SVM','Gaussian','XGB'],\"accuracy\":[nbaccuracy,svmaccuracy,gnbaccuracy,xgbaccuracy]})","e7375ed1":"pd.DataFrame.from_dict(accuracy)","f606c58b":"## Categorization","8a5fca0e":"The data has been created by refering multiple ecommerce platform for furniture and furnishing products. So the amounted of data is inconsistant for each category.","078bd494":"The project is a sample for Search engine optimization for furniture and furnishing products"}}