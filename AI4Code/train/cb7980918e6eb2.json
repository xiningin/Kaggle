{"cell_type":{"e900e8f2":"code","4c76869a":"code","e04c7fa5":"code","5fde9aa7":"code","bad988a9":"code","313bc19f":"code","5d28c452":"code","1e581f90":"code","06b62ee5":"code","0dbfb688":"code","18610314":"code","2e69a334":"code","e43f8bd4":"code","de76e046":"code","898f22e9":"code","368794b1":"code","353338e3":"code","e4fb2503":"code","6ba57289":"code","acc06cbe":"code","ac0c3ca7":"code","3be3e704":"code","87519efc":"code","ee53c91a":"code","476d0a31":"code","5506157d":"code","0e613b9c":"code","3e503395":"code","bb1e76c9":"code","d7037d8b":"code","da7c700d":"code","e2b8e1d3":"code","358b0716":"code","7ba92664":"code","20d277bd":"code","80ead7c2":"code","dd129c3e":"code","80404d46":"code","8f4b7244":"code","e5ffab01":"code","b21bfbdd":"code","657ef2b4":"code","01211e16":"code","a4e996a8":"code","40e2bcf9":"code","a439a66a":"code","888780e6":"markdown","64a01d75":"markdown","3ac6962d":"markdown","42249887":"markdown","ed244029":"markdown","65422e64":"markdown","045681de":"markdown","35627ba3":"markdown","af11fa69":"markdown","929eede8":"markdown","4df463b1":"markdown","2e3b829c":"markdown","71336093":"markdown","a961032b":"markdown","7bfbe00d":"markdown","ce434ccc":"markdown","45a0b178":"markdown","7b60c99b":"markdown","7bc7bad1":"markdown","74ab5c48":"markdown","3f1a0bdd":"markdown","dcdfabf2":"markdown","e4f91762":"markdown","9b049e68":"markdown","a2f74a55":"markdown","010a2019":"markdown","155ac0a9":"markdown","021daaf0":"markdown","7870ce87":"markdown","d3091dd7":"markdown","ef3ec28b":"markdown","fd67baab":"markdown","1c619220":"markdown","f92bd8dc":"markdown","f4f92f68":"markdown","77144a34":"markdown","1e04ce55":"markdown","91ea847d":"markdown","9daf8764":"markdown","4e901a5d":"markdown","05872c61":"markdown"},"source":{"e900e8f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4c76869a":"%pylab inline \n\nfrom pylab import rcParams\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')","e04c7fa5":"Climate_Data = pd.read_csv('\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTrain.csv',\n                           index_col='date', parse_dates=['date'])","5fde9aa7":"Climate_Data.tail(3)","bad988a9":"Climate_Data.describe()","313bc19f":"# get the column name with na_values.\ncol_with_na = [col for col in Climate_Data.columns if Climate_Data[col].isnull().any()]\n\nprint(col_with_na)","5d28c452":"Climate_Data[\"humidity\"].asfreq('M').plot() \n# asfreq method is used to convert a time series to a specified frequency. Here it is monthly frequency.\nplt.title('Humidity in Delhi City over time(Monthly frequency)')\nplt.show()","1e581f90":"Climate_Data.asfreq('M').plot(subplots=True, figsize=(10,12))\nplt.title('Climate in Delhi City from 2013 to 2017')\nplt.savefig('climate.png')\nplt.show()","06b62ee5":"Climate_Data.plot(subplots=True, figsize=(10,12))\nplt.title('Climate in Delhi City from 2013 to 2017')\nplt.savefig('climate.png')\nplt.show()","0dbfb688":"# creating a timestamp\ntimestamp = pd.Timestamp(2014, 1, 1, 12)\n\ntimestamp","18610314":"# creating a period\nperiod = pd.Period('2014', freq='M')\n\nperiod","2e69a334":"print(period.start_time, '\\n', period.end_time)","e43f8bd4":"# Checking if the given timestamp exists in the given period\nperiod.start_time < timestamp < period.end_time","de76e046":"df = pd.DataFrame({'year': [2015, 2016], 'month': [2, 3], 'day': [4, 5], 'temperature':[24, 26]})\ndf","898f22e9":"df['date'] = pd.to_datetime(df[['year','month','day']])\n# change the date as the index of dataframe.\ndf.index = df['date']\ndf = df['temperature']\ndf","368794b1":"Climate_Data['2014':][\"humidity\"].asfreq('M').plot(legend=True)\nshifted = Climate_Data[\"humidity\"].asfreq('M').shift(12).plot(legend=True)\nshifted.legend(['humdity', 'humdity_shifted'])\nplt.show","353338e3":"# we downsample from daily to weekly frequency aggregated using mean.\nclimate_down_sample = Climate_Data.resample('7D').mean()\n\nclimate_down_sample","e4fb2503":"climate_up_sample = climate_down_sample.resample('D').pad()\nclimate_up_sample.head(10)","6ba57289":"# Step one : Upsampling the Climate Data ('D' -> 'W')\nClimate_Data_Weekly = Climate_Data.resample('7D').mean()\n\n# Step two : calculate the changes \nClimate_Data_Weekly['mean_temp_change'] = Climate_Data_Weekly.meantemp.div(Climate_Data_Weekly.meantemp.shift())\n\n# Step three : draw the diff graph. \nClimate_Data_Weekly['mean_temp_change'].plot(figsize=(20, 8))\nplt.title('Weekly meantemp change rate')","acc06cbe":"Climate_Data_Weekly.head(10)","ac0c3ca7":"Climate_Data_Weekly['temp_diff'] = Climate_Data_Weekly.meantemp.sub(Climate_Data_Weekly.meantemp.shift())\nClimate_Data_Weekly['temp_diff'].plot(figsize=(20, 8))","3be3e704":"# in fact, there is a built-in mmethod to do the above job, is the same as the above graph.\nClimate_Data_Weekly.meantemp.diff().plot(figsize=(20, 8), color='r')","87519efc":"# Normalizing and comparision\nnormalized_meantemp = Climate_Data.meantemp.div(Climate_Data.meantemp.iloc[0]).mul(100)\nnormalized_meanpressure = Climate_Data.meanpressure.div(Climate_Data.meanpressure.iloc[0]).mul(100)\nnormalized_humidity = Climate_Data.humidity.div(Climate_Data.humidity.iloc[0]).mul(100)\n# normalized_wind_speed = Climate_Data.wind_speed.div(Climate_Data.wind_speed.iloc[0]+0.01).mul(100)\n\n# plotting \nrcParams['figure.figsize'] = (16, 6)\nnormalized_meantemp.plot()\nnormalized_meanpressure.plot()\nnormalized_humidity.plot()\n# normalized_wind_speed.plot()\nplt.legend(['meantemp', 'meanpressure', 'humidity', 'wind_speed'])\nplt.show()","ee53c91a":"# Rolling window functions\nrolling_meantemp = Climate_Data.meantemp.rolling('20D').mean()\nClimate_Data.meantemp.plot()\nrolling_meantemp.plot()\nplt.legend(['meantemp', 'Rolling Mean'])\n\n# plotting a rolling mean of 20 day window with original meantemp attribute","476d0a31":"# Expandinng window funcitons \nmean_humility = Climate_Data.humidity.expanding().mean()\nstd_humility = Climate_Data.humidity.expanding().std()\n\nClimate_Data.humidity.plot()\nmean_humility.plot()\nstd_humility.plot()\n\nplt.legend(['humility', 'Expanding mean', 'Expanding std'])\nplt.show()","5506157d":"from statsmodels.graphics.tsaplots import plot_acf\n\n# autocorrelation of humility \nplot_acf(Climate_Data.humidity, lags=30, title='humidity')\nplt.show()\n# in fact, we can only find that the smaller the time interval, the greater the correlation. :)","0e613b9c":"from statsmodels.graphics.tsaplots import plot_pacf\nrcParams['figure.figsize'] = (10, 6)\nplot_pacf(Climate_Data.humidity, lags=30)\nplt.show()","3e503395":"Climate_Data.meantemp.plot(figsize=(10, 4))","bb1e76c9":"import statsmodels.api as sm\n\n# now, for decomposition\nrcParams['figure.figsize'] = 11, 9\ndecomposed_meantemp_volume = sm.tsa.seasonal_decompose(Climate_Data.meantemp, freq=360) # the frequency is annual \nfigure = decomposed_meantemp_volume.plot()\nplt.show()","d7037d8b":"# plotting white noise\nrcParams['figure.figsize'] = 16, 6\nwhite_noise = np.random.normal(loc=0, scale=1, size=1000) # loc is mean, scale is variance\n\nplt.plot(white_noise)","da7c700d":"# plotting autocorrelation of white noise\nplot_acf(white_noise, lags=30, title='autocorrelation of white noise')\nplt.show()","e2b8e1d3":"# augmented Dickey-Fuller test on volume of meantemp\nfrom statsmodels.tsa.stattools import adfuller\nadf = adfuller(Climate_Data.meantemp)\nprint(f\"p-value of meantemp_daily : {float(adf[1])}\")\nadf = adf = adfuller(Climate_Data_Weekly.meantemp)\nprint(f\"p-value of meantemp_weekly : {float(adf[1])}\")","358b0716":"# The original non-stationary plot\ndecomposed_meantemp_volume.trend.plot()","7ba92664":"# the new stationary plot\ndecomposed_meantemp_volume.trend.diff().plot()","20d277bd":"from statsmodels.tsa.arima_process import ArmaProcess\n\n# AR(1) MA(1) model : AR parameter = +0.9\nrcParams['figure.figsize'] = 16, 12\nplt.subplot(4, 1, 1)\nar1 = np.array([1, -0.9]) # we choose -0.9 as AR parameter is +0.9\nma1 = np.array([1])\nAR1 = ArmaProcess(ar1, ma1)\nsim1 = AR1.generate_sample(nsample=1000)\nplt.title('AR(1) model: AR parameter = +0.9')\nplt.plot(sim1)\n\n# We will take care of MA model later\n# AR(1) MA(1) AR parameter = -0.9\nplt.subplot(4,1,2)\nar2 = np.array([1, 0.9]) # We choose +0.9 as AR parameter is -0.9\nma2 = np.array([1])\nAR2 = ArmaProcess(ar2, ma2)\nsim2 = AR2.generate_sample(nsample=1000)\nplt.title('AR(1) model: AR parameter = -0.9')\nplt.plot(sim2)\n\n# AR(2) MA(1) AR parameter = 0.9\nplt.subplot(4,1,3)\nar3 = np.array([2, -0.9]) # We choose -0.9 as AR parameter is +0.9\nma3 = np.array([1])\nAR3 = ArmaProcess(ar3, ma3)\nsim3 = AR3.generate_sample(nsample=1000)\nplt.title('AR(2) model: AR parameter = +0.9')\nplt.plot(sim3)\n\n# AR(2) MA(1) AR parameter = -0.9\nplt.subplot(4,1,4)\nar4 = np.array([2, 0.9]) # We choose +0.9 as AR parameter is -0.9\nma4 = np.array([1])\nAR4 = ArmaProcess(ar4, ma4)\nsim4 = AR4.generate_sample(nsample=1000)\nplt.title('AR(2) model: AR parameter = -0.9')\nplt.plot(sim4)\nplt.show()","80ead7c2":"from statsmodels.tsa.arima_model import ARMA\n\nmodel = ARMA(sim1, order=(1, 0))\nresult = model.fit()\nprint(result.summary())\nprint(f\"\u03bc={result.params[0]} ,\u03d5={result.params[1]}\")","dd129c3e":"import math\nfrom sklearn.metrics import mean_squared_error\n\nresult.plot_predict(start=900, end=1010)\nplt.show()\n\n# calculate the mean_squared_error.\nrmse = math.sqrt(mean_squared_error(sim1[900:1010], result.predict(start=900, end=999)))\nprint(f\"The root mean squared error is {rmse}.\")","80404d46":"Climate_test = pd.read_csv('\/kaggle\/input\/daily-climate-time-series-data\/DailyDelhiClimateTest.csv', \n                          index_col='date', parse_dates=['date'])\nClimate_test.head()","8f4b7244":"# get the ground truth \nClimate_test_Weekly = Climate_test.resample('7D').mean()\n\nClimate_test_Weekly.meantemp.plot(figsize=(10, 6))","e5ffab01":"Climate_Data_Weekly.shape","b21bfbdd":"from statsmodels.tsa.arima_model import ARMA\n\nmeantemp_model = ARMA(Climate_Data_Weekly['meantemp'], order=(10, 1))\n\n# fitting our training data.\nresult = meantemp_model.fit()\n\n# The AIC criterion, also known as the Akaike message criterion.\n# is a measure of how well a statistical model fits. The smaller the value, the better the model fits.\nprint(f'AIC: {result.aic : 0.2f}')\n\npredicted = result.predict('2017', '2018')","657ef2b4":"result.plot_predict(start=160, end=230)\nClimate_test_Weekly.meantemp.plot()\nplt.show()","01211e16":"from statsmodels.tsa.arima_model import ARIMA\nrcParams['figure.figsize'] = 16, 6\nARIMA_model = ARIMA(Climate_Data_Weekly.meantemp, order=(4, 2, 3))\nresult = ARIMA_model.fit()\nprint(result.summary())","a4e996a8":"result.plot_predict(start=100, end=220)\nClimate_test_Weekly.meantemp.plot()\nplt.show()","40e2bcf9":"# so we are going to use 2013-1-1 to 2013-5-31 temperatue data to predict \n# 2013-6 temperatue, knowing that temperature's trend is growing during this poried.\n\ntrain_data = Climate_Data.meantemp[:'2013-4-30']\n\ntest_data = Climate_Data.meantemp['2013-5-1':'2013-5-31']\n\nARIMA_model = ARIMA(train_data, order=(5,2,5))\n\nresult = ARIMA_model.fit()\nprint(result.summary())","a439a66a":"result.plot_predict(start=10, end=160)\ntest_data.plot()\nplt.legend(['train_serie', 'prediction', 'ground_truth'])\nplt.show()","888780e6":"### Augmented Dickey-Fuller test\n\nAn augmented Dickey-Fuller test (ADF) tests the null hypothesis that a unit root is present in a time series sample.It is basically Dickey-Fully test with more lagged changes on RHS","64a01d75":"# 2. Climate statistics\n\n## 2.1 Percent change\n\nHere we want to know how meantemp change weekly in 2014, we can use the following code to do simple job.","3ac6962d":"from the above result, \n- there is clearly an upward trend, which is different to observe from the original graph.\n- we can see the uniform season change.\n- Non-uniform noise that represent outliers and missing values","42249887":"## Simulating AR(1) model","ed244029":"# Time series decompostion and Random walks\n\n## 3.1 Trends, seasonality, and noisy\n\nThese are the components of a time series\n\n- **Trend** : Consistent upwards or downwards slope of a time series \n\n- **Seasonality** : Clear periodic pattern of a time series\n\n- **Noise** : Outliers or missing values","65422e64":"## Using date_range\n\nWhat is date_range and how is it useful?\n\n**data_range** is a method that returns a fixed frequency datetimeindex. \n\nIt is quite useful when creating your own time series attribute for pre_existing data or arranging the whole data around the time series attribute created by you.\n\nUsage : \n1. create dayly date_range.\n\n```python\ndate_ran = pd.date_range(start='2013-1-1', end='2013-1-8')\ndate_ran\n\n>>> DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n               '2013-01-05', '2013-01-06', '2013-01-07', '2013-01-08'],\n              dtype='datetime64[ns]', freq='D')\n\n```\n2. create monthly date_range\n\n```python\ndate_ran = pd.date_range(start='2013-4', end='2014-2', freq='M')\ndate_ran\n\n>>> DatetimeIndex(['2013-04-30', '2013-05-31', '2013-06-30', '2013-07-31',\n               '2013-08-31', '2013-09-30', '2013-10-31', '2013-11-30',\n               '2013-12-31', '2014-01-31'],\n              dtype='datetime64[ns]', freq='M')\n```\n\n3. create a datetimeindex specifying start date end date and periods.\n\n```python\n# split 2013-4-24 to 2014-11-27 into 2 part.\ndate_ran =  pd.date_range(start='2013-4-24', end='2014-11-27', periods=3)\ndate_ran\n\n>>> DatetimeIndex(['2013-04-24', '2014-02-09', '2014-11-27'], dtype='datetime64[ns]', freq=None)\n```","045681de":"## 4.4 ARIMA models \n\nAn autoregressive integrated moving average (ARIMA) model is a generalization of an autoregressive moving average(ARMA) model. Both of these model are fitted to time series data either to better understand the data or to predict future points in the series. ARIMA models are applied in some cases when data show evidence of non-stationarity, where an initial differencing step (corresponding to the 'integrated' part of the model) can be applied one or more times to eliminate the non-stationarity. ARIMA model is of the form : ARIMA(p, d, q): p is AR parameter, d is differential parameter, q is MA parameter.","35627ba3":"## Resampling \n\nResampling may play an important role in Time series tasks.\n\n- Upsampling : Time series is resampled from low frequency to high frequency ('M' -> 'D'). \n    - It involves filling or interpolating missing data\n- Downsampling : Time series is resampled from high frequency to low frequency ('D' -> 'M')\n    - It involves aggregation of existing data.","af11fa69":"## Using to_datetime\n\npandas.to_datetime() is used for convertinng arguments to datetime. (but here we won't use this tricks.)\n\nauthor's original example is not typical with no other attributes except year, month, day.\n\nHere we give a more common example, which has a attribute 'temperature' besides year, month, day.\n\n**Note : In fact, to use the to_datetime function we must rename the attribute 'year', 'month', 'day'**","929eede8":"## 2.5 Window functions\n\nWindow functions are used to identify sub periods, calculates sub-metrics of sub-periods.\n\n- **Rolling** : Same size and sliding\n- **Expanding** : Contains all prior values.","4df463b1":"# Modelling using statstools\n\n## 4.1 AR models\n\nAn autoregressive (AR) model is a representation of a type of random process;\n\nThe AR model specifies that the output variable depends linearly on its own previous values and a srochastic term :\n\n**AR (1) model** :\n$R_t = \\mu + \\phi R_{t-1} + \\epsilon_{t}$\n\n> as right hand side has only one lagged value ($R_{t-1}$), this is called AR model of order 1 where $\\mu$ is mean and $\\epsilon$ is noise at time t\n\nIf $\\phi = 1$ AR(1) model is equal to random walk, else if $\\phi = 0$  it is white noise, else if $-1 < \\phi < 1$, it is stationary. \n\n**AR (2) model** :\n$R_t = \\mu + \\phi_{1} R_{t-1} + \\phi_2 R_{t-2} + \\epsilon_{t}$","2e3b829c":"## 3.3 Random Walk\n\nA random walk is a mathematical object, known as a stochastic or random process, that describes a path that consists of a succession of random steps on some mathematical space such as the integers.\n\nIn our task, we may assume that Today's humidity = yesterday's humidity + noise\n\n$$\nP_t = P_{t-1} + \\epsilon_{t}\n$$\n\nrandom walks can't be forecasted well, noise is random.","71336093":"## Forecasting a simulated model\n\n$\\phi(L)(y_t - X_t\\beta) = \\theta(L)\\epsilon_t$","a961032b":"## 2.8 Autocorrelation and Partial Autocorrelation\n\n- **Autocorrelation** : The autocorrelation function (ACF) measures how a series\n     is correlated with itself at different lags\n     \n- **Partial Autocorrelation** : The partial autocorrelation function can be interpreted as a regression of the series against its past lags.The terms can be interpreted the same way as a standard linear regression, that is the contribution of a change in that particular lag while holding others constant.\n\n```python\nfrom statsmodels.graphics.tsaplots import plot_acf\nplot_acf(attribute_name, lags=, title=)\n```","7bfbe00d":"## 2.4 Comparing two or more time series\n\nIn our notebook, we will compare the meantemp and meanpressure in original dataset.\n\nBefore we go further, we should make the two attribute comparable. (i.e. we should normalize our data)","ce434ccc":"Though it is statistically signficant, partial autocorrelation after first 2 lags is very low.\n\nHere, only 0th, 1th, 3th, 4th, 5th, 6th, 8th, 9th, 16th are statistically significant.","45a0b178":"we know timestamps and periods. Make notes as follows:\n\n## Timestamps and Periods\n\nWhat are timestamps and periods and how are they useful?\n\n- Timestamps are used to represent a point in time. \n- Periods represent an interval in time. \n- Periods can used to check if a specific event in the given period. \n- They can also be converted to each other's form.","7b60c99b":"# Preface\n\nThis notebook is used for noted down some tricks and method dulling with time series data.\n\nAnd Many thanks to Siddharth Yadav and his notebook [https:\/\/www.kaggle.com\/thebrownviking20\/everything-you-can-do-with-a-time-series](https:\/\/www.kaggle.com\/thebrownviking20\/everything-you-can-do-with-a-time-series) ","7bc7bad1":"**random walk with drift**\n\n$$\nP_t - P_{t-1} = \\mu + \\epsilon_{t}\n$$\n\nRegression test for random walk \n\n$$\nP_t = \\alpha + \\beta P_{t-1} + \\epsilon_{t}\n$$\n\nEquivalent to $P_t - P_{t-1} = \\alpha + \\beta P_{t-1} + \\epsilon_{t}$\n\nhypothetical test\uff1a\n\n$H_0 : \\beta = 1 $ (this is a random walk)\n\n$H_1 : \\beta \\not= 1$  (this is not a random walk)\n\nDickey-Fuller test\uff1a\n\n$H_0 : \\beta = 0 $ (this is a random walk)\n\n$H_1 : \\beta \\not= 0$  (this is not a random walk)","74ab5c48":"The result of ARIMA is even not so good as ARMA, We may guess that our climate series is a stationarity process.\n\nThat means the assumption is totally wrong, makes our model not so useful QAQ.","3f1a0bdd":"Here we are certainly very lucky that there isn't any na_values in our dataset.\n\nbut if there is any, we can use the following method to fill the na_values:\n\n```\nClimate_Data = Climate_Data.fillna(method='ffill')\n```","dcdfabf2":"## Visualize our dataset","e4f91762":"## Shifting and lags\n\nWe can shift index by desired number of periods with an optional time frequence.\n\nThis is useful when comparing the time series with a past of itself.\n\nIn our study, we can compare the climate (in different year but same month) in one graph. ","9b049e68":"## Cleaning and prepare time series data\n\nNote : Always be careful about na_values. \n\nwe would like to make sure there isn't any columns with na_values before we go further.","a2f74a55":"Much less rows are left. Now we try to upsampling from weekly to daily frequency","010a2019":"## Predicting the models\n\nWe use the built-in function \n```python\nplot_predict(start=, end=)\n```","155ac0a9":"We can find that daily climate data has much more noise than weekly climate dataset.","021daaf0":"Not very impressive. So we want to try some other model","7870ce87":"## 3.4 Stationarity\n\nA stationary time series is one whose statistical properties such as mean, variance, autocorrelation, etc are all constant over time.\n\n- Strong stationarity : is a stochastic process whose unconditional joint probability distribution does not change when shifted in time. Consequently, parameters such as mean and variance also do not change over time.\n\n- Weak stationarity : is a process where mean, variance, autocorrelation are constant throughtout the time.","d3091dd7":"## importing our data\n\nThere is certain some useful tricks for us to load the time series dataset.\n\n- index_col : We always treat 'Time' attribute as the index of our dataFrame.\n\n    - the reason why we use 'Time' as index is that we may use 'Time' to slice our dataset to get the subset of dataset we need.\n\n- parse_dates : The required time series column is imported as a datetime column.","ef3ec28b":"It is a good idea to know some Statistics about our dataset. ","fd67baab":"From the above graph, we can find which week the temperature change rapidly. \n\nBut in many situation, we want to know the Difference but not the changing rate.\n\n## Difference value","1c619220":"## import libraries\n\nsometimes we want to use the least code to draw the most impressive images. So the following tips is important.\n\n1. to make our line graph more pretty. using the following code to change the pylab style\n```python\nplt.style.use('fivethirtyeight')\n```\n2. warnings always makes me struggle, we can now using the following code to ignore unnecessary warnings.\n```python\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n3. To make your code formal, you should using rcParams to change the configure of you pylab.\n```python\nfrom pylab import rcParams\nrcParams['figure.figsize'] = (16, 6)\n```","f92bd8dc":"Stationarity is important as non-stationary series that depend on time have too many parameters to account for when modelling the time series. diff() method can easily convert a non-stationary series to a stationary series.\n\n**In fact, the diff() describes the first derivative information of a time series\uff0cmay be a stationary series.**\n\nWe will try to decompose seasonal component of the above decomposed time series.","f4f92f68":"See how all lags are statistically insigficant as they lie inside the confidence interval (shaded portion)","77144a34":"Next, let's have a look at our dataset.","1e04ce55":"We can find that \u03d5=0.8810767812342137 is near 0.9(ground truth) ;)\n\nWe got this result because our dataset is generate from the AR(1) model ..\n\nNOTE : THOUGH WE ARE USING THE ARMA MODEL, WITH **SETTING ORDER=(AR, MA=0)**,WE SIMPLFY OUR ARMA MODEL INTO AR MODEL.","91ea847d":"## 4.3 ARMA Model","9daf8764":"## 3.2 White noise \n\nWhite noise has ...\n\n- Constant mean\n\n- Constant variance\n\n- Zero auto-correlation at all lags","4e901a5d":"Using a rolling window, we calculate the mean temperature in nearest 20 days as the value of the day.\n\nRolling window act as a Smoothing function in may situation.","05872c61":"### Prediction using ARIMA model"}}