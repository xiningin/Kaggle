{"cell_type":{"9077c6ae":"code","e0549be4":"code","d11e8fec":"code","9ce95d7a":"code","098d0b85":"code","6a6481a5":"code","1c568ad9":"code","a86cd086":"code","e1f7eb42":"code","12b80ef9":"code","372999f2":"code","100c8c31":"code","c3e17ee3":"code","334fddf4":"code","74928e0d":"code","29ffbfbd":"code","3ec18396":"code","a0ea0dc4":"code","7ea16896":"code","8ff445f6":"code","9c0746a9":"code","3d7aec34":"code","2ee1ba3c":"code","b353b720":"code","099a651a":"code","670ff768":"code","1e3a75ce":"code","ff809955":"code","81e20039":"code","e650fe62":"code","061b7c0d":"code","343d3563":"code","acc139de":"code","eca33e1e":"code","10ffdb06":"code","668bbf98":"code","791c1349":"code","74e0db8a":"code","3e499493":"code","9db67918":"code","7d9bbb3c":"code","453905ec":"code","74891ac9":"code","1ec12668":"code","ad7249f1":"code","aaedb5b7":"code","fcd9e180":"code","5f902e39":"code","ec80ef75":"code","dfabb57f":"code","3b42a188":"code","2d299c1f":"code","5db2b7ad":"code","b364cafe":"code","0b50428d":"code","1152cca2":"code","b952aff6":"code","96770f00":"code","6e8a18ff":"code","586babb7":"code","307df851":"code","ba7dfad6":"code","92a830bb":"code","ebb668ab":"code","8119f783":"code","3a1759dd":"code","11710b56":"code","ca5029e2":"code","d42bcf2d":"code","eb212dbf":"code","0f978d01":"code","3c212c82":"code","da2df379":"code","cce2119d":"code","d58aed7e":"code","b5f20871":"code","13f6192c":"code","95e6074b":"code","9e267027":"code","872499fa":"code","b2f89384":"code","5bbd94db":"code","07fef302":"code","8a0e33f5":"code","366c996e":"code","b5cdd6ee":"code","bc3b423d":"code","1bb72ed3":"code","77541029":"code","2e8b765b":"code","2468bbf9":"code","2f78fbea":"markdown","71c11693":"markdown","d67a6766":"markdown","c2f7f29e":"markdown","b3f76cb5":"markdown","822c16ad":"markdown","f15379d4":"markdown","4bed7724":"markdown","a6634292":"markdown","78e33067":"markdown","8d29cbea":"markdown","97a3b613":"markdown","ffa523be":"markdown","8d61b915":"markdown","89f4277f":"markdown","b20aefd7":"markdown","c64e34ae":"markdown","c4829d2f":"markdown","c8d80222":"markdown","9b483a7a":"markdown","023255bb":"markdown","2404c85d":"markdown","5d8fffdb":"markdown","8d07bb2d":"markdown","a6c8ab30":"markdown","cd5791ab":"markdown","6c731d57":"markdown","07e49b80":"markdown","a710c8d4":"markdown","816eca80":"markdown","a7b3f479":"markdown","f885bd73":"markdown","c4a2761c":"markdown","059bd46a":"markdown","6ed5c5c1":"markdown","f084b45c":"markdown","b2f0fa7e":"markdown","6f5c569d":"markdown","ece93c11":"markdown","b86714bd":"markdown","b7368279":"markdown","450e7767":"markdown","61a3b0bd":"markdown","ae54a6f1":"markdown","af4cf010":"markdown","aa63edaf":"markdown","2e4f6335":"markdown","a64248ae":"markdown"},"source":{"9077c6ae":"# This Python 3 environment comes with many helpful analytics libraries installed (Bu Python 3 ortam\u0131, y\u00fckl\u00fc bir\u00e7ok yard\u0131mc\u0131 analiz kitapl\u0131\u011f\u0131 ile birlikte gelir)\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n #TURKISH\n# Bu Python 3 ortam\u0131, y\u00fckl\u00fc bir\u00e7ok yard\u0131mc\u0131 analiz kitapl\u0131\u011f\u0131 ile birlikte gelir\n# Kaggle\/python docker image ile tan\u0131mlan\u0131r: https:\/\/github.com\/kaggle\/docker-python\n# \u00d6rne\u011fin, y\u00fcklenebilecek birka\u00e7 faydal\u0131 paket\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory (Giri\u015f veri dosyalar\u0131 \"..\/input\/\" dizininde mevcuttur.)\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n #( \u00d6rne\u011fin, bunu \u00e7al\u0131\u015ft\u0131rmak (\u00e7al\u0131\u015ft\u0131r'\u0131 t\u0131klatarak veya Shift+Enter tu\u015flar\u0131na basarak) giri\u015f dizinindeki dosyalar\u0131 listeleyecektir.)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n #TURKISH\n# \"Save & Run All\" se\u00e7ene\u011fini kullanarak bir s\u00fcr\u00fcm olu\u015fturdu\u011funuzda \u00e7\u0131kt\u0131 olarak korunan ge\u00e7erli dizine (\/kaggle\/working\/) 20GB'a kadar yazabilirsiniz.\n# \/kaggle\/temp\/ dizinine ge\u00e7ici dosyalar da yazabilirsiniz, ancak bunlar ge\u00e7erli oturumun d\u0131\u015f\u0131nda kaydedilmez","e0549be4":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_PassengerId = test_df[\"PassengerId\"]","d11e8fec":"train_df.columns","9ce95d7a":"train_df.head()\n","098d0b85":"train_df.describe()","6a6481a5":"train_df.info()","1c568ad9":"def bar_plot(variable):\n    \"\"\"input: variable ex: \"Sex\"\n       output: Bar plot & value count\n    \"\"\"\n    # get feature ( \u00f6zellik al)\n    var = train_df[variable]\n    # count  number of catecorical variable(value\/sample)  (kategorik de\u011fi\u015fkenin sayma say\u0131s\u0131(value\/sample))\n    varValue = var.value_counts()\n    \n    #visualize(g\u00f6rselle\u015ftirme)\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"frequency(S\u0131kl\u0131k)\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}:\".format(variable,varValue))\n    ","a86cd086":"category1 =[\"Survived\", \"Sex\", \"Pclass\", \"Embarked\", \"SibSp\", \"Parch\"]\nfor c in category1:\n    bar_plot(c)","e1f7eb42":"category2 = [\"Cabin\", \"Fare\", \"PassengerId\"]\nfor c in category2:\n    print(\"{}  \\n \".format(train_df[c].value_counts()))\n   # bar_plot(c)","12b80ef9":"def plot_hist(variable):\n    plt.figure(figsize=(7,3))\n    plt.hist(train_df[variable], bins= 50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency(s\u0131kl\u0131k)\")\n    plt.title(\"{} distribution with list\".format(variable))\n    plt.show()\n    ","372999f2":"numericVar= [\"Fare\", \"Age\", \"PassengerId\"]\nfor n in numericVar:\n    plot_hist(n)","100c8c31":"#Pclass vs Survived\ntrain_df[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"],as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","c3e17ee3":"#Sex vs Survived\ntrain_df[[\"Sex\", \"Survived\"]].groupby([\"Sex\"],as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","334fddf4":"#SibSp vs Survived\ntrain_df[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"],as_index = False).mean().sort_values(by=\"Survived\", ascending = False)","74928e0d":"#Age vs Survived\ntrain_df[[\"Age\", \"Survived\"]].groupby([\"Age\"],as_index = False).mean().sort_values(by=\"Survived\", ascending = False)\n","29ffbfbd":"#Parch vs Survived\ntrain_df[[\"Parch\", \"Survived\"]].groupby([\"Parch\"],as_index = False).mean().sort_values(by=\"Survived\", ascending = False)\n","3ec18396":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces ( ayk\u0131r\u0131 de\u011ferleri ve indekslerini tespit edin)\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers","a0ea0dc4":"train_df.loc[detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","7ea16896":"#drop outliers\ntrain_df = train_df.drop(detect_outliers(train_df, [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]), axis = 0).reset_index(drop = True)","8ff445f6":"train_df_len = len(train_df)\ntrain_df = pd.concat([train_df, test_df], axis = 0).reset_index(drop = True)","9c0746a9":"train_df.head()","3d7aec34":"train_df.columns[train_df.isnull().any()] # any missing data","2ee1ba3c":"train_df.isnull().sum()  #count missing data  (eksik verileri say)","b353b720":"train_df[train_df[\"Embarked\"].isnull()] #Are there any missing values in the embarked column? Embarked kolonunda eksik veri var m\u0131","099a651a":"train_df.boxplot(column = \"Fare\", by = \"Embarked\") # Fare bilgisine g\u00f6re Embarked \nplt.show()","670ff768":"train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"C\")  # Fill missing Embarked values with C (Eksik  Embarked de\u011ferlerini C ile doldur)\ntrain_df[train_df[\"Embarked\"].isnull()] #  if not missing value does not output (eksik de\u011fer olmad\u0131\u011f\u0131 zaman \u00e7\u0131kt\u0131 vermez) \n","1e3a75ce":"train_df[train_df[\"Fare\"].isnull()]\n","ff809955":"train_df[\"Fare\"] = train_df[\"Fare\"].fillna(np.mean(train_df[train_df[\"Pclass\"] == 3][\"Fare\"]))","81e20039":"train_df[train_df[\"Fare\"].isnull()]\n","e650fe62":"list1 = [\"SibSp\", \"Parch\", \"Age\", \"Fare\", \"Survived\"]\nsns.heatmap(train_df[list1].corr(), annot = True, fmt = \".2f\")\nplt.show()","061b7c0d":"g = sns.factorplot(x=\"SibSp\", y=\"Survived\", data=train_df, kind= \"bar\", size=6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()\n","343d3563":"g = sns.factorplot(x = \"Parch\", y = \"Survived\", kind = \"bar\", data = train_df, size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","acc139de":"g= sns.factorplot(x = \"Pclass\", y = \"Survived\", data = train_df, kind = \"bar\", size = 6)\ng.set_ylabels(\"Survived Probability\")\nplt.show()","eca33e1e":"g = sns.FacetGrid(train_df, col = \"Survived\" )\ng.map(sns.distplot, \"Age\", bins = 25)\nplt.show()","10ffdb06":"g= sns.FacetGrid(train_df, col = \"Survived\", row = \"Pclass\", size = 2)\ng.map(plt.hist, \"Age\", bins = 25)\ng.add_legend()\nplt.show()\n","668bbf98":"\ng = sns.FacetGrid(train_df, row = \"Embarked\", size = 2)\ng.map(sns.pointplot, \"Pclass\", \"Survived\", \"Sex\")\ng.add_legend()\nplt.show()","791c1349":"\ng = sns.FacetGrid(train_df, row = \"Embarked\", col = \"Survived\", size = 2.3)\ng.map(sns.barplot, \"Sex\", \"Fare\")\ng.add_legend()\nplt.show()\n","74e0db8a":"train_df[train_df[\"Age\"].isnull()]","3e499493":"\nsns.factorplot(x = \"Sex\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","9db67918":"sns.factorplot(x = \"Sex\", y = \"Age\", hue = \"Pclass\", data = train_df, kind = \"box\")\nplt.show()","7d9bbb3c":"sns.factorplot(x = \"Parch\", y = \"Age\", data = train_df, kind = \"box\")\nsns.factorplot(x = \"SibSp\", y = \"Age\", data = train_df, kind = \"box\")\nplt.show()","453905ec":"#train_df[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_df[\"Sex\"]]","74891ac9":"# AGE, SibSp Parch, Pclass featurs Is there any correlation between them?(AGE, SibSp Parch, Pclass featurlar\u0131 Aralar\u0131nda korelasayon varm\u0131)\nsns.heatmap(train_df[[\"Age\", \"Sex\", \"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\nplt.show()","1ec12668":"index_nan_age = list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"] == train_df.iloc[i][\"SibSp\"]) &(train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])& (train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median()\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred\n    else:\n        train_df[\"Age\"].iloc[i] = age_med","ad7249f1":"index_nan_age =list(train_df[\"Age\"][train_df[\"Age\"].isnull()].index) # Finding the indexes of the nan values in the age feature and writing them into the list (Age feature i\u00e7indeki bo\u015f de\u011ferlerin indexlerini bul ve listenin i\u00e7ine yaz)\nfor i in index_nan_age:\n    age_pred = train_df[\"Age\"][((train_df[\"SibSp\"]==train_df.iloc[i][\"SibSp\"])& (train_df[\"Parch\"] == train_df.iloc[i][\"Parch\"])&(train_df[\"Pclass\"] == train_df.iloc[i][\"Pclass\"]))].median() #prediction (bu feature lar\u0131n median de\u011ferine g\u00f6re age feature i\u00e7indeki bo\u015f de\u011ferleri tahmin et)\n    age_med = train_df[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_df[\"Age\"].iloc[i] = age_pred # if there is no nan value in it( e\u011fer i\u00e7inde bo\u015f de\u011fer yoksa)\n    else:\n        train_df[\"Age\"].iloc[i]= age_med # take median of age feature if nan(e\u011fer bo\u015f de\u011fer varsa age feature n\u0131n medyan\u0131n\u0131 al)","aaedb5b7":"train_df[train_df[\"Age\"].isnull()]","fcd9e180":"train_df[\"Name\"].head(10)\n#In the train_df dataset, I can't look at the \"name\" feature and find out if they survived, but when I look at them as female (mrs) or male (mr), I can get an inference from here.\n\n#TURKISH\n#train_df veri setinde name \u00f6zelli\u011fine bak\u0131p hayatta kal\u0131p kalmad\u0131klar\u0131n\u0131 \u00f6\u011frenemem ama kad\u0131n(mrs) ya da erkek(mr) olarak bakt\u0131\u011f\u0131m zaman burdan \u00e7\u0131kar\u0131m elde edebilirim","5f902e39":"name = train_df[\"Name\"]\ntrain_df[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]\n# title ad\u0131nda yeni bir liste olu\u015fturup split metoduyla \".\" ya g\u00f6re ay\u0131r\u0131yorum ve 0. indexteki eleman\u0131 al\u0131yorum  ve split\",\" yaparak -1. indexteki eleman\u0131 al\u0131yorum                     ","ec80ef75":"train_df[\"Title\"].head(10)","dfabb57f":"sns.countplot(x=\"Title\", data = train_df)\nplt.xticks(rotation = 60)\nplt.show()","3b42a188":"train_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\n#process of combining low value names (d\u00fc\u015f\u00fck de\u011ferli isimleri birle\u015ftirme i\u015flemi)\n","2d299c1f":"sns.countplot(x=\"Title\", data = train_df) # New Feature (Yeni listedeki \u00f6zelliklerin g\u00f6rselle\u015ftirilmesi)\nplt.xticks(rotation = 60)\nplt.show()","5db2b7ad":"train_df[\"Title\"] = train_df[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_df[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_df[\"Title\"]]\ntrain_df[\"Title\"].head(20)\n\n# names were combined and converted to numbers (isimler birle\u015ftirildi ve say\u0131lara d\u00f6n\u00fc\u015ft\u00fcr\u00fcld\u00fc)","b364cafe":"train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)\n\n# survival rate by name and title (\u0130sim ve \u00fcnvanlara g\u00f6re hayatta kalma oranlar\u0131)\n\n\ng = sns.factorplot(x = \"Title\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_xticklabels ([\"Master\", \"Mirs\", \"Mr\", \"Other\"])\ng.set_ylabels(\"Survival Probability\")\nplt.show()","0b50428d":"#train_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","1152cca2":"train_df.head(10)","b952aff6":"train_df = pd.get_dummies(train_df, columns = [\"Title\"]) #we created 4 new columns with this method( bu method sayesinde Title featurunu 4 s\u00fctuna b\u00f6ld\u00fck)\ntrain_df.head()","96770f00":"train_df.head()","6e8a18ff":"train_df[\"Fsize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"]+1 #new feature \"Fsize\"","586babb7":"train_df.head()","307df851":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","ba7dfad6":"train_df[\"family_size\"] = [1 if i < 5 else 0 for i in train_df[\"Fsize\"]] # be\u015ften k\u00fc\u00e7\u00fck de\u011ferl 1 5 ten b\u00fcy\u00fck de\u011ferler 0\n","92a830bb":"train_df.head(10)","ebb668ab":"sns.countplot(x = \"family_size\", data = train_df) #count (say)","8119f783":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_df, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","3a1759dd":"train_df = pd.get_dummies(train_df, columns = [\"family_size\"]) # new columns family_size_0 ,(iki yeni s\u00fctun olu\u015fturuyoruz)\ntrain_df.head()","11710b56":"train_df[\"Embarked\"].head()","ca5029e2":"sns.countplot(x = \"Embarked\", data =train_df)","d42bcf2d":"train_df = pd.get_dummies(train_df, columns =[\"Embarked\"]) # Create Embarked_C,Embarked_Q Embarked_S\ntrain_df.head()","eb212dbf":"train_df[\"Ticket\"].head(20)","0f978d01":"# example\na = \"A\/5. 2151\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0]\n\n#strip = If there are leading and trailing spaces, it will remove those spaces. ( ba\u015fta ve sonda bo\u015fluk varsa o bo\u015fluklar\u0131 yok eder)","3c212c82":"tickets = []\nfor i in list (train_df.Ticket):\n    if not i.isdigit():                   #If there is a number or digit at the beginning, split it and get the element at index 0\n                                         #E\u011fer ba\u015f\u0131nda bir say\u0131 veya rakam varsa ay\u0131r ve 0. indexteki eleman\u0131 al\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_df[\"Ticket\"] = tickets\n\n","da2df379":"train_df[\"Ticket\"].head(20)","cce2119d":"train_df = pd.get_dummies(train_df, columns= [\"Ticket\"], prefix = \"T\")\ntrain_df.head(10)\n #prefix =takes only initial(sadece ilk harfi al\u0131r)\n","d58aed7e":"sns.countplot(x = \"Pclass\", data= train_df)\nplt.show()","b5f20871":"train_df[\"Pclass\"]= train_df[\"Pclass\"].astype(\"category\")  #create Pclass_1, Pclass_2, Pclass_3\ntrain_df = pd.get_dummies(train_df,columns = [\"Pclass\"])\ntrain_df.head()","13f6192c":"train_df[\"Sex\"] = train_df[\"Sex\"].astype(\"category\")\ntrain_df = pd.get_dummies(train_df, columns=[\"Sex\"])\ntrain_df.head()\n","95e6074b":"train_df.drop(labels = [\"PassengerId\", \"Cabin\"], axis = 1, inplace = True)","9e267027":"train_df.columns","872499fa":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","b2f89384":"train_df_len","5bbd94db":"test = train_df[train_df_len:]  # train_df in uzunlu\u011funun sonuna kadar git ve teste e\u015fitle\ntest.drop(labels = [\"Survived\"],axis = 1, inplace = True)# Survived s\u00fctununu \u00e7\u0131kar ve teste e\u015fitle","07fef302":"test.head()","8a0e33f5":"\ntrain = train_df[:train_df_len]\nX_train = train.drop(labels = \"Survived\", axis = 1)\ny_train = train[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(X_train))\nprint(\"X_test\",len(X_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))\nprint(\"test\",len(test))\n\n\n","366c996e":"\n\nlogreg = LogisticRegression(solver='liblinear')\nlogreg.fit(X_train, y_train)\nacc_log_train = round(logreg.score(X_train, y_train)*100,2) \nacc_log_test = round(logreg.score(X_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))\n","b5cdd6ee":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state = random_state), #ilk olarak benim atayaca\u011f\u0131m bir parametre var oda random state parametresi\n             SVC(random_state = random_state),                      #di\u011fer parametreler hyperparameter tuning(hiperparametre ayarlamas\u0131) yap\u0131l\u0131rken en iyi de\u011fere g\u00f6re se\u00e7ilecek\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(solver='liblinear', random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),  # n = [1,2,3...x] \u015feklinde bir liste olu\u015fturulup eucliadean ve manhattan instancelara bakarak en iyi sonuca sahip parametleri veriyor\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","bc3b423d":"cv_result = []   #sonu\u00e7lar\u0131 tutacak\nbest_estimators = [] # en iyi makine \u00f6\u011frenmesi modelini se\u00e7ecek\nfor i in range(len(classifier)): #classifeirin i\u00e7inde d\u00f6n\u00fcp en iyi makine \u00f6\u011frenmesi modelini se\u00e7ecek\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(X_train,y_train)\n    cv_result.append(clf.best_score_)      # en iyi skoru tutar                                       # njops = kodun paralel olarak ko\u015fmas\u0131n\u0131 sa\u011flayan parametler\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","1bb72ed3":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy(Ortalama Do\u011fruluk)\")\ng.set_title(\"Cross Validation Scores(\u00c7apraz Do\u011frulama Puanlar\u0131)\")","77541029":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(X_train, y_train)\nprint(accuracy_score(votingC.predict(X_test),y_test))","2e8b765b":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_PassengerId, test_survived],axis = 1)\nresults.to_csv(\"titanic_apo.csv\", index = False)","2468bbf9":"test_survived.head(20)","2f78fbea":"<a id= \"11\"> <a\/> <br>\n# Visualization","71c11693":"<a id= \"10\"> <a\/> <br>\n## Fill Missing Value\n* Embarked has 2 missing value ( Embarked 2 eksik de\u011fere sahip)\n* Fare only 1 ( Fare yaln\u0131zca 1 eksik de\u011fere sahip)","d67a6766":"<a id= \"13\"> <a\/> <br>\n\n## SibSp--Survived","c2f7f29e":"<a id= \"20\"> <a\/> <br>\n\n## Fill Mising Age Feature","b3f76cb5":"* Age is not correlated with sex but it is correlated with parch, sibsp and pclass.(Ya\u015f cinsiyetle de\u011fil, parch, sibsp ve pclass ile ili\u015fkilidir.)\n\n","822c16ad":"<a id= \"14\"> <a\/> <br>\n\n## Parch--Survived","f15379d4":"* 1st class passengers are older than 2nd, and 2nd is older than 3rd class.(1. s\u0131n\u0131f yolcular 2. s\u0131n\u0131ftan, 2. s\u0131n\u0131f yolcular 3. s\u0131n\u0131ftan daha ya\u015fl\u0131d\u0131r.)","4bed7724":"* 590 data will be trained 291 data will be tested(590 veri train edilecek 291 veri test edilecek)","a6634292":"<a id= \"24\"> <a\/> <br>\n\n## Embarked","78e33067":"* Small familes have more chance to survive than large families.(K\u00fc\u00e7\u00fck ailelerin b\u00fcy\u00fck ailelere g\u00f6re hayatta kalma \u015fans\u0131 daha y\u00fcksek)","8d29cbea":"* Sibsp and parch can be used for new feature extraction with th = 3 (Sibsp ve parch, th = 3 ile yeni \u00f6zellik \u00e7\u0131kar\u0131m\u0131 i\u00e7in kullan\u0131labilir)\n* small familes have more chance to survive. (k\u00fc\u00e7\u00fck ailelerin hayatta kalma \u015fans\u0131 daha fazlad\u0131r.)\n* there is a std in survival of passenger with parch = 3 (parch = 3 olan yolcunun hayatta kalmas\u0131nda bir std var)","97a3b613":"<a id = \"25\"> <a\/> <br>\n## Ticket","ffa523be":"<a id = \"33\"><\/a><br>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation (Hiperparametre Ayarlama -- Izgara Arama -- \u00c7apraz Do\u011frulama)\n\nWe will compare 5 ml classifier and evaluate mean accuracy of each of them by stratified cross validation.\nTURKISH\n(Bu modelleriin i\u00e7erisinde bulunan parametrelerin en iyisini arayaca\u011f\u0131z bunu ararken Grid Search y\u00f6ntemini kullanaca\u011f\u0131z ve buldu\u011fumuz parametrelerin en iyi de\u011ferlerini cross Validation(\u00e7apraz do\u011frulama) ile kar\u015f\u0131la\u015ft\u0131raca\u011f\u0131z)\n\n\n* Decision Tree\n* SVM (support vector machine)\n* Random Forest \n* KNN\n* Logistic Regression","8d61b915":"<a id =\"3\"><\/a> <br>\n\n# Univariate Variable Analysis (tek de\u011fi\u015fkenli de\u011fi\u015fken analizi)\n  * Categorical Variable(Kategorik de\u011fi\u015fken): Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, SibSp and Parch\n  * Numerical Variable(say\u0131sal de\u011fi\u015fken): Fare, Age and PassengerId","89f4277f":"<a id= \"8\"> <a\/> <br>\n # 5. Missing Value ( Eksik de\u011fer)\n   * Find Missing Value\n\n   * Fill Missing Value\n    ","b20aefd7":"*","c64e34ae":"<a id= \"21\"> <a\/> <br>\n# Feature Engineering\n  ","c4829d2f":"<a id= \"17\"> <a\/> <br>\n\n## Pclass--Survived--Age","c8d80222":"<a id= \"18\"> <a\/> <br>\n## Embarked Pclass Sex Survived","9b483a7a":"* Female passengers have much better survival rate than males.(Kad\u0131n yolcular erkeklerden \u00e7ok daha iyi hayatta kalma oran\u0131na sahiptir.)\n* Males have better surv\u015fval rate in pclass 3 in C. (Erkeklerin C'de pclass 3'te daha iyi hayatta kalma oran\u0131 vard\u0131r.)\n* Embarked and sex will be used in training. (Embarked and sex e\u011fitimlerde kullan\u0131lacakt\u0131r)\n","023255bb":"<a id =\"6\"> <a\/> <br>\n   \n# 3. Basic Data Analysis (Temel Veri Analizi)\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Age - Survived\n* parch - Survived","2404c85d":"<a id = \"30\"> <a\/> <br>\n\n# Modeling","5d8fffdb":"<a id =\"1\"><\/a> <br>\n# 1.Load And Check Data(verileri y\u00fckleyin ve kontrol edin)\n","8d07bb2d":"<a id = \"29\"> <a\/> <br>\n\n## Drop Passenger Id And Cabin (Yolcu Kimli\u011fi Ve Kabin Bilgisini \u00c7\u0131kar)","a6c8ab30":"<a id =\"2\"><a\/> <br>\n# Variable Description (de\u011fi\u015fkenlerin a\u00e7\u0131klamas\u0131)\n    \n1.PassengerId : unique id number each passenger = her yolcunun benzersiz kimlik numaras\u0131\n\n2.Survived : passenger survive(1) or died(0) = yolcu hayatta kald\u0131 (1) veya \u00f6ld\u00fc (0)\n\n3.Pclass: passenger class = yolcu s\u0131n\u0131f\u0131 \n\n4.Name: name = isim \n\n5.Sex: gender of passenger : yolcu cinsiyeti \n\n6.Age : age of passenger : yolcu ya\u015f\u0131\n\n7.SibSp: number of siblings\/spouses = karde\u015f\/e\u015f say\u0131s\u0131\n\n8.Parch: number of parents\/children = aile\/\u00e7ocuk say\u0131s\u0131\n\n9.Ticket: ticket number = bilet numaras\u0131\n\n10.Fare:amount of money spent on ticket: bilet harcanan para\n\n11.Cabin:cabin category = kabin kategorisi\n\n12.Embark: port where passenger embarked(C = Cherbourg, Q =Queenstown, S = Southampton) = yolcular\u0131n bindi\u011fi limanlar","cd5791ab":"<a  id = \"5\" > <a\/> <br>\n## Numerical Variable(say\u0131sal de\u011fi\u015fken)","6c731d57":"<a id= \"19\"> <a\/> <br>\n\n## Embarked Fare Sex Survived","07e49b80":"* float64(2): fare and age\n* int64(5): Pclass,SibSp, Parch, Survived , PassengerId\n* object(5): Name, Sex, Ticket, Cabin , Embarked","a710c8d4":"<a id = \"32\"> <a\/> <br>\n##  simple logistic regression model(basit lojistik regresyon modeli)        \n","816eca80":"<a id= \"12\"> <a\/> <br>\n\n### [Corellation Between SipSp -- Parch -- Age -- Fare -- Survived]","a7b3f479":"* Sex is not informative for age prediction, age distribution seems to be same.(Cinsiyet, ya\u015f tahmini i\u00e7in bilgilendirici de\u011fildir, ya\u015f da\u011f\u0131l\u0131m\u0131 ayn\u0131 g\u00f6r\u00fcnmektedir.)","f885bd73":"<a id = \"26\"> <a\/> <br>\n## Pclass","c4a2761c":"<a id= \"23\"> <a\/> <br>\n## Family size","059bd46a":"<a id = \"35\"><\/a><br>\n## Prediction and Submission(Tahmin ve G\u00f6nderme)","6ed5c5c1":"<a id = \"34\"><\/a><br>\n## Ensemble Modeling (Toplu Modelleme)","f084b45c":"<a id= \"16\"> <a\/> <br>\n\n## Age--Survived","b2f0fa7e":"<a id = \"27\"> <a\/> <br>\n## Sex (Cinsiyet)","6f5c569d":"* Fare feature seems to have correlation with survived feature (0.26).\n\n* (\u00dccret \u00f6zelli\u011finin, hayatta kalan \u00f6zellik (0,26) ile korelasyonu var gibi g\u00f6r\u00fcn\u00fcyor.)","ece93c11":"<a id= \"9\"> <a\/> <br>\n## Find Missing Value","b86714bd":"<a id= \"15\"> <a\/> <br>\n\n## Pclass--Survived\n","b7368279":"* Having a lot of SibSp have less chance to survive. (\u00c7ok say\u0131da SibSp'ye sahip olman\u0131n hayatta kalma \u015fans\u0131 daha azd\u0131r.)\n* if sibsp == 0 or 1 or 2, passenger has more chance to survive (sibsp == 0 veya 1 veya 2 ise, yolcunun hayatta kalma \u015fans\u0131 daha fazlad\u0131r)\n* we can consider a new feature describing these categories.(bu kategorileri a\u00e7\u0131klayan yeni bir \u00f6zellik d\u00fc\u015f\u00fcnebiliriz.)","450e7767":"<a id= \"22\"> <a\/> <br>\n  \n## Name--Title\n","61a3b0bd":"* age <= 10 has a high survival rate, (ya\u015f <= 10 y\u00fcksek bir hayatta kalma oran\u0131na sahiptir,)\n* oldest passengers (80) survived, (en ya\u015fl\u0131 yolcular (80) hayatta kald\u0131,)\n* large number of 20 years old did not survive, (20 ya\u015f\u0131ndaki \u00e7ok say\u0131da ki\u015fi hayatta kalamad\u0131,)\n* most passengers are in 15-35 age range, (\u00e7o\u011fu yolcu 15-35 ya\u015f aral\u0131\u011f\u0131nda,)\n* use age feature in training (e\u011fitimde ya\u015f \u00f6zelli\u011fini kullan)\n* use age distribution for missing value of age (eksik ya\u015f de\u011feri i\u00e7in ya\u015f da\u011f\u0131l\u0131m\u0131n\u0131 kullan)","ae54a6f1":"* Passsengers who pay higher fare have better survival. Fare can be used as categorical for training. (Daha y\u00fcksek \u00fccret \u00f6deyen yolcular daha iyi hayatta kal\u0131r. \u00dccret, e\u011fitim i\u00e7in kategorik olarak kullan\u0131labilir.)\n","af4cf010":"<a id = \"31\"> <a\/> <br>\n ## Train - Test Split\n","aa63edaf":"<a id =\"4\"><\/a> <br>\n\n## Categorical Variable(kategorik de\u011fi\u015fken)\n","2e4f6335":"<a id = \"7\"><a\/> <br>\n# 4. Outlier Delection (Ayk\u0131r\u0131 De\u011fer Se\u00e7imi)","a64248ae":"# Introduction (Tan\u0131t\u0131m)\nThe sinking of Titanic is one of the most notorius shipwredcks in the history.\nAn estimated 100,000 people gathered at the dock in Belfast, Ireland on March 31, 1911, to watch the launch of the Royal Mail Ship (RMS) Titanic. Considered to be an \u201cunsinkable\u201d ship, Titanic was the largest and most luxurious cruise liner of its day, measuring more than 882 feet long from prow to stern\u2014the length of four-city blocks\u2014and 175 feet high, and weighing more than 46,000 tons. It boasted state-of-the-art technology, including a sophisticated electrical control panel, four elevators and an advanced wireless communications system that could transmit Morse Code.\n\n\n(Titanik'in batmas\u0131, tarihin en \u00fcnl\u00fc bat\u0131klar\u0131ndan biridir.\nTahminen 100.000 ki\u015fi, Kraliyet Posta Gemisi (RMS) Titanic'in denize indirilmesini izlemek i\u00e7in 31 Mart 1911'de \u0130rlanda'n\u0131n Belfast kentindeki r\u0131ht\u0131mda topland\u0131. \"Batmaz\" bir gemi olarak kabul edilen Titanic, pruvadan k\u0131\u00e7a 882 fit uzunlu\u011fa (d\u00f6rt \u015fehir blo\u011fu uzunlu\u011funa) ve 175 fit y\u00fcksekli\u011fe ve 175 fit y\u00fcksekli\u011fe sahip olan, zaman\u0131n\u0131n en b\u00fcy\u00fck ve en l\u00fcks yolcu gemisiydi. 46.000 ton. Sofistike bir elektrik kontrol paneli, d\u00f6rt asans\u00f6r ve Mors Kodunu iletebilen geli\u015fmi\u015f bir kablosuz ileti\u015fim sistemi dahil olmak \u00fczere en son teknolojiye sahipti.)\n\nYet on the night of April 14, 1912, just four days after leaving Southampton, England on its maiden voyage to New York, the Titanic struck an iceberg off the coast of Newfoundland and sank. Now, more than a century after the Titanic went down, experts are still debating possible causes of this historic disaster that took the lives of more than 1,500 passengers and crew. Most of them agree that only a combination of circumstances can fully explain what doomed the supposedly unsinkable ship.\n\n\n(Yine de 14 Nisan 1912 gecesi, New York'a ilk yolculu\u011funda \u0130ngiltere, Southampton'dan ayr\u0131ld\u0131ktan sadece d\u00f6rt g\u00fcn sonra, Titanik Newfoundland k\u0131y\u0131lar\u0131nda bir buzda\u011f\u0131na \u00e7arpt\u0131 ve batt\u0131. \u015eimdi, Titanik batt\u0131ktan bir as\u0131rdan fazla bir s\u00fcre sonra, uzmanlar hala 1.500'den fazla yolcu ve m\u00fcrettebat\u0131n hayat\u0131n\u0131 alan bu tarihi felaketin olas\u0131 nedenlerini tart\u0131\u015f\u0131yorlar. \u00c7o\u011fu, yaln\u0131zca ko\u015fullar\u0131n bir kombinasyonunun, s\u00f6zde batmaz geminin kaderini tam olarak a\u00e7\u0131klayabilece\u011fi konusunda hemfikirdir.)\n\n# Note: The texts in parentheses are Turkish translations. And \u0131f you like my work, I will be very happy if you press the like button. (\u00c7al\u0131\u015fmam\u0131 be\u011fendiyseniz be\u011fen butonuna basarsan\u0131z \u00e7ok mutlu olurum.)\n<font color = \"purple\">\nContent :\n    \n \n 1.[Load And Check Data](#1)\n     \n 2.[Veriable Description](#2)\n   * [Univariate Veriable Analysis](#3)\n       * [Categorical Veriable](#4)\n       * [Numerical Veriable](#5)\n\n  \n \n 3.[Basic Data Analysis](#6)\n    \n 4.[Outlier Delection](#7)\n    \n 5.[Missing Value](#8)\n   * [Find Missing Value](#9)\n   * [Fill Missing Value](#10)\n \n6.[Visualization](#11)\n    \n   * [Corellation Between SipSp -- Parch -- Age -- Fare -- Survived](#12)\n   * [SibSp--Survived](#13)\n   * [Parch--Survived](#14)\n   * [Pclass--Survived](#15)\n   * [Age--Survived](#16)\n   * [Pclass--Survived--Age](#17)\n   * [Embarked--Pclass--Sex--Survived](#18)\n   * [Embarked--Fare--Sex--Survived](#19)\n   * [Fill Mising Age Feature](#20)\n    \n    \n7.[Feature Engineering](#21)\n    \n   * [Name--Title](#22)\n   * [Family size](#23)\n   * [Embarked](#24)\n   * [Ticket](#25)\n   * [Pclass](#26)\n   * [Sex](#27)\n   * [Drop Passenger Id And Cabin](#28)\n    \n8.[Modeling](#29)\n   \n   * [Train Test Split](#30)\n   * [Simple Logistic Regression Model](#31)\n   * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32) \n   * [Ensemble Modeling](#33)\n   * [Prediction and Submission](#34)\n   "}}