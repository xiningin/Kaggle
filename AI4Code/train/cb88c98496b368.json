{"cell_type":{"df25da33":"code","fe1ae104":"code","8d130e80":"code","7674f455":"code","b70aa3f5":"code","3dbb187b":"code","fd1831df":"code","9dcfe316":"code","0783ba87":"code","d29749ed":"code","0334c381":"code","2377f573":"code","b4692aae":"code","e9d18e40":"code","76bd036a":"code","bc2a4d96":"code","496531ae":"code","3b6bffe4":"code","8a2e81a8":"code","82edaea8":"code","fdfca34d":"code","df785d0a":"code","aa485c4d":"code","d8c4fdb9":"code","e12fd471":"code","c525d2c7":"code","6ae6bb97":"code","78b17cc0":"code","74d9dceb":"code","222a8592":"code","399da575":"code","8259c62e":"code","cac4c635":"code","57bcabc4":"code","2e14394a":"code","394ceb13":"code","3d8ebedb":"code","36bc0bc2":"code","d504f6b3":"code","111b37e8":"code","90f339e7":"code","f227900f":"code","e1d0b7c0":"code","564ec73a":"code","ea0c6fb7":"code","fdfa5e3b":"code","69ce8391":"code","d165930e":"code","ebcd5b4a":"code","47e094b4":"code","aac8d506":"code","79b58c05":"code","ec288145":"code","a95f7073":"code","f3bdde4e":"code","b6778476":"code","53b423db":"code","0d0169eb":"code","7fed82b8":"code","59f38c5f":"code","9e2231b2":"code","b37dfa95":"code","f992cea4":"code","4f11d852":"code","fa83991c":"code","4344ddcd":"code","aaec9f8f":"code","4150ed1b":"code","b95269d3":"code","106a9010":"code","c59ad021":"code","47cce427":"code","8b64c7d7":"code","1562210c":"code","ef83ad3d":"code","8928be85":"code","dac0019a":"code","e024a41f":"code","019996e4":"code","7b22bc35":"code","c8b1f3e1":"markdown","b28f00e9":"markdown","56bc5f64":"markdown","a85658d5":"markdown","e990d545":"markdown","969611f7":"markdown","c1838ea6":"markdown","782a143b":"markdown","34205cc3":"markdown","0ff8c8a7":"markdown","ce91a493":"markdown","a5db724c":"markdown","5b9f89eb":"markdown","b2f89aee":"markdown","d2aee7cb":"markdown","dd42d060":"markdown","69d03856":"markdown","0df19048":"markdown","20717fb5":"markdown","61e2c87c":"markdown","0db191c0":"markdown"},"source":{"df25da33":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport missingno as msno\nimport yaml\nfrom collections import Counter\nimport plotly.graph_objects as go\nimport plotly.express as xp\n\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.manifold import TSNE\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.metrics import accuracy_score\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\ncolormap = ['#050A30', '#000C66', '#0000FF', '#7EC8E3', '#D4F1F4']\nsns.palplot(colormap)","fe1ae104":"# Let's read the files and check the info\nPATH = \"..\/input\/mymusicalprefrences\/\" \ntrain_data = pd.read_csv(f\"{PATH}train.csv\")\ntest_data = pd.read_csv(f\"{PATH}test.csv\")\ndescription = yaml.load(open(f\"{PATH}Description.yaml\",'r'),Loader=yaml.FullLoader)\n\n# We merge train- and test-data for now\ndf = pd.concat([train_data,test_data], axis = 0, ignore_index = True)\ntrain_mask = ~df.Category.isna()\ndf.info()","8d130e80":"df","7674f455":"df.describe()","b70aa3f5":"# Plot missing values\nmsno.bar(df, color=colormap)","3dbb187b":"df.columns","fd1831df":"# Rename some features\n\n# Remove the space after 'Vocal '\ndf = df.rename(columns = {'Vocal ':'Vocal'})\n\n# (Optional) Remove '_'\ndf = df.rename(columns = {'Artists_Genres':'ArtistsGenres', 'Release_year':'ReleaseYear', 'Album_type':'AlbumType'})\n\n# (Optional) Correct spelling mistakes\ndf = df.rename(columns = {'Dancebility':'Danceability'})\ndf.columns","9dcfe316":"# Let's see the categorical and numerical features\n\ncategorical_features = {\"Artists\",\"Track\",\"Version\",\"ArtistsGenres\",\"Album\",\"AlbumType\",\"Labels\",\"Vocal\",\"Country\",\"Key\"}\nnumerical_features = {\"Duration\",\"ReleaseYear\",\"BPM\",\"Energy\",\"Danceability\",\"Happiness\"}\ndisplay(df[categorical_features].head())\ndisplay(df[numerical_features].head())","0783ba87":"# Let's check for some dependencies visually\nsns.pairplot(df[list(numerical_features)+[\"Category\"]],palette=colormap[2:4], hue=\"Category\")","d29749ed":"# For more easy usage of the Category feature\ndf[\"Category\"] = df[\"Category\"].fillna(\"none\").replace({0:\"dislike\",1:\"like\"})","0334c381":"# Let's check the missing value(s) in 'Artists'\ndf.loc[df['Artists'].isna()==True]","2377f573":"# We can drop this record as it has the least amount of parameters\ndf = df.drop([661])\ndf = df.reset_index(drop=True)\ndf.loc[df['Artists'].isna()==True]","b4692aae":"# Let's check the missing value(s) in 'Album'\ndf.loc[df['Album'].isna()==True]","e9d18e40":"# We replace it with 'none'\ndf[\"Album\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Album'].isna()==True]","76bd036a":"# Let's check the missing value(s) in 'Vocal'\ndf.loc[df['Vocal'].isna()==True]","bc2a4d96":"# We replace it with 'none'\ndf[\"Vocal\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Vocal'].isna()==True]","496531ae":"# Let's check the missing value(s) in 'Country'\ndf.loc[df['Country'].isna()==True]","3b6bffe4":"# We replace it with 'none'\ndf[\"Country\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Country'].isna()==True]","8a2e81a8":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['Labels'].isna()]","82edaea8":"# We replace it with 'none'\ndf[\"Labels\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Labels'].isna()==True]","fdfca34d":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['Version'].isna()]","df785d0a":"# We replace it with 'none'\ndf[\"Version\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['Version'].isna()==True]","aa485c4d":"# Let's check the missing value(s) in 'Labels'\ndf.loc[df['AlbumType'].isna()]","d8c4fdb9":"# We replace it with 'none'\ndf[\"AlbumType\"].replace(np.nan, \"none\", inplace=True)\ndf.loc[df['AlbumType'].isna()==True]","e12fd471":"msno.bar(df, color=colormap)","c525d2c7":"def split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which are only present in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique genre values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimensionality of the dataset.\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    \n    return embedded\n\ndef plot_cumulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation.\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k,marker=dict(color=colormap[i+1])))\n    fig.show()","6ae6bb97":"# Let's see how the description\nprint(description[\"Country\"])","78b17cc0":"# We split to onehot vector and plot the countries\ncountry_onehot = split_to_onehot(df, \"Country\")\nplot_cumulative_onehot(country_onehot)","74d9dceb":"# We drop the old column and replace it by the new onehot vector\ncountry_onehot = country_onehot.drop(\"Category\", axis=1)\ndf = pd.concat([df,country_onehot], axis=1)\ndf = df.drop([\"Country\", \"none\"], axis=1)\ndf.head()","222a8592":"# Let's check what is in 'Vocal'\nprint(description[\"Vocal\"])","399da575":"# Create a new array and split the vocal types\nonehot = np.zeros((len(df),2))\nfor i in range(len(df)):\n    v = df.iloc[i][\"Vocal\"]\n    if v == 'F':\n        onehot[i] = [1,0]\n    elif v == 'M':\n        onehot[i] = [0,1]\n    elif v == 'F|M':\n        onehot[i] = [1,1]\n        \n# We drop the old column and replace it by the new onehot vector\ndf[[\"FemaleVocal\",\"MaleVocal\"]] = onehot\ndf = df.drop(\"Vocal\",axis=1)\ndf.head()","8259c62e":"# Let's check the key feature\ndescription[\"Key\"]","cac4c635":"# Create a scatterplot\nxp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","57bcabc4":"# We correct some keys and replace them with the same value (C# = D\u266d, etc)\ndf[\"Major\"], df[\"Key\"] = df[\"Key\"].apply(lambda x: x.split(\" \")[1]), df[\"Key\"].apply(lambda x: x.split(\" \")[0])\ndf.loc[:,\"Key\"] = df[\"Key\"].replace({\"D\u266d\": \"C#\", \"E\u266d\": \"D#\", \"G\u266d\": \"F#\", \"A\u266d\": \"G#\",\"B\u266d\":\"A#\"})\n\n# Create a scatterplot\nxp.scatter(df, x=\"Key\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","2e14394a":"# We put the Major\/Minor part into new feature, to make it more easy for our model in the fitting process\ndf.loc[:,\"Major\"] = (df[\"Major\"]==\"Major\").astype(int)\n_df = df.groupby([\"Major\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df,x=\"Major\", y=\"Track\",color=\"Category\", height=400, color_discrete_sequence=colormap[1:4])","394ceb13":"# Let's plot a full overview (key + major\/minor)\n_df = df.copy(deep=True)\n_df[\"Key_precise\"] = _df[\"Key\"] +\"_major:\"+ _df[\"Major\"].astype(str)\n_df = _df.groupby([\"Key_precise\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df, x=\"Key_precise\", y=\"Track\", color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","3d8ebedb":"# Replace the old column with our onehot vector\ndf[list(set(df[\"Key\"].values))] = OneHotEncoder().fit_transform(df[[\"Key\"]]).toarray()\ndf = df.drop(\"Key\", axis=1)\ndf.head()","36bc0bc2":"# Check the description\nfor k in [\"Energy\",\"Happiness\",\"Dancebility\"]:\n    print(f\"{k}:{description[k]}\")","d504f6b3":"# Let's scale energy, happiness and danceabilty down proportionally\ndf[['Energy%', 'Happiness%', 'Danceability%']] = df[['Energy', 'Happiness', 'Danceability']].apply(lambda x: x\/sum(x), axis=1)\ndf = df.drop([\"Energy\", \"Danceability\", \"Happiness\"], axis=1)\ndf.head()","111b37e8":"# Let's see how the feature is structured\nprint(description[\"Artists\"])","90f339e7":"# How many artists are there\nall_artists = []\nfor i in df.index:\n    all_artists.extend(df.loc[i, \"Artists\"].split(\"|\"))\nlen(set(all_artists))","f227900f":"# We will put some threshold, not to put some rare artists into one-hot vector.\nthreshold = 3\nrare_artists = Counter(all_artists)\nrare_artists = [k for k in rare_artists if rare_artists[k]<=threshold]\nlen(rare_artists)","e1d0b7c0":"# Drop all artists who are only in the test-set or the train-set\nin_train, in_test = [], []\nfor i in df.loc[train_mask].index:\n    in_train.extend(df.loc[i, \"Artists\"].split(\"|\"))\nfor i in df.loc[~train_mask].index:\n    in_test.extend(df.loc[i, \"Artists\"].split(\"|\"))\n    \nonly_test = set(in_test) - set(in_train)\nonly_train = set(in_train) - set(in_test)\ndisplay(len(only_test))\ndisplay(len(only_train))","564ec73a":"all_artists = list(set(all_artists) - set(rare_artists) - only_test - only_train)\nprint(len(all_artists))\nrare_artists = set(rare_artists) | only_test | only_train\nprint(len(rare_artists))","ea0c6fb7":"# Create onehot vector for artists\nresult = []\ndef prune(x):\n    vector = np.zeros(len(all_artists)+1) # for rare artists\n    x = [i for i in x.split(\"|\")]\n    for i in range(len(all_artists)):\n        vector[i]=1 if all_artists[i] in x else 0\n    if len(x)>sum(vector):\n        vector[-1]=1\n    result.append(vector)\n\ndf[\"Artists\"].apply(prune)\nonehot_artists = pd.DataFrame(result, columns = all_artists + [\"Others\"], index=df.index)\n\nonehot_artists","fdfa5e3b":"# We drop the rare artists (Others) column, it's not really relevant.\nonehot_artists = onehot_artists.drop(\"Others\", axis=1)\n\n# Let's plot the artists\nonehot_artists[\"Category\"] = df[\"Category\"]\nplot_cumulative_onehot(onehot_artists)","69ce8391":"# Since there are too many features in the onehot vector, we will apply tsne (dimensionality reduction)\nartists_embedded = onehot_to_tsne2(onehot_artists, \"Artists\")\n_df = artists_embedded.copy(deep=True)\n_df[[\"Category\",\"Artists\"]] = df[[\"Category\",\"Artists\"]]\n\n# Create scatterplot to visualize artists, now reduced to 2 tsne values\nxp.scatter(_df,x=\"Artists_tsne1\",y=\"Artists_tsne2\",color=\"Category\", hover_data=[\"Artists\"], height=500, color_discrete_sequence=colormap[1:4])","d165930e":"# Replace the old artists column\ndf = pd.concat([df,artists_embedded[[\"Artists_tsne1\",\"Artists_tsne2\"]]], axis=1)\ndf = df.drop(\"Artists\", axis=1)\ndf.head()","ebcd5b4a":"# Check what's in the feature\ndescription[\"Release year\"]","47e094b4":"# Let's create a scatterplot\nxp.scatter(df, x=\"ReleaseYear\", y=\"Track\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","aac8d506":"# Let's create a decade feature, to detect some music of 80s, 90s etc. as a specific genre\ndf.loc[:,\"ReleaseDecade\"] = (df.loc[:,\"ReleaseYear\"]\/\/10 * 10)\n# Because of the small number of values, we will put all <80s values in the 80s genre\ndf.loc[df.loc[:,\"ReleaseDecade\"]<1990,\"ReleaseDecade\"] = 1980 \n_df = df.groupby([\"ReleaseDecade\",\"Category\"], as_index=False).count()\nxp.bar(_df,x=\"ReleaseDecade\", y=\"Track\",color=\"Category\",height=500, color_discrete_sequence=colormap[1:4])","79b58c05":"# Create onehot vector with the decades\ndf[list(set(df[\"ReleaseDecade\"].values))] = OneHotEncoder().fit_transform(df[[\"ReleaseDecade\"]]).toarray()\ndf = df.drop([\"ReleaseDecade\", \"ReleaseYear\"], axis=1)\ndf.head()","ec288145":"# Let's see the description\nprint(description[\"Labels\"])","a95f7073":"# Split the lables into onehot vector\nlabels_onehot = split_to_onehot(df, \"Labels\")\nplot_cumulative_onehot(labels_onehot)","f3bdde4e":"# Use tsne function to reduce dimensionality\nlabels_embedded = onehot_to_tsne2(labels_onehot, \"Labels\")\n_df = labels_embedded.copy(deep=True)\n_df[[\"Category\",\"Labels\"]] = df[[\"Category\",\"Labels\"]]\n\n# Create scatterplot\nxp.scatter(_df,x=\"Labels_tsne1\",y=\"Labels_tsne2\",color=\"Category\", hover_data=[\"Labels\"], height=500, color_discrete_sequence=colormap)","b6778476":"# Replace old column\ndf = pd.concat([df,labels_embedded[[\"Labels_tsne1\",\"Labels_tsne2\"]]], axis=1)\ndf = df.drop(\"Labels\", axis=1)\ndf.head()","53b423db":"# Read the description\ndescription[\"Artists Genres\"]","0d0169eb":"# To onehot vector\ngenres_onehot = split_to_onehot(df, \"ArtistsGenres\")\nplot_cumulative_onehot(genres_onehot)","7fed82b8":"# We have too much values, so we reduce the dimensionality\ngenres_embedded = onehot_to_tsne2(genres_onehot, \"Genres\")\n_df = genres_embedded.copy(deep=True)\n_df[[\"Category\",\"ArtistsGenres\"]] = df[[\"Category\",\"ArtistsGenres\"]]\n\n# Create scatterplot\nxp.scatter(_df,x=\"Genres_tsne1\",y=\"Genres_tsne2\",color=\"Category\", hover_data=[\"ArtistsGenres\"], height=500, color_discrete_sequence=colormap)","59f38c5f":"# Replace the old column\ndf = pd.concat([df,genres_embedded], axis=1)\ndf = df.drop(\"ArtistsGenres\", axis=1)\ndf.head()","9e2231b2":"# See description\nprint(description[\"Album\"])","b37dfa95":"# To onehot vector\nalbum_onehot = split_to_onehot(df, \"Album\")\nplot_cumulative_onehot(album_onehot)","f992cea4":"# Again, too much values, so reduce to 2 tsne values\nalbum_embedded = onehot_to_tsne2(onehot_artists, \"Album\")\n_df = album_embedded.copy(deep=True)\n_df[[\"Category\",\"Album\"]] = df[[\"Category\",\"Album\"]]\n\n# Scatterplot\nxp.scatter(_df,x=\"Album_tsne1\",y=\"Album_tsne2\",color=\"Category\", hover_data=[\"Album\"], height=500, color_discrete_sequence=colormap)","4f11d852":"# Replace column\ndf = pd.concat([df,album_embedded[[\"Album_tsne1\",\"Album_tsne2\"]]], axis=1)\ndf = df.drop(\"Album\", axis=1)\ndf.head()","fa83991c":"# Check the description\nfor i in [\"Track\", \"Version\", \"Album_type\"]:\n    print(description[i])","4344ddcd":"# We do not have features, so we use label encoder\ntrack_encoder = LabelEncoder()\ndf[\"Track\"] = track_encoder.fit_transform(df[\"Track\"])\ndf.head()","aaec9f8f":"# Let's see if there is a dependency\n_df = df.groupby([\"Version\",\"Category\"], as_index=False).count()\n\n# Plot a bar chart\nxp.bar(_df,x=\"Version\",y=\"Id\",color=\"Category\", color_discrete_sequence=colormap)","4150ed1b":"# To onehot vector and replace column\nversions = set(df[\"Version\"])\ndf[list(versions)] = OneHotEncoder().fit_transform(df[[\"Version\"]]).toarray()\ndf = df.drop([\"Version\",\"none\"], axis=1)\ndf.head()","b95269d3":"# Let's see for any relevance\n_df = df.groupby([\"AlbumType\",\"Category\"], as_index=False).count()\n\n# Create a bar chart\nxp.bar(_df,x=\"AlbumType\",y=\"Id\",color=\"Category\", color_discrete_sequence=colormap)","106a9010":"# Create onehot vector and replace old column\nalbumTypes = set(df[\"AlbumType\"])\ndf[list(albumTypes)] = OneHotEncoder().fit_transform(df[[\"AlbumType\"]]).toarray()\ndf = df.drop([\"AlbumType\",\"none\"], axis=1)\ndf.head()","c59ad021":"# Check the description\nfor k in [\"Duration\",\"BPM\"]:\n    print(f\"{k}:{description[k]}\")","47cce427":"# Let's see if there is a dependency\n_df = df.groupby([\"Duration\",\"Category\"], as_index=False).count()\n\n# Create scatterplot\nxp.scatter(df, x=\"Track\", y=\"Duration\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","8b64c7d7":"# No dependency really, so we leave duration as it is\n# We drop the column\ndf.drop('Duration', axis=1, inplace=True)","1562210c":"# Let's see if there is a dependency between BPM and (no) likes\n_df = df.groupby([\"BPM\",\"Category\"], as_index=False).count()\n\n# Create scatterplot\nxp.scatter(df, x=\"Track\", y=\"BPM\",color=\"Category\", height=500, color_discrete_sequence=colormap[1:4])","ef83ad3d":"# No dependency I guess, so we leave BPM as it is\n# We drop the column\ndf.drop('BPM', axis=1, inplace=True)","8928be85":"df","dac0019a":"df.info()","e024a41f":"# Let's select our features\nfeatures = df.columns[2:]\ndummies = pd.get_dummies(df[features])\nx = dummies[:-370]\nx_acc = dummies[-370:-300]\nx_test = dummies[-300:]\n\ntrain_data = df[:-370]\ny = train_data['Category']\ntrain_data_acc = df[-370:-300]\ny_test = train_data_acc[\"Category\"]","019996e4":"# Try different models\nmodel = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 42)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with RandomForest is: ', accuracy)\n\nmodel = AdaBoostClassifier(n_estimators = 1000)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with AdaBoost is: ', accuracy)\n\nmodel = GradientBoostingClassifier(n_estimators = 1000)\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with GradientBoosting is: ', accuracy)\n\nmodel = DecisionTreeClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with DecisionTree is: ', accuracy)\n\nmodel = LinearDiscriminantAnalysis()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with LinearDiscriminant is: ', accuracy)\n\nmodel = SVC()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with SupportVectorMachine: ', accuracy)\n\nmodel = ExtraTreesClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with ExtraTrees: ', accuracy)\n\nmodel = MLPClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with MLPClassifier: ', accuracy)\n\nmodel = GaussianProcessClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with GaussianProcess: ', accuracy)\n\nmodel = KNeighborsClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with KNeighbors: ', accuracy)\n\nmodel = CatBoostClassifier()\nmodel.fit(x, y)\npredictions = model.predict(x_acc)\naccuracy = accuracy_score(y_test, predictions)\nprint('Accuracy with CatBoost: ', accuracy)","7b22bc35":"# RandomForest gives the best accuracy\n\nfinal_model = RandomForestClassifier(n_estimators = 1000, max_depth = 10, random_state = 42)\nfinal_model.fit(x, y)\n\nsample = pd.read_csv(\"..\/input\/mymusicalprefrences\/sample_submition.csv\")\nsample[\"Category\"] = final_model.predict(x_test)\nsample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)\nsample.to_csv(\".\/submission.csv\", index=False)","c8b1f3e1":"**3.9 ALBUM**","b28f00e9":"**3.10 TRACK, VERSION, ALBUM TYPE**","56bc5f64":"Version","a85658d5":"AlbumType","e990d545":"**3.6 RELEASE YEAR**","969611f7":"**3.11 DURATION, BPM**","c1838ea6":"**3.2 VOCAL**","782a143b":"Track","34205cc3":"# **4. MODEL SELECTION**","0ff8c8a7":"# **1. DATA ANALYSIS**","ce91a493":"**3.4 ENERGY, HAPPINESS, DANCEABILITY**","a5db724c":"***SOME USEFUL FUNCTIONS***","5b9f89eb":"**3.8 ARTISTS GENRES**","b2f89aee":"**3.1 COUNTRY**","d2aee7cb":"Duration","dd42d060":"# **3. FEATURE ENGINEERING**","69d03856":"BPM","0df19048":"**3.5 ARTISTS**  ","20717fb5":"**3.3 KEY**","61e2c87c":"**3.7 LABELS**","0db191c0":"# **2. DATA PREPARATION**"}}