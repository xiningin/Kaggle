{"cell_type":{"67fb73b3":"code","bdebfe2a":"code","4b135671":"code","d5af0324":"code","227dfd9c":"code","f4683f62":"code","058ac3f8":"code","d9a05af9":"code","1377880a":"code","4f1bf909":"code","9a8cb816":"code","21f176ac":"code","f143088c":"code","947dd046":"code","37813782":"code","3c87e02d":"code","4c6fc419":"code","9ab7aabf":"code","d67534c7":"code","c3736ecd":"code","6cd66599":"code","87b11487":"code","f7ca595f":"code","dd02fbb9":"code","aa7cb624":"code","cccabbdb":"code","4b27e94d":"code","bbdccafe":"code","01cb6dd9":"code","12e110b1":"code","e996ae9d":"code","04fa75d4":"code","9009bfa1":"code","9430e7d9":"code","f4ae240f":"code","63134e6d":"code","9c769638":"code","155c2848":"code","69116c49":"code","7dd592d7":"code","2cc1a1f7":"code","6c86ab77":"code","d6252337":"code","97629dd8":"code","fabacb3e":"code","8eb1b583":"code","f1805c27":"code","6cb13dac":"code","0970ce6f":"code","14502a71":"code","2c76da6b":"code","1a771871":"code","b14e2ffd":"markdown","d0f916f2":"markdown"},"source":{"67fb73b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bdebfe2a":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","4b135671":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\ncombine = [train_df, test_df]\n\nprint(train_df.columns.values)","d5af0324":"# preview the data\ntrain_df.head()","227dfd9c":"train_df.info()\nprint('_'*40)\ntest_df.info()","f4683f62":"# distribution of numerical feature values\ntrain_df.describe()","058ac3f8":"train_df.describe(include=['O'])","d9a05af9":"train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by=\"Survived\",ascending=False)","1377880a":"train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","4f1bf909":"train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","9a8cb816":"train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","21f176ac":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","f143088c":"grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', )\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\n# grid.add_legend()","947dd046":"# grid = sns.FacetGrid(train_df, col='Embarked')\ngrid = sns.FacetGrid(train_df, row='Embarked', height=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n# grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n\ngrid.add_legend()","37813782":"# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})\ngrid = sns.FacetGrid(train_df, row='Embarked', col='Survived', aspect=1.6)\ngrid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\ngrid.add_legend()","3c87e02d":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\ncombine = [train_df, test_df]","4c6fc419":"train_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","9ab7aabf":"print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\n\n\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape","d67534c7":"# \u53d6\u51fa\u6709\u7528\u7684title\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n# https:\/\/blog.csdn.net\/geek64581\/article\/details\/107060181\/\n# pd.crosstab(train_df['Title'], train_df['Sex'])\npd.pivot_table(train_df, index='Title',columns='Sex',values='Survived',aggfunc='count').head()","c3736ecd":"# \u66ff\u6362\u6389\u5947\u602a\u7684\u7c7b\u522b\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \npd.pivot_table(train_df, index='Title',values='Survived')","6cd66599":"# We can convert the categorical titles to ordinal.\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\n# \u5c06\u6027\u522b\u8f6c\u5316\u4e3aint\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n    \ntrain_df.head()","87b11487":"# \u5220\u6389\u4e0d\u7528\u7684\u884c\ntrain_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape","f7ca595f":"# \u586b\u8865age\u7a7a\u767d\u9879\n","dd02fbb9":"# grid = sns.FacetGrid(train_df, col='Pclass', hue='Gender')\ngrid = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend()","aa7cb624":"# \u586b\u8865\u4e24\u4e2a\u6570\u636e\u96c6\u7684age\u7a7a\uff0c\u6ce8\u610f\u662f\u4e24\u4e2a\u6570\u636e\u96c6\uff01\n# \u6709\u6839\u636esex \u548c pclass \u6709\u516d\u79cd\u7ed3\u679c\nguess_ages = np.zeros((2,3))\nfor dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n            # age_mean = guess_df.mean()\n            # age_std = guess_df.std()\n            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n\n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess\/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n    \n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","cccabbdb":"# Let us create Age bands and determine correlations with Survived.\n# Age \u6570\u636e\u5206\u7bb1\ntrain_df['AgeBand'] = pd.cut(train_df['Age'], 5)\npd.pivot_table(train_df,values=\"Survived\", index=\"AgeBand\")\n\n\n    \n\n\n","4b27e94d":"# \u5c06Age \u66ff\u6362\u6210 Agebands\nfor dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\n\n# \u5220\u6389AgeBand\ntrain_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","bbdccafe":"'''\nsibsp Number of Siblings\/Spouses Aboard\nparch Number of Parents\/Children Aboard\n'''\n\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\npd.pivot_table(train_df,columns=\"Survived\", index=\"FamilySize\",aggfunc=\"count\")","01cb6dd9":"for dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n    \npd.pivot_table(train_df,index=\"IsAlone\",values=\"Survived\")","12e110b1":"pd.pivot_table(train_df,index=\"IsAlone\",columns=\"Survived\",aggfunc=\"count\")","e996ae9d":"train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","04fa75d4":"# We can also create an artificial feature combining Pclass and Age.\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","9009bfa1":"# \u586b\u5145\u4e24\u4e2a\u7a7a\u7f3a\u503c\u7684Embarked\nprint(train_df['Embarked'].isna().sum())\nfreq_port = train_df.Embarked.mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n","9430e7d9":"# converting categorical feature to numeric\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","f4ae240f":"pd.pivot_table(train_df,index=\"Embarked\", values=\"Survived\")","63134e6d":"# \u586b\u5145 test_df fare\nprint(test_df[\"Fare\"].isna().sum())\ntest_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)","9c769638":"a = train_df['Fare'].to_numpy()","155c2848":"\ntrain_df['FareBand'] = pd.qcut(a, 4)\npd.pivot_table(train_df, index='FareBand', values='Survived')\n","69116c49":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)","7dd592d7":"train_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","2cc1a1f7":"test_df.head(10)","6c86ab77":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","d6252337":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","97629dd8":"coeff_df = pd.DataFrame(train_df.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","fabacb3e":"svc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","8eb1b583":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","f1805c27":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","6cb13dac":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","0970ce6f":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","14502a71":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","2c76da6b":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","1a771871":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('\/kaggle\/working\/submission.csv', index=False)","b14e2ffd":"Categorical: Survived, Sex, and Embarked. Ordinal: Pclass.\n\nContinous: Age, Fare. Discrete: SibSp, Parch.\n\nTicket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric.\n","d0f916f2":"## Analyze by pivoting features"}}