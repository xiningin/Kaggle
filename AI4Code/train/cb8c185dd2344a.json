{"cell_type":{"36ab1f9a":"code","d17819ac":"code","dfba56ea":"code","3cd72abc":"code","4e90b230":"code","db1fc822":"code","1d8dd35e":"code","d04dfe35":"code","bd368e70":"code","da295bd2":"code","821b8aa6":"code","417f5619":"code","6495e0d9":"code","38611f43":"code","df26844d":"code","c1db874e":"markdown","18f0b2a0":"markdown","f0221dd9":"markdown","fb56a665":"markdown","01f7f0bb":"markdown","f5c9fadb":"markdown","e3e732bd":"markdown","dd290a25":"markdown","805c4eb5":"markdown","42dfef73":"markdown","1f6ce8fc":"markdown","c8c8c0be":"markdown","47e9b808":"markdown"},"source":{"36ab1f9a":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\nfrom tensorflow.keras.models import Sequential","d17819ac":"DATASET_PATH = \"\/kaggle\/input\/turkish-lira-banknote-dataset\"","dfba56ea":"strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()","3cd72abc":"IMG_WIDTH = 64\nIMG_HEIGHT = 64\n\nNUM_WORKERS = 1\nPER_WORKER_BATCH_SIZE = 64\nGLOBAL_BATCH_SIZE = PER_WORKER_BATCH_SIZE * NUM_WORKERS","4e90b230":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  DATASET_PATH,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(IMG_WIDTH, IMG_HEIGHT),\n  label_mode='categorical',\n  batch_size=GLOBAL_BATCH_SIZE)","db1fc822":"test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  DATASET_PATH,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(IMG_WIDTH, IMG_HEIGHT),\n  label_mode='categorical',\n  batch_size=GLOBAL_BATCH_SIZE)","1d8dd35e":"class_names = train_ds.class_names\nprint(class_names)","d04dfe35":"num_classes = len(class_names)","bd368e70":"def scale(image, label):\n    image = tf.cast(image, tf.float32)\n    image \/= 255\n\n    return image, label","da295bd2":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntrain_ds = train_ds.map(scale, num_parallel_calls=AUTOTUNE).repeat().cache().prefetch(buffer_size=AUTOTUNE)\ntest_ds = test_ds.map(scale, num_parallel_calls=AUTOTUNE).cache().prefetch(buffer_size=AUTOTUNE)","821b8aa6":"dist_dataset = strategy.experimental_distribute_dataset(train_ds)","417f5619":"with strategy.scope():\n    model = Sequential()\n\n    # VGG Blocks\n    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_WIDTH,IMG_HEIGHT,3)))\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(Activation('relu'))\n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Conv2D(128, (3, 3), padding='same'))\n    model.add(Activation('relu'))\n    model.add(Conv2D(128, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n\n    # Dense layers\n    model.add(Dense(128))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(), \n                  loss=tf.keras.losses.CategoricalCrossentropy(),\n                  metrics=[\"accuracy\"])","6495e0d9":"es = EarlyStopping(monitor='loss', verbose=1, mode='min', patience = 2, min_delta=0.01)","38611f43":"history = model.fit(dist_dataset,\n            epochs=15,\n            steps_per_epoch = 75,\n            callbacks=[es])","df26844d":"model.evaluate(test_ds)","c1db874e":"Early stopping to speed up training and reduce overfitting","18f0b2a0":"We implement prefetch and caching of portions of the dataset in order to improve performance as suggested [here](https:\/\/www.tensorflow.org\/guide\/data_performance)","f0221dd9":"Image classification via CNN - Turkish lira\n\nThis work is the project for the Algorithms of Massive Datasets exam of the Data Science master's degree (Universit\u00e0 degli Studi di Milano, Italy)","fb56a665":"Let's train the model. Since the dataset is perfectly balanced, we may skip using a validation set.","01f7f0bb":"We now distribute the input across multiple devices. See [here](https:\/\/www.tensorflow.org\/tutorials\/distribute\/input) for more details.","f5c9fadb":"We will need to scale the rgb values in order to have them in the range [0,1] which is more convenient for a neural network. This scaling will be done real-time while batch reading the images from disk.","e3e732bd":"# Scalable image classification with Tensorflow","dd290a25":"We resize each picture to 64x64. Moreover, we set a batch size of 64 images per worker. In this example we are using a single worker, and that will need to change if you specify more than one worker in the `TF_CONFIG` file.","805c4eb5":"The scalability of the input comes from the fact that we won't load all images into main memory but we'll exploit the `tf.Data` API in order to read batches of them. In order to do this, we won't use the train\/test split provided in the txts but we will randomly split the data into a 80%-20% split.","42dfef73":"Let's define the strategy. `MultiWorkerMirroredStrategy` allows for syncronized training across multiple machines with multiple GPUs. See [here](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/distribute\/experimental\/MultiWorkerMirroredStrategy) and [here](https:\/\/www.tensorflow.org\/tutorials\/distribute\/multi_worker_with_keras) for more details.","1f6ce8fc":"Let's define the model. We build the architecture of our CNN using the famous VGG blocks","c8c8c0be":"In order to achieve distributed training, you should configure the `TF_CONFIG` file like\n\n```json\nos.environ['TF_CONFIG'] = json.dumps({\n    'cluster': {\n        'worker': [\"localhost:20000\", \"localhost:20001\"]\n    },\n    'task': {'type': 'worker', 'index': 0}\n})\n```\n\nand replace \"localhost:20000\" and \"localhost:20001\" with the ip addresses of your workers. More info [here](https:\/\/www.tensorflow.org\/tutorials\/distribute\/multi_worker_with_keras).","47e9b808":"Let's evaluate it on the test set"}}