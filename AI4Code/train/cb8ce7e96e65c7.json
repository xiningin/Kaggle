{"cell_type":{"b8e4bbf8":"code","3984fce3":"code","5a9a293f":"code","f7c31126":"code","2d1bd64f":"code","8b8e60c4":"code","334a61ca":"code","6e435ae3":"code","8402e71d":"code","ba551978":"code","937df29d":"code","a321dae0":"code","225d3f3e":"code","48c47b4e":"code","9b4a2144":"code","ac261f33":"code","b573ab30":"code","decf9d4b":"code","41ab9f3c":"code","9c44d788":"code","014cb3f4":"code","135a1a0e":"code","5158a3cc":"code","485e3c1e":"code","bb2af2c5":"code","be943497":"code","d5c28f53":"code","f507f1b7":"code","8455d6f3":"code","c413e3b1":"code","59aed194":"code","32cd7d1b":"code","f10ca822":"code","d5a5e82f":"code","78323fae":"code","3e197a22":"code","606fea51":"code","e934e06e":"code","8b2bb01a":"code","0c936898":"code","c2ffcd24":"code","a9e9181b":"code","a9ea163c":"code","db1ab5ab":"code","1e2ea527":"code","919e0d19":"code","6da6feaa":"code","e9e758da":"code","06072189":"code","9e5d4246":"code","20b94aa3":"code","788b461a":"code","38691661":"code","9fd65f7d":"code","2afe516e":"code","22f9a0b5":"code","043ebc54":"code","db3f8974":"code","fa936991":"markdown","e8e59a93":"markdown","145350ff":"markdown","2105a143":"markdown","3066d24a":"markdown","76763ca5":"markdown","676a9d09":"markdown","8518b20c":"markdown","d769e84d":"markdown","c931dc86":"markdown","f238a6b6":"markdown","cbc3ce35":"markdown","1e77e236":"markdown","ee4836ca":"markdown","c04fdda0":"markdown"},"source":{"b8e4bbf8":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score,f1_score,recall_score","3984fce3":"cols = pd.read_excel(r'..\/input\/employees-attrition-analysis\/data_dictionary.xlsx')","5a9a293f":"cols","f7c31126":"df = pd.read_csv(r'..\/input\/employees-attrition-analysis\/whole data.csv')","2d1bd64f":"df","8b8e60c4":"df.shape","334a61ca":"sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap='viridis')","6e435ae3":"df = df.dropna()","8402e71d":"df.isnull().sum()","ba551978":"df.describe()","937df29d":"df.info()","a321dae0":"from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\n\nfor i in df.columns:\n    if isinstance(df[i][0],str):\n        df[i] = encoder.fit_transform(df[i])","225d3f3e":"df","48c47b4e":"df.Attrition.value_counts()","9b4a2144":"X = df.drop(['Attrition'], axis=1)\ny =df.Attrition","ac261f33":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n","b573ab30":"lr = LogisticRegression()\n","decf9d4b":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=.2, random_state = 4589)","41ab9f3c":"from sklearn.preprocessing import StandardScaler\nScaler_X = StandardScaler()\nx_train = Scaler_X.fit_transform(x_train)\nx_test = Scaler_X.transform(x_test)","9c44d788":"lr.fit(x_train, y_train)\nlr.score(x_train, y_train)","014cb3f4":"pred = lr.predict(x_test)","135a1a0e":"accuracy_score(y_test, pred)","5158a3cc":"f1_score(y_test, pred)","485e3c1e":"recall_score(y_test,pred)","bb2af2c5":"df.reset_index(inplace=True)\nli = list(df[df.Attrition == 0].sample(n=2910).index)\ndf = df.drop(df.index[li])","be943497":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=.2, random_state = 489)","d5c28f53":"from sklearn.preprocessing import StandardScaler\nScaler_X = StandardScaler()\nx_train = Scaler_X.fit_transform(x_train)\nx_test = Scaler_X.transform(x_test)","f507f1b7":"lr.fit(x_train, y_train)\nlr.score(x_train, y_train)","8455d6f3":"y_pred = lr.predict(x_test)","c413e3b1":"print(metrics.confusion_matrix(y_test, y_pred))","59aed194":"lr.score(x_test, y_test)","32cd7d1b":"accuracy_score(y_test, y_pred)","f10ca822":"recall_score(y_test,y_pred)","d5a5e82f":"f1_score(y_test,y_pred)\n","78323fae":"from imblearn.over_sampling import SMOTE","3e197a22":"Scaler_X = StandardScaler()\nscaled_X = Scaler_X.fit_transform(X)\n","606fea51":"X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.25, random_state=27)\n\nsm = SMOTE(random_state=27, sampling_strategy='auto')\nX_train, y_train = sm.fit_sample(X_train, y_train)","e934e06e":"lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\nsmote_pred = lr.predict(X_test)","8b2bb01a":"accuracy_score(y_test, smote_pred)","0c936898":"f1_score(y_test, smote_pred)","c2ffcd24":"recall_score(y_test, smote_pred)","a9e9181b":"feature_names = X.columns.values\nsummary_table = pd.DataFrame(columns = ['Feature_names'], data = feature_names)\nsummary_table['coeff']= np.transpose(lr.coef_)\nsummary_table\n\nsummary_table.index = summary_table.index +1\nsummary_table.iloc[0]= ['Intercept', lr.intercept_[0]]\n\nsummary_table.sort_index()","a9ea163c":"#get correlations of each features in dataset\ncorrmat = df.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(40,40))\n#plot heat map\ng=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","db1ab5ab":"print(df.Over18.value_counts())\nprint(df.StandardHours.value_counts())\nprint(df.EmployeeCount.value_counts())","1e2ea527":"#Dropping them as they are not relevant\ndf.drop(['StandardHours','EmployeeCount','EmployeeID','Over18'], inplace=True, axis=1)","919e0d19":"X = df.drop(['Attrition'], axis=1)\ny =df.Attrition","6da6feaa":"#Calculating VIF\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\n\nX_vif=add_constant(X)\n\npd.Series([variance_inflation_factor(X_vif.values, i) \n               for i in range(X_vif.shape[1])], \n              index=X_vif.columns)  ","e9e758da":"#get correlations of each features in dataset\ncorrmat = df.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","06072189":"X.drop(['JobInvolvement','Age','BusinessTravel','PerformanceRating','YearsAtCompany','DistanceFromHome', 'StockOptionLevel'], inplace=True, axis=1)","9e5d4246":"X.drop(['Education','Gender','JobRole','Department'],inplace =True, axis =1)","20b94aa3":"Scaler_X = StandardScaler()\nscaled_X = Scaler_X.fit_transform(X)","788b461a":"X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.25, random_state=27)\n\nsm = SMOTE(random_state=27, sampling_strategy='auto')\nX_train, y_train = sm.fit_sample(X_train, y_train)","38691661":"lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n\nsmote_pred = lr.predict(X_test)\n\n# Checking accuracy","9fd65f7d":"accuracy_score(y_test, smote_pred) ","2afe516e":"f1_score(y_test, smote_pred)","22f9a0b5":"recall_score(y_test, smote_pred)","043ebc54":"## recall and F1 increased significantly","db3f8974":"feature_names = X.columns.values\nsummary_table = pd.DataFrame(columns = ['Feature_names'], data = feature_names)\nsummary_table['coeff']= np.transpose(lr.coef_)\nsummary_table\n\nsummary_table.index = summary_table.index +1\nsummary_table.iloc[0]= ['Intercept', lr.intercept_[0]]\n\n\n\n\nsummary_table.sort_index()","fa936991":"## As the data is imbalance, accuracy is might not be the best option for measuring performance.\n## Hence if we look at  F1 score and recall score, they are very low","e8e59a93":"### We can say that SMOTE is best for this imbalanced data set.\n### Now we need to select relevant features and see if we can increase the accuracy more or not!","145350ff":"## Trying undersampling\n","2105a143":"## The data is imbalanced","3066d24a":"# Columns we should drop:\n\n\n\n### 1) Job involvement: because its coefficient value is near 0 that means it does not have major effect on Attrition\n### 2) Age: as it has high correlation with many features such as total working years, years at company and it does not affect Attrition that much.\n### 3) Business travel the coefficient table shows that this feature has approximately zero effect on Attrition\n### 4) Performance Rating: as it is highly correlated to percent salary hike and has less significance, VIF is also high\n### 5) Years At company: it is correlated with years with current manager and age hence dropping it.\n### 6) Stock Option level: approximately zero effect on Attrition\n### 7) Distance from home: approximately zero effect on Attrition\n### 8) Education: approximately zero effect on Attrition\n### 9) Gender: approximately zero effect on Attrition\n### 10) Department: approximately zero effect on Attrition","76763ca5":"## Label encoding: to convert categorical values into continuous values","676a9d09":"## Feature dictionary","8518b20c":"## After undersampling the F1 score and recall score dropped. So undersampling is not the best option.","d769e84d":"## Importing Libraries","c931dc86":"## Null values are very few, we can drop them without affecting data set ","f238a6b6":"## Creating intercept and coefficient table to see how features are related to target.","cbc3ce35":"### Environment Satisfaction, Job satisfaction, Marital Status, Total working years, Years since last promotion, Years with current managers are some important features to take into consideration if company wants to reduce its attrition rate.","1e77e236":"## Loading the dataset","ee4836ca":"## Using SMOTE: Synthetic Minority Oversampling Technique\n## SMOTE uses a nearest neighbors algorithm to generate new and synthetic data we can use for training our model.","c04fdda0":"## Checking for missing values"}}