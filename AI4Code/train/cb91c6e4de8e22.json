{"cell_type":{"458f34ce":"code","5510443e":"code","3b175417":"code","28c1fec3":"code","f4ea207b":"code","7570036b":"code","f411afe5":"code","67dcc09e":"code","0df41df7":"code","7db4c52b":"code","886066b8":"code","23d21ab8":"code","e94e73d0":"code","a9a15c48":"code","d3896c1b":"code","5f42dc38":"code","7ff2c15c":"code","a09a96c4":"code","95c82950":"code","191f3355":"code","c0d3a8b3":"code","98d47cd4":"code","bb8057e3":"code","14bffc00":"code","13ce3ecf":"code","c44dd38d":"code","272ac13e":"code","2b6c233d":"code","4ce9f661":"code","6cf16dcb":"code","549a9e1d":"code","1e2c256e":"code","dcd9de68":"code","8c27d42f":"code","77896dde":"code","056c0266":"code","b25b33d3":"code","6668632e":"code","613b1bac":"code","0e5fe6d9":"code","8cb9238f":"code","610ca552":"code","8d2b9e39":"code","0a84c68c":"code","63d4a368":"code","88db14a8":"code","c1a03fd2":"code","baa9ea9f":"markdown","993b8c72":"markdown","05d561a4":"markdown","67c3c132":"markdown","2680bc23":"markdown","0d0274cc":"markdown","cf92e8fc":"markdown","679451f9":"markdown","522c2a77":"markdown","55ea96fd":"markdown","f59f6d48":"markdown","2b92c318":"markdown","7d71c7cd":"markdown","459db3e4":"markdown","bd5ac304":"markdown","7c623188":"markdown","946ce505":"markdown","2db9d87d":"markdown","98b0e22b":"markdown","86916d82":"markdown","4f25d9ab":"markdown","fd173a9b":"markdown","78116889":"markdown","71dfab28":"markdown","396001c3":"markdown","533390b3":"markdown","122d017e":"markdown","fa5bd38d":"markdown","eb5dea11":"markdown","394d388f":"markdown"},"source":{"458f34ce":"import pandas as pd\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nplt.style.use(\"Solarize_Light2\")\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n#from sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFECV\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","5510443e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3b175417":"data = pd.read_csv('\/kaggle\/input\/heart-failure-prediction\/heart.csv')","28c1fec3":"data","f4ea207b":"data.isnull().sum()","7570036b":"data.info()","f411afe5":"data.nunique()","67dcc09e":"data.columns","0df41df7":"numerical = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\ncategorial = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\ntarget = ['HeartDisease']\ntext = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']","7db4c52b":"sns.pairplot(data[numerical + target])","886066b8":"data_labenc = data.copy()\nlabelencoder = LabelEncoder()\nfor i in text:\n    data_labenc[i] = labelencoder.fit_transform(data_labenc[i])","23d21ab8":"fig = plt.figure(figsize=(20, 20))\nax = fig.gca()\ndata_labenc.plot(kind='density', subplots=True, layout=(4, 4), sharex=False, ax=ax)\nplt.show()","e94e73d0":"fig = plt.figure(figsize=(20, 20))\nax = fig.gca()\ndata_labenc.plot(kind='box', subplots=True, layout=(4, 4), sharex=False, ax=ax)\nplt.show()","a9a15c48":"cat_labelencoder = ['Sex', 'ExerciseAngina']\nfor i in cat_labelencoder:\n    data[i] = labelencoder.fit_transform(data[i])","d3896c1b":"cat_get_dummies = ['ChestPainType', 'RestingECG', 'ST_Slope']\n\ndata = pd.get_dummies(data, columns=cat_get_dummies)","5f42dc38":"data.columns","7ff2c15c":"data.groupby(target)[['Age', 'Sex', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR',\n       'ExerciseAngina', 'Oldpeak', 'ChestPainType_ASY',\n       'ChestPainType_ATA', 'ChestPainType_NAP', 'ChestPainType_TA',\n       'RestingECG_LVH', 'RestingECG_Normal', 'RestingECG_ST', 'ST_Slope_Down',\n       'ST_Slope_Flat', 'ST_Slope_Up']]\\\n.agg(['mean']).plot.bar(subplots=True, figsize=(15, 15), layout=(6, 3))","a09a96c4":"X = data.drop(target, axis=1)\ny = data[target]","95c82950":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","191f3355":"scaler = StandardScaler()\n\nx_train_scaler = scaler.fit_transform(x_train[numerical])\nx_test_scaler = scaler.transform(x_test[numerical])\n\nx_train[numerical] = x_train_scaler\nx_test[numerical] = x_test_scaler","c0d3a8b3":"x_train_scaler","98d47cd4":"rfecv = RFECV(estimator=GradientBoostingClassifier())","bb8057e3":"model = GradientBoostingClassifier()","14bffc00":"pipeline = Pipeline([('Feature Selection', rfecv), ('Model', model)])\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=42)\nn_scores = cross_val_score(pipeline, x_train, y_train.values.ravel(), scoring='recall', cv=cv, n_jobs=-1)\nnp.mean(n_scores)","13ce3ecf":"pipeline.fit(x_train, y_train)","c44dd38d":"print('Optimal number of features :', rfecv.n_features_)","272ac13e":"plt.figure(figsize=(12,6))\nplt.xlabel('Number of features selected')\nplt.ylabel('Cross validation score (nb of correct classifications)')\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","2b6c233d":"pd.DataFrame(rfecv.support_,index=X.columns,columns=['Rank'])","4ce9f661":"data_rfecv = pd.DataFrame(rfecv.support_,index=X.columns,columns=['Rank'])\ndata_rfecv[data_rfecv.Rank == True].index.unique()","6cf16dcb":"col_rfecv = data_rfecv[data_rfecv.Rank == True].index.unique()","549a9e1d":"x_test = x_test[col_rfecv]\nx_train = x_train[col_rfecv]","1e2c256e":"def quality_report(actual, prediction):\n    print(\"Accuracy: {:.3f}\\nPrecision: {:.3f}\\nRecall: {:.3f}\\nf1_score: {:.3f}\\nRoc_auc: {:.3f}\".format(\n        accuracy_score(actual, prediction),\n        precision_score(actual, prediction),\n        recall_score(actual, prediction),\n        f1_score(actual, prediction),\n        roc_auc_score(actual, prediction)))","dcd9de68":"def plot_features(clf):\n    feature_importances = clf.feature_importances_\n    pd.DataFrame({'features': x_train.columns,\n                                           'feature_importances': feature_importances})\\\n    .sort_values('feature_importances', ascending=False).plot.barh(x ='features', figsize=(10, 7))","8c27d42f":"def data_features(clf):\n    feature_importances = clf.feature_importances_\n    return pd.DataFrame({'features': x_train.columns,\n                                           'feature_importances': feature_importances})\\\n    .sort_values('feature_importances', ascending=False)\n    ","77896dde":"def con_matrix(actual, prediction):\n    tn, fp, fn, tp = confusion_matrix(actual, prediction).ravel()\n    print('*True Positive', tp, ' - patients who were correctly diagnosed with heart disease!')\n    print('False Negative', fn, ' - patients who did not have heart disease, but were identified as sick')\n    print('True Negative', tn, ' - patients who did not have heart disease and were identified as healthy')\n    print('*False Positive', fp, ' - patients who had heart disease, but were identified as healthy!')","056c0266":"rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=42)\n\nrnd_clf.fit(x_train, y_train)\n\npredict_rnd = rnd_clf.predict(x_test)\n\nprint('\\nTest quality: \\n')\nquality_report(y_test, predict_rnd)\nprint('\\nThe confusion matrix : \\n')\ncon_matrix(y_test, predict_rnd)","b25b33d3":"tn, fp, fn, tp = confusion_matrix(y_test, predict_rnd).ravel()","6668632e":"confusion_matrix(y_test, predict_rnd)[1][1]","613b1bac":"data_features(rnd_clf)","0e5fe6d9":"plot_features(rnd_clf)","8cb9238f":"ex_clf = ExtraTreesClassifier(n_estimators=400, max_leaf_nodes=14, n_jobs=-1,  random_state=42)\n\nex_clf.fit(x_train, y_train)\n\npredict_ex = ex_clf.predict(x_test)\n\nprint('\\nTest quality: \\n')\nquality_report(y_test, predict_ex)\nprint('\\nThe confusion matrix : \\n')\ncon_matrix(y_test, predict_ex)","610ca552":"data_features(ex_clf)","8d2b9e39":"plot_features(ex_clf)","0a84c68c":"from sklearn.ensemble import GradientBoostingClassifier\ngdc_clf = GradientBoostingClassifier(n_estimators=400, max_features=2, max_depth = 2, random_state = 42) \n\ngdc_clf.fit(x_train, y_train)\n\npredict_gbc = gdc_clf.predict(x_test)\n\nprint('\\nTest quality: \\n')\nquality_report(y_test, predict_gbc)\nprint('\\nThe confusion matrix : \\n')\ncon_matrix(y_test, predict_gbc)","63d4a368":"data_features(gdc_clf)","88db14a8":"plot_features(gdc_clf)","c1a03fd2":"y_predicted_prob_rnd = rnd_clf.predict_proba(x_test)\ny_predicted_prob_ex = ex_clf.predict_proba(x_test)\ny_predicted_prob_gdc = gdc_clf.predict_proba(x_test)\n\nfpr_rnd, tpr_rnd, thresholds_rnd = roc_curve(y_test, y_predicted_prob_rnd[:,1])\nfpr_ex, tpr_ex, thresholds_ex = roc_curve(y_test, y_predicted_prob_ex[:,1])\nfpr_gdc, tpr_gdc, thresholds_gdc = roc_curve(y_test, y_predicted_prob_gdc[:,1])\n\nplt.figure(figsize=(13,8))\nplt.plot(fpr_rnd, tpr_rnd, color='darkblue', label='RandomForest (area = %0.3f)' % auc(fpr_rnd, tpr_rnd))\nplt.plot(fpr_ex, tpr_ex, color='darkorange', label='ExtraTrees (area = %0.3f)' % auc(fpr_ex, tpr_ex))\nplt.plot(fpr_gdc, tpr_gdc, color='darkred', label='GradientBoosting (area = %0.3f)' % auc(fpr_gdc, tpr_gdc))\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n\nplt.xlim([-0.01, 1.0])\nplt.ylim([-0.01, 1.05])\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.title('ROC AUC: RandomForest = {:.3f} \/\/ ExtraTrees = {:.3f} \/\/ GradientBoosting = {:.3f}'\\\n          .format(roc_auc_score(y_test, predict_rnd),\n                  roc_auc_score(y_test, predict_ex),\n                  roc_auc_score(y_test, predict_gbc)))\nplt.legend(loc=\"lower right\", title_fontsize='xx-large')\n\nplt.show()","baa9ea9f":"**We apply the pipeline and get the optimal number of veribles.**","993b8c72":"**Correcting x_test and x_train**","05d561a4":"**The importance of features in our training**","67c3c132":"# Feature selection (feature ranking)","2680bc23":"**The importance of features in our training**","0d0274cc":"**We repeat our actions**","cf92e8fc":"**The importance of features in our training**","679451f9":"# Split and Scaler","522c2a77":"# GradientBoostingClassifier","55ea96fd":"# ExtraTreesClassifier","f59f6d48":"**Defining `pipeline` and `cv`**","2b92c318":"# Importing Necessary Libraries","7d71c7cd":"**Creating an instance of the `RFECV` class specifying the `Gradient Boosting Classifier` evaluator**","459db3e4":"**Creating an instance of the model that we will use**","bd5ac304":"**Estimates during cross-validation**","7c623188":"**Let's encode our variables to build a histogram with the target variable - `Heart Disease`**","946ce505":"**Training the model**","2db9d87d":"**In order not to 'feed' our algorithm 18 features, we will select the most important ones among them using recursive `RFECV` exclusion and `RepeatedStratifiedKFold` cross-validation.**","98b0e22b":"**Plotting density graphs and boxplots**","86916d82":"# RandomForestClassifier","4f25d9ab":"**The histogram clearly shows which signs affect the presence of heart disease (`Heart Disease` == 1)**","fd173a9b":"**Work plan:** \n\n**1. Overview of the datas and variables.**  \n  \n**2. Let's scan numeric variables using `Standard Scale()`, recode test and categorical variables using `get_dummies`.**   \n   \n**3. Let's select the signs using `RFECV` and cross-validation `RepeatedStratifiedKFold`.**  \n  \n**4. Let's train on `RandomForestClassifier`, `ExtraTreesClassifier`, `GradientBoostingClassifie`. Let's take the `recall` metric as a basis.  It is important to us that all cases of possible heart disease are predicted to minimize the `false negative`.** \n  ","78116889":"**Setting the functions**","71dfab28":"**We form variables by category for further processing**","396001c3":"**Visualize the variables with each other using pairplot**","533390b3":"# Data overview","122d017e":"**Getting the list `True`**","fa5bd38d":"**We repeat our actions**","eb5dea11":"# ROC Curves and AUC","394d388f":"**Attribute Information:**  \n      \n**<li>`Age`**: age of the patient [years]  \n      \n**<li>`Sex`**: sex of the patient [M: Male, F: Female]  \n      \n**<li>`ChestPainType`**: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]  \n      \n**<li>`RestingBP`**: resting blood pressure [mm Hg]  \n      \n**<li>`Cholesterol`**: serum cholesterol [mm\/dl]  \n      \n**<li>`FastingBS`**: fasting blood sugar [1: if FastingBS > 120 mg\/dl, 0: otherwise]   \n      \n**<li>`RestingECG`**: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]  \n      \n**<li>`MaxHR`**: maximum heart rate achieved [Numeric value between 60 and 202]  \n      \n**<li>`ExerciseAngina`**: exercise-induced angina [Y: Yes, N: No]  \n      \n**<li>`Oldpeak`**: oldpeak = ST [Numeric value measured in depression]  \n      \n**<li>`ST_Slope`**: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]  \n      \n**<li>`HeartDisease`**: output class [1: heart disease, 0: Normal]"}}