{"cell_type":{"8bded18a":"code","a7001894":"code","6fd4751b":"code","46bde486":"code","4e2e18ef":"code","9be8d4b5":"code","4e1f97ba":"code","535fd588":"code","c5769920":"code","009d2ab4":"code","b60e2cb9":"code","83c29e26":"code","983d38b9":"code","e41bc24b":"code","b0d9f156":"code","214200d3":"code","1e1c7224":"code","f5e97935":"code","a7910d8d":"code","8bf053fc":"code","5ea7b96c":"code","9d4e6699":"code","cd128331":"code","5c946284":"code","057d3a50":"code","2aad8f55":"code","26a84c2b":"code","02b067e6":"markdown","9cfd0594":"markdown","ed52d690":"markdown","24dbb493":"markdown","57c2b908":"markdown","8a8722b0":"markdown","4618fc03":"markdown","a431bfcb":"markdown","223bb820":"markdown"},"source":{"8bded18a":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom scipy.special import boxcox1p\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler,StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split,GridSearchCV\nfrom sklearn.pipeline import make_pipeline\n\nfrom xgboost import XGBRegressor\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.svm import SVR\nfrom mlxtend.regressor import StackingCVRegressor\n\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn","a7001894":"df_train = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv')\ndf_test = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv')\n\ntest_id = df_test['Id']\n\nn_train = df_train.shape[0]\nn_test = df_train.shape[0]","6fd4751b":"df = pd.concat([df_train,df_test],sort = False).reset_index(drop = True)\ndf.shape","46bde486":"df.head()","4e2e18ef":"df.info()","9be8d4b5":"df.isnull().sum()","4e1f97ba":"df.describe()","535fd588":"df['MSZoning'].fillna('RL',inplace = True)\ndf['Utilities'].fillna('AllPub',inplace = True)\n\n#Exter\ndf['Exterior1st'].fillna('Plywood',inplace = True)\ndf['Exterior2nd'].fillna('Plywood',inplace = True)\n\n#MasVnr\ndf['MasVnrType'][2610] = 'BrkFace'\ndf['MasVnrType'].fillna('None',inplace = True)\n\n#Bsmt\ndf['BsmtQual'][2217] = 'Fa'\ndf['BsmtQual'][2218] = 'TA'\ndf['BsmtCond'][2040] = 'TA'\ndf['BsmtCond'][2185] = 'TA'\ndf['BsmtCond'][2524] = 'TA'\ndf['BsmtExposure'][948] = 'No'\ndf['BsmtExposure'][1487] = 'No'\ndf['BsmtExposure'][2348] = 'No'\ndf['BsmtFinType2'][332] = 'Rec'\n\ndf['BsmtQual'].fillna('NA',inplace = True)\ndf['BsmtCond'].fillna('NA',inplace = True)\ndf['BsmtExposure'].fillna('NA',inplace = True)\ndf['BsmtFinType1'].fillna('NA',inplace = True)\ndf['BsmtFinType2'].fillna('NA',inplace = True)\n\n#electrical\ndf['Electrical'].fillna('SBrkr',inplace = True)\n\n#FireplaceQu\ndf['FireplaceQu'].fillna('NA',inplace = True)\n\n#kitchen\ndf['KitchenQual'].fillna('TA',inplace = True)\n\n#Functional\ndf['Functional'].fillna('Typ',inplace = True)\n\n##Garage\ndf['GarageType'][2576] = 'NA'\ndf['GarageYrBlt'][2126] = 1958\ndf['GarageFinish'][2126] = 'Unf'\ndf['GarageQual'][2126] = 'TA'\ndf['GarageCond'][2126] = 'TA'\n\ndf['GarageType'].fillna('NA',inplace = True)\ndf['GarageFinish'].fillna('NA',inplace = True)\ndf['GarageQual'].fillna('NA',inplace = True)\ndf['GarageCond'].fillna('NA',inplace = True)\n\ndf['SaleType'].fillna('WD',inplace = True)","c5769920":"df['MasVnrArea'].fillna(0,inplace = True)\n\n#bsmt\ndf['BsmtFinSF1'].fillna(0,inplace = True)\ndf['BsmtFinSF2'].fillna(0,inplace = True)\ndf['BsmtUnfSF'].fillna(0,inplace = True)\ndf['TotalBsmtSF'].fillna(0,inplace = True)\n\n#bsmt bath\ndf['BsmtFullBath'].fillna(0,inplace = True)\ndf['BsmtHalfBath'].fillna(0,inplace = True)\n\n\n#garage\ndf['GarageYrBlt'].fillna(0,inplace = True)\ndf['GarageCars'].fillna(0,inplace = True)\ndf['GarageArea'].fillna(0,inplace = True)","009d2ab4":"def knn_imputer_nan(x,k):\n    imputer = KNNImputer(n_neighbors=k)\n    return pd.DataFrame(imputer.fit_transform(x))\n\ndf_LotFrontage_LotArea = df[['LotFrontage','LotArea']]\ni_LotFrontage = knn_imputer_nan(df_LotFrontage_LotArea,36)\ni_LotFrontage.iloc[:,0] = round(i_LotFrontage.iloc[:,0])\ndf['LotFrontage'] = i_LotFrontage.iloc[:,0]","b60e2cb9":"Street_map = {'Grvl':0,'Pave':1}\nUtilities_map = {'ELO':1,'NoSeWa':2,'NoSewr':3,'AllPub':4}\nLandSlope_map = {'Sev':1,'Mod':2,'Gtl':3}\nExterQual_map = {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\nExterCond_map = {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5} \nBsmtQual_map = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\nBsmtCond_map = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\nBsmtExposure_map = {'NA':0,'No':1,'Mn':2,'Av':3,'Gd':4}\nBsmtFinType1_map = {'NA':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6}\nBsmtFinType2_map = {'NA':0,'Unf':1,'LwQ':2,'Rec':3,'BLQ':4,'ALQ':5,'GLQ':6}\nHeatingQC_map = {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\nKitchenQual_map = {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\nFunctional_map = {'Sal':1,'Sev':2,'Maj2':3,'Maj1':4,'Mod':5,'Min2':6,'Min1':7,'Typ':8}\nFireplaceQu_map = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\nGarageFinish_map = {'NA':0,'Unf':1,'RFn':2,'Fin':3}\nGarageQual_map = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\nGarageCond_map = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\nPavedDrive_map = {'N':1,'P':2,'Y':3}\n\ndf.replace({'Street':Street_map,'Utilities':Utilities_map,'LandSlope':LandSlope_map,'ExterQual':ExterQual_map,\n           'ExterCond':ExterCond_map,'BsmtQual':BsmtQual_map,'BsmtCond':BsmtCond_map,'BsmtExposure':BsmtExposure_map,\n           'BsmtFinType1':BsmtFinType1_map,'BsmtFinType2':BsmtFinType2_map,'HeatingQC':HeatingQC_map,\n           'KitchenQual':KitchenQual_map,'Functional':Functional_map,'FireplaceQu':FireplaceQu_map,'GarageFinish':GarageFinish_map,\n           'GarageQual':GarageQual_map,'GarageCond':GarageCond_map,'PavedDrive':PavedDrive_map},inplace = True)\n\ndf['BsmtCond'] = df['BsmtCond'].apply(int)","83c29e26":"#YearAdd\nyr_feat = ['YearBuilt','YearRemodAdd']\nfor feature in yr_feat:\n    df[feature] = df['YrSold'] - df[feature]\n    \ndf['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\ndf['Total_porch_SF'] = df['OpenPorchSF'] + df['3SsnPorch'] + df['EnclosedPorch'] + df['ScreenPorch'] + df['WoodDeckSF']\ndf['Total_Bathrooms'] = df['FullBath'] + (0.5 * df['HalfBath']) + df['BsmtFullBath'] + (0.5 * df['BsmtHalfBath'])\ndf['Total_Finished_SF'] = df['1stFlrSF'] + df['2ndFlrSF'] + df['BsmtFinSF1'] + df['BsmtFinSF2']\n\ndf['haspool'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\ndf['has2ndfloor'] = df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\ndf['hasgarage'] = df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\ndf['hasbsmt'] = df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\ndf['hasfireplace'] = df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\ndf['hasMisc'] = df['MiscVal'].apply(lambda x: 1 if x > 0 else 0)","983d38b9":"df['MSSubClass'] = df['MSSubClass'].apply(str)\ndf['YrSold'] = df['YrSold'].apply(str)\ndf['MoSold'] = df['MoSold'].apply(str)\ncat_features = ['MSSubClass','MSZoning','LotShape','LandContour','LotConfig','Neighborhood','Condition1','Condition2',\n                'BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType',\n                'Foundation','Heating','CentralAir','Electrical','GarageType','MoSold','YrSold','SaleType','SaleCondition']\n\nfor feature in cat_features:\n    df_ = pd.get_dummies(df[feature],prefix = feature,drop_first=True)\n    df.drop(feature,inplace = True,axis = 1)\n    df = pd.concat([df,df_],axis = 1)","e41bc24b":"df.drop(['Id','Alley','Utilities','Street','PoolArea','PoolQC','Fence','MiscFeature','MiscVal'],axis = 1,inplace=True)","b0d9f156":"df.head()","214200d3":"corrmat = df.iloc[:n_train,:].corr()\ntop_corr_features = corrmat.index[abs(corrmat[\"SalePrice\"])>0.6]\nplt.figure(figsize=(10,10))\ng = sns.heatmap(df.iloc[:n_train,:][top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","1e1c7224":"# GrLivArea\nplt.scatter(df['GrLivArea'][:n_train],df['SalePrice'][:n_train])\ndf = df.drop(df[((df['GrLivArea']>4000) & (df['SalePrice']<300000))].index)\nn_train -= 2\nplt.scatter(df['GrLivArea'][:n_train],df['SalePrice'][:n_train])\n\n#OverallQual\n# sns.boxplot(df['OverallQual'],df['SalePrice'])\n\n#ExterQual\n# sns.boxplot(df['ExterQual'],df['SalePrice'])","f5e97935":"#SalePrice \nsns.distplot(df['SalePrice'][:n_train],fit = norm)\n\npl = plt.figure()\nstats.probplot(df['SalePrice'][:n_train],plot=plt)\nplt.show()","a7910d8d":"df['SalePrice'][:n_train] = np.log1p(df['SalePrice'][:n_train])\n\nsns.distplot(df['SalePrice'][:n_train] , fit=norm);\n\npl = plt.figure()\nstats.probplot(df['SalePrice'][:n_train],plot=plt)\nplt.show()","8bf053fc":"continuous_features = [feature for feature in df.columns if len(df[feature].unique())>10 and df[feature].dtype != 'object' and 'Year' not in feature and 'Yr' not in feature]\ncontinuous_features,len(continuous_features)","5ea7b96c":"continuous_features.remove('SalePrice')\nsk = df[continuous_features].apply(lambda x:skew(x)).sort_values(ascending = False)\nsk = pd.DataFrame(sk)\nsk","9d4e6699":"ch = [0,0.03,0.05,0.08,0.1,0.13,0.15]\ndf__ = pd.DataFrame()\nfor choice in ch:\n    df_ = pd.DataFrame(skew(boxcox1p(df[continuous_features],choice)),columns=[choice],index = continuous_features)\n    df__ = pd.concat([df__,df_],axis = 1)\n    \ndf__ = pd.concat([pd.DataFrame(skew(df[continuous_features]),columns = ['Org'],index = continuous_features),df__],axis = 1)\n\n\nskew_result = {}\nfor i in df__.index:\n    min_ = 'Org'\n    for j in df__.columns:\n        if df__.loc[i,j]>=0 and df__.loc[i,j]<df__.loc[i,min_]:\n            min_ = j\n            \n    skew_result[i] = min_\n    \n\nprint(skew_result)\nskew_result = {k:v for k,v in skew_result.items() if v != 'Org'}","cd128331":"#boxcox1p for other continuous values \nfor k,v in skew_result.items():\n    df[k] = boxcox1p(df[k],v)","5c946284":"df_train = df.iloc[:n_train,:]\ndf_test = df.iloc[n_train:,:]\n\nx = df_train.drop('SalePrice',axis = 1)\ny = df_train['SalePrice']\ndf_test.drop('SalePrice',inplace = True,axis = 1)","057d3a50":"# x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2)","2aad8f55":"#Validation\nkf = KFold(5, shuffle=True, random_state=42)\n\ndef rmse(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\ndef rmsle_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, x.values, y.values, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","26a84c2b":"lgbm = LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.01, n_estimators=5000,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n\nxgb = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.01, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=5000,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             nthread = -1)\n\ngbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber')\n\nrf = RandomForestRegressor(n_estimators=1200,\n                          max_depth=15,\n                          min_samples_split=5,\n                          min_samples_leaf=5,\n                          max_features=None,\n                          oob_score=True)\n                          \n\n\nalphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\ne_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n\nridge = make_pipeline(RobustScaler(),\n                      RidgeCV(alphas=alphas_alt, cv=kf))\n\nlasso = make_pipeline(RobustScaler(),\n                      LassoCV(max_iter=1e7, alphas=alphas2,\n                              random_state=42, cv=kf))\n\nelasticnet = make_pipeline(RobustScaler(),\n                           ElasticNetCV(max_iter=1e7, alphas=e_alphas,\n                                        cv=kf, l1_ratio=e_l1ratio))\n\n\nstack_gen = StackingCVRegressor(regressors=(xgb, lgbm, gbr, rf,ridge,lasso,elasticnet),\n                                meta_regressor=xgb,\n                                use_features_in_secondary=True,\n                                cv = 5)\n                              \n                                ","02b067e6":"Direct Fill Nan Numerical","9cfd0594":"Dummy Variables 2","ed52d690":"Dummy Variables 1","24dbb493":"Update Numerical Columns","57c2b908":"Direct Fill Nan categorical","8a8722b0":"Model","4618fc03":"Convert Skewed Distribution to Normal(Continuous Values)\n\n1)Take Log\n\n2)Box Cox\n\n3)Square Root","a431bfcb":"Remove Outliers\n\n1)Univariate Using Only Z score\n\n2)Biavariate Using Scatter Or Boxplot\n\n3)Multivariate Using pairplot","223bb820":"Imputing NaN"}}