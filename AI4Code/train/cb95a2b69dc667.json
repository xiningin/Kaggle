{"cell_type":{"1bc1625f":"code","6db17aab":"code","7b87b6bd":"code","1e0ad50d":"code","f038156b":"code","c7299e4d":"code","3be59081":"code","1d0aa422":"code","9965901f":"code","43919f4a":"code","03a67bdd":"code","2e5b4545":"code","2ad63140":"code","06953795":"code","6fe8d50c":"code","62c06a4a":"code","7a7e86cb":"code","6eb55c30":"code","09500b20":"code","5da8cadd":"code","1a9b802b":"code","d56b8208":"code","4cf8c353":"code","4a514c8c":"code","d6c59d22":"code","9f8ca9a0":"code","ecff6853":"code","6012d38e":"code","38aba0f0":"code","f98c22c0":"code","93d02050":"code","db85de8b":"code","9499fa4a":"code","6af3f084":"code","721549e7":"code","cecec7dd":"code","06172e0d":"code","cc91cb4d":"code","8b38d934":"code","33191610":"code","3386cd72":"code","11e4d2da":"code","2f0f9682":"code","27e4e5f7":"code","e2e3daef":"code","f45190e6":"code","0ee760f4":"code","d27b75f6":"code","35f86c94":"code","7ca731ec":"code","f9c1f6a5":"code","97d49146":"code","ddd3abc4":"code","5fe8d566":"code","c34a88b6":"code","80aee70b":"code","c626630b":"code","2e277586":"code","f67668c2":"code","8c03f71d":"code","fb4137fb":"code","68a62045":"code","d814b0e7":"code","37a5012d":"code","68772304":"code","858f5b89":"code","07c3d741":"code","fe71233d":"code","20531fde":"code","2699db9e":"code","a38063eb":"code","cf2fd2b8":"code","0711de19":"code","c38fce91":"code","34c854f6":"code","7b60195c":"code","a558b67c":"code","91c22177":"code","7de15e1f":"code","2d5cf1c7":"code","ab8811cb":"code","86fdb639":"code","ffbac4d2":"code","8ce9ca8f":"code","c26d2d68":"code","96e5cb2f":"code","e8fe0808":"code","743ee3d4":"code","3ecf6d21":"code","f95269d6":"code","eb7fb429":"code","f7e2bfc3":"code","f24716b5":"code","6a5f2c68":"code","0e019482":"code","6f8accd0":"markdown","4a2a1149":"markdown","0eb5b348":"markdown","3f665402":"markdown","b2f419d2":"markdown","f8eb66f8":"markdown","a66fc137":"markdown","c772e096":"markdown","5c4553ba":"markdown","aa9ebf33":"markdown","5cb80bc4":"markdown","35e85736":"markdown","f262c514":"markdown","c1b460c3":"markdown","f60ecd7d":"markdown","3d645247":"markdown","635d40c4":"markdown","6bba2eda":"markdown","a09f1aa5":"markdown","54ff9707":"markdown","ac446fd1":"markdown","a5f9603e":"markdown","1183c99f":"markdown","0c8815e2":"markdown","101599df":"markdown","f7a86deb":"markdown","289167a2":"markdown","9c4fe06e":"markdown","93b2ea97":"markdown","2c891675":"markdown","6bd7dd23":"markdown","9f5d4ed9":"markdown","efa237b4":"markdown","c636d019":"markdown","94ec68be":"markdown","dd4656cf":"markdown","45bc1e65":"markdown","9384c6ca":"markdown","d707f8c8":"markdown"},"source":{"1bc1625f":"##################################################\n# Imports\n##################################################\n!pip install emoji\nimport numpy as np\nimport cv2\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport emoji\nimport seaborn as sns\nfrom itertools import cycle\nfrom scipy import stats\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, auc, roc_curve, balanced_accuracy_score, precision_recall_curve, average_precision_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn import svm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.neural_network import MLPClassifier\n##################################################\n# Params\n##################################################\n\nDATA_BASE_FOLDER = '\/kaggle\/input\/emojify-challenge'\n\n\n##################################################\n# Utils\n##################################################\n\ndef label_to_emoji(label):\n    \"\"\"\n    Converts a label (int or string) into the corresponding emoji code (string) ready to be printed\n    \"\"\"\n    return emoji.emojize(emoji_dictionary[str(label)], use_aliases=True)","6db17aab":"##################################################\n# Load dataset\n##################################################\ndf_train = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'train.csv'))\ndf_validation = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'validation.csv'))\ndf_test = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'sample_submission.csv'))\n\n\ny_train = df_train['class']\ny_validation = df_validation['class']\nemoji_dictionary = {\n    '0': '\\u2764\\uFE0F',\n    '1': ':baseball:',\n    '2': ':smile:',\n    '3': ':disappointed:',\n    '4': ':fork_and_knife:'\n}\n\n# See some data examples\nprint('EXAMPLES:\\n####################')\nfor idx in range(10):\n    print(f'{df_train[\"phrase\"][idx]} -> {label_to_emoji(y_train[idx])}')","7b87b6bd":"# Load phrase representation\n\nx_train = np.load(\n    os.path.join(DATA_BASE_FOLDER, \n                 'train.npy')).reshape(len(df_train), -1)\nx_validation = np.load(\n    os.path.join(DATA_BASE_FOLDER, \n                'validation.npy')).reshape(len(df_validation), -1)\nx_test = np.load(\n    os.path.join(DATA_BASE_FOLDER, \n                 'test.npy')).reshape(len(df_test), -1)\n\nprint(f'Word embedding size: {x_train.shape[-1]}')","1e0ad50d":"scaler = StandardScaler()\n\n# Normalize the entire train and validation set\nx_train_scaled = scaler.fit_transform(x_train)\nx_validation_scaled = scaler.transform(x_validation)\n\n\nprint(\"scaled training set average mean = {0:1.2e}\".format(x_train_scaled.mean()))\nprint(\"scaled training set average standard deviation = {0:1.2f}\".format(x_train_scaled.std()))\nprint(\"scaled validation set average mean = {0:1.2e}\".format(x_validation_scaled.mean()))\nprint(\"scaled validation set average standard deviation = {0:1.2f}\".format(x_validation_scaled.std()))","f038156b":"##################################################\n# Evaluate the model here\n##################################################\n\n# Use this function to evaluate your model\ndef accuracy(y_pred, y_true):\n    '''\n    input y_pred: ndarray of shape (N,)\n    input y_true: ndarray of shape (N,)\n    '''\n    return (1.0 * (y_pred == y_true)).mean()\n\n# Report the accuracy in the train and validation sets.\n\n\n\n\n\n\n","c7299e4d":"fig, ax = plt.subplots(1, 2, figsize=(17, 6))\nplot_1 = sns.countplot(y_train, ax = ax[0])\nplot_2 = sns.countplot(y_validation, ax = ax[1])\nax[0].set_ylabel(\"frequency\")\nax[1].set_ylabel(\"frequency\")\nax[0].set_title(\"training set data distribution among the 5 class\")\nax[1].set_title(\"validation set data distribution among the 5 class\")","3be59081":"# Manhattan distance\n\ndef manhattan_distance(x1,x2):\n    return np.abs(x1-x2).sum(axis=-1)\n\n\n# Euclidian distance\n\ndef euclidian_distance(x1,x2):\n    return np.sqrt(((x1-x2)**2).sum(axis=-1))","1d0aa422":"# K-NN Class\n\nclass KNNModel(object):\n    def __init__(self, x, y, k=1, num_classes=5):\n        self.k = k # number of neighbors to consider\n        self.x = x # samples\n        self.y = y # labels\n        self.num_classes = num_classes\n    \n    def get_k_closest_points(self, x_i, x_list, dist_func):\n        # Compute distances between x_i and all the training samples\n        d_list = dist_func(x_i, x_list)\n        # Get the first k neighbours\n        return np.argsort(d_list)[:self.k]\n\n    def predict(self, x, dist_func):\n        \n        # Matrix of distances: shape(|x|, k)\n        dist_matrix_k = np.zeros([x.shape[0], self.k], dtype=np.int32) \n\n        # Matrix of predicted values: shape(|x|, k)\n        y_pred_k = np.zeros([x.shape[0], self.k], dtype = np.int32)\n       \n        # Compute the distance between x and self.x and Voting\n        for i, x_i in enumerate(x):\n            dist_matrix_k[i, :] = self.get_k_closest_points(x_i, self.x, dist_func)\n            y_pred_k[i, :] = self.y[dist_matrix_k[i]]\n\n        # Get the most frequent class for each sample among the k neighbours\n        mode = stats.mode(y_pred_k.T)[0]\n        return mode","9965901f":"k_list = np.arange(2, 16, dtype=np.int32)\n\n# Loop over k values\nacc_dict_man = {}\n\nfor k in k_list:\n    # Create the k-nn model\n    knn = KNNModel(x_train_scaled, y_train, k=k)\n    \n    # Predict\n    y_valid_pred = knn.predict(x_validation_scaled, manhattan_distance)\n    \n    # Evaluate model\n    acc_dict_man[k] = accuracy(y_valid_pred, np.array(y_validation))\n\n\nprint(acc_dict_man)\nidx_k_best = np.array(list(acc_dict_man.values())).argmax()\nk_best_man = list(acc_dict_man.keys())[idx_k_best]\nprint(f'Best k: {k_best_man}')\nprint(f'Accuracy: {acc_dict_man[k_best_man]}')\n\n# Plot accuracy over parameter k\nplt.figure(figsize=(20, 6))\nplt.title('Accuracy over parameter k of k-NN with Manhattan distance', fontweight='bold')\nplt.bar(list(acc_dict_man.keys()), list(acc_dict_man.values()))\nplt.axhline(y=acc_dict_man[k_best_man], linewidth=1.2, color='r', linestyle='--')\nplt.ylim(0, 0.95)\nplt.xlabel('k', fontweight='bold')\nplt.ylabel('Validation Accuracy', fontweight='bold')\nyticks, _ = plt.yticks()\nplt.yticks(yticks, [f'{int(100 * yy)}%' for yy in yticks])\nplt.xticks(k_list)\nplt.show()","43919f4a":"k_list = np.arange(2, 16, dtype=np.int32)\n\n# Loop over k values\nacc_dict_eu = {}\n\nfor k in k_list:\n    # Create the k-nn model\n    knn = KNNModel(x_train_scaled, y_train, k=k)\n    \n    # Predict\n    y_valid_pred = knn.predict(x_validation_scaled, euclidian_distance)\n    \n    # Evaluate model\n    acc_dict_eu[k] = accuracy(y_valid_pred, np.array(y_validation))\n\n\nprint(acc_dict_eu)\nidx_k_best = np.array(list(acc_dict_eu.values())).argmax()\nk_best_eu = list(acc_dict_eu.keys())[idx_k_best]\nprint(f'Best k: {k_best_eu}')\nprint(f'Accuracy: {acc_dict_eu[k_best_eu]}')\n\n# Plot accuracy over parameter k\nplt.figure(figsize=(20, 6))\nplt.title('Accuracy over parameter k of k-NN with Euclidian distance', fontweight='bold')\nplt.bar(list(acc_dict_eu.keys()), list(acc_dict_eu.values()))\nplt.axhline(y=acc_dict_eu[k_best_eu], linewidth=1.2, color='r', linestyle='--')\nplt.ylim(0, 0.95)\nplt.xlabel('k', fontweight='bold')\nplt.ylabel('Validation Accuracy', fontweight='bold')\nyticks, _ = plt.yticks()\nplt.yticks(yticks, [f'{int(100 * yy)}%' for yy in yticks])\nplt.xticks(k_list)\nplt.show()","03a67bdd":"d = pd.DataFrame({'Manhattan':pd.Series(acc_dict_man),'Euclidian':pd.Series(acc_dict_eu)})\n\nd.plot(kind='bar',figsize=(20,8))\nplt.title('Accuracy over parameter k of k-NN Manhattan vs Euclidian distance', fontweight='bold')\nplt.ylim(0, 0.95)\nplt.xlabel('k', fontweight='bold')\nplt.ylabel('Validation Accuracy', fontweight='bold')\nplt.axhline(y=acc_dict_man[k_best_man], linewidth=1.2, color='r', linestyle='-.', marker='s')\nplt.axhline(y=acc_dict_eu[k_best_eu], linewidth=1.2, color='g', marker='*')\n\n","2e5b4545":"# Create the k-nn model\nknn = KNNModel(x_train_scaled, y_train, k=4)\n\n# Predict\ny_valid_pred = knn.predict(x_validation_scaled, manhattan_distance)\n    \n# Evaluate model\nprint(accuracy(y_valid_pred, np.array(y_validation)))\nprint(classification_report(y_validation, y_valid_pred.reshape(-1), ))\n\ncm = confusion_matrix(y_validation, y_valid_pred.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n\n#plt.show()\n_ = disp.plot()","2ad63140":"# Create the k-nn model\nknn = KNNModel(x_train_scaled, y_train, k=4)\n\n# Predict\ny_valid_pred = knn.predict(x_validation_scaled, euclidian_distance)\n    \n# Evaluate model\nprint(accuracy(y_valid_pred, np.array(y_validation)))\nprint(classification_report(y_validation, y_valid_pred.reshape(-1), ))\n\ncm = confusion_matrix(y_validation, y_valid_pred.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n\n#plt.show()\n_ = disp.plot()","06953795":"class kFoldCV:\n    def __init__(self, nFolds=2):\n        # nFolds: number of folds\n        self.nFolds = nFolds\n    \n    def cvSplit(self, x, y):\n        ### input\n        # x: samples \n        # y: labels\n        ### output\n        # data splitted in train and validation for Cross Validation over nFolds\n\n        np.random.seed(1234) # for debug\n\n        # Get the indeces of the data\n        idx_samples = np.arange(x.shape[0], dtype=np.int32)\n        # Shuffle the samples indices\n       # np.random.shuffle(idx_samples)\n        # Split the idx samples into k-folds\n        n = int(len(idx_samples)\/self.nFolds)\n        idx_sample_folds = []\n        for i in range(self.nFolds):\n            if i == self.nFolds:\n                idx_sample_folds.insert(i,idx_samples)\n            else:\n                idx_sample_folds.insert(i,idx_samples[:n])\n            idx_samples = idx_samples[n:]\n\n        # Arrays to memorize train and validation folds sets\n        x_train_folds, y_train_folds = [], []\n        x_valid_folds, y_valid_folds = [], []\n        \n        # Split the indeces\n        for idx_k in range(self.nFolds):\n            idx_train, idx_valid = [], []\n            for idx_fold in range(self.nFolds):\n                fold = idx_sample_folds[idx_fold]\n                if idx_k == idx_fold:\n                    idx_valid += [fold]\n                    \n                else:\n                    idx_train += [fold]\n      \n            # Concatenate folds\n            x_train_folds += [np.concatenate([x[fold] for fold in idx_train], axis=0)]\n            y_train_folds += [np.concatenate([y[fold] for fold in idx_train], axis=0)]\n            x_valid_folds += [np.concatenate([x[fold] for fold in idx_valid], axis=0)]\n            y_valid_folds += [np.concatenate([y[fold] for fold in idx_valid], axis=0)]\n               \n        return x_train_folds, y_train_folds, x_valid_folds, y_valid_folds\n    \n    def cvEvaluate(self,x,y, minK, maxK, distance):\n        ### input\n        # x: samples \n        # y: labels\n        # minK: min number of neighbors to consider\n        # maxK: max number of neighbors to consider\n        # distance: distance metric\n        ### output\n        # average accuracy dictionary over folds for each k in minK<=k<=maxK\n        # standard deviation accuracy dictionary over folds for each k in minK<=k<=maxK\n        \n        # Split the samples in train and validation for nFolds \n        x_train_folds, y_train_folds, x_valid_folds, y_valid_folds = self.cvSplit(x, y)\n\n        # Set the values of k neighbors to consider\n        kNeighbors = np.arange(minK, maxK, dtype=np.int32)\n\n        # Dictionaries to store avg accuracy and standard deviation over folds\n        accuracy_dict = {}\n        accuracy_std = {}\n        \n        for k in kNeighbors:\n\n            # Compute accuracy for each fold\n            acc_folds = []\n\n            for x_t, y_t, x_v, y_v in zip(x_train_folds, y_train_folds, x_valid_folds, y_valid_folds):\n                \n                # Create the k-nn model\n                knn = KNNModel(x_t, y_t, k=k)\n                \n                # Predict\n                y_valid_pred = knn.predict(x_v, distance)\n                \n                # Evaluate model\n                acc = accuracy(y_valid_pred, np.array(y_v))\n                acc_folds += [acc]\n\n            # Average and standard deviation accuracies over folds\n            accuracy_dict[k] = np.mean(acc_folds)\n            accuracy_std[k] = np.std(acc_folds)\n        \n        return accuracy_dict, accuracy_std\n        ","6fe8d50c":"# Create Cross validation object with Number of Folds = 4\nkfcv = kFoldCV(4)\n\n# Evaluate the KNN model with k values between 3 and 16 with the manhattan distance\nacc_dict_man, acc_std_man = kfcv.cvEvaluate(x_train_scaled, y_train, 3, 16, manhattan_distance)\nprint(acc_dict_man)\nprint(acc_std_man)\n\n# Print best k\nidx_k_best = np.array(list(acc_dict_man.values())).argmax()\nk_best_man = list(acc_dict_man.keys())[idx_k_best]\nprint(f'Best k: {k_best_man}')\nprint(f'Accuracy: {acc_dict_man[k_best_man]}')\n\n# compute max avg accuracy + std\ns_man = {}\nfor k in acc_dict_man.keys():\n    s_man[k] = acc_dict_man[k]+acc_std_man[k]\nidx_max_std = np.array(list(s_man.values())).argmax()\ns_best_man = list(s_man.keys())[idx_max_std]\n\n# Plot accuracy over parameter k\nplt.figure(figsize=(20, 6))\nplt.title('Accuracy over parameter k of k-NN with K-Fold Cross Validation and Manhattan distance', fontweight='bold')\nplt.bar(list(acc_dict_man.keys()), list(acc_dict_man.values()), yerr=list(acc_std_man.values()))\nplt.axhline(y=acc_dict_man[k_best_man], linewidth=1.2, color='r', linestyle='--')\nplt.axhline(y=s_man[s_best_man], linewidth=1.2, color='k', linestyle='--')\nplt.ylim(0, 0.95)\nplt.xlabel('k', fontweight='bold')\nplt.ylabel('Validation Accuracy', fontweight='bold')\nyticks, _ = plt.yticks()\nplt.yticks(yticks, [f'{int(100 * yy)}%' for yy in yticks])\nplt.xticks(list(acc_dict_man.keys()))\nplt.show()","62c06a4a":"# Create Cross validation object with Number of Folds = 4\nkfcv = kFoldCV(4)\n\n# Evaluate the KNN model with k values between 3 and 16 with the euclidian distance\nacc_dict_eu, acc_std_eu = kfcv.cvEvaluate(x_train_scaled, y_train, 3, 16, euclidian_distance)\nprint(acc_dict_eu)\nprint(acc_std_eu)\n\n# Print best k\nidx_k_best = np.array(list(acc_dict_eu.values())).argmax()\nk_best_eu = list(acc_dict_eu.keys())[idx_k_best]\nprint(f'Best k: {k_best_eu}')\nprint(f'Accuracy: {acc_dict_eu[k_best_eu]}')\n\n# compute max avg accuracy + std\ns_eu = {}\nfor k in acc_dict_eu.keys():\n    s_eu[k] = acc_dict_eu[k]+acc_std_eu[k]\nidx_max_std = np.array(list(s_eu.values())).argmax()\ns_best_eu = list(s_eu.keys())[idx_max_std]\n\n\n# Plot accuracy over parameter k\nplt.figure(figsize=(20, 6))\nplt.title('Accuracy over parameter k of k-NN with K-Fold Cross Validation and Manhattan distance', fontweight='bold')\nplt.bar(list(acc_dict_eu.keys()), list(acc_dict_eu.values()), yerr=list(acc_std_eu.values()))\nplt.axhline(y=acc_dict_eu[k_best_eu], linewidth=1.2, color='r', linestyle='--')\nplt.axhline(y=s_eu[s_best_eu], linewidth=1.2, color='k', linestyle='--')\nplt.ylim(0, 0.95)\nplt.xlabel('k', fontweight='bold')\nplt.ylabel('Validation Accuracy', fontweight='bold')\nyticks, _ = plt.yticks()\nplt.yticks(yticks, [f'{int(100 * yy)}%' for yy in yticks])\nplt.xticks(list(acc_dict_eu.keys()))\nplt.show()","7a7e86cb":"d = pd.DataFrame({'Manhattan':pd.Series(acc_dict_man),'Euclidian':pd.Series(acc_dict_eu)})\nerrors = pd.DataFrame({'Manhattan':pd.Series(acc_std_man),'Euclidian':pd.Series(acc_std_eu)})\n\nd.plot(kind='bar',figsize=(20,8), yerr=errors)\nplt.title('Accuracy over parameter k of k-NN Manhattan vs Euclidian distance with 4 Fold CV', fontweight='bold')\nplt.ylim(0, 0.95)\nplt.xlabel('k', fontweight='bold')\nplt.ylabel('Validation Accuracy', fontweight='bold')\nplt.axhline(y=acc_dict_man[k_best_man], linewidth=1.2, color='r', linestyle='-.', marker='s')\nplt.axhline(y=acc_dict_eu[k_best_eu], linewidth=1.2, color='g', marker='*')\nplt.axhline(y=s_man[s_best_man], linewidth=1.2, color='k', linestyle='--')\nplt.axhline(y=s_eu[s_best_eu], linewidth=1.2, color='grey', linestyle='--')","6eb55c30":"# Create the k-nn model\nknn = KNNModel(x_train_scaled, y_train, k=7)\n\n# Predict\ny_valid_pred = knn.predict(x_validation_scaled, manhattan_distance)\n    \n# Evaluate model\nprint(accuracy(y_valid_pred, np.array(y_validation)))\nprint(classification_report(y_validation, y_valid_pred.reshape(-1), ))\n\ncm = confusion_matrix(y_validation, y_valid_pred.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n\n#plt.show()\n_ = disp.plot()","09500b20":"# Create the k-nn model\nknn = KNNModel(x_train_scaled, y_train, k=7)\n\n# Predict\ny_valid_pred = knn.predict(x_validation_scaled, euclidian_distance)\n    \n# Evaluate model\nprint(accuracy(y_valid_pred, np.array(y_validation)))\nprint(classification_report(y_validation, y_valid_pred.reshape(-1), ))\n\ncm = confusion_matrix(y_validation, y_valid_pred.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n\n#plt.show()\n_ = disp.plot()","5da8cadd":"# Apply PCA and reduce the number of components to 50\npca = PCA(n_components = 50)\nx_train_pca = pca.fit_transform(x_train_scaled)\nx_validation_pca = pca.transform(x_validation_scaled)","1a9b802b":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8, 20])\nfor c in C:\n    SVC_classifier = svm.SVC(kernel = \"linear\", C = c)\n    SVC_classifier.fit(x_train_pca, y_train)\n    y_valid_predict = SVC_classifier.predict(x_validation_pca)\n    acc_elem =  accuracy(y_valid_predict, np.array(y_validation)) \n    print(\"regularization parameter : {0:2}\".format(c))\n    print(\"accuracy = {:.3f}, balanced_accuracy = {:.3f}\".format(acc_elem, balanced_accuracy_score(y_validation, y_valid_predict)))","d56b8208":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1])\nplt.figure(figsize=(10,6))\nfor c in C :\n    SVC_classifier = svm.SVC(kernel = \"linear\", C = c).fit(x_train_pca, y_train)\n    \n    train_sizes, train_scores, validation_scores = learning_curve(SVC_classifier, x_train_pca, y_train, cv=4)\n    train_scores_mean = train_scores.mean(axis = 1)\n    validation_scores_mean = validation_scores.mean(axis = 1)\n    train_scores_std = np.std(train_scores, axis=1)\n    validation_scores_std = np.std(validation_scores, axis=1)\n    plt.grid()\n    plt.plot(train_sizes, train_scores_mean, label = 'Training C {}'.format(c))\n    plt.plot(train_sizes, validation_scores_mean, label = 'Validation C {}'.format(c))\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    plt.title('Learning curves with K-Fold Cross Validation k=4', fontweight='bold')\n    plt.legend(loc='upper left')\n    plt.ylim(0,1.2)\nplt.show()","4cf8c353":"SVC_classifier = svm.SVC(kernel = \"linear\", C = 0.25)\nSVC_classifier.fit(x_train_pca, y_train)\ny_valid_predict = SVC_classifier.predict(x_validation_pca)\nprint(\"C = {}\".format(0.25))\nprint(\"accuracy = {:.3f}, balanced accuracy = {:.3f} \\n\".format(accuracy(y_valid_predict, np.array(y_validation)), \n                                                         balanced_accuracy_score(y_validation, y_valid_predict)))\nprint(classification_report(y_validation, y_valid_predict ))\ncm = confusion_matrix(y_validation, y_valid_predict.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot()","4a514c8c":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(SVC_classifier, x_train_pca, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","d6c59d22":"n_classes = 5\n\n# classifier\nclf = OneVsRestClassifier(svm.SVC(kernel = \"linear\", C = 0.25))\ny_score = clf.fit(x_train_pca, y_train).decision_function(x_validation_pca)\n\n#binarize y_validation\ny_validation_binar = np.zeros(y_score.shape)\n\nnrows = y_score.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","9f8ca9a0":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:,i], y_score[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()","ecff6853":"precision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","6012d38e":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8, 20])\nfor c in C:\n    SVC_classifier = svm.SVC(kernel = \"linear\", C = c)\n    SVC_classifier.fit(x_train_scaled, y_train)\n    y_valid_predict = SVC_classifier.predict(x_validation_scaled)\n    acc_elem =  accuracy(y_valid_predict, np.array(y_validation)) \n    print(\"regularization parameter : {0:2}\".format(c))\n    print(\"accuracy = {:.3f}, balanced_accuracy = {:.3f}\".format(acc_elem, balanced_accuracy_score(y_validation, y_valid_predict)))","38aba0f0":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1])\nplt.figure(figsize=(10,6))\nfor c in C :\n    SVC_classifier = svm.SVC(kernel = \"linear\", C = c).fit(x_train_scaled, y_train)\n    \n    train_sizes, train_scores, validation_scores = learning_curve(SVC_classifier, x_train_scaled, y_train, cv=4)\n    train_scores_mean = train_scores.mean(axis = 1)\n    validation_scores_mean = validation_scores.mean(axis = 1)\n    train_scores_std = np.std(train_scores, axis=1)\n    validation_scores_std = np.std(validation_scores, axis=1)\n    plt.grid()\n    plt.plot(train_sizes, train_scores_mean, label = 'Training C {}'.format(c))\n    plt.plot(train_sizes, validation_scores_mean, label = 'Validation C {}'.format(c))\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    plt.title('Learning curves with K-Fold Cross Validation k=4', fontweight='bold')\n    plt.legend(loc='best')\n    plt.ylim(0,1.5)\nplt.show()","f98c22c0":"SVC_classifier = svm.SVC(kernel = \"linear\", C = 0.05)\nSVC_classifier.fit(x_train, y_train)\ny_valid_predict = SVC_classifier.predict(x_validation)\nprint(\"C = {}\".format(0.05))\nprint(\"accuracy = {:.3f}, balanced accuracy = {:.3f}\\n\".format(accuracy(y_valid_predict, np.array(y_validation)), \n                                                                balanced_accuracy_score(y_validation, y_valid_predict)))\nprint(classification_report(y_validation, y_valid_predict ))\ncm = confusion_matrix(y_validation, y_valid_predict.reshape(-1))\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot()","93d02050":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(SVC_classifier, x_train_scaled, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","db85de8b":"n_classes = 5\n\n# classifier\nclf = OneVsRestClassifier(svm.SVC(kernel = \"linear\", C = 0.05))\ny_score = clf.fit(x_train_scaled, y_train).decision_function(x_validation_scaled)\n\n#binarize y_validation\ny_validation_binar = np.zeros(y_score.shape)\nnrows = y_score.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","9499fa4a":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:,i], y_score[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()","6af3f084":"precision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","721549e7":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nfor c in C:\n    SVC_classifier = svm.SVC(kernel = \"sigmoid\", C = c)\n    SVC_classifier.fit(x_train_pca, y_train)\n    y_valid_predict = SVC_classifier.predict(x_validation_pca)\n    acc_elem =  accuracy(y_valid_predict, np.array(y_validation)) \n    print(\"regularization parameter : {0:2}\".format(c))\n    print(\"accuracy = {:.3f}, balanced_accuracy = {:.3f}\".format(acc_elem, balanced_accuracy_score(y_validation, y_valid_predict)))","cecec7dd":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nplt.figure(figsize=(15,7))\nfor c in C :\n    SVC_classifier = svm.SVC(kernel = \"sigmoid\", C = c).fit(x_train_pca, y_train)\n    \n    train_sizes, train_scores, validation_scores = learning_curve(SVC_classifier, x_train_pca, y_train, cv=4)\n    train_scores_mean = train_scores.mean(axis = 1)\n    validation_scores_mean = validation_scores.mean(axis = 1)\n    train_scores_std = np.std(train_scores, axis=1)\n    validation_scores_std = np.std(validation_scores, axis=1)\n    plt.grid()\n    plt.plot(train_sizes, train_scores_mean, label = 'Training C {}'.format(c))\n    plt.plot(train_sizes, validation_scores_mean, label = 'Validation C {}'.format(c))\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    plt.title('Learning curves with K-Fold Cross Validation k=4', fontweight='bold')\n    plt.legend(loc='best')\n    plt.ylim(0,1.2)\nplt.show()","06172e0d":"SVC_classifier = svm.SVC(kernel = \"sigmoid\", C = 2)\nSVC_classifier.fit(x_train_pca, y_train)\ny_valid_predict = SVC_classifier.predict(x_validation_pca)\nprint(\"C = {}\".format(2))\nprint(\"accuracy = {:.3f}, balanced accuracy = {:.3f}\\n\".format(accuracy(y_valid_predict, np.array(y_validation)), \n                                                                balanced_accuracy_score(y_validation, y_valid_predict)))\nprint(classification_report(y_validation, y_valid_predict ))\ncm = confusion_matrix(y_validation, y_valid_predict.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot()","cc91cb4d":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(SVC_classifier, x_train_pca, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","8b38d934":"n_classes = 5\n\n# classifier\nclf = OneVsRestClassifier(svm.SVC(kernel = \"sigmoid\", C = 2))\ny_score = clf.fit(x_train_pca, y_train).decision_function(x_validation_pca)\n\n#binarize y_validation\ny_validation_binar = np.zeros(y_score.shape)\nnrows = y_score.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","33191610":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:,i], y_score[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()\n","3386cd72":"precision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","11e4d2da":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nfor c in C:\n    SVC_classifier = svm.SVC(kernel = \"sigmoid\", C = c)\n    SVC_classifier.fit(x_train_scaled, y_train)\n    y_valid_predict = SVC_classifier.predict(x_validation_scaled)\n    acc_elem =  accuracy(y_valid_predict, np.array(y_validation)) \n    print(\"regularization parameter : {0:2}\".format(c))\n    print(\"accuracy = {:.3f}, balanced_accuracy = {:.3f}\".format(acc_elem, balanced_accuracy_score(y_validation, y_valid_predict)))\n   ","2f0f9682":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1.0, 1.5, 2, 2.5, 3, 8])\nplt.figure(figsize=(15,7))\nfor c in C :\n    SVC_classifier = svm.SVC(kernel = \"sigmoid\", C = c).fit(x_train_scaled, y_train)\n    \n    train_sizes, train_scores, validation_scores = learning_curve(SVC_classifier, x_train_scaled, y_train, cv=4)\n    train_scores_mean = train_scores.mean(axis = 1)\n    validation_scores_mean = validation_scores.mean(axis = 1)\n    train_scores_std = np.std(train_scores, axis=1)\n    validation_scores_std = np.std(validation_scores, axis=1)\n    plt.grid()\n    plt.plot(train_sizes, train_scores_mean, label = 'Training C {}'.format(c))\n    plt.plot(train_sizes, validation_scores_mean, label = 'Validation C {}'.format(c))\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    plt.title('Learning curves with K-Fold Cross Validation k=4', fontweight='bold')\n    plt.legend(loc='best')\n    plt.ylim(0,1.2)\nplt.show()","27e4e5f7":"SVC_classifier = svm.SVC(kernel = \"sigmoid\", C = 1.5)\nSVC_classifier.fit(x_train_scaled, y_train)\ny_valid_predict = SVC_classifier.predict(x_validation_scaled)\nprint(\"C = {}\".format(1.5))\nprint(\"accuracy = {:.3f}, balanced accuracy = {:.3f}\\n\".format(accuracy(y_valid_predict, np.array(y_validation)), \n                                                                balanced_accuracy_score(y_validation, y_valid_predict)))\nprint(classification_report(y_validation, y_valid_predict ))\ncm = confusion_matrix(y_validation, y_valid_predict.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot()","e2e3daef":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(SVC_classifier, x_train_scaled, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","f45190e6":"n_classes = 5\n\n# classifier\nclf = OneVsRestClassifier(svm.SVC(kernel = \"sigmoid\", C = 1.5))\ny_score = clf.fit(x_train_scaled, y_train).decision_function(x_validation_scaled)\n\n#binarize y_validation\ny_validation_binar = np.zeros(y_score.shape)\nnrows = y_score.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","0ee760f4":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:,i], y_score[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()","d27b75f6":"precision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","35f86c94":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nfor c in C:\n    SVC_classifier = svm.SVC(kernel = \"rbf\", C = c)\n    SVC_classifier.fit(x_train_pca, y_train)\n    y_valid_predict = SVC_classifier.predict(x_validation_pca)\n    acc_elem =  accuracy(y_valid_predict, np.array(y_validation)) \n    print(\"regularization parameter : {0:2}\".format(c))\n    print(\"accuracy = {:.3f}, balanced_accuracy = {:.3f}\".format(acc_elem, balanced_accuracy_score(y_validation, y_valid_predict))) ","7ca731ec":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nplt.figure(figsize=(15,7))\nfor c in C :\n    SVC_classifier = svm.SVC(kernel = \"rbf\", C = c).fit(x_train_pca, y_train)\n    \n    train_sizes, train_scores, validation_scores = learning_curve(SVC_classifier, x_train_pca, y_train, cv=4)\n    train_scores_mean = train_scores.mean(axis = 1)\n    validation_scores_mean = validation_scores.mean(axis = 1)\n    train_scores_std = np.std(train_scores, axis=1)\n    validation_scores_std = np.std(validation_scores, axis=1)\n    plt.grid()\n    plt.plot(train_sizes, train_scores_mean, label = 'Training C {}'.format(c))\n    plt.plot(train_sizes, validation_scores_mean, label = 'Validation C {}'.format(c))\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    plt.title('Learning curves with K-Fold Cross Validation k=4', fontweight='bold')\n    plt.legend(loc='best')\n    plt.ylim(0,1.2)\nplt.show()","f9c1f6a5":"SVC_classifier = svm.SVC(kernel = \"rbf\", C = 2)\nSVC_classifier.fit(x_train_pca, y_train)\ny_valid_predict = SVC_classifier.predict(x_validation_pca)\nprint(\"C = {}\".format(2))\nprint(\"accuracy = {:.3f}, balanced accuracy = {:.3f}\\n\".format(accuracy(y_valid_predict, np.array(y_validation)), \n                                                                balanced_accuracy_score(y_validation, y_valid_predict)))\nprint(classification_report(y_validation, y_valid_predict ))\ncm = confusion_matrix(y_validation, y_valid_predict.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot()","97d49146":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(SVC_classifier, x_train_pca, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","ddd3abc4":"n_classes = 5\n\n# classifier\nclf = OneVsRestClassifier(svm.SVC(kernel = \"rbf\", C = 8))\ny_score = clf.fit(x_train_pca, y_train).decision_function(x_validation_pca)\n\n#binarize y_validation\ny_validation_binar = np.zeros(y_score.shape)\nnrows = y_score.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","5fe8d566":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:,i], y_score[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()","c34a88b6":"precision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","80aee70b":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nfor c in C:\n    SVC_classifier = svm.SVC(kernel = \"rbf\", C = c)\n    SVC_classifier.fit(x_train_scaled, y_train)\n    y_valid_predict = SVC_classifier.predict(x_validation_scaled)\n    acc_elem =  accuracy(y_valid_predict, np.array(y_validation)) \n    print(\"regularization parameter : {0:2}\".format(c))\n    print(\"accuracy = {:.3f}, balanced_accuracy = {:.3f}\".format(acc_elem, balanced_accuracy_score(y_validation, y_valid_predict)))\n  ","c626630b":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nplt.figure(figsize=(15,7))\nfor c in C :\n    SVC_classifier = svm.SVC(kernel = \"rbf\", C = c).fit(x_train_scaled, y_train)\n    \n    train_sizes, train_scores, validation_scores = learning_curve(SVC_classifier, x_train_scaled, y_train, cv=4)\n    train_scores_mean = train_scores.mean(axis = 1)\n    validation_scores_mean = validation_scores.mean(axis = 1)\n    train_scores_std = np.std(train_scores, axis=1)\n    validation_scores_std = np.std(validation_scores, axis=1)\n    plt.grid()\n    plt.plot(train_sizes, train_scores_mean, label = 'Training C {}'.format(c))\n    plt.plot(train_sizes, validation_scores_mean, label = 'Validation C {}'.format(c))\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    plt.title('Learning curves with K-Fold Cross Validation k=4', fontweight='bold')\n    plt.legend(loc='best')\n    plt.ylim(0,1.2)\nplt.show()","2e277586":"SVC_classifier = svm.SVC(kernel = \"rbf\", C = 8)\nSVC_classifier.fit(x_train_scaled, y_train)\ny_valid_predict = SVC_classifier.predict(x_validation_scaled)\nprint(\"C = {}\".format(8))\nprint(\"accuracy = {:.3f}, balanced accuracy = {:.3f}\\n\".format(accuracy(y_valid_predict, np.array(y_validation)), \n                                                                balanced_accuracy_score(y_validation, y_valid_predict)))\nprint(classification_report(y_validation, y_valid_predict ))\ncm = confusion_matrix(y_validation, y_valid_predict.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot()","f67668c2":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(SVC_classifier, x_train_scaled, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","8c03f71d":"n_classes = 5\n\n# classifier\nclf = OneVsRestClassifier(svm.SVC(kernel = \"rbf\", C = 8))\ny_score = clf.fit(x_train_scaled, y_train).decision_function(x_validation_scaled)\n\n#binarize y_validation\ny_validation_binar = np.zeros(y_score.shape)\nnrows = y_score.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","fb4137fb":"\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:,i], y_score[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()","68a62045":"precision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","d814b0e7":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nfor d in range(2, 8):\n    print(\"\\n\")\n    print(\"polynomial degree = \", d)\n    for c in C:\n        SVC_classifier = svm.SVC(kernel = \"poly\", C = c, degree = d)\n        SVC_classifier.fit(x_train_pca, y_train)\n        y_valid_predict = SVC_classifier.predict(x_validation_pca)\n        acc_elem =  accuracy(y_valid_predict, np.array(y_validation))\n        print(\"regularization parameter : {0:2}\".format(c))\n        print(\"accuracy = {:.3f}, balanced_accuracy = {:.3f}\".format(acc_elem, balanced_accuracy_score(y_validation, y_valid_predict)))\n   ","37a5012d":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nplt.figure(figsize=(15,7))\nfor c in C :\n    SVC_classifier = svm.SVC(kernel = \"poly\", C = c, degree=2).fit(x_train_pca, y_train)\n    \n    train_sizes, train_scores, validation_scores = learning_curve(SVC_classifier, x_train_pca, y_train, cv=4)\n    train_scores_mean = train_scores.mean(axis = 1)\n    validation_scores_mean = validation_scores.mean(axis = 1)\n    train_scores_std = np.std(train_scores, axis=1)\n    validation_scores_std = np.std(validation_scores, axis=1)\n    plt.grid()\n    plt.plot(train_sizes, train_scores_mean, label = 'Training C {}'.format(c))\n    plt.plot(train_sizes, validation_scores_mean, label = 'Validation C {}'.format(c))\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    plt.title('Learning curves with K-Fold Cross Validation k=4 Polynomial degree=2', fontweight='bold')\n    plt.legend(loc='best')\n    plt.ylim(0,1.5)\nplt.show()","68772304":"SVC_classifier = svm.SVC(kernel = \"poly\", C = 8, degree = 2)\nSVC_classifier.fit(x_train_pca, y_train)\ny_valid_predict = SVC_classifier.predict(x_validation_pca)\nprint(\"C = {}, Polynomial degree = {}\".format(8, 2))\nprint(\"accuracy = {:.3f}, balanced accuracy = {:.3f}\\n\".format(accuracy(y_valid_predict, np.array(y_validation)), \n                                                                balanced_accuracy_score(y_validation, y_valid_predict)))\nprint(classification_report(y_validation, y_valid_predict ))\ncm = confusion_matrix(y_validation, y_valid_predict.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot()","858f5b89":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(SVC_classifier, x_train_pca, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","07c3d741":"n_classes = 5\n\n# classifier\nclf = OneVsRestClassifier(svm.SVC(kernel = \"poly\", C = 8, degree = 2))\ny_score = clf.fit(x_train_pca, y_train).decision_function(x_validation_pca)\n\n#binarize y_validation\ny_validation_binar = np.zeros(y_score.shape)\nnrows = y_score.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","fe71233d":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:,i], y_score[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()","20531fde":"precision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","2699db9e":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nfor d in range(2, 8):\n    print(\"\\n\")\n    print(\"polynomial degree = \", d)\n    for c in C:\n        SVC_classifier = svm.SVC(kernel = \"poly\", C = c, degree = d)\n        SVC_classifier.fit(x_train_scaled, y_train)\n        y_valid_predict = SVC_classifier.predict(x_validation_scaled)\n        acc_elem =  accuracy(y_valid_predict, np.array(y_validation))\n        print(\"regularization parameter : {0:2}\".format(c))\n        print(\"accuracy = {:.3f}, balanced_accuracy = {:.3f}\".format(acc_elem, balanced_accuracy_score(y_validation, y_valid_predict)))\n  ","a38063eb":"C = np.array ([0.05, 0.1, 0.25, 0.5, 1, 1.5, 2, 2.5, 3, 8])\nplt.figure(figsize=(15,7))\nfor c in C :\n    SVC_classifier = svm.SVC(kernel = \"poly\", C = c, degree=2).fit(x_train_scaled, y_train)\n    \n    train_sizes, train_scores, validation_scores = learning_curve(SVC_classifier, x_train_scaled, y_train, cv=4)\n    train_scores_mean = train_scores.mean(axis = 1)\n    validation_scores_mean = validation_scores.mean(axis = 1)\n    train_scores_std = np.std(train_scores, axis=1)\n    validation_scores_std = np.std(validation_scores, axis=1)\n    plt.grid()\n    plt.plot(train_sizes, train_scores_mean, label = 'Training C {}'.format(c))\n    plt.plot(train_sizes, validation_scores_mean, label = 'Validation C {}'.format(c))\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    plt.title('Learning curves with K-Fold Cross Validation k=4 Polynomial degree=2', fontweight='bold')\n    plt.legend(loc='best')\n    plt.ylim(0,1.5)\nplt.show()","cf2fd2b8":"SVC_classifier = svm.SVC(kernel = \"poly\", C = 8, degree = 2)\nSVC_classifier.fit(x_train_scaled, y_train)\ny_valid_predict = SVC_classifier.predict(x_validation_scaled)\nprint(\"C = {}, Polynomial degree = {}\".format(8, 2))\nprint(\"accuracy = {:.3f}, balanced accuracy = {:.3f}\\n\".format(accuracy(y_valid_predict, np.array(y_validation)), \n                                                                balanced_accuracy_score(y_validation, y_valid_predict)))\nprint(classification_report(y_validation, y_valid_predict ))\ncm = confusion_matrix(y_validation, y_valid_predict.reshape(-1))\n\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot()","0711de19":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(SVC_classifier, x_train_scaled, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","c38fce91":"n_classes = 5\n\n# classifier\nclf = OneVsRestClassifier(svm.SVC(kernel = \"poly\", C = 8, degree = 2))\ny_score = clf.fit(x_train_scaled, y_train).decision_function(x_validation_scaled)\n\n#binarize y_validation\ny_validation_binar = np.zeros(y_score.shape)\nnrows = y_score.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","34c854f6":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:,i], y_score[:,i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()","7b60195c":"precision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","a558b67c":"# Parameters\nhidden_layers_sizes = [(100,), (50,), (200,), (150, 75), (200,50,10), (10,30,20)]\nactivation_functions = ['relu', 'logistic', 'tanh']\nsolver_weigth_optimization = ['adam','sgd']\nlearning_rates_init = [0.001, 0.002, 0.005]","91c22177":"param_grid = { \n    'hidden_layer_sizes': hidden_layers_sizes,\n    'activation' : activation_functions,\n    'learning_rate_init' : learning_rates_init,\n    'solver' : solver_weigth_optimization\n}\nmlpClassifier = MLPClassifier(random_state=1, max_iter=5000)\nCV_rfc_grid = GridSearchCV(estimator=mlpClassifier, param_grid=param_grid)\nCV_rfc_grid.fit(x_train_scaled, y_train)\nprint('The best parameters for training the model are {} '.format(CV_rfc_grid.best_params_))\ny_pred_validation = CV_rfc_grid.predict(x_validation_scaled)\nprint('accuracy = {:.3f}'.format(CV_rfc_grid.score(x_validation_scaled, y_validation)))\nprint(\"balanced accuracy = {:.3f}\\n\".format(balanced_accuracy_score(y_validation, y_pred_validation)))\nprint(classification_report(y_validation, y_pred_validation))","7de15e1f":"# Different hidden layers\nloss_dict = {}\nacc_dict = {}\nbal_acc_dict = {}\nfor i in hidden_layers_sizes: \n    mlpClassifier = MLPClassifier(hidden_layer_sizes = i, random_state=1, max_iter=500).fit(x_train_scaled, y_train)\n    loss_dict[i] =  mlpClassifier.loss_curve_\n    y_pred = mlpClassifier.predict(x_validation_scaled)\n    acc_dict[i] = mlpClassifier.score(x_validation_scaled, y_validation)\n    bal_acc_dict[i] = balanced_accuracy_score(y_validation, y_pred)\n\n\nprint('Accuracy on validation set:')\nfor k,v in acc_dict.items():\n    print('Network size: {} Accuracy: {:.3f}, Balanced_accuracy: {:.3f}'.format(k,v, bal_acc_dict[k]))\nprint()\nidx_best = np.array(list(acc_dict.values())).argmax()\nbest_hdl = list(acc_dict.keys())[idx_best]\nprint('The best network size is {}'.format(best_hdl))\n    \ncolors = ['purple', 'darkorange', 'cornflowerblue', 'red', 'green', 'rosybrown']\nplt.figure(figsize=(10,7))\nfor i, color in zip(hidden_layers_sizes, colors):\n    plt.plot(loss_dict[i], color=color, lw=2,\n             label='Size {})'.format(i))\nplt.title('Training loss over hidden layer sizes', fontweight='bold')\nplt.ylabel('Loss')\nplt.xlabel('Iter')\nplt.legend()\nplt.show()","2d5cf1c7":"# Different activation functions\nloss_dict = {}\nacc_dict = {}\nbal_acc_dict = {}\nfor i in activation_functions: \n    mlpClassifier = MLPClassifier(hidden_layer_sizes = best_hdl, activation=i, \n                                  random_state=1, max_iter=500).fit(x_train_scaled, y_train)\n    loss_dict[i] =  mlpClassifier.loss_curve_\n    y_pred = mlpClassifier.predict(x_validation_scaled)\n    acc_dict[i] = mlpClassifier.score(x_validation_scaled, y_validation)\n    bal_acc_dict[i] = balanced_accuracy_score(y_validation, y_pred)\n\nprint('Accuracy on validation set')\nfor k,v in acc_dict.items():\n    print('Activation function: {} Accuracy: {:.3f} Balanced accuracy: {:.3f}'.format(k,v, bal_acc_dict[k]))\nprint()\nidx_best = np.array(list(acc_dict.values())).argmax()\nbest_af = list(acc_dict.keys())[idx_best]\nprint('The best activation function is {}'.format(best_af))\n    \ncolors = ['purple', 'darkorange', 'cornflowerblue']\nplt.figure(figsize=(10,7))\nfor i, color in zip(activation_functions, colors):\n    plt.plot(loss_dict[i], color=color, lw=2,\n             label='Activation {}'.format(i))\nplt.title('Training loss over activation function', fontweight='bold')\nplt.ylabel('Loss')\nplt.xlabel('Iter')\nplt.legend()\nplt.show()","ab8811cb":"# Different solver_weigth_optimization\nloss_dict = {}\nacc_dict = {}\nbal_acc_dict = {}\nfor i in solver_weigth_optimization: \n    mlpClassifier = MLPClassifier(hidden_layer_sizes = best_hdl, activation=best_af, \n                                  solver=i, random_state=1, max_iter=1500).fit(x_train_scaled, y_train)\n    loss_dict[i] =  mlpClassifier.loss_curve_\n    y_pred = mlpClassifier.predict(x_validation_scaled)\n    acc_dict[i] = mlpClassifier.score(x_validation_scaled, y_validation)\n    bal_acc_dict[i] = balanced_accuracy_score(y_validation, y_pred)\n\nprint('Accuracy on validation set')\nfor k,v in acc_dict.items():\n    print('Solver: {} Accuracy: {:.3f} Balanced accuracy: {:.3f}'.format(k,v, bal_acc_dict[k]))\nprint()   \nidx_best = np.array(list(acc_dict.values())).argmax()\nbest_s = list(acc_dict.keys())[idx_best]\nprint('The best solver is {}'.format(best_s))\n\nplt.figure(figsize=(10,7))\ncolors = ['purple', 'darkorange']\nfor i, color in zip(solver_weigth_optimization, colors):\n    plt.plot(loss_dict[i], color=color, lw=2,\n             label='Solver {}'.format(i))\nplt.title('Training loss over solver', fontweight='bold')\nplt.ylabel('Loss')\nplt.xlabel('Iter')\nplt.legend()\nplt.show()","86fdb639":"# Different initial learning rates\nloss_dict = {}\nacc_dict = {}\nbal_acc_dict = {}\nfor i in learning_rates_init: \n    mlpClassifier = MLPClassifier(hidden_layer_sizes = best_hdl, activation=best_af, \n                                  solver=best_s, learning_rate_init=i,\n                                  random_state=1, max_iter=1500).fit(x_train_scaled, y_train)\n    loss_dict[i] =  mlpClassifier.loss_curve_\n    y_pred = mlpClassifier.predict(x_validation_scaled)\n    acc_dict[i] = mlpClassifier.score(x_validation_scaled, y_validation)\n    bal_acc_dict[i] = balanced_accuracy_score(y_validation, y_pred)\n\nprint('Accuracy on validation set')\nfor k,v in acc_dict.items():\n    print('Learning rate init: {} Accuracy: {:.3f} Balanced accuracy: {:.3f}'.format(k,v, bal_acc_dict[k]))\n    \nprint()\nidx_best = np.array(list(acc_dict.values())).argmax()\nbest_lr_init = list(acc_dict.keys())[idx_best]\nprint('The best learning rate initialization is {}'.format(best_lr_init))\n\nplt.figure(figsize=(10,7))\ncolors = ['purple', 'darkorange', 'cornflowerblue']\nfor i, color in zip(learning_rates_init, colors):\n    plt.plot(loss_dict[i], color=color, lw=2,\n             label='Learning rate {}'.format(i))\nplt.title('Training loss over leraning rate init', fontweight='bold')\nplt.ylabel('Loss')\nplt.xlabel('Iter')\nplt.legend()\nplt.show()","ffbac4d2":"from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, auc, roc_curve\nmlpClassifier = MLPClassifier(hidden_layer_sizes = best_hdl, activation = best_af, \n                              solver = best_s, learning_rate_init = best_lr_init, random_state=1,\n                              max_iter=5000).fit(x_train_scaled, y_train)\n\nprint(mlpClassifier.get_params())\ntrain_loss = mlpClassifier.loss_curve_\nplt.title('Training loss function')\nplt.ylabel('Loss')\nplt.xlabel('Iter')\n_ = plt.plot(train_loss)","8ce9ca8f":"y_pred = mlpClassifier.predict(x_validation_scaled)\nprint('Accuracy: {:.3f} Balanced accuracy: {:.3f}'.format(accuracy(y_pred, y_validation), balanced_accuracy_score(y_validation, y_pred)))\n\nprint(classification_report(y_validation, y_pred ))\ncm = confusion_matrix(y_validation, y_pred.reshape(-1))\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n_ = disp.plot()","c26d2d68":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(mlpClassifier, x_train_scaled, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","96e5cb2f":"n_classes = 5\n\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\n\n# classifier\nmlpClassifier = MLPClassifier(hidden_layer_sizes = best_hdl, activation = best_af, \n                              solver = best_s, learning_rate_init = best_lr_init, random_state=1,\n                              max_iter=5000).fit(x_train, y_train)\ny_score = mlpClassifier.fit(x_train_scaled, y_train).predict_proba(x_validation_scaled)\n\n#binarize y_validation\ny_validation_binar = np.zeros((len(y_validation), 5))\nnrows = y_validation.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","e8fe0808":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()","743ee3d4":"precision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","3ecf6d21":"# Since the evaluation of accuracy is not deterministic because each run a random different forest is generated we are going to set a random seed and then\n# we use grid search in order to estimate the best parameters\n\nrfc_grid = RandomForestClassifier(random_state= 52)\nmax_features = ['auto', 'sqrt', 'log2']\nn_estimators = [int(x) for x in np.arange(10, 100, 10)]\ncriterion = ['gini', 'entropy']\nparam_grid = { \n    'n_estimators': n_estimators,\n    'max_features' : max_features,\n    'criterion' : criterion,\n}\nCV_rfc_grid = GridSearchCV(estimator=rfc_grid, param_grid=param_grid)\nCV_rfc_grid.fit(x_train_scaled, y_train)\nprint('The best parameters for training the model are {} '.format(CV_rfc_grid.best_params_))\ny_pred_validation = CV_rfc_grid.predict(x_validation_scaled)\nprint('accuracy = {:.3f}'.format(CV_rfc_grid.score(x_validation_scaled, y_validation)))\nprint(\"balanced accuracy = {:.3f}\".format(balanced_accuracy_score(y_validation, y_pred_validation)))","f95269d6":"print(classification_report(y_validation, y_pred_validation ))\ncm = confusion_matrix(y_validation, y_pred_validation.reshape(-1))\nlabels = [0,1,2,3,4]\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n_ = disp.plot()","eb7fb429":"train_sizes, train_scores, valid_scores, fit_times, _ = learning_curve(CV_rfc_grid, x_train_scaled, y_train, train_sizes= np.linspace(0.1, 1.0, 5), return_times = True, n_jobs = 4)\nx_train_mean = np.mean(train_scores, axis = 1)\nx_valid_mean = np.mean(valid_scores, axis = 1)\nplt.figure(figsize = (10, 6))\nplt.plot(train_sizes, x_train_mean, 'o-', color=\"r\",\n                 label=\"Training set score\")\nplt.plot(train_sizes, x_valid_mean, 'o-', color=\"b\",\n                 label=\"Validation set score\")\nplt.title(\"Training and validation curves\")\nplt.xlabel(\"Training size\")\nplt.ylabel(\"Score\")\nplt.legend(loc = \"best\")","f7e2bfc3":"# setup for graphs\n\nn_classes = 5\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\n\n# classifier\nrfc = RandomForestClassifier(criterion= 'gini', max_features= 'auto', n_estimators = 90, random_state= 52)\ny_score = rfc.fit(x_train_scaled, y_train).predict_proba(x_validation_scaled)\n\n#binarize y_validation\ny_validation_binar = np.zeros((len(y_validation), 5))\nnrows = y_validation.shape[0]\nfor i in range(nrows) :\n    y_validation_binar[i][y_validation[i]] = 1","f24716b5":"# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _= roc_curve(y_validation_binar[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(10,7))\n\ncolors = cycle(['purple', 'darkorange', 'cornflowerblue', 'red', 'green'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]), linestyle = \"--\")\n\nplt.plot([0, 1], [0, 1], 'k-', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic for each class')\nplt.legend(loc=\"lower right\")\nplt.show()","6a5f2c68":"\nprecision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_validation_binar[:, i],\n                                                        y_score[:, i])\n    average_precision[i] = average_precision_score(y_validation_binar[:, i], y_score[:, i])\n\nplt.figure(figsize=(10, 7))\nlines = []\nlabels = []\nfor i, color in zip(range(n_classes), colors):\n    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n    lines.append(l)\n    labels.append('Precision-recall for class {0} (area = {1:0.2f})'\n                  ''.format(i, average_precision[i]))\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-recall curves for each class')\nplt.legend(lines, labels, loc=(\"lower left\"))\n\n\nplt.show()","0e019482":"##################################################\n# Save your test prediction in y_test_pred\n##################################################\n\nSVC_classifier = svm.SVC(kernel = \"rbf\", C = 8)\nSVC_classifier.fit(x_train_scaled, y_train)\nx_test_scaled = scaler.transform(x_test)\n#x_test_pca = pca.transform(x_test_scaled)\ny_test_pred = SVC_classifier.predict(x_test_scaled)\n\n# Create submission\nsubmission = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'sample_submission.csv'))\nx_test = np.load(os.path.join(DATA_BASE_FOLDER, 'test.npy')).reshape(len(submission), -1)\nif y_test_pred is not None:\n    submission['class'] = y_test_pred\nsubmission = submission[['Unnamed: 0', 'class']]\nsubmission = submission.rename(columns={'Unnamed: 0': 'id'})\nsubmission.to_csv('my_submission.csv', index=False)","6f8accd0":"###### with PCA ######","4a2a1149":"Looking at the training set data distribution we can notice how they are not equally distributed among the 5 class. The majority of samples belongs to the second and the third class while the zero, the first and the fourth class are significantly disadvantaged having only slightly more than half samples of the two predominant class. This huge gap will have a side effect on the classification model which it will probably not be able to generalize efficiently the main characteristics of each class.\nIn the validation set the situation is even worse. Class 0, 1 and 4 are still the most disadvantaged while 2 and 3 are the most relevant. Since data are so unbalanced accuracy won't be the unique metric we can take in account. We need to consider precision and recall too.","0eb5b348":"##### with PCA","3f665402":"# Word embeddings\n\nWords can be represented as n-dimentional vectors where the distance between points has a correspondence respect to similarity between word semantics (similar words are closer, while dissimilar ones are distant). This representation is known as word embeddings and here is extrapolated and pre-computed from the [GloVe](https:\/\/nlp.stanford.edu\/projects\/glove\/) model. \n\nHere is depicted an example of bi-dimensional word embeddings:\n![word embedding](https:\/\/shanelynnwebsite-mid9n9g1q9y8tt.netdna-ssl.com\/wp-content\/uploads\/2018\/01\/word-vector-space-similar-words.jpg)\n\nIn our case a single word is represented by a vector of length 25.\n\n# Phrase representation\n\nAll the phrases are padded to the phrase of maximum length, in this case `max_len = 10`, and each phrase is represented by the concatenation of his word embeddings (each phrase thus is a 10 * 25 = 250 dimentional vector).","b2f419d2":"##### Without PCA","f8eb66f8":"# Dataset","a66fc137":"#### K-Fold Cross Validation KNN","c772e096":"**KNN using Manhattan**","5c4553ba":"**Euclidian distance**","aa9ebf33":"**KNN Euclidian k=7**","5cb80bc4":"### SVM ###\n","35e85736":"**KNN Manhattan k=4**","f262c514":"**KNN Euclidian k=4**","c1b460c3":"# Model\n\nHere you have to implement a model (or more models, for finding the most accurate) for classification.\n\nYou can use the sklearn (or optionally other more advanced frameworks such as pytorch or tensorflow) package that contains a pool of models already implemented that perform classification. (SVMs, NNs, LR, kNN, ...)","f60ecd7d":"##### without PCA #####","3d645247":"#### Applying PCA ","635d40c4":"##### with PCA #####","6bba2eda":"The most common *distance functions* are: \n* **Manhattan distance**: <br>\n$manhattan_{L1}(x^{(0)},x^{(1)}) = \\sum_i|x_i^{(0)}-x_i^{(1)}|$\n* **Euclidian distance**: <br>\n$euclidian_{L2}(x^{(0)},x^{(1)}) = \\sqrt{\\sum_i(x_i^{(0)}-x_i^{(1)})^2}$","a09f1aa5":"**Manhattan distance**","54ff9707":"# Standard scaling\nData are scaled by removing the mean and scaling to unit variance.\n\n$z=(x-u)\/s$ where *u* is the mean and *s* the standard deviation of the samples.","ac446fd1":"#### Linear Kernel","a5f9603e":"#### Sigmoid Kernel","1183c99f":"##### Without PCA","0c8815e2":"# Evaluation","101599df":"We are going to do a very brief exploratory data analysis in order to inspect how training data are distributed among the 5 classes.\nWe are going to use countplot provided by the seaborn library.","f7a86deb":"##### With PCA","289167a2":"### MLP","9c4fe06e":"# EDA","93b2ea97":"# Send the submission for the challenge","2c891675":"# References and documentation","6bd7dd23":"* Pandas: https:\/\/pandas.pydata.org\/docs\/\n* NumPy: https:\/\/numpy.org\/doc\/stable\/\n* Scikit-Learn: https:\/\/scikit-learn.org\/stable\/\n* Seaborn: http:\/\/seaborn.pydata.org\n* Matplotlib: https:\/\/matplotlib.org\n* Scipy: https:\/\/www.scipy.org\n* Text-Classification: https:\/\/monkeylearn.com\/text-classification\/\n* Build KNN from scratch: https:\/\/towardsdatascience.com\/build-knn-from-scratch-python-7b714c47631a","9f5d4ed9":"#### Radial Basis Kernel","efa237b4":"### Random Forest ####","c636d019":"#### Polynomial Kernel ####","94ec68be":"# Welcome to the Emojify Challenge!","dd4656cf":"**KNN using Euclidian**","45bc1e65":"**KNN Manhattan k=7**","9384c6ca":"##### Without PCA","d707f8c8":"### KNN ###"}}