{"cell_type":{"7bfc9f44":"code","51a435d6":"code","e530d206":"code","717ce7ca":"code","ebcc717c":"code","9a43755b":"code","b7f2da4d":"code","37621868":"code","30c9e473":"code","4b419142":"code","370a5912":"code","3f580ecb":"code","1c6d2835":"code","5dabe8bc":"code","b23a3858":"code","0afbb86b":"code","6931b76f":"code","151262bf":"code","42e60ed5":"code","e4d5291b":"code","49ea37f5":"markdown","49a0a229":"markdown","a73da484":"markdown","d5b18ccb":"markdown","9e685bf9":"markdown","89c19e98":"markdown","b622ae76":"markdown"},"source":{"7bfc9f44":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom matplotlib import cm\nimport json\nfrom urllib import request\nimport unicodedata\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom PIL import Image\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","51a435d6":"df = pd.read_csv('..\/input\/indianeedsoxygen-tweets\/IndiaWantsOxygen.csv')","e530d206":"df.info()","717ce7ca":"columns_to_drop = ['user_name','user_description','user_favourites','user_friends','user_created','user_verified']\ndf.drop(columns=columns_to_drop,inplace=True)","ebcc717c":"df.head(3)","9a43755b":"null_info=df.isnull().sum()\nnull_info = pd.DataFrame(data=null_info,index=null_info.index,columns=['Null Count'])\nnull_info","b7f2da4d":"index = null_info[null_info['Null Count'] > 0].index.values\ndf.dropna(subset = list(index), inplace=True)\ndf=df.reset_index(drop=True)\ndf.shape","37621868":"cities_df = pd.read_csv('..\/input\/world-cities-database\/worldcitiespop.csv',usecols=['Country','City'])\ncities_df.dropna(inplace=True)","30c9e473":"def remove_accents(cities):\n    def remove(city):\n        nfkd_form = unicodedata.normalize('NFKD', city)\n        byte_city = nfkd_form.encode('ASCII', 'ignore')\n        city = byte_city.decode(\"utf-8\")\n        return city\n    cities = list(map(remove,cities))\n    cities = list(map(lambda x: x.lower(),cities))\n    return cities\n    \ndef get_cities(country_name):\n    cities = cities_df[cities_df['Country'].isin(country_name)]['City']\n    return cities\n\ncountry_dict = {'in': [],'pk': [],'gb': [],'us': [],'ca': [],\n                'au': [],'bd': [],'np': [],'ru': [],\n                'de': [],'fr': []}\ncountries = {'india':'in', 'pakistan':'pk', 'united kingdom':'gb', 'united states':'us',\n             'canada':'ca', 'australia':'au', 'bangladesh':'bd', 'nepal':'np',\n             'russia':'ru',  'france':'fr'}\nfor country in country_dict.keys():\n    cities = get_cities([country])\n    cities = remove_accents(cities)\n    country_dict[country] = cities\ncountry_dict['gb'].append('london')\ncountry_dict['ca'].append('toronto')\npk_cities = ['\u0644\u0627\u06c1\u0648\u0631, \u067e\u0627\u06a9\u0633\u062a\u0627\u0646',   '\u067e\u0627\u06a9\u0633\u062a\u0627\u0646', '\u0627\u0633\u0644\u0627\u0645 \u0622\u0628\u0627\u062f, \u067e\u0627\u06a9\u0633\u062a\u0627\u0646','\u06a9\u0631\u0627\u0686\u06cc, \u067e\u0627\u06a9\u0633\u062a\u0627\u0646']\nfor city in pk_cities: \n    country_dict['pk'].append(city)","4b419142":"def replace_with_country(country,cities,country_list):\n    def is_countrys_city(x):\n        if country in x.lower():\n            return country\n        if x.lower() in cities:\n            return country\n        location=x.split(',')\n        if isinstance(location,list):\n            if location[0].lower() in cities:\n                return country\n        return x\n    locations = df[~df['user_location'].isin(country_list)]['user_location']\n    updated_locations = locations.apply(is_countrys_city)\n    df.iloc[updated_locations.index,0] = updated_locations\n    country_list.append(country)\n\ncountry_list = []\nfor country in ['india','pakistan','united kingdom','united states','canada','australia','bangladesh','nepal','russia','france']:\n    replace_with_country(country,country_dict[countries[country]],country_list)\n    ","370a5912":"plt.figure(figsize=(10,8))\nsns.set(style='darkgrid')\ng=sns.countplot(y='user_location', data=df, order=df['user_location'].value_counts().index[:8],palette=\"muted\")\nplt.xlabel(\"Number of Tweets\", weight='bold')\nplt.ylabel(\"User Location\", weight='bold')\nx_cor = df['user_location'].value_counts()[:8].values\ny_cor = range(8)\ndef convert_to_K(x):\n    x = str(x)\n    if len(x) == 4:\n        y=x[1]\n        if int(x[2]) >=5:\n            y=str(int(x[1])+1)  \n        return x[0]+'.'+y+'K'\n    if len(x) == 3:\n        y=x[1]\n        if int(x[2]) >=5:\n            y=str(int(x[1])+1)  \n        return '0'+'.'+x[0]+y+'K'\n    if len(x) == 2:\n        y=x[0]\n        if int(x[1]) >=5:\n            y=str(int(x[0])+1)  \n        return '0'+'.'+'0'+y+'K'\n        \nvalues = list(map(convert_to_K,x_cor))\nfor Y, X,value in list(zip(y_cor,x_cor,values)):\n    g.text(y=Y,x=X,s=value, color='black', va=\"top\")\nplt.title('Tweet volume of top 8 countries',weight='bold')\nplt.show()","3f580ecb":"hashtags = df['hashtags'].values\nhashtags_text = ' '.join(hashtags)\nhashtags_text = hashtags_text.replace('[','').replace(']','').replace('\\'','').replace(',','')\nmask = np.array(np.array(Image.open('..\/input\/hashtag3\/hashtag.jpeg')))\nwordcloud = WordCloud(max_font_size=200, max_words=1500, background_color=\"black\",collocations=False, mask=mask,colormap='Greys').generate(hashtags_text)\nplt.figure(figsize=(19,19))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()","1c6d2835":"df.date=pd.to_datetime(df.date)\ndays=df.date.dt.day\ndf['day']=days\nts_df=df['day'].value_counts().reset_index()\nplt.figure(figsize=(25,7))\nsns.set_theme(style=\"darkgrid\")\nsns.lineplot(x=\"index\", y=\"day\",data=ts_df)\nplt.xlabel(\"Day of April\", weight='bold')\nplt.ylabel(\"# Tweets\", weight='bold')\nplt.title('Tweet count\/Day',weight='bold')\nplt.show()","5dabe8bc":"def concat(country,ts_df,arr):\n    temp = df[df['user_location'].isin([country])]['day'].value_counts().reset_index()\n    ts_df['day'] = temp['index']\n    ts_df['day count'] = temp['day']\n    ts_df['country'] = [country] * temp.shape[0]\n    arr.append(ts_df)\n    return arr\ndef timeseries_top_8_countries():\n    arr=[]\n    for x in countries.keys():\n        ts_df=pd.DataFrame(columns=['day','day count','country'])\n        arr = concat(x,ts_df,arr)\n    return pd.concat(arr)\ntop_8_ts_df=timeseries_top_8_countries()\n\nplt.figure(figsize=(25,10))\nsns.set_theme(style=\"darkgrid\")\nsns.lineplot(x=\"day\", y=\"day count\", hue=\"country\",data=top_8_ts_df)\nplt.xlabel(\"Day of April\", weight='bold')\nplt.ylabel(\"# Tweets\", weight='bold')\nplt.title('Tweet count\/Day of top 8 countries by tweet volume',weight='bold')\nplt.show()","b23a3858":"plt.figure(figsize=(8,8))\nsource_df = df.source.value_counts()[:4]\nnames = source_df.index\nnames=[x.replace('Twitter for','') for x in names]\nnames=[x.replace('Twitter','') for x in names]\nsize = source_df.values\nmy_circle = plt.Circle((0,0), 0.7, color='white')\nplt.pie(size, labels=names,colors=cm.get_cmap('Set3').colors[5:10])\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('Platform used for tweets',weight='bold')\nplt.show()","0afbb86b":"sia = SentimentIntensityAnalyzer()\ndef get_sentiment_val(tweet):\n    if sia.polarity_scores(tweet)[\"compound\"] > 0:\n        return True,sia.polarity_scores(tweet)['pos']\n    return False,0\nresult = df['text'].apply(get_sentiment_val)\ndef create_column_pos_tweet(x):\n    return x[0]\ndef create_column_pos_val(x):\n    return x[1]\ndf['positive_tweet'] = result.apply(create_column_pos_tweet)\ndf['pos_value'] = result.apply(create_column_pos_val)\ndef get_neg_val(tweet):\n    if sia.polarity_scores(tweet)[\"compound\"] < 0:\n        return sia.polarity_scores(tweet)['neg']\n    return 0\ndf['neg_value'] = df['text'].apply(get_neg_val)","6931b76f":"tweets_sentiment_count = []\ntweets_sentiment_count.append(df['positive_tweet'].value_counts())\ntop_five = list(countries.keys())\ntop_five = top_five[:5]\nfor country in top_five[:5]:\n    tweets_sentiment_count.append(df[df['user_location'].isin([country])]['positive_tweet'].value_counts())","151262bf":"plt.figure(figsize=(10,10))\nfig, ax = plt.subplots(2, 3, sharex='col', sharey='row',figsize=(20,10))\ni=0\nfor x in range(2):\n    for y in range(3):\n        f_count=tweets_sentiment_count[i].loc[False]\n        t_count=tweets_sentiment_count[i].loc[True]\n        Y=tweets_sentiment_count[i].values\n        X=list(tweets_sentiment_count[i].index)\n        if t_count > f_count:\n            c1 = 'green'\n            c2 = 'red'\n           \n        else:\n            c2 = 'green'\n            c1 = 'red'\n          \n        ax[x,y].bar(tweets_sentiment_count[i].index,tweets_sentiment_count[i].values,color=[c1,c2])\n        for y_loc,x_loc,value in list(zip(Y,X,Y)):\n            ax[x,y].text(y=y_loc,x=x_loc,s=value, color='black', ha=\"center\")\n        ax[x,y].get_xaxis().set_visible(False)\n        ax[x,y].get_yaxis().set_visible(False)\n        red_patch = mpatches.Patch(color='red', label='Negative')\n        green_patch = mpatches.Patch(color='green', label='Positive')\n        ax[0,1].legend(handles=[green_patch,red_patch])\n        i+=1\n        \ntitles=['Total']\nfor x in top_five:\n    titles.append(x.capitalize())\ni=0\nfor x in range(2):\n    for y in range(3):\n        ax[x,y].set_title(titles[i])\n        i+=1\nfig.suptitle('Tweets\\' Sentiment Count',weight='bold')\nfig.show()","42e60ed5":"df['user_followers'].describe()","e4d5291b":"fig, ax = plt.subplots(1, 4, sharex=True,figsize=(20,5))\ntemp = []\ntemp.append(df[df['user_followers']<=43].copy())\ntemp.append(df[(df['user_followers']>43) & (df['user_followers']<=184)].copy())\ntemp.append(df[(df['user_followers']>184) & (df['user_followers']<=837)].copy())\ntemp.append(df[df['user_followers']>837].copy())\nvisible=False\ntitles=['Followers <=43','43<Followers<=184','184<Followers<=837','Followers>837']\ni=0\nfor x,y in enumerate(temp):\n    corr_mat = y.loc[:,['user_followers','pos_value','neg_value']].corr()\n    corr_matrix = corr_mat.iloc[:,[0]]\n    if x==3:\n        visible=True\n    sns.heatmap(corr_matrix, annot=True,cmap=\"YlOrBr\",ax=ax[x],cbar=visible,fmt='.2f',linewidths=0.1,linecolor='gray')\n    ax[x].set_title(titles[i],weight='bold')\n    i+=1\n    if x !=0:\n        ax[x].get_yaxis().set_visible(False)\n\nplt.style.use('bmh')\nplt.show()","49ea37f5":"# **Sentimental analysis of tweets**","49a0a229":"# **Loading world cities name dataset**","a73da484":"# **Replacing city with its country name**","d5b18ccb":"# **Word cloud of hashtags**","9e685bf9":"# **Loading Tweet Dataset**","89c19e98":"# **Droping null values**","b622ae76":"# **Droping columns that are not required**"}}