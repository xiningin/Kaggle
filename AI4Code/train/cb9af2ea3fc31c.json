{"cell_type":{"2942e8ba":"code","b794017f":"code","ed458e97":"code","ec194373":"code","0c41c062":"code","80f7d2ca":"code","ff6d7bed":"code","eb43e805":"code","b8fac6a6":"code","bd3391d9":"code","bfffcb45":"code","33f33b63":"code","731a6c11":"code","b59bb625":"code","dba3c759":"code","6f830ced":"code","ed776e5c":"code","fc3bb407":"code","9cb20b4a":"code","0a8a55e9":"code","47140e1c":"code","4082650d":"code","3fa52a3c":"code","122f4287":"code","0fc337dd":"code","358517c2":"code","486399d1":"code","a51de5df":"code","99dc8197":"code","127e9f49":"code","cc64b1b0":"code","22a137cd":"code","de6ab382":"code","936ce68e":"code","96bb8ef7":"code","f762d8ae":"code","4824ca32":"code","c838f43a":"code","9229c9eb":"code","644b3a7d":"code","3d4506b9":"code","bf1f5f6e":"code","d412c6e4":"code","42048450":"code","16183dde":"code","01b51629":"code","fb343411":"code","4d767521":"code","593e68fb":"code","ede08a5f":"code","2b1af516":"code","03e10c8c":"code","917146ba":"code","a9210bac":"code","b3ec7b29":"code","fcdf92db":"code","fb3fee8f":"code","e2ddadf6":"code","8964a03d":"code","8fff52e9":"code","0f48b121":"code","c1117348":"markdown","ab556b89":"markdown","d249f057":"markdown","f3bcdc84":"markdown","cacfcdf1":"markdown","f5125d96":"markdown","699de342":"markdown","4931bf1e":"markdown","b6d4ba1a":"markdown","ff52589f":"markdown","2e4bcb68":"markdown","db7c50ca":"markdown","a0e7bf45":"markdown","de30e6ea":"markdown","4fa5a51a":"markdown","c08d3341":"markdown","d0609f07":"markdown","f24152c5":"markdown","c0509e02":"markdown","121209b3":"markdown","fa6c6cd9":"markdown","c6983aea":"markdown","e84bbf27":"markdown","752f2257":"markdown","92143997":"markdown","b8e67e04":"markdown","f1e330a1":"markdown","8f2595de":"markdown","b97edad6":"markdown","3dd879ff":"markdown","ac9dab61":"markdown","b76d331a":"markdown","69a10c8d":"markdown","1b6cac96":"markdown","2d263fe8":"markdown","9cc35d62":"markdown","e544e0c8":"markdown","cb9a98b0":"markdown"},"source":{"2942e8ba":"# Data analysis\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Imputing missing values\nfrom sklearn.impute import KNNImputer\n\nfrom scipy.stats import chi2_contingency\n\n# Feature engineering\nfrom sklearn.preprocessing import StandardScaler\n\n# Model processing and testing\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\nfrom sklearn.metrics import roc_auc_score, plot_roc_curve, precision_score, recall_score\n\n# Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier","b794017f":"df = pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")","ed458e97":"df.head()","ec194373":"df.info()","0c41c062":"df.shape","80f7d2ca":"s0 = round(df[df['stroke'] == 0].describe(), 2)\ns1 = round(df[df['stroke'] == 1].describe(), 2)\n\npd.concat([s0, s1], axis = 1, keys = ['No Stroke', 'Stroke'])","ff6d7bed":"df.isnull().sum()","eb43e805":"def count_negatives(data):\n    neg_count = 0\n    for n in data:\n        if type(data) == 'int':\n            if n < 0:\n               neg_count += 1\n    return neg_count\n\ncount_negatives(df)","b8fac6a6":"df_knn = df.copy()\ndf_knn.head()","bd3391d9":"impute = KNNImputer(n_neighbors = 5, weights = 'uniform')\ndf_knn['bmi'] = impute.fit_transform(df_knn[['bmi']])","bfffcb45":"df_knn.isnull().sum()","33f33b63":"colors = [\"#f1d295\", \"#c8c14f\", \"#fa8775\", \"#ea5f94\", \"#cd34b5\", \"#9d02d7\"]\npalette = sns.color_palette(palette = colors)\n\nsns.palplot(palette, size = 2)\nplt.text(-0.5, -0.7, 'Color Palette For This Notebook', size = 20, weight = 'bold')","731a6c11":"fig, ax = plt.subplots(figsize = (10,6))\nfig.patch.set_facecolor('#faf9f7')\nax.set_facecolor('#faf9f7')\n\nsns.histplot(\n    df['age'],\n    kde = False,\n    color = \"#ea5f94\"\n)\n\nfor i in ['top', 'left', 'bottom', 'right']:\n    ax.spines[i].set_visible(False)\n\nplt.text(5, 360, r'$\\mu$ = '+str(round(df['age'].mean(), 2)), fontsize = 12)\nplt.text(5, 343, r'$\\sigma$ = '+str(round(df['age'].std(), 2)), fontsize = 12)\nplt.title('Frequency of Ages', fontsize = 18, fontweight = 'bold', pad = 10)\nplt.xlabel('Age', fontsize = 14, labelpad = 10)\nplt.ylabel('Count', fontsize = 14, labelpad = 10)","b59bb625":"fig, ax = plt.subplots(figsize = (10,6))\nfig.patch.set_facecolor('#faf9f7')\nax.set_facecolor('#faf9f7')\n\nsns.histplot(\n    df['avg_glucose_level'],\n    color = \"#ea5f94\",\n    kde = False\n)\n\nfor i in ['top', 'left', 'bottom', 'right']:\n    ax.spines[i].set_visible(False)\n\n\nplt.text(220, 360, r'$\\mu$ = '+str(round(df['avg_glucose_level'].mean(), 2)), fontsize = 12)\nplt.text(220, 340, r'$\\sigma$ = '+str(round(df['avg_glucose_level'].std(), 2)), fontsize = 12)\nplt.title('Frequency of Glucose Levels', fontsize = 18, fontweight = 'bold', pad = 10)\nplt.xlabel('Average Glucose Level', fontsize = 14, labelpad = 10)\nplt.ylabel('Count', fontsize = 14, labelpad = 10)","dba3c759":"fig, ax = plt.subplots(1, 2, figsize = (12, 7))\nfig.patch.set_facecolor('#faf9f7')\nax[0].set_facecolor('#faf9f7')\nax[1].set_facecolor('#faf9f7')\n\nsns.histplot(\n    df['bmi'],\n    color = \"#ea5f94\",\n    kde = False,\n    ax = ax[0]\n)\n\nsns.histplot(\n    df_knn['bmi'],\n    color = \"#ea5f94\",\n    kde = False,\n    ax = ax[1]\n)\n\nax[0].text(70, 330, r'$\\mu$ = '+str(round(df['bmi'].mean(), 2)), fontsize = 11)\nax[0].text(70, 320, r'$\\sigma$ = '+str(round(df['bmi'].std(), 2)), fontsize = 11)\nax[0].set_title('Original BMI Data', fontsize = 16, fontweight = 'bold', pad = 10)\nax[0].set_xlabel('BMI', fontsize = 13)\nax[0].set_ylabel('Count', fontsize = 13)\n\nax[1].text(70, 500, r'$\\mu$ = '+str(round(df_knn['bmi'].mean(), 2)), fontsize = 11)\nax[1].text(70, 485, r'$\\sigma$ = '+str(round(df_knn['bmi'].std(), 2)), fontsize = 11)\nax[1].set_title('KNN Imputed BMI Data', fontsize = 16, fontweight = 'bold', pad = 10)\nax[1].set_xlabel('BMI', fontsize = 13)\nax[1].set_ylabel('')\n\nfor i in ['top', 'left', 'bottom', 'right']:\n    ax[0].spines[i].set_visible(False)\n    ax[1].spines[i].set_visible(False)\n\n\nplt.tight_layout()","6f830ced":"df['bmi'] = df_knn['bmi']\ndf['bmi'].isnull().sum()","ed776e5c":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (14,6))\nfig.patch.set_facecolor('#faf9f7')\n\nfor i in (ax1, ax2, ax3):\n    i.set_facecolor('#faf9f7')\n\nsns.kdeplot(\n    df['age'][df['stroke'] == 0],\n    ax = ax1,\n    color = \"#c8c14f\",\n    shade = True,\n    alpha = 0.5,\n    linewidth = 1.5,\n    ec = 'black'\n)\n\nsns.kdeplot(\n    df['age'][df['stroke'] == 1],\n    ax = ax1,\n    color = \"#cd34b5\",\n    shade = True,\n    alpha = 0.5,\n    linewidth = 1.5,\n    ec = 'black'\n)\nax1.legend(['No Stroke', 'Stroke'], loc = 'upper left')\nax1.set_xlabel('Age', fontsize = 14, labelpad = 10)\nax1.set_ylabel('Density', fontsize = 14, labelpad = 10)\n\nsns.kdeplot(\n    df['avg_glucose_level'][df['stroke'] == 0],\n    ax = ax2,\n    color = \"#c8c14f\",\n    shade = True,\n    alpha = 0.5,\n    linewidth = 1.5,\n    ec = 'black'\n)\n\nsns.kdeplot(\n    df['avg_glucose_level'][df['stroke'] == 1],\n    ax = ax2,\n    color = \"#cd34b5\",\n    shade = True,\n    alpha = 0.5,\n    linewidth = 1.5,\n    ec = 'black'\n)\n\nax2.legend(['No Stroke', 'Stroke'])\nax2.set_xlabel('Average Glucose Levels', fontsize = 14, labelpad = 10)\nax2.set_ylabel('')\n\nsns.kdeplot(\n    df['bmi'][df['stroke'] == 0],\n    ax = ax3,\n    color = \"#c8c14f\",\n    shade = True,\n    alpha = 0.5,\n    linewidth = 1.5,\n    ec = 'black'\n)\n\nsns.kdeplot(\n    df['bmi'][df['stroke'] == 1],\n    ax = ax3,\n    color = \"#cd34b5\",\n    shade = True,\n    alpha = 0.5,\n    linewidth = 1.5,\n    ec = 'black'\n)\n\nax3.legend(['No Stroke', 'Stroke'])\nax3.set_xlabel('BMI', fontsize = 14, labelpad = 10)\nax3.set_ylabel('')\n\nplt.suptitle('Density of Age, Glucose, and BMI by Stroke', fontsize = 16, fontweight = 'bold')\n\nfor i in (ax1, ax2, ax3):\n    for j in ['top', 'left', 'bottom', 'right']:\n        i.spines[j].set_visible(False)\n\nfig.tight_layout()","fc3bb407":"stroke = df[df['stroke'] == 1]\nno_stroke = df[df['stroke'] == 0]","9cb20b4a":"fig, ax = plt.subplots(3, 1, figsize=(16,20))\nfig.patch.set_facecolor('#faf9f7')\nfor j in range(0, 3):\n    ax[j].set_facecolor('#faf9f7')\n\n## Age vs Glucose Levels\nsns.scatterplot(\n    data = no_stroke, x = 'age', y = 'avg_glucose_level', color = '#f1d295',\n    alpha = 0.4, ax = ax[0]\n)\nsns.scatterplot(\n    data = stroke, x = 'age', y = 'avg_glucose_level', color = \"#9d02d7\",\n    ax = ax[0], edgecolor = 'black', linewidth = 1.2, alpha = 0.6\n)\n\n# Age vs BMI\nsns.scatterplot(\n    data = no_stroke, x = 'age', y = 'bmi', color = '#f1d295',\n    alpha = 0.4, ax = ax[1]\n)\nsns.scatterplot(\n    data = stroke, x = 'age', y = 'bmi', color = \"#9d02d7\",\n    ax = ax[1], edgecolor = 'black', linewidth = 1.2, alpha = 0.6\n)\n\n# Glucose Levels vs BMI\nsns.scatterplot(\n    data = no_stroke, x = 'avg_glucose_level', y = 'bmi', color = '#f1d295',\n    alpha = 0.4, ax = ax[2]\n)\nsns.scatterplot(\n    data = stroke, x = 'avg_glucose_level', y = 'bmi', color = \"#9d02d7\",\n    ax = ax[2], edgecolor = 'black', linewidth = 1.2, alpha = 0.6\n)\n    \nsns.despine()\n\nfor i in range(0, 3, 1):\n    ax[i].legend(['No Stroke', 'Stroke'])\n\nfig.tight_layout()","0a8a55e9":"fig, ax = plt.subplots(figsize=(10,6))\nfig.patch.set_facecolor('#faf9f7')\nax.set_facecolor('#faf9f7')\n\nlabels = ['Stroke', 'No Stroke']\ncolors = [\"#f1d295\", \"#ea5f94\"]\nsizes = df['stroke'].value_counts()\n\nplt.pie(sizes, explode = [0, 0.15], labels = labels, colors = colors,\n           autopct = '%1.1f%%', shadow = True, startangle = 130,\n           wedgeprops = {'ec': 'black'}, textprops = {'fontweight': 'medium'}\n)\nplt.axis('equal')\nplt.title('Percentage of Strokes')","47140e1c":"male_str = 0\nfem_str = 0\nmale_nstr = 0\nfem_nstr = 0\n\nfor index, row in df.iterrows():\n    if row['gender'] == 'Male':\n        if row['stroke'] == 1:\n            male_str += 1\n        else:\n            male_nstr += 1\n    else:\n        if row['stroke'] == 1:\n            fem_str += 1\n        else:\n            fem_nstr += 1\n\nprint(male_str, fem_str, male_nstr, fem_nstr)","4082650d":"plt.subplots(figsize=(8,6))\n\nstroke_matrix = np.array([[108, 2007], [141, 2854]])\nlabels = np.array([['Male - Stroke', 'Male - No Stroke'], ['Female - Stroke', 'Female - No Stroke']])\nformatted = (np.asarray([\"{0}\\n{1:.0f}\".format(text, data) for text, data in zip(labels.flatten(), stroke_matrix.flatten())])).reshape(2,2)\n\n\nsns.heatmap(\n    stroke_matrix,\n    annot = formatted,\n    fmt = '',\n    cmap = palette,\n    xticklabels = False,\n    yticklabels = False,\n    linecolor = 'black',\n    linewidth = 1,\n    annot_kws = {'fontweight': 'semibold'}\n)\nplt.title('Two-Way Contingency Table of Strokes by Gender', pad = 15, fontsize = 14)\nplt.ylabel('Gender', fontsize = 12, labelpad = 10)\nplt.xlabel('Stroke', fontsize = 12, labelpad = 10)","3fa52a3c":"heart_cont = pd.crosstab(df['heart_disease'], df['stroke'])\nheart_cont","122f4287":"plt.subplots(figsize=(8,6))\n\nheart_matrix = np.array([[4632, 202], [229, 47]])\nlabels = np.array([['No Heart Disease - No Stroke', 'No Heart Disease - Stroke'], ['Heart Disease - No Stroke', 'Heart Disease - Stroke']])\nformatted = (np.asarray([\"{0}\\n{1:.0f}\".format(text, data) for text, data in zip(labels.flatten(), heart_matrix.flatten())])).reshape(2,2)\n\nsns.heatmap(\n    heart_cont,\n    annot = formatted,\n    fmt = '',\n    cmap = palette,\n    linewidth = 1,\n    linecolor = 'black',\n    xticklabels = False,\n    yticklabels = False,\n    annot_kws = {'fontweight': 'semibold'}\n)\nplt.ylabel('Heart Disease', labelpad = 10, fontsize = 12)\nplt.xlabel('Stroke', labelpad = 10, fontsize = 12)","0fc337dd":"stat, p, dof, expected = chi2_contingency(heart_cont)\nstat, p","358517c2":"hyper_cont = pd.crosstab(df['hypertension'], df['stroke'])\nhyper_cont","486399d1":"plt.subplots(figsize=(8,6))\n\nhyper_matrix = np.array([[4429, 183], [432, 66]])\nlabels = np.array([['No Hypertension - No Stroke', 'No Hypertension - Stroke'], ['Hypertension - No Stroke', 'Hypertension - Stroke']])\nformatted = (np.asarray([\"{0}\\n{1:.0f}\".format(text, data) for text, data in zip(labels.flatten(), hyper_matrix.flatten())])).reshape(2,2)\n\nsns.heatmap(\n    hyper_cont,\n    annot = formatted,\n    fmt = '',\n    cmap = palette,\n    linewidth = 1,\n    linecolor = 'black',\n    xticklabels = False,\n    yticklabels = False,\n    annot_kws = {'fontweight': 'semibold'}\n)\nplt.ylabel('Hypertension', labelpad = 10, fontsize = 12)\nplt.xlabel('Stroke', labelpad = 10, fontsize = 12)","a51de5df":"df.groupby('Residence_type')['stroke'].value_counts()","99dc8197":"res_cont = pd.crosstab(df['Residence_type'], df['stroke'])\nres_cont","127e9f49":"plt.subplots(figsize=(8,6))\n\nres_matrix = np.array([[2400, 114], [2461, 135]])\nlabels = np.array([['Rural - No Stroke', 'Rural - Stroke'], ['Urban - No Stroke', 'Urban - Stroke']])\nformatted = (np.asarray([\"{0}\\n{1:.0f}\".format(text, data) for text, data in zip(labels.flatten(), res_matrix.flatten())])).reshape(2,2)\n\nsns.heatmap(\n    res_cont,\n    annot = formatted,\n    fmt = '',\n    cmap = palette,\n    linewidth = 1,\n    linecolor = 'black',\n    xticklabels = False,\n    yticklabels = False,\n    annot_kws = {'fontweight': 'semibold'}\n)\nplt.ylabel('Residence Type', labelpad = 10, fontsize = 12)\nplt.xlabel('Stroke', labelpad = 10, fontsize = 12)","cc64b1b0":"mar_cont = pd.crosstab(df['ever_married'], df['stroke'])\nmar_cont","22a137cd":"plt.subplots(figsize=(8,6))\n\nmar_matrix = np.array([[1728, 29], [3133, 220]])\nlabels = np.array([['Never Married - No Stroke', 'Never Married - Stroke'], ['Married - No Stroke', 'Married - Stroke']])\nformatted = (np.asarray([\"{0}\\n{1:.0f}\".format(text, data) for text, data in zip(labels.flatten(), mar_matrix.flatten())])).reshape(2,2)\n\nsns.heatmap(\n    mar_cont,\n    annot = formatted,\n    fmt = '',\n    cmap = palette,\n    linewidth = 1,\n    linecolor = 'black',\n    xticklabels = False,\n    yticklabels = False,\n    annot_kws = {'fontweight': 'semibold'}\n)\nplt.ylabel('Ever Married', labelpad = 10, fontsize = 12)\nplt.xlabel('Stroke', labelpad = 10, fontsize = 12)","de6ab382":"df['smoking_status'].unique()","936ce68e":"df.groupby('smoking_status')['stroke'].value_counts()","96bb8ef7":"fig, ax = plt.subplots(figsize=(10,6))\nfig.patch.set_facecolor('#faf9f7')\nax.set_facecolor('#faf9f7')\n\nbar_pal = [\"#c8c14f\", \"#fa8775\"]\n\ns = sns.countplot(\n    data = df, x = 'smoking_status', hue = 'stroke', palette = bar_pal,\n    linewidth = 1.2, ec = 'black'\n)\n\nfor i in ['top', 'right', 'bottom', 'left']:\n    ax.spines[i].set_visible(False)\n\nplt.legend(['No Stroke', 'Stroke'])\nplt.title(\"Smoking Status' Effect on Stroke\", size = 16, weight = 'bold', pad = 12)\nplt.xlabel('Smoking Status', size = 12, labelpad = 12)\nplt.ylabel('Count', size = 12, labelpad = 12)\n\nfor i in s.patches:\n    s.annotate(format(i.get_height(), '.0f'),  (i.get_x() + i.get_width() \/ 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 9), textcoords = 'offset points')\n\nfig.tight_layout()","f762d8ae":"df['work_type'].unique()","4824ca32":"fig, ax = plt.subplots(figsize=(10,6))\nfig.patch.set_facecolor('#faf9f7')\nax.set_facecolor('#faf9f7')\n\nbar_pal = [\"#c8c14f\", \"#fa8775\"]\n\nw = sns.countplot(\n    data = df, x = 'work_type', hue = 'stroke', palette = bar_pal,\n    linewidth = 1.2, ec = 'black'\n)\n\nfor i in ['top', 'right', 'bottom', 'left']:\n    ax.spines[i].set_visible(False)\n\nplt.legend(['No Stroke', 'Stroke'])\nplt.title(\"Work Type's Effect on Stroke\", size = 16, weight = 'bold', pad = 12)\nplt.xlabel('Work Type', size = 12, labelpad = 12)\nplt.ylabel('Count', size = 12, labelpad = 12)\n\nfor i in w.patches:\n    w.annotate(format(i.get_height(), '.0f'),  (i.get_x() + i.get_width() \/ 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 9), textcoords = 'offset points')\n\nfig.tight_layout()","c838f43a":"gen_odds = (108 * 2854) \/ (141 * 2007)\n\nheart_odds = (229 * 202) \/ (4632 * 47)\n\nhyper_odds = (432 * 183) \/ (4429 * 66)\n\nres_odds = (2400 * 135) \/ (2461 * 114)\n\nmar_odds = (1728 * 220) \/ (3133 * 29)\n\nd = {\n    'Features': ['Gender', 'Heart Disease', 'Hypertension',\n                'Residence', 'Married'],\n    'Odds': [gen_odds, heart_odds, hyper_odds, res_odds, mar_odds]\n}\n\nodds_df = pd.DataFrame(data = d)\nodds_df","9229c9eb":"df = pd.get_dummies(df, columns = ['gender', 'work_type', 'Residence_type', 'smoking_status'], prefix = ['sex', 'work', 'residence', 'smoke'])\ndf.head()","644b3a7d":"df['ever_married'] = df['ever_married'].apply(lambda x: 1 if x == 'Yes' else 0)\ndf.head()","3d4506b9":"num_cols = ['age', 'avg_glucose_level', 'bmi']\n\nscaler = StandardScaler()\n\ndf[num_cols] = scaler.fit_transform(df[num_cols])","bf1f5f6e":"df.head()","d412c6e4":"df = df.drop('id', axis = 1)\ndf.head()","42048450":"x = df.drop('stroke', axis = 1)\ny = df['stroke']\n\n\nsmote = SMOTE()\n\nx_oversample, y_oversample = smote.fit_resample(x, y)\n\nprint(y.value_counts())\nprint(y_oversample.value_counts())","16183dde":"x_train, x_test, y_train, y_test = train_test_split(x_oversample, y_oversample, test_size = 0.2, random_state = 0)","01b51629":"log = LogisticRegression()\nlog.fit(x_train, y_train)\ny_pred_log = log.predict(x_test)\ncr = classification_report(y_test, y_pred_log)\nprint(cr)","fb343411":"print('Precision Score: ', round(precision_score(y_test, y_pred_log), 2))\nprint('Recall Score: ', round(recall_score(y_test, y_pred_log), 2))\nprint('F1 Score: ', round(f1_score(y_test, y_pred_log), 2))\nprint('Accuracy Score: ', round(accuracy_score(y_test, y_pred_log), 2))\nprint('ROC AUC: ', round(roc_auc_score(y_test, y_pred_log), 2))","4d767521":"plot_roc_curve(log, x_test, y_test)","593e68fb":"sns.heatmap(\n    confusion_matrix(y_test, y_pred_log),\n    cmap = palette,\n    annot = True,\n    fmt = 'd',\n    yticklabels = ['No Stroke', 'Stroke'],\n    xticklabels = ['Pred No Stroke', 'Pred Stroke']\n)","ede08a5f":"rf = RandomForestClassifier()\nrf.fit(x_train, y_train)\ny_pred_rf = rf.predict(x_test)\ncr_rf = classification_report(y_test, y_pred_rf)\nprint(cr_rf)","2b1af516":"print('Precision Score: ', round(precision_score(y_test, y_pred_rf), 2))\nprint('Recall Score: ', round(recall_score(y_test, y_pred_rf), 2))\nprint('F1 Score: ', round(f1_score(y_test, y_pred_rf), 2))\nprint('Accuracy Score: ', round(accuracy_score(y_test, y_pred_rf), 2))\nprint('ROC AUC: ', round(roc_auc_score(y_test, y_pred_rf), 2))","03e10c8c":"plot_roc_curve(rf, x_test, y_test)","917146ba":"sns.heatmap(\n    confusion_matrix(y_test, y_pred_rf),\n    cmap = palette,\n    annot = True,\n    fmt = 'd',\n    yticklabels = ['No Stroke', 'Stroke'],\n    xticklabels = ['Pred No Stroke', 'Pred Stroke']\n)","a9210bac":"knn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\ny_pred_knn = knn.predict(x_test)\ncr_knn = classification_report(y_test, y_pred_knn)\nprint(cr_knn)","b3ec7b29":"print('Precision Score: ', round(precision_score(y_test, y_pred_knn), 2))\nprint('Recall Score: ', round(recall_score(y_test, y_pred_knn), 2))\nprint('F1 Score: ', round(f1_score(y_test, y_pred_knn), 2))\nprint('Accuracy Score: ', round(accuracy_score(y_test, y_pred_knn), 2))\nprint('ROC AUC: ', round(roc_auc_score(y_test, y_pred_knn), 2))","fcdf92db":"plot_roc_curve(knn, x_test, y_test)","fb3fee8f":"sns.heatmap(\n    confusion_matrix(y_test, y_pred_knn),\n    cmap = palette,\n    annot = True,\n    fmt = 'd',\n    yticklabels = ['No Stroke', 'Stroke'],\n    xticklabels = ['Pred No Stroke', 'Pred Stroke']\n)","e2ddadf6":"ada = AdaBoostClassifier()\nada.fit(x_train, y_train)\ny_pred_ada = ada.predict(x_test)\ncr_ada = classification_report(y_test, y_pred_ada)\nprint(cr_ada)","8964a03d":"print('Precision Score: ', round(precision_score(y_test, y_pred_ada), 2))\nprint('Recall Score: ', round(recall_score(y_test, y_pred_ada), 2))\nprint('F1 Score: ', round(f1_score(y_test, y_pred_ada), 2))\nprint('Accuracy Score: ', round(accuracy_score(y_test, y_pred_ada), 2))\nprint('ROC AUC: ', round(roc_auc_score(y_test, y_pred_ada), 2))","8fff52e9":"plot_roc_curve(ada, x_test, y_test)","0f48b121":"sns.heatmap(\n    confusion_matrix(y_test, y_pred_ada),\n    cmap = palette,\n    annot = True,\n    fmt = 'd',\n    yticklabels = ['No Stroke', 'Stroke'],\n    xticklabels = ['Pred No Stroke', 'Pred Stroke']\n)","c1117348":"# **5. Model Building**\n\n<a id=\"models\"><\/a>","ab556b89":"<p style=\"text-align:center;\"><b>Smoking Status<\/b><\/p>","d249f057":"# **4. Feature Engineering**\n\n<a id=\"features\"><\/a>","f3bcdc84":"#### 5.1 Logistic Regression\n\n<a id=\"logreg\"><\/a>","cacfcdf1":"# **Table of Contents**\n1. [Reading Data](#read)\\\n     1.1 [Initial Hypotheses](#hypotheses)\\\n     1.2 [Impute Data](#impute)\n2. [EDA](#eda)\\\n    2.1 [Custom Color Palette](#color)\\\n    2.2 [Numeric Variables](#numeric)\\\n    2.3 [Categorical Variables](#categorical)\n3. [Bonus EDA- Odds](#bonus)\n4. [Feature Engineering](#features)\n5. [Model Building](#models)\\\n    5.1 [Logistic Regression](#logreg)\\\n    5.2 [Random Forest](#forest)\\\n    5.3 [K-Nearest Neighbors](#neighbors)\\\n    5.4 [AdaBoost](#ada)\n6. [Conclusion](#conclusion)","f5125d96":"* Age will have a significant effect on stroke regardless of any other variable interaction.\n* Previous instances of heart disease will also have a significant effect on stroke.\n* Gender will have a positive, albeit weaker, effect.\n* Positive instances of smoking status as well as higher bmi will both have a significant effect.","699de342":"<p style=\"text-align:center;\"><b>Ever Married<\/b><\/p>","4931bf1e":"<p style=\"text-align:center;\">Count null values<\/p>","b6d4ba1a":"<p style=\"text-align:center;\">Most features seem to have little difference in their odds. The ever married variable has a 4 to 1 odds of having a stroke for individuals that were never married.<\/p>","ff52589f":"<p style=\"text-align:center;\"><b>Work Type<\/b><\/p>","2e4bcb68":"#### 1.1 Initial hypotheses\n\n<a id=\"hypotheses\"><\/a>","db7c50ca":"<p style=\"text-align:center;\">Given its high scores across the board, particularly in recall, I would say we should choose the random forest classifier. With such a high F1 score we can be quite confident in our pick. This model should be quite reliable at predicting which people are most at risk for having a stroke and which do not need unnecessary treatment.<\/p>","a0e7bf45":"<p style=\"text-align:center;\">Check to make sure everything was imputed properly.<\/p>","de30e6ea":"# **6. Conclusion**\n\n<a id=\"conclusion\"><\/a>","4fa5a51a":"<p style=\"text-align:center;\">Count negatives<\/p>","c08d3341":"#### 2.1 Create Custom Color Palette\n\n<a id=\"color\"><\/a>","d0609f07":"Metrics:\n\n* Precision is the total number of people the model correctly identified as having a stroke out of all the people PREDICTED to have a stroke\n\n* Recall is the total number of people the model correctly identified as a having a stroke out of all the people who ACTUALLY HAD a stroke.\n\n* Accuracy is the total number of correct predictions divided by the total number of predictions.\n\n* It is not possible to achieve both a high precision and a high recall value- we must determine which is more important for us in our model.\n\n* F1 gives us the harmonic mean of precision and recall (Aim for a high F1 value to indicate a good precision and a good recall value).\n\n* ROC (Receiver Operating Characteristic) Curve is a plot betwen the True Positive Rate on the y-axis and the False Positive Rate on the x-axis. A plot with the graph closer to the left and top axes is indicative of a better model.\n\n* AUC (Area Under Curve) values range from 0 to 1 with higher scores indicating a better model. The diagonal line on ROC curves usually represents a random model with an AUC of 0.5. (Would definitely want our model's AUC to be higher than 0.5, since that would signify it is better than random chance.\n\n* PRC (Precision-Recall Curves) plot values of precision scores on the y-axis and recall on the x-axis. A plot with the graph closer to the top and right axes is indicative of a better model. As with ROC curves, we should aim for a high AUC.","f24152c5":"# **3. Bonus EDA - Odds**\n\n<a id=\"bonus\"><\/a>","c0509e02":"## **1. Read Data**\n\n<a id=\"read\"><\/a>","121209b3":"<p style=\"text-align:center;\"><b>Heart Disease<\/b><\/p>","fa6c6cd9":"<p style=\"text-align:center;\">Investigate numeric variables- age, glucose, bmi<\/p>\n\n<p style=\"text-align:center;\">Histograms for each, their effect on strokes.<\/p>\n\n<p style=\"text-align:center;\">Potentially graph their effects<\/p>","c6983aea":"#### 5.4 AdaBoost\n\n<a id=\"ada\"><\/a>","e84bbf27":"<p style=\"text-align:center;\"><b>Hypertension<\/b><\/p>","752f2257":"<p style=\"text-align:center;\">Scatter plots of numerical variables colored by stroke.<\/p>","92143997":"<p style=\"text-align:center;\">Investigate the categorical variables- gender, hypertension, heart disease, ever married, work type, smoking status, and stroke<\/p>","b8e67e04":"# **2. EDA**\n\n<a id=\"eda\"><\/a>","f1e330a1":"<p style=\"text-align:center;\"><b>Residence Type<\/b><\/p>","8f2595de":"<p style=\"text-align:center;\">Scale continuous features if you are using distance-based algorithms such as k-nearest neighbors. Since we will be using knn, we will scale our features.<\/p>","b97edad6":"#### 5.3 K-Nearest Neighbors\n\n<a id=\"neighbors\"><\/a>","3dd879ff":"<p style=\"text-align:center;\">SMOTE helps with the severe imabalance of target variable. If we remember, only 5% of all cases actually included a stroke. It can help improve recall; that is- predict the number of people who actually had a stroke. Since we would care more about predicting who might have a stroke rather than who might not have one, SMOTE can help us accomplish that. We could try two different models using the original data and the oversampled data to determine if it is effective.<\/p>","ac9dab61":"#### 2.3 Categorical Variables\n\n<a id=\"categorical\"><\/a>","b76d331a":"<p style=\"text-align:center;\">Random state can be any number<\/p>","69a10c8d":"<p style=\"text-align:center;\">Let's first investigate the target variable.<\/p>","1b6cac96":"#### 2.2 Numeric Variables\n\n<a id=\"numeric\"><\/a>","2d263fe8":"<p style=\"text-align:center;\"><b>Gender<\/b><\/p>","9cc35d62":"#### 1.2 Impute Data\n\n<a id=\"impute\"><\/a>","e544e0c8":"<p style=\"text-align:center;\">Determine data shape, count number of null values, find out if there are any negative values.<\/p>\n<p style=\"text-align:center;\">Formulate initial hypothesis; which variables will have the most significant impact on the target variable?<\/p>","cb9a98b0":"#### 5.2 Random Forest\n\n<a id=\"forest\"><\/a>"}}