{"cell_type":{"dc484da6":"code","5bafa741":"code","f6182904":"code","0f30a547":"code","6b2ac6c1":"code","002aad38":"code","f8372a33":"code","1e48e3a6":"code","82d504d8":"code","dbd9f718":"code","4eb67152":"code","51b9cc92":"code","c0e37443":"code","c1650d0a":"code","f13021a1":"code","cfd09a09":"code","3a1d599a":"code","a92e30f6":"markdown","3b99c2f0":"markdown","35c59c9e":"markdown","af941f9c":"markdown","c3e15d19":"markdown","cc523bda":"markdown","c5d56f81":"markdown","23e0d239":"markdown","b8b40045":"markdown","face288d":"markdown","83ecc3f9":"markdown","6ec16be1":"markdown","43cc71f4":"markdown","b6a2523d":"markdown","ab89d252":"markdown","fa7dd83a":"markdown"},"source":{"dc484da6":"import os\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\nfrom keras.layers.normalization import BatchNormalization\n\nprint(\"Loaded all libraries\")","5bafa741":"fpath = \"..\/input\/images\/Images\/\"\nrandom_seed = 42\n\ncategories = os.listdir(fpath)\ncategories = categories[:20]\nprint(\"List of categories = \",categories,\"\\n\\nNo. of categories = \", len(categories))","f6182904":"def load_images_and_labels(categories):\n    img_lst=[]\n    labels=[]\n    for index, category in enumerate(categories):\n        for image_name in os.listdir(fpath+\"\/\"+category):\n            img = cv2.imread(fpath+\"\/\"+category+\"\/\"+image_name)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n            img_array = Image.fromarray(img, 'RGB')\n            \n            #resize image to 227 x 227 because the input image resolution for AlexNet is 227 x 227\n            resized_img = img_array.resize((227, 227))\n            \n            img_lst.append(np.array(resized_img))\n            \n            labels.append(index)\n    return img_lst, labels\n\nimages, labels = load_images_and_labels(categories)\nprint(\"No. of images loaded = \",len(images),\"\\nNo. of labels loaded = \",len(labels))\nprint(type(images),type(labels))","0f30a547":"images = np.array(images)\nlabels = np.array(labels)\n\nprint(\"Images shape = \",images.shape,\"\\nLabels shape = \",labels.shape)\nprint(type(images),type(labels))","6b2ac6c1":"def display_rand_images(images, labels):\n    plt.figure(1 , figsize = (19 , 10))\n    n = 0 \n    for i in range(9):\n        n += 1 \n        r = np.random.randint(0 , images.shape[0] , 1)\n        \n        plt.subplot(3 , 3 , n)\n        plt.subplots_adjust(hspace = 0.3 , wspace = 0.3)\n        plt.imshow(images[r[0]])\n        \n        plt.title('Dog breed : {}'.format(labels[r[0]]))\n        plt.xticks([])\n        plt.yticks([])\n        \n    plt.show()\n    \ndisplay_rand_images(images, labels)","002aad38":"#1-step in data shuffling\n\n#get equally spaced numbers in a given range\nn = np.arange(images.shape[0])\nprint(\"'n' values before shuffling = \",n)\n\n#shuffle all the equally spaced values in list 'n'\nnp.random.seed(random_seed)\nnp.random.shuffle(n)\nprint(\"\\n'n' values after shuffling = \",n)","f8372a33":"#2-step in data shuffling\n\n#shuffle images and corresponding labels data in both the lists\nimages = images[n]\nlabels = labels[n]\n\nprint(\"Images shape after shuffling = \",images.shape,\"\\nLabels shape after shuffling = \",labels.shape)","1e48e3a6":"images = images.astype(np.float32)\nlabels = labels.astype(np.int32)\nimages = images\/255\nprint(\"Images shape after normalization = \",images.shape)","82d504d8":"display_rand_images(images, labels)","dbd9f718":"x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.2, random_state = random_seed)\n\nprint(\"x_train shape = \",x_train.shape)\nprint(\"y_train shape = \",y_train.shape)\nprint(\"\\nx_test shape = \",x_test.shape)\nprint(\"y_test shape = \",y_test.shape)","4eb67152":"display_rand_images(x_train, y_train)","51b9cc92":"model=Sequential()\n\n#1 conv layer\nmodel.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"valid\",activation=\"relu\",input_shape=(227,227,3)))\n\n#1 max pool layer\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n\nmodel.add(BatchNormalization())\n\n#2 conv layer\nmodel.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n\n#2 max pool layer\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n\nmodel.add(BatchNormalization())\n\n#3 conv layer\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n\n#4 conv layer\nmodel.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n\n#5 conv layer\nmodel.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n\n#3 max pool layer\nmodel.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n\nmodel.add(BatchNormalization())\n\n\nmodel.add(Flatten())\n\n#1 dense layer\nmodel.add(Dense(4096,input_shape=(227,227,3),activation=\"relu\"))\n\nmodel.add(Dropout(0.4))\n\nmodel.add(BatchNormalization())\n\n#2 dense layer\nmodel.add(Dense(4096,activation=\"relu\"))\n\nmodel.add(Dropout(0.4))\n\nmodel.add(BatchNormalization())\n\n#3 dense layer\nmodel.add(Dense(1000,activation=\"relu\"))\n\nmodel.add(Dropout(0.4))\n\nmodel.add(BatchNormalization())\n\n#output layer\nmodel.add(Dense(20,activation=\"softmax\"))\n\nmodel.summary()","c0e37443":"model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])","c1650d0a":"%%time\nmodel.fit(x_train, y_train, epochs=100)","f13021a1":"loss, accuracy = model.evaluate(x_test, y_test)\n\nprint(loss,accuracy)","cfd09a09":"pred = model.predict(x_test)\n\npred.shape","3a1d599a":"plt.figure(1 , figsize = (19 , 10))\nn = 0 \n\nfor i in range(9):\n    n += 1 \n    r = np.random.randint( 0, x_test.shape[0], 1)\n    \n    plt.subplot(3, 3, n)\n    plt.subplots_adjust(hspace = 0.3, wspace = 0.3)\n    \n    plt.imshow(x_test[r[0]])\n    plt.title('Actual = {}, Predicted = {}'.format(y_test[r[0]] , y_test[r[0]]*pred[r[0]][y_test[r[0]]]) )\n    plt.xticks([]) , plt.yticks([])\n\nplt.show()","a92e30f6":"- Fit the model using training data","3b99c2f0":"- Define all layers in the AlexNet CNN model","35c59c9e":"- Check few random images and labels by displaying them in a graph","af941f9c":"## 4. Define AlexNet CNN model","c3e15d19":"- Display few random images after data normalization","cc523bda":"- Metrics to evaluate accuracy and loss in test dataset","c5d56f81":"- Data normalization","23e0d239":"## 2. Data loading and exploration","b8b40045":"## 3. Prepare data for training the CNN model\n\n- For training the CNN model we have to shuffle all the data that is loaded in images, labels list.","face288d":"- Display few random images with actual vs predicted values of labels","83ecc3f9":"## 1. Load all the libraries","6ec16be1":"- Compile the CNN model","43cc71f4":"- Split the loaded dataset into train, test sets","b6a2523d":"**Please note this kernel is for practice purposes only.** <br><br>\nIn this kernel I will be using [AlexNet](https:\/\/en.wikipedia.org\/wiki\/AlexNet) for multiclass image classification.\n\n**Inferences from the given dataset description:**<br>\n- There are 20,580 dogs images divided into 120 different categories (i.e., 120 breeds of dogs)\n\n**Steps followed in this kernel:**\n- Pick different categories of dog images for training the CNN model.\n- After the training is done we will check the accuracy of the CNN model in predicting the dog's breed correctly given an image of the dog.","ab89d252":"## 5. Train the model","fa7dd83a":"## 6. Predict values using the trained model"}}