{"cell_type":{"873bd6d2":"code","76bd65ab":"code","cdd9a627":"code","2586f2f5":"code","357f932f":"code","3e854246":"code","2fa01d8b":"code","5858fd7a":"code","dec4fd18":"code","febb959e":"code","305162bf":"code","f95908cb":"code","b7c98a1b":"code","c92b958e":"code","69e6d9cd":"code","e51d16da":"code","add6f2d8":"code","a7379024":"code","da96196b":"code","8f6fc101":"markdown"},"source":{"873bd6d2":"import os\nimport numpy as np\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nfrom datetime import timedelta, date\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","76bd65ab":"train = pd.read_csv('..\/input\/covid19-global-forecasting-week-5\/train.csv')\ntrain = train.fillna(\"\")","cdd9a627":"def get_wm(date=\"2020-05-09\"):\n    \n\n    if date == \"2020-05-08\":\n        f = \"http:\/\/web.archive.org\/web\/20200508190022\/https:\/\/www.worldometers.info\/coronavirus\/\"\n    elif date == \"2020-05-07\":\n        f = \"http:\/\/web.archive.org\/web\/20200507190101\/https:\/\/www.worldometers.info\/coronavirus\/\"\n    elif date == \"2020-05-06\":\n        f = \"http:\/\/web.archive.org\/web\/20200506190052\/https:\/\/www.worldometers.info\/coronavirus\/\"\n    elif date == \"2020-04-27\":\n        f = \"http:\/\/web.archive.org\/web\/20200427190152\/https:\/\/www.worldometers.info\/coronavirus\/\"\n    else:\n        f = \"https:\/\/www.worldometers.info\/coronavirus\/\"\n    \n    fname = \"page.html\"\n    !wget $f -q -O $fname\n    df_list = pd.read_html(open(fname))\n    \n    cm = {'Country, Territory':'Country_Region', 'Total Cases':'TotalCases', 'New Cases':'NewCases',\n      'Total Deaths':'TotalDeaths', 'Total Recovered': 'TotalRecovered', 'Serious, Critical': 'SeriousCritical',\n       'Country, Other':'Country_Region', 'Country,Other':'Country_Region'}\n\n    df0 = df_list[0]\n    df0.insert(0,'Date',date)\n    df0.rename(mapper=cm, axis=1, inplace=True)\n    \n    inttype = ['NewCases','NewDeaths']\n    \n    for c in inttype:\n        df0[c] = df0[c].astype(str).map(lambda x: x.lstrip('+-,')).str.replace(',', '').astype(float)\n        \n    df0 = df0[~df0[\"Country_Region\"].isin([\"World\", \"Total:\", \"North America\", \"Europe\", \"Asia\", \"South America\", \"Africa\", \"Oceania\",])]\n    \n    wm = df0\n    \n    wm[\"County\"] = np.nan\n    wm[\"Province_State\"] = np.nan\n    \n    recode = {\n     'CAR': 'Central African Republic',\n     'Congo':'Congo (Brazzaville)',\n     'Cruise Ship':'Diamond Princess',\n     'Cura\u00e7ao':'Curacao',\n     'DRC':'Congo (Kinshasa)',\n     'Faeroe Islands':'Faroe Islands',\n     'Falkland Islands': 'Falkland Islands (Malvinas)',\n     'Ivory Coast':\"Cote d'Ivoire\",\n     'Macao':'Macau',\n     'Myanmar':'Burma',\n     'Palestine':'West Bank and Gaza',\n     'R\u00e9union':'Reunion',\n     'S. Korea':'Korea, South',\n     'Saint Martin':'St Martin',\n     'Saint Pierre Miquelon':'Saint Pierre and Miquelon',\n     'St. Vincent Grenadines':'Saint Vincent and the Grenadines',\n     'St. Barth':'Saint Barthelemy',\n     'Taiwan':'Taiwan*',\n     'Turks and Caicos':'Turks and Caicos Islands',\n     'U.A.E.':'United Arab Emirates',\n     'U.K.':'United Kingdom',\n     'U.S. Virgin Islands': 'Virgin Islands',\n     'UAE':'United Arab Emirates',\n     'UK':'United Kingdom',\n     'USA':'US',\n     'USA *':'US',\n     'Vatican City':'Holy See',\n    \"Caribbean Netherlands\" : \"Bonaire, Sint Eustatius and Saba\"\n    }\n    wm['Country_Region'] = wm['Country_Region'].replace(to_replace=recode)\n    \n    \n\n    c = pd.Series(wm[\"Country_Region\"].unique())\n    idx = c.isin(train[\"Country_Region\"])\n   # print(idx.sum())\n   # print(c[~idx])\n    ct = c[~idx].values\n    \n    for c in ct:\n        t = train[train[\"Province_State\"]==c][\"Country_Region\"].values[0]\n        #print(c, \"-\", t)\n        idx = wm[\"Country_Region\"]==c\n        wm.loc[idx, \"Province_State\"] = c\n        wm.loc[idx, \"Country_Region\"] = t\n        \n    wm[\"NewCases\"] = wm[\"NewCases\"].fillna(0)\n    wm[\"NewDeaths\"] = wm[\"NewDeaths\"].fillna(0)\n    wm[\"Province_State\"] = wm[\"Province_State\"].fillna(\"\")\n    wm[\"County\"] = wm[\"County\"].fillna(\"\")\n    \n    last_day = train[train.Date==train.Date.max()]\n    last_day_c = last_day[last_day.Target==\"ConfirmedCases\"]\n    last_day_f = last_day[last_day.Target==\"Fatalities\"]\n    \n    ignore_countries = [\"China\", \"US\", \"Canada\", \"Australia\", \"Kosovo\", \"Brazil\", \"Spain\"]\n        \n    rows = []\n    for i, row in last_day_c.iterrows():\n        #print(row)\n        w = wm[(wm[\"Province_State\"]==row[\"Province_State\"]) & (wm[\"Country_Region\"]==row[\"Country_Region\"]) & (wm[\"County\"]==row[\"County\"])]\n\n        if len(w) < 1 or row[\"Country_Region\"] in ignore_countries:\n            row[\"TargetValue\"] = np.nan\n        else:\n            row[\"TargetValue\"] = w[\"NewCases\"].values[0]\n\n        row[\"Date\"] = wm[\"Date\"].values[0]\n        rows.append(row)\n        \n    new_c = pd.DataFrame(rows)\n    \n    rows = []\n    for i, row in last_day_f.iterrows():\n        #print(row)\n        w = wm[(wm[\"Province_State\"]==row[\"Province_State\"]) & (wm[\"Country_Region\"]==row[\"Country_Region\"]) & (wm[\"County\"]==row[\"County\"])]\n\n        if len(w) < 1 or row[\"Country_Region\"] in ignore_countries:\n            row[\"TargetValue\"] = np.nan\n        else:\n            row[\"TargetValue\"] = w[\"NewDeaths\"].values[0]\n\n        row[\"Date\"] = wm[\"Date\"].values[0]\n        rows.append(row)\n        \n    new_f = pd.DataFrame(rows)\n    \n    new = pd.concat([new_c, new_f], axis=0)\n        \n    \n    new = new.sort_values([\"Country_Region\", \"Target\"])\n    \n    return new\n\ndf = get_wm(date=\"2020-04-27\")\n\ndf.head()","2586f2f5":"df[df.TargetValue.isna()][\"Country_Region\"].value_counts()","357f932f":"train.Date.max()","3e854246":"#train_new = pd.concat([train, df], axis=0).sort_values([\"Country_Region\", \"Province_State\", \"County\", \"Date\", \"Target\"]).reset_index(drop=True)","2fa01d8b":"train_new = df","5858fd7a":"train_new.head()","dec4fd18":"train_new[train_new[\"Country_Region\"]==\"Afghanistan\"].sort_values(\"Date\", ascending=True)","febb959e":"train_new[train_new.TargetValue.isna()]","305162bf":"train_new.to_csv(\"train_extra.csv\", index=False)","f95908cb":"train_new = pd.concat([train, df], axis=0).sort_values([\"Country_Region\", \"Province_State\", \"County\", \"Date\", \"Target\"]).reset_index(drop=True)","b7c98a1b":"train_new.to_csv(\"train.csv\", index=False)","c92b958e":"train = train_new.copy()","69e6d9cd":"#train = train.fillna(0)","e51d16da":"def fix_target(frame, key, target, new_target_name=\"target\"):\n    import numpy as np\n    group_keys = frame[ key].values.tolist()\n    target = frame[target].values.tolist()\n    for i in range(1, len(group_keys) - 1):\n        target[i] =max(0,target[i] )#correct negative values\n    frame[new_target_name] = np.array(target)\n\ndirectory=\"\"\n\ntrain_fatalities=train[train.Target==\"Fatalities\"]\ntrain_confirmed=train[train.Target==\"ConfirmedCases\"]\ntrain_fatalities.columns=[\"Id_Fatalities\",\"County\",\"Province_State\",\"Country_Region\",\n                          \"Population\",\"Weight_Fatalities\",\"Date\",\"Target\",\"diff_Fatalities\"]\ntrain_confirmed.columns=[\"Id_ConfirmedCases\",\"County\",\"Province_State\",\"Country_Region\",\n                         \"Population\",\"Weight_ConfirmedCases\",\"Date\",\"Target\",\"diff_ConfirmedCases\"]\ntrain_confirmed.drop(\"Population\", inplace=True, axis=1)\ntrain_fatalities.drop(\"Target\", axis=1, inplace=True)\ntrain_confirmed.drop(\"Target\", axis=1, inplace=True)\ntrain=pd.merge(train_confirmed, train_fatalities, how=\"left\", left_on=[\"County\",\"Province_State\",\"Country_Region\",\"Date\"],\n              right_on=[\"County\",\"Province_State\",\"Country_Region\",\"Date\"])\ntrain=train[[\"Id_Fatalities\",\"Id_ConfirmedCases\",\"Date\",\"County\",\"Province_State\",\"Country_Region\",\n                          \"Population\",\"Weight_ConfirmedCases\",\"Weight_Fatalities\",\"diff_ConfirmedCases\",\"diff_Fatalities\"]]\ntrain[\"key\"]=train[[\"County\",\"Province_State\",\"Country_Region\"]].apply(lambda row: str(row[0]) + \"_\" + str(row[1])+ \"_\" + str(row[2]),axis=1)\n\nfix_target(train, \"key\", \"diff_ConfirmedCases\", new_target_name=\"diff_ConfirmedCases\")\nfix_target(train, \"key\", \"diff_Fatalities\", new_target_name=\"diff_Fatalities\")\n\n#train[\"diff_ConfirmedCases\"] = train[\"ConfirmedCases\"]\n\ntrain[\"ConfirmedCases\"] = train.groupby(\"key\")[\"diff_ConfirmedCases\"].transform(\"cumsum\")\ntrain[\"Fatalities\"] = train.groupby(\"key\")[\"diff_Fatalities\"].transform(\"cumsum\")\n#get_cumulative(train, \"key\", \"diff_ConfirmedCases\", new_target_name=\"ConfirmedCases\")\n#get_cumulative(train, \"key\", \"diff_Fatalities\", new_target_name=\"Fatalities\")\n","add6f2d8":"train[train[\"Country_Region\"]==\"Afghanistan\"].sort_values(\"Date\", ascending=False)","a7379024":"train[train[\"key\"]==\"__China\"].sort_values(\"Date\", ascending=False)","da96196b":"train.to_csv(\"train_oldformat.csv\", index=False)","8f6fc101":"Thanks to Russ for providing code from his last scraper: https:\/\/www.kaggle.com\/sasrdw\/gbt5fx\n\nWe adapted a few things and rather focused on non-US countries.\n\nThis is just a first attempt, and we are happy for others to contribute. Please do not rely on these results as they are and some countries might be completely wrong."}}