{"cell_type":{"de60e5e6":"code","fb5d1d7d":"code","066e3e0b":"code","9517c722":"code","c08b95df":"code","a888a10b":"code","ff28b480":"code","51016653":"code","8f9012f9":"code","52068c4c":"code","5dca18d5":"code","1badf182":"code","27041177":"code","29bf50ee":"code","1c54f360":"code","39ab7cc0":"code","6be344a2":"code","899248ae":"code","95bc7881":"code","19e59dfb":"markdown","44d1c7cb":"markdown","33b2adbb":"markdown","c504c64f":"markdown","004cad2a":"markdown","bbba7356":"markdown","a3d4ec34":"markdown","30f37df1":"markdown"},"source":{"de60e5e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom spacy.lang.fa import stop_words\nfrom string import punctuation, printable, digits\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fb5d1d7d":"df = pd.read_csv('\/kaggle\/input\/digikala-comments-persian-sentiment-analysis\/data.csv')\ndf.head()","066e3e0b":"df.shape","9517c722":"df.describe()","c08b95df":"df.sort_values(by='Score').head()","a888a10b":"# column 'Suggestion' is not needed\ndf = df.drop(['Suggestion'], axis=1)\ndf.head()","ff28b480":"df['Score'] = (df['Score']\/10).astype('int')","51016653":"# filter only extreme cases, cases in betweem are a combination of pos and neg reviews\ndf = df.loc[(df['Score']<6) | (df['Score']>7)]","8f9012f9":"df.loc[:,'label'] = df['Score'].apply(lambda score: 1 if score>7 else 0)","52068c4c":"plt.bar(['Positive','Negative'], df['label'].value_counts()\/df.shape[0])","5dca18d5":"train_X, test_X, train_y, test_y = train_test_split(df['Text'].values, df['label'].values, stratify=df['label'])\ntrain_X.shape, train_y.shape, test_X.shape, test_y.shape","1badf182":"def load_stopwords():\n    f = open(\"\/kaggle\/input\/farsi-stopwords\/fa_stop_words.txt\", \"r\", encoding='utf8')\n    stopwords = f.read()\n    stopwords = stopwords.split('\\n')\n    stopwords = set(stopwords)\n    custom_stop_words = {'\u0622\u0646\u0643\u0647','\u0622\u064a\u0627','\u0628\u062f\u064a\u0646','\u0628\u0631\u0627\u064a\u0646','\u0628\u0646\u0627\u0628\u0631','\u0645\u06cc\u0634\u0647','\u0645\u06cc\u06a9\u0646\u0647','\u0628\u0627\u0634\u0647','\u0633\u0644\u0627\u0645','\u0645\u06cc\u06a9\u0634\u0647','\u0627\u0648\u0646\u06cc',''}\n    stopwords = stopwords | stop_words.STOP_WORDS | custom_stop_words\n    # excluding space\n    stopwords = list(stopwords)[1:]\n    unwanted_num = {'\u062e\u0648\u0634','\u0628\u0647\u062a\u0631','\u0628\u062f','\u062e\u0648\u0628','\u0646\u06cc\u0633\u062a\u0645','\u0639\u0627\u0644\u06cc','\u0646\u06cc\u0633\u062a','\u0641\u0648\u0642','\u0628\u0647\u062a\u0631\u06cc\u0646'} \n    stopwords = [ele for ele in stopwords if ele not in unwanted_num] \n    return stopwords","27041177":"# we make a transformer so that we can use it in a pipeline\nclass Preprocess(BaseEstimator, TransformerMixin):\n    def __init__(self, stop_words):\n        self.stop_words = stop_words\n    def fit(self, X, y=None):\n        return self\n    def transform(self, corpus):\n        res = []\n        for data in corpus:\n            if not self.stop_words:\n                self.stop_words = set([])\n            ## ensure working with string\n            doc = str(data)\n            # First remove punctuation form string\n            PUNCT_DICT = {ord(punc): None for punc in punctuation+'\u060c'}\n            doc = doc.translate(PUNCT_DICT)\n            # remove numbers\n            doc = doc.translate({ord(k): None for k in digits})\n            tokens = doc.split()\n            tokens = [t for t in tokens if len(t) > 1]\n            res.append(' '.join(w for w in tokens if w not in self.stop_words))\n        return res","29bf50ee":"idx = 10\nprint(train_X[idx])\nPreprocess(load_stopwords()).transform([train_X[idx]])","1c54f360":"text_clf = Pipeline([\n    ('prep', Preprocess(load_stopwords())),\n    ('vect', CountVectorizer()),\n    ('clf', MultinomialNB()),\n])","39ab7cc0":"text_clf.fit(train_X, train_y)","6be344a2":"print(classification_report(train_y, text_clf.predict(train_X)))","899248ae":"test_pred = text_clf.predict(test_X)\nprint(classification_report(test_y, test_pred))","95bc7881":"np.array(test_X)[test_pred!=test_y][10:20]","19e59dfb":"# Make Labels","44d1c7cb":"# Check classifier mistakes","33b2adbb":"# Naive Bayes","c504c64f":"let's see how the preprocessing turns out","004cad2a":"# train and test split","bbba7356":"# Load & Explore","a3d4ec34":"we see that the dataset is not much balanced","30f37df1":"# Preprocess"}}