{"cell_type":{"45773242":"code","3087cb65":"code","ceb0b8f3":"code","ed83b77f":"code","ab892e5b":"code","7458944d":"code","26f78a4f":"code","7f4c6094":"code","a07a894d":"code","fcdb8be5":"code","86b9bf80":"code","7b851f2f":"code","ec5ddad7":"code","f359543a":"code","5acf6f25":"code","dc7a21c5":"markdown","f5f9a5d3":"markdown","720a384b":"markdown","a43688da":"markdown","75df1b89":"markdown","0dae37d5":"markdown","9c1eda6b":"markdown","8b3515a0":"markdown","258568e0":"markdown"},"source":{"45773242":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport pylab as pl\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom matplotlib import pyplot as plt\nfrom scipy.cluster.hierarchy import dendrogram\nfrom sklearn.datasets import load_iris\nfrom sklearn.cluster import AgglomerativeClustering\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3087cb65":"movies = pd.read_csv('\/kaggle\/input\/movietweetings\/movies.dat', delimiter='::', engine='python', header=None, names = ['Movie ID', 'Movie Title', 'Genre'])\nusers = pd.read_csv('\/kaggle\/input\/movietweetings\/users.dat', delimiter='::', engine='python', header=None, names = ['User ID', 'Twitter ID'])\nratings = pd.read_csv('\/kaggle\/input\/movietweetings\/ratings.dat', delimiter='::', engine='python', header=None, names = ['User ID', 'Movie ID', 'Rating', 'Rating Timestamp'])\nmovies.head()","ceb0b8f3":"ratings","ed83b77f":"rating_plot = ratings['Rating'].value_counts()\nplt.figure(figsize=(6,4))\nsns.barplot(rating_plot.index, rating_plot.values, alpha=0.8)\nplt.ylabel('Number of rating', fontsize=12)\nplt.xlabel('rating', fontsize=12)\nplt.xticks(rotation=80)\nplt.show();","ab892e5b":"Mean_rate = ratings.groupby(['User ID']).mean().reset_index()\nMean_rate['Mean_rating'] = Mean_rate['Rating']\nMean_rate.drop(['Movie ID','Rating','Rating Timestamp'],axis=1, inplace=True)","7458944d":"Mean_rate.head()","26f78a4f":"user = pd.merge(ratings,Mean_rate,on=['User ID','User ID'])\nuser.head()","7f4c6094":"Data = pd.merge(movies,user,on=['Movie ID','Movie ID'])\nData= Data[Data['User ID'] <= 10000]\n\nData","a07a894d":"X=Data.copy()\nX.drop(['Movie Title','Genre'],axis=1, inplace=True)\nX","fcdb8be5":"# Creating K-means Cluster Model\nfrom sklearn.cluster import KMeans\n\ndf_model = X\n\n#fit model\nkmeans = KMeans(n_clusters=10)\nk_fit = kmeans.fit(df_model)","86b9bf80":"# Predicting the Clusters\npd.options.display.max_columns = 10\npredictions = k_fit.labels_\ndf_model['Clusters'] = predictions\ndf_model","7b851f2f":"# In order to visualize in 2D graph I will use PCA\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\npca_fit = pca.fit_transform(df_model)\n\ndf_pca = pd.DataFrame(data=pca_fit, columns=['PCA1', 'PCA2'])\ndf_pca['Clusters'] = predictions\ndf_pca","ec5ddad7":"plt.figure(figsize=(10,10))\nsns.scatterplot(data=df_pca, x='PCA1', y='PCA2', hue='Clusters', palette='tab10', alpha=0.8)\nplt.title('Movie Tweetings Clusters after PCA');","f359543a":"from sklearn.manifold import TSNE\n\nXtsne = TSNE(n_components=2).fit_transform(df_pca)\ndftsne = pd.DataFrame(data=Xtsne , columns = ['x1','x2'])\ndftsne['cluster'] = predictions\ndftsne","5acf6f25":"plt.figure(figsize=(10,10))\nsns.scatterplot(data=dftsne,x='x1',y='x2',hue='cluster',legend=\"full\", palette='tab10', alpha=0.8)\nplt.title('Movie Tweetings Clusters Visualized on TSNE 2D');","dc7a21c5":"<h3>Step #4. Merge ratings & Mean_rate<\/h3>","f5f9a5d3":"<h3>Step #3. Add New Features<\/h3>","720a384b":"<h3>Step #5. Merge movies  & user<\/h3>","a43688da":"<h3>Step #8. t-Distributed Stochastic Neighbor Embedding (t-SNE) <\/h3>\n\nt-Distributed Stochastic Neighbor Embedding (t-SNE) is a non-linear technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets. It is extensively applied in image processing, NLP, genomic data and speech processing.\n","75df1b89":"<h3>Step #2.Data Visualization <\/h3>","0dae37d5":"<h3>Step #1. Read data<\/h3>","9c1eda6b":"<h3>Step #0. Import Library<\/h3>","8b3515a0":"<h3>Step #7. Principal Component Analysis PCA<\/h3>\n\nPrincipal Component Analysis (PCA) is an unsupervised machine learning technique that attempts to derive a set of low-dimensional set of features from a much larger set while still preserving as much variance as possible.","258568e0":"<h3>Step #6. K-means<\/h3>\n\nK-means is a centroid-based algorithm, or a distance-based algorithm, where we calculate the distances to assign a point to a cluster. In K-Means, each cluster is associated with a centroid."}}