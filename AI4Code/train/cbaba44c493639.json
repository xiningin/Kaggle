{"cell_type":{"7be07829":"code","2813f374":"code","a30cdd85":"code","cb153195":"code","b5c1f6ab":"code","3f2b2f2d":"code","f8f5151b":"code","2300e9fe":"code","265ddb50":"code","99d02ab3":"code","fb039024":"code","66801d37":"code","99c003ed":"code","2d470f04":"code","d61a07d4":"markdown","0e839f36":"markdown","e1d3f112":"markdown","65b89595":"markdown","d65bd994":"markdown","9ad0ef62":"markdown","96c81455":"markdown","e08324f1":"markdown","6f6f4fb9":"markdown","e452e5e9":"markdown","877233b5":"markdown","0b8830ab":"markdown"},"source":{"7be07829":"# install dependencies: \n!pip install pyyaml==5.1\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n!gcc --version\n# opencv is pre-installed on colab","2813f374":"# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n# See https:\/\/detectron2.readthedocs.io\/tutorials\/install.html for instructions\nimport torch\nassert torch.__version__.startswith(\"1.7\")\n!python -m pip install detectron2 -f \\\n  https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu102\/torch1.7\/index.html\n# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime","a30cdd85":"# Some basic setup:\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport os, json, cv2, random\n# from google.colab.patches import cv2_imshow\nfrom IPython import display\nimport PIL\n\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\n\n\ndef cv2_imshow(a):\n    \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\n    Args:\n    a : np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n      (N, M, 3) is an NxM BGR color image. shape (N, M, 4) is an NxM BGRA color\n      image.\n    \"\"\"\n    a = a.clip(0, 255).astype('uint8')\n    # cv2 stores colors as BGR; convert to RGB\n    if a.ndim == 3:\n        if a.shape[2] == 4:\n            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n        else:\n            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n    display.display(PIL.Image.fromarray(a))","cb153195":"from detectron2.data.datasets import register_coco_instances\nfrom detectron2.structures import BoxMode\n\nfor d in [\"train\", \"val\", \"test\"]:\n    register_coco_instances(f\"physics_{d}\", {},\n                            f\"..\/input\/physics-tasks-written-solutions\/physics_tasks_solutions\/annotations\/{d}.json\",\n                            f\"..\/input\/physics-tasks-written-solutions\/physics_tasks_solutions\/{d}\")","b5c1f6ab":"#visualize training data\nmy_dataset_train_metadata = MetadataCatalog.get(\"physics_train\")\ndataset_dicts = DatasetCatalog.get(\"physics_train\")\n\nimport random\nfrom detectron2.utils.visualizer import Visualizer\n\nfor d in random.sample(dataset_dicts, 3):\n    img = cv2.imread(d[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n    vis = visualizer.draw_dataset_dict(d)\n    cv2_imshow(vis.get_image()[:, :, ::-1])","3f2b2f2d":"from detectron2.engine import DefaultTrainer\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection\/faster_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"physics_train\",)\ncfg.DATASETS.TEST = ()\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection\/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\ncfg.SOLVER.MAX_ITER = 10000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https:\/\/detectron2.readthedocs.io\/tutorials\/datasets.html#update-the-config-for-new-datasets)\n# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n# uncomment below to train\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","f8f5151b":"# !wget \"https:\/\/mipt.one\/mediafiles\/models\/detectron2_miptone\" -o \"model_final.pth\"","2300e9fe":"# %reload_ext tensorboard\n# %tensorboard --logdir \/kaggle\/working\/output","265ddb50":"# Inference should use the config with parameters that are used in training\n# cfg now already contains everything we've set previously. We changed it a little bit for inference:\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\npredictor = DefaultPredictor(cfg)","99d02ab3":"import pickle\nwith open(\"cfg.pkl\", \"wb\") as f:\n    pickle.dump(cfg, f)","fb039024":"my_dataset_test_metadata = MetadataCatalog.get(\"physics_train\")\nfrom detectron2.utils.visualizer import ColorMode\ndataset_dicts = DatasetCatalog.get(\"physics_test\")\nfor d in random.sample(dataset_dicts, 5):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)  # format is documented at https:\/\/detectron2.readthedocs.io\/tutorials\/models.html#model-output-format\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=my_dataset_test_metadata, \n                   scale=0.5, \n#                    instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n    )\n    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    cv2_imshow(out.get_image()[:, :, ::-1])","66801d37":"from detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\nevaluator = COCOEvaluator(\"physics_test\", (\"bbox\", \"segm\"), False, output_dir=\".\/output\/\")\ntest_loader = build_detection_test_loader(cfg, \"physics_test\")\ninference_on_dataset(trainer.model, test_loader, evaluator)\n# another equivalent way to evaluate the model is to use `trainer.test`","99c003ed":"import os\nos.chdir(r'\/kaggle\/working')\n\nfrom IPython.display import FileLink\nFileLink(r'.\/output\/model_final.pth')","2d470f04":"# from detectron2.modeling import build_model\n# from detectron2.checkpoint import DetectionCheckpointer\n\n# with open(\"cfg.pkl\", \"rb\") as f:\n#     cfg = pickle.load(f)\n\n# model = build_model(cfg)\n# DetectionCheckpointer(model).load(file_path_or_url)","d61a07d4":"## Train!\n","0e839f36":"To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n\n","e1d3f112":"## TensorBoard","65b89595":"# Install detectron2","d65bd994":"## Inference & evaluation using the trained model\n\n","9ad0ef62":"We can also evaluate its performance using AP metric implemented in COCO API.\nThis gives an AP of ~60. Not bad!","96c81455":"# Train on a custom dataset","e08324f1":"## Prepare the dataset","6f6f4fb9":"## Exporting trained model weights for deployment","e452e5e9":"# Training detection model to find task numbers using Detectron2","877233b5":"Then, we randomly select several samples to visualize the prediction results.","0b8830ab":"## Or load saved model"}}