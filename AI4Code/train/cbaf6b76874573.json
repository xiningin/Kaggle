{"cell_type":{"4f099487":"code","435f53b9":"code","1374bda3":"code","4a3436f3":"code","7d834aa9":"code","4d702cfc":"code","6a38fea6":"code","197e6856":"code","aaf0f052":"code","c85d2dc9":"code","f7cb4508":"code","1cddbfb7":"code","d8887e35":"code","39f7e4dd":"code","f3dfcef3":"code","10140e20":"code","304e8e2f":"code","2ee6f2e0":"code","69d0c16a":"code","59d9397c":"code","6ec5c105":"code","eb087cc5":"code","93669a17":"code","fa67d0bf":"code","ff214c55":"code","3718c3f7":"markdown","a1cc0285":"markdown","3716a276":"markdown","7ff10eb2":"markdown","509b06db":"markdown","b2a72cbe":"markdown","31dd8448":"markdown"},"source":{"4f099487":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","435f53b9":"import math\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.utils import np_utils","1374bda3":"print('CPU: {}'.format(len(tf.config.list_physical_devices('CPU'))))\nprint('GPU: {}'.format(len(tf.config.list_physical_devices('GPU'))))","4a3436f3":"# loading the dataset\n\ndata = pd.read_csv('\/kaggle\/input\/facial-expression-recognitionferchallenge\/fer2013\/fer2013\/fer2013.csv')\ndata.head()","7d834aa9":"# shape of the dataframe loaded\n\ndata.shape","4d702cfc":"# basic analysis\n\ndata.info()","6a38fea6":"# checking the values for understanding of usage\n\nfor i in ['emotion', 'Usage']:\n    print(data[i].unique())","197e6856":"# calculate the image size\n\nmath.sqrt(len(data.pixels[0].split(' ')))","aaf0f052":"# chaning the pixels to numpy array\n\nX = data['pixels'].apply(lambda x: np.array(x.split()).reshape(48, 48, 1).astype('float32'))\nX = np.stack(X, axis=0)\nX.shape","c85d2dc9":"# extracting y label and declaring the emotions\n\nlookup = ('anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise', 'neutral')\ny = data['emotion']\ny.shape","f7cb4508":"# Count of photo with respect to different emotions\n\nsns.countplot(x=y)\nplt.xticks(range(7), lookup);","1cddbfb7":"# examine the images\n\ndef plot_index(index):\n    plt.imshow(X[index].reshape((48,48)), cmap='gray')\n    plt.title(lookup[y[index]])\n\nindex = int(input('Enter Value: '))\nplot_index(index)","d8887e35":"# Label encoding\n\nle = LabelEncoder()\nimg_labels = le.fit_transform(y)\nimg_labels = np_utils.to_categorical(img_labels)\nimg_labels.shape","39f7e4dd":"# dividing the image value by 255.0 so that all values can be filled between 0.0 and 1.0\n\nprint('Before Transformation', np.max(X))\nX = X \/ 255.0\nprint('After Transformation', np.max(X))","f3dfcef3":"X_train, X_valid, y_train, y_valid = train_test_split(img_array, img_labels,\n                                                    shuffle=True, stratify=img_labels,\n                                                    test_size=0.1, random_state=42)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","10140e20":"# splitting the dataset into training and testing sets\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, img_labels, test_size=0.1, stratify=img_labels)\nprint('Shape of training set', y_train.shape[0])\nprint('Shape of validation set', y_valid.shape[0])","304e8e2f":"# creating model of convolutional neural network\n\nmodel = Sequential()\n\nmodel.add(\n    Conv2D(\n        filters = 64,\n        kernel_size = (5, 5),\n        input_shape = (48, 48, 1),\n        activation = 'elu',\n        padding = 'same',\n        kernel_initializer = 'he_normal'\n    )\n)\nmodel.add(BatchNormalization())\n\nmodel.add(\n    Conv2D(\n        filters = 64,\n        kernel_size = (5, 5),\n        activation = 'elu',\n        padding = 'same',\n        kernel_initializer = 'he_normal'\n    )\n)\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(\n    Conv2D(\n        filters = 128,\n        kernel_size = (3, 3),\n        activation = 'elu',\n        padding = 'same',\n        kernel_initializer = 'he_normal'\n    )\n)\nmodel.add(BatchNormalization())\n\nmodel.add(\n    Conv2D(\n        filters = 128,\n        kernel_size = (3, 3),\n        activation = 'elu',\n        padding = 'same',\n        kernel_initializer = 'he_normal'\n    )\n)\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(\n    Conv2D(\n        filters = 256,\n        kernel_size = (3, 3),\n        activation = 'elu',\n        padding = 'same',\n        kernel_initializer = 'he_normal'\n    )\n)\nmodel.add(BatchNormalization())\n\nmodel.add(\n    Conv2D(\n        filters = 256,\n        kernel_size = (3, 3),\n        activation = 'elu',\n        padding = 'same',\n        kernel_initializer = 'he_normal'\n    )\n)\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten(name='flatten'))\n        \nmodel.add(\n    Dense(\n        128,\n        activation='elu',\n        kernel_initializer='he_normal',\n    )\n)\nmodel.add(BatchNormalization())\n    \nmodel.add(Dropout(0.6))\n    \nmodel.add(\n    Dense(\n        7,\n        activation='softmax'\n    )\n)","2ee6f2e0":"# checking the summary of the model\n\nmodel.summary()","69d0c16a":"# compile the model\n\nmodel.compile(\n    loss = 'categorical_crossentropy',\n    optimizer = 'adam',\n    metrics = ['accuracy']\n)","59d9397c":"# function for early stopping in when change in accuracy is low and ReduceLROnPlateau for learning rate\n\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00005,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n]","6ec5c105":"# creating images for increasing data\n\ngen = ImageDataGenerator(\n    rotation_range = 15,\n    width_shift_range = 0.15,\n    height_shift_range = 0.15,\n    shear_range = 0.15,\n    zoom_range = 0.15,\n    horizontal_flip = True\n)\ngen.fit(X_train)","eb087cc5":"# training the model\n\nmodel.fit(\n    gen.flow(X_train, y_train, batch_size=32),\n    validation_data = (X_valid, y_valid),\n    steps_per_epoch = len(X_train) \/ 32,\n    epochs = 100,\n    callbacks = callbacks,\n    use_multiprocessing = True\n)","93669a17":"#Saving the  model to  use it later on  \n\nfer_json = model.to_json()  \nwith open(\"fer.json\", \"w\") as json_file:  \n    json_file.write(fer_json)  \nmodel.save_weights(\"fer.h5\")  ","fa67d0bf":"predictions = model.predict(X_valid)\nprint(classification_report(np.argmax(y_valid, axis=1), np.argmax(predictions, axis=1)))","ff214c55":"plt.figure(figsize = (10,10))\nsns.heatmap(confusion_matrix(np.argmax(y_valid, axis=1), np.argmax(predictions, axis=1)),\n            xticklabels = lookup,\n            yticklabels = lookup,\n            annot = True\n)","3718c3f7":"# Checking CPU and GPU status","a1cc0285":"# Loading and Analysing the DataSet","3716a276":"# Creating and Training the Model","7ff10eb2":"# Feature Engineering","509b06db":"# Data Visualization","b2a72cbe":"# Importing Libraries","31dd8448":"# Model Evaluation"}}