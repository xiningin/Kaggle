{"cell_type":{"838dc148":"code","587a055c":"code","bbb149aa":"code","d89fd7ff":"code","abea4843":"code","0043741b":"code","e1788aab":"code","eafbc428":"code","91d38455":"code","8132ff8d":"code","66e64352":"code","9a280859":"code","73d7f7cf":"code","280a71c1":"code","fc8bda00":"code","f646967f":"code","138ec966":"code","4802fda8":"code","893ed1a5":"code","a74db4c7":"code","f6f20424":"code","d908db38":"code","2ccb04da":"code","92055dd7":"code","3eecb292":"code","616eb852":"code","772e86cf":"code","1d6e9b06":"code","83d8db72":"code","acd138ae":"code","04264e2b":"code","b1fda921":"code","a406447f":"code","cdbb83a8":"code","092f9c9d":"code","50397a26":"code","8494ca69":"code","96169c22":"code","ef44c455":"code","801d032c":"code","1cbc604c":"code","cca59d63":"code","0920be8a":"code","4a51f874":"code","2496ebf6":"code","34e38143":"code","fde3bb87":"code","2ad986de":"code","ab5171b4":"code","37c96107":"code","6eeb31e8":"code","bac44c15":"code","4bc703ba":"code","d86615ac":"code","690af158":"code","59c828a4":"code","648d4a3f":"code","3f02fbad":"code","58f86600":"markdown","70bbc89b":"markdown","a2a45958":"markdown","814ce3be":"markdown","e55a1cf5":"markdown","08fcb10c":"markdown","84da32c9":"markdown","bca001a0":"markdown","9d5e2466":"markdown","95f604e4":"markdown","876e4513":"markdown","71142dff":"markdown","09cbc040":"markdown","4a6722e8":"markdown","ec282ed9":"markdown","360a5edc":"markdown","011463d1":"markdown","ee43912a":"markdown","863ec854":"markdown","1f8252dc":"markdown","b5c4a5b6":"markdown","24c7a2c8":"markdown","ab494cf1":"markdown","b420b480":"markdown","d4a1712c":"markdown","6ee28dbe":"markdown","f2e82b80":"markdown","f3a49f60":"markdown","3cb234b9":"markdown","906a68fd":"markdown","1eb154bf":"markdown","4699fda7":"markdown","ad9ac870":"markdown","999a5194":"markdown","3b0a687d":"markdown","867e16d1":"markdown","75cddcdc":"markdown","d4c315b7":"markdown","4eae715f":"markdown","39c3dd55":"markdown","d134349b":"markdown","7fe01aff":"markdown","e2fb6dd8":"markdown","c2ab72fe":"markdown","238c4119":"markdown","9360f546":"markdown","cbf40a3c":"markdown","804ec5a9":"markdown","9d18b587":"markdown","cd0ad556":"markdown","d1f81e5a":"markdown","38fc3c55":"markdown","3536fb19":"markdown","b8a8484b":"markdown","9cddf333":"markdown"},"source":{"838dc148":"from math import sqrt\nfrom statistics import mean\n\nimport pandas as pd\nimport pandas_profiling\nimport seaborn as sns\nfrom matplotlib import style\nfrom mlens.ensemble import SuperLearner\nfrom numpy import absolute, std\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.datasets import make_regression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor, BaggingRegressor, RandomForestRegressor, \\\n    ExtraTreesRegressor\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.feature_extraction.text import _VectorizerMixin\nfrom sklearn.feature_selection._base import SelectorMixin\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import SVC, SVR\nfrom sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV, learning_curve, \\\n    validation_curve\nfrom sklearn.metrics import accuracy_score, mean_squared_error, classification_report\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport itertools\nimport warnings\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom statsmodels.tools.eval_measures import mse\n\nwarnings.filterwarnings('ignore')\n","587a055c":"def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None, n_jobs=None,\n                        train_sizes=np.linspace(.1, 1.0, 5), learn_scoring=None, scoring_title=\"Score\"):\n    if axes is None:\n        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n\n    axes[0].set_title(title)\n    if ylim is not None:\n        axes[0].set_ylim(*ylim)\n    axes[0].set_xlabel(\"Training examples\")\n    axes[0].set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores, fit_times, _ = \\\n        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n                       train_sizes=train_sizes,\n                       return_times=True, scoring=learn_scoring)\n\n    if learn_scoring == \"neg_mean_squared_error\":\n        train_scores_mean = -np.mean(train_scores, axis=1)\n        train_scores_std = np.std(train_scores, axis=1)\n        test_scores_mean = -np.mean(test_scores, axis=1)\n        test_scores_std = np.std(test_scores, axis=1)\n        fit_times_mean = np.mean(fit_times, axis=1)\n        fit_times_std = np.std(fit_times, axis=1)\n    else:\n        train_scores_mean = np.mean(train_scores, axis=1)\n        train_scores_std = np.std(train_scores, axis=1)\n        test_scores_mean = np.mean(test_scores, axis=1)\n        test_scores_std = np.std(test_scores, axis=1)\n        fit_times_mean = np.mean(fit_times, axis=1)\n        fit_times_std = np.std(fit_times, axis=1)\n\n    # Plot learning curve\n    axes[0].grid()\n    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"r\")\n    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1,\n                         color=\"g\")\n    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n                 label=\"Training score\")\n    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n                 label=\"Cross-validation score\")\n    axes[0].legend(loc=\"best\")\n    axes[0].set_ylabel(scoring_title)\n\n    # Plot n_samples vs fit_times\n    axes[1].grid()\n    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n                         fit_times_mean + fit_times_std, alpha=0.1)\n    axes[1].set_xlabel(\"Training examples\")\n    axes[1].set_ylabel(\"Fit times\")\n    axes[1].set_title(\"Scalability of the model\")\n\n    # Plot fit_time vs score\n    axes[2].grid()\n    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1)\n    axes[2].set_xlabel(\"Fit times\")\n    axes[2].set_ylabel(scoring_title)\n    axes[2].set_title(\"Performance of the model\")\n\n    return plt","bbb149aa":"df = pd.read_csv('..\/input\/autompg-dataset\/auto-mpg.csv', delimiter = \",\")\n","d89fd7ff":"df.shape\n","abea4843":"df.head()\n","0043741b":"df_auto = df.copy()","e1788aab":"# Rename columns to align with our data dictionary.\ndf_auto = df_auto.rename(columns = {'model year': 'model_year', 'car name': 'car_name'})\ndf_auto_orig = df_auto.copy()","eafbc428":"# Split car_name variable in make and model\ndf_auto['car_make'] = df_auto['car_name'].str.split(' ', 1).str.get(0)\ndf_auto['car_model'] = df_auto['car_name'].str.split(' ', 1).str.get(1)\ndf_auto.head()\n","91d38455":"df_auto.info()","8132ff8d":"df_auto.loc[~df_auto['horsepower'].astype(str).str.isdigit()]\n","66e64352":"df_auto = df_auto.replace('?', np.nan)\ndf_auto['horsepower'] = df_auto['horsepower'].astype(float)","9a280859":"categorical_cols = ['cylinders', 'model_year', 'origin']\nquantitative_cols = ['mpg', 'displacement', 'horsepower', 'weight', 'acceleration']\nquantitative_cols_model = ['displacement', 'horsepower', 'weight', 'acceleration']\n# Re-order columns\ncol_names = ['mpg', 'displacement', 'horsepower', 'weight', 'acceleration', 'cylinders', 'model_year', 'origin',\n             'car_make', 'car_model']\ncol_names_model = ['displacement', 'horsepower', 'weight', 'acceleration', 'cylinders', 'model_year', 'origin']\ndf_auto = df_auto.loc[:, col_names]","73d7f7cf":"#df_auto_model = pd.get_dummies(df_auto, columns = categorical_cols, drop_first=True)\n#cols = list(df_auto_model.columns.values)","280a71c1":"df_auto.sample(10, random_state=0)","fc8bda00":"df_auto.profile_report()","f646967f":"# Check for null values\nmissing_values_train = df_auto.isnull().sum()\nmissing_values_train = missing_values_train.to_frame(name='num_missing')\nmissing_values_train['perc_missing'] = (missing_values_train['num_missing']\/df_auto.shape[0])*100\nfor index, row in missing_values_train.iterrows():\n    if (row['num_missing'] > 0):\n        print (\"For \\\"%s\\\" the number of missing values are: %d (%.0f%%)\" %  (index,\n                                                                     row['num_missing'],\n                                                                    row['perc_missing']))","138ec966":"style.use('fivethirtyeight')\nsns.set_palette('Accent')\npalette = itertools.cycle(sns.color_palette('Accent'))\n\nn_rows, n_cols = (3,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(15, 20))\nfigure.suptitle('\\nDistributions of Continuous Variables', fontsize=25)\n\nfor index, column in enumerate(quantitative_cols):\n    i,j = (index \/\/ n_cols), (index % n_cols)\n    miss_perc=\"%.2f\"%(100*(1-(df_auto[column].dropna().shape[0])\/df_auto.shape[0]))\n    collabel=column+\"\\n({}% is missing)\".format(miss_perc)\n    fig=sns.distplot(df_auto[column], label=collabel, norm_hist=True,\n    ax=axes[i,j], kde_kws={\"lw\":4}, color=next(palette))\n    fig=fig.legend(loc='best', fontsize=18)\n    axes[i,j].set_ylabel(\"Probability Density\",fontsize='medium')\n    axes[i,j].set_xlabel(None)\nfigure.delaxes(axes[2,1])\n\nplt.show()","4802fda8":"style.use('seaborn-darkgrid')","893ed1a5":"n_rows, n_cols = (2,2)\n\nfigure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(15, 15))\nfigure.suptitle('Countplots of Categorical Features', fontsize=25)\n\nfor index, column in enumerate(categorical_cols):\n    i,j = index \/\/ n_cols, index % n_cols\n    miss_perc=\"%.2f\"%(100*(1-(df_auto[column].dropna().shape[0])\/df_auto.shape[0]))\n    collabel=column+\"\\n({}% is missing)\".format(miss_perc)\n    fig = sns.countplot(x=column, data=df_auto,label=collabel, palette='Accent',\n    ax=axes[i,j])\n#order = df_auto[column].value_counts().index)\n    axes[i,j].set_title(collabel,fontsize=20)\n    axes[i,j].set_xlabel(None)\n    axes[i,j].set_ylabel(\"Count\",fontsize=15)\n    axes[i,j].set_xticklabels(axes[i,j].get_xticklabels(), Fontsize=15)\nfigure.delaxes(axes[1,1])\n\nplt.show()","a74db4c7":"_ = plt.figure()\n_ = sns.pairplot(df_auto, diag_kind = \"kde\",hue = \"origin\",kind = \"scatter\",palette = \"Set1\")\n_ = plt.show()","f6f20424":"median = df_auto['horsepower'].median()\ndf_auto['horsepower'].fillna(median, inplace=True)\nprint(\"Number of null values in age column: {}\".format(df_auto['horsepower'].isnull().sum()))","d908db38":"X = df_auto.iloc[:, 1:8]\ny = df_auto.iloc[:, 0]","2ccb04da":"X.head()","92055dd7":"y.head()","3eecb292":"y = np.ravel(y)","616eb852":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","772e86cf":"X_train.shape","1d6e9b06":"X_train = pd.get_dummies(X_train, columns = categorical_cols, drop_first=True)\nX_test = pd.get_dummies(X_test, columns = categorical_cols, drop_first=True)\ncols_train = list(X_train.columns.values)\ncols_test = list(X_test.columns.values)\nX_train = pd.DataFrame(X_train, columns=cols_train)\nX_test = pd.DataFrame(X_test, columns=cols_test)","83d8db72":"X_train.head()","acd138ae":"# Manually enter columns here for testing, need to automate this.\nquantitative_cols_model = ['displacement', 'horsepower', 'weight', 'acceleration']\ncategorical_cols_model = ['cylinders_4', 'cylinders_5', 'cylinders_6', 'cylinders_8', 'model_year_71', 'model_year_72',\n                          'model_year_73', 'model_year_74', 'model_year_75', 'model_year_76', 'model_year_77',\n                          'model_year_78', 'model_year_79', 'model_year_80', 'model_year_81', 'model_year_82',\n                          'origin_2', 'origin_3']\nall_cols_model =  ['displacement', 'horsepower', 'weight', 'acceleration', 'cylinders_4', 'cylinders_5',\n                   'cylinders_6', 'cylinders_8', 'model_year_71', 'model_year_72', 'model_year_73', 'model_year_74',\n                   'model_year_75', 'model_year_76', 'model_year_77', 'model_year_78', 'model_year_79', 'model_year_80',\n                   'model_year_81', 'model_year_82', 'origin_2', 'origin_3']","04264e2b":"std_scaler = ColumnTransformer(\n            transformers=[('std_scaler', StandardScaler(), quantitative_cols_model)],\n            remainder = 'passthrough')\n\nX_train = std_scaler.fit_transform(X_train)\nX_test = std_scaler.fit_transform(X_test)\nX_train = pd.DataFrame(X_train, columns=cols_train)\nX_test = pd.DataFrame(X_test, columns=cols_test)","b1fda921":"reg = MLPRegressor(max_iter=100000, solver=\"lbfgs\", activation=\"relu\",hidden_layer_sizes=(5), random_state=1)\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\nmean_squared_error(y_pred,y_test)","a406447f":"# Default value of 5 fold CV will be used.\ntitle = r\"Learning curve (MLP - Unoptimised)\"\n_ = plot_learning_curve(reg, title, X_train, y_train, cv=None, n_jobs=-1, learn_scoring=\"neg_mean_squared_error\",\n                        scoring_title=\"MSE\")\n","cdbb83a8":"validation_scores = {}\nprint(\"No. Nodes | MSE\")\n\nfor hidden_layer_size in [(i,j) for i in range(2,8) for j in range(2,8)]:\n    reg = MLPRegressor(max_iter = 10000000, solver = \"lbfgs\", activation = \"relu\", hidden_layer_sizes\n    = hidden_layer_size, random_state = 1)\n    score = cross_val_score(estimator = reg, X = X_train, y = y_train, cv = 2, scoring = \"neg_mean_squared_error\")\n    validation_scores[hidden_layer_size] = -score.mean()\n    print(hidden_layer_size, \": %0.5f\" % validation_scores[hidden_layer_size])","092f9c9d":"# Check scores\nprint(\"The highest validation score is: %0.4f\" % min(validation_scores.values()))\noptimal_hidden_layer_size = [name for name, score in validation_scores.items()\n                              if score == min(validation_scores.values())][0]\nprint(\"This corresponds to nodes\", optimal_hidden_layer_size )","50397a26":"reg_par = [np.e**n for n in np.arange(-3,6,1)]\n\nvalidation_scores = {}\nprint(\" alpha  |  MSE \")\nfor param in reg_par:\n    reg = MLPRegressor(max_iter = 100000, solver = \"lbfgs\", activation = \"relu\", hidden_layer_sizes\n    = optimal_hidden_layer_size, alpha = param, random_state = 1)\n    score = cross_val_score(estimator = reg, X = X_train, y = y_train, cv = 2, scoring = \"neg_mean_squared_error\")\n    validation_scores[param] = -score.mean()\n    print(\"%0.5f |  %s\" % (param, -score.mean()))","8494ca69":"_ = plt.plot([np.log(i) for i in validation_scores.keys()], list(validation_scores.values()))\n_ = plt.xlabel(\"Ln of alpha\")\n_ = plt.ylabel(\"MSE\")","96169c22":"#reg_par_rev = reg_par.reverse()\n#reg_par.reverse()\ntrain_scores, test_scores = validation_curve(reg, X_train, y_train, \"alpha\", reg_par, cv=None,\n                                              scoring=\"neg_mean_squared_error\")\n\ntrain_scores_mean = -np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = -np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\n# Reverse scores to plot increasing complexity\ntrain_scores_mean_rev = train_scores_mean[::-1]\ntrain_scores_std = train_scores_std[::-1]\ntest_scores_mean_rev = test_scores_mean[::-1]\ntest_scores_std = test_scores_std[::-1]\nreg_par_rev = reg_par[::-1]\n\nfig, ax = plt.subplots(figsize=(7, 5))\n\n# Plot mean accuracy scores for training and testing scores\nax.plot(reg_par_rev, train_scores_mean_rev, label = \"Training Score\", color = 'b')\nax.plot(reg_par_rev, test_scores_mean_rev, label = \"Cross Validation Score\", color = 'g')\n\n# Creating the plot\nax.set_xlim(150,0)\nax.set_title(\"Validation Curve - MLP regularisation optimisation\")\nax.set_xlabel(\"Alpha value\")\nax.set_ylabel(\"MSE\")\n\nplt.tight_layout()\nplt.legend(loc = 'best')\nplt.show()\n","ef44c455":"print(\"The lowest cross validation error is: %s\" % (min(validation_scores.values())))\nprint(\"This corresponds to regularisation parameter e**%s\" %\n      ([np.log(name) for name, score in validation_scores.items()\n                         if score==min(validation_scores.values())][0]))\noptimal_alpha_param = [np.log(name) for name, score in validation_scores.items()\n                         if score==min(validation_scores.values())][0]","801d032c":"reg = MLPRegressor(max_iter=100000, solver=\"lbfgs\", activation=\"relu\", hidden_layer_sizes=optimal_hidden_layer_size,\n                   alpha=np.e**(optimal_alpha_param), random_state=1)\nreg.fit(X_train, y_train)\ny_pred = reg.predict(X_test)\nmean_squared_error(y_pred,y_test)\n","1cbc604c":"# Default value of 5 fold CV will be used.\ntitle = r\"Learning curve (MLP - Unoptimised)\"\n_ = plot_learning_curve(reg, title, X_train, y_train, cv=None, n_jobs=-1, learn_scoring=\"neg_mean_squared_error\",\n                        scoring_title=\"MSE\")\n\n","cca59d63":"# Obtaining dataframe columns from pipeline.\ndef get_feature_out(estimator, feature_in):\n    if hasattr(estimator,'get_feature_names'):\n        if isinstance(estimator, _VectorizerMixin):\n            return [f'vec_{f}' \\\n                for f in estimator.get_feature_names()]\n        else:\n            return estimator.get_feature_names(feature_in)\n    elif isinstance(estimator, SelectorMixin):\n        return np.array(feature_in)[estimator.get_support()]\n    else:\n        return feature_in\n\ndef get_ct_feature_names(ct):\n    output_features = []\n    for name, estimator, features in ct.transformers_:\n        if name!='remainder':\n            if isinstance(estimator, Pipeline):\n                current_features = features\n                for step in estimator:\n                    current_features = get_feature_out(step, current_features)\n                features_out = current_features\n            else:\n                features_out = get_feature_out(estimator, features)\n            output_features.extend(features_out)\n        elif estimator=='passthrough':\n            output_features.extend(ct._feature_names_in[features])\n\n    return output_features","0920be8a":"def get_models():\n\tmodels = list()\n\tmodels.append(LinearRegression())\n\tmodels.append(ElasticNet())\n\tmodels.append(SVR(gamma='scale'))\n\tmodels.append(DecisionTreeRegressor())\n\tmodels.append(KNeighborsRegressor())\n\tmodels.append(AdaBoostRegressor())\n\tmodels.append(BaggingRegressor(n_estimators=10))\n\tmodels.append(RandomForestRegressor(n_estimators=10))\n\tmodels.append(ExtraTreesRegressor(n_estimators=10))\n\treturn models\n\ndef rmse(yreal, yhat):\n\treturn sqrt(mean_squared_error(yreal, yhat))\n\ndef get_super_learner(X):\n\tensemble = SuperLearner(scorer=rmse, folds=10, shuffle=True, sample_size=len(X))\n\tmodels = get_models()\n\tensemble.add(models)\n\tensemble.add_meta(LinearRegression())\n\treturn ensemble\n\n","4a51f874":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","2496ebf6":"reg = MLPRegressor(max_iter=100000, solver=\"lbfgs\", activation=\"relu\", hidden_layer_sizes=(5), random_state=1)\n\n# Numeric transformations - for this dataset only missing values in numeric columns, so we don't have to impute the\n# categorical variables. Need to change this if this is not the case.\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('std_scaler', StandardScaler()),\n])\n\n# Final transformations, this includes OHE for categorical variables. Here we specify which columns to transform. Cool.\nvar_pipeline = ColumnTransformer(transformers = [\n        (\"num\", num_pipeline, quantitative_cols_model),\n        (\"cat\", OneHotEncoder(drop='first', handle_unknown='error'), categorical_cols),\n        ])\n\n# Pipeline including actual MLP model.\npipeline = Pipeline(steps =\n                    [('var_prep', var_pipeline),\n                     ('mlp_model', reg),\n                     ])\n# Set up cross validation object. Use three splits as this is a small dataset - cannot use less than 3, get an error.\ncv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n\n# Run cross validation on pipeline.\nscores = cross_val_score(pipeline, X_train, y_train, scoring = 'neg_mean_squared_error', cv = cv, n_jobs = -1)\nscores = absolute(scores)\nprint('MSE: %.3f (%.3f)' % (mean(scores), std(scores)))","34e38143":"pipeline.fit(X_train, y_train)\n#print(pipeline.data)\ny_pred = pipeline.predict(X_test)\nprint('Baseline MLP model built with pipeline: MSE %.3f' % (mse(y_test, y_pred)))","fde3bb87":"X_train_simple = var_pipeline.fit_transform(X_train)\nX_train_numpy = X_train_simple.toarray()\ncol_names_pipe = get_ct_feature_names(var_pipeline)\nX_train_final = pd.DataFrame(X_train_numpy, columns = col_names_pipe)","2ad986de":"X_train_final.head()","ab5171b4":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","37c96107":"# We get our baseline MLP regressor again.\nmlp_reg = MLPRegressor(max_iter=100000, solver=\"lbfgs\", activation=\"relu\", hidden_layer_sizes=(5), random_state=1)\n\n# We build our pipeline - same as before.\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('std_scaler', StandardScaler()),\n    ])\n\n# Note - scikit-learn gives an error if you don't specify handle_unknown = \"error\" here. Need to come back to this.\nvar_pipeline = ColumnTransformer(transformers = [\n        (\"num\", num_pipeline, quantitative_cols_model),\n        (\"cat\", OneHotEncoder(drop='first', handle_unknown='error'), categorical_cols),\n        ])\n\npipeline = Pipeline(steps = [\n        ('var_prep', var_pipeline),\n        ('mlp', mlp_reg),\n        ])\n\n# Now we add the secret sauce! GridSearch\n# We use the same parameters as before - for parity\nlayer_sizes = [(i,j) for i in range(2,8) for j in range(2,8)]\n\nalphas = [np.e**n for n in np.arange(-3,6,1)]\n\n# Define parameter grid - keep it at default for parity testing.\nparams = {\n          #'mlp__activation': ['relu', 'tanh', 'logistic', 'identity'],\n          #'mlp__activation': ['relu', 'tanh'],\n          'mlp__activation': ['relu'],\n          #'hidden_layer_sizes': list(itertools.permutations([50,100,150],2)) + list(itertools.permutations([50,100,\n          # 150],3)) + [50,100,150],\n          'mlp__alpha': alphas,\n          'mlp__hidden_layer_sizes': layer_sizes,\n          #'mlp__solver': ['adam', 'lbfgs'],\n          'mlp__solver': ['lbfgs'],\n          #'mlp__solver': ['adam'],\n          #'mlp__learning_rate' : ['constant', 'adaptive', 'invscaling']\n          'mlp__learning_rate' : ['constant']\n         }\n\nmlp_regressor_grid = GridSearchCV(pipeline, param_grid = params, n_jobs = -1, cv = 2, verbose = 5, scoring =\n                    'neg_mean_squared_error')\n                    #'neg_mean_squared_error', return_train_score=True)\nmlp_regressor_grid = mlp_regressor_grid.fit(X_train, y_train)","6eeb31e8":"res = pd.DataFrame(mlp_regressor_grid.cv_results_['params'])\nres['score'] = mlp_regressor_grid.cv_results_['mean_test_score']\nres.sort_values('score', ascending=False)","bac44c15":"final_model = mlp_regressor_grid.best_estimator_","4bc703ba":"print (final_model)\nprint (final_model.get_params()['mlp__alpha'])\nprint (final_model.get_params()['mlp__hidden_layer_sizes'])","d86615ac":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","690af158":"final_model.fit(X_train, y_train)\ny_pred = final_model.predict(X_test)\nprint('Final model: MSE %.3f' % (mse(y_test, y_pred)))","59c828a4":"ensemble = get_super_learner(X_train)\npipeline = Pipeline(steps =\n                    [('var_prep', var_pipeline),\n                     ('ensemble', ensemble)\n                     ])\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_test)\nprint('Ensemble: MSE %.3f' % (mse(y_test, y_pred)))","648d4a3f":"data_pipeline = Pipeline(steps =\n                    [('var_prep', var_pipeline),\n                     ])\n\nX_train_pipe = data_pipeline.fit_transform(X_train)\nX_test_pipe = data_pipeline.transform(X_test)\n\nensemble.fit(X_train_pipe, y_train)\nprint(ensemble.data)\ny_pred = ensemble.predict(X_test_pipe)\nprint('Ensemble: MSE %.3f' % (mse(y_test, y_pred)))\n","3f02fbad":"X_design = X.copy()\nX_design_vec = pd.DataFrame(X_design.median()).transpose()\nX_design_vec.head()\n\nmin_res = min(X.loc[:,\"weight\"])\nmax_res = max(X.loc[:,\"weight\"])\nseq = np.linspace(start=min_res,stop=max_res,num=50)\n\nto_predict = []\nfor result in seq:\n    X_design_vec.loc[0,\"weight\"] = result\n    to_predict.append(X_design_vec.copy())\n\nto_predict = pd.concat(to_predict)\npredictions = final_model.predict(to_predict)\n\nplt.plot(seq,predictions)\nplt.xlabel(\"Weight\")\nplt.ylabel(\"Miles per Gallon\")\nplt.title(\"MPG vs Weight\")\nplt.show()\n","58f86600":"Wonderful. The baseline GridsearchCV seems to work. Modest increase in accuracy too. Happy days.\n\nNow let us see if we can extract our best model and use it on the whole training set as before.","70bbc89b":"We now build a baseline model (MLP) followed by setting up a model pipeline. We first manually optimise\nhyper-parameters (for fun) and then we use GridSearchCV to optimise the parameters for us.\n\nWe start by imputing missing values. Data leakage takes place here. We will fix this going forward with an imputation\n transformer in our pipeline...","a2a45958":"The final analysis dataset looks as follows now:","814ce3be":"Ballpark similar! Yay. Success!\n\nThat concludes this notebook for now. We succeeded in building a Pipeline for our simple MLP.\n\nOur last step will be to do final model validation via plotting a response curve and performing some accuracy tests.","e55a1cf5":"Let us have a look at the original data:","08fcb10c":"We now split and One Hot Encode categorical variables. Our dataset now looks as follows:","84da32c9":"Looks good. Again, ballpark the same as our manual method.\n\nAnother tool for our toolbox! Let us just double check our numbers by manually building datasets and running them\nthrough the ensemble.","bca001a0":"<h2 style = \"font-family:verdana; background-color:#C5D6FA\"><center>Load data<\/center><\/h2>","9d5e2466":"Very nice!\n\nWe start with automated EDA and then follow up with further manual analysis. Exciting times...","95f604e4":"Now we analyse the distribution of continuous variables to get a feel for the data.\n","876e4513":"Finally we build our baseline MLP and note baseline accuracy on test set.","71142dff":"A tiny improvement. We now have an MSE just under 9. Not really a true comparison as it was on the CV set, but good\nenough for now. We can conclude that a simple model architecture suffices in this case.\n\nWe now perform regularisation to try and reduce overfitting more. We use an exponentially increasing series of numbers\naround 0 as possible values for the regularisation parameter <i>alpha<\/i>.","09cbc040":"Success! We obtain a similar result to the one we had when we built the model manually on the whole dataset! The\npipeline works.\n\nNow our final step, we build an automated ensemble of models.","4a6722e8":"This looks perfect! Very happy indeed to have replicated transformation using a pipeline instead of manual\ntransformations.\n\nOur final task is to use GridSearchCV to optimise our parameters from scratch i.e. not using previously found optimal\n parameters for the model. We do that next. This takes a while to run, so be patient!\n\nWe get our fresh datasets again.","ec282ed9":"We start by specifying some pipeline utility functions. Due to scikit-learn pipelines not supporting Dataframes we\nhave to write some functions to deal with conversion back to Dataframe. These ones are used to extract feature names\nfrom pipeline mangled results :) Hopefully scikit-learn fixes this soon, then we can remove these functions.","360a5edc":"It is clear that our model is accurate enough to capture the inversely proportionate relationship between MPG and\nweight. This is a positive outcome, as it means the model as applied to the validation dataset managed to capture the\n underlying signals in the data. We can therefore conclude that the model generalises well and that its accuracy is\n sufficiently high for this model to be used based on the features captured.\n\nNext we will do some actual over expected measurements to validate prediction accuracy for this regression model. We\nwill add this to the notebook during the next week!\n","011463d1":"<h2 style = \"font-family:verdana; background-color:#C5D6FA\"><center>Build Baseline Models<\/center><\/h2>\n<p><center style=\"color:#1F4BA7; font-family:cursive;\">Using manual hyperparameter tuning<\/center><\/p>","ee43912a":"We observe some issues with some of the variables. The horsepower feature is clearly numeric, but is reported as an\nobject. Let us see what is the matter:","863ec854":"Then we build the pipeline. We start by doing Cross-Validation on our MLP model as before. We use our baseline model\nand see if we can improve on it in the same way we did before, but now in an automated fashion.","1f8252dc":"This is indeed very similar to our previous results. Some fluctuation is allowed for w.r.t. different number formats\nused etc.\n\nWe now take a peak to see if our dataset built by the pipeline conforms to our previously built dataset. This is\nwhere we use our utility functions.","b5c4a5b6":"The learning curve for the optimised MLP model looks pretty good. The variance is reduced to within a fraction of the\n value of the training set. The standard deviation of the cross-validation score is also substantially reduced.\n\nOptimising alpha benefited the model considerably.\n\nNow we will string everything together and build an automated model pipeline.\n","24c7a2c8":"This utility function is used to plot learning curves.","ab494cf1":"Yes, 3 is the optimal value for alpha.\n\nWe will use these hyperparameters on our test set as it is double the size of the CV set and measure the accuracy.","b420b480":"Our modelling dataset looks as follows after feature selection:","d4a1712c":"Let us plot the values of the regularisation parameter against the accuracy measure i.e. MSE.","6ee28dbe":"Now we optimise network architecture by manually investigating optimal No. of nodes.\n\nWe use the <i>relu<\/i> activation to ensure we converge on a solution, as our dataset is small (approximately 400\nrecords) and hence more complex architectures can easily result in vanishing gradients. For the same reason we use\nCross-Validation with only 2 CV sets. We use MSE as an accuracy measure (scikit convention of using negative of the\nMSE is inverted for our purposes).","f2e82b80":"There are no obvious outliers. Again we note the few missing values in the horsepower variable. Horsepower has a\nbi-modal distribution, probably due to the segmentation of cars due to cylinders i.e. 4 cylinders vs 6 and 8. This\nholds true for displacement and to a lesser extent weight too. The majority of cars however fall in the smaller\ndisplacement category.\n\nWe will continue with analysis for now, and do a more in-depth EDA in a later notebook.","f3a49f60":"We start by getting a fresh dataset for the Pipeline.","3cb234b9":"<h2 style = \"font-family:verdana; background-color:#C5D6FA\"><center>Build pipeline<\/center><\/h2>\n<p><center style=\"color:#1F4BA7; font-family:cursive;\">Using automatic hyperparameter tuning -\nPipeline & GridSearchCV<\/center><\/p>","906a68fd":"Clearly we have some missing values indicates as strings. Let us fix this by converting these values to missing and\nthe rest of values to numeric.\n\nWe then reorganise the dataset and select columns we will use for the analysis.","1eb154bf":"An MSE of just over 9. Let us see if we can improve on this by optimising the architecture and regularisation\nparameters.\nWe now analyse the bias and variance in the model by plotting a learning curve.","4699fda7":"Well the automated analysis tool turned out to be really cool! The main observations can be summarised from the\n\"Warnings\" tab (sounds ominous!) as follows:\n\n- Car model has high cardinality - almost 75% of the data has different values. I would have expected this value to\nbe unique, as this field should represent each different unique car. We will need to revisit this later.\n- There is high correlation between several of the numeric feature variables. Given the nature of the variables this\nis expected. Displacement is highly correlated with both cylinders and weight.\n- Most variables have inverse correlation with mpg, which makes sense, given the nature of most variables i.e.\nweight, displacement, cylinders etc. Typically refers to size and strength of car which would be inversely correlated\n to mpg.\n- Acceleration, model year and origin are positively correlated, which again makes sense as newer and lighter cars\nwould have better fuel consumption (the correlation with acceleration is slightly surprising however as one would\nexpect heavier muscle cars to accelerate faster, but then again the majority of cars only had 4 cylinders...).\n\nWe will further investigate these observations in our manual analysis.\n\nWe continue by looking at missing values.","ad9ac870":"This looks OK for now!\n\nLet us look at the variable types.","999a5194":"There are missing values in the car model and horsepower fields.\n\nWe will impute values when we get to our model building phase.","3b0a687d":"Next we consider the categorical variables.","867e16d1":"Well this is encouraging. The results are very similar to the manual ones. This means we have a baseline and can\nstart optimising with a greater range of values.\n\nLet us now build a model on the whole training set using these parameters and see what the results look like.","75cddcdc":"We quantify the exact number of missing values in the data set:","d4c315b7":"For this analysis we use the Auto-mpg dataset found on the Kaggle Data Repository at the following location:\n\n<a href=https:\/\/www.kaggle.com\/uciml\/autompg-dataset>Auto-mpg dataset<\/a>\n\n\"The data concerns city-cycle fuel consumption in miles per gallon, to be predicted in terms of 3 multivalued\ndiscrete and 5 continuous attributes.\" (Quinlan, 1993)\n\n\"This dataset is a slightly modified version of the dataset provided in the StatLib library. In line with the use by\nRoss Quinlan (1993) in predicting the attribute \"mpg\", 8 of the original instances were removed because they had\nunknown values for the \"mpg\" attribute. The original dataset is available in the file \"auto-mpg.data-original\".\n\nThe Data Dictionary for this dataset is as follows:\n\n| Variable | Definition | Type |\n|----------|------------|-----|\n| mpg | Miles per Gallon | Continuous |\n| cylinders | No. of Cylinders  | Discrete |\n| displacement | Size of engine | Continuous |\n| horsepower | Power output | Continuous |\n| weight | Vehicle weight | Continuous |\n| acceleration | Vehicle acceleration | Continuous |\n| model_year | Vehicle model | Discrete |\n| origin | Vehicle country of manufacture | Discrete |\n| car_name | Vehicle make and model | Unique |\n\nThe objective of this notebook is to do some high level analyses, implement a simple MLP regressor to predict MLP and\n to compare this implementation to an ML pipeline implementation for the same model. We compare manual hyperparameter\n tuning (network architecture and regularisation) for the simple MLP model to using GridSearchCV in the pipeline.\n\nWe also investigate the use of Response Curve otherwise known as Partial Dependency Plots (PDPs) for investigation of\n the relationship between various features and the responses. The PDPs also indicate how well the model fits the data\n  from the perspective of different features, and is hence useful from two different perspectives.","4eae715f":"For this analysis we start by exploring the automatic EDA functionality in Pandas.\n\nThe notebook by Sercan Ye\u015fil\u00f6z pointed us in this direction:\n\n<a href=https:\/\/www.kaggle.com\/sercanyesiloz\/vehicle-fuel-consumption-prediction-xgboost>Vehicle Fuel Consumption\nPrediction (XGBoost)<\/a>","39c3dd55":"The scatter plot nicely illustrates what our automated EDA showed already:\n\n- Strong negative correlation between mpg and:\n    - displacement\n    - horsepower\n    - weight\n    - cylinders\n- Weak positive correlation between mpg and:\n    - acceleration\n    - model year\n\nWe can also observe that the cars with higher displacement, horsepower and weight all come from origin number 1,\nwhich we assume is the US. This is confirmed by the fact that nearly all the cars with 8 cylinders are from the same\norigin. From the density function we also observe that distribution of mpg for this origin is markedly lower than other\norigins.\n\nWe will now build our baseline MLP, and manually optimise hyperparameters i.e. network architecture and\nregularisation parameter.","d134349b":"#### Missing values","7fe01aff":"<h2 style = \"font-family:verdana; background-color:#C5D6FA\"><center>Exploration of data<\/center><\/h2>","e2fb6dd8":"These utility functions are used to build an ensemble pipeline which will be our final step in this pipeline adventure.","c2ab72fe":"The validation curve shows that regularisation has a clear benefit to both the training and validation datasets. The\nvalidation error plateaus at an alpha value of around 65, increases at around 20 and starts decreasing again at\nvalues less than 1.\n\nIt is appears that a value of around 3 for the alpha parameter results in the lowest score.\nWe confirm this now by extracting the parameter from the list of parameters:","238c4119":"We start by renaming columns to align with our data dictionary and then we One Hot Encode categorical variables.","9360f546":"The first obvious observation is how little variation there is in the accuracy of the training dataset. The plot is\nhowever deceptive as the range of values for MPG is 0 to 50. Matplotlib increased the range of the y-axis scale in\norder to display the full range of variation in the accuracy of the validation set (shaded green area).\n\nThe required level of granularity to understand the lower end of the MSE scale is therefore not available on this\nplot. Nonetheless, relatively speaking the model bias is low. The variance for 1 sample is low, but increases\nsubstantially when around 70 samples are used. For a completely unoptimised model this fluctuation in variance is\nexpected due to model overfitting.\n\nThe cross-validation accuracy decreases at around 180 samples and then plateaus.\n\nBearing in mind that this is an unoptimised model the overall variance reduction is encouraging. One would\nhowever need to use a Validation Curve to better determine whether further optimisation can assist to further\ndecrease variance.\n\nBased on the high variance (standard deviation) of the cross-validation score my guess would be that further\noptimisation would provide a more stable variance result. Let's see if that is the case!","cbf40a3c":"Now we scale our numeric variables. We use a Column Transformer to do the job (neat way of separating categorical and\n numeric variable transformation).","804ec5a9":"Our training set has the following dimensions:","9d18b587":"This is a good result! Ballpark same as our previous baseline result. We used CV of 3 here though. We can probably\ncome closer by tuning parameters but this is good enough for now.\n\nTo think all our transformations are magically correctly applied... Nice!\n\nNow let us build our baseline model on the full training set i.e. not the CV set.","cd0ad556":"This plot clearly shows that regularisation has a marked effect on the accuracy of the validation set.\n\nLet us look at a Validation Curve to better understand this effect.","d1f81e5a":"We now split the car make from the model name. We do this by using a vectorised implementation of the transform. In\nfuture we will create a transformer class for this, so that we can put this into a pipeline.","38fc3c55":"#### Distribution analysis","3536fb19":"There is good variation in all the categorical variables. It is however noticeable that more than 75% of data comes\nfrom a specific origin. We need to find out more about where the different cars are made. Looking at the names this\nis probably the US. The distribution of model years is fairly uniform. Most vehicles have 4 cylinders. This causes an\n imbalance with cars that have more cylinders e.g. 6 and 8. We need to keep this in mind.\n\nWe will perform a more in depth analysis later. We now look at pairwise relationships between variables.","b8a8484b":"![Fuel Saving, the Hoff way!](https:\/\/media1.tenor.com\/images\/09bb20a1e40457b7897ee99a13b6a8a9\/tenor.gif?itemid=7202134)\n\n<h1 style = \"font-family:verdana; background-color:#C5D6FA\"><center>I. Predicting Fuel Consumption - Pipelines Step by\nStep<\/center><\/h1>\n<p><center style=\"color:#1F4BA7; font-family:cursive;\">Exploration of the prediction of fuel consumption using\nMachine Learning - Let the Hoff lead the way!<\/center><\/p>","9cddf333":"The accuracy score on the optimised model reduced further to just over 6! Regularisation had a very positive effect on\nmodel accuracy.\nLet us look at the learning curve for the optimised model."}}