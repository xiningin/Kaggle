{"cell_type":{"9ffc0b4f":"code","0cf2f58d":"code","536b53b2":"code","f718b794":"code","64e2e4c2":"code","55099cd9":"code","39e9c7da":"code","2a071b25":"code","8b7c18c8":"code","2a910634":"code","a90846e1":"code","218dfccc":"code","be77ef78":"code","4a483e93":"markdown","cfdd1d7d":"markdown","6f71b53a":"markdown","a7b91a95":"markdown","78634da1":"markdown","ece1209e":"markdown","491adf3a":"markdown","e490d18a":"markdown","08da2267":"markdown","53ce02a2":"markdown","991baeaf":"markdown","44c440bf":"markdown"},"source":{"9ffc0b4f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.decomposition import PCA\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import roc_curve, auc, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import plot_roc_curve\n\nimport warnings\nwarnings.filterwarnings('ignore')","0cf2f58d":"path = '\/kaggle\/input\/ckdisease\/kidney_disease.csv'\ndf = pd.read_csv(path)\ndf.head()","536b53b2":"df.rename(columns={'classification':'class'},inplace=True)\ndf['class']=df['class'].replace(to_replace={'ckd':1.0,'ckd\\t':1.0,'notckd':0.0,'no':0.0})\ndf.drop('id',axis=1,inplace=True)","f718b794":"for i in ['rc','wc','pcv']:\n    df[i] = df[i].str.extract('(\\d+)').astype(float)\n    \nfor i in ['age','bp','sg','al','su','bgr','bu','sc','sod','pot','hemo','rc','wc','pcv']:\n    df[i].fillna(df[i].mean(),inplace=True)\n    \ndf = df.dropna(axis=1)","64e2e4c2":"X = df.iloc[:,:-1].values\ny = df.iloc[:,-1].values\n\nX_train, X_test, y_train, y_test = train_test_split(\n                                        X, y, test_size=0.33, random_state=42)","55099cd9":"model = {}\nmodel['svm'] = {'model' : svm.SVC(gamma='auto'), \n                'params':{'clf__C':[1,10,20],'clf__kernel':['rbf','linear']}}\n\nmodel['random_forest'] = {'model':RandomForestClassifier(),\n                          'params':{ 'clf__n_estimators':[1,5,10]}}\n\nlogistic_regression = LogisticRegression(solver='liblinear', multi_class='auto')\nmodel['logistic_regression'] = {'model': logistic_regression,\n                                'params':{'clf__C':[1,5,10]}}\n\nmodel['decision_tree'] = {'model': DecisionTreeClassifier(criterion='entropy'),\n                          'params':{ 'clf__min_samples_split' : [4,5,6,7,8,9,10]}}\n\nmodel['knn'] = {'model': KNeighborsClassifier( metric='minkowski',p=2 ),\n                'params':{'clf__n_neighbors' :list(range(1,31)),'clf__weights' : [\"uniform\", \"distance\"]}}\n\nmodel['naive_bayes'] = {'model': GaussianNB(),\n                        'params':{'clf__var_smoothing': np.logspace(0,-9, num=100)}}","39e9c7da":"models = {}\n\nfor k in list(model.keys()):\n    \n    model[k]['params']['pca__n_components'] =  [5, 15, 30, 45, 64]\n    \n    pipeline = Pipeline([\n        ('standard', StandardScaler()),\n        ('pca', PCA()),\n        ('clf', model[k]['model']),\n    ])\n\n    parameters = [\n        model[k]['params']\n    ]\n\n    clf = GridSearchCV(pipeline, parameters, cv=5, n_jobs=12, return_train_score=False, verbose=3)\n    clf.fit(X_train, y_train)\n    models[k] = {\n        'model': clf,\n        'best_score':clf.best_score_,\n        'best_params':clf.best_params_\n    }","2a071b25":"for k in models:\n    print(\"-\" * 70)\n    print('Model : ', k)\n    print(\"-\" * 70)\n    print()\n    preds = models[k]['model'].predict(X_test)\n    print(classification_report(preds, y_test))\n    print()","8b7c18c8":"def get_sl_features(X):\n    all_preds = []\n\n    temp = []\n    for k in list(models.keys()):\n        preds = models[k]['model'].predict(X)\n        temp.append(preds)\n        all_preds.append(temp)\n        temp = []\n\n    all_preds = np.array(all_preds).reshape(len(all_preds), len(X))\n    all_preds = np.swapaxes(all_preds,0,1)\n    \n    return all_preds","2a910634":"X_train_super = get_sl_features(X_train)\nclf = LogisticRegression(random_state=0).fit(X_train_super, y_train)","a90846e1":"X_test_super = get_sl_features(X_test)\npreds = clf.predict(X_test_super)","218dfccc":"print(classification_report(preds, y_test))","be77ef78":"fig, ax = plt.subplots(figsize=(12, 8))\nplot_confusion_matrix(clf, X_test_super, y_test, normalize='true', cmap=plt.cm.Greens, ax=ax)\nplt.show()","4a483e93":"<h1 id=\"training\" style=\"color:#a9dee2; background:#004449; border:0.5px dotted;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","cfdd1d7d":"## Confusion Matrix","6f71b53a":"## Classification Report","a7b91a95":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/1111\/2005\/082b5df90c0f8990d3beb9b68e394659\/dataset-cover.jpg\" \/>\n<\/div>","78634da1":"## Cleaning & Encoding","ece1209e":"## Split Training\/Testing Data","491adf3a":"<h1 id=\"dataset\" style=\"color:#a9dee2; background:#004449; border:0.5px dotted;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#datasets\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","e490d18a":"<h1 id=\"models\" style=\"color:#a9dee2; background:#004449; border:0.5px dotted;\"> \n    <center>Models\n        <a class=\"anchor-link\" href=\"#models\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","08da2267":"## Super Learner Features Stacking Prediction","53ce02a2":"<h1 id=\"analysis\" style=\"color:#a9dee2; background:#004449; border:0.5px dotted;\"> \n    <center>Analysis\n        <a class=\"anchor-link\" href=\"#analysis\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","991baeaf":"<h1 id=\"ensemble\" style=\"color:#a9dee2; background:#004449; border:0.5px dotted;\"> \n    <center>Ensemble\n        <a class=\"anchor-link\" href=\"#ensemble\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","44c440bf":"## Logistic Regression for Ensemble"}}