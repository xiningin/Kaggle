{"cell_type":{"385fa6a8":"code","b1fe7bde":"code","30c055e0":"code","849bfac1":"code","34aafe9f":"code","6c1e33e9":"code","d87256c0":"code","492a0b4b":"code","206b3c2a":"code","370233a0":"code","5bf3949e":"code","abdd3ba4":"code","493fda3f":"code","811322c7":"code","29a98757":"code","a25fcfe0":"code","562a3f89":"code","b79162b5":"code","15307e8a":"code","39409521":"code","526d78cc":"code","be516f55":"code","8af9a6f5":"code","06f6d243":"code","74fb3628":"code","a026ef9f":"code","30342ec9":"code","7c55f976":"code","8bc1055b":"markdown","a7666db7":"markdown","2153977f":"markdown","1aa5e972":"markdown","c906ac10":"markdown","f364c106":"markdown","bffc5d1f":"markdown","f9fc44b1":"markdown","0c61452c":"markdown","ace486b5":"markdown","b2dcf740":"markdown","edae29c4":"markdown","8903c66e":"markdown","8866cd95":"markdown","1778e56d":"markdown","6702ef79":"markdown"},"source":{"385fa6a8":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nimport keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LeakyReLU,PReLU,ELU\nfrom keras.layers import Dropout","b1fe7bde":"df = pd.read_csv('..\/input\/body-performance-data\/bodyPerformance.csv')","30c055e0":"df.head()","849bfac1":"# Find the shape of dataset\n\ndf.shape","34aafe9f":"# Find the datatype of each attribute\n\ndf.info()","6c1e33e9":"# Statistics for numeric attributes\n\ndf.describe()","d87256c0":"# Statistics for object attributes\n\ndf.describe(include=\"object\")","492a0b4b":"# Check for duplicates\n\nduplicate = df[df.duplicated()]\nduplicate","206b3c2a":"# Remove duplicate records except the first occurence\n\ndf.drop_duplicates(inplace=True)","370233a0":"# Again check if any duplicate records are left\n\nduplicate = df[df.duplicated()] \nduplicate","5bf3949e":"# Find the total number of missing values in each column\n\ndf.isna().sum()","abdd3ba4":"# Checking the shape again\n\ndf.shape","493fda3f":"plt.style.use('seaborn')","811322c7":"# PLot Correlation Matrix\n\ncorr = df.corr()\ncorr.style.background_gradient(cmap='PuBu').set_precision(2)","29a98757":"# Plotting all the attributes w.r.t its count\n\nfig, ax = plt.subplots(4, 3, figsize=(20, 30))\nfor variable, subplot in zip(df, ax.flatten()):\n    sns.histplot(df[variable], ax=subplot)\n    for label in subplot.get_xticklabels():\n        label.set_rotation(90)","a25fcfe0":"# Replace categorical variables with integers\n\ndf = df.replace({'M':0, 'F':1})\ndf = df.replace({'A':1,'B':2,'C':3,'D':4})","562a3f89":"X = df.iloc[:, :-1]    # Independent variable\ny = df.iloc[:, -1]     # Dependent variable\n\n# Encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\nencoded_Y = encoder.transform(y)\n# Convert integers to dummy variables (i.e. one hot encoded)\ndummy_y = np_utils.to_categorical(encoded_Y)","b79162b5":"dummy_y","15307e8a":"X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size=0.2, random_state=0)\n\nprint(\"X_train:\", X_train.shape)\nprint(\"X_test:\", X_test.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"y_test:\", y_test.shape)","39409521":"# Initialising the ANN\nclassifier = Sequential()\n\n# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units=20, kernel_initializer='he_uniform', activation='relu', input_dim = 11))\n\n# Adding the second hidden layer\nclassifier.add(Dense(units=35, kernel_initializer='he_uniform', activation='relu'))\n\n# Adding the third hidden layer\nclassifier.add(Dense(units=50, kernel_initializer='he_uniform', activation='relu'))\n\n# Adding the fourth hidden layer\nclassifier.add(Dense(units=65, kernel_initializer='he_uniform', activation='relu'))\nclassifier.add(Dropout(0.2))\n\n# Adding the fifth hidden layer\nclassifier.add(Dense(units=80, kernel_initializer='he_uniform', activation='relu'))\nclassifier.add(Dropout(0.2))\n\n# Adding the sixth hidden layer\nclassifier.add(Dense(units=55, kernel_initializer='he_uniform', activation='relu'))\n\n# Adding the seventh hidden layer\nclassifier.add(Dense(units=35, kernel_initializer='he_uniform', activation='relu'))\n\n# Adding the output layer\nclassifier.add(Dense(units=4, activation='softmax'))  # kernel_initializer='glorot_uniform', \n\n# Compiling the ANN\nclassifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","526d78cc":"classifier.summary()","be516f55":"# Fitting the ANN to the Training set\n\nmodel_history = classifier.fit(X_train, y_train, validation_split=0.33, batch_size=10, epochs=150)","8af9a6f5":"# List all data in history\nprint(model_history.history.keys())\n\n# Summarize history for accuracy\nplt.plot(model_history.history['accuracy'])\nplt.plot(model_history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","06f6d243":"# Summarize history for loss\n\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","74fb3628":"# Calculating score\n\nscore = classifier.evaluate(X_test, y_test)\nscore","a026ef9f":"# Predicting on test data\n\ny_pred = classifier.predict(X_test)\ny_pred = np.argmax(y_pred, axis=1)\ny_test = np.argmax(y_test, axis=1)","30342ec9":"# Accuracy\n\naccuracy_score(y_pred, y_test)","7c55f976":"# Confusion Matrix\n\ncm = confusion_matrix(y_test, y_pred)\n\nax= plt.subplot()\nsns.heatmap(cm, annot=True, ax=ax); #annot=True to annotate cells\n\n# labels, title and ticks\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\nax.set_title('Confusion Matrix')","8bc1055b":"### Split the dataset into training and testing set","a7666db7":"## Loading the dataset","2153977f":"<b> The dataset has 13,393 records and 12 attributes. <\/b>","1aa5e972":"### Attribute Description:-\n\n<ol>\n    <li>age - age of individual between 20~64<\/li>\n    <li>gender - gender of individual Male(M) or Female(F)<\/li>\n    <li>height_cm - height in cm<\/li>\n    <li>weight_kg - weight in kilograms<\/li>\n    <li>body fat_% - body fat in percentage<\/li>\n    <li>diastolic - diastolic blood pressure<\/li>\n    <li>systolic - systolic blood pressure<\/li>\n    <li>gripForce - <\/li>\n    <li>sit and bend forward_cm - <\/li>\n    <li>sit-ups counts - count of sit-ups<\/li>\n    <li>broad jump_cm - distance covered in broad jump in cm<\/li>\n    <li>class - A, B, C, D where A is best<\/li>\n<\/ol>","c906ac10":"<b>There are no missing records present.<\/b>","f364c106":"## Model","bffc5d1f":"<b>After removing duplicate values and checking for missing values there are 13,392 records in dataset.<\/b>","f9fc44b1":"## Exploratory Data Analysis","0c61452c":"<b> The dataset has 10 float and 2 object columns. <\/b>","ace486b5":"<b> Simple statistics like count, mean, min, max, etc is calculated for attributes having numeric datatype.<br>\nSome of the conclusions drawn from the above table are:<br> <\/b>\n<ol>\n    <li>The average age is 36 whereas the median age is 32.<\/li>\n    <li>The median height is 169.2 cm and the median weight is 67.4 kg.<\/li>\n    <li>The average diastolic pressure is 78.79 and average systolic pressure is 130.23.<\/li>\n    <li>The maximum number of sit-up count is 80.<\/li>\n    <li>The minimum distance in broad jump is 39.868 cm and maximum distance is 303 cm.<\/li>\n<\/ol>","b2dcf740":"<b> The dataset has one duplicate record. <\/b>","edae29c4":"<b>Observation:-<\/b>\n\n<ul>\n    <li>There is a negative correlation between age and sit-ups counts of -0.54 which means that young people can do more sit-ups than old people.<\/li>\n    <li>There is a negative correlation between age and broad jump_cm of -0.44 which means that young people can cover more distance in jump than old people.<\/li>\n    <li>There is a positive correlation of 0.73 between height_cm and weight_kg attributes and a negative correlation of -0.52 between height_cm and body fat_% which means that tall people have less body fat and short people have more.<\/li>\n    <li>height_cm and weight_kg have a positive correlation with gripForce, sit-ups counts and broad jump_cm.<\/li>\n    <li>body fat_% has a negative correlation with gripForce, sit-ups counts and broad jump_cm which means that people with less fat have high grip force, can do more sit-ups and cover a larger distance in broad jump.<\/li>\n    <li>diastolic and systolic have a positive correlation of 0.68 with each other.<\/li>\n<\/ul>","8903c66e":"<b>Hence, all duplicate records are removed.<\/b>","8866cd95":"### Building ANN","1778e56d":"<b> The statistics displayed for the attributes of 'object' datatype is different from the one displayed for numeric datatypes.<br>\nSome of the conclusions drawn from the above table are:<br> <\/b>\n<ol>\n    <li>There are 2 unique gender and 4 unique classes in the dataset.<\/li>\n    <li>The top gender is M(Male) occuring 8467 times.<\/li>\n    <li>The top class is C occuring 3349 times.<\/li>\n<\/ol>","6702ef79":"## Importing libraries"}}