{"cell_type":{"d921e231":"code","de15aa02":"code","2827d590":"code","ea8f765b":"code","3b6dad1c":"code","3ec68dc5":"code","1c17c5e3":"code","99313cfb":"code","f99f3b99":"code","eae5b9fb":"code","b35cdb28":"code","d1cff2ae":"code","d2315b53":"markdown","2b145c74":"markdown","ddf866fa":"markdown","733ebe96":"markdown","b7aef150":"markdown","38b58df5":"markdown","abfe3fd0":"markdown","437f9b0a":"markdown","18ea323c":"markdown","3656464f":"markdown","91fcc59a":"markdown"},"source":{"d921e231":"# First thing first. Lets install wikipedia module and import it.\n!pip install wikipedia\nimport wikipedia\nprint(\"\\n\\n\\nWikipedia is ready for use.\")","de15aa02":"# Its easy to find certain topics.\npage_capitals = wikipedia.page(\"List of national capitals\")\n# So what type of objects are we dealing with?\ntype(page_capitals)","2827d590":"# This should have the url we need.\npage_capitals.url","ea8f765b":"# now that we have the URL to work with, lets grab the contents.\npage_content = page_capitals.content\nprint(type(page_content))  # This tells us the object type.\nprint(page_capitals.title)  # This should bring up correct page title. ","3b6dad1c":"print(page_content)","3ec68dc5":"page_capitals.categories","1c17c5e3":"capture_the_flags = page_capitals.images\n# Lets check for any inconsistencies.\ncapture_the_flags","99313cfb":"print(f\"We have flags of total {len(capture_the_flags)} countries here.\")\n","f99f3b99":"!pip install wget\nimport wget\nprint(\"\\n\\n\\n\\nwget is ready for use\")","eae5b9fb":"# We will make a list, capture the names of the flags as well as download them in working directory.\nflags = []\n\n# Looping to get the first 5 flags only.\n\nfor i in capture_the_flags[:5]:\n    # Use wget download method to download specified image url.\n    image_filename = wget.download(i)\n\n    print('Image Successfully Downloaded: ', image_filename)\n    flags.append(image_filename)","b35cdb28":"flags","d1cff2ae":"# import os\n# os.remove(\".\/Flag_of_Afghanistan.svg\")  # file name","d2315b53":"We will search for a certain page and explore it first.","2b145c74":"Time to save the page contents into a variable.","ddf866fa":"To download the files, we will use the wget module which is extremely easy to use.","733ebe96":"Good thing is, this [link](https:\/\/wikipedia.readthedocs.io\/en\/latest\/code.html#indices-and-tables) gives us all the information we need to use wikipedia module.\nLet's see which url our module was able to generate. We would also navigate there manually.","b7aef150":"We can pass .images to capture all the image urls and possibly download the flags? That would be nice. :)","38b58df5":"#### In case you are like me and since 'wget' automatically doesn't overwrite existing file\/file-name, use this code to manually delete them (in my case kaggle) or simply delete everything from your local directoy if you have direct access to. Or just create a simple function to check for existing file and tell wget not to skip that. Possibilities are unlimited. ","abfe3fd0":"Well that wasn't extremely useful. What about the tables? Using wikipedia.html() will definitely work (and pull everything) but will return unformatted text. This is where [BeautifulSoup](https:\/\/pypi.org\/project\/beautifulsoup4\/) comes in (not covered in this article). But let's keep on exploring.","437f9b0a":"### **A snippet on how to use wikipedia resources on Jupyter Notebook**","18ea323c":"Lets check the entire page_content.","3656464f":"### Success!!!","91fcc59a":"### Have a great day :)"}}