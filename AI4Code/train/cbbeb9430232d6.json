{"cell_type":{"fc3c1f87":"code","264b931d":"code","d008d635":"code","6e76867f":"code","f5f0becf":"code","29435360":"code","bfab1da0":"code","4d327940":"code","4d2211e9":"code","e033213d":"code","b1c6f1e4":"code","cf779889":"code","ed9ed2f8":"code","dfb5aba5":"code","0cd804a3":"code","3df5af9a":"code","ab1de327":"code","2146ef53":"code","054735e3":"code","2e9f05e5":"code","8e29398e":"code","d5b77669":"code","774ac033":"code","403afc9d":"code","5540c8f8":"code","003c31f8":"code","b6af51b1":"markdown","c704f357":"markdown","3098db64":"markdown","323c6fff":"markdown","daf0be9e":"markdown","acd4d981":"markdown","6abf44ac":"markdown","b84f33c8":"markdown","30582ece":"markdown","c978d17b":"markdown","c2f9adda":"markdown","47a8b8cd":"markdown","7f719e4e":"markdown","7c0ac15d":"markdown","1df9e74b":"markdown"},"source":{"fc3c1f87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\n# set seed for reproducibility\nnp.random.seed(0)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","264b931d":"# read the data\ndf_train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ndf_test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\n\ndf_train.shape, df_test.shape","d008d635":"# inspect the train dataset\ndf_train.head()","6e76867f":"# split the features X and the target y\nX = df_train.drop(columns='label')\ny = df_train['label']\n\n# inspect the shape of the features X & the target y\nX.shape, y.shape","f5f0becf":"# split the dataset \nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# inpect the shapes\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","29435360":"# view the first number\nplt.imshow(X_train.to_numpy()[0].reshape(28, 28))  # (rows, columns)\n# the label of the first number\nplt.title(f\"Digit: {y_train[0]}\")\nplt.show() ","bfab1da0":"def visualize_input(img, ax):\n    ax.imshow(img, cmap='gray')\n    width, height = img.shape\n    thresh = img.max()\/2.5\n    for x in range(width):\n        for y in range(height):\n            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n                        horizontalalignment='center',\n                        verticalalignment='center',\n                        color='white' if img[x][y]<thresh else 'black')\n\nfig = plt.figure(figsize = (12,12)) \nax = fig.add_subplot(111)\nvisualize_input(X_train.to_numpy()[0].reshape(28, 28), ax)  # pass image (28, 28)","4d327940":"# convert the date frame to numpay array to feed it to the model\n# convert the train dataset\nX_train = X_train.to_numpy()\ny_train = y_train.to_numpy()\n\n# convert the validation dataset\nX_val = X_val.to_numpy()\ny_val = y_val.to_numpy()","4d2211e9":"# plot the pixels distributions\nplt.hist(X_train[0].reshape(784))\nplt.title(\"Pixel Values Distribution\")\nplt.show()","e033213d":"# Scaling the features' pixels\nX_train = X_train \/ 255 # over number of pixels\nX_val = X_val \/ 255     # over number of pixels","b1c6f1e4":"# plot the pixels distributions after Scaling\nplt.hist(X_train[0].reshape(784))\nplt.title(\"Pixel Values Distribution after Scaling\")\nplt.show()","cf779889":"def visualize_input(img, ax):\n    ax.imshow(img, cmap='gray')\n    width, height = img.shape\n    thresh = img.max()\/2.5\n    for x in range(width):\n        for y in range(height):\n            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n                        horizontalalignment='center',\n                        verticalalignment='center',\n                        color='white' if img[x][y]<thresh else 'black')\n\nfig = plt.figure(figsize = (12,12)) \nax = fig.add_subplot(111)\nvisualize_input(X_train[0].reshape(28, 28), ax)  # pass image (28, 28)","ed9ed2f8":"np.unique(y_train, return_counts=True)","dfb5aba5":"# Encoding the target\ny_train = keras.utils.to_categorical(y_train, num_classes=10)\ny_val = keras.utils.to_categorical(y_val, num_classes=10)","0cd804a3":"# inspect the input shape of the network to feed it to the model\n[X_train.shape[1]]","3df5af9a":"# build the model\nmodel = keras.Sequential([\n   \n    # The model\n    layers.Dense(516, activation='relu'),\n    layers.Dropout(0.7),\n    layers.Dense(1024, activation='relu'),\n    layers.Dropout(0.1),\n    layers.Dense(10, activation='softmax')    \n])","ab1de327":"# compiling the sequential model\nmodel.compile(optimizer='Adam',\n              loss='categorical_crossentropy',\n              metrics=['categorical_accuracy'])","2146ef53":"# initiate early stopping to prevent overfitting\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=4,\n    min_delta=0.001,\n    restore_best_weights=True,\n)","054735e3":"# train the model\ntraining = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    batch_size=128,\n    epochs=25,\n    callbacks=[early_stopping],\n    verbose=0\n)","2e9f05e5":"# see the model structure\nmodel.summary()","8e29398e":"# evaluate the model\nloss_and_metrics = model.evaluate(X_val, y_val, verbose=2)\n\nprint(\"Val Loss\", loss_and_metrics[0])\nprint(\"Val Accuracy\", loss_and_metrics[1])","d5b77669":"# plotting the metrics\nfig = plt.figure(figsize=(8,6))\nplt.subplot(2,1,1)\nplt.plot(training.history['categorical_accuracy'])\nplt.plot(training.history['val_categorical_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='lower right')\n\nplt.subplot(2,1,2)\nplt.plot(training.history['loss'])\nplt.plot(training.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper right')\n\nplt.tight_layout()\nplt.show()","774ac033":"# predect the labels of the test dataset, and return the exact number not an array (decode it)\ny_pred = np.argmax(model.predict(df_test.to_numpy()), axis=-1)","403afc9d":"# inspect the first number in the test dataset predicted by the model\nplt.imshow(df_test.to_numpy()[0].reshape(28, 28))\n# the label of the first number\nplt.title(f\"Digit: {y_pred[0]}\")\nplt.show()","5540c8f8":"# Generate Submission File \nsubmission = pd.DataFrame({'ImageId':pd.Series(list(range(1, len(y_pred)+1))),\n                                   'Label':pd.Series(y_pred)})\n# save the df\nsubmission.to_csv(\"Submission.csv\", index=False)","003c31f8":"# preview the dubmission df\nsubmission","b6af51b1":"### One-hot Encoding","c704f357":"## Predicting the target labels","3098db64":"## Submitting the predictions\n","323c6fff":"Generally the bigger the batch, the more stable our stochastic gradient descent updates will be. But beware of GPU memory limitations! We're going for a batch size of 128 and 25 epochs.","daf0be9e":"**For any suggestions, please let me know in the comments!**","acd4d981":"to plot the numbers we need to convert the first row in the dataframe to a numpy array, & then reshape it by (28,28) to look like an image.","6abf44ac":"Let's encode our categories - digits from 0 to 9 - using one-hot encoding. The result is a vector with a length equal to the number of categories. The vector is all zeroes except in the position for the respective category. Thus a `'5'` will be represented by `[0,0,0,0,1,0,0,0,0]`.\n\n![human_transpose.jpg](attachment:7eccad16-57f2-4881-812b-50c3df102c32.jpg)","b84f33c8":"To get a handle on our training progress we also graph the learning curve for our model looking at the loss and accuracy.","30582ece":"the pixel values range from 0 to 255: the background majority close to 0, and those close to 255 representing the digit.\n\nScaling the input data helps to speed up the training. Also, it reduces the chance of getting stuck in local optima, since we're using stochastic gradient descent to find the optimal weights for the network.\n\nNeural network activations generally like their inputs to be Scaled. Scalling inputs to nodes in a network helps prevent the so-called vanishing (and exploding) gradients.\n\nLet's reshape our inputs to a single vector vector and scale the pixel values to lie between 0 and 1.","c978d17b":"### Scale the pixel values","c2f9adda":"## Pre-prossesing","47a8b8cd":"## Modeling","7f719e4e":"## Reading the dataset","7c0ac15d":"### View an Image in More Detail","1df9e74b":"Before training a model in Keras, we need to specify an *optimizer* to perform the gradient descent, a *loss function* to be minimized, and (optionally) any *performance metrics*. The optimization algorithm we'll use for this course is called [\"Adam\"](https:\/\/keras.io\/api\/optimizers\/adam\/), which generally performs well regardless of what kind of problem you're trying to solve."}}