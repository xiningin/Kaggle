{"cell_type":{"c026fc66":"code","f5e1a2a8":"code","4d416b64":"code","d6bb8d65":"code","b53df73b":"code","a990b705":"code","896739d4":"code","d7b6d41a":"code","b10f3af2":"code","cda27222":"code","25e31ec2":"code","c7d39cdb":"code","0575b70b":"code","2deaa63d":"code","8e3f8b68":"code","56b17afb":"code","8aa7a96d":"code","55bf4431":"code","bea6651b":"code","7366137e":"code","939c313f":"code","dd212349":"code","a4b8a6f0":"code","a9fab8a2":"code","357ee3ba":"code","88a6e3f2":"code","a6cc06e0":"code","21c29fa2":"code","00377bf7":"code","fcf7909e":"code","9e2575cc":"code","a9c02afd":"code","aa43ba95":"code","3c38e2c7":"code","45759f76":"code","1fa6798e":"code","79b753a7":"code","314e9d09":"code","d0271356":"code","320e4be4":"markdown","37bbd1a0":"markdown","e95311ba":"markdown","65e0e4bf":"markdown","862cc883":"markdown","597098f0":"markdown","24a0db91":"markdown","a36300e7":"markdown","df8701eb":"markdown","94c251a2":"markdown","d542fff6":"markdown","d340ef4e":"markdown","1d29ef18":"markdown","2dc0305a":"markdown","902a0bdf":"markdown","72e38403":"markdown","4918c681":"markdown","fd9df6a7":"markdown","d60658a6":"markdown","d2ad6804":"markdown","00f4b57a":"markdown","54e48c16":"markdown"},"source":{"c026fc66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5e1a2a8":"# import libraries\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport scipy.cluster.hierarchy as hcluster\nfrom sklearn.cluster import AgglomerativeClustering","4d416b64":"# path \ndata_dict_path = '..\/input\/unsupervised-learning-on-country-data\/data-dictionary.csv'\ncountry_path = '..\/input\/unsupervised-learning-on-country-data\/Country-data.csv'","d6bb8d65":"# read csv files\ndict_df = pd.read_csv(data_dict_path)\ndf = pd.read_csv(country_path)","b53df73b":"# first few rows of dictionary dataset\ndict_df.head()","a990b705":"# first few rows of countrty dataset\ndf.head()","896739d4":"# shape of dataset\ndf.shape","d7b6d41a":"#some basic info\ndf.info()\nprint(50*'-')\ndict_df.info()","b10f3af2":"#some basic statistical data\ndf.describe()","cda27222":"#null value \ndf.isnull().sum()","25e31ec2":"#null value\ndict_df.isnull().sum()","c7d39cdb":"#number of unique countries\ndf['country'].nunique()","0575b70b":"#drop country column\ndata=df.drop(['country'],axis=1)","2deaa63d":"data.head()","8e3f8b68":"#correlation \ncorr_matrix=data.corr()\nsns.heatmap(corr_matrix,annot=True)","56b17afb":"#box plot\nfig, ax = plt.subplots(3, 3, figsize=(15, 15))\nbp=sns.boxplot(y=df.child_mort,ax=ax[0, 0])\nax[0, 0].set_title('Child Mortality Rate')\nbp=sns.boxplot(y=df.health,ax=ax[0, 1])\nax[0, 1].set_title('Health')\nbp=sns.boxplot(y=df.income,ax=ax[0, 2])\nax[0,2].set_title('Income per Person')\nbp=sns.boxplot(y=df.inflation,ax=ax[1, 0])\nax[1,0].set_title('Inflation')\nbp=sns.boxplot(y=df.imports,ax=ax[1,1])\nax[1, 1].set_title('Imports')\ns=sns.boxplot(y=df.life_expec,ax=ax[1, 2])\nax[1,2].set_title('Life Expectancy')\ns=sns.boxplot(y=df.total_fer,ax=ax[2,0])\nax[2,0].set_title('Total Fertility')\ns=sns.boxplot(y=df.gdpp,ax=ax[2, 1])\nax[2,1].set_title('GDP per Capita')\ns=sns.boxplot(y=df.exports,ax=ax[2,2])\nax[2,2].set_title('Exports')\nplt.show()","8aa7a96d":"sns.pairplot(df)","55bf4431":"#scaling data\nscaling=StandardScaler()\nscaled=scaling.fit_transform(data)","bea6651b":"scaled_df=pd.DataFrame(scaled,columns=data.columns)\n\n# princt scaled dataset\nscaled_df.head()","7366137e":"# plot elbow curve\n\na=[]\nK=range(1,10)\nfor i in K:\n    kmean=KMeans(n_clusters=i)\n    kmean.fit(data)\n    a.append(kmean.inertia_)\n    \nplt.plot(K,a,marker='o')\nplt.title('Elbow Method',fontsize=15)\nplt.xlabel('Number of clusters',fontsize=15)\nplt.ylabel('Sum of Squared distance',fontsize=15)\nplt.show()","939c313f":"#chosing no. of clusters as 3 and refitting kmeans model\nkmeans = KMeans(n_clusters = 3,random_state = 111)\nkmeans.fit(scaled_df)","dd212349":"#count number of records in every cluster\npd.Series(kmeans.labels_).value_counts()","a4b8a6f0":"#calculate how good our model is\n#calculate Silhouette Coefficient for K=3\n\nmetrics.silhouette_score(scaled_df, kmeans.labels_)","a9fab8a2":"#predicting values\ncluster_labels = kmeans.fit_predict(scaled_df)","357ee3ba":"preds = kmeans.labels_\nkmeans_df = pd.DataFrame(df)\nkmeans_df['KMeans_Clusters'] = preds\nkmeans_df.head(10)","88a6e3f2":"#save a kmeans file\nkmeans_df.to_csv('kmeans_result.csv',index=False)","a6cc06e0":"#visulization of clusters child mortality vs gdpp\nsns.scatterplot(kmeans_df['child_mort'],kmeans_df['gdpp'],hue='KMeans_Clusters',data=kmeans_df) \nplt.title(\"Child Mortality vs gdpp\", fontsize=15)\nplt.xlabel(\"Child Mortality\", fontsize=12)\nplt.ylabel(\"gdpp\", fontsize=12)\nplt.show()","21c29fa2":"#visulization of clusters inflation vs gdpp\nsns.scatterplot(kmeans_df['inflation'],kmeans_df['gdpp'],hue='KMeans_Clusters',data=kmeans_df) \nplt.title(\"inflation vs gdpp\", fontsize=15)\nplt.xlabel(\"inflation\", fontsize=12)\nplt.ylabel(\"gdpp\", fontsize=12)\nplt.show()","00377bf7":"#find number of developed country,developing country,under-developed country\nunder_developing=kmeans_df[kmeans_df['KMeans_Clusters']==0]['country']\ndeveloping=kmeans_df[kmeans_df['KMeans_Clusters']==1]['country']\ndeveloped=kmeans_df[kmeans_df['KMeans_Clusters']==2]['country']\n\nprint(\"Number of deveoped countries\",len(under_developing))\nprint(\"Number of developing countries\",len(developing))\nprint(\"Number of under-developing countries\",len(developed))","fcf7909e":"#list of developed countries\nlist(developed)","9e2575cc":"#list of developing countries\nlist(developing)","a9c02afd":"for i in developing:\n    if i == 'India':\n        print('Yes', i , 'is present in developing countries list')     ","aa43ba95":"#list of under-developing countries\nlist(under_developing)","3c38e2c7":"#plotting dendogram\nplt.figure(figsize=(50, 12))\ndend=hcluster.dendrogram(hcluster.linkage(scaled_df,method='ward'))","45759f76":"# Getting labels from Agglomearative Hierarchical clustering\nhcluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  \nhcluster.fit_predict(scaled_df)\nhcluster_label = hcluster.labels_","1fa6798e":"hcluster_df = pd.DataFrame(df)\n#adding hcluster labels in hcluster_df\nhcluster_df['hcluster'] = hcluster_label\n#first few rows of hcluster_df\nhcluster_df.head()","79b753a7":"#visulazing hcluster results\n#child mortality vs exports \nsns.scatterplot(hcluster_df['child_mort'],hcluster_df['gdpp'],hue='hcluster',data=hcluster_df)\nplt.title(\"Child Mortality vs gdpp\", fontsize=15)\nplt.xlabel(\"Child Mortality\", fontsize=12)\nplt.ylabel(\"gdpp\", fontsize=12)\nplt.show()","314e9d09":"#visulazing hcluster results\nsns.scatterplot(hcluster_df['inflation'],hcluster_df['gdpp'],hue='hcluster',data=hcluster_df)\nplt.title(\"Inflation vs gdpp\", fontsize=15)\nplt.xlabel(\"Inflation\", fontsize=12)\nplt.ylabel(\"gdpp\", fontsize=12)\nplt.show()","d0271356":"#find number of developed country,developing country,under-developed country\ndeveloped=hcluster_df[hcluster_df['hcluster']==0]['country']\ndeveloping=hcluster_df[hcluster_df['hcluster']==1]['country']\nunder_developing=hcluster_df[hcluster_df['hcluster']==2]['country']\n\nprint(\"Number of deveoped countries\",len(developed))\nprint(\"Number of developing countries\",len(developing))\nprint(\"Number of under-developing countries\",len(under_developing))","320e4be4":"As we can see the elbow or a knee like bend is at 3.So choosing 3 as a number of clusters ","37bbd1a0":"Now we are going to check how our model is,using **Silhouette Coefficient** ","e95311ba":"# Hierarchical Clustering","65e0e4bf":"Our dataset is not scaled some values are much bigger than others,if we will not scale our data our model will not going to perform well.So now we are are going to scale our data for this we are going to use a StandardScaler library<br>\n**StandardScaler** transform the data such the the mean will be 0 and variance will be 1.\n\n**Note:-** Scaling data is necessary just for the algorithms which is based on the distance like K-means clustering and Hierarchical clustering","862cc883":"From above dendogram we can take minimum no of clusters as 2 and maximum number of cluster as 5.As we can see fro dendogram 3 in the the right no of clusters ,so we are going to take 3 no of clusters\n \n","597098f0":"From above we can conclude that:-<br>\n0 = developed country<br>\n1 = developing country<br>\n2 = under-developing country","24a0db91":"# K-Means Clustering","a36300e7":"As we are going to use Unsupervised learning technique we don't need the country column here.So we are going to drop it","df8701eb":"# Visualization hcluster","94c251a2":"# Prediction","d542fff6":"# Scaling data","d340ef4e":"In in this notebook I will going to cluster the countries by using unsupervised learning.I am going to use two techniques here first one is **K-means clustering** and the second one is **Hierarchical clustering**\n\nThe motive of clustering the countries here is to help international NGOs to decide how much money they need to spend on different countries for their development\n\nIn last I am going to make a list of under-developing,developing and developed countries by doing some analysis","1d29ef18":"**Let's check that is India is present in developing countries list**","2dc0305a":"From above we can conclude that:<br>\n\n1. gdpp and income,imports and exports,child_mort and total_fert are highly positive correlated<br>\n2. whereas life_expec and child_mort are highly negative correlated","902a0bdf":"# Visualization of clusters","72e38403":"From above box-plots we can see that their are so many outliers in our dataset.Most of the outliers are in income per person,GDP per captia and Exports.Now we can remove the outliers but we are not going to do it as our dataset is very small (167 rows only)","4918c681":"From above two clusters graph we can conclude that<br>\n1. Country having high child-mortality, low GDP per catia and low inflation(The measurement of the annual growth rate of the Total GDP) is a **under-developing country**\n2. Country having low child-mortality, high gdpp and high infaltion is the **developed country**\n\n\n**So here we conclude that**<br>\n0 = **under-developing country**<br>\n1 = **developing country**<br>\n2 = **developed country**<br>","fd9df6a7":"Let's see the number of unique countries present in our dataset","d60658a6":"Also called Hierarchical cluster analysis or HCA is an unsupervised clustering algorithm which involves creating clusters that have predominant ordering from top to bottom.\nThis clustering technique is divided into two types:\n1. Agglomerative Hierarchical Clustering\n2. Divisive Hierarchical Clustering","d2ad6804":"Agglomerative Hierarchical Clustering<br>\nThe Agglomerative Hierarchical Clustering is the most common type of hierarchical clustering used to group objects in clusters based on their similarity. It\u2019s also known as AGNES (Agglomerative Nesting). It's a \u201cbottom-up\u201d approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.\n\nDendogram<br>\nA Dendrogram is a type of tree diagram showing hierarchical relationships between different sets of data.","00f4b57a":"**If you like the notebook then don't forget to upvote it**","54e48c16":"K-means Clustering is the most popular unsupervised machine learning algorithm.It is a centroid-based or distance-based algorithm.The woking of the alorithms is as follows:<br>\n1. First we initialize k points called means randomly\n2. Then we categorize each item to its closest mean and we update the mean's coordinates,which are the averages of the items     categorized in the mean so far\n3. We repeat the process for a given number of iteartions and at the end,we have our clusters\n\nTo decide how many number of clusters consider we are going to use a most popular elbow method"}}