{"cell_type":{"b26a960a":"code","2336309f":"code","e2e8128a":"code","30be21e6":"code","246d061a":"code","e82e5582":"code","ae12b9f2":"code","03bba0de":"code","97374371":"code","46cc1bd5":"code","f6acd5cd":"code","9a3c9736":"code","147b13a0":"code","2826c662":"code","835ef97c":"code","0b60cb41":"code","e52dffed":"code","422d71b5":"code","3ae84f13":"code","e236b0ec":"code","8c0b27bf":"code","b771b1dc":"code","2713ea4c":"code","5d3e610e":"code","d381f85b":"code","933a27ea":"code","26ec1c8e":"code","0cc70f50":"code","14efc7b8":"code","9266406c":"code","7fd5497f":"code","ffa42d0c":"code","2b00a1c6":"code","f8150b34":"code","a3db213e":"code","8f6047f2":"code","2bb51d4b":"code","809f4ee3":"code","e5014114":"code","9cb7eeb7":"code","727cd186":"code","fae6fe12":"code","b896e130":"code","c2eb56ed":"code","b82de79e":"markdown","4b8869d4":"markdown","efc64163":"markdown","bc841554":"markdown","a8d882d3":"markdown","17b8fb05":"markdown","7a965eba":"markdown"},"source":{"b26a960a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.tree import plot_tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score,KFold,StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler,StandardScaler\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC,SVR\nfrom sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n# importing ensembling algorithms\nfrom sklearn.ensemble import RandomForestRegressor,RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,BaggingClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor,RadiusNeighborsClassifier\nfrom sklearn.decomposition import PCA,TruncatedSVD","2336309f":"data=pd.read_csv('..\/input\/top50spotify2019\/top50.csv',encoding='ISO-8859-1')\ndata.head()","e2e8128a":"data.reset_index(drop=True)","30be21e6":"print(data.info())","246d061a":"sns.heatmap(data.isnull())","e82e5582":"data.isnull().sum()","ae12b9f2":"# finding the number of songs of each genre\ndata.groupby(data['Genre']).size()","03bba0de":"# the columns names are not well represented so we'll rename our columns\ndata.rename(columns={'Unnamed: 0':'sl.No','Track.Name':'Track_name','Artist.Name':'Artist_name','Beats.Per.Minute':'Beats_per_minute','Loudness..dB..':'Loudness(db)','Valence.':'Valence','Length.':'Length','Acousticness..':'Acousticness','Speechiness.':'Speechiness'},inplace=True)\ndata.head()","97374371":"# finding the number of songs sung by each Artist\ndata.groupby(data['Artist_name']).size()","46cc1bd5":"# Artist with most popular track\ndata['Artist_name'][data['Popularity']==data['Popularity'].max()]","f6acd5cd":"# plotting between Genre and count\nsns.countplot(data=data,y='Genre')","9a3c9736":"# popularity of each and every track_name\nplt.pie(np.array(data['Popularity']),labels=np.array(data.Track_name),radius=10,autopct='%0.1f%%',shadow=True,startangle=90)\nplt.show()","147b13a0":"# Danceability of each and every track_name\nplt.pie(np.array(data['Danceability']),labels=np.array(data.Track_name),radius=10,autopct='%0.1f%%',shadow=True,startangle=90,explode=[0,0.5,0,0,1.0,0,0.5,0,0.5,0,0,0,0.5,0.5,0,0,1.0,0.7,0,0,0.8,0,0,1.5,0.5,0,1.0,0,0.5,0,0,1.0,0,0,0,1.0,1.0,1.0,2.0,0,0,0,0,0,0,1.0,0.5,0,0,0.5])\nplt.show()","2826c662":"# representing the data in a pairplot()\nsns.pairplot(data)","835ef97c":"# countplot representing total no. of songs by a group of artists\nsns.countplot(data=data,y=data['Artist_name'].value_counts())","0b60cb41":"fig=plt.figure(figsize=(10,30))\nsns.barplot(data=data,y='Artist_name',x=data['Artist_name'].nunique())","e52dffed":"#barplot of each numerical column in the data\nfig=plt.figure(figsize=(20,20))\nax=plt.gca()\ndata.plot(kind='hist',subplots=True,ax=ax)\nplt.show()","422d71b5":"fig=plt.figure(figsize=(20,20))\nax=plt.gca()\ndata.plot(kind='kde',subplots=True,ax=ax)\nplt.show()","3ae84f13":"# finding correlation of the data\nfig=plt.figure(figsize=(10,10))\nsns.heatmap(data.corr())","e236b0ec":"fig=plt.figure(figsize=(20,20))\nax=plt.gca()\ndata.plot(kind='box',subplots=True,ax=ax)\nplt.show()","8c0b27bf":"# we will check the popularity based on danceability,acousticness and energy \nfig=plt.figure(figsize=(10,10))\nplt.subplot(3,1,1)\nplt.xlabel('popularity')\nplt.ylabel('energy')\nplt.title('popularity vs energy')\nsns.barplot(data=data,y='Energy',x='Popularity')\nplt.subplot(3,1,2)\nplt.xlabel('popularity')\nplt.ylabel('danceability')\nplt.title('popularity vs danceability')\nsns.barplot(data=data,y='Danceability',x='Popularity')\nplt.subplot(3,1,3)\nplt.xlabel('popularity')\nplt.ylabel('acoustics')\nplt.title('popularity vs acousticness')\nsns.barplot(data=data,y='Acousticness',x='Popularity')\n\n","b771b1dc":"# relation between energy and loudness(db)\nfig=plt.figure(figsize=(10,10))\nsns.regplot(data=data,x='Energy',y='Loudness(db)')","2713ea4c":"# relation between acousticness and loudness\nfig=plt.figure(figsize=(10,10))\nsns.jointplot(data=data,x='Acousticness',y='Loudness(db)',kind='kde',color='black')","5d3e610e":"fig=plt.figure(figsize=(15,15))\nsns.countplot(data=data,y='Popularity',hue='Genre')\nplt.legend(loc=\"upper right\")","d381f85b":"data.columns","933a27ea":"# applying some machine learning modelling algorithms\nlin_reg=LinearRegression()\nX=data.loc[:,['Beats_per_minute',\n       'Energy', 'Danceability', 'Loudness(db)', 'Liveness', 'Valence',\n       'Length', 'Acousticness', 'Speechiness']]\ny=data.loc[:,['Popularity']]\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.2)\nlin_reg.fit(X_train,y_train)","26ec1c8e":"y_pred=lin_reg.predict(X_test)\ny_pred,y_test","0cc70f50":"print(lin_reg.score(X_train,y_train))\nlin_reg.score(X_test,y_pred)","14efc7b8":"plt.subplot(2,2,1)\nsns.kdeplot(X_train,y_train)\nplt.subplot(2,2,2)\nsns.kdeplot(X_test,y_pred)\nplt.subplot(2,2,3)\nplt.scatter(X_train.iloc[:,0:1],y_train)\nplt.plot(X_test.iloc[:,0:1],y_pred)","9266406c":"# comparing accuracy scores for LinearRegression and Lasso and Ridge\nlin_accuracy=lin_reg.score(X_test,y_pred)\nridge=Ridge().fit(X_train,y_train)\nridge_accuracy=ridge.score(X_test,ridge.predict(X_test))\nlasso=Lasso().fit(X_train,y_train)\nlasso_accuracy=lasso.score(X_test,lasso.predict(X_test))\nprint(lin_accuracy)\nprint(ridge_accuracy)\nlasso_accuracy","7fd5497f":"# predicting the genre by taking the numerical values present in the dataset\n# - we will use KNeighborsClassifier Algorithm\nX=data.loc[:,['Beats_per_minute',\n       'Energy', 'Danceability', 'Loudness(db)', 'Liveness', 'Valence',\n       'Length', 'Acousticness', 'Speechiness','Popularity']]\ny=data.loc[:,['Genre']]\nknn_clf=KNeighborsClassifier(n_neighbors=5)\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.2)\nknn_clf.fit(X_train,y_train)\nprint(knn_clf.score(X_train,y_train))\nknn_clf.score(X_test,knn_clf.predict(X_test))","ffa42d0c":"n_range=range(1,20)\naccuracy=[]\nfor n in n_range:\n    knn_clf=KNeighborsClassifier(n_neighbors=n)\n    knn_clf.fit(X_train,y_train)\n    accuracy.append(knn_clf.score(X_test,knn_clf.predict(X_test)))\nplt.scatter(n_range,accuracy)","2b00a1c6":"print(knn_clf.predict(X_test))","f8150b34":"gnb=GaussianNB()\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.2)\nprint(gnb.fit(X_train,y_train))\nprint(gnb.score(X_train,y_train))\ngnb.score(X_test,gnb.predict(X_test))","a3db213e":"gnb.predict(X_test)","8f6047f2":"# we will have to first import PCA from decomposition package\nfrom sklearn.decomposition import PCA\npca=PCA(n_components=5)\npca","2bb51d4b":"# also we will have to scale the data into standard scaler\nscaler=StandardScaler()\nscaled_X=scaler.fit_transform(X)\npca_scaled=pca.fit_transform(scaled_X)\npca_scaled","809f4ee3":"X_train,X_test,y_train,y_test=train_test_split(pca_scaled,y,random_state=0,test_size=0.2)\nprint(gnb.fit(X_train,y_train))\nprint(gnb.score(X_train,y_train))\ngnb.score(X_test,gnb.predict(X_test))","e5014114":"# we will find the correlation of the PCA scaled values\nprint(pd.DataFrame(pca_scaled).corr())\nsns.heatmap(pd.DataFrame(pca_scaled).corr())","9cb7eeb7":"sns.pairplot(pd.DataFrame(pca_scaled))","727cd186":"sns.pairplot(pd.DataFrame(pca_scaled),corner=True)","fae6fe12":"sns.pairplot(pd.DataFrame(pca_scaled),kind='kde')","b896e130":"dec_clf=DecisionTreeClassifier(criterion='entropy')\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.2)\nprint(dec_clf.fit(X_train,y_train))\nprint(dec_clf.score(X_train,y_train))\ndec_clf.score(X_test,dec_clf.predict(X_test))","c2eb56ed":"from sklearn import tree\nfig=plt.figure(figsize=(20,20))\n_=tree.plot_tree(dec_clf,feature_names=data.Popularity,class_names=data.Genre,filled=True,max_depth=3)","b82de79e":"# we will use PCA technique to reduce the dimensionality of the data given","4b8869d4":"# Processing of the data given","efc64163":"### if we see the above observations GaussianNB algorithm shows some good results compared to KNeighborsClassifier algorithm\n","bc841554":"# importing required modules","a8d882d3":"#### all the three linear regression shows similar accuracy scores","17b8fb05":"#### there is nothing to process as the data doesn't have any null values","7a965eba":"# Reading the data"}}