{"cell_type":{"6e17f984":"code","2e8c384b":"code","ca379188":"code","ad58e8b5":"code","175be87b":"code","2494c608":"code","a846f991":"code","b6eafb90":"code","e189d482":"code","ad186786":"code","1dc8617f":"code","4268fbcd":"code","d7c28f2d":"code","0f57304c":"code","be202b44":"code","f3cce66e":"code","57dc6336":"code","464e01c7":"code","e737ed8d":"code","ca9c8509":"code","141e119d":"code","131881f2":"markdown","6de5d37d":"markdown","0b617c6e":"markdown","12e67d48":"markdown","e8ccab98":"markdown","114a07b7":"markdown","2e5aeb22":"markdown","c35d31ef":"markdown","0fa7ce77":"markdown","4ca119c4":"markdown","a72dd6bf":"markdown","624244d7":"markdown","20cf444e":"markdown"},"source":{"6e17f984":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2e8c384b":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nimport sklearn.metrics as metrics\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split,RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns","ca379188":"data = pd.read_csv('\/kaggle\/input\/engineering-placements-prediction\/collegePlace.csv')","ad58e8b5":"data.head() #Displaying head of the data","175be87b":"df = pd.read_csv('\/kaggle\/input\/engineering-placements-prediction\/collegePlace.csv')","2494c608":"plt.figure(figsize=(20,10)) #Streams Vs. Gender\nplt.bar(df.Stream,df.Gender,color='red')","a846f991":"plt.figure(figsize=(20,10)) #Streams Vs. CGPA\nplt.bar(df.Stream,df.CGPA,color='blue')","b6eafb90":"import seaborn as sns #Pairplot\nsns.pairplot(df,diag_kind='kde')","e189d482":"data.isnull().sum() #No Null values are there","ad186786":"data.describe() #Basic Info about the data","1dc8617f":"data['Internships'][data['Internships'] == 0] = 'No'\ndata['Internships'][data['Internships'] == 1] = 'Yes'\n\ndata['Hostel'][data['Hostel'] == 0] = 'No'\ndata['Hostel'][data['Hostel'] == 1] = 'Yes'\n\ndata['HistoryOfBacklogs'][data['HistoryOfBacklogs'] == 0] = 'No'\ndata['HistoryOfBacklogs'][data['HistoryOfBacklogs'] == 1] = 'Yes'","4268fbcd":"data.head() #Displaying head of the data","d7c28f2d":"data = pd.get_dummies(data, drop_first=True) #Encoding","0f57304c":"data.head() #Displaying head of the data","be202b44":"# Splitting the dataset into train and test datasets\n# 80% Train Data + 20% Test Data\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data.drop('PlacedOrNot', 1), data['PlacedOrNot'], test_size = .2)","f3cce66e":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score\n# Define the model\n\n    \n    # defining the model\nclf = XGBClassifier(learning_rate=0.09, \n                    n_estimators=100, \n                    use_label_encoder=False,\n                    random_state=42)\n    \nclf.fit(X_train, y_train, eval_metric='logloss')\npredictions = clf.predict(X_test) \nprint(\"accuracy_score: \" + str(accuracy_score(y_test, predictions)))","57dc6336":"#Function for plotting Confusion Matrix\n\n\ndef plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i in range (cm.shape[0]):\n        for j in range (cm.shape[1]):\n            plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","464e01c7":"#Feeding parameters in the CM Function\n\ncm = confusion_matrix(y_true=y_test, y_pred=predictions)","e737ed8d":"#Labels for the CM\n\ncm_plot_labels = ['Not Placed','Placed']","ca9c8509":"#Plotting the CM\n\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')","141e119d":"from sklearn.metrics import roc_curve, auc #for model evaluation\n\nfpr, tpr, thresholds = roc_curve(y_test, predictions)\n\nfig, ax = plt.subplots()\nax.plot(fpr, tpr)\nax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC curve for diabetes classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","131881f2":"# Importing Required Libraries ","6de5d37d":"![](https:\/\/www.pngitem.com\/pimgs\/m\/215-2156289_training-and-placement-hd-png-download.png)","0b617c6e":"# Using XGBoost","12e67d48":"# Now, Let's Encode the Data","e8ccab98":"**After plotting the ROC Curve, we can see that our model has performed really well on the Test Dataset.**","114a07b7":"# Reading the CSV File","2e5aeb22":"# Visualizations","c35d31ef":"# Plotting the ROC Curve","0fa7ce77":"# SPLITTING THE DATASET INTO TRAIN AND TEST DATA\u00b6","4ca119c4":"# Let's us check for NULL Values","a72dd6bf":"# Placement refers to the process of connecting the selected person and the employer in order to establish an ongoing employment relationship. In this step the employee is given the activities he\/she needs to perform and is told about his\/her duties. Placement is usually followed by the orientation process.","624244d7":"# PLOTTING THE CONFUSION MATRIX\u00b6","20cf444e":"# CREATING CONFUSION MATRIX"}}