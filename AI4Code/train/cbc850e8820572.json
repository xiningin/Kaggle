{"cell_type":{"74daa37a":"code","1ceb1ad2":"code","776dc382":"code","18c0e2a5":"code","81393efd":"code","a7d868b8":"code","eff503e4":"code","6e54b055":"code","3a82121b":"markdown","c48eec2a":"markdown","b5021bda":"markdown","abef232d":"markdown","a4722c40":"markdown"},"source":{"74daa37a":"import os\nimport math\nimport itertools\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.pyplot import imshow\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, ZeroPadding2D, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.utils.np_utils import to_categorical\nfrom keras.utils import plot_model\nfrom scipy.misc import imresize\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\n\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)\n\n%matplotlib inline\npd.set_option(\"display.max_rows\", 10)\nnp.random.seed(42)","1ceb1ad2":"os.listdir(\"..\/input\/\")","776dc382":"dataset = pd.read_csv(\"..\/input\/train.csv\")\ndataset.columns = ['filename', 'class'] # renaming to match ImageDataGenerator expectations\ndataset.sample(5)","18c0e2a5":"dataset.shape","81393efd":"\nbatch_size = 128\nsubset = 500\ntarget_size = (64, 64, 1) # set to grayscale\n\ndatagen = ImageDataGenerator(\n    validation_split=.2,\n    featurewise_center=False,\n    featurewise_std_normalization=False,\n    rotation_range=0,\n    width_shift_range=0,\n    height_shift_range=0,\n    horizontal_flip=False)\n\ntrain_generator = datagen.flow_from_dataframe(\n        dataframe=dataset.iloc[:subset],\n        directory='..\/input\/train',\n        target_size=target_size[0:2],\n        color_mode='grayscale', # this has to match the target_size parameter\n        batch_size=batch_size,\n        class_mode='categorical',\n        interpolation='nearest')\n\nnum_classes = len(np.unique(train_generator.classes))\n","a7d868b8":"model = Sequential()\nmodel.add(BatchNormalization(input_shape = target_size ))\nmodel.add(Conv2D(filters=32, \n                 kernel_size=(7,7), \n                 activation='relu'))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\nopt = Adam(lr=0.02, decay=0.005)\nmodel.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\nmodel.build()\nmodel.summary()","eff503e4":"epochs = 3\n\nhistory = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=subset\/\/epochs)","6e54b055":"plt.plot(history.history['categorical_accuracy'])\nplt.title('Model categorical_accuracy')\nplt.ylabel('categorical_accuracy')\nplt.xlabel('epoch')\nplt.show()","3a82121b":"ImageDataGenerator requires `filename` and `class` respectively for the column with all the file names and for the other with the classes. Here I change the columns names but I could have used:\n\n    x_col: string, column in the dataframe that contains\n           the filenames of the target images.\n    y_col: string or list of strings,columns in\n           the dataframe that will be the target data.\nin `flow_from_dataframe` method to override the default Keras behaviour","c48eec2a":"# Using Keras ImageDataGenerator\nHere I'm using Keras [`ImageDataGenerator`](https:\/\/keras.io\/preprocessing\/image\/) to read files from the `train` directory and feed a very simple CNN. I'm still not searching for accuracy here, just trying to simplify the pipeline. ImageDataGenerator has the ability to generate a flow of images to the CNN, applying:\n* resampling to a smaller size\n* changing to grayscale if needed\n* train\/validation split (still not done here)\n* data augmentation\n\nTODO:\n* resample to a different size\n* change the CNN to a more effective one (this one is not learning at all)\n* add the validation_generator and pass it to the model's `fit_generator` method\n* analyze source data\n* train on whole dataset\n* data augmentation\n* implement Mean Average Precision @ 5 for submission (see https:\/\/www.kaggle.com\/pestipeti\/explanation-of-map5-scoring-metric)\n","b5021bda":"### TO BE CONTINUED","abef232d":"The CNN. Notes:\n* `target_size` is passed to the first layer\n* optimizer set to Adam with default learning rate of .02 and a learning rate decay at each epoch","a4722c40":"Here I use only a subset of all the 25k picture in order to be faster. Slicing the dataframe is enough.\n\n* `batch_size` controls how many samples the generator sends to the network each step\n* `subset` is used to slice the source dataset and work on a smaller one when making experiments\n* `target_size` is the image shape to use in the training"}}