{"cell_type":{"5b66901e":"code","4e549c86":"code","1c37b2b5":"code","b66f6b0d":"code","57d2c896":"markdown","ef5ad615":"markdown","529d8e16":"markdown","eb81663f":"markdown"},"source":{"5b66901e":"import plotly.express as px\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n# Copy from ragnar's kernel to reduce memory usage\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]):\n            # skip datetime type\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","4e549c86":"%%time\nstv = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sales_train_validation.csv')\nsales = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sell_prices.csv')\ncal = pd.read_csv('..\/input\/m5-forecasting-accuracy\/calendar.csv')\nss = pd.read_csv('..\/input\/m5-forecasting-accuracy\/sample_submission.csv')\n# From michael mayer's kernel\nfrom sklearn.preprocessing import OrdinalEncoder\ndef prep_calendar(df):\n    df = df.drop([\"date\", \"weekday\"], axis=1)\n    df = df.assign(d = df.d.str[2:].astype(int))\n    df = df.fillna(\"missing\")\n    cols = list(set(df.columns) - {\"wm_yr_wk\", \"d\"})\n    df[cols] = OrdinalEncoder(dtype=\"int\").fit_transform(df[cols])\n    df = reduce_mem_usage(df)\n    return df\n\ndef prep_selling_prices(df):\n    gr = df.groupby([\"store_id\", \"item_id\"])[\"sell_price\"]\n    df[\"sell_price_rel_diff\"] = gr.pct_change()\n    df[\"sell_price_roll_sd7\"] = gr.transform(lambda x: x.rolling(7).std())\n    df[\"sell_price_cumrel\"] = (gr.shift(0) - gr.cummin()) \/ (1 + gr.cummax() - gr.cummin())\n    df = reduce_mem_usage(df)\n    return df\n\ndef reshape_sales(df, drop_d = None):\n    if drop_d is not None:\n        df = df.drop([\"d_\" + str(i + 1) for i in range(drop_d)], axis=1)\n    df = df.assign(id=df.id.str.replace(\"_validation\", \"\"))\n    df = df.reindex(columns=df.columns.tolist() + [\"d_\" + str(1913 + i + 1) for i in range(2 * 28)])\n    df = df.melt(id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n                 var_name='d', value_name='demand')\n    df = df.assign(d=df.d.str[2:].astype(\"int16\"))\n    return df\n\ndef prep_sales(df):\n    df['min'] = df['demand'].apply('min')\n    df['max'] = df['demand'].apply('max')\n    df['std'] = df['demand'].apply('std')\n    df['mean'] = df['demand'].apply('mean')\n\n    # Remove rows with NAs except for submission rows. rolling_mean_t180 was selected as it produces most missings\n    df = reduce_mem_usage(df)\n\n    return df","1c37b2b5":"stv = reshape_sales(stv)\nimport gc\ngc.collect()\nstv = prep_sales(stv)\ngc.collect()\nstv.to_feather('sales_train_validation.feather')\ndel stv\nsales = prep_selling_prices(sales)\ngc.collect()\nsales.to_feather('sell_prices.feather')\ndel sales\ncal = prep_calendar(cal) ### does not help cal\ngc.collect()\ncal.to_feather('calendar.feather')\ndel cal\nss.to_feather('sample_submission.feather')","b66f6b0d":"%%time\nstv = pd.read_feather('sales_train_validation.feather')\nsales = pd.read_feather('sell_prices.feather')\ncal = pd.read_feather('calendar.feather')\nss = pd.read_feather('sample_submission.feather')","57d2c896":"# M5: Feather Files for Fast Data Loading\n\n---\n\nAs you all know, reading in the CSV files takes time for this competition so you can use the `feather` file format to load your files faster.\n\n---\n\n+ Alternatively, you can read it in from the dataset here: https:\/\/www.kaggle.com\/nxrprime\/m5-feather-files","ef5ad615":"---\n\n### Nice! We got a 48x improvement over earlier reading the data. This can really be helpful with speed later!\n\n---","529d8e16":"Let's test it:","eb81663f":"We have a total time of 10.6s secs spent reading the data. Not bad, but it **can** be improved."}}