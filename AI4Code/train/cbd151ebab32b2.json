{"cell_type":{"caee6757":"code","e1074942":"code","3a715644":"code","89744d1e":"code","2f9c95a5":"code","28727700":"code","f5d26c89":"code","5e19b5e3":"code","27e96f60":"code","0fffab0a":"code","89ee93ce":"code","9ec0cd6c":"code","47581548":"code","1ff6579c":"code","5c1db515":"code","b0d080a1":"code","2bca6bdf":"code","2a2e84ba":"code","4514c62e":"code","16286c20":"code","002e0d53":"code","bf17b1e9":"code","7dcb492c":"code","092af217":"code","b91885f2":"code","9a36e1b3":"code","8f2ad6a3":"code","804977ec":"code","7c1ef5a3":"code","92f49e07":"code","d7fc8727":"code","2ab513ae":"code","94ec8c5f":"code","54cfb6be":"code","888dcec2":"code","eddfa7a5":"code","ee047491":"code","6d39a776":"code","5efdb63d":"code","d3ec1df1":"code","55ab1a8a":"code","da7c9b54":"code","5652e66c":"code","c645c867":"code","8df86743":"code","8a33c4b9":"code","581f0c2d":"code","91949976":"code","8497059f":"code","017ae367":"code","ce1b68ea":"code","72c7b349":"code","775b3fb1":"code","4c00761c":"code","a648ee2c":"code","d185a794":"code","2c5fa062":"code","f38b38fc":"code","7cc89999":"code","51cb1b4d":"code","a7e4e5bc":"markdown","e3729231":"markdown","1466fe4b":"markdown","e61b8559":"markdown","4cda8bac":"markdown","3bf5ce28":"markdown","f759c421":"markdown","33f71b58":"markdown","c89ca499":"markdown","6d654673":"markdown","6710660f":"markdown","7c486ee2":"markdown","98d8d525":"markdown","edd0bf28":"markdown","cc3128e0":"markdown","54e018dc":"markdown","43ea62c2":"markdown","ae122b06":"markdown","a1c112c4":"markdown"},"source":{"caee6757":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e1074942":"import numpy as np\nimport pandas as pd","3a715644":"candy = pd.read_excel('\/kaggle\/input\/candy-data\/candyhierarchy2017.xlsx')","89744d1e":"candy.head()","2f9c95a5":"candy.columns","28727700":"candy = candy.rename(columns = {'Q1: GOING OUT?' : 'going_out', 'Q2: GENDER' : 'gender', 'Q3: AGE': 'age', 'Q4: COUNTRY' : 'country',\n       'Q5: STATE, PROVINCE, COUNTY, ETC' : 'area', 'Q10: DRESS' : 'dress', 'Q11: DAY': 'day',\n       'Q12: MEDIA [Daily Dish]' : 'media_DailyDish', 'Q12: MEDIA [Science]': 'media_Science', 'Q12: MEDIA [ESPN]' : 'media_ESPN',\n       'Q12: MEDIA [Yahoo]': 'media_Yahoo'})","f5d26c89":"candy.columns","5e19b5e3":"candy['Unnamed: 113'].unique()","27e96f60":"candy.drop(columns = ['Internal ID','Unnamed: 113', 'Click Coordinates (x, y)'], inplace = True)","0fffab0a":"candy.shape","89ee93ce":"candy.dropna(subset = ['going_out', 'gender', 'age', 'country', 'area'], how = 'all', inplace = True)\ncandy.reset_index(drop = True, inplace = True)","9ec0cd6c":"candy.shape","47581548":"candy.going_out = candy.going_out.fillna('Not Sure')\ncandy.going_out.unique()","1ff6579c":"candy.gender.value_counts()","5c1db515":"# Adding 11 NaN genders to type 3 - I'd rather not say seems to be the closest to unknown\ncandy[candy.gender == \"I'd rather not say\"].shape  #checking for spaces in text - found none","b0d080a1":"candy.gender = candy.gender.fillna(\"I'd rather not say\")\ncandy.gender.value_counts()","2bca6bdf":"candy.country.unique()","2a2e84ba":"candy.country.value_counts(dropna = False).sort_values(ascending = False)","4514c62e":"candy.country.isna().sum()","16286c20":"candy.country = candy.country.fillna('Unknown')","002e0d53":"set([x for x in candy.country if 'u' in str(x)])  # unique values with 'u'","bf17b1e9":"USA = [x for x in candy.country if (('u' in str(x) or 'U' in str(x)) and 'ingdom' not in str(x)\\\n     and 'urope' not in str(x) and 'stralia' not in str(x) and 'South Korea' not in str(x) and 'South africa' not in str(x) and 'uk' not in str(x))]","7dcb492c":"candy.country = candy.country.replace(to_replace = USA, value = 'USA')","092af217":"candy.country.unique()","b91885f2":"candy.country = candy.country.replace(to_replace = ['america','Ahem....Amerca',\"'merica\",'North Carolina ','cascadia',\\\n                                                   'New York','A','California','New Jersey','America','Alaska',\\\n                                                    'N. America'], value = 'USA')","9a36e1b3":"canada = [x for x in candy.country if 'anada' in str(x).strip() or 'ANADA' in str(x) or 'Can' in str(x)]","8f2ad6a3":"candy.country = candy.country.replace(to_replace = canada, value = 'Canada')","804977ec":"candy.country.value_counts()","7c1ef5a3":"other = [x for x in candy.country.unique()]","92f49e07":"other.remove('USA')\nother.remove('Canada')","d7fc8727":"other","2ab513ae":"candy.country = candy.country.replace(to_replace = other, value = 'Other')","94ec8c5f":"candy.country.value_counts()","54cfb6be":"candy.columns","888dcec2":"candy = candy.astype({'going_out':'category', 'gender':'category', 'country':'category', 'dress':'category', 'day':'category'})","eddfa7a5":"candy.describe(include = 'category')","ee047491":"def melt1(row):\n    for c in data.columns:\n        if row[c] == 1:\n            return c","6d39a776":"data = candy[candy.columns[-4:]]","5efdb63d":"data","d3ec1df1":"new_col = data.apply(melt1, axis = 1)","55ab1a8a":"candy['media_preference'] = new_col","da7c9b54":"candy.drop(columns = ['media_DailyDish','media_Science','media_ESPN','media_Yahoo'], inplace = True)","5652e66c":"candy.media_preference.value_counts(dropna = False)","c645c867":"#Dividing questions and other columns\n'''\ncandy_options = [i for i in candy.columns if 'Q6' in i or 'Q7' in i or 'Q8' in i or 'Q9' in i]\nother_columns = [i for i in candy.columns if 'Q6' not in i and 'Q7' not in i and 'Q8' not in i and 'Q9' not in i]\n'''\n\npersonal_info_cols = candy.columns[:6]\nquestionare_cols = candy.columns[5:]","8df86743":"candy.columns","8a33c4b9":"responses = len(questionare_cols) - candy[questionare_cols].isna().sum(axis = 1)","581f0c2d":"candy['responses'] = responses","91949976":"candy.head(3)","8497059f":"candy_questions = [x for x in candy.columns if 'Q6' in str(x)]","017ae367":"candy_questions","ce1b68ea":"data = pd.DataFrame(candy[candy_questions])","72c7b349":"data.shape","775b3fb1":"re = ['type_'+ str(x) for x in range(1,104)]\n\ndic = {}\nfor i in range(len(data.columns)):\n    dic[data.columns[i]] = re[i]","4c00761c":"candy = candy.rename(columns = dic)\ndata = data.rename(columns = dic)","a648ee2c":"data = data.dropna(axis = 0, how = 'all')\ndata = data.reset_index(drop = True)","d185a794":"data.shape","2c5fa062":"data.head(4)","f38b38fc":"d = data.melt()","7cc89999":"d.head(5)","51cb1b4d":"import seaborn as sns\n\nsns.countplot(data = d[:4000], x = 'variable', hue = 'value')","a7e4e5bc":"## 5 Formating columns","e3729231":"Country column got messy and I got so less done :( I am going to ignore area column, will check it out if my analysis wants me to","1466fe4b":"## 7 Wrting a function to convert 4 columns into 1 column","e61b8559":"## 6 Datatype conversion","4cda8bac":"### country column","3bf5ce28":"I found a better way of handling nulls later. (Patched that code and commenting this one out)\n\n'''\ncandy.shape\n\ncandy = candy.dropna(how = 'all')\n\ncandy = candy.dropna(thresh = 5, axis = 0) # I want at least 5 non-NaN values.\n\ncandy.drop(['Unnamed: 113','Click Coordinates (x, y)'], axis = 1, inplace = True)\n\n'''","f759c421":"## 3 Partial columns renaming","33f71b58":"About Data:\n\n* Data is about a 12 questions survey for candies during Halloween.\n* Q1 is if the surveyee is going to trick or treat himself\n* Q6 is specific to a type of candy and how the surveyee finds it (JOY, DESPAIT, NEUTRAL)\n* Q7 is other candy thats gives JOY to surveyee not mentioned in Q6 list\n* Q8 is other candy thats gives DESPAIR to surveyee not mentioned in Q6 list\n* Q10 is what color of the dress does the surveyee sees in first glance (black-blue OR white\/golden)\n* Q11 is what day surveyee likes? Friday OR Sunday\n* Q12 is a Media question of a website that the suveyee would most likely check followed by co-ordinates of click.\n\n*The data is taken from https:\/\/www.scq.ubc.ca\/so-much-candy-data-seriously\/*","c89ca499":"I want help to convert d to a form:\n\n\n|Response| MEH  | JOY  | DESPAIR|\n|------|------|------|--------|\n|type_1|count |count |count   |\n|type_2|count |count |count   |\n|type_3|count |count |count   |","6d654673":"# Part 2 - EDA","6710660f":"## Delete rows that have all NaNs","7c486ee2":"### going out column","98d8d525":"People are so creative !!","edd0bf28":"## 4 Handling null values","cc3128e0":"This concludes the data cleaning part of the dataset","54e018dc":"## 1 Importing packages","43ea62c2":"### gender column","ae122b06":"## 2 Read file and explore","a1c112c4":"# Part 1 - Data Cleaning"}}