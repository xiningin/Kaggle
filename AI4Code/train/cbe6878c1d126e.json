{"cell_type":{"3de7659c":"code","6abd7997":"code","777fda58":"code","59693596":"code","51568128":"code","876ff34c":"code","a159c8f6":"code","47d3a31f":"code","0fe083fe":"code","30d9c1aa":"code","8b04d228":"code","b1ea068f":"code","d8298947":"code","61cfc2cb":"code","d080171c":"code","4969400a":"code","4b1b5af2":"code","6699ed90":"code","c429e612":"code","56dcea98":"code","2cba6ae6":"markdown","87699d5a":"markdown","c45546d3":"markdown","a6e21ecb":"markdown","a896ea11":"markdown","11d140c4":"markdown","5810bd33":"markdown","a4984ffd":"markdown","7636cae2":"markdown","efc6488c":"markdown","bcd9c8a6":"markdown","bbf0de39":"markdown","3c53f197":"markdown","f346d324":"markdown","2980fde3":"markdown","f6b9fa99":"markdown","e07255e4":"markdown","7dfe4c28":"markdown","e48ff990":"markdown","711a2e7d":"markdown"},"source":{"3de7659c":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('retina')\nimport seaborn as sns\nsns.set(palette='viridis_r',context='notebook',\n        font='ubuntu', style='white',font_scale=1)\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\n\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.ensemble import StackingClassifier,\\\nRandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import plot_precision_recall_curve\nfrom sklearn.metrics import plot_roc_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler","6abd7997":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain=train.set_index('PassengerId')\n\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntest=test.set_index('PassengerId')\n\ndata = pd.concat([train,test])\ndata.head()","777fda58":"data.isnull().sum().plot(kind='bar', edgecolor='black')\nsns.despine()\ndata.info()","59693596":"data.select_dtypes('object').describe()","51568128":"fig, axes = plt.subplots(ncols=2,figsize=(13,4))\n\nsns.kdeplot(hue=train.Sex, x=train.Survived, \n            fill=True, edgecolor='darkgreen', ax=axes[0])\nsns.kdeplot(x=train.Age, hue=train.Survived, \n            fill=True, edgecolor='darkgreen')\nsns.despine()\n\ntrain.groupby(['Sex']).agg({'Survived':'mean','Age':'median','Name':'count'}).reset_index()","876ff34c":"def get_title(series):\n    series = series.str.split(', ').str[1]\n    return series.str.split('.').str[0]\n\n\ndata['Title'] = get_title(data['Name'])\n\nfig,axes = plt.subplots(nrows=2,ncols=2, figsize=(10,10),\n                        sharex = False,sharey=False)\n\npd.crosstab(data[data.index.isin(train.index)]['Title'], \n            data[data.index.isin(train.index)]['Sex']).plot(\n            kind='bar',edgecolor='black', ax=axes[0,0], \n            title='Train sample', stacked=True)\n\npd.crosstab(data[data.index.isin(test.index)]['Title'], \n            data[data.index.isin(test.index)]['Sex']).plot(\n            kind='bar', edgecolor='black', ax=axes[0,1],\n            title='Test sample', stacked=True)\n\nsns.boxplot(data=data[data.index.isin(train.index)].\\\n            sort_values('Title'), x='Title',y='Age', ax=axes[1,0])\nsns.boxplot(data=data[data.index.isin(test.index)].\\\n            sort_values('Title'), x='Title',y='Age', ax=axes[1,1])\n\nsns.despine()\n\nfor ax in axes.ravel():\n    ax.legend(frameon=False)\n    ax.tick_params(rotation=70)\n\nplt.tight_layout()","a159c8f6":"def change_title(series):\n    \n    series = series.replace(['Capt','Col','Major','Dr','Jonkheer',\n                             'Sir','Rev'],'Other')\n    series = series.replace(['Don'],'Mr')\n    series = series.replace(['Mlle','Ms'],'Miss')\n    series = series.replace(['Mme','Lady','Dona','the Countess'],'Mrs')\n    return series\n\n\ndata['Title'] = change_title(data['Title'])\n\nfig,axes = plt.subplots(nrows=2,ncols=2, figsize=(10,9), \n                        sharey=False)\n\npd.crosstab(data[data.index.isin(train.index)]['Title'],\n            data[data.index.isin(train.index)]['Sex']).\\\n            sort_values('Title').plot(kind='bar',edgecolor='black', \n            ax=axes[0,0], title='Train sample', stacked=True)\n\nsns.boxplot(data=data[data.index.isin(train.index)].sort_values('Title'), \n            x='Title',y='Age', ax=axes[1,0])\n\npd.crosstab(data[data.index.isin(test.index)]['Title'], \n            data[data.index.isin(test.index)]['Sex']).\\\n            sort_values('Title').plot(kind='bar',edgecolor='black', \n            ax=axes[0,1], title='Test sample', stacked=True)\nsns.boxplot(data=data[data.index.isin(test.index)].sort_values('Title'), \n            x='Title',y='Age', ax=axes[1,1])\n\nfor ax in axes.ravel():\n    ax.legend(frameon=False)\n    ax.tick_params(rotation=90)\nsns.despine()\nplt.tight_layout()\n\n## name of passengers will be deleted\n\ndata = data.drop('Name',axis=1)","47d3a31f":"sns.catplot(data=data,x='Title', hue='Survived', \n            kind='count', edgecolor='black')\nplt.title('Survivals amongst people with different titles',\n          fontsize=14)\nplt.tick_params(rotation=45)\nplt.show()","0fe083fe":"def fill_age(df)->pd.DataFrame:\n    for sex in df.Sex.unique(): \n        for title in df.Title.unique():\n            df.loc[(df.Sex==sex)&(df.Title==title),'Age']=\\\n            df.loc[(df.Sex==sex)&(df.Title==title),'Age'].fillna(\n            df.loc[(df.Sex==sex)&(df.Title==title)].Age.median())\n            \n    return df\n\ndef fam_size(df)->pd.Series:\n    return df.SibSp+df.Parch+1\n\ndef is_mother(series)->pd.Series:\n    mask = series > 0\n    return np.where(mask,1,0)\n\ndef is_alone(series)->pd.Series:\n    mask= series > 0\n    return np.where(mask,1,0)\n\ndef ticket(series)->pd.Series:\n    return [str(i).split()[0] if len(str(i).split())>1 else 'N' \n     for i in series]\n\ndef fill_cabin(series)->pd.Series:\n    series = series.fillna('N')\n    return series.apply(lambda x: x[0][0])\n\ndef has_cabin(series):\n    mask = series=='N'\n    return np.where(mask,0,1)","30d9c1aa":"data = fill_age(data)\n\ndata['Famsize'] = fam_size(data)\ndata['IsMother'] = is_mother(data['Parch'])\ndata['IsAlone'] = is_alone(data['SibSp'])\n# data['Ticket'] = ticket(data['Ticket'])\ndata['Embarked']=data['Embarked'].fillna('ffill')\ndata['Cabin'] = fill_cabin(data['Cabin'])\n\ndata['Age'] = pd.to_numeric(pd.cut(\n   data['Age'],5, labels=[0,1,2,3,4]))\ndata['Fare'] = data['Fare'].fillna(data.Fare.median())\n# data['Fare'] = pd.to_numeric(pd.cut(\n  # data['Fare'],5, labels=[0,1,2,3,4]))\n\ndata['Has_Cabin'] = has_cabin(data['Cabin'])\n\ndata = data.drop(['SibSp','Parch','Ticket','Cabin','Fare'], axis=1)","8b04d228":"encoder = LabelEncoder()\n\nfor col in data.select_dtypes('object'):\n    data[col] = encoder.fit_transform(data[col])\n    \nscaler = MinMaxScaler()\n\nfor col in data.columns:\n    if col!='Survived':\n        data[col] = scaler.fit_transform(data[col].values.reshape(-1,1))","b1ea068f":"plt.figure(figsize=(12,10))\n\nsns.heatmap(data.drop('Survived', axis=1).corr(), annot=True,\n              cmap='viridis_r', linewidth=.25)\nplt.show()","d8298947":"sns.pairplot(data, hue='Survived', \n             markers='x')\nplt.show()","61cfc2cb":"train = data[data.index.isin(train.index)]\ntarget = train.pop('Survived')\ntest = data[data.index.isin(test.index)].drop('Survived', axis=1)\n\nX_train, X_valid, y_train, y_valid = train_test_split(train,target,\n      test_size=.3,random_state=17)","d080171c":"gbc = GradientBoostingClassifier(random_state=42)\nrfc = RandomForestClassifier(random_state=42, n_jobs=-1)\nsvc = SVC(random_state=42, degree=3)\nlgc = LogisticRegression(random_state=42) \nqda = QuadraticDiscriminantAnalysis(reg_param=.0)\nxgb = XGBClassifier(random_state=42,n_jobs=-1,\n                    verbosity=0)\n\nestimators = [('Random Forest Classifier',rfc),\n              ('Support Vector Machines',svc),\n              ('Logistic Regression',lgc), \n              ('Gradient Boosting Classifier',gbc),\n              ('Quadratic Discriminant Analysis',qda),\n              ('XGB Regressor', xgb)]","4969400a":"## define confusion plot and showing metrics\n\ndef confusion_plot(label, y_valid, y_pred, ax=None):\n    \n    co_ma = confusion_matrix(y_valid, y_pred)\n    groups = ['True Neg','False Pos','False Neg','True Pos']\n    counts = [int(value) for value in co_ma.flatten()]\n    shares = ['{0:.2%}'.format(value) for value in\n             co_ma.flatten()\/np.sum(co_ma)]\n    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n              zip(groups,counts,shares)]\n    labels = np.asarray(labels).reshape(2,2)\n    sns.heatmap(co_ma,annot=labels,cmap='binary', alpha=.55, ax=ax,\n             cbar=True, fmt='', linewidth=1,linecolor='black')\n    plt.axis('off')\n    plt.title(f'Confusion Matrix for {label}')\n\n                                            \ndef show_metrics(metrics):\n    try:return pd.DataFrame(metrics).set_index('classifier')\n    except:return pd.DataFrame([metrics]).set_index('classifier')","4b1b5af2":"metrics = []\n\nfor est in estimators:\n    \n    fig, axes = plt.subplots(ncols=3, figsize=(15,4))\n   \n    mod = est[1].fit(X_train, y_train)\n    y_pred = mod.predict(X_valid)\n    plot_precision_recall_curve(mod, X_valid, y_valid, \n                    y_pred, ax=axes[0], color='black')\n    plot_roc_curve(mod, X_valid,\n                   y_valid,ax = axes[1], color='black')\n\n    axes[0].set_title(f'Precision-Recall Curve for {est[0]}')\n    axes[1].set_title(f'ROC Curve for {est[0]}')\n    axes[1].plot([1,0],[1,0], c='green',ls='--')\n    confusion_plot(est[0],y_valid, y_pred, axes[2])\n    for ax in axes.ravel():\n        ax.legend(frameon=False)\n        \n    scores = {}\n    scores['classifier'] = est[0]\n    scores['accuracy_score'] = accuracy_score(y_valid, y_pred)\n    scores['roc_auc_score']=roc_auc_score(y_valid, y_pred)\n    scores['f1_score'] = f1_score(y_valid,y_pred)\n\n    plt.tight_layout()\n    metrics.append(scores)\n\nshow_metrics(metrics)","6699ed90":"stacked_metrics={}\n\nlgm = LGBMClassifier(random_state=42, n_jobs=-1)\n\nstk = StackingClassifier(estimators=estimators,\n    final_estimator=lgm)\ncls_name = 'Stacking Classifier'\n\nregmodel = stk.fit(X_train, y_train)\ny_pred = stk.predict(X_valid)\n\nfig, axes = plt.subplots(ncols=3, figsize=(14,4))\n\nplot_precision_recall_curve(regmodel,X_valid,y_valid, \n            y_pred, color='black', ax=axes[0])\nplot_roc_curve(regmodel,X_valid,y_valid, \n               color='black', ax=axes[1])\n\naxes[0].set_title(f'Precision-Recall Curve for {cls_name}')\naxes[1].plot([1,0],[1,0], c='green',ls='--')\naxes[1].set_title(f'ROC Curve for {cls_name}')\nconfusion_plot(cls_name,y_valid, y_pred, axes[2])\nfor ax in axes:\n    ax.legend(frameon=False)\n\nstacked_metrics['classifier'] = cls_name\nstacked_metrics['accuracy_score'] = accuracy_score(y_valid, y_pred)\nstacked_metrics['roc auc score'] = roc_auc_score(y_valid, y_pred)\nstacked_metrics['f1_score'] = f1_score(y_valid, y_pred)\n    \nplt.tight_layout()\n\nshow_metrics([stacked_metrics])","c429e612":"perm = PermutationImportance(stk, random_state=42).fit(X_valid,y_valid)\neli5.show_weights(perm, feature_names=X_valid.columns.values)","56dcea98":"submission = pd.DataFrame({\n        \"PassengerId\": test.index,\n        \"Survived\": svc.predict(test).astype(int)\n    })\nsubmission.to_csv('submission.csv', index=False)","2cba6ae6":"Update: unfortunately, this stacked model is failed and got not of the highest score. But surprisingly, the SVC model do. ","87699d5a":"$\\implies$ females had good chances to survive in every socket.","c45546d3":"#### Train and Test datasets. Splitting","a6e21ecb":"#### Choosing models for stacking","a896ea11":"### First Look to the Data","11d140c4":"<sup>Thanks for reading! This is my first experience in prediction on Kaggle and I will be grateful for your comments, advice, or upvotes.<\/sup>","5810bd33":"As was seen on a plot above passengers with different titles age are huge split by age. The other possible biases come from rare titles. So, they will be re-categorized based on occurences.","a4984ffd":"For this binary classification task, I've chosen six popular classifiers in an attempt to use stacking and get the best result with LGBMClassifier at the end.","7636cae2":"There are a plenty of nans in `Age` column. Previously we've seen age and gender differentiation between passengers with different titles (e.g., median *Master* is a boy under 10). That is why the missing values in `Age` were replaced with the median age according to the`Sex` & `Title` columns.\n\n`Embarked` represents the ports of embarkations where C - Cherbourg, Q - Queenstown and S - Southampton.The blind filling is used to replace nans.\n\n`Ticket` has a varierty of values which seems not to be meaningful. \n\n`Cabin` is incompleted in many cases, so I would replace to check if there is one.\n\n`Parch` & `Sibsp` are both represents the size of the family but from the different foundations. I would combine them in `FamilySize`. \n\nWe also see above that passengers with *Mrs* title can have a good chance to survive. Consider if there will be females with the child of more we might create a new feature `IsMother`.","efc6488c":"### Preprocessing\n\nFor preprocessing of feature with dtype object LabelEncoder is used. For scaling - MinMaxScaler","bcd9c8a6":"## Submission\n----------","bbf0de39":"## EDA & Feature Engineering\n-------------","3c53f197":"#### Stacking Classifier","f346d324":"At the end we got a data set with 10 features. And can start a prediction.","2980fde3":"## Model Selection & Prediction\n-------","f6b9fa99":"### EDA & Feature Engineering\n--------","e07255e4":"#### Gender, Name & Title\n\nLet's take a quick overlook of Sex, Age & Name columns and get snapshot of whom could be survived.","7dfe4c28":"### Other features","e48ff990":"All the passengers have a special prefix in `Name` that describes their social statuses at various dimensions - from family status to special rank or even an aristocratic title. It also can explain the cultural diversities amongst people.\n\nI would use this prefix to create a new feature `Title`.\n\nIn opposite, `Name` will be deleted.","711a2e7d":"#### Models in Comparasion"}}