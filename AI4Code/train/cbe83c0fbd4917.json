{"cell_type":{"b944c5ad":"code","8799c7cb":"code","84cd3039":"code","9f3391f1":"code","bf4bb825":"code","8412e2e9":"code","43fb19f2":"code","1fc2dcf0":"code","d9c875c5":"code","1d23e47e":"code","d80281aa":"code","da4ff0b2":"code","cb30ad5d":"code","16e2e7c2":"code","cc9f2df9":"code","80f9571d":"code","9d1c41d2":"code","d0e44fbf":"code","c9b1c080":"code","f9b4b877":"code","3c7b3ddf":"code","290dd5c9":"code","a940a291":"code","780781c9":"code","d5ed2d26":"code","7a1c50ee":"code","6d7ad0a0":"code","6d1aaaba":"code","631c07f5":"code","c72ef42e":"code","d121520b":"code","f1674d03":"code","ee579ab0":"code","82409fd2":"code","d6f94e3e":"code","7f648d60":"code","854ee74f":"code","3844e8ab":"code","85127123":"code","5307c150":"code","35f199e2":"code","1c1d2c65":"code","f12c4b51":"code","f068fdab":"code","ecb97a5e":"code","a13e6e95":"markdown","a1f8cce5":"markdown","1bbcad2c":"markdown","cee06e12":"markdown","4ef8b474":"markdown","02b3c9d7":"markdown","b633c66c":"markdown","484dbe9d":"markdown","a85c1320":"markdown","235f039a":"markdown","383afde4":"markdown","489d8a7c":"markdown","02e6bbb0":"markdown","f5725ae4":"markdown"},"source":{"b944c5ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8799c7cb":"# read the data to pandas dataframe\n\nretail = pd.read_csv('..\/input\/online-retail-customer-clustering\/OnlineRetail.csv', sep=\",\", encoding=\"ISO-8859-1\", header=0)\nretail.head()","84cd3039":"# shape of df\n\nretail.shape","9f3391f1":"# df info\n\nretail.info()","bf4bb825":"type_counts = retail['Country'].value_counts()\nCountry=pd.DataFrame(type_counts)\nCountry.head()","8412e2e9":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(20,10))\nCountry=Country.head()\nax = sns.barplot(y='Country',x=Country.index, data=Country.head())\nplt.xticks(rotation=45)","43fb19f2":"retail=retail[retail['Country']=='France']\nretail.shape","1fc2dcf0":"# Calculating the Missing Values % contribution in DF\n\ndf_null = round(100*(retail.isnull().sum())\/len(retail), 2)\ndf_null","d9c875c5":"# Droping rows having missing values\n\nretail = retail.dropna()\nretail.shape","1d23e47e":"# Changing the datatype of Customer Id as per Business understanding\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)","d80281aa":"# New Attribute : Recency\n\n# Convert to datetime to proper datatype\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')","da4ff0b2":"# Compute the maximum date to know the last transaction date\n\nmax_date = max(retail['InvoiceDate'])\nmax_date","cb30ad5d":"# Compute the difference between max date and transaction date\n\nretail['Diff'] = max_date - retail['InvoiceDate']\nretail.head()","16e2e7c2":"# Compute last transaction date to get the recency of customers\n\nrfm_r = retail.groupby('CustomerID')['Diff'].min().reset_index()\nrfm_r.head()","cc9f2df9":"# Extract number of days only\n\nrfm_r['Diff'] = rfm_r['Diff'].dt.days\nrfm_r.columns = ['CustomerID','Recency']\nrfm_r.head()","80f9571d":"### New Attribute : Frequency\n\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count().reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\nrfm_f.head()","9d1c41d2":"# New Attribute : Monetary\n\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\nrfm_m = retail.groupby('CustomerID')['Amount'].sum().reset_index()\nrfm_m.head()","d0e44fbf":"rfm = rfm_r.merge(rfm_f,how='inner',on=['CustomerID'])\nrfm =rfm.merge(rfm_m,how='inner',on=['CustomerID'])\nrfm.head()","c9b1c080":"# Outlier Analysis of Amount Frequency and Recency\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nattributes = ['Recency','Frequency','Amount',]\nplt.rcParams['figure.figsize'] = [10,8]\nsns.boxplot(data = rfm[attributes], orient=\"v\", palette=\"Set2\" ,whis=1.5,saturation=1, width=0.7)\nplt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\nplt.ylabel(\"Range\", fontweight = 'bold')\nplt.xlabel(\"Attributes\", fontweight = 'bold')","f9b4b877":"# Removing (statistical) outliers for Amount\nQ1 = rfm.Amount.quantile(0.05)\nQ3 = rfm.Amount.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Amount >= Q1 - 1.5*IQR) & (rfm.Amount <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Recency\nQ1 = rfm.Recency.quantile(0.05)\nQ3 = rfm.Recency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Recency >= Q1 - 1.5*IQR) & (rfm.Recency <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Frequency\nQ1 = rfm.Frequency.quantile(0.05)\nQ3 = rfm.Frequency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Frequency >= Q1 - 1.5*IQR) & (rfm.Frequency <= Q3 + 1.5*IQR)]","3c7b3ddf":"# Rescaling the attributes\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\n\nrfm_df = rfm[['Recency','Frequency', 'Amount']]\n\n# Instantiate\nscaler = StandardScaler()\n\n# fit_transform\nrfm_df_scaled = scaler.fit_transform(rfm_df)\nrfm_df_scaled.shape","290dd5c9":"rfm_df_scaled = pd.DataFrame(rfm_df_scaled)\nrfm_df_scaled.columns = ['Amount', 'Frequency', 'Recency']\nrfm_df_scaled.head()","a940a291":"# k-means with some arbitrary k\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=4, max_iter=50)\nkmeans.fit(rfm_df_scaled)\n# assign the label\nrfm['Cluster_Id'] = kmeans.labels_\nrfm.head()","780781c9":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Id\"] = rfm[\"Cluster_Id\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Id')\nfig.show()","d5ed2d26":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='distortion')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show() ","7a1c50ee":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='silhouette')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","6d7ad0a0":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='calinski_harabasz')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","6d1aaaba":"# k-means with some arbitrary k\nk=3\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=k, max_iter=50)\nkmeans.fit(rfm_df_scaled)\n# assign the label\nrfm['Cluster_Id'] = kmeans.labels_\nrfm.head()","631c07f5":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Id\"] = rfm[\"Cluster_Id\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Id')\nfig.show()","c72ef42e":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Recency', data=rfm)","d121520b":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Frequency', data=rfm)","f1674d03":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Amount', data=rfm)","ee579ab0":"Target_Customer = rfm[rfm['Cluster_Id']=='1']\nTarget_Customer.head()","82409fd2":"Target_Customer.count()","d6f94e3e":"from scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","7f648d60":"# Single linkage: \n\nmergings = linkage(rfm_df_scaled, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","854ee74f":"# Complete linkage\n\nmergings = linkage(rfm_df_scaled, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","3844e8ab":"# Average linkage\n\nmergings = linkage(rfm_df_scaled, method=\"average\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","85127123":"# 3 clusters\nk=3\ncluster_labels = cut_tree(mergings, n_clusters=k).reshape(-1, )\nrfm['Cluster_Labels'] = cluster_labels\nrfm.head()","5307c150":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Labels\"] = rfm[\"Cluster_Labels\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Labels')\nfig.show()","35f199e2":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Recency', data=rfm)","1c1d2c65":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Frequency', data=rfm)","f12c4b51":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Amount', data=rfm)","f068fdab":"Target_Customer2 = rfm[rfm['Cluster_Labels']=='2']\nTarget_Customer2.head()","ecb97a5e":"Target_Customer2.count()","a13e6e95":"# **Step 2: Data Cleaning**","a1f8cce5":"2. Calculating Frequency","1bbcad2c":"5. Rescaling the Attributes by Standardisation (mean-0, sigma-1)","cee06e12":"3. Calculating Monetary","4ef8b474":"Method 1: Finding the elbow point for (inertia_) \"Sum of squared distances of samples to their closest cluster center\".","02b3c9d7":"1. Initial Cluster Given K","b633c66c":"# **Step 3: K-Means Clustering**","484dbe9d":"# **Step 4: Hierarchical Clustering**","a85c1320":"1. Calculating Recency","235f039a":"# **Step 1: Import and Examine the data**","383afde4":"**2. Finding the best K: A fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. **","489d8a7c":"# **Step 3: Data Preparation for RFM Factors**","02e6bbb0":"4. Remove Outliers","f5725ae4":"1. Visualize Tree by Linkage Methods"}}