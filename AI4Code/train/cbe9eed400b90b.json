{"cell_type":{"c88904e4":"code","b3ca8af3":"code","007dec3b":"code","26b80c85":"code","f9afbc12":"code","8a6cd447":"code","aa2d607c":"code","10dbb2d3":"code","9f7c32a3":"code","5738c049":"code","3e76d2bb":"code","d5078250":"code","21278f7f":"markdown","d6935db4":"markdown","81c8af5a":"markdown","410b0aa7":"markdown","e71fdd40":"markdown","ed2f45d1":"markdown","694cc7c0":"markdown","1b153111":"markdown"},"source":{"c88904e4":"!pip uninstall -y lightgbm\n!apt-get install -y libboost-all-dev\n!git clone --recursive https:\/\/github.com\/Microsoft\/LightGBM","b3ca8af3":"%%bash\ncd LightGBM\nrm -r build\nmkdir build\ncd build\ncmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ ..\nmake -j$(nproc)","007dec3b":"!cd LightGBM\/python-package\/;python setup.py install --precompile","26b80c85":"# cleanup\n!mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n!rm -r LightGBM","f9afbc12":"import warnings\nwarnings.simplefilter(\"ignore\")\nimport logging\nimport sys\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\n\nimport lightgbm as lgb\nimport optuna\noptuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))","8a6cd447":"folds_dir = \"..\/input\/tps-september-2021-strat-kfolds\/\"\ndata_dir = \"..\/input\/tabular-playground-series-sep-2021\/\"\n\ndf_train = pd.read_csv(folds_dir + \"train_folds.csv\")\ndf_test = pd.read_csv(data_dir + \"test.csv\")\nsubmission = pd.read_csv(data_dir + \"sample_solution.csv\")\n\nfeatures = [col for col in df_test.columns if \"f\" in col]\n\nTARGET = \"claim\"\ntarget = df_train[TARGET].copy()","aa2d607c":"# Handling missing values\nmy_imputer = SimpleImputer(strategy=\"mean\")\nimputed_df = pd.DataFrame(my_imputer.fit_transform(df_train))\n# Imputation removed column names; put them back\nimputed_df.columns = df_train.columns\n\ndf_train = imputed_df","10dbb2d3":"def new_objective(seed=1, n_estimators=4500):\n    def objective(trial):\n        fold = 0\n\n        x_train = df_train[df_train.kfold != fold].reset_index(drop=True)\n        x_valid = df_train[df_train.kfold == fold].reset_index(drop=True)\n\n        y_train = x_train[TARGET]\n        y_valid = x_valid[TARGET]\n\n        x_train = x_train[features]\n        x_valid = x_valid[features]\n        \n        # standardize\n        scaler = StandardScaler()\n        x_train = scaler.fit_transform(x_train)\n        x_valid = scaler.transform(x_valid)\n        \n\n        param = {\n            \"random_state\": seed,\n            \"n_estimators\": n_estimators,\n            \"objective\": \"binary\",\n            \"metric\": \"AUC\", \n            \"verbosity\": -1,\n            \n            \"learning_rate\": trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n            \"reg_alpha\": trial.suggest_categorical(\"reg_alpha\", [1,10.0]),\n            \"reg_lambda\": trial.suggest_categorical(\"reg_lambda\", [1e-1,1e-2]),\n            \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", [0.4,0.6,0.8]),\n            \"subsample\": trial.suggest_categorical(\"subsample\", [0.4,0.6,0.8]),\n            \"subsample_freq\": trial.suggest_categorical(\"subsample_freq\", [1,2]),\n            \"max_depth\": -1,\n            \"num_leaves\" : trial.suggest_categorical(\"num_leaves\", [128,512]),\n            \"min_child_weight\" : trial.suggest_categorical(\"min_child_weight\", [128,256]),\n            \"min_child_samples\": trial.suggest_categorical(\"min_child_samples\", [20,100]),\n            \n            # optional: enable gpu\n            \"device\": \"gpu\",\n            \"gpu_platform_id\": 0,\n            \"gpu_device_id\": 0\n        }\n\n        lgb_train = lgb.Dataset(x_train, y_train)\n        lgb_valid = lgb.Dataset(x_valid, y_valid, reference=lgb_train)\n        model = lgb.train(param, lgb_train, valid_sets=[lgb_valid], \n                           early_stopping_rounds=300, verbose_eval=500)   \n        valid_preds = model.predict(x_valid)\n\n        score = roc_auc_score(y_valid, valid_preds) \n        return score\n    return objective","9f7c32a3":"n_trials = 50\nseed = 42\nprint(f\"Training with seed {seed}...\")\n\n# objective function with custom seed\nobj_func = new_objective(seed=seed)\n\nstudy_name = \"optuna_lgbm\"\nstorage_name = f\"sqlite:\/\/\/{study_name}.db\"\nstudy = optuna.create_study(direction=\"maximize\", study_name=study_name, storage=storage_name)\nstudy.optimize(obj_func, n_trials=n_trials)\n\nprint(\"Done.\")","5738c049":"study.best_params","3e76d2bb":"study.best_value","d5078250":"trials_df = study.trials_dataframe()\ntrials_df","21278f7f":"Done.","d6935db4":"We need to setup LightGBM to enable GPU acceleration.","81c8af5a":"## Load dataset","410b0aa7":"## Setup GPU for Lightgbm","e71fdd40":"# TPS September 2021 - Optuna + LGBM","ed2f45d1":"## Preprocessing","694cc7c0":"## Import libraries","1b153111":"## Training"}}