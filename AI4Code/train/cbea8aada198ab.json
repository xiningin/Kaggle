{"cell_type":{"ef4a8c15":"code","1d453b52":"code","26e61eed":"code","ecb76119":"code","b463f372":"code","78689481":"code","4008700a":"code","77423b45":"code","24af0a77":"code","80ab182c":"code","a0cbc388":"code","6c082bc1":"code","c91177a7":"code","9dfe08fe":"code","4f852d3e":"code","92baa249":"code","ed18a7f1":"code","84c2bce0":"code","09fe9554":"code","8a000e2f":"code","baf6a8a7":"code","673544c1":"code","8f8f3c86":"code","1f1e9eb1":"code","ebcfc765":"code","b80c44fe":"code","a7a4a61e":"code","7b9c3ae0":"code","f6e13d50":"markdown","c5dcbe68":"markdown","6c8b4118":"markdown","874ec211":"markdown","6be2cea4":"markdown","32d7f1f3":"markdown","fcb9a657":"markdown","0d240e4c":"markdown","a51d3728":"markdown","81a8d9ef":"markdown","e1c39250":"markdown","98047eff":"markdown","677e3e48":"markdown","ab1e885b":"markdown"},"source":{"ef4a8c15":"!pip install swifter -q","1d453b52":"\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nimport plotly.express as px\nsns.set(rc={'figure.figsize':(10,6)})\nsns.set(font_scale=1.3)\nplt.style.use('fivethirtyeight')\n\nimport re\nimport string\nimport swifter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom collections import Counter\nfrom functools import partial\n\nimport transformers\nfrom tqdm.notebook import tqdm\nfrom tokenizers import BertWordPieceTokenizer\nfrom transformers import BertTokenizer\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Embedding, BatchNormalization, Dense, TimeDistributed, Dropout, Bidirectional, Flatten, GlobalMaxPool1D\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score, classification_report, accuracy_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","26e61eed":"data = pd.read_csv('..\/input\/portuguese-sentiment-analysis\/tw_pt.csv')","ecb76119":"data.head()","b463f372":"data = data.iloc[:,1:3]\ndata.head()","78689481":"data.info()","4008700a":"fig = px.histogram(data, x='Classificacao')\nfig.update_layout(go.Layout(template=\"plotly_dark\", \n                            title={'text': \"Percentage of Type\",'y':0.9,'x':0.45,\n                                   'xanchor': 'center','yanchor': 'top'},\n                            font=dict(size=18, color='white', family=\"Courier New, monospace\"), \n                            xaxis=dict(title='Type'), yaxis=dict(title='Count')))\n\nfig.show()","77423b45":"data['Classificacao'].value_counts()","24af0a77":"values = data['Classificacao'].value_counts().values\nfig = go.Figure(data=[go.Pie(labels=['Positivo','Neutro','Negativo',], values=values)])\nfig.update_layout(template=\"plotly_dark\",title={'text': \"Percentage of Type\",'y':0.9,\n                                                'x':0.45,'xanchor': 'center','yanchor': 'top'},\n                  font=dict(size=18, color='white', family=\"Courier New, monospace\"))\nfig.show()","80ab182c":"def limpa_texto(data):\n    tx = data.apply(lambda x: re.sub(\"http\\S+\", '', str(x)))\n    tx = tx.swifter.apply(lambda x: re.sub(u'[^a-zA-Z0-9\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00e2\u00ea\u00ee\u00f4\u00c2\u00ca\u00ce\u00d4\u00e3\u00f5\u00c3\u00d5\u00e7\u00c7: ]', '',x))\n    tx = tx.swifter.apply(lambda x: re.sub(' +', ' ', x)) # remover espa\u00e7os em brancos\n    tx = tx.swifter.apply(lambda x: re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', x)) # remover as hashtag\n    tx = tx.swifter.apply(lambda x: re.sub('(@[A-Za-z]+[A-za-z0-9-_]+)', '', x)) # remover os @usuario\n    tx = tx.swifter.apply(lambda x: re.sub('rt', '', x)) # remover os rt\n    tx = tx.swifter.apply(lambda x: ''.join([i for i in x if i not in string.punctuation]))\n    return tx","a0cbc388":"data['Text'] = limpa_texto(data['Text'])\ndata.head()","6c082bc1":"print('Before:',len(data))\ndata = data.loc[(data['Text'] != ' ')]\nprint('After:', len(data))","c91177a7":"data.drop_duplicates(inplace=True)\ndata.info()","9dfe08fe":"values = data['Classificacao'].value_counts().values\nfig = go.Figure(data=[go.Pie(labels=['Positivo','Neutro','Negativo',], values=values)])\nfig.update_layout(template=\"plotly_dark\",title={'text': \"Percentage of Type\",'y':0.9,\n                                                'x':0.45,'xanchor': 'center','yanchor': 'top'},\n                  font=dict(size=18, color='white', family=\"Courier New, monospace\"))\nfig.show()","4f852d3e":"data['message_len'] = data['Text'].swifter.apply(lambda x: len(x.split(' ')))\ndata.head()","92baa249":"fig = px.histogram(data, x='message_len')\nfig.update_layout(template=\"plotly_dark\",title={'text': \"Phrase Length\",'y':0.9,\n                                                'x':0.45,'xanchor': 'center','yanchor': 'top'},\n                  font=dict(size=18, color='white', family=\"Courier New, monospace\"))\nfig.show()","ed18a7f1":"tw = np.array(Image.open('..\/input\/mascaras\/tw_img.png'))\n\ndef formato(val):\n    if val == 0:\n        return 255\n    else:\n        return val\n    \nmask_tw = np.ndarray((tw.shape[0],tw.shape[1]), np.int32)\n\nfor i in range(len(mask_tw)):\n    mask_tw[i] = list(map(formato, mask_tw[i]))\n    \nwc = WordCloud(background_color=\"white\", mask=tw, contour_width=3, contour_color='#1DA1F2')\nwc.generate(' '.join(text for text in data.loc[data['Classificacao'] == 'Positivo', 'Text']))\nwc.to_file(\"tw_img.png\")\nplt.figure(figsize=[20,10])\nplt.title('Top words Positive', fontdict={'size': 22,  'verticalalignment': 'bottom', 'color':'#1DA1F2'})\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n","84c2bce0":"tw = np.array(Image.open('..\/input\/mascaras\/tw_img.png'))\n\ndef formato(val):\n    if val == 0:\n        return 255\n    else:\n        return val\n    \nmask_tw = np.ndarray((tw.shape[0],tw.shape[1]), np.int32)\n\nfor i in range(len(mask_tw)):\n    mask_tw[i] = list(map(formato, mask_tw[i]))\n    \nwc = WordCloud(background_color=\"white\", mask=tw, contour_width=3, contour_color='#1DA1F2')\nwc.generate(' '.join(text for text in data.loc[data['Classificacao'] == 'Negativo', 'Text']))\nwc.to_file(\"tw_img.png\")\nplt.figure(figsize=[20,10])\nplt.title('Top words Negative', fontdict={'size': 22,  'verticalalignment': 'bottom', 'color':'#1DA1F2'})\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n","09fe9554":"tw = np.array(Image.open('..\/input\/mascaras\/tw_img.png'))\n\ndef formato(val):\n    if val == 0:\n        return 255\n    else:\n        return val\n    \nmask_tw = np.ndarray((tw.shape[0],tw.shape[1]), np.int32)\n\nfor i in range(len(mask_tw)):\n    mask_tw[i] = list(map(formato, mask_tw[i]))\n    \nwc = WordCloud(background_color=\"white\", max_words=1000, mask=tw, contour_width=3, contour_color='#1DA1F2')\nwc.generate(' '.join(text for text in data.loc[data['Classificacao'] == 'Neutro', 'Text']))\nwc.to_file(\"tw_img.png\")\nplt.figure(figsize=[20,10])\nplt.title('Top words Neutral', fontdict={'size': 22,  'verticalalignment': 'bottom', 'color':'#1DA1F2'})\nplt.imshow(wc, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n","8a000e2f":"tk = Tokenizer(num_words=32)\ntk.fit_on_texts(data['Text'])\nx = tk.texts_to_sequences(data['Text'])","baf6a8a7":"x = pad_sequences(x, padding='post')","673544c1":"le = LabelEncoder()\nle.fit(data['Classificacao'])\ny = le.fit_transform(data['Classificacao'])","8f8f3c86":"x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y)","1f1e9eb1":"max_palavra = 100\nembedding_dim = 30 ","ebcfc765":"adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\nmodel = Sequential()\nmodel.add(Embedding(max_palavra, embedding_dim, input_length=len(x[0])))\nmodel.add(Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.2)))\nmodel.add(GlobalMaxPool1D())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1, activation='softmax'))\nmodel.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])","b80c44fe":"checkpoint = ModelCheckpoint('model.hr', monito='val_loss', verbose=1, save_best_only=True)\nreduce = ReduceLROnPlateau(monitor='val_loss', factor=.5, verbose=1, patience=5, min_lr=0.001)\nstoped = EarlyStopping(monitor='val_loss', patience=7, min_delta=0.0001)","a7a4a61e":"history = model.fit(x_train, y_train, epochs=30, batch_size=32, validation_data=(x_test, y_test), verbose=1, callbacks=[checkpoint, reduce, stoped])","7b9c3ae0":"fig, axes = plt.subplots(1, 2, figsize=(15,5))\naxes[0].plot(history.history['accuracy'])\naxes[0].plot(history.history['val_accuracy'])\naxes[0].set_xlabel('Epochs')\naxes[0].set_ylabel('Acur\u00e1cia')\naxes[0].legend(['Acur\u00e1cia em Treino','Acur\u00e1cia em Teste'])\naxes[0].grid(True)\n\naxes[1].plot(history.history['loss'])\naxes[1].plot(history.history['val_loss'])\naxes[1].set_xlabel('Epochs')\naxes[1].set_ylabel('Erro')\naxes[1].legend(['Erro em Treino','Erro em Teste'])\naxes[1].grid(True)","f6e13d50":"# <p style=\"background-color:#e4e7eb; font-family:newtimeroman; font-size:120%; text-align:center; color:#0091ff; border-radius: 20px 20px; padding-top:8px; padding-bottom:8px;\">Callback<\/p>","c5dcbe68":"# <p style=\"background-color:#e4e7eb; font-family:newtimeroman; font-size:120%; text-align:center; color:#0091ff; border-radius: 20px 20px; padding-top:8px; padding-bottom:8px;\">Token<\/p>","6c8b4118":"# <p style=\"background-color:#66ccff; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  80px 5px; padding-top:8px; padding-bottom:8px;\">LSTM<\/p>","874ec211":"<div style=\"color:black; background-color:#f5f7b0; border-radius:10px; padding:20px;\">\n<b>Conclusion<\/b><br\/>\nThe model can't learn to preditc classes.<br\/>\n<\/div>","6be2cea4":"<div style=\"color:black; background-color:#f5f7b0; border-radius:10px; padding:20px;\">\nThe data set contains 4 blank lines after the data has been cleared.\n<\/div>","32d7f1f3":"# <p style=\"background-color:#66ccff; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  80px 5px; padding-top:8px; padding-bottom:8px;\">Preprocessing<\/p>","fcb9a657":"# <p style=\"background-color:#66ccff; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  80px 5px; padding-top:8px; padding-bottom:8px;\">Sentiment Analysis Portuguese<\/p>","0d240e4c":"<div style=\"color:black; background-color:#f5f7b0; border-radius:10px; padding:20px;\">\nAs we can see we have a lot of duplicate values, the dataset starts with 8199 rows after we have cleared that we have 3626 rows. In addition, the datast is unbalanced.\n<\/div>","a51d3728":"\n# <p style=\"background-color:#e4e7eb; font-family:newtimeroman; font-size:120%; text-align:center; color:#0091ff; border-radius: 20px 20px; padding-top:8px; padding-bottom:8px;\">Train and Test<\/p>","81a8d9ef":"# <p style=\"background-color:#e4e7eb; font-family:newtimeroman; font-size:120%; text-align:center; color:#0091ff; border-radius: 20px 20px; padding-top:8px; padding-bottom:8px;\">Model<\/p>","e1c39250":"\n# <p style=\"background-color:#e4e7eb; font-family:newtimeroman; font-size:120%; text-align:center; color:#0091ff; border-radius: 20px 20px; padding-top:8px; padding-bottom:8px;\">Encoder<\/p>","98047eff":"# <p style=\"background-color:#e4e7eb; font-family:newtimeroman; font-size:120%; text-align:center; color:#0091ff; border-radius: 20px 20px; padding-top:8px; padding-bottom:8px;\">Padding<\/p>","677e3e48":"# <p style=\"background-color:#66ccff; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  80px 5px; padding-top:8px; padding-bottom:8px;\">Continuous with BERT<\/p>","ab1e885b":"# <p style=\"background-color:#66ccff; font-family:newtimeroman; font-size:150%; text-align:center; border-radius:  80px 5px; padding-top:8px; padding-bottom:8px;\">WordCloud<\/p>"}}