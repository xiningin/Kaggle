{"cell_type":{"d6c1a6d4":"code","6768ec83":"code","6e4f79f5":"code","f475ae09":"code","03a3486e":"code","a842b243":"code","d9a4e407":"code","5417bf19":"code","d9787a9d":"code","de0fb4f5":"code","dd46deb8":"code","020ab32f":"code","d9b5f7ce":"code","56c52ca2":"code","c90289dd":"code","e138a7e4":"code","e373024c":"code","2e9c2be6":"code","99f780e5":"code","43017a89":"code","2faef174":"code","ce59b844":"code","162ec325":"code","68d0bba7":"code","0c048714":"code","2f05fd4f":"markdown"},"source":{"d6c1a6d4":"%matplotlib notebook\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","6768ec83":"# load data\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","6e4f79f5":"train.info(), test.info()","f475ae09":"# set \"PassengerId\" variable as index\ntrain.set_index(\"PassengerId\", inplace=True)\ntest.set_index(\"PassengerId\", inplace=True)","03a3486e":"test.head()","a842b243":"# generate training target set (y_train)\ny_train = train[\"Survived\"]","d9a4e407":"# delete column \"Survived\" from train set\ntrain.drop(labels=\"Survived\", axis=1, inplace=True)","5417bf19":"# shapes of train and test sets\ntrain.shape, test.shape","d9787a9d":"# join train and test sets to form a new train_test set\ntrain_test =  train.append(test)","de0fb4f5":"# delete columns that are not used as features for training and prediction\ncolumns_to_drop = [\"Name\", \"Age\", \"SibSp\", \"Ticket\", \"Cabin\", \"Parch\", \"Embarked\"]\ntrain_test.drop(labels=columns_to_drop, axis=1, inplace=True)","dd46deb8":"# convert objects to numbers by pandas.get_dummies\ntrain_test_dummies = pd.get_dummies(train_test, columns=[\"Sex\"])","020ab32f":"# check the dimension\ntrain_test_dummies.shape","d9b5f7ce":"train_test_dummies.head()","56c52ca2":"# replace nulls with 0.0\ntrain_test_dummies.fillna(value=0.0, inplace=True)","c90289dd":"# generate feature sets (X)\nX_train = train_test_dummies.values[0:891]\nX_test = train_test_dummies.values[891:]","e138a7e4":"X_train.shape, X_test.shape","e373024c":"# transform data\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train_scale = scaler.fit_transform(X_train)\nX_test_scale = scaler.transform(X_test)","2e9c2be6":"# split training feature and target sets into training and validation subsets\nfrom sklearn.model_selection import train_test_split\n\nX_train_sub, X_validation_sub, y_train_sub, y_validation_sub = train_test_split(X_train_scale, y_train, random_state=0)","99f780e5":"# import machine learning algorithms\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc","43017a89":"# train with Gradient Boosting algorithm\n# compute the accuracy scores on train and validation sets when training with different learning rates\n\nlearning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\nfor learning_rate in learning_rates:\n    gb = GradientBoostingClassifier(n_estimators=20, learning_rate = learning_rate, max_features=2, max_depth = 2, random_state = 0)\n    gb.fit(X_train_sub, y_train_sub)\n    print(\"Learning rate: \", learning_rate)\n    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train_sub, y_train_sub)))\n    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_validation_sub, y_validation_sub)))\n    print()","2faef174":"# Output confusion matrix and classification report of Gradient Boosting algorithm on validation set\n\ngb = GradientBoostingClassifier(n_estimators=20, learning_rate = 0.5, max_features=2, max_depth = 2, random_state = 0)\ngb.fit(X_train_sub, y_train_sub)\npredictions = gb.predict(X_validation_sub)\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_validation_sub, predictions))\nprint()\nprint(\"Classification Report\")\nprint(classification_report(y_validation_sub, predictions))","ce59b844":"# ROC curve and Area-Under-Curve (AUC)\n\ny_scores_gb = gb.decision_function(X_validation_sub)\nfpr_gb, tpr_gb, _ = roc_curve(y_validation_sub, y_scores_gb)\nroc_auc_gb = auc(fpr_gb, tpr_gb)\n\nprint(\"Area under ROC curve = {:0.2f}\".format(roc_auc_gb))","162ec325":"from sklearn.linear_model import LogisticRegression\n","68d0bba7":"# Output confusion matrix and classification report of Logistic Regression on validation set\n\nlr = LogisticRegression()\nlr.fit(X_train_sub, y_train_sub)\npredictions = lr.predict(X_validation_sub)\n\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_validation_sub, predictions))\nprint()\nprint(\"Classification Report\")\nprint(classification_report(y_validation_sub, predictions))","0c048714":"# ROC curve and Area-Under-Curve (AUC)\n\ny_scores_lr = lr.decision_function(X_validation_sub)\nfpr_lr, tpr_lr, _ = roc_curve(y_validation_sub, y_scores_lr)\nroc_auc_lr = auc(fpr_lr, tpr_lr)\n\nprint(\"Area under ROC curve = {:0.2f}\".format(roc_auc_lr))","2f05fd4f":"#**Data preparation: **\n1. Removed columns \"Name\", \"Age\", \"SibSp\", \"Ticket\", \"Cabin\",  \"Parch\", and \"Embarked\".\n2. Convert objects to numbers with pandas.get_dummies.\n3. Filled nulls with a value of 0.0.\n4. Transformed data with MinMaxScaler() method.\n5. Randomly splited training set into train and validation subsets.\n\n#**Training Gradient Boosting classifier:**\n1. Computed the accuracy scores on train and validation sets when training with different learning rates. When learning rate was 0.5, the accuracy scores on training and validation subsets were 0.829 and 0.830, respectively.\n2. Trained Gradient Boosting classifier on training subset with parameters of criterion=\"mse\", n_estimators=20, learning_rate = 0.5, max_features=2, max_depth = 2, random_state = 0.  The average precision, recall, and  f1-scores on validation subsets were 0.83, 0.83, and 0.82, respectively. The area under ROC (AUC) was 0.88."}}