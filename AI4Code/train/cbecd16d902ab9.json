{"cell_type":{"05a7aae8":"code","6bb6c2f8":"code","c6c6a374":"code","39ed9c8a":"code","2158748b":"code","a934e70f":"code","f6f15f04":"code","615ff1d7":"code","f8fd8d7d":"code","6475ec3a":"code","e7ac612c":"code","48ae4d4a":"code","e14e2b15":"code","fc3094d9":"code","cd3ffe4b":"code","9b5f004b":"code","74ec44af":"code","27f84c44":"code","a7eae813":"code","5eb89ac9":"code","eae2bcca":"code","01781e8b":"markdown","917f19f9":"markdown","3b79ab67":"markdown","15d1e847":"markdown","3b17738f":"markdown","00ef2456":"markdown","2f1766c2":"markdown","f60458cc":"markdown","304ef092":"markdown","5bd06b42":"markdown","933e4d7c":"markdown","3f5ef214":"markdown","f188d435":"markdown","c1b10555":"markdown"},"source":{"05a7aae8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\nimport seaborn as sns\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6bb6c2f8":"import os\nimport cv2 as cv\nimport numpy as np\nimport pandas as pd \nfrom glob import glob\nfrom tensorflow import keras\nfrom keras.layers import Conv2D\nimport matplotlib.pyplot as plt\nfrom keras.models import load_model\nfrom tensorflow.keras.models import load_model\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay","c6c6a374":"train_image_0_df = pd.read_parquet(f'..\/input\/bengaliai-cv19\/train_image_data_0.parquet')","39ed9c8a":"train_tabular_df = pd.read_csv('..\/input\/bengaliai-cv19\/train.csv')","2158748b":"train_image_0_df.info()","a934e70f":"train_tabular_df.info()","f6f15f04":"train_image_0_df.shape","615ff1d7":"train_tabular_df.shape","f8fd8d7d":"train_image_0_df.head()","6475ec3a":"train_tabular_df.head()","e7ac612c":"train_tabular_df.nunique()","48ae4d4a":"train_data =  pd.merge(train_image_0_df, train_tabular_df, on='image_id').drop(['image_id'], axis=1)","e14e2b15":"train_data.shape","fc3094d9":"train_labels = train_data[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic','grapheme']]\ntrain_labels.shape","cd3ffe4b":"train_data = train_data.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic','grapheme'], axis=1)\ntrain_data.shape","9b5f004b":"def resize(df, size=64, need_progress_bar=True):\n    resized = {}\n    for i in range(df.shape[0]):\n        image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n        resized[df.index[i]] = image.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized","74ec44af":"train_data = resize(train_data, size=64)\/255\ntrain_data = train_data.values.reshape(-1, 64, 64, 1)","27f84c44":"model_dict = {\n    'grapheme_root': Sequential(),\n    'vowel_diacritic': Sequential(),\n    'consonant_diacritic': Sequential()\n}\nfor model_type, model in model_dict.items():\n    model.add(Conv2D(input_shape=(64,64,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n    model.add(layers.BatchNormalization(momentum=0.15))\n    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n    model.add(Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(128, 3, activation=\"relu\", padding=\"same\"))\n    model.add(MaxPool2D(2))\n    model.add(Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n    model.add(Conv2D(256, 3, activation=\"relu\", padding=\"same\"))\n    model.add(MaxPool2D(2))\n    model.add(Flatten())\n    model.add(Dense(1024, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(512, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    if model_type == 'grapheme_root':\n        model.add(layers.Dense(168, activation='softmax', name='root_out'))\n    elif model_type == 'vowel_diacritic':\n        model.add(layers.Dense(11, activation='softmax', name='vowel_out'))\n    elif model_type == 'consonant_diacritic':\n        model.add(layers.Dense(7, activation='softmax', name='consonant_out'))\n    model.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\n    \nplot_model(model_dict['grapheme_root'])","a7eae813":"batch_size = 32\nepochs = 500\nhistory_list = []\nmodel_types = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\nfor target in model_types:\n    Y_train = train_labels[target]\n    Y_train = pd.get_dummies(Y_train).values\n    x_train, x_test, y_train, y_test = train_test_split(train_data, Y_train, test_size=0.1, random_state=123)\n    datagen = ImageDataGenerator()\n    datagen.fit(x_train)\n    history = model_dict[target].fit(datagen.flow(x_train, y_train, batch_size=batch_size), \n                                               epochs = epochs, validation_data = (x_test, y_test))\n    history_list.append(history)","5eb89ac9":"model.save('.\/submission.csv')","eae2bcca":"for history in history_list:\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","01781e8b":"En los comandos anteriores es posible observar que `train_image_0_df` posee 50210 im\u00e1genes. Entre sus columnas se observa el `image_id` y los p\u00edxeles de cada una de las im\u00e1genes.\n\nSi restamos de las 32333 columnas el `image_id`, s\u00f3lo restan las columnas que se corresponden a los 137x236 p\u00edxeles de cada imagen, tal como se informa en la seci\u00f3n [data](https:\/\/www.kaggle.com\/c\/bengaliai-cv19\/data) de la documentaci\u00f3n.","917f19f9":"## 3. Ingenier\u00eda de _features_\n\n### 3.1. Fusi\u00f3n de los _dataframes_\n\nEs necesario contar con un \u00fanico conjunto de datos, hasta ahora se tienen las im\u00e1genes y las etiquetas en tablas diferentes. Adem\u00e1s, debido a que no se est\u00e1n utilizando todas las im\u00e1genes (por falta de memoria), es necesario descartar las etiquetas que no perteneces a una imagen dentro de `train_image_0_df`","3b79ab67":"### 2.2. Valores \u00fanicos por columna\n","15d1e847":"## 4. Modelo\n\nDebido a que los grafemas est\u00e1n compuestos por 3 componentes, se decidi\u00f3 entrenar 3 modelos con la misma estructura. El entrenamiento de cada uno de los modelos est\u00e1 enfocado a cada uno de las componentes del grafema.\n\nLa \u00fanica diferencia que hay entre los modelos es la capa de salida. Si bien todos terminan con una activaci\u00f3n _softmax_, cada uno lo hace con la cantidad de salidas correspondientes al n\u00famero de valores \u00fanicos que tiene cada componente. ","3b17738f":"### 4.2. Visualizaci\u00f3n del avance de las m\u00e9tricas en entrenamiento","00ef2456":"## 5. Conclusiones\n\nDespu\u00e9s de hacer repetidas pruebas, se concluye que:\n\n1. El modelo da mejores resultados cuando se entrena para decidir entre menos categor\u00edas. Para el caso de los 168 _grapheme roots_, el modelo tiene su peor _performance_.\n1. La capa `BatchNormalization` tiene un gran impacto en el _accuracy_.\n1. VGG16 no llega a los resultados obtenidos con esta red.\n1. 64x64 parece ser un tama\u00f1o razonable para las im\u00e1genes. Las pruebas con 96x96 y 128x128 resultaron en memoria insuficiente.\n1. Trabajar en colab no fue posible por la cantidad de memoria necesaria.\n1. Trabajar en _hardware_ local (sin GPU) resulta en entrenamientos de casi 3 horas, lo que dificulta el desarrollo.","2f1766c2":"### 4.1. Entrenamiento de los modelos\n\nIterando sobre el diccionario de modelos es posible realizar el entrenamiento de los 3 modelos para detectar las componentes de cada grafema.\n\nCabe se\u00f1alar algunos aspectos importantes del entrenamiento:\n\n1. Se utiliza un `ImageDataGenerator` para hacer _data augmentation_.\n1. Antes de entrenar a cada modelo se divide el _dataset_ en _train_ y _test_, de forma aleatoria, dejando el 10% de las filas para _test_.\n1. El hist\u00f3rico de la evoluci\u00f3n de las m\u00e9tricas se guarda en una lista.","f60458cc":"Al momento de llamar el m\u00e9todo `resize()`, tambi\u00e9n se divide por 255 para obtener valores decimales en cada p\u00edxel. Esto permite que, durante el entrenamiento, se interprete correctamente la naturaleza del n\u00famero como indicador de la intensidad de cada p\u00edxel.","304ef092":"Cabe destacar la cantidad de valores \u00fanicos para cada una de las columnas. Pues esto definir\u00e1 el tipo y cantidad de salidas de la red neuronal.","5bd06b42":"# _Bengali.AI Handwritten Grapheme Classification_\n\nEn el siguiente trabajo se aborda la resoluci\u00f3n del problema planteado para la clasificaci\u00f3n de los componentes de grafemas benagal\u00edes. \n\nPara m\u00e1s informaci\u00f3n [ingrese aqu\u00ed](https:\/\/www.kaggle.com\/c\/bengaliai-cv19)\n\n## 1. Importar m\u00f3dulos y cargar _dataset_","933e4d7c":"## 2. An\u00e1lisis exploratorio\n\nPara conseguir un entendimiento del problema, primero vamos a avanzar analizando las generalidades de los _dataframes_ que se cargaron en memoria. \n\n### 2.1. Informaci\u00f3n de los _dataframes_","3f5ef214":"En la lista podemos ver los archivos que conforman el _dataset_ propuesto para este problema. En nuestro caso s\u00f3lo utilizaremos el archivo `train_image_data_0.parquet` y el archivo `train.csv` para el entrenamiento.","f188d435":"### 3.2. Separar las variables independientes (_features_) de las salidas (_labels_)","c1b10555":"### 3.3. Redimensionar las im\u00e1genes\n\nLamentablemente, es necesario redimiensionar las im\u00e1genes para que sea posible procesarlas con el _hardware_ disponible. Adem\u00e1s, esto acelera el proceso de ensayo. Es probable que, una vez definido el modelo, valga la pena hace pruebas con im\u00e1genes m\u00e1s grandes."}}