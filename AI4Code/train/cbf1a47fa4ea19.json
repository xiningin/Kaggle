{"cell_type":{"08f540a2":"code","d9b65e3c":"code","76aa1f06":"code","44c40d20":"code","3c3e1b45":"code","f3cf130a":"code","a0812f69":"code","03060744":"code","3a74b07f":"code","6b30719a":"code","3f6699e2":"code","9e204db6":"code","c3dbcc2d":"code","8143b6a1":"code","b7fec9bb":"code","a467761a":"code","98f1ef4b":"code","a62e9a35":"code","996f2f67":"code","402d3144":"code","92798df3":"code","eb8b371c":"code","edca2029":"code","efb15cd3":"code","5649b14f":"code","d5b2e7ea":"code","5649681a":"markdown","0376e04d":"markdown","fb5264bd":"markdown","626b48c8":"markdown"},"source":{"08f540a2":"from sklearn.model_selection import train_test_split\nimport cv2\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.preprocessing.image import img_to_array","d9b65e3c":"import numpy as np\nimport pandas as pd\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","76aa1f06":"train_df=pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest_df=pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/test.csv')","44c40d20":"# train_df.head()","3c3e1b45":"target_df = train_df[['healthy', 'multiple_diseases', 'rust', 'scab']]\ntest_ids = test_df['image_id']","f3cf130a":"img_size = 224","a0812f69":"train_imgs = []\n\nfor name in train_df['image_id']:\n    path = '..\/input\/plant-pathology-2020-fgvc7\/images\/' + name + '.jpg'\n    img = cv2.imread(path)\n    image = cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n    train_imgs.append(image)","03060744":"fig, ax = plt.subplots(1, 4, figsize=(15, 15))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(train_imgs[i])","3a74b07f":"test_imgs = []\nfor name in test_df['image_id']:\n    path = '..\/input\/plant-pathology-2020-fgvc7\/images\/' + name + '.jpg'\n    img = cv2.imread(path)\n    image = cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n    test_imgs.append(image)","6b30719a":"fig, ax = plt.subplots(1, 4, figsize=(15, 15))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(test_imgs[i])    ","3f6699e2":"X_train = np.ndarray(shape=(len(train_imgs), img_size, img_size, 3),dtype = np.float32)\n\nfor i, image in enumerate(train_imgs):\n    X_train[i] = img_to_array(image)\n    X_train[i] = train_imgs[i]\n\nX_train = X_train\/255\nprint('Train Shape: {}'.format(X_train.shape))","9e204db6":"X_test = np.ndarray(shape=(len(test_imgs), img_size, img_size, 3),dtype = np.float32)\n\nfor i, image in enumerate(test_imgs):\n    X_test[i] = img_to_array(image)\n    X_test[i] = test_imgs[i]\n    \nX_test = X_test\/255\nprint('Test Shape: {}'.format(X_test.shape))","c3dbcc2d":"y_train = train_df.copy()\ndel y_train['image_id']\ny_train.head()","8143b6a1":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\nX_train.shape, X_val.shape","b7fec9bb":"from keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n\nlr_reduce=ReduceLROnPlateau(monitor='val_accuracy',\n                            factor=.5,\n                            patience=2,\n                            mode='max',\n                            min_lr=.000001,\n                            verbose=1)\n\nes_monitor=EarlyStopping(monitor='val_loss',\n                          patience=8)\n\nmdl_check = ModelCheckpoint('best_model.h5', \n                            monitor='accuracy', \n                            verbose=0, \n                            save_best_only=True, \n                            mode='max')","a467761a":"from tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# reg = 0.0005\n\n# net = InceptionResNetV2(weights= 'imagenet', include_top=False, input_shape= (img_size,img_size,3))\n# x = net.output\n# x = GlobalAveragePooling2D()(x)\n# x = Dense(128, activation=\"relu\")(x)\n# x = Dropout(0.5)(x)\n# x = Dense(64, activation=\"relu\")(x)\n# x = Dense(32, activation=\"relu\")(x)\n# predictions = Dense(4, activation= 'softmax')(x)\n# model = Model(inputs = net.input, outputs = predictions)\n\n# model.summary()","98f1ef4b":"!pip install image-classifiers==1.0.0b1","a62e9a35":"!pip install keras_applications ","996f2f67":"from classification_models.tfkeras import Classifiers\n\nseresnet50, _ = Classifiers.get('seresnet50')\nnet =  seresnet50(weights = 'imagenet', include_top = False, input_shape = (img_size,img_size,3))","402d3144":"# from tensorflow.keras.models import Model\n# from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n\nx = net.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(128, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dense(32, activation=\"relu\")(x)\npredictions = Dense(4, activation= 'softmax')(x)\nmodel = Model(inputs = net.input, outputs = predictions)\n\nmodel.summary()","92798df3":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","eb8b371c":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rotation_range=45,\n                            shear_range=.25,\n                            zoom_range=.25,\n                            width_shift_range=.25,\n                            height_shift_range=.25,\n                            rescale=1\/255,\n                            brightness_range=[.5,1.5],\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            fill_mode='nearest')","edca2029":"history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=24),\n                              epochs = 50,\n                             steps_per_epoch = X_train.shape[0] \/\/ 24,\n                              verbose = 1,\n                              callbacks = [es_monitor,lr_reduce, mdl_check],\n                              validation_data = datagen.flow(X_val, y_val,batch_size=24),\n                              validation_steps = X_val.shape[0] \/\/24)","efb15cd3":"h = history.history\n\noffset = 3\nepochs = range(offset, len(h['loss']))\n\nplt.figure(1, figsize=(12, 12))\n\nplt.subplot(211)\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.plot(epochs, h['loss'][offset:], label='train')\nplt.plot(epochs, h['val_loss'][offset:], label='val')\nplt.legend()\n\nplt.subplot(212)\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.plot(h[f'accuracy'], label='train')\nplt.plot(h[f'val_accuracy'], label='val')\nplt.legend()\n\nplt.show()","5649b14f":"y_pred = model.predict(X_test)","d5b2e7ea":"sub_df = pd.read_csv('..\/input\/plant-pathology-2020-fgvc7\/sample_submission.csv')\nsub_df.loc[:, 'healthy':] = y_pred\nsub_df.to_csv('submission.csv', index=False)\nsub_df.head()","5649681a":"**Split training set**","0376e04d":"**Image processing**","fb5264bd":"**Set Callbacks**","626b48c8":"**Image Data Augmentation and fit model**"}}