{"cell_type":{"2facc1a8":"code","48059ff1":"code","f72601a5":"code","a85e0a34":"code","ebb134fc":"code","6269319a":"code","79fd23c8":"code","69964f38":"code","cc57117e":"code","43937945":"code","4eac1677":"markdown","c4fdf803":"markdown","1ccd7c56":"markdown","7451dcce":"markdown","3004becd":"markdown","3a3529f7":"markdown","7b6b53d1":"markdown"},"source":{"2facc1a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","48059ff1":"import matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tensorflow import keras as k\nfrom keras.utils import np_utils\nimport cv2\nfrom PIL import Image\nfrom keras.preprocessing.image import img_to_array, ImageDataGenerator\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Activation, MaxPooling2D, Flatten, Conv2D, Dropout, Dense","f72601a5":"X=[]\ny=[]\n\n# Since there are subfolders inside the input directory, we've used nested loops\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        path=os.path.join(dirname, filename) \n        \n# Preprocessing the image:\n# - read image\n        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n# - Adaptive Threshold: For every pixel, the same threshold value is applied. If the pixel value\n# is smaller than the threshold, it is set to 0, otherwise it is set to a maximum value\n# It removes the greyish tinge off the image.\n        image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\n  \n# - Closing: It is useful in closing small holes inside the foreground objects, \n# or small black points on the object\n        kernel = np.ones((5,5),np.uint8)\n        image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n        \n# - Dilation: So it increases the white region in the image or \n# size of foreground object increases\n        kernel = np.ones((2,2),np.uint8)\n        image = cv2.dilate(image, kernel, iterations = 1)\n \n# - Blur: As in one-dimensional signals, images also can be filtered with various low-pass filters (LPF), high-pass filters (HPF), etc.\n# LPF helps in removing noise, blurring images, etc. HPF filters help in finding edges in images.\n        image = cv2.GaussianBlur(image, (5,5), 0)\n \n\n# Splitting up the image into sections of each character\n        x=[image[10:50,30:50],image[10:50,50:70],\n                 image[10:50,70:90],image[10:50,90:110],image[10:50,110:130]]\n\n# Labelling segments with the image name\n        for i in range(5):\n            X.append(img_to_array(Image.fromarray(x[i])))\n            y.append(path[len(path)-9:len(path)-4][i])\nX=np.array(X)\ny=np.array(y)","a85e0a34":"X=X.astype('float32')\nX\/=255\n\ny_le = LabelEncoder().fit_transform(y)\ny_ohe = OneHotEncoder(sparse = False).fit_transform(y_le.reshape(len(y_le),1))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y_ohe, test_size = 0.2, random_state = 42)\n\nrow, col = X.shape[1],X.shape[2]\ncategories = y_ohe.shape[1]\n\ninfo = {y_le[i] : y[i] for i in range(len(y))}","ebb134fc":"model = Sequential()\n\nmodel.add(Conv2D(filters=16,kernel_size=(3,3), padding='same', input_shape=(row,col,1)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters=16,kernel_size=(3,3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters=32,kernel_size=(3,3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\nmodel.add(Conv2D(filters=32,kernel_size=(3,3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\n\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1500))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(categories))\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = 'adam' ,\n              metrics = ['accuracy'])\n\nprint(model.summary())","6269319a":"batch_size = 150\nepochs = 200\n\nhistory = model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          validation_data=(X_test, y_test),\n          shuffle=True)","79fd23c8":"scores = model.evaluate(X_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","69964f38":"def pred (img_path) :\n    \n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    \n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    plt.show()\n    \n    image = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\n    image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 145, 0)\n    kernel = np.ones((5,5),np.uint8)\n    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n    kernel = np.ones((2,2),np.uint8)\n    image = cv2.dilate(image, kernel, iterations = 1)\n    image = cv2.GaussianBlur(image, (5,5), 0)\n    \n    \n    x = [image[10:50, 30:50], image[10:50, 50:70], image[10:50, 70:90],\n                  image[10:50, 90:110], image[10:50, 110:130]]\n    \n    X_pred = []\n    for i in range(5) :\n        X_pred.append(img_to_array(Image.fromarray(x[i])))\n    \n    X_pred = np.array(X_pred)\n    X_pred\/= 255.0\n    \n    y_pred = model.predict(X_pred)\n    y_pred = np.argmax(y_pred, axis = 1)\n    \n    print('Prediction: ', end='')\n    for res in y_pred :\n        print(info[res], end='')\n        \n    print('\\nActual:    ', img_path[len(img_path)-9:len(img_path)-4])","cc57117e":"pred('..\/input\/captcha-version-2-images\/samples\/245y5.png')","43937945":"model.save('captcha_recognizer.h5')","4eac1677":"# Evaluating performance of the model","c4fdf803":"# Import required libraries","1ccd7c56":"# Scaling X values; Label Encoding and One Hot Encoding the labels","7451dcce":"# Prediction Function:\n\n**The purpose of this function is to process raw images into model-comprehensible data for better prediction. As we've done in data preprocessing**","3004becd":"# Creating the CNN architecture","3a3529f7":"# Fitting and training data into model","7b6b53d1":"# Loading Dataset and Preprocessing\n\n[Image Thresholding](https:\/\/docs.opencv.org\/3.4\/d7\/d4d\/tutorial_py_thresholding.html)\n\n[Closing, Dilation](https:\/\/docs.opencv.org\/4.x\/d9\/d61\/tutorial_py_morphological_ops.html)\n\n[Gaussian Blur](https:\/\/docs.opencv.org\/3.4\/d4\/d13\/tutorial_py_filtering.html)"}}