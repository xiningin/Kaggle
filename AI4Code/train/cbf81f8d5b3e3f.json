{"cell_type":{"9bff11cf":"code","b9bd346a":"code","d2f0fe7f":"code","b16c147f":"code","c3a569c1":"code","b88bfaab":"code","d3d6a5c0":"code","6bbcb614":"code","55c622fd":"code","444b3a55":"markdown","8bede966":"markdown","7d5ff9c6":"markdown","b88424a1":"markdown","0943675e":"markdown"},"source":{"9bff11cf":"! conda install -y gdown","b9bd346a":"! gdown --id 1yypMeJQFpLrFsO9QuQJPYZ59oe5erO_w","d2f0fe7f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.cluster import DBSCAN\nfrom tqdm.notebook import tqdm","b16c147f":"mall_data = pd.DataFrame(pd.read_csv(\".\/Mall_Customers.csv\"))\n\nprint(\"Shape of mall data = \", mall_data.shape)","c3a569c1":"mall_data.head()","b88bfaab":"X = mall_data.iloc[:, [3,4]].values\n\nprint(\"Shape of X = \", X.shape)\nprint(\"Type = \", type(X))","d3d6a5c0":"plt.figure(figsize  = (12, 8))\nplt.scatter(X[:, 0], X[:, 1], s = 100, c = 'black', label = 'Unclustered Data')\nplt.title(\"Data Points | Pre-Clustering\", fontsize = 18)\nplt.xlabel(\"x1 = Annual Income\", fontsize = 16)\nplt.ylabel(\"x2 = Spending Score\", fontsize = 16)\nplt.grid(True)\nplt.minorticks_on()\nplt.grid(which = \"major\", linestyle = \"-\", linewidth = '1.0', color = \"grey\")\nplt.grid(which = \"minor\", linestyle = \":\", linewidth = '0.5', color = \"black\")\nplt.legend()","6bbcb614":"def perform_clustering(X, epsilon_neighbourhood, min_pts) : \n    \"\"\"\n    performs density based clustering | via DBSCAN\n    \"\"\"\n    print(\"epsilon neighbourhod chosen = \", epsilon_neighbourhood)\n    print(\"min points undertaken = \", min_pts)\n    \n    clustering = DBSCAN(eps = epsilon_neighbourhood, min_samples = min_pts, metric = 'euclidean', algorithm = 'kd_tree').fit(X)\n    labels = clustering.labels_\n    \n    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n    n_noise = list(labels).count(-1)\n    print(\"Number of clusters formed = \", n_clusters)\n    print(\"Noise points observed = \", n_noise)\n    \n    unique_labels = set(labels)\n    colors = [plt.cm.Spectral(val) for val in np.linspace(0, 1, len(unique_labels))]\n    \n    plt.figure(figsize = (12, 8))\n    plt.title(\"Data Points | Post-Clustering\", fontsize = 18)\n    for label, color in zip(unique_labels, colors) : \n        if label == -1 : # noise \n            color = [0,0,0,1]\n        plt.scatter(X[labels == label, 0], X[labels == label, 1], s = 100, c = color)\n        plt.xlabel(\"x1 = Annual Income\", fontsize = 16)\n        plt.ylabel(\"x2 = Spending Score\", fontsize = 16)\n        plt.grid(True)\n        plt.minorticks_on()\n        plt.grid(which = \"major\", linestyle = \"-\", linewidth = '1.0', color = \"grey\")\n        plt.grid(which = \"minor\", linestyle = \":\", linewidth = '0.5', color = \"black\")","55c622fd":"perform_clustering(X, epsilon_neighbourhood = 7, min_pts = 2) ","444b3a55":"* Good article for DBSCAN : \n    * **https:\/\/www.geeksforgeeks.org\/dbscan-clustering-in-ml-density-based-clustering\/**\n    * **https:\/\/towardsdatascience.com\/how-dbscan-works-and-why-should-i-use-it-443b4a191c80**\n    \n* Dataset available at : **https:\/\/drive.google.com\/file\/d\/1yypMeJQFpLrFsO9QuQJPYZ59oe5erO_w\/view?usp=sharing**","8bede966":"## The Algorithm : \n\nThe main idea behind DBSCAN is that a point belongs to a cluster if it is close to many points from that cluster.\nThere are two key parameters of DBSCAN:\n\n* **eps**: The distance that specifies the neighborhoods. Two points are considered to be neighbors if the distance between them are less than or equal to eps.\n* **minPts** : Minimum number of data points to define a cluster.\n\nBased on these two parameters, points are classified as core point, border point, or outlier:\n\n* **Core point** : A point is a core point if there are at least minPts number of points (including the point itself) in its surrounding area with radius eps.\n* **Border point** : A point is a border point if it is reachable from a core point and there are less than minPts number of points within its surrounding area.\n* **Outlier** : A point is an outlier if it is not a core point and not reachable from any core points.","7d5ff9c6":"## Why DBSCAN ? \n\nPartition-based and hierarchical clustering techniques are highly efficient with normal shaped clusters. However, when it comes to arbitrary shaped clusters or detecting outliers, density-based techniques are more efficient.\n\nFor example, the dataset in the figure below can easily be divided into three clusters using k-means algoritm.\n\n![image.png](attachment:image.png)","b88424a1":"# Density-Based Spatial Clustering with Noise [DBSCAN]\n\n![image.png](attachment:image.png) \n\n## Data Mining Track - Book II\n\n___________________\nPrevious works : \n\nData Mining Track - Book I : Agglomerative Clustering - **https:\/\/www.kaggle.com\/fireheart7\/agglomerative-clustering**\n----------------------","0943675e":"However, consider this : \n\n![image.png](attachment:image.png)\n\nThe data points in these figures are grouped in arbitrary shapes or include outliers. Density-based clustering algorithms are very efficient at finding high-density regions and outliers. **It is very important to detect outliers for some task**, e.g. anomaly detection."}}