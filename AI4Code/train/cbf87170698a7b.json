{"cell_type":{"174778ee":"code","4d6ee65d":"code","38c6ee05":"code","daa7e313":"code","2357ae76":"code","0ffda5b4":"code","05fbf4fd":"code","7823c457":"code","8f2c1a70":"code","3fbae945":"code","a1393fd4":"code","2e673e3c":"code","c0d60c38":"code","df70c168":"code","59f1ef80":"code","3b808d6f":"code","0e948615":"code","85c90d2a":"code","3eb673c9":"code","e7ae192d":"code","475b8aa5":"code","c28815fc":"code","6d167043":"code","0b6fc5a7":"code","d3f7afdd":"code","43092663":"code","ef67ad3e":"code","6cefffe5":"code","4f154dae":"code","b9ee7600":"code","547e992b":"code","c23c7609":"code","c3490ea5":"code","af381459":"markdown","448799ba":"markdown","30293aa8":"markdown","a2f778d2":"markdown","e859b7a6":"markdown","6d42f4f9":"markdown","249b0418":"markdown","f7b129d4":"markdown","d4d6170f":"markdown","6d8acdec":"markdown","3c00d975":"markdown","0956cc82":"markdown"},"source":{"174778ee":"import numpy as np \nimport pandas as pd","4d6ee65d":"#read the files \ntrain_data = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv')\nall = [train_data,test_data]","38c6ee05":"#show the data \ntrain_data.head()","daa7e313":"for data in all:\n    data.drop(['PassengerId','Name','Ticket'],axis = 1,inplace=True)","2357ae76":"train_data.info()\nprint('*'*40)\ntest_data.info()","0ffda5b4":"train_data['Sex'].unique()","05fbf4fd":"for data in all:\n    data['Sex'] = data['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\ntrain_data.head()","7823c457":"train_data.info()","8f2c1a70":"for data in all:\n    data.drop(['Cabin'],axis = 1,inplace= True)","3fbae945":"import seaborn as sns \nimport matplotlib.pyplot as plt\nsns.set_style(\"whitegrid\")\ng = sns.FacetGrid(train_data,col = 'Pclass',height = 5,row = 'Survived')\ng.map(plt.hist,'Age')","a1393fd4":"female = train_data[(train_data['Sex'] == 1) & (train_data['Survived'] == 1)]['Sex'].value_counts()[1]\/train_data[(train_data['Survived'] == 1)]['Survived'].value_counts()[1]\nmale = train_data[(train_data['Sex'] == 0) & (train_data['Survived'] == 1)]['Sex'].value_counts()[0]\/train_data[(train_data['Survived'] == 1)]['Survived'].value_counts()[1]\nlabels = [\"females Survived\",'Male survived']\nfig1, ax1 = plt.subplots()\nax1.pie([female,male], labels=labels,shadow=True,startangle=90,autopct='%1.1f%%')\nplt.show()","2e673e3c":"g = sns.FacetGrid(train_data,col = 'Survived',height = 5)\ng.map(plt.hist,'Sex')","c0d60c38":"g = sns.FacetGrid(train_data,col = 'Pclass',height = 5,row = \"Sex\")\ng.map(plt.hist,'Age')","df70c168":"for data in all:\n   for i in range(0,2):\n      for j in range(1,4):     \n          age_mean = data[(data['Sex'] == i) & (data['Pclass'] == j)]['Age'].dropna().mean()\n          data.loc[ (data.Age.isnull()) & (data.Sex == i) & (data.Pclass == j),'Age'] = age_mean","59f1ef80":"train_data.info()\nprint('*'*40)\ntest_data.info()","3b808d6f":"train_data['Embarked'] = train_data['Embarked'].fillna(train_data.Embarked.mode(dropna=True)[0])","0e948615":"for data in all:\n    data.drop('Fare',axis = 1,inplace = True)","85c90d2a":"for data in all:\n    data['Family'] = data['Parch'] + data['SibSp'] + 1\n    data.drop(['Parch','SibSp'],axis = 1,inplace = True)\n","3eb673c9":"train_data.info()\nprint('*'*40)\ntest_data.info()","e7ae192d":"from sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder()\nfor data in all: \n    col = np.array(data['Embarked'])\n    col = col.reshape(len(col),1)\n    new = ohe.fit_transform(col).toarray()\n    new = new.T\n    data['C'] = new[0]\n    data['Q'] = new[1]\n    data['S'] = new[2]\n    data.drop('Embarked',axis = 1 ,inplace = True)","475b8aa5":"train_data.info()","c28815fc":"#for data in all:\n    #data['Embarked'] = data['Embarked'].map( {'S': 1, 'C': 2,'Q' : 3} )\n\n#train_data.head()","6d167043":"X_train = train_data.drop(['Survived'],axis = 1)\ny_train = train_data.Survived","0b6fc5a7":"from sklearn.preprocessing import StandardScaler\nscalerModel = StandardScaler()\nX_train = scalerModel.fit_transform(X_train)\ntest_data = scalerModel.transform(test_data)","d3f7afdd":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_train,y_train,test_size = 0.21,shuffle = True,random_state=33)","43092663":"train_scores = []\ntest_scores = []","ef67ad3e":"from sklearn.svm import SVC\n\n\nSVCModel = SVC(kernel= 'rbf',\n               max_iter=3000,C=.10,gamma='auto')\nSVCModel.fit(X_train, y_train)\n\n\n\nprint('train data score',SVCModel.score(X_train,y_train))\nprint('test data score',SVCModel.score(X_test,y_test))\ntrain_scores.append(SVCModel.score(X_train,y_train))\ntest_scores.append(SVCModel.score(X_test,y_test))","6cefffe5":"from sklearn.ensemble import RandomForestClassifier\n\nRandomForestClassifierModel = RandomForestClassifier(criterion = 'entropy',n_estimators=300,max_depth=5,random_state=33,bootstrap=False,min_samples_leaf=3) \nRandomForestClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('RandomForestClassifierModel Train Score is : ' , RandomForestClassifierModel.score(X_train, y_train))\nprint('RandomForestClassifierModel Test Score is : ' , RandomForestClassifierModel.score(X_test, y_test))\ntrain_scores.append(RandomForestClassifierModel.score(X_train, y_train))\ntest_scores.append(RandomForestClassifierModel.score(X_test, y_test))\n#print('----------------------------------------------------')\n","4f154dae":"from sklearn.linear_model import LogisticRegression\nLogisticRegressionModel = LogisticRegression(penalty='l2',solver='sag',C=0.5,random_state=33)\nLogisticRegressionModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('LogisticRegressionModel Train Score is : ' , LogisticRegressionModel.score(X_train, y_train))\nprint('LogisticRegressionModel Test Score is : ' , LogisticRegressionModel.score(X_test, y_test))\nprint('LogisticRegressionModel No. of iteratios is : ' , LogisticRegressionModel.n_iter_)\ntrain_scores.append(LogisticRegressionModel.score(X_train, y_train))\ntest_scores.append(LogisticRegressionModel.score(X_test, y_test))\nprint('----------------------------------------------------')\n","b9ee7600":"from sklearn.tree import DecisionTreeClassifier\n\nDecisionTreeClassifierModel = DecisionTreeClassifier(criterion='entropy',max_depth=5,random_state=33) \nDecisionTreeClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('DecisionTreeClassifierModel Train Score is : ' , DecisionTreeClassifierModel.score(X_train, y_train))\nprint('DecisionTreeClassifierModel Test Score is : ' , DecisionTreeClassifierModel.score(X_test, y_test))\nprint('----------------------------------------------------')\ntrain_scores.append(DecisionTreeClassifierModel.score(X_train, y_train))\ntest_scores.append(DecisionTreeClassifierModel.score(X_test, y_test))","547e992b":"Labels = ['SVC', 'RFC', 'LR', 'DTC']\nX = np.arange(1,5)\nfig = plt.figure(figsize=(10,7))\nax = fig.add_axes([0,0,1,1])\nplt.style.context('ggplot')\nax.bar(X + 0.00, train_scores, color = 'b', width = 0.40,label = 'train accuracy')\nax.bar(X + 0.40, test_scores, color = 'r', width = 0.40,label = 'test accuracy')\nfor i,m in list(zip(X,train_scores)):\n  plt.text(x = i ,y = m,s = float(\"{:.2f}\".format(m)))\nfor i,m in list(zip(X,test_scores)):\n  plt.text(x = i + 0.45 ,y = m,s = float(\"{:.2f}\".format(m)))\nax.set_xlabel('Models')\nax.set_ylabel('accuracy')\nax.set_xticks(X)\nax.set_xticklabels(Labels)\nplt.legend()","c23c7609":"y_pred = RandomForestClassifierModel.predict(test_data)","c3490ea5":"gs = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission = pd.DataFrame({'PassengerId': gs.PassengerId, 'Survived': y_pred})\nsubmission.to_csv('my_submission.csv', index=False)","af381459":"we have alot of Nan in cabin which we can't deal with it so  we will drop it ","448799ba":"now we only have nan left in Embarked in train data  which is easy to replace by the mode\nand we have 1 missing vlaue in fare in test data","30293aa8":"the best models is RFC and Logistic Regression ","a2f778d2":"we have catoirgal data in sex , cabin,and embarked let's replace them with numrical data","e859b7a6":"NOW! to the hard part \nwe can replace the Nan in the age with mean of it which won't be accurate enought so here is an example of \nwhat i am going to do \nwe can check the males in Pclass 1 for example and get the mean then replace the nan in that pclass 1 for males \nsame for the rest ","6d42f4f9":"The passenger Fare will not help if the passenger survived or not so i am going to drop it ","249b0418":"# Visualize data ","f7b129d4":"we can see that most females almost survived ","d4d6170f":"don't forget to upvote if you found it useful for you \nthanks :)","6d8acdec":"now the data is ready to test it ","3c00d975":"First i perfer to remove the useless columns that's not gonna affect on our output so we can see the data clear enough so.... PassengerId name ticket that won't affect on our outpot","0956cc82":"now before we move on we have two columns 'parch' and 'sibsp' \nparch is the number of spouses aboard the Titanic \nsibsp is the number of of parents \/ children aboard the Titanic\nwhich is better to merage them in one cloumn"}}