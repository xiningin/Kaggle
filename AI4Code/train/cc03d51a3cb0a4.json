{"cell_type":{"c6606687":"code","6d729070":"code","56c1767d":"code","78b0f449":"code","1ef11a10":"code","65d3a8f8":"code","10db7b9d":"code","0ed90d1d":"code","3a94e244":"code","f27906dc":"code","08b63d2f":"code","e249ddae":"code","ac91d24e":"code","736dc5d3":"code","4cecc9f2":"code","31bbd2be":"code","e309ce20":"code","cb3dec89":"code","5b740a3e":"code","503e0738":"code","7c013a8e":"code","42e8535f":"code","1906c339":"code","b842e8d7":"code","466308d0":"code","72f1ad96":"code","7fbda579":"code","e8c4f99a":"code","38a09b95":"code","73c62c09":"code","20fb8ed6":"code","5b472b16":"markdown","fb29f5bf":"markdown","dbdfe864":"markdown","1812ef0e":"markdown"},"source":{"c6606687":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport time\nimport datetime\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\nsns.set_style(style='darkgrid')\n\nimport traceback","6d729070":"# Read the file\nsf = pd.read_csv('\/kaggle\/input\/austin\/Issued_Construction_Permits.csv',low_memory=False)\n","56c1767d":"# remove objects where applied data < issued date \nsf = sf[(sf['Applied Date'] < sf['Issued Date']) ]\n","78b0f449":"# Conversion to datetime\nimport traceback\ntry :\n    sf['Applied Date'] = pd.to_datetime(sf['Applied Date'],errors='coerce')\n    sf['Issued Date'] = pd.to_datetime(sf['Issued Date'],errors='coerce')\n    sf['Status Date'] = pd.to_datetime(sf['Status Date'],errors='coerce')\n\nexcept :    \n    traceback.print_exc()\n\n# Keep a copy to reload\nsfcpy = sf.copy()","1ef11a10":"# Sometimes when re-run is required, one can start from just here, to save time\nsf = sfcpy.copy()\nsf = sf[(sf['Applied Date'].dt.year >= 2016) & (sf['Issued Date'].dt.year >= 2016)]\nsf = sf[(sf['Applied Date'].dt.year <= 2020) & (sf['Issued Date'].dt.year <= 2020)]\nsf = sf[sf['Permit Class Mapped'].str.contains('Residential', case=False, )]\n\n","65d3a8f8":"sf.head()","10db7b9d":"sf.shape","0ed90d1d":"sf.info()","3a94e244":"#Exploring missing values\nmissing_values_counts = sf.isnull().sum()\nprint(missing_values_counts)","f27906dc":"#Visualize missing values for a sample of 250\nimport missingno as msno\nmsno.matrix(sf.sample(250))","08b63d2f":"\nmiss_val_per_column = sf.isnull().sum()\/len(sf)\nmis_val_centage = (miss_val_per_column*100).round(3)\nmis_val_table = pd.concat([miss_val_per_column,mis_val_centage,],axis=1)\nnew_table = mis_val_table.rename(columns = {0 : 'Missing Values', 1 : 'Percentage'})\nnew_table\n","e249ddae":"# set threshold to remove columns with greater than 80% \nmissing_columns = list(new_table[new_table['Percentage']>80].index)\nprint('We will remove %d columns'%len(missing_columns))\nprint('The columns to remove are \\n %s'%missing_columns)","ac91d24e":"sf.drop(columns=list(missing_columns),inplace=True)\n#Now left with 34 columns out of 42.","736dc5d3":"sf.shape","4cecc9f2":"msno.bar(sf.sample(1000))","31bbd2be":"msno.heatmap(sf)","e309ce20":"msno.dendrogram(sf)","cb3dec89":"# Rename for brevity\/readability\nsf = sf.rename(columns =   {\n                            'Permit Type' : 'perm_typ',\n                            'Permit Type Desc': 'perm_typ_des',\n                            'Applied Date':'apply_dt',\n                            'Issued Date':'issue_dt',\n                            'Expires Date' : 'exp_dt',\n                            'Status Date' : 'st_dt',\n                            })\nsf.head()","5b740a3e":"sfr = sf[['perm_typ','perm_typ_des','apply_dt','issue_dt','st_dt']].copy()","503e0738":"sfr[['apply_dt','issue_dt','perm_typ']].info()","7c013a8e":"#  new column wait_time\nsfr = sfr.assign(wait_time = (sfr['issue_dt'] - sfr['apply_dt']).dt.days)","42e8535f":"\nsfr = sfr[(sfr['wait_time'] < 60) & (sfr['wait_time'] >= 0) ]\n","1906c339":"#remove outliers\nfrom scipy import stats\nsfr = sfr[(np.abs(stats.zscore(sfr['wait_time'])) < 3)]","b842e8d7":"#new column\n# Extract month and year\nsfr['month'] = sfr['apply_dt'].dt.month\nsfr['year'] = sfr['apply_dt'].dt.year","466308d0":"_ = plt.figure(figsize=(12,6))\n_ = plt.subplot(1,2,1)\n_ = (sfr.groupby('year').wait_time.mean()).plot.barh()\n_ = plt.title('Average wait time by year')\n_ = plt.subplot(1,2,2)\n_ = (sfr.groupby('year').wait_time.count()).plot.barh()\n_ = plt.title('Permit count by year')","72f1ad96":"# create side-by-side boxplots for every permit type\n_ = plt.figure(figsize=(20,10))\nax = sns.boxplot(y='perm_typ_des', x='wait_time', data = sfr, orient = 'h');\nplt.title('permit_type vs. wait_time if issued date < 60 days from applied date');\nplt.tight_layout(pad=1)\nplt.show()","7fbda579":"#create a new column time in days taken to receive a permit from the filed date and issued date\nsfr['Time_in_Days']= sf['issue_dt'].sub(sf['apply_dt'],axis=0)","e8c4f99a":"sfr['Time_in_Days'].head()# Asnap shot on the time in days taken.","38a09b95":"sfr['Time_in_Days'].describe() # exploring our target variable","73c62c09":"count_in_days= sfr['Time_in_Days'].value_counts(sort=True)\nprint(count_in_days.head()) # The highest number of permits are processed in a few hours.","20fb8ed6":"plt.hist(count_in_days, bins = 50, edgecolor = 'k');\nplt.xlabel('Time Taken in Days'); plt.ylabel('Count of records'); \nplt.title('Count of days distribution')\nplt.show()\n#It's a highly skewed distribution of the time taken for various permits to be processed","5b472b16":"Nullity correlation ranges from -1 (if one variable appears the other definitely does not) to 0 (variables appearing or not appearing have no effect on one another) to 1 (if one variable appears the other definitely also does).\n\nVariables that are always full or always empty have no meaningful correlation, and so are silently removed from the visualization\u2014in this case for instance the datetime and injury number columns, which are completely filled, are not included.\n\nEntries marked <1 or >-1 are have a correlation that is close to being exactingly negative or positive, but is still not quite perfectly so. This points to a small number of records in the dataset which are erroneous. For example, in this dataset the correlation between 'exiting_use' and ' is <1, indicating that, contrary to our expectation, there are a few records which have one or the other, but not both. These cases will require special attention.","fb29f5bf":"# Cleaning\/Formatting the data","dbdfe864":"The dendrogram uses a hierarchical clustering algorithm (courtesy of scipy) to bin variables against one another by their nullity correlation (measured in terms of binary distance). At each step of the tree the variables are split up based on which combination minimizes the distance of the remaining clusters. The more monotone the set of variables, the closer their total distance is to zero, and the closer their average distance (the y-axis) is to zero.\n\nTo interpret this graph, read it from a top-down perspective. Cluster leaves which linked together at a distance of zero fully predict one another's presence\u2014one variable might always be empty when another is filled, or they might always both be filled or both empty, and so on. In this specific example the dendrogram glues together the variables which are required and therefore present in every record.\n\nCluster leaves which split close to zero, but not at it, predict one another very well, but still imperfectly. If your own interpretation of the dataset is that these columns actually are or ought to be match each other in nullity (for example, as CONTRIBUTING FACTOR VEHICLE 2 and VEHICLE TYPE CODE 2 ought to), then the height of the cluster leaf tells you, in absolute terms, how often the records are \"mismatched\" or incorrectly filed\u2014that is, how many values you would have to fill in or drop, if you are so inclined.","1812ef0e":"# permit wait-time anaylsis"}}