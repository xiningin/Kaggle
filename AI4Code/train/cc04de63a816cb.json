{"cell_type":{"451b0dc1":"code","73ecd045":"code","195b299e":"code","971d83dc":"code","d2f40083":"code","2802dc41":"code","34e6a994":"code","6de0d732":"code","c7a4ce26":"code","ad32eb36":"code","4174cab3":"code","869abc60":"code","87088c95":"code","f738aa9e":"code","fed71095":"code","2858e1f7":"code","57945f96":"code","c669e8a3":"code","5b5415a4":"code","0ebeda93":"code","3252fd1a":"code","1253029c":"code","e7780f26":"markdown","8aaff845":"markdown","604a3a9d":"markdown","f61a9ff6":"markdown","dfba8c6a":"markdown","211f8344":"markdown"},"source":{"451b0dc1":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","73ecd045":"df = pd.read_csv('..\/input\/prostate-cancer\/Prostate_Cancer.csv')","195b299e":"df.head()","971d83dc":"df.shape","d2f40083":"sns.set(rc = {'figure.figsize': (10,7)})\nlabels = list(df.diagnosis_result.unique())\nsizes = list(df.diagnosis_result.value_counts())\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct = '%1.2f%%', startangle = 65)","2802dc41":"df.drop(['id'], axis=1, inplace=True)\ndf.head()","34e6a994":"sns.heatmap(df.corr(), annot=True)","6de0d732":"sns.pairplot(df, hue='diagnosis_result')","c7a4ce26":"df.diagnosis_result = [1 if each == 'M' else 0 for each in df.diagnosis_result]\ndf.head()","ad32eb36":"data_train = df.sample(frac = 0.8, random_state=1)\ndata_test = df.drop(data_train.index)","4174cab3":"X_train = data_train.drop(['diagnosis_result'], axis=1)\nY_train = data_train['diagnosis_result']\nX_test = data_test.drop(['diagnosis_result'], axis=1)\nY_test = data_test['diagnosis_result']","869abc60":"from sklearn.preprocessing import MinMaxScaler","87088c95":"scaler = MinMaxScaler(feature_range=(0,1))\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)","f738aa9e":"from sklearn.linear_model import LogisticRegression","fed71095":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\nlr.fit(X_train, Y_train) #Fitting\nY_lr = lr.predict(X_test)","2858e1f7":"from sklearn.metrics import accuracy_score \nscore_LR = accuracy_score(Y_test, Y_lr)\nscore_LR","57945f96":"from sklearn.metrics import confusion_matrix\nresultat = confusion_matrix(Y_test, Y_lr)\nsns.heatmap(resultat, annot=True)\nplt.title('Confusion Matrix')\nplt.xlabel('Y_test')\nplt.ylabel('Y_lr')","c669e8a3":"from sklearn import tree\nad = tree.DecisionTreeClassifier()\nad.fit(X_train,Y_train)\nY_ad = ad.predict(X_test)\nscore_AD = metrics.accuracy_score(Y_test, Y_ad)\nscore_AD","5b5415a4":"resultat_1 = confusion_matrix(Y_test, Y_ad)\nsns.heatmap(resultat_1, annot=True)\nplt.title('Confusion Matrix')\nplt.xlabel('Y_test')\nplt.ylabel('Y_ad')","0ebeda93":"ad1 = tree.DecisionTreeClassifier(max_depth = 3, min_samples_leaf = 20)\nad1.fit(X_train,Y_train)\nY_ad1 = ad1.predict(X_test)\nscore_AD1 = accuracy_score(Y_test, Y_ad1)\nscore_AD1","3252fd1a":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, Y_train)\nY_rf = rf.predict(X_test)\nscore_RF = metrics.accuracy_score(Y_test, Y_rf)\nscore_RF","1253029c":"resultat_2 = confusion_matrix(Y_test, Y_rf)\nsns.heatmap(resultat_2, annot=True)\nplt.title('Confusion Matrix')\nplt.xlabel('Y_test')\nplt.ylabel('Y_rf')","e7780f26":"## R\u00e9gression Logistique","8aaff845":"## Arbres de d\u00e9cision","604a3a9d":"# Pr\u00e9dicton","f61a9ff6":"## Random Forests","dfba8c6a":"On peut modifier certains param\u00e8tres : Le param\u00e8tre max_depth est un seuil sur la profondeur maximale de l\u2019arbre. Le param\u00e8tre min_samples_leaf donne le nombre minimal d\u2019\u00e9chantillons dans un noeud feuille.","211f8344":"Pour construire un arbre de d\u00e9cision \u00e0 partir d'un ensemble d'apprentissage, on va choisir une variable qui s\u00e9pare l'ensemble en deux parties les plus distinctes en fonction d'un crit\u00e8re. Sur les iris par exemple, on peut utiliser la largeur du p\u00e9tale pour s\u00e9parer l'esp\u00e8ce Setosa des autres.\n\nL'indice GINI mesure avec quelle fr\u00e9quence un \u00e9l\u00e9ment al\u00e9atoire de l'ensemble serait mal class\u00e9 si son \u00e9tiquette \u00e9tait s\u00e9lectionn\u00e9e al\u00e9atoirement depuis la distribution des \u00e9tiquettes dans le sous-ensemble."}}