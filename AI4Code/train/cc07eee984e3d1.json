{"cell_type":{"a878cea6":"code","dbce0ed9":"code","c8989163":"code","6f0ce0df":"code","3b0f9c27":"code","35a83cde":"code","83bb5d10":"code","112ccb21":"markdown","8824e64a":"markdown","7c99e3d2":"markdown"},"source":{"a878cea6":"%matplotlib inline\nfrom copy import deepcopy\nfrom collections import OrderedDict\nimport gc\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import SGD,Adam,lr_scheduler\nfrom torch.utils.data import random_split\nimport torchvision\nfrom torchvision import transforms,models","dbce0ed9":"!tar -zxvf ..\/input\/cifar10-python\/cifar-10-python.tar.gz","c8989163":"train_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.RandomHorizontalFlip(p=.40),\n    transforms.RandomRotation(30),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\ntraindata = torchvision.datasets.CIFAR10(root='.', train=True,download=False, transform=train_transform)\ntrainset,valset = random_split(traindata,[42000,8000])\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True)\nvalloader = torch.utils.data.DataLoader(valset, batch_size=64,shuffle=False)\n\ntestset = torchvision.datasets.CIFAR10(root='.', train=False,download=False, transform=test_transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=False)\n\nclasses = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')","6f0ce0df":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        base = models.resnet18(pretrained=True)\n        self.base = nn.Sequential(*list(base.children())[:-1])\n        in_features = base.fc.in_features\n        self.drop = nn.Dropout()\n        self.final = nn.Linear(in_features,10)\n    \n    def forward(self,x):\n        x = self.base(x)\n        x = self.drop(x.view(-1,self.final.in_features))\n        return self.final(x)\n    \nmodel = Model().cuda()\n[x for x,y in model.named_children()]","3b0f9c27":"criterion = nn.CrossEntropyLoss()\nparam_groups = [\n    {'params':model.base.parameters(),'lr':.0001},\n    {'params':model.final.parameters(),'lr':.001}\n]\noptimizer = Adam(param_groups)\nlr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\nstates = {}","35a83cde":"%%time\nbest_val_acc = -1000\nbest_val_model = None\nfor epoch in range(10):  \n    model.train(True)\n    running_loss = 0.0\n    running_acc = 0\n    for i, data in enumerate(trainloader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.cuda(),labels.cuda()\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item() * inputs.size(0)\n        out = torch.argmax(outputs.detach(),dim=1)\n        assert out.shape==labels.shape\n        running_acc += (labels==out).sum().item()\n    print(f\"Train loss {epoch+1}: {running_loss\/len(trainset)},Train Acc:{running_acc*100\/len(trainset)}%\")\n    \n    correct = 0\n    model.train(False)\n    with torch.no_grad():\n        for inputs,labels in valloader:\n            out = model(inputs.cuda()).cpu()\n            out = torch.argmax(out,dim=1)\n            acc = (out==labels).sum().item()\n            correct += acc\n    print(f\"Val accuracy:{correct*100\/len(valset)}%\")\n    if correct>best_val_acc:\n        best_val_acc = correct\n        best_val_model = deepcopy(model.state_dict())\n    lr_scheduler.step()\n    \nprint('Finished Training')  ","83bb5d10":"%%time\ncorrect = 0\nmodel.load_state_dict(best_val_model)\nmodel.train(False)\nwith torch.no_grad():\n    for inputs,labels in testloader:\n        out = model(inputs.cuda()).cpu()\n        out = torch.argmax(out,dim=1)\n        acc = (out==labels).sum().item()\n        \n        correct += acc\nprint(f\"Test accuracy: {correct*100\/len(testset)}%\")","112ccb21":"<h2> Testing the model<\/h2>","8824e64a":"<center><h2> **Transfer Learning** <\/h2><\/center>\n<h3> Note <\/h3>\n<ul> \n    <li>Resnet18 pretrained with Imagenet <\/li>\n    <li> Images resized to 224, with resnet's normalization. Resize doesn't work with multiprocessing, so data loading couldn't be parallelized. <\/li>\n  <\/ul>\n<h3> Configurations<\/h3>\n1. Only last custom linear layer trained : 77.75 %\n2. All layers trained with Adam : ~ 95% ","7c99e3d2":"<h2> Training the model<\/h2>"}}