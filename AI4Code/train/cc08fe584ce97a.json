{"cell_type":{"5ab939d2":"code","bce57eed":"code","bd1ad2f1":"code","c0940c45":"code","ad237455":"code","a0b1ce97":"code","b9bc0278":"code","a5c0ddb4":"code","a6894fc8":"code","3f5db6e5":"code","2564c4fd":"code","e68222bb":"code","a948d320":"code","abf03e25":"code","8cfd62ae":"code","6b7cd06e":"code","7c794e5d":"code","d5f04c61":"code","c482e6a5":"code","65da86cc":"code","44951bb8":"markdown","9bfe536c":"markdown","07921b94":"markdown"},"source":{"5ab939d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bce57eed":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\n\n# Read the data\nX = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv', index_col='Id')\nX_test_full = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv', index_col='Id')\n\n# Remove rows with missing target, separate target from predictors\nX.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X.SalePrice","bd1ad2f1":"X.select_dtypes([\"object\"]).nunique()","c0940c45":"X[\"SaleType\"].value_counts()","ad237455":"# Generate X_encode\\y_encode\\X_pretrain\\y_train directly from X (without imputing or onehotencoding or any other preprocesses!)\n# Noted that X contains SalePrice - the target\n# Encoding split\nX_encode = X.sample(frac=0.20, random_state=0)\ny_encode = X_encode.pop(\"SalePrice\")\n\n# Training split\nX_pretrain = X.drop(X_encode.index)\ny_train = X_pretrain.pop(\"SalePrice\")","a0b1ce97":"print(X_pretrain.head())","b9bc0278":"from category_encoders import MEstimateEncoder\nimport warnings\n# YOUR CODE HERE: Create the MEstimateEncoder\n# Choose a set of features to encode and a value for m\nencoder = MEstimateEncoder(\n    cols=['Neighborhood'],###\n    m=1.0\n)\n\n# Why need y_encode here? Because some encoded value needs the information from SalePrice?\n# How do I get X_test encoded? X_test without target y\n\n# Fit the encoder on the encoding split\nencoder.fit(X_encode, y_encode)\n\n# Encode the training split\nX_train = encoder.transform(X_pretrain, y_train)\n# Ignore warnings from old python code usage version\nwarnings.filterwarnings('ignore')","a5c0ddb4":"# Check format of X_train\nprint(X_train.head())# Contains NaN values; XGB model?","a6894fc8":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score\n\n# Set Matplotlib defaults\nplt.style.use(\"seaborn-whitegrid\")\nplt.rc(\"figure\", autolayout=True)\nplt.rc(\n    \"axes\",\n    labelweight=\"bold\",\n    labelsize=\"large\",\n    titleweight=\"bold\",\n    titlesize=14,\n    titlepad=10,\n)\nwarnings.filterwarnings('ignore')\n\n\ndef score_dataset(X, y, model=XGBRegressor()):\n    # Label encoding for categoricals\n    for colname in X.select_dtypes([\"category\", \"object\"]):\n        X[colname], _ = X[colname].factorize()\n    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n    score = cross_val_score(\n        model, X, y, cv=5, scoring=\"neg_mean_squared_log_error\",\n    )\n    score = -1 * score.mean()\n    score = np.sqrt(score)\n    return score\n","3f5db6e5":"feature = encoder.cols\n\nplt.figure(dpi=90)\nax = sns.distplot(y_train, kde=True, hist=False)\nax = sns.distplot(X_train[feature], color='r', ax=ax, hist=True, kde=False, norm_hist=True)\nax.set_xlabel(\"SalePrice\");","2564c4fd":"X_prone = X.copy()\ny_prone = X_prone.pop(\"SalePrice\")\nscore_base = score_dataset(X_prone, y_prone)\nscore_new = score_dataset(X_train, y_train)\n\nprint(f\"Baseline Score: {score_base:.4f} RMSLE\")\nprint(f\"Score with Encoding: {score_new:.4f} RMSLE\")","e68222bb":"#from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error\n'''\n# Define the model\nmy_model = XGBRegressor(n_estimators=1000, learning_rate=0.05) # Your code here\n\n# Fit the model\nmy_model.fit(X_train, y_train) # Your code here\n'''\n'''\n# Get predictions\npredictions = my_model.predict(X_valid) # Your code here\n\n# Calculate MAE\nmae = mean_absolute_error(predictions, y_valid) # Your code here\n\n# Uncomment to print MAE\nprint(\"Mean Absolute Error:\" , mae)\n'''","a948d320":"X_final = X.copy()\nX_final.pop(\"SalePrice\")# Directly encode raw data X(without target ofcourse)\n\nMEE_encoder = MEstimateEncoder(\n    cols=['Neighborhood'],\n    m=1.0\n)\ntrain_mee = MEE_encoder.fit_transform(X_final, y)\ntest_mee = MEE_encoder.transform(X_test_full)","abf03e25":"# preds = my_model.predict(X_test_full) You should do the same transformation matrices As on X_test_full either!\n\n#X_test = encoder.transform(X_test_full)","8cfd62ae":"# Check\nprint(test_mee.head())","6b7cd06e":"score_dataset(X_final, y)","7c794e5d":"def Label_Encoding(X):\n    for colname in X.select_dtypes([\"category\", \"object\"]):\n        X[colname], _ = X[colname].factorize()","d5f04c61":"# Define the model\nmy_model = XGBRegressor(n_estimators=1000, learning_rate=0.05) # Your code here\n\nLabel_Encoding(X_final)\n# Fit the model\nmy_model.fit(X_final, y)","c482e6a5":"Label_Encoding(test_mee)\npreds = my_model.predict(test_mee)","65da86cc":"# Run the code to save predictions in the format used for competition scoring\n\noutput = pd.DataFrame({'Id': test_mee.index,\n                       'SalePrice': preds})\noutput.to_csv('submission.csv', index=False)","44951bb8":"# Using MEstimateEncoder","9bfe536c":"# Matplotlib defaults & score_dataset() Definition","07921b94":"# Do Predictions using new dataset!"}}