{"cell_type":{"167c558b":"code","5a11b245":"code","5f734f70":"code","7bc39f44":"code","5266287c":"code","55be43fb":"code","6faf0f9e":"code","d9d77d62":"code","20709d5f":"code","52148f83":"code","1386c875":"code","ed8f7f97":"code","f30b8f16":"code","63852519":"code","5228eba2":"code","c93ac128":"markdown","8e218082":"markdown","2b8974cd":"markdown","4ed0c035":"markdown","d03e2c00":"markdown","2570cf09":"markdown","5662e0e0":"markdown","9570a1d0":"markdown","cf27e6b5":"markdown","e037ff7d":"markdown","ba92226f":"markdown","2587f884":"markdown","97b5f651":"markdown","60c4fd79":"markdown","0fecfb76":"markdown","a9e9e83c":"markdown","9e68c47a":"markdown"},"source":{"167c558b":"import nltk.classify.util\nfrom nltk.classify import NaiveBayesClassifier\nfrom nltk.corpus import movie_reviews\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","5a11b245":"# This is how the Naive Bayes classifier expects the input\ndef create_word_features(words):\n    useful_words = [word for word in words if word not in stopwords.words(\"english\")]\n    my_dict = dict([(word, True) for word in useful_words])\n    return my_dict","5f734f70":"for i in stopwords.words(\"english\"):\n    print(i+',',end=' ')","7bc39f44":"create_word_features([\"the\", \"quick\", \"brown\", \"quick\", \"a\", \"fox\"])","5266287c":"neg_reviews = []\nfor fileid in movie_reviews.fileids('neg'):\n    words = movie_reviews.words(fileid)\n    neg_reviews.append((create_word_features(words), \"negative\"))\n                        ","55be43fb":"print(neg_reviews[0],len(neg_reviews))    ","6faf0f9e":"pos_reviews = []\nfor fileid in movie_reviews.fileids('pos'):\n    words = movie_reviews.words(fileid)\n    pos_reviews.append((create_word_features(words), \"positive\"))\n    \nprint(pos_reviews[0])    \nprint(len(pos_reviews))","d9d77d62":"train_set = neg_reviews[:750] + pos_reviews[:750]\ntest_set =  neg_reviews[750:] + pos_reviews[750:]\nprint(len(train_set),  len(test_set))","20709d5f":"classifier = NaiveBayesClassifier.train(train_set)","52148f83":"accuracy = nltk.classify.util.accuracy(classifier, test_set)\nprint(accuracy * 100)","1386c875":"review_1 = '''It would be impossible to sum up all the stuff that sucks about this film, \nso I'll break it down into what I remember most strongly: a man in an ingeniously fake-looking polar bear costume \n(funnier than the \"bear\" from Hercules in New York); an extra with the most unnatural laugh you're ever likely to hear;\nan ex-dope addict martian with tics; kid actors who make sure every syllable of their lines are slowly \nand caaarreee-fulll-yyy prrooo-noun-ceeed;\na newspaper headline stating that Santa's been \"kidnaped\", and a giant robot. Yes, you read that right. A giant robot.\nThe worst acting job in here must be when Mother Claus and her elves have been \"frozen\" by the \"Martians'\" weapons. \nCould they be *more* trembling? I know this was the sixties and everyone was doped up, but still.\n'''\nprint(review_1 )","ed8f7f97":"words = word_tokenize(review_1)\nwords = create_word_features(words)\nclassifier.classify(words)","f30b8f16":"review_spirit = '''Spirited Away' is the first Miyazaki I have seen, but from this stupendous film.\nI can tell he is a master storyteller. A hallmark of a good storyteller is making the audience empathise or\npull them into the shoes of the central character. Miyazaki does this brilliantly in 'Spirited Away'. \nDuring the first fifteen minutes we have no idea what is going on. Neither does the main character Chihiro. \nWe discover the world as Chihiro does and it's truly amazing to watch. But Miyazaki doesn't seem to treat this world as\nsomething amazing. The world is filmed just like our workaday world would. The inhabitants of the world go about their daily\nbusiness as usual as full with apathy as us normal folks. Places and buildings are not greeted by towering establishing shots\nand majestic music. The fact that this place is amazing doesn't seem to concern Miyazaki.\nWhat do however, are the characters. Miyazaki lingers upon the characters as if they were actors. \nHe infixes his animated actors with such subtleties that I have never seen, even from animation giants Pixar. \nTwenty minutes into this film and I completely forgot these were animated characters; \nI started to care for them like they were living and breathing. \nMiyazaki treats the modest achievements of Chihiro with unashamed bombast. \nThe uplifting scene where she cleanses the River God is accompanied by stirring music and is as exciting as \nwatching gladiatorial combatants fight. Of course, by giving the audience developed characters to care about, \nthe action and conflicts will always be more exciting, terrifying and uplifting than normal, generic action scenes. \n'''\nprint(review_spirit)","63852519":"words = word_tokenize(review_spirit)\nwords = create_word_features(words)\nclassifier.classify(words)","5228eba2":"reviews_list=[\"It's a nice movie\",\"It's not a nice movie\",\"the Movie is more violent\",\n             \"In the movie, the hreo doesn't performed well\",\"OK, the movie is well\",\"OK nice\",\"it's a disaster\"\n            ]\n\nfor review in reviews_list:\n    words = word_tokenize(review)\n    words = create_word_features(words)\n    print(review,'      ('+classifier.classify(words)+')')\n","c93ac128":"* We will be using the **<font color=\"red\">Naive Bayes classifier**<font color=\"red\"> for this example. The Naive Bayes is a fairly simple machine learning algorithm, that works mainly with probabilities. \n\n","8e218082":"As accuracy of 72.39999999999999%. Could you improve it? How?\n\nFor now, I want to show you how to classify a review as negative or positive. But before that, a warning.\n\nThe problem with sentiment analysis, as with any machine learning approach, is that your algorithm is only as good as your data. <font color=\"red\">If your data is crap, your algorithm will be crap<\/font>.\n\nNot only that, the <font color=\"red\">algorithm depends on the type of input you train it with<\/font>. So if you train your data with long movie reviews, it will not work with Twitter data, which is much shorter.\n\nThis particular dataset is, imo, a bit short. Also, the reviews are very informal, using a lot of swear words etc. Which is why I found it not very accurate when comparing it to Imdb reviews, where swearing is discouraged and reviews are (slightly) more formal.\n\nAnyway, I was looking for negative and positive reviews. Our algorithm is more accurate when the review contains stronger words (horrible instead of bad). For the bad reviews, I found this gem of a movie. A real masterpiece:","2b8974cd":"* Before we start, there is something that had me stumped for a long time. I saw it in all the examples, but it didn\u2019t make sense. But the Naive Bayes classifier, especially in the **<font color=\"red\">Nltk library**<\/font>, expects the input to be in this format: Every word must be followed by true. So for example, if you have these words:\n    \n```python\n\"Hello World\"\n```\n    you need to pass it in as:\n\n```python\n{'Hello': True,  'World': True}\n```","4ed0c035":"Let\u2019s see how this works:\n","d03e2c00":"Let's see what will return <font color=\"red\">stopwords.words(\"english\")<\/font>","2570cf09":"* Sentiment Analysis means finding the mood of the public about things like movies, politicians, stocks, or even current events. We will analyse the sentiment of the movie reviews corpus we saw earlier.","5662e0e0":"## 1. Let\u2019s import our libraries:","9570a1d0":"And let\u2019s use our test set to find the accuracy:","cf27e6b5":"We create an empty list called neg_reviews. Next, we loop over all the files in the neg folder.\n\nWe get all the words in that file.\n\nThen we use the function we wrote earlier to create word features in the format nltk expects. Here is a sample of the output:","e037ff7d":"* Some of them are correct and few of them aren't, but I\u2019d like to repeat, the  classifier isn\u2019t very accurate overall, I suspect because the original sample is very small and not  very representative for Imdb reviews. But it\u2019s good enough for learning.","ba92226f":"* That was correct, but only because the review was really scathing.\n\n* For the positive review, I chose one of my favourite movies, Spirited Away, a very beautiful movie:","2587f884":"So we have a 1000 negative and 1000 positive reviews, for a total of 2000. We will now create our test and train samples, this time manually:","97b5f651":"* We need to word_tokenize the text, call our function it, and then use the classify() function to let our algorithm decide if this is a positive or negative review.","60c4fd79":"We call our function with the string \u201cthe quick brown quick a fox\u201d.\n\nYou can see that a) The stop words are removed  b) Repeat words are removed  c) There is a True with each word.\n\nAgain, this is just the format the Naive Bayes classifier in nltk expects.\n\nOkay, let\u2019s start with the code. Remember, the sentiment analysis code is just a machine learning algorithm that has been trained to identify positive\/negative reviews.","0fecfb76":"So there are a 1000 negative reviews.\n\nLet\u2019s do the same for the positive reviews. The code is exactly the same:\n\n","a9e9e83c":"# <font color=\"tomato\">Sentiment Analysis on IMDB Movie Reviews<\/font>","9e68c47a":"We end up with 1500 training samples and 500 test.\n\nLet\u2019s create our Naive Bayes Classifier, and train it with our training set."}}