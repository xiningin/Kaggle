{"cell_type":{"cb13a78e":"code","fcf75a28":"code","5b439e86":"code","066a65a5":"code","b76cdcd7":"code","566230a0":"code","a7744b0c":"code","288364de":"code","84e1c3cb":"code","ecbd2e01":"code","cf797a4f":"code","e59fa4c4":"code","b38e6f00":"code","805dcfa8":"code","a036f4de":"code","45e5eeb5":"code","8ad9d05e":"code","98139bf0":"code","e8977aa3":"code","2e4bbe78":"code","9b965a52":"code","7f47a9ac":"code","4acf4302":"code","ab6a8863":"code","39f8c068":"markdown","04d19d40":"markdown","7be484fa":"markdown","a82c2cd1":"markdown","2dabe499":"markdown","7fed4f53":"markdown","61f55a31":"markdown","efb69df6":"markdown","ba7d106c":"markdown","e4a3665a":"markdown"},"source":{"cb13a78e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fcf75a28":"%matplotlib inline","5b439e86":"import numpy as np                   # advanced math library\nimport matplotlib.pyplot as plt      # MATLAB like plotting routines\nimport random                        # for generating random numbers\n\nfrom tensorflow.keras.datasets import mnist     # MNIST dataset is included in Keras\nfrom tensorflow.keras.models import Sequential  # Model type to be used\n\nfrom tensorflow.keras.layers import Dense, Dropout, Activation # Types of layers to be used in our model\nfrom tensorflow.keras.utils import to_categorical                         # NumPy related tools","066a65a5":"(X_train_1, y_train_1), (X_test_1, y_test_1) = mnist.load_data()","b76cdcd7":"# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\nprint(\"X_train shape\", X_train.shape)\nprint(\"y_train shape\", y_train.shape)\nprint(\"X_test shape\", X_test.shape)\nprint(\"y_test shape\", y_test.shape)","566230a0":"plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    num = random.randint(0, len(X_train))\n    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n    plt.title(\"Class {}\".format(y_train[num]))\n    \nplt.tight_layout()","a7744b0c":"X_train = X_train.reshape(60000, 784) # reshape 60,000 28 x 28 matrices into 60,000 784-length vectors.\nX_test = X_test.reshape(10000, 784)   # reshape 10,000 28 x 28 matrices into 10,000 784-length vectors.\n\nX_train = X_train.astype('float32')   # change integers to 32-bit floating point numbers\nX_test = X_test.astype('float32')\n\nX_train \/= 255                        # normalize each value for each pixel for the entire vector for each input\nX_test \/= 255\n\nprint(\"Training matrix shape\", X_train.shape)\nprint(\"Testing matrix shape\", X_test.shape)","288364de":"nb_classes = 10 # number of unique digits\n\nY_train = to_categorical(y_train, nb_classes)\nY_test = to_categorical(y_test, nb_classes)","84e1c3cb":"# The Sequential model is a linear stack of layers and is very common.\nmodel = Sequential()\n\n# Add first layer\nmodel.add(Dense(512, input_shape=(784,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.35))\n\n# Add Second layer\nmodel.add(Dense(512, input_shape=(512,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.35))\n\n# Add Third Hidden layer\nmodel.add(Dense(512, input_shape=(512,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.35))\n\n# Add Third Hidden layer\nmodel.add(Dense(512, input_shape=(512,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.35))\n\n# The final layer with 10 neurons as we have 10 digit 0-9 in output\nmodel.add(Dense(10,input_shape=(512,)))\nmodel.add(Activation('softmax'))\n\n# Summarize the built model\n\nmodel.summary()","ecbd2e01":"# Let's use the Adam optimizer for learning\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","cf797a4f":"model.fit(X_train, Y_train, batch_size=128, epochs=10, verbose=1)","e59fa4c4":"score = model.evaluate(X_test, Y_test)\nprint('Test Loss:', score[0])\nprint('Test accuracy:', score[1])","b38e6f00":"X_test.shape","805dcfa8":"# The predict_classes function outputs the highest probability class\n# according to the trained classifier for each input example.\npredicted_x = model.predict(X_test)\npredicted_classes = np.argmax(predicted_x, axis=1)\n\n# Check which items we got right \/ wrong\ncorrect_indices = np.nonzero(predicted_classes == y_test)[0]\n\nincorrect_indices = np.nonzero(predicted_classes != y_test)[0]","a036f4de":"plt.imshow(X_test[9998].reshape(28,28), cmap='gray', interpolation='none')","45e5eeb5":"#correct predicction\nplt.figure()\nfor i, pred in enumerate(predicted_classes[:9]):\n    plt.subplot(3, 3,i+1)\n    plt.imshow(X_test[pred].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[pred], y_test[pred]))\n    \nplt.tight_layout()","8ad9d05e":"#correct predicction\nplt.figure()\nfor i, correct in enumerate(correct_indices[:6]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n    \nplt.tight_layout()\n    ","98139bf0":"#Incorrect predicction\nplt.figure()\nfor i, incorrect in enumerate(incorrect_indices[:6]):\n    plt.subplot(3,3,i+1)\n    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\n    \nplt.tight_layout()","e8977aa3":"test_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","2e4bbe78":"test_images = np.array(test_df)\ntest_images.shape","9b965a52":"test_data = test_images.reshape(28000, 784)\ntest_data = test_data\/255\ntest_data.shape","7f47a9ac":"preditions = model.predict(test_data)\npreditions = np.argmax(preditions, axis=1)\npreditions[:5]","4acf4302":"# Submission creation\ndef convert_prediction_result(X_test):\n    image_id = []\n    for i in range(1, len(X_test) + 1):\n        image_id += [i]\n    return image_id","ab6a8863":"my_submission = pd.DataFrame({'ImageId': convert_prediction_result(test_data), 'Label': preditions})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","39f8c068":"## Flattern the data","04d19d40":"## Add model optimizer for training","7be484fa":"## Evaluate Model's Accuracy on Test Data","a82c2cd1":"## Make predictions on test data","2dabe499":"## Load the data","7fed4f53":"# Train the model","61f55a31":"## Create model and add Hidden layers","efb69df6":"## Create submission file","ba7d106c":"# Test the predicted result","e4a3665a":"## Assign a output category"}}