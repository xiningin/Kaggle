{"cell_type":{"68f3bf21":"code","ca267d17":"code","34b97f1a":"code","9a752122":"code","0f230cc8":"code","c3e8c903":"code","a392938b":"code","867961db":"code","b6d53877":"code","8bfe3a3e":"code","a1f227a6":"code","864c9ce7":"code","7407ec18":"code","ba3a191d":"code","89830490":"code","f79998dd":"code","ac2b6736":"code","4afbe60e":"code","a8fd03da":"code","4b82b1fb":"code","17602d34":"code","78d98199":"code","5d14f288":"code","b7b79aea":"code","8f6ab6ee":"code","6cf4b53e":"code","088370d5":"code","eb25962d":"code","5c6a9000":"code","f10f94ca":"code","307e6492":"code","d3bb4850":"code","ff5386d8":"code","06199615":"code","38b49fcb":"code","f4f1d7b1":"code","01a038ab":"code","2a5fc78d":"code","323bccbb":"code","3f2f663c":"code","85804c09":"markdown"},"source":{"68f3bf21":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport riiideducation\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder","ca267d17":"train = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/train.csv',\n                   usecols=[1, 2, 3, 4, 5, 7, 8, 9],\n                   dtype={'timestamp': 'int64',\n                          'user_id': 'int32',\n                          'content_id': 'int16',\n                          'content_type_id': 'int8',\n                          'task_container_id': 'int16',\n                          'answered_correctly':'int8',\n                          'prior_question_elapsed_time': 'float32',\n                          'prior_question_had_explanation': 'boolean'})","34b97f1a":"train = train[train.content_type_id == False]\n#Lecture rows have been filtered out from content_type_id col\n\ntrain = train.sort_values(['timestamp'], ascending=True)\ntrain.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)","9a752122":"results_c = train[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\nresults_c.columns = [\"answered_correctly_content\"]","0f230cc8":"results_u = train[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\nresults_u.columns = [\"answered_correctly_user\", 'sum_user_ans', 'count_user_ans']","c3e8c903":"results_t = train[['task_container_id','answered_correctly']].groupby(['task_container_id']).agg(['mean', 'sum', 'count'])\nresults_t.columns = [\"answered_correctly_task\", 'sum_task_ans', 'count_task_ans']","a392938b":"train[\"prior_question_elapsed_time\"] = train[\"prior_question_elapsed_time\"].fillna(13238)","867961db":"train['prior_question_had_explanation'] = train['prior_question_had_explanation'].fillna(True)","b6d53877":"train.isnull().sum()","8bfe3a3e":"# Checked voth mean and max for the same column. \n#train['prior_question_elapsed_time'].min()","a1f227a6":"train[\"duration\"] = train[\"prior_question_elapsed_time\"] \/ 300000","864c9ce7":"X = train.iloc[70000000:, :]","7407ec18":"#X.shape","ba3a191d":"X = pd.merge(X, results_u, on=['user_id'], how=\"left\")","89830490":"X = pd.merge(X, results_c, on=['content_id'], how=\"left\")","f79998dd":"X = pd.merge(X, results_t, on=['task_container_id'], how=\"left\")","ac2b6736":"import gc\ngc.collect()","4afbe60e":"X = X[X.answered_correctly!= -1]\nX = X.sort_values(['user_id'])","a8fd03da":"Y = X[[\"answered_correctly\"]]","4b82b1fb":"X.isnull().sum()","17602d34":"X = X.drop([\"answered_correctly\"], axis=1)","78d98199":"le = LabelEncoder()\n\nX[\"prior_question_had_explanation_enc\"] = le.fit_transform(X[\"prior_question_had_explanation\"])","5d14f288":"#X.head()","b7b79aea":"from sklearn.model_selection import train_test_split","8f6ab6ee":"X.columns","6cf4b53e":"X = X[['prior_question_elapsed_time',\n       'duration', 'answered_correctly_user', 'sum_user_ans', 'count_user_ans',\n       'answered_correctly_content', 'answered_correctly_task', 'sum_task_ans',\n       'count_task_ans', 'prior_question_had_explanation_enc']]","088370d5":"X_t, X_tt, y_t, y_tt = train_test_split(X, Y, test_size=0.01, shuffle=False)","eb25962d":"gc.collect()","5c6a9000":"params = {'objective': 'binary',\n    'max_bin': 650,\n    'learning_rate': 0.04,\n    'num_leaves': 80}","f10f94ca":"lgb_train = lgb.Dataset(X_t, y_t)\nlgb_eval = lgb.Dataset(X_tt, y_tt, reference=lgb_train)","307e6492":"gc.collect()","d3bb4850":"model = lgb.train(\n    params, lgb_train,\n    valid_sets=[lgb_train, lgb_eval],\n    verbose_eval=10,\n    num_boost_round=10000,\n    early_stopping_rounds=200\n)","ff5386d8":"y_pred = model.predict(X_tt)","06199615":"y_true = np.array(y_tt)\n","38b49fcb":"y_pred.min()","f4f1d7b1":"roc_auc_score(y_true, y_pred)","01a038ab":"lgb.plot_importance(model)\nplt.show()","2a5fc78d":"env = riiideducation.make_env()","323bccbb":"iter_test = env.iter_test()","3f2f663c":"for (test_df, sample_prediction_df) in iter_test:\n    test_df = pd.merge(test_df, results_u, on=['user_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_c, on=['content_id'],  how=\"left\")\n    test_df = pd.merge(test_df, results_t, on=['task_container_id'],  how=\"left\")\n    test_df['answered_correctly_user'].fillna(0.5, inplace=True)\n    test_df['answered_correctly_content'].fillna(0.5, inplace=True)\n    test_df['answered_correctly_task'].fillna(0.5, inplace=True)\n    test_df['sum_user_ans'].fillna(0, inplace=True)\n    test_df['sum_task_ans'].fillna(0, inplace=True)\n    test_df['count_user_ans'].fillna(0, inplace=True)\n    test_df['count_task_ans'].fillna(0, inplace=True)\n    test_df['prior_question_elapsed_time'].fillna(test_df['prior_question_elapsed_time'].mean(), inplace=True)\n    sgmin = test_df['prior_question_elapsed_time'].min()\n    sgmax = test_df['prior_question_elapsed_time'].max()\n    test_df['duration'] = (test_df['prior_question_elapsed_time'] - sgmin) \/ (sgmax-sgmin)\n    test_df['prior_question_had_explanation'].fillna(True, inplace=True)\n    test_df[\"prior_question_had_explanation_enc\"] = le.fit_transform(test_df[\"prior_question_had_explanation\"])\n    test_df['answered_correctly'] =  model.predict(test_df[['answered_correctly_user', 'answered_correctly_content', 'sum_user_ans', 'count_user_ans',\n                                                            'answered_correctly_task', 'sum_task_ans', 'count_task_ans', 'duration', \n                                                            'prior_question_elapsed_time','prior_question_had_explanation_enc']])\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","85804c09":"LGBM"}}