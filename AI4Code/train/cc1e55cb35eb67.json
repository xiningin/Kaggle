{"cell_type":{"28d6195f":"code","9be6d34d":"code","635b1c99":"code","0b603feb":"code","9d7e9c9b":"code","b0a3b151":"code","2aa7d308":"code","d9ece5e4":"code","347083b7":"code","7ed928e4":"code","20749e4d":"code","8206b437":"code","2de3ebb1":"code","5401e853":"code","bc920986":"code","1744b3e2":"code","00395f48":"code","afcf1bfe":"markdown","aa4b30e3":"markdown","29f63524":"markdown"},"source":{"28d6195f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers,models\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam","9be6d34d":"BATCH_SIZE =32\nIMAGE_SIZE=256\nCHANNEL = 3","635b1c99":"dataset = tf.keras.utils.image_dataset_from_directory(\n\"..\/input\/plant-village\/PlantVillage\",\n    seed=212,\n    shuffle=True,\n    image_size=(IMAGE_SIZE,IMAGE_SIZE),\n    batch_size=BATCH_SIZE)","0b603feb":"class_names=dataset.class_names\nn_class=len(dataset.class_names)\nprint(n_class)","9d7e9c9b":"print(len(dataset))","b0a3b151":"for image_batch, label_batch in dataset.take(1):\n    print(image_batch.shape)\n    print(label_batch.numpy())","2aa7d308":"plt.figure(figsize=(12,12))\nfor image_batch , label_batch in dataset.take(1):\n    for i in range(15) : \n        ax = plt.subplot(3,5,i+1)\n        #convert the array from tensor to numpy array\n        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[label_batch[i]])\n        plt.axis(\"off\")\n    ","d9ece5e4":"def get_train_val_test_split(ds,shuffle=True,shuffle_size=100):\n    ds_size=len(ds)\n    if shuffle:\n        ds = ds.shuffle(shuffle_size, seed = 12)\n    train_size=int(ds_size*0.8)\n    val_size=int(ds_size*0.1)\n    train_ds=ds.take(train_size)\n    val_ds=ds.skip(train_size).take(val_size)\n    test_ds=ds.skip(train_size).skip(val_size)\n    \n    return train_ds,val_ds,test_ds","347083b7":"train_ds,val_ds,test_ds=get_train_val_test_split(dataset)\nprint(len(train_ds))\nprint(len(val_ds))\nprint(len(test_ds))","7ed928e4":"resize_and_rescale = tf.keras.Sequential([\n  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n  layers.experimental.preprocessing.Rescaling(1.\/255),\n])\n","20749e4d":"data_augmentation = tf.keras.Sequential([\n  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n  layers.experimental.preprocessing.RandomRotation(0.2),\n  layers.experimental.preprocessing.RandomContrast(0.3)\n])","8206b437":"input_shape=(IMAGE_SIZE,IMAGE_SIZE,CHANNEL)\nclassifier = Sequential()\n#resize and augmentation\nclassifier.add(resize_and_rescale)\nclassifier.add(data_augmentation)\n# Convolution Step 1\nclassifier.add(Conv2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=input_shape, activation = 'relu'))\nclassifier.add(BatchNormalization())\n# Max Pooling Step 1\nclassifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 2\nclassifier.add(Conv2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\nclassifier.add(BatchNormalization())\n\n# Max Pooling Step 2\nclassifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 3\nclassifier.add(Conv2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 4\nclassifier.add(Conv2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\nclassifier.add(BatchNormalization())\n\n# Convolution Step 5\nclassifier.add(Conv2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n\n# Max Pooling Step 3\nclassifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\nclassifier.add(BatchNormalization())\n# Flattening Step\nclassifier.add(Flatten())\n# Full Connection Step\nclassifier.add(Dense(units = 4096, activation = 'relu'))\nclassifier.add(Dropout(0.3))\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(units = 2048, activation = 'relu'))\nclassifier.add(Dropout(0.3))\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(units = 1024, activation = 'relu'))\nclassifier.add(Dropout(0.6))\nclassifier.add(BatchNormalization())\nclassifier.add(Dense(units = n_class, activation = 'softmax'))\n\n","2de3ebb1":"opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\nearly_stopping=EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=6, verbose=1, restore_best_weights=True)\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=2,\n    min_lr=1e-7,\n    verbose=1,\n)\ncallbacks = [\n    early_stopping,\n    lr_scheduler    \n]\nclassifier.compile(optimizer=opt,\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy'])\n","5401e853":"history = classifier.fit(train_ds ,validation_data = val_ds , batch_size = 32 , epochs = 50,shuffle=True,callbacks = callbacks)\n","bc920986":"classifier.summary()","1744b3e2":"train_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\n\n\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(train_loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","00395f48":"plt.figure(figsize=(20,20))\nfor img, label in test_ds.take(1):\n    for i in range(9):\n        prediction = classifier.predict(img)\n        ax = plt.subplot(3, 3, i+1)\n        score = tf.nn.softmax(prediction[i])\n        plt.imshow(img[i].numpy().astype('uint8'))\n        plt.title('Truth: ' + class_names[label[i]] +\n                  \"\\n\" + 'Prediction: ' + class_names[np.argmax(score)])\n        plt.axis('off'),\n        plt.tight_layout","afcf1bfe":"#  **Visualize data**","aa4b30e3":"# Data preprocessing ","29f63524":"# BUILD CNN MODEL"}}