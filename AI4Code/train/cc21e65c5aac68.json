{"cell_type":{"786285d7":"code","f1f9ab9c":"code","d1649dfc":"code","d31f7e28":"code","539335fa":"code","4cb7ac97":"code","3e4047f4":"code","ecfbfcc1":"code","94e74a60":"code","3e1e9c59":"code","658533ab":"code","c1b9dfb5":"code","2f1c8e2a":"code","12d632e3":"code","048f98ef":"code","92af5a23":"code","f63ceb0a":"code","8880db64":"code","8d9eff4d":"code","e9655ecf":"code","20e917d5":"code","8344eb5c":"code","c4e90519":"code","748eb86a":"code","5650d67d":"code","7f2c5066":"code","709edd4e":"code","18d5b76e":"code","b25db1f0":"code","821f1bb9":"code","7eddddee":"code","4b6137f6":"code","cab75c41":"code","87da8ae2":"code","e16cfe6e":"code","b116eca3":"markdown","a357f142":"markdown","73ee7915":"markdown","32cf0ae9":"markdown","cad1b8d1":"markdown","624c0014":"markdown","dc2c733b":"markdown","7f982a38":"markdown","c990a571":"markdown","e2972e3d":"markdown","416ba3b9":"markdown","12cfe8a4":"markdown","8cd4617f":"markdown","0c7e224a":"markdown","7c2ccfa8":"markdown","5947a960":"markdown","7ce67f64":"markdown","f3a76cf7":"markdown","1bf38a89":"markdown","a9f30412":"markdown","6339888d":"markdown","8b558152":"markdown","a5cfe83d":"markdown","b28ce0e1":"markdown","e1e088ac":"markdown","d8712c0c":"markdown","d941d063":"markdown","16c61a4c":"markdown","b234d5d0":"markdown"},"source":{"786285d7":"import numpy as np                              # linear algebra\nimport pandas as pd                             # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport missingno as mss                         # Missing data visualization module for Python\nimport matplotlib.pyplot as plt                 # Data visualization\nimport seaborn as sns                           #  Data visualization\nsns.set_style('darkgrid')\nfrom datetime import datetime                   # For Time formate operations\nimport matplotlib.cm as cm                 \nfrom collections import Counter                 # Counter\nimport string                                   # strings\n\nfrom wordcloud import WordCloud, STOPWORDS      # WordCloud \nfrom tqdm import tqdm                           # keep track to iterations\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1f9ab9c":"df_json=pd.read_json('\/kaggle\/input\/youtube-new\/IN_category_id.json').head()\ndf_json.head()","d1649dfc":"df_json['items'][0]","d31f7e28":"df=pd.read_csv('\/kaggle\/input\/youtube-new\/INvideos.csv')\ndf.head()","539335fa":"def permute(x):\n    y=[x.split('.')[0],x.split('.')[2],x.split('.')[1]]\n    return '-'.join(y)\n\ndef convert_to_datetime(df):\n    df['publish_date']=pd.to_datetime(df['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')        # trending date ---> yy|dd|mm\n                                                                                                 # publish time  ---> yyyy|mm|dd\n    df['publish_date']=df['publish_date'].apply(lambda x: str(x)[2:10])\n    \n    df[\"publishing_day\"] = df[\"publish_time\"].apply(\n    lambda x: datetime.strptime(x[:10], \"%Y-%m-%d\").date().strftime('%a'))\n    \n    df.publish_time=df.publish_time.apply(lambda x: str(x)[11:-8])\n    df.trending_date=df.trending_date.apply(permute)\n    \n    return df","4cb7ac97":"def load_data(country_name,fill_catagory=False,change_date=False):\n    file=country_name+str('videos.csv')\n    root_path='\/kaggle\/input\/youtube-new'\n    path=os.path.join(root_path,file)\n    df=pd.read_csv(path)\n    if fill_catagory:\n        title_dict={}\n        json_path=os.path.join(root_path,(country_name+str('_category_id.json')))\n        json_df=pd.read_json(json_path)\n        for dict_ in json_df['items']:\n            title_dict[dict_['id']]=dict_['snippet']['title']\n        global missing_title_cata   # to keep track of missing id ,which shoudn't map from .csv ->.json file\n        missing_title_cata=0\n        def apply_title(x,dictionary):\n            global missing_title_cata\n            try:\n                return dictionary[str(x)]\n            except:\n                missing_title_cata+=1\n                return np.nan\n        df['Title']=df['category_id'].apply(apply_title,args=(title_dict,))\n        \n        if change_date:\n            df=convert_to_datetime(df)\n    \n        print('{} Titles missing'.format(missing_title_cata))\n    return df","3e4047f4":"df=load_data('IN',fill_catagory=True,change_date=True)\ndf.head()","ecfbfcc1":"plt.figure(figsize=(18,7))\nsns.heatmap( df.isnull() , cmap = 'viridis' , yticklabels= False , cbar = True )","94e74a60":"df.info(verbose=0)","3e1e9c59":"df[\"description\"] = df[\"description\"].fillna(value=\" \")","658533ab":"def video_per_year(df,name):\n    df=df.trending_date.apply(lambda x: str(20) + x[:2]).value_counts().reset_index()\n    df.rename(columns={\"index\": \"year\", \"trending_date\": \"video_count\"},inplace=True)\n    sns.barplot(x='year',y='video_count' ,data=df,palette=\"Set1\")\n    \n\nvideo_per_year(df,'in')    ","c1b9dfb5":"def num_title_posted(df):\n    color = [\"#06547a\",\"#36796e\",\"#3e8b7e\",\"#6edda2\", \"#45a4b8\", \"#b6f5f6\", \"#2ecc71\"]\n    df=df.Title.value_counts()\n    df=pd.DataFrame(df)\n    df.reset_index(level=0,inplace=True)\n    plt.figure(figsize=(25,10))\n    df.columns=['Title','value_count']\n    sns.barplot(y='value_count', x=\"Title\", data=df,palette=sns.color_palette(color))","2f1c8e2a":"num_title_posted(df)","12d632e3":"def Plot_hist(df,limit=None,factor='views', per_limit=None):\n    if per_limit is not None:\n        per=(len(df[df[factor]<per_limit][factor])\/len(df[factor]) )*100\n        print('{0} percent of trended videos got less than {1} {2}'.format(per,per_limit,factor))\n    if limit is None:\n        plt.figure(figsize=(14,7))\n        sns.distplot(df[factor], kde=False, color='#976393')\n        plt.ylabel('No. of videos')\n    else:\n        f,ax=plt.subplots(1,2 ,figsize=(20,7))\n        ax[0].set( ylabel=\"No. of Videos\")\n        ax[1].set(ylabel=\"No. of Videos\")\n        sns.distplot(df[factor], kde=False, color='black', ax=ax[0])\n        sns.distplot(df[df[factor] < limit][factor],kde=False, color='b', ax=ax[1])\n    ","048f98ef":"Plot_hist(df,factor='views', limit=0.75e7, per_limit=1.5e6)","92af5a23":"Plot_hist(df, factor='likes', limit=2.5e5, per_limit=25000)","f63ceb0a":"# Function for Single Factor analyses\ndef analyse_by_title(df,factor='views',name=None):\n    print(str(factor))\n    df=df.groupby(['Title'])\n    df=df[factor].mean()\n    df.sort_values(ascending=False,inplace=True)\n    df=pd.DataFrame(df)\n    df.reset_index(level=0,inplace=True)\n    plt.figure(figsize=(20,10))\n    if name is not None:\n        plt.title('Number of {} per Trending Video of each Title category in {}'.format(factor,name))\n    else:\n        plt.title('Number of {} per Trending Video of each Title category'.format(factor))\n    sns.barplot(x=factor, y=\"Title\", data=df)\n    ","8880db64":"# Function for MULTI Factor analyses\ndef analyse_by_mulfactor(df,factors,name=None):\n    print(factors)\n    df=df.groupby(['Title'])\n    f, axes = plt.subplots(1, 2, figsize=(30,9))\n    palettes=['Blues_r','BuGn_r']\n    for i, factor in enumerate(factors):\n        df1=df[factor].mean().drop(['Movies','Gaming','Pets & Animals','Travel & Events','Shows','Autos & Vehicles'])\n        df1.sort_values(ascending=False,inplace=True)\n        df1=pd.DataFrame(df1)\n        df1.reset_index(level=0,inplace=True)\n        plt.figure(figsize=(20,10))\n        if name is not None:\n            axes[i].set_title('Number of {} per Trended Video of each Title category\/Content in {}'.format(factor.capitalize(),name.capitalize()),\n                              fontsize=20 )\n        else:\n            axes[i].set_title('Number of {} per Trended Video of each Title category'.format(factor))\n        sns.barplot(x=factor, y=\"Title\", data=df1,ax=axes[i], palette=palettes[i])\n    ","8d9eff4d":"analyse_by_mulfactor(df,['views','comment_count'],name='India')","e9655ecf":"analyse_by_mulfactor(df,['likes','dislikes'],name='India')","20e917d5":"#Comments Disabled on Videos\n\ndef comment_analysis(df,name):\n    labels=['Comments_disalble','Comments_enable']\n    Values=[df.comments_disabled.value_counts()[1],df.comments_disabled.value_counts()[0]]\n    explode=(0.05,0.2)\n    f,ax=plt.subplots(1,2, figsize=(25,7))\n    ax[0].pie(Values,explode=explode, labels=labels, autopct='%1.1f%%',\n           shadow=True, startangle=90)\n    \n    df=pd.DataFrame(df.groupby(['Title']).comments_disabled.value_counts())\n    df.columns=['Counts']\n    df.reset_index(level=[1,0],inplace=True)\n    plt.title('Comments status of Trending Videos in {}.'.format(name.capitalize()))\n    sns.barplot(x='Counts',y='Title',data=df,hue='comments_disabled',ax= ax[1])\n    return df\n    \n    \ncomment_analysis(df,'INDIA')","8344eb5c":"df['Month']=df.publish_date.apply(lambda x: x[3:5]+str(-20)+x[:2])\ndf.Month.value_counts()","c4e90519":"# We don't have much data of May 2017 ,So we can exclude it.\ndf=df[df.Month!='05-2017']","748eb86a":"#no of content type posted each month\nplt.figure(figsize=(30,13))\nsns.countplot(x='Month', data=df, hue='Title',palette='Set1')\n# Put the legend out of the figure\nplt.xlabel('mm\/yyyy')\nplt.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.1)","5650d67d":"def Plot_Published_Daytime(df,name):\n    Series=df.publishing_day.value_counts()\n    \n    df=df.publish_time.apply(lambda x: x[:2]).value_counts().sort_index().to_frame()\n    df.columns=['Video_Count']; df.reset_index(level=0)\n    \n    f,ax=plt.subplots(1,2, figsize=(25,7))\n    \n    ax[0].set_title(\"DayTime analysis of Video uploads going to Trend in {}\".format(name.capitalize()),fontsize=16)\n    # Set common labels\n    ax[0].set_xlabel('Publishing_hour')\n    ax[0].set_ylabel('video Counts')\n    ax[0].plot(df.index,df.Video_Count,marker='o',ls='--', color='black',\n               markerfacecolor=\"r\",linewidth=2, markersize=10)\n    \n    ax[1].set_xlabel('Publishing_Day')\n    ax[1].set_ylabel('video Counts')\n    ax[1].set_title(\"Publishing day distributions in {}\".format(name.capitalize()),fontsize=16)\n    sns.barplot(x=Series.index, y=Series.values, ax=ax[1],palette='ocean', order=['Mon','Tue','Wed','Thu','Fri','Sat','Sun'])\n    \n\nPlot_Published_Daytime(df,'India')","7f2c5066":"# Selecting Random 5 rows from DataFrame\ndf.sample(5)","709edd4e":"plt.figure(figsize=(12,6))\nlabel=[x.replace('_', ' ',3).title() for x in df.select_dtypes(include=['int','bool']).columns.values]\nsns.heatmap(df.corr(), annot=True,\n           xticklabels=label, yticklabels=label, cmap='Blues')","18d5b76e":"def Plot_corr(df):\n    f,ax=plt.subplots(2,2,figsize=(20,10))\n    \n    sns.scatterplot(x='views',y='likes', data=df, ax=ax[0][0])\n    sns.scatterplot(x='comment_count',y='likes', data=df, ax=ax[0][1])\n    sns.scatterplot(x='dislikes',y='likes', data=df, ax=ax[1][0])\n    sns.scatterplot(x='comment_count',y='views', data=df, ax=ax[1][1])\n\nPlot_corr(df)","b25db1f0":"def Title_dis_visulize(df):\n    f,axes=plt.subplots(1,2, figsize=(20,8))\n    sns.scatterplot(y=df.description.apply(lambda x: len(str(x))),x=df.views, ax=axes[0])\n    sns.scatterplot(y=df.title.apply(len),x=df.views, ax=axes[1])\n    \n    \nTitle_dis_visulize(df)","821f1bb9":"df.head()","7eddddee":"def Show_Wordcolud(df,content_category):\n    print('This may take some Time :-)')\n    if len(content_category) !=4:\n        raise ValueError('Incomplete List to Plot. Expected len:4,got:{}'.format(len(content_category)))\n    else:\n        \n        f,ax=plt.subplots(2,2, figsize=(26,20))\n        i=0\n        for content in tqdm(content_category):\n            mylist=df[df.Title==str(content)].title.apply(lambda x: x.split())\n            mylist = [x for y in mylist for x in y]\n            mylist=[x for x in mylist if x not in string.punctuation]\n            unique_string=(\" \").join(mylist)\n            wordcloud = WordCloud(width=1400, height=1200, background_color='white', max_words=180).generate(unique_string)\n            ax[i\/\/2][i%2].grid(False)\n            ax[i\/\/2][i%2].set_title(\"WordCloud if Titles in '{}' video content\".format(content),fontsize=20)\n            ax[i\/\/2][i%2].imshow(wordcloud, aspect='auto')\n            i+=1\n        plt.show()\n ","4b6137f6":"Show_Wordcolud(df,df.Title.value_counts().index[:4].to_list())","cab75c41":"def Plot_top20_channel(df,name):\n    df=pd.DataFrame(df.channel_title.value_counts()[:20])\n    df=df.reset_index(level=0)\n    df.columns=['Channel_Name', 'Trended Video Count']\n    plt.figure(figsize=(12,6))\n    plt.title('Top 20 Youtube Trending Channel in {}'.format(name))\n    sns.barplot(x='Channel_Name', y='Trended Video Count', data=df, palette=sns.cubehelix_palette(20))\n    plt.xticks(rotation=70)\nPlot_top20_channel(df,'India')    ","87da8ae2":"def Top_Channels(df):\n    Content_list=['Gaming', 'Science & Technology', 'Music', 'Entertainment']\n    f,ax=plt.subplots(2, 2, figsize=(25,12))\n    color=[sns.light_palette((210, 90, 60), input=\"husl\",reverse=True), sns.cubehelix_palette(5,reverse=True),\n          sns.light_palette(\"navy\", reverse=True), sns.light_palette(\"green\",reverse=True)]\n    for i, content in enumerate(Content_list):\n        print('....{}....'.format(content))\n        print(df[df.Title==content].channel_title.value_counts()[:5])\n        print('---------------------------')\n        ax[i\/\/2][i%2].set(xlabel=\"No. of Videos Trended\", ylabel=\"Channel\")\n        ax[i\/\/2][i%2].set_title(content.capitalize(),fontsize=22)\n        sns.barplot(x=df[df.Title==content].channel_title.value_counts()[:5].values,\n                    y=df[df.Title==content].channel_title.value_counts()[:5].index, ax=ax[i\/\/2][i%2], palette=color[i] )\n        ","e16cfe6e":"Top_Channels(df)","b116eca3":"# Correlation between factors to Trend a Video\n\nCorrelation analysis is a method of statistical evaluation used to study the strength of a relationship between two, numerically measured, continuous variables (e.g. height and weight). This particular type of analysis is useful when a researcher wants to establish if there are possible connections between variables. It is often misunderstood that correlation analysis determines cause and effect; however, this is not the case because other variables that are not present in the research may have impacted on the results.\n \n<img src=\"http:\/\/www.djsresearch.co.uk\/images\/Correlation%20Analysis%20Market%20Research.PNG\" width=\"800\" height=\"350\">","a357f142":"# Time series analysis","73ee7915":"**More tha 50% of data is from year 2018  !**","32cf0ae9":"It seems to be quite messy data ,especially for time formating. Also we have to specify video category mapping from **category_id** to our pre-loaded .json file. ","cad1b8d1":"# Pepole's Response factors on trended Videos","624c0014":" **It seems to be factors i.e 'Views', 'Likes' , 'Comment Counts' are positively correlated !**\n<br>\n**Let's take a closer look at them.**","dc2c733b":"There are 560 Videos with **no description**. So to do some sort of data cleaning, and to get rid of those null values, we put an empty string in place of each null value in the description column","7f982a38":"### Top 20 Trended YouTube channels barplot over the data collection time !","c990a571":"### Top 5 Trended Youtube channels in *'Gaming', 'Science & Technology', 'Music', 'Entertainment'* sectors","e2972e3d":"> A heatmap is a graphical representation of data that uses a system of color-coding to represent different values.\n<br>\n> We well use heatmap to visulize correlation strength.","416ba3b9":"1. Now we can see that the **86.2%** of trending videos have **1.5 million** views or less.\n2. Also **82%** of trending videos have **25k likes** or less.\n<br>\n<img src=\"https:\/\/technostalking.com\/wp-content\/uploads\/2019\/10\/image001.jpg\" width=\"400\" >\n<br>\n\n## -------------------------------------------------------------------------\n\n<br>\n","12cfe8a4":"# Visulize video status\/errors","8cd4617f":"# Finding most Appreciated\/Trended video channels among different category\/Titles\nAs One says:\n* Creating consistent content onYouTube isn\u2019t going to guarantee views, shares, likes, or even success.\n* Always deliver more than expected.\n* Success comes down to creating the right content. A big part of this is understanding the type of content that historically does really well on the platform and the types of video that people prefer to consume, especially your audience.","0c7e224a":"# Video Content Distribution","7c2ccfa8":"# Deep analysis on response got by different Content category of Trended Videos\n### Here's what I found on the web about \"*Does the category of a YouTube video affect the views?*\"\nCurrently, the number of YouTube users is huge and almost every aspect of life becomes the inspiration for Youtubers so that they create videos with diverse content. However, not all content will receive the number of views as expected, it completely depends on the tastes of the audience\nThere are millions of people access YouTube every day and their use is completely different. We can divide the purpose of Youtube users into 3 main points:\n*  Entertainment (i.e entertainment, gaming, music, movies etc )\n*  Study         (i.e Science and tech related videos, etc)\n* Discover       (i.e  online teaching videos, travelling, etc )\n\nBecause the purpose of the viewer is not the same, the different categories will receive different views.","5947a960":"# Data Reading and cleaning\n>  Loading .json file first","7ce67f64":"### We can see that from *14\/11\/2017 - 14\/06\/2018*  most people generally gives more preferance to **entertain** themselfs by watching Videos on YouTube !\nI think this is because:\n* People are interested only when any topic is simple and shown to them pictorially . or explained using interesting pictures or examples that are quit common in this world. N people usually see YouTube in there free time. N they see to release there stress not to gain more.\n* When People likes the content in the video. They generally share it with their colleagues, friends, etc to make them feel happy, relax.\n![](https:\/\/i.gifer.com\/74H4.gif)\n<br>\n\n## -------------------------------------------------------------------------\n<br>","f3a76cf7":"## Let's see data distribution w.r.t data collection YEAR","1bf38a89":"# Get feel, Visulize missing values and cataloguing time format of given data","a9f30412":"#### Gaming:\n* In 2017-2018 **Multiplayer combat strategy game** like '*Clash of Clans*'(29 trended videos), '*Clash Royale*'(22 trended videos) gain popularity .\n* Don't know why '*All India Bakchod*' channel is in Gaming category !!?\n\n#### Science & Technology:\n* **Technical Guruji**(215 trended videos), **Geekyranjit**(69 trended videos), **Sharmaji Technical**(68 trended videos) channel providing latest updates from the world of tech, has rose to become world's most subscribed Hindi-Tech YouTube channel.\n*  **Unbox Therapy**(16 trended videos) is a Canadian unboxing and technology YouTube channel produced by Lewis George Hilsenteger and Jack McCann. This channel serve exceptionally great Videos.\n\n#### Music:\n* Channels like **T-Series**(221 trended videos), **Aditya Music**(180 trended videos), **T-Series Apna Punjab(179 trended videos)**, **Zee Music Company(146 trended videos)** provides latest video quality songs, which results in gaining more and more popularity among Viewers.\n\n#### Entertainment:\n* In this sector, Channel gains or losses Popularity accordingly to its content quality and consistency. Look's like **etvteluguindia**, **Flowers Comedy**, **RadaanMedia**, **SAB TV** channels done well here. ","6339888d":"# Text analysis via wordcloud\n**Word clouds (also known as text clouds or tag clouds) work in a simple way: the more a specific word appears in a source of textual data (such as a speech, blog post, or database), the bigger and bolder it appears in the word cloud.**\n\n**A word cloud is a collection, or cluster, of words depicted in different sizes. The bigger and bolder the word appears, the more often it\u2019s mentioned within a given text and the more important it is.**","8b558152":"## Another verification of the correlation matrix is to plot **sactter plot** between variables.\n\n##### 1. High Positive correlation is shown by:\n* Views and likes\n* likes and comment count\n\n##### 2. Moderate Positive correlation is shown by:\n* views and comment count\n\n##### 3. Low correlation is shown by:\n* likes and dislikes\n<br><br>\n\n### Also, We can find the correlation between *length of Trending Video Title,description* with *Views* it gains.\n#### Let's code it below !","a5cfe83d":"Let's read .csv file.","b28ce0e1":"# Welcome .............\nIt should be no surprise that **YouTube** is one of the most popular video hosting platforms out there with almost 5 billion videos watched on the platform per day and 1,300,000,000 users.\n![](https:\/\/images.unsplash.com\/photo-1543185377-99cd16011803?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n<br>\nYouTube is one of the biggest websites around \u2013 to be more specific, it\u2019s currently the second most popular website in the world. And even though most people don\u2019t think of YouTube primarily as a search engine, that\u2019s exactly what most visitors do on the site. YouTube\u2019s not just the second most popular website; it\u2019s also the second most popular search engine \u2013 topped only by Google. This means that the platform presents a huge potential for reach for your business.\n\n\n# >>>><p style=\"font-family:'Courier New'\">This kernel deals with complete EDA on:<p style=\"font-family:verdana\">Trending YouTube Video Statistics dataset<\/p><\/p><<<<\n## To do list -->\n\n* Data Reading and cleaning\n* Get feel, Visulize missing values and cataloguing time format of given data\n* Video Content Distribution\n* Pepole's Response factors on trended Videos\n* Deep analysis on responses of different Content category of trended videos\n* Visulize video status\/errors (i.e comment,likes disabled,video_error_or_removed)\n* Time series analysis\n* Correlation between factors to Trend a Video\n* Text analysis via wordcloud \n* Finding most Appreciated\/Trended video channels among different category\/Titles\n   \n<br>\n\n-\n\n>  Give me your feedback and if you like my kernel **votes up**\n\nNew suggestions or any statistical idea is appreciated.\n## Let's jump to Code Directly.\n------->>>--------->>>-------->>>-------->>>","e1e088ac":"Their is No correlation between them in above 2 Scatter plot !","d8712c0c":"The '**items**' column have more weightage than other columns,\nbecause it contains the dictionary having unique **id**,**title** value pairs for different Video categories. We will then combine it with main .csv file.","d941d063":"### From above Time-Series Graph we can conclude:\n* The days that show the highest level of engagement are from **Thursday through Saturday**, as well as Monday.\n* Videos with around all types of content were actively posted in **month of Dec. 2017** and **May 2018**.\n* Sunday seems to be less active day for video uploads. In general people spend a lot of time trying to master the process of creating an epic YouTube video in free time(i.e **Sunday**)\n* The best time to post, in general, is from **12pm to 2pm**, though we can still get success at early 6am.\n\n\n![](https:\/\/i.pinimg.com\/originals\/78\/9c\/33\/789c3306e7c3813963ad3ca5c237b45a.gif)\n<br>\n\n## -------------------------------------------------------------------------\n<br>","16c61a4c":"## Views Distribution\n**India consumes a tremendous amount of music on YouTube already.**\n* On an average, Popular Music video on YouTube gains around **more than 2.5 million views**.\n* Northern Indian people mostly upvotes Punjabi Type songs.\n* For close to half of those who use YouTube Music commonly, access to the latest soundtracks (49%) is the biggest reason for indulging with the platform.\n\n**Film & Animation**\n* According to bar chart above shown **More than 2 million** people in India enjoys watching movies on YouTube.\n* Youtube is also known for it's hub of movies collection.Also India has a longstanding reputation for its acclaimed film industry and continues to be by far the world\u2019s largest producer of films. Nevertheless, domestic demand for films appears to be waning as in a number of developed countries with mature film industries.\n* India has a longstanding reputation for its acclaimed film industry and continues to be by far the world\u2019s largest producer of films. Nevertheless, domestic demand for films appears to be waning as in a number of developed countries with mature film industries.\n\n**SportsMan Spirit in India.**\n* Trended Sports releated Video  generally gains **more than 1.7 million views**. \n* India is a country that is known for its love of sport and has many sporting teams competing at world class level. Those who play sports in India are passionate and dedicated players, and they are supported by legions of loyal fans.\n\n\n## Response on Comment Section\n\n**Science & Technology**\n* Trended Science fiction Videos or Technical videos have around **17.5k** Comment response. This is because, most of Indian youths show more interest and curiosity in this feild.\n\n**Music**\n* According to ploted bar-chat Trending Music Video on an avg. gets **3.2k** comments.\n* Also fan-Following is one of the major reason behind it.","b234d5d0":"<br>\n<br>\n<br>\n\n## To-Do List completed................!!\n![](https:\/\/i.gifer.com\/7ImI.gif)\n<br>\n# Thanks for reading :-)"}}