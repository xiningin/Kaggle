{"cell_type":{"cf3605ba":"code","3bf1bb30":"code","79d3a459":"code","9422bcb5":"code","60a70856":"code","e7d476d6":"code","a357c4ec":"code","4f8d314d":"code","75beac67":"code","1b458b20":"code","84cb6339":"code","001e1a6f":"code","6ce4cd9e":"code","90b27061":"code","2be80ec2":"code","7c0faa0e":"code","01861736":"code","48176116":"code","fc44a365":"code","9adb9ab1":"code","7738da86":"code","fa478952":"code","f132ae42":"code","66f360fc":"code","4328368c":"code","23a6078b":"code","27d2ebee":"code","18fbd736":"code","b3070106":"code","691437cc":"markdown"},"source":{"cf3605ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3bf1bb30":"os.listdir(\"..\/input\/\")","79d3a459":"base_path = \"..\/input\/\" + os.listdir(\"..\/input\")[0] + \"\/\"\nos.listdir(base_path)","9422bcb5":"drivers_df = pd.read_csv(base_path+\"driver_imgs_list.csv\")","60a70856":"drivers_df.head()","e7d476d6":"categories = {\n\"c0\": \"safe driving\",\n\"c1\": \"texting - right\",\n\"c2\": 'talking on the phone - right',\n\"c3\": \"texting - left\",\n\"c4\": \"talking on the phone - left\",\n'c5': \"operating the radio\",\n'c6': 'drinking',\n'c7': 'reaching behind',\n'c8': 'hair and makeup',\n'c9': 'talking to passenger'\n}","a357c4ec":"??ImageDataBunch.from_folder","4f8d314d":"imgs_path = base_path + \"imgs\/\"\ndata = ImageDataBunch.from_folder(imgs_path, train=imgs_path+\"train\", valid_pct=0.2, test=imgs_path+\"test\",\n                                    ds_tfms=get_transforms(), size=224, bs=16).normalize(imagenet_stats)","75beac67":"data.show_batch(rows=5, figsize=(8,10))","1b458b20":"print(data.classes)\nlen(data.classes),data.c","84cb6339":"learn = cnn_learner(data, models.resnet34, metrics=error_rate)","001e1a6f":"learn.model","6ce4cd9e":"learn.fit_one_cycle(4)","90b27061":"learn.model_dir='\/kaggle\/working\/'","2be80ec2":"learn.save(\"stage-1\")","7c0faa0e":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","01861736":"interp.plot_top_losses(9, figsize=(15,11))","48176116":"interp.plot_confusion_matrix(figsize=(12,12), dpi=60)","fc44a365":"confused = interp.most_confused(min_val=2)","9adb9ab1":"for x in confused:\n    print(\"Real:\",categories[x[0]],\", Predicted:\", categories[x[1]],\", Number of times it did it:\", x[2])","7738da86":"learn.lr_find()","fa478952":"learn.recorder.plot()","f132ae42":"learn.unfreeze()\nlearn.fit_one_cycle(2, max_lr=slice(1e-5,1e-4))","66f360fc":"learn.save(\"stage-2\")","4328368c":"!pip install pytorch2keras","23a6078b":"!pip install onnx","27d2ebee":"pytorch_model = learn.model_dir+\"stage-2.pth\"\nkeras_output = learn.model_dir+\"learn.h5\"","18fbd736":"import tensorflow as tf\nimport torch\nimport onnx","b3070106":"# To Be Continued","691437cc":"# Trying to convert Pytorch(fastai) model to keras\/tf"}}