{"cell_type":{"b51623ba":"code","abe1f646":"code","009cbfdd":"code","ec3ee32a":"code","3fa00682":"code","17b77756":"code","8eac5660":"code","161661b7":"code","75f1e147":"code","611fa928":"code","f1beea1b":"code","ba2c3ecb":"code","7bf73754":"code","2a45d844":"code","3695fe35":"code","6db8d060":"code","c9fbb5f0":"code","3f967127":"code","004baa42":"code","6060ece9":"code","fa9487c1":"code","9e7becd7":"code","81a58e27":"code","d0488b0a":"code","bf62a9bf":"code","757b7be2":"code","c0565ce1":"code","856979d5":"code","c9ffcbea":"code","4f257512":"code","98d817a4":"code","cc7e8840":"code","ccc5e4ae":"code","8d88030d":"code","354f1904":"code","d1ead366":"code","48eaed1e":"code","e8e01df1":"code","7628469e":"code","2f3c0149":"code","d2aa859f":"code","8f312a8d":"code","12201958":"code","3fc7e265":"code","b7ed9a4d":"code","6f8d3dbc":"code","37994873":"code","1ed79079":"code","b829d410":"code","fa6064a8":"code","ed3480ba":"code","59d39a25":"code","3e646229":"code","b7f1a9ca":"code","e39766d5":"code","f1ca8063":"code","250cef5d":"code","1122cafb":"code","4c075054":"code","dfb75e8f":"code","1a1e800e":"code","e24da7e9":"code","722b3cba":"markdown","e3dd7be0":"markdown","8b2152f9":"markdown","75fbadcb":"markdown","9b9401a4":"markdown","f7c55762":"markdown"},"source":{"b51623ba":"import numpy as np\nimport pandas as pd","abe1f646":"df = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf.head()","009cbfdd":"df.isnull().sum()","ec3ee32a":"df_clean = df.drop(['customerID','gender','Partner','Dependents','MonthlyCharges','TotalCharges'],axis = 1)\ndf_clean","3fa00682":"df['PaymentMethod'].unique()","17b77756":"df_clean['PhoneService'] = df_clean['PhoneService'].replace('No','0')\ndf_clean['PhoneService'] = df_clean['PhoneService'].replace('Yes','1')\n\ndf_clean['MultipleLines'] = df_clean['MultipleLines'].replace('No phone service','0')\ndf_clean['MultipleLines'] = df_clean['MultipleLines'].replace('No','1')\ndf_clean['MultipleLines'] = df_clean['MultipleLines'].replace('Yes','2')\n\ndf_clean['InternetService'] = df_clean['InternetService'].replace('DSL','2')\ndf_clean['InternetService'] = df_clean['InternetService'].replace('Fiber optic','1')\ndf_clean['InternetService'] = df_clean['InternetService'].replace('No','0')\n\ndf_clean['OnlineSecurity'] = df_clean['OnlineSecurity'].replace('No internet service','0')\ndf_clean['OnlineSecurity'] = df_clean['OnlineSecurity'].replace('No','1')\ndf_clean['OnlineSecurity'] = df_clean['OnlineSecurity'].replace('Yes','2')\n\ndf_clean['OnlineBackup'] = df_clean['OnlineBackup'].replace('No internet service','0')\ndf_clean['OnlineBackup'] = df_clean['OnlineBackup'].replace('No','1')\ndf_clean['OnlineBackup'] = df_clean['OnlineBackup'].replace('Yes','2')\n\ndf_clean['DeviceProtection'] = df_clean['DeviceProtection'].replace('No internet service','0')\ndf_clean['DeviceProtection'] = df_clean['DeviceProtection'].replace('No','1')\ndf_clean['DeviceProtection'] = df_clean['DeviceProtection'].replace('Yes','2')\n\ndf_clean['TechSupport'] = df_clean['TechSupport'].replace('No internet service','0')\ndf_clean['TechSupport'] = df_clean['TechSupport'].replace('No','1')\ndf_clean['TechSupport'] = df_clean['TechSupport'].replace('Yes','2')\n\ndf_clean['StreamingTV'] = df_clean['StreamingTV'].replace('No internet service','0')\ndf_clean['StreamingTV'] = df_clean['StreamingTV'].replace('No','1')\ndf_clean['StreamingTV'] = df_clean['StreamingTV'].replace('Yes','2')\n\ndf_clean['StreamingMovies'] = df_clean['StreamingMovies'].replace('No internet service','0')\ndf_clean['StreamingMovies'] = df_clean['StreamingMovies'].replace('No','1')\ndf_clean['StreamingMovies'] = df_clean['StreamingMovies'].replace('Yes','2')\n\ndf_clean['Contract'] = df_clean['Contract'].replace('Month-to-month','0')\ndf_clean['Contract'] = df_clean['Contract'].replace('One year','1')\ndf_clean['Contract'] = df_clean['Contract'].replace('Two year','2')\n\ndf_clean['PaperlessBilling'] = df_clean['PaperlessBilling'].replace('No','0')\ndf_clean['PaperlessBilling'] = df_clean['PaperlessBilling'].replace('Yes','1')\n\ndf_clean['PaymentMethod'] = df_clean['PaymentMethod'].replace('Electronic check','0')\ndf_clean['PaymentMethod'] = df_clean['PaymentMethod'].replace('Mailed check','1')\ndf_clean['PaymentMethod'] = df_clean['PaymentMethod'].replace('Bank transfer (automatic)','2')\ndf_clean['PaymentMethod'] = df_clean['PaymentMethod'].replace('Credit card (automatic)','3')\n\ndf_clean['Churn'] = df_clean['Churn'].replace('No','0')\ndf_clean['Churn'] = df_clean['Churn'].replace('Yes','1')\n\ndf_clean","8eac5660":"X = df_clean.drop('Churn', axis = 1)\ny = df_clean['Churn']","161661b7":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)","75f1e147":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=0)","611fa928":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\nparams = {'C' : [1, 2, 4, 8, 16,32,64,128,256,512]}\n\nfrom sklearn.pipeline import Pipeline\nclf = Pipeline([\n  ('scaler', MinMaxScaler(feature_range=(0, 1))),\n  ('feature_selection', SelectKBest(f_classif, k=5)),\n  ('classification', GridSearchCV(LogisticRegression(random_state=0, solver='liblinear'),params, cv=5))\n])\nclf.fit(X_train, y_train)","f1beea1b":"from sklearn.model_selection import cross_val_score\nacc = cross_val_score(clf, X_train, y_train, cv=10)\nprint(\"10CV Training Accuracy : \"+str(acc.mean()))","ba2c3ecb":"yp = clf.predict(X_test)\nacc = sum(yp == y_test)\/len(y_test)\nprint(\"Test accuracy : \"+str(acc*100))","7bf73754":"df = pd.read_csv(\"..\/input\/plenoi-mail\/MAIL.csv\", header = None)\ndf_test = pd.read_csv(\"..\/input\/plenoi-mail\/MAIL_test.csv\", header = None)\ndf_test.head()","2a45d844":"df.groupby(0)[0].count()","3695fe35":"df.isnull().sum()","6db8d060":"X = df.drop(df.columns[0], axis = 1)\ny = df[df.columns[0]]","c9fbb5f0":"from sklearn.model_selection import train_test_split\nX_train, X_test, y, yt = train_test_split(X, y, test_size=0.2, random_state=0)","3f967127":"from sklearn.model_selection import train_test_split\nX_train, X_val, y, yv = train_test_split(X_train, y, test_size=0.2, random_state=0)","004baa42":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=0)\nX_res, y_res = sm.fit_resample(X_train, y)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscl = MinMaxScaler()\nscl.fit(X_res)\nX_train_norm = scl.transform(X_res)\nX_val_norm = scl.transform(X_val)\nX_test_norm = scl.transform(X_test)\ny = y_res","6060ece9":"num_label = len(np.unique(y)) \ny_multi = (np.arange(num_label) == y[:,None]).astype(np.float32)\nyv_multi = (np.arange(num_label) == yv[:,None]).astype(np.float32)","fa9487c1":"sample_size, input_size = X_train_norm.shape","9e7becd7":"import tensorflow as tf\ndef create_model(input_size, num_label):\n    tf.random.set_seed(0)\n    tf.compat.v1.reset_default_graph() # Clear Model\n    model = tf.keras.models.Sequential([\n      tf.keras.layers.Dense(128, activation='relu', input_shape=(input_size,)),  \n      tf.keras.layers.Dense(64, activation='relu'),\n      tf.keras.layers.Dense(32, activation='relu'),\n      tf.keras.layers.Dropout(0.2),\n      tf.keras.layers.Dense(16, activation='relu'),\n      tf.keras.layers.Dense(8, activation='relu'),\n      tf.keras.layers.Dense(4, activation='relu'),\n      tf.keras.layers.Dense(2, activation='relu'),\n      tf.keras.layers.Dropout(0.2),\n      tf.keras.layers.Dense(num_label, activation='softmax')    \n    ])\n    return model","81a58e27":"import tensorflow as tf\ndef create_model(input_size, num_label):\n    tf.random.set_seed(0)\n    tf.compat.v1.reset_default_graph() # Clear Model\n    model = tf.keras.models.Sequential([\n      tf.keras.layers.Dense(128, activation='relu', input_shape=(input_size,)),  \n      tf.keras.layers.Dense(64, activation='relu'),\n      tf.keras.layers.Dense(32, activation='relu'),\n      tf.keras.layers.Dropout(0.2),\n      tf.keras.layers.Dense(16, activation='relu'),\n      tf.keras.layers.Dense(8, activation='relu'),\n      tf.keras.layers.Dense(4, activation='relu'),\n      tf.keras.layers.Dense(2, activation='relu'),\n      tf.keras.layers.Dropout(0.2),\n      tf.keras.layers.Dense(num_label, activation='softmax')    \n    ])\n    return model","d0488b0a":"model = create_model(input_size, num_label)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ntrain_acc = list()\nval_acc = list()\nfor i in range(0,40):\n  history = model.fit(X_train_norm, y_multi, epochs= 2, batch_size = sample_size, validation_data= (X_val_norm, yv_multi))\n  tmp_avg = np.mean(history.history['loss'])\n  tmp_avg_val = np.mean(history.history['val_loss'])\n  train_acc.append(tmp_avg)\n  val_acc.append(tmp_avg_val)","bf62a9bf":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nplt.figure(num=None, figsize=(16, 8), dpi=90, facecolor='w', edgecolor='k')\nplt.plot()\nplt.plot(train_acc)\nplt.plot(val_acc)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","757b7be2":"yp = model.predict(X_test_norm)\nyp = np.argmax(yp, 1)\nsum(yp == yt)\/len(yt)*100","c0565ce1":"Xb = df_test.drop([0],axis=1).values \nyb = df_test[0].values\n\nX_blind_norm = scl.transform(Xb)","856979d5":"yp = model.predict(X_blind_norm)\nyp = np.argmax(yp, 1)\nsum(yp == yb)\/len(yb)*100","c9ffcbea":"df = pd.read_csv(\"..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")\ndf.head()","4f257512":"df.groupby(\"quality\")[\"quality\"].count()","98d817a4":"df_qua = df[(df[\"quality\"]==5) | (df[\"quality\"]==6) | (df[\"quality\"]==7)]\ndf_qua.shape","cc7e8840":"Xo = df_qua.drop([\"quality\"], axis = 1).values\nyo = df_qua[\"quality\"].values","ccc5e4ae":"np.unique(yo)","8d88030d":"yo[yo==5] = 0\nyo[yo==6] = 1\nyo[yo==7] = 2\nnp.unique(yo)","354f1904":"from sklearn.model_selection import train_test_split\nX_train, X_test, y, yt = train_test_split(Xo, yo, test_size=0.2, random_state=0)","d1ead366":"from sklearn.model_selection import train_test_split\nX_train, X_val, y, yv = train_test_split(X_train, y, test_size=0.2, random_state=0)","48eaed1e":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=0)\nX_res, y_res = sm.fit_resample(X_train, y)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscl = MinMaxScaler()\nscl.fit(X_res)\nX_train_norm = scl.transform(X_res)\nX_val_norm = scl.transform(X_val)\nX_test_norm = scl.transform(X_test)\ny = y_res","e8e01df1":"num_label = len(np.unique(y)) \ny_multi = (np.arange(num_label) == y[:,None]).astype(np.float32)\nyv_multi = (np.arange(num_label) == yv[:,None]).astype(np.float32)\nyt_multi = (np.arange(num_label) == yt[:,None]).astype(np.float32)","7628469e":"sample_size, input_size = X_train_norm.shape","2f3c0149":"import tensorflow as tf\ndef create_model(input_size, num_label):\n    tf.random.set_seed(0)\n    tf.compat.v1.reset_default_graph() # Clear Model\n    model = tf.keras.models.Sequential([ \n      tf.keras.layers.Dense(64, activation='relu',input_shape=(input_size,)),\n      tf.keras.layers.Dense(32, activation='relu'),\n      tf.keras.layers.Dense(16, activation='relu'),\n      tf.keras.layers.Dense(8, activation='relu'),\n      tf.keras.layers.Dense(4, activation='relu'),\n      tf.keras.layers.Dense(2, activation='relu'),\n      tf.keras.layers.Dropout(0.2),\n      tf.keras.layers.Dense(num_label, activation='softmax')    \n    ])\n    return model","d2aa859f":"import tensorflow as tf\ndef create_model(input_size, num_label):\n    tf.random.set_seed(0)\n    tf.compat.v1.reset_default_graph() # Clear Model\n    model = tf.keras.models.Sequential([ \n      tf.keras.layers.Dense(64, activation='relu',input_shape=(input_size,)),\n      tf.keras.layers.Dense(32, activation='relu'),\n      tf.keras.layers.Dense(16, activation='relu'),\n      tf.keras.layers.Dense(8, activation='relu'),\n      tf.keras.layers.Dense(4, activation='relu'),\n      tf.keras.layers.Dense(2, activation='relu'),\n      tf.keras.layers.Dropout(0.2),\n      tf.keras.layers.Dense(num_label, activation='softmax')    \n    ])\n    return model","8f312a8d":"model = create_model(input_size, num_label)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ntrain_acc = list()\nval_acc = list()\nfor i in range(0,22):\n  history = model.fit(X_train_norm, y_multi, epochs= 2, batch_size = input_size, validation_data= (X_val_norm, yv_multi))\n  tmp_avg = np.mean(history.history['loss'])\n  tmp_avg_val = np.mean(history.history['val_loss'])\n  train_acc.append(tmp_avg)\n  val_acc.append(tmp_avg_val)","12201958":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nplt.figure(num=None, figsize=(16, 8), dpi=90, facecolor='w', edgecolor='k')\nplt.plot()\nplt.plot(train_acc)\nplt.plot(val_acc)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","3fc7e265":"yp = model.predict(X_test_norm)\nyp = np.argmax(yp, 1)\nsum(yp == yt)\/len(yt)*100","b7ed9a4d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/food41\/images'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6f8d3dbc":"import glob\nccfilename = glob.glob(\"\/kaggle\/input\/food41\/images\/chicken_curry\/*.*\")\nptfilename = glob.glob(\"\/kaggle\/input\/food41\/images\/pad_thai\/*.*\")","37994873":"!mkdir train\n!mkdir train\/chickencurry\n!mkdir train\/padthai","1ed79079":"import shutil \nfor i in range(len(ccfilename)):\n    if i<=i:\n        shutil.copy(ccfilename[i], '.\/train\/chickencurry')","b829d410":"import shutil \nfor i in range(len(ptfilename)):\n    if i<=i:\n        shutil.copy(ptfilename[i], '.\/train\/padthai')","fa6064a8":"!mkdir test\n!mkdir test\/chickencurry\n!mkdir test\/padthai","ed3480ba":"import glob\nfilehd = glob.glob(\".\/train\/chickencurry\/*.*\")\nfiletr = glob.glob(\".\/train\/padthai\/*.*\")","59d39a25":"rng = np.random.RandomState(9)\nmidx = rng.choice(filehd,150, replace=False)\nfidx = rng.choice(filetr,150, replace=False)","3e646229":"for item in fidx:\n    shutil.move(item,'.\/test\/chickencurry\/')\nfor item in midx:\n    shutil.move(item,'.\/test\/padthai\/')","b7f1a9ca":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ndata_generator = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False, \n        samplewise_std_normalization=False, \n\n        zca_whitening=False,  \n        rotation_range=10,  \n        zoom_range = 0.2,\n        width_shift_range=0.1,  \n        height_shift_range=0.1, \n        horizontal_flip=False, \n        vertical_flip=False,  \n        validation_split=0.2)","e39766d5":"train_dir = '.\/train'\nbatch_size = 50\nimg_height = 100 \nimg_width  = 100\ntrain_generator = data_generator.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='training') # set as training data\n\nvalidation_generator = data_generator.flow_from_directory(\n    train_dir, # same directory as training data\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary',\n    subset='validation') # set as validation data","f1ca8063":"train_generator.class_indices","250cef5d":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n# preparing the layers in the Convolutional Deep Neural Network\ndef create_model():\n    tf.random.set_seed(0)\n    tf.compat.v1.reset_default_graph() # Clear Model\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = train_generator.image_shape))\n    model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation = 'relu'))\n    model.add(Conv2D(filters = 8, kernel_size = (3, 3), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Flatten())\n    model.add(Dense(units = 32, activation = 'relu'))\n    model.add(Dropout(rate = 0.1))\n    model.add(Dense(units = 16, activation = 'relu'))\n    model.add(Dropout(rate = 0.1))\n    model.add(Dense(units = 8, activation = 'relu'))\n    model.add(Dense(units = 1, activation = 'sigmoid'))\n    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return model","1122cafb":"model = create_model()\nfitted_model = model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ batch_size,\n    epochs = 20)","4c075054":"import matplotlib.pyplot as plt\n# plotting accuracy and validation accuracy\naccuracy = fitted_model.history['accuracy']\nval_accuracy = fitted_model.history['val_accuracy']\nplt.plot(range(len(accuracy)), accuracy, 'b-', label = 'accuracy')\nplt.plot(range(len(val_accuracy)), val_accuracy, 'r-', label = 'val_accuracy')\nplt.legend()","dfb75e8f":"import glob\nfileCC = glob.glob(\".\/test\/chickencurry\/*.*\")\nfilePT = glob.glob(\".\/test\/padthai\/*.*\")","1a1e800e":"from tensorflow.keras.preprocessing import image\nplabel = []\nfor filename in fileCC:\n    test_image = image.load_img(filename, target_size = (img_height, img_width))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis = 0)\n    plabel.append(np.round(model.predict(test_image)[0][0]))\nplabel = np.array(plabel)\nsum(plabel==0)\/len(plabel)*100","e24da7e9":"from tensorflow.keras.preprocessing import image\nplabel = []\nfor filename in filePT:\n    test_image = image.load_img(filename, target_size = (img_height, img_width))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis = 0)\n    plabel.append(np.round(model.predict(test_image)[0][0]))\nplabel = np.array(plabel)\nsum(plabel==0)\/len(plabel)*100","722b3cba":"#### Q1. Create Model to predict the Telco customer churn (Churn = Label).\n<b><font color=red>The difference of Train and Test accuracy must be lower than 10% to get full score.<\/font><\/b>","e3dd7be0":"#### Q3. Create Deep Learning Model to predict the quality of wine. Our model will focus only on wine with quality of 5, 6, 7 (quality = label)\n<b><font color=red>The difference of Train and Test accuracy must be lower than 10% to get full score.<\/font><\/b>","8b2152f9":"#### Q4. From this food images (\"..\/input\/food41\/images\"), please create an image classifier to classify 2 types of food choosing by yourself. (Show me the accuracy of each type of food) \n<b><font color=red>Both types of food must be more than 50% to get full score.<\/font><\/b>","75fbadcb":"| ![image.png](attachment:68c7e366-9d45-47ff-838c-0c1c38dc08cb.png) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;          |        <em><font size=5>Department of Modern Management and <br> Information Technology <\/font><\/em><br>  <font size=3>College of Arts, Media and Technology,<br> Chiang Mai University<br><\/font> Midterm Examination, Academic Year 2021 <br> Business Data Mining 954471\n|:- |-: \n|<strong>October 18th, 2021 8:00 - 23:59 <\/strong>| <strong>(Total 35 Points) <\/strong>\n\n<b>Name_________________________________________________________________      Student ID_______________________________________________<\/b>\n\nInstructions: \n\n-\tThis exam is worth 35% of your final grade.\n-\tThis exam consists of 5 Questions\n-\tFinish this exam, download it as .ipynb file and send it to my FB messenger.\n-\tWrite your student ID as filename. \n-\tAllow anything.\n-\t<b>Please do this exam alone and be honest to yourself. <\/b>\n-\tThe time allowed students to leave the testing room after the exam is open to copy it.\n-\tStudents who cheat in any way will be prosecuted by the CMU regulation BE 2554, which governs student behavior and describes discipline during the exam period. The proctor must report any suspected cheating to the director.\n<br>\n\n### <em>Score Sheet:<\/em>\n|<font size=3> Question|<font size=3> Full Mark|<font size=3> Student\u2019s Mark|\n|:- |:-:|:-:\n<font size=3> Q1 |<font size=3> 5|\n<font size=3> Q2 |<font size=3> 5|\n<font size=3> Q3 |<font size=3> 5|\n<font size=3> Q4 |<font size=3> 10|\n<font size=3> Q5 |<font size=3> 10|\n<font size=3> Total|<font size=3> 35|\n\n\n\n\n\n\n","9b9401a4":"#### Q2. Create Model to predict the spam mail utilizing feature selection method. (Column 0 = Label)\n<b><font color=red>The difference of Train and Test accuracy must be lower than 10% to get full score.<\/font><\/b>","f7c55762":"#### Q5. Create an object detection model to detect your own face in the picture. (Show me that the model can detect your face in a test image.)\n<b><font color=red>The model must be able to detect your face to get full score.<\/font><\/b>"}}