{"cell_type":{"49030f14":"code","55915695":"code","697022b5":"code","1c5680f0":"code","61d2b69a":"code","39bb3838":"code","0feab4b0":"code","59bebbf6":"code","176678f9":"code","9b378753":"code","2121cc8d":"code","93ed6cb8":"code","6646cac0":"code","4386f52e":"code","ae049a9f":"code","bc450167":"code","086ddb73":"code","68627ba1":"code","c3f93c06":"code","3c7fb3dd":"code","20f58680":"code","1a51c077":"code","577c0f05":"code","f80e465a":"code","52ea062b":"code","21674563":"code","d1966d47":"code","719e9710":"code","93c915ef":"code","57630a3d":"code","401308cf":"code","577feb89":"code","ed8bbc0f":"code","06e0d57e":"code","d1f0e014":"code","530f59e2":"code","5c683495":"code","aa2dc396":"code","614fe98d":"code","c2288653":"code","06a96511":"code","34dce22b":"code","7f3f11d1":"code","f9e68e8c":"code","9700d5f3":"code","3c92b771":"code","585d0516":"code","6cf053df":"code","e8298ff0":"code","0ea01f46":"code","9ef4fb93":"markdown","a3e1dd69":"markdown","c5800317":"markdown","fc79aa58":"markdown","c9b5ffd7":"markdown","1f0cf3a7":"markdown","ebe441a8":"markdown","6e746349":"markdown","b1e3a9e6":"markdown","c9d54fc7":"markdown","1ab650e0":"markdown","5a16cc53":"markdown","d0cc110d":"markdown","3c576b04":"markdown"},"source":{"49030f14":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","55915695":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\nimport re\nfrom category_encoders import MEstimateEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix","697022b5":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\n","1c5680f0":"train_df.head()\n","61d2b69a":"train_df.describe()","39bb3838":"test_df.head()","0feab4b0":"[train_df.shape, test_df.shape]","59bebbf6":"train_df.isnull().sum()","176678f9":"plt.pie(x=train_df[\"Survived\"].value_counts(), \n        colors=[\"seagreen\",\"firebrick\"], \n        labels=[\"Survived\",\"Did not Survive\"], \n        shadow = True, \n        explode = (0, 0.1)\n        )\nplt.show()","9b378753":"sns.countplot(train_df[\"Survived\"], palette=[\"green\", \"red\"]);","2121cc8d":"sns.countplot(train_df[\"Sex\"], palette=[\"blue\", \"pink\"],hue= train_df[\"Survived\"] )","93ed6cb8":"women = train_df.loc[train_df.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women*100)\n\n\nmen = train_df.loc[train_df.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men*100)\n\n","6646cac0":"sns.countplot(x=train_df[\"Pclass\"], palette=\"viridis\", hue= train_df[\"Survived\"] )","4386f52e":"sns.distplot(train_df[\"Age\"], color=\"b\")","ae049a9f":"train_df.isna().sum()","bc450167":"train_df['Age missing']=train_df['Age'].isnull()\n","086ddb73":"for item, frame in train_df['Age'].iteritems():\n    if pd.isnull(frame):\n        if train_df.loc[item,'Parch']==0:\n            train_df.loc[item,'Age']=np.random.randint(low=20, high=60, size=(1,))\n        elif train_df.loc[item,'Parch']>0 and train_df.loc[item,'Parch']<=2:\n            train_df.loc[item,'Age']=np.random.randint(low=1, high=50, size=(1,))\n        elif train_df.loc[item,'Parch']>2 and train_df.loc[item,'Parch']<5:\n            train_df.loc[item,'Age']=np.random.randint(low=25, high=50, size=(1,))\n        elif train_df.loc[item,'Parch']==5:\n            train_df.loc[item,'Age']=np.random.randint(low=35, high=50, size=(1,))\n        elif train_df.loc[item,'Parch']==6:\n            train_df.loc[item,'Age']=np.random.randint(low=40, high=50, size=(1,))","68627ba1":"#Extracting features from name column\u00b6\n\ntrain_df['Nametype']=[''.join(re.findall(', ([a-zA-Z]{1,}).',train_df.loc[z,'Name'])) for z in range(0,len(train_df))]\nmapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5}\ntrain_df['Nametype']=train_df['Nametype'].map(mapping)\ntrain_df['Nametype'].fillna(method='ffill',inplace=True)","c3f93c06":"# Extracting features from Ticket column, like the Ticket number: \n\ntrain_df['Ticketnum']=[''.join(re.findall('[0-9]{1,}',train_df.loc[z,'Ticket'])) for z in range(0,len(train_df))]\ntrain_df['Ticketnum']=pd.to_numeric(train_df['Ticketnum'])\ntrain_df['Ticketnum'].fillna(method='ffill',inplace=True)\n","3c7fb3dd":"train_df.drop(['Ticket','Name','Cabin'],axis=1,inplace=True)","20f58680":"train_df.isna().sum()","1a51c077":"train_df = train_df.dropna()\ntrain_df.isna().sum()","577c0f05":"sex = pd.get_dummies(train_df[\"Sex\"], drop_first=True)\nembarked = pd.get_dummies(train_df[\"Embarked\"], drop_first=True)","f80e465a":"train_df.drop([\"Embarked\", \"Sex\"], axis=1, inplace=True)","52ea062b":"train_df = pd.concat([train_df, sex, embarked], axis=1)\ntrain_df.head()","21674563":"train_df.describe()","d1966d47":"test_df.isna().sum()","719e9710":"test_df['Fare'].fillna(method='ffill',inplace=True)","93c915ef":"sex = pd.get_dummies(test_df[\"Sex\"], drop_first=True)\nembarked = pd.get_dummies(test_df[\"Embarked\"], drop_first=True)","57630a3d":"test_df['Age missing']=test_df['Age'].isnull()\n","401308cf":"for item, frame in test_df['Age'].iteritems():\n    if pd.isnull(frame):\n        if test_df.loc[item,'Parch']==0:\n            test_df.loc[item,'Age']=np.random.randint(low=20, high=60, size=(1,))\n        elif test_df.loc[item,'Parch']>0 and test_df.loc[item,'Parch']<=2:\n            test_df.loc[item,'Age']=np.random.randint(low=1, high=50, size=(1,))\n        elif test_df.loc[item,'Parch']>2 and test_df.loc[item,'Parch']<5:\n            test_df.loc[item,'Age']=np.random.randint(low=25, high=50, size=(1,))\n        elif test_df.loc[item,'Parch']==5:\n            test_df.loc[item,'Age']=np.random.randint(low=35, high=50, size=(1,))\n        elif test_df.loc[item,'Parch']>=6:\n            test_df.loc[item,'Age']=np.random.randint(low=40, high=50, size=(1,))","577feb89":"test_df['Ticketnum']=[''.join(re.findall('[0-9]{1,}',test_df.loc[z,'Ticket'])) for z in range(0,len(test_df))]\ntest_df['Ticketnum']=pd.to_numeric(test_df['Ticketnum'])\ntest_df['Ticketnum'].fillna(method='ffill',inplace=True)","ed8bbc0f":"test_df['Nametype']=[''.join(re.findall(', ([a-zA-Z]{1,}).',test_df.loc[z,'Name'])) for z in range(0,len(test_df))]\ntest_df['Nametype']=test_df['Nametype'].map(mapping)\ntest_df['Nametype'].fillna(method='ffill',inplace=True)","06e0d57e":"test_df.drop([\"Embarked\", \"Sex\", \"Ticket\", \"Name\", \"Cabin\"], axis=1, inplace=True)","d1f0e014":"test_df = pd.concat([test_df, sex, embarked], axis=1)\ntest_df.head()","530f59e2":"train_df['members'] = train_df['SibSp'] + train_df['Parch'] + 1\ntrain_df.head()","5c683495":"test_df['members'] = test_df['SibSp'] + test_df['Parch'] + 1\ntest_df.head()","aa2dc396":"X = train_df.drop('Survived', axis = 1)\ny = train_df['Survived']","614fe98d":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\n","c2288653":"print(len(X_train), len(X_val))","06a96511":"X_val.head()","34dce22b":"logreg=LogisticRegression(C=0.1).fit(X_train,y_train)\nprint(logreg.score(X_train,y_train))\nprint(logreg.score(X_val,y_val))\n","7f3f11d1":"predictions = logreg.predict(X_val)\nfrom ml_metrics import rmse\nprint(rmse(y_val,predictions))","f9e68e8c":"fclf=RandomForestClassifier(n_estimators=10,max_depth=3,random_state=22).fit(X_train,y_train)\nprint(fclf.score(X_train,y_train))\nprint(fclf.score(X_val,y_val))","9700d5f3":"predictions = fclf.predict(X_val)\nfrom ml_metrics import rmse\nprint(rmse(y_val,predictions))","3c92b771":"gbclf=GradientBoostingClassifier(learning_rate=0.05,max_features =4,max_depth=3,random_state=1).fit(X_train,y_train)\nprint(gbclf.score(X_train,y_train))\nprint(gbclf.score(X_val,y_val))\n","585d0516":"predictions = gbclf.predict(X_val)\nfrom ml_metrics import rmse\nprint(rmse(y_val,predictions))","6cf053df":"test_df.dropna(inplace=True)\ntest_df.isna().sum()\n#test_df.head(25)","e8298ff0":"final_prediction = gbclf.predict(test_df) \nprediction = pd.Series(final_prediction)\nprediction.head(25)\n","0ea01f46":"test_df.dropna(inplace=True)\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = prediction\nsubmission['Survived']=submission['Survived'].fillna(0)\nsubmission['Survived']=submission['Survived'].astype(int)\nprint(submission.isna().sum())\nprint(submission.shape)\nsubmission.to_csv('my_submission.csv', index = False)\nprint(\"Your submission was successfully saved!\")","9ef4fb93":"Splitting the data into X train, X test and y train, y test","a3e1dd69":"Parch column can give some indication on age.","c5800317":"Data Preperation and Cleaning","fc79aa58":"**Training the Model**","c9b5ffd7":"Loading the data","1f0cf3a7":"Looking for missing values in the train dataset\n","ebe441a8":"Cleaning Test Data","6e746349":"Data Visualization","b1e3a9e6":"Save Model Using RandomForestClassifier","c9d54fc7":"LinearRegression","1ab650e0":"Drop Cabin Column","5a16cc53":"Importing Libraries","d0cc110d":"Making the submission","3c576b04":"View Data Head"}}