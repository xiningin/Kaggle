{"cell_type":{"03ee012a":"code","43655b72":"code","35550124":"code","2267a6c6":"code","683c653d":"code","d3ea154c":"code","11265c9c":"code","67fb414c":"code","e9460603":"code","812ceb4e":"code","dfb4f4c9":"code","89a185d6":"code","26842722":"code","0a72f22a":"code","c6d76d26":"markdown","7710312d":"markdown","7d27fc61":"markdown","eee75526":"markdown","d16adcf6":"markdown","13d30269":"markdown","c6b516b2":"markdown","0a614f06":"markdown"},"source":{"03ee012a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, ZeroPadding2D, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split\n\nfrom glob import glob\nimport cv2\nimport seaborn as sns\nimport os","43655b72":"labels = ['PNEUMONIA', 'NORMAL']\nimg_size = 150\ndef get_training_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)\n            ","35550124":"train = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train')\nval = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val')\ntest = get_training_data('..\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test')","2267a6c6":"l = []\nfor i in train:\n    if i[1] == 0:\n        l.append(\"PNEUMONIA\")\n    else:\n        l.append(\"NORMAL\")\nsns.set_style('darkgrid')\nsns.countplot(l)","683c653d":"plt.figure(figsize=(5, 5))\nplt.imshow(train[0][0], cmap='gray')\nplt.title(labels[train[0][1]])\n\nplt.figure(figsize=(5, 5))\nplt.imshow(train[-1][0], cmap='gray')\nplt.title(labels[train[-1][1]])","d3ea154c":"x = []\ny = []\n\nfor feature, label in train:\n    x.append(feature)\n    y.append(label)\n    \nfor feature, label in test:\n    x.append(feature)\n    y.append(label)\n    \nfor feature, label in val:\n    x.append(feature)\n    y.append(label)","11265c9c":"x = np.array(x).reshape(-1, img_size, img_size, 1)\ny = np.array(y)\n\nx_train, x_further, y_train, y_further = train_test_split(x, y, test_size=0.2, random_state=0)\nx_val, x_test, y_val, y_test = train_test_split(x_further, y_further, test_size=0.5)\n","67fb414c":"x_train = x_train\/255\nx_test = x_test\/255\nx_val = x_val\/255","e9460603":"datagen = ImageDataGenerator(\n    rotation_range = 30,\n    zoom_range = 0.1,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True,\n    vertical_flip = True\n)\n\ndatagen.fit(x_train)","812ceb4e":"model = Sequential()\n\ninput_shape=(150, 150, 1)\n\nmodel.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', input_shape=input_shape))\nmodel.add(MaxPooling2D((3, 3), strides=2, padding='same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPooling2D((3, 3), strides=2, padding='same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=2, padding='same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=2, padding='same'))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.summary()","dfb4f4c9":"optimizer = Adam(lr = 0.0001)\nearly_stopping_monitor = EarlyStopping(patience=3, monitor=\"val_accuracy\", restore_best_weights=True)\nmodel.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)","89a185d6":"history = model.fit(datagen.flow(x_train,y_train, batch_size=32), epochs = 15, validation_data=datagen.flow(x_val, y_val), callbacks=[early_stopping_monitor])","26842722":"final_loss, final_acc = model.evaluate(x_test, y_test)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4}\".format(final_loss, final_acc))","0a72f22a":"plt.plot(history.history['accuracy'], color='b')\nplt.plot(history.history['val_accuracy'], color='r')\nplt.show()\n\nplt.plot(history.history['loss'], color='b')\nplt.plot(history.history['val_loss'], color='r')\nplt.show()\n","c6d76d26":"# Data Augmentation","7710312d":"# Reshape data and Splitting dataset into Training, Validation and Testing","7d27fc61":"# Convolution Neural Network (CNN)","eee75526":"# Prepare Training, Validation and Testing Data","d16adcf6":"# Process image and Resize them to preferred size","13d30269":"# Normalize data","c6b516b2":"# Visualize Training images","0a614f06":"# Import all Libraries"}}