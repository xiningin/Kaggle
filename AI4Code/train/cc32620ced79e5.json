{"cell_type":{"03bd5ec3":"code","4159d78b":"code","2afe543b":"code","406d3b7e":"code","52b73b3f":"code","e52bbed8":"code","97e2a4c5":"code","818ccf85":"code","f8a0302f":"code","76a692cb":"code","0912441e":"code","ab9ae91f":"code","aeeea0d9":"code","3f7be604":"code","a36fc818":"code","ae9eb328":"code","a831a71b":"code","15ab703a":"code","13fadd08":"code","5b3e46f4":"code","a61864dd":"markdown","6164c79a":"markdown","0bb25fc5":"markdown","7b3f841c":"markdown","239a8130":"markdown"},"source":{"03bd5ec3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","4159d78b":"cc_df = pd.read_csv('..\/input\/creditcard.csv')","2afe543b":"cc_df.info()\ncc_df.describe()\n","406d3b7e":"cc_df.head()","52b73b3f":"sns.pairplot(cc_df,hue='Class')","e52bbed8":"fig, axes = plt.subplots(1,2,figsize=(20,10))\nsns.scatterplot(x='V3', y='V1', hue='Class', data=cc_df, ax=axes[0])\nsns.scatterplot(x='Time', y='Amount', hue= 'Class', data=cc_df, ax=axes[1])","97e2a4c5":"for column in cc_df.columns:\n    a = column + ': ' + str(cc_df[column].isnull().sum())\n    print(a)\n    print('\\n')","818ccf85":"from sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\ncc_df['Amount'] = ss.fit_transform(cc_df['Amount'].values.reshape(-1,1))","f8a0302f":"from sklearn.model_selection import train_test_split\nX = cc_df.drop(['Class','Time'],axis=1)\ny = cc_df['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=109)\n#type(X_train)","76a692cb":"sns.countplot(cc_df['Class'])\ncc_df['Class'].value_counts()","0912441e":"from sklearn.utils import resample\n\n(y_train==0).sum()\nX_train_ones = X_train[y_train == 1]\nX_train_zeros = X_train[y_train == 0]\nX_train_ones = resample(X_train_ones,replace=True,n_samples=len(X_train_zeros))\nX_train_randomOversampled = pd.concat([X_train_ones,X_train_zeros], ignore_index=True)\ny_train_zeros, y_train_ones = y_train[X_train_zeros.index], y_train[X_train_ones.index]\ny_train_randomOversampled = pd.concat([y_train_ones,y_train_zeros], ignore_index=True)\n\n","ab9ae91f":"# Now to try SMOTE\nfrom imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nX_train_smote, y_train_smote = smote.fit_resample(X_train,y_train)\nX_train_smote_df = pd.DataFrame(X_train_smote,columns=X.columns)\ny_train_smote_df = pd.DataFrame(y_train_smote,columns=['Class'])\n","aeeea0d9":"\nsum(y_train_smote_df['Class']==1), sum(y_train_smote_df['Class']==0)","3f7be604":"#Undersampling\nX_train_zeros = X_train[y_train==0].reset_index(drop=True)\n\nimport sklearn\nX_train_ones = X_train[y_train==1]\nX_train_zeros_sampled = X_train_zeros.iloc[sklearn.utils.random.sample_without_replacement(len(X_train_zeros),len(X_train_ones))]\n\nX_train_undersampled = pd.concat([X_train_ones,X_train_zeros_sampled],axis=0).reset_index(drop=True)\ny_train_undersampled = pd.DataFrame(np.concatenate((np.ones(len(X_train_ones)),np.zeros(len(X_train_zeros_sampled))),axis=0)).reset_index(drop=True)\n\n","a36fc818":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import recall_score, f1_score\nseven_foldCV_forC = KFold(n_splits=7)\n\nlist_of_C = [0.001, 0.01, 0.1, 1, 10, 100]\n\nfor C in list_of_C:\n    list_of_recall_scores = []\n    for train_indices, test_indices in seven_foldCV_forC.split(X_train_smote_df):\n        lreg_model = LogisticRegression(C=C, solver='lbfgs')\n        lreg_model.fit(X_train_smote_df.iloc[train_indices],y_train_smote_df.iloc[train_indices].values.ravel())\n        predictions = lreg_model.predict(X_train_smote_df.iloc[test_indices])\n        recall_sc = recall_score(predictions,y_train_smote_df.iloc[test_indices])\n        list_of_recall_scores.append(recall_sc)\n    print('Mean Recall score for C: {} is {}'.format(C, np.mean(list_of_recall_scores)) )\n    \n        ","ae9eb328":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodels = {#'NaiveBayes': MultinomialNB(),\n          'RandomForestClassifier': RandomForestClassifier(n_estimators=400),\n          'LogisticRegression': LogisticRegression(C=10),\n          'SupportVectorClassifier': SVC(),\n          'DecisionTreeClassifier': DecisionTreeClassifier()}","a831a71b":"from sklearn.metrics import roc_auc_score\ndef FindAUC(model, X_train_in, y_train_in, X_test_in, y_test_in):\n    model_fit = model.fit(X_train_in,y_train_in)\n    try:\n        y_pred_score = model_fit.decision_function(X_test_in)\n        return roc_auc_score(y_test_in, y_pred_score)\n    except:\n        y_pred_score = model_fit.predict_proba(X_test_in)    \n        return roc_auc_score(y_test_in, y_pred_score[:,-1])","15ab703a":"    FindAUC(models['LogisticRegression'],X_train_smote_df,y_train_smote_df, X_test, y_test)\n","13fadd08":"auc_list_smote, auc_list_random, auc_list_under = [], [], []\nfor model in models:\n    print('Now checking {}'.format(model))\n    auc_list_smote.append(FindAUC(models[model],X_train_smote_df,y_train_smote_df, X_test, y_test))\n    auc_list_random.append(FindAUC(models[model],X_train_randomOversampled,y_train_randomOversampled, X_test, y_test))\n    auc_list_under.append(FindAUC(models[model],X_train_undersampled,y_train_undersampled, X_test, y_test))\n    print(auc_list_smote)\n    print('\\n')\n#pd.DataFrame(index=[models.keys], columns=['AUC SMOTE', 'AUC RANDOM'])","5b3e46f4":"comp_table = pd.DataFrame(index=[list(models.keys())], columns=['AUC SMOTE', 'AUC RANDOM', 'AUC UNDERSAMPLED'])\ncomp_table['AUC SMOTE'] = auc_list_smote\ncomp_table['AUC RANDOM OVERSAMPLED'] = auc_list_random\ncomp_table['AUC UNDERSAMPLED'] = auc_list_under\ncomp_table","a61864dd":"I want to see how various classification models perform when we use resampled methods for over vs under vs imbalanced sampling of the predictor variables. I don't like the idea of undersampling - because why throw away useful data. I also want to see how the prediction accuracy\/recall changes when using random oversampling from the minority class vs other systematic methods like SMOTE. ","6164c79a":"Now let's look at the balance of the data between the classes","0bb25fc5":"Since most of the variables are anonimized, we can't really draw too many meaningful insights from plotting them but I'll look at a couple that looked interesting from the pairplot.","7b3f841c":"Now that we have a sample to train the models. Let's first use cross validation to tune the hyperparameters for some of the classification models.","239a8130":"Start off with some EDA."}}