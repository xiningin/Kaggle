{"cell_type":{"8e8a2334":"code","0ec1f71f":"code","dcae6eca":"code","52271b32":"code","71fa6bd6":"code","3b2385cc":"code","3057938a":"code","35ef0331":"code","68786c79":"code","70b6471c":"code","42697e47":"code","d852a636":"code","de74b1ea":"code","407e9a43":"code","4a84ff2c":"code","b8a24f95":"code","7955f8fe":"code","d98d2489":"code","f35a5223":"code","63099c86":"code","f3177ac3":"code","0608504d":"code","ecf44f72":"code","94513a59":"code","0bfa1add":"code","a68b2c8f":"markdown","d2f20134":"markdown","918f51be":"markdown","774a760a":"markdown","aee98c8e":"markdown"},"source":{"8e8a2334":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0ec1f71f":"train_data = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/home-data-for-ml-course\/sample_submission.csv')","dcae6eca":"train_data.head()","52271b32":"train_data.info()","71fa6bd6":"train_data.drop(['Id'], axis = 1, inplace = True)\ntest_data.drop(['Id'], axis = 1, inplace = True)","3b2385cc":"y_train = train_data.SalePrice\nX_train = train_data.drop(['SalePrice'], axis = 1)\nX_test = test_data.copy()","3057938a":"object_cols = [col for col in X_train.columns\n              if X_train[col].dtype == 'object']\n\nnum_cols = [col for col in X_train.columns\n           if X_train[col].dtype in ['int64', 'float64']]\n            \nassert len(object_cols) + len(num_cols) == X_train.shape[1]","35ef0331":"X_train[num_cols].isnull().sum()","68786c79":"from sklearn.impute import SimpleImputer\n\nnum_imputer = SimpleImputer(strategy = \"median\")\nimputed_X_train = pd.DataFrame(num_imputer.fit_transform(X_train[num_cols]))\nimputed_X_test = pd.DataFrame(num_imputer.transform(X_test[num_cols]))\n\n# Imputer removes column names, put them back\nimputed_X_train.columns = num_cols\nimputed_X_test.columns = num_cols","70b6471c":"# Final num dataframe\nX_train_num = imputed_X_train.copy()\nX_test_num = imputed_X_test.copy()","42697e47":"X_train_num","d852a636":"X_train[object_cols].isnull().sum()","de74b1ea":"X_train.shape[0]","407e9a43":"# Many missing values\n# less_useful_features = ['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n\nless_useful_features = [col for col in object_cols\n                       if X_train[col].isnull().sum() > 0.25 * X_train.shape[0]]\nuseful_features = list(set(object_cols) - set(less_useful_features))\n\nless_useful_features","4a84ff2c":"assert len(object_cols) - len(useful_features) == len(less_useful_features)","b8a24f95":"X_train[useful_features].isnull().sum()","7955f8fe":"X_train[useful_features].nunique().plot.hist(bins = 30)","d98d2489":"# Columns that are good to be one-hot encoded i.e. have less uniques\ngood_label_cols = [col for col in useful_features\n                  if X_train[col].nunique() < 10]\nbad_label_cols = list(set(useful_features) - set(good_label_cols))\n\nbad_label_cols","f35a5223":"X_train[good_label_cols].copy()","63099c86":"label_X_train = X_train[good_label_cols].copy()\nlabel_X_test = X_test[good_label_cols].copy()\n\ncat_imputer = SimpleImputer(strategy = 'most_frequent')\ncat_imputed_X_train = pd.DataFrame(cat_imputer.fit_transform(label_X_train))\ncat_imputed_X_test = pd.DataFrame(cat_imputer.transform(label_X_test))\n\n# Imputer removes column names, put them back\ncat_imputed_X_train.columns = label_X_train.columns\ncat_imputed_X_test.columns = label_X_test.columns\n\ncat_imputed_X_train","f3177ac3":"from sklearn.preprocessing import OneHotEncoder\n\none_hot_encoder = OneHotEncoder(handle_unknown = 'ignore', sparse = False)\nencoded_X_train = pd.DataFrame(one_hot_encoder.fit_transform(cat_imputed_X_train[good_label_cols]))\nencoded_X_test = pd.DataFrame(one_hot_encoder.transform(cat_imputed_X_test[good_label_cols]))\n\n# One-hot encoder removes index, put it back\nencoded_X_train.index = X_train.index\nencoded_X_test.index = X_test.index\n\n# One-hot encoder removes columns, put it back\ncat_columns = one_hot_encoder.get_feature_names(good_label_cols)\nencoded_X_train.columns = cat_columns\nencoded_X_test.columns = cat_columns","0608504d":"encoded_X_train.head()","ecf44f72":"# Final cat dataframe\nX_train_cat = encoded_X_train.copy()\nX_test_cat = encoded_X_test.copy()","94513a59":"X_train_final = pd.concat([X_train_num, X_train_cat], axis = 1)\nX_test_final = pd.concat([X_test_num, X_test_cat], axis = 1)\n\nX_train_final","0bfa1add":"assert X_train_final.shape[1] == X_train_num.shape[1] + X_train_cat.shape[1]","a68b2c8f":"## Handling categorical features","d2f20134":"## Handling numerical features","918f51be":"## Load the Data","774a760a":"## EDA","aee98c8e":"## Creating final train and test dataframes"}}