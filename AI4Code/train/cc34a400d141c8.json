{"cell_type":{"6f352df1":"code","a1e6e84c":"code","9b449ea0":"code","bbc169a7":"code","a7b37de1":"code","84b1ea7e":"code","79d40fb9":"code","8c4a7a1d":"code","0f349a69":"code","702d1756":"code","f2357617":"code","5104dab5":"code","b0626fe4":"code","121fc306":"code","50e46eb3":"code","46c94545":"code","4f74b40d":"markdown","c8a69570":"markdown","8744df38":"markdown"},"source":{"6f352df1":"import numpy as np \nimport pandas as pd \nimport os \nimport tensorflow as tf \nimport keras\nfrom tensorflow.keras import Input, Model \nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, AlphaDropout, MaxPooling2D, AveragePooling2D, BatchNormalization, Concatenate, Flatten, Reshape, Add, Activation\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom keras.utils.np_utils import to_categorical\nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler ","a1e6e84c":"train_ftr = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_tgt = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv') \ntest_ftr = pd.read_csv('..\/input\/lish-moa\/test_features.csv') \nsubmission = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')\n\ntrain_ftr.shape, train_tgt.shape, test_ftr.shape, submission.shape","9b449ea0":"# visualize train feature dataframe  \ntrain_ftr.head()","bbc169a7":"ignore_columns = ['sig_id','cp_type'] \ntrain_columns = [x for x in train_ftr.columns if x not in ignore_columns]\ntrain = train_ftr[train_columns] \ntest = test_ftr[train_columns] \ntarget = train_tgt.iloc[:,1:].values ","a7b37de1":"le = LabelEncoder() \ntrain['cp_dose'] = le.fit_transform(train['cp_dose']) \ntest['cp_dose'] = le.transform(test['cp_dose'])\n\ntrain['cp_time'] = le.fit_transform(train['cp_time']) \ntest['cp_time'] = le.transform(test['cp_time']) ","84b1ea7e":"train = train.values \ntest = test.values ","79d40fb9":"# column-wise standardization \nscalers = [] \nfor i in range(2,train.shape[1]): \n    arr = train[:,i]\n    arr = arr.reshape(-1,1) \n    sc = StandardScaler() \n    sc.fit(arr) \n    arr = sc.transform(arr) \n    arr = arr.reshape(arr.shape[0]) \n    train[:,i] = arr  \n    scalers.append(sc)","8c4a7a1d":"for i in range(2, test.shape[1]): \n    sc = scalers[i-2] \n    arr = test[:,i] \n    arr = arr.reshape(-1,1)\n    arr = sc.transform(arr) \n    arr = arr.reshape(arr.shape[0])\n    test[:,i] = arr ","0f349a69":"train.shape","702d1756":"def build_model(): \n    inputs = Input((874))\n    dense1 = Dense(256, activation = 'relu')(inputs) \n    dense1 = BatchNormalization()(dense1) \n    dense2 = Dense(256, activation = 'relu')(dense1) \n    dense2 = BatchNormalization()(dense2) \n    dense3 = Dense(256, activation = 'relu')(dense2) \n    dense3 = Add()([dense1, dense3])  \n    dense3 = BatchNormalization()(dense3) \n    outputs = Dropout(0.25)(dense3) \n    outputs = Dense(206, activation = 'sigmoid')(outputs)\n    model = Model(inputs = inputs, outputs = outputs) \n    model.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n    return model \n\nmodel = build_model() \nmodel.summary()","f2357617":"k = int(0.9*len(train))\nx_train = train[:k] \ny_train = target[:k] \n\nx_val = train[k:]\ny_val = target[k:]","5104dab5":"\n\n#checkpoint = ModelCheckpoint(filepath=model_path,monitor='val_loss',verbose=1,save_best_only=True)\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.8)\n\n\nhistory = model.fit(x_train,\n                    y_train,\n                    batch_size = 32,\n                    shuffle = True, \n                    validation_data = (x_val,y_val),\n                    verbose = 1, \n                    epochs = 5)\n","b0626fe4":"pred = model.predict(test)","121fc306":"for i in range(submission.shape[0]):\n    submission.iloc[i,1:] = pred[i] ","50e46eb3":"submission","46c94545":"submission.to_csv('submission.csv', index = False)","4f74b40d":"# Preprocess Data","c8a69570":"This notebook is a baseline I made to make a first submission for the Kaggle MOA contest. ","8744df38":"# Load Dataset"}}