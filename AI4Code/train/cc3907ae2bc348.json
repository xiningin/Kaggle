{"cell_type":{"4d76b78d":"code","6de33b99":"code","417f9b1f":"code","6c5f01bf":"code","5f9ba3e1":"code","2328fffb":"code","92b233da":"code","bb1249c3":"code","6248958d":"code","6d20d9ff":"code","41c23134":"code","02ca2db4":"code","b6c325a8":"code","38cb3960":"code","0db15822":"code","be773e19":"code","69a99d77":"code","e2ca6a47":"code","344edc37":"code","c72ff35a":"code","5706bfe3":"code","a2aa2438":"code","8bb6b7ae":"code","1e6ab124":"code","cbbe6d82":"code","da0ce806":"code","156df56d":"code","2681a5b3":"code","8b421fd1":"code","bfabce5e":"code","660850c5":"code","3b25b7a0":"code","b48d0142":"code","b66868e7":"code","e90791bc":"code","6bc1a78e":"code","822d4a43":"code","9a53118a":"code","6177c448":"code","ed059bf3":"code","bc906914":"code","782753e9":"code","b2e74c47":"code","e0ec2f4c":"code","93ef9691":"code","3b93210c":"code","f2a93abe":"code","4b9db369":"code","3da1a1c8":"code","bde921e6":"code","8456d2cd":"code","e5ab5933":"code","989622c5":"code","f1880f50":"code","81f2ce15":"code","8557759d":"code","0e7ddbbb":"code","c91eb632":"code","3e07c886":"code","cf72e091":"code","452fd46e":"code","26106225":"code","d75c0345":"code","6c309aac":"markdown","956a1df0":"markdown","1de2e6db":"markdown","e3a93517":"markdown","352f1f80":"markdown","89b1aee8":"markdown","abc1a01a":"markdown","2b68ca60":"markdown","2a9af9aa":"markdown","04e99b3a":"markdown","09a494e4":"markdown","7c1141f1":"markdown","8e1521fb":"markdown","2124455a":"markdown","ac62101d":"markdown","edeed366":"markdown","976bd930":"markdown","4c14e438":"markdown","69491298":"markdown","a5b31d5b":"markdown","43d46cda":"markdown","437c0f57":"markdown","6354aa1b":"markdown","eb09ec80":"markdown","5fc27cef":"markdown","a9a1d411":"markdown","33c8e5b2":"markdown","4f1b8f68":"markdown","c36b2dfb":"markdown","6d6b0b8d":"markdown","e936f7bf":"markdown","7475d923":"markdown","4ae7aa8b":"markdown","9fb63159":"markdown","322b6600":"markdown","bf24fb0f":"markdown","3d097303":"markdown","defb3e16":"markdown","e4edf989":"markdown","1aae8bcf":"markdown"},"source":{"4d76b78d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6de33b99":"import pandas as pd\nimport numpy as np\nimport random\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","417f9b1f":"data_train = pd.read_csv('..\/input\/titanic\/train.csv') \ndata_test = pd.read_csv('..\/input\/titanic\/test.csv')\n\nprint(\" Data training: \"+str(data_train.shape[0]) + \" rows and \" + str(data_train.shape[1] - 1) + \" features\" + \"\\n\",\n      \"Data test: \"+str(data_test.shape[0]) + \" rows and \" + str(data_test.shape[1]) + \" features\")","6c5f01bf":"data_train.head()","5f9ba3e1":"data_test.head()","2328fffb":"X_train = data_train.drop(['Survived'],axis=1)\ny_train = data_train[['Survived']]","92b233da":"X_train.head()","bb1249c3":"y_train.head()","6248958d":"data_train.describe()","6d20d9ff":"data_train.corr()","41c23134":"%matplotlib inline\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport pylab as plot\n\nparams = { \n    'axes.labelsize': 30,\n    'legend.fontsize': 25\n}\n\nplot.rcParams.update(params)\n\ndata_train['Died'] = 1 - data_train['Survived']\ndata_train.groupby('Sex').agg('sum')[['Survived', 'Died']].plot(kind='bar', figsize=(32, 10),rot=0, fontsize = 30)","02ca2db4":"\ndata_train.groupby('Sex').agg('mean')[['Survived', 'Died']].plot(kind='bar', figsize=(32, 10),stacked=True,rot=0, fontsize = 30)","b6c325a8":"fig = plt.figure(figsize=(30, 10))\nsns.set(font_scale = 2.5)\nsns.violinplot(x='Sex', y='Age', \n               hue='Survived', data=data_train, \n               split=True,\n               palette={0: \"orange\", 1: \"b\"}\n              );","38cb3960":"figure = plt.figure(figsize=(20, 10))\n\nplt.hist([data_train[data_train['Survived'] == 1]['Fare'], data_train[data_train['Survived'] == 0]['Fare']], \n         stacked=False, color = ['blue','orange'],\n         bins = 40, label = ['Survived','Dead'])\nplt.xlabel('Fare')\nplt.ylabel('Number of passengers')\nplt.legend();","0db15822":"ax = plt.subplot()\nax.set_ylabel('Average fare')\ndata_train.groupby('Pclass').mean()['Fare'].plot(kind='bar', figsize=(20, 7), ax = ax, rot = 0);","be773e19":"fig = plt.figure(figsize=(25, 7))\nsns.violinplot(x='Embarked', y='Fare', hue='Survived', data=data_train, split=True, palette={0: \"orange\", 1: \"blue\"});\n","69a99d77":"titles = set()\nfor name in data_train['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\n\nprint(\"data_train\",titles, '\\n')\n\ntitles = set()\nfor name in data_test['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\n\nprint(\"data_test\",titles, '\\n')","e2ca6a47":"Title_Dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Sir\" : \"Royalty\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Lady\" : \"Royalty\",\n    \"Dona\" : \"Mrs\"\n}\n\ndef status(feature):\n    print('Processing', feature, ': ok')\n\ndef get_titles(combined):\n    # we extract the title from each name\n    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    \n    # a map of more aggregated title\n    # we map each title\n    combined['Title'] = combined.Title.map(Title_Dictionary)\n    status('Title')\n    return combined","344edc37":"X_train = get_titles(X_train)","c72ff35a":"X_train","5706bfe3":"data_test = get_titles(data_test)","a2aa2438":"data_test.head()","8bb6b7ae":"data_test[data_test['Title'].isnull()]","1e6ab124":"grouped_train = X_train.groupby(['Sex','Pclass','Title'])\ngrouped_median_train = grouped_train.median()\ngrouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Title', 'Fare']]\n\ngrouped_median_train","cbbe6d82":"X_train[X_train[\"Fare\"]==0]","da0ce806":"X_train[X_train[\"PassengerId\"]==278]","156df56d":"def fill_fare(row):\n    condition = (\n        (grouped_median_train['Sex'] == row['Sex']) & \n        (grouped_median_train['Title'] == row['Title']) & \n        (grouped_median_train['Pclass'] == row['Pclass'])\n    ) \n    return grouped_median_train[condition]['Fare'].values[0]\n\n\ndef process_fare(combined):\n    # a function that fills the missing values of the Age variable\n    combined['Fare'] = combined.apply(lambda row: fill_fare(row) if row['Fare'] == 0 else row['Fare'], axis=1)\n    combined.Fare.fillna(combined.Fare.mean(), inplace=True)\n    return combined\n\nX_train = process_fare(X_train)\n\ndata_test = process_fare(data_test)","2681a5b3":"X_train[X_train[\"PassengerId\"]==278]","8b421fd1":"X_train[X_train[\"Fare\"]==0]","bfabce5e":"data_test[data_test[\"Fare\"]==0]","660850c5":"grouped_train = X_train.groupby(['Sex','Pclass','Title'])\ngrouped_median_train = grouped_train.median()\ngrouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n\ngrouped_median_train","3b25b7a0":"def fill_age(row):\n    condition = (\n        (grouped_median_train['Sex'] == row['Sex']) & \n        (grouped_median_train['Title'] == row['Title']) & \n        (grouped_median_train['Pclass'] == row['Pclass'])\n    ) \n    return grouped_median_train[condition]['Age'].values[0]\n\n\ndef process_age(combined):\n    # a function that fills the missing values of the Age variable\n    combined['Age'] = combined.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n    status('age')\n    return combined\n\nX_train = process_age(X_train)\ndata_test = process_age(data_test)","b48d0142":"data_test","b66868e7":"def process_names(combined):\n    # we clean the Name variable\n    combined.drop('Name', axis=1, inplace=True)\n    \n    # encoding in dummy variable\n    titles_dummies = pd.get_dummies(combined['Title'], prefix='Title')\n    combined = pd.concat([combined, titles_dummies], axis=1)\n    \n    # removing the title variable\n    combined.drop('Title', axis=1, inplace=True)\n    \n    status('names')\n    return combined\n\nX_train = process_names(X_train)\ndata_test = process_names(data_test)","e90791bc":"def process_embarked(combined):\n    # two missing embarked values - filling them with the most frequent one in the train  set(S)\n    combined.Embarked.fillna('S', inplace=True)\n    # dummy encoding \n    embarked_dummies = pd.get_dummies(combined['Embarked'], prefix='Embarked')\n    combined = pd.concat([combined, embarked_dummies], axis=1)\n    combined.drop('Embarked', axis=1, inplace=True)\n    status('embarked')\n    return combined\n","6bc1a78e":"X_train = process_embarked(X_train)\ndata_test = process_embarked(data_test)","822d4a43":"X_train.drop('PassengerId', axis=1, inplace=True)\ndata_test.drop('PassengerId', axis=1, inplace=True)","9a53118a":"train_cabin, test_cabin = set(), set()\n\nfor c in X_train['Cabin']:\n    try:\n        train_cabin.add(c[0])\n    except:\n        train_cabin.add('U')\n\nprint(train_cabin)\n# set(['A', 'C', 'B', 'E', 'D', 'G', 'F', 'U', 'T'])","6177c448":"def process_cabin(combined):    \n    # replacing missing cabins with U (for Uknown)\n    combined.Cabin.fillna('U', inplace=True)\n    \n    # mapping each Cabin value with the cabin letter\n    combined['Cabin'] = combined['Cabin'].map(lambda c: c[0])\n    \n    # dummy encoding ...\n    cabin_dummies = pd.get_dummies(combined['Cabin'], prefix='Cabin')    \n    combined = pd.concat([combined, cabin_dummies], axis=1)\n\n    combined.drop('Cabin', axis=1, inplace=True)\n    status('cabin')\n    return combined","ed059bf3":"X_train = process_cabin(X_train)\ndata_test = process_cabin(data_test)","bc906914":"def process_sex(combined):\n    # mapping string values to numerical one \n    combined['Sex'] = combined['Sex'].map({'male':1, 'female':0})\n    status('Sex')\n    return combined\n\nX_train = process_sex(X_train)\ndata_test = process_sex(data_test)","782753e9":"X_train.head()","b2e74c47":"def process_pclass(combined):\n    # encoding into 3 categories:\n    pclass_dummies = pd.get_dummies(combined['Pclass'], prefix=\"Pclass\")\n    \n    # adding dummy variable\n    combined = pd.concat([combined, pclass_dummies],axis=1)\n    \n    # removing \"Pclass\"\n    combined.drop('Pclass',axis=1,inplace=True)\n    \n    status('Pclass')\n    return combined\n\nX_train = process_pclass(X_train)\ndata_test = process_pclass(data_test)","e0ec2f4c":"X_train.head()","93ef9691":"def cleanTicket(ticket):\n    ticket = ticket.replace('.', '')\n    ticket = ticket.replace('\/', '')\n    ticket = ticket.split()\n    ticket = map(lambda t : t.strip(), ticket)\n    ticket = list(filter(lambda t : not t.isdigit(), ticket))\n    if len(ticket) > 0:\n        return ticket[0]\n    else: \n        return 'XXX'\n\ndef process_ticket(combined):\n    \n    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n    def cleanTicket(ticket):\n        ticket = ticket.replace('.','')\n        ticket = ticket.replace('\/','')\n        ticket = ticket.split()\n        ticket = map(lambda t : t.strip(), ticket)\n        #ticket = filter(lambda t : not t.isdigit(), ticket)\n        ticket = [t for t in ticket if not t.isdigit()]\n        if len(ticket) > 0:\n            return ticket[0]\n        else: \n            return 'XXX'\n    \n\n    # Extracting dummy variables from tickets:\n\n    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n    tickets_dummies = pd.get_dummies(combined['Ticket'], prefix='Ticket')\n    combined = pd.concat([combined, tickets_dummies], axis=1)\n    combined.drop('Ticket', inplace=True, axis=1)\n\n    status('Ticket')\n    return combined\n\nX_train = process_ticket(X_train)\ndata_test = process_ticket(data_test)","3b93210c":"X_train.head()","f2a93abe":"def process_family(combined):\n    \n    # introducing a new feature : the size of families (including the passenger)\n    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n    \n    # introducing other features based on the family size\n    combined['Singleton'] = combined['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    combined['SmallFamily'] = combined['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n    combined['LargeFamily'] = combined['FamilySize'].map(lambda s: 1 if 5 <= s else 0)\n    \n    status('family')\n    return combined","4b9db369":"process_family(X_train)\nprocess_family(data_test)","3da1a1c8":"X_train.head()","bde921e6":"def compute_score(clf, X, y, scoring='accuracy'):\n    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n    return np.mean(xval)","8456d2cd":"clf = RandomForestClassifier(random_state=0)\nclf = clf.fit(X_train, y_train)","e5ab5933":"features = pd.DataFrame()\nfeatures['feature'] = X_train.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(25, 25))","989622c5":"features['importance'].sort_values(ascending=True)\n\nfeatures.index","f1880f50":"#X_train = X_train[['LargeFamily','FamilySize','Fare','Cabin_U','Title_Officer','Age','Pclass_3','Title_Mr']]\nX_train = X_train[['Cabin_G', 'Ticket_FCC',\n       'Ticket_STONO2', 'Ticket_SCPARIS', 'Cabin_F',\n       'Ticket_CA', 'Ticket_WC', 'Ticket_SOTONOQ', 'Cabin_A',\n       'Ticket_A5', 'Title_Officer', 'Ticket_STONO',\n       'Title_Master', 'Cabin_D', 'Ticket_PC', 'Singleton', 'Cabin_C',\n       'Cabin_B', 'Embarked_Q', 'Cabin_E', 'Embarked_C', 'LargeFamily',\n       'Pclass_2', 'Ticket_XXX', 'Parch', 'Embarked_S', 'Pclass_1',\n       'SmallFamily', 'SibSp', 'FamilySize', 'Title_Mrs', 'Title_Miss',\n       'Cabin_U', 'Pclass_3', 'Sex', 'Title_Mr', 'Age', 'Fare']]\n","81f2ce15":"X_train.head()","8557759d":"#data_test = data_test[['LargeFamily','FamilySize','Fare','Cabin_U','Title_Officer','Age','Pclass_3','Title_Mr']]\n\ndata_test = data_test[['Cabin_G', 'Ticket_FCC',\n       'Ticket_STONO2', 'Ticket_SCPARIS', 'Cabin_F',\n       'Ticket_CA', 'Ticket_WC', 'Ticket_SOTONOQ', 'Cabin_A',\n       'Ticket_A5', 'Title_Officer', 'Ticket_STONO',\n       'Title_Master', 'Cabin_D', 'Ticket_PC', 'Singleton', 'Cabin_C',\n       'Cabin_B', 'Embarked_Q', 'Cabin_E', 'Embarked_C', 'LargeFamily',\n       'Pclass_2', 'Ticket_XXX', 'Parch', 'Embarked_S', 'Pclass_1',\n       'SmallFamily', 'SibSp', 'FamilySize', 'Title_Mrs', 'Title_Miss',\n       'Cabin_U', 'Pclass_3', 'Sex', 'Title_Mr', 'Age', 'Fare']]\n","0e7ddbbb":"data_test.head()","c91eb632":"from sklearn.model_selection import GridSearchCV\n# Create the parameter grid based on the results of random search \n\nparam_grid = {\n    'bootstrap': [True],\n    'max_depth': [90, 100, 110],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300]\n}\n# Create a based model\nrf = RandomForestClassifier(random_state=0)\n# Instantiate the grid search model\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n                          cv = 10, n_jobs = -1, verbose = 2)\n\n# Fit the grid search to the data\ngrid_search.fit(X_train, y_train)\ngrid_search.best_params_","3e07c886":"#X_train\n# 100, 3 , 3, 12, 200\nmodel = RandomForestClassifier(bootstrap= True,\n max_depth = 90,\n max_features = 3,\n min_samples_leaf = 3,\n min_samples_split = 12,\n n_estimators = 200,random_state=0)","cf72e091":"model.fit(X_train, y_train)","452fd46e":"features['importance'].sort_values(ascending=True)\n\nfeatures.index","26106225":"model.predict(data_test)","d75c0345":"output = model.predict(data_test).astype(int)\ndf_output = pd.DataFrame()\naux = pd.read_csv('..\/input\/titanic\/test.csv')\ndf_output['PassengerId'] = aux['PassengerId']\ndf_output['Survived'] = output\ndf_output[['PassengerId','Survived']].to_csv('gridsearch_rf_rn_stt_03_01.csv', index=False)","6c309aac":"# -- Feature Engineering --","956a1df0":"# Categorical value - Sex","1de2e6db":"# Data test","e3a93517":"# Missing age values\n\nI made the same at ages values that we didn't have in our dataframe.","352f1f80":"Now we are looking at port embarked, fare, and survival. Again, we see that richer people have more chances to be alive, except at embarked Q. Q embarked seems to be symmetrical, so poor and rich people have approximately the same chance to be alive.","89b1aee8":"Clearly we can see that 'sex' has a huge importance at survival of titanic's people. In this case, female has more chances to survive.","abc1a01a":"As we can see, young people had more chance to survive. If you look at blue, there are local peaks in both, male and female. However, when we look at the orange, the local peak is at old females. The global peak for males and females is about 20 yrs old.","2b68ca60":"# One-Hot Encoding - Embarked","2a9af9aa":"# Take a brief look at the data\n\nLet's check the data format and what we have in columns.","04e99b3a":"# Defining input and output for training\n\nLet's create two data frames, the first has the features and the second has the labels.","09a494e4":"When we look at the histogram above, we can see that most poor people died. It's, once you are poor, you will have more chance to die. Looking at the richest people, the number of deaths decreased a lot, once you are rich, you will be less chance to die. For example, we can see that fare > 100 people has more chance to be alive than dead.","7c1141f1":"# Analysing data\n\nLet's check the data using the **describe** method from pandas.","8e1521fb":"### Classes","2124455a":"# Missing fare values\n\nI note that some values in Fare are equal to zero, so I decided to create a data frame with median values in the same sex, class, and title group. I took these values and replace them where our data frame was zero.","ac62101d":"### Age vs Survived","edeed366":"### Number of passengers","976bd930":"# References","4c14e438":"## Analysing features","69491298":"How To Start with Kaggle \u2014 An Introduction to the Titanic \ud83d\udea2 Challenge: https:\/\/medium.com\/datadriveninvestor\/start-with-kaggle-a-comprehensive-guide-to-solve-the-titanic-challenge-8ac5815b0473\n\nMatplotlib tutorial: https:\/\/matplotlib.org\/3.3.3\/tutorials\/introductory\/customizing.html\n\nPandas plot: https:\/\/pandas.pydata.org\/pandas-docs\/version\/0.15.2\/generated\/pandas.DataFrame.plot.html\n\nScikit learn (grid_search): https:\/\/scikit-learn.org\/stable\/modules\/grid_search.html\n\nGridSearchCV: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html","a5b31d5b":"# Remove PassengerId","43d46cda":"# One-Hot Encoding - Pclass","437c0f57":"# One-Hot Encoding - Title","6354aa1b":"# Chosing features","eb09ec80":"Fare and Pclass have the absolute highest correlation. After that, we have Parch and SibSp, and Fare and Survived. Note that Pclass and Survived are not continuous data, so these correlations aren't interesting for us. Correlation is more useful when we are making regression instead of classification.","5fc27cef":"# Importing libraries","a9a1d411":"# Getting the data\n\nWe will assign the data to **data_train** and **data_test** data frames and check the amount of data and number of features.","33c8e5b2":"Above, we can see that people in class 1 is significantly richer than the other classes. Class 3 is the poorest. So, we see that class 1 people had more chances to be alive.","4f1b8f68":"# Creating column \"Title\"\n\nOnce we know that rich people have more chances to be alive, your title is important to survive. Create a column with titles can be an interesting feature. After creating this and other features, we're gonna create a random forest model and we will check feature importance using the **feature_importances_** method.","c36b2dfb":"### Analysing 'sex' feature","6d6b0b8d":"# One-hot enconding - ticket","e936f7bf":"# Data training","7475d923":"# Add feature - family","4ae7aa8b":"# Top 7% TITANIC notebook","9fb63159":"You need to note that categorical data won't be shown above (name, ticket, sex...). Next steps we will deal with categorical data, now let's take a look at the numerical data above. We can see that all the features, except Age, are without blanks (remember we have 891 rows in data_train). This is good because we didn't lose a lot of data. Note that, however, we can fill the NaN values with median, median, or another process, never this will be better than have the original data.\n\nLooking above we can check that max Age is 80, Fare values have a large interval between min and max. It's important to take a look at the **describe method** of a data frame, so you can get more insights about the data. ","322b6600":"Let's check our data. Note that it is important to check each step because we have a lot of steps and one mistake will be passed forward to the next steps. \n\n**Hint: one way to avoid a lot of checks is using pipelines. Unfortunately, I didn't use it but can be\nuseful. You can learn about pipelines in Kaggle micro-courses.**","bf24fb0f":"# Creating submission","3d097303":"# One-Hot Encoding - Cabin","defb3e16":"# Parameter tuning","e4edf989":"As you can see, we have a lot of features of Titanic's passengers. \nWe need to check these features and make an analysis to know what is the most important features and if we can build new features from those already been in our data.","1aae8bcf":"We have 11 features. **PassengerId** is just a number to identify the passengers, but you don't need to worry about it. **P-class** is the ticket class, the numbers are 1, 2, or 3, low values are more expensive. People in 1st class, for example, have better accommodations than 3rd class tickets. The **Name** has the passenger's names, pay attention to the title that a person has in your name (Mr, Miss, Mrs, Mr). **Sex** is about male or female. **Age** is the passenger's age. **SibSp** is a number of siblings\/spouses aboard the Titanic. **Parch** is the number of parents\/children aboard the Titanic. In **Ticket**, we have these names, but we don't know about the ticket's name meaning. **Fare** is the money that the passenger needs to pay to trip in titanic. The **Cabin** is the cabin's number and **Embarked** is the port of embarkation."}}