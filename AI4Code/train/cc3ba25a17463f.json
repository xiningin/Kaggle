{"cell_type":{"5352f3e5":"code","5f785b87":"code","ccc4e8ef":"code","3606535c":"code","f7333d14":"code","e1559f80":"code","9d626f91":"code","e46204ac":"code","5a28aa93":"code","59676a47":"code","3365fc76":"code","3988f0ac":"code","c4ff9682":"code","9e0fc266":"code","1fb91713":"code","456a4443":"code","c1e57f78":"markdown"},"source":{"5352f3e5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5f785b87":"!pip install fastai2 fastdot -q\n","ccc4e8ef":"# from fast_tabnet.core import *\n# from fast_tabnet.core import TabNetNoEmbeddings\nfrom fastai2.tabular.all import *\n# import pandas as pd\n# import numpy as np","3606535c":"path = '..\/input\/covid19\/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx'\ndf = pd.read_excel(path)","f7333d14":"dfnum = df.select_dtypes(include=['float64']).astype('float32')","e1559f80":"df.head(15).T","9d626f91":"cat_name = ['WINDOW', 'AGE_ABOVE65', 'GENDER', 'AGE_PERCENTIL', 'DISEASE GROUPING 1', 'DISEASE GROUPING 2', 'DISEASE GROUPING 3',\n             'DISEASE GROUPING 4', 'DISEASE GROUPING 5', 'DISEASE GROUPING 6', 'IMMUNOCOMPROMISED', 'HTN']\ncont_name = [ \"ALBUMIN_MEDIAN\", \"ALBUMIN_MEAN\", \"ALBUMIN_MIN\",\n               \"ALBUMIN_MAX\", \"BE_ARTERIAL_MEDIAN\", \"BE_ARTERIAL_MEAN\",\n               \"BE_ARTERIAL_MIN\", \"BE_ARTERIAL_MAX\", \"BE_VENOUS_MEDIAN\",\n               \"BE_VENOUS_MEAN\", \"BE_VENOUS_MIN\", \"BE_VENOUS_MAX\",\n               \"HEMATOCRITE_MEDIAN\", \"HEMATOCRITE_MEAN\", \"HEMATOCRITE_MIN\",\n               \"HEMATOCRITE_MAX\", \"HEMOGLOBIN_MEDIAN\", \"HEMOGLOBIN_MEAN\",\n               \"HEMOGLOBIN_MIN\", \"HEMOGLOBIN_MAX\", \"LACTATE_MEDIAN\", \"LACTATE_MEAN\",\n               \"LACTATE_MIN\", \"LACTATE_MAX\", \"LEUKOCYTES_MEDIAN\", \"LEUKOCYTES_MEAN\",\n               \"LEUKOCYTES_MIN\", \"LEUKOCYTES_MAX\", \"NEUTROPHILES_MEDIAN\",\n               \"NEUTROPHILES_MEAN\", \"NEUTROPHILES_MIN\", \"NEUTROPHILES_MAX\",\n               \"UREA_MEDIAN\", \"UREA_MEAN\", \"UREA_MIN\", \"UREA_MAX\",\n               \"BLOODPRESSURE_DIASTOLIC_MEAN\", \"RESPIRATORY_RATE_MEAN\",\n               \"BLOODPRESSURE_DIASTOLIC_MEDIAN\", \"RESPIRATORY_RATE_MEDIAN\",\n               \"BLOODPRESSURE_DIASTOLIC_MIN\", \"HEART_RATE_MIN\", \"TEMPERATURE_MIN\",\n               \"OXYGEN_SATURATION_MIN\", \"BLOODPRESSURE_SISTOLIC_MAX\", \"HEART_RATE_MAX\",\n               \"RESPIRATORY_RATE_MAX\", \"OXYGEN_SATURATION_MAX\",\n               \"BLOODPRESSURE_DIASTOLIC_DIFF\", \"BLOODPRESSURE_SISTOLIC_DIFF\",\n               \"HEART_RATE_DIFF\", \"RESPIRATORY_RATE_DIFF\", \"TEMPERATURE_DIFF\",\n               \"OXYGEN_SATURATION_DIFF\", \"BLOODPRESSURE_DIASTOLIC_DIFF_REL\",\n               \"BLOODPRESSURE_SISTOLIC_DIFF_REL\", \"HEART_RATE_DIFF_REL\",\n               \"RESPIRATORY_RATE_DIFF_REL\", \"TEMPERATURE_DIFF_REL\",\n               \"OXYGEN_SATURATION_DIFF_REL\"]\n\nprocs = [FillMissing, Categorify, Normalize] \n\n\nmsk = np.random.rand(len(df)) < 0.7\n\ntrain = df[msk] # Train df 70%\ntest = df[~msk] # Test df  30%\nln = len(train)\nidxs = []\nfor i in range(2):\n    np.random.seed(i+4)\n    valid_idx = np.random.choice(ln, int(ln*0.2), replace=False)\n    idxs.append(valid_idx)","e46204ac":"preds = []\nfor idx in idxs:\n    cat_name = ['WINDOW', 'AGE_ABOVE65', 'GENDER', 'AGE_PERCENTIL']#, 'DISEASE GROUPING 1', 'DISEASE GROUPING 2', 'DISEASE GROUPING 3',\n#              'DISEASE GROUPING 4', 'DISEASE GROUPING 5', 'DISEASE GROUPING 6', 'IMMUNOCOMPROMISED', 'HTN']\n    cont_name = [ \"ALBUMIN_MEDIAN\", \"ALBUMIN_MEAN\", \"ALBUMIN_MIN\",\n               \"ALBUMIN_MAX\", \"BE_ARTERIAL_MEDIAN\", \"BE_ARTERIAL_MEAN\",\n               \"BE_ARTERIAL_MIN\", \"BE_ARTERIAL_MAX\", \"BE_VENOUS_MEDIAN\",\n               \"BE_VENOUS_MEAN\", \"BE_VENOUS_MIN\", \"BE_VENOUS_MAX\",\n               \"HEMATOCRITE_MEDIAN\", \"HEMATOCRITE_MEAN\", \"HEMATOCRITE_MIN\",\n               \"HEMATOCRITE_MAX\", \"HEMOGLOBIN_MEDIAN\", \"HEMOGLOBIN_MEAN\",\n               \"HEMOGLOBIN_MIN\", \"HEMOGLOBIN_MAX\", \"LACTATE_MEDIAN\", \"LACTATE_MEAN\",\n               \"LACTATE_MIN\", \"LACTATE_MAX\", \"LEUKOCYTES_MEDIAN\", \"LEUKOCYTES_MEAN\",\n               \"LEUKOCYTES_MIN\", \"LEUKOCYTES_MAX\", \"NEUTROPHILES_MEDIAN\",\n               \"NEUTROPHILES_MEAN\", \"NEUTROPHILES_MIN\", \"NEUTROPHILES_MAX\",\n               \"UREA_MEDIAN\", \"UREA_MEAN\", \"UREA_MIN\", \"UREA_MAX\",\n               \"BLOODPRESSURE_DIASTOLIC_MEAN\", \"RESPIRATORY_RATE_MEAN\",\n               \"BLOODPRESSURE_DIASTOLIC_MEDIAN\", \"RESPIRATORY_RATE_MEDIAN\",\n               \"BLOODPRESSURE_DIASTOLIC_MIN\", \"HEART_RATE_MIN\", \"TEMPERATURE_MIN\",\n               \"OXYGEN_SATURATION_MIN\", \"BLOODPRESSURE_SISTOLIC_MAX\", \"HEART_RATE_MAX\",\n               \"RESPIRATORY_RATE_MAX\", \"OXYGEN_SATURATION_MAX\",\n               \"BLOODPRESSURE_DIASTOLIC_DIFF\", \"BLOODPRESSURE_SISTOLIC_DIFF\",\n               \"HEART_RATE_DIFF\", \"RESPIRATORY_RATE_DIFF\", \"TEMPERATURE_DIFF\",\n               \"OXYGEN_SATURATION_DIFF\", \"BLOODPRESSURE_DIASTOLIC_DIFF_REL\",\n               \"BLOODPRESSURE_SISTOLIC_DIFF_REL\", \"HEART_RATE_DIFF_REL\",\n               \"RESPIRATORY_RATE_DIFF_REL\", \"TEMPERATURE_DIFF_REL\",\n               \"OXYGEN_SATURATION_DIFF_REL\"]\n\n    procs = [FillMissing, Categorify, Normalize] \n    to = TabularPandas(train, procs, cat_names=cat_name, cont_names=cont_name, y_names=\"ICU\", splits = IndexSplitter(idx)(range_of(train)))\n    dls = to.dataloaders(bs=512)\n    learn = tabular_learner(dls, layers=[400,100], loss_func=MSELossFlat(), emb_drop=0.5)\n    learn.clip =.25\n    learn.fit_one_cycle(8, 5e-4)\n    dl = learn.dls.test_dl(test)\n    pred, _ = learn.get_preds()\n    preds.append(pred.numpy())\n","5a28aa93":"len(preds)","59676a47":"for i in range(len(preds)-1):\n    predict = preds[i]+preds[i+1]\npre = predict\/len(preds)\n","3365fc76":"_, icu = learn.get_preds()\nicus = icu.numpy()","3988f0ac":"def decode(res, th):\n    result = []\n    for p in res:\n        if p > th:\n            result.append(1)\n        else:\n            result.append(0)\n    return result","c4ff9682":"res = decode(pre, 0.01)","9e0fc266":"def precision(res, icus):\n    tp = 0\n    fp = 0\n    tn = 0\n    fn = 0\n    for i, re in enumerate(res):\n        if (icus[i]==1):\n            if re==1:\n                tp=tp+1\n            else:\n                fn=fn+1\n        else:\n            if re==1:\n                fp=fp+1\n            else:\n                tn=tn+1\n    precision = (tp\/(tp+fp))\n    recall = (tp\/(tp+fn))\n    \n    print('Accuracy = {:.2f}'.format(((tp+tn)\/(tp+fp+tn+fn))))\n    print('Precision = {:.2f}'.format(precision))\n    print('Recall = {:.2f}'.format(recall))\n    print('F1 = {:.2f}'.format(2*((precision*recall)\/(precision+recall))))\n\nprecision(res, icus)","1fb91713":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import auc\nfpr, tpr, thresholds = roc_curve(icus, res)","456a4443":"auc = roc_auc_score(icus, res)\nprint('AUC: %.3f' % auc)","c1e57f78":"# Experimenting with fastai2 tabular regression (still working)"}}