{"cell_type":{"38203605":"code","9d5c05e5":"code","d46a560d":"code","6623ea66":"code","a56da3e5":"code","7f351d65":"code","791d028f":"code","817fc54c":"code","419e3cfc":"code","6c5b31c6":"code","98964c40":"code","e0dd89d1":"code","8f4d7f72":"code","90206f52":"code","4ced3046":"code","a7eee794":"code","03de7a49":"code","d6510896":"code","8fc1245c":"markdown","d757cf5c":"markdown","06984535":"markdown","04e46bfb":"markdown","af8cb1da":"markdown","ec2c9d2d":"markdown","94d03999":"markdown","4bdb6418":"markdown","a36b3fd9":"markdown","1fba8bf6":"markdown","8ea553c9":"markdown","1128537a":"markdown","fe624e21":"markdown","f64dba16":"markdown","64111cf2":"markdown","328ae271":"markdown","f24cc22f":"markdown","c9a511fd":"markdown","5cd8ba95":"markdown"},"source":{"38203605":"#importing necessery libraries for future analysis of the dataset\n!pip install calmap\n\nfrom datetime import date\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport geopandas as gpd\nimport geoplot\nfrom geopy import Nominatim\nimport folium\nimport mapclassify\nimport plotly.express as px \nimport plotly.graph_objs as go \nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom folium.plugins import HeatMapWithTime, TimestampedGeoJson\nimport matplotlib.style as style \nstyle.use('fivethirtyeight')\nimport numpy as np; np.random.seed(sum(map(ord, 'calmap')))\nimport pandas as pd\nimport calmap\nfrom shapely.geometry import Polygon\nfrom shapely.geometry import MultiPolygon\n        \n#Now Loading Tweetes Dataset \ncovid_tweets_data = pd.read_csv('..\/input\/covid19-tweets\/covid19_tweets.csv')","9d5c05e5":"covid_tweets_data.head()","d46a560d":"nRow, nCol = covid_tweets_data.shape\nprint(f'There are {nRow} rows and {nCol} columns')","6623ea66":"covid_tweets_data.info()","a56da3e5":"covid_tweets_data.describe()","7f351d65":"# World City Dataset\n\ncities = pd.read_csv('..\/input\/world-cities-datasets\/worldcities.csv')","791d028f":"## Duplicate Location in Tweets Dataset\n\ncovid_tweets_data[\"location\"] = covid_tweets_data[\"user_location\"]\ncovid_tweets_data[\"country\"] = np.NaN\n","817fc54c":"user_location = covid_tweets_data['location'].fillna(value='').str.split(',')","419e3cfc":"lat = cities['lat'].fillna(value = '').values.tolist()\nlng = cities['lng'].fillna(value = '').values.tolist()\ncountry = cities['country'].fillna(value = '').values.tolist()\n\n# Getting all alpha 3 codes into  a list\nworld_city_iso3 = []\nfor c in cities['iso3'].str.lower().str.strip().values.tolist():\n    if c not in world_city_iso3:\n        world_city_iso3.append(c)\n        \n# Getting all alpha 2 codes into  a list    \nworld_city_iso2 = []\nfor c in cities['iso2'].str.lower().str.strip().values.tolist():\n    if c not in world_city_iso2:\n        world_city_iso2.append(c)\n        \n# Getting all countries into  a list        \nworld_city_country = []\nfor c in cities['country'].str.lower().str.strip().values.tolist():\n    if c not in world_city_country:\n        world_city_country.append(c)\n\n# Getting all amdin names into  a list\nworld_states = []\nfor c in cities['admin_name'].str.lower().str.strip().tolist():\n    world_states.append(c)\n\n\n# Getting all cities into  a list\nworld_city = cities['city'].fillna(value = '').str.lower().str.strip().values.tolist()\n\n","6c5b31c6":"\nfor each_loc in range(len(user_location)):\n    ind = each_loc\n    each_loc = user_location[each_loc]\n    for each in each_loc:\n        each = each.lower().strip()\n        if each in world_city:\n            order = world_city.index(each)\n            covid_tweets_data['country'][ind] = country[order]\n            continue\n        if each in world_states:\n            order= world_states.index(each)\n            covid_tweets_data['country'][ind] = country[order]\n            continue\n        if each in world_city_country:\n            order = world_city_country.index(each)\n            covid_tweets_data['country'][ind] = world_city_country[order]\n            continue\n        if each in world_city_iso2:\n            order = world_city_iso2.index(each)\n            covid_tweets_data['country'][ind] = world_city_country[order]\n            continue\n        if each in world_city_iso3:\n            order = world_city_iso3.index(each)\n            covid_tweets_data['country'][ind] = world_city_country[order]\n            continue\n","98964c40":"print('Total Number of valid Tweets Available: ',covid_tweets_data['country'].isnull().sum())","e0dd89d1":"tweet_per_country = covid_tweets_data['country'].str.lower().dropna()\ntw = tweet_per_country.value_counts().rename_axis('Country').reset_index(name='Tweet Count')\nprint(tw)\nplt.rcParams['figure.figsize'] = (15,10)\nplt.title('Top 10 Countries with Most Tweets',fontsize=15)\nsns.set_palette(\"husl\")\nax = sns.barplot(y=tw['Country'].head(10),x=tw['Tweet Count'].head(10))","8f4d7f72":"tweet_per_country = covid_tweets_data['country'].str.lower().dropna()\ntw = tweet_per_country.value_counts().rename_axis('Country').reset_index(name='Tweet Count')\nprint(tw)\nplt.rcParams['figure.figsize'] = (15,10)\nplt.title('10 Countries with Least Tweets',fontsize=15)\nsns.set_palette(\"husl\")\nax = sns.barplot(y=tw['Country'][-9:],x=tw['Tweet Count'][-9:])","90206f52":"print (covid_tweets_data[\"date\"].min())\nprint (covid_tweets_data[\"date\"].max())","4ced3046":"country_graph_03=px.bar(x='Tweet Count',y='Country',data_frame=tw[:15],color='Country')\ncountry_graph_03.show()","a7eee794":"geolocator = Nominatim(user_agent=\"covid19-application\")","03de7a49":"def visualize_Global_Corona_map(df,  zoom):\n    \n    lat_map=30.038557\n    lon_map=31.231781\n    f = folium.Figure(width=1000, height=500)\n    m = folium.Map([lat_map,lon_map], zoom_start=zoom).add_to(f)\n    print(df[\"Country\"])\n    for i in range(0,len(df)):\n        t_country=str(df[\"Country\"][i])\n        location = geolocator.geocode(t_country)\n        popup_text='<i>Location:'+t_country+', Tweets: '+str(df[\"Tweet Count\"][i])+'<\/i>'\n        folium.Marker(location=[location.latitude,location.longitude],popup=popup_text,icon=folium.Icon(icon_color='white',icon ='virus',prefix='fa')).add_to(m)\n    \n    return m","d6510896":"visualize_Global_Corona_map(tw, 1)","8fc1245c":"# Conclusion <a id=\"10\"><\/a>\nThis concludes your Geographical Deep analysis! To go forward from here, click the blue \"Fork Notebook\" button at the top of this kernel. This will create a copy of the code and environment for you to edit. Delete, modify, and add code as you please. Happy Kaggling! For More Follow me or Give me a Star or contact me now at [Safdar Khan](https:\/\/www.safdarhan.ml) or [clikc Here to email me](mailto:safdarkhanofficial@gmail.com).","d757cf5c":"These tweets are collected using Twitter API and a Python script. A query for this high-frequency hashtag (#covid19) is run on a daily basis for a certain time period, to collect a larger number of tweets samples.\n\nContent The tweets have #covid19 hashtag. Collection started on 25\/7\/2020, with an initial 17k batch and will continue on a daily basis.\n\n* The collection script can be found here: https:\/\/github.com\/gabrielpreda\/covid-19-tweets","06984535":"## **<a id=\"6\">Top 10 Countries with Most Tweets<\/a>**","04e46bfb":"<a id=\"2\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Visualizing and Understading of Data<\/div>","af8cb1da":"**<a id=\"5\">Valid Tweets<\/a>**","ec2c9d2d":"<a id=\"1\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Data and library loading<\/div>","94d03999":"This Dataset Contains Following Columns and Datatypes","4bdb6418":"## **<a id=\"7\">10 Countries with Least Tweets<\/a>**","a36b3fd9":"## **<a id=\"8\">Top 15 Countries with Most Tweets Diffrent Representation<\/a>**","1fba8bf6":"1. user_name         **(object)**\n2. user_location     **(object)**\n3. user_description  **(object)**\n4. user_created      **(object)**\n5. user_followers    **(int64)** \n6. user_friends      **(int64)** \n7. user_favourites   **(int64)** \n8. user_verified     **(bool)**  \n9. date              **(object)**\n10. text              **(object)**\n11. hashtags          **(object)**\n12. source            **(object)**\n13. is_retweet        **(bool)**  \n\n> dtypes: bool(2), int64(3), object(8)","8ea553c9":"## **<a id=\"9\">Geo-MAP<\/a>**","1128537a":"View Recentrly Imported Dataset","fe624e21":"<a id=\"4\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Data visualizations<\/div>","f64dba16":"<a id=\"3\"><\/a> <br>\n# <div class=\"alert alert-block alert-info\">Preprocessing\/Data Cleaning<\/div>","64111cf2":"# Removing Mising Values","328ae271":"# <center>\ud83c\udf0e ANALYSIS OF COVID-19  DATA<\/center>","f24cc22f":"The section consists of various section of geo analysis of data\n## **Content**\n\n1. [Data and library loading](#1)\n2. [Visualizing and Understading of Data](#2)\n3. [Preprocessing\/Data Cleaning](#3)\n4. [Data Viualization](#4)\n    * [Valid Tweets](#5)\n    * [Top 10 Countries with Most Tweets](#6)\n    * [10 Countries with Least Tweets](#7)\n    * [Top 15 Countries with Most Tweets Diffrent Representation](#8)\n    * [Geo-MAP](#9)\n10. [Conclusion](#10)","c9a511fd":"**Min and Max Dates Between The Dataset**","5cd8ba95":"# Feature Engineering(Countries Where Users Tweet)"}}