{"cell_type":{"737b4f8d":"code","d542880a":"code","e6643a3f":"code","01846f2a":"code","53a7e66c":"code","cd953b66":"code","f0fb6f59":"code","9967441e":"code","4c7e1fd1":"code","e1edb0ce":"code","108b0fd0":"code","8f5e9ed2":"code","d184b085":"code","62c2cd01":"code","e54b13e1":"code","38a51df9":"code","4e4eb20a":"code","6e844c70":"code","34782c3c":"code","0d3dd6ae":"markdown","ab7b3d6f":"markdown","c50c9e60":"markdown","ebbd0724":"markdown","b231c5ba":"markdown","2cb68950":"markdown","8958ec86":"markdown","93269dff":"markdown","322516f8":"markdown","3f34dbad":"markdown","83436121":"markdown","5d1cb878":"markdown","cf1cbc55":"markdown","ef4ef0a1":"markdown"},"source":{"737b4f8d":"import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_classification\nfrom math import log\nimport math\nfrom sklearn.metrics import log_loss","d542880a":"X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)","e6643a3f":"X.shape, y.shape","01846f2a":"from sklearn.model_selection import train_test_split","53a7e66c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)","cd953b66":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","f0fb6f59":"from sklearn import linear_model","9967441e":"# alpha : float\n# Constant that multiplies the regularization term. \n\n# eta0 : double\n# The initial learning rate for the \u2018constant\u2019, \u2018invscaling\u2019 or \u2018adaptive\u2019 schedules.\n\nclf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\nclf","4c7e1fd1":"clf.fit(X=X_train, y=y_train)","e1edb0ce":"def sigmoid(w,x,b):\n  Z = np.dot(w,x)+b\n  return(1\/(1 + np.exp(-Z)))","108b0fd0":"def mod(w):\n  sum1 = 0\n  for i in w:\n    sum1  = sum1 + i*i\n  return(math.sqrt(sum1)) ","8f5e9ed2":"w = np.zeros_like(X_train[0])\nb = 0\neta0  = 0.0001\nalpha = 0.0001\nN = len(X_train)","d184b085":"TRAIN_LOSS = []\nTEST_LOSS = []\n\n\n#Train loss\nloss = 0\nfor i in range(len(X_train)):\n  loss += (np.log(sigmoid(w,X_train[i],b)) * y_train[i] + np.log(1 - sigmoid(w,X_train[i],b)) * (1 - y_train[i]))\nloss = (-1)*loss\/len(X_train) \nTRAIN_LOSS.append(loss)\n\n#Test Loss\nloss = 0\nfor i in range(len(X_test)):\n  loss += (np.log(sigmoid(w,X_test[i],b)) * y_test[i] + np.log(1 - sigmoid(w,X_test[i],b)) * (1 - y_test[i]))\nloss = (-1)*loss\/len(X_test) \nTEST_LOSS.append(loss)","62c2cd01":"from sklearn.metrics import log_loss\nl = len(X_train)\nfor ep in range(20):\n\n  '''Update weights and intercept for each point'''\n  for i in range(len(X_train)):\n    w = (1 - (0.0001)\/l)*w + 0.0001 * X_train[i] * (y_train[i] - sigmoid(w,X_train[i],b))\n    \n    b = b + 0.0001*(y_train[i]-sigmoid(w,X_train[i],b))\n\n  ''' Find Loss'''\n  #Train loss\n  loss = 0\n  for i in range(len(X_train)):\n    loss += (np.log(sigmoid(w,X_train[i],b)) * y_train[i] + np.log(1 - sigmoid(w,X_train[i],b)) * (1 - y_train[i]))\n  loss = (-1)*loss\/len(X_train) \n  TRAIN_LOSS.append(loss)\n\n  #Test Loss\n  loss = 0\n  for i in range(len(X_test)):\n    loss += (np.log(sigmoid(w,X_test[i],b)) * y_test[i] + np.log(1 - sigmoid(w,X_test[i],b)) * (1 - y_test[i]))\n  loss = (-1)*loss\/len(X_test) \n  TEST_LOSS.append(loss)","e54b13e1":"print(\"Weights are :\",w)\n\nprint(\"Intercept :\" ,b)","38a51df9":"import matplotlib.pyplot as plt\nplt.scatter([i for i in range(21)] ,TRAIN_LOSS, alpha=0.5)\nplt.scatter([i for i in range(21)] ,TEST_LOSS, alpha=0.5)\nplt.title('LOSS changes as per epoches')\nplt.xlabel('epoches')\nplt.ylabel('LOSS')\nplt.show()","4e4eb20a":"print(TRAIN_LOSS)\nprint(TEST_LOSS)","6e844c70":"w-clf.coef_, b-clf.intercept_","34782c3c":"def pred(w,b, X):\n    N = len(X)\n    predict = []\n    for i in range(N):\n        if sigmoid(w, X[i], b) >= 0.5: # sigmoid(w,x,b) returns 1\/(1+exp(-(dot(x,w)+b)))\n            predict.append(1)\n        else:\n            predict.append(0)\n    return np.array(predict)\nprint(1-np.sum(y_train - pred(w,b,X_train))\/len(X_train))\nprint(1-np.sum(y_test  - pred(w,b,X_test))\/len(X_test))","0d3dd6ae":"Apply algorithm to find weights and loss","ab7b3d6f":"## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn","c50c9e60":"Find initial loss and append it to list","ebbd0724":"- for each epoch:\n    - for each batch of data points in train: (keep batch size=1)\n        - calculate the gradient of loss function w.r.t each weight in weight vector\n        - Calculate the gradient of the intercept <a href='https:\/\/drive.google.com\/file\/d\/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H\/view?usp=sharing'>check this<\/a>\n        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https:\/\/drive.google.com\/file\/d\/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H\/view?usp=sharing'>pdf<\/a>): <br>\n        $w^{(t+1)} \u2190 (1 \u2212 \\frac{\u03b1\u03bb}{N} )w^{(t)} + \u03b1x_n(y_n \u2212 \u03c3((w^{(t)})^{T} x_n+b^{t}))$ <br>\n        $b^{(t+1)} \u2190 (b^t +  \u03b1(y_n - \u03c3((w^{(t)})^{T} x_n+b^{t}))$ \n        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n        you can stop the training\n        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n","b231c5ba":"- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss","2cb68950":"Print weights and intercept of model","8958ec86":"### Instructions","93269dff":"Initialize values","322516f8":"- <strong>GOAL<\/strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3","3f34dbad":"Sigmoid","83436121":" Apply sklearn's SGDClassifier and find weights","5d1cb878":"Train LOSS vs Test LOSS","cf1cbc55":" Split data  into train test split","ef4ef0a1":"#Compare weights and intercept"}}