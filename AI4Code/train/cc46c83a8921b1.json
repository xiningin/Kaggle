{"cell_type":{"c5e23e61":"code","54fba6a1":"code","1acd00ea":"code","cda8a720":"code","063527b6":"code","4047c76d":"code","d1cd1934":"code","662b9ad1":"code","01ed8062":"code","1ca920ab":"code","a393bc99":"code","5933b2d2":"code","0ba3aac3":"code","136c7f6c":"code","3ccfb273":"code","2812a810":"code","2e5a5080":"code","502e9893":"code","7b3637f7":"markdown","7b6f93f7":"markdown","53702c35":"markdown","6bdc7e7b":"markdown","2da74912":"markdown"},"source":{"c5e23e61":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\nimport skimage\nfrom skimage.morphology import convex_hull_image, erosion\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D,\\\nZeroPadding2D, Convolution2D, ZeroPadding2D, Conv2DTranspose,ReLU, UpSampling2D, Concatenate, Conv2DTranspose\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\nfrom keras import backend\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","54fba6a1":"MAIN_IMAGE_PATH = Path(\"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/train_val\/images\")\nMAIN_MASK_PATH = Path(\"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/train_val\/masks\")\n\nOBJECT_PATH = list(MAIN_IMAGE_PATH.glob(r\"*.jpg\"))\nMASK_PATH = list(MAIN_MASK_PATH.glob(r\"*.bmp\"))\n\nOBJECT_PATH = sorted(OBJECT_PATH)\nMASK_PATH = sorted(MASK_PATH)\n\nOBJECT_SERIES = pd.Series(OBJECT_PATH,name=\"OBJECTS\").astype(str)\nMASK_SERIES = pd.Series(MASK_PATH,name=\"MASK\").astype(str)\n\nMAIN_DATA = pd.concat([OBJECT_SERIES,MASK_SERIES],axis=1)\n\nMASK_MAIN_TRANSFORMATION = []\nOBJECT_MAIN_TRANSFORMATION = []\nADD_MAIN_TRANSFORMATION = []\n\nfor x_image,x_mask in zip(MAIN_DATA.OBJECTS,MAIN_DATA.MASK):\n    \n    IMAGE_X = cv2.cvtColor(cv2.imread(x_image),cv2.COLOR_BGR2RGB)\n    MASK_X = cv2.cvtColor(cv2.imread(x_mask),cv2.COLOR_BGR2RGB)\n    \n    RESIZED_X_IMAGE = cv2.resize(IMAGE_X,(300,300))\n    RESIZED_X_MASK = cv2.resize(MASK_X,(300,300))\n    \n    ADD_X = cv2.addWeighted(RESIZED_X_IMAGE,0.6,RESIZED_X_MASK,0.6,0.5)\n    \n    RESIZED_X_ADD = cv2.resize(ADD_X,(300,300))\n    \n    MASK_MAIN_TRANSFORMATION.append(RESIZED_X_MASK)\n    OBJECT_MAIN_TRANSFORMATION.append(RESIZED_X_IMAGE)\n    ADD_MAIN_TRANSFORMATION.append(RESIZED_X_ADD)\n    \nprint(\"WHEN IT IS ARRAY IMAGE SHAPE: \",np.shape(np.array(OBJECT_MAIN_TRANSFORMATION)))\nprint(\"WHEN IT IS ARRAY MASK SHAPE: \",np.shape(np.array(MASK_MAIN_TRANSFORMATION)))\nprint(\"WHEN IT IS ARRAY ADD SHAPE: \",np.shape(np.array(ADD_MAIN_TRANSFORMATION)))\n\nTransformation_Image = np.array(OBJECT_MAIN_TRANSFORMATION,dtype=\"float32\")\nTransformation_Mask = np.array(MASK_MAIN_TRANSFORMATION,dtype=\"float32\")\nTransformation_Add = np.array(ADD_MAIN_TRANSFORMATION,dtype=\"float32\")\n\nTransformation_Image = Transformation_Image \/ 255.\nTransformation_Mask = Transformation_Mask \/ 255.\nTransformation_Add = Transformation_Add \/ 255.\n\nprint(\"TRAIN: \",Transformation_Image.shape)\nprint(\"TRANSFORMATION MASK: \",Transformation_Mask.shape)\nprint(\"TRANSFORMATION ADD: \",Transformation_Add.shape)","1acd00ea":"compile_loss = \"binary_crossentropy\"\ncompile_optimizer = Adam(lr=0.000001)\noutput_class = 3\n\nCheckpoint_Model = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\",\n                                                      save_best_only=True,\n                                                      save_weights_only=True,\n                                                      filepath=\".\/modelcheck\")","cda8a720":"Encoder_B = Sequential()\nEncoder_B.add(Conv2D(32,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_B.add(BatchNormalization())\nEncoder_B.add(ReLU())\n#\nEncoder_B.add(Conv2D(64,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_B.add(BatchNormalization())\nEncoder_B.add(ReLU())\n#\nEncoder_B.add(Conv2D(128,(2,2),kernel_initializer = 'he_normal',padding = \"same\",use_bias = True))\nEncoder_B.add(BatchNormalization())\nEncoder_B.add(ReLU())\n\n\nDecoder_B = Sequential()\n#\nDecoder_B.add(Conv2DTranspose(64,(2,2),padding = \"same\",use_bias = True))\nDecoder_B.add(BatchNormalization())\nDecoder_B.add(ReLU())\n#\nDecoder_B.add(Conv2DTranspose(32,(2,2),padding = \"same\",use_bias = True))\nDecoder_B.add(BatchNormalization())\nDecoder_B.add(ReLU())\n#\nDecoder_B.add(Conv2DTranspose(output_class,(2,2),padding = \"same\",use_bias = True))\nDecoder_B.add(BatchNormalization())\nDecoder_B.add(ReLU())","063527b6":"Auto_Encoder = Sequential([Encoder_B,Decoder_B])\nAuto_Encoder.compile(loss=compile_loss,optimizer=compile_optimizer,metrics=[\"mse\"])","4047c76d":"Model_AutoEncoder = Auto_Encoder.fit(Transformation_Image,Transformation_Mask,epochs=20,callbacks=[Checkpoint_Model])","d1cd1934":"Prediction_Seen = Auto_Encoder.predict(Transformation_Image[:10])","662b9ad1":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 1\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","01ed8062":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 3\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","1ca920ab":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 5\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","a393bc99":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 7\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","5933b2d2":"figure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(Transformation_Image[PRE_COUNT])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Seen[PRE_COUNT])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","0ba3aac3":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/n_l_12_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","136c7f6c":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/d_r_129_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","3ccfb273":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/d_r_547_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","2812a810":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/f_r_1220_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","2e5a5080":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/f_r_1410_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","502e9893":"NON_SEEN_PATH = \"..\/input\/semantic-segmentation-of-underwater-imagery-suim\/TEST\/images\/f_r_209_.jpg\"\n\nIMAGE_NON_SEEN = cv2.cvtColor(cv2.imread(NON_SEEN_PATH),cv2.COLOR_BGR2RGB)\n\nRESIZED_NON_SEEN = cv2.resize(IMAGE_NON_SEEN,(256,256))\n\nRESIZED_NON_SEEN = RESIZED_NON_SEEN.reshape(1,RESIZED_NON_SEEN.shape[0],RESIZED_NON_SEEN.shape[1],RESIZED_NON_SEEN.shape[2])\n\nPrediction_Non_Seen = Auto_Encoder.predict(RESIZED_NON_SEEN)\n\nfigure,axis = plt.subplots(1,2,figsize=(15,15))\n\nPRE_COUNT = 9\n\naxis[0].imshow(RESIZED_NON_SEEN[0])\naxis[0].set_title(\"ORIGINAL\")\naxis[1].imshow(Prediction_Non_Seen[0])\naxis[1].set_title(\"PREDICTION\")\n\nplt.tight_layout()\nplt.show()","7b3637f7":"# PACKAGES AND LIBRARIES","7b6f93f7":"# PATH \/ LABEL \/ DATA TRANSFORMATION PROCESS","53702c35":"### MODEL 3","6bdc7e7b":"### ATTENTION\n* CHECK PART: https:\/\/www.kaggle.com\/brsdincer\/underwater-segmentation-process-i\n* CHECK PART: https:\/\/www.kaggle.com\/brsdincer\/underwater-segmentation-prediction-ii\n* CHECK PART: https:\/\/www.kaggle.com\/brsdincer\/underwater-segmentation-prediction-iii","2da74912":"# AUTO-ENCODER PROCESS \/ AE"}}