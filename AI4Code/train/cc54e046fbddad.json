{"cell_type":{"404c5bd4":"code","b17f5b5b":"code","5ab02bcf":"code","52a1d4fc":"code","f462862d":"code","0184b91a":"code","4cdb50ab":"code","bb829702":"code","bd15dbe6":"code","49bc04d4":"markdown"},"source":{"404c5bd4":"def read_train_test_files(train_file,test_file):\n    df_train = pd.read_csv(train_file)\n    df_test = pd.read_csv(test_file)\n    return df_train, df_test","b17f5b5b":"def get_combined_data(df_train,df_test,label_name,label_data_type,\n                      is_train_column):    \n    # add new column is_train which will help in merge and split of \n    # Train and Test datasets\n    df_train[is_train_column] = 1\n    df_test[is_train_column] = 0\n    df_test[label_name] = 0 if label_data_type=='int64' else \"\"\n    df_combined=pd.concat([df_train, df_test],sort=True).reset_index(drop=True)\n    return df_combined","5ab02bcf":"def perform_data_preprocessing(df_combined, features, label,\n                               is_train_column):\n    #### TODO : Cleaning of data on df_combined ###########\n    df_combined_dummies = pd.get_dummies(df_combined[features])\n    df_combined_dummies[label] = df_combined[label].values\n    df_combined_dummies[is_train_column]=df_combined[is_train_column].values\n    df_train = df_combined_dummies[df_combined[is_train_column] == 1]\n    df_test = df_combined_dummies[df_combined[is_train_column] == 0]\n    df_train = df_train.drop([is_train_column], axis=1)\n    df_test = df_test.drop([is_train_column], axis=1)    \n    return df_train,df_test","52a1d4fc":"def Create_confusion_matrix(model_name,y_test,test_predictions):\n    # Compute and print the confusion matrix\n    from sklearn.metrics import confusion_matrix\n    print(f\"confusion_matrix :\")\n    from sklearn.metrics import accuracy_score, f1_score \n    from sklearn.metrics import precision_score, recall_score\n    print(f\"------------ Test Metrics for {model_name}------------------------\")\n    print(\"Accuracy:  {:.3f}\".format(accuracy_score(y_test,test_predictions)))\n    print(\"Precision: {:.3f}\".format(precision_score(y_test,test_predictions,average=\"macro\")))\n    print(\"Recall:    {:.3f}\".format(recall_score(y_test,test_predictions,average=\"macro\")))\n    print(\"F1-Score:  {:.3f}\".format(f1_score(y_test,test_predictions,average=\"macro\")))\n    print(\"--------------------------------------------------\\n\")","f462862d":"def get_GridSearchCV_best_estimator(classifier,params,best_classifiers,\n                                    X_train, X_valid, y_train, y_valid):\n    from sklearn.model_selection import GridSearchCV, cross_val_score\n    model_name = classifier.__class__.__name__    \n    grid_model = GridSearchCV(classifier, params, cv=5, refit=True, \n                              return_train_score=True)    \n    best_model = grid_model.fit(X_train, y_train)\n    best_estimator = grid_model.best_estimator_\n    score=cross_val_score(best_estimator, X_train,y_train,cv=5,\n                          scoring='recall')\n    best_model_cv_score = round(score.mean() * 100, 3)\n    new_row = {'Model_Name': model_name, 'Best_Model': best_estimator,\n               'Best_Params': best_model.best_params_,\n               'Best_training_score': best_model.best_score_,\n               'Best_Model_CV_Score(%)': best_model_cv_score}\n    best_classifiers = best_classifiers.append(new_row,ignore_index=True)\n    best_classifiers = best_classifiers.sort_values(by='Best_Model_CV_Score(%)',ascending=False)\n    print(\n        f\"ClassifierTrainer : {model_name}\"\n        f\"\\n\\t Best Score: {best_model.best_score_}\"\n        f\"\\n\\t Cross Validation Score: {best_model_cv_score}%\"\n        f\"\\n\\t Best parameters : {best_model.best_params_}\"\n        f\"\\n\\t Best Model : {best_estimator}\")\n    # Predict test set labels\n    test_predictions = best_model.predict(X_valid)\n    Create_confusion_matrix(model_name,y_valid,test_predictions)\n    return best_classifiers, best_model","0184b91a":"def get_best_model(X_train, X_valid, y_train, y_valid):\n    best_model = None\n    import pandas as pd\n    columns=['Model_Name','Best_Model','Best_Params',\n             'Best_training_score','Best_Model_CV_Score(%)']\n    best_classifiers = pd.DataFrame(columns=columns)\n    \n    classifiers_list = []\n    params_list = []\n    \n    \n    from sklearn.linear_model import LogisticRegression       \n    params = {\"penalty\": ['l1'],\n              'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n              \"solver\": ['saga', 'liblinear']}\n    classifiers_list.append(LogisticRegression())\n    params_list.append(params)\n    \n    \n    from xgboost import XGBClassifier \n    params = {'learning_rate': [0.001, 0.005, 0.01, 0.02, 0.05, 0.1],\n              'n_estimators': [100, 500, 700, 1000, 1200, 2000],\n              'max_depth': [5, 10, 15, 20, 50, 100, 500]}\n    best_params = {'learning_rate': [0.005],\n              'n_estimators': [1200],\n              'max_depth': [10]}\n    classifiers_list.append(XGBClassifier())\n    params_list.append(best_params)\n    \n    index = -1\n    for classifier in classifiers_list: \n        index += 1\n        best_classifiers,best_model \\\n        =get_GridSearchCV_best_estimator(classifier,\n                                         params_list[index],\n                                         best_classifiers,\n                                         X_train, \n                                         X_valid, \n                                         y_train, \n                                         y_valid)\n        \n    \n    return best_model","4cdb50ab":"def split_train_test(df_data, label_name):\n    from sklearn.model_selection import train_test_split\n    X = df_data.drop([label_name], axis=1).values\n    y = df_data[label_name].values\n    X_train, X_valid, y_train, y_valid=train_test_split(X,y,\n                                                        test_size=0.3,\n                                                        random_state=42,\n                                                        stratify=y)\n    return X_train, X_valid, y_train, y_valid","bb829702":"def submit_predictions(predictions, df_test_original,x_col_name,\n                       y_col_name,filename,label_data_type):\n    # creating submission file\n    submission = pd.DataFrame({x_col_name: df_test_original[x_col_name],\n                               y_col_name: predictions})\n    submission[y_col_name] = submission[y_col_name].astype(label_data_type)\n    print(submission.head())\n    submission.to_csv(filename,index=False)\n    print(f\"Saved submission file: {filename}\")","bd15dbe6":"# Necessary imports\nimport numpy as np\nimport pandas as pd\n\n# define constants\ntrain_file = '\/kaggle\/input\/titanic\/train.csv'\ntest_file = '\/kaggle\/input\/titanic\/test.csv'\nlabel_name = \"Survived\"\ninput_features = ['Pclass','Sex','SibSp','Parch']\nis_train_column = 'is_train'\nlabel_data_type = 'int64'\n\nsubmission_filename = 'Titanic submission.csv'\nsubmission_file_x_col_name=\"PassengerId\"\n\n# read train and test data files and merge the data \ndf_train,df_test = read_train_test_files(train_file,test_file)\ndf_test_original = df_test.copy()\n\n# so that we can perform cleaning on complete data\ndf_combined = get_combined_data(df_train,df_test,label_name,\n                                label_data_type,is_train_column)\n\n# Perform data cleaning on combined data and and split \n# back to train and test data\ndf_train,df_test = perform_data_preprocessing(df_combined,\n                                              input_features,\n                                              label_name,\n                                              is_train_column)\n\n# get X and y ready for model development\nX_train, X_valid, y_train, y_valid = split_train_test(df_train,\n                                                      label_name)\n\n# train couple of algorithms on X and y and get the best model \nbest_model = get_best_model(X_train, X_valid, y_train, y_valid)\n\n# get predictions\nX_test = df_test.drop([label_name], axis=1).values\npredictions = best_model.predict(X_test)\n\n# submit the predictions fro best model\nsubmit_predictions(predictions,df_test_original, \n                   x_col_name=submission_file_x_col_name,\n                   y_col_name=label_name,\n                   filename = submission_filename,\n                   label_data_type=label_data_type)","49bc04d4":"**My idea is to provide clean code for beginners to get started\n# \n# I have submitted the first version to just get started.\n# I will keep on working on this (add more generic code) to get better results\n# **"}}