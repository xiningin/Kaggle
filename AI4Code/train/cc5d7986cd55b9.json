{"cell_type":{"1def29d5":"code","fd015b39":"code","340c10bd":"code","555c9b66":"code","4737bfa5":"code","ec57054c":"code","33167d74":"code","de0b8a8b":"code","35ab454d":"code","69c29dc3":"code","4d886699":"code","fa236fd4":"code","2e25d94a":"code","a1a278ca":"code","6157a8a5":"code","4e422c92":"code","b22ab35a":"code","b0544a06":"code","981ecf16":"code","08d5af17":"code","6c5cc9a3":"code","ea62d5b0":"code","4bfb2095":"code","ca590748":"code","1e9ea2be":"code","a84564f5":"code","8774c063":"code","8fd1143e":"code","80ce7fb0":"code","66041c3d":"code","8f6ee431":"code","168d3b8c":"code","ea8c6579":"code","c76af6b8":"code","6d3c19b5":"code","e97ba086":"code","541b7592":"code","87875b0a":"code","af2bc799":"code","636ff080":"code","966d9ceb":"code","2f2ac985":"code","cffa235d":"code","bf609bff":"code","c526fbff":"code","9431b7e2":"code","9d1cb892":"code","4f09be8a":"code","ec321363":"code","bfbafccb":"code","8eed3450":"code","070823b5":"code","03aeeb8b":"code","0ed17312":"code","cfc5f538":"code","ec392da7":"code","29449315":"code","66de7b27":"code","e2f250ad":"code","668e7771":"code","df12a380":"markdown","253c31d6":"markdown","85cddf6a":"markdown","e7b0e9cf":"markdown","df883b49":"markdown","bbebb271":"markdown","1c5b2566":"markdown","5d2e8103":"markdown","3739ee24":"markdown","0b5d74bd":"markdown","36adc45b":"markdown","63c7282c":"markdown","90fcad34":"markdown","a548e315":"markdown","8c597679":"markdown","a7f3451a":"markdown","a25d2cb6":"markdown","805c3a2a":"markdown","edcaf440":"markdown","1a0cec01":"markdown","59cc217e":"markdown","b5c9efe1":"markdown","3db6eac7":"markdown","d512dca2":"markdown","16e57a9c":"markdown","76b65b93":"markdown","27dae38a":"markdown","66b0e1f9":"markdown","ecf6d39c":"markdown","2a40c2ac":"markdown","da5de811":"markdown"},"source":{"1def29d5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","fd015b39":"df = pd.read_csv('..\/input\/titanic\/train.csv')","340c10bd":"df","555c9b66":"df.info()","4737bfa5":"df.shape","ec57054c":"df.describe()","33167d74":"plt.figure(figsize=(18, 11))\nmatrix = np.triu(df.corr())\nsns.heatmap(df.corr(),center= 0, annot=True, linewidth=0.8, mask=matrix)\n\nplt.title('Features Correlation Heatmap', fontsize = 25)","de0b8a8b":"fig, axes = plt.subplots(1,2, figsize = (16,7))\nfig.suptitle('Useful Boxplots', fontsize = 18)\n\nsns.boxplot(data = df, x = 'Pclass', y = 'Age', ax = axes[0])\nsns.boxplot(data = df, x = 'Pclass', y = 'Fare', ax = axes[1])","35ab454d":"fig, axes = plt.subplots(2,2, figsize = (15,8))\nfig.suptitle('Useful Countplots', fontsize = 18)\n\nsns.countplot(data = df, x = 'Survived', ax = axes[0,0])\nsns.countplot(data = df, x = 'Embarked', ax = axes[0,1])\nsns.countplot(data = df, x = 'Sex', ax = axes[1,0])\nsns.countplot(data = df, x = 'Pclass', ax = axes[1,1])","69c29dc3":"fig, axes = plt.subplots(1,2, figsize = (15,5))\nfig.suptitle('Useful Histograms', fontsize = 18)\n\nsns.histplot(data = df, x = 'Fare', kde= True, bins = 25, ax = axes[0])\nsns.histplot(data = df, x = 'Age', kde= True, bins = 25, ax = axes[1])","4d886699":"df","fa236fd4":"df.isnull().sum()","2e25d94a":"unnecassary_features = ['PassengerId', 'Name', 'Ticket', 'Cabin'] \n# cabin number seems to be important, but lots of its data is missing so it's better to be droped ","a1a278ca":"df.drop(unnecassary_features, axis = 1, inplace=True)","6157a8a5":"df['Sex'] = df['Sex'].map( {'female': 0, 'male': 1} )","4e422c92":"df['FamilySize'] = df['SibSp'] + df['Parch']\ndf.drop(['SibSp', 'Parch'], axis = 1, inplace = True)","b22ab35a":"df","b0544a06":"df.isnull().sum()","981ecf16":"df[df['Embarked'].isnull()]","08d5af17":"df['Fare'].describe()","6c5cc9a3":"dfs = df[df['Embarked'] == 'S']\ndfc = df[df['Embarked'] == 'C']\ndfq = df[df['Embarked'] == 'Q']\n\nfig = plt.figure()\n\nax2 = fig.add_axes([1.2,0,1,1])\nax2.pie(dfs['Pclass'].value_counts(),explode = (0,0,0.3), labels = dfs['Pclass'].value_counts().keys(),\n        labeldistance = 1.03, shadow = True, autopct = '%1.1f%%', \n        startangle = 40, radius = 1.15, rotatelabels = True,\n        textprops = {'fontsize': 12}, colors = [ '#ff2e2e', '#3cf527','#2aafdb'])\n\nax2.set_title('Passengers Class on Southampton harbour', y = 1.05, fontsize = 18)\n\nax1 = fig.add_axes([0,0,1,1])\nax1.pie(dfc['Pclass'].value_counts(),explode = (0.1,0,0), labels = dfc['Pclass'].value_counts().keys(),\n        labeldistance = 1.03, shadow = True, autopct = '%1.1f%%', \n        startangle = -90, radius = 1.15, rotatelabels = True,\n        textprops = {'fontsize': 12}, colors = ['#2aafdb','#3cf527', '#ff2e2e'])\n\nax1.set_title('Passengers Class on Cherbourg harbour', y = 1.05, fontsize = 18)\n\nax3 = fig.add_axes([0,-1.2,1,1])\nax3.pie(dfq['Pclass'].value_counts(),explode = (0,0,0.5), labels = dfq['Pclass'].value_counts().keys(),\n        labeldistance = 1.03, shadow = True, autopct = '%1.1f%%', \n        startangle = 10, radius = 1.15, rotatelabels = True,\n        textprops = {'fontsize': 12}, colors = [ '#ff2e2e', '#3cf527','#2aafdb'])\n\nax3.set_title('Passengers Class on Queenstown harbour', y = 1.05, fontsize = 18)","ea62d5b0":"sns.barplot(y = df['Fare'], x = df['Embarked'])","4bfb2095":"df = df.fillna({'Embarked': 'C'})","ca590748":"df.isnull().sum()","1e9ea2be":"df.corr()","a84564f5":"for i in range(1, 4):\n    \n        df.loc[(df.Age.isnull()) & (df.Pclass == i), 'Age'] = df[(df['Pclass'] == i)]['Age'].median()","8774c063":"df.isnull().sum()","8fd1143e":"df1 = pd.get_dummies(df['Embarked'], drop_first=True)","80ce7fb0":"final_df = pd.concat([df.drop('Embarked', axis = 1),df1], axis=1)","66041c3d":"final_df.head()","8f6ee431":"X = final_df.drop('Survived', axis = 1)\ny = final_df['Survived']","168d3b8c":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)","ea8c6579":"# libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","c76af6b8":"logistic_pipe = Pipeline([('scaler', StandardScaler()), ('logistic', LogisticRegression())])","6d3c19b5":"logistic_pipe.fit(X_train, y_train)","e97ba086":"logistic_pipe['logistic'].coef_","541b7592":"y_log_pred = logistic_pipe.predict(X_test)","87875b0a":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix","af2bc799":"accuracy_score(y_test, y_log_pred)","636ff080":"confusion_matrix(y_test, y_log_pred)","966d9ceb":"plot_confusion_matrix(logistic_pipe, X_test, y_test)","2f2ac985":"print(classification_report(y_test, y_log_pred))","cffa235d":"from sklearn.metrics import plot_precision_recall_curve, plot_roc_curve","bf609bff":"plot_precision_recall_curve(logistic_pipe, X_test, y_test)","c526fbff":"plot_roc_curve(logistic_pipe, X_test, y_test)","9431b7e2":"# libraries\nfrom sklearn.neighbors import KNeighborsClassifier","9d1cb892":"knn_pipe = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 1))])","4f09be8a":"knn_pipe.fit(X_train, y_train)","ec321363":"y_knn_pred = knn_pipe.predict(X_test)","bfbafccb":"accuracy_score(y_test, y_knn_pred)","8eed3450":"error_rate = []\nfor i in range(1,31):\n    knn_pipe = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = i))])\n    \n    knn_pipe.fit(X_train, y_train)\n    y_knn_pred = knn_pipe.predict(X_test)\n    \n    error = 1 - accuracy_score(y_test, y_knn_pred)\n    error_rate.append(error)","070823b5":"plt.figure(figsize=(15,4))\n\nplt.plot(range(1,31), error_rate)\nplt.axhline(min(error_rate), c = 'r', ls = '--')\nplt.grid()\n\nplt.title('Elbow method to choose best K', fontsize=18, y = 1.05)\nplt.xticks(range(1,31,2))\nplt.xlabel('K Neighbors', fontsize=15)\nplt.ylabel('Error Rate', fontsize=15)","03aeeb8b":"final_knn_pipe = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier(n_neighbors = 4))])\n\nfinal_knn_pipe.fit(X_train, y_train)\n\nfinal_y_knn_pred = final_knn_pipe.predict(X_test)","0ed17312":"accuracy_score(y_test, final_y_knn_pred)","cfc5f538":"confusion_matrix(y_test, final_y_knn_pred)","ec392da7":"plot_confusion_matrix(final_knn_pipe, X_test, y_test)","29449315":"print(classification_report(y_test, final_y_knn_pred))","66de7b27":"plot_precision_recall_curve(final_knn_pipe, X_test, y_test)","e2f250ad":"plot_roc_curve(final_knn_pipe, X_test, y_test)","668e7771":"print('**KNN Model**\\n', classification_report(y_test, final_y_knn_pred))\nprint('\\n**Logistic Regression Model**\\n\\n', classification_report(y_test, y_log_pred))","df12a380":"# Data Cleaning","253c31d6":"# 1) Logistic Regression","85cddf6a":"# Dataset Overview","e7b0e9cf":"### Pipeline","df883b49":"# Conclusion","bbebb271":"# missing data","1c5b2566":"# EDA","5d2e8103":"# Read the Dataset","3739ee24":"### Predict","0b5d74bd":"# Import Necessary Libraries","36adc45b":"### Evaluation Curves","63c7282c":"### Evaluation","90fcad34":"**Embarked** and **Age** has missing data and in this part we are going to deal with them:","a548e315":"### Prediction and Evaluation using best **K**","8c597679":"It seems our null data on \"Embarked\" feature, are two independant **rich** ( because of their high \"Fare\" ) **women**...\n\nMost of the rich people embarked on the trip from **cherbourg harbour** (C); so it's very likely that they embarked from cherbourg too...\n\nTo better understand this geuss, let's look at some charts:","a7f3451a":"### Evaluation","a25d2cb6":"Ready to build some models","805c3a2a":"As you can see, **Age** is highly correlated with **Pclass**. So it's better to guess the **Age** of passengers according to their **Pclass**...\n\nIn this section we use the **median** to keep the age distribution in each class unchanged. ","edcaf440":"### Feature adjustment","1a0cec01":"# 1) Embarked","59cc217e":"# 2) Age","b5c9efe1":"# Categorical Data (Embarked)","3db6eac7":"| Variable | Definition | Key |\n| --- | --- | --- |\n| survival | Survival | 0 = No, 1 = Yes |\n| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n| sex | sex |  |\n| Age | Age in years |  |\n| sibsp | # of siblings \/ spouses aboard the Titanic |  |\n| parch | # of parents \/ children aboard the Titanic |  |\n| ticket | Ticket number |  |\n| fare | Passenger fare |  |\n| cabin | Cabin number |  |\n| embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |","d512dca2":"### Predict","16e57a9c":"# 2) KNN","76b65b93":"Best **K** is number 4 (or 6,12,18 ... but we choose 4 for less complexity and same error rate)","27dae38a":"### Pipeline","66b0e1f9":"# Split the Dataset to Train and Test","ecf6d39c":"### Finding the Best K","2a40c2ac":"### Evaluation Curves","da5de811":"# Model Building"}}