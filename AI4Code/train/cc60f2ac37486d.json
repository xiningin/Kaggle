{"cell_type":{"889538e9":"code","adb6970b":"code","2aa92a20":"code","453c76a7":"code","ae18431a":"code","162bc55b":"code","e5a71d20":"code","d5430e94":"code","87208bde":"code","6ab0ef9a":"code","25f4789b":"code","e6145f00":"code","7fe7286b":"code","40c360fd":"code","78b093e4":"code","f0ce4606":"code","992b0fbf":"code","fb51f675":"code","26307ce6":"code","32a79d09":"code","6b3c016d":"code","4e18c286":"code","5b033070":"code","44be1715":"code","5f274e3f":"code","aa5c799d":"code","400a7aa3":"code","60cb8f3e":"code","718e775c":"markdown"},"source":{"889538e9":"%%capture\n!pip uninstall -y scikit-learn \n!pip install -q '..\/input\/sklearn24\/scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl'\nimport sklearn","adb6970b":"sklearn.__version__","2aa92a20":"#!pip install xgboost --no-index --find-links=file:\/\/\/kaggle\/input\/xgboost13123py3nonemanylinux\/xgboost-1.3.2\n!pip uninstall -y xgboost\n!pip install -q '..\/input\/xgboost13123py3nonemanylinux\/xgboost-1.3.2\/xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl'\nimport xgboost","453c76a7":"xgboost.__version__","ae18431a":"!pip install flaml --no-index --find-links=file:\/\/\/kaggle\/input\/flamlmain\/FLAML-main\/\nimport flaml \nfrom flaml import AutoML","162bc55b":"flaml.__version__","e5a71d20":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom tqdm import tqdm\nimport seaborn as sns\nimport random\nimport cv2\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_absolute_percentage_error","d5430e94":"# Tabular data \ntrain = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\nsample_submission = pd.read_csv('..\/input\/petfinder-pawpularity-score\/sample_submission.csv')\n\ntrain_features = train.iloc[:,1:]\n\n# Photo data \ntrain_image = '..\/input\/petfinder-pawpularity-score\/train\/'\ntest_image = '..\/input\/petfinder-pawpularity-score\/test\/'","87208bde":"train_features['income_pawpularity'] = np.ceil(train_features['Pawpularity'] \/ 33)\ntrain_features['income_pawpularity'].where(train_features[\"income_pawpularity\"] < 4 , 4.0 ,inplace=True)\n\nfig = px.parallel_categories(train_features, train_features[['Subject Focus', 'Eyes', \n                                                            'Face', 'Near', 'Action', \n                                                            'Accessory', 'Group',\n                                                            'Collage', 'Human', \n                                                            'Occlusion', 'Info', \n                                                            'Blur', 'income_pawpularity']].columns, \n                             color='income_pawpularity')\nfig.show()","6ab0ef9a":"sns.displot(train_features, x=\"Pawpularity\", hue=\"income_pawpularity\", element=\"step\")","25f4789b":"plate_scale = pd.DataFrame()\nfor i, dicomimage in tqdm(enumerate(train['Id']+'.jpg')):\n    \n    image = cv2.imread(train_image + dicomimage)\n    \n    scale1 = image.shape[:1]\n    scale2 = image.shape[1:2]\n    \n    plate_scale.loc[i, 'image'] = dicomimage\n    plate_scale.loc[i, 'scale1'] = scale1\n    plate_scale.loc[i, 'scale2'] = scale2","e6145f00":"plate_scale['income_pawpularity'] = train_features['income_pawpularity'].astype(str)","7fe7286b":"fig = px.scatter(plate_scale, x=\"scale1\", y=\"scale2\", color=\"income_pawpularity\")\nfig.show()","40c360fd":"def show_img(full_path, pawpularity_file):\n    plt.figure(figsize=(25, 30))\n   \n    for fpath in range(len(full_path)):\n        image = cv2.imread(full_path[fpath])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        plt.subplot(5, 3, fpath+1)\n        plt.title('pawpularity: ' + str(pawpularity_file[fpath]))\n        plt.imshow(image)\n        plt.axis(\"off\")","78b093e4":"for i_income in range(1, 5):\n    index = train_features[train_features['income_pawpularity']==i_income].index\n    id_file = train.iloc[index]['Id'] \n    full_path = id_file.apply(lambda x: '{}'.format(train_image)+f'{x}.jpg') \n    random_ind = random.sample(list(full_path.index), 15) \n    pawpularity_file = train.iloc[random_ind]['Pawpularity'] \n    full_path = full_path.loc[random_ind]\n    \n    show_img(list(full_path), list(pawpularity_file))","f0ce4606":"Y = train_features['Pawpularity'].astype(int)\ntrain_features.drop(['Pawpularity', 'income_pawpularity'], axis=1, inplace=True)\n\ntest_features = test[['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', \n                      'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', \n                      'Info', 'Blur']]","992b0fbf":"skfolds = StratifiedKFold(n_splits=5, \n                          random_state=42, \n                          shuffle = True)\n    \nfor num_fold, (train_index, val_index) in enumerate(skfolds.split(train_features, Y)):\n    train_features.loc[val_index, 'fold'] = int(num_fold)","fb51f675":"train_features.head(3)","26307ce6":"def my_loss_obj(y_true, y_pred):\n    return np.sqrt(((y_pred - y_true) ** 2).mean())","32a79d09":"from flaml.model import LGBMEstimator\n\n''' create a customized LightGBM learner class with your objective function '''\nclass MyLGBM(LGBMEstimator):\n    '''LGBMEstimator with my_loss_obj as the objective function\n    '''\n\n    def __init__(self, **params):\n        super().__init__(objective=my_loss_obj, **params)","6b3c016d":"settings = {\n    \"time_budget\": 240,  \n    \"metric\": 'rmse', \n    \"estimator_list\": ['lgbm'],  \n    \"task\": 'regression',    \n    \"seed\": 7654321,   \n}","4e18c286":"for fold_n in range(5): \n    print('Fold #{}'.format(fold_n+1))\n    \n    train_data = train_features[train_features.fold != fold_n].astype(int).iloc[:,:-1]\n    val_data = train_features[train_features.fold == fold_n].astype(int).iloc[:,:-1]\n    \n    train_data_ind, val_data_ind = train_data.index, val_data.index\n    \n    train_Y = Y[train_data_ind]\n    val_Y = Y[val_data_ind]\n    \n    automl = AutoML()\n    #automl.add_learner(learner_name='my_lgbm', learner_class=MyLGBM)\n    \n    automl.fit(X_train = train_data, y_train = train_Y, **settings)\n    #print('Best hyperparmeter config:', automl.best_config)\n    #print(my_loss_obj(val_Y, automl.predict(train_Y)))","5b033070":"automl.best_config","44be1715":"predictions = automl.predict(test_features)","5f274e3f":"predictions","aa5c799d":"sample_submission.Pawpularity = predictions\nsample_submission.to_csv(\"submission.csv\", index=False)","400a7aa3":"from tensorflow.keras.utils import Sequence","60cb8f3e":"class SETIDataset(Sequence):\n\n    def __init__(self, x_set, y_set=None, batch_size=32, metod_wave=True):\n                 \n        self.x = x_set\n        self.y = y_set\n        self.batch_size = batch_size\n        self.metod_wave = metod_wave \n        \n    def __len__(self):\n        return math.ceil(len(self.x) \/ self.batch_size)\n        \n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size] \n        \n        if self.y is not None:\n            batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size] \n             \n        list_train = [np.load(path).astype('float') for path in batch_x['file_path']]\n        \n        if not self.metod_wave:\n            if self.y is not None:\n                return np.array(list_train), np.array(batch_y)\n            else:\n                return np.array(list_train)\n        else:    \n            hi_inv =  [self.hilbert_invert(image) for image in list_train]\n\n            if self.y is not None:\n                return hi_inv, np.array(batch_y)\n            else:\n                return np.array(list_train)","718e775c":"##########################################################################"}}