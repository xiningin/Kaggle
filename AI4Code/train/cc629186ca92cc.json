{"cell_type":{"d7f2b5f8":"code","af8d5251":"code","4c406252":"code","295862e3":"code","b0349554":"code","6c0a3e8f":"code","41400d9a":"code","1f504bf0":"code","25767d4c":"code","92feba9d":"code","7bd19bf5":"code","388f2542":"code","74b9ca2e":"code","54b408dc":"code","a9cc897c":"code","b0766516":"code","a33d76e3":"code","a8659825":"code","0e745aa0":"code","2a8e6b0d":"code","009f27c7":"code","e539fe3d":"code","01ecbed0":"code","bd346f80":"code","ed46c6b1":"code","6ef4b781":"code","5edc198b":"code","d7f7a1d0":"code","c8e7fab3":"code","1eea489c":"code","8f6e479d":"code","3f625e1b":"code","ab29f49d":"code","c7590cb8":"code","1765dfcd":"code","b79dd18f":"code","c8ca5fb2":"code","0f04e9be":"code","7b254de1":"code","59a67cc4":"code","49b74bc9":"code","01f84e12":"code","fb71639a":"code","101cb341":"code","d99bc27b":"code","2929dcea":"code","5d7a0d29":"code","c6dc2912":"code","53c103e8":"code","864cf643":"code","78f9a5d9":"markdown","e2cb5e1f":"markdown","59f84db2":"markdown","298d9a64":"markdown","58497123":"markdown","04f014b7":"markdown","48652a7b":"markdown","dc22c85c":"markdown","42388847":"markdown","ef76a2f2":"markdown","b75e4872":"markdown"},"source":{"d7f2b5f8":"## imports\nimport pandas as pd\nimport numpy as np","af8d5251":"train_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","4c406252":"test_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","295862e3":"test_df.head()","b0349554":"train_df.head()","6c0a3e8f":"train_df.info()","41400d9a":"test_df.info()","1f504bf0":"train_df['Embarked'].value_counts()","25767d4c":"missing_mean_values = []\nfor Sex in train_df['Sex'].unique():\n    for Pclass in train_df['Pclass'].unique():\n        Age_mean = train_df[(train_df['Sex'] == Sex) & (train_df['Pclass'] == Pclass)]['Age'].mean()\n        Fare_mean = train_df[(train_df['Sex'] == Sex) & (train_df['Pclass'] == Pclass)]['Fare'].mean()\n        Embarked_mean = train_df[(train_df['Sex'] == Sex) & (train_df['Pclass'] == Pclass)]['Embarked'].value_counts().reset_index().iloc[0]['index']\n        \n        missing_mean_values.append((Sex, Pclass, Age_mean, Fare_mean, Embarked_mean))\nmissing_mean_values = pd.DataFrame(missing_mean_values, columns = ['Sex', 'Pclass', 'Age_mean', 'Fare_mean', 'Embarked_mean'])","92feba9d":"missing_mean_values","7bd19bf5":"train_df['Embarked'].fillna('S', inplace = True)\ntest_df['Embarked'].fillna('S', inplace = True)","388f2542":"columns = ['Age', 'Fare']\nfor col in columns :\n    train_df[col] = train_df.apply(\n    lambda row: missing_mean_values[(missing_mean_values['Sex'] == row['Sex']) & (missing_mean_values['Pclass'] == row['Pclass'])]['%s_mean'%(col)].iloc[0] if np.isnan(row[col]) else row[col],\n    axis=1\n)\n    test_df[col] = test_df.apply(\n    lambda row: missing_mean_values[(missing_mean_values['Sex'] == row['Sex']) & (missing_mean_values['Pclass'] == row['Pclass'])]['%s_mean'%(col)].iloc[0] if np.isnan(row[col]) else row[col],\n    axis=1\n)","74b9ca2e":"train_df['HasCabin'] = train_df['Cabin'].notnull()\ntest_df['HasCabin'] = test_df['Cabin'].notnull()","54b408dc":"train_df.info()","a9cc897c":"test_df.info()","b0766516":"train_df['FamilySize'] = train_df['Parch'] + train_df['SibSp']\ntest_df['FamilySize'] = test_df['Parch'] + test_df['SibSp']","a33d76e3":"import matplotlib.pyplot as plt\n","a8659825":"col = 'FamilySize'\ntarget_col = 'Survived'\nfig, ax = plt.subplots(figsize = (14, 8))\ncolors = ['b', 'r', 'g']\nfor index, val in enumerate(train_df[target_col].unique().tolist()):\n    ax.hist(train_df[train_df[target_col] == val][col], bins = 20, range = [0, 8], color = colors[index], alpha = 0.5, label = \"%s_%s\"%(target_col, val))\nplt.title(\"%s distribution\" %(col), fontsize = 15)\nax.set_xlabel(\"%s\" %(col), fontsize = 15)\nax.set_ylabel(\"num of People\", fontsize = 15)\nplt.legend()\nplt.show()","0e745aa0":"train_df.info()","2a8e6b0d":"cols = ['Sex', 'Embarked', 'HasCabin']\nfor col in cols:\n    train_df[col] = train_df[col].astype('category')\n    train_df[\"%sCode\"%(col)] = train_df[col].cat.codes\n    \n    test_df[col] = test_df[col].astype('category')\n    test_df[\"%sCode\"%(col)] = test_df[col].cat.codes","009f27c7":"train_df['Sex'].value_counts()","e539fe3d":"train_df['SexCode'].value_counts()","01ecbed0":"train_df['HasCabin'].value_counts()","bd346f80":"train_df['HasCabinCode'].value_counts()","ed46c6b1":"train_df['Embarked'].value_counts()","6ef4b781":"train_df['EmbarkedCode'].value_counts()","5edc198b":"from sklearn.tree import DecisionTreeClassifier","d7f7a1d0":"clf = DecisionTreeClassifier(random_state=0)","c8e7fab3":"X = train_df[['Pclass', 'SexCode', 'Age', 'Fare', 'FamilySize', 'HasCabinCode', 'EmbarkedCode']]","1eea489c":"X.head()","8f6e479d":"y = train_df['Survived']","3f625e1b":"y.head()","ab29f49d":"from sklearn.model_selection import train_test_split","c7590cb8":"X.shape","1765dfcd":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=0)","b79dd18f":"X_train.shape","c8ca5fb2":"X_test.shape","0f04e9be":"estimator = DecisionTreeClassifier(random_state=0)\nestimator.fit(X_train, y_train)","7b254de1":"from sklearn.metrics import classification_report","59a67cc4":"y_pred = estimator.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","49b74bc9":"## inspecting the tree\nfrom sklearn import tree","01f84e12":"from IPython.display import SVG\nfrom graphviz import Source\ngraph = Source( tree.export_graphviz(estimator, out_file=None, feature_names=X_train.columns))\nSVG(graph.pipe(format='svg'))","fb71639a":"estimator = DecisionTreeClassifier(random_state=0 , min_samples_leaf = 10)\nestimator.fit(X_train, y_train)","101cb341":"y_pred = estimator.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","d99bc27b":"from IPython.display import SVG\nfrom graphviz import Source\ngraph = Source( tree.export_graphviz(estimator, out_file=None, feature_names=X_train.columns))\nSVG(graph.pipe(format='svg'))","2929dcea":"print(estimator.tree_.max_depth)","5d7a0d29":"from sklearn.model_selection import GridSearchCV","c6dc2912":"parameters = {\n                'criterion' : ['gini', 'entropy'],\n                'min_samples_leaf': list(range(5,20)) + [None],\n                'splitter' : ['best', 'random'],\n                'max_depth' : list(range(5, 20)) + [None] ,\n                'class_weight' : ['balanced']\n             }\nestimator = GridSearchCV(tree.DecisionTreeClassifier(), parameters, cv = 10, n_jobs=4)\nestimator.fit(X=X_train, y=y_train)\nbest_estimator = estimator.best_estimator_\nprint (estimator.best_score_, estimator.best_params_)","53c103e8":"y_pred = estimator.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","864cf643":"from IPython.display import SVG\nfrom graphviz import Source\ngraph = Source( tree.export_graphviz(best_estimator, out_file=None, feature_names=X_train.columns))\nSVG(graph.pipe(format='svg'))","78f9a5d9":"Finding best set of parameters using GridSearch and CrossValidation","e2cb5e1f":"Training DecisionTree","59f84db2":"Here we have improved the accuracy on test set by setting the condition on splitting and creating leaf nodes using min_samples_split = 10","298d9a64":"#### Understanding Decision Trees:\n    1. How to Implement in Scikit learn\n    2. Analysing the learned trees by visualisation\n    3. Experimenting with different parameters using GridSearch and Cross Validation","58497123":"Combining Parch and SibSp to Family Size Parameter","04f014b7":"Converting Sex, Embarked, HasCabin Feature to Numerical Codes","48652a7b":"EDA done here : https:\/\/www.kaggle.com\/rahulmittal\/titanic-eda","dc22c85c":"Features used : \n    1. Pclass\n    2. Sex\n    3. Age\n    4. Fare\n    5. FamilySize\n    6. Embarked\n    7. HasCabin\n    \nTarget Variable : Survived\n","42388847":"Filling Null Values","ef76a2f2":"Train_df has null values in Age and and Embarked and Cabin Column.\nTest_df has null values in Age and Fare and Cabin Column.\n\nFilling Age values with the mean where Sex and Pclass is same.\nFilling Fare values with the mean where Sex and Pclass is same.\nFilling Embarked values with the max where Sex and Pclass is same.\n\nCreating a new variable hasCabin True for the instances where we have Cabin Variable","b75e4872":"By inspecting the tree we can see that lot of the Leaf Nodes has only 1 sample, this is overfitting the data"}}