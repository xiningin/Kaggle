{"cell_type":{"d15ee3a0":"code","99dcf058":"code","2ae34849":"code","39224404":"code","0b045157":"code","0c3d82db":"code","73d8d9d1":"code","f9409990":"code","c8b08092":"code","e5b03a46":"code","0aa973a4":"code","1034fc8f":"code","ce265d51":"code","3b4b0cb8":"code","a5bb3c21":"code","ebf9fa3f":"code","faa12b12":"code","320cabb7":"code","c10ea91a":"code","b50ebfcd":"code","8f94e3ca":"code","478eb6f8":"code","281a1cd3":"code","4415c910":"code","bda470a6":"code","1aa778e6":"code","faa8121a":"code","a5dd4fef":"code","d99f60fe":"markdown","74d573ee":"markdown","1a8b4a37":"markdown","0ced5659":"markdown","8bc1eec1":"markdown","374b58b1":"markdown","ed350dc1":"markdown","9b0eb549":"markdown","8ceb45e7":"markdown","e0872654":"markdown","e9d1f54c":"markdown","07122fdc":"markdown","ada4c9f9":"markdown"},"source":{"d15ee3a0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","99dcf058":"data = pd.read_csv(\"..\/input\/countries of the world.csv\")  #getting the data with pandas","2ae34849":"data.info()  # learning more about the data","39224404":"data.head(10)","0b045157":"data.describe()","0c3d82db":"def comma_to_dot(data):\n    \"\"\"This function is created for the replacement of comma with dot and changing the data type to float\"\"\"\n    data = str(data);   # for any type of unexpected data types\n    data = data.replace(\",\",\".\");\n    data = float(data);\n    return data;","73d8d9d1":"print(data.columns)    # checking the full names of each column","f9409990":"data['Pop. Density (per sq. mi.)'] = list(map(comma_to_dot,data['Pop. Density (per sq. mi.)']))\ndata['Coastline (coast\/area ratio)'] = list(map(comma_to_dot,data['Coastline (coast\/area ratio)']))\ndata['Net migration'] = list(map(comma_to_dot,data['Net migration']))\ndata['Infant mortality (per 1000 births)'] = list(map(comma_to_dot,data['Infant mortality (per 1000 births)']))\ndata['GDP ($ per capita)'] = list(map(comma_to_dot,data['GDP ($ per capita)']))\ndata['Literacy (%)'] = list(map(comma_to_dot,data['Literacy (%)']))\ndata['Phones (per 1000)'] = list(map(comma_to_dot,data['Phones (per 1000)']))\ndata['Arable (%)'] = list(map(comma_to_dot,data['Arable (%)']))\ndata['Crops (%)'] = list(map(comma_to_dot,data['Crops (%)']))\ndata['Other (%)'] = list(map(comma_to_dot,data['Other (%)']))\ndata['Climate'] = list(map(comma_to_dot,data['Climate']))\ndata['Birthrate'] = list(map(comma_to_dot,data['Birthrate']))\ndata['Deathrate'] = list(map(comma_to_dot,data['Deathrate']))\ndata['Agriculture'] = list(map(comma_to_dot,data['Agriculture']))\ndata['Industry'] = list(map(comma_to_dot,data['Industry']))\ndata['Service'] = list(map(comma_to_dot,data['Service']))","c8b08092":"data.head(10)   # to see results on dataset","e5b03a46":"data.describe()","0aa973a4":"data.info();","1034fc8f":"data.Climate.value_counts(dropna=False)   \n# it is interesting that 2.0 and 3.0 is most common but the 2.5 is least common one even that it's just between most common values.\n# also we have a lot of NaN values.","ce265d51":"data = data.dropna();\n\ndata.info();   # we still have 180 countries that we can work on easily.  ","3b4b0cb8":"data.boxplot(figsize=(20,8), column='Literacy (%)', by='GDP ($ per capita)', grid=False)","a5bb3c21":"import seaborn as sns\nimport matplotlib.pyplot as plt","ebf9fa3f":"plt.clf()\nplt.figure(figsize=(20,12))\nsns.heatmap(data.corr(),annot=True,fmt='1.1f')","faa12b12":"b = set(data.Region);\nprint(b)   # seems like we have a Lot of spaces, considering that they use storage unnecesarily: I want to delete whole spaces.","320cabb7":"def SpaceRemover(data):\n    \"\"\"This function is created for the replacement of Space with empty\"\"\"\n    data = str(data);   # for any type of unexpected data types\n    data = data.replace(\" \",\"\");\n    return data;","c10ea91a":"data['Region'] = list(map(SpaceRemover,data['Region']))","b50ebfcd":"print(set(data.Region))  # now not super clear but still better.","8f94e3ca":"plt.clf()\nplt.figure(figsize=(15,10));\nplt.scatter(data.Climate , data.Region, alpha=0.1, s=200, c=\"blue\")  \n\n# I made 0.1 opacity to see how often it repeats easily\n# darker the blue, often the appearence of that climate.\n\nplt.show()","478eb6f8":"melted_data = pd.melt(frame=data, id_vars=\"Country\", value_vars=['Literacy (%)','Birthrate','Phones (per 1000)'])\n\nmelted_data  # the picked variables are all correlated, so when I pivot it will has more sense.","281a1cd3":"pivotted_melt = melted_data.pivot(index='Country',columns=\"variable\",values='value')\n\npivotted_melt  # we can see that how dependently numbers change in each column easily.","4415c910":"# assert pivotted_melt.Birthrate.dtype == np.dtype(int)   ## would return an error.\n\nassert pivotted_melt.Birthrate.dtype == np.dtype(float)   # returns no error because data type is really float","bda470a6":"# assert data.columns[1] == \"Efe\"  ## would return an error \n\nassert data.columns[1] != \"Efe\" # in here I assert negatively. (not \"Efe\" is true)","1aa778e6":"dataHead = data.head(10);               dataTail = data.tail(10);\n\nconcated_data = pd.concat([dataHead,dataTail],axis=0,ignore_index=1)","faa8121a":"concated_data   # Rigth Below we see that by \"concat\" operation of numpy we easliy created new data from 2 data(s). ","a5dd4fef":"# this notebook is created for the 3rd homework of Data Science by DATAI on Udemy.","d99f60fe":"Now we have what we wanted, our data is much more easy to work with and data types are just as we would wish.\n","74d573ee":"# Hi, in this kernel I will try to improve my Data Cleaning skills and get used to play with Datasets\n\nthis kernel will include most of the knowledge I get from te course so far such as plots etc.\n","1a8b4a37":"Let's drop the all null values since this notebook is for experimenting","0ced5659":"above we see only 3 columns, which is absolutely not what we desire.\n\nAs seen above with \" data.head() \" our main problem seems to be the comma( , ) instad of dot( . ) if we can replace, then we can transform our data types into float","8bc1eec1":"Example of Concatenaing data could be like this:","374b58b1":"I want to fix our Region values too, they have too much space which makes it hard to read.","ed350dc1":"## The BoxPlot above is interesting but not surprising.\nAs seen, Literacy has very big effect on the income of people and government which is not a surprise. The surprise is that there is not many outliner values on this plot which means there is almost no exceptional cases for it.  ","9b0eb549":"Example usage of assert on my dataset can be like:","8ceb45e7":"I see that Service is very correlated with other columns such as \"Birthrate\" , \"Agriculture\" , \"Phones\" , \"Infant Mortality\".\n\nAlso, GDP per capita and Birtrate is very correlated with many different Columns too.","e0872654":"Let's check for correlation of our dataset.","e9d1f54c":"Our very first problem seems to be data types of most columns. \nAs seen above, numerical values doesn't have a numerical data types such as int or float. But we can work on it\n\nLet's continue to explore","07122fdc":"I will try to improve my data manipualtion skills such as melting or pivoting the data on the dataset.","ada4c9f9":"Now we can apply our function on each column we need below.\n\nUnfortunately, the data has column name inconsistency but we can use as \" data[' GDP ($ per capita ) ' ] \""}}