{"cell_type":{"235f1067":"code","047025c1":"code","7c1de44d":"code","c8b43e57":"code","c5cce6e9":"code","d1a0c362":"code","bfc2030e":"code","60309d6a":"code","614cd5a7":"code","b599a08a":"code","3271169b":"code","7998c480":"code","c06a11f0":"code","b1ff0426":"code","0cfc147a":"code","ba5b867a":"code","f1cd29d0":"code","98b19fa1":"code","757a4b4b":"code","ec2a09a8":"code","57db7822":"code","e8ec12d2":"code","4723b07e":"code","0f395f6f":"code","32ad0164":"code","cb5c880b":"code","dd72e3ed":"code","cca2ff63":"code","4b1dde15":"code","acc8283b":"code","d3f0f10b":"code","7bce7368":"code","bb2f7f22":"code","389cac59":"code","09ae9f94":"code","5c59df84":"code","8356ff93":"code","33539147":"code","e3e438e4":"code","da054041":"code","f7092b63":"code","ca52a172":"code","e7490621":"code","01e42cce":"code","b3d826e9":"code","a5cbdd27":"markdown","3be9d217":"markdown","6f426cb3":"markdown","97d162e3":"markdown","2527afc7":"markdown","e1f009c7":"markdown","50103fea":"markdown","e0e28071":"markdown","02c540a5":"markdown","fa6bdbf3":"markdown","61f1c56d":"markdown","a89c1b0d":"markdown","ba2ef72d":"markdown","1e7d9687":"markdown","a832b679":"markdown","bd9a3a7c":"markdown","a249d21e":"markdown","c26346cb":"markdown","9f93673b":"markdown","c325f3c4":"markdown","ad3d9a07":"markdown","c67f92ba":"markdown"},"source":{"235f1067":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score,confusion_matrix,f1_score","047025c1":"df = pd.read_csv(\"\/kaggle\/input\/water-potability\/water_potability.csv\")\ndf.head(n=5)","7c1de44d":"import missingno as msno\nmsno.bar(df)\nplt.show()","c8b43e57":"df.describe().T","c5cce6e9":"df.info()","d1a0c362":"df.shape","bfc2030e":"df.isnull().sum()","60309d6a":"df['ph'] = df['ph'].fillna(df['ph'].mean())\ndf['Sulfate'] = df['Sulfate'].fillna(df['Sulfate'].mean())\ndf['Trihalomethanes'] = df['Trihalomethanes'].fillna(df['Trihalomethanes'].mean())","614cd5a7":"df.isnull().sum()","b599a08a":"df.duplicated().sum()","3271169b":"plt.figure(figsize=(10,6))\nplt.style.use('ggplot')\nsns.countplot(x='Potability',data=df)\nplt.show()","7998c480":"plt.figure(figsize=(20,16))\nddf=df.drop('Potability',axis=True)\nfor i,column in enumerate(ddf.columns,1):\n    plt.subplot(3,3,i)\n    sns.distplot(ddf[column],hist=True)\nplt.show()","c06a11f0":"plt.figure(figsize=(20,16))\nfor i,column in enumerate(ddf.columns,1):\n    sns.displot(df,x=ddf[column], hue=\"Potability\", kind=\"kde\", multiple=\"stack\")\nplt.show()","b1ff0426":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(),cmap='coolwarm',annot=True)\nplt.show()","0cfc147a":"plt.figure(figsize=(20,20))\nfor i,column in enumerate(ddf.columns,1):\n    plt.subplot(5,2,i)\n    sns.boxplot(data = ddf,x = ddf[column],orient = 'h')\nplt.show()","ba5b867a":"plt.figure(figsize=(20,20))\nfor i,column in enumerate(ddf.columns,1):\n    plt.subplot(5,2,i)\n    sns.violinplot(data = ddf,x = ddf[column],orient = 'h')\nplt.show()","f1cd29d0":"from scipy import stats\nzscore = np.abs(stats.zscore(df))\nprint(zscore)","98b19fa1":"threshold = 2.5\nprint(np.where(zscore > 2.5))","757a4b4b":"df_clean=df\ndf_clean = df_clean[(zscore<2.5).all(axis=1)]","ec2a09a8":"df.shape,df_clean.shape","57db7822":"plt.figure(figsize = (10,8))\nsns.boxplot(data=df_clean,orient='h')","e8ec12d2":"x = df.drop(['Potability'],axis=True)\ny = df['Potability']","4723b07e":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=101)","0f395f6f":"from sklearn.preprocessing import MinMaxScaler\nmscale=MinMaxScaler()\nmscale.fit_transform(x_train)\nmscale.transform(x_test)","32ad0164":"log_reg = LogisticRegression()\nlog_reg.fit(x_train,y_train)\n\nlog_acc=accuracy_score(y_test,log_reg.predict(x_test))\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,log_reg.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,log_reg.predict(x_test))*100))","cb5c880b":"y_pred=log_reg.predict(x_test)\nprint(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\nprint(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\nprint(\"-\"*20, \"confusion matrix\", \"-\"*20)\nplt.figure(figsize=(8,8))\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","dd72e3ed":"d_tree = DecisionTreeClassifier()\nd_tree.fit(x_train,y_train)\n\nd_acc=accuracy_score(y_test,d_tree.predict(x_test))\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,d_tree.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,d_tree.predict(x_test))*100))","cca2ff63":"y_pred=d_tree.predict(x_test)\nprint(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\nprint(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\nprint(\"-\"*20, \"confusion matrix\", \"-\"*20)\nplt.figure(figsize=(8,8))\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","4b1dde15":"r_for = RandomForestClassifier()\nr_for.fit(x_train,y_train)\n\nr_acc=accuracy_score(y_test,r_for.predict(x_test))\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,r_for.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,r_for.predict(x_test))*100))","acc8283b":"y_pred=r_for.predict(x_test)\nprint(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\nprint(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\nprint(\"-\"*20, \"confusion matrix\", \"-\"*20)\nplt.figure(figsize=(8,8))\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","d3f0f10b":"k_nei = KNeighborsClassifier()\nk_nei.fit(x_train,y_train)\n\nk_acc = accuracy_score(y_test,k_nei.predict(x_test))\n\nprint(\"Train set Accuracy:\"+str(accuracy_score(y_train,k_nei.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,k_nei.predict(x_test))*100))","7bce7368":"y_pred=k_nei.predict(x_test)\nprint(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\nprint(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\nprint(\"-\"*20, \"confusion matrix\", \"-\"*20)\nplt.figure(figsize=(8,8))\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","bb2f7f22":"s_vec = SVC()\ns_vec.fit(x_train,y_train)\n\ns_acc = accuracy_score(y_test,s_vec.predict(x_test))\n\nprint(\"Train set Accuracy:\"+str(accuracy_score(y_train,s_vec.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,s_vec.predict(x_test))*100))","389cac59":"y_pred=s_vec.predict(x_test)\nprint(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\nprint(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\nprint(\"-\"*20, \"confusion matrix\", \"-\"*20)\nplt.figure(figsize=(8,8))\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","09ae9f94":"g_clf = GaussianNB()\ng_clf.fit(x_train,y_train)\n\ng_acc = accuracy_score(y_test,s_vec.predict(x_test))\n\nprint(\"Train set Accuracy:\"+str(accuracy_score(y_train,g_clf.predict(x_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,g_clf.predict(x_test))*100))","5c59df84":"y_pred=g_clf.predict(x_test)\nprint(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\nprint(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\nprint(\"-\"*20, \"confusion matrix\", \"-\"*20)\nplt.figure(figsize=(8,8))\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","8356ff93":"y_pred=g_clf.predict(x_test)\nprint(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\nprint(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\nprint(\"-\"*20, \"confusion matrix\", \"-\"*20)\nplt.figure(figsize=(8,8))\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","33539147":"from sklearn.model_selection import GridSearchCV","e3e438e4":"nEstimator = [10,11,12,13,14,15,16]\ndepth = [5,10,20,30,40,50,60]\ncriterion=['entropy', 'gini']\nmin_samples_leaf=[1, 2, 5, 10]\nmin_samples_split=[2, 5, 10, 15]\nmax_features = ['auto', 'sqrt','log2']\n\nRF = RandomForestClassifier()\nhyperParam = [{'n_estimators':nEstimator,'max_depth': depth,'criterion':criterion,'max_features': max_features,'min_samples_leaf':min_samples_leaf,'min_samples_split':min_samples_split}]\ngsv = GridSearchCV(RF,hyperParam,cv=5,verbose=1,scoring='f1_weighted',n_jobs=-1)\ngsv.fit(x_train,y_train)\nprint(\"Best HyperParameter: \",gsv.best_params_)\nprint(gsv.best_score_)","da054041":"GS_acc = accuracy_score(y_test,gsv.predict(x_test))\ny_pred=gsv.predict(x_test)\nprint(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\nprint(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\nprint(\"-\"*20, \"confusion matrix\", \"-\"*20)\nplt.figure(figsize=(8,8))\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","f7092b63":"from sklearn.model_selection import RandomizedSearchCV","ca52a172":"nEstimator = [10,11,12,13,14,15,16,17,18]\ndepth = [5,10,20,30,40,50,60]\ncriterion=['entropy', 'gini']\nmin_samples_leaf=[1, 2, 5, 10,12,14]\nmin_samples_split=[2, 5, 10, 15,16,17]\nmax_features = ['auto', 'sqrt','log2']\n\nRF = RandomForestClassifier()\nhyperParam = [{'n_estimators':nEstimator,'max_depth': depth,'criterion':criterion,'max_features': max_features,'min_samples_leaf':min_samples_leaf,'min_samples_split':min_samples_split}]\nrsv = RandomizedSearchCV(RF,hyperParam,cv=5,verbose=1,scoring='f1_weighted',n_jobs=-1)\nrsv.fit(x_train,y_train)\nprint(\"Best HyperParameter: \",rsv.best_params_)\nprint(rsv.best_score_)","e7490621":"RS_acc = accuracy_score(y_test,s_vec.predict(x_test))\ny_pred=rsv.predict(x_test)\nprint(\"Accuracy on test set: %0.3f%%\"%(accuracy_score(y_test, y_pred)*100))\nprint(\"F1-Score on test set: %0.3f\"%(f1_score(y_test, y_pred)))\nprint(\"-\"*20, \"confusion matrix\", \"-\"*20)\nplt.figure(figsize=(8,8))\ndf_cm = pd.DataFrame(confusion_matrix(y_test, y_pred), range(2),range(2))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}, fmt='g')\nplt.xlabel('Predicted Class')\nplt.ylabel('Original Class')\nplt.show()","01e42cce":"models = pd.DataFrame({\n    'Model': ['Logistic','KNN', 'SVC',  'Decision Tree',\n             'Random Forest',  'Gaussian','GridsearchRF','RandomRf'],\n    'Score': [ log_acc,k_acc, s_acc, d_acc, r_acc, g_acc,GS_acc,RS_acc]\n})\n\nmodels.sort_values(by = 'Score', ascending = False)","b3d826e9":"plt.figure(figsize=(15,6))\nsns.barplot(x=\"Model\", y=\"Score\", data=models)\nplt.show()","a5cbdd27":"# <center> <div class=\"alert-block alert-info alert\"> <span style = \"color:crimson;\"> Done <\/center>","3be9d217":"# Removing Duplicates\n\nif any","6f426cb3":"# GaussianNB","97d162e3":"# Handiling Missing Data","2527afc7":"**Outlier prevention**","e1f009c7":"# <center> <div class=\"alert-block alert-info alert\"> <span style = \"color:crimson;\"> Exploratory Data Analysis <\/center>","50103fea":"![image.png](attachment:50d5b1c5-8088-46e1-a264-431de6f9b3e0.png)\n\n**Water is  perhaps  the  most  precious  natural resource after air. Though the surface of the earth is mostly consists of water, only a small part of it is usable, which makes this resource very limited. This precious and limited resource, therefore, must be used with prudence. As water is required for different purposes, the suitability of it must be checked before use. Also,  sources of  water  must be  monitored regularly  to determine  whether  they  are  in  sound  health  or  not.  Poor condition  of  water  bodies  are  not  only  the  indictor  of environmental  degradation,  it  is  also  a  threat  to  the ecosystem. In industries, improper quality of water may cause hazards and severe economic loss. Thus, the quality of water is very important in both environmental and economic aspects. Thus,  water  quality analysis  is essential for  using it  in any purpose.**","e0e28071":"# Data Description\n\n1. pH value:\nPH is an important parameter in evaluating the acid\u2013base balance of water. It is also the indicator of acidic or alkaline condition of water status. WHO has recommended maximum permissible limit of pH from 6.5 to 8.5. The current investigation ranges were 6.52\u20136.83 which are in the range of WHO standards.\n\n2. Hardness:\nHardness is mainly caused by calcium and magnesium salts. These salts are dissolved from geologic deposits through which water travels. The length of time water is in contact with hardness producing material helps determine how much hardness there is in raw water. Hardness was originally defined as the capacity of water to precipitate soap caused by Calcium and Magnesium.\n\n3. Solids (Total dissolved solids - TDS):\nWater has the ability to dissolve a wide range of inorganic and some organic minerals or salts such as potassium, calcium, sodium, bicarbonates, chlorides, magnesium, sulfates etc. These minerals produced un-wanted taste and diluted color in appearance of water. This is the important parameter for the use of water. The water with high TDS value indicates that water is highly mineralized. Desirable limit for TDS is 500 mg\/l and maximum limit is 1000 mg\/l which prescribed for drinking purpose.\n\n4. Chloramines:\nChlorine and chloramine are the major disinfectants used in public water systems. Chloramines are most commonly formed when ammonia is added to chlorine to treat drinking water. Chlorine levels up to 4 milligrams per liter (mg\/L or 4 parts per million (ppm)) are considered safe in drinking water.\n\n5. Sulfate:\nSulfates are naturally occurring substances that are found in minerals, soil, and rocks. They are present in ambient air, groundwater, plants, and food. The principal commercial use of sulfate is in the chemical industry. Sulfate concentration in seawater is about 2,700 milligrams per liter (mg\/L). It ranges from 3 to 30 mg\/L in most freshwater supplies, although much higher concentrations (1000 mg\/L) are found in some geographic locations.\n\n6. Conductivity:\nPure water is not a good conductor of electric current rather\u2019s a good insulator. Increase in ions concentration enhances the electrical conductivity of water. Generally, the amount of dissolved solids in water determines the electrical conductivity. Electrical conductivity (EC) actually measures the ionic process of a solution that enables it to transmit current. According to WHO standards, EC value should not exceeded 400 \u03bcS\/cm.\n\n7. Organic_carbon:\nTotal Organic Carbon (TOC) in source waters comes from decaying natural organic matter (NOM) as well as synthetic sources. TOC is a measure of the total amount of carbon in organic compounds in pure water. According to US EPA < 2 mg\/L as TOC in treated \/ drinking water, and < 4 mg\/Lit in source water which is use for treatment.\n\n8. Trihalomethanes:\nTHMs are chemicals which may be found in water treated with chlorine. The concentration of THMs in drinking water varies according to the level of organic material in the water, the amount of chlorine required to treat the water, and the temperature of the water that is being treated. THM levels up to 80 ppm is considered safe in drinking water.\n\n9. Turbidity:\nThe turbidity of water depends on the quantity of solid matter present in the suspended state. It is a measure of light emitting properties of water and the test is used to indicate the quality of waste discharge with respect to colloidal matter. The mean turbidity value obtained for Wondo Genet Campus (0.98 NTU) is lower than the WHO recommended value of 5.00 NTU.\n\n10. Potability:\nIndicates if water is safe for human consumption where 1 means Potable and 0 means Not potable.","02c540a5":"# <center> <div class=\"alert-block alert-info alert\"> <span style = \"color:crimson;\"> Importing Libraries <\/center>","fa6bdbf3":"# <center> <div class=\"alert-block alert-info alert\"> <span style = \"color:crimson;\"> Models <\/center>","61f1c56d":"# DecisionTreeClassifier","a89c1b0d":"# Data visualization","ba2ef72d":"# GridSearchCV RandomClassifier","1e7d9687":"# RandomForestClassifier","a832b679":"# Normalizing","bd9a3a7c":"# LogisticRegression","a249d21e":"**Outlier visualize**","c26346cb":"# SVC","9f93673b":"# KNeighborsClassifier","c325f3c4":"# Outlier Treatment","ad3d9a07":"# <center> <div class=\"alert-block alert-info alert\"> <span style = \"color:crimson;\"> Drinking Water Potability | EDA and Prediction <\/center>","c67f92ba":"# RandomSearchcv RandomForestClassifier"}}