{"cell_type":{"367a9ab8":"code","9a48a6d2":"code","e2b25498":"code","b4752660":"code","9dadcdc9":"code","10094c54":"code","0ea5944c":"code","951b1caf":"code","e4cc9b28":"code","cfbe6a05":"code","564db8b4":"code","9572d261":"code","239a0272":"markdown"},"source":{"367a9ab8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import make_union\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9a48a6d2":"train_df = pd.read_csv (\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest_df = pd.read_csv (\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\nsubmission = pd.read_csv (\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")","e2b25498":"train_df.head()","b4752660":"train_text= train_df[\"text\"]\ntest_text=  test_df[\"text\"]\nall_text = pd.concat([train_text, test_text])","9dadcdc9":"word_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    ngram_range=(1, 1),\n    max_features=30000)\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    ngram_range=(1, 4),\n    max_features=30000)\nvectorizer = make_union(word_vectorizer, char_vectorizer, n_jobs=2)","10094c54":"vectorizer.fit(all_text)\ntrain_features = vectorizer.transform(train_text)\ntest_features = vectorizer.transform(test_text)","0ea5944c":"clf = LGBMClassifier()","951b1caf":"#scores = np.mean(cross_val_score(clf, train_features, train_df[\"target\"], cv=3, scoring=\"f1\"))\n#scores","e4cc9b28":"clf.fit(train_features, train_df[\"target\"])","cfbe6a05":"pred = clf.predict(test_features)","564db8b4":"submission[\"target\"] = pred","9572d261":"submission.to_csv(\"submission.csv\", index= False)","239a0272":"This notebook is inspired by this [kernel](https:\/\/www.kaggle.com\/thousandvoices\/logistic-regression-with-words-and-char-n-grams)"}}