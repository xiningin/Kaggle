{"cell_type":{"9f60bcc2":"code","caa3020c":"code","4a4f12e7":"code","adb70ea5":"code","9fa64b13":"code","f1bc443a":"code","ddbf3093":"code","303a4eb6":"code","c7ef40ac":"code","04620884":"code","d01e2587":"code","1d6a1940":"code","4b84dba9":"code","ec0405d0":"code","b1f23b79":"code","e935ff59":"code","7af24bf0":"code","813c9047":"code","9fb818b8":"code","289d8fc3":"markdown","8c359c4c":"markdown","eb3d3185":"markdown","0771c173":"markdown","59c333be":"markdown","79d8ad13":"markdown","8fb14c27":"markdown","5581c3c2":"markdown"},"source":{"9f60bcc2":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nfrom tqdm import tqdm\nimport pandas  as pd\nimport xgboost as xgb","caa3020c":"train_data = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/train.csv')\ntest_data  = pd.read_csv('..\/input\/tabular-playground-series-jan-2021\/test.csv')\ntrain_data.head()","4a4f12e7":"features = ['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7',\n       'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14']\n\nX_train = train_data[features]\ny_train = train_data[\"target\"]\nfinal_X_test = test_data[features]","adb70ea5":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_train, y_train, test_size=0.1)","9fa64b13":"Best_trial = {'lambda': 0.0030282073258141168, 'alpha': 0.01563845128469084, 'colsample_bytree': 0.5,\n             'subsample': 0.7,'n_estimators': 4000, 'learning_rate': 0.01,'max_depth': 15,\n             'random_state': 2020, 'min_child_weight': 257,'tree_method':'gpu_hist'\n             ,'predictor': 'gpu_predictor'}","f1bc443a":"regressor = xgb.XGBRegressor(**Best_trial)\n\nregressor.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_test, y_test)],verbose=False)","ddbf3093":"y_xgb_pred = regressor.predict(final_X_test)","303a4eb6":"output1 = pd.DataFrame({\"id\":test_data.id, \"target\":y_xgb_pred})\noutput1.to_csv('xgb.csv', index=False)","c7ef40ac":"params ={'random_state': 33,'n_estimators':5000,\n 'min_data_per_group': 5,\n 'boosting_type': 'gbdt',\n 'device_type' : 'gpu',\n 'num_leaves': 256,\n 'num_iterations' : 5000,\n 'max_dept': -1,\n 'learning_rate': 0.005,\n 'subsample_for_bin': 200000,\n 'lambda_l1': 1.074622455507616e-05,\n 'lambda_l2': 2.0521330798729704e-06,\n 'n_jobs': -1,\n 'cat_smooth': 1.0,\n 'silent': True,\n 'importance_type': 'split',\n 'metric': 'rmse',\n 'feature_pre_filter': False,\n 'bagging_fraction': 0.8206341150202605,\n 'min_data_in_leaf': 100,\n 'min_sum_hessian_in_leaf': 0.001,\n 'bagging_freq': 6,\n 'feature_fraction': 0.5,\n 'min_gain_to_split': 0.0,\n 'min_child_samples': 20}","04620884":"from lightgbm import LGBMRegressor\n\nlgb_model = LGBMRegressor(**params)\nlgb_model.fit(X_train, y_train, eval_set=(X_test, y_test),early_stopping_rounds = 50, verbose = 0)","d01e2587":"y_pred_lgb = lgb_model.predict(final_X_test)","1d6a1940":"output2 = pd.DataFrame({\"id\":test_data.id, \"target\":y_pred_lgb})\noutput2.to_csv('lgbm.csv', index=False)","4b84dba9":"Best_trial = {'l2_leaf_reg': 0.02247766515106271, 'max_bin': 364, 'subsample': 0.6708650091202213,\n             'learning_rate': 0.010290546311954876, 'max_depth': 10, 'random_state': 24, 'min_data_in_leaf': 300,\n            'loss_function': 'RMSE','n_estimators':  25000,'rsm':0.5}","ec0405d0":"from catboost import CatBoostRegressor\ncb_model = CatBoostRegressor(**Best_trial)","b1f23b79":"cb_model.fit(X_train, y_train,eval_set=(X_test, y_test),use_best_model=True,verbose=1000)","e935ff59":"cat_pred =cb_model.predict(final_X_test)","7af24bf0":"output3 = pd.DataFrame({\"id\":test_data.id, \"target\":cat_pred})\noutput3.to_csv('cat.csv', index=False)","813c9047":"results = (y_pred_lgb + y_xgb_pred + cat_pred) \/ 3 \n\noutput = pd.DataFrame({\"id\":test_data.id, \"target\":results})\noutput.to_csv('submission.csv', index=False)","9fb818b8":"output","289d8fc3":"Parameters adapted from this great notebook, \nhttps:\/\/www.kaggle.com\/hamzaghanmi\/xgboost-hyperparameter-tuning-using-optuna","8c359c4c":"# LightGBM Model","eb3d3185":"# CatBoost Model","0771c173":"# Training XGBoostRegressor","59c333be":"Parameters from this awesome notebook\nhttps:\/\/www.kaggle.com\/hamzaghanmi\/xgboost-hyperparameter-tuning-using-optuna#Catboost-Using-Optuna","79d8ad13":"Loading necessary libraries","8fb14c27":"Splitting the training data","5581c3c2":"parameters from this awesome kernal \nhttps:\/\/www.kaggle.com\/hamditarek\/tabular-playground-series-xgboost-lightgbm"}}