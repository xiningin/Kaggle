{"cell_type":{"c5ea3693":"code","d82fe0b4":"code","e94d720f":"code","73be57ff":"code","0ea8f5af":"code","86916d09":"code","bf332117":"code","478ad588":"code","0f9686f8":"code","4bcc8e42":"code","788c71c3":"code","1ffa0f2a":"code","ab6e6072":"code","aa97114b":"code","3198c2d6":"code","aedbe728":"code","1f1ecc06":"code","195d553d":"code","9d88bff9":"code","a635d05d":"code","113605d6":"code","575e8cd0":"code","88adeca3":"code","3fb3a9d2":"code","da7daf3b":"code","97bcae2f":"code","4176bf62":"code","a580f214":"code","e64ddb16":"code","150ca242":"code","f917942c":"code","73162ab9":"code","0191d4fd":"code","119866be":"code","81678795":"code","22ad68ef":"code","d5004d77":"code","19a398bc":"code","d27cbd1a":"code","328fa665":"code","25b70795":"code","71b4e8e8":"code","ad5c2cc8":"code","0529d21f":"code","35330272":"code","b2e0df48":"code","ffac8315":"code","6f91e8d7":"code","3dfd56da":"code","3689e38e":"code","c5eae62a":"code","03dcbcb1":"code","5bce0482":"code","3aa73cac":"code","f4921eb7":"code","bc92851a":"code","9ad73462":"code","27be6d4b":"code","628b2209":"code","7e8477a8":"code","c9b6f1c4":"code","197e6ca1":"code","e266a4f3":"code","38a6a9b2":"code","6ee35cef":"code","c7325354":"code","540ae11e":"code","b4ba7a34":"code","e0319992":"code","b60582a4":"code","2aea6706":"code","b0ef7f71":"code","6f408db0":"code","b633f2de":"code","0d4f9a96":"code","b442d651":"code","700a0e30":"code","dcd84543":"code","b9322af6":"code","44943d67":"code","1cc9b99b":"code","362b4f3a":"code","f43e9434":"code","1232de78":"code","4303e893":"code","11e50a33":"code","9f97cf58":"code","1617b7db":"code","2d87ebb2":"code","bfeeaf2b":"code","a93e6259":"code","e612c1e5":"code","a473b6c2":"code","d0fb8c74":"code","96d5f74c":"code","79185db7":"code","f50e3e57":"code","93ddfec7":"code","4b515073":"code","5f4e09f1":"code","09f54f12":"code","45e5b66c":"code","15887b0c":"code","fc234ec7":"code","75f1f9c8":"code","04fce14d":"code","d859be4c":"code","d915a431":"code","b77b2841":"code","199345f3":"code","a61bf423":"code","1b46b0c5":"code","94eb3659":"markdown","5d8ce205":"markdown","3fa912c3":"markdown","6e1802ca":"markdown","9584fe18":"markdown","cb36b3df":"markdown","0f110046":"markdown","3711519f":"markdown","05ffa9c3":"markdown","4e8f542b":"markdown","3cf0a7ad":"markdown","8e72589f":"markdown","62c065de":"markdown","51f27d12":"markdown","59e9c9f7":"markdown","ec517d7f":"markdown","25ea67e2":"markdown","c6e10e42":"markdown","c4e81694":"markdown","9dc3068d":"markdown","ccd32d97":"markdown","3df46b5e":"markdown","6b891469":"markdown","c853ade4":"markdown","dbbaecb7":"markdown","18c375de":"markdown","bf72de51":"markdown"},"source":{"c5ea3693":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d82fe0b4":"main_df = pd.read_csv(\"\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf = main_df.copy()\ndf.head()","e94d720f":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom imblearn.over_sampling import SMOTE\nimport warnings\nwarnings.filterwarnings('ignore')","73be57ff":"# Shape of dataframe\n\ndf.shape","0ea8f5af":"# List of all columns\n\ndf.columns","86916d09":"# Basic Information about the dataframe\n\ndf.info()","bf332117":"# List of all features with number of unique values present in them\n\ndf.nunique()","478ad588":"# Statistical measure of dataset\n\ndf.describe()","0f9686f8":"# We are dropping CustomerID because it will not make any contribution in prediction.\n\ndf = df.drop('customerID', axis=1)\ndf.head()","4bcc8e42":"# Here totalcharges are object types so we need to change it into numeric format\ndf['TotalCharges'].dtype","788c71c3":"# Changing in numeric format\n\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors=\"coerce\")","1ffa0f2a":"# Checking for null values \n\ndf.isnull().sum()","ab6e6072":"# Dropping all the rows in which value in not known\n\ndf.drop(df[df['TotalCharges'].isnull()].index, inplace=True)\ndf.reset_index(drop=True, inplace=True)","aa97114b":"df.head()","3198c2d6":"df.shape","aedbe728":"# Visualization of null values\n\nsns.heatmap(df.isnull())","1f1ecc06":"# Checking Correlation \n\ndf.corr()","195d553d":"# Visualizing correalation\n\nsns.heatmap(df.corr(), annot=True)","9d88bff9":"plt.figure(figsize=(5, 5))\nsns.barplot(data = df, y=\"TotalCharges\", x=\"Churn\")","a635d05d":"sns.barplot(data = df, x=\"tenure\", y=\"Churn\")","113605d6":"px.scatter(df, y=\"TotalCharges\", x=\"tenure\")","575e8cd0":"diag = px.histogram(df, x=\"Churn\", color=\"SeniorCitizen\")\ndiag.update_layout(width=750, height=550)\ndiag.show()","88adeca3":"diag = px.pie(df, values='TotalCharges', names='Churn', hole=0.5)\ndiag.show()","3fb3a9d2":"labels = df['MultipleLines'].unique()\nvalues = df['MultipleLines'].value_counts()\n\n# pull is given as a fraction of the pie radius\ndiag = go.Figure(data=[go.Pie(labels=labels, values=values, pull=[0, 0.1, 0.2])])\ndiag.show()","da7daf3b":"labels = df['InternetService'].unique()\nvalues = df['InternetService'].value_counts()\n\n\ndiag = go.Figure(data=[go.Pie(labels=labels, values=values, pull=[0, 0.2, 0.3])])\ndiag.show()","97bcae2f":"labels = df['PaymentMethod'].unique()\nvalues = df['PaymentMethod'].value_counts()\n\n\ndiag = go.Figure(data=[go.Pie(labels=labels, values=values, pull=[0, 0, 0.2, 0])])\ndiag.show()","4176bf62":"labels = df['Contract'].unique()\nvalues = df['Contract'].value_counts()\n\n\ndiag = go.Figure(data=[go.Pie(labels=labels, values=values, pull=[0, 0.2, 0.3])])\ndiag.show()","a580f214":"print (df['Partner'].value_counts(ascending=True))","e64ddb16":"for i in df.columns:\n    if df[i].dtypes==\"object\":\n        print(f'{i} : {df[i].unique()}')\n        print(\"****************************************************\")","150ca242":"df.replace('No internet service', 'No', inplace=True)\ndf.replace('No phone service', 'No', inplace=True)","f917942c":"for i in df.columns:\n    if df[i].dtypes==\"object\":\n        print(f'{i} : {df[i].unique()}')\n        print(\"****************************************************\")","73162ab9":"print(df['gender'].value_counts(ascending=True))","0191d4fd":"# Replaceing Male be 0 and Female by 1\n\ndf['gender'].replace({'Female':1,'Male':0},inplace=True)\ndf.head()","119866be":"print(df['InternetService'].value_counts(ascending=True))","81678795":"for i in df.columns:\n    if (len(df[i].unique()) >2) & (df[i].dtypes != \"int64\") &(df[i].dtypes!= \"float64\"):\n        print(i)","22ad68ef":"print(df['InternetService'].value_counts(ascending=True))","d5004d77":"print(df['Contract'].value_counts(ascending=True))","19a398bc":"print(df['PaymentMethod'].value_counts(ascending=True))","d27cbd1a":"len(df['PaymentMethod'].unique())","328fa665":"more_than_2 = ['InternetService' ,'Contract' ,'PaymentMethod']\ndf = pd.get_dummies(data=df, columns= more_than_2)\ndf.dtypes","25b70795":"df.shape","71b4e8e8":"df.columns","ad5c2cc8":"for i in df.columns:\n    if (df[i].dtypes == \"int64\")  | (df[i].dtypes== \"float64\"):\n        print(i)","0529d21f":"# Using MinMaxScaler of Feature Scaling\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","35330272":"large_cols = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\ndf[large_cols] = scaler.fit_transform(df[large_cols])\ndf[large_cols].head()","b2e0df48":"# After feature scaling we have following dataset\n\ndf.head()","ffac8315":"for i in df.columns:\n    if (df[i].dtypes == \"object\"):\n        print(i)","6f91e8d7":"two_cate = ['Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling', 'Churn']\nfor i in two_cate:\n    df[i].replace({\"No\":0, \"Yes\":1}, inplace=True)\ndf.head()","3dfd56da":"# Splitting Dataset into train and test set\n\nX = df.drop('Churn', axis=1)\ny = df['Churn']","3689e38e":"X.shape, y.shape","c5eae62a":"# Performing Train Test Split\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)","03dcbcb1":"# Importing Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report","5bce0482":"# creating object for model\nmodel_lg = LogisticRegression(max_iter=120,random_state=0, n_jobs=20)","3aa73cac":"# Model Training\n\nmodel_lg.fit(X_train, y_train)","f4921eb7":"# Making Predictions\npred_lg = model_lg.predict(X_test)","bc92851a":"# Calculating Accuracy of the model\n\nlg = round(accuracy_score(y_test, pred_lg)*100,2)\nprint(lg)","9ad73462":"# Classification Report\n\nprint(classification_report(y_test, pred_lg))","27be6d4b":"# confusion Matrix\n\ncm1 = confusion_matrix(y_test, pred_lg)\nsns.heatmap(cm1\/np.sum(cm1), annot=True, fmt='0.2%', cmap=\"Reds\")\nplt.title(\"Logistic Regression Confusion Matrix\",fontsize=12)\nplt.show()","628b2209":"from sklearn.tree import DecisionTreeClassifier","7e8477a8":"# Creating object of the model\nmodel_dt = DecisionTreeClassifier(max_depth=4, random_state=42)","c9b6f1c4":"model_dt.fit(X_train, y_train)","197e6ca1":"pred_dt = model_dt.predict(X_test)","e266a4f3":"dt  = round(accuracy_score(y_test, pred_dt)*100, 2)\nprint(dt)    ","38a6a9b2":"print(classification_report(y_test, pred_dt))","6ee35cef":"# confusion Maxtrix\ncm2 = confusion_matrix(y_test, pred_dt)\nsns.heatmap(cm2\/np.sum(cm2), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"Decision Tree Classifier Confusion Matrix\",fontsize=12)\nplt.show()","c7325354":"from sklearn.ensemble import RandomForestClassifier","540ae11e":"# Creating model object\nmodel_rf = RandomForestClassifier(n_estimators=300,min_samples_leaf=0.16, random_state=42)","b4ba7a34":"# Training Model\nmodel_rf.fit(X_train, y_train)","e0319992":"# Making Prediction\npred_rf = model_rf.predict(X_test)","b60582a4":"# Calculating Accuracy Score\nrf = round(accuracy_score(y_test, pred_rf)*100, 2)\nprint(rf)","2aea6706":"print(classification_report(y_test,pred_rf))","b0ef7f71":"# confusion Maxtrix\ncm3 = confusion_matrix(y_test, pred_rf)\nsns.heatmap(cm3\/np.sum(cm3), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"RandomForest Classifier Confusion Matrix\",fontsize=12)\nplt.show()","6f408db0":"from xgboost import XGBClassifier","b633f2de":"# Creating model object\nmodel_xgb = XGBClassifier(max_depth= 8, n_estimators= 125, random_state= 0,  learning_rate= 0.03, n_jobs=5)","0d4f9a96":"# Training Model\nmodel_xgb.fit(X_train, y_train)","b442d651":"# Making Prediction\npred_xgb = model_xgb.predict(X_test)","700a0e30":"# Calculating Accuracy Score\nxgb = round(accuracy_score(y_test, pred_xgb)*100, 2)\nprint(xgb)","dcd84543":"print(classification_report(y_test,pred_xgb))","b9322af6":"# confusion Maxtrix\ncm4 = confusion_matrix(y_test, pred_xgb)\nsns.heatmap(cm4\/np.sum(cm4), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"XGBoost Classifier Confusion Matrix\",fontsize=12)\nplt.show()","44943d67":"from sklearn.neighbors import KNeighborsClassifier","1cc9b99b":"# Creating model object\nmodel_kn = KNeighborsClassifier(n_neighbors=9, leaf_size=20)","362b4f3a":"# Training Model\nmodel_kn.fit(X_train, y_train)","f43e9434":"# Making Prediction\npred_kn = model_kn.predict(X_test)","1232de78":"# Calculating Accuracy Score\nkn = round(accuracy_score(y_test, pred_kn)*100, 2)\nprint(kn)","4303e893":"print(classification_report(y_test,pred_kn))","11e50a33":"# confusion Maxtrix\ncm5 = confusion_matrix(y_test, pred_kn)\nsns.heatmap(cm5\/np.sum(cm5), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"KN Classifier Confusion Matrix\",fontsize=12)\nplt.show()","9f97cf58":"from sklearn.svm import SVC, LinearSVC","1617b7db":"model_svm = SVC(kernel='rbf', random_state = 42)","2d87ebb2":"model_svm.fit(X_train, y_train)","bfeeaf2b":"# Making Prediction\npred_svm = model_svm.predict(X_test)","a93e6259":"# Calculating Accuracy Score\nsv = round(accuracy_score(y_test, pred_svm)*100, 2)\nprint(sv)","e612c1e5":"print(classification_report(y_test,pred_kn))","a473b6c2":"# confusion Maxtrix\ncm6 = confusion_matrix(y_test, pred_svm)\nsns.heatmap(cm6\/np.sum(cm6), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"SVM Classifier Confusion Matrix\",fontsize=12)\nplt.show()","d0fb8c74":"from sklearn.ensemble import AdaBoostClassifier","96d5f74c":"model_ada = AdaBoostClassifier(learning_rate= 0.002,n_estimators= 205,random_state=42)","79185db7":"model_ada.fit(X_train, y_train)","f50e3e57":"# Making Prediction\npred_ada = model_ada.predict(X_test)","93ddfec7":"# Calculating Accuracy Score\nada = round(accuracy_score(y_test, pred_ada)*100, 2)\nprint(ada)","4b515073":"print(classification_report(y_test,pred_ada))","5f4e09f1":"# confusion Maxtrix\ncm7 = confusion_matrix(y_test, pred_ada)\nsns.heatmap(cm7\/np.sum(cm7), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"Adaboost Classifier Confusion Matrix\",fontsize=12)\nplt.show()","09f54f12":"df.head()","45e5b66c":"oversample = SMOTE()","15887b0c":"X1, y1 = oversample.fit_resample(X,y)","fc234ec7":"X1.shape, y1.shape","75f1f9c8":"X_train, X_test, y_train, y_test = train_test_split( X1, y1, test_size=0.33, random_state=0)","04fce14d":"model_rf_smt=RandomForestClassifier(criterion = \"gini\",random_state = 10,max_depth=10, min_samples_leaf=5)","d859be4c":"model_rf_smt.fit(X_train,y_train)","d915a431":"pred_rf_smt = model_rf_smt.predict(X_test)","b77b2841":"rf_smt  = round(accuracy_score(y_test, pred_rf_smt)*100, 2)\nprint(rf_smt)    ","199345f3":"print(classification_report(y_test, pred_rf_smt))","a61bf423":"cm8 = confusion_matrix(y_test, pred_rf_smt)\nsns.heatmap(cm8\/np.sum(cm8), annot = True, fmt=  '0.2%', cmap = 'Reds')\nplt.title(\"Random Forest (using SMOTE) Confusion Matrix \",fontsize=12)\nplt.show()","1b46b0c5":"models = pd.DataFrame({\n    'Model':['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'KNeighbours', 'SVM', 'AdaBoost', 'Random Forest \\'SMOTE\\''],\n    'Accuracy_score' :[lg, dt, rf, xgb, kn, sv, ada, rf_smt]\n})\nmodels\nsns.barplot(x='Accuracy_score', y='Model', data=models)\n\nmodels.sort_values(by='Accuracy_score', ascending=False)","94eb3659":"###  Using SVM","5d8ce205":"* Above cell shows us the list of all features with their respective categorical variables","3fa912c3":"* Importing the basic libraries required in this notebook","6e1802ca":"### Using decision Tree Classifer","9584fe18":"* It is always considered as a good pratice to work on the copy of original dataset.","cb36b3df":"## Visualization","0f110046":"### Conclusion :- Above graph shows the performance and comparsion of different models used in this notebook.","3711519f":"### Using XGBoost Classifier","05ffa9c3":"### Handling Imbalance dataset Using SMOTE and apply Random Forest Algorithm","4e8f542b":"### Using Random Forest ","3cf0a7ad":"* There are few features in which categorical variables are more than two and they are not \"Yes\" or \"No\" types","8e72589f":"* After Removing all long values we have above dataframe","62c065de":"### Using KNeighbours","51f27d12":"* To deal with such kind of feature column we are required to use one-hot encoding.","59e9c9f7":"Following are the list of algorithms that are used in this notebook.\n\n| Algorithms      |\n| ----------- |\n| Logistic Regression      | \n| Decision Tree   | \n| Random Forest     | \n| XGBoost    | \n| KNeighbours      | \n| SVM   | \n| AdaBoost      | ","ec517d7f":"* Above feature column have numerical data so we will need to bring it into a particular range if they varies a lot","25ea67e2":"* Here we will consider gender and seniorcitizen because because their values already present in a small scale of 0 or 1\n* So we will consider only \"tenure\", \"MonthlyCharges\", \"TotalCharges\"","c6e10e42":"### Using AdaBoost Classifier","c4e81694":"### Preprocessing Data","9dc3068d":"## About Dataset\n\n**Context**\n\n\"Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.\"\n\n**Content**\n\nEach row represents a customer, each column contains customer\u2019s attributes described on the column Metadata.\n\nThe data set includes information about:\n\nCustomers who left within the last month \u2013 the column is called Churn\nServices that each customer has signed up for \u2013 phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\nCustomer account information \u2013 how long they\u2019ve been a customer, contract, payment method, paperless billing, monthly charges, and total charges\nDemographic info about customers \u2013 gender, age range, and if they have partners and dependents","ccd32d97":"* All the column present above have object type of dataset in them i.e here only \"Yes\" or \"No\"","3df46b5e":"## Model Building","6b891469":"### Using Logistics Regression","c853ade4":"<center> <img src=\"https:\/\/images.squarespace-cdn.com\/content\/v1\/588f9607bebafbc786f8c5f8\/1607924812500-Y1JR8L6XP5NKF2YPHDUX\/image6.png?format=1000w\"> <\/center>","dbbaecb7":"* Above 3 Features column in dataset have more than 2 categorical values","18c375de":"### EDA - Exploratory Data Analysis","bf72de51":"* Replace long negative text by \"No\" for ease of access"}}