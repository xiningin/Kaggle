{"cell_type":{"8182da4c":"code","c97dd128":"code","bebf6823":"code","7c094bfc":"code","1125bce3":"code","74c83396":"code","93d4e680":"code","83ab4d95":"code","fbe6a8f5":"code","54890939":"code","587cb29d":"code","6cd0f9a7":"code","2fdf17da":"code","bf31e28a":"code","18f9b32b":"code","405427b8":"code","822a9541":"code","82ee6725":"code","c000be69":"markdown","338c8e8a":"markdown","813934fa":"markdown","7687fb07":"markdown","58ae45d3":"markdown","6ad1efec":"markdown","06e0f281":"markdown"},"source":{"8182da4c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","c97dd128":"PATH = '..\/input\/stanford-covid-vaccine'\n\ntrain = pd.read_json(f'{PATH}\/train.json',lines=True).drop(columns=['index'])\ntest = pd.read_json(f'{PATH}\/test.json', lines=True).drop(columns=['index'])\nsubmission = pd.read_csv(f'{PATH}\/sample_submission.csv')","bebf6823":"def get_structure_mean_value(row, col):\n    r_d = {'S': [], 'M': [], 'I': [], 'B': [], 'H': [], 'E': [], 'X': []}\n    for p, r in zip(row['predicted_loop_type'], row[col]):\n        r_d[p].append(r)\n\n    r_m = {}\n    for k in r_d.keys():\n        r_m[k] = np.mean(r_d[k])\n    return r_m['S'], r_m['M'], r_m['I'], r_m['B'], r_m['H'], r_m['E'], r_m['X']","7c094bfc":"r_vals = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\ne_vals = ['reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C']","1125bce3":"for col in r_vals:\n    train[f'S_{col}'], train[f'M_{col}'], train[f'I_{col}'], train[f'B_{col}'], train[f'H_{col}'], train[f'E_{col}'], train[f'X_{col}'] = zip(*train.apply(lambda x: get_structure_mean_value(x, col), axis=1))","74c83396":"def plot_loop_type_values(df, col, xlim):\n    df[[f'S_{col}', f'M_{col}', f'I_{col}', f'B_{col}', f'H_{col}', f'E_{col}', f'X_{col}']].plot.kde(title=col, xlim=xlim)","93d4e680":"for col in r_vals:\n    plot_loop_type_values(train, col, xlim=[-2, 3])","83ab4d95":"loop_type = ['S', 'M', 'I', 'B', 'H', 'E', 'X']","fbe6a8f5":"all_mean_loop_vals = {}\nsn_train = train[train['SN_filter']==1]\nfor col in r_vals:\n    mean_loop_vals = {}\n    for loop in loop_type:\n        v = sn_train[f'{loop}_{col}']\n        mean_loop_vals[loop] = np.nanmean(v.values)\n    all_mean_loop_vals[col] = mean_loop_vals","54890939":"# Only use the ones that qualify according the Signal to Noise Filter\ncv_train = train[train['SN_filter']==1]","587cb29d":"cv_train = cv_train[['id', 'predicted_loop_type'] + r_vals]","6cd0f9a7":"cv_out = {}\nfor col in r_vals:\n    cv_out[col] = np.array([np.array(x) for x in cv_train[col].values])","2fdf17da":"# Get the predicted values according to the dumb model\ncv_preds = {}\nfor col in r_vals:\n    data = []\n    for i, loop in enumerate(cv_train['predicted_loop_type']):\n        vals = np.zeros(len(loop))\n        for j, nt in enumerate(loop):\n            vals[j] = all_mean_loop_vals[col][nt]\n        data.append(vals[:68])\n    cv_preds[col] = np.array(data)","bf31e28a":"def mcrmse(y_grd, y_hat):\n    r_vals = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n    cv_score = []\n    for col in r_vals:\n        cv_score.append(np.sqrt(np.mean(np.square(y_grd[col] - y_hat[col]))))\n    return np.mean(cv_score)","18f9b32b":"mcrmse(cv_out, cv_preds)","405427b8":"all_rows = []\nfor j,r in test[['id', 'predicted_loop_type']].iterrows():\n    for i, loop in enumerate(r['predicted_loop_type']):\n        #print(loop)\n        row = {}\n        row['id_seqpos'] = f'{r[\"id\"]}_{i}'\n        for col in r_vals:\n            row[col] = all_mean_loop_vals[col][loop]\n        all_rows.append(row)","822a9541":"sub = pd.DataFrame(all_rows)","82ee6725":"sub.to_csv('submission.csv', index=False)","c000be69":"## Dumb Model\n\nLet's make a dumb model that only uses the averages of the overall `predicted_loop_type` values per predicted column.","338c8e8a":"## Evaluation\n\nInterestingly, this is scoring better than some of the other XGBoost and LightGBM models out there!","813934fa":"## EDA","7687fb07":"Here we can see the reactivity by the Predicted Loop Type. Makes sense to think that the stems should be less reactive while the dangling ends are the most reactive.","58ae45d3":"## Dumb Model CV","6ad1efec":"## Ideas\n\n* From a structural perspective, it seems that each nucleotide's reactivity is dependent on its place in the overall structure\n* Perhaps one of the things to ask is what is the overall stability of the molecule itself?\n  * I would hypothesize that a more stable molecule is less likely to have individual nucleotides that are more reactive\n* However we're tasked with finding the local stability as well\n  * Likely this will be dependent on the following:\n    * Nucleotide type - G\/C tend to be more stable compared to A\/T due to three vs two hydrogen bonds\n    * Surrounding structure - anticipate that change points in surrounding structures will correlate to weaknesses","06e0f281":"## Variables\n\n#### Sequence Variables\n\n* `sequence` - provides the nucleotide sequence\n* `structure` - provides the pairing data where `(` and `)` refer to paired sequences at their respective indices while `.` means an unpaired sequence\n* `predicted_loop_type` - describe the structural context of the sequence\n  * S: paired \"Stem\" \n  * M: Multiloop \n  * I: Internal loop \n  * B: Bulge \n  * H: Hairpin loop \n  * E: dangling End \n  * X: eXternal loop\n  \n#### Evaluation\n\n* The model will be predicting `reactivity`, `deg_Mg_pH10`, `deg_pH10`, `deg_Mg_50C`, and `deg_50C` for each nucleotide position in the mRNA\n* However the model will only be evaluated on the first `seq_scored` nucleotides since the competition organizers use a next-generation sequencer that provides measurements for all samples in a single reaction, however \"padding\" nucleotides are used for demultiplexing (https:\/\/www.kaggle.com\/c\/stanford-covid-vaccine\/discussion\/181991)\n* The *mean column-wise root mean squared error (MCRMSE)* is used"}}