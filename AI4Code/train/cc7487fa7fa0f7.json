{"cell_type":{"886dc5c5":"code","b824a332":"code","9f68dfe6":"code","5737132d":"code","c0e1a807":"code","3964d90a":"code","227fdedb":"code","544a564d":"code","0b2ea4a9":"code","b0a0e404":"code","d22a7692":"code","77836b47":"code","871b950a":"code","7e230f1c":"code","2224d16b":"code","a275c0af":"code","d2a24611":"code","da00b08b":"code","e965cef0":"code","1d54c6d7":"code","7a6aceaa":"code","755bd604":"code","a1f396f4":"code","ac17b81a":"code","5e630564":"code","003c820c":"markdown","6faa6e0d":"markdown","3c5caa59":"markdown","9f457721":"markdown","4e29b061":"markdown","ecad55c7":"markdown"},"source":{"886dc5c5":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nimport zipfile\nwith zipfile.ZipFile('..\/input\/plates.zip', 'r') as zip_obj:\n   # Extract all the contents of zip file in current directory\n   zip_obj.extractall('\/kaggle\/working\/')\n    \nprint('After zip extraction:')\nprint(os.listdir(\"\/kaggle\/working\/\"))","b824a332":"data_root = '\/kaggle\/working\/plates\/'\nprint(os.listdir(data_root))","9f68dfe6":"import shutil \nfrom tqdm import tqdm\n\ntrain_dir = 'train'\nval_dir = 'val'\n\nclass_names = ['cleaned', 'dirty']\n\nfor dir_name in [train_dir, val_dir]:\n    for class_name in class_names:\n        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n\nfor class_name in class_names:\n    source_dir = os.path.join(data_root, 'train', class_name)\n    for i, file_name in enumerate(tqdm(os.listdir(source_dir))):\n        if i % 6 != 0:\n            dest_dir = os.path.join(train_dir, class_name) \n        else:\n            dest_dir = os.path.join(val_dir, class_name)\n        shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))","5737132d":"import torch\nimport numpy as np\nimport torchvision\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nfrom torchvision import transforms, models","c0e1a807":"train_transforms = transforms.Compose([\n     transforms.RandomApply([\n        transforms.ColorJitter(\n            brightness=0.2,\n            contrast=0.2,\n            saturation=0.2,\n            hue= (0.1, 0.2)\n        )\n    ]),\n    transforms.CenterCrop(224),\n    transforms.RandomHorizontalFlip(), #p=0.5\n    transforms.RandomVerticalFlip(), #p=0.5\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    transforms.Lambda(\n        lambda x: x[np.random.permutation(3), :, :]) #random channerl permutation\n])\n\nval_transforms = transforms.Compose([\n    transforms.CenterCrop(224),#same as in train\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_dataset = torch.utils.data.ConcatDataset([\n    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n    torchvision.datasets.ImageFolder(train_dir, train_transforms),    \n    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n    torchvision.datasets.ImageFolder(train_dir, train_transforms),\n    torchvision.datasets.ImageFolder(train_dir, train_transforms)\n])\nval_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n\nbatch_size = 8\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)","3964d90a":"len(train_dataloader), len(train_dataset)","227fdedb":"X_batch, y_batch = next(iter(train_dataloader))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nplt.imshow(X_batch[0].permute(1, 2, 0).numpy() * std + mean);","544a564d":"def show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nX_batch, y_batch = next(iter(train_dataloader))\n\nfor x_item, y_item in zip(X_batch, y_batch):\n    show_input(x_item, title=class_names[y_item])","0b2ea4a9":"def train_model(model, loss, optimizer, scheduler, num_epochs):\n    \n    train_loss_row = []\n    train_acc_row = []\n    val_loss_row = []\n    val_acc_row = []\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}:'.format(epoch, num_epochs - 1), flush=True)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                dataloader = val_dataloader\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.\n            running_acc = 0.\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                # forward and backward\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n\n            epoch_loss = running_loss \/ len(dataloader)\n            epoch_acc = running_acc \/ len(dataloader)\n        \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n            \n            if phase == 'train':\n                train_loss_row.append(epoch_loss)\n                train_acc_row.append(epoch_acc)\n            else:\n                val_loss_row.append(epoch_loss)\n                val_acc_row.append(epoch_acc)\n\n    return model, train_loss_row, train_acc_row, val_loss_row, val_acc_row","b0a0e404":"class PlatesNet(torch.nn.Module):\n    def __init__(self):\n        super(PlatesNet, self).__init__()\n        self.resnet = models.resnet152(pretrained=True, progress=False)\n\n        # Disable grad for all conv layers\n        #for param in self.resnet.parameters():\n        #    param.requires_grad = False\n\n        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, self.resnet.fc.in_features \/\/ 2)\n        self.act = torch.nn.LeakyReLU()\n        self.fc = torch.nn.Linear(self.resnet.fc.in_features \/\/ 2, self.resnet.fc.in_features \/\/ 4)\n        self.act1 = torch.nn.LeakyReLU()\n        self.fc1 = torch.nn.Linear(self.resnet.fc.in_features \/\/ 4, 2)\n    \n    def forward(self, X):\n        X = self.resnet(X)\n        X = self.act(X)\n        X = self.fc(X)\n        X = self.act1(X)\n        X = self.fc1(X)\n        \n        return X\n\nmodel = PlatesNet()\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4)\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=14, gamma=0.1)","d22a7692":"num_epochs=60","77836b47":"model, train_loss_row, train_acc_row, val_loss_row, val_acc_row = train_model(model, loss, optimizer, scheduler, num_epochs);","871b950a":"plt.plot(np.arange(num_epochs), train_loss_row, np.arange(num_epochs), val_loss_row)","7e230f1c":"plt.plot(np.arange(num_epochs), train_acc_row, np.arange(num_epochs), val_acc_row)","2224d16b":"test_dir = 'test'\nshutil.copytree(os.path.join(data_root, 'test'), os.path.join(test_dir, 'unknown'))","a275c0af":"class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path\n    \ntest_dataset = ImageFolderWithPaths('\/kaggle\/working\/test', val_transforms)\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)","d2a24611":"test_dataset","da00b08b":"model.eval()\n\ntest_predictions = []\ntest_img_paths = []\nfor inputs, labels, paths in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds = model(inputs)\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    test_img_paths.extend(paths)\n    \ntest_predictions = np.concatenate(test_predictions)","e965cef0":"inputs, labels, paths = next(iter(test_dataloader))\n\nfor img, pred in zip(inputs, test_predictions):\n    show_input(img, title=pred)","1d54c6d7":"submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})","7a6aceaa":"submission_df['label'].mean()","755bd604":"submission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if pred > 0.75 else 'cleaned')\nsubmission_df['id'] = submission_df['id'].str.replace('\/kaggle\/working\/test\/unknown\/', '')\nsubmission_df['id'] = submission_df['id'].str.replace('.jpg', '')\nsubmission_df.set_index('id', inplace=True)\nsubmission_df.head(n=6)","a1f396f4":"submission_df","ac17b81a":"submission_df.to_csv('submission.csv')","5e630564":"!rm -rf train val test","003c820c":"## Simple visualization","6faa6e0d":"## Dataset creation\nAlgorithm of transform and train dataset creation by copying of base train dataset. \n\nDataset size = 32 (base size) * 10 = 320\nbatch size = 8\n\nList of transforms:\n* CenterCrops 224x224 (not Resize(224,224)!) in train and in validation transform\n* ColorJitter\n* RandomFlip with p=0.5\n* Channels random permutation","3c5caa59":"## Own class for network\n\nI use ResNet 152 architecture with 3 additional fully-connected layers.\n\nlr = 0.0001\ngamma = 0.1\nsetp_size = 14","9f457721":"## Using of trained model","4e29b061":"## Train algorithm","ecad55c7":"You should check and change board level before you can use your Net. It's value should be near mean value. "}}