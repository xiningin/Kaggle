{"cell_type":{"cf66376b":"code","e0b1799e":"code","3cf331bf":"code","af0de4a9":"code","3ddc9000":"code","50f101d9":"code","2dddbe51":"code","0370da94":"code","73f5f541":"code","4d1d8b11":"code","5b8be326":"code","ee9de0fb":"code","f07a888d":"code","f7c75a15":"code","2688b909":"markdown","4ab6bb21":"markdown"},"source":{"cf66376b":"import cv2\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import load_model\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Add,BatchNormalization\nfrom keras.models import Model\nimport keras.backend as K\nfrom keras.optimizers import Adam\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\n%matplotlib inline","e0b1799e":"img_h=np.load(\"..\/input\/img-map\/imgs_test_hr.npy\")\nimg_l=np.load(\"..\/input\/img-map\/imgs_test_lr.npy\")\nprint(img_h.shape)\nprint(img_l.shape)","3cf331bf":"img_h=img_h\/255\nimg_l=img_l\/255","af0de4a9":"plt.imshow(img_l[11])","3ddc9000":"plt.imshow(img_h[11])","50f101d9":"num = 11\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 2, 1)\nplt.imshow(np.squeeze(img_l[num]))\n\nax = plt.subplot(1, 2, 2)\nplt.imshow(np.squeeze(img_h[num]))","2dddbe51":"\"\"\"\n\u8bad\u7ec3SRGAN\u6a21\u578b\n\n\u738b\u5251\n\"\"\"\n\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import BatchNormalization, Activation, Add, Input, Dense\nfrom tensorflow.keras.layers import Conv2D, UpSampling2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.applications import VGG19,VGG16\nfrom tensorflow.keras.utils import plot_model\nimport tensorflow.keras.backend as K\nfrom tensorflow import concat\n\n\nclass SRGAN():\n    def __init__(self):\n        self.channels = 3\n        self.lr_h = 120\n        self.lr_w = 120\n        self.lr_shape = (self.lr_h, self.lr_w, self.channels)\n\n        self.hr_h = self.lr_h * 4\n        self.hr_w = self.lr_w * 4\n        self.hr_shape = (self.hr_h, self.hr_w, self.channels)\n\n        patch = int(self.hr_h \/ 2 ** 4)\n        self.D_patch = (patch, patch, 1)\n        self.dataset_name = '20191207_0450'\n\n\n        self.losses = {'epoch': [], 'G_loss': [], 'feature_loss': [], 'mean_loss': []}\n\n        adam = Adam(0.0002, 0.5)\n        self.vgg = self.subvgg()\n        self.vgg.trainable = False\n\n        self.discriminator = self.Discriminator()\n        self.discriminator.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n        #plot_model(self.discriminator, to_file='discriminator_model.png')\n\n        self.generator = self.Generator()\n        #plot_model(self.generator, to_file='generator_model.png')\n\n        img_lr = Input(shape=self.lr_shape)\n        gen_hr = self.generator(img_lr)\n        #gen_hr_vgg = concat([gen_hr, gen_hr, gen_hr], axis=3)\n        gen_features = self.vgg(gen_hr)\n\n        self.discriminator.trainable = False\n        dis = self.discriminator(gen_hr)\n\n        self.combined = Model(img_lr, [dis, gen_features, gen_hr])\n        self.combined.compile(optimizer=adam, loss=['binary_crossentropy', 'mse', 'mean_absolute_error'],\n                              loss_weights=[5e-1, 1, 1])\n\n    def Generator(self):\n        # \u751f\u6210\u5668\n        def residual(input_layer, filters):\n            r = Conv2D(filters, kernel_size=3, strides=1, padding='same',activation='relu')(input_layer)\n            r = BatchNormalization(momentum=0.8)(r)\n            r = Activation('relu')(r)\n            r = Conv2D(filters, kernel_size=3, strides=1, padding='same')(r)\n            r = BatchNormalization(momentum=0.8)(r)\n            r = Add()([r, input_layer])\n            return r\n\n        def deconv2d(input_layer):\n            d = UpSampling2D(size=2)(input_layer)\n            d = Conv2D(256, kernel_size=3, strides=1, padding='same')(d)\n            d = Activation('relu')(d)\n            return d\n\n        img_lr = Input(shape=self.lr_shape)\n        g1 = Conv2D(64, kernel_size=3, strides=1, padding='same')(img_lr)\n        g1 = Activation('relu')(g1)\n\n        g2 = residual(g1, 64)\n        for _ in range(15):\n            g2 = residual(g2, 64)\n        g2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(g2)\n        g2 = BatchNormalization(momentum=0.8)(g2)\n        g2 = Add()([g2, g1])\n\n        g3 = deconv2d(g2)\n        g3 = deconv2d(g3)\n        gen_hr = Conv2D(self.channels, kernel_size=3, strides=1, padding='same', activation='sigmoid')(g3)\n        return Model(img_lr, gen_hr)\n\n    def Discriminator(self):\n        # \u5224\u522b\u5668\n        def sub_block(input_layer, filters, strides):\n            s = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(input_layer)\n            s = LeakyReLU(alpha=0.2)(s)\n            s = BatchNormalization(momentum=0.8)(s)\n            return s\n\n        img_input = Input(shape=self.hr_shape)\n        d1 = Conv2D(64, kernel_size=3, strides=1, padding='same')(img_input)\n        d1 = LeakyReLU(alpha=0.2)(d1)\n\n        d2 = sub_block(d1, 64, 2)\n        d2 = sub_block(d2, 128, 1)\n        d2 = sub_block(d2, 128, 2)\n        d2 = sub_block(d2, 256, 1)\n        d2 = sub_block(d2, 256, 2)\n        d2 = sub_block(d2, 512, 1)\n        d2 = sub_block(d2, 512, 2)\n\n        d3 = Dense(1024)(d2)\n        d3 = LeakyReLU(alpha=0.2)(d3)\n        dis = Dense(1, activation='sigmoid')(d3)\n        return Model(img_input, dis)\n\n    def subvgg(self):\n        vgg = VGG19(input_shape=(self.hr_h, self.hr_w, 3), include_top=False, weights='imagenet')\n        #vgg.outputs = [vgg.layers[9].output]\n        #img_input = Input(shape=(self.hr_h, self.hr_w, 3))\n\n        #img_features = vgg(img_input)\n        return Model(vgg.inputs, vgg.layers[9].output)\n\n    def load_data(self, batch_size=1, band=0):\n        imgs_hr = np.load('..\/input\/img-map\/imgs_test_hr.npy')\n        imgs_lr = np.load('..\/input\/img-map\/imgs_test_lr.npy')\n        imgs_hr=imgs_hr\/255\n        imgs_lr=imgs_lr\/255\n        idx = np.random.choice(imgs_hr.shape[0], size=batch_size, replace=False)\n        img_hr = []\n        img_lr = []\n        for i in range(batch_size):\n            _hr = np.zeros((imgs_hr.shape[1], imgs_hr.shape[2], 3))\n            _lr = np.zeros((imgs_lr.shape[1], imgs_lr.shape[2], 3))\n            _hr[:, :, 0] = imgs_hr[idx[i], :, :, band]\n            _lr[:, :, 0] = imgs_lr[idx[i], :, :, band]\n            img_hr.append(_hr)\n            img_lr.append(_lr)\n        img_hr = np.array(img_hr)\n        img_lr = np.array(img_lr)\n        return img_hr, img_lr\n\n    def scheduler(self, models):\n        # \u5b66\u4e60\u7387\u4e0b\u964d\n        lr = 0\n        for model in models:\n            lr = K.get_value(model.optimizer.lr)\n            K.set_value(model.optimizer.lr, lr * 0.5)\n        print('lr changed to {}'.format(lr * 0.5))\n\n    def loss(self, band):\n        # \u4fdd\u5b58loss\u66f2\u7ebf\n        plt.figure()\n        # loss\n        plt.plot(self.losses['epoch'], self.losses['G_loss'], 'g', label='G loss')\n        plt.plot(self.losses['epoch'], self.losses['feature_loss'], 'k', label='feature loss')\n        plt.plot(self.losses['epoch'], self.losses['mean_loss'], 'r', label='mean loss')\n        plt.grid(True)\n        plt.xlabel('epoch')\n        plt.ylabel('loss')\n        plt.legend(loc=\"upper right\")\n        plt.ylim(0, 40)\n        plt.savefig('loss_band%d.png' % band)\n\n    def train(self, epochs, init_epoch=0, batch_size=1, save_interval=500, band=0):\n        start_time = time.time()\n        self.generator.summary()\n        self.discriminator.summary()\n        g_loss = []\n        temp = [float('inf'), float('inf'), float('inf')]\n        if init_epoch != 0:\n            self.generator.load_weights('gen_epoch%d_%d.h5' % (self.dataset_name, init_epoch, band))\n            self.discriminator.load_weights('dis_epoch%d_%d.h5' % (self.dataset_name, init_epoch, band))\n            self.losses = np.load('loss_%d.npy' % (self.dataset_name, band), allow_pickle=True).item()\n            temp = [self.losses['G_loss'], self.losses['feature_loss'], self.losses['mean_loss']]\n            init_epoch += 1\n        for epoch in range(init_epoch, epochs):\n            if epoch % 20000 == 0 and epoch != 0:\n                self.scheduler([self.combined, self.discriminator])\n            # \u8bad\u7ec3\u5224\u522b\u5668\n            imgs_hr, imgs_lr = self.load_data(batch_size=batch_size, band=band)\n\n            fake_hr = self.generator.predict(imgs_lr)\n            valid = np.ones((batch_size,) + self.D_patch)\n            fake = np.zeros((batch_size,) + self.D_patch)\n            d_loss_real = self.discriminator.train_on_batch(imgs_hr, valid)\n            d_loss_fake = self.discriminator.train_on_batch(fake_hr, fake)\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            # \u8bad\u7ec3\u751f\u6210\u5668\n            imgs_hr, imgs_lr = self.load_data(batch_size=batch_size, band=band)\n            #imgs_hr = np.concatenate([imgs_hr, imgs_hr, imgs_hr], axis=3)\n\n            valid = np.ones((batch_size,) + self.D_patch)\n            image_features = self.vgg.predict(imgs_hr)\n            g_loss = self.combined.train_on_batch(imgs_lr, [valid, image_features, imgs_hr])\n            print(d_loss, g_loss)\n            elapsed_time = time.time() - start_time\n            print(\"[Epoch %d\/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, feature loss: %05f, mean loss: %05f] time: %s \"\n                  % (epoch, epochs, d_loss[0], 100 * d_loss[1], g_loss[1], g_loss[2], g_loss[3], elapsed_time))\n\n            # \u4fdd\u5b58loss\u503c\n            if epoch % 10 == 0:\n                self.losses['epoch'].append(epoch)\n                self.losses['G_loss'].append(g_loss[1])\n                self.losses['feature_loss'].append(g_loss[2])\n                self.losses['mean_loss'].append(g_loss[3])\n            \n            # \u4fdd\u5b58\u6700\u4f73\u6a21\u578b\n            if (temp[0] > g_loss[1]) and (temp[1] > g_loss[2]) and (temp[2] > g_loss[3]):\n                self.generator.save_weights('gen_best_%d.h5')\n                self.discriminator.save_weights('dis_best_%d.h5')\n                temp = [g_loss[1], g_loss[2], g_loss[3]]\n                print('Save current best model (epoch = %d)' % epoch)\n\n            # \u4fdd\u5b58\u6a21\u578b\n            if (epoch % save_interval == 0) & (epoch != 0):\n                self.generator.save_weights('gen_epoch%d_%d.h5')\n                self.discriminator.save_weights('dis_epoch%d_%d.h5')\n                print('Save current model (epoch = %d)' % epoch)\n        self.losses['epoch'].append(epochs)\n        self.losses['G_loss'].append(g_loss[1])\n        self.losses['feature_loss'].append(g_loss[2])\n        self.losses['mean_loss'].append(g_loss[3])\n        self.loss(band=band)\n        self.generator.save_weights('gen_epoch%d_%d.h5')\n        self.discriminator.save_weights('dis_epoch%d_%d.h5')\n        #np.save('..\/Model\/%s\/loss_%d' % (self.dataset_name, band), self.losses)\n\n\nif __name__ == '__main__':\n    for b in range(1):\n        gan = SRGAN()\n        gan.train(epochs=4000, init_epoch=0, batch_size=8, save_interval=1000, band=b)\n    # plot_model(vgg, to_file='model.png')","0370da94":"def Generator():\n    # \u751f\u6210\u5668\n    def residual(input_layer, filters):\n        r = Conv2D(filters, kernel_size=3, strides=1, padding='same',,activation='relu')(input_layer)\n        r = BatchNormalization(momentum=0.8)(r)\n        r = Activation('relu')(r)\n        r = Conv2D(filters, kernel_size=3, strides=1, padding='same')(r)\n        r = BatchNormalization(momentum=0.8)(r)\n        r = Add()([r, input_layer])\n        return r\n\n    def deconv2d(input_layer):\n        d = UpSampling2D(size=2)(input_layer)\n        d = Conv2D(256, kernel_size=3, strides=1, padding='same')(d)\n        d = Activation('relu')(d)\n        return d\n\n    img_lr = Input(shape=[None, None, 3])\n    g1 = Conv2D(64, kernel_size=3, strides=1, padding='same')(img_lr)\n    g1 = Activation('relu')(g1)\n\n    g2 = residual(g1, 64)\n    for _ in range(15):\n        g2 = residual(g2, 64)\n    g2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(g2)\n    g2 = BatchNormalization(momentum=0.8)(g2)\n    g2 = Add()([g2, g1])\n\n    g3 = deconv2d(g2)\n    g3 = deconv2d(g3)\n    gen_hr = Conv2D(3, kernel_size=3, strides=1, padding='same', activation='sigmoid')(g3)\n    return Model(img_lr, gen_hr)\n\ngen =Generator()\ngen.load_weights(\".\/gen_best_%d.h5\")\nresults=gen.predict(img_l,batch_size=4)","73f5f541":"results[0]","4d1d8b11":"n = 33\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 3, 3)\nplt.imshow(np.squeeze(results[n]))\n\nax = plt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(img_h[n]))\n\nax = plt.subplot(1, 3, 1)\nplt.imshow(np.squeeze(img_l[n]))","5b8be326":"n = 34\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 3, 3)\nplt.imshow(np.squeeze(results[n]))\n\nax = plt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(img_h[n]))\n\nax = plt.subplot(1, 3, 1)\nplt.imshow(np.squeeze(img_l[n]))","ee9de0fb":"n = 35\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 3, 3)\nplt.imshow(np.squeeze(results[n]))\n\nax = plt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(img_h[n]))\n\nax = plt.subplot(1, 3, 1)\nplt.imshow(np.squeeze(img_l[n]))","f07a888d":"gen.load_weights(\"gen_epoch%d_%d.h5\")\nresults=gen.predict(img_l,batch_size=4)\nn = 35\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 3, 3)\nplt.imshow(np.squeeze(results[n]))\n\nax = plt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(img_h[n]))\n\nax = plt.subplot(1, 3, 1)\nplt.imshow(np.squeeze(img_l[n]))","f7c75a15":"n = 39\n\nplt.figure(figsize=(14, 7))\n\nax = plt.subplot(1, 3, 3)\nplt.imshow(np.squeeze(results[n]))\n\nax = plt.subplot(1, 3, 2)\nplt.imshow(np.squeeze(img_h[n]))\n\nax = plt.subplot(1, 3, 1)\nplt.imshow(np.squeeze(img_l[n]))","2688b909":"# Results","4ab6bb21":"# Training"}}