{"cell_type":{"460a40c2":"code","2572910e":"code","77a9b4a5":"code","d0fe36e0":"code","02abf640":"code","bef85461":"code","0d76f955":"code","8e5ea234":"code","42263de3":"code","dfa6f950":"code","ca18b9a3":"code","c22f1cb9":"code","71606ee8":"code","064a2068":"code","03778716":"code","4c37ef44":"code","35f648fc":"code","12861413":"markdown","0e736b7d":"markdown","a4f180bf":"markdown","b3a6f650":"markdown","b9dc3742":"markdown","82376470":"markdown","77c37d37":"markdown","ca805b9d":"markdown","95deeba8":"markdown","f71a3133":"markdown","13ced280":"markdown","89638a48":"markdown","b2da8e6d":"markdown","272c54b3":"markdown","e8ff1144":"markdown","e7c3e322":"markdown","994212e0":"markdown","c6acff71":"markdown","efac9cb1":"markdown"},"source":{"460a40c2":"import numpy as np \nimport pandas as pd \nimport os","2572910e":"Instant_Video_df = pd.read_json('..\/input\/Amazon_Instant_Video_5.json', lines=True)\n\nApps_for_Android_df = pd.read_json('..\/input\/Apps_for_Android_5.json', lines=True)\n\nAutomotive_df = pd.read_json('..\/input\/Automotive_5.json', lines=True)\n\nBaby_df = pd.read_json('..\/input\/Baby_5.json', lines=True)\n\nBeauty_df = pd.read_json('..\/input\/Beauty_5.json', lines=True)\n\nCDs_and_Vinyl_df = pd.read_json('..\/input\/CDs_and_Vinyl_5.json', lines=True)\n\nCell_Phones_and_Accessories_df = pd.read_json('..\/input\/Cell_Phones_and_Accessories_5.json', lines=True)\n\nClothing_Shoes_and_Jewelry_df = pd.read_json('..\/input\/Clothing_Shoes_and_Jewelry_5.json', lines=True)\n\nDigital_Music_df = pd.read_json('..\/input\/Digital_Music_5.json', lines=True)\n\nElectronics_df = pd.read_json('..\/input\/Electronics_5.json', lines=True)\n\nGrocery_and_Gourmet_Food_df = pd.read_json('..\/input\/Grocery_and_Gourmet_Food_5.json', lines=True)\n\nHealth_and_Personal_Care_df = pd.read_json('..\/input\/Health_and_Personal_Care_5.json', lines=True)\n\nHome_and_Kitchen_df = pd.read_json('..\/input\/Home_and_Kitchen_5.json', lines=True)\n\nKindle_Store_df = pd.read_json('..\/input\/Kindle_Store_5.json', lines=True)\n\nMusical_Instruments_df = pd.read_json('..\/input\/Musical_Instruments_5.json', lines=True)\n\nOffice_Products_df = pd.read_json('..\/input\/Office_Products_5.json', lines=True)\n\nPatio_Lawn_and_Garden_df = pd.read_json('..\/input\/Patio_Lawn_and_Garden_5.json', lines=True)\n\nPet_Supplies_df = pd.read_json('..\/input\/Pet_Supplies_5.json', lines=True)\n\nSports_and_Outdoors_df = pd.read_json('..\/input\/Sports_and_Outdoors_5.json', lines=True)\n\nTools_and_Home_Improvement_df = pd.read_json('..\/input\/Tools_and_Home_Improvement_5.json', lines=True)\n\nToys_and_Games_df = pd.read_json('..\/input\/Toys_and_Games_5.json', lines=True)\n\nVideo_Games_df = pd.read_json('..\/input\/Video_Games_5.json', lines=True)","77a9b4a5":"import nltk.classify.util\nfrom nltk.classify import NaiveBayesClassifier\nfrom nltk.corpus import movie_reviews","d0fe36e0":"def extract_features(word_list):\n    return dict([(word, True) for word in word_list])","02abf640":"positive_fileids = movie_reviews.fileids('pos')\nnegative_fileids = movie_reviews.fileids('neg')","bef85461":"features_positive = [(extract_features(movie_reviews.words(fileids=[f])), \n           'Positive') for f in positive_fileids]\nfeatures_negative = [(extract_features(movie_reviews.words(fileids=[f])), \n           'Negative') for f in negative_fileids]","0d76f955":"threshold_factor = 0.8\nthreshold_positive = int(threshold_factor * len(features_positive))\nthreshold_negative = int(threshold_factor * len(features_negative))","8e5ea234":"features_train = features_positive[:threshold_positive] + features_negative[:threshold_negative]\nfeatures_test = features_positive[threshold_positive:] + features_negative[threshold_negative:]  \nprint (\"\\nNumber of training datapoints:\", len(features_train))\nprint (\"Number of test datapoints:\", len(features_test))","42263de3":"classifier = NaiveBayesClassifier.train(features_train)\nprint (\"\\nAccuracy of the classifier:\", nltk.classify.util.accuracy(classifier, features_test))","dfa6f950":"print (\"\\nTop 10 most informative words:\")\nfor item in classifier.most_informative_features()[:10]:\n    print (item[0])","ca18b9a3":"def sentence_Scoring(review):\n    probdist = classifier.prob_classify(extract_features(review.split()))\n    pred_sentiment = probdist.max()\n    if pred_sentiment == \"Negative\":\n        return 0\n    else:\n        return 1","c22f1cb9":"Instant_Video_df['Score'] = Instant_Video_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nApps_for_Android_df['Score'] = Apps_for_Android_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nAutomotive_df['Score'] = Automotive_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nBaby_df['Score'] = Baby_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nBeauty_df['Score'] = Beauty_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nCDs_and_Vinyl_df['Score'] = CDs_and_Vinyl_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nCell_Phones_and_Accessories_df['Score'] = Cell_Phones_and_Accessories_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nClothing_Shoes_and_Jewelry_df['Score'] = Clothing_Shoes_and_Jewelry_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nDigital_Music_df['Score'] = Digital_Music_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nElectronics_df['Score'] = Electronics_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nGrocery_and_Gourmet_Food_df['Score'] = Grocery_and_Gourmet_Food_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nHealth_and_Personal_Care_df['Score'] = Health_and_Personal_Care_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nHome_and_Kitchen_df['Score'] = Home_and_Kitchen_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nKindle_Store_df['Score'] = Kindle_Store_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nMusical_Instruments_df['Score'] = Musical_Instruments_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nOffice_Products_df['Score'] = Office_Products_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nPatio_Lawn_and_Garden_df['Score'] = Patio_Lawn_and_Garden_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nPet_Supplies_df['Score'] = Pet_Supplies_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nSports_and_Outdoors_df['Score'] = Sports_and_Outdoors_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nTools_and_Home_Improvement_df['Score'] = Tools_and_Home_Improvement_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nToys_and_Games_df['Score'] = Toys_and_Games_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)\n\nVideo_Games_df['Score'] = Video_Games_df.apply(lambda row : sentence_Scoring(row['reviewText']),axis = 1)","71606ee8":"Trust_Values = [] \ncount_score_IV = Instant_Video_df.groupby('Score').size()\ntotal_neg_IV = count_score_IV.loc[0]\ntotal_pos_IV = count_score_IV.loc[1]\nmax_rate_IV = Instant_Video_df['overall'].max()\ntrust_IV = (total_pos_IV\/(total_pos_IV+total_neg_IV))*max_rate_IV\nTrust_Values.append(trust_IV.round(2))\n\ncount_score_AA = Apps_for_Android_df.groupby('Score').size()\ntotal_neg_AA = count_score_AA.loc[0]\ntotal_pos_AA = count_score_AA.loc[1]\nmax_rate_AA = Apps_for_Android_df['overall'].max()\ntrust_AA = (total_pos_AA\/(total_pos_AA+total_neg_AA))*max_rate_AA\nTrust_Values.append(trust_AA.round(2))\n\ncount_score_A = Automotive_df.groupby('Score').size()\ntotal_neg_A = count_score_A.loc[0]\ntotal_pos_A = count_score_A.loc[1]\nmax_rate_A = Automotive_df['overall'].max()\ntrust_A = (total_pos_A\/(total_pos_A+total_neg_A))*max_rate_A\nTrust_Values.append(trust_A.round(2))\n\ncount_score_B = Baby_df.groupby('Score').size()\ntotal_neg_B = count_score_B.loc[0]\ntotal_pos_B = count_score_B.loc[1]\nmax_rate_B = Baby_df['overall'].max()\ntrust_B = (total_pos_B\/(total_pos_B+total_neg_B))*max_rate_B\nTrust_Values.append(trust_B.round(2))\n\ncount_score_Be = Beauty_df.groupby('Score').size()\ntotal_neg_Be = count_score_Be.loc[0]\ntotal_pos_Be = count_score_Be.loc[1]\nmax_rate_Be = Beauty_df['overall'].max()\ntrust_Be = (total_pos_Be\/(total_pos_Be+total_neg_Be))*max_rate_Be\nTrust_Values.append(trust_Be.round(2))\n\ncount_score_CD = CDs_and_Vinyl_df.groupby('Score').size()\ntotal_neg_CD = count_score_CD.loc[0]\ntotal_pos_CD = count_score_CD.loc[1]\nmax_rate_CD = CDs_and_Vinyl_df['overall'].max()\ntrust_CD = (total_pos_CD\/(total_pos_CD+total_neg_CD))*max_rate_CD\nTrust_Values.append(trust_CD.round(2))\n\ncount_score_Ce = Cell_Phones_and_Accessories_df.groupby('Score').size()\ntotal_neg_Ce = count_score_Ce.loc[0]\ntotal_pos_Ce = count_score_Ce.loc[1]\nmax_rate_Ce = Cell_Phones_and_Accessories_df['overall'].max()\ntrust_Ce = (total_pos_Ce\/(total_pos_Ce+total_neg_Ce))*max_rate_Ce\nTrust_Values.append(trust_Ce.round(2))\n\ncount_score_Cl = Clothing_Shoes_and_Jewelry_df.groupby('Score').size()\ntotal_neg_Cl = count_score_Cl.loc[0]\ntotal_pos_Cl = count_score_Cl.loc[1]\nmax_rate_Cl = Clothing_Shoes_and_Jewelry_df['overall'].max()\ntrust_Cl = (total_pos_Cl\/(total_pos_Cl+total_neg_Cl))*max_rate_Cl\nTrust_Values.append(trust_Cl.round(2))\n\ncount_score_DM = Digital_Music_df.groupby('Score').size()\ntotal_neg_DM = count_score_DM.loc[0]\ntotal_pos_DM = count_score_DM.loc[1]\nmax_rate_DM = Digital_Music_df['overall'].max()\ntrust_DM = (total_pos_DM\/(total_pos_DM+total_neg_DM))*max_rate_DM\nTrust_Values.append(trust_DM.round(2))\n\ncount_score_E = Electronics_df.groupby('Score').size()\ntotal_neg_E = count_score_E.loc[0]\ntotal_pos_E = count_score_E.loc[1]\nmax_rate_E = Electronics_df['overall'].max()\ntrust_E = (total_pos_E\/(total_pos_E+total_neg_E))*max_rate_E\nTrust_Values.append(trust_E.round(2))\n\ncount_score_G = Grocery_and_Gourmet_Food_df.groupby('Score').size()\ntotal_neg_G = count_score_G.loc[0]\ntotal_pos_G = count_score_G.loc[1]\nmax_rate_G = Grocery_and_Gourmet_Food_df['overall'].max()\ntrust_G = (total_pos_G\/(total_pos_G+total_neg_G))*max_rate_G\nTrust_Values.append(trust_G.round(2))\n\ncount_score_H = Health_and_Personal_Care_df.groupby('Score').size()\ntotal_neg_H = count_score_H.loc[0]\ntotal_pos_H = count_score_H.loc[1]\nmax_rate_H = Health_and_Personal_Care_df['overall'].max()\ntrust_H = (total_pos_H\/(total_pos_H+total_neg_H))*max_rate_H\nTrust_Values.append(trust_H.round(2))\n\ncount_score_Ho = Home_and_Kitchen_df.groupby('Score').size()\ntotal_neg_Ho = count_score_Ho.loc[0]\ntotal_pos_Ho = count_score_Ho.loc[1]\nmax_rate_Ho = Home_and_Kitchen_df['overall'].max()\ntrust_Ho = (total_pos_Ho\/(total_pos_Ho+total_neg_Ho))*max_rate_Ho\nTrust_Values.append(trust_Ho.round(2))\n\ncount_score_K = Kindle_Store_df.groupby('Score').size()\ntotal_neg_K = count_score_K.loc[0]\ntotal_pos_K = count_score_K.loc[1]\nmax_rate_K = Kindle_Store_df['overall'].max()\ntrust_K = (total_pos_K\/(total_pos_K+total_neg_K))*max_rate_K\nTrust_Values.append(trust_K.round(2))\n\ncount_score_MI = Musical_Instruments_df.groupby('Score').size()\ntotal_neg_MI = count_score_MI.loc[0]\ntotal_pos_MI = count_score_MI.loc[1]\nmax_rate_MI = Musical_Instruments_df['overall'].max()\ntrust_MI = (total_pos_MI\/(total_pos_MI+total_neg_MI))*max_rate_MI\nTrust_Values.append(trust_MI.round(2))\n\ncount_score_OP = Office_Products_df.groupby('Score').size()\ntotal_neg_OP = count_score_OP.loc[0]\ntotal_pos_OP = count_score_OP.loc[1]\nmax_rate_OP = Office_Products_df['overall'].max()\ntrust_OP = (total_pos_OP\/(total_pos_OP+total_neg_OP))*max_rate_OP\nTrust_Values.append(trust_OP.round(2))\n\ncount_score_PL = Patio_Lawn_and_Garden_df.groupby('Score').size()\ntotal_neg_PL = count_score_PL.loc[0]\ntotal_pos_PL = count_score_PL.loc[1]\nmax_rate_PL = Patio_Lawn_and_Garden_df['overall'].max()\ntrust_PL = (total_pos_PL\/(total_pos_PL+total_neg_PL))*max_rate_PL\nTrust_Values.append(trust_PL.round(2))\n\ncount_score_Pe = Pet_Supplies_df.groupby('Score').size()\ntotal_neg_Pe = count_score_Pe.loc[0]\ntotal_pos_Pe = count_score_Pe.loc[1]\nmax_rate_Pe = Pet_Supplies_df['overall'].max()\ntrust_Pe = (total_pos_Pe\/(total_pos_Pe+total_neg_Pe))*max_rate_Pe\nTrust_Values.append(trust_Pe.round(2))\n\ncount_score_Sp = Sports_and_Outdoors_df.groupby('Score').size()\ntotal_neg_Sp = count_score_Sp.loc[0]\ntotal_pos_Sp = count_score_Sp.loc[1]\nmax_rate_Sp = Sports_and_Outdoors_df['overall'].max()\ntrust_Sp = (total_pos_Sp\/(total_pos_Sp+total_neg_Sp))*max_rate_Sp\nTrust_Values.append(trust_Sp.round(2))\n\ncount_score_TH = Tools_and_Home_Improvement_df.groupby('Score').size()\ntotal_neg_TH = count_score_TH.loc[0]\ntotal_pos_TH = count_score_TH.loc[1]\nmax_rate_TH = Tools_and_Home_Improvement_df['overall'].max()\ntrust_TH = (total_pos_TH\/(total_pos_TH+total_neg_TH))*max_rate_TH\nTrust_Values.append(trust_TH.round(2))\n\ncount_score_TG = Toys_and_Games_df.groupby('Score').size()\ntotal_neg_TG = count_score_TG.loc[0]\ntotal_pos_TG = count_score_TG.loc[1]\nmax_rate_TG = Toys_and_Games_df['overall'].max()\ntrust_TG = (total_pos_TG\/(total_pos_TG+total_neg_TG))*max_rate_TG\nTrust_Values.append(trust_TG.round(2))\n\ncount_score_VG = Video_Games_df.groupby('Score').size()\ntotal_neg_VG = count_score_VG.loc[0]\ntotal_pos_VG = count_score_VG.loc[1]\nmax_rate_VG = Video_Games_df['overall'].max()\ntrust_VG = (total_pos_VG\/(total_pos_VG+total_neg_VG))*max_rate_VG\nTrust_Values.append(trust_VG.round(2))","064a2068":"Category_Products = ['Amazon Instant Video','Apps for Android','Automotive','Baby','Beauty','CDs and Vinyl','Cell Phones and Accessories','Clothing, Shoes and Jewelry','Digital Music','Electronics','Grocery and Gourmet Food','Health and Personal Care','Home and Kitchen','Kindle Store','Musical Instruments','Office Products','Patio, Lawn and Garden','Pet Supplies','Sports and Outdoors','Tools and Home Improvement','Toys and Games','Video Games']\nprint(Category_Products,Trust_Values)","03778716":"Column = ['Category of Product','Vulue of Trust']\nComplete_dict = {'Category of Product': Category_Products,'Vulue of Trust':Trust_Values}\nComplete_df = pd.DataFrame(Complete_dict, columns=Column)","4c37ef44":"Complete_df","35f648fc":"import seaborn\nseaborn.set() \nfrom itertools import cycle, islice\nimport matplotlib.pylab as plt\n\ndf_class = Complete_df\ndf_class.index = Category_Products\ndf_class.plot(kind='bar', figsize=(13,5),title=\"Rating of each product's category\")\nplt.ylabel('Value of Trust',Fontsize = 13)\nplt.bar(range(len(df_class)), df_class['Vulue of Trust'], color=plt.cm.tab20b(np.arange(len(df_class))))\nx = range(len(df_class))\nfor a,b in zip(x, Trust_Values):\n    plt.text(a, b, str(b),ha='center', va='bottom',color= 'brown')\nplt.show()","12861413":"**Step3: Create a new Python file, and import the following packages.**","0e736b7d":"**Step7: Divide the data into training and testing datasets.**","a4f180bf":"**Step1: Import libaries.**","b3a6f650":"**Step10: The classifier object contains the most informative words that it obtained during analysis. These words basically have a strong say in what\u2019s classified as a positive or a negative review.**","b9dc3742":"**Step14: Create array of category's name and print them to check.**","82376470":"**Step9: Use a Naive Bayes classifier. Define the object and train it.**","77c37d37":"# Project 2: Sentiment Analysis\n\n#### **Parichart Meesin 6010017**","ca805b9d":"**Step4: Define a function to extract features.**","95deeba8":"**Step 18: Create bar graph to show the result.**","f71a3133":"**Step13: Calculate trust value of each category and put them into array.**","13ced280":"**Step12: Apply above function to each datasets.**","89638a48":"## **Summary:**\n\n**CDs and Vinyl have the most significant highest score among all other product's category of Amazon  and Automotive have lowest score among all other product's category of Amazon.**","b2da8e6d":"**Step8: Extract the features.**","272c54b3":"**Step15: Create data frame that contains Category's name and Trust value of each categories**","e8ff1144":"**Step11: Create function to analyze that reviews are positive or negative.**","e7c3e322":"**Step16: Print the above data frame(result).**","994212e0":"**Step2: Download data sources.**","c6acff71":"**Step6: Separate these into positive and negative reviews.**","efac9cb1":"**Step5: Training data for this(use movie reviews in NLTK).**"}}