{"cell_type":{"539f9daa":"code","85442d47":"code","1e97706c":"code","882556ab":"code","f950af88":"code","229b4f2c":"code","8696384a":"code","6a17bea1":"code","928aa1cc":"code","662c2910":"code","27012880":"code","591cd16a":"code","cf383a02":"code","67275f4c":"code","ded03394":"code","a98c36c2":"markdown","8028039d":"markdown","74573999":"markdown","aab3ce2f":"markdown","05742365":"markdown","e1e04db7":"markdown"},"source":{"539f9daa":"# Imports\nimport time, os\nfrom typing import Dict\nimport gc\nimport numpy as np\nimport pandas as pd\nfrom numba import njit\nimport janestreet\nfrom tempfile import gettempdir\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom prettytable import PrettyTable\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nfrom torch.utils.data import TensorDataset, Dataset\n\nimport seaborn as sns\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler, minmax_scale\nfrom sklearn.decomposition import PCA\nimport xgboost as xgb\nfrom sklearn.impute import SimpleImputer\n","85442d47":"cfg = {\n    'model_params': {\n        'model_architecture': 'nn',\n        'model_name': \"nn_output\",\n        'lr': 1e-3,\n        'weight_path': '',#'..\/input\/jane-street-neural-network-1200000\/nn_model_state_20000.pth',\n        'train': True,\n        'validate': False\n    },\n\n    'train_params': {\n        'max_num_steps': 10000,\n        'batch_size': 4096,\n    }\n}\n","1e97706c":"%%time\n\nprint('Loading...')\ntrain = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv')\nfeatures = [c for c in train.columns if 'feature' in c]\n\nprint('Filling...')\nf_mean = train[features[1:]].mean()\ntrain = train.loc[train.weight > 0].reset_index(drop = True)\ntrain[features[1:]] = train[features[1:]].fillna(f_mean)\ntrain['action'] = (train['resp'] > 0).astype('int')\n\nprint('Converting...')\nnp.save('f_mean.npy', f_mean.values)\n\nprint('Scaling...')\nscaler = StandardScaler()\nscaler.fit(train[features])\ntrain_featues_norm = scaler.transform(train[features])\n\nprint('Finish.')","882556ab":"class trainData(Dataset):\n    \n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n        return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\n\n","f950af88":"if cfg[\"model_params\"][\"train\"]:\n    train_target = torch.tensor(train['action'].values.astype(np.float32))\n    train_features = torch.tensor(train_featues_norm.astype(np.float32)) \n\n    train_data = trainData(train_features, train_target)\n    train_dataloader = DataLoader(dataset = train_data, batch_size = cfg[\"train_params\"][\"batch_size\"], shuffle = True)\n\n    print(len(train_dataloader))","229b4f2c":"def binary_acc(y_pred, y_test):\n    y_pred = torch.where(y_pred >= 0.5, 1, 0).int()\n    correct_results_sum = (y_pred == y_test).sum().float()\n    acc = correct_results_sum\/y_test.shape[0]\n    acc = torch.round(acc * 100)\n    \n    return acc","8696384a":"# define the MLP architecture\nclass JSMMLP(nn.Module):\n    def __init__(self):\n        super(JSMMLP, self).__init__()\n        self.fc1 = nn.Linear(130, 1000)\n        self.batchnorm1 = nn.BatchNorm1d(1000)\n        self.fc2 = nn.Linear(1000, 2000)\n        self.batchnorm2 = nn.BatchNorm1d(2000)\n        self.fc3 = nn.Linear(2000, 2000)\n        self.batchnorm3 = nn.BatchNorm1d(2000)\n        self.fc4 = nn.Linear(2000, 2000)\n        self.batchnorm4 = nn.BatchNorm1d(2000)\n        self.fc5 = nn.Linear(2000, 1000)\n        self.batchnorm5 = nn.BatchNorm1d(1000)\n        self.fc6 = nn.Linear(1000, 500)\n        self.batchnorm6 = nn.BatchNorm1d(500)\n        self.fc7 = nn.Linear(500, 100)\n        self.batchnorm7 = nn.BatchNorm1d(100)\n        self.fc_out = nn.Linear(100, 1)\n        self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.batchnorm1(x)\n        x = F.relu(self.fc2(x))\n        x = self.batchnorm2(x)\n        x = F.relu(self.fc3(x))\n        x = self.batchnorm3(x)\n        x = F.relu(self.fc4(x))\n        x = self.batchnorm4(x)\n        x = self.dropout(x)\n        x = F.relu(self.fc5(x))\n        x = self.batchnorm5(x)\n        x = self.dropout(x)\n        x = F.relu(self.fc6(x))\n        x = self.batchnorm6(x)\n        x = self.dropout(x)\n        x = F.relu(self.fc7(x))\n        x = self.batchnorm7(x)\n        x = self.dropout(x)\n        x = torch.sigmoid(self.fc_out(x))\n        return x","6a17bea1":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","928aa1cc":"#Instantiate model\nmodel = JSMMLP().to(device)\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=cfg[\"model_params\"][\"lr\"]) \n\n# load weight if there is a pretrained model\nweight_path = cfg[\"model_params\"][\"weight_path\"]\nif weight_path != '':\n    model_state = torch.load(weight_path, map_location=device)\n    model.load_state_dict(model_state['state_dict'])\n    optimizer.load_state_dict(model_state['optimizer'])\n    iteration = model_state['iteration']\nelse:\n    iteration = 0\n#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n#--scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n","662c2910":"if cfg[\"model_params\"][\"train\"]:\n    progress_bar = tqdm( range(iteration, iteration+cfg[\"train_params\"][\"max_num_steps\"]))\n    losses_train = []\n    acc_train = []\n    iterations = []\n    metrics = []\n    times = []\n    model_name = cfg[\"model_params\"][\"model_name\"]\n    start = time.time()\n\n    tr_it = iter(train_dataloader)\n    for i in progress_bar:\n        try:\n            x_data, y_data = next(tr_it)\n        except StopIteration:\n            tr_it = iter(train_dataloader)\n            x_data, y_data = next(tr_it)\n        \n\n        model.train()\n        torch.set_grad_enabled(True)\n\n        #Move data to device\n        inputs = x_data.to(device)\n        targets = y_data.to(device)\n        \n        #Forward model\n        output = model(inputs).view(targets.shape)\n  \n        loss = criterion(output, targets)\n        acc = binary_acc(output, targets)\n        \n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # step the scheduler\n        #--scheduler.step()\n\n        losses_train.append(loss.item())\n        acc_train.append(acc.item())\n\n        progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)} \\\n        | Acc: {acc.item()} Acc(avg): {np.mean(acc_train)}\")\n\n        if ((i != 0) and (i % 10000 == 0)):\n            iterations.append(i)\n            metrics.append(np.mean(losses_train))\n            times.append((time.time()-start)\/60)\n\n    results = pd.DataFrame({\"iterations\": iterations, 'metrics (avg)': metrics, 'elapsed time (min)': times})\n    results.to_csv(f'{model_name}_{cfg[\"train_params\"][\"max_num_steps\"]}.csv', index=False)\n    print(f\"Total training time is {(time.time()-start)\/60} mins\")\n    print(results.head())","27012880":"f_mean = np.load('..\/input\/jane-street-keras-model\/f_mean.npy')","591cd16a":"example_test = pd.read_csv('..\/input\/jane-street-market-prediction\/example_test.csv')\nexample_test = example_test.query('weight > 0').reset_index(drop = True)\nexample_test_features = example_test.loc[:, features].values\n\nif np.isnan(example_test_features[:,1:].sum()):\n    example_test_features[:,1:] = np.nan_to_num(example_test_features[:,1:]) + np.isnan(example_test_features[:,1:])*f_mean\n\n#Scaling\ntest_featues_norm = scaler.transform(example_test_features)\ntest_featues_norm = torch.tensor(test_featues_norm.astype(np.float32)).to(device)\n\nmodel.eval()\nwith torch.no_grad():\n    y_test_pred = model(test_featues_norm)\n    y_pred_tag = y_test_pred.cpu().numpy()\n\nprint(y_pred_tag.min())\nprint(y_pred_tag.max())\nprint(y_pred_tag.mean())\nprint(y_pred_tag.std())\n\nplt.hist(y_pred_tag, bins = 100)\nplt.show()","cf383a02":"@njit\ndef fast_fillna(array, values):\n    if np.isnan(array.sum()):\n        array = np.where(np.isnan(array), values, array)\n    return array\n\ntrain.loc[0, features[1:]] = fast_fillna(train.loc[0, features[1:]].values, 0)","67275f4c":"env = janestreet.make_env()\nenv_iter = env.iter_test()","ded03394":"\nfor (test_df, pred_df) in tqdm(env_iter):\n    if test_df['weight'].item() > 0:\n        test_features = test_df.loc[:, features].values\n        if np.isnan(test_features[:,1:].sum()):\n            test_features[:,1:] = np.nan_to_num(test_features[:,1:]) + np.isnan(test_features[:,1:])*f_mean\n            #test_features[0, :] = fast_fillna(test_features[0, :], f_mean)\n            \n        #Scaling\n        test_featues_norm = scaler.transform(test_features)\n        \n        model.eval()\n        with torch.no_grad():\n            y_test_pred = model(torch.tensor(test_featues_norm.astype(np.float32)).to(device))\n            y_test_pred = y_test_pred.cpu().numpy() \n            pred_df.action = np.where(y_test_pred >= 0.5, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","a98c36c2":"# Preprocessing","8028039d":"# Training","74573999":"# Submitting","aab3ce2f":"# Jane Street: Neural Network baseline","05742365":"# Example Test Prediction Analysis","e1e04db7":"# **Configuration**"}}