{"cell_type":{"0360e067":"code","dc7b8ab1":"code","4b667887":"code","70742dc8":"code","6c9d3ed5":"code","240c5d3f":"code","c5a6c6fd":"code","43f83b40":"code","06ab1178":"code","36818ec8":"code","a4790407":"code","98024b9f":"code","8b24a29e":"code","40f85a10":"code","59f5cd72":"code","650de7b1":"code","79ce6196":"code","732987c7":"code","c8d5dcfe":"code","45dab249":"markdown","24b64677":"markdown","e7723df2":"markdown","b33fe152":"markdown"},"source":{"0360e067":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom tqdm import tqdm\nimport time\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array","dc7b8ab1":"data_dir='..\/input\/highway-cctv-footage-images\/input_images\/'","4b667887":"labels = open('..\/input\/yolo-coco-data\/coco.names').read().strip().split('\\n')\nprint(labels)","70742dc8":"weights_path = '..\/input\/yolo-coco-data\/yolov3.weights'\nconfiguration_path = '..\/input\/yolo-coco-data\/yolov3.cfg'\nprobability_minimum = 0.5\nthreshold = 0.3","6c9d3ed5":"paths=[]\nfor item in os.listdir(data_dir):\n    paths+=[data_dir+item]","240c5d3f":"network = cv2.dnn.readNetFromDarknet(configuration_path, weights_path)\nlayers_names_all = network.getLayerNames()\nlayers_names_output = [layers_names_all[i[0]-1] for i in network.getUnconnectedOutLayers()]","c5a6c6fd":"image_input = cv2.imread(paths[30])\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10,10)\nplt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\nplt.show()","43f83b40":"blob = cv2.dnn.blobFromImage(image_input, 1\/255.0, (416,416), swapRB=True, crop=False)\nblob_to_show = blob[0,:,:,:].transpose(1,2,0)\nnetwork.setInput(blob)\noutput_from_network = network.forward(layers_names_output)\nnp.random.seed(42)\ncolours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')","06ab1178":"bounding_boxes = []\nconfidences = []\nclass_numbers = []\nh,w = image_input.shape[:2]\n\nfor result in output_from_network:\n    for detection in result:\n        scores = detection[5:]\n        class_current = np.argmax(scores)\n        confidence_current = scores[class_current]\n        if confidence_current > probability_minimum:\n            box_current = detection[0:4] * np.array([w, h, w, h])\n            x_center, y_center, box_width, box_height = box_current.astype('int')\n            x_min = int(x_center-(box_width\/2))\n            y_min = int(y_center-(box_height\/2))\n            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n            confidences.append(float(confidence_current))\n            class_numbers.append(class_current)\n\nprint(class_numbers[-1])                  \nprint(labels[class_numbers[-1]])            ","36818ec8":"results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n\nif len(results) > 0:\n    for i in results.flatten():\n        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n        colour_box_current = [int(j) for j in colours[class_numbers[i]]]\n        cv2.rectangle(image_input, (x_min, y_min), (x_min + box_width, y_min + box_height),\n                      colour_box_current, 5)\n        text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])], confidences[i])\n        cv2.putText(image_input, text_box_current, (x_min, y_min - 7), cv2.FONT_HERSHEY_SIMPLEX,\n                    1.5, colour_box_current, 5)","a4790407":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (10,10)\nplt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\nplt.show()","98024b9f":"def ImagePath(path):\n    \n    bounding_boxes = []\n    confidences = []\n    class_numbers = []\n    \n    image_input = cv2.imread(path)\n    blob = cv2.dnn.blobFromImage(image_input, 1\/255.0, (416,416), swapRB=True, crop=False)\n    blob_to_show = blob[0,:,:,:].transpose(1,2,0)\n    network.setInput(blob)\n    output_from_network = network.forward(layers_names_output)\n    h,w = image_input.shape[:2]\n\n    for result in output_from_network:\n        for detection in result:\n            scores = detection[5:]\n            class_current = np.argmax(scores)\n            confidence_current = scores[class_current]\n            if confidence_current > probability_minimum:\n                box_current = detection[0:4] * np.array([w, h, w, h])\n                x_center, y_center, box_width, box_height = box_current.astype('int')\n                x_min = int(x_center-(box_width\/2))\n                y_min = int(y_center-(box_height\/2))\n                bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n                confidences.append(float(confidence_current))\n                class_numbers.append(class_current)\n\n    %matplotlib inline\n    plt.rcParams['figure.figsize'] = (10,10)\n    plt.imshow(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))\n    plt.show()\n    \n    labels2=[]\n    for item in sorted(set(class_numbers)):\n        labels2+=[labels[item]]\n        \n    return labels2","8b24a29e":"ImagePath(paths[30])","40f85a10":"tobjects=[]\n\ndef ExtractImage(path, show=False):\n    \n    bounding_boxes = []\n    confidences = []\n    class_numbers = []\n\n    image_input = cv2.imread(path)\n    blob = cv2.dnn.blobFromImage(image_input, 1\/255.0, (416,416), swapRB=True, crop=False)\n    blob_to_show = blob[0,:,:,:].transpose(1,2,0)\n    network.setInput(blob)\n    output_from_network = network.forward(layers_names_output)\n    h,w = image_input.shape[:2]\n\n    for result in output_from_network:\n        for detection in result:\n            scores = detection[5:]\n            class_current = np.argmax(scores)\n            confidence_current = scores[class_current]\n            if confidence_current > probability_minimum:\n                box_current = detection[0:4] * np.array([w, h, w, h])\n                x_center, y_center, box_width, box_height = box_current.astype('int')\n                x_min = int(x_center-(box_width\/2))\n                y_min = int(y_center-(box_height\/2))\n                \n                if x_min<0:\n                    x_min=0\n                if y_min<0:\n                    y_min=0\n                \n                obj=image_input[int(y_min):int(y_min+box_height),int(x_min):int(x_min+box_width)]\n              \n                obj1 = Image.fromarray(np.uint8(obj))\n                obj2 = np.asarray(obj1.resize((32,32)))\/255.0 \n                tobjects.append(obj2)\n\n                if show:\n                    _ = plt.figure(figsize=(3,3))\n                    _ = plt.xticks([])\n                    _ = plt.yticks([])\n                    _ = plt.imshow(cv2.cvtColor(obj, cv2.COLOR_BGR2RGB))\n\n    return None","59f5cd72":"ExtractImage(paths[3],show=True)","650de7b1":"print(len(paths))","79ce6196":"for i in tqdm(range(98)):\n    ExtractImage(paths[i],show=False)","732987c7":"tobjects_ar=np.array(tobjects)\nprint(tobjects_ar.shape)\nnp.save('tobjects',tobjects_ar)","c8d5dcfe":"# loaded_ar=np.load('tobjects.npy')\n# print(loaded_ar.shape)","45dab249":"# Show images","24b64677":"# Set rectangle at detected area","e7723df2":"# Output detected object","b33fe152":"# Extract rectangle image"}}