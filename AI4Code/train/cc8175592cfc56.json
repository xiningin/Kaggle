{"cell_type":{"63a72b3a":"code","d6b90412":"code","14f2acfc":"code","2c676121":"code","c0a4dee7":"code","44bb046e":"code","a7f13743":"code","8df59fc6":"code","28b63fe0":"code","42ef72d4":"code","1099a4f0":"code","485ceead":"code","aeacc0ad":"code","73fa69b0":"code","bb4710f1":"code","40d05470":"code","0bf74f52":"markdown","77402ca0":"markdown"},"source":{"63a72b3a":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\n\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn import preprocessing\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nimport xgboost\nfrom xgboost import XGBClassifier\nfrom xgboost import XGBRegressor\n\n\n\ndef rmse(x,y):\n    rmse = np.sqrt(sklearn.metrics.mean_squared_error(x,y))\n    return(rmse)","d6b90412":"train = pd.read_csv('..\/input\/tabular-playground-series-feb-2021\/train.csv',index_col = 'id')\ntest = pd.read_csv('..\/input\/tabular-playground-series-feb-2021\/test.csv',index_col = 'id')","14f2acfc":"train.head()","2c676121":"# convert all the categorical variable to multiclass\nle = preprocessing.LabelEncoder()\nle.fit(train['cat9'])\n\ncat =  ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8','cat9']\n\nfor i in cat:\n    train[i] = le.transform(train[i].values)\n    \nfor i in cat:\n    test[i] = le.transform(test[i].values)\n","c0a4dee7":"train.head()","44bb046e":"# prepare datasets\nX = train.drop(columns=['target'])\n\ny = train.iloc[:,-1]","a7f13743":"#split among train and validation\nX_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.25, random_state=42)\n","8df59fc6":"# create a dictionary with the parameter used for tuning\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5,1.5, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8],\n        'learning_rate' : [0.02,0.1]\n        }","28b63fe0":"# initialize a regression random forest, specifying the number of trees, the objective function and the gpu\nxgb = XGBRegressor(n_estimators=800, objective='reg:squarederror',tree_method='gpu_hist')\n","42ef72d4":"# initialize the gridsearch specifying the random forest create before and the dictionary with the parameters\nclf = GridSearchCV(xgb,params, \n                    verbose=1)","1099a4f0":"# normal fit procedure, specifying the validation set\nclf.fit(X_train,y_train,eval_set=[(X_val,y_val)])\n","485ceead":"# using the specified (root mean square error)metric in order to evaluate the model\nrmse(clf.predict(X),y)","aeacc0ad":"#prediction = clf.predict(test)","73fa69b0":"submission = pd.read_csv('..\/input\/tabular-playground-series-feb-2021\/sample_submission.csv',index_col='id')","bb4710f1":"submission['target'] = prediction","40d05470":"submission.to_csv('submission.csv')","0bf74f52":"## xgboost","77402ca0":"## submission"}}