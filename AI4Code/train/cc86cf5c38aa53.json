{"cell_type":{"37da2e20":"code","f2f534e5":"code","00b7dfd9":"code","ca0b9c4b":"code","535fbb67":"code","1a23b62c":"code","0360f41a":"code","581537af":"code","3d29cf65":"code","2847c2ae":"code","c524142f":"code","3f0756ec":"code","d4b44d8d":"code","d6fe69f0":"code","3a1babfb":"markdown","e1962512":"markdown","41ef92e5":"markdown","6e104494":"markdown","e7b41962":"markdown","bbe00731":"markdown","2ebbbe82":"markdown","771f5b71":"markdown","e58d2cbb":"markdown","759eae7a":"markdown","27ae53ad":"markdown","fcb1c36f":"markdown"},"source":{"37da2e20":"%%capture\n\"\"\"\n!pip install pandarallel \n\nimport gc\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nfrom pandarallel import pandarallel\npandarallel.initialize()\n\nBASE_DIR = Path('..\/input\/mlb-player-digital-engagement-forecasting')\ntrain = pd.read_csv(BASE_DIR \/ 'train.csv')\n\nnull = np.nan\ntrue = True\nfalse = False\n\nfor col in train.columns:\n\n    if col == 'date': continue\n\n    _index = train[col].notnull()\n    train.loc[_index, col] = train.loc[_index, col].parallel_apply(lambda x: eval(x))\n\n    outputs = []\n    for index, date, record in train.loc[_index, ['date', col]].itertuples():\n        _df = pd.DataFrame(record)\n        _df['index'] = index\n        _df['date'] = date\n        outputs.append(_df)\n\n    outputs = pd.concat(outputs).reset_index(drop=True)\n\n    outputs.to_csv(f'{col}_train.csv', index=False)\n    outputs.to_pickle(f'{col}_train.pkl')\n\n    del outputs\n    del train[col]\n    gc.collect()\n\"\"\"","f2f534e5":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.metrics import mean_absolute_error\nfrom datetime import timedelta\nfrom functools import reduce\nfrom tqdm import tqdm\nimport lightgbm as lgbm\nimport mlb\nimport gc\n\npd.options.display.max_rows = 200\npd.options.display.max_columns = 100","00b7dfd9":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","ca0b9c4b":"BASE_DIR = Path('..\/input\/mlb-player-digital-engagement-forecasting')\nTRAIN_DIR = Path('..\/input\/mlb-pdef-train-dataset')","535fbb67":"targets_cols = [\n    'playerId', \n    'target1', \n    'target2', \n    'target3', \n    'target4', \n    'date'\n]\n\nplayers_cols = [\n    'playerId', \n    'primaryPositionName'\n]\n\nteams_cols = [\n    'id', \n#     'name', \n#     'teamName', \n#     'teamCode', \n#     'shortName', \n#     'abbreviation', \n#     'locationName', \n    'leagueId', \n#     'leagueName', \n    'divisionId', \n#     'divisionName', \n#     'venueId', \n#     'venueName'\n]\n\nrosters_cols = [\n    'playerId', \n    'teamId', \n    'status', \n    'date'\n]\n\nscores_cols = [\n    'playerId', \n    'battingOrder', \n    'gamesPlayedBatting', \n    'flyOuts',\n    'groundOuts', \n    'runsScored', \n    'doubles', \n    'triples', \n    'homeRuns',\n    'strikeOuts', \n    'baseOnBalls', \n    'intentionalWalks', \n    'hits', \n    'hitByPitch',\n    'atBats', \n    'caughtStealing', \n    'stolenBases', \n    'groundIntoDoublePlay',\n    'groundIntoTriplePlay', \n    'plateAppearances', \n    'totalBases', \n    'rbi',\n    'leftOnBase', \n    'sacBunts', \n    'sacFlies', \n    'catchersInterference',\n    'pickoffs', \n    'gamesPlayedPitching', \n    'gamesStartedPitching',\n    'completeGamesPitching', \n    'shutoutsPitching', \n    'winsPitching',\n    'lossesPitching', \n    'flyOutsPitching', \n    'airOutsPitching',\n    'groundOutsPitching', \n    'runsPitching', \n    'doublesPitching',\n    'triplesPitching', \n    'homeRunsPitching', \n    'strikeOutsPitching',\n    'baseOnBallsPitching', \n    'intentionalWalksPitching', \n    'hitsPitching',\n    'hitByPitchPitching', \n    'atBatsPitching', \n    'caughtStealingPitching',\n    'stolenBasesPitching', \n    'inningsPitched', \n    'saveOpportunities',\n    'earnedRuns', \n    'battersFaced', \n    'outsPitching', \n    'pitchesThrown', \n    'balls',\n    'strikes', \n    'hitBatsmen', \n    'balks', \n    'wildPitches', \n    'pickoffsPitching',\n    'rbiPitching', \n    'gamesFinishedPitching', \n    'inheritedRunners',\n    'inheritedRunnersScored', \n    'catchersInterferencePitching',\n    'sacBuntsPitching', \n    'sacFliesPitching', \n    'saves', \n    'holds', \n    'blownSaves',\n    'assists', \n    'putOuts', \n    'errors', \n    'chances', \n    'date'\n]\n\nawards_cols = [\n    'date', \n    'playerId',\n    'awardId'\n]\n\nplayerTwitterFollowers_cols = [\n    'playerId', \n    'numberOfFollowers'\n]\n\nteamTwitterFollowers_cols = [\n    'teamId', \n    'numberOfFollowers'\n]\n\nstandings_cols = [\n    'teamId', \n#     'wildCardRank', \n    'wins', \n    'losses', \n#     'divisionChamp', \n#     'divisionLeader', \n#     'wildCardLeader', \n    'lastTenWins',\n    'lastTenLosses',\n    'date'\n]\n\nfeature_cols = [\n    'label_playerId', \n    'label_primaryPositionName', \n    'label_teamId',\n    'label_status',\n    'playerId', \n    'battingOrder', \n    'gamesPlayedBatting', \n    'flyOuts',\n    'groundOuts', \n    'runsScored', \n    'doubles', \n    'triples', \n    'homeRuns',\n    'strikeOuts', \n    'baseOnBalls', \n    'intentionalWalks', \n    'hits', \n    'hitByPitch',\n    'atBats', \n    'caughtStealing', \n    'stolenBases', \n    'groundIntoDoublePlay',\n    'groundIntoTriplePlay', \n    'plateAppearances', \n    'totalBases', \n    'rbi',\n    'leftOnBase', \n    'sacBunts', \n    'sacFlies', \n    'catchersInterference',\n    'pickoffs', \n    'gamesPlayedPitching', \n    'gamesStartedPitching',\n    'completeGamesPitching', \n    'shutoutsPitching', \n    'winsPitching',\n    'lossesPitching', \n    'flyOutsPitching', \n    'airOutsPitching',\n    'groundOutsPitching', \n    'runsPitching', \n    'doublesPitching',\n    'triplesPitching', \n    'homeRunsPitching', \n    'strikeOutsPitching',\n    'baseOnBallsPitching', \n    'intentionalWalksPitching', \n    'hitsPitching',\n    'hitByPitchPitching', \n    'atBatsPitching', \n    'caughtStealingPitching',\n    'stolenBasesPitching', \n    'inningsPitched', \n    'saveOpportunities',\n    'earnedRuns', \n    'battersFaced', \n    'outsPitching', \n    'pitchesThrown', \n    'balls',\n    'strikes', \n    'hitBatsmen', \n    'balks', \n    'wildPitches', \n    'pickoffsPitching',\n    'rbiPitching', \n    'gamesFinishedPitching', \n    'inheritedRunners',\n    'inheritedRunnersScored', \n    'catchersInterferencePitching',\n    'sacBuntsPitching', \n    'sacFliesPitching', \n    'saves', \n    'holds', \n    'blownSaves',\n    'assists', \n    'putOuts', \n    'errors', \n    'chances', \n    'target1_mean',\n    'target1_median',\n    'target1_std',\n    'target1_min',\n    'target1_max',\n    'target1_prob',\n    'target2_mean',\n    'target2_median',\n    'target2_std',\n    'target2_min',\n    'target2_max',\n    'target2_prob',\n    'target3_mean',\n    'target3_median',\n    'target3_std',\n    'target3_min',\n    'target3_max',\n    'target3_prob',\n    'target4_mean',\n    'target4_median',\n    'target4_std',\n    'target4_min',\n    'target4_max',\n    'target4_prob',\n    'awardId_count',\n    'playernumberOfFollowers',               \n    'teamnumberOfFollowers',\n    'label_leagueId',\n    'label_divisionId',\n    'wins', \n    'losses', \n    'lastTenWins',\n    'lastTenLosses'\n]","1a23b62c":"players = pd.read_csv(BASE_DIR \/ 'players.csv', usecols = players_cols)\nplayers = reduce_mem_usage(players)\n\n\nteams = pd.read_csv(BASE_DIR \/ 'teams.csv', usecols = teams_cols)\nteams = teams.rename(columns = {'id':'teamId'})\nteams = reduce_mem_usage(teams)\n\n\nrosters = pd.read_csv(TRAIN_DIR \/ 'rosters_train.csv', usecols = rosters_cols)\nrosters = reduce_mem_usage(rosters)\n\n\ntargets = pd.read_csv(TRAIN_DIR \/ 'nextDayPlayerEngagement_train.csv', usecols = targets_cols)\ntargets = reduce_mem_usage(targets)\n\n\nscores = pd.read_csv(TRAIN_DIR \/ 'playerBoxScores_train.csv', usecols = scores_cols)\nscores = scores.groupby(['playerId', 'date']).sum().reset_index()\nscores = reduce_mem_usage(scores)\n\n\nawards = pd.read_csv(TRAIN_DIR \/ 'awards_train.csv', usecols = awards_cols)\n# awards = awards.groupby(['playerId', 'date']).count().reset_index()\n\n\nawards_count = awards[['playerId', 'awardId']].groupby('playerId').count().reset_index()\nawards_count = awards_count.rename(columns = {'awardId':'awardId_count'})\nawards_count = reduce_mem_usage(awards_count)\n\n\nplayerTwitterFollowers = pd.read_csv(TRAIN_DIR \/ 'playerTwitterFollowers_train.csv', usecols = playerTwitterFollowers_cols)\nplayerTwitterFollowers = playerTwitterFollowers.groupby('playerId').sum().reset_index()\nplayerTwitterFollowers = playerTwitterFollowers.rename(columns = {'numberOfFollowers':'playernumberOfFollowers'})\nplayerTwitterFollowers = reduce_mem_usage(playerTwitterFollowers)\n\n\nteamTwitterFollowers = pd.read_csv(TRAIN_DIR \/ 'teamTwitterFollowers_train.csv', usecols = teamTwitterFollowers_cols)\nteamTwitterFollowers = teamTwitterFollowers.groupby('teamId').sum().reset_index()\nteamTwitterFollowers = teamTwitterFollowers.rename(columns = {'numberOfFollowers':'teamnumberOfFollowers'})\nteamTwitterFollowers = reduce_mem_usage(teamTwitterFollowers)\n\n\nstandings = pd.read_csv(TRAIN_DIR \/ 'standings_train.csv', usecols = standings_cols)\nstandings = reduce_mem_usage(standings)\n\ngc.collect()","0360f41a":"player_target_stats = pd.read_csv(\"..\/input\/player-target-stats\/player_target_stats.csv\")\ndata_names=player_target_stats.columns.values.tolist()\ndata_names","581537af":"# creat dataset\n\ntrain = targets.copy()[targets_cols]\n\nprint(targets[targets_cols].shape)\n\ntrain = train.merge(\n    players, \n    on=['playerId'], \n    how='left'\n)\ngc.collect()\n\nprint(train.shape, 'after_players')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    rosters, \n    on=['playerId', 'date'], \n    how='left'\n)\ngc.collect()\n\nprint(train.shape, 'after_rosters')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    scores, \n    on=['playerId', 'date'], \n    how='left'\n)\ngc.collect()\n\nprint(train.shape, 'after_scores')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    player_target_stats, \n    how='inner', \n    on= \"playerId\",\n)\ngc.collect()\n\nprint(train.shape, 'after_player_target_stats')\n\n\nprint('--------------------------------------')\n\ntrain = train.merge(\n    teams,\n    on = 'teamId',\n    how='left'\n)\n# del rosters\ngc.collect()\n\nprint(train.shape, 'after_teams')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    awards_count,\n    on = 'playerId',\n    how = 'left'\n)\n\ntrain['awardId_count'] = train['awardId_count'].fillna(0)\n\nprint(train.shape, 'after_awards_count')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    playerTwitterFollowers, \n    how = 'left', \n    on = 'playerId'\n)\ngc.collect()\n\nprint(train.shape, 'after_playerTwitter')\nprint('--------------------------------------')\n\n\ntrain = train.merge(\n    teamTwitterFollowers, \n    how = 'left', \n    on = 'teamId'\n)\ngc.collect()\n\nprint(train.shape, 'after_taemTwitter')\nprint('--------------------------------------')\n\ntrain = train.merge(\n    standings, \n    how = 'left', \n    on = ['teamId', 'date']\n)\ngc.collect()\n\nprint(train.shape, 'after_standings')\nprint('--------------------------------------')\n\n\n# label encoding\nplayer2num = {c: i for i, c in enumerate(train['playerId'].unique())}\nposition2num = {c: i for i, c in enumerate(train['primaryPositionName'].unique())}\nteamid2num = {c: i for i, c in enumerate(train['teamId'].unique())}\nstatus2num = {c: i for i, c in enumerate(train['status'].unique())}\nleagueId2num = {c: i for i, c in enumerate(train['leagueId'].unique())}\ndivisionId2num = {c: i for i, c in enumerate(train['divisionId'].unique())}\n\n\ntrain['label_playerId'] = train['playerId'].map(player2num)\ntrain['label_primaryPositionName'] = train['primaryPositionName'].map(position2num)\ntrain['label_teamId'] = train['teamId'].map(teamid2num)\ntrain['label_status'] = train['status'].map(status2num)\ntrain['label_leagueId'] = train['leagueId'].map(leagueId2num)\ntrain['label_divisionId'] = train['divisionId'].map(divisionId2num)","3d29cf65":"train.info()","2847c2ae":"print(train.shape)\ntrain.isnull().sum()","c524142f":"train_X = train[feature_cols]\ntrain_y = train[['target1', 'target2', 'target3', 'target4']]\n\n_index = (train['date'] < 20210401)\nx_train = train_X.loc[_index].reset_index(drop=True)\ny_train = train_y.loc[_index].reset_index(drop=True)\nx_valid = train_X.loc[~_index].reset_index(drop=True)\ny_valid = train_y.loc[~_index].reset_index(drop=True)","3f0756ec":"def fit_lgbm(x_train, y_train, x_valid, y_valid, params: dict=None, verbose=100):\n    oof_pred = np.zeros(len(y_valid), dtype=np.float32)\n    model = lgbm.LGBMRegressor(**params)\n    model.fit(x_train, y_train, \n        eval_set=[(x_valid, y_valid)],  \n        early_stopping_rounds=verbose, \n        verbose=verbose)\n    oof_pred = model.predict(x_valid)\n    score = mean_absolute_error(oof_pred, y_valid)\n    print('mae:', score)\n    return oof_pred, model, score\n\n\"\"\"\n# training lightgbm before param\nparams = {\n 'objective':'mae',\n 'reg_alpha': 0.1,\n 'reg_lambda': 0.1, \n 'n_estimators': 100000,\n 'learning_rate': 0.1,\n 'random_state': 42,\n}\n\"\"\"\n\nparams1 = {'objective': 'mae', 'metric': 'l1', 'feature_pre_filter': False, 'lambda_l1': 3.485822021802935e-08, 'lambda_l2': 4.230468117096112e-06, 'num_leaves': 253, 'feature_fraction': 0.8, 'bagging_fraction': 0.550250698524785, 'bagging_freq': 1, 'min_child_samples': 20, 'num_iterations': 10000, 'early_stopping_round': 100}\n\nparams2 = {'objective': 'mae', 'metric': 'l1', 'feature_pre_filter': False, 'lambda_l1': 3.731605225849285, 'lambda_l2': 0.02803980626777797, 'num_leaves': 8, 'feature_fraction': 0.5, 'bagging_fraction': 0.5262728428461787, 'bagging_freq': 3, 'min_child_samples': 20, 'num_iterations': 10000, 'early_stopping_round': 100}\n\nparams3 = {'objective': 'mae', 'metric': 'l1', 'feature_pre_filter': False, 'lambda_l1': 7.654830305013684, 'lambda_l2': 4.14748542765967e-07, 'num_leaves': 252, 'feature_fraction': 0.7200000000000001, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'min_child_samples': 20, 'num_iterations': 10000, 'early_stopping_round': 100}\n\nparams4 = {'objective': 'mae', 'metric': 'l1', 'feature_pre_filter': False, 'lambda_l1': 9.486880706514734e-08, 'lambda_l2': 0.005143767850872896, 'num_leaves': 246, 'feature_fraction': 0.5479999999999999, 'bagging_fraction': 0.5238463354446826, 'bagging_freq': 5, 'min_child_samples': 20, 'num_iterations': 10000, 'early_stopping_round': 100}\n\n\n\noof1, model1, score1 = fit_lgbm(\n    x_train, y_train['target1'],\n    x_valid, y_valid['target1'],\n    params1\n)\noof2, model2, score2 = fit_lgbm(\n    x_train, y_train['target2'],\n    x_valid, y_valid['target2'],\n    params2\n)\noof3, model3, score3 = fit_lgbm(\n    x_train, y_train['target3'],\n    x_valid, y_valid['target3'],\n    params3\n)\noof4, model4, score4 = fit_lgbm(\n    x_train, y_train['target4'],\n    x_valid, y_valid['target4'],\n    params4\n)\n\nscore = (score1+score2+score3+score4) \/ 4\nprint(f'score: {score}')","d4b44d8d":"rosters_cols.remove('date')\nscores_cols.remove('date')\nstandings_cols = [\n    'teamId', \n    'wins', \n    'losses', \n    'lastTenWins',\n    'lastTenLosses'\n]\n\nnull = np.nan\ntrue = True\nfalse = False\n\nenv = mlb.make_env() # initialize the environment\niter_test = env.iter_test() # iterator which loops over each date in test set\n\nfor (test_df, sample_prediction_df) in iter_test: # make predictions here\n    \n    sample_prediction_df = sample_prediction_df.reset_index(drop=True)\n    \n    # creat dataset\n    sample_prediction_df['playerId'] = sample_prediction_df['date_playerId']\\\n                                        .map(lambda x: int(x.split('_')[1]))\n    # Dealing with missing values\n    if test_df['rosters'].iloc[0] == test_df['rosters'].iloc[0]:\n        test_rosters = pd.DataFrame(eval(test_df['rosters'].iloc[0]))\n    else:\n        test_rosters = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in rosters.columns:\n            if col == 'playerId': continue\n            test_rosters[col] = np.nan\n            \n    if test_df['playerBoxScores'].iloc[0] == test_df['playerBoxScores'].iloc[0]:\n        test_scores = pd.DataFrame(eval(test_df['playerBoxScores'].iloc[0]))\n    else:\n        test_scores = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in scores.columns:\n            if col == 'playerId': continue\n            test_scores[col] = np.nan\n            \n    if test_df['standings'].iloc[0] == test_df['standings'].iloc[0]:\n        test_standings = pd.DataFrame(eval(test_df['standings'].iloc[0]))\n    else:\n        test_standings = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in standings.columns:\n            if col == 'playerId': continue\n            test_scores[col] = np.nan\n            \n            \n    test_scores = test_scores.groupby('playerId').sum().reset_index()\n    test = sample_prediction_df[['playerId']].copy()\n    test = test.merge(players[players_cols], on='playerId', how='left')\n    test = test.merge(test_rosters[rosters_cols], on='playerId', how='left')\n    test = test.merge(test_scores[scores_cols], on='playerId', how='left')\n    test = test.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n    test = test.merge(awards_count, how = 'left', on = 'playerId')\n    test = test.merge(teams, how = 'left', on = 'teamId')\n    test['awardId_count'] = test['awardId_count'].fillna(0)\n    test = test.merge(playerTwitterFollowers, how = 'left', on ='playerId')\n    test = test.merge(teamTwitterFollowers, how = 'left', on ='teamId')\n    test = test.merge(test_standings[standings_cols], how = 'left', on = 'teamId')\n\n    \n\n    test['label_playerId'] = test['playerId'].map(player2num)\n    test['label_primaryPositionName'] = test['primaryPositionName'].map(position2num)\n    test['label_teamId'] = test['teamId'].map(teamid2num)\n    test['label_status'] = test['status'].map(status2num)\n    test['label_leagueId'] = test['leagueId'].map(leagueId2num)\n    test['label_divisionId'] = test['divisionId'].map(divisionId2num)\n    \n    test_X = test[feature_cols]\n    \n    # predict\n    pred1 = model1.predict(test_X)\n    pred2 = model2.predict(test_X)\n    pred3 = model3.predict(test_X)\n    pred4 = model4.predict(test_X)\n    \n    # merge submission\n    sample_prediction_df['target1'] = np.clip(pred1, 0, 100)\n    sample_prediction_df['target2'] = np.clip(pred2, 0, 100)\n    sample_prediction_df['target3'] = np.clip(pred3, 0, 100)\n    sample_prediction_df['target4'] = np.clip(pred4, 0, 100)\n    sample_prediction_df = sample_prediction_df.fillna(0.)\n    del sample_prediction_df['playerId']\n    \n    env.predict(sample_prediction_df)","d6fe69f0":"sample_prediction_df","3a1babfb":"Credit to @columbia2131 - I started with his notebook and then added an external data set with descriptive statistics of the targets for each player.","e1962512":"## Training","41ef92e5":"Train.csv is stored as a csv file with each column as follows.  \ntrain.csv\u3092\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3057\u3066\u5404\u30ab\u30e9\u30e0\u3092csv\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u7ba1\u3057\u3066\u3044\u307e\u3059\u3002\n\nTo use many data, I used fruction of \"reduce_mem_usage\" to reduce CPU load.\nCPU\u8ca0\u8377\u3092\u6291\u3048\u308b\u305f\u3081\u306breduce_mem_usage\u3068\u3044\u3046\u95a2\u6570\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002\n\nParams are tuned by Light GBM tuner. \n\u30d1\u30e9\u30e1\u30fc\u30bf\u306fLight GBM tuner\u3067\u8abf\u6574\u3057\u3066\u3044\u307e\u3059\u3002\n\nI want to continue feature engineering, because there are other features not used.\n\u7279\u5fb4\u91cf\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0\u3092\u7d9a\u3051\u305f\u3044\u3001\u307e\u3060\u4f7f\u3063\u3066\u3044\u306a\u3044\u7279\u5fb4\u91cf\u304c\u3042\u308b\u305f\u3081\u3002","6e104494":"## Make train data","e7b41962":"import optuna.integration.lightgbm as lgbm\n\ndef fit_lgbm(x_train, y_train, x_valid, y_valid, params: dict=None, verbose=100):\n        \n    oof_pred = np.zeros(len(y_valid), dtype=np.float32)    \n    \n    trains = lgbm.Dataset(x_train, y_train)\n    valids = lgbm.Dataset(x_valid, y_valid)\n    \n    model = lgbm.train(\n        params, \n        trains,\n        valid_sets = valids,\n        num_boost_round = 10000,\n        verbose_eval = False,\n        early_stopping_rounds = 100\n    )\n    \n    best_params = model.params\n    \n    oof_pred = model.predict(x_valid)\n    score = mean_absolute_error(oof_pred, y_valid)\n    print('mae:', score)\n    return oof_pred, model, score, best_params\n    \nparams = {\n    'objective':'mae',\n    'metric':'mae'\n}\n\n\n\noof4, model4, score4, best_params4 = fit_lgbm(\n        x_train, y_train['target4'],\n        x_valid, y_valid['target4'],\n        params\n)\n\nprint(best_params4)","bbe00731":"## About Dataset","2ebbbe82":"## Fruction to reduce CPU load","771f5b71":"## Read data and groupby","e58d2cbb":"## Select columns","759eae7a":"## Divide train and valid data","27ae53ad":"## Predict","fcb1c36f":"## Example for tuning"}}