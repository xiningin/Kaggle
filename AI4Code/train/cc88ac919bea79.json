{"cell_type":{"f9d77dea":"code","3897cd5d":"code","afc6e8e1":"code","848003b6":"code","0f532932":"code","9dbe78cd":"code","dadcb88a":"code","dd4ea986":"code","1c38f84e":"code","c1e5a39b":"code","b27689b2":"code","366c9055":"code","1393a600":"code","7e3d3a01":"code","755a53dd":"code","43851e3b":"code","a040a0b3":"code","de42822c":"code","94a42ed7":"code","0152fe8c":"code","8aecf5bf":"code","54a6afff":"code","7ad44a94":"code","bc8134e8":"code","529dedf5":"code","46b1eb5c":"code","8956f5ae":"code","425fcfe8":"code","e1cb2b9e":"code","e7f0494e":"code","b6ffa95c":"code","c5f54975":"code","d0de4c28":"code","4db6196d":"code","bf1017a3":"code","58f03ff9":"code","964158a4":"code","9aeb01e1":"code","a1f05f8f":"code","0dcff722":"code","4153c98f":"code","9e5b10e8":"code","cac7aafa":"code","2e68e1e6":"code","cfb0f302":"code","a434acf6":"markdown","31b9ab61":"markdown","04cdec50":"markdown","7ba9b1e0":"markdown","d1a8ddb8":"markdown","32962341":"markdown","d0c24e32":"markdown","80e96fa8":"markdown"},"source":{"f9d77dea":"%%html\n<marquee style='width: 100%; color: red;'><H1>SKIN_CANCER<\/H1><\/marquee>","3897cd5d":"# Regular Imports\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.image as mpimg\nfrom tabulate import tabulate\nimport missingno as msno \nfrom IPython.display import display_html\nfrom PIL import Image\nimport gc\nimport cv2\n\nimport pydicom # for DICOM images\nfrom skimage.transform import resize\n\n# SKLearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# Set Style\nsns.set(style=\"darkgrid\")\nsns.despine(left=True, bottom=True)\n\n","afc6e8e1":"list(os.listdir('..\/input\/siim-isic-melanoma-classification'))","848003b6":"# Directory\ndirectory = '..\/input\/siim-isic-melanoma-classification'\n\n# Import the 2 csv s\ntrain_df = pd.read_csv(directory + '\/train.csv')\ntest_df = pd.read_csv(directory + '\/test.csv')\n\nprint('Train has {:,} rows and Test has {:,} rows.'.format(len(train_df), len(test_df)))\n\n# Change columns names\nnew_names = ['dcm_name', 'ID', 'sex', 'age', 'anatomy', 'diagnosis', 'benign_malignant', 'target']\ntrain_df.columns = new_names\ntest_df.columns = new_names[:5]","0f532932":"print(train_df)","9dbe78cd":"print(test_df)","dadcb88a":"train_df.head()","dd4ea986":"test_df.head()","1c38f84e":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\nsns.countplot(ax=ax1, x=\"anatomy\", data=train_df)\nax1.set_title(\"distribution de anatomy  dans  training data\")\nsns.countplot(ax=ax2, x=\"anatomy\", data=test_df)\nax2.set_title(\"distribution de anatomy dans test data\")\nplt.show()","c1e5a39b":"plt.figure(figsize=(16, 6))\na = sns.countplot(data=train_df, x='benign_malignant', hue='anatomy')\n\nfor p in a.patches:\n    a.annotate(format(p.get_height(), ','), \n           (p.get_x() + p.get_width() \/ 2., \n            p.get_height()), ha = 'center', va = 'center', \n           xytext = (0, 4), textcoords = 'offset points')\n\nplt.title('distribution de Anatomy par Target', fontsize=16)\nsns.despine(left=True, bottom=True);","b27689b2":"f, (ax1, ax2) = plt.subplots(1, 2, figsize = (16, 6))\n\na = sns.countplot(train_df['anatomy'], ax=ax1)\nb = sns.countplot(train_df['diagnosis'], ax=ax2)\n\na.set_xticklabels(a.get_xticklabels(), rotation=35, ha=\"right\")\nb.set_xticklabels(b.get_xticklabels(), rotation=35, ha=\"right\")\n\nfor p in a.patches:\n    a.annotate(format(p.get_height(), ','), \n           (p.get_x() + p.get_width() \/ 2., \n            p.get_height()), ha = 'center', va = 'center', \n           xytext = (0, 4), textcoords = 'offset points')\n    \nfor p in b.patches:\n    b.annotate(format(p.get_height(), ','), \n           (p.get_x() + p.get_width() \/ 2., \n            p.get_height()), ha = 'center', va = 'center', \n           xytext = (0, 4), textcoords = 'offset points')\n    \nax1.set_title('Les fr\u00e9quences de Anatomy', fontsize=16)\nax2.set_title('Les fr\u00e9quences de Diagnosis', fontsize=16)\nsns.despine(left=True, bottom=True);","366c9055":"fig, (ax1) = plt.subplots(1,1, figsize=(20,5))\nsns.countplot(ax=ax1, x=\"benign_malignant\", data=train_df)\nax1.set_title(\"distribution de benign_malignant  dans  training data\")\nplt.show()","1393a600":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\nsns.countplot(ax=ax1, x=\"sex\", data=train_df)\nax1.set_title(\"distribution de sex  dans  training data\")\nsns.countplot(ax=ax2, x=\"sex\", data=test_df)\nax2.set_title(\"distribution de sex dans test data\")\nplt.show()","7e3d3a01":"plt.figure(figsize=(16, 6))\na = sns.countplot(data=train_df, x='benign_malignant', hue='sex')\n\nfor p in a.patches:\n    a.annotate(format(p.get_height(), ','), \n           (p.get_x() + p.get_width() \/ 2., \n            p.get_height()), ha = 'center', va = 'center', \n           xytext = (0, 4), textcoords = 'offset points')\n\nplt.title('distribution de sex par target', fontsize=16)\nsns.despine(left=True, bottom=True);","755a53dd":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,5))\nsns.countplot(ax=ax1, x=\"age\", data=train_df)\nax1.set_title(\"distribution d'age  dans  training data\")\nsns.countplot(ax=ax2, x=\"age\", data=test_df)\nax2.set_title(\"distribution d'age dans test data\")\nplt.show()","43851e3b":"fig, (ax1) = plt.subplots(1,1, figsize=(20,5))\nsns.countplot(ax=ax1, x=\"target\", data=train_df)\nax1.set_title(\"distribution d'age  dans  training data\")\nplt.show()","a040a0b3":"f, (ax1, ax2) = plt.subplots(1, 2, figsize = (16, 6))\n\na = sns.countplot(train_df[train_df['target']==0]['diagnosis'], ax=ax1)\nb = sns.countplot(train_df[train_df['target']==1]['diagnosis'], ax=ax2)\n\na.set_xticklabels(a.get_xticklabels(), rotation=35, ha=\"right\")\nb.set_xticklabels(b.get_xticklabels(), rotation=35, ha=\"right\")\n\nfor p in a.patches:\n    a.annotate(format(p.get_height(), ','), \n           (p.get_x() + p.get_width() \/ 2., \n            p.get_height()), ha = 'center', va = 'center', \n           xytext = (0, 4), textcoords = 'offset points')\n    \nfor p in b.patches:\n    b.annotate(format(p.get_height(), ','), \n           (p.get_x() + p.get_width() \/ 2., \n            p.get_height()), ha = 'center', va = 'center', \n           xytext = (0, 4), textcoords = 'offset points')\n    \nax1.set_title('Cas b\u00e9nins: vue de diagnostic', fontsize=16)\nax2.set_title('Cas malins: vue de diagnostic', fontsize=16)\nsns.despine(left=True, bottom=True);","de42822c":"colors_nude = ['#e0798c','#65365a','#da8886','#cfc4c4','#dfd7ca']\npatients_count_train = train_df.groupby(by='ID')['dcm_name'].count().reset_index()\npatients_count_test = test_df.groupby(by='ID')['dcm_name'].count().reset_index()\n\n# Figure\nf, (ax1, ax2) = plt.subplots(1, 2, figsize = (16, 6))\n\na = sns.distplot(patients_count_train['dcm_name'], kde=False, bins=50, \n                 ax=ax1, color=colors_nude[0], hist_kws={'alpha': 1})\nb = sns.distplot(patients_count_test['dcm_name'], kde=False, bins=50, \n                 ax=ax2, color=colors_nude[1], hist_kws={'alpha': 1})\n    \nax1.set_title('Train: Images per Patient Distribution', fontsize=16)\nax2.set_title('Test: Images per Patient Distribution', fontsize=16)\nsns.despine(left=True, bottom=True);\n","94a42ed7":"# Create the paths\npath_train = directory + '\/train\/' + train_df['dcm_name'] + '.dcm'\npath_test = directory + '\/test\/' + test_df['dcm_name'] + '.dcm'\n\n# Append to the original dataframes\ntrain_df['path_dicom'] = path_train\ntest_df['path_dicom'] = path_test\n\n# === JPEG ===\n# Create the paths\npath_train = directory + '\/jpeg\/train\/' + train_df['dcm_name'] + '.jpg'\npath_test = directory + '\/jpeg\/test\/' + test_df['dcm_name'] + '.jpg'\n\n# Append to the original dataframes\ntrain_df['path_jpeg'] = path_train\ntest_df['path_jpeg'] = path_test","0152fe8c":"fig, ax = plt.subplots()\nax.imshow(image)\nax.axis('off')","8aecf5bf":" plt.subplots(nrows=1, ncols=1, figsize=(16,6))","54a6afff":"data = pydicom.read_file(train_df['path_dicom'][0])\nimage = data.pixel_array\nfig, ax = plt.subplots(figsize=(16,16))\nimage = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\nimage = cv2.resize(image, (512,512))\n#image=cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0) ,256\/10), -4, 128)\nax.imshow(image, cmap=plt.cm.bone,) \nax.axis('off')","7ad44a94":"data = pydicom.read_file(train_df['path_dicom'][1])\nimage = data.pixel_array\nfig, ax = plt.subplots(figsize=(16,16))\n#image = cv2.cvtColor(image)\nimage = cv2.resize(image, (512,512))\n#image=cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0) ,256\/10), -4, 128)\nax.imshow(image, cmap=plt.cm.bone,) \nax.axis('off')","bc8134e8":"data = pydicom.read_file(train_df['path_dicom'][2])\nimage = data.pixel_array\nfig, ax = plt.subplots(figsize=(16,16))\nimage = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\nimage = cv2.resize(image, (512,512))\nax.imshow(image, cmap=plt.cm.bone,) \nax.axis('off')","529dedf5":"data = pydicom.read_file(train_df['path_dicom'][3])\nimage = data.pixel_array\nfig, ax = plt.subplots(figsize=(16,16))\nimage = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\nimage = cv2.resize(image, (512,512))\n#image=cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0) ,256\/10), -4, 128)\nax.imshow(image, cmap=plt.cm.bone,) \nax.axis('off')","46b1eb5c":"data = pydicom.read_file(train_df['path_dicom'][4])\nimage = data.pixel_array\nfig, ax = plt.subplots(figsize=(16,16))\nimage = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\nimage = cv2.resize(image, (512,512))\n#image=cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0) ,256\/10), -4, 128)\nax.imshow(image, cmap=plt.cm.bone,) \nax.axis('off')","8956f5ae":"data = pydicom.read_file(train_df['path_dicom'][5])\nimage = data.pixel_array\nfig, ax = plt.subplots(figsize=(16,16))\nimage = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\nimage = cv2.resize(image, (512,512))\n#image=cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0) ,256\/10), -4, 128)\nax.imshow(image, cmap=plt.cm.bone,) \nax.axis('off')","425fcfe8":"def show_images(data, n = 5, rows=1, cols=6, title='Default'):\n    plt.figure(figsize=(16,4))\n\n    for k, path in enumerate(data['path_dicom'][:n]):\n        image = pydicom.read_file(path)\n        image = image.pixel_array\n        \n        # image = resize(image, (200, 200), anti_aliasing=True)\n\n        plt.suptitle(title, fontsize = 16)\n        plt.subplot(rows, cols, k+1)\n        plt.imshow(image)\n        plt.axis('off')","e1cb2b9e":"show_images(train_df[train_df['target'] == 0], n=10, rows=2, cols=5, title='Benign Sample')","e7f0494e":"fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(16,6))\nplt.suptitle(\"B&W\", fontsize = 16)\n\nfor i in range(0, 1):\n    data = pydicom.read_file(train_df['path_dicom'][i])\n    image = data.pixel_array\n    \n    # Transform to B&W\n    # The function converts an input image from one color space to another.\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    image = cv2.resize(image, (200,200))\n    \n    x = i \n    y = i  \n    axes[x, y].imshow(image, cmap=plt.cm.bone) \n    axes[x, y].axis('off')","b6ffa95c":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(16,6))\nplt.suptitle(\"Without Gaussian Blur\", fontsize = 16)\n\nfor i in range(0, 2*6):\n    data = pydicom.read_file(train_df['path_dicom'][i])\n    image = data.pixel_array\n    \n    # Transform to B&W\n    # The function converts an input image from one color space to another.\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n    image = cv2.resize(image, (200,200))\n    \n    x = i \/\/ 6\n    y = i % 6\n    axes[x, y].imshow(image, cmap=plt.cm.bone) \n    axes[x, y].axis('off')","c5f54975":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(16,6))\nplt.suptitle(\"With Gaussian Blur\", fontsize = 16)\n\nfor i in range(0, 2*6):\n    data = pydicom.read_file(train_df['path_dicom'][i])\n    image = data.pixel_array\n    \n    # Transform to B&W\n    # The function converts an input image from one color space to another.\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n    image = cv2.resize(image, (200,200))\n    image=cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0) ,256\/10), -4, 128)\n    \n    x = i \/\/ 6\n    y = i % 6\n    axes[x, y].imshow(image, cmap=plt.cm.bone) \n    axes[x, y].axis('off')","d0de4c28":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(16,6))\nplt.suptitle(\"Hue, Saturation, Brightness\", fontsize = 16)\n\nfor i in range(0, 2*6):\n    data = pydicom.read_file(train_df['path_dicom'][i])\n    image = data.pixel_array\n    \n    # Transform to B&W\n    # The function converts an input image from one color space to another.\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n    image = cv2.resize(image, (200,200))\n    \n    x = i \/\/ 6\n    y = i % 6\n    axes[x, y].imshow(image, cmap=plt.cm.bone) \n    axes[x, y].axis('off')","4db6196d":"fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(16,6))\nplt.suptitle(\"LUV Color Space\", fontsize = 16)\n\nfor i in range(0, 2*6):\n    data = pydicom.read_file(train_df['path_dicom'][i])\n    image = data.pixel_array\n    \n    # Transform to B&W\n    # The function converts an input image from one color space to another.\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n    image = cv2.resize(image, (200,200))\n    \n    x = i \/\/ 6\n    y = i % 6\n    axes[x, y].imshow(image, cmap=plt.cm.bone) \n    axes[x, y].axis('off')\n\n","bf1017a3":"image_list","58f03ff9":"train_df","964158a4":"t0=train_df['path_jpeg'][0]\nt1=train_df['path_jpeg'][1]\nt2=train_df['path_jpeg'][2]\nt3=train_df['path_jpeg'][3]\nt4=train_df['path_jpeg'][4]\nt5=train_df['path_jpeg'][5]","9aeb01e1":"#image_list = train_df.sample(20)['path_jpeg']\n#image_list = image_list.reset_index()['path_jpeg']\n\n# Show the sample\nplt.figure(figsize=(16,16))\n#plt.suptitle(\"Original View\", fontsize = 16)\n    \n\nimage = mpimg.imread(t0)\nimage = cv2.resize(image, (512,512))\n#plt.subplot(2, 6, k+1)\nplt.imshow(image)\nplt.axis('off')","a1f05f8f":"#image_list = train_df.sample(20)['path_jpeg']\n#image_list = image_list.reset_index()['path_jpeg']\n\n# Show the sample\nplt.figure(figsize=(16,16))\n#plt.suptitle(\"Original View\", fontsize = 16)\n    \n\nimage = mpimg.imread(t1)\nimage = cv2.resize(image, (512,512))\n#plt.subplot(2, 6, k+1)\nplt.imshow(image)\nplt.axis('off')","0dcff722":"#image_list = train_df.sample(20)['path_jpeg']\n#image_list = image_list.reset_index()['path_jpeg']\n\n# Show the sample\nplt.figure(figsize=(16,16))\n#plt.suptitle(\"Original View\", fontsize = 16)\n    \n\nimage = mpimg.imread(t2)\nimage = cv2.resize(image, (512,512))\n#plt.subplot(2, 6, k+1)\nplt.imshow(image)\nplt.axis('off')","4153c98f":"#image_list = train_df.sample(20)['path_jpeg']\n#image_list = image_list.reset_index()['path_jpeg']\n\n# Show the sample\nplt.figure(figsize=(16,16))\n#plt.suptitle(\"Original View\", fontsize = 16)\n    \n\nimage = mpimg.imread(t3)\nimage = cv2.resize(image, (512,512))\n#plt.subplot(2, 6, k+1)\nplt.imshow(image)\nplt.axis('off')","9e5b10e8":"#image_list = train_df.sample(20)['path_jpeg']\n#image_list = image_list.reset_index()['path_jpeg']\n\n# Show the sample\nplt.figure(figsize=(16,16))\n#plt.suptitle(\"Original View\", fontsize = 16)\n    \n\nimage = mpimg.imread(t4)\nimage = cv2.resize(image, (512,512))\n#plt.subplot(2, 6, k+1)\nplt.imshow(image)\nplt.axis('off')","cac7aafa":"#image_list = train_df.sample(20)['path_jpeg']\n#image_list = image_list.reset_index()['path_jpeg']\n\n# Show the sample\nplt.figure(figsize=(16,16))\n#plt.suptitle(\"Original View\", fontsize = 16)\n    \n\nimage = mpimg.imread(t5)\nimage = cv2.resize(image, (512,512))\n#plt.subplot(2, 6, k+1)\nplt.imshow(image)\nplt.axis('off')","2e68e1e6":"#image_list = train_df.sample(20)['path_jpeg']\n#image_list = image_list.reset_index()['path_jpeg']\n\n# Show the sample\nplt.figure(figsize=(16,16))\n#plt.suptitle(\"Original View\", fontsize = 16)\n    \n\nimage = mpimg.imread(t6)\nimage = cv2.resize(image, (512,512))\n#plt.subplot(2, 6, k+1)\nplt.imshow(image)\nplt.axis('off')","cfb0f302":"#image_list = train_df.sample(20)['path_jpeg']\n#image_list = image_list.reset_index()['path_jpeg']\n\n# Show the sample\nplt.figure(figsize=(16,16))\n#plt.suptitle(\"Original View\", fontsize = 16)\n    \n\nimage = mpimg.imread(t0)\nimage = cv2.resize(image, (512,512))\n#plt.subplot(2, 6, k+1)\nplt.imshow(image)\nplt.axis('off')\n","a434acf6":"L'\u00e9chelle de Clark comporte 5 niveaux de m\u00e9lanome :\n\n   1. Les cellules se trouvent dans la couche externe de la peau (\u00e9piderme)\n\n   2. Les cellules se trouvent dans la couche situ\u00e9e directement sous l'\u00e9piderme (derme pupillaire)\n\n   3. Les cellules touchent la couche suivante appel\u00e9e derme profond\n\n   4. Les cellules se sont r\u00e9pandues dans le derme r\u00e9ticulaire\n\n   5. Les cellules se sont d\u00e9velopp\u00e9es dans la couche de graisse\n\n![](https:\/\/media.giphy.com\/media\/lSJElktZ5BKUvYSztq\/giphy.gif)","31b9ab61":"## Visualisation de donn\u00e9es","04cdec50":"## R\u00e9f\u00e9rences \n* [TensorFlow + Transfer Learning: Melanoma](https:\/\/www.kaggle.com\/amyjang\/tensorflow-transfer-learning-melanoma)\n* [GENERAL INFORMATION ABOUT MELANOMA](https:\/\/www.uhhospitals.org\/services\/cancer-services\/skin-cancer\/melanoma\/about-melanoma)\n","7ba9b1e0":"![](https:\/\/nci-media.cancer.gov\/pdq\/media\/images\/578083-750.jpg)","d1a8ddb8":"# 1. Introduction \u25b6\n\n### 1.1Qu'est-ce que le m\u00e9lanome:\n* [Le m\u00e9lanome est le cancer de la peau le moins fr\u00e9quent mais le plus mortel, ne repr\u00e9sentant qu'environ 1 % de tous les cas, mais la grande majorit\u00e9 des d\u00e9c\u00e8s dus au cancer de la peau.](https:\/\/www.aimatmelanoma.org\/about-melanoma\/melanoma-stats-facts-and-figures\/)\n* Le m\u00e9lanome est le troisi\u00e8me cancer le plus fr\u00e9quent chez les hommes et les femmes \u00e2g\u00e9s de 20 \u00e0 39 ans.\n* Aux \u00c9tats-Unis, le m\u00e9lanome continue d'\u00eatre \n    * le cinqui\u00e8me cancer le plus fr\u00e9quent chez les hommes de tous les groupes d'\u00e2ge\n    * le sixi\u00e8me cancer le plus fr\u00e9quent chez les femmes de tous les groupes d'\u00e2ge\n* L'Australie et la Nouvelle-Z\u00e9lande pr\u00e9sentent la plus forte incidence de m\u00e9lanomes au monde (plus de deux fois plus qu'en Am\u00e9rique du Nord)\n\n\n# N\u00f4tre Data:\n### Train Dataset se compose de:\n\n   1. image name -> le nom de fichier de l'image sp\u00e9cifique pour train set\n   2. patient_id -> id unique du patient \n   3. sex -> genre du patient\n   4. age_approx -> \u00e2ge approximatif du patient \n   5. anatom_site_general_challenge -> l'emplacement du  scan site\n   6. diagnosis -> des informations sur le diagnostic\n   7. benign_malignant - indique le r\u00e9sultat du scan s'il est malin ou b\u00e9nin\n   8. target -> m\u00eame chose que ci-dessus mais en mieux pour la mod\u00e9lisation puisqu'elle est binaire\n\n### Test Dataset se compose de:\n\n   1. image name -> le nom de fichier de l'image sp\u00e9cifique pour test set\n   2. patient_id -> id unique du patient \n   3. sex -> genre du patient\n   4. age_approx -> \u00e2ge approximatif du patient \n   5. anatom_site_general_challenge -> l'emplacement du  scan site\n\n\n\n\n### 1.2 objectifs:\n> L'objectif est d'identifier correctement les cas ****b\u00e9nins**** et ****malins****. Une tumeur b\u00e9nigne est une tumeur qui n'envahit pas les tissus environnants ou ne se propage pas dans le corps. Une tumeur maligne est une tumeur qui peut envahir les tissus environnants ou se propager dans le corps. .\n<img src = 'https:\/\/www.verywellhealth.com\/thmb\/IFgBpbmhYCJdS4rvLACzX3Ukqsc=\/1500x0\/filters:no_upscale():max_bytes(150000):strip_icc():format(webp)\/514240-article-img-malignant-vs-benign-tumor2111891f-54cc-47aa-8967-4cd5411fdb2f-5a2848f122fa3a0037c544be.png' width = 300>\n\n> Data: DICOM Files split in Train (33,126 observations) and Test (10,982 observations)\n<img src='https:\/\/i.imgur.com\/or0AoVs.png' width = 500>\n","32962341":"* **0=b\u00e9nins**\n* **1=malins**","d0c24e32":"# 3.Pr\u00e9paration de la base de donn\u00e9es","80e96fa8":"1. Il y a plus d'hommes que de femmes dans l'ensemble de donn\u00e9es\n2. Cependant, les pourcentages sont presque les m\u00eames"}}