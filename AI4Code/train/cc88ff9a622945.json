{"cell_type":{"d8e6a732":"code","81fc0446":"code","325cd4a1":"code","243489b1":"code","9ed8aa6e":"code","d226c533":"code","39e1e89c":"code","a8e53986":"code","9ddbc6e4":"code","2ded13c5":"code","a979a915":"code","8e1bea51":"code","12770987":"code","6825febf":"code","3a8275f0":"code","92b29cfc":"code","0c33bfb8":"code","b706e8a9":"code","7f368db2":"code","1298a523":"code","4094014e":"code","5df83174":"code","ff88afe9":"code","abc8fb7d":"code","65c9b0c7":"code","239943db":"code","a7d6b4bd":"code","e0253d3c":"code","4381585f":"code","2f2b2bee":"code","47c18b53":"code","b5aca7ca":"code","9a52b6ec":"code","45bfb3b8":"code","5236367c":"code","34610e46":"code","fba34832":"code","fdd6abae":"code","1f8ee242":"code","af6b87ed":"code","7cb19140":"code","4181efe6":"code","23c632c9":"code","72da9ec8":"code","71c5b37f":"code","98d694fa":"code","fda79d7e":"code","7181162b":"code","8a58e027":"code","1a63b7ef":"code","30cd718d":"code","d91d0f57":"code","d471512e":"code","06486cd0":"code","c001d4a6":"code","7eaffa06":"code","f1a30225":"code","6f34c150":"code","9caf3cd3":"code","d5009561":"code","a8a234a7":"code","5b92dbec":"code","9673e788":"code","6994a6dc":"code","38fb17a5":"code","c2e463cb":"code","04ad8ecf":"code","023b33b7":"code","3e33c25a":"code","5ad7f771":"code","8ad40079":"code","49b791a5":"code","b22a1243":"code","93c4a02c":"code","9129e06c":"code","43c47560":"code","1bc1d683":"code","ac933bd1":"code","7659ceec":"code","899e06eb":"code","db4df3c7":"code","9eea20ef":"code","8484d755":"code","8f4f9b54":"code","a9e000cd":"code","fc7bb852":"code","201be6e5":"code","7c4e0c61":"code","0b634546":"code","369e7f1d":"code","61340b1e":"code","fd66a970":"code","7945ec29":"markdown","586bbba0":"markdown","4546f7f3":"markdown","daefaf02":"markdown","032eb918":"markdown","5750cc4c":"markdown","a062d117":"markdown","c9aea103":"markdown","a16c9af2":"markdown","943e4a8b":"markdown","19956ee6":"markdown","a20c075d":"markdown","90757cfb":"markdown","b89829ea":"markdown","3eae3550":"markdown","190ee984":"markdown","b805acd2":"markdown","77f12056":"markdown","0313a849":"markdown"},"source":{"d8e6a732":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81fc0446":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score","325cd4a1":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nhit = pd.read_csv(\"..\/input\/advertising-machine-learning\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndf.head()","243489b1":"df.count()","9ed8aa6e":"df.info()","d226c533":"df.describe().T","39e1e89c":"dms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ndms.head()","a8e53986":"y = df[\"Salary\"]","9ddbc6e4":"X_ = df.drop(['Salary','League', 'Division', 'NewLeague'], axis = 1).astype(\"float64\")","2ded13c5":"X_.head()","a979a915":"X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis = 1)\nX.head()","8e1bea51":"from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict","12770987":"X_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y, \n                                                    test_size=0.25, \n                                                    random_state=42)\n\nprint(\"X_train\", X_train.shape)\n\nprint(\"y_train\",y_train.shape)\n\nprint(\"X_test\",X_test.shape)\n\nprint(\"y_test\",y_test.shape)\n\ntraining = df.copy()\n\nprint(\"training\", training.shape)","6825febf":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import scale \npca = PCA()","3a8275f0":"X_reduced_train = pca.fit_transform(scale(X_train))","92b29cfc":"X_reduced_train[0:1,:]","0c33bfb8":"np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4)*100)[0:5]","b706e8a9":"lm = LinearRegression()","7f368db2":"pcr_model = lm.fit(X_reduced_train, y_train)","1298a523":"pcr_model.intercept_","4094014e":"pcr_model.coef_","5df83174":"y_pred = pcr_model.predict(X_reduced_train)","ff88afe9":"y_pred[0:5]","abc8fb7d":"np.sqrt(mean_squared_error(y_train, y_pred))","65c9b0c7":"df[\"Salary\"].mean()","239943db":"r2_score(y_train, y_pred)","a7d6b4bd":"pca2 = PCA()","e0253d3c":"X_reduced_test = pca2.fit_transform(scale(X_test))","4381585f":"y_pred = pcr_model.predict(X_reduced_test)","2f2b2bee":"np.sqrt(mean_squared_error(y_test, y_pred))","47c18b53":"lm = LinearRegression()\npcr_model = lm.fit(X_reduced_train[:,0:10], y_train)\ny_pred = pcr_model.predict(X_reduced_test[:,0:10])\nprint(np.sqrt(mean_squared_error(y_test, y_pred)))","b5aca7ca":"from sklearn import model_selection","9a52b6ec":"cv_10 = model_selection.KFold(n_splits = 10,\n                             shuffle = True,\n                             random_state = 1)","45bfb3b8":"lm = LinearRegression()","5236367c":"RMSE = []","34610e46":"for i in np.arange(1, X_reduced_train.shape[1] + 1):\n    \n    score = np.sqrt(-1*model_selection.cross_val_score(lm, \n                                                       X_reduced_train[:,:i], \n                                                       y_train.ravel(), \n                                                       cv=cv_10, \n                                                       scoring='neg_mean_squared_error').mean())\n    RMSE.append(score)","fba34832":"lm = LinearRegression()","fdd6abae":"pcr_model = lm.fit(X_reduced_train[:,0:6], y_train)","1f8ee242":"y_pred = pcr_model.predict(X_reduced_train[:,0:6])","af6b87ed":"print(np.sqrt(mean_squared_error(y_train, y_pred)))","7cb19140":"y_pred = pcr_model.predict(X_reduced_test[:,0:6])","4181efe6":"print(np.sqrt(mean_squared_error(y_test, y_pred)))","23c632c9":"hit = pd.read_csv(\"..\/input\/advertising-machine-learning\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\nms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","72da9ec8":"from sklearn.linear_model import Ridge","71c5b37f":"ridge_model = Ridge(alpha = 0.01).fit(X_train, y_train)\nridge_model","98d694fa":"ridge_model.coef_","fda79d7e":"10**np.linspace(10,-2,100)*0.5 ","7181162b":"lambdalar = 10**np.linspace(10,-2,100)*0.5\n\nridge_model = Ridge()\nkatsayilar = []\n\nfor i in lambdalar:\n    ridge_model.set_params(alpha = i)\n    ridge_model.fit(X_train, y_train)\n    katsayilar.append(ridge_model.coef_)\n    \n    \nax = plt.gca()\nax.plot(lambdalar, katsayilar)\nax.set_xscale('log')\n\nplt.xlabel('Lambda(Alpha) De\u011ferleri')\nplt.ylabel('Katsay\u0131lar\/A\u011f\u0131rl\u0131klar')\nplt.title('D\u00fczenlile\u015ftirmenin Bir Fonksiyonu Olarak Ridge Katsay\u0131lar\u0131');","8a58e027":"ridge_model.predict(X_test)","1a63b7ef":"y_pred = ridge_model.predict(X_test)","30cd718d":"np.sqrt(mean_squared_error(y_test, y_pred))","d91d0f57":"lambdalar = 10**np.linspace(10,-2,100)*0.5 \nlambdalar[0:5]","d471512e":"from sklearn.linear_model import RidgeCV\nridge_cv = RidgeCV(alphas = lambdalar,\n                  scoring = \"neg_mean_squared_error\",\n                  normalize = True)","06486cd0":"ridge_cv.fit(X_train, y_train)","c001d4a6":"ridge_cv.alpha_","7eaffa06":"ridge_tuned = Ridge(alpha = ridge_cv.alpha_,\n                   normalize = True).fit(X_train,y_train)","f1a30225":"np.sqrt(mean_squared_error(y_test, ridge_tuned.predict(X_test)))","6f34c150":"hit = pd.read_csv(\"..\/input\/advertising-machine-learning\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\nms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","9caf3cd3":"from sklearn.linear_model import Lasso","d5009561":"lasso_model = Lasso(alpha = 0.1).fit(X_train, y_train)","a8a234a7":"lasso_model","5b92dbec":"lasso_model.coef_","9673e788":"lambdalar = 10**np.linspace(10,-2,100)*0.5 \n\nlasso_model = Lasso()\nkatsayilar = []\n\nfor i in lambdalar:\n    lasso_model.set_params(alpha = i)\n    lasso_model.fit(X_train, y_train) \n    katsayilar.append(lasso_model.coef_) \n    \n\n    \nax = plt.gca()\nax.plot(lambdalar*2, katsayilar)\nax.set_xscale('log')\nplt.axis('tight')\nplt.xlabel('alpha')\nplt.ylabel('weights')","6994a6dc":"lasso_model.predict(X_test)","38fb17a5":"y_pred = lasso_model.predict(X_test)","c2e463cb":"np.sqrt(mean_squared_error(y_test, y_pred))","04ad8ecf":"from sklearn.linear_model import LassoCV","023b33b7":"lasso_cv_model = LassoCV(alphas = None,\n                        cv = 10,\n                        max_iter = 10000,\n                        normalize = True)","3e33c25a":"lasso_cv_model.fit(X_train, y_train)","5ad7f771":"lasso_cv_model.alpha_","8ad40079":"lasso_tuned = Lasso(alpha = lasso_cv_model.alpha_)","49b791a5":"lasso_tuned.fit(X_train, y_train)","b22a1243":"y_pred = lasso_tuned.predict(X_test)","93c4a02c":"np.sqrt(mean_squared_error(y_test, y_pred))","9129e06c":"np.sqrt(mean_squared_error(y_test, lasso_tuned.predict(X_test)))","43c47560":"hit = pd.read_csv(\"..\/input\/advertising-machine-learning\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\nms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)\n\n","1bc1d683":"from sklearn.linear_model import ElasticNet","ac933bd1":"enet_model = ElasticNet().fit(X_train, y_train)","7659ceec":"enet_model.coef_","899e06eb":"enet_model.intercept_","db4df3c7":"enet_model","9eea20ef":"enet_model.predict(X_test)","8484d755":"y_pred = enet_model.predict(X_test)","8f4f9b54":"np.sqrt(mean_squared_error(y_test, y_pred))","a9e000cd":"r2_score(y_test, y_pred)","fc7bb852":"from sklearn.linear_model import ElasticNetCV","201be6e5":"enet_cv_model = ElasticNetCV(cv = 10, random_state = 0).fit(X_train, y_train)","7c4e0c61":"enet_cv_model.alpha_","0b634546":"enet_cv_model","369e7f1d":"enet_tuned = ElasticNet(alpha = enet_cv_model.alpha_).fit(X_train, y_train)","61340b1e":"y_pred = enet_tuned.predict(X_test)","fd66a970":"np.sqrt(mean_squared_error(y_test, y_pred))","7945ec29":"### Model Tuning","586bbba0":"### Tahmin","4546f7f3":"* \u00dcretti\u011fi modelin tahmin do\u011frulu\u011funu ve yorumlanabilirli\u011fini artt\u0131rmak i\u00e7in hem de\u011fi\u015fken se\u00e7imi hem de regularization yapar.\n<br>\n* Ayn\u0131 ridge regresyonda oldu\u011fu gibi ama\u00e7 hata kareler toplam\u0131n\u0131 minimize eden katsay\u0131lar\u0131, katsay\u0131lara ceza uygulayarak bulmakt\u0131r.\n<br>\n* Fakat ridge regresyondan farkl\u0131 olarak ilgisiz de\u011fi\u015fkenlerin katsay\u0131lar\u0131n\u0131 s\u0131f\u0131ra e\u015fitler.(Ridge regrestonda ilgisiz katsay\u0131lar\u0131 s\u0131f\u0131ra yakla\u015ft\u0131r\u0131r!)","daefaf02":"### Tahmin","032eb918":"## Model Tuning","5750cc4c":"* Ama\u00e7 Ridge ve Lasso regresyon ile ayn\u0131d\u0131r ama ElasticNet, Ridge ve Lasso regresyonu birle\u015ftirir. Ridge regresyon tarz\u0131 cezaland\u0131rma ve lasso regresyon tarz\u0131nda de\u011fi\u015fken se\u00e7imi yapar.","a062d117":"### Tahmin","c9aea103":"# ElasticNet Regresyonu","a16c9af2":"# Contents\n* PCR\n* PLS\n* Ridge !\n* Lasso !\n* ElasticNet ! ","943e4a8b":"### Model","19956ee6":"## S\u00fcre\u00e7\n1) Veri setimizde x de\u011fi\u015fkenlerimizi ve y de\u011fi\u015fkenimizi belirliyoruz.( hepsi x ise unsupervised oluyor)\n<br>\n\n2) Veri setimizi split ediyoruz(train: %80- test: %20 oran\u0131 tercih ediliyor genelde).Random olarak program verileri kendi se\u00e7iyor ve ay\u0131r\u0131yor..\n\n3) Train veri setimiz \u00fczerinden modelimizi kurup bir denklem elde ediyoruz.(y de\u011ferlerini tahmin etti\u011fimiz bir denklem)\n\n4) Test setine gelip ayn\u0131 denklemi uyguluyoruz. Ve tahmin etti\u011fimiz y de\u011ferleri ile ger\u00e7ek y de\u011ferlerini kar\u015f\u0131la\u015ft\u0131r\u0131yoruz. RMSE de\u011ferini hesapl\u0131yoruz. Bu bizim ilkel test hatam\u0131z..\n\n5) Fakat 2.maddede yapt\u0131\u011f\u0131m\u0131z split i\u015flemi RANDOM olarak yap\u0131l\u0131yor. Bu random konusu \u00f6nemli. Split kodunu yazd\u0131\u011f\u0131m\u0131zda bu test veri seti- bu train veri seti diye bize veri setlerini random se\u00e7erek veriyor. Ve biz model kurup RMSE(ilkel) hesapl\u0131yoruz. Ancak bize split i\u015fleminde ayr\u0131m\u0131 ba\u015fka yaparsa, yani mesela siz yapt\u0131\u011f\u0131n\u0131zda ana veri setimiz i\u00e7erisinden farkl\u0131 se\u00e7ilmi\u015f test-train seti geliyor, ben yaparsam bana ba\u015fka bir test-train veri seti geliyor. Bu nedenle de her seferinde RMSE de\u011ferimiz FARKLI \u00e7\u0131k\u0131yor. Bu nedenle bu ilk RMSE'ye ilkel deniyor..\n\nBiz de bunu \u00f6nlemek i\u00e7in cross validation yap\u0131yoruz. Yani diyoruz ki madem her test-train ayr\u0131m\u0131nda farkl\u0131 RMSE geliyor, biz ger\u00e7ek-nihai RMSE'mizi bulmak istiyoruz bu nedenle cross validation nesnesi olu\u015fturuyoruz. Bu nesneye parametreler veriyoruz ve sen bu i\u015flemi 10 kere yap, yani 10 farkl\u0131 random olarak train seti se\u00e7me i\u015flemi yap(leave-one-out da olabiliyor,5 de,10 da bunu biz belirliyoruz) ve bana en iyi parametrelerle bir model ver. Bu bizim nihai modelimiz oluyor.\n\n\n\n6) Art\u0131k bu modelin  tahmin edilen ve ger\u00e7ekte olan veriler aras\u0131ndaki hatas\u0131n\u0131 hesaplayabiliriz. Diyoruz ki sen bu 10 tane test veri seti \u00fczerinden 10 tane tahmini y de\u011feri hesapla ve ortalamalar\u0131n\u0131 al, sonra gel benim test veri setimdeki y de\u011feri ile kar\u015f\u0131la\u015ft\u0131r, bunu her bir x de\u011fi\u015fkeninin test setindeki farkl\u0131 de\u011ferleri i\u00e7in yap ve bana yeni RMSE de\u011ferini ver.\n\n\n\nYani belirtti\u011finiz gibi RMSE'yi, train veri seti ve test veri seti \u00fczerinden ayr\u0131 ayr\u0131 hesaplamad\u0131k. Bu nedenle aras\u0131ndaki farka bakmak ya da varyans d\u00fc\u015f\u00fckl\u00fc\u011f\u00fc \u00f6nem arz etmiyor...\n\n\n\nModeli train setinde kurduk test setinde RMSE hesaplad\u0131k...\n\n\n\nBi ilkel test hatam\u0131z var bir de valide edilmi\u015f test hatam\u0131z var. Bu nedenle valide edilmi\u015f yani 10 test veri seti \u00fczerinden elde edilen y tahminin ortalamas\u0131 al\u0131narak, test veri setindeki ger\u00e7ek y ile k\u0131yaslan\u0131yor ve nihai\/ger\u00e7ek RMSE de\u011ferimiz bulunmu\u015f oluyor.\n\n","a20c075d":"### Model Tuning","90757cfb":"* \u00c7ok de\u011fi\u015fkenli regresyon verilerini analiz etmede kullan\u0131l\u0131r. Ama\u00e7 hata kareler toplam\u0131n\u0131 minimize eden katsay\u0131lar\u0131, bu katsay\u0131lara bir ceza uygulayarak bulmakt\u0131r.\n<br>\n* Over-fittinge kar\u015f\u0131 d\u015fren\u00e7lidir.T\u00fcm de\u011fi\u015fkenler ile model kurar, ilgisiz de\u011fi\u015fkenleri \u00e7\u0131karmaz sadece katsay\u0131lar\u0131n\u0131 s\u0131f\u0131ra yakla\u015ft\u0131r\u0131r.\n<br>\n* Modeli kurarken alpha-lambda(ceza) i\u00e7in iyi bir de\u011fer bulmak gerekir. Bunuda for d\u00f6ng\u00fcs\u00fc ile bulabiliriz.","b89829ea":"### Model Tuning","3eae3550":"## Ridge Regression","190ee984":"### Tahmin","b805acd2":"# Lasso Regresyon","77f12056":"#### Model","0313a849":"Veri setini daha az say\u0131da bile\u015fene indirmek"}}