{"cell_type":{"d71cffa4":"code","ad8c77d1":"code","ce7de1b0":"code","8215bdf2":"code","a011eaac":"code","2f04672f":"code","51975ea4":"code","789b6b12":"code","94a27868":"code","b9a50bc7":"code","006566a9":"code","5d8b7492":"code","46d4b31d":"code","188ffe59":"code","622be38c":"code","844c6aa2":"code","f9bb1193":"code","a7718ddd":"code","a0f37d36":"code","43d2f7a2":"code","c80632a3":"markdown","01cb960d":"markdown","b35365a4":"markdown"},"source":{"d71cffa4":"!pip -q install timm\n!pip -q install tlt\n!pip -q install pytorch-pfn-extras","ad8c77d1":"from __future__ import print_function\n\nimport glob\nfrom itertools import chain\nimport os\nimport random\nimport zipfile\nimport copy\nimport gc\nimport sys\nimport copy\nimport yaml\nimport random\nimport shutil\nimport typing as tp\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nfrom torch.cuda import amp\n\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nfrom tqdm.notebook import tqdm\n\nimport timm\n\nfrom tlt.utils import load_pretrained_weights\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport pytorch_pfn_extras as ppe\nfrom pytorch_pfn_extras.config import Config\nfrom pytorch_pfn_extras.training import extensions as ppe_exts, triggers as ppe_triggers\n\nsys.path.append(\"..\/input\/volo-package\")\nfrom volo.models import volo_d1, volo_d2, volo_d3, volo_d4, volo_d5  # register models to timm\nfrom volo.utils import load_pretrained_weights as volo_load_weights\n\n%config InlineBackend.figure_format = 'retina'","ce7de1b0":"print(f\"Torch: {torch.__version__}\")","8215bdf2":"# Training settings\nbatch_size = 64\nepochs = 20\nlr = 3e-5\ngamma = 0.7\nseed = 42","a011eaac":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(seed)","2f04672f":"import torchvision\nfrom torchvision.transforms import ToTensor\n\ntrain_data = torchvision.datasets.ImageFolder('..\/input\/battlefront-2-maps-small\/train', transform=ToTensor())\nvalid_data = torchvision.datasets.ImageFolder('..\/input\/battlefront-2-maps-small\/valid', transform=ToTensor())\ntest_data = torchvision.datasets.ImageFolder('..\/input\/battlefront-2-maps-small\/test', transform=ToTensor())","51975ea4":"import torch.utils.data as data\nfrom torch.autograd import Variable\nimport numpy as np\n\ntrain_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\nvalid_loader = data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)\ntest_loader  = data.DataLoader(test_data, batch_size=batch_size, shuffle=True) ","789b6b12":"print(len(train_data), len(train_loader))\nprint(len(valid_data), len(valid_loader))\nprint(len(test_data), len(test_loader))","94a27868":"device = 'cuda'\nmodel = volo_d1(img_size=224)\nload_pretrained_weights(model=model, checkpoint_path='..\/input\/volo-package\/d1_224_84.2.pth.tar')\nmodel = model.to(device)","b9a50bc7":"# loss function\ncriterion = nn.CrossEntropyLoss()\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=lr)\n# scheduler\nscheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n\nn_epochs_stop = 10\n\nmin_val_loss = 10","006566a9":"epoch_l = []\nloss_l = []\nacc_l = []\nv_loss_l = []\nv_acc_l = []","5d8b7492":"for epoch in range(epochs):\n    epoch_loss = 0\n    epoch_accuracy = 0\n\n    for data, label in tqdm(train_loader):\n        data = data.to(device)\n        label = label.to(device)\n\n        output = model(data)[0]      \n        loss = criterion(output, label)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        acc = (output.argmax(dim=1) == label).float().mean()\n        epoch_accuracy += acc \/ len(train_loader)\n        epoch_loss += loss \/ len(train_loader)\n\n    with torch.no_grad():\n        epoch_val_accuracy = 0\n        epoch_val_loss = 0\n        for data, label in valid_loader:\n            data = data.to(device)\n            label = label.to(device)\n\n            val_output = model(data)[0]\n            val_loss = criterion(val_output, label)\n\n            acc = (val_output.argmax(dim=1) == label).float().mean()\n            epoch_val_accuracy += acc \/ len(valid_loader)\n            epoch_val_loss += val_loss \/ len(valid_loader)\n        \n        epoch_l.append(epoch+1)\n        loss_l.append(epoch_loss)\n        acc_l.append(epoch_accuracy)\n        v_loss_l.append(epoch_val_loss)\n        v_acc_l.append(epoch_val_accuracy)\n        \n        print(f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\")\n        \n        if epoch_val_loss < min_val_loss:\n            #Saving the model\n            best_model = copy.deepcopy(model.state_dict())\n            epochs_no_improve = 0\n            min_val_loss = epoch_val_loss\n            early_stoped = False\n\n        else:\n            epochs_no_improve += 1\n            # Check early stopping condition\n            if epochs_no_improve == n_epochs_stop:\n                print('Early stopping!' )\n                model.load_state_dict(best_model)\n                early_stoped = True\n                break\n    if early_stoped:\n        break","46d4b31d":"torch.save(model, '.\/volo.pt')","188ffe59":"y_pred_list = []\ny_true_list = []\nwith torch.no_grad():\n    for x_batch, y_batch in tqdm(test_loader):\n        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n        y_test_pred = model(x_batch)[0]\n        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n        y_pred_list.append(y_pred_tag.cpu().numpy())\n        y_true_list.append(y_batch.cpu().numpy())","622be38c":"def flatten(new:list, target:list):\n    for li in target:\n        for value in list(li):\n            new.append(value)\n\ny_pred = []\ny_true = []\nflatten(y_pred, y_pred_list)\nflatten(y_true, y_true_list)","844c6aa2":"from sklearn.metrics import accuracy_score, f1_score, recall_score\nprint(\"Overall accuracy:\", accuracy_score(y_true, y_pred))\nprint(\"Overall F1:\", f1_score(y_true, y_pred, average='weighted'))\nprint(\"Overall Recall:\", recall_score(y_true, y_pred, average='weighted'))","f9bb1193":"from sklearn.metrics import precision_recall_fscore_support as score\n\nprecision, recall, fscore, support = score(y_true, y_pred)\n\nprint('precision: {}'.format(precision))\nprint('recall: {}'.format(recall))\nprint('fscore: {}'.format(fscore))\nprint('support: {}'.format(support))","a7718ddd":"from sklearn.metrics import confusion_matrix\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\ndef plot_cm(y_true, y_pred, figsize=(10,9)):\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm \/ cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)\n\nplot_cm(y_true, y_pred)\n\ndisplay()","a0f37d36":"loss_l_c = []\nacc_l_c = []\nv_loss_l_c = []\nv_acc_l_c = []\nfor x in loss_l:\n    x = x.cpu().detach().numpy()\n    loss_l_c.append(x)\nfor x in acc_l:\n    x = x.cpu().detach().numpy()\n    acc_l_c.append(x)\nfor x in v_loss_l:\n    x = x.cpu().detach().numpy()\n    v_loss_l_c.append(x)\nfor x in v_acc_l:\n    x = x.cpu().detach().numpy()\n    v_acc_l_c.append(x)","43d2f7a2":"import plotly.graph_objects as go\n\n# Create traces\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=epoch_l, y=loss_l_c,\n                    mode='lines+markers',\n                    name='Train loss'))\nfig.add_trace(go.Scatter(x=epoch_l, y=acc_l_c,\n                    mode='lines+markers',\n                    name='Train accuracy'))\nfig.add_trace(go.Scatter(x=epoch_l, y=v_loss_l_c,\n                    mode='lines+markers',\n                    name='Validation loss'))\nfig.add_trace(go.Scatter(x=epoch_l, y=v_acc_l_c,\n                    mode='lines+markers',\n                    name='Validation accuracy'))\nfig.update_layout(\n    title='VOLO',\n    autosize=False,\n    width=1000,\n    height=600,\n)\n\nfig.show()","c80632a3":"### Train","01cb960d":"## Definition of Model, Dataset, Metric","b35365a4":"### VOLO Model"}}