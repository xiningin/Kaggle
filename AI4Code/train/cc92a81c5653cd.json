{"cell_type":{"1fc3eac4":"code","93cbc222":"code","6f88c955":"code","49df3f94":"code","dcf2eb95":"code","341e87e6":"code","0a1824ce":"code","d2628f0e":"code","1ff2fd4d":"code","be2670c1":"code","77d7e791":"code","71080a33":"code","9708c55a":"code","e6aecdb8":"markdown","afe93546":"markdown","20ffd743":"markdown","04c6ffdb":"markdown","58f2caad":"markdown","3b6155dd":"markdown","996ba1ef":"markdown","676681f0":"markdown","76e8c8bd":"markdown","87366496":"markdown","5fe4095d":"markdown","4abd8826":"markdown","58ef3b23":"markdown","3f941b2a":"markdown","9e30d076":"markdown"},"source":{"1fc3eac4":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom matplotlib import pyplot as plt","93cbc222":"def show_graphs(feature1,feature2):\n    \"\"\"\n    Creates subplots of two Pandas series\n    \"\"\"\n    fig = plt.figure(figsize=(12,8), dpi= 60, facecolor='w', edgecolor='k')\n\n    for i,feature in enumerate([feature1,feature2]):\n        ax = fig.add_subplot(2, 2, (2*(i+1))-1)\n        ax.boxplot(feature,labels=[feature.name])\n        ax.set_ylim(-5,20)\n        ax = fig.add_subplot(2, 2, 2*(i+1))\n        ax.hist(feature,50,facecolor='g')\n        plt.xlabel(feature.name)\n\n    fig.show()\n\n    return ","6f88c955":"from sklearn.datasets import load_wine\n\ndata = pd.DataFrame(load_wine()['data'],columns = load_wine()['feature_names'])\ntarget = pd.DataFrame(load_wine()['target'])\n\ndata.describe()","49df3f94":"show_graphs(data['alcohol'],data['color_intensity'])","dcf2eb95":"alcohol_simple_scaled = pd.Series(preprocessing.scale(data['alcohol']),name='alcohol')\ncolor_intensity_simple_scaled = pd.Series(preprocessing.scale(data['color_intensity']),name='color_intensity')\n\nshow_graphs(alcohol_simple_scaled,color_intensity_simple_scaled)","341e87e6":"scaler = preprocessing.MinMaxScaler()\n\nalcohol_minmax_scaled = pd.Series(scaler.fit_transform(data[['alcohol']]).ravel(),name='alcohol')\ncolor_intensity_minmax_scaled = pd.Series(scaler.fit_transform(data[['color_intensity']]).ravel(),name='color_intensity')\n\nshow_graphs(alcohol_minmax_scaled,color_intensity_minmax_scaled)","0a1824ce":"scaler = preprocessing.MaxAbsScaler()\n\nalcohol_MaxAbs_scaled = pd.Series(scaler.fit_transform(data[['alcohol']]).ravel(),name='alcohol')\ncolor_intensity_MaxAbs_scaled = pd.Series(scaler.fit_transform(data[['color_intensity']]).ravel(),name='color_intensity')\n\nshow_graphs(alcohol_MaxAbs_scaled,color_intensity_MaxAbs_scaled)","d2628f0e":"scaler = preprocessing.RobustScaler()\n\nalcohol_robust_scaled = pd.Series(scaler.fit_transform(data[['alcohol']]).ravel(),name='alcohol')\ncolor_intensity_robust_scaled = pd.Series(scaler.fit_transform(data[['color_intensity']]).ravel(),name='color_intensity')\n\nshow_graphs(alcohol_robust_scaled,color_intensity_robust_scaled)","1ff2fd4d":"scaler = preprocessing.PowerTransformer(method = 'box-cox')\n\nalcohol_power_scaled = pd.Series(scaler.fit_transform(data[['alcohol']]).ravel(),name='alcohol')\ncolor_intensity_power_scaled = pd.Series(scaler.fit_transform(data[['color_intensity']]).ravel(),name='color_intensity')\n\nshow_graphs(alcohol_power_scaled,color_intensity_power_scaled)","be2670c1":"scaler = preprocessing.QuantileTransformer(output_distribution = 'normal', n_quantiles=len(data))\n\nalcohol_Quantile_scaled = pd.Series(scaler.fit_transform(data[['alcohol']]).ravel(),name='alcohol')\ncolor_intensity_Quantile_scaled = pd.Series(scaler.fit_transform(data[['color_intensity']]).ravel(),name='color_intensity')\n\nshow_graphs(alcohol_Quantile_scaled,color_intensity_Quantile_scaled)","77d7e791":"scaler = preprocessing.Normalizer()\n\nalcohol_Normalizer_scaled = pd.Series(scaler.fit_transform(data[['alcohol']]).ravel(),name='alcohol')\ncolor_intensity_Normalizer_scaled = pd.Series(scaler.fit_transform(data[['color_intensity']]).ravel(),name='color_intensity')\n\nshow_graphs(alcohol_Normalizer_scaled,color_intensity_Normalizer_scaled)","71080a33":"from mpl_toolkits.mplot3d import Axes3D\n\nthree_data = data[['alcohol','color_intensity','flavanoids']]\nscaled_three_data = pd.DataFrame(scaler.fit_transform(three_data),columns=three_data.columns)\n\nfig = plt.figure(figsize=(16,8), dpi= 60, facecolor='w', edgecolor='k')\n\nax = fig.add_subplot(1, 2, 1, projection='3d')\nax.scatter(data['alcohol'],data['color_intensity'],data['flavanoids'])\n\nax = fig.add_subplot(1, 2, 2, projection='3d')\nax.scatter(scaled_three_data['alcohol'],scaled_three_data['color_intensity'],scaled_three_data['flavanoids'])","9708c55a":"fig = plt.figure(figsize=(12,8), dpi= 60, facecolor='w', edgecolor='k')\n\nax = plt.scatter(data['color_intensity'],data['flavanoids'])","e6aecdb8":"<a id=\"section-one\"><\/a>\n## 1. Standard Scaler\nThis centres to the mean and a unit variance. It's nothing fancy and does nothing to outliers. It's the one we all learned about in our Stats courses and it's everywhere.","afe93546":"<a id=\"section-three\"><\/a>\n## 3. MaxAbs Scaler\nAs stated in the Sklearn documentation, this one has been designed to work with sparse datasets (where the features array is mostly blank\/null). The differences to MinMax scaler here are the centre is not shifted and we can't assign our own range (min,max), we're forced to use (0,1). For most positive data, MaxAbs is equivalent to MinMax.\n\nNote because the centre isn't shifted the range for alcohol is different (0.75~1.0) to MinMax (0~1). So here our scaled mean stays in the same place, whereas in minmax it's centred in (0,1).","20ffd743":"# An Investigation into the Sklearn Scalers\nI made this notebook as an exercise to help me better visualise the different scalers that are available in the Sklearn prepocessing library. On the surface this is nothing new and there's a really good article on this on the sklearn website [here](https:\/\/scikit-learn.org\/stable\/auto_examples\/preprocessing\/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py). My work almost certainly won't outshine this, but as I say, it's a self-learning exercise (and a bit of fun).","04c6ffdb":"It's still hard to see what's going on here, but the pattern has sort of been collapsed to a 2D version of the first 2 variables: color intensity and flavanoids.","58f2caad":"I think you can sort of see the above pattern in the 3D scaled plot, to me this helps broadly understand what's going on even if I don't yet have full grasp of the 3-dimensional statistics yet.\n\n<a id=\"conclusion\"><\/a>\n## Conclusion\n\nA few things still for me to learn on saclers 5-7, but for most machine learning applications I would imagine 1-4 will suit.\n\nThe one thing missing is log transformation. There doesn't seem to be a standard package in sklearn for this, but it's an important one. I may update this at a later date.\n\nThanks for reading.","3b6155dd":"<a id=\"section-four\"><\/a>\n## 4. Robust Scaler  \nHere the pattern of the data is still unchanged, but now we're scaling using the median and interquartile range. The benefit of this is our resulting scaled distribution won't be affected by outliers as much because the scaled range is more linked to the range of the overall data.","996ba1ef":"<a id=\"section-two\"><\/a>\n## 2. MinMaxScaler \nThis converts everything to a set range, the default is (0,1). The shape of the data is unchanged, so outliers here wil cause issues (Not that we can see this in the below).","676681f0":"<a id=\"section-five\"><\/a>\n## 5. Power Transformer\nThe power transformer has two methods, one for srtictly positive values and one for positive\/negative data (Box-Cox and Yeo-Johnson respectively). This is a maximum likeilhood optimisation problem seeking to achieve unit variance and reduce skewness. This would be used if there were excessive heteroskedasticity (my favourite stats word), i.e. where the variance changes substantially over the range of the variable. We're looking at univariate scaling here, so this is irrelevant.\n\nNote the shape of the distribution will change as a result.","76e8c8bd":"<a id=\"section-seven\"><\/a>\n## 7. Normalizer (and a huge digression)\n\nI'm going to ditch the univariate thing for this last one. This isn't a scaler to use on a univariate series. Let me show you:","87366496":"### Further Reading:\n\nhttp:\/\/benalexkeen.com\/feature-scaling-with-scikit-learn\n\nhttps:\/\/towardsdatascience.com\/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02","5fe4095d":"## Table of Contents\n* [The Data](#section-zero)\n* [Standard Scaler](#section-one)\n* [MinMax Scaler](#section-two)\n* [MaxAbs Scaler](#section-three)\n* [Robust Scaler](#section-four)\n* [Power Transformer](#section-five)\n* [Quantile Transformer](#section-six)\n* [Normalizer](#section-seven)   \n* [Conclusion](#conclusion)","4abd8826":"Terrible right? The real usage of normaliser is to scale higher dimensional variation (2D or more) into a sensible range. The best way to visualise this would be with a nice 3D graph and 3 of our wine variables. I'm going with 'flavanoids', because it's a great word.","58ef3b23":"After exploring the data a bit, I'm choosing two features to use as our guinea pigs for scaling. \n* alcohol - a nice and sort of normal series, which will be useful to see how the scaler deals with\n* color_intensity - a skewed series, with some clear outliers\n\nHere's what the graphs look like without any scaling. Note the levels of the axes, alcohol ranges from 11~15 and color_intensity ranges from 1~13\n\nNote the graphs are all univariate plots. That's intentonal (for now)","3f941b2a":"<a id=\"section-six\"><\/a>\n## 6. Quantile Transformer\nFor when you just need to scale your data with a sledgehammer. This allows you to specify either a uniform or normal distribution and essentially forces the data into this shape. How far is this really from just generating a random normal distribution?\n","9e30d076":"<a id=\"section-zero\"><\/a>\n## 0. The Data\n\nI will be using the Sklearn built in Wine database. It's intended for use in classification exercises, with the target being an undescribed classification of 0, 1 or 2. I assume it's White, Red, Rose (not in that order), but it was hard to find full information on this.\n\nRegardless, since we're only looking to visualise what the scalers do, I'm just going to pick a feature or two."}}