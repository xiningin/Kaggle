{"cell_type":{"4adb24f2":"code","c1f26a1d":"code","0f149e2e":"code","d4ea8416":"code","a4559528":"code","482b3997":"code","2619d3da":"code","654a5278":"code","1b91fd62":"code","9f4810d1":"code","d9532f04":"code","0d6ebae0":"code","a32102d3":"code","87451027":"code","d244994b":"code","8541a696":"code","e523036d":"code","36ffaa8f":"code","ded0b222":"code","c27c434c":"code","117c8f34":"code","4c574a50":"markdown","8da8ac96":"markdown","c8c17579":"markdown","c8231fba":"markdown","7a5d06f3":"markdown","0622c537":"markdown","d5c47242":"markdown","35b55703":"markdown","3ea2ad0e":"markdown","d235efb5":"markdown","c8a24db3":"markdown","b5505f47":"markdown","b7284dd4":"markdown","6542db9f":"markdown","1643e9c1":"markdown"},"source":{"4adb24f2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","c1f26a1d":"import spacy\nfrom spacy import displacy\nnlp = spacy.load('en_core_web_sm')\n\nfrom spacy.matcher import Matcher \nfrom spacy.tokens import Span \n\nimport spacy\nfrom spacy.lang.en import English\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\n\npd.set_option('display.max_colwidth', 200)\n%matplotlib inline","0f149e2e":"\ntext=pd.read_csv(\"..\/input\/wiki-sentences-v2csv\/wiki_sentences_v2.csv\")\ntext.head()","d4ea8416":"doc = nlp(\"Dutch-born audiovisual artist, currently living in Los Angeles\")\n\nfor tok in doc:\n  print(tok.text, \"------>\", tok.dep_)","a4559528":"def get_entities(sent):\n \n  ent1 = \"\"\n  ent2 = \"\"\n\n  prv_tok_dep = \"\"    \n  prv_tok_text = \"\"   \n\n  prefix = \"\"\n  modifier = \"\"\n\n  \n  \n  for tok in nlp(sent):\n    \n    if tok.dep_ != \"punct\":\n     \n      if tok.dep_ == \"compound\":\n        prefix = tok.text\n        \n        if prv_tok_dep == \"compound\":\n          prefix = prv_tok_text + \" \"+ tok.text\n      \n     \n      if tok.dep_.endswith(\"mod\") == True:\n        modifier = tok.text\n       \n        if prv_tok_dep == \"compound\":\n          modifier = prv_tok_text + \" \"+ tok.text\n      \n     \n      if tok.dep_.find(\"subj\") == True:\n        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n        prefix = \"\"\n        modifier = \"\"\n        prv_tok_dep = \"\"\n        prv_tok_text = \"\"      \n\n     \n      if tok.dep_.find(\"obj\") == True:\n        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n        \n      \n      \n      prv_tok_dep = tok.dep_\n      prv_tok_text = tok.text\n \n\n  return [ent1.strip(), ent2.strip()]\n        \n","482b3997":"get_entities(\"is the debut studio album of \")","2619d3da":"text[22:26]","654a5278":"get_entities(\"the album was released digitally on august\")","1b91fd62":"entity_pairs = []\n\nfor i in tqdm(text[\"sentence\"]):\n  entity_pairs.append(get_entities(i))","9f4810d1":"entity_pairs[0:5]","d9532f04":"def get_relation(sent):\n\n  doc = nlp(sent)\n\n  # Matcher class object \n  matcher = Matcher(nlp.vocab)\n\n  #define the pattern \n  pattern = [{'DEP':'ROOT'}, \n            {'DEP':'prep','OP':\"?\"},\n            {'DEP':'agent','OP':\"?\"},  \n            {'POS':'ADJ','OP':\"?\"}] \n\n  matcher.add(\"matching_1\", None, pattern) \n\n  matches = matcher(doc)\n  k = len(matches) - 1\n\n  span = doc[matches[k][1]:matches[k][2]] \n\n  return(span.text)","0d6ebae0":"get_relation(\"the album was released digitally on august\")","a32102d3":"relations = [get_relation(i) for i in tqdm(text['sentence'])]","87451027":"source = [i[0] for i in entity_pairs]\n\n# extract object\ntarget = [i[1] for i in entity_pairs]\n\nkg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relations})","d244994b":"G=nx.from_pandas_edgelist(kg_df, \"source\", \"target\", \n                          edge_attr=True, create_using=nx.MultiDiGraph())","8541a696":"plt.figure(figsize=(12,12))\n\npos = nx.spring_layout(G)\nnx.draw(G, with_labels=True, node_color='teal', edge_cmap=plt.cm.Blues, pos = pos)\nplt.show()","e523036d":"kg_df[20:30]","36ffaa8f":"G=nx.from_pandas_edgelist(kg_df[kg_df['edge']==\"released\"], \"source\", \"target\", \n                          edge_attr=True, create_using=nx.MultiDiGraph())\n\nplt.figure(figsize=(12,12))\npos = nx.spring_layout(G, k = 0.5)\nnx.draw(G, with_labels=True, node_color='teal', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos)\nplt.show()","ded0b222":"G=nx.from_pandas_edgelist(kg_df[kg_df['edge']==\"ended\"], \"source\", \"target\", \n                          edge_attr=True, create_using=nx.MultiDiGraph())\n\nplt.figure(figsize=(12,6))\npos = nx.spring_layout(G, k = 0.5)\nnx.draw(G, with_labels=True, node_color='teal', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos)\nplt.show()","c27c434c":"kg_df[55:60]","117c8f34":"G=nx.from_pandas_edgelist(kg_df[kg_df['edge']==\"include\"], \"source\", \"target\", \n                          edge_attr=True, create_using=nx.MultiDiGraph())\n\nplt.figure(figsize=(12,12))\npos = nx.spring_layout(G, k = 0.8)\nnx.draw(G, with_labels=True, node_color='teal', node_size=1200, edge_cmap=plt.cm.Blues, pos = pos)\nplt.show()","4c574a50":" Knowledge Graph for \"edge\" cloumn values(edge=relations)","8da8ac96":"steps:\n*     Tokenization,\n*     if the previous word was also a 'compound' then add the current word to it\n*     if the token is the subject, then it will be captured as the first entity in the ent1 variable\n*     if the token is the object, then it will be captured as the second entity in the ent2 variable\n*     Captured the subject and the object in the sentence,updated","c8c17579":"### c.Relation \/ Predicate Extraction <a id=\"KG33\"><\/a> <br>\n\n Hypothesis is that the predicate is actually the main verb in a sentence. \n \n For example, in the sentence \u2013 \u201cthe album was **released** digitally on august\u201d, the verb is \u201c**released** in\u201d and this is what we are going to use as the predicate for the triple generated from this sentence.","c8231fba":"![](https:\/\/www.csee.umbc.edu\/courses\/graduate\/691\/fall19\/07\/images\/kg_header.png)\n\n## 1.What is Knowledge Graph?<a id=\"KG1\"><\/a> <br>\n\nA Knowledge Graph is a model of a knowledge domain created by subject-matter experts with the help of intelligent machine learning algorithms. It provides a structure and common interface for all of your data and enables the creation of smart multilateral relations throughout your databases. Structured as an additional virtual data layer, the Knowledge Graph lies on top of your existing databases or data sets to link all your data together at scale \u2013 be it structured or unstructured.\n\n","7a5d06f3":"Relations from all the Wikipedia sentences ","0622c537":"### a.Tokenization <a id=\"KG31\"><\/a> <br>\n**Tokenization** and sentence **segmentation** in Stanza are jointly performed by the *TokenizeProcessor*. This processor splits the raw input text into tokens and sentences, so that downstream annotation can happen at the sentence level. This processor can be invoked by the name *tokenize*.\n \n![](https:\/\/miro.medium.com\/max\/1107\/1*N1YsdSJihlzJrvYBUDI-_A.jpeg) ","d5c47242":"**References**\n* https:\/\/medium.com\/@edezhic\/understanding-knowledge-graphs-5cb05593eb84\n* https:\/\/medium.com\/octavian-ai\/deep-learning-with-knowledge-graphs-3df0b469a61a\n* https:\/\/stackabuse.com\/python-for-nlp-parts-of-speech-tagging-and-named-entity-recognition\/\n* https:\/\/www.analyticsvidhya.com\/blog\/2019\/10\/how-to-build-knowledge-graph-text-using-spacy\/","35b55703":"## 3.Example of Knowledge Graph with Spacy <a id=\"KG3\"><\/a> <br>\n\n\nTo build a knowledge graph from the text, it is important to make our machine understand natural language. This can be done by using **NLP** techniques such as **sentence segmentation**, **dependency parsing**, **parts of speech tagging**, **and entity recognition**","3ea2ad0e":"Importing Wikipedia Sentences","d235efb5":"### b.Parts of Speech (POS) Tagging <a id=\"KG32\"><\/a> <br>\nParts of speech tagging simply refers to assigning parts of speech to individual words in a sentence, which means that, unlike phrase matching, which is performed at the sentence or multi-word level, parts of speech tagging is performed at the token level.WithPOS,The nouns and the proper nouns would be our entities \n\n**Named entity recognition (NER)**, also known as entity chunking\/extraction , is a popular technique used in information extraction to identify and segment the named entities and classify or categorize them under various predefined classes.","c8a24db3":"I'll create a Knowledge Graph for COVID-19 dataset in future","b5505f47":"## 2.How Does It Work?<a id=\"KG2\"><\/a> <br>\n\n\n![](https:\/\/miro.medium.com\/max\/1050\/1*x4SmgMrwe7BLmFk0sbwgew.png)\n\nElementary unit of a knowledge graph is a triplet subject-predicate-object, often denoted as (head, relation, tail) or (h, r, t)\n\n\nOrdinary query to a knowledge base looks like this: find entity by name \u201cArthur Cayley\u201d, find tail of his \u201cHometown\u201d relation and return it\u2019s \u201cName\u201d property. As a result you should probably get \u201cLondon\u201d.\n\n","b7284dd4":" *prv_tok_dep* and *prv_tok_text* will hold the dependency tag of the previous word in the sentence and that previous word itself, respectively","6542db9f":"use this function to extract these entity pairs for all the sentences","1643e9c1":"\n### **Introduction**\n1. [**What is Knowledge Graph?**](#KG1)\n2. [**How Does It Work?**](#KG2)\n3. [**Examples Knowledge Graph with Spacy**](#KG3) <br>\n    1.[**Tokenization**](#KG31)<br>\n    2.[**Parts of Speech (POS) Tagging**](#KG32)<br>\n    3.[**Relation \/ Predicate Extraction**](#KG33)<br>\n\n\n"}}