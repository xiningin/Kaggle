{"cell_type":{"4a49f70a":"code","a31a3d7f":"code","a68d9398":"code","d23e5d6b":"code","1d4a06ee":"code","48c8501d":"code","dbdb3528":"code","12245370":"code","2a07c582":"code","deb20c05":"code","6a0ec2bb":"code","b24be231":"code","ffda34e4":"code","4df558a4":"code","c9cce8d2":"code","b55dc33b":"code","8000677a":"code","e4d53ed1":"code","77dd8a03":"code","af791db1":"code","6382a665":"code","9ba891c2":"code","6d2429e1":"code","9501868d":"code","7b9ec1bb":"code","02213b09":"code","0e796c66":"code","181ff863":"code","98c5e94d":"code","c38ddd76":"code","9a8ea902":"code","c33c0d83":"code","aa4cd208":"code","127d128d":"code","9a5f6140":"code","ccdf7ed1":"code","94733dce":"code","d61ffa30":"code","809f0e93":"code","e1811ac9":"code","09c611e6":"code","4bd0a7b5":"markdown","c83d12a9":"markdown","8ef9eecd":"markdown","a7a3d47a":"markdown","697a4e7c":"markdown","b0294f45":"markdown","13254ac2":"markdown"},"source":{"4a49f70a":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n%matplotlib inline","a31a3d7f":"data = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","a68d9398":"data.sample(5)","d23e5d6b":"#customer id is a waste as it is not req for our prediction so lets drop it\ndata.drop(labels = ['customerID'],axis='columns',inplace=True)","1d4a06ee":"data.dtypes","48c8501d":"#as we can se the totalcharges is string and monthly is number so lets \n#get our dataset in a correct dtype\n# pd.to_numeric(data.TotalCharges)\n# this will currently give error as there are somevalue which have space\n#so lets settle that out.","dbdb3528":"pd.to_numeric(data.TotalCharges,errors='coerce').isnull()","12245370":"data[pd.to_numeric(data.TotalCharges,errors='coerce').isnull()]","2a07c582":"new_df = data[data.TotalCharges!=' '] #lets drop that columns.\nnew_df.shape #total 11 rows are deleted. ","deb20c05":"#now lets do the same thing\nnew_df.TotalCharges = pd.to_numeric(new_df.TotalCharges)","6a0ec2bb":" new_df.dtypes","b24be231":"#Now lets do some quick visualization.\ntenure_churn_no = new_df[new_df.Churn=='No'].tenure\ntenure_churn_yes = new_df[new_df.Churn=='Yes'].tenure","ffda34e4":"plt.xlabel('Number of Customer')\nplt.ylabel('Customer Churn Prediction Visualization')\n\nplt.hist([tenure_churn_yes,tenure_churn_no],color=['green','red'],label=['Churn=Yes','Churn=No'])\nplt.legend()","4df558a4":"#lets see for monthly charges\nmc_churn_no = new_df[new_df.Churn=='No'].MonthlyCharges\nmc_churn_yes = new_df[new_df.Churn=='Yes'].MonthlyCharges\n\nplt.xlabel('Monthly Charges')\nplt.ylabel('Number of Customers')\nplt.title('Customer Churn Prediction Visualization')\n\nblood_sugar_men = [113,85,90,150,149,88,93,115,135,80,77,82,129]\nblood_sugar_women =[67,98,89,120,133,150,84,69,89,79,120,112,100] \n\nplt.hist([mc_churn_yes,mc_churn_no],rwidth=0.95,color=['green','red'],label=['Churn=Yes','Churn=No'])\nplt.legend()","c9cce8d2":"def print_unique_col_value(data):\n    for column in data:\n        if data[column].dtypes=='object':\n            print(f'{column}:{data[column].unique()}')\n    ","b55dc33b":"print_unique_col_value(new_df) #so these are our catagorical columns","8000677a":"#Lets clean our dataset\nnew_df.replace('No internet service','No',inplace=True)\nnew_df.replace('No phone service','No',inplace=True)","e4d53ed1":"print_unique_col_value(new_df)","77dd8a03":"#Now lets replace yes and no with maybe 1 and 0\nyes_no_columns = ['Partner','Dependents','PhoneService','MultipleLines',\n                 'OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport',\n                 'StreamingTV','StreamingMovies','PaperlessBilling','Churn'] #all cloumn with yes and no\n\nfor col in yes_no_columns:\n    new_df[col].replace({'Yes':1,'No':0},inplace=True)","af791db1":"for col in new_df:\n    print(f'{col}:{new_df[col].unique()}')","6382a665":"new_df['gender'].replace({'Female':1,'Male':0},inplace=True)","9ba891c2":"new_df['gender'].unique()","6d2429e1":" new_df1 = pd.get_dummies(data=new_df,columns=['InternetService','Contract','PaymentMethod'])","9501868d":"new_df1.columns","7b9ec1bb":"new_df1.sample(4) #Now our data look quite.","02213b09":"#Now lets see the datatype... as we can see all are number which is quite great\nnew_df1.dtypes","0e796c66":"#Now lets scale our data.\n#so the columns to be scal are tenure,MonthlyCharges,TotalCharges\n#as they are nit in range 0-1\n#We will use min-max or normalization.\ncols_to_scale = ['tenure','MonthlyCharges','TotalCharges']\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nnew_df1[cols_to_scale] = scaler.fit_transform(new_df1[cols_to_scale])","181ff863":"#Now our dataframe is scale and used for prediction\n#We are done with preprocessing,\nfor col in new_df1:\n    print(f'{col}:{new_df1[col].unique()}')","98c5e94d":"def neural_net(x_train,y_train,x_test,y_test):\n    import tensorflow as tf\n    from functools import partial\n    from tensorflow import keras\n    from sklearn.metrics import confusion_matrix,classification_report\n\n\n    model = keras.Sequential(\n        [\n            keras.layers.Dense(20,input_shape=(26,),activation='relu'),\n            keras.layers.Dropout(0.3),\n            keras.layers.Dense(10,activation='relu'),\n            keras.layers.Dropout(0.3),\n            keras.layers.Dense(5,activation='relu'),\n            keras.layers.Dropout(0.3),\n            keras.layers.Dense(1,activation='sigmoid'),\n        ]\n    )\n\n    model.compile(optimizer ='adam',\n                 loss='binary_crossentropy',\n                 metrics=['accuracy'])\n\n    # model.fit(x_train,y_train,epochs=5)\n    model.fit(x_train,y_train,epochs=50,batch_size=8)\n\n    model.evaluate(x_test,y_test)\n    y_pred = model.predict(x_test)\n    y_pred_actual = []\n    for ele in y_pred:\n        if ele > 0.5:\n            y_pred_actual.append(1)\n        else :\n            y_pred_actual.append(0)\n\n    \n    print(\"Classification Reports is:\\n\",classification_report(y_test,y_pred_actual))\n    \n    return y_pred_actual","c38ddd76":"from sklearn.model_selection import train_test_split\nX = new_df1.drop('Churn',axis=1)\ny = new_df1['Churn']\n\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=15,stratify=y)","9a8ea902":"y_train.value_counts()","c33c0d83":"y_test.value_counts()","aa4cd208":"y_preds = neural_net(x_train,y_train,x_test,y_test)","127d128d":"\nimport seaborn as sns\nimport tensorflow as tf\ncm = tf.math.confusion_matrix(labels=y_test,predictions=y_preds)\n\nplt.figure(figsize=(9,7))\nsns.heatmap(cm,annot=True,fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","9a5f6140":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE(sampling_strategy ='minority')\nx_sm, y_sm = smote.fit_resample(X,y)","ccdf7ed1":"y_sm.value_counts() #Now our dataset is balanced.","94733dce":"x_train,x_test,y_train,y_test = train_test_split(x_sm,y_sm,test_size=0.2,random_state=15,stratify=y_sm)","d61ffa30":"y_train.value_counts() #balanced train dataset","809f0e93":"y_test.value_counts() #balanced test dataset","e1811ac9":"y_preds = neural_net(x_train,y_train,x_test,y_test)","09c611e6":"import seaborn as sns\nimport tensorflow as tf\ncm = tf.math.confusion_matrix(labels=y_test,predictions=y_preds)\n\nplt.figure(figsize=(9,7))\nsns.heatmap(cm,annot=True,fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')","4bd0a7b5":"### lets look at confusion matrix","c83d12a9":"### Lets see confusion matrix","8ef9eecd":"## We will use SMOTE (Over sampling by producing syntetic samples) \n**One can refer other methods of balancing :- https:\/\/towardsdatascience.com\/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb**","a7a3d47a":"## Training of Unbalanced Dataset :-","697a4e7c":"## As we can see the f1-score for 1 class is .62 lets Balance our dataset and see the difference","b0294f45":"## As We can see our dataset is imbalanced. Now see the difference between training of unbalanced dataset vs balanced dataset","13254ac2":"## Conclusion :-\n**Balancing the dataset not only helps us improve f1-score of classes in classification problem but also helps improve accuracy.So tackling a unbalanced datset is must.<br>**\n<h6>*Note:- the epochs of neural network is 50 maybe more epochs may result in better result*<\/h6>"}}