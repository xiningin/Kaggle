{"cell_type":{"29bc9987":"code","f1ccf582":"code","6664c0d7":"code","af876cc5":"code","15fabab4":"code","c2568ae9":"code","898f7497":"code","6a51edb1":"code","93eb2696":"code","cd9cd09c":"code","5086326e":"code","ae42b620":"code","d6f48d8d":"code","59272b5e":"code","a89f1a58":"code","1f639c91":"code","15505932":"code","15db658c":"code","0be7a5f2":"code","d5e796b6":"code","fdd86444":"code","da82c77e":"code","6f6647ec":"code","e61e037b":"code","3d39e8a9":"code","b2366a1d":"code","c576f0e5":"code","c3258b2f":"markdown","a7cad1cf":"markdown","28978b17":"markdown","e7cc3ea1":"markdown","0433c540":"markdown","10ccc569":"markdown","bafb610a":"markdown","954090e5":"markdown","e8b208a7":"markdown","fb41b91f":"markdown","317cc831":"markdown","2fdfd63b":"markdown","dd71eb97":"markdown","fc2ba1ab":"markdown","3680ac7d":"markdown","071236e3":"markdown","bb3c621a":"markdown","63dc8e6a":"markdown","09e1e083":"markdown"},"source":{"29bc9987":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f1ccf582":"train_data=pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_data=pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","6664c0d7":"train_data.head()","af876cc5":"test_data.head()","15fabab4":"sample_submission=pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\nsample_submission.head()","c2568ae9":"from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten,BatchNormalization,LeakyReLU,ReLU\nfrom tensorflow.keras.models import Sequential,load_model\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split","898f7497":"trainX=train_data.iloc[:,1:].to_numpy()\ntrainY=train_data.iloc[:,0].to_numpy()\nprint(\"train X shape: \", trainX.shape)\nprint(\"train Y shape: \", trainY.shape)\ntestX=test_data.to_numpy()\nprint(\"test X shape: \", testX.shape)","6a51edb1":"trainX=trainX.reshape((-1,28,28,1))\ntrainY=to_categorical(trainY,num_classes = 10)\ntestX=testX.reshape((-1,28,28,1))\nprint(\"train X shape: \", trainX.shape)\nprint(\"train Y shape: \", trainY.shape)\nprint(\"test X shape: \", testX.shape)","93eb2696":"trainX=trainX\/255.0\ntestX=testX\/255.0","cd9cd09c":"tX,vX,tY,vY=train_test_split(trainX,trainY,test_size=0.2,stratify=trainY,random_state=11)","5086326e":"print(\"train X shape: \", tX.shape)\nprint(\"train Y shape: \", tY.shape)\nprint(\"validation X shape: \", vX.shape)\nprint(\"validation y shape: \", vY.shape)","ae42b620":"def plot_images(images, cls_true, cls_pred=None,w=3,h=3):\n    assert len(images) == len(cls_true)\n    fig, axes = plt.subplots(w, h)\n    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i].reshape((28,28)), cmap='binary')\n        if cls_pred is None:\n            xlabel = \"True: {0}\".format(cls_true[i])\n        else:\n            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n        ax.set_xlabel(xlabel)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","d6f48d8d":"plot_images(tX[0:9],np.argmax(tY[0:9],axis=1))","59272b5e":"model=Sequential()\nmodel.add(Conv2D(input_shape=(28,28,1),filters=64,kernel_size=(5,5),padding='same'))\nmodel.add(Conv2D(filters=64,kernel_size=(5,5),padding='same',strides=2))\nmodel.add(LeakyReLU())\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),padding='same'))\nmodel.add(Conv2D(filters=32,kernel_size=(2,2),padding='same',strides=2))\nmodel.add(LeakyReLU())\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=16,kernel_size=(3,3),padding='same'))\nmodel.add(Conv2D(filters=16,kernel_size=(2,2),padding='same',strides=2))\nmodel.add(LeakyReLU())\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(LeakyReLU())\nmodel.add(Dense(512))\nmodel.add(LeakyReLU())\nmodel.add(Dense(256))\nmodel.add(LeakyReLU())\nmodel.add(Dense(64))\nmodel.add(LeakyReLU())\nmodel.add(Dense(10,activation='softmax'))","a89f1a58":"model.summary()","1f639c91":"model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])","15505932":"from keras.preprocessing.image import ImageDataGenerator","15db658c":"datagen = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False, \n        zca_whitening=False,\n        rotation_range=20, \n        zoom_range = 0.2, \n        width_shift_range=0.2, \n        height_shift_range=0.2,\n        horizontal_flip=False, \n        vertical_flip=False\n)","0be7a5f2":"datagen.fit(tX)","d5e796b6":"train_datagen=datagen.flow(tX,tY,batch_size=128)","fdd86444":"for i in range(5):\n    img=train_datagen.next()\n    plot_images(img[0],np.argmax(img[1],axis=1))","da82c77e":"checkpointer = ModelCheckpoint(filepath='best_model.h5',\n                               monitor=\"val_accuracy\",\n                               mode=\"max\",\n                               verbose=1, \n                               save_best_only=True)\nearly_stop=EarlyStopping(monitor='val_accuracy', \n                         min_delta=0, \n                         patience=10, \n                         verbose=1, \n                         mode='max',\n                         baseline=None, \n                         restore_best_weights=False)\nreduce_lr=ReduceLROnPlateau(monitor='val_accuracy', \n                            factor=0.1,\n                            patience=3, \n                            verbose=1, \n                            mode='max', \n                            min_delta=0.0001, \n                            cooldown=0, \n                            min_lr=0)","6f6647ec":"history=model.fit_generator(train_datagen,\n                            steps_per_epoch=len(tX)\/\/128,\n                            validation_data=(vX,vY),\n                            epochs=200,\n                            callbacks=[checkpointer,early_stop,reduce_lr])","e61e037b":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","3d39e8a9":"model=load_model('best_model.h5')","b2366a1d":"testY=model.predict(testX)\npredictions=np.argmax(testY,axis=1)","c576f0e5":"df=pd.DataFrame()\ndf['ImageId']=[x for x in range(1,len(testX)+1)]\ndf['Label'] = predictions\ndf[['ImageId','Label']].to_csv(\"submission.csv\", index=False)\nprint(df[['ImageId','Label']].head(20))\nplot_images(testX[100:200],np.argmax(testY[100:200],axis=1),w=5,h=5)\nprint(\"Done!\")\nprint(testX.shape)","c3258b2f":"lets train our model","a7cad1cf":"Define our convolutional neural network","28978b17":"prints out first five rows of testing data","e7cc3ea1":"lets predicts values for our test dataset","0433c540":"creating a *submission,csv* file to submit","10ccc569":"visulizing the augmented images","bafb610a":"plotting loss and accuracy graph","954090e5":"seperating data into input data and labels. *trainX* variable stores input data and *trainY* contains labels for input images.","e8b208a7":"Utitlity function to plot images with true class labels and predicted class labels","fb41b91f":"Import all dependencies","317cc831":"divide data to training and validation sets","2fdfd63b":"Image augmentation for reduce model overfitting ","dd71eb97":"lets normalize our images pixel values between 0 and 1","fc2ba1ab":"Lets read data using pandas `read_csv` method","3680ac7d":"Lets see what csv data format we have to submit. visualize sample submission file","071236e3":"prints out first five rows of training data","bb3c621a":"Loading our best model","63dc8e6a":"lets format input 784 image pixels into 28X28 image sizes so that we can feed it into convolutional neural network. Also lets change our labels to one hot encoded vectors","09e1e083":"Initializing model callbacks functions"}}