{"cell_type":{"b491750a":"code","7cecdf3c":"code","60b055aa":"code","b7035aa1":"code","236bd849":"code","5e614ada":"code","89d1f756":"code","42fa8c72":"code","06e6d413":"code","3d5811d6":"code","09dae889":"code","8037051a":"code","1e846d6b":"code","46ebf0a4":"code","779dcdb3":"code","7151336a":"code","9dbdefb0":"code","e3316800":"code","0a0c2305":"code","eeac1f60":"code","b0e9d493":"code","2de78565":"code","56c4f65d":"code","6c92fc97":"code","7e7453e3":"code","1498684d":"code","fc1ebf1c":"code","0473f66d":"code","838bfe15":"code","b7983f3b":"code","1ec0058c":"markdown","1c8c8644":"markdown","84316dec":"markdown","ce83a9b9":"markdown","51c04a7d":"markdown","73b0a670":"markdown","ad7586fe":"markdown","169faa44":"markdown","89c88ef7":"markdown","87adc2c8":"markdown","36001ae7":"markdown","3d95d80b":"markdown","63d17ae4":"markdown","098b6912":"markdown","23043619":"markdown","74a1a4c5":"markdown","3bdac459":"markdown","b2e71f9c":"markdown","1071e131":"markdown","46a70e0e":"markdown","c87652d0":"markdown","5f4c5a1a":"markdown","e5e9dbdf":"markdown","0f918f78":"markdown","11f7d645":"markdown","cb4e5b50":"markdown","27ee4ce7":"markdown","b6df064d":"markdown","6569dd5f":"markdown","44b79f13":"markdown","7c5f0fdb":"markdown","c317d791":"markdown","508b2035":"markdown","9b4b197c":"markdown","4db7715d":"markdown","2310adbb":"markdown","24afb50a":"markdown","1abdcb0b":"markdown","503ed96d":"markdown","927eeebc":"markdown","463fc6fc":"markdown","054657d7":"markdown"},"source":{"b491750a":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","7cecdf3c":"# import the tabular data manipulation and analysis library: pandas as pd\n# TODO\n\n# import thel linear algebra library: numpy as np\n#TODO\n\n# import machine learning model library: sklearn as sk\n#TODO\n\n# import visualization libraries: matplotlib, seaborn\nfrom matplotlib import pyplot as plt \nimport seaborn as sns","60b055aa":"# Read the variable into a pandas DataFrame\nfulldata= # TODO put in the read_csv() function here","b7035aa1":"# Take a peek at top-10 rows of data using the head function of dataframe\n# TODO use the head command to view data","236bd849":"pd.options.display.max_columns=50 # increase the number of columns displayed without truncation\npd.options.display.max_rows=999 # increase the number of rows displayed without truncation","5e614ada":"# Take a peek at top-10 rows of data using the head function of the dataframe\n# TODO check the head function","89d1f756":"# Use shape attribute of DataFrame object to obtain size\n# TODO put in the shape command here","42fa8c72":"# Replace all rows having education==6 with education = 5\n# .loc command allows us to replace values in columns and rows of a dataFrame\n# Format of loc command DataFrame.loc[rowCriteria,colCriteria]=VALUE\n# TODO .loc command to replace value 6 with value 5","06e6d413":"# Check the current dtype\nfulldata.dtypes","3d5811d6":"# Correct the dtypes for categorical variables\nfulldata['ID']=fulldata['ID'].astype(object)\nfulldata['SEX']=fulldata['SEX'].astype(object)\nfulldata['EDUCATION']=fulldata['EDUCATION'].astype(object)\nfulldata['MARRIAGE']=fulldata['MARRIAGE'].astype(object)","09dae889":"# Re-check the current dtype\nfulldata.dtypes","8037051a":"# convert ID as the index for the dataframe\nfulldata=fulldata.set_index('ID')\nfulldata.head()","1e846d6b":"# Use describe() function of pandas DataFrame to get a summary of all numeric attributes. Use a .T at the end of the function call to make the output more readable\n# TODO fill in the describe command here","46ebf0a4":"# Use KDE PLOT to get detailed distribution for each attribute\nfor aCol in fulldata.columns:\n    if fulldata[aCol].dtype==object:\n        continue\n    print('Column:',aCol)\n    sns.kdeplot(fulldata[aCol],shade=True)\n    plt.show()","779dcdb3":"# Use _value_counts() to plot values using histogram\nfor aCol in fulldata.columns:\n    if fulldata[aCol].dtype==object:\n        if aCol=='ID':\n            continue\n        print(aCol)\n        print('----------------------------')\n#         plt.figure(figsize=(15,5))\n        sns.barplot(fulldata[aCol].value_counts().index,fulldata[aCol].value_counts())\n        plt.show()\n        print(fulldata[aCol].value_counts())","7151336a":"rseed=11 # ensures reproducibility of results, detailed later","9dbdefb0":"from sklearn.model_selection import train_test_split # helps split the data into multiple components","e3316800":"# split into X and y\nfullX=fulldata.iloc[:,:-1]\nfully=fulldata.iloc[:,-1]","0a0c2305":"# use train validation test split using command from sklearn to split into Train, Validation and Test\n# TODO use train_test_split() to split the fullX and fullY","eeac1f60":"# convert categorical to one hot\ncatCols=[]\ni=-1\nfor aCol in trainX.columns:\n    i+=1\n    if trainX[aCol].dtype != object:\n        continue\n    catCols.append(i)\n    print(aCol)\nprint('Categorical Features:',catCols)\nohe=sk.preprocessing.OneHotEncoder(categorical_features=catCols)\nohe=ohe.fit(trainX)\ntrainX2=pd.DataFrame(ohe.transform(trainX).toarray())\ntestX2=pd.DataFrame(ohe.transform(testX).toarray())","b0e9d493":"# checking what trainX2 looks like\n# TODO use the head command here","2de78565":"# values identified\nohe.categories_","56c4f65d":"# comparing with initial dataframe\ntrainX.head()","6c92fc97":"# import decision tree module from sklearn\nfrom sklearn.tree import DecisionTreeClassifier\n\n# create a DecisiopnTreeClassifier() object\nmodel=... # TODO createa a decision tree classifier","7e7453e3":"# use the fit function on the model to train the model using training data features and training data labels as parameters\n# syntax model.fit(training data features, training data labels)\n# TODO put the fit() command here","1498684d":"# use the predict function on training and test data to come up with training data predictions\n# syntax model.predict(features)\ntrainp=... # call the predict function on train features\ntestp=... # call the predict function on test features","fc1ebf1c":"print('training dataset accuracy:',sk.metrics.accuracy_score(trainy,trainp))","0473f66d":"print('test dataset accuracy:',...) # TODO fill in the ... with accuracy_score function for test data","838bfe15":"print('TRAINING DATA')\nplt.figure(figsize=(4,4))\nsns.heatmap(sk.metrics.confusion_matrix(trainy,trainp),annot=True,fmt='d',linewidths=0.5,annot_kws={'size':20})\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","b7983f3b":"print('TESTING DATA')\nplt.figure(figsize=(4,4))\nsns.heatmap(sk.metrics.confusion_matrix(testy,testp),annot=True,fmt='d',linewidths=0.5,annot_kws={'size':20})\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","1ec0058c":"# Train Model","1c8c8644":"# Feature Creation","84316dec":"**Observation**\n- What is odd about attribute values for marriage and education, compared to data dictionaries\n    - TODO","ce83a9b9":"**P4. Study attribute value distribution**\n\n***Numerical Attributes***","51c04a7d":"- Since algorithms expect everything to be numeric, we need to modify the categorical variables to numeric columns before feeding them to the model\n- One-hot encoding is a way to convert categorical variables to numeric columns\n\n**Converting all categorical variables to numeric variables using an object of OneHotEncoder**","73b0a670":"**P3. Ensure correctness the data type for each attribute**\n\nGiven some attributes look like numbers but are categories we need to ensure that pandas treats them as categorical attributes and not numbers","ad7586fe":"**Observations**\n* No. of columns having one or more missing value is 0\n* % of cases having default is 22%\n* median age in the dataset is 34 while minimum is 21","169faa44":"# Setup","89c88ef7":"- Once predictions are available, model performance can be evaluated using functions like accuracy_score() from sklearn.metrics module\n\n### Metric: Accuracy\n\n**Estimate the accuracy score for training and test datasets**","87adc2c8":"Python has a suite of libraries that are aimed at data science. Few commonly used libraries of python are:\n* pandas : meant for tabular data manipulation and analysis library\n* numpy : meant for linear algebra operations\n* scikit-learn : meant for machine learning and statistial models\n* matplotlib and seaborn : meant for visualizations and graphs\n* nltk : meant for natural language processing\n\n**Import the necessary libraries for our notebook**","36001ae7":"**Todo**\n- Education has 2 values that are unknown => merge the two values\n- Categorical attributes have been defined using numeric values => ensure pandas treats categorical attributes as categorical\n- ID column is not a useful attribute and should be used as the index for rows","3d95d80b":"***Categorical Attribute***","63d17ae4":"- The notebook has been created as a solution to a handson training session, introduction to machine learning\n- This notebook is converted to fill-in-the-blanks that trainees can use during the session. The main notebook with no blanks is Base\n- Template_1 has less blanks than this notebook","098b6912":"- Q. What variable in the data holds the label ?\n    - A. TODO\n- Q. What are the attribute variables in the data ?\n    - A. TODO\n- Q. How can one describe a row in the above dataset ?\n    - A. TODO","23043619":"### Library Imports","74a1a4c5":"- We will use pandas and it's functions to load and maintain data in the notebook\n- Read the data into a pandas dataframe using read_csv() function of pandas\n    - pd.read_csv(*file_to_read*)\n    - location of file: *\/kaggle\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv*\n    - Returns: Pandas dataframe holding the data\n- You can view top n-rows of the data in a DataFrame using the function head(n)","3bdac459":"**P2. What information is available in the data ?**\n- Input: Raw Data\n- Output: Detailed understanding of features and rows of the data","b2e71f9c":"- Before we begin the model development exercise we need to understand the data available, its quantity and its quality\n- Load the data and try answering the following questions that form the first impression of the data\n    1. Understand how big the data is, number of rows, number of columns, size in MBs\/GBs\/TBs\n    1. What is the label variable ?\n    1. What attributes are available in the data to predict the label ?","1071e131":"describe() function of pandas DataFrame gets a summary of all numeric attributes. It can be pushed to get summary for non-numeric attributes too but that part is not comprehensive so we don't use it that often.\n\nUse describe() function below to get profile summary of numeric attributes","46a70e0e":"# Data Split: Training data and Test data","c87652d0":"# Model Performance Evaluation","5f4c5a1a":"- There are many models that can be used for classification, like, Logistic Regression, Decision Trees and Neural Networks\n- Various models differ in what types of rules they can create to do classification and how they discovered those rules from the data\n- We will try Decision Trees for classifying our data in this exercise\n- Decison trees create a rules in form of a tree like flowchart\n- Decision trees are available in sklearn.tree library in form of class DecisionTreeClassifier\n\n**Create a decision tree classifier and train it using training data prepared above**","e5e9dbdf":"- Although accuracy looks great, note that we can obtain an accuracy of 78% without any learning algorithm\n- Because of above accuracy is not a widely used metric for classification problems\n- Instead of accuracy people use other metrics like Precision, Recall and F1 to capture model performance\n- Most of the metrics are based on confusion matrix which is what we would like to work on next","0f918f78":"### Kaggle Data Location","11f7d645":"**Split the read data into training and test data points in the ratio 8:2**\n- Function train_test_split in sklearn.model_selection package provides a functionality to split training and test data sets\n- Typically different runs of training and test data split give different results due to randomization\n- To ensure that we get same results with each randomization, we provide a specific random_state value to the train_test_split function","cb4e5b50":"**P1. What is the size of the data ?**\n- Input: Raw Data\n- Output:\n    - Number of rows\n    - Number of columns\n    - *Number of files*\n    - *Size of files*\n\nshape attribute of DataFrame holds the number of rows and columns in a dataframe","27ee4ce7":"value_counts() function of pandas DataFrame column(Pandas Series) allows to get frequency distribution for categorical variables. Check it out in action below","b6df064d":"- Once we have the classifier object, sklearn allows us to train the classifier by using the .fit() function\n- .fit() function takes in training data features, X, and training data labels, y as parameters\n\n**Use .fit() function of the model to train classifier**","6569dd5f":"# Business Problem and Solution Framework","44b79f13":"- pandas has a limit on number of columns and rows it shows without truncation. We can alter the limit by setting the variables:\n    - pd.options.display.max_columns\n    - pd.options.display.max_rows","7c5f0fdb":"1. **Business Problem** To predict which credit card accounts are expected to default in their payments next month\n2. **Available Data**\n    1. Geography: Taiwan \n    2. Duration: April 2005 - September 2005\n    3. Source: UCI Machine Learning Repostiory https:\/\/archive.ics.uci.edu\/ml\/\n    4. Contents of Data: Information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients\n4. **Success Criteria** \n    1. Accuracy of prediction","c317d791":"### Evaluation: Confusion Matrix\n\n**Plot the confusion matrix for training and test datasets**","508b2035":"**Model development requires careful selection of attributes**\n1. Adding irrelevant attributes act as noise and requires an effort from the model to learn to ignore. They also cost computation.\n2. Dropping relevant attributes make it difficult for model to learn to make the correct prediction\n3. Further, incorrectly chosen attributes, sometimes (in case of *Target Leakage*), can give false impression of excellent model performance\n\nThough automated techniques exist for feature selection they are not robust against all the issues above. Hence, the first step is always gaining an understanding of attributes available and the values they take.This requires close collaboration with domain experts.\n\nSince we are using a public dataset we have a well defined data dictionary for the dataset","9b4b197c":"Detailed attribute analysis allows one to get a detailed picture of dataset. It helps discover:\n1. Extent of missing values in each columns\n1. Range of categorical values each attribute takes along with frequency of each\n1. Average values of numeric attributes\n1. Anomalous\/extreme\/outlier values present in data\n1. Deviations, if any, from the data dictionary\n1. Irrelevant attributes(e.g. attributes that take only one value)\n1. Distribution of target labels","4db7715d":"With all attribute columns being numeric we can now proceed towards training a classification model.","2310adbb":"**How do we measure model performance**\n- During training we want the model to learn just the right level of rules for classification\n- If model learns more detailed rules than necessary, it will make correct predictions on existing data but incorrect predictions on new data\n- If model learns less detailed rules than necessary, it will make incorrect predicitons on existing data as well as new data\n\n**Held Out Data Sample Setup**\n- To evaluate if the model has learnt the right level of rules:\n    - we hide part of labeled data, called test data, from training process\n    - train the model on remaining available data called training data\n    - evaluate model performance on training data\n    - evaluate model performance on test data\n    - ensure that performance is as high as possible on test data while being similar to performance on training data\n\n\nTypical Ratio of training data and test data size: 8:2","24afb50a":"### Detailed Attribute Analysis","1abdcb0b":"**Attribute Descripition**\n- **ID**\n    - ID: ID of each client\n- **Numeric Variables**\n    - LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family\/supplementary credit\n    - BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n    - BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n    - BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n    - BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n    - BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n    - BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n    - PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n    - PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n    - PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n    - PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n    - PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n    - PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n- **Ordinal Variables**\n    - PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment delay for nine months and above)\n    - PAY_2: Repayment status in August, 2005 (scale same as above)\n    - PAY_3: Repayment status in July, 2005 (scale same as above)\n    - PAY_4: Repayment status in June, 2005 (scale same as above)\n    - PAY_5: Repayment status in May, 2005 (scale same as above)\n    - PAY_6: Repayment status in April, 2005 (scale same as above)\n- **Categorical Variables**\n    - SEX: Gender (1=male, 2=female)\n    - EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)\n    - MARRIAGE: Marital status (1=married, 2=single, 3=others)\n    - AGE: Age in years\n- **Target \/ Label**\n    - default.payment.next.month: Default payment (1=yes, 0=no)","503ed96d":"### Load the data","927eeebc":"### Data Understanding","463fc6fc":"- once trained .predict() function of the classifier can be used to make predictions\n\n**Use .predict() function to get predictions on training and test data sets**","054657d7":"# Data Import and Understanding"}}