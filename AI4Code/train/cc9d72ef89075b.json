{"cell_type":{"38d66b2b":"code","9a67f635":"code","34a826e5":"code","f11511d9":"code","36704274":"code","226cb3e4":"code","61958864":"code","4252c603":"code","e93c2c94":"code","15188716":"code","01429411":"code","13e4cde0":"code","782a09f7":"code","ec2e1fff":"code","f63b483e":"code","3960a26e":"code","9090faee":"code","ed880f46":"code","25da8365":"code","2ded2479":"code","c5d9b1fb":"code","5116fb34":"code","7508d23b":"code","bd62d7d1":"code","2fb4e554":"code","a7940a17":"code","d4fdd796":"code","f70a2c4b":"markdown","439089ff":"markdown","57ac18d3":"markdown","6c863aa3":"markdown","a2132809":"markdown","87f38990":"markdown","7a57e87d":"markdown","e2ffbb7e":"markdown","4c3e10aa":"markdown","a48cb40b":"markdown","fa0cc835":"markdown","83db0b75":"markdown","ddad0f50":"markdown","673677a0":"markdown","b7260875":"markdown","ff7864b2":"markdown","c66d73dd":"markdown","be421bd3":"markdown","f3b6b561":"markdown","f9f9edd5":"markdown","80bbf0f6":"markdown"},"source":{"38d66b2b":"#Video link\nfrom IPython.display import YouTubeVideo      \nYouTubeVideo('u7bE0N0WB1A')","9a67f635":"# load cifar10 data from keras \"https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html\"\n\nfrom tensorflow.keras.datasets import cifar10","34a826e5":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","f11511d9":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()","36704274":"X_train.shape","226cb3e4":"#Video link\nfrom IPython.display import YouTubeVideo      \nYouTubeVideo('lxLyP2yKlp8')","61958864":"# Displaying original images\nplt.figure(figsize=(15,15))\nfor i in range(0,9):\n    plt.subplot(330+1+i)\n    image = X_train[i]\n    plt.imshow(image.astype('uint8'))","4252c603":"datagen = ImageDataGenerator()\n\n# fit parameters from data\ndatagen.fit(X_train)\n\nfor X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n    for i in range(0, 9):\n        plt.subplot(330 + 1 + i)\n        plt.imshow(X_batch[i].astype('uint8'))\n    break","e93c2c94":"training_generator = datagen.flow_from_directory(\n        '..\/input\/multiclass-dataset\/dataset',\n        color_mode=\"rgb\",\n        batch_size=32,\n        class_mode=\"categorical\",                                  # This has more than 2 classes\n        shuffle=True,\n        seed=42,\n        target_size=(100,100))","15188716":"Xbatch, Ybatch = training_generator.next()","01429411":"#Total shape of images\nXbatch.shape","13e4cde0":"#Shape of labels of imges\nYbatch.shape","782a09f7":"Ybatch[:5,]","ec2e1fff":"Xbatch[0].shape","f63b483e":"\ni=0\nplt.figure(figsize=(15,15))\n\nfor img in Xbatch:\n    plt.subplot(5,6, i+1)\n    plt.tight_layout()\n    plt.imshow(img.astype('uint8'))\n    i=i+1    ","3960a26e":"gray_training_generator = datagen.flow_from_directory(\n        '..\/input\/multiclass-dataset\/dataset',\n        color_mode=\"grayscale\",\n        batch_size=32,\n        class_mode=\"categorical\",                                  # This has more than 2 classes\n        shuffle=True,\n        seed=42,\n        target_size=(100, 100))","9090faee":"XbatchGray, YbatchGray = gray_training_generator.next()","ed880f46":"batch_size = 9\ni=0\nplt.figure(figsize=(10,10))\n\nfor img in XbatchGray:\n    plt.subplot(5,6, i+1)\n    plt.tight_layout()\n    gray_img = img[:,:,0]\n    plt.imshow(gray_img.astype('uint8'), cmap='gray')\n    i=i+1  ","25da8365":"batch_size = 8\ndatagen = ImageDataGenerator(rescale= 1. \/ 255.)\ndatagen.fit(Xbatch)\ni=0\nfor img_batch in datagen.flow(Xbatch, batch_size=9):\n    for img in img_batch:\n        plt.subplot(330 + 1 + i)\n        plt.tight_layout()\n        plt.imshow(img)\n        i=i+1    \n    if i >= batch_size:\n        break","2ded2479":"datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\ndatagen.fit(Xbatch)\ni=0\nfor img_batch in datagen.flow(Xbatch, batch_size=9):\n    for img in img_batch:\n        plt.subplot(330 + 1 + i)\n        plt.tight_layout()\n        plt.imshow(img.astype('uint8'))\n        i=i+1    \n    if i >= batch_size:\n        break","c5d9b1fb":"datagen = ImageDataGenerator(rotation_range=90)\ndatagen.fit(Xbatch)\n\ni=0\nfor img_batch in datagen.flow(Xbatch, batch_size=9):\n    for img in img_batch:\n        plt.subplot(330 + 1 + i)\n        plt.tight_layout()\n        plt.imshow(img.astype('uint8'))\n        i=i+1    \n    if i >= batch_size:\n        break","5116fb34":"shift = 0.2\ndatagen = ImageDataGenerator(width_shift_range=shift, fill_mode='wrap')\ndatagen.fit(Xbatch)\ni=0\nfor img_batch in datagen.flow(Xbatch, batch_size=9):\n    for img in img_batch:\n        plt.subplot(330 + 1 + i)\n        plt.tight_layout()\n        plt.imshow(img.astype('uint8'))\n        i=i+1    \n    if i >= batch_size:\n        break","7508d23b":"shift = 0.2\ndatagen = ImageDataGenerator(height_shift_range=shift)\ndatagen.fit(Xbatch)\ni=0\nfor img_batch in datagen.flow(Xbatch, batch_size=9):\n    for img in img_batch:\n        plt.subplot(330 + 1 + i)\n        plt.tight_layout()\n        plt.imshow(img.astype('uint8'))\n        i=i+1    \n    if i >= batch_size:\n        break","bd62d7d1":"datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\ndatagen.fit(Xbatch)\nbatch_size = 9\ni=0\nfor img_batch in datagen.flow(Xbatch, batch_size=9):\n    for img in img_batch:\n        plt.subplot(330 + 1 + i)\n        plt.tight_layout()\n        plt.imshow(img.astype('uint8'))\n        i=i+1    \n    if i >= batch_size:\n        break","2fb4e554":"datagen = ImageDataGenerator(zoom_range=0.75, fill_mode='constant')\ndatagen.fit(Xbatch)\nbatch_size = 9\ni=0\nfor img_batch in datagen.flow(Xbatch, batch_size=9):\n    for img in img_batch:\n        plt.subplot(330 + 1 + i)\n        plt.tight_layout()\n        plt.imshow(img.astype('uint8'))\n        i=i+1    \n    if i >= batch_size:\n        break","a7940a17":"datagen = ImageDataGenerator(shear_range=130)\ndatagen.fit(Xbatch)\nbatch_size = 9\ni=0\nfor img_batch in datagen.flow(Xbatch, batch_size=9):\n    for img in img_batch:\n        plt.subplot(330 + 1 + i)\n        plt.tight_layout()\n        plt.imshow(img.astype('uint8'))\n        i=i+1    \n    if i >= batch_size:\n        break","d4fdd796":"\n#Video link\nfrom IPython.display import YouTubeVideo      \nYouTubeVideo('DbfpXtK4mLY')","f70a2c4b":"# <a>Shifting an image<\/a>\n## Horizontal shift\nThis transformation shifts the image along the horizontal axis. The image is shifted either left or right. This can be done using 2 arguments:\n\nwidth_shift_range: Takes some fraction value less than 1.\nfill_mode: 'constant','nearest','reflect','wrap'\n\n\nQuestion: Can we apply this operation on Traffic signal????","439089ff":"## <a>Flipping an image<\/a>\nThis transformation flips the image according to the axis you have mentioned.\nThis requires two arguments:\n\nhorizontal_flip: True, results a flip in x axisqqqq\nvertical_flip: True, results a flip in y axis","57ac18d3":"## <a>Data preprocessing techniques<\/a>\n\n# <a>Color Conversion: Grayscaling an image (reduce computation complexity)<\/a>\nColor images are 3 dimensional array with the third dimension representing the RGB values. In a lot of image classification tasks, the color of images do not provide additional information and can be performed on grayscale images. This is why we perform grayscaling.\n\n* In other applications, color is important to define certain objects. Like skin cancer detection which relies heavily on the skin colors\n\n** The above image was read in Imagedatagenerator with color_mode='rgb'. **\n\n** Setting color_mode = 'grayscale' performs this operation. **","6c863aa3":"# <a>Tools Required<\/a>\n\nImage Data Generator package can be imported by the following command.  <br>\n** from tensorflow.keras.preprocessing.image import ImageDataGenerator **\n\nYou can easily create an object of Image Data Generator using  <br>\n**datagen = ImageDataGenerator()**","a2132809":"#  <a>Read images from default dataset using flow method<\/a>\n\n\n## Arguments\n\n    x: Input data. Numpy array of rank 4(batches,image_width,image_height,channels)\n    y: Labels. One hot encoded label\n    batch_size: int (default=32)\n    shuffle: Boolean (default: True).\n    sample_weight: Sample weights.\n    seed: Int (default: None).","87f38990":"# <a>Display images<\/a>","7a57e87d":"# <a>Zooming an image<\/a>\nThis transformation zooms the image either in or out. This is controlled using the zoom_range parameter.\nzoom_range = 0.75.\nThe zooming factor will be choosen from (1-0.75) to (1+0.75) or (0.25) to (1.75)","e2ffbb7e":"# <a>Access properties of image<\/a>","4c3e10aa":"## Vertical shift\nThis transformation shifts the image either to the top or down.\nThis can be done with 2 arguments:\n\nheight_shift_range: Fractional value less than 1\nfill_mode: 'constant','nearest','reflect','wrap'","a48cb40b":"# <a>Reading images using Image Data Generator<\/a>\nWe can perform operations on images using two methods:\n\n1. flow()\n\n2. flow_from_directory\n\n    *     ** flow() ** : This is used when you have less amount of data. You need to pass the inputs and the labels.\n\n    *     ** flow_from_directory() ** : This is a very helpful function to read data, when you have a large amount of images. The images are given in different folders where each folder corresponds to a class. Hence we don't need to provide inputs and labels and instead pass the image directory.","fa0cc835":"# <a>Rescaling an image<\/a>\n\n* Most of the images are stored in RGB(Red, Green, Blue) format. \n* In each dimension, the data is stored spatially using pixels whose values are stored as 8 bit unsigned integer type(range from 0 to 255). \n* **Rescaling** is an operation where the pixel values are restricted from 0 to 1. \n* In deep neural networks you might want to restrict your input to the range from 0 to 1, due to possible overflow, optimization, stability issues, and so on.","83db0b75":"This is 4 dimensional array, 27 images,  pixel width ,  pixel height, 3 color channel","ddad0f50":"# <a>Read images from directory using flow_directory method<\/a>\nThis function is used to read images from folders. The labels are automatically identified based on the folders where they are stored.\n## Arguments:\n    * directory: Path to a subdirectory. It should contain one sub directory per class.\n    * target_size: The input image is resized to this size\n    * color_mode: It can be 'grayscale', 'rgb' and 'rgba'. Images will be converted to 1, 3 or 4 channels\n    * classes: Optional list of class subdirectory. If this is not provided, classes are inferred from sub directory name\n    * class_mode: binary for 2 classes or categorical for multiple classes.\n    * batch_size: size of batches of data(default=32)\n    * shuffle: whether to shuffle the data(default=True)\n    * seed: Optional random seed for shuffling and transformations.","673677a0":"    ** The pixel values in these images are between 0 to 1 instead of 0 to 255.**\n       The images looks the same as original, but their values are different.\n       It will not change the content of the image","b7260875":"#  <a>Why do we use Image Data Generator?<\/a>\n** Image Data Generator** is prefered over OpenCV for image processing in deep learning.\n\nUnlike OpenCV which performs the operations and stores them in memory, Image Data Generator performs image processing during the process of model fitting. This process requires less memory and is efficient for deep learning application.","ff7864b2":"# <a>Data Augumentation<\/a>","c66d73dd":"# <a>Shearing an image<\/a>\nShearing displaces each point in the vertical direction by an amount proportional to its distance from an edge of the image. Note that in general the direction can be arbitrary .","be421bd3":"# <a>Rotating an image<\/a>\nThis transformation rotates an image in a certain direction either clockwise or anti-clockwise.\n\nThis can be done with the following argument:\n\nrotation_range=90\nWe specify the range, but the angle is choosen randomly.","f3b6b561":"![image.png](attachment:image.png)","f9f9edd5":"\n# <a>What\/Why image Processing<\/a>\n* Data are usually messy, data preprocessing or cleaning step\n* Image processing could be simple tasks like image resizing. In order to feed a dataset of images to a convolutional network, they must all be the same size. Other processing tasks can take place like geometric and color transformation or converting color to grayscale and many more.\n* The **goal of this step**, To feed them to the ML model (or neural network), they need to be standardized and cleaned up, which helps to reduce the complexity and increase the accuracy.","80bbf0f6":"# <a>Featurewise standardization<\/a>\n\n* In tabular data, the values are standardized along columns, so that they don't have much variance.\n* In the same way it is possible to standardize the pixel values across the dataset.\n\n* This can be done by using 2 arguments:\n    1. featurewise_center = True\n    2. featurewise_std_normalization = True\n\n* It will change the content of the image"}}