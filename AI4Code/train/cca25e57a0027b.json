{"cell_type":{"25ac371d":"code","224e207b":"code","ca6bbe11":"code","8491eee6":"code","40c9bb31":"code","11c51bb6":"code","b2b33e05":"code","a0def81b":"code","ffb40d1b":"code","2bac8bc2":"code","2ee3da4b":"code","d0413015":"code","641e7c79":"code","9be89be1":"code","89aea79a":"code","d38f3949":"code","e7689ea8":"code","9b461b30":"code","1470d5b6":"code","59e81e3b":"code","8a04e4b6":"code","59914cc6":"code","f16cd92d":"code","b6f216ad":"code","05012f98":"code","fc5dcf8b":"code","0fc68383":"code","e5d41690":"code","bcab1fa0":"code","aa5c2d6c":"code","9dceaeb2":"code","4d95a15c":"code","a9759a40":"code","608f6479":"code","81bc0d01":"code","862c0479":"code","dfc9fd04":"code","1c680c12":"code","92522ba8":"markdown","ed666744":"markdown","d7963f58":"markdown","b57f59ec":"markdown","9f4a7e1f":"markdown","1a071a20":"markdown","26d525fe":"markdown","e5d6f31a":"markdown","95952014":"markdown","312791b3":"markdown","8f47a3d3":"markdown","a05ea8dd":"markdown","87ac2080":"markdown","78ff2500":"markdown","bcd584c5":"markdown","353c5929":"markdown","d1d48c6f":"markdown","68a5798e":"markdown","c9bdda39":"markdown","e04e31d9":"markdown","0e5f978f":"markdown","d202f27a":"markdown","7bf27db6":"markdown","791f174a":"markdown","152aa394":"markdown","6dd80ac6":"markdown"},"source":{"25ac371d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","224e207b":"import seaborn as sns\nimport matplotlib.pyplot as plt","ca6bbe11":"df = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')","8491eee6":"df.head()","40c9bb31":"df.isnull().sum()","11c51bb6":"sns.countplot(x=df['sentiment'])","b2b33e05":"df['sentiment'].value_counts()","a0def81b":"review_length = [len(review.split()) for review in df['review']]","ffb40d1b":"df[\"review_len\"] = review_length","2bac8bc2":"df.head(10)","2ee3da4b":"fig = plt.figure(figsize=(12,10))\nax1 = fig.add_subplot(122)\nsns.histplot(data=df[df[\"sentiment\"] == \"positive\"], x = \"review_len\", ax = ax1, kde=True, hue=\"sentiment\", bins=50)\ndescribe = df.review_len[df[\"sentiment\"] == \"positive\"].describe().to_frame().round(2)\n#print(describe)\n\nax2 = fig.add_subplot(121)\nax2.axis(\"off\")\nbbox = [0, 0, 1, 1]\ntable = ax2.table(cellText=describe.values, rowLabels=describe.index,bbox=bbox, colLabels=describe.columns)\nplt.show()","d0413015":"fig = plt.figure(figsize=(12,10))\nax1 = fig.add_subplot(122)\nsns.histplot(data=df[df[\"sentiment\"] == \"negative\"], x = \"review_len\", ax = ax1, kde=True, hue=\"sentiment\", bins=50)\ndescribe = df.review_len[df[\"sentiment\"] == \"negative\"].describe().to_frame().round(2)\n#print(describe)\n\nax2 = fig.add_subplot(121)\nax2.axis(\"off\")\nbbox = [0, 0, 1, 1]\ntable = ax2.table(cellText=describe.values, rowLabels=describe.index,bbox=bbox, colLabels=describe.columns)\nplt.show()","641e7c79":"from wordcloud import WordCloud","9be89be1":"plt.figure(figsize=(20,20))\nwc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(df[df.sentiment == 'positive'].review))                                                                       \nplt.imshow(wc, interpolation='bilinear')","89aea79a":"plt.figure(figsize=(20,20))\nwc = WordCloud(max_words = 200 , width = 1600 , height = 800).generate(\" \".join(df[df.sentiment == 'negative'].review))                                                                       \nplt.imshow(wc, interpolation='bilinear')","d38f3949":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer","e7689ea8":"# lemmatizer = WordNetLemmatizer()\n\n# doc = []\n\n# for i in range(len(df)):\n#     clean_text = re.sub('[^a-zA-Z]', ' ', df['review'][i] )\n#     clean_text = clean_text.lower()\n#     clean_text = clean_text.split()\n#     clean_text = [lemmatizer.lemmatize(word) for word in clean_text if word not in set(stopwords.words('english'))]\n#     clean_text = ' '.join(clean_text)\n#     doc.append(clean_text)","9b461b30":"label_sentiment = {'positive': 0, 'negative': 1}\n\ny = df.sentiment.map(label_sentiment)","1470d5b6":"def clean_html(text):\n    clean_text = re.sub('<.*>', '', text)\n    return clean_text\n    \ndef clean_spcl_chars(text):\n    clean_text = re.sub('[^a-zA-Z]', ' ', text) \n    return clean_text\n\ndef remove_stopwords(text):\n    clean_text = []\n    text = text.split()\n    for word in text:\n        if word not in stopwords.words('english'):\n            clean_text.append(word)\n    return ' '.join(clean_text)\n    ","59e81e3b":"df[\"clean_review\"] = df.review.apply(clean_html)","8a04e4b6":"df.head()","59914cc6":"df.clean_review = df.clean_review.apply(clean_spcl_chars)\ndf.head()","f16cd92d":"df.clean_review = df.clean_review.apply(remove_stopwords)\ndf.head()","b6f216ad":"lemmatizer = WordNetLemmatizer()\n\ndef lemmatize_text(text):\n    text = text.split()\n    text = [lemmatizer.lemmatize(word) for word in text]\n    return ' '.join(text)","05012f98":"df['lemmatized_review'] = df['clean_review'].apply(lemmatize_text)\ndf.head()","fc5dcf8b":"df.to_pickle('cleaned_df.pkl')","0fc68383":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","e5d41690":"X = df['lemmatized_review']\n#X = TfidfVectorizer().fit_transform(X)","bcab1fa0":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","aa5c2d6c":"print(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","9dceaeb2":"from sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, log_loss","4d95a15c":"pipe1 = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB() )])\npipe2 = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC() )])\npipe3 = Pipeline([('tfidf', TfidfVectorizer()), ('clf', RandomForestClassifier() )])","a9759a40":"pipes = [pipe1, pipe2, pipe3]\nlog = []\nfor i,pipe in enumerate(pipes):\n    name = f'pipe_{i}'\n    pipe.fit(X_train, y = y_train)\n    y_pred = pipe.predict(X_test)\n    print('*****RESULTS*****')\n    acc = accuracy_score(y_test, y_pred).round(2)\n    log.append((name, acc))\n    print(classification_report(y_test, y_pred))\n    print(pipe.score(X_test, y_test))","608f6479":"log","81bc0d01":"clf_list = ['MultinomialNB', 'LinearSVC', 'RandomForset']","862c0479":"accuracy = [log[i][1].round(2) for i in range(len(log))]","dfc9fd04":"accuracy","1c680c12":"sns.barplot(x=clf_list, y = accuracy)","92522ba8":"Remove the HTML tags","ed666744":"## Wordcloud for negative sentiments","d7963f58":"## Sentiment Mapping\nComputers understand only binary, so we convert 'positive' and 'negative' sentiments into binary form.\npositive: 0\nnegative: 1","b57f59ec":"# Feature Engineering","9f4a7e1f":"# Read data","1a071a20":"**If you have any doubt or suggestion, please feel free to comment**","26d525fe":"**We have equal number of positive and negative reviews**","e5d6f31a":"## Lemmatize the words","95952014":"**If you found my notebook, please do upvote. Thank you :)**","312791b3":"Remove stopwords","8f47a3d3":"# Count the length of reviews","a05ea8dd":"# Wordcloud","87ac2080":"We see words like \"br\" appearing in the word cloud. This shows that our dataset needs preprocessing.","78ff2500":"## Data cleaning","bcd584c5":"## Wordcloud for positive sentiments","353c5929":"## Save the cleaned review dataframe as pickle object, so that I don't have to run the cleaning process everytime I open this notebook","d1d48c6f":"# Check for null values","68a5798e":"# Perform necessary imports","c9bdda39":"# Check the distribution of positive and negative reviews","e04e31d9":"Remove special characters","0e5f978f":"## Training Pipeline\nWe will create a pipeline for diffrent classifiers","d202f27a":"LinearSVC has the highest accuracy of 86%","7bf27db6":"We define 3 functions for carrying out three different tasks:\n1. Remove HTML tags from the reviews\n2. Remove special characters other than alphabets from the review\n3. Remove stopwords from the review","791f174a":"# Vectorize review\nWe will use Term frequency - inverse document frequency (Tf-idf) as for vectorizing the reviews","152aa394":"* Remove characters other than alphabets\n* Lemmatize the words so that all the words get reduced to their root words\n* Change the words to lowercase so that 'Girl' and 'girl' are not considered as two unique words.","6dd80ac6":"**No null values are present. Hence we are good to go.**"}}