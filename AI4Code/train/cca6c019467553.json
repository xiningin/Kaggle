{"cell_type":{"e1145a7f":"code","15d737e4":"code","9ce9c1de":"code","a3ec8c0c":"code","772491c5":"code","453380ac":"code","03b5044e":"code","5201188c":"code","22aef1c8":"code","a66f7f69":"code","ba58dac8":"code","4235b088":"code","31af593b":"code","bcc1662e":"code","8d0ffdcf":"code","0823ae05":"code","58c68137":"code","86bb5155":"code","d40e81f8":"code","3386e24a":"code","d296c8d8":"code","93078c1c":"code","b6f83f5c":"code","75c94add":"code","e63f5cf8":"code","953475de":"code","6e754ebf":"code","9a16924f":"code","91da1bc1":"code","f75405e5":"code","aab8d0f4":"code","f3d62a9b":"code","7e915fad":"code","7ad6c3cd":"code","7c5332ef":"code","01a8eb90":"code","c1a51822":"code","7b61fb49":"code","ebdf6686":"code","9851c14d":"code","e5b0cd20":"code","25c17b62":"code","5cfd29c0":"code","472dd775":"code","612fb77f":"code","596b2256":"code","98eb1b52":"code","170c6da5":"code","8b54f54e":"code","e3349e8e":"code","4254ff22":"markdown","9222868a":"markdown","07c6c2ae":"markdown","58ce145a":"markdown","7bae9c84":"markdown","8de63381":"markdown","7e57bf7b":"markdown","83f961c6":"markdown","5a72d4e9":"markdown","19edce62":"markdown","0a3ea6af":"markdown","9715cdb9":"markdown","31135c20":"markdown","454c62fa":"markdown","a6b392ed":"markdown","f5517ac6":"markdown"},"source":{"e1145a7f":"# TODO: Make all necessary imports.\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport os\nimport glob\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport logging\nlogger = tf.get_logger()\nlogger.setLevel(logging.ERROR)","15d737e4":"print(tf.__version__)","9ce9c1de":"def get_files(base_dir, target_dir):\n    count = 0\n    path = get_path(base_dir, target_dir)\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            count+=len(glob.glob(os.path.join(dirname, filename)))\n        return path, count\n\ndef get_path(base_dir, target_dir):\n    path = os.path.join(base_dir,target_dir)\n    return path","a3ec8c0c":"base_dir = '..\/input\/pneumonia-xray-images'\ntrain_normal_dir = 'train\/normal'\ntrain_pneumonia_dir = 'train\/opacity'\nval_normal_dir = 'val\/normal'\nval_pneumonia_dir = 'val\/opacity'\ntest_normal_dir = 'test\/normal'\ntest_pneumonia_dir = 'test\/opacity'\n\ntrain_normal_path, train_normal_count = get_files(base_dir,train_normal_dir)\ntrain_pneumonia_path, train_pneumonia_count = get_files(base_dir,train_pneumonia_dir)\n\nval_normal_path, val_normal_count = get_files(base_dir,val_normal_dir)\nval_pneumonia_path, val_pneumonia_count = get_files(base_dir,val_pneumonia_dir)\n\ntest_normal_path, test_normal_count = get_files(base_dir,test_normal_dir)\ntest_pneumonia_path, test_pneumonia_count = get_files(base_dir,test_pneumonia_dir)\n\nprint(\"No of Train Images: {}\".format(train_normal_count + train_pneumonia_count))\nprint(\" \\u2022 No of Normal Images {}\".format(train_normal_count))\nprint(\" \\u2022 No of Pneumonia Images {}\".format(train_pneumonia_count))\n\nprint(\"No of Validation Images: {}\".format(val_normal_count + val_pneumonia_count))\nprint(\" \\u2022 No of Normal Images {}\".format(val_normal_count))\nprint(\" \\u2022 No of Pneumonia Images {}\".format(val_pneumonia_count))\n\nprint(\"No of Test Images: {}\".format(test_normal_count + test_pneumonia_count))\nprint(\" \\u2022 No of Normal Images {}\".format(test_normal_count))\nprint(\" \\u2022 No of Pneumonia Images {}\".format(test_pneumonia_count))\n","772491c5":"train_data = []\nfor filename in os.listdir(train_normal_path):\n    train_data.append((os.path.join(train_normal_path,filename),0))\n\nfor filename in os.listdir(train_pneumonia_path):\n    train_data.append((os.path.join(train_pneumonia_path,filename),1))\n\ntrain_data = pd.DataFrame(train_data, columns=['image_path', 'label'], index=None)\ntrain_data = train_data.sample(frac=1).reset_index(drop=True)\n        \nval_data = []\nfor filename in os.listdir(val_normal_path):\n    val_data.append((os.path.join(val_normal_path,filename),0))\n\nfor filename in os.listdir(val_pneumonia_path):\n    val_data.append((os.path.join(val_pneumonia_path,filename),1))\n        \nval_data = pd.DataFrame(val_data, columns=['image_path', 'label'], index=None)\n        \ntest_data = []\nfor filename in os.listdir(test_normal_path):\n    test_data.append((os.path.join(test_normal_path,filename),0))\n\nfor filename in os.listdir(test_pneumonia_path):\n    test_data.append((os.path.join(test_pneumonia_path,filename),1))\n\ntest_data = pd.DataFrame(test_data, columns=['image_path', 'label'], index=None)\n\nprint(\"Train Data {}\".format(train_data.shape))\nprint(\"Validation Data {}\".format(val_data.shape))\nprint(\"Test Data {}\".format(test_data.shape))","453380ac":"train_data","03b5044e":"class_dict = {0:'Normal', 1:'Pneumonia'}\ntrain_data['class_name'] = train_data.label.map(class_dict)\ntrain_data['class_name'].value_counts().plot(kind='bar')","5201188c":"for filepath in train_data.image_path:\n    image = cv2.imread(filepath)\n    image_size = image.shape\n    break\nimage_size","22aef1c8":"def visualize_img(images):\n    fig = plt.figure(figsize=(20, 15))\n    for i,path in enumerate(images):\n        fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n        img = cv2.imread(path)\n        plt.imshow(img)\n        plt.title(train_data[train_data.image_path == path].class_name.values[0])\n        \nfor i in range(2):\n    images = train_data[train_data.label == i].image_path\n    images = np.random.choice(images , 8)\n    visualize_img(images)","a66f7f69":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip(images_arr, axes):\n        ax.imshow(img)\n    plt.tight_layout()\n    plt.show()","ba58dac8":"BATCH_SIZE = 32\nIMG_SHAPE  = 224\n\ntrain_image_gen = ImageDataGenerator(rescale=1.\/255,\n                                     width_shift_range=0.1,\n                                     height_shift_range=0.1,\n                                     brightness_range=[0.2,1.0],\n                                     zoom_range=0.2,\n                                     horizontal_flip=True,\n                                     fill_mode='nearest')\n\ntrain_gen = train_image_gen.flow_from_dataframe(train_data,\n                                              x_col='image_path',\n                                              y_col='class_name',\n                                              class_mode='binary',\n                                              batch_size=BATCH_SIZE,\n                                              shuffle=True,\n                                              target_size=(IMG_SHAPE,IMG_SHAPE))","4235b088":"augmented_images = [train_gen[0][0][2] for i in range(5)]\nplotImages(augmented_images)","31af593b":"from sklearn.preprocessing import LabelBinarizer\nfrom tensorflow.keras.utils import to_categorical\n\ntrain_lb = to_categorical(train_data.label, dtype = int)\nval_lb = to_categorical(val_data.label, dtype=int)\n\ntrain_data = train_data.reset_index().drop(labels='index', axis=1)\ny_train = pd.DataFrame(train_lb).add_prefix('label_')\n\nval_data = val_data.reset_index().drop(labels='index', axis=1)\ny_val = pd.DataFrame(val_lb).add_prefix('label_')\n\ntrain_data = pd.concat([train_data, y_train], axis=1)\nval_data = pd.concat([val_data, y_val], axis=1)\n\nprint(\"Training set has {} samples\".format(train_data.shape[0]))\nprint(\"Validation set has {} samples\".format(val_data.shape[0]))","bcc1662e":"BATCH_SIZE = 32\nIMG_SHAPE  = 224\nEPOCHS = 20\n\ndef gen():\n    train_image_gen = ImageDataGenerator(rescale=1.\/255,\n                                         width_shift_range=0.1,\n                                         height_shift_range=0.1,\n                                         brightness_range=[0.2,1.0],\n                                         zoom_range=0.2,\n                                         horizontal_flip=True,\n                                         vertical_flip=True,\n                                         fill_mode='nearest')\n\n    train_gen = train_image_gen.flow_from_dataframe(train_data,\n                                              x_col='image_path',\n                                              y_col=[f'label_{x}' for x in np.arange(2)],\n                                              class_mode='raw',\n                                              batch_size=BATCH_SIZE,\n                                              shuffle=True,\n                                              target_size=(IMG_SHAPE,IMG_SHAPE))\n\n\n    val_image_gen = ImageDataGenerator(rescale=1.\/255)\n\n    val_gen = val_image_gen.flow_from_dataframe(val_data,\n                                              x_col='image_path',\n                                              y_col= [f'label_{x}' for x in np.arange(2)],\n                                              class_mode='raw',\n                                              batch_size=BATCH_SIZE,\n                                              target_size=(IMG_SHAPE,IMG_SHAPE))\n    return train_gen, val_gen\n","8d0ffdcf":"def plot(history):\n\n    training_accuracy = history.history['accuracy']\n    validation_accuracy = history.history['val_accuracy']\n\n    training_loss = history.history['loss']\n    validation_loss = history.history['val_loss']\n\n    epochs_range=range(len(training_accuracy))\n\n    plt.figure(figsize=(8, 8))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, training_accuracy, label='Training Accuracy')\n    plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, training_loss, label='Training Loss')\n    plt.plot(epochs_range, validation_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.show()","0823ae05":"from PIL import Image\ndef predict(image_path, model):\n    im = cv2.imread(image_path)\n    test_image = np.asarray(im)\n    processed_test_image = process_image(test_image)\n    processed_test_image = np.expand_dims(processed_test_image, axis = 0)\n    \n    ps = model.predict(processed_test_image)\n    return ps\n    \ndef process_image(image):\n    image = tf.cast(image , tf.float32)\n    image = tf.image.resize(image , (224 , 224))\n    image = image\/255\n    image = image.numpy()\n    return image","58c68137":"tf.keras.backend.clear_session()\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(224, 224, 3)))\nmodel.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2, strides=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\nmodel.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2, strides=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2, strides=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\nmodel.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2, strides=2))\nmodel.add(Dropout(0.2))\n\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.summary()","86bb5155":"from keras.utils.vis_utils import plot_model\nplot_model(model, to_file='baseline_model.png', show_shapes=True, show_layer_names=True)","d40e81f8":"from sklearn.utils import class_weight\n\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(train_data['label']), train_data.label)\nclass_weights = dict(enumerate(class_weights))\nclass_weights","3386e24a":"train_gen, val_gen = gen()\n\noptm = Adam(lr=0.0001)\nmodel.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\nEarlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=.0001,\n                              patience=3,\n                              verbose=1,\n                              mode='auto',\n                              baseline=None,\n                              restore_best_weights=True)\n\nmodel_save = ModelCheckpoint('.\/baseline_model.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\nbase_history = model.fit(train_gen,\n                             steps_per_epoch = train_gen.samples \/\/ BATCH_SIZE,\n                             epochs = 20,\n                             validation_data = val_gen,\n                             callbacks=[EarlyStopping,model_save],\n                             class_weight = class_weights)","d296c8d8":"plot(base_history)","93078c1c":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n\nbase_pred =[]\nfor image in test_data.image_path:\n    base_pred.append(predict(image , model))\n    \nfinal_base_pred  = np.argmax(base_pred , axis=-1)\nactual_label = test_data['label']\n\nprint(classification_report(actual_label, final_base_pred))\nmatrix=confusion_matrix(actual_label, final_base_pred)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');","b6f83f5c":"from tensorflow.keras.applications.vgg16 import VGG16\n\nbase = VGG16(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\ntf.keras.backend.clear_session()\n\nfor layer in base.layers:\n    layer.trainable = False\n    \nvgg_model = Sequential()\nvgg_model.add(base)\nvgg_model.add(GlobalAveragePooling2D())\nvgg_model.add(BatchNormalization())\nvgg_model.add(Dense(256, activation='relu'))\nvgg_model.add(Dropout(0.5))\nvgg_model.add(BatchNormalization())\nvgg_model.add(Dense(128, activation='relu'))\nvgg_model.add(Dropout(0.5))\nvgg_model.add(Dense(2, activation='softmax'))\n\nvgg_model.summary()","75c94add":"from keras.utils.vis_utils import plot_model\nplot_model(vgg_model, to_file='vgg16_model.png', show_shapes=True, show_layer_names=True)","e63f5cf8":"train_gen, val_gen = gen()\n\noptm = Adam(lr=0.0001)\nvgg_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\nEarlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=.0001,\n                              patience=3,\n                              verbose=1,\n                              mode='auto',\n                              baseline=None,\n                              restore_best_weights=True)\n\nmodel_save = ModelCheckpoint('.\/vgg16_model.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\nvgg_history = vgg_model.fit(train_gen,\n                             steps_per_epoch = train_gen.samples \/\/ BATCH_SIZE,\n                             epochs = 20,\n                             validation_data = val_gen,\n                             callbacks=[EarlyStopping, model_save],\n                             class_weight = class_weights)","953475de":"plot(vgg_history)","6e754ebf":"vgg_pred =[]\nfor image in test_data.image_path:\n    vgg_pred.append(predict(image , vgg_model))\n    \nfinal_vgg_pred  = np.argmax(vgg_pred , axis=-1)\nactual_label = test_data['label']\n\nprint(classification_report(actual_label, final_vgg_pred))\nmatrix=confusion_matrix(actual_label, final_vgg_pred)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');","9a16924f":"print(vgg_history.history['val_accuracy'][-3])\nprint(vgg_history.history['val_loss'][-3])","91da1bc1":"from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n\nbase = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\ntf.keras.backend.clear_session()\n    \nfor layer in base.layers:\n    layer.trainable =  False\n\nmobilenet_model = Sequential()\nmobilenet_model.add(base)\nmobilenet_model.add(GlobalAveragePooling2D())\nmobilenet_model.add(BatchNormalization())\nmobilenet_model.add(Dense(256, activation='relu'))\nmobilenet_model.add(Dropout(0.5))\nmobilenet_model.add(BatchNormalization())\nmobilenet_model.add(Dense(128, activation='relu'))\nmobilenet_model.add(Dropout(0.5))\nmobilenet_model.add(Dense(2, activation='softmax'))\n\nmobilenet_model.summary()","f75405e5":"from keras.utils.vis_utils import plot_model\nplot_model(mobilenet_model, to_file='mobilenet_model.png', show_shapes=True, show_layer_names=True)","aab8d0f4":"train_gen, val_gen = gen()\n\noptm = Adam(lr=0.0001)\nmobilenet_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\nEarlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=.0001,\n                              patience=3,\n                              verbose=1,\n                              mode='auto',\n                              baseline=None,\n                              restore_best_weights=True)\n\nmodel_save = ModelCheckpoint('.\/mobilenetV2.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\nmob_history = mobilenet_model.fit(train_gen,\n                              steps_per_epoch = train_gen.samples \/\/ BATCH_SIZE,\n                              epochs = EPOCHS,\n                              validation_data = val_gen,\n                              callbacks=[EarlyStopping, model_save])","f3d62a9b":"plot(mob_history)","7e915fad":"mob_pred =[]\nfor image in test_data.image_path:\n    mob_pred.append(predict(image , mobilenet_model))\n    \nfinal_mob_pred  = np.argmax(mob_pred , axis=-1)\nactual_label = test_data['label']\n\nprint(classification_report(actual_label, final_mob_pred))\nmatrix=confusion_matrix(actual_label, final_mob_pred)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');","7ad6c3cd":"print(mob_history.history['val_accuracy'][-4])\nprint(mob_history.history['val_loss'][-4])","7c5332ef":"from tensorflow.keras.applications.densenet import DenseNet169\nfrom tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n\nbase = DenseNet169(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\ntf.keras.backend.clear_session()\n\nfor layer in base.layers:\n    layer.trainable =  False\n\ndensenet_model = Sequential()\ndensenet_model.add(base)\ndensenet_model.add(GlobalAveragePooling2D())\ndensenet_model.add(BatchNormalization())\ndensenet_model.add(Dense(256, activation='relu'))\ndensenet_model.add(Dropout(0.5))\ndensenet_model.add(BatchNormalization())\ndensenet_model.add(Dense(128, activation='relu'))\ndensenet_model.add(Dropout(0.5))\ndensenet_model.add(Dense(2, activation='softmax'))\n\ndensenet_model.summary()","01a8eb90":"from keras.utils.vis_utils import plot_model\nplot_model(densenet_model, to_file='densenet169_model.png', show_shapes=True, show_layer_names=True)","c1a51822":"train_gen, val_gen = gen()\n\noptm = Adam(lr=0.0001)\ndensenet_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\nEarlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=.0001,\n                              patience=3,\n                              verbose=1,\n                              mode='auto',\n                              baseline=None,\n                              restore_best_weights=True)\n\nmodel_save = ModelCheckpoint('.\/densenet169.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\ndense_history = densenet_model.fit(train_gen,\n                              steps_per_epoch = train_gen.samples \/\/ BATCH_SIZE,\n                              epochs = EPOCHS,\n                              validation_data = val_gen,\n                              callbacks=[EarlyStopping, model_save])","7b61fb49":"plot(dense_history)","ebdf6686":"dense_pred =[]\nfor image in test_data.image_path:\n    dense_pred.append(predict(image , densenet_model))\n    \nfinal_dense_pred  = np.argmax(dense_pred , axis=-1)\nactual_label = test_data['label']\n\nprint(classification_report(actual_label, final_dense_pred))\nmatrix=confusion_matrix(actual_label, final_dense_pred)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');","9851c14d":"print(dense_history.history['val_accuracy'][-4])\nprint(dense_history.history['val_loss'][-4])","e5b0cd20":"model1_list=[]\nmodel2_list=[]\n\npredicted_label_list=[]\n\nfor image in test_data.image_path:\n    model1_list.append(predict(image, densenet_model))\n    model2_list.append(predict(image, mobilenet_model))\n\nfor mob, dense in zip(model1_list, model2_list):\n    predicted_label_list.append(np.argmax(mob\/np.linalg.norm(mob) + dense\/np.linalg.norm(dense)))\n\nactual_label = test_data['label']\nprint(classification_report(actual_label, predicted_label_list))\n\nmatrix=confusion_matrix(actual_label, predicted_label_list)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');\n","25c17b62":"model1_list=[]\nmodel2_list=[]\nmodel3_list=[]\n\npredicted_label_list=[]\n\nfor image in test_data.image_path:\n    model1_list.append(predict(image, densenet_model))\n    model2_list.append(predict(image, mobilenet_model))\n    model3_list.append(predict(image, vgg_model))\n\nfor mob, dense, vgg in zip(model1_list, model2_list, model3_list):\n    predicted_label_list.append(np.argmax(mob\/np.linalg.norm(mob) + dense\/np.linalg.norm(dense) + vgg\/np.linalg.norm(vgg)))\n\nactual_label = test_data['label']\nprint(classification_report(actual_label, predicted_label_list))\n\nmatrix=confusion_matrix(actual_label, predicted_label_list)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');\n","5cfd29c0":"model1_list=[]\nmodel2_list=[]\n\npredicted_label_list=[]\n\nfor image in test_data.image_path:\n    model1_list.append(predict(image, vgg_model))\n    model2_list.append(predict(image, mobilenet_model))\n\nfor vgg, mob in zip(model1_list, model2_list):\n    predicted_label_list.append(np.argmax(vgg\/np.linalg.norm(vgg) + mob\/np.linalg.norm(mob)))\n\nactual_label = test_data['label']\nprint(classification_report(actual_label, predicted_label_list))\n\nmatrix=confusion_matrix(actual_label, predicted_label_list)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');\n","472dd775":"model1_list=[]\nmodel2_list=[]\n\npredicted_label_list=[]\n\nfor image in test_data.image_path:\n    model1_list.append(predict(image, vgg_model))\n    model2_list.append(predict(image, densenet_model))\n\nfor vgg, dense in zip(model1_list, model2_list):\n    predicted_label_list.append(np.argmax(vgg\/np.linalg.norm(vgg) + dense\/np.linalg.norm(dense)))\n\nactual_label = test_data['label']\nprint(classification_report(actual_label, predicted_label_list))\n\nmatrix=confusion_matrix(actual_label, predicted_label_list)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');\n","612fb77f":"from tensorflow.keras.applications import InceptionV3\nbase = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\ntf.keras.backend.clear_session()\nfor layer in base.layers:   \n    layer.trainable = False\n\nincept_model = Sequential()\nincept_model.add(base)\nincept_model.add(GlobalAveragePooling2D())\nincept_model.add(BatchNormalization())\nincept_model.add(Dense(256, activation='relu'))\nincept_model.add(Dropout(0.5))\nincept_model.add(BatchNormalization())\nincept_model.add(Dense(128, activation='relu'))\nincept_model.add(Dropout(0.5))\nincept_model.add(Dense(2, activation='softmax'))\n\nincept_model.summary()","596b2256":"from keras.utils.vis_utils import plot_model\nplot_model(incept_model, to_file='inceptionV3_model.png', show_shapes=True, show_layer_names=True)","98eb1b52":"train_gen, val_gen = gen()\n\noptm = Adam(lr=0.0001)\nincept_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\nEarlyStopping = EarlyStopping(monitor='val_loss',\n                              min_delta=.0001,\n                              patience=3,\n                              verbose=1,\n                              mode='auto',\n                              baseline=None,\n                              restore_best_weights=True)\n\nmodel_save = ModelCheckpoint('.\/inceptionV3.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\nincept_history = incept_model.fit(train_gen,\n                              steps_per_epoch = train_gen.samples \/\/ BATCH_SIZE,\n                              epochs = EPOCHS,\n                              validation_data = val_gen,\n                              callbacks=[EarlyStopping, model_save])","170c6da5":"plot(incept_history)","8b54f54e":"incept_pred =[]\nfor image in test_data.image_path:\n    incept_pred.append(predict(image , incept_model))\n    \nfinal_incept_pred  = np.argmax(incept_pred , axis=-1)\nactual_label = test_data['label']\n\nprint(classification_report(actual_label, final_incept_pred))\nmatrix=confusion_matrix(actual_label, final_incept_pred)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');","e3349e8e":"model1_list=[]\nmodel2_list=[]\nmodel3_list=[]\nmodel4_list=[]\n\npredicted_label_list=[]\n\nfor image in test_data.image_path:\n    model1_list.append(predict(image, densenet_model))\n    model2_list.append(predict(image, mobilenet_model))\n    model3_list.append(predict(image, vgg_model))\n    model4_list.append(predict(image, incept_model))\n    \nfor mob, dense, vgg, incept in zip(model1_list, model2_list, model3_list, model4_list):\n    predicted_label_list.append(np.argmax(mob\/np.linalg.norm(mob) + dense\/np.linalg.norm(dense) + vgg\/np.linalg.norm(vgg) + incept\/np.linalg.norm(incept)))\n\nactual_label = test_data['label']\nprint(classification_report(actual_label, predicted_label_list))\n\nmatrix=confusion_matrix(actual_label, predicted_label_list)\nsns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\nplt.xlabel('Predicted label')\nplt.ylabel('True label');\n","4254ff22":"4. **DenseNet169**","9222868a":"## Visualization","07c6c2ae":"3. **MobileNetV2**","58ce145a":"2. **MobileNetV2 + DenseNet169 + VGG16**","7bae9c84":"## Import Libraries","8de63381":"## Data Preprocessing","7e57bf7b":"## Directory Setup","83f961c6":"4. **VGG16 + DenseNet169**","5a72d4e9":"3. **VGG16 + MobileNetV2**","19edce62":"2. **VGG16**","0a3ea6af":"## Example of Data Augmentation","9715cdb9":"## Baseline Ensemble\n\n1. **MobileNetV2 + DenseNet169**","31135c20":"## Helper Functions","454c62fa":"5. **MobileNetV2 + DenseNet169 + VGG16 + InceptionV3**","a6b392ed":"## Model Building\n\n1. **Baseline Model**","f5517ac6":"5. **InceptionV3**"}}