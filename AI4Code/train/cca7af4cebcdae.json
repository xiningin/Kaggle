{"cell_type":{"4416743f":"code","12fcbbc2":"code","5a42c2ef":"code","1966bf60":"code","f7fb8044":"code","ffbcaaa6":"code","5a618108":"code","6314313b":"code","758ef231":"code","b0193593":"code","611fde6f":"code","d99fc404":"code","5ed98b9d":"code","cf2c6e0c":"code","2a67514f":"code","0187f3c1":"code","3abf89c0":"code","1c4dbc32":"code","23910404":"code","63d884fc":"code","21bb1bdc":"code","f2259034":"code","f275488d":"code","2be53e12":"code","b81cd0c6":"code","69c1150a":"code","280fd435":"code","8c341a86":"code","ce3647bd":"code","4524d558":"code","2625a4aa":"code","4ffd0787":"code","9fdde66a":"code","3e504688":"code","e90a5248":"code","88762d73":"code","411a728f":"code","c2200402":"code","ee46285a":"code","b1c50596":"code","e85041fb":"code","1a664960":"code","c3571c55":"code","12f7b39c":"code","39f4bad9":"code","4043c4be":"code","335276f7":"code","a67442b9":"code","0fb2e398":"code","ea7fc290":"code","73a7ca72":"code","1e5d17db":"code","bce8e9e3":"code","cbd61b08":"code","4af5d78a":"code","dc77d765":"code","1aa18a81":"code","f0b57511":"code","787df783":"code","073e2149":"code","fef4523a":"code","9bf3a294":"code","6af1ae97":"code","f8c841cb":"code","9395b694":"code","b1320ae2":"code","c881dcb0":"code","abea8b86":"code","af1319c5":"code","be810edb":"code","20e5798e":"code","e47962fe":"code","a44e141a":"code","94836dac":"code","6fd68e02":"code","703393b2":"code","46743321":"code","386f7c7d":"code","85f978bf":"code","d772a49c":"code","84a48762":"code","bda5567e":"code","e6fae3c9":"code","4031641f":"code","dc437010":"code","1e5d19b4":"code","bc57d8e9":"code","5218f456":"code","c8087360":"code","640377bd":"code","49329c46":"code","12b57a70":"code","f0437979":"markdown","d25b061e":"markdown","de385be4":"markdown","a4a77e33":"markdown","d8952aca":"markdown","5c88200b":"markdown","c7338850":"markdown","b708a9f9":"markdown","ad318d04":"markdown","5c72cee3":"markdown","2c8bd764":"markdown","cd681a68":"markdown","53948667":"markdown","0d4b76a6":"markdown","6708d7db":"markdown","0aaddfaa":"markdown","bae64c0d":"markdown","1a342a1f":"markdown","11e7ca4f":"markdown","9882a42c":"markdown","aef708a9":"markdown","8b0c7fc1":"markdown","ba57e5b6":"markdown","d36261da":"markdown","1438d565":"markdown","bd2de3e5":"markdown","8d02f2ee":"markdown","17014f09":"markdown","e01d9b83":"markdown","80e031d7":"markdown","0c9b7c6c":"markdown","5bdb4cbf":"markdown","2105471f":"markdown","b5c0216c":"markdown","7f7140a5":"markdown","b4e737f0":"markdown","6fdbd511":"markdown","be145ab2":"markdown","a79833fe":"markdown","3e09fe45":"markdown","e6d45ab5":"markdown","b106a7fa":"markdown","f34b1cc2":"markdown","e1683b5e":"markdown","0a66dddd":"markdown","6f8b5828":"markdown","8b4feeef":"markdown","f44479eb":"markdown"},"source":{"4416743f":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom pylab import figure, show, legend, ylabel\nimport matplotlib.lines as mlines\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\nimport seaborn as sns\n\nimport numpy as np\nfrom scipy import stats\n\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode,  iplot\ninit_notebook_mode(connected=True)","12fcbbc2":"bakery = pd.read_csv('..\/input\/transactions-from-a-bakery\/BreadBasket_DMS.csv')\nbakery.head()","5a42c2ef":"bakery.shape","1966bf60":"#prints count of each item\nprint(bakery['Item'].value_counts().tail(10))","f7fb8044":"#prints count of each item\nprint(bakery['Item'].value_counts().head(10))","ffbcaaa6":"bakery['Item'].value_counts().head(6)","5a618108":"bakery[bakery['Transaction']==348]","6314313b":"bakery[bakery['Item']== 'NONE'].head(3)","758ef231":"bakery = bakery[bakery['Item'] != 'NONE']","b0193593":"bakery[bakery['Item'] == 'NONE']","611fde6f":"bakery[bakery['Item'] == 'Adjustment']","d99fc404":"bakery[bakery['Transaction'] == 938]","5ed98b9d":"bakery = bakery[bakery['Item'] != 'Adjustment']","cf2c6e0c":"#we do not have mising values\nbakery.isnull().sum()","2a67514f":"bakery['Date'].min()","0187f3c1":"bakery['Date'].max()","3abf89c0":"print(bakery.head())\nbakery.dtypes\n#Date is an object, need to chage to proper date","1c4dbc32":"#covert to datetime\nbakery['Date_Time'] = pd.to_datetime(bakery['Date'].apply(str)+' '+bakery['Time'],format=\"%Y\/%m\/%d %H:%M:%S\")\n\n#todatetime \nprint(bakery.dtypes)","23910404":"bakery.head()","63d884fc":"bakery['Day_of_Week'] = bakery['Date_Time'].dt.weekday_name","21bb1bdc":"bakery.to_excel('cleanBakeryDF.xlsx', sheet_name='Sheet1')","f2259034":"bakery['Month'] = bakery['Date_Time'].dt.month","f275488d":"#First month should be October\nbakery['Month'].head(1)","2be53e12":"#Last month should be April\nbakery['Month'].tail(1)","b81cd0c6":"#Dictionary to map months in order\nmo = {10 : 1, 11 : 2, 12 : 3 , 1 : 4 , 2 : 5 , 3 : 6 , 4 : 7}\n \nm = bakery['Month']\nbakery['Month_Order'] = m.map(mo)","69c1150a":"#adding season\n##Dictionary to map month to season\nx = {1 : 'Winter', 2 :'Winter', 3 :'Spring',4:'Spring',5:'Spring',6:'Summer',7:'Summer',8:'Summer',9:'Autumn',10:'Autumn',11:'Autumn',12:'Winter'}\n\ny = bakery['Month']\nbakery['Season'] = y.map(x)","280fd435":"bakery.head(2)","8c341a86":"bakery.loc[(pd.to_datetime(bakery['Date_Time'].dt.date) == '2016-10-30')].groupby(['Item'])['Transaction'].count().plot.bar()","ce3647bd":"bakery[bakery['Time'] == '01:21:05']","4524d558":"bakery['Hour'] = bakery['Date_Time'].dt.hour","2625a4aa":"bakery['Hour'].value_counts()","4ffd0787":"#Dictionary to map session\nt = {7 : 'Morning', 8 :'Morning', 9 :'Morning',10:'Morning',11:'Morning',12:'Morning',13:'Afternoon',14:'Afternoon',15:'Afternoon',16:'Afternoon',17:'Afternoon',18:'Afternoon',19:'Evening',20:'Evening',21:'Evening',22:'Evening',23:'Evening'}\n\nh = bakery['Hour']\nbakery['Session'] = h.map(t)","9fdde66a":"#adding categories to items\nfrom __future__ import print_function\nfrom os.path import join, dirname, abspath\nimport xlrd\n\nd = {}\nwb = xlrd.open_workbook('..\/input\/item-dic\/items_dictionary.xlsx')\nsh = wb.sheet_by_name('sheet1') \n\nfor i in range(sh.nrows):\n    cell_value_id = sh.cell_value(i,0)\n    cell_value_class = sh.cell_value(i,1)\n    d[cell_value_id] = cell_value_class\n    ","3e504688":"it = bakery['Item']\nbakery['Category'] = it.map(d)","e90a5248":"bakery.head(1)","88762d73":"bakery.loc[(pd.to_datetime(bakery['Date_Time'].dt.date) == '2016-10-30')].groupby(['Category'])['Transaction'].count().plot.bar()","411a728f":"bakery['Hourly'] = bakery['Date_Time'].dt.to_period('H')","c2200402":"bakery['Hourly'] = pd.to_datetime(bakery['Hourly'].apply(str),format=\"%Y\/%m\/%d %H:%M:%S\")","ee46285a":"bakery['Monthly'] = pd.to_datetime(bakery['Date_Time']).dt.to_period('M')","b1c50596":"bakery['Weekly'] = pd.to_datetime(bakery['Date_Time']).dt.to_period('W')","e85041fb":"temp_data = pd.read_csv('..\/input\/temperature-data\/temp_data.csv')","1a664960":"temp_data['Hourly'] = pd.to_datetime(temp_data['Hourly'].apply(str), format = '%Y\/%m\/%d %H:%M:%S')","c3571c55":"temp_data.head()","12f7b39c":"temp_data.isnull().sum()","39f4bad9":"dates_for_graph =bakery['Date'].value_counts().sort_index()","4043c4be":"bakery_temp = pd.merge(bakery, temp_data, on='Hourly', how='left')","335276f7":"bakery_temp.describe()","a67442b9":"bakery_temp.fillna(method='ffill', inplace=True)","0fb2e398":"bakery_temp.groupby('Date')['temperature'].min().head(10)","ea7fc290":"trace1 = go.Scatter(\n    x = bakery_temp.groupby('Date')['Item'].count().index,\n    y = bakery_temp.groupby('Date')['Item'].count().values,\n    mode = 'lines+markers',\n    name = 'lines+markers')\n\ndata = [trace1]\nlayout = go.Layout(title = 'Daily Sales')\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","73a7ca72":"fig1 = figure(figsize=(15,6))\n \n# and the first axes using subplot populated with data \nax1 = fig1.add_subplot(1,1,1)\nax1.set_title(\"Sales and Temperature\")\nline1 = ax1.plot(bakery_temp.groupby('Date')['Item'].count(), 'o-')\n\nylabel(\"Total Sales per day\")\n \n# now, the second axes that shares the x-axis with the ax1\nax2 = fig1.add_subplot(111, sharex=ax1, frameon=False)\nline2 = ax2.plot(bakery_temp.groupby('Date')['temperature'].min(), 'xr-')\nax2.yaxis.tick_right()\nax2.yaxis.set_label_position(\"right\")\nylabel(\"Mininum temperature per day\")\n\n\nblue_line = mlines.Line2D([], [], color='blue', marker='o',\n                          markersize=6, label='Sales')\n\nred_line = mlines.Line2D([], [], color='red', marker='*',\n                          markersize=6, label='Temperature')\nplt.legend(handles=[blue_line,red_line])\n#no working but leave it as it removes the axix labels\nax1.get_xaxis().set_major_locator(mdates.MonthLocator(interval=1))\n\nshow()","1e5d17db":"\nfig1 = figure(figsize=(15,6))\n \n#the first axes using subplot populated with data \nax1 = fig1.add_subplot(111)\nax1.set_title(\"Hot drinks sales and Temperature\")\nline1 = ax1.plot(bakery_temp[bakery_temp['Item'].isin(['Coffee', 'Tea', 'Hot Chocolate'])] .groupby('Date')['Item'].count(),'o-')\nylabel(\"Total Sales per day\")\n \n# now, the second axes that shares the x-axis with the ax1\nax2 = fig1.add_subplot(111, sharex=ax1, frameon=False)\nline2 = ax2.plot(bakery_temp.groupby('Date')['temperature'].min(), 'xr-')\nax2.yaxis.tick_right()\nax2.yaxis.set_label_position(\"right\")\nylabel(\"Mininum temperature per day\")\n\n#inverted Axis\nax2.invert_yaxis()\n\nblue_line = mlines.Line2D([], [], color='blue', marker='o',\n                          markersize=6, label='Sales')\n\nred_line = mlines.Line2D([], [], color='red', marker='*',\n                          markersize=6, label='Temperature')\nplt.legend(handles=[blue_line,red_line])\n\nax1.get_xaxis().set_major_locator(mdates.MonthLocator(interval=1))\n\nshow()","bce8e9e3":"item_hour = bakery_temp.groupby('Hourly')['Item'].count().values\n\ntemp_hour = bakery_temp.groupby('Hourly')['temperature'].min().values","cbd61b08":"hot_drink_df = bakery_temp[bakery_temp['Item'].isin(['Coffee', 'Tea', 'Hot Chocolate'])]","4af5d78a":"hot_drink_item_hour = hot_drink_df.groupby('Hourly')['Item'].count().values\nhot_drink_temp_hour = hot_drink_df.groupby('Hourly')['temperature'].min().values","dc77d765":"correlation, p_value = stats.pearsonr(temp_hour,item_hour)\nprint(correlation)\nprint(p_value)","1aa18a81":"plt.scatter(temp_hour, item_hour)","f0b57511":"correlation, p_value = stats.pearsonr(hot_drink_temp_hour,hot_drink_item_hour)\nprint(correlation)\nprint(p_value)","787df783":"plt.scatter(hot_drink_temp_hour, hot_drink_item_hour)","073e2149":"bakery_temp.groupby(['Date','Day_of_Week'])['Item'].count().sort_values()","fef4523a":"bakery_temp[bakery_temp['Date'] == '2017-01-01']","9bf3a294":"bakery_temp.groupby('Day_of_Week')['Item'].count().plot.pie()","6af1ae97":"bakery_temp.groupby('Day_of_Week')['Item'].count().sort_values()","f8c841cb":"fig, axes = plt.subplots(3, 2, figsize=(15,6), sharex=True, sharey=True, squeeze=False )\n\nfig.suptitle('Total Sales by Hour and Day', fontsize=12)\nfig.text(0.06, 0.5, 'Total Item Sold', ha='center', va='center', rotation='vertical')\n#fig.text(0.5, 0.04, 'Hours', ha='center', va='center')\nSaturday = bakery_temp[bakery_temp['Day_of_Week'] == 'Saturday'].groupby('Hour')['Item'].count()\nSaturday.plot(ax=axes[0][0], grid=True, kind='area', title='Saturday', xticks=range(6,24,1), yticks=range(0, 1000,200))\n\n#Removing the item sold at 1:20 in the morning\nSunday = bakery_temp[(bakery_temp['Date'] != '2017-01-01') & (bakery_temp['Day_of_Week'] == 'Sunday')].groupby('Hour')['Item'].count()\nSunday.plot(ax=axes[0][1], grid=True, kind='area', title='Sunday', xticks=range(6,24,1), yticks=range(0, 1000,200))\n\nMonday = bakery_temp[bakery_temp['Day_of_Week'] == 'Monday'].groupby('Hour')['Item'].count()\nMonday.plot(ax=axes[1][0], grid=True, kind='area', title='Monday', xticks=range(6,24,1), yticks=range(0, 1000,200))\n\nTuesday = bakery_temp[bakery_temp['Day_of_Week'] == 'Tuesday'].groupby('Hour')['Item'].count()\nTuesday.plot(ax=axes[1][1], grid=True, kind='area', title='Tuesday', xticks=range(6,24,1), yticks=range(0, 1000,200))\n\nThursday = bakery_temp[bakery_temp['Day_of_Week'] == 'Thursday'].groupby('Hour')['Item'].count()\nThursday.plot(ax=axes[2][0], grid=True, kind='area', title='Thursday', xticks=range(6,24,1), yticks=range(0, 1000,200))\n\nFriday = bakery_temp[bakery_temp['Day_of_Week'] == 'Friday'].groupby('Hour')['Item'].count()\nFriday.plot(ax=axes[2][1], grid=True, kind='area', title='Friday', xticks=range(6,24,1), yticks=range(0, 1000,200))","9395b694":"bakery_temp.groupby('Date')['Item'].count().plot.box()","b1320ae2":"bakery_temp[(bakery_temp['Time'] > '20:00:00') & (bakery_temp['Day_of_Week'] == 'Saturday')].groupby(['Date','Day_of_Week','Time'])['Item'].count()","c881dcb0":"bakery_temp[(bakery_temp['Time'] > '18:00:00') & (bakery_temp['Day_of_Week'] == 'Friday')].groupby(['Date','Day_of_Week'])['Item'].count()","abea8b86":"bakery_temp[(bakery_temp['Time'] > '17:00:00') & (bakery_temp['Day_of_Week'] == 'Friday')].groupby(['Date','Day_of_Week'])['Item'].count()","af1319c5":"bakery_temp.shape","be810edb":"#unstack, will put the categories in columns\nbakery_temp.groupby(['Month_Order','Category'])['Category'].count().unstack()","20e5798e":"\nfig, ax = plt.subplots()\nbakery_temp.groupby(['Month_Order','Category'])['Category'].count().unstack().plot(kind='bar', figsize=(15,6), ax=ax)\nax.set_title('Monthly Sales', fontsize=21, y=1.01)\nax.legend(loc=\"upper right\")\nax.set_ylabel('Sales', fontsize=16)\nax.set_xlabel('Category', fontsize=16)\nax.set_xticklabels(ax.get_xticklabels(), rotation=0)\nplt.show()","e47962fe":"bakery_temp.groupby('Month')['Date'].nunique()","a44e141a":"#this will give me a list with unique names of item\nitem_Name = bakery_temp['Item'].value_counts().index\n#this will give me the values of the unique item name\nitem_Value = bakery_temp['Item'].value_counts().values","94836dac":"#this will give me a list with unique names of item\nbakery_saturday = bakery_temp[bakery_temp['Day_of_Week'] == 'Saturday']\nitem_Name_Saturday = bakery_saturday['Item'].value_counts().index\n#this will give me the values of the unique item name\nitem_Value_Saturday = bakery_saturday['Item'].value_counts().values","6fd68e02":"#this will give me a list with unique names of item\nbakery_monday = bakery_temp[bakery_temp['Day_of_Week'] == 'Monday']\nitem_Name_monday = bakery_monday['Item'].value_counts().index\n#this will give me the values of the unique item name\nitem_Value_monday = bakery_monday['Item'].value_counts().values","703393b2":"item_Value_Saturday[10:].sum()","46743321":"item_Value_monday[:10]","386f7c7d":"item_Name_monday[:10]","85f978bf":"item_Value_Saturday[:10]","d772a49c":"item_Name_Saturday[:10]","84a48762":"#Top 10 items plus aggregating the rest as others","bda5567e":"item_Saturday_Value = [1103,  760,  288,  246,  166,  161,  146,  146,  143,  118, 1328]","e6fae3c9":"item_Saturday_Name = ['Coffee', 'Bread', 'Tea', 'Cake', 'Pastry', 'Sandwich', 'Hot chocolate',\n       'Scone', 'Medialuna', 'Scandinavian', 'Other']","4031641f":"plt.figure(figsize=(12,4))\nplt.ylabel('Values', fontsize='medium')\nplt.xlabel('Items', fontsize='medium')\nplt.title('10 Most sold itme')\nplt.bar(item_Name[:10],item_Value[:10], width = 0.7, color=\"blue\",linewidth=0.4)\n\nplt.xticks(rotation=45)\nplt.show()","dc437010":"init_notebook_mode(connected=True)\n\nlabels = item_Name_Saturday[:10]\nvalues = item_Value_Saturday[:10]\n\ntrace = go.Pie(labels=labels, values=values)\n\ndata= [trace]\nlayout = go.Layout(title = 'Top 10 item sold on Saturday')\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","1e5d19b4":"\nlabels = item_Saturday_Name\nvalues = item_Saturday_Value\n\ntrace = go.Pie(labels=labels, values=values)\n\ndata= [trace]\nlayout = go.Layout(title = 'All Items sold on Saturday')\nfig = go.Figure(data = data, layout = layout)\niplot(fig)","bc57d8e9":"bakery_temp['Session'].value_counts()","5218f456":"bakery_temp.to_pickle('bakery_temp_dataframe.pkl')","c8087360":"#Extract dates as we want then to be the index\ndates = pd.DatetimeIndex(bakery_temp['Date_Time'])","640377bd":"bakery_temp_sum = bakery_temp[['Date_Time','Date','Item','Day_of_Week','temperature']].copy()","49329c46":"bakery_temp_sum.head(10)","12b57a70":"bakery_temp_sum.to_pickle('bakery_temp_sum_dataframe.pkl')","f0437979":"### Need to change date and time to datetime","d25b061e":"### Formally try to see if there is a correlation for all items sold per hour and min temperature. No really.","de385be4":"### Extracting a few more features from datetime to see if can get any more info.","a4a77e33":"- Adding month","d8952aca":"- It seems that when it is really cold, sometimes there are more hot drinks sales.\n- My guess is that people from Edinburg are used to very cold weather and it makes no differences to their day to day life. I could not do the same comparison with hot temperatures and cold drinks as we have limited data. But it will be very interesting to see.","5c88200b":"### The first and last date in bakery dataset","c7338850":"### Creating a data frame with only the features that are needed and then saving to pickle file","b708a9f9":"There is one transaction at 1:21 in the morning. That currently is not included in the sessions. It was the sale of one bread.\n\n**I may add it to afternoon session for completeness****","ad318d04":"Checking what sold the most, food or drink","5c72cee3":"- Adding sessions as well.","2c8bd764":"### Below are the most important business facts discovered\n- Data only from the 30th October 2016 to the 9th of March 2017\n- The bakery sales 96 different items in total, 85 are foods and 6 drinks as well as others for cancellations and adjustment\n- The bakery opens 7 days a week\n- It was closed only 4 days during the 6 month period. Those days were the 25th and 26th of December 2016 and the 1st and 2nd of January 2017\n- Coffee is the most sold item followed by bread\n- There are a few item that have been sold once or twice only, maybe there are worth stop selling those, or at least item that have a short life date\n- There is not enough data to make compare between seasons or months\n- Saturday is the busiest day of the week. Where there are more volume of sales around lunch and tea time. It could be that people prefer to eat lunch out with family or friends while doing shopping or other outdoor activities.\n- The busiest hours are from 10:00 to  14:00 all days. ","cd681a68":"- Adding another column for hour, to see the most\/least busy hours. This info can be use to determine number of staff that needs working.<br> Around midday is when it is most busy. Lunch time","53948667":"### Save clean dataset to excel As I like to explore in more detail the items list.","0d4b76a6":"### Yes, Saturday is the most busy day.","6708d7db":"### Importing all libraries","0aaddfaa":"### Some of the added features such as season, session, month, etc where not really used as this dataset has only data for four full months. ","bae64c0d":"- Temperature does not explain outliner. We see that some days with very low temperature had high sales and the other way around.\n- There is seasonality, as Saturday is the most busy day of the week\n- Can events explain outliners?\n","1a342a1f":"- Not all Saturdays are open until 22:00, Maybe worth checking if the days with longer opening hours where due to local festivities\n- For all days, the volume of sales after six o'clock is very small. is it worth keeping the Bakery open after 6?","11e7ca4f":"- Interesting results below. it seems that often there is one busy period follow by periods which are not as busy. This behaviour keep repeating, maybe there is a day of the week that is most busy. Also I like to find out what date was the lowest item sold, it seems as almost zero. <br>Can I explain why?","9882a42c":"### We can see here the most busiest times of the day as well as the busiest day of the week.","aef708a9":"### Opening the Bakery dataset","8b0c7fc1":"- The graph below confirms the findings, the outliner at the bottom refer to the event on Jan 1st. \n- The outliner at the top refer to some Saturday sales where there were local events.\nLocal events data was taken from http:\/\/www.edinburghguide.com\/events\/\nActual dates '2016-11-05','2016-11-12','2017-01-28','2017-02-04','2017-02-18','2017-03-04'","ba57e5b6":"### Checking to see if there are missing values","d36261da":"- Exploring sales for the first day\nCoffee is the most sold item, followed by bread ","1438d565":"### The following are some of the questions I want to answer\n- Can I predict future sales?\n\n- Could I explain the cause for unnormal periods where sales were really high or low?\n\n- Can we predict repetition of those events based maybe on weather or local events?<br>\nIn order to be able to answer the questions above I will also use **weather dataset** as well as **local events data**.","bd2de3e5":"- There is an item called 'NONE' there are in total 786 rows of it and one item called adjustment, but only one row of it, What are they? <br>This is what I see.","8d02f2ee":"The date with only one sold item was the 1 Jan 2017","17014f09":"### Overall the bakery sells more food than drinks, as expected","e01d9b83":"### See total sells per item","80e031d7":"### Sales and temperature graph, I am going to use the minimum temperatures","0c9b7c6c":"- This will add another column representing month in order","5bdb4cbf":"### Loading temperature dataset.","2105471f":"Can we see any relations if we only have sales of hot drinks and temperature","b5c0216c":"This will display the total sales per month. Can we see why the last and the first have the least sales? Also, we can see that December and January are the months with less sales. Maybe December and Jan have lots of bank holidays? ","7f7140a5":"We can use the Saturday percentage of sales with Saturday sale prediction as a guidance for the bakery stock.","b4e737f0":"aha, mystery solved!!!!. After parting for the new years, one of the employees with a key to the bakery remember that they did not have bread for next day dinner party celebration so on the way home got in a buy one break. As it was new year's the bakery was close.","6fdbd511":"As we have a few missing hours in temperature dataset, adding the last seen value.","be145ab2":" - I am creating a dictionary getting data from excel. Mapping items to category, which is food or drink.","a79833fe":"### Let's try to find out \n- How many items were sold daily\n- days with most sales\n- days with least sales","3e09fe45":"### Adding day of the week, to see which day is the most or least popular and similar for months","e6d45ab5":"Bakery is based on Edinburg old town.","b106a7fa":"Saving dataframe keeping data type","f34b1cc2":"### Will leave temperature just in case","e1683b5e":"- Adding seasons","0a66dddd":"### 'NONE' must be cancellation or errors, I am going to remove. I am going to remove the adjustments as well for the same reason.","6f8b5828":"### Can see what are the top item per day?","8b4feeef":"### Merging the two datasets.","f44479eb":"### Changing datatype of hourly in temperature dataset to datetime"}}