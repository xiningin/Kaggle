{"cell_type":{"4bff9d54":"code","82e3fba0":"code","da78ce22":"code","f5c06d5d":"code","6fa4dcb3":"code","3c411be4":"code","155ae888":"code","b2b35802":"code","64bfd332":"code","ae16b8fb":"code","f2d88c38":"code","6e025716":"code","a328e289":"code","e4a97481":"code","7aa22b5c":"code","02539b9d":"code","8abeb016":"code","b1b9b979":"code","9a2372ae":"code","1ad11965":"code","4ed42599":"code","11fa5e78":"code","5c9c2b2a":"code","70af63e3":"code","dd7c7009":"markdown","a4c09722":"markdown","95f77d8e":"markdown","686a8e63":"markdown","a61385ee":"markdown","a0656c22":"markdown","e32c4c87":"markdown","5a813fb2":"markdown","a05ebf6a":"markdown","452e4ec7":"markdown","f3e192e3":"markdown","5bfdb5f2":"markdown","11f1cc8f":"markdown"},"source":{"4bff9d54":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error\nplt.style.use('ggplot')\nimport warnings\nwarnings.filterwarnings('ignore')","82e3fba0":"train = pd.read_parquet('..\/input\/kaggle-pog-series-s01e01\/train.parquet')\ntest = pd.read_parquet('..\/input\/kaggle-pog-series-s01e01\/test.parquet')\nss = pd.read_csv('..\/input\/kaggle-pog-series-s01e01\/sample_submission.csv')","da78ce22":"cfg = {\n    'TARGET' : 'target',\n    'N_FOLDS' : 5,\n    'RANDOM_STATE': 529,\n    'LEARNING_RATE': 0.1\n}\n\ntrain_vids = train['video_id'].unique()","f5c06d5d":"kf = KFold(n_splits=cfg['N_FOLDS'],\n           shuffle=True,\n           random_state=cfg['RANDOM_STATE'])\n\n# Create Folds\nfold = 1\nfor tr_idx, val_idx in kf.split(train_vids):\n    fold_vids = train_vids[val_idx]\n    train.loc[train['video_id'].isin(fold_vids), 'fold'] = fold\n    fold += 1\ntrain['fold'] = train['fold'].astype('int')","6fa4dcb3":"def create_features(df, train=True):\n    \"\"\"\n    Adds features to training or test set.\n    \"\"\"\n    df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n    df['trending_date'] = pd.to_datetime(df['trending_date'], utc=True)\n    \n    # Feature 1 - Age of video\n    df['video_age_seconds'] = (df['trending_date'] - df['publishedAt']) \\\n        .dt.total_seconds().astype('int')\n    \n    # Trending day of week As a category\n    df['trending_dow'] = df['trending_date'].dt.day_name()\n    df['trending_dow']= df['trending_dow'].astype('category')\n    \n    df['published_dow'] = df['publishedAt'].dt.day_name()\n    df['published_dow']= df['published_dow'].astype('category')\n    \n    df['categoryId'] = df['categoryId'].astype('category')\n    \n    df['channel_occurance'] = df['channelId'].map(\n        df['channelId'].value_counts().to_dict())\n\n    df['channel_unique_video_count'] = df['channelId'].map(\n        df.groupby('channelId')['video_id'].nunique().to_dict())\n    \n    df['video_occurance_count'] = df.groupby('video_id')['trending_date'] \\\n        .rank().astype('int')\n    \n    return df","3c411be4":"train['isTrain'] = True\ntest['isTrain'] = False\ntt = pd.concat([train, test]).reset_index(drop=True).copy()\ntt = create_features(tt)\ntrain_feats = tt.query('isTrain').reset_index(drop=True).copy()\ntest_feats = tt.query('isTrain == False').reset_index(drop=True).copy()","155ae888":"FEATURES = ['video_age_seconds',\n            'trending_dow',\n            'published_dow',\n            'duration_seconds',\n            'categoryId',\n            'comments_disabled',\n            'ratings_disabled',\n            'channel_occurance',\n            'channel_unique_video_count',\n            'video_occurance_count'\n]\n\nTARGET = ['target']","b2b35802":"X_test = test_feats[FEATURES]\noof = train_feats[['id','target','fold']].reset_index(drop=True).copy()\nsubmission_df = test[['id']].copy()","64bfd332":"regs = []\nfis = []\n# Example Fold 1\nfor fold in range(1, 6):\n    print(f'===== Running for fold {fold} =====')\n    # Split train \/ val\n    X_tr = train_feats.query('fold != @fold')[FEATURES]\n    y_tr = train_feats.query('fold != @fold')[TARGET]\n    X_val = train_feats.query('fold == @fold')[FEATURES]\n    y_val = train_feats.query('fold == @fold')[TARGET]\n    print(X_tr.shape, y_tr.shape, X_val.shape, y_val.shape)\n\n    # Create our model\n    reg = lgb.LGBMRegressor(n_estimators=2800,\n                            learning_rate=cfg['LEARNING_RATE'],\n                            objective='mae',\n                            metric=['mae'],\n                            importance_type='gain'\n                           )\n    # Fit our model\n    reg.fit(X_tr, y_tr,\n            eval_set=(X_val, y_val),\n            verbose=200,\n           )\n\n    # Predicting on validation set\n    fold_preds = reg.predict(X_val)\n    oof.loc[oof['fold'] == fold, 'preds'] = fold_preds\n    # Score validation set\n    fold_score = mean_absolute_error(\n        oof.query('fold == 1')['target'],\n            oof.query('fold == 1')['preds']\n    )\n\n    # Creating a feature importance dataframe\n    fi = pd.DataFrame(index=reg.feature_name_,\n                 data=reg.feature_importances_,\n                 columns=[f'{fold}_importance'])\n\n    # Predicting on test\n    fold_test_pred = reg.predict(X_test,\n                num_iteration=reg.best_iteration_)\n    submission_df[f'pred_{fold}'] = fold_test_pred\n    print(f'Score of this fold is {fold_score:0.6f}')\n    regs.append(reg)\n    fis.append(fi)","ae16b8fb":"oof_score = mean_absolute_error(oof['target'], oof['preds'])\nprint(f'Out of fold score {oof_score:0.6f}')","f2d88c38":"fis_df = pd.concat(fis, axis=1)\nfis_df.sort_values('1_importance').plot(kind='barh', figsize=(12, 8),\n                                       title='Feature Importance Across Folds')\nplt.show()","6e025716":"pred_cols = [c for c in submission_df.columns if c.startswith('pred_')]\nsubmission_df['target_LGBM'] = submission_df[pred_cols].mean(axis=1)\noof['preds_LGBM'] = oof['preds']","a328e289":"FEATURES = ['video_age_seconds',\n#             'trending_dow',\n#             'published_dow',\n            'duration_seconds',\n            'categoryId',\n            'comments_disabled',\n            'ratings_disabled',\n            'channel_occurance',\n            'channel_unique_video_count',\n            'video_occurance_count'\n]\nX_test = test_feats[FEATURES]","e4a97481":"regs = []\nfis = []\n# Example Fold 1\nfor fold in range(1, 6):\n    print(f'===== Running for fold {fold} =====')\n    # Split train \/ val\n    X_tr = train_feats.query('fold != @fold')[FEATURES]\n    y_tr = train_feats.query('fold != @fold')[TARGET]\n    X_val = train_feats.query('fold == @fold')[FEATURES]\n    y_val = train_feats.query('fold == @fold')[TARGET]\n    print(X_tr.shape, y_tr.shape, X_val.shape, y_val.shape)\n\n    # Create our model\n    reg = lgb.LGBMRegressor(n_estimators=2500,\n                            learning_rate=0.1,\n                            objective='mae',\n                            metric=['mae'],\n                            importance_type='gain'\n                           )\n    # Fit our model\n    reg.fit(X_tr, y_tr,\n            eval_set=(X_val, y_val),\n            verbose=200,\n           )\n\n    # Predicting on validation set\n    fold_preds = reg.predict(X_val)\n    oof.loc[oof['fold'] == fold, 'preds'] = fold_preds\n    # Score validation set\n    fold_score = mean_absolute_error(\n        oof.query('fold == 1')['target'],\n            oof.query('fold == 1')['preds']\n    )\n\n    # Creating a feature importance dataframe\n    fi = pd.DataFrame(index=reg.feature_name_,\n                 data=reg.feature_importances_,\n                 columns=[f'{fold}_importance'])\n\n    # Predicting on test\n    fold_test_pred = reg.predict(X_test,\n                num_iteration=reg.best_iteration_)\n    submission_df[f'pred_{fold}'] = fold_test_pred\n    print(f'Score of this fold is {fold_score:0.6f}')\n    regs.append(reg)\n    fis.append(fi)","7aa22b5c":"oof_score = mean_absolute_error(oof['target'], oof['preds'])\nprint(f'Out of fold score {oof_score:0.6f}')","02539b9d":"pred_cols = [c for c in submission_df.columns if c.startswith('pred_')]\n\nsubmission_df['target_LGBM2'] = submission_df[pred_cols].mean(axis=1)\noof['preds_LGBM2'] = oof['preds']\n\nfig, axs = plt.subplots(1, 2, figsize=(12, 5))\noof.plot(x='preds_LGBM', y='preds_LGBM2', kind='scatter',\n         title='Compare OOF predictions for two models',\n        ax=axs[0])\n\nsubmission_df.plot(x='target_LGBM', y='target_LGBM2',\n                   kind='scatter', title='Compare Test predictions for two models',\n                  ax=axs[1])\nplt.show()","8abeb016":"weight = 0.5\n\ndef get_oof_score(weight, oof):\n    blend_pred = (oof['preds_LGBM'] * weight) + (oof['preds_LGBM2'] * (1- weight))\n    return mean_absolute_error(oof['target'], blend_pred)","b1b9b979":"myscores = {}\nfor weight in range(100):\n    weight \/= 100\n    score = get_oof_score(weight, oof)\n    myscores[weight] = score","9a2372ae":"blend_results = pd.DataFrame(myscores, index=['score']).T","1ad11965":"ax = blend_results.plot(title='Weight vs. OOF Score')\nax.set_xlabel('Weight %')\nax.set_ylabel('OOF Score')\nplt.show()","4ed42599":"blend_results.loc[blend_results['score'] == blend_results['score'].min()]","11fa5e78":"submission_df['target'] = (submission_df['target_LGBM'] * 0.35) + (submission_df['target_LGBM2'] * (1-0.35))","5c9c2b2a":"# pred_cols = [c for c in submission_df.columns if c.startswith('pred_')]\n\n# submission_df['target'] = submission_df[pred_cols].mean(axis=1)\n# Visually check correlation between fold predictions\n# sns.heatmap(submission_df[pred_cols].corr(), annot=True)","70af63e3":"submission_df[['id','target']] \\\n    .to_csv('submission.csv', index=False)","dd7c7009":"# Create Submission","a4c09722":"# Pog Competition Baselines\n- LightGBM\n- XGBoost\n\nIn this notebook we will ensemble based on out of fold predictions.","95f77d8e":"# Weighted Blend Based on OOF","686a8e63":"# Create Folds\n- This is how we will later split when validating our models","a61385ee":"# Look at Fold Feature Importances","a0656c22":"# Evaluation out of all out of fold predictions","e32c4c87":"# Save off as LGBM results","5a813fb2":"# Set Target and Features","a05ebf6a":"# Feature Engineering","452e4ec7":"# Setup KFold","f3e192e3":"# Train Model 2 - LightGBM Different Learning Rate","5bfdb5f2":"## The best weight is 0.35","11f1cc8f":"# Model 1 -  LGBM Model"}}