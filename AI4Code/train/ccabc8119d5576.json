{"cell_type":{"0b8ce0c9":"code","178c68fc":"code","bc6be75a":"code","1c189a37":"code","0dbed201":"code","34ada2c0":"code","93d83233":"code","f5ea208f":"code","52c6ecb5":"code","9de89a08":"code","ed208195":"code","7d2394ab":"code","2a3f3efb":"code","f002ec34":"code","a6e555d7":"code","d081545a":"markdown","f04146a5":"markdown"},"source":{"0b8ce0c9":"import pandas as pd, numpy as np\nfrom matplotlib import pyplot as plt\n\nimport scipy.stats  as stats","178c68fc":"pd.options.display.max_columns = 50","bc6be75a":"best = pd.read_csv(\"..\/input\/accuracy-best-public-lbs\/kkiller_first_public_notebook_under050_v5.csv\")\nbest.head()","1c189a37":"sales = pd.read_csv(\"..\/input\/m5-forecasting-uncertainty\/sales_train_validation.csv\")\nsales.head()","0dbed201":"sub = best.merge(sales[[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]], on = \"id\")\nsub[\"_all_\"] = \"Total\"\nsub.shape","34ada2c0":"sub.head()","93d83233":"qs = np.array([0.005,0.025,0.165,0.25, 0.5, 0.75, 0.835, 0.975, 0.995])\nqs.shape","f5ea208f":"qs2 = np.log(qs\/(1-qs))*.065\n\nratios = stats.norm.cdf(qs2)\nratios \/= ratios[4]\nratios = pd.Series(ratios, index=qs)\nratios.round(3)","52c6ecb5":"def quantile_coefs(q):\n    return ratios.loc[q].values","9de89a08":"def get_group_preds(pred, level):\n    df = pred.groupby(level)[cols].sum()\n    q = np.repeat(qs, len(df))\n    df = pd.concat([df]*9, axis=0, sort=False)\n    df.reset_index(inplace = True)\n    df[cols] *= quantile_coefs(q)[:, None]\n    if level != \"id\":\n        df[\"id\"] = [f\"{lev}_X_{q:.3f}_validation\" for lev, q in zip(df[level].values, q)]\n    else:\n        df[\"id\"] = [f\"{lev.replace('_validation', '')}_{q:.3f}_validation\" for lev, q in zip(df[level].values, q)]\n    df = df[[\"id\"]+list(cols)]\n    return df","ed208195":"def get_couple_group_preds(pred, level1, level2):\n    df = pred.groupby([level1, level2])[cols].sum()\n    q = np.repeat(qs, len(df))\n    df = pd.concat([df]*9, axis=0, sort=False)\n    df.reset_index(inplace = True)\n    df[cols] *= quantile_coefs(q)[:, None]\n    df[\"id\"] = [f\"{lev1}_{lev2}_{q:.3f}_validation\" for lev1,lev2, q in \n                zip(df[level1].values,df[level2].values, q)]\n    df = df[[\"id\"]+list(cols)]\n    return df","7d2394ab":"levels = [\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\", \"_all_\"]\ncouples = [(\"state_id\", \"item_id\"),  (\"state_id\", \"dept_id\"),(\"store_id\",\"dept_id\"),\n                            (\"state_id\", \"cat_id\"),(\"store_id\",\"cat_id\")]\ncols = [f\"F{i}\" for i in range(1, 29)]","2a3f3efb":"df = []\nfor level in levels :\n    df.append(get_group_preds(sub, level))\nfor level1,level2 in couples:\n    df.append(get_couple_group_preds(sub, level1, level2))\ndf = pd.concat(df, axis=0, sort=False)\ndf.reset_index(drop=True, inplace=True)\ndf = pd.concat([df,df] , axis=0, sort=False)\ndf.reset_index(drop=True, inplace=True)\ndf.loc[df.index >= len(df.index)\/\/2, \"id\"] = df.loc[df.index >= len(df.index)\/\/2, \"id\"].str.replace(\n                                    \"_validation$\", \"_evaluation\")\n\ndf.shape","f002ec34":"df.head()","a6e555d7":"df.to_csv(\"submission.csv\", index = False)","d081545a":"<font color=\"red\" size=\"5\">If this work lightens your pain when switching from accuracy to uncertainty prediction, please let's know your positive feedbacks by upvoting the kernel :)<font>","f04146a5":"This notebook will help you switching easily from **M5 accuracy** prediction to **uncertainty** . We just use a multiplier scheme under the hood."}}