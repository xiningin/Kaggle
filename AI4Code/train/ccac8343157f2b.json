{"cell_type":{"f8da4bf1":"code","685706fd":"code","1dbcd5f8":"code","4e3cfd57":"code","c56443c4":"code","e5ff7ccd":"code","85210861":"code","891d2898":"code","fb6d953a":"code","113d13f7":"code","5069a12a":"code","2291169c":"code","5ec8345e":"code","c8ae9c0f":"code","94b7d53e":"code","0ce9356b":"code","ecfee57b":"code","b1086294":"code","461d8ebc":"code","bde33bd8":"code","ff7c32a4":"code","6872c0c4":"code","35323172":"code","f5e941e2":"code","0226efb7":"code","b9edbe1d":"code","50a9ed28":"markdown","07d0d2f6":"markdown","ae91edc3":"markdown","15c7cf68":"markdown","5201533a":"markdown","893d0ee2":"markdown","764adf91":"markdown","80e1666a":"markdown","10275a32":"markdown","3af285e9":"markdown","dbc314b1":"markdown"},"source":{"f8da4bf1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","685706fd":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ndf=pd.read_csv('\/kaggle\/input\/telecom-users-dataset\/telecom_users.csv')\ndf.head()                                                                 ","1dbcd5f8":"df.shape , df.customerID.nunique()","4e3cfd57":"df.drop(['Unnamed: 0','customerID'],axis=1,inplace=True)\ndf.columns","c56443c4":"df.dtypes","e5ff7ccd":"def check(x):\n    try: \n        float(x)\n        return  False\n    except: \n        return True\ndf.TotalCharges[df.TotalCharges.apply(check)]     ","85210861":"df.iloc[df.TotalCharges[df.TotalCharges.apply(check)].index,17:]","891d2898":"df.drop(df[df.TotalCharges==' '].index,axis=0,inplace=True)\ndf.TotalCharges=df.TotalCharges.astype(float)","fb6d953a":"for i in list(df.dtypes[df.dtypes==object].index):\n    print(df[i].value_counts())\n    sns.histplot(x=df[i])\n    plt.xticks(rotation=90)\n    plt.show()","113d13f7":"df.Contract.replace(['Month-to-month','One year','Two year'],[1,12,24],inplace=True)\ndf.tenure=df.tenure\/12\nsns.displot(x=df.tenure,hue=df.Churn,alpha=0.7,bins=30,kde=True,col=df.gender)","5069a12a":"sns.boxplot(x=df.PaymentMethod,y=df.tenure,hue=df.gender)\nplt.xticks(rotation=90)","2291169c":"for i in df.dtypes[df.dtypes == object].index.tolist():\n    df[i] = df[i].astype('category')\ncat_columns = df.select_dtypes(['category']).columns\ndf[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)","5ec8345e":"pd.DataFrame(df.corr().Churn.sort_values(ascending=False)).loc['gender',:]","c8ae9c0f":"plt.figure(figsize=(12,8))\nsns.heatmap(df.corr())    # ,annot=True","94b7d53e":"pd.DataFrame(df.corr().Churn.sort_values(ascending=False))","0ce9356b":"X=df.drop('Churn',axis=1)\ny=df.Churn","ecfee57b":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=42)\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train=sc.fit_transform(X_train)\nX_test=sc.transform(X_test)","b1086294":"from imblearn.over_sampling import SMOTE\noversample = SMOTE()\nX_train, y_train= oversample.fit_resample(X_train, y_train)","461d8ebc":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score,f1_score\nlr=LogisticRegression()\nlr.fit(X_train,y_train)\naccuracy_score(y_test,lr.predict(X_test)),f1_score(y_test,lr.predict(X_test))","bde33bd8":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(X_train,y_train)\naccuracy_score(y_test,dt.predict(X_test)),f1_score(y_test,dt.predict(X_test))","ff7c32a4":"from sklearn.neighbors import KNeighborsClassifier\nknn=KNeighborsClassifier()\nknn.fit(X_train,y_train)\naccuracy_score(y_test,knn.predict(X_test)),f1_score(y_test,knn.predict(X_test))","6872c0c4":"from sklearn.naive_bayes import GaussianNB\nnb=GaussianNB()\nnb.fit(X_train,y_train)\naccuracy_score(y_test,nb.predict(X_test)),f1_score(y_test,nb.predict(X_test))","35323172":"from xgboost import XGBClassifier\nxgb=XGBClassifier(n_estimators= 50,objective= 'binary:logistic')\nxgb.fit(X_train,y_train)\naccuracy_score(y_test,xgb.predict(X_test)),f1_score(y_test,xgb.predict(X_test))","f5e941e2":"from sklearn.metrics import classification_report,ConfusionMatrixDisplay,confusion_matrix\nprint(classification_report(y_test,xgb.predict(X_test)))\nConfusionMatrixDisplay(confusion_matrix(y_test,xgb.predict(X_test))).plot()","0226efb7":"from sklearn.ensemble import AdaBoostClassifier\nabc=AdaBoostClassifier()\nabc.fit(X_train,y_train)\naccuracy_score(y_test,abc.predict(X_test)),f1_score(y_test,abc.predict(X_test))","b9edbe1d":"print(classification_report(y_test,abc.predict(X_test)))\nConfusionMatrixDisplay(confusion_matrix(y_test,abc.predict(X_test))).plot()","50a9ed28":"Histogram of various object type Columns( Variable )","07d0d2f6":"Above output is the Index nos. of the string (' ') {single space string}","ae91edc3":"TotalCharges is of object type, so when converting it into float type { df.TotalCharges.astype(float) } ,we encounter the below error :\n#       ValueError: could not convert string to float: \n    So, following code is to detect the string Charcter which are not convertible to float","15c7cf68":"# ****From Above two graphs and the cell, we can see that the data is not gender bias or we can say that its correlation with the Churn rate is almost Zero.****","5201533a":"No     4389     \nYes    1587    \n\nChurn rate is highly biased, so will be our Model, So later we'll use SMOTE {Synthetic Minority Over-sampling Technique} technique on our training set to Equalize both Yes and No.","893d0ee2":"# Keeping in mind the tradeoff between Recall and Precision we can here manage high False positive because the model has predicted them as leaving ( instead they are not ).\n\n# But there is a large Room for the improvement of Accuracy , Recall , Precison and F1-Score.","764adf91":"Customer ID entries are unique . ","80e1666a":"#   Churn relation with other variables.","10275a32":"# Any Feedback for EDA , Data Preprocessing or Model Building is Welcome .  ","3af285e9":"# Best Model, so far is the Adaboost model, with pretty high accuracy and high recall.\n\n# We need high Recall here because we want our model to predict less False Negative .\n\n# By increasing the recall we( Telecom Company ) can approach the customer with more offers, who are truly deciding to leave the Service.\n\n#  ****Recall= True Positive \/ ( True Positive + False Neagtive )****","dbc314b1":"# Long Live the Open Source Community"}}