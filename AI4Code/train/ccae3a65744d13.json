{"cell_type":{"16702d41":"code","509f3ffa":"code","309c9408":"code","cd0816a8":"code","65409e8b":"code","04712994":"code","16cbbc5a":"code","bcfef3c4":"code","a6f215b6":"code","af9ca2dc":"code","24287d54":"code","cadff5be":"code","a41bc5f0":"code","8a02e47d":"code","1891d0be":"code","ee31f557":"code","35556112":"markdown","be4cec57":"markdown","a827a8f1":"markdown","d9ba03a6":"markdown","3c8b2945":"markdown","a7fc3ff3":"markdown","acc3aace":"markdown","5e8e7416":"markdown"},"source":{"16702d41":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\ns=StandardScaler()\nimport plotly.graph_objects as go\nfrom sklearn.svm import LinearSVC\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","509f3ffa":"df=pd.read_csv('\/kaggle\/input\/iris-flower-dataset\/IRIS.csv')","309c9408":"df.shape","cd0816a8":"df.head()","65409e8b":"df['species'].value_counts()","04712994":"df['species'].replace({'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2},inplace=True)","16cbbc5a":"df['species'].value_counts()","bcfef3c4":"def plot(x,y,cvar,Scale):\n  if Scale == 'Yes': ## if scaling is needed or not\n    x=s.fit_transform(x)\n  else:\n    pass\n \n  model = LinearSVC(C=cvar, loss='hinge') ## Linear SVM Model with hyper parameter tuning\n  clf = model.fit(x, y)\n  Z = lambda X,Y: (-clf.intercept_[0]-clf.coef_[0][0]*X-clf.coef_[0][1]*Y) \/ clf.coef_[0][2] \n    # The equation of the separating plane is given by all x so that np.dot(svc.coef_[0], x) + b = 0.\n    # Solve for w3 (z)\n    \n  trace1 = go.Mesh3d(x = x[:,0], y = x[:,1], z = Z(x[:,0],x[:,1])) ## for separating plane\n  trace2 = go.Scatter3d(x=x[:,0], y=x[:,1], z=x[:,2], mode='markers',\n                        marker = dict(size = 12,color = y,colorscale = 'Viridis')) ## for vector plots\n  data=[trace1,trace2]\n  fig = go.Figure(data=data,layout={})\n  fig.show()","a6f215b6":"p = df.iloc[:,[2,3,0]].values\nq = (df.species!=0).astype(np.float64)","af9ca2dc":"plot(p,q,0.1,'No')","24287d54":"plot(p,q,0.1,'Yes')","cadff5be":"m = df.iloc[:,[2,3,0]].values\nn = (df.species!=1).astype(np.float64)","a41bc5f0":"plot(m,n,10,'No') ## Without Scaling","8a02e47d":"plot(m,n,10,'Yes') ## With Scaling","1891d0be":"a=df.iloc[:,[2,3,0]].values\nb = (df.species!=0).astype(np.float64)\nplot(a,b,0.01,'Yes')","ee31f557":"plot(a,b,100,'Yes')","35556112":"- For Scaled Data It's Performance is Better","be4cec57":"- Sensitivity is higher to outliers","a827a8f1":"## Effect Of Feature Scaling","d9ba03a6":"## Importance Of Hyper Parameter C","3c8b2945":"## In presence of outliers ","a7fc3ff3":"## 1. Basic EDA","acc3aace":"- C parameter in SVM model, A small value of C ---> leads to more margin violation and for higher value of C ---> means less margin violation","5e8e7416":"## 2. SVM Margin Regularizing and Visualization Function "}}