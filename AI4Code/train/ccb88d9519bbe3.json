{"cell_type":{"57e7b901":"code","d6c09494":"code","5dde4279":"code","fec7db7c":"code","d6c2a972":"code","579cb52e":"code","de53e439":"code","f7c7ed0f":"code","c7ee28c8":"code","d0e086c3":"code","12d9d1d1":"code","bff66f26":"code","322747cf":"code","2b58cdb2":"code","798d6d69":"code","95d190f4":"code","4e46cc6a":"code","61f49cd3":"code","4c44a54e":"code","3282765e":"code","c69c2d77":"code","e4c92a47":"code","1b9baed0":"code","b2adee65":"code","315c01ec":"code","f3bdf413":"code","efd79622":"code","a7f75612":"code","2c73bd0e":"code","dda9e821":"code","ce24fbb0":"code","158ada0d":"code","9cea1ebc":"code","da824a7d":"code","dfe4d148":"code","7f8c7175":"code","d836fdd3":"code","45c06569":"code","144d401b":"code","4f7f1c92":"code","4dca9e19":"code","c5478ed6":"code","c13a7b95":"code","8bb522dd":"code","8e0174d3":"markdown","901010e0":"markdown","4e33354d":"markdown","83f7e3e4":"markdown","8d23ea56":"markdown","e9736b89":"markdown","f3d2237d":"markdown","b78a36f5":"markdown","3e3aa9ed":"markdown","aa35641f":"markdown","9fc1eafc":"markdown","6f415731":"markdown","00643c6f":"markdown","09e10c21":"markdown","1e9bff8a":"markdown","3fed2f68":"markdown","9a16578f":"markdown"},"source":{"57e7b901":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d6c09494":"import urllib\nimport matplotlib.pyplot as plt\nimport cv2\nimport glob\nimport os\nimport time\nfrom PIL import Image","5dde4279":"df = pd.read_json(\"\/kaggle\/input\/vehicle-number-plate-detection\/Indian_Number_plates.json\", lines=True)\ndf.head()","fec7db7c":"df.shape","d6c2a972":"new_csv=df.to_csv(\"indian_license_plates.csv\", index=False)","579cb52e":"new_df=pd.read_csv(\"\/kaggle\/working\/indian_license_plates.csv\")\nnew_df.head(10)","de53e439":"df['annotation'][0]","f7c7ed0f":"os.mkdir(\"Number Plates\")","c7ee28c8":"data = dict()\ndata[\"img_name\"] = list()\ndata[\"img_width\"] = list()\ndata[\"img_height\"] = list()\ndata[\"top-x\"] = list()\ndata[\"top-y\"] = list()\ndata[\"bottom-x\"] = list()\ndata[\"bottom-y\"] = list()","d0e086c3":"data","12d9d1d1":"df['annotation'][0]","bff66f26":"df['annotation'][0][0][\"points\"]","322747cf":"new_df.head(5)","2b58cdb2":"# for index,row in new_df.iterrows():\n#     print(row)","798d6d69":"count = 0\nfor index, row in df.iterrows():\n    img = urllib.request.urlopen(row[\"content\"])\n    img = Image.open(img)\n    img = img.convert('RGB')\n    img.save(\"Number Plates\/car{}.jpeg\".format(count), \"JPEG\")\n    \n    data[\"img_name\"].append(\"car{}\".format(count))\n    \n    d = row[\"annotation\"]\n    \n    data[\"img_width\"].append(d[0][\"imageWidth\"])\n    data[\"img_height\"].append(d[0][\"imageHeight\"])\n    data[\"top-x\"].append(d[0][\"points\"][0][\"x\"])\n    data[\"top-y\"].append(d[0][\"points\"][0][\"y\"])\n    data[\"bottom-x\"].append(d[0][\"points\"][1][\"x\"])\n    data[\"bottom-y\"].append(d[0][\"points\"][1][\"y\"])\n    \n    count += 1\n    \nprint(\"Done Successfully\")    ","95d190f4":"# data","4e46cc6a":"new_data=pd.DataFrame(data)\nnew_data.head()","61f49cd3":"new_data.dtypes","4c44a54e":"new_data.shape","3282765e":"new_data.describe()","c69c2d77":"new_data.dtypes","e4c92a47":"new_data['img_name']=new_data['img_name']+\".jpeg\"","1b9baed0":"new_data","b2adee65":"width= 300\nheight= 300\nchannels= 3","315c01ec":"def viewimage(t):\n    \n    image = cv2.imread(\"Number Plates\/\" + new_data[\"img_name\"].iloc[t])\n    \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, dsize=(width,height))\n    \n    top_x=int(new_data['top-x'].iloc[t]* width)\n    top_y=int(new_data['top-y'].iloc[t]*height)\n    bot_x=int(new_data['bottom-x'].iloc[t]*height)\n    bot_y=int(new_data['bottom-y'].iloc[t]*height)\n    \n    \n    new_img=cv2.rectangle(image,(top_x,top_y),(bot_x,bot_y),(0, 0, 255), 1)\n    \n    plt.imshow(new_img)\n    \n    plt.show()","f3bdf413":"viewimage(10)","efd79622":"viewimage(100)","a7f75612":"n = 5\ndrop_indices = np.random.choice(new_data.index, n, replace=False)\ndf_subset = new_data.drop(drop_indices)","2c73bd0e":"df_subset","dda9e821":"drop_indices","ce24fbb0":"from keras.applications.vgg16 import VGG16\nfrom keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Input, Dropout\nfrom keras.models import Model, Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam","158ada0d":"datagen = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)","9cea1ebc":"train_generator = datagen.flow_from_dataframe(\n    df_subset,\n    directory=\"Number Plates\/\",\n    x_col=\"img_name\",\n    y_col=[\"top-x\", \"top-y\", \"bottom-x\", \"bottom-y\"],\n    target_size=(width,height),\n    batch_size=32, \n    class_mode=\"raw\",\n    subset=\"training\")\n\nvalidation_generator = datagen.flow_from_dataframe(\n    df_subset,\n    directory=\"Number Plates\/\",\n    x_col=\"img_name\",\n    y_col=[\"top-x\", \"top-y\", \"bottom-x\", \"bottom-y\"],\n    target_size=(width,height),\n    batch_size=32, \n    class_mode=\"raw\",\n    subset=\"validation\")","da824a7d":"train_generator","dfe4d148":"len(train_generator)","7f8c7175":"len(validation_generator)","d836fdd3":"model = Sequential()\nmodel.add(VGG16(weights=\"imagenet\", include_top=False, input_shape=(width,height,channels)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(4, activation=\"sigmoid\"))\n\nmodel.layers[-6].trainable = False","45c06569":"model.summary()","144d401b":"adam = Adam(lr=0.0005)\nmodel.compile(optimizer='adam', loss=\"mse\",metrics=['accuracy'])","4f7f1c92":"history = model.fit_generator(train_generator,\n    steps_per_epoch=6,\n    validation_data=validation_generator,\n    validation_steps=2,\n    epochs=20)","4dca9e19":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","c5478ed6":"plt.title('Accuracy')\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.legend()\nplt.show();","c13a7b95":"import pytesseract\nfrom PIL import Image","8bb522dd":"for idx, row in new_data.iloc[drop_indices].iterrows():    \n    \n    img = cv2.resize(cv2.imread(\"Number Plates\/\" + row['img_name']) \/ 255.0, dsize=(width,height))\n    y_hat = model.predict(img.reshape(1, width,height, 3)).reshape(-1) * width\n    \n    xt, yt = y_hat[0], y_hat[1]\n    xb, yb = y_hat[2], y_hat[3]\n    \n    img = cv2.cvtColor(img.astype(np.float32),cv2.COLOR_BGR2RGB)\n    image = cv2.rectangle(img, (xt, yt), (xb, yb), (0,0,255), 1)\n    \n    clone = image.copy() \n    \n    # Cropping the predicted reactangle region into a new image\n    crop_img = clone[int(yt):int(yb),int(xt):int(xb)] \n   \n    plt.imshow(crop_img)\n    im = Image.fromarray((crop_img * 255).astype(np.uint8))\n   \n#     plt.imshow(crop_img)\n    \n    \n   \n    plt.show()\n    ## Detecting Car Number using pytesseract\n    car_number = pytesseract.image_to_string(im, lang=\"eng\")\n    \n    print(\"The Car Number is\",car_number)","8e0174d3":"# Filtering 5 images out of the dataset and dropping this from the training dataset for testing..","901010e0":"# Length of Training Generator..","4e33354d":"# Model Accuracy Graph","83f7e3e4":"# Length of Testing Generator..","8d23ea56":"# Augmenting the data..","e9736b89":"# We have to separate the Image name, Image Width,Image Height,Top X Coordinate, Top Y Coordinate, Bottom x Coordinate, Bootom Y Coordinate..","f3d2237d":"# CNN Model..","b78a36f5":"# For improvement in this model we need to add more training examples and better the quality of the images.","3e3aa9ed":"# Changing the dataset view..\n# Decoding the Annotations Column:-->","aa35641f":"# Indices of dropped images..","9fc1eafc":"# Setting width and height of an image as 300*300 and number of channels as 3(i.e RGB)","6f415731":"# Model Evaluation by testing the dropped images fom training set..","00643c6f":"# Adding jpeg in the end of the image name..","09e10c21":"# Model Loss Graph","1e9bff8a":"# Seeing the pictures in 300*300 dimension:-->","3fed2f68":"# We saw here that our model is locating the board locations decently..And the Pytesseract is also estimating correctly when the image quality and orientation is clear and good.","9a16578f":"# So we have successsfully decoded the data to a dataset.."}}