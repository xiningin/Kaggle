{"cell_type":{"da12e456":"code","3b205350":"code","1825dfc6":"code","2357a7de":"code","ba478837":"code","65789311":"code","49539d6f":"markdown"},"source":{"da12e456":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('..'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","3b205350":"data = pd.read_csv('..\/input\/learn-together\/train.csv', index_col = 0)\nprint(data.columns)\nX = data.drop('Cover_Type',axis=1)\ny = data['Cover_Type']\n\nX.describe()","1825dfc6":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nrfc = RandomForestClassifier()\nparams = {'n_estimators': [20,50,100,150,200,250], 'criterion': ['gini', 'entropy'], 'min_samples_leaf' : [1,.01,.001]}\n\nmysearch = GridSearchCV(rfc, params, cv=5)\nmysearch.fit(X,y)","2357a7de":"mysearch.best_estimator_","ba478837":"testdata = pd.read_csv('..\/input\/learn-together\/test.csv', index_col = 0)\nprint(testdata.tail)\nresults = mysearch.predict(testdata)\n\n","65789311":"predictions = pd.DataFrame({'Id': testdata.index, 'Cover_Type':results})\npredictions.tail\npredictions.to_csv('submission.csv', index= False)","49539d6f":"Now, let's try some different parameters to see what forest configuration gives the best results. As a little review, here's what we're varying in each case:\n\n**n_estimators** - the number of trees in the forest to use\n\n**criterion** - how the alg decides when it's apporpriate to make splits in the tree\n\n**min_samples_leaf **- since they are decimals, they represent the proportion of the sample that may be left on a leaf"}}