{"cell_type":{"55a134f5":"code","0411f0eb":"code","506ea022":"code","b411a2b6":"code","9a7ddaf1":"code","ff8e0739":"code","13fe9897":"code","82278401":"code","536d763d":"code","e041c9bc":"code","04b06552":"code","f91e1b21":"code","696b54d8":"code","1c18189f":"code","db463e70":"code","6d1d1b0a":"code","77ddb4b5":"code","7419e4f0":"code","1145466d":"code","17325bff":"code","4a50ac83":"code","5a3be94a":"code","02e5ef7f":"code","dfb8e93e":"code","2cc6be85":"code","e6854965":"code","e9d1e2d9":"code","71841cc9":"code","559d9f84":"code","6ed17e8c":"code","624e9b59":"code","04f14a8d":"code","b629d5e5":"code","e5cb3575":"markdown","d5228117":"markdown","f01352a6":"markdown","54b71c59":"markdown","56aca8f2":"markdown","62f27874":"markdown","bcf9ab06":"markdown","df8b8ee2":"markdown","2e48e377":"markdown","b70d7e1f":"markdown","fec4166a":"markdown","6bd15776":"markdown","a14f6381":"markdown"},"source":{"55a134f5":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nfrom kaggle_datasets import KaggleDatasets\nimport json\nfrom functools import partial\nprint(\"TensorFlow version: \", tf.__version__)","0411f0eb":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(\"Device:\", tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('#Replicas: ', strategy.num_replicas_in_sync)","506ea022":"train_df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\ntrain_df.head()","b411a2b6":"n0, n1, n2, n3, n4 = np.bincount(train_df['label'])","9a7ddaf1":"total = train_df.shape[0]\ntotal","ff8e0739":"train_df['label'].value_counts()","13fe9897":"GCS_PATH = KaggleDatasets().get_gcs_path()","82278401":"BATCH_SIZE = 64\nIMAGE_SIZE = [512, 512]","536d763d":"FILENAMES = tf.io.gfile.glob(GCS_PATH + \"\/train_tfrecords\/*.tfrec\")\ntrain_split = int(0.7 * len(FILENAMES))\nval_split = int(0.2 * len(FILENAMES))\nTRAINING_FILENAMES, VAL_FILENAMES, EVAL_FILENAMES = FILENAMES[:train_split], FILENAMES[train_split:train_split+val_split],FILENAMES[train_split+val_split:]\n\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + \"\/test_tfrecords\/*.tfrec\")\nprint(\"Total labeled files: \",len(FILENAMES))\nprint(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\nprint(\"Validation TFRecord Files:\", len(VAL_FILENAMES))\nprint(\"Evalution TFRecord Files:\", len(EVAL_FILENAMES))\nprint(\"Test TFRecord Files:\", len(TEST_FILENAMES))","e041c9bc":"TEST_FILENAMES","04b06552":"test_raw_dataset = tf.data.TFRecordDataset(TEST_FILENAMES)\ntest_image_feature_description = {\n\n    \"image\": tf.io.FixedLenFeature([],tf.string),\n    \"image_name\": tf.io.FixedLenFeature([],tf.string)\n}\n\n#read below comment to know about feature description\n\ndef _parse_image_function_test(example_proto):\n  # Parse the input tf.train.Example proto using the dictionary above.\n  return tf.io.parse_single_example(example_proto, test_image_feature_description)\n\ntest_parsed_image_dataset = test_raw_dataset.map(_parse_image_function_test)","f91e1b21":"ids = []\nfor image_features in test_parsed_image_dataset:\n  id = image_features['image_name'].numpy().decode(\"utf-8\") \n  ids.append(id)\nlen(ids)","696b54d8":"def decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.cast(image, tf.float32)\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef read_tfrecord(example, labeled):\n    tfrecord_format = (\n        {\n        \"image\": tf.io.FixedLenFeature([],tf.string),\n        \"image_name\": tf.io.FixedLenFeature([],tf.string),\n        \"target\": tf.io.FixedLenFeature([],tf.int64)\n        }\n        if labeled\n        else { \"image\": tf.io.FixedLenFeature([],tf.string),\n                \"image_name\": tf.io.FixedLenFeature([],tf.string),}\n    )\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example[\"image\"])\n    if labeled:\n        label = [tf.cast(example[\"target\"], tf.int64)]\n        return image, label\n    return image","1c18189f":"def load_dataset(filenames, labeled=True,order = True):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = not order  # disable order, increase speed\n    dataset = tf.data.TFRecordDataset(filenames)  # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order)  # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n    # returns a dataset of (image, label) pairs if labeled=True or just images if labeled=False\n    return dataset\n\ndef get_dataset(filenames, labeled=True,shuffle=True,order=True):\n    \n    dataset = load_dataset(filenames, labeled=labeled,order=order)\n    if shuffle:\n        dataset = dataset.shuffle(2048)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE)\n    return dataset","db463e70":"train_dataset = get_dataset(TRAINING_FILENAMES)\nval_dataset = get_dataset(VAL_FILENAMES)\neval_dataset = get_dataset(EVAL_FILENAMES)","6d1d1b0a":"test_dataset = get_dataset(TEST_FILENAMES, labeled=False,shuffle=False,order=False)\n","77ddb4b5":"labels_file = '..\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json'\nf= open(labels_file)\nlabels = json.load(f)\nf.close()\nlabels","7419e4f0":"train_dataset","1145466d":"image_batch, label_batch = next(iter(train_dataset))\n","17325bff":"def show_batch(image_batch, label_batch):\n    plt.figure(figsize=(15, 15))\n    for n in range(25):\n        ax = plt.subplot(5, 5, n + 1)\n        plt.imshow(image_batch[n] \/ 255.0)\n        t = label_batch[n]\n        \n        title = labels[str(t[0])]\n        plt.title(title)\n        plt.axis(\"off\")\n    plt.tight_layout()\n\n\n\nshow_batch(image_batch.numpy(), label_batch.numpy())","4a50ac83":"weight_for_0 = (1\/n0)*total\/5\nweight_for_1 = (1\/n1)*total\/5\nweight_for_2 = (1\/n2)*total\/5\nweight_for_3 = (1\/n3)*total\/5\nweight_for_4 = (1\/n4)*total\/5\nprint(weight_for_0,weight_for_1,weight_for_2,weight_for_3,weight_for_4)","5a3be94a":"class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2, 3: weight_for_3, 4: weight_for_4}","02e5ef7f":"\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', save_best_only=True, monitor='val_loss', mode='min')\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(\n    patience=10, restore_best_weights=True\n)","dfb8e93e":"  def make_model1():\n    base_model = tf.keras.applications.MobileNet(\n        input_shape=(*IMAGE_SIZE, 3), include_top=False, weights=\"imagenet\"\n    )\n\n    base_model.trainable = False\n\n    inputs = tf.keras.layers.Input([*IMAGE_SIZE, 3])\n    \n    x = base_model(inputs, training=False)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    \n   \n    outputs = tf.keras.layers.Dense(5, activation=\"softmax\")(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    model.compile(\n        optimizer='adam',\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy'])\n    # used sparse_categorical_crossentropy instead of categorical_crossentropy because output is not one hot vector\n    # categorical_accuracy == accuracy for this data\n\n    return model","2cc6be85":"'''import efficientnet.efficientnet.tfkeras as efn \n  def make_model():\n    base_model = efn.EfficientNetB7(\n        input_shape=(*IMAGE_SIZE, 3), include_top=False, weights=\"imagenet\"\n    )\n\n    base_model.trainable = False\n\n    inputs = tf.keras.layers.Input([*IMAGE_SIZE, 3])\n    \n    x = base_model(inputs, training=False)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    \n   \n    outputs = tf.keras.layers.Dense(5, activation=\"softmax\")(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    model.compile(\n        optimizer='adam',\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy'])\n    # used sparse_categorical_crossentropy instead of categorical_crossentropy because output is not one hot vector\n    # categorical_accuracy == accuracy for this data\n\n    return model'''","e6854965":"with strategy.scope():\n    model = make_model1()\n","e9d1e2d9":"history = model.fit(\n    train_dataset,\n    epochs=100,\n    validation_data=val_dataset,\n    callbacks=[early_stopping_cb, checkpoint],\n    class_weight=class_weight\n)","71841cc9":"model.evaluate(eval_dataset)","559d9f84":"pred = model.predict(test_dataset)\npred","6ed17e8c":"pred_classes  = pred.argmax(axis=1)","624e9b59":"sample_df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\nsample_df.head()","04f14a8d":"submission_df = pd.DataFrame()\nsubmission_df['image_id'] = ids\nsubmission_df['label'] = pred_classes\nsubmission_df.head()\n","b629d5e5":"submission_df.to_csv('submission.csv',index=False)","e5cb3575":"# Setup","d5228117":"# This notebook demonstrate use of TF Reocords because TPU training is optimized with TF Record input pipe line","f01352a6":"# Make predictions","54b71c59":"# Tips for improvement\n1. Thing about imbalanced classes\n2. Data augmentation\n3. Better model and fine tuning\n","56aca8f2":"## Get order of IDs of test data, so that we can create submission file accordingly","62f27874":"# Content\n1. Setup\n2. Data processing\n3. Visualize sample batch\n4. Build and train model\n5. Make predictions\n6. Tips for improvement\n","bcf9ab06":"# Data processing","df8b8ee2":"To know, how one can get\/ know feature description, have a loot at this [notebook](https:\/\/www.kaggle.com\/senkmp\/simple-eda-using-tf-records) https:\/\/www.kaggle.com\/senkmp\/simple-eda-using-tf-records","2e48e377":"# Build and train model","b70d7e1f":"# Visualize sample batch","fec4166a":"## Input Pipe line","6bd15776":"**Let me know in comment section if this is helpful \u2b06\ufe0f**","a14f6381":"## Give them equal rights :)"}}