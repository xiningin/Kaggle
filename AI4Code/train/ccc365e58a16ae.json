{"cell_type":{"eeec1bb3":"code","bcede898":"code","9d276750":"code","308c558c":"code","389c345f":"code","afac54b5":"code","3386e86e":"code","fbec9457":"code","2bb5b396":"code","00f7593f":"code","d1dbc40e":"code","930c66c7":"code","e1b97f45":"code","8903c672":"code","c0ef63a6":"code","f58a121d":"code","c9205419":"code","21370825":"code","59b3825f":"code","fcbdb601":"code","3bee3f72":"code","8819d508":"code","ff0cd2cb":"code","9437322a":"code","1c95a2bb":"code","699df962":"code","29e00438":"code","09fa1cfb":"code","12951082":"code","285cf9db":"code","0fb2fd21":"code","381d2ce0":"code","b4e35e13":"code","e4d49737":"code","59434c58":"code","d0071801":"code","ae03613d":"code","af19b512":"code","e998a044":"code","575e3982":"code","75afff6b":"code","91a189a3":"code","2d6a02cc":"code","35bf493c":"code","f4b7edf3":"code","c9056bbe":"code","60b5b75f":"code","65dba3f8":"code","fcea0210":"code","793d7f88":"code","b6b14553":"code","898552e1":"code","41014b64":"code","e3560ad0":"code","dd8428d6":"code","31d9d7f7":"code","3835ec96":"code","866339ee":"code","7c206bdb":"code","e8fb98ca":"code","591e43a7":"code","57bece0f":"code","6f08f2cf":"code","9b728cfa":"code","311940c9":"code","37f62a6b":"code","20786d65":"code","769e4113":"code","0d91347c":"code","79f86f57":"code","2c5e1883":"code","21991f25":"code","6fccd6e0":"markdown","d39e7d9a":"markdown","b6d9e2c4":"markdown","0f5445a1":"markdown","2ffe16a1":"markdown","264bc7b6":"markdown","e06c5d5f":"markdown","f41ad568":"markdown","f550c800":"markdown","a7fdcd33":"markdown","f53ca16c":"markdown","4b4d6ed9":"markdown","467ca51d":"markdown","580d2a99":"markdown","1eba3336":"markdown","0dad829a":"markdown","205f4a8f":"markdown","ee5e8f0f":"markdown","9c495d34":"markdown","13fd2ea1":"markdown","0ef0cf83":"markdown","991289da":"markdown"},"source":{"eeec1bb3":"import pandas as pd\nfilename = \"\/kaggle\/input\/titanic\/train.csv\"\ntitanic_data = pd.read_csv(filename)\ntitanic_data.head()\nimport seaborn as sns \nimport matplotlib as plt\n","bcede898":"titanic_data.head(10)","9d276750":"#Let's find how many rows and columns are present in the dataset\ntitanic_data.shape","308c558c":"sns.countplot(x=\"Survived\",data=titanic_data)","389c345f":"titanic_data[\"Survived\"].value_counts()","afac54b5":"sns.countplot(x=\"Survived\",hue = \"Sex\", data = titanic_data)","3386e86e":"women = titanic_data.loc[titanic_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","fbec9457":"men = titanic_data.loc[titanic_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","2bb5b396":"sns.countplot(x=\"Survived\",hue = \"Pclass\", data = titanic_data)","00f7593f":"titanic_data[\"Age\"].plot.hist()","d1dbc40e":"titanic_data[\"Fare\"].plot.hist(bins=20, figsize=(10,5))","930c66c7":"titanic_data.info()","e1b97f45":"sns.countplot(x=\"SibSp\",data=titanic_data)","8903c672":"sns.countplot(x=\"Parch\",data=titanic_data)","c0ef63a6":"#Checking for null values in the dataset\ntitanic_data.isnull()\n#False means data has a value, True means data does NOT have any value ","f58a121d":"titanic_data.isnull().sum()","c9205419":"sns.boxplot(x=\"Pclass\",y=\"Age\",data=titanic_data)","21370825":"titanic_data.head(5)","59b3825f":"# We will drop Cabin column as it has 77 % data is missing! \ntitanic_data.drop(\"Cabin\",axis=1, inplace=True)","fcbdb601":"titanic_data.head(5)","3bee3f72":"titanic_data['Age'].fillna(titanic_data['Age'].mean(),inplace=True)","8819d508":"titanic_data.isnull().sum()","ff0cd2cb":"sex=pd.get_dummies(titanic_data[\"Sex\"])","9437322a":"sex=pd.get_dummies(titanic_data[\"Sex\"],drop_first=True)","1c95a2bb":"sex.head(5)","699df962":"pd.get_dummies(titanic_data[\"Embarked\"])","29e00438":"embark=pd.get_dummies(titanic_data[\"Embarked\"],drop_first=True)","09fa1cfb":"embark.head(5)\n#drop first value because if Q and S is 0 that means automatically C is 1","12951082":"Pcl=pd.get_dummies(titanic_data[\"Pclass\"])","285cf9db":"Pcl=pd.get_dummies(titanic_data[\"Pclass\"],drop_first=True)","0fb2fd21":"Pcl.head(5)","381d2ce0":"titanic_data=pd.concat([titanic_data,sex,embark,Pcl],axis=1)","b4e35e13":"titanic_data.head(5)","e4d49737":"titanic_data.drop(['Sex','Embarked','Pclass','Name','Ticket','Fare'],axis=1, inplace=True)","59434c58":"\ntitanic_data.head(5)","d0071801":"titanic_data.isnull().sum()","ae03613d":"## Train Data \nX = titanic_data.drop(\"Survived\",axis=1)\ny = titanic_data[\"Survived\"]\nprint(X) ","af19b512":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33,random_state=42) \nfrom sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression()\n","e998a044":"logmodel.fit(X_train, y_train)\npredictions = logmodel.predict(X_train) ","575e3982":"from sklearn.metrics import classification_report\nclassification_report(y_train,predictions)\nfrom sklearn.metrics import confusion_matrix \nconfusion_matrix(y_train,predictions)","75afff6b":"from sklearn.metrics import accuracy_score","91a189a3":"accuracy_score(y_train,predictions)","2d6a02cc":"# Beginning to import the test.csv file ....\n\nimport pandas as pd\nfilename1 = \"\/kaggle\/input\/titanic\/test.csv\"\ntest_data = pd.read_csv(filename1)\ntest_data.shape","35bf493c":"test_data.head()","f4b7edf3":"test_data.info()","c9056bbe":"test_data[\"Age\"].plot.hist()","60b5b75f":"test_data[\"Fare\"].plot.hist()","65dba3f8":"test_data[\"Fare\"].plot.hist(bins=20, figsize=(10,5))","fcea0210":"sns.countplot(x=\"SibSp\",data=test_data)","793d7f88":"sns.countplot(x=\"Parch\",data=test_data)","b6b14553":"test_data.isnull()\n#False means data has a value, True means data does NOT have any value","898552e1":"test_data.isnull().sum()","41014b64":"sns.boxplot(x=\"Pclass\",y=\"Age\",data=test_data)","e3560ad0":"test_data['Age'].fillna(test_data['Age'].mean(),inplace=True)","dd8428d6":"test_data.drop(\"Cabin\",axis=1, inplace=True)","31d9d7f7":"test_data.isnull().sum()","3835ec96":"sex=pd.get_dummies(test_data[\"Sex\"],drop_first=True)","866339ee":"sex.head(5)","7c206bdb":"embark=pd.get_dummies(test_data[\"Embarked\"],drop_first=True)","e8fb98ca":"embark.head(5)","591e43a7":"Pcl=pd.get_dummies(test_data[\"Pclass\"],drop_first=True)","57bece0f":"Pcl.head(5)","6f08f2cf":"test_data=pd.concat([test_data,sex,embark,Pcl],axis=1)","9b728cfa":"test_data.head(5)\n","311940c9":"test_data.drop(['Sex','Embarked','Pclass','Name','Ticket','Fare'],axis=1, inplace=True)","37f62a6b":"test_data.head(5)","20786d65":"# Make sure after all the pre-processing you do on the test data the number of row enteries is 418 \n# otherwise it will throw an error in the final submission file   \ntest_data.shape","769e4113":"test_data.isnull().sum()","0d91347c":"# Now we are using the trained model over the test.csv file to predict the Survived passengers\ntest_predictions = logmodel.predict(test_data)\nprint(test_predictions)","79f86f57":"#I am creating a DataFrame with the passengers ids and our prediction regarding whether they survived or not\nsubmission = pd.DataFrame({'PassengerId':test_data['PassengerId'],'Survived':test_predictions})\n\n#Lets take a quick look at the final data submission - first 5 rows\nsubmission.head()","2c5e1883":"submission.shape","21991f25":"# Now I need to Convert DataFrame to a csv file as required by the Competition site to be uploaded\n\nfilename = 'Titanic Predictions 1.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","6fccd6e0":"Lets look at Passenger Class\n\nYou can infer from the below graph that the survived passengers are more from 1st class and 2nd class vs the 3rd class Passengers\n\n# Passenger Class is also a good predictor of the Survival rate","d39e7d9a":"Let's print the Final Dataframe after all the Pre-Processing and Feature Engineering done!!\nI will be predicting the Survival rate against these features Only","b6d9e2c4":"Now we have successfuly made the columns Sex, PClass and Embarked as categorical-numerical values\n\nNext all the new values need to be concatenated by running the below code","0f5445a1":"# Introduction to the Titanic Dataset\n\n*Here\u2019s a brief summary of the features: *\n\nPclass: Passenger class (1 = 1st; 2 = 2nd; 3 = 3rd)\n\nSurvival: A Boolean indicating whether the passenger survived or not (0 = No; 1 = Yes); this is our target\n\nName: A field rich in information as it contains title and family names\n\nSex: male\/female\n\nAge: Age\n\nSibSp: Number of siblings\/spouses aboard\n\nParch: Number of parents\/children aboard\n\nTicket: Ticket number\n\nFare: Passenger fare (British Pound)\n\nCabin: Location of Cabin\n\nEmbarked: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)","2ffe16a1":"**Now let us look at how many passengers survived and how many did not survive**\nThe column \"Survived\" is the target\n\n0 = Not survived\n\n1 = Survived","264bc7b6":"From the above dataframe the new columns have been added to the right end of the dataframe , so now we dont need the below columns from the original dataset -\n\nSex as it has \"male\" new column\n\nEmbarked as it has \"Q\" and \"S\" new columns\n\nPclass as it has \"2\",\"3\" new columns\n\nFare also I have dropped because we already know which Class the Passenger has travelled in so this looks like a redundant feature\n\nWe also dont need Name and Ticket as it does not add any value to our analysis","e06c5d5f":"# From the below Fare plot - \n\nMajority of the Fare was below 50 British Pounds\n\n50 Pounds is approx Rs.4776 now\n\nLooks like the wealthiest Max 1st Class fare was -\n\n500 Pounds = Rs.47763 appx\n\n..I am talking about these high fares in the year 1912!!","f41ad568":"# Pre-processing on Passenger Class\/PClass column\nSimilarly we can reduce the Pclass column as it has 1, 2 and 3rd class values so with this code if 2 and 3 column values are 0 , it automatically means the Passener was travelling in 1st class","f550c800":"# Pre-processing of column \"Sex\"\nThis column contains \"male\" \"female\" string values. Hence we need to convert this to a categorical data\n\nDo we need both female and male column values ? Not really one value is sufficient to be indicative of either male\/female","a7fdcd33":"# Age is a good feature predictor so I am filling in the null values with their mean value","f53ca16c":"# Analysis and Data Visualization\nI am using Countplot which is like a histogram or a bar graph for some categorical area.\n\nIt simply shows the number of occurrences of an item based on a certain type of category.","4b4d6ed9":"So now lets use the below code to remove first female values, to give an output of just male column where\n\n1 means male\n\n0 would automatically indicate female","467ca51d":"# Passenger Class is also a good predictor\nFrom the plot below You can infer Passengers in 1st class and 2nd class were older than 3rd Class Passengers","580d2a99":"# Achieved a Leaderboard Score of 76.5 % accuracy in my first competition. \n\nThe expert in anything was once a beginner.","1eba3336":"# From the below Plot SibSp = Siblings\/Spouses\nWe can infer since highest count is for 0, neither children nor spouses were onboard","0dad829a":"# We got an Accuracy Score of 79.6 %\n\nOur Model has been trained with 79.6 % accuracy, so Now lets see its performance against the test.csv file We will have to repeat all the same Pre-processing steps on the test.csv file similar to how it was done on the train.csv file ......Rewinding the Reel!!","205f4a8f":"# 38 % is Survival rate\n# 62 % did not Survive the fateful shipwreck\n# We want to analyse which \u201cfeatures\u201d are a good prediction of Survival rate.\n\nDoes the location of the cabin influence chances of survival?\n\nDoes Age influence chances of survival?*\n\nLet's find out as we explore further!!","ee5e8f0f":"Age has 177 missing values so lets analyse this further","9c495d34":"# Pre-processing of Embarked column\nThis column has string values so we need to do the same operation as above and convert to categorical data\n\nEmbarked refers to the Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n\nso we dont need 3 columns , we can drop the first column value of \"C\" because if Q and S is 0 that means automatically Cherbourg is 1, run the next code to complete the removal of Cherbourg","13fd2ea1":"# Titanic Survival Prediction Analysis\n# Inspiration\nTitanic is one of the Greatest movies by James Cameron which explored maximum utilization of Computer Graphics and Visual Effects. This Movie paved path for some of the greatest 3D softwares and SFX softwares. I have used the Titanic dataset for exploratory data analysis and to create a Machine Learning model that predicts the Survival rate.\n\n# Goal\nWe need to create a Machine Learning Model that predicts which Passengers survived the fateful Titanic shipwreck.\n\nA good Accuracy Score reveals the percentage of passengers you correctly predict.","0ef0cf83":"# Data distribution on Age\nshows Kids below 10 years and Adults between 20 - 40 were majority of the Passengers but keep in mind as we review the data further you will see we have a lot of null values for the Age column for the remaining passengers!!","991289da":"# Gender is a good feature to predict Survival rate\nYou can infer from the below plot that a large % of Males did not survive\n\nYou can infer that the % of Females survived is more\n\nI read in Wikipedia about the \"women and children first\" protocol for loading lifeboats which certainly can be tied to our observation too\n\n"}}