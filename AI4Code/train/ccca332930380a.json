{"cell_type":{"426c5f82":"code","086125b7":"code","84a0b888":"code","72acecd8":"code","99bf19d6":"code","9f5ae0e3":"code","29d0cf10":"code","45df60d3":"code","0a9bd75e":"code","be4b23ed":"code","dbcf6b12":"code","37cc0b16":"code","47745689":"code","0782c058":"code","c34178e2":"code","6e449f6c":"code","8978eeee":"code","1412a8c2":"code","3b58d86b":"code","72e5b03b":"code","3787fa3e":"code","8df75c67":"code","93aefba1":"code","15d950ae":"code","aed11fde":"code","c93ffcc2":"code","960d3b35":"code","babd9f4d":"code","c7441356":"code","6cad91e4":"code","90c9dca5":"code","ce0d0e3a":"code","62f9ed3e":"code","81137c9c":"code","ad63431a":"code","255ed86c":"code","408a898c":"code","c723c17c":"code","b5b7a800":"code","15175d22":"code","a9a410b3":"code","f30af343":"code","c85bfb2e":"code","686edbf4":"code","5feee600":"code","3e7eb562":"code","67c817cc":"code","a73e1760":"code","2e695ce8":"code","ca8641fc":"code","e56e2fbb":"code","2cac4767":"code","bc4e15b6":"code","ca94bbc1":"code","8865bfc2":"code","9a3ed2ce":"code","72599f8a":"code","f697a71a":"code","bc9d4f73":"code","45e5a21a":"code","59fc8ccc":"code","2c033fc7":"code","63a8cb0d":"code","02d4447c":"code","844b1a20":"code","b647047a":"code","034c11c6":"code","9d26124e":"code","2884ca01":"code","6a1dac3a":"code","28048f12":"code","ef451830":"code","7a2f5627":"code","b79c198e":"code","01db333b":"code","35fb7b85":"code","77839d2b":"code","8378665f":"markdown","15dafc75":"markdown","f50fe86f":"markdown","1ec7de2e":"markdown","8a2cf017":"markdown","7b0e0c3d":"markdown","40d2bc54":"markdown","4bb91166":"markdown","f5756495":"markdown","3f34ce4c":"markdown","b6fb0ec5":"markdown","55ef476c":"markdown","60218b17":"markdown","36e57ede":"markdown","65c55583":"markdown","91e88802":"markdown","f8206584":"markdown","74a8a35b":"markdown","9138f446":"markdown","b2bb806b":"markdown","69e391cf":"markdown","74a47332":"markdown","3cd17507":"markdown","6ca49365":"markdown","0530c3f7":"markdown","9d74e042":"markdown","43e93394":"markdown","a34dbb95":"markdown","993f94cb":"markdown","9a605af5":"markdown","118a20a0":"markdown","42ec9bab":"markdown"},"source":{"426c5f82":"\n\nimport numpy as np # linear algebra\nimport pandas as pd\nimport matplotlib.pyplot as plt# data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom matplotlib import cm\nfrom IPython.display import Image \n\n","086125b7":"data = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndata.head()","84a0b888":"data.tail()  #last Five rows","72acecd8":"data.info() #about the Dataset","99bf19d6":"print(\"Shape of the Data:{}\".format(data.shape)) #shape of the data","9f5ae0e3":"#check any missing value in the data set\ndata.isnull().sum()","29d0cf10":"for feature in data.columns:\n    print(\"{} in Unique Values:{}\".format(feature ,data[feature].nunique()))","45df60d3":"plt.figure(figsize = (10,10))\nsns.distplot(data.age,kde = True)","0a9bd75e":"fig ,ax = plt.subplots(1,2,figsize =(20,10))\nsns.countplot(x=\"sex\" ,data = data ,palette = \"Set3\" ,ax = ax[0])\nax[0].set_title(\"sex (Male =1 ,,Female =0)\")\nlabels = [\"Male\" ,\"Female\"]\ncolors = [\"lightskyblue\" ,\"gold\"]\nax[1].set_title(\"sex (Male =1 ,,Female =0)\")\ndata.sex.value_counts().plot.pie(explode = [0.1,0] ,autopct=\"%1.1f%%\" ,shadow = True,ax=ax[1] , labels = labels , colors = colors )\nax[1].legend(labels ,loc = \"upper right\")\nplt.show()\n","be4b23ed":"fig ,ax = plt.subplots(1,2,figsize =(20,10))\nsns.countplot(x=\"cp\" ,data = data ,palette = \"Accent\" ,ax = ax[0])\nax[0].set_title(\"Cheast Pain(cp)\")\nax[1].set_title(\"CheastPain(cp)\")\ncolors = [\"lightskyblue\" ,\"gold\",\"red\",\"blue\"]\ndata.cp.value_counts().plot.pie(explode = [0.1,0,0,0] ,autopct=\"%1.1f%%\" ,shadow = True,ax=ax[1],colors = colors)\nlabels = [\"0\",\"1\",\"2\",\"3\"]\nax[1].legend(labels ,loc = \"lower right\")\n\nplt.show()","dbcf6b12":"fig,ax =plt.subplots(1,2,figsize=(20,10))\nsns.countplot(x=\"cp\" ,hue = \"sex\" ,orient = 'h' ,data = data ,saturation = 0.9,palette = \"ocean\",ax=ax[0])\nax[0].set_title(\"Relationship Between Cp(chest Pain) and Sex(Male:1 , Female :0) \")\nsns.countplot(x = \"sex\" , data = data ,hue = \"target\" ,palette = \"Set2\" ,ax = ax[1])\nax[1].set_title(\"Heart Disease affected by sex(Male:1 ,Female:0)\")\nlabels = [\"0-Not affected \",\"1-affted\"]\nax[1].legend(labels ,loc = \"upper right\")\nplt.show()","37cc0b16":"fig ,ax = plt.subplots(1,2,figsize=(20,10))\nsns.kdeplot(data.trestbps ,ax =ax[1])\nax[0].set_title(\"trestbps(resting blood pressure\")\ndata.hist(column = \"trestbps\",bins = 10 ,ax = ax[0])\nax[1].set_title(\"trestbps(resting blood pressure)\")\nplt.show()","47745689":"fig ,ax = plt.subplots(1,2,figsize =(20,10))\nsns.countplot(x=\"target\" ,data = data ,palette = \"Set2\" ,ax = ax[0])\nax[0].set_title(\"Target (1= Affected by Heart diseases ,0=Not Affected by Heart diseases)\")\nlabels = [\"Affected by Heart diseases\" ,\"Not Affected by Heart diseases\"]\ncolors = [\"lightskyblue\" ,\"gold\"]\nax[1].set_title(\"Target (1= Affected by Heart diseases ,0=Not Affected by Heart diseases)\")\ndata.target.value_counts().plot.pie(explode = [0.1,0] ,autopct=\"%1.1f%%\" ,shadow = True,ax=ax[1] , labels = labels , colors = colors )\nax[1].legend(labels ,loc = \"upper right\")\nplt.show()","0782c058":"plt.figure(figsize=(10,5))\nsns.kdeplot(data.chol,shade = True)\nplt.title(\"Serum cholestoral in mg\/dl\")\nplt.show()","c34178e2":"fig ,ax = plt.subplots(1,2,figsize =(20,10))\nsns.countplot(x=\"fbs\" ,data = data ,palette = \"Pastel1\" ,ax = ax[0])\nax[0].set_title(\"Fasting blood sugar &gt; 120 mg\/dl) (1 = True; 0 = False)\")\nlabels = [\"1-True\" , \"0-False\"]\ncolors = [\"lightskyblue\" ,\"red\"]\nax[1].set_title(\"Fasting blood sugar &gt; 120 mg\/dl) (1 = True; 0 = False)\")\ndata.fbs.value_counts().plot.pie(explode = [0.1,0] ,autopct=\"%1.1f%%\" ,shadow = True,ax=ax[1] , labels = labels , colors = colors )\nax[1].legend(labels ,loc = \"upper right\")\nplt.show()","6e449f6c":"fig ,ax = plt.subplots(1,2,figsize =(20,10))\nsns.countplot(x=\"restecg\" ,data = data ,palette = \"Pastel2\" ,ax = ax[0])\nax[0].set_title(\"Resting electrocardiographic results\")\ncolors = [\"gold\" ,\"red\" ,\"lightskyblue\"]\nax[1].set_title(\"Resting electrocardiographic results\")\nlabels =[0,1,2]\ndata.restecg.value_counts().plot.pie(explode = [0,0,0] ,autopct=\"%1.1f%%\" ,shadow = True,ax=ax[1] , labels = labels , colors = colors )\nax[1].legend(labels ,loc = \"upper right\")\nplt.show()","8978eeee":"plt.figure(figsize=(10,5))\nsns.violinplot(x=\"target\", y =\"thalach\" ,hue =\"sex\" ,data = data,palette = \"Set3\")\nplt.title(\"Maximum heart rate affeted person heart Diseases (1-Affected ,0-Not Affected)\")\nlabels = [\"1-Male\" ,\"0-Female\"]\nplt.legend(labels ,loc = \"upper right\")\nplt.show()","1412a8c2":"plt.figure(figsize =(10,5))\nsns.boxplot(x=\"exang\" ,y = \"age\" , data = data ,palette = \"Reds\")\nplt.title(\"Relationship Between Exang and Age\")\nplt.show()\n","3b58d86b":"data.groupby(\"target\")[\"oldpeak\"].mean()","72e5b03b":"fig ,ax = plt.subplots(1,3,figsize = (10,5))\nsns.boxplot(x = \"oldpeak\", data = data,ax=ax[0])\nax[0].set_title(\"Oldpeak\")\nsns.kdeplot(data.oldpeak ,ax = ax[1] )\nax[1].set_title(\"oldpeak\")\nsns.scatterplot(x= \"age\" , y = \"oldpeak\" ,data = data ,ax=ax[2])\nax[2].set_title(\"Relationship between Age and old peak\")\nplt.show()","3787fa3e":"def target(data ,feature):\n    x = data.groupby(feature)[\"target\"].sum()\n    print(\"Feature {}:{}\".format(feature ,x))","8df75c67":"columns =[\"slope\" ,\"ca\" ,\"thal\"]\nfor var in columns:\n    target(data , var)","93aefba1":"fig ,ax = plt.subplots(1,2,figsize =(20,10))\nsns.countplot(x=\"slope\" ,data = data ,palette = \"Pastel1\",hue = \"target\" ,ax = ax[0] )\nax[0].set_title(\"The slope of the peak exercise ST segment (0: upsloping, 1: flat, 2: downsloping)\")\nlabels = [ \"0: upsloping\", \"1: flat\", \"2: downsloping\"]\ncolors = [\"lightskyblue\" ,\"red\" ,\"gold\"]\nax[1].set_title(\"The slope of the peak exercise ST segment (0: upsloping, 1: flat, 2: downsloping)\")\ndata.slope.value_counts().plot.pie(explode = [0.1,0,0] ,autopct=\"%1.1f%%\" ,shadow = True,ax=ax[1] , labels = labels , colors = colors )\nax[1].legend(labels ,loc = \"upper right\")\nplt.show()","15d950ae":"fig ,ax = plt.subplots(1,2,figsize =(20,10))\nsns.countplot(x=\"ca\" ,data = data ,palette = \"Pastel2\",hue = \"target\" ,ax = ax[0] )\nax[0].set_title(\"Number of Major Vessels Affectd by Heart Diseases\")\nax[0].set_xlabel(\"Ca Major Vessels\")\nlabels = [\"0\",\"1\",\"2\",\"3\" ,\"4\"]\ncolors = [\"lightskyblue\" ,\"red\" ,\"gold\" ,\"blue\" ,\"green\"]\nax[1].set_title(\"Number of Major Vessels \")\ndata.ca.value_counts().plot.pie(explode = [0.1,0,0,0,0] ,autopct=\"%1.1f%%\" ,shadow = True,ax=ax[1] , labels = labels , colors = colors )\nax[1].legend(labels ,loc = \"upper right\")\nplt.show()","aed11fde":"\nfig ,ax = plt.subplots(1,2,figsize =(20,10))\nsns.countplot(x = \"thal\" ,data = data ,palette = \"Set1\",hue = \"target\" ,ax = ax[0] )\nax[0].set_title(\"Thalassemia A Blood Disorder Affectd by Heart Diseases\")\nax[0].set_xlabel(\"thal - Thalassemia\")\nlabels = [\"0\" ,\"1\" ,\"2\" ,\"3\"]\ncolors = [\"red\" ,\"gold\" ,\"blue\",\"lightskyblue\"]\nax[1].set_title(\"Thalassemia A Blood Disorder \")\ndata.thal.value_counts().plot.pie(explode = [0,0,0 ,0.1] ,autopct=\"%1.1f%%\" ,shadow = True,ax=ax[1] , labels = labels , colors = colors )\nax[1].legend(labels ,loc = \"upper right\")\nplt.show()","c93ffcc2":"data.columns","960d3b35":"df = [\"trestbps\",\"chol\"]\nfig = plt.figure(figsize=(15,5))\nfor i ,var in zip(range(1,3),df):\n    ax = fig.add_subplot(1,3,i)\n    sns.boxplot(data[var] ,ax= ax ,palette = \"Set3\")\n    plt.xlabel(var)\n    plt.title(var)\nplt.show()\n\n    ","babd9f4d":"\nIQR = data[\"trestbps\"].quantile(0.75) - data[\"trestbps\"].quantile(0.25)\nupper_boundary = data[\"trestbps\"].quantile(0.75) + (1.5 * IQR)\nLower_boundary = data[\"trestbps\"].quantile(0.25) - (1.5 * IQR)\nprint(\"IQR: {} upperBoundary:{} and Lowerboundary:{}\".format(IQR , upper_boundary ,Lower_boundary))","c7441356":"#chol feature\nIQR = data[\"chol\"].quantile(0.75) - data[\"trestbps\"].quantile(0.25)\nupper_boundary = data[\"chol\"].quantile(0.75) + (1.5 * IQR)\nLower_boundary = data[\"chol\"].quantile(0.25) - (1.5 * IQR)\nprint(\"IQR: {} upperBoundary:{} and Lowerboundary:{}\".format(IQR , upper_boundary ,Lower_boundary))","6cad91e4":"data.loc[data[\"trestbps\"] > 170 ,\"trestbps\" ] = 170\ndata.loc[data[\"chol\"]>400 , \"chol\"] = 400","90c9dca5":"plt.figure(figsize=(10,10))\ncorr = data.corr()\nsns.heatmap(corr ,annot = True ,cmap = \"Pastel1\")\nplt.title(\"Correlation Between All Feature\")\nplt.show()","ce0d0e3a":"df = data.copy()\ndata['sex'] = data['sex'].astype('object')\ndata['cp'] = data['cp'].astype('object')\ndata['fbs'] = data['fbs'].astype('object')\ndata['restecg'] = data['restecg'].astype('object')\ndata['exang'] = data['exang'].astype('object')\ndata['slope'] = data['slope'].astype('object')\ndata['thal'] = data['thal'].astype('object')","62f9ed3e":"data.dtypes","81137c9c":"data.head()","ad63431a":"data = pd.get_dummies(data ,drop_first = True)","255ed86c":"data.shape","408a898c":"x = data.drop(columns =\"target\" ,axis = 1)\ny = data[\"target\"]","c723c17c":"print(x.columns)","b5b7a800":"y.head()","15175d22":"from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix,accuracy_score,precision_score ,recall_score ,roc_auc_score","a9a410b3":"x_train,x_test,y_train,y_test = train_test_split(x,y ,test_size =0.2 , random_state = 0)\nprint(\"Shape of Training  and  Testing\")\nprint(x_train.shape ,x_test.shape)","f30af343":"from sklearn.preprocessing import MinMaxScaler\nx_train_std = MinMaxScaler().fit_transform(x_train)\nx_test_std = MinMaxScaler().fit_transform(x_test)","c85bfb2e":"model = {\"LG\":LogisticRegression() ,\"RF\":RandomForestClassifier() ,\"DT\": DecisionTreeClassifier() ,\"svc\":SVC()}\n\ndef create_modle(model ,x_train ,y_train ,x_test,y_test): \n    model_score_train = {}\n    model_score_test = {}\n    cnn = {}\n    for name,model in model.items():\n        np.random.seed(42)\n        model.fit(x_train ,y_train) #fit model\n        pred = model.predict(x_test)\n        model_score_train[name] = model.score(x_train ,y_train)\n        model_score_test[name] = model.score(x_test ,y_test)\n        cnn[name] = confusion_matrix(y_test ,pred)\n        \n    return model_score_train,model_score_test,cnn\n    ","686edbf4":"training_score = create_modle(model , x_train ,y_train ,x_test ,y_test)\ntrain ,test,cnn = training_score","5feee600":"cnn","3e7eb562":"train","67c817cc":"test","a73e1760":"data1 = pd.DataFrame({\"Train_score\":train ,\"Testing_score\":test })\ndata1.head()","2e695ce8":"plt.figure(figsize=(10,20))\ndata1.T.plot.bar(width = 0.9)\nplt.title(\"Model Comparison of Training  and Testing Score\")\nplt.show()","ca8641fc":"fig  = plt.figure(figsize=(10,5))\na =1\nfor key,name in cnn.items():\n    ax = fig.add_subplot(2,2,a)\n    plt.title(key)\n    sns.heatmap(name ,annot =True , ax =ax ,cmap = \"Set3\")\n    a = a+1\nplt.show()","e56e2fbb":"training_score_std = create_modle(model , x_train_std ,y_train ,x_test_std ,y_test)\ntrain_std ,test_std,cnn_std = training_score_std","2cac4767":"print(\"Training Score of After Normalization :{}\".format(train_std))\nprint(\"Testing Score of After Normalization :{}\".format(test_std))","bc4e15b6":"fig  = plt.figure(figsize=(10,5))\na =1\nfor key,name in cnn_std.items():\n    ax = fig.add_subplot(2,2,a)\n    plt.title(key)\n    sns.heatmap(name ,annot =True , ax =ax ,cmap = \"Set3\")\n    a = a+1\nplt.show()","ca94bbc1":"param = {\"penalty\": [\"l1\",\"l2\" ,\"elasticnet\" ,\"none\"],    #Regularization paramater\n         \"C\" : [0.1,0.001,0.1,1.0,1.5 ,3.0],             #strength of regularization\n         \"solver\":[\"newton-cg\", \"lbfgs\", \"liblinear\"],\n         \"multi_class\":['auto', 'ovr', \"multinomial\"],\n         \"max_iter\" :[10,20,30,50,100]\n        }","8865bfc2":"LG_H = LogisticRegression()\nGrid_lg = GridSearchCV(LG_H , param_grid = param ,cv = 5 , scoring = 'accuracy' ,n_jobs = -1).fit(x_train_std,y_train)","9a3ed2ce":"Grid_lg.best_params_","72599f8a":"Grid_best_est = Grid_lg.best_estimator_\nLG_Gr_pred = Grid_best_est.predict(x_test_std)\nLg_accuracy = accuracy_score(y_test , LG_Gr_pred)\nLg_precision = precision_score(y_test , LG_Gr_pred)\nLg_recall = recall_score(y_test ,LG_Gr_pred)\nLg_conf = confusion_matrix(y_test , LG_Gr_pred)\nprint(\"Accuracy_score of Logistic Regression:{}\".format(round(Lg_accuracy * 100)))\nprint(\"RecallScore(Positive Prediction,Low False Negative Rate):{}\".format(round(Lg_recall*100)))\nprint(\"PrecisionScore(Low false Postitive rate):{}\".format(round(Lg_precision *100)))\nsns.heatmap(Lg_conf ,annot = True , cmap = \"Pastel1\")\nplt.title(\"Confusion_matrix on LogisticRegression\")\nplt.show()","f697a71a":"kernel = ['linear', 'poly', 'rbf', 'sigmoid']  # what type of algorithm is used\nC = [0.001,0.005,0.01,0.05, 0.1, 0.5, 1, 5, 10, 50,100,500,1000] \ngamma = [0.001, 0.01, 0.1, 0.5, 1]     #this parem used for Rbf\ndegree =[1,2,3,4]                     #used for polmonial algorithm\nparam = {'kernel':kernel , #\n         \"gamma\":gamma,\n         \"degree\": degree,\n            \"C\" :C}\n\n","bc9d4f73":"svc = SVC()\nsvc_grid = GridSearchCV(svc , param_grid = param ,scoring = \"accuracy\" ,n_jobs = -1 ,verbose = 2 ,cv = 10).fit(x_train_std,y_train)","45e5a21a":"svc_grid.best_params_","59fc8ccc":"svc_est = svc_grid.best_estimator_\nsvc_Gr_pred = Grid_best_est.predict(x_test_std)\nsvc_accuracy = accuracy_score(y_test , svc_Gr_pred)\nsvc_precision = precision_score(y_test , svc_Gr_pred)\nsvc_recall = recall_score(y_test ,svc_Gr_pred)\nsvc_conf = confusion_matrix(y_test , svc_Gr_pred)\nprint(\"Accuracy_score of Support Vector Classifier:{}\".format(round(svc_accuracy * 100)))\nprint(\"RecallScore(Positive Prediction,Low False Negative Rate):{}\".format(round(svc_recall*100)))\nprint(\"PrecisionScore(Low false Postitive rate):{}\".format(round(svc_precision *100)))\nsns.heatmap(Lg_conf ,annot = True , cmap = \"Blues\")\nplt.title(\"Confusion_matrix on Support Vector Classifier\")\nplt.show()\n","2c033fc7":"neighbour = [i for i in range(1,30)]\nprint(neighbour ,end = \" \")\ntrain_score,test_score =[] ,[]\nfor n in range(1,20):\n    knn = KNeighborsClassifier(n_neighbors = n).fit(x_train ,y_train)\n    train_score.append(knn.score(x_train ,y_train))\n    test_score.append(knn.score(x_test ,y_test))","63a8cb0d":"test_score","02d4447c":"plt.figure(figsize = (10,10))\nplt.plot(train_score)\nplt.plot(test_score)\nplt.title(\"Training and Testing Accuracy\")\nplt.xlabel(\"Kneighbors\")\nplt.ylabel(\"accuracy\")\nplt.xticks(range(1,21))\nplt.legend(labels=[\"Train_score\" ,\"Test_score\"] ,loc = \"upper right\")\nplt.show()","844b1a20":"from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\nparem ={\"criterion\" : ['gini', 'entropy'] ,\n       \"splitter\":['best', 'random'] ,\n        \"max_depth\" : [int(x) for x in np.linspace(1, 1000,500)],\n        'min_samples_split': [2, 5, 10,14],\n        'min_samples_leaf' :[1, 2, 4,6,8]\n       }\nDT = DecisionTreeClassifier()\nRandomized = RandomizedSearchCV(estimator=DT,param_distributions=parem,n_iter=100,cv=5,verbose=2,\n                               random_state=100,n_jobs=-1)\nRandomized.fit(x_train ,y_train)","b647047a":"Randomized.best_params_","034c11c6":"Best_estimater = Randomized.best_estimator_","9d26124e":"pred = Best_estimater.predict(x_test)\ny_pred = Best_estimater.predict_proba(x_test)[:, 1]\nConfusion_Dt = confusion_matrix(y_test ,pred)\nprint(\"Accuracy_score for Decision Tree:{}\".format(accuracy_score(y_test ,pred)))\nsns.heatmap(Confusion_Dt , annot = True ,cmap = \"Set3\")\nplt.title(\"Confusion_matrix for Decision Tree\")\nplt.show()","2884ca01":"from sklearn.metrics import roc_curve\nFalse_positive_rate, True_pos_rate, thresholds = roc_curve(y_test, y_pred)\n\nfig, ax = plt.subplots()\nplt.plot(False_positive_rate ,True_pos_rate)\nplt.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.0])\nplt.rcParams['font.size'] = 12\nplt.title('ROC  classifier')\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid(True)","6a1dac3a":"DT = DecisionTreeClassifier()\nparem ={\"criterion\" : ['gini', 'entropy'] ,\n       \"splitter\":['best', 'random'] ,\n        \"max_depth\" : [int(x) for x in np.linspace(1, 100,50)],\n        'min_samples_split': [2, 5, 10,14],\n        'min_samples_leaf' :[1, 2, 4,6,8]\n       }","28048f12":"GS_T = GridSearchCV(estimator = DT , param_grid = parem , scoring = \"accuracy\" ,n_jobs = -1 ,cv = 5  ).fit(x_train ,y_train)","ef451830":"GS_T.best_params_","7a2f5627":"GSVT = GS_T.best_estimator_\ndpred = GSVT.predict(x_test)\nd_con = confusion_matrix(y_test ,dpred)\nd_precision = precision_score(y_test ,dpred)\nd_Recall = recall_score(y_test ,dpred)\nd_accuracy = accuracy_score(y_test , dpred) \nprint(\"Accuracy_score of Decision Tree Classifier:{}\".format(round(d_accuracy * 100)))\nprint(\"RecallScore(Positive Prediction,Low False Negative Rate):{}\".format(round(d_Recall*100)))\nprint(\"PrecisionScore(Low false Postitive rate):{}\".format(round(d_precision *100)))\nsns.heatmap(d_con ,annot = True , cmap = \"Blues\")\nplt.title(\"Confusion_matrix on Decision_tree\")\nplt.show()\n","b79c198e":"n_estimators = [int(x) for x in np.linspace(start = 2, stop = 2000, num = 1000)]\nmax_features = ['auto', 'sqrt','log2']\nmax_depth = [int(x) for x in np.linspace(1, 1000,500)]\nmin_samples_split = [2, 5, 10,14,15]\nmin_samples_leaf = [1, 2, 4,6,8,10,12]\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n              'criterion':['entropy','gini']}\nRF=RandomForestClassifier()\nRf_tuning=RandomizedSearchCV(estimator=RF,param_distributions=random_grid,n_iter=100,cv=5,verbose=2,\n                               random_state=100,n_jobs=-1)\nRf_tuning.fit(x_train,y_train)","01db333b":"Rf_tuning.best_params_","35fb7b85":"rf = Rf_tuning.best_estimator_","77839d2b":"RF_pred = rf.predict(x_test)\nConfusion_Dt = confusion_matrix(y_test ,RF_pred)\npre = precision_score(y_test ,RF_pred)\nRecall = recall_score(y_test ,RF_pred)\nprint(\"Accuracy_score for Random Forest Classifier:{}\".format(accuracy_score(y_test ,RF_pred)))\nprint(\"RecallScore(Positive Prediction,Low False Negative Rate):{}\".format(round(Recall*100)))\nprint(\"PrecisionScore(Low false Postitive rate):{}\".format(round(pre *100)))\nsns.heatmap(Confusion_Dt , annot = True ,cmap = \"Set3\")\nplt.title(\"Confusion_matrix for RandomForestClassifier\")\nplt.show()","8378665f":"In the Data set There is no missing value is present","15dafc75":"# Random Forest Classifier Hyper Tuning","f50fe86f":"# Spliting Model","1ec7de2e":"When I spliting my data  80% Training and 20% Testing","8a2cf017":"# Missing Value \nHandling Missing Value is very Important in Machine Learning ,Because Algorithms Does Not Support  Missing Value to process it","7b0e0c3d":"# Support Vector Classifier HyperTuning","40d2bc54":"# One Hot Encoding ","4bb91166":"# Normalization","f5756495":" The above feature are coverted into catagorical ","3f34ce4c":"# Model HyperTuning","b6fb0ec5":"# Convert Some feature into categorical","55ef476c":"First Check whether The  data is Balanced Dataset or Imbalance Dataset","60218b17":"# Import Dataset ","36e57ede":"# X-y split","65c55583":"# Normalizing  features","91e88802":"# Algorithms used\n1. LogisticRegression\n1. RandomForestClassifier\n1. DecisionTreeClassifier\n1. SupportVectorClassifier\n1. KNeighborsClassifier","f8206584":"We she some oulier is present The threstbps featue 99% of value present below 170 and same as feature chol 99% data present below 380 the other values are outlier so we take a IQR ","74a8a35b":"# Importing Library\n\nBefore To starts with,I imported necessary libraries ","9138f446":"# EDA (Exploratory Data Analysis)","b2bb806b":"# Outlier\nAn Outliers, being the most extreme observations,Oulier can affect the model perfomance,A good practice remove outlier gives a good result.","69e391cf":"# Decision Tree Classifier HyperTuning using RandomizedCV","74a47332":"# Kneighbors Classifier","3cd17507":"A good practice to remove correlated variables during feature selection.In the data there is no one Feature in highly Correlated so we cannot remove any one feature","6ca49365":"# Correlation","0530c3f7":"# IQR (Inter Quantile Range)","9d74e042":"# Logistic Regression with HyperTuning using GridSearchCV","43e93394":"# Decision Tree Classifier with HyperTuning using GridSearchCV","a34dbb95":"Before I train the Model first Normalizing the features \nNormalization Simply said the data feature range from 0 to 1\n\n# Xnorm = X - Xmin \/ Xmax - Xmin","993f94cb":"After Encoding Check Shape of Data ","9a605af5":"#  Heart Disease Prediction \n\nThis Dataset has Whether the Person affected by Heart Diseses or not ","118a20a0":"# When Easy To UnderStand ALL Feature\n\n1. age: The person's age in years\n1. sex: The person's sex (1 = male, 0 = female)\n1. cp: The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n1. trestbps: The person's resting blood pressure (mm Hg on admission to the hospital)\n1. chol: The person's cholesterol measurement in mg\/dl\n1. fbs: The person's fasting blood sugar (> 120 mg\/dl, 1 = true; 0 = false)\n1. restecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n1. thalach: The person's maximum heart rate achieved\n1. exang: Exercise induced angina (1 = yes; 0 = no)\n1. oldpeak: ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)\n1. slope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n1. ca: The number of major vessels (0-3)\n1. thal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n1. target: Heart disease (0 = no, 1 = yes)","42ec9bab":"For the categorical varibles, we need to create dummy variables. I'm also going to drop the first category of each. For example, rather than having 'male' and 'female', we'll have 'male' with values of 0 or 1 (1 being male, and 0 therefore being female)."}}