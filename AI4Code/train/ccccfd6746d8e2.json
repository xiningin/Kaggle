{"cell_type":{"f30722bf":"code","d2305b22":"code","15de6f4a":"code","8a1600cc":"code","375cbd9c":"code","09ab113c":"code","524e9a78":"code","f60b96ce":"code","64fd57b0":"code","ccf1a242":"code","d1cebd6b":"code","2b56f9fa":"code","ca247f8b":"code","f6ed5351":"code","cf9b8ef9":"code","c7637c58":"code","99d9ea90":"code","1513db5e":"code","e20da289":"code","351820cb":"code","8a2ccb28":"code","a616c336":"code","024729c5":"code","20cc7845":"code","bb258dc2":"code","23333da4":"code","aa53099c":"code","4ce5e3b8":"code","b6d1338e":"code","a5ec2310":"code","c54ce44a":"code","0a3d710c":"code","245757da":"code","5a3dad75":"code","df3527bf":"code","36fb086a":"code","500d4de1":"code","7aa146a4":"code","eedf3fb5":"code","a1ecf05a":"code","857d10a0":"code","88858b4b":"code","fa2d23a2":"code","2ec07be2":"code","615c9d0a":"code","40ba05d5":"code","caefdb53":"code","2f3ac50d":"code","601a346d":"code","15c6ce3a":"code","cb0c1ebb":"code","5947364b":"code","2a5137a8":"code","4fac52b4":"code","27878ca5":"markdown","3be5756e":"markdown","137f57c6":"markdown","ce8c0c15":"markdown","4bb1dee4":"markdown","23c586c1":"markdown","f84593fe":"markdown","b8618d52":"markdown","1ac5bec8":"markdown","5950453e":"markdown","ee9a78d3":"markdown","c278c245":"markdown","2ff30eed":"markdown","67fe8568":"markdown","3adc21e8":"markdown","00fef4a8":"markdown","e84f0be8":"markdown","464e18e6":"markdown","c264b8d6":"markdown","bcddffb4":"markdown","abb65b46":"markdown","5ca413f4":"markdown","7444bc59":"markdown","3faf5823":"markdown","870b56c8":"markdown","6934902f":"markdown","1634a088":"markdown","936a728e":"markdown"},"source":{"f30722bf":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline","d2305b22":"order_review_data = pd.read_csv(\"..\/input\/olist_order_reviews_dataset.csv\")","15de6f4a":"order_review_data.head()","8a1600cc":"order_review_data.info()","375cbd9c":"order_review_data = order_review_data.dropna(subset=['review_comment_message'])","09ab113c":"order_review_data['word_count'] = order_review_data.review_comment_message.apply(lambda x: len(str(x).split()))","524e9a78":"order_review_data.word_count.max()","f60b96ce":"g = sns.FacetGrid(data=order_review_data, col='review_score',height=5, aspect=0.8)\nbefore_remove = g.map(plt.hist, 'word_count', bins=30)\nbefore_remove","64fd57b0":"sns.boxplot(x='review_score', y='word_count', data=order_review_data)","ccf1a242":"from wordcloud import WordCloud\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import sent_tokenize\n\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nfrom nltk.stem import RSLPStemmer #Stemmer for portugese words.\n\nfrom nltk.probability import FreqDist\nfrom collections import defaultdict\nfrom heapq import nlargest\n\nstop = stopwords.words('portuguese')\nstop.append('nao') #Stopword already have \"N\u00e3o\", just adding this because it's appear on dataframe","d1cebd6b":"text_review_1 = ' '.join(order_review_data[order_review_data[\"review_score\"]==1][\"review_comment_message\"])\ntext_review_2 = ' '.join(order_review_data[order_review_data[\"review_score\"]==2][\"review_comment_message\"])\ntext_review_3 = ' '.join(order_review_data[order_review_data[\"review_score\"]==3][\"review_comment_message\"])\ntext_review_4 = ' '.join(order_review_data[order_review_data[\"review_score\"]==4][\"review_comment_message\"])\ntext_review_5 = ' '.join(order_review_data[order_review_data[\"review_score\"]==5][\"review_comment_message\"])","2b56f9fa":"def resumo (texto,n):\n    sentencas = sent_tokenize(texto)\n    palavras = word_tokenize(texto.lower())\n    \n    stop = set(stopwords.words('portuguese') + list(punctuation))\n    palavras_sem_stopwords = [palavra for palavra in palavras if palavra not in stop]\n    \n    frequencia = FreqDist(palavras_sem_stopwords)\n    sentencas_importantes = defaultdict(int)\n    \n    for i, sentenca in enumerate(sentencas):\n        for palavra in word_tokenize(sentenca.lower()):\n            if palavra in frequencia:\n                sentencas_importantes[i] += frequencia[palavra]\n                \n    idx_sentencas_importantes = nlargest(n, sentencas_importantes, sentencas_importantes.get)\n    for i in sorted(idx_sentencas_importantes):\n        print(sentencas[i])        ","ca247f8b":"def visualize(label):\n    words = ''\n    for msg in order_review_data[order_review_data['review_score'] == label]['review_comment_message']:\n        msg = msg.lower()\n        words += msg + ' '\n    wordcloud = WordCloud(width=600, height=400).generate(words)\n    plt.figure(figsize=(12,8))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()","f6ed5351":"visualize(1)","cf9b8ef9":"resumo(text_review_1,4)","c7637c58":"visualize(2)","99d9ea90":"resumo(text_review_2,4)","1513db5e":"visualize(3)","e20da289":"resumo(text_review_3,4)","351820cb":"visualize(4)","8a2ccb28":"resumo(text_review_4,4)","a616c336":"visualize(5)","024729c5":"resumo(text_review_5,4)","20cc7845":"stemmer = RSLPStemmer()","bb258dc2":"import re\nimport unicodedata\n\ndef strip_accents(text):\n    \"\"\"\n    Strip accents from input String.\n\n    :param text: The input string.\n    :type text: String.\n\n    :returns: The processed String.\n    :rtype: String.\n    \"\"\"\n    try:\n        text = unicode(text, 'utf-8')\n    except (TypeError, NameError): # unicode is a default on python 3 \n        pass\n    text = unicodedata.normalize('NFD', text)\n    text = text.encode('ascii', 'ignore')\n    text = text.decode(\"utf-8\")\n    return str(text)","23333da4":"#removing numbers\norder_review_data.review_comment_message = order_review_data.review_comment_message.str.replace('\\d+', ' ')\n\n#lower cases.\norder_review_data.review_comment_message = order_review_data.review_comment_message.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n\n#Removing punctuation\norder_review_data.review_comment_message = order_review_data.review_comment_message.str.replace('[^\\w\\s]',' ')\n\n#Removing stopword\norder_review_data.review_comment_message = order_review_data.review_comment_message.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n\n#removing accentuation\norder_review_data.review_comment_message = order_review_data.review_comment_message.apply(strip_accents)\n\n#Tokenmize\norder_review_data.review_comment_message = order_review_data.apply(lambda row: word_tokenize(row['review_comment_message']), axis=1)\n\n#Stemming\norder_review_data.review_comment_message = order_review_data.review_comment_message.apply(lambda x: \" \".join([stemmer.stem(word) for word in x]))","aa53099c":"order_review_data['word_count_new'] = order_review_data.review_comment_message.apply(lambda x: len(str(x).split()))","4ce5e3b8":"order_review_data.head()","b6d1338e":"order_review_data.word_count_new.max()","a5ec2310":"g = sns.FacetGrid(data=order_review_data, col='review_score',height=5, aspect=0.8)\ng.map(plt.hist, 'word_count_new', bins=30)","c54ce44a":"sns.boxplot(x='review_score', y='word_count_new', data=order_review_data)","0a3d710c":"order_training = order_review_data\norder_training['review_score'][order_training.review_score == 2] = 1\norder_training['review_score'][order_training.review_score == 3] = 1\norder_training['review_score'][order_training.review_score == 4] = 5","245757da":"order_training = order_training[(order_training.review_score == 1) | (order_training.review_score == 5)]\norder_training = order_training.loc[:,['review_comment_message','review_score']]","5a3dad75":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer()\nX_count = cv.fit_transform(order_training[\"review_comment_message\"]).toarray()\ny_count = order_training.review_score","df3527bf":"# Applying PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components = 2)\nX_count_pca = pca.fit_transform(X_count)","36fb086a":"pca.explained_variance_ratio_","500d4de1":"plt.figure(figsize=(12,8))\nsns.scatterplot(x = X_count_pca[:,0], y = X_count_pca[:,1] , hue=y_count,palette = 'RdYlBu', legend=\"full\")","7aa146a4":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_count, y_count, test_size = 1\/4, random_state = 42)","eedf3fb5":"logreg_vector = LogisticRegression()\nlogreg_vector.fit(X_train, y_train)","a1ecf05a":"y_pred = logreg_vector.predict(X_test)","857d10a0":"score = logreg_vector.score(X_test, y_test)\nprint(score)","88858b4b":"from sklearn import metrics\ncm = metrics.confusion_matrix(y_test, y_pred)\nprint(cm)","fa2d23a2":"def plot_coefficients(classifier, feature_names, top_features=20):\n    coef = classifier.coef_.ravel()\n    top_positive_coefficients = np.argsort(coef)[-top_features:]\n    top_negative_coefficients = np.argsort(coef)[:top_features]\n    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n    # create plot\n    plt.figure(figsize=(20, 8))\n    colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors, align=\"center\")\n    feature_names = np.array(feature_names)\n    plt.xticks(np.arange(0, 2 * top_features), feature_names[top_coefficients], rotation=90)\n    plt.xlabel(\"20 more significant words for bad reviews (red) and good reviews (right)\")\n    plt.ylabel(\"Coeficient values\")\n    ","2ec07be2":"plot_coefficients(logreg_vector, cv.get_feature_names())","615c9d0a":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer()\nX_tfidf = vectorizer.fit_transform(order_training.review_comment_message)\nX_tfidf = X_tfidf.todense()","40ba05d5":"# Applying PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components = 2)\nX_tfidf_pca = pca.fit_transform(X_tfidf)","caefdb53":"pca.explained_variance_ratio_","2f3ac50d":"plt.figure(figsize=(12,8))\nsns.scatterplot(x = X_tfidf_pca[:,0], y = X_tfidf_pca[:,1] , hue=y_count, palette = 'RdYlBu', legend=\"full\")","601a346d":"X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y_count, test_size = 1\/4, random_state = 42)","15c6ce3a":"logreg_tfidf = LogisticRegression()\nlogreg_tfidf.fit(X_train_tfidf, y_train_tfidf)","cb0c1ebb":"y_pred_tfidf = logreg_tfidf.predict(X_test_tfidf)","5947364b":"score = logreg_tfidf.score(X_test_tfidf, y_test_tfidf)\nprint(score)","2a5137a8":"cm = metrics.confusion_matrix(y_test_tfidf, y_pred_tfidf)\nprint(cm)","4fac52b4":"plot_coefficients(logreg_tfidf, vectorizer.get_feature_names())","27878ca5":"The precision on the test set was not so high using TF-IDF than not using it. 88,5% without TF-IDF vs 89% with.","3be5756e":"This can be seeing here too, low review have high median word count than high review.","137f57c6":"Summary for 1 score review.","ce8c0c15":"Word cloud for 1 score review","4bb1dee4":"This plot show us that low review have more words than high review. Peoples tend to talk more when deslike some product than when like the product.","23c586c1":"Now let's make some data pre processing in 'review_score', like remove punctuation, make all words in lower case, stemming (make all word in their 'radical', so words like love and loved is treated as same words.","f84593fe":"To create our summary, lets join all review comments in a single text, separated by review score.","b8618d52":"Review with 4 and 5 star it's good review.","1ac5bec8":"Looks like the words of each review are more separated using TF-IDF.","5950453e":"As you can see, the max number of word in each sentence decreased after cleaning the data.","ee9a78d3":"As can be seeing in this plot above, words in the review score 1 and 5 has a small separation. So Logistic regression can be useful.","c278c245":"Creating the bag of words.","2ff30eed":"3 score review seems like it's a bad review too. 1 2 and 3 score it's talking more about delivery delay or some mistakes made.","67fe8568":"Even without stopwords low rate review have more words tham high rated.","3adc21e8":"Making a new word counting","00fef4a8":"Word cloud for 2 score review","e84f0be8":"Code below will remove all accents, so words like *p\u00e9ssimo* and *pessimo* will be the same.","464e18e6":"Summary for 2 score review.","c264b8d6":"Creating a word cloud and a summary for all coment for each review, to see what words are more used in each review.  \nWordcloud create a plot with the most frequency or the importance of each word.","bcddffb4":"Based on wordcloud and the summary, it's seens that review with 1 and 2 score are similar.","abb65b46":"88,5% of prediction on the test set, its a good prediction.","5ca413f4":"In this kernel I will make some NLP, for this is just needed the dataset who have review of the customer","7444bc59":"Applying pca to reduce the numbers of features for beter visualization of the words distribution among 1 and 5 review.","3faf5823":"Now lets use TF-IDF to see if we get a better score.","870b56c8":"The graphic above show the the first 10 higher (blue size) coeficients of logistic regression, with the associated word, and the 10 lowest (red size) with the associated word. Works like *P\u00e9ssimo* amd *decep\u00e7\u00e3o* are the words with highest negative impact, and words like *excelente* and *amei* with highest impact.","6934902f":"In the review column have only 41753 not Nan values, more than half of the column have Nan values, can't do nothing about this, so better is remove all lines that have Nan values.","1634a088":"Preparing our data for training. We will only see good and bad reviews, so reviews with 1 and 5 score. Scores 2 and 3 score will be group with 1, and 4 will be group with 5","936a728e":"Let's see how much word is used in each review."}}