{"cell_type":{"d6967cec":"code","57266b8b":"code","a3238680":"code","73e9323c":"code","17348a3c":"code","028d6876":"code","ec50663e":"code","27f110b0":"code","8ffcfec7":"code","9be6d630":"code","dba1cc72":"code","47ffb388":"code","86713c68":"code","ea0f3b3b":"code","7250278c":"code","1aa90652":"code","2b977249":"code","91838e07":"code","a98a78ff":"code","6f90ade9":"code","60c6dc52":"code","3885b347":"code","7475d560":"code","a7b4fe1a":"code","5de34f4c":"code","34a9d3f7":"code","5878e0ed":"code","a5775428":"code","77cc3316":"code","3ac800bb":"code","be964001":"code","60654206":"code","4aa7acd7":"code","8580cddd":"code","65c7b0bf":"code","eeb0cd4d":"code","db63f34b":"code","fb12e9b3":"code","9a2a5327":"code","124e9a42":"code","e29aad1d":"code","2cef0d94":"code","0a9e5468":"code","1f45f6fd":"code","109deb70":"code","2c20f39d":"code","edfc4d7d":"code","1551b0e1":"code","9e38b1bf":"markdown","2a2e41f7":"markdown","da284e06":"markdown","825f85aa":"markdown","72c71ef0":"markdown","a9247429":"markdown","1ae8279b":"markdown","5c87c311":"markdown","0862e616":"markdown","49a3eb16":"markdown","9d8b67bf":"markdown","ecd5da87":"markdown","62410f7d":"markdown","b3728195":"markdown","f18a840f":"markdown","cab3e634":"markdown","206848ac":"markdown","f10bd3d3":"markdown","50abf148":"markdown","0d80447e":"markdown","7da93381":"markdown","52e92bf7":"markdown","a70c5284":"markdown","709a23a0":"markdown","5e5dc2be":"markdown"},"source":{"d6967cec":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n######## REQUIRED INSTALL ########   \n\n# !pip install lightgbm\n# !pip install catboost\n# !pip install xgboost\n# conda install -c conda-forge lightgbm\nimport sklearn\nimport seaborn as sns\nimport matplotlib.mlab as mlab \n    \n############ LIBRARIES ############\n\n# BASE\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\n# WARNINGS\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# DATA PREPROCESSING\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import LocalOutlierFactor \n\n# MODELING\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.exceptions import ConvergenceWarning\n\nimport xgboost\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# MODEL TUNING\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score","57266b8b":"train = pd.read_csv(\"..\/input\/house-price-dataset\/train.csv\")\ntest = pd.read_csv(\"..\/input\/house-price-dataset\/test.csv\")\n\n# train and test sets combined\ndf = train.append(test).reset_index(drop=True)","a3238680":"from shutil import copyfile\n\ncopyfile(src= \"..\/input\/helpers\/data_prep.py\", dst=\"..\/working\/data_prep.py\")\ncopyfile(src= \"..\/input\/helpers\/eda.py\", dst=\"..\/working\/eda.py\")\n\nfrom data_prep import*\nfrom eda import*","73e9323c":"df.head()","17348a3c":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","028d6876":"cat_but_car","ec50663e":"# The cardinal variable is not discarded because it has too many variables and how it carries the information is unknown.\ndf['Neighborhood'].value_counts()","27f110b0":"for col in cat_cols:\n    cat_summary(df, col)","8ffcfec7":"for col in cat_but_car:\n    cat_summary(df, col)","9be6d630":"df[num_cols].describe([0.05, 0.1, 0.25, 0.5, 0.75, 0.95, 0.99]).T","dba1cc72":"df[\"SalePrice\"].describe([0.05, 0.1, 0.25, 0.5, 0.75, 0.8, 0.9, 0.95, 0.99]).T","47ffb388":"def find_correlation(dataframe, numeric_cols, corr_limit=0.60):\n    high_correlations = []\n    low_correlations = []\n    for col in numeric_cols:\n        if col == \"SalePrice\":\n            pass\n        else:\n            correlation = dataframe[[col, \"SalePrice\"]].corr().loc[col, \"SalePrice\"]\n            print(col, correlation)\n            if abs(correlation) > corr_limit:\n                high_correlations.append(col + \": \" + str(correlation))\n            else:\n                low_correlations.append(col + \": \" + str(correlation))\n    return low_correlations, high_correlations\n\nlow_corrs, high_corrs = find_correlation(df, num_cols)","86713c68":"df.corr()[\"SalePrice\"].sort_values(ascending=False).head(20)","ea0f3b3b":"\n# correlation between all variables\n\ndef target_correlation_matrix(dataframe, corr_th=0.5, target=\"SalePrice\"):\n    \"\"\"\n    Returns the variables that have a correlation above the threshold value given with the dependent variable..\n    :param dataframe:\n    :param corr_th: threshold value\n    :param target:  dependent variable name\n    :return:\n    \"\"\"\n    corr = dataframe.corr()\n    corr_th = corr_th\n    try:\n        filter = np.abs(corr[target]) > corr_th\n        corr_features = corr.columns[filter].tolist()\n        sns.clustermap(dataframe[corr_features].corr(), annot=True, fmt=\".2f\")\n        plt.show()\n        return corr_features\n    except:\n        print(\"High threshold value, lower your corr_th value!\")\n\n\ntarget_correlation_matrix(df, corr_th=0.5, target=\"SalePrice\")","7250278c":"# MSZoning\n# Identifies the general zoning classification of the sale.\n# RH + RM = RM\ndf[\"MSZoning\"].value_counts()\ndf.loc[(df[\"MSZoning\"] == \"RH\"), \"MSZoning\"] = \"RM\"\n\n\n# df[\"LotArea\"].mean() # 10168.11408016444\nNew_LotArea =  pd.Series([\"studio_apartment\",\"Small\", \"Middle\", \"Large\",\"Dublex\",\"Luxury Apartment\"], dtype = \"category\")\ndf[\"New_LotArea\"] = New_LotArea\ndf.loc[(df[\"LotArea\"] > 35) & (df[\"LotArea\"] <= 75), \"New_LotArea\"] = New_LotArea[0]\ndf.loc[(df[\"LotArea\"] > 75) & (df[\"LotArea\"] <= 200), \"New_LotArea\"] = New_LotArea[1]\ndf.loc[(df[\"LotArea\"] > 200) & (df[\"LotArea\"] <= 1000), \"New_LotArea\"] = New_LotArea[2]\ndf.loc[(df[\"LotArea\"] > 1000) & (df[\"LotArea\"] <= 3000), \"New_LotArea\"] = New_LotArea[3]\ndf.loc[(df[\"LotArea\"] > 3000) & (df[\"LotArea\"] <= 6000), \"New_LotArea\"] = New_LotArea[4]\ndf.loc[df[\"LotArea\"] > 6000 ,\"New_LotArea\"] = New_LotArea[5]\n\n# LotShape\n# distance from the street connecting to the property\n# aggregates into a single variable\ndf[\"LotShape\"].value_counts()\ndf.loc[(df[\"LotShape\"] == \"IR2\"), \"LotShape\"] = \"IR1\"\ndf.loc[(df[\"LotShape\"] == \"IR3\"), \"LotShape\"] = \"IR1\"\n\n# LandSlope: Slope of property\ndf.loc[(df[\"LandSlope\"] == \"Gtl\"), \"LandSlope\"] = \"Mod\"\n\n# Condition1: Proximity to various conditions \ndf.loc[(df[\"Condition1\"] == \"Feedr\"),\"Condition1\"] = \"Artery\"\ndf.loc[(df[\"Condition1\"] == \"RRNn\"),\"Condition1\"] = \"RRAn\"\ndf.loc[(df[\"Condition1\"] == \"RRNe\"),\"Condition1\"] = \"RRAn\"\ndf.loc[(df[\"Condition1\"] == \"PosN\"),\"Condition1\"] = \"PosA\"\n\n# Condition2: Proximity to various conditions \ndf.loc[(df[\"Condition2\"] == \"RRNn\"),\"Condition1\"] = \"RRAn\"\ndf.loc[(df[\"Condition2\"] == \"PosN\"),\"Condition1\"] = \"PosA\"\ndf.loc[(df[\"Condition2\"] == \"RRNe\"),\"Condition1\"] = \"RRAe\"\n\n# HouseStyle: Style of dwelling \ndf.loc[(df[\"HouseStyle\"] == \"2.5Fin\"), \"HouseStyle\"] = \"2Story\"\ndf.loc[(df[\"HouseStyle\"] == \"1.5Fin\"), \"HouseStyle\"] = \"1.5Unf\"\ndf.loc[(df[\"HouseStyle\"] == \"2.5Fin\"), \"HouseStyle\"] = \"2.5Unf\"\n\n# Total number of bathrooms                                  \ndf[\"new_total_bath\"] = (df[\"BsmtFullBath\"] + df[\"BsmtHalfBath\"] + df[\"FullBath\"] + df[\"HalfBath\"])\n\n# Assessment of the general condition \ndf[\"new_qual_cond\"] = df[\"OverallQual\"] + df[\"OverallCond\"]  \n                                   \n# Building age                                  \ndf[\"new_built_remodadd\"] = df[\"YearBuilt\"] + df[\"YearRemodAdd\"]\n\n# Reviewed according to feature importance values\ndf[\"new_GrLivArea_LotArea\"] = df[\"GrLivArea\"] \/ df[\"LotArea\"]  \ndf[\"total_living_area\"] = df[\"TotalBsmtSF\"] + df[\"GrLivArea\"]","1aa90652":"rare_analyser(df, \"SalePrice\", cat_cols)","2b977249":"def rare_encoder(dataframe, rare_perc, cat_cols):\n    rare_columns = [col for col in cat_cols if (dataframe[col].value_counts() \/ len(dataframe) < 0.01).sum() > 1]\n\n    for col in rare_columns:\n        tmp = dataframe[col].value_counts() \/ len(dataframe)\n        rare_labels = tmp[tmp < rare_perc].index\n        dataframe[col] = np.where(dataframe[col].isin(rare_labels), \"Rare\", dataframe[col])\n    return dataframe\n\ndf = rare_encoder(df, 0.01, cat_cols)","91838e07":"rare_analyser(df, \"SalePrice\", cat_cols)","a98a78ff":"useless_cols = [col for col in cat_cols if df[col].nunique() == 1 or\n                (df[col].nunique() == 2 and (df[col].value_counts() \/ len(df) <= 0.01).any(axis=None))]","6f90ade9":"cat_cols = [col for col in cat_cols if col not in useless_cols]","60c6dc52":"for col in useless_cols:\n    df.drop(col, axis=1, inplace=True)","3885b347":"cat_cols = cat_cols + cat_but_car\ndf = one_hot_encoder(df, cat_cols, drop_first=True)\n\ncheck_df(df)\n\ncat_cols, num_cols, cat_but_car = grab_col_names(df)\n\nrare_analyser(df, \"SalePrice\", cat_cols)\n\nuseless_cols_new = [col for col in cat_cols if (df[col].value_counts() \/ len(df) <= 0.01).any(axis=None)]\n\ndf[useless_cols_new].head()\n\nfor col in useless_cols_new:\n    cat_summary(df, col)\n","7475d560":"missing_values_table(df)\n\ntest.shape\n\nmissing_values_table(train)\n\nna_cols = [col for col in df.columns if df[col].isnull().sum() > 0 and \"SalePrice\" not in col]\n\ndf[na_cols] = df[na_cols].apply(lambda x: x.fillna(x.median()), axis=0)","a7b4fe1a":"for col in num_cols:\n    print(col, check_outlier(df, col))","5de34f4c":"train_df = df[df['SalePrice'].notnull()]\ntest_df = df[df['SalePrice'].isnull()].drop(\"SalePrice\", axis=1)","34a9d3f7":"y = np.log1p(train_df[\"SalePrice\"])\nX = train_df.drop([\"Id\",\"SalePrice\"], axis=1)","5878e0ed":"model = [(\"LightGBM\", LGBMRegressor())]","a5775428":"for name, regressor in model:\n    rmse = np.mean(np.sqrt(-cross_val_score(regressor, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\n    print(f\"RMSE: {round(rmse, 4)} ({name}) \")","77cc3316":"# model object is entered\nlgbm_model = LGBMRegressor(random_state=46)","3ac800bb":"# error before modeling (see 5-fold error with lgbn_model)\nrmse = np.mean(np.sqrt(-cross_val_score(lgbm_model,\n                                        X, y, cv=5, scoring=\"neg_mean_squared_error\")))\nrmse","be964001":"# parameter set (parameter grid) is entered\n\nlgbm_params = {\"learning_rate\": [0.01, 0.1, 0.05],\n               \"n_estimators\": [1500, 3000, 6000],\n               \"colsample_bytree\": [0.5, 0.7],\n               \"num_leaves\": [31, 35],\n               \"max_depth\": [3, 5]}","60654206":"# traverse the parameter set and find the best combination\n# decide which combinations of hyperparameters should be used\nlgbm_gs_best = GridSearchCV(lgbm_model,\n                            lgbm_params,\n                            cv=3,\n                            n_jobs=-1,\n                            verbose=True).fit(X, y)","4aa7acd7":"final_model = lgbm_model.set_params(**lgbm_gs_best.best_params_).fit(X, y)\nfinal_model","8580cddd":"rmse = np.mean(np.sqrt(-cross_val_score(final_model, X, y, cv=5, scoring=\"neg_mean_squared_error\")))\nrmse","65c7b0bf":"def plot_importance(model, features, num=len(X), save=False):\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                     ascending=False)[0:num])\n    plt.title('Features')\n    plt.tight_layout()\n    plt.show()\n    if save:\n        plt.savefig('importances.png')\n        \n# num=len(X) -> to be reviewed\nplot_importance(final_model, X, 30)","eeb0cd4d":"feature_imp = pd.DataFrame({'Value': final_model.feature_importances_, 'Feature': X.columns})","db63f34b":"num_summary(feature_imp, \"Value\", True)","fb12e9b3":"feature_imp[feature_imp[\"Value\"] >0].shape","9a2a5327":"feature_imp[feature_imp[\"Value\"] <1].shape","124e9a42":"# unnecessary variables\nzero_imp_cols = feature_imp[feature_imp[\"Value\"] < 1][\"Feature\"].values","e29aad1d":"selected_cols = [col for col in X.columns if col not in zero_imp_cols]","2cef0d94":"len(selected_cols)","0a9e5468":"lgbm_model = LGBMRegressor(random_state = 46)","1f45f6fd":"lgbm_params = {\"learning_rate\": [0.01],\n               \"n_estimators\": [3000],\n               \"colsample_bytree\": [0.3, 0.8],\n               \"max_depth\": [4],\n               \"num_leaves\": [13],\n               \"min_child_samples\": [3]\n               }","109deb70":"lgbm_gs_best = GridSearchCV(lgbm_model,\n                            lgbm_params,\n                            cv=3,\n                            n_jobs=-1,\n                            verbose=True).fit(X[selected_cols], y)","2c20f39d":"final_model = lgbm_model.set_params(**lgbm_gs_best.best_params_).fit(X[selected_cols], y)\nfinal_model","edfc4d7d":"rmse = np.mean(np.sqrt(-cross_val_score(final_model, X[selected_cols], y, cv=5, scoring=\"neg_mean_squared_error\")))\nrmse","1551b0e1":"\nsubmission_df = pd.DataFrame()\nsubmission_df['Id'] = test_df[\"Id\"].astype(\"Int32\")\n\ny_pred_sub = final_model.predict(test_df[selected_cols])\n\ny_pred_sub = np.expm1(y_pred_sub)\n\nsubmission_df['SalePrice'] = y_pred_sub\n\nsubmission_df.to_csv('submission53.csv', index=False)","9e38b1bf":"<a id = \"3\"><\/a><br>\n# 3. Variable Description","2a2e41f7":" <a id = \"12\"><\/a><br>\n## 7.3 Missing Values","da284e06":" <a id = \"18\"><\/a><br>\n# 11. Hyperparameter Optimization with Selected Features","825f85aa":" <a id = \"17\"><\/a><br>\n# 10. Feature Selection","72c71ef0":"\n#### **find_correlation:**\n- will calculate negative or positive correlations greater than 60%\n- correlations of independent variables","a9247429":"<a id = \"5\"><\/a><br>\n## 3.2 Numerical Variable Analysis","1ae8279b":"# Introduction\n\n\n<font color = 'red'>\nContent: \n    \n1. [Import Libraries & Modules](#1)\n1. [Load Data](#2)\n1. [Variable Description](#3)\n    * [Categorical Variable Analysis](#4)\n    * [Numerical Variable Analysis](#5)\n1. [Target Analysis](#6)\n1. [Correlation Analysis](#7)\n1. [Feature Engineering](#8)\n1. [Data Preprocessing](#9)\n    * [Rare Encoding](#10)\n    * [Label Encoding & One-Hot Encoding](#11)\n    * [Missing Values](#12)\n    * [Outliers](#13)\n1. [Modeling](#14)\n    * [Base Models](#15)\n1. [Hyperparameter Optimization](#16)\n1. [Feature Selection](#17)\n1. [Hyperparameter Optimization with Selected Features](#18)\n1. [Submission](#19)","5c87c311":"#### *grab_col_name*: \nReturns the quantities of categorical, numeric, and categorical but cardinal variables in the data set.","0862e616":" <a id = \"13\"><\/a><br>\n## 7.4 Outliers","49a3eb16":"<a id = \"15\"><\/a><br>\n## 8.1 Base Models","9d8b67bf":" <a id = \"8\"><\/a><br>\n ## 6.Feature Engineering","ecd5da87":"<a id = \"6\"><\/a><br>\n# 4. Target Analysis","62410f7d":"<a id = \"4\"><\/a><br>\n## 3.1 Categorical Variable Analysis","b3728195":"<a id = \"2\"><\/a><br>\n# 2. Load Data","f18a840f":" <a id = \"11\"><\/a><br>\n## 7.2 Label Encoding & One-Hot Encoding\n\nThe main purpose is to meet the demands of the algorithms and to eliminate the measurement problems that may occur or to produce a higher quality data.","cab3e634":" <a id = \"10\"><\/a><br>\n## 7.1 Rare Encoding","206848ac":"\n\n<center> <h1 style=\"background-color:red; color:white\" >HOUSE PRICE PREDICTION<\/h1>","f10bd3d3":" <a id = \"9\"><\/a><br>\n# 7. Data Preprocessing & Feature Engineering","50abf148":" <a id = \"14\"><\/a><br>\n# 8. Modeling","0d80447e":"<a id = \"7\"><\/a><br>\n# 5. Correlation Analysis","7da93381":"\n\n- It is an effort to consolidate the few classes.\n\n\n\n\n#### *rare_encoder* :\n- Examines the rare case of the entire cat_cols list, not just categorical\n- Fix if there is more than 1 rare\n- After the Rare class query is made according to 0.01, the sum of the trues is taken.\n- If it is greater than 1, it is included in the rare col list.","52e92bf7":" <a id = \"16\"><\/a><br>\n## 9. Hyperparameter Optimization","a70c5284":"<center><h1><strong><\/strong><\/h1>\n<img\nsrc=\"https:\/\/kemptonexpress.co.za\/wp-content\/uploads\/sites\/30\/2018\/06\/The-Tembisan-Gauteng-property-market-showing-signs-of-early-recovery.jpeg\" width =\"700\">\n<\/center>","709a23a0":"<a id = \"1\"><\/a><br>\n# 1. Import Libraries & Modules","5e5dc2be":" <a id = \"20\"><\/a><br>\n# 12. Submission"}}