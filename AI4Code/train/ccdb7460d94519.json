{"cell_type":{"c13b2977":"code","acbc0596":"code","346605f0":"code","37a8852e":"code","9c084a2d":"code","ae5bad56":"code","5edcbed9":"code","e76d45fc":"code","9cc160c4":"code","e77c7f98":"code","2e6f85b7":"code","e55f38d3":"code","8e0f39d7":"code","ba095a39":"code","b3fb07c4":"code","8c52047f":"code","dfc724b6":"code","6b685684":"code","637b2aa6":"code","27f5a70d":"code","1179f51f":"code","d1803a36":"code","4ba3df12":"code","ff1e7939":"code","18c8181c":"code","26af3b7c":"code","b550cd64":"code","6b289ea0":"code","054d821c":"code","fef5534e":"code","3be5d9b1":"code","bd9ea738":"code","d1dcd659":"code","b4518454":"code","c122fa6c":"code","6b56de3c":"code","11637bdb":"code","faeadd0d":"code","bc7a9521":"code","17f31551":"code","0b38962a":"code","f88033bc":"code","a1630d9e":"code","2bd5bdd9":"code","cf69a9d2":"code","106aedcd":"code","78bcfbe1":"code","557916f1":"code","fce89154":"code","ebd5f98f":"code","f3546f11":"code","c6e74708":"code","5b381795":"code","76faa296":"code","652e3d11":"code","6145f4af":"code","9b0a152f":"code","678d3ec6":"code","e8754bf6":"code","bfb40213":"code","748e5803":"code","c1fa355a":"code","fe999bf3":"code","d4dae7e2":"code","bb97c3f9":"code","18655af4":"code","74c05d22":"code","e88b1147":"code","d5af853a":"code","339e1eab":"code","150d7e35":"code","b6af699f":"code","a93e99de":"code","837241ba":"code","e979840d":"code","6f8d3be2":"code","dd8b5e71":"code","da54a363":"code","16d2ab10":"code","5bbacecb":"code","d8f1e922":"code","ec0aec29":"code","87017812":"code","b4669160":"code","05aa6629":"code","284183d5":"code","9c08c075":"code","df3c4d40":"code","6e8b2b44":"code","b3c72e2d":"code","350d0554":"code","bf4b1ee1":"code","9e4520d0":"code","baefd57a":"code","a74fd3d4":"code","2760890f":"code","6db3eff0":"code","df1b3e26":"code","b09e7be8":"code","a057200b":"code","155414dc":"code","a00ff84c":"code","e7bc695c":"code","136aa0c7":"code","a8863366":"code","9e05f084":"code","fce82342":"code","e128c6d8":"code","7176c8af":"code","e7f2083f":"code","8aa1244f":"code","f4d94c4f":"code","b9ea8dfa":"code","96e120b3":"code","300a8154":"code","b91842d1":"code","fb17ee01":"code","5d9715ac":"code","e420711c":"code","7e305ce5":"code","ae7eeb2e":"code","8e797ad1":"code","735ca0c2":"code","11b5162c":"code","16358332":"code","145cae32":"code","46aab57e":"code","a072972a":"code","0b3b925f":"code","e29423e3":"code","7b4d034b":"code","79a28d47":"code","97c50599":"code","3b11c28d":"code","c4afd2db":"code","a980990f":"code","c85e3d2a":"code","ef46ce52":"code","b637fb56":"markdown","6d25e823":"markdown","23c8bd22":"markdown","e2045201":"markdown","91d53d94":"markdown","ce2a7c50":"markdown","af2a176a":"markdown","94995595":"markdown","ca5f653d":"markdown","6551af03":"markdown","685c217b":"markdown","9c4d1b88":"markdown","d42b3c26":"markdown","82dacd64":"markdown","880050d9":"markdown","2a30cdd9":"markdown","ff9cc642":"markdown","3151bf86":"markdown","7e6bcfb2":"markdown","b63ac533":"markdown","7abc095e":"markdown","4e85e03b":"markdown","1e1d7119":"markdown","30be13eb":"markdown","54e6bd52":"markdown","34a4c0fc":"markdown","9a47b788":"markdown","73ad12f7":"markdown","e87e61b0":"markdown","50bce61a":"markdown","d20789d7":"markdown","01ae2faf":"markdown","dccd07bc":"markdown","df5a2a4d":"markdown","6579e068":"markdown","9db232cf":"markdown","42695dba":"markdown","2166f093":"markdown","c26230e7":"markdown","44171350":"markdown","620eab71":"markdown","15c84a7e":"markdown","d0a54bc8":"markdown","18b3c6ff":"markdown","c3903369":"markdown","579f2667":"markdown","9e1a26ab":"markdown","bdea1df9":"markdown","35a05fb4":"markdown","7fc1fdb2":"markdown","baf51a99":"markdown","e3e6b7a7":"markdown","9712b78b":"markdown","f6eba63a":"markdown","452c821c":"markdown","95ebcb22":"markdown","37b93227":"markdown","070136cf":"markdown","106545c8":"markdown","fe49d42b":"markdown","ade9f2ec":"markdown","750f360a":"markdown","569e9811":"markdown","294b6430":"markdown","baa984dc":"markdown","3330a22c":"markdown","40623685":"markdown","4207c796":"markdown","84a6e3de":"markdown","2ce95988":"markdown","7cbe6f8e":"markdown","c3cc9743":"markdown","9b795f33":"markdown","8abfded5":"markdown","414bafc6":"markdown","f5ca188e":"markdown","dba6e2f1":"markdown","592b237b":"markdown","9bda94ee":"markdown","f7cbaf04":"markdown","433fa056":"markdown","82ee5313":"markdown"},"source":{"c13b2977":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n#Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n# Plotly for interactive graphics \nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.express as px\n\nfrom collections import Counter\n\n\n\n#Accuracy Score,MSE,ROC_Curve,Confusion Matrix\nfrom sklearn.metrics import accuracy_score,mean_squared_error,roc_curve,roc_auc_score,classification_report,r2_score,confusion_matrix\n#train test split, Grid Search CV\nfrom sklearn.model_selection import train_test_split,cross_val_score,ShuffleSplit,GridSearchCV\n\n#Disabling the warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","acbc0596":"churn = pd.read_csv(\"\/kaggle\/input\/churn-modelling\/Churn_Modelling.csv\")","346605f0":"churn.head()","37a8852e":"df = churn.copy()\ndf.info() # As we can see there is not any Nan values, this sounds perfect but there can be other problems with columns. ","9c084a2d":"df.drop([\"RowNumber\",'CustomerId'],axis = 1).describe().T","ae5bad56":"# df.Gender = [1 if each == 'Male' else 0 for each in df.Gender]","5edcbed9":"plt.style.use(\"ggplot\")\nf,ax=plt.subplots(figsize = (10,8))\nsns.heatmap(df.drop([\"RowNumber\",'CustomerId'],axis = 1).corr(),robust=True,fmt='.1g',linewidths=1.3,linecolor = 'gold', annot=True,);","e76d45fc":"plt.figure(figsize = (12,6)) \nsns.countplot(x=\"HasCrCard\",hue = \"Geography\", data=df, palette=\"husl\");\nprint(df.groupby('Geography')[\"HasCrCard\"].sum())","9cc160c4":"plt.figure(figsize = (12,6)) \nsns.countplot(x=\"HasCrCard\",hue = \"Exited\", data=df, palette=\"husl\");\nprint(df.groupby('Geography')[\"Exited\"].sum())","e77c7f98":"avarage_salaries = df.groupby(\"Geography\").mean()[\"EstimatedSalary\"]\nprint(\"Avarage Salaries according to Countries:\\n\", avarage_salaries)","2e6f85b7":"plt.figure(figsize = (14,8));\nsns.catplot(x='Geography',\n            y = \"EstimatedSalary\",\n            hue=\"Exited\",\n            col=\"Gender\",\n            aspect=1.2,height=5,\n            kind=\"swarm\", data=df);","e55f38d3":"fig = px.box(df, x=\"Geography\", y = \"EstimatedSalary\",color = 'Exited'); # Another visualization about salary effect\nfig.update_layout(title_text=\"The country with the mean salary-With Outliers(Exited-Not Exited groups)\")\nfig.show();","8e0f39d7":"plt.figure(figsize = (14,8)) \nplt.xticks(rotation=90)\nplt.title('Credit Card Usage for Ages',color = 'blue',fontsize=15)\nsns.countplot(x=df[\"Age\"],hue = 'HasCrCard',data=df);\nplt.xlabel('Ages')\nplt.ylabel('Number of Credit Card Users');","ba095a39":"fig = px.box(df, x=\"HasCrCard\", y = \"Age\",color = 'Exited');\nfig.update_layout(title_text=\"Credit Card Usage & Age - With Outliers(Exited-Not Exited groups)\")\nfig.show();","b3fb07c4":"fig = px.parallel_categories(df, dimensions=['Gender', 'Geography', 'Exited'],\n                color=\"Exited\", color_continuous_scale=px.colors.sequential.Inferno,\n                labels={'Gender':'Gender(Female,Male)', 'Exited':'Exited(0:No,1:Yes)'})\nfig.update_layout(title_text=\"Gender-Geography-Exited-Not Exited Schema\")\nfig.show();","8c52047f":"fig = px.parallel_categories(df, dimensions=['Gender','HasCrCard',\"IsActiveMember\", 'Exited'],\n                color=\"Exited\", color_continuous_scale=px.colors.sequential.Inferno,\n                labels={'HasCrCard':'Has Credit Card', 'Gender':'Gender(Female,Male)', 'Exited':'Exited(0:No,1:Yes)'})\nfig.update_layout(title_text=\"Credit Card-Gender-Exited-Not Exited Schema\")\nfig.show(); ","dfc724b6":"print(df.groupby(\"Geography\")[\"CreditScore\"].mean()) ### Cikarilabilir\nfig = px.box(df, x=\"Geography\", y = \"CreditScore\",color = 'Exited');\nfig.update_layout(title_text=\"The country with the highest credit score(mean)-With Outliers(Exited-Not Exited groups)\")\nfig.show();","6b685684":"plt.figure(figsize = (14,8));\nsns.catplot(x='Geography',\n            y = \"CreditScore\",\n            hue=\"Exited\",\n            col=\"IsActiveMember\",\n            aspect=1.2,height=5,\n            kind=\"swarm\", data=df);","637b2aa6":"plt.figure(figsize = (14,8));\nsns.catplot(x='Geography',\n            y = \"CreditScore\",\n            hue=\"Exited\",\n            col=\"Gender\",\n            aspect=1.2,height=5,\n            kind=\"swarm\", data=df);","27f5a70d":"plt.figure(figsize = (16,6)) \nplt.xticks(rotation=45)\nsns.scatterplot(x=df['Age'],y = df[\"CreditScore\"],hue = \"Gender\",data=df);","1179f51f":"plt.figure(figsize = (16,6)) \nplt.xticks(rotation=45)\nsns.scatterplot(x=df['Age'],y = df[\"CreditScore\"],hue = \"Exited\",data=df);","d1803a36":"df[df[\"CreditScore\"]<405]['Exited'].value_counts()","4ba3df12":"plt.figure(figsize = (16,6)) \nplt.xticks(rotation=45)\nsns.countplot(x=df[\"Age\"],hue = 'Exited',data=df, palette=\"husl\");\nplt.xlabel('Age')\nplt.ylabel('Number of customers (Exited or not)');","ff1e7939":"below_30 = df[df[\"Age\"]<30]\nbetween_30_40 = df[(df[\"Age\"]>=30) & (df[\"Age\"]<40)]\nbetween_40_50 = df[(df[\"Age\"]>=40) & (df[\"Age\"]<50)]\nbetween_50_60 = df[(df[\"Age\"]>=50) & (df[\"Age\"]<60)]\nbetween_60_70 = df[(df[\"Age\"]>=60) & (df[\"Age\"]<70)]\nabove_70 = df[(df[\"Age\"]>=70)]\n\n\n\nk = below_30[\"Exited\"].sum()\nl = between_30_40[\"Exited\"].sum()\nm = between_40_50[\"Exited\"].sum()\nn = between_50_60[\"Exited\"].sum()\no = between_60_70[\"Exited\"].sum()\np = above_70[\"Exited\"].sum()","18c8181c":"f,ax = plt.subplots(figsize=(15, 15))\nplt.subplot(6,1,1)\nsns.countplot(x=below_30[\"Age\"],hue = 'Exited',data=df, palette=\"husl\");\nplt.xlabel('Age')\nplt.ylabel('Customers (Exited)');\nplt.xticks(rotation= 30)\n\nplt.subplot(6,1,2)\nsns.countplot(x=between_30_40[\"Age\"],hue = 'Exited',data=df, palette=\"husl\");\nplt.xlabel('Age')\nplt.ylabel('Customers (Exited)');\nplt.xticks(rotation= 30)\n\n\nplt.subplot(6,1,3)\nsns.countplot(x=between_40_50[\"Age\"],hue = 'Exited',data=df, palette=\"husl\");\nplt.xlabel('Age')\nplt.ylabel('Customers (Exited)');\nplt.xticks(rotation= 30);\n\nplt.subplot(6,1,4)\nsns.countplot(x=between_50_60[\"Age\"],hue = 'Exited',data=df, palette=\"husl\");\nplt.xlabel('Age')\nplt.ylabel('Customers (Exited)');\nplt.xticks(rotation= 30);\n\nplt.subplot(6,1,5)\nsns.countplot(x=between_60_70[\"Age\"],hue = 'Exited',data=df, palette=\"husl\");\nplt.xlabel('Age')\nplt.ylabel('Customers (Exited)');\nplt.xticks(rotation= 30);\n\nplt.subplot(6,1,6)\nsns.countplot(x=above_70[\"Age\"],hue = 'Exited',data=df, palette=\"husl\");\nplt.xlabel('Age')\nplt.ylabel('Customers (Exited)');\nplt.xticks(rotation= 30);\n","26af3b7c":"age_list = [('Total Stayed=',below_30['Exited'].value_counts()[:1],\"Ages below 30==>\",k,\"Exited\"),\n            ('Total stayed=',between_30_40['Exited'].value_counts()[:1],'Ages between 30-40==>',l,\"Exited\"),\n            ('Total stayed=',between_40_50['Exited'].value_counts()[:1],\"Ages between 40-50==>\",m,\"Exited\"),\n            ('Total stayed=',between_50_60['Exited'].value_counts()[:1],\"Ages between 50-60==>\",n,\"Exited\"),\n            ('Total stayed=',between_60_70['Exited'].value_counts()[:1],\"Ages between 60-70==>\",o,\"Exited\"),\n            ('Total stayed=',above_70['Exited'].value_counts()[:1],\"Ages above 70==>\",p,\"Exited\")]","b550cd64":"##### Plotly Pie Graph for Visualizing Percentage of Age Groups with Working A Bank \n\npie_list=[k,l,m,n,o,p]\nlabels=age_list\nfig={\n    \"data\":[\n        {\n            \"values\":pie_list,\n            \"labels\":labels,\n            \"domain\": {\"x\": [.2, 1]},\n            \"name\": \"Age Groups-Exit Rate\",\n            \"hoverinfo\":\"label+percent+name\",\n            \"hole\": .4,\n            \"type\": \"pie\"\n        },],\n    \"layout\":{\n        \"title\":\"Percentage of Age Groups for Longer Work With Bank\",\n        \"annotations\":[\n            {\n                \"font\":{\"size\":20},\n                \"showarrow\": False,\n                \"text\": \"Age Group-Exited\",\n                \"x\": 0.60,\n                \"y\": 0.50\n            },\n        ]\n    }  \n}\niplot(fig)","6b289ea0":"plt.figure(figsize = (16,6)) \nplt.xticks(rotation=45)\nsns.barplot(x=df['Geography'],y = df[\"Exited\"],hue = \"Gender\",data=df, palette=\"husl\");\nplt.ylabel('Percetage of people (Exited %)');","054d821c":"plt.figure(figsize = (16,6)) \nplt.xticks(rotation=45)\nsns.countplot(x=df[\"Geography\"],hue = 'Exited',data=df, palette=\"husl\");\nplt.xlabel('Geo')\nplt.ylabel('Number of customers (Exited or not)');","fef5534e":"print(\"Total Number of People By Geography\\n\",df[\"Geography\"].value_counts())\nprint(\"Number of People Exited By Geography\\n\",df[df['Exited']==1][\"Geography\"].value_counts(),'\\n')\n\nprint(\"Number of People Exited By Gender in Germany \\n\",df[(df['Exited']==1)&(df['Geography']=='Germany')][\"Gender\"].value_counts())\nprint(\"Number of People Exited By Gender in France \\n\",df[(df['Exited']==1)&(df['Geography']=='France')][\"Gender\"].value_counts())\nprint(\"Number of People Exited By Gender in Spain \\n\",df[(df['Exited']==1)&(df['Geography']=='Spain')][\"Gender\"].value_counts())","3be5d9b1":"plt.figure(figsize = (16,6)) \nplt.xticks(rotation=45)\nsns.scatterplot(x='Age',y = \"EstimatedSalary\",hue = \"Exited\",data=df);","bd9ea738":"plt.figure(figsize = (16,6)) \nplt.xticks(rotation=45)\nsns.scatterplot(x='Age',y = \"Balance\",hue = \"Exited\",data=df);","d1dcd659":"df = churn.copy()","b4518454":"age_group_data = [None] * len(df['Age'])\nfor i in range(len(df['Age'])):\n    if df['Age'][i] < 30:\n        age_group_data[i] = 'Young'\n    elif df['Age'][i] >=30 and df['Age'][i] < 40:\n        age_group_data[i] = 'Young-Adults'\n    elif df['Age'][i] >=40 and df['Age'][i] < 50:\n        age_group_data[i] = 'Adults'\n    elif df['Age'][i] >=50 and df['Age'][i] < 60:\n        age_group_data[i] = 'Elderly-Adults'\n    elif df['Age'][i] >=60 and df['Age'][i] < 74:\n        age_group_data[i] = 'Old'\n    else:\n        age_group_data[i] = 'Very-Old'\n\ndf['age_group'] = age_group_data","c122fa6c":"Credit = [None] * len(df['CreditScore'])\nfor i in range(len(df['CreditScore'])):\n    if df['CreditScore'][i] < 405:\n        Credit[i] = 0\n    else:\n        Credit[i] = 1\n        \ndf['new_credit'] = Credit\n","6b56de3c":"df['new_credit'].value_counts()","11637bdb":"sns.factorplot(x = \"new_credit\", y = \"Exited\", data = df,kind = \"bar\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Exited(Precent)\");","faeadd0d":"age74 = df[(df[\"Age\"]>=74)]\nage74[\"Exited\"].value_counts()\n# We dropped the 2 lines that is outlier of the above 73 ages.\ndf.drop([3110,3531],axis =0,inplace = True)","bc7a9521":"g = sns.factorplot(x = \"age_group\", y = \"Exited\", data = df, kind = \"bar\")\nplt.xticks(rotation=45)\ng.set_ylabels(\"Exited\")\nplt.show()","17f31551":"gender_dummies = df.replace(to_replace={'Gender': {'Female': 0,'Male':1}})\na = pd.get_dummies(df['Geography'], prefix = \"Geo_dummy\")\nc = pd.get_dummies(df['age_group'], prefix = \"Age_dummy\")","0b38962a":"frames = [gender_dummies,a,c]  \ndf = pd.concat(frames, axis = 1)\ndf = df.drop([\"RowNumber\",\"Geography\",\"Surname\",\"CustomerId\",'Age','age_group','Geography',\"CreditScore\"],axis = 1)\ndf.head()","f88033bc":"x = df.drop([\"Exited\"],axis = 1) #Independent value\ny = df[\"Exited\"] #Depended value ","a1630d9e":"# data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n\n# fit scaler on training data\nnorm = MinMaxScaler().fit(x)\n\n# transform independent data\nx_norm = norm.transform(x)\n\n####Generally code yourself ===>>>        x = (x-np.min(x))\/(np.max(x)-np.min(x)).values","2bd5bdd9":"x_train,x_test,y_train,y_test = train_test_split(x_norm,y,test_size = 0.3, random_state = 42)","cf69a9d2":"from sklearn.linear_model import LogisticRegression","106aedcd":"log_reg = LogisticRegression().fit(x_train,y_train)\ny_pred = log_reg.predict(x_test)\nlog_model = (accuracy_score(y_test,y_pred)*100)\nlog_model","78bcfbe1":"y_probs = log_reg.predict_proba(x_test)[:,1]\ny_pred = [1 if i >0.53 else 0 for i in y_probs]\nlog_proba_score = (accuracy_score(y_test,y_pred)*100)\nprint (\"log score=\",log_proba_score)","557916f1":"confusion_matrix(y_test,y_pred)","fce89154":"log_params = {\"C\":np.logspace(-3,3,7),\n              \"penalty\": [\"l1\",\"l2\"],\n              \"max_iter\":[10,50,500,1000]} #\"solver\":['lbfgs', 'liblinear', 'sag', 'saga'],\nlog =LogisticRegression()\nlog_cv = GridSearchCV(log,log_params,cv = 10)\n\nlog_tuned = log_cv.fit(x_train,y_train)\nlog_tuned.best_params_","ebd5f98f":"log_reg_tuned = LogisticRegression(C=100,max_iter=50,penalty='l2',solver='liblinear').fit(x_train,y_train)\ny_probs = log_reg.predict_proba(x_test)[:,1]\ny_pred = [1 if i >0.53 else 0 for i in y_probs]","f3546f11":"log_tuned_score = (accuracy_score(y_test,y_pred)*100)\nprint (\"log tuned score=\",log_tuned_score)","c6e74708":"lr_cm = confusion_matrix(y_test,y_pred)\nlr_cm","5b381795":"from sklearn.naive_bayes import GaussianNB","76faa296":"nb = GaussianNB()\ngnb_model = nb.fit(x_train,y_train)\ngnb_model","652e3d11":"y_pred = gnb_model.predict(x_test)\nnb_score = (accuracy_score(y_test,y_pred)*100)\nnb_score","6145f4af":"nb_params = {'var_smoothing': np.logspace(0,-9, num=100)}","9b0a152f":"nb =GaussianNB()\nnb_cv = GridSearchCV(nb,nb_params,cv = 10)\n\nnb_cv = nb_cv.fit(x_train,y_train)\nnb_cv.best_params_","678d3ec6":"nb_tuned =GaussianNB(var_smoothing=0.43287612810830584).fit(x_train,y_train)\ny_pred = nb_tuned.predict(x_test)\nnb_tuned = (accuracy_score(y_test,y_pred)*100)\nnb_tuned","e8754bf6":"nb_cm = confusion_matrix(y_test,y_pred)\nnb_cm","bfb40213":"from sklearn.neighbors import KNeighborsClassifier","748e5803":"knn =KNeighborsClassifier()\nknn_model = knn.fit(x_train,y_train)\nknn_model","c1fa355a":"y_pred = knn_model.predict(x_test)\nknn_score = (accuracy_score(y_test,y_pred)*100)\nknn_score","fe999bf3":"knn_params = {\"n_neighbors\":np.arange(1,50),\n              \"weights\": [\"uniform\",\"distance\"],\n              \"metric\":[\"euclidean\",\"manhattan\"]}","d4dae7e2":"knn =KNeighborsClassifier()\nknn_cv = GridSearchCV(knn,knn_params,cv = 10)\nknn_cv = knn_cv.fit(x_train,y_train)","bb97c3f9":"print(\"Best Parameters:\"+str(knn_cv.best_params_))","18655af4":"knn_final =KNeighborsClassifier(n_neighbors =15,metric='manhattan',weights='distance')\nknn_final = knn_final.fit(x_train,y_train)\ny_pred = knn_final.predict(x_test)\nknn_tuned = (accuracy_score(y_test,y_pred)*100)\nknn_tuned","74c05d22":"knn_cm = confusion_matrix(y_test,y_pred)\nknn_cm","e88b1147":"from sklearn.svm import SVC","d5af853a":"svm_model_linear = SVC(kernel='linear').fit(x_train,y_train)\nsvm_model_poly = SVC(kernel='poly').fit(x_train,y_train)\nsvm_model_rbf = SVC(kernel='rbf').fit(x_train,y_train)","339e1eab":"y_pred_linear = svm_model_linear.predict(x_test)\ny_pred_poly = svm_model_poly.predict(x_test)\ny_pred_rbf = svm_model_rbf.predict(x_test)","150d7e35":"print(accuracy_score(y_test,y_pred_linear))\nprint(accuracy_score(y_test,y_pred_poly))\nprint(accuracy_score(y_test,y_pred_rbf))","b6af699f":"svc_params = {\"C\": [1,5,10,50,100,200],\n              'kernel':['poly','rbf'],\n              \"gamma\": [0.001, 0.01, 0.1,0.5],}\n                 \nsvc = SVC()\nsvc_cv_model = GridSearchCV(svc,svc_params,\n                            cv = 5,\n                           n_jobs = -1,\n                           verbose = 2)\nsvc_cv_model.fit(x_train,y_train)\nprint(\"Best Parameters:\"+str(svc_cv_model.best_params_))","a93e99de":"svc_tuned = SVC(kernel = \"poly\",C=100,gamma=0.5).fit(x_train,y_train)","837241ba":"y_pred = svc_tuned.predict(x_test)\nsvc_tuned_score = (accuracy_score(y_test,y_pred)*100)\nsvc_tuned_score","e979840d":"confusion_matrix(y_test,y_pred)","6f8d3be2":"svc_rbf_tuned = SVC(kernel = \"rbf\",C=100,gamma=0.1).fit(x_train,y_train)\ny_pred = svc_rbf_tuned.predict(x_test)","dd8b5e71":"svc_rbf_score = (accuracy_score(y_test,y_pred)*100)\nsvc_rbf_score","da54a363":"svm_cm = confusion_matrix(y_test,y_pred)\nsvm_cm","16d2ab10":"from sklearn.ensemble import RandomForestClassifier","5bbacecb":"r_for = RandomForestClassifier().fit(x_train,y_train)\nr_for","d8f1e922":"y_pred = r_for.predict(x_test)\nrf_score = accuracy_score(y_test,y_pred)*100\nrf_score","ec0aec29":"rf_params  = {'max_depth':list(range(1,10)),\n             \"max_features\":[\"log2\",\"auto\",\"sqrt\"],\n             \"n_estimators\":[2,10,20,50,150,300],\n             'criterion' : ['gini','entropy'],\n             'min_samples_leaf' : [1,3,5,10]}","87017812":"rf_model = RandomForestClassifier()","b4669160":"rf_cv_model = GridSearchCV(rf_model,\n                           rf_params,\n                           cv = 5,\n                           n_jobs = -1)","05aa6629":"rf_cv_model.fit(x_train,y_train)\nrf_cv_model.best_params_","284183d5":"rf_tuned = RandomForestClassifier(max_depth = 10,\n                                  criterion = 'gini',\n                                  max_features = 'log2',\n                                  min_samples_leaf = 1,\n                                  n_estimators = 150,random_state=42)\nrf_tuned = rf_tuned.fit(x_train,y_train)\ny_pred  = rf_tuned.predict(x_test)\nrf_tuned_score = (accuracy_score(y_test,y_pred)*100)\nrf_tuned_score","9c08c075":"rf_cm = confusion_matrix(y_test,y_pred)\nrf_cm","df3c4d40":"from sklearn.ensemble import GradientBoostingClassifier","6e8b2b44":"gbm = GradientBoostingClassifier()\ngbm_model = gbm.fit(x_train,y_train) \ngbm_model","b3c72e2d":"y_pred = gbm_model.predict(x_test)\ngbm_score = accuracy_score(y_test,y_pred)*100\ngbm_score","350d0554":"gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.2],\n             \"n_estimators\": [100,200,300,500,1000],\n             \"max_depth\": [1,3,5,10],\n             \"min_samples_split\": [1,2,5,10]}\ngbm = GradientBoostingClassifier()\nclf = GridSearchCV(gbm,gbm_params,verbose=0,n_jobs=-1,cv=3)\ngb = clf.fit(x_train,y_train)\ngb.best_params_ ","bf4b1ee1":"gbm = GradientBoostingClassifier(n_estimators=100,min_samples_split=5,max_depth=3,learning_rate=0.2,random_state=42)\ngbm.fit(x_train,y_train)\ny_pred = gbm.predict(x_test)\ngbm_tuned_score = accuracy_score(y_test,y_pred)*100\ngbm_tuned_score","9e4520d0":"gbm_cm = confusion_matrix(y_test,y_pred)\ngbm_cm","baefd57a":"#!pip install xgboost\nfrom xgboost import XGBClassifier","a74fd3d4":"xgb = XGBClassifier(n_estimators=100)\nxgb_model = xgb.fit(x_train,y_train) \nxgb_model","2760890f":"y_pred = xgb_model.predict(x_test)\nxgb_score = accuracy_score(y_test,y_pred)*100\nxgb_score","6db3eff0":"xgb_params ={\n        'n_estimators': [50, 100, 200],\n        'subsample': [ 0.6, 0.8, 1.0],\n        'max_depth': [1,2,3,4],\n        'learning_rate': [0.1,0.2, 0.3, 0.4, 0.5],\n        \"min_samples_split\": [1,2,4,6]}","df1b3e26":"xgb = XGBClassifier()\nxgb = GridSearchCV(xgb,xgb_params,verbose=0,n_jobs=-1,cv=3)\nxgb = xgb.fit(x_train,y_train)\nxgb.best_params_","b09e7be8":"xgbm_cv = XGBClassifier(learning_rate=0.3,\n                       max_depth=2,\n                       min_samples_split=1,\n                       n_estimators=100,\n                       subsample=1.0,random_state=42).fit(x_train,y_train)","a057200b":"y_pred = xgbm_cv.predict(x_test)\nxgbm_score = (accuracy_score(y_test,y_pred)*100)\nxgbm_score","155414dc":"xgbm_cm = confusion_matrix(y_test,y_pred)\nxgbm_cm","a00ff84c":"from lightgbm import LGBMClassifier","e7bc695c":"lgbm = LGBMClassifier().fit(x_train,y_train)\ny_pred = lgbm.predict(x_test)","136aa0c7":"lgbm_score = (accuracy_score(y_test,y_pred)*100)\nlgbm_score","a8863366":"lgbm_params = {\"learning_rate\" : [0.001,0.01, 0.1],\n             \"n_estimators\": [100,200,300,500,1000],\n             \"max_depth\": [2,3,5,7],\n             \"min_child_samples\": [1,3,5,7]}\nlgbm = LGBMClassifier()\nlgbm_cv = GridSearchCV(lgbm,lgbm_params,verbose=0,n_jobs=-1,cv=5)\nlgbm_cv_model = lgbm_cv.fit(x_train,y_train)\nlgbm_cv_model.best_params_","9e05f084":"lgbm = LGBMClassifier(learning_rate=0.01,max_depth=5,min_child_samples=5,n_estimators=400)\nlgbm_tuned = lgbm.fit(x_train,y_train)\ny_pred = lgbm_tuned.predict(x_test)\nlgbm_tuned_acc = (accuracy_score(y_test,y_pred)*100)\nlgbm_tuned_acc","fce82342":"lgbm_cm = confusion_matrix(y_test,y_pred)\nlgbm_cm","e128c6d8":"from catboost import CatBoostClassifier","7176c8af":"cat_model = CatBoostClassifier().fit(x_train,y_train)\ny_pred = cat_model.predict(x_test)","e7f2083f":"cat_score = accuracy_score(y_test,y_pred)*100\ncat_score","8aa1244f":"cat_params = {\"iterations\":[100,200,500,700],\n              'loss_function': ['Logloss', 'CrossEntropy'],\n              \"learning_rate\":[0.01,0.02,0.1],\n              \"depth\":[1,3,5,8]}","f4d94c4f":"catb =  CatBoostClassifier()\ncatb_cv_model = GridSearchCV(catb,cat_params,cv = 5,n_jobs = -1,verbose = 2)\ncatb_cv_model.fit(x_train,y_train)\ncatb_cv_model.best_params_","b9ea8dfa":"catb_final = CatBoostClassifier(depth=5,iterations=500,learning_rate=0.02,loss_function= 'Logloss')\ncatb_final = catb_final.fit(x_train,y_train)","96e120b3":"y_pred = catb_final.predict(x_test)\ncatb_final_score =(accuracy_score(y_test,y_pred)*100)\ncatb_final_score ","300a8154":"catb_cm = confusion_matrix(y_test,y_pred)\ncatb_cm","b91842d1":"## We will use also scaler for improving the score of ML algorithms\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(x)\nx_scaled = scaler.transform(x)","fb17ee01":"x_train,x_test,y_train,y_test = train_test_split(x_scaled,y,\n                                                test_size = 0.30,\n                                                random_state = 42)","5d9715ac":"knn_params = {\"n_neighbors\":np.arange(1,50),\n              \"weights\": [\"uniform\",\"distance\"],\n              \"metric\":[\"euclidean\",\"manhattan\"]}\n\nknn =KNeighborsClassifier()\nknn_cv = GridSearchCV(knn,knn_params,cv = 5)\nknn_cv = knn_cv.fit(x_train,y_train)\nprint(\"Best Parameters:\"+str(knn_cv.best_params_))","e420711c":"knn_scaled =KNeighborsClassifier(n_neighbors =29,metric='manhattan',weights='distance')\nknn_scaled = knn_scaled.fit(x_train,y_train)\ny_pred = knn_scaled.predict(x_test)\nknn_sscore = (accuracy_score(y_test,y_pred)*100)\nknn_sscore","7e305ce5":"knn_scaled_conf = confusion_matrix(y_test,y_pred)\nknn_scaled_conf","ae7eeb2e":"svm_scaled_linear = SVC(kernel='linear').fit(x_train,y_train)\nsvm_scaled_poly = SVC(kernel='poly').fit(x_train,y_train)\nsvm_scaled_rbf = SVC(kernel='rbf').fit(x_train,y_train)","8e797ad1":"y_pred_slinear = svm_scaled_linear.predict(x_test)\ny_pred_spoly = svm_scaled_poly.predict(x_test)\ny_pred_srbf = svm_scaled_rbf.predict(x_test)\n\nprint(accuracy_score(y_test,y_pred_slinear))\nprint(accuracy_score(y_test,y_pred_spoly))\nprint(accuracy_score(y_test,y_pred_srbf))","735ca0c2":"svc_params = {\"C\": [10,50,100,500,700],\n              'kernel':['poly','rbf'],\n              \"gamma\": [0.001, 0.01, 0.1]} \n                 \nsvc = SVC()\nsvc_cv_model = GridSearchCV(svc,svc_params,\n                            cv = 5,\n                           n_jobs = -1,\n                           verbose = 2)\nsvc_cv_model.fit(x_train,y_train)\nprint(\"Best Parameters:\"+str(svc_cv_model.best_params_))","11b5162c":"svc_scaled = SVC(kernel = 'rbf',C = 500, gamma = 0.01)\nscaled = svc_scaled.fit(x_train,y_train)\ny_pred = scaled.predict(x_test)","16358332":"svm_scaled_score = (accuracy_score(y_test,y_pred)*100)\nsvm_scaled_score","145cae32":"svc_scaled_conf = confusion_matrix(y_test,y_pred)\nsvc_scaled_conf","46aab57e":"rf_params  = {'max_depth':list(range(1,11)),\n             \"max_features\":[\"log2\",\"auto\",\"sqrt\"],\n             \"n_estimators\":[2,10,20,50,150,300],\n             'criterion' : ['gini','entropy'],\n             'min_samples_leaf' : [1,3,5,10]}","a072972a":"rf_model = RandomForestClassifier(random_state = 42)\nrf_cv_model = GridSearchCV(rf_model,\n                           rf_params,\n                           cv = 5,\n                           n_jobs = -1)\nrf_cv_model.fit(x_train,y_train)\nrf_cv_model.best_params_","0b3b925f":"rf_tuned = RandomForestClassifier(max_depth = 10,\n                                  criterion = 'gini',\n                                  max_features = 'log2',\n                                  min_samples_leaf = 1,\n                                  n_estimators = 150,random_state = 42)\nrf_tuned = rf_tuned.fit(x_train,y_train)\ny_pred  = rf_tuned.predict(x_test)\nrf_scaled_score = (accuracy_score(y_test,y_pred)*100)\nrf_scaled_score","e29423e3":"rf_scaled_conf = confusion_matrix(y_test,y_pred)\nrf_scaled_conf","7b4d034b":"lgbm_params = {\"learning_rate\" : [0.01, 0.02,0.1],\n             \"n_estimators\": [100,200,300,500,1000],\n             \"max_depth\": [2,3,5,7],\n             \"min_child_samples\": [1,2,5,10]}\nlgbm = LGBMClassifier()\nlgbm_cv = GridSearchCV(lgbm,lgbm_params,verbose=0,n_jobs=-1,cv=5)\nlgbm_cv_model = lgbm_cv.fit(x_train,y_train)\nlgbm_cv_model.best_params_","79a28d47":"lgbm = LGBMClassifier(learning_rate=0.02,max_depth=5,min_child_samples=5,n_estimators=500,random_state = 42)\nlgbm_tuned = lgbm.fit(x_train,y_train)\ny_pred = lgbm_tuned.predict(x_test)\nlgbm_scaled_acc = (accuracy_score(y_test,y_pred)*100)\nlgbm_scaled_acc","97c50599":"lgbm_scaled_conf = confusion_matrix(y_test,y_pred)\nlgbm_scaled_conf","3b11c28d":"logit_roc_auc = roc_auc_score(y_test,log_reg_tuned.predict(x_test))\n\nfpr, tpr, tresholds = roc_curve(y_test,log_reg_tuned.predict_proba(x_test)[:,1])\nplt.figure(figsize=(6,6))\nplt.plot(fpr,tpr,label = \"AUC (area = %0.2f)\"%logit_roc_auc)\nplt.plot([0,1],[0,1],\"r--\")\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.0])\nplt.xlabel(\"False Positive Ratio\")\nplt.ylabel(\"True Positive Ratio\")\nplt.title('ROC Curve');","c4afd2db":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y_test,y_probs)","a980990f":"fig = plt.figure(figsize=(15,15))\n\nax1 = fig.add_subplot(4, 4, 1) # row, column, position\nax1.set_title('Logistic Regression Classification')\n\nax2 = fig.add_subplot(4, 4, 2) # row, column, position\nax2.set_title('KNN Classification')\n\nax3 = fig.add_subplot(4, 4, 3)\nax3.set_title('SVM Classification')\n\nax4 = fig.add_subplot(4, 4, 4)\nax4.set_title('Naive Bayes Classification')\n\nax5 = fig.add_subplot(4, 4, 5)\nax5.set_title('Random Forest Classification')\n\nax6 = fig.add_subplot(4, 4, 6)\nax6.set_title('GBM Classification')\n\nax7 = fig.add_subplot(4, 4, 7)\nax7.set_title('LightGBM Classification')\n\nax8 = fig.add_subplot(4, 4, 8)\nax8.set_title('XGBoost Classification')\n\nax9 = fig.add_subplot(4, 4, 9)\nax9.set_title('CatBoost Classification')\n\nax10 = fig.add_subplot(4, 4, 10)\nax10.set_title('KNN Scaled Classification')\n\nax11 = fig.add_subplot(4,4, 11)\nax11.set_title('SVC Scaled Classification')\n\nax12 = fig.add_subplot(4,4, 12)\nax12.set_title('Random Forest Scaled Classification')\n\nax13 = fig.add_subplot(4, 4, 13)\nax13.set_title('LightGBM Scaled Classification')\n\n\nsns.heatmap(data=lr_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax1, cmap='magma')\nsns.heatmap(data=knn_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax2, cmap='magma')   \nsns.heatmap(data=svm_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax3, cmap='magma')\nsns.heatmap(data=nb_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax4, cmap='magma')\nsns.heatmap(data=rf_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax5, cmap='magma')\nsns.heatmap(data=gbm_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax6, cmap='magma')\nsns.heatmap(data=lgbm_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax7, cmap='magma')\nsns.heatmap(data=xgbm_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax8, cmap='magma')\nsns.heatmap(data=catb_cm, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax9, cmap='magma')\nsns.heatmap(data=knn_scaled_conf, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax10, cmap='magma')\nsns.heatmap(data=svc_scaled_conf, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax11, cmap='magma')\nsns.heatmap(data=rf_scaled_conf, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax12, cmap='magma')\nsns.heatmap(data=lgbm_scaled_conf, annot=True, linewidth=0.7, linecolor='cyan', fmt='.0f', ax=ax13, cmap='magma')\nplt.show()","c85e3d2a":"indexx = [\"Log\",\"RF\",\"KNN\",\"SVM\",\"NB\",\"GBM\",\"LightGBM\",\"XGBoost\",'CatBoost',\"KNN Scaled\",\"SVM Scaled\", 'RF Scaled',\"LightGBM Scaled\"]\nregressions = [log_tuned_score,rf_tuned_score,knn_tuned,svc_rbf_score,nb_tuned,gbm_tuned_score,\n               lgbm_tuned_acc,xgbm_score,catb_final_score,knn_sscore,svm_scaled_score,rf_scaled_score,lgbm_scaled_acc]\n\nplt.figure(figsize=(12,8))\nsns.barplot(x=indexx,y=regressions)\nplt.xticks(rotation=45)\nplt.title('Model Comparision',color = 'green',fontsize=20);","ef46ce52":"\npie_list=regressions\nlabels=list(zip(indexx,regressions))\nfig={\n    \"data\":[\n        {\n            \"values\":pie_list,\n            \"labels\":labels,\n            \"domain\": {\"x\": [.2, 1]},\n            \"name\": \"Models-Accuracy Score\",\n            \"hoverinfo\":\"label+percent+name\",\n            \"hole\": .4,\n            \"type\": \"pie\"\n        },],\n    \"layout\":{\n        \"title\":\"Accuracy Scores\",\n        \"annotations\":[\n            {\n                \"font\":{\"size\":20},\n                \"showarrow\": False,\n                \"text\": \"Model Scores\",\n                \"x\": 0.60,\n                \"y\": 0.50\n            },\n        ]\n    }  \n}\niplot(fig)","b637fb56":"### * Logistic Regression ROC Curve","6d25e823":"* Balance has no effect on exit decision.","23c8bd22":"# Conclusion","e2045201":"### KNN","91d53d94":"#### Polinomal kernel(poly)","ce2a7c50":"### Confusion Matrix","af2a176a":"* Gradient Boosting Machines (GBM) (Same as normalized model)\n* XGBoost (Same as normalized model)\n* CatBoost (Same as normalized model)","94995595":"## Gaussian NB","ca5f653d":"## 2.2) The country with the highest salary","6551af03":"- Credit card users and non credit card users accumulated between 25-45 ages. The amount of people credit card owners and others stable in all ages.","685c217b":"* Around %20 of people exited.\n* Females exited proportionally and numerically more (1139 Feamle\/898 Male)\n* Germans proportionally and numerically exited most(448 Female - 366 Male)\n* French female numerically exited more (460)\n* Frenchs continued with a bank numerically and proportionally most(5014 - 810 => 4196)","9c4d1b88":"## 2) A-Feature Engineering","d42b3c26":"* Confusion Matrix","82dacd64":"# Standart Scaler Effect","880050d9":"## 3)Building ML Models\n* **Interpretation of variables**\n* **Preparing variables for model building**\n    1. Building dependent and undependent variables\n    2. Determining Train and Test sets\n* **Building a model**\n    1. Trying all models of the learning algorithms \n    2. Setting the parameters\n    3. Determining best parameters \n    4. Doing Cross validation \n    5. Finding Acury score \n    6. The most effective variables will be determined in each model\n* **Comparing the models**\n    1. Visualization of all models\u2019 acury score\n    2. The model that gives the best results will be determined\n    3. Research will be done on the mathematical algorithm that creates the best model.","2a30cdd9":"### Tuning","ff9cc642":"### Age\n-  We will create new age groups for improve our perdiction score. ","3151bf86":"### Confusion Matrix","7e6bcfb2":"* Confusion Matrix","b63ac533":"### Confusion Matrix","7abc095e":"- Cat Boost model has the higest accuracy rate (87.33333333333333)\n- Cat Boost model is really successfull at catching 'true positives' of conf matrix =>>>(**2356**,73)(307,264)\n- GBM model is succesfull at catching 'false positives' conf matrix ==> (2339,   90) (297,  **274**)\n- Model tuning made quite improvement in all models. \n- We can experienced different scores for some models with normalization and standart scaler.\n- The final model is depends if we aiming catching exited members or all members(true-positive\/false-positive).","4e85e03b":"### Credit Score\n* We will create a boundary line for credit score. Because the credit score has no effect on exit rates that boundary(405) is create two groups and we predict if a person below this boundary then it will precisely exit. ","1e1d7119":"## Model Tuning","30be13eb":"- As we can see the customers without credit card exited 39-52 most(median=45)\n- Credit card owners also same beahivor, exited ages 38-51 most(median=45)\n* As a result for age variable credit card usage does not effect the exit decison directly. This can may be the occur fot that reason in most cases banks give credit card to customers automaticly.","54e6bd52":"## Our Goal:\n* > First: we will explore and clean the data. Deep understanding and data cleaning is so important for making good predictions.\n* > Second: we will make lots of visualization for deep understanding of the data, After that visualizations we will decide if we need creatig new variables or not.\n* > Finally: we will use Machine Learning Algorithms for make predictions about if a customer left the bank or not.","34a4c0fc":"## 9) Cat-Boost","9a47b788":"### Salary Distribution (Leaving Bank)","73ad12f7":"# 4) SVM (Support Vector Machines)","e87e61b0":"# Final Chapter - Models Comparison","50bce61a":"### Tuning","d20789d7":"- As we can see the table above how the categories effect exiting decision:\n * Females and unactive members more prone to exit.\n * Credit card users are also a bit more prone to exit than non credit card users.","01ae2faf":"# 3) KNN","dccd07bc":"### Creating Dummy Variables","df5a2a4d":"### Confusion Matrix","6579e068":"### LightGBM ","9db232cf":"### Random Forest","42695dba":"# 1) Logistic Regression","2166f093":"* Confusion Matrix","c26230e7":"* Salary has no effect on exit decision.","44171350":"## Summary Information about the variables and their types in the data\n* 1) **Surname :** The surname of the customer\n* 2) **CreditScore :** The credit score of the customer\n* 3) **Geography :** The country of the customer(Germany\/France\/Spain)\n* 4) **Gender :** The gender of the customer (Female\/Male)\n* 5) **Age :** The age of the customer\n* 6) **Tenure :** The customer's number of years in the in the bank\n* 7) **Balance :** The customer's account balance\n* 8) **NumOfProducts :** The number of bank products that the customer uses\n* 9) **HasCrCard :** Does the customer has a card? (0=No,1=Yes)\n* 10) **IsActiveMember :** Does the customer has an active mebership (0=No,1=Yes)\n* 11) **EstimatedSalary :** The estimated salary of the customer\n* 12) **Exited :** Churned or not? (0=No,1=Yes)","620eab71":"### Tuning","15c84a7e":"#### Radial basis function kernel(rbf)","d0a54bc8":" * Gender is scattered all age groups homojenous.\n * The most important thing is that ==>All 21 people who has Credit score under 405 are exited.\n * The max credit score (850) is seen nearly all age groups. The credit score also more homojenous for all age groups.\n * In the mid- ages the credit score is around 650. The credit score does not direct effect the exit decision. On the other hand between 45-56 ages exit rates and credit rates are getting more volatile.  ","18b3c6ff":"- As we can see the table below; the number of people using credit card for countries nearly same.(because France population is doubled others.)","c3903369":"## 6)Gradient Boosting Machines (GBM)","579f2667":"* Proba values - probability of the target\/Creating optimum decision boundary(Exited-or-Not)","9e1a26ab":"# 5) Random Forest","bdea1df9":"* Logistic Regression (Same as the normalized method)\n* Navie Bayes (Worse than normalized method)","35a05fb4":"* Age has great effect on exit decision than other variables. that is obvious ages between 45 and 65 are exited most. ","7fc1fdb2":"## 2.5) The country with the highest credit score","baf51a99":"# Chrun Modelling\n## Introduction\n### This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer.","e3e6b7a7":"# 2) Visualization\n* Countries with the less and the most common use of credit cards\n* The country with the highest salary\n* Visualization of credit card\u2019s usage according to ages\n* Rates of credit card\u2019s usage according to gender\n* The country with the highest credit score\n* The gender with the highest credit score\n* The range of age with the highest credit score\n* Customers in which age range work longer with their banks\n* Customers leaving the bank\n* Female \u2013 Male rates\n* Age distribution\n* Salary distribution","9712b78b":"### As we can see our Roc curve is not much close to left top corner. This means our prediction score is a bit lover than expected. ","f6eba63a":"### Tuning","452c821c":"* Salary does not any effect on exit rates.","95ebcb22":"* As we can see there is outliers below 400 credit scores in different countries. On contrast  Credit score does not any direct effect on exit rates. \n* Unactive members exited more.\n* Germans Exited more.","37b93227":"### Support Vector Machines","070136cf":"# If you find my work useful please upvote.","106545c8":"* Confusion Matrix","fe49d42b":"## 2.8) Customers in which age range work longer with their banks","ade9f2ec":"# 1) Exploration of Dataset","750f360a":"## Correlation Heatmap","569e9811":"## 2.1) Countries with the less and the most common use of credit cards","294b6430":"## 7) XGBoost","baa984dc":"### Creating Variables-Normalization","3330a22c":"### Tuning","40623685":"### Confusion Matrix","4207c796":"## Model Tuning","84a6e3de":"## Model Tuning","2ce95988":"## 2.9) Customers leaving the bank\n* Female \u2013 Male rates\n* Age distribution\n* Salary distribution","7cbe6f8e":"### Tuning","c3cc9743":"#### Confusion Matrix","9b795f33":"* The credit score is same for genders in all countries.","8abfded5":"## Confusion Matrix Comparison","414bafc6":"## 2.6) The gender with the highest credit score","f5ca188e":"## Model Score Comparison","dba6e2f1":"## 2.7) The range of age with the highest credit score","592b237b":"## 8) Light GBM","9bda94ee":"# 2) Naive Bayes\n","f7cbaf04":"## 2.3) Visualization of credit card\u2019s usage according to ages","433fa056":"## 2.4) Rates of credit card\u2019s usage according to gender","82ee5313":"### Confusion Matrix"}}