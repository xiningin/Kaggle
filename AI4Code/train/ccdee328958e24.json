{"cell_type":{"ab73f835":"code","1406a3cb":"code","c0d11387":"code","86b87a6d":"code","c7be748c":"code","27efa00c":"code","32968a86":"code","e2a592cd":"code","d48c0093":"code","0382ded9":"code","837fa4ba":"code","3943ca4d":"code","1f6f78ea":"code","a56ab3bb":"code","980c1073":"code","71592708":"code","ac308943":"code","707e6758":"code","9913936b":"code","fc00a612":"code","680a293d":"code","f0e515b0":"code","77bcdd09":"code","b0d8c098":"code","06ceff45":"code","8300b622":"code","0fde4d28":"code","49381bff":"code","6ab0dfb0":"code","2329ed33":"code","341101cc":"markdown","6fdfa59a":"markdown","b98eadfb":"markdown","4db18dcd":"markdown"},"source":{"ab73f835":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1406a3cb":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom pathlib import Path\nfrom sklearn.preprocessing import LabelEncoder\nimport PIL\nimport cv2\n","c0d11387":"image_dir = Path('..\/input\/braille-character-dataset\/Braille Dataset\/Braille Dataset')","86b87a6d":"dir_list = list(image_dir.glob('*.jpg'))","c7be748c":"image_count = len(dir_list)\nimage_count","27efa00c":"name_list = []\nfor i in dir_list:\n    name_list.append(os.path.basename(i)[0])","32968a86":"#opens images and puts into a list\nimages = []\nfor dir in dir_list:\n    I = cv2.imread(str(dir))\n    images.append(I)","e2a592cd":"#turn both lists in numpy arrays\nimages_list = np.array(images)\nname_list = np.array(name_list).T #transpose - convert columns to rows","d48c0093":"#encodes name_list and normalizes image_list\nle = LabelEncoder()\nname_list = le.fit_transform(name_list)\n\n#covert image to 0 to 255 (pixel information)\nimages_list = images_list \/ 255.0 \nprint(images_list[0])","0382ded9":"plt.imshow(images_list[1])","837fa4ba":"from sklearn.model_selection import train_test_split","3943ca4d":"X_train, X_test, y_train, y_test = train_test_split(images_list, name_list, test_size=0.2, random_state=42)","1f6f78ea":"model = keras.Sequential([\n    keras.layers.Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation='relu'),\n    keras.layers.MaxPooling2D(pool_size=(2,2)),\n    keras.layers.BatchNormalization(),\n\n    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n    keras.layers.MaxPooling2D(pool_size=(2,2)),\n    keras.layers.Dropout(0.25),   \n    keras.layers.BatchNormalization(),\n    \n    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n    keras.layers.MaxPooling2D(pool_size=(2,2)),\n    keras.layers.Dropout(0.25),   \n    keras.layers.BatchNormalization(),\n\n    keras.layers.Flatten(),\n    \n    keras.layers.Dense(units=576, activation=\"relu\"),\n    keras.layers.Dropout(0.25),\n    keras.layers.BatchNormalization(),\n\n    keras.layers.Dense(units=288, activation=\"relu\"),\n\n    keras.layers.Dense(units=26, activation=\"softmax\") #output layer\n])","a56ab3bb":"model.compile(optimizer=\"Adam\", loss=\"SparseCategoricalCrossentropy\", metrics=[\"sparse_categorical_accuracy\"])","980c1073":"from keras.callbacks import EarlyStopping","71592708":"es1 = EarlyStopping(patience=20, monitor=\"val_sparse_categorical_accuracy\", mode=\"auto\")\nes2 = EarlyStopping(patience=20, monitor=\"val_loss\", mode=\"auto\")\n\n#The neural network will stop fitting if it gets 20 epochs without converge\n\nhistory = model.fit(x=X_train,\n                    y=y_train,\n                    epochs=100,\n                    validation_split=0.3,\n                    callbacks=[es1, es2])","ac308943":"model.summary()","707e6758":"time = np.arange(1, len(history.history['loss'])+1)","9913936b":"sns.lineplot(data=history.history, x=time, y='loss')\nsns.lineplot(data=history.history, x=time, y='val_loss')\nplt.title('Loss fitting history')\nplt.legend(labels=['Loss', 'Validation loss'])\nplt.show()","fc00a612":"sns.lineplot(data=history.history, x=time, y='val_sparse_categorical_accuracy')\nsns.lineplot(data=history.history, x=time, y='sparse_categorical_accuracy')\nplt.title('Accuracy fitting history')\nplt.legend(labels=['Accuracy', 'Valuation accuracy'])\nplt.show()","680a293d":"print(\"Adam Optimizer\")\nmodel.evaluate(X_test, y_test)","f0e515b0":"model = keras.Sequential([\n    keras.layers.Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation='relu'),\n    keras.layers.MaxPooling2D(pool_size=(2,2)),\n    keras.layers.BatchNormalization(),\n\n    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n    keras.layers.MaxPooling2D(pool_size=(2,2)),\n    keras.layers.Dropout(0.25),   \n    keras.layers.BatchNormalization(),\n\n    keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),\n    keras.layers.MaxPooling2D(pool_size=(2,2)),\n    keras.layers.Dropout(0.25),   \n    keras.layers.BatchNormalization(),\n\n    keras.layers.Flatten(),\n    \n    keras.layers.Dense(units=576, activation=\"relu\"),\n    keras.layers.Dropout(0.25),\n    keras.layers.BatchNormalization(),\n\n    keras.layers.Dense(units=288, activation=\"relu\"),\n    keras.layers.Dense(units=26, activation=\"softmax\") #output layer\n])","77bcdd09":"model.compile(optimizer=\"RMSprop\", loss=\"SparseCategoricalCrossentropy\", metrics=[\"sparse_categorical_accuracy\"])","b0d8c098":"from keras.callbacks import EarlyStopping","06ceff45":"es1 = EarlyStopping(patience=20, monitor=\"val_sparse_categorical_accuracy\", mode=\"auto\")\nes2 = EarlyStopping(patience=20, monitor=\"val_loss\", mode=\"auto\")\n\n#The neural network will stop fitting if it gets 20 epochs without converge\n\nhistory = model.fit(x=X_train,\n                    y=y_train,\n                    epochs=100,\n                    validation_split=0.3,\n                    callbacks=[es1, es2])","8300b622":"model.summary()","0fde4d28":"time = np.arange(1, len(history.history['loss'])+1)","49381bff":"sns.lineplot(data=history.history, x=time, y='loss')\nsns.lineplot(data=history.history, x=time, y='val_loss')\nplt.title('Loss fitting history')\nplt.legend(labels=['Loss', 'Validation loss'])\nplt.show()","6ab0dfb0":"sns.lineplot(data=history.history, x=time, y='val_sparse_categorical_accuracy')\nsns.lineplot(data=history.history, x=time, y='sparse_categorical_accuracy')\nplt.title('Accuracy fitting history')\nplt.legend(labels=['Accuracy', 'Valuation accuracy'])\nplt.show()","2329ed33":"print(\"RMSProp\")\nmodel.evaluate(X_test, y_test)","341101cc":"Creating model: Trial 1: Adam Optimizer","6fdfa59a":"if you use categorical-cross-entropy you need one-hot encoding, and if you use sparse-categorical-cross-entropy you encode as normal integers.","b98eadfb":"SAME Padding: it applies padding to the input image so that the input image gets fully covered by the filter and specified stride.It is called SAME because, for stride 1 , the output will be the same as the input.","4db18dcd":"Creating model: Trial 2: RMS Prop"}}