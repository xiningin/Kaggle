{"cell_type":{"ec371fe1":"code","847e47be":"code","3ff8d655":"code","1c215f40":"code","842685fd":"code","12779d16":"code","86acda3b":"code","cc6ec4d7":"code","f9e67037":"code","f16e3b58":"code","baa419a8":"code","39362a71":"code","51816180":"code","4b274881":"code","a4126719":"code","1260a2f4":"code","c60f6188":"code","c8b1ca9d":"code","98b1a9b0":"code","1a83d655":"code","156b36dc":"code","2f4142d7":"code","d4057ed2":"code","b0cbd281":"code","784a0fc7":"code","d4de17aa":"code","a37274e6":"code","87584f45":"code","1a2f0408":"code","37c5dc76":"code","ed68c614":"code","88d373d3":"code","18013e2d":"code","1282b7bb":"code","8269bf12":"code","e43f5028":"code","c7a9c20b":"code","80c93aa0":"code","99186a4e":"code","f9f64f3c":"code","b71ce760":"code","275ac6a3":"code","89cb0cfd":"code","98c7b19b":"code","bbbabaf5":"code","392784b4":"code","3d7f4700":"code","78ecb255":"code","e2b4c7d3":"code","a37a93fc":"code","68580ba1":"code","21926669":"code","de482c81":"code","ef883bba":"code","a8272d34":"code","a778eb4c":"code","aad59a6a":"code","97349841":"code","9721eeda":"code","4c1eabe7":"code","8b7fb269":"code","72be4f16":"code","e96c221f":"code","fddb49cb":"code","98d90a4c":"code","d416d90b":"code","2d84d584":"code","9290e037":"code","e16753f8":"code","d6876630":"code","2a437e40":"code","53ecc2bd":"code","b6c30dd6":"code","7b9c79a5":"code","d8738ad1":"code","05f10602":"code","10a849b3":"code","a71737b7":"code","b9fbb81c":"code","3c27340e":"code","e24ad21b":"code","a92ee401":"code","e1bf0288":"code","3a542ff5":"code","7edb7162":"code","97b1db9e":"code","699d21af":"code","510371aa":"code","15e5c9be":"code","1c852bce":"code","f91091de":"code","066be4a4":"code","958e1988":"code","c1e741bf":"code","b4040880":"code","4e4e6cd6":"code","7caef88d":"code","085fe98d":"code","f14791d2":"code","d7a93fca":"code","ade790ac":"code","daef04fa":"code","dc88ce65":"code","dbb0c356":"code","14b72f71":"code","d086793c":"markdown","c961d2da":"markdown","f2ebf631":"markdown","601e9db9":"markdown","20959e4e":"markdown","ffec6e03":"markdown","21b46dda":"markdown","b57ffab6":"markdown","8f7908bd":"markdown","00df6ad5":"markdown","f333d5ec":"markdown","2dbf25fe":"markdown","6add3f53":"markdown"},"source":{"ec371fe1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","847e47be":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom pandas import DataFrame, Series\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 100)\n","3ff8d655":"df_train = pd.read_csv('\/kaggle\/input\/homework-for-students3\/train.csv', index_col=0)\ndf_test = pd.read_csv('\/kaggle\/input\/homework-for-students3\/test.csv', index_col=0)\n\nsample_submission = pd.read_csv('\/kaggle\/input\/homework-for-students3\/sample_submission.csv')\nfree_zipcde_database = pd.read_csv('\/kaggle\/input\/homework-for-students3\/free-zipcode-database.csv')\nstatelatlong = pd.read_csv('\/kaggle\/input\/homework-for-students3\/statelatlong.csv')","1c215f40":"df_train.shape, df_test.shape","842685fd":"df_train.head()","12779d16":"df_test.head()","86acda3b":"df_train.describe()","cc6ec4d7":"df_test.describe()","f9e67037":"df_train.groupby('issue_d').agg(np.sum)","f16e3b58":"df_train['issue_d2'] = df_train['issue_d']\ndf_test['issue_d2'] = df_test['issue_d']","baa419a8":"df_train['issue_d2'] = df_train['issue_d2'].replace('Jan-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Feb-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Mar-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Apr-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('May-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Jun-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Jul-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Aug-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Sep-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Oct-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Nov-', '', regex=True)\ndf_train['issue_d2'] = df_train['issue_d2'].replace('Dec-', '', regex=True)","39362a71":"df_train.groupby('issue_d2').agg(np.sum)","51816180":"df_train.drop(df_train.index[df_train['issue_d2'] == '2007'], inplace=True)\ndf_train.drop(df_train.index[df_train['issue_d2'] == '2008'], inplace=True)\ndf_train.drop(df_train.index[df_train['issue_d2'] == '2009'], inplace=True)\ndf_train.drop(df_train.index[df_train['issue_d2'] == '2010'], inplace=True)\ndf_train.drop(df_train.index[df_train['issue_d2'] == '2011'], inplace=True)\n### added Thank you, KK, for giving me great suggestion. Your suggestion made my score improved a lot! \ndf_train.drop(df_train.index[df_train['issue_d2'] == '2012'], inplace=True)\ndf_train.drop(df_train.index[df_train['issue_d2'] == '2013'], inplace=True)\ndf_train.drop(df_train.index[df_train['issue_d2'] == '2014'], inplace=True)","4b274881":"df_train.describe()","a4126719":"df_test.describe()","1260a2f4":"df_train['loan_condition'].isnull().sum()","c60f6188":"df_train['loan_condition'].value_counts()","c8b1ca9d":"## X_train \u3068 X_test \u306e\u5206\u5272\u306f\u3001\u5148\u306b\u8868\u7d50\u5408\u3092\u6e08\u307e\u305b\u305f\u65b9\u304c\u7121\u96e3\u3002\u30bf\u30fc\u30b2\u30c3\u30c8\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3067\u306f\u307e\u3063\u305f\u3002","98b1a9b0":"# df = pd.DataFrame(df_train['purpose'])\n# df_edit = df.copy()\n# df_edit = pd.DataFrame(df_test['purpose'])\n# df_diff = pd.concat([df,df_edit])\n# df_diff = df_diff.drop_duplicates(keep=False)\n# # keep=\"last\"\u3067df_edit\u5074\u306e\u5024\u3092\u6b8b\u3059\n# df_diff.drop_duplicates(subset=\"purpose\",keep=\"last\")","1a83d655":"# df_train[df_train['purpose'].str.contains('educational', regex=True)]","156b36dc":"# df_test[df_test['purpose'].str.contains('educational', regex=True)]","2f4142d7":"# #newdf = df[df['C'] != 'XYZ']\n# df_train = df_train[df_train['purpose'] != 'educational']","d4057ed2":"# df = pd.DataFrame(df_train['addr_state'])\n# df_edit = df.copy()\n# df_edit = pd.DataFrame(df_test['addr_state'])\n# df_diff = pd.concat([df,df_edit])\n# df_diff = df_diff.drop_duplicates(keep=False)\n# # keep=\"last\"\u3067df_edit\u5074\u306e\u5024\u3092\u6b8b\u3059\n# df_diff.drop_duplicates(subset=\"addr_state\",keep=\"last\")","b0cbd281":"# df_train[df_train['addr_state'].str.contains('ID', regex=True)]","784a0fc7":"# df_test[df_test['addr_state'].str.contains('ID', regex=True)]","d4de17aa":"# #newdf = df[df['C'] != 'XYZ']\n# df_test = df_test[df_test['addr_state'] != 'ID']","a37274e6":"# df_test[df_test['addr_state'].str.contains('ID', regex=True)]","87584f45":"# #C:\\Users\\hiroa>cat kadai_zipcode.txt | perl -lane \"print \\\"df_test[df_test['zip_code'].str.contains('$_', regex=True)]\\\"\"\n# df_test[df_test['zip_code'].str.contains('819xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('509xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('503xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('522xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('269xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('892xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('929xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('205xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('709xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('849xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('694xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('520xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('817xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('568xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('399xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('649xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('862xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('507xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('202xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('621xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('552xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('909xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('698xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('055xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('515xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('528xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('966xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('521xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('353xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('009xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('872xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('987xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('525xx', regex=True)]","1a2f0408":"# df_test[df_test['zip_code'].str.contains('525xx', regex=True)]","37c5dc76":"# df_train[df_train['zip_code'].str.contains('525xx', regex=True)]","ed68c614":"# #newdf = df[df['C'] != 'XYZ']\n# df_test = df_test[df_test['zip_code'] != '525xx']","88d373d3":"# df_test = df_test[df_test['zip_code'] != '819xx']\n# df_test = df_test[df_test['zip_code'] != '509xx']\n# df_test = df_test[df_test['zip_code'] != '503xx']\n# df_test = df_test[df_test['zip_code'] != '522xx']\n# df_test = df_test[df_test['zip_code'] != '269xx']\n# df_test = df_test[df_test['zip_code'] != '892xx']\n# df_test = df_test[df_test['zip_code'] != '929xx']\n# df_test = df_test[df_test['zip_code'] != '205xx']\n# df_test = df_test[df_test['zip_code'] != '709xx']\n# df_test = df_test[df_test['zip_code'] != '849xx']\n# df_test = df_test[df_test['zip_code'] != '694xx']\n# df_test = df_test[df_test['zip_code'] != '520xx']\n# df_test = df_test[df_test['zip_code'] != '817xx']\n# df_test = df_test[df_test['zip_code'] != '568xx']\n# df_test = df_test[df_test['zip_code'] != '399xx']\n# df_test = df_test[df_test['zip_code'] != '649xx']\n# df_test = df_test[df_test['zip_code'] != '862xx']\n# df_test = df_test[df_test['zip_code'] != '507xx']\n# df_test = df_test[df_test['zip_code'] != '202xx']\n# df_test = df_test[df_test['zip_code'] != '621xx']\n# df_test = df_test[df_test['zip_code'] != '552xx']\n# df_test = df_test[df_test['zip_code'] != '909xx']\n# df_test = df_test[df_test['zip_code'] != '698xx']\n# df_test = df_test[df_test['zip_code'] != '055xx']\n# df_test = df_test[df_test['zip_code'] != '515xx']\n# df_test = df_test[df_test['zip_code'] != '528xx']\n# df_test = df_test[df_test['zip_code'] != '966xx']\n# df_test = df_test[df_test['zip_code'] != '521xx']\n# df_test = df_test[df_test['zip_code'] != '353xx']\n# df_test = df_test[df_test['zip_code'] != '009xx']\n# df_test = df_test[df_test['zip_code'] != '872xx']\n# df_test = df_test[df_test['zip_code'] != '987xx']\n","18013e2d":"# # #C:\\Users\\hiroa>cat kadai_zipcode.txt | perl -lane \"print \\\"df_test[df_test['zip_code'].str.contains('$_', regex=True)]\\\"\"\n# df_test[df_test['zip_code'].str.contains('819xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('509xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('503xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('522xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('269xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('892xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('929xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('205xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('709xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('849xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('694xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('520xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('817xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('568xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('399xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('649xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('862xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('507xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('202xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('621xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('552xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('909xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('698xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('055xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('515xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('528xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('966xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('521xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('353xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('009xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('872xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('987xx', regex=True)]\n# df_test[df_test['zip_code'].str.contains('525xx', regex=True)]","1282b7bb":"y_train = df_train['loan_condition'].copy()\nX_train = df_train.drop(['loan_condition'], axis=1).copy()\nX_test = df_test.copy()","8269bf12":"cats = []\nothers = []\nfor col in X_train.columns:\n    if df_train[col].dtype == 'object':\n        cats.append(col)\n        \n    else:\n        others.append(col)","e43f5028":"cats","c7a9c20b":"others","80c93aa0":"for i in X_test.columns:\n    print(i, X_test[i].nunique(), X_test[i].dtype)","99186a4e":"\n# X_train['revol_bal'] = X_train['revol_bal'].apply(np.log1p)\n# X_test['revol_bal'] = X_test['revol_bal'].apply(np.log1p)\n\n# X_train['annual_inc'] = X_train['annual_inc'].apply(np.log1p)\n# X_test['annual_inc'] = X_test['annual_inc'].apply(np.log1p)\n\n# X_train['tot_coll_amt'] = X_train['tot_coll_amt'].apply(np.log1p)\n# X_test['tot_coll_amt'] = X_test['tot_coll_amt'].apply(np.log1p)\n\n# X_train['tot_cur_bal'] = X_train['tot_cur_bal'].apply(np.log1p)\n# X_test['tot_cur_bal'] = X_test['tot_cur_bal'].apply(np.log1p)","f9f64f3c":"others = ['loan_amnt',\n 'installment',\n 'annual_inc',\n 'dti',\n 'delinq_2yrs',\n 'inq_last_6mths',\n 'mths_since_last_delinq',\n 'mths_since_last_record',\n 'open_acc',\n 'pub_rec',\n 'revol_bal',\n 'revol_util',\n 'total_acc',\n 'collections_12_mths_ex_med',\n 'mths_since_last_major_derog',\n 'acc_now_delinq',\n 'tot_coll_amt',\n 'tot_cur_bal']","b71ce760":"# Clipping\nfor col in others:\n    p01 = X_train[col].quantile(0.01)\n    p99 = X_train[col].quantile(0.99)\n    X_train[col] = X_train[col].clip(p01, p99)\n    \n    p01 = X_test[col].quantile(0.01)\n    p99 = X_test[col].quantile(0.99)\n    X_test[col] = X_test[col].clip(p01, p99)","275ac6a3":"#\u6570\u5024\u5909\u63db\u3059\u308b\u3053\u3068\u3067\u7cbe\u5ea6\u304c\u4e0a\u304c\u308b\u7279\u5fb4\u91cf\u3092\u5909\u63db\nX_train['emp_length'] = X_train['emp_length'].replace('years', '', regex=True)\nX_train['emp_length'] = X_train['emp_length'].replace('year', '', regex=True)\nX_train['emp_length'] = X_train['emp_length'].replace(\"\\+\", '', regex=True)\nX_train['emp_length'] = X_train['emp_length'].replace(\"\\<\", '', regex=True)\nX_train['emp_length'] = X_train['emp_length'].replace(\" \", '', regex=True)\nX_train['emp_length'] = X_train['emp_length'].astype(\"float32\")\n\nX_test['emp_length'] = X_test['emp_length'].replace('years', '', regex=True)\nX_test['emp_length'] = X_test['emp_length'].replace('year', '', regex=True)\nX_test['emp_length'] = X_test['emp_length'].replace(\"\\+\", '', regex=True)\nX_test['emp_length'] = X_test['emp_length'].replace(\"\\<\", '', regex=True)\nX_test['emp_length'] = X_test['emp_length'].replace(\" \", '', regex=True)\nX_test['emp_length'] = X_test['emp_length'].astype(\"float32\")","89cb0cfd":"X_train['emp_length'].head(100)","98c7b19b":"print(X_train['emp_length'].dtype)\nprint(X_test['emp_length'].dtype)","bbbabaf5":"print(X_train['emp_length'].head())","392784b4":"# mapping\u3002Tree \u7cfb\u306f\u3001\u6570\u5024\u306e\u9806\u5e8f\u6027\u304c\u91cd\u8981\ndef mapping(map_col, mapping):\n    X_train[map_col] = X_train[map_col].map(mapping)\n    X_test[map_col] = X_test[map_col].map(mapping)","3d7f4700":"grade_mapping = { \"A\": 1,\"B\": 2,\"C\": 3,\"D\": 4,\"E\": 5,\"F\": 6,\"G\": 7 }\n\nsubgrade_mapping = {\"A1\": 1,\"A2\": 2,\"A3\": 3,\"A4\": 4,\"A5\": 5,\"B1\": 6,\"B2\": 7,\"B3\": 8,\"B4\": 9,\"B5\": 10,\n                    \"C1\": 11,\"C2\": 12,\"C3\": 13,\"C4\": 14,\"C5\": 15,\"D1\": 16,\"D2\": 17,\"D3\": 18,\"D4\": 19,\"D5\": 20,\n                    \"E1\": 21,\"E2\": 22,\"E3\": 23,\"E4\": 24,\"E5\": 25,\"F1\": 26,\"F2\": 27,\"F3\": 28,\"F4\": 29,\"F5\": 30,\n                    \"G1\": 31,\"G2\": 32,\"G3\": 33,\"G4\": 34,\"G5\": 35\n                   }","78ecb255":"mapping('grade', grade_mapping)\nmapping('sub_grade', subgrade_mapping)","e2b4c7d3":"#\u5f8c\u3067\u56db\u5247\u6f14\u7b97\u3059\u308b\u306e\u3067\u3001\u578b\u306fint \u306e\u307e\u307e\u3067\u304a\u3044\u3066\u304a\u304f\nX_train['grade+subg'] = X_train['grade'] + X_train['sub_grade']\n#X_train['grade*subg'] = X_train['grade'] * X_train['sub_grade']\n#X_train['grade_subg'] = X_train['sub_grade'] - X_train['grade']\n#X_train['grade%subg'] = X_train['sub_grade'] % X_train['grade']","a37a93fc":"X_train['grade'] = X_train['grade'].astype(\"object\")\nX_test['grade'] = X_test['grade'].astype(\"object\")\n\nX_train['sub_grade'] = X_train['sub_grade'].astype(\"object\")\nX_test['sub_grade'] = X_test['sub_grade'].astype(\"object\")","68580ba1":"X_train = X_train.drop(['purpose'], axis=1)\nX_train = X_train.drop(['earliest_cr_line'], axis=1)\nX_train = X_train.drop(['issue_d'], axis=1)\nX_train = X_train.drop(['issue_d2'], axis=1)\n\nX_test = X_test.drop(['purpose'], axis=1)\nX_test = X_test.drop(['earliest_cr_line'], axis=1)\nX_test = X_test.drop(['issue_d'], axis=1)\nX_test = X_test.drop(['issue_d2'], axis=1)","21926669":"# X_train\n#X_train['tot_coll_amt%_annual_inc'] = X_train['tot_coll_amt'] \/ X_train['annual_inc']\nX_train['tot_coll_amt*_annual_inc'] = X_train['tot_coll_amt'] * X_train['annual_inc']\n\n#X_train['tot_cur_bal%_annual_inc'] = X_train['tot_cur_bal'] \/ X_train['annual_inc']\nX_train['tot_cur_bal*_annual_inc'] = X_train['tot_cur_bal'] * X_train['annual_inc']\n\nX_train['tot_coll_amt%_loan_amnt'] = X_train['tot_coll_amt'] \/ X_train['loan_amnt']\nX_train['tot_coll_amt*_loan_amnt'] = X_train['tot_coll_amt'] * X_train['loan_amnt']\n\nX_train['tot_cur_bal%_loan_amnt'] = X_train['tot_cur_bal'] \/ X_train['loan_amnt']\nX_train['tot_cur_bal*_loan_amnt'] = X_train['tot_cur_bal'] * X_train['loan_amnt']\n\n#X_train['loan_amnt_%_annual_inc'] = X_train['loan_amnt'] \/ X_train['annual_inc']\nX_train['loan_amnt_*_annual_inc'] = X_train['loan_amnt'] * X_train['annual_inc']\n\nX_train['dti_%_annual_inc'] = X_train['dti'] \/ X_train['annual_inc']\nX_train['dti_*_annual_inc'] = X_train['dti'] * X_train['annual_inc']\n\n","de482c81":"#X_test['tot_coll_amt%_annual_inc'] = X_test['tot_coll_amt'] \/ X_test['annual_inc']\nX_test['tot_coll_amt*_annual_inc'] = X_test['tot_coll_amt'] * X_test['annual_inc']\n\n#X_test['tot_cur_bal%_annual_inc'] = X_test['tot_cur_bal'] \/ X_test['annual_inc']\nX_test['tot_cur_bal*_annual_inc'] = X_test['tot_cur_bal'] * X_test['annual_inc']\n\nX_test['tot_coll_amt%_loan_amnt'] = X_test['tot_coll_amt'] \/ X_test['loan_amnt']\nX_test['tot_coll_amt*_loan_amnt'] = X_test['tot_coll_amt'] * X_test['loan_amnt']\n\nX_test['tot_cur_bal%_loan_amnt'] = X_test['tot_cur_bal'] \/ X_test['loan_amnt']\nX_test['tot_cur_bal*_loan_amnt'] = X_test['tot_cur_bal'] * X_test['loan_amnt']\n\n#X_test['loan_amnt_%_annual_inc'] = X_test['loan_amnt'] \/ X_test['annual_inc']\nX_test['loan_amnt_*_annual_inc'] = X_test['loan_amnt'] * X_test['annual_inc']\n\nX_test['dti_%_annual_inc'] = X_test['dti'] \/ X_test['annual_inc']\nX_test['dti_*_annual_inc'] = X_test['dti'] * X_test['annual_inc']\n\nX_test['grade+subg'] = X_test['grade'] + X_test['sub_grade']\n#X_test['grade*subg'] = X_test['grade'] * X_test['sub_grade']\n# X_test['grade_subg'] = X_test['sub_grade'] - X_test['grade']\n# X_test['grade%subg'] = X_test['sub_grade'] % X_test['grade']","ef883bba":"#null\u30d5\u30e9\u30b0\nX_train['emp_length_nullflg'] = X_train['emp_length'].apply(lambda x: 0 if not pd.isnull(x) else 1)\nX_train['emp_title_nullflg'] = X_train['emp_title'].apply(lambda x: 0 if not pd.isnull(x) else 1)\nX_train['title_nullflg'] = X_train['title'].apply(lambda x: 0 if not pd.isnull(x) else 1)\n\nX_test['emp_length_nullflg'] = X_test['emp_length'].apply(lambda x: 0 if not pd.isnull(x) else 1)\nX_test['emp_title_nullflg'] = X_test['emp_title'].apply(lambda x: 0 if not pd.isnull(x) else 1)\nX_test['title_nullflg'] = X_test['title'].apply(lambda x: 0 if not pd.isnull(x) else 1)\n","a8272d34":"# #\u52b9\u304d\u305d\u3046\u306aflg\n# X_train['debt_consolidation_flg'] = X_train['title'].apply(lambda x: 1 if x == 'debt_consolidation' else '0')\n# X_test['debt_consolidation_flg'] = X_test['title'].apply(lambda x: 1 if x == 'debt_consolidation' else '0')","a778eb4c":"# zip_code \u30921\u6587\u5b57\uff08\u5dde\u306e\u610f\uff09\u306b\u5909\u63db\uff08\u938c\u7530\u3055\u3093\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3059\uff09","aad59a6a":"X_train['zip_code'] = X_train['zip_code'].str[:1]\nX_test['zip_code'] = X_test['zip_code'].str[:1]\n","97349841":"X_train['zip_code'] = X_train['zip_code'].astype(\"object\")\nX_test['zip_code'] = X_test['zip_code'].astype(\"object\")","9721eeda":"X_train['zip_code']","4c1eabe7":"X_train['emp_title'] = X_train['emp_title'].str[:4]\nX_test['emp_title'] = X_test['emp_title'].str[:4]","8b7fb269":"X_train['emp_title'].value_counts().head(100)","72be4f16":"X_train['emp_title'] = X_train['emp_title'].astype(\"object\")\nX_test['emp_title'] = X_test['emp_title'].astype(\"object\")","e96c221f":"X_train_na = (X_train.isnull().sum() \/ len(X_train)) * 100\nX_train_na = X_train_na.drop(X_train_na[X_train_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :X_train_na})\nmissing_data.head(50)","fddb49cb":"X_test_na = (X_test.isnull().sum() \/ len(X_test)) * 100\nX_test_na = X_test_na.drop(X_test_na[X_test_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :X_test_na})\nmissing_data.head(50)","98d90a4c":"X_train.fillna(X_train.median(), inplace=True)\nX_test.fillna(X_train.median(), inplace=True)","d416d90b":"X_train_na = (X_train.isnull().sum() \/ len(X_train)) * 100\nX_train_na = X_train_na.drop(X_train_na[X_train_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :X_train_na})\nmissing_data.head(50)","2d84d584":"X_train[\"emp_title\"] = X_train[\"emp_title\"].fillna(\"None\")\nX_test[\"emp_title\"] = X_test[\"emp_title\"].fillna(\"None\")\n\nX_train[\"title\"] = X_train[\"title\"].fillna(\"None\")\nX_test[\"title\"] = X_test[\"title\"].fillna(\"None\")","9290e037":"X_test_na = (X_test.isnull().sum() \/ len(X_test)) * 100\nX_test_na = X_test_na.drop(X_test_na[X_test_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :X_test_na})\nmissing_data.head(50)","e16753f8":"cats = []\nothers = []\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \n    else:\n        others.append(col)","d6876630":"cats","2a437e40":"oe_cols = ['emp_title',\n 'home_ownership',\n 'title',\n 'zip_code',\n 'addr_state',\n 'initial_list_status',\n 'application_type']","53ecc2bd":"oe = OrdinalEncoder(cols=oe_cols, return_df=False)\n\nX_train[oe_cols] = oe.fit_transform(X_train[oe_cols])\nX_test[oe_cols] = oe.transform(X_test[oe_cols])","b6c30dd6":"X_train","7b9c79a5":"X_test","d8738ad1":"X_train.describe()","05f10602":"X_test.describe()","10a849b3":"'''\n#emp_title \u306e\u4e2d\u306b\u3001train\u306b\u306a\u304f\u3066\u3001test \u306b\u3042\u308b\u30c7\u30fc\u30bf\u304c\u3042\u308b\n#cols = ['grade', 'sub_grade','emp_title','home_ownership','title','zip_code','addr_state','initial_list_status','application_type','emp_length_nullflg', 'emp_title_nullflg', 'title_nullflg']\ncols = ['grade', 'sub_grade','home_ownership','title','zip_code','addr_state','initial_list_status','application_type']\n\ntarget = 'loan_condition'\n\nfor col in cols:\n    X_temp = pd.concat([X_train, y_train], axis=1)\n    # X_test\u306fX_train\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    summary = X_temp.groupby([col])[target].mean()\n    enc_test = X_test[col].map(summary) \n\n    \n    # X_train\u306e\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092oof\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\n\n    enc_train = Series(np.zeros(len(X_train)), index=X_train.index)\n\n    for i, (train_ix, val_ix) in enumerate((skf.split(X_train, y_train))):\n        X_train_, _ = X_temp.iloc[train_ix], y_train.iloc[train_ix]\n        X_val, _ = X_temp.iloc[val_ix], y_train.iloc[val_ix]\n\n        summary = X_train_.groupby([col])[target].mean()\n        enc_train.iloc[val_ix] = X_val[col].map(summary)\n    \n    X_train[col] = enc_train\n    X_test[col] = enc_test\n'''","a71737b7":"#https:\/\/qiita.com\/rshinji\/items\/80e844beab57c9726b12\nclass TargetEncoding_ws(object):\n    \"\"\"\n    DF\u3068\u5909\u63db\u3057\u305f\u3044\u30ab\u30e9\u30e0\u30ea\u30b9\u30c8\u3001target\u3092\u5f15\u6570\u3068\u3057\u3066\u3001Target Encoding with Smoothing\u3092\u884c\u3046\n    \u5f15\u6570\n    dataframe : DF\u5168\u4f53 (pd.DataFrame)\n    target : \u76ee\u7684\u5909\u6570\u306e\u30ab\u30e9\u30e0 (np.ndarray or np.Series)\n    list_cols : \u5909\u63db\u3057\u305f\u3044\u30ab\u30e9\u30e0\u30ea\u30b9\u30c8 (list[str])\n    k : smoothing\u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf (int)\n    impute : \u672a\u77e5\u306e\u30ab\u30c6\u30b4\u30ea\u306b\u5e73\u5747\u3092\u5165\u308c\u308b\u304b (boolean)\n    \"\"\"\n    def __init__(self, list_cols, k=100, impute=True):\n        self.df = None\n        self.target = None\n        self.list_cols = list_cols\n        self.k = k\n        self.impute = impute\n        self.target_map = {}\n        self.target_mean = None\n\n    def sigmoid(self, x, k):\n        return 1 \/ (1 + np.exp(- x \/ k))\n\n    def fit_univariate(self, target, col):\n        \"\"\"\n        \u4e00\u3064\u306e\u5909\u6570\u306b\u5bfe\u3059\u308bTarget_Encoding\n        col : TargetEncoding\u3057\u305f\u3044\u5909\u6570\u540d\n        \"\"\"\n        df = self.df.copy()\n        k = self.k\n        df[\"target\"] = target\n        n_i = df.groupby(col).count()[\"target\"]\n\n        lambda_n_i = self.sigmoid(n_i, k)\n        uni_map = df.groupby(col).mean()[\"target\"]\n\n        return lambda_n_i * df.loc[:, \"target\"].mean() + (1 - lambda_n_i) * uni_map\n\n    def fit(self, data, target):\n        \"\"\"\n        \u8907\u6570\u30ab\u30e9\u30e0\u306b\u3082\u5bfe\u5fdc\u3057\u305fTargetEncoding\n        \"\"\"\n        self.df = data.copy()\n        self.target = target\n\n        if self.impute == True:\n            self.target_mean = target.mean()\n\n        #\u5404\u30ab\u30e9\u30e0\u306emap\u3092\u4fdd\u5b58\n        for col in list_cols:\n            self.target_map[col] = self.fit_univariate(target, col)\n\n    def transform(self, x):\n        list_cols = self.list_cols\n        x_d = x.copy()\n        for col in list_cols:\n            x_d.loc[:, col] = x_d.loc[:, col].map(self.target_map[col])\n\n            #impute\n            if self.impute == True:\n                x_d.loc[:, col] = np.where(x_d.loc[:, col].isnull(), self.target_mean, x_d.loc[:, col])\n\n        return x_d","b9fbb81c":"cats","3c27340e":"list_cols =[\n 'emp_title',\n 'home_ownership',\n 'title',\n 'zip_code',\n 'addr_state',\n 'initial_list_status',\n 'application_type']\n\nte = TargetEncoding_ws(list_cols=list_cols, k=200, impute=True)\nte.fit(X_train, y_train)\n\nX_train = te.transform(X_train)\nX_test = te.transform(X_test)\n\ndisplay(te.transform(X_train).head())\ndisplay(te.transform(X_test).head())","e24ad21b":"X_train.describe()","a92ee401":"X_test.describe()","e1bf0288":"# X_train.fillna(-9999, inplace=True)\n# X_test.fillna(-9999, inplace=True)","3a542ff5":"import seaborn as sns\nX_train_corr = X_train.corr()\nprint(X_train_corr)\nsns.heatmap(X_train_corr, vmax=1, vmin=-1, center=0, cmap = 'seismic')","7edb7162":"import seaborn as sns\nX_test_corr = X_test.corr()\nprint(X_train_corr)\nsns.heatmap(X_train_corr, vmax=1, vmin=-1, center=0, cmap = 'seismic')","97b1db9e":"for i in X_train.columns:\n    print(i, X_train[i].nunique(), X_train[i].dtype)","699d21af":"from pylab import rcParams\nrcParams['figure.figsize'] = 20,20 # \u30b0\u30e9\u30d5\u306e\u30b5\u30a4\u30ba\u3092\u5927\u304d\u304f\u3059\u308b\nX_train.hist(bins=20);\nplt.tight_layout() # \u30b0\u30e9\u30d5\u540c\u58eb\u304c\u91cd\u306a\u3089\u306a\u3044\u3088\u3046\u306b\u3059\u308b\nplt.show()","510371aa":"from pylab import rcParams\nrcParams['figure.figsize'] = 20,20 # \u30b0\u30e9\u30d5\u306e\u30b5\u30a4\u30ba\u3092\u5927\u304d\u304f\u3059\u308b\nX_test.hist(bins=20);\nplt.tight_layout() # \u30b0\u30e9\u30d5\u540c\u58eb\u304c\u91cd\u306a\u3089\u306a\u3044\u3088\u3046\u306b\u3059\u308b\nplt.show()","15e5c9be":"\n# CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\u3002\u5c64\u5316\u62bd\u51fa\u3067\u826f\u3044\u304b\u306f\u5225\u9014\u3088\u304f\u8003\u3048\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\u21d2yes\nscores = []\nscores2 = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    #\n    #clf = GradientBoostingClassifier(n_estimators=85, \n    #                                learning_rate=0.25,\n    #                                #max_depth=2, #added at version 2\n    #                                random_state=1)\n    #\n    lgbmc = LGBMClassifier(objective='binary',\n                         n_estimators=10000, \n                         class_weight = 'balanced',\n                         #learning_rate=0.3, \n                         #max_depth=2,\n                         #subsample= 0.8,\n                         #bagging_fraction=0.7,\n                         #feature_fraction=0.7,\n                         importance_type='gain', \n                         random_state=71, \n                         silent = 1,\n                         n_jobs=-1)\n    #bagging_fraction': 0.7, 'feature_fraction': 0.7, 'learning_rate': 0.20000000000000004, 'max_depth': 2} 0.8161721235129574\n    \n    #clf.fit(X_train_, y_train_)\n    lgbmc.fit(X_train_, y_train_, early_stopping_rounds=20, eval_metric='binary_logloss', verbose=100, eval_set=[(X_val, y_val)])\n    # verbose_eval=False\n    \n    y_pred = lgbmc.predict_proba(X_val)[:,1]\n    score2 = roc_auc_score(y_train_, lgbmc.predict_proba(X_train_)[:,1])\n    scores2.append(score2)\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n\n    print('===================================================')\n    print('train CV Score of Fold_%d is %f' % (i, score2))\n    print('---------------------------------------------------')\n    print('val CV Score of Fold_%d is %f' % (i, score))\n    print('---------------------------------------------------')\n    print('diff', score - score2)\n    print('===================================================')\n","1c852bce":"# from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\n# # CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\u3002\u5c64\u5316\u62bd\u51fa\u3067\u826f\u3044\u304b\u306f\u5225\u9014\u3088\u304f\u8003\u3048\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\u2192train \u306b\u306f\u306a\u304f\u3066\u3001test\u306b\u306fID\u306e\u304a\u5ba2\u3055\u3093\u304c\u5b58\u5728\u3059\u308b\n# scores = []\n# scores2 = []\n\n# groups = X_train.addr_state.values\n# gkf = GroupKFold(n_splits=5)\n# #skf = StratifiedKFold(n_splits=3, random_state=71, shuffle=True)\n\n# for i, (train_ix, test_ix) in tqdm(enumerate(gkf.split(X_train, y_train, groups))):\n#     X_train_, y_train_, groups_train_ = X_train.iloc[train_ix], y_train.iloc[train_ix], groups[train_ix]\n#     X_val, y_val, group_val = X_train.iloc[test_ix], y_train.iloc[test_ix], groups[test_ix]\n    \n#     '''\n#     clf = GradientBoostingClassifier(n_estimators=85, \n#                                     learning_rate=0.25,\n#                                     #max_depth=2, #added at version 2\n#                                     random_state=1)\n#     '''\n#     lgbmc = LGBMClassifier(objective='binary',\n#                          n_estimators=10000, \n#                          boosting_type='gbdt',\n#                          class_weight = 'balanced',\n#                          #learning_rate=0.3, \n#                          #subsample= 0.8,\n#                          #bagging_fraction=0.7,\n#                          #feature_fraction=0.7,\n#                          importance_type='gain', \n#                          random_state=71, \n#                          silent = 1,\n#                          n_jobs=-1)\n    \n#     #bagging_fraction': 0.7, 'feature_fraction': 0.7, 'learning_rate': 0.20000000000000004, 'max_depth': 2} 0.8161721235129574\n    \n#     #clf.fit(X_train_, y_train_)\n#     lgbmc.fit(X_train_, y_train_, early_stopping_rounds=20, eval_metric='binary_logloss', verbose=200, eval_set=[(X_val, y_val)])\n#     # verbose_eval=False\n    \n#     y_pred = lgbmc.predict_proba(X_val)[:,1]\n#     score2 = roc_auc_score(y_train_, lgbmc.predict_proba(X_train_)[:,1])\n#     scores2.append(score2)\n#     score = roc_auc_score(y_val, y_pred)\n#     scores.append(score)\n\n#     print('===================================================')\n#     print('train CV Score of Fold_%d is %f' % (i, score2))\n#     print('---------------------------------------------------')\n#     print('val CV Score of Fold_%d is %f' % (i, score))\n#     print('---------------------------------------------------')\n#     print('diff', score - score2)\n#     print('===================================================')\n","f91091de":"print('val avg:', np.mean(scores))\nprint(scores)\nprint('=============================')\nprint('train avg:', np.mean(scores2))\nprint(scores2)\nprint('=============================')\nprint('diff',np.mean(scores) - np.mean(scores2))","066be4a4":"# Plot feature importance\n#importances = clf.feature_importance(importance_type='gain')\n\n# Initialize an empty array to hold feature importances\nfeature_importances = np.zeros(X_train.shape[1])\n\nimportances = lgbmc.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n\nfeat_labels = X_train.columns[0:]\nfor f in range(X_train.shape[1]):\n    IMPORTANCES_LIST = pd.DataFrame([[\"%2d) %-*s %f\" % (f +1, 30, feat_labels[indices[f]], importances[indices[f]])]] )\n#    IMPORTANCES_LIST.to_csv('.\/data\/feature_importances.csv', mode='a', header=False, index=False)\n    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]], importances[indices[f]]))","958e1988":"fig, ax = plt.subplots(figsize=(20, 10))\nlgb.plot_importance(lgbmc, max_num_features=50, ax=ax, importance_type='gain')","c1e741bf":"\nfrom hyperopt import fmin, tpe, hp, rand, Trials\n\ndef objective(space):\n    hscores = []\n\n    skf = StratifiedKFold(n_splits=3, random_state=71, shuffle=True)\n\n    for i, (train_ix, test_ix) in enumerate(tqdm(skf.split(X_train, y_train))):\n        X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n        X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n        \n        clf = LGBMClassifier(n_estimators=9999, random_state=71, class_weight = 'balanced', importance_type='gain', **space) \n\n        clf.fit(X_train_, y_train_, early_stopping_rounds=10, eval_metric='auc', verbose=200, eval_set=[(X_val, y_val)])\n        y_pred = clf.predict_proba(X_val)[:,1]\n        score = roc_auc_score(y_val, y_pred)\n        hscores.append(score)\n        \n    hscores = np.array(hscores)\n    print(hscores.mean())\n    \n\n    return -hscores.mean()\n","b4040880":"\nspace ={\n        #'max_depth': hp.choice('max_depth', np.arange(3, 10, dtype=int)),\n        'num_leaves': hp.choice('num_leaves', np.linspace(10, 200, 50, dtype=int)),\n        'subsample': hp.uniform ('subsample', 0.8, 1),\n        'learning_rate' : hp.quniform('learning_rate', 0.1, 0.5, 0.05),\n        'colsample_bytree' : hp.quniform('colsample_bytree', 0.7, 1, 0.05)\n    }\n","4e4e6cd6":"\ntrials = Trials()\n\nbest = fmin(fn=objective,\n              space=space, \n              algo=tpe.suggest,\n              max_evals=20, \n              trials=trials, \n              rstate=np.random.RandomState(71) \n             )\n","7caef88d":"best_model = LGBMClassifier(**best)","085fe98d":"trials.best_trial['result']","f14791d2":"ho_best = - pd.Series(trials.losses()).min()","d7a93fca":"ho_best","ade790ac":"print(best)\n#{'colsample_bytree': 0.8, 'learning_rate': 0.1, 'num_leaves': 10, 'subsample': 0.9929417385040324} \n#\u21d2num_leaves \u304c10\u306b\u306a\u308b\u306e\u306f\u904e\u5b66\u7fd2\u306e\u305b\u3044\u304b","daef04fa":"# # \u5168\u30c7\u30fc\u30bf\u3067\u518d\u5b66\u7fd2\u3057\u3001test\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u3059\u308b\n# lgbmc.fit(X_train, y_train)\n\n# y_pred = lgbmc.predict_proba(X_test)[:,1]\n","dc88ce65":"if ho_best <= np.mean(scores):\n    # \u5168\u30c7\u30fc\u30bf\u3067\u518d\u5b66\u7fd2\u3057\u3001test\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u3059\u308b\n    lgbmc.fit(X_train, y_train)\n    y_pred = lgbmc.predict_proba(X_test)[:,1]\nelse:\n    best_model.fit(X_train, y_train)\n    y_pred = best_model.predict_proba(X_test)[:,1]","dbb0c356":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\n# \u3053\u3061\u3089\u3082\u30b9\u30e0\u30fc\u30ba\u306a\u9032\u884c\u306e\u305f\u3081\u306b20\u5206\u306e\uff11\u306b\u9593\u5f15\u3044\u3066\u3044\u307e\u3059\u304c\u3001\u672c\u756a\u3067\u306f\"skiprows=lambda x: x%20!=0\"\u3092\u524a\u9664\u3057\u3066\u7528\u3044\u3066\u304f\u3060\u3055\u3044\u3002\nsubmission = pd.read_csv('\/kaggle\/input\/homework-for-students3\/sample_submission.csv')\nsubmission.loan_condition = y_pred\nsubmission.to_csv('.\/submission.csv', index=False)","14b72f71":"submission.head()","d086793c":"# \u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f","c961d2da":"#","f2ebf631":"# \u7279\u5fb4\u91cf\u751f\u6210","601e9db9":"# \u4e88\u6e2c","20959e4e":"# \u30d1\u30bf\u30fc\u30f3\u306e\u7570\u306a\u308b\u30c7\u30fc\u30bf\u306e\u524a\u9664","ffec6e03":"# \u6700\u9069\u5316","21b46dda":"# train \u306b\u3042\u3063\u3066 test \u306b\u306a\u3044\u3082\u306e\u3002\u3082\u3057\u304f\u306f\u3001test \u306b\u3042\u3063\u3066\u3001train \u306b\u306a\u3044\u3082\u306e\u3092\u524a\u9664\u3059\u308b","b57ffab6":"# \u30e2\u30c7\u30eb\u751f\u6210","8f7908bd":"# \u4e0d\u8981\u3068\u601d\u308f\u308c\u308b\u5217\u306e\u524a\u9664","00df6ad5":"# \u9806\u5e8f\u6027\u306b\u610f\u5473\u304c\u3042\u308b\u30ab\u30c6\u30b4\u30ea\u30c7\u30fc\u30bf\u306e\u6570\u5024\u5909\u63db","f333d5ec":"# ordinal encoding","2dbf25fe":"# \u30bf\u30fc\u30b2\u30c3\u30c8\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0","6add3f53":"# X_train, y_train, X_test\u306b\u5206\u5272"}}