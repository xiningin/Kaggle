{"cell_type":{"24e66ff8":"code","61654d68":"code","f9ee0b56":"code","960e9fe9":"code","c761480f":"code","05105e4a":"code","38d8c3f0":"code","a0bcc9d8":"code","b02b9e69":"code","1f53928c":"code","c1b2f20a":"code","9b6ff511":"code","b0cb6dc7":"code","9fa9564f":"code","728c97ba":"code","f655cc65":"code","19154180":"code","edaa6227":"code","6547df15":"code","f0e73ac3":"code","ec44491f":"code","139e57cc":"code","b7521fa7":"code","eb49b00c":"code","dd010a07":"code","8d953c42":"code","fdfad2c2":"code","5aafa15b":"code","49e41198":"code","48dcfc08":"markdown","8b126a47":"markdown","aba837c6":"markdown","aacf2c4a":"markdown","c01be5e6":"markdown","bea21a7a":"markdown","37ac40bf":"markdown","d4023543":"markdown","9dfd8c6b":"markdown"},"source":{"24e66ff8":"import numpy as np\nfrom gensim.models import Word2Vec\nfrom annoy import AnnoyIndex\nfrom functools import reduce","61654d68":"import os","f9ee0b56":"os.listdir('\/kaggle\/input')","960e9fe9":"with open('\/kaggle\/input\/sessions', 'r') as f:\n    sessions = [line[:-1].split(' ') for line in f]","c761480f":"model = Word2Vec(sessions, min_count=5, window=5, workers=8, size=100, iter=20)","05105e4a":"# create a quick mapping from product to how many sessions it appeared in\n# proxy for popularity \ni_to_num_sessions = {}\nfor session in sessions:\n    for i in session:\n        i_to_num_sessions[i] = i_to_num_sessions.get(i, 0) + 1","38d8c3f0":"with open('\/kaggle\/input\/id_to_title', 'r') as f:\n    id_to_title = [line[:-1] for line in f]","a0bcc9d8":"# split a title by space and make lowercase\ndef tokenize(title):\n    return title.lower().split(\" \")","b02b9e69":"available_product_ids = set(model.wv.index2word)\ninverted_index = {}\n\nfor i, title in enumerate(id_to_title):\n    if i % 100000 == 0: print(i)\n    if str(i) in available_product_ids:\n        tokens = tokenize(title)\n        for token in tokens:\n            inverted_index[token] = inverted_index.get(token, set())\n            inverted_index[token].add(i)","1f53928c":"findTitlesLike = lambda words: sorted(list(map(lambda i:(i, id_to_title[i]), list(reduce(lambda acc, word: acc.intersection(inverted_index.get(word, set())), words, inverted_index[words[0]])))), key=lambda x: -1 * i_to_num_sessions[str(x[0])])[:10] \n\ngetSimilarProducts = lambda i: list(map(lambda p: (p, id_to_title[int(p[0])]), model.wv.similar_by_word(str(i))))\n","c1b2f20a":"findTitlesLike(['macbook', 'pro', 'retina', '256gb'])[:5]","9b6ff511":"getSimilarProducts(497370)[:5]","b0cb6dc7":"findTitlesLike(['nintendo', 'switch', 'console'])[:5]","9fa9564f":"getSimilarProducts(813190)[:5]","728c97ba":"findTitlesLike(['instant', 'pot'])","f655cc65":"getSimilarProducts(925724)[:5]","19154180":"findTitlesLike(['harry', 'potter', 'deathly', 'hallows'])[:5]","edaa6227":"getSimilarProducts(102115)[:5]","6547df15":"findTitlesLike(['airpods'])[:5]","f0e73ac3":"getSimilarProducts(322055)[:5] # airpods headphones","ec44491f":"getSimilarProducts(152574)[:5] # airpods case","139e57cc":"import time","b7521fa7":"start = time.time()\n\nfor i in range(100):\n    pid = model.wv.index2word[i]\n    model.wv.similar_by_word(pid)\nend = time.time()\n\nprint(end - start)","eb49b00c":"ai = AnnoyIndex(100)","dd010a07":"for i, v in enumerate(model.wv.vectors):\n    try:\n        ai.add_item(int(model.wv.index2word[i]), v)\n    except:\n        print(model.wv.index2word[i])","8d953c42":"ai.build(4)","fdfad2c2":"findTitlesLike(['nintendo', 'switch', 'console'])[:5]","5aafa15b":"[(i, id_to_title[i]) for i in ai.get_nns_by_item(813190, 5)]","49e41198":"start = time.time()\n\nfor i in range(10, 45000):\n    pid = model.wv.index2word[i]\n    ai.get_nns_by_item(int(pid), 5)\nend = time.time()\n\nprint(end - start)","48dcfc08":"## **How fast can we perform this nearest neighbors calculation?**","8b126a47":"## **Import a few things**\n#### numpy is a numerical python library for doing fast matrix math in C instead of in python\n#### gensim is a NLP library with lots of useful stuff including a simple api for word2vec\n#### annoy is a library for super fast approximate nearest neighbors calculations on a memory mapped index","aba837c6":"## **So being able to find similar products like this is cool, but relatively slow, especially as you scale to production sized data** Let's build our annoy index to see if we can speed that up","aacf2c4a":"## **Let's create an inverted index so that we can find products quickly by their titles**\n### Try searching for products by title by performing a scan of `id_to_title` and see how long it takes... I dare you","c01be5e6":"## **Train the word2vec model on the session data**","bea21a7a":"## **100 vs 45,000 so much faster!!**","37ac40bf":"## **Define our methods for finding products by title using our inverted index and finding by the product vector**\n#### very sorry for the long lambda","d4023543":"## **Load in product titles**","9dfd8c6b":"## **Load in the user sessions**"}}