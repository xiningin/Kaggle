{"cell_type":{"1619b7f2":"code","f818555e":"code","71dd5b52":"code","93e10fc8":"code","f7b2f07a":"code","0dfd2060":"code","522e0553":"code","605e3f2e":"code","5ceb4aca":"markdown"},"source":{"1619b7f2":"%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport numpy as np\nimport pandas as pd    \nimport matplotlib.pyplot as plt\nfrom numpy import loadtxt\nimport xgboost as xgb\nfrom lightgbm import plot_metric\n    \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\nfrom sklearn import metrics\nimport itertools\nfrom sklearn.preprocessing import RobustScaler\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\n\nfill_mean = lambda x: x.fillna(x.mean())\n\ndef convert_dummy(df, feature, rank=0):\n    '''Xgboost doesn't have method to process categorical features\n    we should use dummy-encode'''\n    pos = pd.get_dummies(df[feature], prefix=feature)\n    mode = df[feature].value_counts().index[rank]\n    biggest = feature + '_' + str(mode)\n    pos.drop([biggest],axis=1,inplace=True)\n    df.drop([feature],axis=1,inplace=True)\n    df = df.join(pos)\n    return df","f818555e":"train['Age'] = train['Age'].groupby(train['Pclass']).apply(fill_mean)\ntest['Age'] = test['Age'].groupby(test['Pclass']).apply(fill_mean)\n\ntrain['Fare'] = train['Fare'].groupby(train['Pclass']).apply(fill_mean)\ntest['Fare'] = test['Fare'].groupby(test['Pclass']).apply(fill_mean)\n\ntrain['Fare'] = np.log1p(train['Fare'])\ntest['Fare'] = np.log1p(test['Fare'])\n\ntrain['Deck']=train['Cabin'].str[0]\ntest['Deck']=test['Cabin'].str[0]\ntrain['Deck'].fillna('M', inplace=True)\ntest['Deck'].fillna('M', inplace=True)\ntrain['Deck'].replace(['G','T'],'M', inplace=True)\ntest['Deck'].replace(['G','T'],'M', inplace=True)\ntrain['Deck'].unique()\ntest['Deck'].unique()\n\ntrain = convert_dummy(train,'Deck')\ntest = convert_dummy(test,'Deck')\n\ntrain['Sex'] = train['Sex'].replace(['female','male'],[0,1])\ntest['Sex'] = test['Sex'].replace(['female','male'],[0,1])\n\ntrain = convert_dummy(train,'Pclass')\ntest = convert_dummy(test,'Pclass')\n\ntrain.loc[train['SibSp'] > 0, 'SibSp'] = 1\ntest.loc[test['SibSp'] > 0, 'SibSp'] = 1\n\ntrain.loc[train['Parch'] > 0, 'Parch'] = 1\ntest.loc[test['Parch'] > 0, 'Parch'] = 1\n\ntrain = convert_dummy(train,'Embarked')\ntest = convert_dummy(test,'Embarked')\n\ny = train['Survived']\nfeatures = ['Pclass_1', 'Pclass_2','Sex', 'Age', 'SibSp','Parch','Fare', 'Embarked_C', 'Embarked_Q', 'Deck_A', 'Deck_B',\n 'Deck_C', 'Deck_D', 'Deck_E', 'Deck_F']","71dd5b52":"def robust_transfer(df):\n    Scaler = RobustScaler().fit(df) \n    newdf = Scaler.transform(df)\n    df0 = pd.DataFrame(newdf,columns = df.columns)\n    return df0\n\ntrain0 = robust_transfer(train[features])\ntest0 = robust_transfer(test[features])","93e10fc8":"x_train, x_val, y_train, y_val = train_test_split(train0, y, \n                                                  stratify=y, \n                                                  test_size=0.3,\n                                                  random_state=2020)\n\nmodel = xgb.XGBClassifier(n_estimators = 500,\n                          learning_rate = 0.05,   \n                          objective = 'binary:logistic',\n                          max_depth=8,\n                          min_child_weight=1, # \u53f6\u5b50\u4e0a\u7684\u6700\u5c0f\u6837\u672c\u6570\n                          colsample_bytree=0.8, \n                          subsample=0.8,\n                          seed=64,\n                          verbose_eval = 10)\n\nmodel.fit(x_train, y_train,\n          verbose=True,\n          eval_set=[(x_train, y_train), (x_val, y_val)],\n          eval_metric='error',\n          early_stopping_rounds = 20)\n\nevals_result = model.evals_result()\nax = plot_metric(evals_result, metric = 'error')\nplt.title('Xgboost Learning Curve')\nplt.show()\n\ny_val_pred = model.predict(x_val)\ny_test_pred = model.predict(test0)\n\nval_acc = metrics.accuracy_score(y_val, y_val_pred)\nprint('Out of folds accuracy_score is {:.4f}'.format(val_acc))","f7b2f07a":"train.to_csv('train1.csv',index = False)\ntest.to_csv('test1.csv',index = False)\nsubmission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': y_test_pred})\nsubmission.to_csv('submission.csv',index = False)\nsubmission.head(10)","0dfd2060":"fig,ax = plt.subplots(figsize=(8,7))\nxgb.plot_importance(model,\n                ax=ax,\n                height=0.5).set(xlabel='feature importance',\n                                         title='',\n                                         ylabel='feature')","522e0553":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    '''    \n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    '''\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","605e3f2e":"plt.style.use('seaborn-white')\nclass_names = ['0','1']\nplot_confusion_matrix(confusion_matrix(y_val, y_val_pred),classes=class_names, normalize=True, \n                      title='Normalized Confusion Matrix: Xgboost')","5ceb4aca":"# Titanic: FE + Xgboost\n\n[Xiao Song](https:\/\/xsong.ltd\/en)\n\n[Data URL](https:\/\/www.kaggle.com\/c\/titanic\/data)"}}