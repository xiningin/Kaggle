{"cell_type":{"cf6089b6":"code","d0f693da":"code","b20a1303":"code","f5434e4e":"code","37d988c3":"code","7c669746":"code","c4a9d7fd":"code","ae2d6ed9":"code","4c6db956":"code","7c44a866":"code","81968b60":"code","1cd0956e":"code","8af4089e":"code","eaee681a":"code","073c3be1":"code","a23d4c66":"code","ec5025cf":"code","eb3de0ee":"code","0df0ca77":"code","e03d3630":"code","2d4b75f6":"code","ec85dc73":"code","047c09c8":"code","97f6ca66":"code","f3f8bec0":"code","b6eb6220":"code","55ad9b70":"code","f96ec595":"code","7297d1d7":"code","6c929e52":"code","96576438":"code","64850655":"code","1696a285":"code","6e1dbf85":"code","ef3dd865":"code","737f3cbb":"code","13089da5":"code","eb1d38c4":"code","1aea8b2e":"code","1ca1bf1a":"code","13663073":"code","01d05010":"code","364b25ac":"code","956678c0":"code","9c35b2ee":"code","cf714d40":"code","c544f59d":"code","9efedd44":"code","0397dad0":"code","874d1074":"code","0d019fa9":"code","cd160431":"code","c9d06135":"code","4fa270ad":"code","c48a37e8":"code","b1fe1ee4":"code","08dbd83c":"markdown","82fc4e80":"markdown","8b559c26":"markdown","dd54e93d":"markdown","41e52ae9":"markdown","4881a3f5":"markdown","145e5724":"markdown","3756dede":"markdown","c64f82b7":"markdown","853d74f4":"markdown","7226ef55":"markdown","48df5312":"markdown","3b11808f":"markdown","b2314b43":"markdown","04e04c23":"markdown","bee76483":"markdown","1e21e73f":"markdown","e0342697":"markdown","f9b37aaf":"markdown","591cda27":"markdown","d23eeda4":"markdown","afa48ebe":"markdown","0fbcf7c2":"markdown","abf97b7e":"markdown","a496f50c":"markdown","2e99d996":"markdown","f4dde758":"markdown","c82ec3f2":"markdown"},"source":{"cf6089b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d0f693da":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom statsmodels.tsa.holtwinters import SimpleExpSmoothing\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import kpss\nfrom scipy.stats import boxcox\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n\n\npd.set_option('display.max_columns',1000)\npd.set_option('display.max_rows',1000)\n\nitems_df = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv\")\nsample_submission_df = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\nitem_categories_df = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv\")\nsales_train_df = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv\")\nshops_df = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv\")\n","b20a1303":"items_df.head()","f5434e4e":"items_df.shape","37d988c3":"items_df[items_df.duplicated([\"item_name\"])]","7c669746":"shops_df.head()","c4a9d7fd":"shops_df.shape","ae2d6ed9":"#displaying the particular items available in each category.\nitems_df[items_df[\"item_category_id\"]==18]","4c6db956":"items_df.info()","7c44a866":"item_categories_df.head(10)","81968b60":"item_categories_df.shape","1cd0956e":"#Merging the dats sets of items and item categories.\nitems_df = pd.merge(items_df,item_categories_df,on = \"item_category_id\",how = \"inner\")\nitems_df.head()","8af4089e":"sales_train_df.head()","eaee681a":"sales_train_df.info()","073c3be1":"sales_train_df['date'] =  pd.to_datetime(sales_train_df['date'], format='%d.%M.%Y')\nsales_train_df.dtypes\n","a23d4c66":"#records = items_df[items_df['item_category_id'] == 40]\n\n#for index, row in records.iterrows():\n     #print(items_df['item_name'])","ec5025cf":"#Creating a column that gives the total sales of a particular item.\nsales_train_df[\"item_salevalue\"] = sales_train_df[\"item_price\"]*sales_train_df[\"item_cnt_day\"]\n#Merging the sales and shops datasets \nsales_train_df = pd.merge(sales_train_df,shops_df,on = \"shop_id\", how = \"inner\")\n#Merging the sales and items datasets \nsales_train_df = pd.merge(sales_train_df,items_df,on = \"item_id\", how = \"inner\")\n#Displaying the sales dataset that contains all the required coulmns. \nsales_train_df.head()","eb3de0ee":"shops_income = sales_train_df.groupby([\"shop_id\",\"item_category_name\"],as_index = False)[\"item_salevalue\"].sum()\nshops_income.rename(columns={'item_salevalue':'total_income'}, inplace=True)\nshops_income.sort_values(by=[\"shop_id\"],ascending=True,inplace=True)\nshops_income.head()","0df0ca77":"top_selling_item = sales_train_df.groupby([\"item_category_id\"],as_index = False)[\"item_cnt_day\"].count()\ntop_selling_item.tail(50)\ntop_selling_item.sort_values(by=[\"item_cnt_day\"],ascending=False,inplace=True)\ntop_selling_item.head()","e03d3630":"fig, ax = plt.subplots(1, 1, figsize=(20,8))\n\nsns.barplot(data=top_selling_item, x='item_category_id',y=\"item_cnt_day\")\nax.set_title('', fontweight=\"bold\", fontfamily='serif', fontsize=18)\nax.set(xlabel=\"item_category_id\", ylabel = \"item_cnt_day\")\nax.patch.set_alpha(0)\nplt.show()\n","2d4b75f6":"Top_Selling_Month  = sales_train_df.groupby([\"date_block_num\",\"item_salevalue\"],as_index = False).item_salevalue.max()\n#trade_days.sort_values(by=[\"item_salevalue\"],ascending=False,inplace=True)\nTop_Selling_Month = Top_Selling_Month.set_index('date_block_num')\nTop_Selling_Month.head()\n","ec85dc73":"Top_Selling_Month.plot(figsize=(12, 4))\nplt.legend(loc='best')\nplt.title('')\nplt.show(block=False)","047c09c8":"shops_income = sales_train_df.groupby([\"shop_id\"],as_index = False)[\"item_salevalue\"].sum()\nshops_income.rename(columns={'item_salevalue':'total_income'}, inplace=True)\nshops_income.sort_values(by=[\"total_income\"],ascending=False,inplace=True)\nshops_income.head(20)","97f6ca66":"fig, ax = plt.subplots(1, 1, figsize=(15,6))\n\nsns.barplot(data=shops_income, x='shop_id',y=\"total_income\")\nax.set_title('TOTAL Income of Shops', fontweight=\"bold\", fontfamily='serif', fontsize=18)\nax.set(xlabel=\"shop_id\", ylabel = \"total_income\")\nax.patch.set_alpha(0)\nplt.show()\n","f3f8bec0":"#shop_31 = sales_train_df[[\"date_block_num\",\"item_salevalue\"]]\nshop_31 = pd.DataFrame(sales_train_df[sales_train_df[\"shop_id\"]==31])\nshop_31 = shop_31.groupby([\"date_block_num\"],as_index = False)[\"item_salevalue\"].sum()\nshop_31.head()","b6eb6220":"shop_31.shape","55ad9b70":"shop_31.plot(figsize=(12, 4))\nplt.legend(loc='best')\nplt.title('Time Series Plot')\nplt.show(block=False)","f96ec595":"train_len = 26\ntrain = shop_31[0:train_len] # first 26 months as train set\ntest = shop_31[train_len:] # last 8 months as test set","7297d1d7":"y_hat_naive = test.copy()\ny_hat_naive['naive_forecast'] = shop_31['item_salevalue'][train_len-1]","6c929e52":"plt.figure(figsize=(12,4))\nplt.plot(train['item_salevalue'], label='Train')\nplt.plot(test['item_salevalue'], label='Test')\nplt.plot(y_hat_naive['naive_forecast'], label='Naive forecast')\nplt.legend(loc='best')\nplt.title('Naive Method')\nplt.show()","96576438":"rmse = np.sqrt(mean_squared_error(test['item_salevalue'], y_hat_naive['naive_forecast'])).round(2)\nmape = np.round(np.mean(np.abs(test['item_salevalue']-y_hat_naive['naive_forecast'])\/test['item_salevalue'])*100,2)\n\nresults = pd.DataFrame({'Method':['Naive method'], 'MAPE': [mape], 'RMSE': [rmse]})\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","64850655":"from statsmodels.tsa.holtwinters import ExponentialSmoothing\ny_hat_hwm = test.copy()\nmodel = ExponentialSmoothing(np.asarray(shop_31['item_salevalue']) ,seasonal_periods=12 ,trend='add', seasonal='mul')\nmodel_fit = model.fit(optimized=True)\nprint(model_fit.params)\ny_hat_hwm['hw_forecast'] = model_fit.forecast(8)","1696a285":"plt.figure(figsize=(12,4))\nplt.plot( train['item_salevalue'], label='Train')\nplt.plot(test['item_salevalue'], label='Test')\nplt.plot(y_hat_hwm['hw_forecast'], label='Holt Winters\\'s mulitplicative forecast')\nplt.legend(loc='best')\nplt.title('Holt Winters\\' Mulitplicative Method')\nplt.show()","6e1dbf85":"rmse = np.sqrt(mean_squared_error(test['item_salevalue'], y_hat_hwm['hw_forecast'])).round(2)\nmape = np.round(np.mean(np.abs(test['item_salevalue']-y_hat_hwm['hw_forecast'])\/test['item_salevalue'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Holt Winters\\' multiplicative method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","ef3dd865":"from statsmodels.tsa.stattools import adfuller\nadf_test = adfuller(shop_31['item_salevalue'])\n\nprint('ADF Statistic: %f' % adf_test[0])\nprint('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\nprint('p-value: %f' % adf_test[1])","737f3cbb":"from statsmodels.tsa.stattools import kpss\nkpss_test = kpss(shop_31['item_salevalue'])\n\nprint('KPSS Statistic: %f' % kpss_test[0])\nprint('Critical Values @ 0.05: %.2f' % kpss_test[3]['5%'])\nprint('p-value: %f' % kpss_test[1])","13089da5":"#Performing Box-cox transformation to get the data set stationary.\nfrom scipy.stats import boxcox\nshop_31_boxcox = pd.Series(boxcox(shop_31['item_salevalue'], lmbda=0), index = shop_31.index)\n\nplt.figure(figsize=(12,4))\nplt.plot(shop_31_boxcox, label='After Box Cox tranformation')\nplt.legend(loc='best')\nplt.title('After Box Cox transform')\nplt.show()","eb1d38c4":"shop31_boxcox_diff = pd.Series(shop_31_boxcox - shop_31_boxcox.shift(), shop_31.index)\nplt.figure(figsize=(12,4))\nplt.plot(shop31_boxcox_diff, label='After Box Cox tranformation and differencing')\nplt.legend(loc='best')\nplt.title('After Box Cox transform and differencing')\nplt.show()","1aea8b2e":"shop31_boxcox_diff.dropna(inplace=True)","1ca1bf1a":"adf_test = adfuller(shop31_boxcox_diff)\n\nprint('ADF Statistic: %f' % adf_test[0])\nprint('Critical Values @ 0.05: %.2f' % adf_test[4]['5%'])\nprint('p-value: %f' % adf_test[1])","13663073":"kpss_test = kpss(shop31_boxcox_diff)\n\nprint('KPSS Statistic: %f' % kpss_test[0])\nprint('Critical Values @ 0.05: %.2f' % kpss_test[3]['5%'])\nprint('p-value: %f' % kpss_test[1])","01d05010":"plt.figure(figsize=(12,4))\nplot_acf(shop_31[\"item_salevalue\"], ax=plt.gca(), lags = 15)\nplt.show()","364b25ac":"plt.figure(figsize=(12,4))\nplot_pacf(shop_31[\"item_salevalue\"], ax=plt.gca(), lags = 15)\nplt.show()","956678c0":"train_shop31_boxcox = shop_31_boxcox[:train_len]\ntest_shop31_boxcox = shop_31_boxcox[train_len:]\ntrain_shop31_boxcox_diff = shop31_boxcox_diff[:train_len-1]\ntest_shop31_boxcox_diff = shop31_boxcox_diff[train_len-1:]","9c35b2ee":"model = ARIMA(train_shop31_boxcox_diff, order=(1, 0, 1)) \nmodel_fit = model.fit()\nprint(model_fit.params)","cf714d40":"y_hat_ar = shop31_boxcox_diff.copy()\ny_hat_ar['ar_forecast_boxcox_diff'] = model_fit.predict(shop31_boxcox_diff.index.min(), shop31_boxcox_diff.index.max())\ny_hat_ar['ar_forecast_boxcox'] = y_hat_ar['ar_forecast_boxcox_diff'].cumsum()\ny_hat_ar['ar_forecast_boxcox'] = y_hat_ar['ar_forecast_boxcox'].add(shop_31_boxcox[0])\ny_hat_ar['ar_forecast'] = np.exp(y_hat_ar['ar_forecast_boxcox'])","c544f59d":"plt.figure(figsize=(12,4))\nplt.plot(train['item_salevalue'], label='Train')\nplt.plot(test['item_salevalue'], label='Test')\nplt.plot(y_hat_ar['ar_forecast'][test.index.min():], label='Auto regression forecast')\nplt.legend(loc='best')\nplt.title('Auto Regression Method')\nplt.show()","9efedd44":"rmse = np.sqrt(mean_squared_error(test['item_salevalue'], y_hat_ar['ar_forecast'][test.index])).round(2)\nmape = np.round(np.mean(np.abs(test['item_salevalue']-y_hat_ar['ar_forecast'][test.index.min():])\/test['item_salevalue'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Autoregressive (AR) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","0397dad0":"model = ARIMA(train_shop31_boxcox_diff, order=(0, 0, 1)) \nmodel_fit = model.fit()\nprint(model_fit.params)","874d1074":"y_hat_ma = shop31_boxcox_diff.copy()\ny_hat_ma['ma_forecast_boxcox_diff'] = model_fit.predict(shop31_boxcox_diff.index.min(), shop31_boxcox_diff.index.max())\ny_hat_ma['ma_forecast_boxcox'] = y_hat_ma['ma_forecast_boxcox_diff'].cumsum()\ny_hat_ma['ma_forecast_boxcox'] = y_hat_ma['ma_forecast_boxcox'].add(shop_31_boxcox[0])\ny_hat_ma['ma_forecast'] = np.exp(y_hat_ma['ma_forecast_boxcox'])","0d019fa9":"plt.figure(figsize=(12,4))\nplt.plot(shop_31['item_salevalue'][:train_len], label='Train')\nplt.plot(shop_31['item_salevalue'][train_len:], label='Test')\nplt.plot(y_hat_ma['ma_forecast'][test.index.min():], label='Moving average forecast')\nplt.legend(loc='best')\nplt.title('Moving Average Method')\nplt.show()","cd160431":"rmse = np.sqrt(mean_squared_error(test['item_salevalue'], y_hat_ma['ma_forecast'][test.index])).round(2)\nmape = np.round(np.mean(np.abs(test['item_salevalue']-y_hat_ma['ma_forecast'][test.index.min():])\/test['item_salevalue'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Moving Average (MA) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","c9d06135":"model = SARIMAX(train_shop31_boxcox, order=(1, 0, 1), seasonal_order=(1, 0, 1, 15)) \nmodel_fit = model.fit()\nprint(model_fit.params)","4fa270ad":"y_hat_sarima = shop31_boxcox_diff.copy()\ny_hat_sarima['sarima_forecast_boxcox'] = model_fit.predict(shop_31[\"item_salevalue\"].index.min(), shop_31[\"item_salevalue\"].index.max())\ny_hat_sarima['sarima_forecast'] = np.exp(y_hat_sarima['sarima_forecast_boxcox'])","c48a37e8":"plt.figure(figsize=(12,4))\nplt.plot(train['item_salevalue'], label='Train')\nplt.plot(test['item_salevalue'], label='Test')\nplt.plot(y_hat_sarima['sarima_forecast'][test.index.min():], label='SARIMA forecast')\nplt.legend(loc='best')\nplt.title('Seasonal autoregressive integrated moving average (SARIMA) method')\nplt.show()","b1fe1ee4":"rmse = np.sqrt(mean_squared_error(test['item_salevalue'], y_hat_sarima['sarima_forecast'][test.index.min():])).round(2)\nmape = np.round(np.mean(np.abs(test['item_salevalue']-y_hat_sarima['sarima_forecast'][test.index.min():])\/test['item_salevalue'])*100,2)\n\ntempResults = pd.DataFrame({'Method':['Seasonal autoregressive integrated moving average (SARIMA) method'], 'RMSE': [rmse],'MAPE': [mape] })\nresults = pd.concat([results, tempResults])\nresults = results[['Method', 'RMSE', 'MAPE']]\nresults","08dbd83c":"#### Holt Winter's multiplicative method with trend and seasonality","82fc4e80":"#### Plotting train, test and forecast ","8b559c26":"#### RMSE and MAPE Calculations ","dd54e93d":"To perform auto-regression models, stationarity and auto_corelation are the two fundamental requirements. We will check these one by one.\n","41e52ae9":"#### Naive Method","4881a3f5":"#### Plotting train, test and forecast ","145e5724":"#### RMSE and MAPE Calculations ","3756dede":"#### Top Selling Item","c64f82b7":"It is clear that, shop no 31 has the highest income and lets perform our prediction of sales on shop 31 applying time series models.\nUsing these models, we try to predict the sales of the next month.","853d74f4":"Checking the Stationarity of the data set by Adfuller and KPSS tests.","7226ef55":"We are provided with data sets of the items and their categories , sales of the items and shops that sells the items.we will go through these data sets and merge them as required.","48df5312":"#### Plotting ACF and PACF plots.","3b11808f":"Grouping by shop id and total income and sorting the shops according to the total income.","b2314b43":"#### Train-Test Splitting","04e04c23":"#### RMSE and MAPE Calculations ","bee76483":"Objective :\n\nWe are provided with daily historical sales data of one of the largest Russian software firms - 1C Company. \n\nThe task is to forecast the total amount of products sold in every shop for the test set.We are trying to predict total sales for every product and store in the next month by applying time series algorithm.\n\n","1e21e73f":"### Auto-Regression Models","e0342697":"### MOVING AVERAGE","f9b37aaf":"Now, we will build different models and we can choose the best model based on RMSE and MAPE metrics.","591cda27":"### ARIMA Model","d23eeda4":"Checking the p-values after transformation.","afa48ebe":"#### Time Series Forecasting ","0fbcf7c2":"#### RMSE and MAPE Calculations ","abf97b7e":"#### SARIMAX ","a496f50c":"#### Plotting train, test and forecast ","2e99d996":"#### Box-cox transformation","f4dde758":"#### Top_Selling_Month","c82ec3f2":"#### RMSE and MAPE Calculations "}}