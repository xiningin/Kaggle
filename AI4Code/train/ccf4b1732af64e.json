{"cell_type":{"e4bf0747":"code","f869b53a":"code","ec12d40e":"code","ea24fb9a":"code","89de6090":"code","9e7695b9":"code","83e8b48e":"code","f9a20682":"code","30c1ded2":"code","b1d365d7":"code","3eb482b3":"code","44add1cd":"code","cf162b12":"markdown","f7f10b19":"markdown","79f242e1":"markdown","f8ffa50d":"markdown","1c1aad02":"markdown","eaab3dec":"markdown","f0f67b60":"markdown","0246c052":"markdown","d0125e7f":"markdown","03ba31df":"markdown","bab73ebd":"markdown"},"source":{"e4bf0747":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f869b53a":"raw_train = pd.read_csv('..\/input\/train.csv')\nraw_test = pd.read_csv('..\/input\/test.csv')\ntrain = raw_train.copy()\ntest = raw_test.copy()\ntrain.head()","ec12d40e":"train['Sex'] = train['Sex'].map({'male':0,'female':1})\ntest['Sex'] = test['Sex'].map({'male':0,'female':1})\n\ntrain['Embarked'] = train['Embarked'].map({'S':0,'C':1,'Q':2})\ntest['Embarked'] = test['Embarked'].map({'S':0,'C':1,'Q':2})","ea24fb9a":"train.describe()","89de6090":"print(train.info(), test.info())","9e7695b9":"train.loc[pd.isnull(train['Embarked']),'Embarked'] = train['Embarked'].median()\ntrain.loc[pd.isnull(train['Age']),'Age'] = train['Age'].median()\n\ntest.loc[pd.isnull(test['Fare']), ['Fare']] = test['Fare'].median()\ntest.loc[pd.isnull(test['Age']), ['Age']] = train['Age'].median()","83e8b48e":"train['Fare'] = preprocessing.scale(train['Fare'])\ntrain['SibSp'] = preprocessing.scale(train['SibSp'])\ntrain['Parch'] = preprocessing.scale(train['Parch'])\ntrain['Age'] = preprocessing.scale(train['Age'])\n\ntest['Fare'] = preprocessing.scale(test['Fare'])\ntest['SibSp'] = preprocessing.scale(test['SibSp'])\ntest['Parch'] = preprocessing.scale(test['Parch'])\ntest['Age'] = preprocessing.scale(test['Age'])","f9a20682":"# get dummy variables\npclass_dum = pd.get_dummies(train['Pclass'])\nsex_dum = pd.get_dummies(train['Sex'])\nembarked_dum = pd.get_dummies(train['Embarked'])\n\n# rename the columns\npclass_dum.columns = ('Pclass 1', 'Pclass 2', 'Pclass 3')\nsex_dum.columns = ('Male', 'Female')\nembarked_dum.columns = ('S', 'C', 'Q')\n\n# drop the original columns from training data\ntrain = train.drop(columns=['Pclass','Sex','Embarked','Name','Ticket','Cabin'])\n\n# add the new dummy variables into our training data\ntrain = train.join(pclass_dum)\ntrain = train.join(sex_dum)\ntrain = train.join(embarked_dum)\n\n# get dummy variables\npclass_dum = pd.get_dummies(test['Pclass'])\nsex_dum = pd.get_dummies(test['Sex'])\nembarked_dum = pd.get_dummies(test['Embarked'])\n\n# rename the columns\npclass_dum.columns = ('Pclass 1', 'Pclass 2', 'Pclass 3')\nsex_dum.columns = ('Male', 'Female')\nembarked_dum.columns = ('S', 'C', 'Q')\n\n# drop the original columns from testing data\ntest = test.drop(columns=['Pclass','Sex','Embarked','Name','Ticket','Cabin'])\n\n# add the new dummy variables into our testing data\ntest = test.join(pclass_dum)\ntest = test.join(sex_dum)\ntest = test.join(embarked_dum)\n\ntrain.head()","30c1ded2":"x_train = train.iloc[:, [2,3,4,5,6,7,8,9,10,11,12,13]]\ny_train = train.iloc[:, [1]]\n\nlog_reg = LogisticRegression().fit(x_train, y_train)","b1d365d7":"x_test = test.drop(columns=['PassengerId'])\n\npredict_test =  log_reg.predict(x_test)","3eb482b3":"prediction = pd.DataFrame({\n    \"PassengerId\": test['PassengerId'],\n    \"Survived\": predict_test\n})\n\nprediction = prediction.astype(int)\nprediction","44add1cd":"prediction.to_csv(path_or_buf='prediction.csv',index=False)","cf162b12":"After training, I run the test data through the logistic regression model to find a prediction.","f7f10b19":"Looking at the training data above, I have turned the Pclass column into three columns called Pclass 1, Pclass 2, and Pclass 3. A similar change has been made for the Sex column and the Embarked column as well.","79f242e1":"All that is left to do is format my prediction into a dataframe that is ready to be submitted to the kaggle competition.","f8ffa50d":"Using the info method, I can see how much data is missing from our dataframe. The only columns missing data in both sets of data are Age and Embarked. Train is missing Cabin values and Test is missing a Fare value.I will just set the NaN values to the most common port of Embarked, Age, and Fare. I will ignore Cabin for now. ","1c1aad02":"In order to better interpet the classification data without getting confused by the size of the integers that represent them, I will onehot encode the data.","eaab3dec":"We see 12 columns in our data set:\n(I will add the explanations given with the data set)\n1. **PassengerId** - Unique id used to identify each passenger in our data\n1.  **Survived** - Indicates if passenger survived (1 = Yes, 0 = No)\n1.  **Pclass** - Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n1.  **Name** - Name of the passenger\n1.  **Sex** - Sex of passenger\n1.  **Age** - Age of passenger in years\n1.  **SibSp** - Number of the passenger's siblings and spouses on the Titanic\n1.  **Parch** - Number of the passenger's parents and children on the Titanic\n1.  **Ticket** - Ticket number\n1.  **Fare** - Amount paid for ticket\n1. **Cabin** - Cabin number\n1. **Embarked** - Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southhampton)\n\nI will group the columns as Numerical or Categorical.\n\n**Numerical:** PassengerId, Survived, Pclass, Age, SibSp, Parch, Fare\n\n**Categorical:** Name, Sex, Ticket, Cabin, Embarked\n\nBy first impression, I think it will be easiest to work without Name, Ticket Number, and Cabin Number as they are more complicated to pull meaning from. Later on, I can try to implement them to further increase accuracy.\n\nFirst let's change our Sex and Embarked columns to integers so we can gather statistical data on it. I will set Male = 0 and Female = 1 as well as setting S = 0, C = 1, and Q = 2. These integers will have no meaning other than differentiating the classifcations for a given feature. I implement changes to both the training set and the test set because the data being tested needs to be in the same format as the data that was used to train.","f0f67b60":"Update Log:\n* 2019-02-12  Created kernel. Submitted first prediction with accuracy of 0.75598\n* 2019-02-13  Split ages into groups in hopes of having age correlate more with survival.\n* 2019-02-13  Removed split ages due to lower accuracy by ~5% and began including SibSp, Parch, and Fare in regression independent variables. Submitted with a lower accuracy of 0.74162\n* 2019-02-14  Tried replacing null age values with the median rather than settling for a poor linear regression. This resulted in an even lower accuracy of 0.73684\n* 2019-02-24  Onehot encode the categorical data as well as scaling our numerical data to create better training data for our logistic regression.\n\n\nThis is my first data science project. I hope to learn a lot from this experience and improve in the future. I will try to do things in a simple way and expand by using more variables with future updates.","0246c052":"First I will import the training and test data about the passengers of the Titanic.","d0125e7f":"Next I will scale the numerical data so that they are equally weighted when being used in training. I skip PassengerId because it is just used for identification and has no actual value.","03ba31df":"By using the describe method on our data, we can see some possibly useful measures. It looks like the average age of our passengers is rounded up to 30 years old, with a minimum age of 0.42 years old and a maximum of age of 88 years old. There is also more men than women on the Titanic. Additionally, not many people have family aboard.","bab73ebd":"I am ready to run a logistic regression using our training data to build a model that can predict if a passenger survived. I removed PassengerId when training since it has no value in making predictions."}}