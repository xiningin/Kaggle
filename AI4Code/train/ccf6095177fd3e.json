{"cell_type":{"fe15891d":"code","e8e8828f":"code","b4eebd8c":"code","ef38373c":"code","af90bef1":"code","1fea418c":"code","5aac2ffb":"code","aa4a9971":"code","119979b9":"code","103c1b1c":"code","3af29f28":"code","ac84f422":"code","39bb9a45":"code","8d5431e9":"code","7022d553":"code","94942d6f":"code","302b45be":"code","b6dd9724":"code","32366be9":"code","9a54be21":"code","17ea5282":"code","75181c2f":"code","dae0bb4d":"code","87a98ce4":"code","b2b28661":"code","592e4ab0":"code","0b664bd7":"code","20b4f1e2":"code","73d17952":"code","f127b711":"code","00da64c7":"code","9b2f28ac":"code","f66134a0":"code","0401bca3":"code","d8173b69":"code","f16b40bd":"code","d00ab6a4":"code","88c33499":"code","51879fb4":"code","ec09cbcb":"code","8dc517f0":"code","cbaa49d7":"code","e3483699":"code","78b2c723":"code","c124db9c":"code","46fd03d5":"code","889066a5":"code","a7d5d985":"code","f1e551b3":"code","d754d617":"code","12759242":"code","214d0e35":"code","5f018008":"code","4f37e5d5":"code","a64e989e":"code","70efc0ce":"code","d87a06ee":"code","92e35645":"code","139aecfb":"code","9384d544":"code","e31f47b1":"code","26a672f9":"code","9cc03178":"code","f0b07b79":"code","b4d14a3d":"code","dea84d66":"code","fff6ffc7":"code","16f3cba7":"code","d9ffcffe":"code","b82d5446":"markdown","7f4938a9":"markdown","b7598a33":"markdown","7fd12b2a":"markdown","dc409862":"markdown","5be92bfd":"markdown","d6a40bce":"markdown","95b98834":"markdown","6c21205f":"markdown"},"source":{"fe15891d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e8e8828f":"import xml.etree.ElementTree as Xet","b4eebd8c":"def xml(path):\n    cols = [\"date\",\"description\"]\n    rows = []\n\n    # Parsing the XML file\n    xmlparse = Xet.parse(path)\n    root = xmlparse.getroot()\n    for i in root:\n        date = i.find(\"date\").text\n        description = i.find(\"description\").text\n\n\n        rows.append({\"date\": date,\n                     \"description\": description\n                     })\n    df = pd.DataFrame(rows, columns=cols)\n\n    # Writing dataframe to csv\n    df.to_csv('output.csv')\n    \n    return df","ef38373c":"train = pd.read_csv(\"..\/input\/car-crashes-severity-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/car-crashes-severity-prediction\/test.csv\")\nweather_sfcsv = pd.read_csv(\"..\/input\/car-crashes-severity-prediction\/weather-sfcsv.csv\")\nholidays = xml('..\/input\/car-crashes-severity-prediction\/holidays.xml')\n\ntrain.head()","af90bef1":"train.shape,test.shape,holidays.shape,weather_sfcsv.shape","1fea418c":"holidays.head()","5aac2ffb":"holidays.columns = [\"timestamp\", \"Description\"]\nholidays['timestamp'] = pd.to_datetime(holidays['timestamp'])\nholidays.info()","aa4a9971":"weather_sfcsv.head()","119979b9":"cols = ['Year', 'Month', 'Day']\nweather_sfcsv['timestamp'] = weather_sfcsv[cols].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)","103c1b1c":"weather_sfcsv.info()","3af29f28":"weather_sfcsv['timestamp'] = pd.to_datetime(weather_sfcsv['timestamp'])\nweather_sfcsv.head()","ac84f422":"# listt = []\n# for i in weather_sfcsv['Month']:\n#     if ((i==12) or (i==1) or (i== 2)):\n#         listt.append(\"Winter\")\n#     elif ((i==3) or (i==4) or (i== 5)):\n#         listt.append(\"Spring\")\n#     elif ((i==6) or (i==7 )or (i == 8)):\n#         listt.append(\"Summer\")\n#     elif ((i==9) or (i==10) or (i ==11)):\n#         listt.append(\"Autumn\")\n        ","39bb9a45":"#weather_sfcsv[\"Seasons\"]= listt","8d5431e9":"#weather_sfcsv[\"Seasons\"].unique()","7022d553":"weather_sfcsv.info()","94942d6f":"weather_sfcsv = weather_sfcsv.iloc[:,3:]\nweather_sfcsv.head()","302b45be":"def train_preprocessing():\n    \n    train['Hour'] = pd.to_datetime(train['timestamp']).dt.time\n    train['Hour'] = train['Hour'].astype(\"str\")\n    train['Hour'] = train['Hour'].str[:2]\n    #---------------------------------------------------------------------\n    train['timestamp'] = pd.to_datetime(train['timestamp']).dt.date\n    train['timestamp']  = pd.to_datetime(train['timestamp'])\n    #---------------------------------------------------------------------\n    merged_train_data = train.merge(holidays,how='left',  on = \"timestamp\")\n    merged_train_data[\"Description\"].fillna(\"Work_Day\", inplace = True)\n    merged_train_data[\"Description\"].nunique()\n    #---------------------------------------------------------------------\n    merged_train_data[\"Hour\"] = pd.to_numeric(merged_train_data[\"Hour\"], errors='coerce')\n    merged_train_data = merged_train_data.dropna(subset=['Hour'])\n    merged_train_data[\"Hour\"] = merged_train_data[\"Hour\"].astype(\"int\")\n    #---------------------------------------------------------------------\n    final_train_data = merged_train_data.merge(weather_sfcsv,how='left',left_on= ['timestamp','Hour'], right_on= ['timestamp','Hour'])\n    final_train_data = final_train_data.drop_duplicates()\n    #---------------------------------------------------------------------\n    return final_train_data","b6dd9724":"#pd.set_option('display.max_columns', None)\nfinal_train_data = train_preprocessing()\nfinal_train_data.head()","32366be9":"final_train_data.shape","9a54be21":"final_train_data.ID.nunique()","17ea5282":"final_train_data=final_train_data.drop_duplicates(subset='ID', keep=\"last\")\nfinal_train_data.shape","75181c2f":"test.head()","dae0bb4d":"def test_preprocessing():\n    \n    test['Hour'] = pd.to_datetime(test['timestamp']).dt.time\n    test['Hour'] = test['Hour'].astype(\"str\")\n    test['Hour'] = test['Hour'].str[:2]\n\n    test['timestamp'] = pd.to_datetime(test['timestamp']).dt.date\n    test['timestamp']  = pd.to_datetime(test['timestamp'])\n    \n    merged_test_data = test.merge(holidays,how='outer',  on = \"timestamp\")\n    merged_test_data[\"Description\"].fillna(\"Work_Day\", inplace = True)\n    merged_test_data[\"Description\"].nunique()\n    \n    merged_test_data[\"Hour\"] = pd.to_numeric(merged_test_data[\"Hour\"], errors='coerce')\n    merged_test_data = merged_test_data.dropna(subset=['Hour'])\n    merged_test_data[\"Hour\"] = merged_test_data[\"Hour\"].astype(\"int\")\n    \n    final_test_data = merged_test_data.merge(weather_sfcsv,how='outer',left_on= ['timestamp','Hour'], right_on= ['timestamp','Hour'])\n    final_test_data = final_test_data.drop_duplicates()\n    \n    return final_test_data","87a98ce4":"final_test_data = test_preprocessing()","b2b28661":"final_test_data.shape","592e4ab0":"final_test_data.ID.nunique()","0b664bd7":"final_test_data=final_test_data.drop_duplicates(subset='ID', keep=\"last\")\nfinal_test_data.shape","20b4f1e2":"pd.set_option('display.max_columns', None)\nfinal_train_data.head()","73d17952":"final_test_data.head()","f127b711":"final_test_data.shape","00da64c7":"final_train_data.info()","9b2f28ac":"final_train_data.shape","f66134a0":"final_train_data.isnull().sum()","0401bca3":"final_train_data[[\"Wind_Chill(F)\",'Weather_Condition','Precipitation(in)','Temperature(F)','Humidity(%)','Wind_Speed(mph)','Visibility(mi)', 'Severity']].hist(figsize = (13,9));","d8173b69":"final_train_data[\"Weather_Condition\"].hist()","f16b40bd":"final_train_data[\"Visibility(mi)\"] = final_train_data[\"Visibility(mi)\"].fillna(final_train_data[\"Visibility(mi)\"].median())\nfinal_train_data[\"Humidity(%)\"] = final_train_data[\"Humidity(%)\"].fillna(final_train_data[\"Humidity(%)\"].median())\nfinal_train_data[\"Temperature(F)\"] = final_train_data[\"Temperature(F)\"].fillna(final_train_data[\"Temperature(F)\"].mean())\nfinal_train_data[\"Wind_Speed(mph)\"] = final_train_data[\"Wind_Speed(mph)\"].fillna(final_train_data[\"Wind_Speed(mph)\"].median())\n\nfinal_train_data.dropna(subset=['Weather_Condition'],inplace = True)\nfinal_train_data = final_train_data.drop(['Precipitation(in)', 'Wind_Chill(F)'], axis=1)\n\n#final_train_data = final_train_data.dropna()\n\n##final_train_data","d00ab6a4":"final_train_data.isnull().sum()","88c33499":"final_test_data.dropna(subset = [\"ID\"], inplace=True)\nfinal_test_data.isnull().sum()","51879fb4":"final_test_data[\"Wind_Speed(mph)\"].hist();","ec09cbcb":"final_test_data = final_test_data.drop(['Precipitation(in)', 'Wind_Chill(F)'], axis=1)\nfinal_test_data[\"Wind_Speed(mph)\"] = final_test_data[\"Wind_Speed(mph)\"].fillna(final_test_data[\"Wind_Speed(mph)\"].median())\n","8dc517f0":"final_test_data.isnull().sum()","cbaa49d7":"final_train_data.shape, final_test_data.shape","e3483699":"colormap = plt.cm.RdBu\nplt.figure(figsize=(22,11))\nplt.title('Pearson Correlation of Features', y=1.05, size=20)\nsns.heatmap(final_train_data.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","78b2c723":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nfinal_train_data[\"Weather_Condition\"]=le.fit_transform(final_train_data[\"Weather_Condition\"])\nfinal_train_data[\"Selected\"]=le.fit_transform(final_train_data[\"Selected\"])\nfinal_train_data[\"Side\"]=le.fit_transform(final_train_data[\"Side\"])\nfinal_train_data[\"Description\"]=le.fit_transform(final_train_data[\"Description\"])\n#final_train_data[\"Seasons\"]=le.fit_transform(final_train_data[\"Seasons\"])\n#final_train_data[\"Weather_Condition\"]=le.fit_transform(final_train_data[\"Weather_Condition\"])\n\nfinal_test_data[\"Weather_Condition\"]=le.fit_transform(final_test_data[\"Weather_Condition\"])\n#final_test_data[\"Weather_Condition\"]=le.fit_transform(final_test_data[\"Weather_Condition\"])\nfinal_test_data[\"Selected\"]=le.fit_transform(final_test_data[\"Selected\"])\nfinal_test_data[\"Side\"]=le.fit_transform(final_test_data[\"Side\"])\nfinal_test_data[\"Description\"]=le.fit_transform(final_test_data[\"Description\"])\n#final_test_data[\"Seasons\"]=le.fit_transform(final_test_data[\"Seasons\"])\n","c124db9c":"final_train_data.head()","46fd03d5":"colormap = plt.cm.RdBu\nplt.figure(figsize=(28,15))\nplt.title('Pearson Correlation of Features', y=1.05, size=20)\nsns.heatmap(final_train_data.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","889066a5":"final_train_data.columns","a7d5d985":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(final_train_data, test_size=0.2, random_state=42) # Try adding `stratify` here\n\nX_train = train_df.drop(columns=['ID', 'Severity','timestamp'])\n#X_train = train_df[['Lat', 'Lng', 'Stop','Weather_Condition','Bump','Crossing','Give_Way','Railway','Roundabout','Amenity']]\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns=['ID', 'Severity','timestamp'])\n#X_val = val_df[['Lat', 'Lng', 'Stop','Weather_Condition','Bump','Crossing','Give_Way','Railway','Roundabout','Amenity']]\ny_val = val_df['Severity']","f1e551b3":"X_test = final_test_data.drop(columns=['ID','timestamp'])\n#X_test = final_test_data[['Lat', 'Lng', 'Stop','Weather_Condition','Bump','Crossing','Give_Way','Railway','Roundabout','Amenity']]","d754d617":"#X_test = pd.get_dummies(X_test)\n#X_train=pd.get_dummies(X_train)\n#X_val=pd.get_dummies(X_val)","12759242":"#X_train = X_train[['Lat', 'Lng','Stop','Crossing','Weather_Condition']]\n#X_val = X_val[['Lat', 'Lng','Stop','Crossing','Weather_Condition']]","214d0e35":"X_train.columns, X_test.columns","5f018008":"#from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nMMS = MinMaxScaler(feature_range = (0.5,1))\nMMS.fit(X_train)\nMMS.fit(X_test)\nMMS.fit(X_val)\n\n\nMMS.transform(X_train)\nMMS.transform(X_test)\nMMS.transform(X_val)\n","4f37e5d5":"from sklearn.ensemble import RandomForestClassifier\n\n# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)\n\nprint(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","a64e989e":"importance = classifier.feature_importances_\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()\n","70efc0ce":"#0,1,3,4,6,8,10,11,12,13,15,16,17,18,19","d87a06ee":"final_train_data.columns","92e35645":"X_train.columns,X_val.columns,X_test.columns","139aecfb":"# X_train = train_df.drop(columns=['Lng', 'Severity','Crossing','Junction','Railway','Temperature(F)','Temperature(F)', 'Humidity(%)', 'Wind_Speed(mph)',\n#        'Visibility(mi)', 'Selected','timestamp'])\n# y_train = train_df['Severity']\n\n# X_val = val_df.drop(columns=['Lng', 'Severity','Crossing','Junction','Railway','Temperature(F)','Temperature(F)', 'Humidity(%)', 'Wind_Speed(mph)',\n#        'Visibility(mi)', 'Selected','timestamp'])\n# y_val = val_df['Severity']\n\n# X_test = final_test_data.drop(columns=['Lng','Crossing','Junction','Railway','Temperature(F)','Temperature(F)', 'Humidity(%)', 'Wind_Speed(mph)',\n#        'Visibility(mi)', 'Selected','timestamp'])","9384d544":"X_train = train_df[['Lat', 'Lng', 'Stop','Weather_Condition','Bump','Crossing','Give_Way','Railway','Roundabout','Amenity']]\ny_train = train_df['Severity']\n\nX_val = val_df[['Lat', 'Lng', 'Stop','Weather_Condition','Bump','Crossing','Give_Way','Railway','Roundabout','Amenity']]\ny_val = val_df['Severity']\n\nX_test = final_test_data[['Lat', 'Lng', 'Stop','Weather_Condition','Bump','Crossing','Give_Way','Railway','Roundabout','Amenity']]","e31f47b1":"# from imblearn.over_sampling import RandomOverSampler\n# from imblearn.over_sampling import SMOTE\n\n# strategy = {1:3800, 2:4500, 3:4000, 4:3800}\n\n# smt = SMOTE(sampling_strategy=strategy)\n# ros = RandomOverSampler()\n\n# X_smt, y_smt = smt.fit_resample(X_train, y_train)\n# X_smt_val, y_smt_val = smt.fit_resample(X_val, y_val)\n\n# X_ros, y_ros = smt.fit_resample(X_train, y_train)\n# X_ros_val, y_ros_val = smt.fit_resample(X_val, y_val)","26a672f9":"#from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nMMS = MinMaxScaler(feature_range = (0.5,1))\n#MMS.fit(X_smt)\n#MMS.fit(X_ros)\nMMS.fit(X_train)\nMMS.fit(X_test)\nMMS.fit(X_val)\n\n\n#MMS.transform(X_smt)\n#MMS.transform(X_ros)\nMMS.transform(X_train)\nMMS.transform(X_test)\nMMS.transform(X_val)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)\n\nprint(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","9cc03178":"# from sklearn.model_selection import RepeatedStratifiedKFold\n# from sklearn.model_selection import cross_val_score\n\n# def evaluate_model(X, y, model):\n#     # define evaluation procedure\n#     cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n#     # evaluate model\n#     scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n#     return scores","f0b07b79":"\n# scores = evaluate_model(X_val, y_val, classifier)\n# # summarize performance\n# print('Mean Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","b4d14a3d":"y_train.hist()","dea84d66":"y_val.hist()","fff6ffc7":"#X_test = final_test_data.drop(columns=['ID', 'Bump','Roundabout','timestamp','Wind_Speed(mph)','Wind_Chill(F)', 'Precipitation(in)'])\n\n# You should update\/remove the next line once you change the features used for training\n#X_test = X_test[['Lat', 'Lng','Stop','Crossing','Weather_Condition']]\n\ny_test_predicted = classifier.predict(X_test)\n\nfinal_test_data['Severity'] = y_test_predicted\n\nfinal_test_data.head()","16f3cba7":"final_test_data.Severity.hist()","d9ffcffe":"final_test_data.ID = final_test_data.ID.astype(\"int32\")\nfinal_test_data[['ID', 'Severity']].to_csv('\/kaggle\/working\/output.csv', index=False)\n","b82d5446":"## ML Model","7f4938a9":"## Final train set","b7598a33":"## weather","7fd12b2a":"## Data Cleaning","dc409862":"## Test set cleaning","5be92bfd":"## train set cleaning","d6a40bce":"## Data Collection","95b98834":"## holidays","6c21205f":"## Test data preprocessing"}}