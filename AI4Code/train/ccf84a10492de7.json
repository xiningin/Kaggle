{"cell_type":{"3494411d":"code","5a9ba0cc":"code","f411d4b7":"code","4c0a4d4a":"code","5d208ddc":"code","abb0a590":"code","db5958b9":"code","35102da2":"code","b369f3f8":"code","7a3709f1":"code","9cfc3a38":"code","9f336ef5":"code","3cf19e91":"code","a2a240ee":"code","83e3cb43":"code","4e83c137":"code","cdd4b3e7":"code","44968634":"code","3d51e6bb":"code","2308aac4":"code","529d36bd":"markdown","ae7b390c":"markdown","27827f9b":"markdown","f2275a63":"markdown","ddebac68":"markdown","81febe5b":"markdown","f221d9dd":"markdown","399f9d02":"markdown","85eb4a76":"markdown","9228bd33":"markdown","c64134e8":"markdown","405b6388":"markdown"},"source":{"3494411d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/bbc-full-text-document-classification\/bbc-fulltext (document classification)\/bbc\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5a9ba0cc":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import hstack\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport eli5\nfrom IPython.display import Image","f411d4b7":"# Step 1 - Get the file details\ndirectory = []\nfile = []\ntitle = []\ntext = []\nlabel = []\ndatapath = '\/kaggle\/input\/bbc-full-text-document-classification\/bbc-fulltext (document classification)\/bbc\/' \nfor dirname, _ , filenames in os.walk(datapath):\n    #print('Directory: ', dirname)\n    #print('Subdir: ', dirname.split('\/')[-1])\n    # remove the Readme.txt file\n    # will not find file in the second iteration so we skip the error\n    try:\n        filenames.remove('README.TXT')\n    except:\n        pass\n    for filename in filenames:\n        directory.append(dirname)\n        file.append(filename)\n        label.append(dirname.split('\/')[-1])\n        #print(filename)\n        fullpathfile = os.path.join(dirname,filename)\n        with open(fullpathfile, 'r', encoding=\"utf8\", errors='ignore') as infile:\n            intext = ''\n            firstline = True\n            for line in infile:\n                if firstline:\n                    title.append(line.replace('\\n',''))\n                    firstline = False\n                else:\n                    intext = intext + ' ' + line.replace('\\n','')\n            text.append(intext)\n\n#\n","4c0a4d4a":"fulldf = pd.DataFrame(list(zip(directory, file, title, text, label)), \n               columns =['directory', 'file', 'title', 'text', 'label'])\n\ndf = fulldf.filter(['title','text','label'], axis=1)\n\nprint(\"FullDf : \", fulldf.shape)\nprint(\"DF : \", df.shape)","5d208ddc":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df, test_size=0.2)\nprint(\"Train DF: \",train.shape)\nprint(\"Test DF: \",test.shape)","abb0a590":"df.head()","db5958b9":"sns.countplot(df['label']);\nplt.title('Data: Target distribution');","35102da2":"plt.subplots(1, 2)\nplt.subplot(1, 2, 1)\ndf['text'].apply(lambda x: len(x.split())).plot(kind='hist');\nplt.yscale('log');\nplt.title('Text length in words');\nplt.subplot(1, 2, 2)\ndf['title'].apply(lambda x: len(x.split())).plot(kind='hist');\nplt.yscale('log');\nplt.title('Title length in words');","b369f3f8":"from wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https:\/\/www.kaggle.com\/aashita\/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  ","7a3709f1":"plot_wordcloud(df[\"title\"], title=\"Word Cloud of Titles\")","9cfc3a38":"text_transformer = TfidfVectorizer(stop_words='english', \n                                   ngram_range=(1, 2), lowercase=True, max_features=150000)","9f336ef5":"%%time\nX_train_text = text_transformer.fit_transform(train['text'])\nX_test_text = text_transformer.transform(test['text'])","3cf19e91":"# if you wish to have a look at the output uncomment this line\n#print(X_train_text)","a2a240ee":"X_train = X_train_text\nX_test = X_test_text\nprint(\"X Train DF: \",X_train.shape)\nprint(\"X Test DF: \", X_test.shape)","83e3cb43":"logit = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial',\n                           random_state=17, n_jobs=4)","4e83c137":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)","cdd4b3e7":"%%time\ncv_results = cross_val_score(logit, X_train, train['label'], cv=skf, scoring='f1_macro')","44968634":"cv_results, cv_results.mean()","3d51e6bb":"%%time\nlogit.fit(X_train, train['label'])","2308aac4":"eli5.show_weights(estimator=logit, \n                  feature_names= text_transformer.get_feature_names(),top=(50, 5))","529d36bd":"*So let us begin with a simple technique for document classification.*","ae7b390c":"### Preprocessing\nThis is the BBC fulltext news articles dataset from Kaggle. Each article (~2000) have been pre categorised as business, entertainment and politics. Notice the supervised technique. \n\nAs part of getting our data ready for analysis. We need to extract this text as:\n    * title \n    * text \n    * label\nThe above I was able to derive by simply opening a few documents and glancing through them. Please never underestimate this simple step, of physically looking at your data, spend some considerable time understanding your data.\n\nWe will follow the below steps:\n    1. Walk through each folder.\n    2. Pick the complete path, directory and filename.\n    3. Read the file into a string line by line\n    4. Pick the first line as Title\n    5. And the remaining concat to form the text.\n    6. Set the directory name as label.\n*Note don't forget to ignore the Readme.txt file*","27827f9b":"### Lets Train the model","f2275a63":"## VALIDATION\n### Cross Validation\n\n![](http:\/\/)The simplest way to use cross-validation is to call the cross_val_score helper function on the estimator and the dataset.\n\n**StratifiedKFold** is a variation of KFold. First, StratifiedKFold shuffles your data, after that splits the data into n_splits parts and Done. Now, it will use each part as a test set. Note that it only and always shuffles data one time before splitting.StratifiedKFold is a variation of KFold. First, StratifiedKFold shuffles your data, after that splits the data into n_splits parts and Done. Now, it will use each part as a test set. Note that it only and always shuffles data one time before splitting.\n![stratified validation](https:\/\/static.wixstatic.com\/media\/7ebe53_2523c02e18fd4313a0bca50697e75089~mv2.png\/v1\/fill\/w_885,h_613\/grid_search_cross_validation.png)","ddebac68":"### Imports","81febe5b":"### Document Classification\n\nThis is one of the most common task that we perform in NLP and in general is the first task that is done in IE. There are many methods for doing document classification.\n\n#### Types of Document Classification and Techniques\n\n1. Supervised Document Classification\n2. Unsupervised Document Classification\n\n**Supervised Document Classification**\nIn supervised classification we use a human annotated\/classified documents as input. This is used mainly in tasks where we already have a well defined business process, for example in ITOps ticket classification if we already have a series of labelled tickets (buckets) we would use supervised classification. \n\n**Unsupervised Document Classification**\nThis is also known as **clustering** and is done with no specified targetted labels. This is done when we want to group together similar documents to study the clustering of the documents. ","f221d9dd":"## The Model\nAt this stage let us take the simplest model a Logistic Regression model. I will use scikit learns implementation below.","399f9d02":"## TFDF\n\n**What does tf-idf mean?**\nTf-idf stands for term frequency-inverse document frequency, and the tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus. \n\n**How to Compute?**\nTypically, the tf-idf weight is composed by two terms: the first computes the normalized Term Frequency (TF), aka. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears.\n\n* __TF__: _Term Frequency_, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization: \n\n    _TF(t) = (Number of times term t appears in a document) \/ (Total number of terms in the document)._\n\n* __IDF__: _Inverse Document Frequency_, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n\n    *IDF(t) = log_e(Total number of documents \/ Number of documents with term t in it).*\n\n**Example:**\nConsider a document containing 100 words wherein the word cat appears 3 times. The term frequency (i.e., tf) for cat is then (3 \/ 100) = 0.03. Now, assume we have 10 million documents and the word cat appears in one thousand of these. Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 \/ 1,000) = 4. Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12.","85eb4a76":"# Document Analytics\n### Information Extraction vs Information Retreival\n\nTo begin with lets get some terminologies under our belt right. **Information Retreival (IR)** is the process of finding a document within a repository. It has to do with Document search, Google and other search engines perform IR of websites from the Internet. **Information Extraction** is the process of extracting relevant information from within documents. \nIR follows a seperate set of algorithims and design patterns that include search engine, optimisation etc. Here we will concentrate on IE.\n\n### Text Hierarchy \n\n![Text Hierarchy](https:\/\/static.wixstatic.com\/media\/7ebe53_186761b15f4e4286b73a70399b69646e~mv2.png\/v1\/fill\/w_1821,h_383\/Text_Object_Hierarchy.png)\n\nThe basic unit of work in Text Analytics is a Token this translates to a word in general but can include in such cases as Is'nt to Is, ['] and nt. But for all practical purpose it is a **word**. These come together to form **Sentences** and this in turn combine to form a **Paragraph** that come together to form a **Document**. In general Documents belonging to a particular domain or source are stored in a **Document Store**, multiple document stores come together to form a **Repository**.\n\n***Note: In NLP document does not mean a file that has multiple paragraphs with Table of contents etc. A document is a a single complete unit of information e.g. a feedback or review constitutes a document, also a novel constitutes a document ***","9228bd33":"## Hyper-Parameter Tuning\n\nBy partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets.\nA solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k \u201cfolds\u201d:\n\n* A model is trained using  of the folds as training data;\n* the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n\nThe performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data.\n\n![cross validation](https:\/\/static.wixstatic.com\/media\/7ebe53_d740b925ce3b45d99feab6d7279c40d0~mv2.png\/v1\/fill\/w_562,h_204\/XJZve.png)","c64134e8":"## INTERPRETATION\n\nELI5 is a Python package which helps to debug machine learning classifiers and explain their predictions.\n\nThere are two main ways to look at a classification or a regression model:\n\n1. inspect model parameters and try to figure out how the model works globally;\n2. inspect an individual prediction of a model, try to figure out why the model makes the decision it makes.\n\nFor (1) ELI5 provides eli5.show_weights() function; \n\nfor (2) it provides eli5.show_prediction() function.","405b6388":"## EDA\n\nLets do a bit of EDA\n1. Lets find out the distribution of labels in our data.\n1. The distribution of sentence lengths.\n1. The frequency of words."}}