{"cell_type":{"167735ae":"code","26885857":"code","4b8097ee":"code","44cc5847":"code","d605736d":"code","d8dde56c":"code","0ed7c6ad":"code","20171c8d":"code","e14eefd6":"code","ee94996f":"code","2213b897":"code","afe10359":"code","6a6b9bb4":"code","b6bdeaad":"code","f698d39c":"code","4b6f7ec6":"code","8047dc76":"code","c9b93306":"code","3da497f5":"code","c563e316":"code","8f6d0e5d":"code","62c5874b":"code","a284cca3":"code","90947ac6":"code","3a3523e7":"code","c6416f7a":"code","b619d947":"code","0eb43a51":"code","4f3ad800":"code","a85748ac":"code","8e2c0a7c":"code","b1005031":"code","872a4ad2":"code","13ac8a0d":"code","38644a92":"code","d5d22371":"code","847418ba":"code","6d452890":"code","0dafe316":"code","06a414da":"code","e1eddc95":"code","26c9dca1":"code","57f924e6":"code","89c4dc31":"code","7e78e34e":"code","43ecc132":"code","dd36b508":"code","795cbddf":"code","55681067":"code","ea9a7719":"code","d406cfca":"markdown","f73afe36":"markdown","c509bd8a":"markdown","158d6799":"markdown","1fb80c72":"markdown","767d23a1":"markdown","9298bb62":"markdown"},"source":{"167735ae":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline ","26885857":"train=pd.read_csv('..\/input\/bike-sharing-dataset\/train_bikes.csv') ##Loading the training data\ntest=pd.read_csv(\"..\/input\/bike-sharing-dataset\/test_bikes.csv\") ##Loading the testing data","4b8097ee":"train.head() ","44cc5847":"train.groupby(['workingday']).sum()['count'] ","d605736d":"sns.relplot(x='season',y='count',data=train,hue='workingday') \nsns.relplot(x='weather',y='count',data=train,hue='workingday')","d8dde56c":"sns.relplot(x='temp',y='count',data=train,hue='workingday')\nsns.relplot(x='atemp',y='count',data=train,hue='workingday')","0ed7c6ad":"sns.relplot(x='humidity',y='count',data=train,hue='workingday')\nsns.relplot(x='windspeed',y='count',data=train,hue='workingday')\nsns.relplot(x='casual',y='count',data=train,hue='workingday')","20171c8d":"cols = ['temp','atemp','humidity','windspeed','casual','registered']\nfig, axes = plt.subplots(2,3,figsize = (10,5))\n\ncount=0\nfor i in range(2):\n    for j in range(3):\n        x = cols[count+j]\n        sns.distplot(train[x].values, ax = axes[i][j],bins = 30)\n        axes[i][j].set_title(x,fontsize=15)\n        fig.set_size_inches(15,7)\n        plt.tight_layout()\n    count = count+j+1 \n","e14eefd6":"train.info()","ee94996f":"train.describe()","2213b897":"print(\"Shape of training dataset is: \",train.shape)\nprint(\"Does the traing dataset have null values ? -\",train.isnull().values.any())","afe10359":"visual_df = train.copy()","6a6b9bb4":"train['datetime'] = pd.to_datetime(train['datetime'] )#changing the dtype of datetime field to datetime\ntrain['year']=train.datetime.dt.year\ntrain['month']=train.datetime.dt.month\ntrain['day']=train.datetime.dt.day\ntrain['hour']=train.datetime.dt.hour\ntrain['minute']=train.datetime.dt.minute","b6bdeaad":"visual_df['datetime'] = pd.to_datetime(visual_df['datetime'] )#changing the dtype of datetime field to datetime","f698d39c":"# method for creating the count plot based on hour for a given year \ndef plot_by_month(data,aggre,title):\n    d2 = data\n    d2['year'] = d2.datetime.dt.year\n    d2['month'] = d2.datetime.dt.month\n    d2['hour'] = d2.datetime.dt.hour\n    \n    by_year = d2.groupby([aggre,'year'])['count'].sum().unstack() # groupby hour and working day\n    \n    return by_year.plot(kind='bar', figsize=(15,5), width=0.9, title=title) # returning the figure grouped by hour\n\nplot_by_month(visual_df,'month', \"Seasonal trend: There must be high demand during summer season, when temperature is good enough to ride cycle and low demand during winter.\")  \nplot_by_month(visual_df,'hour', \"Hourly trend: There must be high demand during office timings. Early morning and late evening can have moderate trend (cyclist) and low demand during 10:00 pm to 4:00 am.\") ","4b6f7ec6":"# method for creating the count plot based on hour for a given year \ndef plot_by_hour(data, year):\n    d1 = data\n    d1['hour'] = d1.datetime.dt.hour\n    \n    by_hour = d1.groupby(['hour', 'workingday'])['count'].sum().unstack() # groupby hour and working day\n    \n    return by_hour.plot(kind='bar', figsize=(15,5), width=0.9, title=\"Hourly pattern based on working days. High trend during hours when peope start to office and leave to home.Year = {0}\".format(year)) # returning the figure grouped by hour\n\n\nplot_by_hour(visual_df, year=2011) # plotting the count plot based on hour for 2011 \nplot_by_hour(visual_df, year=2012) # plotting the count plot based on hour for 2012","8047dc76":"def plot_hours(data, message):\n    d2 = data.copy()\n    d2['hour'] = data.datetime.dt.hour # extratcing the hour\n    \n    hours = {}\n\n    for hour in range(24):\n        hours[hour] = d2[ d2.hour == hour ]['count'].values\n\n    \n    plt.figure(figsize=(20,10))\n    plt.ylabel(\"Count rent\")\n    plt.xlabel(\"Hours\")\n    plt.title(\"count vs hours\\n\" + message)\n    plt.boxplot( [hours[hour] for hour in range(24)] )\n    plt.grid()\n    \n\nplot_hours( visual_df[visual_df.datetime.dt.year == 2011], 'year 2011') # box plot for hourly count for the mentioned year\nplot_hours( visual_df[visual_df.datetime.dt.year == 2012], 'year 2012') # box plot for hourly count for the mentioned year\n ","c9b93306":"\nplot_hours( visual_df[visual_df.workingday == 0], 'Non-working days') # box plot for hourly count for the mentioned year\nplot_hours( visual_df[visual_df.workingday == 1], 'Working days') # box plot for hourly count for the mentioned year","3da497f5":"train.columns","c563e316":"from sklearn.linear_model import Lasso,Ridge\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split","8f6d0e5d":"from sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import r2_score,mean_squared_error\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor","62c5874b":"train.head()","a284cca3":"train['count'] = np.log(train['count']+1)","90947ac6":"y_train = train['count'] ## Capture the dependent feature\nx_train = train.drop(['datetime','count'],axis=1) ## Capture the independent feature","3a3523e7":"x_train.head()","c6416f7a":"test.head(2)","b619d947":"x_train1 = x_train.drop(['casual','registered'],axis=1) # Removing casual and registered as its not available in test data","0eb43a51":"x_train_pred,x_test_pred,y_train_pred,y_test_pred = train_test_split(x_train1,y_train, test_size=0.3, random_state=42)","4f3ad800":"x_train_pred.head(2)","a85748ac":"models=[RandomForestRegressor(),Lasso(alpha=0.01),DecisionTreeRegressor(),SVR(),KNeighborsRegressor()]\nmodel_names=['RandomForestRegressor','Lasso','DecisionTreeRegressor','SVR','KNeighborsRegressor']\nrmse=[]\nr_squared=[]\ndic={}\nfor model in range (len(models)):\n    alg=models[model]\n    alg.fit(x_train_pred,y_train_pred)\n    alg_y_pred=alg.predict(x_test_pred)\n    rmse.append(np.sqrt(mean_squared_error(y_test_pred,alg_y_pred)))\n    r_squared.append(r2_score(y_test_pred,alg_y_pred))\ndic={'Modelling Algorithms':model_names,'RMSE':rmse,'R-Squared':r_squared}   \nmodel_performances= pd.DataFrame(dic)\n\nmodel_performances","8e2c0a7c":"plt.figure(figsize = (10,5))\nsns.barplot(x='Modelling Algorithms',y='RMSE',data=model_performances)\nplt.title(\"Algorithms vs RMSE\")","b1005031":"plt.figure(figsize = (10,5))\nsns.barplot(x='Modelling Algorithms',y='R-Squared',data=model_performances)\nplt.title(\"Algorithms vs R-Squared\")","872a4ad2":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 5)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(1, 45, num = 3)]\n# Minimum number of samples required to split a node\nmin_samples_split = [5, 10]\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split}","13ac8a0d":"random_grid","38644a92":"rF_random = RandomizedSearchCV(estimator = RandomForestRegressor(), param_distributions = random_grid, n_iter = 10, cv = 10, verbose=2, random_state=42, n_jobs = -1, scoring='neg_mean_squared_error')\n# Fit the random search model\nrF_random.fit(x_train_pred,y_train_pred)","d5d22371":"rF_random.best_params_","847418ba":"# Performance Comparison\nbest_fit= rF_random.best_estimator_.predict(x_test_pred)\nprint(\"RMSE and R-Squared after hyperparameter tuning :\\n\")\nprint(\"Modelling algorithm: RandomForestRegressor \")\nprint(\"RMSE value is: \",np.sqrt(mean_squared_error(y_test_pred,best_fit)))\nprint(\"R-Squared value is \",r2_score(y_test_pred,best_fit))","6d452890":"test.head(2)","0dafe316":"test['datetime'] = pd.to_datetime(test['datetime'])\ntest['year']=test.datetime.dt.year\ntest['month']=test.datetime.dt.month\ntest['day']=test.datetime.dt.day\ntest['hour']=test.datetime.dt.hour\ntest['minute']=test.datetime.dt.minute","06a414da":"test_val = test.drop(['datetime'],axis=1)","e1eddc95":"test_val.head(2)","26c9dca1":"predictions = rF_random.best_estimator_.predict(test_val)","57f924e6":"predictions_exp = np.exp(predictions)-1","89c4dc31":"predictions_exp","7e78e34e":"submission = pd.DataFrame({'datetime':test['datetime'],'count': predictions_exp})","43ecc132":"submission.head()","dd36b508":"submission_viz=submission.copy()","795cbddf":"submission_viz['datetime'] = pd.to_datetime(submission_viz['datetime'])","55681067":"def plot_by_month_pred(data,aggre,title):\n    d2 = data\n    d2['year'] = d2.datetime.dt.year\n    d2['month'] = d2.datetime.dt.month\n    d2['hour'] = d2.datetime.dt.hour\n    \n    by_year = d2.groupby([aggre,'year'])['count'].sum().unstack() # groupby hour and working day\n    \n    return by_year.plot(kind='bar', figsize=(15,5), width=0.9, title=title) # returning the figure grouped by hour\n\n\nplot_by_month_pred(submission_viz,'month', \"Testing Data - Seasonal trend: There must be high demand during summer season,\\n when temperature is good enough to ride cycle and low demand during winter.\")  \nplot_by_month_pred(submission_viz,'hour', \"Testing Data - Hourly trend: There must be high demand during office timings.\\n Early morning and late evening can have moderate trend (cyclist) and low demand during 10:00 pm to 4:00 am.\") ","ea9a7719":"submission.to_csv(\"sampleSubmission.csv\",index=False)","d406cfca":" The below barplot shows that test data prediction matchs that of the training data pattern.","f73afe36":"#           Please upvote if you find useful","c509bd8a":"# Hyperparameter Tuning","158d6799":"# Model Training","1fb80c72":"# Testing","767d23a1":"From above we can conclude that RandomForestRegressor fits good compared to other models taken into consideration. So lets fine tune RandomForestRegressor using randomized search.","9298bb62":"Problem Statement-\nBike-sharing system are meant to rent the bicycle and return to the different place for the bike sharing purpose in Washington DC.\nYou are provided with rental data spanning for 2 years. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period."}}