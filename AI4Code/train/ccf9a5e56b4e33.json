{"cell_type":{"9c341c85":"code","ba8c06e1":"code","efaa8b30":"code","94360ea5":"code","b6b647bd":"code","5706a55d":"code","27f9c085":"code","c1afb667":"code","d69156df":"code","6bcfa7d2":"code","9edce8a6":"code","fb4e9f26":"code","0b7ed178":"code","4642ac33":"code","e54ad4c8":"code","520b7b60":"code","9274c762":"code","d093edf3":"code","3c06a2a1":"code","fa9bb9af":"code","98884edf":"code","6ef3fa3f":"code","09ef4d31":"markdown","9a8932dc":"markdown","ee534daa":"markdown","ebd0e8f6":"markdown","d0891e61":"markdown","c6042ef9":"markdown","fe615431":"markdown","cf431977":"markdown","613d17aa":"markdown"},"source":{"9c341c85":"# Explore the competition data and learn about the competition topic\n# Prepare data for machine learning\n# Train a model\n# Measure the accuracy of your model\n# Prepare and make your first Kaggle submission.\n\n#In this competition, we have a data set of different information about passengers onboard the Titanic, and we see if\n#we can use that information to predict whether those people survived or not.\n\n#Data has a number of feature columns which contain various descriptive data, as well as a column of the target values\n#we are trying to predict survied or not","ba8c06e1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","efaa8b30":"#code snippet:\nimport pandas as pd\n\ntest=pd.read_csv(\"test.csv\")\ntrain=pd.read_csv(\"train.csv\")\ntest_shape = test.shape\ntrain_shape=train.shape\nprint(train_shape,test_shape)","94360ea5":"#here is the features we ll be working w\n\n# PassengerID - A column added by Kaggle to identify each row and make submissions easier\n# Survived - Whether the passenger survived or not and the value we are predicting (0=No, 1=Yes)\n# Pclass - The class of the ticket the passenger purchased (1=1st, 2=2nd, 3=3rd)\n# Sex - The passenger's sex\n# Age - The passenger's age in years\n# SibSp - The number of siblings or spouses the passenger had aboard the Titanic\n# Parch - The number of parents or children the passenger had aboard the Titanic\n# Ticket - The passenger's ticket number\n# Fare - The fare the passenger paid\n# Cabin - The passenger's cabin number\n# Embarked - The port where the passenger embarked (C=Cherbourg, Q=Queenstown, S=Southampton)\n\n#we are performing binary classification, which means that there are only two different states we are classifying.\n\n#domain knowledge is important in ml. understanding the Titanic disaster and specifically what variables\n#might affect the outcome of survival is important. Anyone who has watched the movie Titanic would remember that women\n#and children were given preference to lifeboats (as they were in real life). You would also remember the vast class\n#disparity of the passengers.\n\n#This indicates that Age, Sex, and PClass may be good predictors of survival.We'll start by exploring Sex and Pclass by\n#visualizing the data.\n\n#Because the Survived column contains 0 if the passenger did not survive and 1 if they did, we can segment our data by\n#sex and calculate the mean of this column. We can use DataFrame.pivot_table() to easily do this:\n\nimport matplotlib.pyplot as plt\nsex_pivot = train.pivot_table(index=\"Sex\",values=\"Survived\")\nsex_pivot.plot.bar()\nplt.show()","b6b647bd":"#The Sex and PClass columns are categorical features.That means that the values represented a few separate options\n#(for instance, whether the passenger was male or female).\n\n#Let's take a look at the Age column using Series.describe().\nprint(train[\"Age\"].describe())\n#The Age column contains numbers ranging from 0.42 to 80.0. The other thing to note here is that there are 714 vals in\n#this column,fewer than the 891 rows we discovered that the train data set had earlier which indicates\n#we have some missing values.\n\n#All of this means that the Age column needs to be treated slightly differently, as this is a continuous numerical\n#column. One way to look at distribution of values in a continuous numerical set is to use histograms. We can create\n#two histograms to compare visually the those that survived vs those who died across different age ranges:\nsurvived = train[train[\"Survived\"] == 1]\ndied = train[train[\"Survived\"] == 0]\nsurvived[\"Age\"].plot.hist(alpha=0.5,color='red',bins=50)\ndied[\"Age\"].plot.hist(alpha=0.5,color='blue',bins=50)\nplt.legend(['Survived','Died'])\nplt.show()\n#The relationship here is not simple, but we can see that in some age ranges more passengers survived - where the red\n#bars are higher than the blue bars.\n\n#In order for this to be useful to our machin learning model,we can separate this continuous feature into a categorical\n#feature by dividing it into ranges. We can use the pandas.cut() function to help us out.\n\n#The pandas.cut() function has two required parameters - the column we wish to cut, and a list of numbers which define\n#the boundaries of our cuts. We are also going to use the optional parameter labels, which takes a list of labels for\n#the resultant bins. This will make it easier for us to understand our results.\n\n#Before we modify this column, we have to be aware of two things. Firstly, any change we make to the train data,we also\n#need to make to the test data, otherwise we will be unable to use our model to make predictions for our submissions.\n#Secondly, we need to remember to handle the missing values we observed above.In the ex below, we create a func that:\n\n#uses the pandas.fillna() method to fill all of the missing values with -0.5\n#cuts the Age column into three segments: Missing, Child, and Adult using pandas.cut().\n\n#We then use that function on both the train and test dataframes.","5706a55d":"#code snippet:\ndef process_age(df,cut_points,label_names):\n    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n    return df\n\ncut_points=[-1,0,5,12,18,35,60,100]\nlabel_names=[\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n\ntrain=process_age(train,cut_points,label_names)\ntest=process_age(test,cut_points,label_names)\n\npivot=train.pivot_table(index=\"Age_categories\",values=\"Survived\")\npivot.plot.bar()\nplt.show()","27f9c085":"# So far we have identified three columns that may be useful for predicting survival:\n\n# Sex\n# Pclass\n# Age, and more specifically our newly created Age_categories\n\n#Before we build our model, we need to prepare these columns for machine learning.Most machine learning algorithms cant\n#understand text labels, so we have to convert our values into numbers.Additionally, we need to be careful that we dont\n#imply any numeric relationship where there isn't one. If we think of the values in the Pclass column, we know they are\n#1, 2, and 3. we can confirm this by running the following code:\ntrain[\"Pclass\"].value_counts()\n#While the class of each passenger certainly has some sort of ordered relationship, the relationship between each class\n#is not the same as the relationship between the numbers 1, 2, and 3. For instance, class 2 isn't \"worth\" double what\n#class 1 is, and class 3 isn't \"worth\" triple what class 1 is.\n\n#In order to remove this relationship, we can create dummy columns for each unique value in Pclass:\n#Rather than doing this manually,we can use the pandas.get_dummies() function, which will generate columns shown in the\n#diagram above.The following code creates a function to create the dummy columns for the Pclass column and add it back\n#to the original dataframe. It then applies that function the train and test dataframes.\n\n#Let's use that function to create dummy columns for both the Sex and Age_categories columns.","c1afb667":"#code snippet:\ndef create_dummies(df,column_name):\n    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n    df = pd.concat([df,dummies],axis=1)\n    return df\n\ntrain = create_dummies(train,\"Pclass\")\ntest = create_dummies(test,\"Pclass\")\n\ntrain=create_dummies(train,\"Sex\")\ntest=create_dummies(test,\"Sex\")\n\ntrain=create_dummies(train,\"Age_categories\")\ntest=create_dummies(test,\"Age_categories\")\n","d69156df":"#Now that our data has been prepared, we are ready to train our first model. The first model we will use is called\n#Logistic Regression, which is often the first model you will train when performing classification.\n\n#We will be using the scikit-learn library as it has many tools that make performing machine learning easier.\n#here is the 4 steps that we use for most sklearn process:\n\n# Instantiate (or create) the specific machine learning model you want to use\n# Fit the model to the training data\n# Use the model to make predictions\n# Evaluate the accuracy of the predictions\n\n#Each model in scikit-learn is implemented as a separate class and the first step is to identify the class we want\n#to create an instance of. In our case, we want to use the LogisticRegression class.\n# from sklearn.linear_model import LogisticRegression\n#Next, we create a LogisticRegression object:\n\n#Lastly, we use the LogisticRegression.fit() method to train our model. The .fit() method accepts two arguments: X and\n#y. X must be a two dimensional array (like a dataframe) of the features that we wish to train our model on, and y must\n#be a one-dimensional array (like a series) of our target, or the column we wish to predict.\n","6bcfa7d2":"#code snippet:\ncolumns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n       'Age_categories_Missing','Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior']\n\nfrom sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()\nlr.fit(train[columns],train[\"Survived\"])","9edce8a6":"# Our next step is to find out how accurate our model is, and to do that, we'll have to make some predictions.\n#we have a test dataframe that we could use to make predictions.We could make predictions\n#on that data set, but because it doesn't have the Survived column we would have to submit it to Kaggle to find out our\n#accuracy.This would quickly become a pain if we had to submit to find out accuracy every time we optimized our model\n\n#We could also fit and predict on our train dataframe, however if we do this there is a high likelihood that our model\n#will overfit,which means it will perform well because we're testing on the same data we've trained on,but then perform\n#much worse on new, unseen data.\n\n#Instead we can split our train dataframe into two:\n#One part to train our model on (often 80% of the observations)\n#One part to make predictions with and test our model (often 20% of the observations)\n\n#convention in machine learning is to call these two parts train and test.This can become confusing, since we already\n#have our test dataframe that we will eventually use to make predictions to submit to Kaggle. To avoid confusion, from\n#here on, we're going to call this Kaggle 'test' data holdout data which is tech name given to this type of data used\n#for final predictions.\n\n#The scikit-learn library has a handy model_selection.train_test_split() function that we can use to split our data.\n#train_test_split() accepts two parameters, X and y, which contain all the data we want to train and test on, and\n#returns four objects: train_X, train_y, test_X, test_y:\n\n#You'll notice that there are two other parameters we used: test_size, which lets us control what proportions our data\n#are split into, and random_state. The train_test_split() function randomizes observations before dividing them, and\n#setting a random seed means that our results will be reproducible, which is important if you are collaborating, or\n#need to produce consistent results each time","fb4e9f26":"#code snippet:\nholdout = test # from now on we will refer to this\n               # dataframe as the holdout data\n\nfrom sklearn.model_selection import train_test_split\n\ncolumns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n       'Age_categories_Missing','Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior']\n\nall_X=train[columns]\nall_y=train[\"Survived\"]\n\ntrain_X,test_X,train_y,test_y=train_test_split(all_X,all_y,test_size=0.2,random_state=0)","0b7ed178":"#There are a number of ways to measure the accuracy of machine learning models,but when competing in Kaggle competition\n#we want to make sure we use the same method that Kaggle uses to calculate accuracy for that specific competition.\n\n#In this case, the evaluation section for the Titanic competition on Kaggle tells us that our score calculated as \n#\"the % of passengers correctly predicted\".This is by far the most common form of accuracy for binary classification.\n\n#In this case, our model correctly predicted three out of five values, so the accuracy based on this prediction set\n#would be 60%. Again, scikit-learn has a handy function we can use to calculate accuracy: metrics.accuracy_score().\n#The function accepts two parameters, y_true and y_pred, which are the actual vals and our predicted vals respectively\n#and returns our accuracy score.\n","4642ac33":"#code snippet:\nfrom sklearn.metrics import accuracy_score\nlr = LogisticRegression()\nlr.fit(train_X, train_y)\npredictions = lr.predict(test_X)\naccuracy = accuracy_score(test_y, predictions)\nprint(accuracy)","e54ad4c8":"#Our model has an accuracy score of 81.0% when tested against our 20% test set. Given that this data set is quite small\n#there is a good chance that our model is overfitting, and will not perform as well on totally unseen data.\n\n#To give us a better understanding of the real performance of our model, we can use a technique called cross validation\n#to train and test our model on different splits of our data, and then average the accuracy scores.\n\n#The most common form of cross validation, and the one we will be using, is called k-fold cross validation. 'Fold'\n#refers to each different iteration that we train our model on, and 'k' just refers to the number of folds.\n\n#We will use scikit-learn's model_selection.cross_val_score() function to automate the process. The basic syntax for\n#cross_val_score() is:\n\n#cross_val_score(estimator, X, y, cv=None)\n\n# estimator is a scikit-learn estimator object, like the LogisticRegression() objects we have been creating.\n# X is all features from our data set.\n# y is the target variables.\n# cv specifies the number of folds.\n\n#The function returns a numpy ndarray of the accuracy scores of each fold.\n#It's worth noting, the cross_val_score() function can use a variety of cross validation techniques and scoring types,\n#but it defaults to k-fold validation and accuracy scores for our input types.\n\n#Note:\n#we can also use tr-test-validation set approach.use tr to fit polynomials with degree from 1 to 10\n#then use valid set to select best polynomial (with lowest mse error) degree\n#then we use test set to find best model's accuracy.split is around 60-20-20 ","520b7b60":"#code snippet:\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\nlr = LogisticRegression()\nscores = cross_val_score(lr, all_X, all_y, cv=10)\naccuracy = np.mean(scores)\nprint(scores)\nprint(accuracy)","9274c762":"#From the results of our k-fold validation, we can see that the accuracy number varies with each fold - ranging btw\n#76.4% and 87.6%. This demonstrates why cross validation is important.\n\n#As it happens, our average accuracy score was 80.2%, which is not far from the 81.0% we got from our simple train\/test\n#split, however this will not always be the case, and you should always use cross-validation to make sure the error\n#metrics you are getting from your model are accurate.","d093edf3":"#code snippet:\ncolumns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n       'Age_categories_Missing','Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior']\nlr = LogisticRegression()\nlr.fit(all_X,all_y)\nholdout_predictions = lr.predict(holdout[columns])","3c06a2a1":"#The last thing we need to do is create a submission file. Each Kaggle competition can have slightly dif requirements\n#for the submission file. Here's what is specified on the Titanic competition evaluation page:\n\n#You should submit a csv file with exactly 418 entries plus a header row.Your submission will show an error if you have\n#extra columns (beyond PassengerId and Survived) or rows.\n\n# The file should have exactly 2 columns:\n\n# PassengerId (sorted in any order)\n# Survived (contains your binary predictions: 1 for survived, 0 for deceased)\n\n# The table below shows this in a slightly easier to understand format, so we can visualize what we are aiming for.\n\n# PassengerId\tSurvived\n# 892\t0\n# 893\t1\n# 894\t0\n\n#We will need to create a new dataframe that contains the holdout_predictions we created in the previous screen and the\n#PassengerId column from the holdout dataframe. We don't need to worry about matching the data up, as both of these\n#remain in their original order.\n\n#To do this, we can pass a dictionary to the pandas.DataFrame() function:","fa9bb9af":"#code snippet:\n\n# holdout_ids = holdout[\"PassengerId\"]\n# submission_df = {\"PassengerId\": holdout_ids,\n#                  \"Survived\": holdout_predictions}\n# submission = pd.DataFrame(submission_df)\n\n# submission.to_csv(\"submission.csv\",index=False)","98884edf":"import pandas as pd\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","6ef3fa3f":"import pandas as pd\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","09ef4d31":"## Making predictions on unseen data","9a8932dc":"## Exploring the Data","ee534daa":"## Preparing Data for Machine Learning","ebd0e8f6":"## Creating a Submission File","d0891e61":"## Using Cross Validation for More Accurate Error Measurement","c6042ef9":"## Creating First Machine Learning Model","fe615431":"## Splitting Training Data","cf431977":"## Making Predictions and Measuring their Accuracy","613d17aa":"## Exploring and Converting the Age Column"}}