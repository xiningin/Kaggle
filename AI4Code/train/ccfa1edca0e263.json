{"cell_type":{"bfb872f9":"code","8cc2d35f":"code","261afd83":"code","639a2827":"code","8bb261d7":"code","6debcf4e":"code","f586f7b1":"code","ed9f29e8":"code","4e14a796":"code","4d12e9f5":"code","f1bf2808":"code","2ab60759":"code","6bf65679":"code","36d0ab6d":"code","aa4d1ca7":"code","510c3782":"code","bacf4dca":"code","c6c11d0a":"code","90f53653":"code","0ab03229":"code","f0357eb4":"code","48ffa8e0":"code","e19c801a":"code","86260cae":"code","c89d0f15":"code","0a0dd119":"code","80495b29":"code","edde4ea7":"code","de8146aa":"code","03a8f59a":"code","30a5ee71":"code","058bde5c":"code","e5971193":"code","02834f5d":"code","19662ebf":"code","f955863e":"code","47cf345a":"code","6b4ed4e4":"code","ae90e406":"markdown","a6034392":"markdown","02f8c90b":"markdown","97189f3a":"markdown","82137c6e":"markdown","5a323fcf":"markdown","45285830":"markdown","94c8379b":"markdown","b57407cb":"markdown","c52c2ad9":"markdown","8cf7ea76":"markdown","722de8a0":"markdown","7cb390d1":"markdown","113426d7":"markdown","6a9f580f":"markdown"},"source":{"bfb872f9":"# packages\n\n# basics\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# stats\nimport scipy.stats\nfrom fitter import Fitter, get_common_distributions, get_distributions","8cc2d35f":"# color for plots\nmy_color = 'darkcyan'\n\n# percentile vector\nmy_percs = [0.01,0.05,0.1,0.25,0.5,0.75,0.9,0.95,0.99]","261afd83":"# load minimum version of data, this takes a few minutes nevertheless...\nmy_cols = ['time_id', 'investment_id', 'target']\n\nt1 = time.time()\ndf = pd.read_csv('..\/input\/ubiquant-market-prediction\/train.csv', usecols=my_cols)\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,2))","639a2827":"# first glance\ndf.head()","8bb261d7":"# dimension\ndf.shape","6debcf4e":"# time_id frequencies\ndf.time_id.value_counts()","f586f7b1":"# investment_id frequencies\ndf.investment_id.value_counts()","ed9f29e8":"# check \"availability\" of time \/ investment combinations:\ngaps = pd.crosstab(df.time_id, df.investment_id)\n\nplt.figure(figsize=(16,30))\nsns.heatmap(gaps, cbar=False)\nplt.show()","4e14a796":"# export \"availabilty matrix\"\ngaps.to_csv('gaps.csv')","4d12e9f5":"# look at a \"sparse\" example\nmy_id = 232\ndf_sparse = df[df.investment_id==my_id]\ndf_sparse","f1bf2808":"# plot example with multiple gaps\nplt.figure(figsize=(14,4))\nplt.scatter(df_sparse.time_id, df_sparse.target, alpha=0.25, color=my_color)\nplt.xlabel('time_id')\nplt.ylabel('target')\nplt.title('Investment id=' + str(my_id))\nplt.grid()\nplt.show()","2ab60759":"# target\nplt.figure(figsize=(10,4))\ndf.target.plot(kind='hist', bins=100, color=my_color)\nplt.title('Target - All Investments')\nplt.grid()","6bf65679":"# boxplot\nplt.figure(figsize=(10,4))\nplt.boxplot(df.target, vert=False)\nplt.title('Target - All Investments')\nplt.grid()\nplt.show()","36d0ab6d":"# basic stats\ndf.target.describe(percentiles=my_percs)","aa4d1ca7":"# mean by investment\nplt.figure(figsize=(12,4))\ndf.groupby(by='investment_id').target.mean().plot(color=my_color, alpha=0.5)\nplt.title('Mean by investment')\nplt.grid()\nplt.show()","510c3782":"# let's check the extremely high value\nprint('Outlier mean =', df[df.investment_id==85].target.mean())\ndf[df.investment_id==85]","bacf4dca":"# standard deviation by investment\nplt.figure(figsize=(12,4))\ndf.groupby(by='investment_id').target.std().plot(color=my_color, alpha=0.5)\nplt.title('Stdev by investment')\nplt.grid()\nplt.show()","c6c11d0a":"# let's check the stdev=0 outlier\nprint('Outlier stdev =', df[df.investment_id==1415].target.std())\ndf[df.investment_id==1415]","90f53653":"my_id = 2140\ndf_ex = df[df.investment_id==my_id]","0ab03229":"# plot time series\nplt.figure(figsize=(14,4))\nplt.scatter(df_ex.time_id, df_ex.target, alpha=0.25, color=my_color)\nplt.plot(df_ex.time_id, df_ex.target, alpha=0.5, color=my_color)\nplt.xlabel('time_id')\nplt.ylabel('target')\nplt.grid()\nplt.title('Investment id=' + str(my_id))\nplt.show()","f0357eb4":"# zoom in\nta = 0\ntb = 200\nplt.figure(figsize=(14,4))\nplt.scatter(df_ex[ta:tb].time_id, df_ex[ta:tb].target, alpha=0.25, color=my_color)\nplt.plot(df_ex[ta:tb].time_id, df_ex[ta:tb].target, alpha=0.5, color=my_color)\nplt.xlabel('time_id')\nplt.ylabel('target')\nplt.grid()\nplt.title('Investment id=' + str(my_id) + ' - Subset')\nplt.show()","48ffa8e0":"# plot target for specific investment\nplt.figure(figsize=(10,4))\ndf_ex.target.plot(kind='hist', bins=50, color=my_color)\nplt.title('Target - Investment id=' + str(my_id))\nplt.grid()","e19c801a":"# boxplot\nplt.figure(figsize=(10,4))\nplt.boxplot(df_ex.target, vert=False)\nplt.title('Target - Investment id=' + str(my_id))\nplt.grid()\nplt.show()","86260cae":"# basic stats\ndf_ex.target.describe(percentiles=my_percs)","c89d0f15":"# try to fit a few distribution types to target\n# for full list of available distributions use \"get_distributions()\"\ndist_fits = Fitter(df_ex.target, distributions=['lognorm','norm','beta','t'])\ndist_fits.fit()\nplt.figure(figsize=(12,5))\ndist_fits.summary()","0a0dd119":"# check for autocorrelations\nplt.figure(figsize=(10,5))\nplt.acorr(df_ex.target, maxlags=20, color=my_color)\nplt.title('Autocorrelations of Target - Investment id=' + str(my_id))\nplt.grid()\nplt.show()","80495b29":"# pick two investments over the SAME time grid\ndf_1 = df[df.investment_id==2385]\ndf_2 = df[df.investment_id==1062]","edde4ea7":"# scatter plot - please note that we have chosen two completely aligned time series!\nplt.figure(figsize=(7,6))\nplt.scatter(df_1.target, df_2.target, alpha=0.25, color='darkcyan')\nplt.title('Investment 1062 vs 2385')\nplt.xlabel('Investment 2385 - target')\nplt.ylabel('Investment 1062 - target')\nplt.grid()\nplt.show()","de8146aa":"# correlation of the two investments\nscipy.stats.pearsonr(df_1.target,df_2.target)","03a8f59a":"# import a subset of features\nmy_feats = ['f_0','f_1','f_2','f_3','f_4',\n            'f_5','f_6','f_7','f_8','f_9']\n\nt1 = time.time()\ndf_f = pd.read_csv('..\/input\/ubiquant-market-prediction\/train.csv', usecols=my_feats)\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,2))","30a5ee71":"# basic stats\ndf_f.describe(percentiles=my_percs)","058bde5c":"# plot distributions\nfor f in my_feats:\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,7))\n    \n    ax1.hist(df_f[f], bins=50, color=my_color)\n    ax1.grid()\n    ax1.set_title('Feature ' + f)\n    \n    ax2.boxplot(df_f[f], vert=False)\n    ax2.grid()\n    ax2.set_title('')\n    \n    plt.show()","e5971193":"# calc correlation matrices (Pearson and rank correlation)\ncorr_pearson = df_f.corr(method='pearson')\ncorr_spearman = df_f.corr(method='spearman')","02834f5d":"# plot corr matrices\nplt.figure(figsize=(10,16))\nax1 = plt.subplot(2,1,1)\nsns.heatmap(corr_pearson, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation')\n\nax2 = plt.subplot(2,1,2, sharex=ax1)\nsns.heatmap(corr_spearman, annot=True, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Spearman Correlation')\nplt.show()","19662ebf":"# example of correlated features:\nplt.scatter(df_f.f_2, df_f.f_3, alpha=0.2, color=my_color)\nplt.xlabel('f_2')\nplt.ylabel('f_3')\nplt.title('Feature f_3 vs f_2')\n\n# add regression line\nxx = df_f.f_2\nyy = df_f.f_3\nmm,bb = np.polyfit(xx,yy,1)\nplt.plot(xx, mm*xx + bb, c='darkblue')\nplt.grid()\nplt.show()","f955863e":"# plot features as time series\nfor f in my_feats:\n    plt.figure(figsize=(14,4))\n    plt.scatter(df.time_id, df_f[f], alpha=0.1, color=my_color)\n    plt.xlabel('time')\n    plt.ylabel('feature')\n    plt.title('Feature ' + f)\n    plt.grid()\n    plt.show()","47cf345a":"# zoom in a feature development\nplt.figure(figsize=(14,4))\nplt.scatter(df.time_id, df_f.f_1, alpha=0.125, color=my_color)\nplt.xlabel('time')\nplt.ylabel('feature')\nplt.title('Feature f_1 - Zoom')\nplt.grid()\nplt.xlim(0,30)\nplt.show()","6b4ed4e4":"for f in my_feats:\n    c = scipy.stats.pearsonr(df_f[f],df.target)[0]\n    c = np.round(c,4)\n    plt.scatter(df_f[f], df.target, color=my_color, alpha=0.1)\n    plt.title('Target vs ' + f + '; corr = ' + str(c))\n    plt.grid()\n    plt.show()","ae90e406":"### Feature distributions:","a6034392":"#### We have more than 3 million rows here...","02f8c90b":"### Correlation:","97189f3a":"<a id='pick_ex'><\/a>\n# Pick an example investment","82137c6e":"### Development of features over time:","5a323fcf":"# Visual Exploration of the Data - Table of Contents\n* [Import and first EDA](#import_eda)\n* [Pick an example investment](#pick_ex)\n* [Compare two investments](#compare)\n* [Check some features](#feat)","45285830":"#### We can see that the features do not only depend on time but are also different depending on the specific investment.","94c8379b":"#### We have investments that are only sparsely available... Let's try to visualize (black: not available): ","b57407cb":"### Target","c52c2ad9":"<a id='feat'><\/a>\n# Check some features","8cf7ea76":"### Plot Target vs. Features:","722de8a0":"<a id='compare'><\/a>\n# Compare two investments","7cb390d1":"<a id='import_eda'><\/a>\n# Import and first EDA","113426d7":"#### We observe a moderate correlation at lag 1, the others seem to be negligible...","6a9f580f":"#### We load only a (column-wise) subset due to the massive size of the data set. The full training data contains additional row_id (being concatentation of time_id and investment_id) and 300 numerical features (f_0..f_299):"}}