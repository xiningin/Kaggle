{"cell_type":{"ae247211":"code","c080e1d2":"code","85c64e52":"code","3a67b828":"code","13ae672e":"code","71a882c2":"code","4bb28895":"code","d581d4d4":"code","8bec1b53":"code","e5ee0566":"code","746a874c":"code","0379f0d0":"code","39d9699a":"code","482eb692":"code","2c9a0c12":"code","6eded76f":"code","9e23d231":"code","0c70fb08":"code","e0183e12":"code","7579e147":"code","e316230d":"code","49bb65ce":"code","8cca80a3":"code","7658c143":"code","98d14ea2":"code","4ad63f8c":"code","ecd2709e":"code","3a9e934a":"code","101b8a46":"code","566837ea":"code","3cf00b0b":"code","be0e1612":"code","5476063e":"code","a7a9433e":"code","2a5db2b8":"code","a98f26b5":"code","303bcf93":"code","94dc7cdc":"markdown","f13da81f":"markdown","bb263e34":"markdown","0c584aec":"markdown","a211004d":"markdown","758d198d":"markdown","598df9c7":"markdown","e1f43621":"markdown","0d1af35e":"markdown","68544dff":"markdown","850d1cf2":"markdown","8a18a9fe":"markdown","c9d4beca":"markdown","03a3b6c5":"markdown","e5b6f81e":"markdown","71254a5f":"markdown","e3474840":"markdown","181ca6af":"markdown","af64c782":"markdown","a877efe4":"markdown","e3724efb":"markdown","437cc07a":"markdown","e6a7f4fa":"markdown","0819530d":"markdown","338cd26a":"markdown","6f145793":"markdown","d9c48547":"markdown","bd8bda4a":"markdown","9af8476f":"markdown","67bbbd3c":"markdown","a384d770":"markdown","a42bbd6c":"markdown"},"source":{"ae247211":"#importing nesseray common libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as n\nfrom datetime import datetime\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","c080e1d2":"df_train = pd.read_csv(r\"..\/input\/into-the-future\/train.csv\")\ndf_test = pd.read_csv(r'..\/input\/into-the-future\/test.csv')\ndf_train_originall = df_train.copy()\ndf_test_originall = df_test.copy()","85c64e52":"print('Train set',df_train.columns)\nprint('Test set',df_test.columns)","3a67b828":"df_train.dtypes","13ae672e":"df_test.dtypes","71a882c2":"df_train['Datetime'] = pd.to_datetime(df_train['time'],format='%Y-%m-%d %H:%M:%S')\ndf_test['Datetime'] = pd.to_datetime(df_test['time'],format='%Y-%m-%d %H:%M:%S')","4bb28895":"df_train = df_train.drop('time',1)\ndf_test = df_test.drop('time',1)","d581d4d4":"df_train_original = df_train.copy()\ndf_test_original = df_test.copy()","8bec1b53":"for i in (df_train,df_test,df_test_original,df_train_original):\n    i['year'] = i.Datetime.dt.year\n    i['Month'] = i.Datetime.dt.month\n    i['Hour'] = i.Datetime.dt.hour\n    i['day'] = i.Datetime.dt.day\n# df_train['week_days'] = df_train['Datetime'].dt.dayofweek\nfor i in (df_train,df_test,df_test_original,df_train_original):\n    i['minute'] = i.Datetime.dt.minute\ndf_train['minute'] = df_train['Datetime'].dt.minute","e5ee0566":"def applyer(row):\n    if row.dayofweek == 5 or row.dayofweek == 6:\n        return 1\n    else:\n        return 0\ntemp2 = df_train['Datetime'].apply(applyer)\ndf_train['weekend'] = temp2","746a874c":"df_train.index = df_train['Datetime']\ndf = df_train.drop('id' , 1) ","0379f0d0":"ts = df['feature_2']\nplt.figure(figsize=(16,8)) \n\nplt.plot(ts,label='Feature_2')\n# plt.plot(df['feature_1'],label='Other_feture')\nplt.title('Time Series') \nplt.xlabel(\"Time\") \nplt.ylabel(\"number_count\") \nplt.legend()","39d9699a":"import seaborn as sns\nsns.jointplot(x='feature_1',y='feature_2',data=df_train)","482eb692":"df_train.groupby('year')['feature_2'].mean().plot.bar()","2c9a0c12":"df_train.groupby('Hour')['feature_2'].mean().plot.bar()","6eded76f":"df_train.groupby(['Month','minute'])['feature_2'].mean().plot.bar()","9e23d231":"df_train = df_train_originall\ndf_test = df_test_originall","0c70fb08":"df_train['time'] = pd.to_datetime(df_train['time'],format='%Y-%m-%d %H:%M:%S')\ndata = df_train.drop('time',1)\ndata.index = df_train['time']\ndata = data.drop('id',1)\n\n\n#missing value treatment\ncols = data.columns\nfor j in cols:\n    for i in range(0,len(data)):\n       if data[j][i] == -200:\n           data[j][i] = data[j][i-1]","e0183e12":"train = data[:int(0.8*(len(data)))]\nvalid = data[int(0.8*(len(data))):]\nttrain = train.copy()\nvvalid = valid.copy()","7579e147":"from statsmodels.tsa.vector_ar.var_model import VAR\nimport numpy as np\n\nmodel = VAR(endog=np.asarray(train))\nmodel_fit = model.fit()\nprediction = model_fit.forecast(model_fit.y, steps=len(valid))\nvalid.index = range(0,len(valid))","e316230d":"pred = pd.DataFrame(index=range(0,len(prediction)),columns=[cols])\nfor j in range(0,2):\n    for i in range(0, len(prediction)):\n       pred.iloc[i][j] = prediction[i][j]\n\n#check RMSE\nimport math  \nfrom sklearn.metrics import mean_squared_error\npred.columns = [x[0] for x in pred.columns]\nfor i in cols:\n#     print(pred[i], valid[i])\n    print('rmse value for', i, 'is : ', math.sqrt(mean_squared_error(pred[i], valid[i])))","49bb65ce":"#let's chenge our valid index to original index.\nvalid.index = vvalid.index\npred.index = vvalid.index","8cca80a3":"plt.plot(pred['feature_2'])\nplt.plot(train['feature_2'])\nplt.plot(valid.iloc[:,1:2], '--')\nplt.show()","7658c143":"# # let's perform the same preprocessing step on train data as we performed on Training set\ndf_test['time'] = pd.to_datetime(df_test['time'],format='%Y-%m-%d %H:%M:%S')\npred = df_test.drop('time',1)\npred.index = df_test['time']\npred = pred.drop('id',1)\ncols = data.columns","98d14ea2":"prediction = model_fit.forecast(model_fit.y, steps=len(pred))","4ad63f8c":"if len(prediction) == len(df_test):\n    prediction = pd.DataFrame(prediction,columns=['feature_1','feature_2'],index=range(0, len(prediction), 1))\n    pred['feature_2'] = list(prediction['feature_2'])\n    print(\"Length mached\")\nelse:\n    print(\"Length Does Not Matched\")","ecd2709e":"plt.plot(pred['feature_2'])\nsns.jointplot(x='feature_1',y='feature_2',data=valid)","3a9e934a":"prediction['id'] = index=range(564, 564+len(prediction), 1)\nprediction.index = prediction['id']\n","101b8a46":"prediction =prediction.drop(['id','feature_1'],1)","566837ea":"prediction","3cf00b0b":"prediction.to_csv('Solution.csv')","be0e1612":"df_train = pd.read_csv(r\"..\/input\/into-the-future\/train.csv\")\ndf_test = pd.read_csv(r'..\/input\/into-the-future\/test.csv')","5476063e":"df_train['time'] = pd.to_datetime(df_train['time'],format='%Y-%m-%d %H:%M:%S')\ndata = df_train.drop('time',1)\ndata.index = df_train['time']\ndata = data.drop('id',1)\n\n\n#missing value treatment\ncols = data.columns\nfor j in cols:\n    for i in range(0,len(data)):\n       if data[j][i] == -200:\n           data[j][i] = data[j][i-1]\n\ntrain = data[:int(0.8*(len(data)))]\nvalid = data[int(0.8*(len(data))):]","a7a9433e":"from statsmodels.tsa.statespace.varmax import VARMAX\n\nmodel = VARMAX(train, order = (1,2))\nmodel_fit = model.fit()","2a5db2b8":"predictions_multi = model_fit.forecast( steps=len(valid))","a98f26b5":"plt.plot(train['feature_2'],label='Train')\nplt.plot(valid['feature_2'],label = 'valid')\nplt.plot(predictions_multi.iloc[:,1:2], '--',label= 'predictions')\n\nplt.title('Time Series') \nplt.xlabel(\"Time\") \nplt.ylabel(\"feature_2\") \nplt.legend()\nplt.show()","303bcf93":"predictions_multi.columns = valid.columns\nfor i in cols:\n    \n#     print(pred[i], valid[i])\n    print('rmse value for', i, 'is : ', math.sqrt(mean_squared_error(predictions_multi[i], valid[i])))","94dc7cdc":"### now we will start to explore the data\ngetting values of year month hour and day for exploration","f13da81f":"we need to set index as date to Start Analysis of data","bb263e34":"it seeames there are some outliers are present. but only one is present so i am leaveing this as it is.\n\nour data is yearly distributed or only one year we can check it by ploting","0c584aec":"now we will calculate the prediction on future unkown values of Feture_2","a211004d":"we can see only 2 hours are present have no much diffrence in values. it wont give us much insights\n\nnow let's try to at understand data by grouping Month and minute","758d198d":" we can see the how the fetures is distrubuted in single time, code is given below.","598df9c7":"## Prediction on unknown Values","e1f43621":"### Summary:  tarining error achived\n> #### rmse value for feature_1 is :  29.301804808596287\n> #### rmse value for feature_2 is :  505.620846776973","0d1af35e":"Forcasting The values","68544dff":" # 1. model creation VECTOR AUTO REGRESSION \nwe are selecting this model, since there are 2 features 1) date and 2) feture_1 affecting the target. therfore it is a multivariate time series problem.","850d1cf2":"let's create our model by impoerting VARMAX from statsmodels","8a18a9fe":"we can check the insights of Forcasting based on week days and weekends.","c9d4beca":"Now let's see how the our data is distributed","03a3b6c5":"after convering we not more needed time column since it was converted and stored in Datetime ","e5b6f81e":"## Conclusion: \n##### i have tested with diffrent parameters. and this is the model with best parametaers.\n*Prediction of this model was not better compared to prevous model. therefore we can consider our previous model.*\n\n> #                                             *Thank you*","71254a5f":"looking up the columns we have in the train and test set","e3474840":"checking wether the length of the actual and predicted was same so that we can concatinate both of them","181ca6af":"This Step is Same as In preivious VAR model preprocessing","af64c782":"preproccesing same as we did in previous section.\nand hear we also handle missing values, if any are present","a877efe4":"hear we can see our model performance based on rmse value for feature_1 we got 29.301804807619025 and on feature_2 we got 505.62084678844263\n\nnow lets see how our model is performence by plotiing graph","e3724efb":"let's check our RMSE value","437cc07a":"This looks so messy. hence no insight hear also so it was getting harder to make assumptions.\n\nNow let,s contnue by creating our model","e6a7f4fa":"# Creating a dataframe for Submission","0819530d":"visualizing how our model is getting trained","338cd26a":"only one year data given that is 2019\n\n### now let's see how our data is distributed based on time hours","6f145793":"looking up the data types, hear we can see our time is in object we need to convert it into datetime object.","d9c48547":"keeping the copy of original data before changing further","bd8bda4a":"there is no missing values in this data set.\n\nnow let's divide our training data to caleculate performance and we will keep a copy of splitted data for future use at the time of submission","9af8476f":"importing the dataset","67bbbd3c":"# 2. VARMAX model\n\n> ### note:  other models we can use for multivariate dataset are\n> Vector Autoregression Moving-Average (VARMA),\n> Holt Winter's Exponential Smoothing (HWES)\n\nnow, we let's forget about privious model and start a fresh model by once agin importing data. we can use copy()\nbut we need to scroll up again and agin, that in what variable we copied.\nThis is small data set so we can load again","a384d770":"we can see that time is changeing by 15 min with respect to that our Fature 2 is going upwards.\n\nnow lets try to plot joint plot for both fetures using seaborn library","a42bbd6c":"# Data Spliting\nlet's take our copy of datset and start by fresh implementation "}}