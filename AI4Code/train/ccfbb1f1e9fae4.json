{"cell_type":{"4ab98ca4":"code","d269ba43":"code","ecb29e56":"code","dc650fb6":"code","20559545":"code","068a102a":"code","c08c3391":"code","e9d119ea":"code","15cb0780":"code","444d1621":"code","db5de4cd":"code","702b4a49":"code","fe78f17a":"code","a7ddc6e3":"code","47ad21e7":"code","90057a7c":"code","5e157b49":"code","2800d5c0":"code","8695c406":"code","9d43742a":"code","33a0cd3d":"code","6206bb43":"code","2cf0c626":"code","143d4588":"code","da64392b":"code","ee3dca97":"code","f8927753":"code","c24f3bb9":"code","31a16eb6":"code","ae9bf4f5":"code","55e36a06":"markdown","0632ed2f":"markdown","5816195e":"markdown","299c1810":"markdown","d5a7e72f":"markdown","bdf896c3":"markdown","a590146d":"markdown","f8480665":"markdown","2d7a7d11":"markdown","8eff537b":"markdown","09ee6ae6":"markdown","779426ef":"markdown","75fb4f74":"markdown","fe8037e8":"markdown","d9792d0b":"markdown","672c0227":"markdown","e54c2bcc":"markdown","37560d4f":"markdown","fd95abab":"markdown","c4c03195":"markdown","33818c46":"markdown","772178a2":"markdown","59950eb5":"markdown","e3798e72":"markdown","c6280a81":"markdown","39a8ca1f":"markdown","37be4311":"markdown","009b1cb4":"markdown","09ec873c":"markdown","3b98eb16":"markdown","e6ddeb01":"markdown","89da6b9a":"markdown"},"source":{"4ab98ca4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d269ba43":"data = pd.read_csv(\"\/kaggle\/input\/deep-learning-az-ann\/Churn_Modelling.csv\")\ndata.head()","ecb29e56":"data.drop([\"RowNumber\",\"CustomerId\",\"Surname\"], axis=1, inplace = True)","dc650fb6":"data.head(2)","20559545":"# CreditScore, Age, Tenure, Balance, EstimatedSalary to be rescaled:\n\nfor each in [\"CreditScore\", \"Age\",\"Tenure\", \"Balance\", \"EstimatedSalary\"]:\n    data[each] = (data[each] - np.min(data[each])) \/ (np.max(data[each])-np.min(data[each]))\n","068a102a":"data.head()","c08c3391":"# looking at current types:\ndata.info()","e9d119ea":"# converting type of some features to category\nfor each in [\"Geography\",\"Gender\",\"NumOfProducts\",\"HasCrCard\",\"IsActiveMember\",\"Exited\"]:\n    data[each] = data[each].astype(\"category\")","15cb0780":"# types after conversion\ndata.info()","444d1621":"data.info()","db5de4cd":"data = pd.get_dummies(data, columns = [\"Geography\",\"Gender\", \"NumOfProducts\"])","702b4a49":"data.head()","fe78f17a":"data.info()","a7ddc6e3":"X_train = data.drop(columns = [\"Exited\"], axis=1)","47ad21e7":"y_train = data[\"Exited\"]","90057a7c":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_train, \n    y_train,\n    test_size = 0.33,\n    random_state = 42\n)\n\nprint(\"Length of X_train: \",len(X_train))\nprint(\"Length of X_test: \",len(X_test))\nprint(\"Length of y_train: \",len(y_train))\nprint(\"Length of y_test: \",len(y_test))","5e157b49":"print(\n    \"Shape of X_train: \",np.shape(X_train),\n    \"\\nShape of y_train: \",np.shape(y_train)\n)","2800d5c0":"from sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = pd.DataFrame(sc_x.fit_transform(X_train), columns=X_train.columns.values)\nX_test = pd.DataFrame(sc_x.transform(X_test), columns=X_test.columns.values)","8695c406":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.models import Sequential     # Neural network library\nfrom keras.layers import Dense          # layer library\n","9d43742a":"def create_model():\n    \n    # create model\n    model = Sequential()\n    \n    # adding input layer\n    model.add(Dense(units = 12, kernel_initializer = \"uniform\", activation = \"relu\", input_dim = 16))\n    \n    # adding layer\n    model.add(Dense(units = 8, kernel_initializer = \"uniform\", activation = \"relu\"))\n    \n    # adding layer\n    model.add(Dense(units = 4, kernel_initializer = \"uniform\", activation = \"relu\"))\n        \n    # adding output layer\n    model.add(Dense(units = 1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n    \n    # compile model\n    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n    \n    return model    ","33a0cd3d":"model1 = KerasClassifier(build_fn = create_model, epochs=15)","6206bb43":"history1 = model1.fit(X_train,y_train)","2cf0c626":"model2 = KerasClassifier(build_fn = create_model, epochs=15, batch_size = 10)\nhistory2 = model2.fit(X_train, y_train)","143d4588":"plt.subplots(figsize = (10,6))\nplt.plot(history1.history[\"accuracy\"], label = \"Batch size = 32\")\nplt.plot(history2.history[\"accuracy\"], label = \"Batch size = 10\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracies\")\nplt.title(\"Affects of batch size on accuracy on ANN\")\nplt.grid(axis = \"both\")\n\nplt.legend()\nplt.show()\n","da64392b":"model = KerasClassifier(build_fn = create_model, epochs=15, batch_size = 10)\nkfold = StratifiedKFold(n_splits = 15, shuffle = True, random_state = 42)\naccuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = kfold)","ee3dca97":"plt.subplots(figsize = (10,6))\nplt.plot(accuracies)\nplt.xlabel(\"K-fold values of Cross Validation Score\")\nplt.ylabel(\"Accuracies\")\nplt.title(\"Cross Validation Accuracies vs K-Folds of ANN\")\nplt.grid(axis = \"both\")\n\nplt.show()","f8927753":"print(\"Best accuracy : {} @ k-fold value of {}\".format(round(accuracies.max()*100,2),accuracies.argmax()))","c24f3bb9":"from sklearn.model_selection import GridSearchCV\n\ndef create_model1(optimizer=\"rmsprop\", init=\"glorot_uniform\"):\n        \n    # create model\n    model = Sequential()\n    \n    # adding input layer\n    model.add(Dense(units = 12, kernel_initializer = init, activation = \"relu\", input_dim = 16))\n    \n    # adding layer\n    model.add(Dense(units = 8, kernel_initializer = init, activation = \"relu\"))\n    \n    # adding layer\n    model.add(Dense(units = 4, kernel_initializer = init, activation = \"relu\"))\n        \n    # adding output layer\n    model.add(Dense(units = 1, kernel_initializer = init, activation = \"sigmoid\"))\n    \n    # compile model\n    model.compile(loss = \"binary_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n    \n    return model  \n    ","31a16eb6":"# create model\nmodel_new = KerasClassifier(build_fn = create_model1, epochs = 15, batch_size = 32)\n\n# grid search epochs, batch size and optimizer\noptimizers = ['rmsprop', 'adam']\ninit = ['glorot_uniform', 'uniform']\n\nparam_grid = dict(optimizer = optimizers, init = init)\ngrid = GridSearchCV(estimator = model_new, param_grid = param_grid)\n\nresult = grid.fit(X_train, y_train)\n","ae9bf4f5":"# summarize results\nprint(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\nmeans = result.cv_results_['mean_test_score']\nstds = result.cv_results_['std_test_score']\nparams = result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","55e36a06":"The story: A bank is investigating a very high rate of customer leaving the bank. Here is a 10.000 records dataset to investigate and predict which of the customers are more likely to leave the bank soon","0632ed2f":"<a id=\"6.1.4\"><\/a>\n## 6.1.4. Normalizing (Rescaling) data ","5816195e":"<a id=\"6.2.4\"><\/a>\n## 6.2.4. Modelling Using KerasClassifier","299c1810":"<a id=\"6.2.4.2\"><\/a>\n### 6.2.4.2. Creating model with default `batch_size`","d5a7e72f":"<a id=\"6.2.3\"><\/a>\n## 6.2.3. Feature Scaling","bdf896c3":"<a id=\"6.2.1\"><\/a>\n## 6.2.1. Creating X_train and y_train","a590146d":"Evaluating using 15-fold cross validation:","f8480665":"<a id=\"6.1.2\"><\/a>\n## 6.1.2. Reading Data","2d7a7d11":"* We will use a grid search to evaluate different configurations for our neural network model.\n* And we will report the combination that provides the best-estimated performance.","8eff537b":"<a id=\"6.2.4.6\"><\/a>\n### 6.2.4.6. Deep learning with Grid Search","09ee6ae6":"* In this notebook, i will create an ANN model: Multi-layer NN using KerasClassifier.\n* I did also EDA, Visualisation and Machine Learning study for same topic in my notebook linked below.\n* You can have a look and vote if you enjoy.\n\n\n  https:\/\/www.kaggle.com\/ozkanozturk\/ml-model-with-86-7-accuracy","779426ef":"* KerasClassifier class in Keras takes an argument `build_fn` which is the name of the function to call to get your model.\n* We must define a function that defines our model, compiles it and returns it.\n* Defining function named as `create_model` :","75fb4f74":"<a id=\"6.2.4.1\"><\/a>\n### 6.2.4.1. Defining a function to pass by build_fn argument","fe8037e8":"* `epochs`: generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation.\n* We have 6700 samples in our train data; in one epoch, one forward and backward propogation to be passed for all 6700 samples and one accuracy to be calculated.\n* When we get **epochs** as 10; it means that 10 forward-backward to be passed and 10 accuracies to be calculated.\n* `batch_size`: Number of samples per gradient update. If unspecified, batch_size will bedefault to 32.","d9792d0b":"<a id=\"6.1.6\"><\/a>\n## 6.1.6. Converting some columns to categoricals(Numericals)","672c0227":"<a id=\"6.1.5\"><\/a>\n## 6.1.5. Converting data types to categorical","e54c2bcc":"* From above output:\n* We saw that 15 epochs and 210 iterations for each epoch.\n* Because the default batch size is 32; we had 6700 samples \/ 32 = 210 batches for each epoch.\n* Parameters (weights and bias) were updated and accuracy re-calculated after each batch in each epoch.\n* For example: in 1st epoch, parameters and accuracy calculated (with 32 samples) after 1st batch (1\/210).\n* Then parameters and accuracy re-calculated (with 32 samples) after 2nd batch (2\/210).\n* Then parameters and accuracy re-calculated (with 32 samples) after 3rd batch (3\/210); so on and so on.","37560d4f":"* Geography ---> Geography_France \/ Geography_Spain \/ Geography_Germany\n* Gender ---> Gender_Female \/ Gender_Male\n* NumOfProducts ---> NumOfProducts_1 \/ NumOfProducts_2 \/ NumOfProducts_3 \/ NumOfProducts_4 ","fd95abab":"<a id=\"6.2.4.3\"><\/a>\n### 6.2.4.3. Fitting model","c4c03195":"* Rescaling data to have values between 0 and 1. \n* This is usually called feature scaling. One possible formula to achieve this is:\n![image.png](attachment:image.png)","33818c46":"* Decreasing batch size will increase the iteration number as well as computation time and cpu usage.","772178a2":"<a id=\"6.1\"><\/a>\n# 6.1. DATA PREPARATION","59950eb5":"<a id=\"6.2\"><\/a>\n# 6.2 MULTI LAYER NEURAL NETWORK WITH KERAS","e3798e72":"[6.1. Data Preparation](#6.1) <br>\n>[6.1.1. Loading Libraries](#6.1.1) <br>\n>[6.1.2. Reading Data](#6.1.2) <br>\n>[6.1.3. Dropping unnecessary columns](#6.1.3) <br>\n>[6.1.4. Normalizig\/Rescaling Data](#6.1.4) <br>\n>[6.1.5. Converting data types to Categorical](#6.1.5) <br>\n>[6.1.6. Converting columns to Categorical](#6.1.6) <br>\n\n[6.2. Multi-Layer Neural Network with Keras](#6.2) <br>\n>[6.2.1. Creating X_train, y_train](#6.2.1) <br>\n>[6.2.2. Train-Test split](#6.2.2) <br>\n>[6.2.3. Feature Scaling with StandardScaler](#6.2.3) <br>\n>[6.2.4. Modelling Using KerasClassifier](#6.2.4) <br>\n>>[6.2.4.1. Defining a function to pass by `build_fn` argument](#6.2.4.1) <br>\n>>[6.2.4.2. Creating Model with default `batch_size`](#6.2.4.2) <br>\n>>[6.2.4.3. Fiting Model](#6.2.4.3) <br>\n>>[6.2.4.4. Creating Model with a decreased `batch_size`](#6.2.4.4) <br>\n>>[6.2.4.5. Evaluating model with `cross_val_score` and `StratifiedKFold`](#6.2.4.5) <br>\n>>[6.2.4.6 Deep Learning with Grid Search](#6.2.4.6) <br>","c6280a81":"<a id=\"6.2.4.4\"><\/a>\n### 6.2.4.4. Creating model with a decreased `batch_size`","39a8ca1f":"<a id=\"6.2.4.5\"><\/a>\n### 6.2.4.5. Evaluating model with `cross_val_score` and `StratifiedKFold`","37be4311":"* From above info, although there are some categorical columns (such as Gender:Male-Female); data types are not categorical.\n* They are object (as in Gender), integer (as in HasCrCard and Exited)\n* So, i need to convert data types to categorical.\n* Thus we prevent model to get 1 and 0 as weights of features.","009b1cb4":"<a id=\"6.2.2\"><\/a>\n## 6.2.2. Train - Test split","09ec873c":"<a id=\"6.1.3\"><\/a>\n## 6.1.3. Dropping unnecessary columns","3b98eb16":"# 6. DEEP LEARNING USING ARTIFICIAL NEURAL NETWORK","e6ddeb01":"* We will pass this funtion `create_model`  to the KerasClassifier class by `build_fn` argument. \n* We also pass additional argument of `epochs=15`. \n* We also pass additional argument of `batch_size=10`.\n* There is also argument of `batch_size`; it is 32 as default.","89da6b9a":"<a id=\"6.1.1\"><\/a>\n## 6.1.1. Loading Libraries"}}