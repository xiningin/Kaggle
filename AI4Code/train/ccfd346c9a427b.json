{"cell_type":{"574db97d":"code","d306b861":"code","63e9f4ed":"code","2dd6c71a":"code","227a0b90":"code","b3fbee7b":"code","4a2f0676":"code","9c90ae65":"code","e92607f9":"code","5e8133e3":"code","4f5a7fd4":"code","f6a271b2":"code","8917e49a":"code","5d376cd2":"code","cc797ee5":"code","88537600":"code","3d5a6848":"code","538d4c58":"code","5f09530f":"code","aa93951d":"code","44527a66":"code","c2a9d911":"code","bde0a261":"code","8ac76ca9":"code","918be336":"code","d6f8820d":"code","d2ba6fcd":"code","4c84782f":"code","c4db2071":"code","e90e6b0f":"code","3bdc40ac":"code","27cfd505":"code","ea52120c":"markdown","e07ad431":"markdown","f93d2ef9":"markdown","7f7a1e6f":"markdown","bb018513":"markdown","85735f0d":"markdown","f271da9d":"markdown","0ffa2aee":"markdown","dc47e7b0":"markdown","53569bae":"markdown","46664c43":"markdown","f74879c7":"markdown","9878f657":"markdown"},"source":{"574db97d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nimport scipy as sp\nfrom pandas import DataFrame, Series\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier","d306b861":"# #\u6700\u5927\u8868\u793a\u5217\u6570\u306e\u6307\u5b9a\uff08\u3053\u3053\u3067\u306f100\u5217\u3092\u6307\u5b9a\uff09\n# pd.set_option('display.max_columns', 100)","63e9f4ed":"# \u5168\u4f53\u306e20\u5206\u306e1\u3060\u3051\u8aad\u307f\u8fbc\u307f\u3002\u672c\u756a\u306f\"skiprows=lambda x: x%20!=0\"\u3092\u524a\u9664\n# df_train = pd.read_csv('..\/input\/homework-for-students4plus\/train.csv', index_col=0, skiprows=lambda x: x%20!=0)\ndf_train = pd.read_csv('..\/input\/homework-for-students4plus\/train.csv', index_col=0)\ndf_test = pd.read_csv('..\/input\/homework-for-students4plus\/test.csv', index_col=0)\n\n# df_statelatlong = pd.read_csv('..\/input\/homework-for-students4plus\/statelatlong.csv', index_col=0)\n# df_US_GDP_by_State = pd.read_csv('..\/input\/homework-for-students4plus\/US_GDP_by_State.csv', index_col=0)\n# df_US_GDP_by_State = df_US_GDP_by_State[df_US_GDP_by_State[\"year\"] == 2015]\n\n# df_train = pd.merge(df_train, df_statelatlong, left_on='addr_state', right_on='State')\n# df_test = pd.merge(df_test, df_statelatlong, left_on='addr_state', right_on='State')\n# df_train.head()\n\n# df_train = pd.merge(df_train, df_US_GDP_by_State, left_on='City', right_on='State')\n# df_test = pd.merge(df_test, df_US_GDP_by_State, left_on='City', right_on='State')\n# # addr_state\u3068\u88ab\u308bCity\u3092\u524a\u9664\n# df_train = df_train.drop(columns=['City'])\n# df_test = df_test.drop(columns=['City'])","2dd6c71a":"# train\u3068test\u3092\u9023\u7d50\ndf_train['FLG'] = 'train'\nprint('df_train' + str(df_train.shape))\ndf_test['FLG'] = 'test'\nprint('df_test' + str(df_test.shape))\ndf_temp = pd.concat([df_train,df_test])\n\n# issue_d\u304c2011\u5e74\u4ee5\u964d\u3092\u62bd\u51fa\ndf_temp['issue_d_year'] = df_temp.issue_d.str[-4:].astype(int)\ndf_temp = df_temp[df_temp.issue_d_year > 2010]\nprint('df_temp' + str(df_temp.shape))","227a0b90":"# earliest_cr_line\u304b\u3089\u5e74\u3092\u62bd\u51fa\ndf_temp['earliest_cr_line_year'] = df_temp.earliest_cr_line.str[-4:].astype(int)\n# issue_d\u3068earliest_cr_line\u306e\u5e74\u5dee\ndf_temp['year_difference'] = df_temp['issue_d_year'] - df_temp['earliest_cr_line_year']","b3fbee7b":"# sub_grade\u3092\u6570\u5024\u5909\u63db\ncol = 'sub_grade'\ndf_temp[col] = df_temp[col].str.replace('A1','0.5').str.replace('A2','2').str.replace('A3','3').str.replace('A4','4').str.replace('A5','5') \\\n.str.replace('B1','6').str.replace('B2','7').str.replace('B3','8').str.replace('B4','9').str.replace('B5','10') \\\n.str.replace('C1','11').str.replace('C2','12').str.replace('C3','13').str.replace('C4','14').str.replace('C5','15') \\\n.str.replace('D1','16').str.replace('D2','17').str.replace('D3','18').str.replace('D4','19').str.replace('D5','20') \\\n.str.replace('E1','21').str.replace('E2','22').str.replace('E3','23').str.replace('E4','24').str.replace('E5','25') \\\n.str.replace('F1','26').str.replace('F2','27').str.replace('F3','28').str.replace('F4','29').str.replace('F5','30') \\\n.str.replace('G1','31').str.replace('G2','32').str.replace('G3','33').str.replace('G4','34').str.replace('G5','35')\ndf_temp[col] = pd.to_numeric(df_temp[col], errors='coerce')\nprint(df_temp[col].unique())","4a2f0676":"### \u6b20\u640d\u5024\u30d5\u30e9\u30b0 ###\n# \u6b20\u640d\u5024\u306e\u6570\u3092\u78ba\u8a8d\nprint(df_temp.isnull().sum())","9c90ae65":"# Null\u304c\u3042\u308b\u30ab\u30e9\u30e0\u306e\u6b20\u640d\u30d5\u30e9\u30b0\u4f5c\u6210\n# col = ['emp_title', 'title','dti', \n#        'mths_since_last_delinq', 'mths_since_last_record',\n#        'revol_util','mths_since_last_major_derog',\n#        'tot_coll_amt', 'tot_cur_bal']\n# col2 = ['emp_title_flg', 'title_flg','dti_flg',\n#        'mths_since_last_delinq_flg', 'mths_since_last_record_flg',\n#        'revol_util_flg','mths_since_last_major_derog_flg',\n#        'tot_coll_amt_flg', 'tot_cur_bal_flg']\ncol = ['emp_title', 'emp_length','annual_inc', 'title','dti', 'delinq_2yrs', 'earliest_cr_line',\n       'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record','open_acc',\n       'pub_rec', 'revol_util', 'total_acc','collections_12_mths_ex_med','mths_since_last_major_derog',\n       'acc_now_delinq','tot_coll_amt', 'tot_cur_bal']\ncol2 = ['emp_title_flg', 'emp_length_flg','annual_inc_flg', 'title_flg','dti_flg', 'delinq_2yrs_flg', 'earliest_cr_line_flg',\n       'inq_last_6mths_flg', 'mths_since_last_delinq_flg', 'mths_since_last_record_flg','open_acc_flg',\n       'pub_rec_flg', 'revol_util_flg', 'total_acc_flg','collections_12_mths_ex_med_flg','mths_since_last_major_derog_flg',\n       'acc_now_delinq_flg','tot_coll_amt_flg', 'tot_cur_bal_flg']\n\ndf_temp[col2] = df_temp[col].copy()\n\nfor i in col2:\n    exec(\"df_temp.\" + str(i) + \"[df_temp.\" + str(i) + \".notnull()] = 1\")\n    exec(\"df_temp.\" + str(i) + \".fillna(0, inplace=True)\")\n\nprint(df_temp.info())","e92607f9":"# emp_length\u3092\u6570\u5024\u5909\u63db\ncol = 'emp_length'\ndf_temp[col] = df_temp[col].replace('[^0-9]+', '', regex=True)\ndf_temp[col].fillna('0', inplace=True)\n# df_temp[col] = df_temp[col].str.replace('10','A').str.replace('9','B').str.replace('8','B') \\\n# .str.replace('7','C').str.replace('6','C').str.replace('5','D').str.replace('4','D') \\\n# .str.replace('3','E').str.replace('2','E').str.replace('1','F').str.replace('0','G')\ndf_temp[col] = pd.to_numeric(df_temp[col], errors='coerce')\nprint(df_temp.info())\nprint(df_temp[col].unique())","5e8133e3":"# emp_length \u6700\u5927\u30d5\u30e9\u30b0\ndf_temp['emp_length_max_flg'] = 1\ndf_temp['emp_length_max_flg'] = df_temp['emp_length_max_flg'].where(df_temp['emp_length']==10,0)\n\n# loan_amnt \u6700\u5927\u30d5\u30e9\u30b0\ndf_temp['loan_amnt_max_flg'] = 1\ndf_temp['loan_amnt_max_flg'] = df_temp['loan_amnt_max_flg'].where(df_temp['loan_amnt']==35000,0)\n\n# revol_bal 0\u30d5\u30e9\u30b0\ndf_temp['revol_bal_0_flg'] = 1\ndf_temp['revol_bal_0_flg'] = df_temp['loan_amnt_max_flg'].where(df_temp['loan_amnt']==0,0)\n\n# tot_coll_amt 0\u30d5\u30e9\u30b0\ndf_temp['tot_coll_amt_0_flg'] = 1\ndf_temp['tot_coll_amt_0_flg'] = df_temp['loan_amnt_max_flg'].where(df_temp['loan_amnt']==0,0)","4f5a7fd4":"# emp_title \u91cd\u8981\u30ef\u30fc\u30c9\u30d5\u30e9\u30b0\ndf_temp['emp_title'] = df_temp['emp_title'].str.upper()\ndf_temp['emp_title_flg'] = 1\ndf_temp['emp_title_flg'] = df_temp['emp_title_flg'].where(df_temp['emp_title'].str.contains('MANAGER'),0)\n# df_temp[[\"emp_title\",\"emp_title_flg\"]]\ndf_temp['emp_title_flg2'] = 1\ndf_temp['emp_title_flg2'] = df_temp['emp_title_flg2'].where(df_temp['emp_title'].str.contains('TEACHER'),0)\n# df_temp[[\"emp_title\",\"emp_title_flg2\"]]","f6a271b2":"# zip_code\u3092\u6841\u6570\u5207\u308a\u51fa\u3057\ndf_temp['zip_code_1'] = df_temp.zip_code.str[:1]\n# df_temp['zip_code_2'] = df_temp.zip_code.str[:2]\n# df_temp['zip_code_3'] = df_temp.zip_code.str[:3]\n# df_temp = df_temp.drop(columns=['zip_code'])\n\n# One-hot\u306e\u5143\u30ab\u30e9\u30e0\u3092\u6b8b\u3057\u3066\u5f8c\u3067Ordinal\n# df_temp['purpose2'] = df_temp.grade.copy()\n# df_temp['grade2'] = df_temp.grade.copy()\n# df_temp['home_ownership2'] = df_temp.grade.copy()\n\n## \u5916\u308c\u5024\u306e\u51e6\u7406\nnum_cols = ['loan_amnt','annual_inc','revol_bal','tot_cur_bal']\n# 1%\u70b9\u300199%\u70b9\u3092\u8a08\u7b97\np01 = df_temp[num_cols].quantile(0.01)\np99 = df_temp[num_cols].quantile(0.99)\n# 1%\u70b9\u4ee5\u4e0b\u306e\u5024\u306f1%\u70b9\u306b\u300199%\u70b9\u4ee5\u4e0b\u306e\u5024\u306f99%\u70b9\u306b\u5909\u63db\ndf_temp[num_cols] = df_temp[num_cols].clip(p01,p99,axis=1)\n\n# \u5e74\u53ce\u30e9\u30f3\u30af\u5206\u3051\nlabels=[10,9,8,7,6,5,4,3,2,1]\ndf_temp['loan_amnt_cut'] = pd.cut(df_temp.loan_amnt, 10, labels=labels).astype(int)\n# \u501f\u5165\u984d\u30e9\u30f3\u30af\u5206\u3051\nlabels=[1,2,3,4,5,6,7,8,9,10]\ndf_temp['annual_inc_cut'] = pd.cut(df_temp.annual_inc, 10, labels=labels).astype(int)\n# \u5e74\u53ce\u30e9\u30f3\u30af * \u501f\u5165\u984d\u30e9\u30f3\u30af\u3067\u30ea\u30b9\u30af\u4fc2\u6570\u3092\u7b97\u51fa\ndf_temp['loan_risk'] = df_temp['loan_amnt_cut'] * df_temp['annual_inc_cut']\ndf_temp = df_temp.drop(columns=['loan_amnt_cut'])\ndf_temp = df_temp.drop(columns=['annual_inc_cut'])\n\n# annual_inc \/ 12 \/ installment\ndf_temp['annual_inc_installment_ratio'] = df_temp['annual_inc'] \/ 12 \/ df_temp['installment']\n\n# sub_grade\u6bce\u306eloan_amnt\u5e73\u5747\u3001\u6a19\u6e96\u504f\u5dee\u3001\u5206\u6563\u3001\u5dee\ndf_temp['subgrade_loanamnt_mean'] = df_temp.groupby('sub_grade')['loan_amnt'].transform(lambda x: x.mean())\ndf_temp['subgrade_loanamnt_std'] = df_temp.groupby('sub_grade')['loan_amnt'].transform(lambda x: x.std()) \ndf_temp['subgrade_loanamnt_var'] = df_temp.groupby('sub_grade')['loan_amnt'].transform(lambda x: x.var()) \ndf_temp['subgrade_loanamnt_difference'] = df_temp['subgrade_loanamnt_mean'] - df_temp['loan_amnt']\n\n# sub_grade\u6bce\u306eannual_inc\u5e73\u5747\u3001\u6a19\u6e96\u504f\u5dee\u3001\u5206\u6563\u3001\u5dee\ndf_temp['sub_grade_annual_inc_mean'] = df_temp.groupby('sub_grade')['annual_inc'].transform(lambda x: x.mean())\ndf_temp['sub_grade_annual_inc_std'] = df_temp.groupby('sub_grade')['annual_inc'].transform(lambda x: x.std()) \ndf_temp['sub_grade_annual_inc_var'] = df_temp.groupby('sub_grade')['annual_inc'].transform(lambda x: x.var()) \ndf_temp['sub_grade_annual_inc_difference'] = df_temp['loan_amnt'] \/ df_temp['sub_grade_annual_inc_mean']\ndf_temp['sub_grade_annual_inc_difference2'] = df_temp['sub_grade_annual_inc_mean'] \/ df_temp['loan_amnt']\n\n# loan_amnt \/ sub_grade\ndf_temp['loan_amnt_sub_grade_ratio'] = df_temp['loan_amnt'] \/ df_temp['sub_grade']\n# annual_inc \/ loan_amnt\ndf_temp['annual_inc_loanamnt_ratio'] = df_temp['annual_inc'] \/ df_temp['loan_amnt']\n# loan_amnt \/ sub_grade\ndf_temp['loan_amnt_sub_grade_ratio'] = df_temp['loan_amnt'] \/ df_temp[col]\n# loan_amnt \/ open_acc\ndf_temp['loan_amnt_open_acc_ratio'] = df_temp['loan_amnt'] \/ df_temp['open_acc']\n# annual_inc \/ sub_grade\ndf_temp['annual_inc_sub_grade_ratio'] = df_temp['annual_inc'] \/ df_temp[col]\n# annual_inc \/ open_acc\ndf_temp['annual_inc_open_acc_ratio'] = df_temp['annual_inc'] \/ df_temp['open_acc']\n# revol_bal \/ sub_grade\ndf_temp['revol_bal_sub_grade_ratio'] = df_temp['revol_bal'] \/ df_temp[col]\n# revol_bal \/ open_acc\ndf_temp['revol_bal_open_acc_ratio'] = df_temp['revol_bal'] \/ df_temp['open_acc']\n# tot_cur_bal \/ sub_grade\ndf_temp['tot_cur_bal_sub_grade_ratio'] = df_temp['tot_cur_bal'] \/ df_temp[col]\n# tot_cur_bal \/ open_acc\ndf_temp['tot_cur_bal_open_acc_ratio'] = df_temp['tot_cur_bal'] \/ df_temp['open_acc']\n\nprint(df_temp.shape)\nprint(df_temp.info())","8917e49a":"#One-hot\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\ndf_temp = pd.get_dummies(df_temp, columns=['purpose','grade','home_ownership','zip_code_1'])\ndf_temp.shape","5d376cd2":"#One-hot\u5f8c\u51e6\u7406\nX_train = df_temp[df_temp[\"FLG\"] == \"train\"]\nX_train = X_train.drop(columns=[\"FLG\"])\nprint('X_train' + str(X_train.shape))\n\nX_test = df_temp[df_temp[\"FLG\"] == \"test\"]\nX_test = X_test.drop(columns=[\"FLG\"])\nprint('X_test' + str(X_test.shape))","cc797ee5":"y_train = X_train.loan_condition\nprint('y_train' + str(y_train.shape))\nX_train = X_train.drop(['loan_condition'], axis=1)\nprint('X_train' + str(X_train.shape))\nX_test = X_test.drop(['loan_condition'], axis=1)\nprint('X_test' + str(X_test.shape))","88537600":"X_train['loan_amnt'] = X_train['loan_amnt'].apply(np.log1p)\nX_test['loan_amnt'] = X_test['loan_amnt'].apply(np.log1p)\n\nX_train['emp_length'] = X_train['emp_length'].apply(np.log1p)\nX_test['emp_length'] = X_test['emp_length'].apply(np.log1p)\n\nX_train['annual_inc'] = X_train['annual_inc'].apply(np.log1p)\nX_test['annual_inc'] = X_test['annual_inc'].apply(np.log1p)\n\nX_train['open_acc'] = X_train['open_acc'].apply(np.log1p)\nX_test['open_acc'] = X_test['open_acc'].apply(np.log1p)\n\nX_train['revol_bal'] = X_train['revol_bal'].apply(np.log1p)\nX_test['revol_bal'] = X_test['revol_bal'].apply(np.log1p)\n\nX_train['total_acc'] = X_train['total_acc'].apply(np.log1p)\nX_test['total_acc'] = X_test['total_acc'].apply(np.log1p)\n\nX_train['tot_cur_bal'] = X_train['tot_cur_bal'].apply(np.log1p)\nX_test['tot_cur_bal'] = X_test['tot_cur_bal'].apply(np.log1p)\n","3d5a6848":"nums = ['loan_amnt', 'installment', 'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', \n        'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', \n        'revol_util', 'total_acc', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', \n        'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal']\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u306b\u57fa\u3065\u3044\u3066\u8907\u6570\u30ab\u30e9\u30e0\u306e\u6a19\u6e96\u5316\u3092\u5b9a\u7fa9\nscaler = StandardScaler()\nX_train[nums] = X_train[nums].astype(float)\nX_test[nums] = X_test[nums].astype(float)\nscaler.fit(X_train[nums])\n\n# \u5909\u63db\u5f8c\u306e\u30c7\u30fc\u30bf\u3067\u5404\u5217\u3092\u7f6e\u63db\nX_train[nums] = scaler.transform(X_train[nums])\nX_test[nums] = scaler.transform(X_test[nums])","538d4c58":"cats = ['issue_d','sub_grade',\n        'title','zip_code','addr_state','earliest_cr_line','initial_list_status','application_type']\n# cats = ['issue_d','sub_grade',\n#         'title','zip_code','addr_state','earliest_cr_line','initial_list_status','application_type']\n\noe = OrdinalEncoder(cols=cats, return_df=False)\n\nX_train[cats] = oe.fit_transform(X_train[cats])\nX_test[cats] = oe.transform(X_test[cats])","5f09530f":"# \u30c6\u30ad\u30b9\u30c8\u3068\u305d\u308c\u4ee5\u5916\u306b\u5206\u5272\nTXT_train = X_train.emp_title.copy()\nTXT_test = X_test.emp_title.copy()\n\nTXT_train.head()\n\nX_train.drop(['emp_title'], axis=1, inplace=True)\nX_test.drop(['emp_title'], axis=1, inplace=True)\n\nX_train.fillna(X_train.median(), inplace=True)\nX_test.fillna(X_train.median(), inplace=True)","aa93951d":"target = 'loan_condition'\nX_temp = pd.concat([X_train, y_train], axis=1)\n\ncats = ['issue_d','sub_grade',\n        'title','zip_code','addr_state','earliest_cr_line','initial_list_status','application_type']\n# cats = ['issue_d','sub_grade',\n#         'title','zip_code','addr_state','earliest_cr_line','initial_list_status','application_type']\n#cats= ['purpose2', 'grade2', 'home_ownership2', 'annual_inc', 'sub_grade' ]\n\nfor col in cats:\n\n    # X_test\u306fX_train\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    summary = X_temp.groupby([col])[target].mean()\n    X_test[col] = X_test[col].map(summary) \n\n\n    # X_train\u306e\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092oof\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n    enc_train = Series(np.zeros(len(X_train)), index=X_train.index)\n\n    for i, (train_ix, val_ix) in enumerate((skf.split(X_train, y_train))):\n        X_train_, _ = X_temp.iloc[train_ix], y_train.iloc[train_ix]\n        X_val, _ = X_temp.iloc[val_ix], y_train.iloc[val_ix]\n\n        summary = X_train_.groupby([col])[target].mean()\n        enc_train.iloc[val_ix] = X_val[col].map(summary)\n        \n    X_train[col]  = enc_train","44527a66":"X_train.fillna(X_train.mean(), axis=0, inplace=True)\nX_test.fillna(X_train.mean(), axis=0, inplace=True)","c2a9d911":"# \u5927\u6587\u5b57\u306b\u5909\u63db\nTXT_train = TXT_train.str.upper()\nTXT_test = TXT_test.str.upper()\n# \u6587\u5b57\u4ee5\u5916\u3092\u7a7a\u767d\u306b\u7f6e\u63db\nTXT_train = TXT_train.replace('[^a-zA-Z]', ' ', regex=True)\nTXT_test = TXT_test.replace('[^a-zA-Z]', ' ', regex=True)\n# \u524d\u5f8c\u306e\u7a7a\u767d\u3092\u9664\u53bb\nTXT_train = TXT_train.str.strip()\nTXT_test = TXT_test.str.strip()\n# \u9023\u7d9a\u3059\u308b\u7a7a\u767d\u30921\u3064\u306b\nTXT_train = TXT_train.replace('\\s+',' ', regex=True)\nTXT_test = TXT_test.replace('\\s+',' ', regex=True)\n# TFIDF\ntdidf = TfidfVectorizer(max_features=100, use_idf=True)\nTXT_train = tdidf.fit_transform(TXT_train.fillna('#'))\nTXT_test = tdidf.transform(TXT_test.fillna('#'))\n# hstack\nX_train = sp.sparse.hstack([X_train.values, TXT_train])\nX_test = sp.sparse.hstack([X_test.values, TXT_test])\n\n# X_train = X_train.tocsr()# \u884c\u65b9\u5411\u306e\u30b9\u30e9\u30a4\u30b9\u304c\u3067\u304d\u308b\u3088\u3046\u306b\u5909\u63db\u3059\u308b\n# X_test = X_test.tocsr()","bde0a261":"# seed average(30\u56de\u306e\u5e73\u5747)\ny_pred = np.zeros(X_test.shape[0])\n\nfor i in range(30):\n    clf = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.71,\n                                        importance_type='split', learning_rate=0.05, max_depth=-1,\n                                        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n                                        n_estimators=1000, n_jobs=-1, num_leaves=31, objective=None,\n                                        random_state=i, reg_alpha=1.0, reg_lambda=1.0, silent=True,\n                                        subsample=0.9, subsample_for_bin=200000, subsample_freq=0)\n\n    clf.fit(X_train, y_train)\n    y_pred += clf.predict_proba(X_test)[:,1]\n    \ny_pred \/= 30","8ac76ca9":"# from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\n# # \u5b66\u7fd2\u7528\u3068\u691c\u8a3c\u7528\u306b\u5206\u5272\u3059\u308b\n# X_train_, X_val, y_train_, y_val= train_test_split(X_train, y_train, test_size=0.05, random_state=71)\n\n# clf = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.71,\n#                                 importance_type='split', learning_rate=0.05, max_depth=-1,\n#                                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n#                                 n_estimators=9999, n_jobs=-1, num_leaves=31, objective=None,\n#                                 random_state=4, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n#                                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0) ","918be336":"# %%time\n# clf.fit(X_train_, y_train_, early_stopping_rounds=200, eval_metric='auc', eval_set=[(X_val, y_val)])","d6f8820d":"# clf.booster_.feature_importance(importance_type='gain')","d2ba6fcd":"# imp = DataFrame(clf.booster_.feature_importance(importance_type='gain'), index = X_train.columns, columns=['importance']).sort_values(['importance'], ascending=False)\n# imp","4c84782f":"# fig, ax = plt.subplots(figsize=(5, 8))\n# lgb.plot_importance(clf, max_num_features=50, ax=ax, importance_type='gain')","c4db2071":"# scores = []\n\n# skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\n# for i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n#     X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n#     X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    \n#     clf = GradientBoostingClassifier()\n    \n#     clf.fit(X_train_, y_train_)\n#     y_pred = clf.predict_proba(X_val)[:,1]\n#     score = roc_auc_score(y_val, y_pred)\n#     scores.append(score)\n    \n#     print('CV Score of Fold_%d is %f' % (i, score))","e90e6b0f":"# # \u5e73\u5747\u30b9\u30b3\u30a2\u3092\u7b97\u51fa \n# np.array(scores).mean()","3bdc40ac":"# # \u5168\u30c7\u30fc\u30bf\u3067\u518d\u5b66\u7fd2\u3057\u3001test\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u3059\u308b\n# clf = GradientBoostingClassifier()\n# clf.fit(X_train, y_train)\n\n# y_pred = clf.predict_proba(X_test)[:,1]","27cfd505":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\nsubmission = pd.read_csv('..\/input\/homework-for-students4plus\/sample_submission.csv', index_col=0)\n\nsubmission.loan_condition = y_pred\nsubmission.to_csv('submission.csv')","ea52120c":"\u5bfe\u6570\u5909\u63db","e07ad431":"\u6b63\u898f\u5316","f93d2ef9":"Target\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0","7f7a1e6f":"\u4fdd\u5b58","bb018513":"X\u3068y\u306b\u5206\u5272","85735f0d":"LightGBM","f271da9d":"\u30c6\u30ad\u30b9\u30c8\u7279\u5fb4\u91cf\u3092\u9664\u3044\u3066\u3001\u6b20\u640d\u5024\uff08\u7a7a\u6b04\uff09\u3092\u4e2d\u592e\u5024\u3067\u57cb\u3081\u308b","0ffa2aee":"LightGBM\u691c\u5b9a\u7528","dc47e7b0":"\u7279\u5fb4\u91cf\u30a8\u30f3\u30b8\u30cb\u30a2\u30ea\u30f3\u30b0","53569bae":"Ordinal\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0","46664c43":"GradientBoostingClassifier","f74879c7":"\u30c6\u30ad\u30b9\u30c8\u3092TFIDF","9878f657":"\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\u3068\u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f"}}