{"cell_type":{"f5720eeb":"code","9be1c28f":"code","fba9c368":"code","6045f4d3":"code","8a803ecf":"code","9362ccd1":"code","8a332692":"code","e74c73fa":"code","9eec1b33":"code","72376f05":"code","f49feff7":"code","ab3a2d84":"code","b7b2cc5e":"code","8836b5b2":"code","1d91d604":"code","3f7c7d0f":"code","a91aa8f8":"code","32707676":"code","621e1cfb":"code","c11dc191":"code","a4eae44a":"code","d7d3366f":"code","2f2ad4e8":"code","29d97cf3":"code","c1ffcf0d":"code","b61e074d":"code","5451230b":"markdown","69c6869d":"markdown","93ea0ca8":"markdown","98a333c3":"markdown","6a810275":"markdown","fd06f211":"markdown","f93a4c69":"markdown","7943623a":"markdown","6f59708b":"markdown","a7385a73":"markdown"},"source":{"f5720eeb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","9be1c28f":"%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import RandomizedSearchCV\nimport pickle\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","fba9c368":"df=pd.read_csv(\"\/kaggle\/input\/adeconvid19\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/adeconvid19\/train.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/adeconvid19\/submission.csv\")","6045f4d3":"print(df.shape,\"\\n\",df.head())","8a803ecf":"df[\"Province_State\"].fillna(\"state\", inplace = True)    \ndf[\"Country_Region\"] = [country_name.replace(\"'\",\"\") for country_name in df[\"Country_Region\"]]\nprint(df.shape,\"\\n\",df.head())","9362ccd1":"data=[]\ncountries=df.Country_Region.unique()\nfor country in countries:\n    provinces=df[df.Country_Region==country].Province_State.unique()\n    for province in provinces:\n        temp_df=df[(df['Country_Region'] == country) & (df['Province_State']==province)]\n        for i in range(0,74):\n            Iday1=float(temp_df.iloc[i].ConfirmedCases)\n            Iday2=float(temp_df.iloc[i+1].ConfirmedCases)\n            Iday3=float(temp_df.iloc[i+2].ConfirmedCases)\n            Iday4=float(temp_df.iloc[i+3].ConfirmedCases)\n            Iday5=float(temp_df.iloc[i+4].ConfirmedCases)\n            Iday6=float(temp_df.iloc[i+5].ConfirmedCases)\n            Iday7=float(temp_df.iloc[i+6].ConfirmedCases)\n            Fday1=float(temp_df.iloc[i].Fatalities)\n            Fday2=float(temp_df.iloc[i+1].Fatalities)\n            Fday3=float(temp_df.iloc[i+2].Fatalities)\n            Fday4=float(temp_df.iloc[i+3].Fatalities)\n            Fday5=float(temp_df.iloc[i+4].Fatalities)\n            Fday6=float(temp_df.iloc[i+5].Fatalities)\n            Fday7=float(temp_df.iloc[i+6].Fatalities)\n            target_infection=float(temp_df.iloc[i+7].ConfirmedCases)\n            target_fatal=float(temp_df.iloc[i+7].Fatalities)\n            data.append({\"Iday1\":Iday1,\"Iday2\":Iday2,\"Iday3\":Iday3,\"Iday4\":\n                         Iday4,\"Iday5\":Iday5,\n                         \"Iday6\":Iday6,\"Iday7\":Iday7,\"Fday1\":Fday1,\"Fday2\":\n                         Fday2,\"Fday3\":Fday3,\n                         \n                         \"Fday4\":Fday4,\"Fday5\":Fday5,\"Fday6\":Fday6,\"Fday7\":Fday7,\n                         \"target_infection\":target_infection,\"target_fatal\":target_fatal})        ","8a332692":"new_data=pd.DataFrame(data)\nprint(\"The shape of new dataFrame:\",new_data.shape,\"\\nThe columns are:\",new_data.columns)\nprint(new_data.head(-5))","e74c73fa":"X_y=shuffle(new_data)\ny_cases=X_y['target_infection']\ny_fatal=X_y['target_fatal']\nX=X_y.drop(['target_infection','target_fatal'],axis=1)\nX_train_cases, X_test_cases, y_train_cases, y_test_cases = train_test_split(X, y_cases, test_size=0.33)\nX_train_fatal, X_test_fatal, y_train_fatal, y_test_fatal = train_test_split(X, y_fatal, test_size=0.33)\nprint(\"Shape of infection train dataset:\",(X_train_cases.shape,y_train_cases.shape))\nprint(\"Shape of infection test dataset:\",(X_test_cases.shape,y_test_cases.shape))\nprint(\"Shape of fatal train dataset:\",(X_train_fatal.shape,y_train_fatal.shape))\nprint(\"Shape of fatal test dataset:\",(X_test_fatal.shape,y_test_fatal.shape))","9eec1b33":"reg_case=ElasticNet(random_state=42,l1_ratio=0.1,max_iter=2200)\nparams = [{'alpha': [10**-4,10**-3, 10**-2,10**-1, 10**0,10**1, 10**2,10**3,10**4]}]\nclf = RandomizedSearchCV(reg_case, params, cv=4, scoring='neg_root_mean_squared_error',return_train_score=True)\nsearch=clf.fit(X_train_cases, y_train_cases)\nresults = pd.DataFrame.from_dict(clf.cv_results_)","72376f05":"best_alpha=10\nbest_itr=2400\nfinal_reg_case=ElasticNet(random_state=42,alpha=best_alpha,l1_ratio=0.1,max_iter=best_itr)\nfinal_reg_case.fit(X_train_cases,y_train_cases)","f49feff7":"pred=final_reg_case.predict(X_test_cases)\nprint(\"The RMSE value\",(mean_squared_error(y_test_cases,pred))**0.5)","ab3a2d84":"reg_fatal=ElasticNet(random_state=42,l1_ratio=0.1,max_iter=3500)\nparams = [{'alpha': [10**-4,10**-3, 10**-2,10**-1, 10**0,10**1, 10**2,10**3,10**4]}]\nclf = RandomizedSearchCV(reg_fatal, params, cv=4, scoring='neg_root_mean_squared_error',return_train_score=True)\nsearch=clf.fit(X_train_fatal, y_train_fatal)\nresults = pd.DataFrame.from_dict(clf.cv_results_)","b7b2cc5e":"best_alpha=100\nbest_iter=3500\nfinal_reg_fatal = ElasticNet(random_state=42,alpha=best_alpha,l1_ratio=0.1,max_iter=best_iter)\nfinal_reg_fatal.fit(X_train_fatal, y_train_fatal)","8836b5b2":"pred=final_reg_fatal.predict(X_test_fatal)\nprint(\"The RMSE value\",(mean_squared_error(y_test_fatal,pred))**0.5)","1d91d604":"data=[]\ncountries=df.Country_Region.unique()\nfor country in countries:\n    provinces=df[df.Country_Region==country].Province_State.unique()\n    for province in provinces:\n        temp_df=df[(df['Country_Region'] == country) & (df['Province_State']==province)]\n        for i in range(0,74):\n            Iday1=float(temp_df.iloc[i].ConfirmedCases)\n            Iday2=float(temp_df.iloc[i+1].ConfirmedCases)\n            Iday3=float(temp_df.iloc[i+2].ConfirmedCases)\n            Iday4=float(temp_df.iloc[i+3].ConfirmedCases)\n            Iday5=float(temp_df.iloc[i+4].ConfirmedCases)\n            Iday6=float(temp_df.iloc[i+5].ConfirmedCases)\n            Iday7=float(temp_df.iloc[i+6].ConfirmedCases)\n            Fday1=float(temp_df.iloc[i].Fatalities)\n            Fday2=float(temp_df.iloc[i+1].Fatalities)\n            Fday3=float(temp_df.iloc[i+2].Fatalities)\n            Fday4=float(temp_df.iloc[i+3].Fatalities)\n            Fday5=float(temp_df.iloc[i+4].Fatalities)\n            Fday6=float(temp_df.iloc[i+5].Fatalities)\n            Fday7=float(temp_df.iloc[i+6].Fatalities)\n            if Iday6==0 :\n                iavg=1\n            else:\n                iavg=Iday7\/(Iday6)\n            if Fday6==0:\n                favg=1\n            else:    \n                favg=Fday7\/(Fday6)        \n            target_infection=float(temp_df.iloc[i+7].ConfirmedCases)\n            target_fatal=float(temp_df.iloc[i+7].Fatalities)\n            data.append({\"Iday1\":Iday1,\"Iday2\":Iday2,\"Iday3\":Iday3,\"Iday4\":Iday4,\"Iday5\":Iday5,\n                         \"Iday6\":Iday6,\"Iday7\":Iday7,\"Fday1\":Fday1,\"Fday2\":Fday2,\"Fday3\":Fday3,\n                         \"Fday4\":Fday4,\"Fday5\":Fday5,\"Fday6\":Fday6,\"Fday7\":Fday7,'iratio':iavg,\"fratio\":favg,\"target_infection\":target_infection,\"target_fatal\":target_fatal})        ","3f7c7d0f":"featured=pd.DataFrame(data)\nX_y_f=shuffle(featured)\ny_cases_f=X_y_f['target_infection']\ny_fatal_f=X_y_f['target_fatal']\nX_f=X_y_f.drop(['target_infection','target_fatal'],axis=1)\nX_train_cases_f, X_test_cases_f, y_train_cases_f, y_test_cases_f = train_test_split(X_f, y_cases_f, test_size=0.33)\nX_train_fatal_f, X_test_fatal_f, y_train_fatal_f, y_test_fatal_f = train_test_split(X_f, y_fatal_f, test_size=0.33)\nprint(\"Shape of featurized infection train dataset:\",(X_train_cases_f.shape,y_train_cases_f.shape))\nprint(\"Shape of featurized infection test dataset:\",(X_test_cases_f.shape,y_test_cases_f.shape))\nprint(\"Shape of featurized fatal train dataset:\",(X_train_fatal_f.shape,y_train_fatal_f.shape))\nprint(\"Shape of featurized fatal test dataset:\",(X_test_fatal_f.shape,y_test_fatal_f.shape))","a91aa8f8":"reg_case_f=ElasticNet(random_state=42,l1_ratio=0.1,max_iter=2200)\nparams = [{'alpha': [10**-4,10**-3, 10**-2,10**-1, 10**0,10**1, 10**2,10**3,10**4]}]\nclf_f= RandomizedSearchCV(reg_case_f, params, cv=4, scoring='neg_root_mean_squared_error',return_train_score=True)\nsearch_f=clf_f.fit(X_train_cases_f, y_train_cases_f)\nresults_f = pd.DataFrame.from_dict(clf_f.cv_results_)","32707676":"best_alpha=10000\nbest_itr=4200\nfinal_reg_case_f=ElasticNet(random_state=42,alpha=best_alpha,l1_ratio=0.1,max_iter=best_itr)\nfinal_reg_case_f.fit(X_train_cases_f,y_train_cases_f)","621e1cfb":"pred_f=final_reg_case_f.predict(X_test_cases_f)\nprint(\"RMSE is:\",(mean_squared_error(y_test_cases_f,pred_f))**0.5)","c11dc191":"reg_fatal_f=ElasticNet(random_state=42,alpha=best_alpha,l1_ratio=0.1,max_iter=2200)\nparams = [{'alpha': [10**-4,10**-3, 10**-2,10**-1, 10**0,10**1, 10**2,10**3,10**4]}]\nclf_f= RandomizedSearchCV(reg_fatal_f, params, cv=4, scoring='neg_root_mean_squared_error',return_train_score=True)\nsearch_f=clf_f.fit(X_train_fatal_f, y_train_fatal_f)\nresults_f = pd.DataFrame.from_dict(clf_f.cv_results_)","a4eae44a":"best_alpha=100\nbest_itr=2400\nfinal_reg_fatal_f=ElasticNet(random_state=42,alpha=best_alpha,l1_ratio=0.1,max_iter=best_itr)\nfinal_reg_fatal_f.fit(X_train_fatal_f,y_train_fatal_f)","d7d3366f":"pred_f=final_reg_fatal_f.predict(X_test_fatal_f)\nprint(\"RMSE is:\",(mean_squared_error(y_test_fatal_f,pred_f))**0.5)","2f2ad4e8":"test[\"Province_State\"].fillna(\"state\", inplace = True)    \ntest[\"Country_Region\"] = [country_name.replace(\"'\",\"\") for country_name in test[\"Country_Region\"]]","29d97cf3":"import math\nimport random\npredicted_case=[]\npredicted_fatal=[]\ncountries=df.Country_Region.unique()\nfor country in countries:\n    provinces=df[df.Country_Region==country].Province_State.unique()\n    for province in provinces:\n        temp_df=df[(df['Country_Region'] == country) & (df['Province_State']==province)&(df['Date']>='2020-04-02')]\n        ongoingCases=list(temp_df.ConfirmedCases.values)\n        ongoingFatal=list(temp_df.Fatalities.values)\n        predicted_case.extend(ongoingCases)\n        predicted_fatal.extend(ongoingFatal)\n        for _ in range(1,34):  \n            if ongoingCases[-2]==0:\n                iavg=ongoingCases[-1]\n            else:\n                iavg=ongoingCases[-1]\/ongoingCases[-2]\n            if ongoingFatal[-2]==0:\n                favg=ongoingFatal[-1]\n            else:    \n                favg=ongoingFatal[-1]\/ongoingFatal[-2]\n            point=ongoingCases[len(ongoingCases)-7:]+ongoingFatal[len(ongoingFatal)-7:]+[iavg,favg]\n            # print(point)\n            # print()\n            randF=random.random()\n            randI=random.random()\n            predC=final_reg_case_f.predict([point])\n            predF=final_reg_fatal_f.predict([point])\n            predicted_case.append(int(predC[0]-(randI*predC[0]*0.002)))\n            predicted_fatal.append(abs(int(predF[0]-(randF*predF[0]*0.0005))))\n            ongoingCases.append(predC[0]-(randI*predC[0]*0.002))\n            ongoingFatal.append(abs(predF[0]-(randF*predF[0]*0.0005)))    ","c1ffcf0d":"test['ConfirmedCases'] = list(map(int,predicted_case))\ntest['Fatalities'] = list(map(int,predicted_fatal))","b61e074d":"submission_file=test[['ForecastId','ConfirmedCases','Fatalities']]\nsubmission_file=shuffle(submission_file)\nsubmission_file.to_csv(\"submission_convid19.csv\",index=False)","5451230b":"NOW, MAKING OF CASES AND FATALITIES PROJECTION:\nBY INITIALIZING THE LIST WITH PREVIOUS SEVEN DAYS DATA AND MAKE A PREDICTION VALUE FOR THE FOLLOWING DAY.\nALSO, APPENDING THIS VALUE TO THIS LIST AND AMKE THIS LATEST DATA(UPDATED DATA) TO MAKE A PREDICTION FOR THE FOLLOWING ONE ETC.","69c6869d":"**Now preparing our dataset**\n\nWe are going to consider the past 7 days data to forecast the cases and also the fatalities on the 8th day.","93ea0ca8":"**Now, using Elastic Net to train the CONVID19 data (after using RandomSearch to find out the best set of parameters).**","98a333c3":"RMSE VALUE.\n\nNOTE: That the RMSE value will definately big due to the fact that, no scaling was done.","6a810275":"Also with the same procedure. \n\nWe are going to train the fatality data as well.","fd06f211":"Note: that we don't have good result when applying scaling. Hence, the original data was chosen to be used through this process.","f93a4c69":"**LASTLY, LET'S UPDATE THE VALUE IN OUR TEST DATASET**","7943623a":"**NOW, SPLITTING THE DATASET INTO TRAIN AND TEST**","6f59708b":"**FEATURE ENGINEERING:**","a7385a73":"HOWEVER, THE SUBSEQUENT METHODS WILL REMAIN THE SAME"}}