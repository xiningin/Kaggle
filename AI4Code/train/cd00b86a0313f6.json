{"cell_type":{"67427d5d":"code","564b6db8":"code","740d7509":"code","a4b6e593":"code","b319a7bf":"code","07f2b96e":"code","0eed77cd":"code","3ebd7c15":"code","31d73958":"code","ebffdf80":"code","b709f263":"code","ef22d91e":"code","0985e79c":"code","8b990ea8":"code","ae65bb39":"code","d83f3919":"code","010b3121":"code","ce96a552":"code","eb7f0738":"code","fb12a6dd":"code","c1e5912b":"code","7c9c06a0":"code","ae1ccf8a":"code","2aee2ec9":"code","0c5dacd7":"code","26a62001":"code","be534a1d":"code","cabd619a":"code","053a8de6":"code","8061f423":"code","b190e583":"code","c9d8b4d8":"code","1b594043":"code","3ba3933b":"code","f74b829d":"code","4000eac4":"code","10ac8148":"code","e99f0d74":"code","2df7acfb":"code","25e45022":"code","277521c2":"code","e0d1878e":"code","70c92494":"code","a49e584e":"code","9f51eb66":"code","96c090f6":"code","f26a33ef":"code","fd224451":"code","eba32916":"code","89db718f":"code","77048651":"code","1cacb24c":"code","c295ca91":"code","859e50f1":"code","15a29deb":"code","3ec14418":"code","78dfbab2":"code","be5d69a6":"code","8f4fb35c":"code","f5b1fca1":"code","07b4b39d":"code","ac5b5440":"code","45906f63":"code","8e9bc099":"code","1957fe04":"code","f0499284":"code","18904235":"code","916ed674":"code","bcc4dde6":"code","1cd05835":"code","bd9511d1":"code","7751619d":"code","599ae64b":"code","ebe24271":"code","dc68001d":"code","79113bb0":"code","d99cb661":"code","e035bb37":"code","e1319b34":"code","cd470c33":"code","f70e2db8":"code","3929bf3e":"code","70941dde":"code","5fd80602":"code","5a46d6c6":"code","1bd14de9":"code","4ef51261":"code","25fd58dd":"code","b7296a9d":"code","59c0d771":"code","48777ffa":"code","6d8bd326":"code","626f6f86":"code","eb52acc1":"code","b2dc4ccc":"code","4e5f0a76":"code","99cc1bca":"code","bcad3f20":"code","06776a93":"code","921a0105":"code","9940b1ce":"code","126a5fb5":"code","848dd197":"code","ca9483e3":"code","21c3bf11":"code","2d9ab71c":"code","c0acf129":"code","0f5dd930":"code","ffa64f9a":"markdown","32e5c7d9":"markdown","65676bf1":"markdown","01e87d05":"markdown","1a9c7833":"markdown","ddcb3cd6":"markdown","1b4b0d52":"markdown","33ef40d5":"markdown","84d99b92":"markdown","801b7303":"markdown","b34e2aba":"markdown","c3fb7d15":"markdown","ae8df934":"markdown","842f1f00":"markdown","d91b41a5":"markdown","063b6df4":"markdown","88b1673e":"markdown","4b73e45f":"markdown","a4e3baef":"markdown","30a03690":"markdown","5e971636":"markdown","54630b27":"markdown","6da305c7":"markdown","ac96b349":"markdown","e0663773":"markdown","44c2fa3c":"markdown","a62a758e":"markdown","72ff08f8":"markdown","73a77ed2":"markdown","a2f9b31d":"markdown","f76a3dba":"markdown","508ffcd9":"markdown","4b9c9a2e":"markdown","467cd11e":"markdown","d0a64d56":"markdown","0a08cc13":"markdown","2d01cce7":"markdown","6ac9cfbc":"markdown","6ab20915":"markdown","a76e8769":"markdown","72366854":"markdown","42341879":"markdown","8e75560f":"markdown","7d78c565":"markdown","a294d3f2":"markdown","d8135cde":"markdown","d82cd94b":"markdown","85e51e52":"markdown","205c8dca":"markdown","fd46ec5f":"markdown","38e6e815":"markdown","5548b3ff":"markdown","d3f195fc":"markdown","65d7847a":"markdown","6aba2ae6":"markdown","df380ab3":"markdown","9de49cb8":"markdown","72ec6cb2":"markdown","f934d29b":"markdown"},"source":{"67427d5d":"# Data visualization\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# MODEL\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\n# Some functions used before and after the model\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, \\\n    classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import preprocessing\n\n# Errors and data representation\nimport warnings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 20)\npd.set_option('display.width', 150)\npd.set_option('display.float_format', lambda x: '%.2f' % x)\nwarnings.simplefilter(action = \"ignore\")","564b6db8":"df_ = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndf = df_.copy()","740d7509":"df.head()","a4b6e593":"df.drop('customerID', axis=1, inplace=True)","b319a7bf":"df.info()","07f2b96e":"df['SeniorCitizen'] = df['SeniorCitizen'].astype('O')\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')","0eed77cd":"df.isnull().sum()","3ebd7c15":"df[df['TotalCharges'].isnull()]","31d73958":"null_values = df[df['TotalCharges'].isnull()].index.to_list()\ndf.loc[df.index.isin(null_values), \n       'TotalCharges'] = df.loc[df.index.isin(null_values), 'MonthlyCharges']","ebffdf80":"df[df.index.isin(null_values)] # They are also new customer.","b709f263":"df.isnull().sum()","ef22d91e":"def grab_cols(dataframe, cat_th=10, car_th=20):\n    cat_cols = [col for col in dataframe.columns  # Categorical\n                if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns\n                   if dataframe[col].nunique() < cat_th and  # Numeric but categorical\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns\n                   if dataframe[col].nunique() > car_th and  # Categorical but high cardinal\n                   dataframe[col].dtypes == \"O\"]\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes not in ['O', 'datetime64[ns]'] and\n                dataframe[col].nunique() > 10]  # Numeric\n    return cat_cols, num_but_cat, cat_but_car, num_cols","0985e79c":"cat_cols, num_but_cat, cat_but_car, num_cols = grab_cols(df)","8b990ea8":"cat_cols","ae65bb39":"num_cols","d83f3919":"cat_but_car, num_but_cat # There is not.","010b3121":"df['Churn'] = np.where(df['Churn'] == 'Yes', 1, 0)","ce96a552":"plt.figure(figsize=(12,6))\n(pd.get_dummies(df).corr()['Churn']).sort_values(ascending=False).plot(kind='bar');","eb7f0738":"plt.figure(figsize=(10,6))\nsns.heatmap(df[num_cols].corr(), annot=True, cmap='Reds')\nplt.title('Correlation HeatMap');","fb12a6dd":"df[num_cols].hist(figsize = (14,8), bins=12);","c1e5912b":"def cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}), \n          end='\\n\\n\\n')\n\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.title(col_name)\n        plt.xticks(rotation = 45)\n        plt.show()","7c9c06a0":"for col in cat_cols:\n    cat_summary(df, col, plot=True)","ae1ccf8a":"churn_to_contract = df.groupby(['Churn' ,'Contract'])\\\n.agg({'Contract': 'count'}).unstack().T.reset_index().drop('level_0', axis=1)\nchurn_to_contract.columns = ['Contract', 'Churn_0', 'Churn_1']\nchurn_to_contract['Churn_Ratio'] = churn_to_contract['Churn_1']*100\\\n\/(churn_to_contract['Churn_0'] + churn_to_contract['Churn_1'])\nchurn_to_contract","2aee2ec9":"churn_to_internet = df.groupby(['Churn', 'InternetService']).agg({'InternetService':'count'}).unstack().T.reset_index().drop('level_0', axis=1)\nchurn_to_internet.columns = ['InternetService', 'Churn_0', 'Churn_1']\nchurn_to_internet['Churn_Ratio'] = churn_to_internet['Churn_1']*100 \/(churn_to_internet['Churn_0'] + churn_to_internet['Churn_1'])\nchurn_to_internet.sort_values(by='Churn_Ratio', ascending=False)","0c5dacd7":"internet_to_billing = df.groupby(['InternetService', 'PaperlessBilling']).agg({'PaperlessBilling':'count'}).unstack().T.reset_index().drop('level_0', axis=1)\ninternet_to_billing.columns = ['PaperlessBilling', 'DSL', 'Fiber optic', 'No']\ninternet_to_billing","26a62001":"churn_to_payment = df.groupby(['Churn', 'PaymentMethod'])\\\n.agg({'Churn':'count'}).unstack().T.reset_index().drop('level_0', axis=1)\nchurn_to_payment.columns = ['PaymentMethod', 'Churn_0', 'Churn_1']\nchurn_to_payment['Churn_Ratio'] = churn_to_payment['Churn_1']*100\\\n\/(churn_to_payment['Churn_0'] + churn_to_payment['Churn_1'])\nchurn_to_payment.sort_values(by='Churn_Ratio', ascending=False)","be534a1d":"churn_to_citizen = df.groupby(['Churn', 'SeniorCitizen']).agg({'Churn':'count'}).unstack().T.reset_index().drop('level_0', axis=1)\nchurn_to_citizen.columns = ['SeniorCitizen', 'Churn_0', 'Churn_1']\nchurn_to_citizen['Churn_Ratio'] = churn_to_citizen['Churn_1']*100 \/(churn_to_citizen['Churn_0'] + churn_to_citizen['Churn_1'])\nchurn_to_citizen","cabd619a":"def outliers_threshold(dataframe, column):\n    q1 = dataframe[column].quantile(0.05)\n    q3 = dataframe[column].quantile(0.95)\n    inter_quartile_range = q3 - q1\n    low = q1 - 1.5 * inter_quartile_range\n    up = q3 + 1.5 * inter_quartile_range\n    return low, up","053a8de6":"def grab_outlier(dataframe, column, index=False):\n    low, up = outliers_threshold(dataframe, column)\n    if dataframe[(dataframe[column] < low) |\n                 (dataframe[column] > up)].shape[0] < 10:\n        print(dataframe[(dataframe[column] < low) | (dataframe[column] > up)])\n    else:\n        print(dataframe[(dataframe[column] < low) |\n                 (dataframe[column] > up)].head())\n    if index:\n        outlier_index = dataframe[(dataframe[column] < low) |\n                                  (dataframe[column] > up)].index\n        return outlier_index","8061f423":"for col in num_cols:\n    grab_outlier(df[num_cols], col)","b190e583":"df[['tenure', 'MonthlyCharges']].describe().T","c9d8b4d8":"df[df['tenure'] == 0]['Churn']","1b594043":"df['new_tenure_segment'] = pd.cut(df['tenure'], bins=[0, 0.5, 30, 60, 100],\n                                 labels=['New', 'Low', 'Medium', 'High']).astype('O')","3ba3933b":"df['new_MonhlyCharges_segment'] = pd.cut(df['MonthlyCharges'], bins=[0, 70, 90, 120],\n                                 labels=['Low', 'Medium', 'High']).astype('O')","f74b829d":"churn_to_segment = df.groupby(['Churn', 'new_tenure_segment'])\\\n.agg({'new_tenure_segment': 'count'}).unstack().T.reset_index().drop('level_0', axis=1)\nchurn_to_segment.columns = ['new_tenure_segment', 'Churn_0', 'Churn_1']\nchurn_to_segment['Churn_Ratio'] = churn_to_segment['Churn_1']*100\\\n\/(churn_to_segment['Churn_0'] + churn_to_segment['Churn_1'])\nchurn_to_segment.sort_values('Churn_Ratio', ascending=False)","4000eac4":"churn_to_mcharges = df.groupby(['Churn', 'new_MonhlyCharges_segment'])\\\n.agg({'new_MonhlyCharges_segment': 'count'}).unstack().T.reset_index()\\\n.drop('level_0', axis=1)\nchurn_to_mcharges.columns = ['new_MonhlyCharges_segment', 'Churn_0', 'Churn_1']\nchurn_to_mcharges['Churn_Ratio'] = churn_to_mcharges['Churn_1']*100\\\n\/(churn_to_mcharges['Churn_0'] + churn_to_mcharges['Churn_1'])\nchurn_to_mcharges.sort_values('Churn_Ratio', ascending=False)","10ac8148":"scaler = MinMaxScaler(feature_range=(1, 10))\nscaler.fit(df[['tenure', 'MonthlyCharges']])\ndf[['tenure_scaled', 'MonthlyCharges_scaled']] = scaler\\\n.transform(df[['tenure', 'MonthlyCharges']])","e99f0d74":"# New scaled range 1-10\ndf[['tenure', 'tenure_scaled', 'MonthlyCharges', 'MonthlyCharges_scaled']].head(10)","2df7acfb":"df['segment_score_1'] = (0.65 * df['tenure_scaled'] + 0.35 * df['MonthlyCharges_scaled'])\ndf['segment_1'] = pd.qcut(df['segment_score_1'], 5, \n                          labels=['E', 'D', 'C', 'B', 'A']).astype('O')","25e45022":"df[['segment_score_1', 'segment_1']].head(10)","277521c2":"churn_to_segment_1 = df.groupby(['Churn', 'segment_1'])\\\n.agg({'segment_1':'count'}).unstack().T.reset_index().drop('level_0', axis=1)\nchurn_to_segment_1.columns = ['segment_1', 'Churn_0', 'Churn_1']\nchurn_to_segment_1['Churn_Ratio'] = churn_to_segment_1['Churn_1']*100\\\n\/(churn_to_segment_1['Churn_0'] + churn_to_segment_1['Churn_1'])\nchurn_to_segment_1.sort_values('Churn_Ratio', ascending=True)","e0d1878e":"df.head()","70c92494":"# I'll drop these columns. I won't use them anymore.\ndf.drop(['tenure_scaled', 'segment_score_1', 'MonthlyCharges_scaled', 'tenure', 'MonthlyCharges'], \n        axis=1, inplace=True)","a49e584e":"df['Churn'] = df['Churn'].astype('O')","9f51eb66":"binary_cols = [col for col in df.columns if df[col].nunique() == 2]\nbinary_cols","96c090f6":"multi_col = [col for col in df.columns if df[col].nunique() > 2 and df[col].dtypes == 'O']\nmulti_col","f26a33ef":"num_col = [col for col in df.columns if df[col].dtypes in ['float64', 'int64']]\nnum_col","fd224451":"def label_encoder(dataframe, binary_col):\n    labelencoder = preprocessing.LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe","eba32916":"def one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols,\n                               drop_first=drop_first)\n    return dataframe","89db718f":"for col in binary_cols:\n    label_encoder(df, col)","77048651":"# These columns include same information that are no internet service and no phone service\ndummy_diff = ['OnlineSecurity', 'OnlineBackup', \n              'DeviceProtection', 'TechSupport', \n              'StreamingTV', 'StreamingMovies', \n              'MultipleLines']","1cacb24c":"df = one_hot_encoder(df, dummy_diff, drop_first=False)","c295ca91":"df.head()","859e50f1":"drop_list = df.columns[df.columns.str.contains(pat = 'No internet service')].to_list()\ndrop_list.append('MultipleLines_No phone service')\ndrop_list","15a29deb":"df.drop(drop_list, axis=1, inplace=True)","3ec14418":"# Difference list\ndummy = list(set(multi_col) - set(dummy_diff))\ndummy","78dfbab2":"df = one_hot_encoder(df, dummy, drop_first=True)","be5d69a6":"df.head()","8f4fb35c":"X = df.drop('Churn', axis=1)\ny = df['Churn']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, random_state=101)","f5b1fca1":"scaler = StandardScaler().fit(X_train[num_col])\nX_train[num_col] = scaler.transform(X_train[num_col])\n\nscaler = StandardScaler().fit(X_test[num_col])\nX_test[num_col] = scaler.transform(X_test[num_col])","07b4b39d":"X_train.shape, X_test.shape","ac5b5440":"print(' Churn No Ratio: ', round(df['Churn'].value_counts()[0]\/df.shape[0] ,2), '\\n', \n      'Churn Yes Ratio: ', round(df['Churn'].value_counts()[1]\/df.shape[0] ,2))","45906f63":"models = [('LR', LogisticRegression(solver='liblinear')),\n          ('KNN', KNeighborsClassifier()),\n          ('CART', DecisionTreeClassifier()),\n          ('RF', RandomForestClassifier()),\n          ('SVC', SVC(gamma='auto')),\n          ('GB',GradientBoostingClassifier()),\n          (\"LightGBM\", LGBMClassifier())]\n\nresults = []\nnames = []\n\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=42)\n    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=\"accuracy\")\n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","8e9bc099":"loj = LogisticRegression(solver='liblinear')\nloj_model = loj.fit(X_train, y_train)\ny_pred = loj_model.predict(X_test)\nconfusion_matrix(y_test, y_pred)","1957fe04":"print(classification_report(y_test, y_pred))","f0499284":"LR = [0.81, 0.84, 0.91, 0.88, 0.70, 0.53, 0.61]","18904235":"cross_val_score(loj_model, X_test, y_test, cv=10).mean() # Model Tuned","916ed674":"logit_roc_auc = roc_auc_score(y_test, loj_model.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, loj_model.predict_proba(X_test)[:, 1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.1])\nplt.xlabel('False Positive Ratio')\nplt.ylabel('True Positive Ratio')\nplt.title('ROC_Logistic')\nplt.show();","bcc4dde6":"gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n             \"n_estimators\": [100,500,1000],\n             \"max_depth\": [3,5,10],\n             \"min_samples_split\": [2,5,10]}\n\ngbm = GradientBoostingClassifier()\n\ngbm_cv = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 2)","1cd05835":"gbm_cv.fit(X_train, y_train)","bd9511d1":"print('Best scor : ' + str(gbm_cv.best_score_))\nprint('Best parameters : ' + str(gbm_cv.best_params_))","7751619d":"gbm_tuned = GradientBoostingClassifier(learning_rate=0.05,\n                                      max_depth=5,\n                                      min_samples_split=10,\n                                      n_estimators=100)\ngbm_tuned.fit(X_train, y_train)","599ae64b":"y_pred = gbm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred) # Model Tuned","ebe24271":"print(classification_report(y_test, y_pred))","dc68001d":"GB = [0.80, 0.83, 0.91, 0.87, 0.69, 0.51, 0.59]","79113bb0":"logit_roc_auc = roc_auc_score(y_test, gbm_tuned.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, gbm_tuned.predict_proba(X_test)[:, 1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.1])\nplt.xlabel('False Positive Ratio')\nplt.ylabel('True Positive Ratio')\nplt.title('ROC_GB')\nplt.show();","d99cb661":"conclusion_1 = pd.DataFrame({'LR': LR,\n                             'GB': GB}, index=['accuracy', 'precision_0', \n                                               'recall_0', 'f_1_score_0',\n                                               'precision_1', 'recall_1', \n                                               'f_1_score_1']).T","e035bb37":"df = df_.copy()","e1319b34":"df.drop('customerID', axis=1, inplace=True)\ndf_1 = df[df['Churn'] == 'No'].sample(n=2000, random_state=1)\ndf_2 = df[df['Churn'] == 'Yes']\ndf = pd.concat([df_1, df_2]).reset_index(drop=True)","cd470c33":"df['Churn'].value_counts()","f70e2db8":"df['SeniorCitizen'] = df['SeniorCitizen'].astype('O')\ndf['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\nnull_values = df[df['TotalCharges'].isnull()].index.to_list()\ndf.loc[df.index.isin(null_values), 'TotalCharges'] = df.loc[df.index\\\n                                                            .isin(null_values),\n                                                            'MonthlyCharges']","3929bf3e":"cat_col = [col for col in df.columns if df[col].dtypes == 'O']\nnum_col = [col for col in df.columns if df[col].dtypes != 'O']","70941dde":"cat_col","5fd80602":"num_col","5a46d6c6":"df['new_tenure_segment'] = pd.cut(df['tenure'], bins=[0, 0.5, 30, 60, 100],\n                                 labels=['New', 'Low', 'Medium', 'High']).astype('O')\ndf['new_MonhlyCharges_segment'] = pd.cut(df['MonthlyCharges'], bins=[0, 70, 90, 120],\n                                 labels=['Low', 'Medium', 'High']).astype('O')","1bd14de9":"scaler = MinMaxScaler(feature_range=(1, 10))\nscaler.fit(df[['tenure', 'MonthlyCharges']])\ndf[['tenure_scaled', 'MonthlyCharges_scaled']] = scaler.transform(df[['tenure', 'MonthlyCharges']])\ndf['segment_score_1'] = (0.65 * df['tenure_scaled'] + 0.35 * df['MonthlyCharges_scaled'])\ndf['segment_1'] = pd.qcut(df['segment_score_1'], 5, labels=['E', 'D', 'C', 'B', 'A']).astype('O')\ndf.drop(['tenure_scaled', 'segment_score_1', 'MonthlyCharges_scaled',\n        'tenure', 'MonthlyCharges'], axis=1, inplace=True)","4ef51261":"binary_cols = [col for col in df.columns if df[col].nunique() == 2]\nmulti_col = [col for col in df.columns if df[col].nunique() > 2 and df[col].dtypes == 'O']\nnum_col = [col for col in df.columns if df[col].dtypes in ['float64', 'int64']]","25fd58dd":"for col in binary_cols:\n    label_encoder(df, col)","b7296a9d":"df = one_hot_encoder(df, dummy_diff, drop_first=False)\ndrop_list = df.columns[df.columns.str.contains(pat = 'No internet service')].to_list()\ndrop_list.append('MultipleLines_No phone service')\ndf.drop(drop_list, axis=1, inplace=True)\ndf = one_hot_encoder(df, dummy, drop_first=True)","59c0d771":"X = df.drop('Churn', axis=1)\ny = df['Churn']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)","48777ffa":"num_col = ['TotalCharges']","6d8bd326":"scaler = StandardScaler().fit(X_train[num_col])\nX_train[num_col] = scaler.transform(X_train[num_col])\nscaler = StandardScaler().fit(X_test[num_col])\nX_test[num_col] = scaler.transform(X_test[num_col])","626f6f86":"loj = LogisticRegression(solver='liblinear')\nloj_model = loj.fit(X_train, y_train)\ny_pred = loj_model.predict(X_test)\nconfusion_matrix(y_test, y_pred)","eb52acc1":"print(classification_report(y_test, y_pred))","b2dc4ccc":"LR = [0.77, 0.81, 0.74, 0.77, 0.74, 0.81, 0.77]","4e5f0a76":"cross_val_score(loj_model, X_test, y_test, cv=10).mean() # Tuned Model","99cc1bca":"logit_roc_auc = roc_auc_score(y_test, loj_model.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, loj_model.predict_proba(X_test)[:, 1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.1])\nplt.xlabel('False Positive Ratio')\nplt.ylabel('True Positive Ratio')\nplt.title('ROC_Logistic')\nplt.show();","bcad3f20":"gbm_params = {\"learning_rate\" : [0.001, 0.01, 0.1, 0.05],\n             \"n_estimators\": [100, 500, 1000],\n             \"max_depth\": [3,5,10],\n             \"min_samples_split\": [2,5,10]}\n\ngbm = GradientBoostingClassifier()\n\ngbm_cv = GridSearchCV(gbm, gbm_params, cv = 10, n_jobs = -1, verbose = 2)","06776a93":"gbm_cv.fit(X_train, y_train)","921a0105":"print('Best score : ' + str(gbm_cv.best_score_))\nprint('Best parameters : ' + str(gbm_cv.best_params_))","9940b1ce":"gbm_tuned = GradientBoostingClassifier(learning_rate=0.01,\n                                      max_depth=5,\n                                      min_samples_split=10,\n                                      n_estimators=500)\ngbm_tuned.fit(X_train, y_train)","126a5fb5":"y_pred = gbm_tuned.predict(X_test)\naccuracy_score(y_test, y_pred) # Model Tuned","848dd197":"print(classification_report(y_test, y_pred))","ca9483e3":"GB = [0.74, 0.75, 0.75, 0.75, 0.74, 0.74, 0.74]","21c3bf11":"logit_roc_auc = roc_auc_score(y_test, gbm_tuned.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, gbm_tuned.predict_proba(X_test)[:, 1])\nplt.figure()\nplt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1], 'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.1])\nplt.xlabel('False Positive Ratio')\nplt.ylabel('True Positive Ratio')\nplt.title('ROC_GB')\nplt.show();","2d9ab71c":"conclusion_2 = pd.DataFrame({'LR': LR,\n                        'GB': GB,}, index=['accuracy', 'precision_0', \n                                        'recall_0', 'f_1_score_0',\n                                        'precision_1', 'recall_1', \n                                        'f_1_score_1']).T","c0acf129":"conclusion_1","0f5dd930":"conclusion_2","ffa64f9a":"**I created columns type for encoding process.**","32e5c7d9":"**When we only look at the accuracy values, the success rate of 81% can be seen quite nicely. However, the correct prediction rate of churn ones is quite low, and we can understand this by looking at f1_score and other metrics. This shows that the data set is unbalanced on the basis of the target variable.**\n\n**What needs to be done to correct this imbalance?**\n\n* **Adding other customers who are churn to the data**\n\n* **Establishing a model by taking a sample close to the number of people who can't be churn**\n\n* **To provide balance by giving certain weights before creating the model**","65676bf1":"**Precision and recall are quite low**","01e87d05":"# Customer Segmentation","1a9c7833":"# GB (Gradient Boosting)","ddcb3cd6":"**Now, I'll convert remaining properties to dummy variable but i will set drop first argument to True**","1b4b0d52":"## Logistic Regression","33ef40d5":"* **When we look at the correlation graphs of numeric columns, there is a high correlation between tenure and TotalCharges, and there is also a correlation between MonthlyCharges and TotalCharges. But since it does not exceed 85% I won't drop one of both.**","84d99b92":"**First, I scale the tenure and MonthlyCharges variables over the same range. Because I'm going to generate a score using both.**","801b7303":"* **There is not an outlier observation in the numeric columns.**","b34e2aba":"### Functions","c3fb7d15":"**Now I'll create segment_score_1 to segment new scores**","ae8df934":"* **We can't use customerID so we can drop it**","842f1f00":"# Feature Engineering","d91b41a5":"# Model","063b6df4":"# Outliers","88b1673e":"# Custumer Churn","4b73e45f":"# Some Descriptive Statistics","a4e3baef":"# Scaling\n\n**I scale train and test data separately. Because I don't want the test data to be affected by the bias of the train data.**","30a03690":"* **TotalCharges numeric column but it seems object and also SeniorCitizen categorical column but it seems numeric we need to fix this**","5e971636":"* **I'm determining the columns types but first I'll create a function for this.**","54630b27":"* **Yes there are missing values in the TotalCharges. Let's have a look these**","6da305c7":"## Graphics","ac96b349":"### One-Hot Encoding (with two step)","e0663773":"# Split Data","44c2fa3c":"**Now, I creating a droplist to drop duplicated dummy features**","a62a758e":"* **Are there any missing values? Let's have a check**","72ff08f8":"**When we look at the tenure segment, it is seen that users with high tenure values are less churn.**","73a77ed2":"* **When we look at the graph, there is no correlation exceeding 40%, so it can be said that there is no serious correlation between the target variable and the independent variables.**","a2f9b31d":"**Yes, generally we can say good according to accuracy but we need to see other model success metrics**","f76a3dba":"### But First\n\n**I'm checking to balance of target data**","508ffcd9":"# Model With Sample","4b9c9a2e":"**When we look at the MonthlyCharges category, it is seen that users with low monthly fees are less churn.**","467cd11e":"* **The churn rate of fiber users is about 42%. Is there an infrastructure problem where these users are located? In addition, customers who are not internet users have a low churn rate, which shows that they do not have problems with other services.**","d0a64d56":"**We can say distribution of Churn imbalanced but first let's have a look models.**","0a08cc13":"### Unvalidated raw model results","2d01cce7":"**I choose a random sample from non-churn data.**","6ac9cfbc":"* **There is no missing value anymore**","6ab20915":"* **Churn ratio too high on SeniorCitizen variable. Maybe a special campaign can be made for these users.**","a76e8769":"**When I examined the graphs and distributions, I noticed that:**\n* **The information of the users who do not have internet service exists in 7 different variables and their number is equal to the value of 1526.**\n* **The information of customers who do not receive phone service is in 2 different variables and their number is equal to 682.**\n\n**We need to pay attention to these properties when creating a dummy variables.**","72366854":"dummy_diff = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'MultipleLines']\n\n**These columns have duplicate data that are no internet and no phone.**","42341879":"# Encoding","8e75560f":"## Feature Engineering","7d78c565":"**Yes, accuracy has decreased, but recall, f1_score, and precision success metrics have increased considerably. These metrics are much more important to us as our goal is churn estimation.**","a294d3f2":"* **Numeric columns are not normally distributed. And there is also skewness and kurtosis.**","d8135cde":"* **I'll transform datatype object to numeric for target variable because of using correlation other variables**","d82cd94b":"* **The churn rate of users who make electronic payments as a payment method is too high. Maybe there is a problem with this payment method.**","85e51e52":"* **Yes, these values are missing. But why is it missing? When I look at the tenure values, I see that the tenure values of these customers are 0. So I equate them to MonthlyCharges instead of subtracting them from the data.**","205c8dca":"* **The distribution and graphics of categorical columns are as follows;**","fd46ec5f":"* **I separate the tenure and MonthlyCharges values into different segments**\n* **It seems that users with a tenure of 0 are not churn because they are new customers.**\n* **I create a separate category for these values.**","38e6e815":"### Label Encoding","5548b3ff":"## Logistic Regression","d3f195fc":"**As can be seen, the churn values decrease as the segment values increase.**","65d7847a":"### Let's take a look at the data","6aba2ae6":"* **There are 446 people who pay their bills paperless and are not internet users, and internet service can be sold to these customers. Because they are probably a potential internet user.**","df380ab3":"# Exploratory Data Analysis","9de49cb8":"* **When we look at the 'MonthlyCharges' and 'tenure' variables, we can notice that the 'tenure' value is more effective on the churn, but 'MonthlyCharge' is not that much.**\n\n* **I create a score with these variables but I weighted them**","72ec6cb2":"## GB (GRADIENT BOOSTING)","f934d29b":"* **The churn percentage of monthly subscriptions is quite high and 2-year subscriptions are also quite low. More campaigns can be made for monthly subscriptions. Or, these subscribers may be provided with an incentive for a 2-year contract.**"}}