{"cell_type":{"d1faa8ec":"code","79abff35":"code","84d06cb6":"code","be583d68":"code","52fe7df4":"code","00009bef":"code","96f3d4e0":"code","d2a71d05":"code","5d0e7e9d":"code","77050fe4":"code","b2726d1e":"code","57ab0653":"code","4f534dbe":"code","71225703":"code","47078648":"code","fca52390":"code","cfc48dcb":"code","bfbfd3ce":"code","f8e0cc91":"code","6c9714f7":"code","0ba0bace":"code","f4abb998":"code","87e51a6e":"code","61531a12":"code","d8448075":"code","64904a82":"code","2ead88dc":"code","0181ec58":"code","3a14529c":"code","a0a7d668":"code","9ed981b7":"code","4b4bc6f9":"code","fe464b56":"code","aeb40f91":"code","0f4c88c9":"code","161a9b8e":"code","e7642ab4":"code","c943306c":"code","52a907e6":"code","5e92e708":"code","15c7908e":"code","8b563c1c":"code","d3c09a17":"code","c6f041c6":"code","d751d1dc":"code","ad0e5a6f":"code","2560ada9":"code","ee4504e7":"code","3e0562e6":"code","5a808a21":"markdown","7160adfb":"markdown","1dbcfd21":"markdown","fafda748":"markdown","b3943f34":"markdown","9c40d534":"markdown","271ef0cb":"markdown","04513499":"markdown","04ebf604":"markdown","0882da46":"markdown","63c2fd8a":"markdown","5f6fc973":"markdown","fece93aa":"markdown","108d6ff2":"markdown"},"source":{"d1faa8ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy.stats import norm\nfrom scipy import stats\nfrom sklearn import preprocessing\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.metrics import mean_absolute_error\nfrom math import sqrt\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import scale, StandardScaler, RobustScaler, OneHotEncoder, LabelEncoder\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","79abff35":"an_data = pd.read_csv('..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')\nan_data.head(10)","84d06cb6":"an_data.dtypes","be583d68":"an_data.columns","52fe7df4":"#drop the missing value automatically\nairNyc_model = an_data.dropna('columns') \nairNyc_model.isnull().sum()","00009bef":"#or this method for missing value\nairNyc_model = an_data.drop(columns=['name','id' ,'host_id','host_name', 'last_review'])\n#missing_val_count_by_column = (an_data.isnull().sum())\nmissing_val_count_by_column = (airNyc_model.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])\n\n","96f3d4e0":"fig, ax = plt.subplots(figsize=(17,6))\nplt.title('Null values in reviews_per_month', fontsize=15)\nsns.heatmap(an_data[['reviews_per_month']].isnull(), cmap=\"Blues\", yticklabels=False, ax=ax, cbar_kws={'ticks': [0, 1]})","d2a71d05":"le = preprocessing.LabelEncoder()\n\nle.fit(an_data['neighbourhood_group'])\nan_data['neighbourhood_group']=le.transform(an_data['neighbourhood_group'])\n\nle.fit(an_data['neighbourhood'])\nan_data['neighbourhood']=le.transform(an_data['neighbourhood'])\n\nle.fit(an_data['room_type'])\nan_data['room_type']=le.transform(an_data['room_type'])\n","5d0e7e9d":"# Mean from review_per month\nmean = missing_val_count_by_column['reviews_per_month'].mean()\n\n#replacing\nairNyc_model['reviews_per_month'].fillna(mean, inplace=True)\nairNyc_model.isnull().sum()","77050fe4":"### Checking dataframe shape\nairNyc_model.shape","b2726d1e":"an_data.groupby(['room_type','price'])['availability_365'].describe()","57ab0653":"nycAirbnb_features = ['room_type','neighbourhood_group','minimum_nights', 'availability_365', 'latitude', 'longitude']\nX = an_data[nycAirbnb_features]\nX.describe()","4f534dbe":"#define the y-axis\ny = an_data['price']\ny.head()","71225703":"data =X[X[\"minimum_nights\"]<1000]\n\n### We see a more Gaussian distribution here\n#hist_price2= y[\"price\"][y[\"price\"]<250].hist()\nhist_price2= X[\"minimum_nights\"][X[\"minimum_nights\"]<20].hist()","47078648":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","fca52390":"print('Dimensions of the training feature matrix: {}'.format(X_train.shape))\nprint('Dimensions of the training target vector: {}'.format(y_train.shape))\nprint('Dimensions of the validation feature matrix: {}'.format(X_test.shape))\nprint('Dimensions of the validation target vector: {}'.format(y_test.shape))","cfc48dcb":"for max_leaf_nodes in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n#Define tree\n    dtr_model = DecisionTreeRegressor(criterion='mse',max_depth= max_leaf_nodes,random_state=0)\n\n#Model fitting\n    dtr_model.fit(X_train, y_train)\n\n    y_pred = dtr_model.predict(X_test)\n    print(mean_absolute_error(y_test, y_pred))","bfbfd3ce":"### R squared value. 6,258 -> Overfitting?\ndtr_model.score(X_train, y_train)","f8e0cc91":"from subprocess import check_call\nfrom PIL import Image, ImageDraw, ImageFont\nfrom IPython.display import Image as PImage\nfrom sklearn.tree import export_graphviz\nwith open(\"tree1.dot\", 'w') as f:\n     f = export_graphviz(dtr_model,\n                              out_file=f,\n                              max_depth = 3,\n                              impurity = True,\n                              feature_names = ['room_type', 'neighbourhood_group','minimum_nights', 'availability_365', 'latitude', 'longitude'],\n                              rounded = True,\n                              filled= True )\ncheck_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\nimg = Image.open(\"tree1.png\")\ndraw = ImageDraw.Draw(img)\nimg.save('sample-out.png')\nPImage(\"sample-out.png\")","6c9714f7":"#y_pred = dtr_model.predict(X_test)","0ba0bace":"# Actual vs predicted values\n\nerror = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': y_pred.flatten()})\nerror.head(15)","f4abb998":"mae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test,y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nprint('MAE (Mean Absolute Error): %s' %mae)\nprint('MSE (Mean Squared Error): %s' %mse)\nprint('RMSE (Root mean squared error): %s' %rmse)\nprint('R2 score: %s' %r2)","87e51a6e":"lr_model = LinearRegression(copy_X= True, fit_intercept = True, normalize = True)\n\nlr_model.fit(X_train, y_train)","61531a12":"### R squared value\nlr_model.score(X_train, y_train)","d8448075":"#prediction\nlr_pred = lr_model.predict(X_test)\n","64904a82":"# Actual vs predicted values\n\nerror = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': lr_pred.flatten()})\nerror.head(15)","2ead88dc":"plt.figure(figsize=(16,8))\nsns.regplot(lr_pred, y_test, line_kws={\"color\": \"red\"}, color='blue')\nplt.xlabel('Predictions')\nplt.ylabel('Actual')\nplt.title(\"Linear Model Predictions\")\nplt.grid(False)\nplt.show()","0181ec58":"# Evaluated metrics\n\nmae = metrics.mean_absolute_error(y_test, lr_pred)\nmse = metrics.mean_squared_error(y_test, lr_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, lr_pred))\nr2 = metrics.r2_score(y_test, lr_pred)\n\nprint('MAE (Mean Absolute Error): %s' %mae)\nprint('MSE (Mean Squared Error): %s' %mse)\nprint('RMSE (Root mean squared error): %s' %rmse)\nprint('R2 score: %s' %r2)","3a14529c":"### Initially, lets build a tree without any constraints.\nregrRM = RandomForestRegressor(n_estimators=300)\nregrRM.fit(X_train, y_train)","a0a7d668":"### We get R squared value at 87.1%! There is obviously a problem of overfitting:(\n\nprint(regrRM.score(X_train, y_train))\nrfm_pred= regrRM.predict(X_test)","9ed981b7":"### Using feature importance, we can see which feature had most weight\n#regrRM.feature_importances_","4b4bc6f9":"# Actual vs predicted values\n\nerror = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': rfm_pred.flatten()})\nerror.head(15)","fe464b56":"plt.figure(figsize=(16,8))\nsns.regplot(rfm_pred, y_test, line_kws={\"color\": \"red\"}, color='blue')\nplt.xlabel('Predictions')\nplt.ylabel('Actual')\nplt.title(\"Ridge Model Predictions\")\nplt.grid(False)\nplt.show()","aeb40f91":"mae = metrics.mean_absolute_error(y_test, rfm_pred)\nmse = metrics.mean_squared_error(y_test,rfm_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, rfm_pred))\nr2 = metrics.r2_score(y_test, rfm_pred)\n\nprint('MAE (Mean Absolute Error): %s' %mae)\nprint('MSE (Mean Squared Error): %s' %mse)\nprint('RMSE (Root mean squared error): %s' %rmse)\nprint('R2 score: %s' %r2)","0f4c88c9":"#Ridge Model\nridge_model = Ridge(alpha = 0.01, normalize = True)\nridge_model.fit(X_train, y_train)             \n","161a9b8e":"#prediction\nrm_pred = ridge_model.predict(X_test)","e7642ab4":"### We get R squared value at 87.1%! There is obviously a problem of overfitting:(\n\nprint(ridge_model.score(X_train, y_train))","c943306c":"# Actual vs predicted values\n\nerror = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': rm_pred.flatten()})\nerror.head(15)","52a907e6":"plt.figure(figsize=(16,8))\nsns.regplot(rm_pred, y_test, line_kws={\"color\": \"red\"}, color='blue')\nplt.xlabel('Predictions')\nplt.ylabel('Actual')\nplt.title(\"Ridge Model Predictions\")\nplt.grid(False)\nplt.show()","5e92e708":"# Evaluated metrics\n\nmae = metrics.mean_absolute_error(y_test, rm_pred)\nmse = metrics.mean_squared_error(y_test, rm_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, rm_pred))\nr2 = metrics.r2_score(y_test, rm_pred)\n\nprint('MAE (Mean Absolute Error): %s' %mae)\nprint('MSE (Mean Squared Error): %s' %mse)\nprint('RMSE (Root mean squared error): %s' %rmse)\nprint('R2 score: %s' %r2)\n","15c7908e":"#Lasso Model\nlasso_model = Lasso(alpha = 0.001, normalize =False)\nlasso_model.fit(X_train, y_train)\n\n#prediction\nlasso_pred = lasso_model.predict(X_test)\n\n### R squared value\nlasso_model.score(X_train, y_train)","8b563c1c":"# Actual vs predicted values\n\nerror = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': lasso_pred.flatten()})\nerror.head(15)","d3c09a17":"plt.figure(figsize=(16,8))\nsns.regplot(lasso_pred, y_test, line_kws={\"color\": \"red\"}, color='blue')\nplt.xlabel('Predictions')\nplt.ylabel('Actual')\nplt.title(\"Lasso Model Predictions\")\nplt.grid(False)\nplt.show()","c6f041c6":"# Evaluated metrics\n\nmae = metrics.mean_absolute_error(y_test, lasso_pred)\nmse = metrics.mean_squared_error(y_test, lasso_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, lasso_pred))\nr2 = metrics.r2_score(y_test, lasso_pred)\n\nprint('MAE (Mean Absolute Error): %s' %mae)\nprint('MSE (Mean Squared Error): %s' %mse)\nprint('RMSE (Root mean squared error): %s' %rmse)\nprint('R2 score: %s' %r2)\n","d751d1dc":"#ElasticNet Model\nmodel_enet = ElasticNet(alpha = 0.01, normalize=False)\nmodel_enet.fit(X_train, y_train) \n\n#prediction\nenet_pred = model_enet.predict(X_test)\n\n### R squared value\nmodel_enet.score(X_train, y_train)","ad0e5a6f":"# Actual vs predicted values\n\nerror = pd.DataFrame({'Actual Values': np.array(y_test).flatten(), 'Predicted Values': enet_pred.flatten()})\nerror.head(15)","2560ada9":"plt.figure(figsize=(16,8))\nsns.regplot(enet_pred, y_test, line_kws={\"color\": \"red\"}, color='blue')\nplt.xlabel('Predictions')\nplt.ylabel('Actual')\nplt.title(\"Elastic Net Model Predictions\")\nplt.grid(False)\nplt.show()","ee4504e7":"# Evaluated metrics\n\nmae = metrics.mean_absolute_error(y_test, enet_pred)\nmse = metrics.mean_squared_error(y_test, enet_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, enet_pred))\nr2 = metrics.r2_score(y_test, enet_pred)\n\nprint('MAE (Mean Absolute Error): %s' %mae)\nprint('MSE (Mean Squared Error): %s' %mse)\nprint('RMSE (Root mean squared error): %s' %rmse)\nprint('R2 score: %s' %r2)\n","3e0562e6":"fig, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(2, 4, figsize=(30, 20))\nfig.suptitle('True Values vs Predictions')\n\nax1.scatter(y_test, lr_pred)\nax1.set_title('Linear Regression - Phase-1')\n\nax2.scatter(y_test, rm_pred)\nax2.set_title('Ridge Model Regression - Phase-1')\n\nax3.scatter(y_test, lasso_pred)\nax3.set_title('Lasso Model Regression - Phase-1')\n\nax4.scatter(y_test, enet_pred)\nax4.set_title('ElastricNet - Phase-1')\n\nax5.scatter(y_test, y_pred)\nax5.set_title('Decision Tree Regressor - Phase-1')\n\nax6.scatter(y_test, rfm_pred)\nax6.set_title('Randrom Forest Regressor - Phase-1')\n","5a808a21":"**Visualization**","7160adfb":"**Model 1: Decision Tree Regression**","1dbcfd21":"Lasso","fafda748":"the missing values will be replaced with mean","b3943f34":"Splitting into training and validation data\n\n","9c40d534":"**Random Forest Regressor**\n\n","271ef0cb":"**Ridge Regression**","04513499":"**ElasticNet**","04ebf604":"**Missing Values**","0882da46":"We will use following machine learning models from SciKit Learn to make predictions:\n\n1. Decision Tree\n2. Linear Regression\n3. Random Forest Regressor\n4. Lasso Regression\n5. Ridge Regression\n6. Elastic Net","63c2fd8a":"**Model 2: Linear Regression**","5f6fc973":"Choosing Features (X-Axis)","fece93aa":"![](http:\/\/)Drop the missing value or replace it with mean ","108d6ff2":"# **Designing Price Prediction ML Model**"}}