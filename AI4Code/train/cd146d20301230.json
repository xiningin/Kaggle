{"cell_type":{"ff1a872c":"code","d684ac8d":"code","828307ea":"code","f04e560f":"code","ec3408ff":"code","0eabe43c":"code","08349ffb":"code","8af3c944":"code","f6ba65e1":"code","b1261f0d":"code","d992f78d":"code","7fe76b6c":"code","908f967e":"code","21fe901d":"code","e0ef1c41":"code","6ba327b8":"code","b3c5d5aa":"code","03ad4c15":"code","8b6bae77":"code","5b659a88":"code","4269d07a":"code","c76efec0":"code","ca6f7b4d":"code","775ba61e":"markdown"},"source":{"ff1a872c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) \n# will list the files in the input directory\n\nimport os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import LabelEncoder\n# Any results you write to the current directory are saved as output.","d684ac8d":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","828307ea":"train.head()","f04e560f":"(train.shape, test.shape)","ec3408ff":"all_df = pd.concat([train, test], sort=False)","0eabe43c":"all_df.head()","08349ffb":"def preprocess(df, cat_cols):\n  df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n  \n  for cat_col in cat_cols:\n    if cat_col in ['Embarked']:\n      df[cat_col] = LabelEncoder().fit_transform(df[cat_col].astype(str))\n    else:\n      df[cat_col] = LabelEncoder().fit_transform(df[cat_col])\n  \n  df = df.fillna(df.mean())\n  return df","8af3c944":"cat_cols = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\nall_df = preprocess(all_df, cat_cols)\nall_df.head()","f6ba65e1":"train_df = all_df.head(train.shape[0])\ntrain_df.shape","b1261f0d":"class TabularDataset(Dataset):\n  def __init__(self, df, categorical_columns, output_column=None):\n    super().__init__()\n    self.len = df.shape[0]\n    \n    self.categorical_columns = categorical_columns\n    self.continous_columns = [col for col in df.columns if col not in self.categorical_columns + [output_column]]\n    \n    if self.continous_columns:\n      self.cont_X = df[self.continous_columns].astype(np.float32).values\n    else:\n      self.cont_X = np.zeros((self.len, 1))\n      \n    if self.categorical_columns:\n      self.cat_X = df[self.categorical_columns].astype(np.int64).values\n    else:\n      self.cat_X = np.zeros((self.len, 1))\n      \n    if output_column != None:\n      self.has_label = True\n      self.label = df[output_column].astype(np.float32).values.reshape(-1, 1)\n    else:\n      self.has_label = False\n  \n  def __len__(self):\n    return self.len\n  \n  def __getitem__(self, index):\n    if self.has_label:\n      return [self.label[index], self.cont_X[index], self.cat_X[index]]\n    else:\n      return [self.cont_X[index], self.cat_X[index]]","d992f78d":"train_ds = TabularDataset(train_df, cat_cols, 'Survived')\ntrain_dl = DataLoader(train_ds, 64, shuffle=True)","7fe76b6c":"len(train_ds)","908f967e":"class TitanicNet(nn.Module):\n  def __init__(self, emb_dims, n_cont, lin_layer_sizes, output_size):\n    super().__init__()\n    self.emb_layers = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\n\n    self.n_embs = sum([y for x, y in emb_dims])\n    self.n_cont = n_cont\n\n    # Linear Layers\n    first_lin_layer = nn.Linear(self.n_embs + self.n_cont, lin_layer_sizes[0])\n\n    self.lin_layers = nn.ModuleList(\n        [first_lin_layer] + \n        [nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1]) for i in range(len(lin_layer_sizes) - 1)]\n    )\n    \n#     for lin_layer in self.lin_layers:\n#       nn.init.kaiming_normal_(lin_layer.weight.data)\n\n    # Output Layer\n    self.output_layer = nn.Linear(lin_layer_sizes[-1], output_size)\n    nn.init.kaiming_normal_(self.output_layer.weight.data)\n\n    # Batch Norm Layers\n    self.first_bn_layer = nn.BatchNorm1d(self.n_cont)\n    self.bn_layers = nn.ModuleList([nn.BatchNorm1d(size) for size in lin_layer_sizes])\n    \n  def forward(self, cont_data, cat_data):\n    if self.n_embs != 0:\n      x = [emb_layer(cat_data[:, i]) for i, emb_layer in enumerate(self.emb_layers)]\n      x = torch.cat(x, 1)\n      \n    if self.n_cont != 0:\n      normalized_cont_data = self.first_bn_layer(cont_data)\n\n      if self.n_embs != 0:\n        x = torch.cat([x, normalized_cont_data], 1) \n      else:\n        x = cont_data\n        \n    for lin_layer, bn_layer in zip(self.lin_layers, self.bn_layers):\n      x = torch.relu(lin_layer(x))\n      x = bn_layer(x)\n\n    x = self.output_layer(x)\n    x = torch.sigmoid(x)\n    return x","21fe901d":"cat_dims = [int(all_df[col].nunique()) for col in cat_cols]\ncat_dims","e0ef1c41":"emb_dims = [(x, min(50, (x + 1) \/\/ 2)) for x in cat_dims]\nemb_dims","6ba327b8":"torch.manual_seed(2)","b3c5d5aa":"model = TitanicNet(emb_dims, n_cont=2, lin_layer_sizes=[50, 100, 50], output_size=1)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.003)\nno_of_epochs = 10\ncriterion = nn.BCELoss()\n\nfor epoch in range(no_of_epochs):\n  epoch_loss = 0\n  epoch_accuracy = 0\n  i = 0\n  for y, cont_x, cat_x in train_dl:\n    preds = model(cont_x, cat_x)\n    loss = criterion(preds, y)\n    epoch_loss += loss\n    \n    accuracy = ((preds > 0.5).float() == y).float().mean()\n    epoch_accuracy += accuracy\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n  \n  print(\"Epoch \", epoch, \", loss: \", epoch_loss.item()\/len(train_dl), \"accuracy: \", epoch_accuracy.item()\/len(train_dl))\n  ","03ad4c15":"test_df = all_df.tail(test.shape[0])\ntest_ds = TabularDataset(test_df, cat_cols, 'Survived') # The label is actually useless. But to keep our code consistent, we leave it here.\ntest_dl = DataLoader(test_ds, len(test_ds))","8b6bae77":"with torch.no_grad():\n  for _, cont_x, cat_x in test_dl:\n    preds = model(cont_x, cat_x)\n    preds = (preds > 0.5)","5b659a88":"preds.flatten().shape","4269d07a":"output_df = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':preds.flatten().numpy()})","c76efec0":"output_df.head()","ca6f7b4d":"output_df.to_csv('titanic_preds.csv', index=False)","775ba61e":"commit 6: Use sigmoid and BCELoss()"}}