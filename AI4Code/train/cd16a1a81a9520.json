{"cell_type":{"cc85ab7c":"code","499da5b6":"code","2c46437f":"code","129afa61":"code","021a2165":"code","b2053960":"code","9d8644ec":"code","c8f65f11":"code","ca709324":"code","6d701cc3":"code","016c9b37":"code","8aba0a63":"code","a4d81904":"code","c8be7cb1":"code","7189ebbf":"code","324dc3b0":"code","54411085":"code","8dc1d494":"code","3ba7a4a6":"code","61ff248f":"code","4e9c507d":"code","e63063b1":"code","f0a746a7":"code","3d129d15":"markdown","038a6f8d":"markdown","2c3f4c6a":"markdown","299ea5f4":"markdown","03a3d56e":"markdown","bab94fd3":"markdown","25470dab":"markdown","663a8ea0":"markdown","1e2f3dff":"markdown","c0f835be":"markdown","97f2d576":"markdown","a404fbe0":"markdown","fa794619":"markdown","f712b93d":"markdown","4ced04d4":"markdown","fe5f66ed":"markdown","fd3bbf3b":"markdown","33b2a708":"markdown","8a60c977":"markdown","f75c2e03":"markdown","7becbbdc":"markdown","87c104c8":"markdown"},"source":{"cc85ab7c":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy import stats\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\nfrom os import listdir\nprint(listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","499da5b6":"data = pd.read_csv('..\/input\/hmnist_64_64_L.csv')\ndata.head()","2c46437f":"print(\"The data consists of {} samples\".format(data.shape[0]))","129afa61":"class_names = {1: \"Tumor\", 2: \"Stroma\", 3: \"Complex\", 4: \"Lympho\",\n               5: \"Debris\", 6: \"Mucosa\", 7: \"Adipose\", 8: \"Empty\"}\nclass_colors = {1: \"Red\", 2: \"Orange\", 3: \"Gold\", 4: \"Limegreen\",\n                5: \"Mediumseagreen\", 6: \"Darkturquoise\", 7: \"Steelblue\", 8: \"Purple\"}","021a2165":"sns.set_style(\"whitegrid\")\nfig, ax = plt.subplots(2,4, figsize=(25,11))\nfor n in range(2):\n    for m in range(4):\n        class_idx = n*4+(m+1)\n        sns.distplot(data[data.label == class_idx].drop(\"label\", axis=1).values.flatten(),\n                     ax=ax[n,m],\n                     color=class_colors[class_idx])\n        ax[n,m].set_title(class_names[class_idx])\n        ax[n,m].set_xlabel(\"Intensity\")\n        ax[n,m].set_ylabel(\"Density\")","b2053960":"def get_overall_statistics(data, cancer_class):\n    class_intensities = data[data.label == cancer_class].values.flatten()\n    class_stats = np.zeros(10)\n    class_stats[0] = stats.mode(class_intensities)[0][0]\n    for q in range(1, 10):\n        class_stats[q] = np.quantile(class_intensities, (q * 10)\/100)\n    return class_stats\n\nstats_quantities = [\"Mode\", \"Q10\", \"Q20\", \"Q30\", \"Q40\", \"Median\", \"Q60\", \"Q70\", \"Q80\", \"Q90\"]\noverall_statistics = pd.DataFrame(index = np.arange(1,9), columns=stats_quantities)\n\nfor class_idx in range(1,9):\n    overall_statistics.loc[class_idx,:] = get_overall_statistics(data, class_idx)\n\noverall_statistics = overall_statistics.reset_index()\noverall_statistics[\"index\"] = overall_statistics[\"index\"].apply(lambda l : class_names[l])\noverall_statistics = overall_statistics.set_index(\"index\")\noverall_statistics.index.name = None","9d8644ec":"fig, ax = plt.subplots(1,1,figsize=(15,5))\nsns.heatmap(overall_statistics, annot=True, cbar=False, fmt=\"g\", cmap=\"YlGnBu_r\", ax=ax)","c8f65f11":"image_statistics = pd.DataFrame(index=data.index)\nimage_statistics[\"Mode\"] = data.apply(lambda l: stats.mode(l)[0][0], axis=1)\nfor q in range(1, 10):\n    col_name = \"Q\" + str(q*10)\n    image_statistics[col_name] = data.apply(lambda l: np.quantile(l, (q*10)\/100), axis=1)\n\nimage_statistics[\"label\"] = data.label.values\nimage_statistics.head()","ca709324":"your_choice = [\"Mode\"]","6d701cc3":"sns.set_style(\"whitegrid\")\nfig, ax = plt.subplots(2,4, figsize=(25,11))\nfor n in range(2):\n    for m in range(4):\n        class_idx = n*4+(m+1)\n        sns.distplot(data[data.label == class_idx].drop(\"label\", axis=1).values.flatten(),\n                     ax=ax[n,m],\n                     color=class_colors[class_idx], \n                     norm_hist=True,\n                     bins=50)\n        sns.distplot(image_statistics[image_statistics.label == class_idx][your_choice].values,\n                     ax=ax[n,m],\n                     color=\"lightskyblue\",\n                     norm_hist=True, \n                     bins=50)\n        ax[n,m].set_title(class_names[class_idx])\n        ax[n,m].set_xlabel(\"Intensity\")\n        ax[n,m].set_ylabel(\"Density\")","016c9b37":"sns.pairplot(data=image_statistics,\n             vars=[\"Mode\", \"Q20\", \"Q50\", \"Q70\"],\n             hue=\"label\",\n             palette=class_colors,\n             plot_kws={\"s\": 20, \"alpha\": 0.2},\n             size=4, \n             diag_kind=\"hist\")","8aba0a63":"from sklearn.mixture import GaussianMixture\nfrom sklearn.preprocessing import StandardScaler","a4d81904":"scaler = StandardScaler()\nX = scaler.fit_transform(image_statistics.drop(\"label\", axis=1).values)\ny = image_statistics.label.values","c8be7cb1":"model = GaussianMixture(n_components=8,\n                        covariance_type=\"full\",\n                        n_init=10,\n                        random_state=0)","7189ebbf":"cluster = model.fit_predict(X)\nimage_statistics[\"cluster\"] = cluster","324dc3b0":"counts = image_statistics.groupby(\"label\").cluster.value_counts()\ncounts = counts.unstack()\ncounts.fillna(0, inplace=True)\n\nsns.set()\nplt.figure(figsize=(20,6))\nfor n in range(8):\n    for m in range(1,9):\n        plt.scatter(n, m, s=counts.loc[m,n], color=class_colors[m])\nplt.xlabel(\"Cluster\")\n#plt.ylabel(\"Cancer label\")\nplt.yticks(np.arange(1,9), [class_names[label] for label in list(np.arange(1,9))]);\nplt.title(\"Which cancer type is covered most per cluster?\");","54411085":"selection = image_statistics[(image_statistics.cluster==6) & (image_statistics.label==2)].index.values\nopposite = np.random.choice(\n    image_statistics[(image_statistics.cluster==0) & (image_statistics.label==2)].index.values, \n    size=len(selection)\n)\n\nfig, ax = plt.subplots(2, np.min([len(selection),5]), figsize=(20,10));\nfor n in range(len(selection)):\n    ax[0,n].imshow(data.drop(\"label\", axis=1).loc[selection[n],:].values.reshape(64,64), cmap=\"gray\")\n    ax[0,0].set_title(\"Images of comet tail cluster {}\".format(str(6)))\n    ax[0,1].set_title(\"of the class: {}\".format(class_names[2]))\n    ax[1,n].imshow(data.drop(\"label\", axis=1).loc[opposite[n],:].values.reshape(64,64), cmap=\"gray\")\n    ax[1,0].set_title(\"Images of major cluster {}\".format(str(0)))\n    ax[1,1].set_title(\"of the class: {}\".format(class_names[2]))","8dc1d494":"pal = sns.color_palette(\"Set2\", n_colors=10)\nfig, ax = plt.subplots(2,5, figsize=(20,9))\ncols_to_use = image_statistics.drop(\"label\", axis=1).columns.values\nfor n in range(5):\n    for m in range(2):\n        col = cols_to_use[m*5 + n]\n        sns.distplot(image_statistics[col].values, ax=ax[m,n], color=pal[m*5 + n])\n        ax[m,n].set_title(col)","3ba7a4a6":"cols_to_use = [\"Q10\", \"Q90\", \"Mode\", \"label\"]\nreduced_statistics = image_statistics.loc[:,cols_to_use].copy()","61ff248f":"fig, ax = plt.subplots(1,3, figsize=(20,5));\nsns.kdeplot(reduced_statistics.Q10, reduced_statistics.Mode, shade=True, ax=ax[0]);\nsns.kdeplot(reduced_statistics.Mode, reduced_statistics.Q90, shade=True, ax=ax[1]);\nsns.kdeplot(reduced_statistics.Q10, reduced_statistics.Q90, shade=True, ax=ax[2]);","4e9c507d":"scaler = StandardScaler()\nX = scaler.fit_transform(reduced_statistics.drop(\"label\", axis=1).values)\ny = image_statistics.label.values\n\nmodel = GaussianMixture(n_components=3,\n                        covariance_type=\"full\",\n                        n_init=10,\n                        random_state=0)\n\ncluster = model.fit_predict(X)\nreduced_statistics[\"cluster\"] = cluster\n\ncounts = reduced_statistics.groupby(\"label\").cluster.value_counts()\ncounts = counts.unstack()\ncounts.fillna(0, inplace=True)\n\ncounts = counts.astype(np.int)","e63063b1":"sns.set()\nplt.figure(figsize=(10,6))\nfor n in range(3):\n    for m in range(1,9):\n        plt.scatter(n, m, s=counts.loc[m,n], color=class_colors[m])\nplt.xlabel(\"Cluster\")\nplt.xticks([0, 1, 2])\n#plt.ylabel(\"Cancer label\")\nplt.yticks(np.arange(1,9), [class_names[label] for label in list(np.arange(1,9))]);\nplt.title(\"Which cancer type is covered most per cluster?\");","f0a746a7":"trace1 = go.Scatter3d(\n    x=reduced_statistics.Q10,\n    y=reduced_statistics.Mode,\n    z=reduced_statistics.Q90,\n    mode='markers',\n    marker=dict(\n        color=reduced_statistics.cluster,\n        colorscale = \"Portland\",\n        opacity=0.4,\n        size=3\n    )\n)\n\ndata = [trace1]\nlayout = go.Layout(\n    title = 'Clustering image statistics',\n    scene = dict(\n        xaxis = dict(title=\"Q10\"),\n        yaxis = dict(title=\"Mode\"),\n        zaxis = dict(title=\"Q90\"),\n    ),\n    margin=dict(\n        l=0,\n        r=0,\n        b=0,\n        t=0\n    )\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='3d-scatter-colorscale')","3d129d15":"### Take-Away\n\n* This looks far better organized that the clustering with 8 components. \n* We can see that the **adipose and empty** class with very **bright intensities** per image are grouped together in **cluster 1**. In addition there is a small fraction of debris classes that probably corresponds to the comet tail - images that are very bright but not the same as empty and adipose classes.\n* The next **cluster 1** is occupied by sample images with most **common intensities ranging from 0 to 200**. As they are all grayscaled it makes sense that they have very similar image statistics. \n* From my point of view **cluster 2** is most interesting as it contains samples from each class and probably corresponds to the comet tail. These **could be outlier images that should be treated carefully during cancer classification!** ","038a6f8d":"### How many tissue kinds should we choose?\n\nFollowing the guideline \"start simple, grow complex\" I like to choose a model with 8 components: \n* The first six of them cover the classes tumor, stroma, lympho, debris and mucosa.\n* With the seventh component we like to model the comet tail: all outlier images and the adipose class.\n* The last component hopefully will cover the comet itself which stands for the empty class.\n\nI'm very curious if this idea will be reflected by our unsupervised clustering! :-)","2c3f4c6a":"### Take-Away\n\n* First of all we can see that many features have almost the same distribution. This kind of duplication makes it harder for our model to distinguish between different classes as they are not useful for separation. Consequently we should only keep those with interesting patterns. \n* Let's stay simple again and choose the following quantities: Q10 for darkest values as well as Q90 for the brightest and the mode. ","299ea5f4":"## How does the comet tail differ in the case of Stroma cancer?","03a3d56e":"### Take-Away\n\n* It seems that the outliers in the comet tail are broken tissues. Perhaps the preparation of the probe for the microscope wasn't successful in these cases... \n* Even thoug clustering is not perfect at the moment we have separated images of different quality using gaussian mixture! Hence it's worth it to continue! ;-)","bab94fd3":"### Take-Away\n\n* Besides the heavy growd located more or less close to the identity line we can see data spots close to 250 that look like a **tail of a comet.** Their images have very high intensity values and we assume that they could be empty or of low cellular density. \n* This comet tail is especially interesting for the Mode compared to the Q20 and Q70 quantity:\n    * The mode of the comet tail is very high. **This tells us that the image might be very bright or empty**. But the Q20 tells us that there are some intensities in these comet images that are very low. **This is a hint that there are still some cells**. In addition this depends on the class! High intensity images of the tumor class may contain darker tissues compared to debris or adipose.  \n    * Comparing the mode and Q70 we can still see that **depending on the class** some images of the comet tail are up to 70 % occupied by darker values. This applies particulary strong to the tumor and the stroma class. \n    * Comparing Q20 and Q70 we can see in general that Q70 is of higher intensity than Q20. This makes sense as each image should have some variation in its values. **Only the empty class has values of Q20 and Q70 that are almost identical**. Besides that we can see that the adipose class has some lower Q20 values than Q70 and that this is a way to distinguish from the empty class. Looking at the read tumor data spots we can observe that there are some outlier images that have very low Q20 value but very high Q70. They fit to the finding we already yield by comparisions of the mode. ","25470dab":"## Image intensity distributions per class","663a8ea0":"### Take away\n\n* Using a kernel density plot we have found that there could be three different kinds of images without further preprocessing of Q10, Q90 and the mode. \n* Taking a look at the pairplot above we can see that there are some samples that are somehow drifting to the comet tail. Perhaps we can find such outliers by using only 3 components: 1 for the comet and its tail, 1 for drifting samples and 1 for all samples in a dense region where most of the images live. ","1e2f3dff":"Even though some cancer overall image statistics look similar they are all different and computing these quantities could be a good choice to try out clustering. But in advance we should compute these statistical values per image. We have to clearify wether each image somhow reflects its corresponding overall distribution of if we can find huge variations within classes. ","c0f835be":"### Take-Away\n\n* We can see that the intensity distribution over all images per class are very different.\n* Perhaps we can use this difference to cluster images based on their image statistics.\n* Before doing that we need to make sure than image statistics and overall-intensity distribution statistics are related to each other in a fine way. ","97f2d576":"## Can we find the different kind of tissues?\n\n\nWe have find out that there are **probably more kinds of tissues than classes**. Beside that we have found some special images - of the comet tail - that have both very high and low intensity values. Both observations are very important and a challenge! If we use neural networks to classify cancer **the comet tail images may cause our model to draw bad decision boundaries as it tries to learn from these exotics**. Besides that it may be difficult to cover different tissue subgroups per class with only one model. Consequently it could be worth to cluster images based on image statistics to reveal hidden kinds of tissues and to use this new feature or information for making better predictions. Let's use Gaussian Mixture as a latent variable model for this job! :-) ","a404fbe0":"### Take away\n\n* Browsing through the different statistical quantities from Q10 up to Q90 and the mode we can see that the distribution per image do not reflect the intensity distribution over all image for one class. \n* One example: Take the mode as plot quantity and look at the tumor class. The red distribution is gained by throwing all images in one bag and looking at their overall intensities. Now, the blue curve is obtained by taking the mode of each image and putting all modes in one bag. Hence we are looking at the overall mode values. We can see that the blue curve modes cover both modes of the red curve. What does this tell us? Well :-) We can see that there is some true bimodality in the image distribution of the tumor class. We might say that **there are two kind of images, that both correspond to the tumor class**. \n* This pattern is even stronger for the Debris class. There are three kind of images each of them with a different kind of mode. \n* Looking at the individual image statistics we have now **gained an impression that there are more kind of images than classes**.\n* This is an important finding. If we like to use an algorithm to classify different types of cancer it might be very useful to know the kind of images. \n* In addition it's very interesting that at least some images of each class have a highest mode close to 250. Perhaps these images do not contain many cells and are more empty than the others. We have to check this. ","fa794619":"## Does preprocessing help for clustering?\n\nWe have already explored the distributions of statistical quantities per class. But to decide if we need more preprocessing of these features we should take a look at each statistical quantity over all classes:","f712b93d":"Exploring the data of the baseline model we have seen that 64x64 grayscaled images show interesting intensity distributions per class. To check out if a clustering based on image statistics can be useful to predict cancer classes, let's work with this data again:","4ced04d4":"# Welcome\u00b6\nWithin this series of kaggle kernel notebooks I invite you to dive with me into colorectal cancer classification. Notebooks so far:\n\n* [dataset overview](https:\/\/www.kaggle.com\/allunia\/patterns-of-colorectal-cancer-dataset-overview) (complete)\n* baseline model\n* image clustering\n\n### Short overview\n\n* 8 classes of cancer tissues\n* multiclass classification\n* Kather_texture_2016_image_tiles_5000\n    * 150 x 150 pixel in size\n    * 5000 samples\n\n### Topics in this notebook \n\n* image statistics per class\n* unsupervised clustering\n* supervised clustering\n","fe5f66ed":"## Overall image statistics\n\nOk, let's try to state some meaningful statistical quantities:\n\n1. The mean and the standard deviation are not useful quantities as we have some bimodal or even trimodal distributions or high skewness. The mean is not robust and highly influenced by outliers. \n2. In contrast quantile information and the main mode could be very useful as they give us more insights.","fd3bbf3b":"Now, let's make a scatterplot again to visualise where these clusters are located and if my assumptions are true:","33b2a708":"## Dense, drifting and comet images\n\nThe clustering using 8 components yielded very inhomogenous clusters with overlapping classes. By analysing the image intensitiy distributions per class we figured out that many classes share the same kind of distribution. Finally the kdeplot showed us that there is **only a motivation to choose 3 components and probably that one of these clusters may hold outliers of several classes**. This knowledge could be very helpful during training of many classification algorithm as they are often highly influenced by outliers during their learning procedure. ","8a60c977":"## Loading packages and data","f75c2e03":"### Take-Away\n\n* We can see that the empty images with very high intensities are covered by cluster 1. In addition this group holds some of the adipose images as well. \n* Cluster 6 seems to hold a part of the comet tail as it contains adipose and some empty, debris and stroma images. Perhaps cluster 3 is part of the tail as well. We have to check this! ;-)\n* The other clusters often contain more than one major class which motivates to either improve the features such that we are able to distinguish better between classes or to choose less components for detecting outliers in a single cluster. ","7becbbdc":"## Individual image statistics","87c104c8":"## The emptiness of the comet tail\n\nAre images with a high intensity empty or do they have at least some dark tissues and cells? Perhaps we can gain even more insights by looking at paired-statistical quantities:"}}