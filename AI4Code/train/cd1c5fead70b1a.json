{"cell_type":{"3fd45919":"code","067a4ca8":"code","edf1cf51":"code","d2d417d3":"code","f08af378":"code","b5acae65":"code","9ce00dbe":"code","17b91208":"code","dbc3fb1a":"code","ea4ceddf":"code","b9a29f66":"code","fc78c72e":"code","67170deb":"code","d2830508":"code","d5395416":"code","c33a46d0":"code","33320224":"code","c28b6312":"code","acf048ae":"code","6ecf4881":"code","24ebc3f2":"code","be9489ca":"code","2329cc2e":"markdown","76c37d37":"markdown","42a38c81":"markdown","94c18edf":"markdown","3a885ef0":"markdown","a5e223f9":"markdown","de68a860":"markdown","7c509b2c":"markdown","fb9582ae":"markdown","6d0337a0":"markdown","b5de976d":"markdown","5cd253d3":"markdown","da5e35d3":"markdown","59a4bc5a":"markdown","39870954":"markdown","309e7520":"markdown","c4a7147f":"markdown","149634a8":"markdown","89533a68":"markdown"},"source":{"3fd45919":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier as knn\nfrom sklearn.neural_network import MLPClassifier as mlp\nfrom sklearn.model_selection import GridSearchCV as gs\nfrom sklearn.ensemble import RandomForestClassifier as rf\nfrom sklearn.externals import joblib\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#%matplotlib inline","067a4ca8":"def model_output(grid_model):\n    \"\"\"Outputs the best mean cross validation score, the test set accuracy and the parameters of a gridsearch\"\"\"\n    print('Best mean CV accuracy: ', grid_model.best_score_)\n    print('Holdout test set accuracy: ', accuracy_score(grid_model.best_estimator_.predict(xtest), ytest))\n    print('Best parameters: ', grid_model.best_params_)","edf1cf51":"fifa = pd.read_csv('..\/input\/FIFA 2018 Statistics.csv')\nfifa.head()","d2d417d3":"heat_map = sns.heatmap(fifa.isnull(), yticklabels = False,\n            cbar = False,\n            cmap = 'viridis')","f08af378":"fifa = fifa.drop(['1st Goal', 'Own goal Time', 'Date', 'Team', 'Opponent', 'Round'], axis = 1)","b5acae65":"fifa['Own goals'] = fifa['Own goals'].fillna(0).astype(int)\nfifa['PSO'] = pd.get_dummies(fifa.PSO).Yes\nfifa['Man of the Match'] = pd.get_dummies(fifa['Man of the Match']).Yes","9ce00dbe":"game_group = [n for n in range(len(fifa)\/\/2)]\ngame_group = np.repeat(game_group, 2)\n\nfifa['winner'] = fifa.groupby(game_group)['Goal Scored'].transform(lambda x: x == max(x))\nfifa['winner'] = fifa['winner'].map({True: 1, False: 0})","17b91208":"fifa_x = fifa.drop('Man of the Match', axis = 1)\nfifa_y = fifa['Man of the Match']","dbc3fb1a":"f = plt.figure(figsize = (20, 15))\n\n## Add a density plot for each of the continuous predictors\nfor i in range(0, 15):\n    f.add_subplot(4, 4, i + 1)\n    fifa.iloc[:, i].groupby(fifa_y).plot(kind = 'kde', title = fifa.columns[i])","ea4ceddf":"scaler = StandardScaler()\nfifa_x = scaler.fit_transform(fifa_x)\nfifa_x = pd.DataFrame(fifa_x)","b9a29f66":"xtrain, xtest, ytrain, ytest = train_test_split(fifa_x, \n                                                fifa_y, \n                                                random_state = 42, \n                                                test_size = .33,\n                                                stratify = fifa_y)","fc78c72e":"log_reg = LogisticRegression()\nlog_reg.fit(xtrain, ytrain)","67170deb":"preds = log_reg.predict(xtest)\nprint(confusion_matrix(preds, ytest))\nprint('Test accuracy: ', accuracy_score(preds, ytest))","d2830508":"errors_knn = pd.DataFrame(columns = ['k_value', 'train_acc', 'test_acc'])\n\nfor n in range(1, len(xtrain)):\n    knn_clf = knn(n_neighbors = n)\n    knn_clf.fit(X = xtrain, y = ytrain)\n    \n    preds = knn_clf.predict(xtrain)\n    errors_knn.loc[n, 'train_acc'] = accuracy_score(preds, ytrain)\n    \n    preds = knn_clf.predict(xtest)\n    errors_knn.loc[n, 'test_acc'] = accuracy_score(preds, ytest)","d5395416":"errors_knn.plot(title = 'K Value Selection')\nplt.xlabel('K')\nplt.ylabel('Accuracy')\nplt.show()","c33a46d0":"preds = knn_clf.predict(xtest)\nprint(confusion_matrix(preds, ytest))\nprint('Test accuracy: ', errors_knn.test_acc.max())","33320224":"mlp_clf = mlp()\n\ngrid = {'hidden_layer_sizes': [(10, 10), (20, 10), (30, 10),\n                               (10, 20), (20, 20), (30, 20),\n                               (10, 30), (20, 30), (30, 30)], \n        'max_iter': [1000, 2000], \n        'learning_rate_init': [1e-10, 1e-5, 1e-3, 1e-2, 1e-1],\n        'random_state': [420]}\ngrid_mlp = gs(mlp_clf, grid, cv = 10)\n\ngrid_mlp.fit(xtrain, ytrain)","c28b6312":"model_output(grid_mlp)","acf048ae":"rand_for = rf()\n\ngrid = {'n_estimators': [5, 10, 15, 20, 30, 50, 100, 200, 500],\n        'max_depth' : [None, 2, 3, 5, 10, 20],\n        'criterion': ['gini', 'entropy'],\n        'random_state' : [69]}\n\ngrid_rand = gs(rand_for, grid, cv = 10)\n\ngrid_rand.fit(xtrain, ytrain)","6ecf4881":"model_output(grid_rand)","24ebc3f2":"feat_imp_rf = pd.DataFrame({'Feature' : fifa.drop('Man of the Match', axis = 1).columns,\n                            'Importance' : grid_rand.best_estimator_.feature_importances_})\n\nfeat_imp_rf.set_index('Feature', inplace = True)\nfeat_imp_rf.sort_values('Importance', inplace = True)\n\nfeat_imp_rf.plot(kind = 'barh', legend = None, title = 'Feature Importance')\nplt.show()","be9489ca":"joblib.dump(grid_rand, 'fifa_rf.pkl')","2329cc2e":"### Next try KNN using values of K from 1 to the number of training rows","76c37d37":"### Clean up missing values in own goals (0 will replace NaN since that means no own goals were scored) and dummy encode our two categorical variables","42a38c81":"### The random forest performed the best (looking at CV error)! Let's see which variables played a role in our best predictor","94c18edf":"### Lastly, we test a random forest with different numbers of trees, depths and splitting criteria using gridsearch","3a885ef0":"### Random forests had the best performance with a cross validation score of 89.4%. It allowed us to understand that the winner of the match is the most important predictor of the Man of the Match, followed by the number of goals scored. \n\n### It should be noted that the random forest didn't generalize well to the final test set, scoring only 76%. Other features may need to be mined from the data to correct for this. \n\n### Further work could include training additional model types, generating new features or properly implementing CV in the logisitic and KNN classifiers.","a5e223f9":"### Drop columns where we can't impute missing values ('Own goal Time', '1st Goal') or that intuitively don't have predictive power (such as 'Date')","de68a860":"### We use cross validation in our gridsearch and are able to use the test set properly. Comparing to KNN's test accuracy, the optimal MLP's cross-validated accuracy is slightly lower","7c509b2c":"## This notebook reads in data from the FIFA World Cup 2018, cleans the data, generates a new feature and tests logistic regression, KNN, MLP and random forests to classify the man of the match","fb9582ae":"### Each two rows represent a single game: one row for each team","6d0337a0":"### First try logistic regression and evaluate its performance on the test set","b5de976d":"### The distribution 'Goal Scored' and 'Ball Possession %' differ based on which team won Man of the Match. We now scale our data to feed it into classification models, expecting to see these variable relationships come into play","5cd253d3":"### Split the data into 1\/3 test and 2\/3 train","da5e35d3":"### Separate the outcome variable from the predictors","59a4bc5a":"### Create a column to indicate who won the match. By groups of two rows, decide who got the maximum score within a game and assign 1 for winners and 0 for losers","39870954":"### How many missing values are there, and where?","309e7520":"### What kind of relationships exist within the data? Looking at distributions for each continuous variable, separated by winners and losers of Man of the Match","c4a7147f":"### With the optimal value of K, KNN outperforms logistic regression on the test set. We next test a simple neural network, or multilayer perceptron, using gridsearch for its parameters","149634a8":"### Read in data about the FIFA World Cup 2018","89533a68":"### Save the model"}}