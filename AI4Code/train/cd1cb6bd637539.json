{"cell_type":{"bb7ac56b":"code","122f2931":"code","0876e525":"code","00334c1f":"code","f2b20236":"code","f768adad":"code","68a90084":"code","3cffa1b4":"code","05e59a77":"code","b066bd0b":"code","aef12bd1":"code","1d400d08":"code","7c6bd8d3":"code","a49940d5":"code","4efcb18f":"code","5dae4e81":"code","69e3a2f8":"code","fd2dff41":"code","2a929a79":"code","5f5316c2":"markdown","c97f7086":"markdown","908d5f1d":"markdown","98a501a5":"markdown","d838e32c":"markdown","4dcf3b09":"markdown","bde95d7a":"markdown","4ac97f88":"markdown","70e5dcea":"markdown","3b7dec40":"markdown","94410bc4":"markdown","aadc8171":"markdown","8480f826":"markdown"},"source":{"bb7ac56b":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime as dt\n\nimport plotly\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\nimport cufflinks as cf\n\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\ncf.set_config_file(world_readable=True, theme='space', offline=True)\n\ndata = pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")\ndata","122f2931":"pres = data.copy()\n\npres.loc[pres.sex == 0, 'sex'] = 'Female'\npres.loc[pres.sex == 1, 'sex'] = 'Male'\n\npres.loc[pres.cp == 0, 'cp'] = 'Asymptomatic'\npres.loc[pres.cp == 1, 'cp'] = 'Typical Angina'\npres.loc[pres.cp == 2, 'cp'] = 'Atypical Angina'\npres.loc[pres.cp == 3, 'cp'] = 'Non-anginal pain'\n\npres.rename(columns={'cp': 'Chest Pain Type', 'age': 'Age', 'sex': 'Sex'}, inplace=True)","0876e525":"gend = pres.loc[:, ['Sex', 'output']].groupby('Sex').count()\ngend['+'] = pres.loc[:, ['Sex', 'output']].groupby('Sex').sum()\ngend['output'] -= gend['+']\ngend.rename(columns={'output': '-'}, inplace=True)\ngend.iplot(kind='bar')\n\niplot(\n    px.histogram(data_frame=pres, x='Age', y='output', color='Sex', barmode='overlay',\n                 color_discrete_sequence=['DodgerBlue', 'FireBrick'],\n                 marginal='violin', opacity=0.6, template='plotly_dark',\n                 labels={'output': 'diagnoses'})\n)","00334c1f":"cp_data = pres.groupby('Chest Pain Type').count()[['output']]\ncp_data['+'] = pres.groupby('Chest Pain Type').sum()[['output']]\ncp_data.rename(columns={'output': '-'}, inplace=True)\ncp_data['-'] -= cp_data['+']\ncp_data.sort_values(by='+', ascending=False, inplace=True)\ncp_data.iplot(kind='bar', title='Chest Pain Type')","f2b20236":"iplot(px.violin(pres[pres.output == 1], x='Chest Pain Type', y='Age', color='Sex', template='plotly_dark', box=True,\n               title='Distribution Of Pain Types By Age In Men and Women With Attacks'))","f768adad":"categ_feats = ['fbs', 'restecg', 'exng', 'slp', 'caa', 'thall']\ntitles = ['Fasting blood sugar',\n          'Resting electrocardiographic results',\n          'Exercise induced angina',\n          'The slope of the peak exercise ST segment',\n          'Number of major vessels colored by flourosopy',\n          'Thal']\nvalues = [{0: '<= 120 mg\/dl', 1: '> 120 mg\/dl'},\n          {0: 'hypertrophy', 1: 'normal', 2: 'having ST-T wave abnormality'},\n          {0: 'no', 1: 'yes'},\n          {2: 'upsloping', 1: 'flat', 0: 'downsloping'}, {},\n          {2: 'normal', 1: 'fixed defect', 3: 'reversable defect'}]\ncateg_fig = make_subplots(2, 3);\n\nfor f, t, v in zip(categ_feats, titles, values):\n    f_data = pres.groupby(f).count()[['output']]\n    f_data['+'] = pres.groupby(f).sum()[['output']]\n    f_data.rename(columns={'output': '-'}, inplace=True)\n    f_data['-'] -= f_data['+']\n    f_data.rename(index = v, inplace=True)\n    iplot(px.bar(f_data, barmode='group', opacity=0.6, title=t, labels={f: '', 'value':''},\n                 color_discrete_sequence=['DarkOrange', 'DodgerBlue'], template='plotly_dark'))","68a90084":"num_feats = ['age', 'trtbps', 'chol', 'thalachh', 'oldpeak']\nfig = px.scatter_matrix(data, dimensions=num_feats, color='output', template='plotly_dark')\nfig.update_layout(\n    dragmode='select',\n    width=1000,\n    height=600,\n    hovermode='closest'\n)\niplot(fig)\nfor f in num_feats:\n    iplot(px.histogram(data[[f, 'output']], color='output', barmode='overlay',\n                 color_discrete_sequence=['DodgerBlue', 'Yellow'], labels={'value': f},\n                 marginal='box', opacity=0.6, template='plotly_dark'))","3cffa1b4":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_validate, ShuffleSplit, GridSearchCV\nfrom sklearn import preprocessing\nfrom sklearn import metrics\n\nX = data.drop(columns=['output'])\ny = data['output']\n\nX = preprocessing.normalize(preprocessing.scale(X))\nmodels_stats = pd.DataFrame(index=[\"Neg logloss\", \"Mean accuracy\"])\n\ncv_train = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n\ndef build_model(est, params):\n    bp = GridSearchCV(estimator=est, param_grid=params, cv=cv_train, n_jobs=8, verbose=False).fit(X, y).best_params_\n    print(bp)\n    return est.__class__(**bp)\n\ndef test_model(model, model_name):\n    scores = cross_validate(\n        model, X, y, cv=10,\n        scoring=['neg_log_loss', 'accuracy']\n    )\n    nll, acc = scores['test_neg_log_loss'], scores['test_accuracy']\n    pd.DataFrame(scores)[\n        ['test_neg_log_loss', 'test_accuracy']\n    ].iplot(title=model_name)\n    models_stats[model_name] = [round(nll.mean() * 2, 1) \/ 2, round(acc.mean() * 2, 2) \/ 2]","05e59a77":"# Support Vector Machines\nsvm = build_model(\n    SVC(probability=True),\n    {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n    'tol': [1e-4], 'probability': [True]}\n)","b066bd0b":"# Decision Tree\ndecision_tree = build_model(\n    DecisionTreeClassifier(random_state=0),\n    {'min_samples_leaf': range(2,10), 'random_state': [1, 2, 3]}\n)","aef12bd1":"# Random Forest\nrandom_forest = build_model(\n    RandomForestClassifier(),\n    {'n_estimators': [300, 400, 500], 'min_samples_split': [60],\n    'min_samples_leaf': [25, 30, 35], 'max_depth': [5, 6, 7],\n    'criterion': ['gini'], 'bootstrap': [False], 'random_state': [1, 2, 3]}\n)","1d400d08":"# Extra Trees\nextra_trees = build_model(\n    ExtraTreesClassifier(random_state=0),\n    {'min_samples_leaf' : range(10, 60, 10), 'random_state': [1, 2, 3]}\n)","7c6bd8d3":"# Light GBM\nlight_gbm = build_model(\n    LGBMClassifier(),\n    {'n_estimators': [500, 1000, 5000],\n    'max_depth': range(4, 9),\n    'learning_rate': [0.005, 0.01, 0.05]}\n)","a49940d5":"# CatBoost\ncatboost = build_model(\n    CatBoostClassifier(verbose=False),\n    {'n_estimators': [200, 300, 400], \n    'learning_rate': [0.003, 0.005, 0.01],\n    'max_depth': [4, 5, 6], 'verbose': [False]}\n)","4efcb18f":"# Gaussian Naive Bayes\nnaive_bayes = build_model(\n    GaussianNB(),\n    {'var_smoothing': [1e-8, 1e-9, 1e-10]}\n)","5dae4e81":"# k-Nearest Neighbors\nkNN = build_model(\n    KNeighborsClassifier(),\n    {'n_neighbors': [7, 10, 13, 15],\n    'weights': ['uniform', 'distance'],\n    'p': [1, 2, 3]}\n)","69e3a2f8":"# Gaussian Process\ngauss_proc = build_model(\n    GaussianProcessClassifier(),\n    {'max_iter_predict': [100, 200],\n    'warm_start': [True, False],\n    'n_restarts_optimizer': range(3),\n    'random_state': [1, 2, 3]}\n)","fd2dff41":"models = {\n    \"Support Vector Machines\": svm,\n    \"Decision Tree\": decision_tree,\n    \"Random Forest\": random_forest,\n    \"Extra Trees Classifier\": extra_trees,\n    \"LightGBM\": light_gbm,\n    \"CatBoost\": catboost,\n    \"Gaussian Naive Bayes\": naive_bayes,\n    \"k-Nearest Neighbors\": kNN,\n    \"Gaussian Process\": gauss_proc\n}\n\nfor model_name, model in models.items():\n    test_model(model, model_name)\n\nmodels_stats = models_stats.T.sort_values(by=['Neg logloss', 'Mean accuracy'], ascending=False)\nmodels_stats.iplot(kind=\"bar\")","2a929a79":"from sklearn.metrics import accuracy_score\nfinal_model = random_forest\nfinal_model.fit(X, y)\n\ndef classify(input_data):\n    return final_model.predict(input_data)\n\nprint(f\"{int(round(accuracy_score(classify(X), y), 2) * 100)}%\")","5f5316c2":"## Gender-Age Distribution","c97f7086":"***Conclusions:** list of features' values more common in people prone to heart attack:*\n1. *Age: below 55*\n2. *Thalach: above 150*\n3. *Oldpeak: 0-0.7, 1.3-1.7*","908d5f1d":"# Exploratory Data Analysis","98a501a5":"## Chest Pain Type Distributions","d838e32c":"# Final Model","4dcf3b09":"## Numerical features","bde95d7a":"***Conclusion:*** *list of characteristics more common in people prone to heart attack*:\n1. *Resting electrocardiographic results: normal*\n2. *No exercise induced angina*\n3. *The slope of the peak exercise ST segment: upsloping*\n4. *0 major vessels colored by flourosopy*\n5. *Thal: normal*","4ac97f88":"***Conclusion:*** *Women are more likely to have a heart attack.*","70e5dcea":"### ***Best Models*** \nRandom Forest (85%, 0.45)  \nGaussian Process (84%, 0.4)  \nSupport Vector Machines (83.5%, 0.4)","3b7dec40":"## Other categorical features","94410bc4":"***Note:***  *women age distribution for non-anginal pain is specific (sample feature?)*","aadc8171":"***Conclusions:***  \n1) *asymptomatic pain type indicates a predisposition to heart attack with the least likelihood*  \n2) *atypical angina is the most common chest pain type in people prone to heart attack*","8480f826":"# Model Selection"}}