{"cell_type":{"84b40dff":"code","31dd19b2":"code","1b841fea":"code","4fd41078":"code","62ac4d29":"code","e608347d":"code","455ec275":"code","a6c61eb6":"code","2ba06be5":"code","0851000b":"code","5e73d85b":"code","ea2eb78f":"code","c94749f1":"code","3f41f8b2":"code","979bb8ee":"code","26367c01":"code","f4968d1c":"code","98f59b92":"code","b61d8916":"code","e039bd27":"code","271b454d":"code","b5b2a5f5":"code","57426637":"markdown","d760c968":"markdown","614de838":"markdown","a1918921":"markdown","455e20e3":"markdown","49998996":"markdown"},"source":{"84b40dff":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","31dd19b2":"# Read the dataset\nhousing = pd.read_csv(\"..\/input\/california-housing-prices\/housing.csv\")","1b841fea":"housing.shape\n\n# describe function gives a summary like mean, quartiles, median, std, count, etc for the numeric columns\nhousing.describe()\n\n# %% [code]\n# info functions helps us to understand the data type of all the columns\nhousing.info()","4fd41078":"# lets check if there are missing values in the data\nhousing.isnull().sum()","62ac4d29":"plt.figure(figsize=(5,5))\nplt.hist(housing[housing[\"total_bedrooms\"].notnull()][\"total_bedrooms\"],bins=30,color=\"purple\")\n#histogram of totalbedrooms\n#data has some outliers..??\n(housing[\"total_bedrooms\"]>4000).sum()\nplt.title(\"Historgram\")\nplt.xlabel(\"Total Bedrooms\")\nplt.ylabel(\"Frequency\")\n\n# We can clearly see there are some outliers in the column, but let check with the help of box plot once more","e608347d":"plt.figure(figsize=(15,5))\nsns.boxplot(y=\"total_bedrooms\",data=housing, orient=\"h\", palette=\"plasma\")\nplt.plot\n\n#As we can see there are a lot of outliers, so to fill them we should be using ``Median`` instead of ``Mean``, \n# as the mean would vary a lot because of outliers and can affect the accuracy of our model","455ec275":"# Fill missing values\nhousing['total_bedrooms'] = housing['total_bedrooms'].fillna((housing['total_bedrooms'].median()))","a6c61eb6":"# Lets plot and see what our dependent variable ie; \"Y\" column - (\"median house price\") looks like\n# Histogram would be the best way to do it\n\nplt.figure(figsize=(20,5))\nsns.set_color_codes(palette=\"bright\")\nsns.distplot(housing['median_house_value'],color='g')\n\n# We can see there is sudden increase in the median house value at >= 5,00,000, \n# & this could be outliers. We should definately be removing them.","2ba06be5":"housing[housing[\"median_house_value\"]>300000][\"median_house_value\"].value_counts().head(10)\nhousing = housing.loc[housing[\"median_house_value\"]<500001,:]\nplt.figure(figsize=(20,5))\nsns.set_color_codes(palette=\"bright\")\nsns.distplot(housing[\"median_house_value\"], color=\"r\")","0851000b":"#The bins parameter is used to customize the number of bins shown on the plots.\nhousing.hist(bins=50,figsize=(10,10))","5e73d85b":"# Since we have some geographical data, lets see if get some meaning insights from it..\n\nplt.figure(figsize=(10,5))\nplt.scatter(housing[\"longitude\"],housing[\"latitude\"],c=housing[\"median_house_value\"],\n            s=housing[\"population\"]\/50, alpha=0.1, cmap=\"Oranges\")\nplt.colorbar()\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.title(\"House price based of geographical co-ordinates\")\n\n# We can see there are some high density areas in california, so we can say the price of house is a bit realted to\n# location as well. \n\n# Earlier when I saw the data, I thought longitude & latitude would not be weak predictors\n# but after plotting this, we can conclude even they are useful features.``\n# So never judge it by visually seeing the data just in the first time.","ea2eb78f":"# Before we split our data, we can also see that the feature - total_rooms has no significance, as this talks \n# about the rooms in the entire district. \n# Instead, we should find out, how many rooms are there in individual household, that would be more informative\n# for our analysis...\n\nhousing[\"rooms_household\"] = housing.total_rooms \/ housing.households\n\n# now we can remove this feature\nhousing.drop(\"total_rooms\", axis=1, inplace=True)\n","c94749f1":"# We have one categorical column (\"Ocean Proximity\") in the data set, lets see if we should keep this column or remove it\n\n# Barplot of categorical column\nplt.figure(figsize=(7,4))\nsns.countplot(data=housing,x='ocean_proximity', palette = \"YlOrBr_r\")\n\n# It is very definate we should be keeping this feautre, but since this is a categorical feature, we should perform \n# preprocessing on it to convert it into numerical data.\n","3f41f8b2":"# to conviently split the data into x & y part, I am rearranging the output column and bring it in the last\n\nhousing=housing[[\"longitude\", \"latitude\", \"housing_median_age\", \"total_bedrooms\", \"population\", \n                 \"households\", \"median_income\", \"ocean_proximity\", \"rooms_household\", \"median_house_value\"]]","979bb8ee":"# Spliting the data\nx = housing.iloc[:,0:9].values\ny = housing.iloc[:,9].values","26367c01":"# Converting Categorical attribute to numeric\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabel_encode_x = LabelEncoder()\nx[:, 7] = label_encode_x.fit_transform(x[:, 7])\n\nonehot = OneHotEncoder(categories=\"auto\")\nx = onehot.fit_transform(x).toarray()","f4968d1c":"# Spliting the train & test data set \nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)","98f59b92":"# Feature Scaling \/  Normalization\n\n# from sklearn.preprocessing import StandardScaler\n# scale  = StandardScaler()\n# x_train = scale.fit_transform(x_train)\n# x_test = scale.transform(x_test)","b61d8916":"# from sklearn.linear_model import LinearRegression\n# lin_reg = LinearRegression()\n# lin_reg.fit(x_train, y_train)","e039bd27":"# model for future prediction\n# y_pred = lin_reg.predict(x_test)","271b454d":"# rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n# score = lin_reg.score(x_test, y_test)\n\n# Output of score = 0.6524213016981026\n","b5b2a5f5":"# Plot Actual vs. Predicted\n\n# test = pd.DataFrame({'Predicted':y_pred,'Actual':y_test})\n# fig= plt.figure(figsize=(16,8))\n# test = test.reset_index()\n# test = test.drop(['index'],axis=1)\n# plt.plot(test[:80])\n# plt.legend(['Actual','Predicted'])\n# sns.jointplot(x='Actual',y='Predicted',data=test,kind='reg',color=\"grey\")","57426637":"#### Some memory issues with the kernel, that is why I have written the rest of the codes in comments, you can try at your end I am sure it would work.\n\n### Thank you all for understanding & reading...\n \n#### If you found this helpful an upvote would be really appreciated...","d760c968":"## As we can see only ``total_bedrooms`` column has 207 NAN values, lets treat it.\n#### There are 2 ways to treat NAN\n\n#### 1. We can delete those records which are missing (Not Recommended)\n#### 2. or we can fill those columns using the mean or median - which in this case is a pretty much easier.\n## *But what should we be using ``Mean`` or ``Median``*\n#### So to decide this we need to first check the outliers.\n","614de838":"## 2. Perform Exploratory Data Analysis","a1918921":"## California Housing Price Prediction .","455e20e3":"## 3. Performing Linear Regression\n","49998996":"## 1.Importing required libraries"}}