{"cell_type":{"9ffa7584":"code","916ac1c7":"code","3675efc4":"code","06abf270":"code","ddc68643":"code","fa42858e":"code","e602e145":"code","3b7d5e27":"code","51067d80":"code","6c705b23":"code","a9c87ded":"code","e3af94f8":"code","988e1420":"code","f7c3dec8":"code","4a1f97ec":"code","f70c4eac":"code","73b295d0":"code","b88d2b40":"code","18201845":"code","e9420e76":"code","f8f364cf":"code","124c5220":"code","84c79f0a":"code","a2221168":"code","cc2ebd23":"code","79c59cd6":"code","4272bc4b":"code","59e02f91":"code","08aed088":"code","fdff8ac7":"code","6923fff8":"markdown","c9ee07d1":"markdown","cb040027":"markdown","dbc58127":"markdown","ace8bf25":"markdown","4e529fca":"markdown","eef6c675":"markdown","5649208a":"markdown","1818f3c4":"markdown","82e79840":"markdown","7cbeacc3":"markdown","ec96935c":"markdown","8c90a579":"markdown","f045bc44":"markdown","6c84f86c":"markdown","5a111db3":"markdown","3d376193":"markdown","3ce06080":"markdown","b7df2df8":"markdown"},"source":{"9ffa7584":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, accuracy_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","916ac1c7":"data = pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\ndata.head()","3675efc4":"X = data.drop(\"DEATH_EVENT\", axis=1)\ny = data[\"DEATH_EVENT\"]\n\nrfc = RandomForestClassifier(n_estimators=60, bootstrap=True)\nrfc.fit(X,y)\nf_i = pd.DataFrame(data={\"feature_importances\":rfc.feature_importances_*100}, index=X.columns)\n\nfig = go.Figure(data=[go.Pie(labels=f_i.index, values=f_i[\"feature_importances\"], hole=.4)])\nfig.update_layout(width=700, height=450, template = 'plotly_dark', title_text=\"Feature Importances\")\nfig.show()","06abf270":"f_i.sort_values(by=\"feature_importances\", inplace=True)\nX = X.drop(f_i.index[:5], axis=1)\ndata_ = data.copy().drop(f_i.index[:5], axis=1)\ndata_.head()","ddc68643":"data_.describe()","fa42858e":"fig = px.histogram(data, x=\"sex\", marginal=\"violin\", hover_data=data.columns,\n                   title =\"Gender\", \n                   template=\"plotly_dark\",\n                   opacity=0.8)\nfig.update_layout(\n        width=700,height=600,\n        yaxis_title_text='count',\n        bargap=0.05,\n        )\nfig.show()","e602e145":"fig = px.histogram(data, x=\"sex\", color=\"DEATH_EVENT\", marginal=\"violin\", hover_data=data.columns,\n                   title =\"Gender vs Death Event\", \n                   template=\"plotly_dark\",\n                   color_discrete_map={\"0\": \"RebeccaPurple\", \"1\": \"MediumPurple\"},\n                   opacity=0.8)\nfig.update_layout(\n        width=700,height=600,\n        yaxis_title_text='count',\n        bargap=0.05)\nfig.show()","3b7d5e27":"diabetes = data[data[\"diabetes\"] == 1]\nnon_diabetes = data[data[\"diabetes\"] == 0]\n\nd_d = diabetes[diabetes[\"DEATH_EVENT\"] == 1]\nd_s = diabetes[diabetes[\"DEATH_EVENT\"] == 0]\n\nnd_d = non_diabetes[non_diabetes[\"DEATH_EVENT\"] == 1]\nnd_s = non_diabetes[non_diabetes[\"DEATH_EVENT\"] == 0]\n\nfig = make_subplots(rows=3, cols=1, specs=[[{'type':'domain'}], [{'type':'domain'}],[{'type':'domain'}]])\n\nfig.add_trace(go.Pie(labels=[\"Diabetes\",\"No Diabetes\"],\n                     values=[len(diabetes),len(non_diabetes)],hole=.3),1,1)\nfig.add_trace(go.Pie(name=\"DIABETES vs HEART FAILURE\",labels=[\"Heart Failure\",\"Survived\"], \n                     values=[len(d_d),len(d_s)],hole=.3),2,1)\n\nfig.add_trace(go.Pie(name=\"NO DIABETES vs HEART FAILURE\",labels=[\"Heart Failure\",\"Survived\"],\n                     values=[len(nd_d),len(nd_s)],hole=.3),3,1)\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\nfig.update_layout(width=700, height=900, title_text=\"Diabetes vs Heart Failure\",template='plotly_dark',\n                 annotations=[dict(text='DIABETES', x=0.2, y=0.6, font_size=10, showarrow=False),\n                 dict(text='DIABETES RATIO', x=0.2, y=1.04, font_size=10, showarrow=False),\n                 dict(text='NO DIABETES', x=0.2, y=0.3, font_size=10, showarrow=False)])\nfig.show()","51067d80":"smokers = data[data[\"smoking\"] == 1]\nnon_smokers = data[data[\"smoking\"] == 0]\n\ns_d = smokers[smokers[\"DEATH_EVENT\"] == 1]\ns_s = smokers[smokers[\"DEATH_EVENT\"] == 0]\n\nns_d = non_smokers[non_smokers[\"DEATH_EVENT\"] == 1]\nns_s = non_smokers[non_smokers[\"DEATH_EVENT\"] == 0]\n\nfig = make_subplots(rows=3, cols=1, specs=[[{'type':'domain'}], [{'type':'domain'}],[{'type':'domain'}]])\n\nfig.add_trace(go.Pie(labels=[\"Smokers\",\"Non Smokers\"],\n                     values=[len(smokers),len(non_smokers)],hole=.3),1,1)\nfig.add_trace(go.Pie(labels=[\"Heart Failure\",\"Survived\"], \n                     values=[len(s_d),len(s_s)],hole=.3),2,1)\n\nfig.add_trace(go.Pie(labels=[\"Heart Failure\",\"Survived\"],\n                     values=[len(ns_d),len(ns_s)],hole=.3),3,1)\nfig.update_traces(hole=.4, hoverinfo=\"label+percent\")\nfig.update_layout(width=700, height=900, title_text=\"Smoking vs Heart Failure\",template='plotly_dark',\n                 annotations=[dict(text='SMOKER RATIO', x=0.2, y=1.04, font_size=10, showarrow=False),\n                 dict(text='SMOKERS', x=0.2, y=0.6, font_size=10, showarrow=False),\n                 dict(text='NON SMOKERS', x=0.2, y=0.3, font_size=10, showarrow=False)])\nfig.show()","6c705b23":"for i in X.columns:\n    fig = px.box(X, x=i, color_discrete_sequence=['mediumspringgreen'])\n    fig.update_layout(width=700,height=450, title_text=i, template = 'plotly_dark')\n    fig.show()","a9c87ded":"shape1 = data_.shape\n\nfor column in data_.columns:\n    q1 = data_[column].quantile(0.25)\n    q3 = data_[column].quantile(0.75)\n    iqr = q3-q1\n    minimum = q1-(1.5*iqr)\n    maximum = q3+(1.5*iqr)\n    \n    min_in = data_[data_[column] < minimum].index\n    max_in = data_[data_[column] > maximum].index\n    \n    data_.drop(min_in, inplace=True)\n    data_.drop(max_in, inplace=True)\n\nshape2 = data_.shape\n\noutliers = shape1[0]-shape2[0]\n\nprint(\"Total count of outliers have deleted: \",outliers)","e3af94f8":"for i in data_.columns[:-1]:\n    title = i + \" (without outliers)\"\n    fig = px.box(data_, x=i, color_discrete_sequence = ['red'])\n    fig.update_layout(width=700,height=450, title_text=title, template='plotly_dark')\n    fig.show()","988e1420":"for column in data_.columns:\n    fig = go.Figure()\n    fig.add_trace(go.Histogram(x=data_[column],marker_color=\"#ccffff\",opacity=0.8))\n    fig.update_layout(\n        width=700,height=450, \n        title_text=column,\n        yaxis_title_text='count',\n        bargap=0.05,\n        template = 'plotly_dark')\n    fig.show()\n    if column != \"DEATH_EVENT\":\n        fig = px.violin(data_, y=column, x=\"DEATH_EVENT\",box=True, points=\"all\",hover_data=data_.columns)\n        fig.update_layout(\n        width=700,height=450, \n        title_text=column,\n        yaxis_title_text='distribution',\n        template = 'plotly_dark')\n        fig.show()","f7c3dec8":"X_train, X_test, y_train, y_test = train_test_split(X,y)","4a1f97ec":"rfc = RandomForestClassifier(n_estimators=60, bootstrap=True)\nrfc.fit(X_train, y_train)\ny_pred = rfc.predict(X_test)\naccuracy_rfc = accuracy_score(y_test, y_pred)*100\nprint(\"Ranfom Forests accuracy on test set: \",accuracy_rfc,\"%\")","f70c4eac":"fig = px.imshow(confusion_matrix(y_test, y_pred),\n                labels=dict(x=\"Predictions\", y=\"True\"),\n                x=['Survived (0)','Death Event (1)'],\n                y=['Survived (0)','Death Event (1)'],\n               template=\"plotly_dark\")\nfig.update_layout(width=700, height=600)\nfig.show()","73b295d0":"gbc = GradientBoostingClassifier(max_depth=2, min_samples_split=3, n_estimators=150)\ngbc.fit(X_train, y_train)\n\nerrors = [mean_squared_error(y_test, y_pred) for y_pred in gbc.staged_predict(X_test)]\nacc = [accuracy_score(y_test, y_pred) for y_pred in gbc.staged_predict(X_test)]\nbest_n_estimators = np.argmax(acc)\n\ngbc = GradientBoostingClassifier(max_depth=3, n_estimators=best_n_estimators)\ngbc.fit(X_train, y_train)\ny_pred = gbc.predict(X_test)\naccuracy_gbc = accuracy_score(y_test, y_pred)*100\n\nprint(\"Gradient Boosting Classifier Accuracy: \",accuracy_gbc,\"%\")","b88d2b40":"fig = px.line(x=range(len(errors)), y=errors, title='Validation error')\nfig.update_layout(width=700,height=450,xaxis_title='Number of trees',yaxis_title='MSE',template=\"plotly_dark\")\nfig.show()","18201845":"fig = px.line(x=range(len(acc)), y=acc, title='Validation Accuracy')\nfig.update_layout(width=700,height=450,xaxis_title='Number of trees',yaxis_title='Accuracy',template=\"plotly_dark\")","e9420e76":"fig = px.imshow(confusion_matrix(y_test, y_pred),\n                labels=dict(x=\"Predictions\", y=\"True\"),\n                x=['Death Event (1)', 'Survived (0)'],\n                y=['Death Event (1)', 'Survived (0)'],\n               template=\"plotly_dark\")\nfig.update_layout(width=700, height=600)\nfig.show()","f8f364cf":"X_nn = data.drop(\"DEATH_EVENT\",axis=1)\ny_nn = data[\"DEATH_EVENT\"]\nX_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_nn, y_nn, shuffle=True)\n\nscaler = StandardScaler()\nX_train_nn = scaler.fit_transform(X_train_nn)\nX_test_nn = scaler.transform(X_test_nn)\n\ninput_size = X_nn.shape[1]\n\nmodel = Sequential()\nmodel.add(Dense(units=input_size, input_dim=X_train_nn.shape[1], activation=\"relu\"))\nmodel.add(Dense(units=input_size, activation=\"relu\"))\nmodel.add(Dense(units=input_size, activation=\"relu\"))\nmodel.add(Dense(units=input_size, activation=\"relu\"))\nmodel.add(Dense(units=input_size, activation=\"relu\"))\nmodel.add(Dense(units=input_size\/2, activation=\"relu\"))\nmodel.add(Dense(units=1, activation=\"sigmoid\"))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'] )\nmodel.summary()","124c5220":"history = model.fit(X_train_nn, y_train_nn, epochs=100, verbose=True, validation_split=0.2)","84c79f0a":"print(\"Accuracy on validation set: \",history.history[\"val_accuracy\"][-1]*100,\"%\")","a2221168":"y_pred_nn = model.predict(X_test_nn)\naccuracy = np.dot(history.history[\"accuracy\"],100)\nloss = history.history['loss']\n\nscore = model.evaluate(X_test_nn, y_test_nn, steps=5)\naccuracy_nn = score[1]*100\nprint()\nprint(\"Accuracy on test set: \",accuracy_nn,\"%\")","cc2ebd23":"X_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\nsvc = SVC(kernel=\"rbf\")\nsvc.fit(X_train, y_train)\ny_pred = svc.predict(X_test)\naccuracy_svc = accuracy_score(y_test, y_pred)*100\nprint(\"SVC Accuracy on test set: \",accuracy_svc,\"%\")","79c59cd6":"fig = px.histogram(y_test, template=\"plotly_dark\", title=\"Counts of class samples in test set\")\nfig.update_layout(width=700,height=450, bargap=0.1)","4272bc4b":"fig = px.imshow(confusion_matrix(y_test, y_pred),\n                labels=dict(x=\"Predictions\", y=\"True\"),\n                x=['Survived (0)','Death Event (1)'],\n                y=['Survived (0)','Death Event (1)'],\n               template=\"plotly_dark\")\nfig.update_layout(width=700, height=600)\nfig.show()","59e02f91":"classification_report(y_test, y_pred, target_names=[\"class 0\",\"class 1\"])","08aed088":"compare = pd.DataFrame(index=[\"Random Forests\",\"Gradient Boosting Classifier\",\"Neural Network\",\"Support Vector Classifier\"],\n                       columns=[\"Accuracy\"],\n                      data=[accuracy_rfc,accuracy_gbc,accuracy_nn,accuracy_svc])\ncompare","fdff8ac7":"fig = px.bar(compare,\n             template=\"plotly_dark\", \n             title=\"Comparision of models\",\n             color_discrete_sequence=[\"darkviolet\"])\nfig.update_layout(width=700, height=450, xaxis_title=\"Models\", yaxis_title=\"Accuracy\")\nfig.update(layout_showlegend=False)\nfig.show()","6923fff8":"# Gradient Boosting Classifier","c9ee07d1":"# Neural Network","cb040027":"*In this notebook I used 3 models to classify heart failure using Heart Failure Prediction dataset. The models I used:*\n1. Gradient Boosting Classifier\n2. Neural Network\n3. Support Vector Classifier\n\n*Gradient Boosting classifier is one of ensemble learning methods. This model learns from previous layer tree's error.*\n\n*Random Forests to eliminate important features.*\n\n*Neural network is an efficient and easy way to create machine learning architectures. Using Keras makes it even easier to build.*\n\n*Support Vectors uses decision boundaries to split samples of each class. For non linear problems, they use kernels to fit data. I used radial basis function as kernel.*\n\n*To visualize dataset and model performances, I imported plotly.express, plotly.graph_objs, plotly.subplots.*\n\n\n*I'm not a data scientist or student in computer science departmant, I just enjoy training models and am open to suggestions.*\ud83e\udd73","dbc58127":"*Decision tree based models don't need scaled input. Because of that I will only split train set and test set.*","ace8bf25":"# Random Forests","4e529fca":"# Comparision of Models","eef6c675":"# Support Vector Classifier","5649208a":"# Exploratory Data Analysis","1818f3c4":"## Diabetes","82e79840":"## Smoking","7cbeacc3":"# Feature Counts and Distributions","ec96935c":"# Libraries","8c90a579":"## Gender","f045bc44":"### Feature Importances","6c84f86c":"### Finding optimal hyperparameter","5a111db3":"# ","3d376193":"# Heart Failure Prediction","3ce06080":"*Confusion matrix shows that support vector classifier performed well classifying class 0 samples but bad at classifying class 1 samples with only 50% accuracy in this class. To understand better, classification report can help.*","b7df2df8":"*Before training, I want to find optimal number of trees that model would have to ensure the accuracy maximum. Then define it with this best number of trees by setting n_estimators hyperparameter.*"}}