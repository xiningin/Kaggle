{"cell_type":{"cb79c81f":"code","b4ab3a81":"code","2ae98519":"code","70684963":"code","3931ce98":"code","50fa82f6":"code","e3ba643d":"code","7c8a9859":"code","ca35cb62":"code","7700c025":"code","f14e39e4":"code","e80cdd36":"code","b979a51f":"markdown","3fd4cac2":"markdown","15e26125":"markdown","83b93090":"markdown","85207c55":"markdown","a6f48a6c":"markdown","24dbc182":"markdown","48b1c4d6":"markdown","9675c5c1":"markdown","c0ce7c27":"markdown","b443719a":"markdown","eac040a6":"markdown","c0811934":"markdown","0dadedc9":"markdown","c7e7d52c":"markdown","b527e022":"markdown"},"source":{"cb79c81f":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nfrom sklearn.metrics import confusion_matrix\n\nimport os\n\nimport random\n\nprint(\"Setup complete!\")","b4ab3a81":"random.seed(1)\ntorch.manual_seed(1)\ntorch.cuda.manual_seed(1)\nnp.random.seed(1)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","2ae98519":"print_images = datasets.FashionMNIST('data', train=True, download=True)\n\nfor k, (image, label) in enumerate(print_images):\n    if k >= 18:\n        break\n    plt.subplot(3, 6, k+1)\n    plt.imshow(image)","70684963":"# transform the images to a tensor\nfashion_mnist_data = datasets.FashionMNIST(\"data\", train = True , download = True, transform = transforms.ToTensor())\n\nfashion_mnist_data = list(fashion_mnist_data)","3931ce98":"# check the length of the list to see how many images we have in the data\nprint(len(fashion_mnist_data))","50fa82f6":"# For this example I want 80% of the images for my training (48,000)\n# I want the remaining 20% for testing (12,000)\n\nfashion_mnist_train = fashion_mnist_data[0:48000]\nfashion_mnist_test = fashion_mnist_data[48000 : 60000]\n\nprint(len(fashion_mnist_train))\nprint(len(fashion_mnist_test))","e3ba643d":"first_img, first_lab = fashion_mnist_train[0]\nprint(first_img.size())\nprint(first_lab)","7c8a9859":"# pytorch uses batches of images - lets use 64\ntrainloader = torch.utils.data.DataLoader(fashion_mnist_train,\n                                          batch_size=64,\n                                          num_workers = 0,\n                                          shuffle = True)\n\ntestloader = torch.utils.data.DataLoader(fashion_mnist_test,\n                                          batch_size=64,\n                                          num_workers = 0,\n                                          shuffle = True)","ca35cb62":"class FCN_Model(nn.Module):\n    def __init__(self):\n        super(FCN_Model, self).__init__()\n        self.fc1 = nn.Linear(1 * 28 * 28, 50) #input layer connected to first hidden layer\n        self.fc2 = nn.Linear(50, 20) #first hidden layer connected to second hidden layer\n        self.fc3 = nn.Linear(20, 10) #second hidden layer connected to output layer\n        \n    def forward(self, img):\n        \n        #flatten the image\n        flatten = img.view(-1, 28 * 28) #flatten the image dimensions\n        \n        #activation layers\n        acti1 = F.relu(self.fc1(flatten)) #use the relu activation\n        acti2 = F.relu(self.fc2(acti1))   #introduces non linearity\n        output = self.fc3(acti2)\n        return output","7700c025":"def train(model, train, test, batch_size=64, num_iters=1, learn_rate=0.01, weight_decay=0):\n    train_loader = torch.utils.data.DataLoader(train,\n                                               batch_size=batch_size,\n                                               shuffle=True) # shuffle after every epoch\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=0.9, weight_decay=weight_decay)\n\n    iters, losses, train_acc, test_acc = [], [], [], []\n\n    # training\n    n = 0 # the number of iterations\n    while True:\n        if n >= num_iters:\n            break\n        for imgs, labels in iter(train_loader):\n            model.train() \n            out = model(imgs)             # forward pass\n            loss = criterion(out, labels) # compute the total loss\n            loss.backward()               # backward pass (compute parameter updates)\n            optimizer.step()              # make the updates for each parameter\n            optimizer.zero_grad()         # a clean up step for PyTorch\n\n            # save the current training information\n            if n % 10 == 9:\n                iters.append(n)\n                losses.append(float(loss)\/batch_size)        # compute *average* loss\n                train_acc.append(get_accuracy(model, train)) # compute training accuracy \n                test_acc.append(get_accuracy(model, test))   # compute testing accuracy\n            n += 1\n\n    # plotting\n    plt.figure(figsize=(10,4))\n    plt.subplot(1,2,1)\n    plt.title(\"Training Curve\")\n    plt.plot(iters, losses, label=\"Train\")\n    plt.xlabel(\"Iterations\")\n    plt.ylabel(\"Loss\")\n\n    plt.subplot(1,2,2)\n    plt.title(\"Training Curve\")\n    plt.plot(iters, train_acc, label=\"Train\")\n    plt.plot(iters, test_acc, label=\"Testing\")\n    plt.xlabel(\"Iterations\")\n    plt.ylabel(\"Training Accuracy\")\n    plt.legend(loc='best')\n    plt.show()\n\n    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n    print(\"Final Testing Accuracy: {}\".format(test_acc[-1]))\n    \ndef get_accuracy(model, data):\n    correct = 0\n    total = 0\n    model.eval()\n    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=64):\n        output = model(imgs)\n        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n        correct += pred.eq(labels.view_as(pred)).sum().item()\n        total += imgs.shape[0]\n    return correct \/ total","f14e39e4":"# create an instance and start training!\nmodel1 = FCN_Model()\ntrain(model1 , fashion_mnist_train, fashion_mnist_test, num_iters= 700)","e80cdd36":"model1.eval() # model1 is the name given to my model. In this case a fully connected neural network as defined above.\n\ntrue_class = []\npredicted_class = []\n\nfor data , target in testloader: #image and label from the testing images\n    for label in target.cpu().data.numpy():  #this is to turn the tensor into numpy array\n        true_class.append(label)\n    for prediction in model1.cpu()(data).data.numpy().argmax(1): #this is to turn the tensor into numpy array + position of \n        predicted_class.append(prediction)                      # largest value\n        \nconfusion_matrix(true_class, predicted_class)","b979a51f":"#### Check the image properties","3fd4cac2":"### The Fully connected Neural network\n\nI've completed a classification analysis using a **fully connected neural network** on some red wine data. Check it out [here.](https:\/\/www.kaggle.com\/laurenohare1\/classification-of-quality-using-neural-networks)\n\nFor those who are not familiar with FCN here is some information. \n\nA fully connected neural network consists of linear layers where the connections between nodes are controlled by weights. These weights are updated and trained using backpropagation to aid in optimisation of the neural network. If you would like to read more about fully connected neural networks and backpropagation check out this [link!](https:\/\/towardsdatascience.com\/under-the-hood-of-neural-networks-part-1-fully-connected-5223b7f78528)\n\nThis FCN model will have an input dimension of 1 x 28 x 28. This will be fully connected to 50 hidden nodes. This layer will then be fully connected to 20 hidden nodes. Finally, this will be fully connected to 10 output nodes representing each type of \"fashion\" we want to classify. ","15e26125":"## About the Data\n\nThe images in this data have height and width 28 x 28 pixels. They are also greyscale ie: *they have only one input channel*.\n\nThere are 60,000 images in this dataset of different types of clothing. Their lables are displayed below.\n\n* 0 T-shirt\/top\n* 1 Trouser\n* 2 Pullover\n* 3 Dress\n* 4 Coat\n* 5 Sandal\n* 6 Shirt\n* 7 Sneaker\n* 8 Bag\n* 9 Ankle boot\n\n** Lets start!**","83b93090":"# Classifying Fashion Images with Neural Networks\n\nIn this notebook I want to use the Pytorch dataset \"FashionMNIST\" to classify different clothing items using neural networks. ","85207c55":"### Train the model","a6f48a6c":"### Create a confusion matrix.\n\nThis will tell us how many correct classifications per label this model has achieved.","24dbc182":"### Imports","48b1c4d6":"What does this tell us? Each image has a dimension of 1 x 28 x 28. The first image in this data also has the label 9 which is an \"ankle boot\".","9675c5c1":"### Train\/Test split","c0ce7c27":"### Download the data - this dataset is built in with Pytorch.","b443719a":"### View the images!\n\nI want to **see** the data before I apply some models to it!","eac040a6":"### Create the mini batches","c0811934":"Watch this space! Next I want to try a *convolutional neural network* to classify these images. Read more about them [here!](https:\/\/towardsdatascience.com\/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)","0dadedc9":"### Reproducibility","c7e7d52c":"<img src=\"https:\/\/imgur.com\/fzyWc7F.jpg\" width=\"1000px\"\/>","b527e022":"Approx 80% accuracy! "}}