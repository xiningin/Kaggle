{"cell_type":{"910d9b22":"code","3abd9808":"code","298b9dae":"code","d34189b1":"code","ab25aa69":"code","44f41222":"code","c8b8cd48":"code","d16717af":"code","8f22163d":"code","29acb3a6":"code","07735ea9":"code","4f21a265":"code","781ef563":"code","e00bbff2":"code","deefa864":"code","9e286f13":"code","a073f786":"code","c3a5fe05":"code","93cc2856":"code","22e53a4d":"code","3f0646d0":"code","5f6c40cb":"code","bc98c314":"code","4baf58fa":"code","2735e0e4":"code","dfe060cf":"code","1dfd3944":"code","8566f816":"code","aa84ea97":"code","7f4c2701":"code","a738cd81":"code","b24cb5e4":"code","64ee1bf6":"code","f5426aa3":"code","90fba089":"code","6de6be1b":"markdown","97316aa5":"markdown","b67eeb29":"markdown","75929193":"markdown","eddd5ad8":"markdown","e36d576d":"markdown","199731bf":"markdown","84e82ded":"markdown","1a558424":"markdown","04ffffdc":"markdown","b94df7fa":"markdown","ab493ffb":"markdown","15871ebb":"markdown","6d3283c6":"markdown","bebb0982":"markdown","e863c604":"markdown","b652aa01":"markdown","793c3b6d":"markdown","7e4eedfc":"markdown"},"source":{"910d9b22":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('bmh')\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.preprocessing import MaxAbsScaler,PowerTransformer,MinMaxScaler,RobustScaler, StandardScaler, Normalizer, QuantileTransformer\n\nfrom sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV\nfrom sklearn.decomposition import PCA\n\n# models\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier,VotingClassifier,\\\nGradientBoostingClassifier,StackingClassifier,VotingClassifier,HistGradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression,Perceptron,RidgeClassifier,RidgeClassifierCV,SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.metrics import accuracy_score, f1_score, make_scorer\nfrom scipy import stats\nfrom imblearn.over_sampling import SMOTE, ADASYN,BorderlineSMOTE,KMeansSMOTE,SVMSMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.mixture import GaussianMixture\n\nimport time","3abd9808":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain=pd.read_csv('\/kaggle\/input\/dry-beans-classification-iti-ai-pro-intake01\/train.csv',index_col='ID')\ntest=pd.read_csv('\/kaggle\/input\/dry-beans-classification-iti-ai-pro-intake01\/test.csv',index_col='ID')\ntest_ID=test.index","298b9dae":"train.head()","d34189b1":"train.describe()","ab25aa69":"df1=train[train['y']=='HOROZ']\ndf2=train[train['y']=='SEKER']\ndf3=train[train['y']=='DERMASON']\ndf4=train[train['y']=='SIRA']\ndf5=train[train['y']=='BARBUNYA']\ndf6=train[train['y']=='CALI']\ndf7=train[train['y']=='BOMBAY']","44f41222":"dfs=[df1,df2,df3,df4,df5,df6,df7]\nfor i in dfs:\n    print(i['y'].unique())\n    display(i.describe())","c8b8cd48":"train.info()","d16717af":"train.y.unique()","8f22163d":"print(train.duplicated().sum())\nprint(test.duplicated().sum())","29acb3a6":"sns.pairplot(train,hue='y')","07735ea9":"train.skew(axis=0)","4f21a265":"plt.figure(figsize=(10,7))\nsns.heatmap(train.corr(),annot=True)","781ef563":"train['y'] = train['y'].map({'HOROZ':0, 'SEKER':1, 'DERMASON':2, 'SIRA':3, 'BARBUNYA':4, 'CALI':5, 'BOMBAY':6})","e00bbff2":"train.y.unique()","deefa864":"print(train.shape)\nprint(test.shape)","9e286f13":"plt.figure(figsize=(25, 25))\nfor i, col in enumerate(list(train.columns)):\n    plt.subplot(7, 4, i+1)\n    sns.histplot(train[col], kde=True, bins=10)","a073f786":"plt.figure(figsize=(25, 25))\nfor i, col in enumerate(list(train.columns)):\n    plt.subplot(7, 4, i+1)\n    sns.boxplot(train[train['y'] == 0][col])","c3a5fe05":"# #remove all outliers\n# from scipy import stats\n# z_scores = stats.zscore(train)\n# abs_z_scores = np.abs(z_scores)\n# filtered_entries = (abs_z_scores < 2).all(axis=1)\n# train = train[filtered_entries]","93cc2856":"Y=train['y']\ntrain.drop('y',axis='columns',inplace=True)","22e53a4d":"# #boxcox outliers handling\n# for col in train.columns:\n#     train[col],fitted_lambda= stats.boxcox(train[col] ,lmbda=None)\n#     test[col],fitted_lambda= stats.boxcox(test[col] ,lmbda=None)","3f0646d0":"# #imputing outliers using median\n# for col in train.columns:\n#     q1 = train[col].quantile(0.25)\n#     q3 = train[col].quantile(0.75)\n#     iqr = q3-q1\n#     Lower_tail = q1 - 1.5 * iqr\n#     Upper_tail = q3 + 1.5 * iqr\n#     m = np.median(train[col])\n#     for i in train[col]:\n#         if i > Upper_tail or i < Lower_tail:\n#                 train[col] = train[col].replace(i, m)\n    \n#     q1 = test[col].quantile(0.25)\n#     q3 = test[col].quantile(0.75)\n#     iqr = q3-q1\n#     Lower_tail = q1 - 1.5 * iqr\n#     Upper_tail = q3 + 1.5 * iqr\n#     m = np.median(test[col])\n#     for i in test[col]:\n#         if i > Upper_tail or i < Lower_tail:\n#                 test[col] = test[col].replace(i, m)","5f6c40cb":"X_train, X_valid, y_train, y_valid = train_test_split(train,Y, train_size=0.8,random_state=465,stratify=Y)","bc98c314":"#balancing Dataset\nprint(train.shape)\nprint(Y.value_counts())\noversample = BorderlineSMOTE(sampling_strategy={2:3000,6:1300,4:1300,1:2000,5:1900},random_state = 465)\ntrain, Y = oversample.fit_resample(train, Y)\nprint(train.shape)\nprint(Y.value_counts())","4baf58fa":"scaler=PowerTransformer()\ntrain=pd.DataFrame(scaler.fit_transform(train),columns=train.columns)\ntest=pd.DataFrame(scaler.transform(test),columns=test.columns)","2735e0e4":"# rf=RandomForestClassifier()\n# ada=AdaBoostClassifier()\n# et=ExtraTreesClassifier()\n# gbc=GradientBoostingClassifier()  #excluded due to very long training time and not getting best results\n# hgbc=HistGradientBoostingClassifier()\n# per=Perceptron()\n# rc=RidgeClassifier()\n# rcv=RidgeClassifierCV()\n# sgd=SGDClassifier()\n# dt=DecisionTreeClassifier()\n# svm=SVC()\n# xgb=XGBClassifier()\n# catb=CatBoostClassifier(verbose=None)\n# knn=KNeighborsClassifier(7)\n# mlp=MLPClassifier()\n\n\n# models=[rf,ada,et,hgbc,per,rc,rcv,sgd,dt,svm,xgb,knn,mlp] \n# # models=[svm,ada]\n\n# for model in models:\n#     start=time.time()\n#     grid=GridSearchCV(estimator=model,param_grid={},scoring='f1_micro',cv=5,verbose=1)\n#     grid.fit(train,Y)\n#     end = time.time()\n#     print(model, '\\n', grid.best_score_,'\\n', round(end-start))","dfe060cf":"train.drop(['AspectRation','Eccentricity'],axis=1,inplace=True)\ntest.drop(['AspectRation','Eccentricity'],axis=1,inplace=True)","1dfd3944":"# params={\n#     'C':[5.3],\n#     'kernel' : ['poly'],\n#     'decision_function_shape':['ovo'],\n#     'coef0' : [3.1],\n#        }\n# model = GridSearchCV(estimator=SVC(random_state = 465), param_grid=params, scoring='f1_micro', cv=3,verbose=3)\n# model.fit(train,Y)\n# print(model.best_params_)\n# print(model.best_estimator_)\n# print(model.best_score_)\n# bestmodel=model.best_estimator_","8566f816":"# params={#'hidden_layer_sizes':[45,50,55,60],\n#     'hidden_layer_sizes':[24],\n# #        'activation':['identity', 'logistic', 'tanh', 'relu'],\n# #        'early_stopping':[True],\n#         'beta_1' :[.7],\n#        }\n# model = GridSearchCV(estimator=MLPClassifier(random_state = 158), param_grid=params, scoring='f1_micro', cv=StratifiedKFold(10),verbose=3)\n# model.fit(train,Y)\n# print(model.best_params_)\n# print(model.best_estimator_)\n# print(model.best_score_)\n# bestmodel=model.best_estimat","aa84ea97":"# class CatBoostClassifierInt(CatBoostClassifier):\n#     def predict(self, data, prediction_type='Class', ntree_start=0, ntree_end=0, thread_count=1, verbose=None,parent_method_name=None):\n#         predictions = self._predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose,parent_method_name)\n     \n#         # This line is the only change I did\n#         return np.asarray(predictions, dtype=np.int64).ravel()","7f4c2701":"# catboost=CatBoostClassifierInt(CatBoostClassifier(depth= 8, iterations= 90, learning_rate= 0.2))","a738cd81":"voting_est=[('SVC',SVC(C=5.3, coef0=3.1, decision_function_shape='ovo', kernel='poly',random_state=0)),\n            ('MultiLayer Perceptron',MLPClassifier(beta_1=0.7, hidden_layer_sizes=24, random_state=158)),\n           ('XGBoost',XGBClassifier(booster='dart',eta=0.03,max_depth=15,subsample=0.8,gamma=0,n_estimators=230,colsample_bytree=0.6,colsample_bylevel=0.6,colsample_bynode=0.6))]\nvc=VotingClassifier(estimators=voting_est)\n\n\nmodels=[vc] \n# models=[svm,ada]\n\nfor mod in models:\n    start=time.time()\n    model=GridSearchCV(estimator=mod,param_grid={},scoring='f1_micro',cv=StratifiedKFold(5),verbose=0)\n    model.fit(train,Y)\n    end = time.time()\n    print(mod, '\\n', model.best_score_,'\\n', round(end-start))\n    bestmodel=model.best_estimator_","b24cb5e4":"pred=bestmodel.predict(test)\npredictions = pd.DataFrame({'ID':test_ID,\n                       'y': pred})","64ee1bf6":"predictions['y']=predictions['y'].map({0:'HOROZ', 1:'SEKER', 2:'DERMASON', 3:'SIRA', 4:'BARBUNYA', 5:'CALI',6:'BOMBAY'})","f5426aa3":"predictions","90fba089":"predictions.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","6de6be1b":"# \u2728 Treating Imbalanced Data","97316aa5":"# \u2728 Loading Data","b67eeb29":"# \u2728 Model","75929193":"# \u2728 Splitting the data","eddd5ad8":"# \u2728 Data Scaling","e36d576d":"## Correlation","199731bf":"## Mapping The Target Classes","84e82ded":"# \u2728 Importing Libraries","1a558424":"## Checking the Skeweness of the data","04ffffdc":"# \u2728 Making Predictions","b94df7fa":"# \u2728 Grid Search","ab493ffb":"# \u2728 Gathering Insights\n","15871ebb":"# \u2728 EDA","6d3283c6":"## Checking Duplicates","bebb0982":"## Visualization","e863c604":"* The Data Suffers from High Skeweness\n* The data is Imblanaced there are different distributions in each class\n* There is High correlation between columns\n* No Duplicates \n* No missing Values","b652aa01":"# \u2728 Generating Submission File","793c3b6d":"# \u2728 Hi There \n#  We're Serial Kernels \ud83d\udc32","7e4eedfc":"#  \u2728 Detecting outliers"}}