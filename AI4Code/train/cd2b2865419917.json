{"cell_type":{"583ae925":"code","99741c30":"code","18d6bc07":"code","155526c5":"code","3b0f2c6b":"code","7294bf1c":"code","edf97ae7":"code","7aa2b300":"code","15be0b8f":"code","20475dc9":"code","0007ecdb":"code","2cdb5b0e":"code","4e520a55":"code","6134b86f":"code","d56b446e":"code","3799bed2":"code","ac8cf8d8":"code","fe86139a":"code","6b9bd030":"code","0649168f":"code","fe1c0765":"code","d5e0a097":"code","b745497a":"code","17ec9f47":"code","b692b29e":"code","ea2445ae":"code","56b91680":"code","9e74ed95":"code","e7170dc1":"code","7b9e5f51":"markdown","2d0d41b2":"markdown","d40483f3":"markdown","7c538a41":"markdown","721a2399":"markdown","069e6e51":"markdown"},"source":{"583ae925":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom IPython import display\n\n\n# some additional functions\ndef mask(df, key, function):\n  \"\"\"Returns a filtered dataframe, by applying function to key\"\"\"\n  return df[function(df[key])]\n\ndef flatten_cols(df):\n  df.columns = [' '.join(col).strip() for col in df.columns.values]\n  return df\n\npd.DataFrame.mask = mask\npd.DataFrame.flatten_cols = flatten_cols","99741c30":"!wget http:\/\/files.grouplens.org\/datasets\/movielens\/ml-100k.zip\n!unzip ml-100k.zip","18d6bc07":"with open(\"\/kaggle\/working\/ml-100k\/u.info\",\"r\") as f:\n  print(f.readlines())","155526c5":"###################################################################\n#                                                                 #\n# Reading the required files and see exactly which coloumns we    #\n# need and then select those for moving ahead                     #\n#                                                                 #\n###################################################################\n\nprint(\"User data...\")\nwith open(\"\/kaggle\/working\/ml-100k\/u.user\",\"r\") as f:\n  print(f.readlines(50))\nprint()\n\nprint(\"Ratings Data...\")\nwith open(\"\/kaggle\/working\/ml-100k\/u.data\",\"r\") as f:\n  print(f.readlines(50))\n\nprint()\nprint(\"Movies Data...\")\nwith open(\"\/kaggle\/working\/ml-100k\/u.item\",\"r\") as f:\n  print(f.readlines(1000))\n\nprint()\nprint(\"Genre Data...\")\nwith open(\"\/kaggle\/working\/ml-100k\/u.genre\",\"r\") as f:\n  for line in f.readlines(5):\n    print(line)","3b0f2c6b":"###################################################################\n#\n# Reading Data from the files as per the above spec we just saw\n#\n###################################################################\n\nhome_dir = '\/kaggle\/working\/ml-100k\/'\n\nuser_columns = ['user_id','age','sex','occupation','zip_code']\n\nusers = pd.read_csv(home_dir+'u.user',\n                    sep='|',\n                    names=user_columns,\n                    encoding='latin-1'\n                    )\n\nrating_columns = ['user_id','movie_id','rating','timestamp']\n\nratings = pd.read_csv(home_dir+'u.data',\n                      sep='\\t',\n                      names=rating_columns,\n                      encoding='latin-1')\n\ngenres = pd.read_csv(home_dir+'u.genre',\n                     sep='|',\n                     names=['genre','id'],\n                     encoding='latin-1'\n                     )\n\n# Each record in movies file have a binary indicator if that movie\n# belongs to that genre\n# these genres are from the genre dataframe that we just created above\n\ngenre_columns = list(genres.genre.values)\nmovie_columns = ['movie_id','title','release_date','video_release_date','imdb_url'] + genre_columns\nmovies = pd.read_csv(home_dir+'u.item',\n                     sep='|',\n                     names=movie_columns,\n                     encoding='latin-1'\n                     )","7294bf1c":"###################################################################\n#\n# Movies DataFrame contains information about the movie along with\n# the Genre columns. These Columns can have either 0 or 1 depending\n# on whether or not the movie belong to that particular genre.\n#\n###################################################################\nmovies.head(2)","edf97ae7":"###################################################################\n#\n# Users DataFrame contains an id unique to every user and their\n# information like age, sex, occupation and location. While we \n# do not use these right now for our notebook, but these factors\n# can be useful in one's choice. \n#\n###################################################################\nusers.head(2)","7aa2b300":"###################################################################\n#\n# Ratings Dataframe contains very few, yet important data.\n# This df contains all the ratings given by users for the movie out of\n# 5 and timestamp of the rating given\n#\n###################################################################\nratings.head(2)","15be0b8f":"print('Genres,Ratings,Users,Movies')\ngenres.shape,ratings.shape,users.shape,movies.shape","20475dc9":"###################################################################\n#\n# Our Mandatory functions on a dataframe. While these seem comman\n# can sometimes really be a lifesaver. Notice I used a parameter\n# include = [np.object,int]. You can use this to include a certain \n# type of data in your df which by default is being excluded. You \n# can also use exclude = [] parameter incase you want to exclude.\n#\n###################################################################\n\nusers.describe(include=[np.object,int]).T","0007ecdb":"users.describe(exclude=[int]).T","2cdb5b0e":"###################################################################\n#\n# Merging ratings and Users to get info about user \n# ratings and user in one place. \n#\n###################################################################\n\nuser_ratings = (ratings.groupby('user_id',as_index=False).agg({'rating':['count','mean']}).flatten_cols().merge(users,on='user_id'))\n\nprint(\"Below DataFrame depicts average ratings as well as total number of ratings by a user\\n\")\n\nuser_ratings.head()","4e520a55":"####################################################################\n#\n# Lets try to get more insights about movies and ratings using the \n# base dataframes like average rating and number of ratings for \n# that movie\n#\n####################################################################\n\ntmp_ratings = ratings.groupby('movie_id',as_index=False).agg({'rating':['count','mean']}).flatten_cols()\n\nmovie_ratings = movies.merge(\n    tmp_ratings,\n    on='movie_id'\n)\n\nmovie_ratings.head()","6134b86f":"####################################################################\n#\n# Getting Unique user ids and creating two encodings. One from user_id\n# to index. Another from index to user ids.\n#\n####################################################################\n\nuser_ids = ratings['user_id'].unique().tolist()\nuser2user_encoded = {x:i for i,x in enumerate(user_ids)}\nuserencoded2user = {i:x for i,x in enumerate(user_ids)}","d56b446e":"for i,x in enumerate(user_ids[:10]):\n  print(x,\": \",i,end=\"    \")\n  print(i,\": \",x)","3799bed2":"####################################################################\n#\n# Getting unique movie IDs and create two mappings, one from movie_id\n# to index\/unique number and another vice versa.\n#\n####################################################################\n\nmovie_ids = ratings['movie_id'].unique().tolist()\nmovie2movie_encoded = {x:i for i,x in enumerate(movie_ids)}\nmovieencoded2movie = {i:x for i,x in enumerate(movie_ids)}","ac8cf8d8":"for i,x in enumerate(movie_ids[:10]):\n  print(x,\": \",i,end=\"    \")\n  print(i,\": \",x)","fe86139a":"####################################################################\n#\n# Ratings before mapping the user id and movie id to the encodings\n#\n####################################################################\n\nratings[:10]","6b9bd030":"####################################################################\n#\n# We now map the user_id and movie_id to the mappings in a new column\n# we created before. We take the number of unique movies and users\n# we have. We calculated the min and max rating for normalizing the \n# ratings columns.\n#\n####################################################################\n\nratings['user'] = ratings['user_id'].map(user2user_encoded)\nratings['movie'] = ratings['movie_id'].map(movie2movie_encoded)\n\nn_users = len(user2user_encoded)\nn_movies = len(movieencoded2movie)\n\nratings['ratings'] = ratings['rating'].values.astype(np.float32)\nmin_rating = min(ratings['rating'])\nmax_rating = max(ratings['rating'])\n","0649168f":"####################################################################\n#\n# Ratings after mapping the user id and movie id to the encodings\n#\n####################################################################\n\nratings[:10]","fe1c0765":"####################################################################\n#\n# Shuffling the data before training and creating our training data\n# and labels. Spliting the data into Train and Valid Split.\n#\n####################################################################\n\nratings = ratings.sample(frac=1,random_state=42)\n\nx = ratings[['user','movie']].values\ny = ratings['rating'].apply(lambda x:(x-min_rating)\/(max_rating-min_rating)).values\n\ntrain_idx = int(0.9*ratings.shape[0])\nx_train,x_val,y_train,y_val = (x[:train_idx],\n                               x[train_idx:],\n                               y[:train_idx],\n                               y[train_idx:]\n                               )","d5e0a097":"####################################################################\n#\n# Shape of the datasets.\n#\n####################################################################\n\nx_train.shape,x_val.shape,n_users,n_movies","b745497a":"####################################################################\n#\n# Setup an Embedding size for the latent representation of the \n# users and Movies. Creating our Model.\n#\n####################################################################\n\nEMBEDDING_SIZE = 75\n\nclass RecommenderNet(tf.keras.Model):\n  def __init__(self,num_users,num_movies,embedding_size,**kwargs):\n    super(RecommenderNet,self).__init__(**kwargs)\n    self.num_users =  num_users\n    self.num_movies = num_movies\n    self.embedding_size = embedding_size\n    self.user_embedding = tf.keras.layers.Embedding(\n        num_users,\n        embedding_size,\n        embeddings_initializer=\"he_normal\",\n        embeddings_regularizer=tf.keras.regularizers.l2(1e-6)\n    )\n    self.user_bias = tf.keras.layers.Embedding(num_users,1)\n    self.movie_embedding = tf.keras.layers.Embedding(\n        num_movies,\n        embedding_size,\n        embeddings_initializer=\"he_normal\",\n        embeddings_regularizer=tf.keras.regularizers.l2(1e-6)\n    )\n    self.movie_bias = tf.keras.layers.Embedding(num_movies,1)\n\n  def call(self,inputs):\n    '''\n      we perform a dot product of user vector and\n      movie vector and compare that to our labels\n    '''\n    user_vector = self.user_embedding(inputs[:,0])\n    user_bias = self.user_bias(inputs[:,0])\n    movie_vector = self.movie_embedding(inputs[:,1])\n    movie_bias = self.movie_bias(inputs[:,1])\n\n    dot_user_movie = tf.tensordot(user_vector,movie_vector,2)\n\n    x = dot_user_movie + user_bias + movie_bias\n    \n    return tf.nn.sigmoid(x)\n\nmodel = RecommenderNet(n_users, n_movies, EMBEDDING_SIZE)\n\nmodel.compile(\n    loss=tf.keras.losses.BinaryCrossentropy(),\n    optimizer=tf.keras.optimizers.Adam(lr=0.001)\n)","17ec9f47":"####################################################################\n#\n# Well, After all the typing above lets run the model on the data.\n#\n####################################################################\nmodel.fit(\n    x = x_train,\n    y = y_train,\n    epochs=10,\n    batch_size=128,\n    verbose=1,\n    validation_data=(x_val,y_val)\n)","b692b29e":"model.summary()","ea2445ae":"############################################################################\n#                                                                          #\n#                   Showing movie recommendations to a user                #\n#                                                                          #\n############################################################################","56b91680":"# Getting a user to see the top recommendation\n\nuser = users.user_id.sample(1).iloc[0]\nmovies_watched_by_user = ratings[ratings.user_id==user]\nmovies_not_watched = movies[~movies[\"movie_id\"].isin(movies_watched_by_user.movie_id.values)][\"movie_id\"]\n\nmovies_not_watched = list(set(movies_not_watched).intersection(set(movie2movie_encoded.keys())))\nmovies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n\nuser_encoder = user2user_encoded.get(user)\nuser_movie_array = np.hstack(\n    ([[user_encoder]]*len(movies_not_watched),movies_not_watched)\n)\nprint(user_movie_array.shape)\nrating_pred = model.predict(user_movie_array).flatten()\ntop_ratings_indices = rating_pred.argsort()[-10:][::-1]\n\nrecommended_movie_ids = [\n                         movieencoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n]\n\n","9e74ed95":"for i in recommended_movie_ids:\n  print(movies[movies.movie_id==i].head())","e7170dc1":"#################################################################################\n#\n#                             REFERENCES\n#\n# Thanks to respective articles and tutorials:\n# 1) https:\/\/keras.io\/examples\/structured_data\/collaborative_filtering_movielens\/\n# 2) https:\/\/developers.google.com\/machine-learning\/recommendation\n# \n#\n#################################################################################","7b9e5f51":"## Get the Data\nWe will be using the same MovieLens Dataset we used in previous part of the series. You can get the data from [here](http:\/\/files.grouplens.org\/datasets\/movielens\/ml-100k.zip). Feel Free to browse and look for another subset of data from the movie lens. Steps remain the same.\n\nExtract the data and lets have a look what it contains.","2d0d41b2":"## Lets get the imports \n\nI have created a tutorial for this notebook here: https:\/\/medium.com\/thenoobengineer\/collaborative-filtering-imdb-6f8ab477601","d40483f3":"# II. What do we need to do?\n\nOur goal is to factorize the ratings matrix $A$ into the product of a user embedding matrix $U$ and movie embedding matrix $V$, such that $A \\approx UV^\\top$ with\n$U = \\begin{bmatrix} u_{1} \\\\ \\hline \\vdots \\\\ \\hline u_{N} \\end{bmatrix}$ and\n$V = \\begin{bmatrix} v_{1} \\\\ \\hline \\vdots \\\\ \\hline v_{M} \\end{bmatrix}$.\n\nHere\n- $N$ is the number of users,\n- $M$ is the number of movies,\n- $A_{ij}$ is the rating of the $j$th movies by the $i$th user,\n- each row $U_i$ is a $d$-dimensional vector (embedding) representing user $i$,\n- each row $V_j$ is a $d$-dimensional vector (embedding) representing movie $j$,\n- the prediction of the model for the $(i, j)$ pair is the dot product $\\langle U_i, V_j \\rangle$.\n\n","7c538a41":"# Encode Users and Movies as integer indices","721a2399":"## Start preprocessing the data","069e6e51":"### Read the files as CSV"}}