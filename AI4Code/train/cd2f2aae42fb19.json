{"cell_type":{"d4de6d2e":"code","0f5f0921":"code","2361f5aa":"code","78c277d0":"code","84791f70":"code","f28cd351":"code","062bb063":"code","132bf560":"code","8613e97d":"code","5ca29f88":"code","971aed64":"code","f4ba695f":"code","addcfb84":"code","aa39d701":"code","4d99e1b4":"code","bb9396eb":"markdown","09cba32b":"markdown","9afcc261":"markdown"},"source":{"d4de6d2e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","0f5f0921":"import cv2\nimport matplotlib.pyplot as plt\nimport os","2361f5aa":"train_data = pd.read_csv('\/kaggle\/input\/train.csv')\ntrain_data.head()","78c277d0":"img = cv2.imread('\/kaggle\/input\/train\/train\/0014d7a11e90b62848904c1418fc8cf2.jpg')\nprint(img.shape)\nplt.imshow(img)","84791f70":"print(train_data['id'][0])\na = []\na.append(int(train_data.loc[train_data['id'] == '0014d7a11e90b62848904c1418fc8cf2.jpg']['has_cactus']))\na","f28cd351":"train_path = '\/kaggle\/input\/train\/train\/'\nX_train = []\ny_train = []\ntrain_images = os.listdir(train_path)\n\nfor i in range(len(train_images)):\n    img = cv2.imread(train_path+train_images[i]) #read all images\n    img = img\/255\n    X_train.append(img) # append to list\n    y_train.append(int(train_data.loc[train_data['id'] == str(train_images[i])]['has_cactus']))\nprint(len(X_train))\nprint(len(y_train))","062bb063":"X_train = np.array(X_train)\ny_train = np.array(y_train)","132bf560":"import tensorflow as tf","8613e97d":"import tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense","5ca29f88":"input_shape = (32, 32, 3)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, 2, 2, padding='same', input_shape=input_shape, activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, 2, 2, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n    \nmodel.compile(loss='binary_crossentropy',\n            optimizer=RMSprop(lr=0.0001),\n            metrics=['accuracy'])","971aed64":"model.fit(x=X_train, y= y_train, batch_size=64, epochs=80, validation_split=0.2, shuffle=True)","f4ba695f":"sample_sub = pd.read_csv('\/kaggle\/input\/sample_submission.csv')\nsample_sub.head()","addcfb84":"sample_sub.has_cactus.unique()","aa39d701":"test_path = '\/kaggle\/input\/test\/test\/'\nX_test = {}\ntest_images = os.listdir(test_path)\n\nfor i in range(len(test_images)):\n    img = cv2.imread(test_path+test_images[i]) #read all images\n    img = img\/255\n    img = img.reshape(1, 32, 32, 3)\n    prediction = model.predict(img)\n    prediction = prediction[0][0]\n    if prediction>0.5:\n        prediction = 1\n    else:\n        prediction = 0\n    X_test[test_images[i]] = prediction\n# print(X_test)\ntest_df = pd.DataFrame(list(X_test.items()), columns=['id', 'has_cactus'])\ntest_df.head()","4d99e1b4":"test_df.to_csv(\"cactus_prediction.csv\", index=False)","bb9396eb":"## Building Model","09cba32b":"## Testing","9afcc261":"## Pre processing"}}