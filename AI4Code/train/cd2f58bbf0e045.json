{"cell_type":{"17bd4710":"code","410a064f":"code","3823572f":"code","ee34aab4":"code","39b01d3d":"code","362bc696":"code","e0d2c83b":"code","0bdab969":"code","f2d50b4b":"code","8121b72c":"code","84bf0a97":"code","da2e6125":"markdown","da2c0b5b":"markdown","64e59777":"markdown","899e8754":"markdown","a397e872":"markdown","4731b144":"markdown","a417d62a":"markdown","e88ba4e5":"markdown","81b2de08":"markdown"},"source":{"17bd4710":"import torch\nimport numpy as np\n\n####### HP\nnum_workers = 0\nbatch_size = 128\nvalid_size = 0.2\nnum_epochs = 50\nlr = 0.001\n\n# Check if CUDA is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n  print('CUDA is not available. Training on CPU...')\nelse:\n  print('CUDA is available. Training on GPU')","410a064f":"import torchvision.transforms as transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import datasets\n\n# Transform train and test data\ntransform_train = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Loading train and test data\ntrain_data = datasets.ImageFolder('..\/input\/intel-image-classification\/seg_train\/seg_train',\n                                 transform = transform_train)\ntest_data = datasets.ImageFolder('..\/input\/intel-image-classification\/seg_test\/seg_test',\n                                transform = transform_test)\n\n# Create validation set\nnum_train = len(train_data)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\nsplit = int(np.floor(valid_size*num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\n\n# Define samplers for obtaining training and validation batches\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\n# Create dataloaders\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size,\n                                         sampler = train_sampler,\n                                         num_workers = num_workers)\nvalidloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size,\n                                         sampler = valid_sampler,\n                                         num_workers = num_workers)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size = batch_size,\n                                        num_workers = num_workers)\n\n# Get the classes\nimport pathlib\nroot = pathlib.Path('..\/input\/intel-image-classification\/seg_train\/seg_train')\nclasses = sorted([j.name.split('\/')[-1] for j in root.iterdir()])\nprint(classes)","3823572f":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ndef imshow(img):\n  '''\n  Function to un-normalize and display an image\n  '''\n  img = img\/2 + 0.5 # un-normalize\n  plt.imshow(np.transpose(img, (1, 2, 0))) # convert from tensor image\n  \n# Get a batch of training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# Plot the images from the batch, along with corresponding labels\nfig = plt.figure(figsize = (25, 4))\n\n# Display 20 images\nfor idx in np.arange(20):\n  ax = fig.add_subplot(2, 20\/2, idx+1, xticks = [], yticks = [])\n  imshow(images[idx])\n  ax.set_title(classes[labels[idx]])","ee34aab4":"print(images.shape)","39b01d3d":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass ImageNet (nn.Module):\n    def __init__(self):\n        super (ImageNet, self).__init__ ()\n        self.cv = nn.Sequential(\n            nn.Conv2d(3, 50, 3, padding=1),         # 1\n            nn.BatchNorm2d(50),\n            nn.ReLU(),\n            #nn.Dropout(),\n            nn.MaxPool2d (3, 3),\n\n            nn.Conv2d (50, 100, 3, padding=1),      # 2\n            nn.BatchNorm2d (100),\n            nn.ReLU (),\n            #nn.Dropout (),\n\n            nn.Conv2d (100, 140, 3, padding=1),     # 3\n            nn.BatchNorm2d (140),\n            nn.ReLU (),\n            #nn.Dropout (),\n\n            nn.Conv2d (140, 180, 3, padding=1),     # 4\n            nn.BatchNorm2d (180),\n            nn.ReLU (),\n            #nn.Dropout (),\n\n            nn.Conv2d (180, 200, 3, padding=1),     # 5\n            nn.BatchNorm2d (200),\n            nn.ReLU (),\n            #nn.Dropout (),\n            nn.MaxPool2d (3, 3),\n\n            nn.Conv2d (200, 240, 3, padding=1),     # 6\n            nn.BatchNorm2d (240),\n            nn.ReLU (),\n            #nn.Dropout (),\n\n            nn.Conv2d (240, 300, 3, padding=1),     # 7\n            nn.BatchNorm2d(300),\n            nn.ReLU(),\n            #nn.Dropout(),\n\n            nn.Conv2d (300, 350, 3, padding=1),     # 8\n            nn.BatchNorm2d(350),\n            nn.ReLU(),\n            #nn.Dropout(),\n\n            nn.Conv2d (350, 400, 3, padding=1),      # 9\n            nn.BatchNorm2d(400),\n            nn.ReLU(),\n            #nn.Dropout(),\n            nn.MaxPool2d (3, 3),\n\n            nn.Conv2d (400, 450, 3, padding=1),      # 10\n            nn.BatchNorm2d(450),\n            nn.ReLU(),\n            #nn.Dropout(),\n            \n            nn.Conv2d (450, 500, 3, padding=1),      # 11\n            nn.BatchNorm2d(500),\n            nn.ReLU(),\n            #nn.Dropout(),\n            \n            nn.Conv2d (500, 550, 3, padding=1),      # 12\n            nn.BatchNorm2d(550),\n            nn.ReLU(),\n            #nn.Dropout(),\n            \n            nn.Conv2d (550, 600, 3, padding=1),      # 13\n            nn.BatchNorm2d(600),\n            nn.ReLU(),\n            #nn.Dropout(),\n            nn.MaxPool2d (3, 3)\n        )\n\n        self.fc = nn.Sequential(\n            nn.Linear (600, 100),\n            nn.ReLU (),\n            nn.Dropout (),\n            nn.Linear (100, 50),\n            nn.ReLU (),\n            nn.Dropout (),\n            nn.Linear (50, 6)\n        )\n\n    def forward(self, x):\n        x = self.cv (x)\n        x = x.view (x.size (0), -1)  # flatten\n        x = self.fc (x)\n\n        return x\n\nmodel = ImageNet ()\n\n# Move tensors to GPU if CUDA is available\nif train_on_gpu:\n    model.cuda ()","362bc696":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = lr)","e0d2c83b":"valid_loss_min = np.Inf # track the change in validation loss\n\ntrain_losses = []\nvalid_losses = []\n\nfor epoch in range(1, num_epochs+1):\n  # keep track of training and validation loss\n  train_loss = 0.0\n  valid_loss = 0.0\n  \n  #------------------\n  # train the model\n  #------------------\n  model.train()\n  for data, target in trainloader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n      data, target = data.cuda(), target.cuda()\n    \n    # clear the gradients of all optimized variables\n    optimizer.zero_grad()\n    \n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    \n    # calculate batch loss\n    loss = criterion(output, target)\n    \n    # backward pass: compute gradient of the loss with respect to the \n    # model parameters\n    loss.backward()\n    \n    # perform parameter update\n    optimizer.step()\n    \n    # update training loss\n    train_loss += loss.item()*data.size(0)\n    \n  #------------------\n  # validate the model\n  #------------------\n  model.eval()\n  for data, target in validloader:\n    # move tensors to GPU if CUDA is available\n    if train_on_gpu:\n      data, target = data.cuda(), target.cuda()\n    \n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    \n    # calculate the batch loss\n    loss = criterion(output, target)\n    \n    # update average validation loss\n    valid_loss += loss.item()*data.size(0)\n    \n  # calculate average losses\n  train_loss = train_loss\/len(trainloader.sampler)\n  valid_loss = valid_loss\/len(validloader.sampler)\n  train_losses.append(train_loss)\n  valid_losses.append(valid_loss)\n  \n  # print training and validation stats\n  print('Epoch: {} \\tTraining Loss: {:.4f} \\tValidation loss: {:.4f}'.format(\n        epoch, train_loss, valid_loss))\n  \n  # save model if validation loss has decreased\n  if valid_loss <= valid_loss_min:\n    print('Validation loss decreased ({:.4f} -> {:.4f}) \\n Saving model...'.format(\n          valid_loss_min, valid_loss))\n    torch.save(model.state_dict(), 'intel_image_net.pt')\n    valid_loss_min = valid_loss","0bdab969":"plt.plot(train_losses, label = 'Training loss')\nplt.plot(valid_losses, label = 'Validation loss')\nplt.legend(frameon = False)\nplt.show()","f2d50b4b":"model.load_state_dict(torch.load('intel_image_net.pt'))","8121b72c":"test_loss = 0.0\nclass_correct = list(0. for i in range(6))\nclass_total = list(0. for i in range(6))\n\nmodel.eval()\nfor data, target in testloader:\n  if train_on_gpu:\n    data, target = data.cuda(), target.cuda()\n    \n  output = model(data)\n  loss = criterion(output, target)\n  \n  test_loss += loss.item()*data.size(0)\n  _, pred = torch.max(output, 1)\n  \n  correct_tensor = pred.eq(target.data.view_as(pred))\n  correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n  \n  for i in range(10):\n    label = target.data[i]\n    class_correct[label] += correct[i].item()\n    class_total[label] += 1\n    \ntest_loss = test_loss \/ len(testloader.dataset)\nprint('Test loss: {:.4f}\\n'.format(test_loss))\n\nfor i in range(6):\n  if class_total[i] > 0:\n    print('Test accuracy of %5s: %2d%% (%2d\/%2d)' % (\n          classes[i], 100*class_correct[i] \/ class_total[i], \n          np.sum(class_correct[i]), np.sum(class_total[i])))\n  else:\n    print('Test accuracy of %5s: N\/A (no training examples)' % (classes[i]))\n\nprint('\\nTest accuracy (Overall): %2d%% (%2d\/%2d)' % (\n    100.*np.sum(class_correct)\/ np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","84bf0a97":"transform_pred = transforms.Compose([\n    transforms.Resize((150, 150)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\npred_data = datasets.ImageFolder('..\/input\/intel-image-classification\/seg_pred',\n                                transform = transform_pred)\n\npredloader = torch.utils.data.DataLoader(pred_data, batch_size = batch_size,\n                                        num_workers = num_workers)\n\ndataiter = iter(predloader)\nimages, no_labels = dataiter.next()\nimages.numpy()\n\nif train_on_gpu:\n  images = images.cuda()\n\noutput = model(images)\n_, preds_tensor = torch.max(output, 1)\npreds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n\n# Visualize predicted labels\nfig = plt.figure(figsize = (25,4))\nfor idx in np.arange(20):\n  ax = fig.add_subplot(2, 20\/2, idx + 1, xticks = [], yticks = [])\n  imshow(images.cpu()[idx])\n  ax.set_title('{}'.format(classes[preds[idx]]))","da2e6125":"Test the trained network","da2c0b5b":"Visualize a batch of training data","64e59777":"Load the model with the lowest validation loss","899e8754":"Train the model","a397e872":"Check for CUDA","4731b144":"Load the data","a417d62a":"Create the Network Architecture","e88ba4e5":"Prediction on the pred data set\n\nCreate a subfolder containing all the unlabeled images in seg_pred in order for PyTorch's ImageFolder to work.","81b2de08":"Specify Loss Function and Optimizer"}}