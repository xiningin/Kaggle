{"cell_type":{"da361354":"code","7d2bc74a":"code","2cbbf77d":"code","c54d9c5e":"code","d30a1dcb":"code","de75c4e5":"code","6e861f58":"code","4c0a9ef5":"code","f717efe2":"code","74e943af":"code","b1543674":"code","539db648":"code","fb4eb75c":"code","118e92ff":"code","c5f53418":"code","f0cf3bdb":"code","6e95de64":"code","8c2faeb4":"markdown","b49156a0":"markdown","7e0a48e4":"markdown","88cf4e13":"markdown","789c202b":"markdown","4b5646bc":"markdown","2f1882b2":"markdown","bd7a9290":"markdown","ed86a93c":"markdown","58574315":"markdown"},"source":{"da361354":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\npath = '..\/input\/chinese-mnist-digit-recognizer\/chineseMNIST.csv'","7d2bc74a":"# Read the dataset\nds = pd.read_csv(path)\nds.shape","2cbbf77d":"ds.columns","c54d9c5e":"# the labels and the character cols\nlabels_cols = ['label', 'character']\n# select only the images\ndata = ds.drop(labels_cols, axis=1).values\n# select the labels and the characters\nlabels = ds[labels_cols[0]].values\ncharacters = ds[labels_cols[1]].values\n\ndata.shape, labels.shape, characters.shape","d30a1dcb":"# to process the data and convert to 64x64 images\n# receives data\ndef process_data(x):\n    images = [] # all the images\n    # is each row in x, each image\n    for img in x:\n        # reshape the flatten data\n        image = img.reshape(64,64,1)\n        images.append(image)\n    # return the images in an apropiate format\n    return np.array(images).astype('float32')\/255\n\n# recieves labels\ndef process_target(chars, num_classes):\n    target = [] # is the result\n    class_names = {} # other result\n    count = count_values(chars) # count the characters\n    ###### add the labels for the dict\n    for key, i in zip(count.keys(), range(num_classes)):\n        class_names[key] = i\n    ###### create the labels data, the numbers\n    labs = class_names.keys()\n    for char in chars:\n        pos = class_names[char] # position of the 1\n        row = []\n        for i in range(num_classes):# create the target [0,0,0...,1,...]\n            if pos != i:\n                row.append(0)\n            else:\n                row.append(1)\n        target.append(row)\n    return np.array(target).astype('float32'), class_names\n\n\ndef count_values(arr):\n    dic = {}\n    for val in arr:\n        if val not in dic.keys():\n            dic[val] = 1\n        else:\n            dic[val] += 1\n    return dic\n\n# plot multiple images, preds is for the titles\n# preds must be like [[real, pred]]\ndef plot_images(imgs, dims, figsize, title_size, preds=[]):\n    plt.figure(figsize=figsize)\n    for img, i, in zip(imgs, np.arange(imgs.shape[0])):\n        plt.subplot(dims[0], dims[1], i+1)\n        plt.imshow(np.squeeze(img), cmap='gray')\n        plt.axis('off')\n        title = f'Image {i+1}'\n        if preds != []:\n            title = f'Real: {preds[i][0]}, Pred: {preds[i][1]}'\n        plt.title(title, fontsize=title_size)\n    plt.show()\n    \n# these numbers are just to prove*\nsample_data = process_data(data[:8008:1001])\nplot_images(sample_data, dims=(2,4), figsize=(16,8), title_size=22)","de75c4e5":"# get the images from the df as arrays\nX = process_data(data)\n\n# and obtain the target data from the characters\nY, class_names = process_target(characters, num_classes=15)\n\nX.shape, X.dtype, Y.shape, Y.dtype","6e861f58":"# split the dataset in train and test. validation set will be included in the training, later\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=314, shuffle=True)\nx_train.shape, x_test.shape","4c0a9ef5":"y_train[0] # sample of the result of the predictions","f717efe2":"# to reset the keras session\n#keras.backend.clear_session()\n\ninput_shape = (64,64,1) # the dimension of the data\nnum_classes = 15 # the number of classes\n\nmodel = Sequential([\n    # define the input shape with a layer\n    layers.InputLayer(input_shape=input_shape),\n\n    # convolutional part with relu and later pooling\n    layers.Conv2D(filters=32, kernel_size=5, activation='relu'),\n    layers.MaxPooling2D(pool_size=2),\n\n    # flatten the data, as it comes with (64,64,1) shape\n    layers.Flatten(),\n    \n    # dense part, with neurons\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(rate=.3), # turn off random neurons in each step\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(rate=.3), # it helps to prevent overfitting\n    layers.Dense(num_classes, activation='softmax')\n])\n\n# the last layer has multiple (15) neurons since the result we\n# want looks like the one in the cell above, each neuron provides\n# one of these numbers\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics = ['accuracy'],\n)\n\nmodel.summary()","74e943af":"# as the model performance increases faster\n# it might be good to use an early stopping\n\nearly_stopping = EarlyStopping(\n    min_delta=.005, # minimum performance increase\n    patience=10, # epochs until the stop\n    restore_best_weights=True\n)\n\nhist = model.fit(\n    x_train,\n    y_train,\n    batch_size=64,\n    epochs=20,\n    validation_split=.1,# as there's no val data\n    callbacks=[early_stopping]\n)","b1543674":"plt.figure(figsize=(15, 10))\n\n# plot the loss function\nplt.subplot(1,2,1)\nplt.plot(hist.history['loss'], label='train')\nplt.plot(hist.history['val_loss'], label='validation')\nplt.title('Loss Function')\nplt.grid(True)\nplt.legend()\n\n# and the accuracy\nplt.subplot(1,2,2)\nplt.plot(hist.history['accuracy'], label='train')\nplt.plot(hist.history['val_accuracy'], label='validation')\nplt.grid(True)\nplt.title('Accuracy')\nplt.legend()\n\nplt.show()","539db648":"results = model.evaluate(x_test, y_test, batch_size=64)\nprint(\"test loss, test acc:\", results)","fb4eb75c":"def max_index(arr):\n    mx = 0\n    idx = 0\n    for a, i in zip(arr, range(len(list(arr)))):\n        if a > mx:\n            mx = a\n            idx = i\n    return idx\n\n# prepare the data for the matrix\npreds = model.predict(x_test) # make predictions\ny_pred = []\n# iterate the preds as we want the class number\nfor p in preds:\n    c_num = max_index(p) # find the index of the max\n    y_pred.append(c_num)\n\n# obtain the y_real, the same process but with y_test\ny_real = []\nfor p in y_test:\n    c_num = max_index(p) # find the index of the max\n    y_real.append(c_num)","118e92ff":"# define the matrix with the real classes and the predicted\nm = confusion_matrix(y_real, y_pred)\n# the labels for the plot\nlabels = list(class_names.values()) # the characters throw warnings\nplt.figure(figsize=(20, 8))\n# create the plot\nheatmap = sns.heatmap(m, xticklabels=labels, yticklabels=labels, annot=True, fmt='d', color='blue')\n# labels for the axes\nplt.xlabel('Predicted Class')\nplt.ylabel('True Class')\nplt.title('Confusion Matrix')\nplt.show()","c5f53418":"x_test[:10].shape","f0cf3bdb":"sample_data = x_test[:15] # the first 15 numbers\n# a process similar as the one above\npreds = model.predict(sample_data) # make predictions\ny_pred = []\n\n# iterate the preds as we want the class number\nfor pred,real in zip(preds, y_test):\n    pred_num = max_index(pred) # find the index of the max\n    real_num = max_index(real) # in each arrays\n    y_pred.append((real_num, pred_num)) # first real\n\n\nimages = np.squeeze(sample_data) # delete the extra dim\n# as the shape of sample data is (15, 64, 64, 1)\n\n# it will be 15 preds\nplot_images(images, (3,5), figsize=(25,15), title_size=22, preds=y_pred)","6e95de64":"model.save('Chinese_Digit_Recognizer.h5')\n# also I will save the processed data\nnp.save('training_data.npy', X)\nnp.save('testing_data.npy', Y)","8c2faeb4":"# Samples of Predictions from *test* set","b49156a0":"# Evaluate the Model with *test* set","7e0a48e4":"# Chinese Digit Recognizer with a Keras CNN","88cf4e13":"# Conclusion\nThis is my fist practise where the objective is to recognize hand-written digits. I liked it. `The model reach a performance of almost 0.96 in validation and testing and .99 in training`, I guess that was because of there was a good quantity of data, `1K samples of each class`, and the borders and `lines are such a thing that cnn's are good at` and I think this dataset proves that and helps us to experiment with cnn's. It was a really good dataset. **Thank you :D**","789c202b":"# Confusion Matrix","4b5646bc":"# The Model, a Convolutional Neural Network","2f1882b2":"# Processing and Useful functions","bd7a9290":"# Save the Model","ed86a93c":"# Split the Data on *train* and *test*","58574315":"# Applying the Processing Functions"}}