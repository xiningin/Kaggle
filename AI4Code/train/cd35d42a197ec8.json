{"cell_type":{"17f53b5e":"code","06bbd293":"code","8d888333":"code","157ac4ac":"code","723bf471":"code","c3e6b3c4":"code","64e854fa":"code","9574cba0":"code","a23c90a9":"code","aa39f4c3":"code","da26bef6":"code","4b9cffe7":"code","439d9c31":"code","6e402477":"code","610070bd":"code","9865dbcf":"code","223ad97f":"code","05c40e53":"code","15d86571":"code","4de3a507":"code","57ae03af":"code","46180aef":"code","5b0e3a6e":"code","af327918":"code","40a5b7e5":"code","eec1c8da":"code","7bce5662":"code","48c1618b":"code","307143d7":"code","13893c5b":"markdown","d2bde200":"markdown","ebb5b65f":"markdown","3ca36434":"markdown","aaac3b3a":"markdown","903dd913":"markdown","314dbfb0":"markdown","b0b06f7e":"markdown","123efcd0":"markdown","0ade7c75":"markdown","c1f4c5f6":"markdown","b8c49466":"markdown","7947828e":"markdown","1b3a9673":"markdown","5c42affe":"markdown"},"source":{"17f53b5e":"from keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import  ImageDataGenerator, img_to_array, image, load_img\nfrom keras import backend as K\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\nfrom keras.applications import VGG19\nfrom keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input as resnet50_preprocess_input\nfrom keras.models import load_model\nfrom keras.models import Model\nimport keras\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 16\n\n#Variable defining\nSAMPLE_PER_CATEGORY = 200\nSEED = 42\nWIDTH = 128\nHEIGHT = 128\nDEPTH = 3\nINPUT_SHAPE = (WIDTH, HEIGHT, DEPTH)\n\ndata_dir = '..\/input\/plant-seedlings-classification\/'\ntrain_dir = os.path.join(data_dir, 'train')\ntest_dir = os.path.join(data_dir, 'test')\nsample_submission = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))","06bbd293":"!ls ..\/input\/plant-seedlings-classification","8d888333":"CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\nNUM_CATEGORIES = len(CATEGORIES)\nNUM_CATEGORIES","157ac4ac":"for category in CATEGORIES:\n    print('{} {} images'.format(category, len(os.listdir(os.path.join(train_dir, category)))))","723bf471":"def read_img(filepath, size):\n    img = image.load_img(os.path.join(data_dir, filepath), target_size=size) ## https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/load_img\n    img = image.img_to_array(img)\n    return img","c3e6b3c4":"train = []\nfor category_id, category in enumerate(CATEGORIES):\n    for file in os.listdir(os.path.join(train_dir, category)):\n        train.append(['train\/{}\/{}'.format(category, file), category_id, category])\ntrain = pd.DataFrame(train, columns=['file', 'category_id', 'category'])\ntrain.shape","64e854fa":"train.head(2)","9574cba0":"train = pd.concat([train[train['category'] == c][:SAMPLE_PER_CATEGORY] for c in CATEGORIES])\ntrain = train.sample(frac=1)\ntrain.index = np.arange(len(train))\ntrain.shape","a23c90a9":"train","aa39f4c3":"test = []\nfor file in os.listdir(test_dir):\n    test.append(['test\/{}'.format(file), file])\ntest = pd.DataFrame(test, columns=['filepath', 'file'])\ntest.shape","da26bef6":"test.head(2)","4b9cffe7":"fig = plt.figure(1, figsize=(NUM_CATEGORIES, NUM_CATEGORIES))\ngrid = ImageGrid(fig, 111, nrows_ncols=(NUM_CATEGORIES, NUM_CATEGORIES), axes_pad=0.05)\ni = 0\nfor category_id, category in enumerate(CATEGORIES):\n    for filepath in train[train['category'] == category]['file'].values[:NUM_CATEGORIES]:\n        ax = grid[i]\n        img = read_img(filepath, (WIDTH, HEIGHT))\n        ax.imshow(img \/ 255.)\n        ax.axis('off')\n        if i % NUM_CATEGORIES == NUM_CATEGORIES - 1:\n            ax.text(250, 112, filepath.split('\/')[1], verticalalignment='center')\n        i += 1\nplt.show();","439d9c31":"np.random.seed(seed=SEED)","6e402477":"def setTrainableLayersVGG(vgg_model):\n    set_trainable = False\n    for layer in vgg_model.layers:\n        if layer.name in ['block5_conv1', 'block4_conv1']:\n            set_trainable = True\n            \n        if set_trainable:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n    return vgg_model","610070bd":"vgg = VGG19(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n\noutput = vgg.layers[-1].output\noutput = keras.layers.Flatten()(output)\nvgg_model = Model(vgg.input, output)\n\nvgg_model = setTrainableLayersVGG(vgg_model)\n# vgg_model.trainable = False\n# for layer in vgg_model.layers:\n#     layer.trainable = False\n\npd.set_option('max_colwidth', -1)\nlayers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    ","9865dbcf":"def setTrainableLayersResNet(resnet_model):\n    set_trainable = False\n    for layer in resnet_model.layers:\n        if layer.name in ['res5c_branch2b', 'res5c_branch2c', 'activation_97']:\n            set_trainable = True\n            \n        if set_trainable:\n            layer.trainable = True\n        else:\n            layer.trainable = False\n    return resnet_model","223ad97f":"resnet = ResNet50(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n\noutput = resnet.layers[-1].output\noutput = keras.layers.Flatten()(output)\nresnet_model = Model(resnet.input, output)\n\nsetTrainableLayersResNet(resnet_model)\n# resnet_model.trainable = False\n# for layer in resnet_model.layers:\n#     layer.trainable = False\n\npd.set_option('max_colwidth', -1)\nlayers = [(layer, layer.name, layer.trainable) for layer in resnet_model.layers]\npd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable']) ","05c40e53":"def printHistory(history, title, epochs):\n    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    t = f.suptitle(title, fontsize=12)\n    f.subplots_adjust(top=0.85, wspace=0.3)\n\n    epoch_list = list(range(1,epochs+1))\n    ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n    ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n    ax1.set_xticks(np.arange(0, epochs+1, 5))\n    ax1.set_ylabel('Accuracy Value')\n    ax1.set_xlabel('Epoch')\n    ax1.set_title('Accuracy')\n    l1 = ax1.legend(loc=\"best\")\n\n    ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n    ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n    ax2.set_xticks(np.arange(0, epochs+1, 5))\n    ax2.set_ylabel('Loss Value')\n    ax2.set_xlabel('Epoch')\n    ax2.set_title('Loss')\n    l2 = ax2.legend(loc=\"best\")","15d86571":"#create model from scratch\ndef createModel(pretrainedModel, fineTune, number_of_hidden_layers, activation, optimizer, learning_rate, epochs):\n    print(\"Create Model\")\n\n    tranfer_model = 0 # just define\n    \n    if pretrainedModel == \"ResNet-50\":\n        tranfer_model = ResNet50(weights='imagenet', input_shape=INPUT_SHAPE, include_top=False)\n        if fineTune == True:\n            tranfer_model = setTrainableLayersResNet(tranfer_model)\n        else:\n            for layer in tranfer_model.layers:\n                tranfer_model.trainable = False  # freeze feature extracting layers\n    elif pretrainedModel == \"VGG-19\":\n        tranfer_model = VGG19(weights='imagenet', input_shape=INPUT_SHAPE, include_top=False)\n        \n        if fineTune == True:\n            tranfer_model = setTrainableLayersVGG(tranfer_model)\n        else:\n            for layer in tranfer_model.layers:\n                layer.trainable = False  # freeze feature extracting layers\n\n    output = tranfer_model.layers[-1].output\n    output = keras.layers.Flatten()(output)\n    trans_model = Model(tranfer_model.input, output)\n\n    model = Sequential()\n    model.add(trans_model)\n    \n    for i in range(0,number_of_hidden_layers):\n        model.add(Dense(512))\n        model.add(Activation(activation))\n        model.add(Dropout(0.3))\n\n    model.add(Dense(12, activation='softmax'))\n\n    if optimizer == 'SGD':\n        opt = SGD(lr=learning_rate, decay=learning_rate \/ epochs)\n    elif optimizer == 'Adam':\n        opt = Adam(lr=learning_rate, decay=learning_rate \/ epochs)\n\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    return model","4de3a507":"#callbacks for keras modal\ndef get_callbacks(patience):\n    print(\"Get Callbacks\")\n\n    lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=1e-5, patience=patience, verbose=1)\n    #msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [lr_reduce, EarlyStopping()]","57ae03af":"def trainModelDF(images, pretrainedModel, fineTune, epochs, batch_size, learning_rate, cross_validation_folds, activation, number_of_hidden_layers, optimizer):\n    print(\"Train Model\")\n     \n    datagen_train = ImageDataGenerator(rescale=1.\/255)\n    \n    datagen_valid = ImageDataGenerator(rescale=1.\/255)\n        \n    print(\"Cross validation\")\n    kfold = StratifiedKFold(n_splits=cross_validation_folds, shuffle=True)\n    cvscores = []\n    iteration = 1\n    \n    t = images.category_id\n    \n    for train_index, test_index in kfold.split(np.zeros(len(t)), t):\n\n        print(\"======================================\")\n        print(\"Iteration = \", iteration)\n\n        iteration = iteration + 1\n\n        train = images.loc[train_index]\n        test = images.loc[test_index]\n\n        print(\"======================================\")\n        \n        model = createModel(pretrainedModel, fineTune, number_of_hidden_layers, activation, optimizer, learning_rate, epochs)\n\n        print(\"======================================\")\n        \n        train_generator = datagen_train.flow_from_dataframe(dataframe=train,\n                                                  directory=\"\/kaggle\/input\/plant-seedlings-classification\/\",\n                                                  x_col=\"file\",\n                                                  y_col=\"category\",\n                                                  batch_size=batch_size,\n                                                  seed=SEED,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=(HEIGHT, WIDTH));\n        valid_generator=datagen_valid.flow_from_dataframe(dataframe=test,\n                                                  directory=\"\/kaggle\/input\/plant-seedlings-classification\/\",\n                                                  x_col=\"file\",\n                                                  y_col=\"category\",\n                                                  batch_size=batch_size,\n                                                  seed=SEED,\n                                                  shuffle=False,\n                                                  class_mode=\"categorical\",\n                                                  target_size=(HEIGHT, WIDTH));\n        \n        STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\n        STEP_SIZE_VALID=valid_generator.n\/\/valid_generator.batch_size\n\n        #Trains the model on data generated batch-by-batch by a Python generator\n        history = model.fit_generator(generator=train_generator,\\\n                            validation_data = valid_generator, \\\n                            steps_per_epoch=STEP_SIZE_TRAIN, \\\n                            validation_steps=STEP_SIZE_VALID, \\\n                            epochs=epochs, \\\n                            verbose=1)#, \\\n#                             callbacks = get_callbacks(patience=2))\n        \n        scores = model.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID, pickle_safe=True)\n        print(\"Accuarcy %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n        cvscores.append(scores[1] * 100)\n        \n        printHistory(history, pretrainedModel, epochs)\n\n    accuracy = np.mean(cvscores);\n    std = np.std(cvscores);\n    print(\"Accuracy: %.2f%% (+\/- %.2f%%)\" % (accuracy, std))\n    return accuracy, std","46180aef":"trainModelDF(\n    train,\n    pretrainedModel = \"VGG-19\", #ResNet-50\n    fineTune = False,\n    batch_size =32,\n    cross_validation_folds = 5,\n    learning_rate = 0.001,\n    activation = 'relu',\n    number_of_hidden_layers = 2,\n    optimizer = 'Adam',\n    epochs = 24\n)","5b0e3a6e":"# trainModelDF(\n#     train,\n#     pretrainedModel = \"VGG-19\", #ResNet-50\n#     fineTune = True,\n#     batch_size =32,\n#     cross_validation_folds = 5,\n#     learning_rate = 0.001,\n#     activation = 'relu',\n#     number_of_hidden_layers = 2,\n#     optimizer = 'Adam',\n#     epochs = 24\n# )","af327918":"trainModelDF(\n    train,\n    pretrainedModel = \"ResNet-50\", #ResNet-50\n    fineTune = False,\n    batch_size =4,\n    cross_validation_folds = 5,\n    learning_rate = 0.001,\n    activation = 'relu',\n    number_of_hidden_layers = 1,\n    optimizer = 'Adam',\n    epochs = 64\n)","40a5b7e5":"# trainModelDF(\n#     train,\n#     pretrainedModel = \"ResNet-50\", #ResNet-50\n#     fineTune = True,\n#     batch_size = 4,\n#     cross_validation_folds = 5,\n#     learning_rate = 0.001,\n#     activation = 'relu',\n#     number_of_hidden_layers = 1,\n#     optimizer = 'Adam',\n#     epochs = 64\n# )","eec1c8da":"def trainFinalModel(images, pretrainedModel, fineTune, epochs, batch_size, learning_rate, activation, number_of_hidden_layers, optimizer):\n    print(\"Train Model\")\n     \n    datagen_train = ImageDataGenerator(rescale=1.\/255)\n    \n    print(\"======================================\")    \n    model = createModel(pretrainedModel, fineTune, number_of_hidden_layers, activation, optimizer, learning_rate, epochs)\n    print(\"======================================\")\n    \n    train_generator = datagen_train.flow_from_dataframe(dataframe=images,\n                                                        directory=\"\/kaggle\/input\/plant-seedlings-classification\/\",\n                                                        x_col=\"file\",\n                                                        y_col=\"category\",\n                                                        batch_size=batch_size,\n                                                        seed=SEED,\n                                                        shuffle=True,\n                                                        class_mode=\"categorical\",\n                                                        target_size=(HEIGHT, WIDTH));\n        \n    print (train_generator.class_indices)\n    \n    STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\n    \n    #Trains the model on data generated batch-by-batch by a Python generator\n    model.fit_generator(generator=train_generator,\\\n                            steps_per_epoch=STEP_SIZE_TRAIN, \\\n                            epochs=epochs, \\\n                            verbose=1)#, \\\n#                             callbacks = get_callbacks(patience=2))\n        \n    model.save(\"\/kaggle\/working\/best_model\")\n    \n    return train_generator.class_indices","7bce5662":"#predict values \ndef predict_createSubmission(class_indices):\n    print(\"Predicting......\")\n    \n    datagen_test = ImageDataGenerator(rescale=1.\/255)\n    \n    test_generator = datagen_test.flow_from_dataframe(dataframe=test,\n                                                        directory=\"\/kaggle\/input\/plant-seedlings-classification\/test\/\",\n                                                        x_col=\"file\",\n                                                        y_col=None,\n                                                        batch_size=1,\n                                                        seed=SEED,\n                                                        shuffle=False,\n                                                        class_mode=None,\n                                                        target_size=(HEIGHT, WIDTH));\n        \n    model = load_model('\/kaggle\/working\/best_model')\n    filenames = test_generator.filenames\n    nb_samples = len(filenames)\n\n    predictions = model.predict_generator(test_generator,steps = nb_samples) # return prob of each class per image (softmax)\n    \n    predicted_class_indices=np.argmax(predictions,axis=1)\n    \n    labels = dict((v,k) for k,v in class_indices.items())\n    predicted_labels = [labels[k] for k in predicted_class_indices]\n    \n    results=pd.DataFrame({\"file\":filenames,\n                          \"species\":predicted_labels})\n\n    print (results)\n    \n    results.to_csv(\"submission.csv\",index=False)\n\n    print(\"Prediction Completed\")","48c1618b":"class_indices = trainFinalModel(\n    train,\n    pretrainedModel = \"VGG-19\", #ResNet-50\n    fineTune = False,\n    batch_size = 32,\n    learning_rate = 0.001,\n    activation = 'relu',\n    number_of_hidden_layers = 2,\n    optimizer = 'Adam',\n    epochs = 24\n)","307143d7":"predict_createSubmission(class_indices)","13893c5b":"**Understanding test-set**","d2bde200":"**Introduction**\n\nThis is a very basic implementation of convolutional neural network (CNN) using pretrained models VGG-19 and ResNet-50. Fully implemented using keras. You can learn following things by reading this.  \n\n1. Keras implementation of a CNN using VGG-19.\n2. Keras implementation of a CNN using ResNet-50.\n3. Train only the fully connected layers after above 2 models.\n4. Train last few layers of the above 2 models along with fully connected layers.\n4. StratidiedKFold evaluation.\n5. Utility funcitons required when working with images.\n\n*Comment your improvements and be sure the upvote.*","ebb5b65f":"**Generating vector for training samples taking equal number of images from each category**","3ca36434":"**VGG-19 tuning last 2 layers as well**","aaac3b3a":"**ResNet-50 with fine tuning last 2 layers**","903dd913":"**Print function for training history**","314dbfb0":"**Training sample data set info**","b0b06f7e":"**Transfer learning as a alternative to Basic CNN**\n\n**Complete guide**\n> https:\/\/towardsdatascience.com\/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a\n\n**ResNet example**    \n> https:\/\/www.kaggle.com\/vinlor\/resnet-and-flow-from-dataframe-notebook\n\n**VGG example**   \n> https:\/\/github.com\/jin14\/Xray-classifier\/blob\/master\/kerasBasic.py","123efcd0":"**Imports and Workspace setting**","0ade7c75":"**VGG-19 as a feature extractor**","c1f4c5f6":"**Generating example images**","b8c49466":"**VGG-19 model layers identification**","7947828e":"**ResNet-50 model identification**","1b3a9673":"**Defining categories**","5c42affe":"**ResNet-50 as a feature extractor**"}}