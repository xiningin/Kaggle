{"cell_type":{"35d76fb4":"code","1fdfbaef":"code","e2536aff":"code","28fb6b26":"code","3ff75a4f":"code","664a0e36":"code","900d16bd":"code","83f12191":"code","5706f923":"code","1820bf4c":"code","2139cea9":"code","2a1cde9c":"code","ceca02c8":"code","2485a1a4":"code","81a613d4":"code","f714183f":"code","ceb31e87":"code","a98f292c":"code","a2bc733b":"code","38e591ee":"code","bcae5343":"code","cac607af":"code","9f652a78":"code","5239be24":"code","fa67715a":"code","39ca116c":"code","14b271d9":"code","65e31192":"code","82d62f44":"code","344a873b":"code","e6bba292":"code","6181bb9f":"code","08cf592c":"code","06267179":"code","e8462a49":"code","2db47b3f":"markdown","1e5b9577":"markdown","cdf124db":"markdown","5bd2da7f":"markdown","edd8d61f":"markdown","80935890":"markdown","3c6fbb26":"markdown","b8619f6b":"markdown","8ced6546":"markdown","97d7b17a":"markdown","1c3cfabd":"markdown","5178504a":"markdown","08f35717":"markdown","4dec04db":"markdown","7a531640":"markdown","c612aa38":"markdown","90339094":"markdown","86ba49de":"markdown","61899a06":"markdown","ea7ecd15":"markdown","9232e5ec":"markdown","7f5a1785":"markdown","67981397":"markdown","97aad6b6":"markdown","90fcd839":"markdown","8096aa1d":"markdown"},"source":{"35d76fb4":"import numpy as np\nimport pandas as pd \nimport keras\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n","1fdfbaef":"# unzip the dataset\nfrom zipfile import ZipFile\nzf = ZipFile('..\/input\/dogs-vs-cats\/train.zip')\nzf.extractall('\/kaggle\/working\/') # save files in selected folder\nzf.close()","e2536aff":"filenames = os.listdir(\"\/kaggle\/working\/train\")\ncategories = []\nfor name in filenames:\n    category = name.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\nimage_df = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})","28fb6b26":"# See top 5 rows of the dataset\nimage_df.head()","3ff75a4f":"# See buttom 5 cell of the dataset\nimage_df.tail()","664a0e36":"image_df.shape","900d16bd":"# visualize number of cats and dogs present in the dataframe\nimage_df['category'].value_counts().plot.bar()","83f12191":"sample = random.choice(filenames)\nimage = load_img(\"\/kaggle\/working\/train\/\"+sample)\nplt.imshow(image)","5706f923":"# replace 0 as \"cat\" & 1 as \"dog\"\nimage_df[\"category\"] = image_df[\"category\"].replace({0: 'cat', 1: 'dog'}) ","1820bf4c":"# split the dataset for training & testing\ntrain_df, validate_df = train_test_split(image_df, test_size=0.20, random_state=23)\n# training dataset\ntrain_df = train_df.reset_index(drop=True)\n# testing dataset\nvalidate_df = validate_df.reset_index(drop=True)","2139cea9":"# see frequency of class variables in target column of training dataset\ntrain_df['category'].value_counts().plot.bar(color=[\"cyan\",\"pink\"])","2a1cde9c":"# see frequency of class variables in target column of testing dataset\nvalidate_df['category'].value_counts().plot.bar(color=[\"cyan\",\"pink\"])","ceca02c8":"FAST_RUN = False\nIMAGE_WIDTH=128\nIMAGE_HEIGHT=128\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\nbatch_size=15","2485a1a4":"train_df_size = train_df.shape[0]\nvalidate_df_size = validate_df.shape[0]","81a613d4":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    train_df, \n    \"\/kaggle\/working\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","f714183f":"validation_datagen = ImageDataGenerator(rescale=1.\/255)\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    \"\/kaggle\/working\/train\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","ceb31e87":"example_df = train_df.sample(n=1).reset_index(drop=True)\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"\/kaggle\/working\/train\/\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)","a98f292c":"# visualize generated images from one image\nplt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","a2bc733b":"# initializing the CNN\nmodel = Sequential()\n\n# Convolution layer-1\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Convolution layer-2\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Convolution layer-3\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# flattening layer\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Output layer\nmodel.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n# summary of model\nmodel.summary()","38e591ee":"# EarlyStopping\nearlystop = EarlyStopping(monitor = 'val_loss',\n                          min_delta = 0,\n                          patience = 7,\n                          verbose = 1,\n                          restore_best_weights = True)\n\n# ModelCheckPoint\ncheckPoint = keras.callbacks.ModelCheckpoint(filepath=\"\/content\/sample_data\/cd_model.h5\",\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\n# ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\n# TBoard = tf.keras.callbacks.TensorBoard(log_dir='.\/logs')","bcae5343":"callbacks = [earlystop , checkPoint, learning_rate_reduction]","cac607af":"# this code is to show how much time required to train the model using different algorithms\nfrom datetime import datetime\ndef timer(start_time= None):\n  if not start_time:\n    start_time=datetime.now()\n    return start_time\n  elif start_time:\n    thour,temp_sec=divmod((datetime.now()-start_time).total_seconds(),3600)\n    tmin,tsec=divmod(temp_sec,60)\n    print('\\n Time taken: %i hours %i minutes and %s seconds. '% (thour,tmin,round(tsec,2)))","9f652a78":"start_time=timer(None)\nepochs=3 if FAST_RUN else 40   \nclassifier = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validate_df_size\/\/batch_size,\n    steps_per_epoch=train_df_size\/\/batch_size,\n    callbacks=callbacks\n)\ntimer(start_time)","5239be24":"# As we have used ModelCheckpoint callback function.So no need to save again if your model trained completely.\n#Saving Scikitlearn models\nmodel.save(\"\/kaggle\/working\/cat_dog_classifierr.h5\")","fa67715a":"from keras.models import load_model\nnew_model = load_model('\/kaggle\/working\/cat_dog_classifierr.h5')","39ca116c":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n\n# plot graph of training loss & validation loss\nax1.plot(classifier.history['loss'], color='b', label=\"Training loss\")\nax1.plot(classifier.history['val_loss'], color='r', label=\"validation loss\")\nax1.set_xticks(np.arange(1, 30, 1))\nax1.set_yticks(np.arange(0, 1, 0.1))\nax1.set_xlabel(\"epochs\")\nax1.set_ylabel(\"loss\")\nax1.set_title(\"Graph of training loss & validation loss\")\n\n# plot graph of training accuracy & validation accuracy\nax2.plot(classifier.history['accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(classifier.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nax2.set_xticks(np.arange(1, 30, 1))\nax1.set_xlabel(\"epochs\")\nax1.set_ylabel(\"accuracy\")\nax1.set_title(\"Graph of training accuracy & validation accuracy\")\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","14b271d9":"# unzip the dataset\nfrom zipfile import ZipFile\nzf = ZipFile('..\/input\/dogs-vs-cats\/test1.zip')\nzf.extractall('\/kaggle\/working') #save files in selected folder\nzf.close()","65e31192":"# create a dataframe and store all image files\ntest_filenames = os.listdir(\"\/kaggle\/working\/test1\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnb_samples = test_df.shape[0]","82d62f44":"test_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"\/kaggle\/working\/test1\/\",\n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","344a873b":"# find prediction using predict_generator\npredict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","e6bba292":"# here \"category\" column store the index of higher predicted value\ntest_df['category'] = np.argmax(predict, axis=-1)","6181bb9f":"# here predicted value will replace by \"cat\" for 0 & \"dog\" for 1\nlabel_map = dict((v,k) for k,v in train_generator.class_indices.items())\ntest_df['category'] = test_df['category'].replace(label_map)","08cf592c":"# See predicted dataframe\ntest_df.head()","06267179":"# see how many images classify into which class \ntest_df['category'].value_counts().plot.bar()","e8462a49":"sample_test = test_df.head(18)\nsample_test.head()\nplt.figure(figsize=(12, 24))\nfor index, row in sample_test.iterrows():\n    filename = row['filename']\n    category = row['category']\n    img = load_img(\"\/kaggle\/working\/test1\/\"+filename, target_size=IMAGE_SIZE)\n    plt.subplot(6, 3, index+1)\n    plt.imshow(img)\n    plt.xlabel(filename + '(' + \"{}\".format(category.upper()) + ')' )\nplt.tight_layout()\nplt.show()","2db47b3f":"## **4.2. Training Generator**","1e5b9577":"## **4.3. Validation Generator**","cdf124db":"# **5. Model Building**\n<img src=\"https:\/\/media.geeksforgeeks.org\/wp-content\/uploads\/cat-vs-dog.jpg\" width=\"100%\"\/>","5bd2da7f":"## **5.1. Callback Functions**\nA callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.\n- **EarlyStopping** : Used to avoid overfitting.Here we'll stop the training if there is no improvement in 3 conjecutive epochs.\n- **ModelCheckpoint** : This callback saves the model after every epoch.The model'll save in a particular location with minimun 'val_loss'.\n- **ReduceLROnPlateau** : It reduces learning rate when a metric has stopped improving.\nFor more about callback function click [here](https:\/\/www.kdnuggets.com\/2019\/08\/keras-callbacks-explained-three-minutes.html) [here](https:\/\/keras.io\/api\/callbacks\/)","edd8d61f":"# **4.Data Pre-processing**\nAs we use image genaretor `with class_mode=\"categorical\"`. We need to convert column category into string. Then imagenerator will convert it one-hot encoding. \n\nSo we will convert 1 to \"dog\" and 0 to \"cat\"","80935890":"### The complete code of \"Cat Dog Classification Flask App\" is available on my github profile.\n### Click [here](https:\/\/github.com\/sidharth178\/Cat-Dog-Classification-Flask-App) to access.\n### If you find this notebook useful,don't forget to give a **Upvote**","3c6fbb26":"# **3. Prepare Training Data**\nHere we will create dataframe which will store all file names in \"filenames\" column and value \"1\" for \"dog\" and \"0\" for \"cat\". ","b8619f6b":"# **1. Import Library**","8ced6546":"If you get any issues during run this notebook.Feel free to contact.\n[Linkedin](https:\/\/www.linkedin.com\/in\/sidharth178),\n[Github](https:\/\/github.com\/sidharth178)\n\nThank You.\n","97d7b17a":"## **4.1. Define Constants**","1c3cfabd":"## **5.2. Model Fitting**","5178504a":"<a href=\"https:\/\/colab.research.google.com\/github\/sidharth178\/Cat-Dog-Classification-Flask-App\/blob\/master\/cat_dog_classification.ipynb\" target=\"_parent\"><img src=\"https:\/\/colab.research.google.com\/assets\/colab-badge.svg\" alt=\"Open In Colab\"\/><\/a>","08f35717":"# **Table of Contents**\n\n1. Introduction\n1. Import library\n1. Fetch datasets from kaggle\n1. Prepare training data\n1. Data pre-processing\n1. Model building\n1. Prepare testing data\n1. Find prediction\n\n","4dec04db":"## **3.1. Sample Image**","7a531640":"## **5.5. Visualize training accuracy and loss**","c612aa38":"* **Conv Layer**: Convolutional layers are the layers where filters are applied to the original image, or to other feature maps in a deep CNN.\n* **Conv2D Layer**: Conv2D is a 2D Convolution Layer, this layer creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n* **Pooling Layer**: Its function is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network.\n* **Fully Connected Layer**: It connect the network from a layer to another layer\n* **Output Layer**: It is the predicted values layer. \n* **BatchNormalization**: Layer that normalizes its inputs.Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.","90339094":"# **2. Fetch datasets from kaggle**","86ba49de":"## **5.3. Save the Model**","61899a06":"## **5.4. Load Model**","ea7ecd15":"## **6.1. Create Testing Generator**","9232e5ec":"# **7. Find Prediction**","7f5a1785":"## **7.2. See Predicted Image With Images**","67981397":"# **Introduction**\n\nIn this project, we'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats but our computer will find it a bit more difficult.\n### Data Description\nThe folder \"train\" contains two sub-folders \"cats\" & \"dogs\" which contain images of cats and dogs respectively.The folder \"test1\" contain unknown images which we have to classify.\n### Data\nTo download the Dataset click [here](https:\/\/www.kaggle.com\/c\/dogs-vs-cats\/data)\n### Objective\nTo build a deep learning classification model which classify whether images contain either a dog or a cat. \n\n","97aad6b6":"# **6. Prepare Testing Data**","90fcd839":"## **7.1. Visualize Result**","8096aa1d":"## **4.4. See how generator work**"}}