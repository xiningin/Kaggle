{"cell_type":{"6067962a":"code","3c14c847":"code","49c82c67":"code","9a9ed1b4":"code","03532b42":"code","7682beae":"code","271ec963":"code","cc859261":"code","02b63a83":"code","ecb00e69":"code","5ed0cc03":"code","c0e64769":"code","a7bd83ec":"code","33642bb3":"code","422e932d":"code","443f374b":"code","e956eccf":"code","d339927a":"code","53553914":"code","d55640d7":"code","15ffab37":"code","e8352021":"code","2dcc66d6":"markdown","95239368":"markdown","85b0576f":"markdown","6fd6c071":"markdown","1caeb20a":"markdown"},"source":{"6067962a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3c14c847":"import matplotlib.pyplot as plt\nimport seaborn as sns\ndataset=pd.read_csv('\/kaggle\/input\/new-blackfriday-dataset\/trainBlackFridayData.csv')\ndataset.head()\ndf1=dataset\n","49c82c67":"df1.info()","9a9ed1b4":"df1['Product_Category_2'].fillna(df1['Product_Category_2'].mode()[0], inplace=True)\ndf1['Product_Category_3'].fillna(df1['Product_Category_3'].mode()[0], inplace=True)","03532b42":"df1['Quantity']=df1['Product_Category_1']+df1['Product_Category_2']+df1['Product_Category_3']","7682beae":"df1","271ec963":"df1.City_Category.value_counts().head(5)","cc859261":"from mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\nimport pandas as pd\nimport numpy as np\n","02b63a83":"#using only B City data for now can check for other as well..\ndf1 = df1[df1.City_Category == 'B']","ecb00e69":"basket = pd.pivot_table(data=df1,index='User_ID',columns='Product_ID',values='Quantity', \\\n                        aggfunc='sum',fill_value=0)","5ed0cc03":"basket.head()","c0e64769":"# we dont need quantity sum we need either has taken or not so if user has taken that item mark as 1 else he has not taken 0.\ndef convert_into_binary(x):\n    if x > 0:\n        return 1\n    else:\n        return 0","a7bd83ec":"basket_sets = basket.applymap(convert_into_binary)","33642bb3":"#call apriori function and pass minimum support here we are passing 7%. means 7 times in total number of transaction that item was present.\nfrequent_itemsets = apriori(basket_sets, min_support=0.07, use_colnames=True)","422e932d":"#it will generate frequent itemsets using two step approch\nfrequent_itemsets","443f374b":"# we have association rules which need to put on frequent itemset. here we are setting based on lift and has minimum lift as 1\nfrom mlxtend.frequent_patterns import association_rules\nrules_mlxtend = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\nrules_mlxtend.head()","e956eccf":"rules_mlxtend.sort_values(by='support',ascending=False)","d339927a":"rules=rules_mlxtend\n","53553914":"plt.scatter(rules['support'], rules['confidence'], alpha=0.5)\nplt.xlabel('support')\nplt.ylabel('confidence')\nplt.title('Support vs Confidence')\nplt.show()","d55640d7":"Lin","15ffab37":"plt.scatter(rules['support'], rules['lift'], alpha=0.5)\nplt.xlabel('support')\nplt.ylabel('lift')\nplt.title('Support vs lift')\nplt.show()","e8352021":"\nplt.scatter(rules['confidence'], rules['lift'], alpha=0.5)\nplt.xlabel('confidence')\nplt.ylabel('lift')\nplt.title('confidence vs lift')\nplt.show()\n","2dcc66d6":"****There is strong correlation between ****","95239368":"# In City B , P00025442 is very popular because of highest Support value. Confidence that byuer will buy P00110742 if P00025442 is bought is 50%. Also Lift(1.440) is > than 1. That means (P00025442) & (P00110742)  has strong association.\nFurther the extract for City B will be downloaded and provided to store managers to rearrange the products in stores of city based on the Association rules. Similarly Association rules between products can be generated for other Cities A and C.","85b0576f":"\n# For few products Y : small change in popularity of X makes large chance of selling Y.\n # For most of the products Y : small change in popularity of X makes large chance of selling Y.\n \n![image.png](attachment:image.png)","6fd6c071":"![image.png](attachment:image.png)","1caeb20a":"Definition\nAssociation rules analysis is a technique to uncover how items are associated to each other. There are three common ways to measure association. These measures are very handy to identify the buying patterns of customers.\n\nMeasure 1: Support (Popularity) This says how popular an itemset is, as measured by the proportion of transactions in which an itemset appears. More popular items being more revenues.\n\nMeasure 2: Coincidene Confidence that customer will by Y if they buy X . Might be good measure of instant gratification that Y is sold because of X, But in reality there might be no or minimal association between X and Y. So this measure is mere Coincidence Confidence. What other items goes along with most popular items.\n\nMeasure 3: Lift (Real Association). A lift value greater than 1 means that item Y is likely to be bought if item X is bought, while a value less than 1 means that item Y is unlikely to be bought if item X is bought. What are the real associated items with most popular items.\n\nMore please visit https:\/\/www.kdnuggets.com\/2016\/04\/association-rules-apriori-algorithm-tutorial.html"}}